<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-19  A Multi-task Learning Balanced Attention Convolutional Neural Network   Model for Few-shot Underwater Acoustic Target Recognition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-32bb27d88ec1de00ca71c257db318708.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-19-æ›´æ–°"><a href="#2025-04-19-æ›´æ–°" class="headerlink" title="2025-04-19 æ›´æ–°"></a>2025-04-19 æ›´æ–°</h1><h2 id="A-Multi-task-Learning-Balanced-Attention-Convolutional-Neural-Network-Model-for-Few-shot-Underwater-Acoustic-Target-Recognition"><a href="#A-Multi-task-Learning-Balanced-Attention-Convolutional-Neural-Network-Model-for-Few-shot-Underwater-Acoustic-Target-Recognition" class="headerlink" title="A Multi-task Learning Balanced Attention Convolutional Neural Network   Model for Few-shot Underwater Acoustic Target Recognition"></a>A Multi-task Learning Balanced Attention Convolutional Neural Network   Model for Few-shot Underwater Acoustic Target Recognition</h2><p><strong>Authors:Wei Huang, Shumeng Sun, Junpeng Lu, Zhenpeng Xu, Zhengyang Xiu, Hao Zhang</strong></p>
<p>Underwater acoustic target recognition (UATR) is of great significance for the protection of marine diversity and national defense security. The development of deep learning provides new opportunities for UATR, but faces challenges brought by the scarcity of reference samples and complex environmental interference. To address these issues, we proposes a multi-task balanced channel attention convolutional neural network (MT-BCA-CNN). The method integrates a channel attention mechanism with a multi-task learning strategy, constructing a shared feature extractor and multi-task classifiers to jointly optimize target classification and feature reconstruction tasks. The channel attention mechanism dynamically enhances discriminative acoustic features such as harmonic structures while suppressing noise. Experiments on the Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97% classification accuracy and 95% $F1$-score in 27-class few-shot scenarios, significantly outperforming traditional CNN and ACNN models, as well as popular state-of-the-art UATR methods. Ablation studies confirm the synergistic benefits of multi-task learning and attention mechanisms, while a dynamic weighting adjustment strategy effectively balances task contributions. This work provides an efficient solution for few-shot underwater acoustic recognition, advancing research in marine bioacoustics and sonar signal processing. </p>
<blockquote>
<p>æ°´ä¸‹å£°å­¦ç›®æ ‡è¯†åˆ«ï¼ˆUATRï¼‰å¯¹äºä¿æŠ¤æµ·æ´‹å¤šæ ·æ€§å’Œå›½é˜²å®‰å…¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸ºUATRæä¾›äº†æ–°çš„æœºé‡ï¼Œä½†é¢ä¸´ç€å‚è€ƒæ ·æœ¬ç¨€ç¼ºå’Œå¤æ‚ç¯å¢ƒå¹²æ‰°æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šä»»åŠ¡å¹³è¡¡é€šé“æ³¨æ„åŠ›å·ç§¯ç¥ç»ç½‘ç»œï¼ˆMT-BCA-CNNï¼‰ã€‚è¯¥æ–¹æ³•å°†é€šé“æ³¨æ„åŠ›æœºåˆ¶ä¸å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ç›¸ç»“åˆï¼Œæ„å»ºå…±äº«ç‰¹å¾æå–å™¨å’Œå¤šä»»åŠ¡åˆ†ç±»å™¨ï¼Œè”åˆä¼˜åŒ–ç›®æ ‡åˆ†ç±»å’Œç‰¹å¾é‡å»ºä»»åŠ¡ã€‚é€šé“æ³¨æ„åŠ›æœºåˆ¶èƒ½å¤ŸåŠ¨æ€å¢å¼ºé‰´åˆ«æ€§å£°å­¦ç‰¹å¾ï¼Œå¦‚è°æ³¢ç»“æ„ï¼ŒåŒæ—¶æŠ‘åˆ¶å™ªå£°ã€‚åœ¨Watkinsæµ·æ´‹ç”Ÿå‘½æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMT-BCA-CNNåœ¨27ç±»å°æ ·æœ¬åœºæ™¯ä¸‹å®ç°äº†97%çš„åˆ†ç±»å‡†ç¡®ç‡å’Œ95%çš„F1åˆ†æ•°ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„CNNå’ŒACNNæ¨¡å‹ï¼Œä»¥åŠå…¶ä»–æµè¡Œçš„å…ˆè¿›UATRæ–¹æ³•ã€‚æ¶ˆèç ”ç©¶è¯å®äº†å¤šä»»åŠ¡å­¦ä¹ å’Œæ³¨æ„åŠ›æœºåˆ¶çš„ååŒæ•ˆç›Šï¼Œè€ŒåŠ¨æ€æƒé‡è°ƒæ•´ç­–ç•¥æœ‰æ•ˆåœ°å¹³è¡¡äº†ä»»åŠ¡è´¡çŒ®ã€‚è¿™é¡¹å·¥ä½œä¸ºå°æ°´å£°è¯†åˆ«æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨äº†æµ·æ´‹ç”Ÿç‰©å£°éŸ³å­¦å’Œå£°çº³ä¿¡å·å¤„ç†çš„ç ”ç©¶è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13102v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ°´ä¸‹å£°å­¦ç›®æ ‡è¯†åˆ«ï¼ˆUATRï¼‰å¯¹ä¿æŠ¤æµ·æ´‹å¤šæ ·æ€§å’Œå›½é˜²å®‰å…¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸ºUATRæä¾›äº†æ–°çš„æœºé‡ï¼Œä½†é¢ä¸´æ ·æœ¬ç¨€ç¼ºå’Œå¤æ‚ç¯å¢ƒå¹²æ‰°çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šä»»åŠ¡å¹³è¡¡é€šé“æ³¨æ„åŠ›å·ç§¯ç¥ç»ç½‘ç»œï¼ˆMT-BCA-CNNï¼‰ï¼Œç»“åˆé€šé“æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼Œæ„å»ºå…±äº«ç‰¹å¾æå–å™¨å’Œå¤šä»»åŠ¡åˆ†ç±»å™¨ï¼Œè”åˆä¼˜åŒ–ç›®æ ‡åˆ†ç±»å’Œç‰¹å¾é‡å»ºä»»åŠ¡ã€‚åœ¨ç“¦ç‰¹é‡‘æ–¯æµ·æ´‹ç”Ÿå‘½æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMT-BCA-CNNåœ¨27ç±»å°æ ·æœ¬åœºæ™¯ä¸­å®ç°97%çš„åˆ†ç±»å‡†ç¡®ç‡å’Œ95%çš„F1åˆ†æ•°ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»ŸCNNå’ŒACNNæ¨¡å‹ï¼Œä»¥åŠæµè¡Œçš„é«˜çº§UATRæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹å£°å­¦ç›®æ ‡è¯†åˆ«ï¼ˆUATRï¼‰å¯¹æµ·æ´‹å¤šæ ·æ€§å’Œå›½é˜²å®‰å…¨è‡³å…³é‡è¦ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨UATRä¸­æä¾›æ–°æœºé‡ï¼Œä½†é¢ä¸´æ ·æœ¬ç¨€ç¼ºå’Œç¯å¢ƒå¹²æ‰°çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ç§å¤šä»»åŠ¡å¹³è¡¡é€šé“æ³¨æ„åŠ›å·ç§¯ç¥ç»ç½‘ç»œï¼ˆMT-BCA-CNNï¼‰ã€‚</li>
<li>ç»“åˆé€šé“æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ï¼Œä¼˜åŒ–ç›®æ ‡åˆ†ç±»å’Œç‰¹å¾é‡å»ºã€‚</li>
<li>MT-BCA-CNNåœ¨ç“¦ç‰¹é‡‘æ–¯æµ·æ´‹ç”Ÿå‘½æ•°æ®é›†ä¸Šå®ç°é«˜åˆ†ç±»å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ã€‚</li>
<li>ç›¸è¾ƒäºä¼ ç»ŸCNNå’ŒACNNæ¨¡å‹ä»¥åŠé«˜çº§UATRæ–¹æ³•ï¼ŒMT-BCA-CNNè¡¨ç°æ›´ä¼˜ç§€ã€‚</li>
<li>æ¶ˆèç ”ç©¶è¯å®äº†å¤šä»»åŠ¡å­¦ä¹ å’Œæ³¨æ„åŠ›æœºåˆ¶çš„ååŒæ•ˆç›Šï¼ŒåŠ¨æ€åŠ æƒè°ƒæ•´ç­–ç•¥æœ‰æ•ˆå¹³è¡¡ä»»åŠ¡è´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13102">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cafabe316f39dd21830c708d70ec6f2c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c91f23658d8841229743485284e86623.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7be2d8818386a7aa34b98baaef2a093d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Knowledge-Acquisition-on-Mass-shooting-Events-via-LLMs-for-AI-Driven-Justice"><a href="#Knowledge-Acquisition-on-Mass-shooting-Events-via-LLMs-for-AI-Driven-Justice" class="headerlink" title="Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven   Justice"></a>Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven   Justice</h2><p><strong>Authors:Benign John Ihugba, Afsana Nasrin, Ling Wu, Lin Li, Lijun Qian, Xishuang Dong</strong></p>
<p>Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts. This paper presented the first dataset designed for knowledge acquisition on mass-shooting events through the application of named entity recognition (NER) techniques. It focuses on identifying key entities such as offenders, victims, locations, and criminal instruments, that are vital for legal and investigative purposes. The NER process is powered by Large Language Models (LLMs) using few-shot prompting, facilitating the efficient extraction and organization of critical information from diverse sources, including news articles, police reports, and social media. Experimental results on real-world mass-shooting corpora demonstrate that GPT-4o is the most effective model for mass-shooting NER, achieving the highest Micro Precision, Micro Recall, and Micro F1-scores. Meanwhile, o1-mini delivers competitive performance, making it a resource-efficient alternative for less complex NER tasks. It is also observed that increasing the shot count enhances the performance of all models, but the gains are more substantial for GPT-4o and o1-mini, highlighting their superior adaptability to few-shot learning scenarios. </p>
<blockquote>
<p>å¤§è§„æ¨¡æªå‡»äº‹ä»¶å¯¹å…¬å…±å®‰å…¨æ„æˆé‡å¤§æŒ‘æˆ˜ï¼Œäº§ç”Ÿå¤§é‡éç»“æ„åŒ–æ–‡æœ¬æ•°æ®ï¼Œå¦¨ç¢äº†æœ‰æ•ˆçš„è°ƒæŸ¥å’Œå…¬å…±æ”¿ç­–çš„åˆ¶å®šã€‚å°½ç®¡å½¢åŠ¿ç´§è¿«ï¼Œä½†ä¹‹å‰çš„ç ”ç©¶å¾ˆå°‘æœ‰æ•ˆåœ°å®ç°è‡ªåŠ¨åŒ–æå–è¿™äº›äº‹ä»¶ä¸­çš„å…³é”®ä¿¡æ¯æ¥æ”¯æŒæ³•å¾‹å’Œè°ƒæŸ¥å·¥ä½œã€‚æœ¬æ–‡é€šè¿‡åº”ç”¨å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æŠ€æœ¯ï¼Œå±•ç¤ºäº†é¦–ä¸ªé’ˆå¯¹å¤§è§„æ¨¡æªå‡»äº‹ä»¶çš„çŸ¥è¯†è·å–æ•°æ®é›†çš„è®¾è®¡ã€‚è¯¥æ•°æ®é›†ä¾§é‡äºè¯†åˆ«å¯¹æ³•å¾‹å’Œè°ƒæŸ¥ç›®çš„è‡³å…³é‡è¦çš„å…³é”®å®ä½“ï¼Œå¦‚ç½ªçŠ¯ã€å—å®³è€…ã€åœ°ç‚¹å’ŒçŠ¯ç½ªå·¥å…·ã€‚NERè¿‡ç¨‹ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å°æ ·æœ¬æç¤ºåŠŸèƒ½é©±åŠ¨ï¼Œå¯ä»¥é«˜æ•ˆåœ°æå–å’Œç»„ç»‡æ¥è‡ªæ–°é—»æ–‡ç« ã€è­¦æ–¹æŠ¥å‘Šå’Œç¤¾ä¼šåª’ä½“ç­‰ä¸åŒæ¥æºçš„å…³é”®ä¿¡æ¯ã€‚åœ¨ç°å®çš„å¤§è§„æ¨¡æªå‡»è¯­æ–™åº“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oæ˜¯æªå‡»äº‹ä»¶NERæœ€æœ‰æ•ˆçš„æ¨¡å‹ï¼Œè·å¾—äº†æœ€é«˜çš„å¾®è§‚ç²¾åº¦ã€å¾®è§‚å¬å›ç‡å’Œå¾®è§‚F1åˆ†æ•°ã€‚åŒæ—¶ï¼Œo1-miniä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå¯¹äºè¾ƒç®€å•çš„NERä»»åŠ¡æ¥è¯´æ˜¯ä¸€ä¸ªèµ„æºé«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚æ­¤å¤–è¿˜å‘ç°ï¼Œå¢åŠ æ ·æœ¬æ•°é‡å¯ä»¥æé«˜æ‰€æœ‰æ¨¡å‹çš„è¡¨ç°ï¼Œä½†GPT-4oå’Œo1-miniçš„å¢ç›Šæ›´å¤§ï¼Œå‡¸æ˜¾äº†å®ƒä»¬åœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­çš„å“è¶Šé€‚åº”æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12545v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡é’ˆå¯¹å¤§è§„æ¨¡æªå‡»äº‹ä»¶å¯¹å…¬å…±å®‰å…¨æ„æˆçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†è¿ç”¨å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æŠ€æœ¯åˆ›å»ºé¦–ä¸ªç›¸å…³æ•°æ®é›†çš„æ–¹æ³•ã€‚è¯¥æ•°æ®é›†èƒ½å¤Ÿè¯†åˆ«å…³é”®å®ä½“ï¼Œå¦‚ç½ªçŠ¯ã€å—å®³è€…ã€åœ°ç‚¹å’ŒçŠ¯ç½ªå·¥å…·ç­‰ï¼Œå¯¹æ³•å¾‹å’Œè°ƒæŸ¥å·¥ä½œè‡³å…³é‡è¦ã€‚åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå°‘æ ·æœ¬æç¤ºï¼Œå¯ä»æ–°é—»æ–‡ç« ã€è­¦æ–¹æŠ¥å‘Šå’Œç¤¾ä¼šåª’ä½“ç­‰æ¥æºé«˜æ•ˆæå–å’Œç»„ç»‡å…³é”®ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨å¤§è§„æ¨¡æªå‡»äº‹ä»¶NERä¸­æœ€æœ‰æ•ˆï¼Œè€Œo1-miniåœ¨è¾ƒç®€å•çš„NERä»»åŠ¡ä¸­å…·æœ‰èµ„æºæ•ˆç‡é«˜çš„ç«äº‰ä¼˜åŠ¿ã€‚å¢åŠ å°„å‡»æ¬¡æ•°æœ‰åŠ©äºæé«˜æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½ï¼Œä½†GPT-4oå’Œo1-miniçš„å¢ç›Šæ›´ä¸ºæ˜¾è‘—ï¼Œçªæ˜¾äº†å®ƒä»¬å¯¹å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯çš„å“è¶Šé€‚åº”æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è§„æ¨¡æªå‡»äº‹ä»¶å¯¹å…¬å…±å®‰å…¨æ„æˆé‡å¤§æŒ‘æˆ˜ï¼ŒäºŸéœ€è‡ªåŠ¨åŒ–æå–å…³é”®ä¿¡æ¯ä»¥æ”¯æŒæ³•å¾‹å’Œè°ƒæŸ¥å·¥ä½œã€‚</li>
<li>å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æŠ€æœ¯åœ¨å¤„ç†å¤§è§„æ¨¡æªå‡»äº‹ä»¶ä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼Œå¯è¯†åˆ«ç½ªçŠ¯ã€å—å®³è€…ã€åœ°ç‚¹å’ŒçŠ¯ç½ªå·¥å…·ç­‰å…³é”®å®ä½“ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå°‘æ ·æœ¬æç¤ºï¼Œå¯ä»å¤šç§æ¥æºé«˜æ•ˆæå–å’Œç»„ç»‡å…³é”®ä¿¡æ¯ã€‚</li>
<li>GPT-4oåœ¨å¤§è§„æ¨¡æªå‡»äº‹ä»¶NERä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œå…·æœ‰æœ€é«˜çš„å¾®ç²¾åº¦ã€å¾®å¬å›ç‡å’Œå¾®F1åˆ†æ•°ã€‚</li>
<li>o1-miniåœ¨èµ„æºæ•ˆç‡æ–¹é¢è¡¨ç°å‡ºç«äº‰ä¼˜åŠ¿ï¼Œé€‚ç”¨äºè¾ƒç®€å•çš„NERä»»åŠ¡ã€‚</li>
<li>å¢åŠ å°„å‡»æ¬¡æ•°æœ‰åŠ©äºæé«˜æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12545">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-34b008a2b7ae2964c09faba6fb8b0ca0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5192b1e185fd3f18015d88abcaebab9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a542dd9034dcc66b4d0f614bc6f37ef1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6218bee2e7c5dc15f2c644249bffcd65.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c24c1e5f07a0850a290bb3f0ae5e28be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fbba94e4d11ba6b4d2adf16477912bef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87e657391bedbf51ead4037f4388f23b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Sparsity-Outperforms-Low-Rank-Projections-in-Few-Shot-Adaptation"><a href="#Sparsity-Outperforms-Low-Rank-Projections-in-Few-Shot-Adaptation" class="headerlink" title="Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation"></a>Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation</h2><p><strong>Authors:Nairouz Mrabah, Nicolas Richet, Ismail Ben Ayed, Ã‰ric Granger</strong></p>
<p>Adapting Vision-Language Models (VLMs) to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints. State-of-the-art solutions, such as low-rank reparameterization, mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning. In this paper, a novel Sparse Optimization (SO) framework is proposed. Unlike low-rank approaches that typically constrain updates to a fixed subspace, our SO method leverages high sparsity to dynamically adjust very few parameters. We introduce two key paradigms. First, we advocate for \textit{local sparsity and global density}, which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness. As a second paradigm, we advocate for \textit{local randomness and global importance}, which sparsifies the gradient using random selection while pruning the first moment based on importance. This combination significantly mitigates overfitting and ensures stable adaptation in low-data regimes. Extensive experiments on 11 diverse datasets show that SO achieves state-of-the-art few-shot adaptation performance while reducing memory overhead. </p>
<blockquote>
<p>å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é€‚åº”å…·æœ‰å°‘é‡æ ‡è®°æ ·æœ¬çš„æ–°é¢†åŸŸä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºä¸¥é‡çš„è¿‡åº¦æ‹Ÿåˆå’Œè®¡ç®—çº¦æŸã€‚æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆï¼Œå¦‚ä½ç§©é‡å‚æ•°åŒ–ï¼Œç¼“è§£äº†è¿™äº›é—®é¢˜ï¼Œä½†åœ¨æ¨å¹¿æ–¹é¢ç»å¸¸é‡åˆ°å›°éš¾ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡è°ƒæ•´è¶…å‚æ•°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç¨€ç–ä¼˜åŒ–ï¼ˆSOï¼‰æ¡†æ¶ã€‚ä¸é€šå¸¸å°†æ›´æ–°é™åˆ¶åœ¨å›ºå®šå­ç©ºé—´ä¸­çš„ä½ç§©æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„SOæ–¹æ³•åˆ©ç”¨é«˜ç¨€ç–æ€§æ¥åŠ¨æ€è°ƒæ•´æå°‘çš„å‚æ•°ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸¤ç§å…³é”®èŒƒå¼ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå€¡â€œå±€éƒ¨ç¨€ç–æ€§å’Œå…¨å±€å¯†åº¦â€ï¼Œè¿™å¯ä»¥åœ¨æ¯æ¬¡è¿­ä»£æ—¶æ›´æ–°ä¸€å°éƒ¨åˆ†å‚æ•°ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ•´ä½“è¡¨è¾¾èƒ½åŠ›ã€‚ä½œä¸ºç¬¬äºŒç§èŒƒå¼ï¼Œæˆ‘ä»¬æå€¡â€œå±€éƒ¨éšæœºæ€§å’Œå…¨å±€é‡è¦æ€§â€ï¼Œä½¿ç”¨éšæœºé€‰æ‹©æ¥ç¨€ç–æ¢¯åº¦ï¼Œå¹¶æ ¹æ®é‡è¦æ€§æ¥ä¿®å‰ªç¬¬ä¸€æ—¶åˆ»ã€‚è¿™ç§ç»“åˆæ˜¾è‘—å‡è½»äº†è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶ç¡®ä¿åœ¨ä½æ•°æ®æƒ…å†µä¸‹å®ç°ç¨³å®šçš„é€‚åº”ã€‚åœ¨11ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSOåœ¨å°‘é‡æ ·æœ¬é€‚åº”æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘äº†å†…å­˜å¼€é”€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12436v1">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„Sparse Optimizationï¼ˆSOï¼‰æ¡†æ¶ï¼Œç”¨äºè§£å†³åœ¨å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸‹å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é€‚åº”æ–°é¢†åŸŸçš„é—®é¢˜ã€‚é€šè¿‡å¼•å…¥å±€éƒ¨ç¨€ç–æ€§å’Œå…¨å±€å¯†åº¦ä»¥åŠå±€éƒ¨éšæœºæ€§å’Œå…¨å±€é‡è¦æ€§çš„ä¸¤ä¸ªå…³é”®èŒƒå¼ï¼ŒSOæ–¹æ³•èƒ½å¤Ÿåœ¨åŠ¨æ€è°ƒæ•´æå°‘å‚æ•°çš„åŒæ—¶é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œç¡®ä¿åœ¨ä½æ•°æ®ç¯å¢ƒä¸‹çš„ç¨³å®šé€‚åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSOåœ¨11ä¸ªä¸åŒæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å°‘æ ·æœ¬é€‚åº”æ€§èƒ½ï¼Œå¹¶é™ä½äº†å†…å­˜å¼€é”€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sparse Optimization (SO)æ¡†æ¶è¢«æå‡ºç”¨äºè§£å†³åœ¨å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸‹å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é€‚åº”æ–°é¢†åŸŸçš„é—®é¢˜ã€‚</li>
<li>å½“å‰ä¸»æµæ–¹æ³•å¦‚ä½ç§©é‡å‚æ•°åŒ–è™½ç„¶èƒ½ç¼“è§£ä¸€äº›é—®é¢˜ï¼Œä½†åœ¨æ³›åŒ–å’Œè¶…å‚æ•°è°ƒæ•´æ–¹é¢ä»æœ‰æŒ‘æˆ˜ã€‚</li>
<li>SOæ–¹æ³•é€šè¿‡å¼•å…¥å±€éƒ¨ç¨€ç–æ€§å’Œå…¨å±€å¯†åº¦ä»¥åŠå±€éƒ¨éšæœºæ€§å’Œå…¨å±€é‡è¦æ€§çš„ä¸¤ä¸ªå…³é”®èŒƒå¼æ¥åŠ¨æ€è°ƒæ•´å‚æ•°ã€‚</li>
<li>SOæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—å‡è½»è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶ç¡®ä¿åœ¨ä½æ•°æ®ç¯å¢ƒä¸‹çš„ç¨³å®šé€‚åº”ã€‚</li>
<li>SOæ–¹æ³•åœ¨11ä¸ªä¸åŒæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å°‘æ ·æœ¬é€‚åº”æ€§èƒ½ã€‚</li>
<li>SOæ–¹æ³•é™ä½äº†å†…å­˜å¼€é”€ï¼Œæ˜¯ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12436">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1dc426cf3b5ee5f242807be0176ecfe6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72ca8c845e5e0c5b503a9a6cd06d6375.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4545d7555b25ee673a56a9af356a5cf6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency"><a href="#DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency" class="headerlink" title="DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency"></a>DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency</h2><p><strong>Authors:Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang</strong></p>
<p>Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation modelâ€™s generalization ability and has been applied to various vision tasks, including scene understanding and image&#x2F;video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAMâ€™s prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at <a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM">https://github.com/zaplm/DC-SAM</a>. </p>
<blockquote>
<p>ç»™å®šä¸€ä¸ªå•ä¸€æ ‡è®°çš„ç¤ºä¾‹ï¼Œä¸Šä¸‹æ–‡å†…åˆ†å‰²æ—¨åœ¨åˆ†å‰²ç›¸åº”çš„å¯¹è±¡ã€‚è¿™ç§è®¾ç½®è¢«ç§°ä¸ºå°æ ·æœ¬å­¦ä¹ ä¸­çš„ä¸€æ¬¡åˆ†å‰²ï¼Œæ—¨åœ¨æ¢ç´¢åˆ†å‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å·²åº”ç”¨äºå„ç§è§†è§‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬åœºæ™¯ç†è§£ã€å›¾åƒ&#x2F;è§†é¢‘ç¼–è¾‘ç­‰ã€‚å°½ç®¡æœ€è¿‘çš„Segment Anything Modelsåœ¨äº¤äº’å¼åˆ†å‰²æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼Œä½†è¿™äº›æ–¹æ³•å¹¶ä¸ç›´æ¥é€‚ç”¨äºä¸Šä¸‹æ–‡åˆ†å‰²ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åŸºäºæç¤ºå¾®è°ƒæå‡ºäº†åŒä¸€è‡´æ€§SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œä»¥é€‚åº”å›¾åƒå’Œè§†é¢‘çš„ä¸Šä¸‹æ–‡åˆ†å‰²ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€šè¿‡æä¾›é«˜è´¨é‡è§†è§‰æç¤ºæ¥å¢å¼ºSAMæç¤ºç¼–ç å™¨åœ¨åˆ†å‰²ä¸­çš„åŠŸèƒ½ã€‚åœ¨ç”Ÿæˆæ©è†œå…ˆéªŒæ—¶ï¼Œæˆ‘ä»¬èåˆSAMç‰¹å¾ä»¥æ›´å¥½åœ°å¯¹é½æç¤ºç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨èåˆçš„ç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºä¸Šè®¾è®¡äº†ä¸€ä¸ªå¾ªç¯ä¸€è‡´çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ã€‚æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä½¿ç”¨æç¤ºç¼–ç å™¨ä¸­çš„åˆ¤åˆ«æ€§æ­£å‘å’Œè´Ÿå‘æç¤ºï¼Œæä¾›äº†ä¸€ä¸ªåŒåˆ†æ”¯è®¾è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç®€å•çš„æ©è†œç®¡è®­ç»ƒç­–ç•¥ï¼Œå°†æ‰€æçš„åŒä¸€è‡´æ€§æ–¹æ³•åº”ç”¨åˆ°æ©è†œç®¡ä¸­ã€‚è™½ç„¶æ‰€æå‡ºDC-SAMä¸»è¦ä¸ºå›¾åƒè®¾è®¡ï¼Œä½†ç”±äºSAM2çš„æ”¯æŒï¼Œå®ƒå¯ä»¥æ— ç¼æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸã€‚é‰´äºè§†é¢‘é¢†åŸŸç¼ºä¹ä¸Šä¸‹æ–‡åˆ†å‰²ï¼Œæˆ‘ä»¬ä»ç°æœ‰çš„è§†é¢‘åˆ†å‰²æ•°æ®é›†ä¸­æ‰‹åŠ¨ç­›é€‰å’Œæ„å»ºç¬¬ä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼Œåä¸ºä¸Šä¸‹æ–‡è§†é¢‘å¯¹è±¡åˆ†å‰²ï¼ˆIC-VOSï¼‰ï¼Œä»¥æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹çš„ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨COCO-20iä¸Šå®ç°äº†55.5ï¼ˆ+1.4ï¼‰çš„mIoUï¼Œåœ¨PASCAL-5iä¸Šå®ç°äº†73.0ï¼ˆ+1.1ï¼‰çš„mIoUï¼Œåœ¨æå‡ºçš„IC-VOSåŸºå‡†æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†71.52çš„J&amp;Fåˆ†æ•°ã€‚æˆ‘ä»¬çš„æºä»£ç å’ŒåŸºå‡†æµ‹è¯•é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zaplm/DC-SAMä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12080v2">PDF</a> V1 has been withdrawn due to a template issue, because of the arXiv   policy, we canâ€™t delete it. Please refer to the newest version v2</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæç¤ºè°ƒæ•´ï¼ˆprompt-tuningï¼‰çš„Dual Consistency SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œç”¨äºå•æ¬¡ç¤ºä¾‹ä¸‹çš„ä¸Šä¸‹æ–‡åˆ†å‰²ï¼ˆin-context segmentationï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡é«˜è´¨é‡è§†è§‰æç¤ºå¢å¼ºSAMçš„æç¤ºç¼–ç å™¨ç‰¹å¾ï¼Œè®¾è®¡å¾ªç¯ä¸€è‡´çš„è·¨æ³¨æ„åŠ›èåˆç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºï¼Œå¹¶é‡‡ç”¨åŒåˆ†æ”¯è®¾è®¡ä½¿ç”¨åˆ¤åˆ«æ€§çš„æ­£è´Ÿæç¤ºã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç®€å•çš„mask-tubeè®­ç»ƒç­–ç•¥ï¼Œå¹¶å°†DC-SAMæ‰©å±•åˆ°è§†é¢‘é¢†åŸŸã€‚ä¸ºè¯„ä¼°æ¨¡å‹åœ¨è§†é¢‘é¢†åŸŸçš„ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œå»ºç«‹äº†ç¬¬ä¸€ä¸ªIn-Context Video Object Segmentationï¼ˆIC-VOSï¼‰åŸºå‡†æµ‹è¯•é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒDC-SAMæ–¹æ³•åœ¨COCO-20iä¸Šè¾¾åˆ°55.5ï¼ˆ+1.4ï¼‰mIoUï¼Œåœ¨PASCAL-5iä¸Šè¾¾åˆ°73.0ï¼ˆ+1.1ï¼‰mIoUï¼Œå¹¶åœ¨IC-VOSåŸºå‡†æµ‹è¯•é›†ä¸Šè·å¾—71.52çš„J&amp;Fåˆ†æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« ä»‹ç»äº†ä¸€ç§åä¸ºDC-SAMçš„æ–¹æ³•ï¼Œé’ˆå¯¹å•æ¬¡ç¤ºä¾‹ä¸‹çš„ä¸Šä¸‹æ–‡åˆ†å‰²é—®é¢˜ã€‚</li>
<li>DC-SAMæ–¹æ³•åŸºäºprompt-tuningæŠ€æœ¯ï¼Œæ—¨åœ¨é€šè¿‡é«˜è´¨é‡è§†è§‰æç¤ºå¢å¼ºç‰¹å¾ã€‚</li>
<li>æ–‡ç« è®¾è®¡äº†å¾ªç¯ä¸€è‡´çš„è·¨æ³¨æ„åŠ›æœºåˆ¶æ¥èåˆç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºã€‚</li>
<li>é‡‡ç”¨åŒåˆ†æ”¯è®¾è®¡ï¼Œä½¿ç”¨åˆ¤åˆ«æ€§çš„æ­£è´Ÿæç¤ºåœ¨æç¤ºç¼–ç å™¨ä¸­ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªç®€å•çš„mask-tubeè®­ç»ƒç­–ç•¥ï¼Œå°†DC-SAMæ–¹æ³•åº”ç”¨äºè§†é¢‘é¢†åŸŸã€‚</li>
<li>ä¸ºè¯„ä¼°æ¨¡å‹åœ¨è§†é¢‘é¢†åŸŸçš„ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œå»ºç«‹äº†ç¬¬ä¸€ä¸ªIC-VOSåŸºå‡†æµ‹è¯•é›†ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºDC-SAMæ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—æˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c457651c59c9412b47573ff0840b9a91.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c9799504f3fb87b3954c6ff0422be3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bfd5d15905207191d5e913afedf05e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b462c8815030c27c341509f58b8c06c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f366eeff5770f1b4e7b3c6555fc433e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e991b32da864ea5e7c3f4ae845353d1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Adaptive-Decision-Boundary-for-Few-Shot-Class-Incremental-Learning"><a href="#Adaptive-Decision-Boundary-for-Few-Shot-Class-Incremental-Learning" class="headerlink" title="Adaptive Decision Boundary for Few-Shot Class-Incremental Learning"></a>Adaptive Decision Boundary for Few-Shot Class-Incremental Learning</h2><p><strong>Authors:Linhao Li, Yongzhang Tan, Siyuan Yang, Hao Cheng, Yongfeng Dong, Liang Yang</strong></p>
<p>Few-Shot Class-Incremental Learning (FSCIL) aims to continuously learn new classes from a limited set of training samples without forgetting knowledge of previously learned classes. Conventional FSCIL methods typically build a robust feature extractor during the base training session with abundant training samples and subsequently freeze this extractor, only fine-tuning the classifier in subsequent incremental phases. However, current strategies primarily focus on preventing catastrophic forgetting, considering only the relationship between novel and base classes, without paying attention to the specific decision spaces of each class. To address this challenge, we propose a plug-and-play Adaptive Decision Boundary Strategy (ADBS), which is compatible with most FSCIL methods. Specifically, we assign a specific decision boundary to each class and adaptively adjust these boundaries during training to optimally refine the decision spaces for the classes in each session. Furthermore, to amplify the distinctiveness between classes, we employ a novel inter-class constraint loss that optimizes the decision boundaries and prototypes for each class. Extensive experiments on three benchmarks, namely CIFAR100, miniImageNet, and CUB200, demonstrate that incorporating our ADBS method with existing FSCIL techniques significantly improves performance, achieving overall state-of-the-art results. </p>
<blockquote>
<p>å°‘é‡ç±»åˆ«å¢é‡å­¦ä¹ ï¼ˆFSCILï¼‰æ—¨åœ¨ä»æœ‰é™çš„è®­ç»ƒæ ·æœ¬ä¸­æŒç»­å­¦ä¹ æ–°ç±»åˆ«ï¼ŒåŒæ—¶ä¸é—å¿˜å·²å­¦ä¹ ç±»åˆ«çš„çŸ¥è¯†ã€‚ä¼ ç»Ÿçš„FSCILæ–¹æ³•é€šå¸¸åœ¨åŸºç¡€è®­ç»ƒé˜¶æ®µåˆ©ç”¨ä¸°å¯Œçš„è®­ç»ƒæ ·æœ¬æ„å»ºå¼ºå¤§çš„ç‰¹å¾æå–å™¨ï¼Œéšåå†»ç»“è¯¥æå–å™¨ï¼Œä»…åœ¨åç»­çš„å¢é‡é˜¶æ®µå¾®è°ƒåˆ†ç±»å™¨ã€‚ç„¶è€Œï¼Œå½“å‰ç­–ç•¥ä¸»è¦ä¾§é‡äºé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œåªè€ƒè™‘æ–°ç±»åˆ«å’ŒåŸºç¡€ç±»åˆ«ä¹‹é—´çš„å…³ç³»ï¼Œè€Œæ²¡æœ‰å…³æ³¨æ¯ä¸ªç±»åˆ«çš„ç‰¹å®šå†³ç­–ç©ºé—´ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å³æ’å³ç”¨çš„è‡ªé€‚åº”å†³ç­–è¾¹ç•Œç­–ç•¥ï¼ˆADBSï¼‰ï¼Œå¯ä¸å¤§å¤šæ•°FSCILæ–¹æ³•å…¼å®¹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…ä¸€ä¸ªç‰¹å®šçš„å†³ç­–è¾¹ç•Œï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°è°ƒæ•´è¿™äº›è¾¹ç•Œï¼Œä»¥æœ€ä¼˜æ–¹å¼ç»†åŒ–æ¯ä¸ªä¼šè¯ä¸­ç±»åˆ«çš„å†³ç­–ç©ºé—´ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ”¾å¤§ç±»åˆ«ä¹‹é—´çš„å·®å¼‚ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æ–°å‹ç±»é—´çº¦æŸæŸå¤±ï¼Œè¯¥æŸå¤±ä¼˜åŒ–äº†æ¯ä¸ªç±»åˆ«çš„å†³ç­–è¾¹ç•Œå’ŒåŸå‹ã€‚åœ¨CIFAR100ã€miniImageNetå’ŒCUB200ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œå°†æˆ‘ä»¬çš„ADBSæ–¹æ³•ä¸ç°æœ‰çš„FSCILæŠ€æœ¯ç›¸ç»“åˆï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œè¾¾åˆ°æœ€æ–°çŠ¶æ€çš„æœ€ä½³ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10976v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†Few-Shotç±»å¢é‡å­¦ä¹ ï¼ˆFSCILï¼‰çš„ç›®æ ‡å’Œæ–¹æ³•ã€‚FSCILæ—¨åœ¨ä»æœ‰é™çš„è®­ç»ƒæ ·æœ¬ä¸­æŒç»­å­¦ä¹ æ–°ç±»ï¼ŒåŒæ—¶ä¸é—å¿˜å·²å­¦ä¹ ç±»çš„çŸ¥è¯†ã€‚ä¼ ç»ŸFSCILæ–¹æ³•é€šå¸¸åœ¨åŸºç¡€è®­ç»ƒé˜¶æ®µæ„å»ºå¼ºå¤§çš„ç‰¹å¾æå–å™¨ï¼Œå¹¶åœ¨åç»­å¢é‡é˜¶æ®µä»…å¾®è°ƒåˆ†ç±»å™¨ã€‚ç„¶è€Œï¼Œå½“å‰ç­–ç•¥ä¸»è¦å…³æ³¨é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œåªè€ƒè™‘æ–°ç±»å’ŒåŸºç±»ä¹‹é—´çš„å…³ç³»ï¼Œè€Œå¿½è§†äº†æ¯ä¸ªç±»çš„ç‰¹å®šå†³ç­–ç©ºé—´ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†å³æ’å³ç”¨çš„è‡ªé€‚åº”å†³ç­–è¾¹ç•Œç­–ç•¥ï¼ˆADBSï¼‰ï¼Œä¸å¤§å¤šæ•°FSCILæ–¹æ³•å…¼å®¹ã€‚é€šè¿‡ä¸ºæ¯ä¸ªç±»åˆ†é…ç‰¹å®šçš„å†³ç­–è¾¹ç•Œï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°è°ƒæ•´è¿™äº›è¾¹ç•Œï¼Œä»¥ä¼˜åŒ–æ¯ä¸ªä¼šè¯ä¸­çš„ç±»çš„å†³ç­–ç©ºé—´ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†ä¸€ç§æ–°å‹ç±»é—´çº¦æŸæŸå¤±ï¼Œä»¥ä¼˜åŒ–æ¯ä¸ªç±»çš„å†³ç­–è¾¹ç•Œå’ŒåŸå‹ï¼Œæé«˜äº†ç±»ä¹‹é—´çš„åŒºåˆ†åº¦ã€‚åœ¨CIFAR100ã€miniImageNetå’ŒCUB200ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œå°†ADBSæ–¹æ³•ä¸ç°æœ‰FSCILæŠ€æœ¯ç›¸ç»“åˆï¼Œå¯æ˜¾è‘—æé«˜æ€§èƒ½ï¼Œè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-Shot Class-Incremental Learning (FSCIL)çš„ç›®æ ‡æ˜¯æŒç»­å­¦ä¹ æ–°ç±»ï¼ŒåŒæ—¶ä¿ç•™å¯¹æ—§ç±»çš„çŸ¥è¯†ã€‚</li>
<li>ä¼ ç»ŸFSCILæ–¹æ³•ä¸»è¦å…³æ³¨åŸºç¡€è®­ç»ƒé˜¶æ®µï¼Œå¹¶åœ¨åç»­å¢é‡é˜¶æ®µå¾®è°ƒåˆ†ç±»å™¨ã€‚</li>
<li>å½“å‰ç­–ç•¥ä¸»è¦å…³æ³¨é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œå¿½è§†äº†æ¯ä¸ªç±»çš„ç‰¹å®šå†³ç­–ç©ºé—´ã€‚</li>
<li>æå‡ºçš„Adaptive Decision Boundary Strategy (ADBS)ç­–ç•¥ä¸å¤§å¤šæ•°FSCILæ–¹æ³•å…¼å®¹ï¼Œä¸ºæ¯ä¸ªç±»åˆ†é…ç‰¹å®šçš„å†³ç­–è¾¹ç•Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”è°ƒæ•´ã€‚</li>
<li>é‡‡ç”¨æ–°å‹ç±»é—´çº¦æŸæŸå¤±æ¥ä¼˜åŒ–å†³ç­–è¾¹ç•Œå’ŒåŸå‹ï¼Œæé«˜ç±»ä¹‹é—´çš„åŒºåˆ†åº¦ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç»“åˆADBSä¸ç°æœ‰FSCILæŠ€æœ¯å¯æ˜¾è‘—æé«˜æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b1a42c3d9fe1b779a1ec4d5aad82387b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-31ea2229f48d443464a3c69e8764baf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd38f190db35eac8afab0dc6ac8be6f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86068c9a39d4bb320337e2985d14de2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7886339b3032dc74057e2df9865880d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-641b12cd60d19891e58f1df6ad29a79c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Rethinking-Few-Shot-Image-Fusion-Granular-Ball-Priors-Enable-General-Purpose-Deep-Fusion"><a href="#Rethinking-Few-Shot-Image-Fusion-Granular-Ball-Priors-Enable-General-Purpose-Deep-Fusion" class="headerlink" title="Rethinking Few-Shot Image Fusion: Granular Ball Priors Enable   General-Purpose Deep Fusion"></a>Rethinking Few-Shot Image Fusion: Granular Ball Priors Enable   General-Purpose Deep Fusion</h2><p><strong>Authors:Minjie Deng, Yan Wei, Hao Zhai, An Wu, Yuncan Ouyang, Qianyao Peng</strong></p>
<p>In image fusion tasks, the absence of real fused images as priors presents a fundamental challenge. Most deep learning-based fusion methods rely on large-scale paired datasets to extract global weighting features from raw images, thereby generating fused outputs that approximate real fused images. In contrast to previous studies, this paper explores few-shot training of neural networks under the condition of having prior knowledge. We propose a novel fusion framework named GBFF, and a Granular Ball Significant Extraction algorithm specifically designed for the few-shot prior setting. All pixel pairs involved in the fusion process are initially modeled as a Coarse-Grained Granular Ball. At the local level, Fine-Grained Granular Balls are used to slide through the brightness space to extract Non-Salient Pixel Pairs, and perform splitting operations to obtain Salient Pixel Pairs. Pixel-wise weights are then computed to generate a pseudo-supervised image. At the global level, pixel pairs with significant contributions to the fusion process are categorized into the Positive Region, while those whose contributions cannot be accurately determined are assigned to the Boundary Region. The Granular Ball performs modality-aware adaptation based on the proportion of the positive region, thereby adjusting the neural networkâ€™s loss function and enabling it to complement the information of the boundary region. Extensive experiments demonstrate the effectiveness of both the proposed algorithm and the underlying theory. Compared with state-of-the-art (SOTA) methods, our approach shows strong competitiveness in terms of both fusion time and image expressiveness. Our code is publicly available at: </p>
<blockquote>
<p>åœ¨å›¾åƒèåˆä»»åŠ¡ä¸­ï¼Œç¼ºä¹çœŸå®èåˆå›¾åƒä½œä¸ºå…ˆéªŒä¿¡æ¯æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚å¤§å¤šæ•°åŸºäºæ·±åº¦å­¦ä¹ çš„èåˆæ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡é…å¯¹æ•°æ®é›†ï¼Œä»åŸå§‹å›¾åƒä¸­æå–å…¨å±€åŠ æƒç‰¹å¾ï¼Œä»è€Œç”Ÿæˆè¿‘ä¼¼çœŸå®èåˆå›¾åƒçš„èåˆè¾“å‡ºã€‚ä¸ä»¥å‰çš„ç ”ç©¶ç›¸æ¯”ï¼Œæœ¬æ–‡æ¢ç´¢äº†åœ¨å…·å¤‡å…ˆéªŒçŸ¥è¯†çš„æ¡ä»¶ä¸‹ç¥ç»ç½‘ç»œçš„å°‘æ ·æœ¬è®­ç»ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„èåˆæ¡†æ¶GBFFï¼ˆæ ¼å…°ç‰¹çƒæ³•ï¼‰ï¼Œä»¥åŠä¸€ç§é’ˆå¯¹å°‘æ ·æœ¬å…ˆéªŒç¯å¢ƒçš„ç²’çŠ¶çƒé‡è¦æ€§æå–ç®—æ³•ã€‚å‚ä¸èåˆè¿‡ç¨‹çš„åƒç´ å¯¹æœ€åˆè¢«å»ºæ¨¡ä¸ºç²—ç²’åº¦çš„ç²’çŠ¶çƒã€‚åœ¨å±€éƒ¨å±‚é¢ä¸Šï¼Œä½¿ç”¨ç²¾ç»†ç²’åº¦çš„ç²’çŠ¶çƒéå†äº®åº¦ç©ºé—´ä»¥æå–éæ˜¾è‘—æ€§åƒç´ å¯¹ï¼Œå¹¶è¿›è¡Œåˆ†è£‚æ“ä½œä»¥è·å¾—æ˜¾è‘—æ€§åƒç´ å¯¹ã€‚ç„¶åè®¡ç®—åƒç´ çº§çš„æƒé‡ä»¥ç”Ÿæˆä¼ªç›‘ç£å›¾åƒã€‚åœ¨å…¨å±€å±‚é¢ä¸Šï¼Œå°†å¯¹äºèåˆè¿‡ç¨‹æœ‰æ˜¾è‘—è´¡çŒ®çš„åƒç´ å¯¹åˆ†ç±»ä¸ºæ­£åŒºåŸŸï¼Œè€Œé‚£äº›è´¡çŒ®æ— æ³•å‡†ç¡®ç¡®å®šçš„åƒç´ å¯¹è¢«åˆ†é…ç»™è¾¹ç•ŒåŒºåŸŸã€‚ç²’çŠ¶çƒæ ¹æ®æ­£åŒºåŸŸçš„æ¯”ä¾‹è¿›è¡Œæ¨¡æ€æ„ŸçŸ¥é€‚åº”ï¼Œä»è€Œè°ƒæ•´ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿè¡¥å……è¾¹ç•ŒåŒºåŸŸçš„ä¿¡æ¯ã€‚å¤§é‡å®éªŒè¯æ˜äº†æ‰€æå‡ºç®—æ³•å’Œåº•å±‚ç†è®ºçš„æœ‰æ•ˆæ€§ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨èåˆæ—¶é—´å’Œå›¾åƒè¡¨ç°åŠ›æ–¹é¢éƒ½è¡¨ç°å‡ºå¼ºå¤§çš„ç«äº‰åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨å…¬å¼€æ¸ é“è·å–ï¼š</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08937v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šè¯¥è®ºæ–‡è§£å†³äº†å›¾åƒèåˆä»»åŠ¡ä¸­ç¼ºä¹çœŸå®èåˆå›¾åƒä½œä¸ºå…ˆéªŒçš„é—®é¢˜ã€‚æå‡ºäº†ä¸€ç§åä¸ºGBFFçš„æ–°å‹èåˆæ¡†æ¶ï¼Œä»¥åŠä¸“é—¨é’ˆå¯¹å°æ ·æœ¬å…ˆéªŒç¯å¢ƒçš„Granular Ball Significant Extractionç®—æ³•ã€‚ç®—æ³•é€šè¿‡åˆ›å»ºç²—ç²’åº¦å’Œç»†ç²’åº¦ç²’çƒæ¥å¤„ç†å’Œæå–å›¾åƒä¸­çš„éæ˜¾è‘—åƒç´ å¯¹å’Œæ˜¾è‘—åƒç´ å¯¹ï¼Œå¹¶è®¡ç®—åƒç´ çº§æƒé‡ç”Ÿæˆä¼ªç›‘ç£å›¾åƒã€‚åŒæ—¶ï¼Œç²’çƒè¿˜è¿›è¡Œæ¨¡æ€æ„ŸçŸ¥é€‚åº”ï¼Œè°ƒæ•´ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ä»¥è¡¥å……è¾¹ç•ŒåŒºåŸŸçš„ä¿¡æ¯ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•å’Œç†è®ºçš„æœ‰æ•ˆæ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨èåˆæ—¶é—´å’Œå›¾åƒè¡¨ç°åŠ›æ–¹é¢è¡¨ç°å‡ºå¼ºç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è®ºæ–‡è§£å†³äº†åœ¨å›¾åƒèåˆä»»åŠ¡ä¸­ç¼ºä¹çœŸå®èåˆå›¾åƒå…ˆéªŒçš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„èåˆæ¡†æ¶GBFFã€‚</li>
<li>å¼•å…¥äº†Granular Ball Significant Extractionç®—æ³•ï¼Œè¯¥ç®—æ³•ä¸“ä¸ºå°æ ·æœ¬å…ˆéªŒç¯å¢ƒè®¾è®¡ã€‚</li>
<li>ç®—æ³•é€šè¿‡åˆ›å»ºç²—ç²’åº¦å’Œç»†ç²’åº¦ç²’çƒæ¥å¤„ç†åƒç´ å¯¹ï¼Œå¹¶è®¡ç®—åƒç´ çº§æƒé‡ç”Ÿæˆä¼ªç›‘ç£å›¾åƒã€‚</li>
<li>ç²’çƒè¿›è¡Œæ¨¡æ€æ„ŸçŸ¥é€‚åº”ï¼Œæ ¹æ®æ­£åŒºåŸŸçš„å æ¯”è°ƒæ•´ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•å’Œç†è®ºçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08937">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0c532948e4d681e9a4c8988c25332579.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56b59ddc8423b000de64207f38b799a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-283928e9489f2d5da3549aef93d34139.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d611a0044f0059d8f8b154677112593d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f22368382d44ac5ddda5e49e8b4d95ad.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MalMixer-Few-Shot-Malware-Classification-with-Retrieval-Augmented-Semi-Supervised-Learning"><a href="#MalMixer-Few-Shot-Malware-Classification-with-Retrieval-Augmented-Semi-Supervised-Learning" class="headerlink" title="MalMixer: Few-Shot Malware Classification with Retrieval-Augmented   Semi-Supervised Learning"></a>MalMixer: Few-Shot Malware Classification with Retrieval-Augmented   Semi-Supervised Learning</h2><p><strong>Authors:Jiliang Li, Yifan Zhang, Yu Huang, Kevin Leach</strong></p>
<p>Recent growth and proliferation of malware have tested practitioners ability to promptly classify new samples according to malware families. In contrast to labor-intensive reverse engineering efforts, machine learning approaches have demonstrated increased speed and accuracy. However, most existing deep-learning malware family classifiers must be calibrated using a large number of samples that are painstakingly manually analyzed before training. Furthermore, as novel malware samples arise that are beyond the scope of the training set, additional reverse engineering effort must be employed to update the training set. The sheer volume of new samples found in the wild creates substantial pressure on practitioners ability to reverse engineer enough malware to adequately train modern classifiers. In this paper, we present MalMixer, a malware family classifier using semi-supervised learning that achieves high accuracy with sparse training data. We present a domain-knowledge-aware data augmentation technique for malware feature representations, enhancing few-shot performance of semi-supervised malware family classification. We show that MalMixer achieves state-of-the-art performance in few-shot malware family classification settings. Our research confirms the feasibility and effectiveness of lightweight, domain-knowledge-aware data augmentation methods for malware features and shows the capabilities of similar semi-supervised classifiers in addressing malware classification issues. </p>
<blockquote>
<p>è¿‘æœŸæ¶æ„è½¯ä»¶çš„è¿…é€Ÿå¢é•¿å’Œæ‰©æ•£è€ƒéªŒäº†ä»ä¸šè€…æ ¹æ®æ¶æ„è½¯ä»¶å®¶æ—å¯¹æ–°æ ·æœ¬è¿›è¡ŒåŠæ—¶åˆ†ç±»çš„èƒ½åŠ›ã€‚ä¸åŠ³åŠ¨å¯†é›†å‹çš„é€†å‘å·¥ç¨‹åŠªåŠ›ç›¸æ¯”ï¼Œæœºå™¨å­¦ä¹ çš„æ–¹æ³•å·²ç»æ˜¾ç¤ºå‡ºæ›´é«˜çš„é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„æ·±åº¦å­¦ä¹ çš„æ¶æ„è½¯ä»¶å®¶æ—åˆ†ç±»å™¨éœ€è¦ä½¿ç”¨å¤§é‡çš„æ ·æœ¬è¿›è¡Œæ ¡å‡†ï¼Œè¿™äº›æ ·æœ¬åœ¨è®­ç»ƒä¹‹å‰éœ€è¦è¿›è¡Œç¹ççš„æ‰‹åŠ¨åˆ†æã€‚æ­¤å¤–ï¼Œéšç€è¶…å‡ºè®­ç»ƒé›†èŒƒå›´çš„æ–°çš„æ¶æ„è½¯ä»¶æ ·æœ¬çš„å‡ºç°ï¼Œå¿…é¡»ä½¿ç”¨æ›´å¤šçš„é€†å‘å·¥ç¨‹å·¥ä½œæ¥æ›´æ–°è®­ç»ƒé›†ã€‚åœ¨å®é™…ç¯å¢ƒä¸­å‘ç°çš„å¤§é‡æ–°æ ·æœ¬ç»™ä»ä¸šè€…å¸¦æ¥äº†å·¨å¤§çš„å‹åŠ›ï¼Œä»–ä»¬éœ€è¦é‡æ–°è®¾è®¡è¶³å¤Ÿçš„æ¶æ„è½¯ä»¶æ¥å……åˆ†è®­ç»ƒç°ä»£åˆ†ç±»å™¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†MalMixerï¼Œä¸€ç§ä½¿ç”¨åŠç›‘ç£å­¦ä¹ çš„æ¶æ„è½¯ä»¶å®¶æ—åˆ†ç±»å™¨ï¼Œå®ƒå¯ä»¥åœ¨ç¨€ç–çš„è®­ç»ƒæ•°æ®ä¸Šå®ç°è¾ƒé«˜çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé¢†åŸŸçŸ¥è¯†çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œç”¨äºè¡¨ç¤ºæ¶æ„è½¯ä»¶çš„ç‰¹å¾ï¼Œä»¥æé«˜åŠç›‘ç£æ¶æ„è½¯ä»¶å®¶æ—åˆ†ç±»çš„å°‘æ•°æ ·æœ¬æ€§èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†MalMixeråœ¨å°‘æ•°æ ·æœ¬çš„æ¶æ„è½¯ä»¶å®¶æ—åˆ†ç±»è®¾ç½®ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¯å®äº†é¢†åŸŸçŸ¥è¯†è½»é‡çº§çš„æ•°æ®å¢å¼ºæ–¹æ³•åœ¨æ¶æ„è½¯ä»¶ç‰¹å¾ä¸­çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†ç±»ä¼¼çš„åŠç›‘ç£åˆ†ç±»å™¨åœ¨å¤„ç†æ¶æ„è½¯ä»¶åˆ†ç±»é—®é¢˜æ—¶çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13213v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå½“å‰ç—…æ¯’æ ·æœ¬çš„ä¸æ–­å¢é•¿å’Œå¤šæ ·åŒ–ï¼Œæœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨ç—…æ¯’å®¶æ—åˆ†ç±»ä¸­çš„åº”ç”¨æ—¥ç›Šå‡¸æ˜¾å…¶é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ·±åº¦å­¦ä¹ ç—…æ¯’å®¶æ—åˆ†ç±»å™¨éœ€è¦å¤§é‡æ ·æœ¬è¿›è¡Œæ ¡å‡†ï¼Œä¸”åœ¨é¢å¯¹æ–°å‹ç—…æ¯’æ ·æœ¬æ—¶ä»éœ€äººå·¥è¿›è¡Œé€†å‘å·¥ç¨‹åˆ†ææ›´æ–°è®­ç»ƒé›†ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºåŠç›‘ç£å­¦ä¹ çš„ç—…æ¯’å®¶æ—åˆ†ç±»å™¨MalMixerï¼Œå®ƒå¯ä»¥åœ¨ç¨€ç–è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°è¾ƒé«˜çš„å‡†ç¡®åº¦ã€‚æœ¬ç ”ç©¶è®¾è®¡äº†ä¸€ç§é¢†åŸŸçŸ¥è¯†å¢å¼ºçš„æ•°æ®æ‰©å……æŠ€æœ¯æ¥ä¼˜åŒ–ç—…æ¯’ç‰¹å¾è¡¨ç¤ºï¼Œæé«˜åŠç›‘ç£å‹ç—…æ¯’å®¶æ—åœ¨å°‘æ•°æƒ…å†µä¸‹çš„åˆ†ç±»æ€§èƒ½ã€‚å®éªŒç»“æœè¯å®MalMixeråœ¨å°‘é‡ç—…æ¯’æ ·æœ¬çš„åˆ†ç±»åœºæ™¯ä¸‹å…·æœ‰çªç ´æ€§è¡¨ç°ã€‚æœ¬æ–‡éªŒè¯äº†é¢†åŸŸçŸ¥è¯†å¢å¼ºçš„æ•°æ®æ‰©å……æ–¹æ³•å¯¹äºç—…æ¯’ç‰¹å¾çš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠç±»ä¼¼åŠç›‘ç£åˆ†ç±»å™¨åœ¨è§£å†³ç—…æ¯’åˆ†ç±»é—®é¢˜ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰ç—…æ¯’æ ·æœ¬å¢é•¿è¿…é€Ÿï¼Œæœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨ç—…æ¯’å®¶æ—åˆ†ç±»ä¸­çš„åº”ç”¨æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚</li>
<li>è™½ç„¶ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹è¡¨ç°å‡ºè¾ƒé«˜å‡†ç¡®æ€§ï¼Œä½†ä»é¢ä¸´éœ€è¦å¤§é‡è®­ç»ƒæ ·æœ¬çš„æŒ‘æˆ˜ã€‚æ–°ç—…æ¯’æ ·æœ¬çš„å¿«é€Ÿæ¶Œç°å¯¼è‡´éš¾ä»¥å¯¹æ¨¡å‹è¿›è¡ŒæŒç»­è®­ç»ƒã€‚</li>
<li>MalMixeråŸºäºåŠç›‘ç£å­¦ä¹ æŠ€æœ¯çš„æå‡ºä¸ºè§£å†³è¯¥é—®é¢˜æä¾›äº†æ–°çš„é€”å¾„ï¼Œå¯ä»¥åœ¨æ ·æœ¬ç¨€ç–çš„æƒ…å†µä¸‹å®ç°è¾ƒé«˜çš„åˆ†ç±»å‡†ç¡®åº¦ã€‚</li>
<li>å¼•å…¥äº†é¢†åŸŸçŸ¥è¯†å¢å¼ºçš„æ•°æ®æ‰©å……æŠ€æœ¯æ¥ä¼˜åŒ–ç—…æ¯’ç‰¹å¾è¡¨ç¤ºï¼Œæå‡æ¨¡å‹çš„åˆ†ç±»æ€§èƒ½ã€‚å°¤å…¶æ˜¯é¢å¯¹å°‘é‡æ ·æœ¬æ—¶çš„åˆ†ç±»æ•ˆæœæ›´ä¸ºæ˜¾è‘—ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºMalMixeråœ¨å°‘æ•°ç—…æ¯’æ ·æœ¬åˆ†ç±»åœºæ™¯ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚è¿™ä¸ºåŒç±»æŠ€æœ¯æä¾›äº†ä¸€ç§å¯å‚è€ƒçš„æˆåŠŸæ¡ˆä¾‹å’Œè¿›æ­¥ç©ºé—´ã€‚é€šè¿‡å®ç°æ•°æ®çš„è‡ªä¸»å­¦ä¹ å’Œåˆ©ç”¨å¢å¼ºäº†å…¶åº”ç”¨å¹¿æ³›æ€§å¹¶å‡å°‘äº†äººå·¥æˆæœ¬æŠ•å…¥ï¼Œå‡è½»äº†è´Ÿæ‹…ä¸é™åˆ¶å› ç´ æå‡äº†æ•ˆæœä¸ä»·å€¼è¡¨ç°æ•ˆæœä¸åº”ç”¨æ½œåŠ›å¾—åˆ°è¿›ä¸€æ­¥æå‡è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸‹çš„å¯è¡Œæ€§å’Œå¯é æ€§ ã€‚æ­¤åˆ›æ–°ç ”ç©¶å…‹æœäº†ä»¥å¾€å­˜åœ¨çš„æŒ‘æˆ˜ä¸å±€é™æ€§ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ›´å¤šå¯èƒ½æ€§ä¸æ€è·¯ ã€‚ </li>
<li>ç ”ç©¶éªŒè¯äº†é¢†åŸŸçŸ¥è¯†å¢å¼ºçš„æ•°æ®æ‰©å……æ–¹æ³•å¯¹äºç—…æ¯’ç‰¹å¾çš„æœ‰æ•ˆæ€§ä»¥åŠè¯¥æŠ€æœ¯åœ¨å¤„ç†æ­¤ç±»é—®é¢˜æ—¶çš„é«˜æ•ˆèƒ½æ€§å’Œä¾¿æ·æ€§å¾—åˆ°äº†ä¸šç•Œå¹¿æ³›è®¤å¯å’Œå‘å±•å‰æ™¯ ã€‚è¿™å¯¹äºè®¡ç®—æœºå®‰å…¨é¢†åŸŸçš„å‘å±•å…·æœ‰é‡å¤§æ„ä¹‰ ã€‚åŒæ—¶ç ”ç©¶è¿‡ç¨‹ä¸­æ‰€é‡‡ç”¨çš„æ–¹æ³•å’Œæ€è·¯ä¹Ÿå…·æœ‰ä¸€å®šçš„é€šç”¨æ€§å¯ä»¥åº”ç”¨äºå…¶ä»–ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸­ ã€‚ é€šè¿‡å¯¹æ–°å‹æŠ€æœ¯åº”ç”¨çš„ä¸æ–­æŒ–æ˜å’Œåˆ›æ–°æ¨åŠ¨äº†è®¡ç®—æœºå®‰å…¨é¢†åŸŸçš„ä¸æ–­è¿›æ­¥ä¸å‘å±• ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13213">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7251d8dab1098b2246813f38a1448730.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32bb27d88ec1de00ca71c257db318708.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-910bf5ea638196af9cb760921eea872a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85e209844c377defc431f96d9a81487f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-682db554604070c09fa35e0e49152148.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="ExploRLLM-Guiding-Exploration-in-Reinforcement-Learning-with-Large-Language-Models"><a href="#ExploRLLM-Guiding-Exploration-in-Reinforcement-Learning-with-Large-Language-Models" class="headerlink" title="ExploRLLM: Guiding Exploration in Reinforcement Learning with Large   Language Models"></a>ExploRLLM: Guiding Exploration in Reinforcement Learning with Large   Language Models</h2><p><strong>Authors:Runyu Ma, Jelle Luijkx, Zlatan Ajanovic, Jens Kober</strong></p>
<p>In robot manipulation, Reinforcement Learning (RL) often suffers from low sample efficiency and uncertain convergence, especially in large observation and action spaces. Foundation Models (FMs) offer an alternative, demonstrating promise in zero-shot and few-shot settings. However, they can be unreliable due to limited physical and spatial understanding. We introduce ExploRLLM, a method that combines the strengths of both paradigms. In our approach, FMs improve RL convergence by generating policy code and efficient representations, while a residual RL agent compensates for the FMsâ€™ limited physical understanding. We show that ExploRLLM outperforms both policies derived from FMs and RL baselines in table-top manipulation tasks. Additionally, real-world experiments show that the policies exhibit promising zero-shot sim-to-real transfer. Supplementary material is available at <a target="_blank" rel="noopener" href="https://explorllm.github.io/">https://explorllm.github.io</a>. </p>
<blockquote>
<p>åœ¨æœºå™¨äººæ“ä½œé¢†åŸŸï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¸¸å¸¸é¢ä¸´æ ·æœ¬æ•ˆç‡ä½å’Œæ”¶æ•›ä¸ç¡®å®šçš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§å‹è§‚å¯Ÿå’Œè¡ŒåŠ¨ç©ºé—´ä¸­ã€‚åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰æä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åœºæ™¯ä¸­å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç”±äºæœ‰é™çš„ç‰©ç†å’Œç©ºé—´ç†è§£è€Œå¯èƒ½ä¸å¯é ã€‚æˆ‘ä»¬å¼•å…¥äº†ExploRLLMæ–¹æ³•ï¼Œå®ƒç»“åˆäº†ä¸¤ç§æ¨¡å¼çš„é•¿å¤„ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼ŒåŸºç¡€æ¨¡å‹é€šè¿‡ç”Ÿæˆç­–ç•¥ä»£ç å’Œæœ‰æ•ˆè¡¨ç¤ºå½¢å¼æ¥æé«˜RLçš„æ”¶æ•›æ€§ï¼Œè€Œæ®‹ä½™çš„RLä»£ç†åˆ™å¼¥è¡¥äº†åŸºç¡€æ¨¡å‹çš„æœ‰é™ç‰©ç†ç†è§£ã€‚æˆ‘ä»¬è¯æ˜ExploRLLMåœ¨æ¡Œé¢æ“ä½œä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºæ¥è‡ªåŸºç¡€æ¨¡å‹çš„ç­–ç•¥å’ŒRLåŸºå‡†çº¿ã€‚æ­¤å¤–ï¼ŒçœŸå®ä¸–ç•Œçš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›ç­–ç•¥è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„ä»æ¨¡æ‹Ÿåˆ°çœŸå®çš„é›¶æ ·æœ¬è¿ç§»ã€‚æ›´å¤šææ–™è¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://explorllm.github.io./">https://explorllm.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.09583v4">PDF</a> 6 pages, 6 figures, IEEE International Conference on Robotics and   Automation (ICRA) 2025</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ“ä½œä¸­å­˜åœ¨æ ·æœ¬æ•ˆç‡ä½å’Œæ”¶æ•›ä¸ç¡®å®šçš„é—®é¢˜ï¼Œå°¤å…¶åœ¨å¤§å‹è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ä¸­å°¤ä¸ºæ˜æ˜¾ã€‚è€ŒåŸºç¡€æ¨¡å‹åœ¨å¤§è§„æ¨¡è§‚æµ‹ç©ºé—´ä¸­çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å—é™äºç‰©ç†å’Œç©ºé—´ç†è§£ã€‚æœ¬ç ”ç©¶ç»“åˆäº†å¼ºåŒ–å­¦ä¹ å’ŒåŸºç¡€æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæå‡ºäº†ExploRLLMæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆç­–ç•¥ä»£ç å’Œé«˜æ•ˆè¡¨ç¤ºï¼ŒåŒæ—¶ä½¿ç”¨æ®‹ä½™å¼ºåŒ–å­¦ä¹ ä»£ç†äººæ¥è¡¥å¿åŸºç¡€æ¨¡å‹çš„ç‰©ç†ç†è§£å±€é™æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒExploRLLMåœ¨æ¡Œé¢æ“ä½œä»»åŠ¡ä¸­ä¼˜äºä»…ä½¿ç”¨åŸºç¡€æ¨¡å‹çš„ç­–ç•¥å’Œå¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œå¹¶ä¸”åœ¨å®é™…ç¯å¢ƒä¸­çš„å®éªŒå±•ç¤ºäº†ç­–ç•¥ä»æ¨¡æ‹Ÿåˆ°ç°å®çš„é›¶æ ·æœ¬è½¬ç§»æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ“ä½œä¸­å­˜åœ¨æ ·æœ¬æ•ˆç‡å’Œæ”¶æ•›é—®é¢˜ã€‚</li>
<li>åŸºç¡€æ¨¡å‹åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸­æœ‰æ½œåŠ›ï¼Œä½†å—é™äºç‰©ç†å’Œç©ºé—´ç†è§£ã€‚</li>
<li>ExploRLLMç»“åˆäº†å¼ºåŒ–å­¦ä¹ å’ŒåŸºç¡€æ¨¡å‹çš„ä¼˜åŠ¿ã€‚</li>
<li>ExploRLLMåˆ©ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆç­–ç•¥ä»£ç å’Œé«˜æ•ˆè¡¨ç¤ºã€‚</li>
<li>æ®‹ä½™å¼ºåŒ–å­¦ä¹ ä»£ç†äººè¡¥å¿äº†åŸºç¡€æ¨¡å‹çš„ç‰©ç†ç†è§£å±€é™æ€§ã€‚</li>
<li>ExploRLLMåœ¨æ¡Œé¢æ“ä½œä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.09583">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-48eecde669a3fe9fd064bbc61d630978.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe9297128a5fa28e8a27d5ef3f805459.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e9feb18dda2e9da0372a0a5bf7c44c00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e1d2a67149b3e12796c69c72ab05d6e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-43e64679669f89575c9a0fbc6a3ffa71.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fd10579fd880e5a359598ff16bd9daf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e80729c5fbc7ce8e255b70cbd57f29a8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0f632dc422e20ea6b7fceb16a7b0e4e4.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-19  Multi-Parameter Molecular MRI Quantification using Physics-Informed   Self-Supervised Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-910ee8930f9a3f2d540062a4db969108.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-19  Exploring Expert Failures Improves LLM Agent Tuning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27083.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
