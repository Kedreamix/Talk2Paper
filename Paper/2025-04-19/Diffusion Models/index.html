<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-19  UniEdit-Flow Unleashing Inversion and Editing in the Era of Flow Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-e0b9274db2cf995d7fd150e6bd62f40c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-19-更新"><a href="#2025-04-19-更新" class="headerlink" title="2025-04-19 更新"></a>2025-04-19 更新</h1><h2 id="UniEdit-Flow-Unleashing-Inversion-and-Editing-in-the-Era-of-Flow-Models"><a href="#UniEdit-Flow-Unleashing-Inversion-and-Editing-in-the-Era-of-Flow-Models" class="headerlink" title="UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models"></a>UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models</h2><p><strong>Authors:Guanlong Jiao, Biqing Huang, Kuan-Chieh Wang, Renjie Liao</strong></p>
<p>Flow matching models have emerged as a strong alternative to diffusion models, but existing inversion and editing methods designed for diffusion are often ineffective or inapplicable to them. The straight-line, non-crossing trajectories of flow models pose challenges for diffusion-based approaches but also open avenues for novel solutions. In this paper, we introduce a predictor-corrector-based framework for inversion and editing in flow models. First, we propose Uni-Inv, an effective inversion method designed for accurate reconstruction. Building on this, we extend the concept of delayed injection to flow models and introduce Uni-Edit, a region-aware, robust image editing approach. Our methodology is tuning-free, model-agnostic, efficient, and effective, enabling diverse edits while ensuring strong preservation of edit-irrelevant regions. Extensive experiments across various generative models demonstrate the superiority and generalizability of Uni-Inv and Uni-Edit, even under low-cost settings. Project page: <a target="_blank" rel="noopener" href="https://uniedit-flow.github.io/">https://uniedit-flow.github.io/</a> </p>
<blockquote>
<p>流匹配模型作为扩散模型的强大替代品已经崭露头角，但是为扩散模型设计的现有反转和编辑方法往往对其无效或不可应用。流模型的直线、非交叉轨迹为基于扩散的方法带来了挑战，但也为新颖解决方案打开了通道。在本文中，我们介绍了基于预测校正器框架的流模型反转和编辑方法。首先，我们提出Uni-Inv，一种针对准确重建的有效反转方法。在此基础上，我们将延迟注入的概念扩展到流模型，并引入Uni-Edit，一种区域感知、稳健的图像编辑方法。我们的方法是免调试的、模型无关的、高效的、有效的，能够在确保编辑无关区域得到强烈保留的同时，实现多样化的编辑。在各种生成模型上的广泛实验证明了Uni-Inv和Uni-Edit的优越性和通用性，即使在低成本设置下也是如此。项目页面：<a target="_blank" rel="noopener" href="https://uniedit-flow.github.io/">https://uniedit-flow.github.io/</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13109v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://uniedit-flow.github.io/">https://uniedit-flow.github.io/</a></p>
<p><strong>Summary</strong><br>文本介绍了一种针对流匹配模型的预测校正框架，用于进行反演和编辑操作。提出了Uni-Inv反演方法和Uni-Edit图像编辑方法，具有准确性、区域感知性、鲁棒性等特点，无需调整参数，适用于多种生成模型，并在实验上证明了其优越性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>流匹配模型作为扩散模型的替代方案，对现有扩散模型的反演和编辑方法提出了挑战。</li>
<li>流匹配模型的直线、非交叉轨迹特性对现有扩散模型的方法构成挑战，但也为新的解决方案提供了机会。</li>
<li>引入了一种基于预测校正框架的方法，用于流匹配模型中的反演和编辑操作。</li>
<li>提出了Uni-Inv反演方法，旨在实现准确的重建。</li>
<li>扩展了延迟注入的概念，并引入了Uni-Edit图像编辑方法，具有区域感知性和鲁棒性。</li>
<li>该方法无需调整参数，适用于多种生成模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13109">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ade49c0ac4eacc592f774e14fa75cd16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29de09c107ca87e188128b8774dafe80.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-511b0a1779d05808bc7790dcb6bcbd8d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-33f0e698eebf6d919d46cfb7d0737156.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4bd3f2c00d8fc64ab1dfb20cfebd9a2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3394de6e102800acd889fcb18cd48c7d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="TTRD3-Texture-Transfer-Residual-Denoising-Dual-Diffusion-Model-for-Remote-Sensing-Image-Super-Resolution"><a href="#TTRD3-Texture-Transfer-Residual-Denoising-Dual-Diffusion-Model-for-Remote-Sensing-Image-Super-Resolution" class="headerlink" title="TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for   Remote Sensing Image Super-Resolution"></a>TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for   Remote Sensing Image Super-Resolution</h2><p><strong>Authors:Yide Liu, Haijiang Sun, Xiaowen Zhang, Qiaoyuan Liu, Zhouchang Chen, Chongzhuo Xiao</strong></p>
<p>Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution (HR) remote sensing images from low-resolution inputs to support fine-grained ground object interpretation. Existing methods face three key challenges: (1) Difficulty in extracting multi-scale features from spatially heterogeneous RS scenes, (2) Limited prior information causing semantic inconsistency in reconstructions, and (3) Trade-off imbalance between geometric accuracy and visual quality. To address these issues, we propose the Texture Transfer Residual Denoising Dual Diffusion Model (TTRD3) with three innovations: First, a Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous convolutional kernels for multi-scale feature extraction. Second, a Sparse Texture Transfer Guidance (STTG) module that transfers HR texture priors from reference images of similar scenes. Third, a Residual Denoising Dual Diffusion Model (RDDM) framework combining residual diffusion for deterministic reconstruction and noise diffusion for diverse generation. Experiments on multi-source RS datasets demonstrate TTRD3’s superiority over state-of-the-art methods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared to best-performing baselines. Code&#x2F;model: <a target="_blank" rel="noopener" href="https://github.com/LED-666/TTRD3">https://github.com/LED-666/TTRD3</a>. </p>
<blockquote>
<p>遥感图像超分辨率（RSISR）技术从低分辨率的输入中重建高分辨率（HR）的遥感图像，以支持精细地面对象的解读。现有方法面临三个主要挑战：（1）从空间异质的遥感场景中提取多尺度特征的困难；（2）有限的先验信息导致重建中的语义不一致；（3）几何精度与视觉质量之间的权衡失衡。为了解决这些问题，我们提出了具有三项创新的纹理转移残差去噪双重扩散模型（TTRD3）：首先，采用并行异构卷积核的多尺度特征聚合块（MFAB），用于多尺度特征提取。其次，提出了稀疏纹理转移指导（STTG）模块，该模块从类似场景的参考图像中转移高分辨率纹理先验。第三，结合残差扩散进行确定性重建和噪声扩散进行多样化生成的残差去噪双重扩散模型（RDDM）框架。在多源遥感数据集上的实验表明，TTRD3优于最新方法，与最佳基线相比，实现了1.43%的LPIPS改进和3.67%的FID提升。代码&#x2F;模型：<a target="_blank" rel="noopener" href="https://github.com/LED-666/TTRD3%E3%80%82">https://github.com/LED-666/TTRD3。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13026v1">PDF</a> </p>
<p><strong>Summary</strong><br>远程遥感图像超分辨率重建技术旨在从低分辨率图像重建出高分辨率图像，以支持精细地面目标解读。针对现有方法面临的多尺度特征提取难、语义不一致和几何精度与视觉质量平衡难题，提出纹理传输残差去噪双重扩散模型（TTRD3）。该模型包括多尺度特征聚合块、稀疏纹理传输引导模块和残差去噪双重扩散框架。实验表明，TTRD3在多源遥感数据集上优于现有方法，实现了性能的提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>遥感图像超分辨率重建（RSISR）旨在从低分辨率图像重建高分辨率图像，以促进精细地面目标解读。</li>
<li>现有方法面临三大挑战：多尺度特征提取难、语义不一致以及几何精度与视觉质量的平衡问题。</li>
<li>TTRD3模型通过多尺度特征聚合块提取多尺度特征，采用稀疏纹理传输引导模块转移高分辨率纹理先验信息。</li>
<li>TTRD3模型结合残差扩散进行确定性重建和噪声扩散进行多样生成的RDDM框架。</li>
<li>实验证明，TTRD3在多源遥感数据集上的性能优于现有方法，实现了LPIPS改进1.43%，FID提升3.67%。</li>
<li>TTRD3模型的代码和模型已公开，可访问<a target="_blank" rel="noopener" href="https://github.com/LED-666/TTRD3%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/LED-666/TTRD3获取。</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13026">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3cbc0ef550dd46b13427e3b0f074f027.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d9cead099ef72ab61cfe88da1465e44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4cfbf70b47f49e8d6f652c1ac36a8d50.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce854eeffd339eda180ae4eb63b7c035.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="C2GM-Cascading-conditional-generative-cartography-framework-for-multi-scale-tile-map-generation-with-geographic-feature-constraints"><a href="#C2GM-Cascading-conditional-generative-cartography-framework-for-multi-scale-tile-map-generation-with-geographic-feature-constraints" class="headerlink" title="C2GM: Cascading conditional generative cartography framework for   multi-scale tile map generation with geographic feature constraints"></a>C2GM: Cascading conditional generative cartography framework for   multi-scale tile map generation with geographic feature constraints</h2><p><strong>Authors:Chenxing Sun, Yongyang Xu, Xuwei Xu, Xixi Fan, Jing Bai, Xiechun Lu, Zhanlong Chen</strong></p>
<p>Multi-scale maps are essential representations of surveying and cartographic results, serving as fundamental components of geographic services. Current image generation networks can quickly produce map tiles from remote-sensing images. However, generative models designed for natural images often focus on texture features, neglecting the unique characteristics of remote-sensing features and the scale attributes of tile maps. This limitation in generative models impairs the accurate representation of geographic information, and the quality of tile map generation still needs improvement. Diffusion models have demonstrated remarkable success in various image generation tasks, highlighting their potential to address this challenge. This paper presents C2GM, a novel framework for generating multi-scale tile maps through conditional guided diffusion and multi-scale cascade generation. Specifically, we implement a conditional feature fusion encoder to extract object priors from remote sensing images and cascade reference double branch input, ensuring an accurate representation of complex features. Low-level generated tiles act as constraints for high-level map generation, enhancing visual continuity. Moreover, we incorporate map scale modality information using CLIP to simulate the relationship between map scale and cartographic generalization in tile maps. Extensive experimental evaluations demonstrate that C2GM consistently achieves the state-of-the-art (SOTA) performance on all metrics, facilitating the rapid and effective generation of multi-scale large-format maps for emergency response and remote mapping applications. </p>
<blockquote>
<p>多尺度地图是测绘和地图制作结果的重要表现形式，也是地理服务的基本组成部分。当前的图像生成网络能够快速地从遥感图像中生成地图瓦片。然而，针对自然图像设计的生成模型通常更注重纹理特征，而忽略了遥感特征的独特性以及瓦地图的尺度属性。生成模型的这一局限性影响了地理信息的准确表示，瓦片地图生成的质量仍有待提高。扩散模型在各种图像生成任务中表现出了显著的成功，突显了其解决这一挑战的潜力。本文提出了一种新的生成多尺度瓦片地图的框架C2GM，该框架通过条件引导扩散和多尺度级联生成实现。具体来说，我们实现了条件特征融合编码器，从遥感图像中提取对象先验，并采用级联参考双分支输入，以确保复杂特征的准确表示。低级生成的瓦片作为高级地图生成的约束，增强了视觉连续性。此外，我们利用CLIP结合地图尺度模态信息，模拟瓦片地图中地图尺度和制图概括之间的关系。大量的实验评估表明，C2GM在所有指标上均达到最新技术水平，可实现快速有效地生成多尺度大幅面地图，用于应急响应和远程映射应用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04991v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>多尺度地图是测绘和地图成果的重要表现形式，也是地理服务的基本组成部分。当前图像生成网络能够从遥感图像快速生成地图瓦片，但为自然图像设计的生成模型往往关注纹理特征，忽略了遥感特征的独特性以及地图瓦片的尺度属性。这限制了生成模型对地理信息准确表达的能力，地图瓦片生成的质量仍有待提高。本文提出一种基于扩散模型的新型框架C2GM，通过条件引导扩散和多尺度级联生成技术生成多尺度地图瓦片。实验证明，C2GM在各项指标上均达到最佳效果，能够快速有效地用于生成多尺度大幅面地图，为应急响应和遥感应用提供支持。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多尺度地图在地理服务中起重要作用，用于表达测绘和地图成果。</li>
<li>当前图像生成网络能够从遥感图像生成地图瓦片，但存在对地理信息表达不准确的局限性。</li>
<li>生成模型在关注纹理特征的同时忽略了遥感特征的独特性和地图瓦片的尺度属性。</li>
<li>扩散模型在图像生成任务中表现出显著成功，具有解决此挑战的潜力。</li>
<li>C2GM框架通过条件引导扩散和多尺度级联生成技术解决多尺度地图瓦片生成问题。</li>
<li>C2GM使用条件特征融合编码器和级联参考双分支输入，确保复杂特征的准确表达。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04991">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b62d2a434ebaa1be2cc3b73c30456a1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1316560e6cc955db27bc4fac68c7f55.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Good-Seed-Makes-a-Good-Crop-Discovering-Secret-Seeds-in-Text-to-Image-Diffusion-Models"><a href="#Good-Seed-Makes-a-Good-Crop-Discovering-Secret-Seeds-in-Text-to-Image-Diffusion-Models" class="headerlink" title="Good Seed Makes a Good Crop: Discovering Secret Seeds in Text-to-Image   Diffusion Models"></a>Good Seed Makes a Good Crop: Discovering Secret Seeds in Text-to-Image   Diffusion Models</h2><p><strong>Authors:Katherine Xu, Lingzhi Zhang, Jianbo Shi</strong></p>
<p>Recent advances in text-to-image (T2I) diffusion models have facilitated creative and photorealistic image synthesis. By varying the random seeds, we can generate many images for a fixed text prompt. Technically, the seed controls the initial noise and, in multi-step diffusion inference, the noise used for reparameterization at intermediate timesteps in the reverse diffusion process. However, the specific impact of the random seed on the generated images remains relatively unexplored. In this work, we conduct a large-scale scientific study into the impact of random seeds during diffusion inference. Remarkably, we reveal that the best ‘golden’ seed achieved an impressive FID of 21.60, compared to the worst ‘inferior’ seed’s FID of 31.97. Additionally, a classifier can predict the seed number used to generate an image with over 99.9% accuracy in just a few epochs, establishing that seeds are highly distinguishable based on generated images. Encouraged by these findings, we examined the influence of seeds on interpretable visual dimensions. We find that certain seeds consistently produce grayscale images, prominent sky regions, or image borders. Seeds also affect image composition, including object location, size, and depth. Moreover, by leveraging these ‘golden’ seeds, we demonstrate improved image generation such as high-fidelity inference and diversified sampling. Our investigation extends to inpainting tasks, where we uncover some seeds that tend to insert unwanted text artifacts. Overall, our extensive analyses highlight the importance of selecting good seeds and offer practical utility for image generation. </p>
<blockquote>
<p>最近文本到图像（T2I）扩散模型的进展促进了创造性且逼真的图像合成。通过改变随机种子，我们可以为固定的文本提示生成许多图像。从技术上讲，种子控制初始噪声，并且在多步扩散推断中，用于反向扩散过程中中间时间点的重新参数化的噪声。然而，关于随机种子对生成图像的具体影响尚未得到充分探索。在这项工作中，我们对扩散推断过程中的随机种子影响进行了大规模的科学研究。值得注意的是，我们发现最佳“黄金”种子取得了令人印象深刻的FID（Frechet Inception Distance）得分21.60，而最差的“低级”种子的FID为31.97。此外，分类器能够以超过99.9%的准确率预测用于生成图像的种子编号，这表明基于生成的图像，种子之间具有高度可区分性。基于这些发现，我们考察了种子对可解释的视觉维度的影响。我们发现某些种子会始终产生灰度图像、突出的天空区域或图像边界。种子还会影响图像构图，包括物体位置、大小和深度。此外，通过利用这些“黄金”种子，我们展示了改进的图像生成，如高保真推断和多样化采样。我们的调查还扩展到图像修复任务，我们发现某些种子倾向于插入不需要的文本伪影。总体而言，我们广泛的分析强调了选择良好种子的重要性，并为图像生成提供了实际效用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14828v2">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>文本到图像（T2I）扩散模型的最新进展促进了创造性与逼真的图像合成。通过改变随机种子，我们可以为固定的文本提示生成多个图像。技术上，种子控制初始噪声，并在多步扩散推断中，用于反向扩散过程中间时步的重新参数化的噪声。然而，关于随机种子对生成图像的具体影响尚未得到充分探索。在这项工作中，我们对扩散推断过程中随机种子的影响进行了大规模的科学研究。值得注意的是，我们发现了最佳的“黄金”种子，其FID达到了令人印象深刻的21.60，而最差“劣质”种子的FID为31.97。此外，分类器可以在仅仅几个epoch内以超过99.9%的准确率预测用于生成图像的种子编号，这证明了基于生成的图像，种子之间的区分度极高。受这些发现的鼓舞，我们研究了种子对可解释的视觉维度的影响。我们发现某些种子会一致地产生灰度图像、突出的天空区域或图像边界。种子还会影响图像构图，包括对象的位置、大小和深度。此外，通过利用这些“黄金”种子，我们展示了改进的图像生成，如高保真推断和多样化的采样。我们的调查还扩展到了修复任务，在那里我们发现某些种子倾向于插入不需要的文本伪影。总的来说，我们深入的分析强调了选择良好种子的重要性，并为图像生成提供了实际效用。</p>
<p><strong>要点</strong></p>
<ol>
<li>文本到图像（T2I）扩散模型的最新进展推动了创造性与逼真的图像合成的发展。</li>
<li>随机种子在生成图像中具有显著影响，最佳“黄金”种子能生成高质量的图像。</li>
<li>通过分类器预测生成图像的种子编号，证明了种子之间的区分度极高。</li>
<li>种子影响图像的多方面特征，如灰度、天空区域、图像边界、对象位置、大小和深度。</li>
<li>利用“黄金”种子可改进图像生成，包括高保真推断和多样化采样。</li>
<li>在修复任务中，某些种子可能产生不需要的文本伪影。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.14828">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4664a8d3db72547e9a4f440c2fc292f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ada45763c295057c203d08abf6367d36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f783950b4ec2e7ce40d9db5a519bf59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec0452b20c19db147a9b3a7ee14fba89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5de3c8c626f82b8dd1a21913c2124fe1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3ee9bfcb0345b8e2acc9aa9c2805851.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SparseDM-Toward-Sparse-Efficient-Diffusion-Models"><a href="#SparseDM-Toward-Sparse-Efficient-Diffusion-Models" class="headerlink" title="SparseDM: Toward Sparse Efficient Diffusion Models"></a>SparseDM: Toward Sparse Efficient Diffusion Models</h2><p><strong>Authors:Kafeng Wang, Jianfei Chen, He Li, Zhenpeng Mi, Jun Zhu</strong></p>
<p>Diffusion models represent a powerful family of generative models widely used for image and video generation. However, the time-consuming deployment, long inference time, and requirements on large memory hinder their applications on resource constrained devices. In this paper, we propose a method based on the improved Straight-Through Estimator to improve the deployment efficiency of diffusion models. Specifically, we add sparse masks to the Convolution and Linear layers in a pre-trained diffusion model, then transfer learn the sparse model during the fine-tuning stage and turn on the sparse masks during inference. Experimental results on a Transformer and UNet-based diffusion models demonstrate that our method reduces MACs by 50% while maintaining FID. Sparse models are accelerated by approximately 1.2x on the GPU. Under other MACs conditions, the FID is also lower than 1 compared to other methods. </p>
<blockquote>
<p>扩散模型是一种强大的生成模型家族，广泛应用于图像和视频生成。然而，其耗时的部署、长的推理时间以及对大内存的要求，阻碍了其在资源受限设备上的应用。在本文中，我们提出了一种基于改进后的直通估计器的方法，以提高扩散模型的部署效率。具体来说，我们在预训练的扩散模型的卷积和线性层中添加稀疏掩码，然后在微调阶段对稀疏模型进行迁移学习，并在推理阶段启用稀疏掩码。在基于Transformer和UNet的扩散模型上的实验结果表明，我们的方法将乘加运算（MACs）减少了50%，同时保持了FID。稀疏模型在GPU上的速度提高了大约1.2倍。在其他MACs条件下，与其他方法相比，FID也低于1。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.10445v4">PDF</a> This paper has been accepted by ICME 2025</p>
<p><strong>Summary</strong><br>     本文提出一种基于改进直通估计器的方法，用于提高扩散模型的部署效率。通过在预训练的扩散模型中的卷积和线性层添加稀疏掩码，然后进行微调阶段的迁移学习，并在推理阶段启用稀疏掩码，实验结果表明，该方法在保持FID不变的情况下，将MACs降低了50%，并实现了GPU上的近似1.2倍加速。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>扩散模型广泛应用于图像和视频生成，但其在资源受限设备上的部署存在时间消耗长、推理时间长和大内存要求等问题。</li>
<li>本文提出一种基于改进直通估计器的方法来提高扩散模型的部署效率。</li>
<li>通过添加稀疏掩码到预训练的扩散模型中的卷积和线性层，然后进行迁移学习，实验结果表明能够降低计算复杂度（MACs）并加速推理。</li>
<li>方法在保持图像质量（FID）不变的情况下，将计算量降低了50%。</li>
<li>在GPU上实现了近似1.2倍的加速效果。</li>
<li>在不同的计算条件下，该方法的FID低于其他方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.10445">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2d7da1af4a2f8e90f2d402369cad8eaa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0b9274db2cf995d7fd150e6bd62f40c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afda3a2b8814f66a9f770e8d17ebe0a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-381503bbc12058390c7c3a58813a69c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb04362e6e2476b5dedbf4bf86a0da6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d3b2068c9fe3f0de98f9771d813f3cca.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Detecting-Origin-Attribution-for-Text-to-Image-Diffusion-Models"><a href="#Detecting-Origin-Attribution-for-Text-to-Image-Diffusion-Models" class="headerlink" title="Detecting Origin Attribution for Text-to-Image Diffusion Models"></a>Detecting Origin Attribution for Text-to-Image Diffusion Models</h2><p><strong>Authors:Katherine Xu, Lingzhi Zhang, Jianbo Shi</strong></p>
<p>Modern text-to-image (T2I) diffusion models can generate images with remarkable realism and creativity. These advancements have sparked research in fake image detection and attribution, yet prior studies have not fully explored the practical and scientific dimensions of this task. In addition to attributing images to 12 state-of-the-art T2I generators, we provide extensive analyses on what inference stage hyperparameters and image modifications are discernible. Our experiments reveal that initialization seeds are highly detectable, along with other subtle variations in the image generation process to some extent. We further investigate what visual traces are leveraged in image attribution by perturbing high-frequency details and employing mid-level representations of image style and structure. Notably, altering high-frequency information causes only slight reductions in accuracy, and training an attributor on style representations outperforms training on RGB images. Our analyses underscore that fake images are detectable and attributable at various levels of visual granularity. </p>
<blockquote>
<p>现代文本到图像（T2I）的扩散模型能够生成具有显著真实感和创造力的图像。这些进展引发了关于虚假图像检测和归属的研究，但先前的研究并未完全探索此任务的实际和科学层面。除了将图像归于12种最先进的T2I生成器之外，我们还对推理阶段超参数和图像修改的可识别性进行了广泛的分析。我们的实验表明，初始化种子是高度可检测的，图像生成过程中的其他细微变化也在一定程度上可检测。我们通过扰动高频细节并采用图像风格和结构的中级表示，进一步调查图像归属中利用了什么视觉痕迹。值得注意的是，改变高频信息只会略微降低准确性，而且在风格表示上训练归属者优于在RGB图像上训练。我们的分析强调，虚假图像在各种视觉粒度级别上都是可检测和可归属的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19653v3">PDF</a> Code available at <a target="_blank" rel="noopener" href="https://github.com/k8xu/ImageAttribution">https://github.com/k8xu/ImageAttribution</a></p>
<p><strong>Summary</strong></p>
<p>本文探讨了现代文本到图像（T2I）扩散模型生成的图像的检测与归因问题。研究发现，除了能将图像归因于先进的T2I生成器之外，通过调整推断阶段的超参数和图像修改，可以检测出生成图像的初始化种子等细微变化。同时，通过对图像风格和结构的中级表示进行扰动，发现视觉痕迹在图像归因中的利用方式。实验表明，改变高频信息对准确率影响较小，而以风格表征训练归因器的方法优于以RGB图像训练的方法。研究强调，在视觉粒度不同层面，假图像是可检测和可归因的。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现代文本到图像（T2I）扩散模型可以生成非常逼真和具有创意的图像。</li>
<li>T2I生成的图像的检测与归因问题引起了研究关注。</li>
<li>通过调整推断阶段的超参数和图像修改，可以检测出生成图像的初始化种子等细微变化。</li>
<li>初始化种子在图像生成过程中的检测是一个关键。</li>
<li>通过对图像风格和结构的中级表示进行扰动，揭示了视觉痕迹在图像归因中的重要性。</li>
<li>改变高频信息对假图像检测与归因的准确性影响较小。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.19653">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b1556c5098748137d09fbda4a984b397.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abf841d9a28a02863beea05eed4d4ee1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7866e01d3a0d6be58b5914ee1acdce89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-065da3e9a222078b2987b68b0397b53b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6692fd6482684511e7d58f28e35df3a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75c42d91960cd9310fcb3b06ead83af8.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-2c74f2cca7b848b633bc660dbb1dec93.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-04-19  EchoWorld Learning Motion-Aware World Models for Echocardiography Probe   Guidance
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3cced1b94dcf46520192d77c261d43c8.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-04-19  High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25219.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
