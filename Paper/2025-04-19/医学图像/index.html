<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="医学图像">
    <meta name="description" content="医学图像 方向最新论文已更新，请持续关注 Update in 2025-04-19  EchoWorld Learning Motion-Aware World Models for Echocardiography Probe   Guidance">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>医学图像 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-2c74f2cca7b848b633bc660dbb1dec93.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">医学图像</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">医学图像</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                医学图像
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    26 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-19-更新"><a href="#2025-04-19-更新" class="headerlink" title="2025-04-19 更新"></a>2025-04-19 更新</h1><h2 id="EchoWorld-Learning-Motion-Aware-World-Models-for-Echocardiography-Probe-Guidance"><a href="#EchoWorld-Learning-Motion-Aware-World-Models-for-Echocardiography-Probe-Guidance" class="headerlink" title="EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe   Guidance"></a>EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe   Guidance</h2><p><strong>Authors:Yang Yue, Yulin Wang, Haojun Jiang, Pan Liu, Shiji Song, Gao Huang</strong></p>
<p>Echocardiography is crucial for cardiovascular disease detection but relies heavily on experienced sonographers. Echocardiography probe guidance systems, which provide real-time movement instructions for acquiring standard plane images, offer a promising solution for AI-assisted or fully autonomous scanning. However, developing effective machine learning models for this task remains challenging, as they must grasp heart anatomy and the intricate interplay between probe motion and visual signals. To address this, we present EchoWorld, a motion-aware world modeling framework for probe guidance that encodes anatomical knowledge and motion-induced visual dynamics, while effectively leveraging past visual-motion sequences to enhance guidance precision. EchoWorld employs a pre-training strategy inspired by world modeling principles, where the model predicts masked anatomical regions and simulates the visual outcomes of probe adjustments. Built upon this pre-trained model, we introduce a motion-aware attention mechanism in the fine-tuning stage that effectively integrates historical visual-motion data, enabling precise and adaptive probe guidance. Trained on more than one million ultrasound images from over 200 routine scans, EchoWorld effectively captures key echocardiographic knowledge, as validated by qualitative analysis. Moreover, our method significantly reduces guidance errors compared to existing visual backbones and guidance frameworks, excelling in both single-frame and sequential evaluation protocols. Code is available at <a target="_blank" rel="noopener" href="https://github.com/LeapLabTHU/EchoWorld">https://github.com/LeapLabTHU/EchoWorld</a>. </p>
<blockquote>
<p>超声心动图是检测心血管疾病的关键手段，但很大程度上依赖于经验丰富的超声心动图技师。超声心动图探头引导系统能够提供实时移动指令，获取标准平面图像，为人工智能辅助或全自动扫描提供了前景广阔的解决方案。然而，开发此项任务的有效机器学习模型仍然充满挑战，因为它们必须掌握心脏结构以及探头运动与视觉信号之间的复杂相互作用。针对这一问题，我们提出了EchoWorld，这是一个用于探头引导的运动感知世界建模框架，它编码了解结构知识以及运动引起的视觉动态，同时有效地利用过去的视觉运动序列来提高引导精度。EchoWorld采用了一种受世界建模原理启发的预训练策略，其中模型会预测被遮挡的结构区域并模拟探头调整后的视觉结果。在此基础上，我们在微调阶段引入了一种运动感知注意力机制，有效地集成了历史视觉运动数据，实现了精确和自适应的探头引导。EchoWorld在超过200次常规扫描的超过100万张超声图像上进行训练，有效地捕获了关键超声心动图知识，并通过定性分析得到了验证。此外，我们的方法与现有的视觉主干和引导框架相比，在指导误差方面有了显著的降低，在单帧和顺序评估协议方面都表现出色。相关代码可访问<a target="_blank" rel="noopener" href="https://github.com/LeapLabTHU/EchoWorld%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/LeapLabTHU/EchoWorld获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13065v1">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong><br>     超声心动图在心血管疾病检测中至关重要，但依赖于经验丰富的超声医师。超声心动图探头引导系统提供实时运动指令以获取标准平面图像，为人工智能辅助或全自动扫描提供了有前景的解决方案。然而，开发此任务的有效机器学习模型具有挑战性，需理解心脏解剖结构和探头运动与视觉信号的复杂交互。为此，我们提出EchoWorld，一个用于探头引导的运动感知世界建模框架，编码解剖知识和运动引起的视觉动态，有效利用过去的视觉运动序列以提高引导精度。EchoWorld采用受世界建模原理启发的预训练策略，其中模型预测被遮挡的解剖区域并模拟探头调整的视觉结果。在基于预训练模型的基础上，我们在微调阶段引入运动感知注意力机制，有效整合历史视觉运动数据，实现精确自适应的探头引导。在超过二十万例常规扫描的超声图像上训练，EchoWorld有效捕捉关键超声心动图知识，定性分析得到验证。与现有视觉主干和指导框架相比，我们的方法显著减少了指导误差，在单帧和序列评估协议中均表现优异。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>超声心动图在心血管疾病检测中非常重要，但依赖于专业超声医师的操作。</li>
<li>超声心动图探头引导系统提供实时运动指令，有助于人工智能辅助或全自动扫描。</li>
<li>机器学习模型在开发超声心动图探头引导系统时面临挑战，需理解心脏解剖和探头运动与视觉信号的复杂交互。</li>
<li>EchoWorld是一个运动感知世界建模框架，用于探头引导，编码解剖知识和视觉动态，提高引导精度。</li>
<li>EchoWorld采用预训练策略并引入运动感知注意力机制，有效整合历史视觉运动数据。</li>
<li>EchoWorld在大量超声图像数据上训练，表现优异，显著减少探头引导误差。</li>
<li>EchoWorld代码已公开可用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13065">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f7b7dee2642bc112ecc23872da51fadd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc4b39480f20d89f0d8d857582112651.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c74f2cca7b848b633bc660dbb1dec93.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-53c4affccf6fec15218a21571f8ba118.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c4fbd2f0b044c695341a298a089b2b52.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-391ef8b1101cdbe1b39b75387c9252b0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Towards-Cardiac-MRI-Foundation-Models-Comprehensive-Visual-Tabular-Representations-for-Whole-Heart-Assessment-and-Beyond"><a href="#Towards-Cardiac-MRI-Foundation-Models-Comprehensive-Visual-Tabular-Representations-for-Whole-Heart-Assessment-and-Beyond" class="headerlink" title="Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular   Representations for Whole-Heart Assessment and Beyond"></a>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular   Representations for Whole-Heart Assessment and Beyond</h2><p><strong>Authors:Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan</strong></p>
<p>Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual’s disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis. </p>
<blockquote>
<p>心脏磁共振成像在非侵入式心脏评估中是金标准，它提供了丰富的关于心脏解剖结构和生理功能的时空视图。已知患者层面的健康因素，如人口统计学特征、新陈代谢和生活方式，会对心血管健康和疾病风险产生重大影响，但这些因素仅靠心脏磁共振成像无法捕捉。为了全面了解心脏健康并为个人的疾病风险提供最准确的解释，必须在综合框架中联合利用心脏磁共振成像和患者层面的因素。最近的多种模态方法已经开始弥补这一差距，但它们通常依赖于有限的时空数据并专注于孤立的临床任务，从而阻碍了心脏健康评估的全面表示的发展。为了克服这些限制，我们引入了ViTa，它朝着基础模型迈出了一步，提供了对心脏的全面表示和对个人疾病风险的精确解释。ViTa利用来自42,000名英国生物银行参与者的数据，整合了短轴和长轴视图的3D+T电影堆栈，能够完全捕捉心脏周期。然后，这些成像数据与详细的表格患者层面因素相融合，提供情境感知的见解。这种多模态范式支持广泛的下游任务，包括心脏表型预测和生理特征预测、分割以及在一个统一的框架内对心脏和代谢疾病的分类。通过学习丰富的成像特征和患者上下文的共享潜在表示，ViTa超越了传统的、针对特定任务的模型，朝着通用、针对特定患者的理解心脏健康的方向发展，这突显了其在心脏分析的临床实用性和可扩展性方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13037v1">PDF</a> </p>
<p><strong>Summary</strong><br>    心脏磁共振成像（CMR）是评估心脏健康的金标准，提供了丰富的时空视图。然而，患者级别的健康因素（如人口统计学、代谢和生活方式）对心血管健康及疾病风险有重要影响，而CMR无法捕获这些因素。为全面了解心脏健康及进行个体化的疾病风险评估，需要将CMR与患者级别因素在综合框架内联合利用。ViTa模型是一个朝着基础模型迈进的步骤，提供了心脏的综合表征和精确的疾病风险评估。它融合了来自UK Biobank的4.2万名参与者的数据，整合了来自短轴和长轴视图的3D+T电影堆栈，捕捉了整个心脏周期。成像数据与详细的表格患者级别因素相结合，提供了情境感知的见解。这一多模式范式支持广泛的下游任务，包括心脏表型预测、生理特征预测、分割以及单一统一框架内的代谢性疾病分类。ViTa通过学习一个共享的潜在表征，该表征连接了丰富的成像特征和患者上下文，从而超越了传统的任务特定模型，朝着患者特异性的心脏健康通用理解发展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>心脏磁共振成像（CMR）是评估心脏健康的金标准，但无法捕获患者级别的健康因素如人口统计学、代谢和生活方式等。</li>
<li>为全面了解心脏健康和进行最佳疾病风险评估，需要将CMR与患者级别因素在综合框架内联合利用。</li>
<li>ViTa模型是一个综合的心脏健康表征模型，能够精确评估个体疾病风险。</li>
<li>ViTa模型融合了丰富的成像数据和患者级别因素，支持多种下游任务，包括心脏表型预测、生理特征预测、分割以及疾病分类。</li>
<li>ViTa模型通过共享潜在表征连接丰富的成像特征和患者上下文，从而超越了传统的任务特定模型。</li>
<li>ViTa模型具有潜力提高心脏分析的临床实用性和可扩展性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13037">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1330ca4d73754ccb99ae5719c36413eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e4d92fbcd48897fc9c621cb46f4b9bf.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SC3EF-A-Joint-Self-Correlation-and-Cross-Correspondence-Estimation-Framework-for-Visible-and-Thermal-Image-Registration"><a href="#SC3EF-A-Joint-Self-Correlation-and-Cross-Correspondence-Estimation-Framework-for-Visible-and-Thermal-Image-Registration" class="headerlink" title="SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation   Framework for Visible and Thermal Image Registration"></a>SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation   Framework for Visible and Thermal Image Registration</h2><p><strong>Authors:Xi Tong, Xing Luo, Jiangxin Yang, Yanpeng Cao</strong></p>
<p>Multispectral imaging plays a critical role in a range of intelligent transportation applications, including advanced driver assistance systems (ADAS), traffic monitoring, and night vision. However, accurate visible and thermal (RGB-T) image registration poses a significant challenge due to the considerable modality differences. In this paper, we present a novel joint Self-Correlation and Cross-Correspondence Estimation Framework (SC3EF), leveraging both local representative features and global contextual cues to effectively generate RGB-T correspondences. For this purpose, we design a convolution-transformer-based pipeline to extract local representative features and encode global correlations of intra-modality for inter-modality correspondence estimation between unaligned visible and thermal images. After merging the local and global correspondence estimation results, we further employ a hierarchical optical flow estimation decoder to progressively refine the estimated dense correspondence maps. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming the current state-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore, it also shows competitive generalization capabilities across challenging scenarios, including large parallax, severe occlusions, adverse weather, and other cross-modal datasets (e.g., RGB-N and RGB-D). </p>
<blockquote>
<p>多光谱成像在智能交通应用的各个领域都扮演着关键角色，包括高级驾驶辅助系统（ADAS）、交通监控和夜视。然而，由于模态差异较大，准确的可见光和热（RGB-T）图像配准是一个巨大的挑战。在本文中，我们提出了一种新型的联合自相关和交叉对应估计框架（SC3EF），利用局部代表性特征和全局上下文线索来有效地生成RGB-T对应关系。为此，我们设计了一个基于卷积转换器的管道，以提取局部代表性特征并编码模态内全局相关性，用于未对齐的可见光和热图像之间的模态间对应关系估计。在合并局部和全局对应估计结果后，我们进一步采用分层光流估计解码器来逐步优化估计的密集对应地图。大量实验表明，我们提出的方法非常有效，在代表性RGB-T数据集上的性能超过了当前最先进的（SOTA）方法。此外，它在具有挑战性的场景中还显示出具有竞争力的泛化能力，包括大视差、严重遮挡、恶劣天气和其他跨模态数据集（如RGB-N和RGB-D）。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12869v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文主要介绍了多光谱成像在智能交通应用中的关键作用，包括高级驾驶辅助系统、交通监测和夜视。针对可见光和热成像（RGB-T）图像配准的挑战，提出了一种新的联合自相关和交叉对应估计框架（SC3EF）。该框架利用局部代表性特征和全局上下文线索，通过卷积-变压器基础的管道设计，有效生成RGB-T对应关系。通过合并局部和全局对应估计结果，进一步采用分层光流估计解码器，逐步优化估计的密集对应地图。实验表明，该方法在代表性RGB-T数据集上优于现有先进技术，并在具有挑战性的场景中显示出良好的泛化能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多光谱成像在智能交通应用中扮演重要角色，如高级驾驶辅助系统、交通监测和夜视。</li>
<li>RGB-T图像配准是一个重大挑战，因为不同模态之间的差异很大。</li>
<li>提出了SC3EF框架，该框架利用局部代表性特征和全局上下文线索来生成有效的RGB-T对应关系。</li>
<li>通过卷积-变压器基础的管道设计进行特征提取和编码。</li>
<li>合并局部和全局对应估计结果后，采用分层光流估计解码器逐步优化估计的密集对应地图。</li>
<li>实验表明，该方法在代表性RGB-T数据集上表现优异，优于现有技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12869">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-971240a6b9ab00a1cfb009a32eac07c8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b949e09e23935db8e1688d84a7f4c32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-66d56eabd1e4f2638b9c32d9798d3150.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7be1b185788096357121319356e19f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e30744bf590a87994a74b65e64ffad6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9d499b6fccb4794721e1a089e5d9bca.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multi-Parameter-Molecular-MRI-Quantification-using-Physics-Informed-Self-Supervised-Learning"><a href="#Multi-Parameter-Molecular-MRI-Quantification-using-Physics-Informed-Self-Supervised-Learning" class="headerlink" title="Multi-Parameter Molecular MRI Quantification using Physics-Informed   Self-Supervised Learning"></a>Multi-Parameter Molecular MRI Quantification using Physics-Informed   Self-Supervised Learning</h2><p><strong>Authors:Alex Finkelstein, Nikita Vladimirov, Moritz Zaiss, Or Perlman</strong></p>
<p>Biophysical model fitting plays a key role in obtaining quantitative parameters from physiological signals and images. However, the model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation. The neural-network-based train-by-fit pipeline was used to quantify semisolid magnetization transfer (MT) and chemical exchange saturation transfer (CEST) amide proton exchange parameters in the human brain, in an in-vivo molecular MRI study (n &#x3D; 4). The entire pipeline of the first whole brain quantification was completed in 18.3 $\pm$ 8.3 minutes. Reusing the single-subject-trained network for inference in new subjects took 1.0 $\pm$ 0.2 s, to provide results in agreement with literature values and scan-specific fit results. </p>
<blockquote>
<p>生物物理模型拟合在从生理信号和图像中获得定量参数方面起着关键作用。然而，分子磁共振成像（MRI）的模型复杂性通常会导致计算时间过长，使得其在临床上的实际应用变得不切实际。在这里，我们提出了一种解决由常微分方程（ODE）建模所引发参数提取反问题的通用计算方法，该方法结合了系统动力学的实验测量。我们通过制定数值ODE求解器来使其作为逐步分析的工具，从而使其与基于自动微分的优化相兼容。这实现了有效的基于梯度的模型拟合，并提供了一种基于单一数据观察的自我监督学习的新参数量化方法。基于神经网络训练-拟合管道被用于量化半固态磁化转移（MT）和化学交换饱和转移（CEST）酰胺质子交换参数在人脑内，在一次活体分子MRI研究（n&#x3D;4）。首个全脑量化整个管道在18.3±8.3分钟内完成。对于新受试者进行推理时重复使用单个受试者训练的网络需要花费1.0±0.2秒，其研究结果与文献值和特定扫描结果一致。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.06447v2">PDF</a> This project was funded by the European Union (ERC, BabyMagnet,   project no. 101115639), the Ministry of Innovation, Science and Technology,   Israel, and a grant from the Tel Aviv University Center for AI and Data   Science (TAD, The Blavatnik AI and Data Science Fund). None of above can be   held responsible for views and opinions expressed, which are those of the   authors alone</p>
<p><strong>Summary</strong></p>
<p>本研究提出一种解决生理信号和图像中参数提取逆问题的通用计算方法。通过构建数值常微分方程（ODE）求解器，实现逐步分析，与基于自动微分优化相结合，提高了模型拟合效率，并基于单数据观测的自监督学习实现参数量化。在人体脑部活体分子MRI研究中（n&#x3D;4），利用神经网络训练拟合管道量化半固体磁化转移（MT）和化学交换饱和转移（CEST）酰胺质子交换参数，首次完成全脑量化流程耗时约18分钟。对新受试者的推断使用单一受试者训练的网络即可完成耗时不超过一秒的预测结果。结果符合文献值和扫描特定拟合结果。 </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本研究提出了一种解决生理信号和图像参数提取的通用计算方法，适用于复杂模型中的参数提取问题。</li>
<li>通过构建数值ODE求解器，实现逐步分析，提高了模型拟合效率。</li>
<li>结合自动微分优化技术，使得基于自监督学习的参数量化成为可能。</li>
<li>在人体脑部活体分子MRI研究中应用该方法，成功量化半固体磁化转移和化学交换饱和转移参数。</li>
<li>完成首次全脑量化流程耗时约18分钟，新受试者推断耗时不超过一秒。</li>
<li>结果符合文献值和扫描特定拟合结果，证明了该方法的准确性和可靠性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.06447">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-0f632dc422e20ea6b7fceb16a7b0e4e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fd248e75ee4c7f6ce8b007ffef8bbe50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a667cff34b35234bc0b62f8d7a38010.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d886bd623144a25eaedb5a50acc25ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b830cd0ed4989a05d222a2d02b5373d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Visually-Consistent-Hierarchical-Image-Classification"><a href="#Visually-Consistent-Hierarchical-Image-Classification" class="headerlink" title="Visually Consistent Hierarchical Image Classification"></a>Visually Consistent Hierarchical Image Classification</h2><p><strong>Authors:Seulki Park, Youren Zhang, Stella X. Yu, Sara Beery, Jonathan Huang</strong></p>
<p>Hierarchical classification predicts labels across multiple levels of a taxonomy, e.g., from coarse-level ‘Bird’ to mid-level ‘Hummingbird’ to fine-level ‘Green hermit’, allowing flexible recognition under varying visual conditions. It is commonly framed as multiple single-level tasks, but each level may rely on different visual cues: Distinguishing ‘Bird’ from ‘Plant’ relies on global features like feathers or leaves, while separating ‘Anna’s hummingbird’ from ‘Green hermit’ requires local details such as head coloration. Prior methods improve accuracy using external semantic supervision, but such statistical learning criteria fail to ensure consistent visual grounding at test time, resulting in incorrect hierarchical classification. We propose, for the first time, to enforce internal visual consistency by aligning fine-to-coarse predictions through intra-image segmentation. Our method outperforms zero-shot CLIP and state-of-the-art baselines on hierarchical classification benchmarks, achieving both higher accuracy and more consistent predictions. It also improves internal image segmentation without requiring pixel-level annotations. </p>
<blockquote>
<p>层次分类预测了分类体系中的多级标签，例如从粗略级别的“鸟”到中级别的“蜂鸟”再到精细级别的“绿翅绿鹊”，这在不同的视觉条件下实现了灵活的识别。它通常被视为多个单一级别的任务，但每个级别可能依赖于不同的视觉线索：区分“鸟”和“植物”依赖于羽毛或叶子等全局特征，而将“安娜蜂鸟”与“绿翅绿鹊”区分开则需要局部细节，例如头色。之前的方法通过外部语义监督提高了准确性，但这样的统计学习标准不能保证测试时的视觉一致性，从而导致错误的层次分类。我们首次提出通过图像内分割对精细到粗略的预测进行对齐来强制执行内部视觉一致性。我们的方法在层次分类基准测试上的表现优于零样本CLIP和最新基线，实现了更高的准确性和更一致的预测。同时，它还提高了无需像素级注释的内部图像分割效果。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.11608v2">PDF</a> Accepted to ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了层次分类技术在图像识别中的应用，该技术可以预测多个级别的标签，如从粗级别的“鸟”到中级别的“蜂鸟”再到细级别的“绿翅蜂鸟”。文章指出，虽然层次分类常被看作多个单一级别的任务，但每个级别可能依赖于不同的视觉线索。作者提出一种新方法，通过图像内部分割来强制实施内部视觉一致性，实现对精细到粗糙预测的对齐，该方法在层次分类基准测试上的表现优于零样本CLIP和现有先进技术，提高了准确性和预测的一致性，并能在无需像素级别注释的情况下改善图像分割。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>层次分类可以预测多个级别的标签，适应不同视觉条件下的灵活识别。</li>
<li>每一层次的分类可能依赖于不同的视觉线索。</li>
<li>现有方法通过外部语义监督提高准确性，但在测试时无法保证视觉一致性。</li>
<li>首次提出通过图像内部分割来强制实施内部视觉一致性。</li>
<li>该方法提高了层次分类的准确性和预测的一致性。</li>
<li>该方法在不需像素级别注释的情况下改善了图像分割。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.11608">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c01d9df9778c382debc55f361a55fb5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0da39b7a29dba877b14d654380154fdf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db4dd9277269fef8c49f3133bca5df6b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e45cfc2c2902b5ca25163e7adf046a2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31de7dbc27565807cca15878dc46530a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MCANet-Medical-Image-Segmentation-with-Multi-Scale-Cross-Axis-Attention"><a href="#MCANet-Medical-Image-Segmentation-with-Multi-Scale-Cross-Axis-Attention" class="headerlink" title="MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention"></a>MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention</h2><p><strong>Authors:Hao Shao, Quansheng Zeng, Qibin Hou, Jufeng Yang</strong></p>
<p>Efficiently capturing multi-scale information and building long-range dependencies among pixels are essential for medical image segmentation because of the various sizes and shapes of the lesion regions or organs. In this paper, we present Multi-scale Cross-axis Attention (MCA) to solve the above challenging issues based on the efficient axial attention. Instead of simply connecting axial attention along the horizontal and vertical directions sequentially, we propose to calculate dual cross attentions between two parallel axial attentions to capture global information better. To process the significant variations of lesion regions or organs in individual sizes and shapes, we also use multiple convolutions of strip-shape kernels with different kernel sizes in each axial attention path to improve the efficiency of the proposed MCA in encoding spatial information. We build the proposed MCA upon the MSCAN backbone, yielding our network, termed MCANet. Our MCANet with only 4M+ parameters performs even better than most previous works with heavy backbones (e.g., Swin Transformer) on four challenging tasks, including skin lesion segmentation, nuclei segmentation, abdominal multi-organ segmentation, and polyp segmentation. Code is available at <a target="_blank" rel="noopener" href="https://github.com/haoshao-nku/medical_seg">https://github.com/haoshao-nku/medical_seg</a>. </p>
<blockquote>
<p>在医学图像分割中，由于病变区域或器官的大小和形状各异，有效地捕获多尺度信息以及建立像素之间的长距离依赖关系至关重要。针对以上挑战性问题，本文提出了基于高效轴向注意力的多尺度跨轴注意力（MCA）来解决。我们并不只是简单地按顺序在水平和垂直方向上连接轴向注意力，而是提议计算两个并行轴向注意力之间的双重交叉注意力，以更好地捕获全局信息。为了处理病变区域或器官在大小和形状上的显著差异，我们还将在每个轴向注意力路径中使用不同内核大小的条形卷积核进行多次卷积，以提高所提出MCA编码空间信息的效率。我们将所提出MCA建立在MSCAN主干网络上，形成了我们的网络，称为MCANet。我们的MCANet仅有4M+的参数，在四项具有挑战性的任务上表现甚至超过了以前大多数使用重型骨干网络的工作（例如Swin Transformer），这四项任务包括皮肤病变分割、细胞核分割、腹部多器官分割和息肉分割。相关代码可通过以下网址获取：<a target="_blank" rel="noopener" href="https://github.com/haoshao-nku/medical_seg">https://github.com/haoshao-nku/medical_seg</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.08866v3">PDF</a> accept to Machine Intelligence Research.DOI:   10.1007&#x2F;s11633-025-1552-6</p>
<p><strong>Summary</strong></p>
<p>该文提出了多尺度交叉轴注意力（MCA）机制，用于解决医疗图像分割中的多尺度信息捕捉和长程像素依赖性问题。基于轴向注意力，通过计算两个平行轴向注意力之间的双重交叉注意力来更好地捕捉全局信息。为提高MCANet的效率，采用不同大小的条形卷积核进行多次卷积处理，以应对病灶区域或器官大小和形状的显著变化。MCANet在四个具有挑战性的任务上表现优异，包括皮肤病变分割、细胞核分割、腹部多器官分割和息肉分割。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多尺度信息捕捉和长程像素依赖性是医疗图像分割中的关键挑战。</li>
<li>提出的多尺度交叉轴注意力（MCA）机制旨在解决这些挑战。</li>
<li>MCA通过计算两个平行轴向注意力之间的双重交叉注意力来捕捉全局信息。</li>
<li>为提高效率，采用多种尺寸的条形卷积核处理不同大小和形状的病灶区域或器官。</li>
<li>MCANet在四个挑战性的医疗图像分割任务上表现优秀。</li>
<li>MCANet参数仅4M+，但性能优于大多数带有重型骨干网（如Swin Transformer）的先前工作。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.08866">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-cae8a508011d4b8b5328fda7140293df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e45839ff02132dbd6d405ee7181fa87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e123fa6245d28dbd1d76e13a1bae932b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e5a2004a790b982c71d3d0e50abf19e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f32b52e01b3691eb6d02d1102991af6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2eaad88bea15df7bc8e063c4bdc1932.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">医学图像</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-fe1384de69f524679eb319e8e902826e.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-04-19  EmoVoice LLM-based Emotional Text-To-Speech Model with Freestyle Text   Prompting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e0b9274db2cf995d7fd150e6bd62f40c.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-19  UniEdit-Flow Unleashing Inversion and Editing in the Era of Flow Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">18181.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
