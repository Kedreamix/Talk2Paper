<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent   Collaboration">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4c5851f0c5fba71136fdaee90cf924fd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    72 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-09-æ›´æ–°"><a href="#2025-07-09-æ›´æ–°" class="headerlink" title="2025-07-09 æ›´æ–°"></a>2025-07-09 æ›´æ–°</h1><h2 id="Modeling-Latent-Partner-Strategies-for-Adaptive-Zero-Shot-Human-Agent-Collaboration"><a href="#Modeling-Latent-Partner-Strategies-for-Adaptive-Zero-Shot-Human-Agent-Collaboration" class="headerlink" title="Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent   Collaboration"></a>Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent   Collaboration</h2><p><strong>Authors:Benjamin Li, Shuyang Shi, Lucia Romero, Huao Li, Yaqi Xie, Woojun Kim, Stefanos Nikolaidis, Michael Lewis, Katia Sycara, Simon Stepputtis</strong></p>
<p>In collaborative tasks, being able to adapt to your teammates is a necessary requirement for success. When teammates are heterogeneous, such as in human-agent teams, agents need to be able to observe, recognize, and adapt to their human partners in real time. This becomes particularly challenging in tasks with time pressure and complex strategic spaces where the dynamics can change rapidly. In this work, we introduce TALENTS, a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a range of partner strategies, enabling ad-hoc teamwork. Our approach utilizes a variational autoencoder to learn a latent strategy space from trajectory data. This latent space represents the underlying strategies that agents employ. Subsequently, the system identifies different types of strategy by clustering the data. Finally, a cooperator agent is trained to generate partners for each type of strategy, conditioned on these clusters. In order to adapt to previously unseen partners, we leverage a fixed-share regret minimization algorithm that infers and adjusts the estimated partner strategy dynamically. We assess our approach in a customized version of the Overcooked environment, posing a challenging cooperative cooking task that demands strong coordination across a wide range of possible strategies. Using an online user study, we show that our agent outperforms current baselines when working with unfamiliar human partners. </p>
<blockquote>
<p>åœ¨åä½œä»»åŠ¡ä¸­ï¼Œèƒ½å¤Ÿé€‚åº”é˜Ÿå‹æ˜¯æˆåŠŸçš„å¿…è¦æ¡ä»¶ã€‚å½“é˜Ÿå‹å…·æœ‰å·®å¼‚æ€§ï¼Œå¦‚åœ¨äººç±»ä¸æ™ºèƒ½ä½“ç»„æˆçš„å›¢é˜Ÿä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦èƒ½å¤Ÿå®æ—¶è§‚å¯Ÿã€è¯†åˆ«å¹¶é€‚åº”å…¶äººç±»ä¼™ä¼´ã€‚è¿™åœ¨æœ‰æ—¶é—´å‹åŠ›å’Œå¤æ‚æˆ˜ç•¥ç©ºé—´çš„ä»»åŠ¡ä¸­å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåŠ¨æ€å¯èƒ½ä¼šè¿…é€Ÿå˜åŒ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†TALENTSï¼ˆç­–ç•¥æ¡ä»¶åä½œæ¡†æ¶ï¼‰ï¼Œå®ƒèƒ½å¤Ÿå­¦ä¹ è¡¨ç¤ºã€åˆ†ç±»å¹¶é€‚åº”ä¸€ç³»åˆ—ä¼™ä¼´ç­–ç•¥ï¼Œä»è€Œå®ç°å³æ—¶å›¢é˜Ÿåä½œã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ä»è½¨è¿¹æ•°æ®ä¸­å­¦ä¹ æ½œåœ¨ç­–ç•¥ç©ºé—´ã€‚è¯¥æ½œåœ¨ç©ºé—´ä»£è¡¨äº†æ™ºèƒ½ä½“æ‰€é‡‡ç”¨çš„åº•å±‚ç­–ç•¥ã€‚ç„¶åï¼Œç³»ç»Ÿé€šè¿‡èšç±»æ•°æ®æ¥è¯†åˆ«ä¸åŒç±»å‹çš„ç­–ç•¥ã€‚æœ€åï¼Œè®­ç»ƒä¸€ä¸ªåä½œæ™ºèƒ½ä½“æ¥ä¸ºæ¯ç§ç±»å‹çš„ç­–ç•¥ç”Ÿæˆä¼™ä¼´ï¼Œå¹¶æ ¹æ®è¿™äº›é›†ç¾¤è¿›è¡Œæ¡ä»¶åŒ–ã€‚ä¸ºäº†é€‚åº”ä¹‹å‰æœªè§è¿‡çš„ä¼™ä¼´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å›ºå®šä»½é¢åæ‚”æœ€å°åŒ–ç®—æ³•ï¼Œè¯¥ç®—æ³•èƒ½å¤ŸåŠ¨æ€æ¨æ–­å¹¶è°ƒæ•´ä¼°è®¡çš„ä¼™ä¼´ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨å®šåˆ¶çš„ã€Šç…®ç³Šäº†ï¼ˆOvercookedï¼‰ã€‹ç¯å¢ƒä¸­è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥ç¯å¢ƒæå‡ºäº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åˆä½œçƒ¹é¥ªä»»åŠ¡ï¼Œéœ€è¦å¹¿æ³›çš„ä¸åŒç­–ç•¥ä¹‹é—´å¼ºå¤§çš„åä½œèƒ½åŠ›ã€‚é€šè¿‡åœ¨çº¿ç”¨æˆ·ç ”ç©¶ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ™ºèƒ½ä½“åœ¨ä¸ä¸ç†Ÿæ‚‰çš„äººç±»ä¼™ä¼´åˆä½œæ—¶è¶…è¿‡äº†å½“å‰åŸºçº¿æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05244v1">PDF</a> Best Paper Award at the RSS 2025 Generative Models x HRI (GenAI-HRI)   Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼ºè°ƒåœ¨åä½œä»»åŠ¡ä¸­ï¼Œé€‚åº”é˜Ÿå‹çš„èƒ½åŠ›æ˜¯æˆåŠŸçš„å¿…è¦æ¡ä»¶ã€‚åœ¨äººæœºåä½œå›¢é˜Ÿä¸­ï¼Œé¢å¯¹å¤šæ ·åŒ–çš„é˜Ÿå‹ï¼Œæ™ºèƒ½ä½“éœ€è¦å®æ—¶è§‚å¯Ÿã€è¯†åˆ«å’Œé€‚åº”äººç±»ä¼™ä¼´ã€‚åœ¨æœ‰æ—¶é—´å‹åŠ›å’Œå¤æ‚æˆ˜ç•¥ç©ºé—´çš„ä»»åŠ¡ä¸­ï¼Œè¿™ä¸€è¦æ±‚æ›´å…·æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†TALENTSç­–ç•¥æ€§åä½œæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå­¦ä¹ è¡¨ç¤ºå’Œé€‚åº”å„ç§ä¼™ä¼´æˆ˜ç•¥ï¼Œå®ç°å³å…´å›¢é˜Ÿåˆä½œã€‚é€šè¿‡ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨å­¦ä¹ è½¨è¿¹æ•°æ®çš„æ½œåœ¨ç­–ç•¥ç©ºé—´ï¼Œè¯¥ç©ºé—´ä»£è¡¨æ™ºèƒ½ä½“é‡‡ç”¨çš„æˆ˜ç•¥ã€‚ç„¶åç³»ç»Ÿé€šè¿‡èšç±»æ•°æ®è¯†åˆ«ä¸åŒæˆ˜ç•¥ç±»å‹ã€‚æœ€åï¼Œè®­ç»ƒåä½œæ™ºèƒ½ä½“ä¸ºæ¯ç§ç­–ç•¥ç”Ÿæˆåˆä½œä¼™ä¼´ã€‚ä¸ºåº”å¯¹æœªè§è¿‡çš„ä¼™ä¼´ï¼Œç ”ç©¶ä½¿ç”¨å›ºå®šä»½é¢åæ‚”æœ€å°åŒ–ç®—æ³•åŠ¨æ€æ¨æ–­å’Œè°ƒæ•´ä¼°è®¡çš„ä¼™ä¼´æˆ˜ç•¥ã€‚åœ¨å®šåˆ¶çš„ã€ŠOvercookedã€‹ç¯å¢ƒä¸­è¯„ä¼°è¯¥æ–¹æ³•ï¼Œè¯¥ç¯å¢ƒè¦æ±‚åœ¨å„ç§å¯èƒ½æˆ˜ç•¥ä¸­å±•ç¤ºå¼ºæœ‰åŠ›çš„åè°ƒå’Œåˆä½œèƒ½åŠ›ã€‚é€šè¿‡åœ¨çº¿ç”¨æˆ·ç ”ç©¶ï¼Œæœ¬æ–‡è¯æ˜ç ”ç©¶æå‡ºçš„æ™ºèƒ½ä½“åœ¨ä¸ä¸ç†Ÿæ‚‰çš„äººç±»ä¼™ä¼´åä½œæ—¶è¡¨ç°ä¼˜äºå½“å‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ¨åä½œä»»åŠ¡ä¸­ï¼Œé€‚åº”é˜Ÿå‹çš„èƒ½åŠ›æ˜¯æˆåŠŸçš„é‡è¦å› ç´ ã€‚</li>
<li>é¢å¯¹å¤šæ ·åŒ–çš„é˜Ÿå‹ï¼Œæ™ºèƒ½ä½“éœ€è¦å®æ—¶è§‚å¯Ÿã€è¯†åˆ«å’Œé€‚åº”äººç±»ä¼™ä¼´çš„èƒ½åŠ›ã€‚</li>
<li>TALENTSç­–ç•¥æ€§åä½œæ¡†æ¶èƒ½å¤Ÿå­¦ä¹ è¡¨ç¤ºå’Œé€‚åº”å„ç§ä¼™ä¼´æˆ˜ç•¥ï¼Œå®ç°å³å…´å›¢é˜Ÿåˆä½œã€‚</li>
<li>ä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨å­¦ä¹ è½¨è¿¹æ•°æ®çš„æ½œåœ¨ç­–ç•¥ç©ºé—´ä»¥ä»£è¡¨æ™ºèƒ½ä½“çš„æˆ˜ç•¥ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡èšç±»æ•°æ®è¯†åˆ«ä¸åŒçš„æˆ˜ç•¥ç±»å‹ã€‚</li>
<li>åˆ©ç”¨å›ºå®šä»½é¢åæ‚”æœ€å°åŒ–ç®—æ³•æ¥åŠ¨æ€æ¨æ–­å’Œè°ƒæ•´ä¼™ä¼´æˆ˜ç•¥ä»¥é€‚åº”æœªçŸ¥ä¼™ä¼´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05244">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d829ca8afe7c895b90b2b1d05309b854.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3930a93ae6ea348ec04d3b5d16a5c6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-53b2c93c32c1478e1e16dd40f2382e57.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c70426f6427c5b5836bc0ae023d5f28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b8f94ddb88ed5a0cd56a56d2625b2ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79d10546fb13efdba04068eff252babd.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SciMaster-Towards-General-Purpose-Scientific-AI-Agents-Part-I-X-Master-as-Foundation-Can-We-Lead-on-Humanityâ€™s-Last-Exam"><a href="#SciMaster-Towards-General-Purpose-Scientific-AI-Agents-Part-I-X-Master-as-Foundation-Can-We-Lead-on-Humanityâ€™s-Last-Exam" class="headerlink" title="SciMaster: Towards General-Purpose Scientific AI Agents, Part I.   X-Master as Foundation: Can We Lead on Humanityâ€™s Last Exam?"></a>SciMaster: Towards General-Purpose Scientific AI Agents, Part I.   X-Master as Foundation: Can We Lead on Humanityâ€™s Last Exam?</h2><p><strong>Authors:Jingyi Chai, Shuo Tang, Rui Ye, Yuwen Du, Xinyu Zhu, Mengcheng Zhou, Yanfeng Wang, Weinan E, Siheng Chen</strong></p>
<p>The rapid advancements of AI agents have ignited the long-held ambition of leveraging them to accelerate scientific discovery. Achieving this goal requires a deep understanding of the frontiers of human knowledge. As such, Humanityâ€™s Last Exam (HLE) provides an exceptionally challenging touchstone for evaluating scientific AI agents. In this work, we aim to construct the foundational architecture for general-purpose agents and validate the capabilities through leading performance on HLE. To achieve this, we introduce X-Master, a tool-augmented reasoning agent designed to emulate human researchers by interacting flexibly with external tools during its reasoning process. This agent, guided by the conceptualization of code as an interaction language, can flexibly leverage built-in Python libraries and our customized tools to augment the reasoning. We further scale its capabilities through X-Masters, a scattered-and-stacked agentic workflow that systematically enhances breadth and depth of reasoning. Our open-source solution, X-Masters, sets a new state-of-the-art record on HLE with a score of 32.1%, surpassing OpenAIâ€™s and Googleâ€™s Deep Research (26.6% and 26.9%) and becoming the first to exceed the 30% threshold. This work allows us to gain a deeper understanding of complex task-solving and accumulates valuable experience that can inform future advancements, guiding subsequent model training. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ä»£ç†çš„å¿«é€Ÿè¿›æ­¥æ¿€å‘äº†äººä»¬é•¿æœŸä»¥æ¥åˆ©ç”¨å®ƒä»¬æ¥åŠ é€Ÿç§‘å­¦å‘ç°çš„æ„¿æœ›ã€‚å®ç°è¿™ä¸€ç›®æ ‡éœ€è¦å¯¹äººç±»çŸ¥è¯†çš„å‰æ²¿æœ‰æ·±åˆ»çš„ç†è§£ã€‚å› æ­¤ï¼ŒHumanityâ€™s Last Examï¼ˆHLEï¼‰ä¸ºè¯„ä¼°ç§‘å­¦äººå·¥æ™ºèƒ½ä»£ç†æä¾›äº†æå…·æŒ‘æˆ˜æ€§çš„è¯•é‡‘çŸ³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ„å»ºé€šç”¨ä»£ç†çš„åŸºç¡€æ¶æ„ï¼Œå¹¶é€šè¿‡åœ¨HLEä¸Šçš„é¢†å…ˆæ€§èƒ½æ¥éªŒè¯å…¶èƒ½åŠ›ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†X-Masterï¼Œè¿™æ˜¯ä¸€ä¸ªå·¥å…·å¢å¼ºå‹æ¨ç†ä»£ç†ï¼Œæ—¨åœ¨é€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­ä¸å¤–éƒ¨å·¥å…·çš„çµæ´»äº¤äº’æ¥æ¨¡æ‹Ÿäººç±»ç ”ç©¶è€…ã€‚è¯¥ä»£ç†ä»¥ä»£ç ä½œä¸ºäº¤äº’è¯­è¨€çš„ç†å¿µä¸ºæŒ‡å¯¼ï¼Œå¯ä»¥çµæ´»åœ°åˆ©ç”¨å†…ç½®çš„Pythonåº“å’Œæˆ‘ä»¬çš„å®šåˆ¶å·¥å…·æ¥å¢å¼ºæ¨ç†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡X-Mastersï¼ˆä¸€ç§åˆ†æ•£å †å çš„ä»£ç†å·¥ä½œæµç¨‹ï¼‰æ¥æ‰©å±•å…¶èƒ½åŠ›ï¼Œç³»ç»Ÿåœ°æé«˜æ¨ç†çš„å¹¿åº¦å’Œæ·±åº¦ã€‚æˆ‘ä»¬çš„å¼€æºè§£å†³æ–¹æ¡ˆX-Mastersåœ¨HLEä¸Šåˆ›ä¸‹äº†æ–°çš„æœ€é«˜çºªå½•ï¼Œå¾—åˆ†ä¸º32.1%ï¼Œè¶…è¶Šäº†OpenAIå’ŒGoogle Deep Researchï¼ˆåˆ†åˆ«ä¸º26.6%å’Œ26.9%ï¼‰ï¼Œå¹¶æˆä¸ºé¦–ä¸ªè¶…è¿‡30%é˜ˆå€¼çš„ç ”ç©¶ã€‚è¿™é¡¹å·¥ä½œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´æ·±å…¥åœ°äº†è§£å¤æ‚ä»»åŠ¡è§£å†³ï¼Œå¹¶ç§¯ç´¯äº†å®è´µçš„ç»éªŒï¼Œå¯ä»¥ä¸ºæœªæ¥çš„è¿›æ­¥æä¾›æŒ‡å¯¼ï¼Œä¸ºåç»­çš„æ¨¡å‹è®­ç»ƒæä¾›æŒ‡å¯¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05241v1">PDF</a> 12 pages, 7 figures</p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•æ¿€å‘äº†äººä»¬åˆ©ç”¨äººå·¥æ™ºèƒ½åŠ é€Ÿç§‘å­¦å‘ç°çš„é•¿æœŸæ„¿æœ›ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œéœ€è¦æ·±å…¥ç†è§£äººç±»çŸ¥è¯†çš„å‰æ²¿ã€‚Humanityâ€™s Last Examï¼ˆHLEï¼‰ä¸ºè¯„ä¼°ç§‘å­¦äººå·¥æ™ºèƒ½æä¾›äº†æå…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ã€‚æœ¬ç ”ç©¶æ—¨åœ¨æ„å»ºé€šç”¨æ™ºèƒ½ä½“çš„åŸºç¡€æ¶æ„ï¼Œå¹¶é€šè¿‡åœ¨HLEä¸Šçš„å“è¶Šè¡¨ç°éªŒè¯å…¶èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†X-Masterè¿™ä¸€å·¥å…·è¾…åŠ©æ¨ç†æ™ºèƒ½ä½“ï¼Œä»¥æ¨¡æ‹Ÿäººç±»ç ”ç©¶è€…é€šè¿‡å¤–éƒ¨å·¥å…·è¿›è¡Œçµæ´»äº¤äº’çš„æ¨ç†è¿‡ç¨‹ã€‚åœ¨ä»£ç è¢«è§†ä¸ºä¸€ç§äº¤äº’è¯­è¨€çš„ç†å¿µæŒ‡å¯¼ä¸‹ï¼Œè¯¥æ™ºèƒ½ä½“èƒ½å¤Ÿçµæ´»åˆ©ç”¨å†…ç½®Pythonåº“å’Œè‡ªå®šä¹‰å·¥å…·æ¥å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡X-Mastersï¼ˆä¸€ç§åˆ†æ•£å åŠ çš„æ™ºèƒ½ä½“å·¥ä½œæµç¨‹ï¼‰æ¥è¿›ä¸€æ­¥æ‰©å±•å…¶èƒ½åŠ›ï¼Œç³»ç»Ÿæå‡æ¨ç†çš„å¹¿åº¦å’Œæ·±åº¦ã€‚æˆ‘ä»¬çš„å¼€æºè§£å†³æ–¹æ¡ˆX-Mastersåœ¨HLEä¸Šåˆ›é€ äº†æ–°çš„æœ€é«˜çºªå½•ï¼Œå¾—åˆ†ä¸º32.1%ï¼Œè¶…è¶Šäº†OpenAIå’Œè°·æ­Œçš„æ·±åº¦ç ”ç©¶ï¼ˆåˆ†åˆ«ä¸º26.6%å’Œ26.9%ï¼‰ï¼Œæˆä¸ºé¦–ä¸ªçªç ´30%é˜ˆå€¼çš„æ™ºèƒ½ä½“ã€‚æœ¬ç ”ç©¶ä½¿æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£å¤æ‚ä»»åŠ¡è§£å†³ï¼Œå¹¶ç§¯ç´¯äº†å®è´µçš„ç»éªŒï¼Œå¯ä»¥ä¸ºæœªæ¥çš„è¿›æ­¥æä¾›æŒ‡å¯¼ï¼Œå¸®åŠ©åç»­æ¨¡å‹è®­ç»ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIçš„å‘å±•æ¿€å‘äº†å…¶åœ¨ç§‘å­¦å‘ç°é¢†åŸŸåº”ç”¨çš„æ½œåŠ›ã€‚</li>
<li>Humanityâ€™s Last Exam (HLE)æ˜¯è¯„ä¼°ç§‘å­¦äººå·¥æ™ºèƒ½èƒ½åŠ›çš„æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ã€‚</li>
<li>X-Masterå·¥å…·è¾…åŠ©æ¨ç†æ™ºèƒ½ä½“çš„è®¾è®¡æ—¨åœ¨æ¨¡æ‹Ÿäººç±»ç ”ç©¶è€…ä¸å·¥å…·çš„äº¤äº’è¿‡ç¨‹ã€‚</li>
<li>X-Masterå°†Pythonåº“å’Œè‡ªå®šä¹‰å·¥å…·ç›¸ç»“åˆä»¥å¢å¼ºå…¶æ¨ç†èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡X-Mastersç³»ç»Ÿï¼Œæ™ºèƒ½ä½“çš„æ¨ç†èƒ½åŠ›å’Œæ•ˆç‡å¾—åˆ°äº†è¿›ä¸€æ­¥æå‡ã€‚</li>
<li>X-Mastersåœ¨HLEä¸Šçš„å¾—åˆ†åˆ›ä¸‹äº†æ–°çš„çºªå½•ï¼Œè¾¾åˆ°äº†32.1%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05241">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b7510507065d11e6db55d0098605502b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7085df9138fb407d3f99c786bd5f9216.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af179349a5cc02d78e2b32e47f56e2c2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CREW-WILDFIRE-Benchmarking-Agentic-Multi-Agent-Collaborations-at-Scale"><a href="#CREW-WILDFIRE-Benchmarking-Agentic-Multi-Agent-Collaborations-at-Scale" class="headerlink" title="CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale"></a>CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale</h2><p><strong>Authors:Jonathan Hyun, Nicholas R Waytowich, Boyuan Chen</strong></p>
<p>Despite rapid progress in large language model (LLM)-based multi-agent systems, current benchmarks fall short in evaluating their scalability, robustness, and coordination capabilities in complex, dynamic, real-world tasks. Existing environments typically focus on small-scale, fully observable, or low-complexity domains, limiting their utility for developing and assessing next-generation multi-agent Agentic AI frameworks. We introduce CREW-Wildfire, an open-source benchmark designed to close this gap. Built atop the human-AI teaming CREW simulation platform, CREW-Wildfire offers procedurally generated wildfire response scenarios featuring large maps, heterogeneous agents, partial observability, stochastic dynamics, and long-horizon planning objectives. The environment supports both low-level control and high-level natural language interactions through modular Perception and Execution modules. We implement and evaluate several state-of-the-art LLM-based multi-agent Agentic AI frameworks, uncovering significant performance gaps that highlight the unsolved challenges in large-scale coordination, communication, spatial reasoning, and long-horizon planning under uncertainty. By providing more realistic complexity, scalable architecture, and behavioral evaluation metrics, CREW-Wildfire establishes a critical foundation for advancing research in scalable multi-agent Agentic intelligence. All code, environments, data, and baselines will be released to support future research in this emerging domain. </p>
<blockquote>
<p>å°½ç®¡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œä½†å½“å‰çš„æ ‡å‡†è¯„ä¼°æŒ‡æ ‡åœ¨è¯„ä¼°å…¶å¤„ç†å¤æ‚ã€åŠ¨æ€ã€çœŸå®ä»»åŠ¡çš„å¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œåè°ƒèƒ½åŠ›æ–¹é¢è¿˜å­˜åœ¨ä¸è¶³ã€‚ç°æœ‰çš„ç¯å¢ƒé€šå¸¸ä¸“æ³¨äºå°è§„æ¨¡ã€å®Œå…¨å¯è§‚å¯Ÿæˆ–ä½å¤æ‚åº¦çš„é¢†åŸŸï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å¼€å‘å’Œè¯„ä¼°ä¸‹ä¸€ä»£å¤šæ™ºèƒ½ä½“Agenticäººå·¥æ™ºèƒ½æ¡†æ¶æ–¹é¢çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬æ¨å‡ºäº†CREW-Wildfireï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¼¥è¡¥è¿™ä¸€å·®è·çš„å¼€æºåŸºå‡†æµ‹è¯•ã€‚CREW-Wildfireå»ºç«‹åœ¨äººç±»-äººå·¥æ™ºèƒ½å›¢é˜Ÿåä½œçš„CREWæ¨¡æ‹Ÿå¹³å°ä¹‹ä¸Šï¼Œæä¾›ç¨‹åºåŒ–ç”Ÿæˆçš„æ£®æ—ç«ç¾åº”å¯¹åœºæ™¯ï¼ŒåŒ…æ‹¬å¤§å‹åœ°å›¾ã€ä¸åŒæ™ºèƒ½ä½“ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ã€éšæœºåŠ¨æ€å’Œé•¿æœŸè§„åˆ’ç›®æ ‡ã€‚ç¯å¢ƒé€šè¿‡æ¨¡å—åŒ–çš„æ„ŸçŸ¥å’Œæ‰§è¡Œæ¨¡å—æ”¯æŒä½çº§æ§åˆ¶å’Œé«˜çº§è‡ªç„¶è¯­è¨€äº¤äº’ã€‚æˆ‘ä»¬å®ç°å¹¶è¯„ä¼°äº†å¤šç§å…ˆè¿›çš„åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“Agenticäººå·¥æ™ºèƒ½æ¡†æ¶ï¼Œæ­ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œè¿™äº›å·®è·çªæ˜¾å‡ºå¤§è§„æ¨¡åè°ƒã€é€šä¿¡ã€ç©ºé—´æ¨ç†å’Œä¸ç¡®å®šæ€§ä¸‹çš„é•¿æœŸè§„åˆ’æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡æä¾›æ›´ç°å®çš„å¤æ‚æ€§ã€å¯æ‰©å±•çš„æ¶æ„å’Œè¡Œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼ŒCREW-Wildfireä¸ºæ¨è¿›å¯æ‰©å±•å¤šæ™ºèƒ½ä½“Agenticæ™ºèƒ½çš„ç ”ç©¶å¥ å®šäº†é‡è¦åŸºç¡€ã€‚æ‰€æœ‰ä»£ç ã€ç¯å¢ƒã€æ•°æ®å’ŒåŸºå‡†æµ‹è¯•éƒ½å°†å‘å¸ƒï¼Œä»¥æ”¯æŒè¿™ä¸€æ–°å…´é¢†åŸŸæœªæ¥çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05178v1">PDF</a> Our project website is at:   <a target="_blank" rel="noopener" href="http://generalroboticslab.com/CREW-Wildfire">http://generalroboticslab.com/CREW-Wildfire</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>ä»‹ç»äº†ä¸€ä¸ªåä¸ºCREW-Wildfireçš„å¼€æ”¾æºä»£ç åŸºå‡†æµ‹è¯•ç¯å¢ƒï¼Œç”¨äºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤æ‚ã€åŠ¨æ€ã€çœŸå®ä»»åŠ¡ä¸­çš„å¯æ‰©å±•æ€§ã€ç¨³å¥æ€§å’Œåè°ƒèƒ½åŠ›ã€‚è¯¥ç¯å¢ƒæ¨¡æ‹Ÿäº†å¤§å‹åœ°å›¾ã€å¼‚æ„æ™ºèƒ½ä½“ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ã€éšæœºåŠ¨æ€å’Œé•¿æœŸè§„åˆ’ç›®æ ‡ç­‰åœºæ™¯ï¼Œæ”¯æŒä½çº§åˆ«æ§åˆ¶å’Œé«˜çº§è‡ªç„¶è¯­è¨€äº¤äº’ã€‚æ–‡ç« è¿˜å®ç°äº†å¤šä¸ªæœ€æ–°çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå¹¶åœ¨CREW-Wildfireç¯å¢ƒä¸­è¯„ä¼°äº†å®ƒä»¬çš„è¡¨ç°ï¼Œå¼ºè°ƒäº†åœ¨å¤§è§„æ¨¡åè°ƒã€æ²Ÿé€šã€ç©ºé—´æ¨ç†å’Œé•¿æœŸä¸ç¡®å®šæ€§è§„åˆ’ç­‰æ–¹é¢çš„æŒ‘æˆ˜ã€‚æ­¤ç¯å¢ƒä¸ºæœªæ¥ç ”ç©¶æä¾›äº†ä¸€ä¸ªå…³é”®åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å½“å‰åŸºå‡†æµ‹è¯•åœ¨è¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ—¶å­˜åœ¨å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚ã€åŠ¨æ€ã€çœŸå®ä»»åŠ¡çš„æ‰©å±•æ€§ã€ç¨³å¥æ€§å’Œåè°ƒèƒ½åŠ›æ–¹é¢ã€‚</li>
<li>CREW-Wildfireæ˜¯ä¸€ä¸ªæ–°çš„å¼€æ”¾æºä»£ç åŸºå‡†æµ‹è¯•ç¯å¢ƒï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç¯å¢ƒçš„å±€é™æ€§ï¼Œå¹¶æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å¤æ‚åœºæ™¯ã€‚</li>
<li>CREW-Wildfireç¯å¢ƒæ”¯æŒå¤§å‹åœ°å›¾ã€å¼‚æ„æ™ºèƒ½ä½“ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§ã€éšæœºåŠ¨æ€å’Œé•¿æœŸè§„åˆ’ç›®æ ‡ç­‰ç‰¹æ€§ã€‚</li>
<li>è¯¥ç¯å¢ƒé€šè¿‡æ¨¡å—åŒ–çš„æ„ŸçŸ¥å’Œæ‰§è¡Œæ¨¡å—æ”¯æŒä½çº§åˆ«æ§åˆ¶å’Œé«˜çº§è‡ªç„¶è¯­è¨€äº¤äº’ã€‚</li>
<li>åœ¨CREW-Wildfireç¯å¢ƒä¸­è¯„ä¼°äº†å¤šä¸ªæœ€æ–°çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå‘ç°å®ƒä»¬åœ¨å¤§å‹åè°ƒã€æ²Ÿé€šã€ç©ºé—´æ¨ç†å’Œé•¿æœŸä¸ç¡®å®šæ€§è§„åˆ’ç­‰æ–¹é¢å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ã€‚</li>
<li>CREW-Wildfireç¯å¢ƒçš„æ„å»ºä¸ºæœªæ¥ç ”ç©¶æä¾›äº†ä¸€ä¸ªå…³é”®åŸºç¡€ï¼ŒåŒ…æ‹¬æ›´ç°å®çš„å¤æ‚æ€§ã€å¯æ‰©å±•çš„æ¶æ„å’Œè¡Œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-21680c2a1c88b72ca715a9f4c9084147.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-984afccab52b84ffb08ad3765ebdde61.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f0b51f277906237d09bb5ed9fc9c6a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e91e5b306b5e621646eebe639299854.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Beyond-Features-How-Dataset-Design-Influences-Multi-Agent-Trajectory-Prediction-Performance"><a href="#Beyond-Features-How-Dataset-Design-Influences-Multi-Agent-Trajectory-Prediction-Performance" class="headerlink" title="Beyond Features: How Dataset Design Influences Multi-Agent Trajectory   Prediction Performance"></a>Beyond Features: How Dataset Design Influences Multi-Agent Trajectory   Prediction Performance</h2><p><strong>Authors:Tobias Demmler, Jakob HÃ¤ringer, Andreas Tamke, Thao Dang, Alexander Hegai, Lars Mikelsons</strong></p>
<p>Accurate trajectory prediction is critical for safe autonomous navigation, yet the impact of dataset design on model performance remains understudied. This work systematically examines how feature selection, cross-dataset transfer, and geographic diversity influence trajectory prediction accuracy in multi-agent settings. We evaluate a state-of-the-art model using our novel L4 Motion Forecasting dataset based on our own data recordings in Germany and the US. This includes enhanced map and agent features. We compare our dataset to the US-centric Argoverse 2 benchmark. First, we find that incorporating supplementary map and agent features unique to our dataset, yields no measurable improvement over baseline features, demonstrating that modern architectures do not need extensive feature sets for optimal performance. The limited features of public datasets are sufficient to capture convoluted interactions without added complexity. Second, we perform cross-dataset experiments to evaluate how effective domain knowledge can be transferred between datasets. Third, we group our dataset by country and check the knowledge transfer between different driving cultures. </p>
<blockquote>
<p>ç²¾ç¡®çš„è½¨è¿¹é¢„æµ‹å¯¹äºå®‰å…¨çš„è‡ªä¸»å¯¼èˆªè‡³å…³é‡è¦ï¼Œç„¶è€Œæ•°æ®é›†è®¾è®¡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚è¿™é¡¹å·¥ä½œç³»ç»Ÿåœ°ç ”ç©¶äº†ç‰¹å¾é€‰æ‹©ã€è·¨æ•°æ®é›†è½¬æ¢å’Œåœ°ç†å¤šæ ·æ€§åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å¯¹è½¨è¿¹é¢„æµ‹ç²¾åº¦çš„å½±å“ã€‚æˆ‘ä»¬ä½¿ç”¨åŸºäºåœ¨å¾·å›½å’Œç¾å›½è‡ªå·±å½•åˆ¶æ•°æ®çš„æ–°å‹L4è¿åŠ¨é¢„æµ‹æ•°æ®é›†ï¼Œå¯¹æœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚è¿™åŒ…æ‹¬å¢å¼ºçš„åœ°å›¾å’Œæ™ºèƒ½ä½“ç‰¹å¾ã€‚æˆ‘ä»¬å°†è‡ªå·±çš„æ•°æ®é›†ä¸ç¾å›½ä¸ºä¸»çš„Argoverse 2åŸºå‡†æ•°æ®é›†è¿›è¡Œäº†æ¯”è¾ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å‘ç°ï¼Œçº³å…¥æˆ‘ä»¬æ•°æ®é›†ä¸­ç‰¹æœ‰çš„é™„åŠ åœ°å›¾å’Œæ™ºèƒ½ä½“ç‰¹å¾ï¼Œå¹¶æ²¡æœ‰åœ¨åŸºçº¿ç‰¹å¾ä¸Šå–å¾—æ˜æ˜¾çš„æ”¹è¿›ï¼Œè¿™è¡¨æ˜ç°ä»£æ¶æ„ä¸éœ€è¦å¤§é‡çš„ç‰¹å¾é›†å³å¯å®ç°æœ€ä½³æ€§èƒ½ã€‚å…¬å…±æ•°æ®é›†çš„æœ‰é™ç‰¹å¾è¶³ä»¥æ•æ‰å¤æ‚çš„äº¤äº’ï¼Œè€Œä¸ä¼šå¢åŠ å¤æ‚æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è·¨æ•°æ®é›†å®éªŒï¼Œä»¥è¯„ä¼°ä¸åŒæ•°æ®é›†ä¹‹é—´è¿ç§»é¢†åŸŸçŸ¥è¯†çš„æœ‰æ•ˆæ€§ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬æŒ‰å›½å®¶åˆ†ç»„æ•°æ®é›†ï¼Œå¹¶æ£€æŸ¥ä¸åŒé©¾é©¶æ–‡åŒ–ä¹‹é—´çš„çŸ¥è¯†è¿ç§»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05098v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†æ•°æ®é›†è®¾è®¡å¯¹å¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼ŒåŒ…æ‹¬ç‰¹å¾é€‰æ‹©ã€è·¨æ•°æ®é›†è¿ç§»å’Œåœ°ç†å¤šæ ·æ€§ç­‰å› ç´ ã€‚é€šè¿‡å¯¹æ¯”æ–°å‹L4è¿åŠ¨é¢„æµ‹æ•°æ®é›†ä¸ç¾å›½Argoverse 2åŸºå‡†æ•°æ®é›†ï¼Œå‘ç°ç°ä»£æ¶æ„åœ¨ä¸éœ€è¦å¤§é‡ç‰¹å¾çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°æœ€ä½³æ€§èƒ½ï¼Œå…¬å¼€æ•°æ®é›†æœ‰é™çš„ç‰¹å¾è¶³ä»¥æ•æ‰å¤æ‚çš„äº¤äº’ä½œç”¨ã€‚æ­¤å¤–ï¼Œè¿˜è¿›è¡Œäº†è·¨æ•°æ®é›†å®éªŒæ¥è¯„ä¼°ä¸åŒé©¾é©¶æ–‡åŒ–é—´çš„çŸ¥è¯†è¿ç§»æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°æ®é›†è®¾è®¡å¯¹è½¨è¿¹é¢„æµ‹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚</li>
<li>ç‰¹å¾é€‰æ‹©æ˜¯å…¶ä¸­çš„å…³é”®å› ç´ ï¼Œä½†ç°ä»£æ¨¡å‹ä¸éœ€è¦å¤§é‡ç‰¹å¾ä¹Ÿèƒ½å®ç°æœ€ä½³æ€§èƒ½ã€‚</li>
<li>è·¨æ•°æ®é›†è¿ç§»çŸ¥è¯†åœ¨è½¨è¿¹é¢„æµ‹ä¸­æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ç­–ç•¥ã€‚</li>
<li>å…¬å¼€æ•°æ®é›†çš„æœ‰é™ç‰¹å¾è¶³ä»¥æ•æ‰å¤æ‚çš„äº¤äº’ä½œç”¨ã€‚</li>
<li>åœ°ç†å¤šæ ·æ€§å¯¹è½¨è¿¹é¢„æµ‹æ¨¡å‹æ€§èƒ½æœ‰å½±å“ã€‚</li>
<li>ä¸åŒé©¾é©¶æ–‡åŒ–é—´çš„çŸ¥è¯†è¿ç§»æ˜¯ä¸€ä¸ªå€¼å¾—ç ”ç©¶çš„è¯¾é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05098">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-25dc68e49749ea866e962d6026c0cfcd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f146e1a497409b844bd985387948f3f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f48ecfbe9bdb125e25d1dcf7e87754d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83036cc062a3b8b6e12515ab7905a1d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8d891542145fb53ef56b25ac4e989a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bddfd6afb9e0a8875de686289c5593a5.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MARBLE-A-Multi-Agent-Rule-Based-LLM-Reasoning-Engine-for-Accident-Severity-Prediction"><a href="#MARBLE-A-Multi-Agent-Rule-Based-LLM-Reasoning-Engine-for-Accident-Severity-Prediction" class="headerlink" title="MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident   Severity Prediction"></a>MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident   Severity Prediction</h2><p><strong>Authors:Kaleem Ullah Qasim, Jiashu Zhang</strong></p>
<p>Accident severity prediction plays a critical role in transportation safety systems but is a persistently difficult task due to incomplete data, strong feature dependencies, and severe class imbalance in which rare but high-severity cases are underrepresented and hard to detect. Existing methods often rely on monolithic models or black box prompting, which struggle to scale in noisy, real-world settings and offer limited interpretability. To address these challenges, we propose MARBLE a multiagent rule based LLM engine that decomposes the severity prediction task across a team of specialized reasoning agents, including an interchangeable ML-backed agent. Each agent focuses on a semantic subset of features (e.g., spatial, environmental, temporal), enabling scoped reasoning and modular prompting without the risk of prompt saturation. Predictions are coordinated through either rule-based or LLM-guided consensus mechanisms that account for class rarity and confidence dynamics. The system retains structured traces of agent-level reasoning and coordination outcomes, supporting in-depth interpretability and post-hoc performance diagnostics. Across both UK and US datasets, MARBLE consistently outperforms traditional machine learning classifiers and state-of-the-art (SOTA) prompt-based reasoning methods including Chain-of-Thought (CoT), Least-to-Most (L2M), and Tree-of-Thought (ToT) achieving nearly 90% accuracy where others plateau below 48%. This performance redefines the practical ceiling for accident severity classification under real world noise and extreme class imbalance. Our results position MARBLE as a generalizable and interpretable framework for reasoning under uncertainty in safety-critical applications. </p>
<blockquote>
<p>äº‹æ•…ä¸¥é‡ç¨‹åº¦é¢„æµ‹åœ¨äº¤é€šè¿è¾“å®‰å…¨ç³»ç»Ÿä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ï¼Œä½†ä¸€ç›´æ˜¯ä¸€é¡¹å›°éš¾çš„ä»»åŠ¡ï¼Œå› ä¸ºå­˜åœ¨æ•°æ®ä¸å®Œæ•´ã€ç‰¹å¾ä¾èµ–æ€§å¼ºä»¥åŠä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡ç­‰é—®é¢˜ï¼Œå…¶ä¸­ç½•è§ä½†é«˜ä¸¥é‡æ€§çš„æ¡ˆä¾‹è¢«ä½ä¼°ä¸”éš¾ä»¥æ£€æµ‹ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå•ä¸€æ¨¡å‹æˆ–é»‘ç®±æç¤ºï¼Œéš¾ä»¥åœ¨å˜ˆæ‚çš„ç°å®ç¯å¢ƒä¸­æ‰©å±•ï¼Œä¸”æä¾›æœ‰é™çš„è§£é‡Šæ€§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MARBLEï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šä»£ç†è§„åˆ™çš„LLMå¼•æ“ï¼Œå®ƒå°†ä¸¥é‡ç¨‹åº¦é¢„æµ‹ä»»åŠ¡åˆ†è§£åˆ°ä¸€ä¸ªä¸“ä¸šæ¨ç†ä»£ç†å›¢é˜Ÿä¸­ï¼ŒåŒ…æ‹¬ä¸€ä¸ªå¯äº’æ¢çš„MLæ”¯æŒä»£ç†ã€‚æ¯ä¸ªä»£ç†ä¸“æ³¨äºä¸€ç»„è¯­ä¹‰ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œç©ºé—´ã€ç¯å¢ƒã€æ—¶é—´ï¼‰ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œå±€éƒ¨æ¨ç†å’Œæ¨¡å—åŒ–æç¤ºï¼Œè€Œä¸ä¼šå¯¼è‡´æç¤ºé¥±å’Œçš„é£é™©ã€‚é¢„æµ‹æ˜¯é€šè¿‡åŸºäºè§„åˆ™æˆ–LLMå¼•å¯¼çš„å…±è¯†æœºåˆ¶è¿›è¡Œçš„ï¼Œè¿™äº›æœºåˆ¶ä¼šè€ƒè™‘ç±»åˆ«çš„ç¨€æœ‰æ€§å’Œä¿¡å¿ƒåŠ¨æ€å˜åŒ–ã€‚è¯¥ç³»ç»Ÿä¿ç•™äº†ä»£ç†çº§æ¨ç†å’Œåè°ƒç»“æœçš„ç»“æ„åŒ–è·Ÿè¸ªï¼Œæ”¯æŒæ·±å…¥çš„è§£é‡Šæ€§å’Œäº‹åæ€§èƒ½è¯Šæ–­ã€‚æ— è®ºæ˜¯åœ¨è‹±å›½å’Œç¾å›½çš„æ•°æ®é›†ä¸Šï¼ŒMARBLEéƒ½å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ åˆ†ç±»å™¨ä»¥åŠæœ€æ–°çš„åŸºäºæç¤ºçš„æ¨ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬æ€ç»´é“¾ï¼ˆCoTï¼‰ã€ä»æœ€å°‘åˆ°æœ€å¤šï¼ˆL2Mï¼‰å’Œæ€ç»´æ ‘ï¼ˆToTï¼‰ï¼Œè¾¾åˆ°è¿‘90%çš„å‡†ç¡®ç‡ï¼Œè€Œå…¶ä»–æ–¹æ³•åˆ™ä½äº48%ã€‚è¿™ä¸€æ€§èƒ½é‡æ–°å®šä¹‰äº†ç°å®ä¸–ç•Œå™ªå£°å’Œæç«¯ç±»åˆ«ä¸å¹³è¡¡æ¡ä»¶ä¸‹äº‹æ•…ä¸¥é‡ç¨‹åº¦åˆ†ç±»çš„å®é™…ä¸Šé™ã€‚æˆ‘ä»¬çš„ç»“æœå°†MARBLEå®šä½ä¸ºå®‰å…¨å…³é”®åº”ç”¨ä¸‹ä¸ç¡®å®šæ€§æ¨ç†çš„å¯æ¨å¹¿å’Œå¯è§£é‡Šæ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04893v1">PDF</a> 13 pages, 5 figures</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤šä¸»ä½“è§„åˆ™å¼LLMå¼•æ“ï¼Œç§°ä¸ºMARBLEï¼Œç”¨äºè§£å†³äº¤é€šæ„å¤–ä¸¥é‡æ€§é¢„æµ‹ä¸­çš„æŒ‘æˆ˜ã€‚å®ƒé€šè¿‡åˆ†è§£ä»»åŠ¡åˆ°å¤šä¸ªä¸“ä¸šæ¨ç†ä¸»ä½“æ¥åº”å¯¹æ•°æ®ä¸å®Œæ•´ã€ç‰¹å¾ä¾èµ–æ€§å¼ºä»¥åŠç±»åˆ«ä¸å¹³è¡¡ç­‰é—®é¢˜ã€‚MARBLEåœ¨å„æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨å’Œæœ€æ–°çš„æç¤ºå¼æ¨ç†æ–¹æ³•ï¼Œå®ç°äº†è¿‘90%çš„å‡†ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MARBLEæ˜¯ä¸€ä¸ªå¤šä¸»ä½“è§„åˆ™å¼LLMå¼•æ“ï¼Œä¸“é—¨ç”¨äºè§£å†³äº¤é€šæ„å¤–ä¸¥é‡æ€§é¢„æµ‹çš„æŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆ†è§£ä»»åŠ¡åˆ°å¤šä¸ªä¸“ä¸šæ¨ç†ä¸»ä½“ï¼Œå¤„ç†æ•°æ®ä¸å®Œæ•´ã€ç‰¹å¾ä¾èµ–æ€§å¼ºå’Œç±»åˆ«ä¸å¹³è¡¡ç­‰é—®é¢˜ã€‚</li>
<li>MARBLEé‡‡ç”¨æ¨¡å—åŒ–æç¤ºå’Œè§„åˆ™å…±è¯†æœºåˆ¶ï¼Œé¿å…æç¤ºé¥±å’Œï¼Œå¹¶è€ƒè™‘ç±»åˆ«ç¨€æœ‰æ€§å’Œç½®ä¿¡åº¦åŠ¨æ€ã€‚</li>
<li>MARBLEä¿ç•™äº†ä¸»ä½“çº§æ¨ç†å’Œåè°ƒç»“æœçš„ç»“æ„åŒ–ç—•è¿¹ï¼Œæ”¯æŒæ·±å…¥çš„å¯è§£é‡Šæ€§å’Œäº‹åæ€§èƒ½è¯Šæ–­ã€‚</li>
<li>åœ¨è‹±å›½å’Œç¾å›½çš„æ•°æ®é›†ä¸Šï¼ŒMARBLEçš„å‡†ç¡®ç‡æ¥è¿‘90%ï¼Œä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œæœ€æ–°æç¤ºå¼æ¨ç†æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04893">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7d32d02a531c68219a42c6b08ab4643e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d837d8426ecf240c33fa2107f9b39868.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e3c614ef1d62c8d2d072905c7897d89.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FurniMAS-Language-Guided-Furniture-Decoration-using-Multi-Agent-System"><a href="#FurniMAS-Language-Guided-Furniture-Decoration-using-Multi-Agent-System" class="headerlink" title="FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System"></a>FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System</h2><p><strong>Authors:Toan Nguyen, Tri Le, Quang Nguyen, Anh Nguyen</strong></p>
<p>Furniture decoration is an important task in various industrial applications. However, achieving a high-quality decorative result is often time-consuming and requires specialized artistic expertise. To tackle these challenges, we explore how multi-agent systems can assist in automating the decoration process. We propose FurniMAS, a multi-agent system for automatic furniture decoration. Specifically, given a human prompt and a household furniture item such as a working desk or a TV stand, our system suggests relevant assets with appropriate styles and materials, and arranges them on the item, ensuring the decorative result meets functionality, aesthetic, and ambiance preferences. FurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each fulfilling distinct roles in a typical decoration project. These agents collaborate through communication, logical reasoning, and validation to transform the requirements into the final outcome. Extensive experiments demonstrate that our FurniMAS significantly outperforms other baselines in generating high-quality 3D decor. </p>
<blockquote>
<p>å®¶å…·è£…é¥°åœ¨å„ç§å·¥ä¸šåº”ç”¨ä¸­æ˜¯ä¸€é¡¹é‡è¦çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ç°é«˜è´¨é‡çš„è£…é¥°æ•ˆæœå¾€å¾€å¾ˆè€—æ—¶ï¼Œå¹¶éœ€è¦ä¸“ä¸šçš„è‰ºæœ¯çŸ¥è¯†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¦‚ä½•ååŠ©è‡ªåŠ¨åŒ–è£…é¥°è¿‡ç¨‹ã€‚æˆ‘ä»¬æå‡ºäº†FurniMASï¼Œä¸€ä¸ªç”¨äºè‡ªåŠ¨å®¶å…·è£…é¥°çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªäººå·¥æç¤ºå’Œä¸€ä»¶å®¶å…·ç‰©å“ï¼ˆå¦‚åŠå…¬æ¡Œæˆ–ç”µè§†æ¶ï¼‰ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿä¼šå»ºè®®å…·æœ‰åˆé€‚é£æ ¼å’Œææ–™çš„ç›¸å…³èµ„äº§ï¼Œå¹¶å°†å®ƒä»¬æ’åˆ—åœ¨ç‰©å“ä¸Šï¼Œç¡®ä¿è£…é¥°ç»“æœæ»¡è¶³åŠŸèƒ½ã€ç¾å­¦å’Œæ°›å›´åå¥½ã€‚FurniMASæ±‡é›†äº†åŸºäºLLMå’ŒéLLMçš„æ™ºèƒ½ä½“æ··åˆå›¢é˜Ÿï¼Œåœ¨å…¸å‹çš„è£…é¥°é¡¹ç›®ä¸­ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ‰®æ¼”ç€ç‹¬ç‰¹çš„è§’è‰²ã€‚è¿™äº›æ™ºèƒ½ä½“é€šè¿‡æ²Ÿé€šã€é€»è¾‘æ¨ç†å’ŒéªŒè¯æ¥åä½œï¼Œå°†è¦æ±‚è½¬åŒ–ä¸ºæœ€ç»ˆæˆæœã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„FurniMASåœ¨ç”Ÿæˆé«˜è´¨é‡3Dè£…é¥°æ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04770v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å®¶å…·è£…é¥°åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„é‡è¦æ€§åŠå…¶æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚é«˜è´¨é‡è£…é¥°ç»“æœéœ€è¦è€—è´¹å¤§é‡æ—¶é—´å’Œä¸“ä¸šæŠ€èƒ½ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿâ€”â€”FurniMASï¼Œè¯¥ç³»ç»Ÿèƒ½è‡ªåŠ¨è¿›è¡Œå®¶å…·è£…é¥°ã€‚å€ŸåŠ©äººä¸ºæç¤ºå’Œå®¶åº­å®¶å…·é¡¹ç›®ï¼ˆå¦‚åŠå…¬æ¡Œæˆ–ç”µè§†æŸœç­‰ï¼‰ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®é£æ ¼å’Œææ–™ç­›é€‰ç›¸å…³èµ„äº§ï¼Œå¹¶å°†å…¶æ’åˆ—åœ¨ç‰©å“ä¸Šï¼Œç¡®ä¿è£…é¥°ç»“æœæ»¡è¶³åŠŸèƒ½ã€ç¾å­¦å’Œç¯å¢ƒåå¥½ã€‚æ­¤å¤–ï¼ŒFurniMASèåˆäº†åŸºäºLLMå’ŒéLLMçš„æ™ºèƒ½ä½“ï¼Œå®ƒä»¬åœ¨è£…é¥°é¡¹ç›®ä¸­æ‰®æ¼”ä¸åŒè§’è‰²ï¼Œé€šè¿‡æ²Ÿé€šã€é€»è¾‘æ¨ç†å’ŒéªŒè¯åä½œï¼Œå°†éœ€æ±‚è½¬åŒ–ä¸ºæœ€ç»ˆæˆæœã€‚å®éªŒè¯æ˜ï¼Œç›¸è¾ƒäºå…¶ä»–åŸºå‡†æµ‹è¯•ï¼ŒFurniMASåœ¨é«˜è´¨çš„ä¸‰ç»´è£…é¥°æ•ˆæœä¸Šè¡¨ç°æ›´ä¼˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å®¶å…·è£…é¥°åœ¨å·¥ä¸šåº”ç”¨ä¸­éå¸¸é‡è¦ï¼Œä½†å®ç°é«˜è´¨é‡è£…é¥°ç»“æœé€šå¸¸éœ€è¦å¤§é‡æ—¶é—´å’Œä¸“ä¸šæŠ€èƒ½ã€‚</li>
<li>FurniMASæ˜¯ä¸€ç§ç”¨äºè‡ªåŠ¨å®¶å…·è£…é¥°çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚</li>
<li>FurniMASé€šè¿‡äººä¸ºæç¤ºå’Œå®¶åº­å®¶å…·é¡¹ç›®ï¼Œå¦‚åŠå…¬æ¡Œæˆ–ç”µè§†æŸœç­‰æ¥å®ç°è‡ªåŠ¨è£…é¥°åŠŸèƒ½ã€‚å®ƒèƒ½å¤Ÿæ ¹æ®é£æ ¼å’Œææ–™å»ºè®®ç›¸å…³çš„èµ„äº§å¹¶æ’åˆ—å®ƒä»¬ä»¥è¾¾åˆ°è‰¯å¥½çš„è£…é¥°æ•ˆæœã€‚å®ƒä¸ä»…è€ƒè™‘äº†ç¾å­¦å’ŒåŠŸèƒ½è¦æ±‚ï¼Œè¿˜åŒ…æ‹¬ç¯å¢ƒåå¥½ã€‚ </li>
<li>FurniMASé›†æˆäº†åŸºäºLLMå’ŒéLLMçš„æ™ºèƒ½ä½“ï¼Œå®ƒä»¬åœ¨è£…é¥°é¡¹ç›®ä¸­æ‰®æ¼”ä¸åŒè§’è‰²å¹¶é€šè¿‡æ²Ÿé€šã€é€»è¾‘æ¨ç†å’ŒéªŒè¯åä½œå®Œæˆä»»åŠ¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04770">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b54dcd264589ab4cb127998eede017b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-41006ed275c2250935757f0ad363b42a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c5851f0c5fba71136fdaee90cf924fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ff713105766df50ab198bbd0037ceb33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78b1e4fb85921fcdf15145bb722e82d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a97f337833bc68a0d163fd6ca328b678.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Robustifying-3D-Perception-through-Least-Squares-Multi-Agent-Graphs-Object-Tracking"><a href="#Robustifying-3D-Perception-through-Least-Squares-Multi-Agent-Graphs-Object-Tracking" class="headerlink" title="Robustifying 3D Perception through Least-Squares Multi-Agent Graphs   Object Tracking"></a>Robustifying 3D Perception through Least-Squares Multi-Agent Graphs   Object Tracking</h2><p><strong>Authors:Maria Damanaki, Ioulia Kapsali, Nikos Piperigkos, Alexandros Gkillas, Aris S. Lalos</strong></p>
<p>The critical perception capabilities of EdgeAI systems, such as autonomous vehicles, are required to be resilient against adversarial threats, by enabling accurate identification and localization of multiple objects in the scene over time, mitigating their impact. Single-agent tracking offers resilience to adversarial attacks but lacks situational awareness, underscoring the need for multi-agent cooperation to enhance context understanding and robustness. This paper proposes a novel mitigation framework on 3D LiDAR scene against adversarial noise by tracking objects based on least-squares graph on multi-agent adversarial bounding boxes. Specifically, we employ the least-squares graph tool to reduce the induced positional error of each detectionâ€™s centroid utilizing overlapped bounding boxes on a fully connected graph via differential coordinates and anchor points. Hence, the multi-vehicle detections are fused and refined mitigating the adversarial impact, and associated with existing tracks in two stages performing tracking to further suppress the adversarial threat. An extensive evaluation study on the real-world V2V4Real dataset demonstrates that the proposed method significantly outperforms both state-of-the-art single and multi-agent tracking frameworks by up to 23.3% under challenging adversarial conditions, operating as a resilient approach without relying on additional defense mechanisms. </p>
<blockquote>
<p>è¾¹ç¼˜äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼‰çš„å…³é”®æ„ŸçŸ¥èƒ½åŠ›éœ€è¦å¯¹æŠ—æ¶æ„å¨èƒå…·æœ‰éŸ§æ€§ã€‚è¿™è¦æ±‚ç³»ç»Ÿèƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»ï¼Œå‡†ç¡®è¯†åˆ«å’Œå®šä½åœºæ™¯ä¸­çš„å¤šä¸ªç‰©ä½“ï¼Œå¹¶å‡è½»å…¶å½±å“ã€‚å•æ™ºèƒ½ä½“è·Ÿè¸ªå¯ä»¥æŠµå¾¡æ¶æ„æ”»å‡»ï¼Œä½†ç¼ºä¹æ€åŠ¿æ„ŸçŸ¥ï¼Œè¿™å¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“åˆä½œçš„éœ€è¦ï¼Œä»¥æé«˜ä¸Šä¸‹æ–‡ç†è§£å’Œç¨³å¥æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæœ€å°äºŒä¹˜å›¾çš„å¤šæ™ºèƒ½ä½“å¯¹æŠ—è¾¹ç•Œæ¡†è·Ÿè¸ªå¯¹è±¡çš„æ–°å‹ç¼“è§£æ¡†æ¶ï¼Œä»¥å¯¹æŠ—æ¿€å…‰é›·è¾¾åœºæ™¯ä¸­çš„å¯¹æŠ—æ€§å™ªå£°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨æœ€å°äºŒä¹˜å›¾å·¥å…·ï¼Œé€šè¿‡å·®å¼‚åæ ‡å’Œé”šç‚¹ï¼Œåˆ©ç”¨é‡å çš„è¾¹ç•Œæ¡†å‡å°‘æ¯ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡çš„ä¸­å¿ƒä½ç½®è¯¯å·®ã€‚å› æ­¤ï¼Œå¤šè½¦è¾†æ£€æµ‹è¢«èåˆå’Œç»†åŒ–ï¼Œå‡è½»äº†å¯¹æŠ—å½±å“ï¼Œå¹¶ä¸ç°æœ‰è½¨è¿¹ç›¸å…³è”ï¼Œåœ¨ä¸¤ä¸ªé˜¶æ®µæ‰§è¡Œè·Ÿè¸ªï¼Œä»¥è¿›ä¸€æ­¥æŠ‘åˆ¶å¯¹æŠ—å¨èƒã€‚åœ¨ç°å®ä¸–ç•Œä¸­çš„V2V4Realæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°ç ”ç©¶è¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯¹æŠ—æ¡ä»¶ä¸‹ï¼Œæ¯”æœ€å…ˆè¿›çš„å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“è·Ÿè¸ªæ¡†æ¶é«˜å‡º23.3%ï¼Œä½œä¸ºä¸€ç§ä¸éœ€è¦ä¾èµ–é¢å¤–é˜²å¾¡æœºåˆ¶çš„ç¨³å¥æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04762v1">PDF</a> 6 pages, 3 figures, 4 tables</p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¯¹æŠ—è¾¹ç•Œæ¡†çš„3Dæ¿€å…‰é›·è¾¾åœºæ™¯å¯¹æŠ—å™ªå£°çš„ç¼“è§£æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æœ€å°äºŒä¹˜å›¾å·¥å…·ï¼Œåˆ©ç”¨å…¨è¿æ¥å›¾ä¸Šçš„é‡å è¾¹ç•Œæ¡†ï¼Œé€šè¿‡å·®åˆ†åæ ‡å’Œé”šç‚¹å‡å°‘æ¯ä¸ªæ£€æµ‹å¯¹è±¡ä¸­å¿ƒçš„å®šä½è¯¯å·®ã€‚é€šè¿‡å¤šè½¦æ£€æµ‹èåˆå’Œç»†åŒ–ï¼Œç¼“è§£å¯¹æŠ—å½±å“ï¼Œå¹¶åœ¨ä¸¤ä¸ªé˜¶æ®µæ‰§è¡Œè·Ÿè¸ªå…³è”ç°æœ‰è½¨è¿¹ï¼Œè¿›ä¸€æ­¥æŠ‘åˆ¶å¯¹æŠ—å¨èƒã€‚åœ¨ç°å®ä¸–ç•ŒV2V4Realæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯¹æŠ—æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“è·Ÿè¸ªæ¡†æ¶ï¼Œä½œä¸ºä¸€ç§ä¸ä¾èµ–é¢å¤–é˜²å¾¡æœºåˆ¶çš„ç¨³å¥æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EdgeAIç³»ç»Ÿéœ€è¦å¯¹æŠ—æ¶æ„æ”»å‡»æ—¶çš„å…³é”®æ„ŸçŸ¥èƒ½åŠ›ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å’Œå®šä½åœºæ™¯ä¸­çš„å¤šä¸ªç‰©ä½“ã€‚</li>
<li>å•æ™ºèƒ½ä½“è·Ÿè¸ªè™½å¯¹å¯¹æŠ—æ€§æ”»å‡»æœ‰éŸ§æ€§ï¼Œä½†ç¼ºä¹æƒ…å¢ƒæ„è¯†ï¼Œå› æ­¤éœ€å¤šæ™ºèƒ½ä½“åˆä½œå¢å¼ºä¸Šä¸‹æ–‡ç†è§£å’Œç¨³å¥æ€§ã€‚</li>
<li>è®ºæ–‡æå‡ºåŸºäºæœ€å°äºŒä¹˜å›¾å’Œé‡å è¾¹ç•Œæ¡†çš„ç¼“è§£æ¡†æ¶ï¼Œå‡å°‘æ£€æµ‹å¯¹è±¡ä¸­å¿ƒçš„å®šä½è¯¯å·®ã€‚</li>
<li>è¯¥æ¡†æ¶èåˆå’Œç»†åŒ–å¤šè½¦æ£€æµ‹ï¼Œä»¥ç¼“è§£å¯¹æŠ—å½±å“ï¼Œå¹¶ä¸ç°æœ‰è½¨è¿¹è¿›è¡Œå…³è”ï¼Œè¿›ä¸€æ­¥æŠ‘åˆ¶å¯¹æŠ—å¨èƒã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•åœ¨ç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºå…¶ä»–è·Ÿè¸ªæ¡†æ¶ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰åœ¨æŒ‘æˆ˜æ€§å¯¹æŠ—æ¡ä»¶ä¸‹è¿ä½œçš„ç¨³å¥æ€§ï¼Œä¸ä¾èµ–é¢å¤–çš„é˜²å¾¡æœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04762">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cacb4d35f21d87e8958d72a09f26cd6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bcafd468befa518af46d8882362118e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcef72b82cff44b9e4180c5564fc12a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b8adf703d67655bb32e5e51ce2dd279.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-640fa1c488756879ad93a3b9a9c9fd6b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44f5351099e5cafac0ff0d72def8d7b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ccc4105398b87176b117bd8a6bab92b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Whoâ€™s-the-Mole-Modeling-and-Detecting-Intention-Hiding-Malicious-Agents-in-LLM-Based-Multi-Agent-Systems"><a href="#Whoâ€™s-the-Mole-Modeling-and-Detecting-Intention-Hiding-Malicious-Agents-in-LLM-Based-Multi-Agent-Systems" class="headerlink" title="Whoâ€™s the Mole? Modeling and Detecting Intention-Hiding Malicious Agents   in LLM-Based Multi-Agent Systems"></a>Whoâ€™s the Mole? Modeling and Detecting Intention-Hiding Malicious Agents   in LLM-Based Multi-Agent Systems</h2><p><strong>Authors:Yizhe Xie, Congcong Zhu, Xinyue Zhang, Minghao Wang, Chi Liu, Minglu Zhu, Tianqing Zhu</strong></p>
<p>Multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate remarkable capabilities in collaborative problem-solving. While LLM-MAS exhibit strong collaborative abilities, the security risks in their communication and coordination remain underexplored. We bridge this gap by systematically investigating intention-hiding threats in LLM-MAS, and design four representative attack paradigms that subtly disrupt task completion while maintaining high concealment. These attacks are evaluated in centralized, decentralized, and layered communication structures. Experiments conducted on six benchmark datasets, including MMLU, MMLU-Pro, HumanEval, GSM8K, arithmetic, and biographies, demonstrate that they exhibit strong disruptive capabilities. To identify these threats, we propose a psychology-based detection framework AgentXposed, which combines the HEXACO personality model with the Reid Technique, using progressive questionnaire inquiries and behavior-based monitoring. Experiments conducted on six types of attacks show that our detection framework effectively identifies all types of malicious behaviors. The detection rate for our intention-hiding attacks is slightly lower than that of the two baselines, Incorrect Fact Injection and Dark Traits Injection, demonstrating the effectiveness of intention concealment. Our findings reveal the structural and behavioral risks posed by intention-hiding attacks and offer valuable insights into securing LLM-based multi-agent systems through psychological perspectives, which contributes to a deeper understanding of multi-agent safety. The code and data are available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AgentXposed-F814">https://anonymous.4open.science/r/AgentXposed-F814</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆLLM-MASï¼‰åœ¨ååŒè§£å†³é—®é¢˜æ–¹é¢å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚å°½ç®¡LLM-MASè¡¨ç°å‡ºå¼ºå¤§çš„åä½œèƒ½åŠ›ï¼Œä½†å…¶åœ¨é€šä¿¡å’Œåè°ƒä¸­çš„å®‰å…¨é£é™©ä»ç„¶è¢«å¿½è§†ã€‚æˆ‘ä»¬é€šè¿‡ç³»ç»Ÿåœ°ç ”ç©¶LLM-MASä¸­çš„æ„å›¾éšè—å¨èƒæ¥å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œå¹¶è®¾è®¡äº†å››ç§å…·æœ‰ä»£è¡¨æ€§çš„æ”»å‡»æ¨¡å¼ï¼Œè¿™äº›æ”»å‡»æ¨¡å¼èƒ½å¤Ÿåœ¨å®Œæˆä»»åŠ¡çš„è¿‡ç¨‹ä¸­å¾®å¦™åœ°åˆ¶é€ å¹²æ‰°ï¼ŒåŒæ—¶ä¿æŒé«˜åº¦éšè”½æ€§ã€‚è¿™äº›æ”»å‡»åœ¨é›†ä¸­å¼ã€åˆ†æ•£å¼å’Œåˆ†å±‚é€šä¿¡ç»“æ„ä¸­éƒ½ç»è¿‡äº†è¯„ä¼°ã€‚åœ¨MMLUã€MMLU-Proã€HumanEvalã€GSM8Kã€ç®—æœ¯å’Œä¼ è®°ç­‰å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œå®ƒä»¬å…·æœ‰å¾ˆå¼ºçš„ç ´åæ€§èƒ½åŠ›ã€‚ä¸ºäº†è¯†åˆ«è¿™äº›å¨èƒï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¿ƒç†å­¦çš„æ£€æµ‹æ¡†æ¶AgentXposedï¼Œè¯¥æ¡†æ¶ç»“åˆäº†HEXACOäººæ ¼æ¨¡å‹å’Œé›·å¾·æŠ€æœ¯ï¼Œé‡‡ç”¨æ¸è¿›å¼é—®å·è°ƒæŸ¥å’Œè¡Œä¸ºç›‘æµ‹ã€‚å¯¹å…­ç§ç±»å‹çš„æ”»å‡»è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ£€æµ‹æ¡†æ¶æœ‰æ•ˆåœ°è¯†åˆ«å‡ºæ‰€æœ‰ç±»å‹çš„æ¶æ„è¡Œä¸ºã€‚å¯¹äºæ„å›¾éšè—æ”»å‡»çš„æ£€æµ‹ç‡ç•¥ä½äºå¦å¤–ä¸¤ä¸ªåŸºå‡†ï¼ˆå³é”™è¯¯äº‹å®æ³¨å…¥å’Œé»‘æš—ç‰¹è´¨æ³¨å…¥ï¼‰ï¼Œè¿™è¯æ˜äº†æ„å›¾éšè—çš„éšè”½æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†æ„å›¾éšè—æ”»å‡»çš„ç»“æ„å’Œè¡Œä¸ºé£é™©ï¼Œå¹¶é€šè¿‡å¿ƒç†å­¦è§†è§’ä¸ºåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æä¾›äº†å®è´µè§è§£ï¼Œæœ‰åŠ©äºæ›´æ·±å…¥åœ°äº†è§£å¤šæ™ºèƒ½ä½“çš„å®‰å…¨æ€§ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AgentXposed-F814%E5%A4%84%E8%8E%B7%E5%8F%96%E3%80%82">https://anonymous.4open.science/r/AgentXposed-F814å¤„è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04724v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤šä»£ç†ç³»ç»Ÿé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLM-MASï¼‰å±•ç°å‡ºå“è¶Šçš„ååŒè§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒLLM-MASåœ¨é€šä¿¡å’Œåè°ƒä¸­çš„å®‰å…¨é£é™©å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†LLM-MASä¸­çš„æ„å›¾éšè—å¨èƒï¼Œè®¾è®¡äº†å››ç§å…¸å‹çš„æ”»å‡»æ¨¡å¼ï¼Œè¿™äº›æ”»å‡»æ¨¡å¼å¯ä»¥åœ¨ä¸å¼•äººæ³¨ç›®çš„å‰æä¸‹ç ´åä»»åŠ¡å®Œæˆã€‚å®éªŒåœ¨å…­ç§æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œè¯æ˜è¿™äº›æ”»å‡»å…·æœ‰å¾ˆå¼ºçš„ç ´åæ€§ã€‚ä¸ºäº†è¯†åˆ«è¿™äº›å¨èƒï¼Œæœ¬ç ”ç©¶æå‡ºäº†åŸºäºå¿ƒç†å­¦çš„æ£€æµ‹æ¡†æ¶AgentXposedï¼Œç»“åˆHEXACOäººæ ¼æ¨¡å‹å’ŒReidæŠ€æœ¯ï¼Œé€šè¿‡æ¸è¿›å¼é—®å·è°ƒæŸ¥å’Œè¡Œä¸ºç›‘æµ‹æ¥è¯†åˆ«æ¶æ„è¡Œä¸ºã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ£€æµ‹æ¡†æ¶èƒ½æœ‰æ•ˆè¯†åˆ«å„ç§æ¶æ„æ”»å‡»ï¼Œä½†å¯¹æ„å›¾éšè—çš„æ”»å‡»çš„æ£€æµ‹ç‡ç•¥ä½äºä¸¤ä¸ªåŸºçº¿æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºæ„å›¾éšè—çš„æ•ˆåŠ›ã€‚æœ¬ç ”ç©¶æ­ç¤ºäº†æ„å›¾éšè—æ”»å‡»çš„ç»“æ„å’Œè¡Œä¸ºé£é™©ï¼Œå¹¶ä¸ºé€šè¿‡å¿ƒç†å­¦è§†è§’ä¿éšœLLM-MASæä¾›äº†å®è´µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-MASåœ¨ååŒè§£å†³é—®é¢˜ä¸­è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶é€šä¿¡å’Œåè°ƒä¸­çš„å®‰å…¨é£é™©å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚</li>
<li>å­˜åœ¨æ„å›¾éšè—çš„å¨èƒï¼Œå¯å¾®å¦™åœ°ç ´åä»»åŠ¡å®Œæˆï¼Œä¸”ä¸æ˜“è¢«å¯Ÿè§‰ã€‚</li>
<li>åœ¨å…­ç§æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¿™äº›æ„å›¾éšè—çš„æ”»å‡»å…·æœ‰å¾ˆå¼ºçš„ç ´åæ€§ã€‚</li>
<li>æå‡ºåŸºäºå¿ƒç†å­¦çš„æ£€æµ‹æ¡†æ¶AgentXposedï¼Œé€šè¿‡é—®å·è°ƒæŸ¥å’Œè¡Œä¸ºç›‘æµ‹è¯†åˆ«æ¶æ„è¡Œä¸ºã€‚</li>
<li>AgentXposedèƒ½æœ‰æ•ˆè¯†åˆ«å„ç§æ”»å‡»ï¼Œä½†å¯¹æ„å›¾éšè—çš„æ”»å‡»çš„æ£€æµ‹ç‡ç•¥ä½äºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶æ­ç¤ºäº†æ„å›¾éšè—æ”»å‡»çš„ç»“æ„å’Œè¡Œä¸ºé£é™©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04724">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-399f842256f0b605b7b258beb0c9a07a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c4f5090e7a73be2643bd6f01f7ef67d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-11ad25353a003a38c89eb4a7b0694a48.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf6646140f04a717079608407ae3ce39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50ff547bd3efc25d3dbc50f3a47565e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2527247a49da5bfc9bb378b7891590d7.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="LTMSformer-A-Local-Trend-Aware-Attention-and-Motion-State-Encoding-Transformer-for-Multi-Agent-Trajectory-Prediction"><a href="#LTMSformer-A-Local-Trend-Aware-Attention-and-Motion-State-Encoding-Transformer-for-Multi-Agent-Trajectory-Prediction" class="headerlink" title="LTMSformer: A Local Trend-Aware Attention and Motion State Encoding   Transformer for Multi-Agent Trajectory Prediction"></a>LTMSformer: A Local Trend-Aware Attention and Motion State Encoding   Transformer for Multi-Agent Trajectory Prediction</h2><p><strong>Authors:Yixin Yan, Yang Li, Yuanfan Wang, Xiaozhou Zhou, Beihao Xia, Manjiang Hu, Hongmao Qin</strong></p>
<p>It has been challenging to model the complex temporal-spatial dependencies between agents for trajectory prediction. As each state of an agent is closely related to the states of adjacent time steps, capturing the local temporal dependency is beneficial for prediction, while most studies often overlook it. Besides, learning the high-order motion state attributes is expected to enhance spatial interaction modeling, but it is rarely seen in previous works. To address this, we propose a lightweight framework, LTMSformer, to extract temporal-spatial interaction features for multi-modal trajectory prediction. Specifically, we introduce a Local Trend-Aware Attention mechanism to capture the local temporal dependency by leveraging a convolutional attention mechanism with hierarchical local time boxes. Next, to model the spatial interaction dependency, we build a Motion State Encoder to incorporate high-order motion state attributes, such as acceleration, jerk, heading, etc. To further refine the trajectory prediction, we propose a Lightweight Proposal Refinement Module that leverages Multi-Layer Perceptrons for trajectory embedding and generates the refined trajectories with fewer model parameters. Experiment results on the Argoverse 1 dataset demonstrate that our method outperforms the baseline HiVT-64, reducing the minADE by approximately 4.35%, the minFDE by 8.74%, and the MR by 20%. We also achieve higher accuracy than HiVT-128 with a 68% reduction in model size. </p>
<blockquote>
<p>å¯¹ä»£ç†ä¹‹é—´çš„å¤æ‚æ—¶ç©ºä¾èµ–æ€§è¿›è¡Œè½¨è¿¹é¢„æµ‹å»ºæ¨¡ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç”±äºä»£ç†çš„æ¯ä¸ªçŠ¶æ€éƒ½ä¸ç›¸é‚»æ—¶é—´æ­¥çš„çŠ¶æ€ç´§å¯†ç›¸å…³ï¼Œæ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–æ€§å¯¹é¢„æµ‹æ˜¯æœ‰ç›Šçš„ï¼Œä½†å¤§å¤šæ•°ç ”ç©¶å¾€å¾€å¿½ç•¥äº†è¿™ä¸€ç‚¹ã€‚æ­¤å¤–ï¼Œå­¦ä¹ é«˜é˜¶è¿åŠ¨çŠ¶æ€å±æ€§æœ‰æœ›å¢å¼ºç©ºé—´äº¤äº’å»ºæ¨¡ï¼Œä½†ä¹‹å‰åœ¨çš„å·¥ä½œä¸­å¾ˆå°‘è§åˆ°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„æ¡†æ¶LTMSformerï¼Œç”¨äºæå–æ—¶ç©ºäº¤äº’ç‰¹å¾è¿›è¡Œå¤šæ¨¡æ€è½¨è¿¹é¢„æµ‹ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å±€éƒ¨è¶‹åŠ¿æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡åˆ©ç”¨å…·æœ‰åˆ†å±‚å±€éƒ¨æ—¶é—´æ¡†çš„å·ç§¯æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–æ€§ã€‚æ¥ä¸‹æ¥ï¼Œä¸ºäº†å¯¹ç©ºé—´äº¤äº’ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªè¿åŠ¨çŠ¶æ€ç¼–ç å™¨ï¼Œä»¥èå…¥é«˜é˜¶è¿åŠ¨çŠ¶æ€å±æ€§ï¼Œå¦‚åŠ é€Ÿåº¦ã€æ€¥åŠ¨åº¦ã€æ–¹å‘ç­‰ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–è½¨è¿¹é¢„æµ‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè½»é‡çº§ææ¡ˆä¼˜åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨å¤šå±‚æ„ŸçŸ¥å™¨è¿›è¡Œè½¨è¿¹åµŒå…¥ï¼Œå¹¶ç”Ÿæˆå‚æ•°è¾ƒå°‘çš„ä¼˜åŒ–è½¨è¿¹ã€‚åœ¨Argoverse 1æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºåŸºçº¿HiVT-64ï¼ŒminADEé™ä½äº†çº¦4.35%ï¼ŒminFDEé™ä½äº†8.74%ï¼ŒMRé™ä½äº†20%ã€‚æˆ‘ä»¬è¿˜å®ç°äº†æ¯”HiVT-128æ›´é«˜çš„ç²¾åº¦ï¼Œå¹¶å®ç°äº†æ¨¡å‹ä½“ç§¯çš„68%ç¼©å‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04634v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æå‡ºLTMSformeræ¡†æ¶ç”¨äºå¤šæ¨¡æ€è½¨è¿¹é¢„æµ‹çš„æ—¶ç©ºäº¤äº’ç‰¹å¾æå–ã€‚åˆ©ç”¨å±€éƒ¨è¶‹åŠ¿æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–æ€§ï¼Œå¹¶æ„å»ºè¿åŠ¨çŠ¶æ€ç¼–ç å™¨æ¥æ¨¡æ‹Ÿç©ºé—´äº¤äº’ä¾èµ–æ€§ã€‚æ­¤å¤–ï¼Œæå‡ºè½»é‡çº§å»ºè®®ç»†åŒ–æ¨¡å—ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–è½¨è¿¹é¢„æµ‹ã€‚åœ¨Argoverse 1æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºåŸºçº¿HiVT-64ï¼Œå¹¶å®ç°äº†è¾ƒé«˜çš„å‡†ç¡®æ€§ï¼Œæ¨¡å‹å¤§å°å‡å°‘äº†68%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å»ºæ¨¡è½¨è¿¹é¢„æµ‹ä¸­çš„å¤æ‚æ—¶ç©ºä¾èµ–æ€§æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚</li>
<li>æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–æ€§å¯¹é¢„æµ‹æœ‰ç›Šï¼Œä½†å¤§å¤šæ•°ç ”ç©¶å¿½ç•¥äº†è¿™ä¸€ç‚¹ã€‚</li>
<li>é«˜é˜¶è¿åŠ¨çŠ¶æ€å±æ€§å­¦ä¹ å¯ä»¥å¢å¼ºç©ºé—´äº¤äº’å»ºæ¨¡ï¼Œä½†åœ¨ä»¥å‰çš„ç ”ç©¶ä¸­å¾ˆå°‘çœ‹åˆ°ã€‚</li>
<li>æå‡ºLTMSformeræ¡†æ¶ç”¨äºå¤šæ¨¡æ€è½¨è¿¹é¢„æµ‹ã€‚</li>
<li>å¼•å…¥å±€éƒ¨è¶‹åŠ¿æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–æ€§ã€‚</li>
<li>æ„å»ºè¿åŠ¨çŠ¶æ€ç¼–ç å™¨æ¥æ¨¡æ‹Ÿç©ºé—´äº¤äº’ä¾èµ–æ€§ï¼Œå¹¶çº³å…¥é«˜é˜¶è¿åŠ¨çŠ¶æ€å±æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04634">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7c1196fdcb2f40e2f3a9feecb227f86b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f4838e0b6f280656a3ce4f91cc31fdfd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-044fcccbbbc159edb01100d803bb350e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6f68f23754244f7b707d1b1e0ce99fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce5e8e5c17536848165eb424023b5f2d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Agentic-Distributed-Computing"><a href="#Agentic-Distributed-Computing" class="headerlink" title="Agentic Distributed Computing"></a>Agentic Distributed Computing</h2><p><strong>Authors:Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma</strong></p>
<p>The most celebrated and extensively studied model of distributed computing is the {\em message-passing model,} in which each vertex&#x2F;node of the (distributed network) graph corresponds to a static computational device that communicates with other devices through passing messages. In this paper, we consider the {\em agentic model} of distributed computing which extends the message-passing model in a new direction. In the agentic model, computational devices are modeled as relocatable or mobile computational devices (called agents in this paper), i.e., each vertex&#x2F;node of the graph serves as a container for the devices, and hence communicating with another device requires relocating to the same node. We study two fundamental graph level tasks, leader election, and minimum spanning tree, in the agentic model, which will enhance our understanding of distributed computation across paradigms. The objective is to minimize both time and memory complexities. Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others, and hence the time complexity can be measured in rounds. In this paper, we present two deterministic algorithms for leader election: one for the case of $k&lt;n$ and another for the case of $k&#x3D;n$, minimizing both time and memory complexities, where $k$ and $n$, respectively, are the number of agents and number of nodes of the graph. Using these leader election results, we develop deterministic algorithms for agents to construct a minimum spanning tree of the graph, minimizing both time and memory complexities. To the best of our knowledge, this is the first study of distributed graph level tasks in the agentic model with $k\leq n$. Previous studies only considered the case of $k&#x3D;n$. </p>
<blockquote>
<p>åˆ†å¸ƒå¼è®¡ç®—ä¸­æœ€ä¸ºè‘—åä¸”è¢«å¹¿æ³›ç ”ç©¶çš„æ¨¡å‹æ˜¯æ¶ˆæ¯ä¼ é€’æ¨¡å‹ï¼Œå…¶ä¸­ï¼ˆåˆ†å¸ƒå¼ç½‘ç»œï¼‰å›¾çš„æ¯ä¸ªé¡¶ç‚¹&#x2F;èŠ‚ç‚¹å¯¹åº”äºä¸€ä¸ªé™æ€è®¡ç®—è®¾å¤‡ï¼Œè¿™äº›è®¾å¤‡é€šè¿‡ä¼ é€’æ¶ˆæ¯è¿›è¡Œé€šä¿¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘åˆ†å¸ƒå¼è®¡ç®—çš„æ™ºèƒ½ä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨æ¶ˆæ¯ä¼ é€’æ¨¡å‹çš„åŸºç¡€ä¸Šå‘æ–°çš„æ–¹å‘æ‰©å±•ã€‚åœ¨æ™ºèƒ½ä½“æ¨¡å‹ä¸­ï¼Œè®¡ç®—è®¾å¤‡è¢«å»ºæ¨¡ä¸ºå¯ç§»åŠ¨çš„è®¡ç®—è®¾å¤‡ï¼ˆæœ¬æ–‡ç§°ä¸ºä»£ç†ï¼‰ï¼Œå³å›¾çš„æ¯ä¸ªé¡¶ç‚¹&#x2F;èŠ‚ç‚¹ä½œä¸ºè®¾å¤‡çš„å®¹å™¨ï¼Œå› æ­¤ä¸å…¶ä»–è®¾å¤‡é€šä¿¡éœ€è¦è¿ç§»è‡³åŒä¸€èŠ‚ç‚¹ã€‚æˆ‘ä»¬ç ”ç©¶æ™ºèƒ½ä½“æ¨¡å‹ä¸­çš„ä¸¤ä¸ªåŸºæœ¬çš„å›¾çº§åˆ«ä»»åŠ¡ï¼Œå³é¢†å¯¼é€‰ä¸¾å’Œæœ€å°ç”Ÿæˆæ ‘ï¼Œè¿™å°†å¢å¼ºæˆ‘ä»¬å¯¹ä¸åŒèŒƒå¼ä¸‹åˆ†å¸ƒå¼è®¡ç®—çš„ç†è§£ã€‚ç›®æ ‡æ˜¯æœ€å¤§é™åº¦åœ°å‡å°‘æ—¶é—´å’Œå†…å­˜å¤æ‚æ€§ã€‚æ ¹æ®æ–‡çŒ®ï¼Œæˆ‘ä»¬è€ƒè™‘åŒæ­¥è®¾ç½®ï¼Œå…¶ä¸­æ¯ä¸ªæ™ºèƒ½ä½“ä¸å…¶ä»–æ™ºèƒ½ä½“åŒæ­¥æ‰§è¡Œæ“ä½œï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦å¯ä»¥æŒ‰è½®æ•°æ¥è¡¡é‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸ºé¢†å¯¼é€‰ä¸¾æå‡ºäº†ä¸¤ä¸ªç¡®å®šæ€§ç®—æ³•ï¼šä¸€ä¸ªç”¨äºk &lt; nçš„æƒ…å†µï¼Œå¦ä¸€ä¸ªç”¨äºk &#x3D; nçš„æƒ…å†µï¼Œè¿™ä¸¤ç§æƒ…å†µéƒ½èƒ½æœ€å¤§é™åº¦åœ°å‡å°‘æ—¶é—´å’Œå†…å­˜å¤æ‚æ€§ï¼Œå…¶ä¸­kå’Œnåˆ†åˆ«æ˜¯æ™ºèƒ½ä½“å’Œå›¾çš„èŠ‚ç‚¹æ•°ã€‚åˆ©ç”¨è¿™äº›é¢†å¯¼é€‰ä¸¾çš„ç»“æœï¼Œæˆ‘ä»¬ä¸ºæ™ºèƒ½ä½“å¼€å‘å‡ºäº†æ„å»ºå›¾çš„æœ€å°ç”Ÿæˆæ ‘çš„ç¡®å®šæ€§ç®—æ³•ï¼ŒåŒæ—¶æœ€å°åŒ–æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨æ™ºèƒ½ä½“æ¨¡å‹ä¸­ç ”ç©¶kâ‰¤nçš„åˆ†å¸ƒå¼å›¾çº§åˆ«ä»»åŠ¡ã€‚ä¹‹å‰çš„ç ”ç©¶åªè€ƒè™‘äº†k &#x3D; nçš„æƒ…å†µã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04459v1">PDF</a> 42 pages, 3 figures,3 tables, 8 pseudocodes; some overlaps with   arXiv:2403.13716v2</p>
<p><strong>Summary</strong><br>     è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§æ–°å‹çš„åˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹â€”â€”agenticæ¨¡å‹ã€‚è¯¥æ¨¡å‹æ‰©å±•äº†æ¶ˆæ¯ä¼ é€’æ¨¡å‹ï¼Œå°†è®¡ç®—è®¾å¤‡å»ºæ¨¡ä¸ºå¯ç§»åŠ¨çš„è£…ç½®ï¼ˆç§°ä¸ºagentï¼‰ã€‚æ–‡ç« ç ”ç©¶äº†agenticæ¨¡å‹ä¸­çš„ä¸¤ä¸ªåŸºæœ¬å›¾å½¢çº§ä»»åŠ¡ï¼Œå³é¢†å¯¼é€‰ä¸¾å’Œæœ€å°ç”Ÿæˆæ ‘ï¼Œæ—¨åœ¨æœ€å°åŒ–æ—¶é—´å’Œå†…å­˜å¤æ‚æ€§ã€‚æ–‡ç« è¿˜ä»‹ç»äº†ä¸¤ç§ç”¨äºé¢†å¯¼é€‰ä¸¾çš„ç¡®å®šæ€§ç®—æ³•ï¼Œå¹¶åŸºäºé¢†å¯¼é€‰ä¸¾ç»“æœå¼€å‘äº†æ„å»ºå›¾å½¢æœ€å°ç”Ÿæˆæ ‘çš„ç¡®å®šæ€§ç®—æ³•ã€‚è¿™æ˜¯å…³äºagenticæ¨¡å‹ä¸­kâ‰¤næƒ…å†µä¸‹åˆ†å¸ƒå¼å›¾å½¢çº§åˆ«ä»»åŠ¡çš„é¦–é¡¹ç ”ç©¶ï¼Œä¹‹å‰çš„ç ”ç©¶ä»…è€ƒè™‘k&#x3D;nçš„æƒ…å†µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agenticæ¨¡å‹æ˜¯åˆ†å¸ƒå¼è®¡ç®—çš„ä¸€ç§æ–°å‹æ¨¡å‹ï¼Œå°†è®¡ç®—è®¾å¤‡å»ºæ¨¡ä¸ºå¯ç§»åŠ¨çš„è£…ç½®ï¼ˆagentsï¼‰ã€‚</li>
<li>è¯¥æ¨¡å‹æ‰©å±•äº†æ¶ˆæ¯ä¼ é€’æ¨¡å‹ï¼Œæ³¨é‡ç ”ç©¶å›¾å½¢çº§åˆ«çš„ä»»åŠ¡ã€‚</li>
<li>æ–‡ç« ç ”ç©¶äº†ä¸¤ä¸ªåŸºæœ¬å›¾å½¢çº§åˆ«ä»»åŠ¡ï¼šé¢†å¯¼é€‰ä¸¾å’Œæœ€å°ç”Ÿæˆæ ‘ã€‚</li>
<li>ç ”ç©¶çš„ç›®çš„æ˜¯æœ€å°åŒ–æ—¶é—´å’Œå†…å­˜å¤æ‚æ€§ã€‚</li>
<li>ä»‹ç»äº†ä¸¤ç§ç”¨äºé¢†å¯¼é€‰ä¸¾çš„ç¡®å®šæ€§ç®—æ³•ï¼Œåˆ†åˆ«é’ˆå¯¹k&lt;nå’Œk&#x3D;nçš„æƒ…å†µã€‚</li>
<li>åŸºäºé¢†å¯¼é€‰ä¸¾ç»“æœï¼Œå¼€å‘äº†æ„å»ºå›¾å½¢æœ€å°ç”Ÿæˆæ ‘çš„ç¡®å®šæ€§ç®—æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04459">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a32b96413ab96f4d9055b6fdf70fae1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8475facda76e44237585426373d1959a.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Multimedia-Verification-Through-Multi-Agent-Deep-Research-Multimodal-Large-Language-Models"><a href="#Multimedia-Verification-Through-Multi-Agent-Deep-Research-Multimodal-Large-Language-Models" class="headerlink" title="Multimedia Verification Through Multi-Agent Deep Research Multimodal   Large Language Models"></a>Multimedia Verification Through Multi-Agent Deep Research Multimodal   Large Language Models</h2><p><strong>Authors:Huy Hoan Le, Van Sy Thinh Nguyen, Thi Le Chi Dang, Vo Thanh Khang Nguyen, Truong Thanh Hung Nguyen, Hung Cao</strong></p>
<p>This paper presents our submission to the ACMMM25 - Grand Challenge on Multimedia Verification. We developed a multi-agent verification system that combines Multimodal Large Language Models (MLLMs) with specialized verification tools to detect multimedia misinformation. Our system operates through six stages: raw data processing, planning, information extraction, deep research, evidence collection, and report generation. The core Deep Researcher Agent employs four tools: reverse image search, metadata analysis, fact-checking databases, and verified news processing that extracts spatial, temporal, attribution, and motivational context. We demonstrate our approach on a challenge dataset sample involving complex multimedia content. Our system successfully verified content authenticity, extracted precise geolocation and timing information, and traced source attribution across multiple platforms, effectively addressing real-world multimedia verification scenarios. </p>
<blockquote>
<p>æœ¬æ–‡æ˜¯æˆ‘ä»¬ä¸ºACMMM25å¤šåª’ä½“éªŒè¯æŒ‘æˆ˜èµ›æäº¤çš„è®ºæ–‡ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¤šæ™ºèƒ½ä½“éªŒè¯ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å’Œä¸“ä¸šçš„éªŒè¯å·¥å…·æ¥æ£€æµ‹å¤šåª’ä½“è™šå‡ä¿¡æ¯ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé€šè¿‡å…­ä¸ªé˜¶æ®µè¿›è¡Œæ“ä½œï¼šåŸå§‹æ•°æ®å¤„ç†ã€è§„åˆ’ã€ä¿¡æ¯æå–ã€æ·±å…¥ç ”ç©¶ã€è¯æ®æ”¶é›†å’ŒæŠ¥å‘Šç”Ÿæˆã€‚æ ¸å¿ƒæ·±åº¦ç ”ç©¶å‘˜æ™ºèƒ½ä½“é‡‡ç”¨å››ç§å·¥å…·ï¼šåå‘å›¾åƒæœç´¢ã€å…ƒæ•°æ®åˆ†æã€äº‹å®æ ¸æŸ¥æ•°æ®åº“å’Œç»è¿‡éªŒè¯çš„æ–°é—»å¤„ç†ï¼Œç”¨äºæå–ç©ºé—´ã€æ—¶é—´ã€å½’å±å’ŒåŠ¨æœºä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æˆ‘ä»¬åœ¨æ¶‰åŠå¤æ‚å¤šåª’ä½“å†…å®¹çš„æŒ‘æˆ˜æ•°æ®é›†æ ·æœ¬ä¸Šå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç³»ç»ŸæˆåŠŸéªŒè¯äº†å†…å®¹çš„çœŸå®æ€§ï¼Œæå–äº†ç²¾ç¡®çš„ä½ç½®å’Œæ—¶é—´ä¿¡æ¯ï¼Œå¹¶åœ¨å¤šä¸ªå¹³å°ä¸Šè¿½è¸ªäº†æ¥æºå½’å±ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ç°å®ä¸–ç•Œçš„å¤šåª’ä½“éªŒè¯åœºæ™¯é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04410v1">PDF</a> 33rd ACM International Conference on Multimedia (MMâ€™25) Grand   Challenge on Multimedia Verification</p>
<p><strong>Summary</strong><br>å¤šåª’ä½“éªŒè¯æ˜¯ä¸€é¡¹é‡è¦çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡ä»‹ç»äº†æˆ‘ä»¬åœ¨ACMMM25å¤šåª’ä½“éªŒè¯å¤§èµ›ä¸­çš„æäº¤ä½œå“ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¤šä»£ç†éªŒè¯ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸“ç”¨éªŒè¯å·¥å…·æ¥æ£€æµ‹å¤šåª’ä½“è™šå‡ä¿¡æ¯ã€‚é€šè¿‡å…­ä¸ªé˜¶æ®µæ“ä½œï¼šåŸå§‹æ•°æ®å¤„ç†ã€è§„åˆ’ã€ä¿¡æ¯æå–ã€æ·±åº¦ç ”ç©¶ã€è¯æ®æ”¶é›†å’ŒæŠ¥å‘Šç”Ÿæˆã€‚æ ¸å¿ƒæ·±åº¦ç ”ç©¶å‘˜ä»£ç†é‡‡ç”¨å››ç§å·¥å…·ï¼šåå‘å›¾åƒæœç´¢ã€å…ƒæ•°æ®åˆ†æã€äº‹å®æ ¸æŸ¥æ•°æ®åº“å’Œç»è¿‡éªŒè¯çš„æ–°é—»å¤„ç†ï¼Œæå–ç©ºé—´ã€æ—¶é—´ã€å½’å±å’ŒåŠ¨æœºä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨åŒ…å«å¤æ‚å¤šåª’ä½“å†…å®¹çš„æŒ‘æˆ˜æ•°æ®é›†æ ·æœ¬ä¸Šå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒæˆåŠŸéªŒè¯äº†å†…å®¹çœŸå®æ€§ï¼Œæå–äº†ç²¾ç¡®çš„ä½ç½®å’Œæ—¶é—´ä¿¡æ¯ï¼Œå¹¶è·¨å¤šä¸ªå¹³å°è¿½è¸ªäº†æ¥æºå½’å±ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ç°å®ä¸–ç•Œçš„å¤šåª’ä½“éªŒè¯åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æäº¤ä½œå“ä¸“æ³¨äºACMMM25å¤šåª’ä½“éªŒè¯å¤§èµ›ï¼Œæ—¨åœ¨è§£å†³å¤šåª’ä½“ä¿¡æ¯çœŸå®æ€§é—®é¢˜ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§å¤šä»£ç†éªŒè¯ç³»ç»Ÿï¼Œç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸“ç”¨éªŒè¯å·¥å…·ã€‚</li>
<li>ç³»ç»ŸåŒ…æ‹¬å…­ä¸ªæ“ä½œé˜¶æ®µï¼šä»åŸå§‹æ•°æ®å¤„ç†åˆ°æŠ¥å‘Šç”Ÿæˆã€‚</li>
<li>æ ¸å¿ƒæ·±åº¦ç ”ç©¶å‘˜ä»£ç†ä½¿ç”¨å››ç§å·¥å…·è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼ŒåŒ…æ‹¬åå‘å›¾åƒæœç´¢ã€å…ƒæ•°æ®åˆ†æã€äº‹å®æ ¸æŸ¥æ•°æ®åº“å’ŒéªŒè¯æ–°é—»å¤„ç†ã€‚</li>
<li>è¯¥ç³»ç»Ÿèƒ½å¤ŸéªŒè¯å†…å®¹çœŸå®æ€§ï¼Œæå–ç²¾ç¡®çš„ä½ç½®å’Œæ—¶é—´ä¿¡æ¯ã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿè·¨å¤šä¸ªå¹³å°è¿½è¸ªæ¥æºå½’å±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04410">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9e527aa30c2b80fedade5eebd60396d0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cd7f1fe401a9543555bdc67265ee8517.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c156403a6636f7f241d794bb3811d30d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-858d3628444999c637c1bbafb5cfe59f.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SRefiner-Soft-Braid-Attention-for-Multi-Agent-Trajectory-Refinement"><a href="#SRefiner-Soft-Braid-Attention-for-Multi-Agent-Trajectory-Refinement" class="headerlink" title="SRefiner: Soft-Braid Attention for Multi-Agent Trajectory Refinement"></a>SRefiner: Soft-Braid Attention for Multi-Agent Trajectory Refinement</h2><p><strong>Authors:Liwen Xiao, Zhiyu Pan, Zhicheng Wang, Zhiguo Cao, Wei Li</strong></p>
<p>Accurate prediction of multi-agent future trajectories is crucial for autonomous driving systems to make safe and efficient decisions. Trajectory refinement has emerged as a key strategy to enhance prediction accuracy. However, existing refinement methods often overlook the topological relationships between trajectories, which are vital for improving prediction precision. Inspired by braid theory, we propose a novel trajectory refinement approach, Soft-Braid Refiner (SRefiner), guided by the soft-braid topological structure of trajectories using Soft-Braid Attention. Soft-Braid Attention captures spatio-temporal topological relationships between trajectories by considering both spatial proximity and vehicle motion states at &#96;&#96;soft intersection pointsâ€. Additionally, we extend this approach to model interactions between trajectories and lanes, further improving the prediction accuracy. SRefiner is a multi-iteration, multi-agent framework that iteratively refines trajectories, incorporating topological information to enhance interactions within traffic scenarios. SRefiner achieves significant performance improvements over four baseline methods across two datasets, establishing a new state-of-the-art in trajectory refinement. Code is here <a target="_blank" rel="noopener" href="https://github.com/Liwen-Xiao/SRefiner">https://github.com/Liwen-Xiao/SRefiner</a>. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“æœªæ¥è½¨è¿¹çš„ç²¾ç¡®é¢„æµ‹å¯¹äºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåšå‡ºå®‰å…¨å’Œé«˜æ•ˆçš„å†³ç­–è‡³å…³é‡è¦ã€‚è½¨è¿¹ä¼˜åŒ–å·²æˆä¸ºæé«˜é¢„æµ‹å‡†ç¡®æ€§çš„å…³é”®ç­–ç•¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¼˜åŒ–æ–¹æ³•å¾€å¾€å¿½è§†äº†è½¨è¿¹ä¹‹é—´çš„æ‹“æ‰‘å…³ç³»ï¼Œè¿™å¯¹äºæé«˜é¢„æµ‹ç²¾åº¦è‡³å…³é‡è¦ã€‚å—è¾«çŠ¶ç†è®ºå¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è½¨è¿¹ä¼˜åŒ–æ–¹æ³•â€”â€”Soft-Braid Refinerï¼ˆSRefinerï¼‰ã€‚è¯¥æ–¹æ³•ä»¥è½¨è¿¹çš„è½¯è¾«æ‹“æ‰‘ç»“æ„ä¸ºæŒ‡å¯¼ï¼Œä½¿ç”¨Soft-Braid Attentionã€‚Soft-Braid Attentioné€šè¿‡è€ƒè™‘â€œè½¯äº¤ç‚¹â€å¤„çš„ç©ºé—´æ¥è¿‘åº¦å’Œè½¦è¾†è¿åŠ¨çŠ¶æ€ï¼Œæ•æ‰è½¨è¿¹ä¹‹é—´çš„æ—¶ç©ºæ‹“æ‰‘å…³ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ­¤æ–¹æ³•æ‰©å±•ä¸ºå¯¹è½¨è¿¹å’Œè½¦é“ä¹‹é—´çš„äº¤äº’è¿›è¡Œå»ºæ¨¡ï¼Œè¿›ä¸€æ­¥æé«˜é¢„æµ‹ç²¾åº¦ã€‚SRefineræ˜¯ä¸€ä¸ªå¤šè¿­ä»£ã€å¤šæ™ºèƒ½ä½“çš„æ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–è½¨è¿¹ï¼Œèå…¥æ‹“æ‰‘ä¿¡æ¯ä»¥å¢å¼ºäº¤é€šåœºæ™¯ä¸­çš„äº¤äº’ã€‚SRefineråœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å››ä¸ªåŸºå‡†æ–¹æ³•ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼Œåœ¨è½¨è¿¹ä¼˜åŒ–æ–¹é¢å»ºç«‹äº†æœ€æ–°æŠ€æœ¯ã€‚ä»£ç è¯¦è§ï¼š<a target="_blank" rel="noopener" href="https://github.com/Liwen-Xiao/SRefiner">é“¾æ¥åœ°å€</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04263v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè¾«çŠ¶ç†è®ºå¯å‘ï¼Œæå‡ºä¸€ç§æ–°å‹è½¨è¿¹ä¼˜åŒ–æ–¹æ³•â€”â€”Soft-Braid Refinerï¼ˆSRefinerï¼‰ï¼Œè¯¥æ–¹æ³•é€šè¿‡Soft-Braid Attentionæ•æ‰è½¨è¿¹çš„æ—¶ç©ºæ‹“æ‰‘ç»“æ„å…³ç³»ï¼Œè€ƒè™‘è½¨è¿¹é—´çš„ç©ºé—´æ¥è¿‘ç¨‹åº¦å’Œè½¦è¾†è¿åŠ¨çŠ¶æ€ï¼Œç‰¹åˆ«æ˜¯åœ¨â€œè½¯äº¤ç‚¹â€å¤„çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒSRefinerè¿˜æ‰©å±•äº†è½¨è¿¹ä¸è½¦é“é—´äº¤äº’çš„å»ºæ¨¡ï¼Œè¿›ä¸€æ­¥æé«˜äº†é¢„æµ‹ç²¾åº¦ã€‚SRefineråœ¨å¤šæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºå››ç§åŸºçº¿æ–¹æ³•ï¼Œä¸ºè½¨è¿¹ä¼˜åŒ–æ ‘ç«‹äº†æ–°çš„æ ‡å‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“æœªæ¥è½¨è¿¹çš„å‡†ç¡®é¢„æµ‹å¯¹è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåšå‡ºå®‰å…¨å’Œé«˜æ•ˆå†³ç­–è‡³å…³é‡è¦ã€‚</li>
<li>è½¨è¿¹ä¼˜åŒ–æ˜¯æé«˜é¢„æµ‹å‡†ç¡®æ€§çš„å…³é”®ç­–ç•¥ä¹‹ä¸€ã€‚</li>
<li>ç°æœ‰è½¨è¿¹ä¼˜åŒ–æ–¹æ³•å¸¸å¿½ç•¥è½¨è¿¹é—´çš„æ‹“æ‰‘å…³ç³»ï¼Œè¿™å¯¹æé«˜é¢„æµ‹ç²¾åº¦è‡³å…³é‡è¦ã€‚</li>
<li>Soft-Braid Refinerï¼ˆSRefinerï¼‰åŸºäºè¾«çŠ¶ç†è®ºå¯å‘ï¼Œé€šè¿‡Soft-Braid Attentionæ•æ‰è½¨è¿¹çš„æ—¶ç©ºæ‹“æ‰‘ç»“æ„å…³ç³»ã€‚</li>
<li>SRefinerè€ƒè™‘äº†è½¨è¿¹é—´çš„ç©ºé—´æ¥è¿‘ç¨‹åº¦å’Œè½¦è¾†è¿åŠ¨çŠ¶æ€ï¼Œç‰¹åˆ«æ˜¯åœ¨â€œè½¯äº¤ç‚¹â€å¤„çš„ä¿¡æ¯ã€‚</li>
<li>SRefineræ‰©å±•äº†è½¨è¿¹ä¸è½¦é“é—´äº¤äº’çš„å»ºæ¨¡ï¼Œè¿›ä¸€æ­¥æé«˜äº†é¢„æµ‹ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04263">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-34361317c9acba47739b27cda8735970.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d0a694a64a50bbd42309ccff7b2e34b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-777fd6b87111e1482920ac2766be73f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b04605392c530e7c3b02665731ec2158.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Hijacking-JARVIS-Benchmarking-Mobile-GUI-Agents-against-Unprivileged-Third-Parties"><a href="#Hijacking-JARVIS-Benchmarking-Mobile-GUI-Agents-against-Unprivileged-Third-Parties" class="headerlink" title="Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged   Third Parties"></a>Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged   Third Parties</h2><p><strong>Authors:Guohong Liu, Jialei Ye, Jiacheng Liu, Yuanchun Li, Wei Liu, Pengzhi Gao, Jian Luan, Yunxin Liu</strong></p>
<p>Mobile GUI agents are designed to autonomously execute diverse device-control tasks by interpreting and interacting with mobile screens. Despite notable advancements, their resilience in real-world scenarios where screen content may be partially manipulated by untrustworthy third parties remains largely unexplored. Owing to their black-box and autonomous nature, these agents are vulnerable to manipulations that could compromise user devices. In this work, we present the first systematic investigation into the vulnerabilities of mobile GUI agents. We introduce a scalable attack simulation framework AgentHazard, which enables flexible and targeted modifications of screen content within existing applications. Leveraging this framework, we develop a comprehensive benchmark suite comprising both a dynamic task execution environment and a static dataset of vision-language-action tuples, totaling over 3,000 attack scenarios. The dynamic environment encompasses 58 reproducible tasks in an emulator with various types of hazardous UI content, while the static dataset is constructed from 210 screenshots collected from 14 popular commercial apps. Importantly, our content modifications are designed to be feasible for unprivileged third parties. We evaluate 7 widely-used mobile GUI agents and 5 common backbone models using our benchmark. Our findings reveal that all examined agents are significantly influenced by misleading third-party content (with an average misleading rate of 28.8% in human-crafted attack scenarios) and that their vulnerabilities are closely linked to the employed perception modalities and backbone LLMs. Furthermore, we assess training-based mitigation strategies, highlighting both the challenges and opportunities for enhancing the robustness of mobile GUI agents. Our code and data will be released at <a target="_blank" rel="noopener" href="https://agenthazard.github.io/">https://agenthazard.github.io</a>. </p>
<blockquote>
<p>ç§»åŠ¨GUIä»£ç†æ—¨åœ¨é€šè¿‡è§£é‡Šå’Œä¸ç§»åŠ¨å±å¹•è¿›è¡Œäº¤äº’æ¥è‡ªä¸»æ‰§è¡Œå¤šæ ·åŒ–çš„è®¾å¤‡æ§åˆ¶ä»»åŠ¡ã€‚å°½ç®¡æœ‰äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­ï¼Œå½“å±å¹•å†…å®¹å¯èƒ½è¢«ä¸å¯ä¿¡çš„ç¬¬ä¸‰æ–¹éƒ¨åˆ†æ“çºµæ—¶ï¼Œå®ƒä»¬çš„æ¢å¤èƒ½åŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æœªè¢«æ¢ç´¢ã€‚ç”±äºè¿™äº›ä»£ç†å…·æœ‰é»‘ç®±å’Œè‡ªä¸»æ€§è´¨ï¼Œå®ƒä»¬å®¹æ˜“å—åˆ°å¯èƒ½å¯¼è‡´ç”¨æˆ·è®¾å¤‡å‡ºç°é—®é¢˜çš„æ“çºµã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹ç§»åŠ¨GUIä»£ç†çš„è„†å¼±æ€§è¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿç ”ç©¶ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ”»å‡»æ¨¡æ‹Ÿæ¡†æ¶AgentHazardï¼Œå®ƒèƒ½å¤Ÿåœ¨ç°æœ‰åº”ç”¨ç¨‹åºä¸­çµæ´»åœ°å®ç°æœ‰é’ˆå¯¹æ€§çš„å±å¹•å†…å®¹ä¿®æ”¹ã€‚åˆ©ç”¨è¿™ä¸€æ¡†æ¶ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€å¥—å…¨é¢çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªåŠ¨æ€ä»»åŠ¡æ‰§è¡Œç¯å¢ƒå’Œä¸€ä¸ªåŒ…å«è¶…è¿‡3000ä¸ªæ”»å‡»åœºæ™¯çš„é™æ€è§†è§‰è¯­è¨€åŠ¨ä½œå…ƒç»„æ•°æ®é›†ã€‚åŠ¨æ€ç¯å¢ƒåŒ…æ‹¬æ¨¡æ‹Ÿå™¨ä¸­çš„58ä¸ªå¯å¤åˆ¶ä»»åŠ¡ï¼Œå…¶ä¸­åŒ…å«å„ç§ç±»å‹çš„å±é™©UIå†…å®¹ï¼Œè€Œé™æ€æ•°æ®é›†åˆ™æ˜¯ä»14ä¸ªæµè¡Œçš„å•†ä¸šåº”ç”¨ä¸­æ”¶é›†çš„210å¼ æˆªå›¾ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å†…å®¹ä¿®æ”¹æ˜¯ä¸“ä¸ºæ²¡æœ‰ç‰¹æƒçš„ç¬¬ä¸‰æ–¹è®¾è®¡çš„ã€‚æˆ‘ä»¬ä½¿ç”¨åŸºå‡†æµ‹è¯•å¥—ä»¶è¯„ä¼°äº†7ç§å¸¸ç”¨çš„ç§»åŠ¨GUIä»£ç†å’Œ5ç§å¸¸è§çš„éª¨å¹²æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰ç»è¿‡æµ‹è¯•çš„ä»£ç†éƒ½å—åˆ°ç¬¬ä¸‰æ–¹è¯¯å¯¼å†…å®¹çš„å½±å“ï¼ˆäººä¸ºè®¾è®¡çš„æ”»å‡»åœºæ™¯ä¸­å¹³å‡è¯¯å¯¼ç‡ä¸º28.8%ï¼‰ï¼Œå¹¶ä¸”å®ƒä»¬çš„è„†å¼±æ€§ä¸æ‰€é‡‡ç”¨çš„æ„ŸçŸ¥æ–¹å¼å’Œéª¨å¹²æ¨¡å‹ç´§å¯†ç›¸å…³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯„ä¼°äº†åŸºäºè®­ç»ƒçš„ç¼“è§£ç­–ç•¥ï¼Œå¹¶å¼ºè°ƒäº†å¢å¼ºç§»åŠ¨GUIä»£ç†ç¨³å¥æ€§çš„æŒ‘æˆ˜å’Œæœºé‡ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å°†åœ¨<a target="_blank" rel="noopener" href="https://agenthazard.github.ioä¸Šå‘å¸ƒ./">https://agenthazard.github.ioä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04227v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†ç§»åŠ¨GUIä»£ç†çš„è„†å¼±æ€§ï¼Œå¹¶ä»‹ç»äº†æ”»å‡»æ¨¡æ‹Ÿæ¡†æ¶AgentHazardã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ç°æœ‰åº”ç”¨ç¨‹åºä¸­çµæ´»åœ°ä¿®æ”¹å±å¹•å†…å®¹ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«åŠ¨æ€ä»»åŠ¡æ‰§è¡Œç¯å¢ƒå’Œé™æ€è§†è§‰è¯­è¨€åŠ¨ä½œå…ƒç»„æ•°æ®é›†çš„ç»¼åˆåŸºå‡†æµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«è¶…è¿‡3000ä¸ªæ”»å‡»åœºæ™¯ã€‚è¯„ä¼°äº†7ç§å¸¸ç”¨çš„ç§»åŠ¨GUIä»£ç†å’Œ5ç§å¸¸è§çš„åå°æ¨¡å‹ï¼Œå‘ç°æ‰€æœ‰è¢«è¯„ä¼°çš„ä»£ç†éƒ½å—åˆ°ç¬¬ä¸‰æ–¹è¯¯å¯¼å†…å®¹çš„å½±å“ï¼Œå…¶è„†å¼±æ€§ä¸æ‰€é‡‡ç”¨çš„æ„ŸçŸ¥æ¨¡æ€å’Œåå°LLMå¯†åˆ‡ç›¸å…³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç§»åŠ¨GUIä»£ç†åœ¨è®¾è®¡è‡ªä¸»æ‰§è¡Œå¤šæ ·è®¾å¤‡æ§åˆ¶ä»»åŠ¡æ—¶ï¼Œå¯¹å±å¹•å†…å®¹çš„è§£è¯»å’Œäº¤äº’å­˜åœ¨è„†å¼±æ€§ã€‚</li>
<li>ç°æœ‰ç§»åŠ¨GUIä»£ç†åœ¨é¢å¯¹ç¬¬ä¸‰æ–¹å¯¹å±å¹•å†…å®¹çš„éƒ¨åˆ†æ“æ§æ—¶ï¼Œå…¶å®é™…ä¸–ç•Œåœºæ™¯ä¸­çš„éŸ§æ€§æœ‰å¾…æå‡ã€‚</li>
<li>AgentHazardæ”»å‡»æ¨¡æ‹Ÿæ¡†æ¶è¢«ç”¨äºç³»ç»Ÿåœ°æ¢ç´¢ç§»åŠ¨GUIä»£ç†çš„è„†å¼±æ€§ï¼Œå¹¶å…è®¸å¯¹å±å¹•å†…å®¹è¿›è¡Œçµæ´»å’Œæœ‰é’ˆå¯¹æ€§çš„ä¿®æ”¹ã€‚</li>
<li>ç»¼åˆåŸºå‡†æµ‹è¯•å¥—ä»¶åŒ…å«åŠ¨æ€ä»»åŠ¡æ‰§è¡Œç¯å¢ƒå’Œé™æ€è§†è§‰è¯­è¨€åŠ¨ä½œæ•°æ®é›†ï¼Œæ¶µç›–è¶…è¿‡3000ä¸ªæ”»å‡»åœºæ™¯ã€‚</li>
<li>æ‰€æœ‰è¯„ä¼°çš„ç§»åŠ¨GUIä»£ç†éƒ½å—åˆ°ç¬¬ä¸‰æ–¹è¯¯å¯¼å†…å®¹çš„å½±å“ï¼Œå¹³å‡è¯¯å¯¼ç‡é«˜è¾¾28.8%ã€‚</li>
<li>ç§»åŠ¨GUIä»£ç†çš„è„†å¼±æ€§ä¸æ‰€é‡‡ç”¨çš„æ„ŸçŸ¥æ¨¡æ€å’Œåå°è¯­è¨€æ¨¡å‹ç´§å¯†ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04227">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-604b724dc984a552cdd154c1bd9b1297.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d934fa1aa7ddf010e503dc37828b5ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-226e7c83d793adc4702c227c956096cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ad89e57d2174b212b316a41b037c28d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79894579c9140f7269ee0ee93c058bd2.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="How-to-Train-Your-LLM-Web-Agent-A-Statistical-Diagnosis"><a href="#How-to-Train-Your-LLM-Web-Agent-A-Statistical-Diagnosis" class="headerlink" title="How to Train Your LLM Web Agent: A Statistical Diagnosis"></a>How to Train Your LLM Web Agent: A Statistical Diagnosis</h2><p><strong>Authors:Dheeraj Vattikonda, Santhoshi Ravichandran, Emiliano Penaloza, Hadi Nekoei, Megh Thakkar, Thibault Le Sellier de Chezelles, Nicolas Gontier, Miguel MuÃ±oz-MÃ¡rmol, Sahar Omidi Shayegan, Stefania Raimondo, Xue Liu, Alexandre Drouin, Laurent Charlin, Alexandre PichÃ©, Alexandre Lacoste, Massimo Caccia</strong></p>
<p>LLM-based web agents have recently made significant progress, but much of it has occurred in closed-source systems, widening the gap with open-source alternatives. Progress has been held back by two key challenges: first, a narrow focus on single-step tasks that overlooks the complexity of multi-step web interactions; and second, the high compute costs required to post-train LLM-based web agents. To address this, we present the first statistically grounded study on compute allocation for LLM web-agent post-training. Our approach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate a Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy reinforcement learning. We find this process highly sensitive to hyperparameter choices, making exhaustive sweeps impractical. To spare others from expensive trial-and-error, we sample 1,370 configurations and use bootstrapping to estimate effective hyperparameters. Our results show that combining SFT with on-policy RL consistently outperforms either approach alone on both WorkArena and MiniWob++. Further, this strategy requires only 55% of the compute to match the peak performance of pure SFT on MiniWob++, effectively pushing the compute-performance Pareto frontier, and is the only strategy that can close the gap with closed-source models. </p>
<blockquote>
<p>åŸºäºLLMçš„Webä»£ç†è¿‘æœŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§éƒ¨åˆ†è¿›å±•å‡ºç°åœ¨å°é—­æºä»£ç ç³»ç»Ÿä¸­ï¼Œä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆçš„å·®è·è¿›ä¸€æ­¥æ‰©å¤§ã€‚è¿›å±•å—åˆ°ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜çš„é™åˆ¶ï¼šç¬¬ä¸€ï¼Œå¯¹å•æ­¥ä»»åŠ¡çš„ç‹­çª„å…³æ³¨ï¼Œå¿½è§†äº†å¤šæ­¥Webäº¤äº’çš„å¤æ‚æ€§ï¼›ç¬¬äºŒï¼ŒLLMåŸºäºWebä»£ç†åè®­ç»ƒæ‰€éœ€çš„é«˜è®¡ç®—æˆæœ¬ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¯¹LLM Webä»£ç†åè®­ç»ƒçš„è®¡ç®—åˆ†é…è¿›è¡Œäº†é¦–æ¬¡ç»Ÿè®¡ç ”ç©¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼Œè®­ç»ƒä¸€åªLlama 3.1 8Bå­¦ç”Ÿä»£ç†é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ¨¡ä»¿ä¸€åªLlama 3.3 70Bæ•™å¸ˆä»£ç†ï¼Œéšåè¿›è¡ŒåŸºäºç­–ç•¥çš„ç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬å‘ç°è¿™ä¸ªè¿‡ç¨‹å¯¹è¶…å‚æ•°é€‰æ‹©éå¸¸æ•æ„Ÿï¼Œä½¿å…¨é¢æ‰«æå˜å¾—ä¸åˆ‡å®é™…ã€‚ä¸ºäº†èŠ‚çœä»–äººæ˜‚è´µçš„è¯•é”™æˆæœ¬ï¼Œæˆ‘ä»¬å¯¹1370ä¸ªé…ç½®è¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä½¿ç”¨bootstrapæ–¹æ³•æ¥ä¼°è®¡æœ‰æ•ˆè¶…å‚æ•°ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œç»“åˆSFTå’ŒåŸºäºç­–ç•¥RLçš„æ–¹æ³•åœ¨å·¥ä½œåœºå’ŒMiniWob++ä¸Šçš„è¡¨ç°å§‹ç»ˆä¼˜äºå•ä¸€æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæ­¤ç­–ç•¥ä»…éœ€55%çš„è®¡ç®—é‡å³å¯è¾¾åˆ°çº¯SFTåœ¨MiniWob++ä¸Šçš„å³°å€¼æ€§èƒ½ï¼Œæœ‰æ•ˆåœ°æ¨åŠ¨äº†è®¡ç®—æ€§èƒ½å¸•ç´¯æ‰˜å‰æ²¿çš„è¿›æ­¥ï¼Œæ˜¯å”¯ä¸€èƒ½å¤Ÿç¼©å°ä¸å°é—­æºä»£ç æ¨¡å‹å·®è·çš„ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04103v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLMç½‘ç»œä»£ç†åœ¨é—­æºç³»ç»Ÿä¸­å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆä¹‹é—´å­˜åœ¨å·®è·ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºè¿‡äºå…³æ³¨å•æ­¥ä»»åŠ¡ï¼Œå¿½è§†äº†å¤šæ­¥ç½‘ç»œäº¤äº’çš„å¤æ‚æ€§ï¼Œä»¥åŠè®­ç»ƒLLMç½‘ç»œä»£ç†åè®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å¯¹LLMç½‘ç»œä»£ç†è¿›è¡Œç»Ÿè®¡ç ”ç©¶ï¼Œå…³æ³¨è®¡ç®—åˆ†é…é—®é¢˜ã€‚ç ”ç©¶é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è®­ç»ƒLlama 3.1 8Bå­¦ç”Ÿæ¨¡å‹ä»¥æ¨¡ä»¿Llama 3.3 70Bæ•™å¸ˆæ¨¡å‹ï¼Œéšåè¿›è¡Œç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚ç ”ç©¶å‘ç°è¯¥è¿‡ç¨‹å¯¹è¶…å‚æ•°é€‰æ‹©é«˜åº¦æ•æ„Ÿï¼Œå› æ­¤è¿›è¡Œå¤§è§„æ¨¡æœç´¢ä¸åˆ‡å®é™…ã€‚ä¸ºäº†èŠ‚çœä»–äººæ˜‚è´µçš„è¯•é”™æˆæœ¬ï¼Œæœ¬ç ”ç©¶å¯¹1370ç§é…ç½®è¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä½¿ç”¨å¼•å¯¼æŠ½æ ·ä¼°è®¡æœ‰æ•ˆè¶…å‚æ•°ã€‚ç»“æœæ˜¾ç¤ºï¼Œç»“åˆSFTå’Œç­–ç•¥å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•å§‹ç»ˆä¼˜äºå•ä¸€æ–¹æ³•ï¼Œåœ¨å·¥ä½œç«æŠ€åœºå’ŒMiniWob++ä¸Šçš„è¡¨ç°å°¤ä¸ºçªå‡ºã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä»…éœ€55%çš„è®¡ç®—é‡å³å¯è¾¾åˆ°çº¯SFTåœ¨MiniWob++ä¸Šçš„å³°å€¼æ€§èƒ½ï¼Œæœ‰æ•ˆæ¨åŠ¨è®¡ç®—æ€§èƒ½å¸•ç´¯æ‰˜å‰æ²¿çš„è¿›æ­¥ï¼Œå¹¶ä¸”æ˜¯å”¯ä¸€èƒ½ç¼©å°ä¸é—­æºæ¨¡å‹ä¹‹é—´å·®è·çš„ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMç½‘ç»œä»£ç†åœ¨é—­æºç³»ç»Ÿä¸­è¿›å±•æ˜¾è‘—ï¼Œä½†å¼€æºæ›¿ä»£æ–¹æ¡ˆä¸ä¹‹å­˜åœ¨å·®è·ã€‚</li>
<li>ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ï¼šå…³æ³¨å•æ­¥ä»»åŠ¡è€Œå¿½è§†å¤šæ­¥äº¤äº’çš„å¤æ‚æ€§ï¼Œä»¥åŠLLMç½‘ç»œä»£ç†è®­ç»ƒçš„é«˜è®¡ç®—æˆæœ¬ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼šç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚</li>
<li>è¯¥è¿‡ç¨‹å¯¹è¶…å‚æ•°é€‰æ‹©é«˜åº¦æ•æ„Ÿï¼Œå¤§è§„æ¨¡æœç´¢ä¸åˆ‡å®é™…ã€‚</li>
<li>ç»“åˆSFTå’Œç­–ç•¥å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•åœ¨ä»»åŠ¡è¡¨ç°ä¸Šä¼˜äºå•ä¸€æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæœ‰æ•ˆæ¨åŠ¨è®¡ç®—æ€§èƒ½å¸•ç´¯æ‰˜å‰æ²¿çš„è¿›æ­¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04103">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ca60a1e5c49659792125ebaec31cc76e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f15e727ee7c02ffd31c2340cc89068e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2da968765e51a4dc44b6d54a6e41c97.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="AutoMind-Adaptive-Knowledgeable-Agent-for-Automated-Data-Science"><a href="#AutoMind-Adaptive-Knowledgeable-Agent-for-Automated-Data-Science" class="headerlink" title="AutoMind: Adaptive Knowledgeable Agent for Automated Data Science"></a>AutoMind: Adaptive Knowledgeable Agent for Automated Data Science</h2><p><strong>Authors:Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Shuofei Qiao, Jintian Zhang, Da Zheng, Huajun Chen, Ningyu Zhang</strong></p>
<p>Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire machine learning pipeline, yet their real-world effectiveness remains limited. Existing frameworks depend on rigid, pre-defined workflows and inflexible coding strategies; consequently, they excel only on relatively simple, classical problems and fail to capture the empirical expertise that human practitioners bring to complex, innovative tasks. In this work, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework that overcomes these deficiencies through three key advances: (1) a curated expert knowledge base that grounds the agent in domain expert knowledge, (2) an agentic knowledgeable tree search algorithm that strategically explores possible solutions, and (3) a self-adaptive coding strategy that dynamically tailors code generation to task complexity. Evaluations on two automated data science benchmarks demonstrate that AutoMind delivers superior performance versus state-of-the-art baselines. Additional analyses confirm favorable effectiveness, efficiency, and qualitative solution quality, highlighting AutoMind as an efficient and robust step toward fully automated data science. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨è§£å†³ç°å®ä¸–ç•Œçš„æ•°æ®ç§‘å­¦é—®é¢˜æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚LLMé©±åŠ¨çš„æ•°æ®ç§‘å­¦ä»£ç†æœ‰æœ›è‡ªåŠ¨åŒ–æ•´ä¸ªæœºå™¨å­¦ä¹ æµç¨‹ï¼Œä½†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶æœ‰é™ã€‚ç°æœ‰æ¡†æ¶ä¾èµ–äºåƒµåŒ–ã€é¢„å…ˆå®šä¹‰çš„å·¥ä½œæµç¨‹å’Œä¸å¯çµæ´»è°ƒæ•´çš„ç¼–ç ç­–ç•¥ï¼›å› æ­¤ï¼Œå®ƒä»¬ä»…åœ¨ç›¸å¯¹ç®€å•ã€ç»å…¸çš„é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè€Œæ— æ³•è·å–äººç±»å®è·µè€…åœ¨å¤æ‚ã€åˆ›æ–°ä»»åŠ¡ä¸­æ‰€å¸¦æ¥çš„ç»éªŒçŸ¥è¯†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†AutoMindï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªé€‚åº”ã€çŸ¥è¯†å‹LLMä»£ç†æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®è¿›å±•å…‹æœäº†è¿™äº›ä¸è¶³ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªç²¾é€‰çš„ä¸“å®¶çŸ¥è¯†åº“ï¼Œå°†ä»£ç†ä¸é¢†åŸŸä¸“å®¶çŸ¥è¯†ç›¸ç»“åˆï¼›ï¼ˆ2ï¼‰ä¸€ç§æ™ºèƒ½çŸ¥è¯†æ ‘æœç´¢ç®—æ³•ï¼Œæˆ˜ç•¥æ€§åœ°æ¢ç´¢å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼›ï¼ˆ3ï¼‰ä¸€ç§è‡ªé€‚åº”ç¼–ç ç­–ç•¥ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€è°ƒæ•´ä»£ç ç”Ÿæˆã€‚åœ¨ä¸¤ä¸ªè‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒAutoMindç›¸è¾ƒäºæœ€æ–°åŸºçº¿æŠ€æœ¯è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚é™„åŠ åˆ†æè¯å®äº†å…¶æœ‰æ•ˆæ€§ã€é«˜æ•ˆæ€§å’Œè§£å†³æ–¹æ¡ˆçš„ä¼˜è´¨æ€§ï¼Œå‡¸æ˜¾äº†AutoMindä½œä¸ºå®ç°å®Œå…¨è‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦çš„ç¨³å¥è€Œé«˜æ•ˆçš„æ­¥éª¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10974v2">PDF</a> Ongoing work. Code is at <a target="_blank" rel="noopener" href="https://github.com/innovatingAI/AutoMind">https://github.com/innovatingAI/AutoMind</a></p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§£å†³ç°å®æ•°æ®ç§‘å­¦é—®é¢˜æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼ŒLLMé©±åŠ¨çš„æ•°æ®ç§‘å­¦ä»£ç†æ‰¿è¯ºè‡ªåŠ¨åŒ–æ•´ä¸ªæœºå™¨å­¦ä¹ ç®¡é“ï¼Œä½†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶å—åˆ°é™åˆ¶ã€‚ç°æœ‰æ¡†æ¶ä¾èµ–äºé¢„è®¾çš„å·¥ä½œæµç¨‹å’ŒåƒµåŒ–çš„ç¼–ç ç­–ç•¥ï¼Œä»…æ“…é•¿å¤„ç†ç›¸å¯¹ç®€å•çš„é—®é¢˜ï¼Œéš¾ä»¥æ•æ‰äººç±»å®è·µè€…åœ¨å¤æ‚åˆ›æ–°ä»»åŠ¡ä¸­çš„ç»éªŒçŸ¥è¯†ã€‚æœ¬ç ”ç©¶å¼•å…¥AutoMindï¼Œä¸€ç§è‡ªé€‚åº”çš„çŸ¥è¯†å‹LLMä»£ç†æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®è¿›å±•å…‹æœè¿™äº›ç¼ºé™·ï¼š1ï¼‰ç²¾é€‰çš„ä¸“å®¶çŸ¥è¯†åº“ä½¿ä»£ç†èå…¥é¢†åŸŸä¸“å®¶çŸ¥è¯†ï¼Œ2ï¼‰æ™ºèƒ½çŸ¥è¯†æ ‘æœç´¢ç®—æ³•æˆ˜ç•¥æ€§æ¢ç´¢å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥åŠ3ï¼‰è‡ªé€‚åº”ç¼–ç ç­–ç•¥æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€è°ƒæ•´ä»£ç ç”Ÿæˆã€‚è¯„ä¼°è¡¨æ˜ï¼ŒAutoMindåœ¨è‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜äºæœ€æ–°æŠ€æœ¯çš„æ€§èƒ½ã€‚é™„åŠ åˆ†æè¯å®äº†å…¶æœ‰æ•ˆæ€§ã€æ•ˆç‡å’Œè§£å†³æ–¹æ¡ˆè´¨é‡ï¼Œçªæ˜¾AutoMindæ˜¯æœç€å…¨è‡ªåŠ¨æ•°æ®ç§‘å­¦çš„ç¨³å¥è€Œé«˜æ•ˆçš„ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLMåœ¨è§£å†³æ•°æ®ç§‘å­¦é—®é¢˜æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ç°å®åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å—é™ã€‚</li>
<li>ç°æœ‰æ•°æ®ç§‘å­¦æ¡†æ¶ä¾èµ–äºé¢„è®¾çš„å·¥ä½œæµç¨‹å’ŒåƒµåŒ–çš„ç¼–ç ç­–ç•¥ï¼Œéš¾ä»¥å¤„ç†å¤æ‚åˆ›æ–°ä»»åŠ¡ã€‚</li>
<li>AutoMindæ˜¯ä¸€ä¸ªè‡ªé€‚åº”çš„çŸ¥è¯†å‹LLMä»£ç†æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®åˆ›æ–°æ”¹å–„ç°æœ‰é—®é¢˜ã€‚</li>
<li>AutoMindèå…¥é¢†åŸŸä¸“å®¶çŸ¥è¯†ï¼Œé€šè¿‡æ™ºèƒ½çŸ¥è¯†åº“å¢å¼ºä»£ç†çš„èƒ½åŠ›ã€‚</li>
<li>æ™ºèƒ½çŸ¥è¯†æ ‘æœç´¢ç®—æ³•ä½¿AutoMindèƒ½æˆ˜ç•¥æ€§æ¢ç´¢å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>AutoMindå…·æœ‰è‡ªé€‚åº”ç¼–ç ç­–ç•¥ï¼Œèƒ½æ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€è°ƒæ•´ä»£ç ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10974">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c3263f94db87251acb0b7156a243e57.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d31b3f387549ef2676f3fb3637f94ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-759deafa0a3830461907c0ae116de7f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eea220c72eeb3168242a747f7237750e.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="On-the-Role-of-Feedback-in-Test-Time-Scaling-of-Agentic-AI-Workflows"><a href="#On-the-Role-of-Feedback-in-Test-Time-Scaling-of-Agentic-AI-Workflows" class="headerlink" title="On the Role of Feedback in Test-Time Scaling of Agentic AI Workflows"></a>On the Role of Feedback in Test-Time Scaling of Agentic AI Workflows</h2><p><strong>Authors:Souradip Chakraborty, Mohammadreza Pourreza, Ruoxi Sun, Yiwen Song, Nino Scherrer, Furong Huang, Amrit Singh Bedi, Ahmad Beirami, Jindong Gu, Hamid Palangi, Tomas Pfister</strong></p>
<p>Agentic AI workflows (systems that autonomously plan and act) are becoming widespread, yet their task success rate on complex tasks remains low. A promising solution is inference-time alignment, which uses extra compute at test time to improve performance. Inference-time alignment relies on three components: sampling, evaluation, and feedback. While most prior work studies sampling and automatic evaluation, feedback remains underexplored. To study the role of feedback, we introduce Iterative Agent Decoding (IAD), a procedure that repeatedly inserts feedback extracted from different forms of critiques (reward models or AI-generated textual feedback) between decoding steps. Through IAD, we analyze feedback along four dimensions: (1) its role in the accuracy-compute trade-offs with limited inference budget, (2) quantifying the gains over diversity-only baselines such as best-of-N sampling, (3) effectiveness of composing feedback from reward models versus textual critique, and (4) robustness to noisy or low-quality feedback. Across Sketch2Code, Text2SQL, Intercode, and WebShop, we show that IAD with proper integration of high fidelity feedback leads to consistent gains up to 10 percent absolute performance improvement over various baselines such as best-of-N. Our findings underscore feedback as a crucial knob for inference-time alignment of agentic AI workflows with limited inference budget. </p>
<blockquote>
<p>åŸºäºAIçš„å·¥ä½œæµç¨‹ï¼ˆè‡ªä¸»è®¡åˆ’å’Œè¡ŒåŠ¨çš„ç³»ç»Ÿï¼‰æ­£å˜å¾—è¶Šæ¥è¶Šæ™®éï¼Œç„¶è€Œå®ƒä»¬åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„ä»»åŠ¡æˆåŠŸç‡ä»ç„¶è¾ƒä½ã€‚ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆæ˜¯æ¨ç†æ—¶é—´å¯¹é½ï¼Œå®ƒåˆ©ç”¨é¢å¤–çš„è®¡ç®—æµ‹è¯•æ—¶é—´æ¥æé«˜æ€§èƒ½ã€‚æ¨ç†æ—¶é—´å¯¹é½ä¾èµ–äºä¸‰ä¸ªç»„ä»¶ï¼šé‡‡æ ·ã€è¯„ä¼°å’Œåé¦ˆã€‚è™½ç„¶å¤§å¤šæ•°æ—©æœŸçš„ç ”ç©¶é›†ä¸­åœ¨é‡‡æ ·å’Œè‡ªåŠ¨è¯„ä¼°ä¸Šï¼Œä½†åé¦ˆä»ç„¶è¢«å¿½è§†ã€‚ä¸ºäº†ç ”ç©¶åé¦ˆçš„ä½œç”¨ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¿­ä»£ä»£ç†è§£ç ï¼ˆIADï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è§£ç æ­¥éª¤ä¹‹é—´åå¤æ’å…¥ä»ä¸åŒå½¢å¼çš„è¯„è®ºï¼ˆå¥–åŠ±æ¨¡å‹æˆ–AIç”Ÿæˆçš„æ–‡æœ¬åé¦ˆï¼‰ä¸­æå–çš„åé¦ˆçš„ç¨‹åºã€‚é€šè¿‡IADï¼Œæˆ‘ä»¬æ²¿ç€å››ä¸ªç»´åº¦åˆ†æåé¦ˆï¼šï¼ˆ1ï¼‰å…¶åœ¨æœ‰é™çš„æ¨ç†é¢„ç®—ä¸‹å¯¹å‡†ç¡®æ€§è®¡ç®—æŠ˜è¡·çš„ä½œç”¨ï¼Œï¼ˆ2ï¼‰ç›¸å¯¹äºåªé‡è§†å¤šæ ·æ€§çš„åŸºçº¿ï¼ˆå¦‚æœ€ä½³Né‡‡æ ·ï¼‰çš„é‡åŒ–æ”¶ç›Šï¼Œï¼ˆ3ï¼‰ä»å¥–åŠ±æ¨¡å‹ä¸æ–‡æœ¬è¯„è®ºç»„åˆåé¦ˆçš„æœ‰æ•ˆæ€§ï¼Œï¼ˆ4ï¼‰å¯¹å˜ˆæ‚æˆ–ä½è´¨é‡åé¦ˆçš„ç¨³å¥æ€§ã€‚åœ¨Sketch2Codeã€Text2SQLã€Intercodeå’ŒWebShopä¸Šï¼Œæˆ‘ä»¬å±•ç¤ºäº†é€‚å½“æ•´åˆé«˜ä¿çœŸåé¦ˆçš„IADåœ¨å„ç§åŸºçº¿ï¼ˆå¦‚æœ€ä½³Né‡‡æ ·ï¼‰ä¸Šå®ç°äº†é«˜è¾¾10%çš„ç»å¯¹æ€§èƒ½æ”¹è¿›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¯¹äºå…·æœ‰æœ‰é™æ¨ç†é¢„ç®—çš„åŸºäºAIçš„å·¥ä½œæµç¨‹è€Œè¨€ï¼Œåé¦ˆæ˜¯æ¨ç†æ—¶é—´å¯¹é½çš„å…³é”®å‚æ•°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01931v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è‡ªä¸»è®¡åˆ’è¡ŒåŠ¨çš„Agentic AIå·¥ä½œæµåœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡è¾ƒä½çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†æ¨ç†æ—¶é—´å¯¹é½æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æµ‹è¯•æ—¶åˆ©ç”¨é¢å¤–çš„è®¡ç®—æ¥æé«˜æ€§èƒ½ã€‚æœ¬æ–‡é‡ç‚¹ç ”ç©¶åé¦ˆçš„ä½œç”¨ï¼Œå¹¶ä»‹ç»äº†è¿­ä»£å¼è§£ç ï¼ˆIADï¼‰ï¼Œä¸€ç§åœ¨è§£ç æ­¥éª¤ä¹‹é—´é‡å¤æ’å…¥ä»ä¸åŒå½¢å¼çš„æ‰¹è¯„ä¸­æå–çš„åé¦ˆçš„ç¨‹åºã€‚é€šè¿‡å¯¹IADçš„åˆ†æï¼Œç ”ç©¶å‘ç°å…¶åœ¨æœ‰é™æ¨ç†é¢„ç®—ä¸‹çš„å‡†ç¡®æ€§è®¡ç®—æƒè¡¡ã€ç›¸å¯¹äºå¤šæ ·æ€§åŸºå‡†çš„å¢ç›Šé‡åŒ–ã€ä»å¥–åŠ±æ¨¡å‹ä¸­ç»„åˆåé¦ˆçš„æœ‰æ•ˆæ€§ä»¥åŠå¯¹äºå™ªå£°æˆ–ä½è´¨é‡åé¦ˆçš„ç¨³å¥æ€§ç­‰æ–¹é¢éƒ½æœ‰æ˜¾è‘—è¡¨ç°ã€‚åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡é€‚å½“æ•´åˆé«˜ä¿çœŸåé¦ˆï¼ŒIADåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†é«˜è¾¾10%çš„ç»å¯¹æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agentic AIå·¥ä½œæµåœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä»ç„¶æœ‰å¾…æé«˜ã€‚</li>
<li>æ¨ç†æ—¶é—´å¯¹é½æ–¹æ³•é€šè¿‡ä½¿ç”¨é¢å¤–çš„è®¡ç®—åœ¨æµ‹è¯•æ—¶æé«˜AIçš„æ€§èƒ½ã€‚</li>
<li>åé¦ˆåœ¨æ¨ç†æ—¶é—´å¯¹é½ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œè€Œè¿™ä¸€ç‚¹åœ¨ä¹‹å‰çš„ç ”ç©¶ä¸­å´è¢«å¿½è§†ã€‚</li>
<li>è¿­ä»£å¼è§£ç ï¼ˆIADï¼‰ç¨‹åºèƒ½å¤Ÿåœ¨è§£ç æ­¥éª¤ä¹‹é—´æ’å…¥ä¸åŒå½¢å¼çš„åé¦ˆã€‚</li>
<li>IADåœ¨æœ‰é™æ¨ç†é¢„ç®—ä¸‹çš„å‡†ç¡®æ€§è®¡ç®—æƒè¡¡æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>IADç›¸å¯¹äºå¤šæ ·æ€§åŸºå‡†çš„å¢ç›Šé‡åŒ–æ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6a32c134773104bc86865808f091bcfe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a86cfb2d85c6097c03a0d8d902c7fa41.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-82747c8cfd2f5fbe722b5bffc5f4aeb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a728af8b87baa22f6dba7e0f3d6dbfca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-788a9d7728eb273411051ac6cb275501.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Autonomous-Microscopy-Experiments-through-Large-Language-Model-Agents"><a href="#Autonomous-Microscopy-Experiments-through-Large-Language-Model-Agents" class="headerlink" title="Autonomous Microscopy Experiments through Large Language Model Agents"></a>Autonomous Microscopy Experiments through Large Language Model Agents</h2><p><strong>Authors:Indrajeet Mandal, Jitendra Soni, Mohd Zaki, Morten M. Smedskjaer, Katrin Wondraczek, Lothar Wondraczek, Nitya Nand Gosvami, N. M. Anoop Krishnan</strong></p>
<p>Large language models (LLMs) are revolutionizing self driving laboratories (SDLs) for materials research, promising unprecedented acceleration of scientific discovery. However, current SDL implementations rely on rigid protocols that fail to capture the adaptability and intuition of expert scientists in dynamic experimental settings. We introduce Artificially Intelligent Lab Assistant (AILA), a framework automating atomic force microscopy through LLM driven agents. Further, we develop AFMBench a comprehensive evaluation suite challenging AI agents across the complete scientific workflow from experimental design to results analysis. We find that state of the art models struggle with basic tasks and coordination scenarios. Notably, Claude 3.5 sonnet performs unexpectedly poorly despite excelling in materials domain question answering (QA) benchmarks, revealing that domain specific QA proficiency does not necessarily translate to effective agentic capabilities. Additionally, we observe that LLMs can deviate from instructions, raising safety alignment concerns for SDL applications. Our ablations reveal that multi agent frameworks outperform single-agent architectures. We also observe significant prompt fragility, where slight modifications in prompt structure cause substantial performance variations in capable models like GPT 4o. Finally, we evaluate AILAâ€™s effectiveness in increasingly advanced experiments AFM calibration, feature detection, mechanical property measurement, graphene layer counting, and indenter detection. Our findings underscore the necessity for rigorous benchmarking protocols and prompt engineering strategies before deploying AI laboratory assistants in scientific research environments. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨ä¸ºææ–™ç ”ç©¶çš„è‡ªåŠ¨é©¾é©¶å®éªŒå®¤ï¼ˆSDLï¼‰å¸¦æ¥é©å‘½æ€§çš„å˜é©ï¼Œå¹¶æœ‰æœ›ä¸ºç§‘å­¦å‘ç°å¸¦æ¥å‰æ‰€æœªæœ‰çš„åŠ é€Ÿã€‚ç„¶è€Œï¼Œå½“å‰çš„SDLå®ç°ä¾èµ–äºä¸¥æ ¼çš„åè®®ï¼Œè¿™äº›åè®®æœªèƒ½æ•æ‰åˆ°åŠ¨æ€å®éªŒç¯å¢ƒä¸­ä¸“å®¶ç§‘å­¦å®¶çš„é€‚åº”æ€§å’Œç›´è§‰ã€‚æˆ‘ä»¬å¼•å…¥äº†äººå·¥æ™ºèƒ½å®éªŒå®¤åŠ©æ‰‹ï¼ˆAILAï¼‰è¿™ä¸€æ¡†æ¶ï¼Œé€šè¿‡LLMé©±åŠ¨çš„ä»£ç†å®ç°åŸå­åŠ›æ˜¾å¾®é•œçš„è‡ªåŠ¨åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†AFMBenchè¯„ä¼°å¥—ä»¶ï¼Œå…¨é¢æŒ‘æˆ˜ä»å®éªŒè®¾è®¡åˆ°ç»“æœåˆ†ææ•´ä¸ªç§‘å­¦å·¥ä½œæµç¨‹çš„AIä»£ç†ã€‚æˆ‘ä»¬å‘ç°ï¼Œæœ€å…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹åœ¨åŸºæœ¬ä»»åŠ¡å’Œåè°ƒåœºæ™¯æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡Claude 3.5 sonnetåœ¨ææ–™é¢†åŸŸé—®ç­”ï¼ˆQAï¼‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å®é™…æ‰§è¡Œä¸­è¡¨ç°ä¸ä½³ï¼Œè¿™è¡¨æ˜ç‰¹å®šé¢†åŸŸçš„é—®ç­”èƒ½åŠ›å¹¶ä¸ä¸€å®šèƒ½è½¬åŒ–ä¸ºæœ‰æ•ˆçš„ä»£ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°LLMä¼šåç¦»æŒ‡ä»¤ï¼Œè¿™ç»™SDLåº”ç”¨ç¨‹åºçš„å®‰å…¨å¯¹é½å¸¦æ¥äº†æ‹…å¿§ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå¤šä»£ç†æ¡†æ¶ä¼˜äºå•ä»£ç†æ¶æ„ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°æ˜¾è‘—çš„æç¤ºè„†å¼±æ€§ï¼Œå³æç¤ºç»“æ„çš„å¾®å°å˜åŒ–ä¼šå¯¼è‡´å¦‚GPT 4oç­‰èƒ½åŠ›æ¨¡å‹çš„æ€§èƒ½å‡ºç°å·¨å¤§å˜åŒ–ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨è¶Šæ¥è¶Šå…ˆè¿›çš„å®éªŒä¸­è¯„ä¼°äº†AILAçš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬åŸå­åŠ›æ˜¾å¾®é•œæ ¡å‡†ã€ç‰¹å¾æ£€æµ‹ã€æœºæ¢°æ€§èƒ½æµ‹é‡ã€çŸ³å¢¨çƒ¯å±‚è®¡æ•°å’Œå‹ç—•æ£€æµ‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨éƒ¨ç½²äººå·¥æ™ºèƒ½å®éªŒå®¤åŠ©æ‰‹è¿›è¡Œç§‘å­¦ç ”ç©¶çš„ç¯å¢ƒä¸­ï¼Œè¿›è¡Œä¸¥æ ¼çš„åŸºå‡†æµ‹è¯•åè®®å’Œæç¤ºå·¥ç¨‹ç­–ç•¥çš„å¿…è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10385v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨ä¸ºææ–™ç ”ç©¶çš„è‡ªåŠ¨é©¾é©¶å®éªŒå®¤ï¼ˆSDLï¼‰å¸¦æ¥é©å‘½æ€§å˜é©ï¼ŒåŠ é€Ÿäº†ç§‘å­¦å‘ç°çš„é€Ÿåº¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„SDLå®ç°ä¾èµ–äºåƒµåŒ–çš„åè®®ï¼Œæ— æ³•æ•è·åŠ¨æ€å®éªŒç¯å¢ƒä¸­ä¸“å®¶ç§‘å­¦å®¶çš„é€‚åº”æ€§å’Œç›´è§‰ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†äººå·¥æ™ºèƒ½å®éªŒå®¤åŠ©æ‰‹ï¼ˆAILAï¼‰æ¡†æ¶ï¼Œé€šè¿‡LLMé©±åŠ¨çš„æ™ºèƒ½ä½“è‡ªåŠ¨åŒ–åŸå­åŠ›æ˜¾å¾®é•œã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼€å‘äº†AFMBenchè¯„ä¼°å¥—ä»¶ï¼Œå…¨é¢æŒ‘æˆ˜ä»å®éªŒè®¾è®¡åˆ°ç»“æœåˆ†æçš„æ•´ä¸ªç§‘å­¦å·¥ä½œæµç¨‹ä¸­çš„AIæ™ºèƒ½ä½“ã€‚ç ”ç©¶å‘ç°åœ¨å®é™…åœºæ™¯ä¸­ï¼Œå‰æ²¿æ¨¡å‹åœ¨åŸºæœ¬ä»»åŠ¡å’Œåè°ƒåœºæ™¯æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°LLMå¯èƒ½åç¦»æŒ‡ä»¤çš„é—®é¢˜ï¼Œå¼•å‘äº†SDLåº”ç”¨çš„å®‰å…¨å¯¹é½æ‹…å¿§ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¿˜è¡¨æ˜å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¼˜äºå•æ™ºèƒ½ä½“æ¶æ„ã€‚æœ€åï¼Œæˆ‘ä»¬è¯„ä¼°äº†AILAåœ¨AFMæ ¡å‡†ã€ç‰¹å¾æ£€æµ‹ã€æœºæ¢°æ€§èƒ½æµ‹è¯•ã€çŸ³å¢¨çƒ¯å±‚è®¡æ•°å’Œå°ç—•æ£€æµ‹ç­‰é«˜çº§å®éªŒä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨å°†AIå®éªŒå®¤åŠ©æ‰‹éƒ¨ç½²äºç§‘å­¦ç ”ç©¶ç¯å¢ƒä¹‹å‰ï¼Œéœ€è¦ä¸¥æ ¼çš„åŸºå‡†æµ‹è¯•åè®®å’Œæç¤ºå·¥ç¨‹ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨åŠ é€Ÿææ–™ç ”ç©¶çš„è‡ªåŠ¨é©¾é©¶å®éªŒå®¤ï¼ˆSDLï¼‰çš„ç§‘å­¦å‘ç°è¿‡ç¨‹ã€‚</li>
<li>ç°æœ‰SDLå®ç°ç¼ºä¹é€‚åº”æ€§å’Œç›´è§‰ï¼Œæ— æ³•æ¨¡æ‹Ÿä¸“å®¶ç§‘å­¦å®¶åœ¨åŠ¨æ€å®éªŒç¯å¢ƒä¸­çš„è¡Œä¸ºã€‚</li>
<li>å¼•å…¥äººå·¥æ™ºèƒ½å®éªŒå®¤åŠ©æ‰‹ï¼ˆAILAï¼‰æ¡†æ¶å’ŒAFMBenchè¯„ä¼°å¥—ä»¶ï¼Œä»¥è‡ªåŠ¨åŒ–åŸå­åŠ›æ˜¾å¾®é•œå¹¶å…¨é¢è¯„ä¼°AIæ™ºèƒ½ä½“åœ¨ç§‘å­¦å·¥ä½œæµç¨‹ä¸­çš„è¡¨ç°ã€‚</li>
<li>å³ä½¿æ˜¯å‰æ²¿æ¨¡å‹ï¼Œåœ¨åŸºæœ¬ä»»åŠ¡å’Œåè°ƒåœºæ™¯æ–¹é¢ä¹Ÿå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>LLMå¯èƒ½åç¦»æŒ‡ä»¤ï¼Œå¼•å‘SDLåº”ç”¨çš„å®‰å…¨é—®é¢˜ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“æ¡†æ¶åœ¨æ€§èƒ½ä¸Šä¼˜äºå•æ™ºèƒ½ä½“æ¶æ„ã€‚</li>
<li>åœ¨å°†AIå®éªŒå®¤åŠ©æ‰‹éƒ¨ç½²äºç§‘å­¦ç ”ç©¶ç¯å¢ƒå‰ï¼Œéœ€ä¸¥æ ¼çš„åŸºå‡†æµ‹è¯•åè®®å’Œæç¤ºå·¥ç¨‹ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10385">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-40d07222298af6520d7fe72ac94dbd32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c9c4178947120c0782d2eceb0894117.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60d1b4a4175a01c9cdbbea6ad554c87a.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cbfeb5646c4011c48924e41eea6906a4.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  AI-Driven Cytomorphology Image Synthesis for Medical Diagnostics
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-8488f236b5f9be3b34f1f4606e1c9fe7.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  Beyond Simple Edits X-Planner for Complex Instruction-Based Image   Editing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28292.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
