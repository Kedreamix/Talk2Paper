<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  Physics-Guided Dual Implicit Neural Representations for Source   Separation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-d7eb80ed294d5066d687ba220eab3c79.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    85 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-09-æ›´æ–°"><a href="#2025-07-09-æ›´æ–°" class="headerlink" title="2025-07-09 æ›´æ–°"></a>2025-07-09 æ›´æ–°</h1><h2 id="Physics-Guided-Dual-Implicit-Neural-Representations-for-Source-Separation"><a href="#Physics-Guided-Dual-Implicit-Neural-Representations-for-Source-Separation" class="headerlink" title="Physics-Guided Dual Implicit Neural Representations for Source   Separation"></a>Physics-Guided Dual Implicit Neural Representations for Source   Separation</h2><p><strong>Authors:Yuan Ni, Zhantao Chen, Alexander N. Petsch, Edmund Xu, Cheng Peng, Alexander I. Kolesnikov, Sugata Chowdhury, Arun Bansil, Jana B. Thayer, Joshua J. Turner</strong></p>
<p>Significant challenges exist in efficient data analysis of most advanced experimental and observational techniques because the collected signals often include unwanted contributionsâ€“such as background and signal distortionsâ€“that can obscure the physically relevant information of interest. To address this, we have developed a self-supervised machine-learning approach for source separation using a dual implicit neural representation framework that jointly trains two neural networks: one for approximating distortions of the physical signal of interest and the other for learning the effective background contribution. Our method learns directly from the raw data by minimizing a reconstruction-based loss function without requiring labeled data or pre-defined dictionaries. We demonstrate the effectiveness of our framework by considering a challenging case study involving large-scale simulated as well as experimental momentum-energy-dependent inelastic neutron scattering data in a four-dimensional parameter space, characterized by heterogeneous background contributions and unknown distortions to the target signal. The method is found to successfully separate physically meaningful signals from a complex or structured background even when the signal characteristics vary across all four dimensions of the parameter space. An analytical approach that informs the choice of the regularization parameter is presented. Our method offers a versatile framework for addressing source separation problems across diverse domains, ranging from superimposed signals in astronomical measurements to structural features in biomedical image reconstructions. </p>
<blockquote>
<p>åœ¨å¤§å¤šæ•°å…ˆè¿›çš„å®éªŒå’Œè§‚æµ‹æŠ€æœ¯çš„æœ‰æ•ˆæ•°æ®åˆ†ææ–¹é¢å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºæ”¶é›†çš„ä¿¡å·é€šå¸¸åŒ…æ‹¬ä¸éœ€è¦çš„è´¡çŒ®ï¼Œä¾‹å¦‚èƒŒæ™¯å’Œä¿¡å·å¤±çœŸï¼Œè¿™å¯èƒ½ä¼šæ©ç›–ä¸ç‰©ç†ç›¸å…³çš„æ„Ÿå…´è¶£çš„ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºåŒéšç¥ç»è¡¨ç¤ºæ¡†æ¶çš„è‡ªç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œæºåˆ†ç¦»ï¼Œè¯¥æ¡†æ¶è”åˆè®­ç»ƒä¸¤ä¸ªç¥ç»ç½‘ç»œï¼šä¸€ä¸ªç”¨äºè¿‘ä¼¼æ„Ÿå…´è¶£çš„ç‰©ç†ä¿¡å·çš„å¤±çœŸï¼Œå¦ä¸€ä¸ªç”¨äºå­¦ä¹ æœ‰æ•ˆçš„èƒŒæ™¯è´¡çŒ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ï¼Œé€šè¿‡æœ€å°åŒ–åŸºäºé‡å»ºçš„æŸå¤±å‡½æ•°ï¼Œæ— éœ€æ ‡è®°çš„æ•°æ®æˆ–é¢„å…ˆå®šä¹‰çš„è¯å…¸ã€‚æˆ‘ä»¬é€šè¿‡è€ƒè™‘æ¶‰åŠå¤§è§„æ¨¡æ¨¡æ‹Ÿä»¥åŠå®éªŒåŠ¨é‡èƒ½é‡ä¾èµ–çš„éå¼¹æ€§ä¸­å­æ•£å°„æ•°æ®çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ˆä¾‹ç ”ç©¶æ¥å±•ç¤ºæˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œè¯¥æ•°æ®åœ¨ç”±å¼‚è´¨èƒŒæ™¯è´¡çŒ®å’ŒæœªçŸ¥ç›®æ ‡ä¿¡å·å¤±çœŸè¡¨å¾çš„å››ç»´å‚æ•°ç©ºé—´ä¸­ã€‚è¯¥æ–¹æ³•å³ä½¿åœ¨ä¿¡å·ç‰¹å¾åœ¨å‚æ•°ç©ºé—´çš„æ‰€æœ‰å››ä¸ªç»´åº¦ä¸Šéƒ½å‘ç”Ÿå˜åŒ–æ—¶ï¼Œä¹Ÿèƒ½æˆåŠŸåœ°ä»å¤æ‚æˆ–ç»“æ„åŒ–èƒŒæ™¯ä¸­åˆ†ç¦»å‡ºç‰©ç†ä¸Šæœ‰æ„ä¹‰çš„ä¿¡å·ã€‚ç»™å‡ºäº†ä¸€ä¸ªåˆ†ææ–¹æ³•æ¥æŒ‡å¯¼æ­£åˆ™åŒ–å‚æ•°çš„é€‰æ‹©ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºè§£å†³ä¸åŒé¢†åŸŸçš„æºåˆ†ç¦»é—®é¢˜æä¾›äº†ä¸€ä¸ªé€šç”¨çš„æ¡†æ¶ï¼ŒèŒƒå›´ä»å¤©æ–‡æµ‹é‡ä¸­çš„å åŠ ä¿¡å·åˆ°ç”Ÿç‰©åŒ»å­¦å›¾åƒé‡å»ºä¸­çš„ç»“æ„ç‰¹å¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05249v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨åŒéšç¥ç»ç½‘ç»œè¡¨ç¤ºæ¡†æ¶çš„è‡ªç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œæºåˆ†ç¦»ã€‚è¯¥æ–¹æ³•é€šè¿‡ç›´æ¥æœ€å°åŒ–åŸºäºé‡å»ºçš„æŸå¤±å‡½æ•°æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ï¼Œæ— éœ€æ ‡è®°æ•°æ®æˆ–é¢„å®šä¹‰è¯å…¸ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†å¤§å‹æ¨¡æ‹Ÿå’Œå®éªŒåŠ¨é‡èƒ½é‡ä¾èµ–å¼¹æ€§ä¸­å­æ•£å°„æ•°æ®æ—¶ï¼Œå³ä½¿åœ¨å››ç»´å‚æ•°ç©ºé—´ä¸­ä¿¡å·ç‰¹æ€§å‘ç”Ÿå˜åŒ–æ—¶ï¼Œä¹Ÿèƒ½æˆåŠŸåˆ†ç¦»å‡ºç‰©ç†æ„ä¹‰æ˜æ˜¾çš„ä¿¡å·ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§åˆ†ææ­£åˆ™åŒ–å‚æ•°é€‰æ‹©çš„åˆ†ææ–¹æ³•ï¼Œå¹¶æŒ‡å‡ºè¯¥æ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºä¸åŒé¢†åŸŸä¸­çš„æºåˆ†ç¦»é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æºåˆ†ç¦»æ˜¯å¤„ç†å®éªŒå’Œè§‚æµ‹æ•°æ®çš„é‡è¦æŒ‘æˆ˜ï¼Œå› ä¸ºæ”¶é›†çš„ä¿¡å·é€šå¸¸åŒ…å«èƒŒæ™¯å’Œä¸æƒ³è¦çš„å¤±çœŸã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºåŒéšç¥ç»ç½‘ç»œè¡¨ç¤ºæ¡†æ¶çš„è‡ªç›‘ç£æœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œæºåˆ†ç¦»ã€‚</li>
<li>æ–¹æ³•ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ï¼Œé€šè¿‡æœ€å°åŒ–é‡å»ºæŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼Œæ— éœ€æ ‡è®°æ•°æ®æˆ–é¢„å®šä¹‰è¯å…¸ã€‚</li>
<li>æ–¹æ³•åœ¨å¤„ç†å¤§å‹æ¨¡æ‹Ÿå’Œå®éªŒåŠ¨é‡èƒ½é‡ä¾èµ–å¼¹æ€§ä¸­å­æ•£å°„æ•°æ®æ—¶è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚</li>
<li>å³ä½¿åœ¨å››ç»´å‚æ•°ç©ºé—´ä¸­ä¿¡å·ç‰¹æ€§å˜åŒ–æ—¶ï¼Œä¹Ÿèƒ½æˆåŠŸåˆ†ç¦»ç‰©ç†æ„ä¹‰æ˜æ˜¾çš„ä¿¡å·ã€‚</li>
<li>æä¾›äº†ä¸€ç§åˆ†ææ­£åˆ™åŒ–å‚æ•°é€‰æ‹©çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05249">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3aa387d01c76437aa27c12daf5dd1a45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-584bb7bbd1c8ebc26aa15c1eb58c8e6c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Tianguan-Î¶-Tau-as-a-binary-system-consisting-of-a-Be-star-and-an-accreting-White-Dwarf-opening-a-gate-to-understanding-enigmatic-Î³-Cas-analogues"><a href="#Tianguan-Î¶-Tau-as-a-binary-system-consisting-of-a-Be-star-and-an-accreting-White-Dwarf-opening-a-gate-to-understanding-enigmatic-Î³-Cas-analogues" class="headerlink" title="TiÄnguÄn ($Î¶$ Tau) as a binary system consisting of a   Be-star and an accreting White Dwarf: opening a gate to understanding   enigmatic $Î³$ Cas analogues"></a>TiÄnguÄn ($Î¶$ Tau) as a binary system consisting of a   Be-star and an accreting White Dwarf: opening a gate to understanding   enigmatic $Î³$ Cas analogues</h2><p><strong>Authors:JesÃºs A. ToalÃ¡, Lidia M. Oskinova, Diego A. Vasquez-Torres</strong></p>
<p>The analogues of $\gamma$ Cassiopea are binary early type Be stars which are X-ray bright and have hard thermal X-ray spectra. The nature of low-mass companions in these stars and mechanisms of their X-ray emission remain enigmatic. Among the proposed ideas is the presence of an accretion disc around a white dwarf (WD) companion to the Be star donor. We use modern radiative transfer models accounting for reflection physics in order to calculate the synthetic spectra of such systems, and assume that the hottest plasma is thermal and is located in the accretion disc boundary layer. The models are then used to analyse the archival X-ray observations of the $\gamma$ Cas analogue $\zeta$ Tau (a.k.a. Ti={a}ngu={a}n) which were obtained by the XMM-Newton telescope. Comparisons with X-ray-emitting symbiotic systems, particularly $\delta$- and $\beta&#x2F;\delta$-type systems, support the idea that the hard X-ray emission in $\zeta$ Tau is best explained by a WD accreting wind material of the Be star. The plasma temperature and luminosity of the boundary layer associated with the accretion disc are used to estimate a mass accretion rate of $\dot{M}_\mathrm{acc} \approx 4\times 10^{-10}$ M$_\odot$ yr$^{-1}$, implying a nova recurrence time above 10$^{5}$ yr. Our analysis advances the understanding the production of hard X-ray emission in $\gamma$ Cas analogues, further supporting the idea of accreting WDs as companions of Be-stars in these systems. </p>
<blockquote>
<p>Î³ä»™ååº§çš„ç±»ä¼¼ç‰©æ˜¯æ—©æœŸç±»å‹çš„BeåŒæ˜Ÿï¼Œå®ƒä»¬Xå°„çº¿äº®åº¦é«˜ä¸”å…·æœ‰ç¡¬çƒ­Xå°„çº¿å…‰è°±ã€‚è¿™äº›æ’æ˜Ÿä¸­çš„ä½è´¨é‡ä¼´æ˜Ÿä»¥åŠå®ƒä»¬çš„Xå°„çº¿å‘å°„æœºåˆ¶ä»ç„¶æ˜¯ä¸ªè°œã€‚å…¶ä¸­æå‡ºçš„æƒ³æ³•ä¹‹ä¸€æ˜¯å­˜åœ¨å›´ç»•Beæ˜Ÿä¾›ä½“çš„ç™½çŸ®æ˜Ÿï¼ˆWDï¼‰ä¼´æ˜Ÿçš„ä¸€ä¸ªå¸ç§¯ç›˜ã€‚æˆ‘ä»¬ä½¿ç”¨è€ƒè™‘åå°„ç‰©ç†çš„ç°ä»£è¾å°„ä¼ é€’æ¨¡å‹æ¥è®¡ç®—è¿™ç§ç³»ç»Ÿçš„åˆæˆå…‰è°±ï¼Œå¹¶å‡è®¾æœ€çƒ­çš„ç­‰ç¦»å­ä½“æ˜¯çƒ­æ€å¹¶ä¸”ä½äºå¸ç§¯ç›˜è¾¹ç•Œå±‚ä¸­ã€‚ç„¶åï¼Œè¿™äº›æ¨¡å‹è¢«ç”¨æ¥åˆ†æç”±XMM-ç‰›é¡¿æœ›è¿œé•œè·å¾—çš„Î³ä»™ååº§ç±»ä¼¼ç‰©Î¶é‡‘ç‰›æ˜Ÿï¼ˆä¹Ÿç§°ä¸ºTiÄnguÄnï¼‰çš„æ¡£æ¡ˆXå°„çº¿è§‚æµ‹ç»“æœã€‚ä¸Xå°„çº¿å‘å°„çš„å…±ç”Ÿç³»ç»Ÿï¼ˆç‰¹åˆ«æ˜¯Î´å‹å’ŒÎ²&#x2F;Î´å‹ç³»ç»Ÿï¼‰çš„æ¯”è¾ƒæ”¯æŒè¿™ä¸€è§‚ç‚¹ï¼Œå³Î¶é‡‘ç‰›æ˜Ÿçš„ç¡¬Xå°„çº¿å‘å°„æœ€å¥½ç”¨ç™½çŸ®æ˜Ÿå¸æ”¶é£ç‰©è´¨æ¥è§£é‡Šã€‚ä¸å¸ç§¯ç›˜ç›¸å…³çš„è¾¹ç•Œå±‚çš„ç­‰ç¦»å­ä½“æ¸©åº¦å’Œå…‰åº¦è¢«ç”¨æ¥ä¼°è®¡è´¨é‡å¸ç§¯ç‡$\dot{M}_\mathrm{acc} \approx 4\times 10^{-10}$ MâŠ™yr^-1ï¼Œè¿™æ„å‘³ç€æ–°æ˜Ÿå†ç°æ—¶é—´è¶…è¿‡10^5å¹´ã€‚æˆ‘ä»¬çš„åˆ†ææ¨è¿›äº†å¯¹Î³ä»™ååº§ç±»ä¼¼ç‰©äº§ç”Ÿç¡¬Xå°„çº¿å‘å°„çš„ç†è§£ï¼Œè¿›ä¸€æ­¥æ”¯æŒäº†åœ¨è¿™äº›ç³»ç»Ÿä¸­å¸æ”¶ç™½çŸ®æ˜Ÿä½œä¸ºBeæ˜Ÿçš„ä¼´æ˜Ÿçš„æƒ³æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05203v1">PDF</a> 7 pages, 6 figures, 1 table; Submitted to MNRAS (comments are   welcome)</p>
<p><strong>Summary</strong><br>    Î³å‹ä»™ååº§ç±»ä¼¼æ˜Ÿä½“çš„Xå°„çº¿å‘å°„æœºåˆ¶å’Œä½è´¨é‡ä¼´ä¾£æ˜Ÿçš„æ€§è´¨ä»ç„¶ç¥ç§˜ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨è¾å°„ä¼ è¾“æ¨¡å‹è®¡ç®—è¿™ç±»ç³»ç»Ÿçš„åˆæˆå…‰è°±ï¼Œå¹¶å‡è®¾æœ€çƒ­çš„ç­‰ç¦»å­ä½“ä½äºå¸ç§¯ç›˜è¾¹ç•Œå±‚ï¼Œå‘ˆçƒ­æ€ã€‚é€šè¿‡å¯¹Ï„å‹ä»™å¥³çš„XMM-ç‰›é¡¿æœ›è¿œé•œå­˜æ¡£Xå°„çº¿è§‚æµ‹æ•°æ®çš„åˆ†æï¼Œä»¥åŠä¸å‘å°„Xå°„çº¿çš„å…±ç”Ÿç³»ç»Ÿçš„æ¯”è¾ƒï¼Œæ”¯æŒäº†WDå¸ç§¯Beæ˜Ÿé£ç‰©è´¨äº§ç”Ÿç¡¬Xå°„çº¿å‘å°„çš„è§‚ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Î³å‹ä»™ååº§ç±»ä¼¼æ˜Ÿä½“æ˜¯Xå°„çº¿æ˜äº®çš„æ—©æœŸå‹BeåŒæ˜Ÿï¼Œå…·æœ‰ç¡¬çƒ­Xå°„çº¿å…‰è°±ç‰¹å¾ã€‚</li>
<li>è¿™äº›æ˜Ÿä½“çš„ä½è´¨é‡ä¼´ä¾£æ˜Ÿå’ŒXå°„çº¿å‘å°„æœºåˆ¶ä»ç„¶ä¸æ¸…æ¥šã€‚</li>
<li>è¾å°„ä¼ è¾“æ¨¡å‹è¢«ç”¨æ¥è®¡ç®—è¿™ç±»æ˜Ÿä½“çš„åˆæˆå…‰è°±ï¼Œå¹¶å‡è®¾æœ€çƒ­çš„ç­‰ç¦»å­ä½“ä½äºå¸ç§¯ç›˜è¾¹ç•Œå±‚ã€‚</li>
<li>å¯¹Î¶ Tauï¼ˆå³å¤©è‹‘ï¼‰çš„XMM-ç‰›é¡¿æœ›è¿œé•œå­˜æ¡£Xå°„çº¿è§‚æµ‹æ•°æ®çš„åˆ†ææ”¯æŒäº†WDå¸ç§¯Beæ˜Ÿé£ç‰©è´¨äº§ç”Ÿç¡¬Xå°„çº¿å‘å°„çš„è§‚ç‚¹ã€‚</li>
<li>ç­‰ç¦»å­ä½“æ¸©åº¦å’Œè¾¹ç•Œå±‚å…‰åº¦è¢«ç”¨æ¥ä¼°è®¡å¸ç§¯ç›˜çš„è´¨é‡å¸ç§¯ç‡çº¦ä¸º4Ã—10^-10 MâŠ• yr^-1ã€‚</li>
<li>è¿™æš—ç¤ºäº†æ–°æ˜Ÿå¤å‘çš„å‘¨æœŸè¶…è¿‡10^5å¹´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05203">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ce2829a8e00cb1ee3b0c8752f04f274d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79fd847f00029c36b4d6bbe2a02505cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9f62fb29e7dafac95bb31fe7afc019ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1286f5e3cc1ed933677725001da601c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8ac61995e7d4b48519cbd73326c79b6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e724b9941a900c515b2e69affd971490.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b2a1a8e2924f149e0f7d62f28e4e9b0a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MedGemma-Technical-Report"><a href="#MedGemma-Technical-Report" class="headerlink" title="MedGemma Technical Report"></a>MedGemma Technical Report</h2><p><strong>Authors:Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil, CÃ­an Hughes, Charles Lau, Justin Chen, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Stefanie Anna Baby, Susanna Maria Baby, Jeremy Lai, Samuel Schmidgall, Lu Yang, Kejia Chen, Per Bjornsson, Shashir Reddy, Ryan Brush, Kenneth Philbrick, Howard Hu, Howard Yang, Richa Tiwari, Sunny Jansen, Preeti Singh, Yun Liu, Shekoofeh Azizi, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre RamÃ©, Morgane Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean-bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Elena Buchatskaya, Jean-Baptiste Alayrac,  Dmitry,  Lepikhin, Vlad Feinberg, Sebastian Borgeaud, Alek Andreev, Cassidy Hardin, Robert Dadashi, LÃ©onard Hussenot, Armand Joulin, Olivier Bachem, Yossi Matias, Katherine Chou, Avinatan Hassidim, Kavi Goel, Clement Farabet, Joelle Barral, Tris Warkentin, Jonathon Shlens, David Fleet, Victor Cotruta, Omar Sanseviero, Gus Martins, Phoebe Kirk, Anand Rao, Shravya Shetty, David F. Steiner, Can Kirmizibayrak, Rory Pilgrim, Daniel Golden, Lin Yang</strong></p>
<p>Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcareâ€™s diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10% improvement on medical multimodal question answering, 15.5-18.1% improvement on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at <a target="_blank" rel="noopener" href="https://goo.gle/medgemma">https://goo.gle/medgemma</a>. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨åŒ»ç–—åº”ç”¨æ–¹é¢æ‹¥æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œä½†ç”±äºåŒ»ç–—æ•°æ®çš„å¤šæ ·æ€§ã€ä»»åŠ¡çš„å¤æ‚æ€§ä»¥åŠéœ€è¦ä¿æŠ¤éšç§ï¼Œå…¶åœ¨è®­ç»ƒå’Œéƒ¨ç½²æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚èƒ½å¤Ÿåœ¨åŒ»ç–—ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ä¸”éœ€è¦è¾ƒå°‘ä»»åŠ¡ç‰¹å®šè°ƒæ•´æ•°æ®çš„åŸºç¡€æ¨¡å‹ï¼Œå¯¹äºåŠ é€ŸåŒ»ç–—AIåº”ç”¨çš„å¼€å‘è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¼•å…¥äº†MedGemmaï¼Œè¿™æ˜¯ä¸€ç³»åˆ—åŸºäºGemma 3 4Bå’Œ27Bçš„åŒ»ç–—è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹çš„é›†åˆã€‚MedGemmaå±•ç¤ºäº†å…ˆè¿›çš„åŒ»ç–—ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œåœ¨å›¾åƒå’Œæ–‡æœ¬ä¸Šè¶…è¶Šäº†ç±»ä¼¼å¤§å°çš„ç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ¥è¿‘ä»»åŠ¡ç‰¹å®šæ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†Gemma 3åŸºç¡€æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚å¯¹äºç¦»åˆ†å¸ƒä»»åŠ¡ï¼ŒMedGemmaåœ¨åŒ»ç–—å¤šæ¨¡å¼é—®ç­”ä¸Šå®ç°äº†2.6-10%çš„æ”¹è¿›ï¼Œåœ¨èƒ¸éƒ¨Xå°„çº¿æ£€æŸ¥ç»“æœåˆ†ç±»ä¸Šå®ç°äº†15.5-18.1%çš„æ”¹è¿›ï¼Œåœ¨æ™ºèƒ½è¯„ä¼°ä¸Šå®ç°äº†10.8%çš„æ”¹è¿›ï¼Œç›¸è¾ƒäºåŸºç¡€æ¨¡å‹æœ‰æ‰€æå‡ã€‚è¿›ä¸€æ­¥å¾®è°ƒMedGemmaå¯ä»¥åœ¨å­åŸŸä¸­æé«˜æ€§èƒ½ï¼Œå°†ç”µå­ç—…å†ä¿¡æ¯æ£€ç´¢ä¸­çš„é”™è¯¯å‡å°‘50%ï¼Œå¹¶è¾¾åˆ°æ°”èƒ¸åˆ†ç±»å’Œç»„ç»‡å­¦æ–‘å—åˆ†ç±»çš„ç°æœ‰æœ€æ–°ä¸“ä¸šæ–¹æ³•çš„å¯æ¯”æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†MedSigLIPï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡åŒ»å­¦è°ƒæ•´çš„è§†è§‰ç¼–ç å™¨ï¼ŒæºäºSigLIPã€‚MedSigLIPä¸ºMedGemmaçš„è§†è§‰ç†è§£èƒ½åŠ›æä¾›æ”¯æŒï¼Œä½œä¸ºç¼–ç å™¨ï¼Œå…¶æ€§èƒ½ä¸ä¸“ç”¨åŒ»ç–—å›¾åƒç¼–ç å™¨ç›¸å½“æˆ–æ›´å¥½ã€‚æ€»ä½“è€Œè¨€ï¼ŒMedGemmaç³»åˆ—æä¾›äº†å¼ºå¤§çš„åŒ»ç–—å›¾åƒå’Œæ–‡æœ¬èƒ½åŠ›åŸºç¡€ï¼Œå…·æœ‰åŠ é€ŸåŒ»ç–—ç ”ç©¶å’Œä¸‹æ¸¸åº”ç”¨å¼€å‘çš„å·¨å¤§æ½œåŠ›ã€‚MedGemmaç³»åˆ—ï¼ŒåŒ…æ‹¬æ•™ç¨‹å’Œæ¨¡å‹æƒé‡ï¼Œå¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://goo.gle/medgemma%E6%89%BE%E5%88%B0%E3%80%82">https://goo.gle/medgemmaæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05201v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>AIåœ¨åŒ»ç–—ä¿å¥åº”ç”¨æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å…¶è®­ç»ƒå’Œéƒ¨ç½²é¢ä¸´å¤šæ ·åŒ–æ•°æ®ã€å¤æ‚ä»»åŠ¡å’Œéšç§ä¿æŠ¤ç­‰æ–¹é¢çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥MedGemmaï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäºGemma 3 4Bå’Œ27Bçš„åŒ»ç–—è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹é›†åˆã€‚MedGemmaåœ¨å›¾åƒå’Œæ–‡æœ¬ä¸Šå±•ç°å‡ºé«˜çº§åŒ»ç–—ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç±»ä¼¼å¤§å°çš„ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶æ¥è¿‘ä»»åŠ¡ç‰¹å®šæ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒGemma 3åŸºç¡€æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚å¯¹äºç¦»ç¾¤ä»»åŠ¡ï¼ŒMedGemmaåœ¨åŒ»ç–—å¤šæ¨¡å¼é—®ç­”ã€èƒ¸éƒ¨Xå°„çº¿å‘ç°åˆ†ç±»å’Œæ™ºèƒ½ä½“è¯„ä¼°ç­‰æ–¹é¢ç›¸æ¯”åŸºç¡€æ¨¡å‹æœ‰æ‰€æ”¹å–„ã€‚å¾®è°ƒMedGemmaå¯è¿›ä¸€æ­¥æé«˜å­åŸŸçš„æ€§èƒ½ï¼Œå‡å°‘ç”µå­å¥åº·è®°å½•ä¿¡æ¯æ£€ç´¢ä¸­çš„é”™è¯¯ï¼Œå¹¶è¾¾åˆ°æ°”èƒ¸åˆ†ç±»å’Œç»„ç»‡å­¦æ–‘å—åˆ†ç±»çš„ç°æœ‰ä¸“ä¸šæœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†MedSigLIPï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡åŒ»å­¦è°ƒæ•´çš„è§†è§‰ç¼–ç å™¨ã€‚ä½œä¸ºç¼–ç å™¨ï¼ŒMedSigLIPåœ¨MedGemmaçš„è§†è§‰ç†è§£èƒ½åŠ›æ–¹é¢å…·æœ‰å¼ºå¤§ä½œç”¨ï¼Œå…¶æ€§èƒ½å¯ä¸ä¸“ä¸šåŒ»ç–—å›¾åƒç¼–ç å™¨ç›¸å½“æˆ–æ›´å¥½ã€‚æ€»çš„æ¥è¯´ï¼ŒMedGemmaé›†åˆä¸ºåŒ»ç–—å›¾åƒå’Œæ–‡æœ¬åŠŸèƒ½æä¾›äº†åšå®çš„åŸºç¡€ï¼Œå…·æœ‰åŠ é€ŸåŒ»å­¦ç ”ç©¶å¹¶æ¨åŠ¨ä¸‹æ¸¸åº”ç”¨å¼€å‘æ½œåŠ›ã€‚å¯ä»¥åœ¨goo.gle&#x2F;medgemmaæ‰¾åˆ°MedGemmaé›†åˆï¼ˆåŒ…æ‹¬æ•™ç¨‹å’Œæ¨¡å‹æƒé‡ï¼‰ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>AIåœ¨åŒ»ç–—ä¿å¥åº”ç”¨ä¸­æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†é¢ä¸´æ•°æ®å¤šæ ·æ€§å’Œéšç§ä¿æŠ¤ç­‰æŒ‘æˆ˜ã€‚</li>
<li>MedGemmaæ˜¯ä¸€ä¸ªåŸºäºåŒ»ç–—è§†è§‰è¯­è¨€çš„åŸºç¡€æ¨¡å‹é›†åˆï¼Œå±•ç°å‡ºé«˜çº§åŒ»ç–—ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>MedGemmaç›¸è¾ƒäºç±»ä¼¼å¤§å°çš„ç”Ÿæˆæ¨¡å‹æœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶åœ¨æŸäº›ä»»åŠ¡ä¸Šæ¥è¿‘ä»»åŠ¡ç‰¹å®šæ¨¡å‹ã€‚</li>
<li>MedGemmaåœ¨å¤„ç†ç¦»ç¾¤ä»»åŠ¡æ—¶è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½æ”¹è¿›ã€‚</li>
<li>é€šè¿‡å¾®è°ƒMedGemmaå¯è¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‰¹å®šå­åŸŸä¸­ã€‚</li>
<li>MedSigLIPæ˜¯ä¸€ä¸ªç»è¿‡åŒ»å­¦è°ƒæ•´çš„è§†è§‰ç¼–ç å™¨ï¼Œä¸ºMedGemmaçš„è§†è§‰ç†è§£èƒ½åŠ›æä¾›äº†å¼ºå¤§æ”¯æŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f6766bc9fb4914421b21bc417c96bef3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-961e8abb96f57e2820969b90c43deaa9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b8acd3cd22d4d9615a20f9835d3cb2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-974e25151a35474d8b692fe8883e24cf.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SV-DRR-High-Fidelity-Novel-View-X-Ray-Synthesis-Using-Diffusion-Model"><a href="#SV-DRR-High-Fidelity-Novel-View-X-Ray-Synthesis-Using-Diffusion-Model" class="headerlink" title="SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model"></a>SV-DRR: High-Fidelity Novel View X-Ray Synthesis Using Diffusion Model</h2><p><strong>Authors:Chun Xie, Yuichi Yoshii, Itaru Kitahara</strong></p>
<p>X-ray imaging is a rapid and cost-effective tool for visualizing internal human anatomy. While multi-view X-ray imaging provides complementary information that enhances diagnosis, intervention, and education, acquiring images from multiple angles increases radiation exposure and complicates clinical workflows. To address these challenges, we propose a novel view-conditioned diffusion model for synthesizing multi-view X-ray images from a single view. Unlike prior methods, which are limited in angular range, resolution, and image quality, our approach leverages the Diffusion Transformer to preserve fine details and employs a weak-to-strong training strategy for stable high-resolution image generation. Experimental results demonstrate that our method generates higher-resolution outputs with improved control over viewing angles. This capability has significant implications not only for clinical applications but also for medical education and data extension, enabling the creation of diverse, high-quality datasets for training and analysis. Our code is available at GitHub. </p>
<blockquote>
<p>Xå°„çº¿æˆåƒæ˜¯ä¸€ç§å¿«é€Ÿä¸”æˆæœ¬æ•ˆç›Šé«˜çš„å·¥å…·ï¼Œç”¨äºå¯è§†åŒ–äººä½“å†…éƒ¨ç»“æ„ã€‚è™½ç„¶å¤šè§†è§’Xå°„çº¿æˆåƒæä¾›äº†è¡¥å……ä¿¡æ¯ï¼Œå¢å¼ºäº†è¯Šæ–­ã€å¹²é¢„å’Œæ•™è‚²ï¼Œä½†ä»å¤šä¸ªè§’åº¦è·å–å›¾åƒå¢åŠ äº†è¾å°„æš´éœ²å¹¶ä½¿å¾—ä¸´åºŠå·¥ä½œæµç¨‹å¤æ‚åŒ–ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹è§†è§’åˆæˆæ–¹æ³•ï¼Œå¯ä»¥ä»å•ä¸€è§†è§’åˆæˆå¤šè§†è§’Xå°„çº¿å›¾åƒã€‚ä¸åŒäºå…ˆå‰åœ¨è§’åº¦èŒƒå›´ã€åˆ†è¾¨ç‡å’Œå›¾åƒè´¨é‡æ–¹é¢æœ‰é™çš„æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨æ‰©æ•£å˜å‹å™¨æ¥ä¿ç•™ç»†èŠ‚ï¼Œå¹¶é‡‡ç”¨ç”±å¼±åˆ°å¼ºçš„è®­ç»ƒç­–ç•¥æ¥è¿›è¡Œç¨³å®šçš„é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆäº†æ›´é«˜åˆ†è¾¨ç‡çš„è¾“å‡ºï¼Œå¹¶å¢å¼ºäº†å¯¹æ¯”æ§åˆ¶è§†è§’çš„èƒ½åŠ›ã€‚è¿™é¡¹èƒ½åŠ›ä¸ä»…åœ¨ä¸´åºŠåº”ç”¨æ–¹é¢æœ‰ç€é‡å¤§æ„ä¹‰ï¼Œä¹Ÿåœ¨åŒ»ç–—æ•™è‚²å’Œæ•°æ®æ‰©å±•æ–¹é¢æœ‰ç€å·¨å¤§æ½œåŠ›ï¼Œèƒ½å¤Ÿåˆ›å»ºå¤šæ ·ä¸”é«˜è´¨é‡çš„æ•°æ®é›†ç”¨äºè®­ç»ƒå’Œæ•°æ®åˆ†æã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨GitHubä¸Šè·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05148v1">PDF</a> Accepted by MICCAI2025</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹å¤šè§†è§’Xå°„çº¿å›¾åƒåˆæˆæ–¹æ³•ï¼Œå¯ä»å•ä¸€è§†è§’åˆæˆå¤šè§†è§’Xå°„çº¿å›¾åƒã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£å˜å‹å™¨ä¿å­˜ç»†èŠ‚ï¼Œé‡‡ç”¨ç”±å¼±è‡³å¼ºçš„è®­ç»ƒç­–ç•¥å®ç°ç¨³å®šçš„é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„é«˜åˆ†è¾¨ç‡å›¾åƒå…·æœ‰æ›´å¥½çš„è§†è§’æ§åˆ¶åŠ›ï¼Œå¯¹ä¸´åºŠåº”ç”¨ã€åŒ»å­¦æ•™è‚²å’Œæ•°æ®æ‰©å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Xå°„çº¿æˆåƒæ˜¯ä¸€ç§å¿«é€Ÿã€ç»æµçš„å†…éƒ¨äººä½“ç»“æ„å¯è§†åŒ–å·¥å…·ã€‚</li>
<li>å¤šè§†è§’Xå°„çº¿æˆåƒèƒ½å¤Ÿæä¾›äº’è¡¥ä¿¡æ¯ï¼Œå¢å¼ºè¯Šæ–­ã€å¹²é¢„å’Œæ•™è‚²çš„æ•ˆæœã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤šè§†è§’Xå°„çº¿å›¾åƒåˆæˆæ–¹é¢å­˜åœ¨è§’åº¦èŒƒå›´ã€åˆ†è¾¨ç‡å’Œå›¾åƒè´¨é‡çš„å±€é™ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹åˆæˆæ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£å˜å‹å™¨ä¿å­˜ç»†èŠ‚å¹¶å®ç°é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨ç”±å¼±è‡³å¼ºçš„è®­ç»ƒç­–ç•¥ï¼Œå®ç°äº†ç¨³å®šçš„é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆå’Œå¯¹è§†è§’çš„è‰¯å¥½æ§åˆ¶ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„é«˜åˆ†è¾¨ç‡å›¾åƒå…·æœ‰æ›´å¥½çš„è§†è§’æ§åˆ¶åŠ›ï¼Œåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ï¼Œå¦‚ä¸´åºŠåº”ç”¨ã€åŒ»å­¦æ•™è‚²å’Œæ•°æ®æ‰©å±•ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05148">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0032098c9d5f8965e23647d08006d7f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d5e7fd55a80dc55ba7f842ff3712c7a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-019c69b8a9aa9d30242cd83bfa391eca.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Clinical-test-cases-for-model-based-dose-calculation-algorithm-commissioning-QA-and-benchmarking-for-192Ir-HDR-brachytherapy-of-gynecologic-cancers"><a href="#Clinical-test-cases-for-model-based-dose-calculation-algorithm-commissioning-QA-and-benchmarking-for-192Ir-HDR-brachytherapy-of-gynecologic-cancers" class="headerlink" title="Clinical test cases for model-based dose calculation algorithm   commissioning, QA and benchmarking, for 192Ir HDR brachytherapy of   gynecologic cancers"></a>Clinical test cases for model-based dose calculation algorithm   commissioning, QA and benchmarking, for 192Ir HDR brachytherapy of   gynecologic cancers</h2><p><strong>Authors:V. Peppa, M. Robitaille, F. Akbari, S. A. Enger, R. M. Thomson, F. Mourtada, G. P. Fonseca</strong></p>
<p>Purpose: To develop clinically relevant test cases for commissioning Model-Based Dose Calculation Algorithms (MBDCAs) for 192Ir High Dose Rate (HDR) gynecologic brachytherapy following the workflow proposed by the TG-186 report and the WGDCAB report 372. Acquisition and Validation Methods: Two cervical cancer intracavitary HDR brachytherapy patient models were created, using either uniformly structured regions or realistic segmentation. The computed tomography (CT) images of the models were converted to DICOM CT images via MATLAB and imported into two Treatment Planning Systems (TPSs) with MBDCA capability. The clinical segmentation was expanded to include additional organs at risk. The actual clinical treatment plan was generally maintained, with the source replaced by a generic 192Ir HDR source. Dose to medium in medium calculations were performed using the MBDCA option of each TPS, and three different Monte Carlo (MC) simulation codes. MC results agreed within statistical uncertainty, while comparisons between MBDCA and MC dose distributions highlighted both strengths and limitations of the studied MBDCAs, suggesting potential approaches to overcome the challenges. Data Format and Usage Notes: The datasets for the developed cases are available online at <a target="_blank" rel="noopener" href="http://doi.org/">http://doi.org/</a> 10.5281&#x2F;zenodo.15720996. The DICOM files include the treatment plan for each case, TPS, and the corresponding reference MC dose data. The package also contains a TPS- and case-specific user guide for commissioning the MBDCAs, and files needed to replicate the MC simulations. Potential Applications: The provided datasets and proposed methodology offer a commissioning framework for TPSs using MBDCAs, and serve as a benchmark for brachytherapy researchers using MC methods. They also facilitate intercomparisons of MBDCA performance and provide a quality assurance resource for evaluating future TPS software updates. </p>
<blockquote>
<p>ç›®çš„ï¼šæ ¹æ®TG-186æŠ¥å‘Šå’ŒWGDCABæŠ¥å‘Š372æå‡ºçš„å·¥ä½œæµç¨‹ï¼Œä¸ºåŸºäºæ¨¡å‹çš„å‰‚é‡è®¡ç®—ç®—æ³•ï¼ˆMBDCAsï¼‰å¼€å‘é€‚ç”¨äºä¸´åºŠçš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¿™äº›ç®—æ³•ç”¨äº192Iré«˜å‰‚é‡ç‡ï¼ˆHDRï¼‰å¦‡ç§‘è…”å†…è¿‘è·ç¦»æ”¾å°„æ²»ç–—ã€‚</p>
</blockquote>
<p>è·å–å’ŒéªŒè¯æ–¹æ³•ï¼šåˆ›å»ºäº†ä¸¤ä¸ªå®«é¢ˆç™ŒHDRè…”å†…è¿‘è·ç¦»æ”¾å°„æ²»ç–—æ‚£è€…æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹é‡‡ç”¨å‡åŒ€ç»“æ„åŒ–åŒºåŸŸæˆ–ç°å®åˆ†å‰²ã€‚å°†æ¨¡å‹è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰å›¾åƒé€šè¿‡MATLABè½¬æ¢ä¸ºDICOM CTå›¾åƒï¼Œå¹¶å¯¼å…¥ä¸¤ä¸ªå…·å¤‡MBDCAåŠŸèƒ½çš„æ”¾å°„æ²»ç–—è®¡åˆ’ç³»ç»Ÿï¼ˆTPSï¼‰ã€‚ä¸´åºŠåˆ†å‰²è¢«æ‰©å±•ä»¥åŒ…æ‹¬é¢å¤–çš„é£é™©å™¨å®˜ã€‚å®é™…çš„ä¸´åºŠæ²»ç–—è®¡åˆ’åŸºæœ¬ä¿æŒä¸å˜ï¼Œæºè¢«æ›¿æ¢ä¸ºé€šç”¨çš„192Ir HDRæºã€‚ä½¿ç”¨æ¯ä¸ªTPSçš„MBDCAé€‰é¡¹å’Œä¸‰ç§ä¸åŒçš„è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿä»£ç ï¼Œå¯¹ä»‹è´¨ä¸­çš„å‰‚é‡è¿›è¡Œå‰‚é‡è®¡ç®—ã€‚MCç»“æœç¬¦åˆç»Ÿè®¡ä¸ç¡®å®šæ€§ï¼Œè€ŒMBDCAå’ŒMCå‰‚é‡åˆ†å¸ƒçš„æ¯”è¾ƒçªå‡ºäº†æ‰€ç ”ç©¶MBDCAçš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œè¿™æš—ç¤ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜çš„å¯èƒ½æ–¹æ³•ã€‚</p>
<p>æ•°æ®æ ¼å¼å’Œä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼šæ‰€å¼€å‘æ¡ˆä¾‹çš„æ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="http://doi.org/%E5%9C%A8%E7%BA%BF%E8%8E%B7%E5%8F%96%E3%80%82DICOM%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB%E6%AF%8F%E4%B8%AA%E6%A1%88%E4%BE%8B%E7%9A%84%E6%B2%BB%E7%96%97%E8%AE%A1%E5%88%92%E3%80%81TPS%E5%92%8C%E7%9B%B8%E5%BA%94%E7%9A%84%E5%8F%82%E8%80%83MC%E5%89%82%E9%87%8F%E6%95%B0%E6%8D%AE%E3%80%82%E8%AF%A5%E8%BD%AF%E4%BB%B6%E5%8C%85%E8%BF%98%E5%8C%85%E5%90%AB%E9%92%88%E5%AF%B9TPS%E5%92%8C%E6%A1%88%E4%BE%8B%E7%89%B9%E5%AE%9A%E7%9A%84%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97%EF%BC%8C%E7%94%A8%E4%BA%8E%E8%B0%83%E8%AF%95MBDCAs%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%A4%8D%E5%88%B6MC%E6%A8%A1%E6%8B%9F%E6%89%80%E9%9C%80%E7%9A%84%E6%96%87%E4%BB%B6%E3%80%82%E6%BD%9C%E5%9C%A8%E5%BA%94%E7%94%A8%EF%BC%9A%E6%89%80%E6%8F%90%E4%BE%9B%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E6%8F%90%E5%87%BA%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%BA%E4%BD%BF%E7%94%A8MBDCAs%E7%9A%84TPS%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E8%B0%83%E8%AF%95%E6%A1%86%E6%9E%B6%EF%BC%8C%E5%B9%B6%E4%B8%BA%E4%BD%BF%E7%94%A8MC%E6%96%B9%E6%B3%95%E7%9A%84%E8%BF%91%E8%B7%9D%E7%A6%BB%E6%94%BE%E5%B0%84%E6%B2%BB%E7%96%97%E7%A0%94%E7%A9%B6%E8%80%85%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E5%9F%BA%E5%87%86%E3%80%82%E5%AE%83%E4%BB%AC%E8%BF%98%E4%BF%83%E8%BF%9B%E4%BA%86MBDCA%E6%80%A7%E8%83%BD%E7%9A%84%E7%9B%B8%E4%BA%92%E6%AF%94%E8%BE%83%EF%BC%8C%E5%B9%B6%E4%B8%BA%E8%AF%84%E4%BC%B0%E6%9C%AA%E6%9D%A5%E7%9A%84TPS%E8%BD%AF%E4%BB%B6%E6%9B%B4%E6%96%B0%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E8%B4%A8%E9%87%8F%E4%BF%9D%E8%AF%81%E8%B5%84%E6%BA%90%E3%80%82">http://doi.org/åœ¨çº¿è·å–ã€‚DICOMæ–‡ä»¶åŒ…å«æ¯ä¸ªæ¡ˆä¾‹çš„æ²»ç–—è®¡åˆ’ã€TPSå’Œç›¸åº”çš„å‚è€ƒMCå‰‚é‡æ•°æ®ã€‚è¯¥è½¯ä»¶åŒ…è¿˜åŒ…å«é’ˆå¯¹TPSå’Œæ¡ˆä¾‹ç‰¹å®šçš„ç”¨æˆ·æŒ‡å—ï¼Œç”¨äºè°ƒè¯•MBDCAsï¼Œä»¥åŠå¤åˆ¶MCæ¨¡æ‹Ÿæ‰€éœ€çš„æ–‡ä»¶ã€‚æ½œåœ¨åº”ç”¨ï¼šæ‰€æä¾›çš„æ•°æ®é›†å’Œæå‡ºçš„æ–¹æ³•ä¸ºä½¿ç”¨MBDCAsçš„TPSæä¾›äº†ä¸€ä¸ªè°ƒè¯•æ¡†æ¶ï¼Œå¹¶ä¸ºä½¿ç”¨MCæ–¹æ³•çš„è¿‘è·ç¦»æ”¾å°„æ²»ç–—ç ”ç©¶è€…æä¾›äº†ä¸€ä¸ªåŸºå‡†ã€‚å®ƒä»¬è¿˜ä¿ƒè¿›äº†MBDCAæ€§èƒ½çš„ç›¸äº’æ¯”è¾ƒï¼Œå¹¶ä¸ºè¯„ä¼°æœªæ¥çš„TPSè½¯ä»¶æ›´æ–°æä¾›äº†ä¸€ä¸ªè´¨é‡ä¿è¯èµ„æºã€‚</a></p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05144v1">PDF</a> To be published in Medical Physics</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºæ¨¡å‹å‰‚é‡è®¡ç®—ç®—æ³•ï¼ˆMBDCAï¼‰çš„192Iré«˜å‰‚é‡ç‡ï¼ˆHDRï¼‰å¦‡ç§‘è…”å†…è¿‘è·ç¦»æ²»ç–—çš„æµ‹è¯•æ¡ˆä¾‹å¼€å‘ã€‚é€šè¿‡åˆ›å»ºä¸¤ä¸ªå®«é¢ˆç™ŒHDRè…”å†…è¿‘è·ç¦»æ²»ç–—æ‚£è€…æ¨¡å‹ï¼Œå¯¹MBDCAè¿›è¡Œäº†éªŒè¯å’Œè¯„ä¼°ã€‚é€šè¿‡è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿä¸MBDCAçš„æ¯”è¾ƒï¼Œæ­ç¤ºäº†MBDCAçš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶æå‡ºäº†å…‹æœæŒ‘æˆ˜çš„æ–¹æ³•ã€‚æä¾›çš„æ•°æ®é›†å’Œæ–¹æ³•ä¸ºTPSç³»ç»Ÿæä¾›äº†å§”æ‰˜æ¡†æ¶ï¼Œå¹¶ä¸ºè¿‘è·ç¦»æ²»ç–—ç ”ç©¶è€…æä¾›äº†åŸºå‡†æµ‹è¯•èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨MBDCAså¯¹HDRå¦‡ç§‘è…”å†…è¿‘è·ç¦»æ²»ç–—è¿›è¡Œå»ºæ¨¡æµ‹è¯•æ¡ˆä¾‹å¼€å‘ã€‚</li>
<li>åˆ›å»ºäº†ä¸¤ä¸ªå®«é¢ˆç™ŒHDRè…”å†…è¿‘è·ç¦»æ²»ç–—æ‚£è€…æ¨¡å‹è¿›è¡ŒéªŒè¯ã€‚</li>
<li>é€šè¿‡MATLABå°†CTå›¾åƒè½¬æ¢ä¸ºDICOM CTå›¾åƒï¼Œå¹¶å¯¼å…¥å…·æœ‰MBDCAåŠŸèƒ½çš„ä¸¤ä¸ªæ²»ç–—è®¡åˆ’ç³»ç»Ÿï¼ˆTPSï¼‰ã€‚</li>
<li>ä¸´åºŠåˆ†å‰²æ‰©å±•åˆ°åŒ…æ‹¬é¢å¤–çš„é£é™©å™¨å®˜åœ¨å†…ã€‚</li>
<li>ä½¿ç”¨MBDCAé€‰é¡¹å’Œä¸‰ç§ä¸åŒçš„è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä»£ç è¿›è¡Œå‰‚é‡è®¡ç®—ã€‚</li>
<li>MCç»“æœä¸MBDCAä¹‹é—´çš„æ¯”è¾ƒæ­ç¤ºäº†MBDCAçš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05144">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b54192b61a8341107d65c9ef53d4c9a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3c9fe8707ba8e5abb1eb30fe8881df9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d7822a73cb70d76aee3437363cc72ff.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Uncovering-Neuroimaging-Biomarkers-of-Brain-Tumor-Surgery-with-AI-Driven-Methods"><a href="#Uncovering-Neuroimaging-Biomarkers-of-Brain-Tumor-Surgery-with-AI-Driven-Methods" class="headerlink" title="Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven   Methods"></a>Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven   Methods</h2><p><strong>Authors:Carmen Jimenez-Mesa, Yizhou Wan, Guilio Sansone, Francisco J. Martinez-Murcia, Javier Ramirez, Pietro Lio, Juan M. Gorriz, Stephen J. Price, John Suckling, Michail Mamalakis</strong></p>
<p>Brain tumor resection is a complex procedure with significant implications for patient survival and quality of life. Predictions of patient outcomes provide clinicians and patients the opportunity to select the most suitable onco-functional balance. In this study, global features derived from structural magnetic resonance imaging in a clinical dataset of 49 pre- and post-surgery patients identified potential biomarkers associated with survival outcomes. We propose a framework that integrates Explainable AI (XAI) with neuroimaging-based feature engineering for survival assessment, offering guidance for surgical decision-making. In this study, we introduce a global explanation optimizer that refines survival-related feature attribution in deep learning models, enhancing interpretability and reliability. Our findings suggest that survival is influenced by alterations in regions associated with cognitive and sensory functions, indicating the importance of preserving areas involved in decision-making and emotional regulation during surgery to improve outcomes. The global explanation optimizer improves both fidelity and comprehensibility of explanations compared to state-of-the-art XAI methods. It effectively identifies survival-related variability, underscoring its relevance in precision medicine for brain tumor treatment. </p>
<blockquote>
<p>è„‘è‚¿ç˜¤åˆ‡é™¤æ˜¯ä¸€ç§å¯¹æ‚£è€…ç”Ÿå­˜å’Œç”Ÿæ´»è´¨é‡æœ‰é‡å¤§å½±å“çš„å¤æ‚æ‰‹æœ¯ã€‚é¢„æµ‹æ‚£è€…é¢„åä¸ºä¸´åºŠåŒ»ç”Ÿå’Œæ‚£è€…æä¾›äº†é€‰æ‹©æœ€é€‚å½“è‚¿ç˜¤åŠŸèƒ½å¹³è¡¡çš„æœºä¼šã€‚æœ¬ç ”ç©¶ä»ä¸´åºŠæ•°æ®é›†ä¸­æ”¶é›†äº†æ¥è‡ªç»“æ„ç£å…±æŒ¯æˆåƒçš„å…¨èº«ç‰¹å¾ï¼Œè¿™äº›æ•°æ®é›†åŒ…å«49åæ‰‹æœ¯å‰åçš„æ‚£è€…ï¼Œå¹¶è¯†åˆ«äº†ä¸ç”Ÿå­˜ç»“æœç›¸å…³çš„æ½œåœ¨ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†å¯è§£é‡Šçš„AIï¼ˆXAIï¼‰ä¸åŸºäºç¥ç»æˆåƒçš„ç‰¹å¾å·¥ç¨‹ç›¸ç»“åˆçš„æ¡†æ¶ï¼Œç”¨äºç”Ÿå­˜è¯„ä¼°ï¼Œä¸ºæ‰‹æœ¯å†³ç­–æä¾›äº†æŒ‡å¯¼ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…¨å±€è§£é‡Šä¼˜åŒ–å™¨ï¼Œå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„ç”Ÿå­˜ç›¸å…³ç‰¹å¾å±æ€§è¿›è¡Œç²¾ç‚¼ï¼Œæé«˜äº†å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç”Ÿå­˜å—åˆ°ä¸è®¤çŸ¥å’Œæ„Ÿè§‰åŠŸèƒ½ç›¸å…³åŒºåŸŸçš„æ”¹å˜çš„å½±å“ï¼Œè¿™è¡¨æ˜åœ¨æ‰‹æœ¯è¿‡ç¨‹ä¸­ä¿ç•™å‚ä¸å†³ç­–å’Œæƒ…ç»ªè°ƒèŠ‚çš„åŒºåŸŸå¯¹äºæ”¹å–„ç»“æœè‡³å…³é‡è¦ã€‚ä¸æœ€æ–°çš„XAIæ–¹æ³•ç›¸æ¯”ï¼Œå…¨å±€è§£é‡Šä¼˜åŒ–å™¨æé«˜äº†è§£é‡Šçš„ä¿çœŸåº¦å’Œæ˜“æ‡‚æ€§ã€‚å®ƒæœ‰æ•ˆåœ°è¯†åˆ«äº†ä¸ç”Ÿå­˜ç›¸å…³çš„å˜å¼‚æ€§ï¼Œå¼ºè°ƒäº†å…¶åœ¨è„‘è‚¿ç˜¤æ²»ç–—çš„ç²¾å‡†åŒ»å­¦ä¸­çš„ç›¸å…³æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04881v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†è„‘è‚¿ç˜¤åˆ‡é™¤æ‰‹æœ¯å¯¹æ‚£è€…ç”Ÿå­˜å’Œç”Ÿæ´»è´¨é‡çš„å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç»“åˆå¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰å’Œç¥ç»æˆåƒç‰¹å¾å·¥ç¨‹çš„ç”Ÿå­˜è¯„ä¼°æ¡†æ¶ï¼Œä¸ºæ‰‹æœ¯å†³ç­–æä¾›æ”¯æŒã€‚ç ”ç©¶å‘ç°ï¼Œç”Ÿå­˜ä¸è®¤çŸ¥å’Œæƒ…æ„ŸåŠŸèƒ½åŒºåŸŸçš„æ”¹å˜æœ‰å…³ï¼Œå…¨å±€è§£é‡Šä¼˜åŒ–å™¨èƒ½æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œæœ‰æ•ˆè¯†åˆ«ä¸ç”Ÿå­˜ç›¸å…³çš„å˜é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è„‘è‚¿ç˜¤åˆ‡é™¤æ‰‹æœ¯å¯¹æ‚£è€…çš„ç”Ÿå­˜å’Œç”Ÿæ´»è´¨é‡æœ‰é‡è¦å½±å“ã€‚</li>
<li>ç»“åˆå¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰å’Œç¥ç»æˆåƒç‰¹å¾å·¥ç¨‹å¯è¯„ä¼°æ‚£è€…ç”Ÿå­˜æƒ…å†µã€‚</li>
<li>ç”Ÿå­˜ä¸è®¤çŸ¥å’Œæƒ…æ„ŸåŠŸèƒ½åŒºåŸŸçš„æ”¹å˜æœ‰å…³ã€‚</li>
<li>å…¨å±€è§£é‡Šä¼˜åŒ–å™¨æé«˜äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è§£é‡Šæ€§å’Œå¯é æ€§ã€‚</li>
<li>è¯¥ä¼˜åŒ–å™¨èƒ½æœ‰æ•ˆè¯†åˆ«ä¸ç”Ÿå­˜ç›¸å…³çš„å˜é‡ã€‚</li>
<li>å…¨å±€è§£é‡Šä¼˜åŒ–å™¨åœ¨ç²¾ç¡®åŒ»å­¦é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨è„‘è‚¿ç˜¤æ²»ç–—ä¸­æœ‰é‡è¦åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04881">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fb77e1cea57768ad5a6474961c92a352.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16903d9600b2939f9ac5fc1bfce1c685.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2454e4caadb804487db26509d6f630ae.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GraphBrep-Learning-B-Rep-in-Graph-Structure-for-Efficient-CAD-Generation"><a href="#GraphBrep-Learning-B-Rep-in-Graph-Structure-for-Efficient-CAD-Generation" class="headerlink" title="GraphBrep: Learning B-Rep in Graph Structure for Efficient CAD   Generation"></a>GraphBrep: Learning B-Rep in Graph Structure for Efficient CAD   Generation</h2><p><strong>Authors:Weilin Lai, Tie Xu, Hu Wang</strong></p>
<p>Direct B-Rep generation is increasingly important in CAD workflows, eliminating costly modeling sequence data and supporting complex features. A key challenge is modeling joint distribution of the misaligned geometry and topology. Existing methods tend to implicitly embed topology into the geometric features of edges. Although this integration ensures feature alignment, it also causes edge geometry to carry more redundant structural information compared to the original B-Rep, leading to significantly higher computational cost. To reduce redundancy, we propose GraphBrep, a B-Rep generation model that explicitly represents and learns compact topology. Following the original structure of B-Rep, we construct an undirected weighted graph to represent surface topology. A graph diffusion model is employed to learn topology conditioned on surface features, serving as the basis for determining connectivity between primitive surfaces. The explicit representation ensures a compact data structure, effectively reducing computational cost during both training and inference. Experiments on two large-scale unconditional datasets and one category-conditional dataset demonstrate the proposed method significantly reduces training and inference times (up to 31.3% and 56.3% for given datasets, respectively) while maintaining high-quality CAD generation compared with SOTA. </p>
<blockquote>
<p>ç›´æ¥B-Repç”Ÿæˆåœ¨CADå·¥ä½œæµç¨‹ä¸­è¶Šæ¥è¶Šé‡è¦ï¼Œå®ƒæ¶ˆé™¤äº†æ˜‚è´µçš„å»ºæ¨¡åºåˆ—æ•°æ®å¹¶æ”¯æŒå¤æ‚ç‰¹å¾ã€‚ä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯å¯¹é”™ä½å‡ ä½•å’Œæ‹“æ‰‘è¿›è¡Œè”åˆåˆ†å¸ƒå»ºæ¨¡ã€‚ç°æœ‰æ–¹æ³•å€¾å‘äºå°†æ‹“æ‰‘éšå¼åµŒå…¥åˆ°è¾¹ç¼˜çš„å‡ ä½•ç‰¹å¾ä¸­ã€‚è™½ç„¶è¿™ç§é›†æˆç¡®ä¿äº†ç‰¹å¾å¯¹é½ï¼Œä½†ä¹Ÿå¯¼è‡´è¾¹ç¼˜å‡ ä½•æºå¸¦äº†æ¯”åŸå§‹B-Repæ›´å¤šçš„å†—ä½™ç»“æ„ä¿¡æ¯ï¼Œä»è€Œäº§ç”Ÿäº†æ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚ä¸ºäº†å‡å°‘å†—ä½™ï¼Œæˆ‘ä»¬æå‡ºäº†GraphBrepï¼Œè¿™æ˜¯ä¸€ç§æ˜¾å¼è¡¨ç¤ºå¹¶å­¦ä¹ ç´§å‡‘æ‹“æ‰‘çš„B-Repç”Ÿæˆæ¨¡å‹ã€‚éµå¾ªB-Repçš„åŸå§‹ç»“æ„ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ— å‘åŠ æƒå›¾æ¥è¡¨ç¤ºè¡¨é¢æ‹“æ‰‘ã€‚é‡‡ç”¨å›¾æ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ åŸºäºè¡¨é¢ç‰¹å¾çš„æ‹“æ‰‘ï¼Œä½œä¸ºç¡®å®šåŸå§‹è¡¨é¢ä¹‹é—´è¿æ¥æ€§çš„åŸºç¡€ã€‚æ˜¾å¼è¡¨ç¤ºç¡®ä¿äº†ä¸€ä¸ªç´§å‡‘çš„æ•°æ®ç»“æ„ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­çš„è®¡ç®—æˆæœ¬ã€‚åœ¨ä¸¤ä¸ªå¤§è§„æ¨¡æ— æ¡ä»¶æ•°æ®é›†å’Œä¸€ä¸ªç±»åˆ«æ¡ä»¶æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æ˜¾è‘—å‡å°‘äº†è®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼ˆå¯¹äºç»™å®šæ•°æ®é›†åˆ†åˆ«æœ€å¤šå‡å°‘31.3%å’Œ56.3%ï¼‰ï¼ŒåŒæ—¶ä¿æŒä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„é«˜è´¨é‡CADç”Ÿæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04765v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ç›´æ¥B-Repç”Ÿæˆåœ¨CADå·¥ä½œæµç¨‹ä¸­æ—¥ç›Šé‡è¦ï¼Œèƒ½å¤Ÿæ¶ˆé™¤æ˜‚è´µçš„å»ºæ¨¡åºåˆ—æ•°æ®å¹¶æ”¯æŒå¤æ‚ç‰¹å¾ã€‚ç°æœ‰æ–¹æ³•å€¾å‘äºå°†æ‹“æ‰‘éšå«åœ°åµŒå…¥è¾¹ç¼˜çš„å‡ ä½•ç‰¹å¾ä¸­ï¼Œå¯¼è‡´è¾¹ç¼˜å‡ ä½•æºå¸¦äº†ä¸åŸå§‹B-Repç›¸æ¯”æ›´å¤šçš„å†—ä½™ç»“æ„ä¿¡æ¯ï¼Œä»è€Œå¢åŠ äº†è®¡ç®—æˆæœ¬ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†GraphBrepæ¨¡å‹ï¼Œå®ƒæ˜¾å¼è¡¨ç¤ºå¹¶å­¦ä¹ ç´§å‡‘æ‹“æ‰‘ã€‚æˆ‘ä»¬æŒ‰ç…§B-Repçš„åŸå§‹ç»“æ„æ„å»ºäº†ä¸€ä¸ªæ— å‘åŠ æƒå›¾æ¥è¡¨ç¤ºè¡¨é¢æ‹“æ‰‘ï¼Œå¹¶ä½¿ç”¨å›¾æ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ åŸºäºè¡¨é¢ç‰¹å¾çš„æ‹“æ‰‘ï¼Œä½œä¸ºç¡®å®šåŸºæœ¬è¡¨é¢ä¹‹é—´è¿æ¥æ€§çš„åŸºç¡€ã€‚æ˜¾å¼è¡¨ç¤ºç¡®ä¿äº†ç´§å‡‘çš„æ•°æ®ç»“æ„ï¼Œåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´æœ‰æ•ˆé™ä½äº†è®¡ç®—æˆæœ¬ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§å‹æ— æ¡ä»¶æ•°æ®é›†å’Œç±»åˆ«æ¡ä»¶æ•°æ®é›†ä¸Šçš„è®­ç»ƒæ—¶é—´å’Œæ¨ç†æ—¶é—´åˆ†åˆ«å‡å°‘äº†æœ€å¤šè¾¾31.3%å’Œ56.3%ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„CADç”Ÿæˆæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç›´æ¥B-Repç”Ÿæˆåœ¨CADæµç¨‹ä¸­çš„é‡è¦æ€§åœ¨äºæ¶ˆé™¤æ˜‚è´µçš„å»ºæ¨¡åºåˆ—æ•°æ®å¹¶æ”¯æŒå¤æ‚ç‰¹å¾ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å°†æ‹“æ‰‘éšå«åµŒå…¥è¾¹ç¼˜å‡ ä½•ç‰¹å¾ä¸­ï¼Œå¯¼è‡´è¾¹ç¼˜å‡ ä½•æºå¸¦å†—ä½™ç»“æ„ä¿¡æ¯ã€‚</li>
<li>GraphBrepæ¨¡å‹è¢«æå‡ºä»¥æ˜¾å¼è¡¨ç¤ºå¹¶å­¦ä¹ ç´§å‡‘æ‹“æ‰‘ï¼Œé€šè¿‡æ„å»ºæ— å‘åŠ æƒå›¾è¡¨ç¤ºè¡¨é¢æ‹“æ‰‘ã€‚</li>
<li>å›¾æ‰©æ•£æ¨¡å‹ç”¨äºå­¦ä¹ åŸºäºè¡¨é¢ç‰¹å¾çš„æ‹“æ‰‘ï¼Œä½œä¸ºç¡®å®šåŸºæœ¬è¡¨é¢ä¹‹é—´è¿æ¥æ€§çš„åŸºç¡€ã€‚</li>
<li>æ˜¾å¼è¡¨ç¤ºç¡®ä¿ç´§å‡‘çš„æ•°æ®ç»“æ„ï¼Œæœ‰æ•ˆé™ä½è®­ç»ƒå’Œæ¨ç†æœŸé—´çš„è®¡ç®—æˆæœ¬ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphBrepæ¨¡å‹åœ¨å¤§å‹æ•°æ®é›†ä¸Šæ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´å’Œæ¨ç†æ—¶é—´ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04765">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63c11bef2110d1bd3394c5d6f6370f05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e1d3e62e22aacb5fe5ddc90d8770814.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Gaussian-Process-Modeling-Coronal-X-ray-Variability-of-Active-Galactic-Nuclei"><a href="#Gaussian-Process-Modeling-Coronal-X-ray-Variability-of-Active-Galactic-Nuclei" class="headerlink" title="Gaussian Process Modeling Coronal X-ray Variability of Active Galactic   Nuclei"></a>Gaussian Process Modeling Coronal X-ray Variability of Active Galactic   Nuclei</h2><p><strong>Authors:Haiyun Zhang, Dahai Yan, Li Zhang, Niansheng Tang</strong></p>
<p>The corona is an integral component of active galactic nuclei (AGNs) which can produce the X-ray emission. However, many of its physical properties and the mechanisms powering this emission remain a mystery. In this work, we study the coronal X-ray variabilities of 13 AGNs by Gaussian Process. 2-10 keV light curves of 13 AGNs can be successfully described by the damped-random walk (DRW) model. The extracted coronal X-ray timescales range from 3 to 50 days. In the plot of variability timescale versus black hole mass, the coronal X-ray timescales of four sources occupy almost the same region as the optical timescales of the accretion disk, with the latter matching the predicted thermal instability timescale of the disk. In contrast, the X-ray timescales of the remaining sources exhibit a systematic offset toward lower values. We propose that the coronal X-ray variability may be driven by internal processes within the corona itself (such as thermal conduction). On the other hand, it may also be triggered by local thermal instabilities occurring in different regions (close to the central black hole) of the accretion disk, which propagate to the corona via disk-corona coupling. </p>
<blockquote>
<p>æ˜Ÿå†•æ˜¯æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆAGNsï¼‰çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œèƒ½å¤Ÿäº§ç”ŸXå°„çº¿å‘å°„ã€‚ç„¶è€Œï¼Œå…³äºå…¶è®¸å¤šç‰©ç†æ€§è´¨å’Œé©±åŠ¨è¿™ç§å‘å°„çš„æœºåˆ¶ä»ç„¶æ˜¯ä¸ªè°œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹ç ”ç©¶äº†13ä¸ªæ´»åŠ¨æ˜Ÿç³»æ ¸çš„Xå°„çº¿å¯å˜æ€§ã€‚è¿™13ä¸ªæ´»åŠ¨æ˜Ÿç³»æ ¸çš„2-10 keVå…‰å˜æ›²çº¿å¯ä»¥é€šè¿‡é˜»å°¼éšæœºæ¸¸èµ°ï¼ˆDRWï¼‰æ¨¡å‹æˆåŠŸæè¿°ã€‚æå–çš„æ˜Ÿå†•Xå°„çº¿æ—¶é—´å°ºåº¦èŒƒå›´ä¸º3è‡³50å¤©ã€‚åœ¨æ—¶é—´å°ºåº¦ä¸é»‘æ´è´¨é‡çš„å›¾ä¸­ï¼Œå››ä¸ªæºçš„æ˜Ÿå†•Xå°„çº¿æ—¶é—´å°ºåº¦å‡ ä¹å æ®ä¸å¸ç§¯ç›˜å…‰å­¦æ—¶é—´å°ºåº¦ç›¸åŒçš„åŒºåŸŸï¼Œåè€…ä¸é¢„æœŸçš„ç›˜çƒ­ä¸ç¨³å®šæ—¶é—´å°ºåº¦ç›¸åŒ¹é…ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå…¶ä½™æºçš„Xå°„çº¿æ—¶é—´å°ºåº¦è¡¨ç°å‡ºå‘è¾ƒä½å€¼çš„æœ‰è§„å¾‹åç§»ã€‚æˆ‘ä»¬æå‡ºï¼Œæ˜Ÿå†•Xå°„çº¿å¯å˜æ€§å¯èƒ½æ˜¯ç”±æ˜Ÿå†•å†…éƒ¨è¿‡ç¨‹æœ¬èº«æ‰€é©±åŠ¨çš„ï¼ˆå¦‚çƒ­ä¼ å¯¼ï¼‰ã€‚å¦ä¸€æ–¹é¢ï¼Œå®ƒä¹Ÿå¯èƒ½æ˜¯ç”±å¸ç§¯ç›˜ä¸åŒåŒºåŸŸï¼ˆé è¿‘ä¸­å¿ƒé»‘æ´ï¼‰å‘ç”Ÿçš„å±€éƒ¨çƒ­ä¸ç¨³å®šæ‰€è§¦å‘ï¼Œé€šè¿‡ç›˜å†•è€¦åˆä¼ æ’­åˆ°æ˜Ÿå†•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04715v1">PDF</a> 11 pages, 5 figures, accepted for publication in ApJ</p>
<p><strong>Summary</strong><br>     æ­¤æ–‡æœ¬ç ”ç©¶äº†æ´»è·ƒæ˜Ÿç³»æ ¸ï¼ˆAGNsï¼‰çš„Xå°„çº¿å‘å°„åŠå…¶ç‰©ç†ç‰¹æ€§ã€‚é€šè¿‡å¯¹13ä¸ªAGNsçš„Xå°„çº¿å˜åŒ–æ€§è¿›è¡Œé«˜æ–¯è¿‡ç¨‹ç ”ç©¶ï¼Œå‘ç°å…¶æ—¶é—´å°ºåº¦åœ¨3è‡³50å¤©ä¹‹é—´ã€‚éƒ¨åˆ†æºçš„æ—¶é—´å°ºåº¦ä¸å¸ç§¯ç›˜çš„å…‰å­¦æ—¶é—´å°ºåº¦ç›¸ä¼¼ï¼Œå¯èƒ½å—åˆ°çƒ­ä¼ å¯¼ç­‰å†…éƒ¨è¿‡ç¨‹çš„å½±å“ï¼›è€Œå…¶ä»–æºçš„æ—¶é—´å°ºåº¦åˆ™è¾ƒä½ï¼Œå¯èƒ½æ˜¯ç”±å¸ç§¯ç›˜ä¸åŒåŒºåŸŸçš„å±€éƒ¨çƒ­ä¸ç¨³å®šå¼•èµ·çš„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ´»è·ƒæ˜Ÿç³»æ ¸ï¼ˆAGNsï¼‰çš„Xå°„çº¿å‘å°„ä¸­ï¼Œcoronaèµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚</li>
<li>é€šè¿‡é«˜æ–¯è¿‡ç¨‹ç ”ç©¶äº†13ä¸ªAGNsçš„Xå°„çº¿å˜åŒ–æ€§ã€‚</li>
<li>æˆåŠŸä½¿ç”¨é˜»å°¼éšæœºæ¸¸èµ°ï¼ˆDRWï¼‰æ¨¡å‹æè¿°è¿™äº›AGNsçš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</li>
<li>æå–çš„coronal Xå°„çº¿æ—¶é—´å°ºåº¦åœ¨3è‡³50å¤©ä¹‹é—´ã€‚</li>
<li>éƒ¨åˆ†æºçš„æ—¶é—´å°ºåº¦ä¸å¸ç§¯ç›˜çš„å…‰å­¦æ—¶é—´å°ºåº¦ç›¸ä¼¼ï¼Œå¯èƒ½ä¸å†…éƒ¨è¿‡ç¨‹ï¼ˆå¦‚çƒ­ä¼ å¯¼ï¼‰æœ‰å…³ã€‚</li>
<li>å…¶ä»–æºçš„æ—¶é—´å°ºåº¦è¾ƒä½ï¼Œå¯èƒ½æ˜¯ç”±å¸ç§¯ç›˜ä¸åŒåŒºåŸŸçš„å±€éƒ¨çƒ­ä¸ç¨³å®šå¼•èµ·çš„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04715">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2cddb988b4833f516d6406e6b10f65db.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a509a8ef4b517b3ebd0fa1d5d9b2c5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1217c06b6745577db408fa2963e0092.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b376232aea2f8509f0b9fc703710c45b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d7eb80ed294d5066d687ba220eab3c79.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-27faefb74b1a8dd23bd7e354f864bdfc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48b82f97f5463ac64d297b654e83c24b.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Colorectal-Cancer-Tumor-Grade-Segmentation-in-Digital-Histopathology-Images-From-Giga-to-Mini-Challenge"><a href="#Colorectal-Cancer-Tumor-Grade-Segmentation-in-Digital-Histopathology-Images-From-Giga-to-Mini-Challenge" class="headerlink" title="Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology   Images: From Giga to Mini Challenge"></a>Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology   Images: From Giga to Mini Challenge</h2><p><strong>Authors:Alper Bahcekapili, Duygu Arslan, Umut Ozdemir, Berkay Ozkirli, Emre Akbas, Ahmet Acar, Gozde B. Akar, Bingdou He, Shuoyu Xu, Umit Mert Caglar, Alptekin Temizel, Guillaume Picaud, Marc Chaumont, GÃ©rard Subsol, Luc TÃ©ot, Fahad Alsharekh, Shahad Alghannam, Hexiang Mao, Wenhua Zhang</strong></p>
<p>Colorectal cancer (CRC) is the third most diagnosed cancer and the second leading cause of cancer-related death worldwide. Accurate histopathological grading of CRC is essential for prognosis and treatment planning but remains a subjective process prone to observer variability and limited by global shortages of trained pathologists. To promote automated and standardized solutions, we organized the ICIP Grand Challenge on Colorectal Cancer Tumor Grading and Segmentation using the publicly available METU CCTGS dataset. The dataset comprises 103 whole-slide images with expert pixel-level annotations for five tissue classes. Participants submitted segmentation masks via Codalab, evaluated using metrics such as macro F-score and mIoU. Among 39 participating teams, six outperformed the Swin Transformer baseline (62.92 F-score). This paper presents an overview of the challenge, dataset, and the top-performing methods </p>
<blockquote>
<p>ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰æ˜¯å…¨çƒè¯Šæ–­ç‡ç¬¬ä¸‰é«˜çš„ç™Œç—‡ï¼Œä¹Ÿæ˜¯å¯¼è‡´ç™Œç—‡ç›¸å…³æ­»äº¡çš„ç¬¬äºŒå¤§ä¸»è¦åŸå› ã€‚CRCçš„å‡†ç¡®ç»„ç»‡ç—…ç†å­¦åˆ†çº§å¯¹é¢„åå’Œæ²»ç–—è®¡åˆ’è‡³å…³é‡è¦ï¼Œä½†ä»æ˜¯ä¸€ä¸ªä¸»è§‚è¿‡ç¨‹ï¼Œå®¹æ˜“å—è§‚å¯Ÿè€…å˜å¼‚æ€§çš„å½±å“ï¼Œå¹¶å—åˆ°å…¨çƒè®­ç»ƒæœ‰ç´ ç—…ç†å­¦å®¶çŸ­ç¼ºçš„é™åˆ¶ã€‚ä¸ºäº†æ¨å¹¿è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å…¬å¼€å¯ç”¨çš„METU CCTGSæ•°æ®é›†ï¼Œç»„ç»‡äº†å›½é™…å›¾åƒå‰–æå¤§å¥–èµ›çš„ç»“ç›´è‚ ç™Œè‚¿ç˜¤åˆ†çº§å’Œåˆ†å‰²æŒ‘æˆ˜èµ›ã€‚è¯¥æ•°æ®é›†åŒ…å«103å¼ å…¨å¹»ç¯ç‰‡å›¾åƒï¼ŒåŒ…å«äº”ç§ç»„ç»‡çš„ä¸“å®¶åƒç´ çº§æ³¨é‡Šã€‚å‚èµ›è€…é€šè¿‡Codalabæäº¤åˆ†å‰²æ©è†œï¼Œä½¿ç”¨å®è§‚Fåˆ†æ•°å’ŒmIoUç­‰åº¦é‡æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚åœ¨3eä¸ªå‚èµ›å›¢é˜Ÿä¸­ï¼Œæœ‰å…­ä¸ªå›¢é˜Ÿçš„è¡¨ç°è¶…è¿‡äº†Swin TransformeråŸºçº¿ï¼ˆFåˆ†æ•°ä¸º62.92ï¼‰ã€‚æœ¬æ–‡ä»‹ç»äº†æŒ‘æˆ˜èµ›ã€æ•°æ®é›†å’Œè¡¨ç°æœ€å¥½çš„æ–¹æ³•æ¦‚å†µã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04681v1">PDF</a> Accepted Grand Challenge Paper ICIP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç»“ç›´è‚ ç™Œï¼ˆCRCï¼‰çš„å…¨çƒæ€§è¯Šæ–­ä¸æ²»ç–—ç°çŠ¶ï¼Œå¼ºè°ƒå‡†ç¡®ç»„ç»‡ç—…ç†å­¦åˆ†çº§å¯¹é¢„åå’Œæ²»ç–—è®¡åˆ’çš„é‡è¦æ€§ã€‚é’ˆå¯¹å½“å‰å­˜åœ¨çš„è§‚å¯Ÿè€…ä¸»è§‚å·®å¼‚å’Œç—…ç†åŒ»å¸ˆå…¨çƒçŸ­ç¼ºçš„é—®é¢˜ï¼Œä»‹ç»äº†é€šè¿‡ä¸¾åŠICIP Grand Challengeä¿ƒè¿›çš„è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–è§£å†³æ–¹æ¡ˆã€‚æ–‡ç« è¿˜ä»‹ç»äº†ä½¿ç”¨çš„å…¬å¼€å¯ç”¨çš„METU CCTGSæ•°æ®é›†å’Œè¯„ä»·æŒ‡æ ‡ï¼Œå¦‚å®Fåˆ†æ•°å’ŒmIoUç­‰ã€‚åœ¨å‚ä¸æŒ‘æˆ˜çš„39æ”¯é˜Ÿä¼ä¸­ï¼Œæœ‰å…­æ”¯é˜Ÿä¼è¶…è¶Šäº†Swin TransformeråŸºçº¿æ¨¡å‹ï¼ˆFåˆ†æ•°ä¸º62.92ï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç»“ç›´è‚ ç™Œæ˜¯å…¨çƒè¯Šæ–­ç‡ç¬¬ä¸‰ã€è‡´æ­»ç‡ç¬¬äºŒçš„ç™Œç—‡ã€‚</li>
<li>å‡†ç¡®çš„ç»„ç»‡ç—…ç†å­¦åˆ†çº§å¯¹ç»“ç›´è‚ ç™Œçš„é¢„åå’Œæ²»ç–—è®¡åˆ’è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰ç»„ç»‡ç—…ç†å­¦åˆ†çº§å­˜åœ¨è§‚å¯Ÿè€…ä¸»è§‚å·®å¼‚å’Œç—…ç†åŒ»å¸ˆå…¨çƒçŸ­ç¼ºçš„é—®é¢˜ã€‚</li>
<li>ä¸ºä¿ƒè¿›è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–çš„è§£å†³æ–¹æ¡ˆï¼Œä¸¾åŠäº†ICIP Grand Challengeã€‚</li>
<li>å…¬å¼€çš„METU CCTGSæ•°æ®é›†åŒ…å«ä¸“å®¶åƒç´ çº§æ ‡æ³¨çš„äº”ç§ç»„ç»‡ç±»åˆ«çš„ä¿¡æ¯ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨å®Fåˆ†æ•°å’ŒmIoUç­‰è¯„ä»·æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04681">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f497f58bb7f2f2e3b636ee518ae30438.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-eaad65e546d444407ae2ecf608e1d9cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa8d6172f97c8c97f3dd17b049cdac82.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="CP-Dilatation-A-Copy-and-Paste-Augmentation-Method-for-Preserving-the-Boundary-Context-Information-of-Histopathology-Images"><a href="#CP-Dilatation-A-Copy-and-Paste-Augmentation-Method-for-Preserving-the-Boundary-Context-Information-of-Histopathology-Images" class="headerlink" title="CP-Dilatation: A Copy-and-Paste Augmentation Method for Preserving the   Boundary Context Information of Histopathology Images"></a>CP-Dilatation: A Copy-and-Paste Augmentation Method for Preserving the   Boundary Context Information of Histopathology Images</h2><p><strong>Authors:Sungrae Hong, Sol Lee, Mun Yong Yi</strong></p>
<p>Medical AI diagnosis including histopathology segmentation has derived benefits from the recent development of deep learning technology. However, deep learning itself requires a large amount of training data and the medical image segmentation masking, in particular, requires an extremely high cost due to the shortage of medical specialists. To mitigate this issue, we propose a new data augmentation method built upon the conventional Copy and Paste (CP) augmentation technique, called CP-Dilatation, and apply it to histopathology image segmentation. To the well-known traditional CP technique, the proposed method adds a dilation operation that can preserve the boundary context information of the malignancy, which is important in histopathological image diagnosis, as the boundary between the malignancy and its margin is mostly unclear and a significant context exists in the margin. In our experiments using histopathology benchmark datasets, the proposed method was found superior to the other state-of-the-art baselines chosen for comparison. </p>
<blockquote>
<p>åŒ»å­¦äººå·¥æ™ºèƒ½è¯Šæ–­ï¼ŒåŒ…æ‹¬ç—…ç†åˆ†å‰²ï¼Œå—ç›Šäºæœ€è¿‘æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ã€‚ç„¶è€Œï¼Œæ·±åº¦å­¦ä¹ æœ¬èº«éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œå°¤å…¶æ˜¯åŒ»å­¦å›¾åƒåˆ†å‰²æ©è†œï¼Œç”±äºåŒ»å­¦ä¸“å®¶çŸ­ç¼ºï¼Œå…¶æˆæœ¬æé«˜ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¼ ç»Ÿå¤åˆ¶ç²˜è´´ï¼ˆCPï¼‰å¢å¼ºæŠ€æœ¯çš„æ–°æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œç§°ä¸ºCP-è†¨èƒ€æ³•ï¼Œå¹¶å°†å…¶åº”ç”¨äºç—…ç†å›¾åƒåˆ†å‰²ã€‚ä¸ä¼ ç»Ÿä¼—æ‰€å‘¨çŸ¥çš„CPæŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¢åŠ äº†ä¸€ä¸ªè†¨èƒ€æ“ä½œï¼Œå¯ä»¥ä¿ç•™æ¶æ€§è‚¿ç˜¤çš„è¾¹ç•Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¿™åœ¨ç—…ç†å›¾åƒè¯Šæ–­ä¸­éå¸¸é‡è¦ï¼Œå› ä¸ºæ¶æ€§è‚¿ç˜¤ä¸å…¶è¾¹ç¼˜ä¹‹é—´çš„è¾¹ç•Œå¤§å¤šä¸æ¸…æ¥šï¼Œè¾¹ç¼˜ä¸­å­˜åœ¨é‡è¦çš„ä¸Šä¸‹æ–‡ã€‚åœ¨ä½¿ç”¨ç—…ç†åŸºå‡†æ•°æ®é›†è¿›è¡Œçš„å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•è¢«è¯æ˜ä¼˜äºå…¶ä»–é€‰å®šçš„æœ€æ–°åŸºçº¿æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04660v1">PDF</a> 5 pages, 5 figures</p>
<p><strong>Summary</strong><br>     åŒ»å­¦äººå·¥æ™ºèƒ½è¯Šæ–­ä¸­çš„ç»„ç»‡ç—…ç†å­¦åˆ†å‰²å—ç›Šäºæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ã€‚ç„¶è€Œï¼Œæ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼ŒåŒ»å­¦å›¾åƒåˆ†å‰²å°¤å…¶éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œå› åŒ»å­¦ä¸“å®¶çŸ­ç¼ºå¯¼è‡´æˆæœ¬æé«˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åŸºäºä¼ ç»Ÿå¤åˆ¶ç²˜è´´ï¼ˆCPï¼‰å¢å¼ºæŠ€æœ¯çš„æ–°æ•°æ®å¢å¼ºæ–¹æ³•â€”â€”CP-Dilationï¼Œå¹¶åº”ç”¨äºç»„ç»‡ç—…ç†å­¦å›¾åƒåˆ†å‰²ã€‚ç›¸è¾ƒäºä¼ ç»ŸCPæŠ€æœ¯ï¼Œæ–°æ–¹æ³•æ·»åŠ è†¨èƒ€æ“ä½œï¼Œå¯ä¿ç•™æ¶æ€§è¾¹ç•Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨ç»„ç»‡ç—…ç†å­¦åŸºå‡†æ•°æ®é›†çš„å®éªŒä¸­ï¼Œæ–°æ–¹æ³•ä¼˜äºå…¶ä»–å¯¹æ¯”çš„åŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦äººå·¥æ™ºèƒ½è¯Šæ–­å’Œç»„ç»‡ç—…ç†å­¦åˆ†å‰²ä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚</li>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œå› åŒ»å­¦ä¸“å®¶çŸ­ç¼ºå¯¼è‡´æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæ–¹æ³•CP-Dilationï¼ŒåŸºäºä¼ ç»Ÿçš„å¤åˆ¶ç²˜è´´ï¼ˆCPï¼‰å¢å¼ºæŠ€æœ¯ã€‚</li>
<li>CP-Dilationæ–¹æ³•é€šè¿‡æ·»åŠ è†¨èƒ€æ“ä½œï¼Œèƒ½å¤Ÿä¿ç•™æ¶æ€§è¾¹ç•Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>æ¶æ€§è¾¹ç•Œçš„è¯†åˆ«å¯¹äºç»„ç»‡ç—…ç†å­¦å›¾åƒè¯Šæ–­éå¸¸é‡è¦ã€‚</li>
<li>åœ¨ç»„ç»‡ç—…ç†å­¦åŸºå‡†æ•°æ®é›†çš„å®éªŒä¸­ï¼ŒCP-Dilationæ–¹æ³•ä¼˜äºå…¶ä»–å…ˆè¿›åŸºçº¿æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04660">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ada742155f3c5752315253ef0138ba99.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-801001550fcbedc654617932aedf8f5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-56b35b811c591caf70cb129ef5ffe762.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de61e596a9931ffd0ca6adbfbe55866c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="HiLa-Hierarchical-Vision-Language-Collaboration-for-Cancer-Survival-Prediction"><a href="#HiLa-Hierarchical-Vision-Language-Collaboration-for-Cancer-Survival-Prediction" class="headerlink" title="HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival   Prediction"></a>HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival   Prediction</h2><p><strong>Authors:Jiaqi Cui, Lu Wen, Yuchen Fei, Bo Liu, Luping Zhou, Dinggang Shen, Yan Wang</strong></p>
<p>Survival prediction using whole-slide images (WSIs) is crucial in cancer re-search. Despite notable success, existing approaches are limited by their reliance on sparse slide-level labels, which hinders the learning of discriminative repre-sentations from gigapixel WSIs. Recently, vision language (VL) models, which incorporate additional language supervision, have emerged as a promising solu-tion. However, VL-based survival prediction remains largely unexplored due to two key challenges. First, current methods often rely on only one simple lan-guage prompt and basic cosine similarity, which fails to learn fine-grained associ-ations between multi-faceted linguistic information and visual features within WSI, resulting in inadequate vision-language alignment. Second, these methods primarily exploit patch-level information, overlooking the intrinsic hierarchy of WSIs and their interactions, causing ineffective modeling of hierarchical interac-tions. To tackle these problems, we propose a novel Hierarchical vision-Language collaboration (HiLa) framework for improved survival prediction. Specifically, HiLa employs pretrained feature extractors to generate hierarchical visual features from WSIs at both patch and region levels. At each level, a series of language prompts describing various survival-related attributes are constructed and aligned with visual features via Optimal Prompt Learning (OPL). This ap-proach enables the comprehensive learning of discriminative visual features cor-responding to different survival-related attributes from prompts, thereby improv-ing vision-language alignment. Furthermore, we introduce two modules, i.e., Cross-Level Propagation (CLP) and Mutual Contrastive Learning (MCL) to maximize hierarchical cooperation by promoting interactions and consistency be-tween patch and region levels. Experiments on three TCGA datasets demonstrate our SOTA performance. </p>
<blockquote>
<p>åœ¨ç™Œç—‡ç ”ç©¶ä¸­ï¼Œåˆ©ç”¨å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰è¿›è¡Œç”Ÿå­˜é¢„æµ‹è‡³å…³é‡è¦ã€‚å°½ç®¡å·²æœ‰ä¸€äº›æˆåŠŸçš„æ–¹æ³•ï¼Œä½†å®ƒä»¬ä¾èµ–äºç¨€ç–çš„åˆ‡ç‰‡çº§æ ‡ç­¾ï¼Œè¿™é˜»ç¢äº†ä»gigapixel WSIä¸­å­¦ä¹ åˆ¤åˆ«è¡¨ç¤ºã€‚æœ€è¿‘ï¼Œç»“åˆé¢å¤–è¯­è¨€ç›‘ç£çš„è§†å¬è¯­è¨€ï¼ˆVLï¼‰æ¨¡å‹çš„å‡ºç°ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼ŒåŸºäºVLçš„ç”Ÿå­˜é¢„æµ‹ä»ç„¶å› ä¸¤å¤§æŒ‘æˆ˜è€Œæœªè¢«å……åˆ†æ¢ç´¢ã€‚é¦–å…ˆï¼Œå½“å‰çš„æ–¹æ³•é€šå¸¸åªä¾èµ–ä¸€ä¸ªç®€å•çš„è¯­è¨€æç¤ºå’ŒåŸºæœ¬ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œè¿™æ— æ³•å­¦ä¹ WSIå†…éƒ¨å¤šé¢è¯­è¨€ä¿¡æ¯ä¸è§†è§‰ç‰¹å¾ä¹‹é—´çš„ç²¾ç»†å…³è”ï¼Œå¯¼è‡´è§†è§‰è¯­è¨€å¯¹é½ä¸è¶³ã€‚å…¶æ¬¡ï¼Œè¿™äº›æ–¹æ³•ä¸»è¦åˆ©ç”¨è¡¥ä¸çº§åˆ«çš„ä¿¡æ¯ï¼Œå¿½ç•¥äº†WSIçš„å†…åœ¨å±‚æ¬¡åŠå…¶äº¤äº’ä½œç”¨ï¼Œå¯¼è‡´å±‚æ¬¡äº¤äº’å»ºæ¨¡æ— æ•ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åˆ†å±‚è§†å¬è¯­è¨€åä½œï¼ˆHiLaï¼‰æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›ç”Ÿå­˜é¢„æµ‹ã€‚å…·ä½“æ¥è¯´ï¼ŒHiLaä½¿ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨ç”Ÿæˆæ¥è‡ªWSIçš„å±‚æ¬¡åŒ–è§†è§‰ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨è¡¥ä¸å’ŒåŒºåŸŸå±‚é¢éƒ½æœ‰æ¶‰åŠã€‚åœ¨æ¯ä¸ªå±‚é¢ä¸Šï¼Œæ„å»ºä¸€ç³»åˆ—æè¿°å„ç§ç”Ÿå­˜ç›¸å…³å±æ€§çš„è¯­è¨€æç¤ºï¼Œå¹¶é€šè¿‡æœ€ä½³æç¤ºå­¦ä¹ ï¼ˆOPLï¼‰ä¸è§†è§‰ç‰¹å¾è¿›è¡Œå¯¹é½ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿä»æç¤ºä¸­å…¨é¢å­¦ä¹ å¯¹åº”äºä¸åŒç”Ÿå­˜ç›¸å…³å±æ€§çš„åˆ¤åˆ«æ€§è§†è§‰ç‰¹å¾ï¼Œä»è€Œæé«˜è§†å¬è¯­è¨€å¯¹é½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†è·¨çº§ä¼ æ’­ï¼ˆCLPï¼‰å’Œç›¸äº’å¯¹æ¯”å­¦ä¹ ï¼ˆMCLï¼‰ä¸¤ä¸ªæ¨¡å—ï¼Œé€šè¿‡ä¿ƒè¿›è¡¥ä¸å’ŒåŒºåŸŸçº§åˆ«ä¹‹é—´çš„äº¤äº’å’Œä¸€è‡´æ€§æ¥æœ€å¤§é™åº¦åœ°å®ç°å±‚æ¬¡åä½œã€‚åœ¨ä¸‰ä¸ªTCGAæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„SOTAæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04613v1">PDF</a> Accepted by MICCAI2025</p>
<p><strong>Summary</strong><br>     åŸºäºå…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIsï¼‰çš„ç”Ÿå­˜é¢„æµ‹åœ¨ç™Œç—‡ç ”ç©¶ä¸­è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å—é™äºç¨€ç–çš„å¹»ç¯ç‰‡çº§æ ‡ç­¾ï¼Œæ— æ³•ä»å‰åƒç´ WSIsä¸­å­¦ä¹ åˆ¤åˆ«è¡¨ç¤ºã€‚æœ€è¿‘ï¼Œç»“åˆé™„åŠ è¯­è¨€ç›‘ç£çš„è§†å¬è¯­è¨€ï¼ˆVLï¼‰æ¨¡å‹çš„å‡ºç°ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†å¸Œæœ›ã€‚ç„¶è€Œï¼ŒåŸºäºVLçš„ç”Ÿå­˜é¢„æµ‹ä»å­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ–°é¢–çš„åˆ†å±‚è§†å¬åä½œï¼ˆHiLaï¼‰æ¡†æ¶ï¼Œä»¥æ”¹è¿›ç”Ÿå­˜é¢„æµ‹ã€‚HiLaä½¿ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨ç”ŸæˆWSIsçš„åˆ†å±‚è§†è§‰ç‰¹å¾ï¼Œå¹¶é€šè¿‡æœ€ä½³æç¤ºå­¦ä¹ ï¼ˆOPLï¼‰ä¸æè¿°å„ç§ç”Ÿå­˜ç›¸å…³å±æ€§çš„è¯­è¨€æç¤ºè¿›è¡Œå¯¹é½ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†è·¨çº§ä¼ æ’­ï¼ˆCLPï¼‰å’Œç›¸äº’å¯¹æ¯”å­¦ä¹ ï¼ˆMCLï¼‰ä¸¤ä¸ªæ¨¡å—ï¼Œä»¥é€šè¿‡ä¿ƒè¿›è¡¥ä¸å’ŒåŒºåŸŸçº§åˆ«ä¹‹é—´çš„äº¤äº’å’Œä¸€è‡´æ€§æ¥æœ€å¤§åŒ–åˆ†å±‚åˆä½œã€‚åœ¨ä¸‰ä¸ªTCGAæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†å…¶å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿå­˜é¢„æµ‹åœ¨ç™Œç—‡ç ”ç©¶ä¸­éå¸¸é‡è¦ï¼Œå…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIsï¼‰æ˜¯æ ¸å¿ƒæ•°æ®ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å—é™äºç¨€ç–çš„æ ‡ç­¾ï¼Œæ— æ³•æœ‰æ•ˆå­¦ä¹ åˆ¤åˆ«ç‰¹å¾ã€‚</li>
<li>è§†å¬è¯­è¨€ï¼ˆVLï¼‰æ¨¡å‹ä¸ºè§£å†³é—®é¢˜æä¾›äº†æ–°æ–¹å‘ï¼Œä½†é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºçš„HiLaæ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒç‰¹å¾æå–å™¨ç”Ÿæˆåˆ†å±‚è§†è§‰ç‰¹å¾ï¼Œå¹¶ä¸è¯­è¨€æç¤ºè¿›è¡Œç²¾ç»†å¯¹é½ã€‚</li>
<li>HiLaæ¡†æ¶é€šè¿‡æœ€ä½³æç¤ºå­¦ä¹ ï¼ˆOPLï¼‰æé«˜è§†å¬è¯­è¨€å¯¹é½çš„ç²¾å‡†åº¦ã€‚</li>
<li>å¼•å…¥è·¨çº§ä¼ æ’­ï¼ˆCLPï¼‰å’Œç›¸äº’å¯¹æ¯”å­¦ä¹ ï¼ˆMCLï¼‰æ¨¡å—ä»¥æœ€å¤§åŒ–åˆ†å±‚åˆä½œã€‚</li>
<li>åœ¨ä¸‰ä¸ªTCGAæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†HiLaæ¡†æ¶çš„å“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04613">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b1dec8972dd9bdbc529978bc9cadae70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30a2068165abec94173d76cbdf83d566.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="FB-Diff-Fourier-Basis-guided-Diffusion-for-Temporal-Interpolation-of-4D-Medical-Imaging"><a href="#FB-Diff-Fourier-Basis-guided-Diffusion-for-Temporal-Interpolation-of-4D-Medical-Imaging" class="headerlink" title="FB-Diff: Fourier Basis-guided Diffusion for Temporal Interpolation of 4D   Medical Imaging"></a>FB-Diff: Fourier Basis-guided Diffusion for Temporal Interpolation of 4D   Medical Imaging</h2><p><strong>Authors:Xin You, Runze Yang, Chuyan Zhang, Zhongliang Jiang, Jie Yang, Nassir Navab</strong></p>
<p>The temporal interpolation task for 4D medical imaging, plays a crucial role in clinical practice of respiratory motion modeling. Following the simplified linear-motion hypothesis, existing approaches adopt optical flow-based models to interpolate intermediate frames. However, realistic respiratory motions should be nonlinear and quasi-periodic with specific frequencies. Intuited by this property, we resolve the temporal interpolation task from the frequency perspective, and propose a Fourier basis-guided Diffusion model, termed FB-Diff. Specifically, due to the regular motion discipline of respiration, physiological motion priors are introduced to describe general characteristics of temporal data distributions. Then a Fourier motion operator is elaborately devised to extract Fourier bases by incorporating physiological motion priors and case-specific spectral information in the feature space of Variational Autoencoder. Well-learned Fourier bases can better simulate respiratory motions with motion patterns of specific frequencies. Conditioned on starting and ending frames, the diffusion model further leverages well-learned Fourier bases via the basis interaction operator, which promotes the temporal interpolation task in a generative manner. Extensive results demonstrate that FB-Diff achieves state-of-the-art (SOTA) perceptual performance with better temporal consistency while maintaining promising reconstruction metrics. Codes are available. </p>
<blockquote>
<p>åœ¨4DåŒ»å­¦æˆåƒçš„æ—¶é—´æ’å€¼ä»»åŠ¡ä¸­ï¼Œå¯¹äºå‘¼å¸è¿åŠ¨å»ºæ¨¡çš„ä¸´åºŠå®è·µèµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚éµå¾ªç®€åŒ–çš„çº¿æ€§è¿åŠ¨å‡è®¾ï¼Œç°æœ‰æ–¹æ³•é‡‡ç”¨åŸºäºå…‰æµæ¨¡å‹è¿›è¡Œä¸­é—´å¸§æ’å€¼ã€‚ç„¶è€Œï¼Œç°å®çš„å‘¼å¸è¿åŠ¨åº”è¯¥æ˜¯éçº¿æ€§ã€å‡†å‘¨æœŸæ€§çš„ï¼Œå¹¶å…·æœ‰ç‰¹å®šçš„é¢‘ç‡ã€‚åŸºäºè¿™ä¸€ç‰¹æ€§ï¼Œæˆ‘ä»¬ä»é¢‘ç‡è§’åº¦è§£å†³æ—¶é—´æ’å€¼é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§å‚…é‡Œå¶åŸºç¡€å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸ºFB-Diffã€‚å…·ä½“è€Œè¨€ï¼Œç”±äºå‘¼å¸çš„å¸¸è§„è¿åŠ¨è§„å¾‹ï¼Œæˆ‘ä»¬å¼•å…¥ç”Ÿç†è¿åŠ¨å…ˆéªŒæ¥æè¿°æ—¶é—´æ•°æ®åˆ†å¸ƒçš„ä¸€èˆ¬ç‰¹å¾ã€‚ç„¶åç²¾å¿ƒè®¾è®¡äº†å‚…é‡Œå¶è¿åŠ¨ç®—å­ï¼Œé€šè¿‡ç»“åˆç”Ÿç†è¿åŠ¨å…ˆéªŒå’Œæ¡ˆä¾‹ç‰¹å®šçš„å…‰è°±ä¿¡æ¯ï¼Œåœ¨å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨çš„ç‰¹å¾ç©ºé—´ä¸­æå–å‚…é‡Œå¶åŸºç¡€ã€‚å­¦ä¹ è‰¯å¥½çš„å‚…é‡Œå¶åŸºç¡€èƒ½æ›´å¥½åœ°æ¨¡æ‹Ÿå…·æœ‰ç‰¹å®šé¢‘ç‡çš„è¿åŠ¨æ¨¡å¼ã€‚åŸºäºèµ·å§‹å¸§å’Œç»“æŸå¸§çš„æ¡ä»¶ï¼Œæ‰©æ•£æ¨¡å‹è¿›ä¸€æ­¥åˆ©ç”¨å­¦ä¹ è‰¯å¥½çš„å‚…é‡Œå¶åŸºç¡€ï¼Œé€šè¿‡åŸºç¡€äº¤äº’ç®—å­ï¼Œä»¥ç”Ÿæˆæ–¹å¼ä¿ƒè¿›æ—¶é—´æ’å€¼ä»»åŠ¡ã€‚å¤§é‡ç»“æœè¡¨æ˜ï¼ŒFB-Diffè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ„ŸçŸ¥æ€§èƒ½ï¼Œå…·æœ‰æ›´å¥½çš„æ—¶é—´ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰å¸Œæœ›çš„é‡å»ºæŒ‡æ ‡ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04547v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹å››ç»´åŒ»å­¦æˆåƒçš„ä¸´æ—¶æ’å¸§ä»»åŠ¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å‚…é‡Œå¶åŸºç¡€å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼ˆFB-Diffï¼‰ï¼Œä»é¢‘ç‡è§’åº¦è§£å†³ä¸´æ—¶æ’å¸§é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼•å…¥ç”Ÿç†è¿åŠ¨å…ˆéªŒæ¥æè¿°ä¸´æ—¶æ•°æ®åˆ†å¸ƒçš„ä¸€èˆ¬ç‰¹å¾ï¼Œé€šè¿‡ç²¾ç»†è®¾è®¡çš„å‚…é‡Œå¶è¿åŠ¨ç®—ç¬¦æå–å‚…é‡Œå¶åŸºç¡€ï¼Œå†ç»“åˆæ‰©æ•£æ¨¡å‹å’ŒåŸºç¡€äº¤äº’ç®—ç¬¦ï¼Œä»¥ç”Ÿæˆæ–¹å¼ä¿ƒè¿›ä¸´æ—¶æ’å¸§ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFB-Diffåœ¨æ„ŸçŸ¥æ€§èƒ½å’Œé‡å»ºæŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä½³æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦æˆåƒä¸­çš„ä¸´æ—¶æ’å¸§ä»»åŠ¡å¯¹äºå‘¼å¸è¿åŠ¨å»ºæ¨¡çš„ä¸´åºŠå®è·µè‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦é‡‡ç”¨åŸºäºå…‰å­¦æµçš„æ¨¡å‹è¿›è¡Œä¸­é—´å¸§æ’å€¼ï¼Œä½†çœŸå®å‘¼å¸è¿åŠ¨åº”æ˜¯éçº¿æ€§ã€å‡†å‘¨æœŸæ€§çš„ã€‚</li>
<li>æœ¬æ–‡ä»é¢‘ç‡è§’åº¦è§£å†³ä¸´æ—¶æ’å¸§é—®é¢˜ï¼Œæå‡ºä¸€ç§å‚…é‡Œå¶åŸºç¡€å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼ˆFB-Diffï¼‰ã€‚</li>
<li>å¼•å…¥ç”Ÿç†è¿åŠ¨å…ˆéªŒæ¥æè¿°ä¸´æ—¶æ•°æ®åˆ†å¸ƒçš„ä¸€èˆ¬ç‰¹å¾ã€‚</li>
<li>é€šè¿‡å‚…é‡Œå¶è¿åŠ¨ç®—ç¬¦ç»“åˆç”Ÿç†è¿åŠ¨å…ˆéªŒå’Œç‰¹å®šé¢‘è°±ä¿¡æ¯ï¼Œæå–å‚…é‡Œå¶åŸºç¡€ã€‚</li>
<li>FB-Diffé€šè¿‡åŸºç¡€äº¤äº’ç®—ç¬¦ï¼Œåœ¨ç»™å®šèµ·å§‹å’Œç»“æŸå¸§çš„æ¡ä»¶ä¸‹ï¼Œåˆ©ç”¨å­¦ä¹ è‰¯å¥½çš„å‚…é‡Œå¶åŸºç¡€ä¿ƒè¿›ä¸´æ—¶æ’å¸§ä»»åŠ¡çš„ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04547">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4de01ca49a0b3a5944fe1a316fd66b55.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-395fa22256dc03e84718653f6b5ac703.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d8cad7080218a5ef2bf7dca51c1bb5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b28033422ea31876d122ddd210efc3ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e12517680e6b37b3e92e3d03fe89d4de.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-816a0f0240c97cd29c0c0989a037f20e.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="ViTaL-A-Multimodality-Dataset-and-Benchmark-for-Multi-pathological-Ovarian-Tumor-Recognition"><a href="#ViTaL-A-Multimodality-Dataset-and-Benchmark-for-Multi-pathological-Ovarian-Tumor-Recognition" class="headerlink" title="ViTaL: A Multimodality Dataset and Benchmark for Multi-pathological   Ovarian Tumor Recognition"></a>ViTaL: A Multimodality Dataset and Benchmark for Multi-pathological   Ovarian Tumor Recognition</h2><p><strong>Authors:You Zhou, Lijiang Chen, Guangxia Cui, Wenpei Bai, Yu Guo, Shuchang Lyu, Guangliang Cheng, Qi Zhao</strong></p>
<p>Ovarian tumor, as a common gynecological disease, can rapidly deteriorate into serious health crises when undetected early, thus posing significant threats to the health of women. Deep neural networks have the potential to identify ovarian tumors, thereby reducing mortality rates, but limited public datasets hinder its progress. To address this gap, we introduce a vital ovarian tumor pathological recognition dataset called \textbf{ViTaL} that contains \textbf{V}isual, \textbf{T}abular and \textbf{L}inguistic modality data of 496 patients across six pathological categories. The ViTaL dataset comprises three subsets corresponding to different patient data modalities: visual data from 2216 two-dimensional ultrasound images, tabular data from medical examinations of 496 patients, and linguistic data from ultrasound reports of 496 patients. It is insufficient to merely distinguish between benign and malignant ovarian tumors in clinical practice. To enable multi-pathology classification of ovarian tumor, we propose a ViTaL-Net based on the Triplet Hierarchical Offset Attention Mechanism (THOAM) to minimize the loss incurred during feature fusion of multi-modal data. This mechanism could effectively enhance the relevance and complementarity between information from different modalities. ViTaL-Net serves as a benchmark for the task of multi-pathology, multi-modality classification of ovarian tumors. In our comprehensive experiments, the proposed method exhibited satisfactory performance, achieving accuracies exceeding 90% on the two most common pathological types of ovarian tumor and an overall performance of 85%. Our dataset and code are available at <a target="_blank" rel="noopener" href="https://github.com/GGbond-study/vitalnet">https://github.com/GGbond-study/vitalnet</a>. </p>
<blockquote>
<p>åµå·¢è‚¿ç˜¤æ˜¯ä¸€ç§å¸¸è§çš„å¦‡ç§‘ç–¾ç—…ï¼Œå¦‚æœæ—©æœŸæœªè¢«å‘ç°ï¼Œä¼šè¿…é€Ÿæ¶åŒ–æˆä¸¥é‡çš„å¥åº·å±æœºï¼Œä»è€Œå¯¹å¥³æ€§çš„å¥åº·æ„æˆé‡å¤§å¨èƒã€‚æ·±åº¦ç¥ç»ç½‘ç»œæœ‰æ½œåŠ›è¯†åˆ«åµå·¢è‚¿ç˜¤ï¼Œä»è€Œé™ä½æ­»äº¡ç‡ï¼Œä½†æœ‰é™çš„å…¬å¼€æ•°æ®é›†é˜»ç¢äº†å…¶è¿›å±•ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé‡è¦çš„åµå·¢è‚¿ç˜¤ç—…ç†è¯†åˆ«æ•°æ®é›†ï¼Œåä¸ºâ€œViTaLâ€ï¼Œå®ƒåŒ…å«äº†496åæ‚£è€…è·¨è¶Šå…­ä¸ªç—…ç†ç±»åˆ«çš„è§†è§‰ã€è¡¨æ ¼å’Œè¯­è¨€æ¨¡å¼æ•°æ®ã€‚ViTaLæ•°æ®é›†ç”±ä¸‰ä¸ªå­é›†ç»„æˆï¼Œå¯¹åº”äºä¸åŒçš„æ‚£è€…æ•°æ®æ¨¡å¼ï¼šæ¥è‡ª2216å¼ äºŒç»´è¶…å£°å›¾åƒçš„è§†è§‰æ•°æ®ã€æ¥è‡ª496åæ‚£è€…çš„åŒ»å­¦æ£€æŸ¥è¡¨æ ¼æ•°æ®ä»¥åŠæ¥è‡ª4 9 6åæ‚£è€…çš„è¶…å£°æŠ¥å‘Šè¯­è¨€æ•°æ®ã€‚åœ¨ä¸´åºŠä¸Šï¼Œä»…ä»…åŒºåˆ†è‰¯æ€§å’Œæ¶æ€§åµå·¢è‚¿ç˜¤æ˜¯ä¸å¤Ÿçš„ã€‚ä¸ºäº†å®ç°åµå·¢è‚¿ç˜¤çš„å¤šç—…ç†åˆ†ç±»ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸‰å…ƒå±‚æ¬¡åç§»æ³¨æ„æœºåˆ¶ï¼ˆTHOAMï¼‰çš„ViTaL-Netï¼Œä»¥æœ€å°åŒ–å¤šæ¨¡å¼æ•°æ®ç‰¹å¾èåˆè¿‡ç¨‹ä¸­çš„æŸå¤±ã€‚è¯¥æœºåˆ¶å¯ä»¥æœ‰æ•ˆåœ°å¢å¼ºä¸åŒæ¨¡å¼ä¿¡æ¯ä¹‹é—´çš„ç›¸å…³æ€§å’Œäº’è¡¥æ€§ã€‚ViTaL-Netå¯ä½œä¸ºåµå·¢è‚¿ç˜¤å¤šç—…ç†ã€å¤šæ¨¡å¼åˆ†ç±»ä»»åŠ¡çš„æ ‡å‡†ã€‚æˆ‘ä»¬çš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¡¨ç°è‰¯å¥½ï¼Œåœ¨ä¸¤ç§æœ€å¸¸è§çš„åµå·¢è‚¿ç˜¤ç—…ç†ç±»å‹ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œæ€»ä½“æ€§èƒ½è¾¾åˆ°85%ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/GGbond-study/vitalnet%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/GGbond-study/vitalnetä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04383v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åµå·¢è‚¿ç˜¤ä½œä¸ºä¸€ç§å¸¸è§çš„å¦‡ç§‘ç–¾ç—…ï¼Œæ—©æœŸå‘ç°å¯¹å…¶æ²»ç–—è‡³å…³é‡è¦ã€‚ä¸ºè§£å†³å½“å‰æ·±åº¦å­¦ä¹ åœ¨åµå·¢è‚¿ç˜¤è¯†åˆ«æ–¹é¢çš„æ•°æ®ç¼ºå£é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†ä¸€ä¸ªåŒ…å«è§†è§‰ã€è¡¨æ ¼å’Œè¯­è¨€å­¦æ•°æ®çš„å¤šæ¨¡å¼åµå·¢è‚¿ç˜¤ç—…ç†è¯†åˆ«æ•°æ®é›†â€”â€”ViTaLæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åŸºäºTriplet Hierarchical Offset Attention Mechanismï¼ˆTHOAMï¼‰çš„ViTaL-Netæ¨¡å‹ï¼Œç”¨äºå¤šæ¨¡å¼æ•°æ®çš„ç‰¹å¾èåˆï¼Œæé«˜ä¸åŒä¿¡æ¯ä¹‹é—´çš„ç›¸å…³æ€§å’Œäº’è¡¥æ€§ï¼Œå®ç°å¯¹åµå·¢è‚¿ç˜¤çš„å¤šç—…ç†åˆ†ç±»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¤ç§æœ€å¸¸è§çš„åµå·¢è‚¿ç˜¤ç—…ç†ç±»å‹ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œæ€»ä½“æ€§èƒ½è¾¾åˆ°85%ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€åˆ†äº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åµå·¢è‚¿ç˜¤æ˜¯å¸¸è§çš„å¦‡ç§‘ç–¾ç—…ï¼Œæ—©æœŸå‘ç°å¯¹æ²»ç–—è‡³å…³é‡è¦ã€‚</li>
<li>ç¼ºä¹å…¬å…±æ•°æ®é›†é™åˆ¶äº†æ·±åº¦å­¦ä¹ åœ¨åµå·¢è‚¿ç˜¤è¯†åˆ«æ–¹é¢çš„è¿›å±•ã€‚</li>
<li>æ¨å‡ºäº†ä¸€ä¸ªåŒ…å«è§†è§‰ã€è¡¨æ ¼å’Œè¯­è¨€å­¦æ•°æ®çš„å¤šæ¨¡å¼åµå·¢è‚¿ç˜¤ç—…ç†è¯†åˆ«æ•°æ®é›†â€”â€”ViTaLæ•°æ®é›†ã€‚</li>
<li>ViTaLæ•°æ®é›†åŒ…å«ä¸‰ç§ä¸åŒç±»å‹çš„æ‚£è€…æ•°æ®ï¼šæ¥è‡ª2216å¼ äºŒç»´è¶…å£°å›¾åƒçš„è§†è§‰æ•°æ®ã€æ¥è‡ª496åæ‚£è€…çš„åŒ»å­¦æ£€æŸ¥è¡¨æ ¼æ•°æ®ä»¥åŠæ¥è‡ªç›¸åŒæ‚£è€…çš„è¶…å£°æŠ¥å‘Šè¯­è¨€å­¦æ•°æ®ã€‚</li>
<li>æå‡ºäº†åŸºäºTriplet Hierarchical Offset Attention Mechanismï¼ˆTHOAMï¼‰çš„ViTaL-Netæ¨¡å‹ï¼Œç”¨äºå¤šæ¨¡å¼æ•°æ®çš„ç‰¹å¾èåˆå’Œå¤šç—…ç†åˆ†ç±»ã€‚</li>
<li>ViTaL-Netæ¨¡å‹åœ¨ä¸¤ç§æœ€å¸¸è§çš„åµå·¢è‚¿ç˜¤ç—…ç†ç±»å‹ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œæ€»ä½“æ€§èƒ½è¾¾åˆ°85%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04383">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-002767e4252befd3aba507b50a3ca693.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0cfba260a67bf84762ad7cc7e42561a.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Intertwined-Orders-in-a-Quantum-Entangled-Metal"><a href="#Intertwined-Orders-in-a-Quantum-Entangled-Metal" class="headerlink" title="Intertwined Orders in a Quantum-Entangled Metal"></a>Intertwined Orders in a Quantum-Entangled Metal</h2><p><strong>Authors:Junyoung Kwon, Jaehwon Kim, Gwansuk Oh, Seyoung Jin, Kwangrae Kim, Hoon Kim, Seunghyeok Ha, Hyun-Woo J. Kim, GiBaik Sim, Bjorn Wehinger, Gaston Garbarino, Nour Maraytta, Michael Merz, Matthieu Le Tacon, Christoph J. Sahle, Alessandro Longo, Jungho Kim, Ara Go, Gil Young Cho, Beom Hyun Kim, B. J. Kim</strong></p>
<p>Entanglement underpins quantum information processing and computing, yet its experimental quantification in complex, many-body condensed matter systems remains a considerable challenge. Here, we reveal a highly entangled electronic phase proximate to a quantum metal-insulator transition, identified by resonant inelastic x-ray scattering interferometry. This approach reveals that entanglement across atomic sites generates characteristic interference patterns, which our model accurately reproduces, enabling extraction of a full entanglement spectrum and resolution of the underlying quantum states. Our analysis of the pyrochlore iridate Nd2Ir2O7 demonstrates that the system undergoes pronounced quantum fluctuations in its spin, orbital and charge degrees of freedom, even in the presence of a long-range â€˜all-in-all-outâ€™ antiferromagnetic order. Importantly, the observed entanglement signatures facilitate the coexistence of multiple exotic symmetry-breaking orders. Complementary investigations using Raman spectroscopy corroborate the presence of these hidden orders and their emergent excitations. In particular, we observe a two-magnon-bound state below the lowest single-magnon excitation energy, which, together with split phonon modes, provides strong evidence for cubic symmetry-breaking orders of magnetic origin juxtaposed with the all-in-all-out order. Our work thus establishes a direct link between quantum entanglement and emergent unconventional orders, opening new avenues for investigating quantum materials. </p>
<blockquote>
<p>çº ç¼ æ˜¯é‡å­ä¿¡æ¯å¤„ç†ä¸è®¡ç®—çš„åŸºç¡€ï¼Œä½†åœ¨å¤æ‚çš„ã€å¤šä½“å‡èšæ€ç³»ç»Ÿä¸­å¯¹å…¶è¿›è¡Œå®éªŒé‡åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„å¹²æ¶‰ä»ªæ­ç¤ºäº†ä¸€ç§é«˜åº¦çº ç¼ çš„ç”µå­ç›¸ï¼Œå®ƒä½äºé‡å­é‡‘å±ç»ç¼˜ä½“è½¬å˜é™„è¿‘ã€‚è¿™ç§æ–¹æ³•æ­ç¤ºäº†åŸå­ä½ç‚¹ä¹‹é—´çš„çº ç¼ ä¼šäº§ç”Ÿç‰¹å¾å¹²æ¶‰å›¾æ¡ˆï¼Œæˆ‘ä»¬çš„æ¨¡å‹å‡†ç¡®åœ°å†ç°äº†è¿™äº›å›¾æ¡ˆï¼Œèƒ½å¤Ÿæå–å®Œæ•´çš„çº ç¼ è°±å¹¶è§£å†³æ½œåœ¨çš„é‡å­æ€ã€‚æˆ‘ä»¬å¯¹çƒ§ç»¿çŸ¿å«é“±é…¸ç›Nd2Ir2O7çš„åˆ†æè¡¨æ˜ï¼Œå³ä½¿åœ¨è¿œç¨‹çš„â€œå…¨è¿›å…¨å‡ºâ€åé“ç£åºå­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œè¯¥ç³»ç»Ÿåœ¨è‡ªæ—‹ã€è½¨é“å’Œç”µè·è‡ªç”±åº¦ä¸Šä¹Ÿç»å†äº†æ˜æ˜¾çš„é‡å­æ³¢åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼Œè§‚å¯Ÿåˆ°çš„çº ç¼ ç‰¹å¾ä¿ƒè¿›äº†å¤šç§å¥‡å¼‚çš„å¯¹ç§°ç ´ç¼ºåºçš„å…±å­˜ã€‚ä½¿ç”¨æ‹‰æ›¼å…‰è°±æ³•è¿›è¡Œçš„è¡¥å……è°ƒæŸ¥è¯å®äº†è¿™äº›éšè—è®¢å•åŠå…¶æ–°å…´å…´å¥‹å‰‚çš„å­˜åœ¨ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä½äºæœ€ä½å•ç£æ¿€å‘èƒ½é‡çš„ä¸¤ç£å­æŸç¼šæ€ï¼Œä»¥åŠä¸åˆ†è£‚çš„å£°å­æ¨¡å¼ç›¸ç»“åˆï¼Œè¿™ä¸ºä¸â€œå…¨è¿›å…¨å‡ºâ€é¡ºåºç›¸é‚»çš„ç£èµ·æºçš„ç«‹æ–¹å¯¹ç§°ç ´ç¼ºé¡ºåºæä¾›äº†å¼ºæœ‰åŠ›çš„è¯æ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„å·¥ä½œå»ºç«‹äº†é‡å­çº ç¼ ä¸æ–°å…´éä¼ ç»Ÿé¡ºåºä¹‹é—´çš„ç›´æ¥è”ç³»ï¼Œä¸ºè°ƒæŸ¥é‡å­ææ–™å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04375v1">PDF</a> </p>
<p><strong>Summary</strong><br>é‡å­çº ç¼ æ˜¯é‡å­ä¿¡æ¯å¤„ç†ä¸è®¡ç®—çš„åŸºç¡€ï¼Œä½†åœ¨å¤æ‚çš„ã€å¤šä½“å‡èšæ€ç³»ç»Ÿä¸­å¯¹å…¶è¿›è¡Œå®éªŒé‡åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡é€šè¿‡å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„å¹²æ¶‰æµ‹é‡æ³•æ­ç¤ºäº†ä¸€ç§é«˜åº¦çº ç¼ çš„ç”µå­ç›¸ä½ï¼Œå®ƒä½äºé‡å­é‡‘å±-ç»ç¼˜ä½“è½¬å˜é™„è¿‘ã€‚è¯¥ç ”ç©¶é€šè¿‡åŸå­ä½ç‚¹çš„çº ç¼ äº§ç”Ÿç‰¹å¾å¹²æ¶‰æ¨¡å¼ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å‡†ç¡®å†ç°äº†è¿™äº›æ¨¡å¼ï¼Œä»è€Œæå–äº†å®Œæ•´çš„çº ç¼ è°±å¹¶è§£å†³äº†ä¸€äº›åŸºæœ¬çš„é‡å­çŠ¶æ€ã€‚æˆ‘ä»¬å¯¹é”†é…¸ç›çš„ç ”ç©¶è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨æ—‹è½¬ã€è½¨é“å’Œç”µè·è‡ªç”±åº¦æ–¹é¢ç»å†äº†æ˜æ˜¾çš„é‡å­æ³¢åŠ¨ï¼Œå³ä½¿åœ¨é•¿ç¨‹çš„â€œå…¨è¿›å…¨å‡ºâ€åé“ç£æ’åºä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è§‚å¯Ÿåˆ°çš„é‡è¦çº ç¼ ç‰¹å¾ä½¿å¾—å¤šä¸ªå¼‚ç§å¯¹ç§°æ€§ç ´ç¼ºå…±å­˜æˆä¸ºå¯èƒ½ã€‚æ‹‰æ›¼å…‰è°±æ³•éªŒè¯éšè—ç€çš„é‡å­æ’åºçš„å­˜åœ¨ä»¥åŠå…¶æ–°å…´æ¿€å‘çš„å­˜åœ¨ã€‚è§‚å¯Ÿåˆ°ä½äºæœ€ä½å•ç£æ¿€å‘èƒ½é‡çš„ä¸¤ç£å­æŸç¼šæ€ä»¥åŠåˆ†è£‚çš„å£°å­æ¨¡å¼ï¼Œè¿™ä¸ºç£èµ·æºçš„ç«‹æ–¹å¯¹ç§°æ€§ç ´ç¼ºæ’åºæä¾›äº†å¼ºæœ‰åŠ›çš„è¯æ®ã€‚æˆ‘ä»¬çš„ç ”ç©¶åœ¨é‡å­çº ç¼ å’Œæ–°å…´çš„éä¼ ç»Ÿæ’åºä¹‹é—´å»ºç«‹äº†ç›´æ¥è”ç³»ï¼Œä¸ºè°ƒæŸ¥é‡å­ææ–™å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®éªŒæ­ç¤ºäº†é«˜åº¦çº ç¼ çš„ç”µå­ç›¸ä½åœ¨é‡å­é‡‘å±-ç»ç¼˜ä½“è½¬å˜é™„è¿‘çš„ç‰¹å¾ã€‚</li>
<li>é€šè¿‡å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„å¹²æ¶‰æµ‹é‡æ³•ï¼Œè§‚å¯Ÿåˆ°äº†åŸå­ä½ç‚¹çš„çº ç¼ äº§ç”Ÿçš„ç‰¹å¾å¹²æ¶‰æ¨¡å¼ã€‚</li>
<li>å‡†ç¡®çš„æ¨¡å‹å¤ç°äº†è¿™äº›å¹²æ¶‰æ¨¡å¼ï¼Œä»è€Œèƒ½å¤Ÿæå–å®Œæ•´çš„çº ç¼ è°±ã€‚</li>
<li>åœ¨é”†é…¸ç›çš„ç ”ç©¶ä¸­ï¼Œå‘ç°äº†ç³»ç»Ÿåœ¨æ—‹è½¬ã€è½¨é“å’Œç”µè·è‡ªç”±åº¦æ–¹é¢çš„é‡å­æ³¢åŠ¨ã€‚</li>
<li>è§‚å¯Ÿåˆ°çš„é‡è¦çº ç¼ ç‰¹å¾æ”¯æŒäº†å¤šä¸ªå¼‚ç§å¯¹ç§°æ€§ç ´ç¼ºçš„å…±å­˜å¯èƒ½æ€§ã€‚</li>
<li>æ‹‰æ›¼å…‰è°±æ³•éªŒè¯äº†éšè—çš„é‡å­æ’åºçš„å­˜åœ¨åŠå…¶æ–°å…´æ¿€å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04375">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a62f0729d3ab904f2a92d77c2473382f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-695b06f14cc2606ec13661b1b643c708.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4b835fcda4f8aab6a3f90c22d0a4098.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0067e607a1f9b85650fdcfea67d683b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-326268b577442db1131b4d31de171e77.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="An-Explainable-Transformer-Model-for-Alzheimerâ€™s-Disease-Detection-Using-Retinal-Imaging"><a href="#An-Explainable-Transformer-Model-for-Alzheimerâ€™s-Disease-Detection-Using-Retinal-Imaging" class="headerlink" title="An Explainable Transformer Model for Alzheimerâ€™s Disease Detection Using   Retinal Imaging"></a>An Explainable Transformer Model for Alzheimerâ€™s Disease Detection Using   Retinal Imaging</h2><p><strong>Authors:Saeed Jamshidiha, Alireza Rezaee, Farshid Hajati, Mojtaba Golzan, Raymond Chiong</strong></p>
<p>Alzheimerâ€™s disease (AD) is a neurodegenerative disorder that affects millions worldwide. In the absence of effective treatment options, early diagnosis is crucial for initiating management strategies to delay disease onset and slow down its progression. In this study, we propose Retformer, a novel transformer-based architecture for detecting AD using retinal imaging modalities, leveraging the power of transformers and explainable artificial intelligence. The Retformer model is trained on datasets of different modalities of retinal images from patients with AD and age-matched healthy controls, enabling it to learn complex patterns and relationships between image features and disease diagnosis. To provide insights into the decision-making process of our model, we employ the Gradient-weighted Class Activation Mapping algorithm to visualize the feature importance maps, highlighting the regions of the retinal images that contribute most significantly to the classification outcome. These findings are compared to existing clinical studies on detecting AD using retinal biomarkers, allowing us to identify the most important features for AD detection in each imaging modality. The Retformer model outperforms a variety of benchmark algorithms across different performance metrics by margins of up to 11. </p>
<blockquote>
<p>é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰æ˜¯ä¸€ç§å½±å“å…¨çƒæ•°ç™¾ä¸‡äººçš„ç¥ç»é€€è¡Œæ€§ç–¾ç—…ã€‚ç”±äºæ²¡æœ‰æœ‰æ•ˆçš„æ²»ç–—é€‰æ‹©ï¼Œæ—©æœŸè¯Šæ–­å¯¹äºå¯åŠ¨ç®¡ç†ç­–ç•¥ä»¥å»¶è¿Ÿç–¾ç—…å‘ä½œå’Œå‡ç¼“å…¶è¿›å±•è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Retformerï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå˜å‹å™¨çš„æ–°å‹æ¶æ„ï¼Œåˆ©ç”¨å˜å‹å™¨å’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ›é‡ï¼Œé€šè¿‡è§†ç½‘è†œæˆåƒæ¨¡å¼æ£€æµ‹ADã€‚Retformeræ¨¡å‹æ¥å—æ¥è‡ªADæ‚£è€…å’Œå¹´é¾„ç›¸åŒ¹é…çš„å¥åº·å¯¹ç…§è€…çš„ä¸åŒæ¨¡å¼çš„è§†ç½‘è†œå›¾åƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ å›¾åƒç‰¹å¾ä¸ç–¾ç—…è¯Šæ–­ä¹‹é—´çš„å¤æ‚æ¨¡å¼å’Œå…³ç³»ã€‚ä¸ºäº†æ·±å…¥äº†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼Œæˆ‘ä»¬é‡‡ç”¨å¸¦æ¢¯åº¦çš„ç±»æ¿€æ´»æ˜ å°„ç®—æ³•æ¥å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§å›¾ï¼Œçªå‡ºæ˜¾ç¤ºå¯¹åˆ†ç±»ç»“æœè´¡çŒ®æœ€å¤§çš„è§†ç½‘è†œå›¾åƒåŒºåŸŸã€‚è¿™äº›å‘ç°ä¸ç°æœ‰çš„å…³äºä½¿ç”¨è§†ç½‘è†œç”Ÿç‰©æ ‡å¿—ç‰©æ£€æµ‹ADçš„ä¸´åºŠç ”ç©¶è¿›è¡Œæ¯”è¾ƒï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ç§æˆåƒæ¨¡å¼ä¸­è¯†åˆ«å‡ºå¯¹ADæ£€æµ‹æœ€é‡è¦çš„ç‰¹å¾ã€‚Retformeræ¨¡å‹åœ¨å„ç§æ€§èƒ½æŒ‡æ ‡ä¸Šå‡ä¼˜äºå„ç§åŸºå‡†ç®—æ³•ï¼Œä¼˜åŠ¿å¹…åº¦é«˜è¾¾11%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04259v1">PDF</a> 20 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè§†ç½‘è†œæˆåƒçš„é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰æ£€æµ‹æ–°æ–¹æ³•â€”â€”Retformerã€‚è¯¥æ–¹æ³•åˆ©ç”¨Transformerå’Œå¯è§£é‡Šäººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¼˜åŠ¿ï¼Œé€šè¿‡å¤šæ¨¡æ€è§†ç½‘è†œå›¾åƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ å›¾åƒç‰¹å¾ä¸ç–¾ç—…è¯Šæ–­ä¹‹é—´çš„å¤æ‚æ¨¡å¼å’Œå…³ç³»ã€‚é‡‡ç”¨æ¢¯åº¦åŠ æƒç±»æ¿€æ´»æ˜ å°„ç®—æ³•å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§å›¾ï¼Œä»¥æ­ç¤ºæ¨¡å‹å†³ç­–è¿‡ç¨‹ä¸­çš„å…³é”®åŒºåŸŸã€‚Retformeræ¨¡å‹åœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç®—æ³•ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦æœ€é«˜è¾¾11%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Retformeræ˜¯ä¸€ç§åŸºäºTransformerçš„æ¶æ„ï¼Œç”¨äºé€šè¿‡è§†ç½‘è†œæˆåƒæ£€æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—…ã€‚</li>
<li>è¯¥æ¨¡å‹åˆ©ç”¨å¤šæ¨¡æ€è§†ç½‘è†œå›¾åƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ å›¾åƒç‰¹å¾ä¸ç–¾ç—…è¯Šæ–­ä¹‹é—´çš„å¤æ‚æ¨¡å¼ã€‚</li>
<li>é‡‡ç”¨æ¢¯åº¦åŠ æƒç±»æ¿€æ´»æ˜ å°„ç®—æ³•æ­ç¤ºæ¨¡å‹å†³ç­–è¿‡ç¨‹ä¸­çš„å…³é”®åŒºåŸŸã€‚</li>
<li>Retformeræ¨¡å‹åœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰ç®—æ³•ã€‚</li>
<li>è¯¥ç ”ç©¶é€šè¿‡ä¸ç°æœ‰ä¸´åºŠç ”ç©¶æ¯”è¾ƒï¼Œç¡®å®šäº†ä¸åŒæˆåƒæ¨¡å¼ä¸‹æ£€æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—…çš„å…³é”®ç‰¹å¾ã€‚</li>
<li>è§†ç½‘è†œæˆåƒå¯èƒ½ä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…çš„æ—©æœŸæ£€æµ‹å’Œç–¾ç—…ç®¡ç†ç­–ç•¥æä¾›æœ‰æ•ˆå·¥å…·ã€‚</li>
<li>è¯¥æ–¹æ³•çš„åº”ç”¨æœ‰åŠ©äºå»¶è¿Ÿé˜¿å°”èŒ¨æµ·é»˜ç—…çš„å‘ç—…å¹¶å‡ç¼“å…¶è¿›å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04259">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c1c81947128afae1c50e481ec913b8d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-be53d74449be514830c1b18650d41759.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb0d3f9ef9d3e09aca36c131250b8592.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Grid-Reg-Grid-Based-SAR-and-Optical-Image-Registration-Across-Platforms"><a href="#Grid-Reg-Grid-Based-SAR-and-Optical-Image-Registration-Across-Platforms" class="headerlink" title="Grid-Reg: Grid-Based SAR and Optical Image Registration Across Platforms"></a>Grid-Reg: Grid-Based SAR and Optical Image Registration Across Platforms</h2><p><strong>Authors:Xiaochen Wei, Weiwei Guo, Zenghui Zhang, Wenxian Yu</strong></p>
<p>Registering airborne SAR with spaceborne optical images is crucial for SAR image interpretation and geo-localization. It is challenging for this cross-platform heterogeneous image registration due to significant geometric and radiation differences, which current methods fail to handle. To tackle these challenges, we propose a novel grid-based multimodal registration framework (Grid-Reg) across airborne and space-born platforms, including a new domain-robust descriptor extraction network, Hybrid Siamese Correlation Metric Learning Network (HSCMLNet) and a grid-based solver (Grid-solver) for transformation parameters estimation. Our Grid-Reg is based on detector-free and global matching loss rather than accurate keypoint correspondences. These accurate correspondences are inherently difficult in heterogeneous images with large geometric deformation. By Grid-Solver, our Grid-Reg estimates transformation parameters by optimizing robust global matching loss-based patch correspondences of whole images in a coarse-to-fine strategy. To robustly calculate the similarity between patches, specifically that have noise and change objects, we propose HSCMLNet, including a hybrid Siamese module to extract high-level features of multimodal images and a correlation learning module (CMLModule) based equiangular unit basis vectors (EUBVs). Moreover, we propose a manifold loss EUBVsLoss to constrain the normalized correlation between local embeddings of patches and EUBVs. Furthermore, we curate a new challenging benchmark dataset of SAR-to-optical registration using real-world UAV MiniSAR data and optical images from Google Earth. We extensively analyze factors affecting registration accuracy and compare our method with state-of-the-art techniques on this dataset, showing superior performance. </p>
<blockquote>
<p>å°†ç©ºä¸­SARå›¾åƒä¸å¤ªç©ºå…‰å­¦å›¾åƒè¿›è¡Œé…å‡†å¯¹äºSARå›¾åƒè§£è¯»å’Œåœ°ç†å®šä½è‡³å…³é‡è¦ã€‚ç”±äºæ˜¾è‘—çš„å‡ ä½•å’Œè¾å°„å·®å¼‚ï¼Œè¿™ç§è·¨å¹³å°å¼‚è´¨å›¾åƒé…å‡†é¢ä¸´æŒ‘æˆ˜ï¼Œè€Œç°æœ‰æ–¹æ³•æ— æ³•å¤„ç†è¿™äº›å·®å¼‚ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç½‘æ ¼çš„å¤šæ¨¡å¼é…å‡†æ¡†æ¶ï¼ˆGrid-Regï¼‰ï¼Œé€‚ç”¨äºç©ºä¸­å’Œå¤ªç©ºå¹³å°ï¼ŒåŒ…æ‹¬æ–°çš„åŸŸç¨³å¥æè¿°ç¬¦æå–ç½‘ç»œã€æ··åˆè¥¿å§†æ–¯ç›¸å…³åº¦é‡å­¦ä¹ ç½‘ç»œï¼ˆHSCMLNetï¼‰å’ŒåŸºäºç½‘æ ¼çš„æ±‚è§£å™¨ï¼ˆGrid-solverï¼‰æ¥ä¼°è®¡å˜æ¢å‚æ•°ã€‚æˆ‘ä»¬çš„Grid-RegåŸºäºæ£€æµ‹å™¨è‡ªç”±å’Œå…¨å±€åŒ¹é…æŸå¤±ï¼Œè€Œä¸æ˜¯å‡†ç¡®çš„å…³é”®ç‚¹å¯¹åº”å…³ç³»ã€‚åœ¨å…·æœ‰å¤§å‡ ä½•å˜å½¢çš„å¼‚è´¨å›¾åƒä¸­ï¼Œè¿™äº›å‡†ç¡®çš„å¯¹åº”å…³ç³»æœ¬è´¨ä¸Šæ˜¯å›°éš¾çš„ã€‚é€šè¿‡Grid-Solverï¼Œæˆ‘ä»¬çš„Grid-Regé‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œé€šè¿‡ä¼˜åŒ–åŸºäºå…¨å±€åŒ¹é…æŸå¤±çš„å›¾åƒè¡¥ä¸å¯¹åº”å…³ç³»æ¥ä¼°è®¡å˜æ¢å‚æ•°ã€‚ä¸ºäº†ç¨³å¥åœ°è®¡ç®—è¡¥ä¸ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å…·æœ‰å™ªå£°å’Œå˜åŒ–ç›®æ ‡çš„è¡¥ä¸ï¼Œæˆ‘ä»¬æå‡ºäº†HSCMLNetï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ··åˆè¥¿å§†æ–¯æ¨¡å—æ¥æå–å¤šæ¨¡å¼å›¾åƒçš„é«˜çº§ç‰¹å¾å’Œä¸€ä¸ªåŸºäºç­‰è§’å•ä½åŸºå‘é‡ï¼ˆEUBVsï¼‰çš„ç›¸å…³å­¦ä¹ æ¨¡å—ï¼ˆCMLModuleï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æµå½¢æŸå¤±EUBVsLossæ¥çº¦æŸè¡¥ä¸å±€éƒ¨åµŒå…¥ä¸EUBVsä¹‹é—´çš„å½’ä¸€åŒ–ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¥è‡ªGoogle Earthçš„çœŸå®æ— äººæœºMiniSARæ•°æ®å’Œå…‰å­¦å›¾åƒï¼Œåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„SARåˆ°å…‰å­¦é…å‡†åŸºå‡†æ•°æ®é›†ã€‚æˆ‘ä»¬å…¨é¢åˆ†æäº†å½±å“é…å‡†ç²¾åº¦çš„å› ç´ ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šä¸æœ€å…ˆè¿›çš„æŠ€æœ¯è¿›è¡Œäº†æ¯”è¾ƒï¼Œæ˜¾ç¤ºäº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04233v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹ç©ºä¸­SARå›¾åƒä¸å¤ªç©ºå…‰å­¦å›¾åƒçš„æ³¨å†Œé—®é¢˜ï¼Œå­˜åœ¨æ˜¾è‘—å‡ ä½•å’Œè¾å°„å·®å¼‚ï¼Œå½“å‰æ–¹æ³•éš¾ä»¥å¤„ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åŸºäºç½‘æ ¼çš„å¤šæ¨¡æ€æ³¨å†Œæ¡†æ¶ï¼ˆGrid-Regï¼‰ï¼ŒåŒ…æ‹¬Hybrid Siamese Correlation Metric Learning Networkï¼ˆHSCMLNetï¼‰å’ŒåŸºäºç½‘æ ¼çš„æ±‚è§£å™¨ï¼ˆGrid-solverï¼‰ã€‚Grid-RegåŸºäºæ— æ£€æµ‹å™¨å’Œå…¨å±€åŒ¹é…æŸå¤±ï¼Œæ— éœ€å‡†ç¡®çš„å…³é”®ç‚¹å¯¹åº”å…³ç³»ã€‚é€šè¿‡Grid-solverï¼Œæˆ‘ä»¬çš„Grid-Regé‡‡ç”¨ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œé€šè¿‡ä¼˜åŒ–åŸºäºå…¨å±€åŒ¹é…æŸå¤±çš„å›¾åƒè¡¥ä¸å¯¹åº”å…³ç³»æ¥ä¼°è®¡è½¬æ¢å‚æ•°ã€‚ä¸ºè®¡ç®—å™ªå£°å’Œå˜åŒ–å¯¹è±¡ä¹‹é—´çš„è¡¥ä¸ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬æå‡ºHSCMLNetï¼ŒåŒ…æ‹¬æå–å¤šæ¨¡æ€å›¾åƒé«˜çº§ç‰¹å¾çš„æ··åˆSiameseæ¨¡å—å’ŒåŸºäºç­‰è§’å•ä½åŸºå‘é‡ï¼ˆEUBVsï¼‰çš„ç›¸å…³æ€§å­¦ä¹ æ¨¡å—ï¼ˆCMLModuleï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥æµå½¢æŸå¤±EUBVsLossæ¥çº¦æŸè¡¥ä¸å±€éƒ¨åµŒå…¥ä¸EUBVsä¹‹é—´çš„å½’ä¸€åŒ–ç›¸å…³æ€§ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„SARåˆ°å…‰å­¦æ³¨å†ŒåŸºå‡†æ•°æ®é›†ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šåˆ†æäº†å½±å“æ³¨å†Œç²¾åº¦çš„å› ç´ ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œå±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç©ºä¸­SARå›¾åƒä¸å¤ªç©ºå…‰å­¦å›¾åƒä¹‹é—´çš„æ³¨å†Œå¯¹äºSARå›¾åƒè§£è¯»å’Œåœ°ç†å®šä½è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰æ–¹æ³•éš¾ä»¥å¤„ç†è·¨å¹³å°å’Œå¼‚è´¨å›¾åƒä¹‹é—´çš„æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç½‘æ ¼çš„å¤šæ¨¡æ€æ³¨å†Œæ¡†æ¶ï¼ˆGrid-Regï¼‰ï¼Œç”¨äºå¤„ç†ç©ºä¸­å’Œå¤ªç©ºå¹³å°ä¹‹é—´çš„å¼‚è´¨å›¾åƒã€‚</li>
<li>Grid-Regåˆ©ç”¨æ— æ£€æµ‹å™¨å’Œå…¨å±€åŒ¹é…æŸå¤±ï¼Œé¿å…äº†åœ¨å…·æœ‰å¤§å‡ ä½•å˜å½¢çš„å¼‚è´¨å›¾åƒä¸­å¯»æ‰¾å‡†ç¡®å¯¹åº”ç‚¹çš„å›°éš¾ã€‚</li>
<li>å¼•å…¥äº†Hybrid Siamese Correlation Metric Learning Network (HSCMLNet) æ¥è®¡ç®—è¡¥ä¸ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œç‰¹åˆ«æ˜¯å¤„ç†å«å™ªå£°å’Œå˜åŒ–å¯¹è±¡çš„è¡¥ä¸ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æµå½¢æŸå¤±EUBVsLossï¼Œç”¨äºçº¦æŸå±€éƒ¨åµŒå…¥ä¸ç­‰è§’å•ä½åŸºå‘é‡ï¼ˆEUBVsï¼‰ä¹‹é—´çš„å½’ä¸€åŒ–ç›¸å…³æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04233">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7067b6290b37ddab1fa9a2cdcf9979e1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-88e45d8b00475552f21c9ecaefb324b0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0a0194e3c3b4399f1bc14932df3d8d06.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-98ccb38354d48910fa32bfa1adb158b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54f621587ea237a01d72a2626cdc407a.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Hyperspectral-Dual-Comb-Compressive-Imaging-for-Minimally-Invasive-Video-Rate-Endomicroscopy"><a href="#Hyperspectral-Dual-Comb-Compressive-Imaging-for-Minimally-Invasive-Video-Rate-Endomicroscopy" class="headerlink" title="Hyperspectral Dual-Comb Compressive Imaging for Minimally-Invasive   Video-Rate Endomicroscopy"></a>Hyperspectral Dual-Comb Compressive Imaging for Minimally-Invasive   Video-Rate Endomicroscopy</h2><p><strong>Authors:Myoung-Gyun Suh, David Dang, Maodong Gao, Yucheng Jin, Byoung Jun Park, Beyonce Hu, Wilton J. M. Kort-Kamp, Ho Wai,  Lee</strong></p>
<p>Endoscopic imaging is essential for real-time visualization of internal organs, yet conventional systems remain bulky, complex, and expensive due to their reliance on large, multi-element optical components. This limits their accessibility to delicate or constrained anatomical regions. Achieving real-time, high-resolution endomicroscopy using compact, low-cost hardware at the hundred-micron scale remains an unsolved challenge. Optical fibers offer a promising route toward miniaturization by providing sub-millimeter-scale imaging channels; however, existing fiber-based methods typically rely on raster scanning or multicore bundles, which limit the resolution and imaging speed. In this work, we overcome these limitations by integrating dual-comb interferometry with compressive ghost imaging and advanced computational reconstruction. Our technique, hyperspectral dual-comb compressive imaging, utilizes optical frequency combs to generate wavelength-multiplexed speckle patterns that are delivered through a single-core fiber and detected by a single-pixel photodetector. This parallel speckle illumination and detection enable snapshot compression and acquisition of image information using zero-dimensional hardware, completely eliminating the need for both spatial and spectral scanning. To decode these highly compressed signals, we develop a transformer-based deep learning model capable of rapid, high-fidelity image reconstruction at extremely low sampling ratios. This approach significantly outperforms classical ghost imaging methods in both speed and accuracy, achieving video-rate imaging with a dramatically simplified optical front-end. Our results represent a major advance toward minimally invasive, cost-effective endomicroscopy and provide a generalizable platform for optical sensing in applications where hardware constraints are critical. </p>
<blockquote>
<p>å†…çª¥é•œæˆåƒå¯¹äºå†…éƒ¨å™¨å®˜çš„å®æ—¶å¯è§†åŒ–è‡³å…³é‡è¦ï¼Œç„¶è€Œï¼Œä¼ ç»Ÿç³»ç»Ÿç”±äºå…¶ä¾èµ–äºå¤§å‹å¤šå…ƒå…‰å­¦ç»„ä»¶ï¼Œä»ç„¶åºå¤§ã€å¤æ‚å’Œæ˜‚è´µã€‚è¿™é™åˆ¶äº†å…¶åœ¨ç²¾ç»†æˆ–å—é™çš„è§£å‰–åŒºåŸŸçš„å¯è¾¾æ€§ã€‚åœ¨ç´§å‡‘ã€ä½æˆæœ¬ç¡¬ä»¶çš„ç™¾å¾®ç±³å°ºåº¦ä¸Šå®ç°å®æ—¶é«˜åˆ†è¾¨ç‡çš„å†…çª¥é•œæ£€æŸ¥ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„æŒ‘æˆ˜ã€‚å…‰çº¤é€šè¿‡æä¾›äºšæ¯«ç±³çº§çš„æˆåƒé€šé“ï¼Œä¸ºå®ç°å°å‹åŒ–æä¾›äº†æœ‰å‰æ™¯çš„é€”å¾„ï¼›ç„¶è€Œï¼Œç°æœ‰çš„å…‰çº¤æ–¹æ³•é€šå¸¸ä¾èµ–äºæ …æ ¼æ‰«ææˆ–å¤šèŠ¯æ†æ‰ï¼Œè¿™é™åˆ¶äº†åˆ†è¾¨ç‡å’Œæˆåƒé€Ÿåº¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°†åŒæ¢³å¹²æ¶‰ä»ªä¸å‹ç¼©é¬¼æˆåƒå’Œå…ˆè¿›çš„è®¡ç®—é‡å»ºç›¸ç»“åˆï¼Œå…‹æœäº†è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„æŠ€æœ¯â€”â€”è¶…å…‰è°±åŒæ¢³å‹ç¼©æˆåƒï¼Œåˆ©ç”¨å…‰å­¦é¢‘ç‡æ¢³äº§ç”Ÿæ³¢é•¿å¤šè·¯å¤ç”¨çš„æ–‘ç‚¹æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼é€šè¿‡å•èŠ¯å…‰çº¤ä¼ è¾“å¹¶ç”±å•åƒç´ å…‰ç”µæ¢æµ‹å™¨æ£€æµ‹ã€‚è¿™ç§å¹¶è¡Œæ–‘ç‚¹ç…§æ˜å’Œæ£€æµ‹å®ç°äº†å›¾åƒçš„å³æ—¶å‹ç¼©å’Œè·å–ï¼Œä½¿ç”¨é›¶ç»´ç¡¬ä»¶è·å–å›¾åƒä¿¡æ¯ï¼Œå®Œå…¨æ¶ˆé™¤äº†å¯¹ç©ºé—´å’Œå…‰è°±æ‰«æçš„éœ€æ±‚ã€‚ä¸ºäº†è§£ç è¿™äº›é«˜åº¦å‹ç¼©çš„ä¿¡å·ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºå˜å‹å™¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿä»¥æä½çš„é‡‡æ ·ç‡å¿«é€Ÿè¿›è¡Œé«˜ä¿çœŸåº¦çš„å›¾åƒé‡å»ºã€‚è¿™ç§æ–¹æ³•åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢éƒ½å¤§å¤§ä¼˜äºä¼ ç»Ÿçš„é¬¼æˆåƒæ–¹æ³•ï¼Œå®ç°äº†è§†é¢‘é€Ÿç‡çš„æˆåƒï¼Œå¤§å¤§ç®€åŒ–äº†å…‰å­¦å‰ç«¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœä»£è¡¨äº†å®ç°å¾®åˆ›ã€ç»æµçš„å†…çª¥é•œæ£€æŸ¥çš„é‡å¤§è¿›æ­¥ï¼Œå¹¶ä¸ºç¡¬ä»¶çº¦æŸå…³é”®çš„åº”ç”¨ä¸­çš„å…‰å­¦ä¼ æ„Ÿæä¾›äº†ä¸€ä¸ªå¯æ¨å¹¿çš„å¹³å°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04157v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºåŒé¢‘æ¢³å¹²æ¶‰ä¸å‹ç¼©é¬¼æˆåƒæŠ€æœ¯çš„é«˜å…‰è°±æˆåƒæ–°æ–¹æ³•ï¼Œé€šè¿‡å•èŠ¯å…‰çº¤ä¼ è¾“æ³¢é•¿å¤šè·¯å¤ç”¨æ•£æ–‘å›¾æ¡ˆï¼Œå®ç°æ— éœ€ç©ºé—´ä¸å…‰è°±æ‰«æçš„å®æ—¶é«˜ä¿çœŸå›¾åƒé‡å»ºï¼Œä¸ºå¾®åˆ›ã€ç»æµçš„å†…çª¥é•œæ£€æŸ¥æä¾›äº†é‡å¤§è¿›å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å†…çª¥æˆåƒåœ¨åŒ»å­¦é¢†åŸŸå…·æœ‰é‡è¦æ€§ï¼Œä½†ä¼ ç»Ÿç³»ç»Ÿå­˜åœ¨ä½“ç§¯å¤§ã€å¤æ‚ã€æ˜‚è´µç­‰é—®é¢˜ã€‚</li>
<li>å®ç°å®æ—¶ã€é«˜åˆ†è¾¨ç‡çš„ç«¯å¾®å†…çª¥é•œåœ¨å¾®ç±³å°ºåº¦ä¸Šä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å…‰çº¤ä¸ºå®ç°å¾®å‹åŒ–æä¾›æœ‰å‰é€”çš„è·¯çº¿ï¼Œä½†ç°æœ‰æ–¹æ³•å—é™äºåˆ†è¾¨ç‡å’Œæˆåƒé€Ÿåº¦ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡é›†æˆåŒé¢‘æ¢³å¹²æ¶‰ä¸å‹ç¼©é¬¼æˆåƒæŠ€æœ¯ï¼Œå…‹æœè¿™äº›é™åˆ¶ã€‚</li>
<li>é‡‡ç”¨å…‰å­¦é¢‘ç‡æ¢³ç”Ÿæˆæ³¢é•¿å¤šè·¯å¤ç”¨æ•£æ–‘å›¾æ¡ˆï¼Œé€šè¿‡å•èŠ¯å…‰çº¤ä¼ è¾“å¹¶å®ç°å•åƒç´ æ¢æµ‹å™¨æ£€æµ‹ã€‚</li>
<li>æ­¤æ–¹æ³•å®ç°äº†æ— éœ€ç©ºé—´ä¸å…‰è°±æ‰«æçš„å®æ—¶é«˜ä¿çœŸå›¾åƒé‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04157">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-970484f81708321e7e94b827334d4355.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4156deae37f122d81fdc3f31f62130fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-debde0d30c68e2d5a9e48ce10cf665b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-044bdac58348cc6bc4a1ca53638953bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58b64ecd3622b890e7855cc0ffdb865a.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Bridging-Vision-and-Language-Optimal-Transport-Driven-Radiology-Report-Generation-via-LLMs"><a href="#Bridging-Vision-and-Language-Optimal-Transport-Driven-Radiology-Report-Generation-via-LLMs" class="headerlink" title="Bridging Vision and Language: Optimal Transport-Driven Radiology Report   Generation via LLMs"></a>Bridging Vision and Language: Optimal Transport-Driven Radiology Report   Generation via LLMs</h2><p><strong>Authors:Haifeng Zhao, Yufei Zhang, Leilei Ma, Shuo Xu, Dengdi Sun</strong></p>
<p>Radiology report generation represents a significant application within medical AI, and has achieved impressive results. Concurrently, large language models (LLMs) have demonstrated remarkable performance across various domains. However, empirical validation indicates that general LLMs tend to focus more on linguistic fluency rather than clinical effectiveness, and lack the ability to effectively capture the relationship between X-ray images and their corresponding texts, thus resulting in poor clinical practicability. To address these challenges, we propose Optimal Transport-Driven Radiology Report Generation (OTDRG), a novel framework that leverages Optimal Transport (OT) to align image features with disease labels extracted from reports, effectively bridging the cross-modal gap. The core component of OTDRG is Alignment &amp; Fine-Tuning, where OT utilizes results from the encoding of label features and image visual features to minimize cross-modal distances, then integrating image and text features for LLMs fine-tuning. Additionally, we design a novel disease prediction module to predict disease labels contained in X-ray images during validation and testing. Evaluated on the MIMIC-CXR and IU X-Ray datasets, OTDRG achieves state-of-the-art performance in both natural language generation (NLG) and clinical efficacy (CE) metrics, delivering reports that are not only linguistically coherent but also clinically accurate. </p>
<blockquote>
<p>åŒ»å­¦å½±åƒæŠ¥å‘Šç”Ÿæˆåœ¨åŒ»å­¦äººå·¥æ™ºèƒ½é¢†åŸŸå…·æœ‰é‡å¤§åº”ç”¨ï¼Œå¹¶å·²å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœã€‚åŒæ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§é¢†åŸŸéƒ½è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç»éªŒéªŒè¯è¡¨æ˜ï¼Œé€šç”¨LLMsæ›´ä¾§é‡äºè¯­è¨€æµç•…æ€§è€Œéä¸´åºŠæœ‰æ•ˆæ€§ï¼Œç¼ºä¹æœ‰æ•ˆæ•æ‰Xå…‰å›¾åƒä¸å…¶å¯¹åº”æ–‡æœ¬ä¹‹é—´å…³ç³»çš„èƒ½åŠ›ï¼Œä»è€Œå¯¼è‡´ä¸´åºŠå®ç”¨æ€§è¾ƒå·®ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæœ€ä¼˜ä¼ è¾“é©±åŠ¨çš„åŒ»å­¦å½±åƒæŠ¥å‘Šç”Ÿæˆï¼ˆOTDRGï¼‰æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æœ€ä¼˜ä¼ è¾“ï¼ˆOTï¼‰å¯¹é½å›¾åƒç‰¹å¾ä¸ä»æŠ¥å‘Šä¸­æå–çš„ç–¾ç—…æ ‡ç­¾ï¼Œæœ‰æ•ˆå¼¥åˆäº†è·¨æ¨¡æ€å·®è·ã€‚OTDRGçš„æ ¸å¿ƒç»„ä»¶æ˜¯å¯¹é½ä¸å¾®è°ƒï¼Œå…¶ä¸­OTåˆ©ç”¨æ ‡ç­¾ç‰¹å¾å’Œå›¾åƒè§†è§‰ç‰¹å¾çš„ç¼–ç ç»“æœæ¥æœ€å°åŒ–è·¨æ¨¡æ€è·ç¦»ï¼Œç„¶åæ•´åˆå›¾åƒå’Œæ–‡æœ¬ç‰¹å¾è¿›è¡ŒLLMså¾®è°ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ä¸ªæ–°å‹ç–¾ç—…é¢„æµ‹æ¨¡å—ï¼Œåœ¨éªŒè¯å’Œæµ‹è¯•é˜¶æ®µé¢„æµ‹Xå…‰å›¾åƒä¸­åŒ…å«çš„ç–¾ç—…æ ‡ç­¾ã€‚åœ¨MIMIC-CXRå’ŒIU Xå…‰æ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒOTDRGåœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰å’Œä¸´åºŠæœ‰æ•ˆæ€§ï¼ˆCEï¼‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œç”Ÿæˆçš„æŠ¥å‘Šä¸ä»…è¯­è¨€è¿è´¯ï¼Œè€Œä¸”ä¸´åºŠå‡†ç¡®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03908v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºOptimal Transport-Driven Radiology Report Generationï¼ˆOTDRGï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨Optimal Transportï¼ˆOTï¼‰æŠ€æœ¯å¯¹é½å›¾åƒç‰¹å¾ä¸ä»æŠ¥å‘Šä¸­æå–çš„ç–¾ç—…æ ‡ç­¾ï¼Œæœ‰æ•ˆç¼©å°è·¨æ¨¡æ€å·®è·ï¼Œä»è€Œæé«˜åŒ»å­¦å›¾åƒæŠ¥å‘Šçš„ç”Ÿæˆè´¨é‡å’Œä¸´åºŠå®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒæŠ¥å‘Šç”Ÿæˆæ˜¯åŒ»å­¦AIçš„é‡è¦åº”ç”¨ä¹‹ä¸€ï¼Œä½†ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠåŒ»å­¦åº”ç”¨ä¸­è¡¨ç°æ¬ ä½³ï¼Œéœ€è¦æ›´æœ‰æ•ˆçš„æ–¹å¼æ¥å®ç°è·¨æ¨¡æ€ä¿¡æ¯å¯¹é½ã€‚</li>
<li>OTDRGæ¡†æ¶åˆ©ç”¨Optimal TransportæŠ€æœ¯å¯¹é½å›¾åƒç‰¹å¾å’Œç–¾ç—…æ ‡ç­¾ï¼Œç¼©å°è·¨æ¨¡æ€å·®è·ã€‚</li>
<li>OTDRGçš„æ ¸å¿ƒç»„ä»¶æ˜¯Alignment &amp; Fine-Tuningï¼Œé€šè¿‡åˆ©ç”¨æ ‡ç­¾ç‰¹å¾å’Œå›¾åƒè§†è§‰ç‰¹å¾çš„ç¼–ç ç»“æœæ¥æœ€å°åŒ–è·¨æ¨¡æ€è·ç¦»ï¼Œç„¶åæ•´åˆå›¾åƒå’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒã€‚</li>
<li>è®¾è®¡äº†æ–°å‹ç–¾ç—…é¢„æµ‹æ¨¡å—ï¼Œèƒ½åœ¨éªŒè¯å’Œæµ‹è¯•é˜¶æ®µé¢„æµ‹Xå…‰å›¾åƒä¸­çš„ç–¾ç—…æ ‡ç­¾ã€‚</li>
<li>åœ¨MIMIC-CXRå’ŒIU X-Rayæ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒOTDRGåœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆå’Œä¸´åºŠæœ‰æ•ˆæ€§æ–¹é¢éƒ½è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</li>
<li>OTDRGç”Ÿæˆçš„æŠ¥å‘Šä¸ä»…è¯­è¨€è¿è´¯ï¼Œè€Œä¸”ä¸´åºŠå‡†ç¡®åº¦é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03908">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2512bcf6373d402aae01958ea649264f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be33bb857ca40ae668be90914955dfc9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0e9e8f68b6daf2ca72ec3548994efed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2e2f1a3c5c38d2590fd3e83b6d0fe98.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="ChestGPT-Integrating-Large-Language-Models-and-Vision-Transformers-for-Disease-Detection-and-Localization-in-Chest-X-Rays"><a href="#ChestGPT-Integrating-Large-Language-Models-and-Vision-Transformers-for-Disease-Detection-and-Localization-in-Chest-X-Rays" class="headerlink" title="ChestGPT: Integrating Large Language Models and Vision Transformers for   Disease Detection and Localization in Chest X-Rays"></a>ChestGPT: Integrating Large Language Models and Vision Transformers for   Disease Detection and Localization in Chest X-Rays</h2><p><strong>Authors:Shehroz S. Khan, Petar Przulj, Ahmed Ashraf, Ali Abedi</strong></p>
<p>The global demand for radiologists is increasing rapidly due to a growing reliance on medical imaging services, while the supply of radiologists is not keeping pace. Advances in computer vision and image processing technologies present significant potential to address this gap by enhancing radiologistsâ€™ capabilities and improving diagnostic accuracy. Large language models (LLMs), particularly generative pre-trained transformers (GPTs), have become the primary approach for understanding and generating textual data. In parallel, vision transformers (ViTs) have proven effective at converting visual data into a format that LLMs can process efficiently. In this paper, we present ChestGPT, a deep-learning framework that integrates the EVA ViT with the Llama 2 LLM to classify diseases and localize regions of interest in chest X-ray images. The ViT converts X-ray images into tokens, which are then fed, together with engineered prompts, into the LLM, enabling joint classification and localization of diseases. This approach incorporates transfer learning techniques to enhance both explainability and performance. The proposed method achieved strong global disease classification performance on the VinDr-CXR dataset, with an F1 score of 0.76, and successfully localized pathologies by generating bounding boxes around the regions of interest. We also outline several task-specific prompts, in addition to general-purpose prompts, for scenarios radiologists might encounter. Overall, this framework offers an assistive tool that can lighten radiologistsâ€™ workload by providing preliminary findings and regions of interest to facilitate their diagnostic process. </p>
<blockquote>
<p>éšç€å¯¹åŒ»å­¦æˆåƒæœåŠ¡æ—¥ç›Šå¢é•¿çš„ä¾èµ–ï¼Œå…¨çƒå¯¹æ”¾å°„ç§‘åŒ»ç”Ÿçš„éœ€æ±‚è¿…é€Ÿå¢åŠ ï¼Œè€Œæ”¾å°„ç§‘åŒ»ç”Ÿçš„ä¾›åº”å´è·Ÿä¸ä¸Šè¿™ä¸€éœ€æ±‚ã€‚è®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†æŠ€æœ¯çš„è¿›æ­¥ä¸ºè§£å†³è¿™ä¸€å·®è·æä¾›äº†å·¨å¤§æ½œåŠ›ï¼Œé€šè¿‡å¢å¼ºæ”¾å°„ç§‘åŒ»ç”Ÿçš„èƒ½åŠ›å’Œæé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å°¤å…¶æ˜¯é¢„è®­ç»ƒç”Ÿæˆå˜å‹å™¨ï¼ˆGPTsï¼‰å·²æˆä¸ºç†è§£å’Œç”Ÿæˆæ–‡æœ¬æ•°æ®çš„ä¸»è¦æ–¹æ³•ã€‚åŒæ—¶ï¼Œè§†è§‰å˜å‹å™¨ï¼ˆViTsï¼‰å·²è¯æ˜å…¶åœ¨å°†è§†è§‰æ•°æ®è½¬æ¢ä¸ºLLMså¯ä»¥é«˜æ•ˆå¤„ç†æ ¼å¼æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ChestGPTï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå°†EVA ViTä¸Llama 2 LLMé›†æˆåœ¨ä¸€èµ·ï¼Œç”¨äºå¯¹èƒ¸éƒ¨Xå°„çº¿å›¾åƒä¸­çš„ç–¾ç—…è¿›è¡Œåˆ†ç±»å¹¶å®šä½æ„Ÿå…´è¶£åŒºåŸŸã€‚ViTå°†Xå°„çº¿å›¾åƒè½¬æ¢ä¸ºä»¤ç‰Œï¼Œç„¶åè¿åŒå·¥ç¨‹æç¤ºä¸€èµ·è¾“å…¥åˆ°LLMä¸­ï¼Œä»è€Œå®ç°ç–¾ç—…çš„è”åˆåˆ†ç±»å’Œå®šä½ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†è¿ç§»å­¦ä¹ æŠ€æœ¯ï¼Œä»¥æé«˜è§£é‡Šæ€§å’Œæ€§èƒ½ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨VinDr-CXRæ•°æ®é›†ä¸Šå®ç°äº†å¼ºå¤§çš„å…¨çƒç–¾ç—…åˆ†ç±»æ€§èƒ½ï¼ŒF1åˆ†æ•°ä¸º0.76ï¼Œå¹¶é€šè¿‡å›´ç»•æ„Ÿå…´è¶£åŒºåŸŸç”Ÿæˆè¾¹ç•Œæ¡†æˆåŠŸå®šä½äº†ç—…ç†ã€‚æˆ‘ä»¬è¿˜æ¦‚è¿°äº†é™¤é€šç”¨æç¤ºå¤–ï¼Œé’ˆå¯¹æ”¾å°„ç§‘åŒ»ç”Ÿå¯èƒ½é‡åˆ°çš„å„ç§æƒ…æ™¯çš„ç‰¹å®šä»»åŠ¡æç¤ºã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ä¸ªè¾…åŠ©å·¥å…·ï¼Œé€šè¿‡æä¾›åˆæ­¥å‘ç°å’Œæ„Ÿå…´è¶£åŒºåŸŸæ¥å‡è½»æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œé‡ï¼Œä¿ƒè¿›ä»–ä»¬çš„è¯Šæ–­è¿‡ç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03739v1">PDF</a> 8 pages, 5 figures, 4 tables</p>
<p><strong>Summary</strong><br>åŒ»å­¦å½±åƒå­¦éœ€æ±‚æ¿€å¢ä¸æ”¾å°„ç§‘åŒ»ç”Ÿèµ„æºä¸è¶³ä¹‹é—´çŸ›ç›¾æ—¥ç›Šå‡¸æ˜¾ï¼Œè®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†æŠ€æœ¯çš„è¿›å±•ä¸ºè§£å†³è¿™ä¸€çŸ›ç›¾å¸¦æ¥æœºé‡ã€‚æœ¬æ–‡ä»‹ç»äº†ChestGPTï¼Œä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒé€šè¿‡é›†æˆEVA ViTå’ŒLlama 2 LLMï¼Œå¯¹èƒ¸ç‰‡Xå°„çº¿å›¾åƒè¿›è¡Œç–¾ç—…åˆ†ç±»å’Œæ„Ÿå…´è¶£åŒºåŸŸå®šä½ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è½¬æ¢å­¦ä¹ æŠ€æœ¯æé«˜è§£é‡Šæ€§å’Œæ€§èƒ½ï¼Œåœ¨VinDr-CXRæ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„å…¨çƒç–¾ç—…åˆ†ç±»æ€§èƒ½ï¼ˆF1åˆ†æ•°ä¸º0.76ï¼‰ï¼Œå¹¶èƒ½æˆåŠŸå®šä½ç—…ç†åŒºåŸŸã€‚æ­¤æ¡†æ¶ä¸ºæ”¾å°„ç§‘åŒ»ç”Ÿæä¾›åˆæ­¥è¯Šæ–­ç»“æœå’Œæ„Ÿå…´è¶£åŒºåŸŸæç¤ºï¼Œå¯å‡è½»å…¶å·¥ä½œé‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…¨çƒå¯¹æ”¾å°„ç§‘åŒ»ç”Ÿçš„éœ€æ±‚è¿…é€Ÿå¢é•¿ï¼Œä½†ä¾›åº”ä¸è¶³ã€‚</li>
<li>è®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†æŠ€æœ¯æœ‰åŠ©äºè§£å†³è¿™ä¸€çŸ›ç›¾ã€‚</li>
<li>ChestGPTæ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆäº†EVA ViTå’ŒLlama 2 LLMï¼Œç”¨äºXå°„çº¿å›¾åƒçš„ç–¾ç—…åˆ†ç±»å’ŒåŒºåŸŸå®šä½ã€‚</li>
<li>è¯¥æ¡†æ¶ä½¿ç”¨è½¬æ¢å­¦ä¹ æŠ€æœ¯ä»¥æé«˜è§£é‡Šæ€§å’Œæ€§èƒ½ã€‚</li>
<li>åœ¨VinDr-CXRæ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„ç–¾ç—…åˆ†ç±»æ€§èƒ½ï¼ˆF1åˆ†æ•°ä¸º0.76ï¼‰ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½æˆåŠŸå®šä½ç—…ç†åŒºåŸŸï¼Œç”Ÿæˆå›´ç»•æ„Ÿå…´è¶£åŒºåŸŸçš„è¾¹ç•Œæ¡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03739">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db88ede29c1abd31b63991df0ebb5723.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ed04ad5f23d1db131702c8528519669.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d800fea9816b4ffe409770b295f2590.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71cbb5a4649418693f278bd593808692.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="SAMed-2-Selective-Memory-Enhanced-Medical-Segment-Anything-Model"><a href="#SAMed-2-Selective-Memory-Enhanced-Medical-Segment-Anything-Model" class="headerlink" title="SAMed-2: Selective Memory Enhanced Medical Segment Anything Model"></a>SAMed-2: Selective Memory Enhanced Medical Segment Anything Model</h2><p><strong>Authors:Zhiling Yan, Sifan Song, Dingjie Song, Yiwei Li, Rong Zhou, Weixiang Sun, Zhennong Chen, Sekeun Kim, Hui Ren, Tianming Liu, Quanzheng Li, Xiang Li, Lifang He, Lichao Sun</strong></p>
<p>Recent â€œsegment anythingâ€ efforts show promise by learning from large-scale data, but adapting such models directly to medical images remains challenging due to the complexity of medical data, noisy annotations, and continual learning requirements across diverse modalities and anatomical structures. In this work, we propose SAMed-2, a new foundation model for medical image segmentation built upon the SAM-2 architecture. Specifically, we introduce a temporal adapter into the image encoder to capture image correlations and a confidence-driven memory mechanism to store high-certainty features for later retrieval. This memory-based strategy counters the pervasive noise in large-scale medical datasets and mitigates catastrophic forgetting when encountering new tasks or modalities. To train and evaluate SAMed-2, we curate MedBank-100k, a comprehensive dataset spanning seven imaging modalities and 21 medical segmentation tasks. Our experiments on both internal benchmarks and 10 external datasets demonstrate superior performance over state-of-the-art baselines in multi-task scenarios. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/ZhilingYan/Medical-SAM-Bench">https://github.com/ZhilingYan/Medical-SAM-Bench</a>. </p>
<blockquote>
<p>æœ€è¿‘çš„â€œåˆ†å‰²ä»»ä½•äº‹ç‰©â€çš„åŠªåŠ›é€šè¿‡ä»å¤§è§„æ¨¡æ•°æ®ä¸­å­¦ä¹ æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç›´æ¥å°†æ­¤ç±»æ¨¡å‹åº”ç”¨äºåŒ»å­¦å›¾åƒä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºåŒ»å­¦æ•°æ®çš„å¤æ‚æ€§ã€æ ‡æ³¨çš„å™ªå£°ä»¥åŠè·¨ä¸åŒæ¨¡æ€å’Œè§£å‰–ç»“æ„è¿›è¡ŒæŒç»­å­¦ä¹ çš„è¦æ±‚ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SAMed-2ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºSAM-2æ¶æ„çš„æ–°åŒ»å­¦å›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨å›¾åƒç¼–ç å™¨ä¸­åŠ å…¥äº†ä¸€ä¸ªæ—¶é—´é€‚é…å™¨æ¥æ•æ‰å›¾åƒç›¸å…³æ€§ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºä¿¡å¿ƒçš„å†…å­˜æœºåˆ¶æ¥å­˜å‚¨é«˜ç¡®å®šæ€§ç‰¹å¾ä»¥ä¾›ä»¥åæ£€ç´¢ã€‚è¿™ç§åŸºäºå†…å­˜çš„ç­–ç•¥å¯¹æŠ—äº†å¤§è§„æ¨¡åŒ»å­¦æ•°æ®é›†ä¸­æ™®éå­˜åœ¨çš„å™ªå£°ï¼Œå¹¶å‡è½»äº†é‡åˆ°æ–°ä»»åŠ¡æˆ–æ¨¡æ€æ—¶çš„ç¾éš¾æ€§é—å¿˜ã€‚ä¸ºäº†è®­ç»ƒå’Œè¯„ä¼°SAMed-2ï¼Œæˆ‘ä»¬æ•´ç†äº†MedBank-100kæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–ä¸ƒç§æˆåƒæ¨¡æ€å’Œ21ä¸ªåŒ»å­¦åˆ†å‰²ä»»åŠ¡çš„ç»¼åˆæ•°æ®é›†ã€‚æˆ‘ä»¬åœ¨å†…éƒ¨åŸºå‡†æµ‹è¯•å’Œ10ä¸ªå¤–éƒ¨æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å¤šä»»åŠ¡åœºæ™¯ä¸­ï¼Œå®ƒçš„æ€§èƒ½ä¼˜äºæœ€æ–°åŸºå‡†æµ‹è¯•ã€‚ä»£ç å¯ç”¨åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/ZhilingYan/Medical-SAM-Bench%E3%80%82">https://github.com/ZhilingYan/Medical-SAM-Benchã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03698v1">PDF</a> Accepted by MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºSAM-2æ¶æ„ï¼Œé’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼Œæå‡ºäº†SAMed-2åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†æ—¶é—´é€‚é…å™¨æ•æ‰å›¾åƒå…³è”ï¼Œå¹¶é‡‡ç”¨äº†ä¿¡å¿ƒé©±åŠ¨çš„è®°å¿†æœºåˆ¶æ¥å­˜å‚¨é«˜ç¡®å®šæ€§ç‰¹å¾ä»¥ä¾›åç»­æ£€ç´¢ã€‚æ­¤è®°å¿†ç­–ç•¥æœ‰åŠ©äºåº”å¯¹å¤§è§„æ¨¡åŒ»å­¦æ•°æ®é›†ä¸­çš„æ™®éå™ªå£°ï¼Œå¹¶åœ¨é‡åˆ°æ–°ä»»åŠ¡æˆ–æ¨¡æ€æ—¶å‡è½»ç¾éš¾æ€§é—å¿˜ã€‚ä¸ºè®­ç»ƒå’Œè¯„ä¼°SAMed-2ï¼Œæˆ‘ä»¬åˆ›å»ºäº†åŒ…å«ä¸ƒç§æˆåƒæ¨¡æ€å’Œ21é¡¹åŒ»å­¦åˆ†å‰²ä»»åŠ¡çš„MedBank-100kç»¼åˆæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸‹çš„æ€§èƒ½ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SAMed-2æ¨¡å‹æ˜¯åŸºäºSAM-2æ¶æ„æ„å»ºçš„ï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</li>
<li>å¼•å…¥äº†æ—¶é—´é€‚é…å™¨æ¥æ•æ‰åŒ»å­¦å›¾åƒä¸­çš„å…³è”ã€‚</li>
<li>é‡‡ç”¨ä¿¡å¿ƒé©±åŠ¨çš„è®°å¿†æœºåˆ¶æ¥åº”å¯¹åŒ»å­¦æ•°æ®é›†ä¸­æ™®éå­˜åœ¨çš„å™ªå£°é—®é¢˜ã€‚</li>
<li>è¯¥è®°å¿†æœºåˆ¶æœ‰åŠ©äºå‡è½»åœ¨é‡åˆ°æ–°ä»»åŠ¡æˆ–æ¨¡æ€æ—¶çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚</li>
<li>MedBank-100kæ•°æ®é›†ç”¨äºè®­ç»ƒå’Œè¯„ä¼°SAMed-2æ¨¡å‹ï¼ŒåŒ…å«ä¸ƒç§æˆåƒæ¨¡æ€å’Œ21é¡¹åŒ»å­¦åˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSAMed-2æ¨¡å‹åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸‹çš„æ€§èƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03698">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-47a94d5682d471a7c943b2c09bb9ed73.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-088d82209be4c9594cd702da299225a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-645722c8cac27485163ff461779f5b1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0cbeab8bca8bd40c7c0a711fa187ed87.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8488f236b5f9be3b34f1f4606e1c9fe7.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  OpenS2S Advancing Open-Source End-to-End Empathetic Large Speech   Language Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d86e7c9116b28dbc59a422d07f743fee.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  Geometric-Guided Few-Shot Dental Landmark Detection with Human-Centric   Foundation Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28051.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
