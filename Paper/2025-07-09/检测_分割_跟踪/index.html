<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  CVFusion Cross-View Fusion of 4D Radar and Camera for 3D Object   Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-597ea0e761098ab072596ed0b825dc8b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    33 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-09-æ›´æ–°"><a href="#2025-07-09-æ›´æ–°" class="headerlink" title="2025-07-09 æ›´æ–°"></a>2025-07-09 æ›´æ–°</h1><h2 id="CVFusion-Cross-View-Fusion-of-4D-Radar-and-Camera-for-3D-Object-Detection"><a href="#CVFusion-Cross-View-Fusion-of-4D-Radar-and-Camera-for-3D-Object-Detection" class="headerlink" title="CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object   Detection"></a>CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object   Detection</h2><p><strong>Authors:Hanzhi Zhong, Zhiyu Xiang, Ruoyu Xu, Jingyun Fu, Peng Xu, Shaohong Wang, Zhihao Yang, Tianyu Pu, Eryun Liu</strong></p>
<p>4D radar has received significant attention in autonomous driving thanks to its robustness under adverse weathers. Due to the sparse points and noisy measurements of the 4D radar, most of the research finish the 3D object detection task by integrating images from camera and perform modality fusion in BEV space. However, the potential of the radar and the fusion mechanism is still largely unexplored, hindering the performance improvement. In this study, we propose a cross-view two-stage fusion network called CVFusion. In the first stage, we design a radar guided iterative (RGIter) BEV fusion module to generate high-recall 3D proposal boxes. In the second stage, we aggregate features from multiple heterogeneous views including points, image, and BEV for each proposal. These comprehensive instance level features greatly help refine the proposals and generate high-quality predictions. Extensive experiments on public datasets show that our method outperforms the previous state-of-the-art methods by a large margin, with 9.10% and 3.68% mAP improvements on View-of-Delft (VoD) and TJ4DRadSet, respectively. Our code will be made publicly available. </p>
<blockquote>
<p>4Dé›·è¾¾ç”±äºå…¶æ¶åŠ£å¤©æ°”ä¸‹çš„ç¨³å¥æ€§è€Œåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå¤‡å—å…³æ³¨ã€‚ç”±äº4Dé›·è¾¾çš„ç‚¹æ•°ç¨€ç–å’Œæµ‹é‡å™ªå£°ï¼Œå¤§å¤šæ•°ç ”ç©¶é€šè¿‡æ•´åˆç›¸æœºå›¾åƒå¹¶åœ¨BEVç©ºé—´è¿›è¡Œæ¨¡æ€èåˆæ¥å®Œæˆ3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚ç„¶è€Œï¼Œé›·è¾¾çš„æ½œåŠ›å’Œèåˆæœºåˆ¶å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œé˜»ç¢äº†æ€§èƒ½çš„æå‡ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨è§†å›¾ä¸¤é˜¶æ®µèåˆç½‘ç»œï¼Œåä¸ºCVFusionã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬è®¾è®¡äº†é›·è¾¾å¼•å¯¼è¿­ä»£ï¼ˆRGIterï¼‰BEVèåˆæ¨¡å—ï¼Œä»¥ç”Ÿæˆé«˜å¬å›ç‡çš„3Då€™é€‰æ¡†ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬ä»å¤šä¸ªå¼‚æ„è§†å›¾ï¼ˆåŒ…æ‹¬ç‚¹ã€å›¾åƒå’ŒBEVï¼‰ä¸ºæ¯ä¸ªå€™é€‰æ¡†èšåˆç‰¹å¾ã€‚è¿™äº›å…¨é¢çš„å®ä¾‹çº§ç‰¹å¾æœ‰åŠ©äºæ”¹è¿›å€™é€‰æ¡†å¹¶ç”Ÿæˆé«˜è´¨é‡é¢„æµ‹ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¹…è¶…è¶Šäº†ä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œåœ¨Delftè§†è§’ï¼ˆVoDï¼‰å’ŒTJ4DRadSetä¸Šçš„mAPåˆ†åˆ«æé«˜äº†9.10%å’Œ3.68%ã€‚æˆ‘ä»¬çš„ä»£ç å°†å…¬å¼€æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04587v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿™æ˜¯ä¸€ç¯‡å…³äº4Dé›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶ä¸­åº”ç”¨çš„è®ºæ–‡æ‘˜è¦ã€‚æ–‡ç« ä»‹ç»äº†å½“å‰è‡ªä¸»é©¾é©¶ä¸­å¯¹4Dé›·è¾¾çš„ç ”ç©¶ç°çŠ¶åŠå…¶é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºCVFusionçš„è·¨è§†è§’ä¸¤é˜¶æ®µèåˆç½‘ç»œï¼Œæ—¨åœ¨é€šè¿‡é›·è¾¾å¼•å¯¼è¿­ä»£ï¼ˆRGIterï¼‰BEVèåˆæ¨¡å—ç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´æè®®æ¡†ï¼Œå¹¶é€šè¿‡å¤šè§†è§’ç‰¹å¾èšåˆè¿›ä¸€æ­¥æé«˜é¢„æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºå…ˆå‰çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨VoDå’ŒTJ4DRadSetæ•°æ®é›†ä¸Šçš„mAPæŒ‡æ ‡æœ‰æ˜æ˜¾æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>4Dé›·è¾¾åœ¨è‡ªåŠ¨é©¾é©¶ä¸­å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå› å…¶æ¶åŠ£å¤©æ°”ä¸‹çš„ç¨³å¥æ€§ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†CVFusionç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§è·¨è§†è§’ä¸¤é˜¶æ®µèåˆç½‘ç»œã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µè®¾è®¡äº†ä¸€ä¸ªé›·è¾¾å¼•å¯¼è¿­ä»£ï¼ˆRGIterï¼‰BEVèåˆæ¨¡å—ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´æè®®æ¡†ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µä»ä¸åŒè§†è§’ï¼ˆç‚¹ã€å›¾åƒå’ŒBEVï¼‰èšåˆç‰¹å¾ï¼Œä»¥ä¼˜åŒ–æè®®å¹¶ç”Ÿæˆé«˜è´¨é‡é¢„æµ‹ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</li>
<li>åœ¨VoDå’ŒTJ4DRadSetæ•°æ®é›†ä¸Šçš„mAPæŒ‡æ ‡æœ‰æ˜æ˜¾æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04587">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d7fba0b977511079458b7483b10df00d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1ac13800172bd7eb36eefb3bf7c27f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3777948e88d7731f091085ab0c4323ea.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f3239d359fb677057af6beb39f386916.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Towards-Accurate-and-Efficient-3D-Object-Detection-for-Autonomous-Driving-A-Mixture-of-Experts-Computing-System-on-Edge"><a href="#Towards-Accurate-and-Efficient-3D-Object-Detection-for-Autonomous-Driving-A-Mixture-of-Experts-Computing-System-on-Edge" class="headerlink" title="Towards Accurate and Efficient 3D Object Detection for Autonomous   Driving: A Mixture of Experts Computing System on Edge"></a>Towards Accurate and Efficient 3D Object Detection for Autonomous   Driving: A Mixture of Experts Computing System on Edge</h2><p><strong>Authors:Linshen Liu, Boyan Su, Junyue Jiang, Guanlin Wu, Cong Guo, Ceyu Xu, Hao Frank Yang</strong></p>
<p>This paper presents Edge-based Mixture of Experts (MoE) Collaborative Computing (EMC2), an optimal computing system designed for autonomous vehicles (AVs) that simultaneously achieves low-latency and high-accuracy 3D object detection. Unlike conventional approaches, EMC2 incorporates a scenario-aware MoE architecture specifically optimized for edge platforms. By effectively fusing LiDAR and camera data, the system leverages the complementary strengths of sparse 3D point clouds and dense 2D images to generate robust multimodal representations. To enable this, EMC2 employs an adaptive multimodal data bridge that performs multi-scale preprocessing on sensor inputs, followed by a scenario-aware routing mechanism that dynamically dispatches features to dedicated expert models based on object visibility and distance. In addition, EMC2 integrates joint hardware-software optimizations, including hardware resource utilization optimization and computational graph simplification, to ensure efficient and real-time inference on resource-constrained edge devices. Experiments on open-source benchmarks clearly show the EMC2 advancements as a end-to-end system. On the KITTI dataset, it achieves an average accuracy improvement of 3.58% and a 159.06% inference speedup compared to 15 baseline methods on Jetson platforms, with similar performance gains on the nuScenes dataset, highlighting its capability to advance reliable, real-time 3D object detection tasks for AVs. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†åŸºäºè¾¹ç¼˜è®¡ç®—çš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰ååŒè®¡ç®—ï¼ˆEMC2ï¼‰ç³»ç»Ÿã€‚è¿™æ˜¯ä¸€ç§ä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†è®¾è®¡çš„æœ€ä½³è®¡ç®—ç³»ç»Ÿï¼Œèƒ½å¤ŸåŒæ—¶å®ç°ä½å»¶è¿Ÿå’Œé«˜ç²¾åº¦çš„3Dç›®æ ‡æ£€æµ‹ã€‚ä¸åŒäºä¼ ç»Ÿæ–¹æ³•ï¼ŒEMC2é‡‡ç”¨äº†ä¸€ç§é’ˆå¯¹è¾¹ç¼˜å¹³å°çš„æƒ…æ™¯æ„ŸçŸ¥MoEæ¶æ„ã€‚é€šè¿‡æœ‰æ•ˆåœ°èåˆæ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨ç¨€ç–çš„3Dç‚¹äº‘å’Œå¯†é›†çš„2Då›¾åƒçš„äº’è¡¥ä¼˜åŠ¿ï¼Œç”Ÿæˆç¨³å¥çš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼ŒEMC2é‡‡ç”¨è‡ªé€‚åº”å¤šæ¨¡æ€æ•°æ®æ¡¥ï¼Œå¯¹ä¼ æ„Ÿå™¨è¾“å…¥è¿›è¡Œå¤šå°ºåº¦é¢„å¤„ç†ï¼Œç„¶åé€šè¿‡æƒ…æ™¯æ„ŸçŸ¥è·¯ç”±æœºåˆ¶ï¼Œæ ¹æ®ç›®æ ‡å¯è§æ€§å’Œè·ç¦»åŠ¨æ€å°†ç‰¹å¾æ´¾å‘åˆ°ä¸“ç”¨ä¸“å®¶æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒEMC2é›†æˆäº†è”åˆç¡¬ä»¶è½¯ä»¶ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ç¡¬ä»¶èµ„æºåˆ©ç”¨ä¼˜åŒ–å’Œè®¡ç®—å›¾ç®€åŒ–ï¼Œä»¥ç¡®ä¿åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆå®æ—¶æ¨ç†ã€‚åœ¨å…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒæ¸…æ¥šåœ°è¡¨æ˜äº†EMC2ä½œä¸ºç«¯åˆ°ç«¯ç³»ç»Ÿçš„ä¼˜åŠ¿ã€‚åœ¨KITTIæ•°æ®é›†ä¸Šï¼Œä¸Jetsonå¹³å°ä¸Šçš„15ç§åŸºå‡†æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒçš„å¹³å‡ç²¾åº¦æé«˜äº†3.58%ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†159.06%ï¼Œåœ¨nuScenesæ•°æ®é›†ä¸Šä¹Ÿå–å¾—äº†ç±»ä¼¼çš„æ€§èƒ½æå‡ï¼Œè¿™çªæ˜¾äº†å…¶åœ¨æ¨åŠ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†å¯é å®æ—¶3Dç›®æ ‡æ£€æµ‹ä»»åŠ¡æ–¹é¢çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04123v1">PDF</a> Accepted at ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é¢å‘è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„è¾¹ç¼˜è®¡ç®—ç³»ç»Ÿâ€”â€”è¾¹ç¼˜åŸºç¡€æ··åˆä¸“å®¶ååŒè®¡ç®—ç³»ç»Ÿï¼ˆEMC2ï¼‰ã€‚ç³»ç»Ÿå®ç°äº†ä½å»¶è¿Ÿé«˜å‡†ç¡®åº¦çš„3Dç‰©ä½“æ£€æµ‹ï¼Œç»“åˆäº†åœºæ™¯æ„ŸçŸ¥çš„æ··åˆä¸“å®¶æ¶æ„å’Œè¾¹ç¼˜å¹³å°ä¼˜åŒ–æŠ€æœ¯ã€‚é€šè¿‡èåˆæ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œç³»ç»Ÿåˆ©ç”¨ç¨€ç–çš„3Dç‚¹äº‘å’Œå¯†é›†çš„2Då›¾åƒç”Ÿæˆç¨³å¥çš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚å®éªŒè¡¨æ˜ï¼Œä¸åŸºå‡†æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨KITTIæ•°æ®é›†ä¸Šå¹³å‡ç²¾åº¦æé«˜äº†3.58%ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†159.06%ï¼Œå±•ç¤ºäº†å…¶åœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­çš„å¯é å®æ—¶3Dç‰©ä½“æ£€æµ‹èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯æ–‡æœ¬çš„ä¸»è¦è§‚ç‚¹æ‘˜è¦ï¼š</p>
<ul>
<li>EMC2æ˜¯ä¸€ä¸ªé’ˆå¯¹è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„ä¼˜åŒ–è®¡ç®—ç³»ç»Ÿï¼Œå®ç°äº†ä½å»¶è¿Ÿå’Œé«˜ç²¾åº¦çš„3Dç‰©ä½“æ£€æµ‹ã€‚</li>
<li>ç³»ç»Ÿç»“åˆäº†åœºæ™¯æ„ŸçŸ¥çš„æ··åˆä¸“å®¶æ¶æ„å’Œè¾¹ç¼˜å¹³å°ä¼˜åŒ–æŠ€æœ¯ã€‚</li>
<li>é€šè¿‡èåˆæ¿€å…‰é›·è¾¾å’Œç›¸æœºæ•°æ®ï¼Œç”Ÿæˆç¨³å¥çš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚</li>
<li>EMC2é‡‡ç”¨è‡ªé€‚åº”å¤šæ¨¡æ€æ•°æ®æ¡¥å’Œåœºæ™¯æ„ŸçŸ¥è·¯ç”±æœºåˆ¶ï¼Œæ ¹æ®ç‰©ä½“å¯è§æ€§å’Œè·ç¦»åŠ¨æ€è°ƒåº¦ç‰¹å¾åˆ°ä¸“å®¶æ¨¡å‹ã€‚</li>
<li>ç³»ç»Ÿé›†æˆäº†ç¡¬ä»¶å’Œè½¯ä»¶ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ç¡¬ä»¶èµ„æºåˆ©ç”¨ä¼˜åŒ–å’Œè®¡ç®—å›¾ç®€åŒ–ï¼Œç¡®ä¿åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆå®æ—¶æ¨ç†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04123">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1a2a13b0a7287c5b66e6b60ca99f2fc7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-48b28c8327a2f4073f0b6ac6a5f8da52.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5dee352aee7a6c1fb770fd9c172e4766.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef92d1030d276492e653627732835095.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7cd925cb9a4df213d10b363412ac697d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="2-5D-Object-Detection-for-Intelligent-Roadside-Infrastructure"><a href="#2-5D-Object-Detection-for-Intelligent-Roadside-Infrastructure" class="headerlink" title="2.5D Object Detection for Intelligent Roadside Infrastructure"></a>2.5D Object Detection for Intelligent Roadside Infrastructure</h2><p><strong>Authors:Nikolai Polley, Yacin Boualili, Ferdinand MÃ¼tsch, Maximilian Zipfl, Tobias Fleck, J. Marius ZÃ¶llner</strong></p>
<p>On-board sensors of autonomous vehicles can be obstructed, occluded, or limited by restricted fields of view, complicating downstream driving decisions. Intelligent roadside infrastructure perception systems, installed at elevated vantage points, can provide wide, unobstructed intersection coverage, supplying a complementary information stream to autonomous vehicles via vehicle-to-everything (V2X) communication. However, conventional 3D object-detection algorithms struggle to generalize under the domain shift introduced by top-down perspectives and steep camera angles. We introduce a 2.5D object detection framework, tailored specifically for infrastructure roadside-mounted cameras. Unlike conventional 2D or 3D object detection, we employ a prediction approach to detect ground planes of vehicles as parallelograms in the image frame. The parallelogram preserves the planar position, size, and orientation of objects while omitting their height, which is unnecessary for most downstream applications. For training, a mix of real-world and synthetically generated scenes is leveraged. We evaluate generalizability on a held-out camera viewpoint and in adverse-weather scenarios absent from the training set. Our results show high detection accuracy, strong cross-viewpoint generalization, and robustness to diverse lighting and weather conditions. Model weights and inference code are provided at: <a target="_blank" rel="noopener" href="https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection">https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection</a> </p>
<blockquote>
<p>è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„è½¦è½½ä¼ æ„Ÿå™¨å¯èƒ½ä¼šå—åˆ°é®æŒ¡ã€è§†é‡å—é™æˆ–è§†è§’å˜åŒ–çš„å½±å“ï¼Œå¯¼è‡´ä¸‹æ¸¸é©¾é©¶å†³ç­–å¤æ‚åŒ–ã€‚å®‰è£…åœ¨è¾ƒé«˜æœ‰åˆ©ä½ç½®çš„æ™ºèƒ½è·¯è¾¹åŸºç¡€è®¾æ–½æ„ŸçŸ¥ç³»ç»Ÿå¯ä»¥æä¾›å®½é˜”ã€æ— é®æŒ¡çš„äº¤å‰è·¯å£è¦†ç›–èŒƒå›´ï¼Œå¹¶é€šè¿‡è½¦å¯¹ä¸‡ç‰©ï¼ˆV2Xï¼‰é€šä¿¡ä¸ºè‡ªåŠ¨é©¾é©¶è½¦è¾†æä¾›è¡¥å……ä¿¡æ¯æµã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„3Dç›®æ ‡æ£€æµ‹ç®—æ³•åœ¨ç”±ä¸Šè€Œä¸‹çš„è§†è§’å’Œé™¡å³­çš„ç›¸æœºè§’åº¦å¼•èµ·çš„é¢†åŸŸå˜åŒ–ä¸‹éš¾ä»¥é€šç”¨åŒ–ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹åŸºç¡€è®¾æ–½è·¯è¾¹å®‰è£…çš„ç›¸æœºè®¾è®¡çš„2.5Dç›®æ ‡æ£€æµ‹æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„äºŒç»´æˆ–ä¸‰ç»´ç›®æ ‡æ£€æµ‹ä¸åŒï¼Œæˆ‘ä»¬é‡‡ç”¨é¢„æµ‹æ–¹æ³•æ¥æ£€æµ‹å›¾åƒå¸§ä¸­çš„è½¦è¾†åœ°é¢å¹³é¢ä½œä¸ºå¹³è¡Œå››è¾¹å½¢ã€‚å¹³è¡Œå››è¾¹å½¢ä¿ç•™äº†ç‰©ä½“çš„å¹³é¢ä½ç½®ã€å¤§å°å’Œæ–¹ä½ï¼ŒåŒæ—¶çœç•¥äº†é«˜åº¦ä¿¡æ¯ï¼Œè¿™åœ¨å¤§å¤šæ•°ä¸‹æ¸¸åº”ç”¨ä¸­æ˜¯ä¸å¿…è¦çš„ã€‚ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬ç»“åˆäº†ç°å®åœºæ™¯å’Œåˆæˆåœºæ™¯ã€‚æˆ‘ä»¬åœ¨æœªå‚ä¸è®­ç»ƒçš„ç›¸æœºè§†è§’å’Œæ¶åŠ£å¤©æ°”åœºæ™¯ä¸‹è¯„ä¼°äº†æ¨¡å‹çš„é€šç”¨æ€§ã€‚æˆ‘ä»¬çš„ç»“æœæ˜¾ç¤ºå‡ºè¾ƒé«˜çš„æ£€æµ‹ç²¾åº¦ã€è¾ƒå¼ºçš„è·¨è§†è§’é€šç”¨æ€§ä»¥åŠé€‚åº”ä¸åŒå…‰ç…§å’Œå¤©æ°”æ¡ä»¶çš„ç¨³å¥æ€§ã€‚æ¨¡å‹æƒé‡å’Œæ¨ç†ä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection">https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.03564v1">PDF</a> Accepted at 2025 IEEE 28th International Conference on Intelligent   Transportation Systems (ITSC)</p>
<p><strong>Summary</strong>ï¼š<br>è‡ªä¸»é©¾é©¶è½¦è¾†çš„è½¦è½½ä¼ æ„Ÿå™¨å¯èƒ½å—åˆ°é®æŒ¡ã€è§†é‡å—é™çš„å½±å“ï¼Œå½±å“ä¸‹æ¸¸é©¾é©¶å†³ç­–ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…å¼•å…¥äº†æ™ºèƒ½è·¯è¾¹æ„ŸçŸ¥ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯ä»é«˜å¤„ç›‘æ§äº¤å‰å£å¹¶ä¸ºè‡ªä¸»è½¦è¾†æä¾›è¡¥å……ä¿¡æ¯ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ä¸‰ç»´ç‰©ä½“æ£€æµ‹ç®—æ³•éš¾ä»¥åº”å¯¹ç”±ä¸Šè€Œä¸‹çš„è§†è§’å’Œé™¡å³­ç›¸æœºè§’åº¦å¸¦æ¥çš„é¢†åŸŸåç§»ã€‚ç ”ç©¶è€…æå‡ºä¸€ç§é€‚ç”¨äºè·¯è¾¹å®‰è£…çš„2.5ç»´ç‰©ä½“æ£€æµ‹æ¡†æ¶ï¼Œé‡‡ç”¨é¢„æµ‹æ–¹æ³•æ£€æµ‹è½¦è¾†çš„åœ°é¢å¹³é¢ä½œä¸ºå›¾åƒå¸§ä¸­çš„å¹³è¡Œå››è¾¹å½¢ã€‚æ­¤æ¡†æ¶åœ¨å¿½ç•¥ä¸å¿…è¦çš„é«˜åº¦ä¿¡æ¯çš„åŒæ—¶ï¼Œä¿ç•™äº†ç‰©ä½“çš„å¹³é¢ä½ç½®ã€å¤§å°å’Œæ–¹ä½ã€‚é€šè¿‡ç»“åˆçœŸå®åœºæ™¯å’Œåˆæˆåœºæ™¯è¿›è¡Œè®­ç»ƒï¼Œè¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ£€æµ‹ç²¾åº¦ã€è·¨è§†è§’çš„æ³›åŒ–èƒ½åŠ›ä»¥åŠé€‚åº”å„ç§ç…§æ˜å’Œå¤©æ°”æ¡ä»¶çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªä¸»é©¾é©¶è½¦è¾†çš„è½¦è½½ä¼ æ„Ÿå™¨å¯èƒ½å—åˆ°é®æŒ¡æˆ–è§†é‡é™åˆ¶çš„å½±å“ã€‚</li>
<li>æ™ºèƒ½è·¯è¾¹åŸºç¡€è®¾æ–½æ„ŸçŸ¥ç³»ç»Ÿå¯ä»¥æä¾›å¹¿æ³›çš„ã€æ— é®æŒ¡çš„äº¤å‰å£è¦†ç›–ï¼Œä¸ºè‡ªä¸»è½¦è¾†æä¾›è¡¥å……ä¿¡æ¯ã€‚</li>
<li>ä¼ ç»Ÿä¸‰ç»´ç‰©ä½“æ£€æµ‹ç®—æ³•éš¾ä»¥é€‚åº”ç”±ä¸Šè€Œä¸‹çš„è§†è§’å’Œé™¡å³­ç›¸æœºè§’åº¦å¸¦æ¥çš„å˜åŒ–ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§2.5ç»´ç‰©ä½“æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡é¢„æµ‹è½¦è¾†åœ°é¢å¹³é¢ä¸ºå¹³è¡Œå››è¾¹å½¢è¿›è¡Œæ£€æµ‹ã€‚</li>
<li>è¯¥æ¡†æ¶å¿½ç•¥ç‰©ä½“é«˜åº¦ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™å¹³é¢ä½ç½®ã€å¤§å°å’Œæ–¹ä½ã€‚</li>
<li>ç»“åˆçœŸå®å’Œåˆæˆåœºæ™¯è¿›è¡Œè®­ç»ƒï¼Œå…·æœ‰è‰¯å¥½çš„æ£€æµ‹ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.03564">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3cf80026a59dcb2992e48afd4e363676.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd2ec2283d5459a8d6137ec966211fb7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-93487c7daf065a2a9659fd0db5ee151b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-433052a0433b464385ce31e5b34be465.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-836262d3fff973c60180c7a6ed664cb9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b09125ad74428e4e45e428beb885024f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b8a5a360eb0e919aa8e7f88c3cfa5205.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="No-time-to-train-Training-Free-Reference-Based-Instance-Segmentation"><a href="#No-time-to-train-Training-Free-Reference-Based-Instance-Segmentation" class="headerlink" title="No time to train! Training-Free Reference-Based Instance Segmentation"></a>No time to train! Training-Free Reference-Based Instance Segmentation</h2><p><strong>Authors:Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley</strong></p>
<p>The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP). </p>
<blockquote>
<p>å†å²ä¸Šï¼Œå›¾åƒåˆ†å‰²æ¨¡å‹çš„æ€§èƒ½ä¸€ç›´å—åˆ°æ”¶é›†å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„é«˜æˆæœ¬çš„é™åˆ¶ã€‚Segment Anything Modelï¼ˆSAMï¼‰é€šè¿‡ä¸€ç§å¯æç¤ºçš„ã€ä¸è¯­ä¹‰æ— å…³çš„åˆ†å‰²èŒƒå¼ç¼“è§£äº†è¿™ä¸€åŸå§‹é—®é¢˜ï¼Œä½†ä»ç„¶éœ€è¦æ‰‹åŠ¨è§†è§‰æç¤ºæˆ–å¤æ‚çš„åŸŸç›¸å…³æç¤ºç”Ÿæˆè§„åˆ™æ¥å¤„ç†æ–°å›¾åƒã€‚ä¸ºäº†å‡è½»è¿™ä¸€æ–°è´Ÿæ‹…ï¼Œæˆ‘ä»¬çš„å·¥ä½œç ”ç©¶äº†åœ¨ä»…æä¾›ä¸€å°éƒ¨åˆ†å‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹è¿›è¡Œå¯¹è±¡åˆ†å‰²çš„ä»»åŠ¡ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯åˆ©ç”¨åŸºç¡€æ¨¡å‹å­¦åˆ°çš„å¼ºå¤§è¯­ä¹‰å…ˆéªŒçŸ¥è¯†ï¼Œæ¥è¯†åˆ«å‚è€ƒå›¾åƒå’Œç›®æ ‡å›¾åƒä¹‹é—´çš„ç›¸åº”åŒºåŸŸã€‚æˆ‘ä»¬å‘ç°è¿™ç§å¯¹åº”å…³ç³»èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å®ä¾‹çº§åˆ†å‰²æ©è†œï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¤šé˜¶æ®µã€æ— éœ€è®­ç»ƒçš„æ–¹æ³•å®ç°æˆ‘ä»¬çš„æƒ³æ³•ï¼ŒåŒ…æ‹¬ï¼ˆ1ï¼‰æ„å»ºå†…å­˜é“¶è¡Œï¼›ï¼ˆ2ï¼‰è¡¨ç¤ºèšåˆå’Œï¼ˆ3ï¼‰è¯­ä¹‰æ„ŸçŸ¥ç‰¹å¾åŒ¹é…ã€‚æˆ‘ä»¬çš„å®éªŒæ˜¾ç¤ºåœ¨åˆ†å‰²æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶åœ¨COCO FSODï¼ˆ36.8% nAPï¼‰ã€PASCAL VOC Few-Shotï¼ˆ71.2% nAP50ï¼‰ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨è·¨åŸŸFSODåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†ç°æœ‰çš„æ— è®­ç»ƒæ–¹æ³•ï¼ˆ22.4% nAPï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02798v2">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>å›¾åƒåˆ†å‰²æ¨¡å‹çš„æ€§èƒ½é•¿æœŸå—åˆ°å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®æ”¶é›†æˆæœ¬é«˜æ˜‚çš„åˆ¶çº¦ã€‚Segment Anything Modelï¼ˆSAMï¼‰é€šè¿‡å¯æç¤ºçš„ã€è¯­ä¹‰æ— å…³çš„åˆ†å‰²èŒƒå¼ç¼“è§£äº†è¿™ä¸€é—®é¢˜ï¼Œä½†ä»éœ€æ‰‹åŠ¨è§†è§‰æç¤ºæˆ–å¤æ‚çš„é¢†åŸŸç›¸å…³æç¤ºç”Ÿæˆè§„åˆ™æ¥å¤„ç†æ–°å›¾åƒã€‚ä¸ºå‡è½»è¿™ä¸€æ–°è´Ÿæ‹…ï¼Œæˆ‘ä»¬çš„å·¥ä½œç ”ç©¶åœ¨ä»…æä¾›å°‘é‡å‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹è¿›è¡Œç›®æ ‡åˆ†å‰²çš„ä»»åŠ¡ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯åˆ©ç”¨åŸºç¡€æ¨¡å‹å­¦ä¹ çš„å¼ºè¯­ä¹‰å…ˆéªŒçŸ¥è¯†ï¼Œè¯†åˆ«å‚è€ƒå›¾åƒå’Œç›®æ ‡å›¾åƒä¹‹é—´çš„å¯¹åº”åŒºåŸŸã€‚æˆ‘ä»¬å‘ç°è¿™ç§å¯¹åº”å…³ç³»èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å®ä¾‹çº§åˆ†å‰²æ©è†œï¼Œå¹¶é€šè¿‡ä¸€ä¸ªåŒ…å«ï¼ˆ1ï¼‰å†…å­˜åº“æ„å»ºã€ï¼ˆ2ï¼‰è¡¨ç¤ºèšåˆå’Œï¼ˆ3ï¼‰è¯­ä¹‰æ„ŸçŸ¥ç‰¹å¾åŒ¹é…çš„ã€æ— éœ€è®­ç»ƒçš„å¤šé˜¶æ®µæ–¹æ³•å®ç°äº†æˆ‘ä»¬çš„æƒ³æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å‰²æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶åœ¨COCO FSODï¼ˆ36.8% nAPï¼‰ã€PASCAL VOCå°‘æ•°é•œå¤´ï¼ˆ71.2% nAP50ï¼‰ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸”åœ¨è·¨åŸŸFSODåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºç°æœ‰çš„æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼ˆ22.4% nAPï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒåˆ†å‰²æ¨¡å‹é•¿æœŸå—å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®åˆ¶çº¦ã€‚</li>
<li>Segment Anything Modelï¼ˆSAMï¼‰å¼•å…¥å¯æç¤ºçš„åˆ†å‰²èŒƒå¼ï¼Œä½†ä»éœ€å¤æ‚æç¤ºæ“ä½œã€‚</li>
<li>ç ”ç©¶åœ¨ä»…æä¾›å°‘é‡å‚è€ƒå›¾åƒæƒ…å†µä¸‹çš„ç›®æ ‡åˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨åŸºç¡€æ¨¡å‹çš„å¼ºè¯­ä¹‰å…ˆéªŒçŸ¥è¯†è¯†åˆ«å‚è€ƒå›¾åƒä¸ç›®æ ‡å›¾åƒé—´çš„å¯¹åº”åŒºåŸŸã€‚</li>
<li>å¯¹åº”å…³ç³»èƒ½è‡ªåŠ¨ç”Ÿæˆå®ä¾‹çº§åˆ†å‰²æ©è†œï¼Œç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚</li>
<li>æå‡ºä¸€ä¸ªæ— éœ€è®­ç»ƒçš„å¤šé˜¶æ®µæ–¹æ³•ï¼ŒåŒ…æ‹¬å†…å­˜åº“æ„å»ºã€è¡¨ç¤ºèšåˆå’Œè¯­ä¹‰æ„ŸçŸ¥ç‰¹å¾åŒ¹é…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02798">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3978c1c075fc37ae0437a0e8189b5766.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60929355fb8a4bad99c25d2e219e5af4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-34ef610aa985554711ae9ea98c2158ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07b1ec1b74b110fec2dba51c7bb4fd11.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CRISP-SAM2-SAM2-with-Cross-Modal-Interaction-and-Semantic-Prompting-for-Multi-Organ-Segmentation"><a href="#CRISP-SAM2-SAM2-with-Cross-Modal-Interaction-and-Semantic-Prompting-for-Multi-Organ-Segmentation" class="headerlink" title="CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for   Multi-Organ Segmentation"></a>CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for   Multi-Organ Segmentation</h2><p><strong>Authors:Xinlei Yu, Changmiao Wang, Hui Jin, Ahmed Elazab, Gangyong Jia, Xiang Wan, Changqing Zou, Ruiquan Ge</strong></p>
<p>Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/YU-deep/CRISP_SAM2.git">https://github.com/YU-deep/CRISP_SAM2.git</a>. </p>
<blockquote>
<p>åŒ»å­¦å¤šå™¨å®˜åˆ†å‰²æ˜¯åŒ»å­¦å›¾åƒå¤„ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå¯¹äºåŒ»ç”Ÿè¿›è¡Œå‡†ç¡®çš„è¯Šæ–­å’Œåˆ¶å®šæœ‰æ•ˆçš„æ²»ç–—æ–¹æ¡ˆè‡³å…³é‡è¦ã€‚å°½ç®¡è¯¥é¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ç°æœ‰çš„å¤šå™¨å®˜åˆ†å‰²æ¨¡å‹å¾€å¾€å­˜åœ¨ç»†èŠ‚ä¸å‡†ç¡®ã€ä¾èµ–å‡ ä½•æç¤ºä»¥åŠç©ºé—´ä¿¡æ¯ä¸¢å¤±ç­‰é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åä¸ºCRISP-SAM2çš„æ–°æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŸºäºSAM2å…·æœ‰è·¨æ¨¡æ€äº¤äº’å’Œè¯­ä¹‰æç¤ºã€‚è¯¥æ¨¡å‹æ˜¯ä¸€ç§å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡å™¨å®˜çš„æ–‡æœ¬æè¿°æ¥è¿›è¡Œå¤šå™¨å®˜åŒ»å­¦åˆ†å‰²ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé€šè¿‡æ¸è¿›çš„äº¤å‰æ³¨æ„åŠ›äº¤äº’æœºåˆ¶å°†è§†è§‰å’Œæ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºè·¨æ¨¡æ€ä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚ç„¶åï¼Œè¿™äº›è¯­ä¹‰è¢«æ³¨å…¥å›¾åƒç¼–ç å™¨ï¼Œä»¥å¢å¼ºå¯¹è§†è§‰ä¿¡æ¯çš„è¯¦ç»†ç†è§£ã€‚ä¸ºäº†å‡å°‘å¯¹å‡ ä½•æç¤ºçš„ä¾èµ–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§è¯­ä¹‰æç¤ºç­–ç•¥ï¼Œä»¥æ›¿ä»£åŸå§‹æç¤ºç¼–ç å™¨ï¼Œæé«˜äº†å¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ç›®æ ‡çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜é‡‡ç”¨äº†ç›¸ä¼¼åº¦æ’åºçš„è‡ªæ›´æ–°ç­–ç•¥å¯¹å†…å­˜è¿›è¡Œæ›´æ–°å’Œæ©è†œç»†åŒ–è¿‡ç¨‹ï¼Œè¿›ä¸€æ­¥é€‚åº”åŒ»å­¦å½±åƒå¹¶å¢å¼ºå±€éƒ¨ç»†èŠ‚ã€‚åœ¨ä¸ƒä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¯¹æ¯”å®éªŒè¡¨æ˜ï¼ŒCRISP-SAM2ä¼˜äºç°æœ‰æ¨¡å‹ã€‚å¹¿æ³›çš„åˆ†æä¹Ÿè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œè¯å®äº†å…¶å“è¶Šæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨è§£å†³ä¸Šè¿°æåˆ°çš„å±€é™æ€§æ–¹é¢ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/YU-deep/CRISP_SAM2.git%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/YU-deep/CRISP_SAM2.gitè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23121v2">PDF</a> Accepted By ACMMM25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºCRISP-SAM2çš„å¤šå™¨å®˜åŒ»å­¦åˆ†å‰²æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡è·¨æ¨¡æ€äº¤äº’å’Œè¯­ä¹‰æç¤ºæŠ€æœ¯è§£å†³äº†å½“å‰æ¨¡å‹åœ¨ç»†èŠ‚å‡†ç¡®æ€§ã€å‡ ä½•æç¤ºä¾èµ–æ€§å’Œç©ºé—´ä¿¡æ¯æŸå¤±ç­‰æ–¹é¢çš„é—®é¢˜ã€‚CRISP-SAM2æ¨¡å‹é€šè¿‡å°†è§†è§‰å’Œæ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºè·¨æ¨¡æ€ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œå¹¶æ³¨å…¥å›¾åƒç¼–ç å™¨ä»¥å¢å¼ºå¯¹è§†è§‰ä¿¡æ¯çš„è¯¦ç»†ç†è§£ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨è¯­ä¹‰æç¤ºç­–ç•¥æ¶ˆé™¤å¯¹å‡ ä½•æç¤ºçš„ä¾èµ–ï¼Œå¹¶é‡‡ç”¨ç›¸ä¼¼åº¦æ’åºè‡ªæ›´æ–°ç­–ç•¥å’Œæ©è†œç»†åŒ–è¿‡ç¨‹è¿›ä¸€æ­¥é€‚åº”åŒ»å­¦æˆåƒå¹¶å¢å¼ºå±€éƒ¨ç»†èŠ‚ã€‚åœ¨ä¸ƒä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¯¹æ¯”å®éªŒè¡¨æ˜ï¼ŒCRISP-SAM2æ¨¡å‹ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šå™¨å®˜åŒ»å­¦åˆ†å‰²æ˜¯åŒ»ç–—å›¾åƒå¤„ç†ä¸­çš„å…³é”®éƒ¨åˆ†ï¼Œå¯¹äºåŒ»ç”Ÿçš„å‡†ç¡®è¯Šæ–­å’Œæ²»ç–—è®¡åˆ’åˆ¶å®šè‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰çš„å¤šå™¨å®˜åˆ†å‰²æ¨¡å‹å­˜åœ¨ç»†èŠ‚ä¸å‡†ç¡®ã€ä¾èµ–å‡ ä½•æç¤ºå’ŒæŸå¤±ç©ºé—´ä¿¡æ¯ç­‰é—®é¢˜ã€‚</li>
<li>å¼•å…¥çš„CRISP-SAM2æ¨¡å‹é€šè¿‡è·¨æ¨¡æ€äº¤äº’å’Œè¯­ä¹‰æç¤ºæŠ€æœ¯è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>CRISP-SAM2å°†è§†è§‰å’Œæ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºè·¨æ¨¡æ€ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œæé«˜è§†è§‰ä¿¡æ¯çš„ç†è§£ã€‚</li>
<li>è¯­ä¹‰æç¤ºç­–ç•¥æ¶ˆé™¤å¯¹å‡ ä½•æç¤ºçš„ä¾èµ–ï¼Œå¹¶é‡‡ç”¨ç›¸ä¼¼åº¦æ’åºè‡ªæ›´æ–°ç­–ç•¥å’Œæ©è†œç»†åŒ–è¿‡ç¨‹æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸ƒä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¯¹æ¯”å®éªŒè¯æ˜CRISP-SAM2æ¨¡å‹ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23121">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57da5d89a7496d16c96039457ca0792f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d55eabbad866383adbd05223597f84e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6595d78001f04a7058b24c04f7c1ab2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-849ef97942faad6a6f3872cd1c9d9fc6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Pillar-Voxel-Fusion-Network-for-3D-Object-Detection-in-Airborne-Hyperspectral-Point-Clouds"><a href="#Pillar-Voxel-Fusion-Network-for-3D-Object-Detection-in-Airborne-Hyperspectral-Point-Clouds" class="headerlink" title="Pillar-Voxel Fusion Network for 3D Object Detection in Airborne   Hyperspectral Point Clouds"></a>Pillar-Voxel Fusion Network for 3D Object Detection in Airborne   Hyperspectral Point Clouds</h2><p><strong>Authors:Yanze Jiang, Yanfeng Gu, Xian Li</strong></p>
<p>Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatial and spectral information of ground objects, offering excellent 3D perception and target recognition capabilities. Current approaches for generating HPCs often involve fusion techniques with hyperspectral images and LiDAR point clouds, which inevitably lead to geometric-spectral distortions due to fusion errors and obstacle occlusions. These adverse effects limit their performance in downstream fine-grained tasks across multiple scenarios, particularly in airborne applications. To address these issues, we propose PiV-AHPC, a 3D object detection network for airborne HPCs. To the best of our knowledge, this is the first attempt at this HPCs task. Specifically, we first develop a pillar-voxel dual-branch encoder, where the former captures spectral and vertical structural features from HPCs to overcome spectral distortion, while the latter emphasizes extracting accurate 3D spatial features from point clouds. A multi-level feature fusion mechanism is devised to enhance information interaction between the two branches, achieving neighborhood feature alignment and channel-adaptive selection, thereby organically integrating heterogeneous features and mitigating geometric distortion. Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPC possesses state-of-the-art detection performance and high generalization capability. </p>
<blockquote>
<p>é«˜å…‰è°±ç‚¹äº‘ï¼ˆHPCï¼‰å¯ä»¥åŒæ—¶è¡¨å¾åœ°é¢ç‰©ä½“çš„3Dç©ºé—´å’Œå…‰è°±ä¿¡æ¯ï¼Œæä¾›å‡ºè‰²çš„3Dæ„ŸçŸ¥å’Œç›®æ ‡è¯†åˆ«èƒ½åŠ›ã€‚ç›®å‰ç”ŸæˆHPCçš„æ–¹æ³•é€šå¸¸æ¶‰åŠé«˜å…‰è°±å›¾åƒå’Œæ¿€å…‰é›·è¾¾ç‚¹äº‘çš„èåˆæŠ€æœ¯ï¼Œç”±äºèåˆè¯¯å·®å’Œéšœç¢ç‰©é®æŒ¡ï¼Œä¸å¯é¿å…åœ°ä¼šå¯¼è‡´å‡ ä½•å…‰è°±å¤±çœŸã€‚è¿™äº›ä¸åˆ©å½±å“åœ¨å¤šåœºæ™¯ä¸‹çš„ä¸‹æ¸¸ç²¾ç»†ä»»åŠ¡ä¸­é™åˆ¶äº†å…¶æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç©ºä¸­åº”ç”¨æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PiV-AHPCï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç©ºä¸­HPCçš„3Då¯¹è±¡æ£€æµ‹ç½‘ç»œã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯HPCä»»åŠ¡ä¸Šçš„é¦–æ¬¡å°è¯•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå¼€å‘äº†ä¸€ä¸ªæŸ±ä½“-ä½“ç´ åŒåˆ†æ”¯ç¼–ç å™¨ï¼Œå‰è€…ä»HPCä¸­æå–å…‰è°±å’Œå‚ç›´ç»“æ„ç‰¹å¾ä»¥å…‹æœå…‰è°±å¤±çœŸï¼Œè€Œåè€…åˆ™ä¾§é‡äºä»ç‚¹äº‘ä¸­æå–å‡†ç¡®çš„3Dç©ºé—´ç‰¹å¾ã€‚è®¾è®¡äº†ä¸€ç§å¤šå±‚æ¬¡ç‰¹å¾èåˆæœºåˆ¶ï¼Œä»¥å¢å¼ºä¸¤ä¸ªåˆ†æ”¯ä¹‹é—´çš„ä¿¡æ¯äº¤äº’ï¼Œå®ç°é‚»åŸŸç‰¹å¾å¯¹é½å’Œé€šé“è‡ªé€‚åº”é€‰æ‹©ï¼Œä»è€Œæœ‰æœºåœ°èåˆå¼‚è´¨ç‰¹å¾å¹¶å‡è½»å‡ ä½•å¤±çœŸã€‚åœ¨ä¸¤ä¸ªç©ºä¸­HPCæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPiV-AHPCå…·æœ‰æœ€å…ˆè¿›çš„æ£€æµ‹æ€§èƒ½å’Œé«˜æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09506v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¶…å…‰è°±ç‚¹äº‘ï¼ˆHPCsï¼‰èƒ½åŒæ—¶æè¿°åœ°é¢ç‰©ä½“çš„ä¸‰ç»´ç©ºé—´ä¸å…‰è°±ä¿¡æ¯ï¼Œå…·å¤‡å‡ºè‰²çš„ä¸‰ç»´æ„ŸçŸ¥å’Œç›®æ ‡è¯†åˆ«èƒ½åŠ›ã€‚å½“å‰ç”ŸæˆHPCsçš„æ–¹æ³•å¤§å¤šé‡‡ç”¨ä¸è¶…å…‰è°±å›¾åƒå’Œæ¿€å…‰é›·è¾¾ç‚¹äº‘çš„èåˆæŠ€æœ¯ï¼Œä½†ç”±äºèåˆè¯¯å·®å’Œé®æŒ¡é—®é¢˜ï¼Œä¸å¯é¿å…åœ°ä¼šå‡ºç°å‡ ä½•å…‰è°±å¤±çœŸã€‚è¿™äº›é—®é¢˜åœ¨å¤šåœºæ™¯ä¸‹æ¸¸ç²¾ç»†ä»»åŠ¡ä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨ç©ºä¸­åº”ç”¨ä¸­çš„æ€§èƒ½è¡¨ç°å°¤ä¸ºçªå‡ºã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºPiV-AHPCâ€”â€”ä¸€ç§ç”¨äºç©ºä¸­HPCsçš„ä¸‰ç»´ç›®æ ‡æ£€æµ‹ç½‘ç»œã€‚è¯¥ç½‘ç»œé€šè¿‡æ„å»ºæ”¯æŸ±ä½“ç´ åŒåˆ†æ”¯ç¼–ç å™¨ï¼Œå…‹æœå…‰è°±å¤±çœŸå¹¶æå–å‡†ç¡®çš„3Dç©ºé—´ç‰¹å¾ï¼ŒåŒæ—¶è®¾è®¡å¤šå±‚æ¬¡ç‰¹å¾èåˆæœºåˆ¶ï¼Œå¼ºåŒ–ä¿¡æ¯äº¤äº’ï¼Œå®ç°é‚»åŸŸç‰¹å¾å¯¹é½å’Œé€šé“è‡ªé€‚åº”é€‰æ‹©ï¼Œä»è€Œæœ‰æœºèåˆå¼‚æ„å›¾ç‰¹å¾å¹¶å‡è½»å‡ ä½•å¤±çœŸã€‚åœ¨ä¸¤ç»„ç©ºä¸­HPCsæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPiV-AHPCå…·å¤‡ä¸€æµæ£€æµ‹æ€§èƒ½å’Œé«˜æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å…‰è°±ç‚¹äº‘ï¼ˆHPCsï¼‰èåˆäº†ä¸‰ç»´ç©ºé—´å’Œå…‰è°±ä¿¡æ¯ï¼Œä¸ºåœ°é¢ç‰©ä½“æä¾›äº†å“è¶Šçš„ä¸‰ç»´æ„ŸçŸ¥å’Œç›®æ ‡è¯†åˆ«åŠŸèƒ½ã€‚</li>
<li>å½“å‰HPCç”Ÿæˆæ–¹æ³•ä¸»è¦åŸºäºèåˆæŠ€æœ¯ï¼Œä½†å­˜åœ¨å‡ ä½•å…‰è°±å¤±çœŸé—®é¢˜ã€‚</li>
<li>PiV-AHPCç½‘ç»œé¦–æ¬¡å°è¯•è§£å†³ç©ºä¸­HPCsçš„ä¸‰ç»´ç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚</li>
<li>PiV-AHPCé‡‡ç”¨æ”¯æŸ±ä½“ç´ åŒåˆ†æ”¯ç¼–ç å™¨ï¼Œåˆ†åˆ«å¤„ç†å…‰è°±å’Œå‚ç›´ç»“æ„ç‰¹å¾ä»¥åŠå‡†ç¡®çš„3Dç©ºé—´ç‰¹å¾ã€‚</li>
<li>å¤šå±‚æ¬¡ç‰¹å¾èåˆæœºåˆ¶å¼ºåŒ–äº†ä¿¡æ¯äº¤äº’ï¼Œå®ç°äº†ç‰¹å¾å¯¹é½å’Œé€šé“è‡ªé€‚åº”é€‰æ‹©ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒPiV-AHPCåœ¨æ£€æµ‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡è¾¾åˆ°ä¸€æµæ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09506">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fda8ee2b200b8cb5ffcf6bc4d747dc1e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7db62f7bee30523b3c3e2102acc4db9e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f13fd1179becdb093b11f7d269cbdb6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6fb46b7f33704f0354e8b2c97e6ee17d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bac45d0ea605e7f9facd14be7079930e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Hallucinatory-Image-Tokens-A-Training-free-EAZY-Approach-on-Detecting-and-Mitigating-Object-Hallucinations-in-LVLMs"><a href="#Hallucinatory-Image-Tokens-A-Training-free-EAZY-Approach-on-Detecting-and-Mitigating-Object-Hallucinations-in-LVLMs" class="headerlink" title="Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting   and Mitigating Object Hallucinations in LVLMs"></a>Hallucinatory Image Tokens: A Training-free EAZY Approach on Detecting   and Mitigating Object Hallucinations in LVLMs</h2><p><strong>Authors:Liwei Che, Tony Qingze Liu, Jing Jia, Weiyi Qin, Ruixiang Tang, Vladimir Pavlovic</strong></p>
<p>Despite their remarkable potential, Large Vision-Language Models (LVLMs) still face challenges with object hallucination, a problem where their generated outputs mistakenly incorporate objects that do not actually exist. Although most works focus on addressing this issue within the language-model backbone, our work shifts the focus to the image input source, investigating how specific image tokens contribute to hallucinations. Our analysis reveals a striking finding: a small subset of image tokens with high attention scores are the primary drivers of object hallucination. By removing these hallucinatory image tokens (only 1.5% of all image tokens), the issue can be effectively mitigated. This finding holds consistently across different models and datasets. Building on this insight, we introduce EAZY, a novel, training-free method that automatically identifies and Eliminates hAllucinations by Zeroing out hallucinatorY image tokens. We utilize EAZY for unsupervised object hallucination detection, achieving 15% improvement compared to previous methods. Additionally, EAZY demonstrates remarkable effectiveness in mitigating hallucinations while preserving model utility and seamlessly adapting to various LVLM architectures. </p>
<blockquote>
<p>å°½ç®¡å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä½†å®ƒä»¬ä»é¢ä¸´å¯¹è±¡å¹»è§‰çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¯ä¸€ä¸ªç”Ÿæˆè¾“å‡ºä¸­è¯¯åŒ…å«å®é™…ä¸å­˜åœ¨çš„å¯¹è±¡çš„é—®é¢˜ã€‚è™½ç„¶å¤§å¤šæ•°å·¥ä½œéƒ½é›†ä¸­åœ¨è§£å†³è¯­è¨€æ¨¡å‹ä¸»å¹²ä¸­çš„é—®é¢˜ï¼Œä½†æˆ‘ä»¬çš„å·¥ä½œå°†é‡ç‚¹è½¬å‘å›¾åƒè¾“å…¥æºï¼Œç ”ç©¶ç‰¹å®šçš„å›¾åƒæ ‡è®°æ˜¯å¦‚ä½•å¯¼è‡´å¹»è§‰çš„ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ä¸€ä¸ªæƒŠäººçš„å‘ç°ï¼šå…·æœ‰é«˜æ³¨æ„åŠ›åˆ†æ•°çš„å°‘é‡å›¾åƒæ ‡è®°æ˜¯å¯¹è±¡å¹»è§‰çš„ä¸»è¦é©±åŠ¨åŠ›ã€‚é€šè¿‡ç§»é™¤è¿™äº›äº§ç”Ÿå¹»è§‰çš„å›¾åƒæ ‡è®°ï¼ˆä»…å æ‰€æœ‰å›¾åƒæ ‡è®°çš„1.5%ï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å‡è½»é—®é¢˜ã€‚è¿™ä¸€å‘ç°åœ¨ä¸åŒçš„æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå§‹ç»ˆé€‚ç”¨ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†æ— éœ€è®­ç»ƒçš„EAZYæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å’Œæ¶ˆé™¤é€šè¿‡æ¸…é›¶å¹»è§‰æ ‡è®°çš„å›¾åƒæ¥æ¶ˆé™¤å¹»è§‰æ ‡è®°ï¼ˆZeroing out hallucinatorYï¼‰ã€‚æˆ‘ä»¬åˆ©ç”¨EAZYè¿›è¡Œæ— ç›‘ç£å¯¹è±¡å¹»è§‰æ£€æµ‹ï¼Œä¸ä¹‹å‰çš„æ–¹æ³•ç›¸æ¯”å–å¾—äº†15%çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒEAZYåœ¨ç¼“è§£å¹»è§‰çš„åŒæ—¶ä¿æŒæ¨¡å‹æ•ˆç”¨ï¼Œå¹¶èƒ½æ— ç¼é€‚åº”å„ç§LVLMæ¶æ„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07772v2">PDF</a> Accepted to ICCV2025</p>
<p><strong>Summary</strong>ï¼šå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰è™½æ½œåŠ›å·¨å¤§ï¼Œä½†ä»é¢ä¸´å¯¹è±¡å¹»è§‰é—®é¢˜ï¼Œå³å…¶ç”Ÿæˆè¾“å‡ºä¼šé”™è¯¯åœ°èå…¥å®é™…ä¸å­˜åœ¨çš„å¯¹è±¡ã€‚ç°æœ‰ç ”ç©¶å¤§å¤šå…³æ³¨è¯­è¨€æ¨¡å‹çš„å†…éƒ¨ç»“æ„æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æœ¬ç ”ç©¶è½¬å‘å›¾åƒè¾“å…¥æºï¼Œæ¢è®¨ç‰¹å®šçš„å›¾åƒä»¤ç‰Œå¦‚ä½•å¯¼è‡´å¹»è§‰ã€‚ç ”ç©¶å‘ç°ï¼šå…·æœ‰è¾ƒé«˜æ³¨æ„åŠ›åˆ†æ•°çš„ä¸€å°éƒ¨åˆ†å›¾åƒä»¤ç‰Œæ˜¯å¯¹è±¡å¹»è§‰çš„ä¸»è¦é©±åŠ¨åŠ›ã€‚ç§»é™¤è¿™äº›å¹»è§‰å›¾åƒä»¤ç‰Œï¼ˆä»…å æ‰€æœ‰å›¾åƒä»¤ç‰Œçš„1.5%ï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£è¿™ä¸€é—®é¢˜ã€‚æœ¬ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§åä¸ºEAZYçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€è®­ç»ƒå³å¯è‡ªåŠ¨è¯†åˆ«å¹¶æ¶ˆé™¤å¹»è§‰ï¼Œé€šè¿‡å¯¹äº§ç”Ÿå¹»è§‰çš„å›¾åƒä»¤ç‰Œè¿›è¡Œæ¸…é›¶æ“ä½œï¼Œå®ç°äº†æ— ç›‘ç£å¯¹è±¡å¹»è§‰æ£€æµ‹çš„æ˜¾è‘—æ”¹å–„ï¼Œæé«˜äº†15%ã€‚åŒæ—¶ï¼ŒEAZYåœ¨ä¿æŒæ¨¡å‹å®ç”¨æ€§çš„åŒæ—¶ï¼Œè½»æ¾é€‚åº”å„ç§LVLMæ¶æ„ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å­˜åœ¨å¯¹è±¡å¹»è§‰é—®é¢˜ï¼Œå³ç”Ÿæˆè¾“å‡ºä¼šé”™è¯¯åœ°èå…¥å®é™…ä¸å­˜åœ¨çš„å¯¹è±¡ã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œå…·æœ‰è¾ƒé«˜æ³¨æ„åŠ›åˆ†æ•°çš„å°‘éƒ¨åˆ†å›¾åƒä»¤ç‰Œæ˜¯å¯¹è±¡å¹»è§‰çš„ä¸»è¦é©±åŠ¨åŠ›ã€‚</li>
<li>é€šè¿‡ç§»é™¤è¿™äº›å¹»è§‰å›¾åƒä»¤ç‰Œï¼Œå¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£å¯¹è±¡å¹»è§‰é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•EAZYï¼Œæ— éœ€è®­ç»ƒå³å¯è‡ªåŠ¨è¯†åˆ«å¹¶æ¶ˆé™¤å¹»è§‰ã€‚</li>
<li>EAZYé€šè¿‡å¯¹äº§ç”Ÿå¹»è§‰çš„å›¾åƒä»¤ç‰Œè¿›è¡Œæ¸…é›¶æ“ä½œï¼Œå®ç°äº†æ— ç›‘ç£å¯¹è±¡å¹»è§‰æ£€æµ‹çš„æ˜¾è‘—æ”¹å–„ã€‚</li>
<li>EAZYç›¸è¾ƒäºä¹‹å‰çš„æ–¹æ³•æœ‰15%çš„æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07772">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-daead031a8926ff475931b986de7f291.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-324503d22086771414772d362d99b67e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4350fc65286ec99e62ba62048bc7c8a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d122d236f79f9dcd0a5dcb7a0c8cea3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a6686ad9f6da474741357d5d16d8be21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a24c268d5e223ed6f933872af372ad30.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a9ddf6754482135872bd413db56e65f3.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection"><a href="#UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection" class="headerlink" title="UnitModule: A Lightweight Joint Image Enhancement Module for Underwater   Object Detection"></a>UnitModule: A Lightweight Joint Image Enhancement Module for Underwater   Object Detection</h2><p><strong>Authors:Zhuoyan Liu, Bo Wang, Ye Li, Jiaxian He, Yunfeng Li</strong></p>
<p>Underwater object detection faces the problem of underwater image degradation, which affects the performance of the detector. Underwater object detection methods based on noise reduction and image enhancement usually do not provide images preferred by the detector or require additional datasets. In this paper, we propose a plug-and-play \textbf{U}nderwater joi\textbf{n}t \textbf{i}mage enhancemen\textbf{t} \textbf{Module} (UnitModule) that provides the input image preferred by the detector. We design an unsupervised learning loss for the joint training of UnitModule with the detector without additional datasets to improve the interaction between UnitModule and the detector. Furthermore, a color cast predictor with the assisting color cast loss and a data augmentation called Underwater Color Random Transfer (UCRT) are designed to improve the performance of UnitModule on underwater images with different color casts. Extensive experiments are conducted on DUO for different object detection models, where UnitModule achieves the highest performance improvement of 2.6 AP for YOLOv5-S and gains the improvement of 3.3 AP on the brand-new test set ((\text{URPC}_{test})). And UnitModule significantly improves the performance of all object detection models we test, especially for models with a small number of parameters. In addition, UnitModule with a small number of parameters of 31K has little effect on the inference speed of the original object detection model. Our quantitative and visual analysis also demonstrates the effectiveness of UnitModule in enhancing the input image and improving the perception ability of the detector for object features. The code is available at <a target="_blank" rel="noopener" href="https://github.com/LEFTeyex/UnitModule">https://github.com/LEFTeyex/UnitModule</a>. </p>
<blockquote>
<p>æ°´ä¸‹ç›®æ ‡æ£€æµ‹é¢ä¸´ç€æ°´ä¸‹å›¾åƒé€€åŒ–çš„é—®é¢˜ï¼Œè¿™ä¸€é—®é¢˜ä¼šå½±å“æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚åŸºäºå™ªå£°å‡å°‘å’Œå›¾åƒå¢å¼ºçš„æ°´ä¸‹ç›®æ ‡æ£€æµ‹æ–¹æ³•é€šå¸¸ä¸æä¾›æ£€æµ‹å™¨æ‰€åå¥½çš„å›¾åƒï¼Œæˆ–è€…éœ€è¦é¢å¤–çš„æ•°æ®é›†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å³æ’å³ç”¨çš„æ°´ä¸‹è”åˆå›¾åƒå¢å¼ºæ¨¡å—ï¼ˆUnitModuleï¼‰ï¼Œè¯¥æ¨¡å—å¯æä¾›æ£€æµ‹å™¨æ‰€åå¥½çš„è¾“å…¥å›¾åƒã€‚æˆ‘ä»¬ä¸ºUnitModuleä¸æ£€æµ‹å™¨çš„è”åˆè®­ç»ƒè®¾è®¡äº†ä¸€ç§æ— ç›‘ç£å­¦ä¹ æŸå¤±ï¼Œè€Œæ— éœ€é¢å¤–æ•°æ®é›†ï¼Œä»¥æé«˜UnitModuleä¸æ£€æµ‹å™¨ä¹‹é—´çš„äº¤äº’ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†å¸¦æœ‰è¾…åŠ©è‰²å½©æŠ•å°„æŸå¤±çš„è‰²å½©æŠ•å°„é¢„æµ‹å™¨ï¼Œä»¥åŠä¸€ç§åä¸ºæ°´ä¸‹è‰²å½©éšæœºè½¬æ¢ï¼ˆUCRTï¼‰çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä»¥æé«˜UnitModuleåœ¨ä¸åŒè‰²å½©æŠ•å°„çš„æ°´ä¸‹å›¾åƒä¸Šçš„æ€§èƒ½ã€‚åœ¨DUOæ•°æ®é›†ä¸Šå¯¹ä¸åŒçš„ç›®æ ‡æ£€æµ‹æ¨¡å‹è¿›è¡Œäº†å¤§é‡å®éªŒï¼ŒUnitModuleåœ¨YOLOv5-Sä¸Šå®ç°äº†æœ€é«˜çš„æ€§èƒ½æå‡2.6 APï¼Œå¹¶åœ¨å…¨æ–°æµ‹è¯•é›†URPCtestä¸Šå®ç°äº†3.3 APçš„æå‡ã€‚UnitModuleæ˜¾è‘—æé«˜äº†æˆ‘ä»¬æ‰€æµ‹è¯•çš„æ‰€æœ‰ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å¯¹äºå‚æ•°æ•°é‡è¾ƒå°‘çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒUnitModuleå‚æ•°æ•°é‡è¾ƒå°‘ï¼Œä»…æœ‰31Kä¸ªå‚æ•°ï¼Œå¯¹åŸå§‹ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„æ¨ç†é€Ÿåº¦å‡ ä¹æ²¡æœ‰å½±å“ã€‚æˆ‘ä»¬çš„å®šé‡å’Œè§†è§‰åˆ†æè¿˜è¯æ˜äº†UnitModuleåœ¨å¢å¼ºè¾“å…¥å›¾åƒå’Œæé«˜æ£€æµ‹å™¨å¯¹ç›®æ ‡ç‰¹å¾çš„æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/LEFTeyex/UnitModule%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LEFTeyex/UnitModuleæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04708v2">PDF</a> 15 pages, 10 figures, 13 tables, accepted by PR</p>
<p><strong>Summary</strong><br>æ°´ä¸‹ç›®æ ‡æ£€æµ‹é¢ä¸´å›¾åƒé€€åŒ–é—®é¢˜ï¼Œå½±å“æ£€æµ‹æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å³æ’å³ç”¨å‹çš„æ°´ä¸‹è”åˆå›¾åƒå¢å¼ºæ¨¡å—ï¼ˆUnitModuleï¼‰ï¼Œä¸ºæ£€æµ‹å™¨æä¾›é¦–é€‰çš„è¾“å…¥å›¾åƒã€‚è¯¥æ¨¡å—è®¾è®¡äº†ä¸€ç§æ— ç›‘ç£å­¦ä¹ æŸå¤±ï¼Œå¯ä¸æ£€æµ‹å™¨è¿›è¡Œè”åˆè®­ç»ƒï¼Œæ— éœ€é¢å¤–æ•°æ®é›†å³å¯æ”¹å–„æ¨¡å—ä¸æ£€æµ‹å™¨ä¹‹é—´çš„äº¤äº’ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†è‰²å½©æŠ•å°„é¢„æµ‹å™¨å’Œæ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä»¥æé«˜UnitModuleåœ¨ä¸åŒè‰²å½©æŠ•å°„æ°´ä¸‹å›¾åƒä¸Šçš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒUnitModuleå¯¹å¤šç§ç›®æ ‡æ£€æµ‹æ¨¡å‹éƒ½æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨å‚æ•°è¾ƒå°‘çš„æ¨¡å‹ä¸Šã€‚è¯¥æ¨¡å—å‚æ•°è¾ƒå°‘ï¼Œå¯¹åŸå§‹ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„æ¨ç†é€Ÿåº¦å½±å“è¾ƒå°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹ç›®æ ‡æ£€æµ‹é¢ä¸´å›¾åƒé€€åŒ–é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å³æ’å³ç”¨å‹çš„æ°´ä¸‹è”åˆå›¾åƒå¢å¼ºæ¨¡å—ï¼ˆUnitModuleï¼‰ï¼Œä¸ºæ£€æµ‹å™¨æä¾›ä¼˜åŒ–çš„è¾“å…¥å›¾åƒã€‚</li>
<li>UnitModuleé€šè¿‡æ— ç›‘ç£å­¦ä¹ æŸå¤±ä¸æ£€æµ‹å™¨è”åˆè®­ç»ƒï¼Œæ— éœ€é¢å¤–æ•°æ®é›†ã€‚</li>
<li>è‰²å½©æŠ•å°„é¢„æµ‹å™¨å’Œæ•°æ®å¢å¼ºæ–¹æ³•ç”¨äºæé«˜UnitModuleåœ¨ä¸åŒæ°´ä¸‹å›¾åƒä¸Šçš„æ€§èƒ½ã€‚</li>
<li>UnitModuleå¯¹å¤šç§ç›®æ ‡æ£€æµ‹æ¨¡å‹æœ‰æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå°¤å…¶é€‚ç”¨äºå‚æ•°è¾ƒå°‘çš„æ¨¡å‹ã€‚</li>
<li>UnitModuleå‚æ•°è¾ƒå°‘ï¼Œå¯¹åŸå§‹ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„æ¨ç†é€Ÿåº¦å½±å“è¾ƒå°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.04708">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5777970f343fbc646cd9d60b9921214e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f322a9aa8506e990bd63b75e1e605c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-597ea0e761098ab072596ed0b825dc8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fcbc6a79bf9a793faa9f73a89c6a68fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cfcd9db1fe9ec5093df4861cd883e2a3.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-09/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-6eca5caf497be878e7106b53e04ff5c5.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  CLIP-RL Surgical Scene Segmentation Using Contrastive Language-Vision   Pretraining & Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-09/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-6236f6d3febe66dcf8b706f1b83798bf.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-09  Multi-modal Representations for Fine-grained Multi-label Critical View   of Safety Recognition
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24595.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
