<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  Semi-Supervised 3D Medical Segmentation from 2D Natural Images   Pretrained Model">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-305bb56c15aae926bb206bc5437d48c1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031318&auth_key=1760031318-0-0-c42cfd93581cf4021e9dd425889340a9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-22
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    44 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-20-æ›´æ–°"><a href="#2025-09-20-æ›´æ–°" class="headerlink" title="2025-09-20 æ›´æ–°"></a>2025-09-20 æ›´æ–°</h1><h2 id="Semi-Supervised-3D-Medical-Segmentation-from-2D-Natural-Images-Pretrained-Model"><a href="#Semi-Supervised-3D-Medical-Segmentation-from-2D-Natural-Images-Pretrained-Model" class="headerlink" title="Semi-Supervised 3D Medical Segmentation from 2D Natural Images   Pretrained Model"></a>Semi-Supervised 3D Medical Segmentation from 2D Natural Images   Pretrained Model</h2><p><strong>Authors:Pak-Hei Yeung, Jayroop Ramesh, Pengfei Lyu, Ana Namburete, Jagath Rajapakse</strong></p>
<p>This paper explores the transfer of knowledge from general vision models pretrained on 2D natural images to improve 3D medical image segmentation. We focus on the semi-supervised setting, where only a few labeled 3D medical images are available, along with a large set of unlabeled images. To tackle this, we propose a model-agnostic framework that progressively distills knowledge from a 2D pretrained model to a 3D segmentation model trained from scratch. Our approach, M&amp;N, involves iterative co-training of the two models using pseudo-masks generated by each other, along with our proposed learning rate guided sampling that adaptively adjusts the proportion of labeled and unlabeled data in each training batch to align with the modelsâ€™ prediction accuracy and stability, minimizing the adverse effect caused by inaccurate pseudo-masks. Extensive experiments on multiple publicly available datasets demonstrate that M&amp;N achieves state-of-the-art performance, outperforming thirteen existing semi-supervised segmentation approaches under all different settings. Importantly, ablation studies show that M&amp;N remains model-agnostic, allowing seamless integration with different architectures. This ensures its adaptability as more advanced models emerge. The code is available at <a target="_blank" rel="noopener" href="https://github.com/pakheiyeung/M-N">https://github.com/pakheiyeung/M-N</a>. </p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†ä»åœ¨2Dè‡ªç„¶å›¾åƒä¸Šé¢„è®­ç»ƒçš„é€šç”¨è§†è§‰æ¨¡å‹è¿ç§»çŸ¥è¯†ï¼Œä»¥æé«˜3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„æ•ˆæœã€‚æˆ‘ä»¬å…³æ³¨åŠç›‘ç£è®¾ç½®ï¼Œå…¶ä¸­åªæœ‰å°‘æ•°3DåŒ»å­¦å›¾åƒæœ‰æ ‡ç­¾ï¼Œä»¥åŠå¤§é‡æ— æ ‡ç­¾å›¾åƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¨¡å‹æ— å…³æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»2Dé¢„è®­ç»ƒæ¨¡å‹é€æ­¥è’¸é¦çŸ¥è¯†ï¼Œç”¨äºè®­ç»ƒä»æ— å¼€å§‹çš„3Dåˆ†å‰²æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•M&amp;Næ¶‰åŠä½¿ç”¨ç”±å½¼æ­¤ç”Ÿæˆçš„ä¼ªæ©è†œå¯¹ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œè¿­ä»£ååŒè®­ç»ƒï¼Œä»¥åŠæˆ‘ä»¬æå‡ºçš„å­¦ä¹ ç‡å¼•å¯¼é‡‡æ ·ï¼Œè¯¥é‡‡æ ·å¯è‡ªé€‚åº”åœ°è°ƒæ•´æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾æ•°æ®çš„æ¯”ä¾‹ï¼Œä»¥ç¬¦åˆæ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œä»è€Œæœ€å°åŒ–ç”±ä¸å‡†ç¡®çš„ä¼ªæ©è†œå¼•èµ·çš„ä¸åˆ©å½±å“ã€‚åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒM&amp;Nè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œåœ¨æ‰€æœ‰ä¸åŒè®¾ç½®ä¸‹è¶…è¿‡äº†åä¸‰ç§ç°æœ‰çš„åŠç›‘ç£åˆ†å‰²æ–¹æ³•ã€‚é‡è¦çš„æ˜¯ï¼Œæ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒM&amp;Nä»ç„¶æ˜¯æ¨¡å‹æ— å…³çš„ï¼Œå¯ä»¥ä¸ä¸åŒæ¶æ„æ— ç¼é›†æˆã€‚è¿™ç¡®ä¿äº†å…¶ä½œä¸ºæ›´å…ˆè¿›æ¨¡å‹å‡ºç°æ—¶çš„é€‚åº”æ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/pakheiyeung/M-N%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pakheiyeung/M-Nä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15167v1">PDF</a> Machine Learning in Medical Imaging (MLMI) 2025 Oral</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡ç ”ç©¶äº†åŸºäºè‡ªç„¶å›¾åƒé¢„è®­ç»ƒçš„é€šç”¨è§†è§‰æ¨¡å‹åœ¨æ”¹è¿›ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„åº”ç”¨ã€‚æ–‡ç« å…³æ³¨åŠç›‘ç£åœºæ™¯ï¼Œå³åªæœ‰å°‘é‡æ ‡è®°çš„ä¸‰ç»´åŒ»å­¦å›¾åƒå’Œå¤§é‡æœªæ ‡è®°çš„å›¾åƒã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„æ¡†æ¶M&amp;Nï¼Œå®ƒä»é¢„è®­ç»ƒçš„äºŒç»´æ¨¡å‹é€æ­¥æç‚¼çŸ¥è¯†å¹¶åº”ç”¨äºä»é›¶å¼€å§‹è®­ç»ƒçš„ä¸‰ç»´åˆ†å‰²æ¨¡å‹ã€‚é€šè¿‡ä¸¤ä¸ªæ¨¡å‹çš„è¿­ä»£ååŒè®­ç»ƒä»¥åŠä¼ªæ©ç çš„ç”Ÿæˆå’Œä½¿ç”¨ï¼Œç»“åˆæå‡ºçš„å­¦ä¹ ç‡å¼•å¯¼é‡‡æ ·æŠ€æœ¯ï¼Œè‡ªé€‚åº”è°ƒæ•´æ ‡è®°å’Œæœªæ ‡è®°æ•°æ®åœ¨è®­ç»ƒæ‰¹æ¬¡ä¸­çš„æ¯”ä¾‹ï¼Œä¸æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦å’Œç¨³å®šæ€§ç›¸åŒ¹é…ï¼Œå‡å°‘äº†ä¼ªæ©ç ä¸å‡†ç¡®å¸¦æ¥çš„è´Ÿé¢å½±å“ã€‚åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒM&amp;Nè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼Œåœ¨æ‰€æœ‰ä¸åŒè®¾ç½®ä¸‹å‡ä¼˜äºåä¸‰ç§ç°æœ‰çš„åŠç›‘ç£åˆ†å‰²æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒM&amp;Nå…·æœ‰æ¨¡å‹é€šç”¨æ€§ï¼Œå¯æ— ç¼é›†æˆåˆ°ä¸åŒçš„æ¶æ„ä¸­ï¼Œç¡®ä¿äº†å…¶éšç€æ›´å…ˆè¿›æ¨¡å‹çš„æ¶Œç°è€Œé€‚åº”çš„èƒ½åŠ›ã€‚è®ºæ–‡ä»£ç å¯åœ¨æŒ‡å®šç½‘å€ä¸‹è½½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨äºå°†é¢„è®­ç»ƒçš„é€šç”¨è§†è§‰æ¨¡å‹åº”ç”¨äºä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</li>
<li>æå‡ºäº†æ¨¡å‹é€šç”¨æ¡†æ¶M&amp;Nè¿›è¡ŒäºŒç»´è‡³ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²çŸ¥è¯†çš„è½¬ç§»ã€‚</li>
<li>M&amp;Né€šè¿‡è¿­ä»£ååŒè®­ç»ƒå’Œä¼ªæ©ç ç”Ÿæˆä¿ƒè¿›çŸ¥è¯†æç‚¼å’Œåº”ç”¨ã€‚</li>
<li>å­¦ä¹ ç‡å¼•å¯¼é‡‡æ ·æŠ€æœ¯ç”¨äºè°ƒæ•´è®­ç»ƒæ•°æ®æ¯”ä¾‹ï¼Œä»¥åŒ¹é…æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦å’Œç¨³å®šæ€§ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºç°æœ‰åŠç›‘ç£åˆ†å‰²æ–¹æ³•ã€‚</li>
<li>M&amp;Nå…·æœ‰æ¨¡å‹é€šç”¨æ€§ï¼Œå¯ä¸ä¸åŒæ¶æ„æ— ç¼é›†æˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15167">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4708c76f788f0b580cc8cabcf9c07b4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031325&auth_key=1760031325-0-0-18e28457c0f603c65959a866239c6bdb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-22238d0cada137a5947eb69c7d3d2508~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031332&auth_key=1760031332-0-0-7bc133c05c44dd2dbc916bd81f7e3c92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="No-Modality-Left-Behind-Adapting-to-Missing-Modalities-via-Knowledge-Distillation-for-Brain-Tumor-Segmentation"><a href="#No-Modality-Left-Behind-Adapting-to-Missing-Modalities-via-Knowledge-Distillation-for-Brain-Tumor-Segmentation" class="headerlink" title="No Modality Left Behind: Adapting to Missing Modalities via Knowledge   Distillation for Brain Tumor Segmentation"></a>No Modality Left Behind: Adapting to Missing Modalities via Knowledge   Distillation for Brain Tumor Segmentation</h2><p><strong>Authors:Shenghao Zhu, Yifei Chen, Weihong Chen, Shuo Jiang, Guanyu Zhou, Yuanhan Wang, Feiwei Qin, Changmiao Wang, Qiyuan Tian</strong></p>
<p>Accurate brain tumor segmentation is essential for preoperative evaluation and personalized treatment. Multi-modal MRI is widely used due to its ability to capture complementary tumor features across different sequences. However, in clinical practice, missing modalities are common, limiting the robustness and generalizability of existing deep learning methods that rely on complete inputs, especially under non-dominant modality combinations. To address this, we propose AdaMM, a multi-modal brain tumor segmentation framework tailored for missing-modality scenarios, centered on knowledge distillation and composed of three synergistic modules. The Graph-guided Adaptive Refinement Module explicitly models semantic associations between generalizable and modality-specific features, enhancing adaptability to modality absence. The Bi-Bottleneck Distillation Module transfers structural and textural knowledge from teacher to student models via global style matching and adversarial feature alignment. The Lesion-Presence-Guided Reliability Module predicts prior probabilities of lesion types through an auxiliary classification task, effectively suppressing false positives under incomplete inputs. Extensive experiments on the BraTS 2018 and 2024 datasets demonstrate that AdaMM consistently outperforms existing methods, exhibiting superior segmentation accuracy and robustness, particularly in single-modality and weak-modality configurations. In addition, we conduct a systematic evaluation of six categories of missing-modality strategies, confirming the superiority of knowledge distillation and offering practical guidance for method selection and future research. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/Quanato607/AdaMM">https://github.com/Quanato607/AdaMM</a>. </p>
<blockquote>
<p>ç²¾ç¡®çš„è„‘è‚¿ç˜¤åˆ†å‰²å¯¹äºæœ¯å‰è¯„ä¼°å’Œä¸ªæ€§åŒ–æ²»ç–—è‡³å…³é‡è¦ã€‚å¤šæ¨¡æ€MRIç”±äºå…¶èƒ½å¤Ÿåœ¨ä¸åŒåºåˆ—ä¸­æ•è·äº’è¡¥çš„è‚¿ç˜¤ç‰¹å¾è€Œå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œåœ¨ä¸´åºŠå®è·µä¸­ï¼Œç¼ºå¤±æ¨¡æ€çš„æƒ…å†µå¾ˆå¸¸è§ï¼Œè¿™é™åˆ¶äº†ä¾èµ–å®Œæ•´è¾“å…¥çš„ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•çš„ç¨³å¥æ€§å’Œé€šç”¨æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨éä¸»å¯¼æ¨¡æ€ç»„åˆä¸‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†AdaMMï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ç¼ºå¤±æ¨¡æ€åœºæ™¯çš„å¤šæ¨¡æ€è„‘è‚¿ç˜¤åˆ†å‰²æ¡†æ¶ï¼Œä»¥çŸ¥è¯†è’¸é¦ä¸ºä¸­å¿ƒï¼Œç”±ä¸‰ä¸ªååŒæ¨¡å—ç»„æˆã€‚å›¾å¼•å¯¼è‡ªé€‚åº”ç»†åŒ–æ¨¡å—æ˜¾å¼å»ºæ¨¡é€šç”¨ç‰¹å¾å’Œæ¨¡æ€ç‰¹å®šç‰¹å¾ä¹‹é—´çš„è¯­ä¹‰å…³è”ï¼Œå¢å¼ºäº†é€‚åº”æ¨¡æ€ç¼ºå¤±çš„èƒ½åŠ›ã€‚åŒç“¶é¢ˆè’¸é¦æ¨¡å—é€šè¿‡å…¨å±€é£æ ¼åŒ¹é…å’Œå¯¹æŠ—æ€§ç‰¹å¾å¯¹é½ï¼Œå°†æ•™å¸ˆå’Œå­¦ç”Ÿçš„æ¨¡å‹ä¹‹é—´çš„ç»“æ„å’Œçº¹ç†çŸ¥è¯†è¿›è¡Œäº†ä¼ é€’ã€‚ç—…ç¶å­˜åœ¨å¼•å¯¼å¯é æ€§æ¨¡å—é€šè¿‡è¾…åŠ©åˆ†ç±»ä»»åŠ¡é¢„æµ‹ç—…ç¶ç±»å‹çš„å…ˆéªŒæ¦‚ç‡ï¼Œæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†ä¸å®Œå…¨è¾“å…¥ä¸‹çš„è¯¯æŠ¥ã€‚åœ¨BraTS 2018å’Œ2024æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAdaMMå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å•æ¨¡æ€å’Œå¼±æ¨¡æ€é…ç½®ä¸‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹å…­ç±»ç¼ºå¤±æ¨¡æ€ç­–ç•¥è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œè¯å®äº†çŸ¥è¯†è’¸é¦çš„ä¼˜è¶Šæ€§ï¼Œå¹¶ä¸ºæ–¹æ³•é€‰æ‹©å’Œæœªæ¥ç ”ç©¶æä¾›äº†å®é™…æŒ‡å¯¼ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Quanato607/AdaMM%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Quanato607/AdaMMä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15017v1">PDF</a> 38 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§AdaMMçš„å¤šæ¨¡æ€è„‘è‚¿ç˜¤åˆ†å‰²æ¡†æ¶ï¼Œé€‚ç”¨äºç¼ºå¤±æ¨¡æ€åœºæ™¯ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªååŒæ¨¡å—ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å¢å¼ºå¯¹ç¼ºå¤±æ¨¡æ€çš„é€‚åº”æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaMMåœ¨BraTS 2018å’Œ2024æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šçš„åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å•æ¨¡æ€å’Œå¼±æ¨¡æ€é…ç½®ä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AdaMMæ˜¯ä¸€ä¸ªé’ˆå¯¹ç¼ºå¤±æ¨¡æ€åœºæ™¯çš„å¤šæ¨¡æ€è„‘è‚¿ç˜¤åˆ†å‰²æ¡†æ¶ã€‚</li>
<li>æ¡†æ¶åŒ…å«ä¸‰ä¸ªååŒæ¨¡å—ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å¢å¼ºå¯¹ç¼ºå¤±æ¨¡æ€çš„é€‚åº”æ€§ã€‚</li>
<li>AdaMMåœ¨BraTS 2018å’Œ2024æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>åœ¨å•æ¨¡æ€å’Œå¼±æ¨¡æ€é…ç½®ä¸‹ï¼ŒAdaMMçš„åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§å°¤å…¶çªå‡ºã€‚</li>
<li>ç³»ç»Ÿè¯„ä»·äº†å…­ç§ç¼ºå¤±æ¨¡æ€ç­–ç•¥ï¼Œç¡®è®¤çŸ¥è¯†è’¸é¦çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>AdaMMæºä»£ç å·²å…¬å¼€ï¼Œå¯ä¾›ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15017">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-305bb56c15aae926bb206bc5437d48c1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031339&auth_key=1760031339-0-0-8c6dcdfbd2c1c6271e904bbe7eaf1ce5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d35d74c4ebc033820c07c0406a1889e9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031346&auth_key=1760031346-0-0-23a29f761d056ae7a25db76500583eba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EchoVLM-Dynamic-Mixture-of-Experts-Vision-Language-Model-for-Universal-Ultrasound-Intelligence"><a href="#EchoVLM-Dynamic-Mixture-of-Experts-Vision-Language-Model-for-Universal-Ultrasound-Intelligence" class="headerlink" title="EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal   Ultrasound Intelligence"></a>EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal   Ultrasound Intelligence</h2><p><strong>Authors:Chaoyin She, Ruifang Lu, Lida Chen, Wei Wang, Qinghua Huang</strong></p>
<p>Ultrasound imaging has become the preferred imaging modality for early cancer screening due to its advantages of non-ionizing radiation, low cost, and real-time imaging capabilities. However, conventional ultrasound diagnosis heavily relies on physician expertise, presenting challenges of high subjectivity and low diagnostic efficiency. Vision-language models (VLMs) offer promising solutions for this issue, but existing general-purpose models demonstrate limited knowledge in ultrasound medical tasks, with poor generalization in multi-organ lesion recognition and low efficiency across multi-task diagnostics. To address these limitations, we propose EchoVLM, a vision-language model specifically designed for ultrasound medical imaging. The model employs a Mixture of Experts (MoE) architecture trained on data spanning seven anatomical regions. This design enables the model to perform multiple tasks, including ultrasound report generation, diagnosis and visual question-answering (VQA). The experimental results demonstrated that EchoVLM achieved significant improvements of 10.15 and 4.77 points in BLEU-1 scores and ROUGE-1 scores respectively compared to Qwen2-VL on the ultrasound report generation task. These findings suggest that EchoVLM has substantial potential to enhance diagnostic accuracy in ultrasound imaging, thereby providing a viable technical solution for future clinical applications. Source code and model weights are available at <a target="_blank" rel="noopener" href="https://github.com/Asunatan/EchoVLM">https://github.com/Asunatan/EchoVLM</a>. </p>
<blockquote>
<p>è¶…å£°æˆåƒå› å…¶éç”µç¦»è¾å°„ã€æˆæœ¬ä½ã€å®æ—¶æˆåƒèƒ½åŠ›å¼ºçš„ä¼˜åŠ¿ï¼Œå·²æˆä¸ºæ—©æœŸç™Œç—‡ç­›æŸ¥çš„é¦–é€‰æˆåƒæ–¹å¼ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„è¶…å£°è¯Šæ–­é«˜åº¦ä¾èµ–åŒ»ç”Ÿçš„ä¸“ä¸šçŸ¥è¯†ï¼Œå­˜åœ¨ä¸»è§‚æ€§é«˜ã€è¯Šæ–­æ•ˆç‡ä½çš„æŒ‘æˆ˜ã€‚è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„é€šç”¨æ¨¡å‹åœ¨è¶…å£°åŒ»å­¦ä»»åŠ¡ä¸­çš„çŸ¥è¯†æœ‰é™ï¼Œåœ¨å¤šå™¨å®˜ç—…å˜è¯†åˆ«ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œå¤šä»»åŠ¡è¯Šæ–­çš„æ•ˆç‡ä¹Ÿè¾ƒä½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸“ä¸ºè¶…å£°åŒ»å­¦æˆåƒè®¾è®¡çš„è§†è§‰è¯­è¨€æ¨¡å‹EchoVLMã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„ï¼Œåœ¨æ¶µç›–ä¸ƒä¸ªè§£å‰–åŒºåŸŸçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¿™ç§è®¾è®¡ä½¿æ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œå¤šé¡¹ä»»åŠ¡ï¼ŒåŒ…æ‹¬ç”Ÿæˆè¶…å£°æŠ¥å‘Šã€è¯Šæ–­å’Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸Qwen2-VLç›¸æ¯”ï¼ŒEchoVLMåœ¨è¶…å£°æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸Šçš„BLEU-1å¾—åˆ†å’ŒROUGE-1å¾—åˆ†åˆ†åˆ«æé«˜äº†10.15å’Œ4.77åˆ†ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒEchoVLMåœ¨è¶…å£°æˆåƒè¯Šæ–­å‡†ç¡®æ€§æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œä¸ºæœªæ¥ä¸´åºŠåº”ç”¨æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚æºä»£ç å’Œæ¨¡å‹æƒé‡å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Asunatan/EchoVLM">https://github.com/Asunatan/EchoVLM</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14977v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¶…å£°æˆåƒå› å…·æœ‰éç”µç¦»è¾å°„ã€æˆæœ¬ä½ã€å®æ—¶æˆåƒç­‰ä¼˜ç‚¹ï¼Œå·²æˆä¸ºæ—©æœŸç™Œç—‡ç­›æŸ¥çš„é¦–é€‰å½±åƒæŠ€æœ¯ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿè¶…å£°è¯Šæ–­é«˜åº¦ä¾èµ–åŒ»å¸ˆç»éªŒï¼Œå­˜åœ¨ä¸»è§‚æ€§é«˜ã€è¯Šæ–­æ•ˆç‡ä½çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹è¶…å£°åŒ»å­¦å½±åƒçš„ç‰¹å®šè§†è§‰è¯­è¨€æ¨¡å‹EchoVLMï¼Œé‡‡ç”¨æ··åˆä¸“å®¶æ¶æ„ï¼Œåœ¨ä¸ƒä¸ªè§£å‰–åŒºåŸŸçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹å¯å®Œæˆè¶…å£°æŠ¥å‘Šç”Ÿæˆã€è¯Šæ–­åŠè§†è§‰é—®ç­”ç­‰å¤šé¡¹ä»»åŠ¡ï¼Œå¹¶åœ¨è¶…å£°æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸Šè¾ƒQwen2-VLæ¨¡å‹æ˜¾è‘—æé«˜BLEU-1å’ŒROUGE-1åˆ†æ•°ã€‚è¿™æ˜¾ç¤ºäº†EchoVLMåœ¨è¶…å£°å½±åƒè¯Šæ–­ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥ä¸´åºŠåº”ç”¨æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å£°æˆåƒæˆä¸ºæ—©æœŸç™Œç—‡ç­›æŸ¥çš„é¦–é€‰æ¨¡æ€ï¼Œä½†ä¼ ç»Ÿè¯Šæ–­å­˜åœ¨ä¸»è§‚æ€§é«˜ã€æ•ˆç‡ä½çš„é—®é¢˜ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†æ½œåŠ›ã€‚</li>
<li>ç°æœ‰é€šç”¨VLMåœ¨è¶…å£°åŒ»ç–—ä»»åŠ¡ä¸­çŸ¥è¯†æœ‰é™ï¼Œå¤šå™¨å®˜ç—…å˜è¯†åˆ«æ³›åŒ–èƒ½åŠ›ä½ã€‚</li>
<li>EchoVLMæ¨¡å‹ä¸“ä¸ºè¶…å£°åŒ»å­¦å½±åƒè®¾è®¡ï¼Œé‡‡ç”¨æ··åˆä¸“å®¶æ¶æ„ï¼Œå¯å®Œæˆå¤šé¡¹ä»»åŠ¡ã€‚</li>
<li>EchoVLMåœ¨è¶…å£°æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸Šè¾ƒQwen2-VLæ¨¡å‹æœ‰æ˜¾è‘—æ”¹å–„ã€‚</li>
<li>EchoVLMæœ‰æœ›æé«˜è¶…å£°å½±åƒè¯Šæ–­çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a49118ed4e0451990d715b27d206ec2b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031354&auth_key=1760031354-0-0-8b03bab673b6c12fc317e30d9dc7cc4d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d93c1e080c341faed7c26cbaf4278551~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031361&auth_key=1760031361-0-0-7e9765a792278ef7fe70e15f7fa1055a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d639d95b0058b12f6506cf64c8c4548e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031368&auth_key=1760031368-0-0-b9f5ff05c083caf494b58730a9ec144e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5c82f5d773e021934247547cef3f9610~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031375&auth_key=1760031375-0-0-69ede7493e4dd071ae45c37cfec42224&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5958dc6445c786bf45cbf3e9c57ca16a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031382&auth_key=1760031382-0-0-f725fd372b2b8abcf9123663a383a0cf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ProtoMedX-Towards-Explainable-Multi-Modal-Prototype-Learning-for-Bone-Health-Classification"><a href="#ProtoMedX-Towards-Explainable-Multi-Modal-Prototype-Learning-for-Bone-Health-Classification" class="headerlink" title="ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone   Health Classification"></a>ProtoMedX: Towards Explainable Multi-Modal Prototype Learning for Bone   Health Classification</h2><p><strong>Authors:Alvaro Lopez Pellicer, Andre Mariucci, Plamen Angelov, Marwan Bukhari, Jemma G. Kerns</strong></p>
<p>Bone health studies are crucial in medical practice for the early detection and treatment of Osteopenia and Osteoporosis. Clinicians usually make a diagnosis based on densitometry (DEXA scans) and patient history. The applications of AI in this field are ongoing research. Most successful methods rely on deep learning models that use vision alone (DEXA&#x2F;X-ray imagery) and focus on prediction accuracy, while explainability is often disregarded and left to post hoc assessments of input contributions. We propose ProtoMedX, a multi-modal model that uses both DEXA scans of the lumbar spine and patient records. ProtoMedXâ€™s prototype-based architecture is explainable by design, which is crucial for medical applications, especially in the context of the upcoming EU AI Act, as it allows explicit analysis of model decisions, including incorrect ones. ProtoMedX demonstrates state-of-the-art performance in bone health classification while also providing explanations that can be visually understood by clinicians. Using a dataset of 4,160 real NHS patients, the proposed ProtoMedX achieves 87.58% accuracy in vision-only tasks and 89.8% in its multi-modal variant, both surpassing existing published methods. </p>
<blockquote>
<p>åœ¨åŒ»ç–—å®è·µä¸­ï¼Œéª¨éª¼å¥åº·ç ”ç©¶å¯¹äºéª¨é‡å‡å°‘å’Œéª¨è´¨ç–æ¾çš„æ—©æœŸæ£€æµ‹å’Œæ²»ç–—è‡³å…³é‡è¦ã€‚ä¸´åºŠåŒ»ç”Ÿé€šå¸¸æ ¹æ®éª¨å¯†åº¦æµ‹å®šï¼ˆDEXAæ‰«æï¼‰å’Œæ‚£è€…ç—…å²è¿›è¡Œè¯Šæ–­ã€‚äººå·¥æ™ºèƒ½åœ¨è¯¥é¢†åŸŸçš„åº”ç”¨æ­£åœ¨æŒç»­ç ”ç©¶ä¸­ã€‚å¤§å¤šæ•°æˆåŠŸçš„æ–¹æ³•ä¾èµ–äºä½¿ç”¨æ·±åº¦å­¦ä¹ çš„æ¨¡å‹ï¼Œä»…ä½¿ç”¨è§†è§‰ï¼ˆDEXA&#x2F;Xå°„çº¿å½±åƒï¼‰ï¼Œå¹¶ä¸“æ³¨äºé¢„æµ‹å‡†ç¡®æ€§ï¼Œè€Œå¯è§£é‡Šæ€§é€šå¸¸è¢«å¿½è§†å¹¶åœ¨äº‹åå¯¹è¾“å…¥è´¡çŒ®è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬æå‡ºäº†ProtoMedXï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨è…°æ¤DEXAæ‰«æå’Œæ‚£è€…è®°å½•çš„å¤šæ¨¡å¼æ¨¡å‹ã€‚ProtoMedXåŸºäºåŸå‹çš„è®¾è®¡æ˜¯å¯è§£é‡Šçš„ï¼Œè¿™åœ¨åŒ»ç–—åº”ç”¨ä¸­è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å³å°†åˆ°æ¥çš„æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆçš„èƒŒæ™¯ä¸‹ï¼Œå› ä¸ºå®ƒå…è®¸å¯¹æ¨¡å‹å†³ç­–è¿›è¡Œæ˜ç¡®åˆ†æï¼ŒåŒ…æ‹¬é”™è¯¯çš„å†³ç­–ã€‚ProtoMedXåœ¨éª¨éª¼å¥åº·åˆ†ç±»æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†ä¸´åºŠåŒ»ç”Ÿå¯ä»¥è§†è§‰ç†è§£çš„è§£é‡Šã€‚ä½¿ç”¨åŒ…å«4,160åçœŸå®NHSæ‚£è€…çš„æ•°æ®é›†ï¼Œæ‰€æå‡ºçš„ProtoMedXåœ¨ä»…è§†è§‰ä»»åŠ¡ä¸­è¾¾åˆ°87.58%çš„å‡†ç¡®ç‡ï¼Œå¤šæ¨¡å¼å˜ä½“è¾¾åˆ°89.8%ï¼Œå‡è¶…è¿‡äº†å·²å‘å¸ƒçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14830v1">PDF</a> Accepted ICCV 2025. Adaptation, Fairness, Explainability in AI   Medical Imaging (PHAROS-AFE-AIMI Workshop). 8 pages, 5 figures, 4 tables</p>
<p><strong>Summary</strong><br>    æå‡ºProtoMedXå¤šæ¨¡æ€æ¨¡å‹ï¼Œç»“åˆDEXAæ‰«æå’Œç—…äººè®°å½•ï¼Œç”¨äºéª¨éª¼å¥åº·è¯Šæ–­ã€‚è¯¥æ¨¡å‹å…·æœ‰åŸå‹åŸºç¡€æ¶æ„ï¼Œå¯è§£é‡Šè®¾è®¡ï¼Œèƒ½åˆ†ææ¨¡å‹å†³ç­–ï¼ŒåŒ…æ‹¬é”™è¯¯å†³ç­–ã€‚åœ¨éª¨éª¼å¥åº·åˆ†ç±»ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡é«˜ï¼Œä¸”è§£é‡Šå¯è§†ï¼Œä¾¿äºåŒ»ç”Ÿç†è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éª¨å¥åº·ç ”ç©¶å¯¹åŒ»å­¦å®è·µè‡³å…³é‡è¦ï¼Œæœ‰åŠ©äºæ—©æœŸæ£€æµ‹å’Œæ²»ç–—éª¨è´¨ç–æ¾ç­‰ç–¾ç—…ã€‚</li>
<li>ç›®å‰ä¸´åºŠé€šå¸¸é€šè¿‡éª¨å¯†åº¦æµ‹å®šï¼ˆDEXAæ‰«æï¼‰å’Œæ‚£è€…ç—…å²è¿›è¡Œè¯Šæ–­ã€‚</li>
<li>AIåœ¨è¯¥é¢†åŸŸçš„åº”ç”¨æ­£åœ¨è¿›è¡Œä¸­ï¼Œå¤§å¤šæ•°æˆåŠŸçš„æ–¹æ³•ä¾èµ–äºä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œè§†è§‰åˆ†æï¼ˆDEXA&#x2F;Xå°„çº¿å½±åƒï¼‰ï¼Œå¹¶ä¾§é‡äºé¢„æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨è§£é‡Šæ€§æ–¹é¢å¸¸è¢«å¿½è§†ï¼Œç•™ç»™åç»­è¯„ä¼°ã€‚</li>
<li>ProtoMedXæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¨¡å‹ï¼Œç»“åˆDEXAæ‰«æå’Œç—…äººè®°å½•ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>ProtoMedXçš„åŸå‹åŸºç¡€æ¶æ„è®¾è®¡å¯è§£é‡Šæ€§å¼ºï¼Œæœ‰åŠ©äºåˆ†ææ¨¡å‹å†³ç­–ï¼ŒåŒ…æ‹¬é”™è¯¯çš„å†³ç­–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14830">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-694479c322f36e6cbec7feb6aa81454d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031390&auth_key=1760031390-0-0-94a9fd39de788e79d91b6f6cfd1bdca3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d6760c2f8b0e2ce296f28264aa907cce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031397&auth_key=1760031397-0-0-f0edb1f6a5f9ba3f0b258a0899d7bc0f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4f1775342f30bef6107f77e19d11481~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031404&auth_key=1760031404-0-0-57664dd53f9434a0e8c2bfc0a8be1cd4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b40a21bee6693aa28fcd120acfe463f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031411&auth_key=1760031411-0-0-223b678c13bdc2cb56f0ceede24eeca6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-aab0a14c2ff2fd4a67c516253c7a239d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031417&auth_key=1760031417-0-0-4187cb4b8611e633fb67e9cc278da95b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Radiology-Report-Conditional-3D-CT-Generation-with-Multi-Encoder-Latent-diffusion-Model"><a href="#Radiology-Report-Conditional-3D-CT-Generation-with-Multi-Encoder-Latent-diffusion-Model" class="headerlink" title="Radiology Report Conditional 3D CT Generation with Multi Encoder Latent   diffusion Model"></a>Radiology Report Conditional 3D CT Generation with Multi Encoder Latent   diffusion Model</h2><p><strong>Authors:Sina Amirrajab, Zohaib Salahuddin, Sheng Kuang, Henry C. Woodruff, Philippe Lambin</strong></p>
<p>Text to image latent diffusion models have recently advanced medical image synthesis, but applications to 3D CT generation remain limited. Existing approaches rely on simplified prompts, neglecting the rich semantic detail in full radiology reports, which reduces text image alignment and clinical fidelity. We propose Report2CT, a radiology report conditional latent diffusion framework for synthesizing 3D chest CT volumes directly from free text radiology reports, incorporating both findings and impression sections using multiple text encoder. Report2CT integrates three pretrained medical text encoders (BiomedVLP CXR BERT, MedEmbed, and ClinicalBERT) to capture nuanced clinical context. Radiology reports and voxel spacing information condition a 3D latent diffusion model trained on 20000 CT volumes from the CT RATE dataset. Model performance was evaluated using Frechet Inception Distance (FID) for real synthetic distributional similarity and CLIP based metrics for semantic alignment, with additional qualitative and quantitative comparisons against GenerateCT model. Report2CT generated anatomically consistent CT volumes with excellent visual quality and text image alignment. Multi encoder conditioning improved CLIP scores, indicating stronger preservation of fine grained clinical details in the free text radiology reports. Classifier free guidance further enhanced alignment with only a minor trade off in FID. We ranked first in the VLM3D Challenge at MICCAI 2025 on Text Conditional CT Generation and achieved state of the art performance across all evaluation metrics. By leveraging complete radiology reports and multi encoder text conditioning, Report2CT advances 3D CT synthesis, producing clinically faithful and high quality synthetic data. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒæ½œåœ¨æ‰©æ•£æ¨¡å‹æœ€è¿‘æ¨åŠ¨äº†åŒ»å­¦å›¾åƒåˆæˆçš„å‘å±•ï¼Œä½†å…¶åœ¨3D CTç”Ÿæˆæ–¹é¢çš„åº”ç”¨ä»ç„¶æœ‰é™ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç®€åŒ–çš„æç¤ºï¼Œå¿½ç•¥äº†å®Œæ•´æ”¾å°„å­¦æŠ¥å‘Šä¸­çš„ä¸°å¯Œè¯­ä¹‰ç»†èŠ‚ï¼Œè¿™é™ä½äº†æ–‡æœ¬å›¾åƒå¯¹é½å’Œä¸´åºŠä¿çœŸåº¦ã€‚æˆ‘ä»¬æå‡ºäº†Report2CTï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ”¾å°„å­¦æŠ¥å‘Šçš„æ½œåœ¨æ‰©æ•£æ¡†æ¶ï¼Œå¯ç›´æ¥ä»è‡ªç”±æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šåˆæˆ3Dèƒ¸éƒ¨CTä½“ç§¯ï¼Œå¹¶ç»“åˆæ£€æŸ¥ç»“æœå’Œå°è±¡éƒ¨åˆ†ä½¿ç”¨å¤šä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚Report2CTé›†æˆäº†ä¸‰ä¸ªé¢„è®­ç»ƒçš„åŒ»å­¦æ–‡æœ¬ç¼–ç å™¨ï¼ˆBiomedVLP CXR BERTã€MedEmbedå’ŒClinicalBERTï¼‰æ¥æ•æ‰å¾®å¦™çš„ä¸´åºŠä¸Šä¸‹æ–‡ã€‚æ”¾å°„å­¦æŠ¥å‘Šå’Œä½“ç´ é—´è·ä¿¡æ¯å¯¹åœ¨CT RATEæ•°æ®é›†ä¸Šç»è¿‡è®­ç»ƒçš„2ä¸‡ä¸ªCTä½“ç§¯çš„3Dæ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œäº†æ¡ä»¶å¤„ç†ã€‚æ¨¡å‹æ€§èƒ½è¯„ä¼°é‡‡ç”¨Frechet Inception Distanceï¼ˆFIDï¼‰è¿›è¡ŒçœŸå®ä¸åˆæˆåˆ†å¸ƒç›¸ä¼¼æ€§è¯„ä¼°ï¼Œå¹¶ä½¿ç”¨åŸºäºCLIPçš„æŒ‡æ ‡è¿›è¡Œè¯­ä¹‰å¯¹é½è¯„ä¼°ï¼ŒåŒæ—¶ä¸GenerateCTæ¨¡å‹è¿›è¡Œå®šæ€§å’Œå®šé‡æ¯”è¾ƒã€‚Report2CTç”Ÿæˆçš„CTä½“ç§¯è§£å‰–ç»“æ„ä¸€è‡´ï¼Œè§†è§‰è´¨é‡ä¸Šä¹˜ï¼Œæ–‡æœ¬å›¾åƒå¯¹é½æ•ˆæœè‰¯å¥½ã€‚å¤šç¼–ç å™¨æ¡ä»¶æ”¹å–„äº†CLIPå¾—åˆ†ï¼Œè¡¨æ˜åœ¨è‡ªç”±æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šä¸­ç²¾ç»†çš„ä¸´åºŠç»†èŠ‚å¾—åˆ°äº†æ›´å¥½çš„ä¿ç•™ã€‚æ— åˆ†ç±»å™¨æŒ‡å¯¼è¿›ä¸€æ­¥å¢å¼ºäº†å¯¹é½æ•ˆæœï¼ŒåŒæ—¶FIDçš„ç‰ºç‰²è¾ƒå°ã€‚åœ¨MICCAI 2025å¹´çš„VLM3DæŒ‘æˆ˜ä¸­ï¼Œæˆ‘ä»¬åœ¨æ–‡æœ¬æ¡ä»¶CTç”Ÿæˆæ–¹é¢æ’åç¬¬ä¸€ï¼Œå¹¶åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é€šè¿‡åˆ©ç”¨å®Œæ•´çš„æ”¾å°„å­¦æŠ¥å‘Šå’Œå¤šç¼–ç å™¨æ–‡æœ¬æ¡ä»¶å¤„ç†ï¼ŒReport2CTæ¨åŠ¨äº†3D CTçš„åˆæˆï¼Œç”Ÿæˆäº†ä¸´åºŠçœŸå®ä¸”é«˜è´¨é‡çš„ç»¼åˆæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14780v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Report2CTæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆæˆé¢†åŸŸçš„åº”ç”¨ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆå®Œæ•´çš„æ”¾å°„å­¦æŠ¥å‘Šå’Œå¤šç¼–ç å™¨æ–‡æœ¬æ¡ä»¶æŠ€æœ¯ï¼Œå®ç°äº†ä»æ–‡æœ¬ç›´æ¥ç”Ÿæˆ3Dèƒ¸éƒ¨CTä½“ç§¯çš„å…ˆè¿›æŠ€æœ¯ã€‚è¯¥æ¨¡å‹åœ¨CT RATEæ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶é€šè¿‡å¤šç§è¯„ä¼°æŒ‡æ ‡è¯æ˜äº†å…¶ä¼˜ç§€çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬Frechet Inception Distanceï¼ˆFIDï¼‰å’ŒCLIPæŒ‡æ ‡ã€‚Report2CTåœ¨æ–‡æœ¬å›¾åƒå¯¹é½å’Œè§£å‰–ç»“æ„ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨MICCAI 2025çš„VLM3DæŒ‘æˆ˜ä¸­è·å¾—äº†ç¬¬ä¸€åã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Report2CTæ˜¯ä¸€ä¸ªåŸºäºæ”¾å°„å­¦æŠ¥å‘Šæ¡ä»¶çš„æ½œåœ¨æ‰©æ•£æ¡†æ¶ï¼Œå¯ç›´æ¥ä»æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆ3Dèƒ¸éƒ¨CTä½“ç§¯ã€‚</li>
<li>è¯¥æ¨¡å‹ç»“åˆäº†å‘ç°ä¸å°è±¡ä¸¤éƒ¨åˆ†ï¼Œä½¿ç”¨å¤šä¸ªæ–‡æœ¬ç¼–ç å™¨æ¥æ•æ‰å¾®å¦™çš„ä¸´åºŠèƒŒæ™¯ã€‚</li>
<li>Report2CTä½¿ç”¨äº†ä¸‰ç§é¢„è®­ç»ƒçš„åŒ»ç–—æ–‡æœ¬ç¼–ç å™¨ï¼ŒåŒ…æ‹¬BiomedVLP CXR BERTã€MedEmbedå’ŒClinicalBERTã€‚</li>
<li>æ¨¡å‹åœ¨CT RATEæ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼ŒåŒ…å«20000ä¸ªCTä½“ç§¯ã€‚</li>
<li>é€šè¿‡Frechet Inception Distanceï¼ˆFIDï¼‰å’ŒCLIPæŒ‡æ ‡å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>Report2CTç”Ÿæˆçš„CTä½“ç§¯åœ¨è§£å‰–ç»“æ„ä¸€è‡´æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ–‡æœ¬å›¾åƒå¯¹é½è‰¯å¥½ã€‚</li>
<li>å¤šç¼–ç å™¨æ¡ä»¶æŠ€æœ¯æ”¹è¿›äº†CLIPåˆ†æ•°ï¼Œè¡¨æ˜åœ¨è‡ªç”±æ–‡æœ¬æ”¾å°„å­¦æŠ¥å‘Šä¸­ä¿ç•™äº†æ›´ç²¾ç»†çš„ä¸´åºŠç»†èŠ‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14780">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8223982d0023638a0955b9026ee52d63~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031424&auth_key=1760031424-0-0-8a0077024dde133216371e9aaaebea3c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-71e1aa93fa0106dfdb55be1ecb1dfb32~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031431&auth_key=1760031431-0-0-d735e5067e3720f355fbced8e5d5d656&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-841e74619116d8671e9c18585437ad38~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031438&auth_key=1760031438-0-0-417de34a2b225a13aed6f04a91056b1d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Noninvasive-and-Dispersive-Framework-for-Estimating-Nonuniform-Conductivity-of-Brain-Tumor-in-Patient-Specific-Head-Models"><a href="#A-Noninvasive-and-Dispersive-Framework-for-Estimating-Nonuniform-Conductivity-of-Brain-Tumor-in-Patient-Specific-Head-Models" class="headerlink" title="A Noninvasive and Dispersive Framework for Estimating Nonuniform   Conductivity of Brain Tumor in Patient-Specific Head Models"></a>A Noninvasive and Dispersive Framework for Estimating Nonuniform   Conductivity of Brain Tumor in Patient-Specific Head Models</h2><p><strong>Authors:Yoshiki Kubota, Yosuke Nagata, Manabu Tamura, Akimasa Hirata</strong></p>
<p>We propose a noninvasive and dispersive framework for estimating the spatially nonuniform conductivity of brain tumors using MR images. The method consists of two components: (i) voxel-wise assignment of tumor conductivity based on reference values fitted to the Cole-Cole model using empirical data from the literature and (ii) fine-tuning of a deep learning model pretrained on healthy participants. A total of 67 cases, comprising both healthy participants and tumor patients and including 9,806 paired T1- and T2-weighted MR images, were used for training and evaluation. The proposed method successfully estimated patient-specific conductivity maps, exhibiting smooth spatial variations that reflected tissue characteristics, such as edema, necrosis, and rim-associated intensity gradients observed in T1- and T2-weighted MR images. At 10 kHz, case-wise mean conductivity values varied across patients, ranging from 0.132 to 0.512 S&#x2F;m in the rim (defined as the region within 2 mm of the tumor boundary), from 0.132 to 0.608 S&#x2F;m in the core (the area inside the rim), and from 0.141 to 0.542 S&#x2F;m in the entire tumor. Electromagnetic simulations for transcranial magnetic stimulation in individualized head models showed substantial differences in intratumoral field distributions between uniform assignments and the proposed nonuniform maps. Furthermore, this framework demonstrated voxel-wise dispersive mapping at 10 kHz, 1 MHz, and 100 MHz. This framework supports accurate whole-brain conductivity estimation by incorporating both individual anatomical structures and tumor-specific characteristics. Collectively, these results advance patient-specific EM modeling for tumor-bearing brains and lay the groundwork for subsequent microwave-band validation. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨MRå›¾åƒä¼°è®¡è„‘è‚¿ç˜¤ç©ºé—´éå‡åŒ€å¯¼ç”µæ€§çš„æ— åˆ›åˆ†æ•£æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šï¼ˆiï¼‰åŸºäºæ–‡çŒ®ä¸­çš„ç»éªŒæ•°æ®å¯¹Cole-Coleæ¨¡å‹è¿›è¡Œæ‹Ÿåˆï¼Œä¸ºæ¯ä¸ªä½“ç´ åˆ†é…è‚¿ç˜¤å¯¼ç”µç‡ï¼›ï¼ˆiiï¼‰å¯¹åœ¨å¥åº·å‚ä¸è€…ä¸Šé¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å…±ä½¿ç”¨67ä¸ªç—…ä¾‹ï¼ŒåŒ…æ‹¬å¥åº·å‚ä¸è€…å’Œè‚¿ç˜¤æ‚£è€…çš„9806å¯¹T1å’ŒT2åŠ æƒMRå›¾åƒï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚æ‰€æå‡ºçš„æ–¹æ³•æˆåŠŸåœ°ä¼°è®¡äº†æ‚£è€…ç‰¹å®šçš„å¯¼ç”µç‡å›¾ï¼Œæ˜¾ç¤ºå‡ºå¹³æ»‘çš„ç©ºé—´å˜åŒ–ï¼Œåæ˜ äº†ç»„ç»‡ç‰¹å¾ï¼Œå¦‚æ°´è‚¿ã€åæ­»å’Œåœ¨T1å’ŒT2åŠ æƒMRå›¾åƒä¸­è§‚å¯Ÿåˆ°çš„è¾¹ç¼˜ç›¸å…³å¼ºåº¦æ¢¯åº¦ã€‚åœ¨10 kHzé¢‘ç‡ä¸‹ï¼Œä¸åŒæ‚£è€…ä¹‹é—´çš„å¹³å‡å¯¼ç”µç‡å€¼æœ‰æ‰€å˜åŒ–ï¼Œè¾¹ç¼˜åŒºåŸŸçš„å¯¼ç”µç‡åœ¨0.132è‡³0.512 S&#x2F;mä¹‹é—´ï¼ˆå®šä¹‰ä¸ºè‚¿ç˜¤è¾¹ç•Œ2æ¯«ç±³å†…çš„åŒºåŸŸï¼‰ï¼Œæ ¸å¿ƒåŒºåŸŸçš„å¯¼ç”µç‡åœ¨0.132è‡³0.608 S&#x2F;mä¹‹é—´ï¼ˆå®šä¹‰ä¸ºè¾¹ç¼˜å†…çš„åŒºåŸŸï¼‰ï¼Œæ•´ä¸ªè‚¿ç˜¤çš„å¯¼ç”µç‡åœ¨0.141è‡³0.542 S&#x2F;mä¹‹é—´ã€‚é’ˆå¯¹ä¸ªæ€§åŒ–å¤´éƒ¨æ¨¡å‹çš„é¢…å†…ç£åˆºæ¿€ç”µç£æ¨¡æ‹Ÿæ˜¾ç¤ºï¼Œå‡åŒ€åˆ†é…ä¸éå‡åŒ€å›¾ä¹‹é—´çš„è‚¿ç˜¤å†…åœºåˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨10 kHzã€1 MHzå’Œ100 MHzä¸‹å®ç°äº†ä½“ç´ åˆ†æ•£æ˜ å°„ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆä¸ªä½“è§£å‰–ç»“æ„å’Œè‚¿ç˜¤ç‰¹å¾ï¼Œæ”¯æŒå‡†ç¡®çš„å…¨è„‘å¯¼ç”µç‡ä¼°è®¡ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›ç»“æœæ¨åŠ¨äº†æ‚£è€…ç‰¹å®šçš„è‚¿ç˜¤æ‰¿è½½è„‘ç”µç£å»ºæ¨¡ï¼Œå¹¶ä¸ºéšåçš„å¾®æ³¢é¢‘æ®µéªŒè¯å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14660v1">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨MRå›¾åƒä¼°è®¡è„‘è‚¿ç˜¤ç©ºé—´éå‡åŒ€ç”µå¯¼ç‡çš„éä¾µå…¥æ€§åˆ†æ•£æ¡†æ¶ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸¤éƒ¨åˆ†ï¼šåŸºäºæ–‡çŒ®ç»éªŒæ•°æ®å¯¹Cole-Coleæ¨¡å‹è¿›è¡Œè‚¿ç˜¤ç”µå¯¼ç‡ä½“ç´ çº§èµ‹å€¼ï¼Œä»¥åŠå¯¹å¥åº·å‚ä¸è€…é¢„è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¾®è°ƒã€‚è¯¥ç ”ç©¶ä½¿ç”¨åŒ…å«å¥åº·å‚ä¸è€…å’Œè‚¿ç˜¤æ‚£è€…çš„67ä¾‹ç—…ä¾‹åŠ9806å¯¹T1å’ŒT2åŠ æƒMRå›¾åƒè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚è¯¥æ–¹æ³•æˆåŠŸä¼°è®¡äº†æ‚£è€…ç‰¹å®šçš„ç”µå¯¼ç‡å›¾ï¼Œåæ˜ äº†å¦‚æ°´è‚¿ã€åæ­»å’Œè¾¹ç¼˜ç›¸å…³å¼ºåº¦æ¢¯åº¦ç­‰ç»„ç»‡ç‰¹å¾ã€‚æ­¤æ¡†æ¶æ”¯æŒç»“åˆä¸ªä½“è§£å‰–ç»“æ„å’Œè‚¿ç˜¤ç‰¹å¾è¿›è¡Œå…¨è„‘ç”µå¯¼ç‡å‡†ç¡®ä¼°è®¡ï¼Œä¸ºè‚¿ç˜¤æ€§è„‘éƒ¨çš„æ‚£è€…ç‰¹å®šç”µç£å»ºæ¨¡å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ä¸ªåŸºäºMRå›¾åƒçš„éä¾µå…¥æ€§åˆ†æ•£æ¡†æ¶ï¼Œç”¨äºä¼°è®¡è„‘è‚¿ç˜¤çš„ç©ºé—´éå‡åŒ€ç”µå¯¼ç‡ã€‚</li>
<li>æ–¹æ³•åŒ…æ‹¬ä½“ç´ çº§çš„è‚¿ç˜¤ç”µå¯¼ç‡èµ‹å€¼å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¾®è°ƒã€‚</li>
<li>ä½¿ç”¨åŒ…å«å¥åº·å‚ä¸è€…å’Œè‚¿ç˜¤æ‚£è€…çš„ç—…ä¾‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
<li>æˆåŠŸä¼°è®¡äº†æ‚£è€…ç‰¹å®šçš„ç”µå¯¼ç‡å›¾ï¼Œåæ˜ ç»„ç»‡ç‰¹å¾å¦‚æ°´è‚¿ã€åæ­»ç­‰ã€‚</li>
<li>è¯¥æ¡†æ¶æ”¯æŒå…¨è„‘ç”µå¯¼ç‡çš„å‡†ç¡®ä¼°è®¡ï¼Œç»“åˆä¸ªä½“è§£å‰–ç»“æ„å’Œè‚¿ç˜¤ç‰¹å¾ã€‚</li>
<li>ç”µç£æ¨¡æ‹Ÿæ˜¾ç¤ºï¼Œä¸å‡åŒ€åˆ†é…ç›¸æ¯”ï¼Œéå‡åŒ€åœ°å›¾åœ¨è„‘å†…è‚¿ç˜¤åœºå†…éƒ¨åˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14660">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-54af1f104bd799b2baae42e0892eb816~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031446&auth_key=1760031446-0-0-67f90f2578a02473464d1baf04ab5dc5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a88e482e60995cce9bb7097c9e1c8d05~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031453&auth_key=1760031453-0-0-0659a1a5d9ca80d45aecbced3460950e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2d02613d460ced796caec571f9aed1c2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031460&auth_key=1760031460-0-0-1eb4e4a3fea0ae7d9c6965878706360b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0373f9f4a61eddd4353ae1f4379d6480~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031467&auth_key=1760031467-0-0-9c637ab4f592722b16b54e1cbb5b9be5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e7f2e99d872ef95324a8c78d1d74e8b1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031473&auth_key=1760031473-0-0-27d214b9bac1a778fc6ce18f5651a429&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-24bb3b8b6c5ff1a459c3296f0734635a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031480&auth_key=1760031480-0-0-2c6b756c3fff3b9e158aeb19c5b389da&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-82d9a374bbde401260a2b391bd8ff140~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031487&auth_key=1760031487-0-0-5367f9efd44db723abdac4ac6d188832&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a416017d716e5b5d70d734b22849a115~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031493&auth_key=1760031493-0-0-a618aa8f8c1d8633c5a0d51631e6475a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="HybridMamba-A-Dual-domain-Mamba-for-3D-Medical-Image-Segmentation"><a href="#HybridMamba-A-Dual-domain-Mamba-for-3D-Medical-Image-Segmentation" class="headerlink" title="HybridMamba: A Dual-domain Mamba for 3D Medical Image Segmentation"></a>HybridMamba: A Dual-domain Mamba for 3D Medical Image Segmentation</h2><p><strong>Authors:Weitong Wu, Zhaohu Xing, Jing Gong, Qin Peng, Lei Zhu</strong></p>
<p>In the domain of 3D biomedical image segmentation, Mamba exhibits the superior performance for it addresses the limitations in modeling long-range dependencies inherent to CNNs and mitigates the abundant computational overhead associated with Transformer-based frameworks when processing high-resolution medical volumes. However, attaching undue importance to global context modeling may inadvertently compromise critical local structural information, thus leading to boundary ambiguity and regional distortion in segmentation outputs. Therefore, we propose the HybridMamba, an architecture employing dual complementary mechanisms: 1) a feature scanning strategy that progressively integrates representations both axial-traversal and local-adaptive pathways to harmonize the relationship between local and global representations, and 2) a gated module combining spatial-frequency analysis for comprehensive contextual modeling. Besides, we collect a multi-center CT dataset related to lung cancer. Experiments on MRI and CT datasets demonstrate that HybridMamba significantly outperforms the state-of-the-art methods in 3D medical image segmentation. </p>
<blockquote>
<p>åœ¨3Dç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸï¼ŒMambaå±•ç°äº†å“è¶Šæ€§èƒ½ï¼Œå› ä¸ºå®ƒè§£å†³äº†CNNæ¨¡å‹ä¸­é•¿è·ç¦»ä¾èµ–å»ºæ¨¡çš„å±€é™æ€§ï¼Œå¹¶å‡è½»äº†åŸºäºTransformerçš„æ¡†æ¶åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡åŒ»å­¦ä½“ç§¯å›¾åƒæ—¶çš„å¤§é‡è®¡ç®—å¼€é”€ã€‚ç„¶è€Œï¼Œè¿‡åˆ†å¼ºè°ƒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡å¯èƒ½ä¼šæ— æ„ä¸­æŸå®³å…³é”®å±€éƒ¨ç»“æ„ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´åˆ†å‰²ç»“æœå‡ºç°è¾¹ç•Œæ¨¡ç³Šå’ŒåŒºåŸŸå¤±çœŸã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†HybridMambaæ¶æ„ï¼Œå®ƒé‡‡ç”¨åŒé‡äº’è¡¥æœºåˆ¶ï¼š1ï¼‰ç‰¹å¾æ‰«æç­–ç•¥ï¼Œé€šè¿‡è½´å‘éå†å’Œå±€éƒ¨è‡ªé€‚åº”è·¯å¾„é€æ­¥é›†æˆè¡¨ç¤ºï¼Œä»¥åè°ƒå±€éƒ¨å’Œå…¨å±€è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ï¼›2ï¼‰ç»“åˆç©ºé—´é¢‘ç‡åˆ†æçš„é—¨æ§æ¨¡å—ï¼Œç”¨äºå…¨é¢çš„ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªå¤šä¸­å¿ƒè‚ºç™ŒCTæ•°æ®é›†ã€‚åœ¨MRIå’ŒCTæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHybridMambaåœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14609v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Mambaåœ¨3Dç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè§£å†³äº†CNNå»ºæ¨¡ä¸­çš„è¿œç¨‹ä¾èµ–é—®é¢˜å¹¶å‡è½»äº†å¤„ç†é«˜åˆ†è¾¨ç‡åŒ»ç–—å·ç§¯æ—¶çš„è®¡ç®—å¼€é”€ã€‚ç„¶è€Œï¼Œè¿‡åˆ†å¼ºè°ƒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡å¯èƒ½ä¼šæ— æ„ä¸­ä¸¢å¤±å…³é”®å±€éƒ¨ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†å‰²ç»“æœè¾¹ç•Œæ¨¡ç³Šå’ŒåŒºåŸŸå¤±çœŸã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†HybridMambaæ¶æ„ï¼Œé‡‡ç”¨åŒé‡äº’è¡¥æœºåˆ¶ï¼šä¸€æ˜¯ç‰¹å¾æ‰«æç­–ç•¥ï¼Œé€æ­¥é›†æˆè½´å‘éå†å’Œæœ¬åœ°è‡ªé€‚åº”è·¯å¾„çš„è¡¨ç¤ºï¼Œä½¿å±€éƒ¨å’Œå…¨å±€è¡¨ç¤ºä¹‹é—´å’Œè°å…±å­˜ï¼›äºŒæ˜¯ç»“åˆç©ºé—´é¢‘ç‡åˆ†æçš„å—æ§æ¨¡å—ï¼Œå®ç°å…¨é¢çš„ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ”¶é›†äº†å…³äºè‚ºç™Œçš„å¤šä¸­å¿ƒCTæ•°æ®é›†ã€‚åœ¨MRIå’ŒCTæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHybridMambaåœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Mambaåœ¨è§£å†³CNNå»ºæ¨¡è¿œç¨‹ä¾èµ–é—®é¢˜å’Œå¤„ç†é«˜åˆ†è¾¨ç‡åŒ»ç–—å·ç§¯çš„è®¡ç®—å¼€é”€æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>è¿‡åˆ†å¼ºè°ƒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡å¯èƒ½å¯¼è‡´å…³é”®å±€éƒ¨ç»“æ„ä¿¡æ¯çš„ä¸¢å¤±ã€‚</li>
<li>HybridMambaæ¶æ„é‡‡ç”¨åŒé‡äº’è¡¥æœºåˆ¶æ¥å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ã€‚</li>
<li>ç‰¹å¾æ‰«æç­–ç•¥é€æ­¥é›†æˆè½´å‘éå†å’Œæœ¬åœ°è‡ªé€‚åº”è·¯å¾„è¡¨ç¤ºã€‚</li>
<li>å—æ§æ¨¡å—ç»“åˆç©ºé—´é¢‘ç‡åˆ†æå®ç°å…¨é¢çš„ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚</li>
<li>æ”¶é›†çš„å¤šä¸­å¿ƒCTæ•°æ®é›†ç”¨äºç ”ç©¶è‚ºç™Œç›¸å…³çš„åŒ»å­¦å›¾åƒã€‚</li>
<li>åœ¨MRIå’ŒCTæ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºHybridMambaæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14609">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-83c54491574d143e8077d798e8950dbc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031500&auth_key=1760031500-0-0-128283906e9c3c5891e9ad4e06f85591&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-22adacce7cbab9151eb35e78f7550dc6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031507&auth_key=1760031507-0-0-f54b58f4ecb186282f93f57d7da93bf7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ab36cb0621e368ec9681603ba67108b2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031513&auth_key=1760031513-0-0-817980b2d537659184d6b72ce519f89d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-79eb6d811829d409e568112e732685f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031520&auth_key=1760031520-0-0-cb26523a5725799a9b68bb14bb1ebef0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="The-Stochastic-Dissipation-Model-for-the-Steady-State-Neutrino-and-Multi-Wavelength-Emission-of-TXS-0506-056"><a href="#The-Stochastic-Dissipation-Model-for-the-Steady-State-Neutrino-and-Multi-Wavelength-Emission-of-TXS-0506-056" class="headerlink" title="The Stochastic Dissipation Model for the Steady State Neutrino and   Multi-Wavelength Emission of TXS 0506+056"></a>The Stochastic Dissipation Model for the Steady State Neutrino and   Multi-Wavelength Emission of TXS 0506+056</h2><p><strong>Authors:Zhen-Jie Wang, Ruo-Yu Liu, Xiang-Yu Wang</strong></p>
<p>The blazar TXS 0506+056 has been suggested to be a potential high-energy neutrino source thanks to the observations of IceCube, which found outburst-like neutrino emissions during 2014-2015 and 2017 in the transient emission search, and a $3.5\sigma$ local significance in a 10-year time-integrated search. The conventional one-zone jet model cannot explain the observed neutrino flux during outbursts due to the constraint from the X-ray flux, leading to proposals of multi-zone models (e.g. two-zone model) with multiple radiation zones. In literature, it has been shown that multi-zone models may consistently explain the high-state neutrino emission and the multi-wavelength emission of TXS 0506+056, while the quasi-steady-state long-term emission has not been well studied. In this work, we investigate a physically based model for the quasi-steady-state neutrino and electromagnetic radiation under the same framework, and successfully reproduce the multi-messenger emission of TXS 0506+056. </p>
<blockquote>
<p>æš´è€€ä½“TXS 0506+056ç”±äºå…¶è§‚æµ‹ç»“æœè¢«è®¤ä¸ºæ˜¯æ½œåœ¨çš„é«˜èƒ½ä¸­å¾®å­æºã€‚IceCubeçš„è§‚å¯Ÿç»“æœæ˜¾ç¤ºï¼Œåœ¨ç¬æ€å‘å°„æœç´¢è¿‡ç¨‹ä¸­ï¼Œè¯¥æºåœ¨2014-2015å¹´å’Œ2017å¹´è¡¨ç°å‡ºç±»ä¼¼çˆ†å‘çš„ä¸­å¾®å­å‘å°„ï¼Œå¹¶ä¸”åœ¨ä¸ºæœŸåå¹´çš„æ—¶é—´ç§¯åˆ†æœç´¢ä¸­å…·æœ‰3.5Ïƒçš„å±€éƒ¨æ˜¾è‘—æ€§ã€‚ä¼ ç»Ÿçš„å•åŒºå–·å°„æ¨¡å‹ç”±äºXå°„çº¿æµé‡çš„é™åˆ¶ï¼Œæ— æ³•è§£é‡Šçˆ†å‘æœŸé—´è§‚å¯Ÿåˆ°çš„ä¸­å¾®å­æµé‡ï¼Œè¿™å¯¼è‡´äº†å¤šåŒºæ¨¡å‹ï¼ˆä¾‹å¦‚ä¸¤åŒºæ¨¡å‹ï¼‰çš„æå‡ºï¼Œè¯¥æ¨¡å‹å…·æœ‰å¤šä¸ªè¾å°„åŒºã€‚æ–‡çŒ®è¡¨æ˜ï¼Œå¤šåŒºæ¨¡å‹å¯ä»¥ä¸€è‡´åœ°è§£é‡ŠTXS 0506+056çš„é«˜æ€ä¸­å¾®å­å‘å°„å’Œå¤šæ³¢é•¿å‘å°„ï¼Œè€Œå¯¹å…¶å‡†ç¨³æ€é•¿æœŸå‘å°„çš„ç ”ç©¶å°šä¸å……åˆ†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨åŒä¸€æ¡†æ¶ä¸‹ç ”ç©¶äº†åŸºäºç‰©ç†çš„å‡†ç¨³æ€ä¸­å¾®å­å’Œç”µç£è¾å°„æ¨¡å‹ï¼Œå¹¶æˆåŠŸå†ç°äº†TXS 0506+056çš„å¤šä¿¡ä½¿å‘å°„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14587v1">PDF</a> 10 pages, 3 figures, accepted for publication in PRD</p>
<p><strong>Summary</strong><br>     å¤©ç´åº§BZBZæºTXS 0506+056è§‚æµ‹åˆ°äº†ç–‘ä¼¼çš„é«˜èƒ½ä¸­å¾®å­æºçˆ†å‘ã€‚åŸºäºåå¹´æ—¶é—´ç»¼åˆè§‚æµ‹å’Œå•æ¬¡çˆ†å‘è§‚æµ‹æ•°æ®ï¼Œæå‡ºä¼ ç»Ÿå•åŒºjetæ¨¡å‹æ— æ³•è§£é‡Šè§‚æµ‹åˆ°çš„ä¸­å¾®å­æµé‡çˆ†å‘ã€‚æ–‡çŒ®ä¸­æœ‰ç ”ç©¶æ˜¾ç¤ºå¤šåŒºæ¨¡å‹å¯ä»¥è§£é‡Šé«˜çŠ¶æ€çš„ä¸­å¾®å­å‘å°„å’Œå¤šæ³¢æ®µçš„TXS 0 506+056çš„å‘å°„ï¼Œä½†å¯¹äºå…¶é•¿æœŸå‡†ç¨³æ€çš„å‘å°„ç ”ç©¶å°šä¸å……åˆ†ã€‚æœ¬ç ”ç©¶åœ¨åŒä¸€æ¡†æ¶ä¸‹æ¢ç©¶åŸºäºç‰©ç†çš„å‡†ç¨³æ€ä¸­å¾®å­å’Œç”µç£è¾å°„æ¨¡å‹ï¼ŒæˆåŠŸå†ç°äº†TXS 0506+056çš„å¤šä¿¡ä½¿å‘å°„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤©ç´åº§BZBZæºTXS 0506+056è¢«è®¤ä¸ºæ˜¯æ½œåœ¨çš„é«˜èƒ½ä¸­å¾®å­æºã€‚</li>
<li>IceCubeè§‚æµ‹åˆ°è¯¥æºåœ¨2014-2015å¹´å’Œ2017å¹´çš„çˆ†å‘æ€§ä¸­å¾®å­å‘å°„ã€‚</li>
<li>ä¼ ç»Ÿå•åŒºjetæ¨¡å‹æ— æ³•è§£é‡Šè§‚æµ‹åˆ°çš„ä¸­å¾®å­æµé‡çˆ†å‘ï¼Œå› ä¸ºå—åˆ°Xå°„çº¿æµé‡çš„é™åˆ¶ã€‚</li>
<li>å¤šåŒºæ¨¡å‹ï¼ˆå¦‚ä¸¤åŒºæ¨¡å‹ï¼‰è¢«æå‡ºä»¥è§£é‡Šé«˜çŠ¶æ€çš„ä¸­å¾®å­å‘å°„å’Œå¤šæ³¢æ®µçš„TXS 0506+056çš„å‘å°„ã€‚</li>
<li>å¤šåŒºæ¨¡å‹èƒ½å¤Ÿä¸€è‡´åœ°è§£é‡ŠTXS 0506+056çš„é«˜çŠ¶æ€ä¸­å¾®å­å‘å°„å’Œå¤šæ³¢é•¿å‘å°„ã€‚</li>
<li>å…³äºTXS 0506+056çš„å‡†ç¨³æ€é•¿æœŸå‘å°„å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14587">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-73d3a8d9c04cecbcf212459ae03e83e5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031527&auth_key=1760031527-0-0-ba47fd39e9d8ff7b60fbd6cfe02971da&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ef161b324782e5e98c36be1e33e8cbbf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031535&auth_key=1760031535-0-0-8e3917dfc12b544aec6a4d63b9820807&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8ed6bfbc2aaaed5a9abb7910bac2252f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031542&auth_key=1760031542-0-0-1893f88557c4f65a0fe7315566a168ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="HQCNN-A-Hybrid-Quantum-Classical-Neural-Network-for-Medical-Image-Classification"><a href="#HQCNN-A-Hybrid-Quantum-Classical-Neural-Network-for-Medical-Image-Classification" class="headerlink" title="HQCNN: A Hybrid Quantum-Classical Neural Network for Medical Image   Classification"></a>HQCNN: A Hybrid Quantum-Classical Neural Network for Medical Image   Classification</h2><p><strong>Authors: Shahjalal, Jahid Karim Fahim, Pintu Chandra Paul, Md Robin Hossain, Md. Tofael Ahmed, Dulal Chakraborty</strong></p>
<p>Classification of medical images plays a vital role in medical image analysis; however, it remains challenging due to the limited availability of labeled data, class imbalances, and the complexity of medical patterns. To overcome these challenges, we propose a novel Hybrid Quantum-Classical Neural Network (HQCNN) for both binary and multi-class classification. The architecture of HQCNN integrates a five-layer classical convolutional backbone with a 4-qubit variational quantum circuit that incorporates quantum state encoding, superpositional entanglement, and a Fourier-inspired quantum attention mechanism. We evaluate the model on six MedMNIST v2 benchmark datasets. The HQCNN consistently outperforms classical and quantum baselines, achieving up to 99.91% accuracy and 100.00% AUC on PathMNIST (binary) and 99.95% accuracy on OrganAMNIST (multi-class) with strong robustness on noisy datasets like BreastMNIST (87.18% accuracy). The model demonstrates superior generalization capability and computational efficiency, accomplished with significantly fewer trainable parameters, making it suitable for data-scarce scenarios. Our findings provide strong empirical evidence that hybrid quantum-classical models can advance medical imaging tasks. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†ç±»åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼›ç„¶è€Œï¼Œç”±äºæ ‡è®°æ•°æ®æœ‰é™ã€ç±»åˆ«ä¸å¹³è¡¡ä»¥åŠåŒ»å­¦æ¨¡å¼å¤æ‚æ€§ï¼Œå®ƒä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æ··åˆé‡å­ç»å…¸ç¥ç»ç½‘ç»œï¼ˆHQCNNï¼‰è¿›è¡ŒäºŒå…ƒå’Œå¤šå…ƒåˆ†ç±»ã€‚HQCNNæ¶æ„å°†äº”å±‚ç»å…¸å·ç§¯ä¸»å¹²ä¸åŒ…å«é‡å­æ€ç¼–ç ã€å åŠ çº ç¼ å’Œå‚…ç«‹å¶é‡å­æ³¨æ„åŠ›æœºåˆ¶çš„4é‡å­æ¯”ç‰¹å˜åˆ†é‡å­ç”µè·¯ç›¸ç»“åˆã€‚æˆ‘ä»¬åœ¨å…­ä¸ªMedMNIST v2åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°äº†è¯¥æ¨¡å‹ã€‚HQCNNæŒç»­è¶…è¶Šç»å…¸å’Œé‡å­åŸºçº¿æ¨¡å‹ï¼Œåœ¨PathMNISTï¼ˆäºŒå…ƒï¼‰ä¸Šè¾¾åˆ°æœ€é«˜99.91%çš„å‡†ç¡®ç‡å’Œ100.00%çš„AUCå€¼ï¼Œåœ¨OrganAMNISTï¼ˆå¤šå…ƒï¼‰ä¸Šè¾¾åˆ°æœ€é«˜99.95%çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”å¯¹è¯¸å¦‚BreastMNISTè¿™æ ·çš„å™ªå£°æ•°æ®é›†å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼ˆå‡†ç¡®ç‡è¾¾åˆ°äº†87.18%ï¼‰ã€‚è¯¥æ¨¡å‹å±•ç¤ºäº†å“è¶Šçš„æ€»ä½“åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ï¼Œå®ç°äº†æ›´å°‘æ•°é‡çš„å¯è®­ç»ƒå‚æ•°ï¼Œä½¿å…¶æˆä¸ºæ•°æ®ç¨€ç¼ºåœºæ™¯çš„ç†æƒ³é€‰æ‹©ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†å¼ºæœ‰åŠ›çš„å®è¯è¯æ®è¡¨æ˜æ··åˆé‡å­ç»å…¸æ¨¡å‹å¯ä»¥ä¿ƒè¿›åŒ»å­¦æˆåƒä»»åŠ¡çš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14277v1">PDF</a> 21 pages, 8 figures. Submitted to Quantum Journal. Corresponding   author: Pintu Chandra Paul (<a href="mailto:&#112;&#105;&#110;&#x74;&#117;&#x40;&#x63;&#x6f;&#x75;&#x2e;&#x61;&#x63;&#x2e;&#98;&#100;">&#112;&#105;&#110;&#x74;&#117;&#x40;&#x63;&#x6f;&#x75;&#x2e;&#x61;&#x63;&#x2e;&#98;&#100;</a>)</p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†ç±»åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½†ç”±äºç¼ºä¹æ ‡è®°æ•°æ®ã€ç±»åˆ«ä¸å¹³è¡¡å’ŒåŒ»å­¦æ¨¡å¼å¤æ‚æ€§ï¼Œä»å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹æ··åˆé‡å­ç»å…¸ç¥ç»ç½‘ç»œï¼ˆHQCNNï¼‰ï¼Œå¯ç”¨äºäºŒå…ƒåŠå¤šç±»åˆ†ç±»ã€‚HQCNNæ¶æ„èåˆäº†äº”å±‚ç»å…¸å·ç§¯ä¸»å¹²ä¸åŒ…å«é‡å­çŠ¶æ€ç¼–ç ã€å åŠ çº ç¼ å’Œå‚…é‡Œå¶é‡å­æ³¨æ„åŠ›æœºåˆ¶çš„4é‡å­æ¯”ç‰¹å˜åˆ†é‡å­ç”µè·¯ã€‚åœ¨å…­ä¸ªMedMNIST v2åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°è¯¥æ¨¡å‹ï¼ŒHQCNNæŒç»­è¶…è¶Šç»å…¸å’Œé‡å­åŸºçº¿ï¼Œåœ¨PathMNISTï¼ˆäºŒå…ƒï¼‰ä¸Šè¾¾åˆ°æœ€é«˜99.91%å‡†ç¡®ç‡å’Œ100.0% AUCï¼Œä»¥åŠåœ¨OrganAMNISTï¼ˆå¤šç±»ï¼‰ä¸Šè¾¾åˆ°æœ€é«˜99.95%å‡†ç¡®ç‡ã€‚å³ä½¿åœ¨å™ªéŸ³è¾ƒå¤§çš„æ•°æ®é›†ï¼ˆå¦‚BreastMNISTçš„å‡†ç¡®ç‡æœ€é«˜è¾¾87.18%ï¼‰ä¸­ï¼Œè¯¥æ¨¡å‹ä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ã€‚æ¨¡å‹å…·æœ‰å“è¶Šæ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ï¼Œæ‰€éœ€è®­ç»ƒå‚æ•°æ˜¾è‘—å‡å°‘ï¼Œé€‚ç”¨äºæ•°æ®ç¨€ç¼ºåœºæ™¯ã€‚è¿™ä¸ºæ··åˆé‡å­ç»å…¸æ¨¡å‹åœ¨åŒ»å­¦æˆåƒä»»åŠ¡ä¸­çš„ä¼˜åŠ¿æä¾›äº†å¼ºæœ‰åŠ›çš„å®è¯è¯æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŒ»å­¦å›¾åƒåˆ†ç±»åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­éå¸¸é‡è¦ï¼Œä½†å—é™äºç¼ºä¹æ ‡è®°æ•°æ®ã€ç±»åˆ«ä¸å¹³è¡¡å’Œå¤æ‚çš„åŒ»å­¦æ¨¡å¼ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„æ··åˆé‡å­ç»å…¸ç¥ç»ç½‘ç»œï¼ˆHQCNNï¼‰æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œé€‚ç”¨äºäºŒå…ƒå’Œå¤šç±»åˆ†ç±»ã€‚</li>
<li>HQCNNç»“åˆäº†ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œå’Œé‡å­è®¡ç®—æŠ€æœ¯ï¼ŒåŒ…æ‹¬é‡å­çŠ¶æ€ç¼–ç ã€å åŠ çº ç¼ å’Œå‚…é‡Œå¶é‡å­æ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°HQCNNæ€§èƒ½ï¼Œè¡¨ç°å‡ºè¾ƒé«˜çš„å‡†ç¡®ç‡å’Œé²æ£’æ€§ã€‚</li>
<li>HQCNNå…·æœ‰ä¼˜ç§€çš„æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ï¼Œå°¤å…¶é€‚ç”¨äºæ•°æ®ç¨€ç¼ºåœºæ™¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14277">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0500b193eebe8473f9ea026537646e86~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031549&auth_key=1760031549-0-0-857630f9d9029007abd86efe6f1ea79e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2f7f28f724aefbbbb8d63bc5cfbad3ae~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031557&auth_key=1760031557-0-0-3f0a8348aca248545ef86a54f52257ef&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Microlocal-analysis-of-non-linear-operators-arising-in-Compton-CT"><a href="#Microlocal-analysis-of-non-linear-operators-arising-in-Compton-CT" class="headerlink" title="Microlocal analysis of non-linear operators arising in Compton CT"></a>Microlocal analysis of non-linear operators arising in Compton CT</h2><p><strong>Authors:James W. Webber, Sean Holman</strong></p>
<p>We present a novel microlocal analysis of a non-linear ray transform, $\mathcal{R}$, arising in Compton Scattering Tomography (CST). Due to attenuation effects in CST, the integral weights depend on the reconstruction target, $f$, which has singularities. Thus, standard linear Fourier Integral Operator (FIO) theory does not apply as the weights are non-smooth. The V-line (or broken ray) transform, $\mathcal{V}$, can be used to model the attenuation of incoming and outgoing rays. Through novel analysis of $\mathcal{V}$, we characterize the location and strength of the singularities of the ray transform weights. In conjunction, we provide new results which quantify the strength of the singularities of distributional products based on the Sobolev order of the individual components. By combining this new theory, our analysis of $\mathcal{V}$, and classical linear FIO theory, we determine the Sobolev order of the singularities of $\mathcal{R}f$. The strongest (lowest Sobolev order) singularities of $\mathcal{R}f$ are shown to correspond to the wavefront set elements of the classical Radon transform applied to $f$, and we use this idea and known results on the Radon transform to prove injectivity results for $\mathcal{R}$. In addition, we present novel reconstruction methods based on our theory, and we validate our results using simulated image reconstructions. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹å‡ºç°åœ¨åº·æ™®é¡¿æ•£å°„æ–­å±‚æ‰«ææŠ€æœ¯ï¼ˆCSTï¼‰ä¸­çš„éçº¿æ€§å°„çº¿å˜æ¢ $\mathcal{R}$ è¿›è¡Œäº†ä¸€ç§æ–°é¢–çš„å±€éƒ¨åˆ†æã€‚ç”±äº CST ä¸­çš„è¡°å‡æ•ˆåº”ï¼Œç§¯åˆ†æƒé‡å–å†³äºå…·æœ‰å¥‡å¼‚æ€§çš„é‡å»ºç›®æ ‡ $f$ï¼Œå› æ­¤æ ‡å‡†çš„çº¿æ€§å‚…é‡Œå¶ç§¯åˆ†ç®—å­ç†è®ºæ— æ³•é€‚ç”¨ï¼Œå› ä¸ºæƒé‡æ˜¯éå¹³æ»‘çš„ã€‚V çº¿ï¼ˆæˆ–æ–­çº¿ï¼‰å˜æ¢ $\mathcal{V}$ å¯ç”¨äºæ¨¡æ‹Ÿå…¥å°„å’Œå‡ºå°„å°„çº¿çš„è¡°å‡ã€‚é€šè¿‡å¯¹ $\mathcal{V}$ çš„æ–°é¢–åˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†å°„çº¿å˜æ¢æƒé‡çš„å¥‡å¼‚ç‚¹çš„ä½ç½®å’Œå¼ºåº¦ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æä¾›äº†åŸºäºå„ä¸ªç»„ä»¶çš„ç´¢åšåˆ—å¤«é˜¶æ•°æ¥é‡åŒ–åˆ†å¸ƒäº§å“å¥‡å¼‚ç‚¹å¼ºåº¦çš„æ–°ç»“æœã€‚é€šè¿‡ç»“åˆè¿™ä¸€æ–°ç†è®ºã€æˆ‘ä»¬å¯¹ $\mathcal{V}$ çš„åˆ†æå’Œç»å…¸çš„çº¿æ€§å‚…ç«‹å¶ç§¯åˆ†ç®—å­ç†è®ºï¼Œæˆ‘ä»¬ç¡®å®šäº† $\mathcal{R}f$ å¥‡å¼‚æ€§çš„ç´¢æ³¢åˆ—å¤«é˜¶æ•°ã€‚æˆ‘ä»¬å‘ç° $\mathcal{R}f$ çš„æœ€å¼ºï¼ˆæœ€ä½ç´¢æ³¢åˆ—å¤«é˜¶æ•°ï¼‰å¥‡å¼‚ç‚¹å¯¹åº”äºç»å…¸ Radon å˜æ¢åº”ç”¨äº $f$ çš„æ³¢å‰é›†åˆå…ƒç´ ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸€æ€æƒ³ä»¥åŠ Radon å˜æ¢çš„å·²çŸ¥ç»“æœæ¥è¯æ˜ $\mathcal{R}$ çš„å•å°„æ€§ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºæˆ‘ä»¬çš„ç†è®ºæå‡ºäº†æ–°é¢–çš„é‡æ„æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨æ¨¡æ‹Ÿçš„å›¾åƒé‡æ„æ¥éªŒè¯æˆ‘ä»¬çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.19791v3">PDF</a> 27 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§éçº¿æ€§å°„çº¿å˜æ¢$\mathcal{R}$åœ¨åº·æ™®é¡¿æ•£å°„æ–­å±‚æ‰«æï¼ˆCSTï¼‰ä¸­çš„æ–°å‹å¾®å±€éƒ¨åˆ†æã€‚ç”±äºCSTä¸­çš„è¡°å‡æ•ˆåº”ï¼Œç§¯åˆ†æƒé‡å–å†³äºå…·æœ‰å¥‡å¼‚æ€§çš„é‡å»ºç›®æ ‡$f$ï¼Œå› æ­¤æ ‡å‡†çš„çº¿æ€§å‚…ç«‹å¶ç§¯åˆ†ç®—å­ç†è®ºä¸é€‚ç”¨ã€‚é€šè¿‡Vçº¿ï¼ˆæˆ–æ–­çº¿ï¼‰å˜æ¢$\mathcal{V}$çš„æ–°å‹åˆ†æï¼Œè¡¨å¾å°„çº¿å˜æ¢æƒé‡çš„å¥‡å¼‚ä½ç½®å’Œå¼ºåº¦ã€‚ç»“åˆæ–°çš„å¥‡å¼‚å¼ºåº¦é‡åŒ–ç»“æœå’Œç´¢åšåˆ—å¤«é˜¶æ•°çš„åˆ†å¸ƒäº§å“ï¼Œæˆ‘ä»¬ç¡®å®šäº†$\mathcal{R}f$çš„ç´¢åšåˆ—å¤«é˜¶æ•°ã€‚$\mathcal{R}f$çš„æœ€å¼ºï¼ˆæœ€ä½çš„ç´¢åšåˆ—å¤«é˜¶æ•°ï¼‰å¥‡å¼‚ç‚¹å¯¹åº”äºç»å…¸æ‹‰ä¸œå˜æ¢åº”ç”¨äº$f$çš„æ³¢å‰é›†å…ƒç´ ï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™ä¸€æ€æƒ³å’Œæ‹‰ä¸œå˜æ¢çš„å·²çŸ¥ç»“æœè¯æ˜äº†$\mathcal{R}$çš„æ³¨å…¥æ€§ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºç†è®ºæå‡ºäº†æ–°å‹é‡å»ºæ–¹æ³•ï¼Œå¹¶é€šè¿‡æ¨¡æ‹Ÿå›¾åƒé‡å»ºéªŒè¯äº†æˆ‘ä»¬çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†åœ¨åº·æ™®é¡¿æ•£å°„æ–­å±‚æ‰«æï¼ˆCSTï¼‰ä¸­çš„éçº¿æ€§å°„çº¿å˜æ¢$\mathcal{R}$çš„å¾®å±€éƒ¨åˆ†æã€‚</li>
<li>ç”±äºè¡°å‡æ•ˆåº”ï¼ŒCSTä¸­çš„ç§¯åˆ†æƒé‡å…·æœ‰å¥‡å¼‚æ€§ï¼Œä½¿å¾—æ ‡å‡†çº¿æ€§å‚…ç«‹å¶ç§¯åˆ†ç®—å­ç†è®ºä¸é€‚ç”¨ã€‚</li>
<li>é€šè¿‡Vçº¿ï¼ˆæˆ–æ–­çº¿ï¼‰å˜æ¢$\mathcal{V}$åˆ†æï¼Œæè¿°äº†å°„çº¿å˜æ¢æƒé‡çš„å¥‡å¼‚ä½ç½®å’Œå¼ºåº¦ã€‚</li>
<li>æä¾›äº†æ–°çš„ç»“æœï¼Œé‡åŒ–åˆ†å¸ƒäº§å“çš„å¥‡å¼‚å¼ºåº¦ï¼Œå¹¶åŸºäºä¸ªåˆ«ç»„ä»¶çš„ç´¢åšåˆ—å¤«é˜¶æ•°ã€‚</li>
<li>ç¡®å®šäº†$\mathcal{R}f$çš„ç´¢åšåˆ—å¤«é˜¶æ•°ã€‚</li>
<li>$\mathcal{R}f$çš„æœ€å¼ºå¥‡å¼‚ç‚¹ä¸ç»å…¸æ‹‰ä¸œå˜æ¢åº”ç”¨äº$f$çš„æ³¢å‰é›†å…ƒç´ ç›¸å¯¹åº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.19791">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a335eb4a81afa7ebd79fd1253e7fc3e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031564&auth_key=1760031564-0-0-da1703f02b3865b9e05abd1347fde3b6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="DiffCut-Catalyzing-Zero-Shot-Semantic-Segmentation-with-Diffusion-Features-and-Recursive-Normalized-Cut"><a href="#DiffCut-Catalyzing-Zero-Shot-Semantic-Segmentation-with-Diffusion-Features-and-Recursive-Normalized-Cut" class="headerlink" title="DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion   Features and Recursive Normalized Cut"></a>DiffCut: Catalyzing Zero-Shot Semantic Segmentation with Diffusion   Features and Recursive Normalized Cut</h2><p><strong>Authors:Paul Couairon, Mustafa Shukor, Jean-Emmanuel Haugeard, Matthieu Cord, Nicolas Thome</strong></p>
<p>Foundation models have emerged as powerful tools across various domains including language, vision, and multimodal tasks. While prior works have addressed unsupervised image segmentation, they significantly lag behind supervised models. In this paper, we use a diffusion UNet encoder as a foundation vision encoder and introduce DiffCut, an unsupervised zero-shot segmentation method that solely harnesses the output features from the final self-attention block. Through extensive experimentation, we demonstrate that the utilization of these diffusion features in a graph based segmentation algorithm, significantly outperforms previous state-of-the-art methods on zero-shot segmentation. Specifically, we leverage a recursive Normalized Cut algorithm that softly regulates the granularity of detected objects and produces well-defined segmentation maps that precisely capture intricate image details. Our work highlights the remarkably accurate semantic knowledge embedded within diffusion UNet encoders that could then serve as foundation vision encoders for downstream tasks. Project page at <a target="_blank" rel="noopener" href="https://diffcut-segmentation.github.io/">https://diffcut-segmentation.github.io</a> </p>
<blockquote>
<p>è·¨è¯­è¨€ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ç­‰å¤šä¸ªé¢†åŸŸï¼ŒåŸºç¡€æ¨¡å‹å·²å±•ç°å‡ºå¼ºå¤§çš„å·¥å…·èƒ½åŠ›ã€‚è™½ç„¶ä¹‹å‰çš„å·¥ä½œå·²ç»è§£å†³äº†æ— ç›‘ç£å›¾åƒåˆ†å‰²çš„é—®é¢˜ï¼Œä½†å®ƒä»¬ä¸æœ‰ç›‘ç£æ¨¡å‹ç›¸æ¯”ä»æœ‰è¾ƒå¤§å·®è·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰©æ•£U-Netç¼–ç å™¨ä½œä¸ºåŸºç¡€è§†è§‰ç¼–ç å™¨ï¼Œå¹¶å¼•å…¥äº†DiffCutï¼Œè¿™æ˜¯ä¸€ç§æ— ç›‘ç£é›¶æ ·æœ¬åˆ†å‰²æ–¹æ³•ï¼Œå®ƒä»…åˆ©ç”¨æœ€ç»ˆè‡ªæ³¨æ„åŠ›å—çš„è¾“å‡ºç‰¹å¾ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨åŸºäºå›¾çš„åˆ†å‰²ç®—æ³•ä¸­ä½¿ç”¨è¿™äº›æ‰©æ•£ç‰¹å¾ï¼Œåœ¨é›¶æ ·æœ¬åˆ†å‰²æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨é€’å½’å½’ä¸€åŒ–åˆ‡å‰²ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ä»¥æ¸©å’Œåœ°æ§åˆ¶æ£€æµ‹å¯¹è±¡çš„ç²’åº¦ï¼Œå¹¶äº§ç”Ÿå®šä¹‰æ˜ç¡®çš„åˆ†å‰²å›¾ï¼Œèƒ½å¤Ÿç²¾ç¡®æ•æ‰å›¾åƒç»†èŠ‚ã€‚æˆ‘ä»¬çš„å·¥ä½œçªå‡ºäº†æ‰©æ•£U-Netç¼–ç å™¨ä¸­æ‰€åµŒå…¥çš„ç²¾ç¡®è¯­ä¹‰çŸ¥è¯†ï¼Œä¹‹åå¯ä»¥ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„åŸºç¡€è§†è§‰ç¼–ç å™¨ã€‚é¡¹ç›®é¡µé¢ä¸º<a target="_blank" rel="noopener" href="https://diffcut-segmentation.github.io./">https://diffcut-segmentation.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02842v3">PDF</a> NeurIPS 2024. Project page at <a target="_blank" rel="noopener" href="https://diffcut-segmentation.github.io/">https://diffcut-segmentation.github.io</a>.   Code at <a target="_blank" rel="noopener" href="https://github.com/PaulCouairon/DiffCut">https://github.com/PaulCouairon/DiffCut</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ‰©æ•£UNetç¼–ç å™¨çš„æ— ç›‘ç£é›¶åˆ†å‰²æ–¹æ³•DiffCutã€‚è¯¥æ–¹æ³•ä»…åˆ©ç”¨æœ€ç»ˆè‡ªæ³¨æ„åŠ›å—çš„è¾“å‡ºç‰¹å¾ï¼Œé€šè¿‡åŸºäºå›¾çš„åˆ†å‰²ç®—æ³•ï¼Œæ˜¾è‘—ä¼˜äºä¹‹å‰çš„é›¶åˆ†å‰²æ–¹æ³•ã€‚é€šè¿‡é€’å½’å½’ä¸€åŒ–åˆ‡å‰²ç®—æ³•ï¼Œå¯ä»¥ç²¾ç»†åœ°æ£€æµ‹ç‰©ä½“å¹¶ç”Ÿæˆç²¾ç¡®çš„åˆ†å‰²å›¾ï¼Œæ•æ‰å›¾åƒç»†èŠ‚ã€‚æœ¬æ–‡å¼ºè°ƒäº†æ‰©æ•£UNetç¼–ç å™¨ä¸­çš„è¯­ä¹‰çŸ¥è¯†ï¼Œå¯ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„åŸºç¡€è§†è§‰ç¼–ç å™¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£UNetç¼–ç å™¨ä½œä¸ºåŸºç¡€è§†è§‰ç¼–ç å™¨åœ¨å›¾åƒåˆ†å‰²ä¸­çš„å¼ºå¤§æ€§èƒ½ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ— ç›‘ç£é›¶åˆ†å‰²æ–¹æ³•DiffCutï¼Œåˆ©ç”¨æ‰©æ•£ç‰¹å¾è¿›è¡Œå›¾åƒåˆ†å‰²ã€‚</li>
<li>DiffCuté€šè¿‡ä½¿ç”¨åŸºäºå›¾çš„åˆ†å‰²ç®—æ³•å’Œé€’å½’å½’ä¸€åŒ–åˆ‡å‰²ç®—æ³•å®ç°äº†ç²¾ç¡®çš„å›¾åƒåˆ†å‰²ã€‚</li>
<li>DiffCutåœ¨é›¶åˆ†å‰²æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
<li>Diffusion UNetç¼–ç å™¨ä¸­çš„è¯­ä¹‰çŸ¥è¯†å¯¹å›¾åƒåˆ†å‰²ä»»åŠ¡è‡³å…³é‡è¦ã€‚</li>
<li>æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæ•æ‰å›¾åƒçš„ç»†èŠ‚å¹¶ç”Ÿæˆè¯¦ç»†çš„åˆ†å‰²å›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.02842">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d9435a1eeeac5f9b62fd9e24766f9040~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031571&auth_key=1760031571-0-0-f4323dc4342647e0724a2b16369bc718&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-38012e3a3002d675954a9a4c0af94494~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031579&auth_key=1760031579-0-0-c6f1c876f62d83f2d441e52452f28eef&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-10724cea89d27141f495b0a7f896522a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031585&auth_key=1760031585-0-0-caaa05de6a142416697f26c21c3469f0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-20/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-20/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-20/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-781827a641539cdcc40c2cf3dd3a541a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031593&auth_key=1760031593-0-0-3ac8efaade6e860913ffe1ec0c1ad2ba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  MELA-TTS Joint transformer-diffusion model with representation   alignment for speech synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-20/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-67098d89d2cede73749b941db21f4102~resize:0:q75.jpg?source=1f5c5e47&expiration=1760030892&auth_key=1760030892-0-0-b6f487b65550d82604d5b331e0faa442&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  Lightweight and Accurate Multi-View Stereo with Confidence-Aware   Diffusion Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31086.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
