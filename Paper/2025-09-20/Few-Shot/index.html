<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  Seeing 3D Through 2D Lenses 3D Few-Shot Class-Incremental Learning via   Cross-Modal Geometric Rectification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-7e3f8f182fc20e823326aea988214435~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029538&auth_key=1760029538-0-0-764be6934c9a29e0b3cfe82da6e00a9a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    38 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-20-æ›´æ–°"><a href="#2025-09-20-æ›´æ–°" class="headerlink" title="2025-09-20 æ›´æ–°"></a>2025-09-20 æ›´æ–°</h1><h2 id="Seeing-3D-Through-2D-Lenses-3D-Few-Shot-Class-Incremental-Learning-via-Cross-Modal-Geometric-Rectification"><a href="#Seeing-3D-Through-2D-Lenses-3D-Few-Shot-Class-Incremental-Learning-via-Cross-Modal-Geometric-Rectification" class="headerlink" title="Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via   Cross-Modal Geometric Rectification"></a>Seeing 3D Through 2D Lenses: 3D Few-Shot Class-Incremental Learning via   Cross-Modal Geometric Rectification</h2><p><strong>Authors:Xiang Tuo, Xu Xuemiao, Liu Bangzhen, Li Jinyi, Li Yong, He Shengfeng</strong></p>
<p>The rapid growth of 3D digital content necessitates expandable recognition systems for open-world scenarios. However, existing 3D class-incremental learning methods struggle under extreme data scarcity due to geometric misalignment and texture bias. While recent approaches integrate 3D data with 2D foundation models (e.g., CLIP), they suffer from semantic blurring caused by texture-biased projections and indiscriminate fusion of geometric-textural cues, leading to unstable decision prototypes and catastrophic forgetting. To address these issues, we propose Cross-Modal Geometric Rectification (CMGR), a framework that enhances 3D geometric fidelity by leveraging CLIPâ€™s hierarchical spatial semantics. Specifically, we introduce a Structure-Aware Geometric Rectification module that hierarchically aligns 3D part structures with CLIPâ€™s intermediate spatial priors through attention-driven geometric fusion. Additionally, a Texture Amplification Module synthesizes minimal yet discriminative textures to suppress noise and reinforce cross-modal consistency. To further stabilize incremental prototypes, we employ a Base-Novel Discriminator that isolates geometric variations. Extensive experiments demonstrate that our method significantly improves 3D few-shot class-incremental learning, achieving superior geometric coherence and robustness to texture bias across cross-domain and within-domain settings. </p>
<blockquote>
<p>éšç€ä¸‰ç»´æ•°å­—å†…å®¹çš„å¿«é€Ÿå¢é•¿ï¼Œå¼€æ”¾ä¸–ç•Œåœºæ™¯éœ€è¦å¯æ‰©å±•çš„è¯†åˆ«ç³»ç»Ÿã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸‰ç»´ç±»å¢é‡å­¦ä¹ æ–¹æ³•åœ¨æç«¯æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œç”±äºå‡ ä½•å¤±é…å’Œçº¹ç†åè§ï¼Œè¡¨ç°æŒ£æ‰ã€‚è™½ç„¶æœ€è¿‘çš„æ–¹æ³•å°†ä¸‰ç»´æ•°æ®ä¸äºŒç»´åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚CLIPï¼‰ç›¸ç»“åˆï¼Œä½†å®ƒä»¬å—åˆ°çº¹ç†åå‘æŠ•å½±å’Œå‡ ä½•çº¹ç†çº¿ç´¢çš„æ•£æ¼«èåˆå¯¼è‡´çš„è¯­ä¹‰æ¨¡ç³Šçš„å½±å“ï¼Œå¯¼è‡´å†³ç­–åŸå‹ä¸ç¨³å®šå’Œç¾éš¾æ€§é—å¿˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è·¨æ¨¡æ€å‡ ä½•æ ¡æ­£ï¼ˆCMGRï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨CLIPçš„åˆ†å±‚ç©ºé—´è¯­ä¹‰å¢å¼ºä¸‰ç»´å‡ ä½•ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç»“æ„æ„ŸçŸ¥å‡ ä½•æ ¡æ­£æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡æ³¨æ„åŠ›é©±åŠ¨çš„å‡ ä½•èåˆå±‚æ¬¡åœ°ä¸CLIPçš„ä¸­é—´ç©ºé—´å…ˆéªŒå¯¹é½ä¸‰ç»´éƒ¨åˆ†ç»“æ„ã€‚æ­¤å¤–ï¼Œçº¹ç†æ”¾å¤§æ¨¡å—åˆæˆæœ€å°ä½†å…·æœ‰åŒºåˆ†åŠ›çš„çº¹ç†ï¼Œä»¥æŠ‘åˆ¶å™ªå£°å¹¶å¢å¼ºè·¨æ¨¡æ€ä¸€è‡´æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¨³å®šå¢é‡åŸå‹ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†åŸºç¡€-æ–°é¢–é‰´åˆ«å™¨ï¼Œä»¥éš”ç¦»å‡ ä½•å˜åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ç»´å°æ ·æœ¬ç±»å¢é‡å­¦ä¹ ä¸Šæ˜¾è‘—æ”¹è¿›ï¼Œå®ç°äº†è·¨åŸŸå’ŒåŸŸå†…è®¾ç½®ä¸­çš„å‡ºè‰²å‡ ä½•è¿è´¯æ€§å’Œå¯¹çº¹ç†åè§çš„ç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14958v1">PDF</a> ICCV2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¸‰ç»´æ•°å­—å†…å®¹çš„å¿«é€Ÿå¢é•¿å¯¹å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸‹çš„è¯†åˆ«ç³»ç»Ÿæå‡ºäº†æ›´é«˜çš„è¦æ±‚ã€‚ç°æœ‰çš„ä¸‰ç»´ç±»å¢é‡å­¦ä¹ æ–¹æ³•åœ¨æç«¯æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹å­˜åœ¨å‡ ä½•å¤±é…å’Œçº¹ç†åè§çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§åä¸ºCross-Modal Geometric Rectificationï¼ˆCMGRï¼‰çš„æ¡†æ¶ï¼Œåˆ©ç”¨CLIPçš„å±‚æ¬¡ç©ºé—´è¯­ä¹‰æé«˜ä¸‰ç»´å‡ ä½•ä¿çœŸåº¦ã€‚é€šè¿‡å¼•å…¥ç»“æ„æ„ŸçŸ¥å‡ ä½•æ ¡æ­£æ¨¡å—å’Œçº¹ç†æ”¾å¤§æ¨¡å—ï¼Œå®ç°äº†å¯¹ä¸‰ç»´éƒ¨åˆ†ç»“æ„ä¸CLIPä¸­é—´ç©ºé—´å…ˆéªŒçš„å±‚æ¬¡å¯¹é½ï¼Œå¹¶åˆæˆæœ€å°ä½†å…·æœ‰é‰´åˆ«åŠ›çš„çº¹ç†ä»¥æŠ‘åˆ¶å™ªå£°å¹¶å¢å¼ºè·¨æ¨¡æ€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡é‡‡ç”¨åŸºç¡€-æ–°å‹åˆ¤åˆ«å™¨è¿›ä¸€æ­¥ç¨³å®šå¢é‡åŸå‹ï¼Œéš”ç¦»å‡ ä½•å˜åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ç»´å°æ ·æœ¬ç±»å¢é‡å­¦ä¹ ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œæé«˜äº†å‡ ä½•ä¸€è‡´æ€§å’Œå¯¹çº¹ç†åè§çš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯å…³äºè¯¥æ–‡æœ¬çš„å…³é”®è§è§£ï¼š</p>
<ol>
<li>ä¸‰ç»´æ•°å­—å†…å®¹çš„å¢é•¿æ¨åŠ¨äº†å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸‹è¯†åˆ«ç³»ç»Ÿçš„éœ€æ±‚ã€‚</li>
<li>ç°æœ‰ä¸‰ç»´ç±»å¢é‡å­¦ä¹ æ–¹æ³•é¢ä¸´æç«¯æ•°æ®ç¨€ç¼ºæ—¶çš„å‡ ä½•å¤±é…å’Œçº¹ç†åè§é—®é¢˜ã€‚</li>
<li>Cross-Modal Geometric Rectificationï¼ˆCMGRï¼‰æ¡†æ¶åˆ©ç”¨CLIPçš„å±‚æ¬¡ç©ºé—´è¯­ä¹‰æé«˜ä¸‰ç»´å‡ ä½•ä¿çœŸåº¦ã€‚</li>
<li>ç»“æ„æ„ŸçŸ¥å‡ ä½•æ ¡æ­£æ¨¡å—å®ç°äº†ä¸‰ç»´éƒ¨åˆ†ç»“æ„ä¸CLIPä¸­é—´ç©ºé—´å…ˆéªŒçš„å±‚æ¬¡å¯¹é½ã€‚</li>
<li>çº¹ç†æ”¾å¤§æ¨¡å—åˆæˆæœ€å°ä½†å…·æœ‰é‰´åˆ«åŠ›çš„çº¹ç†ï¼Œä»¥æŠ‘åˆ¶å™ªå£°å¹¶å¢å¼ºè·¨æ¨¡æ€ä¸€è‡´æ€§ã€‚</li>
<li>åŸºç¡€-æ–°å‹åˆ¤åˆ«å™¨ç”¨äºè¿›ä¸€æ­¥ç¨³å®šå¢é‡åŸå‹ï¼Œéš”ç¦»å‡ ä½•å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14958">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-1cbb59b39c82c5ce445f8174b0b79581~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029548&auth_key=1760029548-0-0-e2dba9bce7356458d015f558d5e013a7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e01d2c5a3277616a91317d76b754895f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029556&auth_key=1760029556-0-0-cf8e6a01bb8268cb5a1b84da66e72386&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1a703653ef39737083a1d7ae0bb07d6d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029563&auth_key=1760029563-0-0-dbea69e48c67fda27ef69da4398940e0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-251425028bcf6ed3241d02c5eb83e868~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029570&auth_key=1760029570-0-0-912c285bdffe8dc1c95e9dd0782d6513&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Trade-offs-in-Cross-Domain-Generalization-of-Foundation-Model-Fine-Tuned-for-Biometric-Applications"><a href="#Trade-offs-in-Cross-Domain-Generalization-of-Foundation-Model-Fine-Tuned-for-Biometric-Applications" class="headerlink" title="Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned   for Biometric Applications"></a>Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned   for Biometric Applications</h2><p><strong>Authors:Tahar Chettaoui, Naser Damer, Fadi Boutros</strong></p>
<p>Foundation models such as CLIP have demonstrated exceptional zero- and few-shot transfer capabilities across diverse vision tasks. However, when fine-tuned for highly specialized biometric tasks, face recognition (FR), morphing attack detection (MAD), and presentation attack detection (PAD), these models may suffer from over-specialization. Thus, they may lose one of their foundational strengths, cross-domain generalization. In this work, we systematically quantify these trade-offs by evaluating three instances of CLIP fine-tuned for FR, MAD, and PAD. We evaluate each adapted model as well as the original CLIP baseline on 14 general vision datasets under zero-shot and linear-probe protocols, alongside common FR, MAD, and PAD benchmarks. Our results indicate that fine-tuned models suffer from over-specialization, especially when fine-tuned for complex tasks of FR. Also, our results pointed out that task complexity and classification head design, multi-class (FR) vs. binary (MAD and PAD), correlate with the degree of catastrophic forgetting. The FRoundation model with the ViT-L backbone outperforms other approaches on the large-scale FR benchmark IJB-C, achieving an improvement of up to 58.52%. However, it experiences a substantial performance drop on ImageNetV2, reaching only 51.63% compared to 69.84% achieved by the baseline CLIP model. Moreover, the larger CLIP architecture consistently preserves more of the modelâ€™s original generalization ability than the smaller variant, indicating that increased model capacity may help mitigate over-specialization. </p>
<blockquote>
<p>è¯¸å¦‚CLIPç­‰åŸºç¡€æ¨¡å‹åœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å‡ºè‰²çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“é’ˆå¯¹é«˜åº¦ä¸“ä¸šåŒ–çš„ç”Ÿç‰©è¯†åˆ«ä»»åŠ¡ï¼ˆå¦‚äººè„¸è¯†åˆ«ï¼ˆFRï¼‰ã€å½¢æ€æ”»å‡»æ£€æµ‹ï¼ˆMADï¼‰å’Œå‘ˆç°æ”»å‡»æ£€æµ‹ï¼ˆPADï¼‰ï¼‰è¿›è¡Œå¾®è°ƒæ—¶ï¼Œè¿™äº›æ¨¡å‹å¯èƒ½ä¼šè¿‡åº¦ä¸“ä¸šåŒ–ã€‚å› æ­¤ï¼Œå®ƒä»¬å¯èƒ½ä¼šä¸§å¤±å…¶åŸºç¡€ä¼˜åŠ¿ä¹‹ä¸€ï¼Œå³è·¨åŸŸæ³›åŒ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è¯„ä¼°é’ˆå¯¹FRã€MADå’ŒPADå¾®è°ƒçš„ä¸‰ä¾‹CLIPæ¥ç³»ç»Ÿåœ°é‡åŒ–è¿™äº›æƒè¡¡ã€‚æˆ‘ä»¬è¯„ä¼°æ¯ä¸ªé€‚é…æ¨¡å‹ä»¥åŠåŸå§‹CLIPåŸºå‡†çº¿åœ¨é›¶æ ·æœ¬å’Œçº¿æ€§æ¢é’ˆåè®®ä¸‹çš„14ä¸ªé€šç”¨è§†è§‰æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶è¿˜æœ‰äººè„¸è¯†åˆ«ã€å½¢æ€æ”»å‡»æ£€æµ‹å’Œå‘ˆç°æ”»å‡»æ£€æµ‹çš„å¸¸è§åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¾®è°ƒæ¨¡å‹å­˜åœ¨è¿‡åº¦ä¸“ä¸šåŒ–çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é’ˆå¯¹å¤æ‚çš„äººè„¸è¯†åˆ«ä»»åŠ¡è¿›è¡Œå¾®è°ƒæ—¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœè¿˜æŒ‡å‡ºï¼Œä»»åŠ¡å¤æ‚æ€§å’Œåˆ†ç±»å¤´éƒ¨è®¾è®¡ï¼ˆå¤šç±»ï¼ˆäººè„¸è¯†åˆ«ï¼‰ä¸äºŒå…ƒï¼ˆå½¢æ€æ”»å‡»æ£€æµ‹å’Œå‘ˆç°æ”»å‡»æ£€æµ‹ï¼‰ï¼‰ä¸ç¾éš¾æ€§é—å¿˜çš„ç¨‹åº¦æœ‰å…³ã€‚å…·æœ‰ViT-Lä¸»å¹²çš„åŸºç¡€æ¨¡å‹åœ¨å¤§è§„æ¨¡äººè„¸è¯†åˆ«åŸºå‡†æµ‹è¯•IJB-Cä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæé«˜äº†é«˜è¾¾58.52%ã€‚ç„¶è€Œï¼Œå®ƒåœ¨ImageNetV2ä¸Šçš„æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œä»…è¾¾åˆ°51.63%ï¼Œè€ŒåŸºçº¿CLIPæ¨¡å‹åˆ™è¾¾åˆ°äº†69.84%ã€‚æ­¤å¤–ï¼Œè¾ƒå¤§çš„CLIPæ¶æ„å§‹ç»ˆä¿ç•™äº†æ¨¡å‹æ›´å¤šçš„åŸå§‹æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æš—ç¤ºç€å¢åŠ æ¨¡å‹å®¹é‡å¯èƒ½æœ‰åŠ©äºç¼“è§£è¿‡åº¦ä¸“ä¸šåŒ–çš„é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14921v1">PDF</a> Accepted at the IEEE International Joint Conference on Biometrics   2025 (IJCB 2025)</p>
<p><strong>Summary</strong><br>    æœ¬ç ”ç©¶æ¢è®¨äº†CLIPç­‰åŸºç¡€æ¨¡å‹åœ¨äººè„¸è¯†åˆ«ï¼ˆFRï¼‰ã€å½¢æ€æ”»å‡»æ£€æµ‹ï¼ˆMADï¼‰å’Œå‘ˆç°æ”»å‡»æ£€æµ‹ï¼ˆPADï¼‰ç­‰é«˜åº¦ä¸“ä¸šåŒ–ç”Ÿç‰©è¯†åˆ«ä»»åŠ¡ä¸Šçš„å¾®è°ƒè¡¨ç°ï¼Œå‘ç°è¿™äº›æ¨¡å‹å¯èƒ½å› è¿‡åº¦ä¸“ä¸šåŒ–è€Œä¸§å¤±è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚åœ¨å¤šç§é€šç”¨è§†è§‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå¾®è°ƒæ¨¡å‹åœ¨é›¶æ ·æœ¬å’Œçº¿æ€§æ¢æµ‹åè®®ä¸‹å‡ºç°è¿‡åº¦ä¸“ä¸šåŒ–ç°è±¡ï¼Œç‰¹åˆ«æ˜¯é¢å¯¹å¤æ‚çš„äººè„¸è¯†åˆ«ä»»åŠ¡æ—¶ã€‚åŒæ—¶ï¼Œä»»åŠ¡å¤æ‚åº¦å’Œåˆ†ç±»å¤´éƒ¨è®¾è®¡ï¼ˆå¤šç±»äººè„¸è¯†åˆ«ä¸äºŒå…ƒæ”»å‡»æ£€æµ‹ï¼‰ä¸ç¾éš¾æ€§é—å¿˜ç¨‹åº¦ç›¸å…³ã€‚æ­¤å¤–ï¼Œå…·æœ‰ViT-Lä¸»å¹²çš„åŸºç¡€æ¨¡å‹åœ¨å¤§å‹äººè„¸è¯†åˆ«åŸºå‡†æµ‹è¯•IJB-Cä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ImageNetV2ä¸Šçš„æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚æ›´å¤§è§„æ¨¡çš„CLIPæ¶æ„æ›´èƒ½ä¿æŒæ¨¡å‹çš„åŸå§‹æ³›åŒ–èƒ½åŠ›ï¼Œè¡¨æ˜å¢åŠ æ¨¡å‹å®¹é‡å¯èƒ½æœ‰åŠ©äºç¼“è§£è¿‡åº¦ä¸“ä¸šåŒ–é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºç¡€æ¨¡å‹å¦‚CLIPåœ¨é«˜åº¦ä¸“ä¸šåŒ–çš„ç”Ÿç‰©è¯†åˆ«ä»»åŠ¡ï¼ˆå¦‚äººè„¸è¯†åˆ«ã€å½¢æ€æ”»å‡»æ£€æµ‹ã€å‘ˆç°æ”»å‡»æ£€æµ‹ï¼‰ä¸Šç»è¿‡å¾®è°ƒåå¯èƒ½é¢ä¸´è¿‡åº¦ä¸“ä¸šåŒ–çš„é—®é¢˜ï¼Œå¯¼è‡´ä¸§å¤±è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨é€šç”¨è§†è§‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå¾®è°ƒæ¨¡å‹åœ¨é›¶æ ·æœ¬å’Œçº¿æ€§æ¢æµ‹åè®®ä¸‹å‡ºç°è¿‡åº¦ä¸“ä¸šåŒ–ç°è±¡ã€‚</li>
<li>ä»»åŠ¡å¤æ‚åº¦å’Œåˆ†ç±»å¤´éƒ¨è®¾è®¡ï¼ˆå¤šç±»ä¸äºŒå…ƒï¼‰ä¸ç¾éš¾æ€§é—å¿˜ç¨‹åº¦æœ‰å…³ã€‚</li>
<li>å…·æœ‰ViT-Lä¸»å¹²çš„åŸºç¡€æ¨¡å‹åœ¨äººè„¸è¯†åˆ«åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å…¶ä»–å¤§å‹å›¾åƒæ•°æ®é›†ä¸Šçš„æ€§èƒ½å¯èƒ½ä¸‹é™ã€‚</li>
<li>æ›´å¤§è§„æ¨¡çš„CLIPæ¶æ„èƒ½å¤Ÿæ›´å¥½åœ°ä¿æŒæ¨¡å‹çš„åŸå§‹æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¢åŠ æ¨¡å‹å®¹é‡å¯èƒ½æœ‰åŠ©äºç¼“è§£è¿‡åº¦ä¸“ä¸šåŒ–é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14921">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f21e63aa19fa56bc11eefcb9d2ddebcc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029578&auth_key=1760029578-0-0-998f3478eee96ffd997b913b2660494d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-34122b936f0b517a163ae81dd4b6a27a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029585&auth_key=1760029585-0-0-31be44ad9f3a616503504fe1bcd9a2c3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7de623561dbef88f6c8c91254b16bd0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029591&auth_key=1760029591-0-0-187558681f8199329d3f2d8b61bc65b4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-Data-and-Parameter-Efficient-Strategies-for-Arabic-Dialect-Identifications"><a href="#Exploring-Data-and-Parameter-Efficient-Strategies-for-Arabic-Dialect-Identifications" class="headerlink" title="Exploring Data and Parameter Efficient Strategies for Arabic Dialect   Identifications"></a>Exploring Data and Parameter Efficient Strategies for Arabic Dialect   Identifications</h2><p><strong>Authors:Vani Kanjirangat, Ljiljana Dolamic, Fabio Rinaldi</strong></p>
<p>This paper discusses our exploration of different data-efficient and parameter-efficient approaches to Arabic Dialect Identification (ADI). In particular, we investigate various soft-prompting strategies, including prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA reparameterizations. For the data-efficient strategy, we analyze hard prompting with zero-shot and few-shot inferences to analyze the dialect identification capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT approaches, we conducted our experiments using Arabic-specific encoder models on several major datasets. We also analyzed the n-shot inferences on open-source decoder-only models, a general multilingual model (Phi-3.5), and an Arabic-specific one(SILMA). We observed that the LLMs generally struggle to differentiate the dialectal nuances in the few-shot or zero-shot setups. The soft-prompted encoder variants perform better, while the LoRA-based fine-tuned models perform best, even surpassing full fine-tuning. </p>
<blockquote>
<p>æœ¬æ–‡è®¨è®ºäº†æˆ‘ä»¬åœ¨é˜¿æ‹‰ä¼¯è¯­æ–¹è¨€è¯†åˆ«ï¼ˆADIï¼‰æ–¹é¢å¯¹ä¸åŒæ•°æ®é«˜æ•ˆå’Œå‚æ•°é«˜æ•ˆæ–¹æ³•çš„æ¢ç´¢ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å„ç§è½¯æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬å‰ç¼€è°ƒæ•´ã€æç¤ºè°ƒæ•´ã€P-tuningå’ŒP-tuning V2ï¼Œä»¥åŠLoRAé‡æ–°å‚æ•°åŒ–ã€‚å¯¹äºæ•°æ®é«˜æ•ˆç­–ç•¥ï¼Œæˆ‘ä»¬åˆ†æäº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ¨æ–­ä¸­çš„ç¡¬æç¤ºï¼Œä»¥åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹è¨€è¯†åˆ«èƒ½åŠ›ã€‚å¯¹äºå‚æ•°é«˜æ•ˆçš„PEFTæ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨å‡ ä¸ªä¸»è¦æ•°æ®é›†ä¸Šä½¿ç”¨äº†é˜¿æ‹‰ä¼¯è¯­è¨€ç‰¹å®šç¼–ç å™¨æ¨¡å‹è¿›è¡Œå®éªŒã€‚æˆ‘ä»¬è¿˜åˆ†æäº†å¼€æºè§£ç å™¨æ¨¡å‹ã€é€šç”¨å¤šè¯­è¨€æ¨¡å‹ï¼ˆPhi-3.5ï¼‰å’Œé˜¿æ‹‰ä¼¯è¯­è¨€ç‰¹å®šæ¨¡å‹ï¼ˆSILMAï¼‰çš„næ¬¡å°„å‡»æ¨æ–­ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹é€šå¸¸åœ¨å°‘æ ·æœ¬æˆ–é›¶æ ·æœ¬è®¾ç½®ä¸­éš¾ä»¥åŒºåˆ†æ–¹è¨€ç»†å¾®å·®åˆ«ã€‚è½¯æç¤ºç¼–ç å™¨å˜ä½“è¡¨ç°æ›´å¥½ï¼Œè€ŒåŸºäºLoRAçš„å¾®è°ƒæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œç”šè‡³è¶…è¿‡äº†å…¨é‡å¾®è°ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13775v2">PDF</a> 4 main pages, 4 additional, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ•°æ®é«˜æ•ˆå’Œå‚æ•°é«˜æ•ˆçš„é˜¿æ‹‰ä¼¯è¯­æ–¹è¨€è¯†åˆ«ï¼ˆADIï¼‰æ–¹æ³•ã€‚ç ”ç©¶äº†å¤šç§è½¯æç¤ºç­–ç•¥ï¼Œå¦‚å‰ç¼€è°ƒæ•´ã€æç¤ºè°ƒæ•´ã€P-tuningå’ŒP-tuning V2ï¼Œä»¥åŠLoRAé‡æ–°å‚æ•°åŒ–ã€‚å¯¹äºæ•°æ®é«˜æ•ˆç­–ç•¥ï¼Œæˆ‘ä»¬åˆ†æäº†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ¨æ–­ä¸‹çš„ç¡¬æç¤ºæ–¹æ³•ï¼Œä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹è¨€è¯†åˆ«èƒ½åŠ›ã€‚å¯¹äºå‚æ•°é«˜æ•ˆçš„PEFTæ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªä¸»è¦æ•°æ®é›†ä¸Šè¿›è¡Œäº†é˜¿æ‹‰ä¼¯è¯­ç‰¹å®šç¼–ç å™¨æ¨¡å‹çš„å®éªŒï¼Œå¹¶åˆ†æäº†å¼€æºè§£ç å™¨æ¨¡å‹ã€é€šç”¨å¤šè¯­è¨€æ¨¡å‹ï¼ˆPhi-3.5ï¼‰å’Œé˜¿æ‹‰ä¼¯è¯­ç‰¹å®šæ¨¡å‹ï¼ˆSILMAï¼‰çš„n-shotæ¨æ–­ç»“æœã€‚è§‚å¯Ÿåˆ°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å°‘æ ·æœ¬æˆ–é›¶æ ·æœ¬è®¾ç½®ä¸­éš¾ä»¥åŒºåˆ†æ–¹è¨€ç»†å¾®å·®åˆ«ã€‚è½¯æç¤ºç¼–ç å™¨å˜ä½“è¡¨ç°è¾ƒå¥½ï¼Œè€ŒåŸºäºLoRAçš„ç²¾ç»†è°ƒæ•´æ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œç”šè‡³è¶…è¶Šå…¨ç²¾ç»†è°ƒæ•´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡æ¢è®¨äº†æ•°æ®é«˜æ•ˆå’Œå‚æ•°é«˜æ•ˆçš„é˜¿æ‹‰ä¼¯è¯­æ–¹è¨€è¯†åˆ«æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶äº†å¤šç§è½¯æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬å‰ç¼€è°ƒæ•´ã€æç¤ºè°ƒæ•´ç­‰ã€‚</li>
<li>åœ¨æ•°æ®é«˜æ•ˆç­–ç•¥æ–¹é¢ï¼Œç¡¬æç¤ºæ–¹æ³•ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹è¨€è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>åœ¨å‚æ•°é«˜æ•ˆçš„å®éªŒä¸­ï¼Œä½¿ç”¨äº†é˜¿æ‹‰ä¼¯è¯­ç‰¹å®šç¼–ç å™¨æ¨¡å‹å¹¶è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚</li>
<li>LLMåœ¨å°‘æ ·æœ¬æˆ–é›¶æ ·æœ¬è®¾ç½®ä¸­æ–¹è¨€è¯†åˆ«èƒ½åŠ›å—é™ã€‚</li>
<li>è½¯æç¤ºç¼–ç å™¨å˜ä½“åœ¨æ–¹è¨€è¯†åˆ«ä¸­è¡¨ç°è¾ƒå¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13775">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-63ee891ddcf7f6225d9bf665007e14d7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029599&auth_key=1760029599-0-0-95579027a5f913ffdf0074599bef30bb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1256a228e2b26db63cd06c65b77c479b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029606&auth_key=1760029606-0-0-33d699b56bd4459c8a7b015b374c3a37&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9ebb80089163d7e56d48bb3ee763efaa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029612&auth_key=1760029612-0-0-9c9aa69211270907f1dbfdf0a57c6f78&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ThinkAct-Vision-Language-Action-Reasoning-via-Reinforced-Visual-Latent-Planning"><a href="#ThinkAct-Vision-Language-Action-Reasoning-via-Reinforced-Visual-Latent-Planning" class="headerlink" title="ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent   Planning"></a>ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent   Planning</h2><p><strong>Authors:Chi-Pin Huang, Yueh-Hua Wu, Min-Hung Chen, Yu-Chiang Frank Wang, Fu-En Yang</strong></p>
<p>Vision-language-action (VLA) reasoning tasks require agents to interpret multimodal instructions, perform long-horizon planning, and act adaptively in dynamic environments. Existing approaches typically train VLA models in an end-to-end fashion, directly mapping inputs to actions without explicit reasoning, which hinders their ability to plan over multiple steps or adapt to complex task variations. In this paper, we propose ThinkAct, a dual-system framework that bridges high-level reasoning with low-level action execution via reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate embodied reasoning plans guided by reinforcing action-aligned visual rewards based on goal completion and trajectory consistency. These reasoning plans are compressed into a visual plan latent that conditions a downstream action model for robust action execution on target environments. Extensive experiments on embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct enables few-shot adaptation, long-horizon planning, and self-correction behaviors in complex embodied AI tasks. </p>
<blockquote>
<p>è§†è§‰-è¯­è¨€-è¡ŒåŠ¨ï¼ˆVLAï¼‰æ¨ç†ä»»åŠ¡è¦æ±‚æ™ºèƒ½ä½“è§£é‡Šå¤šæ¨¡å¼æŒ‡ä»¤ï¼Œè¿›è¡Œé•¿æœŸè§„åˆ’ï¼Œå¹¶åœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œè‡ªé€‚åº”è¡ŒåŠ¨ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è®­ç»ƒVLAæ¨¡å‹ï¼Œç›´æ¥å°†è¾“å…¥æ˜ å°„åˆ°è¡ŒåŠ¨ï¼Œè€Œæ²¡æœ‰æ˜ç¡®çš„æ¨ç†ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨å¤šä¸ªæ­¥éª¤ä¸Šè¿›è¡Œè§„åˆ’æˆ–é€‚åº”å¤æ‚ä»»åŠ¡å˜åŒ–çš„èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ThinkActï¼Œè¿™æ˜¯ä¸€ä¸ªåŒç³»ç»Ÿæ¡†æ¶ï¼Œå®ƒé€šè¿‡å¼ºåŒ–è§†è§‰æ½œåœ¨è§„åˆ’ï¼Œå°†é«˜çº§æ¨ç†ä¸ä½çº§è¡ŒåŠ¨æ‰§è¡Œè”ç³»èµ·æ¥ã€‚ThinkActè®­ç»ƒäº†ä¸€ä¸ªå¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®ç›®æ ‡å®Œæˆå’Œè½¨è¿¹ä¸€è‡´æ€§ç”Ÿæˆå¼ºåŒ–è¡ŒåŠ¨å¯¹é½çš„è§†è§‰å¥–åŠ±æ¥æŒ‡å¯¼å…·è±¡åŒ–æ¨ç†è®¡åˆ’ã€‚è¿™äº›æ¨ç†è®¡åˆ’è¢«å‹ç¼©æˆè§†è§‰è®¡åˆ’æ½œåœ¨çŠ¶æ€ï¼Œä»¥åœ¨ç›®æ ‡ç¯å¢ƒä¸­å¯¹ä¸‹æ¸¸è¡ŒåŠ¨æ¨¡å‹è¿›è¡Œç¨³å¥çš„è¡ŒåŠ¨æ‰§è¡Œã€‚åœ¨å…·è±¡æ¨ç†å’Œæœºå™¨äººæ“ä½œåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒThinkActèƒ½å¤Ÿåœ¨å¤æ‚çš„åµŒå…¥å¼AIä»»åŠ¡ä¸­å®ç°å°‘é‡é€‚åº”ã€é•¿æœŸè§„åˆ’å’Œè‡ªæˆ‘ä¿®æ­£è¡Œä¸ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.16815v2">PDF</a> NeurIPS 2025. Project page:   <a target="_blank" rel="noopener" href="https://jasper0314-huang.github.io/thinkact-vla/">https://jasper0314-huang.github.io/thinkact-vla/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºThinkActçš„åŒå‘ç³»ç»Ÿæ¡†æ¶ï¼Œç”¨äºå®ç°è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨ç†ä»»åŠ¡ä¸­çš„é«˜çº§æ¨ç†ä¸ä½çº§åŠ¨ä½œæ‰§è¡Œçš„æ¡¥æ¢ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼ºåŒ–è§†è§‰æ½œåœ¨è§„åˆ’ï¼Œç”Ÿæˆä»¥è¡ŒåŠ¨å¯¹é½çš„è§†è§‰å¥–åŠ±ä¸ºæŒ‡å¯¼çš„å®ä½“æ¨ç†è®¡åˆ’ã€‚è¿™äº›æ¨ç†è®¡åˆ’è¢«å‹ç¼©æˆè§†è§‰è®¡åˆ’æ½œåœ¨çŠ¶æ€ï¼Œä»¥åœ¨ç›®æ ‡ç¯å¢ƒä¸­è¿›è¡Œç¨³å¥çš„åŠ¨ä½œæ‰§è¡Œã€‚ThinkActèƒ½å¤Ÿåœ¨å¤æ‚çš„å®ä½“AIä»»åŠ¡ä¸­å®ç°å°‘é‡é€‚åº”ã€é•¿æœŸè§„åˆ’å’Œè‡ªæˆ‘æ ¡æ­£è¡Œä¸ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ThinkActæ˜¯ä¸€ä¸ªåŒç³»ç»Ÿæ¡†æ¶ï¼Œç»“åˆäº†é«˜çº§æ¨ç†å’Œä½çº§åŠ¨ä½œæ‰§è¡Œã€‚</li>
<li>é€šè¿‡å¼ºåŒ–è§†è§‰æ½œåœ¨è§„åˆ’æ¥å®ç°VLAä»»åŠ¡ã€‚</li>
<li>ç”Ÿæˆä»¥è¡ŒåŠ¨å¯¹é½çš„è§†è§‰å¥–åŠ±ä¸ºæŒ‡å¯¼çš„å®ä½“æ¨ç†è®¡åˆ’ã€‚</li>
<li>æ¨ç†è®¡åˆ’è¢«å‹ç¼©æˆè§†è§‰è®¡åˆ’æ½œåœ¨çŠ¶æ€ä»¥æŒ‡å¯¼åŠ¨ä½œæ‰§è¡Œã€‚</li>
<li>ThinkActèƒ½å¤Ÿåœ¨å¤æ‚çš„å®ä½“AIä»»åŠ¡ä¸­å®ç°å°‘é‡é€‚åº”ã€‚</li>
<li>å…·å¤‡é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.16815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e856f7068800be5947fc00d6c082cf2d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029620&auth_key=1760029620-0-0-2b7fa70ea3223f9170a91896f28be578&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-26165280aef05380758055dc6996ac68~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029627&auth_key=1760029627-0-0-29f2d9c267a4fb36bc7e140267eb6d21&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6087562152b4780163d95b6009a36d66~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029635&auth_key=1760029635-0-0-918e6ceafcae88d351de2b62e273f7d4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Self-Adapting-Language-Models"><a href="#Self-Adapting-Language-Models" class="headerlink" title="Self-Adapting Language Models"></a>Self-Adapting Language Models</h2><p><strong>Authors:Adam Zweiger, Jyothish Pari, Han Guo, Ekin AkyÃ¼rek, Yoon Kim, Pulkit Agrawal</strong></p>
<p>Large language models (LLMs) are powerful but static; they lack mechanisms to adapt their weights in response to new tasks, knowledge, or examples. We introduce Self-Adapting LLMs (SEAL), a framework that enables LLMs to self-adapt by generating their own finetuning data and update directives. Given a new input, the model produces a self-edit-a generation that may restructure the information in different ways, specify optimization hyperparameters, or invoke tools for data augmentation and gradient-based updates. Through supervised finetuning (SFT), these self-edits result in persistent weight updates, enabling lasting adaptation. To train the model to produce effective self-edits, we use a reinforcement learning loop with the downstream performance of the updated model as the reward signal. Unlike prior approaches that rely on separate adaptation modules or auxiliary networks, SEAL directly uses the modelâ€™s own generation to control its adaptation process. Experiments on knowledge incorporation and few-shot generalization show that SEAL is a promising step toward language models capable of self-directed adaptation. Our website and code is available at <a target="_blank" rel="noopener" href="https://jyopari.github.io/posts/seal">https://jyopari.github.io/posts/seal</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è™½ç„¶å¼ºå¤§ä½†é™æ€ï¼Œç¼ºä¹æ ¹æ®æ–°ä»»åŠ¡ã€çŸ¥è¯†æˆ–ç¤ºä¾‹è°ƒæ•´å…¶æƒé‡çš„æœºåˆ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†è‡ªé€‚åº”è¯­è¨€æ¨¡å‹ï¼ˆSEALï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œå…è®¸LLMé€šè¿‡ç”Ÿæˆè‡ªå·±çš„å¾®è°ƒæ•°æ®å’Œæ›´æ–°æŒ‡ä»¤è¿›è¡Œè‡ªæˆ‘é€‚åº”ã€‚å¯¹äºæ–°çš„è¾“å…¥ï¼Œæ¨¡å‹ä¼šäº§ç”Ÿè‡ªæˆ‘ç¼–è¾‘çš„ç‰ˆæœ¬ï¼Œè¿™ä¸ªç‰ˆæœ¬å¯èƒ½ä¼šä»¥ä¸åŒçš„æ–¹å¼é‡æ–°ç»„ç»‡ä¿¡æ¯ï¼ŒæŒ‡å®šä¼˜åŒ–è¶…å‚æ•°ï¼Œæˆ–è°ƒç”¨æ•°æ®å¢å¼ºå·¥å…·å’ŒåŸºäºæ¢¯åº¦çš„æ›´æ–°å·¥å…·ã€‚é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œè¿™äº›è‡ªæˆ‘ç¼–è¾‘ä¼šå¯¼è‡´æŒä¹…çš„æƒé‡æ›´æ–°ï¼Œä»è€Œå®ç°æŒä¹…çš„é€‚åº”ã€‚ä¸ºäº†è®­ç»ƒæ¨¡å‹äº§ç”Ÿæœ‰æ•ˆçš„è‡ªæˆ‘ç¼–è¾‘ï¼Œæˆ‘ä»¬ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¾ªç¯ï¼Œä»¥æ›´æ–°æ¨¡å‹çš„ä¸‹æ¸¸æ€§èƒ½ä½œä¸ºå¥–åŠ±ä¿¡å·ã€‚ä¸åŒäºä¾èµ–å•ç‹¬é€‚åº”æ¨¡å—æˆ–è¾…åŠ©ç½‘ç»œçš„å…ˆå‰æ–¹æ³•ï¼ŒSEALç›´æ¥ä½¿ç”¨æ¨¡å‹è‡ªèº«çš„ç”Ÿæˆæ¥æ§åˆ¶å…¶é€‚åº”è¿‡ç¨‹ã€‚åœ¨çŸ¥è¯†æ•´åˆå’Œå°‘é‡æ ·æœ¬æ³›åŒ–æ–¹é¢çš„å®éªŒè¡¨æ˜ï¼ŒSEALæ˜¯æœç€èƒ½å¤Ÿè‡ªæˆ‘æŒ‡å¯¼é€‚åº”çš„è¯­è¨€æ¨¡å‹è¿ˆå‡ºçš„æœ‰å‰æ™¯çš„ä¸€æ­¥ã€‚æˆ‘ä»¬çš„ç½‘ç«™å’Œä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://jyopari.github.io/posts/seal%E8%AE%BF%E9%97%AE%E3%80%82">https://jyopari.github.io/posts/sealè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10943v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠŸèƒ½å¼ºå¤§ä½†é™æ€ä¸å˜ï¼Œæ— æ³•æ ¹æ®æ–°ä»»åŠ¡ã€çŸ¥è¯†æˆ–ç¤ºä¾‹è°ƒæ•´è‡ªèº«æƒé‡ã€‚æˆ‘ä»¬æå‡ºSelf-Adapting LLMsï¼ˆSEALï¼‰æ¡†æ¶ï¼Œä½¿LLMsèƒ½å¤Ÿé€šè¿‡ç”Ÿæˆè‡ªèº«çš„å¾®è°ƒæ•°æ®å’Œæ›´æ–°æŒ‡ä»¤æ¥å®ç°è‡ªæˆ‘é€‚åº”ã€‚å¯¹äºæ–°è¾“å…¥çš„ä¿¡æ¯ï¼Œæ¨¡å‹ä¼šäº§ç”Ÿè‡ªæˆ‘ç¼–è¾‘ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰äº§ç”ŸæŒä¹…æ€§çš„æƒé‡æ›´æ–°ï¼Œå®ç°é•¿æœŸé€‚åº”ã€‚æˆ‘ä»¬é€šè¿‡å¼ºåŒ–å­¦ä¹ å¾ªç¯è®­ç»ƒæ¨¡å‹äº§ç”Ÿæœ‰æ•ˆçš„è‡ªæˆ‘ç¼–è¾‘ï¼Œä»¥æ›´æ–°æ¨¡å‹çš„ä¸‹æ¸¸æ€§èƒ½ä½œä¸ºå¥–åŠ±ä¿¡å·ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–é¢å¤–é€‚åº”æ¨¡å—æˆ–è¾…åŠ©ç½‘ç»œçš„æ–¹æ³•ï¼ŒSEALç›´æ¥åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„ç”Ÿæˆæ¥æ§åˆ¶å…¶é€‚åº”è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼ŒSEALåœ¨çŸ¥è¯†èåˆå’Œå°‘é‡æ ·æœ¬æ³›åŒ–æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæ˜¯å‘èƒ½å¤Ÿè‡ªæˆ‘å®šå‘é€‚åº”çš„è¯­è¨€æ¨¡å‹è¿ˆè¿›çš„é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsè™½ç„¶å¼ºå¤§ï¼Œä½†ç¼ºä¹æ ¹æ®æ–°ä»»åŠ¡ã€çŸ¥è¯†æˆ–ç¤ºä¾‹è‡ªæˆ‘è°ƒæ•´çš„èƒ½åŠ›ã€‚</li>
<li>SEALæ¡†æ¶ä½¿LLMsèƒ½å¤Ÿé€šè¿‡ç”Ÿæˆè‡ªæˆ‘ç¼–è¾‘æ•°æ®å’ŒæŒ‡ä»¤æ¥å®ç°è‡ªæˆ‘é€‚åº”ã€‚</li>
<li>æ¨¡å‹äº§ç”Ÿçš„è‡ªæˆ‘ç¼–è¾‘å¯ä»¥é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å¯¼è‡´æŒä¹…çš„æƒé‡æ›´æ–°ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ å¾ªç¯ç”¨äºè®­ç»ƒæ¨¡å‹äº§ç”Ÿæœ‰æ•ˆçš„è‡ªæˆ‘ç¼–è¾‘ã€‚</li>
<li>æ¨¡å‹ä¸‹æ¸¸æ€§èƒ½ä½œä¸ºå¥–åŠ±ä¿¡å·æ¥è¯„ä¼°è‡ªæˆ‘ç¼–è¾‘çš„æ•ˆæœã€‚</li>
<li>ä¸å…¶ä»–é€‚åº”æ¨¡å—æˆ–è¾…åŠ©ç½‘ç»œä¸åŒï¼ŒSEALåˆ©ç”¨æ¨¡å‹è‡ªèº«çš„ç”Ÿæˆæ¥æ§åˆ¶é€‚åº”è¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10943">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-47b41faf0a772c46b5006145033d386e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029642&auth_key=1760029642-0-0-d74eedf92d41d736ba47ad343ae391a5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8e44568cb184743b4959907b0f9ce90e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029649&auth_key=1760029649-0-0-a3ebba0daa2767263f53946f4551d963&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a753461583488b92e0b9e22800090050~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029656&auth_key=1760029656-0-0-cd5e157572b1b50c902d3f6eb01e150e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ebc40b6d26a274647b2f4bef3d56e414~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029663&auth_key=1760029663-0-0-712070ee30722f94c297571fc38c0541&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MOLE-Metadata-Extraction-and-Validation-in-Scientific-Papers-Using-LLMs"><a href="#MOLE-Metadata-Extraction-and-Validation-in-Scientific-Papers-Using-LLMs" class="headerlink" title="MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs"></a>MOLE: Metadata Extraction and Validation in Scientific Papers Using LLMs</h2><p><strong>Authors:Zaid Alyafeai, Maged S. Al-Shaibani, Bernard Ghanem</strong></p>
<p>Metadata extraction is essential for cataloging and preserving datasets, enabling effective research discovery and reproducibility, especially given the current exponential growth in scientific research. While Masader (Alyafeai et al.,2021) laid the groundwork for extracting a wide range of metadata attributes from Arabic NLP datasetsâ€™ scholarly articles, it relies heavily on manual annotation. In this paper, we present MOLE, a framework that leverages Large Language Models (LLMs) to automatically extract metadata attributes from scientific papers covering datasets of languages other than Arabic. Our schema-driven methodology processes entire documents across multiple input formats and incorporates robust validation mechanisms for consistent output. Additionally, we introduce a new benchmark to evaluate the research progress on this task. Through systematic analysis of context length, few-shot learning, and web browsing integration, we demonstrate that modern LLMs show promising results in automating this task, highlighting the need for further future work improvements to ensure consistent and reliable performance. We release the code: <a target="_blank" rel="noopener" href="https://github.com/IVUL-KAUST/MOLE">https://github.com/IVUL-KAUST/MOLE</a> and dataset: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/IVUL-KAUST/MOLE">https://huggingface.co/datasets/IVUL-KAUST/MOLE</a> for the research community. </p>
<blockquote>
<p>å…ƒæ•°æ®æå–å¯¹äºæ•°æ®é›†ç¼–ç›®å’Œä¿å­˜è‡³å…³é‡è¦ï¼Œå®ƒä¿ƒè¿›äº†æœ‰æ•ˆçš„ç ”ç©¶å‘ç°å’Œå¯é‡å¤æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å½“å‰ç§‘å­¦ç ”ç©¶å‘ˆæŒ‡æ•°çº§å¢é•¿çš„æƒ…å†µä¸‹ã€‚è™½ç„¶Masaderï¼ˆAlyafeaiç­‰äººï¼Œ2021å¹´ï¼‰å¥ å®šäº†ä»é˜¿æ‹‰ä¼¯è¯­NLPæ•°æ®é›†å­¦æœ¯è®ºæ–‡ä¸­æå–å¹¿æ³›å…ƒæ•°æ®å±æ€§çš„åŸºç¡€ï¼Œä½†å®ƒä¸»è¦ä¾èµ–äºäººå·¥æ ‡æ³¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†MOLEæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨ä»æ¶‰åŠéé˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†çš„ç§‘å­¦è®ºæ–‡ä¸­æå–å…ƒæ•°æ®å±æ€§ã€‚æˆ‘ä»¬çš„åŸºäºæ¨¡å¼çš„æ–¹æ³•å¤„ç†å¤šç§è¾“å…¥æ ¼å¼çš„æ•´ä¸ªæ–‡æ¡£ï¼Œå¹¶åŒ…å«ç”¨äºä¸€è‡´è¾“å‡ºçš„ç¨³å¥éªŒè¯æœºåˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æ­¤ä»»åŠ¡çš„ç ”ç©¶è¿›å±•ã€‚é€šè¿‡ç³»ç»Ÿåˆ†æä¸Šä¸‹æ–‡é•¿åº¦ã€å°æ ·æœ¬å­¦ä¹ å’Œç½‘é¡µæµè§ˆé›†æˆï¼Œæˆ‘ä»¬è¯æ˜äº†ç°ä»£LLMåœ¨è¯¥ä»»åŠ¡çš„è‡ªåŠ¨åŒ–æ–¹é¢æ˜¾ç¤ºå‡ºæœ‰å‰é€”çš„ç»“æœï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›å·¥ä½œä»¥ç¡®ä¿æ€§èƒ½å’Œå¯é æ€§çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å‘ç ”ç©¶ç¤¾åŒºå‘å¸ƒä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/IVUL-KAUST/MOLE%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9Ahttps://huggingface.co/datasets/IVUL-KAUST/MOLE%E3%80%82">https://github.com/IVUL-KAUST/MOLEå’Œæ•°æ®é›†ï¼šhttps://huggingface.co/datasets/IVUL-KAUST/MOLEã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19800v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†MOLEæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨ä»éé˜¿æ‹‰ä¼¯è¯­çš„ç§‘å­¦è®ºæ–‡ä¸­æå–å…ƒæ•°æ®å±æ€§ã€‚æ­¤æ¡†æ¶æ˜¯è‡ªåŠ¨çš„ï¼Œå¯ä»¥åœ¨å¤šç§è¾“å…¥æ ¼å¼ä¸‹å¤„ç†æ•´ä¸ªæ–‡æ¡£ï¼Œå¹¶åŒ…å«ç¨³å¥çš„éªŒè¯æœºåˆ¶ä»¥ç¡®ä¿ä¸€è‡´è¾“å‡ºã€‚è¯¥ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æ­¤ä»»åŠ¡çš„ç ”ç©¶è¿›å±•ï¼Œå¹¶é€šè¿‡ä¸Šä¸‹æ–‡é•¿åº¦ã€å°æ ·æœ¬å­¦ä¹ å’Œç½‘é¡µæµè§ˆæ•´åˆçš„ç³»ç»Ÿæ€§åˆ†æï¼Œè¯æ˜äº†ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯¥ä»»åŠ¡è‡ªåŠ¨åŒ–æ–¹é¢çš„å‰æ™¯ã€‚è¯¥ç ”ç©¶çš„ä»£ç å’Œæ•°æ®é›†å·²å…¬å¼€å‘å¸ƒï¼Œä¾›ç ”ç©¶ç¤¾åŒºä½¿ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MOLEæ¡†æ¶èƒ½è‡ªåŠ¨ä»éé˜¿æ‹‰ä¼¯è¯­çš„ç§‘å­¦è®ºæ–‡ä¸­æå–å…ƒæ•°æ®å±æ€§ï¼Œæå¤§åœ°å‡å°‘äº†æ‰‹åŠ¨æ ‡æ³¨çš„éœ€æ±‚ã€‚</li>
<li>MOLEé‡‡ç”¨äº†åŸºäºschemaçš„æ–¹æ³•æ¥å¤„ç†ä¸åŒæ ¼å¼çš„æ–‡æ¡£ã€‚</li>
<li>å®ƒåŒ…å«äº†ç¨³å¥çš„éªŒè¯æœºåˆ¶ä»¥ç¡®ä¿è¾“å‡ºçš„å‡†ç¡®æ€§åŠä¸€è‡´æ€§ã€‚</li>
<li>ç ”ç©¶äººå‘˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°è‡ªåŠ¨æå–å…ƒæ•°æ®å±æ€§çš„ç ”ç©¶è¿›å±•ã€‚</li>
<li>é€šè¿‡ä¸Šä¸‹æ–‡é•¿åº¦ã€å°æ ·æœ¬å­¦ä¹ ç­‰æ–¹é¢çš„ç³»ç»Ÿæ€§åˆ†æï¼ŒéªŒè¯äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–æå–å…ƒæ•°æ®æ–¹é¢çš„æ½œåŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶å‘å¸ƒäº†MOLEæ¡†æ¶çš„ä»£ç å’ŒåŸºå‡†æ•°æ®é›†ä»¥ä¾›ç ”ç©¶ç¤¾åŒºä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-79913c05b3ec704ecf3605a4fb0a3eba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029670&auth_key=1760029670-0-0-a63d0abd0a0249a17488e235b12ea709&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-24e7d3182931e410263f0949695940bf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029678&auth_key=1760029678-0-0-5a0b28534afbda7e77f61be424ab9360&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c3c5dde6f3df9e4275ea84e3509be80c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029684&auth_key=1760029684-0-0-b8009afac9f52110dcbd5312914a99ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-59acb9844a43690cc94bd82e5cbb37f3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029691&auth_key=1760029691-0-0-bba4c5022532dafb9d2204daf7c989e1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e2a6d593aef7c8570f9167f9165de5d5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029697&auth_key=1760029697-0-0-c12a5bc047d72e1cb6f81d0f391525fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2abf251e611771762ac3f2c5611d769d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029704&auth_key=1760029704-0-0-7e544399d5f036d7d70a08a0b3b1a902&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cea7bb028b15f18c21dd6987afc159ae~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029711&auth_key=1760029711-0-0-660687f9e47cc5b16055704ebbdc0f72&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-562e52156200bb8315d0176aca8d0151~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029718&auth_key=1760029718-0-0-974c1411858bff8a8ba23d3940cebebc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SNaRe-Domain-aware-Data-Generation-for-Low-Resource-Event-Detection"><a href="#SNaRe-Domain-aware-Data-Generation-for-Low-Resource-Event-Detection" class="headerlink" title="SNaRe: Domain-aware Data Generation for Low-Resource Event Detection"></a>SNaRe: Domain-aware Data Generation for Low-Resource Event Detection</h2><p><strong>Authors:Tanmay Parekh, Yuxuan Dong, Lucas Bandarkar, Artin Kim, I-Hung Hsu, Kai-Wei Chang, Nanyun Peng</strong></p>
<p>Event Detection (ED) â€“ the task of identifying event mentions from natural language text â€“ is critical for enabling reasoning in highly specialized domains such as biomedicine, law, and epidemiology. Data generation has proven to be effective in broadening its utility to wider applications without requiring expensive expert annotations. However, when existing generation approaches are applied to specialized domains, they struggle with label noise, where annotations are incorrect, and domain drift, characterized by a distributional mismatch between generated sentences and the target domain. To address these issues, we introduce SNaRe, a domain-aware synthetic data generation framework composed of three components: Scout, Narrator, and Refiner. Scout extracts triggers from unlabeled target domain data and curates a high-quality domain-specific trigger list using corpus-level statistics to mitigate domain drift. Narrator, conditioned on these triggers, generates high-quality domain-aligned sentences, and Refiner identifies additional event mentions, ensuring high annotation quality. Experimentation on three diverse domain ED datasets reveals how SNaRe outperforms the best baseline, achieving average F1 gains of 3-7% in the zero-shot&#x2F;few-shot settings and 4-20% F1 improvement for multilingual generation. Analyzing the generated trigger hit rate and human evaluation substantiates SNaReâ€™s stronger annotation quality and reduced domain drift. </p>
<blockquote>
<p>äº‹ä»¶æ£€æµ‹ï¼ˆEDï¼‰â€”â€”ä»è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­è¯†åˆ«äº‹ä»¶æåŠçš„ä»»åŠ¡â€”â€”å¯¹äºåœ¨ç”Ÿç‰©åŒ»å­¦ã€æ³•å¾‹å’Œæµè¡Œç—…å­¦ç­‰é«˜åº¦ä¸“ä¸šåŒ–é¢†åŸŸè¿›è¡Œæ¨ç†è‡³å…³é‡è¦ã€‚æ•°æ®ç”Ÿæˆå·²è¯æ˜åœ¨æ‰©å¤§å…¶åœ¨æ›´å¹¿æ³›åº”ç”¨ä¸­çš„æ•ˆç”¨æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œè€Œæ— éœ€æ˜‚è´µçš„ä¸“å®¶æ³¨é‡Šã€‚ç„¶è€Œï¼Œå½“å°†ç°æœ‰çš„ç”Ÿæˆæ–¹æ³•åº”ç”¨äºä¸“ä¸šé¢†åŸŸæ—¶ï¼Œå®ƒä»¬ä¼šé¢ä¸´æ ‡ç­¾å™ªå£°çš„é—®é¢˜ï¼Œå³æ³¨é‡Šä¸æ­£ç¡®ï¼Œä»¥åŠé¢†åŸŸæ¼‚ç§»ï¼Œè¡¨ç°ä¸ºç”Ÿæˆå¥å­ä¸ç›®æ ‡é¢†åŸŸä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SNaReï¼Œè¿™æ˜¯ä¸€ä¸ªé¢†åŸŸæ„ŸçŸ¥çš„åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œç”±ä¸‰ä¸ªç»„ä»¶ç»„æˆï¼šä¾¦å¯Ÿå…µã€å™è¿°è€…å’Œç²¾ç‚¼è€…ã€‚ä¾¦å¯Ÿå…µä»ç›®æ ‡é¢†åŸŸçš„æ— æ ‡ç­¾æ•°æ®ä¸­æå–è§¦å‘å™¨ï¼Œå¹¶ä½¿ç”¨è¯­æ–™åº“çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯æ¥åˆ›å»ºé«˜è´¨é‡çš„ä¸“ä¸šç‰¹å®šè§¦å‘å™¨åˆ—è¡¨ï¼Œä»¥å‡è½»é¢†åŸŸæ¼‚ç§»çš„é—®é¢˜ã€‚å™è¿°è€…æ ¹æ®è¿™äº›è§¦å‘å™¨ç”Ÿæˆé«˜è´¨é‡ã€ç¬¦åˆé¢†åŸŸè¦æ±‚çš„å¥å­ï¼Œè€Œç²¾ç‚¼è€…åˆ™è´Ÿè´£è¯†åˆ«å…¶ä»–äº‹ä»¶æåŠï¼Œç¡®ä¿é«˜è´¨é‡çš„æ³¨é‡Šã€‚åœ¨ä¸‰ä¸ªä¸åŒé¢†åŸŸçš„EDæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒè¡¨æ˜ï¼ŒSNaReçš„è¡¨ç°è¶…è¿‡äº†æœ€ä½³åŸºçº¿ï¼Œåœ¨é›¶æ ·æœ¬&#x2F;å°‘æ ·æœ¬è®¾ç½®ä¸­å¹³å‡F1å¾—åˆ†æé«˜äº†3-7%ï¼Œåœ¨å¤šè¯­è¨€ç”Ÿæˆä¸­F1å¾—åˆ†æé«˜äº†4-20%ã€‚å¯¹ç”Ÿæˆçš„è§¦å‘å™¨å‘½ä¸­ç‡å’Œäººç±»è¯„ä¼°çš„åˆ†æè¯å®äº†SNaReå…·æœ‰æ›´é«˜çš„æ³¨é‡Šè´¨é‡å’Œå‡å°‘çš„é¢†åŸŸæ¼‚ç§»é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17394v3">PDF</a> Accepted at EMNLP 2025 Main</p>
<p><strong>Summary</strong></p>
<p>äº‹ä»¶æ£€æµ‹ï¼ˆEDï¼‰æ˜¯ä»è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­è¯†åˆ«äº‹ä»¶æåŠçš„ä»»åŠ¡ï¼Œå¯¹äºç”Ÿç‰©åŒ»è¯ã€æ³•å¾‹å’Œæµè¡Œç—…å­¦ç­‰é«˜åº¦ä¸“ä¸šåŒ–é¢†åŸŸä¸­çš„æ¨ç†è‡³å…³é‡è¦ã€‚æ•°æ®ç”Ÿæˆå·²è¯æ˜åœ¨æ‰©å¤§å…¶åº”ç”¨èŒƒå›´è€Œæ— éœ€æ˜‚è´µçš„ä¸“å®¶æ³¨é‡Šæ–¹é¢éå¸¸æœ‰æ•ˆã€‚ç„¶è€Œï¼Œå½“ç°æœ‰ç”Ÿæˆæ–¹æ³•åº”ç”¨äºä¸“ä¸šé¢†åŸŸæ—¶ï¼Œå®ƒä»¬é¢ä¸´æ ‡ç­¾å™ªå£°ï¼ˆæ³¨é‡Šä¸æ­£ç¡®ï¼‰å’Œé¢†åŸŸæ¼‚ç§»ï¼ˆç”Ÿæˆå¥å­ä¸ç›®æ ‡é¢†åŸŸçš„åˆ†å¸ƒä¸åŒ¹é…ï¼‰çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SNaReï¼Œè¿™æ˜¯ä¸€ä¸ªé¢†åŸŸæ„ŸçŸ¥çš„åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œç”±Scoutã€Narratorå’ŒRefinerä¸‰ä¸ªç»„ä»¶ç»„æˆã€‚é€šè¿‡ä»ç›®æ ‡é¢†åŸŸæ— æ ‡ç­¾æ•°æ®ä¸­æå–è§¦å‘å™¨å¹¶ä½¿ç”¨è¯­æ–™åº“çº§ç»Ÿè®¡æ¥åˆ›å»ºé«˜è´¨é‡ç‰¹å®šé¢†åŸŸçš„è§¦å‘å™¨åˆ—è¡¨ï¼Œä»è€Œå‡è½»é¢†åŸŸæ¼‚ç§»ã€‚Narratoræ ¹æ®è¿™äº›è§¦å‘å™¨ç”Ÿæˆé«˜è´¨é‡çš„é¢†åŸŸå¯¹é½å¥å­ï¼Œè€ŒRefineråˆ™è¯†åˆ«å…¶ä»–äº‹ä»¶æåŠï¼Œç¡®ä¿é«˜æ³¨é‡Šè´¨é‡ã€‚åœ¨ä¸‰ä¸ªä¸åŒçš„é¢†åŸŸEDæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSNaReä¼˜äºæœ€ä½³åŸºçº¿ï¼Œåœ¨é›¶æ ·æœ¬&#x2F;å°‘æ ·æœ¬è®¾ç½®ä¸­å¹³å‡F1å¾—åˆ†æé«˜äº†3-7%ï¼Œåœ¨å¤šè¯­è¨€ç”Ÿæˆä¸­æé«˜äº†4-20%ã€‚å¯¹ç”Ÿæˆçš„è§¦å‘å™¨å‘½ä¸­ç‡å’Œäººç±»è¯„ä¼°çš„åˆ†æè¯å®äº†SNaReæ›´å¼ºçš„æ³¨é‡Šè´¨é‡å’Œå‡å°‘çš„é¢†åŸŸæ¼‚ç§»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äº‹ä»¶æ£€æµ‹ï¼ˆEDï¼‰åœ¨é«˜åº¦ä¸“ä¸šåŒ–é¢†åŸŸä¸­è‡³å…³é‡è¦ï¼Œå¦‚ç”Ÿç‰©åŒ»è¯ã€æ³•å¾‹å’Œæµè¡Œç—…å­¦ã€‚</li>
<li>æ•°æ®ç”Ÿæˆæ–¹æ³•å·²è¢«è¯æ˜å¯¹äºæ‰©å¤§äº‹ä»¶æ£€æµ‹çš„åº”ç”¨èŒƒå›´éå¸¸æœ‰æ•ˆã€‚</li>
<li>å½“å‰æ•°æ®ç”Ÿæˆæ–¹æ³•é¢ä¸´æ ‡ç­¾å™ªå£°å’Œé¢†åŸŸæ¼‚ç§»çš„æŒ‘æˆ˜ã€‚</li>
<li>SNaReæ˜¯ä¸€ä¸ªé¢†åŸŸæ„ŸçŸ¥çš„åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œç”±Scoutã€Narratorå’ŒRefinerä¸‰ä¸ªç»„ä»¶ç»„æˆã€‚</li>
<li>SNaReé€šè¿‡ä»ç›®æ ‡é¢†åŸŸæ— æ ‡ç­¾æ•°æ®ä¸­æå–è§¦å‘å™¨æ¥å‡è½»é¢†åŸŸæ¼‚ç§»é—®é¢˜ã€‚</li>
<li>SNaReåœ¨å¤šä¸ªé¢†åŸŸæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜äºæœ€ä½³åŸºçº¿ï¼Œå…·æœ‰æ˜¾è‘—çš„æ•ˆæœæå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17394">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-111477456dd120accfbe4eac95e00242~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029725&auth_key=1760029725-0-0-cace59a298ea2e4d8ca8d7fb78855011&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e3bc99ffc6591e22bec2c183875be39d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029732&auth_key=1760029732-0-0-4b6cd008fca5e6672c8f2e37a9b44319&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e90d7191f9d168f2eb99570834aea0f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029739&auth_key=1760029739-0-0-4baa125c606df501f68730bf14e1b257&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c54568f5754cd360a88bbc8d284057e6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029746&auth_key=1760029746-0-0-fd3d9de3287a05867816413c8a8f42c4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-de938d790d53e75d2b1833d3b07d68e8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029753&auth_key=1760029753-0-0-8f91f1a3a6a81b9c7de319319eb12404&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6cec76433eb8acf6759c650eb840a286~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029760&auth_key=1760029760-0-0-4fdd8eb159000a81b58b54b6245888fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="ReMoBot-Retrieval-Based-Few-Shot-Imitation-Learning-for-Mobile-Manipulation-with-Vision-Foundation-Models"><a href="#ReMoBot-Retrieval-Based-Few-Shot-Imitation-Learning-for-Mobile-Manipulation-with-Vision-Foundation-Models" class="headerlink" title="ReMoBot: Retrieval-Based Few-Shot Imitation Learning for Mobile   Manipulation with Vision Foundation Models"></a>ReMoBot: Retrieval-Based Few-Shot Imitation Learning for Mobile   Manipulation with Vision Foundation Models</h2><p><strong>Authors:Yuying Zhang, Wenyan Yang, Francesco Verdoja, Ville Kyrki, Joni Pajarinen</strong></p>
<p>Imitation learning (IL) algorithms typically distill experience into parametric behavior policies to mimic expert demonstrations. However, with limited demonstrations, existing methods often struggle to generate accurate actions, particularly under partial observability. To address this problem, we introduce a few-shot IL approach, ReMoBot, which directly retrieves information from demonstrations to solve Mobile manipulation tasks with ego-centric visual observations. Given the current observation, ReMoBot utilizes vision foundation models to identify relevant demonstrations, considering visual similarity w.r.t. both individual observations and history trajectories. A motion selection policy then selects the proper command for the robot until the task is successfully completed.   The performance of ReMoBot is evaluated on three mobile manipulation tasks with a Boston Dynamics Spot robot in both simulation and the real world. After benchmarking five approaches in simulation, we compare our method with two baselines in the real world, training directly on the real-world dataset without sim-to-real transfer. With only 20 demonstrations, ReMoBot outperforms the baselines, achieving high success rates in Table Uncover (70%) and Gap Cover (80%), while also showing promising performance on the more challenging Curtain Open task in the real-world setting. Furthermore, ReMoBot demonstrates generalization across varying robot positions, object sizes, and material types. Additional details are available at: <a target="_blank" rel="noopener" href="https://sites.google.com/view/remobot/home">https://sites.google.com/view/remobot/home</a> </p>
<blockquote>
<p>æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰ç®—æ³•é€šå¸¸ä¼šå°†ç»éªŒè½¬åŒ–ä¸ºå‚æ•°åŒ–çš„è¡Œä¸ºç­–ç•¥ï¼Œä»¥æ¨¡ä»¿ä¸“å®¶æ¼”ç¤ºã€‚ç„¶è€Œï¼Œåœ¨æ¼”ç¤ºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥ç”Ÿæˆå‡†ç¡®çš„è¡Œä¸ºï¼Œç‰¹åˆ«æ˜¯åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿçš„æƒ…å†µä¸‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§few-shot ILæ–¹æ³•ReMoBotï¼Œå®ƒç›´æ¥ä»æ¼”ç¤ºä¸­æ£€ç´¢ä¿¡æ¯ï¼Œä»¥è§£å†³ä½¿ç”¨è‡ªæˆ‘ä¸­å¿ƒè§†è§‰è§‚å¯Ÿçš„ç§»åŠ¨æ“ä½œä»»åŠ¡ã€‚ç»™å®šå½“å‰è§‚å¯Ÿï¼ŒReMoBotåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹æ¥è¯†åˆ«ä¸æ¼”ç¤ºç›¸å…³çš„å†…å®¹ï¼ŒåŒæ—¶è€ƒè™‘ä¸ªä½“è§‚å¯Ÿå’Œå†å²è½¨è¿¹çš„è§†è§‰ç›¸ä¼¼æ€§ã€‚ç„¶åï¼Œè¿åŠ¨é€‰æ‹©ç­–ç•¥ä¼šä¸ºæœºå™¨äººé€‰æ‹©é€‚å½“çš„å‘½ä»¤ï¼Œç›´åˆ°ä»»åŠ¡æˆåŠŸå®Œæˆã€‚ReMoBotåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­å¯¹ä¸‰é¡¹ç§»åŠ¨æ“ä½œä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œä½¿ç”¨çš„æ˜¯æ³¢å£«é¡¿åŠ¨åŠ›å…¬å¸çš„Spotæœºå™¨äººã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å¯¹äº”ç§æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•åï¼Œæˆ‘ä»¬åœ¨çœŸå®ç¯å¢ƒä¸­å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸ä¸¤ä¸ªåŸºå‡†æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œç›´æ¥å¯¹çœŸå®ä¸–ç•Œæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€æ¨¡æ‹Ÿåˆ°çœŸå®çš„è½¬ç§»ã€‚ä»…å‡­20ä¸ªæ¼”ç¤ºï¼ŒReMoBotå°±è¶…è¶Šäº†åŸºå‡†æ–¹æ³•ï¼Œåœ¨â€œè¡¨é¢æ­å¼€â€ï¼ˆ70%ï¼‰å’Œâ€œç¼éš™è¦†ç›–â€ï¼ˆ80%ï¼‰ä»»åŠ¡ä¸­å–å¾—äº†è¾ƒé«˜çš„æˆåŠŸç‡ï¼ŒåŒæ—¶åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„â€œçª—å¸˜æ‰“å¼€â€ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºäº†æœ‰å‰æ™¯çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒReMoBotå±•ç¤ºäº†åœ¨ä¸åŒæœºå™¨äººä½ç½®ã€ç‰©ä½“å¤§å°å’Œæè´¨ç±»å‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/remobot/home%EF%BC%88%E9%93%BE%E6%8E%A5%E5%9C%B0%E5%9D%80%E4%B8%BARemoBot%E6%AD%A3%E5%AE%B6%EF%BC%89">https://sites.google.com/view/remobot/homeï¼ˆé“¾æ¥åœ°å€ä¸ºReMoBotå®˜ç½‘ï¼‰</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.15919v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰ç®—æ³•é€šå¸¸å°†ç»éªŒè½¬åŒ–ä¸ºå‚æ•°åŒ–çš„è¡Œä¸ºç­–ç•¥ä»¥æ¨¡ä»¿ä¸“å®¶æ¼”ç¤ºã€‚ä½†åœ¨æ¼”ç¤ºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥ç”Ÿæˆå‡†ç¡®åŠ¨ä½œï¼Œå°¤å…¶åœ¨éƒ¨åˆ†å¯è§‚æµ‹æ¡ä»¶ä¸‹ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å°‘æ ·æœ¬ILæ–¹æ³•ReMoBotï¼Œå®ƒç›´æ¥ä»æ¼”ç¤ºä¸­è·å–ä¿¡æ¯ï¼Œè§£å†³ç§»åŠ¨æ“ä½œä»»åŠ¡æ—¶çš„è‡ªæˆ‘ä¸­å¿ƒè§†è§‰è§‚å¯Ÿé—®é¢˜ã€‚ç»™å®šå½“å‰è§‚å¯Ÿç»“æœï¼ŒReMoBotåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹è¯†åˆ«ä¸æ¼”ç¤ºç›¸å…³çš„å†…å®¹ï¼Œè€ƒè™‘ä¸ªä½“è§‚å¯Ÿå’Œå†å²è½¨è¿¹çš„è§†è§‰ç›¸ä¼¼æ€§ã€‚è¿åŠ¨é€‰æ‹©ç­–ç•¥åˆ™ä¸ºæœºå™¨äººé€‰æ‹©é€‚å½“çš„å‘½ä»¤ï¼Œç›´è‡³ä»»åŠ¡å®Œæˆã€‚ReMoBotåœ¨æ³¢å£«é¡¿åŠ¨åŠ›æ–‘ç‚¹æœºå™¨äººä¸Šçš„ä¸‰é¡¹ç§»åŠ¨æ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œç¯å¢ƒä¸­éƒ½å¾—åˆ°äº†è¯„ä¼°ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å¯¹æ¯”äº”ç§æ–¹æ³•åï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ä¸ä¸¤ä¸ªåŸºçº¿è¿›è¡Œäº†æ¯”è¾ƒï¼Œç›´æ¥åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— éœ€æ¨¡æ‹Ÿåˆ°ç°å®çš„è¿ç§»ã€‚å‡­å€Ÿä»…æœ‰çš„20ä¸ªæ¼”ç¤ºï¼ŒReMoBotè¶…è¶Šäº†åŸºçº¿æ–¹æ³•ï¼Œåœ¨è¡¨è¦†ç›–ï¼ˆ70%ï¼‰å’Œé—´éš™è¦†ç›–ï¼ˆ80%ï¼‰ä»»åŠ¡ä¸Šå–å¾—äº†é«˜æˆåŠŸç‡ï¼ŒåŒæ—¶åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„çª—å¸˜æ‰“å¼€ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºäº†æœ‰å‰æ™¯çš„æ€§èƒ½ï¼Œå±•ç°äº†åœ¨ä¸åŒæœºå™¨äººä½ç½®ã€ç‰©ä½“å¤§å°å’Œæè´¨ç±»å‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ReMoBotæ˜¯ä¸€ç§å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰æ–¹æ³•ï¼Œç›´æ¥ä»æ¼”ç¤ºä¸­è·å–ä¿¡æ¯ä»¥è§£å†³ç§»åŠ¨æ“ä½œä»»åŠ¡ã€‚</li>
<li>ReMoBotåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹æ¥è¯†åˆ«ä¸å½“å‰è§‚å¯Ÿç»“æœç›¸å…³çš„æ¼”ç¤ºå†…å®¹ã€‚</li>
<li>è¯¥æ–¹æ³•è€ƒè™‘è§†è§‰ç›¸ä¼¼æ€§ï¼Œæ—¢é’ˆå¯¹ä¸ªä½“è§‚å¯Ÿä¹Ÿå…³æ³¨å†å²è½¨è¿¹ã€‚</li>
<li>é€šè¿‡è¿åŠ¨é€‰æ‹©ç­–ç•¥ï¼ŒReMoBotä¸ºæœºå™¨äººé€‰æ‹©é€‚å½“å‘½ä»¤ä»¥å®Œæˆä»»åŠ¡ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ç¯å¢ƒä¸­ï¼ŒReMoBotåœ¨ä¸‰é¡¹ç§»åŠ¨æ“ä½œä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚</li>
<li>ä»…å‡­20ä¸ªæ¼”ç¤ºï¼ŒReMoBotåœ¨è¡¨è¦†ç›–å’Œé—´éš™è¦†ç›–ä»»åŠ¡ä¸Šå–å¾—äº†é«˜æˆåŠŸç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.15919">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-fedaa80bc926eb5d423b2b44418cc742~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029767&auth_key=1760029767-0-0-5ed341b3f38b87fe5af9bcb141e01afd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-12be1533e06f2ffb2b741096727a04a6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029774&auth_key=1760029774-0-0-dfc2c83b7e3bc2159322c1d7adfdf56a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49f9d55befdbf8cd9064130fae33fd11~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029781&auth_key=1760029781-0-0-9479b84ac74f957636e3cf513f3a6756&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7e3f8f182fc20e823326aea988214435~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029788&auth_key=1760029788-0-0-ced58d81cebac0fdd75b98407e9dbfe3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-da8710d2138f0317790518032754cf8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029795&auth_key=1760029795-0-0-5128da30bc03cc33d14ab6af1970d4f0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="VLM-Agents-Generate-Their-Own-Memories-Distilling-Experience-into-Embodied-Programs-of-Thought"><a href="#VLM-Agents-Generate-Their-Own-Memories-Distilling-Experience-into-Embodied-Programs-of-Thought" class="headerlink" title="VLM Agents Generate Their Own Memories: Distilling Experience into   Embodied Programs of Thought"></a>VLM Agents Generate Their Own Memories: Distilling Experience into   Embodied Programs of Thought</h2><p><strong>Authors:Gabriel Sarch, Lawrence Jang, Michael J. Tarr, William W. Cohen, Kenneth Marino, Katerina Fragkiadaki</strong></p>
<p>Large-scale generative language and vision-language models (LLMs and VLMs) excel in few-shot learning but require high-quality demonstrations. We propose In-Context Abstraction Learning (ICAL), enabling VLM agents to transform suboptimal trajectories into high-quality training data through self-reflection and human feedback. Given imperfect task demonstrations, a VLM abstracts trajectories into generalized strategies and action annotations by correcting inefficiencies and annotating cognitive abstractions: causal relationships, object state changes, temporal subgoals, and task-relevant visual elements. These annotations are iteratively refined through human feedback during execution in similar environments. The resulting examples significantly improve decision-making when used for retrieval-augmented generation or fine-tuning. As the agentâ€™s example library grows, it becomes more efficient at abstracting new examples, requiring less human feedback and fewer environment interactions. ICAL achieves state-of-the-art results across multiple benchmarks. In TEACh dialogue-based instruction following, combining fine-tuning and retrieval on ICAL examples outperforms raw human demonstrations and expert examples by 17.5% in goal-condition success. In VisualWebArena, retrieval-augmented GPT-4V with ICAL improves task success 1.6x, while fine-tuned Qwen2-VL achieves 2.8x improvement over the base model. In Ego4D action forecasting, we surpass few-shot GPT-4V and remain competitive with supervised models. Our approach scales 2x better than raw demonstrations and significantly reduces manual prompt engineering requirements. </p>
<blockquote>
<p>å¤§è§„æ¨¡ç”Ÿæˆå¼è¯­è¨€å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLLMå’ŒVLMï¼‰åœ¨å°‘é‡æ ·æœ¬å­¦ä¹ æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†éœ€è¦é«˜è´¨é‡ç¤ºèŒƒã€‚æˆ‘ä»¬æå‡ºä¸Šä¸‹æ–‡æŠ½è±¡å­¦ä¹ ï¼ˆICALï¼‰æ–¹æ³•ï¼Œä½¿VLMä»£ç†èƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘åæ€å’Œäººç±»åé¦ˆå°†æ¬¡ä¼˜è½¨è¿¹è½¬åŒ–ä¸ºé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚é¢å¯¹ä¸å®Œç¾çš„ä»»åŠ¡ç¤ºèŒƒï¼ŒVLMé€šè¿‡çº æ­£æ— æ•ˆè¡Œä¸ºå¹¶æ ‡æ³¨è®¤çŸ¥æŠ½è±¡ï¼ˆåŒ…æ‹¬å› æœå…³ç³»ã€å¯¹è±¡çŠ¶æ€å˜åŒ–ã€ä¸´æ—¶å­ç›®æ ‡å’Œä»»åŠ¡ç›¸å…³è§†è§‰å…ƒç´ ï¼‰ï¼Œå°†è½¨è¿¹è½¬åŒ–ä¸ºé€šç”¨ç­–ç•¥å’Œè¡ŒåŠ¨æ³¨é‡Šã€‚è¿™äº›æ³¨é‡Šåœ¨æ‰§è¡Œç±»ä¼¼ç¯å¢ƒçš„è¿‡ç¨‹ä¸­é€šè¿‡äººç±»åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚å½“ç”¨äºå¢å¼ºç”Ÿæˆæˆ–å¾®è°ƒæ—¶ï¼Œè¿™äº›ç¤ºä¾‹èƒ½æ˜¾è‘—æ”¹å–„å†³ç­–æ•ˆæœã€‚éšç€ä»£ç†ç¤ºä¾‹åº“çš„å¢é•¿ï¼Œå®ƒåœ¨æŠ½è±¡æ–°ç¤ºä¾‹æ–¹é¢å˜å¾—æ›´åŠ é«˜æ•ˆï¼Œéœ€è¦æ›´å°‘çš„äººç±»åé¦ˆå’Œç¯å¢ƒäº¤äº’ã€‚ICALåœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æˆæœã€‚åœ¨TEAChå¯¹è¯å¼æŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸­ï¼Œä»¥ICALç¤ºä¾‹è¿›è¡Œå¾®è°ƒä¸æ£€ç´¢çš„ç»“åˆï¼Œåœ¨ç›®æ ‡æ¡ä»¶æˆåŠŸç‡æ–¹é¢è¶…è¶Šäº†åŸå§‹äººç±»ç¤ºèŒƒå’Œä¸“ä¸šç¤ºä¾‹17.5%ã€‚åœ¨VisualWebArenaä»»åŠ¡ä¸­ï¼Œç»“åˆICALçš„GPT-4Vå¢å¼ºæ£€ç´¢ä»»åŠ¡æˆåŠŸç‡æå‡1.6å€ï¼Œè€Œç»è¿‡å¾®è°ƒçš„Qwen2-VLè¾ƒåŸºç¡€æ¨¡å‹å®ç°äº†2.8å€çš„æå‡ã€‚åœ¨Ego4DåŠ¨ä½œé¢„æµ‹ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬è¶…è¶Šäº†å°‘é‡æ ·æœ¬çš„GPT-4Vï¼Œå¹¶åœ¨ç›‘ç£æ¨¡å‹ä¿æŒç«äº‰åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¯”åŸå§‹æ¼”ç¤ºæ‰©å±•äº†2å€ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†æ‰‹åŠ¨æç¤ºå·¥ç¨‹éœ€æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14596v6">PDF</a> Project website: <a target="_blank" rel="noopener" href="https://ical-learning.github.io/">https://ical-learning.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡ç”Ÿæˆå¼è¯­è¨€å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLLMså’ŒVLMsï¼‰åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†éœ€è¦é«˜è´¨é‡ç¤ºèŒƒã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºIn-Context Abstraction Learningï¼ˆICALï¼‰çš„æ–¹æ³•ï¼Œä½¿VLMä»£ç†èƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘åæ€å’Œäººç±»åé¦ˆå°†æ¬¡ä¼˜è½¨è¿¹è½¬åŒ–ä¸ºé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚ICALé€šè¿‡çº æ­£æ•ˆç‡ä¸è¶³å¹¶æ³¨é‡Šå› æœå…³ç³»ã€å¯¹è±¡çŠ¶æ€å˜åŒ–ã€ä¸´æ—¶å­ç›®æ ‡å’Œä»»åŠ¡ç›¸å…³è§†è§‰å…ƒç´ ç­‰è®¤çŸ¥æŠ½è±¡æ¥æŠ½è±¡åŒ–è½¨è¿¹ä¸ºé€šç”¨ç­–ç•¥å’Œè¡ŒåŠ¨æ³¨é‡Šã€‚è¿™äº›æ³¨é‡Šåœ¨æ‰§è¡Œç±»ä¼¼ç¯å¢ƒçš„è¿‡ç¨‹ä¸­é€šè¿‡äººç±»åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚ä½¿ç”¨ICALç”Ÿæˆçš„ç¤ºä¾‹åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆæˆ–å¾®è°ƒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†å†³ç­–èƒ½åŠ›ã€‚éšç€ä»£ç†ç¤ºä¾‹åº“çš„å¢é•¿ï¼Œå®ƒæ›´æœ‰æ•ˆåœ°æŠ½è±¡å‡ºæ–°çš„ç¤ºä¾‹ï¼Œéœ€è¦æ›´å°‘çš„äººç±»åé¦ˆå’Œç¯å¢ƒäº¤äº’ã€‚ICALåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€ä½³ç»“æœã€‚åœ¨TEAChå¯¹è¯å¼æŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸­ï¼Œç»“åˆICALç¤ºä¾‹çš„å¾®è°ƒä¸æ£€ç´¢è¶…è¶Šäº†åŸå§‹äººç±»ç¤ºèŒƒå’Œä¸“ä¸šç¤ºä¾‹çš„ç›®æ ‡æ¡ä»¶æˆåŠŸç‡ï¼Œè¾¾åˆ°17.5%ã€‚åœ¨VisualWebArenaä¸­ï¼Œä½¿ç”¨ICALçš„æ£€ç´¢å¢å¼ºGPT-4Vä»»åŠ¡æˆåŠŸç‡æé«˜äº†1.6å€ï¼Œè€Œç»è¿‡è°ƒæ ¡çš„Qwen2-VLæ¨¡å‹ç›¸å¯¹äºåŸºç¡€æ¨¡å‹æé«˜äº†2.8å€ã€‚åœ¨Ego4DåŠ¨ä½œé¢„æµ‹ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬è¶…è¶Šäº†å°‘æ ·æœ¬GPT-4Vå¹¶ä¿æŒä¸ç›‘ç£æ¨¡å‹çš„ç«äº‰åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¯”åŸå§‹ç¤ºèŒƒæ›´å¥½åœ°æ‰©å±•äº†2å€å¹¶å¤§å¤§å‡å°‘äº†æ‰‹åŠ¨æç¤ºå·¥ç¨‹è¦æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è§„æ¨¡ç”Ÿæˆå¼è¯­è¨€å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLLMså’ŒVLMsï¼‰åœ¨å°‘æ ·æœ¬å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†éœ€è¦é«˜è´¨é‡ç¤ºèŒƒæ¥æå‡æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•In-Context Abstraction Learningï¼ˆICALï¼‰ï¼Œä½¿VLMä»£ç†èƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘åæ€å’Œäººç±»åé¦ˆå°†æ¬¡ä¼˜è½¨è¿¹è½¬åŒ–ä¸ºé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚</li>
<li>ICALé€šè¿‡æŠ½è±¡åŒ–è½¨è¿¹ä¸ºé€šç”¨ç­–ç•¥å’Œè¡ŒåŠ¨æ³¨é‡Šï¼ŒåŒ…æ‹¬å› æœå…³ç³»ã€å¯¹è±¡çŠ¶æ€å˜åŒ–ã€ä¸´æ—¶å­ç›®æ ‡å’Œä»»åŠ¡ç›¸å…³è§†è§‰å…ƒç´ ç­‰ã€‚</li>
<li>ICALç”Ÿæˆçš„ç¤ºä¾‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€ä½³ç»“æœï¼Œæ˜¾è‘—æé«˜äº†å†³ç­–èƒ½åŠ›ã€‚</li>
<li>éšç€ä»£ç†ç¤ºä¾‹åº“çš„å¢é•¿ï¼ŒICALæ–¹æ³•æ›´æœ‰æ•ˆåœ°æŠ½è±¡å‡ºæ–°çš„ç¤ºä¾‹ï¼Œå¹¶å‡å°‘äº†äººç±»åé¦ˆå’Œç¯å¢ƒäº¤äº’çš„éœ€æ±‚ã€‚</li>
<li>åœ¨TEAChå¯¹è¯å¼æŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸­ï¼Œç»“åˆICALçš„ç¤ºä¾‹çš„å¾®è°ƒä¸æ£€ç´¢è¶…è¶Šäº†åŸå§‹äººç±»ç¤ºèŒƒå’Œä¸“ä¸šç¤ºä¾‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.14596">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a309fc6b3817dab3ec02c2fc7473c601~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029802&auth_key=1760029802-0-0-eebe61f585fec00106089d851614b2ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f50a399f8145c12177ffd0d2239e90bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029810&auth_key=1760029810-0-0-622941f386748774046d707d9fa24d33&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bf3e5fc2d4993a836fd351ecc79180b8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029816&auth_key=1760029816-0-0-08a9a7f45dc48a3052ff544b6a24e909&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-20/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-20/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-20/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-f69f1399f3fe648a56e7d18c8c299852~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029823&auth_key=1760029823-0-0-77f5067bf15435e24f7335d14aca11d0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  Roll Your Eyes Gaze Redirection via Explicit 3D Eyeball Rotation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-20/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-19f877595158f8e9bd206c4ee7e85cb6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760029069&auth_key=1760029069-0-0-898edd11119f365ab5fe9bfb7594c753&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-20  ScaleCUA Scaling Open-Source Computer Use Agents with Cross-Platform   Data
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31373.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
