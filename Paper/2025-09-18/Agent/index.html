<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-09-18  Scaling Agents via Continual Pre-training">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    18.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    74 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-18-更新"><a href="#2025-09-18-更新" class="headerlink" title="2025-09-18 更新"></a>2025-09-18 更新</h1><h2 id="Scaling-Agents-via-Continual-Pre-training"><a href="#Scaling-Agents-via-Continual-Pre-training" class="headerlink" title="Scaling Agents via Continual Pre-training"></a>Scaling Agents via Continual Pre-training</h2><p><strong>Authors:Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</strong></p>
<p>Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE. </p>
<blockquote>
<p>大型语言模型（LLM）已经进化成能够进行自主工具使用和多步骤推理以解决复杂问题的代理系统。然而，基于通用基础模型的后续训练方法在代理任务上的表现一直不佳，特别是在开源实现中。我们找到了根本原因：缺乏稳健的代理基础模型迫使模型在后续训练过程中同时学习多种代理行为，同时将它们与专家演示对齐，从而产生了基本的优化张力。为此，我们首次提出将代理持续预训练（Agentic CPT）纳入深度研究代理训练管道，以构建强大的代理基础模型。基于这种方法，我们开发了一个名为AgentFounder的深度研究代理模型。我们在10个基准测试上对AgentFounder-30B进行了评估，实现了卓越的性能，同时保持了强大的工具使用能力，特别是在BrowseComp-en上达到39.9%，BrowseComp-zh上达到43.3%，HLE上Pass@1达到31.5%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13310v1">PDF</a> <a target="_blank" rel="noopener" href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a></p>
<p><strong>Summary</strong></p>
<p>大型语言模型进化为具有自主工具使用和复杂问题多步推理能力的代理系统。然而，基于通用基础模型的后续训练方法，在代理任务中的表现一直不尽人意，特别是在开源实现中。问题的根源在于缺乏稳健的代理基础模型，这使得模型在后续训练时需要同时学习多种代理行为并使其与专家演示对齐，从而产生基本的优化紧张。为此，我们首次提出在深度研究代理训练管道中融入代理持续预训练（Agentic CPT），以构建强大的代理基础模型。基于此方法，我们开发了一款名为AgentFounder的深度研究代理模型。我们在10个基准测试上对AgentFounder-30B进行了评估，取得了卓越的性能，同时保持了强大的工具使用能力，特别是在BrowseComp-en上达到39.9%，BrowseComp-zh上达到43.3%，HLE上Pass@1达到31.5%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）已进化为具有自主工具使用和复杂问题多步推理能力的代理系统。</li>
<li>基于通用基础模型的后续训练方法，在代理任务中的表现欠佳，其根本原因在于缺乏稳健的代理基础模型。</li>
<li>代理持续预训练（Agentic CPT）被首次融入深度研究代理训练，以构建强大的代理基础模型。</li>
<li>提出的AgentFounder模型在多个基准测试上表现出卓越性能。</li>
<li>AgentFounder模型在工具使用能力方面表现突出。</li>
<li>AgentFounder在BrowseComp-en、BrowseComp-zh和HLE等任务上的性能分别达到39.9%、43.3%和31.5%的优异表现。</li>
<li>这些进展表明，通过结合代理持续预训练，可以在代理任务中显著提高模型的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13310">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13310v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13310v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13310v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13310v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WebResearcher-Unleashing-unbounded-reasoning-capability-in-Long-Horizon-Agents"><a href="#WebResearcher-Unleashing-unbounded-reasoning-capability-in-Long-Horizon-Agents" class="headerlink" title="WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon   Agents"></a>WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon   Agents</h2><p><strong>Authors:Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, Rui Min, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</strong></p>
<p>Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems. </p>
<blockquote>
<p>近期深度研究系统的进展已经证明了AI代理能够自主地从外部来源发现并合成知识的潜力。在本文中，我们介绍了WebResearcher，这是一个构建此类代理的新型框架，主要包括两个关键组成部分：（1）WebResearcher，一种迭代式深度研究范式，将深度研究重新定义为马尔可夫决策过程，在此过程中，代理会定期将发现整合为不断演变的报告，同时保持专注的工作空间，克服困扰现有单语境方法的上下文窒息和噪声污染；（2）WebFrontier，一个可扩展的数据合成引擎，通过工具增强的复杂性升级生成高质量的训练数据，能够系统地创建研究任务，以弥合被动知识回忆和主动知识构建之间的鸿沟。值得注意的是，我们发现我们的范式训练数据甚至能提升传统单语境方法的工具使用能力。此外，我们的范式能够通过平行思考自然扩展，以实现多代理并发探索，得出更全面的结论。在6个具有挑战性的基准测试上的广泛实验表明，WebResearcher达到了最新技术水平，甚至超越了前沿专有系统。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13309v1">PDF</a> <a target="_blank" rel="noopener" href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a></p>
<p><strong>Summary</strong><br>深度研究系统的最新进展展现了AI自主发现并融合外部知识的潜力。本文介绍了一种新型框架WebResearcher，包含两大关键组件：一是WebResearcher迭代深度研究范式，它将深度研究转化为马尔可夫决策过程，使AI代理能够定期整合研究成果并生成报告，克服单一语境方法的局限；二是WebFrontier可伸缩数据融合引擎，它通过工具辅助的复杂性升级生成高质量的训练数据，缩小被动知识回忆与主动知识构建之间的差距。实验证明WebResearcher的卓越性能，即使在最具挑战性的基准测试中也能达到业界前沿水平。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>WebResearcher框架引入了一种新型的AI自主研究方式，结合了迭代深度研究范式和数据融合引擎。</li>
<li>WebResearcher将深度研究转化为马尔可夫决策过程，允许AI代理定期整合研究成果并生成报告。</li>
<li>WebFrontier数据融合引擎生成高质量训练数据，提升工具使用能力并缩小被动与主动知识构建间的差距。</li>
<li>WebResearcher能够克服单一语境方法的局限，如上下文缺失和噪声污染。</li>
<li>该框架通过并行思考自然扩展，实现多代理并发探索，得出更全面结论。</li>
<li>实验证明WebResearcher在多个基准测试中表现卓越，达到业界前沿水平。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13309">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13309v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13309v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13309v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="WebSailor-V2-Bridging-the-Chasm-to-Proprietary-Agents-via-Synthetic-Data-and-Scalable-Reinforcement-Learning"><a href="#WebSailor-V2-Bridging-the-Chasm-to-Proprietary-Agents-via-Synthetic-Data-and-Scalable-Reinforcement-Learning" class="headerlink" title="WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic   Data and Scalable Reinforcement Learning"></a>WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic   Data and Scalable Reinforcement Learning</h2><p><strong>Authors:Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, Xinyu Wang, Zile Qiao, Zhen Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</strong></p>
<p>Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents’ performance and closing the capability gap. </p>
<blockquote>
<p>突破人类认知局限是大型语言模型训练的重要前沿领域。DeepResearch等专有代理系统已在BrowseComp等极为复杂的信息检索基准测试上展现出超人的能力，这是以前无法实现的。我们认为，它们的成功关键在于一种开源模型所缺少的复杂推理模式：在浏览巨大信息景观时，系统性降低极端不确定性的能力。基于此见解，我们推出了WebSailor，这是一种完整的后训练方法论，旨在培养这种关键能力。我们的方法包括通过结构化采样和信息模糊、RFT冷启动以及高效的代理强化学习训练算法Duplicating Sampling Policy Optimization（DUPO）来生成新型高不确定性任务。通过这一集成流程，WebSailor在复杂的信息检索任务中大大超越了所有开源代理，匹配了专有代理的性能，并缩小了能力差距。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13305v1">PDF</a> <a target="_blank" rel="noopener" href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a></p>
<p><strong>Summary</strong>：<br>超越人类认知局限是大型语言模型训练的重要前沿领域。DeepResearch等专有代理系统已在极端复杂的信息检索基准测试（如BrowseComp）中展现出超人类能力，这在过去是无法实现的。其成功关键在于一种复杂推理模式，这是开源模型所缺乏的：在浏览巨大信息景观时系统减少极端不确定性的能力。基于此，我们引入了WebSailor，这是一种设计用于培养这种关键能力的全面后训练方法论。通过结构化采样和信息模糊生成新型高不确定性任务，结合RFT冷启动和高效的代理强化学习训练算法DUPO，WebSailor在复杂信息检索任务中显著优于所有开源代理，达到专有代理的性能水平，缩小了能力差距。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>专有代理系统如DeepResearch已超越人类在某些复杂信息检索任务上的能力。</li>
<li>这种成功的关键在于处理极端不确定性，这是开源模型所缺乏的推理模式。</li>
<li>WebSailor是一种全面的后训练方法论，旨在培养这种关键能力。</li>
<li>WebSailor通过结构化采样和信息模糊生成新型高不确定性任务。</li>
<li>RFT冷启动和高效的代理强化学习训练算法DUPO是WebSailor的重要组成部分。</li>
<li>WebSailor在复杂信息检索任务中显著优于开源代理，并缩小了与专有代理的性能差距。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13305">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13305v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13305v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="xOffense-An-AI-driven-autonomous-penetration-testing-framework-with-offensive-knowledge-enhanced-LLMs-and-multi-agent-systems"><a href="#xOffense-An-AI-driven-autonomous-penetration-testing-framework-with-offensive-knowledge-enhanced-LLMs-and-multi-agent-systems" class="headerlink" title="xOffense: An AI-driven autonomous penetration testing framework with   offensive knowledge-enhanced LLMs and multi agent systems"></a>xOffense: An AI-driven autonomous penetration testing framework with   offensive knowledge-enhanced LLMs and multi agent systems</h2><p><strong>Authors:Phung Duc Luong, Le Tran Gia Bao, Nguyen Vu Khai Tam, Dong Huu Nguyen Khoa, Nguyen Huu Quyen, Van-Hau Pham, Phan The Duy</strong></p>
<p>This work introduces xOffense, an AI-driven, multi-agent penetration testing framework that shifts the process from labor-intensive, expert-driven manual efforts to fully automated, machine-executable workflows capable of scaling seamlessly with computational infrastructure. At its core, xOffense leverages a fine-tuned, mid-scale open-source LLM (Qwen3-32B) to drive reasoning and decision-making in penetration testing. The framework assigns specialized agents to reconnaissance, vulnerability scanning, and exploitation, with an orchestration layer ensuring seamless coordination across phases. Fine-tuning on Chain-of-Thought penetration testing data further enables the model to generate precise tool commands and perform consistent multi-step reasoning. We evaluate xOffense on two rigorous benchmarks: AutoPenBench and AI-Pentest-Benchmark. The results demonstrate that xOffense consistently outperforms contemporary methods, achieving a sub-task completion rate of 79.17%, decisively surpassing leading systems such as VulnBot and PentestGPT. These findings highlight the potential of domain-adapted mid-scale LLMs, when embedded within structured multi-agent orchestration, to deliver superior, cost-efficient, and reproducible solutions for autonomous penetration testing. </p>
<blockquote>
<p>本文介绍了xOffense，这是一个AI驱动的多代理渗透测试框架，它将流程从劳动密集型的专家驱动的手工努力转变为全自动的机器可执行工作流程，能够随着计算基础设施无缝扩展。其核心是利用经过精细调整的中型开源LLM（Qwen3-32B）来驱动渗透测试中的推理和决策。该框架将专业代理分配给侦察、漏洞扫描和利用等环节，通过协同层确保各阶段之间的无缝协作。在Chain-of-Thought渗透测试数据上进行微调，进一步使模型能够生成精确的工具命令并执行一致的多步推理。我们在两个严格的基准测试（AutoPenBench和AI-Pentest-Benchmark）上评估了xOffense的性能。结果表明，xOffense的性能始终优于当代方法，其完成任务率为79.17%，显著超越了领先的VulnBot和PentestGPT系统。这些发现突显了当嵌入结构化多代理协同工作时，领域适应的中型LLMs在提供卓越、高效且可重复使用的自主渗透测试解决方案方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13021v1">PDF</a> 17 pages, 4 figures</p>
<p><strong>Summary</strong><br>这是一项关于xOffense的研究，这是一个AI驱动的、多代理渗透测试框架。它改变了渗透测试的过程，使其从依赖劳动力和专家知识的复杂手动过程转变为全自动化和可扩展的计算过程。框架核心采用一个微调过的中规模开源LLM模型进行决策推理。经过针对多步思维和跨阶段的协作的专门设计后，评估发现xOffense优于现有的系统。它不仅具有卓越的性能表现，而且在自主渗透测试领域展现出独特的优势。我们相信它有望成为渗透测试的新标杆。它不仅通过简化自动化降低了人力成本，也大大提高了测试的准确性和一致性。这显示出中等规模LLM的潜力。更重要的是，该框架的自动化特性使它在面临大规模网络攻击时能够迅速响应和应对威胁。同时，该框架的灵活性和可扩展性使其成为应对未来网络威胁的理想选择。因此，它不仅能够提高渗透测试的效率，还能推动AI技术在网络安全领域的进一步发展。总之，xOffense具有巨大的潜力，将成为网络安全领域的重要突破。</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13021">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13021v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.13021v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="HLSMAC-A-New-StarCraft-Multi-Agent-Challenge-for-High-Level-Strategic-Decision-Making"><a href="#HLSMAC-A-New-StarCraft-Multi-Agent-Challenge-for-High-Level-Strategic-Decision-Making" class="headerlink" title="HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic   Decision-Making"></a>HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic   Decision-Making</h2><p><strong>Authors:Xingxing Hong, Yungong Wang, Dexin Jin, Ye Yuan, Ximing Huang, Zijian Wu, Wenxin Li</strong></p>
<p>Benchmarks are crucial for assessing multi-agent reinforcement learning (MARL) algorithms. While StarCraft II-related environments have driven significant advances in MARL, existing benchmarks like SMAC focus primarily on micromanagement, limiting comprehensive evaluation of high-level strategic intelligence. To address this, we introduce HLSMAC, a new cooperative MARL benchmark with 12 carefully designed StarCraft II scenarios based on classical stratagems from the Thirty-Six Stratagems. Each scenario corresponds to a specific stratagem and is designed to challenge agents with diverse strategic elements, including tactical maneuvering, timing coordination, and deception, thereby opening up avenues for evaluating high-level strategic decision-making capabilities. We also propose novel metrics across multiple dimensions beyond conventional win rate, such as ability utilization and advancement efficiency, to assess agents’ overall performance within the HLSMAC environment. We integrate state-of-the-art MARL algorithms and LLM-based agents with our benchmark and conduct comprehensive experiments. The results demonstrate that HLSMAC serves as a robust testbed for advancing multi-agent strategic decision-making. </p>
<blockquote>
<p>基准测试对于评估多智能体强化学习（MARL）算法至关重要。虽然与《星际争霸II》相关的环境已经推动了MARL的重大进展，但现有的基准测试（如SMAC）主要侧重于微观管理，限制了高级战略情报的全面评估。为了解决这个问题，我们引入了HLSMAC，这是一个新的合作式MARL基准测试，包含12个基于《星际争霸II》的经典战略精心设计的场景。每个场景都对应一个特定的战略，旨在挑战包含战术机动、时间协调和欺骗等多种战略元素，从而为评估高级战略决策能力打开途径。除了传统的胜率外，我们还提出了新型的多维度评估指标，如能力利用和进展效率，以评估智能体在HLSMAC环境中的整体表现。我们将最先进的MARL算法和基于LLM的代理与我们的基准测试集成在一起，并进行了全面的实验。结果表明，HLSMAC是推进多智能体战略决策的一个稳健的测试平台。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12927v1">PDF</a> 30 pages, 13 figures with appendix</p>
<p><strong>Summary</strong></p>
<p>StarCraft II环境下的多智能体强化学习（MARL）算法评估至关重要。现有基准测试如SMAC主要关注微观管理，无法全面评估高级战略智能。为此，引入HLSMAC基准测试，包含基于古典兵法《三十六计》设计的十二种StarCraft II场景。每个场景对应一种策略，设计挑战涉及战术机动、时间协调与欺骗等多样化战略元素，以评估高级战略决策能力。提出超越传统胜率的新评价指标，如能力利用和进展效率等，以全面评估代理在HLSMAC环境中的表现。整合最新MARL算法与基于LLM的代理，实验结果显示HLSMAC为推进多智能体战略决策提供了稳健的测试平台。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有MARL基准测试如SMAC主要关注微观管理，限制了高级战略智能的全面评估。</li>
<li>HLSMAC基准测试引入十二种基于《三十六计》设计的StarCraft II场景。</li>
<li>HLSMAC设计旨在挑战多样化的战略元素，包括战术机动、时间协调与欺骗等。</li>
<li>HLSMAC为评估高级战略决策能力提供了测试平台。</li>
<li>提出超越传统胜率的新评价指标，如能力利用和进展效率等。</li>
<li>整合了最新的MARL算法与基于LLM的代理进行实验验证。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12927">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12927v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12927v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12927v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12927v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Tool-R1-Sample-Efficient-Reinforcement-Learning-for-Agentic-Tool-Use"><a href="#Tool-R1-Sample-Efficient-Reinforcement-Learning-for-Agentic-Tool-Use" class="headerlink" title="Tool-R1: Sample-Efficient Reinforcement Learning for Agentic Tool Use"></a>Tool-R1: Sample-Efficient Reinforcement Learning for Agentic Tool Use</h2><p><strong>Authors:Yabo Zhang, Yihan Zeng, Qingyun Li, Zhen Hu, Kavin Han, Wangmeng Zuo</strong></p>
<p>Large language models (LLMs) have demonstrated strong capabilities in language understanding and reasoning, yet they remain limited when tackling real-world tasks that require up-to-date knowledge, precise operations, or specialized tool use. To address this, we propose Tool-R1, a reinforcement learning framework that enables LLMs to perform general, compositional, and multi-step tool use by generating executable Python code. Tool-R1 supports integration of user-defined tools and standard libraries, with variable sharing across steps to construct coherent workflows. An outcome-based reward function, combining LLM-based answer judgment and code execution success, guides policy optimization. To improve training efficiency, we maintain a dynamic sample queue to cache and reuse high-quality trajectories, reducing the overhead of costly online sampling. Experiments on the GAIA benchmark show that Tool-R1 substantially improves both accuracy and robustness, achieving about 10% gain over strong baselines, with larger improvements on complex multi-step tasks. These results highlight the potential of Tool-R1 for enabling reliable and efficient tool-augmented reasoning in real-world applications. Our code will be available at <a target="_blank" rel="noopener" href="https://github.com/YBYBZhang/Tool-R1">https://github.com/YBYBZhang/Tool-R1</a>. </p>
<blockquote>
<p>大型语言模型（LLM）在理解和推理方面表现出了强大的能力，但在处理需要最新知识、精确操作或专业工具使用的现实世界任务时仍存在局限。为了解决这一问题，我们提出了Tool-R1，这是一个强化学习框架，能够通过生成可执行Python代码，使LLM执行通用、组合和多步骤的工具使用。Tool-R1支持用户定义的工具和标准库的集成，步骤间变量共享以构建连贯的工作流。结合LLM的答案判断和代码执行成功的基于结果奖励函数，引导策略优化。为提高训练效率，我们维护了一个动态样本队列来缓存和重用高质量轨迹，减少昂贵的在线采样开销。在GAIA基准测试上的实验表明，Tool-R1在准确率和稳健性方面都有显著提高，相较于强基线有约10%的增益，在复杂的多步骤任务上表现更为明显。这些结果突出了Tool-R1在现实世界应用中实现可靠和高效工具增强推理的潜力。我们的代码将在<a target="_blank" rel="noopener" href="https://github.com/YBYBZhang/Tool-R1%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/YBYBZhang/Tool-R1上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12867v1">PDF</a> </p>
<p><strong>Summary</strong><br>强化学习框架Tool-R1，支持大型语言模型进行通用、组合和多步骤的工具使用，通过生成Python代码实现。框架支持用户定义的工具和标准库集成，通过步骤间的变量共享构建连贯的工作流程。采用基于结果的奖励函数，结合语言模型的答案判断和代码执行成功来指导策略优化。实验表明，Tool-R1在GAIA基准测试中提高了准确性和鲁棒性，相比基线方法获得了约10%的提升，特别是在复杂多步骤任务上表现更优异。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Tool-R1是一个强化学习框架，用于增强大型语言模型（LLMs）的工具使用能力。</li>
<li>LLMs可通过生成Python代码进行通用、组合和多步骤的操作。</li>
<li>支持用户自定义工具和标准库的集成。</li>
<li>框架通过步骤间的变量共享构建连贯的工作流程。</li>
<li>采用基于结果的奖励函数，结合LLM答案判断和代码执行成功来优化策略。</li>
<li>动态样本队列用于缓存和重用高质量轨迹，提高训练效率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12867">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12867v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12867v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12867v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DeltaHedge-A-Multi-Agent-Framework-for-Portfolio-Options-Optimization"><a href="#DeltaHedge-A-Multi-Agent-Framework-for-Portfolio-Options-Optimization" class="headerlink" title="DeltaHedge: A Multi-Agent Framework for Portfolio Options Optimization"></a>DeltaHedge: A Multi-Agent Framework for Portfolio Options Optimization</h2><p><strong>Authors:Feliks Bańka, Jarosław A. Chudziak</strong></p>
<p>In volatile financial markets, balancing risk and return remains a significant challenge. Traditional approaches often focus solely on equity allocation, overlooking the strategic advantages of options trading for dynamic risk hedging. This work presents DeltaHedge, a multi-agent framework that integrates options trading with AI-driven portfolio management. By combining advanced reinforcement learning techniques with an ensembled options-based hedging strategy, DeltaHedge enhances risk-adjusted returns and stabilizes portfolio performance across varying market conditions. Experimental results demonstrate that DeltaHedge outperforms traditional strategies and standalone models, underscoring its potential to transform practical portfolio management in complex financial environments. Building on these findings, this paper contributes to the fields of quantitative finance and AI-driven portfolio optimization by introducing a novel multi-agent system for integrating options trading strategies, addressing a gap in the existing literature. </p>
<blockquote>
<p>在波动较大的金融市场中，平衡风险与收益仍然是一项巨大挑战。传统方法通常只专注于股权分配，忽视了期权交易在动态风险对冲中的战略优势。本文介绍了DeltaHedge，这是一个将期权交易与AI驱动的组合管理相结合的多智能体框架。通过将先进的强化学习技术与基于期权的对冲策略相结合，DeltaHedge提高了风险调整后的收益，并在各种市场条件下稳定了投资组合的表现。实验结果表明，DeltaHedge优于传统策略和独立模型，突显其在复杂金融环境中改变实际投资组合管理的潜力。基于这些发现，本文通过引入一个用于整合期权交易策略的新型多智能体系统，为量化金融和AI驱动的组合优化领域做出贡献，填补了现有文献的空白。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12753v1">PDF</a> Presented at Pacific Asia Conference on Information Systems (PACIS   2025), Kuala Lumpur. Official proceedings available at   <a target="_blank" rel="noopener" href="https://aisel.aisnet.org/pacis2025/aiandml/aiandml/25/">https://aisel.aisnet.org/pacis2025/aiandml/aiandml/25/</a>. 16 pages, 7 figures,   3 tables</p>
<p><strong>总结</strong></p>
<p>在金融市场波动性增强的背景下，如何在风险与回报之间取得平衡依然是一个重大挑战。传统方法往往只关注股权分配，忽略了期权交易在动态风险管理中的战略优势。本研究提出了DeltaHedge，这是一个将期权交易与人工智能驱动的资产管理相结合的多智能体框架。通过结合先进的强化学习技术和基于期权的对冲策略，DeltaHedge增强了风险调整后的回报并稳定了在不同市场条件下的投资组合表现。实验结果表明，DeltaHedge的表现优于传统策略和独立模型，突显其在复杂金融环境中实际应用投资组合管理的潜力。本研究为量化金融和人工智能驱动的投资组合优化领域引入了一种新型的多智能体系统，填补了现有文献中的空白。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>传统方法主要关注股权分配，忽略了期权交易在风险管理中的优势。</li>
<li>DeltaHedge是一个多智能体框架，结合了期权交易与人工智能驱动的资产管理。</li>
<li>DeltaHedge通过强化学习技术和基于期权的对冲策略来实现优化的投资组合管理。</li>
<li>DeltaHedge可以增强风险调整后的回报并稳定投资组合在不同市场条件下的表现。</li>
<li>实验结果表明，DeltaHedge的表现优于传统策略和独立模型。</li>
<li>DeltaHedge有潜力在复杂金融环境中实现实际投资组合管理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12753">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12753v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12753v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12753v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="EvoEmpirBench-Dynamic-Spatial-Reasoning-with-Agent-ExpVer"><a href="#EvoEmpirBench-Dynamic-Spatial-Reasoning-with-Agent-ExpVer" class="headerlink" title="EvoEmpirBench: Dynamic Spatial Reasoning with Agent-ExpVer"></a>EvoEmpirBench: Dynamic Spatial Reasoning with Agent-ExpVer</h2><p><strong>Authors:Pukun Zhao, Longxiang Wang, Miaowei Wang, Chen Chen, Fanqing Zhou, Haojian Huang</strong></p>
<p>Most existing spatial reasoning benchmarks focus on static or globally observable environments, failing to capture the challenges of long-horizon reasoning and memory utilization under partial observability and dynamic changes. We introduce two dynamic spatial benchmarks, locally observable maze navigation and match-2 elimination that systematically evaluate models’ abilities in spatial understanding and adaptive planning when local perception, environment feedback, and global objectives are tightly coupled. Each action triggers structural changes in the environment, requiring continuous update of cognition and strategy. We further propose a subjective experience-based memory mechanism for cross-task experience transfer and validation. Experiments show that our benchmarks reveal key limitations of mainstream models in dynamic spatial reasoning and long-term memory, providing a comprehensive platform for future methodological advances. Our code and data are available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/EvoEmpirBench-143C/">https://anonymous.4open.science/r/EvoEmpirBench-143C/</a>. </p>
<blockquote>
<p>现有的大多数空间推理基准测试主要集中在静态或全局可观察的环境上，未能捕捉到部分可观察性和动态变化下长期推理和记忆利用的挑战。我们引入了两个动态空间基准测试，即局部可观察的迷宫导航和匹配-2消除，以系统地评估模型在局部感知、环境反馈和全局目标紧密耦合时的空间理解和自适应规划能力。每个动作都会引发环境结构的变化，需要不断更新认知策略。我们还提出了一种基于主观经验的记忆机制，用于跨任务经验转移和验证。实验表明，我们的基准测试揭示了主流模型在动态空间推理和长期记忆方面的关键局限性，为未来方法的发展提供了一个综合平台。我们的代码和数据可在[<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/EvoEmpirBench-143C/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://anonymous.4open.science/r/EvoEmpirBench-143C/]上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12718v1">PDF</a> Ongoing Work, 29 pages, 3 figures, 7 tables</p>
<p><strong>Summary</strong></p>
<p>该文介绍了两个动态空间基准测试：局部可观测迷宫导航和匹配-2消除。这些测试旨在评估模型在紧密耦合局部感知、环境反馈和全局目标时的空间理解和自适应规划能力。每项行动都会引起环境变化，需要不断更新认知和调整策略。文章还提出了一种基于主观经验的记忆机制，用于跨任务经验迁移和验证。实验表明，这些基准测试揭示了主流模型在动态空间推理和长期记忆方面的关键局限性，为未来的方法论进步提供了一个综合平台。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有空间推理基准测试主要集中在静态或全局可观测环境，无法捕捉长周期推理和记忆利用在局部可观测性和动态变化下的挑战。</li>
<li>引入两个动态空间基准测试：局部可观测迷宫导航和匹配-2消除，以评估模型在紧密耦合局部感知、环境反馈和全局目标时的能力。</li>
<li>环境结构随每个行动而改变，需要不断更新认知和策略。</li>
<li>提出一种基于主观经验的记忆机制，用于跨任务经验迁移和验证。</li>
<li>实验显示，这些基准测试揭示了主流模型在动态空间推理和长期记忆方面的局限性。</li>
<li>这些基准测试为未来的方法论进步提供了一个综合平台。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12718">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12718v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12718v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12718v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12718v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12718v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Learning-to-Generate-Pointing-Gestures-in-Situated-Embodied-Conversational-Agents"><a href="#Learning-to-Generate-Pointing-Gestures-in-Situated-Embodied-Conversational-Agents" class="headerlink" title="Learning to Generate Pointing Gestures in Situated Embodied   Conversational Agents"></a>Learning to Generate Pointing Gestures in Situated Embodied   Conversational Agents</h2><p><strong>Authors:Anna Deichler, Siyang Wang, Simon Alexanderson, Jonas Beskow</strong></p>
<p>One of the main goals of robotics and intelligent agent research is to enable natural communication with humans in physically situated settings. While recent work has focused on verbal modes such as language and speech, non-verbal communication is crucial for flexible interaction. We present a framework for generating pointing gestures in embodied agents by combining imitation and reinforcement learning. Using a small motion capture dataset, our method learns a motor control policy that produces physically valid, naturalistic gestures with high referential accuracy. We evaluate the approach against supervised learning and retrieval baselines in both objective metrics and a virtual reality referential game with human users. Results show that our system achieves higher naturalness and accuracy than state-of-the-art supervised models, highlighting the promise of imitation-RL for communicative gesture generation and its potential application to robots. </p>
<blockquote>
<p>机器人和智能体研究的主要目标之一是实现在物理环境中与人类的自然交流。虽然最近的研究主要集中在语言和语音等言语模式上，但非言语交流对于灵活的互动至关重要。我们提出了一种结合模仿和强化学习在实体生成指向手势的框架。使用小型动作捕捉数据集，我们的方法学习了一种电机控制策略，能够产生物理上有效、具有表现力的手势，并且具有较高的指代准确性。我们在客观指标和虚拟现实指代游戏中对人类用户进行了评估，并将我们的方法与监督学习和检索基线进行了比较。结果表明，我们的系统在自然性和准确性方面优于最新的监督模型，突显了模仿强化学习在交际手势生成方面的前景及其应用于机器人的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12507v1">PDF</a> DOI: 10.3389&#x2F;frobt.2023.1110534. This is the author’s LaTeX version</p>
<p><strong>Summary</strong>：<br>本研究旨在实现智能机器人与人类的自然沟通。除了语言和言语等语言模式外，非语言沟通对于灵活的互动至关重要。本研究提出了一种结合模仿和强化学习的方法，为智能机器人生成指向性手势。使用小型动作捕捉数据集的方法可以产生物理上有效且高度指代准确的自然手势。在虚拟现实参照游戏中与人类用户进行的评估显示，该系统在客观指标上表现出比目前最先进的有监督模型更高的自然性和准确性，展现出模仿强化学习在交际手势生成方面的前景及其在未来机器人的潜在应用。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>智能机器人与人类沟通是研究的重点，而非语言沟通对灵活互动至关重要。</li>
<li>提出了一种结合模仿和强化学习的方法生成智能机器人的指向性手势。</li>
<li>使用小型动作捕捉数据集的方法学习生成物理上有效且高度指代准确的自然手势。</li>
<li>该系统产生的手势自然性和准确性高于目前最先进的有监督模型。</li>
<li>评估结果表明模仿强化学习在交际手势生成方面的潜力。</li>
<li>本研究不仅限于机器人技术，还可能对人工智能、智能代理和人机交互等领域产生重要影响。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12507">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12507v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Finite-Agent-Stochastic-Differential-Games-on-Large-Graphs-II-Graph-Based-Architectures"><a href="#Finite-Agent-Stochastic-Differential-Games-on-Large-Graphs-II-Graph-Based-Architectures" class="headerlink" title="Finite-Agent Stochastic Differential Games on Large Graphs: II.   Graph-Based Architectures"></a>Finite-Agent Stochastic Differential Games on Large Graphs: II.   Graph-Based Architectures</h2><p><strong>Authors:Ruimeng Hu, Jihao Long, Haosheng Zhou</strong></p>
<p>We propose a novel neural network architecture, called Non-Trainable Modification (NTM), for computing Nash equilibria in stochastic differential games (SDGs) on graphs. These games model a broad class of graph-structured multi-agent systems arising in finance, robotics, energy, and social dynamics, where agents interact locally under uncertainty. The NTM architecture imposes a graph-guided sparsification on feedforward neural networks, embedding fixed, non-trainable components aligned with the underlying graph topology. This design enhances interpretability and stability, while significantly reducing the number of trainable parameters in large-scale, sparse settings. We theoretically establish a universal approximation property for NTM in static games on graphs and numerically validate its expressivity and robustness through supervised learning tasks. Building on this foundation, we incorporate NTM into two state-of-the-art game solvers, Direct Parameterization and Deep BSDE, yielding their sparse variants (NTM-DP and NTM-DBSDE). Numerical experiments on three SDGs across various graph structures demonstrate that NTM-based methods achieve performance comparable to their fully trainable counterparts, while offering improved computational efficiency. </p>
<blockquote>
<p>我们提出了一种新的神经网络架构，名为非训练修改（NTM），用于计算图上随机微分博弈（SDG）的纳什均衡。这些游戏对金融、机器人、能源和社会动态中出现的图结构多智能体系统进行了广泛建模，在这些系统中，智能体在不确定性条件下进行局部交互。NTM架构对前馈神经网络实施了图引导稀疏化，嵌入固定、不可训练组件，与底层图拓扑结构相匹配。这种设计提高了可解释性和稳定性，同时在大规模稀疏环境中显著减少了可训练参数的数量。我们在理论上为静态博弈中的NTM建立了通用近似属性，并通过监督学习任务对其表达性和稳健性进行了数值验证。在此基础上，我们将NTM融入两种最先进的博弈求解器——直接参数化和深度BSDE，得到它们的稀疏变体（NTM-DP和NTM-DBSDE）。在三种不同图结构上的SDG数值实验表明，基于NTM的方法实现了与完全可训练方法相当的性能，同时提高了计算效率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12484v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新型的神经网络架构——非训练性修改（NTM），用于计算图上随机微分博弈（SDG）的纳什均衡。该架构对前馈神经网络实施了图引导稀疏化，嵌入固定、不可训练组件，与底层图拓扑结构对齐。该设计提高了可解释性和稳定性，同时在大型稀疏设置中显著减少了可训练参数的数量。文章从理论上建立了NTM在静态图博弈中的通用逼近属性，并通过监督学习任务对其表达性和稳健性进行了数值验证。在此基础上，将NTM融入两种先进博弈求解器——直接参数化和深度BSDE中，形成其稀疏变体NTM-DP和NTM-DBSDE。在不同图结构上的三个SDG数值实验表明，基于NTM的方法在性能上与其完全可训练的对应方法相当，同时提高了计算效率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了新型神经网络架构Non-Trainable Modification（NTM），用于计算图上随机微分博弈的纳什均衡。</li>
<li>NTM架构通过图引导稀疏化前馈神经网络，嵌入固定、不可训练的组件，以增强可解释性和稳定性，并减少大型稀疏设置中的可训练参数数量。</li>
<li>NTM在静态图博弈中具有通用逼近属性。</li>
<li>通过监督学习任务验证了NTM的表达性和稳健性。</li>
<li>将NTM融入Direct Parameterization和Deep BSDE两种先进博弈求解器，形成其稀疏变体NTM-DP和NTM-DBSDE。</li>
<li>基于NTM的方法在性能上与传统方法相当。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12484">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.12484v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Agentic-Lybic-Multi-Agent-Execution-System-with-Tiered-Reasoning-and-Orchestration"><a href="#Agentic-Lybic-Multi-Agent-Execution-System-with-Tiered-Reasoning-and-Orchestration" class="headerlink" title="Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and   Orchestration"></a>Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and   Orchestration</h2><p><strong>Authors:Liangxuan Guo, Bin Zhu, Qingqian Tao, Kangning Liu, Xun Zhao, Xianzhe Qin, Jin Gao, Guangfu Hao</strong></p>
<p>Autonomous agents for desktop automation struggle with complex multi-step tasks due to poor coordination and inadequate quality control. We introduce Agentic Lybic, a novel multi-agent system where the entire architecture operates as a finite-state machine (FSM). This core innovation enables dynamic orchestration. Our system comprises four components: a Controller, a Manager, three Workers (Technician for code-based operations, Operator for GUI interactions, and Analyst for decision support), and an Evaluator. The critical mechanism is the FSM-based routing between these components, which provides flexibility and generalization by dynamically selecting the optimal execution strategy for each subtask. This principled orchestration, combined with robust quality gating, enables adaptive replanning and error recovery. Evaluated officially on the OSWorld benchmark, Agentic Lybic achieves a state-of-the-art 57.07% success rate in 50 steps, substantially outperforming existing methods. Results demonstrate that principled multi-agent orchestration with continuous quality control provides superior reliability for generalized desktop automation in complex computing environments. </p>
<blockquote>
<p>桌面自动化中的自主代理在处理复杂的多步骤任务时，由于协调不佳和质量控制不足而面临困难。我们引入了Agentic Lybic，这是一种新型的多代理系统，整个架构作为有限状态机（FSM）运行。这一核心创新实现了动态协同。我们的系统由四个组件组成：控制器、管理器、三个工作者（技术工人负责基于代码的操作、操作员负责GUI交互、分析师负责决策支持），以及评估器。关键机制是这些组件之间的FSM基于路由，它通过动态选择每个子任务的最佳执行策略来提供灵活性和通用性。这种有原则性的协同，结合强大的质量门控，能够实现自适应的重新规划和错误恢复。在OSWorld基准测试上进行官方评估，Agentic Lybic在50步内达到了最先进的57.07%的成功率，大幅超越了现有方法。结果表明，在复杂的计算环境中，有原则的多代理协同配合以及持续的质量控制能为通用的桌面自动化提供更高的可靠性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11067v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>文章介绍了一种名为Agentic Lybic的新型多智能体系统，该系统通过有限状态机（FSM）对整个架构进行动态编排。包括控制器、管理器、技术工人、操作工人、分析师和评估器在内的系统组件之间通过FSM进行状态路由选择最优执行策略以实现自动化任务的高可靠性。评价结果表明，基于原则的多智能体编排与持续的质量控制为复杂的桌面自动化提供了卓越的可靠性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agentic Lybic是一种新型的多智能体系统，用于解决桌面自动化中的复杂多任务问题。</li>
<li>该系统采用有限状态机（FSM）进行智能体间的协调和任务执行策略的选择。</li>
<li>Agentic Lybic包括控制器、管理器、技术工人、操作工人、分析师和评估器等组件。</li>
<li>FSM为基础的状态路由选择能够实现动态编排，提供系统的灵活性和通用性。</li>
<li>通过连续的质量控制，Agentic Lybic能够在复杂计算环境中实现高质量的桌面自动化。</li>
<li>在OSWorld基准测试中，Agentic Lybic达到了57.07%的成功率，显著优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11067">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.11067v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.11067v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Auditable-Early-Stopping-for-Agentic-Routing-Ledger-Verified-Run-Wise-Certificates-under-Local-DP"><a href="#Auditable-Early-Stopping-for-Agentic-Routing-Ledger-Verified-Run-Wise-Certificates-under-Local-DP" class="headerlink" title="Auditable Early Stopping for Agentic Routing: Ledger-Verified Run-Wise   Certificates under Local DP"></a>Auditable Early Stopping for Agentic Routing: Ledger-Verified Run-Wise   Certificates under Local DP</h2><p><strong>Authors:Shivam Akhauri</strong></p>
<p>We address when a best-first router for tool-use agents can stop exploring without missing a better leaf, while preserving local differential privacy (LDP) and leaving an audit trail. We introduce a run-wise certificate that couples each node’s key to the same exponential race that realizes leaf perturbations; the usual halting rule (stop when the maximum over $v$ in $F$ of Key$(v) \le B^*$) then certifies the realized run. We give two certified modes on context-indexed prefix DAGs with child partition: (i) Exact (known counts), using lazy offset propagation with winner reuse; and (ii) Surrogate (upper bounds only), which anchors keys to a parent-level surrogate race and allows validator tightening via $\kappa &#x3D; \log(N &#x2F; N_{ub}$). A small compiler enforces the partition property, and an admissible, race-independent M(tau) keeps keys sound. The ledger logs uniforms, counts, and tie handling; privacy follows by post-processing. Experiments on synthetic graphs and a small real pipeline show tight stopping, deterministic replay, and low overhead. </p>
<blockquote>
<p>我们探讨了在工具使用代理中使用最佳优先路由器时，如何能在不遗漏更好节点的情况下停止探索，同时保留本地差分隐私（LDP）并留下审计跟踪。我们引入了一种运行证书，它将每个节点的密钥与实现叶节点扰动的相同指数竞赛相结合；通常的停止规则（当F中的v的最大值Key(v)≤B*时停止）验证了已实现运行的有效性。我们在具有子分区的上下文索引前缀DAG上给出了两种认证模式：（i）精确模式（已知计数），使用懒惰偏移传播和重用赢家；（ii）替代模式（仅上限），将密钥锚定到父级替代竞赛，并通过κ&#x3D;log(N&#x2F;Nub)允许验证器收紧。一个小型编译器强制执行分区属性，一个可接受的、与比赛无关的M(tau)保持密钥声音清晰。账簿记录统一信息、计数和平局处理；隐私通过后期处理实现。在合成图和一个小型真实管道上的实验表明，停止紧密、确定性重播和开销低。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10550v2">PDF</a> </p>
<p><strong>Summary</strong>：我们设计了一种用于工具使用代理的最佳首路由器，可在停止探索时不会错过更好的叶子节点，同时保留本地差分隐私（LDP）并留下审计跟踪。我们引入了运行证书，将每个节点的密钥与实现叶子扰动的相同指数竞赛相结合。通常的停止规则是当在F中的v的最大值满足Key(v)≤B*时停止运行。我们在具有子分区的上下文索引前缀DAG上提供了两种认证模式：（i）精确模式（已知计数），使用懒惰偏移传播和重用获胜者；（ii）替代模式（仅上限），将密钥锚定到父级替代竞赛，并通过κ&#x3D;log(N &#x2F; Nub)允许验证器收紧。小型编译器强制执行分区属性，不受竞赛影响的M(tau)使密钥保持有效性。分类帐记录统一信息、计数和捆绑处理情况；隐私通过后期处理实现。合成图和实际管道的实验显示停止紧密、确定性回放和开销低。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>最佳首路由器允许工具使用代理在探索过程中停止，同时确保不会错过更优的叶子节点。</li>
<li>通过引入运行证书，结合节点密钥与叶子扰动的指数竞赛，实现了停止探索的认证。</li>
<li>提供了两种认证模式：精确模式和替代模式，分别适用于不同的使用场景和需求。</li>
<li>懒惰偏移传播和重用获胜者的策略提高了效率和准确性。</li>
<li>通过将密钥锚定到父级替代竞赛和验证器收紧机制，增强了系统的稳定性和可靠性。</li>
<li>小型编译器负责强制执行分区属性，确保系统的分区特性得到遵守。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10550">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2509.10550v2/page_0_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning"><a href="#PVPO-Pre-Estimated-Value-Based-Policy-Optimization-for-Agentic-Reasoning" class="headerlink" title="PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic   Reasoning"></a>PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic   Reasoning</h2><p><strong>Authors:Wenfeng Feng, Penghong Zhao, Guochao Jiang, Chuzhan Hao, Yuewei Zhang, Hao Wang, Guohua Liu</strong></p>
<p>Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts during training. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Moreover, PVPO is orthogonal to other advanced critic-free RL algorithms, making it compatible with and complementary to these methods. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales. </p>
<blockquote>
<p>无评论家强化学习方法，特别是小组策略，因其在处理复杂任务时的效率而备受关注。然而，这些方法严重依赖于策略内的多次采样和比较来估算优势，这可能导致策略陷入局部最优并增加计算成本。为了解决这些问题，我们提出了PVPO，这是一种通过优势参考锚点和数据预采样增强效率的无评论家强化学习方法。具体来说，我们提前使用参考模型进行推演，并将计算出的奖励分数作为参考锚点。我们的方法有效地纠正了组内比较引起的累积偏差，并显著减少了训练过程中对手游次数的依赖。同时，参考模型可以在数据预采样时评估样本难度，从而实现高收益数据的有效选择，提高训练效率。此外，PVPO与其他先进的无评论家强化学习算法正交，使其能够与其他方法兼容并互补。在两个领域的九个数据集上进行的实验表明，PVPO达到了最新技术水平。我们的方法不仅表现出跨多个任务的稳健泛化能力，而且在不同规模的模型上表现出可扩展的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.21104v2">PDF</a> 17 pages, 9 figures</p>
<p><strong>Summary</strong><br>强化学习中的无评论家方法，特别是群组策略，因其在复杂任务中的高效率而受到关注。但此方法依赖于策略内的多次采样和比较来估算优势，可能导致策略陷入局部最优并增加计算成本。为解决这些问题，我们提出PVPO方法，通过优势参考锚点和数据预采样增强效率。使用参考模型提前预测，并将计算得到的奖励分数作为参考锚点，有效纠正由组内比较引起的累积偏差，并显著降低训练过程中对多次预测滚动的依赖。同时，参考模型可在数据预采样时评估样本难度，有效选择高收益数据提高训练效率。PVPO与其他先进无评论家强化学习算法正交，可与之兼容并互补。在多个数据集上的实验表明，PVPO达到最佳性能，不仅表现稳健且适用于各种任务规模。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>批评家强化学习方法在处理复杂任务时具有很高的效率。</li>
<li>该方法依赖于多次采样和比较来估算优势，可能导致局部最优和计算成本增加。</li>
<li>PVPO方法通过优势参考锚点和数据预采样提高了强化学习的效率。</li>
<li>参考模型用于提前预测并计算奖励分数作为参考锚点，纠正了累积偏差并减少了训练中对多次预测滚动的依赖。</li>
<li>参考模型可以评估样本难度，选择高收益数据提高训练效率。</li>
<li>PVPO与其他先进强化学习算法兼容并可以与之互补。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.21104">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.21104v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.21104v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AMAZe-A-Multi-Agent-Zero-shot-Index-Advisor-for-Relational-Databases"><a href="#AMAZe-A-Multi-Agent-Zero-shot-Index-Advisor-for-Relational-Databases" class="headerlink" title="AMAZe: A Multi-Agent Zero-shot Index Advisor for Relational Databases"></a>AMAZe: A Multi-Agent Zero-shot Index Advisor for Relational Databases</h2><p><strong>Authors:Zhaodonghui Li, Haitao Yuan, Jiachen Shi, Hao Zhang, Yu Rong, Gao Cong</strong></p>
<p>Index recommendation is one of the most important problems in database management system (DBMS) optimization. Given queries and certain index-related constraints, traditional methods rely on heuristic optimization or learning-based models to select effective indexes and improve query performance. However, heuristic optimization suffers from high computation time, and learning-based models lose generalisability due to training for different workloads and database schemas. With the recent rapid development of large language models (LLMs), methods using prompt tuning have been proposed to enhance the efficiency of index selection. However, such methods still can not achieve the state-of-the-art (SOTA) results, and preparing the index selection demonstrations is also resource-intensive. To address these issues, we propose AMAZe, a zero-shot LLM-based index advisor with a multi-agent framework. We decompose the index recommendation problem into sub-steps, including planning, selection, combination, revision, and reflection. A set of LLM-embedded agents is designed to handle each one of the different sub-steps. Our method utilizes high-level agents to control the index selection process and low-level agents to select and revise indexes. Through extensive experiments, we show that our proposed AMAZe not only achieves the SOTA performance compared to the heuristic methods, but also outperforms learning-based and prompt-based methods with higher efficiency and better zero-shot inference ability. </p>
<blockquote>
<p>数据库管理系统（DBMS）优化中最重要的问题之一是索引推荐。给定查询和某些与索引相关的约束，传统方法依赖于启发式优化或基于学习模型的策略来选择有效索引并提高查询性能。然而，启发式优化存在计算时间长的问题，而基于学习模型的策略由于针对不同工作负载和数据库模式进行训练，其泛化能力受到限制。随着大型语言模型（LLM）的快速发展，提出了基于提示调整的方法来提高索引选择的效率。然而，这些方法仍无法达到最新水平的结果，并且准备索引选择演示也是资源密集型的。为了解决这些问题，我们提出了AMAZe，这是一个基于多智能体框架的零样本LLM索引顾问。我们将索引推荐问题分解为规划、选择、组合、修订和反思等子步骤。设计了一组嵌入LLM的智能体来处理不同的子步骤。我们的方法利用高级智能体来控制索引选择过程，而低级智能体则负责选择和修订索引。通过广泛的实验，我们证明了所提出的AMAZe不仅与启发式方法相比达到了最新水平的表现，而且与基于学习和基于提示的方法相比，具有更高的效率和更好的零样本推理能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.16044v2">PDF</a> </p>
<p><strong>Summary</strong><br>数据库优化中最重要的挑战之一是索引推荐。传统方法通常依赖启发式优化或基于学习模型的策略来选择有效索引以提高查询性能，但存在计算时间长和泛化能力不足的问题。随着大型语言模型（LLM）的发展，已有通过提示调整提高索引选择效率的方法，但仍未达到最佳效果。为解决这些问题，我们提出了AMAZe，这是一个基于多智能体的零样本LLM索引顾问。它将索引推荐问题分解为规划、选择、组合、修订和反思等子步骤，并设计了一组LLM嵌入的智能体来处理每个子步骤。我们的方法利用高级智能体控制索引选择过程，低级智能体进行索引的选择和修订。实验表明，相比启发式方法和其他LLM相关方法，AMAZe性能更优。它不仅达到当前状态的最佳水平，且更具效率且有良好的零样本推理能力。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>数据库管理系统优化的关键问题是索引推荐。</li>
<li>传统方法依赖启发式优化和基于学习模型的策略，存在计算时间长和泛化能力不足的问题。</li>
<li>大型语言模型（LLM）在索引选择中展现出潜力。</li>
<li>提出AMAZe方法，基于多智能体框架进行索引推荐，包括规划、选择等子步骤。</li>
<li>高级和低级智能体分别控制索引选择过程和进行具体选择修订。</li>
<li>AMAZe达到了最佳性能水平，并具有更高的效率和零样本推理能力。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.16044">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2508.16044v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Breaking-Single-Tester-Limits-Multi-Agent-LLMs-for-Multi-User-Feature-Testing"><a href="#Breaking-Single-Tester-Limits-Multi-Agent-LLMs-for-Multi-User-Feature-Testing" class="headerlink" title="Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature   Testing"></a>Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature   Testing</h2><p><strong>Authors:Sidong Feng, Changhao Du, Huaxiao Liu, Qingnan Wang, Zhengwei Lv, Mengfei Wang, Chunyang Chen</strong></p>
<p>The growing dependence on mobile phones and their apps has made multi-user interactive features, like chat calls, live streaming, and video conferencing, indispensable for bridging the gaps in social connectivity caused by physical and situational barriers. However, automating these interactive features for testing is fraught with challenges, owing to their inherent need for timely, dynamic, and collaborative user interactions, which current automated testing methods inadequately address. Inspired by the concept of agents designed to autonomously and collaboratively tackle problems, we propose MAdroid, a novel multi-agent approach powered by the Large Language Models (LLMs) to automate the multi-user interactive task for app feature testing. Specifically, MAdroid employs two functional types of multi-agents: user agents (Operator) and supervisor agents (Coordinator and Observer). Each agent takes a specific role: the Coordinator directs the interactive task; the Operator mimics user interactions on the device; and the Observer monitors and reviews the task automation process. Our evaluation, which included 41 multi-user interactive tasks, demonstrates the effectiveness of our approach, achieving 82.9% of the tasks with 96.8% action similarity, outperforming the ablation studies and state-of-the-art baselines. Additionally, a preliminary investigation underscores MAdroid’s practicality by helping identify 11 multi-user interactive bugs during regression app testing, confirming its potential value in real-world software development contexts. </p>
<blockquote>
<p>随着对手机和应用程序的依赖日益增强，多用户交互功能（如语音通话、直播和视频会议）已成为弥合因物理和情境障碍造成的社交连接间隙不可或缺的工具。然而，自动化测试这些交互功能充满挑战，因为它们需要及时、动态和协作性的用户交互，而当前自动化测试方法在这方面并不充分。受自主协作解决问题的代理概念启发，我们提出了MAdroid，这是一种新型的多代理方法，借助大型语言模型（LLM）的力量，为应用程序功能测试中的多用户交互任务提供自动化支持。具体来说，MAdroid采用两种功能型多代理：用户代理（操作者）和监管代理（协调者和观察者）。每个代理都扮演着特定的角色：协调者负责指导交互任务；操作者模仿设备上的用户交互；观察者则监控和审查任务自动化过程。我们的评估包括41个多用户交互任务，证明了我们的方法的有效性，在82.9%的任务中实现了96.8%的动作相似性，超过了消融研究和最先进的基线技术。此外，初步调查强调了MAdroid的实际应用价值，在回归应用测试中帮助识别了11个多用户交互缺陷，证实了其在现实软件开发环境中的潜在价值。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.17539v3">PDF</a> Accepted to International Conference on Software Engineering (ICSE   2026). arXiv admin note: substantial text overlap with arXiv:2504.15474</p>
<p><strong>Summary</strong><br>移动设备和应用程序的日益依赖使得多用户交互功能（如聊天通话、直播和视频会议）变得至关重要，它们弥补了社交连接中的差距。然而，自动化这些交互功能的测试充满挑战，因为需要及时的动态协作交互，现有的自动化测试方法难以满足需求。本文提出了基于大型语言模型（LLMs）的MAdroid多代理方法，该方法采用用户代理和监管代理共同执行任务，为应用功能测试中的多用户交互任务提供自动化解决方案。评估结果表明，该方法在任务完成率和动作相似性方面均优于基准模型，具有实用价值。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>移动设备和应用程序的依赖推动了多用户交互功能的重要性。</li>
<li>多用户交互功能的自动化测试面临挑战，需要及时的动态协作交互。</li>
<li>MAdroid是一种基于大型语言模型的多代理方法，用于自动化多用户交互任务的测试。</li>
<li>MAdroid包含三种代理：协调者、操作者和观察者。</li>
<li>评估结果表明MAdroid在任务完成率和动作相似性方面表现出色。</li>
<li>MAdroid有助于识别多用户交互中的回归测试错误，具有实用价值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.17539">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.17539v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Small-Language-Models-are-the-Future-of-Agentic-AI"><a href="#Small-Language-Models-are-the-Future-of-Agentic-AI" class="headerlink" title="Small Language Models are the Future of Agentic AI"></a>Small Language Models are the Future of Agentic AI</h2><p><strong>Authors:Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan Fu, Xin Dong, Saurav Muralidharan, Yingyan Celine Lin, Pavlo Molchanov</strong></p>
<p>Large language models (LLMs) are often praised for exhibiting near-human performance on a wide range of tasks and valued for their ability to hold a general conversation. The rise of agentic AI systems is, however, ushering in a mass of applications in which language models perform a small number of specialized tasks repetitively and with little variation.   Here we lay out the position that small language models (SLMs) are sufficiently powerful, inherently more suitable, and necessarily more economical for many invocations in agentic systems, and are therefore the future of agentic AI. Our argumentation is grounded in the current level of capabilities exhibited by SLMs, the common architectures of agentic systems, and the economy of LM deployment. We further argue that in situations where general-purpose conversational abilities are essential, heterogeneous agentic systems (i.e., agents invoking multiple different models) are the natural choice. We discuss the potential barriers for the adoption of SLMs in agentic systems and outline a general LLM-to-SLM agent conversion algorithm.   Our position, formulated as a value statement, highlights the significance of the operational and economic impact even a partial shift from LLMs to SLMs is to have on the AI agent industry. We aim to stimulate the discussion on the effective use of AI resources and hope to advance the efforts to lower the costs of AI of the present day. Calling for both contributions to and critique of our position, we commit to publishing all such correspondence at <a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/lpr/slm-agents">https://research.nvidia.com/labs/lpr/slm-agents</a>. </p>
<blockquote>
<p>大型语言模型（LLM）通常因在广泛的任务中展现出接近人类的性能而受到赞誉，并因其能够进行一般对话的能力而备受重视。然而，代理人工智能系统的兴起正迎来大量应用，在这些应用中，语言模型反复执行少量专门任务，且变化甚微。在这里，我们提出观点，小型语言模型（SLM）足够强大，内在地更适合，并且在代理系统中的多次调用中更加经济，因此是代理人工智能的未来。我们的论证依据是小型语言模型当前所展现的能力水平、代理系统的常见架构，以及语言模型部署的经济性。我们进一步认为，在需要通用对话能力的情况下，异质代理系统（即调用多个不同模型的代理）是自然而然的选择。我们讨论了小型语言模型在代理系统中采用可能遇到的潜在障碍，并概述了从大型语言模型到小型语言模型代理的转换算法。我们的立场作为价值陈述而制定，突显了从大型语言模型部分转向小型语言模型对人工智能代理行业操作和经济的重大影响。我们旨在激发关于人工智能资源有效利用的讨论，并希望推动降低当前人工智能成本的努力。我们呼吁对我们的立场做出贡献和批评，并承诺将在<a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/lpr/slm-agents%E4%B8%8A%E5%85%AC%E5%B8%83%E6%89%80%E6%9C%89%E5%BE%80%E6%9D%A5%E9%80%9A%E4%BF%A1%E3%80%82">https://research.nvidia.com/labs/lpr/slm-agents上公布所有往来通信。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02153v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）虽被誉为能在多种任务上展现出接近人类的性能，并具备通用对话能力，但在智能代理系统的新浪潮中，小型语言模型（SLM）因其强大的专业能力、内在的优势和经济的成本而备受关注。本文主张SLM是智能代理系统的未来，并在适当的情况下提倡使用异构智能代理系统（即调用多个不同模型的代理）。文章讨论了采用SLM的潜在障碍，并概述了从大型语言模型转向小型语言模型的智能代理转换算法。本文旨在激发关于AI资源有效利用的讨论，并希望推动降低当前AI成本的努力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）和小型语言模型（SLM）在智能代理系统中的应用差异。</li>
<li>SLM的专业能力、内在优势和经济效益在智能代理系统中的体现。</li>
<li>在需要通用对话能力的情况下，提倡使用异构智能代理系统。</li>
<li>采用SLM的潜在障碍分析。</li>
<li>从LLM到SLM的智能代理转换算法的概述。</li>
<li>SLM对智能代理行业运营和经济影响的重要性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02153">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.02153v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2506.02153v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="HiMATE-A-Hierarchical-Multi-Agent-Framework-for-Machine-Translation-Evaluation"><a href="#HiMATE-A-Hierarchical-Multi-Agent-Framework-for-Machine-Translation-Evaluation" class="headerlink" title="HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation   Evaluation"></a>HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation   Evaluation</h2><p><strong>Authors:Shijie Zhang, Renhao Li, Songsheng Wang, Philipp Koehn, Min Yang, Derek F. Wong</strong></p>
<p>The advancement of Large Language Models (LLMs) enables flexible and interpretable automatic evaluations. In the field of machine translation evaluation, utilizing LLMs with translation error annotations based on Multidimensional Quality Metrics (MQM) yields more human-aligned judgments. However, current LLM-based evaluation methods still face challenges in accurately identifying error spans and assessing their severity. In this paper, we propose HiMATE, a Hierarchical Multi-Agent Framework for Machine Translation Evaluation. We argue that existing approaches inadequately exploit the fine-grained structural and semantic information within the MQM hierarchy. To address this, we develop a hierarchical multi-agent system grounded in the MQM error typology, enabling granular evaluation of subtype errors. Two key strategies are incorporated to further mitigate systemic hallucinations within the framework: the utilization of the model’s self-reflection capability and the facilitation of agent discussion involving asymmetric information. Empirically, HiMATE outperforms competitive baselines across different datasets in conducting human-aligned evaluations. Further analyses underscore its significant advantage in error span detection and severity assessment, achieving an average F1-score improvement of 89% over the best-performing baseline. We make our code and data publicly available at <a target="_blank" rel="noopener" href="https://github.com/nlp2ct-shijie/HiMATE">https://github.com/nlp2ct-shijie/HiMATE</a>. </p>
<blockquote>
<p>随着大型语言模型（LLMs）的不断发展，灵活的自动评估与可解释性评估得以实现。在机器翻译评估领域，基于多维质量指标（MQM）的翻译错误标注与LLMs的应用相结合，使得判断更加符合人类标准。然而，当前基于LLM的评估方法仍面临准确识别错误跨度及评估其严重性的挑战。本文提出了一种用于机器翻译评估的分层多智能体框架HiMATE。我们认为现有方法未能充分利用MQM层次结构中的精细结构化和语义信息。为解决这一问题，我们开发了一个基于MQM错误分类的分层多智能体系统，实现对子类型错误的精细评估。此外，我们通过两种方法进一步缓解系统内的虚构现象：利用模型的自我反思能力和促进涉及不对称信息的智能体讨论。经验表明，HiMATE在不同数据集上进行符合人类标准的评估时表现优于竞争基线。进一步的分析强调了其在错误跨度检测和严重性评估方面的显著优势，平均F1分数较最佳基线提高了89%。我们的代码和数据将在<a target="_blank" rel="noopener" href="https://github.com/nlp2ct-shijie/HiMATE%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/nlp2ct-shijie/HiMATE公开可用。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16281v3">PDF</a> </p>
<p><strong>Summary</strong><br>LLMs结合多维质量度量MQM对机器翻译进行评估越来越接近人类判断。但现有方法难以准确识别错误范围和评估其严重性。本文提出HiMATE，一种基于MQM错误分类的分层多智能体机器翻译评估框架。框架融合了两种策略应对系统偏见现象。分析显示，HiMATE相比其它方案有更好的性能。通过开放源码数据展示了优越性。欢迎访问<a target="_blank" rel="noopener" href="https://github.com/nlp2ct-shijie/HiMATE%E4%BA%86%E8%A7%A3%E6%9B%B4%E5%A4%9A%E4%BF%A1%E6%81%AF%E3%80%82">https://github.com/nlp2ct-shijie/HiMATE了解更多信息。</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMs与MQM结合的机器翻译评估更接近人类判断。</li>
<li>当前方法难以准确识别错误范围和评估其严重性。</li>
<li>提出HiMATE框架，基于MQM错误分类进行分层多智能体评估。</li>
<li>融合两种策略应对系统偏见现象。</li>
<li>HiMATE在多个数据集上超越其他方案，特别是在错误识别和评估方面表现显著。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16281">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2505.16281v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2505.16281v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2505.16281v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2505.16281v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="TRANSAGENT-An-LLM-Based-Multi-Agent-System-for-Code-Translation"><a href="#TRANSAGENT-An-LLM-Based-Multi-Agent-System-for-Code-Translation" class="headerlink" title="TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation"></a>TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation</h2><p><strong>Authors:Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou</strong></p>
<p>Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages.   In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent. </p>
<blockquote>
<p>代码翻译是将代码从一个编程语言转换为另一个语言，同时保持其原始功能，这在软件迁移、系统重构和跨平台开发中是至关重要的。传统的基于规则的方法依赖于手动编写的规则，这既耗时又常常导致生成的代码可读性较差。为了克服这一问题，已经开发了基于学习的方法，利用并行数据来训练模型以实现自动化代码翻译。最近，大型语言模型（LLM）的进展进一步推动了基于学习的代码翻译。尽管前景看好，但LLM翻译的程序仍然存在多种质量问题（例如，语法错误和语义错误）。特别是，当仅提供相应的错误消息时，LLM自我调试这些错误可能会面临挑战。</p>
</blockquote>
<p>在这项工作中，我们提出了一种基于LLM的多智能体系统TRANSAGENT，它通过四个基于LLM的智能体之间的协同作用，提高了基于LLM的代码翻译，包括初始代码翻译器、语法错误修复器、代码对齐器和语义错误修复器。TRANSAGENT的主要见解是基于目标程序与源程序的执行对齐来首先定位错误代码块，这样可以缩小修复空间，从而降低修复难度。为了评估TRANSAGENT，我们首先构建了新的基准测试，以缓解潜在的数据泄露问题。在我们的基准测试中，TRANSAGENT在翻译效果和效率上都超越了最新的LLM-based代码翻译技术UniTrans；此外，我们对不同LLM的评估显示了TRANSAGENT的通用性，我们的消融研究显示了每个智能体的贡献。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.19894v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了代码翻译的重要性，其可将代码从一种编程语言转换为另一种语言，同时保持原始功能。传统的方法依赖于手动编写的规则，但这种方法耗时且生成的代码可读性较差。为了解决这个问题，研究者开发了基于学习的方法，利用平行数据训练模型进行自动化代码翻译。最近，大型语言模型（LLM）的进步进一步推动了基于学习的代码翻译的发展。然而，LLM翻译的程序仍存在各种质量问题，如语法和语义错误。针对这些问题，本文提出了一种基于LLM的多代理系统TRANSAGENT，它通过四个LLM代理的协同工作，包括初始代码翻译器、语法错误修复器、代码对齐器和语义错误修复器，提高了LLM基于的代码翻译的质量。TRANSAGENT的主要见解是通过执行目标程序与源程序的对比来定位错误代码块，从而缩小修复范围并降低修复难度。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>代码翻译是将代码从一种编程语言转换为另一种语言的过程，对于软件迁移、系统重构和跨平台开发至关重要。</li>
<li>传统规则方法耗时且生成的代码可读性较差，因此研究者开发了基于学习的方法以提高效率。</li>
<li>大型语言模型（LLM）在代码翻译领域具有广泛的应用前景，但仍存在语法和语义错误等问题。</li>
<li>TRANSAGENT是一种基于LLM的多代理系统，通过协同工作提高了LLM在代码翻译方面的性能，包括初始代码翻译、语法错误修复、代码对齐和语义错误修复。</li>
<li>TRANSAGENT能够定位错误代码块，缩小修复范围，降低修复难度。</li>
<li>TRANSAGENT在翻译有效性和效率方面都优于最新的LLM-based代码翻译技术UniTrans。</li>
<li>TRANSAGENT具有泛化能力，并且在不同的LLM上的评价表现良好。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.19894">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2409.19894v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Crafting-Customisable-Characters-with-LLMs-A-Persona-Driven-Role-Playing-Agent-Framework"><a href="#Crafting-Customisable-Characters-with-LLMs-A-Persona-Driven-Role-Playing-Agent-Framework" class="headerlink" title="Crafting Customisable Characters with LLMs: A Persona-Driven   Role-Playing Agent Framework"></a>Crafting Customisable Characters with LLMs: A Persona-Driven   Role-Playing Agent Framework</h2><p><strong>Authors:Bohao Yang, Dong Liu, Chenghao Xiao, Kun Zhao, Chen Tang, Chao Li, Lin Yuan, Guang Yang, Chenghua Lin</strong></p>
<p>Large Language Models (LLMs) demonstrate remarkable ability to comprehend instructions and generate human-like text, enabling sophisticated agent simulation beyond basic behavior replication. However, the potential for creating freely customisable characters remains underexplored. We introduce the Customisable Conversation Agent Framework, which employs LLMs to simulate real-world characters through personalised characteristic feature injection, enabling diverse character creation according to user preferences. We propose the SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn role-playing dialogues across 1,360 real-world scenes. Characters are initially customised using pre-defined elements (career, aspiration, traits, skills), then expanded through personal and social profiles. Building on this, we present SimsChat, a freely customisable role-playing agent incorporating various realistic settings and topic-specified character interactions. Experimental results on both SimsConv and WikiRoleEval datasets demonstrate SimsChat’s superior performance in maintaining character consistency, knowledge accuracy, and appropriate question rejection compared to existing models. Our framework provides valuable insights for developing more accurate and customisable human simulacra. Our data and code are publicly available at <a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat">https://github.com/Bernard-Yang/SimsChat</a>. </p>
<blockquote>
<p>大型语言模型（LLMs）表现出令人瞩目的理解和执行指令的能力，以及生成类似人类的文本，使得复杂的代理模拟超越了基本行为复制。然而，创建可自由定制角色的潜力仍未被充分探索。我们引入了可定制对话代理框架，该框架利用LLMs通过个性化特征注入来模拟现实角色，并根据用户偏好实现多样化的角色创建。我们提出了SimsConv数据集，包含68个自定义角色和13971个跨1360个现实场景的多轮角色扮演对话。角色最初使用预定义元素（职业、抱负、特质、技能）进行定制，然后通过个人和社会档案进行扩展。在此基础上，我们推出了SimsChat，这是一个可自由定制的角色扮演代理，包含各种现实场景和特定话题的角色互动。在SimsConv和WikiRoleEval数据集上的实验结果证明了SimsChat在保持角色一致性、知识准确性和适当问题拒绝方面的优越性能。我们的框架为开发更准确、可定制的人类模拟物提供了有价值的见解。我们的数据和代码可在<a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/Bernard-Yang/SimsChat公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.17962v7">PDF</a> EMNLP 2025 Findings</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLMs）能够理解和执行指令，生成人类文本，实现超越基本行为复制的复杂代理模拟。然而，创建可自由定制角色的潜力尚未得到充分探索。我们引入了可定制对话代理框架，利用LLMs模拟现实世界角色，通过个性化特征注入实现根据用户偏好创建多样化角色。我们提出SimsConv数据集，包含68个自定义角色和13971个跨1360个现实场景的多轮角色扮演对话。角色首先使用预定义元素（职业、抱负、特质、技能）进行定制，然后通过个人和社会概况进行扩展。在此基础上，我们推出了SimsChat，一个可自由定制的角色扮演代理，融入各种现实场景和主题特定的角色交互。在SimsConv和WikiRoleEval数据集上的实验结果证明了SimsChat在保持角色一致性、知识准确性和适当问题拒绝方面的优势。我们的框架为开发更准确、可定制的人类模拟物提供了有价值的见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）能模拟复杂行为，但创建自由定制角色的潜力尚未充分探索。</li>
<li>提出了可定制对话代理框架，利用LLMs模拟现实角色，实现用户偏好下的多样化角色创建。</li>
<li>SimsConv数据集包含自定义角色和多轮角色扮演对话，用于训练和评估对话代理。</li>
<li>角色通过预定义元素（如职业、特质）进行定制，并通过个人和社会概况进一步扩展。</li>
<li>SimsChat能融入现实场景和主题特定的角色交互，并在实验上展示了其性能优势。</li>
<li>SimsChat在保持角色一致性、知识准确性和问题拒绝方面表现优越。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.17962">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2406.17962v7/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2406.17962v7/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2406.17962v7/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Agent/2406.17962v7/page_5_1.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-18/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-18/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-18/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Few-Shot/2509.12387v1/page_0_0.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-09-18  The Few-shot Dilemma Over-prompting Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-18/LLM/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_LLM/2509.13310v1/page_2_0.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-09-18  Scaling Agents via Continual Pre-training
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30341.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
