<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-09-18  MIA-EPT Membership Inference Attack via Error Prediction for Tabular   Data">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_2_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    31 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-18-更新"><a href="#2025-09-18-更新" class="headerlink" title="2025-09-18 更新"></a>2025-09-18 更新</h1><h2 id="MIA-EPT-Membership-Inference-Attack-via-Error-Prediction-for-Tabular-Data"><a href="#MIA-EPT-Membership-Inference-Attack-via-Error-Prediction-for-Tabular-Data" class="headerlink" title="MIA-EPT: Membership Inference Attack via Error Prediction for Tabular   Data"></a>MIA-EPT: Membership Inference Attack via Error Prediction for Tabular   Data</h2><p><strong>Authors:Eyal German, Daniel Samira, Yuval Elovici, Asaf Shabtai</strong></p>
<p>Synthetic data generation plays an important role in enabling data sharing, particularly in sensitive domains like healthcare and finance. Recent advances in diffusion models have made it possible to generate realistic, high-quality tabular data, but they may also memorize training records and leak sensitive information. Membership inference attacks (MIAs) exploit this vulnerability by determining whether a record was used in training. While MIAs have been studied in images and text, their use against tabular diffusion models remains underexplored despite the unique risks of structured attributes and limited record diversity. In this paper, we introduce MIAEPT, Membership Inference Attack via Error Prediction for Tabular Data, a novel black-box attack specifically designed to target tabular diffusion models. MIA-EPT constructs errorbased feature vectors by masking and reconstructing attributes of target records, disclosing membership signals based on how well these attributes are predicted. MIA-EPT operates without access to the internal components of the generative model, relying only on its synthetic data output, and was shown to generalize across multiple state-of-the-art diffusion models. We validate MIA-EPT on three diffusion-based synthesizers, achieving AUC-ROC scores of up to 0.599 and TPR@10% FPR values of 22.0% in our internal tests. Under the MIDST 2025 competition conditions, MIA-EPT achieved second place in the Black-box Multi-Table track (TPR@10% FPR &#x3D; 20.0%). These results demonstrate that our method can uncover substantial membership leakage in synthetic tabular data, challenging the assumption that synthetic data is inherently privacy-preserving. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/eyalgerman/MIA-EPT">https://github.com/eyalgerman/MIA-EPT</a>. </p>
<blockquote>
<p>合成数据生成在促进数据共享方面发挥着重要作用，特别是在医疗和金融等敏感领域。扩散模型的最新进展使得生成现实、高质量表格数据成为可能，但它们也可能记住训练记录并泄露敏感信息。成员推理攻击（MIAs）通过确定记录是否用于训练来利用这一漏洞。虽然MIAs在图像和文本方面已有研究，但针对表格扩散模型的应用仍然被忽视，尽管结构化属性和记录多样性有限存在独特风险。在本文中，我们介绍了MIA-EPT（基于错误预测的表格数据成员推理攻击），这是一种专门针对表格扩散模型设计的新型黑箱攻击。MIA-EPT通过掩盖和重建目标记录的属性来构建基于错误的特征向量，并根据这些属性的预测情况披露成员身份信号。MIA-EPT操作无需访问生成模型的内部组件，仅依赖其合成数据输出，并且被证明可以在多个最先进的扩散模型中实现通用化。我们在三个基于扩散的合成器上验证了MIA-EPT，在我们的内部测试中，AUC-ROC得分高达0.599，TPR@10%FPR值为22.0%。在MIDST 2025竞赛条件下，MIA-EPT在Black-box Multi-Table赛道中取得第二名（TPR@10%FPR &#x3D; 20.0%）。这些结果表明，我们的方法可以揭示合成表格数据中的大量成员身份泄露，挑战了合成数据固有隐私保护假设。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/eyalgerman/MIA-EPT%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/eyalgerman/MIA-EPT公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13046v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>合成数据生成在促进数据共享方面发挥着重要作用，特别是在医疗和金融等敏感领域。扩散模型的最新进展使得生成现实、高质量的数据表成为可能，但它们也可能记住训练记录并泄露敏感信息。成员推理攻击（MIAs）利用这一漏洞，通过确定记录是否用于训练来利用扩散模型的脆弱性。尽管结构化属性和记录多样性的独特风险，针对数据表扩散模型的MIAs的使用仍然被忽视。本文介绍了一种专门针对数据表扩散模型的新型黑盒攻击MIA-EPT（基于误差预测的成员推理攻击）。MIA-EPT通过掩盖和重建目标记录的属性来构建基于错误的特征向量，并基于这些属性预测的准确度来披露成员身份信号。MIA-EPT无需访问生成模型的内部组件，仅依赖其合成数据输出进行操作，并且在多个最先进的扩散模型上表现出普遍适用性。我们在三个基于扩散的合成器上验证了MIA-EPT的有效性，在内部测试中达到AUC-ROC分数高达0.599，在TPR@10%FPR值为22.0%的情况下实现有效识别。在MIDST 2025竞赛条件下，MIA-EPT在黑盒多表赛道中获得了第二名（TPR@10%FPR &#x3D; 20.0%）。这些结果表明，我们的方法可以揭示合成数据表中的大量成员身份泄露，挑战了合成数据固有隐私保护属性的假设。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/eyalgerman/MIA-EPT">https://github.com/eyalgerman/MIA-EPT</a>公开访问。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>合成数据生成在敏感领域如医疗和金融中促进了数据共享。</li>
<li>扩散模型能够生成高质量的数据表，但可能泄露训练记录中的敏感信息。</li>
<li>成员推理攻击（MIAs）被用来确定记录是否用于扩散模型的训练，这是一种新型的攻击方式。</li>
<li>论文提出了一种新的黑盒攻击方法MIA-EPT，专门用于针对数据表扩散模型。</li>
<li>MIA-EPT通过构建基于错误的特征向量来揭示成员身份信号，这种方法不需要访问生成模型的内部组件。</li>
<li>在多个先进的扩散模型和多种测试环境下，MIA-EPT均表现出较高的识别准确率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13046">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13046v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13046v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13046v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ReTrack-Data-Unlearning-in-Diffusion-Models-through-Redirecting-the-Denoising-Trajectory"><a href="#ReTrack-Data-Unlearning-in-Diffusion-Models-through-Redirecting-the-Denoising-Trajectory" class="headerlink" title="ReTrack: Data Unlearning in Diffusion Models through Redirecting the   Denoising Trajectory"></a>ReTrack: Data Unlearning in Diffusion Models through Redirecting the   Denoising Trajectory</h2><p><strong>Authors:Qitan Shi, Cheng Jin, Jiawei Zhang, Yuantao Gu</strong></p>
<p>Diffusion models excel at generating high-quality, diverse images but suffer from training data memorization, raising critical privacy and safety concerns. Data unlearning has emerged to mitigate this issue by removing the influence of specific data without retraining from scratch. We propose ReTrack, a fast and effective data unlearning method for diffusion models. ReTrack employs importance sampling to construct a more efficient fine-tuning loss, which we approximate by retaining only dominant terms. This yields an interpretable objective that redirects denoising trajectories toward the $k$-nearest neighbors, enabling efficient unlearning while preserving generative quality. Experiments on MNIST T-Shirt, CelebA-HQ, CIFAR-10, and Stable Diffusion show that ReTrack achieves state-of-the-art performance, striking the best trade-off between unlearning strength and generation quality preservation. </p>
<blockquote>
<p>扩散模型在生成高质量、多样化的图像方面表现出色，但存在训练数据记忆问题，引发了关于隐私和安全的担忧。为了解决这一问题，数据遗忘通过在不重新训练的基础上消除特定数据的影响而出现。我们提出了ReTrack，这是一种快速有效的针对扩散模型的数据遗忘方法。ReTrack采用重要性采样构建更有效的微调损失，我们只保留主要项来进行近似，从而产生一个可解释的目标，引导降噪轨迹朝向k个最近邻，能够在保持生成质量的同时实现高效遗忘。在MNIST T恤、CelebA-HQ、CIFAR-10和Stable Diffusion上的实验表明，ReTrack达到了最先进的性能，在遗忘强度和生成质量保留之间取得了最佳平衡。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13007v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文讨论了扩散模型在生成高质量、多样化图像方面的优势，但同时也存在训练数据记忆问题，引发了隐私和安全担忧。为缓解这一问题，出现了数据遗忘技术，无需从头开始重新训练即可消除特定数据的影响。本文提出了一种快速有效的针对扩散模型的数据遗忘方法——ReTrack。ReTrack采用重要性采样构建更有效的微调损失，只保留主导项进行近似，从而产生可解释的目标，引导去噪轨迹朝向k近邻，在保持生成质量的同时实现高效遗忘。实验结果表明，ReTrack在MNIST T-Shirt、CelebA-HQ、CIFAR-10和Stable Diffusion数据集上达到了最佳遗忘强度和生成质量保留之间的平衡，实现了最先进的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>扩散模型虽能生成高质量、多样化的图像，但存在训练数据记忆问题，引发隐私和安全问题。</li>
<li>数据遗忘技术旨在缓解这一问题，无需完全重新训练即可消除特定数据的影响。</li>
<li>提出了一种新的数据遗忘方法——ReTrack，适用于扩散模型。</li>
<li>ReTrack采用重要性采样构建更有效的微调损失，只保留主导项进行近似。</li>
<li>ReTrack产生可解释的目标，引导去噪轨迹朝向k近邻，实现高效遗忘同时保持生成质量。</li>
<li>实验结果表明，ReTrack在多个数据集上实现了最先进的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13007">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13007v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13007v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13007v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13007v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.13007v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Runge-Kutta-Approximation-and-Decoupled-Attention-for-Rectified-Flow-Inversion-and-Semantic-Editing"><a href="#Runge-Kutta-Approximation-and-Decoupled-Attention-for-Rectified-Flow-Inversion-and-Semantic-Editing" class="headerlink" title="Runge-Kutta Approximation and Decoupled Attention for Rectified Flow   Inversion and Semantic Editing"></a>Runge-Kutta Approximation and Decoupled Attention for Rectified Flow   Inversion and Semantic Editing</h2><p><strong>Authors:Weiming Chen, Zhihan Zhu, Yijia Wang, Zhihai He</strong></p>
<p>Rectified flow (RF) models have recently demonstrated superior generative performance compared to DDIM-based diffusion models. However, in real-world applications, they suffer from two major challenges: (1) low inversion accuracy that hinders the consistency with the source image, and (2) entangled multimodal attention in diffusion transformers, which hinders precise attention control. To address the first challenge, we propose an efficient high-order inversion method for rectified flow models based on the Runge-Kutta solver of differential equations. To tackle the second challenge, we introduce Decoupled Diffusion Transformer Attention (DDTA), a novel mechanism that disentangles text and image attention inside the multimodal diffusion transformers, enabling more precise semantic control. Extensive experiments on image reconstruction and text-guided editing tasks demonstrate that our method achieves state-of-the-art performance in terms of fidelity and editability. Code is available at <a target="_blank" rel="noopener" href="https://github.com/wmchen/RKSovler_DDTA">https://github.com/wmchen/RKSovler_DDTA</a>. </p>
<blockquote>
<p>纠正流（RF）模型最近表现出比基于DDIM的扩散模型更优越的生成性能。然而，在实际应用中，它们面临两大挑战：（1）较低的反转精度，阻碍了与源图像的一致性；（2）扩散变压器中的纠缠多模态注意力，这阻碍了精确的控制注意力。为了解决第一个挑战，我们提出了一种基于Runge-Kutta微分方程求解器的高效高阶反转方法为纠正流模型。为了解决第二个挑战，我们引入了“解耦扩散变压器注意力”（DDTA）这一新机制，它在多模态扩散变压器内部解耦文本和图像注意力，从而实现更精确语义控制。在图像重建和文本指导编辑任务上的大量实验表明，我们的方法在保真度和可编辑性方面达到了最先进的性能。代码可在<a target="_blank" rel="noopener" href="https://github.com/wmchen/RKSovler_DDTA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/wmchen/RKSovler_DDTA找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12888v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于Rectified Flow模型的最新研究进展。针对现有挑战，如低反转精度和扩散变压器中的多模态注意力纠缠问题，研究团队提出了高效的高阶反转方法和解耦扩散变压器注意力机制（DDTA）。实验结果在图像重建和文本引导编辑任务上显示出卓越性能。相关代码已公开于GitHub。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Rectified flow模型在生成性能上展现出优于DDIM-based扩散模型的潜力。</li>
<li>该模型面临两大挑战：低反转精度和扩散变压器中的多模态注意力纠缠。</li>
<li>提出了一种基于Runge-Kutta解算器的高效高阶反转方法来解决低反转精度问题。</li>
<li>引入了Decoupled Diffusion Transformer Attention（DDTA）机制，解决了多模态注意力纠缠问题，实现了更精确的语义控制。</li>
<li>广泛的实验结果显示，该方法在图像重建和文本引导编辑任务上达到业界领先水平。</li>
<li>模型在提高保真度和可编辑性方面表现突出。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12888">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12888v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12888v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12888v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12888v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12888v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Generalizable-Holographic-Reconstruction-via-Amplitude-Only-Diffusion-Priors"><a href="#Generalizable-Holographic-Reconstruction-via-Amplitude-Only-Diffusion-Priors" class="headerlink" title="Generalizable Holographic Reconstruction via Amplitude-Only Diffusion   Priors"></a>Generalizable Holographic Reconstruction via Amplitude-Only Diffusion   Priors</h2><p><strong>Authors:Jeongsol Kim, Chanseok Lee, Jong Chul Ye, Mooseok Jang</strong></p>
<p>Phase retrieval in inline holography is a fundamental yet ill-posed inverse problem due to the nonlinear coupling between amplitude and phase in coherent imaging. We present a novel off-the-shelf solution that leverages a diffusion model trained solely on object amplitude to recover both amplitude and phase from diffraction intensities. Using a predictor-corrector sampling framework with separate likelihood gradients for amplitude and phase, our method enables complex field reconstruction without requiring ground-truth phase data for training. We validate the proposed approach through extensive simulations and experiments, demonstrating robust generalization across diverse object shapes, imaging system configurations, and modalities, including lensless setups. Notably, a diffusion prior trained on simple amplitude data (e.g., polystyrene beads) successfully reconstructs complex biological tissue structures, highlighting the method’s adaptability. This framework provides a cost-effective, generalizable solution for nonlinear inverse problems in computational imaging, and establishes a foundation for broader coherent imaging applications beyond holography. </p>
<blockquote>
<p>在内联全息术中，相位恢复是一个基本但不适定的反问题，这是由于相干成像中振幅和相位之间的非线性耦合所导致的。我们提出了一种新颖的解决方案，该方案利用仅对物体振幅进行训练的扩散模型，从衍射强度恢复振幅和相位。我们的方法采用预测校正采样框架，为振幅和相位提供单独的可能性梯度，从而实现复杂场的重建，而无需为训练提供真实相位数据。我们通过大量的模拟和实验验证了所提出的方法，证明了其在不同物体形状、成像系统配置和模式（包括无透镜设置）中的稳健泛化能力。值得注意的是，使用简单的振幅数据（例如聚苯乙烯珠）训练的扩散先验成功地重建了复杂的生物组织结构，凸显了该方法的适应性。此框架为解决计算成像中的非线性反问题提供了经济高效、可推广的解决方案，并为全息技术以外的更广泛相干成像应用奠定了基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12728v1">PDF</a> Keywords: Diffusion model, phase retrieval, inline-holography,   inverse problem</p>
<p><strong>Summary</strong></p>
<p>在相干成像中，相位检索是内联全息术的基本问题之一，由于振幅和相位之间的非线性耦合导致它是一个不适定的反问题。我们提出了一种新颖的即用解决方案，它通过扩散模型仅对物体振幅进行训练，从衍射强度恢复振幅和相位。我们的方法采用预测校正采样框架，为振幅和相位提供单独的似然梯度，能够在不需要训练基准相位数据的情况下重建复杂场。通过广泛的模拟和实验验证了该方法的有效性，证明了其在不同物体形状、成像系统配置和模式（包括无透镜设置）下的稳健泛化能力。值得注意的是，仅使用简单的振幅数据（如聚苯乙烯珠）训练的扩散先验模型成功重建了复杂的生物组织结构，凸显了该方法的适应性。此框架为解决计算成像中的非线性反问题提供了经济高效、通用性强的解决方案，并为全息术以外的更广泛相干成像应用奠定了基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>相位检索在内联全息术中是一个基本但不适定的反问题，因为振幅和相位之间存在非线性耦合。</li>
<li>提出了一种新型的即用解决方案，通过扩散模型从衍射强度恢复振幅和相位。</li>
<li>采用预测校正采样框架，无需基准相位数据即可重建复杂场。</li>
<li>方法经过广泛模拟和实验验证，具有在不同物体形状、成像系统配置和模式下的稳健泛化能力。</li>
<li>扩散先验模型能够在不使用复杂的训练数据的情况下成功重建复杂的生物组织结构。</li>
<li>框架为解决计算成像中的非线性反问题提供了有效的解决方案。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12728">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12728v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12728v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12728v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2509.12728v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AC-Refiner-Efficient-Arithmetic-Circuit-Optimization-Using-Conditional-Diffusion-Models"><a href="#AC-Refiner-Efficient-Arithmetic-Circuit-Optimization-Using-Conditional-Diffusion-Models" class="headerlink" title="AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional   Diffusion Models"></a>AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional   Diffusion Models</h2><p><strong>Authors:Chenhao Xue, Kezhi Li, Jiaxing Zhang, Yi Ren, Zhengyuan Shi, Chen Zhang, Yibo Lin, Lining Zhang, Qiang Xu, Guangyu Sun</strong></p>
<p>Arithmetic circuits, such as adders and multipliers, are fundamental components of digital systems, directly impacting the performance, power efficiency, and area footprint. However, optimizing these circuits remains challenging due to the vast design space and complex physical constraints. While recent deep learning-based approaches have shown promise, they struggle to consistently explore high-potential design variants, limiting their optimization efficiency. To address this challenge, we propose AC-Refiner, a novel arithmetic circuit optimization framework leveraging conditional diffusion models. Our key insight is to reframe arithmetic circuit synthesis as a conditional image generation task. By carefully conditioning the denoising diffusion process on target quality-of-results (QoRs), AC-Refiner consistently produces high-quality circuit designs. Furthermore, the explored designs are used to fine-tune the diffusion model, which focuses the exploration near the Pareto frontier. Experimental results demonstrate that AC-Refiner generates designs with superior Pareto optimality, outperforming state-of-the-art baselines. The performance gain is further validated by integrating AC-Refiner into practical applications. </p>
<blockquote>
<p>算术电路，如加法器和乘法器，是数字系统的基本组成部分，直接影响性能、功耗和面积占用。然而，由于巨大的设计空间和复杂的物理约束，优化这些电路仍然是一个挑战。虽然最近的基于深度学习的方法显示出了一定的前景，但它们难以持续探索高潜力的设计变体，从而限制了优化效率。为了应对这一挑战，我们提出了AC-Refiner，一个利用条件扩散模型的新型算术电路优化框架。我们的关键见解是将算术电路合成重新构建为条件图像生成任务。通过仔细将去噪扩散过程置于目标结果质量（QoR）上，AC-Refiner能够持续产生高质量的电路设计。此外，所探索的设计用于微调扩散模型，这将探索重点放在了帕累托前沿附近。实验结果表明，AC-Refiner生成的设计具有优越的帕累托最优性，超过了最新的基线标准。通过将AC-Refiner集成到实际应用中，进一步验证了其性能提升。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02598v2">PDF</a> 8 pages, 12 figures, to appear in ASP-DAC’26</p>
<p><strong>Summary</strong></p>
<p>基于算术电路在数字系统中的核心作用及其优化挑战，研究团队提出了AC-Refiner框架，利用条件扩散模型进行算术电路优化。该研究将算术电路合成重新定义为条件图像生成任务，并通过目标结果质量对去噪扩散过程进行细致调节，以生成高质量电路设计。此外，利用生成的电路设计对扩散模型进行微调，使其专注于帕累托前沿的探索。实验结果显示，AC-Refiner生成的设计具有优越的帕累托最优性，超越了现有基线水平，并通过实际应用验证其性能提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>算术电路是数字系统的核心组件，影响其性能、功耗和面积占用。</li>
<li>近期深度学习方法在优化算术电路方面展现出潜力，但难以持续探索高潜力设计变体，优化效率有限。</li>
<li>AC-Refiner框架利用条件扩散模型进行算术电路优化，将电路合成定义为条件图像生成任务。</li>
<li>AC-Refiner通过目标结果质量对去噪扩散过程进行细致调节，生成高质量电路设计。</li>
<li>扩散模型利用生成的电路设计进行微调，专注于帕累托前沿的探索。</li>
<li>实验结果显示AC-Refiner生成的设计具有优越的帕累托最优性，超越现有基线。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02598">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2507.02598v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="WorldExplorer-Towards-Generating-Fully-Navigable-3D-Scenes"><a href="#WorldExplorer-Towards-Generating-Fully-Navigable-3D-Scenes" class="headerlink" title="WorldExplorer: Towards Generating Fully Navigable 3D Scenes"></a>WorldExplorer: Towards Generating Fully Navigable 3D Scenes</h2><p><strong>Authors:Manuel-Andreas Schneider, Lukas Höllein, Matthias Nießner</strong></p>
<p>Generating 3D worlds from text is a highly anticipated goal in computer vision. Existing works are limited by the degree of exploration they allow inside of a scene, i.e., produce streched-out and noisy artifacts when moving beyond central or panoramic perspectives. To this end, we propose WorldExplorer, a novel method based on autoregressive video trajectory generation, which builds fully navigable 3D scenes with consistent visual quality across a wide range of viewpoints. We initialize our scenes by creating multi-view consistent images corresponding to a 360 degree panorama. Then, we expand it by leveraging video diffusion models in an iterative scene generation pipeline. Concretely, we generate multiple videos along short, pre-defined trajectories, that explore the scene in depth, including motion around objects. Our novel scene memory conditions each video on the most relevant prior views, while a collision-detection mechanism prevents degenerate results, like moving into objects. Finally, we fuse all generated views into a unified 3D representation via 3D Gaussian Splatting optimization. Compared to prior approaches, WorldExplorer produces high-quality scenes that remain stable under large camera motion, enabling for the first time realistic and unrestricted exploration. We believe this marks a significant step toward generating immersive and truly explorable virtual 3D environments. </p>
<blockquote>
<p>从文本生成3D世界是计算机视觉领域一个备受期待的目标。现有工作受限于场景内的探索程度，即在中心或全景视角之外移动时，会产生拉伸和嘈杂的伪影。为此，我们提出了WorldExplorer，这是一种基于自回归视频轨迹生成的新方法，构建了在广泛视点范围内具有一致视觉质量的可完全导航的3D场景。我们通过创建与360度全景相对应的多视角一致图像来初始化场景。然后，我们利用视频扩散模型在迭代场景生成管道中进行扩展。具体来说，我们沿着短预定义轨迹生成多个视频，深入探索场景，包括围绕物体的运动。我们的新场景记忆以最重要的先前视图为条件，对每一个视频进行约束，同时碰撞检测机制防止了退化结果，如进入物体内部。最后，我们通过3D高斯拼贴优化将所有生成的视图融合成统一的三维表示。与世界上的其他方法相比，WorldExplorer能够生成高质量的场景，在大范围相机运动下保持稳定，首次实现了真实且不受限制的探索。我们相信，这是朝着生成沉浸式和真正可探索的虚拟3D环境迈出的重要一步。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01799v2">PDF</a> Accepted to SIGGRAPH Asia 2025. Project page: see   <a target="_blank" rel="noopener" href="https://mschneider456.github.io/world-explorer">https://mschneider456.github.io/world-explorer</a>, video: see   <a target="_blank" rel="noopener" href="https://youtu.be/N6NJsNyiv6I">https://youtu.be/N6NJsNyiv6I</a>, code:   <a target="_blank" rel="noopener" href="https://github.com/mschneider456/WorldExplorer">https://github.com/mschneider456/WorldExplorer</a></p>
<p><strong>Summary</strong></p>
<p>本文提出了WorldExplorer方法，基于视频轨迹生成技术，构建可在广泛视角范围内具有一致视觉质量的可导航3D场景。通过创建多视角一致图像初始化场景，并借助视频扩散模型在迭代场景生成管道中扩展。该方法生成多个视频，沿预定义的短轨迹探索场景深度，包括物体周围的运动。场景记忆使每个视频以最相关的先前视角为条件，碰撞检测机制防止产生退化结果。最终，将所有生成的视角融合成统一的三维表示，通过三维高斯拼贴优化。WorldExplorer生成高质量场景，在大范围相机运动中保持稳定，首次实现真实且不受限制的探索。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WorldExplorer方法允许在3D世界中的广泛探索，解决现有技术中场景探索程度有限的难题。</li>
<li>通过创建多视角一致图像初始化场景，确保场景的准确性及连贯性。</li>
<li>利用视频扩散模型在迭代场景生成管道中扩展，增强场景的细节和丰富度。</li>
<li>生成多个视频短轨迹，深入探索场景，包括物体周围的运动。</li>
<li>场景记忆机制确保视频生成与先前视角的相关性。</li>
<li>碰撞检测机制避免了生成结果的退化，如穿透物体等。</li>
<li>最终将所有生成的视角融合成统一的三维表示，实现场景的全面呈现。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01799">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2506.01799v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2506.01799v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2506.01799v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2506.01799v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="WaterFlow-Learning-Fast-Robust-Watermarks-using-Stable-Diffusion"><a href="#WaterFlow-Learning-Fast-Robust-Watermarks-using-Stable-Diffusion" class="headerlink" title="WaterFlow: Learning Fast &amp; Robust Watermarks using Stable Diffusion"></a>WaterFlow: Learning Fast &amp; Robust Watermarks using Stable Diffusion</h2><p><strong>Authors:Vinay Shukla, Prachee Sharma, Ryan Rossi, Sungchul Kim, Tong Yu, Aditya Grover</strong></p>
<p>The ability to embed watermarks in images is a fundamental problem of interest for computer vision, and is exacerbated by the rapid rise of generated imagery in recent times. Current state-of-the-art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments. In addition, other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality. In this work, we propose WaterFlow (WF), a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent-dependent watermark. Our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the Fourier Domain of the latent. The transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre-trained model to better preserve image quality while permitting robust and tractable detection. Most notably, WaterFlow demonstrates state-of-the-art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks. We validate our findings on three widely used real and generated datasets: MS-COCO, DiffusionDB, and WikiArt. </p>
<blockquote>
<p>将图片嵌入水印是计算机视觉领域的一个基础且重要的问题，近年来随着生成图像技术的快速发展，这一问题愈发严重。当前最先进的技术面临着计算和统计方面的挑战，如在实际部署中的执行速度慢。此外，其他方法虽然实现了快速的水印嵌入速度，但在其稳健性或感知质量方面存在很大的缺陷。在这项工作中，我们提出了WaterFlow（WF），这是一种基于学习潜在依赖水印的快速且非常稳健的高保真视觉水印嵌入方法。我们的方法利用预训练的潜在扩散模型将任意图像编码到潜在空间，并产生学习的水印，然后将其植入潜在空间的傅里叶域。通过可逆流层进行转换，增强了预训练模型的潜在空间的表现力，可以更好地保持图像质量，同时实现稳健且易于检测。最值得注意的是，WaterFlow在一般稳健性方面表现出卓越的性能，并且是第一种能够有效防御复杂组合攻击的方法。我们在三个广泛使用的真实和生成数据集MS-COCO、DiffusionDB和WikiArt上验证了我们的发现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12354v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种基于预训练扩散模型的快速且极其鲁棒的高保真视觉水印技术——WaterFlow（WF）。它通过利用扩散模型将任意图像编码到潜在空间，并在潜在空间的傅立叶域中植入学习到的水印来实现水印嵌入。WaterFlow通过可逆流层进行转换，增强了预训练模型的潜在空间表达能力，从而更好地保持图像质量并实现了鲁棒性和可检测性。WaterFlow在通用鲁棒性方面表现出卓越性能，并且是首个能有效防御复杂组合攻击的方法。实验在MS-COCO、DiffusionDB和WikiArt三个广泛使用的真实和生成数据集上进行了验证。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WaterFlow是一种基于预训练扩散模型的快速且鲁棒的高保真视觉水印技术。</li>
<li>利用扩散模型将图像编码到潜在空间，并在该空间内植入学习到的水印。</li>
<li>WaterFlow通过可逆流层进行转换，增强了潜在空间的表达能力。</li>
<li>该方法能够在保持图像质量的同时实现鲁棒性和可检测性。</li>
<li>WaterFlow在通用鲁棒性方面表现出卓越性能，能够防御复杂的组合攻击。</li>
<li>实验在MS-COCO、DiffusionDB和WikiArt三个数据集上进行了验证。</li>
<li>该技术对于应对生成图像中水印嵌入的需求具有重大意义。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12354">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2504.12354v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Detection-of-Synthetic-Face-Images-Accuracy-Robustness-Generalization"><a href="#Detection-of-Synthetic-Face-Images-Accuracy-Robustness-Generalization" class="headerlink" title="Detection of Synthetic Face Images: Accuracy, Robustness, Generalization"></a>Detection of Synthetic Face Images: Accuracy, Robustness, Generalization</h2><p><strong>Authors:Nela Petrzelkova, Jan Cech</strong></p>
<p>An experimental study on detecting synthetic face images is presented. We collected a dataset, called FF5, of five fake face image generators, including recent diffusion models. We find that a simple model trained on a specific image generator can achieve near-perfect accuracy in separating synthetic and real images. The model handles common image distortions (reduced resolution, compression) by using data augmentation. Moreover, partial manipulations, where synthetic images are blended into real ones by inpainting, are identified and the area of the manipulation is localized by a simple model of YOLO architecture. However, the model turned out to be vulnerable to adversarial attacks and does not generalize to unseen generators. Failure to generalize to detect images produced by a newer generator also occurs for recent state-of-the-art methods, which we tested on Realistic Vision, a fine-tuned version of StabilityAI’s Stable Diffusion image generator. </p>
<blockquote>
<p>本文介绍了对检测合成面部图像的实验研究。我们收集了一个名为FF5的数据集，包含五个虚假面部图像生成器，包括最新的扩散模型。我们发现，在特定图像生成器上训练的简单模型在区分合成图像和真实图像时可以达到近乎完美的精度。该模型通过使用数据增强来处理常见的图像失真（降低分辨率、压缩）。此外，该模型还能识别将合成图像通过修复技术混合到真实图像中的部分操作，并通过YOLO架构的简单模型对操作区域进行定位。然而，该模型在对抗攻击面前显得脆弱，并且无法推广到未见过的生成器上。我们测试的最新先进方法也未能推广到由更新的生成器产生的图像检测上，我们在“现实视觉”上对其实施了测试，这是微调后的StabilityAI的稳定扩散图像生成器的一个版本。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.17547v2">PDF</a> The paper was presented at the DAGM German Conference on Pattern   Recognition (GCPR), 2025</p>
<p><strong>Summary</strong><br>本文研究了检测合成人脸图像的实验。研究团队收集了一个名为FF5的数据集，包含了五个虚假人脸图像生成器，包括最新的扩散模型。研究发现，针对特定图像生成器训练的简单模型可以在区分合成图像和真实图像方面达到近乎完美的准确率。该模型通过数据增强处理常见的图像失真（如降低分辨率、压缩）。此外，该模型还能识别出合成图像通过补全技术融入真实图像的部分操纵，并使用YOLO架构的简单模型定位操纵区域。然而，该模型容易受到对抗性攻击的影响，且无法推广到未见过的生成器。对于最新、最先进的测试方法也是如此，它们在针对精细调整过的StabilityAI的稳定扩散图像生成器的Realistic Vision上也出现了检测失败的情况。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究团队收集了一个名为FF5的数据集，包含五个虚假人脸图像生成器。</li>
<li>简单模型可以针对特定图像生成器达到近乎完美的区分合成与真实图像准确率。</li>
<li>模型通过数据增强处理常见的图像失真问题。</li>
<li>模型可以识别合成图像通过补全技术融入真实图像的操纵。</li>
<li>模型使用YOLO架构定位操纵区域。</li>
<li>模型容易受到对抗性攻击的影响，无法推广到未见过的生成器。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.17547">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2406.17547v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2406.17547v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2406.17547v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_Diffusion Models/2406.17547v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-18/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-18/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-18/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_医学图像/2509.12600v1/page_5_0.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-09-18  Curriculum Multi-Task Self-Supervision Improves Lightweight   Architectures for Onboard Satellite Hyperspectral Image Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-18/NeRF/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-18\./crop_NeRF/2509.12286v1/page_5_0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-09-18  Prediction of Stocks Index Price using Quantum GANs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29774.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
