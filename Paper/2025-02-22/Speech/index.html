<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  WavRAG Audio-Integrated Retrieval Augmented Generation for Spoken   Dialogue Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-15e67e0c5ed3d31f2504af5082533e69.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    24 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-22-æ›´æ–°"><a href="#2025-02-22-æ›´æ–°" class="headerlink" title="2025-02-22 æ›´æ–°"></a>2025-02-22 æ›´æ–°</h1><h2 id="WavRAG-Audio-Integrated-Retrieval-Augmented-Generation-for-Spoken-Dialogue-Models"><a href="#WavRAG-Audio-Integrated-Retrieval-Augmented-Generation-for-Spoken-Dialogue-Models" class="headerlink" title="WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken   Dialogue Models"></a>WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken   Dialogue Models</h2><p><strong>Authors:Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao</strong></p>
<p>Retrieval Augmented Generation (RAG) has gained widespread adoption owing to its capacity to empower large language models (LLMs) to integrate external knowledge. However, existing RAG frameworks are primarily designed for text-based LLMs and rely on Automatic Speech Recognition to process speech input, which discards crucial audio information, risks transcription errors, and increases computational overhead. Therefore, we introduce WavRAG, the first retrieval augmented generation framework with native, end-to-end audio support. WavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw audio for both embedding and retrieval. 2) WavRAG integrates audio and text into a unified knowledge representation. Specifically, we propose the WavRetriever to facilitate the retrieval from a text-audio hybrid knowledge base, and further enhance the in-context capabilities of spoken dialogue models through the integration of chain-of-thought reasoning. In comparison to state-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval performance while delivering a 10x acceleration. Furthermore, WavRAGâ€™s unique text-audio hybrid retrieval capability extends the boundaries of RAG to the audio modality. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç”±äºå…¶èµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•´åˆå¤–éƒ¨çŸ¥è¯†çš„èƒ½åŠ›è€Œå¾—åˆ°å¹¿æ³›é‡‡ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RAGæ¡†æ¶ä¸»è¦è®¾è®¡ç”¨äºåŸºäºæ–‡æœ¬çš„LLMï¼Œå¹¶ä¾èµ–è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å¤„ç†è¯­éŸ³è¾“å…¥ï¼Œè¿™ä¸¢å¼ƒäº†é‡è¦çš„éŸ³é¢‘ä¿¡æ¯ï¼Œå­˜åœ¨è½¬å½•é”™è¯¯çš„é£é™©ï¼Œå¹¶å¢åŠ äº†è®¡ç®—å¼€é”€ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†WavRAGï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…·æœ‰åŸç”Ÿç«¯åˆ°ç«¯éŸ³é¢‘æ”¯æŒçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚WavRAGæä¾›ä¸¤ä¸ªå…³é”®åŠŸèƒ½ï¼š1ï¼‰ç»•è¿‡ASRï¼ŒWavRAGç›´æ¥å¤„ç†åŸå§‹éŸ³é¢‘è¿›è¡ŒåµŒå…¥å’Œæ£€ç´¢ã€‚2ï¼‰WavRAGå°†éŸ³é¢‘å’Œæ–‡æœ¬é›†æˆåˆ°ç»Ÿä¸€çš„çŸ¥è¯†è¡¨ç¤ºä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºWavRetrieverï¼Œä¾¿äºä»æ–‡æœ¬-éŸ³é¢‘æ··åˆçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ï¼Œå¹¶é€šè¿‡æ•´åˆæ€ç»´é“¾æ¨ç†ï¼Œå¢å¼ºå¯¹è¯æ¨¡å‹çš„ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚ä¸æœ€æ–°çš„ASR-Text RAGç®¡é“ç›¸æ¯”ï¼ŒWavRAGå®ç°äº†ç›¸å½“çš„æ£€ç´¢æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†10å€çš„åŠ é€Ÿã€‚æ­¤å¤–ï¼ŒWavRAGç‹¬ç‰¹çš„æ–‡æœ¬-éŸ³é¢‘æ··åˆæ£€ç´¢èƒ½åŠ›å°†RAGçš„è¾¹ç•Œæ‰©å±•åˆ°éŸ³é¢‘æ¨¡å¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14727v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>WavRAGæ˜¯é¦–ä¸ªå…·å¤‡åŸç”Ÿç«¯åˆ°ç«¯éŸ³é¢‘æ”¯æŒçš„çŸ¥è¯†å¢å¼ºç”Ÿæˆæ¨¡å‹æ¡†æ¶ï¼Œå¯ç›´æ¥å¤„ç†åŸå§‹éŸ³é¢‘è¿›è¡ŒåµŒå…¥å’Œæ£€ç´¢ï¼Œå¹¶æ•´åˆéŸ³é¢‘ä¸æ–‡æœ¬ä¸ºç»Ÿä¸€çš„çŸ¥è¯†è¡¨ç¤ºã€‚ç›¸æ¯”åŸºäºASRçš„æ–‡æœ¬RAGç®¡é“ï¼ŒWavRAGå®ç°äº†ç›¸ä¼¼çš„æ£€ç´¢æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†é«˜è¾¾10å€çš„åŠ é€Ÿï¼Œå¹¶æ‰©å±•äº†RAGåœ¨éŸ³é¢‘æ¨¡æ€çš„åº”ç”¨è¾¹ç•Œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WavRAGæ˜¯ä¸€ä¸ªå…·å¤‡åŸç”Ÿç«¯åˆ°ç«¯éŸ³é¢‘æ”¯æŒçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚</li>
<li>WavRAGå¯ç›´æ¥å¤„ç†åŸå§‹éŸ³é¢‘è¿›è¡ŒåµŒå…¥å’Œæ£€ç´¢ï¼Œç»•è¿‡è¯­éŸ³è¯†åˆ«æŠ€æœ¯ï¼ˆASRï¼‰ã€‚</li>
<li>WavRAGæ•´åˆéŸ³é¢‘å’Œæ–‡æœ¬ä¸ºç»Ÿä¸€çš„çŸ¥è¯†è¡¨ç¤ºã€‚</li>
<li>WavRetrieverçš„æå‡ºä¿ƒè¿›äº†ä»æ–‡æœ¬-éŸ³é¢‘æ··åˆçŸ¥è¯†åº“ä¸­çš„æ£€ç´¢ã€‚</li>
<li>WavRAGé€šè¿‡å¼•å…¥é“¾å¼æ€ç»´æ¨ç†å¢å¼ºäº†å£è¯­å¯¹è¯æ¨¡å‹çš„èƒ½åŠ›ã€‚</li>
<li>ä¸ç°æœ‰åŸºäºASRçš„RAGç®¡é“ç›¸æ¯”ï¼ŒWavRAGå®ç°äº†é«˜æ•ˆçš„æ€§èƒ½åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒç›¸ä¼¼çš„æ£€ç´¢æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14727">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-49cb3d1c803e3728d86fde163736a181.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c510a2eecf0670e466dd7d87459cb270.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5addb5b73d6e6fb7b1ca9cae3ed1a15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0408ae5fa8e585e1f1636a503c844e95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b442b42e06adc7a16579cbf1ee42323f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SegAug-CTC-Aligned-Segmented-Augmentation-For-Robust-RNN-Transducer-Based-Speech-Recognition"><a href="#SegAug-CTC-Aligned-Segmented-Augmentation-For-Robust-RNN-Transducer-Based-Speech-Recognition" class="headerlink" title="SegAug: CTC-Aligned Segmented Augmentation For Robust RNN-Transducer   Based Speech Recognition"></a>SegAug: CTC-Aligned Segmented Augmentation For Robust RNN-Transducer   Based Speech Recognition</h2><p><strong>Authors:Khanh Le, Tuan Vu Ho, Dung Tran, Duc Thanh Chau</strong></p>
<p>RNN-Transducer (RNN-T) is a widely adopted architecture in speech recognition, integrating acoustic and language modeling in an end-to-end framework. However, the RNN-T predictor tends to over-rely on consecutive word dependencies in training data, leading to high deletion error rates, particularly with less common or out-of-domain phrases. Existing solutions, such as regularization and data augmentation, often compromise other aspects of performance. We propose SegAug, an alignment-based augmentation technique that generates contextually varied audio-text pairs with low sentence-level semantics. This method encourages the model to focus more on acoustic features while diversifying the learned textual patterns of its internal language model, thereby reducing deletion errors and enhancing overall performance. Evaluations on the LibriSpeech and Tedlium-v3 datasets demonstrate a relative WER reduction of up to 12.5% on small-scale and 6.9% on large-scale settings. Notably, most of the improvement stems from reduced deletion errors, with relative reductions of 45.4% and 18.5%, respectively. These results highlight SegAugâ€™s effectiveness in improving RNN-Tâ€™s robustness, offering a promising solution for enhancing speech recognition performance across diverse and challenging scenarios. </p>
<blockquote>
<p>RNN-Transducerï¼ˆRNN-Tï¼‰æ˜¯è¯­éŸ³è¯†åˆ«ä¸­å¹¿æ³›é‡‡ç”¨çš„æ¶æ„ï¼Œå®ƒåœ¨ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­æ•´åˆäº†å£°å­¦æ¨¡å‹å’Œè¯­è¨€æ¨¡å‹ã€‚ç„¶è€Œï¼ŒRNN-Té¢„æµ‹å™¨åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡äºä¾èµ–è¿ç»­çš„å•è¯ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´åˆ é™¤é”™è¯¯ç‡è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸å¸¸è§æˆ–è¶…å‡ºèŒƒå›´çš„çŸ­è¯­ä¸­ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆï¼Œå¦‚æ­£åˆ™åŒ–å’Œæ•°æ®å¢å¼ºï¼Œå¾€å¾€ä¼šæŸå®³æ€§èƒ½çš„å…¶ä»–æ–¹é¢ã€‚æˆ‘ä»¬æå‡ºäº†SegAugï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¯¹é½çš„å¢å¼ºæŠ€æœ¯ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰ä½å¥å­çº§è¯­ä¹‰çš„ä¸Šä¸‹æ–‡å˜åŒ–çš„éŸ³é¢‘æ–‡æœ¬å¯¹ã€‚è¿™ç§æ–¹æ³•é¼“åŠ±æ¨¡å‹æ›´å¤šåœ°å…³æ³¨å£°å­¦ç‰¹å¾ï¼ŒåŒæ—¶ä½¿å…¶å†…éƒ¨è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬æ¨¡å¼å¤šæ ·åŒ–ï¼Œä»è€Œå‡å°‘åˆ é™¤é”™è¯¯å¹¶å¢å¼ºæ•´ä½“æ€§èƒ½ã€‚åœ¨LibriSpeechå’ŒTedlium-v3æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå°è§„æ¨¡è®¾ç½®ç›¸å¯¹é™ä½äº†WERè¾¾12.5%ï¼Œå¤§è§„æ¨¡è®¾ç½®ç›¸å¯¹é™ä½äº†6.9%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¤§éƒ¨åˆ†æ”¹è¿›æ¥è‡ªäºåˆ é™¤é”™è¯¯çš„å‡å°‘ï¼Œåˆ†åˆ«é™ä½äº†45.4%å’Œ18.5%ã€‚è¿™äº›ç»“æœçªå‡ºäº†SegAugåœ¨æé«˜RNN-Tç¨³å¥æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåœ¨å¤šæ ·åŒ–å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­æé«˜è¯­éŸ³è¯†åˆ«æ€§èƒ½æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14685v1">PDF</a> Accepted to ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>RNN-Tåœ¨è¯­éŸ³è¯†åˆ«ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å­˜åœ¨è¿‡åº¦ä¾èµ–è®­ç»ƒæ•°æ®ä¸­çš„è¿ç»­è¯ä¾èµ–å…³ç³»çš„é—®é¢˜ï¼Œå¯¼è‡´åˆ é™¤é”™è¯¯ç‡è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸å¸¸è§æˆ–è·¨é¢†åŸŸçš„çŸ­è¯­ä¸­ã€‚æœ¬æ–‡æå‡ºSegAugæ–¹æ³•ï¼Œä¸€ç§åŸºäºå¯¹é½çš„å¢å¼ºæŠ€æœ¯ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä½å¥å­çº§è¯­ä¹‰çš„ä¸Šä¸‹æ–‡å˜åŒ–çš„éŸ³é¢‘æ–‡æœ¬å¯¹ã€‚è¯¥æ–¹æ³•é¼“åŠ±æ¨¡å‹æ›´å¤šåœ°å…³æ³¨å£°å­¦ç‰¹å¾ï¼ŒåŒæ—¶å¤šæ ·åŒ–å…¶å†…éƒ¨è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬æ¨¡å¼ï¼Œä»è€Œå‡å°‘åˆ é™¤é”™è¯¯å¹¶å¢å¼ºæ•´ä½“æ€§èƒ½ã€‚åœ¨LibriSpeechå’ŒTedlium-v3æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œç›¸å¯¹äºå°è§„æ¨¡å’Œå¤§è§„æ¨¡è®¾ç½®ï¼ŒWERåˆ†åˆ«é™ä½äº†æœ€å¤šè¾¾12.5%å’Œ6.9%ã€‚æ”¹è¿›ä¸»è¦æ¥æºäºåˆ é™¤é”™è¯¯çš„å‡å°‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RNN-Tåœ¨è¯­éŸ³è¯†åˆ«ä¸­é›†æˆå£°å­¦å’Œè¯­è¨€å»ºæ¨¡ï¼Œä½†å­˜åœ¨åˆ é™¤é”™è¯¯ç‡é«˜çš„é—®é¢˜ã€‚</li>
<li>SegAugæ˜¯ä¸€ç§åŸºäºå¯¹é½çš„å¢å¼ºæŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³RNN-Tçš„åˆ é™¤é”™è¯¯é—®é¢˜ã€‚</li>
<li>SegAugé€šè¿‡ç”Ÿæˆå…·æœ‰ä½å¥å­çº§è¯­ä¹‰çš„ä¸Šä¸‹æ–‡å˜åŒ–çš„éŸ³é¢‘æ–‡æœ¬å¯¹ï¼Œé¼“åŠ±æ¨¡å‹å…³æ³¨å£°å­¦ç‰¹å¾ã€‚</li>
<li>SegAugèƒ½å¤Ÿå¤šæ ·åŒ–RNN-Tå†…éƒ¨è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬æ¨¡å¼ã€‚</li>
<li>åœ¨LibriSpeechå’ŒTedlium-v3æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒSegAugæ˜¾è‘—æé«˜RNN-Tçš„æ€§èƒ½ã€‚</li>
<li>SegAugå¸¦æ¥çš„æ”¹è¿›ä¸»è¦æºäºåˆ é™¤é”™è¯¯çš„æ˜¾è‘—å‡å°‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14685">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bfd1fdcec5b008b59e47fc514c6a2a31.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c329f5ef97cbccc3a2ae2ec0128d6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-88c5b4acd6e5c0c6951cf124cde89681.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Rethinking-Spiking-Neural-Networks-from-an-Ensemble-Learning-Perspective"><a href="#Rethinking-Spiking-Neural-Networks-from-an-Ensemble-Learning-Perspective" class="headerlink" title="Rethinking Spiking Neural Networks from an Ensemble Learning Perspective"></a>Rethinking Spiking Neural Networks from an Ensemble Learning Perspective</h2><p><strong>Authors:Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Hanpu Deng</strong></p>
<p>Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer from limited performance. In this paper, we consider SNNs as ensembles of temporal subnetworks that share architectures and weights, and highlight a crucial issue that affects their performance: excessive differences in initial states (neuronal membrane potentials) across timesteps lead to unstable subnetwork outputs, resulting in degraded performance. To mitigate this, we promote the consistency of the initial membrane potential distribution and output through membrane potential smoothing and temporally adjacent subnetwork guidance, respectively, to improve overall stability and performance. Moreover, membrane potential smoothing facilitates forward propagation of information and backward propagation of gradients, mitigating the notorious temporal gradient vanishing problem. Our method requires only minimal modification of the spiking neurons without adapting the network structure, making our method generalizable and showing consistent performance gains in 1D speech, 2D object, and 3D point cloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset, we achieved 83.20% accuracy with only four timesteps. This provides valuable insights into unleashing the potential of SNNs. </p>
<blockquote>
<p>è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰å…·æœ‰å‡ºè‰²çš„èƒ½æºæ•ˆç‡ï¼Œä½†æ€§èƒ½æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†SNNsè§†ä¸ºå…·æœ‰å…±äº«æ¶æ„å’Œæƒé‡çš„ä¸´æ—¶å­ç½‘ç»œçš„é›†åˆï¼Œå¹¶å¼ºè°ƒä¸€ä¸ªå½±å“å®ƒä»¬æ€§èƒ½çš„å…³é”®é—®é¢˜ï¼šä¸åŒæ—¶é—´æ­¥é•¿çš„åˆå§‹çŠ¶æ€ï¼ˆç¥ç»å…ƒè†œç”µä½ï¼‰å·®å¼‚è¿‡å¤§å¯¼è‡´å­ç½‘ç»œè¾“å‡ºä¸ç¨³å®šï¼Œä»è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡è†œç”µä½å¹³æ»‘å’Œç›¸é‚»å­ç½‘ç»œæŒ‡å¯¼åˆ†åˆ«ä¿ƒè¿›äº†åˆå§‹è†œç”µä½åˆ†å¸ƒå’Œè¾“å‡ºçš„ä¸€è‡´æ€§ï¼Œæé«˜äº†æ•´ä½“ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚æ­¤å¤–ï¼Œè†œç”µä½å¹³æ»‘æœ‰åŠ©äºä¿¡æ¯çš„æ­£å‘ä¼ æ’­å’Œæ¢¯åº¦çš„åå‘ä¼ æ’­ï¼Œç¼“è§£äº†è‘—åçš„æ—¶åºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»…éœ€è¦å¯¹è„‰å†²ç¥ç»å…ƒè¿›è¡Œæœ€å°çš„ä¿®æ”¹ï¼Œè€Œæ— éœ€é€‚åº”ç½‘ç»œç»“æ„ï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¹¶åœ¨ä¸€ç»´è¯­éŸ³ã€äºŒç»´å¯¹è±¡è¯†åˆ«å’Œä¸‰ç»´ç‚¹äº‘è¯†åˆ«ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæŒç»­çš„æ€§èƒ½æå‡ã€‚ç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„CIFAR10-DVSæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬ä»…åœ¨å››ä¸ªæ—¶é—´æ­¥é•¿å†…å°±è¾¾åˆ°äº†83.20%çš„å‡†ç¡®ç‡ã€‚è¿™ä¸ºé‡Šæ”¾SNNsçš„æ½œåŠ›æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14218v1">PDF</a> Published as a conference paper at ICLR 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡ç ”ç©¶äº†è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰ä½œä¸ºæ—¶é—´å­ç½‘ç»œçš„é›†åˆçš„ç‰¹æ€§ï¼Œå¹¶æå‡ºä¸€ç§æé«˜SNNsæ€§èƒ½çš„æ–¹æ³•ã€‚æ–‡ä¸­æŒ‡å‡ºåˆå§‹çŠ¶æ€å·®å¼‚è¿‡å¤§å¯¼è‡´çš„å­ç½‘ç»œè¾“å‡ºä¸ç¨³å®šæ˜¯é™åˆ¶å…¶æ€§èƒ½çš„å…³é”®å› ç´ ã€‚ä¸ºæ­¤ï¼Œä½œè€…é€šè¿‡è†œç”µä½å¹³æ»‘å’Œç›¸é‚»å­ç½‘ç»œæŒ‡å¯¼æ¥ä¿ƒè¿›åˆå§‹è†œç”µä½åˆ†å¸ƒå’Œè¾“å‡ºçš„ç¨³å®šæ€§ï¼Œä»è€Œæé«˜æ•´ä½“æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä»…éœ€å¯¹è„‰å†²ç¥ç»å…ƒè¿›è¡Œå¾®å°ä¿®æ”¹ï¼Œæ— éœ€è°ƒæ•´ç½‘ç»œç»“æ„ï¼Œå¯åœ¨ä¸€ç»´è¯­éŸ³ã€äºŒç»´ç‰©ä½“å’Œä¸‰ç»´ç‚¹äº‘è¯†åˆ«ä»»åŠ¡ä¸­å–å¾—ä¸€è‡´çš„æ€§èƒ½æå‡ã€‚åœ¨CIFAR10-DVSæ•°æ®é›†ä¸Šå–å¾—äº†83.20%çš„å‡†ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰å±•ç°å‡ºä¼˜è¶Šçš„èƒ½é‡æ•ˆç‡ï¼Œä½†æ€§èƒ½å—é™ã€‚</li>
<li>åˆå§‹çŠ¶æ€å·®å¼‚å¯¼è‡´å­ç½‘ç»œè¾“å‡ºä¸ç¨³å®šï¼Œå½±å“æ€§èƒ½ã€‚</li>
<li>é€šè¿‡è†œç”µä½å¹³æ»‘å’Œç›¸é‚»å­ç½‘ç»œæŒ‡å¯¼æ¥ä¿ƒè¿›åˆå§‹è†œç”µä½åˆ†å¸ƒå’Œè¾“å‡ºçš„ç¨³å®šæ€§ã€‚</li>
<li>æ–¹æ³•ä»…éœ€å¯¹è„‰å†²ç¥ç»å…ƒè¿›è¡Œå¾®å°ä¿®æ”¹ï¼Œæ— éœ€è°ƒæ•´ç½‘ç»œç»“æ„ã€‚</li>
<li>åœ¨ä¸€ç»´è¯­éŸ³ã€äºŒç»´ç‰©ä½“å’Œä¸‰ç»´ç‚¹äº‘è¯†åˆ«ä»»åŠ¡ä¸­å–å¾—æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„CIFAR10-DVSæ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾83.20%çš„å‡†ç¡®ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14218">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-192717ee21a0e871fb5485775dd72ea1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7786249d0ab6f4c89277912c2d4d825c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe7cba39badde0d86de5dd3d0279652f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f3180835f73c09f909ea74d11ec5ce54.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="NeRF-3DTalker-Neural-Radiance-Field-with-3D-Prior-Aided-Audio-Disentanglement-for-Talking-Head-Synthesis"><a href="#NeRF-3DTalker-Neural-Radiance-Field-with-3D-Prior-Aided-Audio-Disentanglement-for-Talking-Head-Synthesis" class="headerlink" title="NeRF-3DTalker: Neural Radiance Field with 3D Prior Aided Audio   Disentanglement for Talking Head Synthesis"></a>NeRF-3DTalker: Neural Radiance Field with 3D Prior Aided Audio   Disentanglement for Talking Head Synthesis</h2><p><strong>Authors:Xiaoxing Liu, Zhilei Liu, Chongke Bi</strong></p>
<p>Talking head synthesis is to synthesize a lip-synchronized talking head video using audio. Recently, the capability of NeRF to enhance the realism and texture details of synthesized talking heads has attracted the attention of researchers. However, most current NeRF methods based on audio are exclusively concerned with the rendering of frontal faces. These methods are unable to generate clear talking heads in novel views. Another prevalent challenge in current 3D talking head synthesis is the difficulty in aligning acoustic and visual spaces, which often results in suboptimal lip-syncing of the generated talking heads. To address these issues, we propose Neural Radiance Field with 3D Prior Aided Audio Disentanglement for Talking Head Synthesis (NeRF-3DTalker). Specifically, the proposed method employs 3D prior information to synthesize clear talking heads with free views. Additionally, we propose a 3D Prior Aided Audio Disentanglement module, which is designed to disentangle the audio into two distinct categories: features related to 3D awarded speech movements and features related to speaking style. Moreover, to reposition the generated frames that are distant from the speakerâ€™s motion space in the real space, we have devised a local-global Standardized Space. This method normalizes the irregular positions in the generated frames from both global and local semantic perspectives. Through comprehensive qualitative and quantitative experiments, it has been demonstrated that our NeRF-3DTalker outperforms state-of-the-art in synthesizing realistic talking head videos, exhibiting superior image quality and lip synchronization. Project page: <a target="_blank" rel="noopener" href="https://nerf-3dtalker.github.io/NeRF-3Dtalker">https://nerf-3dtalker.github.io/NeRF-3Dtalker</a>. </p>
<blockquote>
<p>å¤´éƒ¨è¯´è¯äººåˆæˆæ˜¯é€šè¿‡éŸ³é¢‘åˆæˆä¸€ä¸ªå”‡åŒæ­¥çš„å¤´éƒ¨è¯´è¯è§†é¢‘ã€‚æœ€è¿‘ï¼ŒNeRFæŠ€æœ¯æå‡åˆæˆè¯´è¯å¤´éƒ¨çš„ç°å®æ„Ÿå’Œçº¹ç†ç»†èŠ‚çš„èƒ½åŠ›å¼•èµ·äº†ç ”ç©¶äººå‘˜çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“å‰å¤§å¤šæ•°åŸºäºéŸ³é¢‘çš„NeRFæ–¹æ³•ä¸»è¦å…³æ³¨æ­£é¢è„¸éƒ¨çš„æ¸²æŸ“ã€‚è¿™äº›æ–¹æ³•æ— æ³•åœ¨æ–°çš„è§†è§’ç”Ÿæˆæ¸…æ™°çš„è¯´è¯å¤´éƒ¨ã€‚å½“å‰3Dè¯´è¯å¤´éƒ¨åˆæˆçš„å¦ä¸€ä¸ªæ™®éæŒ‘æˆ˜æ˜¯éŸ³é¢‘å’Œè§†è§‰ç©ºé—´å¯¹é½çš„å›°éš¾ï¼Œè¿™é€šå¸¸å¯¼è‡´ç”Ÿæˆçš„è¯´è¯å¤´éƒ¨å”‡åŒæ­¥ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç¥ç»è¾å°„åœºä¸ä¸‰ç»´å…ˆéªŒè¾…åŠ©éŸ³é¢‘åˆ†ç¦»æŠ€æœ¯ç”¨äºå¤´éƒ¨è¯´è¯åˆæˆï¼ˆNeRF-3DTalkerï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸‰ç»´å…ˆéªŒä¿¡æ¯åˆæˆæ¸…æ™°çš„å…·æœ‰è‡ªç”±è§†è§’çš„è¯´è¯å¤´éƒ¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸‰ç»´å…ˆéªŒè¾…åŠ©éŸ³é¢‘åˆ†ç¦»æ¨¡å—ï¼Œå®ƒè¢«è®¾è®¡æ¥å°†éŸ³é¢‘åˆ†ä¸ºä¸¤ç±»ï¼šä¸ä¸‰ç»´è·å¥–è¯­éŸ³åŠ¨ä½œç›¸å…³çš„ç‰¹å¾å’Œä¸è®²è¯é£æ ¼ç›¸å…³çš„ç‰¹å¾ã€‚è€Œä¸”ï¼Œä¸ºäº†é‡æ–°å®šä½è¿œç¦»çœŸå®ç©ºé—´ä¸­è¯´è¯è€…è¿åŠ¨ç©ºé—´çš„ç”Ÿæˆå¸§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå±€éƒ¨å…¨å±€æ ‡å‡†åŒ–ç©ºé—´ã€‚è¯¥æ–¹æ³•ä»å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰è§’åº¦å¯¹ç”Ÿæˆå¸§ä¸­çš„ä¸è§„åˆ™ä½ç½®è¿›è¡Œå½’ä¸€åŒ–ã€‚é€šè¿‡å…¨é¢å®šæ€§å’Œå®šé‡å®éªŒï¼Œè¯æ˜æˆ‘ä»¬çš„NeRF-3DTalkeråœ¨åˆæˆé€¼çœŸçš„è¯´è¯å¤´éƒ¨è§†é¢‘æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå…·æœ‰å‡ºè‰²çš„å›¾åƒè´¨é‡å’Œå”‡åŒæ­¥ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://nerf-3dtalker.github.io/NeRF-3Dtalker%E3%80%82">https://nerf-3dtalker.github.io/NeRF-3Dtalkerã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14178v1">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºéŸ³é¢‘åˆæˆå”‡åŒæ­¥åŠ¨æ€å¤´éƒ¨è§†é¢‘çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚æ— æ³•ç”Ÿæˆæ¸…æ™°çš„å¤šè§†è§’åŠ¨æ€å¤´éƒ¨å›¾åƒå’ŒéŸ³é¢‘è§†è§‰ç©ºé—´å¯¹é½å›°éš¾ï¼Œæå‡ºäº†åŸºäºç¥ç»è¾å°„åœºå’Œ3Då…ˆéªŒè¾…åŠ©éŸ³é¢‘åˆ†ç¦»æŠ€æœ¯çš„è¯´è¯äººå¤´éƒ¨åˆæˆæ–¹æ³•ï¼ˆNeRF-3DTalkerï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨3Då…ˆéªŒä¿¡æ¯åˆæˆå¤šè§†è§’æ¸…æ™°å¤´éƒ¨å›¾åƒï¼Œå¹¶æå‡º3Då…ˆéªŒè¾…åŠ©éŸ³é¢‘åˆ†ç¦»æ¨¡å—ï¼Œå°†éŸ³é¢‘åˆ†ä¸ºä¸3DåŠ¨æ€è¯­éŸ³è¿åŠ¨ç›¸å…³çš„ç‰¹å¾å’Œä¸è¯´è¯é£æ ¼ç›¸å…³çš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†å±€éƒ¨å…¨å±€æ ‡å‡†åŒ–ç©ºé—´ï¼Œä»¥é‡æ–°å®šä½ç”Ÿæˆçš„ä¸ç°å®ç©ºé—´è¯´è¯äººåŠ¨ä½œç©ºé—´åç¦»çš„å¸§ã€‚å®éªŒè¯æ˜ï¼ŒNeRF-3DTalkeråœ¨åˆæˆçœŸå®å¤´éƒ¨è§†é¢‘æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå…·æœ‰æ›´é«˜çš„å›¾åƒè´¨é‡å’Œå”‡åŒæ­¥æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>NeRF-3DTalkeræ–¹æ³•åˆ©ç”¨ç¥ç»è¾å°„åœºå’Œ3Då…ˆéªŒä¿¡æ¯åˆæˆå¤šè§†è§’æ¸…æ™°å¤´éƒ¨å›¾åƒã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„3Då…ˆéªŒè¾…åŠ©éŸ³é¢‘åˆ†ç¦»æ¨¡å—ï¼Œèƒ½å¤Ÿå°†éŸ³é¢‘åˆ†ä¸ºä¸è¯­éŸ³åŠ¨æ€å’Œè¯´è¯é£æ ¼ç›¸å…³çš„ç‰¹å¾ã€‚</li>
<li>è®¾è®¡äº†å±€éƒ¨å…¨å±€æ ‡å‡†åŒ–ç©ºé—´ï¼Œä»¥æ”¹å–„ç”Ÿæˆçš„å¸§ä¸çœŸå®ç©ºé—´è¯´è¯äººåŠ¨ä½œç©ºé—´çš„åŒ¹é…åº¦ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æé«˜å›¾åƒè´¨é‡å’Œå”‡åŒæ­¥æ€§èƒ½æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>é€šè¿‡ç»¼åˆçš„å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†NeRF-3DTalkerçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>NeRF-3DTalkeræ–¹æ³•åœ¨è‡ªç”±è§†è§’çš„å¤´éƒ¨åˆæˆä¸Šå…·æœ‰æ½œåœ¨åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-33f39c28483642770755a9d862fceb50.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c7e356ec4ae9c547eb88d9baaf3abd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be6d752ce401869c5e645a63c25c02e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a226b727a51a06b3348f4aa67c6b8ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d18d694cf3a1b85dc08767f11e949739.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-914205336696af67294722fb386f3ffc.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Speech-to-Speech-Translation-with-Translatotron-A-State-of-the-Art-Review"><a href="#Speech-to-Speech-Translation-with-Translatotron-A-State-of-the-Art-Review" class="headerlink" title="Speech to Speech Translation with Translatotron: A State of the Art   Review"></a>Speech to Speech Translation with Translatotron: A State of the Art   Review</h2><p><strong>Authors:Jules R. Kala, Emmanuel Adetiba, Abdultaofeek Abayom, Oluwatobi E. Dare, Ayodele H. Ifijeh</strong></p>
<p>A cascade-based speech-to-speech translation has been considered a benchmark for a very long time, but it is plagued by many issues, like the time taken to translate a speech from one language to another and compound errors. These issues are because a cascade-based method uses a combination of methods such as speech recognition, speech-to-text translation, and finally, text-to-speech translation. Translatotron, a sequence-to-sequence direct speech-to-speech translation model was designed by Google to address the issues of compound errors associated with cascade model. Today there are 3 versions of the Translatotron model: Translatotron 1, Translatotron 2, and Translatotron3. The first version was designed as a proof of concept to show that a direct speech-to-speech translation was possible, it was found to be less effective than the cascade model but was producing promising results. Translatotron2 was an improved version of Translatotron 1 with results similar to the cascade model. Translatotron 3 the latest version of the model is better than the cascade model at some points. In this paper, a complete review of speech-to-speech translation will be presented, with a particular focus on all the versions of Translatotron models. We will also show that Translatotron is the best model to bridge the language gap between African Languages and other well-formalized languages. </p>
<blockquote>
<p>åŸºäºçº§è”çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘å¾ˆé•¿ä¸€æ®µæ—¶é—´ä»¥æ¥ä¸€ç›´è¢«è§†ä¸ºä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œä½†å®ƒå­˜åœ¨è®¸å¤šé—®é¢˜ï¼Œå¦‚å°†è¯­éŸ³ä»ä¸€ç§è¯­è¨€ç¿»è¯‘åˆ°å¦ä¸€ç§è¯­è¨€æ‰€éœ€çš„æ—¶é—´ä»¥åŠå¤åˆé”™è¯¯ã€‚è¿™äº›é—®é¢˜çš„åŸå› æ˜¯ï¼Œçº§è”æ–¹æ³•ç»“åˆäº†è¯¸å¦‚è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ä»¥åŠæœ€ç»ˆçš„æ–‡æœ¬åˆ°è¯­éŸ³ç¿»è¯‘ç­‰æ–¹æ³•ã€‚è°·æ­Œè®¾è®¡äº†åºåˆ—åˆ°åºåˆ—ç›´æ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘æ¨¡å‹Translatotronï¼Œä»¥è§£å†³ä¸çº§è”æ¨¡å‹ç›¸å…³çš„å¤åˆé”™è¯¯é—®é¢˜ã€‚å¦‚ä»Šï¼ŒTranslatotronæ¨¡å‹æœ‰ä¸‰ä¸ªç‰ˆæœ¬ï¼šTranslatotron 1ã€Translatotron 2å’ŒTranslatotron3ã€‚ç¬¬ä¸€ä¸ªç‰ˆæœ¬æ˜¯ä¸ºäº†è¯æ˜ç›´æ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘çš„å¯èƒ½æ€§è€Œè®¾è®¡çš„ï¼Œå‘ç°å…¶æ•ˆæœä¸å¦‚çº§è”æ¨¡å‹ï¼Œä½†äº§ç”Ÿäº†ä»¤äººé¼“èˆçš„ç»“æœã€‚Translatotron2æ˜¯Translatotron 1çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå…¶ç»“æœä¸çº§è”æ¨¡å‹ç›¸ä¼¼ã€‚Translatotron 3ï¼Œå³è¯¥æ¨¡å‹çš„æœ€æ–°ç‰ˆæœ¬ï¼Œåœ¨æŸäº›æ–¹é¢ä¼˜äºçº§è”æ¨¡å‹ã€‚æœ¬æ–‡å°†å…¨é¢å›é¡¾è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ï¼Œç‰¹åˆ«å…³æ³¨æ‰€æœ‰ç‰ˆæœ¬çš„Translatotronæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†å±•ç¤ºTranslatotronæ˜¯å¼¥åˆéæ´²è¯­è¨€ä¸å…¶ä»–è§„èŒƒåŒ–è¯­è¨€ä¹‹é—´è¯­è¨€éšœç¢çš„æœ€ä½³æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05980v2">PDF</a> 12 pages and 3 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºçº§è”çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘é•¿æœŸä»¥æ¥è¢«è§†ä¸ºåŸºå‡†æµ‹è¯•ï¼Œä½†å®ƒå­˜åœ¨è®¸å¤šå¦‚ç¿»è¯‘æ—¶é—´é•¿å’Œå¤åˆé”™è¯¯ç­‰é—®é¢˜ã€‚è¿™äº›é—®é¢˜æºäºçº§è”æ–¹æ³•ç»“åˆäº†è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ç­‰æŠ€æœ¯ã€‚è°·æ­Œè®¾è®¡äº†åºåˆ—åˆ°åºåˆ—çš„ç›´æ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘æ¨¡å‹Translatotronæ¥è§£å†³ä¸çº§è”æ¨¡å‹ç›¸å…³çš„å¤åˆé”™è¯¯é—®é¢˜ã€‚ç›®å‰å·²æœ‰ä¸‰ä¸ªç‰ˆæœ¬çš„Translatotronæ¨¡å‹ï¼šTranslatotron 1ã€Translatotron 2å’ŒTranslatotron 3ã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘ï¼Œé‡ç‚¹å…³æ³¨äº†æ‰€æœ‰ç‰ˆæœ¬çš„Translatotronæ¨¡å‹ï¼Œå¹¶è¡¨æ˜Translatotronæ˜¯å¼¥åˆéæ´²è¯­è¨€ä¸å…¶ä»–æ­£å¼è¯­è¨€ä¹‹é—´è¯­è¨€é¸¿æ²Ÿçš„æœ€ä½³æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çº§è”çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘å­˜åœ¨ç¿»è¯‘æ—¶é—´é•¿å’Œå¤åˆé”™è¯¯ç­‰é—®é¢˜ã€‚</li>
<li>Translatotronæ¨¡å‹ç”±è°·æ­Œè®¾è®¡ï¼Œæ—¨åœ¨è§£å†³ä¸çº§è”æ¨¡å‹ç›¸å…³çš„å¤åˆé”™è¯¯é—®é¢˜ã€‚</li>
<li>ç›®å‰å·²æœ‰ä¸‰ä¸ªç‰ˆæœ¬çš„Translatotronæ¨¡å‹ï¼ŒåŒ…æ‹¬Translatotron 1ã€Translatotron 2å’ŒTranslatotron 3ã€‚</li>
<li>Translatotron 1ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œè¯æ˜ç›´æ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘çš„å¯èƒ½æ€§ï¼Œä½†æ•ˆæœä¸å¦‚çº§è”æ¨¡å‹ã€‚</li>
<li>Translatotron 2æ˜¯Translatotron 1çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå…¶æ•ˆæœä¸çº§è”æ¨¡å‹ç›¸ä¼¼ã€‚</li>
<li>Translatotron 3åœ¨æŸäº›æ–¹é¢ä¼˜äºçº§è”æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05980">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fbe3ab9654590f099e43d9512f414b60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3988b4455770aedb4ddbadff9604179a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0426fb81106a34846c470965b5963a29.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MT2KD-Towards-A-General-Purpose-Encoder-for-Speech-Speaker-and-Audio-Events"><a href="#MT2KD-Towards-A-General-Purpose-Encoder-for-Speech-Speaker-and-Audio-Events" class="headerlink" title="MT2KD: Towards A General-Purpose Encoder for Speech, Speaker, and Audio   Events"></a>MT2KD: Towards A General-Purpose Encoder for Speech, Speaker, and Audio   Events</h2><p><strong>Authors:Xiaoyu Yang, Qiujia Li, Chao Zhang, Phil Woodland</strong></p>
<p>With the advances in deep learning, the performance of end-to-end (E2E) single-task models for speech and audio processing has been constantly improving. However, it is still challenging to build a general-purpose model with high performance on multiple tasks, since different speech and audio processing tasks usually require different training data, input features, or model architectures to achieve optimal performance. In this work, MT2KD, a novel two-stage multi-task learning framework is proposed to build a general-purpose speech and audio encoder that jointly performs three fundamental tasks: automatic speech recognition (ASR), audio tagging (AT) and speaker verification (SV). In the first stage, multi-teacher knowledge distillation (KD) is applied to align the feature spaces of three single-task high-performance teacher encoders into a single student encoder using the same unlabelled data. In the second stage, multi-task supervised fine-tuning is carried out by initialising the model from the first stage and training on the separate labelled data of each single task. Experiments demonstrate that the proposed multi-task training pipeline significantly outperforms a baseline model trained with multi-task learning from scratch. The final system achieves good performance on ASR, AT and SV: with less than 4% relative word-error-rate increase on ASR, only 1.9 lower mean averaged precision on AT and 0.23% absolute higher equal error rate on SV compared to the best-performing single-task encoders, using only a 66M total model parameters. </p>
<blockquote>
<p>éšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼Œç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰å•ä»»åŠ¡æ¨¡å‹åœ¨è¯­éŸ³å’ŒéŸ³é¢‘å¤„ç†æ–¹é¢çš„æ€§èƒ½ä¸æ–­æå‡ã€‚ç„¶è€Œï¼Œæ„å»ºèƒ½å¤Ÿåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°é«˜æ€§èƒ½çš„é€šç”¨æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºä¸åŒçš„è¯­éŸ³å’ŒéŸ³é¢‘å¤„ç†ä»»åŠ¡é€šå¸¸éœ€è¦ä¸åŒçš„è®­ç»ƒæ•°æ®ã€è¾“å…¥ç‰¹å¾æˆ–æ¨¡å‹æ¶æ„æ¥å®ç°æœ€ä½³æ€§èƒ½ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæå‡ºäº†MT2KDè¿™ä¸€æ–°å‹ä¸¤é˜¶æ®µå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ„å»ºä¸€ç§é€šç”¨è¯­éŸ³å’ŒéŸ³é¢‘ç¼–ç å™¨ï¼Œè¯¥ç¼–ç å™¨å¯è”åˆæ‰§è¡Œä¸‰ä¸ªåŸºæœ¬ä»»åŠ¡ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€éŸ³é¢‘æ ‡ç­¾ï¼ˆATï¼‰å’Œè¯´è¯äººéªŒè¯ï¼ˆSVï¼‰ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œåº”ç”¨å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰æŠ€æœ¯ï¼Œä½¿ç”¨ç›¸åŒçš„æ— æ ‡ç­¾æ•°æ®å°†ä¸‰ä¸ªé«˜æ€§èƒ½å•ä»»åŠ¡æ•™å¸ˆç¼–ç å™¨çš„ç‰¹å¾ç©ºé—´å¯¹é½åˆ°ä¸€ä¸ªå•ä¸€çš„å­¦ç”Ÿç¼–ç å™¨ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œé€šè¿‡åˆå§‹æ¨¡å‹è¿›è¡Œç¬¬ä¸€é˜¶æ®µçš„å¤šä»»åŠ¡ç›‘ç£å¾®è°ƒï¼Œå¹¶åœ¨æ¯ä¸ªå•ç‹¬ä»»åŠ¡çš„æ ‡è®°æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å¤šä»»åŠ¡è®­ç»ƒæµæ°´çº¿æ˜¾è‘—ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„å¤šä»»åŠ¡å­¦ä¹ åŸºçº¿æ¨¡å‹ã€‚æœ€ç»ˆç³»ç»Ÿåœ¨ASRã€ATå’ŒSVæ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼šASRçš„è¯é”™è¯¯ç‡å¢åŠ ä¸åˆ°4%ï¼ŒATçš„å¹³å‡ç²¾åº¦ä¸‹é™åªæœ‰1.9ï¼ŒSVçš„ç»å¯¹ç­‰é”™è¯¯ç‡æé«˜0.23%ï¼Œè€Œæ€»æ¨¡å‹å‚æ•°ä»…ä½¿ç”¨66Mã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.17010v4">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong></p>
<p>éšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼Œç«¯åˆ°ç«¯å•ä¸€ä»»åŠ¡æ¨¡å‹åœ¨è¯­éŸ³å’ŒéŸ³é¢‘å¤„ç†æ–¹é¢çš„æ€§èƒ½æŒç»­æå‡ã€‚ç„¶è€Œï¼Œæ„å»ºèƒ½åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°é«˜æ€§èƒ½çš„é€šç”¨æ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºMT2KDï¼Œä¸€ç§æ–°å‹ä¸¤é˜¶æ®µå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æ„å»ºèƒ½å¤Ÿæ‰§è¡Œä¸‰é¡¹åŸºæœ¬ä»»åŠ¡çš„é€šç”¨è¯­éŸ³å’ŒéŸ³é¢‘ç¼–ç å™¨ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€éŸ³é¢‘æ ‡ç­¾ï¼ˆATï¼‰å’Œè¯´è¯äººéªŒè¯ï¼ˆSVï¼‰ã€‚è¯¥æ¡†æ¶å…ˆé€šè¿‡å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦å°†ä¸‰ä¸ªé«˜æ€§èƒ½å•ä¸€ä»»åŠ¡æ•™å¸ˆç¼–ç å™¨çš„ç‰¹å¾ç©ºé—´å¯¹é½åˆ°ä¸€ä¸ªå•ä¸€çš„å­¦ç”Ÿç¼–ç å™¨ä¸Šã€‚æ¥ç€åœ¨ç¬¬ä¸€é˜¶æ®µæ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨æ¯ä¸ªå•ä¸€ä»»åŠ¡çš„æ ‡æ³¨æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥å¤šä»»åŠ¡è®­ç»ƒæµç¨‹æ˜¾è‘—ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„å¤šä»»åŠ¡å­¦ä¹ åŸºçº¿æ¨¡å‹ã€‚æœ€ç»ˆç³»ç»Ÿåœ¨ä¸æœ€ä½³çš„å•ä»»åŠ¡ç¼–ç å™¨ç›¸æ¯”æ—¶ï¼Œåœ¨ASRä¸Šçš„ç›¸å¯¹è¯é”™è¯¯ç‡å¢åŠ ä¸åˆ°4%ï¼Œåœ¨ATä¸Šçš„å¹³å‡ç²¾åº¦ä»…ä½1.9ï¼Œåœ¨SVä¸Šçš„ç­‰é”™è¯¯ç‡ç»å¯¹é«˜å‡º0.23%ï¼Œä¸”æ€»æ¨¡å‹å‚æ•°ä»…ä¸º66Mã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç«¯åˆ°ç«¯å•ä¸€ä»»åŠ¡æ¨¡å‹åœ¨è¯­éŸ³å’ŒéŸ³é¢‘å¤„ç†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†æ„å»ºå¤šç”¨é€”æ¨¡å‹å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µå¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶MT2KDã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µé€šè¿‡å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦å°†å¤šä¸ªä»»åŠ¡çš„ç‰¹å¾ç©ºé—´æ•´åˆåˆ°å•ä¸€å­¦ç”Ÿæ¨¡å‹ä¸­ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µåœ¨å¤šä»»åŠ¡æ ‡æ³¨æ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒã€‚</li>
<li>MT2KDæ˜¾è‘—ä¼˜äºå¤šä»»åŠ¡å­¦ä¹ åŸºçº¿æ¨¡å‹ã€‚</li>
<li>æœ€ç»ˆæ¨¡å‹åœ¨ASRã€ATå’ŒSVä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°ç›¸å¯¹ä¼˜å¼‚ã€‚</li>
<li>æ¨¡å‹æ€»å‚æ•°ä»…ä¸º66Mã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.17010">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-310fa02a80b5596f264388fbfe602ead.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96870bebe383a7e026db69c2b22a6bdc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58b3408412588edeb8c16371af7cb616.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15e67e0c5ed3d31f2504af5082533e69.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cd6c4d2e3ec03d2a84165805ad0faa56.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  A Racing Dataset and Baseline Model for Track Detection in Autonomous   Racing
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-f1f51db6dcce32bab82abcd113417182.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  Monocular Depth Estimation and Segmentation for Transparent Object with   Iterative Semantic and Geometric Fusion
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18799.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
