<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-02-22  Exploiting Deblurring Networks for Radiance Fields">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-992c3f7fd01472b55deeef96bc1109a4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-22-更新"><a href="#2025-02-22-更新" class="headerlink" title="2025-02-22 更新"></a>2025-02-22 更新</h1><h2 id="Exploiting-Deblurring-Networks-for-Radiance-Fields"><a href="#Exploiting-Deblurring-Networks-for-Radiance-Fields" class="headerlink" title="Exploiting Deblurring Networks for Radiance Fields"></a>Exploiting Deblurring Networks for Radiance Fields</h2><p><strong>Authors:Haeyun Choi, Heemin Yang, Janghyeok Han, Sunghyun Cho</strong></p>
<p>In this paper, we propose DeepDeblurRF, a novel radiance field deblurring approach that can synthesize high-quality novel views from blurred training views with significantly reduced training time. DeepDeblurRF leverages deep neural network (DNN)-based deblurring modules to enjoy their deblurring performance and computational efficiency. To effectively combine DNN-based deblurring and radiance field construction, we propose a novel radiance field (RF)-guided deblurring and an iterative framework that performs RF-guided deblurring and radiance field construction in an alternating manner. Moreover, DeepDeblurRF is compatible with various scene representations, such as voxel grids and 3D Gaussians, expanding its applicability. We also present BlurRF-Synth, the first large-scale synthetic dataset for training radiance field deblurring frameworks. We conduct extensive experiments on both camera motion blur and defocus blur, demonstrating that DeepDeblurRF achieves state-of-the-art novel-view synthesis quality with significantly reduced training time. </p>
<blockquote>
<p>本文提出了DeepDeblurRF，这是一种新的辐射场去模糊方法，能够从模糊的训练视角合成高质量的新视角，并显著减少训练时间。DeepDeblurRF利用基于深度神经网络（DNN）的去模糊模块，享受其去模糊性能和计算效率。为了有效地结合基于DNN的去模糊和辐射场构建，我们提出了一种新的辐射场（RF）引导去模糊方法和迭代框架，该框架以交替的方式进行RF引导去模糊和辐射场构建。此外，DeepDeblurRF可与各种场景表示兼容，例如体素网格和3D高斯，扩大了其适用性。我们还推出了BlurRF-Synth，这是第一个用于训练辐射场去模糊框架的大规模合成数据集。我们对相机运动模糊和失焦模糊进行了大量实验，结果表明，DeepDeblurRF在新型视图合成质量方面达到了最新水平，并显著减少了训练时间。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14454v1">PDF</a> </p>
<p><strong>Summary</strong><br>深度去模糊射线场（DeepDeblurRF）是一种新型的去模糊方法，结合了深度神经网络（DNN）和射线场技术，可从模糊的训练视角合成高质量的新视角，同时显著减少训练时间。此方法通过交替进行射线场引导和去模糊操作，兼容多种场景表示，如体素网格和三维高斯模型。此外，还推出了BlurRF-Synth，这是首个用于训练射线场去模糊框架的大型合成数据集。实验证明，DeepDeblurRF在新型视角合成质量方面达到领先水平，同时显著缩短了训练时间。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeepDeblurRF是一种结合深度神经网络和射线场的去模糊方法。</li>
<li>该方法可以合成高质量的新视角，从模糊的训练视角出发，显著减少训练时间。</li>
<li>通过交替进行射线场引导和去模糊操作，实现了DNN去模糊模块和射线场构建的有效结合。</li>
<li>DeepDeblurRF兼容多种场景表示，如体素网格和三维高斯模型。</li>
<li>推出了首个用于训练射线场去模糊框架的大型合成数据集BlurRF-Synth。</li>
<li>实验结果表明，DeepDeblurRF在新型视角合成质量方面表现优异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14454">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5aebc58c42ef19744fe22c6ed0acd826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-466f7869a67b350e22fbc95a62059f46.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb96f18acd6fda449931e53315484738.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41c259793aca5256c7cc0b01e5a35d06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-893834eb569131adb6b9634ff323932a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fdeda11eb46c5b6bfef5c9db0752bc9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="OG-Gaussian-Occupancy-Based-Street-Gaussians-for-Autonomous-Driving"><a href="#OG-Gaussian-Occupancy-Based-Street-Gaussians-for-Autonomous-Driving" class="headerlink" title="OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving"></a>OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving</h2><p><strong>Authors:Yedong Shen, Xinran Zhang, Yifan Duan, Shiqi Zhang, Heng Li, Yilong Wu, Jianmin Ji, Yanyong Zhang</strong></p>
<p>Accurate and realistic 3D scene reconstruction enables the lifelike creation of autonomous driving simulation environments. With advancements in 3D Gaussian Splatting (3DGS), previous studies have applied it to reconstruct complex dynamic driving scenes. These methods typically require expensive LiDAR sensors and pre-annotated datasets of dynamic objects. To address these challenges, we propose OG-Gaussian, a novel approach that replaces LiDAR point clouds with Occupancy Grids (OGs) generated from surround-view camera images using Occupancy Prediction Network (ONet). Our method leverages the semantic information in OGs to separate dynamic vehicles from static street background, converting these grids into two distinct sets of initial point clouds for reconstructing both static and dynamic objects. Additionally, we estimate the trajectories and poses of dynamic objects through a learning-based approach, eliminating the need for complex manual annotations. Experiments on Waymo Open dataset demonstrate that OG-Gaussian is on par with the current state-of-the-art in terms of reconstruction quality and rendering speed, achieving an average PSNR of 35.13 and a rendering speed of 143 FPS, while significantly reducing computational costs and economic overhead. </p>
<blockquote>
<p>准确而逼真的3D场景重建能够实现自动驾驶模拟环境的真实创建。随着3D高斯拼贴（3DGS）的发展，先前的研究已将其应用于重建复杂的动态驾驶场景。这些方法通常需要使用昂贵的激光雷达传感器和动态物体的预标注数据集。为了解决这些挑战，我们提出了OG-高斯（OG-Gaussian）这一新方法，它用占用网格（OGs）替代激光雷达点云，这些占用网格是通过使用占用预测网络（ONet）从周围视图图像生成的。我们的方法利用网格中的语义信息来分离动态车辆和静态街道背景，将这些网格转换为两组不同的初始点云，以重建静态和动态物体。此外，我们还通过基于学习的方法估计动态物体的轨迹和姿态，无需进行复杂的手动标注。在Waymo Open数据集上的实验表明，OG-高斯在重建质量和渲染速度方面与当前先进技术相当，平均PSNR达到35.13，渲染速度为每秒143帧，同时显著降低了计算成本和经济成本。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14235v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于精准的实时动态驾驶场景重建，通过Occupancy Grids技术构建道路信息环境并实现场景的复现。提出OG-Gaussian新方法利用环绕视图相机图像和Occupancy Prediction Network技术替代昂贵的LiDAR传感器和动态物体预标注数据集，通过语义信息分离动态车辆与静态街道背景并转化为不同的初始点云集合。同时，利用学习技术预测动态物体的轨迹和姿态，无需复杂的标记标注过程。实验数据在Waymo Open数据集上显示出该方法的优越性，可实现高效稳定的驾驶模拟场景重建。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>基于实时的动态驾驶场景重建技术实现了道路的精准模拟复现。</li>
<li>利用Occupancy Grids技术构建道路信息环境，提高场景复现的准确度。</li>
<li>提出OG-Gaussian新方法替代昂贵的LiDAR传感器和预标注数据集。</li>
<li>利用环绕视图相机图像和Occupancy Prediction Network技术提取场景语义信息，便于后续处理。</li>
<li>通过语义信息分离动态车辆与静态街道背景并转化为不同的初始点云集合，提高重建质量。</li>
<li>利用学习技术预测动态物体的轨迹和姿态，减少人工标注的工作量。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14235">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d1209a0cfd89661a53ff9abd0e0ab2dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44bb7b612969efdc95f515390cdee352.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e609acd447efe11ea90f4ab0f2eb7bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b0d6e562babcfb8066a4a384a352cd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7904bb232ea945828824c8c26f25ee4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15738cbeb1e590c6ecf6df9c3daf982f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ef788f1daff0372f52894715d61b324.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Inter3D-A-Benchmark-and-Strong-Baseline-for-Human-Interactive-3D-Object-Reconstruction"><a href="#Inter3D-A-Benchmark-and-Strong-Baseline-for-Human-Interactive-3D-Object-Reconstruction" class="headerlink" title="Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object   Reconstruction"></a>Inter3D: A Benchmark and Strong Baseline for Human-Interactive 3D Object   Reconstruction</h2><p><strong>Authors:Gan Chen, Ying He, Mulin Yu, F. Richard Yu, Gang Xu, Fei Ma, Ming Li, Guang Zhou</strong></p>
<p>Recent advancements in implicit 3D reconstruction methods, e.g., neural rendering fields and Gaussian splatting, have primarily focused on novel view synthesis of static or dynamic objects with continuous motion states. However, these approaches struggle to efficiently model a human-interactive object with n movable parts, requiring 2^n separate models to represent all discrete states. To overcome this limitation, we propose Inter3D, a new benchmark and approach for novel state synthesis of human-interactive objects. We introduce a self-collected dataset featuring commonly encountered interactive objects and a new evaluation pipeline, where only individual part states are observed during training, while part combination states remain unseen. We also propose a strong baseline approach that leverages Space Discrepancy Tensors to efficiently modelling all states of an object. To alleviate the impractical constraints on camera trajectories across training states, we propose a Mutual State Regularization mechanism to enhance the spatial density consistency of movable parts. In addition, we explore two occupancy grid sampling strategies to facilitate training efficiency. We conduct extensive experiments on the proposed benchmark, showcasing the challenges of the task and the superiority of our approach. </p>
<blockquote>
<p>近期隐式三维重建方法的进展，例如神经网络渲染和高斯贴图技术，主要关注静态或动态物体的新型视图合成，这些物体具有连续的运动状态。然而，这些方法在模拟具有n个可移动部件的人机交互物体时面临困难，需要2^n个独立模型来表示所有离散状态。为了克服这一局限性，我们提出了Inter3D，这是一个新的基准测试方法和人机交互物体新型状态合成的方法。我们引入了一个自收集的数据集，其中包含常见交互物体，以及一个新的评估流程，在训练期间仅观察单个部件的状态，而部件组合状态则保持未见。我们还提出了一种强大的基线方法，利用空间差异张量来有效地模拟物体的所有状态。为了缓解训练状态下相机轨迹的不切实际约束，我们提出了一种互状态正则化机制，以提高可移动部件的空间密度一致性。此外，我们探索了两种占用网格采样策略以提高训练效率。我们在提出的基准测试上进行了大量实验，展示了该任务的挑战性以及我们方法的优越性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14004v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>近期隐式三维重建方法，如神经网络渲染和高斯涂抹技术，主要关注静态或动态物体的新视角合成。但对于含有可移动部件的人机交互物体，这些方法在高效建模方面存在挑战，需用2^n个模型表示所有离散状态。为此，我们提出Inter3D，一个针对人机交互物体新状态合成的新基准和方法。我们引入了自收集数据集和新评估流程，训练时仅观察单个部件状态，组合状态则不可见。我们提出了一个强大的基线方法，利用空间差异张量来高效建模物体的所有状态。同时，为解决训练状态下相机轨迹的不实际约束问题，我们提出了相互状态正则化机制，以提高可移动部件的空间密度一致性。此外，我们还探索了两种占用网格采样策略以提高训练效率。在提出的基准上进行了大量实验，展示了任务挑战性和我们方法的优越性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>近期隐式三维重建方法主要关注静态或动态物体的新视角合成。</li>
<li>现有方法难以高效建模含多个可移动部件的人机交互物体。</li>
<li>Inter3D提出一个自收集数据集和新评估流程，用于人机交互物体的新状态合成。</li>
<li>Inter3D仅观察单个部件状态进行训练，组合状态在训练时不可见。</li>
<li>提出利用空间差异张量进行高效建模的基线方法。</li>
<li>提出相互状态正则化机制，提高可移动部件的空间密度一致性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14004">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-57a3349d761052cdcc95d575b301f19c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53273eca528371fad8eceb7cd969d94e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3384db6f322ffc2dd8dcb85e4f35c48.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cbdcbaa8fabe942a6a2a0372d1eb7874.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55ad0686c60475225883d0f268c2b26c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8613b97fb01151570636dacca7cff0b6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CaRtGS-Computational-Alignment-for-Real-Time-Gaussian-Splatting-SLAM"><a href="#CaRtGS-Computational-Alignment-for-Real-Time-Gaussian-Splatting-SLAM" class="headerlink" title="CaRtGS: Computational Alignment for Real-Time Gaussian Splatting SLAM"></a>CaRtGS: Computational Alignment for Real-Time Gaussian Splatting SLAM</h2><p><strong>Authors:Dapeng Feng, Zhiqiang Chen, Yizhen Yin, Shipeng Zhong, Yuhua Qi, Hongbo Chen</strong></p>
<p>Simultaneous Localization and Mapping (SLAM) is pivotal in robotics, with photorealistic scene reconstruction emerging as a key challenge. To address this, we introduce Computational Alignment for Real-Time Gaussian Splatting SLAM (CaRtGS), a novel method enhancing the efficiency and quality of photorealistic scene reconstruction in real-time environments. Leveraging 3D Gaussian Splatting (3DGS), CaRtGS achieves superior rendering quality and processing speed, which is crucial for scene photorealistic reconstruction. Our approach tackles computational misalignment in Gaussian Splatting SLAM (GS-SLAM) through an adaptive strategy that enhances optimization iterations, addresses long-tail optimization, and refines densification. Experiments on Replica, TUM-RGBD, and VECtor datasets demonstrate CaRtGS’s effectiveness in achieving high-fidelity rendering with fewer Gaussian primitives. This work propels SLAM towards real-time, photorealistic dense rendering, significantly advancing photorealistic scene representation. For the benefit of the research community, we release the code and accompanying videos on our project website: <a target="_blank" rel="noopener" href="https://dapengfeng.github.io/cartgs">https://dapengfeng.github.io/cartgs</a>. </p>
<blockquote>
<p>同时定位与地图构建（SLAM）在机器人技术中至关重要，而真实感场景重建成为了一项关键挑战。为解决这一问题，我们引入了面向实时高斯拼贴SLAM的计算对齐（CaRtGS）方法，这是一种提高实时环境中真实感场景重建效率和质量的新型技术。通过利用三维高斯拼贴（3DGS），CaRtGS可实现出色的渲染质量和处理速度，对于场景的真实感重建至关重要。我们的方法通过自适应策略解决了高斯拼贴SLAM中的计算失准问题，通过优化迭代增强、解决长期优化并改进密集化。在Replica、TUM-RGBD和VECtor数据集上的实验表明，CaRtGS在实现使用更少高斯原语的高保真渲染方面非常有效。这项工作推动了SLAM技术向实时真实感密集渲染的发展，极大地推动了真实感场景表示的进步。为了造福研究界，我们在项目网站上发布了代码和相关视频：<a target="_blank" rel="noopener" href="https://dapengfeng.github.io/cartgs">https://dapengfeng.github.io/cartgs</a> 。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00486v3">PDF</a> Accepted by IEEE Robotics and Automation Letters (RA-L)</p>
<p><strong>Summary</strong><br>     实时环境下的光写实场景重建是机器人技术中的关键挑战。为解决这一问题，我们提出计算对齐实时高斯贴片SLAM（CaRtGS），这是一种增强光写实场景重建效率和质量的新方法。借助3D高斯贴片技术，CaRtGS实现了出色的渲染质量和处理速度，对高斯贴片SLAM中的计算错位问题采用自适应策略，优化迭代过程，解决长尾优化问题，并改进了密集化过程。在Replica、TUM-RGBD和VECtor数据集上的实验表明，CaRtGS在高保真渲染方面表现出色，使用的Gaussian primitives数量更少。本研究推动了SLAM技术向实时光写实密集渲染的发展，显著提升了光写实场景的表现能力。有关该项目的代码和相关视频可在我们的网站上获取：<a target="_blank" rel="noopener" href="https://dapengfeng.github.io/cartgs%E3%80%82">https://dapengfeng.github.io/cartgs。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Simultaneous Localization and Mapping (SLAM)在机器人技术中非常重要，而光写实场景重建是其中的一项关键挑战。</li>
<li>提出了计算对齐实时高斯贴片SLAM（CaRtGS）方法，旨在提高光写实场景重建的效率和质量。</li>
<li>CaRtGS利用3D高斯贴片技术实现高渲染质量和处理速度，对高斯贴片SLAM中的计算错位问题进行了优化。</li>
<li>CaRtGS通过自适应策略解决长尾优化问题并改进密集化过程。</li>
<li>在多个数据集上的实验表明，CaRtGS在高保真渲染方面表现优越，使用较少的Gaussian primitives即可实现高质量渲染。</li>
<li>CaRtGS的研究推动了SLAM技术向实时光写实密集渲染的发展。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00486">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c68a9eef5d0a407567e6a19e01f4bb9b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f8c3e5a42edbdf0e3c6cfc08a60f9aa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-992c3f7fd01472b55deeef96bc1109a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-315b9a3f3b99e768c60172bcdbc222c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1d60d995257fd3f0fe617c01b996bf85.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6604033cfbe81e8165d2f48eb163e909.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Hier-SLAM-Scaling-up-Semantics-in-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting"><a href="#Hier-SLAM-Scaling-up-Semantics-in-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting" class="headerlink" title="Hier-SLAM: Scaling-up Semantics in SLAM with a Hierarchically   Categorical Gaussian Splatting"></a>Hier-SLAM: Scaling-up Semantics in SLAM with a Hierarchically   Categorical Gaussian Splatting</h2><p><strong>Authors:Boying Li, Zhixi Cai, Yuan-Fang Li, Ian Reid, Hamid Rezatofighi</strong></p>
<p>We propose Hier-SLAM, a semantic 3D Gaussian Splatting SLAM method featuring a novel hierarchical categorical representation, which enables accurate global 3D semantic mapping, scaling-up capability, and explicit semantic label prediction in the 3D world. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making it particularly challenging and costly for scene understanding. To address this problem, we introduce a novel hierarchical representation that encodes semantic information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs). We further introduce a novel semantic loss designed to optimize hierarchical semantic information through both inter-level and cross-level optimization. Furthermore, we enhance the whole SLAM system, resulting in improved tracking and mapping performance. Our Hier-SLAM outperforms existing dense SLAM methods in both mapping and tracking accuracy, while achieving a 2x operation speed-up. Additionally, it exhibits competitive performance in rendering semantic segmentation in small synthetic scenes, with significantly reduced storage and training time requirements. Rendering FPS impressively reaches 2,000 with semantic information and 3,000 without it. Most notably, it showcases the capability of handling the complex real-world scene with more than 500 semantic classes, highlighting its valuable scaling-up capability. </p>
<blockquote>
<p>我们提出了名为 Hier-SLAM 的语义三维高斯模糊 SLAM 方法，它采用了一种新型层次分类表示，能够实现准确的全局三维语义映射、可扩展性和三维世界中的显式语义标签预测。随着环境复杂性的增加，语义 SLAM 系统中的参数使用量也显著增加，这对场景理解构成了极大的挑战和成本。为了解决这个问题，我们引入了一种新型层次表示，利用大型语言模型的能力，将语义信息以紧凑的形式编码到三维高斯模糊中。我们进一步引入了一种新型语义损失，通过跨级别优化来优化层次语义信息。此外，我们增强了整个 SLAM 系统的功能，提高了跟踪和映射性能。我们的 Hier-SLAM 在映射和跟踪精度方面优于现有的密集 SLAM 方法，同时实现了 2 倍的操作速度提升。此外，它在小型合成场景中的语义分割渲染表现具有竞争力，显著减少了存储和训练时间要求。在有语义信息的情况下，渲染 FPS 令人印象深刻地达到了 2000，而没有语义信息的情况下则达到了 3000。最值得注意的是，它展示了处理具有超过 500 个语义类别的复杂现实世界场景的能力，突显了其有价值的可扩展性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.12518v3">PDF</a> Accepted for publication at ICRA 2025. Code will be released soon</p>
<p><strong>摘要</strong></p>
<p>本文提出一种名为Hier-SLAM的语义3D高斯点云SLAM方法，它采用新颖的分层次类别表示，能够实现准确的全局3D语义映射、扩展能力和明确的语义标签预测。随着环境复杂性的增长，语义SLAM系统中的参数使用量急剧增加，给场景理解带来巨大挑战和成本。为解决此问题，我们借助大型语言模型（LLMs）的能力，将语义信息以紧凑的形式编码到3D高斯点云中。我们还引入了一种新的语义损失，通过跨级别优化来优化层次语义信息。此外，我们增强了整个SLAM系统的性能，提高了跟踪和映射的精确度。Hier-SLAM在映射和跟踪精度上均优于现有的密集SLAM方法，同时实现了2倍的操作速度提升。此外，它在小型合成场景中实现了具有竞争力的语义分割性能，并显著降低了存储和训练时间要求。渲染帧率在带有语义信息的情况下达到了惊人的2000帧，而在没有语义信息的情况下则达到了3000帧。最引人注目的是，它展示了处理具有超过500个语义类别的复杂真实场景的能力，突显了其有价值的扩展能力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>Hier-SLAM是一种语义3D高斯点云SLAM方法，融合了新颖的分层次类别表示。</li>
<li>该方法实现了准确的全局3D语义映射、扩展能力和明确的语义标签预测。</li>
<li>面对环境复杂性的增长，Hier-SLAM通过利用大型语言模型（LLMs）以紧凑形式编码语义信息，有效应对参数使用量的增加。</li>
<li>引入新的语义损失来优化层次语义信息，既有跨级别优化功能又提升了整体性能。</li>
<li>Hier-SLAM在映射和跟踪精度上优于现有密集SLAM方法，且操作速度提升了2倍。</li>
<li>在小型合成场景中，其渲染语义分割性能表现出竞争力，存储和训练时间显著降低。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.12518">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-142c8307d391a22615b3681e8a4912c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b462872e952aef9627cc81d60b2250e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d22e350e89836280c502fb0d0cde93e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09e961952d393b81e27a6e583d11bc50.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-203f669809245a1cba5536083d65fe95.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-db775b894136a77cceee561116670472.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="OccGaussian-3D-Gaussian-Splatting-for-Occluded-Human-Rendering"><a href="#OccGaussian-3D-Gaussian-Splatting-for-Occluded-Human-Rendering" class="headerlink" title="OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering"></a>OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering</h2><p><strong>Authors:Jingrui Ye, Zongkai Zhang, Yujiao Jiang, Qingmin Liao, Wenming Yang, Zongqing Lu</strong></p>
<p>Rendering dynamic 3D human from monocular videos is crucial for various applications such as virtual reality and digital entertainment. Most methods assume the people is in an unobstructed scene, while various objects may cause the occlusion of body parts in real-life scenarios. Previous method utilizing NeRF for surface rendering to recover the occluded areas, but it requiring more than one day to train and several seconds to render, failing to meet the requirements of real-time interactive applications. To address these issues, we propose OccGaussian based on 3D Gaussian Splatting, which can be trained within 6 minutes and produces high-quality human renderings up to 160 FPS with occluded input. OccGaussian initializes 3D Gaussian distributions in the canonical space, and we perform occlusion feature query at occluded regions, the aggregated pixel-align feature is extracted to compensate for the missing information. Then we use Gaussian Feature MLP to further process the feature along with the occlusion-aware loss functions to better perceive the occluded area. Extensive experiments both in simulated and real-world occlusions, demonstrate that our method achieves comparable or even superior performance compared to the state-of-the-art method. And we improving training and inference speeds by 250x and 800x, respectively. Our code will be available for research purposes. </p>
<blockquote>
<p>从单目视频中渲染动态3D人体对于虚拟现实和数字娱乐等应用程序至关重要。大多数方法都假设人在一个无遮挡的场景中，而在现实场景中，各种物体可能会导致身体部位的遮挡。之前的方法使用NeRF进行表面渲染以恢复遮挡区域，但需要一天以上的训练时间和数秒的渲染时间，无法满足实时互动应用的要求。为了解决这些问题，我们提出了基于三维高斯拼贴技术的OccGaussian方法。该方法可以在6分钟内完成训练，并在高达每秒最多产生帧率为每秒十六帧的情况下生成高质量的人体渲染效果，适用于有遮挡输入的情况。OccGaussian在标准空间中对三维高斯分布进行初始化，然后在遮挡区域执行遮挡特征查询操作。为了补偿丢失的信息，我们提取聚合像素对齐特征。然后，我们使用高斯特征多层感知器进一步处理特征，并结合遮挡感知损失函数，以更好地感知遮挡区域。在模拟和真实遮挡环境中进行的广泛实验表明，我们的方法与最新技术相比具有相当或更好的性能。我们还提高了训练和推理速度，分别为原来的二百五十倍和八百倍。我们的代码将用于研究目的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.08449v3">PDF</a> We have decided to withdraw this paper because the results require   further verification or additional experimental data. We plan to resubmit an   updated version once the necessary work is completed</p>
<p><strong>Summary</strong></p>
<p>本文介绍了在虚拟现实和数字娱乐等应用中，从单目视频中渲染动态3D人体的重要性。针对现实中物体遮挡身体部位的问题，提出了一种基于3D高斯涂污的OccGaussian方法。该方法可在6分钟内进行训练，以高达160FPS的速度生成高质量的遮挡人体渲染。通过初始化规范空间中的3D高斯分布，在遮挡区域执行遮挡特征查询，提取聚合像素对齐特征以补偿缺失信息。然后结合高斯特征多层感知器和遮挡感知损失函数，进一步提高对遮挡区域的感知能力。在模拟和真实遮挡环境下的广泛实验表明，该方法与最新技术相比取得了相当或更优的性能，并将训练和推理速度分别提高了250倍和800倍。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>动态3D人体渲染对于虚拟现实和数字娱乐等应用至关重要。</li>
<li>现有方法大多假设人体处于无遮挡场景中，但现实中存在物体遮挡问题。</li>
<li>提出的OccGaussian方法基于3D高斯涂污，可快速训练并生成高质量的人体渲染。</li>
<li>OccGaussian通过在规范空间中初始化3D高斯分布，并在遮挡区域执行特征查询来处理遮挡问题。</li>
<li>通过提取聚合像素对齐特征来补偿缺失信息。</li>
<li>结合高斯特征多层感知器和遮挡感知损失函数，提高对遮挡区域的感知。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.08449">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-22b96540b149a8534443374615ca8599.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab11fe939c3521e47d3227ac9f217bda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3930eb7a35a4e86cf46c4da432a8a109.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe0032a9957ec683a4fc3e6deab6cc1d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d18d694cf3a1b85dc08767f11e949739.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-02-22  NeRF-3DTalker Neural Radiance Field with 3D Prior Aided Audio   Disentanglement for Talking Head Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cd6c4d2e3ec03d2a84165805ad0faa56.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2025-02-22  A Racing Dataset and Baseline Model for Track Detection in Autonomous   Racing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19380.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
