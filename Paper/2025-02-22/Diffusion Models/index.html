<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  A Survey on Text-Driven 360-Degree Panorama Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-a5f906428dc7327be918f0b7e1b6dc75.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    34 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-22-æ›´æ–°"><a href="#2025-02-22-æ›´æ–°" class="headerlink" title="2025-02-22 æ›´æ–°"></a>2025-02-22 æ›´æ–°</h1><h2 id="A-Survey-on-Text-Driven-360-Degree-Panorama-Generation"><a href="#A-Survey-on-Text-Driven-360-Degree-Panorama-Generation" class="headerlink" title="A Survey on Text-Driven 360-Degree Panorama Generation"></a>A Survey on Text-Driven 360-Degree Panorama Generation</h2><p><strong>Authors:Hai Wang, Xiaoyu Xiang, Weihao Xia, Jing-Hao Xue</strong></p>
<p>The advent of text-driven 360-degree panorama generation, enabling the synthesis of 360-degree panoramic images directly from textual descriptions, marks a transformative advancement in immersive visual content creation. This innovation significantly simplifies the traditionally complex process of producing such content. Recent progress in text-to-image diffusion models has accelerated the rapid development in this emerging field. This survey presents a comprehensive review of text-driven 360-degree panorama generation, offering an in-depth analysis of state-of-the-art algorithms and their expanding applications in 360-degree 3D scene generation. Furthermore, we critically examine current limitations and propose promising directions for future research. A curated project page with relevant resources and research papers is available at <a target="_blank" rel="noopener" href="https://littlewhitesea.github.io/Text-Driven-Pano-Gen/">https://littlewhitesea.github.io/Text-Driven-Pano-Gen/</a>. </p>
<blockquote>
<p>æ–‡æœ¬é©±åŠ¨å¼360åº¦å…¨æ™¯ç”Ÿæˆçš„å‡ºç°ï¼Œä½¿å¾—èƒ½å¤Ÿç›´æ¥ä»æ–‡æœ¬æè¿°ä¸­åˆæˆ360åº¦å…¨æ™¯å›¾åƒï¼Œè¿™æ ‡å¿—ç€æ²‰æµ¸å¼è§†è§‰å†…å®¹åˆ›ä½œé¢†åŸŸçš„ä¸€æ¬¡å˜é©æ€§è¿›æ­¥ã€‚è¿™ä¸€åˆ›æ–°æå¤§åœ°ç®€åŒ–äº†ä¼ ç»Ÿä¸Šåˆ¶ä½œæ­¤ç±»å†…å®¹çš„å¤æ‚è¿‡ç¨‹ã€‚æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•åŠ é€Ÿäº†è¿™ä¸€æ–°å…´é¢†åŸŸçš„å¿«é€Ÿå‘å±•ã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†æ–‡æœ¬é©±åŠ¨çš„360åº¦å…¨æ™¯ç”ŸæˆæŠ€æœ¯ï¼Œæ·±å…¥åˆ†æäº†æœ€æ–°ç®—æ³•åŠå…¶åœ¨360åº¦ä¸‰ç»´åœºæ™¯ç”Ÿæˆä¸­çš„ä¸æ–­æ‰©å±•çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¹å½“å‰çš„å±€é™æ€§è¿›è¡Œäº†æ‰¹åˆ¤æ€§å®¡è§†ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„å¸Œæœ›æ–¹å‘ã€‚ç›¸å…³èµ„æºå’Œç ”ç©¶è®ºæ–‡ç²¾é€‰çš„é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://littlewhitesea.github.io/Text-Driven-Pano-Gen/%E6%89%BE%E5%88%B0%E3%80%82">https://littlewhitesea.github.io/Text-Driven-Pano-Gen/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14799v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬é©±åŠ¨çš„360åº¦å…¨æ™¯ç”ŸæˆæŠ€æœ¯ç®€åŒ–äº†ä¼ ç»Ÿå¤æ‚çš„å†…å®¹åˆ¶ä½œè¿‡ç¨‹ï¼Œä½¿å¾—ä»æ–‡æœ¬æè¿°ç›´æ¥åˆæˆ360åº¦å…¨æ™¯å›¾åƒæˆä¸ºå¯èƒ½ã€‚æ­¤åˆ›æ–°æ ‡å¿—ç€æ²‰æµ¸å¼è§†è§‰å†…å®¹åˆ›ä½œé¢†åŸŸçš„å˜é©æ€§è¿›å±•ã€‚æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–°è¿›å±•æ¨åŠ¨äº†è¯¥é¢†åŸŸçš„å¿«é€Ÿå‘å±•ã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†æ–‡æœ¬é©±åŠ¨çš„360åº¦å…¨æ™¯ç”ŸæˆæŠ€æœ¯ï¼Œæ·±å…¥åˆ†ææœ€æ–°ç®—æ³•åŠå…¶åœ¨360åº¦ä¸‰ç»´åœºæ™¯ç”Ÿæˆä¸­çš„åº”ç”¨ï¼ŒåŒæ—¶å®¡è§†äº†å½“å‰å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚ç›¸å…³èµ„æºå’Œç ”ç©¶è®ºæ–‡å¯åœ¨[<a target="_blank" rel="noopener" href="https://littlewhitesea.github.io/Text-Driven-Pano-Gen/]%E6%89%BE%E5%88%B0%E3%80%82">https://littlewhitesea.github.io/Text-Driven-Pano-Gen/]æ‰¾åˆ°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬é©±åŠ¨çš„360åº¦å…¨æ™¯ç”ŸæˆæŠ€æœ¯å®ç°äº†ä»æ–‡æœ¬æè¿°åˆ°360åº¦å…¨æ™¯å›¾åƒçš„åˆæˆï¼Œç®€åŒ–äº†å†…å®¹åˆ¶ä½œè¿‡ç¨‹ã€‚</li>
<li>è¯¥æŠ€æœ¯æ ‡å¿—ç€æ²‰æµ¸å¼è§†è§‰å†…å®¹åˆ›ä½œé¢†åŸŸçš„é‡å¤§è¿›å±•ã€‚</li>
<li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–°è¿›å±•æ¨åŠ¨äº†è¯¥é¢†åŸŸçš„å¿«é€Ÿå‘å±•ã€‚</li>
<li>æ–‡ç« å…¨é¢å›é¡¾äº†æ–‡æœ¬é©±åŠ¨çš„360åº¦å…¨æ™¯ç”ŸæˆæŠ€æœ¯ï¼ŒåŒ…æ‹¬æœ€æ–°ç®—æ³•çš„åº”ç”¨ã€‚</li>
<li>æ–‡ç« æ·±å…¥åˆ†æäº†å½“å‰æŠ€æœ¯çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</li>
<li>å¯åœ¨æŒ‡å®šç½‘ç«™æ‰¾åˆ°ç›¸å…³èµ„æºå’Œç ”ç©¶è®ºæ–‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f4a386326d1407130d2feba4d0a36731.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-512b7a417b3d6d0ec03a6a6b36057b59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44c62439542c856261aabb0aa730214c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0e6bdcba7371633f469593dba7e96e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e90436512a8a28e33dffcd5b3c0f9ec.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DiffExp-Efficient-Exploration-in-Reward-Fine-tuning-for-Text-to-Image-Diffusion-Models"><a href="#DiffExp-Efficient-Exploration-in-Reward-Fine-tuning-for-Text-to-Image-Diffusion-Models" class="headerlink" title="DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image   Diffusion Models"></a>DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image   Diffusion Models</h2><p><strong>Authors:Daewon Chae, June Suk Choi, Jinkyu Kim, Kimin Lee</strong></p>
<p>Fine-tuning text-to-image diffusion models to maximize rewards has proven effective for enhancing model performance. However, reward fine-tuning methods often suffer from slow convergence due to online sample generation. Therefore, obtaining diverse samples with strong reward signals is crucial for improving sample efficiency and overall performance. In this work, we introduce DiffExp, a simple yet effective exploration strategy for reward fine-tuning of text-to-image models. Our approach employs two key strategies: (a) dynamically adjusting the scale of classifier-free guidance to enhance sample diversity, and (b) randomly weighting phrases of the text prompt to exploit high-quality reward signals. We demonstrate that these strategies significantly enhance exploration during online sample generation, improving the sample efficiency of recent reward fine-tuning methods, such as DDPO and AlignProp. </p>
<blockquote>
<p>å¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥æœ€å¤§åŒ–å¥–åŠ±ï¼Œå·²è¢«è¯æ˜æ˜¯æé«˜æ¨¡å‹æ€§èƒ½çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äºåœ¨çº¿æ ·æœ¬ç”Ÿæˆï¼Œå¥–åŠ±å¾®è°ƒæ–¹æ³•é€šå¸¸å­˜åœ¨æ”¶æ•›ç¼“æ…¢çš„é—®é¢˜ã€‚å› æ­¤ï¼Œè·å¾—å…·æœ‰å¼ºçƒˆå¥–åŠ±ä¿¡å·çš„å¤šæ ·æ ·æœ¬å¯¹äºæé«˜æ ·æœ¬æ•ˆç‡å’Œæ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†DiffExpï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¥–åŠ±å¾®è°ƒç®€å•æœ‰æ•ˆçš„æ¢ç´¢ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ç§å…³é”®ç­–ç•¥ï¼šï¼ˆaï¼‰åŠ¨æ€è°ƒæ•´æ— åˆ†ç±»å™¨æŒ‡å¯¼çš„è§„æ¨¡ï¼Œä»¥å¢å¼ºæ ·æœ¬å¤šæ ·æ€§ï¼›ï¼ˆbï¼‰éšæœºåŠ æƒæ–‡æœ¬æç¤ºçš„çŸ­è¯­ï¼Œä»¥åˆ©ç”¨é«˜è´¨é‡çš„å¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¿™äº›ç­–ç•¥æ˜¾è‘—å¢å¼ºäº†åœ¨çº¿æ ·æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¢ç´¢èƒ½åŠ›ï¼Œæé«˜äº†è¿‘æœŸå¥–åŠ±å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚DDPOå’ŒAlignPropï¼‰çš„æ ·æœ¬æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14070v1">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¾®è°ƒä»¥æœ€å¤§åŒ–å¥–åŠ±å·²è¯æ˜å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºåœ¨çº¿æ ·æœ¬ç”Ÿæˆï¼Œå¥–åŠ±å¾®è°ƒæ–¹æ³•å¸¸å¸¸é¢ä¸´æ”¶æ•›ç¼“æ…¢çš„é—®é¢˜ã€‚å› æ­¤ï¼Œè·å¾—å…·æœ‰å¼ºçƒˆå¥–åŠ±ä¿¡å·çš„å¤šæ ·æ ·æœ¬å¯¹äºæé«˜æ ·æœ¬æ•ˆç‡å’Œæ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†DiffExpï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å¥–åŠ±å¾®è°ƒæ¢ç´¢ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ç§å…³é”®ç­–ç•¥ï¼šï¼ˆaï¼‰åŠ¨æ€è°ƒæ•´æ— åˆ†ç±»å™¨å¼•å¯¼çš„è§„æ¨¡ä»¥å¢å¼ºæ ·æœ¬å¤šæ ·æ€§ï¼Œï¼ˆbï¼‰éšæœºåŠ æƒæ–‡æœ¬æç¤ºçš„çŸ­è¯­ä»¥åˆ©ç”¨é«˜è´¨é‡çš„å¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬è¯æ˜è¿™äº›ç­–ç•¥å¯ä»¥æ˜¾è‘—æé«˜åœ¨çº¿æ ·æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¢ç´¢èƒ½åŠ›ï¼Œæé«˜è¿‘æœŸå¥–åŠ±å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚DDPOå’ŒAlignPropï¼‰çš„æ ·æœ¬æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¥–åŠ±å¾®è°ƒæ–¹æ³•å¯¹äºæé«˜æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ€§èƒ½æ˜¯æœ‰æ•ˆçš„ã€‚</li>
<li>æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¥–åŠ±å¾®è°ƒé¢ä¸´åœ¨çº¿æ ·æœ¬ç”Ÿæˆæ—¶çš„æ”¶æ•›ç¼“æ…¢é—®é¢˜ã€‚</li>
<li>è·å¾—å…·æœ‰å¼ºçƒˆå¥–åŠ±ä¿¡å·çš„å¤šæ ·æ ·æœ¬å¯¹æå‡æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>DiffExpæ˜¯ä¸€ç§é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å¥–åŠ±å¾®è°ƒçš„æœ‰æ•ˆæ¢ç´¢ç­–ç•¥ã€‚</li>
<li>DiffExpé€šè¿‡åŠ¨æ€è°ƒæ•´æ— åˆ†ç±»å™¨å¼•å¯¼è§„æ¨¡å’ŒéšæœºåŠ æƒæ–‡æœ¬æç¤ºçš„çŸ­è¯­æ¥å¢å¼ºæ ·æœ¬å¤šæ ·æ€§å’Œé«˜è´¨é‡å¥–åŠ±ä¿¡å·ã€‚</li>
<li>DiffExpæ˜¾è‘—æé«˜äº†åœ¨çº¿æ ·æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¢ç´¢èƒ½åŠ›ã€‚</li>
<li>DiffExpæé«˜äº†è¿‘æœŸå¥–åŠ±å¾®è°ƒæ–¹æ³•çš„æ ·æœ¬æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14070">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e4fcdbf7a9ec9e783da6342e602eb779.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-054ca00fb9cdf9919e9bc7717e30fcf3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5f906428dc7327be918f0b7e1b6dc75.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ef04def18c0e594663e7207ea6ca277.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a421dda9f3d0a911cd45a413ab3f73fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e22c2ccfdeb78a736d6a5b830148b0c.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="d-Sketch-Improving-Visual-Fidelity-of-Sketch-to-Image-Translation-with-Pretrained-Latent-Diffusion-Models-without-Retraining"><a href="#d-Sketch-Improving-Visual-Fidelity-of-Sketch-to-Image-Translation-with-Pretrained-Latent-Diffusion-Models-without-Retraining" class="headerlink" title="d-Sketch: Improving Visual Fidelity of Sketch-to-Image Translation with   Pretrained Latent Diffusion Models without Retraining"></a>d-Sketch: Improving Visual Fidelity of Sketch-to-Image Translation with   Pretrained Latent Diffusion Models without Retraining</h2><p><strong>Authors:Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal, Michael Blumenstein</strong></p>
<p>Structural guidance in an image-to-image translation allows intricate control over the shapes of synthesized images. Generating high-quality realistic images from user-specified rough hand-drawn sketches is one such task that aims to impose a structural constraint on the conditional generation process. While the premise is intriguing for numerous use cases of content creation and academic research, the problem becomes fundamentally challenging due to substantial ambiguities in freehand sketches. Furthermore, balancing the trade-off between shape consistency and realistic generation contributes to additional complexity in the process. Existing approaches based on Generative Adversarial Networks (GANs) generally utilize conditional GANs or GAN inversions, often requiring application-specific data and optimization objectives. The recent introduction of Denoising Diffusion Probabilistic Models (DDPMs) achieves a generational leap for low-level visual attributes in general image synthesis. However, directly retraining a large-scale diffusion model on a domain-specific subtask is often extremely difficult due to demanding computation costs and insufficient data. In this paper, we introduce a technique for sketch-to-image translation by exploiting the feature generalization capabilities of a large-scale diffusion model without retraining. In particular, we use a learnable lightweight mapping network to achieve latent feature translation from source to target domain. Experimental results demonstrate that the proposed method outperforms the existing techniques in qualitative and quantitative benchmarks, allowing high-resolution realistic image synthesis from rough hand-drawn sketches. </p>
<blockquote>
<p>åœ¨å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ä¸­ï¼Œç»“æ„æŒ‡å¯¼å…è®¸å¯¹åˆæˆå›¾åƒçš„å½¢çŠ¶è¿›è¡Œç²¾ç»†æ§åˆ¶ã€‚ä»ç”¨æˆ·æŒ‡å®šçš„ç²—ç•¥æ‰‹ç»˜è‰å›¾ç”Ÿæˆé«˜è´¨é‡é€¼çœŸå›¾åƒæ˜¯ä¸€é¡¹æ—¨åœ¨å¯¹æ¡ä»¶ç”Ÿæˆè¿‡ç¨‹æ–½åŠ ç»“æ„çº¦æŸçš„ä»»åŠ¡ã€‚è™½ç„¶è¿™ä¸€å‰æå¯¹äºå†…å®¹åˆ›å»ºå’Œå­¦æœ¯ç ”ç©¶æœ‰è®¸å¤šç”¨ä¾‹è€Œè¨€å¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†ç”±äºè‡ªç”±æ‰‹ç»˜è‰å›¾ä¸­çš„å¤§é‡æ­§ä¹‰ï¼Œè¯¥é—®é¢˜å˜å¾—å…·æœ‰æ ¹æœ¬æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œåœ¨å½¢çŠ¶ä¸€è‡´æ€§å’Œç°å®ç”Ÿæˆä¹‹é—´å–å¾—å¹³è¡¡ï¼Œä¸ºè¯¥è¿‡ç¨‹å¢åŠ äº†é¢å¤–çš„å¤æ‚æ€§ã€‚åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„ç°æœ‰æ–¹æ³•é€šå¸¸åˆ©ç”¨æ¡ä»¶GANæˆ–GANåæ¼”ï¼Œé€šå¸¸éœ€è¦ç‰¹å®šåº”ç”¨çš„æ•°æ®å’Œä¼˜åŒ–ç›®æ ‡ã€‚æœ€è¿‘å‡ºç°çš„å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMsï¼‰å®ç°äº†é€šç”¨å›¾åƒåˆæˆä¸­ä½çº§è§†è§‰å±æ€§çš„é£è·ƒã€‚ç„¶è€Œï¼Œç”±äºè®¡ç®—æˆæœ¬é«˜æ˜‚å’Œæ•°æ®ä¸è¶³ï¼Œç›´æ¥åœ¨ç‰¹å®šé¢†åŸŸçš„å­ä»»åŠ¡ä¸Šé‡æ–°è®­ç»ƒå¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹é€šå¸¸æå…¶å›°éš¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆ©ç”¨å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç‰¹æ€§æ³›åŒ–èƒ½åŠ›æ¥è¿›è¡Œè‰å›¾åˆ°å›¾åƒç¿»è¯‘çš„æŠ€æœ¯ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨å¯å­¦ä¹ çš„è½»å‹æ˜ å°„ç½‘ç»œæ¥å®ç°ä»æºåŸŸåˆ°ç›®æ ‡åŸŸçš„æ½œåœ¨ç‰¹å¾ç¿»è¯‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡åŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»ç²—ç•¥çš„æ‰‹ç»˜è‰å›¾ä¸­ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„é€¼çœŸå›¾åƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14007v1">PDF</a> Accepted in The International Conference on Pattern Recognition   (ICPR) 2024</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨å¤§å‹æ‰©æ•£æ¨¡å‹çš„ç‰¹æ€§è¿›è¡Œè‰å›¾åˆ°å›¾åƒç¿»è¯‘çš„æŠ€æœ¯ã€‚é€šè¿‡åˆ©ç”¨å¯å­¦ä¹ çš„è½»é‡åŒ–æ˜ å°„ç½‘ç»œï¼Œå®ç°äº†ä»æºåŸŸåˆ°ç›®æ ‡åŸŸçš„æ½œåœ¨ç‰¹å¾ç¿»è¯‘ï¼Œæ— éœ€åœ¨ç‰¹å®šé¢†åŸŸå­ä»»åŠ¡ä¸Šé‡æ–°è®­ç»ƒå¤§å‹æ‰©æ•£æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿä»ç²—ç³™çš„æ‰‹ç»˜è‰å›¾ä¸­ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„çœŸå®å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒåˆ°å›¾åƒç¿»è¯‘å¯ä»¥é€šè¿‡å¼•å…¥ç»“æ„æŒ‡å¯¼æ¥å®ç°å¯¹åˆæˆå›¾åƒå½¢çŠ¶çš„ç²¾ç»†æ§åˆ¶ã€‚</li>
<li>ä»ç”¨æˆ·æŒ‡å®šçš„ç²—ç•¥æ‰‹ç»˜è‰å›¾ä¸­ç”Ÿæˆé«˜è´¨é‡çœŸå®å›¾åƒæ˜¯å¯¹æ¡ä»¶ç”Ÿæˆè¿‡ç¨‹æ–½åŠ ç»“æ„çº¦æŸçš„ä¸€ä¸ªä»»åŠ¡ã€‚</li>
<li>è¯¥ä»»åŠ¡é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è‡ªç”±æ‰‹ç»˜è‰å›¾ä¸­çš„å¤§é‡æ¨¡ç³Šæ€§å’Œå¹³è¡¡å½¢çŠ¶ä¸€è‡´æ€§ä¸ç°å®ç”Ÿæˆä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ¡ä»¶GANsæˆ–GANåæ¼”ï¼Œéœ€è¦ç‰¹å®šåº”ç”¨çš„æ•°æ®å’Œä¼˜åŒ–ç›®æ ‡ã€‚</li>
<li>é™å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMsï¼‰çš„å¼•å…¥å®ç°äº†é€šç”¨å›¾åƒåˆæˆä¸­ä½çº§è§†è§‰å±æ€§çš„é£è·ƒã€‚</li>
<li>ç›´æ¥åœ¨ç‰¹å®šé¢†åŸŸçš„å­ä»»åŠ¡ä¸Šé‡æ–°è®­ç»ƒå¤§å‹æ‰©æ•£æ¨¡å‹é¢ä¸´è®¡ç®—æˆæœ¬é«˜å’Œæ•°æ®ä¸è¶³çš„æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14007">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6e14ab397fa2f7f99f63a35233331de7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c72a4687c2ce6dfeaa7d819eab4c6fb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc3e212c997f0ef96c17da1a1b8b8ff7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SigStyle-Signature-Style-Transfer-via-Personalized-Text-to-Image-Models"><a href="#SigStyle-Signature-Style-Transfer-via-Personalized-Text-to-Image-Models" class="headerlink" title="SigStyle: Signature Style Transfer via Personalized Text-to-Image Models"></a>SigStyle: Signature Style Transfer via Personalized Text-to-Image Models</h2><p><strong>Authors:Ye Wang, Tongyuan Bai, Xuping Xie, Zili Yi, Yilin Wang, Rui Ma</strong></p>
<p>Style transfer enables the seamless integration of artistic styles from a style image into a content image, resulting in visually striking and aesthetically enriched outputs. Despite numerous advances in this field, existing methods did not explicitly focus on the signature style, which represents the distinct and recognizable visual traits of the image such as geometric and structural patterns, color palettes and brush strokes etc. In this paper, we introduce SigStyle, a framework that leverages the semantic priors that embedded in a personalized text-to-image diffusion model to capture the signature style representation. This style capture process is powered by a hypernetwork that efficiently fine-tunes the diffusion model for any given single style image. Style transfer then is conceptualized as the reconstruction process of content image through learned style tokens from the personalized diffusion model. Additionally, to ensure the content consistency throughout the style transfer process, we introduce a time-aware attention swapping technique that incorporates content information from the original image into the early denoising steps of target image generation. Beyond enabling high-quality signature style transfer across a wide range of styles, SigStyle supports multiple interesting applications, such as local style transfer, texture transfer, style fusion and style-guided text-to-image generation. Quantitative and qualitative evaluations demonstrate our approach outperforms existing style transfer methods for recognizing and transferring the signature styles. </p>
<blockquote>
<p>é£æ ¼è½¬æ¢æŠ€æœ¯èƒ½å¤Ÿå®ç°å°†é£æ ¼å›¾åƒä¸­çš„è‰ºæœ¯é£æ ¼æ— ç¼é›†æˆåˆ°å†…å®¹å›¾åƒä¸­ï¼Œä»è€Œç”Ÿæˆè§†è§‰å†²å‡»åŠ›å¼ºä¸”å®¡ç¾ä¸°å¯Œçš„è¾“å‡ºã€‚å°½ç®¡æ­¤é¢†åŸŸå·²ç»æœ‰å¾ˆå¤šè¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•å¹¶æ²¡æœ‰æ˜ç¡®å…³æ³¨ç­¾åé£æ ¼ï¼Œç­¾åé£æ ¼ä»£è¡¨äº†å›¾åƒçš„ç‹¬ç‰¹ä¸”å¯è¯†åˆ«çš„è§†è§‰ç‰¹å¾ï¼Œå¦‚å‡ ä½•å’Œç»“æ„å›¾æ¡ˆã€è‰²å½©æ­é…å’Œç¬”è§¦ç­‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SigStyleæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨åµŒå…¥åœ¨ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è¯­ä¹‰å…ˆéªŒçŸ¥è¯†æ¥æ•æ‰ç­¾åé£æ ¼è¡¨ç¤ºã€‚è¿™ç§é£æ ¼æ•æ‰è¿‡ç¨‹ç”±è¶…ç½‘ç»œé©±åŠ¨ï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿé’ˆå¯¹ç»™å®šçš„ä»»ä½•å•ä¸ªé£æ ¼å›¾åƒé«˜æ•ˆåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ã€‚é£æ ¼è½¬æ¢è¢«æ¦‚å¿µåŒ–ä¸ºé€šè¿‡ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹ä¸­å­¦åˆ°çš„é£æ ¼æ ‡è®°å¯¹å†…å®¹å›¾åƒè¿›è¡Œé‡å»ºçš„è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç¡®ä¿åœ¨æ•´ä¸ªé£æ ¼è½¬æ¢è¿‡ç¨‹ä¸­å†…å®¹çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ—¶é—´æ„ŸçŸ¥æ³¨æ„åŠ›äº¤æ¢æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†åŸå§‹å›¾åƒçš„å†…å®¹ä¿¡æ¯èå…¥åˆ°ç›®æ ‡å›¾åƒç”Ÿæˆæ—©æœŸçš„å»å™ªæ­¥éª¤ä¸­ã€‚é™¤äº†å®ç°é«˜è´¨é‡ç­¾åé£æ ¼è½¬æ¢ï¼Œè¦†ç›–å„ç§é£æ ¼å¤–ï¼ŒSigStyleè¿˜æ”¯æŒå¤šç§æœ‰è¶£çš„åº”ç”¨ï¼Œå¦‚å±€éƒ¨é£æ ¼è½¬æ¢ã€çº¹ç†è½¬æ¢ã€é£æ ¼èåˆå’Œé£æ ¼æŒ‡å¯¼çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¯†åˆ«å’Œè½¬æ¢ç­¾åé£æ ¼æ–¹é¢ä¼˜äºç°æœ‰çš„é£æ ¼è½¬æ¢æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13997v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSigStyleçš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨åµŒå…¥åœ¨ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è¯­ä¹‰å…ˆéªŒæ¥æ•æ‰ä»£è¡¨å›¾åƒç‹¬ç‰¹å¯è¯†åˆ«ç‰¹å¾çš„ç­¾åé£æ ¼ã€‚é€šè¿‡è¶…ç½‘ç»œé«˜æ•ˆå¾®è°ƒç»™å®šå•ä¸€é£æ ¼å›¾åƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é£æ ¼æ•æ‰ã€‚é£æ ¼è½¬ç§»è¢«æ¦‚å¿µåŒ–ä¸ºé€šè¿‡ä»ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹ä¸­å­¦ä¹ çš„é£æ ¼ä»¤ç‰Œé‡å»ºå†…å®¹å›¾åƒçš„è¿‡ç¨‹ã€‚ä¸ºç¡®ä¿é£æ ¼è½¬ç§»è¿‡ç¨‹ä¸­å†…å®¹çš„ä¸€è‡´æ€§ï¼Œå¼•å…¥äº†æ—¶é—´æ„ŸçŸ¥æ³¨æ„åŠ›äº¤æ¢æŠ€æœ¯ï¼Œå°†åŸå§‹å›¾åƒçš„å†…å®¹ä¿¡æ¯èå…¥ç›®æ ‡å›¾åƒç”Ÿæˆçš„æ—©æœŸå»å™ªæ­¥éª¤ã€‚SigStyleä¸ä»…å®ç°äº†é«˜è´¨é‡ç­¾åé£æ ¼çš„è·¨é£æ ¼è½¬ç§»ï¼Œè¿˜æ”¯æŒå±€éƒ¨é£æ ¼è½¬ç§»ã€çº¹ç†è½¬ç§»ã€é£æ ¼èåˆå’Œé£æ ¼æŒ‡å¯¼çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç­‰å¤šç§æœ‰è¶£åº”ç”¨ï¼Œä¸”è¾ƒç°æœ‰é£æ ¼è½¬ç§»æ–¹æ³•åœ¨è¯†åˆ«å’Œè½¬ç§»ç­¾åé£æ ¼æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SigStyleæ¡†æ¶åˆ©ç”¨ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è¯­ä¹‰å…ˆéªŒæ•æ‰ç­¾åé£æ ¼ã€‚</li>
<li>é€šè¿‡è¶…ç½‘ç»œé«˜æ•ˆå¾®è°ƒæ‰©æ•£æ¨¡å‹ä»¥é€‚é…å•ä¸€é£æ ¼å›¾åƒã€‚</li>
<li>é£æ ¼è½¬ç§»è¢«é‡æ–°å®šä¹‰ä¸ºé€šè¿‡å­¦åˆ°çš„é£æ ¼ä»¤ç‰Œä»ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹ä¸­é‡å»ºå†…å®¹å›¾åƒçš„è¿‡ç¨‹ã€‚</li>
<li>å¼•å…¥æ—¶é—´æ„ŸçŸ¥æ³¨æ„åŠ›äº¤æ¢æŠ€æœ¯ï¼Œç¡®ä¿é£æ ¼è½¬ç§»è¿‡ç¨‹ä¸­å†…å®¹çš„ä¸€è‡´æ€§ã€‚</li>
<li>SigStyleæ”¯æŒå¤šç§åº”ç”¨ï¼ŒåŒ…æ‹¬å±€éƒ¨é£æ ¼è½¬ç§»ã€çº¹ç†è½¬ç§»ã€é£æ ¼èåˆå’Œé£æ ¼æŒ‡å¯¼çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚</li>
<li>SigStyleåœ¨è¯†åˆ«å’Œè½¬ç§»ç­¾åé£æ ¼æ–¹é¢è¾ƒç°æœ‰æ–¹æ³•è¡¨ç°æ›´ä¼˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13997">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f0418eef9849ddc6da3d714159a4f77f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-03aecf7c4dc6566834a3231634875903.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d7929144067828d93c4db4c2d4cadd4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28ae58667534dadd1e9bae659416df88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebafc3f2debb5dd8f77f9c2eaaa8bc6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c385b5cd09f80029178b3f906a92604.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d598764dead8198cbbd3e84ec1fb4c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7de4dab868f19beae850e670579ec96.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SelfAge-Personalized-Facial-Age-Transformation-Using-Self-reference-Images"><a href="#SelfAge-Personalized-Facial-Age-Transformation-Using-Self-reference-Images" class="headerlink" title="SelfAge: Personalized Facial Age Transformation Using Self-reference   Images"></a>SelfAge: Personalized Facial Age Transformation Using Self-reference   Images</h2><p><strong>Authors:Taishi Ito, Yuki Endo, Yoshihiro Kanamori</strong></p>
<p>Age transformation of facial images is a technique that edits age-related personâ€™s appearances while preserving the identity. Existing deep learning-based methods can reproduce natural age transformations; however, they only reproduce averaged transitions and fail to account for individual-specific appearances influenced by their life histories. In this paper, we propose the first diffusion model-based method for personalized age transformation. Our diffusion model takes a facial image and a target age as input and generates an age-edited face image as output. To reflect individual-specific features, we incorporate additional supervision using self-reference images, which are facial images of the same person at different ages. Specifically, we fine-tune a pretrained diffusion model for personalized adaptation using approximately 3 to 5 self-reference images. Additionally, we design an effective prompt to enhance the performance of age editing and identity preservation. Experiments demonstrate that our method achieves superior performance both quantitatively and qualitatively compared to existing methods. The code and the pretrained model are available at <a target="_blank" rel="noopener" href="https://github.com/shiiiijp/SelfAge">https://github.com/shiiiijp/SelfAge</a>. </p>
<blockquote>
<p>é¢éƒ¨å›¾åƒçš„å¹´é¾„å˜æ¢æ˜¯ä¸€ç§ç¼–è¾‘ä¸å¹´é¾„ç›¸å…³çš„äººè„¸å¤–è§‚åŒæ—¶ä¿ç•™èº«ä»½ç‰¹å¾çš„æŠ€æœ¯ã€‚ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•å¯ä»¥å¤åˆ¶è‡ªç„¶çš„å¹´é¾„å˜æ¢ï¼Œä½†å®ƒä»¬åªå¤åˆ¶å¹³å‡è¿‡æ¸¡ï¼Œå¿½ç•¥äº†å—ä¸ªäººç”Ÿæ´»å²å½±å“ä¸ªä½“ç‰¹å®šçš„å¤–è§‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ‰©æ•£æ¨¡å‹çš„é¦–ä¸ªä¸ªæ€§åŒ–å¹´é¾„å˜æ¢æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ‰©æ•£æ¨¡å‹ä»¥é¢éƒ¨å›¾åƒå’Œç›®æ ‡å¹´é¾„ä¸ºè¾“å…¥ï¼Œç”Ÿæˆå¹´é¾„ç¼–è¾‘åçš„é¢éƒ¨å›¾åƒä½œä¸ºè¾“å‡ºã€‚ä¸ºäº†åæ˜ ä¸ªä½“ç‰¹å®šçš„ç‰¹å¾ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå‚è€ƒå›¾åƒï¼ˆå³åŒä¸€äººåœ¨ä¸åŒå¹´é¾„é˜¶æ®µçš„é¢éƒ¨å›¾åƒï¼‰å¢åŠ é¢å¤–çš„ç›‘ç£ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤§çº¦3åˆ°5å¼ è‡ªå‚è€ƒå›¾åƒå¯¹é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°ä¸ªæ€§åŒ–é€‚åº”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆçš„æç¤ºæ¥å¢å¼ºå¹´é¾„ç¼–è¾‘å’Œèº«ä»½ä¿ç•™çš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/shiiiijp/SelfAge">https://github.com/shiiiijp/SelfAge</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13987v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¸ªæ€§åŒ–å¹´é¾„è½¬æ¢æ–¹æ³•ã€‚è¯¥æŠ€æœ¯é‡‡ç”¨é¢éƒ¨å›¾åƒå’Œç›®æ ‡å¹´é¾„ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆç»è¿‡å¹´é¾„ç¼–è¾‘çš„é¢éƒ¨å›¾åƒä½œä¸ºè¾“å‡ºã€‚é€šè¿‡é‡‡ç”¨è‡ªæˆ‘å‚ç…§å›¾åƒè¿›è¡Œé¢å¤–ç›‘ç£ï¼Œåæ˜ ä¸ªäººç‰¹å®šç‰¹å¾ã€‚ä½¿ç”¨å¤§çº¦3åˆ°5å¼ è‡ªæˆ‘å‚ç…§å›¾åƒå¯¹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°ä¸ªæ€§åŒ–é€‚åº”ã€‚è®¾è®¡æœ‰æ•ˆæç¤ºä»¥å¢å¼ºå¹´é¾„ç¼–è¾‘å’Œèº«ä»½ä¿ç•™çš„æ€§èƒ½ã€‚ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢å‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹è¢«é¦–æ¬¡åº”ç”¨äºä¸ªæ€§åŒ–å¹´é¾„è½¬æ¢ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨é¢éƒ¨å›¾åƒå’Œç›®æ ‡å¹´é¾„ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºç»è¿‡å¹´é¾„ç¼–è¾‘çš„é¢éƒ¨å›¾åƒã€‚</li>
<li>é€šè¿‡è‡ªæˆ‘å‚ç…§å›¾åƒè¿›è¡Œé¢å¤–ç›‘ç£ï¼Œä»¥ä½“ç°ä¸ªäººç‰¹å®šç‰¹å¾ã€‚</li>
<li>ä½¿ç”¨å¤§çº¦3åˆ°5å¼ è‡ªæˆ‘å‚ç…§å›¾åƒå¯¹é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°ä¸ªæ€§åŒ–é€‚åº”ã€‚</li>
<li>è®¾è®¡äº†æœ‰æ•ˆæç¤ºä»¥å¢å¼ºå¹´é¾„ç¼–è¾‘å’Œèº«ä»½ä¿ç•™çš„æ•ˆæœã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸Šå‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13987">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-529ed1cb2723b49670d45b6e3b7c4ed3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0219fbef4407a33e45335900b38c1a85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afdc44a50f0688bd442761239401fcab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f075dfd35a1d9539e801ab1ccbee61db.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Compression-Aware-One-Step-Diffusion-Model-for-JPEG-Artifact-Removal"><a href="#Compression-Aware-One-Step-Diffusion-Model-for-JPEG-Artifact-Removal" class="headerlink" title="Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal"></a>Compression-Aware One-Step Diffusion Model for JPEG Artifact Removal</h2><p><strong>Authors:Jinpei Guo, Zheng Chen, Wenbo Li, Yong Guo, Yulun Zhang</strong></p>
<p>Diffusion models have demonstrated remarkable success in image restoration tasks. However, their multi-step denoising process introduces significant computational overhead, limiting their practical deployment. Furthermore, existing methods struggle to effectively remove severe JPEG artifact, especially in highly compressed images. To address these challenges, we propose CODiff, a compression-aware one-step diffusion model for JPEG artifact removal. The core of CODiff is the compression-aware visual embedder (CaVE), which extracts and leverages JPEG compression priors to guide the diffusion model. We propose a dual learning strategy that combines explicit and implicit learning. Specifically, explicit learning enforces a quality prediction objective to differentiate low-quality images with different compression levels. Implicit learning employs a reconstruction objective that enhances the modelâ€™s generalization. This dual learning allows for a deeper and more comprehensive understanding of JPEG compression. Experimental results demonstrate that CODiff surpasses recent leading methods in both quantitative and visual quality metrics. The code and models will be released at <a target="_blank" rel="noopener" href="https://github.com/jp-guo/CODiff">https://github.com/jp-guo/CODiff</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒæ¢å¤ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œå…¶å¤šæ­¥éª¤å»å™ªè¿‡ç¨‹å¸¦æ¥äº†è¾ƒå¤§çš„è®¡ç®—å¼€é”€ï¼Œé™åˆ¶äº†å…¶å®é™…éƒ¨ç½²çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå»é™¤ä¸¥é‡çš„JPEGå‹ç¼©ä¼ªå½±ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åº¦å‹ç¼©çš„å›¾åƒä¸­ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†CODiffï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºJPEGä¼ªå½±å»é™¤çš„å‹ç¼©æ„ŸçŸ¥ä¸€æ­¥æ‰©æ•£æ¨¡å‹ã€‚CODiffçš„æ ¸å¿ƒæ˜¯å‹ç¼©æ„ŸçŸ¥è§†è§‰åµŒå…¥å™¨ï¼ˆCaVEï¼‰ï¼Œå®ƒæå–å¹¶åˆ©ç”¨JPEGå‹ç¼©å…ˆéªŒæ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆæ˜¾å¼å­¦ä¹ å’Œéšå¼å­¦ä¹ çš„åŒé‡å­¦ä¹ ç­–ç•¥ã€‚å…·ä½“æ¥è¯´ï¼Œæ˜¾å¼å­¦ä¹ é€šè¿‡å®æ–½è´¨é‡é¢„æµ‹ç›®æ ‡æ¥åŒºåˆ†ä¸åŒå‹ç¼©æ°´å¹³çš„ä½è´¨é‡å›¾åƒã€‚éšå¼å­¦ä¹ é‡‡ç”¨é‡å»ºç›®æ ‡ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§åŒé‡å­¦ä¹ å¯ä»¥æ›´æ·±å…¥ã€æ›´å…¨é¢åœ°ç†è§£JPEGå‹ç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCODiffåœ¨å®šé‡å’Œè§†è§‰è´¨é‡æŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†æœ€æ–°çš„å…ˆè¿›æ–¹æ³•ã€‚ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/jp-guo/CODiff%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/jp-guo/CODiffä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.09873v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å…¶å¤šæ­¥å»å™ªè¿‡ç¨‹å¸¦æ¥äº†è¾ƒå¤§çš„è®¡ç®—å¼€é”€ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚é’ˆå¯¹æ­¤åŠç°æœ‰æ–¹æ³•å¯¹ä¸¥é‡JPEGä¼ªå½±å»é™¤çš„å›°éš¾ï¼Œæˆ‘ä»¬æå‡ºäº†CODiffï¼Œä¸€ç§æ„ŸçŸ¥å‹ç¼©çš„ä¸€æ­¥æ‰©æ•£æ¨¡å‹ã€‚CODiffçš„æ ¸å¿ƒæ˜¯å‹ç¼©æ„ŸçŸ¥è§†è§‰åµŒå…¥å™¨ï¼ˆCaVEï¼‰ï¼Œå®ƒæå–å¹¶åˆ©ç”¨JPEGå‹ç¼©å…ˆéªŒæ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§ç»“åˆæ˜¾å¼å­¦ä¹ å’Œéšå¼å­¦ä¹ çš„åŒé‡å­¦ä¹ ç­–ç•¥ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒCODiffåœ¨å®šé‡å’Œè§†è§‰è´¨é‡æŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†ç°æœ‰é¢†å…ˆæ–¹æ³•ã€‚ç›¸å…³ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/jp-guo/CODiff%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/jp-guo/CODiffå‘å¸ƒã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†è®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå»é™¤ä¸¥é‡JPEGä¼ªå½±ï¼Œå°¤å…¶æ˜¯åœ¨é«˜åº¦å‹ç¼©çš„å›¾åƒä¸­ã€‚</li>
<li>CODiffæ˜¯ä¸€ç§æ„ŸçŸ¥å‹ç¼©çš„ä¸€æ­¥æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>CODiffçš„æ ¸å¿ƒæ˜¯å‹ç¼©æ„ŸçŸ¥è§†è§‰åµŒå…¥å™¨ï¼ˆCaVEï¼‰ï¼Œåˆ©ç”¨JPEGå‹ç¼©å…ˆéªŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨æ˜¾å¼å­¦ä¹ å’Œéšå¼å­¦ä¹ ç›¸ç»“åˆçš„åŒå­¦ä¹ ç­–ç•¥ï¼Œæé«˜æ¨¡å‹å¯¹JPEGå‹ç¼©çš„æ·±å…¥ç†è§£ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCODiffåœ¨å®šé‡å’Œè§†è§‰è´¨é‡æŒ‡æ ‡ä¸Šå‡è¶…è¶Šç°æœ‰é¢†å…ˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.09873">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-849ecde17a919d06b1adcc4432756451.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d32f562cdd63e561076e85fcc07d65a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34469b00ee587ed56dea382c840f8edd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a0dd8e954813b8248ce62e19205bf74.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91d46780117c2bd14789373d3334fc99.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Conditional-diffusion-model-with-spatial-attention-and-latent-embedding-for-medical-image-segmentation"><a href="#Conditional-diffusion-model-with-spatial-attention-and-latent-embedding-for-medical-image-segmentation" class="headerlink" title="Conditional diffusion model with spatial attention and latent embedding   for medical image segmentation"></a>Conditional diffusion model with spatial attention and latent embedding   for medical image segmentation</h2><p><strong>Authors:Behzad Hejrati, Soumyanil Banerjee, Carri Glide-Hurst, Ming Dong</strong></p>
<p>Diffusion models have been used extensively for high quality image and video generation tasks. In this paper, we propose a novel conditional diffusion model with spatial attention and latent embedding (cDAL) for medical image segmentation. In cDAL, a convolutional neural network (CNN) based discriminator is used at every time-step of the diffusion process to distinguish between the generated labels and the real ones. A spatial attention map is computed based on the features learned by the discriminator to help cDAL generate more accurate segmentation of discriminative regions in an input image. Additionally, we incorporated a random latent embedding into each layer of our model to significantly reduce the number of training and sampling time-steps, thereby making it much faster than other diffusion models for image segmentation. We applied cDAL on 3 publicly available medical image segmentation datasets (MoNuSeg, Chest X-ray and Hippocampus) and observed significant qualitative and quantitative improvements with higher Dice scores and mIoU over the state-of-the-art algorithms. The source code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/Hejrati/cDAL/">https://github.com/Hejrati/cDAL/</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹å·²è¢«å¹¿æ³›åº”ç”¨äºé«˜è´¨é‡å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰ç©ºé—´æ³¨æ„åŠ›å’Œæ½œåœ¨åµŒå…¥ï¼ˆcDALï¼‰çš„æ–°å‹æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ã€‚åœ¨cDALä¸­ï¼Œæ‰©æ•£è¿‡ç¨‹çš„æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä½¿ç”¨åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„åˆ¤åˆ«å™¨æ¥åŒºåˆ†ç”Ÿæˆçš„æ ‡ç­¾å’ŒçœŸå®çš„æ ‡ç­¾ã€‚åŸºäºåˆ¤åˆ«å™¨å­¦ä¹ çš„ç‰¹å¾è®¡ç®—ç©ºé—´æ³¨æ„åŠ›å›¾ï¼Œå¸®åŠ©cDALç”Ÿæˆè¾“å…¥å›¾åƒä¸­åˆ¤åˆ«åŒºåŸŸçš„æ›´å‡†ç¡®åˆ†å‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†éšæœºæ½œåœ¨åµŒå…¥èå…¥æ¨¡å‹ä¸­çš„æ¯ä¸€å±‚ï¼Œä»¥å¤§å¤§å‡å°‘è®­ç»ƒå’Œé‡‡æ ·æ—¶é—´æ­¥çš„æ•°é‡ï¼Œä»è€Œä½¿å®ƒæ¯”å…¶ä»–ç”¨äºå›¾åƒåˆ†å‰²çš„æ‰©æ•£æ¨¡å‹æ›´å¿«ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…¬å¼€çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ï¼ˆMoNuSegã€Chest X-rayå’ŒHippocampusï¼‰ä¸Šåº”ç”¨äº†cDALï¼Œå¹¶åœ¨æœ€å…ˆè¿›çš„ç®—æ³•ä¸Šè§‚å¯Ÿåˆ°æ˜¾è‘—çš„å®šæ€§å’Œå®šé‡æ”¹è¿›ï¼Œå…·æœ‰æ›´é«˜çš„Diceåˆ†æ•°å’ŒmIoUã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Hejrati/cDAL/%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Hejrati/cDAL/å…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06997v2">PDF</a> 13 pages, 5 figures, 3 tables, Accepted in MICCAI 2024</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹cDALï¼Œç»“åˆäº†ç©ºé—´æ³¨æ„åŠ›å’Œæ½œåœ¨åµŒå…¥ï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ã€‚cDALåœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤ä¸­ä½¿ç”¨åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„é‰´åˆ«å™¨ï¼Œä»¥åŒºåˆ†ç”Ÿæˆçš„æ ‡ç­¾å’ŒçœŸå®æ ‡ç­¾ã€‚é€šè¿‡è®¡ç®—åŸºäºé‰´åˆ«å™¨å­¦ä¹ çš„ç‰¹å¾çš„ç©ºé—´æ³¨æ„åŠ›å›¾ï¼ŒcDALèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç”Ÿæˆè¾“å…¥å›¾åƒä¸­çš„åˆ¤åˆ«åŒºåŸŸçš„åˆ†å‰²ã€‚æ­¤å¤–ï¼Œæ¨¡å‹ä¸­è¿˜èå…¥äº†éšæœºæ½œåœ¨åµŒå…¥ï¼Œæ˜¾è‘—å‡å°‘äº†è®­ç»ƒå’Œé‡‡æ ·çš„æ—¶é—´æ­¥éª¤ï¼Œä½¿å…¶ç›¸è¾ƒäºå…¶ä»–å›¾åƒåˆ†å‰²çš„æ‰©æ•£æ¨¡å‹æ›´åŠ å¿«é€Ÿã€‚åœ¨ä¸‰ä¸ªå…¬å¼€çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ä¸Šåº”ç”¨cDALï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„ç®—æ³•ï¼Œè·å¾—äº†æ›´é«˜çš„Diceåˆ†æ•°å’ŒmIoUï¼Œå–å¾—äº†æ˜¾è‘—çš„è´¨é‡å’Œæ•°é‡ä¸Šçš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†æ–°å‹æ¡ä»¶æ‰©æ•£æ¨¡å‹cDALç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œç»“åˆäº†ç©ºé—´æ³¨æ„åŠ›å’Œæ½œåœ¨åµŒå…¥æŠ€æœ¯ã€‚</li>
<li>ä½¿ç”¨CNNé‰´åˆ«å™¨åœ¨æ‰©æ•£è¿‡ç¨‹çš„æ¯ä¸ªæ­¥éª¤ä¸­è¿›è¡ŒçœŸå®ä¸ç”Ÿæˆæ ‡ç­¾çš„åŒºåˆ†ã€‚</li>
<li>ç©ºé—´æ³¨æ„åŠ›å›¾å¸®åŠ©cDALæ›´å‡†ç¡®åœ°ç”Ÿæˆè¾“å…¥å›¾åƒä¸­çš„åˆ¤åˆ«åŒºåŸŸåˆ†å‰²ã€‚</li>
<li>èå…¥éšæœºæ½œåœ¨åµŒå…¥ï¼Œå‡å°‘è®­ç»ƒå’Œé‡‡æ ·æ—¶é—´æ­¥éª¤ï¼Œæé«˜æ¨¡å‹æ•ˆç‡ã€‚</li>
<li>åœ¨ä¸‰ä¸ªåŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ä¸Šåº”ç”¨cDALï¼Œè·å¾—è¾ƒé«˜çš„Diceåˆ†æ•°å’ŒmIoUã€‚</li>
<li>cDALç›¸è¾ƒäºå…¶ä»–å›¾åƒåˆ†å‰²çš„æ‰©æ•£æ¨¡å‹æ›´åŠ å¿«é€Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06997">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-69d3b4fed0d242f0ec8d4a7984619fda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a77ce743221a1e323f776121fce2cc5.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="T2ISafety-Benchmark-for-Assessing-Fairness-Toxicity-and-Privacy-in-Image-Generation"><a href="#T2ISafety-Benchmark-for-Assessing-Fairness-Toxicity-and-Privacy-in-Image-Generation" class="headerlink" title="T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in   Image Generation"></a>T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in   Image Generation</h2><p><strong>Authors:Lijun Li, Zhelun Shi, Xuhao Hu, Bowen Dong, Yiran Qin, Xihui Liu, Lu Sheng, Jing Shao</strong></p>
<p>Text-to-image (T2I) models have rapidly advanced, enabling the generation of high-quality images from text prompts across various domains. However, these models present notable safety concerns, including the risk of generating harmful, biased, or private content. Current research on assessing T2I safety remains in its early stages. While some efforts have been made to evaluate models on specific safety dimensions, many critical risks remain unexplored. To address this gap, we introduce T2ISafety, a safety benchmark that evaluates T2I models across three key domains: toxicity, fairness, and bias. We build a detailed hierarchy of 12 tasks and 44 categories based on these three domains, and meticulously collect 70K corresponding prompts. Based on this taxonomy and prompt set, we build a large-scale T2I dataset with 68K manually annotated images and train an evaluator capable of detecting critical risks that previous work has failed to identify, including risks that even ultra-large proprietary models like GPTs cannot correctly detect. We evaluate 12 prominent diffusion models on T2ISafety and reveal several concerns including persistent issues with racial fairness, a tendency to generate toxic content, and significant variation in privacy protection across the models, even with defense methods like concept erasing. Data and evaluator are released under <a target="_blank" rel="noopener" href="https://github.com/adwardlee/t2i_safety">https://github.com/adwardlee/t2i_safety</a>. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹å·²å¾—åˆ°è¿…é€Ÿå‘å±•ï¼Œèƒ½å¤Ÿåœ¨å„ä¸ªé¢†åŸŸæ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¹Ÿå¼•å‘äº†æ˜¾è‘—çš„å®‰å…¨æ‹…å¿§ï¼ŒåŒ…æ‹¬ç”Ÿæˆæœ‰å®³ã€åå‘æˆ–ç§å¯†å†…å®¹çš„é£é™©ã€‚å½“å‰å¯¹T2Iå®‰å…¨æ€§çš„è¯„ä¼°ç ”ç©¶ä»å¤„äºæ—©æœŸé˜¶æ®µã€‚è™½ç„¶å·²æœ‰ä¸€äº›åŠªåŠ›åœ¨ç‰¹å®šå®‰å…¨ç»´åº¦ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œä½†è®¸å¤šå…³é”®é£é™©ä»æœªè¢«æ¢ç´¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†T2ISafetyï¼Œè¿™æ˜¯ä¸€ä¸ªå®‰å…¨åŸºå‡†ï¼Œç”¨äºè¯„ä¼°T2Iæ¨¡å‹åœ¨ä¸‰ä¸ªå…³é”®é¢†åŸŸçš„è¡¨ç°ï¼šæ¯’æ€§ã€å…¬å¹³æ€§å’Œåè§ã€‚æˆ‘ä»¬åŸºäºè¿™ä¸‰ä¸ªé¢†åŸŸæ„å»ºäº†12é¡¹ä»»åŠ¡å’Œ44ä¸ªç±»åˆ«çš„è¯¦ç»†å±‚æ¬¡ç»“æ„ï¼Œå¹¶ç²¾å¿ƒæ”¶é›†äº†7ä¸‡é¡¹ç›¸åº”çš„æç¤ºã€‚åŸºäºè¿™ä¸ªåˆ†ç±»å’Œæç¤ºé›†ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„T2Iæ•°æ®é›†ï¼ŒåŒ…å«6.8ä¸‡å¼ æ‰‹åŠ¨æ³¨é‡Šçš„å›¾åƒï¼Œå¹¶è®­ç»ƒäº†ä¸€ä¸ªèƒ½å¤Ÿæ£€æµ‹å‡ºä»¥å‰çš„å·¥ä½œæœªèƒ½è¯†åˆ«å‡ºçš„å…³é”®é£é™©çš„è¯„ä¼°å™¨ï¼ŒåŒ…æ‹¬å¤§å‹ä¸“æœ‰æ¨¡å‹å¦‚GPTæ— æ³•æ­£ç¡®æ£€æµ‹åˆ°çš„é£é™©ã€‚æˆ‘ä»¬åœ¨T2ISafetyä¸Šè¯„ä¼°äº†12ä¸ªæµè¡Œçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶æ­ç¤ºäº†åŒ…æ‹¬ç§æ—å…¬å¹³æ–¹é¢çš„æŒç»­é—®é¢˜ã€ç”Ÿæˆæœ‰æ¯’å†…å®¹çš„å€¾å‘ä»¥åŠæ¨¡å‹é—´éšç§ä¿æŠ¤çš„æ˜¾è‘—å·®å¼‚ç­‰æ‹…å¿§ï¼Œå³ä½¿é‡‡ç”¨æ¦‚å¿µæ¶ˆé™¤ç­‰é˜²å¾¡æ–¹æ³•ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ•°æ®å’Œè¯„ä¼°å™¨å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/adwardlee/t2i_safety%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/adwardlee/t2i_safetyä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12612v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œä½†åœ¨å®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—é—®é¢˜ï¼ŒåŒ…æ‹¬ç”Ÿæˆæœ‰å®³ã€åè§æˆ–ç§äººå†…å®¹çš„é£é™©ã€‚å½“å‰å¯¹T2Iå®‰å…¨æ€§çš„è¯„ä¼°ç ”ç©¶ä»å¤„äºæ—©æœŸé˜¶æ®µï¼Œè®¸å¤šå…³é”®é£é™©å°šæœªè¢«æ¢ç´¢ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥T2ISafetyå®‰å…¨åŸºå‡†ï¼Œå¯¹æ¯’æ€§ã€å…¬å¹³æ€§å’Œåè§ä¸‰ä¸ªå…³é”®é¢†åŸŸè¿›è¡ŒT2Iæ¨¡å‹è¯„ä¼°ã€‚å»ºç«‹åŸºäºè¿™äº›é¢†åŸŸçš„è¯¦ç»†å±‚æ¬¡ç»“æ„å’Œä»»åŠ¡ç±»åˆ«ï¼Œå¹¶æ”¶é›†ç›¸åº”çš„æç¤ºã€‚åŸºäºæ­¤åˆ†ç±»å’Œæç¤ºé›†ï¼Œå»ºç«‹å¤§è§„æ¨¡T2Iæ•°æ®é›†ï¼Œè®­ç»ƒè¯„ä¼°å™¨ä»¥æ£€æµ‹å…ˆå‰å·¥ä½œæœªèƒ½è¯†åˆ«çš„å…³é”®é£é™©ã€‚å¯¹12ä¸ªæµè¡Œçš„æ‰©æ•£æ¨¡å‹è¿›è¡ŒT2ISafetyè¯„ä¼°ï¼Œå¹¶æ­ç¤ºäº†åŒ…æ‹¬ç§æ—å…¬å¹³é—®é¢˜ã€ç”Ÿæˆæœ‰æ¯’å†…å®¹çš„å€¾å‘ä»¥åŠæ¨¡å‹é—´éšç§ä¿æŠ¤æ–¹é¢çš„æ˜¾è‘—å·®å¼‚ç­‰å‡ ä¸ªé—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>T2Iæ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—å¿«é€Ÿè¿›å±•ï¼Œä½†å­˜åœ¨æ˜¾è‘—çš„å®‰å…¨æ€§é—®é¢˜ã€‚</li>
<li>å½“å‰å¯¹T2Iæ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°ç ”ç©¶ä»å¤„äºæ—©æœŸé˜¶æ®µï¼Œè®¸å¤šå…³é”®é£é™©å°šæœªè¢«æ¢ç´¢ã€‚</li>
<li>å¼•å…¥T2ISafetyå®‰å…¨åŸºå‡†ï¼Œç”¨äºè¯„ä¼°T2Iæ¨¡å‹åœ¨æ¯’æ€§ã€å…¬å¹³æ€§å’Œåè§ä¸‰ä¸ªå…³é”®é¢†åŸŸçš„å®‰å…¨æ€§ã€‚</li>
<li>å»ºç«‹äº†ä¸€ä¸ªè¯¦ç»†çš„å±‚æ¬¡ç»“æ„ï¼ŒåŒ…æ‹¬12ä¸ªä»»åŠ¡å’Œ44ä¸ªç±»åˆ«ï¼Œå¹¶æ”¶é›†äº†70Kç›¸åº”çš„æç¤ºã€‚</li>
<li>åŸºäºæ­¤åˆ†ç±»å’Œæç¤ºé›†ï¼Œå»ºç«‹äº†å¤§è§„æ¨¡T2Iæ•°æ®é›†ï¼Œå¹¶è®­ç»ƒäº†èƒ½å¤Ÿæ£€æµ‹å…ˆå‰æœªè¯†åˆ«å…³é”®é£é™©çš„è¯„ä¼°å™¨ã€‚</li>
<li>å¯¹12ä¸ªæµè¡Œçš„æ‰©æ•£æ¨¡å‹è¿›è¡ŒT2ISafetyè¯„ä¼°ï¼Œå‘ç°å­˜åœ¨ç§æ—å…¬å¹³é—®é¢˜ã€ç”Ÿæˆæœ‰æ¯’å†…å®¹çš„å€¾å‘ä»¥åŠæ¨¡å‹é—´çš„éšç§ä¿æŠ¤å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12612">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-cdd4436ea80404b815f0cc425bd303dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8827abf4aa42f8a4553b2fad620664bc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-32ef989ed17f0a5f8a8fa04b7d0b768c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-089743b87379bcdb99f64fb2413e76dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc0895fdb436f2b410b074ab272ca95c.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Text-to-Image-Rectified-Flow-as-Plug-and-Play-Priors"><a href="#Text-to-Image-Rectified-Flow-as-Plug-and-Play-Priors" class="headerlink" title="Text-to-Image Rectified Flow as Plug-and-Play Priors"></a>Text-to-Image Rectified Flow as Plug-and-Play Priors</h2><p><strong>Authors:Xiaofeng Yang, Cheng Chen, Xulei Yang, Fayao Liu, Guosheng Lin</strong></p>
<p>Large-scale diffusion models have achieved remarkable performance in generative tasks. Beyond their initial training applications, these models have proven their ability to function as versatile plug-and-play priors. For instance, 2D diffusion models can serve as loss functions to optimize 3D implicit models. Rectified flow, a novel class of generative models, enforces a linear progression from the source to the target distribution and has demonstrated superior performance across various domains. Compared to diffusion-based methods, rectified flow approaches surpass in terms of generation quality and efficiency, requiring fewer inference steps. In this work, we present theoretical and experimental evidence demonstrating that rectified flow based methods offer similar functionalities to diffusion models - they can also serve as effective priors. Besides the generative capabilities of diffusion priors, motivated by the unique time-symmetry properties of rectified flow models, a variant of our method can additionally perform image inversion. Experimentally, our rectified flow-based priors outperform their diffusion counterparts - the SDS and VSD losses - in text-to-3D generation. Our method also displays competitive performance in image inversion and editing. </p>
<blockquote>
<p>å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ã€‚é™¤äº†åˆå§‹çš„è®­ç»ƒåº”ç”¨ä¹‹å¤–ï¼Œè¿™äº›æ¨¡å‹è¿˜è¯æ˜äº†å®ƒä»¬ä½œä¸ºé€šç”¨å³æ’å³ç”¨ä¼˜å…ˆåŠŸèƒ½çš„èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œ2Dæ‰©æ•£æ¨¡å‹å¯ä»¥ä½œä¸ºæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–3Déšå¼æ¨¡å‹ã€‚æ•´æµæµæ˜¯ä¸€ç§æ–°å‹ç”Ÿæˆæ¨¡å‹ï¼Œå¼ºåˆ¶ä»æºåˆ†å¸ƒåˆ°ç›®æ ‡åˆ†å¸ƒçš„çº¿æ€§è¿›å±•ï¼Œå¹¶åœ¨å„ä¸ªé¢†åŸŸéƒ½è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ä¸åŸºäºæ‰©æ•£çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ•´æµæµæ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡æ–¹é¢æ›´èƒœä¸€ç­¹ï¼Œæ‰€éœ€çš„æ¨ç†æ­¥éª¤è¾ƒå°‘ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ç†è®ºå’Œå®éªŒè¯æ®ï¼Œè¯æ˜åŸºäºæ•´æµæµçš„æ–¹æ³•æä¾›äº†ä¸æ‰©æ•£æ¨¡å‹ç›¸ä¼¼çš„åŠŸèƒ½â€”â€”å®ƒä»¬ä¹Ÿå¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„å…ˆéªŒã€‚é™¤äº†æ‰©æ•£å…ˆéªŒçš„ç”Ÿæˆèƒ½åŠ›å¤–ï¼Œè¿˜å—åˆ°æ•´æµæµæ¨¡å‹ç‹¬ç‰¹çš„æ—¶é—´å¯¹ç§°æ€§çš„å¯å‘ï¼Œæˆ‘ä»¬çš„æ–¹æ³•çš„ä¸€ä¸ªå˜ä½“è¿˜å¯ä»¥æ‰§è¡Œå›¾åƒåè½¬ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åŸºäºæ•´æµæµçš„å…ˆéªŒåœ¨æ–‡æœ¬åˆ°3Dç”Ÿæˆæ–¹é¢ä¼˜äºSDSå’ŒVSDæŸå¤±ç­‰æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒåè½¬å’Œç¼–è¾‘æ–¹é¢ä¹Ÿè¡¨ç°å‡ºæœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.03293v4">PDF</a> ICLR 2025 Camera Ready. Code:   <a target="_blank" rel="noopener" href="https://github.com/yangxiaofeng/rectified_flow_prior">https://github.com/yangxiaofeng/rectified_flow_prior</a></p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¿™äº›æ¨¡å‹ä¸ä»…é€‚ç”¨äºåˆå§‹è®­ç»ƒåº”ç”¨ï¼Œè¿˜å±•ç°å‡ºä½œä¸ºé€šç”¨å³æ’å³ç”¨å…ˆéªŒçš„æ½œåŠ›ã€‚ä¾‹å¦‚ï¼Œ2Dæ‰©æ•£æ¨¡å‹å¯ä½œä¸ºæŸå¤±å‡½æ•°æ¥ä¼˜åŒ–3Déšå¼æ¨¡å‹ã€‚æ–°å‹ç”Ÿæˆæ¨¡å‹â€”â€”æ•´æµæµï¼ˆRectified Flowï¼‰é€šè¿‡å¼ºåˆ¶ä»æºåˆ†å¸ƒåˆ°ç›®æ ‡åˆ†å¸ƒçš„çº¿æ€§è¿›å±•ï¼Œåœ¨å„ç§é¢†åŸŸè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç›¸è¾ƒäºæ‰©æ•£æ–¹æ³•ï¼Œæ•´æµæµåœ¨ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡æ–¹é¢æ›´èƒœä¸€ç­¹ï¼Œæ‰€éœ€æ¨ç†æ­¥éª¤æ›´å°‘ã€‚æœ¬ç ”ç©¶æä¾›äº†ç†è®ºå’Œå®éªŒè¯æ®ï¼Œè¯æ˜æ•´æµæµæ–¹æ³•å…·æœ‰ä¸æ‰©æ•£æ¨¡å‹ç›¸ä¼¼çš„åŠŸèƒ½â€”â€”å®ƒä»¬ä¹Ÿå¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„å…ˆéªŒã€‚æ­¤å¤–ï¼Œå—æ•´æµæµæ¨¡å‹çš„ç‹¬ç‰¹æ—¶é—´å¯¹ç§°å±æ€§çš„å¯å‘ï¼Œæˆ‘ä»¬çš„æ–¹æ³•çš„ä¸€ä¸ªå˜ä½“è¿˜èƒ½è¿›è¡Œå›¾åƒåè½¬ã€‚å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„åŸºäºæ•´æµæµçš„å…ˆéªŒåœ¨æ–‡æœ¬åˆ°3Dç”Ÿæˆä»»åŠ¡ä¸­è¶…è¶Šäº†SDSå’ŒVSDæŸå¤±ï¼ŒåŒæ—¶åœ¨å›¾åƒåè½¬å’Œç¼–è¾‘æ–¹é¢ä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å…·æœ‰ä½œä¸ºé€šç”¨å³æ’å³ç”¨å…ˆéªŒçš„æ½œåŠ›ã€‚</li>
<li>2Dæ‰©æ•£æ¨¡å‹èƒ½ä½œä¸ºæŸå¤±å‡½æ•°ä¼˜åŒ–3Déšå¼æ¨¡å‹ã€‚</li>
<li>æ–°å‹ç”Ÿæˆæ¨¡å‹â€”â€”æ•´æµæµï¼ˆRectified Flowï¼‰è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå¹¶å¼ºåˆ¶ä»æºåˆ°ç›®æ ‡çš„çº¿æ€§è¿›å±•ã€‚</li>
<li>ç›¸è¾ƒäºæ‰©æ•£æ–¹æ³•ï¼Œæ•´æµæµåœ¨ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ä¸Šæ›´èƒœä¸€ç­¹ã€‚</li>
<li>æ•´æµæµæ–¹æ³•å¯ä»¥ä½œä¸ºæœ‰æ•ˆçš„å…ˆéªŒï¼Œå¹¶å…·æœ‰ä¸æ‰©æ•£æ¨¡å‹ç›¸ä¼¼çš„åŠŸèƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.03293">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-227ccc00afa1a67c34782646b88130a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ede17b98e976ac3a568e8f037740170e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab1b8bd29a277977c62d2b9e127bef5c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-22/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-66847e975d9f58abc0b6078652e5f7d0.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  MedVAE Efficient Automated Interpretation of Medical Images with   Large-Scale Generalizable Autoencoders
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d18d694cf3a1b85dc08767f11e949739.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  NeRF-3DTalker Neural Radiance Field with 3D Prior Aided Audio   Disentanglement for Talking Head Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31180k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
