<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-10  Benchmarking Ophthalmology Foundation Models for Clinically Significant   Age Macular Degeneration Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-bd010ac558ed289bc849f7bf15c26b11.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    23 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-10-æ›´æ–°"><a href="#2025-05-10-æ›´æ–°" class="headerlink" title="2025-05-10 æ›´æ–°"></a>2025-05-10 æ›´æ–°</h1><h2 id="Benchmarking-Ophthalmology-Foundation-Models-for-Clinically-Significant-Age-Macular-Degeneration-Detection"><a href="#Benchmarking-Ophthalmology-Foundation-Models-for-Clinically-Significant-Age-Macular-Degeneration-Detection" class="headerlink" title="Benchmarking Ophthalmology Foundation Models for Clinically Significant   Age Macular Degeneration Detection"></a>Benchmarking Ophthalmology Foundation Models for Clinically Significant   Age Macular Degeneration Detection</h2><p><strong>Authors:Benjamin A. Cohen, Jonathan Fhima, Meishar Meisel, Baskin Meital, Luis Filipe Nakayama, Eran Berkowitz, Joachim A. Behar</strong></p>
<p>Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to learn robust representations from large-scale natural image datasets, enhancing their generalization across domains. In retinal imaging, foundation models pretrained on either natural or ophthalmic data have shown promise, but the benefits of in-domain pretraining remain uncertain. To investigate this, we benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets totaling 70,000 expert-annotated images for the task of moderate-to-late age-related macular degeneration (AMD) identification. Our results show that iBOT pretrained on natural images achieves the highest out-of-distribution generalization, with AUROCs of 0.80-0.97, outperforming domain-specific models, which achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining, which achieved AUROCs of 0.68-0.91. These findings highlight the value of foundation models in improving AMD identification and challenge the assumption that in-domain pretraining is necessary. Furthermore, we release BRAMD, an open-access dataset (n&#x3D;587) of DFIs with AMD labels from Brazil. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰ä½¿å¾—è§†è§‰Transformerï¼ˆViTï¼‰èƒ½å¤Ÿä»å¤§è§„æ¨¡çš„è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸­å­¦ä¹ é²æ£’æ€§è¡¨ç¤ºï¼Œå¢å¼ºäº†å…¶åœ¨ä¸åŒé¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨è§†ç½‘è†œæˆåƒä¸­ï¼Œé¢„è®­ç»ƒåœ¨è‡ªç„¶æˆ–çœ¼ç§‘æ•°æ®ä¸Šçš„åŸºç¡€æ¨¡å‹å·²ç»æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†é¢†åŸŸå†…é¢„è®­ç»ƒçš„å¥½å¤„ä»ä¸ç¡®å®šã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åœ¨åŒ…å«æ€»è®¡7ä¸‡å¼ ä¸“å®¶æ ‡æ³¨å›¾åƒçš„7ä¸ªæ•°å­—çœ¼åº•å›¾åƒï¼ˆDFIï¼‰æ•°æ®é›†ä¸Šï¼Œå¯¹å…­ä¸ªSSLé¢„è®­ç»ƒçš„ViTè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç”¨äºä¸­åº¦è‡³æ™šæœŸå¹´é¾„ç›¸å…³æ€§é»„æ–‘ç—…å˜ï¼ˆAMDï¼‰çš„è¯†åˆ«ä»»åŠ¡ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨è‡ªç„¶å›¾åƒä¸Šé¢„è®­ç»ƒçš„iBOTå…·æœ‰æœ€é«˜çš„è·¨åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ï¼ŒAUCå€¼åœ¨0.80è‡³0.97ä¹‹é—´ï¼Œä¼˜äºç‰¹å®šé¢†åŸŸçš„æ¨¡å‹ï¼ˆAUCå€¼åœ¨0.78è‡³0.96ä¹‹é—´ï¼‰å’Œæœªç»é¢„è®­ç»ƒçš„åŸºçº¿ViT-Lï¼ˆAUCå€¼åœ¨0.68è‡³0.91ä¹‹é—´ï¼‰ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†åŸºç¡€æ¨¡å‹åœ¨æ”¹è¿›AMDè¯†åˆ«æ–¹é¢çš„ä»·å€¼ï¼Œå¹¶æŒ‘æˆ˜äº†è®¤ä¸ºé¢†åŸŸå†…é¢„è®­ç»ƒæ˜¯å¿…è¦çš„å‡è®¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘å¸ƒäº†BRAMDï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾è®¿é—®çš„çœ¼åº•å›¾åƒæ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªå·´è¥¿çš„AMDæ ‡ç­¾å›¾åƒå…±è®¡587å¼ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05291v1">PDF</a> 10 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>åœ¨è§†ç½‘è†œæˆåƒé¢†åŸŸï¼Œè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰èµ‹èƒ½Vision Transformersï¼ˆViTsï¼‰ä»å¤§è§„æ¨¡è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸­å­¦ä¹ ç¨³å¥è¡¨ç¤ºï¼Œæå‡å…¶åœ¨ä¸åŒé¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬ç ”ç©¶å¯¹æ¯”äº†å…­ç§SSLé¢„è®­ç»ƒViTsåœ¨çœ¼åº•å›¾åƒï¼ˆDFIï¼‰æ•°æ®é›†ä¸­è¯†åˆ«å¹´é¾„ç›¸å…³æ€§é»„æ–‘ç—…å˜ï¼ˆAMDï¼‰çš„è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼Œä»¥è‡ªç„¶å›¾åƒé¢„è®­ç»ƒçš„iBOTæ¨¡å‹è¡¨ç°å‡ºæœ€ä½³æ³›åŒ–èƒ½åŠ›ï¼Œé¢†åŸŸç›¸å…³æ¨¡å‹çš„æ€§èƒ½æ¬¡ä¹‹ï¼Œæ— é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹æ€§èƒ½æœ€ä½ã€‚è¿™è¡¨æ˜åœ¨AMDè¯†åˆ«æ–¹é¢ï¼ŒåŸºç¡€æ¨¡å‹å…·æœ‰æ”¹å–„æ½œåŠ›ï¼ŒæŒ‘æˆ˜äº†é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„å¿…è¦å‡è®¾ã€‚åŒæ—¶ï¼Œæœ¬ç ”ç©¶å…¬å¼€äº†å·´è¥¿AMDæ ‡è®°çœ¼åº•å›¾åƒæ•°æ®é›†BRAMDã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç›‘ç£å­¦ä¹ ä½¿Vision Transformersèƒ½ä»å¤§è§„æ¨¡è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸­å­¦ä¹ ç¨³å¥è¡¨ç¤ºï¼Œæå‡å…¶åœ¨è§†ç½‘è†œæˆåƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨çœ¼åº•å›¾åƒæ•°æ®é›†ä¸­è¯†åˆ«å¹´é¾„ç›¸å…³æ€§é»„æ–‘ç—…å˜çš„ç ”ç©¶ä¸­ï¼ŒiBOTé¢„è®­ç»ƒæ¨¡å‹è¡¨ç°å‡ºæœ€ä½³æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä¸é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼ŒiBOTé¢„è®­ç»ƒæ¨¡å‹æ€§èƒ½æ›´ä¼˜ï¼Œè¿™æŒ‘æˆ˜äº†é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„å¿…è¦å‡è®¾ã€‚</li>
<li>å…¬å¼€äº†å·´è¥¿çš„çœ¼åº•å›¾åƒæ•°æ®é›†BRAMDï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ•°æ®æ”¯æŒã€‚</li>
<li>ç ”ç©¶è¡¨æ˜ï¼ŒåŸºç¡€æ¨¡å‹åœ¨æ”¹å–„AMDè¯†åˆ«æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚</li>
<li>ç ”ç©¶ç»“æœå¼ºè°ƒäº†é¢„è®­ç»ƒåœ¨æå‡æ¨¡å‹æ€§èƒ½ä¸­çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05291">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b245454123b152d60525ad92933e9f33.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-68741de23d21e9d4dad004d22b15d06b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8192d69baa4700648077845d9e99c26f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0807d42c6ed63bc81380acd094ea026.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-facd00a4ec60fc0008689a87d4cff094.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f09d21aa63fcb8123fdf58a54e7ad52.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Biomed-DPT-Dual-Modality-Prompt-Tuning-for-Biomedical-Vision-Language-Models"><a href="#Biomed-DPT-Dual-Modality-Prompt-Tuning-for-Biomedical-Vision-Language-Models" class="headerlink" title="Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language   Models"></a>Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language   Models</h2><p><strong>Authors:Wei Peng, Kang Liu, Jianchen Hu, Meng Zhang</strong></p>
<p>Prompt learning is one of the most effective paradigms for adapting pre-trained vision-language models (VLMs) to the biomedical image classification tasks in few shot scenarios. However, most of the current prompt learning methods only used the text prompts and ignored the particular structures (such as the complex anatomical structures and subtle pathological features) in the biomedical images. In this work, we propose Biomed-DPT, a knowledge-enhanced dual modality prompt tuning technique. In designing the text prompt, Biomed-DPT constructs a dual prompt including the template-driven clinical prompts and the large language model (LLM)-driven domain-adapted prompts, then extracts the clinical knowledge from the domain-adapted prompts through the knowledge distillation technique. In designing the vision prompt, Biomed-DPT introduces the zero vector as a soft prompt to leverage attention re-weighting so that the focus on non-diagnostic regions and the recognition of non-critical pathological features are avoided. Biomed-DPT achieves an average classification accuracy of 66.14% across 11 biomedical image datasets covering 9 modalities and 10 organs, with performance reaching 78.06% in base classes and 75.97% in novel classes, surpassing the Context Optimization (CoOp) method by 6.20%, 3.78%, and 8.04%, respectively. Our code are available at \underline{<a target="_blank" rel="noopener" href="https://github.com/Kanyooo/Biomed-DPT%7D">https://github.com/Kanyooo/Biomed-DPT}</a>. </p>
<blockquote>
<p>æç¤ºå­¦ä¹ æ˜¯åœ¨å°æ ·æœ¬åœºæ™¯ä¸­ï¼Œå°†é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é€‚åº”ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡çš„æœ€æœ‰æ•ˆèŒƒå¼ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œå½“å‰å¤§å¤šæ•°æç¤ºå­¦ä¹ æ–¹æ³•ä»…ä½¿ç”¨æ–‡æœ¬æç¤ºï¼Œè€Œå¿½ç•¥äº†ç”Ÿç‰©åŒ»å­¦å›¾åƒä¸­çš„ç‰¹å®šç»“æ„ï¼ˆå¦‚å¤æ‚çš„è§£å‰–ç»“æ„å’Œå¾®å¦™çš„ç—…ç†ç‰¹å¾ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçŸ¥è¯†å¢å¼ºçš„åŒæ¨¡æ€æç¤ºè°ƒæ•´æŠ€æœ¯â€”â€”Biomed-DPTã€‚åœ¨è®¾è®¡æ–‡æœ¬æç¤ºæ—¶ï¼ŒBiomed-DPTæ„å»ºäº†ä¸€ä¸ªåŒæç¤ºï¼ŒåŒ…æ‹¬æ¨¡æ¿é©±åŠ¨çš„ä¸´åºŠæç¤ºå’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„åŸŸé€‚é…æç¤ºï¼Œç„¶åé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯ä»åŸŸé€‚é…æç¤ºä¸­æå–ä¸´åºŠçŸ¥è¯†ã€‚åœ¨è®¾è®¡è§†è§‰æç¤ºæ—¶ï¼ŒBiomed-DPTå¼•å…¥äº†é›¶å‘é‡ä½œä¸ºè½¯æç¤ºï¼Œä»¥åˆ©ç”¨æ³¨æ„åŠ›é‡æ–°åŠ æƒï¼Œä»è€Œé¿å…å…³æ³¨éè¯Šæ–­åŒºåŸŸå’Œè¯†åˆ«éå…³é”®ç—…ç†ç‰¹å¾ã€‚Biomed-DPTåœ¨æ¶µç›–9ç§æ¨¡æ€å’Œ10ä¸ªå™¨å®˜çš„11ä¸ªç”Ÿç‰©åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šå–å¾—äº†å¹³å‡åˆ†ç±»å‡†ç¡®ç‡66.14%çš„æˆç»©ï¼Œå…¶ä¸­åŸºç¡€ç±»çš„æ€§èƒ½è¾¾åˆ°78.06%ï¼Œæ–°å‹ç±»çš„æ€§èƒ½è¾¾åˆ°75.97%ï¼Œåˆ†åˆ«è¶…è¿‡äº†CoOpæ–¹æ³•6.20%ã€3.78%å’Œ8.04%ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Kanyooo/Biomed-DPT%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Kanyooo/Biomed-DPTæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05189v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§çŸ¥è¯†å¢å¼ºçš„åŒæ¨¡æ€æç¤ºè°ƒæ•´æŠ€æœ¯ï¼ˆBiomed-DPTï¼‰ï¼Œè¯¥æŠ€æœ¯é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒè§†è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å¿«é€Ÿé€‚åº”ã€‚é€šè¿‡è®¾è®¡æ–‡æœ¬æç¤ºå’Œè§†è§‰æç¤ºï¼ŒBiomed-DPTæ„å»ºäº†ä¸€ç§åŒæç¤ºç³»ç»Ÿï¼ŒåŒ…æ‹¬æ¨¡æ¿é©±åŠ¨çš„ä¸´åºŠæç¤ºå’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„é¢†åŸŸè‡ªé€‚åº”æç¤ºï¼Œå¹¶é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯æå–é¢†åŸŸè‡ªé€‚åº”æç¤ºä¸­çš„ä¸´åºŠçŸ¥è¯†ã€‚åŒæ—¶ï¼Œå¼•å…¥é›¶å‘é‡ä½œä¸ºè½¯æç¤ºï¼Œé¿å…å¯¹éè¯Šæ–­åŒºåŸŸçš„å…³æ³¨å’Œå¯¹éå…³é”®ç—…ç†ç‰¹å¾çš„è¯†åˆ«ã€‚åœ¨è·¨è¶Šå¤šä¸ªæ•°æ®é›†çš„å®éªŒä¸­ï¼ŒBiomed-DPTçš„åˆ†ç±»å‡†ç¡®åº¦è¾¾åˆ°å¹³å‡66.14%ï¼Œå¹¶ä¸”åœ¨åŸºå‡†ç±»å’Œæ–°å‹ç±»ä¸­åˆ†åˆ«è¾¾åˆ°äº†78.06%å’Œ75.97%ï¼Œè¶…è¿‡äº†CoOpæ–¹æ³•çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰å¤§å¤šæ•°æç¤ºå­¦ä¹ æ–¹æ³•ä»…ä¾èµ–æ–‡æœ¬æç¤ºï¼Œå¿½ç•¥äº†ç”Ÿç‰©åŒ»å­¦å›¾åƒä¸­çš„ç‰¹å®šç»“æ„ã€‚</li>
<li>Biomed-DPTæ˜¯ä¸€ç§çŸ¥è¯†å¢å¼ºçš„åŒæ¨¡æ€æç¤ºè°ƒæ•´æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„å¿«é€Ÿé€‚åº”é—®é¢˜ã€‚</li>
<li>è¯¥æŠ€æœ¯é€šè¿‡æ„å»ºåŒæç¤ºç³»ç»Ÿï¼ˆåŒ…æ‹¬ä¸´åºŠæç¤ºå’Œé¢†åŸŸè‡ªé€‚åº”æç¤ºï¼‰æ¥ä¼˜åŒ–æ–‡æœ¬æç¤ºè®¾è®¡ã€‚</li>
<li>é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯ä»é¢†åŸŸè‡ªé€‚åº”æç¤ºä¸­æå–ä¸´åºŠçŸ¥è¯†ã€‚</li>
<li>å¼•å…¥é›¶å‘é‡ä½œä¸ºè§†è§‰è½¯æç¤ºï¼Œé¿å…å¯¹éè¯Šæ–­åŒºåŸŸçš„å…³æ³¨å’Œå¯¹éå…³é”®ç—…ç†ç‰¹å¾çš„è¯†åˆ«ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBiomed-DPTçš„åˆ†ç±»å‡†ç¡®åº¦åœ¨å¤šä¸ªç”Ÿç‰©åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šå¹³å‡è¾¾åˆ°66.14%ï¼Œå¹¶ä¸”åœ¨åŸºå‡†ç±»å’Œæ–°å‹ç±»ä¸­éƒ½è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05189">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-85409a86524f5f5f989f6009ea4b9f1c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fc03b81920a476b80dab0b27c27c8e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c13e0c6a1dd4c8db9deaed54a6ccb7c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a14e463700270160e6c604d25130173.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ddaec8a2136730f9e1f705f0568b385.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd010ac558ed289bc849f7bf15c26b11.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Hyb-KAN-ViT-Hybrid-Kolmogorov-Arnold-Networks-Augmented-Vision-Transformer"><a href="#Hyb-KAN-ViT-Hybrid-Kolmogorov-Arnold-Networks-Augmented-Vision-Transformer" class="headerlink" title="Hyb-KAN ViT: Hybrid Kolmogorov-Arnold Networks Augmented Vision   Transformer"></a>Hyb-KAN ViT: Hybrid Kolmogorov-Arnold Networks Augmented Vision   Transformer</h2><p><strong>Authors:Sainath Dey, Mitul Goswami, Jashika Sethi, Prasant Kumar Pattnaik</strong></p>
<p>This study addresses the inherent limitations of Multi-Layer Perceptrons (MLPs) in Vision Transformers (ViTs) by introducing Hybrid Kolmogorov-Arnold Network (KAN)-ViT (Hyb-KAN ViT), a novel framework that integrates wavelet-based spectral decomposition and spline-optimized activation functions, prior work has failed to focus on the prebuilt modularity of the ViT architecture and integration of edge detection capabilities of Wavelet functions. We propose two key modules: Efficient-KAN (Eff-KAN), which replaces MLP layers with spline functions and Wavelet-KAN (Wav-KAN), leveraging orthogonal wavelet transforms for multi-resolution feature extraction. These modules are systematically integrated in ViT encoder layers and classification heads to enhance spatial-frequency modeling while mitigating computational bottlenecks. Experiments on ImageNet-1K (Image Recognition), COCO (Object Detection and Instance Segmentation), and ADE20K (Semantic Segmentation) demonstrate state-of-the-art performance with Hyb-KAN ViT. Ablation studies validate the efficacy of wavelet-driven spectral priors in segmentation and spline-based efficiency in detection tasks. The framework establishes a new paradigm for balancing parameter efficiency and multi-scale representation in vision architectures. </p>
<blockquote>
<p>æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥æ··åˆKolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰-ViTï¼ˆHyb-KAN ViTï¼‰è¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œè§£å†³äº†å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰åœ¨è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ä¸­çš„å›ºæœ‰å±€é™æ€§ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºå°æ³¢è°±åˆ†è§£å’Œæ ·æ¡ä¼˜åŒ–æ¿€æ´»å‡½æ•°ã€‚å…ˆå‰çš„å·¥ä½œæœªèƒ½å…³æ³¨ViTæ¶æ„çš„é¢„æ„å»ºæ¨¡å—æ€§å’Œå°æ³¢åŠŸèƒ½çš„è¾¹ç¼˜æ£€æµ‹èƒ½åŠ›çš„é›†æˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šEfficient-KANï¼ˆEff-KANï¼‰ï¼Œç”¨æ ·æ¡å‡½æ•°æ›¿æ¢MLPå±‚ï¼›Wavelet-KANï¼ˆWav-KANï¼‰ï¼Œåˆ©ç”¨æ­£äº¤å°æ³¢å˜æ¢è¿›è¡Œå¤šåˆ†è¾¨ç‡ç‰¹å¾æå–ã€‚è¿™äº›æ¨¡å—ç³»ç»Ÿåœ°é›†æˆåœ¨ViTç¼–ç å™¨å±‚å’Œåˆ†ç±»å¤´ä¸­ï¼Œä»¥å¢å¼ºç©ºé—´é¢‘ç‡å»ºæ¨¡ï¼ŒåŒæ—¶ç¼“è§£è®¡ç®—ç“¶é¢ˆã€‚åœ¨ImageNet-1Kï¼ˆå›¾åƒè¯†åˆ«ï¼‰ã€COCOï¼ˆç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ï¼‰å’ŒADE20Kï¼ˆè¯­ä¹‰åˆ†å‰²ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyb-KAN ViTå…·æœ‰æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†åŸºäºå°æ³¢é©±åŠ¨çš„è°±å…ˆéªŒåœ¨åˆ†å‰²ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠåŸºäºæ ·æ¡çš„æ£€æµ‹ä»»åŠ¡æ•ˆç‡ã€‚è¯¥æ¡†æ¶ä¸ºåœ¨è§†è§‰æ¶æ„ä¸­å¹³è¡¡å‚æ•°æ•ˆç‡å’Œå¤šå°ºåº¦è¡¨ç¤ºå»ºç«‹äº†æ–°èŒƒå¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04740v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºHybrid Kolmogorov-Arnold Networkï¼ˆKANï¼‰-ViTï¼ˆHyb-KAN ViTï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œè§£å†³äº†å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰åœ¨è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ä¸­çš„å›ºæœ‰å±€é™æ€§ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºå°æ³¢è°±åˆ†è§£å’Œæ ·æ¡ä¼˜åŒ–æ¿€æ´»å‡½æ•°ã€‚å®ƒæå‡ºäº†ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šEfficient-KANï¼ˆEff-KANï¼‰å’ŒWavelet-KANï¼ˆWav-KANï¼‰ã€‚å‰è€…ç”¨æ ·æ¡å‡½æ•°æ›¿ä»£MLPå±‚ï¼Œåè€…åˆ©ç”¨æ­£äº¤å°æ³¢å˜æ¢è¿›è¡Œå¤šåˆ†è¾¨ç‡ç‰¹å¾æå–ã€‚è¿™äº›æ¨¡å—è¢«ç³»ç»Ÿåœ°é›†æˆåˆ°ViTç¼–ç å±‚å’Œåˆ†ç±»å¤´ä¸­ï¼Œä»¥å¢å¼ºç©ºé—´é¢‘ç‡å»ºæ¨¡å¹¶ç¼“è§£è®¡ç®—ç“¶é¢ˆã€‚åœ¨ImageNet-1Kï¼ˆå›¾åƒè¯†åˆ«ï¼‰ã€COCOï¼ˆå¯¹è±¡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ï¼‰å’ŒADE20Kï¼ˆè¯­ä¹‰åˆ†å‰²ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHyb-KAN ViTå…·æœ‰æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†ä»¥æ³¢ä¸ºé©±åŠ¨è°±å…ˆéªŒåœ¨åˆ†å‰²ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠåŸºäºæ ·æ¡çš„æ•ˆç‡åœ¨æ£€æµ‹ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚è¯¥æ¡†æ¶ä¸ºå¹³è¡¡å‚æ•°æ•ˆç‡å’Œå¤šå°ºåº¦è¡¨ç¤ºåœ¨è§†è§‰æ¶æ„ä¸­å»ºç«‹äº†æ–°çš„èŒƒä¾‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†Hybrid Kolmogorov-Arnold Network (KAN)-ViTæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰åœ¨è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ä¸­çš„å±€é™æ€§ã€‚</li>
<li>æå‡ºäº†Efficient-KANå’ŒWavelet-KANä¸¤ä¸ªå…³é”®æ¨¡å—ï¼Œå‰è€…ç”¨æ ·æ¡å‡½æ•°æ›¿ä»£MLPå±‚ä»¥æé«˜æ•ˆç‡ï¼Œåè€…åˆ©ç”¨å°æ³¢å˜æ¢è¿›è¡Œå¤šåˆ†è¾¨ç‡ç‰¹å¾æå–ã€‚</li>
<li>å°†è¿™äº›æ¨¡å—ç³»ç»Ÿåœ°é›†æˆåˆ°ViTç¼–ç å±‚å’Œåˆ†ç±»å¤´ä¸­ï¼Œä»¥å¢å¼ºç©ºé—´é¢‘ç‡å»ºæ¨¡ï¼Œå¹¶ç¼“è§£è®¡ç®—ç“¶é¢ˆã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜Hyb-KAN ViTå…·æœ‰æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ImageNet-1Kã€COCOå’ŒADE20Kã€‚</li>
<li>æ¶ˆèç ”ç©¶éªŒè¯äº†ä»¥æ³¢ä¸ºé©±åŠ¨è°±å…ˆéªŒåœ¨åˆ†å‰²ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠåŸºäºæ ·æ¡çš„æ¿€æ´»å‡½æ•°åœ¨æ£€æµ‹ä»»åŠ¡ä¸­çš„æ•ˆç‡ã€‚</li>
<li>è¯¥æ¡†æ¶ä¸ºå¹³è¡¡å‚æ•°æ•ˆç‡å’Œå¤šå°ºåº¦è¡¨ç¤ºåœ¨è§†è§‰æ¶æ„ä¸­æä¾›äº†æ–°èŒƒä¾‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04740">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f03a828ae6c37c2d871cdeb96618097.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8afb7eff808fab8e83b2569b255b83b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4bdae75667d9d276316b36494bc1b6b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0657555f2f225fae0f83f5d14deb8b00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b19acd3e099d022bfd80f1f94668b1b2.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Rethinking-Boundary-Detection-in-Deep-Learning-Based-Medical-Image-Segmentation"><a href="#Rethinking-Boundary-Detection-in-Deep-Learning-Based-Medical-Image-Segmentation" class="headerlink" title="Rethinking Boundary Detection in Deep Learning-Based Medical Image   Segmentation"></a>Rethinking Boundary Detection in Deep Learning-Based Medical Image   Segmentation</h2><p><strong>Authors:Yi Lin, Dong Zhang, Xiao Fang, Yufan Chen, Kwang-Ting Cheng, Hao Chen</strong></p>
<p>Medical image segmentation is a pivotal task within the realms of medical image analysis and computer vision. While current methods have shown promise in accurately segmenting major regions of interest, the precise segmentation of boundary areas remains challenging. In this study, we propose a novel network architecture named CTO, which combines Convolutional Neural Networks (CNNs), Vision Transformer (ViT) models, and explicit edge detection operators to tackle this challenge. CTO surpasses existing methods in terms of segmentation accuracy and strikes a better balance between accuracy and efficiency, without the need for additional data inputs or label injections. Specifically, CTO adheres to the canonical encoder-decoder network paradigm, with a dual-stream encoder network comprising a mainstream CNN stream for capturing local features and an auxiliary StitchViT stream for integrating long-range dependencies. Furthermore, to enhance the modelâ€™s ability to learn boundary areas, we introduce a boundary-guided decoder network that employs binary boundary masks generated by dedicated edge detection operators to provide explicit guidance during the decoding process. We validate the performance of CTO through extensive experiments conducted on seven challenging medical image segmentation datasets, namely ISIC 2016, PH2, ISIC 2018, CoNIC, LiTS17, and BTCV. Our experimental results unequivocally demonstrate that CTO achieves state-of-the-art accuracy on these datasets while maintaining competitive model complexity. The codes have been released at: <a target="_blank" rel="noopener" href="https://github.com/xiaofang007/CTO">https://github.com/xiaofang007/CTO</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯åŒ»å­¦å›¾åƒåˆ†æå’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ã€‚è™½ç„¶å½“å‰æ–¹æ³•åœ¨å‡†ç¡®åˆ†å‰²ä¸»è¦æ„Ÿå…´è¶£åŒºåŸŸæ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†è¾¹ç•ŒåŒºåŸŸçš„ç²¾ç¡®åˆ†å‰²ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºCTOçš„æ–°å‹ç½‘ç»œæ¶æ„ï¼Œå®ƒç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰æ¨¡å‹å’Œæ˜ç¡®çš„è¾¹ç¼˜æ£€æµ‹ç®—å­ï¼Œä»¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚CTOåœ¨åˆ†å‰²ç²¾åº¦ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†æ›´å¥½çš„å¹³è¡¡ï¼Œæ— éœ€é¢å¤–çš„æ•°æ®è¾“å…¥æˆ–æ ‡ç­¾æ³¨å…¥ã€‚å…·ä½“æ¥è¯´ï¼ŒCTOéµå¾ªå…¸å‹çš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œèŒƒå¼ï¼Œå…·æœ‰åŒæµç¼–ç å™¨ç½‘ç»œï¼ŒåŒ…æ‹¬ç”¨äºæ•è·å±€éƒ¨ç‰¹å¾çš„ä¸»æµCNNæµå’Œç”¨äºé›†æˆè¿œç¨‹ä¾èµ–çš„è¾…åŠ©StitchViTæµã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜æ¨¡å‹å­¦ä¹ è¾¹ç•ŒåŒºåŸŸçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¾¹ç•Œå¼•å¯¼è§£ç å™¨ç½‘ç»œï¼Œè¯¥ç½‘ç»œä½¿ç”¨ç”±ä¸“ç”¨è¾¹ç¼˜æ£€æµ‹ç®—å­ç”Ÿæˆçš„äºŒè¿›åˆ¶è¾¹ç•Œæ©è†œåœ¨è§£ç è¿‡ç¨‹ä¸­æä¾›æ˜ç¡®æŒ‡å¯¼ã€‚æˆ‘ä»¬åœ¨ä¸ƒä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼ŒéªŒè¯äº†CTOçš„æ€§èƒ½ï¼Œè¿™äº›æ•°æ®é›†åˆ†åˆ«æ˜¯ISIC 2016ã€PH2ã€ISIC 2018ã€CoNICã€LiTS17å’ŒBTCVã€‚æˆ‘ä»¬çš„å®éªŒç»“æœæ˜ç¡®è¯æ˜ï¼ŒCTOåœ¨è¿™äº›æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰æ€§çš„æ¨¡å‹å¤æ‚åº¦ã€‚ä»£ç å·²å‘å¸ƒåœ¨ï¼š[<a target="_blank" rel="noopener" href="https://github.com/xiaofang007/CTO%E3%80%82]">https://github.com/xiaofang007/CTOã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04652v1">PDF</a> Accepted by Medical Image Analysis</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ç½‘ç»œæ¶æ„CTOï¼Œèåˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰æ¨¡å‹å’Œè¾¹ç¼˜æ£€æµ‹ç®—å­ï¼Œä»¥åº”å¯¹åŒ»ç–—å›¾åƒåˆ†å‰²ä¸­è¾¹ç•ŒåŒºåŸŸç²¾ç¡®åˆ†å‰²çš„æŒ‘æˆ˜ã€‚CTOåœ¨åˆ†å‰²ç²¾åº¦ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†æ›´å¥½çš„å¹³è¡¡ï¼Œæ— éœ€é¢å¤–çš„æ•°æ®è¾“å…¥æˆ–æ ‡ç­¾æ³¨å…¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—å›¾åƒåˆ†å‰²æ˜¯åŒ»å­¦å›¾åƒåˆ†æå’Œè®¡ç®—æœºè§†è§‰ä¸­çš„å…³é”®ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨ç²¾ç¡®åˆ†å‰²è¾¹ç•ŒåŒºåŸŸæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹ç½‘ç»œæ¶æ„CTOï¼Œç»“åˆäº†CNNã€ViTæ¨¡å‹å’Œè¾¹ç¼˜æ£€æµ‹ç®—å­æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>CTOè¶…è¶Šäº†ç°æœ‰æ–¹æ³•çš„åˆ†å‰²ç²¾åº¦ï¼Œå¹¶åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚</li>
<li>CTOé‡‡ç”¨å…¸å‹çš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œèŒƒå¼ï¼Œå…·æœ‰åŒæµç¼–ç å™¨ç½‘ç»œï¼ŒåŒ…æ‹¬ä¸»æµCNNæµå’Œè¾…åŠ©StitchViTæµã€‚</li>
<li>ä¸ºæé«˜æ¨¡å‹å¯¹è¾¹ç•ŒåŒºåŸŸçš„å­¦ä¹ èƒ½åŠ›ï¼Œå¼•å…¥äº†è¾¹ç•Œå¼•å¯¼è§£ç å™¨ç½‘ç»œï¼Œé‡‡ç”¨ä¸“ç”¨è¾¹ç¼˜æ£€æµ‹ç®—å­ç”Ÿæˆçš„äºŒè¿›åˆ¶è¾¹ç•Œæ©è†œä¸ºè§£ç è¿‡ç¨‹æä¾›æ˜ç¡®æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ad1843bcb2bfc5cebfd1b7d52c72f0fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba3464f4eec9332272a3e07a9cd6d120.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77cc6a2bf4b8e84be2d393e6442e2104.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca45fb0cad8a82dc687e997b025d76e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-327b43dbc5d647fccf99d964853e6b81.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MambaNUT-Nighttime-UAV-Tracking-via-Mamba-based-Adaptive-Curriculum-Learning"><a href="#MambaNUT-Nighttime-UAV-Tracking-via-Mamba-based-Adaptive-Curriculum-Learning" class="headerlink" title="MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum   Learning"></a>MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum   Learning</h2><p><strong>Authors:You Wu, Xiangyang Yang, Xucheng Wang, Hengzhou Ye, Dan Zeng, Shuiwang Li</strong></p>
<p>Harnessing low-light enhancement and domain adaptation, nighttime UAV tracking has made substantial strides. However, over-reliance on image enhancement, limited high-quality nighttime data, and a lack of integration between daytime and nighttime trackers hinder the development of an end-to-end trainable framework. Additionally, current ViT-based trackers demand heavy computational resources due to their reliance on the self-attention mechanism. In this paper, we propose a novel pure Mamba-based tracking framework (MambaNUT) that employs a state space model with linear complexity as its backbone, incorporating a single-stream architecture that integrates feature learning and template-search coupling within Vision Mamba. We introduce an adaptive curriculum learning (ACL) approach that dynamically adjusts sampling strategies and loss weights, thereby improving the modelâ€™s ability of generalization. Our ACL is composed of two levels of curriculum schedulers: (1) sampling scheduler that transforms the data distribution from imbalanced to balanced, as well as from easier (daytime) to harder (nighttime) samples; (2) loss scheduler that dynamically assigns weights based on the size of the training data and IoU of individual instances. Exhaustive experiments on multiple nighttime UAV tracking benchmarks demonstrate that the proposed MambaNUT achieves state-of-the-art performance while requiring lower computational costs. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/wuyou3474/MambaNUT">https://github.com/wuyou3474/MambaNUT</a>. </p>
<blockquote>
<p>åˆ©ç”¨ä½å…‰å¢å¼ºå’Œé¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯ï¼Œå¤œé—´æ— äººæœºè·Ÿè¸ªå·²ç»å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå¯¹å›¾åƒå¢å¼ºçš„è¿‡åº¦ä¾èµ–ã€é«˜è´¨é‡å¤œé—´æ•°æ®çš„æœ‰é™æ€§ä»¥åŠæ—¥é—´å’Œå¤œé—´è·Ÿè¸ªå™¨ä¹‹é—´ç¼ºä¹æ•´åˆï¼Œé˜»ç¢äº†ç«¯åˆ°ç«¯å¯è®­ç»ƒæ¡†æ¶çš„å‘å±•ã€‚æ­¤å¤–ï¼Œå½“å‰çš„åŸºäºViTçš„è·Ÿè¸ªå™¨ç”±äºä¾èµ–äºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºçº¯Mambaçš„è·Ÿè¸ªæ¡†æ¶ï¼ˆMambaNUTï¼‰ï¼Œå®ƒé‡‡ç”¨å…·æœ‰çº¿æ€§å¤æ‚åº¦çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œå¹¶é‡‡ç”¨äº†å•æµæ¶æ„ï¼Œè¯¥æ¶æ„åœ¨Vision Mambaå†…é›†æˆäº†ç‰¹å¾å­¦ä¹ å’Œæ¨¡æ¿æœç´¢è€¦åˆã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ ï¼ˆACLï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥å’ŒæŸå¤±æƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ACLç”±ä¸¤çº§è¯¾ç¨‹è°ƒåº¦å™¨ç»„æˆï¼šï¼ˆ1ï¼‰é‡‡æ ·è°ƒåº¦å™¨ï¼Œå®ƒæ”¹å˜æ•°æ®åˆ†å¸ƒï¼Œä»ä¸å¹³è¡¡åˆ°å¹³è¡¡ï¼Œä»ç®€å•çš„ï¼ˆæ—¥é—´ï¼‰æ ·æœ¬åˆ°å¤æ‚çš„ï¼ˆå¤œé—´ï¼‰æ ·æœ¬ï¼›ï¼ˆ2ï¼‰æŸå¤±è°ƒåº¦å™¨ï¼Œå®ƒæ ¹æ®è®­ç»ƒæ•°æ®çš„å¤§å°å’Œå„ä¸ªå®ä¾‹çš„IoUåŠ¨æ€åˆ†é…æƒé‡ã€‚åœ¨å¤šä¸ªå¤œé—´æ— äººæœºè·Ÿè¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„MambaNUTè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è®¡ç®—æˆæœ¬è¾ƒä½ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/wuyou3474/MambaNUT%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/wuyou3474/MambaNUTä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00626v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºMambaçš„çº¯è·Ÿè¸ªæ¡†æ¶ï¼ˆMambaNUTï¼‰ï¼Œé‡‡ç”¨çº¿æ€§å¤æ‚åº¦çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ä½œä¸ºéª¨å¹²ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç‰¹å¾å­¦ä¹ ä¸æ¨¡æ¿æœç´¢è€¦åˆçš„å•æµæ¶æ„ï¼Œå¹¶å¼•å…¥äº†è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼ˆACLï¼‰ä»¥åŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥å’ŒæŸå¤±æƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒMambaNUTåœ¨å¤œé—´æ— äººæœºè·Ÿè¸ªæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤œé—´æ— äººæœºè·Ÿè¸ªé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´å›¾åƒå¢å¼ºè¿‡åº¦ä¾èµ–ã€é«˜è´¨é‡å¤œé—´æ•°æ®æœ‰é™ä»¥åŠæ—¥å¤œè·Ÿè¸ªå™¨èåˆä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†åŸºäºMambaçš„çº¯è·Ÿè¸ªæ¡†æ¶ï¼ˆMambaNUTï¼‰ï¼Œç»“åˆç‰¹å¾å­¦ä¹ ä¸æ¨¡æ¿æœç´¢è€¦åˆçš„å•æµæ¶æ„ã€‚</li>
<li>MambaNUTé‡‡ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œå…·æœ‰çº¿æ€§å¤æ‚åº¦ï¼Œé™ä½äº†è®¡ç®—èµ„æºçš„æ¶ˆè€—ã€‚</li>
<li>å¼•å…¥äº†è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼ˆACLï¼‰ï¼ŒåŠ¨æ€è°ƒæ•´é‡‡æ ·ç­–ç•¥å’ŒæŸå¤±æƒé‡ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ACLåŒ…å«ä¸¤ä¸ªå±‚æ¬¡çš„è¯¾ç¨‹è°ƒåº¦å™¨ï¼šé‡‡æ ·è°ƒåº¦å™¨å’ŒæŸå¤±è°ƒåº¦å™¨ï¼Œåˆ†åˆ«å¯¹æ•°æ®çš„åˆ†å¸ƒå’ŒæŸå¤±æƒé‡è¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒMambaNUTåœ¨å¤šä¸ªå¤œé—´æ— äººæœºè·Ÿè¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.00626">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dd13ec40030f8b56e87df14f76794694.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1e3aa283c1e6091e0b81c4b3b07db80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-037b80f29793a9347d71e3c3e0c90d61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b37629b0d5437c966aab83fafb97a7e4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-14c307eca7ff56a567e04c62f5670b76.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Evaluating-Deep-Learning-Models-for-Breast-Cancer-Classification-A-Comparative-Study"><a href="#Evaluating-Deep-Learning-Models-for-Breast-Cancer-Classification-A-Comparative-Study" class="headerlink" title="Evaluating Deep Learning Models for Breast Cancer Classification: A   Comparative Study"></a>Evaluating Deep Learning Models for Breast Cancer Classification: A   Comparative Study</h2><p><strong>Authors:Sania Eskandari, Ali Eslamian, Nusrat Munia, Amjad Alqarni, Qiang Cheng</strong></p>
<p>This study evaluates the effectiveness of deep learning models in classifying histopathological images for early and accurate detection of breast cancer. Eight advanced models, including ResNet-50, DenseNet-121, ResNeXt-50, Vision Transformer (ViT), GoogLeNet (Inception v3), EfficientNet, MobileNet, and SqueezeNet, were compared using a dataset of 277,524 image patches. The Vision Transformer (ViT) model, with its attention-based mechanisms, achieved the highest validation accuracy of 94%, outperforming conventional CNNs. The study demonstrates the potential of advanced machine learning methods to enhance precision and efficiency in breast cancer diagnosis in clinical settings. </p>
<blockquote>
<p>æœ¬ç ”ç©¶è¯„ä¼°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆ†ç±»ç—…ç†å›¾åƒä»¥æ—©æœŸå’Œå‡†ç¡®æ£€æµ‹ä¹³è…ºç™Œæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä½¿ç”¨åŒ…å«277524ä¸ªå›¾åƒå—çš„æ•°æ®é›†ï¼Œå¯¹æ¯”äº†ResNet-50ã€DenseNet-121ã€ResNeXt-50ã€Vision Transformerï¼ˆViTï¼‰ã€GoogLeNetï¼ˆInception v3ï¼‰ã€EfficientNetã€MobileNetå’ŒSqueezeNetç­‰å…«ç§å…ˆè¿›æ¨¡å‹ã€‚å…¶ä¸­ï¼Œé‡‡ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„Vision Transformerï¼ˆViTï¼‰æ¨¡å‹å–å¾—äº†æœ€é«˜çš„éªŒè¯å‡†ç¡®ç‡ï¼Œè¾¾åˆ°äº†94%ï¼Œå¹¶ä¼˜äºä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨æé«˜ä¹³è…ºç™Œè¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.16859v2">PDF</a> 4 pages, 2 figures, 2 tables</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶è¯„ä¼°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆ†ç±»ç—…ç†å›¾åƒä»¥è¿›è¡Œä¹³è…ºç™Œæ—©æœŸå‡†ç¡®æ£€æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶æ¯”è¾ƒäº†ResNet-50ã€DenseNet-121ç­‰å…«ç§å…ˆè¿›æ¨¡å‹ï¼Œä½¿ç”¨åŒ…å«277,524ä¸ªå›¾åƒè¡¥ä¸çš„æ•°æ®é›†è¿›è¡Œæµ‹è¯•ã€‚å…¶ä¸­ï¼ŒVision Transformerï¼ˆViTï¼‰æ¨¡å‹å‡­å€Ÿæ³¨æ„åŠ›æœºåˆ¶å®ç°äº†æœ€é«˜éªŒè¯å‡†ç¡®ç‡94%ï¼Œè¶…è¿‡äº†ä¼ ç»ŸCNNã€‚æ­¤ç ”ç©¶å±•ç¤ºäº†å…ˆè¿›æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å¢å¼ºä¹³è…ºç™Œè¯Šæ–­ç²¾åº¦å’Œæ•ˆç‡æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œç—…ç†å›¾åƒåˆ†ç±»ï¼Œæ—¨åœ¨æ—©æœŸå‡†ç¡®æ£€æµ‹ä¹³è…ºç™Œã€‚</li>
<li>è¯„ä¼°äº†å…«ç§å…ˆè¿›æ¨¡å‹ï¼ˆResNet-50ç­‰ï¼‰ï¼Œé€šè¿‡å¯¹æ¯”éªŒè¯æ¨¡å‹æ•ˆæœã€‚</li>
<li>Vision Transformerï¼ˆViTï¼‰æ¨¡å‹å› å…·å¤‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œå–å¾—äº†æœ€é«˜çš„éªŒè¯å‡†ç¡®ç‡94%ã€‚</li>
<li>Vision Transformeræ¨¡å‹çš„æ€§èƒ½ä¼˜äºä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºä¸´åºŠç¯å¢ƒä¸­çš„ä¹³è…ºç™Œè¯Šæ–­æä¾›äº†æ›´ä¸ºç²¾ç¡®å’Œé«˜æ•ˆçš„æœºå™¨å­¦ä¹ æ–¹æ³•çš„æ½œåŠ›è¯æ®ã€‚</li>
<li>æ•°æ®é›†åŒ…å«å¤§é‡çš„å›¾åƒè¡¥ä¸ï¼ˆ277,524ä¸ªï¼‰ï¼Œæœ‰åŠ©äºæ¨¡å‹çš„è®­ç»ƒå’ŒéªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.16859">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bfeba4bf8172ab70ba1a0b89323253ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b476f4e9aaf20f144c75a608572c3b03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef9a33f05d22e19d1d4002a7fb56f12e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28dea6e3f041edd6758be36e31d49330.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0d6169567c1dc4abeac209b7307d9785.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-10  MonoCoP Chain-of-Prediction for Monocular 3D Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-9b9e4f3b6b85ab15d2695e8184141a49.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-10  Latte Transfering LLMs` Latent-level Knowledge for Few-shot Tabular   Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27083.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
