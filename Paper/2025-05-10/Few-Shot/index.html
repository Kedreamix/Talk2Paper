<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-05-10  Latte Transfering LLMs` Latent-level Knowledge for Few-shot Tabular   Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-9b9e4f3b6b85ab15d2695e8184141a49.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-10-更新"><a href="#2025-05-10-更新" class="headerlink" title="2025-05-10 更新"></a>2025-05-10 更新</h1><h2 id="Latte-Transfering-LLMs-Latent-level-Knowledge-for-Few-shot-Tabular-Learning"><a href="#Latte-Transfering-LLMs-Latent-level-Knowledge-for-Few-shot-Tabular-Learning" class="headerlink" title="Latte: Transfering LLMs&#96; Latent-level Knowledge for Few-shot Tabular   Learning"></a>Latte: Transfering LLMs&#96; Latent-level Knowledge for Few-shot Tabular   Learning</h2><p><strong>Authors:Ruxue Shi, Hengrui Gu, Hangting Ye, Yiwei Dai, Xu Shen, Xin Wang</strong></p>
<p>Few-shot tabular learning, in which machine learning models are trained with a limited amount of labeled data, provides a cost-effective approach to addressing real-world challenges. The advent of Large Language Models (LLMs) has sparked interest in leveraging their pre-trained knowledge for few-shot tabular learning. Despite promising results, existing approaches either rely on test-time knowledge extraction, which introduces undesirable latency, or text-level knowledge, which leads to unreliable feature engineering. To overcome these limitations, we propose Latte, a training-time knowledge extraction framework that transfers the latent prior knowledge within LLMs to optimize a more generalized downstream model. Latte enables general knowledge-guided downstream tabular learning, facilitating the weighted fusion of information across different feature values while reducing the risk of overfitting to limited labeled data. Furthermore, Latte is compatible with existing unsupervised pre-training paradigms and effectively utilizes available unlabeled samples to overcome the performance limitations imposed by an extremely small labeled dataset. Extensive experiments on various few-shot tabular learning benchmarks demonstrate the superior performance of Latte, establishing it as a state-of-the-art approach in this domain </p>
<blockquote>
<p>少样本表格学习（Few-Shot Tabular Learning）是指利用有限量标记数据来训练机器学习模型，为解决现实世界挑战提供具有成本效益的方法。大型语言模型（LLM）的出现引发了利用预训练知识来促进少样本表格学习的兴趣。尽管已有方法取得了一些有前景的结果，但它们要么依赖于测试时的知识提取，这引入了不必要的延迟，要么依赖于文本级别的知识，这导致了不可靠的特征工程。为了克服这些局限性，我们提出了Latte，这是一个训练时的知识提取框架，它将LLM中的潜在先验知识转移出来以优化更通用的下游模型。Latte能够实现通用知识指导的下游表格学习，促进不同特征值之间信息的加权融合，同时降低对有限标记数据过度拟合的风险。此外，Latte与现有的无监督预训练模式兼容，并能有效利用可用的未标记样本，以克服由于极小的标记数据集而带来的性能限制。在各种少样本表格学习基准测试上的广泛实验表明，Latte的性能卓越，已成为该领域的最前沿方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05237v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>少量标注数据的表格学习提供了一种具有成本效益的方法来解决现实世界的问题。利用大型语言模型（LLM）的潜在先验知识，提出一种名为Latte的训练时间知识提取框架，以优化更通用的下游模型。Latte通过加权融合不同特征值的信息，减少了对有限标注数据的过度拟合风险，并可与现有的无监督预训练范式兼容，有效利用可用的未标注样本。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-shot tabular learning利用有限的标注数据来训练机器学习模型，为现实世界的问题解决提供了成本效益高的方法。</li>
<li>大型语言模型（LLMs）的潜在先验知识在few-shot表格学习中具有应用价值。</li>
<li>Latte框架是一种训练时间的知识提取方法，能够转移LLM中的潜在知识来优化下游模型。</li>
<li>Latte通过加权融合不同特征值的信息，提高了模型的泛化能力，并降低了过度拟合的风险。</li>
<li>Latte与现有的无监督预训练范式兼容，可以充分利用未标注的样本数据。</li>
<li>Latte在多种few-shot表格学习基准测试上表现出卓越的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05237">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a860ab2e82b0131f407a6f3912174523.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cae4672510d6a0e0615bd91e8f274ac3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-320de0c4d5fc208f15b6b708f3d02c83.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-342424ea6700154eb92c9dee696b6cd9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Biomed-DPT-Dual-Modality-Prompt-Tuning-for-Biomedical-Vision-Language-Models"><a href="#Biomed-DPT-Dual-Modality-Prompt-Tuning-for-Biomedical-Vision-Language-Models" class="headerlink" title="Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language   Models"></a>Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language   Models</h2><p><strong>Authors:Wei Peng, Kang Liu, Jianchen Hu, Meng Zhang</strong></p>
<p>Prompt learning is one of the most effective paradigms for adapting pre-trained vision-language models (VLMs) to the biomedical image classification tasks in few shot scenarios. However, most of the current prompt learning methods only used the text prompts and ignored the particular structures (such as the complex anatomical structures and subtle pathological features) in the biomedical images. In this work, we propose Biomed-DPT, a knowledge-enhanced dual modality prompt tuning technique. In designing the text prompt, Biomed-DPT constructs a dual prompt including the template-driven clinical prompts and the large language model (LLM)-driven domain-adapted prompts, then extracts the clinical knowledge from the domain-adapted prompts through the knowledge distillation technique. In designing the vision prompt, Biomed-DPT introduces the zero vector as a soft prompt to leverage attention re-weighting so that the focus on non-diagnostic regions and the recognition of non-critical pathological features are avoided. Biomed-DPT achieves an average classification accuracy of 66.14% across 11 biomedical image datasets covering 9 modalities and 10 organs, with performance reaching 78.06% in base classes and 75.97% in novel classes, surpassing the Context Optimization (CoOp) method by 6.20%, 3.78%, and 8.04%, respectively. Our code are available at \underline{<a target="_blank" rel="noopener" href="https://github.com/Kanyooo/Biomed-DPT%7D">https://github.com/Kanyooo/Biomed-DPT}</a>. </p>
<blockquote>
<p>提示学习是在少量场景中将预训练的视觉语言模型（VLMs）适应生物医学图像分类任务的最有效范式之一。然而，当前大多数提示学习方法仅使用文本提示，而忽略了生物医学图像中的特定结构（如复杂的解剖结构和微妙的病理特征）。在本研究中，我们提出了生物医学DPT（Biomed-DPT），这是一种知识增强的双模态提示调整技术。在设计文本提示时，Biomed-DPT构建了一个双提示，包括模板驱动的临床提示和大型语言模型（LLM）驱动的域适应提示，然后通过知识蒸馏技术从域适应提示中提取临床知识。在设计视觉提示时，Biomed-DPT引入了零向量作为软提示，以利用注意力重新加权，从而避免关注非诊断区域和识别非关键病理特征。Biomed-DPT在涵盖9种模态和10个器官的11个生物医学图像数据集上实现了平均分类准确率66.14％，其中基础类的性能达到78.06％，新型类的性能达到75.97％，分别超越了上下文优化（CoOp）方法6.20％、3.78％和8.04％。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/Kanyooo/Biomed-DPT%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Kanyooo/Biomed-DPT上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05189v1">PDF</a> </p>
<p><strong>Summary</strong><br>     生物医学图像分类任务中，基于提示学习是预训练视觉语言模型的有效范式之一。然而，当前大多数提示学习方法仅使用文本提示，忽略了生物医学图像中的特定结构。本文提出Biomed-DPT，一种知识增强的双模态提示调整技术。设计文本提示时，Biomed-DPT构建包括模板驱动的临床提示和大型语言模型驱动领域自适应提示的双重提示，并通过知识蒸馏技术提取领域自适应提示中的临床知识。在视觉提示设计上，Biomed-DPT引入零向量作为软提示，利用注意力重新加权，避免关注非诊断区域和识别非关键病理特征。Biomed-DPT在涵盖九种模态和十个器官的11个生物医学图像数据集上取得了平均分类准确率66.14%，其中基础类别和新颖类别的性能分别达到了78.06%和75.97%，超过了CoOp方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提示学习是适应预训练视觉语言模型进行生物医学图像分类的有效方法。</li>
<li>当前提示学习方法多忽略生物医学图像中的特定结构。</li>
<li>Biomed-DPT是一种知识增强的双模态提示调整技术，结合临床提示和大型语言模型。</li>
<li>Biomed-DPT通过知识蒸馏提取临床知识。</li>
<li>在视觉提示设计上，Biomed-DPT引入零向量避免关注非诊断区域和识别非关键病理特征。</li>
<li>Biomed-DPT在多个生物医学图像数据集上取得了较高的分类准确率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05189">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-85409a86524f5f5f989f6009ea4b9f1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fc03b81920a476b80dab0b27c27c8e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c13e0c6a1dd4c8db9deaed54a6ccb7c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a14e463700270160e6c604d25130173.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ddaec8a2136730f9e1f705f0568b385.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd010ac558ed289bc849f7bf15c26b11.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CacheFL-Efficient-Federated-Cache-Model-Fine-Tuning-for-Vision-Language-Models"><a href="#CacheFL-Efficient-Federated-Cache-Model-Fine-Tuning-for-Vision-Language-Models" class="headerlink" title="CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language   Models"></a>CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language   Models</h2><p><strong>Authors:Mengjun Yi, Hanwen Zhang, Hui Dou, Jian Zhao, Furao Shen</strong></p>
<p>Large pre-trained Vision-Language Models (VLMs), such as Contrastive Language-Image Pre-training (CLIP), have exhibited remarkable zero-shot performance across various image classification tasks. Fine-tuning these models on domain-specific datasets further enhances their effectiveness for downstream applications. However, fine-tuning in cloud environments raises significant concerns regarding data security and privacy. Federated Learning (FL) offers a decentralized solution by enabling model training across local clients without centralizing sensitive data, but the high communication and computation costs of transmitting full pre-trained models during training limit its scalability. Additionally, non-Independent and Identically Distributed (non-IID) data across local clients can negatively impact model convergence and performance. To address these challenges, we propose CacheFL, a novel federated learning method that replaces traditional full model fine-tuning with lightweight cache model fine-tuning. The cache model is initialized using a class-balanced dataset generated by a generative pre-trained model, effectively mitigating the impact of non-IID data. This cache model is then distributed to local clients for fine-tuning, and the updated parameters from each client are aggregated on the server and redistributed. With the updated cache model, the classification performance of CLIP is improved after just a few epochs. By limiting the training and communication to the cache model, CacheFL significantly reduces resource demands while ensuring data privacy and security. Extensive experiments conducted on ImageNet and 10 additional datasets demonstrate that CacheFL outperforms traditional approaches in terms of classification accuracy, resource efficiency, and privacy preservation. </p>
<blockquote>
<p>大型预训练视觉语言模型（VLMs），如对比语言图像预训练（CLIP），在各种图像分类任务中表现出了出色的零样本性能。在特定领域数据集上对这些模型进行微调，可以进一步提高其下游应用的有效性。然而，在云环境中进行微调引发了关于数据安全和隐私的重大担忧。联邦学习（FL）通过支持本地客户端的模型训练，无需集中敏感数据，提供了分散的解决方案。但在训练过程中传输完整的预训练模型的高通信和计算成本限制了其可扩展性。此外，本地客户端之间的非独立同分布（non-IID）数据可能对模型收敛和性能产生负面影响。为了解决这些挑战，我们提出了CacheFL，这是一种新型的联邦学习方法，它用轻量级的缓存模型微调取代了传统的全模型微调。缓存模型使用由生成式预训练模型生成的类别平衡数据集进行初始化，有效地减轻了非IID数据的影响。然后，该缓存模型将分发给本地客户端进行微调，从每个客户端更新的参数将在服务器上聚合并重新分发。仅通过几个周期，使用更新后的缓存模型，CLIP的分类性能就得到了提高。通过将训练和通信限制在缓存模型上，CacheFL在降低资源需求的同时，确保了数据隐私和安全。在ImageNet和另外10个数据集上进行的广泛实验表明，CacheFL在分类精度、资源效率和隐私保护方面优于传统方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05130v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型预训练视听模型，如对比语言图像预训练（CLIP），在各种图像分类任务中表现出出色的零样本性能。对这些模型进行领域特定数据集的微调可进一步提高其下游应用的效果。然而，在云环境中进行微调引发了关于数据安全和隐私的重大担忧。联邦学习（FL）提供了一种去中心化的解决方案，通过在本地客户端进行模型训练，而不集中敏感数据。但传输完整的预训练模型进行训练导致的通信和计算成本高昂，限制了其可扩展性。此外，本地客户端的非独立同分布（non-IID）数据可能给模型收敛和性能带来负面影响。为解决这些挑战，我们提出了CacheFL这一新型的联邦学习方法，它将传统的全模型微调替换为轻量级的缓存模型微调。缓存模型使用由生成式预训练模型生成的类别平衡数据集进行初始化，有效减轻了非IID数据的影响。缓存模型然后分发到本地客户端进行微调，来自每个客户端的更新参数在服务器上聚合并重新分发。通过仅对缓存模型进行训练和通信，CacheFL在降低资源需求的同时确保了数据隐私和安全。在ImageNet和另外10个数据集上进行的广泛实验表明，CacheFL在分类精度、资源效率和隐私保护方面优于传统方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型预训练视听模型如CLIP在图像分类任务中表现出优秀的零样本性能。</li>
<li>模型的微调在特定领域数据集上能够提升其在下游应用中的效果。</li>
<li>云环境中模型微调存在数据安全和隐私的担忧。</li>
<li>联邦学习（FL）提供了一种去中心化的训练方式，但全模型传输导致的通信和计算成本高。</li>
<li>CacheFL方法通过轻量级的缓存模型微调来提高效率和性能。</li>
<li>缓存模型使用类别平衡数据集初始化，减轻非IID数据的影响。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05130">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d3db8146717338d64cb948d7f481a9c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3fc609fe6200169a52c8046f3eef9a25.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6734d90a1a1a38bb16504fb2c851df1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7b684e50c9e8d4ac6b5e6d6518e209ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-05cf617fa32a973d3acb54eca518a502.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-657a64f73c489ede6602f9c6ed86a81c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Search-is-All-You-Need-for-Few-shot-Anomaly-Detection"><a href="#Search-is-All-You-Need-for-Few-shot-Anomaly-Detection" class="headerlink" title="Search is All You Need for Few-shot Anomaly Detection"></a>Search is All You Need for Few-shot Anomaly Detection</h2><p><strong>Authors:Qishan Wang, Jia Guo, Shuyong Gao, Haofen Wang, Li Xiong, Junjie Hu, Hanqi Guo, Wenqiang Zhang</strong></p>
<p>Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging task in industrial inspection, where normal distribution modeling must be accomplished with only a few normal images. While existing approaches typically employ multi-modal foundation models combining language and vision modalities for prompt-guided anomaly detection, these methods often demand sophisticated prompt engineering and extensive manual tuning. In this paper, we demonstrate that a straightforward nearest-neighbor search framework can surpass state-of-the-art performance in both single-class and multi-class FSAD scenarios. Our proposed method, VisionAD, consists of four simple yet essential components: (1) scalable vision foundation models that extract universal and discriminative features; (2) dual augmentation strategies - support augmentation to enhance feature matching adaptability and query augmentation to address the oversights of single-view prediction; (3) multi-layer feature integration that captures both low-frequency global context and high-frequency local details with minimal computational overhead; and (4) a class-aware visual memory bank enabling efficient one-for-all multi-class detection. Extensive evaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate VisionAD’s exceptional performance. Using only 1 normal images as support, our method achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8% respectively, outperforming current state-of-the-art approaches by significant margins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior few-shot capabilities of VisionAD make it particularly appealing for real-world applications where samples are scarce or expensive to obtain. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Qiqigeww/VisionAD">https://github.com/Qiqigeww/VisionAD</a>. </p>
<blockquote>
<p>少量样本异常检测（FSAD）在工业检测中是一项至关重要且充满挑战的任务，只需要少量的正常图像即可完成正常分布建模。尽管现有方法通常采用多模态基础模型，结合语言和视觉模式进行提示引导异常检测，但这些方法往往需要进行复杂的提示工程和大量的手动调整。在本文中，我们证明了一个简单的最近邻搜索框架可以在单类和多类FSAD场景中超越最新技术性能。我们提出的方法VisionAD由四个简单但至关重要的组件构成：（1）可扩展的视觉基础模型，用于提取通用和判别特征；（2）双增强策略——支持增强以提高特征匹配的适应性，查询增强以解决单视图预测的遗漏；（3）多层特征融合，以最小的计算开销捕获低频全局上下文和高频局部细节；（4）类感知视觉内存库，实现高效的一对多类检测。在MVTec-AD、VisA和Real-IAD基准测试上的广泛评估表明，VisionAD具有卓越的性能。仅使用1张正常图像作为支持，我们的方法在图像级AUROC得分上分别实现了97.4%、94.8%和70.8%的显著成绩，显著超越了当前的最先进方法（+1.6%、+3.2%和+1.4%）。VisionAD的无训练性质和优越的少量样本能力使其成为在现实世界应用中特别吸引人的选择，尤其是在样本稀缺或难以获取的情况下。相关代码可通过<a target="_blank" rel="noopener" href="https://github.com/Qiqigeww/VisionAD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Qiqigeww/VisionAD获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11895v2">PDF</a> </p>
<p><strong>Summary</strong><br>    本论文提出了一种基于最近邻搜索框架的通用少样本异常检测框架VisionAD。其主要贡献包括利用可扩展的视觉基础模型提取特征、双重增强策略提高特征匹配适应性及解决单视图预测缺陷、多层级特征融合捕捉全局与局部细节信息，以及建立类感知视觉记忆库实现多类检测效率。在MVTec-AD等数据集上，使用仅一个正常图像作为支持样本，VisionAD实现了显著的性能提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VisionAD利用最近邻搜索框架在少样本异常检测中表现优异。</li>
<li>VisionAD包含四个关键组件：可扩展视觉基础模型、双重增强策略、多层级特征融合和类感知视觉记忆库。</li>
<li>VisionAD在MVTec-AD等数据集上实现了显著的性能提升，使用仅一个正常图像作为支持样本。</li>
<li>VisionAD具有无需训练的优势，特别适用于样本稀缺或昂贵的真实世界应用。</li>
<li>VisionAD具有高效的多类检测能力。</li>
<li>VisionAD通过结合语言与视觉模态的提示引导异常检测，减少了复杂的手动调整需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11895">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bcee1309aae06551107eed810e479219.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-93ffe254053fd759668e372e54e90347.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9db877ce20b04d448eb7f469457f288c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-473761b5ede54e71d026eb9f557f9dbd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ba9f71e9be97d88c7a2d1b114ba840f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ValuesRAG-Enhancing-Cultural-Alignment-Through-Retrieval-Augmented-Contextual-Learning"><a href="#ValuesRAG-Enhancing-Cultural-Alignment-Through-Retrieval-Augmented-Contextual-Learning" class="headerlink" title="ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented   Contextual Learning"></a>ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented   Contextual Learning</h2><p><strong>Authors:Wonduk Seo, Zonghao Yuan, Yi Bu</strong></p>
<p>Ensuring cultural values alignment in Large Language Models (LLMs) remains a critical challenge, as these models often embed Western-centric biases from their training data, leading to misrepresentations and fairness concerns in cross-cultural applications. Existing approaches such as role assignment and few-shot learning struggle to address these limitations effectively due to their reliance on pre-trained knowledge, limited scalability, and inability to capture nuanced cultural values. To address these issues, we propose ValuesRAG, a novel and effective framework that applies Retrieval-Augmented Generation (RAG) with In-Context Learning (ICL) to integrate cultural and demographic knowledge dynamically during text generation. Leveraging the World Values Survey (WVS) dataset, ValuesRAG first generates summaries of values for each individual. We subsequently curate several representative regional datasets to serve as test datasets and retrieve relevant summaries of values based on demographic features, followed by a reranking step to select the top-k relevant summaries. We evaluate ValuesRAG using 6 diverse regional datasets and show that it consistently outperforms baselines: including zero-shot, role-assignment, few-shot, and hybrid methods, both in main experiments and ablation settings. Notably, ValuesRAG achieves the best overall performance over prior methods, demonstrating its effectiveness in fostering culturally aligned and inclusive AI systems. Our findings underscore the potential of dynamic retrieval-based methods to bridge the gap between global LLM capabilities and localized cultural values. </p>
<blockquote>
<p>确保大型语言模型（LLM）中的文化价值观对齐仍然是一个关键挑战，因为这些模型通常从其训练数据中嵌入西方中心主义的偏见，导致跨文化应用中的误解和公平性问题。现有方法，如角色分配和少样本学习，由于依赖预训练知识、可扩展性有限以及无法捕捉微妙的文化价值观，难以有效地解决这些局限性。为了解决这个问题，我们提出了ValuesRAG，这是一个将检索增强生成（RAG）与上下文学习（ICL）相结合的新型有效框架，用于在文本生成过程中动态整合文化和人口统计数据知识。借助世界价值观调查（WVS）数据集，ValuesRAG首先为每个人生成价值观摘要。随后，我们精心挑选了几个具有代表性的区域数据集作为测试数据集，并根据人口统计特征检索相关的价值观摘要，然后进行重新排序以选择前k个最相关的摘要。我们使用6个不同的区域数据集对ValuesRAG进行了评估，结果表明，与零样本、角色分配、少样本和混合方法相比，无论是在主要实验还是消融设置中，ValuesRAG始终表现出更高的性能。值得注意的是，ValuesRAG在先前的方法中取得了最佳的整体性能，证明了其在促进文化对齐和包容性人工智能系统方面的有效性。我们的研究结果表明了动态检索方法在弥合全球LLM能力与本地化文化价值观之间的差距方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01031v3">PDF</a> preprint</p>
<p><strong>Summary</strong></p>
<p>训练数据中的西方中心偏见导致大型语言模型（LLM）在跨文化应用中存在误表示和公平性担忧的问题。ValuesRAG是一个结合检索增强生成（RAG）和上下文学习（ICL）的新框架，旨在动态集成文化和人口统计知识来进行文本生成，以解决这一问题。它利用世界价值观调查（WVS）数据集为每个个体生成价值观摘要，并根据人口统计特征检索相关的价值观摘要，然后进行重新排序。评估表明，ValuesRAG在多个区域数据集上的表现均优于包括零样本、角色分配、小样本和混合方法在内的基线方法，证明了其在促进文化对齐和包容性人工智能系统方面的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）在跨文化应用中面临文化价值观对齐的挑战，存在西方中心偏见问题。</li>
<li>现有方法如角色分配和少样本学习无法有效解决这个问题，因为它们依赖预训练知识，具有有限的扩展能力，并且无法捕捉细微的文化价值观。</li>
<li>ValuesRAG框架结合了检索增强生成（RAG）和上下文学习（ICL），能够动态集成文化和人口统计知识来进行文本生成。</li>
<li>ValuesRAG利用世界价值观调查（WVS）数据集为每个个体生成价值观摘要，并通过检索和重新排序选择与人口统计特征相关的摘要。</li>
<li>ValuesRAG在多个区域数据集上的表现优于其他方法，证明了其在促进文化对齐和包容性人工智能系统方面的有效性。</li>
<li>ValuesRAG的实现为动态检索方法弥合全球LLM能力和本地化文化价值观之间的差距提供了潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01031">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c7c64170fca253d9924c69b53f134ae3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9b9e4f3b6b85ab15d2695e8184141a49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73ba93f83314fd4bea440ce503258300.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23adeb97f711f844bbcef38e55e3f670.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2088fc377147946c2565d15c8b3bf6ce.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-bd010ac558ed289bc849f7bf15c26b11.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2025-05-10  Benchmarking Ophthalmology Foundation Models for Clinically Significant   Age Macular Degeneration Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-6cd858a7d58c219ebbe442bd4dc8c874.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-05-10  HEXGEN-TEXT2SQL Optimizing LLM Inference Request Scheduling for Agentic   Text-to-SQL Workflow
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
