<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-05-10  SVAD From Single Image to 3D Avatar via Synthetic Data Generation with   Video Diffusion and Data Augmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9a0f7f547c5c0d5070c43eda88d51f67.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    28 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-10-更新"><a href="#2025-05-10-更新" class="headerlink" title="2025-05-10 更新"></a>2025-05-10 更新</h1><h2 id="SVAD-From-Single-Image-to-3D-Avatar-via-Synthetic-Data-Generation-with-Video-Diffusion-and-Data-Augmentation"><a href="#SVAD-From-Single-Image-to-3D-Avatar-via-Synthetic-Data-Generation-with-Video-Diffusion-and-Data-Augmentation" class="headerlink" title="SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with   Video Diffusion and Data Augmentation"></a>SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with   Video Diffusion and Data Augmentation</h2><p><strong>Authors:Yonwoo Choi</strong></p>
<p>Creating high-quality animatable 3D human avatars from a single image remains a significant challenge in computer vision due to the inherent difficulty of reconstructing complete 3D information from a single viewpoint. Current approaches face a clear limitation: 3D Gaussian Splatting (3DGS) methods produce high-quality results but require multiple views or video sequences, while video diffusion models can generate animations from single images but struggle with consistency and identity preservation. We present SVAD, a novel approach that addresses these limitations by leveraging complementary strengths of existing techniques. Our method generates synthetic training data through video diffusion, enhances it with identity preservation and image restoration modules, and utilizes this refined data to train 3DGS avatars. Comprehensive evaluations demonstrate that SVAD outperforms state-of-the-art (SOTA) single-image methods in maintaining identity consistency and fine details across novel poses and viewpoints, while enabling real-time rendering capabilities. Through our data augmentation pipeline, we overcome the dependency on dense monocular or multi-view training data typically required by traditional 3DGS approaches. Extensive quantitative, qualitative comparisons show our method achieves superior performance across multiple metrics against baseline models. By effectively combining the generative power of diffusion models with both the high-quality results and rendering efficiency of 3DGS, our work establishes a new approach for high-fidelity avatar generation from a single image input. </p>
<blockquote>
<p>从单一图像创建高质量的可动画3D人类角色，仍然是计算机视觉领域的一个重大挑战。这是由于从单一视角重建完整的3D信息的固有难度所致。当前的方法存在一个明显的局限性：3D高斯喷溅（3DGS）方法虽然能产生高质量的结果，但需要多个视角或视频序列，而视频扩散模型虽然可以从单个图像生成动画，但在一致性和身份保持方面却存在困难。我们提出了SVAD这一新方法，它通过利用现有技术的互补优势来解决这些局限性。我们的方法通过视频扩散生成合成训练数据，通过身份保持和图像恢复模块对其进行增强，并利用这些精细数据训练3DGS角色。综合评估表明，SVAD在保持身份一致性、精细细节以及新型姿势和视角方面，优于最先进的单图像方法，同时实现了实时渲染功能。通过我们的数据增强流程，我们克服了传统3DGS方法通常对密集单眼或多视角训练数据的依赖。大量的定量和定性对比显示，我们的方法在多个指标上优于基线模型。通过有效地结合扩散模型的生成能力与3DGS的高质量结果和渲染效率，我们的工作建立了一种从单个图像输入生成高保真角色的新方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05475v1">PDF</a> Accepted by CVPR 2025 SyntaGen Workshop, Project Page:   <a target="_blank" rel="noopener" href="https://yc4ny.github.io/SVAD/">https://yc4ny.github.io/SVAD/</a></p>
<p><strong>Summary</strong></p>
<p>该文本介绍了在计算机视觉领域创建高质量的可动画三维人类头像的重大挑战。现有方法存在局限性，如需要多视角或视频序列，或面临一致性及身份保持问题。本文提出了一种新方法SVAD，结合现有技术的优势，生成合成训练数据，增强身份保持和图像恢复模块，并利用这些数据训练三维高斯喷涂（3DGS）头像。新方法可在保持身份一致性和细节方面优于单图像方法，并具备实时渲染能力。通过数据增强管道，克服了传统3DGS方法对密集单目或多视角训练数据的依赖。本文结合了扩散模型的生成能力与3DGS的高质量结果和渲染效率，为从单张图像生成高质量头像提供了新的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>当前创建单一图像的高质量可动画三维人类头像是一大挑战。</li>
<li>现有方法如3DGS和视频扩散模型存在局限性。</li>
<li>SVAD方法结合视频扩散模型的生成能力与身份保持和图像恢复模块来生成合成训练数据。</li>
<li>SVAD利用这些数据训练三维高斯喷涂（3DGS）头像，实现高质量结果和实时渲染能力。</li>
<li>SVAD通过数据增强管道克服了对密集单目或多视角训练数据的依赖。</li>
<li>SVAD在保持身份一致性和细节方面优于单图像方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05475">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a2be95e70c3de02aa94a853d1c54a26c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61886fdbd9be482750452cca8b4fca6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c439904c9da32ca25d8c35b71402be1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a0f7f547c5c0d5070c43eda88d51f67.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="3D-Scene-Generation-A-Survey"><a href="#3D-Scene-Generation-A-Survey" class="headerlink" title="3D Scene Generation: A Survey"></a>3D Scene Generation: A Survey</h2><p><strong>Authors:Beichen Wen, Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu</strong></p>
<p>3D scene generation seeks to synthesize spatially structured, semantically meaningful, and photorealistic environments for applications such as immersive media, robotics, autonomous driving, and embodied AI. Early methods based on procedural rules offered scalability but limited diversity. Recent advances in deep generative models (e.g., GANs, diffusion models) and 3D representations (e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene distributions, improving fidelity, diversity, and view consistency. Recent advances like diffusion models bridge 3D scene synthesis and photorealism by reframing generation as image or video synthesis problems. This survey provides a systematic overview of state-of-the-art approaches, organizing them into four paradigms: procedural generation, neural 3D-based generation, image-based generation, and video-based generation. We analyze their technical foundations, trade-offs, and representative results, and review commonly used datasets, evaluation protocols, and downstream applications. We conclude by discussing key challenges in generation capacity, 3D representation, data and annotations, and evaluation, and outline promising directions including higher fidelity, physics-aware and interactive generation, and unified perception-generation models. This review organizes recent advances in 3D scene generation and highlights promising directions at the intersection of generative AI, 3D vision, and embodied intelligence. To track ongoing developments, we maintain an up-to-date project page: <a target="_blank" rel="noopener" href="https://github.com/hzxie/Awesome-3D-Scene-Generation">https://github.com/hzxie/Awesome-3D-Scene-Generation</a>. </p>
<blockquote>
<p>三维场景生成旨在合成具有空间结构、语义和逼真的环境，为沉浸式媒体、机器人技术、自动驾驶和人工智能等应用提供支持。早期基于程序规则的方法提供了可扩展性但限制了多样性。最近深度生成模型（如GANs和扩散模型）和三维表示（如NeRF和三维高斯）的进步使得学习真实场景分布成为可能，提高了逼真度、多样性和视角一致性。最近的扩散模型等技术通过将生成重新构建为图像或视频合成问题，从而实现了三维场景合成与逼真性的结合。这篇综述系统地概述了当前先进技术的方法，将它们归纳为四种范式：程序生成、基于神经的三维生成、基于图像的生成和基于视频的生成。我们分析了它们的技术基础、权衡和代表性成果，并回顾了常用的数据集、评估协议和下游应用。最后，我们讨论了生成能力、三维表示、数据和注释以及评估方面的关键挑战，并概述了具有前景的方向，包括更高的逼真度、物理感知和交互式生成以及统一的感知生成模型。这篇综述整理了三维场景生成的最新进展，并强调了生成人工智能、三维视觉和人工智能交叉领域的具有前景的方向。要了解最新进展，请访问我们的项目页面：<a target="_blank" rel="noopener" href="https://github.com/hzxie/Awesome-3D-Scene-Generation%E3%80%82">https://github.com/hzxie/Awesome-3D-Scene-Generation。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05474v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://github.com/hzxie/Awesome-3D-Scene-Generation">https://github.com/hzxie/Awesome-3D-Scene-Generation</a></p>
<p><strong>Summary</strong></p>
<p>这篇论文综述了当前三维场景生成的前沿技术，概述了四种主要方法：基于过程的生成、基于神经的三维生成、基于图像的生成和基于视频的生成。文章分析了它们的技术基础、优缺点及典型成果，并讨论了生成能力、三维表征、数据和标注、评估中的关键挑战，以及未来发展方向，包括更高保真度、物理感知和交互式生成以及统一的感知生成模型等。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D场景生成旨在合成用于沉浸式媒体、机器人技术、自动驾驶和嵌入式人工智能等应用的空间结构、语义丰富和逼真的环境。</li>
<li>早期基于过程规则的方法虽然具有良好的可扩展性，但多样性有限。</li>
<li>深度生成模型（如GANs和扩散模型）和3D表示（如NeRF和3D高斯）的最新进展推动了学习现实场景分布的能力，提高了逼真度、多样性和视图一致性。</li>
<li>扩散模型等最新技术通过重新构建图像或视频合成问题，将3D场景合成与逼真性联系起来。</li>
<li>文章概述了当前研究的主要挑战，包括生成能力、3D表征技术和评价协议等。</li>
<li>文章强调了未来发展方向，包括提高保真度、物理感知和交互式生成以及统一的感知生成模型等。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05474">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c14f07200e7b00574de4cbff9d1fb309.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-860fdec74d557d4e5fdbe5f7828924c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91c13532cdfbbf395edcd0c5d25da980.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2cb32e3058d6aeb29684431d549e7777.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Time-of-the-Flight-of-the-Gaussians-Optimizing-Depth-Indirectly-in-Dynamic-Radiance-Fields"><a href="#Time-of-the-Flight-of-the-Gaussians-Optimizing-Depth-Indirectly-in-Dynamic-Radiance-Fields" class="headerlink" title="Time of the Flight of the Gaussians: Optimizing Depth Indirectly in   Dynamic Radiance Fields"></a>Time of the Flight of the Gaussians: Optimizing Depth Indirectly in   Dynamic Radiance Fields</h2><p><strong>Authors:Runfeng Li, Mikhail Okunev, Zixuan Guo, Anh Ha Duong, Christian Richardt, Matthew O’Toole, James Tompkin</strong></p>
<p>We present a method to reconstruct dynamic scenes from monocular continuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that achieves similar or better accuracy than neural volumetric approaches and is 100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a single viewpoint is a significant challenge in computer vision. In C-ToF radiance field reconstruction, the property of interest-depth-is not directly measured, causing an additional challenge. This problem has a large and underappreciated impact upon the optimization when using a fast primitive-based scene representation like 3D Gaussian splatting, which is commonly used with multi-view data to produce satisfactory results and is brittle in its optimization otherwise. We incorporate two heuristics into the optimization to improve the accuracy of scene geometry represented by Gaussians. Experimental results show that our approach produces accurate reconstructions under constrained C-ToF sensing conditions, including for fast motions like swinging baseball bats. <a target="_blank" rel="noopener" href="https://visual.cs.brown.edu/gftorf">https://visual.cs.brown.edu/gftorf</a> </p>
<blockquote>
<p>我们提出了一种利用单眼连续波飞行时间（C-ToF）相机的原始传感器样本重建动态场景的方法，该方法可以达到或超过神经体积方法的准确性，并且速度提高了100倍。从单一视角快速实现高保真动态3D重建是计算机视觉领域的一个重大挑战。在C-ToF辐射场重建中，感兴趣的深度属性并不能直接测量，这造成了额外的挑战。在使用基于原始场景的快速表示方法（如用于产生满意结果的3D高斯涂斑法）时，这个问题会对优化产生很大且被低估的影响。我们采用了两种启发式方法来优化高斯表示的场景几何的准确性。实验结果表明，我们的方法在受限的C-ToF感应条件下能产生准确的重建效果，包括快速运动如挥动棒球棒等。<a target="_blank" rel="noopener" href="https://visual.cs.brown.edu/gftorf">具体链接</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05356v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种利用单目连续波飞行时间（C-ToF）相机原始传感器样本重建动态场景的方法，该方法在保持与神经体积方法相似或更高的准确性的同时，速度提高了100倍。对于从单一视角快速实现高保真动态3D重建这一计算机视觉领域的重大挑战，该方法解决了C-ToF辐射场重建中深度信息未直接测量的问题，并采用两种启发式优化策略提高了高斯表示的几何场景的准确性。实验结果表明，该方法在受限的C-ToF传感条件下对快速运动场景也能进行准确重建。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>方法使用单目连续波飞行时间（C-ToF）相机实现动态场景的快速重建。</li>
<li>该方法具有与神经体积方法相似的准确性，但速度提高了100倍。</li>
<li>在C-ToF辐射场重建中解决了深度信息未直接测量的问题。</li>
<li>采用两种启发式优化策略提高高斯表示的几何场景的准确性。</li>
<li>实验结果证明，该方法能处理快速运动场景的重建，如摇摆的棒球棍。</li>
<li>该方法适用于受限的C-ToF传感条件。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05356">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e0b6b0349e0005b7dc13ecb9137dfe1e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47dd9448e5deda01c7daa445400aabb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c2811171738b57790b2398d4d49f6bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bbde533e0e3ef8fe0c16a09928aca2e0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MoRe-3DGSMR-Motion-resolved-reconstruction-framework-for-free-breathing-pulmonary-MRI-based-on-3D-Gaussian-representation"><a href="#MoRe-3DGSMR-Motion-resolved-reconstruction-framework-for-free-breathing-pulmonary-MRI-based-on-3D-Gaussian-representation" class="headerlink" title="MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing   pulmonary MRI based on 3D Gaussian representation"></a>MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing   pulmonary MRI based on 3D Gaussian representation</h2><p><strong>Authors:Tengya Peng, Ruyi Zha, Qing Zou</strong></p>
<p>This study presents an unsupervised, motion-resolved reconstruction framework for high-resolution, free-breathing pulmonary magnetic resonance imaging (MRI), utilizing a three-dimensional Gaussian representation (3DGS). The proposed method leverages 3DGS to address the challenges of motion-resolved 3D isotropic pulmonary MRI reconstruction by enabling data smoothing between voxels for continuous spatial representation. Pulmonary MRI data acquisition is performed using a golden-angle radial sampling trajectory, with respiratory motion signals extracted from the center of k-space in each radial spoke. Based on the estimated motion signal, the k-space data is sorted into multiple respiratory phases. A 3DGS framework is then applied to reconstruct a reference image volume from the first motion state. Subsequently, a patient-specific convolutional neural network is trained to estimate the deformation vector fields (DVFs), which are used to generate the remaining motion states through spatial transformation of the reference volume. The proposed reconstruction pipeline is evaluated on six datasets from six subjects and bench-marked against three state-of-the-art reconstruction methods. The experimental findings demonstrate that the proposed reconstruction framework effectively reconstructs high-resolution, motion-resolved pulmonary MR images. Compared with existing approaches, it achieves superior image quality, reflected by higher signal-to-noise ratio and contrast-to-noise ratio. The proposed unsupervised 3DGS-based reconstruction method enables accurate motion-resolved pulmonary MRI with isotropic spatial resolution. Its superior performance in image quality metrics over state-of-the-art methods highlights its potential as a robust solution for clinical pulmonary MR imaging. </p>
<blockquote>
<p>本研究提出了一种基于三维高斯表示（3DGS）的无监督、动态解析重建框架，用于高分辨率、自由呼吸的肺部磁共振成像（MRI）。该方法利用3DGS解决动态解析的3D立体肺部MRI重建的挑战，通过在体素之间进行数据平滑处理，实现连续的空间表示。肺部MRI数据采集采用金角径向采样轨迹，从每个径向射线的k空间中心提取呼吸运动信号。基于估计的运动信号，将k空间数据分为多个呼吸阶段。然后应用3DGS框架从第一个运动状态重建参考图像体积。随后，训练患者特定的卷积神经网络来估计变形矢量场（DVF），用于通过参考体积的空间变换生成其余的运动状态。该重建流水线在六个受试者数据集上进行了评估，并与三种最先进的重建方法进行了基准测试。实验结果表明，该重建框架有效地重建了高分辨率的肺部MRI图像序列。与现有方法相比，它在信号噪声比和对比噪声比方面表现出更高的图像质量。这种基于无监督的3DGS重建方法可实现精确的动态解析肺部MRI，具有立体空间分辨率。其在图像质量指标上的卓越性能，突出了其在临床肺部MRI成像中的稳健解决方案潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04959v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本研究提出了一种基于三维高斯表示（3DGS）的无监督、动态解析重建框架，用于高分辨、自由呼吸的肺部磁共振成像（MRI）。该研究利用3DGS解决动态解析的3D立体肺部MRI重建难题，通过优化数据在体素间的平滑处理，实现连续的空间表示。该研究采用黄金角径向采样轨迹进行肺部MRI数据采集，从每个径向射线的k空间中心提取呼吸运动信号。基于估计的运动信号，将k空间数据按多个呼吸阶段排序。使用3DGS框架从第一个运动状态重建参考图像体积。然后，训练患者特定的卷积神经网络来估计变形矢量场（DVFs），用于通过参考体积的空间变换生成其余的运动状态。该重建流程在六个来自六个受试者的数据集上进行了评估，并与三种最先进的重建方法进行了比较。实验结果表明，所提出的重建框架有效地重建了高分辨、动态解析的肺部MR图像。相较于现有方法，它在图像质量和噪声比方面表现更优。该无监督的基于3DGS的重建方法可实现准确的动态解析肺部MRI，具有各向同性分辨率。其在图像质量指标上的卓越性能表明其在临床肺部MR成像中的稳健解决方案潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本研究提出了一种基于三维高斯表示（3DGS）的无监督重建框架，用于自由呼吸的肺部磁共振成像（MRI）。</li>
<li>利用3DGS解决动态解析的肺部MRI重建难题，实现数据在连续空间内的平滑表示。</li>
<li>采用黄金角径向采样轨迹进行肺部MRI数据采集，并从k空间中心提取呼吸运动信号。</li>
<li>基于估计的运动信号，将k空间数据分为多个呼吸阶段，并使用3DGS框架从第一个运动状态重建参考图像体积。</li>
<li>利用卷积神经网络估计变形矢量场（DVFs），用于生成其余运动状态。</li>
<li>该方法在实验数据集上的表现优于三种最先进的重建方法，具有更高的图像质量和噪声比。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04959">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1e662333de0d65b3180582a4191c517c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SGCR-Spherical-Gaussians-for-Efficient-3D-Curve-Reconstruction"><a href="#SGCR-Spherical-Gaussians-for-Efficient-3D-Curve-Reconstruction" class="headerlink" title="SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction"></a>SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction</h2><p><strong>Authors:Xinran Yang, Donghao Ji, Yuanqi Li, Jie Guo, Yanwen Guo, Junyuan Xie</strong></p>
<p>Neural rendering techniques have made substantial progress in generating photo-realistic 3D scenes. The latest 3D Gaussian Splatting technique has achieved high quality novel view synthesis as well as fast rendering speed. However, 3D Gaussians lack proficiency in defining accurate 3D geometric structures despite their explicit primitive representations. This is due to the fact that Gaussian’s attributes are primarily tailored and fine-tuned for rendering diverse 2D images by their anisotropic nature. To pave the way for efficient 3D reconstruction, we present Spherical Gaussians, a simple and effective representation for 3D geometric boundaries, from which we can directly reconstruct 3D feature curves from a set of calibrated multi-view images. Spherical Gaussians is optimized from grid initialization with a view-based rendering loss, where a 2D edge map is rendered at a specific view and then compared to the ground-truth edge map extracted from the corresponding image, without the need for any 3D guidance or supervision. Given Spherical Gaussians serve as intermedia for the robust edge representation, we further introduce a novel optimization-based algorithm called SGCR to directly extract accurate parametric curves from aligned Spherical Gaussians. We demonstrate that SGCR outperforms existing state-of-the-art methods in 3D edge reconstruction while enjoying great efficiency. </p>
<blockquote>
<p>神经渲染技术在生成逼真的三维场景方面取得了重大进展。最新的三维高斯平铺技术实现了高质量的新型视图合成以及快速的渲染速度。然而，尽管三维高斯具有明确的原始表示，但它们在定义准确的三维几何结构方面并不熟练。这是由于高斯属性主要是为了利用其各向异性来渲染各种二维图像而定制和精细调整的。为了为高效的3D重建铺平道路，我们提出了球形高斯（Spherical Gaussians），这是一种用于三维几何边界的简单有效的表示方法，我们可以直接从一组校准的多视图图像重建三维特征曲线。球形高斯通过基于视图的渲染损失从网格初始化进行优化，其中在特定视图上呈现二维边缘图，然后将其与从相应图像中提取的真实边缘图进行比较，无需任何三维指导或监督。由于球形高斯充当稳健边缘表示的媒介，我们进一步引入了一种基于优化的新算法SGCR（球面高斯曲线重建算法），该算法直接从对齐的球形高斯中提取准确的参数曲线。我们证明了SGCR在三维边缘重建方面的表现优于现有先进技术，同时具有很高的效率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04668v1">PDF</a> The IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition   2025, 8 pages</p>
<p><strong>Summary</strong></p>
<p>最新的三维高斯涂抹技术虽可实现高质量的新型视图合成和快速渲染速度，但在定义准确的3D几何结构方面存在不足。为此，我们提出球形高斯，这是一种简单有效的三维几何边界表示方法，可从一系列校准的多视图图像中直接重建三维特征曲线。我们进一步引入了一种基于优化的算法SGCR，可从对齐的球形高斯中提取准确的参数曲线。SGCR在三维边缘重建中表现优于现有方法，同时具有高效性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>神经渲染技术在生成逼真的三维场景方面取得了重大进展。</li>
<li>最新三维高斯涂抹技术实现了高质量的新型视图合成和快速渲染。</li>
<li>现有的三维几何结构定义存在不足，主要局限在二维图像渲染上。</li>
<li>提出球形高斯作为新的三维几何边界表示方法，适用于从多视图图像重建三维特征曲线。</li>
<li>球形高斯通过网格初始化优化，采用基于视图的渲染损失进行渲染。</li>
<li>引入了一种新的优化算法SGCR，可从对齐的球形高斯中提取准确的参数曲线。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04668">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-97db455c750426c6eaf8b576e6c47cc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2024c1ce1ac9f61841494d60f18346b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0417ab5086446a456e272a036d8560e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50fe073ed4ea96b29811f12eabb1d3e1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GSsplat-Generalizable-Semantic-Gaussian-Splatting-for-Novel-view-Synthesis-in-3D-Scenes"><a href="#GSsplat-Generalizable-Semantic-Gaussian-Splatting-for-Novel-view-Synthesis-in-3D-Scenes" class="headerlink" title="GSsplat: Generalizable Semantic Gaussian Splatting for Novel-view   Synthesis in 3D Scenes"></a>GSsplat: Generalizable Semantic Gaussian Splatting for Novel-view   Synthesis in 3D Scenes</h2><p><strong>Authors:Feng Xiao, Hongbin Xu, Wanlin Liang, Wenxiong Kang</strong></p>
<p>The semantic synthesis of unseen scenes from multiple viewpoints is crucial for research in 3D scene understanding. Current methods are capable of rendering novel-view images and semantic maps by reconstructing generalizable Neural Radiance Fields. However, they often suffer from limitations in speed and segmentation performance. We propose a generalizable semantic Gaussian Splatting method (GSsplat) for efficient novel-view synthesis. Our model predicts the positions and attributes of scene-adaptive Gaussian distributions from once input, replacing the densification and pruning processes of traditional scene-specific Gaussian Splatting. In the multi-task framework, a hybrid network is designed to extract color and semantic information and predict Gaussian parameters. To augment the spatial perception of Gaussians for high-quality rendering, we put forward a novel offset learning module through group-based supervision and a point-level interaction module with spatial unit aggregation. When evaluated with varying numbers of multi-view inputs, GSsplat achieves state-of-the-art performance for semantic synthesis at the fastest speed. </p>
<blockquote>
<p>在三维场景理解研究中，从未见过的场景从多个视角进行语义合成至关重要。当前的方法能够通过重建可概括的神经辐射场来生成新型视角图像和语义地图。然而，它们在速度和分割性能上往往存在局限性。我们提出了一种通用的语义高斯飞溅方法（GSsplat）来进行高效的新型视角合成。我们的模型从一次输入预测场景自适应高斯分布的位置和属性，取代了传统场景特定高斯飞溅的密集化和修剪过程。在多任务框架下，设计了一个混合网络来提取颜色和语义信息并预测高斯参数。为了提高高斯的空间感知以进行高质量渲染，我们提出了通过基于组的监督和点级交互模块与空间单位聚合相结合的新型偏移学习模块。在多种不同数量的多视角输入进行评估时，GSsplat在语义合成方面实现了最快速度和最先进的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04659v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文研究了基于神经网络辐射场（Neural Radiance Fields）的三维场景理解中的语义合成问题。针对现有方法的速度和分割性能方面的局限性，提出了一种通用的语义高斯Splatting方法（GSsplat）。该方法通过一次输入预测场景自适应高斯分布的位置和属性，实现高效的新型视角合成。在混合任务框架中设计了一个混合网络来提取颜色和语义信息并预测高斯参数。为了提高高斯的空间感知能力以实现高质量渲染，提出了新型偏移学习模块和基于空间单位聚合的点级交互模块。实验表明，GSsplat在多视角输入不同数量的情况下，实现了语义合成的最佳性能，同时速度最快。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>三维场景理解中的语义合成是从多个视角对未见场景进行理解的关键。</li>
<li>当前方法通过重建可概括的神经网络辐射场进行新型视角图像和语义地图的渲染。</li>
<li>现有方法存在速度和分割性能方面的局限性。</li>
<li>提出的GSsplat方法通过一次输入预测场景自适应高斯分布的位置和属性，实现高效的新型视角合成。</li>
<li>GSsplat设计了混合网络来提取颜色和语义信息，并预测高斯参数。</li>
<li>为了提高高斯的空间感知能力，引入了偏移学习模块和点级交互模块。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04659">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-eb4a291144792fc74d21bc074f1b4c1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7271002fe07041ebe1f01be27e037123.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-604afe69df333804a6e043298c97e186.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ddb1898e8c11930cc2c8d842bc6bb6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f3d058bc12166d04926349917d5ef508.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da827e5f77aa63a2d61faf27d65528f9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="PhysFlow-Unleashing-the-Potential-of-Multi-modal-Foundation-Models-and-Video-Diffusion-for-4D-Dynamic-Physical-Scene-Simulation"><a href="#PhysFlow-Unleashing-the-Potential-of-Multi-modal-Foundation-Models-and-Video-Diffusion-for-4D-Dynamic-Physical-Scene-Simulation" class="headerlink" title="PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and   Video Diffusion for 4D Dynamic Physical Scene Simulation"></a>PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and   Video Diffusion for 4D Dynamic Physical Scene Simulation</h2><p><strong>Authors:Zhuoman Liu, Weicai Ye, Yan Luximon, Pengfei Wan, Di Zhang</strong></p>
<p>Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles. However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials. We introduce PhysFlow, a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation. Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation. We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss. This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations. </p>
<blockquote>
<p>真实场景的动态模拟需要准确捕捉各种材料属性，并基于物理原理对复杂的物体交互进行建模。然而，现有方法仅限于具有有限可预测参数的基本材料类型，无法代表真实世界材料的复杂性。我们引入了PhysFlow，这是一种利用多模态基础模型和视频扩散来实现增强的4D动态场景模拟的新方法。我们的方法利用多模态模型通过图像查询识别材料类型并初始化材料参数，同时推断3D高斯斑点用于详细的场景表示。我们进一步使用可微分的物质点法（MPM）和光流指导，而不是渲染损失或评分蒸馏采样（SDS）损失，来完善这些材料参数。这一综合框架能够准确预测和模拟真实场景中的动态交互，提高基于物理的模拟的准确性和灵活性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.14423v4">PDF</a> CVPR 2025. Homepage: <a target="_blank" rel="noopener" href="https://zhuomanliu.github.io/PhysFlow/">https://zhuomanliu.github.io/PhysFlow/</a></p>
<p><strong>Summary</strong><br>现实动态场景的模拟需要准确捕捉各种材料属性并基于物理原理模拟复杂的物体交互。现有方法受限于基本材料类型和有限的可预测参数，无法代表真实世界的复杂性。我们引入了PhysFlow，这是一种利用多模态基础模型和视频扩散来实现增强的四维动态场景模拟的新方法。我们的方法使用多模态模型通过图像查询识别材料类型并初始化材料参数，同时推断三维高斯斑点进行详细的场景表示。我们进一步使用可区分的物质点法（MPM）和光流指导的视频扩散来优化这些材料参数，而不是使用渲染损失或评分蒸馏采样（SDS）损失。这一综合框架为实现真实场景中动态交互的准确预测和模拟提供了可能，提高了物理模拟的准确性和灵活性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现实动态场景模拟需要捕捉材料属性和复杂物体交互。</li>
<li>现有模拟方法存在对材料类型和可预测参数的局限性。</li>
<li>PhysFlow利用多模态基础模型和视频扩散增强四维动态场景模拟。</li>
<li>多模态模型可识别材料类型并初始化材料参数，通过图像查询进行。</li>
<li>使用三维高斯斑点进行详细的场景表示。</li>
<li>通过可区分的物质点法（MPM）和光流指导的视频扩散优化材料参数。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.14423">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9b99826b36dd74387e0f66eecf96cb08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c09963984c1b5b738996f4f484688193.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87d11d8f0496dc06610c3b247b06e27f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c965a6e9191d6e93ce3939e2a5bf8683.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-def3c97017b8fc1e1e507ea27fdb981e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-10/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-860fdec74d557d4e5fdbe5f7828924c4.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-05-10  3D Scene Generation A Survey
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-10/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9a0f7f547c5c0d5070c43eda88d51f67.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-05-10  SVAD From Single Image to 3D Avatar via Synthetic Data Generation with   Video Diffusion and Data Augmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27083.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
