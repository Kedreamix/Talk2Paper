<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-23  Towards Faithful and Controllable Personalization via Critique-Post-Edit   Reinforcement Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-8bedb78797f5c0f238db7ac71b82ed53')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-23-æ›´æ–°"><a href="#2025-10-23-æ›´æ–°" class="headerlink" title="2025-10-23 æ›´æ–°"></a>2025-10-23 æ›´æ–°</h1><h2 id="Towards-Faithful-and-Controllable-Personalization-via-Critique-Post-Edit-Reinforcement-Learning"><a href="#Towards-Faithful-and-Controllable-Personalization-via-Critique-Post-Edit-Reinforcement-Learning" class="headerlink" title="Towards Faithful and Controllable Personalization via Critique-Post-Edit   Reinforcement Learning"></a>Towards Faithful and Controllable Personalization via Critique-Post-Edit   Reinforcement Learning</h2><p><strong>Authors:Chenghao Zhu, Meiling Tao, Tiannan Wang, Dongyi Ding, Yuchen Eleanor Jiang, Wangchunshu Zhou</strong></p>
<p>Faithfully personalizing large language models (LLMs) to align with individual user preferences is a critical but challenging task. While supervised fine-tuning (SFT) quickly reaches a performance plateau, standard reinforcement learning from human feedback (RLHF) also struggles with the nuances of personalization. Scalar-based reward models are prone to reward hacking which leads to verbose and superficially personalized responses. To address these limitations, we propose Critique-Post-Edit, a robust reinforcement learning framework that enables more faithful and controllable personalization. Our framework integrates two key components: (1) a Personalized Generative Reward Model (GRM) that provides multi-dimensional scores and textual critiques to resist reward hacking, and (2) a Critique-Post-Edit mechanism where the policy model revises its own outputs based on these critiques for more targeted and efficient learning. Under a rigorous length-controlled evaluation, our method substantially outperforms standard PPO on personalization benchmarks. Personalized Qwen2.5-7B achieves an average 11% win-rate improvement, and personalized Qwen2.5-14B model surpasses the performance of GPT-4.1. These results demonstrate a practical path to faithful, efficient, and controllable personalization. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¿ å®ä¸ªæ€§åŒ–ï¼Œä»¥ç¬¦åˆä¸ªäººç”¨æˆ·åå¥½æ˜¯ä¸€é¡¹è‡³å…³é‡è¦ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚è™½ç„¶ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å¯ä»¥å¿«é€Ÿè¾¾åˆ°æ€§èƒ½å³°å€¼ï¼Œä½†æ ‡å‡†çš„äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰åœ¨ä¸ªæ€§åŒ–ç»†èŠ‚æ–¹é¢ä¹Ÿå­˜åœ¨å›°éš¾ã€‚åŸºäºæ ‡é‡çš„å¥–åŠ±æ¨¡å‹å®¹æ˜“é­å—å¥–åŠ±ç ´è§£æ”»å‡»ï¼Œä»è€Œå¯¼è‡´å†—é•¿å’Œè¡¨é¢ä¸Šçš„ä¸ªæ€§åŒ–å›åº”ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Critique-Post-Editï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°æ›´å¿ å®å’Œå¯æ§çš„ä¸ªæ€§åŒ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶é›†æˆäº†ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šï¼ˆ1ï¼‰ä¸ªæ€§åŒ–ç”Ÿæˆå¥–åŠ±æ¨¡å‹ï¼ˆGRMï¼‰ï¼Œæä¾›å¤šç»´åˆ†æ•°å’Œæ–‡æœ¬è¯„ä»·æ¥æŠµæŠ—å¥–åŠ±ç ´è§£ï¼›ï¼ˆ2ï¼‰Critique-Post-Editæœºåˆ¶ï¼Œç­–ç•¥æ¨¡å‹æ ¹æ®è¿™äº›è¯„ä»·ä¿®è®¢å…¶è‡ªå·±çš„è¾“å‡ºæ¥å®ç°æ›´æœ‰é’ˆå¯¹æ€§å’Œé«˜æ•ˆçš„å­¦ä¹ ã€‚åœ¨ä¸¥æ ¼æ§åˆ¶çš„é•¿åº¦è¯„ä¼°ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ªæ€§åŒ–åŸºå‡†æµ‹è¯•ä¸Šå¤§å¤§ä¼˜äºæ ‡å‡†PPOã€‚ä¸ªæ€§åŒ–Qwen2.5-7Bçš„å¹³å‡èƒœç‡æé«˜äº†11%ï¼Œä¸ªæ€§åŒ–Qwen2.5-14Bæ¨¡å‹è¶…è¶Šäº†GPT-4.1çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœå±•ç¤ºäº†ä¸€æ¡å®ç°å¿ å®ã€é«˜æ•ˆå’Œå¯æ§ä¸ªæ€§åŒ–çš„å®ç”¨é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18849v1">PDF</a> work in progress</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å®ç°ä¸ªæ€§åŒ–æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚æ–‡ç« æŒ‡å‡ºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒåŸºäºäººç±»åé¦ˆçš„æ ‡å‡†å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰åœ¨ä¸ªæ€§åŒ–æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¹¶æå‡ºäº†åä¸ºCritique-Post-Editçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶æ¥æ›´æœ‰æ•ˆåœ°å®ç°ä¸ªæ€§åŒ–ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šä¸€æ˜¯Personalized Generative Reward Modelï¼ˆGRMï¼‰ï¼Œæä¾›å¤šç»´è¯„åˆ†å’Œæ–‡æœ¬è¯„ä»·æ¥æŠµæŠ—å¥–åŠ±é»‘å®¢æ”»å‡»ï¼›äºŒæ˜¯Critique-Post-Editæœºåˆ¶ï¼Œç­–ç•¥æ¨¡å‹æ ¹æ®è¿™äº›è¯„ä»·ä¿®è®¢è‡ªå·±çš„è¾“å‡ºï¼Œä»¥å®ç°æ›´æœ‰é’ˆå¯¹æ€§çš„é«˜æ•ˆå­¦ä¹ ã€‚åœ¨ä¸¥æ ¼çš„é•¿åº¦æ§åˆ¶è¯„ä¼°ä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ªäººåŒ–åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæ ‡å‡†PPOã€‚ä¸ªæ€§åŒ–çš„Qwen2.5-7Bæ¨¡å‹å¹³å‡æå‡äº†11%çš„èƒœç‡ï¼Œè€Œä¸ªæ€§åŒ–çš„Qwen2.5-14Bæ¨¡å‹æ€§èƒ½è¶…è¿‡äº†GPT-4.1ã€‚è¿™ä¸€å®è·µé€”å¾„å®ç°äº†ä¸ªæ€§åŒ–æ¨¡å‹çš„å¿ è¯šã€é«˜æ•ˆå’Œå¯æ§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®ç°ä¸ªæ€§åŒ–æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œä½†è‡³å…³é‡è¦çš„ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰åœ¨ä¸ªæ€§åŒ–æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æå‡ºçš„Critique-Post-Editå¼ºåŒ–å­¦ä¹ æ¡†æ¶æ—¨åœ¨æ›´å¿ å®ã€å¯æ§åœ°å®ç°ä¸ªæ€§åŒ–ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…å«Personalized Generative Reward Modelï¼ˆGRMï¼‰å’ŒCritique-Post-Editæœºåˆ¶ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ã€‚</li>
<li>GRMæä¾›å¤šç»´è¯„åˆ†å’Œæ–‡æœ¬è¯„ä»·ï¼ŒæŠµæŠ—å¥–åŠ±é»‘å®¢æ”»å‡»ã€‚</li>
<li>Critique-Post-Editæœºåˆ¶ä½¿ç­–ç•¥æ¨¡å‹æ ¹æ®è¯„ä»·ä¿®è®¢è¾“å‡ºï¼Œå®ç°æ›´é«˜æ•ˆã€æœ‰é’ˆå¯¹æ€§çš„å­¦ä¹ ã€‚</li>
<li>åœ¨ä¸ªäººåŒ–åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—ä¼˜äºæ ‡å‡†PPOã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18849">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ece372b6b609f8488d302aa7935e483a" align="middle">
<img src="https://picx.zhimg.com/v2-a29656658d78e111642e1e989643ddb3" align="middle">
<img src="https://picx.zhimg.com/v2-cbe70530880fd980e5e16caaaeb1b738" align="middle">
<img src="https://picx.zhimg.com/v2-94502518bda6eaf33bc6c8ee9bb1b2bd" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Fine-Tuned-Thoughts-Leveraging-Chain-of-Thought-Reasoning-for-Industrial-Asset-Health-Monitoring"><a href="#Fine-Tuned-Thoughts-Leveraging-Chain-of-Thought-Reasoning-for-Industrial-Asset-Health-Monitoring" class="headerlink" title="Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for   Industrial Asset Health Monitoring"></a>Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for   Industrial Asset Health Monitoring</h2><p><strong>Authors:Shuxin Lin, Dhaval Patel, Christodoulos Constantinides</strong></p>
<p>Small Language Models (SLMs) are becoming increasingly popular in specialized fields, such as industrial applications, due to their efficiency, lower computational requirements, and ability to be fine-tuned for domain-specific tasks, enabling accurate and cost-effective solutions. However, performing complex reasoning using SLMs in specialized fields such as Industry 4.0 remains challenging. In this paper, we propose a knowledge distillation framework for industrial asset health, which transfers reasoning capabilities via Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) to smaller, more efficient models (SLMs). We discuss the advantages and the process of distilling LLMs using multi-choice question answering (MCQA) prompts to enhance reasoning and refine decision-making. We also perform in-context learning to verify the quality of the generated knowledge and benchmark the performance of fine-tuned SLMs with generated knowledge against widely used LLMs. The results show that the fine-tuned SLMs with CoT reasoning outperform the base models by a significant margin, narrowing the gap to their LLM counterparts. Our code is open-sourced at: <a target="_blank" rel="noopener" href="https://github.com/IBM/FailureSensorIQ">https://github.com/IBM/FailureSensorIQ</a>. </p>
<blockquote>
<p>å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰åœ¨å·¥ä¸šåº”ç”¨ç­‰ä¸“é—¨é¢†åŸŸè¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œå› ä¸ºå®ƒä»¬æ•ˆç‡é«˜ã€è®¡ç®—è¦æ±‚ä½ï¼Œå¹¶èƒ½é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œä»è€Œå®ç°ç²¾ç¡®ä¸”ç»æµå®æƒ çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œåœ¨åƒå·¥ä¸š4.0è¿™æ ·çš„ä¸“ä¸šé¢†åŸŸï¼Œä½¿ç”¨SLMè¿›è¡Œå¤æ‚æ¨ç†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢å‘å·¥ä¸šèµ„äº§å¥åº·çš„çŸ¥è¯†è’¸é¦æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰è’¸é¦çš„æ–¹å¼ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›è½¬ç§»åˆ°æ›´å°ã€æ›´æœ‰æ•ˆç‡çš„å°å‹è¯­è¨€æ¨¡å‹ä¸Šã€‚æˆ‘ä»¬è®¨è®ºäº†ä½¿ç”¨å¤šé€‰é—®ç­”ï¼ˆMCQAï¼‰æç¤ºè¿›è¡ŒLLMè’¸é¦çš„ä¼˜åŠ¿å’Œè¿‡ç¨‹ï¼Œä»¥æé«˜æ¨ç†èƒ½åŠ›å¹¶ä¼˜åŒ–å†³ç­–åˆ¶å®šã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œä»¥éªŒè¯ç”ŸæˆçŸ¥è¯†çš„è´¨é‡ï¼Œå¹¶å¯¹æ¯”äº†å¾®è°ƒåçš„SLMä¸å¹¿æ³›ä½¿ç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æ€ç»´é“¾æ¨ç†çš„å¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹æ¯”åŸºç¡€æ¨¡å‹æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„å·®è·ç¼©å°ã€‚æˆ‘ä»¬çš„ä»£ç å·²å¼€æºåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/IBM/FailureSensorIQ%E3%80%82">https://github.com/IBM/FailureSensorIQã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18817v1">PDF</a> Accepted at EMNLP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡é’ˆå¯¹å·¥ä¸šåº”ç”¨ä¸­çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨å¤æ‚æ¨ç†æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†è’¸é¦çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼ŒCoTï¼‰è’¸é¦çš„æ–¹å¼ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›è½¬ç§»åˆ°å°å‹ã€æ›´é«˜æ•ˆçš„æ¨¡å‹ä¸Šã€‚é€šè¿‡å¤šé€‰é—®ç­”ï¼ˆMCQAï¼‰æç¤ºæ¥å¢å¼ºæ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¼˜åŒ–å†³ç­–è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡ç²¾ç»†è°ƒæ•´å¹¶å…·å¤‡CoTæ¨ç†èƒ½åŠ›çš„SLMsåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—è¶…è¶Šäº†åŸºç¡€æ¨¡å‹ï¼Œå¹¶ç¼©å°äº†ä¸LLMsçš„å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„ä¼˜åŠ¿åœ¨äºå…¶æ•ˆç‡å’Œè®¡ç®—èµ„æºéœ€æ±‚è¾ƒä½ï¼Œä¸”èƒ½å¤Ÿé’ˆå¯¹ç‰¹å®šé¢†åŸŸè¿›è¡Œå¾®è°ƒï¼Œæä¾›ç²¾ç¡®å’Œç»æµçš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åœ¨å¤æ‚æ¨ç†æ–¹é¢ï¼Œç‰¹åˆ«æ˜¯åœ¨å·¥ä¸š4.0é¢†åŸŸï¼ŒSLMsä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›è½¬ç§»åˆ°å°å‹æ¨¡å‹çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼ŒCoTï¼‰è’¸é¦é€šè¿‡æ¨¡æ‹Ÿäººç±»çš„æ€è€ƒè¿‡ç¨‹ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡å¤šé€‰é—®ç­”ï¼ˆMCQAï¼‰æç¤ºå¢å¼ºSLMsçš„æ¨ç†èƒ½åŠ›å¹¶è¿›è¡Œå†³ç­–ä¼˜åŒ–ã€‚</li>
<li>ç»è¿‡ç²¾ç»†è°ƒæ•´å¹¶å…·å¤‡CoTæ¨ç†èƒ½åŠ›çš„SLMsæ€§èƒ½æ˜¾è‘—è¶…è¶ŠåŸºç¡€æ¨¡å‹ï¼Œå¹¶æ¥è¿‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18817">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2cdec7f605ab6b07bc1a3db005f265df" align="middle">
<img src="https://picx.zhimg.com/v2-7ba01eb0b4981d54530921ccbacf8627" align="middle">
<img src="https://picx.zhimg.com/v2-35dd2678d1ba08da42903f0a19f5b40c" align="middle">
<img src="https://picx.zhimg.com/v2-cad8a4d33c9bfeb9ab18ee7b3d858755" align="middle">
<img src="https://picx.zhimg.com/v2-13325004a093a7ec4dc6790bcebbabae" align="middle">
<img src="https://picx.zhimg.com/v2-0689919410ea96bf2e1d3e9418ab2e39" align="middle">
<img src="https://picx.zhimg.com/v2-2197c609a2b9f8f010b885e80861ae76" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Online-SFT-for-LLM-Reasoning-Surprising-Effectiveness-of-Self-Tuning-without-Rewards"><a href="#Online-SFT-for-LLM-Reasoning-Surprising-Effectiveness-of-Self-Tuning-without-Rewards" class="headerlink" title="Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning   without Rewards"></a>Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning   without Rewards</h2><p><strong>Authors:Mengqi Li, Lei Zhao, Anthony Man-Cho So, Ruoyu Sun, Xiao Li</strong></p>
<p>We present a simple, self-help online supervised finetuning (OSFT) paradigm for LLM reasoning. In this paradigm, the model generates its own responses and is immediately finetuned on this self-generated data. OSFT is a highly efficient training strategy for LLM reasoning, as it is reward-free and uses just one rollout by default. Experiment results show that OSFT achieves downstream performance on challenging mathematical reasoning tasks comparable to strong reinforcement learning with verifiable rewards (RLVR) methods such as GRPO. Our ablation study further demonstrates the efficiency and robustness of OSFT. The major mechanism of OSFT lies in facilitating the modelâ€™s own existing preference (latent knowledge) learned from pretraining, which leads to reasoning ability improvement. We believe that OSFT offers an efficient and promising alternative to more complex, reward-based training paradigms. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/ElementQi/OnlineSFT">https://github.com/ElementQi/OnlineSFT</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†çš„ç®€å•è‡ªåŠ©åœ¨çº¿ç›‘ç£å¾®è°ƒï¼ˆOSFTï¼‰èŒƒå¼ã€‚åœ¨æ­¤èŒƒå¼ä¸­ï¼Œæ¨¡å‹ç”Ÿæˆè‡ªå·±çš„ç­”æ¡ˆï¼Œå¹¶ç«‹å³æ ¹æ®è¿™äº›è‡ªæˆ‘ç”Ÿæˆçš„æ•°æ®è¿›è¡Œå¾®è°ƒã€‚OSFTæ˜¯ä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†çš„é«˜æ•ˆè®­ç»ƒç­–ç•¥ï¼Œå› ä¸ºå®ƒä¸éœ€è¦å¥–åŠ±ï¼Œå¹¶ä¸”é»˜è®¤åªä½¿ç”¨ä¸€æ¬¡æ»šåŠ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOSFTåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„ä¸‹æ¸¸æ€§èƒ½ä¸å…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ–¹æ³•ï¼ˆå¦‚GRPOï¼‰ç›¸å½“ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†OSFTçš„æ•ˆç‡å’Œç¨³å¥æ€§ã€‚OSFTçš„ä¸»è¦æœºåˆ¶åœ¨äºä¿ƒè¿›æ¨¡å‹ä»é¢„è®­ç»ƒä¸­å­¦åˆ°çš„è‡ªèº«åå¥½ï¼ˆæ½œåœ¨çŸ¥è¯†ï¼‰ï¼Œä»è€Œæé«˜æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬ç›¸ä¿¡OSFTä¸ºæ›´å¤æ‚çš„åŸºäºå¥–åŠ±çš„è®­ç»ƒèŒƒå¼æä¾›äº†é«˜æ•ˆä¸”æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ElementQi/OnlineSFT">https://github.com/ElementQi/OnlineSFT</a>å¤„è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18814v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä»»åŠ¡çš„ç®€å•è‡ªåŠ©åœ¨çº¿å¾®è°ƒï¼ˆOSFTï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•è®©æ¨¡å‹è‡ªè¡Œç”Ÿæˆå“åº”å¹¶ç«‹å³åŸºäºæ­¤æ•°æ®è¿›è¡Œå¾®è°ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOSFTåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸é‡‡ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ–¹æ³•ç›¸è¿‘ï¼Œå¦‚GRPOç­‰ã€‚OSFTçš„ä¸»è¦æœºåˆ¶åœ¨äºä¿ƒè¿›æ¨¡å‹ä»é¢„è®­ç»ƒä¸­å­¦åˆ°çš„åå¥½ï¼ˆéšæ€§çŸ¥è¯†ï¼‰ï¼Œä»è€Œæé«˜å…¶æ¨ç†èƒ½åŠ›ã€‚OSFTä½œä¸ºä¸€ç§é«˜æ•ˆä¸”å‰æ™¯å¹¿é˜”çš„è®­ç»ƒæ–¹æ³•ï¼Œä¸ºæ›´å¤æ‚çš„å¥–åŠ±åŸºç¡€è®­ç»ƒèŒƒå¼æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OSFTæ˜¯ä¸€ç§ç”¨äºLLMæ¨ç†ä»»åŠ¡çš„ç®€å•è‡ªåŠ©åœ¨çº¿å¾®è°ƒæ–¹æ³•ï¼Œè®©æ¨¡å‹è‡ªè¡Œç”Ÿæˆå“åº”å¹¶ç«‹å³å¾®è°ƒã€‚</li>
<li>OSFTæ˜¯ä¸€ç§é«˜æ•ˆè®­ç»ƒç­–ç•¥ï¼Œæ— éœ€å¥–åŠ±ï¼Œé»˜è®¤åªä½¿ç”¨ä¸€æ¬¡æ»šåŠ¨ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOSFTåœ¨æŒ‘æˆ˜æ€§æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¦‚GRPOç›¸å½“ã€‚</li>
<li>OSFTçš„ä¸»è¦æœºåˆ¶åœ¨äºä¿ƒè¿›æ¨¡å‹ä»é¢„è®­ç»ƒä¸­å­¦åˆ°çš„åå¥½ï¼ˆéšæ€§çŸ¥è¯†ï¼‰ã€‚</li>
<li>OSFTå¯¹äºæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æœ‰ç§¯æä½œç”¨ã€‚</li>
<li>OSFTä¸ºä¸€ç§é«˜æ•ˆä¸”å‰æ™¯å¹¿é˜”çš„è®­ç»ƒæ–¹æ³•ï¼Œå¯ä½œä¸ºæ›´å¤æ‚å¥–åŠ±åŸºç¡€è®­ç»ƒèŒƒå¼çš„æ›¿ä»£æ–¹æ¡ˆã€‚</li>
<li>ç›¸å…³ä»£ç å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/ElementQi/OnlineSFT%E3%80%82">https://github.com/ElementQi/OnlineSFTã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18814">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b6d2cdf62e7ec4a17e10438e4f39f10d" align="middle">
<img src="https://picx.zhimg.com/v2-681c290ff58035730a47ad3a263987d0" align="middle">
<img src="https://picx.zhimg.com/v2-89e7377cde71df207064c52fcbcfae84" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="KAT-Coder-Technical-Report"><a href="#KAT-Coder-Technical-Report" class="headerlink" title="KAT-Coder Technical Report"></a>KAT-Coder Technical Report</h2><p><strong>Authors:Zizheng Zhan, Ken Deng, Xiaojiang Zhang, Jinghui Wang, Huaixi Tang, Zhiyi Lai, Haoyang Huang, Wen Xiang, Kun Wu, Wenhao Zhuang, Minglei Zhang, Shaojie Wang, Shangpeng Yan, Kepeng Lei, Zongxian Feng, Huiming Wang, Zheng Lin, Mengtong Li, Mengfei Xie, Yinghan Cui, Xuxing Chen, Chao Wang, Weihao Li, Wenqiang Zhu, Jiarong Zhang, Jingxuan Xu, Songwei Yu, Yifan Yao, Xinping Lei, Han Li, Junqi Xiong, Zuchen Gao, Dailin Li, Haimo Li, Jiaheng Liu, Yuqun Zhang, Junyi Peng, Haotian Zhang, Bin Chen</strong></p>
<p>Recent advances in large language models (LLMs) have enabled progress in agentic coding, where models autonomously reason, plan, and act within interactive software development workflows. However, bridging the gap between static text-based training and dynamic real-world agentic execution remains a core challenge. In this technical report, we present KAT-Coder, a large-scale agentic code model trained through a multi-stage curriculum encompassing Mid-Term Training, Supervised Fine-Tuning (SFT), Reinforcement Fine-Tuning (RFT), and Reinforcement-to-Deployment Adaptation. The Mid-Term stage enhances reasoning, planning, and reflection capabilities through a corpus of real software engineering data and synthetic agentic interactions. The SFT stage constructs a million-sample dataset balancing twenty programming languages, ten development contexts, and ten task archetypes. The RFT stage introduces a novel multi-ground-truth reward formulation for stable and sample-efficient policy optimization. Finally, the Reinforcement-to-Deployment phase adapts the model to production-grade IDE environments using Error-Masked SFT and Tree-Structured Trajectory Training. In summary, these stages enable KAT-Coder to achieve robust tool-use reliability, instruction alignment, and long-context reasoning, forming a deployable foundation for real-world intelligent coding agents. Our KAT series 32B model, KAT-Dev, has been open-sourced on <a target="_blank" rel="noopener" href="https://huggingface.co/Kwaipilot/KAT-Dev">https://huggingface.co/Kwaipilot/KAT-Dev</a>. </p>
<blockquote>
<p>æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•ä¸ºä»£ç†ç¼–ç å¸¦æ¥äº†è¿›æ­¥ï¼Œå…¶ä¸­æ¨¡å‹å¯ä»¥åœ¨äº¤äº’å¼è½¯ä»¶å¼€å‘å·¥ä½œæµä¸­è‡ªä¸»æ¨ç†ã€è§„åˆ’å’Œè¡ŒåŠ¨ã€‚ç„¶è€Œï¼Œå¼¥åˆåŸºäºé™æ€æ–‡æœ¬çš„åŸ¹è®­å’ŒåŠ¨æ€ç°å®ä¸–ç•Œä»£ç†æ‰§è¡Œä¹‹é—´çš„å·®è·ä»æ˜¯æ ¸å¿ƒæŒ‘æˆ˜ã€‚åœ¨æœ¬æŠ€æœ¯æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†KAT-Coderï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡åŒ…æ‹¬ä¸­æœŸåŸ¹è®­ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰å’Œå¼ºåŒ–åˆ°éƒ¨ç½²é€‚åº”çš„å¤šé˜¶æ®µè¯¾ç¨‹è®­ç»ƒçš„å¤§è§„æ¨¡ä»£ç†ç¼–ç æ¨¡å‹ã€‚ä¸­æœŸé˜¶æ®µé€šè¿‡çœŸå®è½¯ä»¶å·¥ç¨‹æ•°æ®å’Œåˆæˆä»£ç†äº¤äº’çš„è¯­æ–™åº“å¢å¼ºäº†æ¨ç†ã€è§„åˆ’å’Œåæ€èƒ½åŠ›ã€‚SFTé˜¶æ®µæ„å»ºäº†ä¸€ä¸ªç™¾ä¸‡æ ·æœ¬æ•°æ®é›†ï¼Œå¹³è¡¡äº†äºŒåç§ç¼–ç¨‹è¯­è¨€ã€åç§å¼€å‘èƒŒæ™¯å’Œåç§ä»»åŠ¡åŸå‹ã€‚RFTé˜¶æ®µå¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šåœ°é¢çœŸå®å¥–åŠ±å…¬å¼ï¼Œç”¨äºç¨³å®šå’Œé«˜æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ã€‚æœ€åï¼Œå¼ºåŒ–åˆ°éƒ¨ç½²é˜¶æ®µä½¿ç”¨é”™è¯¯æ©ç SFTå’Œæ ‘ç»“æ„è½¨è¿¹è®­ç»ƒä½¿æ¨¡å‹é€‚åº”ç”Ÿäº§çº§IDEç¯å¢ƒã€‚æ€»ä¹‹ï¼Œè¿™äº›é˜¶æ®µä½¿KAT-Coderå®ç°äº†ç¨³å¥çš„å·¥å…·ä½¿ç”¨å¯é æ€§ã€æŒ‡ä»¤å¯¹é½å’Œé•¿ä¸Šä¸‹æ–‡æ¨ç†ï¼Œä¸ºç°å®ä¸–ç•Œçš„æ™ºèƒ½ç¼–ç ä»£ç†æä¾›äº†å¯éƒ¨ç½²çš„åŸºç¡€ã€‚æˆ‘ä»¬çš„KATç³»åˆ—32Bæ¨¡å‹KAT-Devå·²åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/Kwaipilot/KAT-Dev">https://huggingface.co/Kwaipilot/KAT-Dev</a>ä¸Šå¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18779v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šè¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥æ¨åŠ¨äº†ç¼–ç¨‹ä»£ç†ç¼–ç çš„å‘å±•ï¼Œè‡ªä¸»æ¨ç†ã€è§„åˆ’å’Œè¡ŒåŠ¨çš„è½¯ä»¶å¼€å‘å·¥ä½œæµç¨‹æˆä¸ºå¯èƒ½ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºKAT-Coderçš„ä»£ç†ç¼–ç æ¨¡å‹ï¼Œé€šè¿‡ä¸­æœŸè®­ç»ƒã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰å’Œå¼ºåŒ–éƒ¨ç½²é€‚åº”ç­‰é˜¶æ®µå®ç°ã€‚è¿™äº›é˜¶æ®µå¢å¼ºäº†æ¨¡å‹åœ¨å·¥å…·ä½¿ç”¨å¯é æ€§ã€æŒ‡ä»¤å¯¹é½å’Œé•¿æœŸä¸Šä¸‹æ–‡æ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œä¸ºç°å®ä¸–ç•Œæ™ºèƒ½ç¼–ç ä»£ç†çš„éƒ¨ç½²å¥ å®šäº†åŸºç¡€ã€‚KATç³»åˆ—32Bæ¨¡å‹KAT-Devå·²åœ¨huggingface.co&#x2F;Kwaipilot&#x2F;KAT-Devä¸Šå¼€æºã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†ä»£ç†ç¼–ç é¢†åŸŸçš„å‘å±•ã€‚</li>
<li>KAT-Coderæ˜¯ä¸€ç§æ–°çš„ä»£ç†ç¼–ç æ¨¡å‹ï¼Œé€šè¿‡å¤šé˜¶æ®µè®­ç»ƒå®ç°ã€‚</li>
<li>ä¸­æœŸè®­ç»ƒé˜¶æ®µå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†ã€è§„åˆ’å’Œåæ€èƒ½åŠ›ã€‚</li>
<li>ç›‘ç£å¾®è°ƒé˜¶æ®µæ„å»ºäº†å¹³è¡¡å¤šç§ç¼–ç¨‹è¯­è¨€ã€å¼€å‘ç¯å¢ƒå’Œä»»åŠ¡åŸå‹çš„ç™¾ä¸‡æ ·æœ¬æ•°æ®é›†ã€‚</li>
<li>å¼ºåŒ–å¾®è°ƒé˜¶æ®µå¼•å…¥äº†æ–°çš„å¤šåœ°é¢çœŸå®å¥–åŠ±å…¬å¼ï¼Œç”¨äºç¨³å®šå’Œé«˜æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ã€‚</li>
<li>å¼ºåŒ–éƒ¨ç½²é€‚åº”é˜¶æ®µä½¿æ¨¡å‹é€‚åº”ç”Ÿäº§çº§IDEç¯å¢ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18779">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-760cffb2dc68addd1a7e5f5de789d0a7" align="middle">
<img src="https://picx.zhimg.com/v2-0b032abf160d33516216963a9b7d0dc7" align="middle">
<img src="https://picx.zhimg.com/v2-da2a93e57df6f05a0bf4ad41ab5fcdf1" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="VAR-Visual-Attention-Reasoning-via-Structured-Search-and-Backtracking"><a href="#VAR-Visual-Attention-Reasoning-via-Structured-Search-and-Backtracking" class="headerlink" title="VAR: Visual Attention Reasoning via Structured Search and Backtracking"></a>VAR: Visual Attention Reasoning via Structured Search and Backtracking</h2><p><strong>Authors:Wei Cai, Jian Zhao, Yuchen Yuan, Tianle Zhang, Ming Zhu, Haichuan Tang, Chi Zhang, Xuelong Li</strong></p>
<p>Multimodal Large Language Models (MLLMs), despite their advances, are hindered by their high hallucination tendency and heavy reliance on brittle, linear reasoning processes, leading to failures in complex tasks. To address these limitations, we introduce Visual Attention Reasoning (VAR), a novel framework that recasts grounded reasoning as a structured search over a reasoning trajectory space. VAR decomposes the reasoning process into two key stages: traceable evidence grounding and search-based chain-of-thought (CoT) generation, which incorporates a backtracking mechanism for self-correction. The search is guided by a multi-faceted reward function with semantic and geometric self-verification components, which penalize outputs that are not faithfully grounded in the visual input. We provide a theoretical analysis for our search strategy, validating its capability to find the correct solution with high probability. Experimental results show that our 7B model, VAR-7B, sets a new state-of-the-art on a comprehensive suite of hallucination and safety benchmarks, significantly outperforming existing open-source models and demonstrating competitive performance against leading proprietary systems. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å°½ç®¡å–å¾—äº†è¿›å±•ï¼Œä½†ä»å—åˆ°å…¶é«˜å¹»è§†å€¾å‘å’Œè¿‡åº¦ä¾èµ–è„†å¼±ã€çº¿æ€§æ¨ç†è¿‡ç¨‹çš„é˜»ç¢ï¼Œå¯¼è‡´åœ¨å¤æ‚ä»»åŠ¡ä¸­å¤±è´¥ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†è§†è§‰æ³¨æ„åŠ›æ¨ç†ï¼ˆVARï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œå®ƒå°†åŸºäºæƒ…å¢ƒæ¨ç†é‡æ–°æ„å»ºä¸ºåœ¨æ¨ç†è½¨è¿¹ç©ºé—´ä¸Šçš„ç»“æ„åŒ–æœç´¢ã€‚VARå°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šå¯è¿½è¸ªçš„è¯æ®æ¥åœ°å’ŒåŸºäºæœç´¢çš„æ€ç»´é“¾ï¼ˆCoTï¼‰ç”Ÿæˆï¼Œåè€…ç»“åˆäº†ç”¨äºè‡ªæˆ‘æ ¡æ­£çš„å›æº¯æœºåˆ¶ã€‚æœç´¢ç”±å¤šé¢å¥–åŠ±å‡½æ•°å¼•å¯¼ï¼ŒåŒ…æ‹¬è¯­ä¹‰å’Œå‡ ä½•è‡ªæˆ‘éªŒè¯ç»„ä»¶ï¼Œè¯¥å¥–åŠ±å‡½æ•°æƒ©ç½šé‚£äº›æ²¡æœ‰å¿ å®äºè§†è§‰è¾“å…¥çš„è¾“å‡ºæ¥ã€‚æˆ‘ä»¬å¯¹æœç´¢ç­–ç•¥è¿›è¡Œäº†ç†è®ºåˆ†æï¼ŒéªŒè¯äº†å…¶ä»¥é«˜æ¦‚ç‡æ‰¾åˆ°æ­£ç¡®è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„7Bæ¨¡å‹ï¼ˆVAR-7Bï¼‰åœ¨å¹»è§†å’Œå®‰å…¨åŸºå‡†æµ‹è¯•å¥—ä»¶ä¸Šåˆ›é€ äº†æ–°çš„æŠ€æœ¯æ ‡æ†ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºæ¨¡å‹ï¼Œå¹¶åœ¨é¢†å…ˆä¸“æœ‰ç³»ç»Ÿä¸­è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18619v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å­˜åœ¨é«˜å¹»è§†å€¾å‘å’Œä¾èµ–è„†å¼±ã€çº¿æ€§æ¨ç†è¿‡ç¨‹çš„é—®é¢˜ï¼Œå¯¼è‡´åœ¨å¤æ‚ä»»åŠ¡ä¸­å¤±è´¥ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºè§†è§‰æ³¨æ„åŠ›æ¨ç†ï¼ˆVARï¼‰æ–°æ¡†æ¶ï¼Œå°†æ¨ç†è½¨è¿¹ç©ºé—´ä½œä¸ºç»“æ„åŒ–æœç´¢å¯¹è±¡æ¥è¿›è¡Œé‡æ–°æ„å»ºã€‚VARå°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šå¯è¿½æº¯è¯æ®å®šä½å’ŒåŸºäºæœç´¢çš„é“¾å¼æ€ç»´ç”Ÿæˆã€‚æœç´¢ç”±å¤šé¢å¥–åŠ±å‡½æ•°å¼•å¯¼ï¼ŒåŒ…å«è¯­ä¹‰å’Œå‡ ä½•è‡ªæˆ‘éªŒè¯æˆåˆ†ï¼Œæƒ©ç½šé‚£äº›æ²¡æœ‰å¿ å®äºè§†è§‰è¾“å…¥çš„è¾“å‡ºæ¥è¿›è¡Œè‡ªæ ¡ã€‚æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„æœç´¢ç­–ç•¥æä¾›äº†ç†è®ºåˆ†æï¼ŒéªŒè¯äº†å…¶æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆçš„é«˜æ¦‚ç‡èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„7Bæ¨¡å‹VAR-7Båœ¨å¹»è§†å’Œå®‰å…¨åŸºå‡†æµ‹è¯•ä¸­æ ‘ç«‹äº†æ–°çš„æ ‡å‡†ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºæ¨¡å‹ï¼Œå¹¶åœ¨é¢†å…ˆä¸“æœ‰ç³»ç»Ÿé¢å‰å±•ç°å‡ºç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å­˜åœ¨é«˜å¹»è§†å€¾å‘å’Œä¾èµ–çº¿æ€§æ¨ç†çš„é—®é¢˜ã€‚</li>
<li>è§†è§‰æ³¨æ„åŠ›æ¨ç†ï¼ˆVARï¼‰æ¡†æ¶è¢«å¼•å…¥ä»¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>VARå°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºå¯è¿½æº¯è¯æ®å®šä½å’ŒåŸºäºæœç´¢çš„é“¾å¼æ€ç»´ç”Ÿæˆä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>VARé‡‡ç”¨ç»“æ„åŒ–æœç´¢æ¥å¯»æ‰¾æ¨ç†è½¨è¿¹ç©ºé—´ã€‚</li>
<li>å¤šé¢å¥–åŠ±å‡½æ•°åŒ…å«è¯­ä¹‰å’Œå‡ ä½•è‡ªæˆ‘éªŒè¯æˆåˆ†ï¼Œä»¥æŒ‡å¯¼æœç´¢è¿‡ç¨‹å¹¶é¿å…é”™è¯¯è¾“å‡ºã€‚</li>
<li>VAR-7Bæ¨¡å‹åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºæ¨¡å‹ï¼Œå¹¶åœ¨ä¸“æœ‰ç³»ç»Ÿé¢å‰å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5cfe41bdff8a52829b81fe71b377c294" align="middle">
<img src="https://picx.zhimg.com/v2-20e3dc3673ac0ad3ab50dc8fb4e4baec" align="middle">
<img src="https://picx.zhimg.com/v2-e3f2424f150ac4d204b6db90c1549178" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CodeRL-Improving-Code-Generation-via-Reinforcement-with-Execution-Semantics-Alignment"><a href="#CodeRL-Improving-Code-Generation-via-Reinforcement-with-Execution-Semantics-Alignment" class="headerlink" title="CodeRL+: Improving Code Generation via Reinforcement with Execution   Semantics Alignment"></a>CodeRL+: Improving Code Generation via Reinforcement with Execution   Semantics Alignment</h2><p><strong>Authors:Xue Jiang, Yihong Dong, Mengyang Liu, Hongyi Deng, Tian Wang, Yongding Tao, Rongyu Cao, Binhua Li, Zhi Jin, Wenpin Jiao, Fei Huang, Yongbin Li, Ge Li</strong></p>
<p>While Large Language Models (LLMs) excel at code generation by learning from vast code corpora, a fundamental semantic gap remains between their training on textual patterns and the goal of functional correctness, which is governed by formal execution semantics. Reinforcement Learning with Verifiable Rewards (RLVR) approaches attempt to bridge this gap using outcome rewards from executing test cases. However, solely relying on binary pass&#x2F;fail signals is inefficient for establishing a well-aligned connection between the textual representation of code and its execution semantics, especially for subtle logical errors within the code. In this paper, we propose CodeRL+, a novel approach that integrates execution semantics alignment into the RLVR training pipeline for code generation. CodeRL+ enables the model to infer variable-level execution trajectory, providing a direct learning signal of execution semantics. CodeRL+ can construct execution semantics alignment directly using existing on-policy rollouts and integrates seamlessly with various RL algorithms. Extensive experiments demonstrate that CodeRL+ outperforms post-training baselines (including RLVR and Distillation), achieving a 4.6% average relative improvement in pass@1. CodeRL+ generalizes effectively to other coding tasks, yielding 15.5% and 4.4% higher accuracy on code-reasoning and test-output-generation benchmarks, respectively. CodeRL+ shows strong applicability across diverse RL algorithms and LLMs. Furthermore, probe analyses provide compelling evidence that CodeRL+ strengthens the alignment between codeâ€™s textual representations and its underlying execution semantics. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡ä»å¤§é‡ä»£ç è¯­æ–™åº“ä¸­å­¦ä¹ åœ¨ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨æ–‡æœ¬æ¨¡å¼è®­ç»ƒä¸ç›®æ ‡åŠŸèƒ½æ€§æ­£ç¡®æ€§ä¹‹é—´ä»å­˜åœ¨åŸºæœ¬è¯­ä¹‰é¸¿æ²Ÿï¼ŒåŠŸèƒ½æ€§æ­£ç¡®æ€§æ˜¯ç”±å½¢å¼æ‰§è¡Œè¯­ä¹‰å†³å®šçš„ã€‚å¼ºåŒ–å­¦ä¹ åŠ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æ–¹æ³•è¯•å›¾é€šè¿‡ä½¿ç”¨æµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œç»“æœå¥–åŠ±æ¥å¼¥è¡¥è¿™ä¸€é¸¿æ²Ÿã€‚ç„¶è€Œï¼Œä»…ä»…ä¾èµ–äºŒè¿›åˆ¶é€šè¿‡&#x2F;å¤±è´¥ä¿¡å·å¯¹äºåœ¨ä»£ç æ–‡æœ¬è¡¨ç¤ºä¸å…¶æ‰§è¡Œè¯­ä¹‰ä¹‹é—´å»ºç«‹è‰¯å¥½å¯¹åº”å…³ç³»æ˜¯ä¸é«˜æ•ˆçš„ï¼Œç‰¹åˆ«æ˜¯å¯¹äºä»£ç ä¸­çš„ç»†å¾®é€»è¾‘é”™è¯¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†CodeRL+æ–¹æ³•ï¼Œå®ƒå°†æ‰§è¡Œè¯­ä¹‰å¯¹é½é›†æˆåˆ°RLVRè®­ç»ƒç®¡é“ä¸­è¿›è¡Œä»£ç ç”Ÿæˆã€‚CodeRL+ä½¿æ¨¡å‹èƒ½å¤Ÿæ¨æ–­å˜é‡çº§åˆ«çš„æ‰§è¡Œè½¨è¿¹ï¼Œæä¾›æ‰§è¡Œè¯­ä¹‰çš„ç›´æ¥å­¦ä¹ ä¿¡å·ã€‚CodeRL+èƒ½å¤Ÿç›´æ¥ä½¿ç”¨ç°æœ‰çš„ç­–ç•¥å†…æ»šåŠ¨æ¥æ„å»ºæ‰§è¡Œè¯­ä¹‰å¯¹é½ï¼Œå¹¶å¯ä»¥ä¸å„ç§å¼ºåŒ–å­¦ä¹ ç®—æ³•æ— ç¼é›†æˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCodeRl+ä¼˜äºè®­ç»ƒåçš„åŸºçº¿ï¼ˆåŒ…æ‹¬RLVRå’Œè’¸é¦ï¼‰ï¼Œåœ¨pass@1çš„å¹³å‡ç›¸å¯¹æ”¹è¿›è¾¾åˆ°4.6%ã€‚CodeRL+åœ¨å…¶ä»–ç¼–ç¨‹ä»»åŠ¡ä¸­ä¹Ÿèƒ½æœ‰æ•ˆæ¨å¹¿ï¼Œåœ¨ä»£ç æ¨ç†å’Œæµ‹è¯•è¾“å‡ºç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«æé«˜äº†15.5%å’Œ4.4%çš„å‡†ç¡®ç‡ã€‚CodeRL+åœ¨å¤šç§å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œå¤§è¯­è¨€æ¨¡å‹ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ã€‚æ­¤å¤–ï¼Œæ¢é’ˆåˆ†ææä¾›äº†æœ‰åŠ›çš„è¯æ®è¡¨æ˜CodeRL+åŠ å¼ºäº†ä»£ç æ–‡æœ¬è¡¨ç¤ºä¸å…¶æ½œåœ¨æ‰§è¡Œè¯­ä¹‰ä¹‹é—´çš„å¯¹é½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18471v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä»£ç ç”Ÿæˆé¢†åŸŸä¸­å­˜åœ¨çš„è¯­ä¹‰å·®è·é—®é¢˜ï¼Œå³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€šè¿‡æ–‡æœ¬æ¨¡å¼å­¦ä¹ ä»£ç ç”Ÿæˆæ—¶ï¼Œéš¾ä»¥è¾¾åˆ°åŠŸèƒ½æ­£ç¡®æ€§è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†CodeRL+æ–¹æ³•ï¼Œå°†æ‰§è¡Œè¯­ä¹‰å¯¹é½é›†æˆåˆ°RLVRè®­ç»ƒç®¡é“ä¸­ï¼Œé€šè¿‡ç›´æ¥å­¦ä¹ æ‰§è¡Œè¯­ä¹‰æ¥å¼¥è¡¥è¿™ä¸€å·®è·ã€‚CodeRL+èƒ½å¤Ÿæ¨æ–­å˜é‡çº§çš„æ‰§è¡Œè½¨è¿¹ï¼Œå¹¶åˆ©ç”¨ç°æœ‰çš„ç­–ç•¥è¯„ä¼°ç»“æœæ¥æ„å»ºæ‰§è¡Œè¯­ä¹‰å¯¹é½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCodeRL+ç›¸è¾ƒäºè®­ç»ƒåçš„åŸºå‡†æ¨¡å‹ï¼ˆåŒ…æ‹¬RLVRå’Œè’¸é¦æ–¹æ³•ï¼‰è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œå¹³å‡ç›¸å¯¹æé«˜äº†4.6%çš„pass@1æŒ‡æ ‡ã€‚æ­¤å¤–ï¼ŒCodeRL+åœ¨å…¶ä»–ç¼–ç¨‹ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨ä»£ç æ¨ç†å’Œæµ‹è¯•è¾“å‡ºç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«æé«˜äº†15.5%å’Œ4.4%çš„å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•åœ¨ä¸åŒç±»å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œè¯­è¨€æ¨¡å‹ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å­˜åœ¨è¯­ä¹‰å·®è·ï¼Œå³è®­ç»ƒæ—¶çš„æ–‡æœ¬æ¨¡å¼ä¸åŠŸèƒ½æ­£ç¡®æ€§è¦æ±‚ä¹‹é—´å­˜åœ¨å·®è·ã€‚</li>
<li>CodeRL+æ–¹æ³•æ—¨åœ¨é€šè¿‡æ•´åˆæ‰§è¡Œè¯­ä¹‰å¯¹é½åˆ°RLVRè®­ç»ƒç®¡é“æ¥ç¼©å°è¿™ä¸€å·®è·ã€‚</li>
<li>CodeRL+èƒ½å¤Ÿæ¨æ–­å˜é‡çº§çš„æ‰§è¡Œè½¨è¿¹ï¼Œæä¾›ç›´æ¥çš„å­¦ä¹ ä¿¡å·ä»¥äº†è§£æ‰§è¡Œè¯­ä¹‰ã€‚</li>
<li>CodeRL+åˆ©ç”¨ç°æœ‰çš„ç­–ç•¥è¯„ä¼°ç»“æœæ¥æ„å»ºæ‰§è¡Œè¯­ä¹‰å¯¹é½ï¼Œä¸”èƒ½æ— ç¼é›†æˆå„ç§å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCodeRL+åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†å…¶ä»–è®­ç»ƒåçš„åŸºå‡†æ¨¡å‹ï¼Œå¹³å‡ç›¸å¯¹æé«˜äº†pass@1æŒ‡æ ‡ã€‚</li>
<li>CodeRL+åœ¨å…¶ä»–ç¼–ç¨‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¦‚ä»£ç æ¨ç†å’Œæµ‹è¯•è¾“å‡ºç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18471">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b6d9216f90cb23b41371f94f496dc946" align="middle">
<img src="https://picx.zhimg.com/v2-b167a05035e70b3a75ff0af186543c9b" align="middle">
<img src="https://picx.zhimg.com/v2-9432e7e24444d1ce275040b5033891fa" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="KoSimpleQA-A-Korean-Factuality-Benchmark-with-an-Analysis-of-Reasoning-LLMs"><a href="#KoSimpleQA-A-Korean-Factuality-Benchmark-with-an-Analysis-of-Reasoning-LLMs" class="headerlink" title="KoSimpleQA: A Korean Factuality Benchmark with an Analysis of Reasoning   LLMs"></a>KoSimpleQA: A Korean Factuality Benchmark with an Analysis of Reasoning   LLMs</h2><p><strong>Authors:Donghyeon Ko, Yeguk Jin, Kyubyung Chae, Byungwook Lee, Chansong Jo, Sookyo In, Jaehong Lee, Taesup Kim, Donghyun Kwak</strong></p>
<p>We present $\textbf{Korean SimpleQA (KoSimpleQA)}$, a benchmark for evaluating factuality in large language models (LLMs) with a focus on Korean cultural knowledge. KoSimpleQA is designed to be challenging yet easy to grade, consisting of 1,000 short, fact-seeking questions with unambiguous answers. We conduct a comprehensive evaluation across a diverse set of open-source LLMs of varying sizes that support Korean, and find that even the strongest model generates correct answer only 33.7% of the time, underscoring the challenging nature of KoSimpleQA. Notably, performance rankings on KoSimpleQA differ substantially from those on the English SimpleQA, highlighting the unique value of our dataset. Furthermore, our analysis of reasoning LLMs shows that engaging reasoning capabilities in the factual QA task can both help models better elicit their latent knowledge and improve their ability to abstain when uncertain. KoSimpleQA can be found at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/KoSimpleQA-62EB">https://anonymous.4open.science/r/KoSimpleQA-62EB</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†**Korean SimpleQA (KoSimpleQA)**ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº‹å®æ€§è¯„ä¼°åŸºå‡†æµ‹è¯•ï¼Œé‡ç‚¹å…³æ³¨éŸ©å›½æ–‡åŒ–çŸ¥è¯†ã€‚KoSimpleQAçš„è®¾è®¡æ—¨åœ¨å…·æœ‰æŒ‘æˆ˜æ€§ä½†æ˜“äºè¯„åˆ†ï¼ŒåŒ…å«1000ä¸ªç®€çŸ­ã€å¯»æ±‚äº‹å®çš„é—®é¢˜ï¼Œç­”æ¡ˆæ˜ç¡®ã€‚æˆ‘ä»¬åœ¨æ”¯æŒéŸ©è¯­çš„å¼€æºLLMçš„å¤šæ ·åŒ–é›†åˆä¸­è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå‘ç°å³ä½¿æ˜¯æœ€å¼ºå¤§çš„æ¨¡å‹ä¹Ÿåªæœ‰33.7%çš„æ—¶é—´ç»™å‡ºäº†æ­£ç¡®ç­”æ¡ˆï¼Œè¿™å‡¸æ˜¾äº†KoSimpleQAçš„æŒ‘æˆ˜æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒKoSimpleQAä¸Šçš„æ€§èƒ½æ’åä¸è‹±è¯­SimpleQAä¸Šçš„æ’åå­˜åœ¨å¾ˆå¤§å·®å¼‚ï¼Œè¿™å‡¸æ˜¾äº†æˆ‘ä»¬æ•°æ®é›†çš„ç‹¬ç‰¹ä»·å€¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ¨ç†å‹LLMçš„åˆ†æè¡¨æ˜ï¼Œåœ¨äº‹å®é—®ç­”ä»»åŠ¡ä¸­åˆ©ç”¨æ¨ç†èƒ½åŠ›æ—¢æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°æ¿€å‘å…¶æ½œåœ¨çŸ¥è¯†ï¼Œåˆèƒ½æé«˜å…¶åœ¨ä¸ç¡®å®šæ—¶çš„å¼ƒæƒèƒ½åŠ›ã€‚KoSimpleQAå¯åœ¨<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/KoSimpleQA-62EB%E6%89%BE%E5%88%B0%E3%80%82">https://anonymous.4open.science/r/KoSimpleQA-62EBæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18368v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éŸ©å›½SimpleQAï¼ˆKoSimpleQAï¼‰åŸºå‡†æµ‹è¯•æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº‹å®æ€§ï¼Œå°¤å…¶ä¾§é‡äºéŸ©å›½æ–‡åŒ–çŸ¥è¯†ã€‚è¯¥æµ‹è¯•åŒ…å«1000ä¸ªç®€çŸ­ã€å¯»æ±‚äº‹å®çš„é—®é¢˜ï¼Œå…·æœ‰æ˜ç¡®çš„ç­”æ¡ˆã€‚è¯„ä¼°å‘ç°ï¼Œå³ä½¿åœ¨æœ€å¼ºçš„æ¨¡å‹ä¸Šï¼Œä¹Ÿåªæœ‰33.7%çš„æ—¶é—´ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆï¼Œçªæ˜¾äº†KoSimpleQAçš„æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œä¸è‹±è¯­SimpleQAç›¸æ¯”ï¼ŒKoSimpleQAçš„æ’åè¡¨ç°å·®å¼‚æ˜¾è‘—ï¼Œå‡¸æ˜¾äº†æ•°æ®é›†çš„ç‹¬ç‰¹ä»·å€¼ã€‚åŒæ—¶ï¼Œåˆ†ææ˜¾ç¤ºï¼Œåœ¨äº‹å®é—®ç­”ä»»åŠ¡ä¸­å¼•å…¥æ¨ç†èƒ½åŠ›æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°æ¿€å‘æ½œåœ¨çŸ¥è¯†å¹¶æé«˜ä¸ç¡®å®šæ—¶çš„æ‹’ç»å›ç­”èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KoSimpleQAæ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº‹å®æ€§è¯„ä¼°åŸºå‡†ï¼Œç‰¹åˆ«å…³æ³¨éŸ©å›½æ–‡åŒ–çŸ¥è¯†ã€‚</li>
<li>è¯¥æµ‹è¯•åŒ…å«1000ä¸ªç®€çŸ­çš„é—®é¢˜ï¼Œç­”æ¡ˆæ˜ç¡®ï¼Œæ—¨åœ¨è¯„ä¼°LLMçš„æ€§èƒ½ã€‚</li>
<li>è¯„ä¼°å‘ç°ï¼Œå³ä½¿æ˜¯æœ€å¥½çš„æ¨¡å‹ä¹Ÿä»…æœ‰33.7%çš„æ—¶é—´ç»™å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œçªæ˜¾äº†æµ‹è¯•çš„æŒ‘æˆ˜æ€§ã€‚</li>
<li>KoSimpleQAä¸è‹±è¯­SimpleQAç›¸æ¯”ï¼Œè¡¨ç°æ’åå·®å¼‚æ˜¾è‘—ï¼Œå‡¸æ˜¾äº†å…¶ç‹¬ç‰¹ä»·å€¼ã€‚</li>
<li>å¼•å…¥æ¨ç†èƒ½åŠ›æœ‰åŠ©äºæ¨¡å‹åœ¨äº‹å®é—®ç­”ä»»åŠ¡ä¸­æ›´å¥½åœ°æ¿€å‘æ½œåœ¨çŸ¥è¯†ã€‚</li>
<li>å½“æ¨¡å‹ä¸ç¡®å®šæ—¶ï¼Œæé«˜æ‹’ç»å›ç­”çš„èƒ½åŠ›å¯ä»¥ä¼˜åŒ–å…¶æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18368">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8f4da45e8cd0e30e00c344b3fd282616" align="middle">
<img src="https://picx.zhimg.com/v2-8e84260a132cf9baf171f711563394a6" align="middle">
<img src="https://picx.zhimg.com/v2-07ec77617f1767a1505ede57284ac684" align="middle">
<img src="https://picx.zhimg.com/v2-d0072a8439f281476af313774e7bd37b" align="middle">
<img src="https://picx.zhimg.com/v2-fda73873097faa7afb82b7827b499c33" align="middle">
<img src="https://picx.zhimg.com/v2-80c8630a88ccfc5793a21ab55f57ed5c" align="middle">
<img src="https://picx.zhimg.com/v2-0f75f561980ede597ba1be6b05f5f6bc" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Proactive-Reasoning-with-Retrieval-Framework-for-Medical-Multimodal-Large-Language-Models"><a href="#Proactive-Reasoning-with-Retrieval-Framework-for-Medical-Multimodal-Large-Language-Models" class="headerlink" title="Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models"></a>Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models</h2><p><strong>Authors:Lehan Wang, Yi Qin, Honglong Yang, Xiaomeng Li</strong></p>
<p>Incentivizing the reasoning ability of Multimodal Large Language Models (MLLMs) is essential for medical applications to transparently analyze medical scans and provide reliable diagnosis. However, existing medical MLLMs rely solely on internal knowledge during reasoning, leading to hallucinated reasoning and factual inaccuracies when encountering cases beyond their training scope. Although recent Agentic Retrieval-Augmented Generation (RAG) methods elicit the medical modelâ€™s proactive retrieval ability during reasoning, they are confined to unimodal LLMs, neglecting the crucial visual information during reasoning and retrieval. Consequently, we propose the first Multimodal Medical Reasoning-with-Retrieval framework, Med-RwR, which actively retrieves external knowledge by querying observed symptoms or domain-specific medical concepts during reasoning. Specifically, we design a two-stage reinforcement learning strategy with tailored rewards that stimulate the model to leverage both visual diagnostic findings and textual clinical information for effective retrieval. Building on this foundation, we further propose a Confidence-Driven Image Re-retrieval (CDIR) method for test-time scaling when low prediction confidence is detected. Evaluation on various public medical benchmarks demonstrates Med-RwRâ€™s significant improvements over baseline models, proving the effectiveness of enhancing reasoning capabilities with external knowledge integration. Furthermore, Med-RwR demonstrates remarkable generalizability to unfamiliar domains, evidenced by 8.8% performance gain on our proposed EchoCardiography Benchmark (ECBench), despite the scarcity of echocardiography data in the training corpus. Our data, model, and codes will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/Med-RwR">https://github.com/xmed-lab/Med-RwR</a>. </p>
<blockquote>
<p>æ¿€åŠ±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨ç†èƒ½åŠ›æ˜¯åŒ»ç–—åº”ç”¨é€æ˜åˆ†æåŒ»å­¦æ‰«æå’Œæä¾›å¯é è¯Šæ–­çš„å…³é”®ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»ç–—MLLMsåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä»…ä¾èµ–å†…éƒ¨çŸ¥è¯†ï¼Œå¯¼è‡´åœ¨é‡åˆ°è¶…å‡ºå…¶è®­ç»ƒèŒƒå›´çš„æƒ…å†µæ—¶å‡ºç°å¹»æƒ³æ¨ç†å’Œäº‹å®é”™è¯¯ã€‚å°½ç®¡æœ€è¿‘çš„Agenticæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•æ¿€å‘äº†åŒ»ç–—æ¨¡å‹çš„ä¸»åŠ¨æ£€ç´¢èƒ½åŠ›ï¼Œä½†å®ƒä»¬ä»…é™äºå•æ¨¡æ€LLMï¼Œå¿½è§†äº†æ¨ç†å’Œæ£€ç´¢è¿‡ç¨‹ä¸­çš„å…³é”®è§†è§‰ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªå¤šæ¨¡æ€åŒ»ç–—æ¨ç†æ£€ç´¢æ¡†æ¶Med-RwRï¼Œå®ƒä¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸»åŠ¨é€šè¿‡æŸ¥è¯¢è§‚å¯Ÿåˆ°çš„ç—‡çŠ¶æˆ–ç‰¹å®šé¢†åŸŸçš„åŒ»ç–—æ¦‚å¿µæ¥æ£€ç´¢å¤–éƒ¨çŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä½¿ç”¨å®šåˆ¶å¥–åŠ±æ¥åˆºæ¿€æ¨¡å‹åˆ©ç”¨è§†è§‰è¯Šæ–­ç»“æœå’Œæ–‡æœ¬ä¸´åºŠä¿¡æ¯è¿›è¡Œæœ‰æ•ˆæ£€ç´¢ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§ä¿¡å¿ƒé©±åŠ¨å›¾åƒå†æ£€ç´¢ï¼ˆCDIRï¼‰æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼Œå½“æ£€æµ‹åˆ°ä½é¢„æµ‹ä¿¡å¿ƒæ—¶ã€‚åœ¨å„ç§å…¬å…±åŒ»ç–—åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒMed-RwRåœ¨åŸºå‡†æ¨¡å‹ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œè¯æ˜äº†é€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†å¢å¼ºæ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå°½ç®¡è®­ç»ƒè¯­æ–™åº“ä¸­ç¼ºä¹è¶…å£°å¿ƒåŠ¨å›¾æ•°æ®ï¼ŒMed-RwRåœ¨æˆ‘ä»¬æå‡ºçš„å¿ƒåŠ¨å›¾åŸºå‡†æµ‹è¯•ï¼ˆECBenchï¼‰ä¸Šè¡¨ç°å‡ºå“è¶Šçš„å¯æ¨å¹¿æ€§ï¼Œæ€§èƒ½æé«˜äº†8.8%ã€‚æˆ‘ä»¬çš„æ•°æ®ã€æ¨¡å‹å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/xmed-lab/Med-RwR%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/xmed-lab/Med-RwRä¸Šå…¬å¼€å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18303v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼ºè°ƒæ¿€åŠ±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨ç†èƒ½åŠ›å¯¹äºåŒ»ç–—åº”ç”¨çš„é‡è¦æ€§ï¼Œä»¥å®ç°åŒ»ç–—æ‰«æçš„é€æ˜åˆ†æå’Œå¯é çš„è¯Šæ–­ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»ç–—MLLMsåœ¨æ¨ç†æ—¶ä»…ä¾èµ–å†…éƒ¨çŸ¥è¯†ï¼Œå¯¼è‡´åœ¨é¢ä¸´è¶…å‡ºè®­ç»ƒèŒƒå›´çš„æƒ…å†µæ—¶å‡ºç°è™šæ„æ¨ç†å’Œäº‹å®ä¸å‡†ç¡®çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†é¦–ä¸ªå¤šæ¨¡æ€åŒ»ç–—æ¨ç†ä¸æ£€ç´¢æ¡†æ¶Med-RwRï¼Œé€šè¿‡æŸ¥è¯¢è§‚å¯Ÿåˆ°çš„ç—‡çŠ¶æˆ–ç‰¹å®šé¢†åŸŸçš„åŒ»å­¦æ¦‚å¿µæ¥ç§¯ææ£€ç´¢å¤–éƒ¨çŸ¥è¯†ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡å®šåˆ¶å¥–åŠ±åˆºæ¿€æ¨¡å‹åˆ©ç”¨è§†è§‰è¯Šæ–­ç»“æœå’Œæ–‡æœ¬ä¸´åºŠä¿¡æ¯è¿›è¡Œæœ‰æ•ˆæ£€ç´¢ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¿¡å¿ƒé©±åŠ¨å›¾åƒå†æ£€ç´¢ï¼ˆCDIRï¼‰æ–¹æ³•ï¼Œç”¨äºåœ¨æ£€æµ‹åˆ°ä½é¢„æµ‹ä¿¡å¿ƒæ—¶è¿›è¡Œæµ‹è¯•æ—¶é—´ç¼©æ”¾ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒMed-RwRåœ¨åŸºå‡†æ¨¡å‹ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œè¯æ˜äº†æ•´åˆå¤–éƒ¨çŸ¥è¯†å¢å¼ºæ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒMed-RwRåœ¨æˆ‘ä»¬æå‡ºçš„EchoCardiography Benchmarkï¼ˆECBenchï¼‰ä¸Šè¡¨ç°å‡ºå“è¶Šçš„å¯æ³›åŒ–æ€§ï¼Œå°½ç®¡è®­ç»ƒè¯­æ–™åº“ä¸­ç¼ºä¹è¶…å£°å¿ƒåŠ¨å›¾æ•°æ®ï¼Œä½†å…¶æ€§èƒ½æé«˜äº†8.8%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¿€åŠ±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨ç†èƒ½åŠ›å¯¹äºåŒ»ç–—åº”ç”¨è‡³å…³é‡è¦ï¼Œèƒ½æ›´å¯é åœ°åˆ†æåŒ»ç–—æ‰«æå’Œæä¾›è¯Šæ–­ã€‚</li>
<li>ç°æœ‰åŒ»ç–—MLLMså­˜åœ¨å±€é™ï¼Œä»…ä¾èµ–å†…éƒ¨çŸ¥è¯†å¯¼è‡´è™šæ„æ¨ç†å’Œäº‹å®ä¸å‡†ç¡®ã€‚</li>
<li>æå‡ºé¦–ä¸ªå¤šæ¨¡æ€åŒ»ç–—æ¨ç†ä¸æ£€ç´¢æ¡†æ¶Med-RwRï¼Œç»“åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œæ£€ç´¢ã€‚</li>
<li>Med-RwRé‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œé€šè¿‡å®šåˆ¶å¥–åŠ±åˆºæ¿€æ¨¡å‹åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯æ£€ç´¢ã€‚</li>
<li>Med-RwRæå‡ºä¿¡å¿ƒé©±åŠ¨å›¾åƒå†æ£€ç´¢ï¼ˆCDIRï¼‰æ–¹æ³•ï¼Œæé«˜é¢„æµ‹ä¿¡å¿ƒã€‚</li>
<li>Med-RwRåœ¨å…¬å…±åŒ»ç–—åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜æ•´åˆå¤–éƒ¨çŸ¥è¯†å¢å¼ºæ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18303">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-df8405479e13c7863db1965332b22707" align="middle">
<img src="https://picx.zhimg.com/v2-599e5c440f170daa5b4fabcbb54ab616" align="middle">
<img src="https://picx.zhimg.com/v2-8bedb78797f5c0f238db7ac71b82ed53" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="From-Competition-to-Synergy-Unlocking-Reinforcement-Learning-for-Subject-Driven-Image-Generation"><a href="#From-Competition-to-Synergy-Unlocking-Reinforcement-Learning-for-Subject-Driven-Image-Generation" class="headerlink" title="From Competition to Synergy: Unlocking Reinforcement Learning for   Subject-Driven Image Generation"></a>From Competition to Synergy: Unlocking Reinforcement Learning for   Subject-Driven Image Generation</h2><p><strong>Authors:Ziwei Huang, Ying Shu, Hao Fang, Quanyu Long, Wenya Wang, Qiushi Guo, Tiezheng Ge, Leilei Gan</strong></p>
<p>Subject-driven image generation models face a fundamental trade-off between identity preservation (fidelity) and prompt adherence (editability). While online reinforcement learning (RL), specifically GPRO, offers a promising solution, we find that a naive application of GRPO leads to competitive degradation, as the simple linear aggregation of rewards with static weights causes conflicting gradient signals and a misalignment with the temporal dynamics of the diffusion process. To overcome these limitations, we propose Customized-GRPO, a novel framework featuring two key innovations: (i) Synergy-Aware Reward Shaping (SARS), a non-linear mechanism that explicitly penalizes conflicted reward signals and amplifies synergistic ones, providing a sharper and more decisive gradient. (ii) Time-Aware Dynamic Weighting (TDW), which aligns the optimization pressure with the modelâ€™s temporal dynamics by prioritizing prompt-following in the early, identity preservation in the later. Extensive experiments demonstrate that our method significantly outperforms naive GRPO baselines, successfully mitigating competitive degradation. Our model achieves a superior balance, generating images that both preserve key identity features and accurately adhere to complex textual prompts. </p>
<blockquote>
<p>ä¸»é¢˜é©±åŠ¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨èº«ä»½ä¿ç•™ï¼ˆä¿çœŸåº¦ï¼‰å’Œæç¤ºéµå¾ªï¼ˆå¯ç¼–è¾‘æ€§ï¼‰ä¹‹é—´é¢ä¸´æ ¹æœ¬çš„æƒè¡¡ã€‚è™½ç„¶åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆç‰¹åˆ«æ˜¯GPROï¼‰æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œä½†æˆ‘ä»¬å‘ç°ç®€å•åº”ç”¨GRPOä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå› ä¸ºä½¿ç”¨é™æ€æƒé‡çš„ç®€å•çº¿æ€§å¥–åŠ±èšåˆä¼šäº§ç”Ÿå†²çªçš„æ¢¯åº¦ä¿¡å·ï¼Œå¹¶ä¸æ‰©æ•£è¿‡ç¨‹çš„æ—¶æ€åŠ¨æ€ä¸åŒ¹é…ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å®šåˆ¶åŒ–çš„GRPOï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰ä¸¤é¡¹å…³é”®åˆ›æ–°çš„æ–°å‹æ¡†æ¶ï¼šï¼ˆiï¼‰ååŒæ„ŸçŸ¥å¥–åŠ±å¡‘å½¢ï¼ˆSARSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§éçº¿æ€§æœºåˆ¶ï¼Œå¯ä»¥æ˜ç¡®æƒ©ç½šå†²çªçš„å¥–åŠ±ä¿¡å·å¹¶æ”¾å¤§ååŒä¿¡å·ï¼Œä»è€Œæä¾›æ›´æ¸…æ™°ã€æ›´æœæ–­çš„æ¢¯åº¦ã€‚ï¼ˆiiï¼‰æ—¶é—´æ„ŸçŸ¥åŠ¨æ€åŠ æƒï¼ˆTDWï¼‰ï¼Œå®ƒé€šè¿‡ä¼˜å…ˆå…³æ³¨æ—©æœŸçš„æç¤ºéµå¾ªå’ŒåæœŸçš„èº«ä»½ä¿ç•™ï¼Œä½¿ä¼˜åŒ–å‹åŠ›ä¸æ¨¡å‹çš„æ—¶æ€åŠ¨æ€ç›¸åŒ¹é…ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç®€å•çš„GRPOåŸºçº¿ï¼ŒæˆåŠŸç¼“è§£äº†ç«äº‰é€€åŒ–é—®é¢˜ã€‚æˆ‘ä»¬çš„æ¨¡å‹å®ç°äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œç”Ÿæˆçš„å›¾åƒæ—¢ä¿ç•™äº†å…³é”®çš„èº«ä»½ç‰¹å¾ï¼Œåˆå‡†ç¡®åœ°éµå¾ªäº†å¤æ‚çš„æ–‡æœ¬æç¤ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18263v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä¸»é¢˜é©±åŠ¨å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨èº«ä»½ä¿ç•™å’Œæç¤ºéµå¾ªä¹‹é—´å­˜åœ¨æ­¤åŸºæœ¬æƒè¡¡é—®é¢˜ã€‚GRPOåœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸ºè§£å†³æ­¤é—®é¢˜æä¾›äº†å¸Œæœ›ï¼Œä½†å…¶ç®€å•åº”ç”¨ä¼šå¯¼è‡´ç«äº‰é€€åŒ–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºCustomized-GRPOæ¡†æ¶ï¼ŒåŒ…å«ä¸¤å¤§åˆ›æ–°ï¼šååŒå¥–åŠ±å¡‘å½¢ï¼ˆSARSï¼‰å’Œæ—¶é—´æ„ŸçŸ¥åŠ¨æ€åŠ æƒï¼ˆTDWï¼‰ã€‚SARSæ˜ç¡®æƒ©ç½šå†²çªå¥–åŠ±ä¿¡å·å¹¶æ”¾å¤§ååŒä¿¡å·ï¼Œæä¾›æ¸…æ™°æ¢¯åº¦ã€‚TDWé€šè¿‡ä¸æ¨¡å‹æ—¶é—´åŠ¨æ€å¯¹é½ä¼˜åŒ–å‹åŠ›æ¥ä¼˜å…ˆè¿›è¡Œæ—©æœŸæç¤ºå’ŒåæœŸèº«ä»½ä¿ç•™ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜æ˜¾ä¼˜äºç®€å•çš„GRPOåŸºçº¿ï¼ŒæˆåŠŸç¼“è§£ç«äº‰é€€åŒ–é—®é¢˜ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¿ç•™å…³é”®èº«ä»½ç‰¹å¾å’Œå‡†ç¡®éµå¾ªå¤æ‚æ–‡æœ¬æç¤ºä¹‹é—´è¾¾åˆ°äº†å“è¶Šå¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸»é¢˜é©±åŠ¨å›¾åƒç”Ÿæˆæ¨¡å‹é¢ä¸´èº«ä»½ä¿ç•™å’Œæç¤ºéµå¾ªä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚</li>
<li>ç®€å•çš„GRPOåº”ç”¨ä¼šå¯¼è‡´ç«äº‰é€€åŒ–ï¼Œå› ä¸ºé™æ€æƒé‡ä¸‹çš„çº¿æ€§å¥–åŠ±èšåˆä¼šå¼•èµ·å†²çªçš„æ¢¯åº¦ä¿¡å·ã€‚</li>
<li>Customized-GRPOæ¡†æ¶é€šè¿‡ä¸¤å¤§åˆ›æ–°è§£å†³æ­¤é—®é¢˜ï¼šååŒå¥–åŠ±å¡‘å½¢ï¼ˆSARSï¼‰å’Œæ—¶é—´æ„ŸçŸ¥åŠ¨æ€åŠ æƒï¼ˆTDWï¼‰ã€‚</li>
<li>SARSæ˜ç¡®æƒ©ç½šå†²çªçš„å¥–åŠ±ä¿¡å·å¹¶æ”¾å¤§ååŒä¿¡å·ï¼Œä»¥æä¾›æ›´æ¸…æ™°çš„æ¢¯åº¦æ–¹å‘ã€‚</li>
<li>TDWé€šè¿‡ä¸æ¨¡å‹çš„æ—¶é—´åŠ¨æ€å¯¹é½ä¼˜åŒ–å‹åŠ›ï¼Œåœ¨åˆæœŸæ›´é‡è§†æç¤ºéµå¾ªï¼Œåœ¨åæœŸæ›´é‡è§†èº«ä»½ä¿ç•™ã€‚</li>
<li>å®éªŒè¯æ˜Customized-GRPOæ˜¾è‘—ä¼˜äºåŸºç¡€GRPOæ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£ç«äº‰é€€åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18263">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35be56608742a1e310aca4b93a77f762" align="middle">
<img src="https://picx.zhimg.com/v2-cd9263867f9fa83c834cd23bdf881f5c" align="middle">
<img src="https://picx.zhimg.com/v2-8482a643d2b91a860eb3f3400d0e0478" align="middle">
<img src="https://picx.zhimg.com/v2-005c52cf19f9aeea552a51d4de323a2b" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Adaptive-Divergence-Regularized-Policy-Optimization-for-Fine-tuning-Generative-Models"><a href="#Adaptive-Divergence-Regularized-Policy-Optimization-for-Fine-tuning-Generative-Models" class="headerlink" title="Adaptive Divergence Regularized Policy Optimization for Fine-tuning   Generative Models"></a>Adaptive Divergence Regularized Policy Optimization for Fine-tuning   Generative Models</h2><p><strong>Authors:Jiajun Fan, Tong Wei, Chaoran Cheng, Yuxin Chen, Ge Liu</strong></p>
<p>Balancing exploration and exploitation during reinforcement learning fine-tuning of generative models presents a critical challenge, as existing approaches rely on fixed divergence regularization that creates an inherent dilemma: strong regularization preserves model capabilities but limits reward optimization, while weak regularization enables greater alignment but risks instability or reward hacking. We introduce Adaptive Divergence Regularized Policy Optimization (ADRPO), which automatically adjusts regularization strength based on advantage estimates-reducing regularization for high-value samples while applying stronger regularization to poor samples, enabling policies to navigate between exploration and aggressive exploitation according to data quality. Our implementation with Wasserstein-2 regularization for flow matching generative models achieves remarkable results on text-to-image generation, achieving better semantic alignment and diversity than offline methods like DPO and online methods with fixed regularization like ORW-CFM-W2. ADRPO enables a 2B parameter SD3 model to surpass much larger models with 4.8B and 12B parameters in attribute binding, semantic consistency, artistic style transfer, and compositional control while maintaining generation diversity. ADRPO generalizes to KL-regularized fine-tuning of both text-only LLMs and multi-modal reasoning models, enhancing existing online RL methods like GRPO. In LLM fine-tuning, ADRPO demonstrates an emergent ability to escape local optima through active exploration, while in multi-modal audio reasoning, it outperforms GRPO through superior step-by-step reasoning, enabling a 7B model to outperform substantially larger commercial models including Gemini 2.5 Pro and GPT-4o Audio, offering an effective plug-and-play solution to the exploration-exploitation challenge across diverse generative architectures and modalities. </p>
<blockquote>
<p>åœ¨å¼ºåŒ–å­¦ä¹ å¯¹ç”Ÿæˆæ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå›ºå®šçš„å‘æ•£æ­£åˆ™åŒ–ï¼Œè¿™å¸¦æ¥äº†ä¸€ä¸ªå›ºæœ‰çš„å›°å¢ƒï¼šå¼ºæ­£åˆ™åŒ–ä¿ç•™äº†æ¨¡å‹çš„èƒ½åŠ›ï¼Œä½†é™åˆ¶äº†å¥–åŠ±ä¼˜åŒ–ï¼›è€Œå¼±æ­£åˆ™åŒ–è™½ç„¶å®ç°äº†æ›´å¤§çš„å¯¹é½ï¼Œä½†å­˜åœ¨ä¸ç¨³å®šæˆ–å¥–åŠ±ä½œå¼Šçš„é£é™©ã€‚æˆ‘ä»¬å¼•å…¥äº†è‡ªé€‚åº”å‘æ•£æ­£åˆ™åŒ–ç­–ç•¥ä¼˜åŒ–ï¼ˆADRPOï¼‰ï¼Œå®ƒå¯ä»¥æ ¹æ®ä¼˜åŠ¿ä¼°è®¡è‡ªåŠ¨è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦ï¼Œä¸ºé«˜ä»·å€¼æ ·æœ¬å‡å°‘æ­£åˆ™åŒ–ï¼Œå¯¹ä¸è‰¯æ ·æœ¬åº”ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼Œä½¿ç­–ç•¥èƒ½å¤Ÿæ ¹æ®æ•°æ®è´¨é‡åœ¨æ¢ç´¢å’Œæ¿€è¿›åˆ©ç”¨ä¹‹é—´å¯¼èˆªã€‚æˆ‘ä»¬ä½¿ç”¨Wasserstein-2æ­£åˆ™åŒ–å®ç°æµåŒ¹é…ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœï¼Œå®ç°äº†æ¯”DPOç­‰ç¦»çº¿æ–¹æ³•å’Œå…·æœ‰å›ºå®šæ­£åˆ™åŒ–çš„åœ¨çº¿æ–¹æ³•ï¼ˆå¦‚ORW-CFM-W2ï¼‰æ›´å¥½çš„è¯­ä¹‰å¯¹é½å’Œå¤šæ ·æ€§ã€‚ADRPOä½¿ä¸€ä¸ªå…·æœ‰2Bå‚æ•°çš„SD3æ¨¡å‹èƒ½å¤Ÿåœ¨å±æ€§ç»‘å®šã€è¯­ä¹‰ä¸€è‡´æ€§ã€è‰ºæœ¯é£æ ¼è½¬æ¢å’Œç»„åˆæ§åˆ¶æ–¹é¢è¶…è¶Šå‚æ•°æ›´å¤šçš„4.8Bå’Œ12Bæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆå¤šæ ·æ€§ã€‚ADRPOé€‚ç”¨äºæ–‡æœ¬ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨ç†æ¨¡å‹çš„KLæ­£åˆ™åŒ–å¾®è°ƒï¼Œå¯ä»¥å¢å¼ºç°æœ‰çš„åœ¨çº¿RLæ–¹æ³•ï¼Œå¦‚GRPOã€‚åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒä¸­ï¼ŒADRPOå±•ç°å‡ºé€šè¿‡ä¸»åŠ¨æ¢ç´¢é€ƒç¦»å±€éƒ¨æœ€ä¼˜çš„æ½œèƒ½ï¼›è€Œåœ¨å¤šæ¨¡æ€éŸ³é¢‘æ¨ç†ä¸­ï¼Œå®ƒé€šè¿‡å‡ºè‰²çš„é€æ­¥æ¨ç†è¶…è¶Šäº†GRPOï¼Œä½¿ä¸€ä¸ª7Bæ¨¡å‹èƒ½å¤Ÿè¶…è¶Šæ›´å¤§è§„æ¨¡çš„å•†ä¸šæ¨¡å‹ï¼ŒåŒ…æ‹¬Gemini 2.5 Proå’ŒGPT-4o Audioï¼Œä¸ºè§£å†³ä¸åŒç”Ÿæˆæ¶æ„å’Œæ¨¡å¼ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨æŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆçš„å³æ’å³ç”¨è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18053v1">PDF</a> 30 pages</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒç”Ÿæˆæ¨¡å‹æ—¶ï¼Œæ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´çš„å¹³è¡¡æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šçš„å‘æ•£æ­£åˆ™åŒ–ï¼Œå­˜åœ¨ä¼˜åŒ–å¥–åŠ±ä¸ä¿æŒæ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„å†…åœ¨çŸ›ç›¾ã€‚æˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”å‘æ•£æ­£åˆ™åŒ–ç­–ç•¥ä¼˜åŒ–ï¼ˆADRPOï¼‰ï¼Œæ ¹æ®ä¼˜åŠ¿ä¼°è®¡è‡ªåŠ¨è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦ï¼Œå¯¹é«˜è´¨é‡æ ·æœ¬å‡å°‘æ­£åˆ™åŒ–ï¼Œå¯¹ä½è´¨é‡æ ·æœ¬åº”ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–ã€‚è¿™ä½¿å¾—ç­–ç•¥èƒ½å¤Ÿæ ¹æ®æ•°æ®è´¨é‡åœ¨æ¢ç´¢å’Œæ¿€è¿›åˆ©ç”¨ä¹‹é—´çµæ´»å¯¼èˆªã€‚åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹é¢ï¼Œä½¿ç”¨Wasserstein-2æ­£åˆ™åŒ–çš„ADRPOå®ç°æ˜¾è‘—æˆæœï¼Œåœ¨å±æ€§ç»‘å®šã€è¯­ä¹‰ä¸€è‡´æ€§ã€è‰ºæœ¯é£æ ¼è½¬æ¢å’Œç»„åˆæ§åˆ¶ç­‰æ–¹é¢è¶…è¶Šäº†è®¸å¤šæ›´å¤§çš„æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆå¤šæ ·æ€§ã€‚ADRPOè¿˜å¯æ¨å¹¿åˆ°KLæ­£åˆ™åŒ–çš„æ–‡æœ¬ä»…å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨ç†æ¨¡å‹çš„å¾®è°ƒï¼Œå¹¶å¢å¼ºç°æœ‰åœ¨çº¿RLæ–¹æ³•ï¼Œå¦‚GRPOã€‚åœ¨LLMå¾®è°ƒä¸­ï¼ŒADRPOå±•ç°å‡ºé€šè¿‡ä¸»åŠ¨æ¢ç´¢é€ƒç¦»å±€éƒ¨æœ€ä¼˜çš„èƒ½åŠ›ï¼›åœ¨å¤šæ¨¡æ€éŸ³é¢‘æ¨ç†ä¸­ï¼Œå®ƒå‡­å€Ÿå‡ºè‰²çš„é€æ­¥æ¨ç†è¡¨ç°ä¼˜äºGRPOï¼Œä½¿ä¸€ä¸ª7Bæ¨¡å‹è¶…è¶Šæ›´å¤§è§„æ¨¡çš„å•†ä¸šæ¨¡å‹ï¼Œå¦‚Gemini 2.5 Proå’ŒGPT-4o Audioã€‚å®ƒä¸ºè§£å†³å„ç§ç”Ÿæˆæ¶æ„å’Œæ¨¡å¼ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨æŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆçš„å³æ’å³ç”¨è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒç”Ÿæˆæ¨¡å‹ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–å›ºå®šå‘æ•£æ­£åˆ™åŒ–å­˜åœ¨çŸ›ç›¾ï¼šå¼ºæ­£åˆ™åŒ–é™åˆ¶å¥–åŠ±ä¼˜åŒ–ï¼Œå¼±æ­£åˆ™åŒ–åˆ™å¯èƒ½å¼•å‘ä¸ç¨³å®šæˆ–å¥–åŠ±æ¬ºéª—ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”å‘æ•£æ­£åˆ™åŒ–ç­–ç•¥ä¼˜åŒ–ï¼ˆADRPOï¼‰ï¼Œæ ¹æ®æ•°æ®è´¨é‡è‡ªåŠ¨è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦ã€‚</li>
<li>ADRPOåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹é¢å®ç°æ˜¾è‘—æˆæœï¼Œè¶…è¶Šå¤§å‹æ¨¡å‹ï¼Œæé«˜è¯­ä¹‰å¯¹é½ã€å¤šæ ·æ€§å’Œå…¶ä»–æŒ‡æ ‡ã€‚</li>
<li>ADRPOé€‚ç”¨äºKLæ­£åˆ™åŒ–çš„å¤šç§æ¨¡å‹å¾®è°ƒï¼ŒåŒ…æ‹¬æ–‡æœ¬ä»…å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨ç†æ¨¡å‹ã€‚</li>
<li>åœ¨LLMå¾®è°ƒä¸­ï¼ŒADRPOå±•ç°é€ƒç¦»å±€éƒ¨æœ€ä¼˜çš„èƒ½åŠ›ï¼›åœ¨å¤šæ¨¡æ€éŸ³é¢‘æ¨ç†ä¸­ï¼Œå®ƒä¼˜äºGRPOã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18053">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-130fe1a5b66c9767ee3080764022b244" align="middle">
<img src="https://picx.zhimg.com/v2-9c4de01e4205092c9007369081de7048" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-23/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-23/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-23/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-82ae12e967f2b361e411f5374cbf505d" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-23  Grasp Any Region Towards Precise, Contextual Pixel Understanding for   Multimodal LLMs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-30ac3b5962f32623eb45e4ff2f40f17a" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  When Words Smile Generating Diverse Emotional Facial Expressions from   Text
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33125.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
