<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-23  TreeFedDG Alleviating Global Drift in Federated Domain Generalization   for Medical Image Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-0e40db0000336e4641a83dfa726e5eab~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178793&auth_key=1761178793-0-0-d95f94630b5d0f746a197f3e2657447b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    63 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-23-æ›´æ–°"><a href="#2025-10-23-æ›´æ–°" class="headerlink" title="2025-10-23 æ›´æ–°"></a>2025-10-23 æ›´æ–°</h1><h2 id="TreeFedDG-Alleviating-Global-Drift-in-Federated-Domain-Generalization-for-Medical-Image-Segmentation"><a href="#TreeFedDG-Alleviating-Global-Drift-in-Federated-Domain-Generalization-for-Medical-Image-Segmentation" class="headerlink" title="TreeFedDG: Alleviating Global Drift in Federated Domain Generalization   for Medical Image Segmentation"></a>TreeFedDG: Alleviating Global Drift in Federated Domain Generalization   for Medical Image Segmentation</h2><p><strong>Authors:Yucheng Song, Chenxi Li, Haokang Ding, Zhining Liao, Zhifang Liao</strong></p>
<p>In medical image segmentation tasks, Domain Generalization (DG) under the Federated Learning (FL) framework is crucial for addressing challenges related to privacy protection and data heterogeneity. However, traditional federated learning methods fail to account for the imbalance in information aggregation across clients in cross-domain scenarios, leading to the Global Drift (GD) problem and a consequent decline in model generalization performance. This motivates us to delve deeper and define a new critical issue: global drift in federated domain generalization for medical imaging (FedDG-GD). In this paper, we propose a novel tree topology framework called TreeFedDG. First, starting from the distributed characteristics of medical images, we design a hierarchical parameter aggregation method based on a tree-structured topology to suppress deviations in the global model direction. Second, we introduce a parameter difference-based style mixing method (FedStyle), which enforces mixing among clients with maximum parameter differences to enhance robustness against drift. Third, we develop a a progressive personalized fusion strategy during model distribution, ensuring a balance between knowledge transfer and personalized features. Finally, during the inference phase, we use feature similarity to guide the retrieval of the most relevant model chain from the tree structure for ensemble decision-making, thereby fully leveraging the advantages of hierarchical knowledge. We conducted extensive experiments on two publicly available datasets. The results demonstrate that our method outperforms other state-of-the-art domain generalization approaches in these challenging tasks and achieves better balance in cross-domain performance. </p>
<blockquote>
<p>åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œè”é‚¦å­¦ä¹ æ¡†æ¶ä¸‹çš„é¢†åŸŸæ³›åŒ–ï¼ˆDGï¼‰å¯¹äºåº”å¯¹éšç§ä¿æŠ¤å’Œæ•°æ®å¼‚æ„æ€§çš„æŒ‘æˆ˜è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„è”é‚¦å­¦ä¹ æ–¹æ³•æœªèƒ½è€ƒè™‘åˆ°è·¨åŸŸåœºæ™¯ä¸­å®¢æˆ·ç«¯ä¿¡æ¯èšåˆçš„ä¸å¹³è¡¡ï¼Œä»è€Œå¼•å‘äº†å…¨å±€æ¼‚ç§»ï¼ˆGDï¼‰é—®é¢˜ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–æ€§èƒ½ä¸‹é™ã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬æ·±å…¥ç ”ç©¶å¹¶å®šä¹‰äº†ä¸€ä¸ªæ–°çš„å…³é”®é—®é¢˜ï¼šåŒ»å­¦æˆåƒè”é‚¦é¢†åŸŸæ³›åŒ–ä¸­çš„å…¨å±€æ¼‚ç§»ï¼ˆFedDG-GDï¼‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ ‘æ‹“æ‰‘æ¡†æ¶ï¼Œç§°ä¸ºTreeFedDGã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»åŒ»å­¦å›¾åƒçš„åˆ†å¸ƒå¼ç‰¹ç‚¹å‡ºå‘ï¼Œè®¾è®¡äº†ä¸€ç§åŸºäºæ ‘ç»“æ„æ‹“æ‰‘çš„åˆ†å±‚å‚æ•°èšåˆæ–¹æ³•ï¼Œä»¥æŠ‘åˆ¶å…¨å±€æ¨¡å‹æ–¹å‘çš„åå·®ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºå‚æ•°å·®å¼‚çš„æ ·å¼æ··åˆæ–¹æ³•ï¼ˆFedStyleï¼‰ï¼Œé€šè¿‡å¼ºåˆ¶å‚æ•°å·®å¼‚æœ€å¤§çš„å®¢æˆ·ç«¯è¿›è¡Œæ··åˆï¼Œä»¥å¢å¼ºå¯¹æ¼‚ç§»çš„é²æ£’æ€§ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬åœ¨æ¨¡å‹åˆ†å¸ƒè¿‡ç¨‹ä¸­å¼€å‘äº†ä¸€ç§æ¸è¿›å¼ä¸ªæ€§åŒ–èåˆç­–ç•¥ï¼Œç¡®ä¿çŸ¥è¯†è½¬ç§»å’Œä¸ªæ€§åŒ–ç‰¹å¾ä¹‹é—´çš„å¹³è¡¡ã€‚æœ€åï¼Œåœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹å¾ç›¸ä¼¼æ€§æ¥æŒ‡å¯¼ä»æ ‘ç»“æ„ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ¨¡å‹é“¾ï¼Œä»¥è¿›è¡Œé›†æˆå†³ç­–ï¼Œä»è€Œå……åˆ†åˆ©ç”¨åˆ†å±‚çŸ¥è¯†çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿™äº›å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„é¢†åŸŸæ³›åŒ–æ–¹æ³•ï¼Œå¹¶åœ¨è·¨åŸŸæ€§èƒ½ä¸Šå®ç°äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18268v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­è”é‚¦å­¦ä¹ æ¡†æ¶ä¸‹çš„åŸŸæ³›åŒ–é—®é¢˜ã€‚é’ˆå¯¹è·¨åŸŸåœºæ™¯ä¸­ä¿¡æ¯èšåˆä¸å¹³è¡¡å¯¼è‡´çš„å…¨å±€æ¼‚ç§»é—®é¢˜ï¼Œæå‡ºäº†æ–°å‹æ ‘æ‹“æ‰‘æ¡†æ¶TreeFedDGã€‚é€šè¿‡å±‚æ¬¡å‚æ•°èšåˆæ–¹æ³•ã€å‚æ•°å·®å¼‚é£æ ¼æ··åˆæ–¹æ³•å’Œæ¸è¿›ä¸ªæ€§åŒ–èåˆç­–ç•¥ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½å’Œé²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„åŸŸæ³›åŒ–æ–¹æ³•ï¼Œå®ç°äº†è·¨åŸŸæ€§èƒ½çš„æ›´å¥½å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œè”é‚¦å­¦ä¹ æ¡†æ¶ä¸‹çš„åŸŸæ³›åŒ–ï¼ˆDGï¼‰è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯è§£å†³éšç§ä¿æŠ¤å’Œæ•°æ®çš„å¼‚è´¨æ€§æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿè”é‚¦å­¦ä¹ æ–¹æ³•åœ¨è·¨åŸŸåœºæ™¯ä¸­æ— æ³•å¹³è¡¡ä¿¡æ¯èšåˆï¼Œå¯¼è‡´å…¨å±€æ¼‚ç§»ï¼ˆGDï¼‰é—®é¢˜ï¼Œå½±å“æ¨¡å‹æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>æ–°å‹æ ‘æ‹“æ‰‘æ¡†æ¶TreeFedDGè¢«æå‡ºä»¥è§£å†³æ­¤é—®é¢˜ï¼Œé€šè¿‡å±‚æ¬¡å‚æ•°èšåˆæ–¹æ³•æŠ‘åˆ¶å…¨å±€æ¨¡å‹æ–¹å‘ä¸Šçš„åå·®ã€‚</li>
<li>å¼•å…¥å‚æ•°å·®å¼‚é£æ ¼æ··åˆæ–¹æ³•ï¼ˆFedStyleï¼‰ï¼Œé€šè¿‡æ··åˆå‚æ•°å·®å¼‚æœ€å¤§çš„å®¢æˆ·ç«¯æ¥å¢å¼ºå¯¹æ¼‚ç§»çš„é²æ£’æ€§ã€‚</li>
<li>å¼€å‘æ¸è¿›ä¸ªæ€§åŒ–èåˆç­–ç•¥ï¼Œåœ¨æ¨¡å‹åˆ†å¸ƒæ—¶å¹³è¡¡çŸ¥è¯†è½¬ç§»å’Œä¸ªæ€§åŒ–ç‰¹å¾ã€‚</li>
<li>åœ¨æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨ç‰¹å¾ç›¸ä¼¼æ€§æ¥å¼•å¯¼ä»æ ‘ç»“æ„ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ¨¡å‹é“¾ï¼Œä»¥å®ç°åˆ†å±‚çŸ¥è¯†çš„å……åˆ†åˆ©ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18268">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-422bcd0f27b2428d74e339646f0f4828~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178536&auth_key=1761178536-0-0-283546673689b81b9dd5c85b3b5b58ae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-277c47c3e16ae60c12346d7287cd8dc1~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178544&auth_key=1761178544-0-0-b69e929702e1f288716999336d2c3249&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3d5a4dedaef102bb5d197b21f386a38f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178551&auth_key=1761178551-0-0-7f2a93492048fcbf790f12610b6a1a6e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d393e9b9507f87efb721d6aa664e5aa5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178557&auth_key=1761178557-0-0-eeb66ac2562a823fa4d44a8b6d331025&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0692043ab2251e76dea7090a4233b9ec~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178564&auth_key=1761178564-0-0-6fa50c5a4a567ca01a16624131025df4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EMA-SAM-Exponential-Moving-average-for-SAM-based-PTMC-Segmentation"><a href="#EMA-SAM-Exponential-Moving-average-for-SAM-based-PTMC-Segmentation" class="headerlink" title="EMA-SAM: Exponential Moving-average for SAM-based PTMC Segmentation"></a>EMA-SAM: Exponential Moving-average for SAM-based PTMC Segmentation</h2><p><strong>Authors:Maryam Dialameh, Hossein Rajabzadeh, Jung Suk Sim, Hyock Ju Kwon</strong></p>
<p>Papillary thyroid microcarcinoma (PTMC) is increasingly managed with radio-frequency ablation (RFA), yet accurate lesion segmentation in ultrasound videos remains difficult due to low contrast, probe-induced motion, and heat-related artifacts. The recent Segment Anything Model 2 (SAM-2) generalizes well to static images, but its frame-independent design yields unstable predictions and temporal drift in interventional ultrasound. We introduce \textbf{EMA-SAM}, a lightweight extension of SAM-2 that incorporates a confidence-weighted exponential moving average pointer into the memory bank, providing a stable latent prototype of the tumour across frames. This design preserves temporal coherence through probe pressure and bubble occlusion while rapidly adapting once clear evidence reappears. On our curated PTMC-RFA dataset (124 minutes, 13 patients), EMA-SAM improves \emph{maxDice} from 0.82 (SAM-2) to 0.86 and \emph{maxIoU} from 0.72 to 0.76, while reducing false positives by 29%. On external benchmarks, including VTUS and colonoscopy video polyp datasets, EMA-SAM achieves consistent gains of 2â€“5 Dice points over SAM-2. Importantly, the EMA pointer adds \textless0.1% FLOPs, preserving real-time throughput of $\sim$30,FPS on a single A100 GPU. These results establish EMA-SAM as a robust and efficient framework for stable tumour tracking, bridging the gap between foundation models and the stringent demands of interventional ultrasound. Codes are available here \hyperref[code {<a target="_blank" rel="noopener" href="https://github.com/mdialameh/EMA-SAM%7D">https://github.com/mdialameh/EMA-SAM}</a>. </p>
<blockquote>
<p>ç”²çŠ¶è…ºå¾®å°ä¹³å¤´çŠ¶ç™Œï¼ˆPTMCï¼‰è¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨å°„é¢‘æ¶ˆèï¼ˆRFAï¼‰è¿›è¡Œæ²»ç–—ï¼Œä½†ç”±äºè¶…å£°è§†é¢‘ä¸­çš„ä½å¯¹æ¯”åº¦ã€æ¢é’ˆå¼•èµ·çš„è¿åŠ¨ä»¥åŠçƒ­ç›¸å…³ä¼ªå½±ï¼Œå‡†ç¡®çš„ç—…ç¶åˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªéš¾é¢˜ã€‚æœ€è¿‘çš„Segment Anything Model 2ï¼ˆSAM-2ï¼‰å¯¹é™æ€å›¾åƒå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œä½†å…¶ç‹¬ç«‹äºå¸§çš„è®¾è®¡å¯¼è‡´é¢„æµ‹ä¸ç¨³å®šå’Œä»‹å…¥è¶…å£°ä¸­çš„æ—¶é—´æ¼‚ç§»ã€‚æˆ‘ä»¬å¼•å…¥äº†EMA-SAMï¼Œå®ƒæ˜¯SAM-2çš„ä¸€ä¸ªè½»é‡çº§æ‰©å±•ï¼Œå®ƒå°†ç½®ä¿¡åº¦åŠ æƒæŒ‡æ•°ç§»åŠ¨å¹³å‡æŒ‡é’ˆå¼•å…¥åˆ°å†…å­˜é“¶è¡Œä¸­ï¼Œä¸ºè·¨å¸§çš„è‚¿ç˜¤æä¾›äº†ä¸€ä¸ªç¨³å®šçš„æ½œåœ¨åŸå‹ã€‚è¿™ç§è®¾è®¡åœ¨æ¢å¤´å‹åŠ›å’Œæ°”æ³¡é—­å¡æ—¶ä¼šä¿ç•™æ—¶é—´çš„è¿è´¯æ€§ï¼Œå½“æ¸…æ™°çš„è¯æ®å†æ¬¡å‡ºç°æ—¶èƒ½å¤Ÿè¿…é€Ÿé€‚åº”ã€‚åœ¨æˆ‘ä»¬çš„å®šåˆ¶çš„PTMC-RFAæ•°æ®é›†ä¸Šï¼ˆ124åˆ†é’Ÿï¼Œ13åæ‚£è€…ï¼‰ï¼ŒEMA-SAMå°†æœ€å¤§Diceç³»æ•°ä»SAM-2çš„0.82æé«˜åˆ°0.86ï¼Œæœ€å¤§IoUä»0.72æé«˜åˆ°0.76ï¼ŒåŒæ—¶å‡å°‘äº†å‡é˜³æ€§ç»“æœè¾¾29%ã€‚åœ¨å¤–éƒ¨åŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŒ…æ‹¬VTUSå’Œç»“è‚ é•œæ£€æŸ¥è§†é¢‘æ¯è‚‰æ•°æ®é›†ï¼ŒEMA-SAMç›¸è¾ƒäºSAM-2å®ç°äº†ç¨³å®šçš„å¢ç›Šï¼ŒDiceç‚¹æ•°æé«˜äº†2-5ç‚¹ã€‚é‡è¦çš„æ˜¯ï¼ŒEMAæŒ‡é’ˆå¢åŠ äº†ä¸åˆ°0.1%çš„FLOPsï¼Œåœ¨å•ä¸ªA100 GPUä¸Šä¿æŒäº†çº¦30 FPSçš„å®æ—¶ååé‡ã€‚è¿™äº›ç»“æœè¯æ˜äº†EMA-SAMæ˜¯ä¸€ä¸ªç¨³å¥ä¸”é«˜æ•ˆçš„æ¡†æ¶ï¼Œç”¨äºç¨³å®šçš„è‚¿ç˜¤è¿½è¸ªï¼Œç¼©å°äº†åŸºç¡€æ¨¡å‹ä¸ä»‹å…¥è¶…å£°çš„ä¸¥æ ¼éœ€æ±‚ä¹‹é—´çš„å·®è·ã€‚ä»£ç å¯é€šè¿‡æ­¤é“¾æ¥è·å¾—ï¼š<a target="_blank" rel="noopener" href="https://github.com/mdialameh/EMA-SAM">https://github.com/mdialameh/EMA-SAM</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.18213v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è®ºæ–‡ä»‹ç»äº†é’ˆå¯¹ä¹³å¤´çŠ¶ç”²çŠ¶è…ºå¾®å°ç™Œï¼ˆPTMCï¼‰çš„å°„é¢‘æ¶ˆèï¼ˆRFAï¼‰æ²»ç–—ä¸­ï¼Œè¶…å£°è§†é¢‘ä¸­çš„ç—…ç¶åˆ†å‰²éš¾é¢˜ã€‚æå‡ºä¸€ç§åä¸ºEMA-SAMçš„æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥ä¿¡å¿ƒåŠ æƒæŒ‡æ•°ç§»åŠ¨å¹³å‡æŒ‡é’ˆåˆ°è®°å¿†é“¶è¡Œä¸­ï¼Œå®ç°äº†å¯¹è‚¿ç˜¤çš„ç¨³å®šè¿½è¸ªï¼Œæé«˜äº†åˆ†å‰²ç²¾åº¦å¹¶é™ä½äº†è¯¯æŠ¥ã€‚åœ¨PTMC-RFAæ•°æ®é›†ä¸Šï¼ŒEMA-SAMç›¸è¾ƒäºSAM-2æé«˜äº†åˆ†å‰²æ•ˆæœï¼Œå¹¶åœ¨å¤–éƒ¨åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†ç¨³å®šçš„æ€§èƒ½æå‡ã€‚EMAæŒ‡é’ˆçš„æ·»åŠ å‡ ä¹ä¸å½±å“è®¡ç®—è´Ÿæ‹…ï¼Œå¯åœ¨å•ä¸ªA100 GPUä¸Šå®ç°å®æ—¶å¤„ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¹³å¤´çŠ¶ç”²çŠ¶è…ºå¾®å°ç™Œï¼ˆPTMCï¼‰çš„å°„é¢‘æ¶ˆèï¼ˆRFAï¼‰æ²»ç–—ä¸­çš„è¶…å£°è§†é¢‘ç—…ç¶åˆ†å‰²é¢ä¸´å›°éš¾ï¼Œä¸»è¦ç”±äºä½å¯¹æ¯”åº¦ã€æ¢é’ˆå¼•èµ·çš„è¿åŠ¨å’Œçƒ­ç›¸å…³ä¼ªå½±ã€‚</li>
<li>Segment Anything Model 2ï¼ˆSAM-2ï¼‰åœ¨é™æ€å›¾åƒä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä»‹å…¥æ€§è¶…å£°ä¸­å­˜åœ¨ä¸ç¨³å®šé¢„æµ‹å’Œæ—¶é—´æ¼‚ç§»çš„é—®é¢˜ã€‚</li>
<li>EMA-SAMæ¨¡å‹æ˜¯SAM-2çš„è½»é‡çº§æ‰©å±•ï¼Œé€šè¿‡å¼•å…¥ä¿¡å¿ƒåŠ æƒæŒ‡æ•°ç§»åŠ¨å¹³å‡æŒ‡é’ˆåˆ°è®°å¿†é“¶è¡Œä¸­ï¼Œæé«˜äº†åˆ†å‰²ç²¾åº¦å¹¶é™ä½äº†è¯¯æŠ¥ã€‚</li>
<li>åœ¨PTMC-RFAæ•°æ®é›†ä¸Šï¼ŒEMA-SAMæé«˜äº†æœ€å¤§Diceç³»æ•°å’Œæœ€å¤§IoUï¼Œå¹¶å‡å°‘äº†è¯¯æŠ¥ã€‚</li>
<li>EMA-SAMåœ¨å¤–éƒ¨åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†ç¨³å®šçš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºSAM-2å¢åŠ äº†2-5ä¸ªDiceç‚¹ã€‚</li>
<li>EMAæŒ‡é’ˆçš„æ·»åŠ å‡ ä¹ä¸å½±å“è®¡ç®—è´Ÿæ‹…ï¼Œå¯å®ç°å®æ—¶å¤„ç†ã€‚</li>
<li>EMA-SAMæ¨¡å‹ä¸ºç¨³å®šçš„è‚¿ç˜¤è¿½è¸ªæä¾›äº†ç¨³å¥ä¸”é«˜æ•ˆçš„æ¡†æ¶ï¼Œç¼©å°äº†åŸºç¡€æ¨¡å‹ä¸ä»‹å…¥æ€§è¶…å£°çš„ä¸¥æ ¼éœ€æ±‚ä¹‹é—´çš„å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.18213">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2c8ba6660d974c6ee219b704f9c103ce~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178571&auth_key=1761178571-0-0-9cfecaf25369349939ffb7dba5bde503&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-83f5b4fe9d554b19a630ececae277123~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178579&auth_key=1761178579-0-0-d2c18fb734c40bc5d888b1e110a6bc90&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Spherical-Radiomics-â€“-A-Novel-Approach-to-Glioblastoma-Radiogenomic-Analysis-of-Heterogeneity"><a href="#Spherical-Radiomics-â€“-A-Novel-Approach-to-Glioblastoma-Radiogenomic-Analysis-of-Heterogeneity" class="headerlink" title="Spherical Radiomics â€“ A Novel Approach to Glioblastoma Radiogenomic   Analysis of Heterogeneity"></a>Spherical Radiomics â€“ A Novel Approach to Glioblastoma Radiogenomic   Analysis of Heterogeneity</h2><p><strong>Authors:Haotian Feng, Ke Sheng</strong></p>
<p>We develop and validate a novel spherical radiomics framework for predicting key molecular biomarkers using multiparametric MRI. Conventional Cartesian radiomics extract tumor features on orthogonal grids, which do not fully capture the tumorâ€™s radial growth patterns and can be insensitive to evolving molecular signatures. In this study, we analyzed GBM radiomic features on concentric 2D shells, which were then mapped onto 2D planes for radiomics analysis. Radiomic features were extracted using PyRadiomics from four different regions in GBM. Feature selection was performed using ANOVA F-statistics. Classification was conducted with multiple machine-learning models. Model interpretability was evaluated through SHAP analysis, clustering analysis, feature significance profiling, and comparison between radiomic patterns and underlying biological processes. Spherical radiomics consistently outperformed conventional 2D and 3D Cartesian radiomics across all prediction tasks. The best framework reached an AUC of 0.85 for MGMT, 0.80 for EGFR, 0.80 for PTEN, and 0.83 for survival prediction. GLCM-derived features were identified as the most informative predictors. Radial transition analysis using the Mann-Whitney U-test demonstrates that transition slopes between T1-weighted contrast-enhancing and T2&#x2F;FLAIR hyperintense lesion regions, as well as between T2 intense lesion and a 2 cm peritumoral expansion region, are significantly associated with biomarker status. Furthermore, the observed radiomic changes along the radial direction closely reflected known biological characteristics. Radiomic features extracted on the spherical surfaces at varying radial distances to the GBM tumor centroid are better correlated with important tumor molecular markers and patient survival than the conventional Cartesian analysis. </p>
<blockquote>
<p>æˆ‘ä»¬å¼€å‘å¹¶éªŒè¯äº†ä¸€ç§æ–°å‹çƒå½¢æ”¾å°„å­¦ç‰¹å¾æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨å¤šå‚æ•°MRIé¢„æµ‹å…³é”®åˆ†å­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚ä¼ ç»Ÿçš„ç¬›å¡å°”æ”¾å°„å­¦åœ¨æ­£äº¤ç½‘æ ¼ä¸Šæå–è‚¿ç˜¤ç‰¹å¾ï¼Œè¿™å¹¶ä¸èƒ½å®Œå…¨æ•æ‰è‚¿ç˜¤çš„å¾„å‘ç”Ÿé•¿æ¨¡å¼ï¼Œå¹¶ä¸”å¯¹ä¸æ–­å‘å±•çš„åˆ†å­ç‰¹å¾å¯èƒ½ä¸æ•æ„Ÿã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨åŒå¿ƒäºŒç»´å¤–å£³ä¸Šåˆ†æäº†GBMçš„æ”¾å°„å­¦ç‰¹å¾ï¼Œç„¶åå°†å…¶æ˜ å°„åˆ°äºŒç»´å¹³é¢ä¸Šè¿›è¡Œæ”¾å°„å­¦åˆ†æã€‚ä½¿ç”¨PyRadiomicsä»GBMçš„å››ä¸ªä¸åŒåŒºåŸŸæå–æ”¾å°„å­¦ç‰¹å¾ã€‚ä½¿ç”¨ANOVA Fç»Ÿè®¡é‡è¿›è¡Œç‰¹å¾é€‰æ‹©ã€‚åˆ†ç±»é‡‡ç”¨å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚é€šè¿‡SHAPåˆ†æã€èšç±»åˆ†æã€ç‰¹å¾æ˜¾è‘—æ€§åˆ†æå’Œæ”¾å°„å­¦æ¨¡å¼ä¸æ½œåœ¨ç”Ÿç‰©å­¦è¿‡ç¨‹ä¹‹é—´çš„æ¯”è¾ƒæ¥è¯„ä¼°æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚çƒå½¢æ”¾å°„å­¦åœ¨æ‰€æœ‰é¢„æµ‹ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„äºŒç»´å’Œä¸‰ç»´ç¬›å¡å°”æ”¾å°„å­¦ã€‚æœ€ä½³æ¡†æ¶å¯¹MGMTçš„AUCè¾¾åˆ°0.85ï¼Œå¯¹EGFRçš„AUCä¸º0.80ï¼Œå¯¹PTENçš„AUCä¸º0.80ï¼Œå¯¹ç”Ÿå­˜é¢„æµ‹çš„AUCä¸º0.83ã€‚GLCMè¡ç”Ÿçš„ç‰¹å¾è¢«è¯†åˆ«ä¸ºæœ€æœ‰ä¿¡æ¯é‡çš„é¢„æµ‹å› å­ã€‚ä½¿ç”¨Mann-Whitney Uæ£€éªŒè¿›è¡Œçš„å¾„å‘è½¬æ¢åˆ†æè¡¨æ˜ï¼ŒT1åŠ æƒå¯¹æ¯”å¢å¼ºåŒºåŸŸä¸T2&#x2F;FLAIRé«˜ä¿¡å·ç—…å˜åŒºåŸŸä¹‹é—´ä»¥åŠT2é«˜ä¿¡å·ç—…å˜åŒºåŸŸä¸å‘¨å›´è‚¿ç˜¤æ‰©å±•åŒºä¹‹é—´çš„è¿‡æ¸¡æ–œç‡ä¸ç”Ÿç‰©æ ‡å¿—ç‰©çŠ¶æ€å¯†åˆ‡ç›¸å…³ã€‚æ­¤å¤–ï¼Œæ²¿å¾„å‘è§‚å¯Ÿåˆ°çš„æ”¾å°„å­¦å˜åŒ–å¯†åˆ‡åæ˜ äº†å·²çŸ¥çš„ç”Ÿç‰©ç‰¹æ€§ã€‚åœ¨è·ç¦»GBMè‚¿ç˜¤ä¸­å¿ƒä¸åŒå¾„å‘è·ç¦»çš„çƒå½¢è¡¨é¢ä¸Šæå–çš„æ”¾å°„å­¦ç‰¹å¾ä¸é‡è¦çš„è‚¿ç˜¤åˆ†å­æ ‡è®°å’Œæ‚£è€…ç”Ÿå­˜æƒ…å†µç›¸æ¯”ï¼Œä¸ä¼ ç»Ÿçš„ç¬›å¡å°”åˆ†æç›¸æ¯”å…·æœ‰æ›´å¥½çš„ç›¸å…³æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.13658v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡å¼€å‘å¹¶éªŒè¯äº†ä¸€ç§æ–°å‹çƒå½¢æ”¾å°„å­¦æ¡†æ¶ï¼Œç”¨äºåˆ©ç”¨å¤šå‚æ•°MRIé¢„æµ‹å…³é”®åˆ†å­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚è¯¥ç ”ç©¶åœ¨åŒå¿ƒäºŒç»´å¤–å£³ä¸Šåˆ†æäº†GBMæ”¾å°„å­¦ç‰¹å¾ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°äºŒç»´å¹³é¢ä¸Šè¿›è¡Œæ”¾å°„å­¦åˆ†æã€‚ä½¿ç”¨PyRadiomicsä»GBMçš„å››ä¸ªä¸åŒåŒºåŸŸä¸­æå–æ”¾å°„å­¦ç‰¹å¾ã€‚é€šè¿‡ANOVA Fç»Ÿè®¡è¿›è¡Œç‰¹å¾é€‰æ‹©ã€‚ä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œåˆ†ç±»ã€‚é€šè¿‡SHAPåˆ†æã€èšç±»åˆ†æã€ç‰¹å¾æ˜¾è‘—æ€§åˆ†æå’Œæ”¾å°„å­¦æ¨¡å¼ä¸åŸºç¡€ç”Ÿç‰©å­¦è¿‡ç¨‹ä¹‹é—´çš„æ¯”è¾ƒæ¥è¯„ä¼°æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚çƒå½¢æ”¾å°„å­¦åœ¨æ‰€æœ‰é¢„æµ‹ä»»åŠ¡ä¸­å‡ä¼˜äºä¼ ç»Ÿçš„äºŒç»´å’Œä¸‰ç»´ç¬›å¡å°”æ”¾å°„å­¦ã€‚æœ€ä½³æ¡†æ¶å¯¹MGMTçš„AUCè¾¾åˆ°0.85ï¼Œå¯¹EGFRå’ŒPTENçš„AUCå‡ä¸º0.80ï¼Œç”Ÿå­˜é¢„æµ‹AUCä¸º0.83ã€‚GLCMè¡ç”Ÿçš„ç‰¹å¾è¢«è¯†åˆ«ä¸ºæœ€æœ‰ä¿¡æ¯é‡çš„é¢„æµ‹å› å­ã€‚é€šè¿‡Mann-Whitney Uæ£€éªŒè¿›è¡Œçš„å¾„å‘è½¬æ¢åˆ†ææ˜¾ç¤ºï¼ŒT1åŠ æƒå¯¹æ¯”å¢å¼ºåŒºåŸŸä¸T2&#x2F;FLAIRé«˜äº®åº¦ç—…å˜åŒºåŸŸä¹‹é—´çš„è½¬æ¢æ–œç‡ä»¥åŠä¸è‚¿ç˜¤å‘¨å›´æ‰©å¼ åŒºåŸŸçš„è½¬æ¢æ–œç‡ä¸ç”Ÿç‰©æ ‡å¿—ç‰©çŠ¶æ€æ˜¾è‘—ç›¸å…³ã€‚æ­¤å¤–ï¼Œè§‚å¯Ÿåˆ°çš„æ²¿å¾„å‘æ–¹å‘çš„æ”¾å°„å­¦å˜åŒ–ç´§å¯†åæ˜ äº†å·²çŸ¥çš„ç”Ÿç‰©ç‰¹æ€§ã€‚ä¸å¸¸è§„ç¬›å¡å°”åˆ†æç›¸æ¯”ï¼Œåœ¨è·GBMè‚¿ç˜¤ä¸­å¿ƒä¸åŒå¾„å‘è·ç¦»çš„çƒå½¢è¡¨é¢ä¸Šæå–çš„æ”¾å°„å­¦ç‰¹å¾ä¸é‡è¦çš„è‚¿ç˜¤åˆ†å­æ ‡è®°ç‰©å’Œæ‚£è€…ç”Ÿå­˜ç‡çš„å…³è”æ›´ä¸ºå¯†åˆ‡ã€‚</p>
<p><strong>å…³é”®å‘ç°</strong></p>
<ol>
<li>å¼€å‘å¹¶éªŒè¯äº†ä¸€ç§æ–°å‹çƒå½¢æ”¾å°„å­¦æ¡†æ¶ï¼Œç”¨äºåˆ©ç”¨å¤šå‚æ•°MRIé¢„æµ‹å…³é”®åˆ†å­ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚</li>
<li>ç›¸æ¯”ä¼ ç»Ÿçš„ç¬›å¡å°”æ”¾å°„å­¦ï¼Œçƒå½¢æ”¾å°„å­¦åœ¨é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°æ›´ä½³ã€‚</li>
<li>æœ€ä½³æ¡†æ¶çš„AUCå€¼è¾ƒé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢„æµ‹MGMTã€EGFRã€PTENä»¥åŠç”Ÿå­˜é¢„æµ‹æ–¹é¢ã€‚</li>
<li>GLCMè¡ç”Ÿçš„ç‰¹å¾æ˜¯æœ€å…·ä¿¡æ¯é‡çš„é¢„æµ‹å› å­ã€‚</li>
<li>å¾„å‘è½¬æ¢åˆ†ææ­ç¤ºäº†ç‰¹å®šåŒºåŸŸé—´è½¬æ¢æ–œç‡ä¸ç”Ÿç‰©æ ‡å¿—ç‰©çŠ¶æ€çš„æ˜¾è‘—å…³è”ã€‚</li>
<li>æ”¾å°„å­¦å˜åŒ–ä¸å·²çŸ¥çš„ç”Ÿç‰©ç‰¹æ€§ç´§å¯†ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.13658">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8fb6e073ecd95df99496c5871a3481c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178586&auth_key=1761178586-0-0-d06d16ef18c170ee03858e351a300c32&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2850f920d68530a85879283320ad3168~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178594&auth_key=1761178594-0-0-4c43c22ca54843ca0e4aa02ac873f7cc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1008f529ababdbd26c1681376a3a6b99~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178601&auth_key=1761178601-0-0-e18d8b4b6f5e743baf7dc4f5528a71aa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4e255918c48b089d3624ba04194e8c9d~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178608&auth_key=1761178608-0-0-6e32386019fe4c9fc269e9559449c08d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GeoCAD-Local-Geometry-Controllable-CAD-Generation-with-Large-Language-Models"><a href="#GeoCAD-Local-Geometry-Controllable-CAD-Generation-with-Large-Language-Models" class="headerlink" title="GeoCAD: Local Geometry-Controllable CAD Generation with Large Language   Models"></a>GeoCAD: Local Geometry-Controllable CAD Generation with Large Language   Models</h2><p><strong>Authors:Zhanwei Zhang, Kaiyuan Liu, Junjie Liu, Wenxiao Wang, Binbin Lin, Liang Xie, Chen Shen, Deng Cai</strong></p>
<p>Local geometry-controllable computer-aided design (CAD) generation aims to modify local parts of CAD models automatically, enhancing design efficiency. It also ensures that the shapes of newly generated local parts follow user-specific geometric instructions (e.g., an isosceles right triangle or a rectangle with one corner cut off). However, existing methods encounter challenges in achieving this goal. Specifically, they either lack the ability to follow textual instructions or are unable to focus on the local parts. To address this limitation, we introduce GeoCAD, a user-friendly and local geometry-controllable CAD generation method. Specifically, we first propose a complementary captioning strategy to generate geometric instructions for local parts. This strategy involves vertex-based and VLLM-based captioning for systematically annotating simple and complex parts, respectively. In this way, we caption $\sim$221k different local parts in total. In the training stage, given a CAD model, we randomly mask a local part. Then, using its geometric instruction and the remaining parts as input, we prompt large language models (LLMs) to predict the masked part. During inference, users can specify any local part for modification while adhering to a variety of predefined geometric instructions. Extensive experiments demonstrate the effectiveness of GeoCAD in generation quality, validity and text-to-CAD consistency. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/Zhanwei-Z/GeoCAD">https://github.com/Zhanwei-Z/GeoCAD</a>. </p>
<blockquote>
<p>å±€éƒ¨å‡ ä½•å¯æ§è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆæ—¨åœ¨è‡ªåŠ¨ä¿®æ”¹CADæ¨¡å‹çš„éƒ¨åˆ†ï¼Œæé«˜è®¾è®¡æ•ˆç‡ã€‚åŒæ—¶ï¼Œå®ƒè¿˜èƒ½ç¡®ä¿æ–°ç”Ÿæˆçš„å±€éƒ¨éƒ¨ä»¶çš„å½¢çŠ¶ç¬¦åˆç”¨æˆ·ç‰¹å®šçš„å‡ ä½•æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼Œç­‰è…°ç›´è§’ä¸‰è§’å½¢æˆ–åˆ‡æ‰ä¸€è§’çš„çŸ©å½¢ï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å®ç°è¿™ä¸€ç›®æ ‡æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä»¬è¦ä¹ˆæ— æ³•éµå¾ªæ–‡æœ¬æŒ‡ä»¤ï¼Œè¦ä¹ˆæ— æ³•ä¸“æ³¨äºå±€éƒ¨éƒ¨ä»¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†GeoCADï¼Œè¿™æ˜¯ä¸€ç§ç”¨æˆ·å‹å¥½ã€å±€éƒ¨å‡ ä½•å¯æ§çš„CADç”Ÿæˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§è¡¥å……æ ‡é¢˜ç­–ç•¥ï¼Œä¸ºå±€éƒ¨éƒ¨ä»¶ç”Ÿæˆå‡ ä½•æŒ‡ä»¤ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬åŸºäºé¡¶ç‚¹å’ŒåŸºäºVLLMçš„æ ‡é¢˜ï¼Œåˆ†åˆ«ç”¨äºç³»ç»Ÿæ³¨é‡Šç®€å•å’Œå¤æ‚éƒ¨ä»¶ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æ€»å…±æ ‡æ³¨äº†çº¦22ä¸‡1åƒä¸ªä¸åŒçš„å±€éƒ¨éƒ¨ä»¶ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œç»™å®šä¸€ä¸ªCADæ¨¡å‹ï¼Œæˆ‘ä»¬éšæœºé®æŒ¡ä¸€ä¸ªå±€éƒ¨éƒ¨ä»¶ã€‚ç„¶åï¼Œåˆ©ç”¨å…¶å‡ ä½•æŒ‡ä»¤å’Œå‰©ä½™éƒ¨ä»¶ä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬æç¤ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„æµ‹è¢«é®æŒ¡çš„éƒ¨åˆ†ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šä»»ä½•å±€éƒ¨éƒ¨ä»¶è¿›è¡Œä¿®æ”¹ï¼ŒåŒæ—¶éµå¾ªå¤šç§é¢„å®šä¹‰çš„å‡ ä½•æŒ‡ä»¤ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGeoCADåœ¨ç”Ÿæˆè´¨é‡ã€æœ‰æ•ˆæ€§å’Œæ–‡æœ¬åˆ°CADçš„ä¸€è‡´æ€§æ–¹é¢éƒ½éå¸¸æœ‰æ•ˆã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Zhanwei-Z/GeoCAD">https://github.com/Zhanwei-Z/GeoCAD</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10337v2">PDF</a> Accepted by NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§åä¸ºGeoCADçš„ç”¨æˆ·å‹å¥½å‹æœ¬åœ°å‡ ä½•å¯æ§è®¡ç®—æœºè¾…åŠ©è®¾è®¡ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡äº’è¡¥æ ‡æ³¨ç­–ç•¥ç”Ÿæˆå±€éƒ¨å‡ ä½•æŒ‡ä»¤ï¼Œé‡‡ç”¨é¡¶ç‚¹åŸºå’ŒVLLMåŸºæ ‡æ³¨æ–¹å¼åˆ†åˆ«æ ‡æ³¨ç®€å•å’Œå¤æ‚éƒ¨ä»¶ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œéšæœºé®æŒ¡CADæ¨¡å‹ä¸­çš„å±€éƒ¨éƒ¨ä»¶ï¼Œåˆ©ç”¨å‡ ä½•æŒ‡ä»¤å’Œå‰©ä½™éƒ¨ä»¶ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹é¢„æµ‹é®æŒ¡éƒ¨ä»¶ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç”¨æˆ·å¯æŒ‡å®šä»»ä½•å±€éƒ¨éƒ¨ä»¶è¿›è¡Œä¿®æ”¹ï¼ŒåŒæ—¶éµå¾ªå¤šç§é¢„å®šä¹‰çš„å‡ ä½•æŒ‡ä»¤ã€‚è¯¥æ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡ã€æœ‰æ•ˆæ€§å’Œæ–‡æœ¬åˆ°CADçš„ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GeoCADæ˜¯ä¸€ç§ç”¨æˆ·å‹å¥½å‹ã€å±€éƒ¨å‡ ä½•å¯æ§çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>GeoCADé‡‡ç”¨äº’è¡¥æ ‡æ³¨ç­–ç•¥ç”Ÿæˆå±€éƒ¨å‡ ä½•æŒ‡ä»¤ã€‚</li>
<li>GeoCADé€šè¿‡é¡¶ç‚¹åŸºå’ŒVLLMåŸºæ ‡æ³¨æ–¹å¼åˆ†åˆ«å¤„ç†ç®€å•å’Œå¤æ‚éƒ¨ä»¶çš„æ ‡æ³¨ã€‚</li>
<li>åœ¨è®­ç»ƒé˜¶æ®µï¼ŒGeoCADé€šè¿‡éšæœºé®æŒ¡CADæ¨¡å‹ä¸­çš„å±€éƒ¨éƒ¨ä»¶ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚</li>
<li>ç”¨æˆ·å¯æŒ‡å®šä»»ä½•å±€éƒ¨éƒ¨ä»¶è¿›è¡Œä¿®æ”¹ï¼Œå¹¶éµå¾ªå¤šç§é¢„å®šä¹‰çš„å‡ ä½•æŒ‡ä»¤ã€‚</li>
<li>GeoCADåœ¨ç”Ÿæˆè´¨é‡ã€æœ‰æ•ˆæ€§å’Œæ–‡æœ¬åˆ°CADçš„ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5c428ef56b7d2f179f0562de9c85e6b3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178616&auth_key=1761178616-0-0-8f4e8fd086f9403d74138cd8bc66c1f3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7de652074f2479549fa4d7080f512d6a~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178623&auth_key=1761178623-0-0-73b6f500e9d7dbdb9d78d78422755088&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8f75b1607519c11708af755a419f4ed6~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178630&auth_key=1761178630-0-0-f2ad7cfcdac7d7401ca5f7218a6292fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-efac1f30db1974c9ec432c1811f9253c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178637&auth_key=1761178637-0-0-f59ecf4fa198cef667a84cf7c6de2671&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CAD-Coder-Text-to-CAD-Generation-with-Chain-of-Thought-and-Geometric-Reward"><a href="#CAD-Coder-Text-to-CAD-Generation-with-Chain-of-Thought-and-Geometric-Reward" class="headerlink" title="CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric   Reward"></a>CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric   Reward</h2><p><strong>Authors:Yandong Guan, Xilin Wang, Ximing Xing, Jing Zhang, Dong Xu, Qian Yu</strong></p>
<p>In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametric CAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CAD-Coderè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒå°†æ–‡æœ¬åˆ°CADçš„è½¬æ¢é‡æ–°å®šä¹‰ä¸ºCadQueryè„šæœ¬çš„ç”Ÿæˆâ€”â€”ä¸€ç§åŸºäºPythonçš„å‚æ•°åŒ–CADè¯­è¨€ã€‚è¿™ç§è¡¨ç¤ºæ–¹æ³•èƒ½å¤Ÿå®ç°ç›´æ¥çš„å‡ ä½•éªŒè¯ã€æ›´ä¸°å¯Œçš„å»ºæ¨¡è¯æ±‡ï¼Œä»¥åŠä¸ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ— ç¼é›†æˆã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ä»£ç çš„æœ‰æ•ˆæ€§å’Œå‡ ä½•ä¿çœŸåº¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„å­¦ä¹ ç®¡é“ï¼šï¼ˆ1ï¼‰åœ¨æˆå¯¹çš„æ–‡æœ¬-CadQueryæ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼›ï¼ˆ2ï¼‰é‡‡ç”¨ç¾¤ä½“å¥–åŠ±æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ ï¼Œç”±åŒ…æ‹¬å‡ ä½•å¥–åŠ±ï¼ˆChamferè·ç¦»ï¼‰å’Œæ ¼å¼å¥–åŠ±åœ¨å†…çš„CADç‰¹å®šå¥–åŠ±è¿›è¡ŒæŒ‡å¯¼ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†æ€ç»´é“¾ï¼ˆCoTï¼‰è§„åˆ’è¿‡ç¨‹ï¼Œä»¥æé«˜æ¨¡å‹æ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡è‡ªåŠ¨åŒ–ç®¡é“æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„åŒ…å«110Kä¸ªæ–‡æœ¬-CadQuery-3Dæ¨¡å‹ä¸‰å…ƒç»„å’Œ1.5Kä¸ªCoTæ ·æœ¬çš„æ•°æ®é›†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCAD-Coderä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç›´æ¥ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆå¤šæ ·ã€æœ‰æ•ˆå’Œå¤æ‚çš„CADæ¨¡å‹ï¼Œæ¨åŠ¨äº†æ–‡æœ¬åˆ°CADç”Ÿæˆå’Œå‡ ä½•æ¨ç†çš„æœ€æ–°æŠ€æœ¯è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19713v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>CAD-Coderæ¡†æ¶èƒ½å°†æ–‡æœ¬è½¬åŒ–ä¸ºCADè®¾è®¡ï¼Œé€šè¿‡ç”ŸæˆCadQueryè„šæœ¬å®ç°ã€‚è¯¥æ¡†æ¶æ”¯æŒç›´æ¥å‡ ä½•éªŒè¯ã€ä¸°å¯Œçš„å»ºæ¨¡è¯æ±‡ï¼Œå¹¶èƒ½æ— ç¼èå…¥ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ä¸ºæé«˜ä»£ç æœ‰æ•ˆæ€§å’Œå‡ ä½•ä¿çœŸåº¦ï¼Œç ”ç©¶æå‡ºä¸¤é˜¶æ®µå­¦ä¹ ç®¡é“ï¼šç›‘ç£å¾®è°ƒä¸é…å¯¹æ–‡æœ¬-CadQueryæ•°æ®å¼ºåŒ–å­¦ä¹ ã€‚æ­¤å¤–ï¼Œå¼•å…¥æ€ç»´é“¾è§„åˆ’è¿‡ç¨‹æ”¹å–„æ¨¡å‹æ¨ç†ï¼Œå¹¶é€šè¿‡è‡ªåŠ¨åŒ–ç®¡é“æ„å»ºå¤§å‹é«˜è´¨é‡æ•°æ®é›†ã€‚å®éªŒè¯æ˜ï¼ŒCAD-Coderä½¿LLMsèƒ½ç›´æ¥ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆå¤šæ ·ã€æœ‰æ•ˆã€å¤æ‚çš„CADæ¨¡å‹ï¼Œæ¨åŠ¨æ–‡æœ¬åˆ°CADç”Ÿæˆå’Œå‡ ä½•æ¨ç†é¢†åŸŸçš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CAD-Coderæ¡†æ¶å°†æ–‡æœ¬è½¬åŒ–ä¸ºCADè®¾è®¡ï¼Œé€šè¿‡ç”ŸæˆCadQueryè„šæœ¬å®ç°ï¼Œæ”¯æŒç›´æ¥å‡ ä½•éªŒè¯å’Œä¸°å¯Œçš„å»ºæ¨¡è¯­è¨€ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨ä¸¤é˜¶æ®µå­¦ä¹ ç®¡é“ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ï¼Œæé«˜ä»£ç æœ‰æ•ˆæ€§å’Œå‡ ä½•ä¿çœŸåº¦ã€‚</li>
<li>å¼•å…¥æ€ç»´é“¾ï¼ˆCoTï¼‰è§„åˆ’è¿‡ç¨‹ï¼Œæ”¹å–„æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚</li>
<li>æ„å»ºå¤§å‹é«˜è´¨é‡æ•°æ®é›†ï¼ŒåŒ…å«110Kæ–‡æœ¬-CadQuery-3Dæ¨¡å‹ä¸‰å…ƒç»„å’Œ1.5Kæ€ç»´é“¾æ ·æœ¬ã€‚</li>
<li>CAD-Coderæ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ã€æœ‰æ•ˆã€å¤æ‚çš„CADæ¨¡å‹ã€‚</li>
<li>è¯¥æ¡†æ¶æ¨åŠ¨äº†æ–‡æœ¬åˆ°CADç”Ÿæˆé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯å‘å±•æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19713">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5e694957e3bcdb4cb41af2c89af311cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178643&auth_key=1761178643-0-0-f62b64fe6e6f73a8de6179c68c7eaf40&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-325289a9ce2e1548256c6f53f002686f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178651&auth_key=1761178651-0-0-af62d18c2ce0957932628670d9db008e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-69e3a0b1472798b3cf897d12a1f99e67~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178658&auth_key=1761178658-0-0-f07f2e1f993bea41893db6b82d730fff&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Sampling-Kantorovich-operators-for-speckle-noise-reduction-using-a-Down-Up-scaling-approach-and-gap-filling-in-remote-sensing-images"><a href="#Sampling-Kantorovich-operators-for-speckle-noise-reduction-using-a-Down-Up-scaling-approach-and-gap-filling-in-remote-sensing-images" class="headerlink" title="Sampling Kantorovich operators for speckle noise reduction using a   Down-Up scaling approach and gap filling in remote sensing images"></a>Sampling Kantorovich operators for speckle noise reduction using a   Down-Up scaling approach and gap filling in remote sensing images</h2><p><strong>Authors:Danilo Costarelli, Mariarosaria Natale</strong></p>
<p>In the literature, several approaches have been proposed for restoring and enhancing remote sensing images, including methods based on interpolation, filtering, and deep learning. In this paper, we investigate the application of multivariate sampling Kantorovich (SK) operators for image reconstruction, with a particular focus on gap filling and speckle noise reduction. To understand the accuracy performances of the proposed algorithms, we first derive a quantitative estimate in $C(\R^n)$ for the error of approximation using the Euler-Maclaurin summation formula, under weak regularity conditions. We also establish a convergence result and a quantitative estimate with respect to the dissimilarity index measured by the continuous SSIM for functions in Lebesgue spaces. Additionally, we prove a multidimensional linear prediction result, which is used to design a new SK-based reconstruction algorithm to handle missing data, that we call LP-SK algorithm. To address speckle noise, we integrate SK operators into a newly proposed Down-Up scaling approach. Numerical tests are presented on synthetic and real SAR images to validate the proposed methods. Performance is assessed using similarity metrics such as SSIM and PSNR, along with speckle-specific indexes. Comparative analysis with state-of-the-art techniques highlights the effectiveness of the proposed approaches. </p>
<blockquote>
<p>åœ¨æ–‡çŒ®ä¸­ï¼Œå·²ç»æå‡ºäº†å¤šç§ç”¨äºæ¢å¤å’Œå¢å¼ºé¥æ„Ÿå›¾åƒçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºæ’å€¼ã€æ»¤æ³¢å’Œæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ã€‚æœ¬æ–‡ç ”ç©¶äº†å¤šå…ƒé‡‡æ ·Kantorovichï¼ˆSKï¼‰ç®—å­åœ¨å›¾åƒé‡å»ºä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«å…³æ³¨é—´éš™å¡«å……å’Œæ–‘ç‚¹å™ªå£°å‡å°‘ã€‚ä¸ºäº†äº†è§£æ‰€æå‡ºç®—æ³•çš„å‡†ç¡®æ€§èƒ½ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ©ç”¨æ¬§æ‹‰-éº¦å…‹åŠ³æ—æ±‚å’Œå…¬å¼ï¼Œåœ¨è¾ƒå¼±çš„æ­£åˆ™æ¡ä»¶ä¸‹ï¼Œå¯¹è¿‘ä¼¼è¯¯å·®è¿›è¡Œäº†å®šé‡ä¼°è®¡ã€‚æˆ‘ä»¬è¿˜å»ºç«‹äº†å…³äºå‹’è´æ ¼ç©ºé—´ä¸­å‡½æ•°çš„ä¸ç›¸ä¼¼æ€§æŒ‡æ•°æµ‹é‡çš„æ”¶æ•›ç»“æœå’Œå®šé‡ä¼°è®¡ï¼Œå¹¶è¯æ˜äº†å¤šç»´çº¿æ€§é¢„æµ‹ç»“æœï¼Œè¯¥ç»“æœç”¨äºè®¾è®¡ä¸€ç§å¤„ç†ç¼ºå¤±æ•°æ®çš„æ–°SKé‡å»ºç®—æ³•ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºLP-SKç®—æ³•ã€‚ä¸ºè§£å†³æ–‘ç‚¹å™ªå£°é—®é¢˜ï¼Œæˆ‘ä»¬å°†SKç®—å­é›†æˆåˆ°æ–°æå‡ºçš„ä¸Šä¸‹ç¼©æ”¾æ–¹æ³•ä¸­ã€‚å¯¹åˆæˆå’ŒçœŸå®SARå›¾åƒè¿›è¡Œäº†æ•°å€¼æµ‹è¯•ï¼Œä»¥éªŒè¯æ‰€æå‡ºçš„æ–¹æ³•ã€‚æ€§èƒ½è¯„ä¼°ä½¿ç”¨SSIMå’ŒPSNRç­‰ç›¸ä¼¼åº¦åº¦é‡ä»¥åŠæ–‘ç‚¹ç‰¹å®šæŒ‡æ ‡ã€‚ä¸æœ€æ–°æŠ€æœ¯çš„æ¯”è¾ƒåˆ†æçªå‡ºäº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02422v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ’å€¼ã€æ»¤æ³¢å’Œæ·±åº¦å­¦ä¹ ç­‰æ–¹æ³•ï¼Œæ–‡çŒ®ä¸­æå‡ºäº†å¤šç§é¥æ„Ÿå›¾åƒæ¢å¤å’Œå¢å¼ºçš„æ–¹æ³•ã€‚æœ¬æ–‡ç ”ç©¶åº”ç”¨å¤šå…ƒé‡‡æ ·Kantorovichï¼ˆSKï¼‰ç®—å­è¿›è¡Œå›¾åƒé‡å»ºï¼Œç‰¹åˆ«å…³æ³¨æ•°æ®å¡«å……å’Œæ–‘ç‚¹å™ªå£°å‡å°‘ã€‚æœ¬æ–‡æ¨å¯¼äº†ä½¿ç”¨Euler-Maclaurinæ±‚å’Œå…¬å¼è¿›è¡Œè¿‘ä¼¼è¯¯å·®çš„å®šé‡ä¼°è®¡ï¼Œå»ºç«‹äº†å…³äºè¿ç»­SSIMæµ‹é‡çš„æ”¶æ•›ç»“æœå’Œå®šé‡ä¼°è®¡ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¯æ˜äº†ç”¨äºå¤„ç†ç¼ºå¤±æ•°æ®çš„åŸºäºSKé‡å»ºç®—æ³•çš„å¤šç»´çº¿æ€§é¢„æµ‹ç»“æœã€‚ä¸ºäº†è§£å†³æ–‘ç‚¹å™ªå£°é—®é¢˜ï¼Œæˆ‘ä»¬å°†SKç®—å­é›†æˆåˆ°ä¸€ç§æ–°çš„ä¸‹é‡‡æ ·ä¸Šé‡‡æ ·ç¼©æ”¾æ–¹æ³•ä¸­ã€‚æ•°å€¼æµ‹è¯•è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®SARå›¾åƒä¸Šçš„æ€§èƒ½ä¼˜å¼‚ã€‚é€šè¿‡å¯¹æ¯”æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼ŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶äº†å¤šå…ƒé‡‡æ ·Kantorovichï¼ˆSKï¼‰ç®—å­åœ¨é¥æ„Ÿå›¾åƒæ¢å¤ä¸­çš„åº”ç”¨ã€‚</li>
<li>æ¨å¯¼äº†è¿‘ä¼¼è¯¯å·®çš„å®šé‡ä¼°è®¡æ–¹æ³•ã€‚</li>
<li>å»ºç«‹äº†å…³äºè¿ç»­SSIMæµ‹é‡çš„æ”¶æ•›æ€§å’Œå®šé‡ä¼°è®¡ã€‚</li>
<li>è¯æ˜äº†å¤„ç†ç¼ºå¤±æ•°æ®çš„åŸºäºSKé‡å»ºç®—æ³•çš„å¤šç»´çº¿æ€§é¢„æµ‹ç»“æœã€‚</li>
<li>é›†æˆSKç®—å­åˆ°ä¸€ç§æ–°é¢–çš„ä¸‹é‡‡æ ·ä¸Šé‡‡æ ·ç¼©æ”¾æ–¹æ³•ä»¥è§£å†³æ–‘ç‚¹å™ªå£°é—®é¢˜ã€‚</li>
<li>é€šè¿‡æ•°å€¼æµ‹è¯•éªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬åœ¨åˆæˆå’ŒçœŸå®SARå›¾åƒä¸Šçš„æµ‹è¯•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02422">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-67414038a45704bb84b3b5a804d03502~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178665&auth_key=1761178665-0-0-433416ed99ec75d49b392ca4d9369bc1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Regression-is-all-you-need-for-medical-image-translation"><a href="#Regression-is-all-you-need-for-medical-image-translation" class="headerlink" title="Regression is all you need for medical image translation"></a>Regression is all you need for medical image translation</h2><p><strong>Authors:Sebastian Rassmann, David KÃ¼gler, Christian Ewert, Martin Reuter</strong></p>
<p>While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have achieved impressive results in natural image synthesis, their core strengths - creativity and realism - can be detrimental in medical applications, where accuracy and fidelity are paramount. These models instead risk introducing hallucinations and replication of unwanted acquisition noise. Here, we propose YODA (You Only Denoise once - or Average), a 2.5D diffusion-based framework for medical image translation (MIT). Consistent with DM theory, we find that conventional diffusion sampling stochastically replicates noise. To mitigate this, we draw and average multiple samples, akin to physical signal averaging. As this effectively approximates the DMâ€™s expected value, we term this Expectation-Approximation (ExpA) sampling. We additionally propose regression sampling YODA, which retains the initial DM prediction and omits iterative refinement to produce noise-free images in a single step. Across five diverse multi-modal datasets - including multi-contrast brain MRI and pelvic MRI-CT - we demonstrate that regression sampling is not only substantially more efficient but also matches or exceeds image quality of full diffusion sampling even with ExpA. Our results reveal that iterative refinement solely enhances perceptual realism without benefiting information translation, which we confirm in relevant downstream tasks. YODA outperforms eight state-of-the-art DMs and GANs and challenges the presumed superiority of DMs and GANs over computationally cheap regression models for high-quality MIT. Furthermore, we show that YODA-translated images are interchangeable with, or even superior to, physical acquisitions for several medical applications. </p>
<blockquote>
<p>å°½ç®¡ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨è‡ªç„¶å›¾åƒåˆæˆæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†å®ƒä»¬åœ¨åŒ»å­¦åº”ç”¨ä¸­çš„æ ¸å¿ƒä¼˜åŠ¿â€”â€”åˆ›é€ æ€§å’Œé€¼çœŸæ€§â€”â€”å¯èƒ½ä¼šå¸¦æ¥è´Ÿé¢å½±å“ï¼Œå› ä¸ºåœ¨åŒ»å­¦åº”ç”¨ä¸­ï¼Œå‡†ç¡®æ€§å’Œä¿çœŸåº¦æ˜¯è‡³å…³é‡è¦çš„ã€‚è¿™äº›æ¨¡å‹åè€Œå¯èƒ½å¼•å…¥å¹»è§‰å’Œå¤åˆ¶ä¸éœ€è¦çš„é‡‡é›†å™ªå£°ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†YODAï¼ˆYou Only Denoise once - or Averageï¼Œä»…å»å™ªä¸€æ¬¡æˆ–å¹³å‡ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£çš„åŒ»å­¦å›¾åƒç¿»è¯‘ï¼ˆMITï¼‰çš„2.5Dæ¡†æ¶ã€‚ç¬¦åˆDMç†è®ºï¼Œæˆ‘ä»¬å‘ç°ä¼ ç»Ÿçš„æ‰©æ•£é‡‡æ ·ä¼šéšæœºå¤åˆ¶å™ªå£°ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç»˜åˆ¶å¹¶å¹³å‡å¤šä¸ªæ ·æœ¬ï¼Œç±»ä¼¼äºç‰©ç†ä¿¡å·å¹³å‡ã€‚ç”±äºè¿™æœ‰æ•ˆåœ°è¿‘ä¼¼äº†DMçš„æœŸæœ›å€¼ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºæœŸæœ›è¿‘ä¼¼ï¼ˆExpAï¼‰é‡‡æ ·ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†å›å½’é‡‡æ ·YODAï¼Œå®ƒä¿ç•™äº†åˆå§‹DMé¢„æµ‹å€¼ï¼Œå¹¶çœç•¥äº†è¿­ä»£ç»†åŒ–ï¼Œä»¥å•æ­¥ç”Ÿæˆæ— å™ªå£°å›¾åƒã€‚åœ¨äº”ä¸ªå¤šæ ·åŒ–çš„å¤šæ¨¡å¼æ•°æ®é›†ä¸Šâ€”â€”åŒ…æ‹¬å¤šå¯¹æ¯”åº¦è„‘éƒ¨MRIå’Œç›†è…”MRI-CTâ€”â€”æˆ‘ä»¬è¯æ˜å›å½’é‡‡æ ·ä¸ä»…å¤§å¤§æé«˜äº†æ•ˆç‡ï¼Œè€Œä¸”å³ä½¿ä½¿ç”¨ExpAï¼Œå…¶å›¾åƒè´¨é‡ä¹Ÿä¸å…¨æ‰©æ•£é‡‡æ ·ç›¸åŒ¹é…æˆ–æ›´é«˜ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè¿­ä»£ç»†åŒ–åªæ˜¯æé«˜äº†æ„ŸçŸ¥çš„é€¼çœŸåº¦ï¼Œå¹¶æ²¡æœ‰æé«˜ä¿¡æ¯ç¿»è¯‘çš„è´¨é‡ï¼Œè¿™ä¸€ç‚¹åœ¨ç›¸å…³çš„ä¸‹æ¸¸ä»»åŠ¡ä¸­ä¹Ÿå¾—åˆ°äº†è¯å®ã€‚YODAè¡¨ç°ä¼˜äºå…«ç§æœ€å…ˆè¿›çš„DMså’ŒGANsï¼Œå¹¶æŒ‘æˆ˜äº†DMså’ŒGANsåœ¨é«˜è´¨é‡MITæ–¹é¢ç›¸å¯¹äºè®¡ç®—æˆæœ¬è¾ƒä½çš„å›å½’æ¨¡å‹çš„å‡å®šä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼ŒYODAç¿»è¯‘çš„å›¾åƒå¯ä¸å¤šç§åŒ»å­¦åº”ç”¨ä¸­çš„ç‰©ç†é‡‡é›†äº’æ¢ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°æ›´ä½³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02048v3">PDF</a> </p>
<p><strong>Summary</strong><br>    YODAæ˜¯ä¸€ç§ç”¨äºåŒ»å­¦å›¾åƒç¿»è¯‘ï¼ˆMITï¼‰çš„2.5Dæ‰©æ•£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨åŒ»å­¦åº”ç”¨ä¸­å¼•å…¥çš„å™ªå£°å’Œå¹»è§‰é—®é¢˜ã€‚YODAé€šè¿‡å¤šæ¬¡é‡‡æ ·å¹³å‡æ¥æé«˜å›¾åƒè´¨é‡ï¼Œå¹¶å¼•å…¥æœŸæœ›è¿‘ä¼¼ï¼ˆExpAï¼‰é‡‡æ ·å’Œå›å½’é‡‡æ ·æ–¹æ³•ã€‚åœ¨å¤šä¸ªå¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå›å½’é‡‡æ ·ä¸ä»…æ•ˆç‡æ›´é«˜ï¼Œè€Œä¸”å›¾åƒè´¨é‡ä¸å…¨æ‰©æ•£é‡‡æ ·ç›¸åŒ¹é…æˆ–æ›´é«˜ã€‚YODAæŒ‘æˆ˜äº†DMså’ŒGANsåœ¨è®¡ç®—æˆæœ¬è¾ƒä½çš„å›å½’æ¨¡å‹ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œå¹¶è¯æ˜å…¶ç¿»è¯‘çš„å›¾åƒå¯äº’æ¢æˆ–ä¼˜äºç‰©ç†é‡‡é›†çš„å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>YODAæ˜¯ä¸€ç§é’ˆå¯¹åŒ»å­¦å›¾åƒç¿»è¯‘çš„2.5Dæ‰©æ•£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³GANså’ŒDMsåœ¨åŒ»å­¦åº”ç”¨ä¸­å¯èƒ½å¼•å…¥çš„å™ªå£°å’Œå¹»è§‰é—®é¢˜ã€‚</li>
<li>YODAé€šè¿‡å¤šæ¬¡é‡‡æ ·å¹³å‡æ¥æé«˜å›¾åƒè´¨é‡ï¼Œæå‡ºäº†æœŸæœ›è¿‘ä¼¼ï¼ˆExpAï¼‰é‡‡æ ·æ–¹æ³•ã€‚</li>
<li>å›å½’é‡‡æ ·æ–¹æ³•åœ¨YODAä¸­è¢«å¼•å…¥ï¼Œè¯¥æ–¹æ³•ä¿ç•™äº†åˆå§‹DMé¢„æµ‹ï¼Œå¹¶äº§ç”Ÿæ— å™ªå£°å›¾åƒï¼Œæ— éœ€è¿­ä»£ä¼˜åŒ–ã€‚</li>
<li>åœ¨å¤šä¸ªå¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå›å½’é‡‡æ ·ä¸ä»…æ•ˆç‡æ›´é«˜ï¼Œè€Œä¸”å›¾åƒè´¨é‡è‡³å°‘ä¸å…¨æ‰©æ•£é‡‡æ ·ç›¸åŒ¹é…ã€‚</li>
<li>YODAæŒ‘æˆ˜äº†DMså’ŒGANsåœ¨è®¡ç®—æˆæœ¬è¾ƒä½çš„å›å½’æ¨¡å‹ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</li>
<li>YODAåœ¨åŒ»å­¦å›¾åƒç¿»è¯‘æ–¹é¢çš„æ€§èƒ½è¶…è¶Šäº†å…«ç§æœ€æ–°çš„DMså’ŒGANsã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02048">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b486b6294d7fc6364d028753e9317b50~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178673&auth_key=1761178673-0-0-ea415d8317cedfc9ce03c88b38f10743&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1ea44dc7a98d675fa9d609126c80ab94~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178681&auth_key=1761178681-0-0-784d3ce514f7cd6e4b9d86018c34d30c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7181044938cdf69a8519e967aff606ba~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178688&auth_key=1761178688-0-0-ebfda51e6fd6c28923c0acc399df6d1f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7f48012af80d448ccb3dcd226b8bfc6~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178695&auth_key=1761178695-0-0-2a10d5a1a1493577b15e839b199ddf62&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Monitoring-morphometric-drift-in-lifelong-learning-segmentation-of-the-spinal-cord"><a href="#Monitoring-morphometric-drift-in-lifelong-learning-segmentation-of-the-spinal-cord" class="headerlink" title="Monitoring morphometric drift in lifelong learning segmentation of the   spinal cord"></a>Monitoring morphometric drift in lifelong learning segmentation of the   spinal cord</h2><p><strong>Authors:Enamundram Naga Karthik, Sandrine BÃ©dard, Jan ValoÅ¡ek, Christoph S. Aigner, Elise Bannier, Josef BednaÅ™Ã­k, Virginie Callot, Anna Combes, Armin Curt, Gergely David, Falk Eippert, Lynn Farner, Michael G Fehlings, Patrick Freund, Tobias Granberg, Cristina Granziera, RHSCIR Network Imaging Group, Ulrike Horn, TomÃ¡Å¡ HorÃ¡k, Suzanne Humphreys, Markus Hupp, Anne Kerbrat, Nawal Kinany, Shannon Kolind, Petr KudliÄka, Anna Lebret, Lisa Eunyoung Lee, Caterina Mainero, Allan R. Martin, Megan McGrath, Govind Nair, Kristin P. Oâ€™Grady, Jiwon Oh, Russell Ouellette, Nikolai Pfender, Dario Pfyffer, Pierre-FranÃ§ois Pradat, Alexandre Prat, Emanuele PravatÃ , Daniel S. Reich, Ilaria Ricchi, Naama Rotem-Kohavi, Simon Schading-Sassenhausen, Maryam Seif, Andrew Smith, Seth A Smith, Grace Sweeney, Roger Tam, Anthony Traboulsee, Constantina Andrada Treaba, Charidimos Tsagkas, Zachary Vavasour, Dimitri Van De Ville, Kenneth Arnold Weber II, Sarath Chandar, Julien Cohen-Adad</strong></p>
<p>Morphometric measures derived from spinal cord segmentations can serve as diagnostic and prognostic biomarkers in neurological diseases and injuries affecting the spinal cord. While robust, automatic segmentation methods to a wide variety of contrasts and pathologies have been developed over the past few years, whether their predictions are stable as the model is updated using new datasets has not been assessed. This is particularly important for deriving normative values from healthy participants. In this study, we present a spinal cord segmentation model trained on a multisite $(n&#x3D;75)$ dataset, including 9 different MRI contrasts and several spinal cord pathologies. We also introduce a lifelong learning framework to automatically monitor the morphometric drift as the model is updated using additional datasets. The framework is triggered by an automatic GitHub Actions workflow every time a new model is created, recording the morphometric values derived from the modelâ€™s predictions over time. As a real-world application of the proposed framework, we employed the spinal cord segmentation model to update a recently-introduced normative database of healthy participants containing commonly used measures of spinal cord morphometry. Results showed that: (i) our model outperforms previous versions and pathology-specific models on challenging lumbar spinal cord cases, achieving an average Dice score of $0.95 \pm 0.03$; (ii) the automatic workflow for monitoring morphometric drift provides a quick feedback loop for developing future segmentation models; and (iii) the scaling factor required to update the database of morphometric measures is nearly constant among slices across the given vertebral levels, showing minimum drift between the current and previous versions of the model monitored by the framework. The code and model are open-source and accessible via Spinal Cord Toolbox v7.0. </p>
<blockquote>
<p>ä»è„Šé«“åˆ†å‰²å¾—åˆ°çš„å½¢æ€æµ‹é‡æŒ‡æ ‡å¯ä»¥ä½œä¸ºç¥ç»ç³»ç»Ÿç–¾ç—…å’Œè„Šé«“æŸä¼¤çš„è¯Šæ–­å’Œé¢„åç”Ÿç‰©æ ‡å¿—ç‰©ã€‚è™½ç„¶è¿‡å»å‡ å¹´å·²ç»å¼€å‘å‡ºäº†é’ˆå¯¹å„ç§å¯¹æ¯”åº¦å’Œç—…ç†ç‰¹å¾çš„ç¨³å¥è‡ªåŠ¨åˆ†å‰²æ–¹æ³•ï¼Œä½†å°šæœªè¯„ä¼°éšç€æ–°æ•°æ®é›†çš„ä½¿ç”¨æ¨¡å‹æ›´æ–°åå…¶é¢„æµ‹çš„ç¨³å®šæ€§ã€‚è¿™å¯¹äºä»å¥åº·å‚ä¸è€…ä¸­å¾—å‡ºè§„èŒƒå€¼å°¤ä¸ºé‡è¦ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªåœ¨å¤šä¸ªç«™ç‚¹ï¼ˆn&#x3D;75ï¼‰æ•°æ®é›†ä¸Šè®­ç»ƒçš„è„Šé«“åˆ†å‰²æ¨¡å‹ï¼ŒåŒ…æ‹¬9ç§ä¸åŒçš„MRIå¯¹æ¯”åº¦å’Œå‡ ç§è„Šé«“ç—…ç†ç‰¹å¾ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ä¸ªç»ˆèº«å­¦ä¹ æ¡†æ¶ï¼Œä»¥è‡ªåŠ¨ç›‘æ§æ¨¡å‹ä½¿ç”¨é™„åŠ æ•°æ®é›†æ›´æ–°æ—¶çš„å½¢æ€æ¼‚ç§»ã€‚æ¯å½“åˆ›å»ºæ–°æ¨¡å‹æ—¶ï¼Œè¯¥æ¡†æ¶éƒ½ä¼šç”±GitHub Actionså·¥ä½œæµç¨‹è‡ªåŠ¨è§¦å‘ï¼Œè®°å½•æ¨¡å‹é¢„æµ‹éšæ—¶é—´æ¨ç§»å¾—å‡ºçš„å½¢æ€æµ‹é‡å€¼ã€‚ä½œä¸ºæ‰€æå‡ºæ¡†æ¶çš„å®é™…åº”ç”¨ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è„Šé«“åˆ†å‰²æ¨¡å‹æ¥æ›´æ–°æœ€è¿‘å¼•å…¥çš„å¥åº·å‚ä¸è€…è§„èŒƒæ•°æ®åº“ï¼Œå…¶ä¸­åŒ…å«å¸¸ç”¨çš„è„Šé«“å½¢æ€æµ‹é‡æŒ‡æ ‡ã€‚ç»“æœè¡¨æ˜ï¼šï¼ˆiï¼‰æˆ‘ä»¬çš„æ¨¡å‹åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è…°æ¤è„Šé«“ç—…ä¾‹ä¸Šçš„è¡¨ç°ä¼˜äºä»¥å‰ç‰ˆæœ¬å’Œç‰¹å®šç—…ç†æ¨¡å‹ï¼Œå¹³å‡Diceå¾—åˆ†ä¸º$0.95 \pm 0.03$ï¼›ï¼ˆiiï¼‰ç”¨äºç›‘æ§å½¢æ€æ¼‚ç§»çš„è‡ªåŠ¨å·¥ä½œæµç¨‹ä¸ºå¼€å‘æœªæ¥çš„åˆ†å‰²æ¨¡å‹æä¾›äº†å¿«é€Ÿåé¦ˆå¾ªç¯ï¼›ï¼ˆiiiï¼‰ç”¨äºæ›´æ–°å½¢æ€æµ‹é‡æ•°æ®åº“çš„ç¼©æ”¾å› å­åœ¨ç»™å®šçš„æ¤ä½“æ°´å¹³ä¹‹é—´çš„åˆ‡ç‰‡ä¸­å‡ ä¹æ’å®šï¼Œæ˜¾ç¤ºå‡ºå½“å‰ç‰ˆæœ¬å’Œç”±æ¡†æ¶ç›‘æ§çš„å…ˆå‰ç‰ˆæœ¬ä¹‹é—´çš„æœ€å°æ¼‚ç§»ã€‚ä»£ç å’Œæ¨¡å‹éƒ½æ˜¯å¼€æºçš„ï¼Œå¯é€šè¿‡è„Šé«“å·¥å…·ç®±v7.0è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01364v2">PDF</a> Under review (after 1st round of revision) at Imaging Neuroscience   journal</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºåŒ»å­¦å›¾åƒåˆ†å‰²çš„è„Šé«“å½¢æ€è®¡é‡æµ‹é‡å¯ä½œä¸ºç¥ç»ç³»ç»Ÿç–¾ç—…å’Œè„Šé«“æŸä¼¤çš„è¯Šæ–­å’Œé¢„åç”Ÿç‰©æ ‡å¿—ç‰©ã€‚å°½ç®¡è¿‡å»å‡ å¹´å·²ç»å¼€å‘äº†è®¸å¤šç¨³å¥çš„è‡ªåŠ¨åˆ†å‰²æ–¹æ³•ï¼Œä»¥é€‚åº”å„ç§å¯¹æ¯”åº¦å’Œç—…ç†å­¦ï¼Œä½†å°šæœªè¯„ä¼°ä½¿ç”¨æ–°æ•°æ®é›†æ›´æ–°æ¨¡å‹æ—¶å…¶é¢„æµ‹çš„ç¨³å®šæ€§ã€‚è¿™å¯¹äºä»å¥åº·å‚ä¸è€…ä¸­å¾—å‡ºè§„èŒƒå€¼å°¤ä¸ºé‡è¦ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªåœ¨å¤šä¸ªç«™ç‚¹ï¼ˆn&#x3D;75ï¼‰çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„è„Šé«“åˆ†å‰²æ¨¡å‹ï¼ŒåŒ…æ‹¬9ç§ä¸åŒçš„MRIå¯¹æ¯”åº¦å’Œå¤šç§è„Šé«“ç—…ç†ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ç§ç»ˆèº«å­¦ä¹ æ¡†æ¶ï¼Œå¯è‡ªåŠ¨ç›‘è§†å½¢æ€è®¡é‡æ¼‚ç§»ï¼Œéšç€ä½¿ç”¨é™„åŠ æ•°æ®é›†æ›´æ–°æ¨¡å‹æ—¶ä¹Ÿä¼šè§¦å‘ã€‚è¯¥æ¡†æ¶æ¯æ¬¡åˆ›å»ºæ–°æ¨¡å‹æ—¶éƒ½ä¼šç”±GitHub Actionså·¥ä½œæµè‡ªåŠ¨è§¦å‘ï¼Œè®°å½•æ¨¡å‹é¢„æµ‹å¾—å‡ºçš„å½¢æ€è®¡é‡å€¼éšæ—¶é—´çš„å˜åŒ–ã€‚ä½œä¸ºæ‰€æå‡ºæ¡†æ¶çš„å®é™…åº”ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨è„Šé«“åˆ†å‰²æ¨¡å‹æ¥æ›´æ–°æœ€è¿‘å¼•å…¥çš„å¥åº·å‚ä¸è€…çš„è§„èŒƒæ•°æ®åº“ï¼Œå…¶ä¸­åŒ…å«å¸¸ç”¨çš„è„Šé«“å½¢æ€è®¡é‡æµ‹é‡ã€‚ç»“æœè¡¨æ˜ï¼šï¼ˆiï¼‰æˆ‘ä»¬çš„æ¨¡å‹åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è…°æ¤è„Šé«“ç—…ä¾‹ä¸Šçš„è¡¨ç°ä¼˜äºä»¥å‰ç‰ˆæœ¬å’Œç‰¹å®šç—…ç†æ¨¡å‹ï¼Œå¹³å‡Diceå¾—åˆ†ä¸º0.95Â±0.03ï¼›ï¼ˆiiï¼‰ç”¨äºç›‘è§†å½¢æ€è®¡é‡æ¼‚ç§»çš„è‡ªåŠ¨å·¥ä½œæµç¨‹ä¸ºå¼€å‘æœªæ¥çš„åˆ†å‰²æ¨¡å‹æä¾›äº†å¿«é€Ÿåé¦ˆå¾ªç¯ï¼›ï¼ˆiiiï¼‰ç”¨äºæ›´æ–°æ•°æ®åº“çš„å½¢æ€è®¡é‡æµ‹é‡çš„ç¼©æ”¾å› å­åœ¨ç»™å®šçš„æ¤ä½“æ°´å¹³ä¹‹é—´å‡ ä¹æ’å®šï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹å’Œå½“å‰ç‰ˆæœ¬ä¹‹é—´æœ€å°çš„æ¼‚ç§»ã€‚ä»£ç å’Œæ¨¡å‹æ˜¯å¼€æºçš„ï¼Œå¯é€šè¿‡è„Šé«“å·¥å…·ç®±v7.0è®¿é—®ã€‚ </p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²çš„è„Šé«“å½¢æ€è®¡é‡æµ‹é‡å¯ä½œä¸ºç¥ç»ç³»ç»Ÿç–¾ç—…å’ŒæŸä¼¤çš„é¢„åæŒ‡æ ‡ã€‚</li>
<li>è™½ç„¶å·²æœ‰è‡ªåŠ¨åˆ†å‰²æ–¹æ³•çš„å‘å±•ï¼Œä½†ç¼ºä¹å¯¹ä½¿ç”¨æ–°æ•°æ®é›†æ›´æ–°æ¨¡å‹æ—¶çš„é¢„æµ‹ç¨³å®šæ€§çš„è¯„ä¼°ã€‚</li>
<li>ä»‹ç»äº†ä¸€ç§æ–°å‹çš„è„Šé«“åˆ†å‰²æ¨¡å‹å’Œç»ˆèº«å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯è‡ªåŠ¨ç›‘è§†å½¢æ€è®¡é‡å˜åŒ–å¹¶è¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ç¨³å®šæ€§ã€‚</li>
<li>æ¨¡å‹è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è…°æ¤è„Šé«“ç—…ä¾‹ä¸­ã€‚</li>
<li>è‡ªåŠ¨å·¥ä½œæµä¸ºæœªæ¥çš„åˆ†å‰²æ¨¡å‹æä¾›äº†å¿«é€Ÿåé¦ˆå¾ªç¯ï¼Œå¸®åŠ©ä¼˜åŒ–å’Œæ”¹è¿›æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ›´æ–°åçš„æ•°æ®åº“å½¢æ€è®¡é‡æµ‹é‡çš„ç¼©æ”¾å› å­åœ¨ç»™å®šçš„æ¤ä½“æ°´å¹³ä¹‹é—´å‡ ä¹æ’å®šï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01364">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c9bcc319629af2acabaca0ced70c59a8~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178702&auth_key=1761178702-0-0-b460827a53c45db9527d1441fbe3bb51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Jasmine-Harnessing-Diffusion-Prior-for-Self-supervised-Depth-Estimation"><a href="#Jasmine-Harnessing-Diffusion-Prior-for-Self-supervised-Depth-Estimation" class="headerlink" title="Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation"></a>Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation</h2><p><strong>Authors:Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li, Kang Liao, Yao Zhao</strong></p>
<p>In this paper, we propose Jasmine, the first Stable Diffusion (SD)-based self-supervised framework for monocular depth estimation, which effectively harnesses SDâ€™s visual priors to enhance the sharpness and generalization of unsupervised prediction. Previous SD-based methods are all supervised since adapting diffusion models for dense prediction requires high-precision supervision. In contrast, self-supervised reprojection suffers from inherent challenges (e.g., occlusions, texture-less regions, illumination variance), and the predictions exhibit blurs and artifacts that severely compromise SDâ€™s latent priors. To resolve this, we construct a novel surrogate task of hybrid image reconstruction. Without any additional supervision, it preserves the detail priors of SD models by reconstructing the images themselves while preventing depth estimation from degradation. Furthermore, to address the inherent misalignment between SDâ€™s scale and shift invariant estimation and self-supervised scale-invariant depth estimation, we build the Scale-Shift GRU. It not only bridges this distribution gap but also isolates the fine-grained texture of SD output against the interference of reprojection loss. Extensive experiments demonstrate that Jasmine achieves SoTA performance on the KITTI benchmark and exhibits superior zero-shot generalization across multiple datasets. </p>
<blockquote>
<p>æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Jasmineï¼Œè¿™æ˜¯åŸºäºStable Diffusionï¼ˆSDï¼‰çš„é¦–ä¸ªå•ç›®æ·±åº¦ä¼°è®¡è‡ªç›‘ç£æ¡†æ¶ï¼Œå®ƒæœ‰æ•ˆåœ°åˆ©ç”¨SDçš„è§†è§‰å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜äº†æ— ç›‘ç£é¢„æµ‹çš„æ¸…æ™°åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¹‹å‰çš„åŸºäºSDçš„æ–¹æ³•éƒ½æ˜¯æœ‰ç›‘ç£çš„ï¼Œå› ä¸ºå°†æ‰©æ•£æ¨¡å‹ç”¨äºå¯†é›†é¢„æµ‹éœ€è¦é«˜ç²¾åº¦ç›‘ç£ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè‡ªç›‘ç£é‡æŠ•å½±é¢ä¸´å›ºæœ‰çš„æŒ‘æˆ˜ï¼ˆä¾‹å¦‚é®æŒ¡ã€æ— çº¹ç†åŒºåŸŸã€å…‰ç…§å˜åŒ–ï¼‰ï¼Œå¹¶ä¸”é¢„æµ‹ç»“æœå‡ºç°æ¨¡ç³Šå’Œä¼ªå½±ï¼Œä¸¥é‡æŸå®³SDçš„æ½œåœ¨å…ˆéªŒçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ··åˆå›¾åƒé‡å»ºçš„æ–°å‹æ›¿ä»£ä»»åŠ¡ã€‚å®ƒä¸ä¾èµ–ä»»ä½•é¢å¤–çš„ç›‘ç£ï¼Œé€šè¿‡é‡å»ºå›¾åƒæœ¬èº«æ¥ä¿ç•™SDæ¨¡å‹çš„ç»†èŠ‚å…ˆéªŒçŸ¥è¯†ï¼ŒåŒæ—¶é˜²æ­¢æ·±åº¦ä¼°è®¡é€€åŒ–ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³SDå°ºåº¦ä¸ç§»ä½ä¸å˜ä¼°è®¡å’Œè‡ªç›‘ç£å°ºåº¦ä¸å˜æ·±åº¦ä¼°è®¡ä¹‹é—´çš„å›ºæœ‰ä¸åŒ¹é…é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†Scale-Shift GRUã€‚å®ƒä¸ä»…å¼¥è¡¥äº†åˆ†å¸ƒå·®è·ï¼Œè€Œä¸”é’ˆå¯¹é‡æŠ•å½±æŸå¤±çš„å¹²æ‰°ï¼Œéš”ç¦»äº†SDè¾“å‡ºçš„ç²¾ç»†çº¹ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒJasmineåœ¨KITTIåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå‡ºè‰²çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15905v3">PDF</a> Accepted to NeurIPS 2025. 23 pages, with the appendix</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†Jasmineï¼Œé¦–ä¸ªåŸºäºStable Diffusionï¼ˆSDï¼‰çš„è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡æ¡†æ¶ã€‚å®ƒæœ‰æ•ˆåœ°åˆ©ç”¨SDçš„è§†è§‰å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜äº†æ— ç›‘ç£é¢„æµ‹çš„æ¸…æ™°åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè§£å†³SDæ¨¡å‹åœ¨å¯†é›†é¢„æµ‹ä¸­çš„é«˜ç²¾åº¦ç›‘ç£éœ€æ±‚é—®é¢˜ï¼Œä»¥åŠè‡ªç›‘ç£é‡æŠ•å½±é¢ä¸´çš„å›ºæœ‰æŒ‘æˆ˜ï¼ˆå¦‚é®æŒ¡ã€æ— çº¹ç†åŒºåŸŸã€å…‰ç…§å˜åŒ–ç­‰ï¼‰ï¼Œæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªæ··åˆå›¾åƒé‡å»ºçš„æ›¿ä»£ä»»åŠ¡ï¼Œæ— éœ€é¢å¤–ç›‘ç£å³å¯ä¿ç•™SDæ¨¡å‹çš„ç»†èŠ‚å…ˆéªŒï¼ŒåŒæ—¶é˜²æ­¢æ·±åº¦ä¼°è®¡é€€åŒ–ã€‚æ­¤å¤–ï¼Œä¸ºè§£å†³SDå°ºåº¦ä¸è‡ªç›‘ç£æ·±åº¦ä¼°è®¡ä¹‹é—´çš„å›ºæœ‰ä¸åŒ¹é…é—®é¢˜ï¼Œæœ¬æ–‡æ„å»ºäº†Scale-Shift GRUï¼Œä¸ä»…å¼¥è¡¥äº†åˆ†å¸ƒå·®è·ï¼Œè¿˜éš”ç¦»äº†SDè¾“å‡ºçš„ç²¾ç»†çº¹ç†ï¼Œå‡å°‘äº†é‡æŠ•å½±æŸå¤±çš„å¹²æ‰°ã€‚å®éªŒè¡¨æ˜ï¼ŒJasmineåœ¨KITTIåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Jasmineæ˜¯é¦–ä¸ªåŸºäºStable Diffusionï¼ˆSDï¼‰çš„è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡æ¡†æ¶ï¼Œåˆ©ç”¨SDçš„è§†è§‰å…ˆéªŒçŸ¥è¯†æé«˜é¢„æµ‹æ¸…æ™°åº¦ã€‚</li>
<li>æ›¿ä»£ä»»åŠ¡â€”â€”æ··åˆå›¾åƒé‡å»ºï¼Œæ— éœ€é¢å¤–ç›‘ç£å³å¯ä¿ç•™SDæ¨¡å‹çš„ç»†èŠ‚å…ˆéªŒï¼Œé˜²æ­¢æ·±åº¦ä¼°è®¡é€€åŒ–ã€‚</li>
<li>è§£å†³äº†SDæ¨¡å‹åœ¨å¯†é›†é¢„æµ‹ä¸­çš„é«˜ç²¾å¯†ç›‘ç£éœ€æ±‚é—®é¢˜ã€‚</li>
<li>æå‡ºäº†Scale-Shift GRUä»¥è§£å†³SDå°ºåº¦ä¸è‡ªç›‘ç£æ·±åº¦ä¼°è®¡ä¹‹é—´çš„å›ºæœ‰ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>Jasmineåœ¨KITTIåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>Jasmineå±•ç°å‡ºè‰¯å¥½çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15905">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-db2799dab1cc468518320dccefd58040~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178710&auth_key=1761178710-0-0-af3dede0e8a8cf7f20ce47eb6defaf4d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-57ac9dce7c85472e0932817a00e262bd~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178718&auth_key=1761178718-0-0-9e888802a528e14b0d203d345f2bad0b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6358a4e090a41e3ebb50e6c1991d8154~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178724&auth_key=1761178724-0-0-67cdbbff7661edf0c16b8f7d771147ca&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-42fb4dfe50642e077f38951cdbdfc7b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178730&auth_key=1761178730-0-0-a50c957b3fdbb2ea4d3a89b456d5f0a5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Adaptive-Label-Correction-for-Robust-Medical-Image-Segmentation-with-Noisy-Labels"><a href="#Adaptive-Label-Correction-for-Robust-Medical-Image-Segmentation-with-Noisy-Labels" class="headerlink" title="Adaptive Label Correction for Robust Medical Image Segmentation with   Noisy Labels"></a>Adaptive Label Correction for Robust Medical Image Segmentation with   Noisy Labels</h2><p><strong>Authors:Chengxuan Qian, Kai Han, Jianxia Ding, Chongwen Lyu, Zhenlong Yuan, Jun Chen, Zhe Liu</strong></p>
<p>Deep learning has shown remarkable success in medical image analysis, but its reliance on large volumes of high-quality labeled data limits its applicability. While noisy labeled data are easier to obtain, directly incorporating them into training can degrade model performance. To address this challenge, we propose a Mean Teacher-based Adaptive Label Correction (ALC) self-ensemble framework for robust medical image segmentation with noisy labels. The framework leverages the Mean Teacher architecture to ensure consistent learning under noise perturbations. It includes an adaptive label refinement mechanism that dynamically captures and weights differences across multiple disturbance versions to enhance the quality of noisy labels. Additionally, a sample-level uncertainty-based label selection algorithm is introduced to prioritize high-confidence samples for network updates, mitigating the impact of noisy annotations. Consistency learning is integrated to align the predictions of the student and teacher networks, further enhancing model robustness. Extensive experiments on two public datasets demonstrate the effectiveness of the proposed framework, showing significant improvements in segmentation performance. By fully exploiting the strengths of the Mean Teacher structure, the ALC framework effectively processes noisy labels, adapts to challenging scenarios, and achieves competitive results compared to state-of-the-art methods. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†ææ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆå°±ï¼Œä½†å…¶ä¾èµ–äºå¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ç‰¹æ€§é™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚è™½ç„¶è·å–å¸¦å™ªå£°çš„æ ‡æ³¨æ•°æ®æ›´å®¹æ˜“ï¼Œä½†ç›´æ¥å°†å…¶çº³å…¥è®­ç»ƒä¼šé™ä½æ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºMean Teacherçš„è‡ªé€‚åº”æ ‡ç­¾æ ¡æ­£ï¼ˆALCï¼‰è‡ªé›†æˆæ¡†æ¶ï¼Œç”¨äºç¨³å¥çš„åŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œè¯¥æ¡†æ¶å¸¦æœ‰å™ªå£°æ ‡ç­¾ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Mean Teacheræ¶æ„ç¡®ä¿åœ¨å™ªå£°æ‰°åŠ¨ä¸‹çš„æŒç»­å­¦ä¹ ã€‚å®ƒåŒ…å«ä¸€ä¸ªè‡ªé€‚åº”æ ‡ç­¾ä¼˜åŒ–æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤ŸåŠ¨æ€æ•è·å¹¶æƒè¡¡å¤šä¸ªæ‰°åŠ¨ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œä»¥æé«˜å™ªå£°æ ‡ç­¾çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºæ ·æœ¬çº§åˆ«ä¸ç¡®å®šæ€§çš„æ ‡ç­¾é€‰æ‹©ç®—æ³•ï¼Œä»¥ä¼˜å…ˆå¤„ç†é«˜ç½®ä¿¡åº¦æ ·æœ¬è¿›è¡Œç½‘ç»œæ›´æ–°ï¼Œå‡è½»å™ªå£°æ³¨é‡Šçš„å½±å“ã€‚é›†æˆä¸€è‡´æ€§å­¦ä¹ ä»¥å¯¹é½å­¦ç”Ÿå’Œæ•™å¸ˆç½‘ç»œçš„é¢„æµ‹ï¼Œè¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„ç¨³å¥æ€§ã€‚åœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æ‰€ææ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºåˆ†å‰²æ€§èƒ½çš„æ˜¾è‘—æé«˜ã€‚é€šè¿‡å……åˆ†åˆ©ç”¨Mean Teacherç»“æ„çš„ä¼˜åŠ¿ï¼ŒALCæ¡†æ¶æœ‰æ•ˆåœ°å¤„ç†äº†å™ªå£°æ ‡ç­¾ï¼Œé€‚åº”äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12218v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å…¶ä¾èµ–äºå¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„åº”ç”¨èŒƒå›´æœ‰é™ã€‚ä¸ºäº†å¤„ç†å¸¦å™ªå£°æ ‡ç­¾æ•°æ®å¸¦æ¥çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºMean Teacherçš„è‡ªé€‚åº”æ ‡ç­¾ä¿®æ­£ï¼ˆALCï¼‰è‡ªé›†æˆæ¡†æ¶ï¼Œç”¨äºç¨³å¥åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Mean Teacheræ¶æ„ç¡®ä¿åœ¨å™ªå£°æ‰°åŠ¨ä¸‹çš„å­¦ä¹ ä¸€è‡´æ€§ï¼Œå¹¶åŒ…æ‹¬è‡ªé€‚åº”æ ‡ç­¾ä¼˜åŒ–æœºåˆ¶ï¼ŒåŠ¨æ€æ•æ‰å¹¶æƒè¡¡ä¸åŒæ‰°åŠ¨ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œä»¥æé«˜å™ªå£°æ ‡ç­¾çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†åŸºäºæ ·æœ¬çº§åˆ«ä¸ç¡®å®šæ€§çš„æ ‡ç­¾é€‰æ‹©ç®—æ³•ï¼Œä¼˜å…ˆé€‰å–é«˜ç½®ä¿¡åº¦æ ·æœ¬è¿›è¡Œç½‘ç»œæ›´æ–°ï¼Œå‡å°‘å™ªå£°æ ‡æ³¨çš„å½±å“ã€‚ä¸€è‡´æ€§å­¦ä¹ è¢«æ•´åˆä»¥å¯¹é½å­¦ç”Ÿå’Œæ•™å¸ˆç½‘ç»œçš„é¢„æµ‹ï¼Œè¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„ç¨³å¥æ€§ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œåœ¨åˆ†å‰²æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†æä¸­å…·æœ‰æ˜¾è‘—æˆåŠŸï¼Œä½†ä¾èµ–å¤§é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„é™åˆ¶å…¶åº”ç”¨èŒƒå›´ã€‚</li>
<li>æå‡ºçš„åŸºäºMean Teacherçš„è‡ªé€‚åº”æ ‡ç­¾ä¿®æ­£ï¼ˆALCï¼‰æ¡†æ¶æ—¨åœ¨å¤„ç†å¸¦å™ªå£°æ ‡ç­¾æ•°æ®çš„é—®é¢˜ã€‚</li>
<li>ALCæ¡†æ¶åˆ©ç”¨Mean Teacheræ¶æ„ç¡®ä¿å™ªå£°æ‰°åŠ¨ä¸‹å­¦ä¹ çš„ä¸€è‡´æ€§ã€‚</li>
<li>è‡ªé€‚åº”æ ‡ç­¾ä¼˜åŒ–æœºåˆ¶èƒ½åŠ¨æ€æ•æ‰å¹¶æƒè¡¡ä¸åŒæ‰°åŠ¨ç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚ï¼Œæé«˜å™ªå£°æ ‡ç­¾è´¨é‡ã€‚</li>
<li>åŸºäºæ ·æœ¬çº§åˆ«ä¸ç¡®å®šæ€§çš„æ ‡ç­¾é€‰æ‹©ç®—æ³•ä¼˜å…ˆé€‰å–é«˜ç½®ä¿¡åº¦æ ·æœ¬è¿›è¡Œç½‘ç»œæ›´æ–°ã€‚</li>
<li>ä¸€è‡´æ€§å­¦ä¹ è¢«æ•´åˆä»¥æé«˜æ¨¡å‹çš„ç¨³å¥æ€§ï¼Œå¯¹é½å­¦ç”Ÿå’Œæ•™å¸ˆç½‘ç»œçš„é¢„æµ‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12218">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9c21161a5bce4b0019b85e22fd3b683b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178738&auth_key=1761178738-0-0-e7748b528626461e13b231ce214c555d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-de13153cb5be302f694f2ed7f15c71df~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178745&auth_key=1761178745-0-0-3990707186c2aadafa8ef35d7bde1933&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-59527a8925802bc3c5e7078b9a86afe7~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178752&auth_key=1761178752-0-0-94068db70e9c4d6adb72b8eca2abbaed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5e175ffcb69c6713afaa8d5aa8882897~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178758&auth_key=1761178758-0-0-5905997af6250c8f10ed399ea03b4eae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4e4dec8853c0d99ea7c64e68b6f27e43~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178765&auth_key=1761178765-0-0-f9d1a133fef008ecca329b643bb40304&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-859b3fc8de3ecb3082c3ec70d24d20cc~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178772&auth_key=1761178772-0-0-96370b7ed4396989328f2470f49efa12&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Geodesic-Diffusion-Models-for-Efficient-Medical-Image-Enhancement"><a href="#Geodesic-Diffusion-Models-for-Efficient-Medical-Image-Enhancement" class="headerlink" title="Geodesic Diffusion Models for Efficient Medical Image Enhancement"></a>Geodesic Diffusion Models for Efficient Medical Image Enhancement</h2><p><strong>Authors:Teng Zhang, Hongxu Jiang, Kuang Gong, Wei Shao</strong></p>
<p>Diffusion models generate data by learning to reverse a forward process, where samples are progressively perturbed with Gaussian noise according to a predefined noise schedule. From a geometric perspective, each noise schedule corresponds to a unique trajectory in probability space from the data distribution to a Gaussian prior. However, prior diffusion models rely on empirically chosen schedules that may not be optimal. This inefficiency necessitates many intermediate time steps, resulting in high computational costs during both training and sampling. To address this, we derive a family of geodesic noise schedules corresponding to the shortest paths in probability space under the Fisher-Rao metric. Based on these schedules, we propose Geodesic Diffusion Models (GDMs), which significantly improve training and sampling efficiency by minimizing the energy required to transform between probability distributions. This efficiency further enables sampling to start from an intermediate distribution in conditional image generation, achieving state-of-the-art results with as few as 6 steps. We evaluated GDM on two medical image enhancement tasks: CT image denoising and MRI image super-resolution. Experimental results show that GDM achieved state-of-the-art performance while reducing training time by 20- to 30-fold compared to Denoising Diffusion Probabilistic Models (DDPMs) and 4- to 6-fold compared to Fast-DDPM, and accelerating sampling by 160- to 170-fold and 1.6-fold, respectively. These gains support the use of GDM for efficient model development and real-time clinical applications. Our code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/mirthAI/GDM-VE">https://github.com/mirthAI/GDM-VE</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ åè½¬ä¸€ä¸ªé¢„å…ˆå®šä¹‰å™ªå£°è®¡åˆ’é€æ­¥æ‰°åŠ¨æ ·æœ¬çš„å‰å‘è¿‡ç¨‹æ¥ç”Ÿæˆæ•°æ®ã€‚ä»å‡ ä½•å­¦çš„è§’åº¦æ¥çœ‹ï¼Œæ¯ä¸ªå™ªå£°è®¡åˆ’å¯¹åº”äºæ¦‚ç‡ç©ºé—´ä¸­ä»æ•°æ®åˆ†å¸ƒåˆ°é«˜æ–¯å…ˆéªŒçš„ç‹¬ç‰¹è½¨è¿¹ã€‚ç„¶è€Œï¼Œå…ˆå‰çš„æ‰©æ•£æ¨¡å‹ä¾èµ–äºç»éªŒé€‰æ‹©çš„è®¡åˆ’ï¼Œè¿™äº›è®¡åˆ’å¯èƒ½å¹¶éæœ€ä¼˜ã€‚è¿™ç§ä½æ•ˆæ€§éœ€è¦å¤§é‡çš„ä¸­é—´æ­¥éª¤ï¼Œå¯¼è‡´è®­ç»ƒå’Œé‡‡æ ·è¿‡ç¨‹ä¸­çš„è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºå¯¹åº”äºFisher-Raoåº¦é‡ä¸‹æ¦‚ç‡ç©ºé—´ä¸­æœ€çŸ­è·¯å¾„çš„ä¸€ç³»åˆ—æµ‹åœ°çº¿å™ªå£°è®¡åˆ’ã€‚åŸºäºè¿™äº›è®¡åˆ’ï¼Œæˆ‘ä»¬æå‡ºäº†æµ‹åœ°çº¿æ‰©æ•£æ¨¡å‹ï¼ˆGDMsï¼‰ï¼Œé€šè¿‡æœ€å°åŒ–æ¦‚ç‡åˆ†å¸ƒä¹‹é—´è½¬æ¢æ‰€éœ€çš„èƒ½é‡ï¼Œæ˜¾è‘—æé«˜è®­ç»ƒå’Œé‡‡æ ·çš„æ•ˆç‡ã€‚è¿™ç§æ•ˆç‡è¿˜ä½¿å¾—å¯ä»¥ä»æ¡ä»¶å›¾åƒç”Ÿæˆçš„ä¸­é—´åˆ†å¸ƒå¼€å§‹é‡‡æ ·ï¼Œä»…ç”¨6æ­¥å°±å®ç°äº†ä¸šç•Œé¢†å…ˆçš„ç»“æœã€‚æˆ‘ä»¬åœ¨ä¸¤é¡¹åŒ»å­¦å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šè¯„ä¼°äº†GDMï¼šCTå›¾åƒå»å™ªå’ŒMRIå›¾åƒè¶…åˆ†è¾¨ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGDMåœ¨è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ€§èƒ½çš„åŒæ—¶ï¼Œä¸å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMsï¼‰ç›¸æ¯”å°†è®­ç»ƒæ—¶é—´ç¼©çŸ­äº†20è‡³30å€ï¼Œä¸Fast-DDPMç›¸æ¯”ç¼©çŸ­äº†4è‡³6å€ï¼›é‡‡æ ·é€Ÿåº¦åˆ†åˆ«åŠ å¿«äº†160è‡³170å€å’Œ1.6å€ã€‚è¿™äº›ä¼˜åŠ¿æ”¯æŒä½¿ç”¨GDMè¿›è¡Œé«˜æ•ˆæ¨¡å‹å¼€å‘å’Œå®æ—¶ä¸´åºŠåº”ç”¨ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/mirthAI/GDM-VE">https://github.com/mirthAI/GDM-VE</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.00745v2">PDF</a> </p>
<p><strong>Summary</strong><br>     åŸºäºFisher-Raoåº¦é‡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç³»åˆ—æœ€çŸ­è·¯å¾„çš„æµ‹åœ°çº¿å™ªå£°è°ƒåº¦æ–¹æ¡ˆï¼Œå¹¶æ®æ­¤æå‡ºäº†Geodesic Diffusion Modelsï¼ˆGDMsï¼‰ã€‚GDMé€šè¿‡æœ€å°åŒ–æ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„èƒ½é‡è½¬æ¢éœ€æ±‚ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œé‡‡æ ·çš„æ•ˆç‡ã€‚åœ¨åŒ»å­¦å›¾åƒå¢å¼ºä»»åŠ¡ä¸­ï¼ŒGDMå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å¤§å¹…åº¦å‡å°‘äº†è®­ç»ƒæ—¶é—´å’Œé‡‡æ ·æ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ åè½¬ä¸€ä¸ªæ­£å‘è¿‡ç¨‹æ¥ç”Ÿæˆæ•°æ®ï¼Œè¯¥è¿‡ç¨‹æŒ‰ç…§é¢„å®šçš„å™ªå£°è°ƒåº¦é€æ­¥æ‰°åŠ¨æ ·æœ¬ã€‚</li>
<li>è¿‡å»çš„æ‰©æ•£æ¨¡å‹ä¾èµ–äºç»éªŒé€‰æ‹©çš„è°ƒåº¦ï¼Œå¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ï¼Œå¯¼è‡´è®­ç»ƒå’Œé‡‡æ ·çš„è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†åŸºäºFisher-Raoåº¦é‡çš„æœ€çŸ­è·¯å¾„æµ‹åœ°çº¿å™ªå£°è°ƒåº¦æ–¹æ¡ˆã€‚</li>
<li>åŸºäºè¿™äº›è°ƒåº¦æ–¹æ¡ˆï¼Œæå‡ºäº†Geodesic Diffusion Modelsï¼ˆGDMsï¼‰ï¼Œæé«˜äº†è®­ç»ƒå’Œé‡‡æ ·çš„æ•ˆç‡ã€‚</li>
<li>GDMèƒ½å¤Ÿåœ¨æ¡ä»¶å›¾åƒç”Ÿæˆä¸­ä»ä¸­é—´åˆ†å¸ƒå¼€å§‹é‡‡æ ·ï¼Œä»¥è¾ƒå°‘çš„æ­¥éª¤è¾¾åˆ°æœ€å…ˆè¿›çš„ç”Ÿæˆæ•ˆæœã€‚</li>
<li>åœ¨åŒ»å­¦å›¾åƒå¢å¼ºä»»åŠ¡ä¸­ï¼ŒGDMå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å¤§å¹…åº¦å‡å°‘äº†è®­ç»ƒæ—¶é—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.00745">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e425e1c7c67681cfe7148337fb5dcd4e~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178779&auth_key=1761178779-0-0-b3210a125e375f73b22216fd587c1934&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a64229edf413c1ff5787a601efbadf08~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178786&auth_key=1761178786-0-0-b77fc679d771b5153dd2a6f2bde60673&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0e40db0000336e4641a83dfa726e5eab~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178793&auth_key=1761178793-0-0-d95f94630b5d0f746a197f3e2657447b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7f2c20fef5c59b2bc0e8e9de30e55619~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178799&auth_key=1761178799-0-0-610df896807c2ff3ca1e307411c6a762&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-79c022186e45a7eec38a54a417c3f4f5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178806&auth_key=1761178806-0-0-4125edecb13d4d85af283478a0ac7ec0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-95241cb1b677bf8bfbc6c342d6654a06~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178812&auth_key=1761178812-0-0-e181bd6ebddbe3508c38ff39c48749c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Physics-motivated-models-of-pulsar-X-ray-hotspots-off-center-dipole-configurations"><a href="#Physics-motivated-models-of-pulsar-X-ray-hotspots-off-center-dipole-configurations" class="headerlink" title="Physics motivated models of pulsar X-ray hotspots: off-center dipole   configurations"></a>Physics motivated models of pulsar X-ray hotspots: off-center dipole   configurations</h2><p><strong>Authors:Chun Huang, Alexander Y. Chen</strong></p>
<p>Recently, it was proposed that an off-center dipole magnetic configuration, together with a non-trivial temperature profile, may be the best model to explain the X-ray light curve of PSR J0030+0451 observed by the Neutron Star Interior Composition Explorer (\emph{NICER}). Using a theoretical model for the electric current density in a force-free pulsar magnetosphere, we compute from first principles the distribution of electric current over the polar cap associated with an off-center magnetic dipole. We then use a simple prescription to compute the resulting temperature distribution, which allows us to derive the observed X-ray light curve. We investigate the role of the volumetric return current region in the polar cap and find that although it does not make a big difference in an aligned dipole case, the difference can be bigger in the case of an off-center dipole. Finally, we apply Markov Chain Monte Carlo (MCMC) fitting to the X-ray light curves of pulsars PSR J0030+0451 and PSR J0437â€“4715 with and without the volumetric return current, and find that our model can reasonably recover the observed X-ray light curves. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œæœ‰æè®®è®¤ä¸ºéä¸­å¿ƒå¶æç£åœºé…ç½®ä¸éå¸¸è§„æ¸©åº¦åˆ†å¸ƒç›¸ç»“åˆå¯èƒ½æ˜¯è§£é‡Šç”±ä¸­å­æ˜Ÿå†…éƒ¨ç»“æ„æ¢æµ‹å™¨ï¼ˆNICERï¼‰è§‚å¯Ÿåˆ°çš„PSR J0030+0451çš„Xå°„çº¿å…‰å˜çš„æœ€ä½³æ¨¡å‹ã€‚æˆ‘ä»¬ä½¿ç”¨è‡ªç”±åŠ›å¶æè„‰å†²æ˜Ÿç£å±‚ä¸­çš„ç”µæµå¯†åº¦ç†è®ºæ¨¡å‹ï¼Œä»ç¬¬ä¸€åŸç†å‡ºå‘è®¡ç®—éä¸­å¿ƒç£å¶ææå† ä¸Šçš„ç”µæµåˆ†å¸ƒã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å…¬å¼æ¥è®¡ç®—æ‰€å¾—çš„æ¸©åº¦åˆ†å¸ƒï¼Œä»è€Œæ¨å¯¼å‡ºè§‚å¯Ÿåˆ°çš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä½“ç§¯è¿”å›ç”µæµåŒºåŸŸåœ¨æå† ä¸­çš„ä½œç”¨ï¼Œå‘ç°è™½ç„¶åœ¨å¶æå¯¹é½çš„æƒ…å†µä¸‹å·®å¼‚ä¸å¤§ï¼Œä½†åœ¨éä¸­å¿ƒå¶æçš„æƒ…å†µä¸‹å·®å¼‚å¯èƒ½æ›´å¤§ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹åŒ…å«å’Œä¸åŒ…å«ä½“ç§¯è¿”å›ç”µæµçš„è„‰å†²æ˜ŸPSR J0030+0451å’ŒPSR J0437-4715çš„Xå°„çº¿å…‰å˜æ›²çº¿åº”ç”¨é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›ï¼ˆMCMCï¼‰æ‹Ÿåˆæ–¹æ³•ï¼Œå‘ç°æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åˆç†åœ°æ¢å¤è§‚å¯Ÿåˆ°çš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15881v3">PDF</a> Accepted publication in ApJ</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†ä¸­å­æ˜Ÿå†…éƒ¨æˆåˆ†æ¢æµ‹å™¨ï¼ˆNICERï¼‰è§‚æµ‹åˆ°çš„PSR J0030+0451çš„Xå°„çº¿å…‰å˜æ›²çº¿ï¼Œå¹¶æå‡ºä¸€ä¸ªåç¦»ä¸­å¿ƒçš„å¶æç£åœºé…ç½®ä¸éå¹³å‡¡çš„æ¸©åº¦åˆ†å¸ƒå¯èƒ½æ˜¯æœ€ä½³æ¨¡å‹æ¥è§£é‡Šè¿™ä¸€ç°è±¡ã€‚ç ”ç©¶ä»è‡ªç”±åŠ›å¶æç£åœºæ¨¡å‹å‡ºå‘ï¼Œè®¡ç®—æå† åŒºåŸŸçš„ç”µæµåˆ†å¸ƒã€‚è¿›ä¸€æ­¥ï¼Œåˆ©ç”¨ç®€å•çš„æ¸©åº¦åˆ†å¸ƒå…¬å¼æ¨å¯¼Xå°„çº¿å…‰å˜æ›²çº¿ã€‚ç ”ç©¶å‘ç°æå† çš„ä½“ç§¯è¿”å›ç”µæµåŒºåŸŸåœ¨åç¦»ä¸­å¿ƒå¶ææƒ…å†µä¸‹å½±å“è¾ƒå¤§ã€‚æœ€åï¼Œåˆ©ç”¨é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡ç½—ï¼ˆMCMCï¼‰æ–¹æ³•å¯¹åŒ…å«å’Œä¸åŒ…å«ä½“ç§¯è¿”å›ç”µæµçš„PSR J0030+0451å’ŒPSR J0437-4715çš„Xå°„çº¿å…‰å˜æ›²çº¿è¿›è¡Œæ‹Ÿåˆï¼Œå‘ç°æ¨¡å‹èƒ½å¤Ÿè¾ƒå¥½åœ°æ¢å¤è§‚æµ‹åˆ°çš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PSR J0030+0451çš„Xå°„çº¿å…‰å˜æ›²çº¿å¯é€šè¿‡åç¦»ä¸­å¿ƒçš„å¶æç£åœºé…ç½®å’Œéå¹³å‡¡çš„æ¸©åº¦åˆ†å¸ƒæ¨¡å‹æ¥è§£é‡Šã€‚</li>
<li>é€šè¿‡è‡ªç”±åŠ›å¶æç£åœºæ¨¡å‹è®¡ç®—äº†æå† åŒºåŸŸçš„ç”µæµåˆ†å¸ƒã€‚</li>
<li>æå† çš„ä½“ç§¯è¿”å›ç”µæµåŒºåŸŸåœ¨åç¦»ä¸­å¿ƒå¶ææƒ…å†µä¸‹ä½œç”¨æ˜¾è‘—ã€‚</li>
<li>ä½¿ç”¨ç®€å•å…¬å¼è®¡ç®—æ¸©åº¦åˆ†å¸ƒä»¥æ¨å¯¼Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</li>
<li>MCMCæ–¹æ³•è¢«ç”¨äºæ‹ŸåˆPSR J0030+0451å’ŒPSR J0437-4715çš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿè¾ƒå¥½åœ°æ¢å¤è§‚æµ‹åˆ°çš„Xå°„çº¿å…‰å˜æ›²çº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15881">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7dfd79a5abcf4bab54a82f90a2535b22~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178820&auth_key=1761178820-0-0-0a57973e613d9ec987c13377776b02b3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b6e00c62eb850dba27d070864d35590f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178827&auth_key=1761178827-0-0-0df0f9b9967596aa36017179ea16b880&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="H3DE-Net-Efficient-and-Accurate-3D-Landmark-Detection-in-Medical-Imaging"><a href="#H3DE-Net-Efficient-and-Accurate-3D-Landmark-Detection-in-Medical-Imaging" class="headerlink" title="H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical   Imaging"></a>H3DE-Net: Efficient and Accurate 3D Landmark Detection in Medical   Imaging</h2><p><strong>Authors:Zhen Huang, Tao Tang, Ronghao Xu, Yangbo Wei, Wenkai Yang, Suhua Wang, Xiaoxin Sun, Han Li, Qingsong Yao</strong></p>
<p>3D landmark detection is a critical task in medical image analysis, and accurately detecting anatomical landmarks is essential for subsequent medical imaging tasks. However, mainstream deep learning methods in this field struggle to simultaneously capture fine-grained local features and model global spatial relationships, while maintaining a balance between accuracy and computational efficiency. Local feature extraction requires capturing fine-grained anatomical details, while global modeling requires understanding the spatial relationships within complex anatomical structures. The high-dimensional nature of 3D volume further exacerbates these challenges, as landmarks are sparsely distributed, leading to significant computational costs. Therefore, achieving efficient and precise 3D landmark detection remains a pressing challenge in medical image analysis.   In this work, We propose a \textbf{H}ybrid \textbf{3}D \textbf{DE}tection \textbf{Net}(H3DE-Net), a novel framework that combines CNNs for local feature extraction with a lightweight attention mechanism designed to efficiently capture global dependencies in 3D volumetric data. This mechanism employs a hierarchical routing strategy to reduce computational cost while maintaining global context modeling. To our knowledge, H3DE-Net is the first 3D landmark detection model that integrates such a lightweight attention mechanism with CNNs. Additionally, integrating multi-scale feature fusion further enhances detection accuracy and robustness. Experimental results on a public CT dataset demonstrate that H3DE-Net achieves state-of-the-art(SOTA) performance, significantly improving accuracy and robustness, particularly in scenarios with missing landmarks or complex anatomical variations. We aready open-source our project, including code, data and model weights. </p>
<blockquote>
<p>ä¸‰ç»´ï¼ˆ3Dï¼‰åœ°æ ‡æ£€æµ‹æ˜¯åŒ»å­¦å›¾åƒåˆ†æä¸­çš„ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œå‡†ç¡®åœ°æ£€æµ‹è§£å‰–åœ°æ ‡å¯¹äºåç»­åŒ»å­¦æˆåƒä»»åŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¯¥é¢†åŸŸçš„ä¸»æµæ·±åº¦å­¦ä¹ æ–¹æ³•éš¾ä»¥åœ¨ç²¾ç»†çš„å±€éƒ¨ç‰¹å¾æ•æ‰ã€å…¨å±€ç©ºé—´å…³ç³»å»ºæ¨¡ã€å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´ä¿æŒå¹³è¡¡ã€‚å±€éƒ¨ç‰¹å¾æå–éœ€è¦æ•æ‰ç²¾ç»†çš„è§£å‰–ç»†èŠ‚ï¼Œè€Œå…¨å±€å»ºæ¨¡åˆ™éœ€è¦ç†è§£å¤æ‚è§£å‰–ç»“æ„å†…çš„ç©ºé—´å…³ç³»ã€‚ç”±äºåœ°æ ‡åˆ†å¸ƒç¨€ç–ï¼Œä¸‰ç»´ä½“ç§¯çš„é«˜ç»´æ€§è´¨è¿›ä¸€æ­¥åŠ å‰§äº†è¿™äº›æŒ‘æˆ˜ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚å› æ­¤ï¼Œå®ç°é«˜æ•ˆä¸”ç²¾ç¡®çš„3Dåœ°æ ‡æ£€æµ‹ä»ç„¶æ˜¯åŒ»å­¦å›¾åƒåˆ†æé¢†åŸŸçš„ä¸€ä¸ªç´§è¿«æŒ‘æˆ˜ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆä¸‰ç»´æ£€æµ‹ç½‘ç»œï¼ˆHybrid 3D Detection Netï¼Œç®€ç§°H3DE-Netï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œå±€éƒ¨ç‰¹å¾æå–å’Œä¸€ä¸ªè½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ—¨åœ¨é«˜æ•ˆæ•æ‰ä¸‰ç»´ä½“ç§¯æ•°æ®ä¸­çš„å…¨å±€ä¾èµ–å…³ç³»ã€‚è¯¥æœºåˆ¶é‡‡ç”¨åˆ†å±‚è·¯ç”±ç­–ç•¥æ¥é™ä½è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒH3DE-Netæ˜¯ç¬¬ä¸€ä¸ªå°†æ­¤ç±»è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶ä¸CNNç›¸ç»“åˆçš„3Dåœ°æ ‡æ£€æµ‹æ¨¡å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¤šå°ºåº¦ç‰¹å¾èåˆè¿›ä¸€æ­¥æé«˜äº†æ£€æµ‹ç²¾åº¦å’Œç¨³å¥æ€§ã€‚åœ¨å…¬å…±CTæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒH3DE-Netè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨åœ°æ ‡ç¼ºå¤±æˆ–è§£å‰–ç»“æ„å¤æ‚çš„åœºæ™¯ä¸­æ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚æˆ‘ä»¬çš„é¡¹ç›®å·²ç»å¼€æºï¼ŒåŒ…æ‹¬ä»£ç ã€æ•°æ®å’Œæ¨¡å‹æƒé‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14221v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ··åˆä¸‰ç»´æ£€æµ‹ç½‘ç»œï¼ˆH3DE-Netï¼‰ï¼Œç»“åˆå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡Œå±€éƒ¨ç‰¹å¾æå–ï¼Œå¹¶é‡‡ç”¨è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶é«˜æ•ˆæ•æ‰ä¸‰ç»´ä½“ç§¯æ•°æ®ä¸­çš„å…¨å±€ä¾èµ–å…³ç³»ã€‚è¯¥æ–¹æ³•é‡‡ç”¨åˆ†å±‚è·¯ç”±ç­–ç•¥ï¼Œé™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ä¿æŒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒH3DE-Netåœ¨å…¬å¼€CTæ•°æ®é›†ä¸Šè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œæé«˜äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼ºå¤±åœ°æ ‡æˆ–å¤æ‚è§£å‰–å˜å¼‚æƒ…å†µä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D landmarkæ£€æµ‹æ˜¯åŒ»å­¦å›¾åƒåˆ†æä¸­çš„å…³é”®ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶æ•æ‰å±€éƒ¨ç²¾ç»†ç‰¹å¾å’Œå…¨å±€ç©ºé—´å…³ç³»ã€‚</li>
<li>ä¸»æµæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨æ­¤ä»»åŠ¡ä¸Šé¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦åœ¨å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹å¤æ‚åº¦ä¹‹é—´å–å¾—å¹³è¡¡ã€‚</li>
<li>H3DE-Netç»“åˆCNNè¿›è¡Œå±€éƒ¨ç‰¹å¾æå–ï¼Œé‡‡ç”¨è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶æ•æ‰å…¨å±€ä¾èµ–ã€‚</li>
<li>åˆ†å±‚è·¯ç”±ç­–ç•¥é™ä½è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚</li>
<li>H3DE-Netæ˜¯é¦–ä¸ªå°†è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶ä¸CNNç»“åˆç”¨äº3D landmarkæ£€æµ‹æ¨¡å‹ã€‚</li>
<li>å¤šå°ºåº¦ç‰¹å¾èåˆè¿›ä¸€æ­¥æé«˜æ£€æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14221">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5af5f1c0f9e4716028b3383b307fff46~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178835&auth_key=1761178835-0-0-be538128e0c01fdd44888c6856b5ad1e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5fe47c7fe534ba91abeb6a20d65dcb48~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178842&auth_key=1761178842-0-0-a9779f99ccfadd6c20462238c77b3b9b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c810e48c6d2884f8cf6892b40ca45156~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178849&auth_key=1761178849-0-0-9cc903b57c705dc38568a83bb174fd97&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-18951e5564e0809cd45a8670e6df2d62~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178855&auth_key=1761178855-0-0-7d81cdb7093fb7f09778f459c7393961&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-69e864929e4d4b967ea0c2092f48d0a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178862&auth_key=1761178862-0-0-5740aca9457696fe4883f137c07ae0e6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3b89edefac317bda12e1bdf8238ba04c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178869&auth_key=1761178869-0-0-e09a4d1ae9b54c2d41e7b7823688ca2c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3160351667cef4290aa1937cc7722053~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178875&auth_key=1761178875-0-0-2fcb55a72a5ad24662e508a4ec3ebcf1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="A-Synthetic-Data-Driven-Radiology-Foundation-Model-for-Pan-tumor-Clinical-Diagnosis"><a href="#A-Synthetic-Data-Driven-Radiology-Foundation-Model-for-Pan-tumor-Clinical-Diagnosis" class="headerlink" title="A Synthetic Data-Driven Radiology Foundation Model for Pan-tumor   Clinical Diagnosis"></a>A Synthetic Data-Driven Radiology Foundation Model for Pan-tumor   Clinical Diagnosis</h2><p><strong>Authors:Wenhui Lei, Hanyu Chen, Zitian Zhang, Luyang Luo, Qiong Xiao, Yannian Gu, Peng Gao, Yankai Jiang, Ci Wang, Guangtao Wu, Tongjia Xu, Yingjie Zhang, Pranav Rajpurkar, Xiaofan Zhang, Shaoting Zhang, Zhenning Wang</strong></p>
<p>AI-assisted imaging made substantial advances in tumor diagnosis and management. However, a major barrier to developing robust oncology foundation models is the scarcity of large-scale, high-quality annotated datasets, which are limited by privacy restrictions and the high cost of manual labeling. To address this gap, we present PASTA, a pan-tumor radiology foundation model built on PASTA-Gen, a synthetic data framework that generated 30,000 3D CT scans with pixel-level lesion masks and structured reports of tumors across ten organ systems. Leveraging this resource, PASTA achieves state-of-the-art performance on 45 of 46 oncology tasks, including non-contrast CT tumor screening, lesion segmentation, structured reporting, tumor staging, survival prediction, and MRI-modality transfer. To assess clinical applicability, we developed PASTA-AID, a clinical decision support system, and ran a retrospective simulated clinical trial across two scenarios. For pan-tumor screening on plain CT with fixed reading time, PASTA-AID increased radiologistsâ€™ throughput by 11.1-25.1% and improved sensitivity by 17.0-31.4% and precision by 10.5-24.9%; additionally, in a diagnosis-aid workflow, it reduced segmentation time by up to 78.2% and reporting time by up to 36.5%. Beyond gains in accuracy and efficiency, PASTA-AID narrowed the expertise gap, enabling less-experienced radiologists to approach expert-level performance. Together, this work establishes an end-to-end, synthetic data-driven pipeline spanning data generation, model development, and clinical validation, thereby demonstrating substantial potential for pan-tumor research and clinical translation. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½è¾…åŠ©æˆåƒåœ¨è‚¿ç˜¤è¯Šæ–­å’Œæ²»ç–—æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå¼€å‘ç¨³å¥çš„è‚¿ç˜¤åŸºç¡€æ¨¡å‹çš„ä¸»è¦éšœç¢æ˜¯ç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æœ‰æ ‡æ³¨æ•°æ®é›†ï¼Œè¿™å—åˆ°éšç§é™åˆ¶å’Œæ‰‹åŠ¨æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆæˆæ•°æ®æ¡†æ¶PASTA-Genæ„å»ºçš„æ³›è‚¿ç˜¤æ”¾å°„å­¦åŸºç¡€æ¨¡å‹PASTAã€‚PASTA-Genç”Ÿæˆäº†å¸¦æœ‰åƒç´ çº§ç—…å˜æ©ç çš„åä¸‡ä¸ªä¸‰ç»´CTæ‰«æå›¾åƒä»¥åŠæ¶µç›–åä¸ªç³»ç»Ÿçš„ç»“æ„åŒ–è‚¿ç˜¤æŠ¥å‘Šã€‚åˆ©ç”¨è¿™ä¸€èµ„æºï¼ŒPASTAåœ¨46é¡¹è‚¿ç˜¤å­¦ä»»åŠ¡ä¸­çš„45é¡¹ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬éå¯¹æ¯”å¢å¼ºCTè‚¿ç˜¤ç­›æŸ¥ã€ç—…å˜åˆ†å‰²ã€ç»“æ„åŒ–æŠ¥å‘Šã€è‚¿ç˜¤åˆ†æœŸã€ç”Ÿå­˜é¢„æµ‹å’ŒMRIæ¨¡æ€è½¬æ¢ç­‰ã€‚ä¸ºäº†è¯„ä¼°å…¶ä¸´åºŠé€‚ç”¨æ€§ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåä¸ºPASTA-AIDçš„ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿï¼Œå¹¶åœ¨ä¸¤ç§æƒ…å¢ƒä¸‹è¿›è¡Œäº†å›é¡¾æ€§æ¨¡æ‹Ÿä¸´åºŠè¯•éªŒã€‚åœ¨å¸¸è§„CTä¸Šçš„æ³›è‚¿ç˜¤ç­›æŸ¥ä¸­ï¼Œä½¿ç”¨å›ºå®šé˜…è¯»æ—¶é—´çš„æƒ…å†µä¸‹ï¼ŒPASTA-AIDæé«˜äº†æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œæ•ˆç‡ï¼Œæé«˜äº†åŒ»ç”Ÿè¯Šæ–­çš„æ•æ„Ÿæ€§è¾¾17.0%~31.4%ï¼Œç²¾ç¡®åº¦æé«˜è¾¾10.5%~24.9%ã€‚æ­¤å¤–ï¼Œåœ¨è¯Šæ–­è¾…åŠ©å·¥ä½œæµç¨‹ä¸­ï¼Œå®ƒå‡å°‘äº†åˆ†å‰²æ—¶é—´é«˜è¾¾78.2%ï¼Œå¹¶å‡å°‘äº†æŠ¥å‘Šæ—¶é—´é«˜è¾¾36.5%ã€‚é™¤äº†æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ä¹‹å¤–ï¼ŒPASTA-AIDç¼©å°äº†ä¸“å®¶ä¹‹é—´çš„å·®è·ï¼Œä½¿ç»éªŒè¾ƒå°‘çš„æ”¾å°„ç§‘åŒ»ç”Ÿèƒ½å¤Ÿè¾¾åˆ°ä¸“å®¶çº§åˆ«çš„æ€§èƒ½ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œå»ºç«‹äº†ä¸€æ¡ç«¯åˆ°ç«¯çš„åˆæˆæ•°æ®é©±åŠ¨ç®¡é“ï¼Œæ¶µç›–æ•°æ®ç”Ÿæˆã€æ¨¡å‹å¼€å‘å’Œä¸´åºŠéªŒè¯ï¼Œä»è€Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ³›è‚¿ç˜¤ç ”ç©¶å’Œä¸´åºŠè½¬åŒ–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06171v2">PDF</a> 63 pages, 7 figures</p>
<p><strong>Summary</strong><br>     åŸºäºåˆæˆæ•°æ®æ¡†æ¶ç”Ÿæˆçš„æ¨¡æ‹Ÿå›¾åƒåº“â€”â€”PASTA-Genï¼Œæ„å»ºäº†ä¸€ä¸ªæ³›è‚¿ç˜¤æ”¾å°„å­¦åŸºç¡€æ¨¡å‹PASTAï¼Œè¯¥æ¨¡å‹åœ¨è‚¿ç˜¤è¯Šæ–­å’Œç®¡ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚é€šè¿‡åˆæˆæ•°æ®ç”Ÿæˆçš„3ä¸‡å¤šä¸ªä¸‰ç»´CTæ‰«æå›¾åƒå’Œåƒç´ çº§åˆ«çš„è‚¿ç˜¤é®ç½©ç»“æ„æŠ¥å‘Šï¼Œè¦†ç›–äº†åä¸ªç³»ç»Ÿå™¨å®˜çš„è‚¿ç˜¤æ•°æ®ã€‚ç›¸è¾ƒäºç°æœ‰çš„è‚¿ç˜¤è¯Šæ–­ä»»åŠ¡ï¼Œå…¶å±•ç°äº†å‡ºè‰²çš„æ€§èƒ½ï¼Œåœ¨ä¸¤é¡¹è¯„ä¼°ä¸­å®ç°äº†ä¸´åºŠåº”ç”¨ï¼Œä¸ä»…æé«˜äº†æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œæ•ˆç‡ï¼Œä¹Ÿæå‡äº†è¯Šæ–­çš„å‡†ç¡®æ€§å’Œç²¾åº¦ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¯¥æ¨¡å‹ç¼©å°äº†ä¸“å®¶ä¹‹é—´çš„å·®è·ï¼Œä½¿ç»éªŒä¸è¶³çš„æ”¾å°„ç§‘åŒ»ç”Ÿä¹Ÿèƒ½æ¥è¿‘ä¸“å®¶æ°´å¹³ã€‚æ­¤ç ”ç©¶å±•ç¤ºäº†ä¸€ä¸ªæ¶µç›–æ•°æ®ç”Ÿæˆã€æ¨¡å‹å¼€å‘å’Œä¸´åºŠéªŒè¯çš„ç«¯åˆ°ç«¯çš„åˆæˆæ•°æ®é©±åŠ¨ç®¡é“ï¼Œä¸ºæ³›è‚¿ç˜¤ç ”ç©¶å’Œä¸´åºŠåº”ç”¨æä¾›äº†å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AIè¾…åŠ©æˆåƒåœ¨è‚¿ç˜¤è¯Šæ–­å’Œæ²»ç–—ä¸­å–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡æ ‡æ³¨æ•°æ®é›†æ˜¯å¼€å‘ç¨³å¥çš„è‚¿ç˜¤åŸºç¡€æ¨¡å‹çš„ä¸»è¦éšœç¢ã€‚</li>
<li>PASTAæ¨¡å‹åˆ©ç”¨åˆæˆæ•°æ®æ¡†æ¶PASTA-Genç”Ÿæˆäº†è¦†ç›–åä¸ªç³»ç»Ÿå™¨å®˜çš„æ³›è‚¿ç˜¤å›¾åƒæ•°æ®é›†ã€‚</li>
<li>PASTAæ¨¡å‹åœ¨å¤šé¡¹è‚¿ç˜¤è¯Šæ–­ä»»åŠ¡ä¸Šè¾¾åˆ°æœ€ä½³æ€§èƒ½æ°´å¹³ã€‚</li>
<li>é€šè¿‡ä¸¤é¡¹è¯„ä¼°çš„ä¸´åºŠåº”ç”¨æµ‹è¯•è¡¨æ˜ï¼ŒPASTA-AIDæå‡äº†æ”¾å°„ç§‘åŒ»ç”Ÿçš„å·¥ä½œæ•ˆç‡ï¼Œå¢å¼ºäº†è¯Šæ–­çš„å‡†ç¡®æ€§å’Œç²¾ç¡®åº¦ã€‚</li>
<li>è¯¥æ¨¡å‹æé«˜äº†åŒ»ç”Ÿçš„ç»éªŒä¸è¶³çš„æ”¾å°„ç§‘åŒ»ç”Ÿçš„è¡¨ç°æ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ce061904c12d29fa57796dc85caaa822~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178882&auth_key=1761178882-0-0-498c4f4a39e49704075c10f7a7c49c9d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-34794cb6d800ecfaedc2007bf020dd3e~resize:0:q75.jpg?source=1f5c5e47&expiration=1761178890&auth_key=1761178890-0-0-54bb228c0269cf0441295f0052d9c3d5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-23/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-23/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-23/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-c558bc45c86c949fd50cc7e0522743b6~resize:0:q75.jpg?source=1f5c5e47&expiration=1761180533&auth_key=1761180533-0-0-44219f995b13c3938ffb6a1897eaae0f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-23  ParaStyleTTS Toward Efficient and Robust Paralinguistic Style Control   for Expressive Text-to-Speech Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-23/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-feef80c69a578484d5110b11d2cdd7a9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761174605&auth_key=1761174605-0-0-46f631f2f55e75da0d4505f8ec79f6af&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-23  GeoDiff Geometry-Guided Diffusion for Metric Depth Estimation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31686.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
