<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-16  InfGen A Resolution-Agnostic Paradigm for Scalable Image Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_5_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-16-æ›´æ–°"><a href="#2025-09-16-æ›´æ–°" class="headerlink" title="2025-09-16 æ›´æ–°"></a>2025-09-16 æ›´æ–°</h1><h2 id="InfGen-A-Resolution-Agnostic-Paradigm-for-Scalable-Image-Synthesis"><a href="#InfGen-A-Resolution-Agnostic-Paradigm-for-Scalable-Image-Synthesis" class="headerlink" title="InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis"></a>InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis</h2><p><strong>Authors:Tao Han, Wanghan Xu, Junchao Gong, Xiaoyu Yue, Song Guo, Luping Zhou, Lei Bai</strong></p>
<p>Arbitrary resolution image generation provides a consistent visual experience across devices, having extensive applications for producers and consumers. Current diffusion models increase computational demand quadratically with resolution, causing 4K image generation delays over 100 seconds. To solve this, we explore the second generation upon the latent diffusion models, where the fixed latent generated by diffusion models is regarded as the content representation and we propose to decode arbitrary resolution images with a compact generated latent using a one-step generator. Thus, we present the \textbf{InfGen}, replacing the VAE decoder with the new generator, for generating images at any resolution from a fixed-size latent without retraining the diffusion models, which simplifies the process, reducing computational complexity and can be applied to any model using the same latent space. Experiments show InfGen is capable of improving many models into the arbitrary high-resolution era while cutting 4K image generation time to under 10 seconds. </p>
<blockquote>
<p>ä»»æ„åˆ†è¾¨ç‡å›¾åƒç”ŸæˆæŠ€æœ¯ä¸ºå„ç§è®¾å¤‡æä¾›äº†ä¸€è‡´çš„è§†è§‰ä½“éªŒï¼Œå¯¹ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…å…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚å½“å‰çš„æ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—éœ€æ±‚ä¸Šéšç€åˆ†è¾¨ç‡çš„å¢åŠ è€Œå‘ˆç°äºŒæ¬¡æ–¹å¢é•¿ï¼Œå¯¼è‡´4Kå›¾åƒç”Ÿæˆå»¶è¿Ÿè¶…è¿‡100ç§’ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œäº†ç¬¬äºŒä»£æ¢ç´¢ï¼Œå…¶ä¸­ç”±æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›ºå®šæ½œåœ¨è¢«è§†ä¸ºå†…å®¹è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºä½¿ç”¨ä¸€æ­¥ç”Ÿæˆå™¨ï¼Œåˆ©ç”¨ç´§å‡‘çš„ç”Ÿæˆæ½œåœ¨æ¥è§£ç ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†<strong>InfGen</strong>ï¼Œç”¨æ–°çš„ç”Ÿæˆå™¨æ›¿æ¢VAEè§£ç å™¨ï¼Œå¯ä»¥ä»å›ºå®šå¤§å°çš„æ½œåœ¨ç”Ÿæˆä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œè¿™ç®€åŒ–äº†æµç¨‹ï¼Œé™ä½äº†è®¡ç®—å¤æ‚æ€§ï¼Œå¹¶ä¸”å¯ä»¥åº”ç”¨äºä½¿ç”¨ç›¸åŒæ½œåœ¨ç©ºé—´çš„ä»»ä½•æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒInfGenèƒ½å¤Ÿå°†è®¸å¤šæ¨¡å‹å¸¦å…¥ä»»æ„é«˜åˆ†è¾¨ç‡æ—¶ä»£ï¼ŒåŒæ—¶å°†4Kå›¾åƒç”Ÿæˆæ—¶é—´ç¼©çŸ­åˆ°ä¸åˆ°10ç§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10441v1">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢çš„åº”ç”¨å®ç°äº†è·¨è®¾å¤‡çš„ç»Ÿä¸€è§†è§‰ä½“éªŒï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ–¹é¢æœ‰ç€æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚é€šè¿‡é‡‡ç”¨å›ºå®šå¤§å°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„æ½œåœ¨é‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è§£ç å™¨æ¥ç”Ÿæˆä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒã€‚è¿™ç§åä¸ºInfGençš„æ–°æŠ€æœ¯ä¸ä»…ç®€åŒ–äº†æµç¨‹ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œè€Œä¸”å¯ä»¥åº”ç”¨äºä½¿ç”¨åŒä¸€æ½œåœ¨ç©ºé—´çš„ä»»ä½•æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒInfGenå¯å°†è®¸å¤šæ¨¡å‹æå‡ä¸ºä»»æ„é«˜åˆ†è¾¨ç‡æ—¶ä»£ï¼Œå¹¶å°†4Kå›¾åƒç”Ÿæˆæ—¶é—´ç¼©çŸ­è‡³ä¸åˆ°10ç§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å¯å®ç°ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆï¼Œæä¾›è·¨è®¾å¤‡çš„ç»Ÿä¸€è§†è§‰ä½“éªŒã€‚</li>
<li>å½“å‰æ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—éœ€æ±‚ä¸Šéšç€åˆ†è¾¨ç‡çš„å¢åŠ è€Œå‘ˆäºŒæ¬¡æ–¹å¢é•¿ï¼Œå¯¼è‡´é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ—¶é—´è¾ƒé•¿ã€‚</li>
<li>ç¬¬äºŒä»£æ‰©æ•£æ¨¡å‹é€šè¿‡å›ºå®šæ½œåœ¨é‡ç”Ÿæˆï¼Œå°†å†…å®¹è¡¨ç¤ºä¸æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆã€‚</li>
<li>InfGenæŠ€æœ¯ç”¨äºè§£ç ä»»æ„åˆ†è¾¨ç‡çš„å›¾åƒï¼Œä½¿ç”¨ç´§å‡‘çš„ç”Ÿæˆæ½œåœ¨é‡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>InfGenç®€åŒ–äº†æµç¨‹ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¯å¹¿æ³›åº”ç”¨äºä½¿ç”¨åŒä¸€æ½œåœ¨ç©ºé—´çš„æ¨¡å‹ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒInfGenæŠ€æœ¯èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œè¿›å…¥ä»»æ„é«˜åˆ†è¾¨ç‡æ—¶ä»£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10441">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10441v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10441v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10441v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10441v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10441v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GARD-Gamma-based-Anatomical-Restoration-and-Denoising-for-Retinal-OCT"><a href="#GARD-Gamma-based-Anatomical-Restoration-and-Denoising-for-Retinal-OCT" class="headerlink" title="GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT"></a>GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT</h2><p><strong>Authors:Botond Fazekas, Thomas Pinetz, Guilherme Aresta, Taha Emre, Hrvoje Bogunovic</strong></p>
<p>Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing and monitoring retinal diseases. However, OCT images are inherently degraded by speckle noise, which obscures fine details and hinders accurate interpretation. While numerous denoising methods exist, many struggle to balance noise reduction with the preservation of crucial anatomical structures. This paper introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel deep learning approach for OCT image despeckling that leverages the strengths of diffusion probabilistic models. Unlike conventional diffusion models that assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more accurately reflect the statistical properties of speckle. Furthermore, we introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed, less-noisy image to guide the denoising process. This crucial addition prevents the reintroduction of high-frequency noise. We accelerate the inference process by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans demonstrate that GARD significantly outperforms traditional denoising methods and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE. Qualitative results confirm that GARD produces sharper edges and better preserves fine anatomical details. </p>
<blockquote>
<p>å…‰å­¦ç›¸å¹²å±‚ææˆåƒï¼ˆOCTï¼‰æ˜¯è¯Šæ–­è§†ç½‘è†œç–¾ç—…å¹¶è¿›è¡Œç›‘æµ‹çš„é‡è¦æˆåƒæ–¹å¼ã€‚ç„¶è€Œï¼ŒOCTå›¾åƒå—åˆ°æ–‘ç‚¹å™ªå£°çš„å›ºæœ‰å¹²æ‰°ï¼Œè¿™æ©ç›–äº†ç»†èŠ‚å¹¶é˜»ç¢äº†å‡†ç¡®è§£é‡Šã€‚è™½ç„¶å­˜åœ¨è®¸å¤šå»å™ªæ–¹æ³•ï¼Œä½†è®¸å¤šæ–¹æ³•åœ¨å¹³è¡¡å™ªå£°é™ä½ä¸å…³é”®è§£å‰–ç»“æ„çš„ä¿ç•™æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æœ¬æ–‡ä»‹ç»äº†åŸºäºä¼½é©¬è§£å‰–ç»“æ„æ¢å¤å’Œå»å™ªï¼ˆGARDï¼‰æŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨æ‰©æ•£æ¦‚ç‡æ¨¡å‹çš„æ·±åº¦å­¦ä¹ æ–¹æ³•è¿›è¡ŒOCTå›¾åƒå»æ–‘å¤„ç†ã€‚ä¸ä¼ ç»Ÿçš„å‡è®¾é«˜æ–¯å™ªå£°çš„æ‰©æ•£æ¨¡å‹ä¸åŒï¼ŒGARDé‡‡ç”¨å»å™ªæ‰©æ•£ä¼½é©¬æ¨¡å‹ï¼Œæ›´å‡†ç¡®åæ˜ æ–‘ç‚¹å™ªå£°çš„ç»Ÿè®¡ç‰¹æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†é™å™ªä¿çœŸåº¦æœ¯è¯­ï¼Œåˆ©ç”¨é¢„å¤„ç†åçš„å™ªå£°è¾ƒå°‘çš„å›¾åƒæ¥å¼•å¯¼å»å™ªè¿‡ç¨‹ã€‚è¿™ä¸€å…³é”®è¡¥å……é¿å…äº†é«˜é¢‘å™ªå£°çš„å†æ¬¡å¼•å…¥ã€‚æˆ‘ä»¬é€šè¿‡å°†å»å™ªæ‰©æ•£éšæ¨¡å‹æ¡†æ¶é€‚åº”åˆ°åŸºäºä¼½é©¬çš„æ¨¡å‹æ¥åŠ é€Ÿæ¨ç†è¿‡ç¨‹ã€‚åœ¨å…·æœ‰é…å¯¹å™ªå£°å’Œéå™ªå£°OCT Bæ‰«ææ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„å»å™ªæ–¹æ³•å’Œæœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼ŒGARDåœ¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚å®šæ€§ç»“æœè¯å®ï¼ŒGARDå¯ä»¥äº§ç”Ÿæ›´æ¸…æ™°çš„è¾¹ç¼˜å¹¶æ›´å¥½åœ°ä¿ç•™ç»†å¾®è§£å‰–ç»“æ„ç»†èŠ‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10341v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å…‰å­¦ç›¸å¹²å±‚ææˆåƒï¼ˆOCTï¼‰å›¾åƒå»å™ªæ–¹æ³•â€”â€”GARDï¼ˆåŸºäºä¼½é©¬çš„è§£å‰–å­¦æ¢å¤å’Œå»å™ªï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¦‚ç‡æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œé€šè¿‡é‡‡ç”¨ä¼½é©¬æ¨¡å‹æ›´å‡†ç¡®åæ˜ æ•£æ–‘çš„ç»Ÿè®¡ç‰¹æ€§ï¼Œå¹¶å¼•å…¥å»å™ªä¿çœŸåº¦é¡¹æ¥æŒ‡å¯¼å»å™ªè¿‡ç¨‹ï¼Œé˜²æ­¢é«˜é¢‘å™ªå£°çš„é‡æ–°å¼•å…¥ã€‚å®éªŒè¯æ˜ï¼ŒGARDåœ¨PSNRã€SSIMå’ŒMSEæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå»å™ªæ–¹æ³•å’Œæœ€æ–°æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿäº§ç”Ÿæ›´æ¸…æ™°è¾¹ç¼˜å¹¶æ›´å¥½ä¿ç•™ç²¾ç»†è§£å‰–å­¦ç»†èŠ‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GARDæ˜¯ä¸€ç§é’ˆå¯¹OCTå›¾åƒå»å™ªçš„æ·±åº¦å­¦ä¹ æ–°æ–¹æ³•ï¼ŒåŸºäºæ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€‚</li>
<li>GARDé‡‡ç”¨ä¼½é©¬æ¨¡å‹æ›´å‡†ç¡®åæ˜ æ•£æ–‘å™ªå£°çš„ç»Ÿè®¡ç‰¹æ€§ã€‚</li>
<li>å¼•å…¥å»å™ªä¿çœŸåº¦é¡¹ï¼Œé˜²æ­¢é«˜é¢‘å™ªå£°çš„é‡æ–°å¼•å…¥ï¼ŒæŒ‡å¯¼å»å™ªè¿‡ç¨‹ã€‚</li>
<li>GARDæ˜¾è‘—æé«˜äº†å»å™ªæ€§èƒ½ï¼Œåœ¨PSNRã€SSIMå’ŒMSEæŒ‡æ ‡ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œæœ€æ–°æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</li>
<li>GARDèƒ½å¤Ÿäº§ç”Ÿæ›´æ¸…æ™°è¾¹ç¼˜ï¼Œæ›´å¥½åœ°ä¿ç•™OCTå›¾åƒä¸­çš„ç²¾ç»†è§£å‰–å­¦ç»†èŠ‚ã€‚</li>
<li>GARDæ–¹æ³•å…·æœ‰åŠ é€Ÿæ¨æ–­è¿‡ç¨‹çš„èƒ½åŠ›ï¼Œé€šè¿‡é€‚åº”éšå¼æ‰©æ•£æ¨¡å‹æ¡†æ¶å®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10341">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10341v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Compute-Only-16-Tokens-in-One-Timestep-Accelerating-Diffusion-Transformers-with-Cluster-Driven-Feature-Caching"><a href="#Compute-Only-16-Tokens-in-One-Timestep-Accelerating-Diffusion-Transformers-with-Cluster-Driven-Feature-Caching" class="headerlink" title="Compute Only 16 Tokens in One Timestep: Accelerating Diffusion   Transformers with Cluster-Driven Feature Caching"></a>Compute Only 16 Tokens in One Timestep: Accelerating Diffusion   Transformers with Cluster-Driven Feature Caching</h2><p><strong>Authors:Zhixin Zheng, Xinyu Wang, Chang Zou, Shaobo Wang, Linfeng Zhang</strong></p>
<p>Diffusion transformers have gained significant attention in recent years for their ability to generate high-quality images and videos, yet still suffer from a huge computational cost due to their iterative denoising process. Recently, feature caching has been introduced to accelerate diffusion transformers by caching the feature computation in previous timesteps and reusing it in the following timesteps, which leverage the temporal similarity of diffusion models while ignoring the similarity in the spatial dimension. In this paper, we introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and complementary perspective for previous feature caching. Specifically, ClusCa performs spatial clustering on tokens in each timestep, computes only one token in each cluster and propagates their information to all the other tokens, which is able to reduce the number of tokens by over 90%. Extensive experiments on DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image and text-to-video generation. Besides, it can be directly applied to any diffusion transformer without requirements for training. For instance, ClusCa achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing the original model by 0.51%. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Shenyi-Z/Cache4Diffusion">https://github.com/Shenyi-Z/Cache4Diffusion</a>. </p>
<blockquote>
<p>æ‰©æ•£å˜å‹å™¨è¿‘å¹´æ¥å› å…¶ç”Ÿæˆé«˜è´¨é‡å›¾åƒå’Œè§†é¢‘çš„èƒ½åŠ›è€Œå¤‡å—å…³æ³¨ï¼Œä½†ç”±äºå…¶è¿­ä»£å»å™ªè¿‡ç¨‹ï¼Œä»ç„¶é¢ä¸´ç€å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚æœ€è¿‘ï¼Œç‰¹å¾ç¼“å­˜çš„å¼•å…¥é€šè¿‡ç¼“å­˜å…ˆå‰çš„æ—¶é—´æ­¥é•¿çš„ç‰¹å¾è®¡ç®—å¹¶åœ¨åç»­çš„æ—¶é—´æ­¥é•¿ä¸­é‡å¤ä½¿ç”¨å®ƒæ¥åŠ é€Ÿæ‰©æ•£å˜å‹å™¨ï¼Œè¿™åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„æ—¶é—´ç›¸ä¼¼æ€§ï¼ŒåŒæ—¶å¿½ç•¥äº†ç©ºé—´ç»´åº¦çš„ç›¸ä¼¼æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ­£äº¤ä¸”äº’è¡¥äºä»¥å‰ç‰¹å¾ç¼“å­˜çš„ Cluster-Driven Feature Caching (ClusCa)ã€‚å…·ä½“æ¥è¯´ï¼ŒClusCa å¯¹æ¯ä¸ªæ—¶é—´æ­¥é•¿çš„ä»¤ç‰Œè¿›è¡Œç©ºé—´èšç±»ï¼Œæ¯ä¸ªé›†ç¾¤åªè®¡ç®—ä¸€ä¸ªä»¤ç‰Œï¼Œå¹¶å°†å…¶ä¿¡æ¯ä¼ æ’­åˆ°æ‰€æœ‰å…¶ä»–ä»¤ç‰Œï¼Œè¿™èƒ½å¤Ÿå°†ä»¤ç‰Œæ•°é‡å‡å°‘è¶…è¿‡ 90%ã€‚åœ¨ DiTã€FLUX å’Œ HunyuanVideo ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†å…¶åœ¨æ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥æ— éœ€è®­ç»ƒç›´æ¥åº”ç”¨äºä»»ä½•æ‰©æ•£å˜å‹å™¨ã€‚ä¾‹å¦‚ï¼ŒClusCa åœ¨ FLUX ä¸Šå®ç°äº† 4.96 å€çš„åŠ é€Ÿï¼ŒImageReward ä¸º 99.49%ï¼Œè¶…å‡ºåŸå§‹æ¨¡å‹ 0.51%ã€‚ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/Shenyi-Z/Cache4Diffusion">https://github.com/Shenyi-Z/Cache4Diffusion</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10312v1">PDF</a> 11 pages, 11 figures; Accepted by ACM MM2025; Mainly focus on feature   caching for diffusion transformers acceleration</p>
<p><strong>æ‘˜è¦</strong><br>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒå’Œè§†é¢‘è´¨é‡é«˜ï¼Œä½†ç”±äºè¿­ä»£å»å™ªè¿‡ç¨‹ï¼Œè®¡ç®—æˆæœ¬ä»ç„¶å¾ˆé«˜ã€‚æœ€è¿‘å¼•å…¥äº†ç‰¹å¾ç¼“å­˜æ¥åŠ é€Ÿæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡åœ¨åç»­æ—¶é—´æ­¥é‡ç”¨ä¹‹å‰æ—¶é—´æ­¥çš„ç‰¹å¾è®¡ç®—ï¼Œå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶åºç›¸ä¼¼æ€§æ¥å¿½ç•¥ç©ºé—´ç»´åº¦çš„ç›¸ä¼¼æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†é›†ç¾¤é©±åŠ¨ç‰¹å¾ç¼“å­˜ï¼ˆClusCaï¼‰ä½œä¸ºä¸€ç§æ­£äº¤ä¸”è¡¥å……çš„è§†è§’ã€‚å…·ä½“æ¥è¯´ï¼ŒClusCaåœ¨æ¯ä¸ªæ—¶é—´æ­¥å¯¹ä»¤ç‰Œè¿›è¡Œç©ºé—´èšç±»ï¼Œåªè®¡ç®—æ¯ä¸ªé›†ç¾¤ä¸­çš„ä¸€ä¸ªä»¤ç‰Œï¼Œå¹¶å°†å…¶ä¿¡æ¯ä¼ æ’­åˆ°æ‰€æœ‰å…¶ä»–ä»¤ç‰Œï¼Œèƒ½å¤Ÿå‡å°‘è¶…è¿‡90%çš„ä»¤ç‰Œæ•°é‡ã€‚åœ¨DiTã€FLUXå’ŒHunyuanVideoä¸Šçš„å¤§é‡å®éªŒè¯æ˜å…¶åœ¨æ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥æ— éœ€è®­ç»ƒç›´æ¥åº”ç”¨äºä»»ä½•æ‰©æ•£æ¨¡å‹ã€‚ä¾‹å¦‚ï¼ŒClusCaåœ¨FLUXä¸Šå®ç°äº†4.96å€çš„åŠ é€Ÿï¼ŒImageRewardä¸º99.49%ï¼Œè¶…è¶Šäº†åŸå§‹æ¨¡å‹0.51%ã€‚ä»£ç å¯é€šè¿‡é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/Shenyi-Z/Cache4Diffusion">https://github.com/Shenyi-Z/Cache4Diffusion</a>ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å›¾åƒå’Œè§†é¢‘ä½†è®¡ç®—æˆæœ¬é«˜ã€‚</li>
<li>ç‰¹å¾ç¼“å­˜æ—¨åœ¨åŠ é€Ÿæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡é‡ç”¨ä¹‹å‰æ—¶é—´æ­¥çš„ç‰¹å¾è®¡ç®—ã€‚</li>
<li>Cluster-Driven Feature Cachingï¼ˆClusCaï¼‰é€šè¿‡ç©ºé—´èšç±»å‡å°‘è®¡ç®—è´Ÿæ‹…ã€‚</li>
<li>ClusCaèƒ½å¤Ÿåœ¨ä¿æŒé«˜è´¨é‡è¾“å‡ºçš„åŒæ—¶å¤§å¹…åº¦å‡å°‘è®¡ç®—ä»¤ç‰Œæ•°é‡ã€‚</li>
<li>ClusCaæ–¹æ³•åœ¨å„ç§å®éªŒè®¾ç½®ä¸­éƒ½è¡¨ç°å‡ºäº†æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºä»»ä½•æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæ­¥éª¤ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10312">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10312v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10312v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10312v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10312v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10312v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Scalable-Training-for-Vector-Quantized-Networks-with-100-Codebook-Utilization"><a href="#Scalable-Training-for-Vector-Quantized-Networks-with-100-Codebook-Utilization" class="headerlink" title="Scalable Training for Vector-Quantized Networks with 100% Codebook   Utilization"></a>Scalable Training for Vector-Quantized Networks with 100% Codebook   Utilization</h2><p><strong>Authors:Yifan Chang, Jie Qin, Limeng Qiao, Xiaofeng Wang, Zheng Zhu, Lin Ma, Xingang Wang</strong></p>
<p>Vector quantization (VQ) is a key component in discrete tokenizers for image generation, but its training is often unstable due to straight-through estimation bias, one-step-behind updates, and sparse codebook gradients, which lead to suboptimal reconstruction performance and low codebook usage. In this work, we analyze these fundamental challenges and provide a simple yet effective solution. To maintain high codebook usage in VQ networks (VQN) during learning annealing and codebook size expansion, we propose VQBridge, a robust, scalable, and efficient projector based on the map function method. VQBridge optimizes code vectors through a compress-process-recover pipeline, enabling stable and effective codebook training. By combining VQBridge with learning annealing, our VQN achieves full (100%) codebook usage across diverse codebook configurations, which we refer to as FVQ (FullVQ). Through extensive experiments, we demonstrate that FVQ is effective, scalable, and generalizable: it attains 100% codebook usage even with a 262k-codebook, achieves state-of-the-art reconstruction performance, consistently improves with larger codebooks, higher vector channels, or longer training, and remains effective across different VQ variants. Moreover, when integrated with LlamaGen, FVQ significantly enhances image generation performance, surpassing visual autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID, highlighting the importance of high-quality tokenizers for strong autoregressive image generation. </p>
<blockquote>
<p>å‘é‡é‡åŒ–ï¼ˆVQï¼‰æ˜¯å›¾åƒç”Ÿæˆç¦»æ•£åˆ†è¯å™¨ä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œä½†å…¶è®­ç»ƒé€šå¸¸ä¸ç¨³å®šï¼ŒåŸå› åœ¨äºç›´é€šä¼°è®¡åå·®ã€ä¸€æ­¥æ»åæ›´æ–°å’Œç¨€ç–ä»£ç æœ¬æ¢¯åº¦ï¼Œå¯¼è‡´é‡å»ºæ€§èƒ½ä¸ä½³å’Œä»£ç æœ¬ä½¿ç”¨ç‡ä½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†è¿™äº›åŸºæœ¬æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†åœ¨å­¦ä¹ é€€ç«å’Œä»£ç æœ¬å¤§å°æ‰©å±•è¿‡ç¨‹ä¸­ä¿æŒVQç½‘ç»œï¼ˆVQNï¼‰çš„é«˜ä»£ç æœ¬ä½¿ç”¨ç‡ï¼Œæˆ‘ä»¬æå‡ºäº†VQBridgeï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ˜ å°„å‡½æ•°æ–¹æ³•çš„ç¨³å¥ã€å¯æ‰©å±•å’Œé«˜æ•ˆçš„æŠ•å½±ä»ªã€‚VQBridgeé€šè¿‡å‹ç¼©-å¤„ç†-æ¢å¤ç®¡é“ä¼˜åŒ–ä»£ç å‘é‡ï¼Œèƒ½å¤Ÿå®ç°ç¨³å®šå’Œæœ‰æ•ˆçš„ä»£ç æœ¬è®­ç»ƒã€‚é€šè¿‡å°†VQBridgeä¸å­¦ä¹ é€€ç«ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„VQNåœ¨ä¸åŒä»£ç æœ¬é…ç½®ä¸‹å®ç°äº†100%çš„ä»£ç æœ¬ä½¿ç”¨ç‡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºFVQï¼ˆFullVQï¼‰ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†FVQçš„æœ‰æ•ˆæ€§ã€å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ï¼šå®ƒå³ä½¿åœ¨262kä»£ç æœ¬ä¸‹ä¹Ÿèƒ½å®ç°100%çš„ä»£ç æœ¬ä½¿ç”¨ç‡ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„é‡å»ºæ€§èƒ½ï¼Œéšç€æ›´å¤§çš„ä»£ç æœ¬ã€æ›´é«˜çš„å‘é‡é€šé“æˆ–æ›´é•¿çš„è®­ç»ƒæ—¶é—´è€Œä¸æ–­æ”¹è¿›ï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„VQå˜ä½“ä¸­éƒ½æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œå½“ä¸LlamaGené›†æˆæ—¶ï¼ŒFVQæ˜¾ç€æé«˜äº†å›¾åƒç”Ÿæˆæ€§èƒ½ï¼Œä»¥0.5çš„rFIDè¶…è¿‡äº†è§†è§‰è‡ªå›å½’æ¨¡å‹ï¼ˆVARï¼‰ï¼Œä»¥0.2çš„rFIDè¶…è¿‡äº†æ‰©æ•£æ¨¡å‹ï¼ˆDiTï¼‰ï¼Œçªæ˜¾äº†é«˜è´¨é‡åˆ†è¯å™¨å¯¹äºå¼ºå¤§çš„è‡ªå›å½’å›¾åƒç”Ÿæˆçš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10140v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å‘é‡é‡åŒ–ï¼ˆVQï¼‰åœ¨å›¾åƒç”Ÿæˆç¦»æ•£åˆ†è¯å™¨ä¸­çš„å…³é”®ä½œç”¨å’Œå­˜åœ¨çš„è®­ç»ƒä¸ç¨³å®šæ€§é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆVQBridgeã€‚å®ƒé€šè¿‡å‹ç¼©-å¤„ç†-æ¢å¤ç®¡é“ä¼˜åŒ–ä»£ç å‘é‡ï¼Œå®ç°ç¨³å®šçš„ä»£ç æœ¬è®­ç»ƒã€‚ç»“åˆVQBridgeå’Œå­¦ä¹ é€€ç«æŠ€æœ¯ï¼Œå®ç°äº†å…¨ä»£ç æœ¬ä½¿ç”¨ç‡çš„FVQï¼ˆFullVQï¼‰ã€‚å®éªŒè¡¨æ˜ï¼ŒFVQæ•ˆæœæ˜¾è‘—ï¼Œå¯æ‰©å±•åˆ°å¤§è§„æ¨¡ä»£ç æœ¬ï¼Œå¹¶ä¸å…¶ä»–æŠ€æœ¯ç›¸ç»“åˆæ—¶æ€§èƒ½æ›´ä½³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‘é‡é‡åŒ–ï¼ˆVQï¼‰æ˜¯å›¾åƒç”Ÿæˆç¦»æ•£åˆ†è¯å™¨ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä½†å…¶è®­ç»ƒå­˜åœ¨ä¸ç¨³å®šé—®é¢˜ã€‚</li>
<li>è®­ç»ƒä¸ç¨³å®šçš„ä¸»è¦åŸå› åŒ…æ‹¬ç›´é€šä¼°è®¡åå·®ã€ä¸€æ­¥æ»åæ›´æ–°å’Œç¨€ç–ä»£ç æœ¬æ¢¯åº¦ã€‚</li>
<li>VQBridgeæ˜¯ä¸€ä¸ªåŸºäºæ˜ å°„å‡½æ•°æ–¹æ³•çš„ç¨³å¥ã€å¯æ‰©å±•å’Œé«˜æ•ˆçš„æŠ•å½±ä»ªï¼Œå¯ä¼˜åŒ–ä»£ç å‘é‡ã€‚</li>
<li>VQBridgeé€šè¿‡å‹ç¼©-å¤„ç†-æ¢å¤ç®¡é“å®ç°ç¨³å®šçš„ä»£ç æœ¬è®­ç»ƒï¼Œå¹¶ç»“åˆå­¦ä¹ é€€ç«æŠ€æœ¯å®ç°å…¨ä»£ç æœ¬ä½¿ç”¨ç‡ï¼ˆFVQï¼‰ã€‚</li>
<li>FVQå…·æœ‰æ˜¾è‘—æ•ˆæœï¼Œå¯æ‰©å±•åˆ°å¤§è§„æ¨¡ä»£ç æœ¬ï¼Œå¹¶ä¸å…¶ä»–æŠ€æœ¯ç»“åˆæ—¶è¡¨ç°æ›´ä½³ã€‚</li>
<li>FVQåœ¨å¤šç§VQé…ç½®ä¸­å®ç°äº†100%çš„ä»£ç æœ¬ä½¿ç”¨ç‡ï¼Œå¹¶åœ¨ä¸LlamaGené›†æˆæ—¶æ˜¾è‘—å¢å¼ºäº†å›¾åƒç”Ÿæˆæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10140">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10140v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10140v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10140v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10140v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10140v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Realism-Control-One-step-Diffusion-for-Real-World-Image-Super-Resolution"><a href="#Realism-Control-One-step-Diffusion-for-Real-World-Image-Super-Resolution" class="headerlink" title="Realism Control One-step Diffusion for Real-World Image Super-Resolution"></a>Realism Control One-step Diffusion for Real-World Image Super-Resolution</h2><p><strong>Authors:Zongliang Wu, Siming Zheng, Peng-Tao Jiang, Xin Yuan</strong></p>
<p>Pre-trained diffusion models have shown great potential in real-world image super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions. While one-step diffusion (OSD) methods significantly improve efficiency compared to traditional multi-step approaches, they still have limitations in balancing fidelity and realism across diverse scenarios. Since the OSDs for SR are usually trained or distilled by a single timestep, they lack flexible control mechanisms to adaptively prioritize these competing objectives, which are inherently manageable in multi-step methods through adjusting sampling steps. To address this challenge, we propose a Realism Controlled One-step Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping strategy that enables explicit control over fidelity-realism trade-offs during the noise prediction phase with minimal training paradigm modifications and original training data. A degradation-aware sampling strategy is also introduced to align distillation regularization with the grouping strategy and enhance the controlling of trade-offs. Moreover, a visual prompt injection module is used to replace conventional text prompts with degradation-aware visual tokens, enhancing both restoration accuracy and semantic consistency. Our method achieves superior fidelity and perceptual quality while maintaining computational efficiency. Extensive experiments demonstrate that RCOD outperforms state-of-the-art OSD methods in both quantitative metrics and visual qualities, with flexible realism control capabilities in the inference stage. The code will be released. </p>
<blockquote>
<p>é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œèƒ½å¤Ÿå®ç°é«˜åˆ†è¾¨ç‡é‡å»ºã€‚ä¸ä¼ ç»Ÿçš„å¤šæ­¥æ–¹æ³•ç›¸æ¯”ï¼Œä¸€æ­¥æ‰©æ•£ï¼ˆOSDï¼‰æ–¹æ³•æ˜¾è‘—æé«˜äº†æ•ˆç‡ï¼Œä½†åœ¨å¹³è¡¡ä¸åŒåœºæ™¯ä¸‹çš„ä¿çœŸåº¦å’ŒçœŸå®æ„Ÿæ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚ç”±äºOSDè¶…åˆ†è¾¨ç‡é€šå¸¸é€šè¿‡å•ä¸€æ—¶é—´æ­¥é•¿è¿›è¡Œè®­ç»ƒæˆ–è’¸é¦ï¼Œå®ƒä»¬ç¼ºä¹çµæ´»çš„æ§åˆ¶æœºåˆ¶æ¥é€‚åº”æ€§åœ°ä¼˜å…ˆè€ƒè™‘è¿™äº›ç›¸äº’ç«äº‰çš„ç›®æ ‡ï¼Œè€Œè¿™äº›ç›®æ ‡åœ¨å¤šæ­¥æ–¹æ³•ä¸­å¯ä»¥é€šè¿‡è°ƒæ•´é‡‡æ ·æ­¥éª¤æ¥å†…åœ¨ç®¡ç†ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºReal-ISRçš„çœŸå®æ„Ÿæ§åˆ¶ä¸€æ­¥æ‰©æ•£ï¼ˆRCODï¼‰æ¡†æ¶ã€‚RCODæä¾›äº†ä¸€ç§æ½œåœ¨é¢†åŸŸåˆ†ç»„ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å™ªå£°é¢„æµ‹é˜¶æ®µé€šè¿‡æœ€å°çš„è®­ç»ƒèŒƒå¼ä¿®æ”¹å’ŒåŸå§‹è®­ç»ƒæ•°æ®å®ç°å¯¹ä¿çœŸåº¦-çœŸå®æ„Ÿæƒè¡¡çš„æ˜ç¡®æ§åˆ¶ã€‚è¿˜å¼•å…¥äº†ä¸€ç§é€€åŒ–æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œä»¥ä½¿è’¸é¦æ­£åˆ™åŒ–ä¸åˆ†ç»„ç­–ç•¥ç›¸ä¸€è‡´ï¼Œå¹¶å¢å¼ºå¯¹æƒè¡¡çš„æ§åˆ¶ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è§†è§‰æç¤ºæ³¨å…¥æ¨¡å—æ¥æ›¿ä»£ä¼ ç»Ÿçš„æ–‡æœ¬æç¤ºï¼Œä½¿ç”¨é€€åŒ–æ„ŸçŸ¥è§†è§‰ä»¤ç‰Œï¼Œæé«˜æ¢å¤ç²¾åº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œå®ç°äº†ä¼˜è¶Šçš„ä¿çœŸåº¦å’Œæ„ŸçŸ¥è´¨é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRCODåœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºæœ€æ–°çš„OSDæ–¹æ³•ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µå…·æœ‰çµæ´»çš„çœŸå®æ„Ÿæ§åˆ¶èƒ½åŠ›ã€‚ä»£ç å°†å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10122v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œé€šè¿‡ä¸€æ­¥æ‰©æ•£æ–¹æ³•æé«˜æ•ˆç‡ã€‚ä½†ä¸€æ­¥æ‰©æ•£æ–¹æ³•é¢ä¸´ä¿çœŸåº¦å’Œç°å®æ„Ÿå¹³è¡¡çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åä¸ºRCODçš„æ–°æ¡†æ¶ï¼Œæä¾›æ½œåœ¨åŸŸåˆ†ç»„ç­–ç•¥ï¼Œåœ¨å™ªå£°é¢„æµ‹é˜¶æ®µæ˜ç¡®æ§åˆ¶ä¿çœŸåº¦ä¸ç°å®æ„Ÿçš„æƒè¡¡ï¼ŒåŒæ—¶å¼•å…¥é™è§£æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥å’Œè§†è§‰æç¤ºæ³¨å…¥æ¨¡å—ï¼Œæé«˜æ¢å¤ç²¾åº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚RCODæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šå®ç°äº†é«˜ä¿çœŸå’Œæ„ŸçŸ¥è´¨é‡ï¼Œå¹¶åœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰è´¨é‡ä¸Šä¼˜äºæœ€å…ˆè¿›çš„ä¸€æ­¥æ‰©æ•£æ–¹æ³•ï¼Œå…·æœ‰çµæ´»çš„æ¨ç†é˜¶æ®µç°å®æ„Ÿæ§åˆ¶åŠŸèƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ½œåŠ›ã€‚</li>
<li>ä¸€æ­¥æ‰©æ•£æ–¹æ³•æé«˜äº†æ•ˆç‡ï¼Œä½†åœ¨å¹³è¡¡ä¿çœŸåº¦å’Œç°å®æ„Ÿæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>RCODæ¡†æ¶é€šè¿‡æ½œåœ¨åŸŸåˆ†ç»„ç­–ç•¥æ˜ç¡®æ§åˆ¶ä¿çœŸåº¦ä¸ç°å®æ„Ÿçš„æƒè¡¡ã€‚</li>
<li>å¼•å…¥é™è§£æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥å’Œè§†è§‰æç¤ºæ³¨å…¥æ¨¡å—æå‡æ¢å¤ç²¾åº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>RCODæ–¹æ³•åœ¨å®šé‡æŒ‡æ ‡å’Œè§†è§‰è´¨é‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºå…¶ä»–å…ˆè¿›çš„ä¸€æ­¥æ‰©æ•£æ–¹æ³•ã€‚</li>
<li>RCODå…·æœ‰çµæ´»çš„æ¨ç†é˜¶æ®µç°å®æ„Ÿæ§åˆ¶åŠŸèƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10122">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.10122v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Chord-Chain-of-Rendering-Decomposition-for-PBR-Material-Estimation-from-Generated-Texture-Images"><a href="#Chord-Chain-of-Rendering-Decomposition-for-PBR-Material-Estimation-from-Generated-Texture-Images" class="headerlink" title="Chord: Chain of Rendering Decomposition for PBR Material Estimation from   Generated Texture Images"></a>Chord: Chain of Rendering Decomposition for PBR Material Estimation from   Generated Texture Images</h2><p><strong>Authors:Zhi Ying, Boxiang Rong, Jingyu Wang, Maoyuan Xu</strong></p>
<p>Material creation and reconstruction are crucial for appearance modeling but traditionally require significant time and expertise from artists. While recent methods leverage visual foundation models to synthesize PBR materials from user-provided inputs, they often fall short in quality, flexibility, and user control. We propose a novel two-stage generate-and-estimate framework for PBR material generation. In the generation stage, a fine-tuned diffusion model synthesizes shaded, tileable texture images aligned with user input. In the estimation stage, we introduce a chained decomposition scheme that sequentially predicts SVBRDF channels by passing previously extracted representation as input into a single-step image-conditional diffusion model. Our method is efficient, high quality, and enables flexible user control. We evaluate our approach against existing material generation and estimation methods, demonstrating superior performance. Our material estimation method shows strong robustness on both generated textures and in-the-wild photographs. Furthermore, we highlight the flexibility of our framework across diverse applications, including text-to-material, image-to-material, structure-guided generation, and material editing. </p>
<blockquote>
<p>æè´¨åˆ›å»ºå’Œé‡å»ºå¯¹äºå¤–è§‚å»ºæ¨¡è‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿä¸Šéœ€è¦è‰ºæœ¯å®¶èŠ±è´¹å¤§é‡æ—¶é—´å’Œä¸“ä¸šæŠ€èƒ½ã€‚è™½ç„¶æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹æ¥åˆæˆç”¨æˆ·æä¾›çš„è¾“å…¥çš„ç‰©ç†åŸºç¡€æ¸²æŸ“ï¼ˆPBRï¼‰æè´¨ï¼Œä½†åœ¨è´¨é‡ã€çµæ´»æ€§å’Œç”¨æˆ·æ§åˆ¶æ–¹é¢å¾€å¾€å­˜åœ¨ä¸è¶³ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºPBRæè´¨ç”Ÿæˆçš„æ–°å‹ä¸¤é˜¶æ®µç”Ÿæˆå’Œä¼°è®¡æ¡†æ¶ã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œç»è¿‡å¾®è°ƒçš„åˆ†æ‰©æ•£æ¨¡å‹åˆæˆä¸ç”¨æˆ·è¾“å…¥å¯¹é½çš„é˜´å½±ã€å¯æ‹¼æ¥çº¹ç†å›¾åƒã€‚åœ¨ä¼°è®¡é˜¶æ®µï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é“¾å¼åˆ†è§£æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆé€šè¿‡å°†ç”±å…ˆå‰æå–çš„è¡¨ç¤ºä½œä¸ºè¾“å…¥ä¼ é€’ç»™å•æ­¥å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹æ¥é¡ºåºé¢„æµ‹SVBRDFé€šé“ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ•ˆç‡é«˜ã€è´¨é‡é«˜ï¼Œå¹¶èƒ½å®ç°çµæ´»çš„ç”¨æˆ·æ§åˆ¶ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸ç°æœ‰çš„æè´¨ç”Ÿæˆå’Œä¼°è®¡æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒè¯„ä¼°ï¼Œå±•ç¤ºäº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æè´¨ä¼°è®¡æ–¹æ³•åœ¨åˆæˆçº¹ç†å’Œè‡ªç„¶ç…§ç‰‡ä¸Šéƒ½è¡¨ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨å„ç§åº”ç”¨ä¸­çš„çµæ´»æ€§ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°æè´¨ã€å›¾åƒåˆ°æè´¨ã€ç»“æ„å¼•å¯¼ç”Ÿæˆå’Œæè´¨ç¼–è¾‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.09952v1">PDF</a> Accepted to SIGGRAPH Asia 2025. Project page:   <a target="_blank" rel="noopener" href="https://ubisoft-laforge.github.io/world/chord">https://ubisoft-laforge.github.io/world/chord</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¸¤é˜¶æ®µPBRæè´¨ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…æ‹¬ç”Ÿæˆé˜¶æ®µå’Œä¼°è®¡é˜¶æ®µã€‚ç”Ÿæˆé˜¶æ®µåˆ©ç”¨ç²¾ç»†è°ƒæ•´çš„æ‰©æ•£æ¨¡å‹åˆæˆä¸ç”¨æˆ·è¾“å…¥å¯¹é½çš„å¸¦é˜´å½±ã€å¯è´´å›¾çš„çº¹ç†å›¾åƒï¼›ä¼°è®¡é˜¶æ®µåˆ™é‡‡ç”¨é“¾å¼åˆ†è§£æ–¹æ¡ˆï¼Œé€šè¿‡å•æ¬¡å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹æŒ‰é¡ºåºé¢„æµ‹SVBRDFé€šé“ã€‚è¯¥æ–¹æ³•é«˜æ•ˆã€é«˜è´¨é‡ï¼Œå¯å®ç°çµæ´»çš„ç”¨æˆ·æ§åˆ¶ï¼Œå¹¶åœ¨å¤šç§åº”ç”¨åœºåˆä¸­å±•ç¤ºå‡ºè‰²æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ä¸¤é˜¶æ®µPBRæè´¨ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…æ‹¬ç”Ÿæˆå’Œä¼°è®¡ä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>ç”Ÿæˆé˜¶æ®µåˆ©ç”¨ç²¾ç»†è°ƒæ•´çš„æ‰©æ•£æ¨¡å‹åˆæˆå¸¦é˜´å½±ã€å¯è´´å›¾çš„çº¹ç†å›¾åƒï¼Œä¸ç”¨æˆ·è¾“å…¥å¯¹é½ã€‚</li>
<li>ä¼°è®¡é˜¶æ®µé‡‡ç”¨é“¾å¼åˆ†è§£æ–¹æ¡ˆï¼Œé€šè¿‡å•æ¬¡å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹æŒ‰é¡ºåºé¢„æµ‹SVBRDFé€šé“ã€‚</li>
<li>æ–¹æ³•é«˜æ•ˆã€é«˜è´¨é‡ï¼Œå¹¶å®ç°çµæ´»çš„ç”¨æˆ·æ§åˆ¶ã€‚</li>
<li>ä¸ç°æœ‰æè´¨ç”Ÿæˆå’Œä¼°è®¡æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>æè´¨ä¼°è®¡æ–¹æ³•å¯¹åˆæˆçº¹ç†å’ŒçœŸå®ç…§ç‰‡å‡è¡¨ç°å‡ºå¼ºå¤§ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.09952">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.09952v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.09952v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.09952v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2509.09952v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Just-Say-the-Word-Annotation-Free-Fine-Grained-Object-Counting"><a href="#Just-Say-the-Word-Annotation-Free-Fine-Grained-Object-Counting" class="headerlink" title="Just Say the Word: Annotation-Free Fine-Grained Object Counting"></a>Just Say the Word: Annotation-Free Fine-Grained Object Counting</h2><p><strong>Authors:Adriano Dâ€™Alessandro, Ali Mahdavi-Amiri, Ghassan Hamarneh</strong></p>
<p>Fine-grained object counting remains a major challenge for class-agnostic counting models, which overcount visually similar but incorrect instances (e.g., jalape~no vs. poblano). Addressing this by annotating new data and fully retraining the model is time-consuming and does not guarantee generalization to additional novel categories at test time. Instead, we propose an alternative paradigm: Given a category name, tune a compact concept embedding derived from the prompt using synthetic images and pseudo-labels generated by a text-to-image diffusion model. This embedding conditions a specialization module that refines raw overcounts from any frozen counter into accurate, category-specific estimates\textemdash without requiring real images or human annotations. We validate our approach on \textsc{Lookalikes}, a challenging new benchmark containing 1,037 images across 27 fine-grained subcategories, and show substantial improvements over strong baselines. Code will be released upon acceptance. Dataset - <a target="_blank" rel="noopener" href="https://dalessandro.dev/datasets/lookalikes/">https://dalessandro.dev/datasets/lookalikes/</a> </p>
<blockquote>
<p>ç²¾ç»†å¯¹è±¡è®¡æ•°ä»ç„¶æ˜¯é¢å‘ç±»åˆ«æ— å…³çš„è®¡æ•°æ¨¡å‹çš„ä¸»è¦æŒ‘æˆ˜ï¼Œè¿™äº›æ¨¡å‹ä¼šè¿‡åº¦è®¡ç®—è§†è§‰ä¸Šç›¸ä¼¼ä½†é”™è¯¯çš„å®ä¾‹ï¼ˆä¾‹å¦‚ï¼Œè¾£æ¤’ä¸æ³¢å¸ƒæ‹‰è¯ºè¾£æ¤’ï¼‰ã€‚é€šè¿‡æ ‡æ³¨æ–°æ•°æ®å¹¶å®Œå…¨é‡æ–°è®­ç»ƒæ¨¡å‹æ¥è§£å†³è¿™ä¸€é—®é¢˜æ˜¯éå¸¸è€—æ—¶çš„ï¼Œå¹¶ä¸”åœ¨æµ‹è¯•æ—¶å¹¶ä¸èƒ½ä¿è¯èƒ½å¤Ÿæ¨å¹¿åˆ°æ–°çš„ç±»åˆ«ã€‚ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼šç»™å®šä¸€ä¸ªç±»åˆ«åç§°ï¼Œä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆå›¾åƒå’Œä¼ªæ ‡ç­¾æ¥å¾®è°ƒç”±æç¤ºæ´¾ç”Ÿçš„ç´§å‡‘æ¦‚å¿µåµŒå…¥ã€‚è¿™ä¸ªåµŒå…¥æ¡ä»¶ä¼šä½œç”¨äºä¸€ä¸ªä¸“ä¸šæ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿå°†æ¥è‡ªä»»ä½•å†·å†»è®¡æ•°å™¨çš„åŸå§‹è¿‡åº¦è®¡æ•°è°ƒæ•´ä¸ºç²¾ç¡®ã€é’ˆå¯¹ç‰¹å®šç±»åˆ«çš„ä¼°è®¡å€¼â€”â€”è¿™ä¸éœ€è¦çœŸå®å›¾åƒæˆ–äººå·¥æ³¨é‡Šã€‚æˆ‘ä»¬åœ¨æ–°çš„æŒ‘æˆ˜åŸºå‡†æµ‹è¯•Lookalikesä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥åŸºå‡†æµ‹è¯•åŒ…å«æ¶‰åŠ27ä¸ªç²¾ç»†ç²’åº¦å­ç±»åˆ«çš„å…±1037å¼ å›¾åƒï¼Œå¹¶æ˜¾ç¤ºå‡ºç›¸å¯¹äºå¼ºå¤§åŸºå‡†çº¿çš„å®è´¨æ€§æ”¹è¿›ã€‚æ¥å—åå°†å‘å¸ƒä»£ç ã€‚æ•°æ®é›†ï¼š<a target="_blank" rel="noopener" href="https://dalessandro.dev/datasets/lookalikes/">https://dalessandro.dev/datasets/lookalikes/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11705v3">PDF</a> data - <a target="_blank" rel="noopener" href="https://dalessandro.dev/datasets/lookalikes/">https://dalessandro.dev/datasets/lookalikes/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–°å‹è®¡æ•°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç±»åˆ«åç§°ç”Ÿæˆåˆæˆå›¾åƒå’Œä¼ªæ ‡ç­¾ï¼Œæ„å»ºç´§å‡‘çš„æ¦‚å¿µåµŒå…¥ï¼Œç”¨äºè°ƒæ•´ç‰¹å®šç±»åˆ«çš„è®¡æ•°æ¨¡å—ã€‚è¯¥æ–¹æ³•å¯ä»¥åœ¨ä¸éœ€è¦çœŸå®å›¾åƒæˆ–äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå¯¹ä»»æ„å†»ç»“è®¡æ•°å™¨çš„ç²—ç•¥è®¡æ•°è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´ï¼Œç‰¹åˆ«é€‚ç”¨äºç²¾ç»†åˆ†ç±»çš„å›¾åƒè®¡æ•°æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç²¾ç»†åˆ†ç±»å¯¹è±¡è®¡æ•°æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ï¼Œç°æœ‰æ¨¡å‹å®¹æ˜“å¯¹è§†è§‰ä¸Šç›¸ä¼¼ä½†é”™è¯¯çš„å®ä¾‹è¿›è¡Œè¿‡åº¦è®¡æ•°ã€‚</li>
<li>æè®®çš„æ–¹æ³•åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆå›¾åƒå’Œä¼ªæ ‡ç­¾ï¼Œæ„å»ºæ¦‚å¿µåµŒå…¥ã€‚</li>
<li>ä½¿ç”¨è¯¥åµŒå…¥æ¥è®­ç»ƒç‰¹å®šç±»åˆ«çš„è®¡æ•°æ¨¡å—ï¼Œèƒ½å¤Ÿè°ƒæ•´åŸå§‹è®¡æ•°ï¼Œè·å¾—æ›´å‡†ç¡®çš„ä¼°è®¡ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸éœ€è¦çœŸå®å›¾åƒæˆ–äººå·¥æ ‡æ³¨ï¼Œä¸ºè®¡æ•°ä»»åŠ¡æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€æ³›åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°æ•°æ®é›†\textsc{Lookalikes}ï¼ŒåŒ…å«æ¶µç›–å¤šä¸ªç²¾ç»†åˆ†ç±»çš„å­ç±»åˆ«çš„å›¾åƒï¼Œå¯¹äºæ¨¡å‹éªŒè¯æ˜¯ä¸€ä¸ªé‡è¦èµ„æºã€‚</li>
<li>ä¸ç°æœ‰çš„å¼ºåŸºçº¿ç›¸æ¯”ï¼Œæ–°æ–¹æ³•åœ¨æ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11705">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2504.11705v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2504.11705v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2504.11705v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2504.11705v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2504.11705v3/page_4_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Can-Generative-Geospatial-Diffusion-Models-Excel-as-Discriminative-Geospatial-Foundation-Models"><a href="#Can-Generative-Geospatial-Diffusion-Models-Excel-as-Discriminative-Geospatial-Foundation-Models" class="headerlink" title="Can Generative Geospatial Diffusion Models Excel as Discriminative   Geospatial Foundation Models?"></a>Can Generative Geospatial Diffusion Models Excel as Discriminative   Geospatial Foundation Models?</h2><p><strong>Authors:Yuru Jia, Valerio Marsocci, Ziyang Gong, Xue Yang, Maarten Vergauwen, Andrea Nascetti</strong></p>
<p>Self-supervised learning (SSL) has revolutionized representation learning in Remote Sensing (RS), advancing Geospatial Foundation Models (GFMs) to leverage vast unlabeled satellite imagery for diverse downstream tasks. Currently, GFMs primarily employ objectives like contrastive learning or masked image modeling, owing to their proven success in learning transferable representations. However, generative diffusion models, which demonstrate the potential to capture multi-grained semantics essential for RS tasks during image generation, remain underexplored for discriminative applications. This prompts the question: can generative diffusion models also excel and serve as GFMs with sufficient discriminative power? In this work, we answer this question with SatDiFuser, a framework that transforms a diffusion-based generative geospatial foundation model into a powerful pretraining tool for discriminative RS. By systematically analyzing multi-stage, noise-dependent diffusion features, we develop three fusion strategies to effectively leverage these diverse representations. Extensive experiments on remote sensing benchmarks show that SatDiFuser outperforms state-of-the-art GFMs, achieving gains of up to +5.7% mIoU in semantic segmentation and +7.9% F1-score in classification, demonstrating the capacity of diffusion-based generative foundation models to rival or exceed discriminative GFMs. The source code is available at: <a target="_blank" rel="noopener" href="https://github.com/yurujaja/SatDiFuser">https://github.com/yurujaja/SatDiFuser</a>. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å·²ç»å½»åº•æ”¹å˜äº†é¥æ„Ÿï¼ˆRSï¼‰ä¸­çš„è¡¨ç¤ºå­¦ä¹ ï¼Œæ¨åŠ¨äº†åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGFMsï¼‰åˆ©ç”¨å¤§é‡æ— æ ‡ç­¾å«æ˜Ÿå›¾åƒç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚ç›®å‰ï¼ŒGFMsä¸»è¦ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æˆ–æ©è†œå›¾åƒå»ºæ¨¡ç­‰ç›®æ ‡ï¼Œå› ä¸ºå®ƒä»¬åœ¨å­¦ä¹ å¯è½¬ç§»è¡¨ç¤ºæ–¹é¢å–å¾—äº†æˆåŠŸçš„è¯æ˜ã€‚ç„¶è€Œï¼Œç”Ÿæˆæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­æ˜¾ç¤ºå‡ºæ•è·å¯¹é¥æ„Ÿä»»åŠ¡è‡³å…³é‡è¦çš„å¤šç²’åº¦è¯­ä¹‰çš„æ½œåŠ›ï¼Œä½†å¯¹äºåˆ¤åˆ«æ€§åº”ç”¨ä»ç„¶æ¢ç´¢ä¸è¶³ã€‚è¿™å¼•å‘äº†ä»¥ä¸‹é—®é¢˜ï¼šç”Ÿæˆæ‰©æ•£æ¨¡å‹æ˜¯å¦ä¹Ÿèƒ½è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä½œä¸ºå…·æœ‰è¶³å¤Ÿåˆ¤åˆ«åŠ›çš„GFMsï¼Ÿåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç”¨SatDiFuserå›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†åŸºäºæ‰©æ•£çš„ç”Ÿæˆåœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹è½¬åŒ–ä¸ºå¼ºå¤§çš„é¢„è®­ç»ƒå·¥å…·æ¡†æ¶ï¼Œç”¨äºåˆ¤åˆ«é¥æ„Ÿã€‚é€šè¿‡ç³»ç»Ÿåˆ†æå¤šé˜¶æ®µã€å™ªå£°ç›¸å…³çš„æ‰©æ•£ç‰¹å¾ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸‰ç§èåˆç­–ç•¥ï¼Œä»¥æœ‰æ•ˆåˆ©ç”¨è¿™äº›ä¸åŒçš„è¡¨ç¤ºå½¢å¼ã€‚åœ¨é¥æ„ŸåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSatDiFuserä¼˜äºæœ€æ–°GFMsï¼Œåœ¨è¯­ä¹‰åˆ†å‰²ä¸Šå®ç°äº†é«˜è¾¾+5.7%çš„mIoUæå‡ï¼Œåœ¨åˆ†ç±»ä¸Šå®ç°äº†+7.9%çš„F1åˆ†æ•°æå‡ï¼Œè¯æ˜äº†åŸºäºæ‰©æ•£çš„ç”ŸæˆåŸºç¡€æ¨¡å‹ä¸åˆ¤åˆ«GFMsç›¸åŒ¹æ•Œæˆ–è¶…è¶Šçš„èƒ½åŠ›ã€‚æºä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/yurujaja/SatDiFuser%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/yurujaja/SatDiFuserè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07890v2">PDF</a> ICCV 2025, camera ready</p>
<p><strong>Summary</strong>ï¼šè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰åœ¨é¥æ„Ÿé¢†åŸŸå¼•å‘äº†è¡¨å¾å­¦ä¹ çš„é©å‘½ï¼Œæ¨åŠ¨äº†åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹ï¼ˆGFMsï¼‰åˆ©ç”¨å¤§é‡æ— æ ‡ç­¾å«æ˜Ÿå›¾åƒè¿›è¡Œå„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚å½“å‰GFMsä¸»è¦ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æˆ–æ©è†œå›¾åƒå»ºæ¨¡ç­‰ç›®æ ‡ï¼Œè€Œç”Ÿæˆæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½å¤Ÿæ•æ‰é¥æ„Ÿä»»åŠ¡æ‰€éœ€çš„å¤šç²’åº¦è¯­ä¹‰ä¿¡æ¯ï¼Œä½†åœ¨åˆ¤åˆ«åº”ç”¨æ–¹é¢ä»è¢«ä½ä¼°ã€‚æœ¬ç ”ç©¶é€šè¿‡SatDiFuseræ¡†æ¶ï¼Œå°†åŸºäºæ‰©æ•£çš„ç”Ÿæˆå‹åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹è½¬åŒ–ä¸ºå¼ºå¤§çš„é¢„è®­ç»ƒå·¥å…·ï¼Œç”¨äºåˆ¤åˆ«é¥æ„Ÿã€‚é€šè¿‡ç³»ç»Ÿåˆ†æå¤šé˜¶æ®µå™ªå£°ç›¸å…³æ‰©æ•£ç‰¹å¾ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸‰ç§èåˆç­–ç•¥ï¼Œä»¥æœ‰æ•ˆåˆ©ç”¨è¿™äº›ä¸åŒçš„è¡¨ç¤ºã€‚åœ¨é¥æ„ŸåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSatDiFuserä¼˜äºæœ€æ–°GFMsï¼Œè¯­ä¹‰åˆ†å‰²çš„mIoUæé«˜äº†5.7%ï¼Œåˆ†ç±»çš„F1åˆ†æ•°æé«˜äº†7.9%ï¼Œè¯æ˜äº†æ‰©æ•£åŸºç¡€æ¨¡å‹çš„æ½œåŠ›å¯ä¸åˆ¤åˆ«GFMsç›¸æŠ—è¡¡æˆ–è¶…è¶Šã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªç›‘ç£å­¦ä¹ åœ¨é¥æ„Ÿé¢†åŸŸä¿ƒè¿›äº†åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œåˆ©ç”¨å¤§é‡æ— æ ‡ç­¾å«æ˜Ÿå›¾åƒè¿›è¡Œå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚</li>
<li>å½“å‰GFMsä¸»è¦åˆ©ç”¨å¯¹æ¯”å­¦ä¹ æˆ–æ©è†œå›¾åƒå»ºæ¨¡ç­‰æ–¹æ³•ã€‚</li>
<li>ç”Ÿæˆæ‰©æ•£æ¨¡å‹åœ¨æ•æ‰é¥æ„Ÿä»»åŠ¡æ‰€éœ€çš„å¤šç²’åº¦è¯­ä¹‰ä¿¡æ¯æ–¹é¢å…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨åˆ¤åˆ«åº”ç”¨æ–¹é¢å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>SatDiFuseræ¡†æ¶å°†åŸºäºæ‰©æ•£çš„ç”Ÿæˆå‹åœ°ç†ç©ºé—´åŸºç¡€æ¨¡å‹è½¬åŒ–ä¸ºå¼ºå¤§çš„é¢„è®­ç»ƒå·¥å…·ï¼Œç”¨äºåˆ¤åˆ«é¥æ„Ÿä»»åŠ¡ã€‚</li>
<li>é€šè¿‡ç³»ç»Ÿåˆ†æå¤šé˜¶æ®µå™ªå£°ç›¸å…³æ‰©æ•£ç‰¹å¾ï¼Œå¼€å‘äº†ä¸‰ç§èåˆç­–ç•¥ã€‚</li>
<li>åœ¨é¥æ„ŸåŸºå‡†æµ‹è¯•ä¸Šï¼ŒSatDiFuserè¡¨ç°å‡ºä¼˜äºç°æœ‰GFMsçš„æ€§èƒ½ï¼Œè¯­ä¹‰åˆ†å‰²å’Œåˆ†ç±»ä»»åŠ¡åˆ†åˆ«å®ç°äº†mIoUå’ŒF1åˆ†æ•°çš„æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07890">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2503.07890v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2503.07890v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2503.07890v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Your-Image-is-Secretly-the-Last-Frame-of-a-Pseudo-Video"><a href="#Your-Image-is-Secretly-the-Last-Frame-of-a-Pseudo-Video" class="headerlink" title="Your Image is Secretly the Last Frame of a Pseudo Video"></a>Your Image is Secretly the Last Frame of a Pseudo Video</h2><p><strong>Authors:Wenlong Chen, Wenlin Chen, Lapo Rastrelli, Yingzhen Li</strong></p>
<p>Diffusion models, which can be viewed as a special case of hierarchical variational autoencoders (HVAEs), have shown profound success in generating photo-realistic images. In contrast, standard HVAEs often produce images of inferior quality compared to diffusion models. In this paper, we hypothesize that the success of diffusion models can be partly attributed to the additional self-supervision information for their intermediate latent states provided by corrupted images, which along with the original image form a pseudo video. Based on this hypothesis, we explore the possibility of improving other types of generative models with such pseudo videos. Specifically, we first extend a given image generative model to their video generative model counterpart, and then train the video generative model on pseudo videos constructed by applying data augmentation to the original images. Furthermore, we analyze the potential issues of first-order Markov data augmentation methods, which are typically used in diffusion models, and propose to use more expressive data augmentation to construct more useful information in pseudo videos. Our empirical results on the CIFAR10 and CelebA datasets demonstrate that improved image generation quality can be achieved with additional self-supervised information from pseudo videos. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹å¯ä»¥çœ‹ä½œåˆ†å±‚å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆHVAEsï¼‰çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œåœ¨ç”Ÿæˆé€¼çœŸçš„å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ ‡å‡†çš„HVAEsäº§ç”Ÿçš„å›¾åƒè´¨é‡å¾€å¾€ä¸å¦‚æ‰©æ•£æ¨¡å‹ã€‚æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºæ‰©æ•£æ¨¡å‹çš„æˆåŠŸéƒ¨åˆ†å½’åŠŸäºç”±æŸåå›¾åƒæä¾›çš„ä¸­é—´æ½œåœ¨çŠ¶æ€çš„é¢å¤–è‡ªæˆ‘ç›‘ç£ä¿¡æ¯ï¼Œè¿™äº›ä¸åŸå§‹å›¾åƒä¸€èµ·å½¢æˆä¼ªè§†é¢‘ã€‚åŸºäºè¿™ä¸€å‡è®¾ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹æ˜¯å¦å¯ä»¥é€šè¿‡è¿™ç§ä¼ªè§†é¢‘è¿›è¡Œæ”¹è¿›çš„å¯èƒ½æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå°†ä»ç»™å®šçš„å›¾åƒç”Ÿæˆæ¨¡å‹æ‰©å±•åˆ°å…¶å¯¹åº”çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œç„¶ååœ¨é€šè¿‡åŸå§‹å›¾åƒçš„æ•°æ®å¢å¼ºæ„å»ºä¼ªè§†é¢‘çš„åŸºç¡€ä¸Šå¯¹è§†é¢‘ç”Ÿæˆæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†æ‰©æ•£æ¨¡å‹ä¸­å¸¸ç”¨çš„ä¸€é˜¶é©¬å°”å¯å¤«æ•°æ®å¢å¼ºæ–¹æ³•çš„æ½œåœ¨é—®é¢˜ï¼Œå¹¶æå‡ºä½¿ç”¨æ›´å…·è¡¨ç°åŠ›çš„æ•°æ®å¢å¼ºæ–¹æ³•åœ¨ä¼ªè§†é¢‘ä¸­æ„å»ºæ›´æœ‰ç”¨çš„ä¿¡æ¯ã€‚æˆ‘ä»¬åœ¨CIFAR10å’ŒCelebAæ•°æ®é›†ä¸Šçš„å®è¯ç»“æœè¡¨æ˜ï¼Œé€šè¿‡æ¥è‡ªä¼ªè§†é¢‘çš„é¢å¤–è‡ªæˆ‘ç›‘ç£ä¿¡æ¯å¯ä»¥å®ç°æ”¹è¿›çš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.20158v3">PDF</a> Presented at the ICLR 2025 Workshop on Deep Generative Model in   Machine Learning: Theory, Principle and Efficacy (DeLTa). 1-frame results for   CIFAR10 in Table 2 corrected. Code released</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ‰©æ•£æ¨¡å‹ï¼ˆä½œä¸ºåˆ†å±‚å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆHVAEsï¼‰çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼‰åœ¨ç”Ÿæˆé€¼çœŸå›¾åƒæ–¹é¢çš„æˆåŠŸï¼Œå¹¶æå‡ºå…¶éƒ¨åˆ†åŸå› åœ¨äºé€šè¿‡æŸåå›¾åƒæä¾›çš„ä¸­é—´æ½œåœ¨çŠ¶æ€çš„é¢å¤–è‡ªæˆ‘ç›‘ç£ä¿¡æ¯ï¼Œè¿™äº›ä¸åŸå§‹å›¾åƒä¸€èµ·å½¢æˆä¼ªè§†é¢‘ã€‚åŸºäºæ­¤å‡è®¾ï¼Œæ–‡ç« æ¢è®¨äº†å°†è¿™ç§ä¼ªè§†é¢‘åº”ç”¨äºå…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹ä»¥æé«˜å›¾åƒç”Ÿæˆè´¨é‡çš„å¯è¡Œæ€§ã€‚é€šè¿‡æ‰©å±•ç°æœ‰å›¾åƒç”Ÿæˆæ¨¡å‹ä¸ºè§†é¢‘ç”Ÿæˆæ¨¡å‹å¯¹åº”ç‰©ï¼Œå¹¶ä½¿ç”¨åŸå§‹å›¾åƒçš„æ•°æ®å¢å¼ºæ„å»ºä¼ªè§†é¢‘æ¥è®­ç»ƒè§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæ–‡ç« åˆ†æäº†æ‰©æ•£æ¨¡å‹ä¸­å¸¸ç”¨çš„ä¸€é˜¶é©¬å°”å¯å¤«æ•°æ®å¢å¼ºæ–¹æ³•çš„æ½œåœ¨é—®é¢˜ï¼Œå¹¶æå‡ºä½¿ç”¨æ›´å…·è¡¨ç°åŠ›çš„æ•°æ®å¢å¼ºæ¥æ„å»ºä¼ªè§†é¢‘ä¸­æ›´æœ‰ç”¨çš„ä¿¡æ¯ã€‚åœ¨CIFAR10å’ŒCelebAæ•°æ®é›†ä¸Šçš„å®è¯ç»“æœè¡¨æ˜ï¼Œé€šè¿‡ä¼ªè§†é¢‘çš„é¢å¤–è‡ªæˆ‘ç›‘ç£ä¿¡æ¯å¯ä»¥æé«˜å›¾åƒç”Ÿæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„é€¼çœŸå›¾åƒï¼Œå…¶æˆåŠŸéƒ¨åˆ†å½’å› äºé€šè¿‡æŸåå›¾åƒæä¾›çš„é¢å¤–è‡ªæˆ‘ç›‘ç£ä¿¡æ¯ã€‚</li>
<li>è¿™ç§è‡ªæˆ‘ç›‘ç£ä¿¡æ¯ä¸ºæ‰©æ•£æ¨¡å‹çš„ä¸­é—´æ½œåœ¨çŠ¶æ€æä¾›äº†é™„åŠ ä¿¡æ¯ï¼Œä¸åŸå§‹å›¾åƒç»“åˆå½¢æˆä¼ªè§†é¢‘ã€‚</li>
<li>æ–‡ç« æ¢è®¨äº†å°†è¿™ç§ä¼ªè§†é¢‘åº”ç”¨äºå…¶ä»–ç”Ÿæˆæ¨¡å‹çš„å¯è¡Œæ€§ï¼Œä»¥æé«˜å›¾åƒç”Ÿæˆè´¨é‡ã€‚</li>
<li>é€šè¿‡å°†å›¾åƒç”Ÿæˆæ¨¡å‹æ‰©å±•åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹å¹¶ä½¿ç”¨æ•°æ®å¢å¼ºæ„å»ºä¼ªè§†é¢‘æ¥è®­ç»ƒè¯¥æ¨¡å‹ã€‚</li>
<li>æ–‡ç« æŒ‡å‡ºäº†ä½¿ç”¨ä¸€é˜¶é©¬å°”å¯å¤«æ•°æ®å¢å¼ºæ–¹æ³•çš„æ½œåœ¨é—®é¢˜ï¼Œå¹¶æå€¡ä½¿ç”¨æ›´å…·è¡¨ç°åŠ›çš„æ•°æ®å¢å¼ºæ–¹æ³•ã€‚</li>
<li>å®è¯ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä¼ªè§†é¢‘çš„è‡ªæˆ‘ç›‘ç£ä¿¡æ¯èƒ½å¤Ÿæ”¹è¿›å›¾åƒç”Ÿæˆè´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.20158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2410.20158v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2410.20158v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2410.20158v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Diffusion Models/2410.20158v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-16/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-16/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_åŒ»å­¦å›¾åƒ/2509.10098v1/page_2_1.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-16  Joint X-ray, kinetic Sunyaev-Zeldovich, and weak lensing measurements   toward a consensus picture of efficient gas expulsion from groups and   clusters
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-16/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-16\./crop_Face Swapping/2509.10409v1/page_5_1.jpg" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-16  Optimizing Inter-chip Coupler Link Placement for Modular and Chiplet   Quantum Systems
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
