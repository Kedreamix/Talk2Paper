<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-09  Efficient Flow Matching using Latent Variables">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-de804d728ada58b8fa4a97244451761d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-09-æ›´æ–°"><a href="#2025-05-09-æ›´æ–°" class="headerlink" title="2025-05-09 æ›´æ–°"></a>2025-05-09 æ›´æ–°</h1><h2 id="Efficient-Flow-Matching-using-Latent-Variables"><a href="#Efficient-Flow-Matching-using-Latent-Variables" class="headerlink" title="Efficient Flow Matching using Latent Variables"></a>Efficient Flow Matching using Latent Variables</h2><p><strong>Authors:Anirban Samaddar, Yixuan Sun, Viktor Nilsson, Sandeep Madireddy</strong></p>
<p>Flow matching models have shown great potential in image generation tasks among probabilistic generative models. Building upon the ideas of continuous normalizing flows, flow matching models generalize the transport path of the diffusion models from a simple prior distribution to the data. Most flow matching models in the literature do not explicitly model the underlying structure&#x2F;manifold in the target data when learning the flow from a simple source distribution like the standard Gaussian. This leads to inefficient learning, especially for many high-dimensional real-world datasets, which often reside in a low-dimensional manifold. Existing strategies of incorporating manifolds, including data with underlying multi-modal distribution, often require expensive training and hence frequently lead to suboptimal performance. To this end, we present \texttt{Latent-CFM}, which provides simplified training&#x2F;inference strategies to incorporate multi-modal data structures using pretrained deep latent variable models. Through experiments on multi-modal synthetic data and widely used image benchmark datasets, we show that \texttt{Latent-CFM} exhibits improved generation quality with significantly less training ($\sim 50%$ less in some cases) and computation than state-of-the-art flow matching models. Using a 2d Darcy flow dataset, we demonstrate that our approach generates more physically accurate samples than competitive approaches. In addition, through latent space analysis, we demonstrate that our approach can be used for conditional image generation conditioned on latent features. </p>
<blockquote>
<p>æµä½“åŒ¹é…æ¨¡å‹åœ¨æ¦‚ç‡ç”Ÿæˆæ¨¡å‹ä¸­çš„å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚åŸºäºè¿ç»­å½’ä¸€åŒ–æµçš„æ€æƒ³ï¼Œæµä½“åŒ¹é…æ¨¡å‹å°†æ‰©æ•£æ¨¡å‹çš„ä¼ è¾“è·¯å¾„ä»ç®€å•çš„å…ˆéªŒåˆ†å¸ƒæ¨å¹¿åˆ°æ•°æ®ã€‚æ–‡çŒ®ä¸­çš„å¤§å¤šæ•°æµä½“åŒ¹é…æ¨¡å‹åœ¨å­¦ä¹ ä»æ ‡å‡†é«˜æ–¯ç­‰ç®€å•æºåˆ†å¸ƒåˆ°ç›®æ ‡çš„æµä½“æ—¶ï¼Œå¹¶æ²¡æœ‰æ˜¾å¼åœ°å»ºæ¨¡ç›®æ ‡æ•°æ®çš„åº•å±‚ç»“æ„&#x2F;æµå½¢ã€‚è¿™å¯¼è‡´äº†å­¦ä¹ çš„ä¸é«˜æ•ˆï¼Œç‰¹åˆ«æ˜¯å¯¹äºè®¸å¤šé«˜ç»´çš„ç°å®ä¸–ç•Œæ•°æ®é›†ï¼Œå®ƒä»¬ç»å¸¸å±…ä½åœ¨ä½ç»´æµå½¢ä¸­ã€‚ç°æœ‰çš„ç»“åˆæµå½¢çš„ç­–ç•¥ï¼ŒåŒ…æ‹¬å…·æœ‰æ½œåœ¨å¤šå…ƒåˆ†å¸ƒçš„æ•°æ®ï¼Œé€šå¸¸éœ€è¦æ˜‚è´µçš„è®­ç»ƒæˆæœ¬ï¼Œå› æ­¤ç»å¸¸å¯¼è‡´æ¬¡ä¼˜æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†â€œæ½œåœ¨CFMâ€ï¼Œå®ƒæä¾›äº†ç®€åŒ–çš„è®­ç»ƒ&#x2F;æ¨ç†ç­–ç•¥ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ·±åº¦æ½œåœ¨å˜é‡æ¨¡å‹æ¥ç»“åˆå¤šæ¨¡æ€æ•°æ®ç»“æ„ã€‚é€šè¿‡å¯¹å¤šæ¨¡æ€åˆæˆæ•°æ®å’Œå¹¿æ³›ä½¿ç”¨çš„å›¾åƒåŸºå‡†æ•°æ®é›†è¿›è¡Œå®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†â€œæ½œåœ¨CFMâ€åœ¨ç”Ÿæˆè´¨é‡ä¸Šçš„æé«˜ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒé‡å’Œè®¡ç®—é‡ä¸Šå¤§å¤§å‡å°‘äº†ï¼ˆåœ¨æŸäº›æƒ…å†µä¸‹å‡å°‘äº†çº¦50%ï¼‰ç›¸æ¯”äºæœ€å…ˆè¿›çš„æµä½“åŒ¹é…æ¨¡å‹ã€‚ä½¿ç”¨äºŒç»´è¾¾è¥¿æµæ•°æ®é›†ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„æ ·æœ¬æ¯”ç«äº‰æ–¹æ³•æ›´å…·æœ‰ç‰©ç†å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ½œåœ¨ç©ºé—´åˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ç”¨äºåŸºäºæ½œåœ¨ç‰¹å¾çš„æ¡ä»¶å›¾åƒç”Ÿæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04486v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æµåŒ¹é…æ¨¡å‹åœ¨æ¦‚ç‡ç”Ÿæˆæ¨¡å‹ä¸­åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚åŸºäºè¿ç»­å½’ä¸€åŒ–æµçš„æ€æƒ³ï¼ŒæµåŒ¹é…æ¨¡å‹å°†æ•°æ®ä»ç®€å•å…ˆéªŒåˆ†å¸ƒæ¨å¹¿åˆ°æ‰©æ•£æ¨¡å‹çš„ä¼ è¾“è·¯å¾„ã€‚ç°æœ‰æ–‡çŒ®ä¸­çš„å¤§å¤šæ•°æµåŒ¹é…æ¨¡å‹åœ¨å­¦ä¹ ä»ç®€å•æºåˆ†å¸ƒï¼ˆå¦‚æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼‰å¼€å§‹çš„æµæ—¶ï¼Œå¹¶æ²¡æœ‰æ˜¾å¼åœ°å»ºæ¨¡ç›®æ ‡æ•°æ®çš„åº•å±‚ç»“æ„&#x2F;æµå½¢ã€‚è¿™å¯¼è‡´äº†å¯¹è®¸å¤šé«˜ç»´ç°å®æ•°æ®é›†çš„æ— æ•ˆå­¦ä¹ ï¼Œå°¤å…¶æ˜¯é‚£äº›ç»å¸¸å¤„äºä½ç»´æµå½¢ä¸­çš„æ•°æ®é›†ã€‚å°½ç®¡ç°æœ‰çš„ç»“åˆæµå½¢ç­–ç•¥åŒ…æ‹¬å…·æœ‰æ½œåœ¨å¤šæ¨¡æ€åˆ†å¸ƒçš„æ•°æ®ï¼Œä½†å…¶è®­ç»ƒæˆæœ¬é«˜æ˜‚ä¸”ç»å¸¸å¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé¢„è®­ç»ƒçš„æ·±åº¦æ½œåœ¨å˜é‡æ¨¡å‹çš„â€œLatent-CFMâ€ï¼Œå®ƒå¯ä»¥é€šè¿‡ç®€åŒ–è®­ç»ƒå’Œæ¨ç†ç­–ç•¥æ¥ç»“åˆå¤šæ¨¡æ€æ•°æ®ç»“æ„ã€‚é€šè¿‡å®éªŒè¡¨æ˜ï¼ŒLatent-CFMåœ¨ç”Ÿæˆè´¨é‡ä¸Šæœ‰æ‰€æå‡ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹è®­ç»ƒæ—¶é—´å‡å°‘äº†çº¦ä¸€åŠï¼Œè®¡ç®—æ•ˆç‡ä¹Ÿæ˜¾è‘—æé«˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜èƒ½ç”¨äºåŸºäºæ½œåœ¨ç‰¹å¾çš„æ¡ä»¶å›¾åƒç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æµåŒ¹é…æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>æµåŒ¹é…æ¨¡å‹åŸºäºè¿ç»­å½’ä¸€åŒ–æµæ¨å¹¿æ•°æ®ä¼ è¾“è·¯å¾„ã€‚</li>
<li>ç°æœ‰æµåŒ¹é…æ¨¡å‹æœªæ˜¾å¼å»ºæ¨¡ç›®æ ‡æ•°æ®çš„åº•å±‚ç»“æ„ï¼Œå¯¼è‡´å¯¹é«˜ç»´ç°å®æ•°æ®é›†çš„å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚</li>
<li>Latent-CFMé€šè¿‡ç®€åŒ–è®­ç»ƒå’Œæ¨ç†ç­–ç•¥ï¼Œèƒ½å¤Ÿç»“åˆå¤šæ¨¡æ€æ•°æ®ç»“æ„ã€‚</li>
<li>Latent-CFMæé«˜äº†ç”Ÿæˆè´¨é‡ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬ã€‚</li>
<li>Latent-CFMåœ¨ç‰©ç†æ ·æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºæ›´å‡†ç¡®çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04486">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1af039e694d9960d94c8d7f5dd208133.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-830c52f8cad95b8a4cefd06af99e3cb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90ce1230cc7e61483e4156bbd8a79f3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a26bcb5af701278146d790add613e39d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CountDiffusion-Text-to-Image-Synthesis-with-Training-Free-Counting-Guidance-Diffusion"><a href="#CountDiffusion-Text-to-Image-Synthesis-with-Training-Free-Counting-Guidance-Diffusion" class="headerlink" title="CountDiffusion: Text-to-Image Synthesis with Training-Free   Counting-Guidance Diffusion"></a>CountDiffusion: Text-to-Image Synthesis with Training-Free   Counting-Guidance Diffusion</h2><p><strong>Authors:Yanyu Li, Pencheng Wan, Liang Han, Yaowei Wang, Liqiang Nie, Min Zhang</strong></p>
<p>Stable Diffusion has advanced text-to-image synthesis, but training models to generate images with accurate object quantity is still difficult due to the high computational cost and the challenge of teaching models the abstract concept of quantity. In this paper, we propose CountDiffusion, a training-free framework aiming at generating images with correct object quantity from textual descriptions. CountDiffusion consists of two stages. In the first stage, an intermediate denoising result is generated by the diffusion model to predict the final synthesized image with one-step denoising, and a counting model is used to count the number of objects in this image. In the second stage, a correction module is used to correct the object quantity by changing the attention map of the object with universal guidance. The proposed CountDiffusion can be plugged into any diffusion-based text-to-image (T2I) generation models without further training. Experiment results demonstrate the superiority of our proposed CountDiffusion, which improves the accurate object quantity generation ability of T2I models by a large margin. </p>
<blockquote>
<p>Stable Diffusionå·²ç»å®ç°äº†å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒåˆæˆæŠ€æœ¯ï¼Œä½†ç”±äºè®¡ç®—æˆæœ¬é«˜æ˜‚ä»¥åŠæ•™æˆæ¨¡å‹ç†è§£æ•°é‡è¿™ä¸€æŠ½è±¡æ¦‚å¿µå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè®­ç»ƒæ¨¡å‹ä»¥ç”Ÿæˆå…·æœ‰å‡†ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒä»ç„¶å¾ˆå›°éš¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†CountDiffusionï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒå³å¯ç”Ÿæˆæ­£ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒçš„ç›®æ ‡æ¡†æ¶ã€‚CountDiffusionåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸­é—´å»å™ªç»“æœï¼Œä»¥é€šè¿‡ä¸€æ­¥å»å™ªé¢„æµ‹æœ€ç»ˆçš„åˆæˆå›¾åƒï¼Œå¹¶ä½¿ç”¨è®¡æ•°æ¨¡å‹è®¡ç®—å›¾åƒä¸­çš„å¯¹è±¡æ•°é‡ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨æ ¡æ­£æ¨¡å—é€šè¿‡æ”¹å˜å¯¹è±¡çš„æ³¨æ„åŠ›å›¾è¿›è¡Œé€šç”¨æŒ‡å¯¼æ¥æ ¡æ­£å¯¹è±¡æ•°é‡ã€‚æ‰€æå‡ºçš„CountDiffusionå¯ä»¥æ’å…¥ä»»ä½•åŸºäºæ‰©æ•£çš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ç”Ÿæˆæ¨¡å‹ä¸­è€Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„CountDiffusionå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤§å¹…åº¦æé«˜T2Iæ¨¡å‹ç”Ÿæˆå‡†ç¡®å¯¹è±¡æ•°é‡çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04347v1">PDF</a> 8 pages, 9 figures, 3 tables</p>
<p><strong>Summary</strong></p>
<p>ç¨³å®šæ‰©æ•£å·²æå‡äº†æ–‡æœ¬åˆ°å›¾åƒçš„åˆæˆæŠ€æœ¯ï¼Œä½†ç”Ÿæˆå…·æœ‰å‡†ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒä»å­˜åœ¨å›°éš¾ï¼Œå› æ¶‰åŠé«˜è®¡ç®—æˆæœ¬åŠæ•™æˆæ¨¡å‹æŠ½è±¡æ•°é‡æ¦‚å¿µçš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºCountDiffusionï¼Œä¸€ç§æ— éœ€è®­ç»ƒã€æ—¨åœ¨ä»æ–‡æœ¬æè¿°ç”Ÿæˆå…·æœ‰æ­£ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒæ¡†æ¶ã€‚CountDiffusionåˆ†ä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸­é—´å»å™ªç»“æœï¼Œé€šè¿‡ä¸€æ­¥å»å™ªé¢„æµ‹æœ€ç»ˆåˆæˆå›¾åƒï¼Œå¹¶åˆ©ç”¨è®¡æ•°æ¨¡å‹è®¡ç®—å›¾åƒä¸­å¯¹è±¡çš„æ•°é‡ã€‚ç¬¬äºŒé˜¶æ®µé‡‡ç”¨æ ¡æ­£æ¨¡å—ï¼Œé€šè¿‡æ”¹å˜å¯¹è±¡çš„æ³¨æ„åŠ›å›¾è¿›è¡Œé€šç”¨æŒ‡å¯¼ï¼Œä»¥æ ¡æ­£å¯¹è±¡æ•°é‡ã€‚CountDiffusionå¯æ— ç¼é›†æˆä»»ä½•åŸºäºæ‰©æ•£çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCountDiffusionå¤§å¹…æå‡äº†æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å‡†ç¡®å¯¹è±¡æ•°é‡ç”Ÿæˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¨³å®šæ‰©æ•£è™½å·²æå‡æ–‡æœ¬åˆ°å›¾åƒçš„åˆæˆæŠ€æœ¯ï¼Œä½†ç”Ÿæˆå…·æœ‰å‡†ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒä»ç„¶å…·æœ‰æŒ‘æˆ˜ã€‚</li>
<li>CountDiffusionæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œå¯ä»æ–‡æœ¬æè¿°ç”Ÿæˆå…·æœ‰æ­£ç¡®å¯¹è±¡æ•°é‡çš„å›¾åƒã€‚</li>
<li>CountDiffusionåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µé¢„æµ‹å›¾åƒå¹¶è®¡ç®—å¯¹è±¡æ•°é‡ï¼Œç¬¬äºŒé˜¶æ®µæ ¡æ­£å¯¹è±¡æ•°é‡ã€‚</li>
<li>CountDiffusionå¯æ— ç¼é›†æˆåˆ°ä»»ä½•æ‰©æ•£åŸºç¡€çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ã€‚</li>
<li>CountDiffusioné€šè¿‡æ”¹å˜å¯¹è±¡çš„æ³¨æ„åŠ›å›¾è¿›è¡Œé€šç”¨æŒ‡å¯¼ä»¥æ ¡æ­£å¯¹è±¡æ•°é‡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜CountDiffusionæ˜¾è‘—æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å‡†ç¡®å¯¹è±¡æ•°é‡ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•é¢å¯¹çš„æŒ‘æˆ˜åŒ…æ‹¬é«˜è®¡ç®—æˆæœ¬å’Œæ•™æˆæ¨¡å‹æŠ½è±¡æ•°é‡æ¦‚å¿µçš„å›°éš¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04347">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-851d1b1a21c2aeea5dce2bd7f6fb9e98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20c58d51d38062902f0153e89a79a4b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f865d89608174b6488f53229f6863d73.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77a91e3def149e958df452124849708d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8895e4dd82e8e902e13a6ecf57f8e0ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-649f403c50bd4b6ca4078e5d656b67a6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="TS-Diff-Two-Stage-Diffusion-Model-for-Low-Light-RAW-Image-Enhancement"><a href="#TS-Diff-Two-Stage-Diffusion-Model-for-Low-Light-RAW-Image-Enhancement" class="headerlink" title="TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement"></a>TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement</h2><p><strong>Authors:Yi Li, Zhiyuan Zhang, Jiangnan Xia, Jianghan Cheng, Qilong Wu, Junwei Li, Yibin Tian, Hui Kong</strong></p>
<p>This paper presents a novel Two-Stage Diffusion Model (TS-Diff) for enhancing extremely low-light RAW images. In the pre-training stage, TS-Diff synthesizes noisy images by constructing multiple virtual cameras based on a noise space. Camera Feature Integration (CFI) modules are then designed to enable the model to learn generalizable features across diverse virtual cameras. During the aligning stage, CFIs are averaged to create a target-specific CFI$^T$, which is fine-tuned using a small amount of real RAW data to adapt to the noise characteristics of specific cameras. A structural reparameterization technique further simplifies CFI$^T$ for efficient deployment. To address color shifts during the diffusion process, a color corrector is introduced to ensure color consistency by dynamically adjusting global color distributions. Additionally, a novel dataset, QID, is constructed, featuring quantifiable illumination levels and a wide dynamic range, providing a comprehensive benchmark for training and evaluation under extreme low-light conditions. Experimental results demonstrate that TS-Diff achieves state-of-the-art performance on multiple datasets, including QID, SID, and ELD, excelling in denoising, generalization, and color consistency across various cameras and illumination levels. These findings highlight the robustness and versatility of TS-Diff, making it a practical solution for low-light imaging applications. Source codes and models are available at <a target="_blank" rel="noopener" href="https://github.com/CircccleK/TS-Diff">https://github.com/CircccleK/TS-Diff</a> </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µæ‰©æ•£æ¨¡å‹ï¼ˆTS-Diffï¼‰ï¼Œç”¨äºå¢å¼ºæä½å…‰ç…§çš„RAWå›¾åƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒTS-Diffé€šè¿‡æ„å»ºåŸºäºå™ªå£°ç©ºé—´çš„å¤šä¸ªè™šæ‹Ÿç›¸æœºæ¥åˆæˆå™ªå£°å›¾åƒã€‚éšåè®¾è®¡äº†ç›¸æœºç‰¹å¾èåˆï¼ˆCFIï¼‰æ¨¡å—ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§è™šæ‹Ÿç›¸æœºä¸Šå­¦ä¹ å¯æ¨å¹¿çš„ç‰¹å¾ã€‚åœ¨å¯¹é½é˜¶æ®µï¼ŒCFIsè¢«å¹³å‡åŒ–ä»¥åˆ›å»ºç›®æ ‡ç‰¹å®šçš„CFI$^T$ï¼Œå¹¶ä½¿ç”¨å°‘é‡çœŸå®RAWæ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šç›¸æœºçš„å™ªå£°ç‰¹æ€§ã€‚ä¸€ç§ç»“æ„å†å‚æ•°åŒ–æŠ€æœ¯è¿›ä¸€æ­¥ç®€åŒ–äº†CFI$^T$ï¼Œä»¥ä¾¿æœ‰æ•ˆéƒ¨ç½²ã€‚ä¸ºäº†è§£å†³æ‰©æ•£è¿‡ç¨‹ä¸­çš„é¢œè‰²åç§»é—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ç§é¢œè‰²æ ¡æ­£å™¨ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´å…¨å±€é¢œè‰²åˆ†å¸ƒæ¥ç¡®ä¿é¢œè‰²ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æ„å»ºäº†ä¸€ä¸ªæ–°å‹æ•°æ®é›†QIDï¼Œå…·æœ‰å¯é‡åŒ–çš„ç…§æ˜æ°´å¹³å’Œå®½åŠ¨æ€èŒƒå›´ï¼Œä¸ºæç«¯ä½å…‰ç…§æ¡ä»¶ä¸‹çš„è®­ç»ƒå’Œè¯„ä¼°æä¾›äº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTS-Diffåœ¨å¤šæ•°æ®é›†ï¼ˆåŒ…æ‹¬QIDã€SIDå’ŒELDï¼‰ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œåœ¨é™å™ªã€é€šç”¨æ€§å’Œè·¨ä¸åŒç›¸æœºå’Œå…‰ç…§çº§åˆ«çš„é¢œè‰²ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è¿™äº›å‘ç°çªå‡ºäº†TS-Diffçš„ç¨³å¥æ€§å’Œå¤šåŠŸèƒ½æ€§ï¼Œä½¿å…¶æˆä¸ºä½å…‰æˆåƒåº”ç”¨çš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚ç›¸å…³æºä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/CircccleK/TS-Diff">https://github.com/CircccleK/TS-Diff</a> è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.04281v1">PDF</a> International Joint Conference on Neural Networks (IJCNN)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µæ‰©æ•£æ¨¡å‹ï¼ˆTS-Diffï¼‰ï¼Œç”¨äºå¢å¼ºæä½å…‰ç…§ä¸‹çš„RAWå›¾åƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒTS-Diffé€šè¿‡æ„å»ºå¤šä¸ªåŸºäºå™ªå£°ç©ºé—´çš„è™šæ‹Ÿç›¸æœºåˆæˆå™ªå£°å›¾åƒã€‚è®¾è®¡äº†ç›¸æœºç‰¹å¾èåˆï¼ˆCFIï¼‰æ¨¡å—ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„è™šæ‹Ÿç›¸æœºä¸Šå­¦ä¹ é€šç”¨ç‰¹å¾ã€‚åœ¨è°ƒæ•´é˜¶æ®µï¼ŒCFIsç»è¿‡å¹³å‡åŒ–å¤„ç†ä»¥åˆ›å»ºç›®æ ‡ç‰¹å®šçš„CFI^Tï¼Œå¹¶ä½¿ç”¨å°‘é‡çœŸå®RAWæ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šç›¸æœºçš„å™ªå£°ç‰¹æ€§ã€‚é€šè¿‡ç»“æ„å†å‚æ•°åŒ–æŠ€æœ¯è¿›ä¸€æ­¥ç®€åŒ–CFI^Tï¼Œä»¥ä¾¿æœ‰æ•ˆéƒ¨ç½²ã€‚ä¸ºè§£å†³æ‰©æ•£è¿‡ç¨‹ä¸­çš„è‰²å½©åç§»é—®é¢˜ï¼Œå¼•å…¥äº†è‰²å½©æ ¡æ­£å™¨ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´å…¨å±€è‰²å½©åˆ†å¸ƒæ¥ç¡®ä¿è‰²å½©ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æ„å»ºäº†ä¸€ä¸ªæ–°å‹æ•°æ®é›†QIDï¼Œå…·æœ‰å¯é‡åŒ–çš„ç…§æ˜æ°´å¹³å’Œå®½åŠ¨æ€èŒƒå›´ï¼Œä¸ºæç«¯ä½å…‰ç…§æ¡ä»¶ä¸‹çš„è®­ç»ƒå’Œè¯„ä¼°æä¾›äº†å…¨é¢çš„åŸºå‡†ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTS-Diffåœ¨å¤šä¸ªæ•°æ®é›†ï¼ˆåŒ…æ‹¬QIDã€SIDå’ŒELDï¼‰ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨é™å™ªã€é€šç”¨æ€§å’Œè‰²å½©ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œé€‚ç”¨äºå„ç§ç›¸æœºå’Œå…‰ç…§æ°´å¹³ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>TS-Diffæ¨¡å‹é€šè¿‡æ„å»ºè™šæ‹Ÿç›¸æœºåˆæˆå™ªå£°å›¾åƒï¼Œä¸ºæä½å…‰ç…§ä¸‹çš„RAWå›¾åƒå¢å¼ºæä¾›äº†æ–°æ–¹æ³•ã€‚</li>
<li>å¼•å…¥ç›¸æœºç‰¹å¾èåˆï¼ˆCFIï¼‰æ¨¡å—ï¼Œä½¿æ¨¡å‹èƒ½åœ¨ä¸åŒçš„è™šæ‹Ÿç›¸æœºä¸Šå­¦ä¹ é€šç”¨ç‰¹å¾ã€‚</li>
<li>é€šè¿‡åˆ›å»ºç›®æ ‡ç‰¹å®šçš„CFI^Tå¹¶å¾®è°ƒï¼Œæ¨¡å‹èƒ½é€‚åº”ç‰¹å®šç›¸æœºçš„å™ªå£°ç‰¹æ€§ã€‚</li>
<li>ç»“æ„å†å‚æ•°åŒ–æŠ€æœ¯ç®€åŒ–äº†CFI^Tçš„éƒ¨ç½²ã€‚</li>
<li>å¼•å…¥è‰²å½©æ ¡æ­£å™¨æ¥è§£å†³æ‰©æ•£è¿‡ç¨‹ä¸­çš„è‰²å½©åç§»é—®é¢˜ï¼Œç¡®ä¿è‰²å½©ä¸€è‡´æ€§ã€‚</li>
<li>æ–°å‹æ•°æ®é›†QIDçš„æ„å»ºä¸ºæç«¯ä½å…‰ç…§æ¡ä»¶ä¸‹çš„è®­ç»ƒå’Œè¯„ä¼°æä¾›äº†åŸºå‡†ã€‚</li>
<li>TS-Diffåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨é™å™ªã€é€šç”¨æ€§å’Œè‰²å½©ä¸€è‡´æ€§æ–¹é¢è¡¨ç°çªå‡ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.04281">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ea664589c338e4de673d7da9f3b9ad8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5650b5d018c0a9f982929d2ccdc5170.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6169a0f2068e61453e296091bf0eecab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-43c4f8ae4bdb7cc37ca7e8f6c53f8afb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f3db9ddd9821a6a9808992ed986cd88.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6073e4edd7b7b98722fce716c0d7950c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7816f58b1588cba03dded873ec5c4a5.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Ming-Lite-Uni-Advancements-in-Unified-Architecture-for-Natural-Multimodal-Interaction"><a href="#Ming-Lite-Uni-Advancements-in-Unified-Architecture-for-Natural-Multimodal-Interaction" class="headerlink" title="Ming-Lite-Uni: Advancements in Unified Architecture for Natural   Multimodal Interaction"></a>Ming-Lite-Uni: Advancements in Unified Architecture for Natural   Multimodal Interaction</h2><p><strong>Authors:Inclusion AI, Biao Gong, Cheng Zou, Dandan Zheng, Hu Yu, Jingdong Chen, Jianxin Sun, Junbo Zhao, Jun Zhou, Kaixiang Ji, Lixiang Ru, Libin Wang, Qingpei Guo, Rui Liu, Weilong Chai, Xinyu Xiao, Ziyuan Huang</strong></p>
<p>We introduce Ming-Lite-Uni, an open-source multimodal framework featuring a newly designed unified visual generator and a native multimodal autoregressive model tailored for unifying vision and language. Specifically, this project provides an open-source implementation of the integrated MetaQueries and M2-omni framework, while introducing the novel multi-scale learnable tokens and multi-scale representation alignment strategy. By leveraging a fixed MLLM and a learnable diffusion model, Ming-Lite-Uni enables native multimodal AR models to perform both text-to-image generation and instruction based image editing tasks, expanding their capabilities beyond pure visual understanding. Our experimental results demonstrate the strong performance of Ming-Lite-Uni and illustrate the impressive fluid nature of its interactive process. All code and model weights are open-sourced to foster further exploration within the community. Notably, this work aligns with concurrent multimodal AI milestones - such as ChatGPT-4o with native image generation updated in March 25, 2025 - underscoring the broader significance of unified models like Ming-Lite-Uni on the path toward AGI. Ming-Lite-Uni is in alpha stage and will soon be further refined. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Ming-Lite-Uniï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„å¤šæ¨¡å¼æ¡†æ¶ï¼Œå…·æœ‰æ–°è®¾è®¡çš„ç»Ÿä¸€è§†è§‰ç”Ÿæˆå™¨å’Œé’ˆå¯¹è§†è§‰å’Œè¯­è¨€çš„èåˆé‡èº«å®šåˆ¶çš„æœ¬åœŸå¤šæ¨¡å¼è‡ªå›å½’æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæ­¤é¡¹ç›®æä¾›äº†é›†æˆMetaQuerieså’ŒM2-omniæ¡†æ¶çš„å¼€æºå®ç°ï¼ŒåŒæ—¶å¼•å…¥äº†æ–°å‹çš„å¤šå°ºåº¦å¯å­¦ä¹ ä»¤ç‰Œå’Œå¤šå°ºåº¦è¡¨ç¤ºå¯¹é½ç­–ç•¥ã€‚é€šè¿‡åˆ©ç”¨å›ºå®šçš„MLLMå’Œå¯å­¦ä¹ çš„æ‰©æ•£æ¨¡å‹ï¼ŒMing-Lite-Uniä½¿æœ¬åœŸå¤šæ¨¡å¼è‡ªå›å½’æ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’ŒåŸºäºæŒ‡ä»¤çš„å›¾åƒç¼–è¾‘ä»»åŠ¡ï¼Œæ‰©å±•äº†å…¶è¶…è¶Šçº¯è§†è§‰ç†è§£çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¯æ˜äº†Ming-Lite-Uniçš„å¼ºå¤§æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†å…¶äº¤äº’è¿‡ç¨‹çš„æƒŠäººæµç•…æ€§ã€‚æ‰€æœ‰ä»£ç å’Œæ¨¡å‹æƒé‡å‡å¼€æºï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºå†…çš„è¿›ä¸€æ­¥æ¢ç´¢ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™é¡¹å·¥ä½œä¸åŒæœŸçš„å¤šæ¨¡å¼äººå·¥æ™ºèƒ½é‡Œç¨‹ç¢‘äº‹ä»¶ç›¸ç¬¦ï¼Œå¦‚2025å¹´3æœˆ25æ—¥æ›´æ–°çš„å…·æœ‰åŸç”Ÿå›¾åƒç”Ÿæˆçš„ChatGPT-4oï¼Œçªæ˜¾å‡ºåƒMing-Lite-Uniè¿™æ ·çš„ç»Ÿä¸€æ¨¡å‹åœ¨é€šå¾€äººå·¥æ™ºèƒ½é€šç”¨æ€§ï¼ˆAGIï¼‰é“è·¯ä¸Šçš„é‡è¦æ€§ã€‚ç›®å‰Ming-Lite-Uniå¤„äºAlphaé˜¶æ®µï¼Œæœªæ¥å°†ä¼šè¿›ä¸€æ­¥å®Œå–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02471v2">PDF</a> <a target="_blank" rel="noopener" href="https://github.com/inclusionAI/Ming/tree/main/Ming-unify">https://github.com/inclusionAI/Ming/tree/main/Ming-unify</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Ming-Lite-Uniè¿™ä¸€å¼€æºå¤šæ¨¡æ€æ¡†æ¶ï¼Œå…¶ç‰¹ç‚¹ä¸ºå…¨æ–°è®¾è®¡çš„ç»Ÿä¸€è§†è§‰ç”Ÿæˆå™¨ä»¥åŠé’ˆå¯¹è§†è§‰å’Œè¯­è¨€ç»Ÿä¸€åŒ–çš„æœ¬åœ°å¤šæ¨¡æ€è‡ªå›å½’æ¨¡å‹ã€‚è¯¥é¡¹ç›®å®ç°äº†é›†æˆMetaQuerieså’ŒM2-omniæ¡†æ¶çš„å¼€æºå®ç°ï¼Œå¼•å…¥æ–°å‹å¤šå°ºåº¦å¯å­¦ä¹ ä»¤ç‰Œå’Œå¤šå°ºåº¦è¡¨ç¤ºå¯¹é½ç­–ç•¥ã€‚åˆ©ç”¨å›ºå®šçš„MLLMå’Œå¯å­¦ä¹ çš„æ‰©æ•£æ¨¡å‹ï¼ŒMing-Lite-Uniä½¿æœ¬åœ°å¤šæ¨¡æ€ARæ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’ŒåŸºäºæŒ‡ä»¤çš„å›¾åƒç¼–è¾‘ä»»åŠ¡ï¼Œè¶…è¶Šäº†çº¯è§†è§‰ç†è§£çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜äº†Ming-Lite-Uniçš„å¼ºå¤§æ€§èƒ½ï¼Œå…¶äº¤äº’è¿‡ç¨‹è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æµç•…æ€§ã€‚æ‰€æœ‰ä»£ç å’Œæ¨¡å‹æƒé‡å‡å¼€æºï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºå†…çš„è¿›ä¸€æ­¥æ¢ç´¢ã€‚è¯¥å·¥ä½œä¸å½“å‰çš„å¤šå…ƒæ¨¡æ€äººå·¥æ™ºèƒ½é‡Œç¨‹ç¢‘ï¼ˆå¦‚ChatGPT-4oç­‰ï¼‰ç›¸å»åˆï¼Œæ˜¾ç¤ºå‡ºç»Ÿä¸€æ¨¡å‹åœ¨è¿ˆå‘äººå·¥æ™ºèƒ½é€šç”¨æ€§è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚Ming-Lite-Uniå°šå¤„äºAlphaé˜¶æ®µï¼Œæœªæ¥å°†æœ‰è¿›ä¸€æ­¥çš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ming-Lite-Uniæ˜¯ä¸€ä¸ªå¼€æºå¤šæ¨¡æ€æ¡†æ¶ï¼Œé›†æˆäº†è§†è§‰å’Œè¯­è¨€å¤„ç†åŠŸèƒ½ã€‚</li>
<li>å®ƒé‡‡ç”¨ç»Ÿä¸€è§†è§‰ç”Ÿæˆå™¨å’Œæœ¬åœ°å¤šæ¨¡æ€è‡ªå›å½’æ¨¡å‹è®¾è®¡ã€‚</li>
<li>è¯¥é¡¹ç›®å®ç°äº†MetaQuerieså’ŒM2-omniæ¡†æ¶çš„é›†æˆã€‚</li>
<li>å¼•å…¥æ–°å‹çš„å¤šå°ºåº¦å¯å­¦ä¹ ä»¤ç‰Œå’Œå¤šå°ºåº¦è¡¨ç¤ºå¯¹é½ç­–ç•¥æ˜¯è¯¥æ¡†æ¶çš„åˆ›æ–°ç‚¹ã€‚</li>
<li>Ming-Lite-Uniæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»¥åŠåŸºäºæŒ‡ä»¤çš„å›¾åƒç¼–è¾‘ä»»åŠ¡ã€‚</li>
<li>è¯¥æ¡†æ¶çš„å®éªŒç»“æœè¡¨ç°ä¼˜ç§€ï¼Œä¸å½“å‰çš„å¤šå…ƒæ¨¡æ€äººå·¥æ™ºèƒ½é‡Œç¨‹ç¢‘ç›¸ç¬¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02471">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-06380fed336a1af539b00aeae9b6b812.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-161e89071d69ff9ea19ef921d96c9afe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4250c4cfea42b43946ce25636b1e44a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a12669519da0fb4b4b9ba0b26683f33d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-29c7288bc0de2e28b2c88cd12d144e21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d019031236945e165e3541d7f4f6b1a7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d2bba3d34902481f35e1b20940b3e5c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Probability-Density-Geodesics-in-Image-Diffusion-Latent-Space"><a href="#Probability-Density-Geodesics-in-Image-Diffusion-Latent-Space" class="headerlink" title="Probability Density Geodesics in Image Diffusion Latent Space"></a>Probability Density Geodesics in Image Diffusion Latent Space</h2><p><strong>Authors:Qingtao Yu, Jaskirat Singh, Zhaoyuan Yang, Peter Henry Tu, Jing Zhang, Hongdong Li, Richard Hartley, Dylan Campbell</strong></p>
<p>Diffusion models indirectly estimate the probability density over a data space, which can be used to study its structure. In this work, we show that geodesics can be computed in diffusion latent space, where the norm induced by the spatially-varying inner product is inversely proportional to the probability density. In this formulation, a path that traverses a high density (that is, probable) region of image latent space is shorter than the equivalent path through a low density region. We present algorithms for solving the associated initial and boundary value problems and show how to compute the probability density along the path and the geodesic distance between two points. Using these techniques, we analyze how closely video clips approximate geodesics in a pre-trained image diffusion space. Finally, we demonstrate how these techniques can be applied to training-free image sequence interpolation and extrapolation, given a pre-trained image diffusion model. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡é—´æ¥ä¼°è®¡æ•°æ®ç©ºé—´çš„æ¦‚ç‡å¯†åº¦ï¼Œå¯ç”¨äºç ”ç©¶å…¶ç»“æ„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´ä¸­è®¡ç®—æµ‹åœ°çº¿ï¼Œå…¶ä¸­ç”±ç©ºé—´å˜åŒ–çš„å†…ç§¯å¼•èµ·çš„èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ã€‚åœ¨è¿™ç§è¡¨è¿°ä¸­ï¼Œéå†å›¾åƒæ½œåœ¨ç©ºé—´çš„é«˜å¯†åº¦ï¼ˆå³å¯èƒ½çš„ï¼‰åŒºåŸŸçš„è·¯å¾„æ¯”é€šè¿‡ä½å¯†åº¦åŒºåŸŸçš„ç­‰æ•ˆè·¯å¾„æ›´çŸ­ã€‚æˆ‘ä»¬æå‡ºäº†è§£å†³ç›¸å…³åˆå§‹å€¼å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•è®¡ç®—è·¯å¾„ä¸Šçš„æ¦‚ç‡å¯†åº¦ä»¥åŠä¸¤ç‚¹ä¹‹é—´çš„æµ‹åœ°è·ç¦»ã€‚ä½¿ç”¨è¿™äº›æŠ€æœ¯ï¼Œæˆ‘ä»¬åˆ†æäº†è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£ç©ºé—´ä¸­å¦‚ä½•è¿‘ä¼¼æµ‹åœ°çº¿ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨ç»™å®šé¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå°†è¿™äº›æŠ€æœ¯åº”ç”¨äºæ— è®­ç»ƒå›¾åƒåºåˆ—çš„æ’å€¼å’Œå¤–æ¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.06675v2">PDF</a> CVPR2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ‰©æ•£æ¨¡å‹åœ¨æ•°æ®ç©ºé—´æ¦‚ç‡å¯†åº¦ä¼°è®¡æ–¹é¢çš„åº”ç”¨ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæµ‹åœ°çº¿è®¡ç®—ã€‚ç ”ç©¶å‘ç°ï¼Œç”±ç©ºé—´å˜åŒ–å†…ç§¯è¯±å¯¼çš„èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ï¼Œé«˜å¯†åº¦åŒºåŸŸçš„è·¯å¾„æ¯”ä½å¯†åº¦åŒºåŸŸçš„è·¯å¾„çŸ­ã€‚æœ¬æ–‡æå‡ºäº†è§£å†³ç›¸å…³åˆå§‹å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•è®¡ç®—è·¯å¾„ä¸Šçš„æ¦‚ç‡å¯†åº¦å’Œä¸¤ç‚¹ä¹‹é—´çš„æµ‹åœ°è·ç¦»ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜åˆ†æäº†è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒå›¾åƒæ‰©æ•£ç©ºé—´ä¸­çš„è¿‘ä¼¼æµ‹åœ°çº¿è·¯æƒ…å†µï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•å°†è¯¥æŠ€æœ¯åº”ç”¨äºè®­ç»ƒå›¾åƒåºåˆ—çš„æ’å€¼ä¸å¤–å»¶é¢„æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å¯ä¼°è®¡æ•°æ®ç©ºé—´çš„æ¦‚ç‡å¯†åº¦ã€‚</li>
<li>åœ¨æ‰©æ•£æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæµ‹åœ°çº¿è®¡ç®—ã€‚</li>
<li>ç©ºé—´å˜åŒ–å†…ç§¯è¯±å¯¼çš„èŒƒæ•°ä¸æ¦‚ç‡å¯†åº¦æˆåæ¯”ã€‚</li>
<li>é«˜å¯†åº¦åŒºåŸŸè·¯å¾„çŸ­äºä½å¯†åº¦åŒºåŸŸè·¯å¾„ã€‚</li>
<li>æå‡ºäº†è§£å†³åˆå§‹å’Œè¾¹ç•Œå€¼é—®é¢˜çš„ç®—æ³•ã€‚</li>
<li>åˆ†æäº†è§†é¢‘å‰ªè¾‘åœ¨é¢„è®­ç»ƒå›¾åƒæ‰©æ•£ç©ºé—´ä¸­çš„è¿‘ä¼¼æµ‹åœ°çº¿è·¯æƒ…å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.06675">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c7330cbfd513e3c1cef2c59e69ded84d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d06b122adb1825e79c3a16d4ba9b898.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b296e7c1379b1ae87ad2cd2a3b809087.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f34efe72965049724f3fa2baf72f5e30.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-652fbb387a0eea35ddddc517bb64e55a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Generative-Detail-Enhancement-for-Physically-Based-Materials"><a href="#Generative-Detail-Enhancement-for-Physically-Based-Materials" class="headerlink" title="Generative Detail Enhancement for Physically Based Materials"></a>Generative Detail Enhancement for Physically Based Materials</h2><p><strong>Authors:Saeed Hadadan, Benedikt Bitterli, Tizian Zeltner, Jan NovÃ¡k, Fabrice Rousselle, Jacob Munkberg, Jon Hasselgren, Bartlomiej Wronski, Matthias Zwicker</strong></p>
<p>We present a tool for enhancing the detail of physically based materials using an off-the-shelf diffusion model and inverse rendering. Our goal is to enhance the visual fidelity of materials with detail that is often tedious to author, by adding signs of wear, aging, weathering, etc. As these appearance details are often rooted in real-world processes, we leverage a generative image model trained on a large dataset of natural images with corresponding visuals in context. Starting with a given geometry, UV mapping, and basic appearance, we render multiple views of the object. We use these views, together with an appearance-defining text prompt, to condition a diffusion model. The details it generates are then backpropagated from the enhanced images to the material parameters via inverse differentiable rendering. For inverse rendering to be successful, the generated appearance has to be consistent across all the images. We propose two priors to address the multi-view consistency of the diffusion model. First, we ensure that the initial noise that seeds the diffusion process is itself consistent across views by integrating it from a view-independent UV space. Second, we enforce geometric consistency by biasing the attention mechanism via a projective constraint so that pixels attend strongly to their corresponding pixel locations in other views. Our approach does not require any training or finetuning of the diffusion model, is agnostic of the material model used, and the enhanced material properties, i.e., 2D PBR textures, can be further edited by artists. This project is available at <a target="_blank" rel="noopener" href="https://generative-detail.github.io/">https://generative-detail.github.io</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨ç°æˆçš„æ‰©æ•£æ¨¡å‹å’Œé€†å‘æ¸²æŸ“æŠ€æœ¯ï¼Œæé«˜åŸºäºç‰©ç†æè´¨ç»†èŠ‚çš„å·¥å…·ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡æ·»åŠ ç£¨æŸã€è€åŒ–ã€é£åŒ–ç­‰è¿¹è±¡ï¼Œæé«˜æè´¨çš„è§†è§‰ä¿çœŸåº¦å’Œç»†èŠ‚ã€‚ç”±äºè¿™äº›å¤–è§‚ç»†èŠ‚å¾€å¾€æºäºç°å®ä¸–ç•Œçš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬åˆ©ç”¨åœ¨å¤§è§„æ¨¡è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒçš„ç”Ÿæˆå›¾åƒæ¨¡å‹ï¼Œä»¥åŠç›¸åº”çš„ä¸Šä¸‹æ–‡è§†è§‰ã€‚ä»ç»™å®šçš„å‡ ä½•å½¢çŠ¶ã€UVè´´å›¾å’ŒåŸºæœ¬å¤–è§‚å¼€å§‹ï¼Œæˆ‘ä»¬æ¸²æŸ“å¯¹è±¡çš„å¤šä¸ªè§†å›¾ã€‚æˆ‘ä»¬ä½¿ç”¨è¿™äº›è§†å›¾ä»¥åŠå®šä¹‰å¤–è§‚çš„æ–‡æœ¬æç¤ºï¼Œå¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–å¤„ç†ã€‚å®ƒç”Ÿæˆçš„ç»†èŠ‚ç„¶åä¼šä»å¢å¼ºå›¾åƒåå‘ä¼ æ’­åˆ°æè´¨å‚æ•°ï¼Œé€šè¿‡é€†å‘å¯å¾®åˆ†æ¸²æŸ“ã€‚ä¸ºäº†é€†å‘æ¸²æŸ“æˆåŠŸï¼Œç”Ÿæˆçš„å¤–è§‚å¿…é¡»åœ¨æ‰€æœ‰å›¾åƒä¸­ä¿æŒä¸€è‡´ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§å…ˆéªŒçŸ¥è¯†æ¥è§£å†³æ‰©æ•£æ¨¡å‹çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡ä»ä¸è§†å›¾æ— å…³çš„UVç©ºé—´è¿›è¡Œç§¯åˆ†ï¼Œç¡®ä¿ç§å­æ‰©æ•£è¿‡ç¨‹çš„åˆå§‹å™ªå£°æœ¬èº«åœ¨ä¸åŒè§†å›¾ä¸­æ˜¯ä¸€è‡´çš„ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬é€šè¿‡æŠ•å½±çº¦æŸæ¥å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¼ºåˆ¶å‡ ä½•ä¸€è‡´æ€§ï¼Œä½¿åƒç´ å¼ºçƒˆå…³æ³¨å…¶ä»–è§†å›¾ä¸­çš„å¯¹åº”åƒç´ ä½ç½®ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œä»»ä½•è®­ç»ƒæˆ–å¾®è°ƒï¼Œä¸å—æ‰€ä½¿ç”¨çš„ææ–™æ¨¡å‹çš„å½±å“ï¼Œå¹¶ä¸”å¢å¼ºçš„ææ–™å±æ€§ï¼ˆå³2D PBRçº¹ç†ï¼‰å¯ä»¥è¿›ä¸€æ­¥ç”±è‰ºæœ¯å®¶è¿›è¡Œç¼–è¾‘ã€‚æ­¤é¡¹ç›®åœ¨<a target="_blank" rel="noopener" href="https://generative-detail.github.ioä¸Šæä¾›çš„./">https://generative-detail.github.ioä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13994v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨ç°æˆçš„æ‰©æ•£æ¨¡å‹å’Œé€†å‘æ¸²æŸ“æŠ€æœ¯æå‡ç‰©ç†åŸºç¡€ææ–™çš„ç»†èŠ‚ä¸°å¯Œåº¦çš„å·¥å…·ã€‚å…¶ç›®æ ‡æ˜¯é€šè¿‡æ·»åŠ ç£¨æŸã€è€åŒ–ã€é£åŒ–ç­‰è¿¹è±¡ï¼Œæé«˜ææ–™çš„è§†è§‰é€¼çœŸåº¦ï¼Œè¿™äº›å¤–è§‚ç»†èŠ‚é€šå¸¸éš¾ä»¥åˆ¶ä½œã€‚è¯¥ç ”ç©¶åˆ©ç”¨å¤§å‹è‡ªç„¶å›¾åƒæ•°æ®é›†è®­ç»ƒçš„ç”Ÿæˆå›¾åƒæ¨¡å‹ï¼Œç»“åˆç‰©ä½“çš„å¤šä¸ªè§†å›¾å’Œå®šä¹‰å¤–è§‚çš„æ–‡æœ¬æç¤ºï¼Œæ¥è°ƒæ§æ‰©æ•£æ¨¡å‹ã€‚ç”Ÿæˆçš„ç»†èŠ‚é€šè¿‡é€†å‘å¯å¾®æ¸²æŸ“ä»å¢å¼ºå›¾åƒä¼ æ’­å›ææ–™å‚æ•°ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸¤ç§ä¼˜å…ˆç­–ç•¥ï¼Œä»¥ç¡®ä¿æ‰©æ•£æ¨¡å‹åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢çš„æˆåŠŸã€‚ä¸€æ˜¯ç¡®ä¿æ‰©æ•£è¿‡ç¨‹åˆå§‹å™ªå£°åœ¨è§†å›¾é—´æ˜¯ä¸€è‡´ï¼Œé€šè¿‡ä»ä¸è§†å›¾æ— å…³çš„UVç©ºé—´è¿›è¡Œæ•´åˆå®ç°ï¼›äºŒæ˜¯é€šè¿‡æŠ•å½±çº¦æŸå¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å‡ ä½•ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•æ— éœ€å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œä»»ä½•è®­ç»ƒæˆ–å¾®è°ƒï¼Œå¯¹ä½¿ç”¨çš„ææ–™æ¨¡å‹å…·æœ‰é€šç”¨æ€§ï¼Œä¸”å¢å¼ºçš„ææ–™å±æ€§ï¼ˆå¦‚2D PBRçº¹ç†ï¼‰å¯è¿›ä¸€æ­¥ç”±è‰ºæœ¯å®¶ç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œé€†å‘æ¸²æŸ“å¢å¼ºç‰©ç†åŸºç¡€ææ–™ç»†èŠ‚çš„æ–¹æ³•ã€‚</li>
<li>æ–¹æ³•çš„ç›®çš„æ˜¯æé«˜ææ–™çš„è§†è§‰é€¼çœŸåº¦ï¼Œç‰¹åˆ«æ˜¯æ·»åŠ ç£¨æŸã€è€åŒ–ã€é£åŒ–ç­‰ç»†èŠ‚ã€‚</li>
<li>åˆ©ç”¨ç”Ÿæˆå›¾åƒæ¨¡å‹å’Œå¯¹ç‰©ä½“çš„å¤šä¸ªè§†å›¾ä»¥åŠå®šä¹‰å¤–è§‚çš„æ–‡æœ¬æç¤ºæ¥è°ƒæ§æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>é€šè¿‡é€†å‘å¯å¾®æ¸²æŸ“å°†ç”Ÿæˆçš„ç»†èŠ‚ä»å¢å¼ºå›¾åƒä¼ æ’­å›ææ–™å‚æ•°ã€‚</li>
<li>æå‡ºäº†ä¸¤ç§ç­–ç•¥ç¡®ä¿å¤šè§†å›¾ä¸€è‡´æ€§ï¼šæ•´åˆUVç©ºé—´çš„åˆå§‹å™ªå£°å’Œé€šè¿‡æŠ•å½±çº¦æŸå¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œè®­ç»ƒæˆ–å¾®è°ƒï¼Œé€‚ç”¨äºå„ç§ææ–™æ¨¡å‹ã€‚</li>
<li>å¢å¼ºçš„ææ–™å±æ€§ï¼ˆå¦‚2D PBRçº¹ç†ï¼‰å¯ç”±è‰ºæœ¯å®¶è¿›ä¸€æ­¥ç¼–è¾‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13994">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0c35c2cdedd5eb7bd674e56bdc63dbb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a17b6d434a27dd49478953ebe89c0df8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ad98893ef6e615a8ab604040e3cf077.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65e79c3d53d342349f547588fe3e0e31.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d7c4c877c2bbf02fd46d980426f0f050.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficiency-Meets-Fidelity-A-Novel-Quantization-Framework-for-Stable-Diffusion"><a href="#Efficiency-Meets-Fidelity-A-Novel-Quantization-Framework-for-Stable-Diffusion" class="headerlink" title="Efficiency Meets Fidelity: A Novel Quantization Framework for Stable   Diffusion"></a>Efficiency Meets Fidelity: A Novel Quantization Framework for Stable   Diffusion</h2><p><strong>Authors:Shuaiting Li, Juncan Deng, Zeyu Wang, Kedong Xu, Rongtao Deng, Hong Gu, Haibin Shen, Kejie Huang</strong></p>
<p>Text-to-image generation via Stable Diffusion models (SDM) have demonstrated remarkable capabilities. However, their computational intensity, particularly in the iterative denoising process, hinders real-time deployment in latency-sensitive applications. While Recent studies have explored post-training quantization (PTQ) and quantization-aware training (QAT) methods to compress Diffusion models, existing methods often overlook the consistency between results generated by quantized models and those from floating-point models. This consistency is paramount for professional applications where both efficiency and output reliability are essential. To ensure that quantized SDM generates high-quality and consistent images, we propose an efficient quantization framework for SDM. Our framework introduces a Serial-to-Parallel pipeline that simultaneously maintains training-inference consistency and ensures optimization stability. Building upon this foundation, we further develop several techniques including multi-timestep activation quantization, time information precalculation, inter-layer distillation, and selective freezing, to achieve high-fidelity generation in comparison to floating-point models while maintaining quantization efficiency.   Through comprehensive evaluation across multiple Stable Diffusion variants (v1-4, v2-1, XL 1.0, and v3), our method demonstrates superior performance over state-of-the-art approaches with shorter training times. Under W4A8 quantization settings, we achieve significant improvements in both distribution similarity and visual fidelity, while preserving a high image quality. </p>
<blockquote>
<p>é€šè¿‡ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼ˆSDMï¼‰è¿›è¡Œçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå·²ç»æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…¶è®¡ç®—å¼ºåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿­ä»£å»å™ªè¿‡ç¨‹ä¸­ï¼Œé˜»ç¢äº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåº”ç”¨ä¸­çš„å®æ—¶éƒ¨ç½²ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰æ–¹æ³•æ¥å‹ç¼©æ‰©æ•£æ¨¡å‹ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†é‡åŒ–æ¨¡å‹ç”Ÿæˆçš„ç»“æœä¸æµ®ç‚¹æ¨¡å‹ç”Ÿæˆçš„ç»“æœä¹‹é—´çš„ä¸€è‡´æ€§ã€‚å¯¹äºæ—¢éœ€è¦æ•ˆç‡åˆéœ€è¦è¾“å‡ºå¯é æ€§çš„ä¸“ä¸šåº”ç”¨è€Œè¨€ï¼Œè¿™ç§ä¸€è‡´æ€§è‡³å…³é‡è¦ã€‚ä¸ºäº†ç¡®ä¿é‡åŒ–çš„SDMç”Ÿæˆé«˜è´¨é‡ä¸”ä¸€è‡´çš„å›¾åƒï¼Œæˆ‘ä»¬ä¸ºSDMæå‡ºäº†ä¸€ä¸ªé«˜æ•ˆçš„é‡åŒ–æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¼•å…¥äº†ä¸€ä¸ªä¸²è¡Œåˆ°å¹¶è¡Œçš„æµæ°´çº¿ï¼ŒåŒæ—¶ä¿æŒè®­ç»ƒæ¨ç†çš„ä¸€è‡´æ€§å’Œç¡®ä¿ä¼˜åŒ–ç¨³å®šæ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼€å‘äº†å‡ ç§æŠ€æœ¯ï¼ŒåŒ…æ‹¬å¤šæ—¶é—´æ­¥æ¿€æ´»é‡åŒ–ã€æ—¶é—´ä¿¡æ¯é¢„è®¡ç®—ã€å±‚é—´è’¸é¦å’Œé€‰æ‹©æ€§å†»ç»“ï¼Œä»¥å®ç°ä¸æµ®ç‚¹æ¨¡å‹ç›¸æ¯”çš„é«˜ä¿çœŸç”Ÿæˆï¼ŒåŒæ—¶ä¿æŒé‡åŒ–æ•ˆç‡ã€‚é€šè¿‡å¯¹å¤šä¸ªç¨³å®šæ‰©æ•£å˜ä½“ï¼ˆv1-4ã€v2-1ã€XL 1.0å’Œv3ï¼‰çš„ç»¼åˆè¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è®­ç»ƒæ—¶é—´ä¸Šä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚åœ¨W4A8é‡åŒ–è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬åœ¨åˆ†å¸ƒç›¸ä¼¼æ€§å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å›¾åƒè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06661v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºStable Diffusionæ¨¡å‹ï¼ˆSDMï¼‰çš„æ–‡æœ¬è½¬å›¾åƒç”ŸæˆæŠ€æœ¯å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶è®¡ç®—å¯†é›†å‹çš„è¿­ä»£å»å™ªè¿‡ç¨‹é˜»ç¢äº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­çš„å®æ—¶éƒ¨ç½²ã€‚ä¸ºç¡®ä¿é‡åŒ–åçš„SDMç”Ÿæˆé«˜è´¨é‡ä¸”ä¸€è‡´çš„å›¾åƒï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºä¸€ä¸ªé«˜æ•ˆé‡åŒ–æ¡†æ¶ï¼Œé‡‡ç”¨ä¸²è¡Œè½¬å¹¶è¡Œç®¡é“ï¼Œä¿æŒè®­ç»ƒæ¨ç†ä¸€è‡´æ€§å¹¶ä¼˜åŒ–ç¨³å®šæ€§ã€‚é€šè¿‡å¤šé¡¹æŠ€æœ¯ï¼ŒåŒ…æ‹¬å¤šæ—¶é—´æ­¥æ¿€æ´»é‡åŒ–ã€æ—¶é—´ä¿¡æ¯é¢„è®¡ç®—ã€å±‚é—´è’¸é¦å’Œé€‰æ‹©æ€§å†»ç»“ç­‰ï¼Œè¯¥æ¡†æ¶ç›¸è¾ƒäºæµ®ç‚¹æ¨¡å‹åœ¨ä¿æŒé‡åŒ–æ•ˆç‡çš„åŒæ—¶å®ç°äº†é«˜ä¿çœŸç”Ÿæˆã€‚ç»è¿‡å¯¹å¤šä¸ªStable Diffusionç‰ˆæœ¬çš„ç»¼åˆè¯„ä¼°ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½å’Œè®­ç»ƒæ—¶é—´ä¸Šå‡è¡¨ç°å‡ºè¶…è¶Šç°æœ‰æŠ€æœ¯çš„ä¼˜åŠ¿ã€‚åœ¨W4A8é‡åŒ–è®¾ç½®ä¸‹ï¼Œå…¶åœ¨åˆ†å¸ƒç›¸ä¼¼æ€§å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å›¾åƒè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Stable Diffusionæ¨¡å‹åœ¨æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆä¸Šè¡¨ç°å“è¶Šï¼Œä½†è®¡ç®—å¯†é›†å‹çš„å»å™ªè¿‡ç¨‹å¯¼è‡´å®æ—¶éƒ¨ç½²å—é™ã€‚</li>
<li>é‡åŒ–æ¡†æ¶ç”¨äºæé«˜SDMçš„æ•ˆç‡å¹¶ç”Ÿæˆé«˜è´¨é‡ã€ä¸€è‡´çš„å›¾åƒã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨ä¸²è¡Œè½¬å¹¶è¡Œç®¡é“ï¼Œæ—¨åœ¨ä¿æŒè®­ç»ƒæ¨ç†ä¸€è‡´æ€§å¹¶ä¼˜åŒ–ç¨³å®šæ€§ã€‚</li>
<li>é€šè¿‡å¤šé¡¹æŠ€æœ¯å®ç°é«˜ä¿çœŸç”Ÿæˆï¼ŒåŒ…æ‹¬å¤šæ—¶é—´æ­¥æ¿€æ´»é‡åŒ–ã€æ—¶é—´ä¿¡æ¯é¢„è®¡ç®—ç­‰ã€‚</li>
<li>æ¡†æ¶åœ¨å¤šä¸ªStable Diffusionç‰ˆæœ¬è¯„ä¼°ä¸­è¡¨ç°ä¼˜è¶Šï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­ã€‚</li>
<li>åœ¨W4A8é‡åŒ–è®¾ç½®ä¸‹ï¼Œæ¡†æ¶åœ¨åˆ†å¸ƒç›¸ä¼¼æ€§å’Œè§†è§‰ä¿çœŸåº¦ä¸Šå–å¾—æ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06661">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d3fa101b120d05b6303238761aad3620.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cbc4be7dc44772e90b4431ed6f422623.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d70f199936df6264c8c332589207ad86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5f78148f3c049d8f7dd834c359e812a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de804d728ada58b8fa4a97244451761d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DynamicControl-Adaptive-Condition-Selection-for-Improved-Text-to-Image-Generation"><a href="#DynamicControl-Adaptive-Condition-Selection-for-Improved-Text-to-Image-Generation" class="headerlink" title="DynamicControl: Adaptive Condition Selection for Improved Text-to-Image   Generation"></a>DynamicControl: Adaptive Condition Selection for Improved Text-to-Image   Generation</h2><p><strong>Authors:Qingdong He, Jinlong Peng, Pengcheng Xu, Boyuan Jiang, Xiaobin Hu, Donghao Luo, Yong Liu, Yabiao Wang, Chengjie Wang, Xiangtai Li, Jiangning Zhang</strong></p>
<p>To enhance the controllability of text-to-image diffusion models, current ControlNet-like models have explored various control signals to dictate image attributes. However, existing methods either handle conditions inefficiently or use a fixed number of conditions, which does not fully address the complexity of multiple conditions and their potential conflicts. This underscores the need for innovative approaches to manage multiple conditions effectively for more reliable and detailed image synthesis. To address this issue, we propose a novel framework, DynamicControl, which supports dynamic combinations of diverse control signals, allowing adaptive selection of different numbers and types of conditions. Our approach begins with a double-cycle controller that generates an initial real score sorting for all input conditions by leveraging pre-trained conditional generation models and discriminative models. This controller evaluates the similarity between extracted conditions and input conditions, as well as the pixel-level similarity with the source image. Then, we integrate a Multimodal Large Language Model (MLLM) to build an efficient condition evaluator. This evaluator optimizes the ordering of conditions based on the double-cycle controllerâ€™s score ranking. Our method jointly optimizes MLLMs and diffusion models, utilizing MLLMsâ€™ reasoning capabilities to facilitate multi-condition text-to-image (T2I) tasks. The final sorted conditions are fed into a parallel multi-control adapter, which learns feature maps from dynamic visual conditions and integrates them to modulate ControlNet, thereby enhancing control over generated images. Through both quantitative and qualitative comparisons, DynamicControl demonstrates its superiority over existing methods in terms of controllability, generation quality and composability under various conditional controls. </p>
<blockquote>
<p>ä¸ºäº†å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§æ€§ï¼Œå½“å‰çš„ControlNetç±»æ¨¡å‹å·²ç»æ¢ç´¢äº†å„ç§æ§åˆ¶ä¿¡å·æ¥æŒ‡ç¤ºå›¾åƒå±æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆå¤„ç†æ¡ä»¶æ•ˆç‡ä½ä¸‹ï¼Œè¦ä¹ˆä½¿ç”¨å›ºå®šæ•°é‡çš„æ¡ä»¶ï¼Œè¿™å¹¶æ²¡æœ‰å®Œå…¨è§£å†³å¤šä¸ªæ¡ä»¶çš„å¤æ‚æ€§åŠå…¶æ½œåœ¨å†²çªã€‚è¿™å¼ºè°ƒäº†éœ€è¦é‡‡ç”¨åˆ›æ–°æ–¹æ³•æœ‰æ•ˆç®¡ç†å¤šä¸ªæ¡ä»¶ï¼Œä»¥å®ç°æ›´å¯é å’Œæ›´è¯¦ç»†çš„å›¾åƒåˆæˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶DynamicControlï¼Œå®ƒæ”¯æŒå„ç§æ§åˆ¶ä¿¡å·çš„åŠ¨æ€ç»„åˆï¼Œå¹¶å…è®¸è‡ªé€‚åº”é€‰æ‹©ä¸åŒæ•°é‡å’Œç±»å‹çš„æ¡ä»¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å§‹äºåŒé‡å¾ªç¯æ§åˆ¶å™¨ï¼Œè¯¥æ§åˆ¶å™¨åˆ©ç”¨é¢„è®­ç»ƒçš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹ï¼Œå¯¹æ‰€æœ‰è¾“å…¥æ¡ä»¶ç”Ÿæˆåˆå§‹çœŸå®åˆ†æ•°æ’åºã€‚è¯¥æ§åˆ¶å™¨è¯„ä¼°æå–çš„æ¡ä»¶ä¸è¾“å…¥æ¡ä»¶ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œä»¥åŠä¸æºå›¾åƒçš„åƒç´ çº§ç›¸ä¼¼æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬é›†æˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œä»¥æ„å»ºé«˜æ•ˆçš„æ¡ä»¶è¯„ä¼°å™¨ã€‚è¯¥è¯„ä¼°å™¨æ ¹æ®åŒé‡å¾ªç¯æ§åˆ¶å™¨çš„å¾—åˆ†æ’åä¼˜åŒ–æ¡ä»¶çš„é¡ºåºã€‚æˆ‘ä»¬çš„æ–¹æ³•è”åˆä¼˜åŒ–MLLMså’Œæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨MLLMsçš„æ¨ç†èƒ½åŠ›ä¿ƒè¿›å¤šæ¡ä»¶æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ä»»åŠ¡ã€‚æœ€ç»ˆçš„æ’åºæ¡ä»¶è¢«è¾“å…¥åˆ°å¹¶è¡Œå¤šæ§åˆ¶é€‚é…å™¨ä¸­ï¼Œè¯¥é€‚é…å™¨ä»åŠ¨æ€è§†è§‰æ¡ä»¶ä¸­å­¦ä¹ ç‰¹å¾æ˜ å°„å¹¶å°†å…¶é›†æˆï¼Œä»¥è°ƒåˆ¶ControlNetï¼Œä»è€Œæé«˜å¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶èƒ½åŠ›ã€‚é€šè¿‡å®šé‡å’Œå®šæ€§æ¯”è¾ƒï¼ŒDynamicControlåœ¨å„ç§æ¡ä»¶æ§åˆ¶ä¸‹ï¼Œåœ¨å¯æ§æ€§ã€ç”Ÿæˆè´¨é‡å’Œç»„åˆæ€§æ–¹é¢å‡è¡¨ç°å‡ºå…¶ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03255v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>ä¸ºæé«˜æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§æ€§ï¼Œå½“å‰ControlNetç±»æ¨¡å‹å·²å°è¯•ä½¿ç”¨å„ç§æ§åˆ¶ä¿¡å·æ¥æŒ‡ç¤ºå›¾åƒå±æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆå¤„ç†æ¡ä»¶æ•ˆç‡ä½ä¸‹ï¼Œè¦ä¹ˆä½¿ç”¨å›ºå®šæ•°é‡çš„æ¡ä»¶ï¼Œè¿™å¹¶æœªå……åˆ†è§£å†³å¤šä¸ªæ¡ä»¶çš„å¤æ‚æ€§åŠå…¶æ½œåœ¨å†²çªã€‚å› æ­¤ï¼Œéœ€è¦åˆ›æ–°æ–¹æ³•æœ‰æ•ˆç®¡ç†å¤šä¸ªæ¡ä»¶ï¼Œä»¥å®ç°æ›´å¯é å’Œè¯¦ç»†çš„å›¾åƒåˆæˆã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DynamicControlæ¡†æ¶ï¼Œæ”¯æŒå„ç§æ§åˆ¶ä¿¡å·çš„åŠ¨æ€ç»„åˆï¼Œå¯å®ç°ä¸åŒæ•°é‡å’Œç±»å‹çš„æ¡ä»¶çš„è‡ªé€‚åº”é€‰æ‹©ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹ï¼Œæ„å»ºä¸€ä¸ªåŒå¾ªç¯æ§åˆ¶å™¨ï¼Œç”Ÿæˆæ‰€æœ‰è¾“å…¥æ¡ä»¶çš„åˆå§‹çœŸå®åˆ†æ•°æ’åºã€‚è¯¥æ§åˆ¶å™¨è¯„ä¼°æå–çš„æ¡ä»¶ä¸è¾“å…¥æ¡ä»¶çš„ç›¸ä¼¼æ€§ï¼Œä»¥åŠä¸æºå›¾åƒçš„åƒç´ çº§ç›¸ä¼¼æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬æ•´åˆäº†ä¸€ä¸ªå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¥æ„å»ºä¸€ä¸ªé«˜æ•ˆçš„æ¡ä»¶è¯„ä¼°å™¨ã€‚è¯¥è¯„ä¼°å™¨åŸºäºåŒå¾ªç¯æ§åˆ¶å™¨çš„åˆ†æ•°æ’åä¼˜åŒ–æ¡ä»¶çš„æ’åºã€‚æˆ‘ä»¬çš„æ–¹æ³•è”åˆä¼˜åŒ–MLLMså’Œæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨MLLMsçš„æ¨ç†èƒ½åŠ›ä¿ƒè¿›å¤šæ¡ä»¶æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ä»»åŠ¡ã€‚æœ€ç»ˆæ’åºçš„æ¡ä»¶è¢«è¾“å…¥åˆ°å¹¶è¡Œå¤šæ§åˆ¶é€‚é…å™¨ä¸­ï¼Œè¯¥é€‚é…å™¨ä»åŠ¨æ€è§†è§‰æ¡ä»¶ä¸­å­¦ä¹ ç‰¹å¾æ˜ å°„å¹¶å°†å…¶é›†æˆä»¥è°ƒåˆ¶ControlNetï¼Œä»è€Œæé«˜å¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶èƒ½åŠ›ã€‚é€šè¿‡å®šé‡å’Œå®šæ€§æ¯”è¾ƒï¼ŒDynamicControlåœ¨å¯æ§æ€§ã€ç”Ÿæˆè´¨é‡å’Œå„ç§æ¡ä»¶æ§åˆ¶çš„ç»„åˆæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>å½“å‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹é¢ä¸´å¯æ§æ€§é—®é¢˜ï¼Œéœ€è¦æœ‰æ•ˆç®¡ç†å¤šä¸ªæ¡ä»¶çš„æ–¹æ³•ã€‚</li>
<li>DynamicControlæ¡†æ¶æ”¯æŒåŠ¨æ€ç»„åˆå¤šç§æ§åˆ¶ä¿¡å·ï¼Œå®ç°æ¡ä»¶æ•°é‡å’Œç±»å‹çš„è‡ªé€‚åº”é€‰æ‹©ã€‚</li>
<li>åˆ©ç”¨åŒå¾ªç¯æ§åˆ¶å™¨ç”Ÿæˆåˆå§‹çœŸå®åˆ†æ•°æ’åºï¼Œè¯„ä¼°æ¡ä»¶ç›¸ä¼¼æ€§ã€‚</li>
<li>é›†æˆå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ„å»ºé«˜æ•ˆæ¡ä»¶è¯„ä¼°å™¨ï¼Œä¼˜åŒ–æ¡ä»¶æ’åºã€‚</li>
<li>è”åˆä¼˜åŒ–MLLMså’Œæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨MLLMsçš„æ¨ç†èƒ½åŠ›ä¿ƒè¿›å¤šæ¡ä»¶æ–‡æœ¬åˆ°å›¾åƒä»»åŠ¡ã€‚</li>
<li>æœ€åçš„æ¡ä»¶æ’åºè¢«è¾“å…¥åˆ°å¹¶è¡Œå¤šæ§åˆ¶é€‚é…å™¨ä¸­ï¼Œè¯¥é€‚é…å™¨å­¦ä¹ å¹¶é›†æˆåŠ¨æ€è§†è§‰æ¡ä»¶ä»¥è°ƒåˆ¶ControlNetã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03255">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ff48f17347fe8711f0d05bd19cac5566.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8dbb1d1ea24bdd3d7330f6a851fe0345.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5224713e0b2322ebfe4f1e385bfa9219.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6762a09abb139e5cf0b4091265ff8a8f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Replace-Anyone-in-Videos"><a href="#Replace-Anyone-in-Videos" class="headerlink" title="Replace Anyone in Videos"></a>Replace Anyone in Videos</h2><p><strong>Authors:Xiang Wang, Shiwei Zhang, Haonan Qiu, Ruihang Chu, Zekun Li, Yingya Zhang, Changxin Gao, Yuehuan Wang, Chunhua Shen, Nong Sang</strong></p>
<p>The field of controllable human-centric video generation has witnessed remarkable progress, particularly with the advent of diffusion models. However, achieving precise and localized control over human motion in videos, such as replacing or inserting individuals while preserving desired motion patterns, still remains a formidable challenge. In this work, we present the ReplaceAnyone framework, which focuses on localized human replacement and insertion featuring intricate backgrounds. Specifically, we formulate this task as an image-conditioned video inpainting paradigm with pose guidance, utilizing a unified end-to-end video diffusion architecture that facilitates image-conditioned video inpainting within masked regions. To prevent shape leakage and enable granular local control, we introduce diverse mask forms involving both regular and irregular shapes. Furthermore, we implement an enriched visual guidance mechanism to enhance appearance alignment, a hybrid inpainting encoder to further preserve the detailed background information in the masked video, and a two-phase optimization methodology to simplify the training difficulty. ReplaceAnyone enables seamless replacement or insertion of characters while maintaining the desired pose motion and reference appearance within a single framework. Extensive experimental results demonstrate the effectiveness of our method in generating realistic and coherent video content. The proposed ReplaceAnyone can be seamlessly applied not only to traditional 3D-UNet base models but also to DiT-based video models such as Wan2.1. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/ali-vilab/UniAnimate-DiT">https://github.com/ali-vilab/UniAnimate-DiT</a>. </p>
<blockquote>
<p>å¯æ§ä»¥äººä¸ºä¸­å¿ƒçš„è§†é¢‘ç”Ÿæˆé¢†åŸŸå·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯éšç€æ‰©æ•£æ¨¡å‹çš„å…´èµ·ã€‚ç„¶è€Œï¼Œåœ¨è§†é¢‘ä¸­å¯¹äººç±»åŠ¨ä½œè¿›è¡Œç²¾ç¡®å’Œå±€éƒ¨åŒ–çš„æ§åˆ¶ï¼Œå¦‚æ›¿æ¢æˆ–æ’å…¥ä¸ªä½“åŒæ—¶ä¿æŒæœŸæœ›çš„åŠ¨ä½œæ¨¡å¼ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ReplaceAnyoneæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸“æ³¨äºå…·æœ‰å¤æ‚èƒŒæ™¯çš„å±€éƒ¨äººç±»æ›¿æ¢å’Œæ’å…¥ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ­¤ä»»åŠ¡åˆ¶å®šä¸ºå›¾åƒæ¡ä»¶è§†é¢‘ä¿®å¤æ¨¡å¼å¸¦æœ‰å§¿åŠ¿æŒ‡å¯¼ï¼Œåˆ©ç”¨ç»Ÿä¸€ç«¯åˆ°ç«¯è§†é¢‘æ‰©æ•£æ¶æ„ï¼Œä¾¿äºåœ¨é®ç½©åŒºåŸŸå†…è¿›è¡Œå›¾åƒæ¡ä»¶è§†é¢‘ä¿®å¤ã€‚ä¸ºäº†é˜²æ­¢å½¢çŠ¶æ³„éœ²å¹¶å®ç°ç²¾ç»†çš„å±€éƒ¨æ§åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šç§å½¢å¼çš„é®ç½©ï¼ŒåŒ…æ‹¬è§„åˆ™å’Œä¸è§„åˆ™å½¢çŠ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°äº†ä¸°å¯Œçš„è§†è§‰å¼•å¯¼æœºåˆ¶ä»¥å¢å¼ºå¤–è§‚å¯¹é½ï¼Œæ··åˆä¿®å¤ç¼–ç å™¨ä»¥è¿›ä¸€æ­¥ä¿ç•™é®ç½©è§†é¢‘ä¸­çš„è¯¦ç»†èƒŒæ™¯ä¿¡æ¯ï¼Œä»¥åŠä¸¤é˜¶æ®µä¼˜åŒ–æ–¹æ³•æ¥ç®€åŒ–è®­ç»ƒéš¾åº¦ã€‚ReplaceAnyoneèƒ½å¤Ÿåœ¨å•ä¸€æ¡†æ¶å†…æ— ç¼æ›¿æ¢æˆ–æ’å…¥è§’è‰²ï¼ŒåŒæ—¶ä¿æŒæœŸæœ›çš„å§¿åŠ¿åŠ¨ä½œå’Œå‚è€ƒå¤–è§‚ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆç°å®å’Œè¿è´¯çš„è§†é¢‘å†…å®¹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„ReplaceAnyoneä¸ä»…å¯ä»¥æ— ç¼åº”ç”¨äºä¼ ç»Ÿçš„3D-UNetåŸºç¡€æ¨¡å‹ï¼Œè¿˜å¯ä»¥åº”ç”¨äºåŸºäºDiTçš„è§†é¢‘æ¨¡å‹ï¼Œå¦‚Wan 2.1ã€‚ç›¸å…³ä»£ç å°†å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/ali-vilab/UniAnimate-DiT%E3%80%82">https://github.com/ali-vilab/UniAnimate-DiTã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.19911v2">PDF</a> </p>
<p><strong>Summary</strong><br>     éšç€æ‰©æ•£æ¨¡å‹çš„å‘å±•ï¼Œä»¥äººä¸ºä¸­å¿ƒçš„å¯æ§è§†é¢‘ç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†åœ¨è§†é¢‘ä¸­å®ç°ç²¾ç¡®å’Œå±€éƒ¨åŒ–çš„è¿åŠ¨æ§åˆ¶ï¼Œå¦‚åœ¨ä¿ç•™æ‰€éœ€è¿åŠ¨æ¨¡å¼çš„åŒæ—¶æ›¿æ¢æˆ–æ’å…¥ä¸ªä½“ï¼Œä»æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†ReplaceAnyoneæ¡†æ¶ï¼Œä¸“æ³¨äºå±€éƒ¨äººç‰©æ›¿æ¢å’Œæ’å…¥ï¼Œå¸¦æœ‰å¤æ‚èƒŒæ™¯ã€‚æˆ‘ä»¬å°†æ­¤ä»»åŠ¡åˆ¶å®šä¸ºå›¾åƒæ¡ä»¶è§†é¢‘ä¿®å¤èŒƒå¼ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„ç«¯åˆ°ç«¯è§†é¢‘æ‰©æ•£æ¶æ„ï¼Œåœ¨æ©ç åŒºåŸŸå†…è¿›è¡Œå›¾åƒæ¡ä»¶è§†é¢‘ä¿®å¤ã€‚ä¸ºé¢„é˜²å½¢çŠ¶æ³„éœ²å¹¶å®ç°ç²¾ç»†å±€éƒ¨æ§åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šç§æ©ç å½¢å¼ï¼ŒåŒ…æ‹¬è§„åˆ™å’Œä¸è§„åˆ™å½¢çŠ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å®æ–½äº†ä¸°å¯Œçš„è§†è§‰å¼•å¯¼æœºåˆ¶ï¼Œä»¥æé«˜å¤–è§‚å¯¹é½åº¦ï¼Œæ··åˆä¿®å¤ç¼–ç å™¨ä»¥è¿›ä¸€æ­¥ä¿ç•™æ©ç è§†é¢‘ä¸­çš„è¯¦ç»†èƒŒæ™¯ä¿¡æ¯ï¼Œä»¥åŠä¸¤é˜¶æ®µä¼˜åŒ–æ–¹æ³•ä»¥ç®€åŒ–è®­ç»ƒéš¾åº¦ã€‚ReplaceAnyoneèƒ½å¤Ÿåœ¨å•ä¸€æ¡†æ¶å†…æ— ç¼æ›¿æ¢æˆ–æ’å…¥è§’è‰²ï¼ŒåŒæ—¶ä¿æŒæ‰€éœ€çš„å§¿åŠ¿è¿åŠ¨å’Œå‚è€ƒå¤–è§‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨ä»¥äººä¸ºä¸­å¿ƒçš„å¯æ§è§†é¢‘ç”Ÿæˆé¢†åŸŸå–å¾—æ˜¾è‘—è¿›æ­¥ã€‚</li>
<li>å®ç°ç²¾ç¡®å’Œå±€éƒ¨åŒ–çš„è¿åŠ¨æ§åˆ¶ï¼ˆå¦‚æ›¿æ¢æˆ–æ’å…¥è§†é¢‘ä¸­çš„ä¸ªä½“ï¼‰ä»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>ReplaceAnyoneæ¡†æ¶ä¸“æ³¨äºå±€éƒ¨äººç‰©æ›¿æ¢å’Œæ’å…¥ï¼Œå¸¦æœ‰å¤æ‚èƒŒæ™¯ã€‚</li>
<li>è¯¥ä»»åŠ¡è¢«åˆ¶å®šä¸ºå›¾åƒæ¡ä»¶è§†é¢‘ä¿®å¤èŒƒå¼ï¼Œåˆ©ç”¨ç»Ÿä¸€çš„ç«¯åˆ°ç«¯è§†é¢‘æ‰©æ•£æ¶æ„ã€‚</li>
<li>ä¸ºå®ç°ç²¾ç»†å±€éƒ¨æ§åˆ¶ï¼Œå¼•å…¥äº†å¤šç§æ©ç å½¢å¼å’Œä¸°å¯Œçš„è§†è§‰å¼•å¯¼æœºåˆ¶ã€‚</li>
<li>ReplaceAnyoneèƒ½æ— ç¼æ›¿æ¢æˆ–æ’å…¥è§’è‰²ï¼ŒåŒæ—¶ä¿æŒå§¿åŠ¿è¿åŠ¨å’Œå¤–è§‚ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ä»…é€‚ç”¨äºä¼ ç»Ÿçš„3D-UNetåŸºç¡€æ¨¡å‹ï¼Œä¹Ÿé€‚ç”¨äºDiT-basedè§†é¢‘æ¨¡å‹ï¼Œå¦‚Wan2.1ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.19911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f2de81fc88ef8bdd3059f073c63be93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc6ce7af988fa9e983a747c34e839ed4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ede94b47fc530380b5aed1cadab15da9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cfa5a7fbe79221e5b437f60379b972bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-57189adf87590c97692f3c707a276f4f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-246e9b7a85f96adb40cc36219d2291b0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-09/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-09/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-09/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-aac96b3ebfbae988da12a816938a33ca.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-09  Active Sampling for MRI-based Sequential Decision Making
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-09/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2ad56f32c9dc60dd7bad97809a6d3e2d.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-09  MAISY Motion-Aware Image SYnthesis for MedicalImage Motion Correction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17663.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
