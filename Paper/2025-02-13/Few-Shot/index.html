<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Explanation based In-Context Demonstrations Retrieval for Multilingual   Grammatical Error Correction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-80d8acb33bdcaba3f7608b2be4ffc7a9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-13-æ›´æ–°"><a href="#2025-02-13-æ›´æ–°" class="headerlink" title="2025-02-13 æ›´æ–°"></a>2025-02-13 æ›´æ–°</h1><h2 id="Explanation-based-In-Context-Demonstrations-Retrieval-for-Multilingual-Grammatical-Error-Correction"><a href="#Explanation-based-In-Context-Demonstrations-Retrieval-for-Multilingual-Grammatical-Error-Correction" class="headerlink" title="Explanation based In-Context Demonstrations Retrieval for Multilingual   Grammatical Error Correction"></a>Explanation based In-Context Demonstrations Retrieval for Multilingual   Grammatical Error Correction</h2><p><strong>Authors:Wei Li, Wen Luo, Guangyue Peng, Houfeng Wang</strong></p>
<p>Grammatical error correction (GEC) aims to correct grammatical, spelling, and semantic errors in natural language text. With the growing of large language models (LLMs), direct text generation has gradually become the focus of the GEC methods, and few-shot in-context learning presents a cost-effective solution. However, selecting effective in-context examples remains challenging, as the similarity between input texts does not necessarily correspond to similar grammatical error patterns. In this paper, we propose a novel retrieval method based on natural language grammatical error explanations (GEE) to address this issue. Our method retrieves suitable few-shot demonstrations by matching the GEE of the test input with that of pre-constructed database samples, where explanations for erroneous samples are generated by LLMs. We conducted multilingual GEC few-shot experiments on both major open-source and closed-source LLMs. Experiments across five languages show that our method outperforms existing semantic and BM25-based retrieval techniques, without requiring additional training or language adaptation. This also suggests that matching error patterns is key to selecting examples. </p>
<blockquote>
<p>è¯­æ³•é”™è¯¯ä¿®æ­£ï¼ˆGECï¼‰æ—¨åœ¨ä¿®æ­£è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­çš„è¯­æ³•ã€æ‹¼å†™å’Œè¯­ä¹‰é”™è¯¯ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¢é•¿ï¼Œç›´æ¥æ–‡æœ¬ç”Ÿæˆé€æ¸æˆä¸ºGECæ–¹æ³•çš„é‡ç‚¹ï¼Œè€Œå°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ æä¾›äº†ä¸€ç§å…·æœ‰æˆæœ¬æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œé€‰æ‹©æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè¾“å…¥æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§å¹¶ä¸ä¸€å®šå¯¹åº”ç›¸ä¼¼çš„è¯­æ³•é”™è¯¯æ¨¡å¼ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­æå‡ºäº†ä¸€ç§åŸºäºè‡ªç„¶è¯­è¨€è¯­æ³•é”™è¯¯è§£é‡Šï¼ˆGEEï¼‰çš„æ£€ç´¢æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åŒ¹é…æµ‹è¯•è¾“å…¥çš„GEEä¸é¢„å…ˆæ„å»ºçš„æ•°æ®åº“æ ·æœ¬çš„GEEæ¥æ£€ç´¢åˆé€‚çš„å°‘æ ·æœ¬æ¼”ç¤ºï¼Œå…¶ä¸­é”™è¯¯æ ·æœ¬çš„è§£é‡Šæ˜¯ç”±LLMç”Ÿæˆçš„ã€‚æˆ‘ä»¬åœ¨ä¸»è¦çš„å¼€æºå’Œé—­æºLLMä¸Šè¿›è¡Œäº†å¤šè¯­è¨€GECå°‘æ ·æœ¬å®éªŒã€‚è·¨è¶Šäº”ç§è¯­è¨€çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„è¯­ä¹‰å’ŒåŸºäºBM25çš„æ£€ç´¢æŠ€æœ¯ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–è¯­è¨€é€‚åº”ã€‚è¿™ä¹Ÿè¡¨æ˜åŒ¹é…é”™è¯¯æ¨¡å¼æ˜¯é€‰æ‹©ç¤ºä¾‹çš„å…³é”®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08507v1">PDF</a> Accepted by NAACL 2025 main conference</p>
<p><strong>Summary</strong><br>è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­çš„è¯­æ³•é”™è¯¯ä¿®æ­£ï¼ˆGECï¼‰æ—¨åœ¨çº æ­£è¯­æ³•ã€æ‹¼å†™å’Œè¯­ä¹‰é”™è¯¯ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•ï¼Œç›´æ¥æ–‡æœ¬ç”Ÿæˆé€æ¸æˆä¸ºGECæ–¹æ³•çš„é‡ç‚¹ï¼Œè€Œå°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ åˆ™æä¾›äº†å…·æœ‰æˆæœ¬æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œé€‰æ‹©æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡å®ä¾‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè¾“å…¥æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§å¹¶ä¸ä¸€å®šå¯¹åº”ç›¸ä¼¼çš„è¯­æ³•é”™è¯¯æ¨¡å¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè‡ªç„¶è¯­è¨€è¯­æ³•é”™è¯¯è§£é‡Šï¼ˆGEEï¼‰çš„æ£€ç´¢æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åŒ¹é…æµ‹è¯•è¾“å…¥çš„GEEä¸é¢„æ„å»ºçš„æ•°æ®åº“æ ·æœ¬ï¼Œæ£€ç´¢åˆé€‚çš„å°‘æ ·æœ¬ç¤ºä¾‹ï¼Œå…¶ä¸­é”™è¯¯æ ·æœ¬çš„è§£é‡Šæ˜¯ç”±LLMç”Ÿæˆçš„ã€‚æˆ‘ä»¬åœ¨ä¸»è¦å¼€æºå’Œé—­æºçš„LLMä¸Šè¿›è¡Œäº†å¤šè¯­è¨€GECå°‘æ ·æœ¬å®éªŒã€‚è·¨è¶Šäº”ç§è¯­è¨€çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„è¯­ä¹‰å’ŒBM25åŸºç¡€æ£€ç´¢æŠ€æœ¯ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–è¯­è¨€é€‚åº”ã€‚è¿™ä¹Ÿè¡¨æ˜åŒ¹é…é”™è¯¯æ¨¡å¼æ˜¯é€‰æ‹©ç¤ºä¾‹çš„å…³é”®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GECæ—¨åœ¨çº æ­£è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­çš„è¯­æ³•ã€æ‹¼å†™å’Œè¯­ä¹‰é”™è¯¯ã€‚</li>
<li>éšç€LLMçš„å‘å±•ï¼Œç›´æ¥æ–‡æœ¬ç”Ÿæˆæˆä¸ºGECæ–¹æ³•çš„é‡ç‚¹ï¼Œå°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ æä¾›æˆæœ¬æ•ˆç›Šè§£å†³æ–¹æ¡ˆã€‚</li>
<li>é€‰æ‹©æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡å®ä¾‹å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè¾“å…¥æ–‡æœ¬ç›¸ä¼¼æ€§ä¸ä¸€å®šå¯¹åº”ç›¸ä¼¼çš„è¯­æ³•é”™è¯¯æ¨¡å¼ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºGEEçš„æ£€ç´¢æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åŒ¹é…æµ‹è¯•è¾“å…¥çš„GEEä¸é¢„æ„å»ºæ•°æ®åº“æ ·æœ¬è¿›è¡Œæ£€ç´¢ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§è¯­è¨€ä¸Šå‡ä¼˜äºç°æœ‰è¯­ä¹‰å’ŒBM25åŸºç¡€æ£€ç´¢æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08507">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bba5ff79cc04768b1ee6f363fe5d75fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9264654bc5093f0686d4831d9a32b813.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cba8b3293070385218ad7bba4215f106.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcc7da750505da19c6dafe5ee22f44b5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MEMHD-Memory-Efficient-Multi-Centroid-Hyperdimensional-Computing-for-Fully-Utilized-In-Memory-Computing-Architectures"><a href="#MEMHD-Memory-Efficient-Multi-Centroid-Hyperdimensional-Computing-for-Fully-Utilized-In-Memory-Computing-Architectures" class="headerlink" title="MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for   Fully-Utilized In-Memory Computing Architectures"></a>MEMHD: Memory-Efficient Multi-Centroid Hyperdimensional Computing for   Fully-Utilized In-Memory Computing Architectures</h2><p><strong>Authors:Do Yeong Kang, Yeong Hwan Oh, Chanwook Hwang, Jinhee Kim, Kang Eun Jeon, Jong Hwan Ko</strong></p>
<p>The implementation of Hyperdimensional Computing (HDC) on In-Memory Computing (IMC) architectures faces significant challenges due to the mismatch between highdimensional vectors and IMC array sizes, leading to inefficient memory utilization and increased computation cycles. This paper presents MEMHD, a Memory-Efficient Multi-centroid HDC framework designed to address these challenges. MEMHD introduces a clustering-based initialization method and quantization aware iterative learning for multi-centroid associative memory. Through these approaches and its overall architecture, MEMHD achieves a significant reduction in memory requirements while maintaining or improving classification accuracy. Our approach achieves full utilization of IMC arrays and enables one-shot (or few-shot) associative search. Experimental results demonstrate that MEMHD outperforms state-of-the-art binary HDC models, achieving up to 13.69% higher accuracy with the same memory usage, or 13.25x more memory efficiency at the same accuracy level. Moreover, MEMHD reduces computation cycles by up to 80x and array usage by up to 71x compared to baseline IMC mapping methods when mapped to 128x128 IMC arrays, while significantly improving energy and computation cycle efficiency. </p>
<blockquote>
<p>å°†è¶…ç»´è®¡ç®—ï¼ˆHDCï¼‰åœ¨å†…å­˜è®¡ç®—ï¼ˆIMCï¼‰æ¶æ„ä¸Šçš„å®ç°é¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ï¼Œè¿™æ˜¯ç”±äºé«˜ç»´å‘é‡ä¸IMCæ•°ç»„å¤§å°ä¹‹é—´çš„ä¸åŒ¹é…å¯¼è‡´çš„ï¼Œä»è€Œå¯¼è‡´äº†å†…å­˜åˆ©ç”¨ç‡ä½ä¸‹å’Œè®¡ç®—å‘¨æœŸå¢åŠ ã€‚æœ¬æ–‡é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMEMHDçš„é«˜æ•ˆå†…å­˜å¤šä¸­å¿ƒHDCæ¡†æ¶ã€‚MEMHDå¼•å…¥äº†ä¸€ç§åŸºäºèšç±»çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œä»¥åŠé¢å‘å¤šä¸­å¿ƒå…³è”å†…å­˜çš„é‡åŒ–æ„ŸçŸ¥è¿­ä»£å­¦ä¹ ã€‚é€šè¿‡è¿™äº›æ–¹æ³•åŠå…¶æ•´ä½“æ¶æ„ï¼ŒMEMHDåœ¨ä¿æŒæˆ–æé«˜åˆ†ç±»å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜è¦æ±‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†IMCé˜µåˆ—çš„å®Œå…¨åˆ©ç”¨ï¼Œå¹¶å®ç°äº†ä¸€æ¬¡ï¼ˆæˆ–å°‘æ•°å‡ æ¬¡ï¼‰å…³è”æœç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMEMHDä¼˜äºæœ€æ–°çš„äºŒè¿›åˆ¶HDCæ¨¡å‹ï¼Œåœ¨ç›¸åŒå†…å­˜ä½¿ç”¨é‡çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®ç‡æé«˜äº†é«˜è¾¾13.69%ï¼Œæˆ–åœ¨ç›¸åŒå‡†ç¡®ç‡æ°´å¹³ä¸‹ï¼Œå†…å­˜ä½¿ç”¨æ•ˆç‡æé«˜äº†13.25å€ã€‚æ­¤å¤–ï¼Œä¸åŸºå‡†IMCæ˜ å°„æ–¹æ³•ç›¸æ¯”ï¼ŒMEMHDåœ¨æ˜ å°„åˆ°128x128 IMCé˜µåˆ—æ—¶ï¼Œè®¡ç®—å‘¨æœŸå‡å°‘äº†é«˜è¾¾80å€ï¼Œé˜µåˆ—ä½¿ç”¨ç‡å‡å°‘äº†é«˜è¾¾71å€ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†èƒ½æºå’Œè®¡ç®—å‘¨æœŸçš„æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07834v1">PDF</a> Accepted to appear at DATE 2025</p>
<p><strong>Summary</strong><br>     å†…å­˜é«˜æ•ˆçš„å¤šä¸­å¿ƒè¶…ç»´è®¡ç®—æ¡†æ¶MEMHDè§£å†³äº†é«˜ç»´å‘é‡ä¸å†…å­˜è®¡ç®—é˜µåˆ—å¤§å°ä¸åŒ¹é…çš„é—®é¢˜ï¼Œæé«˜äº†å†…å­˜åˆ©ç”¨ç‡å¹¶å‡å°‘äº†è®¡ç®—å‘¨æœŸã€‚é€šè¿‡èšç±»åˆå§‹åŒ–æ–¹æ³•å’Œé‡åŒ–æ„ŸçŸ¥è¿­ä»£å­¦ä¹ ç­‰æ–¹æ³•ï¼ŒMEMHDåœ¨ç»´æŒæˆ–æé«˜åˆ†ç±»å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—é™ä½äº†å†…å­˜è¦æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMEMHDç›¸è¾ƒäºæœ€å…ˆè¿›çš„å…¨äºŒè¿›åˆ¶è¶…ç»´è®¡ç®—æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨ç›¸åŒçš„å†…å­˜ä½¿ç”¨é‡ä¸‹å‡†ç¡®ç‡æé«˜äº†é«˜è¾¾13.69%ï¼Œæˆ–åœ¨ç›¸åŒå‡†ç¡®ç‡æ°´å¹³ä¸‹å†…å­˜æ•ˆç‡æé«˜äº†é«˜è¾¾13.25å€ã€‚æ­¤å¤–ï¼Œç›¸è¾ƒäºåŸºçº¿IMCæ˜ å°„æ–¹æ³•ï¼ŒMEMHDåœ¨è®¡ç®—å‘¨æœŸä¸Šå‡å°‘äº†é«˜è¾¾80å€ï¼Œåœ¨é˜µåˆ—ä½¿ç”¨ä¸Šå‡å°‘äº†é«˜è¾¾71å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MEMHDæ˜¯ä¸€ä¸ªé’ˆå¯¹å†…å­˜è®¡ç®—æ¶æ„çš„è¶…ç»´è®¡ç®—æ¡†æ¶ï¼Œè§£å†³äº†é«˜ç»´å‘é‡ä¸å†…å­˜è®¡ç®—é˜µåˆ—å¤§å°ä¸åŒ¹é…çš„é—®é¢˜ã€‚</li>
<li>MEMHDå¼•å…¥èšç±»åˆå§‹åŒ–æ–¹æ³•å’Œé‡åŒ–æ„ŸçŸ¥è¿­ä»£å­¦ä¹ æŠ€æœ¯ä»¥æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡è¿™äº›æŠ€æœ¯å’Œæ•´ä½“æ¶æ„ï¼ŒMEMHDæ˜¾è‘—é™ä½äº†å†…å­˜è¦æ±‚ï¼ŒåŒæ—¶ç»´æŒæˆ–æé«˜äº†åˆ†ç±»å‡†ç¡®ç‡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMEMHDç›¸è¾ƒäºç°æœ‰æŠ€æœ¯è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ›´é«˜çš„å†…å­˜æ•ˆç‡ã€‚</li>
<li>MEMHDèƒ½å¤Ÿå®ç°ä¸€æ¬¡æ€§æˆ–å°‘æ•°å‡ æ¬¡çš„å…³è”æœç´¢ã€‚</li>
<li>ä¸åŸºçº¿IMCæ˜ å°„æ–¹æ³•ç›¸æ¯”ï¼ŒMEMHDåœ¨è®¡ç®—å‘¨æœŸå’Œé˜µåˆ—ä½¿ç”¨ä¸Šå®ç°äº†æ˜¾è‘—ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07834">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-80d8acb33bdcaba3f7608b2be4ffc7a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf84dd9e22b49bf37db007f04a6f1a56.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7347ab6e2395e0afcc22e76f817f881b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0bbcb8c8557e13edf6e3f3d7390588c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-370527c4a43ef79a73bd3c06bd414b65.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d51c5d2e8a15a6a6801b3cc935c02a08.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="URECA-The-Chain-of-Two-Minimum-Set-Cover-Problems-exists-behind-Adaptation-to-Shifts-in-Semantic-Code-Search"><a href="#URECA-The-Chain-of-Two-Minimum-Set-Cover-Problems-exists-behind-Adaptation-to-Shifts-in-Semantic-Code-Search" class="headerlink" title="URECA: The Chain of Two Minimum Set Cover Problems exists behind   Adaptation to Shifts in Semantic Code Search"></a>URECA: The Chain of Two Minimum Set Cover Problems exists behind   Adaptation to Shifts in Semantic Code Search</h2><p><strong>Authors:Seok-Ung Choi, Joonghyuk Hahn, Yo-Sub Han</strong></p>
<p>Adaptation is to make model learn the patterns shifted from the training distribution. In general, this adaptation is formulated as the minimum entropy problem. However, the minimum entropy problem has inherent limitation â€“ shifted initialization cascade phenomenon. We extend the relationship between the minimum entropy problem and the minimum set cover problem via Lebesgue integral. This extension reveals that internal mechanism of the minimum entropy problem ignores the relationship between disentangled representations, which leads to shifted initialization cascade. From the analysis, we introduce a new clustering algorithm, Union-find based Recursive Clustering Algorithm~(URECA). URECA is an efficient clustering algorithm for the leverage of the relationships between disentangled representations. The update rule of URECA depends on Thresholdly-Updatable Stationary Assumption to dynamics as a released version of Stationary Assumption. This assumption helps URECA to transport disentangled representations with no errors based on the relationships between disentangled representations. URECA also utilize simulation trick to efficiently cluster disentangled representations. The wide range of evaluations show that URECA achieves consistent performance gains for the few-shot adaptation to diverse types of shifts along with advancement to State-of-The-Art performance in CoSQA in the scenario of query shift. </p>
<blockquote>
<p>é€‚åº”æ˜¯æŒ‡ä½¿æ¨¡å‹å­¦ä¹ ä»è®­ç»ƒåˆ†å¸ƒä¸­è½¬ç§»çš„æ¨¡å¼ã€‚é€šå¸¸ï¼Œè¿™ç§é€‚åº”è¢«åˆ¶å®šä¸ºæœ€å°ç†µé—®é¢˜ã€‚ç„¶è€Œï¼Œæœ€å°ç†µé—®é¢˜å…·æœ‰å›ºæœ‰çš„å±€é™æ€§â€”â€”è½¬ç§»åˆå§‹åŒ–çº§è”ç°è±¡ã€‚æˆ‘ä»¬é€šè¿‡å‹’è´æ ¼ç§¯åˆ†æ‰©å±•æœ€å°ç†µé—®é¢˜å’Œæœ€å°é›†è¦†ç›–é—®é¢˜ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§æ‰©å±•æ­ç¤ºäº†æœ€å°ç†µé—®é¢˜çš„å†…éƒ¨æœºåˆ¶å¿½ç•¥äº†è§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå¯¼è‡´è½¬ç§»åˆå§‹åŒ–çº§è”ã€‚é€šè¿‡åˆ†æï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„èšç±»ç®—æ³•â€”â€”åŸºäºè”åˆæŸ¥æ‰¾çš„é€’å½’èšç±»ç®—æ³•ï¼ˆURECAï¼‰ã€‚URECAæ˜¯ä¸€ç§åˆ©ç”¨è§£çº ç¼ è¡¨ç¤ºä¹‹é—´å…³ç³»çš„æœ‰æ•ˆèšç±»ç®—æ³•ã€‚URECAçš„æ›´æ–°è§„åˆ™å–å†³äºé˜ˆå€¼å¯æ›´æ–°ç¨³æ€å‡è®¾ï¼Œä½œä¸ºç¨³æ€å‡è®¾çš„å‘å¸ƒç‰ˆæœ¬ã€‚è¿™ä¸€å‡è®¾æœ‰åŠ©äºURECAåŸºäºè§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»æ— è¯¯åœ°ä¼ è¾“ã€‚URECAè¿˜ä½¿ç”¨ä»¿çœŸæŠ€å·§æœ‰æ•ˆåœ°èšç±»è§£çº ç¼ è¡¨ç¤ºã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼ŒURECAåœ¨å°‘é‡é€‚åº”å„ç§ç±»å‹çš„å˜åŒ–æ—¶å®ç°äº†æ€§èƒ½ä¸Šçš„æŒç»­å¢ç›Šï¼Œå¹¶åœ¨æŸ¥è¯¢å˜åŒ–çš„æƒ…å†µä¸‹æé«˜äº†CoSQAçš„æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07494v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ¨¡å‹é€‚åº”è®­ç»ƒåˆ†å¸ƒå˜åŒ–çš„é—®é¢˜è¢«ä¸€èˆ¬æ€§åœ°è¡¨è¿°ä¸ºæœ€å°ç†µé—®é¢˜ï¼Œä½†å­˜åœ¨å›ºæœ‰çš„é™åˆ¶â€”â€”åˆå§‹åŒ–çº§è”ç°è±¡ã€‚æœ¬æ–‡é€šè¿‡å‹’è´æ ¼ç§¯åˆ†æ‰©å±•äº†æœ€å°ç†µé—®é¢˜å’Œæœ€å°é›†è¦†ç›–é—®é¢˜ä¹‹é—´çš„å…³ç³»ï¼Œæ­ç¤ºäº†æœ€å°ç†µé—®é¢˜å†…åœ¨æœºåˆ¶å¿½è§†äº†è§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´åˆå§‹åŒ–çº§è”ã€‚åŸºäºæ­¤åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„èšç±»ç®—æ³•â€”â€”åŸºäºå¹¶æŸ¥é›†çš„é€’å½’èšç±»ç®—æ³•ï¼ˆURECAï¼‰ã€‚URECAæ˜¯ä¸€ç§é«˜æ•ˆçš„èšç±»ç®—æ³•ï¼Œèƒ½å¤Ÿåˆ©ç”¨è§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚å…¶æ›´æ–°è§„åˆ™ä¾èµ–äºé˜ˆå€¼å¯æ›´æ–°å¹³ç¨³å‡è®¾ï¼Œæœ‰åŠ©äºåŸºäºè§£çº ç¼ è¡¨ç¤ºçš„å…³ç³»è¿›è¡Œæ— è¯¯ä¼ è¾“ã€‚URECAè¿˜é‡‡ç”¨æ¨¡æ‹ŸæŠ€å·§ä»¥æœ‰æ•ˆåœ°å¯¹è§£çº ç¼ è¡¨ç¤ºè¿›è¡Œèšç±»ã€‚å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒURECAåœ¨å¤šç§ç±»å‹çš„è¿ç§»é€‚åº”ä¸­å®ç°äº†æ€§èƒ½æå‡ï¼Œå¹¶åœ¨æŸ¥è¯¢è¿ç§»çš„åœºæ™¯ä¸‹è¾¾åˆ°äº†CoSQAé¢†åŸŸçš„æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨¡å‹é€‚åº”è®­ç»ƒåˆ†å¸ƒå˜åŒ–çš„é—®é¢˜å¯è¡¨è¿°ä¸ºæœ€å°ç†µé—®é¢˜ï¼Œä½†å­˜åœ¨åˆå§‹åŒ–çº§è”ç°è±¡ã€‚</li>
<li>é€šè¿‡å‹’è´æ ¼ç§¯åˆ†æ‰©å±•äº†æœ€å°ç†µé—®é¢˜å’Œæœ€å°é›†è¦†ç›–é—®é¢˜ä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>æœ€å°ç†µé—®é¢˜å¿½è§†äº†è§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>æå‡ºäº†åŸºäºå¹¶æŸ¥é›†çš„é€’å½’èšç±»ç®—æ³•ï¼ˆURECAï¼‰ï¼Œæœ‰æ•ˆåˆ©ç”¨è§£çº ç¼ è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>URECAçš„æ›´æ–°è§„åˆ™ä¾èµ–äºé˜ˆå€¼å¯æ›´æ–°å¹³ç¨³å‡è®¾ï¼Œå®ç°æ— è¯¯ä¼ è¾“ã€‚</li>
<li>URECAé‡‡ç”¨æ¨¡æ‹ŸæŠ€å·§ä»¥æœ‰æ•ˆèšç±»è§£çº ç¼ è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07494">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4509df9a4a52b06f1645f7c64526a35c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afa1e055dfa31f474f2e5cf5fd543279.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Donâ€™t-Just-Demo-Teach-Me-the-Principles-A-Principle-Based-Multi-Agent-Prompting-Strategy-for-Text-Classification"><a href="#Donâ€™t-Just-Demo-Teach-Me-the-Principles-A-Principle-Based-Multi-Agent-Prompting-Strategy-for-Text-Classification" class="headerlink" title="Donâ€™t Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent   Prompting Strategy for Text Classification"></a>Donâ€™t Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent   Prompting Strategy for Text Classification</h2><p><strong>Authors:Peipei Wei, Dimitris Dimitriadis, Yan Xu, Mingwei Shen</strong></p>
<p>We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent prompting strategy for text classification. It first asks multiple LLM agents to independently generate candidate principles based on analysis of demonstration samples with or without labels, consolidates them into final principles via a finalizer agent, and then sends them to a classifier agent to perform downstream classification tasks. Extensive experiments on binary and multi-class classification datasets with different sizes of LLMs show that our approach not only achieves substantial performance gains (1.55% - 19.37%) over zero-shot prompting on macro-F1 score but also outperforms other strong baselines (CoT and stepback prompting). Principles generated by our approach help LLMs perform better on classification tasks than human crafted principles on two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach also shows on-par or better performance compared to demonstration-based few-shot prompting approaches, yet with substantially lower inference costs. Ablation studies show that label information and the multi-agent cooperative LLM framework play an important role in generating high-quality principles to facilitate downstream classification tasks. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†åŸºäºåŸåˆ™çš„æç¤ºï¼ˆPRINCIPLE-BASED PROMPTINGï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“æç¤ºç­–ç•¥ï¼Œç”¨äºæ–‡æœ¬åˆ†ç±»ã€‚å®ƒé¦–å…ˆè¦æ±‚å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“åŸºäºæœ‰æˆ–æ²¡æœ‰æ ‡ç­¾çš„æ¼”ç¤ºæ ·æœ¬è¿›è¡Œç‹¬ç«‹åˆ†æï¼Œç”Ÿæˆå€™é€‰åŸåˆ™ï¼Œå¹¶é€šè¿‡ç»ˆç»“è€…æ™ºèƒ½ä½“å°†å®ƒä»¬æ•´åˆä¸ºæœ€ç»ˆåŸåˆ™ï¼Œç„¶åå°†å…¶å‘é€åˆ°åˆ†ç±»å™¨æ™ºèƒ½ä½“æ‰§è¡Œä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ã€‚åœ¨äºŒå…ƒå’Œå¤šç±»åˆ†ç±»æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒï¼Œä»¥åŠä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹æ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…åœ¨å®è§‚F1åˆ†æ•°ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ˆ1.55%-19.3.3%ï¼‰ï¼Œè€Œä¸”è¿˜ä¼˜äºå…¶ä»–å¼ºå¤§çš„åŸºçº¿ï¼ˆå¦‚è¿è´¯æ€§æç¤ºå’Œé€€æ­¥æç¤ºï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„åŸåˆ™æœ‰åŠ©äºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”ä¸¤ä¸ªç§æœ‰æ•°æ®é›†ä¸Šçš„äººå·¥åŸåˆ™è¡¨ç°å¾—æ›´å¥½ã€‚æˆ‘ä»¬çš„å¤šæ™ºèƒ½ä½“åŸºäºåŸåˆ™çš„æç¤ºæ–¹æ³•è¿˜æ˜¾ç¤ºå‡ºä¸åŸºäºæ¼”ç¤ºçš„å°‘é‡æç¤ºæ–¹æ³•ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†æ¨ç†æˆæœ¬ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œæ ‡ç­¾ä¿¡æ¯å’Œå¤šæ™ºèƒ½ä½“åˆä½œçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶åœ¨ç”Ÿæˆé«˜è´¨é‡åŸåˆ™ä»¥ä¿ƒè¿›ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­èµ·ç€é‡è¦ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07165v1">PDF</a> To be published in AAAI 2025 Workshop on Advancing LLM-Based   Multi-Agent Collaboration</p>
<p><strong>Summary</strong></p>
<p>åŸºäºåŸåˆ™çš„å¤šæ™ºèƒ½ä½“æç¤ºç­–ç•¥ä¸ºæ–‡æœ¬åˆ†ç±»æä¾›äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“æç¤ºæ–¹æ³•ã€‚è¯¥ç­–ç•¥è®©å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“ç‹¬ç«‹ç”ŸæˆåŸºäºæ ·æœ¬åˆ†æçš„åŸåˆ™å€™é€‰ï¼Œé€šè¿‡æ•´åˆå™¨æ™ºèƒ½ä½“åˆå¹¶æˆæœ€ç»ˆåŸåˆ™ï¼Œå¹¶å‘é€ç»™åˆ†ç±»å™¨æ™ºèƒ½ä½“æ‰§è¡Œä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äºŒå…ƒåŠå¤šç±»åˆ«åˆ†ç±»æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå®ç°äº†å¯è§‚çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†é›¶å°„æç¤ºæ–¹æ³•å’Œå…¶å®ƒå¼ºå¤§çš„åŸºçº¿æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç”Ÿæˆçš„åŸåˆ™æœ‰åŠ©äºLLMåœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¶…è¶Šäººç±»åˆ¶å®šçš„åŸåˆ™ã€‚æ­¤å¤–ï¼ŒåŸºäºå¤šæ™ºèƒ½ä½“çš„åŸåˆ™æç¤ºæ–¹æ³•å±•ç°å‡ºä¸åŸºäºæ¼”ç¤ºçš„å°‘é‡æ ·æœ¬æç¤ºæ–¹æ³•ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†æ¨ç†æˆæœ¬ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œæ ‡ç­¾ä¿¡æ¯å’Œå¤šæ™ºèƒ½ä½“åˆä½œæ¡†æ¶åœ¨ç”Ÿæˆé«˜è´¨é‡åŸåˆ™ä»¥ä¿ƒè¿›ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­èµ·åˆ°äº†é‡è¦ä½œç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PRINCIPLE-BASED PROMPTINGæ˜¯ä¸€ç§å¤šæ™ºèƒ½ä½“æç¤ºç­–ç•¥ï¼Œç”¨äºæ–‡æœ¬åˆ†ç±»ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¤šä¸ªLLMæ™ºèƒ½ä½“ç‹¬ç«‹ç”ŸæˆåŸåˆ™å€™é€‰ï¼Œç»æ•´åˆåç”¨äºä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åˆ†ç±»æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
<li>ä¸é›¶å°„æç¤ºå’Œå…¶å®ƒåŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è¡¨ç°æ›´ä¼˜ã€‚</li>
<li>è¯¥æ–¹æ³•ç”Ÿæˆçš„åŸåˆ™æœ‰åŠ©äºLLMåœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¶…è¶Šäººç±»åˆ¶å®šçš„åŸåˆ™ã€‚</li>
<li>ä¸åŸºäºæ¼”ç¤ºçš„å°‘é‡æ ·æœ¬æç¤ºæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•çš„æ€§èƒ½ç›¸å½“æˆ–æ›´å¥½ï¼ŒåŒæ—¶é™ä½äº†æ¨ç†æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec9253093f51346b9c445ca1d0b66b97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-469a46aa9405519443472793417bf68b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22b851e40c5825b83379aac99f7b33b1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Few-Shot-Multi-Human-Neural-Rendering-Using-Geometry-Constraints"><a href="#Few-Shot-Multi-Human-Neural-Rendering-Using-Geometry-Constraints" class="headerlink" title="Few-Shot Multi-Human Neural Rendering Using Geometry Constraints"></a>Few-Shot Multi-Human Neural Rendering Using Geometry Constraints</h2><p><strong>Authors:Qian li, Victoria FernÃ ndez Abrevaya, Franck Multon, Adnane Boukhayma</strong></p>
<p>We present a method for recovering the shape and radiance of a scene consisting of multiple people given solely a few images. Multi-human scenes are complex due to additional occlusion and clutter. For single-human settings, existing approaches using implicit neural representations have achieved impressive results that deliver accurate geometry and appearance. However, it remains challenging to extend these methods for estimating multiple humans from sparse views. We propose a neural implicit reconstruction method that addresses the inherent challenges of this task through the following contributions: First, we propose to use geometry constraints by exploiting pre-computed meshes using a human body model (SMPL). Specifically, we regularize the signed distances using the SMPL mesh and leverage bounding boxes for improved rendering. Second, we propose a ray regularization scheme to minimize rendering inconsistencies, and a saturation regularization for robust optimization in variable illumination. Extensive experiments on both real and synthetic datasets demonstrate the benefits of our approach and show state-of-the-art performance against existing neural reconstruction methods. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»…é€šè¿‡å°‘é‡å›¾åƒæ¢å¤ç”±å¤šäººç»„æˆçš„åœºæ™¯çš„å½¢çŠ¶å’Œè¾å°„äº®åº¦çš„æ–¹æ³•ã€‚å¤šäººåœºæ™¯ç”±äºé¢å¤–çš„é®æŒ¡å’Œæ‚ä¹±è€Œæ›´åŠ å¤æ‚ã€‚å¯¹äºå•äººè®¾ç½®ï¼Œä½¿ç”¨éšå¼ç¥ç»è¡¨ç¤ºæ–¹æ³•çš„ç°æœ‰æŠ€æœ¯å·²ç»å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œèƒ½å¤Ÿå‡†ç¡®æä¾›å‡ ä½•ç»“æ„å’Œå¤–è§‚ã€‚ç„¶è€Œï¼Œä»ç¨€ç–è§†è§’ä¼°è®¡å¤šä¸ªè¡Œäººä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§éšå¼ç¥ç»é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡ä»¥ä¸‹è´¡çŒ®æ¥è§£å†³æ­¤ä»»åŠ¡å›ºæœ‰çš„æŒ‘æˆ˜ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨äººä½“æ¨¡å‹ï¼ˆSMPLï¼‰çš„é¢„å…ˆè®¡ç®—ç½‘æ ¼æå‡ºä½¿ç”¨å‡ ä½•çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç”¨SMPLç½‘æ ¼è§„åˆ™åŒ–ç¬¦å·è·ç¦»å¹¶åˆ©ç”¨è¾¹ç•Œæ¡†è¿›è¡Œæ”¹è¿›æ¸²æŸ“ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…‰çº¿è§„åˆ™åŒ–æ–¹æ¡ˆï¼Œä»¥æœ€å°åŒ–æ¸²æŸ“çš„ä¸ä¸€è‡´æ€§ï¼Œå¹¶æå‡ºäº†ç”¨äºå¯å˜å…‰ç…§çš„ç¨³å¥ä¼˜åŒ–çš„é¥±å’Œåº¦è§„åˆ™åŒ–æ–¹æ³•ã€‚åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„å¥½å¤„ï¼Œä¸ç°æœ‰çš„ç¥ç»é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07140v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ä»…é€šè¿‡å°‘é‡å›¾åƒæ¢å¤å¤šäººåœºæ™¯çš„å½¢çŠ¶å’Œè¾å°„åº¦çš„æ–¹æ³•ã€‚é’ˆå¯¹å¤šäººç‰©åœºæ™¯é¢å¤–çš„é®æŒ¡å’Œæ‚ä¹±å¸¦æ¥çš„å¤æ‚æ€§ï¼Œæå‡ºä¸€ç§ç¥ç»éšå¼é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨äººä½“æ¨¡å‹ï¼ˆSMPLï¼‰çš„é¢„è®¡ç®—ç½‘æ ¼å®ç°å‡ ä½•çº¦æŸï¼Œé€šè¿‡æ­£åˆ™åŒ–æœ‰ç¬¦å·è·ç¦»å’Œåˆ©ç”¨è¾¹ç•Œæ¡†æ”¹è¿›æ¸²æŸ“ã€‚åŒæ—¶ï¼Œæå‡ºä¸€ç§å°„çº¿æ­£åˆ™åŒ–æ–¹æ¡ˆæ¥æœ€å°åŒ–æ¸²æŸ“ä¸ä¸€è‡´æ€§ï¼Œä»¥åŠä¸€ç§é¥±å’Œæ­£åˆ™åŒ–ä»¥åœ¨å¯å˜ç…§æ˜ä¸­å®ç°ç¨³å¥ä¼˜åŒ–ã€‚åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„å¥½å¤„å¹¶æ˜¾ç¤ºå‡ºä¸ç°æœ‰ç¥ç»é‡å»ºæ–¹æ³•ç›¸æ¯”çš„å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºä¸€ç§é’ˆå¯¹å¤šäººç‰©åœºæ™¯çš„ç¥ç»éšå¼é‡å»ºæ–¹æ³•ï¼Œè§£å†³ä»ç¨€ç–è§†è§’ä¼°è®¡å¤šä¸ªäººçš„æŒ‘æˆ˜ã€‚</li>
<li>åˆ©ç”¨äººä½“æ¨¡å‹ï¼ˆSMPLï¼‰çš„é¢„è®¡ç®—ç½‘æ ¼å®ç°å‡ ä½•çº¦æŸã€‚</li>
<li>é€šè¿‡æ­£åˆ™åŒ–æœ‰ç¬¦å·è·ç¦»å’Œè¾¹ç•Œæ¡†æ”¹è¿›æ¸²æŸ“ã€‚</li>
<li>æå‡ºå°„çº¿æ­£åˆ™åŒ–æ–¹æ¡ˆä»¥æœ€å°åŒ–æ¸²æŸ“ä¸ä¸€è‡´æ€§ã€‚</li>
<li>é¥±å’Œæ­£åˆ™åŒ–ç”¨äºåœ¨å¯å˜ç…§æ˜ä¸­å®ç°ç¨³å¥ä¼˜åŒ–ã€‚</li>
<li>åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07140">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a5e6968e17b3ab43f978c5a975722e7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e373d66d6607deac5cb21e2ef4c9b1a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c0e1ba2d621a9bc66be03badcfc8bb50.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Model-Diffusion-for-Certifiable-Few-shot-Transfer-Learning"><a href="#Model-Diffusion-for-Certifiable-Few-shot-Transfer-Learning" class="headerlink" title="Model Diffusion for Certifiable Few-shot Transfer Learning"></a>Model Diffusion for Certifiable Few-shot Transfer Learning</h2><p><strong>Authors:Fady Rezk, Royson Lee, Henry Gouk, Timothy Hospedales, Minyoung Kim</strong></p>
<p>In modern large-scale deep learning, a prevalent and effective workflow for solving low-data problems is adapting powerful pre-trained foundation models (FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while empirically effective, the resulting solutions lack generalisation guarantees to certify their accuracy - which may be required for ethical or legal reasons prior to deployment in high-importance applications. In this paper we develop a novel transfer learning approach that is designed to facilitate non-vacuous learning theoretic generalisation guarantees for downstream tasks, even in the low-shot regime. Specifically, we first use upstream tasks to train a distribution over PEFT parameters. We then learn the downstream task by a sample-and-evaluate procedure â€“ sampling plausible PEFTs from the trained diffusion model and selecting the one with the highest likelihood on the downstream data. Crucially, this confines our model hypothesis to a finite set of PEFT samples. In contrast to learning in the typical continuous hypothesis spaces of neural network weights, this facilitates tighter risk certificates. We instantiate our bound and show non-trivial generalization guarantees compared to existing learning approaches which lead to vacuous bounds in the low-shot regime. </p>
<blockquote>
<p>åœ¨ç°ä»£å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œé’ˆå¯¹ä½æ•°æ®é—®é¢˜çš„ä¸€ç§æµè¡Œä¸”æœ‰æ•ˆçš„å·¥ä½œæµç¨‹æ˜¯é€šè¿‡å‚æ•°æœ‰æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰å°†å¼ºå¤§çš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰é€‚åº”åˆ°æ–°ä»»åŠ¡ä¸­ã€‚ç„¶è€Œï¼Œå°½ç®¡åœ¨ç»éªŒä¸Šæœ‰æ•ˆï¼Œä½†æ‰€å¾—è§£å†³æ–¹æ¡ˆç¼ºä¹æ³›åŒ–ä¿è¯æ¥è¯æ˜å…¶å‡†ç¡®æ€§ï¼Œè¿™å¯èƒ½ä¼šåœ¨éƒ¨ç½²åˆ°é«˜é‡è¦æ€§åº”ç”¨ä¹‹å‰å‡ºäºé“å¾·æˆ–æ³•å¾‹åŸå› è€Œè¦æ±‚è¯æ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°å‹è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨ä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡çš„éç©ºæ´å­¦ä¹ ç†è®ºæ³›åŒ–ä¿è¯ï¼Œå³ä½¿åœ¨ä½å°„å‡»æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¸Šæ¸¸ä»»åŠ¡æ¥è®­ç»ƒPEFTå‚æ•°çš„åˆ†å¸ƒã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡é‡‡æ ·å’Œè¯„ä¼°ç¨‹åºæ¥å­¦ä¹ ä¸‹æ¸¸ä»»åŠ¡â€”â€”ä»è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­é‡‡æ ·åˆç†çš„PEFTsï¼Œå¹¶é€‰æ‹©åœ¨ä¸‹æ¸¸æ•°æ®ä¸Šå¯èƒ½æ€§æœ€é«˜çš„ä¸€ä¸ªã€‚å…³é”®çš„æ˜¯ï¼Œè¿™å°†æˆ‘ä»¬çš„æ¨¡å‹å‡è®¾é™åˆ¶åœ¨PEFTæ ·æœ¬çš„æœ‰é™é›†åˆä¸­ã€‚ä¸åœ¨ç¥ç»ç½‘ç»œæƒé‡çš„å…¸å‹è¿ç»­å‡è®¾ç©ºé—´ä¸­å­¦ä¹ ä¸åŒï¼Œè¿™æœ‰åŠ©äºè·å¾—æ›´ä¸¥æ ¼çš„é£é™©è¯ä¹¦ã€‚æˆ‘ä»¬å®ä¾‹åŒ–æˆ‘ä»¬çš„ç•Œé™ï¼Œå¹¶æ˜¾ç¤ºå‡ºä¸éç©ºæ´æ³›åŒ–ä¿è¯çš„ç°æœ‰å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨ä½å°„å‡»æƒ…å†µä¸‹å…·æœ‰éç©ºæ´çš„æ³›åŒ–ä¿è¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06970v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¢„è®­ç»ƒæ¨¡å‹é€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰é€‚åº”æ–°ä»»åŠ¡ï¼Œæ˜¯ç°ä»£å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è§£å†³ä½æ•°æ®é—®é¢˜çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼Œå°½ç®¡è¿™ç§æ–¹æ³•åœ¨å®è·µä¸­æœ‰æ•ˆï¼Œä½†ç¼ºä¹æ³›åŒ–ä¿è¯æ¥éªŒè¯å…¶åœ¨é«˜ä¼˜å…ˆçº§åº”ç”¨éƒ¨ç½²å‰çš„å‡†ç¡®æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨ä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡çš„éç©ºæ´å­¦ä¹ ç†è®ºæ³›åŒ–ä¿è¯ï¼Œå³ä½¿åœ¨ä½èµ„æºæƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚é€šè¿‡ä¸Šæ¸¸ä»»åŠ¡è®­ç»ƒä¸€ä¸ªPEFTå‚æ•°çš„åˆ†å¸ƒï¼Œç„¶åé€šè¿‡é‡‡æ ·å’Œè¯„ä¼°ç¨‹åºå­¦ä¹ ä¸‹æ¸¸ä»»åŠ¡ï¼Œä»è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­é‡‡æ ·å¯èƒ½çš„PEFTsï¼Œå¹¶é€‰æ‹©åœ¨ä¸‹æ¸¸æ•°æ®ä¸Šå¯èƒ½æ€§æœ€é«˜çš„ä¸€ä¸ªã€‚é€šè¿‡å°†æ¨¡å‹å‡è®¾é™åˆ¶åœ¨PEFTæ ·æœ¬çš„æœ‰é™é›†åˆä¸­ï¼Œä¸ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œæƒé‡è¿ç»­å‡è®¾ç©ºé—´å­¦ä¹ ç›¸æ¯”ï¼Œè¿™æœ‰åŠ©äºè·å¾—æ›´ä¸¥æ ¼çš„é£é™©è¯ä¹¦ã€‚æˆ‘ä»¬å®ä¾‹åŒ–äº†æˆ‘ä»¬çš„ç•Œé™ï¼Œä¸ç°æœ‰å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨ä½èµ„æºæƒ…å†µä¸‹æä¾›äº†éç©ºæ´çš„æ³›åŒ–ä¿è¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°ä»£æ·±åº¦å­¦ä¹ ä¸­çš„ä½æ•°æ®é—®é¢˜å¯ä»¥é€šè¿‡é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰è§£å†³ã€‚</li>
<li>å°½ç®¡PEFTæ–¹æ³•åœ¨å®è·µä¸­æœ‰æ•ˆï¼Œä½†åœ¨é«˜ä¼˜å…ˆçº§åº”ç”¨éƒ¨ç½²å‰éœ€è¦æ³›åŒ–ä¿è¯æ¥éªŒè¯å…¶å‡†ç¡®æ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨ä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡çš„éç©ºæ´å­¦ä¹ ç†è®ºæ³›åŒ–ä¿è¯ã€‚</li>
<li>æ–¹æ³•é€šè¿‡ä¸Šæ¸¸ä»»åŠ¡è®­ç»ƒä¸€ä¸ªå…³äºPEFTå‚æ•°çš„åˆ†å¸ƒã€‚</li>
<li>é€šè¿‡é‡‡æ ·å’Œè¯„ä¼°ç¨‹åºå­¦ä¹ ä¸‹æ¸¸ä»»åŠ¡ï¼Œé‡‡æ ·å¯èƒ½çš„PEFTså¹¶ä»æ‰©æ•£æ¨¡å‹ä¸­é€‰å‡ºæœ€ä½³çš„ä¸€ä¸ªã€‚</li>
<li>å°†æ¨¡å‹å‡è®¾é™åˆ¶åœ¨PEFTæ ·æœ¬çš„æœ‰é™é›†åˆä¸­ï¼Œæœ‰åŠ©äºè·å¾—æ›´ä¸¥æ ¼çš„é£é™©è¯ä¹¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06970">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dceef0931cbc4df5ae2bc4c6c66e4d86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ab0a2857fde201b5d5a68d5a19ae3de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e6d2c391ed4dd4331466aec01ee1776.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23d65ea662ac8dc68d60342b4d591757.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Exploring-Few-Shot-Defect-Segmentation-in-General-Industrial-Scenarios-with-Metric-Learning-and-Vision-Foundation-Models"><a href="#Exploring-Few-Shot-Defect-Segmentation-in-General-Industrial-Scenarios-with-Metric-Learning-and-Vision-Foundation-Models" class="headerlink" title="Exploring Few-Shot Defect Segmentation in General Industrial Scenarios   with Metric Learning and Vision Foundation Models"></a>Exploring Few-Shot Defect Segmentation in General Industrial Scenarios   with Metric Learning and Vision Foundation Models</h2><p><strong>Authors:Tongkun Liu, Bing Li, Xiao Jin, Yupeng Shi, Qiuying Li, Xiang Wei</strong></p>
<p>Industrial defect segmentation is critical for manufacturing quality control. Due to the scarcity of training defect samples, few-shot semantic segmentation (FSS) holds significant value in this field. However, existing studies mostly apply FSS to tackle defects on simple textures, without considering more diverse scenarios. This paper aims to address this gap by exploring FSS in broader industrial products with various defect types. To this end, we contribute a new real-world dataset and reorganize some existing datasets to build a more comprehensive few-shot defect segmentation (FDS) benchmark. On this benchmark, we thoroughly investigate metric learning-based FSS methods, including those based on meta-learning and those based on Vision Foundation Models (VFMs). We observe that existing meta-learning-based methods are generally not well-suited for this task, while VFMs hold great potential. We further systematically study the applicability of various VFMs in this task, involving two paradigms: feature matching and the use of Segment Anything (SAM) models. We propose a novel efficient FDS method based on feature matching. Meanwhile, we find that SAM2 is particularly effective for addressing FDS through its video track mode. The contributed dataset and code will be available at: <a target="_blank" rel="noopener" href="https://github.com/liutongkun/GFDS">https://github.com/liutongkun/GFDS</a>. </p>
<blockquote>
<p>å·¥ä¸šç¼ºé™·åˆ†å‰²å¯¹äºåˆ¶é€ è´¨é‡æ§åˆ¶è‡³å…³é‡è¦ã€‚ç”±äºè®­ç»ƒç¼ºé™·æ ·æœ¬çš„ç¨€ç¼ºæ€§ï¼Œå°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆFSSï¼‰åœ¨è¯¥é¢†åŸŸå…·æœ‰é‡å¤§æ„ä¹‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç ”ç©¶å¤§å¤šå°†FSSåº”ç”¨äºç®€å•çº¹ç†ä¸Šçš„ç¼ºé™·æ£€æµ‹ï¼Œå¹¶æœªè€ƒè™‘æ›´å¤šæ ·åŒ–çš„åœºæ™¯ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡æ¢ç´¢FSSåœ¨æ›´å¹¿æ³›çš„å·¥ä¸šäº§å“ä¸­çš„å¤šç§ç¼ºé™·ç±»å‹æ¥è§£å†³è¿™ä¸€å·®è·ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªæ–°çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œå¹¶é‡ç»„äº†ä¸€äº›ç°æœ‰æ•°æ®é›†ä»¥å»ºç«‹æ›´å…¨é¢çš„å°‘æ•°ç¼ºé™·åˆ†å‰²ï¼ˆFDSï¼‰åŸºå‡†æµ‹è¯•ã€‚åœ¨è¿™ä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼Œæˆ‘ä»¬æ·±å…¥ç ”ç©¶äº†åŸºäºåº¦é‡å­¦ä¹ çš„FSSæ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºå…ƒå­¦ä¹ å’ŒåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬å‘ç°ç°æœ‰çš„åŸºäºå…ƒå­¦ä¹ çš„æ–¹æ³•é€šå¸¸ä¸é€‚åˆè¿™é¡¹ä»»åŠ¡ï¼Œè€ŒVFMså…·æœ‰å·¨å¤§æ½œåŠ›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç³»ç»Ÿåœ°ç ”ç©¶äº†å„ç§VFMsåœ¨æ­¤ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œæ¶‰åŠç‰¹å¾åŒ¹é…å’Œä½¿ç”¨Segment Anythingï¼ˆSAMï¼‰æ¨¡å‹çš„ä¸¤ç§èŒƒå¼ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç‰¹å¾åŒ¹é…çš„é«˜æ•ˆFDSæ–¹æ³•ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å‘ç°SAM2é€šè¿‡å…¶è§†é¢‘è·Ÿè¸ªæ¨¡å¼åœ¨è§£å†³FDSé—®é¢˜æ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚ç›¸å…³æ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/liutongkun/GFDS%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/liutongkun/GFDSä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01216v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨å·¥ä¸šç¼ºé™·åˆ†å‰²é¢†åŸŸä¸­çš„å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆFSSï¼‰é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ç®€å•çº¹ç†ç¼ºé™·ä¸Šï¼Œæœ¬æ–‡æ—¨åœ¨æ¢ç´¢FSSåœ¨æ›´å¹¿æ³›çš„å·¥ä¸šäº§å“ä¸­çš„å¤šæ ·åœºæ™¯åº”ç”¨ï¼Œå¹¶ä¸ºæ­¤è´¡çŒ®æ–°çš„çœŸå®ä¸–ç•Œæ•°æ®é›†å’Œæ„å»ºå…¨é¢çš„å°‘æ ·æœ¬ç¼ºé™·åˆ†å‰²ï¼ˆFDSï¼‰åŸºå‡†æµ‹è¯•é›†ã€‚é€šè¿‡å¯¹åŸºäºåº¦é‡å­¦ä¹ çš„FSSæ–¹æ³•è¿›è¡Œæ·±å…¥ç ”ç©¶ï¼Œå‘ç°åŸºäºå…ƒå­¦ä¹ çš„æ–¹æ³•ä¸é€‚ç”¨äºæ­¤ä»»åŠ¡ï¼Œè€ŒåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰çš„æ–¹æ³•å…·æœ‰æ½œåŠ›ã€‚åŒæ—¶ç³»ç»Ÿåœ°ç ”ç©¶äº†å„ç§VFMsåœ¨æ­¤ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¹¶åŸºäºç‰¹å¾åŒ¹é…æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„FDSæ–¹æ³•ã€‚æ­¤å¤–ï¼Œå‘ç°SAMæ¨¡å‹ä¸­çš„è§†é¢‘è·Ÿè¸ªæ¨¡å¼å¯¹äºè§£å†³FDSç‰¹åˆ«æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å·¥ä¸šç¼ºé™·åˆ†å‰²ä¸­ï¼Œå°æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆFSSï¼‰å…·æœ‰é‡è¦ä»·å€¼ï¼Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ç®€å•çº¹ç†ç¼ºé™·ä¸Šï¼Œæœ¬æ–‡æ—¨åœ¨æ‹“å®½å…¶åº”ç”¨èŒƒå›´ã€‚</li>
<li>è´¡çŒ®äº†æ–°çš„çœŸå®ä¸–ç•Œæ•°æ®é›†å’Œæ„å»ºäº†å…¨é¢çš„å°‘æ ·æœ¬ç¼ºé™·åˆ†å‰²ï¼ˆFDSï¼‰åŸºå‡†æµ‹è¯•é›†ã€‚</li>
<li>åŸºäºåº¦é‡å­¦ä¹ çš„FSSæ–¹æ³•è¢«æ·±å…¥ç ”ç©¶ï¼Œå‘ç°åŸºäºå…ƒå­¦ä¹ çš„æ–¹æ³•ä¸é€‚ç”¨äºæ­¤ä»»åŠ¡ã€‚</li>
<li>è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMsï¼‰åœ¨æ­¤ä»»åŠ¡ä¸­å±•ç°å‡ºæ½œåŠ›ã€‚</li>
<li>é’ˆå¯¹ä¸åŒVFMsçš„åº”ç”¨è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼ŒåŒ…æ‹¬ç‰¹å¾åŒ¹é…å’ŒSegment Anythingï¼ˆSAMï¼‰æ¨¡å‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç‰¹å¾åŒ¹é…çš„é«˜æ•ˆçš„FDSæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01216">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ea9a3135a407f73637fa36ba0c7a024d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-99d8a384eefdee79192c00ca6e1df719.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-311f2e2c682c470e30a72c9bdad79bd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af72cc79e3660d0f7d4d34c818820ef4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8167fb787c69aaf5d66852400b7e2063.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fb3494d0b537e648abfde399e6484f2.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Holistic-Semantic-Representation-for-Navigational-Trajectory-Generation"><a href="#Holistic-Semantic-Representation-for-Navigational-Trajectory-Generation" class="headerlink" title="Holistic Semantic Representation for Navigational Trajectory Generation"></a>Holistic Semantic Representation for Navigational Trajectory Generation</h2><p><strong>Authors:Ji Cao, Tongya Zheng, Qinghong Guo, Yu Wang, Junshu Dai, Shunyu Liu, Jie Yang, Jie Song, Mingli Song</strong></p>
<p>Trajectory generation has garnered significant attention from researchers in the field of spatio-temporal analysis, as it can generate substantial synthesized human mobility trajectories that enhance user privacy and alleviate data scarcity. However, existing trajectory generation methods often focus on improving trajectory generation quality from a singular perspective, lacking a comprehensive semantic understanding across various scales. Consequently, we are inspired to develop a HOlistic SEmantic Representation (HOSER) framework for navigational trajectory generation. Given an origin-and-destination (OD) pair and the starting time point of a latent trajectory, we first propose a Road Network Encoder to expand the receptive field of road- and zone-level semantics. Second, we design a Multi-Granularity Trajectory Encoder to integrate the spatio-temporal semantics of the generated trajectory at both the point and trajectory levels. Finally, we employ a Destination-Oriented Navigator to seamlessly integrate destination-oriented guidance. Extensive experiments on three real-world datasets demonstrate that HOSER outperforms state-of-the-art baselines by a significant margin. Moreover, the modelâ€™s performance in few-shot learning and zero-shot learning scenarios further verifies the effectiveness of our holistic semantic representation. </p>
<blockquote>
<p>è½¨è¿¹ç”Ÿæˆå·²å¼•èµ·æ—¶ç©ºåˆ†æé¢†åŸŸç ”ç©¶äººå‘˜çš„å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºå®ƒå¯ä»¥ç”Ÿæˆå¤§é‡åˆæˆçš„äººç±»ç§»åŠ¨è½¨è¿¹ï¼Œå¢å¼ºç”¨æˆ·éšç§å¹¶ç¼“è§£æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è½¨è¿¹ç”Ÿæˆæ–¹æ³•å¾€å¾€ä»å•ä¸€è§’åº¦ç€çœ¼äºæé«˜è½¨è¿¹ç”Ÿæˆè´¨é‡ï¼Œç¼ºä¹è·¨ä¸åŒå°ºåº¦çš„å…¨é¢è¯­ä¹‰ç†è§£ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å—åˆ°å¯å‘ï¼Œå¼€å‘äº†ä¸€ä¸ªç”¨äºå¯¼èˆªè½¨è¿¹ç”Ÿæˆçš„HOlistic SEmantic Representationï¼ˆHOSERï¼‰æ¡†æ¶ã€‚ç»™å®šèµ·ç‚¹å’Œç»ˆç‚¹ï¼ˆODï¼‰å¯¹ä»¥åŠæ½œåœ¨è½¨è¿¹çš„èµ·å§‹æ—¶é—´ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºä¸€ä¸ªé“è·¯ç½‘ç»œç¼–ç å™¨ï¼Œä»¥æ‰©å¤§é“è·¯å’ŒåŒºåŸŸçº§åˆ«çš„è¯­ä¹‰æ„Ÿå—é‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šç²’åº¦è½¨è¿¹ç¼–ç å™¨ï¼Œä»¥æ•´åˆç”Ÿæˆè½¨è¿¹åœ¨ç‚¹å’Œè½¨è¿¹ä¸¤ä¸ªçº§åˆ«çš„æ—¶ç©ºè¯­ä¹‰ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨ç›®çš„å¯¼å‘çš„å¯¼èˆªå™¨ï¼Œæ— ç¼é›†æˆä»¥ç›®çš„åœ°ä¸ºä¸­å¿ƒçš„å¯¼èˆªã€‚åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHOSERæ˜¾è‘—ä¼˜äºæœ€æ–°åŸºçº¿ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å°‘æ ·æœ¬å­¦ä¹ å’Œé›¶æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­çš„è¡¨ç°è¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æ•´ä½“è¯­ä¹‰è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02737v2">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„å¯¼èˆªè½¨è¿¹ç”Ÿæˆæ¡†æ¶HOSERï¼ˆHOlistic SEmantic Representationï¼‰ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†é“è·¯ç½‘ç»œç¼–ç å™¨å’Œå¤šç²’åº¦è½¨è¿¹ç¼–ç å™¨ï¼Œæ—¨åœ¨å…¨é¢ç†è§£ä¸åŒå°ºåº¦çš„è¯­ä¹‰ä¿¡æ¯ã€‚é€šè¿‡å¼•å…¥ç›®çš„åœ°å¯¼å‘å¯¼èˆªå™¨ï¼Œç”Ÿæˆæ›´ç¬¦åˆäººç±»å®é™…é©¾é©¶è¡Œä¸ºçš„è½¨è¿¹ã€‚åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒHOSERç›¸è¾ƒäºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•æœ‰ç€æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶åœ¨å°‘æ ·æœ¬å­¦ä¹ å’Œé›¶æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­è¯æ˜äº†å…¶æ•ˆèƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HOSERæ¡†æ¶ç»“åˆäº†é“è·¯ç½‘ç»œç¼–ç å™¨å’Œå¤šç²’åº¦è½¨è¿¹ç¼–ç å™¨ï¼Œæ—¨åœ¨å…¨é¢ç†è§£ä¸åŒå°ºåº¦çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡å¼•å…¥é“è·¯ç½‘ç»œç¼–ç å™¨ï¼Œæ‰©å¤§å¯¹é“è·¯å’ŒåŒºåŸŸçº§åˆ«è¯­ä¹‰çš„æ„Ÿå—é‡ã€‚</li>
<li>å¤šç²’åº¦è½¨è¿¹ç¼–ç å™¨èƒ½å¤Ÿæ•´åˆç”Ÿæˆçš„è½¨è¿¹åœ¨ç‚¹å’Œè½¨è¿¹ä¸¤ä¸ªå±‚æ¬¡ä¸Šçš„æ—¶ç©ºè¯­ä¹‰ã€‚</li>
<li>ç›®çš„åœ°å¯¼å‘å¯¼èˆªå™¨çš„å¼•å…¥ä½¿å¾—ç”Ÿæˆçš„è½¨è¿¹æ›´ç¬¦åˆäººç±»å®é™…é©¾é©¶è¡Œä¸ºã€‚</li>
<li>åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜HOSERç›¸è¾ƒäºå…¶ä»–æ–¹æ³•å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
<li>HOSERåœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02737">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-80424f36c8c9e99884d068cc5ac0f1be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56642d1816dcc57e2c7cda260022ddef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24ca6454840c08c68ce4aa5865168bbf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-589977983682146fe063ebdbe9fb5859.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aecd38687e7bdf493cb0e2ed03b3b86c.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="All-You-Need-in-Knowledge-Distillation-Is-a-Tailored-Coordinate-System"><a href="#All-You-Need-in-Knowledge-Distillation-Is-a-Tailored-Coordinate-System" class="headerlink" title="All You Need in Knowledge Distillation Is a Tailored Coordinate System"></a>All You Need in Knowledge Distillation Is a Tailored Coordinate System</h2><p><strong>Authors:Junjie Zhou, Ke Zhu, Jianxin Wu</strong></p>
<p>Knowledge Distillation (KD) is essential in transferring dark knowledge from a large teacher to a small student network, such that the student can be much more efficient than the teacher but with comparable accuracy. Existing KD methods, however, rely on a large teacher trained specifically for the target task, which is both very inflexible and inefficient. In this paper, we argue that a SSL-pretrained model can effectively act as the teacher and its dark knowledge can be captured by the coordinate system or linear subspace where the features lie in. We then need only one forward pass of the teacher, and then tailor the coordinate system (TCS) for the student network. Our TCS method is teacher-free and applies to diverse architectures, works well for KD and practical few-shot learning, and allows cross-architecture distillation with large capacity gap. Experiments show that TCS achieves significantly higher accuracy than state-of-the-art KD methods, while only requiring roughly half of their training time and GPU memory costs. </p>
<blockquote>
<p>çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰å¯¹äºå°†ä»å¤§å‹æ•™å¸ˆç½‘ç»œè½¬ç§»åˆ°å°å‹å­¦ç”Ÿç½‘ç»œä¸­çš„æš—çŸ¥è¯†è‡³å…³é‡è¦ï¼Œè¿™æ ·å­¦ç”Ÿå¯ä»¥æ¯”æ•™å¸ˆæ›´æœ‰æ•ˆç‡ï¼Œä½†å…·æœ‰ç›¸å½“çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„KDæ–¹æ³•ä¾èµ–äºä¸“é—¨ä¸ºç›®æ ‡ä»»åŠ¡è®­ç»ƒçš„å¤§å‹æ•™å¸ˆï¼Œè¿™æ—¢éå¸¸ä¸çµæ´»åˆæ•ˆç‡ä½ä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºSSLé¢„è®­ç»ƒæ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°ä½œä¸ºæ•™å¸ˆï¼Œå…¶æš—çŸ¥è¯†å¯ä»¥é€šè¿‡ç‰¹å¾æ‰€åœ¨çš„åæ ‡ç³»æˆ–çº¿æ€§å­ç©ºé—´æ¥æ•è·ã€‚ç„¶åæˆ‘ä»¬åªéœ€è¦æ•™å¸ˆçš„ä¸€æ¬¡å‰å‘ä¼ é€’ï¼Œç„¶åä¸ºå­¦ç”Ÿç½‘ç»œå®šåˆ¶åæ ‡ç³»ï¼ˆTCSï¼‰ã€‚æˆ‘ä»¬çš„TCSæ–¹æ³•æ— éœ€æ•™å¸ˆï¼Œé€‚ç”¨äºå„ç§æ¶æ„ï¼Œå¯¹äºKDå’Œå®ç”¨çš„å°‘æ ·æœ¬å­¦ä¹ æ•ˆæœå¾ˆå¥½ï¼Œå¹¶å…è®¸å…·æœ‰å¤§å®¹é‡å·®è·çš„è·¨æ¶æ„è’¸é¦ã€‚å®éªŒè¡¨æ˜ï¼ŒTCSæ–¹æ³•åœ¨å‡†ç¡®ç‡ä¸Šæ˜æ˜¾ä¼˜äºæœ€æ–°KDæ–¹æ³•ï¼ŒåŒæ—¶åªéœ€å¤§è‡´å‡åŠçš„è®­ç»ƒæ—¶é—´å’ŒGPUå†…å­˜æˆæœ¬ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.09388v2">PDF</a> Accepted by AAAI 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰åœ¨å°†å¤§å‹æ•™å¸ˆç½‘ç»œçš„æš—çŸ¥è¯†è½¬ç§»åˆ°å°å‹å­¦ç”Ÿç½‘ç»œä¸­çš„é‡è¦æ€§ï¼Œä½¿å¾—å­¦ç”Ÿç½‘ç»œå¯ä»¥åœ¨æ•ˆç‡ä¸Šæ¯”æ•™å¸ˆç½‘ç»œæ›´é«˜ï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„KDæ–¹æ³•ä¾èµ–äºé’ˆå¯¹ç›®æ ‡ä»»åŠ¡ä¸“é—¨è®­ç»ƒçš„å¤§å‹æ•™å¸ˆç½‘ç»œï¼Œè¿™æ—¢éå¸¸ä¸çµæ´»åˆæ•ˆç‡ä½ä¸‹ã€‚æœ¬æ–‡ä¸»å¼ ä½¿ç”¨SSLé¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºæ•™å¸ˆç½‘ç»œï¼Œé€šè¿‡ç‰¹å¾æ‰€åœ¨çš„åæ ‡ç³»æˆ–çº¿æ€§å­ç©ºé—´æ•è·å…¶æš—çŸ¥è¯†ã€‚åªéœ€æ•™å¸ˆç½‘ç»œçš„ä¸€æ¬¡å‰å‘ä¼ é€’ï¼Œç„¶åä¸ºå­¦ç”Ÿç½‘ç»œå®šåˆ¶åæ ‡ç³»ï¼ˆTCSï¼‰ã€‚æˆ‘ä»¬çš„TCSæ–¹æ³•æ— éœ€æ•™å¸ˆç½‘ç»œï¼Œé€‚ç”¨äºå„ç§æ¶æ„ï¼Œå¯¹äºKDå’Œå®é™…å°‘æ ·æœ¬å­¦ä¹ æ•ˆæœå¾ˆå¥½ï¼Œå¹¶å…è®¸è·¨æ¶æ„è’¸é¦ï¼Œå…·æœ‰è¾ƒå¤§çš„å®¹é‡å·®è·ã€‚å®éªŒè¡¨æ˜ï¼ŒTCSå®ç°äº†æ¯”ç°æœ‰KDæ–¹æ³•æ›´é«˜çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä»…éœ€å®ƒä»¬å¤§çº¦ä¸€åŠçš„è®­ç»ƒæ—¶é—´å’ŒGPUå†…å­˜æˆæœ¬ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰èƒ½æœ‰æ•ˆå°†å¤§å‹æ•™å¸ˆç½‘ç»œçš„æš—çŸ¥è¯†è½¬ç§»è‡³å°å‹å­¦ç”Ÿç½‘ç»œã€‚</li>
<li>ç°æœ‰KDæ–¹æ³•ä¾èµ–ä¸“é—¨è®­ç»ƒçš„æ•™å¸ˆç½‘ç»œï¼Œç¼ºä¹çµæ´»æ€§å’Œæ•ˆç‡ã€‚</li>
<li>SSLé¢„è®­ç»ƒæ¨¡å‹å¯æœ‰æ•ˆåœ°ä½œä¸ºæ•™å¸ˆç½‘ç»œã€‚</li>
<li>é€šè¿‡ç‰¹å¾æ‰€åœ¨çš„åæ ‡ç³»æˆ–çº¿æ€§å­ç©ºé—´æ•è·æ•™å¸ˆç½‘ç»œçš„æš—çŸ¥è¯†ã€‚</li>
<li>åªéœ€æ•™å¸ˆç½‘ç»œä¸€æ¬¡å‰å‘ä¼ é€’ï¼Œå®šåˆ¶åæ ‡ç³»ï¼ˆTCSï¼‰ä¸ºå­¦ç”Ÿç½‘ç»œã€‚</li>
<li>TCSæ–¹æ³•æ— éœ€æ•™å¸ˆç½‘ç»œï¼Œé€‚ç”¨äºå¤šç§æ¶æ„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.09388">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fc179e2864a57ed1e9a272a6e194b58b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2851a5433a84297e669cc17eb1804b2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b76fbf49d3c102fb870666a0516c5ab6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e2ee85537b0f8a2b0ed8e3bcdc34c628.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-829e0ef8897d47c82e9fc676aa5814aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff79d4a13f99916760db8a42c05d75cd.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Observe-Then-Act-Asynchronous-Active-Vision-Action-Model-for-Robotic-Manipulation"><a href="#Observe-Then-Act-Asynchronous-Active-Vision-Action-Model-for-Robotic-Manipulation" class="headerlink" title="Observe Then Act: Asynchronous Active Vision-Action Model for Robotic   Manipulation"></a>Observe Then Act: Asynchronous Active Vision-Action Model for Robotic   Manipulation</h2><p><strong>Authors:Guokang Wang, Hang Li, Shuyuan Zhang, Di Guo, Yanhong Liu, Huaping Liu</strong></p>
<p>In real-world scenarios, many robotic manipulation tasks are hindered by occlusions and limited fields of view, posing significant challenges for passive observation-based models that rely on fixed or wrist-mounted cameras. In this paper, we investigate the problem of robotic manipulation under limited visual observation and propose a task-driven asynchronous active vision-action model.Our model serially connects a camera Next-Best-View (NBV) policy with a gripper Next-Best Pose (NBP) policy, and trains them in a sensor-motor coordination framework using few-shot reinforcement learning. This approach allows the agent to adjust a third-person camera to actively observe the environment based on the task goal, and subsequently infer the appropriate manipulation actions.We trained and evaluated our model on 8 viewpoint-constrained tasks in RLBench. The results demonstrate that our model consistently outperforms baseline algorithms, showcasing its effectiveness in handling visual constraints in manipulation tasks. </p>
<blockquote>
<p>åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè®¸å¤šæœºå™¨äººæ“ä½œä»»åŠ¡å—åˆ°é®æŒ¡å’Œè§†é‡æœ‰é™çš„é˜»ç¢ï¼Œè¿™ç»™ä¾èµ–å›ºå®šæˆ–æ‰‹è…•å¼ç›¸æœºçš„åŸºäºè¢«åŠ¨è§‚å¯Ÿæ¨¡å‹å¸¦æ¥äº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨æœ‰é™è§†è§‰è§‚å¯Ÿä¸‹çš„æœºå™¨äººæ“ä½œé—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§ä»»åŠ¡é©±åŠ¨çš„å¼‚æ­¥ä¸»åŠ¨è§†è§‰åŠ¨ä½œæ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†ç›¸æœºçš„ä¸‹ä¸€ä¸ªæœ€ä½³è§†å›¾ï¼ˆNBVï¼‰ç­–ç•¥ä¸å¤¹å…·çš„ä¸‹ä¸€ä¸ªæœ€ä½³å§¿æ€ï¼ˆNBPï¼‰ç­–ç•¥ä¸²è”èµ·æ¥ï¼Œåœ¨ä¸€ä¸ªä¼ æ„Ÿå™¨-ç”µæœºåè°ƒæ¡†æ¶ä¸­ä½¿ç”¨å°‘é‡çš„å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚è¿™ç§æ–¹æ³•å…è®¸æ™ºèƒ½ä½“æ ¹æ®ä»»åŠ¡ç›®æ ‡ä¸»åŠ¨è°ƒæ•´ç¬¬ä¸‰äººç§°ç›¸æœºçš„è§†è§’æ¥è§‚å¯Ÿç¯å¢ƒï¼Œç„¶åæ¨æ–­é€‚å½“çš„æ“ä½œåŠ¨ä½œã€‚æˆ‘ä»¬åœ¨RLBenchçš„8ä¸ªè§†ç‚¹çº¦æŸä»»åŠ¡ä¸Šè®­ç»ƒå’Œè¯„ä¼°äº†æˆ‘ä»¬çš„æ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å§‹ç»ˆä¼˜äºåŸºçº¿ç®—æ³•ï¼Œå±•ç¤ºäº†åœ¨å¤„ç†æ“ä½œä»»åŠ¡ä¸­çš„è§†è§‰çº¦æŸæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.14891v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åœ¨æœ‰é™è§†è§‰è§‚å¯Ÿä¸‹çš„æœºå™¨äººæ“ä½œé—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§ä»»åŠ¡é©±åŠ¨çš„å¼‚æ­¥ä¸»åŠ¨è§†è§‰åŠ¨ä½œæ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¸²è”ç›¸æœºæœ€ä½³è§†è§’ï¼ˆNBVï¼‰æ”¿ç­–å’ŒæŠ“æ‰‹æœ€ä½³å§¿æ€ï¼ˆNBPï¼‰æ”¿ç­–ï¼Œåœ¨ä¼ æ„Ÿå™¨-ç”µæœºåè°ƒæ¡†æ¶ä¸­ä½¿ç”¨å°æ ·æœ¬å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚è¯¥æ–¹æ³•ä½¿æœºå™¨äººèƒ½å¤ŸåŸºäºä»»åŠ¡ç›®æ ‡ä¸»åŠ¨è°ƒæ•´ç¬¬ä¸‰äººç§°ç›¸æœºè§‚å¯Ÿç¯å¢ƒï¼Œå¹¶æ®æ­¤æ¨æ–­é€‚å½“çš„æ“ä½œåŠ¨ä½œã€‚åœ¨RLBenchçš„8ä¸ªè§†è§’å—é™ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹çš„ç»“æœè¡¨æ˜å…¶åœ¨å¤„ç†æ“ä½œä»»åŠ¡ä¸­çš„è§†è§‰çº¦æŸæ–¹é¢å§‹ç»ˆä¼˜äºåŸºå‡†ç®—æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœºå™¨äººæ“ä½œä»»åŠ¡åœ¨å®é™…åœºæ™¯ä¸­å¸¸å¸¸å—åˆ°é®æŒ¡å’Œè§†é‡é™åˆ¶çš„æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»»åŠ¡é©±åŠ¨çš„å¼‚æ­¥ä¸»åŠ¨è§†è§‰åŠ¨ä½œæ¨¡å‹ï¼Œè§£å†³æœ‰é™è§†è§‰è§‚å¯Ÿä¸‹çš„æœºå™¨äººæ“ä½œé—®é¢˜ã€‚</li>
<li>æ¨¡å‹é€šè¿‡ä¸²è”ç›¸æœºæœ€ä½³è§†è§’ï¼ˆNBVï¼‰æ”¿ç­–å’ŒæŠ“æ‰‹æœ€ä½³å§¿æ€ï¼ˆNBPï¼‰æ”¿ç­–ï¼Œä»¥åº”å¯¹è§†è§’å’Œæ“ä½œçº¦æŸã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨ä¼ æ„Ÿå™¨-ç”µæœºåè°ƒæ¡†æ¶ä¸­ä½¿ç”¨å°æ ·æœ¬å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚</li>
<li>æœºå™¨äººèƒ½å¤ŸåŸºäºä»»åŠ¡ç›®æ ‡ä¸»åŠ¨è°ƒæ•´ç›¸æœºè§‚å¯Ÿç¯å¢ƒã€‚</li>
<li>æ¨¡å‹åœ¨RLBenchçš„å¤šä¸ªè§†è§’å—é™ä»»åŠ¡ä¸­è¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œç»“æœä¼˜äºåŸºå‡†ç®—æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.14891">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-98feafc1c51d6658157a01eb7de228c8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-039cdd79b2b8a595052ec048e159ddc6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63003be4f18381d8fe99a01328fe6c01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-261c40f8a19841abc7a4e032f114d0c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aa866b6d69fd6cd15af3f508fabcbfb0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8dc9662a143f04bb19966e0decb61029.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fb8fdb02018337ef69d02ff5f14eb543.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Self-Harmonized-Chain-of-Thought"><a href="#Self-Harmonized-Chain-of-Thought" class="headerlink" title="Self-Harmonized Chain of Thought"></a>Self-Harmonized Chain of Thought</h2><p><strong>Authors:Ziqi Jin, Wei Lu</strong></p>
<p>Chain-of-thought (CoT) prompting has demonstrated the capacity of large language models to perform complex reasoning through intermediate steps. While effective, current CoT methods face challenges: Zero-shot-CoT can lead to reasoning errors, and Few-shot-CoT requires labor-intensive manual demonstrations. Auto-CoT attempts to address these issues by automatically generating diverse demonstrations, but this diversity can lead to inconsistent reasoning patterns. We propose ECHO (Self-Harmonized Chain of Thought), a novel method that unifies diverse solution paths into a consistent and effective reasoning pattern. ECHO employs an iterative process to refine and harmonize automatically generated demonstrations, mitigating the limitations of existing approaches. Our comprehensive experiments across arithmetic, commonsense, and symbolic reasoning tasks demonstrate that ECHO outperforms Auto-CoT by an average of 2.8%. These findings suggest that ECHO represents a significant step towards more robust and generalizable automated reasoning in large language models. </p>
<blockquote>
<p>æ€ç»´é“¾ï¼ˆCoTï¼‰æç¤ºå±•ç°äº†å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡ä¸­é—´æ­¥éª¤è¿›è¡Œå¤æ‚æ¨ç†çš„èƒ½åŠ›ã€‚è™½ç„¶ç°æœ‰CoTæ–¹æ³•æœ‰æ•ˆï¼Œä½†é¢ä¸´æŒ‘æˆ˜ï¼šé›¶é•œå¤´CoTå¯èƒ½å¯¼è‡´æ¨ç†é”™è¯¯ï¼Œè€Œå°‘é•œå¤´CoTéœ€è¦ç¹ççš„æ‰‹åŠ¨æ¼”ç¤ºã€‚Auto-CoTè¯•å›¾é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–çš„æ¼”ç¤ºæ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œä½†è¿™ç§å¤šæ ·æ€§å¯èƒ½å¯¼è‡´æ¨ç†æ¨¡å¼çš„ä¸ä¸€è‡´ã€‚æˆ‘ä»¬æå‡ºäº†ECHOï¼ˆè‡ªæˆ‘åè°ƒæ€ç»´é“¾ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å°†å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè·¯å¾„ç»Ÿä¸€ä¸ºä¸€è‡´æœ‰æ•ˆæ¨ç†æ¨¡å¼çš„æ–°æ–¹æ³•ã€‚ECHOé‡‡ç”¨è¿­ä»£è¿‡ç¨‹æ¥ä¼˜åŒ–å’Œåè°ƒè‡ªåŠ¨ç”Ÿæˆçš„æ¼”ç¤ºï¼Œç¼“è§£äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚æˆ‘ä»¬åœ¨ç®—æœ¯ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†ä»»åŠ¡ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒECHOçš„å¹³å‡æ€§èƒ½ä¼˜äºAuto-CoT 2.8%ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒECHOåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å®ç°æ›´ç¨³å¥å’Œå¯æ¨å¹¿çš„è‡ªåŠ¨åŒ–æ¨ç†æ–¹é¢è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.04057v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå±•ç°å‡ºäº†æ‰§è¡Œå¤æ‚æ¨ç†çš„èƒ½åŠ›ï¼Œé€šè¿‡ä¸­é—´æ­¥éª¤è¿›è¡Œã€‚å°½ç®¡ç°æœ‰CoTæ–¹æ³•æœ‰æ•ˆï¼Œä½†ä»é¢ä¸´æŒ‘æˆ˜ï¼šé›¶æ­¥CoTå¯èƒ½å¯¼è‡´æ¨ç†é”™è¯¯ï¼Œè€Œå°‘æ­¥CoTéœ€è¦ç¹ççš„æ‰‹åŠ¨æ¼”ç¤ºã€‚è‡ªåŠ¨CoTè¯•å›¾é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¤šæ ·çš„æ¼”ç¤ºæ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œä½†å…¶å¤šæ ·æ€§å¯èƒ½å¯¼è‡´æ¨ç†æ¨¡å¼çš„ä¸ä¸€è‡´ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºECHOï¼ˆè‡ªæˆ‘åè°ƒçš„é“¾å¼æ€ç»´ï¼‰çš„æ–°æ–¹æ³•ï¼Œå®ƒå°†ä¸åŒçš„è§£å†³æ–¹æ¡ˆè·¯å¾„ç»Ÿä¸€ä¸ºä¸€ä¸ªä¸€è‡´ä¸”æœ‰æ•ˆçš„æ¨ç†æ¨¡å¼ã€‚ECHOé‡‡ç”¨è¿­ä»£è¿‡ç¨‹æ¥ä¼˜åŒ–å’Œåè°ƒè‡ªåŠ¨ç”Ÿæˆçš„æ¼”ç¤ºï¼Œç¼“è§£äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚åœ¨ç®—æœ¯ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†ä»»åŠ¡ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒECHOçš„å¹³å‡æ€§èƒ½æ¯”è‡ªåŠ¨CoTæé«˜äº†2.8%ã€‚è¿™è¡¨æ˜ECHOåœ¨æœç€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ›´ç¨³å¥å’Œæ›´é€šç”¨çš„è‡ªåŠ¨åŒ–æ¨ç†è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå¤§å‹è¯­è¨€æ¨¡å‹æ‰§è¡Œå¤æ‚æ¨ç†çš„ä¸­é—´æ­¥éª¤èƒ½åŠ›ã€‚</li>
<li>å½“å‰CoTæ–¹æ³•é¢ä¸´æ¨ç†é”™è¯¯å’Œéœ€è¦ç¹çæ‰‹åŠ¨æ¼”ç¤ºçš„é—®é¢˜ã€‚</li>
<li>è‡ªåŠ¨CoTæ–¹æ³•è¯•å›¾é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¤šæ ·çš„æ¼”ç¤ºæ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œä½†å¯èƒ½å¯¼è‡´æ¨ç†æ¨¡å¼çš„ä¸ä¸€è‡´ã€‚</li>
<li>ECHOï¼ˆè‡ªæˆ‘åè°ƒçš„é“¾å¼æ€ç»´ï¼‰æå‡ºä¸€ç§å°†ä¸åŒè§£å†³æ–¹æ¡ˆè·¯å¾„ç»Ÿä¸€ä¸ºä¸€è‡´ä¸”æœ‰æ•ˆæ¨ç†æ¨¡å¼çš„æ–°æ–¹æ³•ã€‚</li>
<li>ECHOé‡‡ç”¨è¿­ä»£è¿‡ç¨‹ä¼˜åŒ–å’Œåè°ƒè‡ªåŠ¨ç”Ÿæˆçš„æ¼”ç¤ºã€‚</li>
<li>åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒECHOçš„æ€§èƒ½ä¼˜äºè‡ªåŠ¨CoTã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.04057">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52f615c04b189b74241460464ca4ef67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a38b8415d4b737fce0ce40422b6ac02d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4898fb4f2c26baadec0ae3ba02bc35bc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1591e92d90782abd2ad4144391de8f73.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-42702818ec49ca577b43d88be668d7aa.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Demonstration of Fourier-domain Quantum Optical Coherence Tomography for   a fast tomographic quantum imaging
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-04fc13813f6549fb5d8d50b7fb684543.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Learning in Markets with Heterogeneous Agents Dynamics and Survival of   Bayesian vs. No-Regret Learners
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">14918.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
