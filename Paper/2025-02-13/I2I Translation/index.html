<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Demonstration of Fourier-domain Quantum Optical Coherence Tomography for   a fast tomographic quantum imaging">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-42702818ec49ca577b43d88be668d7aa.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-13-æ›´æ–°"><a href="#2025-02-13-æ›´æ–°" class="headerlink" title="2025-02-13 æ›´æ–°"></a>2025-02-13 æ›´æ–°</h1><h2 id="Demonstration-of-Fourier-domain-Quantum-Optical-Coherence-Tomography-for-a-fast-tomographic-quantum-imaging"><a href="#Demonstration-of-Fourier-domain-Quantum-Optical-Coherence-Tomography-for-a-fast-tomographic-quantum-imaging" class="headerlink" title="Demonstration of Fourier-domain Quantum Optical Coherence Tomography for   a fast tomographic quantum imaging"></a>Demonstration of Fourier-domain Quantum Optical Coherence Tomography for   a fast tomographic quantum imaging</h2><p><strong>Authors:Sylwia M. Kolenderska, Crislane Vieira de Brito, Piotr Kolenderski</strong></p>
<p>Using spectrally correlated photon pairs instead of classical laser light and coincidence detection instead of light intensity detection, Quantum Optical Coherence Tomography (Q-OCT) outperforms classical OCT in several experimental terms. It provides twice better axial resolution with the same spectral bandwidth and it is immune to even-order chromatic dispersion, including Group Velocity Dispersion responsible for the bulk of axial resolution degradation in the OCT images. Q-OCT has been performed in the time domain configuration, where one line of the two-dimensional image is acquired by axially translating the mirror in the interferometerâ€™s reference arm and measuring the coincidence rate of photons arriving at two single-photon-sensitive detectors. Although successful at producing resolution-doubled and dispersion-cancelled images, it is still relatively slow and cannot compete with its classical counterpart. Here, we experimentally demonstrate Q-OCT in a novel Fourier-domain configuration, theoretically proposed in 2020, where the reference mirror is fixed and the joint spectra are acquired. We show that such a configuration allows for faster image acquisition than its time-domain configuration, providing a step forward towards a practical and competitive solution in the OCT arena. The limitations of the novel approach are discussed, contrasted with the limitations of both the time-domain approach and the traditional OCT. </p>
<blockquote>
<p>åˆ©ç”¨å…‰è°±ç›¸å…³å…‰å­å¯¹ä»£æ›¿ç»å…¸æ¿€å…‰å…‰ï¼Œä»¥åŠç¬¦åˆæ£€æµ‹ä»£æ›¿å…‰å¼ºåº¦æ£€æµ‹ï¼Œé‡å­å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æï¼ˆQ-OCTï¼‰åœ¨å¤šä¸ªå®éªŒæ–¹é¢ä¼˜äºç»å…¸OCTã€‚å®ƒåœ¨ç›¸åŒçš„å…‰è°±å¸¦å®½ä¸‹æä¾›äº†ä¸¤å€çš„è½´å‘åˆ†è¾¨ç‡ï¼Œå¹¶ä¸”ä¸å—å¶æ¬¡è‰²æ•£çš„å½±å“ï¼ŒåŒ…æ‹¬å¼•èµ·OCTå›¾åƒä¸­å¤§éƒ¨åˆ†è½´å‘åˆ†è¾¨ç‡é€€åŒ–çš„ç¾¤é€Ÿåº¦è‰²æ•£ã€‚Q-OCTå·²ç»åœ¨æ—¶åŸŸé…ç½®ä¸­è¿›è¡Œï¼Œå…¶ä¸­äºŒç»´å›¾åƒçš„ä¸€è¡Œæ˜¯é€šè¿‡åœ¨å¹²æ¶‰ä»ªçš„å‚è€ƒè‡‚ä¸­è½´å‘å¹³ç§»é•œå­å¹¶æµ‹é‡åˆ°è¾¾ä¸¤ä¸ªå•å…‰å­æ•æ„Ÿæ£€æµ‹å™¨çš„å…‰å­ç¬¦åˆç‡æ¥è·å¾—çš„ã€‚å°½ç®¡æˆåŠŸäº§ç”Ÿäº†åˆ†è¾¨ç‡åŠ å€ä¸”æ¶ˆæ•£çš„å›¾åƒï¼Œä½†å®ƒä»ç„¶ç›¸å¯¹è¾ƒæ…¢ï¼Œæ— æ³•ä¸å…¶ç»å…¸åŒç±»ç«äº‰ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åœ¨å®éªŒä¸Šå±•ç¤ºäº†åœ¨å‚…ç«‹å¶åŸŸé…ç½®ä¸­çš„Q-OCTï¼Œè¯¥é…ç½®åœ¨ç†è®ºä¸Šäº2020å¹´æå‡ºï¼Œå…¶ä¸­å‚è€ƒé•œæ˜¯å›ºå®šçš„å¹¶ä¸”è”åˆå…‰è°±è¢«é‡‡é›†ã€‚æˆ‘ä»¬è¡¨æ˜è¿™æ ·çš„é…ç½®å…è®¸æ¯”å…¶æ—¶åŸŸé…ç½®æ›´å¿«çš„å›¾åƒé‡‡é›†é€Ÿåº¦ï¼Œè¿™ä¸ºåœ¨OCTé¢†åŸŸä¸­å®ç°å®ç”¨ä¸”ç«äº‰çš„è§£å†³æ–¹æ¡ˆå‘å‰è¿ˆå‡ºäº†ä¸€æ­¥ã€‚å¯¹æ–°å‹æ–¹æ³•çš„å±€é™æ€§è¿›è¡Œäº†è®¨è®ºï¼Œå¹¶å°†å…¶ä¸æ—¶åŸŸæ–¹æ³•å’Œä¼ ç»ŸOCTçš„å±€é™æ€§è¿›è¡Œäº†å¯¹æ¯”ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08372v1">PDF</a> 11 pages, 7 figures, 1 table</p>
<p><strong>Summary</strong>ï¼šé‡å­å…‰å­¦ç›¸å¹²å±‚ææˆåƒï¼ˆQ-OCTï¼‰é‡‡ç”¨å…‰è°±ç›¸å…³å…‰å­å¯¹æ›¿ä»£ç»å…¸æ¿€å…‰å…‰ï¼Œé‡‡ç”¨ç¬¦åˆæ£€æµ‹æ›¿ä»£å…‰å¼ºåº¦æ£€æµ‹ï¼Œåœ¨å¤šä¸ªå®éªŒæ¡ä»¶ä¸‹è¡¨ç°ä¼˜äºä¼ ç»ŸOCTã€‚å®ƒåœ¨ç›¸åŒçš„è°±å¸¦å®½ä¸‹æä¾›ä¸¤å€çš„è½´å‘åˆ†è¾¨ç‡ï¼Œå¹¶å¯¹åŒ…æ‹¬ç¾¤é€Ÿåº¦è‰²æ•£åœ¨å†…çš„å¶é˜¶è‰²æ•£å…·æœ‰å…ç–«æ€§ï¼Œè¿™æ˜¯OCTå›¾åƒä¸­å¤§éƒ¨åˆ†è½´å‘åˆ†è¾¨ç‡é€€åŒ–çš„åŸå› ã€‚å°½ç®¡æˆåŠŸå®ç°äº†åˆ†è¾¨ç‡åŠ å€å’Œè‰²æ•£æŠµæ¶ˆçš„å›¾åƒï¼Œä½†Q-OCTä»ç„¶ç›¸å¯¹è¾ƒæ…¢ï¼Œæ— æ³•ä¸å…¶ç»å…¸å¯¹åº”ç‰©ç«äº‰ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬åœ¨å®éªŒä¸Šè¯æ˜äº†Q-OCTçš„ä¸€ç§æ–°å‹å‚…ç«‹å¶åŸŸé…ç½®ï¼Œè¯¥é…ç½®çš„ç†è®ºæå‡ºäº2020å¹´ï¼Œå…¶ä¸­å‚è€ƒé•œæ˜¯å›ºå®šçš„ï¼Œä¸”è·å¾—è”åˆå…‰è°±ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè¿™ç§é…ç½®å…è®¸æ¯”å…¶æ—¶åŸŸé…ç½®æ›´å¿«çš„å›¾åƒé‡‡é›†ï¼Œæœç€å®ç”¨å’Œç«äº‰çš„OCTè§£å†³æ–¹æ¡ˆè¿ˆå‡ºäº†ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Q-OCTåˆ©ç”¨å…‰è°±ç›¸å…³å…‰å­å¯¹å’Œç¬¦åˆæ£€æµ‹ï¼Œç›¸æ¯”ä¼ ç»ŸOCTåœ¨å®éªŒä¸Šè¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>Q-OCTåœ¨ç›¸åŒçš„è°±å¸¦å®½ä¸‹æä¾›ä¸¤å€çš„è½´å‘åˆ†è¾¨ç‡ï¼Œå¹¶å¯¹å¶é˜¶è‰²æ•£å…·æœ‰å…ç–«æ€§ã€‚</li>
<li>Q-OCTçš„æ—¶åŸŸé…ç½®è™½ç„¶èƒ½ç”Ÿæˆåˆ†è¾¨ç‡åŠ å€å’Œè‰²æ•£æŠµæ¶ˆçš„å›¾åƒï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ã€‚</li>
<li>æ–°å‹å‚…ç«‹å¶åŸŸé…ç½®çš„Q-OCTå…è®¸æ›´å¿«çš„å›¾åƒé‡‡é›†ï¼Œæœå®ç”¨å’Œç«äº‰çš„OCTè§£å†³æ–¹æ¡ˆè¿ˆè¿›ã€‚</li>
<li>æ–°é…ç½®çš„Q-OCTä»å­˜åœ¨å±€é™æ€§ï¼Œéœ€ä¸å…¶æ—¶åŸŸé…ç½®å’Œä¼ ç»ŸOCTçš„å±€é™æ€§è¿›è¡Œå¯¹æ¯”ã€‚</li>
<li>Q-OCTçš„å‘å±•å¯¹äºæé«˜å…‰å­¦æˆåƒæŠ€æœ¯çš„æ€§èƒ½å’Œå®ç”¨æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08372">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-507c3a723b7541f4b7496f1527a3a1e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c7c962840ef3a497e4f2e4283c978291.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7d7c4150f84bb7a11c0c984629e49db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7b6b99679f66a360ff9106a97c53523.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fba7568278c8552a0e6bfb1a705face.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f509f25b950098f36e4093e9058ccd74.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="From-Brainwaves-to-Brain-Scans-A-Robust-Neural-Network-for-EEG-to-fMRI-Synthesis"><a href="#From-Brainwaves-to-Brain-Scans-A-Robust-Neural-Network-for-EEG-to-fMRI-Synthesis" class="headerlink" title="From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI   Synthesis"></a>From Brainwaves to Brain Scans: A Robust Neural Network for EEG-to-fMRI   Synthesis</h2><p><strong>Authors:Kristofer Grover Roos, Quan Huu Cap, Atsushi Fukuda</strong></p>
<p>While functional magnetic resonance imaging (fMRI) offers rich spatial resolution, it is limited by high operational costs and significant infrastructural demands. In contrast, electroencephalography (EEG) provides millisecond-level precision in capturing electrical activity but lacks the spatial resolution necessary for precise neural localization. To bridge these gaps, we introduce E2fNet, a simple yet effective deep learning model for synthesizing fMRI images from low-cost EEG data. E2fNet is specifically designed to capture and translate meaningful features from EEG across electrode channels into accurate fMRI representations. Extensive evaluations across three datasets demonstrate that E2fNet consistently outperforms existing methods, achieving state-of-the-art results in terms of the structural similarity index measure (SSIM). Our findings suggest that E2fNet is a promising, cost-effective solution for enhancing neuroimaging capabilities. The code is available at <a target="_blank" rel="noopener" href="https://github.com/kgr20/E2fNet">https://github.com/kgr20/E2fNet</a>. </p>
<blockquote>
<p>è™½ç„¶åŠŸèƒ½ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰æä¾›äº†ä¸°å¯Œçš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œä½†ç”±äºå…¶é«˜æ˜‚çš„æ“ä½œæˆæœ¬å’Œå·¨å¤§çš„åŸºç¡€è®¾æ–½éœ€æ±‚è€Œå—åˆ°é™åˆ¶ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè„‘ç”µå›¾ï¼ˆEEGï¼‰åœ¨æ•æ‰ç”µæ´»åŠ¨æ–¹é¢å…·æœ‰æ¯«ç§’çº§çš„ç²¾ç¡®åº¦ï¼Œä½†åœ¨ç²¾ç¡®ç¥ç»å®šä½æ–¹é¢ç¼ºä¹å¿…è¦çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚ä¸ºäº†å¼¥è¡¥è¿™äº›å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†E2fNetï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥ä»ä½æˆæœ¬EEGæ•°æ®ä¸­åˆæˆfMRIå›¾åƒã€‚E2fNetä¸“é—¨è®¾è®¡ç”¨äºæ•è·ç”µæé€šé“ä¸­çš„EEGæœ‰æ„ä¹‰ç‰¹å¾ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå‡†ç¡®çš„fMRIè¡¨ç¤ºã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒE2fNetå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰æ–¹é¢è¾¾åˆ°æœ€æ–°ç»“æœã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒE2fNetæ˜¯ä¸€ä¸ªæœ‰å‰æ™¯çš„ã€æ€§ä»·æ¯”é«˜çš„è§£å†³æ–¹æ¡ˆï¼Œå¯å¢å¼ºç¥ç»æˆåƒèƒ½åŠ›ã€‚ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/kgr20/E2fNet">https://github.com/kgr20/E2fNet</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08025v1">PDF</a> </p>
<p><strong>Summary</strong>:<br>åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹E2fNetå°†EEGæ•°æ®è½¬åŒ–ä¸ºfMRIå›¾åƒï¼Œå®ç°ä½æˆæœ¬ã€é«˜æ•ˆçš„ç¥ç»å¸¸è§„æˆåƒã€‚E2fNetèƒ½å¤Ÿæ•æ‰EEGæ•°æ®ä¸­çš„æœ‰æ„ä¹‰ç‰¹å¾ï¼Œå¹¶è½¬åŒ–ä¸ºå‡†ç¡®çš„fMRIè¡¨ç¤ºï¼Œé€šè¿‡è·¨ç”µæé€šé“çš„åˆæˆæé«˜ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>E2fNetæ˜¯ä¸€ç§ç”¨äºä»ä½æˆæœ¬EEGæ•°æ®ä¸­åˆæˆfMRIå›¾åƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</li>
<li>E2fNetæ—¨åœ¨æ•æ‰EEGæ•°æ®ä¸­çš„æœ‰æ„ä¹‰ç‰¹å¾ï¼Œå¹¶è½¬åŒ–ä¸ºfMRIè¡¨ç¤ºã€‚</li>
<li>E2fNeté€šè¿‡è·¨ç”µæé€šé“çš„åˆæˆï¼Œå®ç°äº†ä»EEGåˆ°fMRIçš„è½¬åŒ–ã€‚</li>
<li>E2fNetåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰ã€‚</li>
<li>E2fNetçš„å¼•å…¥ä¸ºç¥ç»æˆåƒæä¾›äº†ä¸€ç§æˆæœ¬æ•ˆç›Šé«˜ã€å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>E2fNetçš„ä»£ç å·²å…¬å¼€å‘å¸ƒï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08025">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2e7c4adbec8f1fc6ea93a50e3e823b0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-abae403a3766f0d98aee36c1ffdab3bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92e3b563e432effe929fd3a540eb0804.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8afe8889eccff1819fb72ce7210c3b9d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SurGrID-Controllable-Surgical-Simulation-via-Scene-Graph-to-Image-Diffusion"><a href="#SurGrID-Controllable-Surgical-Simulation-via-Scene-Graph-to-Image-Diffusion" class="headerlink" title="SurGrID: Controllable Surgical Simulation via Scene Graph to Image   Diffusion"></a>SurGrID: Controllable Surgical Simulation via Scene Graph to Image   Diffusion</h2><p><strong>Authors:Yannik Frisch, Ssharvien Kumar Sivakumar, Ã‡aÄŸhan KÃ¶ksal, Elsa BÃ¶hm, Felix Wagner, Adrian Gericke, Ghazal Ghazaei, Anirban Mukhopadhyay</strong></p>
<p>Surgical simulation offers a promising addition to conventional surgical training. However, available simulation tools lack photorealism and rely on hardcoded behaviour. Denoising Diffusion Models are a promising alternative for high-fidelity image synthesis, but existing state-of-the-art conditioning methods fall short in providing precise control or interactivity over the generated scenes.   We introduce SurGrID, a Scene Graph to Image Diffusion Model, allowing for controllable surgical scene synthesis by leveraging Scene Graphs. These graphs encode a surgical sceneâ€™s componentsâ€™ spatial and semantic information, which are then translated into an intermediate representation using our novel pre-training step that explicitly captures local and global information.   Our proposed method improves the fidelity of generated images and their coherence with the graph input over the state-of-the-art. Further, we demonstrate the simulationâ€™s realism and controllability in a user assessment study involving clinical experts.   Scene Graphs can be effectively used for precise and interactive conditioning of Denoising Diffusion Models for simulating surgical scenes, enabling high fidelity and interactive control over the generated content. </p>
<blockquote>
<p>æ‰‹æœ¯æ¨¡æ‹Ÿä¸ºä¼ ç»Ÿæ‰‹æœ¯è®­ç»ƒæä¾›äº†æœ‰å‰é€”çš„è¡¥å……ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ¨¡æ‹Ÿå·¥å…·ç¼ºä¹é€¼çœŸçš„è§†è§‰æ•ˆæœï¼Œå¹¶ä¾èµ–äºç¡¬ç¼–ç çš„è¡Œä¸ºã€‚å»å™ªæ‰©æ•£æ¨¡å‹æ˜¯é«˜ä¿çœŸå›¾åƒåˆæˆçš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„æœ€å…ˆè¿›çš„æ¡ä»¶è®¾å®šæ–¹æ³•åœ¨æä¾›å¯¹ç”Ÿæˆåœºæ™¯çš„ç²¾ç¡®æ§åˆ¶æˆ–äº¤äº’æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æˆ‘ä»¬å¼•å…¥äº†SurGrIDï¼Œä¸€ç§åœºæ™¯å›¾åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨åœºæ™¯å›¾ï¼Œå®ç°å¯æ§æ‰‹æœ¯åœºæ™¯åˆæˆã€‚è¿™äº›å›¾ç¼–ç äº†æ‰‹æœ¯åœºæ™¯ç»„ä»¶çš„ç©ºé—´å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨æˆ‘ä»¬æ–°é¢–çš„é¢„è®­ç»ƒæ­¥éª¤å°†è¿™äº›ä¿¡æ¯ç¿»è¯‘ä¸ºä¸€ç§ä¸­é—´è¡¨ç¤ºå½¢å¼ï¼Œè¯¥æ­¥éª¤èƒ½å¤Ÿæ˜¾å¼æ•è·å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ã€‚ç›¸æ¯”ç°æœ‰æŠ€æœ¯ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æé«˜äº†ç”Ÿæˆå›¾åƒçš„çœŸå®æ€§å’Œä¸å›¾çš„è¾“å…¥çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡æ¶‰åŠä¸´åºŠä¸“å®¶çš„ç”¨æˆ·è¯„ä¼°ç ”ç©¶è¯æ˜äº†æ¨¡æ‹Ÿçš„çœŸå®æ€§å’Œå¯æ§æ€§ã€‚åœºæ™¯å›¾å¯æœ‰æ•ˆåœ°ç”¨äºå¯¹å»å™ªæ‰©æ•£æ¨¡å‹è¿›è¡Œç²¾ç¡®å’Œäº¤äº’å¼çš„æ¡ä»¶è®¾å®šï¼Œä»¥æ¨¡æ‹Ÿæ‰‹æœ¯åœºæ™¯ï¼Œå®ç°å¯¹ç”Ÿæˆå†…å®¹çš„é«˜ä¿çœŸå’Œäº¤äº’å¼æ§åˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07945v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ‰‹æœ¯æ¨¡æ‹Ÿä¸ºä¼ ç»Ÿæ‰‹æœ¯è®­ç»ƒæä¾›äº†æœ‰å‰æ™¯çš„è¡¥å……ã€‚ç°æœ‰çš„æ¨¡æ‹Ÿå·¥å…·ç¼ºä¹é€¼çœŸåº¦å¹¶ä¾èµ–ç¡¬ç¼–ç è¡Œä¸ºã€‚æˆ‘ä»¬å¼•å…¥SurGrIDï¼Œä¸€ä¸ªåœºæ™¯å›¾åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨åœºæ™¯å›¾ï¼Œå®ç°å¯æ§æ‰‹æœ¯åœºæ™¯åˆæˆã€‚è¯¥æ–¹æ³•æé«˜äº†ç”Ÿæˆå›¾åƒçš„é€¼çœŸåº¦å’Œä¸å›¾å½¢è¾“å…¥çš„è¿è´¯æ€§ï¼Œå¹¶åœ¨æ¶‰åŠä¸´åºŠä¸“å®¶çš„ç”¨æˆ·è¯„ä¼°ç ”ç©¶ä¸­è¯æ˜äº†æ¨¡æ‹Ÿçš„çœŸå®æ€§å’Œå¯æ§æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰‹æœ¯æ¨¡æ‹Ÿæ˜¯ä¼ ç»Ÿæ‰‹æœ¯è®­ç»ƒçš„æœ‰å‰æ™¯çš„è¡¥å……ã€‚</li>
<li>å½“å‰æ¨¡æ‹Ÿå·¥å…·å­˜åœ¨é€¼çœŸåº¦ä¸è¶³å’Œä¾èµ–ç¡¬ç¼–ç è¡Œä¸ºçš„é—®é¢˜ã€‚</li>
<li>Denoising Diffusion Modelså¯ç”¨äºé«˜ä¿çœŸå›¾åƒåˆæˆï¼Œä½†åœ¨ç²¾ç¡®æ§åˆ¶å’Œäº¤äº’æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>SurGrIDæ˜¯ä¸€ä¸ªåœºæ™¯å›¾åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨åœºæ™¯å›¾å®ç°å¯æ§æ‰‹æœ¯åœºæ™¯åˆæˆã€‚</li>
<li>è¯¥æ–¹æ³•æé«˜äº†ç”Ÿæˆå›¾åƒçš„é€¼çœŸåº¦å’Œä¸å›¾å½¢è¾“å…¥çš„è¿è´¯æ€§ã€‚</li>
<li>ç”¨æˆ·è¯„ä¼°ç ”ç©¶è¯æ˜äº†æ¨¡æ‹Ÿçš„çœŸå®æ€§å’Œå¯æ§æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07945">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-316d50d1fbd86c8be6f4e33dddf527c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc54086dc98a19669fe9bd9b6e24f970.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6edeae3ac3f2919e40929ba457c6690.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Unified-Graph-Networks-UGN-A-Deep-Neural-Framework-for-Solving-Graph-Problems"><a href="#Unified-Graph-Networks-UGN-A-Deep-Neural-Framework-for-Solving-Graph-Problems" class="headerlink" title="Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph   Problems"></a>Unified Graph Networks (UGN): A Deep Neural Framework for Solving Graph   Problems</h2><p><strong>Authors:Rudrajit Dawn, Madhusudan Ghosh, Partha Basuchowdhuri, Sudip Kumar Naskar</strong></p>
<p>Deep neural networks have enabled researchers to create powerful generalized frameworks, such as transformers, that can be used to solve well-studied problems in various application domains, such as text and image. However, such generalized frameworks are not available for solving graph problems. Graph structures are ubiquitous in many applications around us and many graph problems have been widely studied over years. In recent times, there has been a surge in deep neural network based approaches to solve graph problems, with growing availability of graph structured datasets across diverse domains. Nevertheless, existing methods are mostly tailored to solve a specific task and lack the capability to create a generalized model leading to solutions for different downstream tasks. In this work, we propose a novel, resource-efficient framework named \emph{U}nified \emph{G}raph \emph{N}etwork (UGN) by leveraging the feature extraction capability of graph convolutional neural networks (GCN) and 2-dimensional convolutional neural networks (Conv2D). UGN unifies various graph learning tasks, such as link prediction, node classification, community detection, graph-to-graph translation, knowledge graph completion, and more, within a cohesive framework, while exercising minimal task-specific extensions (e.g., formation of supernodes for coarsening massive networks to increase scalability, use of \textit{mean target connectivity matrix} (MTCM) representation for achieving scalability in graph translation task, etc.) to enhance the generalization capability of graph learning and analysis. We test the novel UGN framework for six uncorrelated graph problems, using twelve different datasets. Experimental results show that UGN outperforms the state-of-the-art baselines by a significant margin on ten datasets, while producing comparable results on the remaining dataset. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿåˆ›å»ºå¼ºå¤§çš„é€šç”¨æ¡†æ¶ï¼Œå¦‚å˜å‹å™¨ç­‰ï¼Œè¿™äº›æ¡†æ¶å¯ç”¨äºè§£å†³æ–‡æœ¬å’Œå›¾åƒç­‰é¢†åŸŸçš„å…¬è®¤é—®é¢˜ã€‚ç„¶è€Œï¼Œå°šä¸å­˜åœ¨ç”¨äºè§£å†³å›¾å½¢é—®é¢˜çš„æ­¤ç±»é€šç”¨æ¡†æ¶ã€‚å›¾å½¢ç»“æ„åœ¨æˆ‘ä»¬å‘¨å›´çš„è®¸å¤šåº”ç”¨ä¸­æ— å¤„ä¸åœ¨ï¼Œè®¸å¤šå›¾å½¢é—®é¢˜å¤šå¹´æ¥å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ã€‚æœ€è¿‘æœ‰åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„è§£å†³å›¾å½¢é—®é¢˜çš„æ–°æ–¹æ³•æ¶Œç°ï¼Œä»¥åŠä¸åŒé¢†åŸŸå›¾å½¢ç»“æ„æ•°æ®é›†çš„æ—¥ç›Šå¯ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤§å¤šé’ˆå¯¹ç‰¹å®šä»»åŠ¡è€Œå®šåˆ¶ï¼Œç¼ºä¹åˆ›å»ºé€šç”¨æ¨¡å‹ä»¥ç”¨äºè§£å†³ä¸åŒä¸‹æ¸¸ä»»åŠ¡çš„èƒ½åŠ›ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºç»Ÿä¸€å›¾ç½‘ç»œï¼ˆUGNï¼‰çš„æ–°å‹èµ„æºé«˜æ•ˆæ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨å›¾å·ç§¯ç¥ç»ç½‘ç»œï¼ˆGCNï¼‰å’ŒäºŒç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConv2Dï¼‰çš„ç‰¹å¾æå–èƒ½åŠ›ã€‚UGNåœ¨ä¸€ä¸ªè¿è´¯çš„æ¡†æ¶å†…ç»Ÿä¸€äº†å„ç§å›¾å½¢å­¦ä¹ ä»»åŠ¡ï¼Œå¦‚é“¾æ¥é¢„æµ‹ã€èŠ‚ç‚¹åˆ†ç±»ã€ç¤¾åŒºæ£€æµ‹ã€å›¾åˆ°å›¾çš„ç¿»è¯‘ã€çŸ¥è¯†å›¾è°±è¡¥å…¨ç­‰ï¼ŒåŒæ—¶è¿›è¡Œäº†æœ€å°çš„ç‰¹å®šä»»åŠ¡æ‰©å±•ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡å½¢æˆè¶…èŠ‚ç‚¹æ¥ç²—åŒ–å¤§è§„æ¨¡ç½‘ç»œä»¥æé«˜å¯æ‰©å±•æ€§ï¼Œä½¿ç”¨å¹³å‡ç›®æ ‡è¿æ¥çŸ©é˜µï¼ˆMTCMï¼‰è¡¨ç¤ºæ¥å®ç°å›¾ç¿»è¯‘ä»»åŠ¡çš„æ‰©å±•æ€§ç­‰ï¼‰ï¼Œä»¥å¢å¼ºå›¾å½¢å­¦ä¹ å’Œåˆ†æçš„ä¸€èˆ¬åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨å…­ä¸ªä¸ç›¸å…³çš„å›¾å½¢é—®é¢˜ä¸Šæµ‹è¯•äº†æ–°å‹UGNæ¡†æ¶ï¼Œä½¿ç”¨äº†åäºŒç§ä¸åŒçš„æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUGNåœ¨åä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¿œè¶…æœ€æ–°åŸºå‡†çº¿ï¼Œå¹¶åœ¨å…¶ä½™æ•°æ®é›†ä¸Šå–å¾—äº†ç›¸å½“çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07500v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œå·²å¹¿æ³›åº”ç”¨äºæ–‡æœ¬å’Œå›¾åƒç­‰é¢†åŸŸçš„é—®é¢˜è§£å†³ï¼Œä½†å¯¹äºå›¾ç»“æ„é—®é¢˜ä»ç¼ºä¹é€šç”¨æ¡†æ¶ã€‚è¿‘æœŸåŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„æ–¹æ³•ä¸æ–­æ¶Œç°ï¼Œä½†å¤šæ•°é’ˆå¯¹ç‰¹å®šä»»åŠ¡ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºUGNçš„ç»Ÿä¸€å›¾ç½‘ç»œæ¡†æ¶ï¼Œç»“åˆå›¾å·ç§¯ç¥ç»ç½‘ç»œå’ŒäºŒç»´å·ç§¯ç¥ç»ç½‘ç»œçš„ç‰¹ç‚¹ï¼Œå®ç°äº†å¤šç§å›¾å­¦ä¹ ä»»åŠ¡çš„ç»Ÿä¸€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUGNåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç›®å‰æ·±åº¦å­¦ä¹ åœ¨å›¾ç»“æ„é—®é¢˜ä¸Šç¼ºä¹é€šç”¨æ¡†æ¶ã€‚</li>
<li>åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„å›¾é—®é¢˜è§£å†³æ–¹æ³•æ—¥ç›Šå¢å¤šï¼Œä½†å¤§å¤šé’ˆå¯¹ç‰¹å®šä»»åŠ¡ã€‚</li>
<li>UGNæ¡†æ¶ç»“åˆäº†å›¾å·ç§¯ç¥ç»ç½‘ç»œå’ŒäºŒç»´å·ç§¯ç¥ç»ç½‘ç»œçš„ç‰¹ç‚¹ã€‚</li>
<li>UGNæ¡†æ¶èƒ½å¤Ÿç»Ÿä¸€å¤šç§å›¾å­¦ä¹ ä»»åŠ¡ï¼Œå¦‚é“¾æ¥é¢„æµ‹ã€èŠ‚ç‚¹åˆ†ç±»ã€ç¤¾åŒºæ£€æµ‹ã€å›¾å¯¹å›¾ç¿»è¯‘å’ŒçŸ¥è¯†å›¾è°±è¡¥å…¨ç­‰ã€‚</li>
<li>UGNé€šè¿‡å½¢æˆè¶…èŠ‚ç‚¹ç­‰æ–¹æ³•å¢å¼ºäº†å¤§è§„æ¨¡ç½‘ç»œçš„æ‰©å±•æ€§ã€‚</li>
<li>UGNä½¿ç”¨å¹³å‡ç›®æ ‡è¿æ¥çŸ©é˜µè¡¨ç¤ºæ³•ï¼Œå®ç°äº†å›¾ç¿»è¯‘ä»»åŠ¡çš„æ‰©å±•æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07500">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5aec8b9f1adbaab2c8f8ae05ce620f51.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb9ad0e0eb0c0bc348eb7cbf9ea49104.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-633d4816bda6077c6a4076bb0ca95bef.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RusCode-Russian-Cultural-Code-Benchmark-for-Text-to-Image-Generation"><a href="#RusCode-Russian-Cultural-Code-Benchmark-for-Text-to-Image-Generation" class="headerlink" title="RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation"></a>RusCode: Russian Cultural Code Benchmark for Text-to-Image Generation</h2><p><strong>Authors:Viacheslav Vasilev, Julia Agafonova, Nikolai Gerasimenko, Alexander Kapitanov, Polina Mikhailova, Evelina Mironova, Denis Dimitrov</strong></p>
<p>Text-to-image generation models have gained popularity among users around the world. However, many of these models exhibit a strong bias toward English-speaking cultures, ignoring or misrepresenting the unique characteristics of other language groups, countries, and nationalities. The lack of cultural awareness can reduce the generation quality and lead to undesirable consequences such as unintentional insult, and the spread of prejudice. In contrast to the field of natural language processing, cultural awareness in computer vision has not been explored as extensively. In this paper, we strive to reduce this gap. We propose a RusCode benchmark for evaluating the quality of text-to-image generation containing elements of the Russian cultural code. To do this, we form a list of 19 categories that best represent the features of Russian visual culture. Our final dataset consists of 1250 text prompts in Russian and their translations into English. The prompts cover a wide range of topics, including complex concepts from art, popular culture, folk traditions, famous peopleâ€™s names, natural objects, scientific achievements, etc. We present the results of a human evaluation of the side-by-side comparison of Russian visual concepts representations using popular generative models. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å…¨çƒèŒƒå›´å†…å—åˆ°ç”¨æˆ·çš„æ¬¢è¿ã€‚ç„¶è€Œï¼Œè®¸å¤šè¿™äº›æ¨¡å‹å¯¹è‹±æ–‡æ–‡åŒ–è¡¨ç°å‡ºå¼ºçƒˆçš„åè§ï¼Œå¿½ç•¥æˆ–é”™è¯¯ä»£è¡¨å…¶ä»–è¯­è¨€ç¾¤ä½“ã€å›½å®¶å’Œæ°‘æ—çš„ç‹¬ç‰¹ç‰¹å¾ã€‚ç¼ºä¹æ–‡åŒ–æ„è¯†å¯èƒ½ä¼šé™ä½ç”Ÿæˆè´¨é‡ï¼Œå¹¶å¯¼è‡´ä¸€äº›ä¸å¸Œæœ›çš„åæœï¼Œå¦‚æ— æ„å†’çŠ¯å’Œåè§çš„ä¼ æ’­ã€‚ä¸è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸åŒï¼Œè®¡ç®—æœºè§†è§‰ä¸­çš„æ–‡åŒ–æ„è¯†å°šæœªå¾—åˆ°å¹¿æ³›æ¢ç´¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åŠªåŠ›ç¼©å°è¿™ä¸€å·®è·ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆè´¨é‡çš„RusCodeåŸºå‡†æµ‹è¯•ï¼Œå…¶ä¸­åŒ…å«ä¿„ç½—æ–¯æ–‡åŒ–ä»£ç çš„å…ƒç´ ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å½¢æˆäº†æœ€èƒ½ä»£è¡¨ä¿„ç½—æ–¯è§†è§‰æ–‡åŒ–ç‰¹å¾çš„19ä¸ªç±»åˆ«åˆ—è¡¨ã€‚æˆ‘ä»¬çš„æœ€ç»ˆæ•°æ®é›†åŒ…å«1250ä¸ªä¿„è¯­æ–‡æœ¬æç¤ºåŠå…¶è‹±æ–‡ç¿»è¯‘ã€‚æç¤ºæ¶µç›–å¹¿æ³›çš„ä¸»é¢˜ï¼ŒåŒ…æ‹¬è‰ºæœ¯ã€æµè¡Œæ–‡åŒ–ã€æ°‘é—´ä¼ ç»Ÿã€åäººå§“åã€è‡ªç„¶ç‰©ä½“ã€ç§‘å­¦æˆå°±ç­‰ä¸­çš„å¤æ‚æ¦‚å¿µã€‚æˆ‘ä»¬å±•ç¤ºäº†ä½¿ç”¨æµè¡Œç”Ÿæˆæ¨¡å‹å¯¹ä¿„ç½—æ–¯è§†è§‰æ¦‚å¿µè¡¨ç¤ºè¿›è¡Œå¹¶æ’æ¯”è¾ƒçš„äººç±»è¯„ä¼°ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07455v1">PDF</a> Accepted for NAACL 2025 Findings, GitHub:   <a target="_blank" rel="noopener" href="https://github.com/ai-forever/RusCode">https://github.com/ai-forever/RusCode</a></p>
<p><strong>Summary</strong><br>æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆæ¨¡å‹å—åˆ°å…¨çƒç”¨æˆ·çš„æ¬¢è¿ï¼Œä½†å¤šæ•°æ¨¡å‹å­˜åœ¨å¯¹è‹±è¯­æ–‡åŒ–åå¥½çš„é—®é¢˜ï¼Œå¿½è§†æˆ–è¯¯ä»£è¡¨å…¶ä»–è¯­è¨€ç¾¤ä½“ã€å›½å®¶å’Œæ°‘æ—çš„ç‰¹å¾ã€‚ç¼ºä¹æ–‡åŒ–æ„è¯†ä¼šé™ä½ç”Ÿæˆè´¨é‡ï¼Œå¹¶å¯èƒ½å¯¼è‡´ä¸è‰¯åæœï¼Œå¦‚æ— æ„å†’çŠ¯å’Œä¼ æ’­åè§ã€‚æœ¬æ–‡æ—¨åœ¨ç¼©å°è¿™ä¸€å·®è·ï¼Œæå‡ºä¸€ä¸ªç”¨äºè¯„ä¼°æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆè´¨é‡çš„RusCodeåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ä¿„ç½—æ–¯æ–‡åŒ–ä»£ç çš„å…ƒç´ ã€‚é€šè¿‡å½¢æˆæœ€èƒ½ä»£è¡¨ä¿„ç½—æ–¯è§†è§‰æ–‡åŒ–ç‰¹å¾çš„19ä¸ªç±»åˆ«ï¼Œæ„å»ºæœ€ç»ˆæ•°æ®é›†ï¼ŒåŒ…å«1250ä¸ªä¿„è¯­æ–‡æœ¬æç¤ºåŠå…¶è‹±æ–‡ç¿»è¯‘ã€‚æœ¬æ–‡è¿˜ä»‹ç»äº†ä½¿ç”¨æµè¡Œç”Ÿæˆæ¨¡å‹è¿›è¡Œä¿„ç½—æ–¯è§†è§‰æ¦‚å¿µè¡¨ç¤ºçš„äººç±»è¯„ä¼°ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å…¨çƒèŒƒå›´å†…å—æ¬¢è¿ï¼Œä½†å­˜åœ¨å¯¹è‹±è¯­æ–‡åŒ–çš„åå¥½é—®é¢˜ã€‚</li>
<li>ç¼ºä¹æ–‡åŒ–æ„è¯†å¯èƒ½å¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™ï¼Œç”šè‡³å¼•å‘æ— æ„å†’çŠ¯å’Œä¼ æ’­åè§ç­‰åæœã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨æé«˜æ–‡åŒ–æ„è¯†ï¼Œæå‡ºä¸€ä¸ªè¯„ä¼°æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆè´¨é‡çš„åŸºå‡†æµ‹è¯•â€”â€”RusCodeã€‚</li>
<li>RusCodeåŒ…å«ä»£è¡¨ä¿„ç½—æ–¯æ–‡åŒ–ä»£ç çš„å…ƒç´ ï¼Œå½¢æˆ19ä¸ªä»£è¡¨ä¿„ç½—æ–¯è§†è§‰æ–‡åŒ–ç‰¹å¾çš„ç±»åˆ«ã€‚</li>
<li>æœ€ç»ˆæ•°æ®é›†åŒ…å«1250ä¸ªä¿„è¯­æ–‡æœ¬æç¤ºåŠå…¶è‹±æ–‡ç¿»è¯‘ï¼Œæ¶µç›–è‰ºæœ¯ã€æµè¡Œæ–‡åŒ–ã€æ°‘é—´ä¼ ç»Ÿã€åäººå§“åã€è‡ªç„¶ç‰©ä½“ã€ç§‘å­¦æˆå°±ç­‰è¯é¢˜ã€‚</li>
<li>é€šè¿‡äººç±»è¯„ä¼°ï¼Œå¯¹æ¯”äº†ä½¿ç”¨æµè¡Œç”Ÿæˆæ¨¡å‹çš„ä¿„ç½—æ–¯è§†è§‰æ¦‚å¿µè¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07455">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-05855c86af314466cdc55118f90a75e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67f5363eabffb24a949841b699adb258.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cbe046804ee118d022dd2559267db51c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5baf5553a3dcf69973ae656300554cb4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ca64488f17306086b64f54cb1a818ff.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Learning-to-Synthesize-Compatible-Fashion-Items-Using-Semantic-Alignment-and-Collocation-Classification-An-Outfit-Generation-Framework"><a href="#Learning-to-Synthesize-Compatible-Fashion-Items-Using-Semantic-Alignment-and-Collocation-Classification-An-Outfit-Generation-Framework" class="headerlink" title="Learning to Synthesize Compatible Fashion Items Using Semantic Alignment   and Collocation Classification: An Outfit Generation Framework"></a>Learning to Synthesize Compatible Fashion Items Using Semantic Alignment   and Collocation Classification: An Outfit Generation Framework</h2><p><strong>Authors:Dongliang Zhou, Haijun Zhang, Kai Yang, Linlin Liu, Han Yan, Xiaofei Xu, Zhao Zhang, Shuicheng Yan</strong></p>
<p>The field of fashion compatibility learning has attracted great attention from both the academic and industrial communities in recent years. Many studies have been carried out for fashion compatibility prediction, collocated outfit recommendation, artificial intelligence (AI)-enabled compatible fashion design, and related topics. In particular, AI-enabled compatible fashion design can be used to synthesize compatible fashion items or outfits in order to improve the design experience for designers or the efficacy of recommendations for customers. However, previous generative models for collocated fashion synthesis have generally focused on the image-to-image translation between fashion items of upper and lower clothing. In this paper, we propose a novel outfit generation framework, i.e., OutfitGAN, with the aim of synthesizing a set of complementary items to compose an entire outfit, given one extant fashion item and reference masks of target synthesized items. OutfitGAN includes a semantic alignment module, which is responsible for characterizing the mapping correspondence between the existing fashion items and the synthesized ones, to improve the quality of the synthesized images, and a collocation classification module, which is used to improve the compatibility of a synthesized outfit. In order to evaluate the performance of our proposed models, we built a large-scale dataset consisting of 20,000 fashion outfits. Extensive experimental results on this dataset show that our OutfitGAN can synthesize photo-realistic outfits and outperform state-of-the-art methods in terms of similarity, authenticity and compatibility measurements. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ—¶å°šæ­é…å­¦ä¹ é¢†åŸŸå¼•èµ·äº†å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å¹¿æ³›å…³æ³¨ã€‚å…³äºæ—¶å°šæ­é…é¢„æµ‹ã€æ­é…æœé¥°æ¨èã€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ”¯æŒçš„å…¼å®¹æ—¶å°šè®¾è®¡ä»¥åŠç›¸å…³ä¸»é¢˜ï¼Œå·²ç»è¿›è¡Œäº†è®¸å¤šç ”ç©¶ã€‚ç‰¹åˆ«æ˜¯ï¼ŒAIæ”¯æŒçš„å…¼å®¹æ—¶å°šè®¾è®¡å¯ç”¨äºåˆæˆå…¼å®¹çš„æ—¶å°šå•å“æˆ–æ­é…ï¼Œä»¥æé«˜è®¾è®¡å¸ˆçš„è®¾è®¡ä½“éªŒæˆ–æé«˜å®¢æˆ·æ¨èçš„æ•ˆç‡ã€‚ç„¶è€Œï¼Œä¹‹å‰ç”¨äºåˆæˆæ­é…çš„ç”Ÿæˆæ¨¡å‹ä¸€èˆ¬ä¸»è¦å…³æ³¨ä¸Šä¸‹è¡£ä¹‹é—´å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æœé¥°ç”Ÿæˆæ¡†æ¶ï¼Œå³OutfitGANï¼Œå®ƒçš„ç›®æ ‡æ˜¯åœ¨ç»™å®šä¸€ä¸ªç°æœ‰çš„æ—¶å°šå•å“å’Œç›®æ ‡åˆæˆå•å“çš„å‚è€ƒæ©æ¨¡çš„æƒ…å†µä¸‹ï¼Œåˆæˆä¸€ç³»åˆ—äº’è¡¥å•å“ä»¥ç»„æˆä¸€å¥—å®Œæ•´çš„æ­é…ã€‚OutfitGANåŒ…æ‹¬ä¸€ä¸ªè¯­ä¹‰å¯¹é½æ¨¡å—ï¼Œè´Ÿè´£è¡¨å¾ç°æœ‰æ—¶å°šå•å“å’Œåˆæˆå•å“ä¹‹é—´çš„æ˜ å°„å¯¹åº”å…³ç³»ï¼Œä»¥æé«˜åˆæˆå›¾åƒçš„è´¨é‡ï¼Œä»¥åŠä¸€ä¸ªæ­é…åˆ†ç±»æ¨¡å—ï¼Œç”¨äºæé«˜åˆæˆæ­é…çš„å…¼å®¹æ€§ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬æå‡ºçš„æ¨¡å‹æ€§èƒ½ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«2ä¸‡å¥—æ—¶å°šæ­é…çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚åœ¨è¯¥æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„OutfitGANèƒ½å¤Ÿåˆæˆé€¼çœŸçš„æ­é…ï¼Œå¹¶åœ¨ç›¸ä¼¼æ€§ã€çœŸå®æ€§å’Œå…¼å®¹æ€§æµ‹é‡æ–¹é¢ä¼˜äºç°æœ‰æœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06827v1">PDF</a> This paper was accepted by IEEE TNNLS</p>
<p><strong>Summary</strong>:<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æœé¥°ç”Ÿæˆæ¡†æ¶OutfitGANï¼Œæ—¨åœ¨é€šè¿‡åˆæˆä¸€ç³»åˆ—äº’è¡¥çš„æœé¥°å•å“æ¥ç»„æˆä¸€å¥—å®Œæ•´çš„æœé¥°ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬è¯­ä¹‰å¯¹é½æ¨¡å—å’Œæ­é…åˆ†ç±»æ¨¡å—ï¼Œæ—¨åœ¨æé«˜åˆæˆå›¾åƒçš„è´¨é‡å’Œæœé¥°çš„å…¼å®¹æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOutfitGANèƒ½å¤Ÿåˆæˆé€¼çœŸçš„æœé¥°å¹¶åœ¨ç›¸ä¼¼æ€§ã€çœŸå®æ€§å’Œå…¼å®¹æ€§æ–¹é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>æ—¶å°šå…¼å®¹æ€§å­¦ä¹ é¢†åŸŸè¿‘å¹´æ¥å—åˆ°å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å¹¿æ³›å…³æ³¨ã€‚</li>
<li>AIæŠ€æœ¯å¯ç”¨äºè¿›è¡Œæ—¶å°šå…¼å®¹æ€§é¢„æµ‹ã€æ­é…æ¨èå’Œå…¼å®¹æ—¶å°šè®¾è®¡ã€‚</li>
<li>ç°æœ‰ç”Ÿæˆæ¨¡å‹ä¸»è¦å…³æ³¨ä¸Šä¸‹è£…ä¹‹é—´çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æœé¥°ç”Ÿæˆæ¡†æ¶OutfitGANï¼Œèƒ½å¤Ÿåˆæˆä¸€ç³»åˆ—äº’è¡¥çš„æœé¥°å•å“æ¥ç»„æˆä¸€å¥—å®Œæ•´çš„æœé¥°ã€‚</li>
<li>OutfitGANåŒ…æ‹¬è¯­ä¹‰å¯¹é½æ¨¡å—ï¼Œè´Ÿè´£è¡¨å¾ç°æœ‰æœé¥°å•å“ä¸åˆæˆå•å“ä¹‹é—´çš„æ˜ å°„å¯¹åº”å…³ç³»ï¼Œä»¥æé«˜åˆæˆå›¾åƒçš„è´¨é‡ã€‚</li>
<li>OutfitGANè¿˜åŒ…æ‹¬ä¸€ä¸ªæ­é…åˆ†ç±»æ¨¡å—ï¼Œæ—¨åœ¨æé«˜åˆæˆæœé¥°çš„å…¼å®¹æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06827">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-726592143731da063303f486d977e1ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92257c565ee15538ab529d91f94168d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4fa77f99ce553fc30abfb7ef1a6d7f37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c9d5181a1e3e45a6e6d94f817406a0f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="UniDB-A-Unified-Diffusion-Bridge-Framework-via-Stochastic-Optimal-Control"><a href="#UniDB-A-Unified-Diffusion-Bridge-Framework-via-Stochastic-Optimal-Control" class="headerlink" title="UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal   Control"></a>UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal   Control</h2><p><strong>Authors:Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi</strong></p>
<p>Recent advances in diffusion bridge models leverage Doobâ€™s $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doobâ€™s $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/UniDB-SOC/UniDB/">https://github.com/UniDB-SOC/UniDB/</a>. </p>
<blockquote>
<p>è¿‘æœŸæ‰©æ•£æ¡¥æ¨¡å‹çš„æ–°è¿›å±•åˆ©ç”¨Doobçš„$h$-å˜æ¢åœ¨åˆ†å¸ƒä¹‹é—´å»ºç«‹å›ºå®šç«¯ç‚¹ï¼Œåœ¨å›¾åƒç¿»è¯‘å’Œæ¢å¤ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ç»å¸¸äº§ç”Ÿæ¨¡ç³Šæˆ–è¿‡åº¦å¹³æ»‘çš„å›¾åƒç»†èŠ‚ï¼Œå¹¶ä¸”ç¼ºä¹å…¨é¢çš„ç†è®ºåŸºç¡€æ¥è§£é‡Šè¿™äº›ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºéšæœºæœ€ä¼˜æ§åˆ¶ï¼ˆSOCï¼‰çš„æ‰©æ•£æ¡¥ç»Ÿä¸€æ¡†æ¶UniDBã€‚UniDBé€šè¿‡åŸºäºSOCçš„ä¼˜åŒ–æ¥åˆ¶å®šé—®é¢˜ï¼Œå¹¶æ¨å¯¼å‡ºæœ€ä¼˜æ§åˆ¶å™¨çš„å°é—­å½¢å¼è§£å†³æ–¹æ¡ˆï¼Œä»è€Œç»Ÿä¸€å¹¶æ¨å¹¿ç°æœ‰çš„æ‰©æ•£æ¡¥æ¨¡å‹ã€‚æˆ‘ä»¬è¯æ˜ï¼Œé‡‡ç”¨Doobçš„$h$-å˜æ¢çš„ç°æœ‰æ‰©æ•£æ¡¥æ„æˆäº†æˆ‘ä»¬æ¡†æ¶çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œå‡ºç°åœ¨SOCæˆæœ¬å‡½æ•°çš„ç»ˆç«¯æƒ©ç½šç³»æ•°è¶‹äºæ— ç©·å¤§æ—¶ã€‚é€šè¿‡å¼•å…¥å¯è°ƒç»ˆç«¯æƒ©ç½šç³»æ•°ï¼ŒUniDBå®ç°äº†æ§åˆ¶æˆæœ¬ä¸ç»ˆç«¯æƒ©ç½šä¹‹é—´çš„æœ€ä½³å¹³è¡¡ï¼Œå¤§å¤§æé«˜äº†ç»†èŠ‚ä¿ç•™å’Œè¾“å‡ºè´¨é‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒUniDBå¯ä»¥æ— ç¼åœ°èå…¥ç°æœ‰çš„æ‰©æ•£æ¡¥æ¨¡å‹ï¼Œåªéœ€è¿›è¡Œæœ€å°çš„ä»£ç ä¿®æ”¹ã€‚åœ¨ä¸åŒå›¾åƒæ¢å¤ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„ä¼˜è¶Šæ€§å’Œé€‚åº”æ€§ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/UniDB-SOC/UniDB/%E3%80%82">https://github.com/UniDB-SOC/UniDB/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05749v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºéšæœºæœ€ä¼˜æ§åˆ¶ï¼ˆSOCï¼‰çš„UniDBç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡è§£å†³æ‰©æ•£æ¡¥æ¢æ¨¡å‹ä¸­çš„çŸ­æ¿ï¼Œæœ‰æ•ˆæ”¹è¿›äº†å›¾åƒç¿»è¯‘å’Œæ¢å¤ä»»åŠ¡ã€‚è¯¥æ¡†æ¶è§£å†³äº†ç°æœ‰æ‰©æ•£æ¡¥æ¢æ¨¡å‹äº§ç”Ÿçš„æ¨¡ç³Šæˆ–è¿‡åº¦å¹³æ»‘å›¾åƒç»†èŠ‚çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡å¼•å…¥å¯è°ƒç»ˆç«¯æƒ©ç½šç³»æ•°ï¼Œå®ç°äº†æ§åˆ¶æˆæœ¬ä¸ç»ˆç«¯æƒ©ç½šä¹‹é—´çš„æœ€ä¼˜å¹³è¡¡ï¼Œæé«˜äº†ç»†èŠ‚ä¿ç•™å’Œè¾“å‡ºè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¡¥æ¢æ¨¡å‹åˆ©ç”¨Doobçš„$h$-å˜æ¢åœ¨åˆ†å¸ƒä¹‹é—´å»ºç«‹å›ºå®šç«¯ç‚¹ï¼Œåœ¨å›¾åƒç¿»è¯‘å’Œæ¢å¤ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¸¸äº§ç”Ÿæ¨¡ç³Šæˆ–è¿‡åº¦å¹³æ»‘çš„å›¾åƒç»†èŠ‚ï¼Œä¸”ç¼ºä¹å…¨é¢ç†è®ºæ¥è§£é‡Šè¿™äº›çŸ­æ¿ã€‚</li>
<li>UniDBåŸºäºéšæœºæœ€ä¼˜æ§åˆ¶ï¼ˆSOCï¼‰æå‡ºç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³æ‰©æ•£æ¡¥æ¢é—®é¢˜å¹¶å¯¼å‡ºæœ€ä¼˜æ§åˆ¶å™¨çš„å°é—­å½¢å¼è§£å†³æ–¹æ¡ˆã€‚</li>
<li>UniDBå°†ç°æœ‰ä½¿ç”¨Doobçš„$h$-å˜æ¢çš„æ‰©æ•£æ¡¥æ¢è§†ä¸ºæ¡†æ¶çš„ç‰¹æ®Šæƒ…å½¢ï¼Œå½“SOCæˆæœ¬å‡½æ•°ä¸­çš„ç»ˆç«¯æƒ©ç½šç³»æ•°è¶‹äºæ— ç©·æ—¶ã€‚</li>
<li>é€šè¿‡å¼•å…¥å¯è°ƒç»ˆç«¯æƒ©ç½šç³»æ•°ï¼ŒUniDBåœ¨æ§åˆ¶æˆæœ¬ä¸ç»ˆç«¯æƒ©ç½šä¹‹é—´è¾¾åˆ°æœ€ä¼˜å¹³è¡¡ï¼Œæ”¹å–„ç»†èŠ‚ä¿ç•™å’Œè¾“å‡ºè´¨é‡ã€‚</li>
<li>UniDBä¸ç°æœ‰æ‰©æ•£æ¡¥æ¢æ¨¡å‹æ— ç¼é›†æˆï¼Œåªéœ€æœ€å°ä»£ç ä¿®æ”¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05749">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1f3d9f5ee52d15d41ed0506e3233ffd0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42702818ec49ca577b43d88be668d7aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ccdd65aa023a3f3a7229dd8c9e6f225e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Transformer-Neural-Processes-Kernel-Regression"><a href="#Transformer-Neural-Processes-Kernel-Regression" class="headerlink" title="Transformer Neural Processes - Kernel Regression"></a>Transformer Neural Processes - Kernel Regression</h2><p><strong>Authors:Daniel Jenson, Jhonathan Navott, Mengyan Zhang, Makkunda Sharma, Elizaveta Semenova, Seth Flaxman</strong></p>
<p>Neural Processes (NPs) are a rapidly evolving class of models designed to directly model the posterior predictive distribution of stochastic processes. Originally developed as a scalable alternative to Gaussian Processes (GPs), which are limited by $O(n^3)$ runtime complexity, the most accurate modern NPs can often rival GPs but still suffer from an $O(n^2)$ bottleneck due to their attention mechanism. We introduce the Transformer Neural Process - Kernel Regression (TNP-KR), a scalable NP featuring: (1) a Kernel Regression Block (KRBlock), a simple, extensible, and parameter efficient transformer block with complexity $O(n_c^2 + n_c n_t)$, where $n_c$ and $n_t$ are the number of context and test points, respectively; (2) a kernel-based attention bias; and (3) two novel attention mechanisms: scan attention (SA), a memory-efficient scan-based attention that when paired with a kernel-based bias can make TNP-KR translation invariant, and deep kernel attention (DKA), a Performer-style attention that implicitly incoporates a distance bias and further reduces complexity to $O(n_c)$. These enhancements enable both TNP-KR variants to perform inference with 100K context points on over 1M test points in under a minute on a single 24GB GPU. On benchmarks spanning meta regression, Bayesian optimization, image completion, and epidemiology, TNP-KR with DKA outperforms its Performer counterpart on nearly every benchmark, while TNP-KR with SA achieves state-of-the-art results. </p>
<blockquote>
<p>ç¥ç»è¿‡ç¨‹ï¼ˆNPsï¼‰æ˜¯ä¸€ç±»å¿«é€Ÿæ¼”å˜çš„æ¨¡å‹ï¼Œæ—¨åœ¨ç›´æ¥å¯¹éšæœºè¿‡ç¨‹çš„åéªŒé¢„æµ‹åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚æœ€åˆä½œä¸ºé«˜æ–¯è¿‡ç¨‹ï¼ˆGPsï¼‰çš„å¯æ‰©å±•æ›¿ä»£æ–¹æ¡ˆè€Œå¼€å‘ï¼Œé«˜æ–¯è¿‡ç¨‹å—åˆ°$O(n^3)$è¿è¡Œæ—¶é—´å¤æ‚åº¦çš„é™åˆ¶ï¼Œè€Œç°ä»£æœ€å‡†ç¡®çš„ç¥ç»è¿‡ç¨‹å¾€å¾€å¯ä»¥ä¸é«˜æ–¯è¿‡ç¨‹ç›¸ç«äº‰ï¼Œä½†ç”±äºå…¶æ³¨æ„åŠ›æœºåˆ¶ï¼Œä»ç„¶å—åˆ°$O(n^2)$ç“¶é¢ˆçš„é™åˆ¶ã€‚æˆ‘ä»¬ä»‹ç»äº†Transformerç¥ç»è¿‡ç¨‹-æ ¸å›å½’ï¼ˆTNP-KRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯æ‰©å±•çš„NPï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼šï¼ˆ1ï¼‰æ ¸å›å½’å—ï¼ˆKRBlockï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•ã€å¯æ‰©å±•ã€å‚æ•°é«˜æ•ˆçš„å˜å‹å™¨å—ï¼Œå¤æ‚åº¦ä¸º$O(n_c^2 + n_c n_t)$ï¼Œå…¶ä¸­$n_c$å’Œ$n_t$åˆ†åˆ«æ˜¯ä¸Šä¸‹æ–‡ç‚¹å’Œæµ‹è¯•ç‚¹çš„æ•°é‡ï¼›ï¼ˆ2ï¼‰åŸºäºæ ¸çš„æ³¨æ„åŠ›åå·®ï¼›ï¼ˆ3ï¼‰ä¸¤ç§æ–°å‹æ³¨æ„åŠ›æœºåˆ¶ï¼šæ‰«ææ³¨æ„åŠ›ï¼ˆSAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰«æçš„ã€å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ï¼Œä¸åŸºäºæ ¸çš„åå·®ç›¸ç»“åˆï¼Œå¯ä»¥ä½¿TNP-KRå…·æœ‰å¹³ç§»ä¸å˜æ€§ï¼›æ·±åº¦æ ¸æ³¨æ„åŠ›ï¼ˆDKAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§éšå¼åŒ…å«è·ç¦»åå·®çš„Performeré£æ ¼çš„æ³¨æ„åŠ›ï¼Œè¿›ä¸€æ­¥å°†å¤æ‚åº¦é™ä½åˆ°$O(n_c)$ã€‚è¿™äº›å¢å¼ºåŠŸèƒ½ä½¿TNP-KRçš„ä¸¤ä¸ªå˜ä½“èƒ½å¤Ÿåœ¨å•ä¸ª24GB GPUä¸Šåœ¨ä¸€åˆ†é’Ÿå†…å¯¹è¶…è¿‡ä¸€ç™¾ä¸‡æµ‹è¯•ç‚¹è¿›è¡Œä¸€ä¸‡ä¸ªä¸Šä¸‹æ–‡ç‚¹çš„æ¨ç†ã€‚åœ¨æ¶µç›–å…ƒå›å½’ã€è´å¶æ–¯ä¼˜åŒ–ã€å›¾åƒè¡¥å…¨å’Œæµè¡Œç—…å­¦ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå¸¦æœ‰DKAçš„TNP-KRåœ¨å‡ ä¹æ¯ä¸ªåŸºå‡†æµ‹è¯•ä¸­éƒ½è¶…è¿‡äº†å…¶Performerå¯¹æ‰‹ï¼Œè€Œå¸¦æœ‰SAçš„TNP-KRåˆ™å®ç°äº†æœ€æ–°ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.12502v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œè¿‡ç¨‹ï¼ˆNPsï¼‰æ˜¯ä¸€ç±»ç›´æ¥æ¨¡æ‹Ÿéšæœºè¿‡ç¨‹åéªŒé¢„æµ‹åˆ†å¸ƒçš„æ¨¡å‹ã€‚ä½œä¸ºä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£é«˜æ–¯è¿‡ç¨‹ï¼ˆGPsï¼‰çš„æ¨¡å‹ï¼Œç¥ç»ç½‘ç»œè¿‡ç¨‹æœ€åˆå…‹æœäº†GPsçš„O(n^3)è¿è¡Œæ—¶é—´å¤æ‚åº¦é™åˆ¶ã€‚æˆ‘ä»¬å¼•å…¥Transformerç¥ç»ç½‘ç»œè¿‡ç¨‹-æ ¸å›å½’ï¼ˆTNP-KRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯æ‰©å±•çš„NPï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼šç®€å•çš„æ ¸å›å½’å—ï¼ˆKRBlockï¼‰ï¼›åŸºäºæ ¸çš„æ³¨æ„åŠ›åå·®ï¼›ä¸¤ç§æ–°å‹æ³¨æ„åŠ›æœºåˆ¶ï¼šæ‰«ææ³¨æ„åŠ›ï¼ˆSAï¼‰å’Œæ·±åº¦æ ¸æ³¨æ„åŠ›ï¼ˆDKAï¼‰ã€‚è¿™äº›æ”¹è¿›ä½¿å¾—TNP-KRèƒ½å¤Ÿåœ¨å•ä¸ª24GB GPUä¸Šåœ¨ä¸€åˆ†é’Ÿå†…å®Œæˆå¯¹è¶…è¿‡ä¸€ç™¾ä¸‡æµ‹è¯•ç‚¹çš„ä¸€ä¸‡ç‚¹è¿›è¡Œæ¨æ–­ã€‚åœ¨æ¶µç›–å…ƒå›å½’ã€è´å¶æ–¯ä¼˜åŒ–ã€å›¾åƒè¡¥å…¨å’Œæµè¡Œç—…å­¦ç­‰é¢†åŸŸçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTNP-KRä¼˜äºå…¶è¡¨æ¼”è€…ç«å“ï¼Œå®ç°äº†å“è¶Šçš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œè¿‡ç¨‹ï¼ˆNPsï¼‰ç›´æ¥æ¨¡æ‹Ÿéšæœºè¿‡ç¨‹çš„åéªŒé¢„æµ‹åˆ†å¸ƒã€‚</li>
<li>TNP-KRä½œä¸ºä¸€ç§å¯æ‰©å±•çš„NPæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³é«˜æ–¯è¿‡ç¨‹ï¼ˆGPsï¼‰çš„è¿ç®—ç“¶é¢ˆã€‚</li>
<li>TNP-KRå¼•å…¥äº†Kernel Regression Blockï¼ˆKRBlockï¼‰ï¼Œå…·æœ‰ç®€å•ã€å¯æ‰©å±•å’Œå‚æ•°é«˜æ•ˆçš„ç‰¹æ€§ã€‚</li>
<li>TNP-KRé‡‡ç”¨äº†åŸºäºæ ¸çš„æ³¨æ„åŠ›åå·®å’Œä¸¤ç§æ–°å‹æ³¨æ„åŠ›æœºåˆ¶ï¼šæ‰«ææ³¨æ„åŠ›ï¼ˆSAï¼‰å’Œæ·±åº¦æ ¸æ³¨æ„åŠ›ï¼ˆDKAï¼‰ã€‚</li>
<li>TNP-KRèƒ½å¤Ÿå¤„ç†å¤§é‡çš„ä¸Šä¸‹æ–‡ç‚¹å’Œæµ‹è¯•ç‚¹ï¼Œå®ç°é«˜æ•ˆæ¨æ–­ã€‚</li>
<li>TNP-KRåœ¨å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬å…ƒå›å½’ã€è´å¶æ–¯ä¼˜åŒ–ã€å›¾åƒè¡¥å…¨å’Œæµè¡Œç—…å­¦ç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.12502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ac580d3d661143b9d1397e5760421cb1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeb689aef6b2367a3b4f590c3e65ccc9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2b35e5d98ecd41dd69a802f77b215380.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-017088891f4396a03e0d26ec1cce3533.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Efficient-Image-to-Image-Diffusion-Classifier-for-Adversarial-Robustness"><a href="#Efficient-Image-to-Image-Diffusion-Classifier-for-Adversarial-Robustness" class="headerlink" title="Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness"></a>Efficient Image-to-Image Diffusion Classifier for Adversarial Robustness</h2><p><strong>Authors:Hefei Mei, Minjing Dong, Chang Xu</strong></p>
<p>Diffusion models (DMs) have demonstrated great potential in the field of adversarial robustness, where DM-based defense methods can achieve superior defense capability without adversarial training. However, they all require huge computational costs due to the usage of large-scale pre-trained DMs, making it difficult to conduct full evaluation under strong attacks and compare with traditional CNN-based methods. Simply reducing the network size and timesteps in DMs could significantly harm the image generation quality, which invalidates previous frameworks. To alleviate this issue, we redesign the diffusion framework from generating high-quality images to predicting distinguishable image labels. Specifically, we employ an image translation framework to learn many-to-one mapping from input samples to designed orthogonal image labels. Based on this framework, we introduce an efficient Image-to-Image diffusion classifier with a pruned U-Net structure and reduced diffusion timesteps. Besides the framework, we redesign the optimization objective of DMs to fit the target of image classification, where a new classification loss is incorporated in the DM-based image translation framework to distinguish the generated label from those of other classes. We conduct sufficient evaluations of the proposed classifier under various attacks on popular benchmarks. Extensive experiments show that our method achieves better adversarial robustness with fewer computational costs than DM-based and CNN-based methods. The code is available at <a target="_blank" rel="noopener" href="https://github.com/hfmei/IDC">https://github.com/hfmei/IDC</a> </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å¯¹æŠ—ç¨³å¥æ€§é¢†åŸŸè¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œè¯¥é¢†åŸŸä¸­çš„DMsé˜²å¾¡æ–¹æ³•å¯ä»¥åœ¨æ— éœ€å¯¹æŠ—è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°å‡ºè‰²çš„é˜²å¾¡èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºä½¿ç”¨äº†å¤§è§„æ¨¡çš„é¢„è®­ç»ƒDMsï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½éœ€è¦å·¨å¤§çš„è®¡ç®—æˆæœ¬ï¼Œä½¿å¾—åœ¨å¼ºæ”»å‡»ä¸‹è¿›è¡Œå…¨é¢è¯„ä¼°å’Œä¸ä¼ ç»ŸåŸºäºCNNçš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒå˜å¾—å›°éš¾ã€‚ç®€å•ç¼©å°DMsçš„ç½‘ç»œè§„æ¨¡å’Œå‡å°‘æ—¶é—´æ­¥é•¿å¯èƒ½ä¼šæå¤§åœ°æŸå®³å›¾åƒç”Ÿæˆè´¨é‡ï¼Œä»è€Œä½¿ç°æœ‰æ¡†æ¶å¤±æ•ˆã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡æ–°è®¾è®¡äº†æ‰©æ•£æ¡†æ¶ï¼Œä»ç”Ÿæˆé«˜è´¨é‡å›¾åƒè½¬å‘é¢„æµ‹å¯åŒºåˆ†çš„å›¾åƒæ ‡ç­¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨å›¾åƒç¿»è¯‘æ¡†æ¶æ¥å­¦ä¹ ä»è¾“å…¥æ ·æœ¬åˆ°è®¾è®¡çš„æ­£äº¤å›¾åƒæ ‡ç­¾çš„å¤šå¯¹ä¸€æ˜ å°„ã€‚åŸºäºè¿™ä¸€æ¡†æ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é«˜æ•ˆçš„å›¾åƒåˆ°å›¾åƒçš„æ‰©æ•£åˆ†ç±»å™¨ï¼Œå®ƒå…·æœ‰ä¿®å‰ªçš„U-Netç»“æ„å’Œå‡å°‘çš„æ‰©æ•£æ—¶é—´æ­¥é•¿ã€‚é™¤äº†æ¡†æ¶ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜é‡æ–°è®¾è®¡äº†DMsçš„ä¼˜åŒ–ç›®æ ‡ä»¥é€‚åº”å›¾åƒåˆ†ç±»çš„ç›®æ ‡ï¼Œåœ¨åŸºäºDMçš„å›¾åƒç¿»è¯‘æ¡†æ¶ä¸­èå…¥æ–°çš„åˆ†ç±»æŸå¤±æ¥åŒºåˆ†ç”Ÿæˆçš„æ ‡ç­¾ä¸å…¶ä»–ç±»åˆ«çš„æ ‡ç­¾ã€‚æˆ‘ä»¬åœ¨æµè¡Œçš„åŸºå‡†æµ‹è¯•ä¸Šå¯¹æå‡ºçš„åˆ†ç±»å™¨è¿›è¡Œäº†å„ç§æ”»å‡»ä¸‹çš„å……åˆ†è¯„ä¼°ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è®¡ç®—æˆæœ¬æ›´ä½çš„æƒ…å†µä¸‹å®ç°äº†æ¯”åŸºäºDMå’ŒåŸºäºCNNçš„æ–¹æ³•æ›´å¥½çš„å¯¹æŠ—ç¨³å¥æ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/hfmei/IDC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/hfmei/IDCæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.08502v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å¯¹æŠ—é²æ£’æ€§é¢†åŸŸçš„åº”ç”¨ã€‚é’ˆå¯¹DMsè®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ†ç±»æ‰©æ•£æ¨¡å‹ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å›¾åƒç¿»è¯‘æ¡†æ¶ï¼Œé€šè¿‡è®¸å¤šä¸€å¯¹ä¸€çš„æ˜ å°„æ–¹å¼ç”Ÿæˆè®¾è®¡æ­£äº¤å›¾åƒæ ‡ç­¾ã€‚ä¼˜åŒ–åçš„æ¨¡å‹å…·æœ‰æ›´é«˜çš„å¯¹æŠ—é²æ£’æ€§å’Œæ›´ä½çš„è®¡ç®—æˆæœ¬ã€‚ç›¸å…³ä»£ç å·²å‘å¸ƒåœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å¯¹æŠ—é²æ£’æ€§é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œæ— éœ€å¯¹æŠ—è®­ç»ƒå³å¯å®ç°å‡ºè‰²çš„é˜²å¾¡èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰çš„æ‰©æ•£æ¨¡å‹è®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥åœ¨å¼ºæ”»å‡»ä¸‹è¿›è¡Œå…¨é¢è¯„ä¼°å¹¶ä¸ä¼ ç»Ÿçš„CNNæ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ†ç±»æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å›¾åƒç¿»è¯‘æ¡†æ¶å®ç°è¾“å…¥æ ·æœ¬åˆ°è®¾è®¡æ­£äº¤å›¾åƒæ ‡ç­¾çš„æ˜ å°„ã€‚</li>
<li>å¼•å…¥äº†å…·æœ‰ä¿®å‰ªU-Netç»“æ„å’Œå‡å°‘æ‰©æ•£æ—¶æ­¥çš„é«˜æ•ˆå›¾åƒåˆ°å›¾åƒçš„æ‰©æ•£åˆ†ç±»å™¨ã€‚</li>
<li>å¯¹DMçš„ä¼˜åŒ–ç›®æ ‡è¿›è¡Œäº†é‡æ–°è®¾è®¡ï¼Œä»¥é€‚åº”å›¾åƒåˆ†ç±»çš„ç›®æ ‡ï¼Œå°†æ–°çš„åˆ†ç±»æŸå¤±çº³å…¥DMåŸºäºå›¾åƒç¿»è¯‘æ¡†æ¶ä¸­ï¼Œä»¥åŒºåˆ†ç”Ÿæˆçš„æ ‡ç­¾ä¸å…¶ä»–ç±»åˆ«çš„æ ‡ç­¾ã€‚</li>
<li>åœ¨æµè¡Œçš„åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å……åˆ†çš„è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¯¹æŠ—é²æ£’æ€§æ–¹é¢è¡¨ç°æ›´å¥½ï¼Œè®¡ç®—æˆæœ¬æ›´ä½ï¼Œä¼˜äºDMå’ŒCNNæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.08502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f210132023f34e878e58e0c3b9d875f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f97af9c9769d34765cea25490ed9b2bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a5ed8cbb338025ebd0b1878cf9d92ef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b398304448e4440fb1c3d8060718bf4e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2057c61709b56dfe23d52e86ea5edeae.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-844fb2a7569e1a6e83fa78ee4260f6da.jpg" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  CoS Chain-of-Shot Prompting for Long Video Understanding
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-80d8acb33bdcaba3f7608b2be4ffc7a9.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Explanation based In-Context Demonstrations Retrieval for Multilingual   Grammatical Error Correction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25243.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
