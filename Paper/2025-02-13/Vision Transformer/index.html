<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  ViLa-MIL Dual-scale Vision-Language Multiple Instance Learning for   Whole Slide Image Classification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-edeb99732cb1da4e93c800a291f4cf89.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-13-æ›´æ–°"><a href="#2025-02-13-æ›´æ–°" class="headerlink" title="2025-02-13 æ›´æ–°"></a>2025-02-13 æ›´æ–°</h1><h2 id="ViLa-MIL-Dual-scale-Vision-Language-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification"><a href="#ViLa-MIL-Dual-scale-Vision-Language-Multiple-Instance-Learning-for-Whole-Slide-Image-Classification" class="headerlink" title="ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for   Whole Slide Image Classification"></a>ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for   Whole Slide Image Classification</h2><p><strong>Authors:Jiangbo Shi, Chen Li, Tieliang Gong, Yefeng Zheng, Huazhu Fu</strong></p>
<p>Multiple instance learning (MIL)-based framework has become the mainstream for processing the whole slide image (WSI) with giga-pixel size and hierarchical image context in digital pathology. However, these methods heavily depend on a substantial number of bag-level labels and solely learn from the original slides, which are easily affected by variations in data distribution. Recently, vision language model (VLM)-based methods introduced the language prior by pre-training on large-scale pathological image-text pairs. However, the previous text prompt lacks the consideration of pathological prior knowledge, therefore does not substantially boost the modelâ€™s performance. Moreover, the collection of such pairs and the pre-training process are very time-consuming and source-intensive.To solve the above problems, we propose a dual-scale vision-language multiple instance learning (ViLa-MIL) framework for whole slide image classification. Specifically, we propose a dual-scale visual descriptive text prompt based on the frozen large language model (LLM) to boost the performance of VLM effectively. To transfer the VLM to process WSI efficiently, for the image branch, we propose a prototype-guided patch decoder to aggregate the patch features progressively by grouping similar patches into the same prototype; for the text branch, we introduce a context-guided text decoder to enhance the text features by incorporating the multi-granular image contexts. Extensive studies on three multi-cancer and multi-center subtyping datasets demonstrate the superiority of ViLa-MIL. </p>
<blockquote>
<p>åŸºäºå¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰çš„æ¡†æ¶å·²æˆä¸ºå¤„ç†å…·æœ‰åƒå…†åƒç´ å¤§å°å’Œåˆ†å±‚å›¾åƒä¸Šä¸‹æ–‡çš„å…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„ä¸»æµæ–¹æ³•ï¼Œåœ¨æ•°å­—ç—…ç†å­¦ä¸­å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸¥é‡ä¾èµ–äºå¤§é‡çš„åŒ…çº§æ ‡ç­¾ï¼Œå¹¶ä¸”ä»…ä»åŸå§‹å¹»ç¯ç‰‡ä¸­å­¦ä¹ ï¼Œè¿™å¾ˆå®¹æ˜“å—åˆ°æ•°æ®åˆ†å¸ƒå˜åŒ–çš„å½±å“ã€‚æœ€è¿‘ï¼ŒåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æ–¹æ³•é€šè¿‡å¤§è§„æ¨¡ç—…ç†å­¦å›¾åƒæ–‡æœ¬å¯¹è¿›è¡Œé¢„è®­ç»ƒï¼Œå¼•å…¥äº†è¯­è¨€å…ˆéªŒçŸ¥è¯†ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ–‡æœ¬æç¤ºæ²¡æœ‰è€ƒè™‘åˆ°ç—…ç†å…ˆéªŒçŸ¥è¯†ï¼Œå› æ­¤å¹¶æ²¡æœ‰æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ­¤ç±»å¯¹çš„æ”¶é›†ä»¥åŠé¢„è®­ç»ƒè¿‡ç¨‹éå¸¸è€—æ—¶ä¸”èµ„æºå¯†é›†ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºå…¨å¹»ç¯ç‰‡å›¾åƒåˆ†ç±»çš„åŒå°ºåº¦è§†è§‰è¯­è¨€å¤šå®ä¾‹å­¦ä¹ ï¼ˆViLa-MILï¼‰æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åŸºäºå†»ç»“çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æå‡ºäº†åŒå°ºåº¦è§†è§‰æè¿°æ–‡æœ¬æç¤ºï¼Œä»¥æœ‰æ•ˆæé«˜VLMçš„æ€§èƒ½ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å°†VLMç”¨äºå¤„ç†WSIï¼Œå¯¹äºå›¾åƒåˆ†æ”¯ï¼Œæˆ‘ä»¬æå‡ºäº†åŸå‹å¼•å¯¼è¡¥ä¸è§£ç å™¨ï¼Œé€šè¿‡å°†ç›¸ä¼¼çš„è¡¥ä¸åˆ†ç»„åˆ°åŒä¸€åŸå‹ä¸­æ¥é€æ­¥èšåˆè¡¥ä¸ç‰¹å¾ï¼›å¯¹äºæ–‡æœ¬åˆ†æ”¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸Šä¸‹æ–‡å¼•å¯¼æ–‡æœ¬è§£ç å™¨ï¼Œé€šè¿‡ç»“åˆå¤šç²’åº¦å›¾åƒä¸Šä¸‹æ–‡æ¥å¢å¼ºæ–‡æœ¬ç‰¹å¾ã€‚åœ¨ä¸‰ä¸ªå¤šç™Œå’Œå¤šä¸­å¿ƒäºšå‹æ•°æ®é›†ä¸Šçš„å¹¿æ³›ç ”ç©¶è¡¨æ˜ï¼ŒViLa-MILå…·æœ‰ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08391v1">PDF</a> CVPR 2024 (Updated version with corrections for typos and errors.)</p>
<p><strong>Summary</strong><br>åœ¨æ•°å­—ç—…ç†å­¦ä¸­ï¼Œå¤„ç†å…·æœ‰åƒå…†åƒç´ å¤§å°å’Œå±‚æ¬¡å›¾åƒä¸Šä¸‹æ–‡çš„å…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„ä¸»æµæ–¹æ³•æ˜¯åŸºäºå¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰çš„æ¡†æ¶ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸¥é‡ä¾èµ–äºå¤§é‡çš„åŒ…çº§æ ‡ç­¾ï¼Œå¹¶ä»…ä»åŸå§‹å¹»ç¯ç‰‡ä¸­å­¦ä¹ ï¼Œå®¹æ˜“å—åˆ°æ•°æ®åˆ†å¸ƒå˜åŒ–çš„å½±å“ã€‚æœ€è¿‘ï¼ŒåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æ–¹æ³•é€šè¿‡åœ¨å¤§è§„æ¨¡ç—…ç†å›¾åƒæ–‡æœ¬å¯¹ä¸Šé¢„è®­ç»ƒå¼•å…¥äº†è¯­è¨€å…ˆéªŒã€‚ç„¶è€Œï¼Œç”±äºä¹‹å‰çš„æ–‡æœ¬æç¤ºç¼ºä¹ç—…ç†å…ˆéªŒçŸ¥è¯†è€ƒè™‘ï¼Œæœªèƒ½æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ­¤ç±»å¯¹çš„æ”¶é›†å’Œé¢„è®­ç»ƒè¿‡ç¨‹éå¸¸è€—æ—¶å’Œè€—è´¹èµ„æºã€‚ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºå…¨å¹»ç¯ç‰‡å›¾åƒåˆ†ç±»çš„åŒå°ºåº¦è§†è§‰è¯­è¨€å¤šå®ä¾‹å­¦ä¹ ï¼ˆViLa-MILï¼‰æ¡†æ¶ã€‚é€šè¿‡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŒå°ºåº¦è§†è§‰æè¿°æ–‡æœ¬æç¤ºæœ‰æ•ˆå¢å¼ºVLMæ€§èƒ½ã€‚ä¸ºäº†å°†VLMæœ‰æ•ˆåœ°åº”ç”¨äºWSIå¤„ç†ï¼Œæˆ‘ä»¬åœ¨å›¾åƒåˆ†æ”¯ä¸­æå‡ºäº†åŸå‹å¼•å¯¼è¡¥ä¸è§£ç å™¨ï¼Œé€šè¿‡é€æ­¥èšåˆè¡¥ä¸ç‰¹å¾å°†ç›¸ä¼¼çš„è¡¥ä¸åˆ†ç»„åˆ°åŒä¸€åŸå‹ä¸­ï¼›åœ¨æ–‡æœ¬åˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸Šä¸‹æ–‡å¼•å¯¼æ–‡æœ¬è§£ç å™¨ï¼Œé€šè¿‡ç»“åˆå¤šç²’åº¦å›¾åƒä¸Šä¸‹æ–‡å¢å¼ºæ–‡æœ¬ç‰¹å¾ã€‚åœ¨ä¸‰ä¸ªå¤šç™Œå’Œå¤šä¸­å¿ƒäºšå‹æ•°æ®é›†ä¸Šçš„å¹¿æ³›ç ”ç©¶è¡¨æ˜ï¼ŒViLa-MILå…·æœ‰ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ˜¯å½“å‰å¤„ç†æ•°å­—ç—…ç†å­¦ä¸­çš„å…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„ä¸»æµæ–¹æ³•ã€‚</li>
<li>MILæ–¹æ³•å­˜åœ¨å¯¹å¤§é‡åŒ…çº§æ ‡ç­¾çš„ä¾èµ–å’Œæ•°æ®åˆ†å¸ƒå˜åŒ–çš„æ•æ„Ÿæ€§ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¼•å…¥è¯­è¨€å…ˆéªŒï¼Œä½†ä¹‹å‰çš„æ–¹æ³•ç¼ºä¹ç—…ç†å…ˆéªŒçŸ¥è¯†çš„è€ƒè™‘ã€‚</li>
<li>ViLa-MILæ¡†æ¶ç»“åˆåŒå°ºåº¦è§†è§‰æè¿°æ–‡æœ¬æç¤ºå’ŒåŸå‹å¼•å¯¼è¡¥ä¸è§£ç å™¨ï¼Œå¢å¼ºVLMæ€§èƒ½ã€‚</li>
<li>å›¾åƒåˆ†æ”¯é‡‡ç”¨åŸå‹å¼•å¯¼è¡¥ä¸è§£ç å™¨ï¼Œé€šè¿‡åˆ†ç»„ç›¸ä¼¼è¡¥ä¸åˆ°åŒä¸€åŸå‹æ¥èšåˆç‰¹å¾ã€‚</li>
<li>æ–‡æœ¬åˆ†æ”¯å¼•å…¥ä¸Šä¸‹æ–‡å¼•å¯¼æ–‡æœ¬è§£ç å™¨ï¼Œç»“åˆå¤šç²’åº¦å›¾åƒä¸Šä¸‹æ–‡å¢å¼ºæ–‡æœ¬ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08391">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-373be23ac5914191089640733bf4cc85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-964b724051df6b4f0d109c0c1845b728.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edeb99732cb1da4e93c800a291f4cf89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24a60953342f0342ce8f332e993527cc.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Hi-End-MAE-Hierarchical-encoder-driven-masked-autoencoders-are-stronger-vision-learners-for-medical-image-segmentation"><a href="#Hi-End-MAE-Hierarchical-encoder-driven-masked-autoencoders-are-stronger-vision-learners-for-medical-image-segmentation" class="headerlink" title="Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger   vision learners for medical image segmentation"></a>Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger   vision learners for medical image segmentation</h2><p><strong>Authors:Fenghe Tang, Qingsong Yao, Wenxin Ma, Chenxu Wu, Zihang Jiang, S. Kevin Zhou</strong></p>
<p>Medical image segmentation remains a formidable challenge due to the label scarcity. Pre-training Vision Transformer (ViT) through masked image modeling (MIM) on large-scale unlabeled medical datasets presents a promising solution, providing both computational efficiency and model generalization for various downstream tasks. However, current ViT-based MIM pre-training frameworks predominantly emphasize local aggregation representations in output layers and fail to exploit the rich representations across different ViT layers that better capture fine-grained semantic information needed for more precise medical downstream tasks. To fill the above gap, we hereby present Hierarchical Encoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-training solution, which centers on two key innovations: (1) Encoder-driven reconstruction, which encourages the encoder to learn more informative features to guide the reconstruction of masked patches; and (2) Hierarchical dense decoding, which implements a hierarchical decoding structure to capture rich representations across different layers. We pre-train Hi-End-MAE on a large-scale dataset of 10K CT scans and evaluated its performance across seven public medical image segmentation benchmarks. Extensive experiments demonstrate that Hi-End-MAE achieves superior transfer learning capabilities across various downstream tasks, revealing the potential of ViT in medical imaging applications. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/Hi-End-MAE">https://github.com/FengheTan9/Hi-End-MAE</a> </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªç”±äºæ ‡ç­¾ç¨€ç¼ºè€Œéš¾ä»¥åº”å¯¹çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¤§è§„æ¨¡æ— æ ‡ç­¾åŒ»å­¦æ•°æ®é›†è¿›è¡Œæ©æ¨¡å›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰çš„é¢„è®­ç»ƒè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ä¸ºè¿™ä¸€é—®é¢˜æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºå„ç§ä¸‹æ¸¸ä»»åŠ¡æä¾›äº†è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„åŸºäºViTçš„MIMé¢„è®­ç»ƒæ¡†æ¶ä¸»è¦ä¾§é‡äºè¾“å‡ºå±‚çš„å±€éƒ¨èšåˆè¡¨ç¤ºï¼Œå¹¶æœªèƒ½å……åˆ†åˆ©ç”¨ä¸åŒViTå±‚ä¸­çš„ä¸°å¯Œè¡¨ç¤ºï¼Œè¿™äº›å±‚èƒ½æ›´å¥½åœ°æ•è·ç”¨äºæ›´ç²¾ç¡®åŒ»å­¦ä¸‹æ¸¸ä»»åŠ¡çš„ç»†ç²’åº¦è¯­ä¹‰ä¿¡æ¯ã€‚ä¸ºäº†å¡«è¡¥ä¸Šè¿°ç©ºç™½ï¼Œæˆ‘ä»¬ç‰¹æ­¤æ¨å‡ºå±‚æ¬¡ç¼–ç å™¨é©±åŠ¨MAEï¼ˆHi-End-MAEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„åŸºäºViTçš„é¢„è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼Œå…¶æ ¸å¿ƒåŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ç¼–ç å™¨é©±åŠ¨é‡å»ºï¼Œè¿™é¼“åŠ±ç¼–ç å™¨å­¦ä¹ æ›´å¤šä¿¡æ¯ç‰¹å¾ä»¥æŒ‡å¯¼æ©ç è¡¥ä¸çš„é‡å»ºï¼›ï¼ˆ2ï¼‰å±‚æ¬¡å¯†é›†è§£ç ï¼Œå®ƒå®ç°äº†å±‚æ¬¡è§£ç ç»“æ„ä»¥æ•è·ä¸åŒå±‚æ¬¡çš„ä¸°å¯Œè¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨åŒ…å«ä¸€ä¸‡æ¬¡CTæ‰«æçš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒäº†Hi-End-MAEï¼Œå¹¶åœ¨ä¸ƒä¸ªå…¬å¼€åŒ»å­¦å›¾åƒåˆ†å‰²åŸºå‡†ä¸Šè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHi-End-MAEåœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šå®ç°äº†å“è¶Šçš„è¿ç§»å­¦ä¹ èƒ½åŠ›ï¼Œå±•ç°äº†ViTåœ¨åŒ»å­¦æˆåƒåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚ä»£ç å¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://github.com/FengheTan9/Hi-End-MAE">https://github.com/FengheTan9/Hi-End-MAE</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08347v1">PDF</a> 19 pages, Code: <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/Hi-End-MAE">https://github.com/FengheTan9/Hi-End-MAE</a></p>
<p><strong>Summary</strong>ï¼š<br>åŒ»å­¦å›¾åƒåˆ†å‰²å› æ ‡ç­¾ç¨€ç¼ºè€Œé¢ä¸´æŒ‘æˆ˜ã€‚é€šè¿‡å¤§è§„æ¨¡æ— æ ‡ç­¾åŒ»å­¦æ•°æ®é›†å¯¹è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œé‡‡ç”¨æ©è†œå›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰çš„æ–¹æ³•å±•ç°å‡ºäº†ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹å¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºViTçš„MIMé¢„è®­ç»ƒæ¡†æ¶ä¸»è¦ä¾§é‡äºè¾“å‡ºå±‚çš„å±€éƒ¨èšåˆè¡¨ç¤ºï¼Œå¹¶æœªå……åˆ†åˆ©ç”¨ä¸åŒViTå±‚ä¸­çš„ä¸°å¯Œè¡¨ç¤ºï¼Œè¿™äº›å±‚èƒ½æ›´å¥½åœ°æ•æ‰ç²¾ç»†çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¹äºæ›´ç²¾ç¡®çš„åŒ»å­¦ä¸‹æ¸¸ä»»åŠ¡è‡³å…³é‡è¦ã€‚ä¸ºäº†å¼¥è¡¥ä¸Šè¿°ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å±‚ç¼–ç å™¨çš„MAEï¼ˆHi-End-MAEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„ViTé¢„è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼Œå®ƒèšç„¦äºä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ç¼–ç å™¨é©±åŠ¨çš„é‡æ„ï¼Œé¼“åŠ±ç¼–ç å™¨å­¦ä¹ æ›´æœ‰ä¿¡æ¯çš„ç‰¹å¾æ¥æŒ‡å¯¼é®æŒ¡è¡¥ä¸çš„é‡æ„ï¼›ï¼ˆ2ï¼‰åˆ†å±‚å¯†é›†è§£ç ï¼Œå®ç°åˆ†å±‚è§£ç ç»“æ„ï¼Œä»¥æ•è·ä¸åŒå±‚çš„ä¸°å¯Œè¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨åŒ…å«1ä¸‡å¼ CTæ‰«æçš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒäº†Hi-End-MAEï¼Œå¹¶åœ¨ä¸ƒä¸ªå…¬å…±åŒ»å­¦å›¾åƒåˆ†å‰²åŸºå‡†ä¸Šè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒHi-End-MAEåœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šå®ç°äº†å“è¶Šçš„è¿ç§»å­¦ä¹ èƒ½åŠ›ï¼Œå±•ç°äº†ViTåœ¨åŒ»å­¦æˆåƒåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´æ ‡ç­¾ç¨€ç¼ºçš„æŒ‘æˆ˜ã€‚</li>
<li>é¢„è®­ç»ƒVision Transformerï¼ˆViTï¼‰é€šè¿‡æ©è†œå›¾åƒå»ºæ¨¡ï¼ˆMIMï¼‰åœ¨å¤§å‹æ— æ ‡ç­¾åŒ»å­¦æ•°æ®é›†ä¸Šæ˜¯ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰ViT-based MIMé¢„è®­ç»ƒæ¡†æ¶ä¸»è¦ä¾§é‡äºè¾“å‡ºå±‚çš„å±€éƒ¨èšåˆè¡¨ç¤ºï¼Œéœ€è¦æ”¹è¿›ã€‚</li>
<li>Hi-End-MAEæå‡ºä¸€ç§åŸºäºåˆ†å±‚ç¼–ç å™¨çš„é¢„è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç¼–ç å™¨é©±åŠ¨çš„é‡æ„å’Œåˆ†å±‚å¯†é›†è§£ç ã€‚</li>
<li>Hi-End-MAEåœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªå…¬å…±åŒ»å­¦å›¾åƒåˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>Hi-End-MAEçš„å®ç°æ˜¾ç¤ºå‡ºViTåœ¨åŒ»å­¦æˆåƒåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08347">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5178ece69358f5c154c14087166dca3f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-498a4896204c168f5018e6a0d4e6cb32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31a24c243e039d4fee3a395c329cdaa7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82b5ca3f28882dab571a3a64a25ac750.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1d7a9cced67687a8ab65afd3013d3a2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ViSIR-Vision-Transformer-Single-Image-Reconstruction-Method-for-Earth-System-Models"><a href="#ViSIR-Vision-Transformer-Single-Image-Reconstruction-Method-for-Earth-System-Models" class="headerlink" title="ViSIR: Vision Transformer Single Image Reconstruction Method for Earth   System Models"></a>ViSIR: Vision Transformer Single Image Reconstruction Method for Earth   System Models</h2><p><strong>Authors:Ehsan Zeraatkar, Salah Faroughi, Jelena TeÅ¡iÄ‡</strong></p>
<p>Purpose: Earth system models (ESMs) integrate the interactions of the atmosphere, ocean, land, ice, and biosphere to estimate the state of regional and global climate under a wide variety of conditions. The ESMs are highly complex, and thus, deep neural network architectures are used to model the complexity and store the down-sampled data. In this paper, we propose the Vision Transformer Sinusoidal Representation Networks (ViSIR) to improve the single image SR (SR) reconstruction task for the ESM data.   Methods: ViSIR combines the SR capability of Vision Transformers (ViT) with the high-frequency detail preservation of the Sinusoidal Representation Network (SIREN) to address the spectral bias observed in SR tasks.   Results: The ViSIR outperforms ViT by 4.1 dB, SIREN by 7.5 dB, and SR-Generative Adversarial (SR-GANs) by 7.1dB PSNR on average for three different measurements.   Conclusion: The proposed ViSIR is evaluated and compared with state-of-the-art methods. The results show that the proposed algorithm is outperforming other methods in terms of Mean Square Error(MSE), Peak-Signal-to-Noise-Ratio(PSNR), and Structural Similarity Index Measure(SSIM). </p>
<blockquote>
<p>ç›®çš„ï¼šåœ°çƒç³»ç»Ÿæ¨¡å‹ï¼ˆESMï¼‰æ•´åˆäº†å¤§æ°”ã€æµ·æ´‹ã€é™†åœ°ã€å†°å·å’Œç”Ÿç‰©åœˆçš„ç›¸äº’ä½œç”¨ï¼Œä»¥åœ¨å¤šç§æ¡ä»¶ä¸‹ä¼°è®¡åŒºåŸŸå’Œå…¨çƒæ°”å€™çš„çŠ¶æ€ã€‚ç”±äºESMé«˜åº¦å¤æ‚ï¼Œå› æ­¤ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„æ¥å¯¹å…¶å¤æ‚æ€§è¿›è¡Œå»ºæ¨¡å¹¶å­˜å‚¨é™é‡‡æ ·æ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºVision Transformeræ­£å¼¦è¡¨ç¤ºç½‘ç»œï¼ˆViSIRï¼‰æ¥æ”¹è¿›ESMæ•°æ®çš„å•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰é‡å»ºä»»åŠ¡ã€‚æ–¹æ³•ï¼šViSIRç»“åˆäº†Vision Transformerï¼ˆViTï¼‰çš„è¶…åˆ†è¾¨ç‡èƒ½åŠ›ä¸æ­£å¼¦è¡¨ç¤ºç½‘ç»œï¼ˆSIRENï¼‰çš„é«˜é¢‘ç»†èŠ‚ä¿ç•™åŠŸèƒ½ï¼Œä»¥è§£å†³SRä»»åŠ¡ä¸­è§‚å¯Ÿåˆ°çš„å…‰è°±åå·®ã€‚ç»“æœï¼šViSIRåœ¨ä¸‰ä¸ªä¸åŒæµ‹é‡æŒ‡æ ‡ä¸Šçš„å¹³å‡PSNRå€¼æ¯”ViTé«˜å‡º4.1 dBï¼Œæ¯”SIRENé«˜å‡º7.5 dBï¼Œæ¯”SR-ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆSR-GANsï¼‰é«˜å‡º7.1 dBã€‚ç»“è®ºï¼šæ‰€æå‡ºçš„ViSIRä¸æœ€æ–°æŠ€æœ¯æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°æ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰æ–¹é¢ï¼Œè¯¥ç®—æ³•çš„æ€§èƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06741v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ°çƒç³»ç»Ÿæ¨¡å‹ï¼ˆESMsï¼‰çš„å¤æ‚æ€§åŠå…¶åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ç»“åˆVision Transformerå’ŒSinusoidal Representation Networkçš„ViSIRç½‘ç»œï¼Œä»¥æ”¹è¿›åœ°çƒç³»ç»Ÿæ•°æ®çš„å•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰é‡å»ºä»»åŠ¡ã€‚ViSIRé€šè¿‡ç»“åˆVision Transformerçš„SRèƒ½åŠ›å’ŒSinusoidal Representation Networkçš„é«˜é¢‘ç»†èŠ‚ä¿ç•™èƒ½åŠ›ï¼Œè§£å†³äº†SRä»»åŠ¡ä¸­çš„å…‰è°±åå·®é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒViSIRåœ¨PSNRæŒ‡æ ‡ä¸Šè¾ƒViTã€SIRENå’ŒSR-GANsåˆ†åˆ«æé«˜äº†4.1dBã€7.5dBå’Œ7.1dBã€‚æ€»ä½“è€Œè¨€ï¼ŒViSIRè¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åœ°çƒç³»ç»Ÿæ¨¡å‹çš„å¤æ‚æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ°çƒç³»ç»Ÿæ¨¡å‹ï¼ˆESMsï¼‰åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„å¯¹å¤§æ°”ã€æµ·æ´‹ã€é™†åœ°ã€å†°å’Œç”Ÿç‰©åœˆä¹‹é—´çš„ç›¸äº’ä½œç”¨è¿›è¡Œå»ºæ¨¡ï¼Œä»¥ä¼°ç®—å„ç§æ¡ä»¶ä¸‹çš„åŒºåŸŸå’Œå…¨çƒæ°”å€™çŠ¶æ€ã€‚</li>
<li>æå‡ºçš„ViSIRç½‘ç»œç»“åˆäº†Vision Transformerå’ŒSinusoidal Representation Networkçš„ä¼˜åŠ¿ï¼Œæ—¨åœ¨æ”¹è¿›åœ°çƒç³»ç»Ÿæ•°æ®çš„å•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰é‡å»ºä»»åŠ¡ã€‚</li>
<li>ViSIRé€šè¿‡è§£å†³SRä»»åŠ¡ä¸­çš„å…‰è°±åå·®é—®é¢˜ï¼Œå®ç°äº†è‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒViSIRåœ¨PSNRã€MSEå’ŒSSIMç­‰è¯„ä»·æŒ‡æ ‡ä¸Šè¾ƒå…¶ä»–å…ˆè¿›æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>ViSIRèƒ½å¤Ÿå¤„ç†åœ°çƒç³»ç»Ÿæ¨¡å‹çš„å¤æ‚æ•°æ®ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨åœ°çƒç³»ç»Ÿæ¨¡å‹æ•°æ®å»ºæ¨¡ä¸­çš„åº”ç”¨å±•ç¤ºäº†å…¶å¼ºå¤§çš„å¤„ç†å¤æ‚æ•°æ®çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06741">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cf9048c3b816cee988efb911d2fe6083.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88028bcf0c1828b06f6099fcd8baf426.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee43ee84dd1032a6ae63795dd0fd3c89.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0272a4ba28fe565af009c03462bf7be8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Guiding-Medical-Vision-Language-Models-with-Explicit-Visual-Prompts-Framework-Design-and-Comprehensive-Exploration-of-Prompt-Variations"><a href="#Guiding-Medical-Vision-Language-Models-with-Explicit-Visual-Prompts-Framework-Design-and-Comprehensive-Exploration-of-Prompt-Variations" class="headerlink" title="Guiding Medical Vision-Language Models with Explicit Visual Prompts:   Framework Design and Comprehensive Exploration of Prompt Variations"></a>Guiding Medical Vision-Language Models with Explicit Visual Prompts:   Framework Design and Comprehensive Exploration of Prompt Variations</h2><p><strong>Authors:Kangyu Zhu, Ziyuan Qin, Huahui Yi, Zekun Jiang, Qicheng Lao, Shaoting Zhang, Kang Li</strong></p>
<p>While mainstream vision-language models (VLMs) have advanced rapidly in understanding image level information, they still lack the ability to focus on specific areas designated by humans. Rather, they typically rely on large volumes of high-quality image-text paired data to learn and generate posterior attention maps. To address this critical issue, we propose leveraging visual prompts:simple visual markers in various forms to guide and enhance the formation of region-specific attention. Thus, we introduce MedVP, a pioneering framework that integrates medical entity extraction, visual prompt generation, and dataset adaptation for visual prompt guided fine-tuning. We successfully outperform recent state-of-the-art large models across multiple medical VQA datasets. Extensive experiments and Human evaluation are conducted to analyze the impact of different visual prompt forms and how they contribute to performance improvement. The results demonstrate both the effectiveness and clinical significance of our approach. </p>
<blockquote>
<p>ä¸»æµçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è™½ç„¶åœ¨ç†è§£å›¾åƒçº§åˆ«çš„ä¿¡æ¯æ–¹é¢å–å¾—äº†å¿«é€Ÿå‘å±•ï¼Œä½†å®ƒä»¬ä»ç„¶ç¼ºä¹å…³æ³¨äººç±»æŒ‡å®šçš„ç‰¹å®šåŒºåŸŸçš„èƒ½ã€‚ç›¸åï¼Œå®ƒä»¬é€šå¸¸ä¾èµ–äºå¤§é‡é«˜è´¨é‡å›¾åƒæ–‡æœ¬é…å¯¹æ•°æ®æ¥å­¦ä¹ å’Œç”Ÿæˆåç»­æ³¨æ„åŠ›å›¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨è§†è§‰æç¤ºï¼šä»¥å„ç§å½¢å¼çš„ç®€å•è§†è§‰æ ‡è®°æ¥å¼•å¯¼å’Œå¢å¼ºç‰¹å®šåŒºåŸŸçš„æ³¨æ„åŠ›å½¢æˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†MedVPï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„æ¡†æ¶ï¼Œå®ƒèåˆäº†åŒ»å­¦å®ä½“æå–ã€è§†è§‰æç¤ºç”Ÿæˆå’Œæ•°æ®é›†è‡ªé€‚åº”ï¼Œç”¨äºè§†è§‰æç¤ºå¼•å¯¼çš„å¾®è°ƒã€‚æˆ‘ä»¬åœ¨å¤šä¸ªåŒ»å­¦VQAæ•°æ®é›†ä¸ŠæˆåŠŸè¶…è¶Šäº†æœ€æ–°çš„æœ€å…ˆè¿›çš„å¤§å‹æ¨¡å‹ã€‚è¿›è¡Œäº†å¤§é‡å®éªŒå’Œäººç±»è¯„ä¼°ï¼Œåˆ†æäº†ä¸åŒè§†è§‰æç¤ºå½¢å¼çš„å½±å“ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•æœ‰åŠ©äºæ€§èƒ½æå‡ã€‚ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¸´åºŠæ„ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02385v2">PDF</a> Accepted to NAACL 2025 Main Conference</p>
<p><strong>Summary</strong><br>åœ¨è¿™ä¸ªæ–‡æœ¬ä¸­ï¼Œä»‹ç»äº†é’ˆå¯¹ä¸»æµè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å›¾åƒå±‚é¢ä¿¡æ¯å¤„ç†ä¸Šå­˜åœ¨çš„ä¸è¶³è€Œæå‡ºçš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆé€šè¿‡åˆ©ç”¨è§†è§‰æç¤ºï¼ˆVisual Promptsï¼‰æ¥å¢å¼ºæ¨¡å‹å¯¹ç‰¹å®šåŒºåŸŸçš„æ³¨æ„åŠ›ï¼Œä»è€Œæ”¹è¿›æ¨¡å‹çš„è¡¨ç°ã€‚ä¸ºæ­¤ï¼Œä»–ä»¬æå‡ºäº†MedVPæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†åŒ»å­¦å®ä½“æå–ã€è§†è§‰æç¤ºç”Ÿæˆå’Œé’ˆå¯¹è§†è§‰æç¤ºå¼•å¯¼å¾®è°ƒçš„æ•°æ®é›†é€‚é…æŠ€æœ¯ã€‚ç»è¿‡åœ¨å¤šä¸ªåŒ»å­¦VQAæ•°æ®é›†ä¸Šçš„å®éªŒå’Œäººæ–‡è¯„ä¼°ï¼Œè¯æ˜è¯¥æ–¹æ³•æ—¢æœ‰æ•ˆåˆå…·æœ‰ä¸´åºŠæ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸»æµè§†è§‰è¯­è¨€æ¨¡å‹è™½ç„¶èƒ½è¿…é€Ÿç†è§£å›¾åƒçº§åˆ«çš„ä¿¡æ¯ï¼Œä½†éš¾ä»¥èšç„¦äºäººç±»æŒ‡å®šçš„ç‰¹å®šåŒºåŸŸã€‚</li>
<li>è§†è§‰æç¤ºæ˜¯ä¸€ç§ç®€å•çš„è§†è§‰æ ‡è®°ï¼Œç”¨äºæŒ‡å¯¼å’Œå¢å¼ºæ¨¡å‹å¯¹ç‰¹å®šåŒºåŸŸçš„æ³¨æ„åŠ›ã€‚</li>
<li>MedVPæ¡†æ¶ç»“åˆäº†åŒ»å­¦å®ä½“æå–ã€è§†è§‰æç¤ºç”Ÿæˆå’Œé’ˆå¯¹è§†è§‰æç¤ºå¼•å¯¼å¾®è°ƒçš„æ•°æ®é›†é€‚é…æŠ€æœ¯ã€‚</li>
<li>é€šè¿‡åœ¨å¤šä¸ªåŒ»å­¦VQAæ•°æ®é›†ä¸Šçš„å®éªŒå’Œäººæ–‡è¯„ä¼°ï¼Œè¯æ˜è¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œä¸´åºŠæ„ä¹‰ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰æç¤ºæ¥æ”¹å–„æ¨¡å‹çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¢å¼ºæ¨¡å‹å¯¹å…³é”®åŒºåŸŸçš„æ³¨æ„åŠ›æ¥å®ç°è¿™ä¸€ç‚¹ã€‚</li>
<li>è§†è§‰æç¤ºçš„å½¢å¼å¯¹æ¨¡å‹æ€§èƒ½æœ‰å½±å“ï¼Œæ–‡ç« æ¢è®¨äº†ä¸åŒå½¢å¼è§†è§‰æç¤ºçš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02385">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2359de5dbf449da69e28d57f4110c5e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-001774c6f2cc04073995e6e0e9bcf237.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf8cfe5f1916e6af5e550dab44a2a489.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="YOLO11-and-Vision-Transformers-based-3D-Pose-Estimation-of-Immature-Green-Fruits-in-Commercial-Apple-Orchards-for-Robotic-Thinning"><a href="#YOLO11-and-Vision-Transformers-based-3D-Pose-Estimation-of-Immature-Green-Fruits-in-Commercial-Apple-Orchards-for-Robotic-Thinning" class="headerlink" title="YOLO11 and Vision Transformers based 3D Pose Estimation of Immature   Green Fruits in Commercial Apple Orchards for Robotic Thinning"></a>YOLO11 and Vision Transformers based 3D Pose Estimation of Immature   Green Fruits in Commercial Apple Orchards for Robotic Thinning</h2><p><strong>Authors:Ranjan Sapkota, Manoj Karkee</strong></p>
<p>In this study, a robust method for 3D pose estimation of immature green apples (fruitlets) in commercial orchards was developed, utilizing the YOLO11(or YOLOv11) object detection and pose estimation algorithm alongside Vision Transformers (ViT) for depth estimation (Dense Prediction Transformer (DPT) and Depth Anything V2). For object detection and pose estimation, performance comparisons of YOLO11 (YOLO11n, YOLO11s, YOLO11m, YOLO11l and YOLO11x) and YOLOv8 (YOLOv8n, YOLOv8s, YOLOv8m, YOLOv8l and YOLOv8x) were made under identical hyperparameter settings among the all configurations. It was observed that YOLO11n surpassed all configurations of YOLO11 and YOLOv8 in terms of box precision and pose precision, achieving scores of 0.91 and 0.915, respectively. Conversely, YOLOv8n exhibited the highest box and pose recall scores of 0.905 and 0.925, respectively. Regarding the mean average precision at 50% intersection over union (mAP@50), YOLO11s led all configurations with a box mAP@50 score of 0.94, while YOLOv8n achieved the highest pose mAP@50 score of 0.96. In terms of image processing speed, YOLO11n outperformed all configurations with an impressive inference speed of 2.7 ms, significantly faster than the quickest YOLOv8 configuration, YOLOv8n, which processed images in 7.8 ms. Subsequent integration of ViTs for the green fruitâ€™s pose depth estimation revealed that Depth Anything V2 outperformed Dense Prediction Transformer in 3D pose length validation, achieving the lowest Root Mean Square Error (RMSE) of 1.52 and Mean Absolute Error (MAE) of 1.28, demonstrating exceptional precision in estimating immature green fruit lengths. Integration of YOLO11 and Depth Anything Model provides a promising solution to 3D pose estimation of immature green fruits for robotic thinning applications. (YOLOv11 pose detection, YOLOv11 Pose, YOLOv11 Keypoints detection, YOLOv11 pose estimation) </p>
<blockquote>
<p>åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œå¼€å‘äº†ä¸€ç§åˆ©ç”¨YOLO11ï¼ˆæˆ–YOLOv11ï¼‰ç›®æ ‡æ£€æµ‹ä¸å§¿æ€ä¼°è®¡ç®—æ³•ä»¥åŠç”¨äºæ·±åº¦ä¼°è®¡çš„Vision Transformersï¼ˆViTï¼‰ï¼ˆåŒ…æ‹¬Dense Prediction Transformerï¼ˆDPTï¼‰å’ŒDepth Anything V2ï¼‰è¿›è¡Œå•†ç”¨æœå›­ä¸­æœªæˆç†Ÿé’è‹¹æœï¼ˆå¹¼æœï¼‰çš„3Då§¿æ€ä¼°è®¡çš„ç¨³å¥æ–¹æ³•ã€‚åœ¨ç›®æ ‡æ£€æµ‹å’Œå§¿æ€ä¼°è®¡æ–¹é¢ï¼Œåœ¨ç›¸åŒçš„è¶…å‚æ•°è®¾ç½®ä¸‹ï¼Œå¯¹YOLO11ï¼ˆYOLO11nã€YOLO1sã€YOLO11mã€YOLO11lå’ŒYOLO1lxï¼‰å’ŒYOLOv8ï¼ˆYOLOv8nã€YOLOv8sã€YOLOv8mã€YOLOv8lå’ŒYOLOv8xï¼‰çš„æ‰€æœ‰é…ç½®è¿›è¡Œäº†æ€§èƒ½æ¯”è¾ƒã€‚è§‚å¯Ÿå‘ç°ï¼ŒYOLO1lnåœ¨æ¡†ç²¾åº¦å’Œå§¿æ€ç²¾åº¦æ–¹é¢è¶…è¶Šäº†æ‰€æœ‰YOLO11å’ŒYOLOv8çš„é…ç½®ï¼Œåˆ†åˆ«è¾¾åˆ°äº†0.91å’Œ0.915ã€‚ç›¸åï¼ŒYOLOv8nåœ¨ç›’å’Œå§¿æ€å¬å›ç‡æ–¹é¢è¡¨ç°å‡ºæœ€é«˜å¾—åˆ†ï¼Œåˆ†åˆ«ä¸º0.905å’Œ0.925ã€‚åœ¨50%äº¤é›†è”åˆçš„å¹³å‡ç²¾åº¦ï¼ˆmAP@50ï¼‰æ–¹é¢ï¼ŒYOLO1lsåœ¨æ‰€æœ‰é…ç½®ä¸­è¡¨ç°æœ€ä½³ï¼Œç›’mAP@50å¾—åˆ†ä¸º0.94ï¼Œè€ŒYOLOv8nåˆ™å–å¾—äº†æœ€é«˜çš„å§¿æ€mAP@50å¾—åˆ†ï¼Œä¸º0.96ã€‚åœ¨å›¾åƒå¤„ç†é€Ÿåº¦æ–¹é¢ï¼ŒYOLO1lnè¡¨ç°æœ€ä½³ï¼Œæ¨ç†é€Ÿåº¦ä¸º2.7æ¯«ç§’ï¼Œæ¯”æœ€å¿«çš„YOLOv8é…ç½®YOLOv8nå¿«å¾—å¤šï¼Œåè€…å¤„ç†å›¾åƒéœ€è¦7.8æ¯«ç§’ã€‚éšåå¯¹ç»¿è‰²æœå®å§¿æ€æ·±åº¦ä¼°è®¡çš„ViTsé›†æˆæ˜¾ç¤ºï¼ŒDepth Anything V2åœ¨3Då§¿æ€é•¿åº¦éªŒè¯ä¸­ä¼˜äºDense Prediction Transformerï¼Œå®ç°äº†æœ€ä½çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ä¸º1.52å’Œå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ä¸º1.28ï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¼°ç®—æœªæˆç†Ÿç»¿è‰²æœå®é•¿åº¦æ–¹é¢çš„å‡ºè‰²ç²¾ç¡®åº¦ã€‚YOLO11ä¸Depth Anythingæ¨¡å‹çš„èåˆä¸ºè§£å†³æœºå™¨äººä¿®å‰ªåº”ç”¨çš„æœªæˆç†Ÿç»¿è‰²æœå®3Då§¿æ€ä¼°è®¡é—®é¢˜æä¾›äº†æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚ï¼ˆYOLOvllå§¿æ€æ£€æµ‹ã€YOLOvllå§¿æ€ã€YOLOvllå…³é”®ç‚¹æ£€æµ‹ã€YOLOvllå§¿æ€ä¼°è®¡ï¼‰</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19846v2">PDF</a> 24 Pages, 13 Figures, 1 Table</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶åˆ©ç”¨YOLOv11è¿›è¡Œè‹¹æœå¹¼æœçš„ä¸‰ç»´å§¿æ€ä¼°è®¡ï¼Œç»“åˆVision Transformersä¸­çš„Dense Prediction Transformerå’ŒDepth Anything V2è¿›è¡Œæ·±åº¦é¢„æµ‹ã€‚YOLOv11ä¸­çš„YOLO11nåœ¨boxç²¾åº¦å’Œå§¿æ€ç²¾åº¦ä¸Šè¡¨ç°æœ€ä½³ï¼Œè€ŒYOLOv8nåœ¨å¬å›ç‡ä¸Šè¡¨ç°æœ€ä½³ã€‚Depth Anything V2åœ¨ä¼°ç®—ç»¿è‰²å¹¼æœé•¿åº¦æ–¹é¢è¡¨ç°å‡ºè¾ƒé«˜ç²¾ç¡®åº¦ã€‚ç»“åˆYOLO11å’ŒDepth Anything Modelå¯ä¸ºæœºå™¨äººè‡ªåŠ¨ç–æœåº”ç”¨æä¾›å¯é çš„ä¸‰ç»´å§¿æ€ä¼°è®¡è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡‡ç”¨YOLOv11è¿›è¡Œè‹¹æœå¹¼æœçš„ä¸‰ç»´å§¿æ€ä¼°è®¡ï¼Œå…·æœ‰å¤šç§é…ç½®ç”¨äºæ¯”è¾ƒæ€§èƒ½ã€‚</li>
<li>YOLO11nåœ¨boxç²¾åº¦å’Œå§¿æ€ç²¾åº¦ä¸Šè¶…è¶Šå…¶ä»–é…ç½®ï¼Œè€ŒYOLOv8nåœ¨å¬å›ç‡æ–¹é¢è¡¨ç°æœ€ä½³ã€‚</li>
<li>Depth Anything V2åœ¨ä¼°ç®—ç»¿è‰²å¹¼æœé•¿åº¦æ–¹é¢è¡¨ç°å‡ºè¾ƒé«˜ç²¾ç¡®åº¦ï¼Œç›¸è¾ƒäºDense Prediction Transformeræœ‰æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>Vision Transformersè¢«æˆåŠŸåº”ç”¨äºæ·±åº¦ä¼°è®¡ã€‚</li>
<li>YOLOv11ç»“åˆDepth Anything Modelå±•ç°å‡ºåœ¨ä¼°ç®—ä¸æˆç†Ÿç»¿æœä¸‰ç»´å§¿æ€æ–¹é¢çš„æ½œåŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºæœºå™¨äººè‡ªåŠ¨ç–æœåº”ç”¨æä¾›äº†å¯é çš„ä¸‰ç»´å§¿æ€ä¼°è®¡è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19846">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-858bef01394a43b4daf8c53ffb0228cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8e844f550b4d61b54760aff6aecf768.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d04302418979873c1613027df315461a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffe6967911603b22b91aaa9bb7abc240.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Interpretable-Vision-Language-Survival-Analysis-with-Ordinal-Inductive-Bias-for-Computational-Pathology"><a href="#Interpretable-Vision-Language-Survival-Analysis-with-Ordinal-Inductive-Bias-for-Computational-Pathology" class="headerlink" title="Interpretable Vision-Language Survival Analysis with Ordinal Inductive   Bias for Computational Pathology"></a>Interpretable Vision-Language Survival Analysis with Ordinal Inductive   Bias for Computational Pathology</h2><p><strong>Authors:Pei Liu, Luping Ji, Jiaxiang Gou, Bo Fu, Mao Ye</strong></p>
<p>Histopathology Whole-Slide Images (WSIs) provide an important tool to assess cancer prognosis in computational pathology (CPATH). While existing survival analysis (SA) approaches have made exciting progress, they are generally limited to adopting highly-expressive network architectures and only coarse-grained patient-level labels to learn visual prognostic representations from gigapixel WSIs. Such learning paradigm suffers from critical performance bottlenecks, when facing present scarce training data and standard multi-instance learning (MIL) framework in CPATH. To overcome it, this paper, for the first time, proposes a new Vision-Language-based SA (VLSA) paradigm. Concretely, (1) VLSA is driven by pathology VL foundation models. It no longer relies on high-capability networks and shows the advantage of data efficiency. (2) In vision-end, VLSA encodes textual prognostic prior and then employs it as auxiliary signals to guide the aggregating of visual prognostic features at instance level, thereby compensating for the weak supervision in MIL. Moreover, given the characteristics of SA, we propose i) ordinal survival prompt learning to transform continuous survival labels into textual prompts; and ii) ordinal incidence function as prediction target to make SA compatible with VL-based prediction. Notably, VLSAâ€™s predictions can be interpreted intuitively by our Shapley values-based method. The extensive experiments on five datasets confirm the effectiveness of our scheme. Our VLSA could pave a new way for SA in CPATH by offering weakly-supervised MIL an effective means to learn valuable prognostic clues from gigapixel WSIs. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/liupei101/VLSA">https://github.com/liupei101/VLSA</a>. </p>
<blockquote>
<p>ç»„ç»‡ç—…ç†å­¦å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWhole-Slide Images, WSIï¼‰ä¸ºè®¡ç®—ç—…ç†å­¦ï¼ˆCPATHï¼‰ä¸­è¯„ä¼°ç™Œç—‡é¢„åæä¾›äº†ä¸€ç§é‡è¦å·¥å…·ã€‚å°½ç®¡ç°æœ‰çš„ç”Ÿå­˜åˆ†æï¼ˆSurvival Analysis, SAï¼‰æ–¹æ³•å·²ç»å–å¾—äº†ä»¤äººå…´å¥‹çš„è¿›å±•ï¼Œä½†å®ƒä»¬é€šå¸¸ä»…é™äºé‡‡ç”¨é«˜åº¦è¡¨è¾¾çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¹¶ä¸”ä»…ä½¿ç”¨ç²—ç²’åº¦çš„æ‚£è€…çº§æ ‡ç­¾æ¥å­¦ä¹ æ¥è‡ªgigapixel WSIçš„è§†è§‰é¢„åè¡¨ç¤ºã€‚å½“é¢ä¸´å½“å‰ç¨€ç¼ºçš„è®­ç»ƒæ•°æ®å’ŒCPATHä¸­çš„æ ‡å‡†å¤šå®ä¾‹å­¦ä¹ ï¼ˆMultiple Instance Learning, MILï¼‰æ¡†æ¶æ—¶ï¼Œè¿™ç§å­¦ä¹ æ¨¡å¼é¢ä¸´å…³é”®çš„æ€§èƒ½ç“¶é¢ˆã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæœ¬æ–‡é¦–æ¬¡æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç”Ÿå­˜åˆ†æï¼ˆVision-Language-based SA, VLSAï¼‰æ–°æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œï¼ˆ1ï¼‰VLSAç”±ç—…ç†å­¦è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹é©±åŠ¨ï¼Œä¸å†ä¾èµ–é«˜æ€§èƒ½ç½‘ç»œï¼Œå¹¶æ˜¾ç¤ºå‡ºæ•°æ®æ•ˆç‡çš„ä¼˜åŠ¿ã€‚ï¼ˆ2ï¼‰åœ¨è§†è§‰ç«¯ï¼ŒVLSAç¼–ç æ–‡æœ¬é¢„åå…ˆéªŒï¼Œç„¶åå°†å…¶ä½œä¸ºè¾…åŠ©ä¿¡å·æ¥æŒ‡å¯¼å®ä¾‹çº§è§†è§‰é¢„åç‰¹å¾çš„èšåˆï¼Œä»è€Œå¼¥è¡¥äº†MILä¸­çš„å¼±ç›‘ç£ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°ç”Ÿå­˜åˆ†æçš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬æå‡ºiï¼‰æœ‰åºç”Ÿå­˜æç¤ºå­¦ä¹ ï¼Œå°†è¿ç»­ç”Ÿå­˜æ ‡ç­¾è½¬æ¢ä¸ºæ–‡æœ¬æç¤ºï¼›ä»¥åŠiiï¼‰ä»¥æœ‰åºå‘ç”Ÿç‡å‡½æ•°ä½œä¸ºé¢„æµ‹ç›®æ ‡ï¼Œä½¿ç”Ÿå­˜åˆ†æä¸åŸºäºè§†è§‰è¯­è¨€çš„é¢„æµ‹å…¼å®¹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒVLSAçš„é¢„æµ‹å¯ä»¥é€šè¿‡æˆ‘ä»¬åŸºäºæ²™æ™®åˆ©å€¼çš„æ–¹æ³•ç›´è§‚åœ°è§£é‡Šã€‚åœ¨äº”å¥—æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯å®äº†æˆ‘ä»¬çš„æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„VLSAå¯èƒ½ä¸ºCPATHä¸­çš„ç”Ÿå­˜åˆ†æå¼€è¾Ÿä¸€æ¡æ–°è·¯ï¼Œé€šè¿‡ä¸ºå¼±ç›‘ç£MILæä¾›ä¸€ç§ä»gigapixel WSIå­¦ä¹ æœ‰ä»·å€¼é¢„åçº¿ç´¢çš„æœ‰æ•ˆæ‰‹æ®µã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/liupei101/VLSA">https://github.com/liupei101/VLSA</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09369v4">PDF</a> Accepted to ICLR 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„åŸºäºè§†è§‰å’Œè‡ªç„¶è¯­è¨€çš„ç”Ÿå­˜åˆ†æï¼ˆVLSAï¼‰èŒƒå¼ï¼Œè§£å†³äº†è®¡ç®—ç—…ç†å­¦ä¸­å¯¹å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„ç²¾ç»†åˆ†ææŒ‘æˆ˜ã€‚é€šè¿‡å¼•å…¥è‡ªç„¶è¯­è¨€æ¨¡å‹åˆ°ç—…ç†å­¦çš„ç»“åˆï¼Œè¯¥æ–¹æ³•æå‡äº†åœ¨è®­ç»ƒæ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹æ¨¡å‹çš„æ•°æ®åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶åœ¨æ ‡å‡†çš„å¤šå®ä¾‹å­¦ä¹ æ¡†æ¶å†…è§£å†³äº†æ ‡ç­¾å¼±åŒ–çš„é—®é¢˜ã€‚æ–°æ–¹æ³•è¿˜åŒ…æ‹¬å°†è¿ç»­ç”Ÿå­˜æ ‡ç­¾è½¬åŒ–ä¸ºæ–‡æœ¬æç¤ºï¼Œå¹¶åˆ©ç”¨åŸºäºShapleyå€¼çš„è§£é‡Šæ–¹æ³•ç›´è§‚åœ°è§£é‡Šé¢„æµ‹ç»“æœã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå‡æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLSAé¦–æ¬¡å°†è§†è§‰å’Œè‡ªç„¶è¯­è¨€ç»“åˆç”¨äºç”Ÿå­˜åˆ†æï¼Œè§£å†³è®¡ç®—ç—…ç†å­¦ä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>åˆ©ç”¨ç°æœ‰çš„è‡ªç„¶è¯­è¨€æ¨¡å‹æé«˜æ•°æ®åˆ©ç”¨æ•ˆç‡ï¼Œå‡å°‘å¯¹é«˜åº¦ä¸“ä¸šåŒ–çš„ç½‘ç»œæ¶æ„çš„ä¾èµ–ã€‚</li>
<li>æå‡ºä½¿ç”¨æ–‡æœ¬é¢„åå…ˆéªŒä¿¡æ¯æ¥æŒ‡å¯¼è§†è§‰é¢„åç‰¹å¾çš„èšåˆï¼Œå¼ºåŒ–å¤šå®ä¾‹å­¦ä¹ ä¸­çš„å¼±ç›‘ç£ã€‚</li>
<li>é€šè¿‡å°†è¿ç»­ç”Ÿå­˜æ ‡ç­¾è½¬åŒ–ä¸ºæ–‡æœ¬æç¤ºä»¥åŠé‡‡ç”¨æœ‰åºå‘ç”Ÿç‡å‡½æ•°ä½œä¸ºé¢„æµ‹ç›®æ ‡ï¼Œä½¿ç”Ÿå­˜åˆ†æä¸åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„é¢„æµ‹ç›¸å…¼å®¹ã€‚</li>
<li>é‡‡ç”¨åŸºäºShapleyå€¼çš„è§£é‡Šæ–¹æ³•ç›´è§‚åœ°è§£é‡Šé¢„æµ‹ç»“æœï¼Œå¢å¼ºäº†æ¨¡å‹çš„è§£é‡Šæ€§ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜ï¼ŒVLSAæ–¹æ¡ˆåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09369">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5e7098d5b272fd260f2d4597b4d01cda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94f1737ff90020bfee69a1f9b3d4e33f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-13/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ecc5a2b63abe41724fa1ac8438e80570.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  Amnesia as a Catalyst for Enhancing Black Box Pixel Attacks in Image   Classification and Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-13/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-844fb2a7569e1a6e83fa78ee4260f6da.jpg" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-13  CoS Chain-of-Shot Prompting for Long Video Understanding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24801.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
