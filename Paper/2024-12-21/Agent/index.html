<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2024-12-21  Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e52f299d172a0c3ea8966cf353feefcd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    47 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-21-更新"><a href="#2024-12-21-更新" class="headerlink" title="2024-12-21 更新"></a>2024-12-21 更新</h1><h2 id="Operationalising-Rawlsian-Ethics-for-Fairness-in-Norm-Learning-Agents"><a href="#Operationalising-Rawlsian-Ethics-for-Fairness-in-Norm-Learning-Agents" class="headerlink" title="Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents"></a>Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents</h2><p><strong>Authors:Jessica Woodgate, Paul Marshall, Nirav Ajmeri</strong></p>
<p>Social norms are standards of behaviour common in a society. However, when agents make decisions without considering how others are impacted, norms can emerge that lead to the subjugation of certain agents. We present RAWL-E, a method to create ethical norm-learning agents. RAWL-E agents operationalise maximin, a fairness principle from Rawlsian ethics, in their decision-making processes to promote ethical norms by balancing societal well-being with individual goals. We evaluate RAWL-E agents in simulated harvesting scenarios. We find that norms emerging in RAWL-E agent societies enhance social welfare, fairness, and robustness, and yield higher minimum experience compared to those that emerge in agent societies that do not implement Rawlsian ethics. </p>
<blockquote>
<p>社会规范是社会中普遍的行为标准。然而，当决策者不考虑他人所受的影响时，可能会出现导致某些代理人受压迫的规范。我们提出了RAWL-E方法，用于创建遵循道德规范的智能体。RAWL-E智能体在执行决策时实施来自罗尔斯正义论的公平原则最大化原则，通过平衡社会福祉与个人目标来促进道德规范。我们在模拟的采集场景中评估RAWL-E智能体。我们发现，在RAWL-E智能体社会中出现的规范增强了社会福祉、公平性和稳健性，与不在实施罗尔斯伦理学的智能体社会中出现的规范相比，产生了更高的最低体验。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15163v1">PDF</a> 14 pages, 7 figures, 8 tables (and supplementary material with   reproducibility and additional results), accepted at AAAI 2025</p>
<p><strong>Summary</strong><br>社会规范是一社会中普遍的行为标准。然而，当代理人做决策时若没有考虑他人的影响，可能会产生导致某些代理人被奴役的规范。我们提出了RAWL-E方法，用于创建遵循道德规范的智能体。RAWL-E智能体在决策过程中运用罗尔斯式公平原则——最大化原则，在兼顾社会福祉和个人目标的基础上推动道德规范的发展。我们在模拟的收割场景中评估了RAWL-E智能体的表现。我们发现，在RAWL-E智能体社会中形成的规范提高了社会福利、公平性和稳健性，与那些在不实施罗尔斯伦理的智能体社会中出现的规范相比，产生了更高的最低体验。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>社会规范是特定社会中的行为标准。</li>
<li>当代理人做决策时未考虑他人影响，可能出现对部分代理人不利的规范。</li>
<li>RAWL-E方法用于创建遵循道德规范的智能体。</li>
<li>RAWL-E智能体在决策时运用罗尔斯式公平原则。</li>
<li>RAWL-E智能体在模拟场景中表现优越，形成的规范提高了社会福利、公平性和稳健性。</li>
<li>与其他智能体社会相比，RAWL-E智能体社会中出现的规范产生了更高的最低体验。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15163">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-de9abb7622b8b03f86d48689aa42f49e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b813f14abfa5e3f17b2d8c2a1c58225.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4101f493936d62f15065bae0f01cface.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad86fb070de40973a4128c99edbddf36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f6a83e0a8af6ed703211e042d6d9478.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6971c5150b1827c6fbac03ea1d8def2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3e30537b546c885c97608a72afb6c08.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Bel-Esprit-Multi-Agent-Framework-for-Building-AI-Model-Pipelines"><a href="#Bel-Esprit-Multi-Agent-Framework-for-Building-AI-Model-Pipelines" class="headerlink" title="Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines"></a>Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines</h2><p><strong>Authors:Yunsu Kim, AhmedElmogtaba Abdelaziz, Thiago Castro Ferreira, Mohamed Al-Badrashiny, Hassan Sawaf</strong></p>
<p>As the demand for artificial intelligence (AI) grows to address complex real-world tasks, single models are often insufficient, requiring the integration of multiple models into pipelines. This paper introduces Bel Esprit, a conversational agent designed to construct AI model pipelines based on user-defined requirements. Bel Esprit employs a multi-agent framework where subagents collaborate to clarify requirements, build, validate, and populate pipelines with appropriate models. We demonstrate the effectiveness of this framework in generating pipelines from ambiguous user queries, using both human-curated and synthetic data. A detailed error analysis highlights ongoing challenges in pipeline construction. Bel Esprit is available for a free trial at <a target="_blank" rel="noopener" href="https://belesprit.aixplain.com/">https://belesprit.aixplain.com</a>. </p>
<blockquote>
<p>随着对人工智能（AI）的需求不断增长以解决复杂的现实世界任务，单一模型往往不足以应对，需要多个模型的集成到管道中。本文介绍了Bel Esprit，这是一个对话代理，旨在根据用户定义的要求构建AI模型管道。Bel Esprit采用多代理框架，子代理协同工作以明确需求、构建、验证和用适当的模型填充管道。我们展示了该框架在处理模糊用户查询时生成管道的有效性，并使用了人工和合成数据。详细的误差分析突出了管道构建中的持续挑战。Bel Esprit可在<a target="_blank" rel="noopener" href="https://belesprit.aixplain.com进行免费试用./">https://belesprit.aixplain.com进行免费试用。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.14684v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>随着人工智能需求增长以解决复杂的现实世界任务，单一模型常常不足以应对，需要构建AI模型管道集成多个模型。本文介绍了一款基于用户定义需求构建AI模型管道的智能对话代理Bel Esprit。Bel Esprit采用多代理框架，子代理协作澄清需求、构建、验证和填充适当的模型管道。通过人类精心策划和合成数据生成的管道实例演示了该框架的有效性。详细的错误分析突显了管道构建中的挑战。Bel Esprit已在<a target="_blank" rel="noopener" href="https://belesprit.aixplain.com提供免费试用./">https://belesprit.aixplain.com提供免费试用。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI需求的增长促使了模型管道的需求：为了满足复杂任务的完成需求，需要整合多个AI模型成管道以提高效率和准确性。</li>
<li>Bel Esprit是一个智能对话代理：它可以根据用户需求构建AI模型管道，简化了复杂的构建过程。</li>
<li>多代理框架的应用：Bel Esprit利用多代理框架实现子代理间的协作，以明确需求、建立、验证并填充模型管道。</li>
<li>框架有效性展示：通过实例演示了利用人类精心策划和合成数据生成AI模型管道的可行性及有效性。</li>
<li>详细的错误分析：揭示了当前在构建AI模型管道过程中存在的挑战和问题，为后续改进提供了方向。</li>
<li>Bel Esprit提供免费试用：用户可以通过访问指定网站体验这款智能对话代理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.14684">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f59d31f6b6725c0b1b48efe13fcdd66c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53d49d7005c96ead1e033f70a594338e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b81625a13f08a0a6093353c0f19e6d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0633d86af51a6f23fb01b511cb6fff9d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8adbe1dadc45049a711742dcc1b00ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d8d7552d70df0f20e3766786e18fe3d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Agent-SafetyBench-Evaluating-the-Safety-of-LLM-Agents"><a href="#Agent-SafetyBench-Evaluating-the-Safety-of-LLM-Agents" class="headerlink" title="Agent-SafetyBench: Evaluating the Safety of LLM Agents"></a>Agent-SafetyBench: Evaluating the Safety of LLM Agents</h2><p><strong>Authors:Zhexin Zhang, Shiyao Cui, Yida Lu, Jingzhuo Zhou, Junxiao Yang, Hongning Wang, Minlie Huang</strong></p>
<p>As large language models (LLMs) are increasingly deployed as agents, their integration into interactive environments and tool use introduce new safety challenges beyond those associated with the models themselves. However, the absence of comprehensive benchmarks for evaluating agent safety presents a significant barrier to effective assessment and further improvement. In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents. Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions. Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%. This highlights significant safety challenges in LLM agents and underscores the considerable need for improvement. Through quantitative analysis, we identify critical failure modes and summarize two fundamental safety detects in current LLM agents: lack of robustness and lack of risk awareness. Furthermore, our findings suggest that reliance on defense prompts alone is insufficient to address these safety issues, emphasizing the need for more advanced and robust strategies. We release Agent-SafetyBench at \url{<a target="_blank" rel="noopener" href="https://github.com/thu-coai/Agent-SafetyBench%7D">https://github.com/thu-coai/Agent-SafetyBench}</a> to facilitate further research and innovation in agent safety evaluation and improvement. </p>
<blockquote>
<p>随着大型语言模型（LLM）越来越多地被部署为代理，它们与交互式环境的集成和工具使用带来了新的安全挑战，这些挑战超出了与模型本身相关的挑战。然而，缺乏用于评估代理安全性的综合基准，成为有效评估和进一步改进的重大障碍。在本文中，我们介绍了Agent-SafetyBench，这是一个旨在评估LLM代理安全性的综合基准。Agent-SafetyBench包含349个交互环境和2000个测试用例，评估了8类安全风险，并涵盖了不安全交互中经常遇到的10种常见故障模式。我们对16个流行的LLM代理的评估结果令人担忧：没有一个代理的安全分数超过60%。这凸显了LLM代理存在的重大安全挑战，并强调迫切需要进行改进。通过定量分析，我们确定了关键的失败模式，并总结了当前LLM代理中的两个基本安全缺陷：缺乏稳健性和缺乏风险意识。此外，我们的研究结果表明，仅仅依赖防御提示不足以解决这些安全问题，强调需要更先进和稳健的策略。我们在\url{<a target="_blank" rel="noopener" href="https://github.com/thu-coai/Agent-SafetyBench%7D%E5%8F%91%E5%B8%83%E4%BA%86Agent-SafetyBench%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E5%9C%A8%E4%BB%A3%E7%90%86%E5%AE%89%E5%85%A8%E8%AF%84%E4%BC%B0%E5%92%8C%E6%94%B9%E8%BF%9B%E6%96%B9%E9%9D%A2%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%A0%94%E7%A9%B6%E5%92%8C%E5%88%9B%E6%96%B0%E3%80%82">https://github.com/thu-coai/Agent-SafetyBench}发布了Agent-SafetyBench，以促进在代理安全评估和改进方面的进一步研究和创新。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.14470v1">PDF</a> 23 pages, 9 figures</p>
<p><strong>Summary</strong>：随着大型语言模型（LLM）作为代理的部署越来越多，它们在交互式环境和工具使用中的集成带来了新的安全挑战。然而，缺乏全面的代理安全评估基准，阻碍了有效的评估和进一步的改进。本文介绍了Agent-SafetyBench，一个全面的基准测试，旨在评估LLM代理的安全性。它包括349个交互环境和2000个测试用例，涵盖十个常见失效模式，并评估八类安全风险。通过对当前流行的LLM代理人的评估，发现无一安全得分超过百分之六十，凸显了LLM代理人的安全挑战和巨大的改进需求。研究发现依赖防御提示并不能解决这些安全问题，因此需要更先进和稳健的策略。同时发布了Agent-SafetyBench来推动对代理安全评估和改进的进一步研究和创新。</p>
<p><strong>Key Takeaways</strong>：</p>
<ul>
<li>大型语言模型（LLM）作为代理在集成到交互式环境和工具使用时面临新的安全挑战。</li>
<li>缺乏全面的代理安全评估基准阻碍了有效的评估和进一步的改进。</li>
<li>Agent-SafetyBench是一个全面的基准测试，旨在评估LLM代理的安全性，包括多种交互环境和测试用例。</li>
<li>当前流行的LLM代理存在显著的安全挑战，无一安全得分超过百分之六十。</li>
<li>定量分析发现关键失效模式，总结了当前LLM代理的两个基本安全问题：缺乏稳健性和风险意识。</li>
<li>仅依赖防御提示不足以解决这些安全问题，需要更先进和稳健的策略。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.14470">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8af3ed94ea10452b3a41246919b4db8f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-113ee0626f0666a7008d3d3c73b01ebc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3b24b88e82dda76688b602da0bb3cb2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-379b8730e0356c89de4017333998e164.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Can-Modern-LLMs-Act-as-Agent-Cores-in-Radiology-Environments"><a href="#Can-Modern-LLMs-Act-as-Agent-Cores-in-Radiology-Environments" class="headerlink" title="Can Modern LLMs Act as Agent Cores in Radiology Environments?"></a>Can Modern LLMs Act as Agent Cores in Radiology Environments?</h2><p><strong>Authors:Qiaoyu Zheng, Chaoyi Wu, Pengcheng Qiu, Lisong Dai, Ya Zhang, Yanfeng Wang, Weidi Xie</strong></p>
<p>Advancements in large language models (LLMs) have paved the way for LLM-based agent systems that offer enhanced accuracy and interpretability across various domains. Radiology, with its complex analytical requirements, is an ideal field for the application of these agents. This paper aims to investigate the pre-requisite question for building concrete radiology agents which is, &#96;Can modern LLMs act as agent cores in radiology environments?’ To investigate it, we introduce RadABench with three-fold contributions: First, we present RadABench-Data, a comprehensive synthetic evaluation dataset for LLM-based agents, generated from an extensive taxonomy encompassing 6 anatomies, 5 imaging modalities, 10 tool categories, and 11 radiology tasks. Second, we propose RadABench-EvalPlat, a novel evaluation platform for agents featuring a prompt-driven workflow and the capability to simulate a wide range of radiology toolsets. Third, we assess the performance of 7 leading LLMs on our benchmark from 5 perspectives with multiple metrics. Our findings indicate that while current LLMs demonstrate strong capabilities in many areas, they are still not sufficiently advanced to serve as the central agent core in a fully operational radiology agent system. Additionally, we identify key factors influencing the performance of LLM-based agent cores, offering insights for clinicians on how to apply agent systems in real-world radiology practices effectively. All of our code and data are open-sourced in <a target="_blank" rel="noopener" href="https://github.com/MAGIC-AI4Med/RadABench">https://github.com/MAGIC-AI4Med/RadABench</a>. </p>
<blockquote>
<p>大型语言模型（LLM）的进步为基于LLM的代理系统铺平了道路，这些系统在各个领域提供了增强准确性和可解释性。由于其复杂的分析要求，放射学是这些代理应用的理想领域。本文旨在探讨构建具体放射学代理的先决问题，即“现代LLM能否在放射线环境中充当代理核心？”为了调查这个问题，我们推出了RadABench，它包括三方面的贡献：首先，我们展示了RadABench-Data，这是一套全面的合成评估数据集，用于基于LLM的代理，数据来自包含6个解剖学、5种成像模式、10个工具类别和11个放射学任务的广泛分类。其次，我们提出了RadABench-EvalPlat，这是一个新型代理评估平台，具有提示驱动的工作流程和模拟广泛放射学工具集的能力。第三，我们从5个角度对7个领先的大型语言模型进行了评估，使用多个指标。我们的研究发现，虽然当前的大型语言模型在许多领域表现出强大的能力，但它们仍不足以作为完全运行的放射学代理系统的核心代理。此外，我们还确定了影响基于LLM的代理核心性能的关键因素，为临床医生提供了如何在现实世界的放射学实践中有效应用代理系统的见解。所有代码和数据均在<a target="_blank" rel="noopener" href="https://github.com/MAGIC-AI4Med/RadABench%E4%B8%8A%E5%BC%80%E6%BA%90%E3%80%82">https://github.com/MAGIC-AI4Med/RadABench上开源。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.09529v2">PDF</a> 22 pages,7 figures</p>
<p><strong>Summary</strong></p>
<p>本文探讨了大型语言模型（LLM）在放射学领域的应用潜力。文章介绍了RadABench的三个主要贡献：提供了一个综合的LLM评估数据集RadABench-Data，一个用于评估LLM作为放射学代理核心性能的平台RadABench-EvalPlat，以及对七款领先的LLM的性能评估。研究结果表明，当前LLM虽在某些方面表现出色，但仍不足以作为完全运营的放射学代理系统的核心。文章还公开了所有代码和数据。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在放射学领域有广泛的应用潜力。</li>
<li>RadABench-Data是一个为LLM代理系统提供的综合评估数据集。</li>
<li>RadABench-EvalPlat是一个评估LLM作为放射学代理核心性能的平台。</li>
<li>当前LLM在某些方面表现出色，但不足以作为完全运营的放射学代理系统的核心。</li>
<li>LLM在放射学领域的应用受到一些关键因素的影响。</li>
<li>公开的代码和数据有助于临床医生有效应用代理系统在真实世界的放射学实践中。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.09529">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1e3c80dd1ef26eb84ad020d169c4df0f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-190becf8a05e2e891b2dd0eb3f6052c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-465e5a878f0cbf8788985f515e140601.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Knowledge-Tagging-with-Large-Language-Model-based-Multi-Agent-System"><a href="#Knowledge-Tagging-with-Large-Language-Model-based-Multi-Agent-System" class="headerlink" title="Knowledge Tagging with Large Language Model based Multi-Agent System"></a>Knowledge Tagging with Large Language Model based Multi-Agent System</h2><p><strong>Authors:Hang Li, Tianlong Xu, Ethan Chang, Qingsong Wen</strong></p>
<p>Knowledge tagging for questions is vital in modern intelligent educational applications, including learning progress diagnosis, practice question recommendations, and course content organization. Traditionally, these annotations have been performed by pedagogical experts, as the task demands not only a deep semantic understanding of question stems and knowledge definitions but also a strong ability to link problem-solving logic with relevant knowledge concepts. With the advent of advanced natural language processing (NLP) algorithms, such as pre-trained language models and large language models (LLMs), pioneering studies have explored automating the knowledge tagging process using various machine learning models. In this paper, we investigate the use of a multi-agent system to address the limitations of previous algorithms, particularly in handling complex cases involving intricate knowledge definitions and strict numerical constraints. By demonstrating its superior performance on the publicly available math question knowledge tagging dataset, MathKnowCT, we highlight the significant potential of an LLM-based multi-agent system in overcoming the challenges that previous methods have encountered. Finally, through an in-depth discussion of the implications of automating knowledge tagging, we underscore the promising results of deploying LLM-based algorithms in educational contexts. </p>
<blockquote>
<p>知识标签在现代智能教育应用中的使用非常重要，包括学习进度诊断、实践问题推荐和课程内容组织。传统上，这些注释由教学专家完成，因为这项工作不仅需要深入理解问题的根源和知识定义，还需要具备将问题解决逻辑与相关知识概念紧密相连的强烈能力。随着先进的自然语言处理（NLP）算法的出现，如预训练语言模型和大型语言模型（LLM），开创性研究开始尝试使用各种机器学习模型自动化知识标签过程。在本文中，我们探讨了多代理系统在解决先前算法局限方面的使用，特别是在处理涉及复杂知识定义和严格数值约束的复杂案例方面。通过在公开可用的数学知识标签数据集MathKnowCT上展示其卓越性能，我们突出了基于LLM的多代理系统在克服先前方法所面临的挑战方面的巨大潜力。最后，通过对自动化知识标签的影响进行深入讨论，我们强调了在教育环境中部署基于LLM算法的令人鼓舞的结果。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08406v2">PDF</a> Accepted by AAAI 2025 (AAAI&#x2F;IAAI 2025 Innovative Application Award)</p>
<p><strong>总结</strong><br>随着现代智能教育应用的发展，知识标注对于问题的重要性日益凸显，涉及学习进度诊断、练习问题推荐和课程内容组织等方面。传统上，这些标注由教育专家执行，任务需要深厚的语义理解、知识定义以及将问题解决逻辑与相关知识概念联系起来的强大能力。随着预训练语言模型和大语言模型（LLM）等先进自然语言处理算法的兴起，有开创性研究开始探索使用各种机器学习模型自动化知识标注过程。本文调查了多智能体系统在解决以前算法局限性方面的应用，特别是在处理复杂知识定义和严格数值约束方面的优势。在公开可用的数学问题知识标注数据集MathKnowCT上展示其卓越性能，凸显了基于LLM的多智能体系统在克服以前方法所遇到挑战方面的巨大潜力。最后，通过深入探讨自动化知识标注的影响，我们强调了部署基于LLM的算法在教育环境中的有前途的结果。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>知识标注在现代智能教育应用中具有重要意义，包括学习进度诊断、实践问题推荐和课程内容组织。</li>
<li>传统知识标注主要由教育专家完成，需要深厚的语义理解和联系问题解决与知识概念的能力。</li>
<li>随着自然语言处理算法的发展，特别是预训练语言模型和大语言模型（LLM），自动化知识标注的可行性得到提高。</li>
<li>多智能体系统能有效解决复杂知识标注问题，尤其在处理复杂知识定义和严格数值约束方面表现出优势。</li>
<li>在MathKnowCT数据集上的卓越性能表明，基于LLM的多智能体系统有巨大潜力克服先前方法的挑战。</li>
<li>自动化知识标注的深入应用有望改变教育方式，提高教育效率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08406">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5eab2143f156147757b3b70e7d058e8a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dec7e2bef41052c1d6d24f7e02431b61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e52f299d172a0c3ea8966cf353feefcd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-932a206f18cd6babf7270cf52c6086fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34f28fb558b8b866ab6d14b7529929d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-935372e271cf710d2cee66f2f7cfaec9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce7a54548c75bd2522dec9b935412922.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="IDEA-Enhancing-the-Rule-Learning-Ability-of-Large-Language-Model-Agent-through-Induction-Deduction-and-Abduction"><a href="#IDEA-Enhancing-the-Rule-Learning-Ability-of-Large-Language-Model-Agent-through-Induction-Deduction-and-Abduction" class="headerlink" title="IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent   through Induction, Deduction, and Abduction"></a>IDEA: Enhancing the Rule Learning Ability of Large Language Model Agent   through Induction, Deduction, and Abduction</h2><p><strong>Authors:Kaiyu He, Mian Zhang, Shuo Yan, Peilin Wu, Zhiyu Zoey Chen</strong></p>
<p>While large language models (LLMs) have been thoroughly evaluated for deductive and inductive reasoning, their proficiency in holistic rule learning in interactive environments remains less explored. We introduce RULEARN, a novel benchmark to assess the rule-learning abilities of LLM agents in interactive settings. In RULEARN, agents strategically interact with simulated environments to gather observations, discern patterns, and solve complex problems. To enhance the rule-learning capabilities for LLM agents, we propose IDEA, a novel reasoning framework that integrates the process of Induction, Deduction, and Abduction. The IDEA agent generates initial hypotheses from limited observations through abduction, devises plans to validate these hypotheses or leverages them to solve problems via deduction, and refines previous hypotheses through induction, dynamically establishing and applying rules that mimic human rule-learning behaviors. Our evaluation of the IDEA framework, which involves five representative LLMs, demonstrates significant improvements over the baseline. Furthermore, our study with human participants reveals notable discrepancies in rule-learning behaviors between humans and LLMs. We believe our benchmark will serve as a valuable and challenging resource, and IDEA will provide crucial insights for the development of LLM agents capable of human-like rule learning in real-world scenarios. Our code and data is publicly available. </p>
<blockquote>
<p>虽然大型语言模型（LLM）在演绎和归纳推理方面已经得到了充分的评估，但它们在交互式环境中进行整体规则学习的能力仍然缺乏探索。我们引入了RULEARN这一新型基准测试，以评估LLM代理在交互式环境中学习规则的能力。在RULEARN中，代理与模拟环境进行战略交互，以收集观察资料、识别模式并解决复杂问题。为了增强LLM代理的规则学习能力，我们提出了IDEA，这是一个集演绎、归纳和假设的新推理框架。IDEA代理通过假设从有限的观察中生成初步假设，通过演绎制定验证假设或解决问题的计划，并通过归纳修正先前的假设，动态建立和应用模仿人类规则学习行为的规则。我们对包含五个代表性LLM的IDEA框架的评估，证明了其较基线有明显的改进。此外，我们与人类参与者的研究揭示了人类和LLM在规则学习行为之间的显著差异。我们相信，我们的基准测试将成为一个宝贵且具有挑战性的资源，而IDEA将为开发能够在现实世界中像人类一样进行规则学习的LLM代理提供关键见解。我们的代码和数据已公开可用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.10455v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在演绎和归纳推理方面已经得到了广泛评估，但它们在互动环境中整体规则学习的能力仍缺乏探索。本文引入了RULEARN基准测试，以评估LLM代理人在互动环境中的规则学习能力。本文提出了IDEA，一个结合归纳、演绎和溯因推理的新型框架，用于增强LLM代理人的规则学习能力。通过五种代表性LLM的评估，显示IDEA框架较基线有显著改善。此外，与人类参与者的研究揭示了人类与LLM在规则学习行为上的显著差异。本文认为，RULEARN将为有价值且具有挑战性的资源，而IDEA将为开发能在真实场景中实现人类式规则学习的LLM代理人提供关键见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在互动环境中的整体规则学习能力尚未得到充分探索。</li>
<li>引入RULEARN基准测试，用于评估LLM在互动环境中的规则学习能力。</li>
<li>提出IDEA框架，整合归纳、演绎和溯因推理，增强LLM的规则学习能力。</li>
<li>对五种代表性LLM的评估显示，IDEA框架较基线有显著改善。</li>
<li>人类与LLM在规则学习行为上存在显著差异。</li>
<li>RULEARN基准测试是一个有价值的挑战资源。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.10455">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9a9b464aa4177de7279f002413e3cd07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2c9f1b7909fbaf5171e5913b59e6dea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01e99bb2e570e8c135ce1599aeaa7dcc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af9683d9d8fc1507f46ffc42e8915eaf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ed80002466659c5c0f18b137b9887057.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d415e834b0a3c500176f267f6a21641b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Trajectory-Prediction-with-Difficulty-Guided-Feature-Enhancement-Network"><a href="#Multi-Agent-Trajectory-Prediction-with-Difficulty-Guided-Feature-Enhancement-Network" class="headerlink" title="Multi-Agent Trajectory Prediction with Difficulty-Guided Feature   Enhancement Network"></a>Multi-Agent Trajectory Prediction with Difficulty-Guided Feature   Enhancement Network</h2><p><strong>Authors:Guipeng Xin, Duanfeng Chu, Liping Lu, Zejian Deng, Yuang Lu, Xigang Wu</strong></p>
<p>Trajectory prediction is crucial for autonomous driving as it aims to forecast the future movements of traffic participants. Traditional methods usually perform holistic inference on the trajectories of agents, neglecting the differences in prediction difficulty among agents. This paper proposes a novel Difficulty-Guided Feature Enhancement Network (DGFNet), which leverages the prediction difficulty differences among agents for multi-agent trajectory prediction. Firstly, we employ spatio-temporal feature encoding and interaction to capture rich spatio-temporal features. Secondly, a difficulty-guided decoder controls the flow of future trajectories into subsequent modules, obtaining reliable future trajectories. Then, feature interaction and fusion are performed through the future feature interaction module. Finally, the fused agent features are fed into the final predictor to generate the predicted trajectory distributions for multiple participants. Experimental results demonstrate that our DGFNet achieves state-of-the-art performance on the Argoverse 1&amp;2 motion forecasting benchmarks. Ablation studies further validate the effectiveness of each module. Moreover, compared with SOTA methods, our method balances trajectory prediction accuracy and real-time inference speed. </p>
<blockquote>
<p>轨迹预测对自动驾驶至关重要，因为它旨在预测交通参与者的未来移动。传统的方法通常对代理的轨迹进行整体推理，忽略了代理之间预测难度的差异。本文提出了一种新的难度引导特征增强网络（DGFNet），该网络利用代理之间预测难度的差异进行多代理轨迹预测。首先，我们采用时空特征编码和交互来捕捉丰富的时空特征。其次，难度引导解码器控制未来轨迹的流向后续模块，以获得可靠的未来轨迹。然后，通过未来特征交互模块进行特征交互和融合。最后，融合后的代理特征被输入到最终预测器中，以生成多个参与者的预测轨迹分布。实验结果表明，我们的DGFNet在Argoverse 1&amp;2运动预测基准测试中达到了最新技术水平。消融研究进一步验证了每个模块的有效性。此外，与最先进的方法相比，我们的方法在轨迹预测精度和实时推理速度之间达到了平衡。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.18551v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>文章提出了一种基于难度引导的特征增强网络（DGFNet）进行多智能体轨迹预测的方法。该模型考虑到了不同智能体预测难度的差异，并对其进行时空特征编码和交互，然后通过一个难度引导解码器进行未来轨迹的预测。最后，通过与现有先进方法的对比实验，证明了其在Argoverse 1&amp;2运动预测基准测试上的优越性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>该方法考虑到不同智能体轨迹预测的难度差异。</li>
<li>利用时空特征编码和交互来捕捉丰富的时空特征。</li>
<li>难度引导解码器负责控制未来轨迹的流动，以获取可靠的未来轨迹。</li>
<li>通过未来特征交互模块进行特征交互和融合。</li>
<li>该方法在Argoverse运动预测基准测试中达到了先进水平。</li>
<li>消融研究验证了每个模块的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.18551">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-c863c96e84ceea223bae3274031f2d7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f481ac63f394e18699e4eb4bf41a2e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-45ae6f589e5562ed1b62b8a094b7cf50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-379f357d00074e9cbbad6a1b5d2c95f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1242e41b4af2d954c861adc7f54460d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fd7c39bafd6d50d911aff967bd36be9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d7568a559ac7e449d8ae0a17cd58b25.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DialSim-A-Real-Time-Simulator-for-Evaluating-Long-Term-Multi-Party-Dialogue-Understanding-of-Conversational-Agents"><a href="#DialSim-A-Real-Time-Simulator-for-Evaluating-Long-Term-Multi-Party-Dialogue-Understanding-of-Conversational-Agents" class="headerlink" title="DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party   Dialogue Understanding of Conversational Agents"></a>DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party   Dialogue Understanding of Conversational Agents</h2><p><strong>Authors:Jiho Kim, Woosog Chay, Hyeonji Hwang, Daeun Kyung, Hyunseung Chung, Eunbyeol Cho, Yohan Jo, Edward Choi</strong></p>
<p>Recent advancements in Large Language Models (LLMs) have significantly enhanced the capabilities of conversational agents, making them applicable to various fields (e.g., education). Despite their progress, the evaluation of the agents often overlooks the complexities of real-world conversations, such as real-time interactions, multi-party dialogues, and extended contextual dependencies. To bridge this gap, we introduce DialSim, a real-time dialogue simulator. In this simulator, an agent is assigned the role of a character from popular TV shows, requiring it to respond to spontaneous questions using past dialogue information and to distinguish between known and unknown information. Key features of DialSim include assessing the agent’s ability to respond within a reasonable time limit, handling long-term multi-party dialogues, and evaluating performance under randomized questioning with LongDialQA, a novel, high-quality question-answering dataset. Our experiments using DialSim reveal the strengths and weaknesses of the latest conversational agents, offering valuable insights for future advancements in conversational AI. DialSim is available at <a target="_blank" rel="noopener" href="https://dialsim.github.io/">https://dialsim.github.io/</a>. </p>
<blockquote>
<p>最近大型语言模型（LLM）的进步显著增强了对话代理的能力，使其适用于各个领域（例如教育）。尽管取得了进展，但对代理的评估往往忽略了现实世界中对话的复杂性，如实时互动、多方对话和扩展的上下文依赖关系。为了弥补这一差距，我们引入了DialSim，一个实时对话模拟器。在这个模拟器中，代理被分配扮演流行电视剧中的角色，需要利用过去的对话信息回答突发问题，并区分已知和未知信息。DialSim的关键功能包括评估代理在合理时间限制内做出响应的能力、处理长期多方对话的能力，以及使用LongDialQA这一新型高质量问答数据集在随机提问下评估表现的能力。我们使用DialSim进行的实验揭示了最新对话代理的优势和劣势，为未来对话人工智能的发展提供了宝贵的见解。DialSim可在<a target="_blank" rel="noopener" href="https://dialsim.github.io/%E8%AE%BF%E9%97%AE%E3%80%82">https://dialsim.github.io/访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13144v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>对话模拟工具DialSim填补了对话AI评价中的现实差距，该工具要求对话AI模型扮演电视剧中的角色，模拟现实对话场景进行应答，评估其在限定时间内回应的能力、处理多方的长期对话的能力以及在随机问题下的表现。对于提升对话AI的进步具有重要价值。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Large Language Models (LLMs)的进展增强了对话AI的应用能力，但现实对话的复杂性在评估中常被忽视。</li>
<li>DialSim是一个实时对话模拟器，旨在填补这一评估差距。</li>
<li>DialSim要求对话AI模型扮演电视剧角色，模拟真实对话场景。</li>
<li>DialSim的关键功能包括评估AI在限定时间内回应的能力、处理长期多方的对话的能力以及在随机问题下的表现。</li>
<li>使用DialSim进行的实验揭示了最新对话AI的优势和劣势。</li>
<li>DialSim为未来的对话AI发展提供了有价值的见解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.13144">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-39b8fd60a581ea48dd0cb91f083885a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb397c5a945676c9e3749a51596ec1ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-379e21ea0c54cf9485a322e0008379cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a61eea18be2c4241dbae6e672909886.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45d7f7754df33406b50d25bff52bf58d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AndroidWorld-A-Dynamic-Benchmarking-Environment-for-Autonomous-Agents"><a href="#AndroidWorld-A-Dynamic-Benchmarking-Environment-for-Autonomous-Agents" class="headerlink" title="AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents"></a>AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents</h2><p><strong>Authors:Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva</strong></p>
<p>Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device’s system state. We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld’s tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges. AndroidWorld and the experiments in this paper are available at github.com&#x2F;google-research&#x2F;android_world. </p>
<blockquote>
<p>通过控制计算机执行人类任务，自主代理可以增强人类生产力和应用程序的可访问性。然而，这一领域的进展将取决于现实且可再生的基准测试。我们推出了AndroidWorld，这是一个功能齐全的Android环境，为20个真实世界的Android应用程序中的116个程序化任务提供了奖励信号。与现有的交互式环境不同，AndroidWorld能够动态构建任务，这些任务以自然语言参数化表达，且方式无限，从而能够在更大且更现实的任务套件上进行测试。为确保可重复性，每个任务都包含专用的初始化、成功检查和拆除逻辑，这些逻辑可以修改和检查设备系统状态。我们以基准代理进行实验来测试AndroidWorld，并在该基准测试上提供了初步结果。我们表现最佳的代理可以完成AndroidWorld的30.6%的任务，这为未来的工作留下了充足的空间。此外，我们将一个流行的桌面网络代理改编为适用于Android的版本，但发现在移动设备上效果较差，这表明需要未来的研究来实现通用跨平台代理。最后，我们还进行了稳健性分析，表明任务变化会显著影响代理性能，表明如果没有这样的测试，代理性能指标可能无法充分反映实际挑战。AndroidWorld以及本文中的实验可在<a target="_blank" rel="noopener" href="http://github.com/google-research/android_world">github.com&#x2F;google-research&#x2F;android_world</a>获取。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14573v4">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>自主执行人类任务并控制电脑的智能代理可以提升人类生产力和应用可及性。然而，该领域的进展将取决于现实且可复制的基准测试。我们推出AndroidWorld，这是一个功能齐全的Android环境，为20个真实世界Android应用程序中的116个程序化任务提供奖励信号。与现有的交互式环境不同，AndroidWorld能够动态构建任务，这些任务以自然语言无限表达，参数化设定，从而能够在更大范围和更现实的场景下测试任务。为确保可重复性，每个任务都包含专门的初始化、成功检查和清理逻辑，这些逻辑会修改和检查设备系统状态。我们对基准测试智能代理进行实验并提供了初步结果。表现最佳的智能代理能完成AndroidWorld的30.6%的任务，这为未来的工作留下了充足的空间。此外，我们还将一个流行的桌面网页智能代理改编为适用于Android的版本，发现其在移动设备上效果较差，这表明需要研究以实现跨平台的通用智能代理。我们还进行了稳健性分析，表明任务变化会显著影响智能代理的表现，表明没有这样的测试，智能代理的性能指标可能无法充分反映实际挑战。AndroidWorld以及本文中的实验可在github.com&#x2F;google-research&#x2F;android_world上找到。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>自主代理能够通过控制电脑执行人类任务，提高人类生产力和应用可及性。</li>
<li>AndroidWorld是一个功能齐全的Android环境，提供奖励信号供程序化任务测试。</li>
<li>AndroidWorld能够动态构建任务，实现更大范围和更现实的测试场景。</li>
<li>每个任务都包含初始化、成功检查和清理逻辑以确保测试的可靠性和可重复性。</li>
<li>目前最佳智能代理只能完成AndroidWorld的30.6%的任务，表明未来研究空间巨大。</li>
<li>将桌面网页智能代理改编为适用于Android的版本效果较差，需要研究跨平台智能代理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.14573">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f6f929bdf7cbe31493cdde17ad821d77.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21ba6a8ff3dc2c16781fab9afddb76ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-730ca0f13fe01c8993fe652131c112d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b83658b457458e77dc055871c774eea.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Agent-Planning-with-World-Knowledge-Model"><a href="#Agent-Planning-with-World-Knowledge-Model" class="headerlink" title="Agent Planning with World Knowledge Model"></a>Agent Planning with World Knowledge Model</h2><p><strong>Authors:Shuofei Qiao, Runnan Fang, Ningyu Zhang, Yuqi Zhu, Xiang Chen, Shumin Deng, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</strong></p>
<p>Recent endeavors towards directly using large language models (LLMs) as agent models to execute interactive planning tasks have shown commendable results. Despite their achievements, however, they still struggle with brainless trial-and-error in global planning and generating hallucinatory actions in local planning due to their poor understanding of the &#96;&#96;real’’ physical world. Imitating humans’ mental world knowledge model which provides global prior knowledge before the task and maintains local dynamic knowledge during the task, in this paper, we introduce parametric World Knowledge Model (WKM) to facilitate agent planning. Concretely, we steer the agent model to self-synthesize knowledge from both expert and sampled trajectories. Then we develop WKM, providing prior task knowledge to guide the global planning and dynamic state knowledge to assist the local planning. Experimental results on three complex real-world simulated datasets with three state-of-the-art open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our method can achieve superior performance compared to various strong baselines. Besides, we analyze to illustrate that our WKM can effectively alleviate the blind trial-and-error and hallucinatory action issues, providing strong support for the agent’s understanding of the world. Other interesting findings include: 1) our instance-level task knowledge can generalize better to unseen tasks, 2) weak WKM can guide strong agent model planning, and 3) unified WKM training has promising potential for further development. The code is available at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/WKM">https://github.com/zjunlp/WKM</a>. </p>
<blockquote>
<p>最近，直接使用大型语言模型（LLM）作为代理模型来执行交互式规划任务的研究取得了值得赞扬的成果。然而，尽管取得了成就，它们仍然在全球规划方面存在盲目的试错问题，并在局部规划中产生幻觉行为，这是因为它们对“真实”物理世界的理解不足。本文中，我们引入参数化世界知识模型（WKM）来辅助代理规划，模仿人类的精神世界知识模型，在任务前提供全局先验知识，并在任务期间保持局部动态知识。具体地，我们引导代理模型从专家轨迹和采样轨迹中自行合成知识。然后，我们开发WKM，提供任务先验知识来指导全局规划，以及动态状态知识来辅助局部规划。在三个复杂的真实世界模拟数据集上与三种最先进的开源LLM（Mistral-7B、Gemma-7B和Llama-3-8B）的实验结果表明，我们的方法相比各种强大的基线方法可以达到更优越的性能。此外，我们通过分析证明，我们的WKM可以有效地减轻盲目的试错和幻觉行为问题，为代理对世界的理解提供强有力的支持。其他有趣的发现包括：1）我们的实例级任务知识可以更好地推广到未见过的任务；2）弱的WKM可以指导强大的代理模型规划；3）统一的WKM训练具有进一步开发的巨大潜力。代码可用在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/WKM%E3%80%82">https://github.com/zjunlp/WKM。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14205v3">PDF</a> NeurIPS 2024</p>
<p><strong>摘要</strong><br>大型语言模型（LLM）作为代理模型直接执行交互式规划任务取得了可喜的成果，但仍存在全球规划中的盲目试错和局部规划中产生幻觉行动的问题，因为它们对“真实”物理世界的理解不足。本文通过引入参数化世界知识模型（WKM），模拟人类的先验知识和动态知识，帮助代理规划。通过专家轨迹和采样轨迹合成知识，提供任务先验知识指导全局规划，动态状态知识辅助局部规划。在三个复杂真实世界模拟数据集上的实验结果表明，该方法优于各种强大的基线。此外，分析表明WKM能有效缓解盲目试错和幻觉行为问题，为代理理解世界提供有力支持。该代码可在“<a target="_blank" rel="noopener" href="https://github.com/zjunlp/WKM%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zjunlp/WKM找到”。</a></p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLMs）在交互式规划任务中表现出色，但仍存在对真实物理世界理解不足的问题。</li>
<li>引入参数化世界知识模型（WKM）以模仿人类的精神世界知识模型。</li>
<li>WKM能从专家轨迹和采样轨迹合成知识，提供任务先验知识指导全局规划，并辅助局部规划。</li>
<li>实验结果表明，WKM方法在所有测试数据集上均优于各种强大的基线。</li>
<li>WKM能有效缓解LLMs的盲目试错和幻觉行为问题，提高其对世界的理解。</li>
<li>实例级任务知识具有良好的未见任务泛化能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.14205">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2f637791366f511544ef30d96e71ae56.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c988b7da694d55c09897345596a1403.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1b82792178546b9e8265d0e4b645cf5.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Agent-OM-Leveraging-LLM-Agents-for-Ontology-Matching"><a href="#Agent-OM-Leveraging-LLM-Agents-for-Ontology-Matching" class="headerlink" title="Agent-OM: Leveraging LLM Agents for Ontology Matching"></a>Agent-OM: Leveraging LLM Agents for Ontology Matching</h2><p><strong>Authors:Zhangcheng Qiang, Weiqing Wang, Kerry Taylor</strong></p>
<p>Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of simple OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks. </p>
<blockquote>
<p>本体匹配（OM）能够使不同本体之间实现语义互操作性，并通过对齐相关实体解决其概念上的异质性。目前，OM系统主要有两种流行的设计范式：传统的基于知识的专家系统和更新的基于机器学习的预测系统。虽然大型语言模型（LLM）和LLM代理已经彻底改变了数据工程，并在许多领域得到了创造性的应用，但它们在OM中的潜力仍未得到充分探索。本研究引入了一种基于代理的LLM设计范式的新型OM系统。考虑到在利用LLM代理进行OM时面临的若干特定挑战，我们提出了一个通用框架，即Agent-OM（用于本体匹配的代理），它由两个用于检索和匹配的Siamese代理和一组简单的OM工具组成。我们的框架在一个概念验证系统中实现。对最先进的OM系统进行了三个本体对齐评估倡议（OAEI）轨道的评估显示，我们的系统在简单的OM任务上的结果非常接近长期以来的最佳性能，并在复杂的和少镜头OM任务上可以显著提高性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00326v5">PDF</a> 19 pages, 13 figures, 4 tables</p>
<p><strong>Summary</strong><br>     本研究提出一种新型基于LLM代理的OM系统设计范式，利用大型语言模型代理实现语义互操作性以解决不同本体之间的概念异质性。通过考虑利用LLM代理进行OM的特定挑战，本研究提出了一个通用框架Agent-OM，包含用于检索和匹配的Siamese代理以及一套简单的OM工具。在多个OM系统评估中，该系统在简单任务上表现接近最佳水平，并在复杂和少量任务上显著提高性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本体匹配（OM）是解决不同本体间概念异质性的关键手段，它使得语义互操作性成为可能。</li>
<li>目前有两种主要的OM系统设计范式：传统的知识型专家系统和新兴的基于机器学习的预测系统。</li>
<li>大型语言模型（LLM）和LLM代理在数据工程领域具有革命性应用，但在OM方面的潜力尚未得到充分探索。</li>
<li>本研究提出了一种基于LLM代理的新型OM系统设计范式，即Agent-OM框架。</li>
<li>Agent-OM框架包含两个用于检索和匹配的Siamese代理，并辅以一套简单的OM工具。</li>
<li>在多个OM系统评估中，该框架表现优秀，尤其在复杂和少量任务上显著提升了性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.00326">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0dbc27aec0e0a35ba6385cfcae4c3111.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dad1989b38d614c47b96192c82520f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1049414e1280085db2a3d9c3ec55934f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7144d14f0bb04f3a3c2414b2ea0a0c73.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Scaling-Laws-for-Imitation-Learning-in-Single-Agent-Games"><a href="#Scaling-Laws-for-Imitation-Learning-in-Single-Agent-Games" class="headerlink" title="Scaling Laws for Imitation Learning in Single-Agent Games"></a>Scaling Laws for Imitation Learning in Single-Agent Games</h2><p><strong>Authors:Jens Tuyls, Dhruv Madeka, Kari Torkkola, Dean Foster, Karthik Narasimhan, Sham Kakade</strong></p>
<p>Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, many works find it is often unable to fully recover the underlying expert behavior, even in constrained environments like single-agent games. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where “scaling up” has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting for single-agent games. We first demonstrate our findings on a variety of Atari games, and thereafter focus on the extremely challenging game of NetHack. In all games, we find that IL loss and mean return scale smoothly with the compute budget (FLOPs) and are strongly correlated, resulting in power laws for training compute-optimal IL agents. Finally, we forecast and train several NetHack agents with IL and find they outperform prior state-of-the-art by 1.5x in all settings. Our work both demonstrates the scaling behavior of imitation learning in a variety of single-agent games, as well as the viability of scaling up current approaches for increasingly capable agents in NetHack, a game that remains elusively hard for current AI systems. </p>
<blockquote>
<p>模仿学习（IL）是机器学习中应用最广泛的方法之一。然而，许多研究表明，即使在单智能体游戏等受限环境中，它也无法完全恢复专家行为。然而，这些研究都没有深入探讨扩大模型和数据规模的作用。受自然语言处理（NLP）领域最近工作的启发，“规模化”已经导致了越来越强大的大型语言模型的出现，我们调查了是否通过精心扩大模型和数据的规模，可以在单智能体游戏的模仿学习环境中带来类似的改进。我们首先在各种Atari游戏上展示我们的发现，然后专注于极具挑战性的NetHack游戏。在所有游戏中，我们发现IL损失和平均回报率随着计算预算（FLOPs）的扩大而平稳扩展，并且存在强烈的相关性，从而形成了训练计算最优IL代理的幂律。最后，我们预测并训练了多个NetHack代理使用模仿学习，发现它们在所有设置中的性能超过了现有最新技术水平的1.5倍。我们的工作既展示了在各种单智能体游戏中模仿学习的扩展行为，也证明了在NetHack这个仍然对当前人工智能系统具有挑战性的游戏中，扩大当前方法的规模以产生越来越强大的代理的可行性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09423v3">PDF</a> Accepted at TMLR 2024</p>
<p><strong>Summary</strong></p>
<p>本文探讨了通过扩大模型和数据量来提升模仿学习（IL）效果的可能性。在单智能体游戏的场景下，研究发现在不断扩大计算预算（FLOPs）时，IL损失和平均回报率能够平稳扩展并相互关联，呈现出幂律关系。最终，通过预测并训练多个NetHack智能体，发现它们在所有设置中均超过了先前最优水平，表现出更强的性能。这项工作既展示了模仿学习在多种单智能体游戏中的可扩展性，也证明了在当前系统仍无法轻易解决的NetHack游戏中，通过扩大规模和提升技术，模仿学习的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>模仿学习（IL）在机器学习中应用广泛，但在单智能体游戏中往往无法完全恢复专家行为。</li>
<li>扩大模型和数据量在NLP中的大型语言模型（LLMs）取得了成功，本文探索了这种策略在模仿学习中的潜力。</li>
<li>在Atari游戏和NetHack游戏中的研究发现，IL损失和平均回报率随着计算预算的增加而平稳扩展。</li>
<li>这种扩展表现出强烈的幂律关系，即计算预算的增加对训练效果有显著的正面影响。</li>
<li>在NetHack游戏中训练的智能体表现优于先前的最优水平，显示出模仿学习的巨大潜力。</li>
<li>本文工作证明了模仿学习在单智能体游戏中的可扩展性，特别是在解决复杂任务时的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2307.09423">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f009658cbf99b96c8a8749e19b7a29af.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b07bb2bfcd0c7e6861f0138874d9a90a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70385827d6cb86ceb6067b1e7c8d576b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc7d09556c89c894f6ab710880e3e334.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-21/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-21/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-21/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-54f4a070763060ed8ee365ac9fa4bd01.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2024-12-21  DS$^2$-ABSA Dual-Stream Data Synthesis with Label Refinement for   Few-Shot Aspect-Based Sentiment Analysis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-21/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c533e46ae19cc805c73a90ab515107a2.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2024-12-21  OpenEMMA Open-Source Multimodal Model for End-to-End Autonomous Driving
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">17663.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
