<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="医学图像">
    <meta name="description" content="医学图像 方向最新论文已更新，请持续关注 Update in 2025-02-28  Deep learning and classical computer vision techniques in medical image   analysis Case studies on brain MRI tissue segmentation, lung CT COPD   registration, and skin lesion classification">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>医学图像 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2405.19492v2/page_2_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">医学图像</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">医学图像</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                医学图像
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    38 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-28-更新"><a href="#2025-02-28-更新" class="headerlink" title="2025-02-28 更新"></a>2025-02-28 更新</h1><h2 id="Deep-learning-and-classical-computer-vision-techniques-in-medical-image-analysis-Case-studies-on-brain-MRI-tissue-segmentation-lung-CT-COPD-registration-and-skin-lesion-classification"><a href="#Deep-learning-and-classical-computer-vision-techniques-in-medical-image-analysis-Case-studies-on-brain-MRI-tissue-segmentation-lung-CT-COPD-registration-and-skin-lesion-classification" class="headerlink" title="Deep learning and classical computer vision techniques in medical image   analysis: Case studies on brain MRI tissue segmentation, lung CT COPD   registration, and skin lesion classification"></a>Deep learning and classical computer vision techniques in medical image   analysis: Case studies on brain MRI tissue segmentation, lung CT COPD   registration, and skin lesion classification</h2><p><strong>Authors:Anyimadu Daniel Tweneboah, Suleiman Taofik Ahmed, Hossain Mohammad Imran</strong></p>
<p>Medical imaging spans diverse tasks and modalities which play a pivotal role in disease diagnosis, treatment planning, and monitoring. This study presents a novel exploration, being the first to systematically evaluate segmentation, registration, and classification tasks across multiple imaging modalities. Integrating both classical and deep learning (DL) approaches in addressing brain MRI tissue segmentation, lung CT image registration, and skin lesion classification from dermoscopic images, we demonstrate the complementary strengths of these methodologies in diverse applications. For brain tissue segmentation, 3D DL models outperformed 2D and patch-based models, specifically nnU-Net achieving Dice of 0.9397, with 3D U-Net models on ResNet34 backbone, offering competitive results with Dice 0.8946. Multi-Atlas methods provided robust alternatives for cases where DL methods are not feasible, achieving average Dice of 0.7267. In lung CT registration, classical Elastix-based methods outperformed DL models, achieving a minimum Target Registration Error (TRE) of 6.68 mm, highlighting the effectiveness of parameter tuning. HighResNet performed best among DL models with a TRE of 7.40 mm. For skin lesion classification, ensembles of DL models like InceptionResNetV2 and ResNet50 excelled, achieving up to 90.44%, and 93.62% accuracies for binary and multiclass classification respectively. Also, adopting One-vs-All method, DL attained accuracies of 94.64% (mel vs. others), 95.35% (bcc vs. others), and 96.93% (scc vs. others), while ML models specifically Multi-Layer Perceptron (MLP) on handcrafted features offered interpretable alternatives with 85.04% accuracy using SMOTE for class imbalance correction on the multi-class task and 83.27% on the binary-class task. Links to source code are available on request. </p>
<blockquote>
<p>医学影像涵盖了多种任务和模态，在疾病诊断、治疗计划和监测中起到了至关重要的作用。本研究提出了一种新的探索方法，首次系统地评估了跨多种成像模态的分割、配准和分类任务。通过结合经典和深度学习（DL）方法，解决脑MRI组织分割、肺部CT图像配准和皮肤病变分类等问题，我们展示了这些方法在不同应用中的互补优势。对于脑组织分割，3D深度学习模型优于2D和基于补丁的模型，尤其是nnU-Net的Dice系数达到0.9397，基于ResNet34的3DU-Net模型也取得了令人竞争的结果，Dice系数为0.8946。当深度学习方法不可行时，多图谱方法提供了稳健的替代方案，平均Dice系数为0.7267。在肺部CT配准中，基于Elastix的经典方法优于深度学习模型，实现了最低目标注册误差（TRE）为6.68毫米，这突显了参数调整的有效性。在深度学习模型中，HighResNet表现最佳，TRE为7.40毫米。对于皮肤病变分类，如InceptionResNetV2和ResNet50等深度学习模型集成表现出色，二元分类和多类分类的准确率分别高达90.44%和93.62%。此外，采用一对一与所有其他类别对比的方法，深度学习模型的准确率达到了94.64%（黑色素瘤与其他）、95.35%（基底细胞癌与其他）和96.93%（鳞状细胞癌与其他）。而机器学习模型（特别是基于手工特征的多层感知器）提供了可解释的替代方案，在多类任务中使用SMOTE进行类别不平衡校正的准确率为85.04%，二元类任务的准确率为83.27%。源代码链接可根据要求提供。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19258v1">PDF</a> 27 pages, 18 figures</p>
<p><strong>摘要</strong><br>医学成像涵盖多种任务和模态，在疾病诊断、治疗规划和监测中扮演重要角色。本研究首次系统地评价了分割、配准和分类任务在多种成像模态中的应用。通过结合经典和深度学习（DL）方法，对脑MRI组织分割、肺部CT图像配准和皮肤病变分类等应用进行了展示。在脑组织分割方面，3D DL模型表现出优于2D和基于补丁的模型的效果，尤其是nnU-Net的Dice系数达到0.9397。在肺部CT配准中，基于Elastix的经典方法优于DL模型，达到最低目标注册误差（TRE）为6.68毫米。对于皮肤病变分类，DL模型如InceptionResNetV2和ResNet50的集成表现最佳，二进制和多类分类的准确率分别高达90.44％和93.62％。此外，采用One-vs-All方法的DL实现了多项超过94％的准确率，而采用多层感知器（MLP）等机器学习模型处理手工特征为解决类别不平衡问题提供了可解释性替代方案。代码链接可供请求。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>医学成像涵盖多种任务和模态，对疾病诊断、治疗规划至关重要。</li>
<li>本研究首次系统地评价了不同成像模态中的分割、配准和分类任务。</li>
<li>在脑组织分割中，3D深度学习模型表现出卓越性能，尤其是nnU-Net。</li>
<li>在肺部CT图像配准方面，经典Elastix方法表现最佳，凸显参数调整的重要性。</li>
<li>对于皮肤病变分类，集成深度学习模型表现出高准确率，尤其是多类分类任务。</li>
<li>One-vs-All方法的深度学习模型在多类别皮肤病变分类中表现出优异的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19258">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.19258v1/page_5_1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FreeTumor-Large-Scale-Generative-Tumor-Synthesis-in-Computed-Tomography-Images-for-Improving-Tumor-Recognition"><a href="#FreeTumor-Large-Scale-Generative-Tumor-Synthesis-in-Computed-Tomography-Images-for-Improving-Tumor-Recognition" class="headerlink" title="FreeTumor: Large-Scale Generative Tumor Synthesis in Computed Tomography   Images for Improving Tumor Recognition"></a>FreeTumor: Large-Scale Generative Tumor Synthesis in Computed Tomography   Images for Improving Tumor Recognition</h2><p><strong>Authors:Linshan Wu, Jiaxin Zhuang, Yanning Zhou, Sunan He, Jiabo Ma, Luyang Luo, Xi Wang, Xuefeng Ni, Xiaoling Zhong, Mingxiang Wu, Yinghua Zhao, Xiaohui Duan, Varut Vardhanabhuti, Pranav Rajpurkar, Hao Chen</strong></p>
<p>Tumor is a leading cause of death worldwide, with an estimated 10 million deaths attributed to tumor-related diseases every year. AI-driven tumor recognition unlocks new possibilities for more precise and intelligent tumor screening and diagnosis. However, the progress is heavily hampered by the scarcity of annotated datasets, which demands extensive annotation efforts by radiologists. To tackle this challenge, we introduce FreeTumor, an innovative Generative AI (GAI) framework to enable large-scale tumor synthesis for mitigating data scarcity. Specifically, FreeTumor effectively leverages a combination of limited labeled data and large-scale unlabeled data for tumor synthesis training. Unleashing the power of large-scale data, FreeTumor is capable of synthesizing a large number of realistic tumors on images for augmenting training datasets. To this end, we create the largest training dataset for tumor synthesis and recognition by curating 161,310 publicly available Computed Tomography (CT) volumes from 33 sources, with only 2.3% containing annotated tumors. To validate the fidelity of synthetic tumors, we engaged 13 board-certified radiologists in a Visual Turing Test to discern between synthetic and real tumors. Rigorous clinician evaluation validates the high quality of our synthetic tumors, as they achieved only 51.1% sensitivity and 60.8% accuracy in distinguishing our synthetic tumors from real ones. Through high-quality tumor synthesis, FreeTumor scales up the recognition training datasets by over 40 times, showcasing a notable superiority over state-of-the-art AI methods including various synthesis methods and foundation models. These findings indicate promising prospects of FreeTumor in clinical applications, potentially advancing tumor treatments and improving the survival rates of patients. </p>
<blockquote>
<p>肿瘤是全球主要的死亡原因之一，每年估计有1000万人因肿瘤相关疾病而死亡。人工智能驱动的肿瘤识别为更精确和智能的肿瘤筛查和诊断开启了新的可能性。然而，由于缺乏标注数据集，这一进展受到了严重阻碍，这需要放射科医生进行大量的标注工作。为了解决这一挑战，我们推出了FreeTumor，这是一个创新的生成式人工智能（GAI）框架，能够实现大规模的肿瘤合成，以缓解数据稀缺的问题。具体来说，FreeTumor有效地结合了有限的标记数据和大规模的未标记数据来进行肿瘤合成训练。利用大规模数据的力量，FreeTumor能够在图像上合成大量逼真的肿瘤，以扩充训练数据集。为此，我们通过整合来自33个来源的161310个公开可用的计算机断层扫描（CT）体积，创建了最大的肿瘤合成和识别训练数据集，其中只有2.3%包含标注的肿瘤。为了验证合成肿瘤的保真度，我们邀请了13名认证放射科医生进行视觉图灵测试，以区分合成肿瘤和真实肿瘤。严格的临床医生评估证实了我们合成肿瘤的高质量，因为他们在区分我们的合成肿瘤和真实肿瘤时只达到了51.1%的灵敏度和60.8%的准确度。通过高质量的肿瘤合成，FreeTumor将识别训练数据集扩大了40多倍，相较于包括各种合成方法和基础模型在内的最先进的人工智能方法，展示出了显著的优势。这些发现表明，FreeTumor在临床应用方面有着广阔的前景，有望推动肿瘤治疗改善患者的生存率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18519v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<pre><code>本文介绍了一种基于生成式人工智能（GAI）的FreeTumor框架，旨在解决肿瘤识别数据稀缺的问题。FreeTumor通过结合有限标记数据和大量无标记数据进行肿瘤合成训练，能够合成大量逼真的肿瘤图像，从而扩充训练数据集。此外，该研究还创建了最大的肿瘤合成和识别训练数据集，并通过严格的医生评估验证了合成肿瘤的逼真度。研究结果表明，FreeTumor在肿瘤识别方面表现出显著优势，并有望在临床应用中推进肿瘤治疗和改善患者生存率。
</code></pre>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI在肿瘤筛查和诊断中发挥着重要作用，但数据稀缺是限制其进展的关键因素。</li>
<li>FreeTumor是一个基于生成式人工智能（GAI）的框架，旨在解决肿瘤识别数据稀缺的问题。</li>
<li>FreeTumor通过结合有限标记数据和大量无标记数据进行训练，实现肿瘤图像的合成。</li>
<li>创建了最大的肿瘤合成和识别训练数据集。</li>
<li>合成肿瘤的逼真度通过严格的医生评估得到验证。</li>
<li>FreeTumor在肿瘤识别方面表现出显著优势，优于其他先进的AI方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18519">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18519v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18519v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-Patient-Data-Requirements-in-Training-Effective-AI-Models-for-MRI-based-Breast-Cancer-Classification"><a href="#Exploring-Patient-Data-Requirements-in-Training-Effective-AI-Models-for-MRI-based-Breast-Cancer-Classification" class="headerlink" title="Exploring Patient Data Requirements in Training Effective AI Models for   MRI-based Breast Cancer Classification"></a>Exploring Patient Data Requirements in Training Effective AI Models for   MRI-based Breast Cancer Classification</h2><p><strong>Authors:Solha Kang, Wesley De Neve, Francois Rameau, Utku Ozbulak</strong></p>
<p>The past decade has witnessed a substantial increase in the number of startups and companies offering AI-based solutions for clinical decision support in medical institutions. However, the critical nature of medical decision-making raises several concerns about relying on external software. Key issues include potential variations in image modalities and the medical devices used to obtain these images, potential legal issues, and adversarial attacks. Fortunately, the open-source nature of machine learning research has made foundation models publicly available and straightforward to use for medical applications. This accessibility allows medical institutions to train their own AI-based models, thereby mitigating the aforementioned concerns. Given this context, an important question arises: how much data do medical institutions need to train effective AI models? In this study, we explore this question in relation to breast cancer detection, a particularly contested area due to the prevalence of this disease, which affects approximately 1 in every 8 women. Through large-scale experiments on various patient sizes in the training set, we show that medical institutions do not need a decade’s worth of MRI images to train an AI model that performs competitively with the state-of-the-art, provided the model leverages foundation models. Furthermore, we observe that for patient counts greater than 50, the number of patients in the training set has a negligible impact on the performance of models and that simple ensembles further improve the results without additional complexity. </p>
<blockquote>
<p>过去十年，提供人工智能临床决策支持解决方案的初创公司和机构数量显著增加。然而，医疗决策的重要性导致对依赖外部软件的诸多担忧。关键问题包括图像模式以及获取这些图像所用医疗设备的潜在差异、潜在的法律问题和对抗攻击。幸运的是，机器学习研究的开源特性使得基础模型公开可用，并易于用于医疗应用。这种可及性让医疗机构能够训练自己的基于人工智能的模型，从而缓解上述的担忧。基于此背景，出现了一个重要问题：医疗机构需要多少数据来训练有效的人工智能模型？本研究以乳腺癌检测为视角来探索这个问题，由于这种疾病的普遍性（大约每8名女性中有1名受影响），这是一个特别有争议的话题。通过在大规模训练集上对各个患者规模的实验，我们显示，医疗机构不需要花费十年时间来收集MRI图像，就能训练出与最新技术前沿相竞争的人工智能模型，前提是该模型利用基础模型。此外，我们发现对于患者人数超过50的情况，训练集中的患者数量对模型性能的影响微乎其微，简单的组合技术能进一步改善结果，且不会增加复杂性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18506v1">PDF</a> Accepted for publication in MICCAI 2024 Deep Breast Workshop on AI   and Imaging for Diagnostic and Treatment Challenges in Breast Care</p>
<p><strong>Summary</strong><br>     近年来，医疗领域出现大量提供人工智能临床决策支持的初创公司和机构。然而，医疗决策的重要性引发了对依赖外部软件的担忧，包括图像模态和设备差异、潜在的法律问题和对抗性攻击等问题。幸运的是，机器学习研究的开源性质使得基础模型可公开使用和用于医疗应用。本研究探索了医疗机构需要多少数据来训练有效的AI模型的问题，并以乳腺癌检测为例进行研究。通过大规模实验证明，在利用基础模型的前提下，医疗机构不需要十年的MRI图像数据就能训练出与最新技术相竞争的AI模型。此外，对于超过50例的患者，训练集中的患者数量对模型性能的影响微乎其微，简单的组合方法能够进一步提升效果，且不增加复杂性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>人工智能在临床决策支持领域的应用迅速增长，引发对依赖外部软件的担忧。</li>
<li>开源机器学习的普及使得基础模型在医疗领域易于使用。</li>
<li>医疗机构的AI模型训练不需要大量数据，可以利用基础模型进行高效训练。</li>
<li>在乳腺癌检测的研究中，少量数据训练出的模型性能可与最新技术相竞争。</li>
<li>对于一定规模以上的患者数据，训练集大小对模型性能的影响微小。</li>
<li>简单组合方法可以进一步提升AI模型的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18506">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18506v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18506v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18506v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18506v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2502.18506v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Vision-Foundation-Models-for-Computed-Tomography"><a href="#Vision-Foundation-Models-for-Computed-Tomography" class="headerlink" title="Vision Foundation Models for Computed Tomography"></a>Vision Foundation Models for Computed Tomography</h2><p><strong>Authors:Suraj Pai, Ibrahim Hadzic, Dennis Bontempi, Keno Bressem, Benjamin H. Kann, Andriy Fedorov, Raymond H. Mak, Hugo J. W. L. Aerts</strong></p>
<p>Foundation models (FMs) have shown transformative potential in radiology by performing diverse, complex tasks across imaging modalities. Here, we developed CT-FM, a large-scale 3D image-based pre-trained model designed explicitly for various radiological tasks. CT-FM was pre-trained using 148,000 computed tomography (CT) scans from the Imaging Data Commons through label-agnostic contrastive learning. We evaluated CT-FM across four categories of tasks, namely, whole-body and tumor segmentation, head CT triage, medical image retrieval, and semantic understanding, showing superior performance against state-of-the-art models. Beyond quantitative success, CT-FM demonstrated the ability to cluster regions anatomically and identify similar anatomical and structural concepts across scans. Furthermore, it remained robust across test-retest settings and indicated reasonable salient regions attached to its embeddings. This study demonstrates the value of large-scale medical imaging foundation models and by open-sourcing the model weights, code, and data, aims to support more adaptable, reliable, and interpretable AI solutions in radiology. </p>
<blockquote>
<p>基础模型（FMs）在放射学中表现出了变革性的潜力，能够在不同的成像模式下执行多样且复杂的任务。在这里，我们开发了CT-FM，这是一个大规模基于3D图像的预训练模型，专门为各种放射学任务而设计。CT-FM是使用来自影像数据共享平台的14.8万份计算机断层扫描（CT）数据通过无标签对比学习进行预训练的。我们对CT-FM在四类任务中进行了评估，分别是全身和肿瘤分割、头部CT初步诊断、医学图像检索和语义理解，表现出超越最新模型的性能。除了量化成功之外，CT-FM还证明了自己具备在解剖区域进行聚类以及在扫描之间识别相似解剖和结构概念的能力。此外，它在测试重测环境中表现稳健，并且其嵌入的显著区域相对合理。本研究展示了大规模医学成像基础模型的价值，并通过公开模型权重、代码和数据，旨在支持更灵活、可靠和可解释的放射学人工智能解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09001v2">PDF</a> 6 figures, followed by 9 Extended Data Figures and a Supplementary   Information document</p>
<p><strong>Summary</strong></p>
<p>大规模医学成像基础模型CT-FM在放射学中的潜力评估。通过对比现有模型，CT-FM在多种任务中表现出卓越性能，包括全身和肿瘤分割、头部CT评估、医学图像检索和语义理解。此外，CT-FM具有聚类解剖区域的能力，并能识别不同扫描中的相似解剖和结构概念。开源模型权重、代码和数据，为放射学中更灵活、可靠和可解释的AI解决方案提供支持。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CT-FM是一个大规模基于三维图像的预训练模型，专为各种放射学任务设计。</li>
<li>通过使用来自Imaging Data Commons的148,000次计算机断层扫描进行预训练，采用标签无关的对比学习方法。</li>
<li>在四个不同类别的任务中评估CT-FM，包括全身和肿瘤分割、头部CT评估、医学图像检索和语义理解，表现出卓越性能。</li>
<li>CT-FM具有识别相似解剖和结构概念的能力，并在不同扫描中聚类解剖区域。</li>
<li>CT-FM在测试重测环境中表现稳健，并能合理地识别关键区域与其嵌入信息相关联。</li>
<li>该研究证明了大规模医学成像基础模型的价值。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09001">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2501.09001v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2501.09001v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="The-FLAMINGO-project-cosmology-with-the-redshift-dependence-of-weak-gravitational-lensing-peaks"><a href="#The-FLAMINGO-project-cosmology-with-the-redshift-dependence-of-weak-gravitational-lensing-peaks" class="headerlink" title="The FLAMINGO project: cosmology with the redshift dependence of weak   gravitational lensing peaks"></a>The FLAMINGO project: cosmology with the redshift dependence of weak   gravitational lensing peaks</h2><p><strong>Authors:Jeger C. Broxterman, Matthieu Schaller, Henk Hoekstra, Joop Schaye, Robert J. McGibbon, Victor J. Forouhar Moreno, Roi Kugel, Willem Elbers</strong></p>
<p>Weak gravitational lensing (WL) convergence peaks contain valuable cosmological information in the regime of non-linear collapse. Using the FLAMINGO suite of cosmological hydrodynamical simulations, we study the physical origin and redshift distributions of the objects generating WL peaks selected from a WL convergence map mimicking a $\textit{Euclid}$ signal. We match peaks to individual haloes and show that the high signal-to-noise ratio (SNR$<del>&gt;</del>5$) WL peaks measured by Stage IV WL surveys primarily trace $M_{\mathrm{200c}} &gt; 10^{14}<del>\mathrm{M_\odot}$ haloes. We find that the WL peak sample can compete with the purity and completeness of state-of-the-art X-ray and Sunyaev-Zel’dovich cluster abundance inferences. By comparing the distributions predicted by simulation variations that have been calibrated to the observed gas fractions of local clusters and the present-day galaxy stellar mass function, or shifted versions of these, we illustrate that the shape of the redshift distribution of SNR$</del>&gt;~5$ peaks is insensitive to baryonic physics while it does change with cosmology. The difference highlights the potential of using WL peaks to constrain cosmology. As the WL convergence and redshift number densities of WL peaks scale differently with cosmology and baryonic feedback, WL peak statistics can simultaneously calibrate baryonic feedback and constrain cosmology. </p>
<blockquote>
<p>弱引力透镜（WL）收敛峰在非线性的领域包含了宝贵的宇宙学信息。我们使用FLAMINGO宇宙学流体动力学模拟套件，研究生成WL峰的物理起源和红移分布，这些峰是从模仿Euclid信号的WL收敛图中选择的。我们将峰值与单个晕匹配，并显示由第四阶段WL调查测量的高信噪比（SNR &gt; 5）的WL峰值主要追踪M_{200c} &gt; 10^{14} M_\odot的晕。我们发现，WL峰值样本可以与最先进的X射线和Sunyaev-Zel’dovich簇丰度推断的纯净度和完整性相竞争。通过将模拟预测的分布与根据本地簇的观察气体分数和当前星系恒星质量函数校准的模拟变化进行比较，以及这些变化的偏移版本，我们说明了SNR &gt; 5的峰值红移分布的形态对重子物理不敏感，但会随着宇宙学变化而变化。这种差异突显了使用WL峰值来约束宇宙学的潜力。由于WL收敛和WL峰的红移数量密度在宇宙学和重子反馈上随不同的尺度变化，因此WL峰统计可以同时校准重子反馈并约束宇宙学。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.02736v2">PDF</a> 20 pages, 12 figures (including the appendices). Accepted for   publication in MNRAS</p>
<p><strong>Summary</strong><br>    弱引力透镜（WL）收敛峰包含非线性崩溃区域的宝贵宇宙学信息。通过宇宙学流体动力学模拟套件FLAMINGO，我们研究了生成WL峰的天体的物理起源和红尘分布，这些WL峰是从模仿Euclid信号的WL收敛图中选择的。我们将峰值与单个星系匹配，并显示第四阶段WL调查测量的高信噪比（SNR &gt; 5）的WL峰值主要追踪M_{200c} &gt; 10^{14} M_odot的星系。我们发现WL峰值样本可以与先进的X射线和Sunyaev-Zel’dovich集群丰度推断的纯度和完整性相竞争。通过比较由模拟变化预测的分布，这些模拟变化已根据本地集群的观察气体分数和当前星系恒星质量函数进行校准，或者这些分布的移位版本，我们说明了SNR &gt; 5峰的redshift分布形状对重子物理不敏感，而随宇宙学变化。差异突显了使用WL峰值来约束宇宙学的潜力。由于WL收敛和WL峰的redshift数量密度随宇宙学和重子反馈的不同比例变化，因此WL峰值统计可以同时校准重子反馈并约束宇宙学。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WL收敛峰包含重要的宇宙学信息，特别是在非线性崩溃区域。</li>
<li>使用FLAMINGO模拟套件研究WL峰的物理起源和红尘分布。</li>
<li>高信噪比（SNR &gt; 5）的WL峰值与大型星系（M_{200c} &gt; 10^{14} M_odot）相关联。</li>
<li>WL峰值样本在纯度与完整性方面与X射线和Sunyaev-Zel’dovich集群丰度推断相竞争。</li>
<li>模拟预测的分布表明，SNR &gt; 5的峰值对重子物理不敏感，但对宇宙学变化敏感。</li>
<li>WL峰值统计可同时校准重子反馈并约束宇宙学。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.02736">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2412.02736v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2412.02736v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2412.02736v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Low-dimensional-representation-of-multi-patient-flow-cytometry-datasets-using-optimal-transport-for-minimal-residual-disease-detection-in-leukemia"><a href="#Low-dimensional-representation-of-multi-patient-flow-cytometry-datasets-using-optimal-transport-for-minimal-residual-disease-detection-in-leukemia" class="headerlink" title="Low dimensional representation of multi-patient flow cytometry datasets   using optimal transport for minimal residual disease detection in leukemia"></a>Low dimensional representation of multi-patient flow cytometry datasets   using optimal transport for minimal residual disease detection in leukemia</h2><p><strong>Authors:Erell Gachon, Jérémie Bigot, Elsa Cazelles, Audrey Bidet, Jean-Philippe Vial, Pierre-Yves Dumas, Aguirre Mimoun</strong></p>
<p>Representing and quantifying Minimal Residual Disease (MRD) in Acute Myeloid Leukemia (AML), a type of cancer that affects the blood and bone marrow, is essential in the prognosis and follow-up of AML patients. As traditional cytological analysis cannot detect leukemia cells below 5%, the analysis of flow cytometry dataset is expected to provide more reliable results. In this paper, we explore statistical learning methods based on optimal transport (OT) to achieve a relevant low-dimensional representation of multi-patient flow cytometry measurements (FCM) datasets considered as high-dimensional probability distributions. Using the framework of OT, we justify the use of the K-means algorithm for dimensionality reduction of multiple large-scale point clouds through mean measure quantization by merging all the data into a single point cloud. After this quantization step, the visualization of the intra and inter-patients FCM variability is carried out by embedding low-dimensional quantized probability measures into a linear space using either Wasserstein Principal Component Analysis (PCA) through linearized OT or log-ratio PCA of compositional data. Using a publicly available FCM dataset and a FCM dataset from Bordeaux University Hospital, we demonstrate the benefits of our approach over the popular kernel mean embedding technique for statistical learning from multiple high-dimensional probability distributions. We also highlight the usefulness of our methodology for low-dimensional projection and clustering patient measurements according to their level of MRD in AML from FCM. In particular, our OT-based approach allows a relevant and informative two-dimensional representation of the results of the FlowSom algorithm, a state-of-the-art method for the detection of MRD in AML using multi-patient FCM. </p>
<blockquote>
<p>在急性髓系白血病（AML）中，表示和量化最小残留病（MRD）对于预测和跟踪AML患者的预后至关重要。由于传统细胞学分分析无法检测到低于5%的白血病细胞，因此流式细胞术数据集的分析有望提供更可靠的结果。在本文中，我们探索了基于最优传输（OT）的统计学习方法，以实现多患者流式细胞术（FCM）数据集的低维表示，这些数据集被视为高维概率分布。我们使用OT的框架，通过将所有数据合并到一个点云中，证明了K-means算法用于大规模点云降维的合理性。在量化步骤之后，通过线性化OT的Wasserstein主成分分析（PCA）或组合数据的对数比率PCA，将低维量化概率度量嵌入线性空间以可视化患者内外FCM的变异性。我们使用公开可用的FCM数据集和波尔多大学医院的数据集证明了我们方法在流行内核均值嵌入技术上的优势，该技术用于从多个高维概率分布进行统计学习。我们还强调了我们方法在根据FCM中AML患者的MRD水平进行低维投影和聚类测量的实用性。特别是我们的基于OT的方法可以为FlowSom算法的结果提供一个有意义且信息丰富的二维表示，FlowSom算法是目前检测AML中MRD的先进方法，使用多患者FCM数据。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.17329v3">PDF</a> </p>
<p><strong>Summary</strong><br>     运用基于最优传输的统计学习方法对急性髓系白血病患者的流式细胞术数据进行低维表示，以更准确地检测和量化最小残留病（MRD）。该方法通过量化步骤将多尺度点云合并到单点云中，并使用Wasserstein主成分分析或对数比率主成分分析对量化概率措施进行低维嵌入，从而可视化患者间和患者内部的FCM变异性。与流行的核均值嵌入技术相比，该方法在统计学习方面表现出优势，并且对于根据MRD水平对患者测量进行低维投影和聚类特别有用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MRD的量化在AML的预后和随访中至关重要，传统细胞学分难以检测低于5%的白血病细胞，流式细胞术数据集的分析提供更可靠的结果。</li>
<li>基于最优传输的统计学习方法用于实现流式细胞术数据的相关低维表示。</li>
<li>通过量化步骤将多尺度点云合并到单点云中，使用Wasserstein PCA或对数比率PCA对量化概率措施进行低维嵌入，实现患者间和患者内部的FCM变异性的可视化。</li>
<li>与流行的核均值嵌入技术相比，该方法在统计学习方面表现出优势。</li>
<li>此方法对于根据MRD水平对患者测量进行低维投影和聚类特别有用。</li>
<li>基于最优传输的方法为FlowSom算法的结果提供了有意义且信息丰富的二维表示，FlowSom算法是检测AML中MRD的先进方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.17329">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2407.17329v3/page_0_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="TotalSegmentator-MRI-Robust-Sequence-independent-Segmentation-of-Multiple-Anatomic-Structures-in-MRI"><a href="#TotalSegmentator-MRI-Robust-Sequence-independent-Segmentation-of-Multiple-Anatomic-Structures-in-MRI" class="headerlink" title="TotalSegmentator MRI: Robust Sequence-independent Segmentation of   Multiple Anatomic Structures in MRI"></a>TotalSegmentator MRI: Robust Sequence-independent Segmentation of   Multiple Anatomic Structures in MRI</h2><p><strong>Authors:Tugba Akinci D’Antonoli, Lucas K. Berger, Ashraya K. Indrakanti, Nathan Vishwanathan, Jakob Weiß, Matthias Jung, Zeynep Berkarda, Alexander Rau, Marco Reisert, Thomas Küstner, Alexandra Walter, Elmar M. Merkle, Daniel Boll, Hanns-Christian Breit, Andrew Phillip Nicoli, Martin Segeroth, Joshy Cyriac, Shan Yang, Jakob Wasserthal</strong></p>
<p>Since the introduction of TotalSegmentator CT, there is demand for a similar robust automated MRI segmentation tool that can be applied across all MRI sequences and anatomic structures. In this retrospective study, a nnU-Net model (TotalSegmentator) was trained on MRI and CT examinations to segment 80 anatomic structures relevant for use cases such as organ volumetry, disease characterization, surgical planning and opportunistic screening. Examinations were randomly sampled from routine clinical studies to represent real-world examples. Dice scores were calculated between the predicted segmentations and expert radiologist reference standard segmentations to evaluate model performance on an internal test set, two external test sets and against two publicly available models, and TotalSegmentator CT. The model was applied to an internal dataset containing abdominal MRIs to investigate age-dependent volume changes. A total of 1143 examinations (616 MRIs, 527 CTs) (median age 61 years, IQR 50-72) were split into training (n&#x3D;1088, CT and MRI) and an internal test set (n&#x3D;55; only MRI), two external test sets (AMOS, n&#x3D;20; CHAOS, n&#x3D;20; only MRI), and an internal aging-study dataset of 8672 abdominal MRIs (median age 59 years, IQR 45-70) were included. The model showed a Dice Score of 0.839 on the internal test set and outperformed two other models (Dice Score, 0.862 versus 0.759; and 0.838 versus 0.560; p&lt;.001 for both). The proposed open-source, easy-to-use model allows for automatic, robust segmentation of 80 structures, extending the capabilities of TotalSegmentator to MRIs of any sequence. The ready-to-use online tool is available at <a target="_blank" rel="noopener" href="https://totalsegmentator.com/">https://totalsegmentator.com</a>, the model at <a target="_blank" rel="noopener" href="https://github.com/wasserth/TotalSegmentator">https://github.com/wasserth/TotalSegmentator</a>, and the dataset at <a target="_blank" rel="noopener" href="https://zenodo.org/records/14710732">https://zenodo.org/records/14710732</a>. </p>
<blockquote>
<p>自从TotalSegmentator CT引入以来，人们对一种类似功能强大的自动化MRI分割工具的需求愈发强烈，该工具可应用于所有MRI序列和解剖结构。在这项回顾性研究中，使用MRI和CT检查训练了一个nnU-Net模型（TotalSegmentator），以对80个解剖结构进行分割，这些结构对于诸如器官体积测量、疾病特征化、手术规划和机会性筛查等应用场景非常重要。检查是从常规临床研究中随机抽样得到的，以代表真实世界的情况。通过计算预测的分割与专家放射科医生参考标准分割之间的Dice系数，以评估模型在内部测试集、两个外部测试集和两个公开可用模型以及TotalSegmentator CT上的性能。该模型应用于包含腹部MRI的内部数据集，以研究年龄相关的体积变化。总共1143项检查（616项MRI，527项CT）（中位年龄61岁，IQR 50-72）被分为训练集（n&#x3D;1088，CT和MRI）、内部测试集（n&#x3D;55；仅MRI）、两个外部测试集（AMOS，n&#x3D;20；CHAOS，n&#x3D;20；仅MRI）以及包含8672项腹部MRI的内部老龄化研究数据集（中位年龄59岁，IQR 45-70）。该模型在内部测试集上的Dice得分为0.839，并且优于另外两个模型（Dice得分分别为0.862与0.759和0.838与0.560；两者p&lt;.001）。所提出的开源、易于使用的模型允许对80个结构进行自动、稳健的分割，扩展了TotalSegmentator在任意序列MRI上的功能。易于使用的在线工具可在<a target="_blank" rel="noopener" href="https://totalsegmentator.com上获得,模型可在https//github.com/wasserth/TotalSegmentator%E4%B8%8A%E6%89%BE%E5%88%B0%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%AF%E5%9C%A8https://zenodo.org/records/14710732%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://totalsegmentator.com上获得，模型可在https://github.com/wasserth/TotalSegmentator上找到，数据集可在https://zenodo.org/records/14710732上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.19492v2">PDF</a> Published in Radiology</p>
<p><strong>Summary</strong><br>     总Segmentator MRI模型实现全自动MRI分割，适用于所有MRI序列和解剖结构。研究采用nnU-Net模型进行训练，对80个解剖结构进行分割，并应用于器官体积测量、疾病特征分析、手术规划和机会筛查等应用场景。模型性能良好，可应用于内部数据集腹部MRI的年龄相关性体积变化研究。该模型公开且易于使用，允许自动、稳健地分割80个结构，扩展了总Segmentator在MRI序列中的功能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>总Segmentator MRI模型实现了全自动MRI分割工具的应用，可应用于多种MRI序列和解剖结构。</li>
<li>模型采用nnU-Net进行训练，用于分割80个解剖结构，用于多种医学应用场景如器官体积测量等。</li>
<li>研究采用了多种测试集来评估模型性能，包括内部测试集、外部测试集和公开模型对比。</li>
<li>模型在内部数据集腹部MRI的年龄相关性体积变化研究中得到应用。</li>
<li>模型公开且易于使用，提供在线工具和模型代码等资源。</li>
<li>模型性能良好，相比其他模型有明显优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.19492">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2405.19492v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2405.19492v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2405.19492v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2405.19492v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Distributed-Stochastic-Optimization-of-a-Neural-Representation-Network-for-Time-Space-Tomography-Reconstruction"><a href="#Distributed-Stochastic-Optimization-of-a-Neural-Representation-Network-for-Time-Space-Tomography-Reconstruction" class="headerlink" title="Distributed Stochastic Optimization of a Neural Representation Network   for Time-Space Tomography Reconstruction"></a>Distributed Stochastic Optimization of a Neural Representation Network   for Time-Space Tomography Reconstruction</h2><p><strong>Authors:K. Aditya Mohan, Massimiliano Ferrucci, Chuck Divin, Garrett A. Stevenson, Hyojin Kim</strong></p>
<p>4D time-space reconstruction of dynamic events or deforming objects using X-ray computed tomography (CT) is an important inverse problem in non-destructive evaluation. Conventional back-projection based reconstruction methods assume that the object remains static for the duration of several tens or hundreds of X-ray projection measurement images (reconstruction of consecutive limited-angle CT scans). However, this is an unrealistic assumption for many in-situ experiments that causes spurious artifacts and inaccurate morphological reconstructions of the object. To solve this problem, we propose to perform a 4D time-space reconstruction using a distributed implicit neural representation (DINR) network that is trained using a novel distributed stochastic training algorithm. Our DINR network learns to reconstruct the object at its output by iterative optimization of its network parameters such that the measured projection images best match the output of the CT forward measurement model. We use a forward measurement model that is a function of the DINR outputs at a sparsely sampled set of continuous valued 4D object coordinates. Unlike previous neural representation architectures that forward and back propagate through dense voxel grids that sample the object’s entire time-space coordinates, we only propagate through the DINR at a small subset of object coordinates in each iteration resulting in an order-of-magnitude reduction in memory and compute for training. DINR leverages distributed computation across several compute nodes and GPUs to produce high-fidelity 4D time-space reconstructions. We use both simulated parallel-beam and experimental cone-beam X-ray CT datasets to demonstrate the superior performance of our approach. </p>
<blockquote>
<p>使用X射线计算机断层扫描（CT）对动态事件或变形对象进行4D时空重建是非破坏性评估中的一个重要反问题。传统的基于反向投影的重建方法假设物体在数十或数百张X射线投影测量图像的时间内保持静止（连续有限角度CT扫描的重建）。然而，对于许多现场实验来说，这是一个不切实际的假设，会导致虚假的人工制品和物体形态重建不准确。为了解决此问题，我们提出使用分布式隐神经表示（DINR）网络进行4D时空重建，该网络使用新型分布式随机训练算法进行训练。我们的DINR网络通过迭代优化其网络参数来学习重建物体，以使测量的投影图像与CT前向测量模型的输出最佳匹配。我们使用的前向测量模型是DINR输出在稀疏采样的连续值4D物体坐标上的函数。与以前的前向和后向传播通过密集体素网格的神经网络架构不同，该架构采样物体的整个时空坐标，我们仅在每次迭代中通过一小部分物体坐标传播DINR，从而导致内存和训练计算的数量级减少。DINR利用多个计算节点和GPU进行分布式计算，以产生高保真度的4D时空重建。我们使用模拟的平行束和实验用的锥形束X射线CT数据集来展示我们方法的卓越性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.19075v2">PDF</a> accepted for publication at IEEE Transactions in Computational   Imaging</p>
<p><strong>Summary</strong></p>
<p>基于X射线计算机断层扫描（CT）的4D时空重建是无损检测中的一个重要反问题。传统的基于反向投影的重建方法假设物体在数十或数百张X射线投影测量图像期间保持静止，这不适用于许多现场实验。为解决此问题，我们提出使用分布式隐神经表示（DINR）网络进行4D时空重建，并采用新型分布式随机训练算法进行训练。DINR网络通过优化其网络参数来重建物体，使测量的投影图像与CT正向测量模型的输出最佳匹配。我们使用正向测量模型，该函数是DINR输出在稀疏采样的连续值4D物体坐标上的函数。不同于之前的前向和后向传播通过密集体素网格的神经网络架构，我们仅在每次迭代中通过一小部分物体坐标进行传播，从而实现了内存和计算训练的一个数量级的减少。DINR利用多个计算节点和GPU的分布式计算来生成高保真度的4D时空重建。我们使用模拟的平行束和实验用的锥形束X射线CT数据集来展示我们方法的优势。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>4D时空重建是无损检测中的关键反问题，尤其在X射线CT中。</li>
<li>传统重建方法假设物体在测量期间保持静态，这在许多现场实验中并不现实。</li>
<li>提出的DINR网络通过优化网络参数进行物体重建，以匹配CT正向测量模型的输出。</li>
<li>DINR使用稀疏采样的4D物体坐标上的正向测量模型，与前述架构不同。</li>
<li>DINR仅在每次迭代中通过一小部分物体坐标进行传播，降低了内存和计算需求。</li>
<li>DINR利用分布式计算进行高效、高保真度的4D时空重建。</li>
<li>使用模拟和实验数据集验证了DINR方法的优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.19075">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2404.19075v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2404.19075v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2404.19075v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_医学图像/2404.19075v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-28/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-28/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">医学图像</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-28/TTS/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_TTS/2502.19078v1/page_0_0.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-02-28  Sparse Brains are Also Adaptive Brains Cognitive-Load-Aware Dynamic   Activation for LLMs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-28/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-02-28\./crop_Diffusion Models/2404.02747v3/page_5_0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-02-28  HDM Hybrid Diffusion Model for Unified Image Anomaly Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19380.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
