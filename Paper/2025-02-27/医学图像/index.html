<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-27  Training Consistency Models with Variational Noise Coupling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_2_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    61 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-27-æ›´æ–°"><a href="#2025-02-27-æ›´æ–°" class="headerlink" title="2025-02-27 æ›´æ–°"></a>2025-02-27 æ›´æ–°</h1><h2 id="Training-Consistency-Models-with-Variational-Noise-Coupling"><a href="#Training-Consistency-Models-with-Variational-Noise-Coupling" class="headerlink" title="Training Consistency Models with Variational Noise Coupling"></a>Training Consistency Models with Variational Noise Coupling</h2><p><strong>Authors:Gianluigi Silvestri, Luca Ambrogioni, Chieh-Hsin Lai, Yuhta Takida, Yuki Mitsufuji</strong></p>
<p>Consistency Training (CT) has recently emerged as a promising alternative to diffusion models, achieving competitive performance in image generation tasks. However, non-distillation consistency training often suffers from high variance and instability, and analyzing and improving its training dynamics is an active area of research. In this work, we propose a novel CT training approach based on the Flow Matching framework. Our main contribution is a trained noise-coupling scheme inspired by the architecture of Variational Autoencoders (VAE). By training a data-dependent noise emission model implemented as an encoder architecture, our method can indirectly learn the geometry of the noise-to-data mapping, which is instead fixed by the choice of the forward process in classical CT. Empirical results across diverse image datasets show significant generative improvements, with our model outperforming baselines and achieving the state-of-the-art (SoTA) non-distillation CT FID on CIFAR-10, and attaining FID on par with SoTA on ImageNet at $64 \times 64$ resolution in 2-step generation. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/sony/vct">https://github.com/sony/vct</a> . </p>
<blockquote>
<p>ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰ä½œä¸ºä¸€ç§æ‰©æ•£æ¨¡å‹çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ³•ï¼Œæœ€è¿‘åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„è¡¨ç°ã€‚ç„¶è€Œï¼Œéè’¸é¦ä¸€è‡´æ€§è®­ç»ƒç»å¸¸é­å—é«˜æ–¹å·®å’Œä¸ç¨³å®šæ€§çš„å›°æ‰°ï¼Œå¯¹å…¶è®­ç»ƒåŠ¨æ€è¿›è¡Œåˆ†æå’Œæ”¹è¿›æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæµåŒ¹é…æ¡†æ¶çš„æ–°å‹CTè®­ç»ƒæ–¹æ³•ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯å—åˆ°å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰æ¶æ„å¯å‘çš„è®­ç»ƒå™ªå£°è€¦åˆæ–¹æ¡ˆã€‚é€šè¿‡è®­ç»ƒä¸€ä¸ªæ•°æ®ä¾èµ–çš„å™ªå£°å‘å°„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹è¢«å®ç°ä¸ºç¼–ç å™¨æ¶æ„ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é—´æ¥åœ°å­¦ä¹ å™ªå£°åˆ°æ•°æ®æ˜ å°„çš„å‡ ä½•ç»“æ„ï¼Œè¿™åœ¨ç»å…¸CTä¸­æ˜¯é€šè¿‡å‰å‘è¿‡ç¨‹çš„é€‰æ‹©æ¥å›ºå®šçš„ã€‚åœ¨ä¸åŒçš„å›¾åƒæ•°æ®é›†ä¸Šçš„ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè¶…è¿‡äº†åŸºçº¿å¹¶å®ç°äº†CIFAR-10ä¸Šçš„æœ€å…ˆè¿›çš„éè’¸é¦CT FIDï¼Œå¹¶ä¸”åœ¨2æ­¥ç”Ÿæˆä¸­ä»¥64x64çš„åˆ†è¾¨ç‡è¾¾åˆ°äº†ä¸ImageNetä¸Šçš„æœ€æ–°æ°´å¹³ç›¸å½“çš„FIDã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sony/vct%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sony/vctä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18197v1">PDF</a> 23 pages, 11 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºFlow Matchingæ¡†æ¶çš„æ–°å‹ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªæ•°æ®ä¾èµ–çš„å™ªå£°å‘å°„æ¨¡å‹ï¼Œé—´æ¥å­¦ä¹ å™ªå£°åˆ°æ•°æ®çš„æ˜ å°„å‡ ä½•ï¼Œæ˜¾è‘—æé«˜äº†å›¾åƒç”Ÿæˆä»»åŠ¡çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—ç”Ÿæˆæ”¹è¿›ï¼Œå¹¶åœ¨CIFAR-10ä¸Šå®ç°äº†éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒçš„æœ€æ–°éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒFIDï¼Œåœ¨ImageNetçš„64x64åˆ†è¾¨ç‡çš„2æ­¥ç”Ÿæˆä¸­è¾¾åˆ°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„FIDã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰å·²æˆä¸ºæ‰©æ•£æ¨¡å‹çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
<li>éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒé€šå¸¸å­˜åœ¨é«˜æ–¹å·®å’Œä¸ç¨³å®šçš„é—®é¢˜ï¼Œä»æ˜¯æ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºFlow Matchingæ¡†æ¶çš„æ–°å‹CTè®­ç»ƒæ–¹æ³•ã€‚</li>
<li>ä¸»è¦è´¡çŒ®æ˜¯å—åˆ°å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰æ¶æ„å¯å‘çš„è®­ç»ƒå™ªå£°è€¦åˆæ–¹æ¡ˆã€‚</li>
<li>é€šè¿‡è®­ç»ƒæ•°æ®ä¾èµ–çš„å™ªå£°å‘å°„æ¨¡å‹ï¼Œè¯¥æ–¹æ³•èƒ½é—´æ¥å­¦ä¹ å™ªå£°åˆ°æ•°æ®çš„æ˜ å°„å‡ ä½•ã€‚</li>
<li>åœ¨å¤šä¸ªå›¾åƒæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†æ˜¾è‘—çš„ç”Ÿæˆæ”¹è¿›ï¼Œå¹¶åœ¨CIFAR-10å’ŒImageNetä¸Šè¾¾åˆ°äº†æœ€æ–°çš„éè’¸é¦ä¸€è‡´æ€§è®­ç»ƒæ€§èƒ½ã€‚</li>
<li>ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/sony/vct%E3%80%82">https://github.com/sony/vctã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18197">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18197v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18197v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18197v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="VesselSAM-Leveraging-SAM-for-Aortic-Vessel-Segmentation-with-LoRA-and-Atrous-Attention"><a href="#VesselSAM-Leveraging-SAM-for-Aortic-Vessel-Segmentation-with-LoRA-and-Atrous-Attention" class="headerlink" title="VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and   Atrous Attention"></a>VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and   Atrous Attention</h2><p><strong>Authors:Adnan Iltaf, Rayan Merghani Ahmed, Bin Li, Shoujun Zhou</strong></p>
<p>Medical image segmentation is crucial for clinical diagnosis and treatment planning, particularly for complex anatomical structures like vessels. In this work, we propose VesselSAM, a modified version of the Segmentation Anything Model (SAM), specifically designed for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module that combines Atrous Attention with Low-Rank Adaptation (LoRA), to improve segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine local details and broader global context. At the same time, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and ensuring computational efficiency. We evaluate VesselSAM on two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance with DSC scores of 93.50%, 93.25%, 93.02%, and 93.26% across multiple medical centers. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at <a target="_blank" rel="noopener" href="https://github.com/Adnan-CAS/AtrousLora">https://github.com/Adnan-CAS/AtrousLora</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹äºä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è®¡åˆ’çš„åˆ¶å®šè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯å¯¹äºè¡€ç®¡ç­‰å¤æ‚è§£å‰–ç»“æ„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†VesselSAMï¼Œå®ƒæ˜¯Segmentation Anything Modelï¼ˆSAMï¼‰çš„æ”¹è¿›ç‰ˆï¼Œä¸“ä¸ºä¸»åŠ¨è„‰è¡€ç®¡åˆ†å‰²è€Œè®¾è®¡ã€‚VesselSAMç»“åˆäº†AtrousLoRAè¿™ä¸€æ–°é¢–æ¨¡å—ï¼Œè¯¥æ¨¡å—èåˆäº†Atrous Attentionä¸Low-Rank Adaptationï¼ˆLoRAï¼‰æŠ€æœ¯ï¼Œä»¥æé«˜åˆ†å‰²æ€§èƒ½ã€‚Atrous Attentionä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç²¾ç»†çš„å±€éƒ¨ç»†èŠ‚å’Œæ›´å¹¿æ³›çš„å…¨å±€ä¸Šä¸‹æ–‡ã€‚åŒæ—¶ï¼ŒLoRAæœ‰åŠ©äºæœ‰æ•ˆå¾®è°ƒå†»ç»“çš„SAMå›¾åƒç¼–ç å™¨ï¼Œå‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œç¡®ä¿è®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†VesselSAMï¼šä¸»åŠ¨è„‰è¡€ç®¡æ ‘ï¼ˆAVTï¼‰æ•°æ®é›†å’ŒBå‹ä¸»åŠ¨è„‰å¤¹å±‚ï¼ˆTBADï¼‰æ•°æ®é›†ã€‚VesselSAMåœ¨å¤šä¸ªåŒ»å­¦ä¸­å¿ƒå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒDSCå¾—åˆ†åˆ†åˆ«ä¸º93.50ï¼…ã€93.25ï¼…ã€93.02ï¼…å’Œ93.26ï¼…ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰çš„å¤§è§„æ¨¡æ¨¡å‹ç›¸æ¯”ï¼ŒVesselSAMåœ¨æä¾›é«˜åˆ†å‰²å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œè®¡ç®—å¼€é”€æ˜¾è‘—é™ä½ã€‚è¿™ä¸€å‘å±•å¼€è¾Ÿäº†ä¸´åºŠç¯å¢ƒä¸­å¢å¼ºå‹AIä¸»åŠ¨è„‰è¡€ç®¡åˆ†å‰²çš„é“è·¯ã€‚ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Adnan-CAS/AtrousLora%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Adnan-CAS/AtrousLoraå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18185v1">PDF</a> Submitted to IEEE JBHI</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹ä¸»åŠ¨è„‰è¡€ç®¡åˆ†å‰²çš„æ”¹è¿›æ¨¡å‹VesselSAMã€‚å®ƒç»“åˆäº†Atrous Attentionå’ŒLoRAæ¨¡å—ï¼Œå®ç°äº†å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•æ‰å’Œé«˜æ•ˆçš„æ¨¡å‹å¾®è°ƒã€‚åœ¨ä¸»åŠ¨è„‰è¡€ç®¡æ ‘å’ŒBå‹ä¸»åŠ¨è„‰å¤¹å±‚ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒVesselSAMè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼Œå…·æœ‰é«˜åˆ†å‰²ç²¾åº¦å’Œä½è®¡ç®—å¼€é”€ã€‚è¯¥æ¨¡å‹ä¸ºä¸´åºŠç¯å¢ƒä¸­åŸºäºAIçš„ä¸»åŠ¨è„‰è¡€ç®¡åˆ†å‰²æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VesselSAMæ˜¯ä¸“ä¸ºä¸»åŠ¨è„‰è¡€ç®¡åˆ†å‰²è®¾è®¡çš„æ¨¡å‹ï¼ŒåŸºäºSegmentation Anything Modelï¼ˆSAMï¼‰è¿›è¡Œæ”¹è¿›ã€‚</li>
<li>VesselSAMå¼•å…¥äº†AtrousLoRAæ¨¡å—ï¼Œç»“åˆäº†Atrous Attentionä¸Low-Rank Adaptationï¼ˆLoRAï¼‰æŠ€æœ¯ã€‚</li>
<li>Atrous Attentionæ¨¡å—ä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç²¾ç»†çš„å±€éƒ¨å’Œå…¨å±€ä¸Šä¸‹æ–‡ã€‚</li>
<li>LoRAæ¨¡å—æœ‰åŠ©äºé«˜æ•ˆå¾®è°ƒå†»ç»“çš„SAMå›¾åƒç¼–ç å™¨ï¼Œå‡å°‘å¯è®­ç»ƒå‚æ•°å¹¶ç¡®ä¿è®¡ç®—æ•ˆç‡ã€‚</li>
<li>åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼šä¸»åŠ¨è„‰è¡€ç®¡æ ‘ï¼ˆAVTï¼‰å’ŒBå‹ä¸»åŠ¨è„‰å¤¹å±‚ï¼ˆTBADï¼‰ã€‚</li>
<li>VesselSAMå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒDSCå¾—åˆ†è¶…è¿‡å¤šä¸ªåŒ»å­¦ä¸­å¿ƒçš„ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18185">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18185v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18185v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18185v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18185v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Topology-Design-of-Reconffgurable-Intelligent-Surfaces-Based-on-Current-Distribution-and-Otsu-Image-Segmentation"><a href="#Topology-Design-of-Reconffgurable-Intelligent-Surfaces-Based-on-Current-Distribution-and-Otsu-Image-Segmentation" class="headerlink" title="Topology Design of Reconffgurable Intelligent Surfaces Based on Current   Distribution and Otsu Image Segmentation"></a>Topology Design of Reconffgurable Intelligent Surfaces Based on Current   Distribution and Otsu Image Segmentation</h2><p><strong>Authors:Zhen Zhang, Jun Wei Zhang, Hui Dong Li, Junhui Qiu, Lijie Wu, Wan Wan Cao, Ren Wang, Jia Nan Zhang, Qiang Cheng</strong></p>
<p>Miniaturization of reconffgurable intelligent surface RIS) elements is a crucial trend in the development of RISs. It not only facilitates the attainment of multifunctional integration but also promotes seamless amalgamation with other elements. The current on the RIS element plays a crucial role in determining the characteristics of the induced electromagnetic ffeld components. Segments with high current intensity determine the performance of RIS elements. Carving the parts with strong current distribution density into the metal patch of RIS element structure can achieve miniaturization. Based on this insight, this work proposes a topology design method that leverages current distribution and image processing techniques to achieve efffcient miniaturization of the RIS elements. In this proposed method, we ffrst obtain the current distribution across different operational states and the period of the working frequency. Next, we employ the Otsu image segmentation method to extract relevant image information from the current distribution images of the RIS elements. Subsequently, we utilize linear mapping techniques to convert this image information into the structure of RIS elements. Then, based on the structure of the RIS elements, the Quasi-Newton optimization algorithm is utilized to obtain the parameters of the tunable device that correspond to various operational states. As a result, we successfully construct the structural topology of the RIS elements based on their current distribution, designing areas with strong current distribution as metal patches. To validate the performance of the proposed method, a 16 by 16 3-bit RIS was developed, fabricated and measured. Compared with existing RIS designs, the proportion of the top-layer metal patches is smaller, which provides the possibility for integrating other functions and devices. </p>
<blockquote>
<p>å¯é‡æ„æ™ºèƒ½è¡¨é¢ï¼ˆRISï¼‰å…ƒç´ çš„å¾®å‹åŒ–æ˜¯RISå‘å±•çš„ä¸€ä¸ªé‡è¦è¶‹åŠ¿ã€‚å®ƒä¸ä»…æœ‰åˆ©äºå®ç°å¤šåŠŸèƒ½é›†æˆï¼Œè€Œä¸”ä¿ƒè¿›äº†ä¸å…¶ä»–å…ƒç´ çš„æ— ç¼èåˆã€‚RISå…ƒä»¶ä¸Šçš„ç”µæµåœ¨å†³å®šæ„Ÿåº”ç”µç£åœºç‰¹æ€§çš„è¿‡ç¨‹ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚ç”µæµå¼ºåº¦é«˜çš„åŒºåŸŸå†³å®šäº†RISå…ƒä»¶çš„æ€§èƒ½ã€‚é€šè¿‡åœ¨RISå…ƒä»¶ç»“æ„çš„é‡‘å±è¡¥ä¸ä¸Šé›•åˆ»ç”µæµåˆ†å¸ƒå¯†åº¦è¾ƒé«˜çš„éƒ¨åˆ†ï¼Œå¯ä»¥å®ç°å¾®å‹åŒ–ã€‚åŸºäºè¿™ä¸€è§è§£ï¼Œè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§åˆ©ç”¨ç”µæµåˆ†å¸ƒå’Œå›¾åƒå¤„ç†æŠ€æœ¯å®ç°RISå…ƒä»¶é«˜æ•ˆå¾®å‹åŒ–çš„æ‹“æ‰‘è®¾è®¡æ–¹æ³•ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè·å¾—ä¸åŒå·¥ä½œçŠ¶æ€å’Œå·¥ä½œé¢‘ç‡å‘¨æœŸçš„ç”µæµåˆ†å¸ƒï¼Œç„¶åé‡‡ç”¨Otsuå›¾åƒåˆ†å‰²æ–¹æ³•ä»RISå…ƒä»¶çš„ç”µæµåˆ†å¸ƒå›¾åƒä¸­æå–ç›¸å…³å›¾åƒä¿¡æ¯ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ©ç”¨çº¿æ€§æ˜ å°„æŠ€æœ¯å°†è¿™äº›å›¾åƒä¿¡æ¯è½¬åŒ–ä¸ºRISå…ƒä»¶çš„ç»“æ„ã€‚ç„¶åï¼ŒåŸºäºRISå…ƒä»¶çš„ç»“æ„ï¼Œåˆ©ç”¨æ‹Ÿç‰›é¡¿ä¼˜åŒ–ç®—æ³•è·å¾—å¯¹åº”äºå„ç§å·¥ä½œçŠ¶æ€çš„å¯è°ƒè®¾å¤‡çš„å‚æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ ¹æ®ç”µæµåˆ†å¸ƒæˆåŠŸåœ°æ„å»ºäº†RISå…ƒä»¶çš„ç»“æ„æ‹“æ‰‘ï¼Œè®¾è®¡ç”µæµåˆ†å¸ƒè¾ƒå¼ºçš„åŒºåŸŸä½œä¸ºé‡‘å±è¡¥ä¸ã€‚ä¸ºäº†éªŒè¯æ‰€æå‡ºæ–¹æ³•çš„æ€§èƒ½ï¼Œå¼€å‘ã€åˆ¶ä½œå¹¶æµ‹é‡äº†ä¸€ä¸ª16x16 3ä½çš„RISã€‚ä¸ç°æœ‰çš„RISè®¾è®¡ç›¸æ¯”ï¼Œé¡¶å±‚é‡‘å±è¡¥ä¸çš„æ¯”ä¾‹è¾ƒå°ï¼Œè¿™ä¸ºé›†æˆå…¶ä»–åŠŸèƒ½å’Œè®¾å¤‡æä¾›äº†å¯èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18067v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç”µæµåˆ†å¸ƒå’Œå›¾åƒå¤„ç†æŠ€æœ¯çš„å¯é‡æ„æ™ºèƒ½è¡¨é¢ï¼ˆRISï¼‰å…ƒç´ æ‹“æ‰‘è®¾è®¡æ–¹æ³•ï¼Œå®ç°RISå…ƒç´ çš„å¾®å‹åŒ–ã€‚é€šè¿‡è·å–ä¸åŒæ“ä½œçŠ¶æ€ä¸‹å’Œå·¥ä½œé¢‘ç‡å‘¨æœŸçš„ç”µæµåˆ†å¸ƒï¼Œé‡‡ç”¨Otsuå›¾åƒåˆ†å‰²æ–¹æ³•å’Œçº¿æ€§æ˜ å°„æŠ€æœ¯å¤„ç†ä¿¡æ¯ï¼Œå¹¶åŸºäºQuasi-Newtonä¼˜åŒ–ç®—æ³•è·å–å¯è°ƒè®¾å¤‡çš„å‚æ•°ã€‚æˆåŠŸæ„å»ºåŸºäºç”µæµåˆ†å¸ƒçš„RISå…ƒç´ ç»“æ„æ‹“æ‰‘ï¼Œå¹¶åœ¨å®é™…åˆ¶é€ çš„16x16 3ä½RISä¸­å¾—åˆ°éªŒè¯ï¼Œè¯¥è®¾è®¡æœ‰åŠ©äºå®ç°å¤šåŠŸèƒ½é›†æˆå’Œå…¶ä»–åŠŸèƒ½è®¾å¤‡çš„èåˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¾®å‹åŒ–æ˜¯RISå…ƒç´ å‘å±•çš„é‡è¦è¶‹åŠ¿ï¼Œæœ‰åŠ©äºå®ç°å¤šåŠŸèƒ½é›†æˆå’Œå…¶ä»–å…ƒç´ çš„æ— ç¼èåˆã€‚</li>
<li>RISå…ƒç´ çš„ç”µæµåˆ†å¸ƒå¯¹å…¶æ€§èƒ½å…·æœ‰å†³å®šæ€§ä½œç”¨ï¼Œé«˜ç”µæµå¼ºåº¦åŒºåŸŸæ˜¯æ ¸å¿ƒæ€§èƒ½çš„å†³å®šå› ç´ ã€‚</li>
<li>é€šè¿‡åœ¨é‡‘å±è´´ç‰‡ç»“æ„ä¸­ç²¾ç»†é›•åˆ»å¼ºç”µæµåˆ†å¸ƒçš„éƒ¨åˆ†æ¥å®ç°RISå…ƒç´ çš„å¾®å‹åŒ–ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºç”µæµåˆ†å¸ƒå’Œå›¾åƒå¤„ç†æŠ€æœ¯çš„æ‹“æ‰‘è®¾è®¡æ–¹æ³•ï¼Œé€šè¿‡è·å–ä¸åŒæ“ä½œçŠ¶æ€ä¸‹çš„ç”µæµåˆ†å¸ƒæ¥å®ç°é«˜æ•ˆå¾®å‹åŒ–ã€‚</li>
<li>åˆ©ç”¨Otsuå›¾åƒåˆ†å‰²æ–¹æ³•æå–ç›¸å…³å›¾åƒä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨çº¿æ€§æ˜ å°„æŠ€æœ¯å°†å›¾åƒä¿¡æ¯è½¬åŒ–ä¸ºRISå…ƒç´ ç»“æ„ã€‚</li>
<li>ä½¿ç”¨Quasi-Newtonä¼˜åŒ–ç®—æ³•è·å–å¯è°ƒè®¾å¤‡çš„å‚æ•°ï¼Œä»¥æ„å»ºåŸºäºç”µæµåˆ†å¸ƒçš„RISå…ƒç´ ç»“æ„æ‹“æ‰‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18067">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18067v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18067v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18067v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18067v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.18067v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="HERMES-Pathfinder-SpIRIT-a-progress-report"><a href="#HERMES-Pathfinder-SpIRIT-a-progress-report" class="headerlink" title="HERMES Pathfinder &amp; SpIRIT: a progress report"></a>HERMES Pathfinder &amp; SpIRIT: a progress report</h2><p><strong>Authors:F. Fiore, M. Trenti, Y. Evangelista, R. Campana, G. Baroni, F. Ceraudo, M. Citossi, G. Della Casa, G. Dilillo, M. Feroci, M. Fiorini, G. Ghirlanda, C. Labanti, G. La Rosa, E. J. Marchesini, G. Morgante, L. Nava, P. Nogara, A. Nuti, M. Perri, F. Russo, G. Sottile, M. Lavagna. A. Colagrossi, S. Silvestrini, M. Quirino, M. Bechini, L. Bianchi, A. Brandonisio, F. De Cecio, A. Dottori, I. Troisi, G. Bertuccio, F. Mele, B. Negri, R. Bertacin, C. Grappasonni, R. Piazzolla, S. Pirrotta, S. Puccetti, M. Rinaldi, A. Tiberia, L. Burderi, A. Sanna, A. Riggio, C. Cabras, A. Tsvetkova, A. Santangelo, A. Guzman, P. Hedderman, S. Pliego Cagallero, C. Tenzer, A. Vacchi, N. Zampa, R. Crupi, P. Bellutti, E. Demenev, F. Ficorella, D. Novel, G. Pepponi, A. Picciotto, N. Zorzi, M. Grassi, P. Malcovati, T. Di Salvo, W. Leone, S. Trevisan, I Rashevskaya, A. Rachevski, G. Zampa, T. Chen, N. Gao, S. Xiong, S. Yi, S. Zhang, M. Ortiz del Castillo, R. Mearns, J. McRobbie, A. Chapman, M. Thomas, A. Woods, J. Morgan, S. Barraclough, N. Werner, J. Ripa, F. Munz, A. Pal, D. Gacnik, A. Hudrap, D. Selkan, G. Molera Calves</strong></p>
<p>HERMES Pathfinder is an in-orbit demonstration consisting of a constellation of six 3U cubesats hosting simple but innovative X-ray&#x2F;gamma-ray detectors for the monitoring of cosmic high-energy transients. HERMES-PF, funded by ASI and by the EC Horizon 2020 grant, is scheduled for launch in Q1 2025. An identical X-ray&#x2F;gamma-ray detector is hosted by the Australian 6U cubesat SpIRIT, launched on December 1st 2023. The main objective of HERMES-PF&#x2F;SpIRIT is to demonstrate that high energy cosmic transients can be detected efficiently by miniatured hardware and localized using triangulation techniques. The HERMES-PF X-ray&#x2F;gamma-ray detector is made by 60 GAGG:Ce scintillator crystals and 12 2x5 silicon drift detector (SDD) mosaics, used to detect both the cosmic X-rays directly and the optical photons produced by gamma-ray interactions with the scintillator crystals. This design provides a unique broad band spectral coverage from a few keV to a few MeV. Furthermore, the use of fast GAGG:Ce crystals and small SDD cells allows us to reach an exquisite time resolution better than a microsecond. We present a progress report on the missions focusing the discussion on the scientific innovation of the project and on the main lessons learned during the project development including: the importance and the challenges of using distributed architectures to achieve ambitious scientific objectives; the importance of developing critical technologies under science agreements for the realization of high-performing but low-cost payloads; best use of COTS technologies in scientific missions. We finally discuss the prospects of applying these concepts for the creation of an all-sky, all-time monitor to search for the high-energy counterparts of gravitational wave events that Advanced LIGO&#x2F;Virgo&#x2F;Kagra will find at the end of this decade and the Einstein Telescope during the 2030s. </p>
<blockquote>
<p>HERMES Pathfinderæ˜¯ä¸€ä¸ªç”±å…­é¢—3Uç«‹æ–¹å«æ˜Ÿç»„æˆçš„åœ¨è½¨æ¼”ç¤ºæ˜Ÿåº§ï¼Œæ­è½½ç®€å•ä½†åˆ›æ–°çš„Xå°„çº¿&#x2F;ä¼½é©¬å°„çº¿æ¢æµ‹å™¨ï¼Œç”¨äºç›‘æµ‹å®‡å®™é«˜èƒ½ç¬å˜æºã€‚HERMES-PFé¡¹ç›®ç”±ASIå’ŒEC Horizon 2020èµ„åŠ©ï¼Œè®¡åˆ’äº2025å¹´ç¬¬ä¸€å­£åº¦å‘å°„ã€‚ä¸€ä¸ªç›¸åŒçš„Xå°„çº¿&#x2F;ä¼½é©¬å°„çº¿æ¢æµ‹å™¨è¢«æ­è½½åœ¨æ¾³å¤§åˆ©äºšçš„6Uç«‹æ–¹å«æ˜ŸSpIRITä¸Šï¼Œäº2023å¹´12æœˆ1æ—¥å‘å°„ã€‚HERMES-PF&#x2F;SpIRITçš„ä¸»è¦ç›®æ ‡æ˜¯è¯æ˜åˆ©ç”¨å¾®å‹ç¡¬ä»¶å¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹åˆ°é«˜èƒ½å®‡å®™ç¬å˜æºï¼Œå¹¶åˆ©ç”¨ä¸‰è§’æµ‹é‡æŠ€æœ¯è¿›è¡Œå®šä½ã€‚HERMES-PFçš„Xå°„çº¿&#x2F;ä¼½é©¬å°„çº¿æ¢æµ‹å™¨ç”±60å—GAGG:Ceé—ªçƒä½“æ™¶ä½“å’Œ12å—2x5ç¡…æ¼‚ç§»æ¢æµ‹å™¨ï¼ˆSDDï¼‰æ‹¼èŠ±ç»„æˆï¼Œç”¨äºç›´æ¥æ£€æµ‹å®‡å®™Xå°„çº¿å’Œç”±ä¼½é©¬å°„çº¿ä¸é—ªçƒä½“æ™¶ä½“ç›¸äº’ä½œç”¨äº§ç”Ÿçš„å…‰å­¦å…‰å­ã€‚è¿™ç§è®¾è®¡æä¾›äº†ä»å‡ keVåˆ°å‡ MeVçš„å®½æ³¢æ®µå…‰è°±è¦†ç›–ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¿«é€ŸGAGG:Ceæ™¶ä½“å’Œå°å‹SDDç»†èƒï¼Œæˆ‘ä»¬è¾¾åˆ°äº†å¾®å¦™çº§åˆ«çš„æ—¶é—´åˆ†è¾¨ç‡ã€‚æœ¬æ¬¡è¿›åº¦æŠ¥å‘Šé‡ç‚¹è®¨è®ºè¯¥é¡¹ç›®çš„ç§‘å­¦åˆ›æ–°ä»¥åŠé¡¹ç›®å¼€å‘è¿‡ç¨‹ä¸­å¸å–çš„ä¸»è¦æ•™è®­ï¼ŒåŒ…æ‹¬ï¼šä½¿ç”¨åˆ†å¸ƒå¼æ¶æ„å®ç°é›„å¿ƒå‹ƒå‹ƒçš„ç§‘å­¦ç›®æ ‡çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜ï¼›åœ¨ç§‘å­¦ç ”ç©¶åè®®ä¸‹å¼€å‘å…³é”®æŠ€æœ¯å¯¹äºå®ç°é«˜æ€§èƒ½ä½†ä½æˆæœ¬æœ‰æ•ˆè½½è·çš„é‡è¦æ€§ï¼›åœ¨ç§‘ç ”ä»»åŠ¡ä¸­æœ€ä½³åœ°ä½¿ç”¨å•†ä¸šç°æˆæŠ€æœ¯ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å°†è¿™äº›æ¦‚å¿µåº”ç”¨äºåˆ›å»ºå…¨å¤©å…¨æ—¶ç›‘æµ‹å™¨ä»¥å¯»æ‰¾é«˜çº§LIGO&#x2F;å¤„å¥³åº§&#x2F;Kagraå°†åœ¨æœ¬åå¹´æœ«å‘ç°ä»¥åŠçˆ±å› æ–¯å¦æœ›è¿œé•œå°†åœ¨2030å¹´ä»£å‘ç°çš„é‡åŠ›æ³¢äº‹ä»¶çš„é«˜èƒ½å¯¹åº”ç‰©çš„å¯èƒ½æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17952v1">PDF</a> proceedings of the 75th International Astronautical Congress (IAC),   Milan, Italy, 14-18 October 2024</p>
<p><strong>Summary</strong><br>    HERMES Pathfinderæ˜¯ç”±å…­ä¸ª3Uç«‹æ–¹å«æ˜Ÿç»„æˆçš„ä¸€ä¸ªåœ¨è½¨æ¼”ç¤ºé¡¹ç›®ï¼Œç”¨äºç›‘æµ‹å®‡å®™é«˜èƒ½ç¬å˜ç°è±¡ã€‚å…¶æ­è½½çš„X-ray&#x2F;gammaå°„çº¿æ¢æµ‹å™¨ç”±æ–°å‹ç®€å•ä½†åˆ›æ–°çš„ç¡¬ä»¶è®¾å¤‡æ„æˆï¼Œå°†åœ¨å¾®å‹åŒ–çš„åŒæ—¶æœ‰æ•ˆç›‘æµ‹è¿™äº›é«˜èƒ½äº‹ä»¶ã€‚æ­¤é¡¹ç›®é¢„è®¡äºQ1 2025è¿›è¡Œå‘å°„ã€‚è¯¥é¡¹ç›®çš„ç›®æ ‡æ˜¯é€šè¿‡ä¸‰è§’å®šä½æŠ€æœ¯å±•ç¤ºä½¿ç”¨å¾®å‹ç¡¬ä»¶æ£€æµ‹å®‡å®™é«˜èƒ½ç¬å˜ç°è±¡çš„èƒ½åŠ›ã€‚æ¢æµ‹å™¨è®¾è®¡ç‹¬ç‰¹ï¼Œå…·å¤‡å®½é¢‘è°±è¦†ç›–å’Œé«˜æ—¶é—´åˆ†è¾¨ç‡ç‰¹ç‚¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è®¨è®ºäº†è¯¥é¡¹ç›®çš„ç§‘å­¦åˆ›æ–°ã€ä¸»è¦ç»éªŒæ•™è®­ä»¥åŠåœ¨æœªæ¥åº”ç”¨è¿™äº›æ¦‚å¿µçš„å¯èƒ½æ€§ï¼Œä¾‹å¦‚å»ºç«‹å…¨å¤©å€™ã€å…¨æ—¶ç›‘æµ‹å™¨æ¥å¯»æ‰¾å¼•åŠ›æ³¢äº‹ä»¶çš„èƒ½é‡å¯¹åº”ç‰©ã€‚è¯¥ç›‘æµ‹å™¨æœ‰æœ›æˆä¸ºæœªæ¥çš„åœ°çƒè§†é‡è®¾å¤‡çš„å‘å±•èŒƒä¾‹ã€‚ç›®å‰æ¢æµ‹å™¨å·²ç»å¼€å§‹æ­£å¼åº”ç”¨å¹¶è¿›è¡Œæœªæ¥çš„ç›¸å…³æµ‹è¯•å’Œç ”ç©¶ï¼Œç›®æ ‡æ˜¯å‘å±•é«˜æ•ˆè€Œæˆæœ¬è¾ƒä½è½½è·å’Œæœªæ¥å‘å±•åº”ç”¨äºå¤šä¸ªåœºæ™¯çš„ä»ªå™¨è£…å¤‡çš„åŸºç¡€åŸå‹æ­å»ºå®Œæˆä¸»è¦çš„å¤©æ–‡å­¦ç©ºé—´ç«™å®éªŒè®¾å¤‡çš„æµ‹è¯•é˜¶æ®µå¹¶æœ‰æœ›æ¨è¿›ç›¸å…³æŠ€æœ¯çš„å‰æ²¿æ¢ç´¢å’Œåº”ç”¨åœºæ™¯ã€‚æ­¤å¤–è¿˜è®¨è®ºæœªæ¥å…¨æ—¶ç›‘æµ‹å™¨çš„å»ºè®¾å°†ä¸ºå¼•åŠ›æ³¢äº‹ä»¶çš„å‘ç°å’Œæ¢æµ‹æä¾›å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒä»è€Œå¸¦åŠ¨å…¨å¤©æ–‡äº§ä¸šçš„ç§‘æŠ€å‘å±•åœ¨æœªæ¥å°†ä»¥æˆ‘ä»¬æœ€æ–°çš„é«˜ç²¾åº¦å®æ—¶å¤„ç†å’Œå‡†ç¡®æ•°æ®å¤„ç†ä¸ºä¸»è¦çš„æŠ€æœ¯æ‰‹æ®µè¿›è¡Œè¿›ä¸€æ­¥çš„æ¨è¿›å’Œç ”å‘å·¥ä½œã€‚åŒæ—¶æœ¬é¡¹ç›®è¿˜æ¶‰åŠåˆ°é¥æ„Ÿé¢†åŸŸçš„ç›¸å…³åº”ç”¨å’Œå‘å±•è¶‹åŠ¿ç­‰è¯é¢˜ã€‚æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡å›½é™…åˆä½œæ¨åŠ¨å…ˆè¿›æŠ€æœ¯çš„ç ”å‘å’Œåº”ç”¨ä¸ºæœªæ¥çš„ç©ºé—´ç§‘å­¦æ¢ç´¢æä¾›æ–°çš„æ€è·¯å’Œè§£å†³æ–¹æ¡ˆã€‚è¯¥é¡¹ç›®è¿˜å°†å¯¹å®‡å®™æ¢ç´¢é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“å¹¶æœ‰æœ›æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåˆ›æ–°å‘å±•ã€‚ä¸»è¦è¿›å±•å’ŒæŒ‘æˆ˜åœ¨äºå¦‚ä½•åœ¨å°å‹è½½è·ä¸­åŒæ—¶å®ç°é«˜æ•ˆçš„æ¢æµ‹åŠŸèƒ½å’Œä¸¥æ ¼çš„æ—¶ç©ºç²¾åº¦æ ‡å‡†å°†å…·æœ‰æ·±è¿œçš„æŠ€æœ¯å’Œå•†ä¸šå‰æ™¯å¯¹äºç©ºé—´ç§‘å­¦ä¸æŠ€æœ¯çš„å‘å±•å…·æœ‰é‡è¦çš„æˆ˜ç•¥æ„ä¹‰å¹¶å°†è¿›ä¸€æ­¥æ¨åŠ¨å…¨çƒèŒƒå›´å†…çš„ç©ºé—´æ¢ç´¢åˆä½œä¸å‘å±•ã€‚æœ¬é¡¹ç›®å°†æœ‰æœ›åœ¨æœªæ¥å®ç°æ›´å¹¿æ³›çš„åº”ç”¨åœºæ™¯å’Œæ›´å¤šé¢†åŸŸçš„æŠ€æœ¯çªç ´æˆä¸ºæ¨åŠ¨æœªæ¥å®‡å®™æ¢ç´¢é¢†åŸŸå‘å±•çš„é‡è¦åŠ›é‡ä¹‹ä¸€æ¨åŠ¨æœªæ¥ç©ºé—´ç§‘å­¦å’ŒæŠ€æœ¯çš„å‘å±•å¹¶æœ‰æœ›åœ¨æœªæ¥äº§ç”Ÿé‡è¦çš„å•†ä¸šä»·å€¼å’Œç»æµæ•ˆç›Šã€‚æœ¬é¡¹ç›®å°†ä¸æ–­çªç ´æŠ€æœ¯ç“¶é¢ˆå®ç°æ›´å¤šçš„æŠ€æœ¯çªç ´å’Œåˆ›æ–°å‘å±•ä»¥æ¨åŠ¨æ•´ä¸ªè¡Œä¸šçš„è¿›æ­¥å’Œå‘å±•å¹¶æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œç»æµå¢é•¿å‰æ™¯æŒç»­å¹¿é˜”ã€‚ã€‚å°†èšç„¦æå‡æ•°æ®å¤„ç†æ•ˆç‡ä¸ºç§‘å­¦æ¢ç´¢å¼€è¾Ÿæ–°é€”å¾„é¢å‘å›½å®¶é‡å¤§éœ€æ±‚åŠäº§ä¸šç«äº‰é¢†åŸŸä¸ºå…¨çƒæ¢ç´¢å·¥ä½œè´¡çŒ®é‡è¦åŠ›é‡ç§¯æå‘æŒ¥ç§‘å­¦ç ”ç©¶å’ŒæŠ€æœ¯çš„åˆ›æ–°å¼•é¢†ä½œç”¨é¢å‘æœªæ¥çš„æŒ‘æˆ˜å¯»æ±‚æ›´å¤šçš„åˆ›æ–°çªç ´å’Œåº”ç”¨æ‹“å±•é¢†åŸŸåœ¨å…¨ç¤¾ä¼šå½¢æˆé‡å¤§ç»æµæ•ˆç›Šå’Œäº§ä¸šå¼•é¢†ä»·å€¼åŠæ–°çš„å¢é•¿ç‚¹å¹¶å°†åŠ é€Ÿç§‘æŠ€è‡ªç«‹è‡ªå¼ºã€‚è™½ç„¶ä»æœ‰å¾…å®Œå–„å’Œä¼˜åŒ–ä¹‹å¤„ä½†ä»æ˜¾ç¤ºå‡ºæ— é™æ½œåŠ›å’Œå‘å±•å‰æ™¯æœªæ¥å°†å¼€å¯æ›´å¤šæ¢ç´¢é¢†åŸŸçš„å›½é™…åˆä½œå’Œåˆ›æ–°ç ”ç©¶å€¼å¾—æœŸå¾…æœªæ¥éšç€æŠ€æœ¯çš„å‘å±•å°†å¼€å¯å…¨æ–°çš„ç§‘å­¦æ¢ç´¢æ¨¡å¼åœ¨åœ°çƒè§‚æµ‹ç­‰é¢†åŸŸæä¾›å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ä¸ºæœªæ¥ç§‘å­¦ç ”ç©¶æä¾›å…¨æ–°çš„è§†è§’å’Œè§£å†³æ–¹æ¡ˆä¿ƒè¿›å›½é™…åˆä½œå’Œå…¨çƒç§‘æŠ€åˆ›æ–°å‘å±•æ¨è¿›æœªæ¥äººç±»æ–‡æ˜çš„è¿›æ­¥å‘å±•å’Œç¤¾ä¼šå‘å±•ä½œå‡ºé‡è¦è´¡çŒ®æœ¬é¡¹ç›®åœ¨å›½é™…èŒƒå›´å†…æ ‘ç«‹äº†å¼€æ”¾åˆä½œä¸äº¤æµçš„æ„è¯†å……åˆ†å‘æŒ¥è·¨ç•Œäººæ‰çš„ä¸“ä¸šç‰¹é•¿å»ºç«‹é¢å‘å›½é™…çš„åˆä½œç ”ç©¶æœºåˆ¶å’Œç§‘æŠ€åˆ›æ–°å‘å±•æ¨åŠ¨æœ¬è¡Œä¸šä¸æ–­å‘é«˜è´¨é‡é«˜æ°´å¹³æ–¹å‘å‘å±•ã€‚ã€‚ç»¼ä¸Šæ‰€è¿°HERMES Pathfinderé¡¹ç›®çš„æˆåŠŸå®æ–½å°†å¼•é¢†æœªæ¥çš„ç©ºé—´æ¢ç´¢å’Œç§‘å­¦çªç ´çš„å‰æ™¯å……æ»¡å¸Œæœ›æˆ‘ä»¬å°†ç»§ç»­åŠªåŠ›åœ¨æ¨è¿›åœ°çƒè§‚å¯ŸæŠ€æœ¯åº”ç”¨å‘å±•å’Œè¿›ä¸€æ­¥å¼€è¾Ÿç§‘å­¦æŠ€æœ¯åˆä½œæ–¹é¢çš„æ–°æ€è·¯ç§¯ææ¢ç´¢è´¡çŒ®è‡ªèº«çš„åˆ›æ–°æ™ºæ…§å’ŒæœåŠ¡å›½é™…å¤ªç©ºç§‘å­¦çš„æ•´ä½“å®åŠ›ä¸è¿›æ­¥å‘å±•å’Œåˆ›æ–°èƒ½åŠ›å‘æ˜æ›´å¥½åœ°æ¨è¿›å›½å†…ç§‘æŠ€æˆæœçš„æŒç»­ä¾›ç»™ä¸å®Œå–„åŠ å¿«æ¨è¿›è‡ªèº«é˜Ÿä¼çš„äººæ‰å»ºè®¾å’Œå›½é™…åŒ–äº¤æµåˆä½œå…¨é¢æå‡è¡Œä¸šæœåŠ¡è´¨é‡å’Œç§‘æŠ€åˆ›æ–°å½±å“åŠ›ç­‰æ–¹é¢è´¡çŒ®å‡ºè‡ªèº«çš„æ™ºæ…§å’ŒåŠ›é‡æŒç»­ä¸æ–­çš„å¼€å±•æ–°æŠ€æœ¯çš„ç ”ç©¶ä¸åˆ›æ–°å¹¶ä¸æ–­æ¢ç´¢å’Œåˆ›æ–°æ‹“å±•æ›´å¤šåº”ç”¨åœºæ™¯ä¸æŠ€æœ¯æ–¹å‘å®ç°æ›´å¹¿æ³›çš„åº”ç”¨ä»·å€¼ä¸ç¤¾ä¼šæ•ˆç›Šæå‡å¹¶åŠªåŠ›å¼€åˆ›å›½é™…å‰æ²¿çš„ç§‘ç ”åˆ›æ–°ä¹‹è·¯å°†ä¼šæ”¶è·æœªæ¥æœªçŸ¥çš„åˆ›æ–°ä¹‹æœå°†æˆä¸ºæˆ‘ä»¬åœ¨æ–°ä¸–ç•Œä¸­æœ€ä¸ºé‡è¦çš„å·¥å…·ä¹‹ä¸€åŠ©åŠ›æˆ‘ä»¬èµ°å‘æ›´åŠ å¹¿é˜”çš„æœªæ¥ä¸–ç•Œå’Œå®‡å®™æ¢ç´¢ä¹‹è·¯ä¸ºäººç±»å®ç°è·¨æ—¶ä»£ç§‘æŠ€åˆ›æ–°æ·»ç –åŠ ç“¦å…·æœ‰éå‡¡çš„æˆ˜ç•¥æ„ä¹‰å’Œå¹¿é˜”çš„å‘å±•ç©ºé—´ã€‚â€œæ€»æœ‰ä¸€æ®µç¾å¦™çš„å†å²ç¯‡ç« å°†ä¼šå‘ˆç°åœ¨æˆ‘ä»¬é¢å‰ç­‰å¾…æˆ‘ä»¬å»å…±åŒåˆ›é€ ä¹¦å†™å’Œè§è¯å…¶è¯ç”Ÿä¸å‘å±•å†ç¨‹ï¼</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17952">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17952v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17952v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17952v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Can-Score-Based-Generative-Modeling-Effectively-Handle-Medical-Image-Classification"><a href="#Can-Score-Based-Generative-Modeling-Effectively-Handle-Medical-Image-Classification" class="headerlink" title="Can Score-Based Generative Modeling Effectively Handle Medical Image   Classification?"></a>Can Score-Based Generative Modeling Effectively Handle Medical Image   Classification?</h2><p><strong>Authors:Sushmita Sarker, Prithul Sarker, George Bebis, Alireza Tavakkoli</strong></p>
<p>The remarkable success of deep learning in recent years has prompted applications in medical image classification and diagnosis tasks. While classification models have demonstrated robustness in classifying simpler datasets like MNIST or natural images such as ImageNet, this resilience is not consistently observed in complex medical image datasets where data is more scarce and lacks diversity. Moreover, previous findings on natural image datasets have indicated a potential trade-off between data likelihood and classification accuracy. In this study, we explore the use of score-based generative models as classifiers for medical images, specifically mammographic images. Our findings suggest that our proposed generative classifier model not only achieves superior classification results on CBIS-DDSM, INbreast and Vin-Dr Mammo datasets, but also introduces a novel approach to image classification in a broader context. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/sushmitasarker/sgc_for_medical_image_classification">https://github.com/sushmitasarker/sgc_for_medical_image_classification</a> </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ å–å¾—äº†ä»¤äººç©ç›®çš„æˆåŠŸï¼Œå¹¶å¹¿æ³›åº”ç”¨äºåŒ»å­¦å›¾åƒåˆ†ç±»å’Œè¯Šæ–­ä»»åŠ¡ã€‚è™½ç„¶åˆ†ç±»æ¨¡å‹åœ¨åˆ†ç±»MNISTç­‰ç®€å•æ•°æ®é›†æˆ–ImageNetç­‰è‡ªç„¶å›¾åƒæ—¶è¡¨ç°å‡ºäº†ç¨³å¥æ€§ï¼Œä½†åœ¨å¤æ‚åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸­ï¼Œè¿™ç§ç¨³å¥æ€§å¹¶ä¸æ€»æ˜¯å­˜åœ¨ã€‚å¤æ‚åŒ»å­¦å›¾åƒæ•°æ®é›†çš„æ•°æ®æ›´åŠ ç¨€ç¼ºä¸”ç¼ºä¹å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œä»¥å¾€åœ¨è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šçš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ•°æ®å¯èƒ½æ€§å’Œåˆ†ç±»å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨æ½œåœ¨æƒè¡¡ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä¹³è…ºXå…‰å›¾åƒçš„åˆ†ç±»ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œæ‰€æå‡ºçš„ç”Ÿæˆåˆ†ç±»æ¨¡å‹ä¸ä»…åœ¨CBIS-DDSMã€INbreastå’ŒVin-Dr Mammographyæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜å¼‚çš„åˆ†ç±»ç»“æœï¼Œè€Œä¸”ä¸ºå›¾åƒåˆ†ç±»æä¾›äº†æ›´å¹¿æ³›çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/sushmitasarker/sgc_for_medical_image_classification">https://github.com/sushmitasarker/sgc_for_medical_image_classification</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17727v1">PDF</a> Accepted at the International Symposium on Biomedical Imaging (ISBI)   2025</p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å­¦ä¹ åœ¨è¿‘å¹´æ¥çš„æ˜¾è‘—æˆåŠŸä¿ƒè¿›äº†å…¶åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»å’Œè¯Šæ–­ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚å°½ç®¡åˆ†ç±»æ¨¡å‹åœ¨åˆ†ç±»ç®€å•æ•°æ®é›†ï¼ˆå¦‚MNISTï¼‰æˆ–è‡ªç„¶å›¾åƒï¼ˆå¦‚ImageNetï¼‰æ—¶è¡¨ç°å‡ºç¨³å¥æ€§ï¼Œä½†åœ¨å¤æ‚çš„åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸­ï¼Œç”±äºæ•°æ®æ›´åŠ ç¨€ç¼ºä¸”ç¼ºä¹å¤šæ ·æ€§ï¼Œè¿™ç§ç¨³å¥æ€§å¹¶ä¸æ€»æ˜¯è¢«è§‚å¯Ÿåˆ°ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒï¼ˆç‰¹åˆ«æ˜¯ä¹³è…ºXå…‰å›¾åƒï¼‰åˆ†ç±»ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç”Ÿæˆåˆ†ç±»æ¨¡å‹ä¸ä»…åœ¨CBIS-DDSMã€INbreastå’ŒVin-Dr Mammoæ•°æ®é›†ä¸Šå®ç°äº†å‡ºè‰²çš„åˆ†ç±»æ•ˆæœï¼Œè€Œä¸”ä¸ºå›¾åƒåˆ†ç±»æä¾›äº†æ›´å¹¿æ³›çš„èƒŒæ™¯ä¸‹çš„æ–°æ–¹æ³•ã€‚ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/sushmitasarker/sgc_for_medical_image_classification%E3%80%82">https://github.com/sushmitasarker/sgc_for_medical_image_classificationã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»å’Œè¯Šæ–­ä¸­çš„åº”ç”¨æ˜¾è‘—ã€‚</li>
<li>åˆ†ç±»æ¨¡å‹åœ¨è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šè¡¨ç°ç¨³å¥ï¼Œä½†åœ¨åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸­è¡¨ç°ä¸ç¨³å®šã€‚</li>
<li>åŒ»å­¦å›¾åƒæ•°æ®æ›´åŠ ç¨€ç¼ºä¸”ç¼ºä¹å¤šæ ·æ€§ï¼Œç»™åˆ†ç±»å¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹è¢«æ¢ç´¢ç”¨äºåŒ»å­¦å›¾åƒåˆ†ç±»ã€‚</li>
<li>æ‰€æå‡ºçš„ç”Ÿæˆåˆ†ç±»æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†ä¼˜è¶Šçš„åˆ†ç±»æ•ˆæœã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºå›¾åƒåˆ†ç±»æä¾›äº†æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ›´å¹¿æ³›çš„èƒŒæ™¯ä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17727">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17727v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17727v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17727v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SynthRAD2025-Grand-Challenge-dataset-generating-synthetic-CTs-for-radiotherapy"><a href="#SynthRAD2025-Grand-Challenge-dataset-generating-synthetic-CTs-for-radiotherapy" class="headerlink" title="SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for   radiotherapy"></a>SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for   radiotherapy</h2><p><strong>Authors:Adrian Thummerer, Erik van der Bijl, Arthur Jr Galapon, Florian Kamp, Mark Savenije, Christina Muijs, Shafak Aluwini, Roel J. H. M. Steenbakkers, Stephanie Beuel, Martijn P. W. Intven, Johannes A. Langendijk, Stefan Both, Stefanie Corradini, Viktor Rogowski, Maarten Terpstra, Niklas Wahl, Christopher Kurz, Guillaume Landry, Matteo Maspero</strong></p>
<p>Medical imaging is essential in modern radiotherapy, supporting diagnosis, treatment planning, and monitoring. Synthetic imaging, particularly synthetic computed tomography (sCT), is gaining traction in radiotherapy. The SynthRAD2025 dataset and Grand Challenge promote advancements in sCT generation by providing a benchmarking platform for algorithms using cone-beam CT (CBCT) and magnetic resonance imaging (MRI).   The dataset includes 2362 cases: 890 MRI-CT and 1472 CBCT-CT pairs from head-and-neck, thoracic, and abdominal cancer patients treated at five European university medical centers (UMC Groningen, UMC Utrecht, Radboud UMC, LMU University Hospital Munich, and University Hospital of Cologne). Data were acquired with diverse scanners and protocols. Pre-processing, including rigid and deformable image registration, ensures high-quality, modality-aligned images. Extensive quality assurance validates image consistency and usability.   All imaging data is provided in MetaImage (.mha) format, ensuring compatibility with medical image processing tools. Metadata, including acquisition parameters and registration details, is available in structured CSV files. To maintain dataset integrity, SynthRAD2025 is divided into training (65%), validation (10%), and test (25%) sets. The dataset is accessible at <a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.14918089">https://doi.org/10.5281/zenodo.14918089</a> under the SynthRAD2025 collection.   This dataset supports benchmarking and the development of synthetic imaging techniques for radiotherapy applications. Use cases include sCT generation for MRI-only and MR-guided photon&#x2F;proton therapy, CBCT-based dose calculations, and adaptive radiotherapy workflows. By integrating diverse acquisition settings, SynthRAD2025 fosters robust, generalizable image synthesis algorithms, advancing personalized cancer care and adaptive radiotherapy. </p>
<blockquote>
<p>åŒ»å­¦æˆåƒåœ¨ç°ä»£æ”¾å°„æ²»ç–—ä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼Œæ”¯æŒè¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œæ²»ç–—ç›‘æµ‹ã€‚åˆæˆæˆåƒï¼Œå°¤å…¶æ˜¯åˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆsCTï¼‰ï¼Œåœ¨æ”¾å°„æ²»ç–—é¢†åŸŸæ­£è·å¾—è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚SynthRAD2025æ•°æ®é›†å’Œå¤§èµ›é€šè¿‡ä¸ºä½¿ç”¨é”¥å½¢æŸCTï¼ˆCBCTï¼‰å’Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„ç®—æ³•æä¾›åŸºå‡†æµ‹è¯•å¹³å°ï¼Œä¿ƒè¿›äº†sCTç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚æ•°æ®é›†åŒ…å«2362ä¸ªæ¡ˆä¾‹ï¼š890ä¸ªMRI-CTå¯¹å’Œ1472ä¸ªCBCT-CTå¯¹ï¼Œæ¥è‡ªæ¬§æ´²äº”æ‰€å¤§å­¦åŒ»ç–—ä¸­å¿ƒï¼ˆæ ¼ç½—å®æ ¹UMCã€ä¹Œå¾—å‹’æ”¯UMCã€æ‹‰å¾·å¸ƒå¾·UMCã€æ…•å°¼é»‘LMUå¤§å­¦åŒ»é™¢å’Œç§‘éš†å¤§å­¦åŒ»é™¢ï¼‰æ²»ç–—çš„å¤´é¢ˆã€èƒ¸éƒ¨å’Œè…¹éƒ¨ç™Œç—‡æ‚£è€…ã€‚æ•°æ®é‡‡ç”¨å¤šç§æ‰«æå™¨å’Œåè®®é‡‡é›†è€Œæˆã€‚é¢„å¤„ç†åŒ…æ‹¬åˆšæ€§å’Œå¯å˜å½¢å›¾åƒé…å‡†ï¼Œç¡®ä¿é«˜è´¨é‡ã€æ¨¡æ€å¯¹é½çš„å›¾åƒã€‚å¹¿æ³›çš„è´¨é‡ä¿è¯éªŒè¯äº†å›¾åƒçš„ä¸€è‡´æ€§å’Œå¯ç”¨æ€§ã€‚æ‰€æœ‰å›¾åƒæ•°æ®å‡ä»¥MetaImageï¼ˆ.mhaï¼‰æ ¼å¼æä¾›ï¼Œç¡®ä¿ä¸åŒ»å­¦å½±åƒå¤„ç†å·¥å…·å…¼å®¹ã€‚å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬é‡‡é›†å‚æ•°å’Œé…å‡†ç»†èŠ‚ï¼Œéƒ½å­˜å‚¨åœ¨ç»“æ„åŒ–çš„CSVæ–‡ä»¶ä¸­ã€‚ä¸ºäº†ä¿æŒæ•°æ®é›†çš„å®Œæ•´æ€§ï¼ŒSynthRAD2025è¢«åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆå 65%ï¼‰ã€éªŒè¯é›†ï¼ˆå 10%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆå 25%ï¼‰ã€‚æ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.14918089%E5%9C%A8SynthRAD2025%E6%94%B6%E8%97%8F%E4%B8%8B%E8%8E%B7%E5%8F%96%E3%80%82%E8%AF%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%AF%E6%8C%81%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%92%8C%E5%90%88%E6%88%90%E6%88%90%E5%83%8F%E6%8A%80%E6%9C%AF%E5%9C%A8%E6%94%BE%E5%B0%84%E6%B2%BB%E7%96%97%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84%E5%8F%91%E5%B1%95%E3%80%82%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E5%8C%85%E6%8B%AC%E4%BB%85%E4%BD%BF%E7%94%A8MRI%E5%92%8CMR%E5%BC%95%E5%AF%BC%E7%9A%84%E5%85%89%E5%AD%90/%E8%B4%A8%E5%AD%90%E7%96%97%E6%B3%95%E4%B8%AD%E7%9A%84sCT%E7%94%9F%E6%88%90%E3%80%81%E5%9F%BA%E4%BA%8ECBCT%E7%9A%84%E5%89%82%E9%87%8F%E8%AE%A1%E7%AE%97%E5%92%8C%E8%87%AA%E9%80%82%E5%BA%94%E6%94%BE%E7%96%97%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E3%80%82%E9%80%9A%E8%BF%87%E6%95%B4%E5%90%88%E5%90%84%E7%A7%8D%E9%87%87%E9%9B%86%E7%8E%AF%E5%A2%83%EF%BC%8CSynthRAD2025%E5%9F%B9%E8%82%B2%E7%A8%B3%E5%81%A5%E3%80%81%E5%8F%AF%E6%8E%A8%E5%B9%BF%E7%9A%84%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90%E7%AE%97%E6%B3%95%EF%BC%8C%E6%8E%A8%E5%8A%A8%E4%B8%AA%E6%80%A7%E5%8C%96%E7%99%8C%E7%97%87%E6%8A%A4%E7%90%86%E5%92%8C%E8%87%AA%E9%80%82%E5%BA%94%E6%94%BE%E5%B0%84%E6%B2%BB%E7%96%97%E7%9A%84%E5%8F%91%E5%B1%95%E3%80%82">https://doi.org/10.5281/zenodo.14918089åœ¨SynthRAD2025æ”¶è—ä¸‹è·å–ã€‚è¯¥æ•°æ®é›†æ”¯æŒåŸºå‡†æµ‹è¯•å’ŒåˆæˆæˆåƒæŠ€æœ¯åœ¨æ”¾å°„æ²»ç–—åº”ç”¨ä¸­çš„å‘å±•ã€‚åº”ç”¨åœºæ™¯åŒ…æ‹¬ä»…ä½¿ç”¨MRIå’ŒMRå¼•å¯¼çš„å…‰å­/è´¨å­ç–—æ³•ä¸­çš„sCTç”Ÿæˆã€åŸºäºCBCTçš„å‰‚é‡è®¡ç®—å’Œè‡ªé€‚åº”æ”¾ç–—å·¥ä½œæµç¨‹ã€‚é€šè¿‡æ•´åˆå„ç§é‡‡é›†ç¯å¢ƒï¼ŒSynthRAD2025åŸ¹è‚²ç¨³å¥ã€å¯æ¨å¹¿çš„å›¾åƒåˆæˆç®—æ³•ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–ç™Œç—‡æŠ¤ç†å’Œè‡ªé€‚åº”æ”¾å°„æ²»ç–—çš„å‘å±•ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17609v1">PDF</a> 22 pages, 8 tables, 4 figures; Under submission to Medical Physics,   as dataset paper for the SynhtRAD2025 Grand Challenge   <a target="_blank" rel="noopener" href="https://synthrad2025.grand-challenge.org/">https://synthrad2025.grand-challenge.org/</a></p>
<p><strong>Summary</strong><br>     åŒ»å­¦æˆåƒåœ¨ç°ä»£æ”¾å°„æ²»ç–—ä¸­è‡³å…³é‡è¦ï¼Œæ”¯æŒè¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œç›‘æµ‹ã€‚åˆæˆæˆåƒï¼Œç‰¹åˆ«æ˜¯åˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆsCTï¼‰åœ¨æ”¾å°„æ²»ç–—ä¸­è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚SynthRAD2025æ•°æ®é›†å’Œå¤§èµ›ä¿ƒè¿›äº†sCTç”ŸæˆæŠ€æœ¯çš„å‘å±•ï¼Œä¸ºä½¿ç”¨é”¥å½¢æŸCTï¼ˆCBCTï¼‰å’Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„ç®—æ³•æä¾›äº†åŸºå‡†æµ‹è¯•å¹³å°ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªäº”ä¸ªæ¬§æ´²å¤§å­¦åŒ»ç–—ä¸­å¿ƒçš„å¤´é¢ˆã€èƒ¸éƒ¨å’Œè…¹éƒ¨ç™Œç—‡æ‚£è€…çš„MRI-CTå’ŒCBCT-CTé…å¯¹æ¡ˆä¾‹ï¼Œæ¶µç›–å¤šç§æ‰«æä»ªå’Œåè®®ã€‚é€šè¿‡é¢„å¤„ç†å’Œå¹¿æ³›çš„è´¨é‡ä¿è¯ï¼Œç¡®ä¿å›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚è¯¥æ•°æ®é›†æ”¯æŒåˆæˆæˆåƒæŠ€æœ¯çš„åŸºå‡†æµ‹è¯•å’Œå¼€å‘ï¼Œç”¨äºæ”¾å°„æ²»ç–—åº”ç”¨ï¼Œå¦‚ä»…MRIå’ŒMRå¼•å¯¼çš„å…‰å­&#x2F;è´¨å­ç–—æ³•ã€CBCTå‰‚é‡è®¡ç®—å’Œè‡ªé€‚åº”æ”¾å°„æ²»ç–—å·¥ä½œæµç¨‹ã€‚SynthRAD2025çš„å¤šæ ·é‡‡é›†è®¾ç½®ä¿ƒè¿›äº†ç¨³å¥ã€é€šç”¨çš„å›¾åƒåˆæˆç®—æ³•çš„å‘å±•ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–ç™Œç—‡æŠ¤ç†å’Œè‡ªé€‚åº”æ”¾å°„æ²»ç–—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦æˆåƒåœ¨ç°ä»£æ”¾å°„æ²»ç–—ä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼ŒåŒ…æ‹¬è¯Šæ–­ã€æ²»ç–—è§„åˆ’å’Œç›‘æµ‹ã€‚</li>
<li>åˆæˆæˆåƒæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åˆæˆè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆsCTï¼‰åœ¨æ”¾å°„æ²»ç–—ä¸­æ—¥ç›Šå—åˆ°å…³æ³¨ã€‚</li>
<li>SynthRAD2025æ•°æ®é›†åŒ…å«æ¥è‡ªäº”ä¸ªæ¬§æ´²å¤§å­¦åŒ»ç–—ä¸­å¿ƒçš„å¤šç§ç™Œç—‡æ‚£è€…çš„åŒ»å­¦å›¾åƒæ•°æ®ã€‚</li>
<li>æ•°æ®é›†æä¾›é«˜è´¨é‡çš„å›¾åƒï¼Œé€šè¿‡é¢„å¤„ç†å’Œå¹¿æ³›çš„è´¨é‡ä¿è¯ç¡®ä¿å›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ•°æ®é›†æ”¯æŒåˆæˆæˆåƒæŠ€æœ¯çš„åŸºå‡†æµ‹è¯•å’Œå¼€å‘ï¼Œåœ¨æ”¾å°„æ²»ç–—ä¸­æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>SynthRAD2025æ•°æ®é›†æä¾›äº†è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•çš„æ•°æ®åˆ†å‰²ï¼Œä¾¿äºç®—æ³•çš„å¼€å‘å’Œè¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17609">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17609v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17609v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17609v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2502.17609v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Measurement-of-Medial-Elbow-Joint-Space-using-Landmark-Detection"><a href="#Measurement-of-Medial-Elbow-Joint-Space-using-Landmark-Detection" class="headerlink" title="Measurement of Medial Elbow Joint Space using Landmark Detection"></a>Measurement of Medial Elbow Joint Space using Landmark Detection</h2><p><strong>Authors:Shizuka Akahori, Shotaro Teruya, Pragyan Shrestha, Yuichi Yoshii, Ryuhei Michinobu, Satoshi Iizuka, Itaru Kitahara</strong></p>
<p>Ultrasound imaging of the medial elbow is crucial for the early diagnosis of Ulnar Collateral Ligament (UCL) injuries. Specifically, measuring the elbow joint space in ultrasound images is used to assess the valgus instability of the elbow caused by UCL injuries. To automate this measurement, a model trained on a precisely annotated dataset is necessary; however, no publicly available dataset exists to date. This study introduces a novel ultrasound medial elbow dataset to measure the joint space. The dataset comprises 4,201 medial elbow ultrasound images from 22 subjects, with landmark annotations on the humerus and ulna, based on the expertise of three orthopedic surgeons. We evaluated joint space measurement methods on our proposed dataset using heatmap-based, regression-based, and token-based landmark detection methods. While heatmap-based landmark detection methods generally achieve high accuracy, they sometimes produce multiple peaks on a heatmap, leading to incorrect detection. To mitigate this issue and enhance landmark localization, we propose Shape Subspace (SS) landmark refinement by measuring geometrical similarities between the detected and reference landmark positions. The results show that the mean joint space measurement error is 0.116 mm when using HRNet. Furthermore, SS landmark refinement can reduce the mean absolute error of landmark positions by 0.010 mm with HRNet and by 0.103 mm with ViTPose on average. These highlight the potential for high-precision, real-time diagnosis of UCL injuries by accurately measuring joint space. Lastly, we demonstrate point-based segmentation for the humerus and ulna using the detected landmarks as inputs. Our dataset will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/Akahori000/Ultrasound-Medial-Elbow-Dataset">https://github.com/Akahori000/Ultrasound-Medial-Elbow-Dataset</a> </p>
<blockquote>
<p>è¶…å£°æˆåƒå¯¹å°ºä¾§éŸ§å¸¦ï¼ˆUCLï¼‰æŸä¼¤çš„æ—©æœŸè¯Šæ–­è‡³å…³é‡è¦ã€‚ç‰¹åˆ«æ˜¯ï¼Œé€šè¿‡æµ‹é‡è¶…å£°å›¾åƒä¸­çš„è‚˜å…³èŠ‚é—´éš™æ¥è¯„ä¼°ç”±UCLæŸä¼¤å¼•èµ·çš„è‚˜éƒ¨å¤–ç¿»ä¸ç¨³å®šã€‚ä¸ºäº†è‡ªåŠ¨åŒ–æ­¤æµ‹é‡è¿‡ç¨‹ï¼Œéœ€è¦ä¸€ä¸ªç»è¿‡ç²¾ç¡®æ ‡æ³¨çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹ï¼Œä½†ç›®å‰å°šæ— å…¬å¼€æ•°æ®é›†å¯ç”¨ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ä¸ªç”¨äºæµ‹é‡å…³èŠ‚é—´éš™çš„æ–°å‹è¶…å£°å†…ä¾§è‚˜å…³èŠ‚æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ª22åå—è¯•è€…çš„4,201å¼ å†…ä¾§è‚˜å…³èŠ‚è¶…å£°å›¾åƒï¼ŒåŸºäºä¸‰åéª¨ç§‘ä¸“å®¶çš„ä¸“ä¸šçŸ¥è¯†ï¼Œå¯¹è‚¡éª¨å’Œå°ºéª¨è¿›è¡Œäº†åœ°æ ‡æ ‡æ³¨ã€‚æˆ‘ä»¬åœ¨æ‰€æå‡ºçš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†å…³èŠ‚é—´éš™æµ‹é‡æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºçƒ­å›¾çš„ã€åŸºäºå›å½’çš„å’ŒåŸºäºä»¤ç‰Œçš„åœ°æ ‡æ£€æµ‹æ–¹æ³•ã€‚è™½ç„¶åŸºäºçƒ­å›¾çš„åœ°æ ‡æ£€æµ‹æ–¹æ³•é€šå¸¸å…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§ï¼Œä½†å®ƒä»¬æœ‰æ—¶ä¼šåœ¨çƒ­å›¾ä¸Šäº§ç”Ÿå¤šä¸ªå³°å€¼ï¼Œä»è€Œå¯¼è‡´æ£€æµ‹é”™è¯¯ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜å¹¶å¢å¼ºåœ°æ ‡å®šä½ï¼Œæˆ‘ä»¬æå‡ºäº†é€šè¿‡æµ‹é‡æ£€æµ‹åˆ°çš„åœ°æ ‡å’Œå‚è€ƒåœ°æ ‡ä½ç½®ä¹‹é—´çš„å‡ ä½•ç›¸ä¼¼æ€§æ¥è¿›è¡ŒShape Subspaceï¼ˆSSï¼‰åœ°æ ‡ç»†åŒ–ã€‚ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨HRNetæ—¶ï¼Œå¹³å‡å…³èŠ‚é—´éš™æµ‹é‡è¯¯å·®ä¸º0.116æ¯«ç±³ã€‚æ­¤å¤–ï¼ŒSSåœ°æ ‡ç»†åŒ–å¯ä»¥å¹³å‡å‡å°‘ä½¿ç”¨HRNetæ—¶çš„åœ°æ ‡ä½ç½®å¹³å‡ç»å¯¹è¯¯å·®0.010æ¯«ç±³ï¼Œä½¿ç”¨ViTPoseæ—¶å‡å°‘0.103æ¯«ç±³ã€‚è¿™äº›ç»“æœçªæ˜¾äº†é€šè¿‡å‡†ç¡®æµ‹é‡å…³èŠ‚é—´éš™è¿›è¡ŒUCLæŸä¼¤é«˜ç²¾åº¦å®æ—¶è¯Šæ–­çš„æ½œåŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨æ£€æµ‹åˆ°çš„åœ°æ ‡ä½œä¸ºè¾“å…¥å±•ç¤ºäº†åŸºäºç‚¹çš„è‚¡éª¨å’Œå°ºéª¨åˆ†å‰²ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Akahori000/Ultrasound-Medial-Elbow-Dataset%E4%B8%8A%E5%85%AC%E5%BC%80%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/Akahori000/Ultrasound-Medial-Elbow-Datasetä¸Šå…¬å¼€æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13010v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¶…å£°æˆåƒæŠ€æœ¯åœ¨è¯Šæ–­å°ºä¾§å‰¯éŸ§å¸¦ï¼ˆUCLï¼‰æŸä¼¤ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡æµ‹é‡è‚˜å…³èŠ‚é—´éš™æ¥è¿›è¡Œè¯„ä¼°ã€‚ç”±äºç¼ºä¹å…¬å¼€æ•°æ®é›†ï¼Œæœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªæ–°çš„è¶…å£°è‚˜å…³èŠ‚æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨å¤šç§æ–¹æ³•å¯¹å…³èŠ‚é—´éš™è¿›è¡Œæµ‹é‡ã€‚ä¸ºæé«˜æµ‹é‡ç²¾åº¦ï¼Œæå‡ºäº†ä¸€ç§åä¸ºShape Subspaceï¼ˆSSï¼‰çš„æ ‡å¿—æ€§åœ°ç‚¹ä¼˜åŒ–æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¿˜å±•ç¤ºäº†åŸºäºæ£€æµ‹åˆ°çš„æ ‡å¿—æ€§åœ°ç‚¹çš„ç‚¹åˆ†å‰²æ–¹æ³•ã€‚æœ¬æ–‡çš„æˆæœå°†ä¸ºå®æ—¶ã€é«˜ç²¾åº¦è¯Šæ–­UCLæŸä¼¤æä¾›æ½œåŠ›ã€‚æ•°æ®é›†å°†åœ¨å…¬å¼€å¹³å°ä¸Šå‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å£°æˆåƒå¯¹äºæ—©æœŸè¯Šæ–­UCLæŸä¼¤è‡³å…³é‡è¦ï¼Œé€šè¿‡æµ‹é‡è‚˜å…³èŠ‚é—´éš™è¯„ä¼°å…¶ç¨³å®šæ€§ã€‚</li>
<li>ç›®å‰ç¼ºä¹å…¬å¼€å¯ç”¨çš„è¶…å£°è‚˜å…³èŠ‚æ•°æ®é›†æ¥è¿›è¡Œè‡ªåŠ¨åŒ–æµ‹é‡ã€‚</li>
<li>æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªæ–°çš„è¶…å£°è‚˜å…³èŠ‚æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ª22åå—è¯•è€…çš„4,201å¼ è¶…å£°å›¾åƒï¼Œå…·æœ‰åŸºäºä¸‰ä½éª¨ç§‘ä¸“å®¶ç»éªŒçš„æ ‡å¿—æ€§åœ°ç‚¹æ ‡æ³¨ã€‚</li>
<li>é‡‡ç”¨äº†å¤šç§æ–¹æ³•è¿›è¡Œå…³èŠ‚é—´éš™æµ‹é‡ï¼ŒåŒ…æ‹¬åŸºäºçƒ­å›¾ã€å›å½’å’Œæ ‡è®°çš„æ–¹æ³•ã€‚</li>
<li>Shape Subspaceï¼ˆSSï¼‰æ ‡å¿—æ€§åœ°ç‚¹ä¼˜åŒ–æ–¹æ³•è¢«æå‡ºä»¥æé«˜æµ‹é‡ç²¾åº¦ã€‚</li>
<li>ä½¿ç”¨HRNetæ—¶ï¼ŒSSæ ‡å¿—æ€§åœ°ç‚¹ä¼˜åŒ–å¯ä»¥å‡å°‘å¹³å‡ç»å¯¹è¯¯å·®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13010">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2412.13010v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2412.13010v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2412.13010v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CheXalign-Preference-fine-tuning-in-chest-X-ray-interpretation-models-without-human-feedback"><a href="#CheXalign-Preference-fine-tuning-in-chest-X-ray-interpretation-models-without-human-feedback" class="headerlink" title="CheXalign: Preference fine-tuning in chest X-ray interpretation models   without human feedback"></a>CheXalign: Preference fine-tuning in chest X-ray interpretation models   without human feedback</h2><p><strong>Authors:Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, Eduardo Pontes Reis, Arne Edward Michalson, Christian Bluethgen, Hyun Joo Shin, Curtis Langlotz, Akshay S Chaudhari</strong></p>
<p>Radiologists play a crucial role in translating medical images into actionable reports. However, the field faces staffing shortages and increasing workloads. While automated approaches using vision-language models (VLMs) show promise as assistants, they require exceptionally high accuracy. Most current VLMs in radiology rely solely on supervised fine-tuning. Meanwhile, additional preference fine-tuning in the post-training pipeline has become standard practice in the general domain. The challenge in radiology lies in the prohibitive cost of obtaining radiologist feedback at scale. To address this challenge, we propose an automated pipeline for preference feedback, focusing on chest X-ray radiology report generation (RRG). Specifically, our method leverages publicly available datasets containing pairs of images and radiologist-written reference reports with reference-based metrics, or Judges, eliminating the need for additional radiologist feedback. We investigate reward overoptimization via length exploitation in this setting and introduce a length-controlled version of the GREEN score. Our best-performing setup achieves state-of-the-art CheXbert scores on the MIMIC-CXR dataset for the RRG task while on average maintaining robust performance across six additional image perception and reasoning tasks. </p>
<blockquote>
<p>æ”¾å°„ç§‘åŒ»ç”Ÿåœ¨å°†åŒ»å­¦å›¾åƒè½¬åŒ–ä¸ºå¯æ“ä½œçš„æŠ¥å‘Šæ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œè¯¥é¢†åŸŸé¢ä¸´ç€äººå‘˜çŸ­ç¼ºå’Œå·¥ä½œé‡ä¸æ–­å¢åŠ çš„é—®é¢˜ã€‚è™½ç„¶ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æ–¹æ³•ä½œä¸ºåŠ©ç†æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬éœ€è¦æé«˜çš„å‡†ç¡®æ€§ã€‚å½“å‰å¤§å¤šæ•°æ”¾å°„ç§‘çš„è§†è§‰è¯­è¨€æ¨¡å‹ä»…ä¾èµ–äºç›‘ç£å¾®è°ƒã€‚ä¸æ­¤åŒæ—¶ï¼Œåœ¨è®­ç»ƒåçš„ç®¡é“ä¸­è¿›è¡Œé¢å¤–çš„åå¥½å¾®è°ƒå·²æˆä¸ºé€šç”¨é¢†åŸŸçš„æ ‡å‡†å®è·µã€‚æ”¾å°„å­¦é¢†åŸŸçš„æŒ‘æˆ˜åœ¨äºå¤§è§„æ¨¡è·å–æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆçš„ä»£ä»·é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–ç®¡é“æ¥è¿›è¡Œåå¥½åé¦ˆï¼Œä¸“æ³¨äºèƒ¸éƒ¨Xå°„çº¿æ”¾å°„æŠ¥å‘Šç”Ÿæˆï¼ˆRRGï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å›¾åƒå’Œæ”¾å°„ç§‘åŒ»ç”Ÿæ’°å†™çš„å‚è€ƒæŠ¥å‘Šå¯¹ï¼Œå¹¶ä½¿ç”¨åŸºäºå‚è€ƒçš„åº¦é‡æ ‡å‡†æˆ–åˆ¤æ–­ä¾æ®ï¼Œæ— éœ€é¢å¤–çš„æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆã€‚æˆ‘ä»¬ç ”ç©¶äº†è¯¥ç¯å¢ƒä¸‹çš„é•¿åº¦åˆ©ç”¨æ‰€å¯¼è‡´çš„å¥–åŠ±ä¼˜åŒ–è¿‡åº¦é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†å—æ§é•¿åº¦çš„GREENè¯„åˆ†ç‰ˆæœ¬ã€‚æˆ‘ä»¬åœ¨MIMIC-CXRæ•°æ®é›†ä¸Šçš„æ”¾å°„æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„CheXbertåˆ†æ•°ï¼ŒåŒæ—¶åœ¨å…¶ä»–å…­ä¸ªå›¾åƒæ„ŸçŸ¥å’Œæ¨ç†ä»»åŠ¡ä¸Šä¿æŒäº†ç¨³å¥çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07025v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ”¾å°„ç§‘åŒ»ç”Ÿåœ¨å°†åŒ»å­¦å›¾åƒè½¬åŒ–ä¸ºå¯æ“ä½œæŠ¥å‘Šæ–¹é¢çš„é‡è¦ä½œç”¨ï¼ŒåŒæ—¶æŒ‡å‡ºè¯¥é¢†åŸŸé¢ä¸´äººå‘˜çŸ­ç¼ºå’Œå·¥ä½œé‡å¢åŠ çš„é—®é¢˜ã€‚è™½ç„¶ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æ–¹æ³•æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬éœ€è¦æé«˜çš„å‡†ç¡®æ€§ã€‚å¤§å¤šæ•°å½“å‰çš„åŒ»å­¦å½±åƒå­¦VLMsä»…ä¾èµ–äºç›‘ç£å¾®è°ƒã€‚åœ¨é€šç”¨é¢†åŸŸï¼Œåœ¨è®­ç»ƒåç®¡é“ä¸­åŠ å…¥åå¥½å¾®è°ƒå·²æˆä¸ºæ ‡å‡†åšæ³•ã€‚æ”¾å°„å­¦é¢ä¸´çš„æŒ‘æˆ˜åœ¨äºå¤§è§„æ¨¡è·å–æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆçš„ä»£ä»·é«˜æ˜‚ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–åå¥½åé¦ˆç®¡é“ï¼Œä¸“æ³¨äºèƒ¸éƒ¨Xå°„çº¿æ”¾å°„æŠ¥å‘Šç”Ÿæˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŒ…å«å›¾åƒå’Œæ”¾å°„ç§‘åŒ»ç”Ÿæ’°å†™çš„å‚è€ƒæŠ¥å‘Šçš„å…¬å¼€æ•°æ®é›†ä»¥åŠåŸºäºå‚è€ƒçš„åº¦é‡æ ‡å‡†ï¼Œæ— éœ€é¢å¤–çš„æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆã€‚æœ¬æ–‡è¿˜ç ”ç©¶äº†é•¿åº¦åˆ©ç”¨å¯¼è‡´çš„å¥–åŠ±è¿‡åº¦ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†å—æ§é•¿åº¦çš„GREENè¯„åˆ†ç‰ˆæœ¬ã€‚æœ€ä½³è®¾ç½®åœ¨MIMIC-CXRæ•°æ®é›†ä¸Šçš„RRGä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„CheXbertåˆ†æ•°ï¼ŒåŒæ—¶åœ¨å¦å¤–å…­ä¸ªå›¾åƒæ„ŸçŸ¥å’Œæ¨ç†ä»»åŠ¡ä¸Šä¿æŒç¨³å¥æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ”¾å°„ç§‘åŒ»ç”Ÿåœ¨å°†åŒ»å­¦å›¾åƒè½¬åŒ–ä¸ºæŠ¥å‘Šæ–¹é¢èµ·å…³é”®ä½œç”¨ï¼Œä½†é¢ä¸´äººå‘˜çŸ­ç¼ºå’Œå·¥ä½œé‡å¤§çš„æŒ‘æˆ˜ã€‚</li>
<li>è‡ªåŠ¨åŒ–æ–¹æ³•ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä½œä¸ºæ”¾å°„ç§‘çš„è¾…åŠ©å·¥å…·ï¼Œä½†é«˜å‡†ç¡®æ€§è¦æ±‚æˆä¸ºå…¶åº”ç”¨çš„ä¸€å¤§æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰å¤§å¤šæ•°åŒ»å­¦å½±åƒå­¦VLMsä»…é‡‡ç”¨ç›‘ç£å¾®è°ƒæ–¹æ³•ã€‚</li>
<li>åœ¨é€šç”¨é¢†åŸŸï¼Œæ·»åŠ åå¥½å¾®è°ƒå·²æˆä¸ºè®­ç»ƒåç®¡é“çš„æ ‡å‡†åšæ³•ï¼Œä½†åœ¨æ”¾å°„å­¦ä¸­é¢ä¸´æˆæœ¬é«˜æ˜‚çš„æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§è‡ªåŠ¨åŒ–ç®¡é“ç”¨äºåå¥½åé¦ˆï¼Œä¸“æ³¨äºèƒ¸éƒ¨Xå°„çº¿æ”¾å°„æŠ¥å‘Šç”Ÿæˆï¼Œåˆ©ç”¨å…¬å¼€æ•°æ®é›†å’ŒåŸºäºå‚è€ƒçš„åº¦é‡æ ‡å‡†ï¼Œæ— éœ€é¢å¤–æ”¾å°„ç§‘åŒ»ç”Ÿåé¦ˆã€‚</li>
<li>ç ”ç©¶äº†å› é•¿åº¦åˆ©ç”¨å¯¼è‡´çš„å¥–åŠ±è¿‡åº¦ä¼˜åŒ–é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07025">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2410.07025v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2410.07025v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2410.07025v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2410.07025v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2410.07025v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Personalized-Topology-Informed-Localization-of-Standard-12-Lead-ECG-Electrode-Placement-from-Incomplete-Cardiac-MRIs-for-Efficient-Cardiac-Digital-Twins"><a href="#Personalized-Topology-Informed-Localization-of-Standard-12-Lead-ECG-Electrode-Placement-from-Incomplete-Cardiac-MRIs-for-Efficient-Cardiac-Digital-Twins" class="headerlink" title="Personalized Topology-Informed Localization of Standard 12-Lead ECG   Electrode Placement from Incomplete Cardiac MRIs for Efficient Cardiac   Digital Twins"></a>Personalized Topology-Informed Localization of Standard 12-Lead ECG   Electrode Placement from Incomplete Cardiac MRIs for Efficient Cardiac   Digital Twins</h2><p><strong>Authors:Lei Li, Hannah Smith, Yilin Lyu, Julia Camps, Shuang Qian, Blanca Rodriguez, Abhirup Banerjee, Vicente Grau</strong></p>
<p>Cardiac digital twins (CDTs) offer personalized in-silico cardiac representations for the inference of multi-scale properties tied to cardiac mechanisms. The creation of CDTs requires precise information about the electrode position on the torso, especially for the personalized electrocardiogram (ECG) calibration. However, current studies commonly rely on additional acquisition of torso imaging and manual&#x2F;semi-automatic methods for ECG electrode localization. In this study, we propose a novel and efficient topology-informed model to fully automatically extract personalized ECG standard electrode locations from 2D clinically standard cardiac MRIs. Specifically, we obtain the sparse torso contours from the cardiac MRIs and then localize the standard electrodes of 12-lead ECG from the contours. Cardiac MRIs aim at imaging of the heart instead of the torso, leading to incomplete torso geometry within the imaging. To tackle the missing topology, we incorporate the electrodes as a subset of the keypoints, which can be explicitly aligned with the 3D torso topology. The experimental results demonstrate that the proposed model outperforms the time-consuming conventional model projection-based method in terms of accuracy (Euclidean distance: $1.24 \pm 0.293$ cm vs. $1.48 \pm 0.362$ cm) and efficiency ($2$<del>s vs. $30$-$35$</del>min). We further demonstrate the effectiveness of using the detected electrodes for in-silico ECG simulation, highlighting their potential for creating accurate and efficient CDT models. The code is available at <a target="_blank" rel="noopener" href="https://github.com/lileitech/12lead_ECG_electrode_localizer">https://github.com/lileitech/12lead_ECG_electrode_localizer</a>. </p>
<blockquote>
<p>å¿ƒè„æ•°å­—åŒèƒèƒï¼ˆCDTsï¼‰ä¸ºæ¨æ–­ä¸å¿ƒè„æœºåˆ¶ç›¸å…³çš„å¤šå°ºåº¦å±æ€§æä¾›äº†ä¸ªæ€§åŒ–çš„ç¡…åŸºå¿ƒè„è¡¨å¾ã€‚CDTçš„åˆ›å»ºéœ€è¦å…³äºèº¯å¹²ä¸Šç”µæä½ç½®çš„ç²¾ç¡®ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å¯¹äºä¸ªæ€§åŒ–å¿ƒç”µå›¾ï¼ˆECGï¼‰æ ¡å‡†ã€‚ç„¶è€Œï¼Œå½“å‰çš„ç ”ç©¶é€šå¸¸ä¾èµ–äºé¢å¤–çš„èº¯å¹²æˆåƒä»¥åŠæ‰‹åŠ¨æˆ–åŠè‡ªåŠ¨çš„ECGç”µæå®šä½æ–¹æ³•ã€‚åœ¨æœ¬æ¡ˆä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹é«˜æ•ˆæ‹“æ‰‘ä¿¡æ¯æ¨¡å‹ï¼Œèƒ½å¤Ÿå…¨è‡ªåŠ¨åœ°ä»ä¸´åºŠæ ‡å‡†çš„2Då¿ƒè„MRIä¸­æå–ä¸ªæ€§åŒ–ECGæ ‡å‡†ç”µæä½ç½®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»å¿ƒè„MRIä¸­è·å–ç¨€ç–çš„èº¯å¹²è½®å»“ï¼Œç„¶åå®šä½12å¯¼è”å¿ƒç”µå›¾çš„æ ‡å‡†ç”µæã€‚å¿ƒè„MRIæ—¨åœ¨æˆåƒå¿ƒè„è€Œéèº¯å¹²ï¼Œå¯¼è‡´æˆåƒä¸­èº¯å¹²å‡ ä½•ç»“æ„ä¸å®Œæ•´ã€‚ä¸ºäº†è§£å†³ç¼ºå¤±çš„æ‹“æ‰‘ç»“æ„é—®é¢˜ï¼Œæˆ‘ä»¬å°†ç”µæä½œä¸ºå…³é”®ç‚¹çš„ä¸€ä¸ªå­é›†ï¼Œå¯ä»¥æ˜ç¡®åœ°ä¸3Dèº¯å¹²æ‹“æ‰‘ç»“æ„å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸è€—æ—¶è¾ƒé•¿çš„ä¼ ç»Ÿæ¨¡å‹æŠ•å½±æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼š1.24Â±0.293å˜ç±³ vs 1.48Â±0.362å˜ç±³ï¼‰å’Œæ•ˆç‡ï¼ˆ2ç§’ vs 30-35åˆ†é’Ÿï¼‰ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥éªŒè¯äº†ä½¿ç”¨æ£€æµ‹åˆ°çš„ç”µæè¿›è¡Œç¡…åŸºå¿ƒç”µå›¾æ¨¡æ‹Ÿçš„æœ‰æ•ˆæ€§ï¼Œè¿™çªæ˜¾äº†å®ƒä»¬åˆ›å»ºå‡†ç¡®é«˜æ•ˆCDTæ¨¡å‹çš„æ½œåŠ›ã€‚ç›¸å…³ä»£ç å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/lileitech/12lead_ECG_electrode_localizer%E3%80%82">https://github.com/lileitech/12lead_ECG_electrode_localizerã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.13945v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬ç ”ç©¶æå‡ºä¸€ç§ç»“åˆæ‹“æ‰‘ä¿¡æ¯çš„æ–°æ¨¡å‹ï¼Œå¯ä»ä¸´åºŠæ ‡å‡†çš„äºŒç»´å¿ƒè„MRIå›¾åƒå…¨è‡ªåŠ¨æå–ä¸ªæ€§åŒ–çš„å¿ƒç”µå›¾æ ‡å‡†ç”µæä½ç½®ã€‚é€šè¿‡ä»å¿ƒè„MRIå›¾åƒä¸­è·å–ç¨€ç–çš„èº¯å¹²è½®å»“ï¼Œç„¶åå®šä½å¿ƒç”µå›¾çš„12å¯¼è”ç”µæä½ç½®ã€‚ç”±äºå¿ƒè„MRIä¸»è¦å…³æ³¨å¿ƒè„æˆåƒè€Œéèº¯å¹²ï¼Œå¯¼è‡´æˆåƒä¸­èº¯å¹²å‡ ä½•ç»“æ„ä¸å®Œæ•´ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å°†ç”µæä½œä¸ºå…³é”®ç‚¹çš„å­é›†ï¼Œå¯ä¸ä¸‰ç»´èº¯å¹²æ‹“æ‰‘æ˜ç¡®å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºåŸºäºæ¨¡å‹æŠ•å½±çš„ä¼ ç»Ÿè€—æ—¶æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å±•ç¤ºäº†ä½¿ç”¨æ£€æµ‹åˆ°çš„ç”µæè¿›è¡Œè™šæ‹Ÿå¿ƒç”µå›¾æ¨¡æ‹Ÿçš„æœ‰æ•ˆæ€§ï¼Œçªæ˜¾å…¶åœ¨åˆ›å»ºå‡†ç¡®é«˜æ•ˆçš„Cardiacæ•°å­—åŒèƒèƒæ¨¡å‹æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>Cardiacæ•°å­—åŒèƒèƒï¼ˆCDTsï¼‰èƒ½å¤ŸåŸºäºå¤šå°ºåº¦å±æ€§å¯¹å¿ƒè„æœºåˆ¶è¿›è¡Œæ¨ç†ï¼Œåˆ›å»ºä¸ªæ€§åŒ–çš„è™šæ‹Ÿå¿ƒè„è¡¨ç¤ºã€‚</li>
<li>å½“å‰ç ”ç©¶åœ¨å¿ƒç”µå›¾ç”µæå®šä½ä¸Šä¾èµ–é¢å¤–çš„èº¯å¹²æˆåƒå’Œæ‰‹åŠ¨&#x2F;åŠè‡ªåŠ¨æ–¹æ³•ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ‹“æ‰‘ä¿¡æ¯æ¨¡å‹ï¼Œèƒ½å…¨è‡ªåŠ¨ä»ä¸´åºŠæ ‡å‡†çš„äºŒç»´å¿ƒè„MRIå›¾åƒæå–ä¸ªæ€§åŒ–å¿ƒç”µå›¾æ ‡å‡†ç”µæä½ç½®ã€‚</li>
<li>é€šè¿‡ç»“åˆç¨€ç–çš„èº¯å¹²è½®å»“å’Œ12å¯¼è”å¿ƒç”µå›¾ç”µæçš„å®šä½ï¼Œè§£å†³å› å¿ƒè„MRIä¸»è¦å…³æ³¨å¿ƒè„æˆåƒå¯¼è‡´çš„èº¯å¹²å‡ ä½•ç»“æ„ä¸å®Œæ•´é—®é¢˜ã€‚</li>
<li>æ–°æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šä¼˜äºä¼ ç»Ÿçš„æ¨¡å‹æŠ•å½±æ–¹æ³•ã€‚</li>
<li>æ£€æµ‹åˆ°çš„å¿ƒç”µå›¾ç”µæç”¨äºæœ‰æ•ˆçš„è™šæ‹Ÿå¿ƒç”µå›¾æ¨¡æ‹Ÿï¼Œçªæ˜¾å…¶åœ¨åˆ›å»ºCardicæ•°å­—åŒèƒèƒæ¨¡å‹æ–¹é¢çš„æ½œåŠ›ã€‚</li>
<li>ç›¸å…³ä»£ç å·²å…¬å¼€ï¼Œå¯ä¾›è¿›ä¸€æ­¥ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.13945">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2408.13945v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Argus-Benchmarking-and-Enhancing-Vision-Language-Models-for-3D-Radiology-Report-Generation"><a href="#Argus-Benchmarking-and-Enhancing-Vision-Language-Models-for-3D-Radiology-Report-Generation" class="headerlink" title="Argus: Benchmarking and Enhancing Vision-Language Models for 3D   Radiology Report Generation"></a>Argus: Benchmarking and Enhancing Vision-Language Models for 3D   Radiology Report Generation</h2><p><strong>Authors:Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci</strong></p>
<p>Automatic radiology report generation holds significant potential to streamline the labor-intensive process of report writing by radiologists, particularly for 3D radiographs such as CT scans. While CT scans are critical for clinical diagnostics, they remain less explored compared to 2D radiographs. To date, there has been no comprehensive benchmark for 3D radiograph report generation (3DRRG), nor sufficient investigation into the optimal training strategies for Vision Language Models (VLMs) in this context, particularly with respect to vision encoder choices, visual token compression, and model scaling. In this work, we make three key contributions. We curate <strong>CT-3DRRG</strong>, the largest <strong>publicly</strong> available 3D CT-report dataset, establishing a robust and diverse benchmark for evaluating VLM performance on 3DRRG. Furthermore, we propose a comprehensive training recipe for building high-performing VLMs for 3DRRG, exploring key factors such as vision encoder pretraining strategies, visual token compression, and the impact of data &amp; model scale. Guided by these findings, we introduce <strong>Argus</strong>, a state-of-the-art family of VLMs that achieve superior performance across different model sizes and input 3D medical image resolutions, efficiently processing high-resolution 3D images up to $512 \times 512 \times 256$[^1]. </p>
<blockquote>
<p>è‡ªåŠ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆåœ¨ç®€åŒ–æ”¾å°„ç§‘åŒ»ç”ŸæŠ¥å‘Šå†™ä½œè¿™ä¸€åŠ³åŠ¨å¯†é›†å‹æµç¨‹æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹ä¸‰ç»´å°„å½±åƒï¼ˆå¦‚CTæ‰«æï¼‰ä¸Šå°¤ä¸ºå¦‚æ­¤ã€‚è™½ç„¶CTæ‰«æåœ¨ä¸´åºŠè¯Šæ–­ä¸­è‡³å…³é‡è¦ï¼Œä½†ä¸äºŒç»´æ”¾å°„å½±åƒç›¸æ¯”ï¼Œå®ƒä»¬çš„ç ”ç©¶ä»ç„¶è¾ƒå°‘ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œå°šæ— é’ˆå¯¹ä¸‰ç»´æ”¾å°„å½±åƒæŠ¥å‘Šç”Ÿæˆï¼ˆ3DRRGï¼‰çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œå¯¹äºè¯¥èƒŒæ™¯ä¸‹çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æœ€ä½³è®­ç»ƒç­–ç•¥çš„ç ”ç©¶ä¹Ÿè¿˜ä¸å¤Ÿå……åˆ†ï¼Œå°¤å…¶æ˜¯åœ¨è§†è§‰ç¼–ç å™¨é€‰æ‹©ã€è§†è§‰ä»¤ç‰Œå‹ç¼©å’Œæ¨¡å‹ç¼©æ”¾æ–¹é¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åšå‡ºäº†ä¸‰é¡¹å…³é”®è´¡çŒ®ã€‚æˆ‘ä»¬æ•´ç†æ¨å‡ºäº†æœ€å¤§çš„å…¬å¼€å¯ç”¨ä¸‰ç»´CTæŠ¥å‘Šæ•°æ®é›†CT-3DRRGï¼Œä¸ºè¯„ä¼°VLMåœ¨3DRRGä¸Šçš„æ€§èƒ½å»ºç«‹äº†ç¨³å¥ä¸”å¤šæ ·åŒ–çš„åŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸ºæ„å»ºé«˜æ€§èƒ½çš„ç”¨äº3DRRGçš„VLMæå‡ºäº†ä¸€ç§å…¨é¢çš„è®­ç»ƒæ–¹æ¡ˆï¼Œæ¢è®¨äº†è§†è§‰ç¼–ç å™¨é¢„è®­ç»ƒç­–ç•¥ã€è§†è§‰ä»¤ç‰Œå‹ç¼©ä»¥åŠæ•°æ®å’Œæ¨¡å‹è§„æ¨¡çš„å½±å“ç­‰å…³é”®å› ç´ ã€‚æ ¹æ®è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æ¨å‡ºäº†æœ€å…ˆè¿›çš„VLMå®¶æ—äº§å“Argusï¼Œåœ¨ä¸åŒæ¨¡å‹å°ºå¯¸å’Œè¾“å…¥çš„ä¸‰ç»´åŒ»å­¦å½±åƒåˆ†è¾¨ç‡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†é«˜è¾¾512Ã—512Ã—256åˆ†è¾¨ç‡çš„ä¸‰ç»´é«˜è§£æåº¦å›¾åƒ[^1]ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.07146v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è‡ªåŠ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆåœ¨ç®€åŒ–æ”¾å°„ç§‘åŒ»ç”ŸæŠ¥å‘Šå†™ä½œæµç¨‹æ–¹é¢çš„æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸‰ç»´æ”¾å°„å½±åƒï¼ˆå¦‚CTæ‰«æï¼‰æ–¹é¢ã€‚æ–‡ç« æå‡ºäº†CT-3DRRGæ•°æ®é›†ï¼Œä¸ºè¯„ä¼°VLMåœ¨ä¸‰ç»´æ”¾å°„å½±åƒæŠ¥å‘Šç”Ÿæˆä¸­çš„æ€§èƒ½æä¾›äº†ç¨³å¥ä¸”å¤šæ ·åŒ–çš„åŸºå‡†ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜æå‡ºäº†ä¸€ç§æ„å»ºé«˜æ€§èƒ½VLMçš„ç»¼åˆè®­ç»ƒç­–ç•¥ï¼Œå¹¶ä»‹ç»äº†Argusç³»åˆ—æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨ä¸åŒæ¨¡å‹å°ºå¯¸å’Œè¾“å…¥çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†è¾¨ç‡ä¸Šå®ç°å“è¶Šæ€§èƒ½ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†é«˜è¾¾$512 \times 512 \times 256$çš„é«˜åˆ†è¾¨ç‡ä¸‰ç»´å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆå…·æœ‰ç®€åŒ–æ”¾å°„ç§‘åŒ»ç”ŸæŠ¥å‘Šå†™ä½œæµç¨‹çš„æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸‰ç»´æ”¾å°„å½±åƒå¦‚CTæ‰«ææ–¹é¢ã€‚</li>
<li>æå‡ºäº†CT-3DRRGæ•°æ®é›†ï¼Œä¸ºè¯„ä¼°VLMåœ¨ä¸‰ç»´æ”¾å°„å½±åƒæŠ¥å‘Šç”Ÿæˆä¸­çš„æ€§èƒ½æä¾›äº†åŸºå‡†ã€‚</li>
<li>æ¢è®¨äº†æ„å»ºé«˜æ€§èƒ½VLMçš„ç»¼åˆè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬è§†è§‰ç¼–ç å™¨é¢„è®­ç»ƒç­–ç•¥ã€è§†è§‰ç¬¦å·å‹ç¼©å’Œæ•°æ®ä¸æ¨¡å‹è§„æ¨¡çš„å½±å“ã€‚</li>
<li>ä»‹ç»äº†Argusç³»åˆ—æ¨¡å‹ï¼Œå®ç°äº†åœ¨ä¸åŒæ¨¡å‹å°ºå¯¸å’Œè¾“å…¥çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†è¾¨ç‡ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚</li>
<li>Argusæ¨¡å‹èƒ½å¤Ÿé«˜æ•ˆå¤„ç†é«˜è‡³$512 \times 512 \times 256$åˆ†è¾¨ç‡çš„ä¸‰ç»´å›¾åƒã€‚</li>
<li>æ–‡ç« å¡«è¡¥äº†å…³äºä¸‰ç»´æ”¾å°„å½±åƒæŠ¥å‘Šç”Ÿæˆçš„åŸºå‡†å’ŒVLMè®­ç»ƒç­–ç•¥ç ”ç©¶çš„ç©ºç™½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.07146">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2406.07146v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Exploring-Quasi-Global-Solutions-to-Compound-Lens-Based-Computational-Imaging-Systems"><a href="#Exploring-Quasi-Global-Solutions-to-Compound-Lens-Based-Computational-Imaging-Systems" class="headerlink" title="Exploring Quasi-Global Solutions to Compound Lens Based Computational   Imaging Systems"></a>Exploring Quasi-Global Solutions to Compound Lens Based Computational   Imaging Systems</h2><p><strong>Authors:Yao Gao, Qi Jiang, Shaohua Gao, Lei Sun, Kailun Yang, Kaiwei Wang</strong></p>
<p>Recently, joint design approaches that simultaneously optimize optical systems and downstream algorithms through data-driven learning have demonstrated superior performance over traditional separate design approaches. However, current joint design approaches heavily rely on the manual identification of initial lenses, posing challenges and limitations, particularly for compound lens systems with multiple potential starting points. In this work, we present Quasi-Global Search Optics (QGSO) to automatically design compound lens based computational imaging systems through two parts: (i) Fused Optimization Method for Automatic Optical Design (OptiFusion), which searches for diverse initial optical systems under certain design specifications; and (ii) Efficient Physic-aware Joint Optimization (EPJO), which conducts parallel joint optimization of initial optical systems and image reconstruction networks with the consideration of physical constraints, culminating in the selection of the optimal solution in all search results. Extensive experimental results illustrate that QGSO serves as a transformative end-to-end lens design paradigm for superior global search ability, which automatically provides compound lens based computational imaging systems with higher imaging quality compared to existing paradigms. The source code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/LiGpy/QGSO">https://github.com/LiGpy/QGSO</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œé€šè¿‡æ•°æ®é©±åŠ¨å­¦ä¹ åŒæ—¶ä¼˜åŒ–å…‰å­¦ç³»ç»Ÿå’Œä¸‹æ¸¸ç®—æ³•çš„è”åˆè®¾è®¡æ–¹æ³•ï¼Œå·²æ˜¾ç¤ºå‡ºå…¶ç›¸è¾ƒäºä¼ ç»Ÿåˆ†ç¦»è®¾è®¡æ–¹æ³•çš„å“è¶Šæ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“å‰çš„è”åˆè®¾è®¡æ–¹æ³•ä¸¥é‡ä¾èµ–äºåˆå§‹é•œå¤´çš„æ‰‹åŠ¨è¯†åˆ«ï¼Œè¿™å¸¦æ¥äº†æŒ‘æˆ˜å’Œå±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå…·æœ‰å¤šä¸ªæ½œåœ¨èµ·å§‹ç‚¹çš„å¤åˆé•œå¤´ç³»ç»Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å‡†å…¨å±€æœç´¢å…‰å­¦ï¼ˆQGSOï¼‰æ–¹æ³•ï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†è‡ªåŠ¨è®¾è®¡åŸºäºå¤åˆé•œå¤´çš„è®¡ç®—æˆåƒç³»ç»Ÿï¼šï¼ˆiï¼‰è‡ªåŠ¨å…‰å­¦è®¾è®¡çš„èåˆä¼˜åŒ–æ–¹æ³•ï¼ˆOptiFusionï¼‰ï¼Œå®ƒä¼šåœ¨ç‰¹å®šçš„è®¾è®¡è§„æ ¼ä¸‹æœç´¢å¤šæ ·åŒ–çš„åˆå§‹å…‰å­¦ç³»ç»Ÿï¼›ï¼ˆiiï¼‰é«˜æ•ˆçš„ç‰©ç†æ„ŸçŸ¥è”åˆä¼˜åŒ–ï¼ˆEPJOï¼‰ï¼Œå®ƒåœ¨è€ƒè™‘ç‰©ç†çº¦æŸçš„åŒæ—¶ï¼Œå¯¹åˆå§‹å…‰å­¦ç³»ç»Ÿå’Œå›¾åƒé‡å»ºç½‘ç»œè¿›è¡Œå¹¶è¡Œè”åˆä¼˜åŒ–ï¼Œæœ€ç»ˆä»æ‰€æœ‰æœç´¢ç»“æœä¸­é€‰æ‹©æœ€ä½³è§£å†³æ–¹æ¡ˆã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜ï¼ŒQGSOä½œä¸ºä¸€ç§å˜é©æ€§çš„ç«¯åˆ°ç«¯é•œå¤´è®¾è®¡èŒƒå¼ï¼Œå…·æœ‰å“è¶Šçš„å…¨å±€æœç´¢èƒ½åŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ä¸ºåŸºäºå¤åˆé•œå¤´çš„è®¡ç®—æˆåƒç³»ç»Ÿæä¾›æ›´é«˜çš„æˆåƒè´¨é‡ï¼Œç›¸è¾ƒäºç°æœ‰çš„æ–¹æ³•æœ‰ç€æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/LiGpy/QGSO%E4%B8%8A%E5%BC%BA%E5%85%AC%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/LiGpy/QGSOä¸Šå…¬å¼€æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.19201v2">PDF</a> Accepted to IEEE Transactions on Computational Imaging (TCI). The   source code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/LiGpy/QGSO">https://github.com/LiGpy/QGSO</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºQuasi-Global Search Opticsï¼ˆQGSOï¼‰çš„è”åˆè®¾è®¡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯è‡ªåŠ¨è®¾è®¡å¤åˆé€é•œè®¡ç®—æˆåƒç³»ç»Ÿï¼Œé€šè¿‡æœç´¢å¤šç§åˆå§‹å…‰å­¦ç³»ç»Ÿå¹¶è¿›è¡Œä¼˜åŒ–ï¼Œå®ç°å…¨å±€æœ€ä¼˜è§£ï¼Œä»è€Œæé«˜æˆåƒè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰è”åˆè®¾è®¡æ–¹æ³•é€šè¿‡æ•°æ®é©±åŠ¨å­¦ä¹ åŒæ—¶ä¼˜åŒ–å…‰å­¦ç³»ç»Ÿå’Œä¸‹æ¸¸ç®—æ³•ï¼Œè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>ä¼ ç»Ÿå•ç‹¬è®¾è®¡æ–¹æ³•å­˜åœ¨æŒ‘æˆ˜å’Œå±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤šä¸ªæ½œåœ¨èµ·ç‚¹çš„å¤åˆé€é•œç³»ç»Ÿä¸­ã€‚</li>
<li>QGSOé€šè¿‡ä¸¤éƒ¨åˆ†å®ç°è‡ªåŠ¨è®¾è®¡å¤åˆé€é•œè®¡ç®—æˆåƒç³»ç»Ÿï¼šFused Optimization Method for Automatic Optical Designï¼ˆOptiFusionï¼‰å’ŒEfficient Physic-aware Joint Optimizationï¼ˆEPJOï¼‰ã€‚</li>
<li>OptiFusionåœ¨ç‰¹å®šè®¾è®¡è§„æ ¼ä¸‹æœç´¢å„ç§åˆå§‹å…‰å­¦ç³»ç»Ÿã€‚</li>
<li>EPJOè€ƒè™‘ç‰©ç†çº¦æŸï¼Œå¯¹åˆå§‹å…‰å­¦ç³»ç»Ÿå’Œå›¾åƒé‡å»ºç½‘ç»œè¿›è¡Œå¹¶è¡Œè”åˆä¼˜åŒ–ï¼Œä»æ‰€æœ‰æœç´¢ç»“æœä¸­é€‰æ‹©æœ€ä½³è§£å†³æ–¹æ¡ˆã€‚</li>
<li>QGSOå…·æœ‰å“è¶Šçš„å…¨å±€æœç´¢èƒ½åŠ›ï¼Œèƒ½è‡ªåŠ¨æä¾›å…·æœ‰è¾ƒé«˜æˆåƒè´¨é‡çš„å¤åˆé€é•œè®¡ç®—æˆåƒç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.19201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2404.19201v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2404.19201v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2404.19201v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="T3D-Advancing-3D-Medical-Vision-Language-Pre-training-by-Learning-Multi-View-Visual-Consistency"><a href="#T3D-Advancing-3D-Medical-Vision-Language-Pre-training-by-Learning-Multi-View-Visual-Consistency" class="headerlink" title="T3D: Advancing 3D Medical Vision-Language Pre-training by Learning   Multi-View Visual Consistency"></a>T3D: Advancing 3D Medical Vision-Language Pre-training by Learning   Multi-View Visual Consistency</h2><p><strong>Authors:Che Liu, Cheng Ouyang, Yinda Chen, Cesar CÃ©sar QuilodrÃ¡n-Casas, Lei Ma, Jie Fu, Yike Guo, Anand Shah, Wenjia Bai, Rossella Arcucci</strong></p>
<p>While 3D visual self-supervised learning (vSSL) shows promising results in capturing visual representations, it overlooks the clinical knowledge from radiology reports. Meanwhile, 3D medical vision-language pre-training (MedVLP) remains underexplored due to the lack of a large-scale, publicly available 3D medical image-report dataset. To bridge this gap, we introduce <strong>CT-3DVLP</strong>, the first and largest <strong>public</strong> 3D volume-report dataset, establishing a comprehensive benchmark for 3D MedVLP research. Meanwhile, we propose the <strong>T3D</strong> framework, which enhances 3D MedVLP beyond naive CLIP-style alignment that directly pairs volumes with reports but neglects local visual representations. Instead, we introduce <strong>Text-informed Multi-view Alignment (TMA)</strong>, a novel approach that clusters volumetric data while enforcing consistency across different views of the same volume-report pair. TMA integrates textual features into fine-grained visual representations, ensuring contextual coherence across views. We evaluate T3D across multiple downstream tasks in both unimodal and cross-modal settings, including zero-shot and fine-tuned classification, cross-modal retrieval, report generation, and semantic segmentation. Our results show that T3D consistently outperforms existing vSSL and multimodal methods, demonstrating superior zero-shot and fine-tuning capabilities and setting a new benchmark for 3D medical image understanding. </p>
<blockquote>
<p>è™½ç„¶ä¸‰ç»´è§†è§‰è‡ªç›‘ç£å­¦ä¹ ï¼ˆvSSLï¼‰åœ¨æ•æ‰è§†è§‰è¡¨ç¤ºæ–¹é¢æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å®ƒå¿½ç•¥äº†æ¥è‡ªæ”¾å°„å­¦æŠ¥å‘Šçš„åŒ»å­¦çŸ¥è¯†ã€‚åŒæ—¶ï¼Œç”±äºç¼ºä¹å¤§è§„æ¨¡ã€å…¬å¼€çš„3DåŒ»å­¦å›¾åƒæŠ¥å‘Šæ•°æ®é›†ï¼Œ3DåŒ»å­¦è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼ˆMedVLPï¼‰ä»è¢«è¾ƒå°‘æ¢ç´¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†<strong>CT-3DVLP</strong>ï¼Œè¿™æ˜¯é¦–ä¸ªæœ€å¤§çš„<strong>å…¬å¼€</strong>3Dä½“ç§¯æŠ¥å‘Šæ•°æ®é›†ï¼Œä¸º3D MedVLPç ”ç©¶å»ºç«‹äº†ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>T3D</strong>æ¡†æ¶ï¼Œå®ƒè¶…è¶Šäº†ç®€å•çš„CLIPé£æ ¼å¯¹é½æ–¹å¼ï¼Œç›´æ¥é…å¯¹ä½“ç§¯ä¸æŠ¥å‘Šï¼Œä½†å¿½ç•¥äº†å±€éƒ¨è§†è§‰è¡¨ç¤ºã€‚ç›¸åï¼Œæˆ‘ä»¬å¼•å…¥äº†<strong>æ–‡æœ¬ä¿¡æ¯å¤šè§†å›¾å¯¹é½ï¼ˆTMAï¼‰</strong>ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œå®ƒèšç±»ä½“ç§¯æ•°æ®ï¼ŒåŒæ—¶å¼ºåˆ¶æ‰§è¡ŒåŒä¸€ä½“ç§¯æŠ¥å‘Šå¯¹çš„ä¸åŒè§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚TMAå°†æ–‡æœ¬ç‰¹å¾é›†æˆåˆ°ç²¾ç»†çš„è§†è§‰è¡¨ç¤ºä¸­ï¼Œç¡®ä¿è·¨è§†å›¾çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚æˆ‘ä»¬åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¯„ä¼°äº†T3Dï¼ŒåŒ…æ‹¬å•æ¨¡æ€å’Œè·¨æ¨¡æ€è®¾ç½®ä¸‹çš„é›¶æ ·æœ¬å’Œå¾®è°ƒåˆ†ç±»ã€è·¨æ¨¡æ€æ£€ç´¢ã€æŠ¥å‘Šç”Ÿæˆå’Œè¯­ä¹‰åˆ†å‰²ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒT3Dåœ¨ç°æœ‰vSSLå’Œå¤šæ¨¡æ€æ–¹æ³•ä¸Šè¡¨ç°æ›´ä¼˜è¶Šï¼Œå±•ç°å‡ºå‡ºè‰²çš„é›¶æ ·æœ¬å’Œå¾®è°ƒèƒ½åŠ›ï¼Œå¹¶ä¸ºä¸‰ç»´åŒ»å­¦å›¾åƒç†è§£è®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.01529v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†CT-3DVLPæ•°æ®é›†ä»¥åŠåŸºäºæ­¤æ•°æ®é›†çš„T3Dæ¡†æ¶çš„ç ”ç©¶ä¸åº”ç”¨ã€‚CT-3DVLPæ˜¯é¦–ä¸ªæœ€å¤§çš„å…¬å¼€3DåŒ»å­¦å›¾åƒæŠ¥å‘Šæ•°æ®é›†ï¼Œä¸º3D MedVLPç ”ç©¶æä¾›äº†å…¨é¢çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚åŒæ—¶ï¼Œæå‡ºçš„T3Dæ¡†æ¶é€šè¿‡å¼•å…¥æ–‡æœ¬ä¿¡æ¯å¤šè§†è§’å¯¹é½ï¼ˆTMAï¼‰æŠ€æœ¯ï¼Œä¼˜åŒ–äº†å•çº¯çš„CLIPé£æ ¼å¯¹é½æ–¹æ³•ï¼Œç¡®ä¿ä¸åŒè§†è§’ä¹‹é—´çš„è§†è§‰è¡¨å¾å…·æœ‰ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚åœ¨å¤šä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°ä¸­ï¼ŒT3Då±•ç°å‡ºå‡ºè‰²çš„é›¶æ ·æœ¬å’Œå¾®è°ƒèƒ½åŠ›ï¼Œä¸º3DåŒ»å­¦å›¾åƒç†è§£è®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»‹ç»äº†CT-3DVLPæ•°æ®é›†ä½œä¸ºé¦–ä¸ªå…¬å¼€çš„3DåŒ»å­¦å›¾åƒæŠ¥å‘Šæ•°æ®é›†çš„é‡è¦æ€§ã€‚</li>
<li>æå‡ºäº†T3Dæ¡†æ¶æ¥ä¼˜åŒ–ç°æœ‰çš„è§†è§‰è‡ªç›‘ç£å­¦ä¹ å’Œå¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>TMAæŠ€æœ¯èƒ½å¤Ÿæ•´åˆæ–‡æœ¬ç‰¹å¾åˆ°ç²¾ç»†çš„è§†è§‰è¡¨å¾ä¸­ï¼Œç¡®ä¿ä¸åŒè§†è§’ä¹‹é—´çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚</li>
<li>T3Dæ¡†æ¶åœ¨å¤šä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬å’Œå¾®è°ƒåˆ†ç±»ã€è·¨æ¨¡æ€æ£€ç´¢ã€æŠ¥å‘Šç”Ÿæˆå’Œè¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.01529">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2312.01529v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2312.01529v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2312.01529v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2312.01529v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="SCALES-Boost-Binary-Neural-Network-for-Image-Super-Resolution-with-Efficient-Scalings"><a href="#SCALES-Boost-Binary-Neural-Network-for-Image-Super-Resolution-with-Efficient-Scalings" class="headerlink" title="SCALES: Boost Binary Neural Network for Image Super-Resolution with   Efficient Scalings"></a>SCALES: Boost Binary Neural Network for Image Super-Resolution with   Efficient Scalings</h2><p><strong>Authors:Renjie Wei, Zechun Liu, Yuchen Fan, Runsheng Wang, Ru Huang, Meng Li</strong></p>
<p>Deep neural networks for image super-resolution (SR) have demonstrated superior performance. However, the large memory and computation consumption hinders their deployment on resource-constrained devices. Binary neural networks (BNNs), which quantize the floating point weights and activations to 1-bit can significantly reduce the cost. Although BNNs for image classification have made great progress these days, existing BNNs for SR still suffer from a large performance gap between the FP SR networks. To this end, we observe the activation distribution in SR networks and find much larger pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variation in the activation distribution than image classification networks. However, existing BNNs for SR fail to capture these variations that contain rich information for image reconstruction, leading to inferior performance. To address this problem, we propose SCALES, a binarization method for SR networks that consists of the layer-wise scaling factor, the spatial re-scaling method, and the channel-wise re-scaling method, capturing the layer-wise, pixel-wise, and channel-wise variations efficiently in an input-dependent manner. We evaluate our method across different network architectures and datasets. For CNN-based SR networks, our binarization method SCALES outperforms the prior art method by 0.2dB with fewer parameters and operations. With SCALES, we achieve the first accurate binary Transformer-based SR network, improving PSNR by more than 1dB compared to the baseline method. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æ–¹é¢çš„è¡¨ç°å·²ç»å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…¶å¤§é‡çš„å†…å­˜å’Œè®¡ç®—æ¶ˆè€—é˜»ç¢äº†å…¶åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²ã€‚äºŒè¿›åˆ¶ç¥ç»ç½‘ç»œï¼ˆBNNsï¼‰å¯ä»¥å°†æµ®ç‚¹æƒé‡å’Œæ¿€æ´»å€¼é‡åŒ–ä¸º1ä½ï¼Œä»è€Œæ˜¾è‘—é™ä½æˆæœ¬ã€‚å°½ç®¡æœ€è¿‘ç”¨äºå›¾åƒåˆ†ç±»çš„BNNså–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†ç°æœ‰çš„ç”¨äºSRçš„BNNsä¸FP SRç½‘ç»œä¹‹é—´ä»å­˜åœ¨è¾ƒå¤§çš„æ€§èƒ½å·®è·ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è§‚å¯ŸSRç½‘ç»œä¸­çš„æ¿€æ´»åˆ†å¸ƒï¼Œå‘ç°ä¸å›¾åƒåˆ†ç±»ç½‘ç»œç›¸æ¯”ï¼Œæ¿€æ´»åˆ†å¸ƒåœ¨åƒç´ åˆ°åƒç´ ã€é€šé“åˆ°é€šé“ã€å±‚åˆ°å±‚å’Œå›¾åƒåˆ°å›¾åƒä¹‹é—´çš„å˜åŒ–æ›´å¤§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç”¨äºSRçš„BNNsæ— æ³•æ•è·è¿™äº›å˜åŒ–ï¼Œè¿™äº›å˜åŒ–åŒ…å«ä¸°å¯Œçš„å›¾åƒé‡å»ºä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SCALESï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹SRç½‘ç»œçš„äºŒå€¼åŒ–æ–¹æ³•ï¼Œå®ƒåŒ…æ‹¬é€å±‚ç¼©æ”¾å› å­ã€ç©ºé—´é‡æ–°ç¼©æ”¾æ–¹æ³•å’Œé€šé“é‡æ–°ç¼©æ”¾æ–¹æ³•ï¼Œä»¥è¾“å…¥ä¾èµ–çš„æ–¹å¼é«˜æ•ˆæ•è·é€å±‚ã€åƒç´ çº§å’Œé€šé“çº§çš„å˜å¼‚ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„ç½‘ç»œæ¶æ„å’Œæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚å¯¹äºåŸºäºCNNçš„SRç½‘ç»œï¼Œæˆ‘ä»¬çš„äºŒå€¼åŒ–æ–¹æ³•SCALESåœ¨è¾ƒå°‘å‚æ•°å’Œè¿ç®—çš„æƒ…å†µä¸‹ï¼Œæ¯”ç°æœ‰æŠ€æœ¯æ–¹æ³•é«˜å‡º0.2dBã€‚å€ŸåŠ©SCALESï¼Œæˆ‘ä»¬å®ç°äº†é¦–ä¸ªå‡†ç¡®çš„åŸºäºäºŒè¿›åˆ¶Transformerçš„SRç½‘ç»œï¼Œä¸åŸºå‡†æ–¹æ³•ç›¸æ¯”ï¼ŒPSNRæé«˜äº†è¶…è¿‡1dBã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2303.12270v2">PDF</a> Accpeted by DATE 2025</p>
<p><strong>Summary</strong><br>     æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æ–¹é¢çš„æ€§èƒ½å“è¶Šï¼Œä½†å†…å­˜å’Œè®¡ç®—æ¶ˆè€—å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚äºŒè¿›åˆ¶ç¥ç»ç½‘ç»œï¼ˆBNNsï¼‰å¯ä»¥å°†æµ®ç‚¹æƒé‡å’Œæ¿€æ´»é‡åŒ–åˆ°1ä½ï¼Œæ˜¾è‘—é™ä½æˆæœ¬ã€‚å°½ç®¡BNNsåœ¨å›¾åƒåˆ†ç±»æ–¹é¢å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†ç°æœ‰çš„SR-BNNsä¸æµ®ç‚¹SRç½‘ç»œä¹‹é—´ä»å­˜åœ¨è¾ƒå¤§æ€§èƒ½å·®è·ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°SRç½‘ç»œä¸­æ¿€æ´»åˆ†å¸ƒçš„æ›´å¤§å˜åŒ–ï¼Œå¹¶å‘ç°ç°æœ‰SR-BNNsæ— æ³•æ•è·è¿™äº›å˜åŒ–ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†é’ˆå¯¹SRç½‘ç»œçš„äºŒè¿›åˆ¶åŒ–æ–¹æ³•â€”â€” SCALESï¼ŒåŒ…æ‹¬é€å±‚ç¼©æ”¾å› å­ã€ç©ºé—´é‡æ–°ç¼©æ”¾æ–¹æ³•å’Œé€šé“é‡æ–°ç¼©æ”¾æ–¹æ³•ï¼Œä»¥è¾“å…¥ç›¸å…³çš„æ–¹å¼é«˜æ•ˆæ•è·é€å±‚ã€åƒç´ çº§å’Œé€šé“çº§çš„å·®å¼‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒçš„ç½‘ç»œæ¶æ„å’Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¯¹äºåŸºäºCNNçš„SRç½‘ç»œï¼Œæˆ‘ä»¬çš„äºŒè¿›åˆ¶åŒ–æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯0.2dBï¼Œå¹¶ä¸”å‚æ•°å’Œè¿ç®—æ›´å°‘ã€‚å€ŸåŠ© SCALESï¼Œæˆ‘ä»¬å®ç°äº†é¦–ä¸ªå‡†ç¡®çš„äºŒè¿›åˆ¶Transformer-based SRç½‘ç»œï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”æé«˜äº†è¶…è¿‡1dBçš„PSNRã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹é¢çš„æ€§èƒ½å‡ºè‰²ï¼Œä½†èµ„æºæ¶ˆè€—å¤§ã€‚</li>
<li>äºŒè¿›åˆ¶ç¥ç»ç½‘ç»œï¼ˆBNNsï¼‰èƒ½å¤Ÿæ˜¾è‘—é™ä½æ·±åº¦ç¥ç»ç½‘ç»œçš„å†…å­˜å’Œè®¡ç®—æˆæœ¬ã€‚</li>
<li>åœ¨SRç½‘ç»œä¸­ï¼Œæ¿€æ´»åˆ†å¸ƒçš„å˜åŒ–æ¯”å›¾åƒåˆ†ç±»ç½‘ç»œæ›´å¤§ã€‚</li>
<li>ç°æœ‰SR-BNNsæ— æ³•æ•è·è¿™äº›å˜åŒ–ä¸°å¯Œçš„ä¿¡æ¯ç”¨äºå›¾åƒé‡å»ºï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é’ˆå¯¹SRç½‘ç»œçš„äºŒè¿›åˆ¶åŒ–æ–¹æ³•â€”â€” SCALESã€‚</li>
<li>SCALESæ–¹æ³•åŒ…æ‹¬é€å±‚ç¼©æ”¾å› å­ã€ç©ºé—´é‡æ–°ç¼©æ”¾æ–¹æ³•å’Œé€šé“é‡æ–°ç¼©æ”¾æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2303.12270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_åŒ»å­¦å›¾åƒ/2303.12270v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/Interactive/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_Interactive/2409.05860v2/page_1_0.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-27  Nonlinear Gravitational Radiation Reaction Failed Tail, Memories &   Squares
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-02-27\./crop_Diffusion Models/2502.09278v3/page_0_0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-27  LDGen Enhancing Text-to-Image Synthesis via Large Language Model-Driven   Language Representation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">12809.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
