<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-02-27  AgentRM Enhancing Agent Generalization with Reward Modeling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-08e2895a318dd12f07ce9551d82799a5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-03-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    58 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-27-更新"><a href="#2025-02-27-更新" class="headerlink" title="2025-02-27 更新"></a>2025-02-27 更新</h1><h2 id="AgentRM-Enhancing-Agent-Generalization-with-Reward-Modeling"><a href="#AgentRM-Enhancing-Agent-Generalization-with-Reward-Modeling" class="headerlink" title="AgentRM: Enhancing Agent Generalization with Reward Modeling"></a>AgentRM: Enhancing Agent Generalization with Reward Modeling</h2><p><strong>Authors:Yu Xia, Jingru Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yaxi Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun</strong></p>
<p>Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area. </p>
<blockquote>
<p>现有基于大型语言模型的代理在固定任务上表现良好，但在未见任务上的泛化能力仍然较差。因此，一些最近的研究专注于通过更多多样化的任务微调策略模型，以提高其泛化能力。在这项工作中，我们发现相较于直接微调策略模型，通过奖励模型进行微调以指导策略模型更加稳健。基于这一发现，我们提出了AgentRM（一种通用奖励模型），用于引导策略模型进行有效的测试时间搜索。我们全面研究了三种构建奖励模型的方法，包括显式奖励建模、隐式奖励建模和LLM作为评判者。然后，我们使用AgentRM指导答案生成，采用最佳N采样和步骤级光束搜索。在四种类型的九个代理任务中，AgentRM平均提高了基础策略模型的性能8.8个点，超过了顶级通用代理4.0个点。此外，它展示了从弱到强的泛化能力，对LLaMA-3-70B策略模型的改进提高了12.6个点。至于专项能力方面，AgentRM也能提升微调后的策略模型性能，并在三项固定任务上超过顶级专业代理11.4个点。进一步的分析验证了其在测试时间扩展中的有效性。相关代码将发布，以促进该领域的研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18407v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了在LLM基础上构建的代理在未见任务上的泛化能力问题。研究发现，通过微调奖励模型来指导政策模型比直接微调政策模型更为稳健。基于此，提出了AgentRM，一种可泛化的奖励模型，用于指导政策模型进行有效的测试时间搜索。通过三种构建奖励模型的方法（显式奖励建模、隐式奖励建模和LLM作为判官），AgentRM平均提升了基础政策模型8.8个百分点，并在LLaMA-3-70B政策模型上实现了高达12.6个百分点的改进。同时，AgentRM也能提升微调后的政策模型在特定任务上的表现。该方法的代码将公开发布，以促进相关领域的研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM基础代理在未见任务上的泛化能力有待提高。</li>
<li>通过微调奖励模型指导政策模型能提升代理的泛化能力。</li>
<li>AgentRM是一种可泛化的奖励模型，通过三种方法构建：显式奖励建模、隐式奖励建模和LLM作为判官。</li>
<li>AgentRM在多种任务上提升了基础政策模型的表现，平均提升8.8个百分点，并在LLaMA-3-70B政策模型上实现更大的改进。</li>
<li>AgentRM能提升特定任务上的表现，并超越顶尖专业代理的表现。</li>
<li>AgentRM的有效性在测试时间缩放方面得到了进一步验证。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18407">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2f8cc325bab86545f12adea0929d8c11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3a1776de5f2de1819df0d7b7f87e53e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07a53082828ec4c57ff17a9050b91edb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8284bc9b7967afad6b43aebc00320213.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WebGames-Challenging-General-Purpose-Web-Browsing-AI-Agents"><a href="#WebGames-Challenging-General-Purpose-Web-Browsing-AI-Agents" class="headerlink" title="WebGames: Challenging General-Purpose Web-Browsing AI Agents"></a>WebGames: Challenging General-Purpose Web-Browsing AI Agents</h2><p><strong>Authors:George Thomas, Alex J. Chan, Jikun Kang, Wenqi Wu, Filippos Christianos, Fraser Greenlee, Andy Toulis, Marvin Purtorab</strong></p>
<p>We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems’ ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents. </p>
<blockquote>
<p>我们介绍了WebGames，这是一套全面的基准测试套件，旨在通过50多个交互式挑战来评估通用网页浏览人工智能代理。这些挑战是专为人类设计得简单易懂的，同时系统地测试了当前人工智能系统在基本浏览器交互、高级输入处理、认知任务、工作流程自动化和互动娱乐等方面的局限性。我们的框架通过密闭的测试环境消除了外部依赖，确保可重复评估和可验证的基准解决方案。我们评估了领先的视觉语言模型，包括GPT-4o、Claude计算机使用、Gemini-1.5 Pro和Qwen2-VL与人类性能的对比。结果表明存在显著的能力差距，最好的人工智能系统只有43.1%的成功率，而人类性能为95.7%，这突显了当前人工智能系统在处理人类认为直观的常见网页交互模式方面的根本性局限。该基准测试在webgames.convergence.ai上公开可用，提供了一个轻量级的客户端实现，促进了快速的评估周期。通过其模块化架构和标准化的挑战规格，WebGames为衡量更能力强的网页浏览代理的开发进度提供了坚实的基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18356v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>WebGames是一个全面评估通用网页浏览AI系统的基准测试套件，包含超过五十项互动挑战，旨在通过设计特定挑战评估人工智能系统的基本浏览器交互、高级输入处理、认知任务、工作流程自动化及互动娱乐的能力。框架消除依赖封闭测试环境以确保可重复验证评估。评测显示顶尖的视觉语言模型仍有明显短板，最好的AI系统成功率为人类成绩的不到一半，展示其在处理常见网页交互模式上的局限。WebGames基准测试套件已公开发布并提供轻量级客户端实现，便于快速评估循环。其模块化架构和标准挑战规格为衡量网页浏览代理的发展进步提供了稳健基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WebGames是一个全面评估网页浏览AI的基准测试套件，包含超过五十项互动挑战。</li>
<li>该框架旨在测试AI系统的多项能力，包括基本浏览器交互、高级输入处理等。</li>
<li>测试环境封闭消除外部依赖，确保评估结果的可重复性。</li>
<li>评测结果揭示了顶尖视觉语言模型存在的显著能力差距。</li>
<li>最佳AI系统的成功率仅为人类成绩的约一半，表明在处理常见网页交互模式上存在局限。</li>
<li>WebGames基准测试套件已公开发布并提供客户端实现，便于快速评估AI性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18356">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-aa7dab13b7ec778a6123f410e3da1b3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83e06e133610da009e6e4a5b8a03e3cb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-470d1e98f09dde6bafe70c7fdced2332.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a6a95706d05494b18a8da4bb14fb442.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RefuteBench-2-0-–-Agentic-Benchmark-for-Dynamic-Evaluation-of-LLM-Responses-to-Refutation-Instruction"><a href="#RefuteBench-2-0-–-Agentic-Benchmark-for-Dynamic-Evaluation-of-LLM-Responses-to-Refutation-Instruction" class="headerlink" title="RefuteBench 2.0 – Agentic Benchmark for Dynamic Evaluation of LLM   Responses to Refutation Instruction"></a>RefuteBench 2.0 – Agentic Benchmark for Dynamic Evaluation of LLM   Responses to Refutation Instruction</h2><p><strong>Authors:Jianhao Yan, Yun Luo, Yue Zhang</strong></p>
<p>In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM’s ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.   We design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. <a target="_blank" rel="noopener" href="https://github.com/ElliottYan/RefuteBench-2.0">https://github.com/ElliottYan/RefuteBench-2.0</a> </p>
<blockquote>
<p>在多轮交互模式中，大型语言模型（LLM）可以利用用户反馈来提高其响应的质量和相关性。然而，评估LLM融入用户反驳性反馈的能力是至关重要且充满挑战的。在这项研究中，我们推出了RefuteBench 2.0，它通过引入LLM代理作为反驳者和评估者，对原始RefuteBench进行了重大扩展，从而实现了灵活全面的评估。我们设计了具有不同有效期限的瞬时和持久反驳指令。元评估表明，基于LLM的反驳者能够产生更多人性化的反驳，评估者的评分与人类评分高度相关。各种LLM的实验结果表明，当前模型虽然能满足反驳需求，但无法记住反驳信息。有趣的是，我们还观察到随着反驳的增加，初始任务性能有所下降。对注意力分数的进一步分析揭示了当前LLM的潜在弱点：在长期的对话情境中，它们很难保留并正确使用以前的信息。详情请访问 <a target="_blank" rel="noopener" href="https://github.com/ElliottYan/RefuteBench-2.0">https://github.com/ElliottYan/RefuteBench-2.0</a> 了解更多。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18308v1">PDF</a> Work on progess</p>
<p><strong>Summary</strong></p>
<p>基于多轮交互模式，大型语言模型（LLM）能够利用用户反馈来提升响应的质量和相关性。本研究介绍了RefuteBench 2.0，它在原有基础上纳入了LLM作为反驳者和评估者，实现了灵活和全面的评估。通过设计瞬时和持久性反驳指令，并进行了元评估，显示LLM生成的反驳更具人性化，评估者的评分与人类高度相关。实验结果显示，当前模型能有效满足反驳要求，但无法记住反驳信息。随着反驳的增加，初始任务性能有所下降。注意力得分分析揭示了当前LLM的潜在弱点：在长篇对话中，它们难以保留并正确使用以前的信息。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在多轮交互模式中可以利用用户反馈提升响应质量。</li>
<li>RefuteBench 2.0通过纳入LLM作为反驳者和评估者进行更全面的评估。</li>
<li>LLM生成的反驳更具人性化，评估者的评分与人类高度相关。</li>
<li>当前模型虽能满足反驳要求，但无法有效记忆反驳信息。</li>
<li>随着反驳的增加，初始任务性能会下降。</li>
<li>LLM在长篇对话中难以保留并正确使用以前的信息。</li>
<li>注意力得分分析揭示了LLM的潜在弱点。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18308">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1128ab506d152a527a206dfd2c80f912.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2b37f1251b7f8bf85801363e0bff1ee0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d61160993f5a68cfb69851393e2314d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2efe510934517cd175b74c2af9479310.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ViDoRAG-Visual-Document-Retrieval-Augmented-Generation-via-Dynamic-Iterative-Reasoning-Agents"><a href="#ViDoRAG-Visual-Document-Retrieval-Augmented-Generation-via-Dynamic-Iterative-Reasoning-Agents" class="headerlink" title="ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic   Iterative Reasoning Agents"></a>ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic   Iterative Reasoning Agents</h2><p><strong>Authors:Qiuchen Wang, Ruixue Ding, Zehui Chen, Weiqi Wu, Shihang Wang, Pengjun Xie, Feng Zhao</strong></p>
<p>Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model’s reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark. </p>
<blockquote>
<p>从视觉丰富的文档中理解信息对于传统的检索增强生成（RAG）方法来说仍然是一个巨大的挑战。现有的基准测试主要关注基于图像的问答（QA），忽视了在密集的视觉文档中进行高效检索、理解和推理的根本性挑战。为了弥补这一差距，我们引入了ViDoSeek，这是一个新型数据集，旨在评估RAG在需要复杂推理的视觉丰富文档上的表现。基于此，我们确定了当前RAG方法的关键局限性：（i）纯粹的视觉检索方法难以有效地整合文本和视觉特征；（ii）以前的方法通常分配了不足的推理令牌，限制了其有效性。为了应对这些挑战，我们提出了ViDoRAG，这是一个为跨视觉文档的复杂推理量身定制的新型多代理RAG框架。ViDoRAG采用基于高斯混合模型（GMM）的混合策略，以有效处理多模式检索。为了进一步激发模型的推理能力，我们引入了一种迭代代理工作流程，融合了探索、总结和反思，为RAG领域中的测试时间缩放提供了研究框架。在ViDoSeek上的广泛实验验证了我们的方法的有效性和通用性。值得注意的是，ViDoRAG在竞争性的ViDoSeek基准测试上的表现优于现有方法，准确率提高了10%以上。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18017v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了针对视觉丰富文档进行复杂推理的RAG方法的重要挑战。为解决现有RAG方法在视觉丰富文档上的局限性，提出了ViDoRAG，一个为复杂视觉文档推理定制的多代理RAG框架。该框架采用基于高斯混合模型（GMM）的混合策略，有效处理多模式检索，并引入迭代代理工作流程，以激发模型的推理能力。在ViDoSeek上的实验验证了该方法的有效性和泛化能力，且ViDoRAG在竞争性的ViDoSeek基准测试上的表现优于现有方法超过10%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视觉丰富文档的RAG方法面临重大挑战，需要高效检索、理解和推理。</li>
<li>现有基准测试主要关注图像问答，忽视了视觉丰富文档中的复杂推理挑战。</li>
<li>引入ViDoSeek数据集，用于评估视觉丰富文档上的RAG性能。</li>
<li>现有RAG方法的局限性：纯视觉检索方法难以整合文本和视觉特征，以往方法分配推理令牌不足。</li>
<li>提出ViDoRAG框架，采用高斯混合模型（GMM）的混合策略处理多模式检索。</li>
<li>ViDoRAG引入迭代代理工作流程，包括探索、总结和反思，以激发模型的推理能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18017">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-18fb2775f24db45d3dce0d4526a979b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32c76eb1bff432a5208e52c579ab43f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ebfb11ada3509f3c500a06c8b8bfb4e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ad7582dafc8ecc08db07f1051da3709.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LLM-Knows-Geometry-Better-than-Algebra-Numerical-Understanding-of-LLM-Based-Agents-in-A-Trading-Arena"><a href="#LLM-Knows-Geometry-Better-than-Algebra-Numerical-Understanding-of-LLM-Based-Agents-in-A-Trading-Arena" class="headerlink" title="LLM Knows Geometry Better than Algebra: Numerical Understanding of   LLM-Based Agents in A Trading Arena"></a>LLM Knows Geometry Better than Algebra: Numerical Understanding of   LLM-Based Agents in A Trading Arena</h2><p><strong>Authors:Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou</strong></p>
<p>Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at <a target="_blank" rel="noopener" href="https://github.com/wekjsdvnm/Agent-Trading-Arena.git">https://github.com/wekjsdvnm/Agent-Trading-Arena.git</a>. </p>
<blockquote>
<p>最近的大型语言模型（LLM）的进步在自然语言处理任务中显著提高了性能。然而，它们在应对动态、未见任务的推广能力，特别是在数值推理方面，仍然是一个挑战。现有的基准测试主要对LLMs评估预定义最优解决方案的问题，这可能不符合现实世界场景，其中没有明确的答案。为了弥补这一差距，我们设计了Agent Trading Arena，这是一个通过零和游戏模拟复杂经济系统的虚拟数值游戏，其中代理投资于股票组合。我们的实验表明，包括GPT-4o在内的LLMs在处理纯文本股票数据时，在代数推理方面遇到困难，往往关注局部细节而非全局趋势。相比之下，当以视觉数据（如散点图或K线图）呈现时，LLMs在几何推理方面的表现要好得多，这表明视觉表示增强了数值推理。通过引入反射模块，这种能力得到了进一步提高，有助于分析和解释复杂数据。我们在NASDAQ股票数据集上验证了我们的发现，其中LLMs在视觉数据下的推理能力相较于文本更强。我们的代码和数据公开可访问于<a target="_blank" rel="noopener" href="https://github.com/wekjsdvnm/Agent-Trading-Arena.git%E3%80%82">https://github.com/wekjsdvnm/Agent-Trading-Arena.git。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17967v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在自然语言处理任务上的表现有了显著提升，但在动态未见任务的泛化能力上仍存在挑战。现有基准测试主要评估LLM在具有预设最优解决方案的问题上的表现，这可能不符合现实世界场景。为解决此差距，我们设计了一个名为Agent Trading Arena的虚拟数值游戏，模拟复杂的经济系统通过零和游戏进行股票组合投资。实验表明，LLM在处理纯文本股票数据时面临代数推理困难，常常关注局部细节而忽视全局趋势。相比之下，当呈现可视化数据时，如散点图或K线图，LLM的几何推理能力表现更好。引入反射模块后，这一能力得到了进一步提升，有助于分析复杂数据。我们在NASDAQ股票数据集上验证了这些发现。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLM）在自然语言处理任务上表现优异，但在泛化到动态未见任务方面存在挑战。</li>
<li>现有基准测试与真实世界场景存在差距，需要新的评估方法。</li>
<li>Agent Trading Arena是一个模拟复杂经济系统的虚拟数值游戏，用于评估LLM在股票组合投资方面的能力。</li>
<li>LLM在处理纯文本股票数据时面临代数推理困难。</li>
<li>LLM在可视化数据（如散点图、K线图）上的几何推理能力更强。</li>
<li>引入反射模块可进一步提升LLM对复杂数据的分析和理解能力。</li>
<li>在NASDAQ股票数据集上，LLM在可视化数据上的推理能力优于文本数据。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17967">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-944135cc6e58b668b2e56d1525c19e63.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3fbd546245f3fc505f9c26bcead86d5d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a9e8fd069881501dbeb323cc7e2dac5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e3ba4d0b236ddef7c8511a9ad051f90.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Assessing-Large-Language-Models-in-Agentic-Multilingual-National-Bias"><a href="#Assessing-Large-Language-Models-in-Agentic-Multilingual-National-Bias" class="headerlink" title="Assessing Large Language Models in Agentic Multilingual National Bias"></a>Assessing Large Language Models in Agentic Multilingual National Bias</h2><p><strong>Authors:Qianying Liu, Katrina Qiyao Wang, Fei Cheng, Sadao Kurohashi</strong></p>
<p>Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM’s applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education. </p>
<blockquote>
<p>大型语言模型在多语种自然语言处理方面引起了广泛关注，但关于与跨语种偏见相关的风险研究仅限于即时语境偏好。基于推理的推荐中的跨语言差异仍被大量探索，甚至缺乏描述性分析。本研究首次填补了这一空白。我们测试了大型语言模型在三种关键场景（大学申请、旅行和搬迁）中提供个性化建议的适用性和能力。通过分析大型语言模型对多语种决策任务的回应，我们研究了其存在的多语种偏见。我们量化模型生成分数中的偏见，并评估人口统计因素和推理策略（如“思维链”提示）对偏见模式的影响。我们的研究发现在不同的任务中都普遍存在本地语言偏见，GPT-4和Sonnet与GPT-3.5相比减少了英语国家的偏见，但未能实现稳健的多语种对齐，这凸显了对多语种人工智能代理和教育应用等更广泛的启示。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17945v1">PDF</a> 13 pages</p>
<p><strong>Summary</strong><br>大型语言模型在多语种自然语言处理中受到广泛关注，但关于跨语言偏见的研究仍限于即时语境偏好。本研究首次探讨了语言模型在提供个性化建议方面的适用性，并研究了其在大学申请、旅行和搬迁等三个关键场景中的表现。通过分析决策任务中的多语种偏见，我们量化了模型生成的分数中的偏见，并评估了人口统计因素和推理策略（如Chain-of-Thought提示）对偏见模式的影响。研究发现，本地语言偏见在不同任务中普遍存在，GPT-4和Sonnet相较于GPT-3.5在英语国家的偏见有所减少，但仍未实现稳健的多语种对齐。这强调了多语种人工智能在教育等领域的更广泛影响的重要性。此外也进一步说明即使是现今前沿的语言模型仍然存在多方面的局限和偏误需要加以深入探索研究才能优化AI语言模型的全面应用与适用性以适应多种语言的挑战同时也有望扩大在多语种场景下智能体的应用场景和服务范围推动相关领域的发展进步。研究也揭示了对不同语言的认知和表达存在差异因此在未来的研究中应进一步关注如何克服这些差异以提高模型的泛化能力和跨文化适应性从而更好地服务于全球用户。随着技术的不断进步和语言模型研究的深入我们期待未来能够开发出更加智能、高效且适应多语种环境的语言模型从而更好地满足社会的需求服务于全球的交流和合作推动世界进步。总体来说这是一个对前沿领域有益的补充和发展推动了人工智能在多语种环境下的应用和发展。总的来说本研究的发现对于未来多语种人工智能的发展和应用具有重要的启示意义。同时该研究也为我们提供了宝贵的见解和思路为未来的研究提供了重要的参考方向。我们相信随着技术的不断进步这一领域的研究将不断发展和壮大并为多语种交流带来更多的便利和创新贡献力量为社会进步发展作出贡献奠定了重要的理论基础和启示。未来对于大型语言模型的研究也将朝着更加全面和深入的方向发展推动人工智能技术的不断进步和创新发展以更好地服务于社会需求和人类进步发展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在多语种自然语言处理中受到关注，但跨语言偏见的研究仍存在局限，且尚未在理据型推荐中得到足够探索。此研究意在填补此领域的空白并深入了解现状并进行原因分析、研究和策略构建以帮助当前问题的解决以实现全面的应用研究并最终有效支持泛化和决策策略的构建和优化以实现多语种场景下的智能决策支持和服务提升用户体验和满意度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17945">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-17b4048bbae153ef4b54f0a447a3b707.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04af96c726c07b1efc3bb10fb5e627b9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-998b2bfda23066f5207f41694243f585.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="FACT-AUDIT-An-Adaptive-Multi-Agent-Framework-for-Dynamic-Fact-Checking-Evaluation-of-Large-Language-Models"><a href="#FACT-AUDIT-An-Adaptive-Multi-Agent-Framework-for-Dynamic-Fact-Checking-Evaluation-of-Large-Language-Models" class="headerlink" title="FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking   Evaluation of Large Language Models"></a>FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking   Evaluation of Large Language Models</h2><p><strong>Authors:Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua</strong></p>
<p>Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs’ fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs’ factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis. </p>
<blockquote>
<p>大型语言模型（LLM）在事实核查研究方面取得了显著进展。然而，现有的自动化事实核查评估方法依赖于静态数据集和分类指标，这些方法无法自动评估论证的产生，并揭示LLM在事实核查中的微妙局限性。在这项工作中，我们引入了FACT-AUDIT，这是一个以代理驱动的框架，能够自适应和动态地评估LLM的事实核查能力。借助重要性采样原理和多代理协作，FACT-AUDIT生成自适应和可扩展的数据集，执行迭代模型为中心的评估，并根据模型特定的响应更新评估结果。通过结合论证的产生和裁决预测，该框架提供了对LLM事实推理能力的全面和不断发展的审计，以调查其可信度。大量实验表明，FACT-AUDIT能够有效地区分最先进的LLM，在模型为中心的事实核查分析中提供了关于模型优势和局限性的宝贵见解。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17924v1">PDF</a> </p>
<p><strong>Summary</strong><br>大型语言模型（LLM）在事实核查研究中取得了显著进展。然而，现有的自动化事实核查评估方法依赖于静态数据集和分类指标，无法自动评估论证生成并揭示LLM在事实核查中的微妙局限性。为此，我们引入了FACT-AUDIT这一以代理驱动框架，自适应地动态评估LLM的事实核查能力。该框架利用重要性采样原理和跨代理协作生成自适应和可扩展数据集，执行迭代模型中心评估，并根据模型特定响应更新评估结果。通过结合论证生成与裁决预测，该框架对LLM的事实推理能力进行了全面和不断发展的审计，以研究其可靠性。实验表明，FACT-AUDIT有效地区分了最先进的大型语言模型，为模型中心的事实核查分析提供了有价值的见解。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLMs）在事实核查领域有重要进展。</li>
<li>现有自动化评估方法存在局限性，无法全面评估LLMs在事实核查中的性能。</li>
<li>FACT-AUDIT框架基于代理驱动，能自适应、动态地评估LLMs的事实核查能力。</li>
<li>该框架利用重要性采样和跨代理协作生成数据集，执行模型中心的评价。</li>
<li>FACT-AUDIT结合论证生成与裁决预测，全面审计LLM的事实推理能力。</li>
<li>实验证明，FACT-AUDIT能有效区分不同的大型语言模型。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17924">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f066a9701dfac06ab9e17ce46d3dd7bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5e1d1a6ae7aa971d262a57bb974958f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2766002e220373f4f271299095bdb086.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34bea02d7527c279f8cda28a1a1e5fe8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Safe-Multi-Agent-Navigation-guided-by-Goal-Conditioned-Safe-Reinforcement-Learning"><a href="#Safe-Multi-Agent-Navigation-guided-by-Goal-Conditioned-Safe-Reinforcement-Learning" class="headerlink" title="Safe Multi-Agent Navigation guided by Goal-Conditioned Safe   Reinforcement Learning"></a>Safe Multi-Agent Navigation guided by Goal-Conditioned Safe   Reinforcement Learning</h2><p><strong>Authors:Meng Feng, Viraj Parimi, Brian Williams</strong></p>
<p>Safe navigation is essential for autonomous systems operating in hazardous environments. Traditional planning methods excel at long-horizon tasks but rely on a predefined graph with fixed distance metrics. In contrast, safe Reinforcement Learning (RL) can learn complex behaviors without relying on manual heuristics but fails to solve long-horizon tasks, particularly in goal-conditioned and multi-agent scenarios.   In this paper, we introduce a novel method that integrates the strengths of both planning and safe RL. Our method leverages goal-conditioned RL and safe RL to learn a goal-conditioned policy for navigation while concurrently estimating cumulative distance and safety levels using learned value functions via an automated self-training algorithm. By constructing a graph with states from the replay buffer, our method prunes unsafe edges and generates a waypoint-based plan that the agent follows until reaching its goal, effectively balancing faster and safer routes over extended distances.   Utilizing this unified high-level graph and a shared low-level goal-conditioned safe RL policy, we extend this approach to address the multi-agent safe navigation problem. In particular, we leverage Conflict-Based Search (CBS) to create waypoint-based plans for multiple agents allowing for their safe navigation over extended horizons. This integration enhances the scalability of goal-conditioned safe RL in multi-agent scenarios, enabling efficient coordination among agents.   Extensive benchmarking against state-of-the-art baselines demonstrates the effectiveness of our method in achieving distance goals safely for multiple agents in complex and hazardous environments. Our code will be released to support future research. </p>
<blockquote>
<p>安全导航对于在危险环境中运行自主系统至关重要。传统规划方法在长远任务上表现出色，但依赖于具有固定距离度量的预定义图。相比之下，安全强化学习（RL）能够学习复杂行为，无需依赖手动启发式方法，但在解决长远任务时却会失败，特别是在目标条件和多智能体场景中。在本文中，我们引入了一种结合规划和安全强化学习优点的新方法。我们的方法利用目标条件强化学习和安全强化学习来学习导航的目标条件策略，同时使用通过自动化自训练算法学到的值函数来估计累积距离和安全水平。通过利用回放缓冲区中的状态构建图，我们的方法可以剔除不安全边缘并生成基于路点的计划，智能体遵循该计划直至达到目标，有效地在较长距离上实现更快的安全路线平衡。利用这种统一的高级图和共享的底层目标条件安全强化学习策略，我们将这一方法扩展到解决多智能体安全导航问题。特别是，我们利用基于冲突的搜索（CBS）为多个智能体创建基于路点的计划，允许它们在扩展范围内安全导航。这种融合提高了目标条件安全强化学习在多智能体场景中的可扩展性，实现了智能体之间的有效协调。与最新技术的基准测试相比，我们的方法在复杂和危险环境中为多个智能体实现安全距离目标的有效性得到了验证。我们的代码将发布以支持未来的研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17813v1">PDF</a> Due to the limitation “The abstract field cannot be longer than 1,920   characters”, the abstract here is shorter than that in the PDF file</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种结合规划和安全强化学习（RL）的方法，用于自主系统在危险环境中的安全导航。该方法通过构建包含回放缓冲区状态的高层次图形，能够学习目标条件下的策略，同时估计累积距离和安全级别。通过修剪不安全边缘并生成基于路径点的计划，该方法使代理能够在达到目标的过程中实现更快、更安全的路线。此外，该方法还扩展到解决多代理安全导航问题，利用基于冲突的搜索（CBS）为多个代理创建基于路径点的计划，以实现长期安全导航。该方法在复杂和危险环境中对多个代理实现安全距离目标方面表现出有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>传统规划方法擅长处理长期任务，但依赖于预定义的图形和固定距离度量。</li>
<li>安全强化学习（RL）可以学习复杂行为，但无法解决长期任务，特别是在目标调节和多代理场景中。</li>
<li>本文提出的方法结合了规划和安全RL的优点，通过构建包含回放缓冲区状态的高层次图形来实现目标条件下的安全导航。</li>
<li>该方法通过修剪不安全边缘并生成基于路径点的计划，实现更快、更安全的路线。</li>
<li>该方法扩展到多代理安全导航问题，利用基于冲突的搜索（CBS）为多个代理创建基于路径点的计划。</li>
<li>通过集成CBS，该方法提高了目标调节安全RL在多代理场景中的可扩展性，实现了高效的代理间协调。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17813">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-798056b9992d2c925c808a97dba240d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fb05d20dfd3efff50f7bfc2150a17e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6799cef7ba7a9eff34c9ae531a8f1e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8b500a7577a9840fd8836067122ff777.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6533c70ef56224ea44b142d19d02f357.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2c3382096ce91feb7782b95d2560b3d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Mobile-Agent-V-Learning-Mobile-Device-Operation-Through-Video-Guided-Multi-Agent-Collaboration"><a href="#Mobile-Agent-V-Learning-Mobile-Device-Operation-Through-Video-Guided-Multi-Agent-Collaboration" class="headerlink" title="Mobile-Agent-V: Learning Mobile Device Operation Through Video-Guided   Multi-Agent Collaboration"></a>Mobile-Agent-V: Learning Mobile Device Operation Through Video-Guided   Multi-Agent Collaboration</h2><p><strong>Authors:Junyang Wang, Haiyang Xu, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Jitao Sang</strong></p>
<p>The rapid increase in mobile device usage necessitates improved automation for seamless task management. However, many AI-driven frameworks struggle due to insufficient operational knowledge. Manually written knowledge helps but is labor-intensive and inefficient. To address these challenges, we introduce Mobile-Agent-V, a framework that leverages video guidance to provide rich and cost-effective operational knowledge for mobile automation. Mobile-Agent-V enhances task execution capabilities by leveraging video inputs without requiring specialized sampling or preprocessing. Mobile-Agent-V integrates a sliding window strategy and incorporates a video agent and deep-reflection agent to ensure that actions align with user instructions. Through this innovative approach, users can record task processes with guidance, enabling the system to autonomously learn and execute tasks efficiently. Experimental results show that Mobile-Agent-V achieves a 30% performance improvement compared to existing frameworks. The code will be open-sourced at <a target="_blank" rel="noopener" href="https://github.com/X-PLUG/MobileAgent">https://github.com/X-PLUG/MobileAgent</a>. </p>
<blockquote>
<p>随着移动设备使用的快速增加，需要改进自动化以实现无缝任务管理。然而，许多人工智能驱动的框架由于操作知识不足而面临困境。手动编写知识会有所帮助，但这种方法劳动强度大且效率低下。为了解决这些挑战，我们推出了Mobile-Agent-V框架，它利用视频指导，为移动自动化提供丰富且成本效益高的操作知识。Mobile-Agent-V通过利用视频输入，无需特殊采样或预处理，增强了任务执行能力。Mobile-Agent-V采用滑动窗口策略，并融入视频代理和深度反思代理，确保操作与用户指令一致。通过这一创新方法，用户可以按指导记录任务过程，使系统能够自主高效学习和执行任务。实验结果表明，与现有框架相比，Mobile-Agent-V实现了30%的性能提升。代码将在<a target="_blank" rel="noopener" href="https://github.com/X-PLUG/MobileAgent">https://github.com/X-PLUG/MobileAgent</a>上开源。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17110v2">PDF</a> 16 pages, 7 figures, 7tables</p>
<p><strong>Summary</strong><br>移动设备使用量的迅速增长需要改进自动化以实现无缝任务管理。然而，许多人工智能驱动的框架因缺乏操作知识而面临挑战。手动编写知识虽有帮助，但劳动密集且效率低下。为解决这些挑战，我们推出了Mobile-Agent-V框架，该框架利用视频指导，提供丰富且经济实惠的操作知识，用于移动自动化。Mobile-Agent-V通过利用视频输入增强任务执行能力，无需特殊采样或预处理。它采用滑动窗口策略，并结合视频代理和深度反思代理，确保操作与用户指令一致。用户可通过指导录制任务流程，使系统能够自主高效学习和执行任务。实验结果表明，与现有框架相比，Mobile-Agent-V实现了30%的性能提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>移动设备使用量的增长推动了自动化任务管理的需求。</li>
<li>许多AI框架因操作知识不足而面临挑战。</li>
<li>Mobile-Agent-V框架利用视频指导提供操作知识，促进移动自动化。</li>
<li>Mobile-Agent-V通过视频输入增强任务执行能力，效率更高。</li>
<li>Mobile-Agent-V采用滑动窗口策略结合视频代理和深度反思代理，确保操作与用户指令一致。</li>
<li>用户可通过指导录制任务流程，使系统能够自主高效学习并执行任务。</li>
<li>实验结果显示，Mobile-Agent-V相较于现有框架有30%的性能提升。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17110">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-39bcb4179423c5b0b554a4ddd6d28acb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34d129e108cf33302c9f91adc5c65ba5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8fdef6a2296924295ca3bfb4dade019d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab42316b042490714d21579b6184f11a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09042f0eb66b64ee33467f052f0b2c8a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents"><a href="#SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents" class="headerlink" title="SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents"></a>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents</h2><p><strong>Authors:Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen</strong></p>
<p>With the integration of large language models (LLMs), embodied agents have strong capabilities to process the scene information and plan complicated instructions in natural language, paving the way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in the real world. To study this issue, we present SafeAgentBench-a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that, although agents based on different design frameworks exhibit substantial differences in task success rates, their overall safety awareness remains weak. The most safety-conscious baseline achieves only a 10% rejection rate for detailed hazardous tasks. Moreover, simply replacing the LLM driving the agent does not lead to notable improvements in safety awareness. More details and code are available at <a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench">https://github.com/shengyin1224/SafeAgentBench</a>. </p>
<blockquote>
<p>随着大型语言模型（LLM）的集成，实体代理具备了强大的场景信息处理能力和自然语言复杂指令规划能力，为实体机器人的潜在部署铺平了道路。然而，一个可预见的问题是他们能够完美执行一些危险的任务，有可能对现实世界造成破坏。为了研究这个问题，我们提出了SafeAgentBench——一个新的针对实体LLM代理的安全意识任务规划的基准测试。SafeAgentBench包括：（1）一个新的数据集，包含750个任务，涵盖10种潜在危险和3种任务类型；（2）SafeAgentEnv是一个通用的实体环境，配备低级控制器，支持多个代理使用带有包括细致的仿真和场景设计等特点的代理执行17种高级动作；（3）从执行和语义两个角度提供可靠的评估方法。实验结果表明，虽然基于不同设计框架的代理在任务成功率上展现出较大差异，但整体的安全意识仍然薄弱。最具有安全意识的基线仅对详细的危险任务达到拒绝率为百分之十。此外，简单地更换驱动代理的LLM并不会导致安全意识的显著提高。更多细节和代码可在 <a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench">https://github.com/shengyin1224/SafeAgentBench</a> 上查看。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13178v3">PDF</a> 23 pages, 17 tables, 8 figures</p>
<p><strong>Summary</strong></p>
<p>大型语言模型驱动的实体代理具备处理场景信息和规划复杂指令的能力，为实体机器人的部署提供了可能。但存在潜在风险，实体代理人可能执行危险任务并造成实际损害。为解决这一问题，推出SafeAgentBench——实体LLM代理安全感知任务规划的新基准。SafeAgentBench包含：新的包含750个任务的数据集，涵盖10种潜在危险和三种任务类型；通用实体环境SafeAgentEnv，支持多代理执行并配备用于八种最新基线模型的十七种高级动作；以及从执行和语义两个角度的可靠评估方法。实验结果显示，不同框架的代理人在任务成功率上有显著差异，但整体安全意识仍然薄弱。最具安全意识的基线模型详细危险任务的拒绝率仅为百分之十。替换LLM模型驱动对安全意识并无显著改善。更多详情和代码可访问SafeAgentBench官网：<a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench">链接地址</a>。 </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型驱动的实体代理人具备强大的场景信息处理能力和复杂指令规划能力。</li>
<li>实体机器人在执行任务时存在潜在风险，可能造成实际损害。</li>
<li>SafeAgentBench是一个新的基准，用于评估实体LLM代理的安全意识任务规划能力。</li>
<li>SafeAgentBench包含新的数据集、通用实体环境和评估方法。</li>
<li>不同框架的代理人在任务成功率上存在差异，但整体安全意识仍然薄弱。</li>
<li>最具安全意识的基线模型对详细危险任务的拒绝率较低。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13178">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-7750d05c8787b43c388040913dd9d5d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5044b1b1d59aa5bbb36ac221a2e54e86.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60a122c7761fe2ec7cd3496caa49c43d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-08e2895a318dd12f07ce9551d82799a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8fe10df61c7d83148a53067563ddb91.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AFlow-Automating-Agentic-Workflow-Generation"><a href="#AFlow-Automating-Agentic-Workflow-Generation" class="headerlink" title="AFlow: Automating Agentic Workflow Generation"></a>AFlow: Automating Agentic Workflow Generation</h2><p><strong>Authors:Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, Chenglin Wu</strong></p>
<p>Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow’s efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/geekan/MetaGPT">https://github.com/geekan/MetaGPT</a>. </p>
<blockquote>
<p>大规模语言模型（LLM）在解决跨不同领域的复杂任务中表现出了显著潜力，通常是通过采用遵循详细指令和操作序列的代理工作流程来实现。然而，构建这些工作流程需要大量的人工努力，限制了其可扩展性和通用性。最近的研究试图实现这些工作流程的自动生成和优化，但现有方法仍然依赖于初始的手动设置，并无法实现完全自动化和有效的工作流程生成。为了应对这一挑战，我们将工作流程优化重新构建为一个在代码表示的工作流程上的搜索问题，其中LLM调用节点通过边缘连接。我们引入了AFlow，这是一个自动化框架，它利用蒙特卡洛树搜索有效地探索了这个空间，通过代码修改、树形经验和执行反馈来迭代优化工作流程。在六个基准数据集上的实证评估证明了AFlow的有效性，与最新基线相比，平均提高了5.7%。此外，AFlow使较小的模型能够以4.55%的美元推理成本在特定任务上超越GPT-4o。代码将在<a target="_blank" rel="noopener" href="https://github.com/geekan/MetaGPT%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/geekan/MetaGPT上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.10762v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在解决跨域复杂任务方面具有显著潜力，通常通过遵循详细指令和操作序列的agentic工作流程来实现。然而，构建这些工作流程需要大量人力，限制了其可扩展性和通用性。为解决这个问题，研究者们将工作流程优化重新构建为代码表示的工作流程搜索问题，并提出AFlow自动化框架，利用蒙特卡洛树搜索高效探索这个空间，通过代码修改、树结构经验和执行反馈来迭代优化工作流程。实证评估显示，AFlow在六个基准数据集上的效果优于最新基线方法，平均提高了5.7%。此外，AFlow使小型模型能够在特定任务上优于GPT-4，且推理成本仅为GPT-4的4.55%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在解决跨域复杂任务方面具有潜力。</li>
<li>现有工作流程构建需要大量人力，限制了可扩展性和通用性。</li>
<li>研究者将工作流程优化重新构建为代码表示的工作流程搜索问题。</li>
<li>AFlow框架通过蒙特卡洛树搜索高效探索工作流程空间。</li>
<li>AFlow通过代码修改、树结构经验和执行反馈迭代优化工作流程。</li>
<li>实证评估显示AFlow优于最新基线方法，平均提高了5.7%。</li>
<li>AFlow使小型模型在特定任务上表现优异，且推理成本较低。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.10762">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-afdba60a32a9bffc53a221047d1880a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76f4471e3aa7cc84c0b3142cafcd3cda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b3b2cd913c6c6a6940d33c84f9b5e7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94886232bf46ceff8bea22415e607f02.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Learning-Multi-agent-Multi-machine-Tending-by-Mobile-Robots"><a href="#Learning-Multi-agent-Multi-machine-Tending-by-Mobile-Robots" class="headerlink" title="Learning Multi-agent Multi-machine Tending by Mobile Robots"></a>Learning Multi-agent Multi-machine Tending by Mobile Robots</h2><p><strong>Authors:Abdalwhab Abdalwhab, Giovanni Beltrame, Samira Ebrahimi Kahou, David St-Onge</strong></p>
<p>Robotics can help address the growing worker shortage challenge of the manufacturing industry. As such, machine tending is a task collaborative robots can tackle that can also highly boost productivity. Nevertheless, existing robotics systems deployed in that sector rely on a fixed single-arm setup, whereas mobile robots can provide more flexibility and scalability. In this work, we introduce a multi-agent multi-machine tending learning framework by mobile robots based on Multi-agent Reinforcement Learning (MARL) techniques with the design of a suitable observation and reward. Moreover, an attention-based encoding mechanism is developed and integrated into Multi-agent Proximal Policy Optimization (MAPPO) algorithm to boost its performance for machine tending scenarios. Our model (AB-MAPPO) outperformed MAPPO in this new challenging scenario in terms of task success, safety, and resources utilization. Furthermore, we provided an extensive ablation study to support our various design decisions. </p>
<blockquote>
<p>机器人技术有助于解决制造业日益严重的劳动力短缺挑战。因此，机器照料是一个协作机器人可以完成的任务，可以大幅提高生产效率。然而，目前在该领域部署的机器人系统依赖于固定的单臂设置，而移动机器人可以提供更大的灵活性和可扩展性。在这项工作中，我们引入了一种基于移动机器人的多智能体多机器照料学习框架，采用多智能体强化学习（MARL）技术，并设计了一个合适的观察和奖励机制。此外，开发了一种基于注意力的编码机制，并将其整合到多智能体近端策略优化（MAPPO）算法中，以提高其在机器照料场景中的性能。我们的模型（AB-MAPPO）在任务成功、安全性和资源利用方面，在这个具有挑战性的新场景中优于MAPPO。此外，我们还通过广泛的消融研究来支持我们的各种设计决策。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.16875v2">PDF</a> 7 pages, 4 figures, Accepted at an AAAI workshop (The Multi-Agent AI   in the Real World Workshop)</p>
<p><strong>Summary</strong>：<br>工业机器人可以帮助解决制造业日益严重的劳动力短缺挑战。机器照料是一项协作机器人能够完成的任务，可以大大提高生产力。然而，当前制造业使用的机器人系统大多依赖于固定的单臂设置，而移动机器人可以提供更大的灵活性和可扩展性。本文介绍了一种基于多智能体强化学习（MARL）技术的移动机器人多机器照料学习框架，并设计了合适的观察和奖励机制。此外，开发了一种基于注意力的编码机制，并将其集成到多智能体近端策略优化（MAPPO）算法中，以提高机器照料场景的性能。AB-MAPPO模型在此新挑战场景中在任务成功、安全性和资源利用率方面优于MAPPO。我们还进行了一项广泛的研究以支持我们的各种设计决策。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>工业机器人可助力解决制造业劳动力短缺问题。</li>
<li>机器照料是协作机器人能提升生产效的任务之一。</li>
<li>当前机器人系统存在固定单臂设置的局限性，移动机器人更具灵活性和可扩展性。</li>
<li>引入基于多智能体强化学习（MARL）的移动机器人多机器照料学习框架。</li>
<li>提出了一种注意力编码机制并集成到MAPPO算法中，提高了机器照料性能。</li>
<li>AB-MAPPO模型在任务成功、安全性和资源利用率方面优于MAPPO。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.16875">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-83ecee426aa4e03f5a4e5e4ebe87c4be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-726fd421962222224afa0e2ca1575c9c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69b732d5dca26e1217059213449e9ac1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a44590d563aed29af308857fc757fa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3862fcb75d2c45b25707a7fc0b3cd781.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Crafting-Customisable-Characters-with-LLMs-Introducing-SimsChat-a-Persona-Driven-Role-Playing-Agent-Framework"><a href="#Crafting-Customisable-Characters-with-LLMs-Introducing-SimsChat-a-Persona-Driven-Role-Playing-Agent-Framework" class="headerlink" title="Crafting Customisable Characters with LLMs: Introducing SimsChat, a   Persona-Driven Role-Playing Agent Framework"></a>Crafting Customisable Characters with LLMs: Introducing SimsChat, a   Persona-Driven Role-Playing Agent Framework</h2><p><strong>Authors:Bohao Yang, Dong Liu, Chenghao Xiao, Kun Zhao, Chen Tang, Chao Li, Lin Yuan, Guang Yang, Lanxiao Huang, Chenghua Lin</strong></p>
<p>Large Language Models (LLMs) demonstrate remarkable ability to comprehend instructions and generate human-like text, enabling sophisticated agent simulation beyond basic behavior replication. However, the potential for creating freely customisable characters remains underexplored. We introduce the Customisable Conversation Agent Framework, which employs LLMs to simulate real-world characters through personalised characteristic feature injection, enabling diverse character creation according to user preferences. We propose the SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn role-playing dialogues across 1,360 real-world scenes. Characters are initially customised using pre-defined elements (career, aspiration, traits, skills), then expanded through personal and social profiles. Building on this, we present SimsChat, a freely customisable role-playing agent incorporating various realistic settings and topic-specified character interactions. Experimental results on both SimsConv and WikiRoleEval datasets demonstrate SimsChat’s superior performance in maintaining character consistency, knowledge accuracy, and appropriate question rejection compared to existing models. Our framework provides valuable insights for developing more accurate and customisable human simulacra. Our data and code are publicly available at <a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat">https://github.com/Bernard-Yang/SimsChat</a>. </p>
<blockquote>
<p>大型语言模型（LLMs）显示出理解和执行指令以及生成人类文本方面的显著能力，能够实现超越基本行为复制的复杂代理模拟。然而，创建可自由定制角色的潜力仍未得到充分探索。我们引入了可定制对话代理框架，该框架采用LLMs通过个性化特征注入模拟现实世界角色，根据用户偏好实现多样化角色创建。我们提出了SimsConv数据集，包含68个自定义角色和13971个跨1360个现实场景的多轮角色扮演对话。角色最初使用预定义元素（职业、抱负、特征、技能）进行定制，然后通过个人和社会资料进一步扩展。在此基础上，我们推出了SimsChat，这是一个可自由定制的角色扮演代理，包含各种现实场景和特定话题的角色互动。在SimsConv和WikiRoleEval数据集上的实验结果证明了SimsChat在保持角色一致性、知识准确性和适当问题拒绝方面的优越性能，相比于现有模型。我们的框架为开发更准确、可定制的人类模拟物提供了宝贵的见解。我们的数据和代码可在<a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat%E5%B9%B3%E5%AE%9A%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/Bernard-Yang/SimsChat公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.17962v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLMs）在理解和执行指令以及生成人类文本方面展现出显著的能力，不仅能模仿基本行为，还能模拟复杂的人物行为。然而，创建可自由定制的角色潜力尚未被充分研究。我们引入了可定制对话代理框架，该框架利用LLMs通过个性化特征注入来模拟现实角色，可根据用户偏好创建多样化的角色。我们提出了SimsConv数据集，包含68个自定义角色和13971个跨1360个现实场景的多轮角色扮演对话。角色通过预设元素（职业、抱负、特质、技能）进行初步定制，然后通过个人和社会资料进一步扩展。在此基础上，我们推出了SimsChat，这是一个可自由定制的角色扮演代理，包含各种现实场景和特定话题的角色互动。在SimsConv和WikiRoleEval数据集上的实验结果证明了SimsChat在保持角色一致性、知识准确性和适当的问题拒绝方面的优越性。我们的框架为开发更准确、可定制的人类模拟体提供了有价值的见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）能模拟复杂的人物行为，而创建可自由定制的角色潜力尚未被充分研究。</li>
<li>引入了可定制对话代理框架，利用LLMs模拟现实角色，可创建多样化的角色。</li>
<li>提出了SimsConv数据集，包含自定义角色和跨现实场景的多轮角色扮演对话。</li>
<li>角色通过预设元素进行初步定制，包括职业、抱负、特质、技能等。</li>
<li>SimsChat是一个可自由定制的角色扮演代理，包含各种现实场景和特定话题的角色互动。</li>
<li>SimsChat在保持角色一致性、知识准确性和问题拒绝方面表现出优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.17962">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-37cd1a476799126f3c4861a22a103e45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4c5244b4a9d50e72b6e1124bc10a55a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a3f9e1bd73a42947d50dc059a32ca9b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73b5a27da3fc6d6d2330ffcbf51f834b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63ef47c9f16d71a22cb8865b5943a326.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="GOAL-A-Generalist-Combinatorial-Optimization-Agent-Learner"><a href="#GOAL-A-Generalist-Combinatorial-Optimization-Agent-Learner" class="headerlink" title="GOAL: A Generalist Combinatorial Optimization Agent Learner"></a>GOAL: A Generalist Combinatorial Optimization Agent Learner</h2><p><strong>Authors:Darko Drakulic, Sofia Michel, Jean-Marc Andreoli</strong></p>
<p>Machine Learning-based heuristics have recently shown impressive performance in solving a variety of hard combinatorial optimization problems (COPs). However, they generally rely on a separate neural model, specialized and trained for each single problem. Any variation of a problem requires adjustment of its model and re-training from scratch. In this paper, we propose GOAL (for Generalist combinatorial Optimization Agent Learner), a generalist model capable of efficiently solving multiple COPs and which can be fine-tuned to solve new COPs. GOAL consists of a single backbone plus light-weight problem-specific adapters for input and output processing. The backbone is based on a new form of mixed-attention blocks which allows to handle problems defined on graphs with arbitrary combinations of node, edge and instance-level features. Additionally, problems which involve heterogeneous types of nodes or edges are handled through a novel multi-type transformer architecture, where the attention blocks are duplicated to attend the meaningful combinations of types while relying on the same shared parameters. We train GOAL on a set of routing, scheduling and classic graph problems and show that it is only slightly inferior to the specialized baselines while being the first multi-task model that solves a wide range of COPs. Finally we showcase the strong transfer learning capacity of GOAL by fine-tuning it on several new problems. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/naver/goal-co/">https://github.com/naver/goal-co/</a>. </p>
<blockquote>
<p>基于机器学习的启发式算法最近在解决各种复杂的组合优化问题（COPs）方面表现出了令人印象深刻的性能。然而，它们通常依赖于针对每个单独问题专门设计和训练的神经网络模型。任何问题的变化都需要调整其模型并从头开始重新训练。在本文中，我们提出了GOAL（通用组合优化代理学习者），这是一个通用模型，能够高效地解决多个COPs，并且可以微调以解决新的COPs。GOAL由单个主干加上用于输入和输出处理的轻量级问题特定适配器组成。主干基于一种新的混合注意力块形式，能够处理定义在图上并具有节点、边和实例级特征任意组合的问题。此外，涉及不同类型节点或边的问题是通过一种新型的多类型变压器架构处理的，其中注意力块被复制以关注类型的有意义的组合，同时依赖于相同的共享参数。我们在一组路由、调度和经典图问题上训练GOAL，并展示它略逊于专用基准测试，但它是第一个解决广泛COPs的多任务模型。最后，我们通过在一系列新问题上进行微调，展示了GOAL强大的迁移学习能力。我们的代码可在[<a target="_blank" rel="noopener" href="https://github.com/naver/goal-co/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/naver/goal-co/]上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15079v3">PDF</a> Accepted to ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>机器学习启发式算法在解决组合优化问题上表现出强大的性能，但它们通常针对每个特定问题都需要特定的神经网络模型并进行训练。本文提出一种通用模型GOAL（通用组合优化学习者），能够高效解决多种组合优化问题，并可通过微调适应新问题的求解。GOAL采用单一主干网络加上针对输入输出处理的轻量化问题特定适配器，主干网络基于新型混合注意力块，能够处理具有任意组合节点、边缘和实例级特征的图形定义问题。对于涉及不同类型的节点或边缘的问题，采用新型多类型变换器架构处理。实验证明GOAL在多任务环境下的表现与专门基准模型相当，且具有良好的迁移学习能力。代码已开源在[<a target="_blank" rel="noopener" href="https://github.com/naver/goal-co/]%E4%B8%8A%E3%80%82">https://github.com/naver/goal-co/]上。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>机器学习启发式算法在处理组合优化问题上展现了出色的性能。</li>
<li>现有模型针对每个问题需要单独的神经网络模型进行训练。</li>
<li>GOAL是一种通用模型，可高效解决多种组合优化问题。</li>
<li>GOAL具有微调能力，能适应解决新问题。</li>
<li>GOAL的主干网络采用新型混合注意力块技术，能处理复杂图形问题。</li>
<li>对于涉及不同类型的问题，GOAL采用多类型变换器架构进行处理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15079">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4a3ea764a1743a0a6108f71d6ec7730c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b68b04fbb6423fd47c694f8387b4e2ad.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ebf80ad53a9eeb409480d81dcf1d545c.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-02-27  Multi-Perspective Data Augmentation for Few-shot Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f77f7318064117728c2f612e77128504.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-02-27  LLM-Based Design Pattern Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">16573k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
