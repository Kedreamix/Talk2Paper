<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-02-27  Multi-Perspective Data Augmentation for Few-shot Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ebf80ad53a9eeb409480d81dcf1d545c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-27-更新"><a href="#2025-02-27-更新" class="headerlink" title="2025-02-27 更新"></a>2025-02-27 更新</h1><h2 id="Multi-Perspective-Data-Augmentation-for-Few-shot-Object-Detection"><a href="#Multi-Perspective-Data-Augmentation-for-Few-shot-Object-Detection" class="headerlink" title="Multi-Perspective Data Augmentation for Few-shot Object Detection"></a>Multi-Perspective Data Augmentation for Few-shot Object Detection</h2><p><strong>Authors:Anh-Khoa Nguyen Vu, Quoc-Truong Truong, Vinh-Tiep Nguyen, Thanh Duc Ngo, Thanh-Toan Do, Tam V. Nguyen</strong></p>
<p>Recent few-shot object detection (FSOD) methods have focused on augmenting synthetic samples for novel classes, show promising results to the rise of diffusion models. However, the diversity of such datasets is often limited in representativeness because they lack awareness of typical and hard samples, especially in the context of foreground and background relationships. To tackle this issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework. In terms of foreground-foreground relationships, we propose in-context learning for object synthesis (ICOS) with bounding box adjustments to enhance the detail and spatial information of synthetic samples. Inspired by the large margin principle, support samples play a vital role in defining class boundaries. Therefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in diffusion models, producing hard novel samples. For foreground-background relationships, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the effectiveness of our approach. Our framework significantly outperforms traditional methods, achieving an average increase of $17.5%$ in nAP50 over the baseline on PASCAL VOC. Code is available at <a target="_blank" rel="noopener" href="https://github.com/nvakhoa/MPAD">https://github.com/nvakhoa/MPAD</a>. </p>
<blockquote>
<p>最近，小样本目标检测（FSOD）方法主要集中于增加新类别的合成样本，这预示着扩散模型的兴起。然而，这些数据集在代表性方面往往存在局限性，因为它们没有意识到典型样本和困难样本的存在，特别是在前景和背景关系方面。为了解决这个问题，我们提出了一个多角度数据增强（MPAD）框架。在前景与前景关系方面，我们提出了上下文学习用于目标合成（ICOS），通过调整边界框来增强合成样本的细节和空间信息。受大边界原理的启发，支持样本在定义类别边界方面起着至关重要的作用。因此，我们设计了一种和谐提示聚合调度器（HPAS），在扩散模型的生成过程中每个时间步混合提示嵌入，产生困难的全新样本。对于前景与背景关系，我们引入背景提案方法（BAP）来采样典型的和困难的背景。在多FSOD基准测试上的广泛实验证明了我们方法的有效性。我们的框架显著优于传统方法，在PASCAL VOC基准测试上相对于基线提高了平均17.5%的nAP50指标。代码可以在<a target="_blank" rel="noopener" href="https://github.com/nvakhoa/MPAD">https://github.com/nvakhoa/MPAD</a>找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18195v1">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong><br>     针对少样本目标检测（FSOD）中合成样本代表性不足的问题，提出了一个多视角数据增强（MPAD）框架，包含上下文内学习对象合成（ICOS）、和谐提示聚合调度器（HPAS）和背景提案方法（BAP）。在多个FSOD基准测试中，该方法显著优于传统技术，特别是在PASCAL VOC上，相比基线平均提高了17.5%的nAP50。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FSOD方法侧重于合成新类别的样本以增强数据集多样性。</li>
<li>MPAD框架被提出以解决现有方法中合成样本代表性不足的问题。</li>
<li>引入ICOS方法，通过调整边界框增强合成样本的细节和空间信息，关注前景内部关系。</li>
<li>基于大间隔原则，支持样本在定义类边界中起关键作用，因此设计了HPAS来生成难以区分的样本。</li>
<li>提出BAP方法来采样典型和难以区分的背景，关注前景与背景之间的关系。</li>
<li>MPAD框架在多个FSOD基准测试中表现优异，显著优于传统方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18195">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-47d3ef4f167f41e88613c909b819e9b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93def23f53ae6cc3d2f0389d9afc3f36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6ae700d328102b11fb58931c0d4e754.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebf80ad53a9eeb409480d81dcf1d545c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2ac4f681e12fc52cb5a064e48731f9a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-LLMs-for-Identifying-and-Prioritizing-Important-Medical-Jargons-from-Electronic-Health-Record-Notes-Utilizing-Data-Augmentation"><a href="#Enhancing-LLMs-for-Identifying-and-Prioritizing-Important-Medical-Jargons-from-Electronic-Health-Record-Notes-Utilizing-Data-Augmentation" class="headerlink" title="Enhancing LLMs for Identifying and Prioritizing Important Medical   Jargons from Electronic Health Record Notes Utilizing Data Augmentation"></a>Enhancing LLMs for Identifying and Prioritizing Important Medical   Jargons from Electronic Health Record Notes Utilizing Data Augmentation</h2><p><strong>Authors:Won Seok Jang, Sharmin Sultana, Zonghai Yao, Hieu Tran, Zhichao Yang, Sunjae Kwon, Hong Yu</strong></p>
<p>OpenNotes enables patients to access EHR notes, but medical jargon can hinder comprehension. To improve understanding, we evaluated closed- and open-source LLMs for extracting and prioritizing key medical terms using prompting, fine-tuning, and data augmentation. We assessed LLMs on 106 expert-annotated EHR notes, experimenting with (i) general vs. structured prompts, (ii) zero-shot vs. few-shot prompting, (iii) fine-tuning, and (iv) data augmentation. To enhance open-source models in low-resource settings, we used ChatGPT for data augmentation and applied ranking techniques. We incrementally increased the augmented dataset size (10 to 10,000) and conducted 5-fold cross-validation, reporting F1 score and Mean Reciprocal Rank (MRR). Our result show that fine-tuning and data augmentation improved performance over other strategies. GPT-4 Turbo achieved the highest F1 (0.433), while Mistral7B with data augmentation had the highest MRR (0.746). Open-source models, when fine-tuned or augmented, outperformed closed-source models. Notably, the best F1 and MRR scores did not always align. Few-shot prompting outperformed zero-shot in vanilla models, and structured prompts yielded different preferences across models. Fine-tuning improved zero-shot performance but sometimes degraded few-shot performance. Data augmentation performed comparably or better than other methods. Our evaluation highlights the effectiveness of prompting, fine-tuning, and data augmentation in improving model performance for medical jargon extraction in low-resource scenarios. </p>
<blockquote>
<p>OpenNotes使患者能够访问电子健康记录（EHR）笔记，但医学术语可能会妨碍理解。为了改善理解，我们评估了闭源和开源的大型语言模型（LLMs），通过提示、微调和数据增强来提取和优先排序关键医学术语。我们在106份专家标注的EHR笔记上评估了LLMs，尝试了（i）通用提示与结构化提示，（ii）零样本提示与少样本提示，（iii）微调，以及（iv）数据增强。为了在低资源环境中增强开源模型，我们使用ChatGPT进行数据增强并应用排名技术。我们逐步增加了增强数据集的大小（从10到10,000），进行了5折交叉验证，并报告了F1分数和平均倒数排名（MRR）。结果表明，微调和数据增强在性能上优于其他策略。GPT-4 Turbo获得了最高的F1分数（0.433），而Mistral7B通过数据增强获得了最高的MRR（0.746）。当开源模型进行微调或数据增强时，其性能超过了闭源模型。值得注意的是，最佳的F1分数和MRR并不总是相符。少样本提示在原始模型中表现优于零样本提示，结构化提示在不同模型之间产生不同的偏好。微调可以提高零样本性能，但有时会降低少样本性能。数据增强的表现与其他方法相当或更好。我们的评估强调了提示、微调和数据增强在提高低资源场景下医学术语提取模型性能方面的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16022v2">PDF</a> 21pages, 5 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>该文本探讨了利用大型语言模型（LLMs）帮助患者理解电子健康记录（EHR）笔记中医疗术语的方法。实验评估了不同策略，包括提示、微调、数据增强等，以提高模型在提取和优先展示关键医疗术语方面的性能。实验结果表明，微调和数据增强可以提高性能，且在不同模型中表现各有优势。此外，开源模型在资源有限的情况下表现较好。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）可用于帮助患者理解电子健康记录（EHR）笔记中的医疗术语。</li>
<li>实验中评估了提示、微调、数据增强等策略在提取和优先展示关键医疗术语方面的效果。</li>
<li>微调和数据增强能提高模型性能。</li>
<li>GPT-4 Turbo在F1得分上表现最佳，而Mistral7B在数据增强后的Mean Reciprocal Rank（MRR）上表现最佳。</li>
<li>开源模型在资源有限的情况下表现较好，当进行微调或数据增强时，其性能超过封闭源模型。</li>
<li>最好的F1和MRR得分并不总是对齐，说明不同评估指标可能具有不同的侧重点。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16022">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-3cc94d906f01a782553143dd3eb1da1f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-35740911d587ff17db7d6bc11781608c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f51ce4c78a0ef5f740f0d06fe9761fc5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26da0512aecf25bd3998960496ea89c8.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Transforming-Role-Classification-in-Scientific-Teams-Using-LLMs-and-Advanced-Predictive-Analytics"><a href="#Transforming-Role-Classification-in-Scientific-Teams-Using-LLMs-and-Advanced-Predictive-Analytics" class="headerlink" title="Transforming Role Classification in Scientific Teams Using LLMs and   Advanced Predictive Analytics"></a>Transforming Role Classification in Scientific Teams Using LLMs and   Advanced Predictive Analytics</h2><p><strong>Authors:Wonduk Seo, Yi Bu</strong></p>
<p>Scientific team dynamics are critical in determining the nature and impact of research outputs. However, existing methods for classifying author roles based on self-reports and clustering lack comprehensive contextual analysis of contributions. Thus, we present a transformative approach to classifying author roles in scientific teams using advanced large language models (LLMs), which offers a more refined analysis compared to traditional clustering methods. Specifically, we seek to complement and enhance these traditional methods by utilizing open source and proprietary LLMs, such as GPT-4, Llama3 70B, Llama2 70B, and Mistral 7x8B, for role classification. Utilizing few-shot prompting, we categorize author roles and demonstrate that GPT-4 outperforms other models across multiple categories, surpassing traditional approaches such as XGBoost and BERT. Our methodology also includes building a predictive deep learning model using 10 features. By training this model on a dataset derived from the OpenAlex database, which provides detailed metadata on academic publications – such as author-publication history, author affiliation, research topics, and citation counts – we achieve an F1 score of 0.76, demonstrating robust classification of author roles. </p>
<blockquote>
<p>科研团队的动态在决定研究成果的性质和影响方面至关重要。然而，现有的基于自我报告和聚类的作者角色分类方法缺乏对贡献的全面上下文分析。因此，我们提出了一种利用先进的大型语言模型（LLMs）对科研团队中的作者角色进行分类的变革性方法，相比传统的聚类方法，它提供了更为精细的分析。具体来说，我们希望通过利用开源和专有的大型语言模型（如GPT-4、Llama 3 70B、Llama 2 70B和Mistral 7x8B）来分类角色，以补充和增强这些传统方法。通过少量提示，我们对作者角色进行分类，并证明GPT-4在多类别中表现优于其他模型，超越了如XGBoost和BERT等传统方法。我们的方法还包括建立一个基于深度学习的预测模型，使用10个特征进行训练。通过在OpenAlex数据库衍生的数据集上训练该模型，该数据库提供了关于学术出版物（如作者出版历史、作者隶属关系、研究主题和引用计数等）的详细元数据，我们实现了F1分数为0.76，证明了作者角色分类的稳健性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07267v3">PDF</a> Accepted by Quantitative Science Studies (QSS)</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种利用大型语言模型（LLMs）对科研团队作者角色进行分类的创新方法。该方法通过利用GPT-4、Llama3 70B等先进LLMs进行精细化分析，弥补了传统聚类方法的不足。通过少量提示进行角色分类，并展示了GPT-4在多个类别中的优越性。此外，研究还建立了一个基于深度学习的预测模型，在OpenAlex数据库提供的详细元数据上训练，实现了作者角色分类的稳健性，F1分数达到0.76。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>作者角色分类对科研团队动力及研究产出影响重大。</li>
<li>现有作者角色分类方法基于自我报告和聚类，缺乏全面贡献分析。</li>
<li>采用大型语言模型（LLMs）进行作者角色分类是一种创新方法。</li>
<li>GPT-4在多个类别中表现出优秀的角色分类性能。</li>
<li>研究建立了基于深度学习的预测模型，使用10个特征进行训练。</li>
<li>训练模型采用OpenAlex数据库提供的详细元数据，实现稳健的作者角色分类。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07267">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-48d7104f8458fc3d0d86e98ccf4b453c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7004172d9fb6699b9a6091ca0d081d94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5617eb243b81c147dba300cef9fd59cf.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multimodality-Helps-Few-shot-3D-Point-Cloud-Semantic-Segmentation"><a href="#Multimodality-Helps-Few-shot-3D-Point-Cloud-Semantic-Segmentation" class="headerlink" title="Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation"></a>Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation</h2><p><strong>Authors:Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie</strong></p>
<p>Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models to segment novel categories with minimal annotated support samples. While existing FS-PCS methods have shown promise, they primarily focus on unimodal point cloud inputs, overlooking the potential benefits of leveraging multimodal information. In this paper, we address this gap by introducing a multimodal FS-PCS setup, utilizing textual labels and the potentially available 2D image modality. Under this easy-to-achieve setup, we present the MultiModal Few-Shot SegNet (MM-FSS), a model effectively harnessing complementary information from multiple modalities. MM-FSS employs a shared backbone with two heads to extract intermodal and unimodal visual features, and a pretrained text encoder to generate text embeddings. To fully exploit the multimodal information, we propose a Multimodal Correlation Fusion (MCF) module to generate multimodal correlations, and a Multimodal Semantic Fusion (MSF) module to refine the correlations using text-aware semantic guidance. Additionally, we propose a simple yet effective Test-time Adaptive Cross-modal Calibration (TACC) technique to mitigate training bias, further improving generalization. Experimental results on S3DIS and ScanNet datasets demonstrate significant performance improvements achieved by our method. The efficacy of our approach indicates the benefits of leveraging commonly-ignored free modalities for FS-PCS, providing valuable insights for future research. The code is available at <a target="_blank" rel="noopener" href="https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot">https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot</a> </p>
<blockquote>
<p>少量数据下的3D点云分割（FS-PCS）旨在通过最少的标注支持样本对新型类别进行模型泛化。虽然现有的FS-PCS方法已经显示出潜力，但它们主要关注单模态点云输入，忽略了利用多模态信息可能带来的潜在好处。针对这一问题，本文引入了一种多模态FS-PCS设置，利用文本标签和可用的2D图像模态。在这个易于实现的设置下，我们提出了多模态少量射击SegNet（MM-FSS），该模型能够有效地利用多模态的互补信息。MM-FSS采用共享主干和两个头来提取跨模态和单模态视觉特征，并使用预训练的文本编码器生成文本嵌入。为了充分利用多模态信息，我们提出了多模态关联融合（MCF）模块来生成多模态关联，以及多模态语义融合（MSF）模块，利用文本感知语义指导来优化关联。此外，我们还提出了一种简单有效的测试时自适应跨模态校准（TACC）技术，以减轻训练偏见，进一步提高泛化能力。在S3DIS和ScanNet数据集上的实验结果表明，我们的方法取得了显著的性能改进。我们的方法的有效性表明了利用常被忽略的免费模态对FS-PCS的益处，为未来研究提供了有价值的见解。代码可用在<a target="_blank" rel="noopener" href="https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot%E3%80%82">https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.22489v3">PDF</a> Published at ICLR 2025 (Spotlight)</p>
<p><strong>Summary</strong></p>
<p>本文介绍了少样本3D点云分割（FS-PCS）的新挑战，即如何利用有限的标注样本对新型类别进行分割。现有FS-PCS方法主要关注单一模式的点云输入，忽视了多模态信息的潜在优势。为解决此问题，本文提出了多模态FS-PCS设置，并利用文本标签和可用的2D图像模式。基于此设置，提出了MultiModal Few-Shot SegNet（MM-FSS）模型，该模型能有效利用多模态的互补信息。实验结果表明，该方法在S3DIS和ScanNet数据集上的性能显著提高。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本文介绍了少样本3D点云分割（FS-PCS）的挑战，即如何对新型类别进行分割，仅使用有限的标注样本。</li>
<li>现有FS-PCS方法主要关注单一模式的点云输入，忽视了多模态信息的优势。</li>
<li>为解决此问题，本文提出了多模态FS-PCS设置，结合文本标签和2D图像模式。</li>
<li>提出了MultiModal Few-Shot SegNet（MM-FSS）模型，该模型能利用多种模态的互补信息。</li>
<li>MM-FSS模型包含用于提取跨模态和单模态视觉特征的共享骨架和两个头，以及用于生成文本嵌入的预训练文本编码器。</li>
<li>提出了Multimodal Correlation Fusion（MCF）模块和Multimodal Semantic Fusion（MSF）模块，以充分利用多模态信息并优化关联。</li>
<li>本文还提出了一种简单的Test-time Adaptive Cross-modal Calibration（TACC）技术，以减轻训练偏见，进一步提高模型的泛化能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.22489">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c35616db51de3c37d366b3a5fbbe671d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34e1d87a672b2ab72f358652d60ab31e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-966d105562dd589f0a4bc4c602a2b221.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Implicit-In-context-Learning"><a href="#Implicit-In-context-Learning" class="headerlink" title="Implicit In-context Learning"></a>Implicit In-context Learning</h2><p><strong>Authors:Zhuowei Li, Zihao Xu, Ligong Han, Yunhe Gao, Song Wen, Di Liu, Hao Wang, Dimitris N. Metaxas</strong></p>
<p>In-context Learning (ICL) empowers large language models (LLMs) to swiftly adapt to unseen tasks at inference-time by prefixing a few demonstration examples before queries. Despite its versatility, ICL incurs substantial computational and memory overheads compared to zero-shot learning and is sensitive to the selection and order of demonstration examples. In this work, we introduce Implicit In-context Learning (I2CL), an innovative paradigm that reduces the inference cost of ICL to that of zero-shot learning with minimal information loss. I2CL operates by first generating a condensed vector representation, namely a context vector, extracted from the demonstration examples. It then conducts an inference-time intervention through injecting a linear combination of the context vector and query activations back into the model’s residual streams. Empirical evaluation on nine real-world tasks across three model architectures demonstrates that I2CL achieves few-shot level performance at zero-shot inference cost, and it exhibits robustness against variations in demonstration examples. Furthermore, I2CL facilitates a novel representation of task-ids, enhancing task similarity detection and fostering effective transfer learning. We also perform a comprehensive analysis and ablation study on I2CL, offering deeper insights into its internal mechanisms. Code is available at <a target="_blank" rel="noopener" href="https://github.com/LzVv123456/I2CL">https://github.com/LzVv123456/I2CL</a>. </p>
<blockquote>
<p>上下文学习（ICL）通过在前缀查询之前提供少量示例，使大型语言模型（LLM）能够迅速适应推理时间未见的任务。尽管其通用性很强，但与零样本学习相比，ICL产生了大量的计算和内存开销，并且对示例的选择和顺序很敏感。在这项工作中，我们引入了隐上下文学习（I2CL）这一创新范式，它通过生成从示例中提取的浓缩向量表示（即上下文向量）来减少ICL的推理成本，几乎没有任何信息损失。然后，I2CL通过在模型残差流中注入上下文向量和查询激活的线性组合来进行推理时间干预。在三个模型架构的九个真实任务上的经验评估表明，I2CL以零样本推理成本实现了小样本级别的性能，并且对示例变化表现出稳健性。此外，I2CL促进了任务ID的新表示，增强了任务相似性检测，并促进了有效的迁移学习。我们还对I2CL进行了全面的分析和消融研究，对其内部机制提供了更深入的了解。代码可访问 <a target="_blank" rel="noopener" href="https://github.com/LzVv123456/I2CL%E3%80%82">https://github.com/LzVv123456/I2CL。</a></p>
</blockquote>
<p><strong>简化版翻译</strong></p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14660v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>隐式上下文学习（I2CL）是一种减少上下文学习（ICL）推理成本的方法，将推理成本降低到零样本学习的水平，同时保持少样本级别的性能。它通过将演示示例生成的上下文向量注入到模型的残差流中来实现。这种方法对演示示例的选择和顺序具有鲁棒性，并促进了任务标识符的新表示，增强了任务相似性检测和有效迁移学习。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>I2CL是一种减少ICL推理成本的方法，达到零样本学习的水平。</li>
<li>I2CL通过生成演示示例的上下文向量实现推理时间的干预。</li>
<li>I2CL保持了少样本级别的性能，对演示示例的选择和顺序具有鲁棒性。</li>
<li>I2CL促进任务标识符的新表示，增强任务相似性检测和迁移学习。</li>
<li>I2CL在九个真实任务、三种模型架构上的实证评估表现出其有效性。</li>
<li>I2CL提供了任务内部机制的深入分析和消融研究。</li>
<li>代码已公开在GitHub上。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.14660">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-265b58a03e967fe84dd61fc19b0af4b7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3fea0c6f606343ccb174d01ab6615f83.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e668f7106bfb73c6ae45f668e30b623d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3f0c2f7dbbfce15c94af1475bf42901.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d1f9cd8f223b01879de7fb36c5fd76f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Are-Chatbots-Reliable-Text-Annotators-Sometimes"><a href="#Are-Chatbots-Reliable-Text-Annotators-Sometimes" class="headerlink" title="Are Chatbots Reliable Text Annotators? Sometimes"></a>Are Chatbots Reliable Text Annotators? Sometimes</h2><p><strong>Authors:Ross Deans Kristensen-McLachlan, Miceal Canavan, Márton Kardos, Mia Jacobsen, Lene Aarøe</strong></p>
<p>Recent research highlights the significant potential of ChatGPT for text annotation in social science research. However, ChatGPT is a closed-source product which has major drawbacks with regards to transparency, reproducibility, cost, and data protection. Recent advances in open-source (OS) large language models (LLMs) offer an alternative without these drawbacks. Thus, it is important to evaluate the performance of OS LLMs relative to ChatGPT and standard approaches to supervised machine learning classification. We conduct a systematic comparative evaluation of the performance of a range of OS LLMs alongside ChatGPT, using both zero- and few-shot learning as well as generic and custom prompts, with results compared to supervised classification models. Using a new dataset of tweets from US news media, and focusing on simple binary text annotation tasks, we find significant variation in the performance of ChatGPT and OS models across the tasks, and that the supervised classifier using DistilBERT generally outperforms both. Given the unreliable performance of ChatGPT and the significant challenges it poses to Open Science we advise caution when using ChatGPT for substantive text annotation tasks. </p>
<blockquote>
<p>最近的研究强调了ChatGPT在社会科学研究中文本标注的巨大潜力。然而，ChatGPT是一个闭源产品，在透明度、可重复性、成本和数据保护方面存在重大缺陷。开源（OS）大型语言模型（LLM）的最新进展提供了一种没有这些缺陷的替代方案。因此，评估OS LLM相对于ChatGPT和传统监督学习分类方法的性能表现至关重要。我们进行了一项系统的比较评估，使用一系列OS LLM与ChatGPT进行对照，采用零次和少次学习以及通用和自定义提示，并将结果与监督分类模型进行比较。我们使用美国新闻媒体推文的新数据集，专注于简单的二元文本标注任务，发现ChatGPT和OS模型在各项任务中的性能存在显著差异，而使用DistilBERT的监督分类器通常表现最佳。鉴于ChatGPT的不稳定性能和给开源科学带来的重大挑战，我们建议在实质性文本标注任务中使用ChatGPT时要谨慎。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05769v2">PDF</a> Accepted for publication in PNAS Nexus (accepted Feb. 2025)</p>
<p><strong>Summary</strong></p>
<p>ChatGPT在社会科学研究中的文本标注潜力显著，但作为闭源产品，其在透明度、可复现性、成本和数据保护等方面存在重大缺陷。开源大型语言模型（LLMs）的最近进展提供了一种没有这些缺陷的替代方案。本文系统评价了开源LLMs与ChatGPT及传统监督机器学习分类方法的性能，通过零样本和少样本学习、通用和自定义提示进行了评估，并将结果与使用DistilBERT的监督分类模型进行了比较。研究表明，在不同任务中，ChatGPT和开源模型的性能存在显著差异，而DistilBERT监督分类器通常表现最佳。鉴于ChatGPT的不稳定性能和给开放科学带来的挑战，建议在使用ChatGPT进行实质性文本标注任务时保持谨慎。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ChatGPT在文本标注任务中展现出潜力，但存在透明度、可复现性、成本和数据保护等重大问题。</li>
<li>开源大型语言模型（LLMs）提供了一个替代方案，没有上述缺陷。</li>
<li>系统比较了开源LLMs、ChatGPT和监督机器学习分类方法的性能。</li>
<li>使用新推特数据集进行试验，专注于简单的二元文本标注任务。</li>
<li>在不同任务中，ChatGPT和开源模型的性能存在显著差异。</li>
<li>DistilBERT监督分类器通常表现最佳。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.05769">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-863cce111a2331e404f68ffff16871b7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-27/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-12428cc3e07c0c98e919a47ff833ffe8.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-02-27  CheXalign Preference fine-tuning in chest X-ray interpretation models   without human feedback
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-27/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-08e2895a318dd12f07ce9551d82799a5.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-02-27  AgentRM Enhancing Agent Generalization with Reward Modeling
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">24474.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
