<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-03-06  Federated Learning for Privacy-Preserving Feedforward Control in   Multi-Agent Systems">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-33f5731f87983614ccc75d058787baab.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    57 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-06-更新"><a href="#2025-03-06-更新" class="headerlink" title="2025-03-06 更新"></a>2025-03-06 更新</h1><h2 id="Federated-Learning-for-Privacy-Preserving-Feedforward-Control-in-Multi-Agent-Systems"><a href="#Federated-Learning-for-Privacy-Preserving-Feedforward-Control-in-Multi-Agent-Systems" class="headerlink" title="Federated Learning for Privacy-Preserving Feedforward Control in   Multi-Agent Systems"></a>Federated Learning for Privacy-Preserving Feedforward Control in   Multi-Agent Systems</h2><p><strong>Authors:Jakob Weber, Markus Gurtner, Benedikt Alt, Adrian Trachte, Andreas Kugi</strong></p>
<p>Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability. However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs. Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges. This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data. By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability. We demonstrate the effectiveness of our method in an autonomous driving use case. Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control. Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control. We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control. Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications. </p>
<blockquote>
<p>前馈控制（FF）在许多控制系统中经常与反馈控制（FB）相结合，提高了跟踪性能、效率和稳定性。然而，在多智能体系统中设计有效的数据驱动FF控制器需要大量的数据采集，包括传输私有或专有数据，这引发了隐私担忧并产生了高昂的通信成本。因此，我们提出了一种将联邦学习（FL）集成到FF控制中来解决这些挑战的新方法。该方法能够在不共享个人或专有数据的情况下，实现隐私保护、通信高效、分散式的FF控制器持续改进。通过利用联邦学习，每个智能体使用其数据学习本地神经FF控制器，并为全局聚合过程提供模型更新，从而确保数据隐私和可扩展性。我们通过自动驾驶用例展示了该方法的有效性。其中，配备轨迹跟踪反馈控制器的车辆通过基于联邦学习的神经FF控制得到增强。模拟结果表明，与纯FB控制相比，跟踪性能得到了显著提高，类似于基于模型的FF控制。与集中式神经FF控制相比，我们在不交换私有车辆特定数据的情况下实现了相当的跟踪性能。我们的结果强调了基于联邦学习的神经FF控制的潜力，能够在多智能体控制系统中实现隐私保护学习，为可扩展和高效的自主系统应用铺平道路。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02693v1">PDF</a> Submitted to IJCNN 2025</p>
<p><strong>Summary</strong></p>
<p>基于联邦学习（Federated Learning，简称FL）的前馈控制（Feedforward Control，简称FF）是一个新颖的方法，它在多智能体系统中解决了隐私和通信成本的问题，实现了隐私保护、通信高效的FF控制器持续改进。该方法利用联邦学习，使每个智能体使用其数据学习本地神经FF控制器，并仅将模型更新贡献给全局聚合过程，确保了数据隐私和可扩展性。在自动驾驶用例中，配备了轨迹跟踪反馈控制器的车辆通过基于联邦学习的神经FF控制得到增强。模拟结果表明，与纯反馈控制相比，跟踪性能得到显著改善，与基于模型的FF控制相当。在不交换私有车辆特定数据的情况下，与集中式神经FF控制相比，我们实现了相当的跟踪性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>联邦学习与前馈控制的结合，能够在多智能体系统中改善跟踪性能、效率和稳定性。</li>
<li>新的方法解决了设计数据驱动FF控制器时的隐私和通信成本挑战。</li>
<li>通过联邦学习，每个智能体使用其数据学习本地神经FF控制器，确保数据隐私。</li>
<li>仅在全局聚合过程中贡献模型更新，提高系统的可扩展性。</li>
<li>在自动驾驶应用中，基于联邦学习的神经FF控制显著提高了车辆的轨迹跟踪性能。</li>
<li>模拟结果与基于模型的FF控制相当，但无需交换私有数据。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02693">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-091461718423013de744092a318323dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0d2b43b8f5a537b3134cf1af6fea147.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99324ba8be4a5451da310b2a0938bf04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6a598fbf281e857bc0d7876a2a1e70fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f949aae892449eec2e6cf6fd4a25945.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b220fd96cded0c971f75a14d4c78c60.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e1508b80bde01136b086bd98cad44030.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36bc1f0e5d956104a4a429e1cb727106.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FinArena-A-Human-Agent-Collaboration-Framework-for-Financial-Market-Analysis-and-Forecasting"><a href="#FinArena-A-Human-Agent-Collaboration-Framework-for-Financial-Market-Analysis-and-Forecasting" class="headerlink" title="FinArena: A Human-Agent Collaboration Framework for Financial Market   Analysis and Forecasting"></a>FinArena: A Human-Agent Collaboration Framework for Financial Market   Analysis and Forecasting</h2><p><strong>Authors:Congluo Xu, Zhaobin Liu, Ziyang Li</strong></p>
<p>To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework. Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction. The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies. The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements. To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data. Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors’ individual risk preferences. Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles. These findings highlight FinArena’s potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations. </p>
<blockquote>
<p>本文提出了一个名为FinArena的新型人机协作框架，旨在改进股票趋势预测并支持个性化的投资决策。受专家混合（MoE）方法的启发，FinArena结合了多模式财务分析与用户交互。人类模块具有一个交互式界面，可以捕捉个人的风险偏好，从而允许制定个性化的投资策略。机器模块利用基于大型语言模型（LLM）的多代理系统来整合各种数据源，如股票价格、新闻文章和财务报表。为了解决大型语言模型中的虚构问题，FinArena采用自适应检索增强生成（RAG）方法处理非结构化新闻数据。最后，一个通用专家代理根据从多模式数据中提取的特征以及投资者的个人风险偏好做出投资决策。大量实验表明，在股票趋势预测方面，FinArena超越了传统和最新的基准测试，并在各种风险概况的交易模拟中产生了有希望的结果。这些发现强调了FinArena的潜力，即通过战略见解与个性化的风险考量来提高投资结果。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02692v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>FinArena是受到专家组合（MoE）方法启发的一种新型人机协作框架，旨在改进股票趋势预测并支持个性化投资决策。它结合了多模式财务数据分析与用户互动，包含人机两个模块。人类模块通过交互界面捕捉个人风险偏好，允许制定个性化投资策略。机器模块则基于大型语言模型（LLM）的多智能体系统，整合股票行情、新闻报道和财务报表等多种数据来源。为解决LLM中的虚构问题，FinArena采用自适应检索增强生成（RAG）方法处理非结构化新闻数据。最终，一个通用专家智能体基于从多模式数据中提取的特征和个人投资者的风险偏好做出投资决策。研究表明，FinArena在股票趋势预测方面超越了传统和最新技术基准，并在各种风险概况的交易模拟中取得了令人鼓舞的结果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FinArena是一个新型人机协作框架，结合了多模式财务数据分析与用户互动，用于改进股票趋势预测并支持个性化投资决策。</li>
<li>它包含人机两个模块，人类模块捕捉个人风险偏好，机器模块整合多种数据来源。</li>
<li>FinArena采用自适应检索增强生成（RAG）方法处理非结构化新闻数据，以解决LLM中的虚构问题。</li>
<li>通用专家智能体基于从多模式数据中提取的特征和个人投资者的风险偏好做出投资决策。</li>
<li>研究表明，FinArena在股票趋势预测方面表现出卓越性能，超越了传统和最新技术基准。</li>
<li>FinArena在交易模拟中取得了令人鼓舞的结果，展现了其在各种风险概况下的潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02692">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-31ab1c1f3ccd058c934cf5af4b593bbd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0b255139ccd59b4dba9280054349557b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af9c5754029aabc7eab1e45f3a6e2e63.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MPO-Boosting-LLM-Agents-with-Meta-Plan-Optimization"><a href="#MPO-Boosting-LLM-Agents-with-Meta-Plan-Optimization" class="headerlink" title="MPO: Boosting LLM Agents with Meta Plan Optimization"></a>MPO: Boosting LLM Agents with Meta Plan Optimization</h2><p><strong>Authors:Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, Xun Wang, Sujian Li</strong></p>
<p>Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent’s task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios. </p>
<blockquote>
<p>近期，大型语言模型（LLM）的进步使得基于LLM的代理能够成功处理交互规划任务。然而，尽管已经取得了一些成功，现有方法仍然经常受到规划幻觉的影响，并且需要为每个新代理进行再训练。为了解决这些挑战，我们提出了元计划优化（MPO）框架，它通过直接融入明确的指导来增强代理的规划能力。与其他依赖复杂知识的方法不同，这些方法需要大量的人力投入或缺乏质量保证，MPO通过元计划提供高级一般指导来协助代理规划，并根据代理任务执行的反馈持续优化元计划。我们在两个代表性任务上进行的实验表明，MPO显著优于现有基线。此外，我们的分析表明，MPO提供了一种即插即用的解决方案，提高了任务完成效率和在未见过场景中的泛化能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02682v1">PDF</a> </p>
<p><strong>总结</strong></p>
<p>近期大型语言模型（LLM）在交互规划任务上的进展显著，但现有方法常常面临规划幻觉的问题，并为每个新代理需要重训。为解决这些挑战，提出了Meta Plan Optimization（MPO）框架，通过直接引入明确指导来提升代理规划能力。不同于依赖复杂知识的旧方法，MPO利用高级通用指导通过元计划协助代理规划，并基于代理任务执行的反馈持续优化元计划。在两项代表性任务上的实验表明，MPO显著优于现有基线。分析显示，MPO提供了即插即用的解决方案，提高了任务完成效率和在未见过场景中的泛化能力。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLM）在交互规划任务上取得显著进展。</li>
<li>现有方法面临规划幻觉的问题，需要为每个新代理进行重训。</li>
<li>MPO框架通过直接引入明确指导提升代理规划能力。</li>
<li>MPO利用高级通用指导通过元计划协助代理规划。</li>
<li>MPO能够基于代理任务执行的反馈持续优化元计划。</li>
<li>在两项代表性任务上，MPO显著优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02682">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-dffdb007490f1ead707e2662ca6d474b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a085ff4985f81a46ddd595ad6ce9650.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-514d5b04ae30d954a24dc7225b826964.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7a0ccd7791530e56776b4a235e3a041.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ef8c9144d5cec04d075aed378184f6f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Generator-Assistant-Stepwise-Rollback-Framework-for-Large-Language-Model-Agent"><a href="#Generator-Assistant-Stepwise-Rollback-Framework-for-Large-Language-Model-Agent" class="headerlink" title="Generator-Assistant Stepwise Rollback Framework for Large Language Model   Agent"></a>Generator-Assistant Stepwise Rollback Framework for Large Language Model   Agent</h2><p><strong>Authors:Xingzuo Li, Kehai Chen, Yunfei Long, Xuefeng Bai, Yong Xu, Min Zhang</strong></p>
<p>Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods. </p>
<blockquote>
<p>大型语言模型（LLM）代理通常采用一种逐步推理框架，在该框架中，它们将思考和行动的过程交织在一起，以完成给定的任务。然而，这种范式面临一个根深蒂固的一次性通过问题，即无论中间想法的正确与否，都会将其插入轨迹中，这可能导致不可逆的错误传播。为了解决这一问题，本文提出了一种名为Generator-Assistant Stepwise Rollback（GA-Rollback）的新型框架，以引导LLM代理做出更好的决策。特别是，GA-Rollback利用生成器与环境进行交互，并利用助理检查生成器产生的每个动作，当助理检测到不正确的动作时，会触发回滚操作。此外，我们引入了两种针对回滚场景的额外策略，以进一步提高其有效性。大量实验表明，GA-Rollback在三个广泛使用的基准测试上优于多个强大的基线模型。我们的分析还表明，GA-Rollback可以作为一个强大的即插即用模块，与其他方法无缝集成。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02519v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>新一代大型语言模型（LLM）代理采用逐步推理框架，但存在一次通过问题，可能导致错误不可逆地传播。为解决这一问题，本文提出了名为Generator-Assistant Stepwise Rollback（GA-Rollback）的新型框架，旨在实现更好的决策制定。GA-Rollback通过生成器与环境交互，并利用助理检查生成器的每个动作，并在检测到错误动作时触发回滚操作。此外，还引入两种针对回滚场景的策略以提高其有效性。实验表明，GA-Rollback在三个广泛使用的基准测试上优于多个强大的基线模型。分析表明，GA-Rollback可作为强大的即插即用模块与其他方法无缝集成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理采用逐步推理框架，但存在错误传播问题。</li>
<li>GA-Rollback框架旨在解决这一问题，包括生成器、助理以及回滚机制。</li>
<li>生成器与环境交互，助理检查每个动作，错误动作会触发回滚操作。</li>
<li>引入两种策略以提高回滚机制的有效性。</li>
<li>实验证明，GA-Rollback在多个基准测试上表现优于现有模型。</li>
<li>GA-Rollback可作为强大的插件与其他方法无缝集成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02519">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a847e014565dab06d6e490113cfcbb15.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b82006f12ff1675a9bfae6c53113f654.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e651f69779712bb9d217572d19509bd5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-78c320d48c7dee25782a8690d989b8c6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BRIDGE-Bootstrapping-Text-to-Control-Time-Series-Generation-via-Multi-Agent-Iterative-Optimization-and-Diffusion-Modelling"><a href="#BRIDGE-Bootstrapping-Text-to-Control-Time-Series-Generation-via-Multi-Agent-Iterative-Optimization-and-Diffusion-Modelling" class="headerlink" title="BRIDGE: Bootstrapping Text to Control Time-Series Generation via   Multi-Agent Iterative Optimization and Diffusion Modelling"></a>BRIDGE: Bootstrapping Text to Control Time-Series Generation via   Multi-Agent Iterative Optimization and Diffusion Modelling</h2><p><strong>Authors:Hao Li, Yu-Hao Huang, Chang Xu, Viktor Schlegel, Ren-He Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</strong></p>
<p>Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce &#96;&#96;Text-Controlled TSG’’, a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data. </p>
<blockquote>
<p>时间序列生成（TSG）是一个具有广泛应用前景的重要研究领域，如模拟、数据增强和假设分析等领域。虽然现有方法在无条件单域TSG方面表现出一定潜力，但现实世界的应用需求需要跨域方法，能够针对特定领域的约束和实例级需求进行受控生成。在本文中，我们主张文本可以提供语义洞察、领域信息和实例特定的时间模式，以指导和改进TSG。我们引入了“文本控制TSG”，这是一个通过融入文本描述来生成真实时间序列的任务。为了解决此场景下的数据稀缺问题，我们提出了一个基于大型语言模型的多智能体框架，该框架可以合成多样且真实的文本到时间序列数据集。此外，我们还引入了BRIDGE，一个混合文本控制TSG框架，它将语义原型与文本描述相结合，以支持领域级的指导。该方法在12个数据集中的11个数据集上实现了最先进的生成保真度，并且在均方误差（MSE）和平均绝对误差（MAE）方面，与无文本输入生成相比，可控性提高了12.52%和6.34%，突显其在生成定制时间序列数据方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02445v1">PDF</a> Preprint. Work in progress</p>
<p><strong>Summary</strong><br>时间序列生成（TSG）是模拟、数据增强和反向事实分析等领域的重要研究方向。现有方法主要关注无条件单一领域的TSG，但实际应用需要跨领域的生成方法，以满足特定领域的约束和实例级需求。本文提出“文本控制时间序列生成（Text-Controlled TSG）”任务，旨在通过引入文本描述来生成真实的时间序列数据。为解决数据稀缺问题，我们提出了一种基于大型语言模型的多智能体框架，合成多样且真实的文本到时间序列数据集。此外，我们引入了混合文本控制TSG框架BRIDGE，它将语义原型与文本描述相结合，为领域级指导提供支持。该方法在12个数据集中有11个达到了最先进的生成保真度，并且在均方误差和平均绝对误差方面分别提高了12.52%和6.34%，显示出其在生成定制时间序列数据方面的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>时间序列生成（TSG）是模拟、数据增强和反向事实分析的关键研究方向。</li>
<li>现有方法主要关注无条件单一领域的TSG，缺乏满足跨领域约束和实例级需求的生成方法。</li>
<li>本文提出了“文本控制时间序列生成（Text-Controlled TSG）”任务，通过引入文本描述来生成真实的时间序列数据。</li>
<li>为解决数据稀缺问题，研究提出了一种基于大型语言模型的多智能体框架。</li>
<li>引入的混合文本控制TSG框架BRIDGE结合了语义原型与文本描述，为领域级指导提供支持。</li>
<li>该方法在多个数据集上达到了最先进的生成效果，提高了生成数据的真实性和可控性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02445">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4543e2fb0217891b41ef3d9edb4c0587.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33f5731f87983614ccc75d058787baab.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="AutoEval-A-Practical-Framework-for-Autonomous-Evaluation-of-Mobile-Agents"><a href="#AutoEval-A-Practical-Framework-for-Autonomous-Evaluation-of-Mobile-Agents" class="headerlink" title="AutoEval: A Practical Framework for Autonomous Evaluation of Mobile   Agents"></a>AutoEval: A Practical Framework for Autonomous Evaluation of Mobile   Agents</h2><p><strong>Authors:Jiahui Sun, Zhichao Hua, Yubin Xia</strong></p>
<p>Accurate and systematic evaluation of mobile agents can significantly advance their development and real-world applicability. However, existing benchmarks for mobile agents lack practicality and scalability due to the extensive manual effort required to define task reward signals and implement corresponding evaluation codes. To this end, we propose AutoEval, an autonomous agent evaluation framework that tests a mobile agent without any manual effort. First, we design a Structured Substate Representation to describe the UI state changes while agent execution, such that task reward signals can be automatically generated. Second, we utilize a Judge System that can autonomously evaluate agents’ performance given the automatically generated task reward signals. By providing only a task description, our framework evaluates agents with fine-grained performance feedback to that task without any extra manual effort. We implement a prototype of our framework and validate the automatically generated task reward signals, finding over 93% coverage to human-annotated reward signals. Moreover, to prove the effectiveness of our autonomous Judge System, we manually verify its judge results and demonstrate that it achieves 94% accuracy. Finally, we evaluate the state-of-the-art mobile agents using our framework, providing detailed insights into their performance characteristics and limitations. </p>
<blockquote>
<p>对移动代理进行准确、系统的评估可以显著促进其发展和在现实世界中的适用性。然而，由于需要大量手动工作来定义任务奖励信号和实现相应的评估代码，现有的移动代理基准测试缺乏实用性和可扩展性。为此，我们提出了AutoEval，一个无需人工努力的自主代理评估框架。首先，我们设计了一种结构化子状态表示来描述代理执行过程中的UI状态变化，以便自动生成任务奖励信号。其次，我们利用一个判断系统，可以根据自动生成的任务奖励信号自主评估代理的性能。仅通过提供任务描述，我们的框架就能对代理进行精细的反馈评估，无需任何额外的人工努力。我们实现了框架的原型，验证了自动生成的任务奖励信号，发现其覆盖率超过93%。此外，为了证明我们自主的判断系统有效，我们手动验证了其判断结果，并证明其准确率达到了94%。最后，我们使用我们的框架对最先进的移动代理进行了评估，提供了关于其性能特征和局限性的详细见解。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02403v1">PDF</a> </p>
<p><strong>Summary</strong><br>移动智能代理的评估和测试对其发展和实际应用至关重要。然而，现有的移动智能代理评估基准测试缺乏实用性和可扩展性，需要大量手动工作来定义任务奖励信号和实现相应的评估代码。为此，我们提出了AutoEval框架，这是一种无需人工介入的移动智能代理评估方法。首先，我们设计了一种结构化子状态表示法来描述代理执行时的UI状态变化，从而可以自动生成任务奖励信号。其次，我们利用裁判系统自主评估智能代理的性能表现。只需提供任务描述，我们的框架即可对智能代理进行精细的性能反馈评估，无需任何额外的人工操作。我们实现了框架的原型，验证了自动生成的奖励信号的准确性，发现其覆盖率超过93%。此外，为了验证自主裁判系统的有效性，我们手动验证了其判断结果，并证明其准确率为94%。最后，我们使用此框架对最先进的移动智能代理进行了评估，提供了对其性能特征和局限性的深入了解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>移动智能代理的评估和测试是其发展的重要环节，能显著促进其发展和提升其在现实世界的应用能力。</li>
<li>现有评估基准测试需要大量手动工作，缺乏实用性和可扩展性。</li>
<li>AutoEval框架能自主评估移动智能代理的性能表现，无需人工介入。</li>
<li>通过结构化子状态表示法描述UI状态变化，自动生成任务奖励信号。</li>
<li>利用裁判系统自主评估智能代理的任务完成情况。</li>
<li>原型验证显示自动生成的奖励信号覆盖率超过93%，自主裁判系统的准确率为94%。</li>
<li>使用此框架对最先进的移动智能代理进行了评估，揭示了其性能特征和局限性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02403">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ecc28377a445ae2373116bfd49515a1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5c6da1308d914bc85c92e172bf6e50a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-392524d63539c6796b5eaf9005790689.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b3e1e854f80819bcb36d4dc3bc2cac5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c76442fc7855ea05810cfa77602b02c5.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ReSo-A-Reward-driven-Self-organizing-LLM-based-Multi-Agent-System-for-Reasoning-Tasks"><a href="#ReSo-A-Reward-driven-Self-organizing-LLM-based-Multi-Agent-System-for-Reasoning-Tasks" class="headerlink" title="ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for   Reasoning Tasks"></a>ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for   Reasoning Tasks</h2><p><strong>Authors:Heng Zhou, Hejia Geng, Xiangyuan Xue, Zhenfei Yin, Lei Bai</strong></p>
<p>Multi-agent systems have emerged as a promising approach for enhancing the reasoning capabilities of large language models in complex problem-solving. However, current MAS frameworks are limited by poor flexibility and scalability, with underdeveloped optimization strategies. To address these challenges, we propose ReSo, which integrates task graph generation with a reward-driven two-stage agent selection process. The core of ReSo is the proposed Collaborative Reward Model, which can provide fine-grained reward signals for MAS cooperation for optimization. We also introduce an automated data synthesis framework for generating MAS benchmarks, without human annotations. Experimentally, ReSo matches or outperforms existing methods. ReSo achieves \textbf{33.7%} and \textbf{32.3%} accuracy on Math-MAS and SciBench-MAS SciBench, while other methods completely fail. Code is available at: \href{<a target="_blank" rel="noopener" href="https://github.com/hengzzzhou/ReSo%7D%7BReSo%7D">https://github.com/hengzzzhou/ReSo}{ReSo}</a> </p>
<blockquote>
<p>多智能体系统作为一种有前景的方法，在复杂的问题解决中增强了大型语言模型的推理能力。然而，当前的多智能体系统框架受限于灵活性和可扩展性较差，优化策略也不够完善。为了解决这些挑战，我们提出了ReSo，它将任务图生成与奖励驱动的两阶段智能体选择过程相结合。ReSo的核心是提出的协同奖励模型，该模型可以为多智能体系统的合作提供精细的奖励信号，以实现优化。我们还引入了一个自动化的数据合成框架，用于生成多智能体系统的基准测试，无需人工注释。实验表明，ReSo与现有方法相匹配或表现更好。ReSo在Math-MAS和SciBench-MAS SciBench上的准确率分别达到**33.7%<strong>和</strong>32.3%**，而其他方法则完全失败。代码可在<a target="_blank" rel="noopener" href="https://github.com/hengzzzhou/ReSo">https://github.com/hengzzzhou/ReSo</a>获取。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02390v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>多智能体系统通过任务图生成与奖励驱动的两阶段智能体选择过程，提高了大型语言模型在复杂问题解决中的推理能力。针对当前MAS框架的灵活性和可扩展性限制，提出了ReSo。其核心是协作奖励模型，为MAS合作提供精细奖励信号以实现优化。同时，引入自动化数据合成框架生成MAS基准测试集，无需人工标注。实验表明，ReSo在Math-MAS和SciBench-MAS上的准确率分别达到了33.7%和32.3%，而其他方法则完全失败。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多智能体系统已用于增强大型语言模型的推理能力，以解决复杂问题。</li>
<li>当前MAS框架存在灵活性和可扩展性的限制。</li>
<li>ReSo通过任务图生成和奖励驱动的智能体选择过程来克服这些挑战。</li>
<li>ReSo的核心是协作奖励模型，为MAS合作提供精细奖励信号。</li>
<li>ReSo引入了一个自动化数据合成框架，能够生成MAS基准测试集，无需人工标注。</li>
<li>ReSo在Math-MAS和SciBench-MAS上的准确率高于其他方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02390">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a3ca3be22e09e23623ec1cfa0589f0ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6b7ce059c252e0e00369fd17aab3a5d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2b5cecbabc593af58eec2d8439d7cde.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AppAgentX-Evolving-GUI-Agents-as-Proficient-Smartphone-Users"><a href="#AppAgentX-Evolving-GUI-Agents-as-Proficient-Smartphone-Users" class="headerlink" title="AppAgentX: Evolving GUI Agents as Proficient Smartphone Users"></a>AppAgentX: Evolving GUI Agents as Proficient Smartphone Users</h2><p><strong>Authors:Wenjia Jiang, Yangyang Zhuang, Chenxi Song, Xu Yang, Chi Zhang</strong></p>
<p>Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required predefined rules. However, the reliance on step-by-step reasoning in LLM-based agents often results in inefficiencies, particularly for routine tasks. In contrast, traditional rule-based systems excel in efficiency but lack the intelligence and flexibility to adapt to novel scenarios. To address this challenge, we propose a novel evolutionary framework for GUI agents that enhances operational efficiency while retaining intelligence and flexibility. Our approach incorporates a memory mechanism that records the agent’s task execution history. By analyzing this history, the agent identifies repetitive action sequences and evolves high-level actions that act as shortcuts, replacing these low-level operations and improving efficiency. This allows the agent to focus on tasks requiring more complex reasoning, while simplifying routine actions. Experimental results on multiple benchmark tasks demonstrate that our approach significantly outperforms existing methods in both efficiency and accuracy. The code will be open-sourced to support further research. </p>
<blockquote>
<p>最近，大型语言模型（LLM）的进展导致了基于智能LLM的代理的发展，这些代理能够与图形用户界面（GUI）进行交互。这些代理人表现出强大的推理和适应能力，使他们能够完成传统上需要预先设定规则才能完成的复杂任务。然而，基于LLM的代理人在逐步推理上的依赖往往会导致效率低下，特别是在执行常规任务时。相比之下，传统的基于规则的系统在效率上表现出色，但缺乏适应新场景的智力和灵活性。为了解决这一挑战，我们提出了一种新型的GUI代理进化框架，该框架提高了操作效率，同时保留了智力和灵活性。我们的方法采用了一种记忆机制，可以记录代理的任务执行历史。通过分析这些历史记录，代理可以识别出重复的动作序列，并进化出高级动作作为快捷方式，从而取代这些低级操作，提高效率。这允许代理专注于需要更复杂推理的任务，同时简化常规操作。在多个基准任务上的实验结果表明，我们的方法在效率和准确性方面都显著优于现有方法。代码将开源以支持进一步研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02268v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>随着大型语言模型（LLM）的近期发展，基于LLM的智能代理能够与用户界面交互，展示强大的推理和适应性，可完成传统需要预设规则的复杂任务。然而，对于常规任务，基于LLM的代理的逐步推理过程可能会导致效率低下。为了解决这个问题，我们提出了一种新的GUI代理进化框架，它在提高效率的同时保留智能和灵活性。通过记忆机制记录代理任务执行历史，并分析这些历史数据，找出重复操作序列并形成快捷方式以提高效率。在多个基准测试任务上的实验结果显示，该方法在效率和准确性上均显著优于现有方法。代码将开源以支持进一步研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>基于大型语言模型的智能代理能与图形用户界面交互。</li>
<li>这些代理具备强大的推理和适应性，能完成复杂任务。</li>
<li>基于LLM的代理在处理常规任务时可能效率不高。</li>
<li>提出一种新的GUI代理进化框架以提高效率和保留智能。</li>
<li>通过记忆机制记录并分析代理任务执行历史，形成高效快捷方式。</li>
<li>在多个任务上的实验证明该方法优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02268">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2f7fb0fa33b25679c49979894d956c06.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ff11f924d859c6f59de9022f6d9a283c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1776df495f7e509244116de302afc6ce.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="ATLaS-Agent-Tuning-via-Learning-Critical-Steps"><a href="#ATLaS-Agent-Tuning-via-Learning-Critical-Steps" class="headerlink" title="ATLaS: Agent Tuning via Learning Critical Steps"></a>ATLaS: Agent Tuning via Learning Critical Steps</h2><p><strong>Authors:Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou</strong></p>
<p>Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and weaken generalization to states not covered by the expert data. Additionally, critical steps, such as planning, complex reasoning for intermediate subtasks, and strategic decision-making, are essential to success in agent tasks, so learning these steps is the key to improving LLM agents. For more effective and efficient agent tuning, we propose ATLaS that identifies the critical steps in expert trajectories and finetunes LLMs solely on these steps with reduced costs. By steering the training’s focus to a few critical steps, our method mitigates the risk of overfitting entire trajectories and promotes generalization across different environments and tasks. In extensive experiments, an LLM finetuned on only 30% critical steps selected by ATLaS outperforms the LLM finetuned on all steps and recent open-source LLM agents. ATLaS maintains and improves base LLM skills as generalist agents interacting with diverse environments. </p>
<blockquote>
<p>大型语言模型（LLM）代理在多域任务中展现出了显著的泛化能力。现有的代理调整方法通常会对整个专家轨迹进行有监督的微调。然而，全轨迹的行为克隆可能会引入专家偏见，并削弱对专家数据未覆盖状态的泛化能力。此外，规划、中间子任务的复杂推理和战略决策等关键步骤对于代理任务的成功至关重要，因此学习这些步骤是改进LLM代理的关键。为了更有效、更高效地调整代理，我们提出了ATLaS方法，该方法能够识别专家轨迹中的关键步骤，并以减少的成本仅在这些步骤上对LLM进行微调。通过引导训练的重点关注少数关键步骤，我们的方法减轻了对整个轨迹过度拟合的风险，并促进了在不同环境和任务中的泛化。在大量实验中，仅通过ATLaS选择的30%关键步骤进行微调的LLM，其性能优于在所有步骤上进行微调的LLM以及最近的开源LLM代理。ATLaS在作为与各种环境互动的通用代理时，能够保持并提升LLM的基础技能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02197v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理在多域任务中展现出卓越的泛化能力。现有代理调整方法通常对整个专家轨迹进行有监督的微调，但完全轨迹的行为克隆可能会引入专家偏见，并在专家数据未覆盖的状态下削弱泛化能力。此外，成功完成代理任务的关键步骤包括规划、中间子任务的复杂推理和战略决策制定。为了更有效地调整代理并提高效率，我们提出了ATLaS方法，该方法能够识别专家轨迹中的关键步骤，并仅针对这些步骤对LLM进行微调以降低成本。通过专注于少数关键步骤的训练，我们的方法降低了对整个轨迹的过拟合风险，并促进了不同环境和任务之间的泛化能力。实验表明，仅对ATLaS选择的30%关键步骤进行微调的大型语言模型在所有步骤上都表现得很好优于最近的开源大型语言模型代理，并且在与不同环境的交互中维持和改进了基础大型语言模型的技能作为全能代理。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理在多域任务中展现出良好的泛化能力。</li>
<li>当前代理调整方法可能引入专家偏见并削弱泛化能力。</li>
<li>成功完成代理任务的关键步骤包括规划、复杂推理和战略决策制定。</li>
<li>ATLaS方法能够识别专家轨迹中的关键步骤并对LLM进行微调以降低训练成本。</li>
<li>通过专注于少数关键步骤的训练，ATLaS降低了过拟合风险并提高了不同环境和任务之间的泛化能力。</li>
<li>仅对ATLaS选择的30%关键步骤进行微调的大型语言模型性能优于完整轨迹微调和近期开源的大型语言模型代理。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02197">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f8eb2df4659271d18ad53f57ca7fa844.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c51a72ea43562b4c43916efcd3c6ac1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cb5a214931e6aba1f6a8722e3a15c943.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30db74f80ac8e951feb58e1a72f88398.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Improved-MMS-Approximations-for-Few-Agent-Types"><a href="#Improved-MMS-Approximations-for-Few-Agent-Types" class="headerlink" title="Improved MMS Approximations for Few Agent Types"></a>Improved MMS Approximations for Few Agent Types</h2><p><strong>Authors:Jugal Garg, Parnian Shahkar</strong></p>
<p>We study fair division of indivisible goods under the maximin share (MMS) fairness criterion in settings where agents are grouped into a small number of types, with agents within each type having identical valuations. For the special case of a single type, an exact MMS allocation is always guaranteed to exist. However, for two or more distinct agent types, exact MMS allocations do not always exist, shifting the focus to establishing the existence of approximate-MMS allocations. A series of works over the last decade has resulted in the best-known approximation guarantee of $\frac{3}{4} + \frac{3}{3836}$.   In this paper, we improve the approximation guarantees for settings where agents are grouped into two or three types, a scenario that arises in many practical settings. Specifically, we present novel algorithms that guarantee a $\frac{4}{5}$-MMS allocation for two agent types and a $\frac{16}{21}$-MMS allocation for three agent types. Our approach leverages the MMS partition of the majority type and adapts it to provide improved fairness guarantees for all types. </p>
<blockquote>
<p>我们研究了不可分物品公平分配问题，此问题的背景是存在少数几种类型的代理群体，同一类型内的代理具有相同的估价。在单一类型的特殊情况下，总能保证存在一个精确的MMS分配方案。然而，在两种或更多种不同类型的代理群体中，精确的MMS分配方案并不总是存在，因此研究重点转向了近似MMS分配方案的存在性。近十年的一系列研究得到了著名的近似保证界限，即$\frac{3}{4} + \frac{3}{3836}$。在本文中，我们改进了将代理划分为两种或三种类型的设置中的近似保证界限，这在许多实际应用场景中都很常见。具体来说，我们提出了新型算法，为两种代理类型提供$\frac{4}{5}$的MMS分配方案，为三种代理类型提供$\frac{16}{21}$的MMS分配方案。我们的方法利用多数类型的MMS分割，并对其进行调整，以确保所有类型的代理都能获得更高的公平性保障。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02089v1">PDF</a> 27 pages</p>
<p><strong>Summary</strong></p>
<p>本文研究了不可分物品在最大最小份额（MMS）公平性标准下的分配问题，特别关注了当代理人被分为少量类型时的情况，同一类型内的代理人具有相同的价值评估。对于单一类型特殊情况，存在精确的MMS分配。然而，对于两个或更多不同类型的代理人，精确的MMS分配并不总是存在，因此研究重点转向了近似MMS分配的存在性。本文提高了当代理人为两种或三种类型时的近似保证，对于两种类型代理人的场景，能保证$\frac{4}{5}$的MMS分配；对于三种类型代理人的场景，能保证$\frac{16}{21}$的MMS分配。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究了基于最大最小份额（MMS）公平性标准的不可分物品的分配问题。</li>
<li>当代理人被分为少量类型时，同一类型内的代理人具有相同价值评估。</li>
<li>对于单一类型的特殊情况，存在精确的MMS分配。</li>
<li>对于多个类型的代理人，精确的MMS分配并不总是存在，需要寻找近似MMS分配。</li>
<li>本文提高了对两种类型代理人的近似保证至$\frac{4}{5}$的MMS分配。</li>
<li>对于三种类型代理人的场景，本文提供了$\frac{16}{21}$的MMS分配的保证。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02089">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-1cb954b86c388dd0d1628c707b7b919a.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Smoothing-Grounding-and-Reasoning-for-MLLM-Powered-GUI-Agents-with-Query-Oriented-Pivot-Tasks"><a href="#Smoothing-Grounding-and-Reasoning-for-MLLM-Powered-GUI-Agents-with-Query-Oriented-Pivot-Tasks" class="headerlink" title="Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with   Query-Oriented Pivot Tasks"></a>Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with   Query-Oriented Pivot Tasks</h2><p><strong>Authors:Zongru Wu, Pengzhou Cheng, Zheng Wu, Tianjie Ju, Zhuosheng Zhang, Gongshen Liu</strong></p>
<p>Perception-enhanced pre-training, particularly through grounding techniques, is widely adopted to enhance the performance of graphical user interface (GUI) agents. However, in resource-constrained scenarios, the format discrepancy between coordinate-oriented grounding and action-oriented reasoning limits the effectiveness of grounding for reasoning tasks. To address this challenge, we propose a query-oriented pivot approach called query inference, which serves as a bridge between GUI grounding and reasoning. By inferring potential user queries from a screenshot and its associated element coordinates, query inference improves the understanding of coordinates while aligning more closely with reasoning tasks. Experimental results show that query inference outperforms previous grounding techniques under the same training data scale. Notably, query inference achieves comparable or even better performance to large-scale grounding-enhanced OS-Atlas with less than 0.1% of training data. Furthermore, we explore the impact of reasoning formats and demonstrate that integrating additional semantic information into the input further boosts reasoning performance. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/ZrW00/GUIPivot">https://github.com/ZrW00/GUIPivot</a>. </p>
<blockquote>
<p>感知增强预训练，特别是通过接地技术，广泛应用于提高图形用户界面（GUI）代理的性能。然而，在资源受限的场景下，坐标导向接地与行动导向推理之间的格式差异限制了接地在推理任务中的有效性。为了应对这一挑战，我们提出了一种称为查询推理的查询导向轴心方法，它作为GUI接地和推理之间的桥梁。通过从截图及其相关元素坐标推断潜在用户查询，查询推理提高了对坐标的理解，同时更紧密地符合推理任务。实验结果表明，在相同的训练数据规模下，查询推理优于之前的接地技术。值得注意的是，查询推理在不到0.1%的训练数据的情况下实现了与大规模接地增强OS-Atlas相当的甚至更好的性能。此外，我们探讨了推理格式的影响，并证明将额外的语义信息集成到输入中进一步提高了推理性能。代码公开在<a target="_blank" rel="noopener" href="https://github.com/ZrW00/GUIPivot">https://github.com/ZrW00/GUIPivot</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.00401v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>感知增强预训练，特别是通过接地技术，广泛应用于提高图形用户界面（GUI）代理的性能。然而，在资源受限的情况下，坐标导向接地与行动导向推理之间的格式差异限制了接地对于推理任务的效力。为解决此挑战，我们提出一种称为查询推断的查询导向式枢轴方法，作为GUI接地和推理之间的桥梁。通过从截图及其相关元素坐标推断潜在用户查询，查询推断提高了对坐标的理解，同时更紧密地与推理任务对齐。实验结果显示，在相同的训练数据规模下，查询推断优于先前的接地技术。值得注意的是，使用不到0.1%的训练数据，查询推断即可实现与大规模接地增强的OS-Atlas相当的甚至更好的性能。此外，我们还探讨了推理格式的影响，并证明将额外的语义信息整合到输入中可进一步提高推理性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>感知增强预训练通过接地技术提升GUI代理性能。</li>
<li>资源受限情况下，坐标导向接地与行动导向推理的格式差异限制其效力。</li>
<li>提出查询推断方法，作为GUI接地和推理间的桥梁。</li>
<li>查询推断通过推断用户查询提高坐标理解，并与推理任务对齐。</li>
<li>查询推断在少量训练数据下表现优异，与大规模接地增强方法性能相当。</li>
<li>推理格式对性能有影响。</li>
<li>将额外语义信息整合到输入中可进一步提高推理性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.00401">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-524b3a0a79676f220a949a4bfb81a693.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e49add45d0fd0a4575242decf7b4fcd9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3aa88bfab73ebfa083a8c25ee8f28948.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70eed3dd719c9f2cd45d1213e1c62193.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Adaptive-Attacks-Break-Defenses-Against-Indirect-Prompt-Injection-Attacks-on-LLM-Agents"><a href="#Adaptive-Attacks-Break-Defenses-Against-Indirect-Prompt-Injection-Attacks-on-LLM-Agents" class="headerlink" title="Adaptive Attacks Break Defenses Against Indirect Prompt Injection   Attacks on LLM Agents"></a>Adaptive Attacks Break Defenses Against Indirect Prompt Injection   Attacks on LLM Agents</h2><p><strong>Authors:Qiusi Zhan, Richard Fang, Henil Shalin Panchal, Daniel Kang</strong></p>
<p>Large Language Model (LLM) agents exhibit remarkable performance across diverse applications by using external tools to interact with environments. However, integrating external tools introduces security risks, such as indirect prompt injection (IPI) attacks. Despite defenses designed for IPI attacks, their robustness remains questionable due to insufficient testing against adaptive attacks. In this paper, we evaluate eight different defenses and bypass all of them using adaptive attacks, consistently achieving an attack success rate of over 50%. This reveals critical vulnerabilities in current defenses. Our research underscores the need for adaptive attack evaluation when designing defenses to ensure robustness and reliability. The code is available at <a target="_blank" rel="noopener" href="https://github.com/uiuc-kang-lab/AdaptiveAttackAgent">https://github.com/uiuc-kang-lab/AdaptiveAttackAgent</a>. </p>
<blockquote>
<p>大型语言模型（LLM）代理通过利用外部工具与环境进行交互，在多种应用中表现出卓越的性能。然而，整合外部工具会引入安全风险，例如间接提示注入（IPI）攻击。尽管已经设计了针对IPI攻击的防御措施，但由于对适应性攻击的测试不足，其稳健性仍然令人质疑。在本文中，我们评估了八种不同的防御措施，并使用适应性攻击绕过它们，始终实现超过50%的攻击成功率。这揭示了当前防御措施中的关键漏洞。我们的研究强调在设计防御措施时进行适应性攻击评估的必要性，以确保其稳健性和可靠性。相关代码可在<a target="_blank" rel="noopener" href="https://github.com/uiuc-kang-lab/AdaptiveAttackAgent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/uiuc-kang-lab/AdaptiveAttackAgent找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.00061v2">PDF</a> 17 pages, 5 figures, 6 tables (NAACL 2025 Findings)</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理在多种应用中表现出卓越性能，通过使用外部工具与环境进行交互。然而，集成外部工具带来了安全风险，如间接提示注入（IPI）攻击。现有防御措施在面对适应性攻击时显得不够稳健，存在关键漏洞。本文评估了八种不同的防御措施并绕过了它们，攻击成功率超过50%。研究强调了在设计防御措施时进行适应性攻击评估的必要性，以确保其稳健性和可靠性。有关代码已公开提供。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLM）代理在与环境交互中使用外部工具时表现出强大的性能。</li>
<li>集成外部工具引入安全风险，特别是间接提示注入（IPI）攻击。</li>
<li>目前针对IPI攻击的防御措施在面对适应性攻击时存在关键漏洞。</li>
<li>现有防御措施被成功绕过，攻击成功率超过50%。</li>
<li>需要进行适应性攻击评估以确保防御措施的设计的稳健性和可靠性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.00061">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d1fdadd862b850136ec899028fdc2f9c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-36a4a576f40b99293894d779608eca5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3e3625fe5534cd4665d9b3268c7f800.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-acd0e6a80fff37b2968be3dd9c91eed4.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="A-MEM-Agentic-Memory-for-LLM-Agents"><a href="#A-MEM-Agentic-Memory-for-LLM-Agents" class="headerlink" title="A-MEM: Agentic Memory for LLM Agents"></a>A-MEM: Agentic Memory for LLM Agents</h2><p><strong>Authors:Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang</strong></p>
<p>While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems’ fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at <a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory">https://github.com/WujiangXu/AgenticMemory</a>, while the source code of agentic memory system is available at <a target="_blank" rel="noopener" href="https://github.com/agiresearch/A-mem">https://github.com/agiresearch/A-mem</a>. </p>
<blockquote>
<p>虽然大型语言模型（LLM）代理可以有效地利用外部工具来完成复杂的现实世界任务，但它们需要记忆系统来利用历史经验。当前的记忆系统虽然实现了基本的存储和检索功能，但缺乏高级的记忆组织功能，尽管最近尝试引入图数据库。此外，这些系统的固定操作和结构限制了它们在多样化任务中的适应性。为了解决这一局限性，本文提出了一种新型的大型语言模型代理的记忆系统，它能够以动态的方式组织记忆。我们遵循Zettelkasten方法的基本原则，设计了一个记忆系统，通过动态索引和链接创建相互关联的知识网络。每当添加新的记忆时，我们会生成一个包含多个结构化属性的综合笔记，包括上下文描述、关键词和标签。然后，系统分析历史记忆以识别相关联系，在存在有意义的相似性时建立链接。此外，这个过程实现了记忆的进化——当新记忆被集成时，它们可以触发对现有历史记忆的上下文表示和属性的更新，使记忆网络能够不断完善其理解。我们的方法结合了Zettelkasten的结构化组织原则与代理驱动的决策的灵活性，从而实现更适应和上下文感知的记忆管理。对六个基础模型的实证实验表明，与现有的最先进的基线相比，我们的方法具有显著的改进。性能评估的源代码可在<a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory%E4%B8%8A%E6%89%BE%E5%88%B0%EF%BC%8C%E8%80%8C%E4%BB%A3%E7%90%86%E8%AE%B0%E5%BF%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%99%E5%8F%AF%E4%BB%A5%E5%9C%A8https://github.com/agiresearch/A-mem.%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/WujiangXu/AgenticMemory上找到，而代理记忆系统的源代码则可在https://github.com/agiresearch/A-mem上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12110v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理在利用外部工具进行复杂现实世界任务时表现出色，但它们需要记忆系统来利用历史经验。当前记忆系统可实现基本存储和检索功能，但缺乏复杂的记忆组织。本文提出了一种新颖的代理记忆系统，可以根据基本原则动态组织记忆。结合Zettelkasten方法的结构组织原则和代理驱动的决策灵活性，实现了更加自适应和上下文感知的记忆管理。在六个基础模型上的实证实验表明，与现有最佳基线相比具有显著改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理需要记忆系统来利用历史经验，当前记忆系统缺乏复杂的记忆组织。</li>
<li>代理记忆系统需要能够动态组织记忆并具有适应性。</li>
<li>本文提出了一种新颖的代理记忆系统，结合Zettelkasten方法的结构组织原则和代理驱动的决策灵活性。</li>
<li>该系统通过生成包含多个结构化属性的综合笔记来创建相互关联的知识网络，如上下文描述、关键词和标签。</li>
<li>系统能够分析历史记忆以识别相关连接，并在新记忆集成时触发对上下文表示和属性的更新。</li>
<li>通过实验证明，该代理记忆系统在六个基础模型上的性能优于现有最佳基线。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12110">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b52ff1fc3c01414f534b0172c690c16b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-43f60cff38e4f45d95c7cc2c7568c14b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d4a3e95cf2de0ecf3b48d938d5aff05.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Tool-Learning-in-the-Wild-Empowering-Language-Models-as-Automatic-Tool-Agents"><a href="#Tool-Learning-in-the-Wild-Empowering-Language-Models-as-Automatic-Tool-Agents" class="headerlink" title="Tool Learning in the Wild: Empowering Language Models as Automatic Tool   Agents"></a>Tool Learning in the Wild: Empowering Language Models as Automatic Tool   Agents</h2><p><strong>Authors:Zhengliang Shi, Shen Gao, Lingyong Yan, Yue Feng, Xiuyi Chen, Zhumin Chen, Dawei Yin, Suzan Verberne, Zhaochun Ren</strong></p>
<p>Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. Previous methods manually parse tool documentation and create in-context demonstrations, transforming tools into structured formats for LLMs to use in their step-by-step reasoning. However, this manual process requires domain expertise and struggles to scale to large toolsets. Additionally, these methods rely heavily on ad-hoc inference techniques or special tokens to integrate free-form LLM generation with tool-calling actions, limiting the LLM’s flexibility in handling diverse tool specifications and integrating multiple tools.   In this work, we propose AutoTools, a framework that enables LLMs to automate the tool-use workflow. Specifically, the LLM automatically transforms tool documentation into callable functions, verifying syntax and runtime correctness. Then, the LLM integrates these functions into executable programs to solve practical tasks, flexibly grounding tool-use actions into its reasoning processes. Extensive experiments on existing and newly collected, more challenging benchmarks illustrate the superiority of our framework. Inspired by these promising results, we further investigate how to improve the expertise of LLMs, especially open-source LLMs with fewer parameters, within AutoTools. Thus, we propose the AutoTools-learning approach, training the LLMs with three learning tasks on 34k instances of high-quality synthetic data, including documentation understanding, relevance learning, and function programming. Fine-grained results validate the effectiveness of our overall training approach and each individual task. Our methods are an important step towards the use of LLMs for solving real-world tasks with external tools. </p>
<blockquote>
<p>通过外部工具增强大型语言模型（LLM）的实用性已成为一种前景广阔的方法，使它们能够解决实际任务。以前的方法会手动解析工具文档并创建上下文演示，将工具转换为LLM可以使用的结构化格式，以便进行逐步推理。然而，这种手动过程需要领域专业知识，且难以扩展到大型工具集。此外，这些方法还严重依赖于临时推理技术或特殊令牌，将自由形式的LLM生成与工具调用操作相结合，这限制了LLM在处理各种工具规格和集成多个工具方面的灵活性。</p>
</blockquote>
<p>在这项工作中，我们提出了AutoTools框架，使LLM能够自动化工具使用工作流程。具体来说，LLM会自动将工具文档转换为可调用的函数，验证语法和运行时正确性。然后，LLM将这些函数集成到可执行程序中以解决实际任务，灵活地将工具使用操作融入其推理过程。在现有和新收集的更具挑战性的基准测试上的大量实验证明了我们的框架的优越性。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.16533v2">PDF</a> Accepted by WWW 2025</p>
<p><strong>Summary</strong></p>
<p>该文探讨了一种名为AutoTools的框架，该框架能够自动化工具使用流程，使得大型语言模型（LLMs）能够处理实用任务。LLM能够自动将工具文档转化为可调用函数，验证语法和运行时正确性。之后，LLM将这些函数整合到可执行程序中解决问题。该框架的优越性通过广泛的实验得到了验证。此外，文章还探讨了如何提升LLM在AutoTools中的专业性，特别是针对参数较少的开源LLM。为此，提出了AutoTools-learning方法，通过对高质量合成数据进行三项学习任务训练来提升LLM的能力。实验结果验证了该方法的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AutoTools框架使得大型语言模型（LLMs）能够自动化使用外部工具解决实用任务。</li>
<li>LLM能够自动将工具文档转化为可调用函数，并进行语法和运行时正确性验证。</li>
<li>AutoTools框架的优越性通过广泛实验验证。</li>
<li>文章探讨了提升LLM在AutoTools中的专业性，特别是针对开源LLM。</li>
<li>提出了AutoTools-learning方法，通过三项学习任务训练来提升LLM的能力。</li>
<li>训练数据包括工具文档理解、相关性学习和函数编程等高质量合成数据。</li>
<li>实验结果验证了AutoTools-learning方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.16533">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-338b3cc1a77bc010d523dd0544e4702a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc088d011a4da85eaf823492fb36484f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b68f0033d4be6265d3a9ce3cb2ae4c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-367ff79f6fdc638395ac32c7a9de2ee7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a467a76ce9cd40db7fad9e83ff37a360.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-807e3239124e4eaff21247aa38a0a2e8.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Interpretable-Interaction-Modeling-for-Trajectory-Prediction-via-Agent-Selection-and-Physical-Coefficient"><a href="#Interpretable-Interaction-Modeling-for-Trajectory-Prediction-via-Agent-Selection-and-Physical-Coefficient" class="headerlink" title="Interpretable Interaction Modeling for Trajectory Prediction via Agent   Selection and Physical Coefficient"></a>Interpretable Interaction Modeling for Trajectory Prediction via Agent   Selection and Physical Coefficient</h2><p><strong>Authors:Shiji Huang, Lei Ye, Min Chen, Wenhai Luo, Dihong Wang, Chenqi Xu, Deyuan Liang</strong></p>
<p>A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods. </p>
<blockquote>
<p>对目标代理与周围代理之间交互的深刻理解是准确预测轨迹的先决条件。尽管已经探索了许多方法，但它们以纯粹的学习方式为周围代理分配相关系数。在本研究中，我们提出了ASPILin，它手动选择交互代理，并用新计算得到的物理相关系数替换Transformer中的注意力得分，增强了交互建模的可解释性。令人惊讶的是，这些简单的修改可以显著提高预测性能并大幅降低计算成本。我们有意在其他方面简化了我们的模型，例如地图编码。值得注意的是，在INTERACTION、highD和CitySim数据集上进行的实验表明，我们的方法高效且直观，优于其他最先进的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.13152v4">PDF</a> code:<a target="_blank" rel="noopener" href="https://github.com/kkk00714/ASPILin">https://github.com/kkk00714/ASPILin</a></p>
<p><strong>Summary</strong>：<br>本研究提出ASPILin方法，通过手动选择交互代理并替换Transformer中的注意力分数为新的物理相关系数，提高了交互建模的可解释性。这种方法在预测性能方面有很大提升，并降低了计算成本。在INTERACTION、highD和CitySim数据集上的实验表明，该方法有效且简单，优于其他最先进的方法。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>理解目标代理与周围代理之间的交互是准确预测轨迹的前提。</li>
<li>现有方法主要通过学习来分配与周围代理的相关性系数。</li>
<li>ASPILin方法手动选择交互代理，增强交互建模的可解释性。</li>
<li>ASPILin通过替换Transformer中的注意力分数为物理相关系数，显著提高预测性能。</li>
<li>该方法降低计算成本，同时在实验数据集上表现优异。</li>
<li>实验在INTERACTION、highD和CitySim数据集上进行，证明该方法的有效性和优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.13152">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7f148082dce8b4396ce9f9096ea37498.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c33d4b393ab4974902a67ce63f8371c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ef3a98ce2b5d1fab4fae015bc5bd2c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5959c9726d1522e75b47fcba368908dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d2d5ccd37deead036a2ad525b8713fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9da25f9130d5082034a057fdd20c8574.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3636a14b2dfc37cd0dbadc51a7344626.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89b351fe86b4ffc9a0db391bd8f13852.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-06/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-06/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-06/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-54d7d93040223efbb147b43c5cb5a993.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-06  MX-Font++ Mixture of Heterogeneous Aggregation Experts for Few-shot   Font Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-06/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-55c83592273e96c08993adcd4e1ff6f7.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-06  Prompting Generative AI with Interaction-Augmented Instructions
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27083.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
