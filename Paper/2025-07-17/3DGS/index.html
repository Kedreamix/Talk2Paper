<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-17  TRAN-D 2D Gaussian Splatting-based Sparse-view Transparent Object Depth   Reconstruction via Physics Simulation for Scene Update">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-894e9f3d1a97ef18374a6596eab94432.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    50 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-17-æ›´æ–°"><a href="#2025-07-17-æ›´æ–°" class="headerlink" title="2025-07-17 æ›´æ–°"></a>2025-07-17 æ›´æ–°</h1><h2 id="TRAN-D-2D-Gaussian-Splatting-based-Sparse-view-Transparent-Object-Depth-Reconstruction-via-Physics-Simulation-for-Scene-Update"><a href="#TRAN-D-2D-Gaussian-Splatting-based-Sparse-view-Transparent-Object-Depth-Reconstruction-via-Physics-Simulation-for-Scene-Update" class="headerlink" title="TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth   Reconstruction via Physics Simulation for Scene Update"></a>TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth   Reconstruction via Physics Simulation for Scene Update</h2><p><strong>Authors:Jeongyun Kim, Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun, Ayoung Kim</strong></p>
<p>Understanding the 3D geometry of transparent objects from RGB images is challenging due to their inherent physical properties, such as reflection and refraction. To address these difficulties, especially in scenarios with sparse views and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian Splatting-based depth reconstruction method for transparent objects. Our key insight lies in separating transparent objects from the background, enabling focused optimization of Gaussians corresponding to the object. We mitigate artifacts with an object-aware loss that places Gaussians in obscured regions, ensuring coverage of invisible surfaces while reducing overfitting. Furthermore, we incorporate a physics-based simulation that refines the reconstruction in just a few seconds, effectively handling object removal and chain-reaction movement of remaining objects without the need for rescanning. TRAN-D is evaluated on both synthetic and real-world sequences, and it consistently demonstrated robust improvements over existing GS-based state-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean absolute error by over 39% for the synthetic TRansPose sequences. Furthermore, despite being updated using only one image, TRAN-D reaches a {\delta} &lt; 2.5 cm accuracy of 48.46%, over 1.5 times that of baselines, which uses six images. Code and more results are available at <a target="_blank" rel="noopener" href="https://jeongyun0609.github.io/TRAN-D/">https://jeongyun0609.github.io/TRAN-D/</a>. </p>
<blockquote>
<p>ç†è§£é€æ˜ç‰©ä½“çš„3Då‡ ä½•ç»“æ„ä»RGBå›¾åƒæ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒä»¬çš„å›ºæœ‰ç‰©ç†å±æ€§ï¼Œå¦‚åå°„å’ŒæŠ˜å°„ã€‚ä¸ºäº†è§£å†³è¿™äº›å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†å›¾ç¨€ç–å’ŒåŠ¨æ€ç¯å¢ƒåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†TRAN-Dï¼Œä¸€ç§åŸºäºäºŒç»´é«˜æ–¯å±•å¼€çš„æ–°å‹é€æ˜ç‰©ä½“æ·±åº¦é‡å»ºæ–¹æ³•ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£åœ¨äºå°†é€æ˜ç‰©ä½“ä¸èƒŒæ™¯åˆ†ç¦»ï¼Œä»è€Œèƒ½å¤Ÿå¯¹å¯¹åº”äºç‰©ä½“çš„é«˜æ–¯è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ã€‚æˆ‘ä»¬é€šè¿‡å¯¹è±¡æ„ŸçŸ¥æŸå¤±å‡è½»äº†ä¼ªå½±ï¼Œè¯¥æŸå¤±å°†é«˜æ–¯æ”¾ç½®åœ¨é®æŒ¡åŒºåŸŸï¼Œç¡®ä¿éšå½¢è¡¨é¢çš„è¦†ç›–ï¼ŒåŒæ—¶å‡å°‘è¿‡åº¦æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿï¼Œåœ¨çŸ­çŸ­å‡ ç§’é’Ÿå†…å¯¹é‡å»ºè¿›è¡Œç»†åŒ–ï¼Œæœ‰æ•ˆåœ°å¤„ç†å¯¹è±¡ç§»é™¤å’Œå‰©ä½™å¯¹è±¡çš„è¿é”ååº”ç§»åŠ¨ï¼Œæ— éœ€é‡æ–°æ‰«æã€‚TRAN-Dåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œåºåˆ—ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œä¸åŸºäºGSçš„ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒå§‹ç»ˆè¡¨ç°å‡ºç¨³å¥çš„æ”¹è¿›ã€‚ä¸åŸºçº¿ç›¸æ¯”ï¼ŒTRAN-Då°†åˆæˆTRansPoseåºåˆ—çš„å¹³å‡ç»å¯¹è¯¯å·®å‡å°‘äº†è¶…è¿‡3 9%ã€‚æ­¤å¤–ï¼Œå°½ç®¡ä»…ä½¿ç”¨ä¸€å¼ å›¾åƒè¿›è¡Œæ›´æ–°ï¼Œä½†TRAN-Dè¾¾åˆ°äº†Î´&lt;2.5 cmçš„ç²¾åº¦ä¸º48.46%ï¼Œè¿™æ˜¯åŸºçº¿ä½¿ç”¨å…­å¼ å›¾åƒæ—¶çš„1.5å€ä»¥ä¸Šã€‚ä»£ç å’Œæ›´å¤šç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://jeongyun0609.github.io/TRAN-D/%E6%89%BE%E5%88%B0%E3%80%82">https://jeongyun0609.github.io/TRAN-D/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.11069v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹é€æ˜ç‰©ä½“ä»RGBå›¾åƒç†è§£å…¶3Då‡ ä½•ç»“æ„çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åŸºäºäºŒç»´é«˜æ–¯æº…å°„çš„æ·±åº¦é‡å»ºæ–¹æ³•â€”â€”TRAN-Dã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåˆ†ç¦»é€æ˜ç‰©ä½“ä¸èƒŒæ™¯ï¼Œä¼˜åŒ–å¯¹åº”ç‰©ä½“çš„é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶å‡å°‘é®æŒ¡åŒºåŸŸçš„ä¼ªå½±ã€‚æ­¤å¤–ï¼Œè¿˜ç»“åˆäº†ç‰©ç†æ¨¡æ‹Ÿï¼Œå¯å¿«é€Ÿå¤„ç†ç‰©ä½“ç§»é™¤å’Œå‰©ä½™ç‰©ä½“çš„è¿é”ååº”ç§»åŠ¨ï¼Œæ— éœ€é‡æ–°æ‰«æã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œåºåˆ—ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒTRAN-Dè¾ƒåŸºäºé«˜æ–¯æº…å°„çš„ç°æœ‰å…ˆè¿›æ–¹æ³•æœ‰æ˜æ˜¾æ”¹è¿›ã€‚ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒTRAN-Dåœ¨åˆæˆTRansPoseåºåˆ—ä¸Šçš„å¹³å‡ç»å¯¹è¯¯å·®é™ä½äº†è¶…è¿‡39%ã€‚å°½ç®¡ä»…ä½¿ç”¨ä¸€å¼ å›¾åƒè¿›è¡Œæ›´æ–°ï¼Œä½†TRAN-Dçš„ç²¾åº¦è¾¾åˆ°äº†å°äº2.5å˜ç±³ï¼Œæ˜¯åŸºçº¿æ–¹æ³•ï¼ˆä½¿ç”¨å…­å¼ å›¾åƒï¼‰çš„1.5å€ä»¥ä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>TRAN-Dæ˜¯ä¸€ç§é’ˆå¯¹é€æ˜ç‰©ä½“çš„äºŒç»´é«˜æ–¯æº…å°„æ·±åº¦é‡å»ºæ–¹æ³•ã€‚</li>
<li>é€šè¿‡åˆ†ç¦»é€æ˜ç‰©ä½“ä¸èƒŒæ™¯ï¼Œå®ç°å¯¹ç‰©ä½“å¯¹åº”çš„é«˜æ–¯åˆ†å¸ƒä¼˜åŒ–ã€‚</li>
<li>ä½¿ç”¨å¯¹è±¡æ„ŸçŸ¥æŸå¤±å‡å°‘é®æŒ¡åŒºåŸŸçš„ä¼ªå½±ã€‚</li>
<li>ç»“åˆç‰©ç†æ¨¡æ‹Ÿï¼Œå¿«é€Ÿå¤„ç†ç‰©ä½“ç§»é™¤å’Œè¿é”ååº”ç§»åŠ¨ã€‚</li>
<li>TRAN-Dåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œåºåˆ—ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>åœ¨åˆæˆTRansPoseåºåˆ—ä¸Šï¼ŒTRAN-Dè¾ƒåŸºçº¿æ–¹æ³•çš„å¹³å‡ç»å¯¹è¯¯å·®é™ä½äº†è¶…è¿‡39%ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.11069">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2ce4b61fe5d926917d6c440785667e80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60af47cec5a889d087bd0511d8f0167d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93bc2bd63b1df530ffa29258c3d8c8c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e90033766347ee09c7fe8766ee4b64f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e33702f735559bed5ce45a9b9a065cef.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Robust-3D-Masked-Part-level-Editing-in-3D-Gaussian-Splatting-with-Regularized-Score-Distillation-Sampling"><a href="#Robust-3D-Masked-Part-level-Editing-in-3D-Gaussian-Splatting-with-Regularized-Score-Distillation-Sampling" class="headerlink" title="Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with   Regularized Score Distillation Sampling"></a>Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with   Regularized Score Distillation Sampling</h2><p><strong>Authors:Hayeon Kim, Ji Ha Jang, Se Young Chun</strong></p>
<p>Recent advances in 3D neural representations and instance-level editing models have enabled the efficient creation of high-quality 3D content. However, achieving precise local 3D edits remains challenging, especially for Gaussian Splatting, due to inconsistent multi-view 2D part segmentations and inherently ambiguous nature of Score Distillation Sampling (SDS) loss. To address these limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that enables precise and drastic part-level modifications. First, we introduce a robust 3D mask generation module with our 3D-Geometry Aware Label Prediction (3D-GALP), which uses spherical harmonics (SH) coefficients to model view-dependent label variations and soft-label property, yielding accurate and consistent part segmentations across viewpoints. Second, we propose a regularized SDS loss that combines the standard SDS loss with additional regularizers. In particular, an L1 anchor loss is introduced via our Scheduled Latent Mixing and Part (SLaMP) editing method, which generates high-quality part-edited 2D images and confines modifications only to the target region while preserving contextual coherence. Additional regularizers, such as Gaussian prior removal, further improve flexibility by allowing changes beyond the existing context, and robust 3D masking prevents unintended edits. Experimental results demonstrate that our RoMaP achieves state-of-the-art local 3D editing on both reconstructed and generated Gaussian scenes and objects qualitatively and quantitatively, making it possible for more robust and flexible part-level 3D Gaussian editing. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œä¸‰ç»´ç¥ç»è¡¨å¾å’Œå®ä¾‹çº§ç¼–è¾‘æ¨¡å‹çš„è¿›æ­¥ä½¿å¾—é«˜è´¨é‡çš„ä¸‰ç»´å†…å®¹åˆ›ä½œæ•ˆç‡å¤§å¤§æé«˜ã€‚ç„¶è€Œï¼Œå®ç°ç²¾ç¡®å±€éƒ¨ä¸‰ç»´ç¼–è¾‘ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜æ–¯æ‹¼è´´æŠ€æœ¯ä¸­ï¼Œç”±äºå¤šè§†è§’äºŒç»´éƒ¨åˆ†åˆ†å‰²çš„ä¸ä¸€è‡´æ€§å’Œå¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±çš„æœ¬è´¨æ¨¡ç³Šæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†RoMaPï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å±€éƒ¨ä¸‰ç»´é«˜æ–¯ç¼–è¾‘æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°ç²¾ç¡®ä¸”å¤§å¹…çš„éƒ¨åˆ†çº§ä¿®æ”¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç¨³å¥çš„ä¸‰ç»´æ©è†œç”Ÿæˆæ¨¡å—ï¼Œé…åˆæˆ‘ä»¬çš„ä¸‰ç»´å‡ ä½•æ„ŸçŸ¥æ ‡ç­¾é¢„æµ‹ï¼ˆ3D-GALPï¼‰ï¼Œä½¿ç”¨çƒé¢è°æ³¢ï¼ˆSHï¼‰ç³»æ•°æ¥å»ºæ¨¡è§†å›¾ç›¸å…³çš„æ ‡ç­¾å˜åŒ–å’Œè½¯æ ‡ç­¾å±æ€§ï¼Œä»è€Œåœ¨å„ä¸ªè§†ç‚¹ä¸Šå®ç°å‡†ç¡®ä¸”ä¸€è‡´çš„éƒ¨åˆ†åˆ†å‰²ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ­£åˆ™åŒ–çš„SDSæŸå¤±ï¼Œå®ƒå°†æ ‡å‡†SDSæŸå¤±ä¸é¢å¤–çš„æ­£åˆ™åŒ–å™¨ç›¸ç»“åˆã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡è®¡åˆ’çš„æ½œåœ¨æ··åˆå’Œéƒ¨åˆ†ï¼ˆSLaMPï¼‰ç¼–è¾‘æ–¹æ³•å¼•å…¥äº†L1é”šæŸå¤±ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆé«˜è´¨é‡çš„éƒ¨åˆ†ç¼–è¾‘äºŒç»´å›¾åƒï¼Œå¹¶å°†ä¿®æ”¹é™åˆ¶åœ¨ç›®æ ‡åŒºåŸŸï¼ŒåŒæ—¶ä¿ç•™ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚é¢å¤–çš„æ­£åˆ™åŒ–å™¨ï¼Œå¦‚é«˜æ–¯å…ˆéªŒç§»é™¤ï¼Œé€šè¿‡å…è®¸è¶…å‡ºç°æœ‰ä¸Šä¸‹æ–‡çš„æ›´æ”¹æ¥æé«˜çµæ´»æ€§ï¼Œè€Œç¨³å¥çš„ä¸‰ç»´æ©è†œåˆ™é˜²æ­¢äº†æ„å¤–çš„ç¼–è¾‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„RoMaPåœ¨é‡å»ºå’Œç”Ÿæˆçš„é«˜æ–¯åœºæ™¯å’Œå¯¹è±¡ä¸Šå®ç°äº†å…ˆè¿›çš„ä¸‰ç»´å±€éƒ¨ç¼–è¾‘æ•ˆæœï¼Œæ— è®ºæ˜¯ä»ä¸»è§‚è´¨é‡è¯„ä¼°è¿˜æ˜¯å®šé‡è¯„ä¼°æ–¹é¢ã€‚è¿™ä¸ºæ›´ç¨³å¥å’Œçµæ´»çš„éƒ¨åˆ†çº§ä¸‰ç»´é«˜æ–¯ç¼–è¾‘æä¾›äº†å¯èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.11061v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºRoMaPçš„æ–°å‹å±€éƒ¨3Dé«˜æ–¯ç¼–è¾‘æ¡†æ¶ï¼Œè§£å†³äº†ç²¾ç¡®å±€éƒ¨3Dç¼–è¾‘çš„éš¾é¢˜ã€‚é€šè¿‡å¼•å…¥åŸºäº3Då‡ ä½•æ„ŸçŸ¥æ ‡ç­¾é¢„æµ‹çš„æ©è†œç”Ÿæˆæ¨¡å—ï¼Œå¹¶é‡‡ç”¨æ­£åˆ™åŒ–çš„SDSæŸå¤±å‡½æ•°ï¼Œå®ç°äº†ç²¾ç¡®çš„å±€éƒ¨ä¿®æ”¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRoMaPæ¡†æ¶åœ¨é‡å»ºå’Œç”Ÿæˆçš„Gaussianåœºæ™¯å’Œå¯¹è±¡ä¸Šå®ç°äº†å…ˆè¿›çš„å±€éƒ¨3Dç¼–è¾‘æ•ˆæœï¼Œä½¿å¾—é²æ£’æ€§å’Œçµæ´»çš„å±€éƒ¨çº§åˆ«3Dé«˜æ–¯ç¼–è¾‘æˆä¸ºå¯èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RoMaPæ¡†æ¶è§£å†³äº†ç²¾ç¡®å±€éƒ¨3Dç¼–è¾‘çš„éš¾é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜æ–¯ç»˜å›¾é¢†åŸŸã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäº3Då‡ ä½•æ„ŸçŸ¥æ ‡ç­¾é¢„æµ‹çš„æ©è†œç”Ÿæˆæ¨¡å—ï¼Œèƒ½å¤Ÿå‡†ç¡®ä¸”ä¸€è‡´åœ°åˆ†å‰²è·¨ä¸åŒè§†è§’çš„éƒ¨åˆ†ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ­£åˆ™åŒ–çš„SDSæŸå¤±å‡½æ•°ï¼Œç»“åˆäº†æ ‡å‡†SDSæŸå¤±å’Œå…¶ä»–é¢å¤–çš„æ­£åˆ™å™¨ã€‚</li>
<li>L1é”šæŸå¤±é€šè¿‡ç‰¹å®šçš„Scheduled Latent Mixingå’ŒPartï¼ˆSLaMPï¼‰ç¼–è¾‘æ–¹æ³•å¼•å…¥ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„éƒ¨åˆ†ç¼–è¾‘åçš„2Då›¾åƒå¹¶ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚</li>
<li>é€šè¿‡å¼•å…¥é«˜æ–¯å…ˆéªŒç§»é™¤å’Œå…¶ä»–é™„åŠ æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæé«˜äº†æ¡†æ¶çš„çµæ´»æ€§å’Œé²æ£’æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.11061">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b106a05ebc0e79e66c7105cb0c7abd0d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-18e50154576f165cea01da0fed17cb48.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f1567793a303bd46037e8b9089c7f6b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb9c6d8b45f773368e852f409d4db478.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f760d12eb4081e189e92fbad09b25ce.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ScaffoldAvatar-High-Fidelity-Gaussian-Avatars-with-Patch-Expressions"><a href="#ScaffoldAvatar-High-Fidelity-Gaussian-Avatars-with-Patch-Expressions" class="headerlink" title="ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions"></a>ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions</h2><p><strong>Authors:Shivangi Aneja, Sebastian Weiss, Irene Baeza, Prashanth Chandran, Gaspard Zoss, Matthias NieÃŸner, Derek Bradley</strong></p>
<p>Generating high-fidelity real-time animated sequences of photorealistic 3D head avatars is important for many graphics applications, including immersive telepresence and movies. This is a challenging problem particularly when rendering digital avatar close-ups for showing characterâ€™s facial microfeatures and expressions. To capture the expressive, detailed nature of human heads, including skin furrowing and finer-scale facial movements, we propose to couple locally-defined facial expressions with 3D Gaussian splatting to enable creating ultra-high fidelity, expressive and photorealistic 3D head avatars. In contrast to previous works that operate on a global expression space, we condition our avatarâ€™s dynamics on patch-based local expression features and synthesize 3D Gaussians at a patch level. In particular, we leverage a patch-based geometric 3D face model to extract patch expressions and learn how to translate these into local dynamic skin appearance and motion by coupling the patches with anchor points of Scaffold-GS, a recent hierarchical scene representation. These anchors are then used to synthesize 3D Gaussians on-the-fly, conditioned by patch-expressions and viewing direction. We employ color-based densification and progressive training to obtain high-quality results and faster convergence for high resolution 3K training images. By leveraging patch-level expressions, ScaffoldAvatar consistently achieves state-of-the-art performance with visually natural motion, while encompassing diverse facial expressions and styles in real time. </p>
<blockquote>
<p>ç”Ÿæˆé«˜ä¿çœŸå®æ—¶åŠ¨ç”»åºåˆ—çš„å…‰ç…§çœŸå®ä¸‰ç»´å¤´åƒå¯¹äºè®¸å¤šå›¾å½¢åº”ç”¨ç¨‹åºéå¸¸é‡è¦ï¼ŒåŒ…æ‹¬æ²‰æµ¸å¼è¿œç¨‹å­˜åœ¨å’Œç”µå½±ã€‚è¿™æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¸²æŸ“æ•°å­—å¤´åƒç‰¹å†™ä»¥å±•ç¤ºè§’è‰²çš„é¢éƒ¨ç»†å¾®ç‰¹å¾å’Œè¡¨æƒ…æ—¶ã€‚ä¸ºäº†æ•æ‰äººç±»å¤´éƒ¨çš„è¡¨æƒ…å’Œç»†èŠ‚ç‰¹å¾ï¼ŒåŒ…æ‹¬çš®è‚¤è¤¶çš±å’Œæ›´ç²¾ç»†çš„é¢éƒ¨åŠ¨ä½œï¼Œæˆ‘ä»¬æè®®å°†å±€éƒ¨å®šä¹‰çš„é¢éƒ¨è¡¨æƒ…ä¸ä¸‰ç»´é«˜æ–¯å–·æ¶‚ç›¸ç»“åˆï¼Œä»¥åˆ›å»ºè¶…é«˜ä¿çœŸã€è¡¨æƒ…ä¸°å¯Œä¸”å…‰ç…§çœŸå®çš„ä¸‰ç»´å¤´åƒã€‚ä¸ä»¥å‰åœ¨å…¨çƒè¡¨è¾¾ç©ºé—´ä¸Šæ“ä½œçš„å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬å°†å¤´åƒçš„åŠ¨æ€ç‰¹æ€§å»ºç«‹åœ¨åŸºäºè¡¥ä¸çš„å±€éƒ¨è¡¨æƒ…ç‰¹å¾ä¸Šï¼Œå¹¶åœ¨è¡¥ä¸çº§åˆ«ä¸Šåˆæˆä¸‰ç»´é«˜æ–¯ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºè¡¥ä¸çš„ä¸‰ç»´å‡ ä½•é¢éƒ¨æ¨¡å‹æ¥æå–è¡¥ä¸è¡¨æƒ…ï¼Œå¹¶å­¦ä¹ å¦‚ä½•å°†å®ƒä»¬è½¬åŒ–ä¸ºå±€éƒ¨åŠ¨æ€çš®è‚¤å¤–è§‚å’Œè¿åŠ¨ï¼Œé€šè¿‡å°†è¡¥ä¸ä¸æ”¯æ¶GSçš„é”šç‚¹ç›¸ç»“åˆæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚æ”¯æ¶æ˜¯ä¸€ç§æœ€æ–°çš„åˆ†å±‚åœºæ™¯è¡¨ç¤ºã€‚ç„¶åï¼Œè¿™äº›é”šç‚¹è¢«ç”¨æ¥å³æ—¶åˆæˆå—è¡¥ä¸è¡¨è¾¾å’Œè§‚å¯Ÿæ–¹å‘å½±å“çš„ä¸‰ç»´é«˜æ–¯ã€‚æˆ‘ä»¬é‡‡ç”¨åŸºäºé¢œè‰²çš„å¢å¯†å’Œæ¸è¿›è®­ç»ƒæ³•ï¼Œä»¥è·å¾—é«˜è´¨é‡çš„ç»“æœå¹¶åŠ å¿«å¯¹é«˜åˆ†è¾¨ç‡3Kè®­ç»ƒå›¾åƒçš„æ”¶æ•›é€Ÿåº¦ã€‚é€šè¿‡åˆ©ç”¨è¡¥ä¸çº§åˆ«çš„è¡¨è¾¾ï¼Œæ”¯æ¶å¤´åƒä¸€ç›´å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·æœ‰è§†è§‰ä¸Šè‡ªç„¶çš„è¿åŠ¨ï¼ŒåŒæ—¶åŒ…å«å®æ—¶ä¸­çš„å¤šç§é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.10542v1">PDF</a> (SIGGRAPH 2025) Paper Video: <a target="_blank" rel="noopener" href="https://youtu.be/VyWkgsGdbkk">https://youtu.be/VyWkgsGdbkk</a> Project   Page: <a target="_blank" rel="noopener" href="https://shivangi-aneja.github.io/projects/scaffoldavatar/">https://shivangi-aneja.github.io/projects/scaffoldavatar/</a></p>
<p><strong>æ‘˜è¦</strong><br>æœ¬æ–‡ç ”ç©¶äº†åŸºäºå±€éƒ¨å®šä¹‰çš„è¡¨æƒ…ä¸ä¸‰ç»´é«˜æ–¯å±•å¹³æŠ€æœ¯çš„é«˜ä¿çœŸå®æ—¶åŠ¨æ€ä¸‰ç»´å¤´åƒåˆ¶ä½œæŠ€æœ¯ã€‚è¯¥æŠ€æœ¯å¯¹äºå›¾å½¢åº”ç”¨ä¸­çš„æ²‰æµ¸å¼è¿œç¨‹å‡ºå¸­å’Œç”µå½±åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡åˆ©ç”¨å±€éƒ¨è¡¨æƒ…ç‰¹å¾å’Œä¸‰ç»´é«˜æ–¯å±•å¹³æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨è¶…é«˜åˆ†è¾¨ç‡ä¸‹åˆ›å»ºå…·æœ‰è¡¨æƒ…å’ŒçœŸå®æ„Ÿçš„åŠ¨æ€å¤´åƒã€‚è¯¥æŠ€æœ¯é‡‡ç”¨åŸºäºè¡¥ä¸çš„å‡ ä½•é¢éƒ¨æ¨¡å‹æå–è¡¨æƒ…ç‰¹å¾ï¼Œå¹¶å°†è¿™äº›ç‰¹å¾è½¬åŒ–ä¸ºå±€éƒ¨åŠ¨æ€çš®è‚¤å¤–è§‚å’Œè¿åŠ¨ã€‚é€šè¿‡å®æ—¶åˆæˆä¸‰ç»´é«˜æ–¯å›¾åƒï¼Œå®ç°äº†é«˜è´¨é‡ã€è‡ªç„¶è¿åŠ¨çš„å¤´åƒåˆ¶ä½œï¼Œå…·æœ‰å¤šæ ·åŒ–çš„é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿçš„é«˜ä¿çœŸå®æ—¶åŠ¨æ€ä¸‰ç»´å¤´åƒå¯¹äºå›¾å½¢åº”ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>æŠ€æœ¯é‡ç‚¹ç ”ç©¶å¦‚ä½•åœ¨ç»†èŠ‚ä¸°å¯Œä¸”è¡¨è¾¾çœŸå®çš„å¤´åƒåˆ¶ä½œä¸­å±•ç°é¢éƒ¨å¾®è§‚ç‰¹å¾å’Œè¡¨æƒ…ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå±€éƒ¨è¡¨æƒ…ä¸ä¸‰ç»´é«˜æ–¯å±•å¹³æŠ€æœ¯çš„æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºè¶…é«˜åˆ†è¾¨ç‡çš„å¤´åƒã€‚</li>
<li>é‡‡ç”¨åŸºäºè¡¥ä¸çš„å‡ ä½•é¢éƒ¨æ¨¡å‹æå–è¡¨æƒ…ç‰¹å¾ï¼Œå¹¶è½¬åŒ–ä¸ºå±€éƒ¨åŠ¨æ€çš®è‚¤å¤–è§‚å’Œè¿åŠ¨ã€‚</li>
<li>åˆ©ç”¨è¡¥ä¸çº§åˆ«çš„é”šç‚¹åˆæˆä¸‰ç»´é«˜æ–¯å›¾åƒï¼Œå®ç°å®æ—¶åˆæˆé«˜è´¨é‡çš„å¤´åƒã€‚</li>
<li>é‡‡ç”¨é¢œè‰²å¯†é›†åŒ–å’Œæ¸è¿›å¼è®­ç»ƒæŠ€æœ¯æé«˜å¤´åƒè´¨é‡å’Œæ”¶æ•›é€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.10542">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b55fb1f3947f22c8370448ed8a690793.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f139b437c8d51e8e8937344267fb29cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af66de510626b7f389a27d2c3c6e0c74.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68a1932768ce7d0ea6f4f477838950cf.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="3DGAA-Realistic-and-Robust-3D-Gaussian-based-Adversarial-Attack-for-Autonomous-Driving"><a href="#3DGAA-Realistic-and-Robust-3D-Gaussian-based-Adversarial-Attack-for-Autonomous-Driving" class="headerlink" title="3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for   Autonomous Driving"></a>3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for   Autonomous Driving</h2><p><strong>Authors:Yixun Zhang, Lizhi Wang, Junjun Zhao, Wending Zhao, Feng Zhou, Yonghao Dang, Jianqin Yin</strong></p>
<p>Camera-based object detection systems play a vital role in autonomous driving, yet they remain vulnerable to adversarial threats in real-world environments. While existing 2D and 3D physical attacks typically optimize texture, they often struggle to balance physical realism and attack robustness. In this work, we propose 3D Gaussian-based Adversarial Attack (3DGAA), a novel adversarial object generation framework that leverages the full 14-dimensional parameterization of 3D Gaussian Splatting (3DGS) to jointly optimize geometry and appearance in physically realizable ways. Unlike prior works that rely on patches or texture, 3DGAA jointly perturbs both geometric attributes (shape, scale, rotation) and appearance attributes (color, opacity) to produce physically realistic and transferable adversarial objects. We further introduce a physical filtering module to preserve geometric fidelity, and a physical augmentation module to simulate complex physical scenarios, thus enhancing attack generalization under real-world conditions. We evaluate 3DGAA on both virtual benchmarks and physical-world setups using miniature vehicle models. Experimental results show that 3DGAA achieves to reduce the detection mAP from 87.21% to 7.38%, significantly outperforming existing 3D physical attacks. Moreover, our method maintains high transferability across different physical conditions, demonstrating a new state-of-the-art in physically realizable adversarial attacks. These results validate 3DGAA as a practical attack framework for evaluating the safety of perception systems in autonomous driving. </p>
<blockquote>
<p>åŸºäºæ‘„åƒå¤´çš„ç‰©ä½“æ£€æµ‹ç³»ç»Ÿå¯¹è‡ªåŠ¨é©¾é©¶èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½†åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œå®ƒä»¬ä»é¢ä¸´å¯¹æŠ—æ€§å¨èƒçš„è„†å¼±æ€§ã€‚å°½ç®¡ç°æœ‰çš„2Då’Œ3Dç‰©ç†æ”»å‡»é€šå¸¸ä¼˜åŒ–çº¹ç†ï¼Œä½†å®ƒä»¬å¾€å¾€éš¾ä»¥åœ¨ç‰©ç†çœŸå®æ€§å’Œæ”»å‡»ç¨³å¥æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäº3Dé«˜æ–¯çš„å¯¹æŠ—æ”»å‡»ï¼ˆ3DGAAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¯¹æŠ—æ€§ç‰©ä½“ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨3Dé«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰çš„14ç»´å‚æ•°åŒ–ï¼Œä»¥ç‰©ç†å¯å®ç°çš„æ–¹å¼è”åˆä¼˜åŒ–å‡ ä½•å’Œå¤–è§‚ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–äºè¡¥ä¸æˆ–çº¹ç†çš„å·¥ä½œï¼Œ3DGAAåŒæ—¶æ‰°åŠ¨å‡ ä½•å±æ€§ï¼ˆå½¢çŠ¶ã€å°ºåº¦ã€æ—‹è½¬ï¼‰å’Œå¤–è§‚å±æ€§ï¼ˆé¢œè‰²ã€é€æ˜åº¦ï¼‰ï¼Œä»¥äº§ç”Ÿç‰©ç†çœŸå®ä¸”å¯è¿ç§»çš„å¯¹æŠ—æ€§ç‰©ä½“ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥ç‰©ç†æ»¤æ³¢æ¨¡å—ä»¥ä¿æŒå‡ ä½•ä¿çœŸåº¦ï¼Œå¹¶å¼•å…¥ç‰©ç†å¢å¼ºæ¨¡å—æ¥æ¨¡æ‹Ÿå¤æ‚çš„ç‰©ç†åœºæ™¯ï¼Œä»è€Œå¢å¼ºç°å®æ¡ä»¶ä¸‹çš„æ”»å‡»é€šç”¨æ€§ã€‚æˆ‘ä»¬åœ¨è™šæ‹ŸåŸºå‡†æµ‹è¯•å’Œç‰©ç†ç¯å¢ƒè®¾ç½®ä¸­ä½¿ç”¨å°å‹è½¦è¾†æ¨¡å‹å¯¹3DGAAè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ3DGAAå°†æ£€æµ‹mAPä»87.21%é™ä½åˆ°7.38%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰3Dç‰©ç†æ”»å‡»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒç‰©ç†æ¡ä»¶ä¸‹ä¿æŒäº†é«˜å¯è¿ç§»æ€§ï¼Œåœ¨ç‰©ç†å¯å®ç°çš„å¯¹æŠ—æ”»å‡»æ–¹é¢å±•ç°äº†æœ€æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚è¿™äº›ç»“æœéªŒè¯äº†3DGAAä½œä¸ºè¯„ä¼°è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿå®‰å…¨çš„å®é™…æ”»å‡»æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.09993v1">PDF</a> Submitted to WACV 2026</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯ï¼ˆ3DGAAï¼‰çš„æ–°å‹å¯¹æŠ—æ€§æ”»å‡»æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä¸‰ç»´é«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰çš„å®Œæ•´åå››ç»´å‚æ•°åŒ–æ¥è”åˆä¼˜åŒ–å‡ ä½•å’Œå¤–è§‚ï¼Œä»¥ç‰©ç†å¯å®ç°çš„æ–¹å¼å®ç°ã€‚ä¸åŒäºä¾èµ–è¡¥ä¸æˆ–çº¹ç†çš„å…ˆå‰å·¥ä½œï¼Œå®ƒé€šè¿‡è”åˆæ‰°åŠ¨å‡ ä½•å±æ€§å’Œå¤–è§‚å±æ€§æ¥ç”Ÿæˆç‰©ç†çœŸå®çš„å¯¹æŠ—æ€§ç‰©ä½“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºç°æœ‰çš„ä¸‰ç»´ç‰©ç†æ”»å‡»ï¼Œæœ¬æ–‡æå‡ºçš„æ”»å‡»æ¡†æ¶åœ¨è™šæ‹ŸåŸºå‡†æµ‹è¯•å’Œç‰©ç†ä¸–ç•Œè®¾ç½®ä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œå°†æ£€æµ‹mAPä»87.21%é™ä½åˆ°7.38%ï¼Œå¹¶ä¸”åœ¨ä¸åŒç‰©ç†æ¡ä»¶ä¸‹å…·æœ‰è‰¯å¥½çš„å¯è¿ç§»æ€§ã€‚è¿™ä¸ºè¯„ä¼°è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿçš„å®‰å…¨æ€§æä¾›äº†æ–°çš„å®ç”¨æ”»å‡»æ¡†æ¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°å‹å¯¹æŠ—æ€§æ”»å‡»æ¡†æ¶ï¼ˆ3DGAAï¼‰ï¼ŒåŸºäºä¸‰ç»´é«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰æŠ€æœ¯ã€‚</li>
<li>åˆ©ç”¨å®Œæ•´çš„åå››ç»´å‚æ•°åŒ–è”åˆä¼˜åŒ–å‡ ä½•å’Œå¤–è§‚ï¼Œå®ç°ç‰©ç†çœŸå®çš„å¯¹æŠ—æ€§ç‰©ä½“ç”Ÿæˆã€‚</li>
<li>é€šè¿‡æ‰°åŠ¨å‡ ä½•å±æ€§å’Œå¤–è§‚å±æ€§è”åˆç”Ÿæˆå¯¹æŠ—æ€§ç‰©ä½“ï¼Œçªç ´äº†ä¼ ç»Ÿæ”»å‡»æ–¹æ³•çš„å±€é™ã€‚</li>
<li>å¼•å…¥ç‰©ç†è¿‡æ»¤æ¨¡å—ä»¥ä¿æŒå‡ ä½•ä¿çœŸåº¦ï¼Œå¹¶å¼•å…¥ç‰©ç†å¢å¼ºæ¨¡å—æ¨¡æ‹Ÿå¤æ‚ç‰©ç†åœºæ™¯ï¼Œå¢å¼ºäº†æ”»å‡»åœ¨ç°å®æ¡ä»¶ä¸‹çš„é€šç”¨æ€§ã€‚</li>
<li>åœ¨è™šæ‹ŸåŸºå‡†æµ‹è¯•å’Œç‰©ç†ä¸–ç•Œè®¾ç½®ä¸­è¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œæ˜¾è‘—é™ä½äº†ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>æ”»å‡»æ¡†æ¶åœ¨ä¸åŒç‰©ç†æ¡ä»¶ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„å¯è¿ç§»æ€§ï¼Œä¸ºè¯„ä¼°è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿå®‰å…¨æ€§æä¾›äº†å®ç”¨å·¥å…·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.09993">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-02a3f6a55d02c93c0416af7451e02565.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9cc45d66d58265c1a78e561fc45cfc51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-802d34da79f7a03e02294b37ee0e3b3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8bacaa1d87c2d16712853e6adce893f9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-906db25552a6eab62ac1669e8a80ed80.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f008a558637885efc40c0694e12ff57c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BayesSDF-Surface-Based-Laplacian-Uncertainty-Estimation-for-3D-Geometry-with-Neural-Signed-Distance-Fields"><a href="#BayesSDF-Surface-Based-Laplacian-Uncertainty-Estimation-for-3D-Geometry-with-Neural-Signed-Distance-Fields" class="headerlink" title="BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry   with Neural Signed Distance Fields"></a>BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry   with Neural Signed Distance Fields</h2><p><strong>Authors:Rushil Desai</strong></p>
<p>Quantifying uncertainty in neural implicit 3D representations, particularly those utilizing Signed Distance Functions (SDFs), remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. Existing methods typically neglect direct geometric integration, leading to poorly calibrated uncertainty maps. We introduce BayesSDF, a novel probabilistic framework for uncertainty quantification in neural implicit SDF models, motivated by scientific simulation applications with 3D environments (e.g., forests) such as modeling fluid flow through forests, where precise surface geometry and reliable uncertainty estimates are essential. Unlike radiance-based models such as Neural Radiance Fields (NeRF) or 3D Gaussian splatting, which lack explicit surface formulations, Signed Distance Functions (SDFs) define continuous and differentiable geometry, making them better suited for physical modeling and analysis. BayesSDF leverages a Laplace approximation to quantify local surface instability using Hessian-based metrics, enabling efficient, surfaceaware uncertainty estimation. Our method shows that uncertainty predictions correspond closely with poorly reconstructed geometry, providing actionable confidence measures for downstream use. Extensive evaluations on synthetic and real-world datasets demonstrate that BayesSDF outperforms existing methods in both calibration and geometric consistency, establishing a strong foundation for uncertainty-aware 3D scene reconstruction, simulation, and robotic decision-making. </p>
<blockquote>
<p>åœ¨ç¥ç»éšå¼ä¸‰ç»´è¡¨ç¤ºä¸­é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ä½¿ç”¨å¸¦ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFsï¼‰çš„è¡¨ç¤ºï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºè®¡ç®—æ•ˆç‡ä½ä¸‹ã€å¯æ‰©å±•æ€§é—®é¢˜ä»¥åŠå‡ ä½•ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å¿½ç•¥äº†ç›´æ¥çš„å‡ ä½•é›†æˆï¼Œå¯¼è‡´æ ¡å‡†ä¸è‰¯çš„ä¸ç¡®å®šæ€§æ˜ å°„ã€‚æˆ‘ä»¬å¼•å…¥äº†BayesSDFï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºç¥ç»éšå¼SDFæ¨¡å‹ä¸­ä¸ç¡®å®šæ€§é‡åŒ–çš„æ–°å‹æ¦‚ç‡æ¡†æ¶ï¼Œå…¶çµæ„Ÿæ¥æºäºå…·æœ‰ä¸‰ç»´ç¯å¢ƒçš„ç§‘å­¦æ¨¡æ‹Ÿåº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚æ£®æ—æ¨¡æ‹Ÿï¼‰ï¼Œå¦‚æ£®æ—ä¸­çš„æ°´æµå»ºæ¨¡ï¼Œå…¶ä¸­ç²¾ç¡®çš„æ›²é¢å‡ ä½•å’Œå¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ˜¯å¿…ä¸å¯å°‘çš„ã€‚ä¸åŸºäºè¾å°„çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æˆ–ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼‰ä¸åŒï¼Œåè€…ç¼ºä¹æ˜ç¡®çš„è¡¨é¢å…¬å¼ï¼Œå¸¦ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFsï¼‰å®šä¹‰äº†è¿ç»­ä¸”å¯å¾®åˆ†çš„å‡ ä½•å½¢çŠ¶ï¼Œä½¿å…¶æ›´é€‚åˆç‰©ç†å»ºæ¨¡å’Œåˆ†æã€‚BayesSDFåˆ©ç”¨æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼å€¼æ¥é‡åŒ–åŸºäºHessianåº¦é‡çš„å±€éƒ¨è¡¨é¢ä¸ç¨³å®šæ€§ï¼Œä»è€Œå®ç°é«˜æ•ˆã€é¢å‘è¡¨é¢çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨æ˜ï¼Œä¸ç¡®å®šæ€§é¢„æµ‹ä¸é‡å»ºä¸è‰¯çš„å‡ ä½•å½¢çŠ¶ç´§å¯†å¯¹åº”ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›äº†å¯è¡Œçš„ç½®ä¿¡åº¦åº¦é‡ã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œåœ¨æ ¡å‡†å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢ï¼ŒBayesSDFä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„3Dåœºæ™¯é‡å»ºã€æ¨¡æ‹Ÿå’Œæœºå™¨äººå†³ç­–åˆ¶å®šå»ºç«‹äº†åšå®çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06269v2">PDF</a> ICCV 2025 Workshops (8 Pages, 6 Figures, 2 Tables)</p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œéšå¼ä¸‰ç»´è¡¨ç¤ºä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ç¬¦å·è·ç¦»å‡½æ•°ï¼ˆSDFsï¼‰çš„æƒ…å†µä¸‹ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºè®¡ç®—æ•ˆç‡ä½ä¸‹ã€å¯æ‰©å±•æ€§é—®é¢˜ä»¥åŠå‡ ä½•ä¸ä¸€è‡´æ€§ã€‚å¿½è§†ç›´æ¥å‡ ä½•é›†æˆå¯¼è‡´ä¸ç¡®å®šæ€§æ˜ å°„æ ¡å‡†ä¸è‰¯ã€‚æˆ‘ä»¬æå‡ºBayesSDFï¼Œä¸€ä¸ªç”¨äºç¥ç»ç½‘ç»œéšå¼SDFæ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–çš„æ–°å‹æ¦‚ç‡æ¡†æ¶ï¼Œå…¶çµæ„Ÿæ¥æºäºéœ€è¦ç²¾ç¡®è¡¨é¢å‡ ä½•å’Œå¯é ä¸ç¡®å®šæ€§ä¼°è®¡çš„3Dç¯å¢ƒæ¨¡æ‹Ÿåº”ç”¨ï¼ˆå¦‚æ£®æ—ä¸­çš„æ°´æµï¼‰ã€‚ä¸åŒäºåŸºäºè¾å°„çš„æ¨¡å‹ï¼ˆå¦‚ç¥ç»è¾å°„åœºæˆ–3Dé«˜æ–¯æ‹¼è´´ï¼‰ï¼Œç¬¦å·è·ç¦»å‡½æ•°å®šä¹‰è¿ç»­å¯å¾®çš„å‡ ä½•å½¢çŠ¶ï¼Œä½¿å…¶æ›´é€‚åˆç‰©ç†å»ºæ¨¡å’Œåˆ†æã€‚BayesSDFåˆ©ç”¨æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼å€¼ï¼Œä½¿ç”¨åŸºäºHessiançš„åº¦é‡æ¥è¡¡é‡å±€éƒ¨è¡¨é¢ä¸ç¨³å®šæ€§ï¼Œä»è€Œå®ç°é«˜æ•ˆã€å…³æ³¨è¡¨é¢çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¾ç¤ºï¼Œä¸ç¡®å®šæ€§é¢„æµ‹ä¸é‡å»ºä¸è‰¯çš„å‡ ä½•å½¢çŠ¶ç´§å¯†å¯¹åº”ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›äº†å¯è¡Œçš„ç½®ä¿¡åº¦åº¦é‡ã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒBayesSDFåœ¨æ ¡å‡†å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„3Dåœºæ™¯é‡å»ºã€æ¨¡æ‹Ÿå’Œæœºå™¨äººå†³ç­–æä¾›äº†åšå®çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œéšå¼ä¸‰ç»´è¡¨ç¤ºä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–é¢ä¸´è®¡ç®—æ•ˆç‡ã€å¯æ‰©å±•æ€§å’Œå‡ ä½•ä¸ä¸€è‡´æ€§çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½è§†ç›´æ¥å‡ ä½•é›†æˆï¼Œå¯¼è‡´ä¸ç¡®å®šæ€§æ˜ å°„æ ¡å‡†ä¸è‰¯ã€‚</li>
<li>BayesSDFæ˜¯ä¸€ä¸ªæ–°å‹æ¦‚ç‡æ¡†æ¶ï¼Œç”¨äºç¥ç»ç½‘ç»œéšå¼SDFæ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚</li>
<li>BayesSDFé€‚ç”¨äºéœ€è¦ç²¾ç¡®è¡¨é¢å‡ ä½•å’Œå¯é ä¸ç¡®å®šæ€§ä¼°è®¡çš„3Dç¯å¢ƒæ¨¡æ‹Ÿåº”ç”¨ã€‚</li>
<li>ç¬¦å·è·ç¦»å‡½æ•°èƒ½å®šä¹‰è¿ç»­å¯å¾®çš„å‡ ä½•å½¢çŠ¶ï¼Œä½¿å…¶æ›´é€‚åˆç‰©ç†å»ºæ¨¡å’Œåˆ†æã€‚</li>
<li>BayesSDFåˆ©ç”¨æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼å’ŒHessianåº¦é‡è¡¡é‡å±€éƒ¨è¡¨é¢ä¸ç¨³å®šæ€§ï¼Œå®ç°é«˜æ•ˆã€å…³æ³¨è¡¨é¢çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06269">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e4732eac41095a2c2e3d100a11670b3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78019045f314a3ea7e5d4034d8174e9c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-894e9f3d1a97ef18374a6596eab94432.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Sparfels-Fast-Reconstruction-from-Sparse-Unposed-Imagery"><a href="#Sparfels-Fast-Reconstruction-from-Sparse-Unposed-Imagery" class="headerlink" title="Sparfels: Fast Reconstruction from Sparse Unposed Imagery"></a>Sparfels: Fast Reconstruction from Sparse Unposed Imagery</h2><p><strong>Authors:Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma</strong></p>
<p>We present a method for Sparse view reconstruction with surface element splatting that runs within 3 minutes on a consumer grade GPU. While few methods address sparse radiance field learning from noisy or unposed sparse cameras, shape recovery remains relatively underexplored in this setting. Several radiance and shape learning test-time optimization methods address the sparse posed setting by learning data priors or using combinations of external monocular geometry priors. Differently, we propose an efficient and simple pipeline harnessing a single recent 3D foundation model. We leverage its various task heads, notably point maps and camera initializations to instantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image correspondences to guide camera optimization midst 2DGS training. Key to our contribution is a novel formulation of splatted color variance along rays, which can be computed efficiently. Reducing this moment in training leads to more accurate shape reconstructions. We demonstrate state-of-the-art performances in the sparse uncalibrated setting in reconstruction and novel view benchmarks based on established multi-view datasets. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´æŠ€æœ¯çš„ç¨€ç–è§†å›¾é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œæ—¶é—´ä¸è¶…è¿‡3åˆ†é’Ÿã€‚å°½ç®¡å·²æœ‰å°‘æ•°æ–¹æ³•è§£å†³äº†ä»å™ªå£°æˆ–æœªæ ¡å‡†çš„ç¨€ç–ç›¸æœºä¸­å­¦ä¹ ç¨€ç–è¾å°„åœºçš„é—®é¢˜ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½¢çŠ¶æ¢å¤çš„æ¢ç´¢ä»ç„¶ç›¸å¯¹è¾ƒå°‘ã€‚ä¸€äº›è¾å°„å’Œå½¢çŠ¶å­¦ä¹ æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•é€šè¿‡å­¦ä¹ æ•°æ®å…ˆéªŒæˆ–ä½¿ç”¨å¤–éƒ¨å•çœ¼å‡ ä½•å…ˆéªŒçš„ç»„åˆæ¥è§£å†³ç¨€ç–å®šä½è®¾ç½®é—®é¢˜ã€‚ä¸ä¹‹ä¸åŒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”ç®€å•çš„æµç¨‹ï¼Œåˆ©ç”¨æœ€æ–°çš„å•ä¸€3DåŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬åˆ©ç”¨å…¶å„ç§ä»»åŠ¡å¤´ï¼Œç‰¹åˆ«æ˜¯ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–æ¥å®ä¾‹åŒ–è°ƒæ•´æŸçš„äºŒç»´é«˜æ–¯æ‹¼è´´ï¼ˆ2DGSï¼‰æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æ¥æŒ‡å¯¼2DGSè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›¸æœºä¼˜åŒ–ã€‚æˆ‘ä»¬è´¡çŒ®çš„å…³é”®åœ¨äºæ²¿å°„çº¿æ‹¼è´´é¢œè‰²æ–¹å·®çš„æ–°å…¬å¼ï¼Œè¯¥å…¬å¼å¯ä»¥é«˜æ•ˆè®¡ç®—ã€‚åœ¨è®­ç»ƒä¸­å‡å°‘è¿™ä¸€æ—¶åˆ»ä¼šå¯¼è‡´æ›´å‡†ç¡®çš„å½¢çŠ¶é‡å»ºã€‚æˆ‘ä»¬åœ¨ç¨€ç–æœªæ ¡å‡†è®¾ç½®ä¸‹çš„é‡å»ºå’ŒåŸºäºç°æœ‰å¤šè§†å›¾æ•°æ®é›†çš„æ–°è§†å›¾åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.02178v2">PDF</a> ICCV 2025. Project page :   <a target="_blank" rel="noopener" href="https://shubhendu-jena.github.io/Sparfels-web/">https://shubhendu-jena.github.io/Sparfels-web/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´æŠ€æœ¯çš„ç¨€ç–è§†è§’é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œæ—¶é—´ä¸è¶…è¿‡3åˆ†é’Ÿã€‚å°½ç®¡å·²æœ‰ä¸€äº›æ–¹æ³•è§£å†³äº†ç¨€ç–è¾å°„åœºå­¦ä¹ çš„é—®é¢˜ï¼Œä½†åœ¨å™ªå£°æˆ–æ— å§¿æ€ç¨€ç–ç›¸æœºçš„æƒ…å†µä¸‹ï¼Œå½¢çŠ¶æ¢å¤çš„æ¢ç´¢ç›¸å¯¹è¾ƒå°‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åŒäºç°æœ‰çš„æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•é€šè¿‡æ•°æ®å…ˆéªŒæˆ–å¤–éƒ¨å•çœ¼å‡ ä½•å…ˆéªŒçš„ç»„åˆæ¥è§£å†³ç¨€ç–å®šä½è®¾ç½®çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºä¸€ç§é«˜æ•ˆä¸”ç®€å•çš„ç®¡é“ï¼Œåˆ©ç”¨æœ€æ–°çš„å•ä¸€3DåŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬åˆ©ç”¨å…¶å„ç§ä»»åŠ¡å¤´ï¼Œç‰¹åˆ«æ˜¯ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–æ¥å®ä¾‹åŒ–æŸè°ƒæ•´äºŒç»´é«˜æ–¯æ‹¼è´´æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æŒ‡å¯¼ç›¸æœºä¼˜åŒ–åœ¨äºŒç»´GSè®­ç»ƒæœŸé—´ã€‚æˆ‘ä»¬å·¥ä½œçš„å…³é”®åˆ›æ–°åœ¨äºæ²¿å°„çº¿æ‹¼è´´é¢œè‰²æ–¹å·®çš„æ–°å…¬å¼ï¼Œè¯¥å…¬å¼å¯ä»¥é«˜æ•ˆè®¡ç®—ã€‚åœ¨è®­ç»ƒä¸­å‡å°‘è¿™ä¸€æ—¶åˆ»ä¼šå¯¼è‡´æ›´å‡†ç¡®çš„å½¢çŠ¶é‡å»ºã€‚æˆ‘ä»¬åœ¨ç¨€ç–æœªæ ¡å‡†ç¯å¢ƒä¸­å±•ç¤ºäº†åœ¨é‡å»ºå’ŒåŸºäºå¤šè§†è§’æ•°æ®é›†çš„æ–°è§†è§’åŸºå‡†æµ‹è¯•ä¸­çš„æœ€ä½³æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ƒç´ æ‹¼è´´æŠ€æœ¯çš„ç¨€ç–è§†è§’é‡å»ºæ–¹æ³•ï¼Œèƒ½åœ¨æ¶ˆè´¹çº§GPUä¸Šå¿«é€Ÿè¿è¡Œã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦è§£å†³ç¨€ç–è¾å°„åœºå­¦ä¹ é—®é¢˜ï¼Œè€Œè¯¥ç ”ç©¶åœ¨å™ªå£°æˆ–æ— å§¿æ€ç¨€ç–ç›¸æœºæ¡ä»¶ä¸‹å¯¹å½¢çŠ¶æ¢å¤çš„æ¢ç´¢å…·æœ‰åˆ›æ–°æ€§ã€‚</li>
<li>ä¸å…¶ä»–æµ‹è¯•æ—¶é—´ä¼˜åŒ–æ–¹æ³•ä¸åŒï¼Œè¯¥ç ”ç©¶åˆ©ç”¨å•ä¸€3DåŸºç¡€æ¨¡å‹ï¼Œåˆ©ç”¨å…¶ç‚¹å›¾å’Œç›¸æœºåˆå§‹åŒ–ç­‰ä»»åŠ¡å¤´æ¥å®ç°é«˜æ•ˆé‡å»ºã€‚</li>
<li>ç ”ç©¶ä¸­æå‡ºäº†æ²¿å°„çº¿æ‹¼è´´é¢œè‰²æ–¹å·®çš„æ–°å…¬å¼ï¼Œå¯é«˜æ•ˆè®¡ç®—ä»¥æé«˜å½¢çŠ¶é‡å»ºçš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç¨€ç–æœªæ ¡å‡†ç¯å¢ƒä¸­çš„é‡å»ºå’Œæ–°è§†è§’åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ã€‚</li>
<li>åˆ©ç”¨å›¾åƒå¯¹åº”å…³ç³»æ¥æŒ‡å¯¼ç›¸æœºä¼˜åŒ–åœ¨äºŒç»´GSè®­ç»ƒæœŸé—´çš„è¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.02178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3644046175101076ff0094314bacc44c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf25476d8c5619f994d28881ef64681c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc06a9504ea90975e1a1236c6b411a72.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CoMoGaussian-Continuous-Motion-Aware-Gaussian-Splatting-from-Motion-Blurred-Images"><a href="#CoMoGaussian-Continuous-Motion-Aware-Gaussian-Splatting-from-Motion-Blurred-Images" class="headerlink" title="CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from   Motion-Blurred Images"></a>CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from   Motion-Blurred Images</h2><p><strong>Authors:Jungho Lee, Donghyeong Kim, Dogyoon Lee, Suhwan Cho, Minhyeok Lee, Wonjoon Lee, Taeoh Kim, Dongyoon Wee, Sangyoun Lee</strong></p>
<p>3D Gaussian Splatting (3DGS) has gained significant attention due to its high-quality novel view rendering, motivating research to address real-world challenges. A critical issue is the camera motion blur caused by movement during exposure, which hinders accurate 3D scene reconstruction. In this study, we propose CoMoGaussian, a Continuous Motion-Aware Gaussian Splatting that reconstructs precise 3D scenes from motion-blurred images while maintaining real-time rendering speed. Considering the complex motion patterns inherent in real-world camera movements, we predict continuous camera trajectories using neural ordinary differential equations (ODEs). To ensure accurate modeling, we employ rigid body transformations, preserving the shape and size of the object but rely on the discrete integration of sampled frames. To better approximate the continuous nature of motion blur, we introduce a continuous motion refinement (CMR) transformation that refines rigid transformations by incorporating additional learnable parameters. By revisiting fundamental camera theory and leveraging advanced neural ODE techniques, we achieve precise modeling of continuous camera trajectories, leading to improved reconstruction accuracy. Extensive experiments demonstrate state-of-the-art performance both quantitatively and qualitatively on benchmark datasets, which include a wide range of motion blur scenarios, from moderate to extreme blur. </p>
<blockquote>
<p>3Dé«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆ3DGSï¼‰å› å…¶é«˜è´¨é‡çš„æ–°è§†è§’æ¸²æŸ“è€Œå¤‡å—å…³æ³¨ï¼Œä»è€Œæ¿€åŠ±ç ”ç©¶è€…åº”å¯¹çœŸå®ä¸–ç•Œçš„æŒ‘æˆ˜ã€‚ä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯æ›å…‰è¿‡ç¨‹ä¸­è¿åŠ¨é€ æˆçš„ç›¸æœºè¿åŠ¨æ¨¡ç³Šï¼Œè¿™é˜»ç¢äº†å‡†ç¡®çš„3Dåœºæ™¯é‡å»ºã€‚æœ¬ç ”ç©¶æå‡ºäº†CoMoGaussianï¼Œä¸€ç§è¿ç»­è¿åŠ¨æ„ŸçŸ¥é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»è¿åŠ¨æ¨¡ç³Šå›¾åƒé‡å»ºç²¾ç¡®çš„3Dåœºæ™¯ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚è€ƒè™‘åˆ°çœŸå®ä¸–ç•Œç›¸æœºè¿åŠ¨æ‰€å›ºæœ‰çš„å¤æ‚è¿åŠ¨æ¨¡å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹é¢„æµ‹è¿ç»­çš„ç›¸æœºè½¨è¿¹ã€‚ä¸ºäº†ç¡®ä¿å‡†ç¡®å»ºæ¨¡ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆšä½“å˜æ¢ï¼Œä¿æŒç‰©ä½“çš„å½¢çŠ¶å’Œå¤§å°ä¸å˜ï¼Œä½†ä¾èµ–äºé‡‡æ ·å¸§çš„ç¦»æ•£ç§¯åˆ†ã€‚ä¸ºäº†æ›´å¥½åœ°è¿‘ä¼¼è¿åŠ¨æ¨¡ç³Šçš„è¿ç»­æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¿ç»­è¿åŠ¨ç»†åŒ–ï¼ˆCMRï¼‰å˜æ¢ï¼Œé€šè¿‡å¼•å…¥é¢å¤–çš„å¯å­¦ä¹ å‚æ•°æ¥ä¼˜åŒ–åˆšä½“å˜æ¢ã€‚é€šè¿‡é‡æ–°ç ”ç©¶åŸºæœ¬çš„ç›¸æœºç†è®ºå¹¶åˆ©ç”¨å…ˆè¿›çš„ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹æŠ€æœ¯ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹è¿ç»­ç›¸æœºè½¨è¿¹çš„ç²¾ç¡®å»ºæ¨¡ï¼Œæé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šåœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œæ¶µç›–äº†ä»è½»åº¦åˆ°é‡åº¦æ¨¡ç³Šçš„å¹¿æ³›è¿åŠ¨æ¨¡ç³Šåœºæ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.05332v2">PDF</a> Revised Version of CRiM-GS, Project Page:   <a target="_blank" rel="noopener" href="https://jho-yonsei.github.io/CoMoGaussian">https://Jho-Yonsei.github.io/CoMoGaussian</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹ç›¸æœºè¿åŠ¨æ¨¡ç³Šé—®é¢˜æå‡ºçš„è¿ç»­è¿åŠ¨æ„ŸçŸ¥é«˜æ–¯èåˆæŠ€æœ¯ï¼ˆCoMoGaussianï¼‰ã€‚è¯¥æŠ€æœ¯èƒ½å¤Ÿé‡å»ºç²¾ç¡®çš„3Dåœºæ™¯ï¼Œå¹¶ç»´æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚é€šè¿‡åˆ©ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹é¢„æµ‹è¿ç»­ç›¸æœºè½¨è¿¹ï¼Œå¹¶ç»“åˆè¿ç»­è¿åŠ¨ç»†åŒ–æŠ€æœ¯ï¼ˆCMRï¼‰ï¼Œå®ç°å¯¹å¤æ‚è¿åŠ¨æ¨¡å¼çš„ç²¾ç¡®å»ºæ¨¡ï¼Œä»è€Œæé«˜äº†é‡å»ºå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒ…å«å¤šç§è¿åŠ¨æ¨¡ç³Šåœºæ™¯çš„åŸºå‡†æ•°æ®é›†ä¸Šï¼Œå…¶æ€§èƒ½è¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸‰ç»´é«˜æ–¯èåˆæŠ€æœ¯ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†å›¾æ¸²æŸ“ä¸­çš„åº”ç”¨åŠå…¶å¯¹ç°å®ä¸–ç•ŒæŒ‘æˆ˜çš„æ„ä¹‰ã€‚</li>
<li>å¼ºè°ƒäº†ç›¸æœºè¿åŠ¨æ¨¡ç³Šå¯¹å‡†ç¡®ä¸‰ç»´åœºæ™¯é‡å»ºçš„å½±å“ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºCoMoGaussiançš„è¿ç»­è¿åŠ¨æ„ŸçŸ¥é«˜æ–¯èåˆæŠ€æœ¯æ¥è§£å†³è¿åŠ¨æ¨¡ç³Šé—®é¢˜ã€‚è¯¥æŠ€æœ¯å¯åœ¨é‡å»ºè¿‡ç¨‹ä¸­ç»´æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.05332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-670b42f6e49529669f49cc4e906cab8d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d0caf58cc6e908e21fbf481bcde83ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd5054acd9a4418810d18f9d450270bb.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SEGS-SLAM-Structure-enhanced-3D-Gaussian-Splatting-SLAM-with-Appearance-Embedding"><a href="#SEGS-SLAM-Structure-enhanced-3D-Gaussian-Splatting-SLAM-with-Appearance-Embedding" class="headerlink" title="SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance   Embedding"></a>SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance   Embedding</h2><p><strong>Authors:Tianci Wen, Zhiang Liu, Yongchun Fang</strong></p>
<p>3D Gaussian splatting (3D-GS) has recently revolutionized novel view synthesis in the simultaneous localization and mapping (SLAM) problem. However, most existing algorithms fail to fully capture the underlying structure, resulting in structural inconsistency. Additionally, they struggle with abrupt appearance variations, leading to inconsistent visual quality. To address these problems, we propose SEGS-SLAM, a structure-enhanced 3D Gaussian Splatting SLAM, which achieves high-quality photorealistic mapping. Our main contributions are two-fold. First, we propose a structure-enhanced photorealistic mapping (SEPM) framework that, for the first time, leverages highly structured point cloud to initialize structured 3D Gaussians, leading to significant improvements in rendering quality. Second, we propose Appearance-from-Motion embedding (AfME), enabling 3D Gaussians to better model image appearance variations across different camera poses. Extensive experiments on monocular, stereo, and RGB-D datasets demonstrate that SEGS-SLAM significantly outperforms state-of-the-art (SOTA) methods in photorealistic mapping quality, e.g., an improvement of $19.86%$ in PSNR over MonoGS on the TUM RGB-D dataset for monocular cameras. The project page is available at <a target="_blank" rel="noopener" href="https://segs-slam.github.io/">https://segs-slam.github.io/</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯å–·æº…ï¼ˆ3D-GSï¼‰æœ€è¿‘ä¸ºåŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰é—®é¢˜ä¸­çš„æ–°å‹è§†å›¾åˆæˆå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç®—æ³•æ— æ³•å®Œå…¨æ•æ‰åº•å±‚ç»“æ„ï¼Œå¯¼è‡´ç»“æ„ä¸ä¸€è‡´ã€‚æ­¤å¤–ï¼Œå®ƒä»¬è¿˜éš¾ä»¥åº”å¯¹çªå‘çš„å¤–è§‚å˜åŒ–ï¼Œå¯¼è‡´è§†è§‰è´¨é‡ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SEGS-SLAMï¼Œä¸€ç§ç»“æ„å¢å¼ºçš„3Dé«˜æ–¯å–·æº…SLAMï¼Œå®ç°é«˜è´¨é‡çš„ç…§ç‰‡çº§æ˜ å°„ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æœ‰ä¸¤ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ç»“æ„å¢å¼ºçš„ç…§ç‰‡çº§æ˜ å°„ï¼ˆSEPMï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é¦–æ¬¡åˆ©ç”¨é«˜åº¦ç»“æ„çš„ç‚¹äº‘æ¥åˆå§‹åŒ–ç»“æ„åŒ–3Dé«˜æ–¯ï¼Œä»è€Œåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢å®ç°äº†æ˜¾è‘—æ”¹è¿›ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†è¿åŠ¨ä¸­çš„å¤–è§‚åµŒå…¥ï¼ˆAfMEï¼‰ï¼Œä½¿3Dé«˜æ–¯èƒ½å¤Ÿæ›´å¥½åœ°æ¨¡æ‹Ÿä¸åŒç›¸æœºå§¿æ€ä¸‹å›¾åƒçš„å¤–è§‚å˜åŒ–ã€‚åœ¨å•ç›®ã€ç«‹ä½“å’ŒRGB-Dæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSEGS-SLAMåœ¨ç…§ç‰‡çº§æ˜ å°„è´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨TUM RGB-Dæ•°æ®é›†ä¸Šçš„å•ç›®ç›¸æœºPSNRæé«˜äº†19.86%ã€‚é¡¹ç›®é¡µé¢å¯åœ¨[<a target="_blank" rel="noopener" href="https://segs-slam.github.io/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://segs-slam.github.io/]ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05242v3">PDF</a> ICCV 2025 accept;code, video, demos, and project are available at   Project page <a target="_blank" rel="noopener" href="https://segs-slam.github.io/">https://segs-slam.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SEGS-SLAMï¼ˆç»“æ„å¢å¼ºä¸‰ç»´é«˜æ–¯æ˜ å°„SLAMï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯è§£å†³äº†åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰é—®é¢˜ä¸­çš„ç»“æ„ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚æ–‡ç« çš„æ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬åˆ©ç”¨ç»“æ„åŒ–ç‚¹äº‘åˆå§‹åŒ–ç»“æ„åŒ–ä¸‰ç»´é«˜æ–¯ï¼ˆSEPMæ¡†æ¶ï¼‰å’Œä»è¿åŠ¨è·å–å¤–è§‚åµŒå…¥ï¼ˆAfMEï¼‰ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜SEGS-SLAMåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚æ–‡ç« è¿˜å¯¹æŠ€æœ¯çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåšäº†ä»‹ç»ã€‚å…³äºSEGS-SLAMé¡¹ç›®ï¼Œå¯åœ¨å®˜ç½‘<a target="_blank" rel="noopener" href="https://segs-slam.github.ioä¸Šè·å–æ›´å¤šä¿¡æ¯./">https://segs-slam.github.ioä¸Šè·å–æ›´å¤šä¿¡æ¯ã€‚</a> </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SEGS-SLAMè§£å†³äº†ç°æœ‰SLAMç®—æ³•æ— æ³•å®Œå…¨æ•æ‰åº•å±‚ç»“æ„çš„é—®é¢˜ï¼Œå®ç°äº†é«˜è´¨é‡çš„å…‰æ …åŒ–æ˜ å°„ã€‚</li>
<li>SEGS-SLAMé€šè¿‡SEPMæ¡†æ¶é¦–æ¬¡åˆ©ç”¨ç»“æ„åŒ–ç‚¹äº‘åˆå§‹åŒ–ç»“æ„åŒ–ä¸‰ç»´é«˜æ–¯ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡ã€‚</li>
<li>SEGS-SLAMé€šè¿‡AfMEæŠ€æœ¯ä½¿ä¸‰ç»´é«˜æ–¯æ›´å¥½åœ°æ¨¡æ‹Ÿä¸åŒç›¸æœºå§¿æ€ä¸‹çš„å›¾åƒå¤–è§‚å˜åŒ–ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSEGS-SLAMåœ¨å•ç›®ã€ç«‹ä½“å’ŒRGB-Dæ•°æ®é›†ä¸Šçš„å…‰æ …åŒ–æ˜ å°„è´¨é‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨TUM RGB-Dæ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºMonoGSï¼ŒSEGS-SLAMåœ¨PSNRä¸Šæé«˜äº†19.86%ã€‚</li>
<li>SEGS-SLAMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œè‡ªåŠ¨å¯¼èˆªç­‰é¢†åŸŸã€‚ </li>
<li>ç”¨æˆ·å¯ä»¥é€šè¿‡åœ¨çº¿é¡¹ç›®é¡µé¢äº†è§£æ›´å¤šå…³äºSEGS-SLAMçš„ä¿¡æ¯å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚è¯¥é¡¹ç›®é¡µé¢çš„é“¾æ¥æ˜¯ï¼š<a target="_blank" rel="noopener" href="https://segs-slam.github.io/">https://segs-slam.github.io</a>ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05242">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f09cc6961848579a6f9b88700a4f98a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9666756b2beffc2ecf8038fdd5a75419.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f42c766666aa0385bd0fbcbcae5f13d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-807052d7d70ff90029e01de10284ba60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f225625ab96cc6ecf649ae24d1d1f6ff.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SLGaussian-Fast-Language-Gaussian-Splatting-in-Sparse-Views"><a href="#SLGaussian-Fast-Language-Gaussian-Splatting-in-Sparse-Views" class="headerlink" title="SLGaussian: Fast Language Gaussian Splatting in Sparse Views"></a>SLGaussian: Fast Language Gaussian Splatting in Sparse Views</h2><p><strong>Authors:Kangjie Chen, BingQuan Dai, Minghan Qin, Dongbin Zhang, Peihao Li, Yingshuang Zou, Haoqian Wang</strong></p>
<p>3D semantic field learning is crucial for applications like autonomous navigation, AR&#x2F;VR, and robotics, where accurate comprehension of 3D scenes from limited viewpoints is essential. Existing methods struggle under sparse view conditions, relying on inefficient per-scene multi-view optimizations, which are impractical for many real-world tasks. To address this, we propose SLGaussian, a feed-forward method for constructing 3D semantic fields from sparse viewpoints, allowing direct inference of 3DGS-based scenes. By ensuring consistent SAM segmentations through video tracking and using low-dimensional indexing for high-dimensional CLIP features, SLGaussian efficiently embeds language information in 3D space, offering a robust solution for accurate 3D scene understanding under sparse view conditions. In experiments on two-view sparse 3D object querying and segmentation in the LERF and 3D-OVS datasets, SLGaussian outperforms existing methods in chosen IoU, Localization Accuracy, and mIoU. Moreover, our model achieves scene inference in under 30 seconds and open-vocabulary querying in just 0.011 seconds per query. </p>
<blockquote>
<p>ä¸‰ç»´è¯­ä¹‰åœºå­¦ä¹ å¯¹äºè‡ªä¸»å¯¼èˆªã€å¢å¼ºç°å®&#x2F;è™šæ‹Ÿç°å®å’Œæœºå™¨äººç­‰åº”ç”¨è‡³å…³é‡è¦ï¼Œåœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œä»æœ‰é™è§†è§’å‡†ç¡®ç†è§£ä¸‰ç»´åœºæ™¯è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹è¡¨ç°å›°éš¾ï¼Œä¾èµ–äºä½æ•ˆçš„é’ˆå¯¹æ¯ä¸ªåœºæ™¯çš„å¤šè§†è§’ä¼˜åŒ–ï¼Œè¿™åœ¨è®¸å¤šç°å®ä»»åŠ¡ä¸­ä¸åˆ‡å®é™…ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SLGaussianæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å‰é¦ˆæ–¹æ³•ï¼Œå¯ä»¥ä»ç¨€ç–è§†è§’æ„å»ºä¸‰ç»´è¯­ä¹‰åœºï¼Œå…è®¸ç›´æ¥æ¨æ–­åŸºäº3DGSçš„åœºæ™¯ã€‚é€šè¿‡ç¡®ä¿é€šè¿‡è§†é¢‘è·Ÿè¸ªè¿›è¡Œä¸€è‡´çš„SAMåˆ†å‰²ï¼Œå¹¶ä½¿ç”¨é’ˆå¯¹é«˜ç»´CLIPç‰¹å¾çš„ä½ç»´ç´¢å¼•ï¼ŒSLGaussianæœ‰æ•ˆåœ°å°†è¯­è¨€ä¿¡æ¯åµŒå…¥ä¸‰ç»´ç©ºé—´ï¼Œä¸ºç¨€ç–è§†å›¾æ¡ä»¶ä¸‹çš„å‡†ç¡®ä¸‰ç»´åœºæ™¯ç†è§£æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨LERFå’Œ3D-OVSæ•°æ®é›†ä¸Šçš„ä¸¤è§†å›¾ç¨€ç–ä¸‰ç»´å¯¹è±¡æŸ¥è¯¢å’Œåˆ†å‰²å®éªŒä¸­ï¼ŒSLGaussianåœ¨é€‰æ‹©çš„IoUã€å®šä½ç²¾åº¦å’ŒmIoUæ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸åˆ°30ç§’å†…å®ç°åœºæ™¯æ¨æ–­ï¼Œæ¯ä¸ªæŸ¥è¯¢çš„å¼€æ”¾è¯æ±‡æŸ¥è¯¢æ—¶é—´ä»…ä¸º0.011ç§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.08331v2">PDF</a> Accepted by ACM MM 2025. Project page:   <a target="_blank" rel="noopener" href="https://chenkangjie1123.github.io/SLGaussian.github.io/">https://chenkangjie1123.github.io/SLGaussian.github.io/</a></p>
<p><strong>æ‘˜è¦</strong><br>    é’ˆå¯¹ç¨€ç–è§†ç‚¹ä¸‹çš„ä¸‰ç»´è¯­ä¹‰åœºå­¦ä¹ é—®é¢˜ï¼Œæå‡ºSLGaussianæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å‰é¦ˆæ–¹å¼æ„å»ºä¸‰ç»´è¯­ä¹‰åœºï¼Œæ”¯æŒä»ç¨€ç–è§†ç‚¹è¿›è¡Œç›´æ¥æ¨ç†ï¼Œæœ‰æ•ˆåµŒå…¥è¯­è¨€ä¿¡æ¯ï¼Œæå‡åœ¨ç¨€ç–è§†ç‚¹æ¡ä»¶ä¸‹çš„ä¸‰ç»´åœºæ™¯ç†è§£å‡†ç¡®æ€§ã€‚åœ¨LERFå’Œ3D-OVSæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSLGaussianåœ¨IoUã€å®šä½ç²¾åº¦å’ŒmIoUç­‰æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœºæ™¯æ¨ç†æ—¶é—´å°äº30ç§’ï¼Œå¼€æ”¾è¯æ±‡æŸ¥è¯¢æ¯ç§’å¯è¾¾0.011æ¬¡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>3Dè¯­ä¹‰åœºå­¦ä¹ åœ¨è‡ªä¸»å¯¼èˆªã€AR&#x2F;VRå’Œæœºå™¨äººç­‰åº”ç”¨ä¸­è‡³å…³é‡è¦ï¼Œå…¶ä¸­ä»æœ‰é™è§†è§’å‡†ç¡®ç†è§£3Dåœºæ™¯æ˜¯å…³é”®ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ï¼Œä¾èµ–äºä½æ•ˆçš„æ¯åœºæ™¯å¤šè§†å›¾ä¼˜åŒ–ï¼Œä¸é€‚ç”¨äºè®¸å¤šçœŸå®ä»»åŠ¡ã€‚</li>
<li>SLGaussianæ˜¯ä¸€ç§ä»ç¨€ç–è§†ç‚¹æ„å»º3Dè¯­ä¹‰åœºçš„é¦ˆé€æ–¹æ³•ï¼Œæ”¯æŒç›´æ¥æ¨ç†3DGSåœºæ™¯ã€‚</li>
<li>SLGaussiané€šè¿‡è§†é¢‘è·Ÿè¸ªç¡®ä¿SAMåˆ†å‰²çš„ä¸€è‡´æ€§ï¼Œå¹¶ä½¿ç”¨é«˜ç»´CLIPç‰¹å¾çš„ä½ç»´ç´¢å¼•ï¼Œæœ‰æ•ˆåµŒå…¥è¯­è¨€ä¿¡æ¯ã€‚</li>
<li>åœ¨LERFå’Œ3D-OVSæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSLGaussianåœ¨IoUã€å®šä½ç²¾åº¦å’ŒmIoUç­‰æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>SLGaussianå®ç°äº†åœºæ™¯æ¨ç†æ—¶é—´çš„ä¼˜åŒ–ï¼Œå°äº30ç§’ã€‚</li>
<li>å¼€æ”¾è¯æ±‡æŸ¥è¯¢æ•ˆç‡é«˜ï¼Œæ¯ç§’å¯è¾¾0.011æ¬¡æŸ¥è¯¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.08331">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e67fb4440da308b4b76b6a055855edb6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5daa037b7a54349652e6e8d01f2656dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ecc0bcd944a462f4ef58085159d3c13.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MEGA-Memory-Efficient-4D-Gaussian-Splatting-for-Dynamic-Scenes"><a href="#MEGA-Memory-Efficient-4D-Gaussian-Splatting-for-Dynamic-Scenes" class="headerlink" title="MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes"></a>MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes</h2><p><strong>Authors:Xinjie Zhang, Zhening Liu, Yifan Zhang, Xingtong Ge, Dailan He, Tongda Xu, Yan Wang, Zehong Lin, Shuicheng Yan, Jun Zhang</strong></p>
<p>4D Gaussian Splatting (4DGS) has recently emerged as a promising technique for capturing complex dynamic 3D scenes with high fidelity. It utilizes a 4D Gaussian representation and a GPU-friendly rasterizer, enabling rapid rendering speeds. Despite its advantages, 4DGS faces significant challenges, notably the requirement of millions of 4D Gaussians, each with extensive associated attributes, leading to substantial memory and storage cost. This paper introduces a memory-efficient framework for 4DGS. We streamline the color attribute by decomposing it into a per-Gaussian direct color component with only 3 parameters and a shared lightweight alternating current color predictor. This approach eliminates the need for spherical harmonics coefficients, which typically involve up to 144 parameters in classic 4DGS, thereby creating a memory-efficient 4D Gaussian representation. Furthermore, we introduce an entropy-constrained Gaussian deformation technique that uses a deformation field to expand the action range of each Gaussian and integrates an opacity-based entropy loss to limit the number of Gaussians, thus forcing our model to use as few Gaussians as possible to fit a dynamic scene well. With simple half-precision storage and zip compression, our framework achieves a storage reduction by approximately 190$\times$ and 125$\times$ on the Technicolor and Neural 3D Video datasets, respectively, compared to the original 4DGS. Meanwhile, it maintains comparable rendering speeds and scene representation quality, setting a new standard in the field. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Xinjie-Q/MEGA">https://github.com/Xinjie-Q/MEGA</a>. </p>
<blockquote>
<p>4Dé«˜æ–¯æ¨¡ç³ŠæŠ€æœ¯ï¼ˆ4DGSï¼‰ä½œä¸ºä¸€ç§æ–°å…´æŠ€æœ¯ï¼Œåœ¨é«˜ä¿çœŸæ•æ‰å¤æ‚åŠ¨æ€ä¸‰ç»´åœºæ™¯æ–¹é¢è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚å®ƒé‡‡ç”¨4Dé«˜æ–¯è¡¨ç¤ºå’ŒGPUå‹å¥½çš„å…‰æ …åŒ–å™¨ï¼Œå®ç°å¿«é€Ÿæ¸²æŸ“é€Ÿåº¦ã€‚å°½ç®¡å…·æœ‰ä¼˜åŠ¿ï¼Œä½†4DGSé¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯éœ€è¦æ•°ç™¾ä¸‡ä¸ªå…·æœ‰å¤§é‡ç›¸å…³å±æ€§çš„4Dé«˜æ–¯ï¼Œå¯¼è‡´å†…å­˜å’Œå­˜å‚¨æˆæœ¬é«˜æ˜‚ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé«˜æ•ˆçš„å†…å­˜ç®¡ç†æ¡†æ¶ç”¨äº4DGSã€‚æˆ‘ä»¬é€šè¿‡å°†é¢œè‰²å±æ€§ç®€åŒ–ä¸ºæ¯ä¸ªé«˜æ–¯ä»…å…·æœ‰ä¸‰ä¸ªå‚æ•°çš„ç›´æ¥é¢œè‰²ç»„ä»¶å’Œä¸€ä¸ªå…±äº«çš„è½»é‡çº§äº¤æµé¢œè‰²é¢„æµ‹å™¨æ¥ä¼˜åŒ–æµç¨‹ã€‚è¿™ç§æ–¹æ³•æ¶ˆé™¤äº†éœ€è¦ä½¿ç”¨çƒé¢è°æ³¢ç³»æ•°ï¼Œä¼ ç»Ÿ4DGSé€šå¸¸éœ€è¦é«˜è¾¾144ä¸ªå‚æ•°ï¼Œä»è€Œåˆ›å»ºäº†ä¸€ä¸ªå†…å­˜é«˜æ•ˆçš„4Dé«˜æ–¯è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºç†µçº¦æŸçš„é«˜æ–¯å˜å½¢æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ä½¿ç”¨å˜å½¢åœºæ‰©å±•æ¯ä¸ªé«˜æ–¯çš„ä½œç”¨èŒƒå›´ï¼Œå¹¶ç»“åˆåŸºäºä¸é€æ˜åº¦çš„ç†µæŸå¤±æ¥é™åˆ¶é«˜æ–¯æ•°é‡ï¼Œä»è€Œè¿«ä½¿æˆ‘ä»¬çš„æ¨¡å‹å°½å¯èƒ½ä½¿ç”¨æœ€å°‘çš„é«˜æ–¯æ¥é€‚åº”åŠ¨æ€åœºæ™¯ã€‚é€šè¿‡ç®€å•çš„åŠç²¾åº¦å­˜å‚¨å’Œzipå‹ç¼©ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨Technicolorå’ŒNeural 3D Videoæ•°æ®é›†ä¸Šå®ç°äº†çº¦190å€å’Œ125å€çš„å­˜å‚¨ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„æ¸²æŸ“é€Ÿåº¦å’Œåœºæ™¯è¡¨ç¤ºè´¨é‡ï¼Œä¸ºè¿™ä¸€é¢†åŸŸè®¾å®šäº†æ–°çš„æ ‡å‡†ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Xinjie-Q/MEGA%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Xinjie-Q/MEGAè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13613v2">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†æ–°å‹çš„4Dé«˜æ–¯æ··åˆæŠ€æœ¯ï¼ˆ4DGSï¼‰ï¼Œç”¨äºæ•æ‰å¤æ‚çš„åŠ¨æ€ä¸‰ç»´åœºæ™¯ã€‚ä¸ºæé«˜æ•ˆç‡ï¼Œè¯¥æ–‡æå‡ºä¸€ç§å†…å­˜ä¼˜åŒ–çš„æ¡†æ¶ï¼Œé€šè¿‡ç®€åŒ–é¢œè‰²å±æ€§å’Œå¼•å…¥åŸºäºç†µçº¦æŸçš„é«˜æ–¯å˜å½¢æŠ€æœ¯ï¼Œå®ç°äº†æ˜¾è‘—çš„å†…å­˜èŠ‚çœã€‚è¯¥æ¡†æ¶åœ¨ä¿æŒæ¸²æŸ“é€Ÿåº¦å’Œåœºæ™¯è¡¨ç¤ºè´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„å†…å­˜ç©ºé—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>4DGSæŠ€æœ¯èƒ½å¤Ÿæ•æ‰å¤æ‚çš„åŠ¨æ€ä¸‰ç»´åœºæ™¯å¹¶å…·å¤‡é«˜ä¿çœŸåº¦ã€‚</li>
<li>ä¸ºè§£å†³å†…å­˜å’Œå­˜å‚¨æˆæœ¬é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§å†…å­˜ä¼˜åŒ–çš„æ¡†æ¶ã€‚</li>
<li>é€šè¿‡ç®€åŒ–é¢œè‰²å±æ€§å’Œå¼•å…¥ç†µçº¦æŸçš„é«˜æ–¯å˜å½¢æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆçš„å†…å­˜ä½¿ç”¨ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨åŠç²¾åº¦å­˜å‚¨å’Œzipå‹ç¼©ï¼Œå®ç°äº†æ˜¾è‘—çš„å­˜å‚¨ç¼©å‡ï¼ŒåŒæ—¶ä¿æŒæ¸²æŸ“é€Ÿåº¦å’Œåœºæ™¯è¡¨ç¤ºè´¨é‡ã€‚</li>
<li>è¯¥æŠ€æœ¯å¯¹äºåŠ¨æ€åœºæ™¯çš„æ‹Ÿåˆèƒ½åŠ›å¼ºå¤§ï¼Œä½¿ç”¨çš„é«˜æ–¯æ•°é‡å°½å¯èƒ½å°‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13613">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-95d325e720a93a256274f173f6277710.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-324fadbf6e8fa9bcecede36f6d1b44c5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf2ef38a374f766ffc6c0b788e959dff.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa1ef2b2e8678f54e3302e0348dc8640.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-61354a063317be6add01ece22839f7fa.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="HGSLoc-3DGS-based-Heuristic-Camera-Pose-Refinement"><a href="#HGSLoc-3DGS-based-Heuristic-Camera-Pose-Refinement" class="headerlink" title="HGSLoc: 3DGS-based Heuristic Camera Pose Refinement"></a>HGSLoc: 3DGS-based Heuristic Camera Pose Refinement</h2><p><strong>Authors:Zhongyan Niu, Zhen Tan, Jinpu Zhang, Xueliang Yang, Dewen Hu</strong></p>
<p>Visual localization refers to the process of determining camera poses and orientation within a known scene representation. This task is often complicated by factors such as changes in illumination and variations in viewing angles. In this paper, we propose HGSLoc, a novel lightweight plug-and-play pose optimization framework, which integrates 3D reconstruction with a heuristic refinement strategy to achieve higher pose estimation accuracy. Specifically, we introduce an explicit geometric map for 3D representation and high-fidelity rendering, allowing the generation of high-quality synthesized views to support accurate visual localization. Our method demonstrates higher localization accuracy compared to NeRF-based neural rendering localization approaches. We introduce a heuristic refinement strategy, its efficient optimization capability can quickly locate the target node, while we set the step level optimization step to enhance the pose accuracy in the scenarios with small errors. With carefully designed heuristic functions, it offers efficient optimization capabilities, enabling rapid error reduction in rough localization estimations. Our method mitigates the dependence on complex neural network models while demonstrating improved robustness against noise and higher localization accuracy in challenging environments, as compared to neural network joint optimization strategies. The optimization framework proposed in this paper introduces novel approaches to visual localization by integrating the advantages of 3D reconstruction and the heuristic refinement strategy, which demonstrates strong performance across multiple benchmark datasets, including 7Scenes and Deep Blending dataset. The implementation of our method has been released at <a target="_blank" rel="noopener" href="https://github.com/anchang699/HGSLoc">https://github.com/anchang699/HGSLoc</a>. </p>
<blockquote>
<p>è§†è§‰å®šä½æ˜¯æŒ‡ç¡®å®šç›¸æœºåœ¨å·²çŸ¥åœºæ™¯è¡¨ç¤ºä¸­çš„å§¿æ€å’Œæ–¹å‘çš„è¿‡ç¨‹ã€‚è¿™ä¸ªä»»åŠ¡é€šå¸¸å—åˆ°å…‰ç…§å˜åŒ–å’Œè§‚çœ‹è§’åº¦å˜åŒ–ç­‰å› ç´ çš„å½±å“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†HGSLocï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹è½»é‡çº§çš„å³æ’å³ç”¨å§¿æ€ä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒå°†3Dé‡å»ºä¸å¯å‘å¼ç»†åŒ–ç­–ç•¥ç›¸ç»“åˆï¼Œä»¥å®ç°æ›´é«˜çš„å§¿æ€ä¼°è®¡ç²¾åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç”¨äº3Dè¡¨ç¤ºçš„æ˜¾å¼å‡ ä½•åœ°å›¾å’Œé«˜ä¿çœŸæ¸²æŸ“ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡åˆæˆè§†å›¾ï¼Œæ”¯æŒç²¾ç¡®è§†è§‰å®šä½ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åŸºäºNeRFçš„ç¥ç»æ¸²æŸ“å®šä½æ–¹æ³•ç›¸æ¯”ï¼Œå±•ç¤ºäº†æ›´é«˜çš„å®šä½ç²¾åº¦ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¯å‘å¼ç»†åŒ–ç­–ç•¥ï¼Œå…¶é«˜æ•ˆçš„ä¼˜åŒ–èƒ½åŠ›å¯ä»¥å¿«é€Ÿå®šä½ç›®æ ‡èŠ‚ç‚¹ï¼ŒåŒæ—¶æˆ‘ä»¬è®¾ç½®äº†æ­¥éª¤çº§ä¼˜åŒ–æ­¥éª¤ï¼Œä»¥æé«˜åœ¨é”™è¯¯è¾ƒå°çš„åœºæ™¯ä¸­çš„å§¿æ€ç²¾åº¦ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¯å‘å¼å‡½æ•°ï¼Œå®ƒæä¾›äº†é«˜æ•ˆçš„ä¼˜åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ç²—ç•¥çš„å®šä½ä¼°è®¡ä¸­å¿«é€Ÿå‡å°‘è¯¯å·®ã€‚æˆ‘ä»¬çš„æ–¹æ³•å‡è½»äº†å¯¹äºå¤æ‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹çš„ä¾èµ–ï¼ŒåŒæ—¶å±•ç¤ºäº†åœ¨å™ªå£°ç¯å¢ƒä¸­çš„é²æ£’æ€§å’Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­çš„æ›´é«˜å®šä½ç²¾åº¦ï¼Œè¿™ä¸ç¥ç»ç½‘ç»œè”åˆä¼˜åŒ–ç­–ç•¥ç›¸æ¯”ã€‚æœ¬æ–‡æå‡ºçš„ä¼˜åŒ–æ¡†æ¶é€šè¿‡æ•´åˆ3Dé‡å»ºå’Œå¯å‘å¼ç»†åŒ–ç­–ç•¥çš„ä¼˜ç‚¹ï¼Œä¸ºè§†è§‰å®šä½å¼•å…¥äº†æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆåŒ…æ‹¬7Sceneså’ŒDeep Blendingæ•°æ®é›†ï¼‰ä¸Šå‡è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å®ç°å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/anchang699/HGSLoc">https://github.com/anchang699/HGSLoc</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.10925v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„è§†è§‰å®šä½æ–¹æ³•HGSLocï¼Œå®ƒç»“åˆäº†ä¸‰ç»´é‡å»ºå’Œå¯å‘å¼ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚é€šè¿‡æ„å»ºæ˜ç¡®çš„å‡ ä½•åœ°å›¾è¿›è¡Œä¸‰ç»´è¡¨ç¤ºå’Œé«˜ä¿çœŸæ¸²æŸ“ï¼Œç”Ÿæˆé«˜è´¨é‡åˆæˆè§†å›¾ä»¥æ”¯æŒç²¾ç¡®è§†è§‰å®šä½ã€‚ç›¸è¾ƒäºåŸºäºNeRFçš„ç¥ç»æ¸²æŸ“å®šä½æ–¹æ³•ï¼ŒHGSLocå…·æœ‰æ›´é«˜çš„å®šä½ç²¾åº¦ã€‚æ­¤å¤–ï¼Œå…¶å¯å‘å¼ä¼˜åŒ–ç­–ç•¥èƒ½è¿…é€Ÿå®šä½ç›®æ ‡èŠ‚ç‚¹ï¼Œå¹¶åœ¨å­˜åœ¨å°è¯¯å·®çš„åœºæ™¯ä¸­é€šè¿‡æ­¥çº§ä¼˜åŒ–æ­¥éª¤æé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚HGSLocæ–¹æ³•é¿å…äº†ä¾èµ–å¤æ‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œåœ¨å™ªå£°ç¯å¢ƒä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­å®ç°äº†æ›´é«˜çš„å®šä½ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>HGSLocæ˜¯ä¸€ç§æ–°å‹çš„è§†è§‰å®šä½æ–¹æ³•ï¼Œç»“åˆäº†ä¸‰ç»´é‡å»ºå’Œå¯å‘å¼ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>é€šè¿‡æ„å»ºå‡ ä½•åœ°å›¾è¿›è¡Œé«˜ä¿çœŸæ¸²æŸ“ï¼Œæé«˜äº†å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
<li>HGSLocå…·æœ‰æ›´é«˜çš„å®šä½ç²¾åº¦ï¼Œç›¸è¾ƒäºåŸºäºNeRFçš„ç¥ç»æ¸²æŸ“å®šä½æ–¹æ³•ã€‚</li>
<li>å¯å‘å¼ä¼˜åŒ–ç­–ç•¥èƒ½è¿…é€Ÿå®šä½ç›®æ ‡èŠ‚ç‚¹ï¼Œå¹¶èƒ½åœ¨å­˜åœ¨å°è¯¯å·®çš„åœºæ™¯ä¸­æé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
<li>HGSLocé¿å…äº†ä¾èµ–å¤æ‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚</li>
<li>HGSLocåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­å®ç°äº†æ›´é«˜çš„å®šä½ç²¾åº¦ã€‚</li>
<li>HGSLocå·²åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼ŒåŒ…æ‹¬7Sceneså’ŒDeep Blendingæ•°æ®é›†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.10925">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d9f1dae8a3059d0e2ba14bb0b4923152.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8062c0dfced018845afeda77a2779d65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68e60997014262ee7f72a952ff13cda2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f475a0102588e07cf81a28f9000853f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cca31034e5c7f2b546866b55cebb8f4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2a048e73cc9d728bcf20ec48538f14b3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2ad29adf5e71b649ca34be3dcb1d596.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="GaussianOcc-Fully-Self-supervised-and-Efficient-3D-Occupancy-Estimation-with-Gaussian-Splatting"><a href="#GaussianOcc-Fully-Self-supervised-and-Efficient-3D-Occupancy-Estimation-with-Gaussian-Splatting" class="headerlink" title="GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation   with Gaussian Splatting"></a>GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation   with Gaussian Splatting</h2><p><strong>Authors:Wanshui Gan, Fang Liu, Hongbin Xu, Ningkai Mo, Naoto Yokoya</strong></p>
<p>We introduce GaussianOcc, a systematic method that investigates the two usages of Gaussian splatting for fully self-supervised and efficient 3D occupancy estimation in surround views. First, traditional methods for self-supervised 3D occupancy estimation still require ground truth 6D poses from sensors during training. To address this limitation, we propose Gaussian Splatting for Projection (GSP) module to provide accurate scale information for fully self-supervised training from adjacent view projection. Additionally, existing methods rely on volume rendering for final 3D voxel representation learning using 2D signals (depth maps, semantic maps), which is both time-consuming and less effective. We propose Gaussian Splatting from Voxel space (GSV) to leverage the fast rendering properties of Gaussian splatting. As a result, the proposed GaussianOcc method enables fully self-supervised (no ground truth pose) 3D occupancy estimation in competitive performance with low computational cost (2.7 times faster in training and 5 times faster in rendering). The relevant code is available in <a target="_blank" rel="noopener" href="https://github.com/GANWANSHUI/GaussianOcc.git">https://github.com/GANWANSHUI/GaussianOcc.git</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†GaussianOccï¼Œè¿™æ˜¯ä¸€ç§ç³»ç»Ÿæ€§æ–¹æ³•ï¼Œç ”ç©¶äº†é«˜æ–¯å±•å¸ƒï¼ˆGaussian Splattingï¼‰çš„ä¸¤ç§åº”ç”¨ï¼Œä»¥åœ¨å‘¨å›´è§†å›¾ä¸­å®ç°å…¨è‡ªç›‘ç£å’Œé«˜æ•ˆç‡çš„3Då ç”¨ä¼°è®¡ã€‚é¦–å…ˆï¼Œç°æœ‰çš„è‡ªç›‘ç£3Då ç”¨ä¼°è®¡æ–¹æ³•ä»ç„¶éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨æ¥è‡ªä¼ æ„Ÿå™¨çš„çœŸå®6Då§¿æ€ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºæŠ•å½±çš„é«˜æ–¯å±•å¸ƒï¼ˆGaussian Splatting for Projectionï¼ŒGSPï¼‰æ¨¡å—ï¼Œé€šè¿‡ç›¸é‚»è§†å›¾æŠ•å½±æä¾›å‡†ç¡®çš„å°ºåº¦ä¿¡æ¯ä»¥å®ç°å…¨è‡ªç›‘ç£è®­ç»ƒã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºä½“ç§¯æ¸²æŸ“æ¥åˆ©ç”¨äºŒç»´ä¿¡å·ï¼ˆæ·±åº¦å›¾ã€è¯­ä¹‰å›¾ï¼‰è¿›è¡Œæœ€ç»ˆçš„ä¸‰ç»´ä½“ç´ è¡¨ç¤ºå­¦ä¹ ï¼Œè¿™æ—¢è€—æ—¶åˆæ•ˆç‡è¾ƒä½ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºä½“ç´ ç©ºé—´çš„é«˜æ–¯å±•å¸ƒï¼ˆGaussian Splatting from Voxel spaceï¼ŒGSVï¼‰ï¼Œåˆ©ç”¨é«˜æ–¯å±•å¸ƒçš„å¿«é€Ÿæ¸²æŸ“å±æ€§ã€‚å› æ­¤ï¼Œæå‡ºçš„GaussianOccæ–¹æ³•èƒ½å¤Ÿåœ¨æ— éœ€çœŸå®å§¿æ€çš„æƒ…å†µä¸‹å®ç°å…¨è‡ªç›‘ç£çš„3Då ç”¨ä¼°è®¡ï¼Œå…·æœ‰ç«äº‰åŠ›ä¸”è®¡ç®—æˆæœ¬ä½ï¼ˆè®­ç»ƒé€Ÿåº¦æé«˜äº†2.7å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº†5å€ï¼‰ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/GANWANSHUI/GaussianOcc.git%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/GANWANSHUI/GaussianOcc.gitä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.11447v4">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://ganwanshui.github.io/GaussianOcc/">https://ganwanshui.github.io/GaussianOcc/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†GaussianOccæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡é«˜æ–¯æ‘Šé“ºæŠ€æœ¯å®ç°äº†å…¨è‡ªæˆ‘ç›‘ç£çš„3Då ç”¨ç©ºé—´ä¼°è®¡ã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•éœ€è¦ä¼ æ„Ÿå™¨æä¾›çš„åœ°é¢çœŸå®6Då§¿æ€æ•°æ®è¿›è¡Œè®­ç»ƒçš„é—®é¢˜ï¼Œæå‡ºäº†é«˜æ–¯æ‘Šé“ºæŠ•å½±ï¼ˆGSPï¼‰æ¨¡å—ï¼Œç”¨äºä»ç›¸é‚»è§†å›¾æŠ•å½±æä¾›å‡†ç¡®çš„å°ºåº¦ä¿¡æ¯ä»¥å®ç°å…¨è‡ªæˆ‘ç›‘ç£è®­ç»ƒã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–ä½“ç§¯æ¸²æŸ“æ¥é€šè¿‡äºŒç»´ä¿¡å·ï¼ˆæ·±åº¦å›¾ã€è¯­ä¹‰å›¾ï¼‰å­¦ä¹ æœ€ç»ˆçš„3Dä½“ç´ è¡¨ç¤ºï¼Œè¿™æ—¢è€—æ—¶åˆæ•ˆæœä¸ä½³ã€‚å› æ­¤æå‡ºä»ä½“ç´ ç©ºé—´è¿›è¡Œé«˜æ–¯æ‘Šé“ºï¼ˆGSVï¼‰ï¼Œåˆ©ç”¨é«˜æ–¯æ‘Šé“ºçš„å¿«é€Ÿæ¸²æŸ“å±æ€§ã€‚è¿™ä½¿å¾—GaussianOccæ–¹æ³•èƒ½å¤Ÿåœ¨æ— éœ€åœ°é¢çœŸå®å§¿æ€æ•°æ®çš„æƒ…å†µä¸‹å®ç°è‡ªæˆ‘ç›‘ç£çš„3Då ç”¨ç©ºé—´ä¼°è®¡ï¼Œå…·æœ‰ç«äº‰æ€§çš„æ€§èƒ½ä¸”è®¡ç®—æˆæœ¬ä½ï¼ˆè®­ç»ƒé€Ÿåº¦æé«˜2.7å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜5å€ï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GaussianOccé€šè¿‡é«˜æ–¯æ‘Šé“ºæŠ€æœ¯å®ç°äº†å…¨è‡ªæˆ‘ç›‘ç£çš„3Då ç”¨ç©ºé—´ä¼°è®¡ã€‚</li>
<li>æå‡ºäº†é«˜æ–¯æ‘Šé“ºæŠ•å½±ï¼ˆGSPï¼‰æ¨¡å—ï¼Œä¸ºå…¨è‡ªæˆ‘ç›‘ç£è®­ç»ƒæä¾›å‡†ç¡®å°ºåº¦ä¿¡æ¯ã€‚</li>
<li>ç°æœ‰çš„æ–¹æ³•ä¾èµ–ä½“ç§¯æ¸²æŸ“æ¥å­¦ä¹ æœ€ç»ˆçš„3Dä½“ç´ è¡¨ç¤ºï¼Œä½†è¿™ä¸€è¿‡ç¨‹æ—¢è€—æ—¶åˆæ•ˆæœä¸ä½³ã€‚</li>
<li>æå‡ºäº†ä»ä½“ç´ ç©ºé—´è¿›è¡Œé«˜æ–¯æ‘Šé“ºï¼ˆGSVï¼‰ï¼Œåˆ©ç”¨é«˜æ–¯æ‘Šé“ºçš„å¿«é€Ÿæ¸²æŸ“å±æ€§ã€‚</li>
<li>GaussianOccæ–¹æ³•æé«˜äº†è®­ç»ƒé€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å·²å…¬å¼€å¯è®¿é—®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.11447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-34b1b59782e2741cb0cd6491c222b1f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af85a32c028b261bea8ef6b40bab669b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e0f4c89227b659eadbb63b4f85d6549.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf43d5a685c8ae5d3878cc82c85b0321.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-368c4b9feec0e598b54343c839161805.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-17/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-17/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-17/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0b2fc8b2251a1d2ea767a20df9bf662e.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-17  AI-Enhanced Pediatric Pneumonia Detection A CNN-Based Approach Using   Data Augmentation and Generative Adversarial Networks (GANs)
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-17/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f139b437c8d51e8e8937344267fb29cd.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-17  ScaffoldAvatar High-Fidelity Gaussian Avatars with Patch Expressions
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
