<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM 方向最新论文已更新，请持续关注 Update in 2025-07-17  FalseReject A Resource for Improving Contextual Safety and Mitigating   Over-Refusals in LLMs via Structured Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-cca6f327a9e0a5dece7366cde8a1f565.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-17-更新"><a href="#2025-07-17-更新" class="headerlink" title="2025-07-17 更新"></a>2025-07-17 更新</h1><h2 id="FalseReject-A-Resource-for-Improving-Contextual-Safety-and-Mitigating-Over-Refusals-in-LLMs-via-Structured-Reasoning"><a href="#FalseReject-A-Resource-for-Improving-Contextual-Safety-and-Mitigating-Over-Refusals-in-LLMs-via-Structured-Reasoning" class="headerlink" title="FalseReject: A Resource for Improving Contextual Safety and Mitigating   Over-Refusals in LLMs via Structured Reasoning"></a>FalseReject: A Resource for Improving Contextual Safety and Mitigating   Over-Refusals in LLMs via Structured Reasoning</h2><p><strong>Authors:Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy</strong></p>
<p>Safety alignment approaches in large language models (LLMs) often lead to the over-refusal of benign queries, significantly diminishing their utility in sensitive scenarios. To address this challenge, we introduce FalseReject, a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safety-related categories. We propose a graph-informed adversarial multi-agent interaction framework to generate diverse and complex prompts, while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts. FalseReject includes training datasets tailored for both standard instruction-tuned models and reasoning-oriented models, as well as a human-annotated benchmark test set. Our extensive benchmarking on 29 state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges. Empirical results demonstrate that supervised finetuning with FalseReject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities. </p>
<blockquote>
<p>大型语言模型（LLM）的安全对齐方法通常会导致良性查询被拒绝的情况过多，这在敏感场景中显著降低了其效用。为了解决这一挑战，我们引入了FalseReject，这是一个包含16,000个看似有毒查询的综合资源，并配有44个安全相关类别的结构化响应。我们提出了一种基于图对抗的多智能体交互框架，以生成多样化和复杂的提示，同时利用结构化响应的明确推理来帮助模型准确区分安全和不安全的上下文。FalseReject包括针对标准指令调整模型和推理导向模型的训练数据集，以及一个人工注释的基准测试集。我们对29种最先进的LLM进行了广泛的基准测试，发现仍存在持续的过度拒绝挑战。经验结果表明，使用FalseReject进行有监督微调可以大大减少不必要的拒绝，同时不损害整体安全性或通用语言功能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08054v2">PDF</a> Accepted at COLM 2025</p>
<p><strong>Summary</strong>：大型语言模型（LLM）的安全对齐方法往往会导致良性查询被拒绝，降低了其在敏感场景中的实用性。为解决这一问题，我们推出FalseReject资源，包含看似有毒的查询和结构化响应。我们提出基于图对抗的多智能体交互框架来生成不同场景，响应结构化的理由能帮助模型区分安全和不安全环境。通过训练集，我们发现包括监督微调都能大幅减少不必要的拒绝拒绝而不影响总体安全或语言通用能力。对现状技术的全面基准测试证明依然存在持续存在的过度拒绝挑战。这个挑战利用FalseReject的用例明显减缓了很多不必要的情况，同时也能够保障总体的安全。此外，它还包含针对不同模型类型和任务类型的数据集，如标准指令训练模型和推理导向模型等。同时包含人类注释的基准测试集。我们的实验结果表明，使用FalseReject进行微调可以显著减少不必要的拒绝，同时不会损害模型的整体安全性或通用语言处理能力。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型（LLM）在敏感场景中面临过度拒绝良性查询的问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08054">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3c26e09695a5ecae12a59943bb2f90d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0adadf2a510332c238525ad7a93fe17.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36e99019cab94072ed8ae4323559cc39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc1db6aae8770ba80ffbe10729f83475.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf42d01b744e093a66248ec76173c7fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2a65556492b1749cbfc3ffbe5691237.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Ophora-A-Large-Scale-Data-Driven-Text-Guided-Ophthalmic-Surgical-Video-Generation-Model"><a href="#Ophora-A-Large-Scale-Data-Driven-Text-Guided-Ophthalmic-Surgical-Video-Generation-Model" class="headerlink" title="Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video   Generation Model"></a>Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video   Generation Model</h2><p><strong>Authors:Wei Li, Ming Hu, Guoan Wang, Lihao Liu, Kaijing Zhou, Junzhi Ning, Xin Guo, Zongyuan Ge, Lixu Gu, Junjun He</strong></p>
<p>In ophthalmic surgery, developing an AI system capable of interpreting surgical videos and predicting subsequent operations requires numerous ophthalmic surgical videos with high-quality annotations, which are difficult to collect due to privacy concerns and labor consumption. Text-guided video generation (T2V) emerges as a promising solution to overcome this issue by generating ophthalmic surgical videos based on surgeon instructions. In this paper, we present Ophora, a pioneering model that can generate ophthalmic surgical videos following natural language instructions. To construct Ophora, we first propose a Comprehensive Data Curation pipeline to convert narrative ophthalmic surgical videos into a large-scale, high-quality dataset comprising over 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive Video-Instruction Tuning scheme to transfer rich spatial-temporal knowledge from a T2V model pre-trained on natural video-text datasets for privacy-preserved ophthalmic surgical video generation based on Ophora-160K. Experiments on video quality evaluation via quantitative analysis and ophthalmologist feedback demonstrate that Ophora can generate realistic and reliable ophthalmic surgical videos based on surgeon instructions. We also validate the capability of Ophora for empowering downstream tasks of ophthalmic surgical workflow understanding. Code is available at <a target="_blank" rel="noopener" href="https://github.com/uni-medical/Ophora">https://github.com/uni-medical/Ophora</a>. </p>
<blockquote>
<p>在眼科手术中，开发一个能够解读手术视频并预测后续操作的AI系统，需要大量的高质量标注眼科手术视频。由于隐私问题和劳动消耗，这些视频的收集非常困难。文本引导的视频生成（T2V）作为一种有前途的解决方案应运而生，它可以根据外科医生的指令生成眼科手术视频。在本文中，我们提出了Ophora，一个能够基于自然语言指令生成眼科手术视频的开创性模型。为了构建Ophora，我们首先提出了一个全面的数据整理管道，将叙述性眼科手术视频转化为大规模高质量数据集，包含超过16万对视频指令，称为Ophora-160K。然后，我们提出了一种渐进的视频指令调整方案，从在天然视频文本数据集上预训练的T2V模型中转移丰富的时空知识，用于基于Ophora-160K的隐私保护眼科手术视频生成。通过对视频质量的定量分析和眼科医生的反馈进行的实验表明，Ophora可以根据外科医生的指令生成现实和可靠的眼科手术视频。我们还验证了Ophora在眼科手术工作流程理解下游任务中的能力。代码可访问<a target="_blank" rel="noopener" href="https://github.com/uni-medical/Ophora%E3%80%82">https://github.com/uni-medical/Ophora。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07449v7">PDF</a> Early accepted in MICCAI25</p>
<p><strong>Summary</strong></p>
<p>基于自然语言指令生成眼科手术视频是一个新兴的技术方向。本文提出了一种名为Ophora的模型，该模型可以通过大规模数据集和高质量注释生成眼科手术视频。通过数据清洗和逐步的视频指令调整策略，该模型能够基于自然语言指令生成真实可靠的眼科手术视频。此外，该模型还能支持眼科手术工作流程理解等下游任务。</p>
<p><strong>Key Takeaways</strong></p>
<p>1.Ophora是一个能够基于自然语言指令生成眼科手术视频的模型。<br>2.该模型使用大规模数据集和高质量注释来训练。<br>3.数据清洗和逐步的视频指令调整策略使得该模型能够生成真实可靠的眼科手术视频。<br>4.模型可以应用于眼科手术工作流程理解等下游任务。<br>5.模型具有隐私保护的功能，可以在保护患者隐私的前提下进行眼科手术视频的生成。<br>6.模型的代码已经开源，便于其他研究者进行研究和改进。</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07449">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-09151bae0e30df526a784bfb12cfdb11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a4ec3b71a8c06c8f6d824bb3db7290c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cca6f327a9e0a5dece7366cde8a1f565.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Localizing-Before-Answering-A-Hallucination-Evaluation-Benchmark-for-Grounded-Medical-Multimodal-LLMs"><a href="#Localizing-Before-Answering-A-Hallucination-Evaluation-Benchmark-for-Grounded-Medical-Multimodal-LLMs" class="headerlink" title="Localizing Before Answering: A Hallucination Evaluation Benchmark for   Grounded Medical Multimodal LLMs"></a>Localizing Before Answering: A Hallucination Evaluation Benchmark for   Grounded Medical Multimodal LLMs</h2><p><strong>Authors:Dung Nguyen, Minh Khoi Ho, Huy Ta, Thanh Tam Nguyen, Qi Chen, Kumar Rav, Quy Duong Dang, Satwik Ramchandre, Son Lam Phung, Zhibin Liao, Minh-Son To, Johan Verjans, Phi Le Nguyen, Vu Minh Hieu Phan</strong></p>
<p>Medical Large Multi-modal Models (LMMs) have demonstrated remarkable capabilities in medical data interpretation. However, these models frequently generate hallucinations contradicting source evidence, particularly due to inadequate localization reasoning. This work reveals a critical limitation in current medical LMMs: instead of analyzing relevant pathological regions, they often rely on linguistic patterns or attend to irrelevant image areas when responding to disease-related queries. To address this, we introduce HEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive benchmark designed to evaluate LMMs’ localization abilities and hallucination robustness. HEAL-MedVQA features (i) two innovative evaluation protocols to assess visual and textual shortcut learning, and (ii) a dataset of 67K VQA pairs, with doctor-annotated anatomical segmentation masks for pathological regions. To improve visual reasoning, we propose the Localize-before-Answer (LobA) framework, which trains LMMs to localize target regions of interest and self-prompt to emphasize segmented pathological areas, generating grounded and reliable answers. Experimental results demonstrate that our approach significantly outperforms state-of-the-art biomedical LMMs on the challenging HEAL-MedVQA benchmark, advancing robustness in medical VQA. </p>
<blockquote>
<p>医疗领域的大型多模态模型（LMMs）在医疗数据解读方面展现出了显著的能力。然而，这些模型经常产生与源证据相矛盾的幻觉，尤其是因为定位推理不足。这项工作揭示了当前医疗LMMs的一个关键局限：它们通常不是分析相关的病理区域，而是依赖于语言模式或关注与疾病相关查询不相关的图像区域来做出回应。为了解决这一问题，我们引入了HEAL-MedVQA（通过定位MedVQA评估幻觉），这是一个全面的基准测试，旨在评估LMMs的定位能力和幻觉稳健性。HEAL-MedVQA的特点包括：（i）两个创新的评估协议，用于评估视觉和文本捷径学习；（ii）包含67K个VQA对的数据集，每个问题都有医生注释的解剖分割掩膜来标记病理区域。为了提高视觉推理能力，我们提出了先定位再回答（LobA）框架，该框架训练LMMs定位感兴趣区域并进行自我提示以强调分割的病理区域，从而生成有根据且可靠的答案。实验结果表明，我们的方法在具有挑战性的HEAL-MedVQA基准测试上显著优于最先进的生物医学LMMs，提高了医疗VQA的稳健性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00744v4">PDF</a> Accepted at Joint Conference on Artificial Intelligence (IJCAI) 2025</p>
<p><strong>Summary</strong><br>     医疗领域的大型多模态模型（LMMs）在医疗数据解读方面展现出显著能力，但经常产生与源证据相矛盾的幻觉，尤其是因为缺乏定位推理。为解决此问题，本文揭示了当前医学LMMs的一个关键局限：它们往往不分析相关病理区域，而是依赖于语言模式或对疾病相关查询的无关图像区域进行回应。为此，我们引入了HEAL-MedVQA（通过定位评估幻觉的医萃问答）评估基准测试，旨在评估LMMs的定位能力和幻觉稳健性。HEAL-MedVQA包括两个创新评估协议来评估视觉和文本捷径学习，以及一个包含医生注释的解剖学分割掩膜数据集用于病理区域。为提高视觉推理能力，我们提出了先定位后回答（LobA）框架，训练LMMs定位感兴趣区域并自我提示强调分割的病理区域，生成可靠答案。实验结果表明，我们的方法在具有挑战性的HEAL-MedVQA基准测试中显著优于最新的生物医学LMMs，提升了医疗领域的视觉问答的稳健性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医疗大型多模态模型（LMMs）在解读医疗数据上表现卓越，但存在生成与源证据矛盾的幻觉问题。</li>
<li>LMMs的一个关键局限是缺乏定位推理，倾向于依赖语言模式或对非相关图像区域的回应。</li>
<li>HEAL-MedVQA是一个新的评估基准，旨在评价LMMs的定位能力和幻觉稳健性。</li>
<li>HEAL-MedVQA包括两个评估协议和包含医生注释的数据集用于评估病理区域。</li>
<li>先定位后回答（LobA）框架旨在提高LMMs的视觉推理能力，通过训练模型定位感兴趣区域并强调病理区域来生成可靠答案。</li>
<li>实验结果显示，LobA框架在HEAL-MedVQA基准测试中显著优于现有生物医学LMMs。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00744">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-89b6d9f2a09e5a6cbdaef809c101cb37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ecb7e7b82b0fec3b5e9baa2a9e09f8da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1703307304b17a2c64791d995597fa35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d73ecf14df8174330c0268ca330c9580.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d8507d8bb7a80ef1a61b8858cc2b04f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5b96215a9b3c23a895fea3dee5dfb9b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-879a683b2e6652338e55ccb07a1e7af4.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="BEExformer-A-Fast-Inferencing-Binarized-Transformer-with-Early-Exits"><a href="#BEExformer-A-Fast-Inferencing-Binarized-Transformer-with-Early-Exits" class="headerlink" title="BEExformer: A Fast Inferencing Binarized Transformer with Early Exits"></a>BEExformer: A Fast Inferencing Binarized Transformer with Early Exits</h2><p><strong>Authors:Wazib Ansar, Saptarsi Goswami, Amlan Chakrabarti</strong></p>
<p>Large Language Models (LLMs) based on transformers achieve cutting-edge results on a variety of applications. However, their enormous size and processing requirements hinder deployment on constrained resources. To enhance efficiency, binarization and Early Exit (EE) have proved to be effective solutions. However, binarization may lead to performance loss as reduced precision affects gradient estimation and parameter updates. Besides, research on EE mechanisms is still in its early stages. To address these challenges, we introduce Binarized Early Exit Transformer (BEExformer), the first-ever selective learning-based transformer integrating Binarization-Aware Training (BAT) with EE for efficient and fast textual inference. Each transformer block has an integrated Selective-Learn Forget Network (SLFN) to enhance contextual retention while eliminating irrelevant information. The BAT employs a differentiable second-order approximation to the sign function, enabling gradient computation that captures both the sign and magnitude of the weights. This aids in 21.30 times reduction in model size. The EE mechanism hinges on fractional reduction in entropy among intermediate transformer blocks with soft-routing loss estimation. This accelerates inference by reducing FLOPs by 52.08% and even improves accuracy by 2.89% by resolving the “overthinking” problem inherent in deep networks. Extensive evaluation through comparison with the SOTA methods and various ablations across six datasets covering multiple NLP tasks demonstrates its Pareto-optimal performance-efficiency trade-off. </p>
<blockquote>
<p>基于Transformer的大型语言模型（LLM）在各种应用上取得了尖端的结果。然而，它们庞大的规模和处理要求阻碍了其在有限资源上的部署。为了提高效率，二值化和提前退出（EE）已被证明是有效的解决方案。然而，二值化可能导致性能损失，因为精度降低会影响梯度估计和参数更新。此外，关于EE机制的研究仍处于早期阶段。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05225v2">PDF</a> This revised manuscript includes 18 pages, 17 figures, and 6 tables.   Methodology and results sections have been improved for clarity and depth,   incorporating additional comparisons, ablations, and a new evaluation   dataset. A few relevant references were added, and overall organization   refined for better readability</p>
<p><strong>Summary</strong></p>
<p>基于Transformer的大型语言模型（LLM）在各种应用上取得了尖端成果，但其庞大的规模和计算资源需求限制了其在资源受限环境中的应用。为提高效率，二进制化和提前退出（EE）被证明是有效的解决方案。然而，二进制化可能导致性能损失，影响梯度估计和参数更新。为解决这些挑战，我们推出Binarized Early Exit Transformer（BEExformer），首款结合二进制感知训练（BAT）和EE的选择性学习型变压器。每个变压器块都集成了选择性学习遗忘网络（SLFN），以增强上下文保留并消除无关信息。BAT使用符号函数的可微二阶近似进行梯度计算，有助于减小模型大小。EE机制依赖于中间变压器块之间熵的分数减少，以及软路由损失估计。这通过减少浮点运算次数（FLOPs）加速推理，并解决深度网络固有的“过度思考”问题，提高了准确率。在六个数据集上的大量评估表明其在性能效率上具有帕累托最优的权衡。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在多种应用上表现卓越，但资源需求大，部署受限。</li>
<li>二进制化和提前退出（EE）是提高模型效率的有效方法。</li>
<li>二进制感知训练（BAT）结合选择性学习遗忘网络（SLFN）以增强模型的上下文保留能力并消除无关信息。</li>
<li>BAT使用可微二阶近似进行梯度计算，有助于显著减小模型大小。</li>
<li>EE机制通过减少中间变压器块的熵来加速推理，并解决“过度思考”问题，从而提高准确率。</li>
<li>BEExformer在多个数据集上的评估表现出其帕累托最优的性能效率权衡。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.05225">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-925284e718fe0e838c852169f1f5d37e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65dda04a24981ac174173e2d5f27848a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LASER-Attention-with-Exponential-Transformation"><a href="#LASER-Attention-with-Exponential-Transformation" class="headerlink" title="LASER: Attention with Exponential Transformation"></a>LASER: Attention with Exponential Transformation</h2><p><strong>Authors:Sai Surya Duvvuri, Inderjit S. Dhillon</strong></p>
<p>Transformers have had tremendous impact for several sequence related tasks, largely due to their ability to retrieve from any part of the sequence via softmax based dot-product attention. This mechanism plays a crucial role in Transformer’s performance. We analyze the gradients backpropagated through the softmax operation in the attention mechanism and observe that these gradients can often be small. This poor gradient signal backpropagation can lead to inefficient learning of parameters preceeding the attention operations. To this end, we introduce a new attention mechanism called LASER, which we analytically show to admit a larger gradient signal. We show that LASER attention can be implemented by making small modifications to existing attention implementations. We conduct experiments on autoregressive large language models (LLMs) with upto 7.7 billion parameters with an average improvement of upto 1.44% over standard attention on downstream evaluations and 1.65% finetuning improvements. Additionally, LASER demonstrates generalization performance improvement across a variety of tasks (vision, text and speech):Vision Transformer (ViT) on Imagenet, Conformer on the Librispeech speech-to-text and BERT with 2.2 billion parameters. </p>
<blockquote>
<p>Transformer对多个序列相关任务产生了巨大影响，这主要归功于其通过基于softmax的点积注意力从序列中检索信息的能力。这一机制在Transformer的性能中起着关键作用。我们分析了注意力机制中softmax操作反向传播的梯度，观察到这些梯度通常很小。这种不良的梯度信号反向传播可能导致注意力操作之前的参数学习效率低下。为此，我们引入了一种新的注意力机制，称为LASER。我们通过分析证明，LASER可以接纳更大的梯度信号。我们表明，通过对现有注意力实现进行微小修改，就可以实现LASER注意力。我们在具有高达7.7亿参数的自动回归大型语言模型（LLM）上进行了实验，在下游评估和标准注意力相比，平均改进了高达1.44%，微调改进了1.65%。此外，LASER在各种任务（视觉、文本和语音）上展示了泛化性能的提升：在Imagenet上的Vision Transformer（ViT）、Librispeech语音到文本的Conformer，以及具有22亿参数的BERT。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03493v2">PDF</a> ICML 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了Transformer中的注意力机制对序列相关任务的影响，并分析了softmax操作中反向传播的梯度问题。针对这一问题，提出了一种新的注意力机制——LASER注意力，它可以实现更大的梯度信号，并通过对现有注意力实现的小修改实现。实验结果表明，在大型语言模型（LLM）中，LASER注意力在下游评估和微调方面均取得了显著改进。此外，LASER还在多种任务中展示了泛化性能的提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformer的注意力机制对序列相关任务有巨大影响，得益于其通过softmax基于点积的注意力机制从序列中检索信息的能力。</li>
<li>分析发现，softmax操作中反向传播的梯度信号往往较小，可能导致注意力操作前参数的无效学习。</li>
<li>针对此问题，提出了名为LASER的新注意力机制，它可以实现更大的梯度信号，从而提高学习效率。</li>
<li>LASER注意力可以通过对现有注意力实现的小修改来实现。</li>
<li>在大型语言模型（LLM）的下游评估和微调方面，LASER注意力取得了显著改进，平均改进率高达1.44%。</li>
<li>LASER注意力在多种任务中展示了泛化性能的提升，包括图像分类（Vision Transformer on Imagenet）、语音识别（Conformer on Librispeech）和文本处理（BERT with 2.2 billion parameters）。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03493">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-31e6c6ad944ddec29419217836e73dd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0944887faa4bbc6140c562dcae36f807.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8271694abb532a76b77fc6c68d48dd55.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Large-Language-Models-Engineer-Too-Many-Simple-Features-For-Tabular-Data"><a href="#Large-Language-Models-Engineer-Too-Many-Simple-Features-For-Tabular-Data" class="headerlink" title="Large Language Models Engineer Too Many Simple Features For Tabular Data"></a>Large Language Models Engineer Too Many Simple Features For Tabular Data</h2><p><strong>Authors:Jaris Küken, Lennart Purucker, Frank Hutter</strong></p>
<p>Tabular machine learning problems often require time-consuming and labor-intensive feature engineering. Recent efforts have focused on using large language models (LLMs) to capitalize on their potential domain knowledge. At the same time, researchers have observed ethically concerning negative biases in other LLM-related use cases, such as text generation. These developments motivated us to investigate whether LLMs exhibit a bias that negatively impacts the performance of feature engineering. While not ethically concerning, such a bias could hinder practitioners from fully utilizing LLMs for automated data science. Therefore, we propose a method to detect potential biases by detecting anomalies in the frequency of operators (e.g., adding two features) suggested by LLMs when engineering new features. Our experiments evaluate the bias of four LLMs, two big frontier and two small open-source models, across 27 tabular datasets. Our results indicate that LLMs are biased toward simple operators, such as addition, and can fail to utilize more complex operators, such as grouping followed by aggregations. Furthermore, the bias can negatively impact the predictive performance when using LLM-generated features. Our results call for mitigating bias when using LLMs for feature engineering. </p>
<blockquote>
<p>表格型机器学习问题通常需要耗时且劳动密集型的特征工程。最近的努力集中在利用大型语言模型（LLM）发挥其潜在的领域知识优势上。与此同时，研究人员在其他与LLM相关的用例中观察到有悖伦理的负面偏见，例如文本生成。这些发展促使我们调查LLM是否表现出对特征工程性能产生负面影响的偏见。虽然并不违背伦理，但这种偏见可能会阻碍从业者充分利用LLM进行自动化数据科学。因此，我们提出了一种通过检测LLM在特征工程中建议的操作符频率异常来检测潜在偏见的方法（例如，添加两个特征）。我们的实验评估了四个LLM的偏见，包括两个大型前沿模型和两个小型的开源模型，跨越27个表格数据集。我们的结果表明，LLM偏向于简单的操作符，如加法，并且可能无法利用更复杂的操作符，如分组后的聚合。此外，这种偏见在使用LLM生成的特性进行预测时可能会产生负面影响。我们的研究结果呼吁在利用LLM进行特征工程时减轻偏见。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17787v2">PDF</a> Accepted at the 3rd Table Representation Learning Workshop @ NeurIPS   2024</p>
<p><strong>Summary</strong><br>大型语言模型（LLM）在特征工程应用中存在偏见。研究提出一种检测LLM偏见的方法，通过观察LLM建议的操作符频率来检测异常值。实验结果显示，LLM倾向于使用简单操作符，可能影响预测性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在特征工程中具有潜力，但存在偏见问题。</li>
<li>LLM倾向于使用简单操作符，如加法，可能忽视更复杂操作符。</li>
<li>LLM的偏见可能影响预测性能。</li>
<li>提出一种通过检测LLM建议的操作符频率异常来检测潜在偏见的方法。</li>
<li>实验评估了四种LLM的偏见，包括两种大型前沿和两种小型开源模型。</li>
<li>LLM在27个表格数据集上的表现存在偏见。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17787">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-07bf1eec3c07750d333e954bc268b054.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43e43a29133b9b6d3cc760e03b766b50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91b9bbb4ef0dc06996ad85ed7f6263fa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-80d3de6a0903788e3f1aabaf879e1603.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66263c601eb8c7e2fa87d1d283ef89a4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-17/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-17/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-17/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-8030ab6220eb9d5af66ba57f0797f4b8.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-07-17  Journalism-Guided Agentic In-Context Learning for News Stance Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-17/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a970e2bbb9edf925c2b94b260c5e7e8d.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning 方向最新论文已更新，请持续关注 Update in 2025-07-17  Comprehension Without Competence Architectural Limits of LLMs in   Symbolic Computation and Reasoning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27685.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
