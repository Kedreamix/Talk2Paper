<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-09  Perceptual Decoupling for Scalable Multi-modal Reasoning via   Reward-Optimized Captioning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-7de1d642a339137fcd331c11d7b07719.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    21.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    87 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-09-æ›´æ–°"><a href="#2025-06-09-æ›´æ–°" class="headerlink" title="2025-06-09 æ›´æ–°"></a>2025-06-09 æ›´æ–°</h1><h2 id="Perceptual-Decoupling-for-Scalable-Multi-modal-Reasoning-via-Reward-Optimized-Captioning"><a href="#Perceptual-Decoupling-for-Scalable-Multi-modal-Reasoning-via-Reward-Optimized-Captioning" class="headerlink" title="Perceptual Decoupling for Scalable Multi-modal Reasoning via   Reward-Optimized Captioning"></a>Perceptual Decoupling for Scalable Multi-modal Reasoning via   Reward-Optimized Captioning</h2><p><strong>Authors:Yunhao Gou, Kai Chen, Zhili Liu, Lanqing Hong, Xin Jin, Zhenguo Li, James T. Kwok, Yu Zhang</strong></p>
<p>Recent advances in slow-thinking language models (e.g., OpenAI-o1 and DeepSeek-R1) have demonstrated remarkable abilities in complex reasoning tasks by emulating human-like reflective cognition. However, extending such capabilities to multi-modal large language models (MLLMs) remains challenging due to the high cost of retraining vision-language alignments when upgrading the underlying reasoner LLMs. A straightforward solution is to decouple perception from reasoning, i.e., converting visual inputs into language representations (e.g., captions) that are then passed to a powerful text-only reasoner. However, this decoupling introduces a critical challenge: the visual extractor must generate descriptions that are both faithful to the image and informative enough to support accurate downstream reasoning. To address this, we propose Reasoning-Aligned Perceptual Decoupling via Caption Reward Optimization (RACRO) - a reasoning-guided reinforcement learning strategy that aligns the extractorâ€™s captioning behavior with the reasoning objective. By closing the perception-reasoning loop via reward-based optimization, RACRO significantly enhances visual grounding and extracts reasoning-optimized representations. Experiments on multi-modal math and science benchmarks show that the proposed RACRO method achieves state-of-the-art average performance while enabling superior scalability and plug-and-play adaptation to more advanced reasoning LLMs without the necessity for costly multi-modal re-alignment. </p>
<blockquote>
<p>å…³äºæ…¢æ€è€ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚OpenAI-o1å’ŒDeepSeek-R1ï¼‰çš„æœ€æ–°è¿›å±•æ˜¾ç¤ºï¼Œé€šè¿‡æ¨¡ä»¿äººç±»åæ€è®¤çŸ¥ï¼Œå®ƒä»¬åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†è¿™äº›èƒ½åŠ›æ‰©å±•åˆ°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåœ¨å‡çº§åŸºç¡€æ¨ç†LLMsæ—¶éœ€è¦é‡æ–°è®­ç»ƒè§†è§‰è¯­è¨€å¯¹é½ï¼Œæˆæœ¬é«˜æ˜‚ã€‚ä¸€ç§ç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯å°†æ„ŸçŸ¥ä¸æ¨ç†è§£è€¦ï¼Œå³é€šè¿‡å°†è§†è§‰è¾“å…¥è½¬æ¢ä¸ºè¯­è¨€è¡¨ç¤ºå½¢å¼ï¼ˆä¾‹å¦‚æè¿°ï¼‰ï¼Œç„¶åä¼ é€’ç»™å¼ºå¤§çš„çº¯æ–‡æœ¬æ¨ç†å™¨ã€‚ç„¶è€Œï¼Œè¿™ç§è§£è€¦å¼•å…¥äº†ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šè§†è§‰æå–å™¨å¿…é¡»ç”Ÿæˆæ—¢å¿ äºå›¾åƒåˆèƒ½æ”¯æŒå‡†ç¡®ä¸‹æ¸¸æ¨ç†çš„æè¿°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡æè¿°å¥–åŠ±ä¼˜åŒ–å®ç°æ¨ç†æ„ŸçŸ¥è§£è€¦ï¼ˆRACROï¼‰â€”â€”ä¸€ç§å—æ¨ç†å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä½¿æå–å™¨çš„æè¿°è¡Œä¸ºä¸æ¨ç†ç›®æ ‡ä¿æŒä¸€è‡´ã€‚é€šè¿‡åŸºäºå¥–åŠ±çš„ä¼˜åŒ–æ¥å…³é—­æ„ŸçŸ¥æ¨ç†å¾ªç¯ï¼ŒRACROæ˜¾è‘—æé«˜äº†è§†è§‰å®šä½èƒ½åŠ›å¹¶æå–äº†ç”¨äºæ¨ç†çš„ä¼˜åŒ–è¡¨ç¤ºå½¢å¼ã€‚åœ¨å¤šæ¨¡æ€æ•°å­¦å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„RACROæ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„å¹³å‡æ€§èƒ½ï¼ŒåŒæ—¶å®ç°äº†å“è¶Šçš„å¯æ‰©å±•æ€§å’Œå³æ’å³ç”¨é€‚åº”æ›´å…ˆè¿›çš„æ¨ç†LLMsçš„èƒ½åŠ›ï¼Œæ— éœ€æ˜‚è´µçš„å¤šæ¨¡æ€é‡æ–°å¯¹é½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04559v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¿‘æœŸæ…¢æ€è€ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚OpenAI-o1å’ŒDeepSeek-R1ï¼‰åœ¨æ¨¡æ‹Ÿäººç±»åæ€è®¤çŸ¥åï¼Œå±•ç°å‡ºæƒŠäººçš„å¤æ‚æ¨ç†ä»»åŠ¡èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†å…¶èƒ½åŠ›æ‰©å±•åˆ°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ—¶ï¼Œç”±äºéœ€è¦å‡çº§åº•å±‚æ¨ç†å™¨LLMsæ—¶é‡è®­è§†è§‰è¯­è¨€å¯¹é½çš„æˆæœ¬é«˜æ˜‚è€Œé¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºä¸€ç§é€šè¿‡å¥–åŠ±ä¼˜åŒ–ï¼ˆRACROï¼‰è¿›è¡Œæ¨ç†å¯¹é½çš„æ„ŸçŸ¥è§£è€¦æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¥–åŠ±ä¼˜åŒ–å®ç°æ„ŸçŸ¥ä¸æ¨ç†çš„é—­ç¯ï¼Œæ˜¾è‘—æé«˜äº†è§†è§‰å®šä½çš„å‡†ç¡®æ€§å¹¶æå–å‡ºæ¨ç†ä¼˜åŒ–åçš„è¡¨ç¤ºå½¢å¼ã€‚å®éªŒè¯æ˜RACROæ–¹æ³•åœ¨å¤šæ¨¡æ€æ•°å­¦å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¹³å‡æ€§èƒ½ï¼ŒåŒæ—¶åœ¨é€‚åº”æ›´å…ˆè¿›çš„æ¨ç†LLMsæ—¶å…·æœ‰å‡ºè‰²çš„å¯æ‰©å±•æ€§å’Œå³æ’å³ç”¨æ€§ï¼Œæ— éœ€æ˜‚è´µçš„å¤šæ¨¡æ€é‡æ–°å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ…¢æ€è€ƒè¯­è¨€æ¨¡å‹å¦‚OpenAI-o1å’ŒDeepSeek-R1å…·å¤‡å¤æ‚æ¨ç†ä»»åŠ¡çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„åæ€è®¤çŸ¥ã€‚</li>
<li>å°†è¿™äº›æ¨¡å‹çš„èƒ½åŠ›æ‰©å±•åˆ°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºè§†è§‰è¯­è¨€å¯¹é½çš„é‡è®­æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>æå‡ºä¸€ç§åä¸ºRACROçš„æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå®ƒé€šè¿‡å¥–åŠ±ä¼˜åŒ–å®ç°æ„ŸçŸ¥ä¸æ¨ç†çš„è§£è€¦å’Œé—­ç¯ã€‚</li>
<li>RACROæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜è§†è§‰å®šä½çš„å‡†ç¡®æ€§å¹¶æå–æ¨ç†ä¼˜åŒ–åçš„è¡¨ç¤ºå½¢å¼ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºRACROåœ¨å¤šæ¨¡æ€æ•°å­¦å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—æœ€å…ˆè¿›çš„å¹³å‡æ€§èƒ½ã€‚</li>
<li>RACROæ–¹æ³•å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ï¼Œå¯ä»¥è½»æ¾é€‚åº”æ›´å…ˆè¿›çš„æ¨ç†LLMsè€Œæ— éœ€è¿›è¡Œå¤æ‚çš„é‡æ–°è®­ç»ƒå’Œè°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04559">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f4770c771227d67a441a3039ed781dd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c151dcb46d91827f74b5542708c1328.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f397eb8b61a4e4069d49f682cc8198a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97fbdd378b6fbf5ef4f79ae2dbe744d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-391c39fd294ff938a471bd483b2d792f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-519253ed13097ccaa955555b0ff8f85d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Leveraging-Reward-Models-for-Guiding-Code-Review-Comment-Generation"><a href="#Leveraging-Reward-Models-for-Guiding-Code-Review-Comment-Generation" class="headerlink" title="Leveraging Reward Models for Guiding Code Review Comment Generation"></a>Leveraging Reward Models for Guiding Code Review Comment Generation</h2><p><strong>Authors:Oussama Ben Sghaier, Rosalia Tufano, Gabriele Bavota, Houari Sahraoui</strong></p>
<p>Code review is a crucial component of modern software development, involving the evaluation of code quality, providing feedback on potential issues, and refining the code to address identified problems. Despite these benefits, code review can be rather time consuming, and influenced by subjectivity and human factors. For these reasons, techniques to (partially) automate the code review process have been proposed in the literature. Among those, the ones exploiting deep learning (DL) are able to tackle the generative aspect of code review, by commenting on a given code as a human reviewer would do (i.e., comment generation task) or by automatically implementing code changes required to address a reviewerâ€™s comment (i.e., code refinement task). In this paper, we introduce CoRAL, a deep learning framework automating review comment generation by exploiting reinforcement learning with a reward mechanism considering both the semantics of the generated comments as well as their usefulness as input for other models automating the code refinement task. The core idea is that if the DL model generates comments that are semantically similar to the expected ones or can be successfully implemented by a second model specialized in code refinement, these comments are likely to be meaningful and useful, thus deserving a high reward in the reinforcement learning framework. We present both quantitative and qualitative comparisons between the comments generated by CoRAL and those produced by the latest baseline techniques, highlighting the effectiveness and superiority of our approach. </p>
<blockquote>
<p>ä»£ç å®¡æŸ¥æ˜¯ç°ä»£è½¯ä»¶å¼€å‘çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œæ¶‰åŠè¯„ä¼°ä»£ç è´¨é‡ã€å¯¹æ½œåœ¨é—®é¢˜æä¾›åé¦ˆä»¥åŠé’ˆå¯¹å·²è¯†åˆ«é—®é¢˜å¯¹ä»£ç è¿›è¡Œæ”¹è¿›ã€‚å°½ç®¡æœ‰è¿™äº›å¥½å¤„ï¼Œä»£ç å®¡æŸ¥å¯èƒ½ä¼šç›¸å½“è€—æ—¶ï¼Œå¹¶å—åˆ°ä¸»è§‚æ€§å’Œäººä¸ºå› ç´ çš„å½±å“ã€‚å› æ­¤ï¼Œæ–‡çŒ®ä¸­å·²æå‡ºäº†ï¼ˆéƒ¨åˆ†ï¼‰è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥è¿‡ç¨‹çš„æŠ€å·§ã€‚å…¶ä¸­ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰çš„æŠ€å·§èƒ½å¤Ÿé€šè¿‡åƒäººç±»å®¡æŸ¥å‘˜é‚£æ ·å¯¹ç»™å®šä»£ç è¿›è¡Œæ³¨é‡Šï¼ˆå³æ³¨é‡Šç”Ÿæˆä»»åŠ¡ï¼‰æˆ–è‡ªåŠ¨æ‰§è¡Œä¸ºè§£å†³å®¡ç¨¿äººè¯„è®ºæ‰€éœ€çš„ä»£ç æ›´æ”¹ï¼ˆå³ä»£ç æ”¹è¿›ä»»åŠ¡ï¼‰æ¥å¤„ç†ä»£ç å®¡æŸ¥çš„ç”Ÿæˆæ–¹é¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CoRALï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨åŒ–å®¡æŸ¥è¯„è®ºç”Ÿæˆçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…¶å¥–åŠ±æœºåˆ¶è€ƒè™‘åˆ°ç”Ÿæˆçš„æ³¨é‡Šçš„è¯­ä¹‰ä»¥åŠå®ƒä»¬ä½œä¸ºå…¶ä»–è‡ªåŠ¨åŒ–ä»£ç æ”¹è¿›ä»»åŠ¡æ¨¡å‹çš„è¾“å…¥çš„æœ‰ç”¨æ€§ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œå¦‚æœDLæ¨¡å‹ç”Ÿæˆçš„æ³¨é‡Šä¸é¢„æœŸçš„æ³¨é‡Šè¯­ä¹‰ç›¸ä¼¼ï¼Œæˆ–è€…å¯ä»¥è¢«ä¸“é—¨è¿›è¡Œä»£ç æ”¹è¿›çš„ç¬¬äºŒæ¨¡å‹æˆåŠŸå®æ–½ï¼Œé‚£ä¹ˆè¿™äº›æ³¨é‡Šå¯èƒ½æ˜¯æœ‰æ„ä¹‰å’Œæœ‰ç”¨çš„ï¼Œå› æ­¤åœ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­å€¼å¾—é«˜å¥–åŠ±ã€‚æˆ‘ä»¬æä¾›äº†CoRALç”Ÿæˆçš„æ³¨é‡Šä¸æœ€æ–°åŸºå‡†æŠ€æœ¯äº§ç”Ÿçš„æ³¨é‡Šä¹‹é—´çš„å®šé‡å’Œå®šæ€§æ¯”è¾ƒï¼Œçªå‡ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04464v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä»£ç å®¡æŸ¥åœ¨ç°ä»£è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºäº†å…¶å­˜åœ¨çš„è€—æ—¶ã€å—ä¸»è§‚å› ç´ å½±å“ç­‰é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥è¿‡ç¨‹çš„æ¡†æ¶CoRALã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆä¸äººç±»å®¡æŸ¥è€…ç›¸ä¼¼çš„è¯„è®ºï¼Œå¹¶è‡ªåŠ¨å®æ–½è§£å†³å®¡æŸ¥è€…è¯„è®ºæ‰€éœ€çš„ä»£ç æ›´æ”¹ã€‚æ–‡ç« é€šè¿‡å®šé‡å’Œå®šæ€§æ¯”è¾ƒï¼Œå±•ç¤ºäº†CoRALç›¸è¾ƒäºæœ€æ–°åŸºçº¿æŠ€æœ¯åœ¨è¯„è®ºç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»£ç å®¡æŸ¥åœ¨è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦æ€§ï¼šåŒ…æ‹¬è¯„ä¼°ä»£ç è´¨é‡ã€æä¾›æ½œåœ¨é—®é¢˜åé¦ˆå’Œé’ˆå¯¹å·²è¯†åˆ«é—®é¢˜ä¼˜åŒ–ä»£ç ã€‚</li>
<li>ä»£ç å®¡æŸ¥çš„æŒ‘æˆ˜ï¼šåŒ…æ‹¬æ—¶é—´æ¶ˆè€—å¤§ã€å—ä¸»è§‚æ€§å’Œäººä¸ºå› ç´ å½±å“ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ä¸­çš„åº”ç”¨ï¼šå°¤å…¶æ˜¯è¯„è®ºç”Ÿæˆå’Œä»£ç ä¼˜åŒ–çš„ä»»åŠ¡ã€‚</li>
<li>CoRALæ¡†æ¶ä»‹ç»ï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨åŒ–è¯„è®ºç”Ÿæˆï¼Œå¹¶è€ƒè™‘ç”Ÿæˆçš„è¯„è®ºè¯­ä¹‰å’Œå…¶ä½œä¸ºä»£ç ä¼˜åŒ–è¾“å…¥çš„æœ‰ç”¨æ€§ã€‚</li>
<li>CoRALæ¡†æ¶çš„å¥–åŠ±æœºåˆ¶ï¼šæ ¹æ®è¯„è®ºçš„è¯­ä¹‰ç›¸ä¼¼æ€§å’Œå¯¹ä»£ç ä¼˜åŒ–æ¨¡å‹çš„æœ‰æ•ˆæ€§æ¥ç¡®å®šå¥–åŠ±ã€‚</li>
<li>æ–‡ç« é€šè¿‡æ¯”è¾ƒå±•ç¤ºäº†CoRALçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ï¼šä¸æœ€æ–°åŸºçº¿æŠ€æœ¯åœ¨è¯„è®ºç”Ÿæˆæ–¹é¢çš„æ¯”è¾ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04464">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-86e937dbb23fd9300703e8f9b1a56442.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0e382d1ff1acc0cd112af239b879c90a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e7a80b14f40df803b7c8418a85accef.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RedRFT-A-Light-Weight-Benchmark-for-Reinforcement-Fine-Tuning-Based-Red-Teaming"><a href="#RedRFT-A-Light-Weight-Benchmark-for-Reinforcement-Fine-Tuning-Based-Red-Teaming" class="headerlink" title="RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red   Teaming"></a>RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red   Teaming</h2><p><strong>Authors:Xiang Zheng, Xingjun Ma, Wei-Bin Lee, Cong Wang</strong></p>
<p>Red teaming has proven to be an effective method for identifying and mitigating vulnerabilities in Large Language Models (LLMs). Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy among existing red teaming techniques. However, a lack of a unified benchmark hinders current RFT-based red teaming methods. Implementation details, especially in Proximal Policy Optimization (PPO)-based RFT, significantly affect outcome stability and reproducibility. To address this issue, we introduce RedRFT, a lightweight benchmark designed to simplify and standardize the implementation and evaluation of RFT-based red teaming. RedRFT combines the design strengths of both single-file CleanRL and highly modularized Tianshou, offering high-quality single-file red teaming implementations and modular PPO core components, such as the General Advantage Estimator. It supports a variety of token and sentence diversity metrics, featuring modularized intrinsic reward computation that facilitates plug-and-play experimentation. To clarify their influence on RFT performance, we conducted an extensive ablation study on key components, including Low-Rank Adaptation (LoRA), Kullback-Leibler (KL) divergence, and Lagrange Multiplier. We hope this work contributes to 1) gaining a comprehensive understanding of the implementation nuances of RFT-based red teaming algorithms, and 2) enabling rapid prototyping of innovative features for RFT-based red teaming. Code for the benchmark can be accessed at <a target="_blank" rel="noopener" href="https://github.com/x-zheng16/RedRFT.git">https://github.com/x-zheng16/RedRFT.git</a>. </p>
<blockquote>
<p>çº¢é˜Ÿå®è·µå·²è¢«è¯æ˜æ˜¯è¯†åˆ«å’Œè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¼æ´çš„æœ‰æ•ˆæ–¹æ³•ã€‚å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰ä½œä¸ºç°æœ‰çº¢é˜ŸæŠ€æœ¯ä¸­çš„ä¸€ç§æœ‰å‰é€”çš„ç­–ç•¥è€Œå´­éœ²å¤´è§’ã€‚ç„¶è€Œï¼Œç¼ºä¹ç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•é˜»ç¢äº†å½“å‰çš„åŸºäºRFTçš„çº¢é˜Ÿæ–¹æ³•ã€‚å®ç°ç»†èŠ‚ï¼Œç‰¹åˆ«æ˜¯åœ¨åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰çš„RFTä¸­ï¼Œä¼šæ˜¾è‘—å½±å“ç»“æœçš„ç¨³å®šæ€§å’Œå¯é‡å¤æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RedRFTï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨ç®€åŒ–å’Œæ ‡å‡†åŒ–åŸºäºRFTçš„çº¢é˜Ÿçš„å®ç°å’Œè¯„ä¼°ã€‚RedRFTç»“åˆäº†å•æ–‡ä»¶CleanRLå’Œé«˜åº¦æ¨¡å—åŒ–çš„Tianshouçš„è®¾è®¡ä¼˜åŠ¿ï¼Œæä¾›é«˜è´¨é‡çš„å•æ–‡ä»¶çº¢é˜Ÿå®ç°å’Œæ¨¡å—åŒ–PPOæ ¸å¿ƒç»„ä»¶ï¼Œå¦‚é€šç”¨ä¼˜åŠ¿ä¼°è®¡å™¨ã€‚å®ƒæ”¯æŒå¤šç§ä»¤ç‰Œå’Œå¥å­å¤šæ ·æ€§æŒ‡æ ‡ï¼Œå…·æœ‰æ¨¡å—åŒ–çš„å†…åœ¨å¥–åŠ±è®¡ç®—ï¼Œä¾¿äºå³æ’å³ç”¨å®éªŒã€‚ä¸ºäº†æ˜ç¡®å…³é”®ç»„ä»¶å¯¹RFTæ€§èƒ½çš„å½±å“ï¼Œæˆ‘ä»¬å¯¹åŒ…æ‹¬ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰ã€Kullback-Leiblerï¼ˆKLï¼‰æ•£åº¦å’Œæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°åœ¨å†…çš„å…³é”®ç»„ä»¶è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèç ”ç©¶ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œæœ‰åŠ©äº1ï¼‰å…¨é¢ç†è§£åŸºäºRFTçš„çº¢é˜Ÿç®—æ³•çš„å®ç°ç»†èŠ‚ï¼›2ï¼‰åŠ å¿«åŸºäºRFTçš„çº¢é˜Ÿåˆ›æ–°åŠŸèƒ½çš„å¿«é€ŸåŸå‹è®¾è®¡ã€‚è¯¥åŸºå‡†æµ‹è¯•çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/x-zheng16/RedRFT.git">https://github.com/x-zheng16/RedRFT.git</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04302v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„çº¢é˜Ÿæµ‹è¯•ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç¼ºä¹ç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•å½±å“äº†å…¶åº”ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¼•å…¥RedRFTåŸºå‡†æµ‹è¯•ï¼Œç®€åŒ–å¹¶æ ‡å‡†åŒ–RFTçº¢é˜Ÿæµ‹è¯•çš„å®æ–½ä¸è¯„ä¼°ã€‚RedRFTç»“åˆCleanRLå’ŒTianshouçš„ä¼˜åŠ¿ï¼Œæä¾›é«˜è´¨é‡çš„å•æ–‡ä»¶çº¢é˜Ÿæµ‹è¯•å®ç°å’Œæ¨¡å—åŒ–PPOæ ¸å¿ƒç»„ä»¶ã€‚å®ƒæ”¯æŒå¤šç§ä»¤ç‰Œå’Œå¥å­å¤šæ ·æ€§æŒ‡æ ‡ï¼Œå¹¶æ¨¡å—åŒ–å†…åœ¨å¥–åŠ±è®¡ç®—ï¼Œä¾¿äºå®éªŒã€‚é€šè¿‡æ¶ˆé™¤ç ”ç©¶ï¼Œæˆ‘ä»¬äº†è§£äº†å…³é”®ç»„ä»¶å¯¹RFTæ€§èƒ½çš„å½±å“ã€‚æ­¤å·¥ä½œæ—¨åœ¨å…¨é¢ç†è§£RFTçº¢é˜Ÿæµ‹è¯•ç®—æ³•çš„å®æ–½ç»†èŠ‚å¹¶åŠ é€Ÿåˆ›æ–°åŠŸèƒ½åŸå‹è®¾è®¡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>çº¢é˜Ÿæµ‹è¯•å·²è¯æ˜æ˜¯è¯†åˆ«å¹¶ç¼“è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¼æ´çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰æ˜¯çº¢é˜Ÿæµ‹è¯•ä¸­çš„æœ‰å‰é€”çš„ç­–ç•¥ã€‚</li>
<li>ç¼ºä¹ç»Ÿä¸€åŸºå‡†å½±å“äº†RFTçš„åº”ç”¨ã€‚</li>
<li>RedRFTåŸºå‡†æµ‹è¯•æ—¨åœ¨ç®€åŒ–å¹¶æ ‡å‡†åŒ–RFTçº¢é˜Ÿæµ‹è¯•çš„å®æ–½ä¸è¯„ä¼°ã€‚</li>
<li>RedRFTç»“åˆäº†CleanRLå’ŒTianshouçš„ä¼˜ç‚¹ï¼Œæä¾›é«˜è´¨é‡çš„å•æ–‡ä»¶å®ç°å’Œæ¨¡å—åŒ–PPOæ ¸å¿ƒç»„ä»¶ã€‚</li>
<li>RedRFTæ”¯æŒå¤šç§ä»¤ç‰Œå’Œå¥å­å¤šæ ·æ€§æŒ‡æ ‡ï¼Œå¹¶æ¨¡å—åŒ–å†…åœ¨å¥–åŠ±è®¡ç®—ã€‚</li>
<li>é€šè¿‡æ¶ˆé™¤ç ”ç©¶ï¼Œå…³é”®ç»„ä»¶å¯¹RFTæ€§èƒ½çš„å½±å“å¾—åˆ°äº†ç†è§£ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04302">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4fc9393e72ed3114a211f19f53a19f37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25a6d2e935b8968fd87b3804988e209c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OpenThoughts-Data-Recipes-for-Reasoning-Models"><a href="#OpenThoughts-Data-Recipes-for-Reasoning-Models" class="headerlink" title="OpenThoughts: Data Recipes for Reasoning Models"></a>OpenThoughts: Data Recipes for Reasoning Models</h2><p><strong>Authors:Etash Guha, Ryan Marten, Sedrick Keh, Negin Raoof, Georgios Smyrnis, Hritik Bansal, Marianna Nezhurina, Jean Mercat, Trung Vu, Zayne Sprague, Ashima Suvarna, Benjamin Feuer, Liangyu Chen, Zaid Khan, Eric Frankel, Sachin Grover, Caroline Choi, Niklas Muennighoff, Shiye Su, Wanjia Zhao, John Yang, Shreyas Pimpalgaonkar, Kartik Sharma, Charlie Cheng-Jie Ji, Yichuan Deng, Sarah Pratt, Vivek Ramanujan, Jon Saad-Falcon, Jeffrey Li, Achal Dave, Alon Albalak, Kushal Arora, Blake Wulfe, Chinmay Hegde, Greg Durrett, Sewoong Oh, Mohit Bansal, Saadia Gabriel, Aditya Grover, Kai-Wei Chang, Vaishaal Shankar, Aaron Gokaslan, Mike A. Merrill, Tatsunori Hashimoto, Yejin Choi, Jenia Jitsev, Reinhard Heckel, Maheswaran Sathiamoorthy, Alexandros G. Dimakis, Ludwig Schmidt</strong></p>
<p>Reasoning models have made rapid progress on many benchmarks involving math, code, and science. Yet, there are still many open questions about the best training recipes for reasoning since state-of-the-art models often rely on proprietary datasets with little to no public information available. To address this, the goal of the OpenThoughts project is to create open-source datasets for training reasoning models. After initial explorations, our OpenThoughts2-1M dataset led to OpenThinker2-32B, the first model trained on public reasoning data to match DeepSeek-R1-Distill-32B on standard reasoning benchmarks such as AIME and LiveCodeBench. We then improve our dataset further by systematically investigating each step of our data generation pipeline with 1,000+ controlled experiments, which led to OpenThoughts3. Scaling the pipeline to 1.2M examples and using QwQ-32B as teacher yields our OpenThoughts3-7B model, which achieves state-of-the-art results: 53% on AIME 2025, 51% on LiveCodeBench 06&#x2F;24-01&#x2F;25, and 54% on GPQA Diamond - improvements of 15.3, 17.2, and 20.5 percentage points compared to the DeepSeek-R1-Distill-Qwen-7B. All of our datasets and models are available on <a target="_blank" rel="noopener" href="https://openthoughts.ai/">https://openthoughts.ai</a>. </p>
<blockquote>
<p>æ¨ç†æ¨¡å‹åœ¨æ•°å­¦ã€ä»£ç å’Œç§‘å­¦ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†å¿«é€Ÿè¿›å±•ã€‚ç„¶è€Œï¼Œå…³äºæœ€ä½³æ¨ç†è®­ç»ƒæ–¹æ¡ˆä»ç„¶å­˜åœ¨è®¸å¤šæœªè§£å†³çš„é—®é¢˜ï¼Œå› ä¸ºæœ€å…ˆè¿›çš„æ¨¡å‹é€šå¸¸ä¾èµ–äºä¸“æœ‰æ•°æ®é›†ï¼Œè€Œå…¬å¼€ä¿¡æ¯å¾ˆå°‘æˆ–æ²¡æœ‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒOpenThoughtsé¡¹ç›®çš„ç›®æ ‡æ˜¯åˆ›å»ºç”¨äºè®­ç»ƒæ¨ç†æ¨¡å‹çš„å¼€æºæ•°æ®é›†ã€‚ç»è¿‡åˆæ­¥æ¢ç´¢ï¼Œæˆ‘ä»¬çš„OpenThoughts2-1Mæ•°æ®é›†å‚¬ç”Ÿäº†OpenThinker2-32Bï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨å…¬å¼€æ¨ç†æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨AIMEå’ŒLiveCodeBenchç­‰æ ‡å‡†æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šä¸DeepSeek-R1-Distill-32Bç›¸åŒ¹é…ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ç³»ç»Ÿåœ°è°ƒæŸ¥æ•°æ®ç”Ÿæˆç®¡é“çš„æ¯ä¸€æ­¥è¿›è¡Œäº†1000å¤šæ¬¡å—æ§å®éªŒï¼Œè¿›ä¸€æ­¥æ”¹è¿›äº†æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œä»è€Œäº§ç”Ÿäº†OpenThoughts3ã€‚å°†ç®¡é“æ‰©å±•åˆ°120ä¸‡ä¸ªä¾‹å­ï¼Œå¹¶ä½¿ç”¨QwQ-32Bä½œä¸ºæ•™å¸ˆï¼Œæˆ‘ä»¬å¾—åˆ°äº†OpenThoughts3-7Bæ¨¡å‹ï¼Œå–å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼šAIME 2025ä¸Šè¾¾åˆ°53%ï¼ŒLiveCodeBench 06&#x2F;24-01&#x2F;25ä¸Šè¾¾åˆ°51%ï¼ŒGPQA Diamondä¸Šè¾¾åˆ°54%â€”â€”ä¸DeepSeek-R1-Distill-Qwen-7Bç›¸æ¯”ï¼Œåˆ†åˆ«æé«˜äº†15.3ã€17.2å’Œ20.5ä¸ªç™¾åˆ†ç‚¹ã€‚æˆ‘ä»¬çš„æ‰€æœ‰æ•°æ®é›†å’Œæ¨¡å‹éƒ½å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://openthoughts.ai/">https://openthoughts.ai</a>ä¸Šæ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04178v2">PDF</a> <a target="_blank" rel="noopener" href="https://www.openthoughts.ai/blog/ot3">https://www.openthoughts.ai/blog/ot3</a>. arXiv admin note: text overlap   with arXiv:2505.23754 by other authors</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†OpenThoughtsé¡¹ç›®è‡´åŠ›äºåˆ›å»ºç”¨äºè®­ç»ƒæ¨ç†æ¨¡å‹å…¬å¼€æ•°æ®é›†çš„ç›®æ ‡ã€‚ä»åˆå§‹æ¢ç´¢çš„OpenThoughts2-1Mæ•°æ®é›†å¼€å§‹ï¼ŒæˆåŠŸç ”å‘å‡ºèƒ½åœ¨å…¬å¼€æ¨ç†æ•°æ®ä¸Šè®­ç»ƒçš„OpenThinker2-32Bæ¨¡å‹ï¼Œå…¶æ€§èƒ½åŒ¹é…DeepSeek-R1-Distill-32Båœ¨AIMEå’ŒLiveCodeBenchç­‰æ ‡å‡†æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ã€‚åç»­é€šè¿‡ç³»ç»Ÿåœ°ç ”ç©¶æ•°æ®ç”Ÿæˆç®¡é“çš„æ¯ä¸€æ­¥ï¼Œè¿›è¡Œäº†è¶…è¿‡ä¸€åƒæ¬¡çš„æ§åˆ¶å®éªŒï¼Œæ¨å‡ºäº†OpenThoughts3æ•°æ®é›†å’ŒOpenThoughts3-7Bæ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨AIME 2025ã€LiveCodeBench 06&#x2F;24-01&#x2F;25ä»¥åŠGPQA Diamondä¸Šå®ç°äº†ä¸šç•Œé¢†å…ˆçš„ç»“æœã€‚æ‰€æœ‰æ•°æ®é›†å’Œæ¨¡å‹å‡å¯åœ¨<a target="_blank" rel="noopener" href="https://openthoughts.aiä¸Šè·å–./">https://openthoughts.aiä¸Šè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OpenThoughtsé¡¹ç›®çš„ç›®æ ‡æ˜¯åˆ›å»ºå…¬å¼€æ•°æ®é›†ä»¥è®­ç»ƒæ¨ç†æ¨¡å‹ï¼Œè§£å†³å½“å‰è®¸å¤šæ¨ç†æ¨¡å‹ä¾èµ–äºä¸“æœ‰æ•°æ®é›†çš„é—®é¢˜ã€‚</li>
<li>OpenThoughts2-1Mæ•°æ®é›†è¡ç”Ÿå‡ºOpenThinker2-32Bæ¨¡å‹ï¼Œèƒ½åœ¨å…¬å¼€æ¨ç†æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ€§èƒ½ä¸DeepSeek-R1-Distill-32Bç›¸åŒ¹é…ã€‚</li>
<li>é€šè¿‡ç³»ç»Ÿåœ°ç ”ç©¶æ•°æ®ç”Ÿæˆç®¡é“çš„æ¯ä¸€æ­¥ä»¥åŠè¿›è¡Œå¤§é‡æ§åˆ¶å®éªŒï¼ŒOpenThoughtsé¡¹ç›®è¿›ä¸€æ­¥ä¼˜åŒ–äº†æ•°æ®é›†å¹¶æ¨å‡ºäº†OpenThoughts3ã€‚</li>
<li>OpenThoughts3-7Bæ¨¡å‹é€šè¿‡æ‰©å¤§ç®¡é“è§„æ¨¡è‡³1.2Mç¤ºä¾‹å¹¶ä½¿ç”¨QwQ-32Bä½œä¸ºæ•™å¸ˆï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>OpenThoughts3-7Bæ¨¡å‹åœ¨AIME 2025ã€LiveCodeBench 06&#x2F;24-01&#x2F;25ä»¥åŠGPQA Diamondä¸Šå–å¾—äº†ä¸šç•Œæœ€ä½³ç»“æœã€‚</li>
<li>OpenThoughtsé¡¹ç›®å…¬å¼€äº†æ‰€æœ‰æ•°æ®é›†å’Œæ¨¡å‹ï¼Œæ–¹ä¾¿å…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ece3bfc62cea6df4bae9f6c85e6f8fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-99cdd32681bb33847a3059e6e3672d77.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea99bd99e8f513ebea30ba316225138a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8c632e581ad1cab232efebdc022e3e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d886903ef8238d4762723dbbf5ba4b25.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Toward-Entailment-Checking-Explore-Eigenmarking-Search"><a href="#Toward-Entailment-Checking-Explore-Eigenmarking-Search" class="headerlink" title="Toward Entailment Checking: Explore Eigenmarking Search"></a>Toward Entailment Checking: Explore Eigenmarking Search</h2><p><strong>Authors:Tatpong Katanyukul</strong></p>
<p>Logic entailment is essential to reasoning,   but entailment checking has the worst-case complexity of an exponential of the variable size.   With recent development, quantum computing when mature   may allow an effective approach for various combinatorial problems,   including entailment checking.   Grover algorithm uses Grover operations, selective phase inversion and amplitude amplification   to address a search over unstructured data with quadratic improvement from a classical method.   Its original form is intended to a single-winner scenario: exactly one match is promised.   Its extension to multiple-winner cases employs probabilistic control over   a number of applications of Grover operations, while a no-winner case is handled by time-out.   Our study explores various schemes of &#96;&#96;eigenmarkingâ€™â€™ approach.   Still relying on Grover operations, but the approach introduces additional qubits   to tag the eigenstates.   The tagged eigenstates are to facilitate an interpretation of the measured results and   enhance identification of a no-winner case (related to no logic violation in entailment context).   Our investigation experiments three variations of eigenmarking on a two-qubit system   using an IBM Aer simulator.   The results show strong distinguishability in all schemes with the best relative distinguishabilities of 19 and 53 in worst case   and in average case, respectively.   Our findings reveal a viable quantum mechanism to differentiate a no-winner case   from other scenarios, which could play a pivot role in entailment checking and logic reasoning in general. </p>
<blockquote>
<p>é€»è¾‘æ¨ç†ä¸­è•´å«å…³ç³»è‡³å…³é‡è¦ï¼Œä½†è•´å«å…³ç³»çš„æ£€éªŒåœ¨æœ€åæƒ…å†µä¸‹çš„å¤æ‚åº¦æ˜¯å˜é‡å¤§å°çš„æŒ‡æ•°çº§ã€‚éšç€æœ€æ–°å‘å±•ï¼Œå½“é‡å­è®¡ç®—æœºæˆç†Ÿæ—¶ï¼Œå®ƒå¯èƒ½ä¸ºå„ç§ç»„åˆé—®é¢˜æä¾›ä¸€ç§æœ‰æ•ˆæ–¹æ³•ï¼ŒåŒ…æ‹¬è•´å«å…³ç³»æ£€éªŒã€‚Groverç®—æ³•ä½¿ç”¨Groveræ“ä½œã€é€‰æ‹©æ€§ç›¸ä½åè½¬å’ŒæŒ¯å¹…æ”¾å¤§æ¥è§£å†³å¯¹æ— ç»“æ„æ•°æ®çš„æœç´¢é—®é¢˜ï¼Œä¸ç»å…¸æ–¹æ³•ç›¸æ¯”æœ‰äºŒæ¬¡æ”¹è¿›ã€‚å…¶åŸå§‹å½¢å¼æ˜¯ä¸ºäº†è§£å†³å•ä¸€èƒœå‡ºåœºæ™¯ï¼šä¿è¯æ°å¥½æœ‰ä¸€ä¸ªåŒ¹é…ã€‚å…¶æ‰©å±•åˆ°å¤šä¸ªèƒœå‡ºåœºæ™¯çš„æƒ…å†µé‡‡ç”¨æ¦‚ç‡æ§åˆ¶å¤šæ¬¡åº”ç”¨Groveræ“ä½œï¼Œè€Œæ— èƒœå‡ºæƒ…å†µåˆ™é€šè¿‡è¶…æ—¶å¤„ç†ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ¢ç´¢äº†â€œç‰¹å¾æ ‡è®°â€æ–¹æ³•çš„å¤šç§æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•ä»ç„¶ä¾èµ–äºGroveræ“ä½œï¼Œä½†å¼•å…¥äº†é¢å¤–çš„é‡å­æ¯”ç‰¹æ¥æ ‡è®°æœ¬å¾æ€ã€‚æ ‡è®°çš„æœ¬å¾æ€æœ‰åŠ©äºè§£é‡Šæµ‹é‡ç»“æœï¼Œå¹¶æé«˜å¯¹æ— èƒœå‡ºæƒ…å†µçš„è¯†åˆ«ï¼ˆä¸è•´å«å…³ç³»ä¸Šä¸‹æ–‡ä¸­çš„æ— é€»è¾‘è¿è§„ç›¸å…³ï¼‰ã€‚æˆ‘ä»¬åœ¨IBM Aeræ¨¡æ‹Ÿå™¨ä¸Šå¯¹ä¸€ä¸ªä¸¤é‡å­æ¯”ç‰¹ç³»ç»Ÿè¿›è¡Œäº†ä¸‰ç§ç‰¹å¾æ ‡è®°æ–¹æ³•çš„å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ–¹æ¡ˆçš„åŒºåˆ†åº¦éƒ½å¾ˆå¼ºï¼Œå…¶ä¸­æœ€åæƒ…å†µä¸‹æœ€ä½³ç›¸å¯¹åŒºåˆ†åº¦ä¸º19ï¼Œå¹³å‡æƒ…å†µä¸‹çš„æœ€ä½³ç›¸å¯¹åŒºåˆ†åº¦ä¸º53ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†ä¸€ç§å¯è¡Œçš„é‡å­æœºåˆ¶æ¥åŒºåˆ†æ— èƒœå‡ºæƒ…å†µä¸å…¶ä»–åœºæ™¯ï¼Œè¿™åœ¨è•´å«æ£€éªŒå’Œé€»è¾‘æ¨ç†ä¸­å¯èƒ½èµ·åˆ°å…³é”®ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03771v1">PDF</a> 8 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†é€»è¾‘è•´å«åœ¨æ¨ç†ä¸­çš„é‡è¦æ€§ï¼Œä»¥åŠé‡å­è®¡ç®—åœ¨è§£å†³åŒ…å«é€»è¾‘è•´å«æ£€æŸ¥åœ¨å†…çš„ç»„åˆé—®é¢˜ä¸Šçš„æ½œåœ¨åº”ç”¨ã€‚æ–‡ç« ä»‹ç»äº†Groverç®—æ³•åŠå…¶åœ¨ä¸åŒåœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œå¹¶æ¢ç´¢äº†ä¸€ç§åä¸ºâ€œeigenmarkingâ€çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨é¢å¤–çš„é‡å­æ¯”ç‰¹æ ‡è®°æœ¬å¾æ€ï¼Œä»¥æé«˜æ— èµ¢å®¶æƒ…å†µçš„è¯†åˆ«èƒ½åŠ›ã€‚åœ¨IBM Aeræ¨¡æ‹Ÿå™¨ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•çš„åŒºåˆ†èƒ½åŠ›è¾ƒå¼ºï¼Œåœ¨æœ€åå’Œå¹³å‡æƒ…å†µä¸‹ï¼Œæœ€ä½³ç›¸å¯¹åŒºåˆ†åº¦åˆ†åˆ«ä¸º19å’Œ53ã€‚è¿™ä¸ºé‡å­æœºåˆ¶åœ¨é€»è¾‘è•´å«æ£€æŸ¥å’Œé€»è¾‘æ¨ç†ä¸­åŒºåˆ†æ— èµ¢å®¶æƒ…å†µæä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é€»è¾‘è•´å«åœ¨æ¨ç†ä¸­è‡³å…³é‡è¦ï¼Œä½†è•´å«æ£€æŸ¥çš„è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ã€‚</li>
<li>é‡å­è®¡ç®—å¯¹äºè§£å†³ç»„åˆé—®é¢˜ï¼ŒåŒ…æ‹¬é€»è¾‘è•´å«æ£€æŸ¥å…·æœ‰æ½œåŠ›ã€‚</li>
<li>Groverç®—æ³•æ˜¯ä¸€ç§ç”¨äºæœç´¢æœªç»“æ„åŒ–æ•°æ®çš„æœ‰æ•ˆæ–¹æ³•ï¼Œå¯é€šè¿‡äºŒæ¬¡æ”¹è¿›ç»å…¸æ–¹æ³•ã€‚</li>
<li>Groverç®—æ³•å¯ä»¥æ‰©å±•åˆ°å¤šèµ¢å®¶æƒ…å†µï¼Œå¹¶é€šè¿‡è¶…æ—¶å¤„ç†æ— èµ¢å®¶æƒ…å†µã€‚</li>
<li>â€œEigenmarkingâ€æ–¹æ³•ä½¿ç”¨é¢å¤–çš„é‡å­æ¯”ç‰¹æ ‡è®°æœ¬å¾æ€ï¼Œæé«˜ç»“æœçš„è§£é‡Šæ€§å’Œæ— èµ¢å®¶æƒ…å†µçš„è¯†åˆ«ã€‚</li>
<li>åœ¨IBM Aeræ¨¡æ‹Ÿå™¨ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œeigenmarkingæ–¹æ³•å…·æœ‰è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03771">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3f3f7751e03dc18dc85ff028c582cf87.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b576844b933fe9387611ae268e94c1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9b7aefb63082fbd8419a4357b7a40d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20904688a7aa75cced7d9875bf1c9859.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7de1d642a339137fcd331c11d7b07719.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87829a144829df2a43a323f6af7164ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e463f05c791ff7402683ea3d6deb820b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e33a76a42f670d6307fad9b19c319ce3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Seed-Coder-Let-the-Code-Model-Curate-Data-for-Itself"><a href="#Seed-Coder-Let-the-Code-Model-Curate-Data-for-Itself" class="headerlink" title="Seed-Coder: Let the Code Model Curate Data for Itself"></a>Seed-Coder: Let the Code Model Curate Data for Itself</h2><p><strong>Authors:ByteDance Seed, Yuyu Zhang, Jing Su, Yifan Sun, Chenguang Xi, Xia Xiao, Shen Zheng, Anxiang Zhang, Kaibo Liu, Daoguang Zan, Tao Sun, Jinhua Zhu, Shulin Xin, Dong Huang, Yetao Bai, Lixin Dong, Chao Li, Jianchong Chen, Hanzhi Zhou, Yifan Huang, Guanghan Ning, Xierui Song, Jiaze Chen, Siyao Liu, Kai Shen, Liang Xiang, Yonghui Wu</strong></p>
<p>Code data in large language model (LLM) pretraining is recognized crucial not only for code-related tasks but also for enhancing general intelligence of LLMs. Current open-source LLMs often heavily rely on human effort to produce their code pretraining data, such as employing hand-crafted filtering rules tailored to individual programming languages, or using human-annotated data to train quality filters. However, these approaches are inherently limited in scalability, prone to subjective biases, and costly to extend and maintain across diverse programming languages. To address these challenges, we introduce Seed-Coder, a series of open-source LLMs comprising base, instruct and reasoning models of 8B size, minimizing human involvement in data construction. Our code pretraining data is produced by a model-centric data pipeline, which predominantly leverages LLMs for scoring and filtering code data. The instruct model is further trained via supervised fine-tuning and preference optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT) reinforcement learning to improve multi-step code reasoning. Seed-Coder achieves state-of-the-art results among open-source models of similar size and even surpasses some much larger models, demonstrating superior performance in code generation, code completion, code editing, code reasoning, and software engineering tasks. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é¢„è®­ç»ƒä»£ç æ•°æ®è¢«è®¤ä¸ºæ˜¯è‡³å…³é‡è¦çš„ï¼Œè¿™ä¸ä»…å¯¹ä¸ä»£ç ç›¸å…³çš„ä»»åŠ¡è‡³å…³é‡è¦ï¼Œè€Œä¸”å¯¹æé«˜LLMçš„æ•´ä½“æ™ºèƒ½æ°´å¹³ä¹Ÿèµ·ç€é‡è¦ä½œç”¨ã€‚ç›®å‰ï¼Œå¼€æºLLMå¾€å¾€ä¸¥é‡ä¾èµ–äººå·¥æ¥ç”Ÿæˆå®ƒä»¬çš„ä»£ç é¢„è®­ç»ƒæ•°æ®ï¼Œä¾‹å¦‚é’ˆå¯¹ç‰¹å®šç¼–ç¨‹è¯­è¨€å®šåˆ¶çš„æ‰‹åŠ¨è¿‡æ»¤è§„åˆ™ï¼Œæˆ–ä½¿ç”¨äººå·¥æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒè´¨é‡è¿‡æ»¤å™¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æœ¬è´¨ä¸Šå…·æœ‰å¯æ‰©å±•æ€§é™åˆ¶ã€å®¹æ˜“å—ä¸»è§‚åè§çš„å½±å“ï¼Œå¹¶ä¸”åœ¨è·¨ä¸åŒç¼–ç¨‹è¯­è¨€æ—¶æ‰©å±•å’Œç»´æŠ¤æˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Seed-Coderï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºLLMç³»åˆ—ï¼ŒåŒ…æ‹¬åŸºç¡€ã€æŒ‡ä»¤å’Œæ¨ç†æ¨¡å‹ï¼Œå®¹é‡ä¸º8Bï¼Œæœ€å¤§é™åº¦åœ°å‡å°‘äººç±»å‚ä¸æ•°æ®æ„å»ºã€‚æˆ‘ä»¬çš„ä»£ç é¢„è®­ç»ƒæ•°æ®æ˜¯ç”±ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç®¡é“ç”Ÿæˆçš„ï¼Œè¯¥ç®¡é“ä¸»è¦åˆ©ç”¨LLMè¿›è¡Œè¯„åˆ†å’Œè¿‡æ»¤ä»£ç æ•°æ®ã€‚æŒ‡ä»¤æ¨¡å‹é€šè¿‡ç›‘ç£å¾®è°ƒåå¥½ä¼˜åŒ–è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒï¼Œè€Œæ¨ç†æ¨¡å‹åˆ™åˆ©ç”¨é•¿é“¾æ€ç»´ï¼ˆLongCoTï¼‰å¼ºåŒ–å­¦ä¹ æ¥æé«˜å¤šæ­¥éª¤ä»£ç æ¨ç†èƒ½åŠ›ã€‚Seed-Coderåœ¨ç±»ä¼¼è§„æ¨¡çš„å¼€æºæ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æˆæœï¼Œç”šè‡³è¶…è¶Šäº†æŸäº›æ›´å¤§çš„æ¨¡å‹ï¼Œåœ¨ä»£ç ç”Ÿæˆã€ä»£ç è¡¥å…¨ã€ä»£ç ç¼–è¾‘ã€ä»£ç æ¨ç†å’Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03524v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒä¸­çš„ä»£ç æ•°æ®å¯¹äºä»£ç ç›¸å…³ä»»åŠ¡ä»¥åŠå¢å¼ºLLMçš„é€šç”¨æ™ºèƒ½è‡³å…³é‡è¦ã€‚å½“å‰å¼€æºLLMå¾€å¾€ä¾èµ–äººå·¥æ¥ç”Ÿæˆä»£ç é¢„è®­ç»ƒæ•°æ®ï¼Œå¦‚é’ˆå¯¹ä¸ªåˆ«ç¼–ç¨‹è¯­è¨€å®šåˆ¶çš„æ‰‹åŠ¨è¿‡æ»¤è§„åˆ™æˆ–ä½¿ç”¨äººå·¥æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒè´¨é‡è¿‡æ»¤å™¨ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨å¯æ‰©å±•æ€§ä½ã€æ˜“å¼•å…¥ä¸»è§‚åè§ä»¥åŠè·¨å¤šç§ç¼–ç¨‹è¯­è¨€ç»´æŠ¤å’Œæ‰©å±•æˆæœ¬é«˜æ˜‚ç­‰å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºSeed-Coderç³»åˆ—å¼€æºLLMï¼ŒåŒ…æ‹¬åŸºç¡€ã€æŒ‡ä»¤å’Œæ¨ç†æ¨¡å‹ï¼Œè§„æ¨¡å‡ä¸º8Bï¼Œæœ€å°åŒ–æ•°æ®æ„å»ºä¸­çš„äººä¸ºå¹²é¢„ã€‚å…¶ä»£ç é¢„è®­ç»ƒæ•°æ®ä¸»è¦ç”±ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç®¡é“ç”Ÿæˆï¼Œä¸»è¦åˆ©ç”¨LLMè¿›è¡Œè¯„åˆ†å’Œè¿‡æ»¤ã€‚æŒ‡ä»¤æ¨¡å‹é€šè¿‡ç›‘ç£å¾®è°ƒä¸åå¥½ä¼˜åŒ–è¿›è¡Œè®­ç»ƒï¼Œè€Œæ¨ç†æ¨¡å‹åˆ™åˆ©ç”¨é•¿é“¾æ€ç»´å¼ºåŒ–å­¦ä¹ æ¥æå‡å¤šæ­¥éª¤ä»£ç æ¨ç†èƒ½åŠ›ã€‚Seed-Coderåœ¨åŒç±»å¼€æºæ¨¡å‹ä¸­è¡¨ç°é¢†å…ˆï¼Œç”šè‡³åœ¨æŸäº›ä»»åŠ¡ä¸Šè¶…è¿‡äº†éƒ¨åˆ†æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ï¼Œåœ¨ä»£ç ç”Ÿæˆã€ä»£ç è¡¥å…¨ã€ä»£ç ç¼–è¾‘ã€ä»£ç æ¨ç†å’Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»£ç æ•°æ®åœ¨LLMé¢„è®­ç»ƒä¸­çš„é‡è¦æ€§ï¼šä¸ä»…å¯¹äºä»£ç ç›¸å…³ä»»åŠ¡å…³é”®ï¼Œè€Œä¸”æœ‰åŠ©äºå¢å¼ºLLMçš„é€šç”¨æ™ºèƒ½ã€‚</li>
<li>å½“å‰ä¾èµ–äººå·¥ç”Ÿæˆä»£ç é¢„è®­ç»ƒæ•°æ®çš„å±€é™æ€§ï¼šåŒ…æ‹¬å¯æ‰©å±•æ€§ä½ã€ä¸»è§‚åè§ä»¥åŠé«˜ç»´æŠ¤æˆæœ¬ã€‚</li>
<li>Seed-Coderçš„ç‰¹ç‚¹ï¼šå¼€æºLLMç³»åˆ—ï¼ŒåŒ…æ‹¬åŸºç¡€ã€æŒ‡ä»¤å’Œæ¨ç†æ¨¡å‹ï¼Œæœ€å°åŒ–æ•°æ®æ„å»ºä¸­çš„äººä¸ºå¹²é¢„ã€‚</li>
<li>æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼šä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç®¡é“ï¼Œä¸»è¦åˆ©ç”¨LLMè¿›è¡Œè¯„åˆ†å’Œè¿‡æ»¤ã€‚</li>
<li>æŒ‡ä»¤æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼šé€šè¿‡ç›‘ç£å¾®è°ƒä¸åå¥½ä¼˜åŒ–è¿›è¡Œè®­ç»ƒã€‚</li>
<li>æ¨ç†æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ åº”ç”¨ï¼šåˆ©ç”¨é•¿é“¾æ€ç»´å¼ºåŒ–å­¦ä¹ æå‡å¤šæ­¥éª¤ä»£ç æ¨ç†èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03524">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4379a53db1d9bc9453bc88ed4710a98c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be7c7e32a984f802ef4bc7107440d683.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ProRank-Prompt-Warmup-via-Reinforcement-Learning-for-Small-Language-Models-Reranking"><a href="#ProRank-Prompt-Warmup-via-Reinforcement-Learning-for-Small-Language-Models-Reranking" class="headerlink" title="ProRank: Prompt Warmup via Reinforcement Learning for Small Language   Models Reranking"></a>ProRank: Prompt Warmup via Reinforcement Learning for Small Language   Models Reranking</h2><p><strong>Authors:Xianming Li, Aamir Shakir, Rui Huang, Julius Lipp, Jing Li</strong></p>
<p>Reranking is fundamental to information retrieval and retrieval-augmented generation, with recent Large Language Models (LLMs) significantly advancing reranking quality. While recent advances with LLMs have significantly improved document reranking quality, current approaches primarily rely on large-scale LLMs (&gt;7B parameters) through zero-shot prompting, presenting high computational costs. Small Language Models (SLMs) offer a promising alternative because of their efficiency, but our preliminary quantitative analysis reveals they struggle with understanding task prompts without fine-tuning. This limits their effectiveness for document reranking tasks. To address this issue, we introduce a novel two-stage training approach, ProRank, for SLM-based document reranking. First, we propose a prompt warmup stage using reinforcement learning GRPO to steer SLMs to understand task prompts and generate more accurate coarse-grained binary relevance scores for document reranking. Then, we continuously fine-tune the SLMs with a fine-grained score learning stage without introducing additional layers to further improve the reranking quality. Comprehensive experimental results demonstrate that the proposed ProRank consistently outperforms both the most advanced open-source and proprietary reranking models. Notably, our lightweight ProRank-0.5B model even surpasses the powerful 32B LLM reranking model on the BEIR benchmark, establishing that properly trained SLMs can achieve superior document reranking performance while maintaining computational efficiency. </p>
<blockquote>
<p>é‡æ’åºåœ¨ä¿¡æ¯æ£€ç´¢å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆä¸­èµ·ç€æ ¹æœ¬æ€§çš„ä½œç”¨ï¼Œæœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¾è‘—åœ°æ¨åŠ¨äº†é‡æ’åºè´¨é‡çš„æå‡ã€‚å°½ç®¡ä½¿ç”¨LLMçš„æœ€æ–°è¿›å±•æ˜¾è‘—æé«˜äº†æ–‡æ¡£é‡æ’åºçš„è´¨é‡ï¼Œä½†å½“å‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå¤§è§„æ¨¡LLMï¼ˆå…·æœ‰è¶…è¿‡7äº¿ä¸ªå‚æ•°ï¼‰é€šè¿‡é›¶æ ·æœ¬æç¤ºæ¥å®ç°ï¼Œè¿™å¸¦æ¥äº†è¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰å› å…¶æ•ˆç‡è€Œæˆä¸ºä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†æˆ‘ä»¬çš„åˆæ­¥å®šé‡åˆ†æè¡¨æ˜ï¼Œå®ƒä»¬åœ¨ç†è§£ä»»åŠ¡æç¤ºæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œé™¤éè¿›è¡Œå¾®è°ƒã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ–‡æ¡£é‡æ’åºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºSLMæ–‡æ¡£é‡æ’åºçš„æ–°å‹ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•ProRankã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å¼ºåŒ–å­¦ä¹ GRPOçš„æç¤ºé¢„çƒ­é˜¶æ®µï¼Œä»¥å¼•å¯¼SLMç†è§£ä»»åŠ¡æç¤ºå¹¶ä¸ºæ–‡æ¡£é‡æ’åºç”Ÿæˆæ›´å‡†ç¡®çš„ç²—ç•¥äºŒå…ƒç›¸å…³æ€§åˆ†æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨ä¸å¼•å…¥é¢å¤–å±‚çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç²¾ç»†ç²’åº¦çš„åˆ†æ•°å­¦ä¹ é˜¶æ®µæŒç»­å¾®è°ƒSLMï¼Œä»¥è¿›ä¸€æ­¥æé«˜é‡æ’åºè´¨é‡ã€‚å…¨é¢çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºProRankæŒç»­ä¼˜äºæœ€å…ˆè¿›çš„å¼€æºå’Œä¸“æœ‰é‡æ’åºæ¨¡å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è½»é‡çº§çš„ProRank-0.5Bæ¨¡å‹ç”šè‡³åœ¨BEIRåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å¼ºå¤§çš„32B LLMé‡æ’åºæ¨¡å‹ï¼Œè¯æ˜äº†ç»è¿‡é€‚å½“è®­ç»ƒçš„å°å‹è¯­è¨€æ¨¡å‹å¯ä»¥åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å®ç°å“è¶Šçš„æ–‡æ¡£é‡æ’åºæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03487v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¿¡æ¯æ£€ç´¢å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„é‡æ’æŠ€æœ¯ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é‡æ’è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬çš„é«˜è®¡ç®—æˆæœ¬é™åˆ¶äº†å®é™…åº”ç”¨ã€‚ä¸ºè§£å†³å°è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰åœ¨ä»»åŠ¡æç¤ºç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µè®­ç»ƒæ³•â€”â€”ProRankã€‚åˆæ­¥å®éªŒè¡¨æ˜ï¼ŒProRankåœ¨æ–‡æ¡£é‡æ’ä»»åŠ¡ä¸Šè¡¨ç°å“è¶Šï¼Œå°¤å…¶æ˜¯è½»é‡åŒ–æ¨¡å‹ProRank-0.5Bï¼Œåœ¨BEIRåŸºå‡†æµ‹è¯•ä¸­ç”šè‡³è¶…è¶Šäº†å¼ºå¤§çš„32B LLMé‡æ’æ¨¡å‹ï¼Œå®ç°äº†è®¡ç®—æ•ˆç‡ä¸æ€§èƒ½çš„åŒé‡ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¿¡æ¯æ£€ç´¢å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„é‡æ’æŠ€æœ¯è‡³å…³é‡è¦ï¼Œè¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ­¤é¢†åŸŸå–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>è™½ç„¶LLMsæé«˜äº†æ–‡æ¡£é‡æ’è´¨é‡ï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬é™åˆ¶äº†å®é™…åº”ç”¨ã€‚</li>
<li>å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰å› é«˜æ•ˆæ€§æˆä¸ºæœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†åœ¨ä»»åŠ¡æç¤ºç†è§£æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µè®­ç»ƒæ³•â€”â€”ProRankï¼Œä»¥è§£å†³SLMsåœ¨æ–‡æ¡£é‡æ’ä»»åŠ¡ä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>ProRankåŒ…æ‹¬ä¸€ä¸ªæç¤ºé¢„çƒ­é˜¶æ®µï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ GRPOå¼•å¯¼SLMsç†è§£ä»»åŠ¡æç¤ºå¹¶ç”Ÿæˆæ›´å‡†ç¡®çš„ç²—ç²’åº¦äºŒè¿›åˆ¶ç›¸å…³æ€§å¾—åˆ†ã€‚</li>
<li>ProRanké€šè¿‡ç²¾ç»†ç²’åº¦çš„å¾—åˆ†å­¦ä¹ é˜¶æ®µæŒç»­å¾®è°ƒSLMsï¼Œè¿›ä¸€æ­¥æé«˜é‡æ’è´¨é‡ï¼Œä¸”æ— éœ€æ·»åŠ é¢å¤–å±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03487">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f23df72fefa065fce8000ae7780d35c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f8da151acc2c8ac886f030722e9c45f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a182cbc51dc0600bf9ec184a6fe1a9b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-148bdc9586e721684bb2d3bf3ca9af9d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Critique-GRPO-Advancing-LLM-Reasoning-with-Natural-Language-and-Numerical-Feedback"><a href="#Critique-GRPO-Advancing-LLM-Reasoning-with-Natural-Language-and-Numerical-Feedback" class="headerlink" title="Critique-GRPO: Advancing LLM Reasoning with Natural Language and   Numerical Feedback"></a>Critique-GRPO: Advancing LLM Reasoning with Natural Language and   Numerical Feedback</h2><p><strong>Authors:Xiaoying Zhang, Hao Sun, Yipeng Zhang, Kaituo Feng, Chaochao Lu, Chao Yang, Helen Meng</strong></p>
<p>Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly enhanced the complex reasoning capabilities of large language models (LLMs). Despite this success, we identify three key challenges encountered by RL with solely numerical feedback: performance plateaus, limited effectiveness of self-reflection, and persistent failures. We then demonstrate that RL-finetuned models, even after exhibiting performance plateaus, can generate correct refinements on persistently failed problems by leveraging natural language feedback in the form of critiques. Building on this insight, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for effective policy optimization. Critique-GRPO enables LLMs to learn from initial responses and critique-guided refinements simultaneously while maintaining exploration. Extensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that Critique-GRPO consistently outperforms supervised learning-based and RL-based fine-tuning approaches across eight challenging mathematical, STEM, and general reasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%, respectively. Notably, Critique-GRPO surpasses a strong baseline that incorporates expert demonstrations within online RL. Further analysis reveals two critical insights about policy exploration: (1) higher entropy does not always guarantee efficient learning from exploration, and (2) longer responses do not necessarily lead to more effective exploration. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å…·æœ‰æ•°å€¼åé¦ˆæ–¹é¢çš„è¿›å±•ï¼Œå¦‚æ ‡é‡å¥–åŠ±ï¼Œå·²ç»æ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä»…ä½¿ç”¨æ•°å€¼åé¦ˆçš„RLæ‰€é¢ä¸´çš„ä¸‰å¤§æŒ‘æˆ˜ï¼šæ€§èƒ½é«˜åŸæœŸã€è‡ªæˆ‘åæ€çš„å±€é™æ€§ä»¥åŠæŒç»­å¤±è´¥ã€‚æˆ‘ä»¬éšåè¯æ˜ï¼Œå³ä½¿åœ¨æ€§èƒ½é«˜åŸæœŸåï¼Œé€šè¿‡åˆ©ç”¨æ‰¹åˆ¤å½¢å¼çš„è‡ªç„¶è¯­è¨€åé¦ˆï¼ŒRLå¾®è°ƒæ¨¡å‹ä¹Ÿå¯ä»¥åœ¨æŒç»­å¤±è´¥çš„é—®é¢˜ä¸Šäº§ç”Ÿæ­£ç¡®çš„æ”¹è¿›ã€‚åŸºäºæ­¤è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†Critique-GRPOï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨çº¿RLæ¡†æ¶ï¼Œå®ƒç»“åˆäº†è‡ªç„¶è¯­è¨€åé¦ˆå’Œæ•°å€¼åé¦ˆæ¥è¿›è¡Œæœ‰æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ã€‚Critique-GRPOä½¿LLMèƒ½å¤ŸåŒæ—¶ä»åˆå§‹å“åº”å’Œæ‰¹åˆ¤æŒ‡å¯¼çš„æ”¹è¿›ä¸­å­¦ä¹ ï¼ŒåŒæ—¶ä¿æŒæ¢ç´¢ã€‚ä½¿ç”¨Qwen2.5-7B-Baseå’ŒQwen3-8B-Baseçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCritique-GRPOåœ¨å…«ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦ã€STEMå’Œä¸€èˆ¬æ¨ç†ä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºåŸºäºç›‘ç£å­¦ä¹ å’ŒRLçš„å¾®è°ƒæ–¹æ³•ï¼Œå¹³å‡pass@1å¾—åˆ†åˆ†åˆ«æé«˜äº†çº¦4.5%å’Œ5%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒCritique-GRPOè¶…è¶Šäº†ä¸€ä¸ªå¼ºå¤§çš„åŸºçº¿ï¼Œè¯¥åŸºçº¿ç»“åˆäº†åœ¨çº¿RLä¸­çš„ä¸“å®¶æ¼”ç¤ºã€‚è¿›ä¸€æ­¥çš„åˆ†ææ­ç¤ºäº†å…³äºç­–ç•¥æ¢ç´¢çš„ä¸¤ä¸ªå…³é”®è§è§£ï¼šï¼ˆ1ï¼‰é«˜ç†µå¹¶ä¸æ€»æ˜¯ä¿è¯ä»æ¢ç´¢ä¸­æœ‰æ•ˆåœ°å­¦ä¹ ï¼Œï¼ˆ2ï¼‰æ›´é•¿çš„å“åº”å¹¶ä¸ä¸€å®šèƒ½å¯¼è‡´æ›´æœ‰æ•ˆçš„æ¢ç´¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03106v2">PDF</a> 38 pages</p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æ•°å€¼åé¦ˆï¼ˆå¦‚æ ‡é‡å¥–åŠ±ï¼‰æ–¹é¢çš„æœ€æ–°è¿›å±•æ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ã€‚å³ä½¿æ€§èƒ½è¿›å…¥ç“¶é¢ˆæœŸï¼Œåˆ©ç”¨æ‰¹åˆ¤æ€§çš„è‡ªç„¶è¯­è¨€åé¦ˆï¼ŒRLå¾®è°ƒæ¨¡å‹ä»ç„¶èƒ½å¯¹æŒç»­å¤±è´¥çš„é—®é¢˜è¿›è¡Œæ­£ç¡®çš„æ”¹è¿›ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†ç»“åˆè‡ªç„¶è¯­è¨€ä¸æ•°å€¼åé¦ˆçš„åœ¨çº¿RLæ¡†æ¶â€”â€”Critique-GRPOï¼Œç”¨äºæœ‰æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ã€‚è¯¥æ¡†æ¶ä½¿LLMèƒ½å¤ŸåŒæ—¶ä»åˆæ­¥å“åº”å’Œæ‰¹åˆ¤æ€§æŒ‡å¯¼çš„æ”¹è¿›ä¸­å­¦ä¹ ï¼Œå¹¶ä¿æŒæ¢ç´¢ã€‚å®éªŒè¡¨æ˜ï¼ŒCritique-GRPOåœ¨å¤šä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºåŸºäºç›‘ç£å­¦ä¹ å’ŒRLçš„å¾®è°ƒæ–¹æ³•ï¼Œå¹³å‡é€šè¿‡ç‡æé«˜çº¦4.5%å’Œ5%ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°äº†å…³äºç­–ç•¥æ¢ç´¢çš„ä¸¤ä¸ªå…³é”®è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç»“åˆæ•°å€¼åé¦ˆæå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>å•çº¯ä¾èµ–æ•°å€¼åé¦ˆçš„RLé¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼šæ€§èƒ½ç“¶é¢ˆã€è‡ªæˆ‘åæ€çš„å±€é™æ€§ä»¥åŠæŒç»­å¤±è´¥çš„é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨æ‰¹åˆ¤æ€§çš„è‡ªç„¶è¯­è¨€åé¦ˆï¼ŒRLå¾®è°ƒæ¨¡å‹å¯ä»¥åœ¨æ€§èƒ½ç“¶é¢ˆæœŸåå¯¹æŒç»­å¤±è´¥çš„é—®é¢˜è¿›è¡Œæ­£ç¡®æ”¹è¿›ã€‚</li>
<li>æå‡ºçš„Critique-GRPOæ¡†æ¶ç»“åˆäº†è‡ªç„¶è¯­è¨€ä¸æ•°å€¼åé¦ˆï¼Œå®ç°æœ‰æ•ˆçš„ç­–ç•¥ä¼˜åŒ–ï¼Œä½¿LLMèƒ½ä»åˆæ­¥å“åº”å’Œæ‰¹åˆ¤æŒ‡å¯¼çš„æ”¹è¿›ä¸­å­¦ä¹ ã€‚</li>
<li>Critique-GRPOæ¡†æ¶åœ¨å¤šä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä¼˜äºç›‘ç£å­¦ä¹ å’ŒRLçš„å¾®è°ƒæ–¹æ³•ã€‚</li>
<li>é«˜ç†µä¸ä¸€å®šèƒ½ä¿è¯ä»æ¢ç´¢ä¸­é«˜æ•ˆå­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03106">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3a2ff486d67de9c2ce78be24eb75b9cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c98186d07317f4fdd65e7f80dfc47fca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-746679213523921763c70312f3a76f46.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-237e1b794a8c4695c7c5052ec050975a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0cd6f4f7786fbac2184a06729eae2e87.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="BitBypass-A-New-Direction-in-Jailbreaking-Aligned-Large-Language-Models-with-Bitstream-Camouflage"><a href="#BitBypass-A-New-Direction-in-Jailbreaking-Aligned-Large-Language-Models-with-Bitstream-Camouflage" class="headerlink" title="BitBypass: A New Direction in Jailbreaking Aligned Large Language Models   with Bitstream Camouflage"></a>BitBypass: A New Direction in Jailbreaking Aligned Large Language Models   with Bitstream Camouflage</h2><p><strong>Authors:Kalyan Nakka, Nitesh Saxena</strong></p>
<p>The inherent risk of generating harmful and unsafe content by Large Language Models (LLMs), has highlighted the need for their safety alignment. Various techniques like supervised fine-tuning, reinforcement learning from human feedback, and red-teaming were developed for ensuring the safety alignment of LLMs. However, the robustness of these aligned LLMs is always challenged by adversarial attacks that exploit unexplored and underlying vulnerabilities of the safety alignment. In this paper, we develop a novel black-box jailbreak attack, called BitBypass, that leverages hyphen-separated bitstream camouflage for jailbreaking aligned LLMs. This represents a new direction in jailbreaking by exploiting fundamental information representation of data as continuous bits, rather than leveraging prompt engineering or adversarial manipulations. Our evaluation of five state-of-the-art LLMs, namely GPT-4o, Gemini 1.5, Claude 3.5, Llama 3.1, and Mixtral, in adversarial perspective, revealed the capabilities of BitBypass in bypassing their safety alignment and tricking them into generating harmful and unsafe content. Further, we observed that BitBypass outperforms several state-of-the-art jailbreak attacks in terms of stealthiness and attack success. Overall, these results highlights the effectiveness and efficiency of BitBypass in jailbreaking these state-of-the-art LLMs. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆæœ‰å®³å’Œä¸å®‰å…¨å†…å®¹çš„å›ºæœ‰é£é™©ï¼Œå‡¸æ˜¾äº†å¯¹å®‰å…¨å¯¹é½çš„éœ€æ±‚ã€‚ä¸ºäº†ç¡®ä¿LLMsçš„å®‰å…¨å¯¹é½ï¼Œå¼€å‘äº†å„ç§æŠ€æœ¯ï¼Œå¦‚ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆå’Œå›¢é˜Ÿåä½œã€‚ç„¶è€Œï¼Œè¿™äº›å¯¹é½çš„LLMsçš„ç¨³å¥æ€§æ€»æ˜¯å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„å¨èƒï¼Œè¿™äº›æ”»å‡»åˆ©ç”¨å®‰å…¨å¯¹é½çš„æœªæ¢ç´¢å’Œæ½œåœ¨æ¼æ´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°å‹çš„é»‘ç›’è¶Šç‹±æ”»å‡»ï¼Œç§°ä¸ºBitBypassï¼Œå®ƒåˆ©ç”¨è¿å­—ç¬¦åˆ†éš”çš„æ¯”ç‰¹æµä¼ªè£…æ¥çªç ´å¯¹é½çš„LLMsã€‚è¿™ä»£è¡¨äº†ä¸€ç§æ–°çš„è¶Šç‹±æ–¹å‘ï¼Œå®ƒé€šè¿‡åˆ©ç”¨æ•°æ®çš„åŸºæœ¬ä¿¡æ¯è¡¨ç¤ºä½œä¸ºè¿ç»­çš„æ¯”ç‰¹æµæ¥çªç ´ï¼Œè€Œä¸æ˜¯ä¾é æç¤ºå·¥ç¨‹æˆ–å¯¹æŠ—æ€§æ“çºµã€‚æˆ‘ä»¬å¯¹äº”ä¸ªæœ€å…ˆè¿›çš„LLMsï¼Œå³GPT-4oã€åŒå­åº§1.5ã€å…‹åŠ³å¾·3.5ã€ç¾Šé©¼é©¼å¼å¦å…‹åˆ—è½¦é«˜é€Ÿèˆ¹æåœ°è£…ç”²è¿å…µè½¦V6åŒ—æå·å’ŒMixtralï¼Œä»å¯¹æŠ—æ€§è§’åº¦è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°BitBypassç»•è¿‡å…¶å®‰å…¨å¯¹é½å¹¶è¯±éª—å®ƒä»¬ç”Ÿæˆæœ‰å®³å’Œä¸å®‰å…¨å†…å®¹çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°BitBypassåœ¨éšè”½æ€§å’Œæ”»å‡»æˆåŠŸç‡æ–¹é¢ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„è¶Šç‹±æ”»å‡»ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›ç»“æœçªå‡ºäº†BitBypassåœ¨çªç ´è¿™äº›æœ€å…ˆè¿›çš„LLMsæ–¹é¢çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02479v1">PDF</a> 24 pages, 24 figures, and 7 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆæœ‰å®³å’Œä¸å®‰å…¨å†…å®¹çš„å›ºæœ‰é£é™©ï¼Œçªæ˜¾äº†å¯¹å®‰å…¨å¯¹é½çš„éœ€æ±‚ã€‚ä¸ºç¡®ä¿LLMsçš„å®‰å…¨å¯¹é½ï¼Œå¼€å‘äº†å„ç§æŠ€æœ¯ï¼Œå¦‚ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆå’Œå›¢é˜Ÿåä½œã€‚ç„¶è€Œï¼Œè¿™äº›å¯¹é½çš„LLMsçš„ç¨³å¥æ€§æ€»æ˜¯å—åˆ°æŒ‘æˆ˜ï¼Œå› ä¸ºå¯¹æŠ—æ€§æ”»å‡»ä¼šåˆ©ç”¨å°šæœªè¢«å‘ç°çš„åŸºç¡€è„†å¼±æ€§ã€‚æœ¬æ–‡å¼€å‘äº†ä¸€ç§æ–°å‹çš„é»‘ç›’è¶Šç‹±æ”»å‡»BitBypassï¼Œåˆ©ç”¨è¿å­—ç¬¦åˆ†éš”çš„æ¯”ç‰¹æµä¼ªè£…æ¥è¿›è¡Œè¶Šç‹±ã€‚è¿™ä»£è¡¨äº†ä¸€ä¸ªæ–°æ–¹å‘ï¼Œå³é€šè¿‡åˆ©ç”¨æ•°æ®è¿ç»­ä½çš„åŸºæœ¬ä¿¡æ¯è¡¨ç¤ºè¿›è¡Œè¶Šç‹±ï¼Œè€Œä¸æ˜¯åˆ©ç”¨æç¤ºå·¥ç¨‹æˆ–å¯¹æŠ—æ€§æ“ä½œã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒBitBypassèƒ½å¤Ÿç»•è¿‡è¿™äº›æœ€å…ˆè¿›LLMsçš„å®‰å…¨å¯¹é½ï¼Œå¹¶æ¬ºéª—å®ƒä»¬ç”Ÿæˆæœ‰å®³å’Œä¸å®‰å…¨çš„å†…å®¹ã€‚æ€»çš„æ¥è¯´ï¼ŒBitBypassåœ¨è¶Šç‹±è¿™äº›æœ€å…ˆè¿›LLMsæ–¹é¢éå¸¸æœ‰æ•ˆå’Œé«˜æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆå†…å®¹æ–¹é¢å­˜åœ¨æ½œåœ¨é£é™©ï¼Œéœ€è¦ç¡®ä¿å®ƒä»¬çš„å®‰å…¨å¯¹é½ã€‚</li>
<li>ä¸ºç¡®ä¿LLMsçš„å®‰å…¨å¯¹é½ï¼Œå·²ç»å¼€å‘äº†å¤šç§æŠ€æœ¯ï¼Œå¦‚ç›‘ç£å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆç­‰ã€‚</li>
<li>å¯¹é½çš„LLMsçš„ç¨³å¥æ€§ä¼šå—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„æŒ‘æˆ˜ï¼Œè¿™äº›æ”»å‡»ä¼šåˆ©ç”¨å®‰å…¨å¯¹é½çš„æœªçŸ¥è„†å¼±æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹é»‘ç›’è¶Šç‹±æ”»å‡»BitBypassï¼Œå®ƒåˆ©ç”¨æ¯”ç‰¹æµä¼ªè£…æŠ€æœ¯ã€‚</li>
<li>BitBypassèƒ½å¤Ÿç»•è¿‡æœ€å…ˆè¿›LLMsçš„å®‰å…¨å¯¹é½ï¼Œå¹¶ä½¿å…¶ç”Ÿæˆæœ‰å®³å’Œä¸å®‰å…¨çš„å†…å®¹ã€‚</li>
<li>BitBypassç›¸æ¯”å…¶ä»–è¶Šç‹±æ”»å‡»å…·æœ‰æ›´é«˜çš„éšè”½æ€§å’Œæ”»å‡»æˆåŠŸç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02479">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bd3351db6828b954b1658017e1334ffd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-18291045573f242c8e91a096a841ea0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ca194c0f3117533d8d51364fb67c213.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efa09f9c7b89e1db1356b45efa28fa3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3763ebfab51fb320734a22b428629bcf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3be57f9151852718100d0c2b32fd7e4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-32653d88de4d79440da3b55279ad1f25.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RewardBench-2-Advancing-Reward-Model-Evaluation"><a href="#RewardBench-2-Advancing-Reward-Model-Evaluation" class="headerlink" title="RewardBench 2: Advancing Reward Model Evaluation"></a>RewardBench 2: Advancing Reward Model Evaluation</h2><p><strong>Authors:Saumya Malik, Valentina Pyatkin, Sander Land, Jacob Morrison, Noah A. Smith, Hannaneh Hajishirzi, Nathan Lambert</strong></p>
<p>Reward models are used throughout the post-training of language models to capture nuanced signals from preference data and provide a training target for optimization across instruction following, reasoning, safety, and more domains. The community has begun establishing best practices for evaluating reward models, from the development of benchmarks that test capabilities in specific skill areas to others that test agreement with human preferences. At the same time, progress in evaluation has not been mirrored by the effectiveness of reward models in downstream tasks â€“ simpler direct alignment algorithms are reported to work better in many cases. This paper introduces RewardBench 2, a new multi-skill reward modeling benchmark designed to bring new, challenging data for accuracy-based reward model evaluation â€“ models score about 20 points on average lower on RewardBench 2 compared to the first RewardBench â€“ while being highly correlated with downstream performance. Compared to most other benchmarks, RewardBench 2 sources new human prompts instead of existing prompts from downstream evaluations, facilitating more rigorous evaluation practices. In this paper, we describe our benchmark construction process and report how existing models perform on it, while quantifying how performance on the benchmark correlates with downstream use of the models in both inference-time scaling algorithms, like best-of-N sampling, and RLHF training algorithms like proximal policy optimization. </p>
<blockquote>
<p>å¥–åŠ±æ¨¡å‹è¢«å¹¿æ³›åº”ç”¨äºè¯­è¨€æ¨¡å‹çš„è®­ç»ƒåé˜¶æ®µï¼Œç”¨äºæ•æ‰åå¥½æ•°æ®çš„å¾®å¦™ä¿¡å·ï¼Œå¹¶ä¸ºæŒ‡ä»¤éµå¾ªã€æ¨ç†ã€å®‰å…¨ç­‰å¤šä¸ªé¢†åŸŸçš„ä¼˜åŒ–æä¾›è®­ç»ƒç›®æ ‡ã€‚ç¤¾åŒºå·²ç»å¼€å§‹å»ºç«‹è¯„ä¼°å¥–åŠ±æ¨¡å‹çš„æœ€ä½³å®è·µï¼Œä»å¼€å‘æµ‹è¯•ç‰¹å®šæŠ€èƒ½é¢†åŸŸèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•åˆ°æµ‹è¯•ä¸äººç±»åå¥½ä¸€è‡´æ€§çš„åŸºå‡†æµ‹è¯•ã€‚ä¸æ­¤åŒæ—¶ï¼Œè¯„ä¼°æ–¹é¢çš„è¿›å±•å¹¶æœªåæ˜ åœ¨å¥–åŠ±æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä¸Šâ€”â€”æ®æŠ¥é“ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ›´ç®€å•çš„ç›´æ¥å¯¹é½ç®—æ³•æ•ˆæœæ›´å¥½ã€‚æœ¬æ–‡ä»‹ç»äº†RewardBench 2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„å¤šæŠ€èƒ½å¥–åŠ±å»ºæ¨¡åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨å¸¦æ¥æ›´å…·æŒ‘æˆ˜æ€§æ•°æ®ä»¥å‡†ç¡®è¯„ä¼°å¥–åŠ±æ¨¡å‹â€”â€”ä¸ç¬¬ä¸€ä¸ªRewarBenchç›¸æ¯”ï¼Œæ¨¡å‹åœ¨RewardBench 2ä¸Šçš„å¾—åˆ†å¹³å‡ä½çº¦20åˆ†ï¼Œä½†å¥–åŠ±æ¨¡å‹ä¸ä¸‹æ¸¸æ€§èƒ½é«˜åº¦ç›¸å…³ã€‚ä¸å…¶ä»–å¤§å¤šæ•°åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒRewardBench 2æºè‡ªæ–°çš„äººç±»æç¤ºè€Œéæ¥è‡ªä¸‹æ¸¸è¯„ä¼°çš„ç°æœ‰æç¤ºï¼Œä»è€Œä¿ƒè¿›äº†æ›´ä¸¥æ ¼çš„è¯„ä¼°å®è·µã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ„å»ºè¿‡ç¨‹ï¼Œå¹¶æŠ¥å‘Šäº†ç°æœ‰æ¨¡å‹åœ¨å…¶ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶é‡åŒ–äº†è¯¥åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½å¦‚ä½•ä¸ä¸‹æ¸¸åœ¨æ¨ç†æ—¶é—´ç¼©æ”¾ç®—æ³•ï¼ˆå¦‚Né‡‡æœ€ä½³ç­–ç•¥ï¼‰å’ŒRLHFè®­ç»ƒç®—æ³•ï¼ˆå¦‚è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰ä¸­ä½¿ç”¨æ¨¡å‹çš„æ€§èƒ½ç›¸å…³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01937v1">PDF</a> Data, models, and leaderboard available at   <a target="_blank" rel="noopener" href="https://huggingface.co/collections/allenai/reward-bench-2-683d2612a4b3e38a3e53bb51">https://huggingface.co/collections/allenai/reward-bench-2-683d2612a4b3e38a3e53bb51</a></p>
<p><strong>Summary</strong>ï¼šè¯­è¨€æ¨¡å‹åè®­ç»ƒå¹¿æ³›åº”ç”¨å¥–åŠ±æ¨¡å‹ä»¥æ•æ‰åå¥½æ•°æ®ä¸­çš„å¾®å¦™ä¿¡å·ï¼Œå¹¶ä¸ºå…¶åœ¨æŒ‡ä»¤éµå¾ªã€æ¨ç†ã€å®‰å…¨ç­‰å¤šé¢†åŸŸçš„ä¼˜åŒ–æä¾›è®­ç»ƒç›®æ ‡ã€‚ç¤¾åŒºå¼€å§‹å»ºç«‹è¯„ä¼°å¥–åŠ±æ¨¡å‹çš„æœ€ä½³å®è·µï¼Œä»å¼€å‘ç‰¹å®šæŠ€èƒ½é¢†åŸŸçš„åŸºå‡†æµ‹è¯•åˆ°ä¸äººç±»åå¥½ä¸€è‡´çš„æµ‹è¯•ã€‚å°½ç®¡è¯„ä¼°æ–¹é¢å–å¾—è¿›å±•ï¼Œå¥–åŠ±æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å°šæœªå¾—åˆ°åæ˜ â€”â€”åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ›´ç®€å•çš„ç›´æ¥å¯¹é½ç®—æ³•è¡¨ç°æ›´å¥½ã€‚æœ¬æ–‡ä»‹ç»äº†RewardBench 2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„å¤šæŠ€èƒ½å¥–åŠ±å»ºæ¨¡åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨å¸¦æ¥å‡†ç¡®æ€§çš„æŒ‘æˆ˜æ•°æ®ä»¥è¯„ä¼°å¥–åŠ±æ¨¡å‹â€”â€”ä¸ç¬¬ä¸€ä¸ªRewardBenchç›¸æ¯”ï¼Œæ¨¡å‹å¾—åˆ†å¹³å‡ä½çº¦20åˆ†ï¼Œä½†ä¸ä¸‹æ¸¸æ€§èƒ½é«˜åº¦ç›¸å…³ã€‚ä¸å…¶ä»–å¤§å¤šæ•°åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒRewardBench 2ä»ä¸‹æ¸¸è¯„ä¼°ä¸­è·å–æ–°çš„äººç±»æç¤ºè€Œéç°æœ‰çš„æç¤ºï¼Œä»è€Œä¿ƒè¿›æ›´ä¸¥æ ¼çš„è¯„ä¼°å®è·µã€‚æœ¬æ–‡æè¿°äº†æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ„å»ºè¿‡ç¨‹å¹¶æŠ¥å‘Šç°æœ‰æ¨¡å‹åœ¨å…¶ä¸Šçš„è¡¨ç°ï¼ŒåŒæ—¶é‡åŒ–åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¸ä¸‹æ¸¸æ¨¡å‹ä½¿ç”¨ä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒ…æ‹¬æ¨ç†æ—¶é—´ç¼©æ”¾ç®—æ³•å’ŒRLHFè®­ç»ƒç®—æ³•ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¥–åŠ±æ¨¡å‹åœ¨æ•æ‰åå¥½æ•°æ®å¾®å¦™ä¿¡å·æ–¹é¢è¡¨ç°å‡ºé‡è¦ä½œç”¨ï¼Œå¹¶ä¸ºè¯­è¨€æ¨¡å‹çš„å¤šä¸ªé¢†åŸŸä¼˜åŒ–æä¾›ç›®æ ‡ã€‚</li>
<li>ç¤¾åŒºå·²ç»å»ºç«‹äº†è¯„ä¼°å¥–åŠ±æ¨¡å‹çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬ç‰¹å®šæŠ€èƒ½é¢†åŸŸçš„åŸºå‡†æµ‹è¯•å’Œä¸äººç±»åå¥½ä¸€è‡´çš„æµ‹è¯•ã€‚</li>
<li>RewardBench 2æ˜¯ä¸€ä¸ªæ–°çš„å¤šæŠ€èƒ½å¥–åŠ±å»ºæ¨¡åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„æ•°æ®ä»¥å‡†ç¡®è¯„ä¼°å¥–åŠ±æ¨¡å‹çš„è¡¨ç°ã€‚</li>
<li>ä¸å…ˆå‰çš„åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒRewardBench 2å…·æœ‰æ›´ä½çš„æ¨¡å‹å¹³å‡å¾—åˆ†ï¼Œä½†é«˜åº¦ç›¸å…³äºä¸‹æ¸¸æ€§èƒ½ã€‚</li>
<li>RewardBench 2é‡‡ç”¨æ–°çš„äººç±»æç¤ºï¼Œä¿ƒè¿›æ›´ä¸¥æ ¼çš„è¯„ä¼°å®è·µã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨RewardBench 2ä¸Šçš„è¡¨ç°æŠ¥å‘Šï¼Œä¸ºæ¨¡å‹æ€§èƒ½æä¾›é‡åŒ–æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01937">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-daaec118143ca2025d8c8f13884d0b4f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b99be67a4e619bf9dc087844d0eaa96.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b0e87f5585e08102d5cd41f835e751d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f38971472d30ca175a2da656b7f88a89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f10308a9959a031519939523479a14e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97bf26d30d599df49a9da22a5df867e5.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Reinforcement-Learning-Tuning-for-VideoLLMs-Reward-Design-and-Data-Efficiency"><a href="#Reinforcement-Learning-Tuning-for-VideoLLMs-Reward-Design-and-Data-Efficiency" class="headerlink" title="Reinforcement Learning Tuning for VideoLLMs: Reward Design and Data   Efficiency"></a>Reinforcement Learning Tuning for VideoLLMs: Reward Design and Data   Efficiency</h2><p><strong>Authors:Hongyu Li, Songhao Han, Yue Liao, Junfeng Luo, Jialin Gao, Shuicheng Yan, Si Liu</strong></p>
<p>Understanding real-world videos with complex semantics and long temporal dependencies remains a fundamental challenge in computer vision. Recent progress in multimodal large language models (MLLMs) has demonstrated strong capabilities in vision-language tasks, while reinforcement learning tuning (RLT) has further improved their reasoning abilities. In this work, we explore RLT as a post-training strategy to enhance the video-specific reasoning capabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO) framework, we propose a dual-reward formulation that supervises both semantic and temporal reasoning through discrete and continuous reward signals. To facilitate effective preference-based optimization, we introduce a variance-aware data selection strategy based on repeated inference to identify samples that provide informative learning signals. We evaluate our approach across eight representative video understanding tasks, including VideoQA, Temporal Video Grounding, and Grounded VideoQA. Our method consistently outperforms supervised fine-tuning and existing RLT baselines, achieving superior performance with significantly less training data. These results underscore the importance of reward design and data selection in advancing reasoning-centric video understanding with MLLMs. Notably, The initial code release (two months ago) has now been expanded with updates, including optimized reward mechanisms and additional datasets. The latest version is available at <a target="_blank" rel="noopener" href="https://github.com/appletea233/Temporal-R1">https://github.com/appletea233/Temporal-R1</a> . </p>
<blockquote>
<p>ç†è§£å’Œå¤„ç†çœŸå®ä¸–ç•Œä¸­çš„è§†é¢‘ï¼Œè¿™äº›è§†é¢‘å…·æœ‰å¤æ‚çš„è¯­ä¹‰å’Œé•¿æœŸæ—¶é—´ä¾èµ–æ€§ï¼Œä»ç„¶æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚è¿‘æœŸå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„èƒ½åŠ›ï¼Œè€Œå¼ºåŒ–å­¦ä¹ è°ƒä¼˜ï¼ˆRLTï¼‰åˆ™è¿›ä¸€æ­¥æé«˜äº†å®ƒä»¬çš„æ¨ç†èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†RLTä½œä¸ºä¸€ç§åè®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºMLLMsçš„è§†é¢‘ç‰¹å®šæ¨ç†èƒ½åŠ›ã€‚åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¡†æ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒå¥–åŠ±å…¬å¼ï¼Œé€šè¿‡ç¦»æ•£å’Œè¿ç»­å¥–åŠ±ä¿¡å·æ¥ç›‘ç£è¯­ä¹‰å’Œæ—¶é—´æ¨ç†ã€‚ä¸ºäº†ä¿ƒè¿›æœ‰æ•ˆçš„åŸºäºåå¥½çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºé‡å¤æ¨ç†çš„æ–¹å·®æ„ŸçŸ¥æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œä»¥è¯†åˆ«æä¾›ä¿¡æ¯ä¸°å¯Œå­¦ä¹ ä¿¡å·çš„æ ·æœ¬ã€‚æˆ‘ä»¬åœ¨å…«ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬è§†é¢‘é—®ç­”ï¼ˆVideoQAï¼‰ã€æ—¶é—´è§†é¢‘å®šä½ï¼ˆTemporal Video Groundingï¼‰å’ŒåŸºäºåœºæ™¯çš„è§†é¢‘é—®ç­”ï¼ˆGrounded VideoQAï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè¶…è¶Šç›‘ç£å¾®è°ƒï¼ˆsupervised fine-tuningï¼‰å’Œç°æœ‰RLTåŸºçº¿æ–¹æ³•çš„æ€§èƒ½ï¼Œä¸”åœ¨è®­ç»ƒæ•°æ®é‡è¾ƒå°çš„æƒ…å†µä¸‹ä¹Ÿè¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚è¿™äº›ç»“æœçªæ˜¾äº†å¥–åŠ±è®¾è®¡å’Œæ•°æ®é€‰æ‹©åœ¨åˆ©ç”¨MLLMsæ¨åŠ¨ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„è§†é¢‘ç†è§£ä¸­çš„é‡è¦æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåˆå§‹ä»£ç å‘å¸ƒï¼ˆä¸¤ä¸ªæœˆå‰ï¼‰ç°å·²æ›´æ–°æ‰©å±•ï¼ŒåŒ…æ‹¬ä¼˜åŒ–çš„å¥–åŠ±æœºåˆ¶å’Œé¢å¤–çš„æ•°æ®é›†ã€‚æœ€æ–°ç‰ˆæœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/appletea233/Temporal-R1%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/appletea233/Temporal-R1æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01908v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤šåª’ä½“æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£ä»»åŠ¡ä¸­å…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†ä»é¢ä¸´å¤„ç†å¤æ‚è¯­ä¹‰å’Œé•¿æœŸæ—¶é—´ä¾èµ–æ€§çš„æŒ‘æˆ˜ã€‚å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ï¼ˆRLTï¼‰å¯ä»¥æ”¹å–„å…¶æ¨ç†èƒ½åŠ›ã€‚æœ¬ç ”ç©¶æ¢ç´¢å°†RLTä½œä¸ºæé«˜MLLMsè§†é¢‘ç‰¹å®šæ¨ç†èƒ½åŠ›çš„åè®­ç»ƒç­–ç•¥ã€‚åŸºäºé›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¡†æ¶ï¼Œæå‡ºäº†ä¸€ç§åŒå¥–åŠ±å…¬å¼ï¼Œé€šè¿‡ç¦»æ•£å’Œè¿ç»­å¥–åŠ±ä¿¡å·ç›‘ç£è¯­ä¹‰å’Œæ—¶é—´æ¨ç†ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºé‡å¤æ¨ç†çš„æ–¹å·®æ„ŸçŸ¥æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œä»¥ä¿ƒè¿›æœ‰æ•ˆçš„åŸºäºåå¥½çš„ä¼˜åŒ–ï¼Œè¯†åˆ«æä¾›ä¿¡æ¯ä¸°å¯Œå­¦ä¹ ä¿¡å·çš„æ ·æœ¬ã€‚åœ¨å…«ä¸ªä»£è¡¨æ€§è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼ŒåŒ…æ‹¬VideoQAã€æ—¶é—´è§†é¢‘å®šä½ã€åŸºäºåœºæ™¯çš„è§†é¢‘é—®ç­”ç­‰ã€‚è¯¥æ–¹æ³•åœ¨è®­ç»ƒæ•°æ®è¾ƒå°‘çš„æƒ…å†µä¸‹è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚é‡è§†å¥–åŠ±æœºåˆ¶è®¾è®¡å’Œæ•°æ®é€‰æ‹©å¯¹æ¨è¿›ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„è§†é¢‘ç†è§£å…·æœ‰é‡è¦æ„ä¹‰ã€‚ç›®å‰è¯¥é¡¹ç›®å·²åœ¨GitHubä¸Šå‘å¸ƒæœ€æ–°ç‰ˆæœ¬ï¼Œåˆå§‹ä»£ç å·²å‘å¸ƒä¸¤ä¸ªæœˆä»¥ä¸Šï¼Œç°åœ¨å·²æ›´æ–°åŒ…æ‹¬ä¼˜åŒ–å¥–åŠ±æœºåˆ¶å’Œæ–°å¢æ•°æ®é›†ç­‰å†…å®¹ï¼š<a target="_blank" rel="noopener" href="https://github.com/appletea233/Temporal-R1">https://github.com/appletea233/Temporal-R1</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£ä¸­å±•ç°å¼ºå¤§èƒ½åŠ›ï¼Œä½†ä»é¢ä¸´å¤„ç†å¤æ‚è¯­ä¹‰å’Œé•¿æœŸæ—¶é—´ä¾èµ–æ€§çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ è°ƒä¼˜ï¼ˆRLTï¼‰èƒ½æœ‰æ•ˆæé«˜MLLMsçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨GRPOæ¡†æ¶å’ŒåŒå¥–åŠ±å…¬å¼ï¼Œé€šè¿‡ç¦»æ•£å’Œè¿ç»­å¥–åŠ±ä¿¡å·ä¿ƒè¿›è¯­ä¹‰å’Œæ—¶é—´æ¨ç†ã€‚</li>
<li>å¼•å…¥æ–¹å·®æ„ŸçŸ¥æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œä»¥æé«˜åŸºäºåå¥½çš„ä¼˜åŒ–æ•ˆæœã€‚</li>
<li>æ–¹æ³•åœ¨å¤šä¸ªä»£è¡¨æ€§è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶å½“è®­ç»ƒæ•°æ®æœ‰é™æ—¶ã€‚</li>
<li>å¥–åŠ±è®¾è®¡å’Œæ•°æ®é€‰æ‹©åœ¨æé«˜è§†é¢‘ç†è§£ä¸­èµ·å…³é”®ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01908">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9796382b979cdc7e41f24e2be78442f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60d343dfa3709220a33725cf97b73bc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72be766cf3890caaee31d9ac44935aa1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Analysis-of-LLM-Bias-Chinese-Propaganda-Anti-US-Sentiment-in-DeepSeek-R1-vs-ChatGPT-o3-mini-high"><a href="#Analysis-of-LLM-Bias-Chinese-Propaganda-Anti-US-Sentiment-in-DeepSeek-R1-vs-ChatGPT-o3-mini-high" class="headerlink" title="Analysis of LLM Bias (Chinese Propaganda &amp; Anti-US Sentiment) in   DeepSeek-R1 vs. ChatGPT o3-mini-high"></a>Analysis of LLM Bias (Chinese Propaganda &amp; Anti-US Sentiment) in   DeepSeek-R1 vs. ChatGPT o3-mini-high</h2><p><strong>Authors:PeiHsuan Huang, ZihWei Lin, Simon Imbot, WenCheng Fu, Ethan Tu</strong></p>
<p>Large language models (LLMs) increasingly shape public understanding and civic decisions, yet their ideological neutrality is a growing concern. While existing research has explored various forms of LLM bias, a direct, cross-lingual comparison of models with differing geopolitical alignments-specifically a PRC-system model versus a non-PRC counterpart-has been lacking. This study addresses this gap by systematically evaluating DeepSeek-R1 (PRC-aligned) against ChatGPT o3-mini-high (non-PRC) for Chinese-state propaganda and anti-U.S. sentiment. We developed a novel corpus of 1,200 de-contextualized, reasoning-oriented questions derived from Chinese-language news, presented in Simplified Chinese, Traditional Chinese, and English. Answers from both models (7,200 total) were assessed using a hybrid evaluation pipeline combining rubric-guided GPT-4o scoring with human annotation. Our findings reveal significant model-level and language-dependent biases. DeepSeek-R1 consistently exhibited substantially higher proportions of both propaganda and anti-U.S. bias compared to ChatGPT o3-mini-high, which remained largely free of anti-U.S. sentiment and showed lower propaganda levels. For DeepSeek-R1, Simplified Chinese queries elicited the highest bias rates; these diminished in Traditional Chinese and were nearly absent in English. Notably, DeepSeek-R1 occasionally responded in Simplified Chinese to Traditional Chinese queries and amplified existing PRC-aligned terms in its Chinese answers, demonstrating an â€œinvisible loudspeakerâ€ effect. Furthermore, such biases were not confined to overtly political topics but also permeated cultural and lifestyle content, particularly in DeepSeek-R1. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå½±å“å…¬ä¼—ç†è§£å’Œå…¬æ°‘å†³ç­–ï¼Œä½†å®ƒä»¬çš„ä¸­ç«‹æ€§æˆä¸ºäº†ä¸€ä¸ªæ—¥ç›Šå¢é•¿çš„æ‹…å¿§ã€‚è™½ç„¶ç°æœ‰ç ”ç©¶å·²ç»æ¢ç´¢äº†LLMåè§çš„å„ç§å½¢å¼ï¼Œä½†ç¼ºä¹å¯¹å…·æœ‰ä¸åŒåœ°ç¼˜æ”¿æ²»å¯¹é½æ¨¡å‹è¿›è¡Œç›´æ¥ã€è·¨è¯­è¨€çš„æ¯”è¾ƒï¼Œç‰¹åˆ«æ˜¯PRCç³»ç»Ÿæ¨¡å‹ä¸éPRCç³»ç»Ÿçš„å¯¹åº”æ¨¡å‹ä¹‹é—´çš„æ¯”è¾ƒã€‚æœ¬ç ”ç©¶é€šè¿‡ç³»ç»Ÿåœ°è¯„ä¼°DeepSeek-R1ï¼ˆPRCå¯¹é½ï¼‰ä¸ChatGPT o3-mini-highï¼ˆéPRCï¼‰è¿›è¡Œä¸­æ–‡å›½å®¶å®£ä¼ å’Œåç¾æƒ…ç»ªï¼Œæ¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç”±1200ä¸ªè„±ç¦»ä¸Šä¸‹æ–‡ã€ä»¥æ¨ç†ä¸ºå¯¼å‘çš„é—®é¢˜ç»„æˆçš„æ–°å‹è¯­æ–™åº“ï¼Œè¿™äº›é—®é¢˜æ¥è‡ªç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡å’Œè‹±æ–‡çš„æ–°é—»ã€‚é€šè¿‡ç»“åˆåŸºäºè§„åˆ™çš„GPT-4oè¯„åˆ†ä¸äººç±»æ³¨é‡Šçš„æ··åˆè¯„ä¼°ç®¡é“ï¼Œå¯¹è¿™ä¸¤ä¸ªæ¨¡å‹çš„ç­”æ¡ˆï¼ˆå…±7200ä¸ªï¼‰è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜å­˜åœ¨æ˜¾è‘—çš„æ¨¡å‹çº§åˆ«å’Œè¯­è¨€ä¾èµ–åè§ã€‚ä¸ChatGPT o3-mini-highç›¸æ¯”ï¼ŒDeepSeek-R1æŒç»­è¡¨ç°å‡ºæ›´é«˜æ¯”ä¾‹çš„å®£ä¼ å’Œåç¾åè§ï¼Œè€ŒChatGPT o3-mini-highåˆ™åŸºæœ¬ä¸å­˜åœ¨åç¾æƒ…ç»ªï¼Œå®£ä¼ æ°´å¹³ä¹Ÿè¾ƒä½ã€‚å¯¹äºDeepSeek-R1æ¥è¯´ï¼Œç®€ä½“ä¸­æ–‡æŸ¥è¯¢å¼•å‘çš„åè§ç‡æœ€é«˜ï¼›åœ¨ç¹ä½“ä¸­æ–‡ä¸­æœ‰æ‰€å‡å°‘ï¼Œè‹±æ–‡ä¸­å‡ ä¹ä¸å­˜åœ¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDeepSeek-R1æœ‰æ—¶ä¼šå¯¹ç¹ä½“ä¸­æ–‡æŸ¥è¯¢ä»¥ç®€ä½“ä¸­æ–‡å›åº”ï¼Œå¹¶åœ¨å…¶ä¸­ç­”æ¡ˆä¸­æ”¾å¤§ç°æœ‰PRCç›¸å…³æœ¯è¯­ï¼Œæ˜¾ç¤ºå‡ºä¸€ç§â€œéšå½¢æ‰¬å£°å™¨â€æ•ˆåº”ã€‚æ­¤å¤–ï¼Œè¿™ç§åè§ä¸ä»…é™äºæ˜æ˜¾çš„æ”¿æ²»è¯é¢˜ï¼Œä¹Ÿæ¸—é€åˆ°æ–‡åŒ–å’Œç”Ÿæ´»æ–¹å¼å†…å®¹ä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨DeepSeek-R1ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01814v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹å…¬ä¼—ç†è§£å’Œå…¬æ°‘å†³ç­–çš„å½±å“æ—¥ç›Šå¢å¤§ï¼Œä½†å…¶æ„è¯†å½¢æ€ä¸­ç«‹æ€§å¼•å‘å…³æ³¨ã€‚ç°æœ‰ç ”ç©¶å·²æ¢ç´¢äº†LLMçš„åè§å½¢å¼ï¼Œä½†ç¼ºä¹å¯¹ä¸åŒåœ°ç¼˜æ”¿æ²»å¯¹é½æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯PRCç³»ç»Ÿæ¨¡å‹ä¸éPRCæ¨¡å‹ï¼‰çš„ç›´æ¥è·¨è¯­è¨€æ¯”è¾ƒã€‚æœ¬ç ”ç©¶é€šè¿‡ç³»ç»Ÿè¯„ä¼°PRCå¯¹é½çš„DeepSeek-R1ä¸éPRCå¯¹é½çš„ChatGPT o3-mini-highï¼Œé’ˆå¯¹ä¸­æ–‡å›½å®¶å®£ä¼ å’Œåç¾æƒ…ç»ªè¿›è¡Œæ¯”è¾ƒã€‚ç ”ç©¶å‘ç°ï¼ŒDeepSeek-R1åœ¨å®£ä¼ å’Œåç¾åè§ä¸Šæ˜¾è‘—é«˜äºChatGPT o3-mini-highï¼Œè€ŒChatGPT o3-mini-highåœ¨åç¾æƒ…ç»ªå’Œå®£ä¼ æ°´å¹³ä¸Šè¾ƒä½ã€‚DeepSeek-R1åœ¨ç®€ä½“ä¸­æ–‡æŸ¥è¯¢ä¸Šå¼•å‘çš„åè§ç‡æœ€é«˜ï¼Œåœ¨ç¹ä½“ä¸­æ–‡ä¸­å‡å°‘ï¼Œåœ¨è‹±è¯­ä¸­å‡ ä¹ä¸å­˜åœ¨ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›åè§ä¸ä»…é™äºæ”¿æ²»è¯é¢˜ï¼Œä¹Ÿæ¸—é€åˆ°æ–‡åŒ–å’Œç”Ÿæ´»æ–¹å¼å†…å®¹ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å…¬ä¼—ç†è§£å’Œå†³ç­–ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å…¶æ„è¯†å½¢æ€ä¸­ç«‹æ€§å—åˆ°å…³æ³¨ã€‚</li>
<li>ç°æœ‰ç ”ç©¶å·²æ¢ç´¢LLMåè§ï¼Œä½†ç¼ºä¹å¯¹ä¸åŒåœ°ç¼˜æ”¿æ²»å¯¹é½æ¨¡å‹çš„è·¨è¯­è¨€æ¯”è¾ƒã€‚</li>
<li>DeepSeek-R1ï¼ˆPRCå¯¹é½ï¼‰åœ¨å®£ä¼ å’Œåç¾åè§ä¸Šæ˜¾è‘—é«˜äºChatGPT o3-mini-highï¼ˆéPRCå¯¹é½ï¼‰ã€‚</li>
<li>DeepSeek-R1åœ¨ç®€ä½“ä¸­æ–‡æŸ¥è¯¢ä¸Šçš„åè§ç‡æœ€é«˜ï¼Œåœ¨ç¹ä½“ä¸­æ–‡å’Œè‹±è¯­ä¸­è¡¨ç°ä¸åŒã€‚</li>
<li>åè§ä¸ä»…é™äºæ”¿æ²»è¯é¢˜ï¼Œä¹Ÿæ¸—é€åˆ°æ–‡åŒ–å’Œç”Ÿæ´»æ–¹å¼å†…å®¹ä¸­ã€‚</li>
<li>DeepSeek-R1åœ¨å›åº”æŸäº›æŸ¥è¯¢æ—¶è¡¨ç°å‡ºâ€œéšå½¢æ‰¬å£°å™¨â€æ•ˆåº”ï¼Œå³æ”¾å¤§ç°æœ‰PRCå¯¹é½æœ¯è¯­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01814">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1026a8bd34fedaa0cd00e6ca0112d40c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-31593c9a93ac5fd04bd000716e4cef24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-441032e73d1a810be8de6d1d54759ff4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a321e6cb798ba4382a4ccead303cc739.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="SRPO-Enhancing-Multimodal-LLM-Reasoning-via-Reflection-Aware-Reinforcement-Learning"><a href="#SRPO-Enhancing-Multimodal-LLM-Reasoning-via-Reflection-Aware-Reinforcement-Learning" class="headerlink" title="SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware   Reinforcement Learning"></a>SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware   Reinforcement Learning</h2><p><strong>Authors:Zhongwei Wan, Zhihao Dou, Che Liu, Yu Zhang, Dongfei Cui, Qinjian Zhao, Hui Shen, Jing Xiong, Yi Xin, Yifan Jiang, Yangfan He, Mi Zhang, Shen Yan</strong></p>
<p>Multimodal large language models (MLLMs) have shown promising capabilities in reasoning tasks, yet still struggle with complex problems requiring explicit self-reflection and self-correction, especially compared to their unimodal text-based counterparts. Existing reflection methods are simplistic and struggle to generate meaningful and instructive feedback, as the reasoning ability and knowledge limits of pre-trained models are largely fixed during initial training. To overcome these challenges, we propose Multimodal Self-Reflection enhanced reasoning with Group Relative Policy Optimization (SRPO), a two-stage reflection-aware reinforcement learning (RL) framework explicitly designed to enhance multimodal LLM reasoning. In the first stage, we construct a high-quality, reflection-focused dataset under the guidance of an advanced MLLM, which generates reflections based on initial responses to help the policy model learn both reasoning and self-reflection. In the second stage, we introduce a novel reward mechanism within the GRPO framework that encourages concise and cognitively meaningful reflection while avoiding redundancy. Extensive experiments across multiple multimodal reasoning benchmarks, including MathVista, MathVision, MathVerse, and MMMU-Pro, using Qwen-2.5-VL-7B and Qwen-2.5-VL-32B demonstrate that SRPO significantly outperforms state-of-the-art models, achieving notable improvements in both reasoning accuracy and reflection quality. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰å‰æ™¯çš„èƒ½åŠ›ï¼Œä½†åœ¨éœ€è¦æ˜ç¡®çš„è‡ªæˆ‘åæ€å’Œè‡ªæˆ‘çº æ­£çš„å¤æ‚é—®é¢˜ä¸Šä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ä¸åŸºäºå•æ¨¡æ€æ–‡æœ¬çš„åŒç±»å‹æ¨¡å‹ç›¸æ¯”ã€‚ç°æœ‰çš„åæ€æ–¹æ³•è¿‡äºç®€å•ï¼Œéš¾ä»¥ç”Ÿæˆæœ‰æ„ä¹‰å’Œæœ‰ç›Šçš„åé¦ˆï¼Œå› ä¸ºé¢„è®­ç»ƒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†å±€é™åœ¨åˆå§‹è®­ç»ƒé˜¶æ®µå°±å·²ç»åŸºæœ¬å›ºå®šã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¤šæ¨¡æ€è‡ªæˆ‘åæ€å¢å¼ºæ¨ç†ï¼ˆSRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸¤é˜¶æ®µçš„åæ€å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºå¢å¼ºå¤šæ¨¡æ€LLMæ¨ç†èƒ½åŠ›è€Œè®¾è®¡ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬åœ¨å…ˆè¿›MLLMçš„æŒ‡å¯¼ä¸‹æ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„ä»¥åæ€ä¸ºé‡ç‚¹çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ ¹æ®åˆå§‹å“åº”ç”Ÿæˆåæ€ï¼Œä»¥å¸®åŠ©ç­–ç•¥æ¨¡å‹å­¦ä¹ æ¨ç†å’Œè‡ªåå°„ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬åœ¨GRPOæ¡†æ¶å†…å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„å¥–åŠ±æœºåˆ¶ï¼Œè¯¥æœºåˆ¶é¼“åŠ±ç®€æ´è€Œæœ‰è®¤çŸ¥æ„ä¹‰çš„åæ€ï¼ŒåŒæ—¶é¿å…å†—ä½™ã€‚åœ¨å¤šä¸ªå¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒï¼ŒåŒ…æ‹¬MathVistaã€Mathvisionã€MathVerseå’ŒMMMU-Proç­‰åŸºå‡†æµ‹è¯•ï¼Œä½¿ç”¨Qwen-2.5-VL-7Bå’ŒQwen-2.5-VL-32Bç­‰æ¨¡å‹æ˜¾ç¤ºï¼ŒSRPOæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œåœ¨æ¨ç†å‡†ç¡®æ€§å’Œåæ€è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01713v1">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>MLLMåœ¨æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†åœ¨éœ€è¦æ˜ç¡®è‡ªæˆ‘åæ€å’Œè‡ªæˆ‘çº æ­£çš„å¤æ‚é—®é¢˜ä¸Šä»æœ‰å›°éš¾ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†ç»“åˆå¤šæ¨¡æ€è‡ªæˆ‘åæ€ä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆSRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜MLLMçš„æ¨ç†èƒ½åŠ›ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œåˆ©ç”¨å…ˆè¿›çš„MLLMæ„å»ºé«˜è´¨é‡ã€ä»¥åæ€ä¸ºé‡ç‚¹çš„æ•°æ®é›†ï¼›ç¬¬äºŒé˜¶æ®µï¼Œå¼•å…¥æ–°çš„å¥–åŠ±æœºåˆ¶ï¼Œé¼“åŠ±ç®€æ´ã€è®¤çŸ¥æ„ä¹‰æ˜ç¡®çš„åæ€ã€‚å®éªŒè¯æ˜ï¼ŒSRPOåœ¨å¤šä¸ªå¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œæé«˜äº†æ¨ç†å‡†ç¡®æ€§å’Œåæ€è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MLLMsåœ¨å¤æ‚çš„éœ€è¦è‡ªæˆ‘åæ€å’Œçº æ­£çš„æ¨ç†é—®é¢˜ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰åæ€æ–¹æ³•ç®€å•ï¼Œéš¾ä»¥ç”Ÿæˆæœ‰æ„ä¹‰å’ŒæŒ‡å¯¼æ€§çš„åé¦ˆã€‚</li>
<li>æå‡ºç»“åˆå¤šæ¨¡æ€è‡ªæˆ‘åæ€ä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆSRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜MLLMçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µï¼šæ„å»ºé«˜è´¨é‡çš„åæ€æ•°æ®é›†ï¼Œå¸®åŠ©ç­–ç•¥æ¨¡å‹å­¦ä¹ æ¨ç†å’Œåæ€ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µï¼šå¼•å…¥æ–°çš„å¥–åŠ±æœºåˆ¶ï¼Œé¼“åŠ±ç®€æ´ä¸”è®¤çŸ¥æ„ä¹‰æ˜ç¡®çš„åæ€ã€‚</li>
<li>SRPOåœ¨å¤šä¸ªå¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæé«˜äº†æ¨ç†å‡†ç¡®æ€§å’Œåæ€è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01713">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bd260163d1e803a06030a300410808cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1392f37b8b9c73efb18996109003503.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a5ebc1463f20e9004f81dbacccd12bb.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Alignment-as-Distribution-Learning-Your-Preference-Model-is-Explicitly-a-Language-Model"><a href="#Alignment-as-Distribution-Learning-Your-Preference-Model-is-Explicitly-a-Language-Model" class="headerlink" title="Alignment as Distribution Learning: Your Preference Model is Explicitly   a Language Model"></a>Alignment as Distribution Learning: Your Preference Model is Explicitly   a Language Model</h2><p><strong>Authors:Jihun Yun, Juno Kim, Jongho Park, Junhyuck Kim, Jongha Jon Ryu, Jaewoong Cho, Kwang-Sung Jun</strong></p>
<p>Alignment via reinforcement learning from human feedback (RLHF) has become the dominant paradigm for controlling the quality of outputs from large language models (LLMs). However, when viewed as &#96;loss + regularization,â€™ the standard RLHF objective lacks theoretical justification and incentivizes degenerate, deterministic solutions, an issue that variants such as Direct Policy Optimization (DPO) also inherit. In this paper, we rethink alignment by framing it as \emph{distribution learning} from pairwise preference feedback by explicitly modeling how information about the target language model bleeds through the preference data. This explicit modeling leads us to propose three principled learning objectives: preference maximum likelihood estimation, preference distillation, and reverse KL minimization. We theoretically show that all three approaches enjoy strong non-asymptotic $O(1&#x2F;n)$ convergence to the target language model, naturally avoiding degeneracy and reward overfitting. Finally, we empirically demonstrate that our distribution learning framework, especially preference distillation, consistently outperforms or matches the performances of RLHF and DPO across various tasks and models. </p>
<blockquote>
<p>é€šè¿‡å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰è¿›è¡Œå¯¹é½å·²ç»æˆä¸ºæ§åˆ¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºè´¨é‡çš„ä¸»å¯¼èŒƒå¼ã€‚ç„¶è€Œï¼Œå½“è¢«è§†ä¸ºâ€œæŸå¤±+æ­£åˆ™åŒ–â€æ—¶ï¼Œæ ‡å‡†çš„RLHFç›®æ ‡ç¼ºä¹ç†è®ºæ”¯æŒï¼Œå¹¶æ¿€åŠ±é€€åŒ–ã€ç¡®å®šæ€§è§£å†³æ–¹æ¡ˆï¼Œè¿™ä¸€é—®é¢˜ä¹Ÿæ˜¯Direct Policy Optimizationï¼ˆDPOï¼‰ç­‰å˜ä½“æ‰€ç»§æ‰¿çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ˜ç¡®åœ°å»ºæ¨¡ç›®æ ‡è¯­è¨€æ¨¡å‹å¦‚ä½•é€è¿‡åå¥½æ•°æ®æ³„æ¼ä¿¡æ¯ï¼Œå°†å…¶é‡æ–°æ„æƒ³ä¸ºä»æˆå¯¹åå¥½åé¦ˆè¿›è¡Œçš„â€œåˆ†å¸ƒå­¦ä¹ â€ã€‚è¿™ç§æ˜ç¡®çš„å»ºæ¨¡ä½¿æˆ‘ä»¬æå‡ºä¸‰ç§åŸåˆ™æ€§çš„å­¦ä¹ ç›®æ ‡ï¼šåå¥½æœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€åå¥½è’¸é¦å’Œåå‘KLæœ€å°åŒ–ã€‚æˆ‘ä»¬ä»ç†è®ºä¸Šè¯æ˜ï¼Œæ‰€æœ‰ä¸‰ç§æ–¹æ³•éƒ½äº«æœ‰å¯¹ç›®æ ‡è¯­è¨€æ¨¡å‹çš„å¼ºéæ¸è¿‘O(1&#x2F;n)æ”¶æ•›æ€§ï¼Œè‡ªç„¶åœ°é¿å…äº†é€€åŒ–å’Œå¥–åŠ±è¿‡åº¦æ‹Ÿåˆã€‚æœ€åï¼Œæˆ‘ä»¬å®è¯è¡¨æ˜ï¼Œæˆ‘ä»¬çš„åˆ†å¸ƒå­¦ä¹ æ¡†æ¶ï¼Œå°¤å…¶æ˜¯åå¥½è’¸é¦ï¼Œåœ¨å„ç§ä»»åŠ¡å’Œæ¨¡å‹ä¸­å§‹ç»ˆä¼˜äºæˆ–åŒ¹é…RLHFå’ŒDPOçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01523v1">PDF</a> 26 pages, 7 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡é‡æ–°æ€è€ƒäº†é€šè¿‡å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰è¿›è¡Œå¯¹é½çš„æ–¹æ³•ï¼Œå°†å…¶é‡æ–°å®šä½ä¸ºåˆ†å¸ƒå­¦ä¹ ï¼ˆdistribution learningï¼‰é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸‰ç§åŸºäºäººç±»åå¥½åé¦ˆçš„å­¦ä¹ ç›®æ ‡ï¼šåå¥½æœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€åå¥½è’¸é¦å’Œåå‘KLæœ€å°åŒ–ã€‚ç†è®ºåˆ†æå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ä¸‰ç§æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ”¶æ•›æ€§å’Œé¿å…é€€åŒ–é—®é¢˜çš„ä¼˜åŠ¿ï¼Œå¹¶ä¸”åœ¨å„ç§ä»»åŠ¡å’Œæ¨¡å‹ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLHFä½œä¸ºæ§åˆ¶å¤§å‹è¯­è¨€æ¨¡å‹è¾“å‡ºçš„ä¸»è¦æ–¹æ³•ï¼Œå­˜åœ¨ç†è®ºä¸Šçš„ä¸è¶³å’Œæ¿€åŠ±é€€åŒ–è§£å†³æ–¹æ¡ˆçš„é—®é¢˜ã€‚</li>
<li>åˆ†å¸ƒå­¦ä¹ æ¡†æ¶é‡æ–°æ€è€ƒäº†å¯¹é½é—®é¢˜ï¼Œé€šè¿‡æ˜ç¡®å»ºæ¨¡ç›®æ ‡è¯­è¨€æ¨¡å‹å¦‚ä½•é€è¿‡åå¥½æ•°æ®å‘ˆç°ã€‚</li>
<li>æå‡ºäº†ä¸‰ç§åŸºäºäººç±»åå¥½åé¦ˆçš„å­¦ä¹ ç›®æ ‡ï¼šåå¥½æœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€åå¥½è’¸é¦å’Œåå‘KLæœ€å°åŒ–ã€‚</li>
<li>è¿™ä¸‰ç§æ–¹æ³•å…·æœ‰ç†è®ºä¸Šçš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿè‡ªç„¶é¿å…é€€åŒ–å’Œå¥–åŠ±è¿‡åº¦æ‹Ÿåˆçš„é—®é¢˜ã€‚</li>
<li>è¿™äº›æ–¹æ³•åœ¨å„ç§ä»»åŠ¡å’Œæ¨¡å‹ä¸­çš„è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åå¥½è’¸é¦æ–¹æ³•ã€‚</li>
<li>åˆ†å¸ƒå­¦ä¹ æ¡†æ¶çš„ç†è®ºå’Œå®è¯åˆ†æä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥æ”¹è¿›æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01523">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7543c2523207b70515dd5530618d64b8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aac851f2e743bbbe8dc99bf8528716d5.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="ReFoCUS-Reinforcement-guided-Frame-Optimization-for-Contextual-Understanding"><a href="#ReFoCUS-Reinforcement-guided-Frame-Optimization-for-Contextual-Understanding" class="headerlink" title="ReFoCUS: Reinforcement-guided Frame Optimization for Contextual   Understanding"></a>ReFoCUS: Reinforcement-guided Frame Optimization for Contextual   Understanding</h2><p><strong>Authors:Hosu Lee, Junho Kim, Hyunjun Kim, Yong Man Ro</strong></p>
<p>Recent progress in Large Multi-modal Models (LMMs) has enabled effective vision-language reasoning, yet the ability to understand video content remains constrained by suboptimal frame selection strategies. Existing approaches often rely on static heuristics or external retrieval modules to feed frame information into video-LLMs, which may fail to provide the query-relevant information. In this work, we introduce ReFoCUS (Reinforcement-guided Frame Optimization for Contextual UnderStanding), a novel frame-level policy optimization framework that shifts the optimization target from textual responses to visual input selection. ReFoCUS learns a frame selection policy via reinforcement learning, using reward signals derived from a reference LMM to reflect the modelâ€™s intrinsic preferences for frames that best support temporally grounded responses. To efficiently explore the large combinatorial frame space, we employ an autoregressive, conditional selection architecture that ensures temporal coherence while reducing complexity. Our approach does not require explicit supervision at the frame-level and consistently improves reasoning performance across multiple video QA benchmarks, highlighting the benefits of aligning frame selection with model-internal utility. </p>
<blockquote>
<p>æœ€è¿‘å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰çš„è¿›å±•ä¸ºå®ç°æœ‰æ•ˆçš„è§†è§‰è¯­è¨€æ¨ç†æä¾›äº†å¯èƒ½ï¼Œä½†ç†è§£è§†é¢‘å†…å®¹çš„èƒ½åŠ›ä»ç„¶å—åˆ°æ¬¡ä¼˜å¸§é€‰æ‹©ç­–ç•¥çš„é™åˆ¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºé™æ€å¯å‘å¼æˆ–å¤–éƒ¨æ£€ç´¢æ¨¡å—å°†å¸§ä¿¡æ¯è¾“å…¥è§†é¢‘LLMä¸­ï¼Œè¿™å¯èƒ½æ— æ³•æä¾›ä¸æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ReFoCUSï¼ˆç”¨äºä¸Šä¸‹æ–‡ç†è§£çš„å¼ºåŒ–å¼•å¯¼å¸§ä¼˜åŒ–ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„å¸§çº§ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒå°†ä¼˜åŒ–ç›®æ ‡ä»æ–‡æœ¬å“åº”è½¬ç§»åˆ°è§†è§‰è¾“å…¥é€‰æ‹©ã€‚ReFoCUSé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ å¸§é€‰æ‹©ç­–ç•¥ï¼Œä½¿ç”¨æ¥è‡ªå‚è€ƒLMMçš„å¥–åŠ±ä¿¡å·æ¥åæ˜ æ¨¡å‹å¯¹äºæœ€èƒ½æ”¯æŒåŸºäºæ—¶é—´ç‚¹çš„å“åº”çš„å¸§çš„å†…åœ¨åå¥½ã€‚ä¸ºäº†æœ‰æ•ˆåœ°æ¢ç´¢å¤§å‹ç»„åˆå¸§ç©ºé—´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§è‡ªå›å½’æ¡ä»¶é€‰æ‹©æ¶æ„ï¼Œå®ƒåœ¨ç¡®ä¿æ—¶é—´è¿è´¯æ€§çš„åŒæ—¶é™ä½äº†å¤æ‚æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦åœ¨å¸§çº§åˆ«è¿›è¡Œæ˜¾å¼ç›‘ç£ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªè§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æŒç»­æé«˜äº†æ¨ç†æ€§èƒ½ï¼Œè¿™çªå‡ºäº†å°†å¸§é€‰æ‹©ä¸æ¨¡å‹å†…éƒ¨æ•ˆç”¨å¯¹é½æ‰€å¸¦æ¥çš„å¥½å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01274v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡ç« æ¢è®¨äº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨è§†é¢‘å†…å®¹ç†è§£æ–¹é¢çš„æ–°è¿›å±•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸­å¸§é€‰æ‹©ç­–ç•¥ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ReFoCUSæ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»¥æ”¯æŒæ—¶é—´å®šä½å“åº”çš„å¸§ä¸ºå¥–åŠ±ä¿¡å·ï¼Œæé«˜è§†é¢‘å†…å®¹çš„ç†è§£ã€‚è¯¥æ¡†æ¶é‡‡ç”¨æ¡ä»¶é€‰æ‹©æ¶æ„ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ï¼Œæ— éœ€æ˜¾å¼ç›‘ç£å³å¯å®ç°è·¨å¤šä¸ªè§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨è§†è§‰è¯­è¨€æ¨ç†æ–¹é¢å–å¾—äº†æœ‰æ•ˆè¿›å±•ï¼Œä½†åœ¨ç†è§£è§†é¢‘å†…å®¹æ–¹é¢ä»å­˜åœ¨å±€é™ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–é™æ€å¯å‘å¼æˆ–å¤–éƒ¨æ£€ç´¢æ¨¡å—å°†å¸§ä¿¡æ¯è¾“å…¥è§†é¢‘-LLMsï¼Œå¯èƒ½æ— æ³•æä¾›ä¸æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ã€‚</li>
<li>ReFoCUSæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»¥æ”¯æŒæ—¶é—´å®šä½å“åº”çš„å¸§ä¸ºå¥–åŠ±ä¿¡å·ã€‚</li>
<li>ReFoCUSæ¡†æ¶é‡‡ç”¨æ¡ä»¶é€‰æ‹©æ¶æ„ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ï¼Œå¹¶å‡å°‘å¤æ‚æ€§ã€‚</li>
<li>ReFoCUSæ¡†æ¶ä¸éœ€è¦æ˜¾å¼ç›‘ç£å³å¯å®ç°å¸§çº§åˆ«çš„ä¼˜åŒ–ã€‚</li>
<li>ReFoCUSæ¡†æ¶åœ¨å¤šä¸ªè§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b85735a84d3e07e4a1fccf445b16adbe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19f1fe0352289c247f933695239da194.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75295772766b332875dddf8b420b7803.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ecf94bfd4cf10ade65ec35f7b00d830.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Uni-LoRA-One-Vector-is-All-You-Need"><a href="#Uni-LoRA-One-Vector-is-All-You-Need" class="headerlink" title="Uni-LoRA: One Vector is All You Need"></a>Uni-LoRA: One Vector is All You Need</h2><p><strong>Authors:Kaiyang Li, Shaobo Han, Qing Su, Wei Li, Zhipeng Cai, Shihao Ji</strong></p>
<p>Low-Rank Adaptation (LoRA) has become the de facto parameter-efficient fine-tuning (PEFT) method for large language models (LLMs) by constraining weight updates to low-rank matrices. Recent works such as Tied-LoRA, VeRA, and VB-LoRA push efficiency further by introducing additional constraints to reduce the trainable parameter space. In this paper, we show that the parameter space reduction strategies employed by these LoRA variants can be formulated within a unified framework, Uni-LoRA, where the LoRA parameter space, flattened as a high-dimensional vector space $R^D$, can be reconstructed through a projection from a subspace R^d, with $d \ll D$. We demonstrate that the fundamental difference among various LoRA methods lies in the choice of the projection matrix, $P \in R^{D \times d}$.Most existing LoRA variants rely on layer-wise or structure-specific projections that limit cross-layer parameter sharing, thereby compromising parameter efficiency. In light of this, we introduce an efficient and theoretically grounded projection matrix that is isometric, enabling global parameter sharing and reducing computation overhead. Furthermore, under the unified view of Uni-LoRA, this design requires only a single trainable vector to reconstruct LoRA parameters for the entire LLM - making Uni-LoRA both a unified framework and a â€œone-vector-onlyâ€ solution. Extensive experiments on GLUE, mathematical reasoning, and instruction tuning benchmarks demonstrate that Uni-LoRA achieves state-of-the-art parameter efficiency while outperforming or matching prior approaches in predictive performance. </p>
<blockquote>
<p>Low-Rank Adaptationï¼ˆLoRAï¼‰é€šè¿‡çº¦æŸæƒé‡æ›´æ–°ä¸ºä½é˜¶çŸ©é˜µï¼Œå·²æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®é™…å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ã€‚æœ€è¿‘çš„å·¥ä½œï¼Œå¦‚Tied-LoRAã€VeRAå’ŒVB-LoRAï¼Œé€šè¿‡å¼•å…¥é¢å¤–çš„çº¦æŸæ¥å‡å°‘å¯è®­ç»ƒå‚æ•°ç©ºé—´ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™äº›LoRAå˜ä½“æ‰€é‡‡ç”¨çš„å‚æ•°ç©ºé—´å‡å°‘ç­–ç•¥å¯ä»¥åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶Uni-LoRAå†…åˆ¶å®šã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸­ï¼ŒLoRAå‚æ•°ç©ºé—´è¢«å±•å¹³ä¸ºä¸€ä¸ªé«˜ç»´å‘é‡ç©ºé—´RDï¼Œå¯ä»¥é€šè¿‡ä»å­ç©ºé—´Rdçš„æŠ•å½±è¿›è¡Œé‡å»ºï¼Œå…¶ä¸­dâ‰ªDã€‚æˆ‘ä»¬è¯æ˜ï¼Œå„ç§LoRAæ–¹æ³•ä¹‹é—´çš„æ ¹æœ¬åŒºåˆ«åœ¨äºæŠ•å½±çŸ©é˜µPâˆˆRDÃ—dçš„é€‰æ‹©ã€‚å¤§å¤šæ•°ç°æœ‰çš„LoRAå˜ä½“ä¾èµ–äºé€å±‚æˆ–ç»“æ„ç‰¹å®šçš„æŠ•å½±ï¼Œè¿™é™åˆ¶äº†è·¨å±‚å‚æ•°å…±äº«ï¼Œä»è€ŒæŸå®³äº†å‚æ•°æ•ˆç‡ã€‚é‰´äºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé«˜æ•ˆä¸”ç†è®ºä¸Šæœ‰æ ¹æ®çš„æŠ•å½±çŸ©é˜µï¼Œè¯¥çŸ©é˜µæ˜¯ç­‰è·çš„ï¼Œèƒ½å¤Ÿå®ç°å…¨å±€å‚æ•°å…±äº«ï¼Œå¹¶å‡å°‘è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œåœ¨Uni-LoRAçš„ç»Ÿä¸€è§‚ç‚¹ä¸‹ï¼Œè¿™ç§è®¾è®¡åªéœ€è¦ä¸€ä¸ªå¯è®­ç»ƒå‘é‡æ¥é‡å»ºæ•´ä¸ªLLMçš„LoRAå‚æ•°ï¼Œä½¿Uni-LoRAæ—¢æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªâ€œä»…ä¸€ä¸ªå‘é‡â€çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨GLUEã€æ•°å­¦æ¨ç†å’ŒæŒ‡ä»¤è°ƒæ•´åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒUni-LoRAåœ¨å‚æ•°æ•ˆç‡æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼ŒåŒæ—¶åœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¼˜äºæˆ–åŒ¹é…äº†å…ˆå‰çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00799v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>LoRAæ–¹æ³•é€šè¿‡çº¦æŸæƒé‡æ›´æ–°ä¸ºä½ç§©çŸ©é˜µï¼Œæˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹å‚æ•°æ•ˆç‡å¾®è°ƒçš„ä¸»æµæ–¹æ³•ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶Uni-LoRAï¼Œè¯¥æ¡†æ¶å¯ä»¥æ•´åˆå„ç§LoRAå˜ä½“æ‰€é‡‡ç”¨çš„å‚æ•°ç©ºé—´ç¼©å‡ç­–ç•¥ã€‚é€šè¿‡æŠ•å½±çŸ©é˜µPï¼Œå°†LoRAå‚æ•°ç©ºé—´ä»é«˜ç»´ç©ºé—´RDæŠ•å½±åˆ°å­ç©ºé—´Rdï¼Œå®ç°å‚æ•°ç©ºé—´çš„ä¼˜åŒ–ã€‚ç°æœ‰LoRAå˜ä½“é€šå¸¸é‡‡ç”¨å±‚çŠ¶æˆ–ç»“æ„ç‰¹å®šçš„æŠ•å½±æ–¹å¼ï¼Œé™åˆ¶äº†è·¨å±‚å‚æ•°å…±äº«ã€‚å› æ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§é«˜æ•ˆä¸”ç†è®ºåŸºç¡€çš„ç­‰è·æŠ•å½±çŸ©é˜µï¼Œå®ç°å…¨å±€å‚æ•°å…±äº«ï¼Œé™ä½è®¡ç®—å¼€é”€ã€‚åœ¨GLUEã€æ•°å­¦æ¨ç†å’ŒæŒ‡ä»¤è°ƒæ•´åŸºå‡†æµ‹è¯•ä¸­ï¼ŒUni-LoRAå±•ç°äº†å‡ºè‰²çš„å‚æ•°æ•ˆç‡å’Œé¢„æµ‹æ€§èƒ½ï¼Œè¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LoRAå·²æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å‚æ•°æ•ˆç‡å¾®è°ƒçš„ä¸»æµæ–¹æ³•ï¼Œé€šè¿‡çº¦æŸæƒé‡æ›´æ–°ä¸ºä½ç§©çŸ©é˜µã€‚</li>
<li>Uni-LoRAæ¡†æ¶æ•´åˆäº†å„ç±»LoRAå˜ä½“çš„å‚æ•°ç©ºé—´ç¼©å‡ç­–ç•¥ã€‚</li>
<li>LoRAå‚æ•°ç©ºé—´å¯é€šè¿‡æŠ•å½±çŸ©é˜µPä»é«˜ç»´ç©ºé—´æŠ•å½±åˆ°å­ç©ºé—´è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>ç°æœ‰LoRAå˜ä½“çš„æŠ•å½±æ–¹å¼é™åˆ¶äº†è·¨å±‚å‚æ•°å…±äº«ã€‚</li>
<li>å¼•å…¥çš„ç­‰è·æŠ•å½±çŸ©é˜µå®ç°å…¨å±€å‚æ•°å…±äº«ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚</li>
<li>Uni-LoRAåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œå‚æ•°æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fec179b52c23f621f191dca81375f039.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-17104c6a4aa5fb59b21febbd75c6223d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bcd5293f41acea7c2d74a45bda3bfc0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="QoQ-Med-Building-Multimodal-Clinical-Foundation-Models-with-Domain-Aware-GRPO-Training"><a href="#QoQ-Med-Building-Multimodal-Clinical-Foundation-Models-with-Domain-Aware-GRPO-Training" class="headerlink" title="QoQ-Med: Building Multimodal Clinical Foundation Models with   Domain-Aware GRPO Training"></a>QoQ-Med: Building Multimodal Clinical Foundation Models with   Domain-Aware GRPO Training</h2><p><strong>Authors:Wei Dai, Peilin Chen, Chanakya Ekbote, Paul Pu Liang</strong></p>
<p>Clinical decision-making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision-centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B&#x2F;32B, the first open generalist clinical foundation model that jointly reasons across medical images, time-series signals, and text reports. QoQ-Med is trained with Domain-aware Relative Policy Optimization (DRPO), a novel reinforcement-learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro-F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces at <a target="_blank" rel="noopener" href="https://github.com/DDVD233/QoQ_Med">https://github.com/DDVD233/QoQ_Med</a>. </p>
<blockquote>
<p>ä¸´åºŠå†³ç­–é€šå¸¸éœ€è¦å¯¹å¼‚è´¨æ•°æ®è¿›è¡Œæ¨ç†ï¼Œä½†ç°æœ‰çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä»ç„¶ä¸»è¦ä¾§é‡äºè§†è§‰ï¼Œä¸”æ— æ³•åœ¨ä¸´åºŠä¸“ç§‘ä¹‹é—´é€šç”¨åŒ–ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†QoQ-Med-7B&#x2F;32Bï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¼€æ”¾çš„é€šç”¨ä¸´åºŠåŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿè”åˆå¯¹åŒ»å­¦å›¾åƒã€æ—¶é—´åºåˆ—ä¿¡å·å’Œæ–‡æœ¬æŠ¥å‘Šè¿›è¡Œæ¨ç†ã€‚QoQ-Medé‡‡ç”¨é¢†åŸŸæ„ŸçŸ¥ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDRPOï¼‰è¿›è¡Œè®­ç»ƒï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼ŒæŒ‰é¢†åŸŸç¨€æœ‰æ€§å’Œæ¨¡æ€éš¾åº¦åˆ†å±‚ç¼©æ”¾æ ‡å‡†åŒ–å¥–åŠ±ï¼Œç¼“è§£ç”±ä¸´åºŠæ•°æ®åˆ†å¸ƒä¸å‡å¯¼è‡´æ€§èƒ½ä¸å¹³è¡¡çš„é—®é¢˜ã€‚åœ¨æ¶µç›–9ä¸ªä¸´åºŠé¢†åŸŸçš„261ä¸‡ä¸ªæŒ‡ä»¤è°ƒæ•´å¯¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬è¯æ˜ï¼Œä¸GRPOç­‰å…¶ä»–æ— æ‰¹è¯„è®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒDRPOè®­ç»ƒåœ¨æé«˜æ‰€æœ‰è§†è§‰é¢†åŸŸçš„å®è§‚F1åˆ†æ•°æ–¹é¢å¹³å‡æé«˜äº†43%çš„è¯Šæ–­æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒQoQ-Medç»è¿‡å¯†é›†åˆ†å‰²æ•°æ®è®­ç»ƒåï¼Œèƒ½å¤Ÿçªå‡ºä¸è¯Šæ–­ç›¸å…³çš„å…³é”®åŒºåŸŸï¼Œå…¶IoUå€¼æ¯”å¼€æ”¾æ¨¡å‹é«˜10å€ï¼ŒåŒæ—¶è¾¾åˆ°OpenAI o4-miniçš„æ€§èƒ½æ°´å¹³ã€‚ä¸ºäº†ä¿ƒè¿›å¯é‡å¤æ€§å’Œä¸‹æ¸¸ç ”ç©¶ï¼Œæˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/DDVD233/QoQ_Med">https://github.com/DDVD233/QoQ_Med</a>ä¸Šå‘å¸ƒäº†ï¼ˆiï¼‰å®Œæ•´æ¨¡å‹æƒé‡ã€ï¼ˆiiï¼‰æ¨¡å—åŒ–è®­ç»ƒç®¡é“å’Œï¼ˆiiiï¼‰æ‰€æœ‰ä¸­é—´æ¨ç†è½¨è¿¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00711v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºä¸´åºŠå†³ç­–éœ€è¦å¤„ç†å¼‚è´¨æ•°æ®çš„å¸¸è§„éœ€æ±‚ï¼Œç°æœ‰çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸»è¦é›†ä¸­åœ¨è§†è§‰é¢†åŸŸï¼Œä¸”éš¾ä»¥è·¨ä¸´åºŠä¸“ä¸šé¢†åŸŸè¿›è¡Œæ³›åŒ–ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç¼ºé™·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†QoQ-Med-7B&#x2F;32Bï¼Œè¿™æ˜¯é¦–ä¸ªå¼€æ”¾çš„é€šç”¨ä¸´åºŠåŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿè·¨åŒ»å­¦å›¾åƒã€æ—¶é—´åºåˆ—ä¿¡å·å’Œæ–‡æœ¬æŠ¥å‘Šè¿›è¡Œè”åˆæ¨ç†ã€‚QoQ-Medé‡‡ç”¨é¢†åŸŸæ„ŸçŸ¥çš„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆDRPOï¼‰è¿›è¡Œè®­ç»ƒï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼Œèƒ½å¤ŸæŒ‰é¢†åŸŸç¨€æœ‰æ€§å’Œæ¨¡æ€éš¾åº¦åˆ†å±‚ç¼©æ”¾æ ‡å‡†åŒ–å¥–åŠ±ï¼Œä»è€Œç¼“è§£ç”±ä¸´åºŠæ•°æ®åˆ†å¸ƒä¸å‡å¯¼è‡´æ€§èƒ½ä¸å¹³è¡¡çš„é—®é¢˜ã€‚åœ¨æ¶µç›–9ä¸ªä¸´åºŠé¢†åŸŸçš„261ä¸‡ä¸ªæŒ‡ä»¤è°ƒæ•´å¯¹ä¸Šè¿›è¡Œçš„è®­ç»ƒè¡¨æ˜ï¼ŒDRPOè®­ç»ƒæé«˜äº†ä¸å…¶ä»–æ— æ‰¹è¯„è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚GRPOï¼‰ç›¸æ¯”çš„å¹³å‡å®è§‚F1åˆ†æ•°ï¼Œè¯Šæ–­æ€§èƒ½æé«˜äº†43%ã€‚æ­¤å¤–ï¼Œç»è¿‡å¯†é›†åˆ†å‰²æ•°æ®è®­ç»ƒçš„QoQ-Medèƒ½å¤Ÿçªå‡ºæ˜¾ç¤ºä¸è¯Šæ–­ç›¸å…³çš„æ˜¾è‘—åŒºåŸŸï¼Œå…¶IoUæ˜¯å¼€æ”¾æ¨¡å‹çš„åå€ä»¥ä¸ŠåŒæ—¶è¾¾åˆ°äº†OpenAI o4-miniçš„æ€§èƒ½æ°´å¹³ã€‚ä¸ºäº†ä¿ƒè¿›å¤åˆ¶å’Œä¸‹æ¸¸ç ”ç©¶ï¼Œæˆ‘ä»¬åœ¨GitHubä¸Šå‘å¸ƒäº†ï¼ˆiï¼‰å®Œæ•´æ¨¡å‹æƒé‡ã€ï¼ˆiiï¼‰æ¨¡å—åŒ–è®­ç»ƒç®¡é“å’Œï¼ˆiiiï¼‰æ‰€æœ‰ä¸­é—´æ¨ç†ç—•è¿¹ï¼š<a target="_blank" rel="noopener" href="https://github.com/DDVD233/QoQ_Med">https://github.com/DDVD233/QoQ_Med</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QoQ-Medæ˜¯é¦–ä¸ªå¼€æ”¾çš„é€šç”¨ä¸´åºŠåŸºç¡€æ¨¡å‹ï¼Œèƒ½è·¨åŒ»å­¦å›¾åƒã€æ—¶é—´åºåˆ—ä¿¡å·å’Œæ–‡æœ¬æŠ¥å‘Šè¿›è¡Œè”åˆæ¨ç†ã€‚</li>
<li>DRPOè®­ç»ƒæ³•æŒ‰é¢†åŸŸç¨€æœ‰æ€§å’Œæ¨¡æ€éš¾åº¦åˆ†å±‚ç¼©æ”¾æ ‡å‡†åŒ–å¥–åŠ±ï¼Œç¼“è§£ä¸´åºŠæ•°æ®åˆ†å¸ƒä¸å‡å¯¼è‡´çš„æ€§èƒ½é—®é¢˜ã€‚</li>
<li>DRPOè®­ç»ƒæé«˜äº†è¯Šæ–­æ€§èƒ½ï¼Œä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œå®è§‚F1åˆ†æ•°å¹³å‡æé«˜43%ã€‚</li>
<li>QoQ-Medç»è¿‡å¯†é›†åˆ†å‰²æ•°æ®è®­ç»ƒï¼Œèƒ½çªå‡ºæ˜¾ç¤ºä¸è¯Šæ–­ç›¸å…³çš„æ˜¾è‘—åŒºåŸŸï¼ŒIoUé«˜äºå…¶ä»–å¼€æ”¾æ¨¡å‹ã€‚</li>
<li>QoQ-Medçš„æ€§èƒ½è¾¾åˆ°OpenAI o4-miniæ°´å¹³ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæä¾›äº†å®Œæ•´çš„æ¨¡å‹æƒé‡ã€æ¨¡å—åŒ–è®­ç»ƒç®¡é“å’Œä¸­é—´æ¨ç†ç—•è¿¹ä»¥æ¨åŠ¨ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00711">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a5df9a71fcc5897339ce94158cdb82e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13e2492d7a081908f48e4945a9f4e53f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeee23fcec6c9c0d9d01e5c8211f8c43.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="ReasonGen-R1-CoT-for-Autoregressive-Image-generation-models-through-SFT-and-RL"><a href="#ReasonGen-R1-CoT-for-Autoregressive-Image-generation-models-through-SFT-and-RL" class="headerlink" title="ReasonGen-R1: CoT for Autoregressive Image generation models through SFT   and RL"></a>ReasonGen-R1: CoT for Autoregressive Image generation models through SFT   and RL</h2><p><strong>Authors:Yu Zhang, Yunqi Li, Yifan Yang, Rui Wang, Yuqing Yang, Dai Qi, Jianmin Bao, Dongdong Chen, Chong Luo, Lili Qiu</strong></p>
<p>Although chain-of-thought reasoning and reinforcement learning (RL) have driven breakthroughs in NLP, their integration into generative vision models remains underexplored. We introduce ReasonGen-R1, a two-stage framework that first imbues an autoregressive image generator with explicit text-based â€œthinkingâ€ skills via supervised fine-tuning on a newly generated reasoning dataset of written rationales, and then refines its outputs using Group Relative Policy Optimization. To enable the model to reason through text before generating images, We automatically generate and release a corpus of model crafted rationales paired with visual prompts, enabling controlled planning of object layouts, styles, and scene compositions. Our GRPO algorithm uses reward signals from a pretrained vision language model to assess overall visual quality, optimizing the policy in each update. Evaluations on GenEval, DPG, and the T2I benchmark demonstrate that ReasonGen-R1 consistently outperforms strong baselines and prior state-of-the-art models. More: aka.ms&#x2F;reasongen. </p>
<blockquote>
<p>å°½ç®¡é“¾å¼æ€ç»´æ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨NLPé¢†åŸŸå–å¾—äº†çªç ´ï¼Œä½†å®ƒä»¬èå…¥ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ä¸­çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚æˆ‘ä»¬å¼•å…¥äº†ReasonGen-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ¡†æ¶ï¼Œé¦–å…ˆé€šè¿‡åœ¨æ–°ç”Ÿæˆçš„åŸºäºæ–‡æœ¬æ¨ç†æ•°æ®é›†ä¸Šè¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼Œä½¿è‡ªå›å½’å›¾åƒç”Ÿæˆå™¨å…·å¤‡æ˜ç¡®çš„åŸºäºæ–‡æœ¬çš„â€œæ€è€ƒâ€æŠ€èƒ½ï¼Œç„¶åä½¿ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–å¯¹å…¶è¾“å‡ºè¿›è¡Œæ”¹è¿›ã€‚ä¸ºäº†èƒ½å¤Ÿè®©æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒä¹‹å‰é€šè¿‡æ–‡æœ¬è¿›è¡Œæ¨ç†ï¼Œæˆ‘ä»¬è‡ªåŠ¨ç”Ÿæˆå¹¶å‘å¸ƒäº†ä¸€ç³»åˆ—ä¸è§†è§‰æç¤ºé…å¯¹çš„äººå·¥æ„é€ çš„æ¨ç†è¯­æ–™åº“ï¼Œå®ç°å¯¹ç‰©ä½“å¸ƒå±€ã€é£æ ¼å’Œåœºæ™¯ç»„åˆçš„æ§åˆ¶è§„åˆ’ã€‚æˆ‘ä»¬çš„GRPOç®—æ³•ä½¿ç”¨é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹çš„å¥–åŠ±ä¿¡å·æ¥è¯„ä¼°æ€»ä½“è§†è§‰è´¨é‡ï¼Œå¹¶åœ¨æ¯æ¬¡æ›´æ–°ä¸­ä¼˜åŒ–ç­–ç•¥ã€‚åœ¨GenEvalã€DPGå’ŒT2IåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒReasonGen-R1æŒç»­è¶…è¶Šå¼ºå¤§çš„åŸºå‡†çº¿å’Œå…ˆå‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æ›´å¤šä¿¡æ¯è¯·è®¿é—®aka.ms&#x2F;reasongenã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24875v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ä¸ªåä¸ºReasonGen-R1çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå®ƒå°†é“¾å¼æ€ç»´æ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ç»“åˆåˆ°ç”Ÿæˆå¼è§†è§‰æ¨¡å‹ä¸­ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡åœ¨æ–°ç”Ÿæˆçš„æ–‡å­—æ¨ç†æ•°æ®é›†ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œèµ‹äºˆè‡ªå›å½’å›¾åƒç”Ÿæˆå™¨åŸºäºæ–‡æœ¬çš„â€œæ€è€ƒâ€æŠ€èƒ½ã€‚ç„¶åï¼Œä½¿ç”¨é›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–æ¥ä¼˜åŒ–å…¶è¾“å‡ºã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ç”Ÿæˆå›¾åƒä¹‹å‰é€šè¿‡æ–‡å­—è¿›è¡Œæ¨ç†ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆä¸è§†è§‰æç¤ºé…å¯¹çš„æ•°æ®é›†ï¼Œä»¥å®ç°å¯¹è±¡å¸ƒå±€ã€é£æ ¼å’Œåœºæ™¯ç»„æˆçš„å—æ§è§„åˆ’ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒReasonGen-R1åœ¨GenEvalã€DPGå’ŒT2IåŸºå‡†æµ‹è¯•ä¸Šå‡ä¼˜äºå¼ºå¤§çš„åŸºå‡†æ¨¡å‹å’Œå…ˆå‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ReasonGen-R1æ¡†æ¶æˆåŠŸç»“åˆäº†é“¾å¼æ€ç»´æ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ï¼Œåº”ç”¨äºç”Ÿæˆå¼è§†è§‰æ¨¡å‹ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ç›‘ç£å¾®è°ƒèµ‹äºˆå›¾åƒç”Ÿæˆå™¨åŸºäºæ–‡æœ¬çš„â€œæ€è€ƒâ€æŠ€èƒ½ï¼Œä½¿ç”¨æ–°ç”Ÿæˆçš„æ–‡å­—æ¨ç†æ•°æ®é›†ã€‚</li>
<li>Group Relative Policy Optimizationç”¨äºä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿé€šè¿‡æ–‡å­—è¿›è¡Œæ¨ç†ï¼Œå†ç”Ÿæˆå›¾åƒï¼Œå¢å¼ºäº†å—æ§çš„è§„åˆ’å’Œå¸ƒå±€èƒ½åŠ›ã€‚</li>
<li>è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®é›†åŒ…å«æ¨¡å‹åˆ¶ä½œçš„ç†æ®å’Œè§†è§‰æç¤ºé…å¯¹ï¼Œæœ‰åŠ©äºåœºæ™¯ç»„æˆçš„è§„åˆ’ã€‚</li>
<li>è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒReasonGen-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24875">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-81fb1b66eea477a71b1fa73db4b16b40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-debe48d58b784601f6665116c06c313d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29607de14dfb23e5fd4e97cc527dd3a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43f02e83ac37ad95ab0cea9104727f8f.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="MoDoMoDo-Multi-Domain-Data-Mixtures-for-Multimodal-LLM-Reinforcement-Learning"><a href="#MoDoMoDo-Multi-Domain-Data-Mixtures-for-Multimodal-LLM-Reinforcement-Learning" class="headerlink" title="MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement   Learning"></a>MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement   Learning</h2><p><strong>Authors:Yiqing Liang, Jielin Qiu, Wenhao Ding, Zuxin Liu, James Tompkin, Mengdi Xu, Mengzhou Xia, Zhengzhong Tu, Laixi Shi, Jiacheng Zhu</strong></p>
<p>Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for post-training large language models (LLMs), achieving state-of-the-art performance on tasks with structured, verifiable answers. Applying RLVR to Multimodal LLMs (MLLMs) presents significant opportunities but is complicated by the broader, heterogeneous nature of vision-language tasks that demand nuanced visual, logical, and spatial capabilities. As such, training MLLMs using RLVR on multiple datasets could be beneficial but creates challenges with conflicting objectives from interaction among diverse datasets, highlighting the need for optimal dataset mixture strategies to improve generalization and reasoning. We introduce a systematic post-training framework for Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation and benchmark implementation. Specifically, (1) We developed a multimodal RLVR framework for multi-dataset post-training by curating a dataset that contains different verifiable vision-language problems and enabling multi-domain online RL learning with different verifiable rewards; (2) We proposed a data mixture strategy that learns to predict the RL fine-tuning outcome from the data mixture distribution, and consequently optimizes the best mixture. Comprehensive experiments showcase that multi-domain RLVR training, when combined with mixture prediction strategies, can significantly boost MLLM general reasoning capacities. Our best mixture improves the post-trained modelâ€™s accuracy on out-of-distribution benchmarks by an average of 5.24% compared to the same model post-trained with uniform data mixture, and by a total of 20.74% compared to the pre-finetuning baseline. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰ä½œä¸ºä¸€ç§å¼ºå¤§çš„èŒƒå¼ï¼Œåœ¨è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åè¡¨ç°å‡ºäº†å‡ºè‰²çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰ç»“æ„åŒ–ã€å¯éªŒè¯ç­”æ¡ˆçš„ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å°†RLVRåº”ç”¨äºå¤šæ¨¡æ€LLMï¼ˆMLLMï¼‰æä¾›äº†å·¨å¤§çš„æœºä¼šï¼Œä½†ç”±äºéœ€è¦å¾®å¦™çš„è§†è§‰ã€é€»è¾‘å’Œç©ºé—´èƒ½åŠ›çš„è§†è§‰è¯­è¨€ä»»åŠ¡çš„å¹¿æ³›æ€§å’Œå¼‚è´¨æ€§ï¼Œä½¿å…¶å¤æ‚åŒ–ã€‚å› æ­¤ï¼Œä½¿ç”¨RLVRåœ¨å¤šæ•°æ®é›†ä¸Šè®­ç»ƒMLLMå¯èƒ½æœ‰ç›Šï¼Œä½†åˆ›å»ºäº†æ¥è‡ªä¸åŒæ•°æ®é›†ä¹‹é—´äº¤äº’çš„å†²çªç›®æ ‡æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¿™çªå‡ºè¡¨æ˜éœ€è¦æœ€ä½³çš„æ•°æ®é›†æ··åˆç­–ç•¥æ¥æé«˜æ³›åŒ–å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬ä¸ºå¤šæ¨¡æ€LLM RLVRå¼•å…¥äº†ä¸€ä¸ªç³»ç»Ÿçš„åè®­ç»ƒæ¡†æ¶ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸¥æ ¼çš„æ•°æ®æ··åˆé—®é¢˜å…¬å¼å’ŒåŸºå‡†å®ç°ã€‚å…·ä½“æ¥è¯´ï¼Œ(1) æˆ‘ä»¬ä¸ºè·¨æ•°æ®é›†çš„åè®­ç»ƒå¼€å‘äº†ä¸€ä¸ªå¤šæ¨¡æ€RLVRæ¡†æ¶ï¼Œé€šè¿‡æ•´ç†åŒ…å«ä¸åŒå¯éªŒè¯çš„è§†è§‰è¯­è¨€é—®é¢˜çš„æ•°æ®é›†ï¼Œå¹¶å®ç°äº†ä½¿ç”¨ä¸åŒå¯éªŒè¯å¥–åŠ±çš„å¤šåŸŸåœ¨çº¿RLå­¦ä¹ ï¼›(2) æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•°æ®æ··åˆç­–ç•¥ï¼Œèƒ½å¤Ÿé¢„æµ‹ä»æ•°æ®æ··åˆåˆ†å¸ƒä¸­çš„RLå¾®è°ƒç»“æœï¼Œä»è€Œä¼˜åŒ–æœ€ä½³çš„æ··åˆç­–ç•¥ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼Œå½“å¤šåŸŸRLVRè®­ç»ƒä¸æ··åˆé¢„æµ‹ç­–ç•¥ç›¸ç»“åˆæ—¶ï¼Œå¯ä»¥æ˜¾è‘—æé«˜MLLMçš„ä¸€èˆ¬æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æœ€ä½³æ··åˆä¸å‡åŒ€æ•°æ®æ··åˆåè®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œåœ¨è¶…å‡ºåˆ†å¸ƒçš„åŸºå‡†æµ‹è¯•ä¸Šçš„å‡†ç¡®ç‡å¹³å‡æé«˜äº†5.24%ï¼Œä¸å¾®è°ƒå‰çš„åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œæé«˜äº†20.74%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24871v2">PDF</a> Project Webpage: <a target="_blank" rel="noopener" href="https://modomodo-rl.github.io/">https://modomodo-rl.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åè¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰ç»“æ„åŒ–ã€å¯éªŒè¯ç­”æ¡ˆçš„ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºã€‚å¯¹äºå¤šæ¨¡æ€LLMï¼ˆMLLMï¼‰ï¼ŒRLVRçš„åº”ç”¨è™½ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚è§†è§‰è¯­è¨€ä»»åŠ¡çš„å¹¿æ³›æ€§å’Œå¼‚è´¨æ€§éœ€æ±‚å¾®å¦™çš„è§†è§‰ã€é€»è¾‘å’Œç©ºé—´èƒ½åŠ›ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒMLLMä½¿ç”¨RLVRå¯èƒ½æœ‰ç›Šï¼Œä½†ä¸åŒæ•°æ®é›†ä¹‹é—´çš„äº¤äº’ä¼šäº§ç”Ÿç›¸äº’å†²çªçš„ç›®æ ‡ï¼Œå‡¸æ˜¾å‡ºéœ€è¦ä¼˜åŒ–æ•°æ®é›†æ··åˆç­–ç•¥ä»¥æé«˜æ³›åŒ–å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬ä¸ºå¤šæ¨¡æ€LLM RLVRå¼•å…¥äº†ä¸€ä¸ªç³»ç»Ÿçš„åè®­ç»ƒæ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸¥æ ¼çš„æ•°æ®æ··åˆé—®é¢˜å…¬å¼å’ŒåŸºå‡†å®ç°ã€‚æˆ‘ä»¬çš„æœ€ä½³æ··åˆç­–ç•¥èƒ½æé«˜æ¨¡å‹åœ¨è¶…å‡ºåˆ†å¸ƒåŸºå‡†æµ‹è¯•ä¸Šçš„å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºå‡åŒ€æ•°æ®æ··åˆç­–ç•¥æé«˜å¹³å‡5.24%ï¼Œç›¸è¾ƒäºé¢„å¾®è°ƒåŸºçº¿æé«˜æ€»è®¡20.74%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLVRå¯¹äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹åå±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰ç»“æ„åŒ–ç­”æ¡ˆçš„ä»»åŠ¡ä¸Šã€‚</li>
<li>åœ¨å¤šæ¨¡æ€LLMä¸­åº”ç”¨RLVRé¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚è§†è§‰è¯­è¨€ä»»åŠ¡çš„å¹¿æ³›æ€§å’Œå¼‚è´¨æ€§éœ€æ±‚å¤æ‚çš„è§†è§‰ã€é€»è¾‘å’Œç©ºé—´æŠ€èƒ½ã€‚</li>
<li>å¤šä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒMLLMä½¿ç”¨RLVRå¯èƒ½æœ‰ç›Šï¼Œä½†å­˜åœ¨ä¸åŒæ•°æ®é›†äº¤äº’äº§ç”Ÿçš„å†²çªç›®æ ‡é—®é¢˜ã€‚</li>
<li>éœ€è¦ä¼˜åŒ–æ•°æ®é›†æ··åˆç­–ç•¥ä»¥æé«˜æ³›åŒ–å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„åè®­ç»ƒæ¡†æ¶å’Œå¤šæ¨¡æ€LLM RLVRçš„åŸºå‡†å®ç°ã€‚</li>
<li>å¼•å…¥äº†æ•°æ®æ··åˆç­–ç•¥æ¥é¢„æµ‹RLç²¾ç»†è°ƒæ•´ç»“æœï¼Œä»è€Œä¼˜åŒ–æœ€ä½³æ··åˆç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24871">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2d85798cfd2364b078b3ff40a2c35862.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60ef819a3443b217f2c0c7108ce1a507.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21051e331554f8f02cf8d1d66e991621.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c67e153c04b4d96cc51c4234436d89f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e25c3e4a4305bb9ed94e3db090e834c.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Reinforcing-Video-Reasoning-with-Focused-Thinking"><a href="#Reinforcing-Video-Reasoning-with-Focused-Thinking" class="headerlink" title="Reinforcing Video Reasoning with Focused Thinking"></a>Reinforcing Video Reasoning with Focused Thinking</h2><p><strong>Authors:Jisheng Dang, Jingze Wu, Teng Wang, Xuanhui Lin, Nannan Zhu, Hongbo Chen, Wei-Shi Zheng, Meng Wang, Tat-Seng Chua</strong></p>
<p>Recent advancements in reinforcement learning, particularly through Group Relative Policy Optimization (GRPO), have significantly improved multimodal large language models for complex reasoning tasks. However, two critical limitations persist: 1) they often produce unfocused, verbose reasoning chains that obscure salient spatiotemporal cues and 2) binary rewarding fails to account for partially correct answers, resulting in high reward variance and inefficient learning. In this paper, we propose TW-GRPO, a novel framework that enhances visual reasoning with focused thinking and dense reward granularity. Specifically, we employs a token weighting mechanism that prioritizes tokens with high informational density (estimated by intra-group variance), suppressing redundant tokens like generic reasoning prefixes. Furthermore, we reformulate RL training by shifting from single-choice to multi-choice QA tasks, where soft rewards enable finer-grained gradient estimation by distinguishing partial correctness. Additionally, we propose question-answer inversion, a data augmentation strategy to generate diverse multi-choice samples from existing benchmarks. Experiments demonstrate state-of-the-art performance on several video reasoning and general understanding benchmarks. Notably, TW-GRPO achieves 50.4% accuracy on CLEVRER (18.8% improvement over Video-R1) and 65.8% on MMVU. Our codes are available at \href{<a target="_blank" rel="noopener" href="https://github.com/longmalongma/TW-GRPO%7D">https://github.com/longmalongma/TW-GRPO}</a>. </p>
<blockquote>
<p>æœ€è¿‘å¼ºåŒ–å­¦ä¹ æ–¹é¢çš„è¿›å±•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå·²ç»æ˜¾è‘—æ”¹å–„äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ç„¶è€Œï¼Œè¿˜æœ‰ä¸¤ä¸ªå…³é”®å±€é™æ€§ï¼š1ï¼‰å®ƒä»¬ç»å¸¸äº§ç”Ÿä¸èšç„¦ã€å†—é•¿çš„æ¨ç†é“¾ï¼Œæ©ç›–äº†é‡è¦çš„æ—¶ç©ºçº¿ç´¢ï¼›2ï¼‰äºŒå…ƒå¥–åŠ±æ— æ³•è€ƒè™‘éƒ¨åˆ†æ­£ç¡®çš„ç­”æ¡ˆï¼Œå¯¼è‡´å¥–åŠ±æ³¢åŠ¨å¤§å’Œå­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†TW-GRPOï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œé€šè¿‡èšç„¦æ€è€ƒå’Œå¯†é›†çš„å¥–åŠ±ç²’åº¦æ¥å¢å¼ºè§†è§‰æ¨ç†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§ä»¤ç‰ŒåŠ æƒæœºåˆ¶ï¼Œä¼˜å…ˆå¤„ç†å…·æœ‰é«˜ä¿¡æ¯å¯†åº¦çš„ä»¤ç‰Œï¼ˆç”±ç»„å†…æ–¹å·®ä¼°è®¡ï¼‰ï¼ŒåŒæ—¶æŠ‘åˆ¶å†—ä½™ä»¤ç‰Œï¼Œå¦‚é€šç”¨æ¨ç†å‰ç¼€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¿›è¡Œé‡æ„ï¼Œä»å•é€‰é¢˜è½¬å‘å¤šé€‰é¢˜é—®ç­”ä»»åŠ¡ï¼Œå…¶ä¸­è½¯å¥–åŠ±èƒ½å¤Ÿé€šè¿‡åŒºåˆ†éƒ¨åˆ†æ­£ç¡®æ€§æ¥å®ç°æ›´ç²¾ç»†çš„æ¢¯åº¦ä¼°è®¡ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†é—®é¢˜ç­”æ¡ˆåè½¬ï¼Œè¿™æ˜¯ä¸€ç§æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¯ä»¥ä»ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­ç”Ÿæˆå¤šæ ·åŒ–çš„å¤šé€‰æ ·æœ¬ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªè§†é¢‘æ¨ç†å’Œé€šç”¨ç†è§£åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒTW-GRPOåœ¨CLEVRERä¸Šè¾¾åˆ°äº†50.4%çš„å‡†ç¡®ç‡ï¼ˆç›¸å¯¹äºVideo-R1æé«˜äº†18.8%ï¼‰ï¼Œåœ¨MMVUä¸Šè¾¾åˆ°äº†65.8%ã€‚æˆ‘ä»¬çš„ä»£ç å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/longmalongma/TW-GRPO%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/longmalongma/TW-GRPOä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24718v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸå¼ºåŒ–å­¦ä¹ åœ¨é€šè¿‡Group Relative Policy Optimizationï¼ˆGRPOï¼‰æ–¹æ³•åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¿›è¡Œå¤æ‚æ¨ç†ä»»åŠ¡æ–¹é¢çš„è¿›å±•æ˜¾è‘—ã€‚ç„¶è€Œï¼Œä»å­˜åœ¨ä¸¤ä¸ªå…³é”®å±€é™ï¼šä¸€æ˜¯äº§ç”Ÿçš„æ¨ç†é“¾å¸¸å¸¸ä¸èšç„¦ä¸”å†—é•¿ï¼Œæ©ç›–äº†é‡è¦çš„æ—¶ç©ºçº¿ç´¢ï¼›äºŒæ˜¯äºŒå…ƒå¥–åŠ±æ— æ³•åº”å¯¹éƒ¨åˆ†æ­£ç¡®ç­”æ¡ˆï¼Œå¯¼è‡´å¥–åŠ±æ³¢åŠ¨è¾ƒå¤§ä¸”å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºTW-GRPOæ¡†æ¶ï¼Œé€šè¿‡æ ‡è®°æƒé‡æœºåˆ¶çªå‡ºä¿¡æ¯å¯†åº¦é«˜çš„æ ‡è®°ï¼ˆé€šè¿‡ç»„å†…æ–¹å·®ä¼°è®¡ï¼‰ï¼ŒæŠ‘åˆ¶é€šç”¨æ¨ç†å‰ç¼€ç­‰å†—ä½™æ ‡è®°ï¼Œå¢å¼ºè§†è§‰æ¨ç†çš„èšç„¦æ€ç»´ã€‚åŒæ—¶ï¼Œé€šè¿‡ä»å•é€‰é¢˜è½¬å‘å¤šé€‰é¢˜é—®ç­”ä»»åŠ¡ï¼Œä»¥è½¯å¥–åŠ±è¿›è¡Œæ›´ç²¾ç»†çš„æ¢¯åº¦ä¼°è®¡æ¥åŒºåˆ†éƒ¨åˆ†æ­£ç¡®æ€§ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨é—®ç­”å€’ç½®ç­–ç•¥ï¼Œå¯¹ç°æœ‰æ•°æ®é›†è¿›è¡Œå¤šæ ·åŒ–å¤šé€‰é¢˜æ ·æœ¬ç”Ÿæˆã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘æ¨ç†å’Œé€šç”¨ç†è§£åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°é¢†å…ˆï¼Œå¦‚åœ¨CLEVRERä¸Šè¾¾åˆ°50.4%å‡†ç¡®ç‡ï¼ˆè¾ƒVideo-R1æé«˜18.8%ï¼‰ï¼Œåœ¨MMVUä¸Šè¾¾åˆ°65.8%å‡†ç¡®ç‡ã€‚ä»£ç å…¬å¼€å¯è®¿é—®ï¼š[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ é€šè¿‡GRPOæ–¹æ³•åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡å–å¾—è¿›å±•ã€‚</li>
<li>å­˜åœ¨çš„ä¸¤ä¸ªå…³é”®é—®é¢˜æ˜¯æ¨ç†é“¾ä¸èšç„¦ã€å†—é•¿ï¼Œä»¥åŠäºŒå…ƒå¥–åŠ±æ— æ³•åº”å¯¹éƒ¨åˆ†æ­£ç¡®ç­”æ¡ˆã€‚</li>
<li>TW-GRPOæ¡†æ¶é€šè¿‡æ ‡è®°æƒé‡æœºåˆ¶çªå‡ºä¿¡æ¯å¯†åº¦é«˜çš„æ ‡è®°ï¼ŒæŠ‘åˆ¶å†—ä½™æ ‡è®°ï¼Œå¢å¼ºè§†è§‰æ¨ç†çš„èšç„¦æ€ç»´ã€‚</li>
<li>é‡‡ç”¨è½¯å¥–åŠ±è¿›è¡Œå¤šé€‰é¢˜é—®ç­”ä»»åŠ¡ï¼Œä»¥åŒºåˆ†éƒ¨åˆ†æ­£ç¡®æ€§ï¼Œå®ç°æ›´ç²¾ç»†çš„æ¢¯åº¦ä¼°è®¡ã€‚</li>
<li>é—®ç­”å€’ç½®ç­–ç•¥ç”¨äºç”Ÿæˆå¤šæ ·åŒ–å¤šé€‰é¢˜æ ·æœ¬ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºTW-GRPOåœ¨è§†é¢‘æ¨ç†å’Œé€šç”¨ç†è§£åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°é¢†å…ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24718">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f80555fb341dfb80dd1f6cc7d222621d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f3a23e9723f93aa2127b7aea300fbe70.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c37a4e160fb362e4f3d64d191092857.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-09/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-09/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-09/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-79cc1066eda96c070681845e2ee1fb80.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-09  LLaDA-V Large Language Diffusion Models with Visual Instruction Tuning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-08/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c6aa8c7508abb08bc847736f25f1b917.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Galactic Science -- Rapporteur Talk of the 8th Heidelberg International   Symposium on High Energy Gamma Ray Astronomy
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29474.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
