<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-05  MonoGS++ Fast and Accurate Monocular RGB Gaussian SLAM">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-babcc3d35c2069d2b3b48c21c116c8bf.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    62 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-05-æ›´æ–°"><a href="#2025-04-05-æ›´æ–°" class="headerlink" title="2025-04-05 æ›´æ–°"></a>2025-04-05 æ›´æ–°</h1><h2 id="MonoGS-Fast-and-Accurate-Monocular-RGB-Gaussian-SLAM"><a href="#MonoGS-Fast-and-Accurate-Monocular-RGB-Gaussian-SLAM" class="headerlink" title="MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM"></a>MonoGS++: Fast and Accurate Monocular RGB Gaussian SLAM</h2><p><strong>Authors:Renwu Li, Wenjing Ke, Dong Li, Lu Tian, Emad Barsoum</strong></p>
<p>We present MonoGS++, a novel fast and accurate Simultaneous Localization and Mapping (SLAM) method that leverages 3D Gaussian representations and operates solely on RGB inputs. While previous 3D Gaussian Splatting (GS)-based methods largely depended on depth sensors, our approach reduces the hardware dependency and only requires RGB input, leveraging online visual odometry (VO) to generate sparse point clouds in real-time. To reduce redundancy and enhance the quality of 3D scene reconstruction, we implemented a series of methodological enhancements in 3D Gaussian mapping. Firstly, we introduced dynamic 3D Gaussian insertion to avoid adding redundant Gaussians in previously well-reconstructed areas. Secondly, we introduced clarity-enhancing Gaussian densification module and planar regularization to handle texture-less areas and flat surfaces better. We achieved precise camera tracking results both on the synthetic Replica and real-world TUM-RGBD datasets, comparable to those of the state-of-the-art. Additionally, our method realized a significant 5.57x improvement in frames per second (fps) over the previous state-of-the-art, MonoGS. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†MonoGS++ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¿«é€Ÿä¸”ç²¾ç¡®çš„SLAMï¼ˆSimultaneous Localization and Mappingï¼Œå³æ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼‰æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œå¹¶ä¸”ä»…ä½¿ç”¨RGBè¾“å…¥è¿›è¡Œæ“ä½œã€‚å°½ç®¡å…ˆå‰çš„åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆGSï¼‰çš„æ–¹æ³•åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ·±åº¦ä¼ æ„Ÿå™¨ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•å‡å°‘äº†ç¡¬ä»¶ä¾èµ–ï¼Œä»…éœ€è¦RGBè¾“å…¥ï¼Œå¹¶åˆ©ç”¨åœ¨çº¿è§†è§‰é‡Œç¨‹è®¡ï¼ˆVOï¼‰æ¥å®æ—¶ç”Ÿæˆç¨€ç–ç‚¹äº‘ã€‚ä¸ºäº†å‡å°‘å†—ä½™å¹¶å¢å¼ºä¸‰ç»´åœºæ™¯é‡å»ºçš„è´¨é‡ï¼Œæˆ‘ä»¬åœ¨ä¸‰ç»´é«˜æ–¯æ˜ å°„ä¸­å®ç°äº†ä¸€ç³»åˆ—æ–¹æ³•ä¸Šçš„æ”¹è¿›ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€ä¸‰ç»´é«˜æ–¯æ’å…¥ï¼Œä»¥é¿å…åœ¨å…ˆå‰é‡å»ºè‰¯å¥½çš„åŒºåŸŸä¸­æ·»åŠ å†—ä½™çš„é«˜æ–¯ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ¸…æ™°åº¦å¢å¼ºé«˜æ–¯ç»†åŒ–æ¨¡å—å’Œå¹³é¢æ­£åˆ™åŒ–ï¼Œä»¥æ›´å¥½åœ°å¤„ç†æ— çº¹ç†åŒºåŸŸå’Œå¹³å¦è¡¨é¢ã€‚æˆ‘ä»¬åœ¨åˆæˆå‰¯æœ¬å’ŒçœŸå®ä¸–ç•Œçš„TUM-RGBDæ•°æ®é›†ä¸Šå®ç°äº†ç²¾ç¡®çš„ç›¸æœºè·Ÿè¸ªç»“æœï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”è¡¨ç°ç›¸å½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¯ç§’å¸§æ•°ï¼ˆfpsï¼‰ä¸Šè¾ƒä¹‹å‰çš„æœ€æ–°æŠ€æœ¯MonoGSå®ç°äº†5.57å€çš„æ˜¾è‘—æå‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02437v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡æå‡ºMonoGS++æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¿«é€Ÿä¸”ç²¾ç¡®çš„SLAMæ–¹æ³•ï¼Œåˆ©ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œä»…ä¾èµ–RGBè¾“å…¥è¿›è¡Œæ“ä½œã€‚ç›¸è¾ƒäºä¹‹å‰ä¾èµ–æ·±åº¦ä¼ æ„Ÿå™¨çš„ä¸‰ç»´é«˜æ–¯æ˜ å°„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å‡å°‘äº†ç¡¬ä»¶ä¾èµ–ï¼Œå¹¶å€ŸåŠ©åœ¨çº¿è§†è§‰é‡Œç¨‹è®¡ç”Ÿæˆå®æ—¶ç¨€ç–ç‚¹äº‘ã€‚åœ¨ä¸‰ç»´é«˜æ–¯æ˜ å°„æ–¹é¢ï¼Œè¯¥æ–¹æ³•å®ç°äº†å¤šé¡¹æ”¹è¿›ä»¥æå‡åœºæ™¯é‡å»ºè´¨é‡å¹¶é™ä½å†—ä½™ã€‚æµ‹è¯•è¡¨æ˜ï¼Œæ— è®ºåœ¨åˆæˆReplicaæ•°æ®é›†è¿˜æ˜¯çœŸå®ä¸–ç•ŒTUM-RGBDæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„ç›¸æœºè¿½è¸ªç»“æœéƒ½ç²¾ç¡®ï¼Œä¸”ä¸ç°æœ‰æŠ€æœ¯ç›¸å½“ã€‚ç›¸è¾ƒäºä¸Šä¸€ä»£MonoGSæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¯ç§’å¸§æ•°æé«˜äº†5.57å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MonoGS++æ˜¯ä¸€ç§åŸºäºRGBè¾“å…¥çš„å¿«é€Ÿä¸”ç²¾ç¡®çš„SLAMæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºè¿›è¡Œæ“ä½œï¼Œå®ç°äº†å¯¹ä¹‹å‰ä¾èµ–æ·±åº¦ä¼ æ„Ÿå™¨çš„ä¸‰ç»´é«˜æ–¯æ˜ å°„æ–¹æ³•çš„æ”¹è¿›ã€‚</li>
<li>MonoGS++é€šè¿‡åœ¨çº¿è§†è§‰é‡Œç¨‹è®¡ç”Ÿæˆå®æ—¶ç¨€ç–ç‚¹äº‘ï¼Œå‡å°‘äº†ç¡¬ä»¶ä¾èµ–ã€‚</li>
<li>æ–¹æ³•å®æ–½äº†å¤šé¡¹æ”¹è¿›æå‡ä¸‰ç»´åœºæ™¯é‡å»ºçš„è´¨é‡å’Œé™ä½å†—ä½™ã€‚</li>
<li>åŠ¨æ€ä¸‰ç»´é«˜æ–¯æ’å…¥é¿å…äº†åœ¨å·²é‡å»ºåŒºåŸŸæ·»åŠ å†—ä½™é«˜æ–¯ã€‚</li>
<li>å¼•å…¥äº†æ¸…æ™°åº¦æå‡çš„é«˜æ–¯å¯†é›†åŒ–æ¨¡å—å’Œå¹³é¢æ­£åˆ™åŒ–ï¼Œä»¥æ›´å¥½åœ°å¤„ç†æ— çº¹ç†åŒºåŸŸå’Œå¹³å¦è¡¨é¢ã€‚</li>
<li>åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒMonoGS++çš„ç›¸æœºè¿½è¸ªç»“æœç²¾ç¡®ï¼Œæ€§èƒ½ä¸ç°æœ‰æŠ€æœ¯ç›¸å½“ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02437">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b09314475767a950231093dffd9c08b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09c358b67ac3ac1b9df37865e0828908.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-705ac013f68f369e9059f9e3397bcf20.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ConsDreamer-Advancing-Multi-View-Consistency-for-Zero-Shot-Text-to-3D-Generation"><a href="#ConsDreamer-Advancing-Multi-View-Consistency-for-Zero-Shot-Text-to-3D-Generation" class="headerlink" title="ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D   Generation"></a>ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D   Generation</h2><p><strong>Authors:Yuan Zhou, Shilong Jin, Litao Hua, Wanjun Lv, Haoran Duan, Jungong Han</strong></p>
<p>Recent advances in zero-shot text-to-3D generation have revolutionized 3D content creation by enabling direct synthesis from textual descriptions. While state-of-the-art methods leverage 3D Gaussian Splatting with score distillation to enhance multi-view rendering through pre-trained text-to-image (T2I) models, they suffer from inherent view biases in T2I priors. These biases lead to inconsistent 3D generation, particularly manifesting as the multi-face Janus problem, where objects exhibit conflicting features across views. To address this fundamental challenge, we propose ConsDreamer, a novel framework that mitigates view bias by refining both the conditional and unconditional terms in the score distillation process: (1) a View Disentanglement Module (VDM) that eliminates viewpoint biases in conditional prompts by decoupling irrelevant view components and injecting precise camera parameters; and (2) a similarity-based partial order loss that enforces geometric consistency in the unconditional term by aligning cosine similarities with azimuth relationships. Extensive experiments demonstrate that ConsDreamer effectively mitigates the multi-face Janus problem in text-to-3D generation, outperforming existing methods in both visual quality and consistency. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œé›¶æ ·æœ¬æ–‡æœ¬åˆ°3Dç”ŸæˆæŠ€æœ¯çš„è¿›å±•é€šè¿‡å®ç°ä»æ–‡æœ¬æè¿°åˆ°ç›´æ¥åˆæˆçš„è½¬å˜ï¼Œå½»åº•æ”¹å˜äº†3Då†…å®¹çš„åˆ›ä½œæ–¹å¼ã€‚è™½ç„¶ç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯å¹³é“ºå’Œåˆ†æ•°è’¸é¦æŠ€æœ¯ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹å¢å¼ºå¤šè§’åº¦æ¸²æŸ“ï¼Œä½†å®ƒä»¬å´é­å—äº†T2Iå…ˆéªŒçš„å›ºæœ‰è§†è§’åå·®çš„å½±å“ã€‚è¿™äº›åå·®å¯¼è‡´äº†3Dç”Ÿæˆçš„ä¸ä¸€è‡´æ€§ï¼Œç‰¹åˆ«è¡¨ç°ä¸ºå¤šé¢ Janus é—®é¢˜ï¼Œå³ç‰©ä½“åœ¨ä¸åŒè§†è§’ä¸‹çš„ç‰¹å¾ç›¸äº’å†²çªã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€åŸºæœ¬æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† ConsDreamer è¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ”¹è¿›åˆ†æ•°è’¸é¦è¿‡ç¨‹ä¸­çš„æ¡ä»¶å’Œæ— æ¡ä»¶æœ¯è¯­æ¥å‡è½»è§†è§’åå·®ï¼šï¼ˆ1ï¼‰è§†è§’åˆ†ç¦»æ¨¡å—ï¼ˆVDMï¼‰ï¼Œé€šè¿‡åˆ†ç¦»æ— å…³çš„è§†è§’æˆåˆ†å¹¶æ³¨å…¥ç²¾ç¡®çš„ç›¸æœºå‚æ•°ï¼Œæ¶ˆé™¤æ¡ä»¶æç¤ºä¸­çš„è§†è§’åå·®ï¼›ï¼ˆ2ï¼‰åŸºäºç›¸ä¼¼åº¦çš„éƒ¨åˆ†é¡ºåºæŸå¤±ï¼Œé€šè¿‡è°ƒæ•´ä½™å¼¦ç›¸ä¼¼æ€§ä¸æ–¹ä½å…³ç³»ï¼Œåœ¨æ— æ¡ä»¶æœ¯è¯­ä¸­å¼ºåˆ¶å®æ–½å‡ ä½•ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒConsDreamer æœ‰æ•ˆåœ°è§£å†³äº†æ–‡æœ¬åˆ°3Dç”Ÿæˆä¸­çš„å¤šé¢ Janus é—®é¢˜ï¼Œåœ¨è§†è§‰è´¨é‡å’Œä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02316v1">PDF</a> 13 pages, 11 figures, 3 tables</p>
<p><strong>Summary</strong><br>æ–‡æœ¬æè¿°ç›´æ¥åˆæˆ3Då†…å®¹çš„æ–¹æ³•å–å¾—äº†è¿›å±•ï¼Œä½†ç°æœ‰æŠ€æœ¯å­˜åœ¨è§†å›¾åå·®é—®é¢˜ï¼Œå¯¼è‡´3Dç”Ÿæˆä¸ä¸€è‡´ï¼Œå‡ºç°å¤šé¢äººé—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºConsDreameræ¡†æ¶ï¼Œé€šè¿‡æ”¹è¿›æ¡ä»¶å’Œæ— æ¡ä»¶æœ¯è¯­ä¸­çš„è¯„åˆ†è’¸é¦è¿‡ç¨‹æ¥æ¶ˆé™¤è§†å›¾åå·®ï¼ŒåŒ…æ‹¬è§†å›¾åˆ†è§£æ¨¡å—å’ŒåŸºäºç›¸ä¼¼æ€§çš„éƒ¨åˆ†é¡ºåºæŸå¤±ã€‚å®éªŒè¯æ˜ï¼ŒConsDreameråœ¨æ–‡æœ¬åˆ°3Dç”Ÿæˆä¸­æœ‰æ•ˆè§£å†³äº†å¤šé¢äººé—®é¢˜ï¼Œåœ¨è§†è§‰è´¨é‡å’Œä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬ç›´æ¥åˆæˆ3Då†…å®¹æˆä¸º3Då†…å®¹åˆ›å»ºçš„é©å‘½æ€§æ–¹æ³•ã€‚</li>
<li>å½“å‰æŠ€æœ¯å­˜åœ¨è§†å›¾åå·®é—®é¢˜ï¼Œå¯¼è‡´3Dç”Ÿæˆä¸ä¸€è‡´ã€‚</li>
<li>ConsDreameræ¡†æ¶æ—¨åœ¨è§£å†³è§†å›¾åå·®é—®é¢˜ï¼Œé€šè¿‡æ”¹è¿›è¯„åˆ†è’¸é¦è¿‡ç¨‹ä¸­çš„æ¡ä»¶å’Œæ— æ¡ä»¶æœ¯è¯­ã€‚</li>
<li>ConsDreameråŒ…æ‹¬è§†å›¾åˆ†è§£æ¨¡å—ï¼ˆVDMï¼‰ï¼Œé€šè¿‡è§£è€¦æ— å…³è§†å›¾ç»„ä»¶å¹¶æ³¨å…¥ç²¾ç¡®ç›¸æœºå‚æ•°æ¥æ¶ˆé™¤è§†ç‚¹åå·®ã€‚</li>
<li>ConsDreameré‡‡ç”¨åŸºäºç›¸ä¼¼æ€§çš„éƒ¨åˆ†é¡ºåºæŸå¤±ï¼Œé€šè¿‡å¯¹é½ä½™å¼¦ç›¸ä¼¼æ€§ä¸æ–¹ä½å…³ç³»æ¥ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ConsDreameråœ¨æ–‡æœ¬åˆ°3Dç”Ÿæˆä¸­è§£å†³äº†å¤šé¢äººé—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02316">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0938886b4dac8accc50f4949450bfa8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f6f8fc2c616dd72de4f98df5addac443.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-999834a237ab04ee54cf419e8b34d76a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5d9639011ace3cb471661dc441745b1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Digital-twin-imaging-based-on-descattering-Gaussian-splatting"><a href="#Digital-twin-imaging-based-on-descattering-Gaussian-splatting" class="headerlink" title="Digital-twin imaging based on descattering Gaussian splatting"></a>Digital-twin imaging based on descattering Gaussian splatting</h2><p><strong>Authors:Suguru Shimomura, Kazuki Yamanouchi, Jun Tanida</strong></p>
<p>Three-dimensional imaging through scattering media is important in medical science and astronomy. We propose a digital-twin imaging method based on Gaussian splatting to observe an object behind a scattering medium. A digital twin model built through data assimilation, emulates the behavior of objects and environmental changes in a virtual space. By constructing a digital twin using point clouds composed of Gaussians and simulating the scattering process through the convolution of a point spread function, three-dimensional objects behind a scattering medium can be reproduced as a digital twin. In this study, a high-contrast digital twin reproducing a three-dimensional object was successfully constructed from degraded images, assuming that data were acquired from wavefronts disturbed by a scattering medium. This technique reproduces objects by integrating data processing with image measurements. </p>
<blockquote>
<p>é€šè¿‡æ•£å°„ä»‹è´¨è¿›è¡Œä¸‰ç»´æˆåƒåœ¨åŒ»å­¦å’Œå¤©æ–‡å­¦ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯å±•å¼€çš„æ•°å­—åŒ–åŒèƒèƒæˆåƒæ–¹æ³•æ¥è§‚å¯Ÿæ•£å°„ä»‹è´¨åçš„ç‰©ä½“ã€‚é€šè¿‡æ•°æ®åŒåŒ–å»ºç«‹çš„æ•°å­—åŒèƒèƒæ¨¡å‹ï¼Œæ¨¡æ‹Ÿè™šæ‹Ÿç©ºé—´ä¸­çš„å¯¹è±¡è¡Œä¸ºå’Œç¯å¢ƒå˜åŒ–ã€‚é€šè¿‡ä½¿ç”¨ç”±é«˜æ–¯ç»„æˆçš„ç‚¹äº‘æ„å»ºæ•°å­—åŒèƒèƒï¼Œå¹¶é€šè¿‡ç‚¹æ‰©æ•£å‡½æ•°çš„å·ç§¯æ¨¡æ‹Ÿæ•£å°„è¿‡ç¨‹ï¼Œå¯ä»¥å°†åœ¨æ•£å°„ä»‹è´¨åçš„ä¸‰ç»´å¯¹è±¡å¤åˆ¶ä¸ºæ•°å­—åŒèƒèƒã€‚æœ¬ç ”ç©¶ä¸­ï¼Œä»é€€åŒ–å›¾åƒæˆåŠŸæ„å»ºäº†ä¸€ä¸ªé«˜å¯¹æ¯”åº¦çš„ä¸‰ç»´æ•°å­—åŒèƒèƒã€‚å‡è®¾æ•°æ®æ¥è‡ªè¢«æ•£å°„ä»‹è´¨å¹²æ‰°çš„æ³¢å‰æ‰€è·å¾—çš„æ•°æ®ã€‚æ­¤æŠ€æœ¯é€šè¿‡å°†æ•°æ®å¤„ç†ä¸å›¾åƒæµ‹é‡ç›¸ç»“åˆæ¥é‡ç°ç‰©ä½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02278v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åŸºäºé«˜æ–¯å–·æ¶‚çš„æ•°å­—å­ªç”Ÿæˆåƒæ–¹æ³•å¯ç”¨äºè§‚æµ‹æ•£å°„ä»‹è´¨åçš„ç‰©ä½“ã€‚é€šè¿‡æ•°æ®åŒåŒ–æ„å»ºæ•°å­—å­ªç”Ÿæ¨¡å‹ï¼Œæ¨¡æ‹Ÿè™šæ‹Ÿç©ºé—´ä¸­å¯¹è±¡å’Œç¯å¢ƒå˜åŒ–çš„è¡Œä¸ºã€‚åˆ©ç”¨é«˜æ–¯ç‚¹äº‘æ„å»ºæ•°å­—å­ªç”Ÿä½“ï¼Œå¹¶é€šè¿‡ç‚¹æ‰©æ•£å‡½æ•°çš„å·ç§¯æ¨¡æ‹Ÿæ•£å°„è¿‡ç¨‹ï¼ŒæˆåŠŸæ„å»ºå‡ºä¸‰ç»´ç‰©ä½“çš„é«˜å¯¹æ¯”åº¦æ•°å­—å­ªç”Ÿä½“ã€‚æ­¤æŠ€æœ¯é€šè¿‡å°†æ•°æ®å¤„ç†ä¸å›¾åƒæµ‹é‡ç›¸ç»“åˆï¼Œå®ç°å¯¹ç‰©ä½“çš„é‡å»ºã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æå‡ºä¸€ç§åŸºäºé«˜æ–¯å–·æ¶‚çš„æ•°å­—å­ªç”Ÿæˆåƒæ–¹æ³•ï¼Œç”¨äºé€è¿‡æ•£å°„ä»‹è´¨è§‚æµ‹ç‰©ä½“ã€‚</li>
<li>é€šè¿‡æ•°æ®åŒåŒ–æ„å»ºæ•°å­—å­ªç”Ÿæ¨¡å‹ï¼Œæ¨¡æ‹Ÿè™šæ‹Ÿç©ºé—´ä¸­å¯¹è±¡çš„è¡Œä¸ºå’Œç¯å¢ƒå˜åŒ–ã€‚</li>
<li>åˆ©ç”¨é«˜æ–¯ç‚¹äº‘æ„å»ºæ•°å­—å­ªç”Ÿä½“ï¼Œæ¨¡æ‹Ÿæ•£å°„è¿‡ç¨‹ã€‚</li>
<li>æˆåŠŸæ„å»ºå‡ºé«˜å¯¹æ¯”åº¦çš„ä¸‰ç»´ç‰©ä½“æ•°å­—å­ªç”Ÿä½“ã€‚</li>
<li>æ­¤æŠ€æœ¯é›†æˆäº†æ•°æ®å¤„ç†å’Œå›¾åƒæµ‹é‡ï¼Œå®ç°äº†ç‰©ä½“çš„é‡å»ºã€‚</li>
<li>æ­¤æ–¹æ³•åœ¨åŒ»å­¦å’Œå¤©æ–‡å­¦ç­‰é¢†åŸŸå…·æœ‰åº”ç”¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02278">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-493b997d3a26443f0724e8b5cd4da34e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c5293f35e890b78738d079b5ae5f9bbb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2ccd443bc45ea9e41201de00f30a2d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51187f7a230607dc5c961d8b7e78e58b.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="UAVTwin-Neural-Digital-Twins-for-UAVs-using-Gaussian-Splatting"><a href="#UAVTwin-Neural-Digital-Twins-for-UAVs-using-Gaussian-Splatting" class="headerlink" title="UAVTwin: Neural Digital Twins for UAVs using Gaussian Splatting"></a>UAVTwin: Neural Digital Twins for UAVs using Gaussian Splatting</h2><p><strong>Authors:Jaehoon Choi, Dongki Jung, Yonghan Lee, Sungmin Eum, Dinesh Manocha, Heesung Kwon</strong></p>
<p>We present UAVTwin, a method for creating digital twins from real-world environments and facilitating data augmentation for training downstream models embedded in unmanned aerial vehicles (UAVs). Specifically, our approach focuses on synthesizing foreground components, such as various human instances in motion within complex scene backgrounds, from UAV perspectives. This is achieved by integrating 3D Gaussian Splatting (3DGS) for reconstructing backgrounds along with controllable synthetic human models that display diverse appearances and actions in multiple poses. To the best of our knowledge, UAVTwin is the first approach for UAV-based perception that is capable of generating high-fidelity digital twins based on 3DGS. The proposed work significantly enhances downstream models through data augmentation for real-world environments with multiple dynamic objects and significant appearance variations-both of which typically introduce artifacts in 3DGS-based modeling. To tackle these challenges, we propose a novel appearance modeling strategy and a mask refinement module to enhance the training of 3D Gaussian Splatting. We demonstrate the high quality of neural rendering by achieving a 1.23 dB improvement in PSNR compared to recent methods. Furthermore, we validate the effectiveness of data augmentation by showing a 2.5% to 13.7% improvement in mAP for the human detection task. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†UAVTwinæ–¹æ³•ï¼Œå®ƒå¯ä»¥ä»çœŸå®ä¸–ç•Œç¯å¢ƒä¸­åˆ›å»ºæ•°å­—å­ªç”Ÿä½“ï¼Œå¹¶ä¿ƒè¿›æ— äººæœºï¼ˆUAVï¼‰ä¸­åµŒå…¥çš„ä¸‹æ¸¸æ¨¡å‹çš„æ•°æ®å¢å¼ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¾§é‡äºä»æ— äººæœºçš„è§†è§’åˆæˆå‰æ™¯ç»„ä»¶ï¼Œä¾‹å¦‚å¤æ‚åœºæ™¯èƒŒæ™¯ä¸­è¿åŠ¨çš„å¤šç§äººç±»å®ä¾‹ã€‚è¿™æ˜¯é€šè¿‡æ•´åˆ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ¥é‡å»ºèƒŒæ™¯ï¼ŒåŒæ—¶æ§åˆ¶åˆæˆçš„äººç±»æ¨¡å‹ï¼Œä»¥åœ¨å¤šç§å§¿åŠ¿ä¸‹å‘ˆç°å¤šæ ·çš„å¤–è§‚å’ŒåŠ¨ä½œæ¥å®ç°çš„ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒUAVTwinæ˜¯åŸºäºæ— äººæœºçš„æ„ŸçŸ¥æ–¹æ³•çš„é¦–æ¬¡å°è¯•ï¼Œå®ƒèƒ½å¤ŸåŸºäº3DGSç”Ÿæˆé«˜ä¿çœŸæ•°å­—å­ªç”Ÿä½“ã€‚æ‰€æå‡ºçš„å·¥ä½œé€šè¿‡æ•°æ®å¢å¼ºæ˜¾è‘—æé«˜äº†ä¸‹æ¸¸æ¨¡å‹åœ¨å…·æœ‰å¤šä¸ªåŠ¨æ€å¯¹è±¡å’Œé‡å¤§å¤–è§‚å˜åŒ–çš„çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„æ€§èƒ½ï¼Œè€Œè¿™ä¸¤è€…é€šå¸¸åœ¨åŸºäº3DGSçš„å»ºæ¨¡ä¸­å¼•å…¥ä¼ªå½±ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤–è§‚å»ºæ¨¡ç­–ç•¥å’Œä¸€ä¸ªæ©è†œä¼˜åŒ–æ¨¡å—ï¼Œä»¥æé«˜3Dé«˜æ–¯æ‹¼è´´çš„è®­ç»ƒæ•ˆæœã€‚æˆ‘ä»¬é€šè¿‡åœ¨PSNRä¸Šå®ç°1.23 dBçš„æ”¹è¿›å±•ç¤ºäº†ç¥ç»æ¸²æŸ“çš„é«˜è´¨é‡ï¼Œä¸æœ€è¿‘çš„æ–¹æ³•ç›¸æ¯”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨äººæ£€æµ‹ä»»åŠ¡ä¸Šæé«˜2.5%è‡³13.7%çš„mAPæ¥è¯æ˜æ•°æ®å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02158v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ— äººæœºæ•°å­—åŒèƒèƒç”Ÿæˆæ–¹æ³•UAVTwinèƒ½å¤Ÿåˆ›å»ºçœŸå®ç¯å¢ƒçš„æ•°å­—åŒèƒèƒï¼Œå¹¶ä¿ƒè¿›æ— äººæœºåµŒå…¥å¼ä¸‹æ¸¸æ¨¡å‹çš„è®­ç»ƒæ•°æ®å¢å¼ºã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼Œé‡å»ºèƒŒæ™¯å¹¶ç”Ÿæˆå¯æ§çš„åˆæˆäººç‰©æ¨¡å‹ï¼Œå±•ç°å¤šæ ·åŒ–å¤–è§‚å’ŒåŠ¨ä½œã€‚UAVTwinå¯ç”Ÿæˆé«˜è´¨é‡çš„æ•°å­—åŒèƒèƒå¹¶æå‡ä¸‹æ¸¸æ¨¡å‹åœ¨é¢å¯¹å…·æœ‰å¤šä¸ªåŠ¨æ€ç‰©ä½“å’Œæ˜¾è‘—å¤–è§‚å˜åŒ–çš„å®é™…ç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚ç ”ç©¶è§£å†³äº†ä¼ ç»Ÿå»ºæ¨¡ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æ”¹è¿›æ¨¡å‹ç­–ç•¥å’Œè’™ç‰ˆä¼˜åŒ–æ¨¡å—ä»¥æå‡æ¨¡å‹è®­ç»ƒè´¨é‡ã€‚å…¶ç¥ç»æ¸²æŸ“æŠ€æœ¯æ˜¾è‘—æé«˜PSNRï¼ŒåŒæ—¶åœ¨äººæ£€ä»»åŠ¡ä¸­çš„å¹³å‡å‡†ç¡®ç‡æå‡äº†è¿‘ä¸‰ä¸ªç™¾åˆ†ç‚¹ã€‚æœ¬æŠ€æœ¯å¯¹æœªæ¥æ— äººæœºçš„ç¯å¢ƒæ„ŸçŸ¥æœ‰ç€é‡å¤§æ„ä¹‰ã€‚ </p>
<p><strong>Key Takeaways</strong> </p>
<p>ä¸€ã€ç ”ç©¶ä»‹ç»äº†ä¸€ç§åŸºäºæ— äººæœºçš„æ–°å‹æ•°å­—åŒèƒèƒç”Ÿæˆæ–¹æ³•ï¼ˆUAVTwinï¼‰ï¼Œé€šè¿‡ç»“åˆä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼ˆ3DGSï¼‰åˆ›å»ºçœŸå®ç¯å¢ƒçš„æ•°å­—åŒèƒèƒã€‚<br>äºŒã€UAVTwinæ–¹æ³•å¯ä»¥åˆæˆå‰æ™¯ç»„ä»¶ï¼Œå¦‚å¤æ‚åœºæ™¯èƒŒæ™¯ä¸­çš„åŠ¨æ€äººç‰©ï¼Œä¸ºæ— äººæœºæä¾›æ›´å…¨é¢çš„æ„ŸçŸ¥ä¿¡æ¯ã€‚<br>ä¸‰ã€ç ”ç©¶é¦–æ¬¡æå‡ºä½¿ç”¨åˆæˆäººç‰©æ¨¡å‹åœ¨åŸºäºæ— äººæœºçš„æƒ…å†µä¸‹å®ç°é«˜åº¦çœŸå®çš„æ•°å­—åŒèƒèƒç”Ÿæˆï¼Œå±•ç¤ºäº†è‰¯å¥½çš„æ€§èƒ½å’Œå®ç”¨æ€§ã€‚<br>å››ã€é€šè¿‡å¼•å…¥æ–°çš„å¤–è§‚å»ºæ¨¡ç­–ç•¥å’Œè’™ç‰ˆä¼˜åŒ–æ¨¡å—ï¼Œè§£å†³äº†åœ¨é‡å»ºè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„æŒ‘æˆ˜å’Œç¼ºé™·ã€‚<br>äº”ã€è¯¥ç ”ç©¶é€šè¿‡æ•°æ®å¢å¼ºæŠ€æœ¯æ˜¾è‘—æå‡äº†ä¸‹æ¸¸æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šä¸ªåŠ¨æ€ç‰©ä½“å’Œæ˜¾è‘—å¤–è§‚å˜åŒ–æ–¹é¢ã€‚<br>å…­ã€ç¥ç»æ¸²æŸ“æŠ€æœ¯å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†PSNRå€¼è¾¾åˆ°è¿‘ä¸‰ä¸ªç™¾åˆ†ç‚¹ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d76bd3e95ddf8dde1f16cdbdf984228d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e27b5d8781a840590fa4292e2ef9c2b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2d563b146813b7b485a2717d7a07d11.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f05bd2d7548bb64d12057f7552f8704c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="WorldPrompter-Traversable-Text-to-Scene-Generation"><a href="#WorldPrompter-Traversable-Text-to-Scene-Generation" class="headerlink" title="WorldPrompter: Traversable Text-to-Scene Generation"></a>WorldPrompter: Traversable Text-to-Scene Generation</h2><p><strong>Authors:Zhaoyang Zhang, Yannick Hold-Geoffroy, MiloÅ¡ HaÅ¡an, Chen Ziwen, Fujun Luan, Julie Dorsey, Yiwei Hu</strong></p>
<p>Scene-level 3D generation is a challenging research topic, with most existing methods generating only partial scenes and offering limited navigational freedom. We introduce WorldPrompter, a novel generative pipeline for synthesizing traversable 3D scenes from text prompts. We leverage panoramic videos as an intermediate representation to model the 360{\deg} details of a scene. WorldPrompter incorporates a conditional 360{\deg} panoramic video generator, capable of producing a 128-frame video that simulates a person walking through and capturing a virtual environment. The resulting video is then reconstructed as Gaussian splats by a fast feedforward 3D reconstructor, enabling a true walkable experience within the 3D scene. Experiments demonstrate that our panoramic video generation model achieves convincing view consistency across frames, enabling high-quality panoramic Gaussian splat reconstruction and facilitating traversal over an area of the scene. Qualitative and quantitative results also show it outperforms the state-of-the-art 360{\deg} video generators and 3D scene generation models. </p>
<blockquote>
<p>åœºæ™¯çº§åˆ«çš„3Dç”Ÿæˆæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶è¯¾é¢˜ï¼Œç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•åªèƒ½ç”Ÿæˆéƒ¨åˆ†åœºæ™¯ï¼Œæä¾›çš„å¯¼èˆªè‡ªç”±æœ‰é™ã€‚æˆ‘ä»¬å¼•å…¥äº†WorldPrompterï¼Œè¿™æ˜¯ä¸€ç§ä»æ–‡æœ¬æç¤ºåˆæˆå¯éå†çš„3Dåœºæ™¯çš„æ–°å‹ç”Ÿæˆç®¡é“ã€‚æˆ‘ä»¬åˆ©ç”¨å…¨æ™¯è§†é¢‘ä½œä¸ºä¸­é—´è¡¨ç¤ºæ¥å»ºæ¨¡åœºæ™¯çš„360Â°ç»†èŠ‚ã€‚WorldPrompterç»“åˆäº†ä¸€ä¸ªæ¡ä»¶æ€§çš„360Â°å…¨æ™¯è§†é¢‘ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸€ä¸ªæ¨¡æ‹Ÿäººèµ°è¿‡å¹¶æ•æ‰è™šæ‹Ÿç¯å¢ƒçš„128å¸§è§†é¢‘ã€‚ç„¶åï¼Œç»“æœè§†é¢‘è¢«å¿«é€Ÿå‰é¦ˆçš„3Dé‡å»ºå™¨é‡å»ºä¸ºé«˜æ–¯æ–‘ç‚¹ï¼Œä»è€Œåœ¨3Dåœºæ™¯ä¸­å®ç°çœŸæ­£çš„å¯æ­¥è¡Œä½“éªŒã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å…¨æ™¯è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨å¸§ä¹‹é—´å®ç°äº†ä»¤äººä¿¡æœçš„è§†å›¾ä¸€è‡´æ€§ï¼Œå®ç°äº†é«˜è´¨é‡çš„å…¨æ™¯é«˜æ–¯æ–‘ç‚¹é‡å»ºï¼Œå¹¶ä¿ƒè¿›äº†åœºæ™¯çš„æŸä¸ªåŒºåŸŸçš„éå†ã€‚å®šæ€§å’Œå®šé‡ç»“æœä¹Ÿè¡¨æ˜ï¼Œå®ƒçš„æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„360Â°è§†é¢‘ç”Ÿæˆå™¨å’Œ3Dåœºæ™¯ç”Ÿæˆæ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02045v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†WorldPrompterè¿™ä¸€æ–°å‹ä¸‰ç»´åœºæ™¯ç”Ÿæˆç®¡é“ï¼Œå…¶åŸºäºæ–‡æœ¬æç¤ºç”Ÿæˆå¯å¯¼èˆªçš„ä¸‰ç»´åœºæ™¯ã€‚åˆ©ç”¨å…¨æ™¯è§†é¢‘ä½œä¸ºä¸­é—´è¡¨ç°å½¢å¼æ¥æ¨¡æ‹Ÿåœºæ™¯çš„360åº¦ç»†èŠ‚ã€‚é€šè¿‡æ¡ä»¶360åº¦å…¨æ™¯è§†é¢‘ç”Ÿæˆå™¨äº§ç”Ÿæ¨¡æ‹Ÿäººè¡Œèµ°å¹¶æ•æ‰è™šæ‹Ÿç¯å¢ƒçš„128å¸§è§†é¢‘ã€‚ç„¶åï¼Œé€šè¿‡å¿«é€Ÿå‰é¦ˆä¸‰ç»´é‡å»ºå™¨å°†è§†é¢‘é‡å»ºä¸ºé«˜æ–¯æ–‘ç‚¹ï¼Œå®ç°çœŸæ­£çš„åœºæ™¯å†…éƒ¨å¯èµ°åŠ¨ä½“éªŒã€‚å®éªŒè¯æ˜ï¼Œå…¨æ™¯è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨å¸§é—´è§†è§’ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå®ç°äº†é«˜è´¨é‡çš„å…¨æ™¯é«˜æ–¯æ–‘ç‚¹é‡å»ºï¼Œå¹¶ä¿ƒè¿›äº†åœºæ™¯çš„éå†ã€‚ç›¸è¾ƒäºç°æœ‰çš„360åº¦è§†é¢‘ç”Ÿæˆå™¨å’Œä¸‰ç»´åœºæ™¯ç”Ÿæˆæ¨¡å‹ï¼Œæœ¬æ–‡çš„æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WorldPrompteræ˜¯ä¸€ç§æ–°å‹çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆç®¡é“ï¼Œå¯ä»æ–‡æœ¬æç¤ºç”Ÿæˆå¯å¯¼èˆªçš„ä¸‰ç»´åœºæ™¯ã€‚</li>
<li>åˆ©ç”¨å…¨æ™¯è§†é¢‘ä½œä¸ºä¸­é—´è¡¨ç°å½¢å¼ï¼Œæ¨¡æ‹Ÿåœºæ™¯çš„360åº¦ç»†èŠ‚ã€‚</li>
<li>é€šè¿‡æ¡ä»¶å…¨æ™¯è§†é¢‘ç”Ÿæˆå™¨äº§ç”Ÿæ¨¡æ‹Ÿäººè¡Œèµ°çš„128å¸§è§†é¢‘ã€‚</li>
<li>å¿«é€Ÿå‰é¦ˆä¸‰ç»´é‡å»ºå™¨å°†è§†é¢‘é‡å»ºä¸ºé«˜æ–¯æ–‘ç‚¹ï¼Œå®ç°åœºæ™¯å†…éƒ¨çš„å¯èµ°åŠ¨ä½“éªŒã€‚</li>
<li>å…¨æ™¯è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨å¸§é—´è§†è§’ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„å…¨æ™¯é«˜æ–¯æ–‘ç‚¹é‡å»ºï¼Œä¿ƒè¿›äº†åœºæ™¯çš„éå†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02045">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-babcc3d35c2069d2b3b48c21c116c8bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-896e66fabad6d08ed7ddf511c138ff8d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-39af21ed30c92f253244b349967ebfad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-835ac848637ac805294987ca29182fa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8613a3886b067c6d5157d855e7f073d3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Toward-Real-world-BEV-Perception-Depth-Uncertainty-Estimation-via-Gaussian-Splatting"><a href="#Toward-Real-world-BEV-Perception-Depth-Uncertainty-Estimation-via-Gaussian-Splatting" class="headerlink" title="Toward Real-world BEV Perception: Depth Uncertainty Estimation via   Gaussian Splatting"></a>Toward Real-world BEV Perception: Depth Uncertainty Estimation via   Gaussian Splatting</h2><p><strong>Authors:Shu-Wei Lu, Yi-Hsuan Tsai, Yi-Ting Chen</strong></p>
<p>Birdâ€™s-eye view (BEV) perception has gained significant attention because it provides a unified representation to fuse multiple view images and enables a wide range of down-stream autonomous driving tasks, such as forecasting and planning. Recent state-of-the-art models utilize projection-based methods which formulate BEV perception as query learning to bypass explicit depth estimation. While we observe promising advancements in this paradigm, they still fall short of real-world applications because of the lack of uncertainty modeling and expensive computational requirement. In this work, we introduce GaussianLSS, a novel uncertainty-aware BEV perception framework that revisits unprojection-based methods, specifically the Lift-Splat-Shoot (LSS) paradigm, and enhances them with depth un-certainty modeling. GaussianLSS represents spatial dispersion by learning a soft depth mean and computing the variance of the depth distribution, which implicitly captures object extents. We then transform the depth distribution into 3D Gaussians and rasterize them to construct uncertainty-aware BEV features. We evaluate GaussianLSS on the nuScenes dataset, achieving state-of-the-art performance compared to unprojection-based methods. In particular, it provides significant advantages in speed, running 2.5x faster, and in memory efficiency, using 0.3x less memory compared to projection-based methods, while achieving competitive performance with only a 0.4% IoU difference. </p>
<blockquote>
<p>é¸Ÿç°è§†å›¾ï¼ˆBEVï¼‰æ„ŸçŸ¥å·²å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºå®ƒä¸ºå¤šè§†å›¾å›¾åƒèåˆæä¾›äº†ç»Ÿä¸€è¡¨ç¤ºï¼Œå¹¶èƒ½å¤Ÿæ”¯æŒå¤šç§ä¸‹æ¸¸è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ï¼Œå¦‚é¢„æµ‹å’Œè§„åˆ’ã€‚æœ€è¿‘æœ€å…ˆè¿›çš„æ¨¡å‹é‡‡ç”¨åŸºäºæŠ•å½±çš„æ–¹æ³•ï¼Œå°†BEVæ„ŸçŸ¥åˆ¶å®šä¸ºæŸ¥è¯¢å­¦ä¹ ï¼Œä»¥è§„é¿æ˜ç¡®çš„æ·±åº¦ä¼°è®¡ã€‚è™½ç„¶æˆ‘ä»¬åœ¨è¿™ä¸€èŒƒå¼ä¸­çœ‹åˆ°äº†æœ‰å‰æ™¯çš„è¿›å±•ï¼Œä½†å®ƒä»¬ä»ç„¶å› ç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡å’Œæ˜‚è´µçš„è®¡ç®—è¦æ±‚è€Œæ— æ³•åº”ç”¨äºç°å®ä¸–ç•Œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GaussianLSSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥BEVæ„ŸçŸ¥æ¡†æ¶ï¼Œå®ƒé‡æ–°å®¡è§†äº†åŸºäºéæŠ•å½±çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯æå‡-å¹³é“º-å°„å‡»ï¼ˆLSSï¼‰èŒƒå¼ï¼Œå¹¶é€šè¿‡æ·±åº¦ä¸ç¡®å®šæ€§å»ºæ¨¡å¢å¼ºäº†å®ƒä»¬ã€‚GaussianLSSé€šè¿‡å­¦ä¹ è½¯æ·±åº¦å‡å€¼å¹¶è®¡ç®—æ·±åº¦åˆ†å¸ƒçš„æ–¹å·®æ¥è¡¨ç¤ºç©ºé—´åˆ†æ•£æ€§ï¼Œè¿™éšå«åœ°æ•è·äº†å¯¹è±¡èŒƒå›´ã€‚ç„¶åæˆ‘ä»¬å°†æ·±åº¦åˆ†å¸ƒè½¬åŒ–ä¸º3Dé«˜æ–¯å¹¶è¿›è¡Œæ …æ ¼åŒ–ï¼Œä»¥æ„å»ºå…·æœ‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„BEVç‰¹å¾ã€‚æˆ‘ä»¬åœ¨nuscenesæ•°æ®é›†ä¸Šè¯„ä¼°äº†GaussianLSSçš„æ€§èƒ½ï¼Œä¸åŸºäºéæŠ•å½±çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå®ƒåœ¨é€Ÿåº¦ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œè¿è¡Œé€Ÿåº¦ä¸ºåŸºäºæŠ•å½±æ–¹æ³•çš„2.5å€ï¼Œå¹¶ä¸”åœ¨å†…å­˜æ•ˆç‡æ–¹é¢ä¹Ÿæœ‰æé«˜ï¼Œä½¿ç”¨äº†ä»…ç›¸å½“äºåŸºäºæŠ•å½±æ–¹æ³•0.3å€çš„å†…å­˜ï¼ŒåŒæ—¶åœ¨IoUå·®å¼‚ä¸Šä»…ç›¸å·®0.4%ï¼Œè¡¨ç°å‡ºäº†ç«äº‰åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01957v2">PDF</a> Accepted to CVPRâ€™25. <a target="_blank" rel="noopener" href="https://hcis-lab.github.io/GaussianLSS/">https://hcis-lab.github.io/GaussianLSS/</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åä¸ºGaussianLSSçš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥é¸Ÿç°å›¾æ„ŸçŸ¥æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡æ–°å®¡è§†åŸºäºéæŠ•å½±çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯Lift-Splat-Shootï¼ˆLSSï¼‰èŒƒå¼ï¼Œå¹¶é€šè¿‡æ·±åº¦ä¸ç¡®å®šæ€§å»ºæ¨¡è¿›è¡Œå¢å¼ºã€‚å®ƒé€šè¿‡å­¦ä¹ è½¯æ·±åº¦å‡å€¼å¹¶è®¡ç®—æ·±åº¦åˆ†å¸ƒçš„æ–¹å·®æ¥è¡¨ç¤ºç©ºé—´åˆ†å¸ƒï¼Œä»è€Œéšå¼åœ°æ•è·å¯¹è±¡èŒƒå›´ã€‚ç„¶åï¼Œå°†æ·±åº¦åˆ†å¸ƒè½¬æ¢ä¸º3Dé«˜æ–¯å¹¶å°†å…¶æ …æ ¼åŒ–ï¼Œä»¥æ„å»ºå…·æœ‰æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„é¸Ÿç°å›¾ç‰¹å¾ã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šè¯„ä¼°GaussianLSSï¼Œä¸åŸºäºéæŠ•å½±çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·æœ‰é€Ÿåº¦å¿«ã€å†…å­˜æ•ˆç‡é«˜ç­‰ä¼˜ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>BEVæ„ŸçŸ¥èåˆå¤šè§†è§’å›¾åƒè¡¨ç¤ºï¼Œä¿ƒè¿›è‡ªåŠ¨é©¾é©¶ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚é¢„æµ‹å’Œè§„åˆ’ã€‚</li>
<li>æœ€æ–°æ¨¡å‹ä½¿ç”¨åŸºäºæŸ¥è¯¢çš„å­¦ä¹ æ–¹æ³•ç»•è¿‡æ˜¾å¼æ·±åº¦ä¼°è®¡ï¼Œä½†ç¼ºä¹ä¸ç¡®å®šæ€§å»ºæ¨¡å’Œè®¡ç®—æˆæœ¬é«˜ã€‚</li>
<li>GaussianLSSæ˜¯ä¸€ç§ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„BEVæ„ŸçŸ¥æ¡†æ¶ï¼ŒåŸºäºéæŠ•å½±æ–¹æ³•ï¼ˆç‰¹åˆ«æ˜¯LSSèŒƒå¼ï¼‰ã€‚</li>
<li>GaussianLSSé€šè¿‡å»ºæ¨¡æ·±åº¦ä¸ç¡®å®šæ€§å¢å¼ºæ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡å­¦ä¹ å’Œè®¡ç®—æ·±åº¦åˆ†å¸ƒçš„è½¯å‡å€¼å’Œæ–¹å·®æ¥è¡¨ç¤ºç©ºé—´åˆ†å¸ƒã€‚</li>
<li>å°†æ·±åº¦åˆ†å¸ƒè½¬æ¢ä¸º3Dé«˜æ–¯å¹¶æ …æ ¼åŒ–ï¼Œæ„å»ºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„BEVç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01957">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-74efedd9d284529a48785c1a5b25e105.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7339336e6eb1f00486630ae4946f87fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f73f51e96852fb51455f8ebaf150e34b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0f483396fdf57f70db3cede0c2127b48.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Distilling-Multi-view-Diffusion-Models-into-3D-Generators"><a href="#Distilling-Multi-view-Diffusion-Models-into-3D-Generators" class="headerlink" title="Distilling Multi-view Diffusion Models into 3D Generators"></a>Distilling Multi-view Diffusion Models into 3D Generators</h2><p><strong>Authors:Hao Qin, Luyuan Chen, Ming Kong, Mengxu Lu, Qiang Zhu</strong></p>
<p>We introduce DD3G, a formulation that Distills a multi-view Diffusion model (MV-DM) into a 3D Generator using gaussian splatting. DD3G compresses and integrates extensive visual and spatial geometric knowledge from the MV-DM by simulating its ordinary differential equation (ODE) trajectory, ensuring the distilled generator generalizes better than those trained solely on 3D data. Unlike previous amortized optimization approaches, we align the MV-DM and 3D generator representation spaces to transfer the teacherâ€™s probabilistic flow to the student, thus avoiding inconsistencies in optimization objectives caused by probabilistic sampling. The introduction of probabilistic flow and the coupling of various attributes in 3D Gaussians introduce challenges in the generation process. To tackle this, we propose PEPD, a generator consisting of Pattern Extraction and Progressive Decoding phases, which enables efficient fusion of probabilistic flow and converts a single image into 3D Gaussians within 0.06 seconds. Furthermore, to reduce knowledge loss and overcome sparse-view supervision, we design a joint optimization objective that ensures the quality of generated samples through explicit supervision and implicit verification. Leveraging existing 2D generation models, we compile 120k high-quality RGBA images for distillation. Experiments on synthetic and public datasets demonstrate the effectiveness of our method. Our project is available at: <a target="_blank" rel="noopener" href="https://qinbaigao.github.io/DD3G_project/">https://qinbaigao.github.io/DD3G_project/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†DD3Gï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é«˜æ–¯æ‹¼è´´æ³•å°†å¤šè§†å›¾æ‰©æ•£æ¨¡å‹ï¼ˆMV-DMï¼‰è’¸é¦åˆ°3Dç”Ÿæˆå™¨çš„æ–¹æ³•ã€‚DD3Gé€šè¿‡æ¨¡æ‹ŸMV-DMçš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰è½¨è¿¹ï¼Œå‹ç¼©å¹¶é›†æˆäº†å¤§é‡çš„è§†è§‰å’Œç©ºé—´å‡ ä½•çŸ¥è¯†ï¼Œç¡®ä¿è’¸é¦å‡ºçš„ç”Ÿæˆå™¨æ¯”ä»…åŸºäº3Dæ•°æ®è®­ç»ƒçš„ç”Ÿæˆå™¨å…·æœ‰æ›´å¥½çš„é€šç”¨æ€§ã€‚ä¸åŒäºä¹‹å‰çš„æŠ˜ä¸­ä¼˜åŒ–æ–¹æ³•ï¼Œæˆ‘ä»¬å°†MV-DMå’Œ3Dç”Ÿæˆå™¨çš„è¡¨ç¤ºç©ºé—´è¿›è¡Œå¯¹é½ï¼Œä»¥å°†æ•™å¸ˆçš„æ¦‚ç‡æµä¼ è¾“ç»™å­¦ç”Ÿï¼Œä»è€Œé¿å…ç”±æ¦‚ç‡é‡‡æ ·å¼•èµ·çš„ä¼˜åŒ–ç›®æ ‡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚æ¦‚ç‡æµçš„å¼•å…¥å’Œ3Dé«˜æ–¯ä¸­å„ç§å±æ€§çš„è€¦åˆç»™ç”Ÿæˆè¿‡ç¨‹å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PEPDç”Ÿæˆå™¨ï¼Œå®ƒç”±æ¨¡å¼æå–å’Œæ¸è¿›è§£ç ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°èåˆæ¦‚ç‡æµï¼Œå¹¶åœ¨0.06ç§’å†…å°†å•å¹…å›¾åƒè½¬æ¢ä¸º3Dé«˜æ–¯ã€‚æ­¤å¤–ï¼Œä¸ºäº†å‡å°‘çŸ¥è¯†æŸå¤±å¹¶å…‹æœç¨€ç–è§†å›¾ç›‘ç£ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè”åˆä¼˜åŒ–ç›®æ ‡ï¼Œé€šè¿‡æ˜¾å¼ç›‘ç£å’Œéšå¼éªŒè¯ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„è´¨é‡ã€‚æˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„2Dç”Ÿæˆæ¨¡å‹ï¼Œç¼–è¯‘äº†12ä¸‡å¼ é«˜è´¨é‡RGBAå›¾åƒè¿›è¡Œè’¸é¦ã€‚åœ¨åˆæˆå’Œå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„é¡¹ç›®åœ¨<a target="_blank" rel="noopener" href="https://qinbaigao.github.io/DD3G_project/">https://qinbaigao.github.io/DD3G_project/</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00457v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºé«˜æ–¯å–·æº…æŠ€æœ¯ï¼Œç ”ç©¶æå‡ºä¸€ç§å¤šè§†è§’æ‰©æ•£æ¨¡å‹ï¼ˆMV-DMï¼‰åˆ°ä¸‰ç»´ç”Ÿæˆå™¨ï¼ˆDD3Gï¼‰çš„è’¸é¦æ–¹æ³•ã€‚é€šè¿‡æ¨¡æ‹ŸMV-DMçš„æ™®é€šå¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰è½¨è¿¹ï¼ŒDD3Gæ•´åˆå¹¶å‹ç¼©äº†è§†è§‰å’Œç©ºé—´å‡ ä½•çŸ¥è¯†ï¼Œä½¿å…¶ç”Ÿæˆçš„æ¨¡å‹ç›¸è¾ƒäºä»…ä¾èµ–ä¸‰ç»´æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ›´å…·æ³›åŒ–èƒ½åŠ›ã€‚ä¸åŒäºä¼ ç»Ÿçš„æŠ˜åŠä¼˜åŒ–æ³•ï¼Œç ”ç©¶é€šè¿‡å°†MV-DMå’Œä¸‰ç»´ç”Ÿæˆå™¨çš„è¡¨ç°ç©ºé—´å¯¹é½ï¼Œä¼ é€’äº†æ•™å¸ˆæ¨¡å‹çš„æ¦‚ç‡æµç»™å­¦ç”Ÿæ¨¡å‹ï¼Œé¿å…äº†ç”±æ¦‚ç‡é‡‡æ ·å¸¦æ¥çš„ç›®æ ‡ä¼˜åŒ–ä¸ä¸€è‡´é—®é¢˜ã€‚ä¸ºè§£å†³æ¦‚ç‡æµå¼•å…¥åŠä¸‰ç»´é«˜æ–¯ä¸­çš„å±æ€§è€¦åˆå¸¦æ¥çš„ç”ŸæˆæŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†åŒ…å«æ¨¡å¼æå–å’Œæ¸è¿›è§£ç é˜¶æ®µçš„PEPDç”Ÿæˆå™¨ï¼Œèƒ½åœ¨0.06ç§’å†…å®ç°æ¦‚ç‡æµçš„èåˆå¹¶å°†å•ä¸€å›¾åƒè½¬åŒ–ä¸ºä¸‰ç»´é«˜æ–¯å›¾åƒã€‚ä¸ºå‡å°‘çŸ¥è¯†æŸå¤±å¹¶è§£å†³ç›‘ç£è§†å›¾çš„ç¨€ç–æ€§é—®é¢˜ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§è”åˆä¼˜åŒ–ç›®æ ‡ï¼Œç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œå¯é æ€§ã€‚ç°æœ‰äºŒç»´ç”Ÿæˆæ¨¡å‹çš„åº”ç”¨å’Œå®éªŒç»“æœéªŒè¯äº†ç ”ç©¶çš„æ•ˆç”¨æ€§ã€‚ç ”ç©¶æ›´å¤šå†…å®¹å¯é€šè¿‡ç½‘å€<a target="_blank" rel="noopener" href="https://qinbaigao.github.io/DD3G_project/">https://qinbaigao.github.io/DD3G_project/</a> è¿›è¡ŒæŸ¥çœ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨é«˜æ–¯å–·æº…æŠ€æœ¯æå‡ºDD3Gè’¸é¦å…¬å¼ã€‚è¯¥å…¬å¼åŸºäºMV-DMæ•´åˆå¹¶å‹ç¼©è§†è§‰å’Œç©ºé—´å‡ ä½•çŸ¥è¯†ã€‚</li>
<li>é‡‡ç”¨ODEè½¨è¿¹æ¨¡æ‹Ÿï¼Œä½¿è’¸é¦åçš„ç”Ÿæˆå™¨å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¯¹é½MV-DMå’Œä¸‰ç»´ç”Ÿæˆå™¨çš„è¡¨ç°ç©ºé—´ï¼Œä¼ é€’æ•™å¸ˆæ¨¡å‹çš„æ¦‚ç‡æµé¿å…ç›®æ ‡ä¼˜åŒ–ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥PEPDç”Ÿæˆå™¨å¤„ç†æ¦‚ç‡æµå¼•å…¥åŠä¸‰ç»´é«˜æ–¯ä¸­çš„å±æ€§è€¦åˆå¸¦æ¥çš„æŒ‘æˆ˜ã€‚</li>
<li>PEPDç”Ÿæˆå™¨å¯å®ç°æ¦‚ç‡æµçš„èåˆå¹¶å°†å•ä¸€å›¾åƒå¿«é€Ÿè½¬åŒ–ä¸ºä¸‰ç»´é«˜æ–¯å›¾åƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00457">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1ce28162b577c4f3fe5dba65a99d4f1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd5ced50961b209c9ff6ef2cd5c0663e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f7b487ff167a29735997ac5d402d1d2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6eb6f5bc327dbaba705f3566712c6fc2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b572b2194b81b3883cafe56abae3366.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Synthetic-Prior-for-Few-Shot-Drivable-Head-Avatar-Inversion"><a href="#Synthetic-Prior-for-Few-Shot-Drivable-Head-Avatar-Inversion" class="headerlink" title="Synthetic Prior for Few-Shot Drivable Head Avatar Inversion"></a>Synthetic Prior for Few-Shot Drivable Head Avatar Inversion</h2><p><strong>Authors:Wojciech Zielonka, Stephan J. Garbin, Alexandros Lattas, George Kopanas, Paulo Gotardo, Thabo Beeler, Justus Thies, Timo Bolkart</strong></p>
<p>We present SynShot, a novel method for the few-shot inversion of a drivable head avatar based on a synthetic prior. We tackle three major challenges. First, training a controllable 3D generative network requires a large number of diverse sequences, for which pairs of images and high-quality tracked meshes are not always available. Second, the use of real data is strictly regulated (e.g., under the General Data Protection Regulation, which mandates frequent deletion of models and data to accommodate a situation when a participantâ€™s consent is withdrawn). Synthetic data, free from these constraints, is an appealing alternative. Third, state-of-the-art monocular avatar models struggle to generalize to new views and expressions, lacking a strong prior and often overfitting to a specific viewpoint distribution. Inspired by machine learning models trained solely on synthetic data, we propose a method that learns a prior model from a large dataset of synthetic heads with diverse identities, expressions, and viewpoints. With few input images, SynShot fine-tunes the pretrained synthetic prior to bridge the domain gap, modeling a photorealistic head avatar that generalizes to novel expressions and viewpoints. We model the head avatar using 3D Gaussian splatting and a convolutional encoder-decoder that outputs Gaussian parameters in UV texture space. To account for the different modeling complexities over parts of the head (e.g., skin vs hair), we embed the prior with explicit control for upsampling the number of per-part primitives. Compared to SOTA monocular and GAN-based methods, SynShot significantly improves novel view and expression synthesis. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºSynShotçš„æ–°æ–¹æ³•ï¼Œç”¨äºåŸºäºåˆæˆå…ˆéªŒçš„å°‘é‡é©±åŠ¨å¤´éƒ¨åŒ–èº«å€’ç½®ã€‚æˆ‘ä»¬è§£å†³äº†ä¸‰å¤§æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œè®­ç»ƒå¯æ§çš„3Dç”Ÿæˆç½‘ç»œéœ€è¦å¤§é‡çš„ä¸åŒåºåˆ—ï¼Œè€Œå›¾åƒå’Œé«˜è´¨é‡è·Ÿè¸ªç½‘æ ¼çš„é…å¯¹å¹¶ä¸æ€»æ˜¯å¯ç”¨ã€‚å…¶æ¬¡ï¼ŒçœŸå®æ•°æ®çš„ä½¿ç”¨å—åˆ°ä¸¥æ ¼ç›‘ç®¡ï¼ˆä¾‹å¦‚ï¼Œæ ¹æ®ã€Šé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ã€‹ï¼Œå½“å‚ä¸è€…åŒæ„æ’¤å›æ—¶ï¼Œç»å¸¸éœ€è¦åˆ é™¤æ¨¡å‹å’Œæ•°æ®ï¼‰ã€‚ä¸å—è¿™äº›çº¦æŸçš„åˆæˆæ•°æ®æ˜¯ä¸€ä¸ªå¸å¼•äººçš„æ›¿ä»£æ–¹æ¡ˆã€‚ç¬¬ä¸‰ï¼Œæœ€å…ˆè¿›çš„å•çœ¼åŒ–èº«æ¨¡å‹å¾ˆéš¾æ¨å¹¿åˆ°æ–°çš„è§†è§’å’Œè¡¨æƒ…ï¼Œç¼ºä¹å¼ºå¤§çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ä¸”ç»å¸¸è¿‡åº¦é€‚åº”ç‰¹å®šçš„è§†è§’åˆ†å¸ƒã€‚å—åªæ¥å—åˆæˆæ•°æ®è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»åŒ…å«å„ç§èº«ä»½ã€è¡¨æƒ…å’Œè§†è§’çš„åˆæˆå¤´éƒ¨çš„å¤§å‹æ•°æ®é›†ä¸­å­¦ä¹ å…ˆéªŒæ¨¡å‹ã€‚å‡­å€Ÿå°‘é‡çš„è¾“å…¥å›¾åƒï¼ŒSynShotå¯¹é¢„è®­ç»ƒçš„åˆæˆå…ˆéªŒè¿›è¡Œäº†å¾®è°ƒï¼Œä»¥å¼¥åˆé¢†åŸŸå·®è·ï¼Œå¹¶å»ºç«‹ä¸€ä¸ªé€¼çœŸçš„å¤´éƒ¨åŒ–èº«ï¼Œèƒ½å¤Ÿæ¨å¹¿åˆ°æ–°çš„è¡¨æƒ…å’Œè§†è§’ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸‰ç»´é«˜æ–¯å¹³é“ºå’Œå·ç§¯ç¼–ç å™¨-è§£ç å™¨æ¥æ¨¡æ‹Ÿå¤´éƒ¨åŒ–èº«ï¼Œè¾“å‡ºUVçº¹ç†ç©ºé—´çš„é«˜æ–¯å‚æ•°ã€‚ä¸ºäº†è€ƒè™‘å¤´éƒ¨å„éƒ¨åˆ†çš„å»ºæ¨¡å¤æ‚æ€§ï¼ˆä¾‹å¦‚çš®è‚¤å’Œå¤´å‘ï¼‰ï¼Œæˆ‘ä»¬åœ¨å…ˆéªŒåµŒå…¥ä¸­åŠ å…¥äº†æ˜ç¡®çš„æ§åˆ¶ï¼Œä»¥å®ç°å¯¹æ¯ä¸ªéƒ¨åˆ†åŸå§‹æ•°é‡çš„ä¸Šé‡‡æ ·ã€‚ä¸æœ€å…ˆè¿›çš„å•çœ¼å’ŒåŸºäºGANçš„æ–¹æ³•ç›¸æ¯”ï¼ŒSynShotåœ¨æ–°å‹è§†è§’å’Œè¡¨æƒ…åˆæˆæ–¹é¢æœ‰äº†æ˜¾è‘—æ”¹å–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06903v3">PDF</a> Accepted to CVPR25 Website: <a target="_blank" rel="noopener" href="https://zielon.github.io/synshot/">https://zielon.github.io/synshot/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SynShotæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåˆæˆå…ˆéªŒçš„å°‘æ•°äººå¤´é©¾é©¶å¤´åƒåè½¬æŠ€æœ¯çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•è§£å†³äº†ä¸‰å¤§æŒ‘æˆ˜ï¼šç¼ºä¹å¤šæ ·åºåˆ—å›¾åƒå’Œé«˜å“è´¨è¿½è¸ªç½‘æ ¼çš„è®­ç»ƒæ•°æ®ã€çœŸå®æ•°æ®ä½¿ç”¨å—åˆ°ä¸¥æ ¼ç›‘ç®¡ä»¥åŠå½“å‰å•çœ¼å¤´åƒæ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°æ–°è§†è§’å’Œè¡¨æƒ…ã€‚é€šè¿‡ä»å¤§é‡åˆæˆå¤´åƒæ•°æ®ä¸­å­¦ä¹ å…ˆéªŒæ¨¡å‹ï¼ŒSynShotèƒ½å¤Ÿåœ¨å°‘é‡è¾“å…¥å›¾åƒçš„åŸºç¡€ä¸Šç²¾ç»†è°ƒæ•´é¢„è®­ç»ƒåˆæˆå…ˆéªŒï¼Œä»¥å¼¥è¡¥é¢†åŸŸå·®è·ï¼Œä»è€Œå»ºç«‹èƒ½å¤Ÿæ³›åŒ–åˆ°æ–°è§†è§’å’Œè¡¨æƒ…çš„çœŸå®å¤´åƒæ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´æŠ€æœ¯å’Œå·ç§¯ç¼–ç å™¨è§£ç å™¨è¾“å‡ºUVçº¹ç†ç©ºé—´çš„å‚æ•°ã€‚è€ƒè™‘å¤´éƒ¨ä¸åŒéƒ¨åˆ†çš„å»ºæ¨¡å¤æ‚æ€§ï¼ŒSynShoté‡‡ç”¨å…·æœ‰æ˜¾å¼æ§åˆ¶çš„å…ˆéªŒæ¨¡å‹æ¥æ¨¡æ‹Ÿä¸åŒéƒ¨åˆ†çš„ç»†èŠ‚ç‰¹å¾ã€‚ç›¸è¾ƒäºå…¶ä»–å…ˆè¿›çš„å•çœ¼æ¨¡å‹å’ŒåŸºäºGANçš„æ–¹æ³•ï¼ŒSynShotæ˜¾è‘—æå‡äº†æ–°è§†è§’å’Œè¡¨æƒ…åˆæˆçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SynShotæ˜¯ä¸€ç§é’ˆå¯¹é©¾é©¶å¤´åƒå°‘æ•°æƒ…å†µä¸‹çš„åè½¬æŠ€æœ¯çš„åˆ›æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†ä¸‰å¤§ä¸»è¦é—®é¢˜ï¼šç¼ºä¹å¤šæ ·è®­ç»ƒæ•°æ®ã€çœŸå®æ•°æ®ä½¿ç”¨çš„ç›‘ç®¡æŒ‘æˆ˜ä»¥åŠç°æœ‰æ¨¡å‹åœ¨æ–°è§†è§’å’Œè¡¨æƒ…ä¸Šçš„æ³›åŒ–é—®é¢˜ã€‚</li>
<li>é€šè¿‡å­¦ä¹ ä»å¤§å‹åˆæˆå¤´åƒæ•°æ®é›†çš„å…ˆéªŒæ¨¡å‹ï¼ŒSynShotèƒ½å¤Ÿåˆ©ç”¨å°‘é‡è¾“å…¥å›¾åƒè¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚</li>
<li>SynShoté‡‡ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´æŠ€æœ¯å’Œå·ç§¯ç¼–ç å™¨è§£ç å™¨æ¥å»ºç«‹çœŸå®å¤´åƒæ¨¡å‹ï¼Œå¹¶è¾“å‡ºUVçº¹ç†ç©ºé—´çš„å‚æ•°ã€‚</li>
<li>ä¸ºäº†æ¨¡æ‹Ÿå¤´éƒ¨ä¸åŒéƒ¨åˆ†çš„å¤æ‚æ€§ï¼Œè¯¥æ¨¡å‹æä¾›äº†æ˜¾å¼æ§åˆ¶çš„å…ˆéªŒæ¨¡å‹æ¥ç»†åŒ–ç‰¹å¾è¡¨è¾¾ã€‚</li>
<li>ä¸å…¶ä»–å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼ŒSynShotåœ¨æ–°è§†è§’å’Œè¡¨æƒ…åˆæˆæ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06903">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d0bd43aa12bbc98f505f9bcecfbb35ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c6c599bcc7d81e1ada08fc3bb3d40bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00244ec435f68322181bf9ee515280f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4f38e20d8fd6d3e48e671855e82f200.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-950e2b8244c0fac09198e2129caece27.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2bfaf37bfdfe73c4a5d22dd4d3c8c0a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="ActiveGAMER-Active-GAussian-Mapping-through-Efficient-Rendering"><a href="#ActiveGAMER-Active-GAussian-Mapping-through-Efficient-Rendering" class="headerlink" title="ActiveGAMER: Active GAussian Mapping through Efficient Rendering"></a>ActiveGAMER: Active GAussian Mapping through Efficient Rendering</h2><p><strong>Authors:Liyan Chen, Huangying Zhan, Kevin Chen, Xiangyu Xu, Qingan Yan, Changjiang Cai, Yi Xu</strong></p>
<p>We introduce ActiveGAMER, an active mapping system that utilizes 3D Gaussian Splatting (3DGS) to achieve high-quality, real-time scene mapping and exploration. Unlike traditional NeRF-based methods, which are computationally demanding and restrict active mapping performance, our approach leverages the efficient rendering capabilities of 3DGS, allowing effective and efficient exploration in complex environments. The core of our system is a rendering-based information gain module that dynamically identifies the most informative viewpoints for next-best-view planning, enhancing both geometric and photometric reconstruction accuracy. ActiveGAMER also integrates a carefully balanced framework, combining coarse-to-fine exploration, post-refinement, and a global-local keyframe selection strategy to maximize reconstruction completeness and fidelity. Our system autonomously explores and reconstructs environments with state-of-the-art geometric and photometric accuracy and completeness, significantly surpassing existing approaches in both aspects. Extensive evaluations on benchmark datasets such as Replica and MP3D highlight ActiveGAMERâ€™s effectiveness in active mapping tasks. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ActiveGAMERï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰å®ç°é«˜è´¨é‡ã€å®æ—¶åœºæ™¯æ˜ å°„å’Œæ¢ç´¢çš„ä¸»åŠ¨æ˜ å°„ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„åŸºäºNeRFçš„æ–¹æ³•ä¸åŒï¼Œå®ƒä»¬åœ¨è®¡ç®—ä¸Šéœ€æ±‚è¾ƒé«˜ï¼Œé™åˆ¶äº†ä¸»åŠ¨æ˜ å°„çš„æ€§èƒ½ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨3DGSçš„é«˜æ•ˆæ¸²æŸ“èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆä¸”é«˜æ•ˆçš„æ¢ç´¢ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿçš„æ ¸å¿ƒæ˜¯åŸºäºæ¸²æŸ“çš„ä¿¡æ¯å¢ç›Šæ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤ŸåŠ¨æ€åœ°è¯†åˆ«ä¸‹ä¸€ä¸ªæœ€ä½³è§†è§’çš„è§†ç‚¹ä¿¡æ¯ï¼Œä»è€Œæé«˜å‡ ä½•å’Œå…‰åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚ActiveGAMERè¿˜æ•´åˆäº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„æ¡†æ¶ï¼Œç»“åˆäº†ä»ç²—åˆ°ç»†çš„æ¢ç´¢ã€åæœŸä¼˜åŒ–ä»¥åŠå…¨å±€å±€éƒ¨å…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–é‡å»ºçš„å®Œæ•´æ€§å’Œé€¼çœŸåº¦ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿä»¥æœ€æ–°çš„å‡ ä½•å’Œå…‰åº¦å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ï¼Œè‡ªä¸»æ¢ç´¢å’Œé‡å»ºç¯å¢ƒï¼Œåœ¨è¿™ä¸¤æ–¹é¢éƒ½å¤§å¤§è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚åœ¨Replicaå’ŒMP3Dç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°çªå‡ºäº†ActiveGAMERåœ¨ä¸»åŠ¨æ˜ å°„ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06897v2">PDF</a> Accepted to CVPR2025</p>
<p><strong>Summary</strong></p>
<p>ActiveGAMERç³»ç»Ÿåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æŠ•å½±æŠ€æœ¯å®ç°é«˜è´¨é‡å®æ—¶åœºæ™¯æ˜ å°„å’Œæ¢ç´¢ã€‚ä¸ä¼ ç»Ÿçš„NeRFæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç³»ç»Ÿæ›´é«˜æ•ˆä¸”å…·æœ‰å¼ºå¤§çš„æ¸²æŸ“èƒ½åŠ›ï¼Œå¯åœ¨å¤æ‚ç¯å¢ƒä¸­è¿›è¡Œé«˜æ•ˆæ¢ç´¢ã€‚å…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªåŸºäºæ¸²æŸ“çš„ä¿¡æ¯å¢ç›Šæ¨¡å—ï¼Œèƒ½åŠ¨æ€è¯†åˆ«æœ€å…·ä¿¡æ¯é‡çš„è§†ç‚¹ï¼Œä»è€Œæé«˜å‡ ä½•å’Œå…‰åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿç»“åˆç²—åˆ°ç»†çš„æ¢ç´¢æ–¹å¼ã€åæœŸä¼˜åŒ–å’Œå…¨å±€å±€éƒ¨å…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œæ—¨åœ¨æœ€å¤§åŒ–é‡å»ºçš„å®Œæ•´æ€§å’Œä¿çœŸåº¦ã€‚ActiveGAMERè‡ªä¸»æ¢ç´¢å’Œé‡å»ºç¯å¢ƒï¼Œå‡ ä½•å’Œå…‰åº¦å‡†ç¡®æ€§å’Œå®Œæ•´æ€§å‡è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ActiveGAMERç³»ç»Ÿåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æŠ•å½±ï¼ˆ3DGSï¼‰å®ç°åœºæ™¯æ˜ å°„å’Œæ¢ç´¢ã€‚</li>
<li>è¯¥ç³»ç»Ÿè¾ƒä¼ ç»ŸNeRFæ–¹æ³•æ›´é«˜æ•ˆï¼Œå…·æœ‰å¼ºå¤§çš„æ¸²æŸ“èƒ½åŠ›ã€‚</li>
<li>åŸºäºæ¸²æŸ“çš„ä¿¡æ¯å¢ç›Šæ¨¡å—å¯åŠ¨æ€è¯†åˆ«æœ€å…·ä¿¡æ¯é‡çš„è§†ç‚¹ã€‚</li>
<li>è¯¥ç³»ç»Ÿèƒ½æé«˜å‡ ä½•å’Œå…‰åº¦é‡å»ºçš„å‡†ç¡®æ€§ã€‚</li>
<li>ActiveGAMERç»“åˆç²—åˆ°ç»†çš„æ¢ç´¢æ–¹å¼ã€åæœŸä¼˜åŒ–å’Œå…³é”®å¸§é€‰æ‹©ç­–ç•¥ï¼Œæ—¨åœ¨æœ€å¤§åŒ–é‡å»ºçš„å®Œæ•´æ€§å’Œä¿çœŸåº¦ã€‚</li>
<li>ç³»ç»Ÿè‡ªä¸»æ¢ç´¢å’Œé‡å»ºç¯å¢ƒï¼Œå‡ ä½•å’Œå…‰åº¦å‡†ç¡®æ€§å’Œå®Œæ•´æ€§å‡è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ee2068cd514667fdf8590d3278fd8d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ec14eb4cb933ec03aae06000294635e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-50bac8affe1e91cfbfd2b6b121faa689.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-39039f9725c9caaa76b25907768bed3e.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MaskGaussian-Adaptive-3D-Gaussian-Representation-from-Probabilistic-Masks"><a href="#MaskGaussian-Adaptive-3D-Gaussian-Representation-from-Probabilistic-Masks" class="headerlink" title="MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic   Masks"></a>MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic   Masks</h2><p><strong>Authors:Yifei Liu, Zhihang Zhong, Yifan Zhan, Sheng Xu, Xiao Sun</strong></p>
<p>While 3D Gaussian Splatting (3DGS) has demonstrated remarkable performance in novel view synthesis and real-time rendering, the high memory consumption due to the use of millions of Gaussians limits its practicality. To mitigate this issue, improvements have been made by pruning unnecessary Gaussians, either through a hand-crafted criterion or by using learned masks. However, these methods deterministically remove Gaussians based on a snapshot of the pruning moment, leading to sub-optimized reconstruction performance from a long-term perspective. To address this issue, we introduce MaskGaussian, which models Gaussians as probabilistic entities rather than permanently removing them, and utilize them according to their probability of existence. To achieve this, we propose a masked-rasterization technique that enables unused yet probabilistically existing Gaussians to receive gradients, allowing for dynamic assessment of their contribution to the evolving scene and adjustment of their probability of existence. Hence, the importance of Gaussians iteratively changes and the pruned Gaussians are selected diversely. Extensive experiments demonstrate the superiority of the proposed method in achieving better rendering quality with fewer Gaussians than previous pruning methods, pruning over 60% of Gaussians on average with only a 0.02 PSNR decline. Our code can be found at: <a target="_blank" rel="noopener" href="https://github.com/kaikai23/MaskGaussian">https://github.com/kaikai23/MaskGaussian</a> </p>
<blockquote>
<p>è™½ç„¶3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰åœ¨æ–°å‹è§†å›¾åˆæˆå’Œå®æ—¶æ¸²æŸ“æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½†ç”±äºä½¿ç”¨äº†æ•°ç™¾ä¸‡ä¸ªé«˜æ–¯ï¼Œå…¶é«˜å†…å­˜æ¶ˆè€—é™åˆ¶äº†å®ç”¨æ€§ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå·²ç»é€šè¿‡åˆ é™¤ä¸å¿…è¦çš„é«˜æ–¯è¿›è¡Œäº†æ”¹è¿›ï¼Œæ–¹æ³•åŒ…æ‹¬ä½¿ç”¨æ‰‹å·¥åˆ¶å®šçš„æ ‡å‡†æˆ–ä½¿ç”¨å­¦ä¹ åˆ°çš„æ©è†œã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ ¹æ®åˆ é™¤æ—¶åˆ»çš„å¿«ç…§ç¡®å®šæ€§åœ°åˆ é™¤é«˜æ–¯ï¼Œä»é•¿è¿œæ¥çœ‹å¯¼è‡´é‡å»ºæ€§èƒ½ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†MaskGaussianï¼Œå®ƒå°†é«˜æ–¯å»ºæ¨¡ä¸ºæ¦‚ç‡å®ä½“ï¼Œè€Œä¸æ˜¯æ°¸ä¹…åˆ é™¤å®ƒä»¬ï¼Œå¹¶æ ¹æ®å…¶å­˜åœ¨çš„æ¦‚ç‡æ¥ä½¿ç”¨å®ƒä»¬ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ©è†œæ …æ ¼åŒ–æŠ€æœ¯ï¼Œä½¿æœªä½¿ç”¨ä½†æ¦‚ç‡å­˜åœ¨çš„é«˜æ–¯èƒ½å¤Ÿæ¥å—æ¢¯åº¦ï¼Œä»è€ŒåŠ¨æ€è¯„ä¼°å®ƒä»¬å¯¹ä¸æ–­å˜åŒ–åœºæ™¯çš„è´¡çŒ®å¹¶è°ƒæ•´å…¶å­˜åœ¨çš„æ¦‚ç‡ã€‚å› æ­¤ï¼Œé«˜æ–¯çš„é‡è¦æ€§ä¼šè¿­ä»£åœ°æ”¹å˜ï¼Œè¢«åˆ é™¤çš„é«˜æ–¯é€‰æ‹©ä¹Ÿä¼šå¤šæ ·åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ä½¿ç”¨è¾ƒå°‘çš„é«˜æ–¯å®ç°æ›´å¥½çš„æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºä»¥å‰çš„é«˜æ–¯åˆ é™¤æ–¹æ³•ï¼Œå¹³å‡åˆ é™¤è¶…è¿‡60%çš„é«˜æ–¯ï¼Œè€ŒPSNRä»…ä¸‹é™0.02ã€‚æˆ‘ä»¬çš„ä»£ç å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/kaikai23/MaskGaussian">https://github.com/kaikai23/MaskGaussian</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20522v2">PDF</a> CVPR 2025; Project page:<a target="_blank" rel="noopener" href="https://maskgaussian.github.io/">https://maskgaussian.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰åœ¨çœŸå®åœºæ™¯é‡å»ºä¸­å­˜åœ¨çš„é—®é¢˜æ‰€æå‡ºçš„ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œåä¸ºMaskGaussianã€‚æ­¤æ–¹æ¡ˆé€šè¿‡å°†é«˜æ–¯è§†ä¸ºæ¦‚ç‡å®ä½“è€Œéæ°¸ä¹…ç§»é™¤ï¼Œåˆ©ç”¨æ©è†œæŠ€æœ¯åŠ¨æ€è¯„ä¼°é«˜æ–¯å¯¹åœºæ™¯å˜åŒ–çš„è´¡çŒ®ï¼Œå¹¶è°ƒæ•´å…¶å­˜åœ¨æ¦‚ç‡ã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„ä¿®å‰ªæ–¹æ³•ï¼ŒMaskGaussianèƒ½åœ¨å‡å°‘é«˜æ–¯ä½¿ç”¨æ•°é‡çš„åŒæ—¶ä¿æŒæˆ–æé«˜æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSåœ¨æ–°å‹è§†è§’åˆæˆå’Œå®æ—¶æ¸²æŸ“ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å…¶é«˜å†…å­˜æ¶ˆè€—é™åˆ¶äº†å®é™…åº”ç”¨ã€‚</li>
<li>å½“å‰æ”¹å–„æ–¹æ³•ä¸»è¦é€šè¿‡ä¿®å‰ªä¸å¿…è¦çš„Gaussianså®ç°ï¼Œä½†è¿™äº›æ–¹æ³•åŸºäºå¿«ç…§æ—¶åˆ»ç¡®å®šæ€§åœ°ç§»é™¤Gaussiansï¼Œä»é•¿è¿œè§’åº¦çœ‹ä¼šå¯¼è‡´é‡å»ºæ€§èƒ½ä¸è¶³ã€‚</li>
<li>MaskGaussianæ–¹æ¡ˆé€šè¿‡å°†Gaussiansè§†ä¸ºæ¦‚ç‡å®ä½“è§£å†³æ­¤é—®é¢˜ï¼Œåˆ©ç”¨æ©è†œæŠ€æœ¯åŠ¨æ€è¯„ä¼°Gaussiansçš„è´¡çŒ®å¹¶è°ƒæ•´å…¶å­˜åœ¨æ¦‚ç‡ã€‚</li>
<li>MaskGaussiané‡‡ç”¨äº†ä¸€ç§æ–°å‹çš„masked-rasterizationæŠ€æœ¯ï¼Œå…è®¸æ¦‚ç‡å­˜åœ¨çš„æœªä½¿ç”¨Gaussiansæ¥æ”¶æ¢¯åº¦ï¼Œä»¥ä¾¿åŠ¨æ€è¯„ä¼°å…¶å¯¹åœºæ™¯å˜åŒ–çš„è´¡çŒ®ã€‚</li>
<li>MaskGaussianæ–¹æ³•èƒ½å¤Ÿåœ¨å‡å°‘Gaussiansä½¿ç”¨æ•°é‡çš„åŒæ—¶ä¿æŒæˆ–æé«˜æ¸²æŸ“è´¨é‡ï¼Œå¹³å‡ä¿®å‰ªè¶…è¿‡60%çš„Gaussiansï¼ŒåŒæ—¶ä»…é™ä½0.02 PSNRã€‚</li>
<li>MaskGaussiançš„ä»£ç å¯åœ¨å…¬å¼€ä»£ç åº“ä¸­æ‰¾åˆ°ï¼Œä¸ºç›¸å…³ç ”ç©¶å’Œåº”ç”¨æä¾›äº†ä¾¿åˆ©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20522">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6c159007779100ceabe63080ebe74665.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e527205d731c6c386552e2ea38669f99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c2d0765651b6968a22fd7d2ceb6ec2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48ceff63829ec22e11fbf3b662df60df.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="6DOPE-GS-Online-6D-Object-Pose-Estimation-using-Gaussian-Splatting"><a href="#6DOPE-GS-Online-6D-Object-Pose-Estimation-using-Gaussian-Splatting" class="headerlink" title="6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting"></a>6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting</h2><p><strong>Authors:Yufeng Jin, Vignesh Prasad, Snehal Jauhri, Mathias Franzius, Georgia Chalvatzaki</strong></p>
<p>Efficient and accurate object pose estimation is an essential component for modern vision systems in many applications such as Augmented Reality, autonomous driving, and robotics. While research in model-based 6D object pose estimation has delivered promising results, model-free methods are hindered by the high computational load in rendering and inferring consistent poses of arbitrary objects in a live RGB-D video stream. To address this issue, we present 6DOPE-GS, a novel method for online 6D object pose estimation &amp; tracking with a single RGB-D camera by effectively leveraging advances in Gaussian Splatting. Thanks to the fast differentiable rendering capabilities of Gaussian Splatting, 6DOPE-GS can simultaneously optimize for 6D object poses and 3D object reconstruction. To achieve the necessary efficiency and accuracy for live tracking, our method uses incremental 2D Gaussian Splatting with an intelligent dynamic keyframe selection procedure to achieve high spatial object coverage and prevent erroneous pose updates. We also propose an opacity statistic-based pruning mechanism for adaptive Gaussian density control, to ensure training stability and efficiency. We evaluate our method on the HO3D and YCBInEOAT datasets and show that 6DOPE-GS matches the performance of state-of-the-art baselines for model-free simultaneous 6D pose tracking and reconstruction while providing a 5$\times$ speedup. We also demonstrate the methodâ€™s suitability for live, dynamic object tracking and reconstruction in a real-world setting. </p>
<blockquote>
<p>é«˜æ•ˆä¸”ç²¾ç¡®çš„ç›®æ ‡å§¿æ€ä¼°è®¡æ˜¯ç°ä»£è§†è§‰ç³»ç»Ÿåœ¨è®¸å¤šåº”ç”¨ä¸­çš„å…³é”®ç»„ä»¶ï¼Œä¾‹å¦‚å¢å¼ºç°å®ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯ã€‚å°½ç®¡åŸºäºæ¨¡å‹çš„6Då¯¹è±¡å§¿æ€ä¼°è®¡ç ”ç©¶å·²ç»å–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†æ— æ¨¡å‹æ–¹æ³•å—åˆ°æ¸²æŸ“å’Œæ¨æ–­å®æ—¶RGB-Dè§†é¢‘æµä¸­ä»»æ„å¯¹è±¡çš„ä¸€è‡´å§¿æ€çš„è®¡ç®—è´Ÿè½½çš„é˜»ç¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†6DOPE-GSï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨é«˜æ–¯å¹³é“ºæŠ€æœ¯çš„æ–°åœ¨çº¿6Då¯¹è±¡å§¿æ€ä¼°è®¡å’Œè·Ÿè¸ªæ–¹æ³•ã€‚å¾—ç›Šäºé«˜æ–¯å¹³é“ºçš„å¿«é€Ÿå¯å¾®åˆ†æ¸²æŸ“èƒ½åŠ›ï¼Œ6DOPE-GSå¯ä»¥åŒæ—¶ä¼˜åŒ–6Då¯¹è±¡å§¿æ€å’Œ3Då¯¹è±¡é‡å»ºã€‚ä¸ºäº†å®ç°å®æ—¶è·Ÿè¸ªçš„å¿…è¦æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨å¢é‡2Dé«˜æ–¯å¹³é“ºå’Œæ™ºèƒ½åŠ¨æ€å…³é”®å¸§é€‰æ‹©ç¨‹åºï¼Œä»¥å®ç°å¯¹è±¡çš„é«˜ç©ºé—´è¦†ç›–å¹¶é˜²æ­¢é”™è¯¯çš„å§¿æ€æ›´æ–°ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºä¸é€æ˜åº¦ç»Ÿè®¡çš„ä¿®å‰ªæœºåˆ¶ï¼Œç”¨äºè‡ªé€‚åº”é«˜æ–¯å¯†åº¦æ§åˆ¶ï¼Œä»¥ç¡®ä¿è®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡ã€‚æˆ‘ä»¬åœ¨HO3Då’ŒYCBInEOATæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œ6DOPE-GSåœ¨æ— éœ€æ¨¡å‹çš„åŒæ—¶å®ç°6Då§¿æ€è·Ÿè¸ªå’Œé‡å»ºæ–¹é¢çš„æ€§èƒ½ä¸æœ€æ–°åŸºçº¿ç›¸åŒ¹é…ï¼ŒåŒæ—¶æä¾›äº†5å€çš„åŠ é€Ÿã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†è¯¥æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œå®æ—¶åŠ¨æ€å¯¹è±¡è·Ÿè¸ªå’Œé‡å»ºçš„é€‚ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01543v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    é«˜æ•ˆå‡†ç¡®çš„ç‰©ä½“å§¿æ€ä¼°è®¡æ˜¯å¢å¼ºç°å®ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯ç­‰å¤šä¸ªç°ä»£è§†è§‰ç³»ç»Ÿåº”ç”¨ä¸­çš„æ ¸å¿ƒç»„ä»¶ã€‚é’ˆå¯¹åŸºäºæ¨¡å‹çš„6Dç‰©ä½“å§¿æ€ä¼°è®¡æ¨¡å‹å·²å–å¾—è‰¯å¥½ç»“æœï¼Œä½†æ— æ¨¡å‹æ–¹æ³•å› åœ¨å®æ—¶RGB-Dè§†é¢‘æµä¸­å‘ˆç°å’Œæ¨æ–­ä»»æ„ç‰©ä½“çš„ä¸€è‡´æ€§å§¿æ€çš„è®¡ç®—è´Ÿè·è¾ƒé«˜è€Œå—åˆ°é˜»ç¢ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åä¸º6DOPE-GSçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œå®ç°åˆ©ç”¨å•ä¸ªRGB-Dç›¸æœºçš„åœ¨çº¿6Dç‰©ä½“å§¿æ€ä¼°è®¡ä¸è·Ÿè¸ªã€‚ç”±äºé«˜æ–¯æ¶‚æŠ¹çš„å¿«é€Ÿå¯å¾®åˆ†æ¸²æŸ“èƒ½åŠ›ï¼Œ6DOPE-GSå¯ä»¥åŒæ—¶ä¼˜åŒ–6Dç‰©ä½“å§¿æ€å’Œ3Dç‰©ä½“é‡å»ºã€‚ä¸ºå®ç°å®æ—¶è·Ÿè¸ªæ‰€éœ€çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨å¢é‡å¼äºŒç»´é«˜æ–¯æ¶‚æŠ¹å’Œæ™ºèƒ½åŠ¨æ€å…³é”®å¸§é€‰æ‹©ç¨‹åºï¼Œä»¥å®ç°é«˜ç©ºé—´ç‰©ä½“è¦†ç›–å¹¶é˜²æ­¢é”™è¯¯çš„å§¿æ€æ›´æ–°ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºä¸é€æ˜åº¦ç»Ÿè®¡çš„ä¿®å‰ªæœºåˆ¶ï¼Œä»¥ç¡®ä¿è®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡ï¼Œå®ç°å¯¹é«˜æ–¯å¯†åº¦çš„è‡ªé€‚åº”æ§åˆ¶ã€‚æˆ‘ä»¬åœ¨HO3Då’ŒYCBInEOATæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¡¨æ˜6DOPE-GSåœ¨æ— éœ€æ¨¡å‹çš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„6Då§¿æ€è·Ÿè¸ªå’Œé‡å»ºçš„åŒ¹é…æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†5å€çš„é€Ÿåº¦æå‡ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­çš„å®æ—¶åŠ¨æ€ç‰©ä½“è·Ÿè¸ªå’Œé‡å»ºçš„é€‚ç”¨æ€§ã€‚</p>
<p><strong>è¦ç‚¹è§£æ</strong></p>
<ol>
<li>å¯¹è±¡å§¿æ€ä¼°è®¡æ˜¯ç°ä»£è§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œåº”ç”¨äºå¤šç§é¢†åŸŸå¦‚å¢å¼ºç°å®ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯ã€‚</li>
<li>å½“å‰æ¨¡å‹åŸºäº6Dçš„å¯¹è±¡å§¿æ€ä¼°è®¡å·²å–å¾—è‰¯å¥½è¿›å±•ï¼Œä½†æ— æ¨¡å‹æ–¹æ³•çš„å®æ—¶æ€§èƒ½å—åˆ°è®¡ç®—è´Ÿè·çš„é™åˆ¶ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†åä¸º6DOPE-GSçš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯å®ç°RGB-Dç›¸æœºçš„åœ¨çº¿6Då¯¹è±¡å§¿æ€ä¼°è®¡ä¸è·Ÿè¸ªã€‚</li>
<li>6DOPE-GSç»“åˆäº†ä¼˜åŒ–çš„å¯¹è±¡å§¿æ€ä¸3Då¯¹è±¡é‡å»ºä»»åŠ¡ï¼Œè¿™æ˜¯ç”±äºå…¶å¯å¾®åˆ†æ¸²æŸ“èƒ½åŠ›çš„æ”¯æŒã€‚</li>
<li>æ–¹æ³•é‡‡ç”¨å¢é‡å¼äºŒç»´é«˜æ–¯æ¶‚æŠ¹ä¸æ™ºèƒ½åŠ¨æ€å…³é”®å¸§é€‰æ‹©ï¼Œç¡®ä¿é«˜æ•ˆä¸”å‡†ç¡®çš„å®æ—¶è·Ÿè¸ªæ€§èƒ½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºä¸é€æ˜åº¦ç»Ÿè®¡çš„ä¿®å‰ªæœºåˆ¶æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹å’Œæé«˜æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01543">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a65fb6c94670d3a1fd3438faa726a2b9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea7f7acca8d7a762c0918f82eae64394.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd973662a99379e3b95044debf0a6969.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LVSM-A-Large-View-Synthesis-Model-with-Minimal-3D-Inductive-Bias"><a href="#LVSM-A-Large-View-Synthesis-Model-with-Minimal-3D-Inductive-Bias" class="headerlink" title="LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias"></a>LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</h2><p><strong>Authors:Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi, Tianyuan Zhang, Fujun Luan, Noah Snavely, Zexiang Xu</strong></p>
<p>We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations. Both models bypass the 3D inductive biases used in previous methods â€“ from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) â€“ addressing novel view synthesis with a fully data-driven approach. While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality. Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs). Please see our website for more details: <a target="_blank" rel="noopener" href="https://haian-jin.github.io/projects/LVSM/">https://haian-jin.github.io/projects/LVSM/</a> . </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†å¤§å‹è§†å›¾åˆæˆæ¨¡å‹ï¼ˆLVSMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºtransformerçš„å¯æ‰©å±•å’Œé€šç”¨æ–°å‹è§†å›¾åˆæˆæ–¹æ³•ï¼Œå¯ä»ç¨€ç–è§†å›¾è¾“å…¥ä¸­è¿›è¡Œåˆæˆã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸¤ç§æ¶æ„ï¼šï¼ˆ1ï¼‰ç¼–ç å™¨-è§£ç å™¨LVSMï¼Œå®ƒå°†è¾“å…¥å›¾åƒæ ‡è®°ç¼–ç ä¸ºå›ºå®šæ•°é‡çš„1Dæ½œåœ¨æ ‡è®°ï¼Œä½œä¸ºå®Œå…¨å­¦ä¹ çš„åœºæ™¯è¡¨ç¤ºï¼Œå¹¶ä»ä¸­è§£ç å‡ºæ–°çš„è§†å›¾å›¾åƒï¼›ï¼ˆ2ï¼‰ä»…è§£ç å™¨LVSMï¼Œå®ƒç›´æ¥å°†è¾“å…¥å›¾åƒæ˜ å°„åˆ°æ–°çš„è§†å›¾è¾“å‡ºï¼Œå®Œå…¨æ¶ˆé™¤äº†ä¸­é—´åœºæ™¯è¡¨ç¤ºã€‚ä¸¤ç§æ¨¡å‹éƒ½ç»•è¿‡äº†ä»¥å‰æ–¹æ³•ä¸­ä½¿ç”¨çš„3Då½’çº³åè§ï¼Œä»3Dè¡¨ç¤ºï¼ˆä¾‹å¦‚NeRFã€3DGSï¼‰åˆ°ç½‘ç»œè®¾è®¡ï¼ˆä¾‹å¦‚ææŠ•å½±ã€å¹³é¢æ‰«æï¼‰ï¼Œé€šè¿‡ä¸€ç§å®Œå…¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•è§£å†³æ–°çš„è§†å›¾åˆæˆé—®é¢˜ã€‚ç”±äºç‹¬ç«‹çš„æ½œåœ¨è¡¨ç¤ºï¼Œç¼–ç å™¨-è§£ç å™¨æ¨¡å‹æä¾›æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œè€Œä»…è§£ç å™¨LVSMåœ¨è´¨é‡ã€å¯æ‰©å±•æ€§å’Œé›¶æ ·æœ¬æ³›åŒ–æ–¹é¢è¡¨ç°æ›´ä¼˜è¶Šï¼Œæ¯”å…ˆå‰æœ€å…ˆè¿›çš„æ–¹æ³•é«˜å‡º1.5è‡³3.5 dB PSNRã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œä¸¤ç§LVSMå˜ä½“éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ–°å‹è§†å›¾åˆæˆè´¨é‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ç”šè‡³åœ¨å‡å°‘çš„è®¡ç®—èµ„æºï¼ˆ1-2ä¸ªGPUï¼‰çš„æƒ…å†µä¸‹ä¹Ÿè¶…è¿‡äº†ä»¥å‰çš„æ‰€æœ‰æ–¹æ³•ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è§æˆ‘ä»¬çš„ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://haian-jin.github.io/projects/LVSM/%E3%80%82">https://haian-jin.github.io/projects/LVSM/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17242v2">PDF</a> project page: <a target="_blank" rel="noopener" href="https://haian-jin.github.io/projects/LVSM/">https://haian-jin.github.io/projects/LVSM/</a></p>
<p><strong>Summary</strong><br>     æå‡ºLarge View Synthesis Modelï¼ˆLVSMï¼‰ï¼Œé‡‡ç”¨æ–°å‹transformeræŠ€æœ¯ï¼Œå®ç°ç¨€ç–è§†è§’è¾“å…¥çš„å¯æ‰©å±•å’Œé€šç”¨åŒ–æ–°è§†è§’åˆæˆã€‚åŒ…å«ä¸¤ç§æ¶æ„ï¼šä¸€ç§ä¸ºç¼–ç è§£ç å™¨LVSMï¼Œå°†è¾“å…¥å›¾åƒæ ‡è®°ç¼–ç ä¸ºå›ºå®šæ•°é‡çš„1Dæ½œåœ¨æ ‡è®°ï¼Œä½œä¸ºå®Œå…¨å­¦ä¹ çš„åœºæ™¯è¡¨ç¤ºï¼Œå¹¶ä»ä¸­è§£ç å‡ºæ–°è§†è§’å›¾åƒï¼›å¦ä¸€ç§ä¸ºä»…è§£ç å™¨LVSMï¼Œç›´æ¥å°†è¾“å…¥å›¾åƒæ˜ å°„åˆ°æ–°è§†è§’è¾“å‡ºï¼Œæ— éœ€ä¸­é—´åœºæ™¯è¡¨ç¤ºã€‚ä¸¤ç§æ¨¡å‹å‡ç»•è¿‡ä¹‹å‰æ–¹æ³•ä½¿ç”¨çš„3Då½’çº³åè§ï¼Œé‡‡ç”¨å…¨æ•°æ®é©±åŠ¨æ–¹æ³•è§£å†³æ–°è§†è§’åˆæˆé—®é¢˜ã€‚ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹å…·æœ‰æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œè€Œä»…è§£ç å™¨LVSMåœ¨è´¨é‡ã€å¯æ‰©å±•æ€§å’Œé›¶é•œå¤´æ³›åŒ–æ–¹é¢æ›´èƒœä¸€ç­¹ï¼Œè¾ƒä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†1.5è‡³3.5 dB PSNRã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œä¸¤ç§LVSMå˜ä½“å‡å®ç°äº†æœ€æ–°é¢–çš„è§†å›¾åˆæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºLarge View Synthesis Modelï¼ˆLVSMï¼‰ï¼ŒåŸºäºtransformerçš„æ–°æ–¹æ³•ç”¨äºç¨€ç–è§†è§’è¾“å…¥çš„æ–°è§†è§’åˆæˆã€‚</li>
<li>åŒ…å«ä¸¤ç§æ¶æ„ï¼šç¼–ç è§£ç å™¨LVSMå’Œä»…è§£ç å™¨LVSMã€‚</li>
<li>ç¼–ç è§£ç å™¨LVSMé€šè¿‡ç¼–ç è¾“å…¥å›¾åƒæ ‡è®°åˆ°æ½œåœ¨æ ‡è®°æ¥å®ç°åœºæ™¯è¡¨ç¤ºå’Œæ–°è§†è§’å›¾åƒè§£ç ã€‚</li>
<li>ä»…è§£ç å™¨LVSMç›´æ¥æ˜ å°„è¾“å…¥å›¾åƒåˆ°æ–°è§†è§’è¾“å‡ºï¼Œæ— éœ€ä¸­é—´åœºæ™¯è¡¨ç¤ºï¼Œå®ç°é«˜è´¨é‡ã€å¯æ‰©å±•æ€§å’Œé›¶é•œå¤´æ³›åŒ–ã€‚</li>
<li>LVSMæ¨¡å‹è¾ƒä¹‹å‰æ–¹æ³•æé«˜äº†1.5è‡³3.5 dB PSNRï¼Œå®ç°äº†å…ˆè¿›çš„æ–°è§†è§’åˆæˆè´¨é‡ã€‚</li>
<li>ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼Œä¸¤ç§LVSMå˜ä½“åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17242">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f7b1bf9505401c3d0a1111802cf0cf97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e15f469bbc5c7833fc0865375a2de227.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a44391e0a1ae34bf3c6068ea0f679e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01aa542831a2e6276ccfec73c493690f.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="UniGS-Modeling-Unitary-3D-Gaussians-for-Novel-View-Synthesis-from-Sparse-view-Images"><a href="#UniGS-Modeling-Unitary-3D-Gaussians-for-Novel-View-Synthesis-from-Sparse-view-Images" class="headerlink" title="UniGS: Modeling Unitary 3D Gaussians for Novel View Synthesis from   Sparse-view Images"></a>UniGS: Modeling Unitary 3D Gaussians for Novel View Synthesis from   Sparse-view Images</h2><p><strong>Authors:Jiamin Wu, Kenkun Liu, Yukai Shi, Xiaoke Jiang, Yuan Yao, Lei Zhang</strong></p>
<p>In this work, we introduce UniGS, a novel 3D Gaussian reconstruction and novel view synthesis model that predicts a high-fidelity representation of 3D Gaussians from arbitrary number of posed sparse-view images. Previous methods often regress 3D Gaussians locally on a per-pixel basis for each view and then transfer them to world space and merge them through point concatenation. In contrast, Our approach involves modeling unitary 3D Gaussians in world space and updating them layer by layer. To leverage information from multi-view inputs for updating the unitary 3D Gaussians, we develop a DETR (DEtection TRansformer)-like framework, which treats 3D Gaussians as queries and updates their parameters by performing multi-view cross-attention (MVDFA) across multiple input images, which are treated as keys and values. This approach effectively avoids &#96;ghostingâ€™ issue and allocates more 3D Gaussians to complex regions. Moreover, since the number of 3D Gaussians used as decoder queries is independent of the number of input views, our method allows arbitrary number of multi-view images as input without causing memory explosion or requiring retraining. Extensive experiments validate the advantages of our approach, showcasing superior performance over existing methods quantitatively (improving PSNR by 4.2 dB when trained on Objaverse and tested on the GSO benchmark) and qualitatively. The code will be released at <a target="_blank" rel="noopener" href="https://github.com/jwubz123/UNIG">https://github.com/jwubz123/UNIG</a>. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†UniGSï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„3Dé«˜æ–¯é‡å»ºå’Œè§†å›¾åˆæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿä»ä»»æ„æ•°é‡çš„å®šä½ç¨€ç–è§†å›¾å›¾åƒé¢„æµ‹å‡ºé«˜ä¿çœŸåº¦çš„3Dé«˜æ–¯è¡¨ç¤ºã€‚ä¹‹å‰çš„æ–¹æ³•é€šå¸¸åœ¨æ¯ä¸ªè§†å›¾çš„åƒç´ åŸºç¡€ä¸Šå±€éƒ¨å›å½’3Dé«˜æ–¯ï¼Œç„¶åå°†å®ƒä»¬è½¬ç§»åˆ°ä¸–ç•Œç©ºé—´å¹¶é€šè¿‡ç‚¹è¿æ¥è¿›è¡Œåˆå¹¶ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¯åœ¨ä¸–ç•Œç©ºé—´ä¸­å»ºç«‹å•ä½3Dé«˜æ–¯æ¨¡å‹ï¼Œå¹¶é€å±‚æ›´æ–°å®ƒä»¬ã€‚ä¸ºäº†åˆ©ç”¨æ¥è‡ªå¤šè§†å›¾è¾“å…¥çš„çš„ä¿¡æ¯æ¥æ›´æ–°å•ä½3Dé«˜æ–¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç±»ä¼¼äºDETRï¼ˆæ£€æµ‹è½¬æ¢å™¨ï¼‰çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†3Dé«˜æ–¯ä½œä¸ºæŸ¥è¯¢ï¼Œé€šè¿‡å¤šè§†å›¾äº¤å‰æ³¨æ„åŠ›ï¼ˆMVDFAï¼‰åœ¨å¤šä¸ªè¾“å…¥å›¾åƒï¼ˆä½œä¸ºé”®å’Œå€¼ï¼‰ä¹‹é—´æ›´æ–°å…¶å‚æ•°ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆåœ°é¿å…äº†â€œé‡å½±â€é—®é¢˜ï¼Œå¹¶å°†æ›´å¤šçš„3Dé«˜æ–¯åˆ†é…ç»™å¤æ‚åŒºåŸŸã€‚æ­¤å¤–ï¼Œç”±äºç”¨ä½œè§£ç å™¨æŸ¥è¯¢çš„3Dé«˜æ–¯çš„æ•°é‡ä¸è¾“å…¥è§†å›¾çš„æ•°é‡æ— å…³ï¼Œå› æ­¤æˆ‘ä»¬çš„æ–¹æ³•å…è®¸ä»»æ„æ•°é‡çš„å¤šè§†å›¾å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè€Œä¸ä¼šå¯¼è‡´å†…å­˜çˆ†ç‚¸æˆ–éœ€è¦é‡æ–°è®­ç»ƒã€‚å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œåœ¨å®šé‡ä¸Šå±•ç¤ºäº†ä¼˜äºç°æœ‰æ–¹æ³•çš„è¡¨ç°ï¼ˆåœ¨Objaverseä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨GSOåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œæµ‹è¯•æ—¶ï¼Œå³°å€¼ä¿¡å™ªæ¯”æé«˜äº†4.2 dBï¼‰ï¼Œå¹¶åœ¨å®šæ€§ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä»£ç å°†å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/jwubz123/UNIG%E3%80%82">https://github.com/jwubz123/UNIGã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13195v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†UniGSï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„3Dé«˜æ–¯é‡å»ºå’Œè§†å›¾åˆæˆæ¨¡å‹ï¼Œå¯ä»ä»»æ„æ•°é‡çš„å®šä½ç¨€ç–è§†å›¾å›¾åƒé¢„æµ‹é«˜ä¿çœŸ3Dé«˜æ–¯è¡¨ç¤ºã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒUniGSç›´æ¥åœ¨ä¸–ç•Œç©ºé—´ä¸­å¯¹å•ä½3Dé«˜æ–¯è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶é€å±‚æ›´æ–°å®ƒä»¬ã€‚ä¸ºè§£å†³å•ä½3Dé«˜æ–¯æ›´æ–°çš„ä¿¡æ¯èåˆé—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†DETRï¼ˆæ£€æµ‹è½¬æ¢å™¨ï¼‰æ¡†æ¶ï¼Œå°†3Dé«˜æ–¯è§†ä¸ºæŸ¥è¯¢ï¼Œé€šè¿‡å¤šè§†å›¾äº¤å‰æ³¨æ„åŠ›ï¼ˆMVDFAï¼‰åœ¨å¤šä¸ªè¾“å…¥å›¾åƒï¼ˆè§†ä¸ºé”®å’Œå€¼ï¼‰ä¹‹é—´æ›´æ–°å…¶å‚æ•°ã€‚æ­¤æ–¹æ³•æœ‰æ•ˆé¿å…äº†â€œå¹½çµâ€é—®é¢˜ï¼Œå¹¶åœ¨å¤æ‚åŒºåŸŸåˆ†é…äº†æ›´å¤šçš„3Dé«˜æ–¯ã€‚ç”±äºç”¨ä½œè§£ç å™¨æŸ¥è¯¢çš„3Dé«˜æ–¯æ•°é‡ä¸è¾“å…¥è§†å›¾çš„æ•°é‡æ— å…³ï¼Œå› æ­¤è¯¥æ–¹æ³•å…è®¸ä»»æ„æ•°é‡çš„å¤šè§†å›¾å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè€Œä¸ä¼šé€ æˆå†…å­˜çˆ†ç‚¸æˆ–éœ€è¦é‡æ–°è®­ç»ƒã€‚å¤§é‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•ç›¸è¾ƒäºç°æœ‰æŠ€æœ¯çš„ä¼˜åŠ¿ï¼Œåœ¨å®šæ€§å’Œå®šé‡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ˆåœ¨Objaverseä¸Šè®­ç»ƒååœ¨GSOåŸºå‡†æµ‹è¯•ä¸Šæé«˜äº†4.2 dBçš„PSNRï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UniGSæ˜¯ä¸€ä¸ªæ–°å‹çš„3Dé«˜æ–¯é‡å»ºå’Œè§†å›¾åˆæˆæ¨¡å‹ï¼Œå¯ä»ä»»æ„æ•°é‡çš„å®šä½ç¨€ç–è§†å›¾å›¾åƒé¢„æµ‹é«˜ä¿çœŸ3Dé«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>UniGSåœ¨ä¸–ç•Œç©ºé—´ä¸­å¯¹å•ä½3Dé«˜æ–¯è¿›è¡Œå»ºæ¨¡å¹¶é€å±‚æ›´æ–°ï¼Œé¿å…äº†ä»¥å¾€æ–¹æ³•ä¸­å±€éƒ¨å›å½’å’Œåˆå¹¶çš„å¤æ‚æ€§ã€‚</li>
<li>å¼•å…¥DETRæ¡†æ¶æ¥å¤„ç†å¤šè§†å›¾è¾“å…¥ï¼Œé€šè¿‡å¤šè§†å›¾äº¤å‰æ³¨æ„åŠ›ï¼ˆMVDFAï¼‰æ›´æ–°å•ä½3Dé«˜æ–¯å‚æ•°ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†â€œå¹½çµâ€é—®é¢˜ï¼Œå¹¶åœ¨å¤æ‚åŒºåŸŸåˆ†é…æ›´å¤š3Dé«˜æ–¯ã€‚</li>
<li>æ¨¡å‹å…è®¸ä½¿ç”¨ä»»æ„æ•°é‡çš„å¤šè§†å›¾å›¾åƒä½œä¸ºè¾“å…¥ï¼Œä¸”ä¸ä¼šå¢åŠ å†…å­˜éœ€æ±‚æˆ–éœ€è¦é‡æ–°è®­ç»ƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒUniGSåœ¨å®šæ€§å’Œå®šé‡ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨GSOåŸºå‡†æµ‹è¯•ä¸Šçš„PSNRæé«˜äº†4.2 dBã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13195">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d95c48c9d91d1ae489a55780fad2cd3e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e7ed73be7ed140792089c191effc795a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2c3a71be13f5e78e144817960f8af8ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-52176f05c59b9e56f9080002def9fc79.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Gaussian-Eigen-Models-for-Human-Heads"><a href="#Gaussian-Eigen-Models-for-Human-Heads" class="headerlink" title="Gaussian Eigen Models for Human Heads"></a>Gaussian Eigen Models for Human Heads</h2><p><strong>Authors:Wojciech Zielonka, Timo Bolkart, Thabo Beeler, Justus Thies</strong></p>
<p>Current personalized neural head avatars face a trade-off: lightweight models lack detail and realism, while high-quality, animatable avatars require significant computational resources, making them unsuitable for commodity devices. To address this gap, we introduce Gaussian Eigen Models (GEM), which provide high-quality, lightweight, and easily controllable head avatars. GEM utilizes 3D Gaussian primitives for representing the appearance combined with Gaussian splatting for rendering. Building on the success of mesh-based 3D morphable face models (3DMM), we define GEM as an ensemble of linear eigenbases for representing the head appearance of a specific subject. In particular, we construct linear bases to represent the position, scale, rotation, and opacity of the 3D Gaussians. This allows us to efficiently generate Gaussian primitives of a specific head shape by a linear combination of the basis vectors, only requiring a low-dimensional parameter vector that contains the respective coefficients. We propose to construct these linear bases (GEM) by distilling high-quality compute-intense CNN-based Gaussian avatar models that can generate expression-dependent appearance changes like wrinkles. These high-quality models are trained on multi-view videos of a subject and are distilled using a series of principal component analyses. Once we have obtained the bases that represent the animatable appearance space of a specific human, we learn a regressor that takes a single RGB image as input and predicts the low-dimensional parameter vector that corresponds to the shown facial expression. In a series of experiments, we compare GEMâ€™s self-reenactment and cross-person reenactment results to state-of-the-art 3D avatar methods, demonstrating GEMâ€™s higher visual quality and better generalization to new expressions. </p>
<blockquote>
<p>å½“å‰ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«é¢ä¸´æƒè¡¡ï¼šè½»é‡çº§æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ„Ÿï¼Œè€Œé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„åŒ–èº«éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºï¼Œä½¿å…¶ä¸é€‚åˆæ™®é€šè®¾å¤‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†é«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰ï¼Œå®ƒæä¾›é«˜è´¨é‡ã€è½»ä¾¿ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚GEMä½¿ç”¨3Dé«˜æ–¯åŸå§‹å›¾å½¢æ¥è¡¨ç¤ºå¤–è§‚ï¼Œå¹¶ç»“åˆé«˜æ–¯æ‹¼è´´è¿›è¡Œæ¸²æŸ“ã€‚åŸºäºåŸºäºç½‘æ ¼çš„3Då¯å˜å½¢é¢éƒ¨æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æˆåŠŸï¼Œæˆ‘ä»¬å°†GEMå®šä¹‰ä¸ºè¡¨ç¤ºç‰¹å®šä¸»ä½“å¤´éƒ¨å¤–è§‚çš„çº¿æ€§ç‰¹å¾åŸºé›†åˆã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æ„å»ºäº†è¡¨ç¤ºä½ç½®ã€æ¯”ä¾‹ã€æ—‹è½¬å’Œé€æ˜åº¦çš„çº¿æ€§åŸºã€‚è¿™å…è®¸æˆ‘ä»¬é€šè¿‡çº¿æ€§ç»„åˆåŸºå‘é‡æœ‰æ•ˆåœ°ç”Ÿæˆç‰¹å®šå¤´éƒ¨å½¢çŠ¶çš„é«˜æ–¯åŸå§‹å›¾å½¢ï¼Œåªéœ€è¦åŒ…å«ç›¸åº”ç³»æ•°çš„ä½ç»´å‚æ•°å‘é‡ã€‚æˆ‘ä»¬æè®®é€šè¿‡æç‚¼é«˜è´¨é‡çš„è®¡ç®—å¯†é›†å‹CNNé«˜æ–¯åŒ–èº«æ¨¡å‹æ¥æ„å»ºè¿™äº›çº¿æ€§åŸºï¼ˆGEMï¼‰ï¼Œè¯¥æ¨¡å‹å¯ä»¥ç”Ÿæˆä¸è¡¨æƒ…ç›¸å…³çš„å¤–è§‚å˜åŒ–ï¼Œå¦‚çš±çº¹ã€‚è¿™äº›é«˜è´¨é‡æ¨¡å‹æ˜¯åœ¨ä¸»ä½“çš„å¤šè§†è§’è§†é¢‘ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œå¹¶ä½¿ç”¨ä¸€ç³»åˆ—ä¸»æˆåˆ†åˆ†æè¿›è¡Œæç‚¼ã€‚ä¸€æ—¦æˆ‘ä»¬è·å¾—äº†ä»£è¡¨ç‰¹å®šäººç±»å¯åŠ¨ç”»å¤–è§‚ç©ºé—´çš„åŸºåœ°ï¼Œæˆ‘ä»¬å°±å­¦ä¹ ä¸€ä¸ªå›å½’å™¨ï¼Œå®ƒæ¥å—å•å¼ RGBå›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶é¢„æµ‹ä¸æ‰€ç¤ºé¢éƒ¨è¡¨æƒ…ç›¸å¯¹åº”çš„ä½ç»´å‚æ•°å‘é‡ã€‚åœ¨ä¸€ç³»åˆ—å®éªŒä¸­ï¼Œæˆ‘ä»¬å°†GEMçš„è‡ªæˆ‘å†æ¼”ç»å’Œè·¨äººå†æ¼”ç»ç»“æœä¸æœ€å…ˆè¿›çš„3DåŒ–èº«æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜äº†GEMæ›´é«˜çš„è§†è§‰è´¨é‡å’Œå¯¹æ–°è¡¨æƒ…çš„æ›´å¥½æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.04545v4">PDF</a> Accepted to CVPR25 Website: <a target="_blank" rel="noopener" href="https://zielon.github.io/gem/">https://zielon.github.io/gem/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä¸ºäº†è§£å†³ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«é¢ä¸´çš„å›°å¢ƒâ€”â€”è½»é‡åŒ–æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’Œé€¼çœŸåº¦ï¼Œè€Œé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„åŒ–èº«éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºï¼Œä¸é€‚åˆæ™®é€šè®¾å¤‡ä½¿ç”¨ï¼Œæå‡ºäº†é«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰ã€‚GEMåˆ©ç”¨3Dé«˜æ–¯åŸå§‹ç‰¹å¾è¡¨ç¤ºå¤–è§‚ï¼Œç»“åˆé«˜æ–¯è´´å›¾è¿›è¡Œæ¸²æŸ“ï¼Œæä¾›é«˜è´¨é‡ã€è½»é‡åŒ–ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚åŸºäºç½‘æ ¼çš„3Då¯å˜å½¢é¢éƒ¨æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æˆåŠŸï¼Œå®šä¹‰GEMä¸ºç‰¹å®šçš„å¤´éƒ¨å¤–è§‚è¡¨ç¤ºçº¿æ€§ç‰¹å¾åŸºé›†åˆã€‚é€šè¿‡æ„å»ºè¡¨ç¤ºä½ç½®ã€å°ºåº¦ã€æ—‹è½¬å’Œé€æ˜åº¦çš„çº¿æ€§åŸºï¼Œé€šè¿‡çº¿æ€§ç»„åˆåŸºå‘é‡æœ‰æ•ˆåœ°ç”Ÿæˆå…·æœ‰ç‰¹å®šå¤´éƒ¨å½¢çŠ¶çš„é«˜æ–¯åŸå§‹ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæå‡ºäº†é€šè¿‡è’¸é¦é«˜è´¨é‡çš„è®¡ç®—å¯†é›†å‹CNNé«˜æ–¯åŒ–èº«æ¨¡å‹æ¥æ„å»ºè¿™äº›çº¿æ€§åŸºï¼ˆGEMï¼‰ï¼Œå¯ä»¥ç”Ÿæˆå¦‚çš±çº¹ç­‰è¡¨æƒ…ç›¸å…³çš„å¤–è§‚å˜åŒ–ã€‚è¿™äº›é«˜è´¨é‡æ¨¡å‹é€šè¿‡ä¸»ä½“å¤šè§†è§’è§†é¢‘è¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨ä¸»æˆåˆ†åˆ†æè¿›è¡Œè’¸é¦ã€‚åœ¨è·å¾—ä»£è¡¨ç‰¹å®šäººç±»å¯åŠ¨ç”»å¤–è§‚ç©ºé—´çš„åŸºåï¼Œå­¦ä¹ ä¸€ä¸ªå›å½’å™¨ï¼Œä»¥å•å¼ RGBå›¾åƒä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸æ‰€ç¤ºé¢éƒ¨è¡¨æƒ…ç›¸å¯¹åº”çš„ä½ç»´å‚æ•°å‘é‡ã€‚ä¸€ç³»åˆ—å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„3DåŒ–èº«æ–¹æ³•ç›¸æ¯”ï¼ŒGEMçš„è‡ªæˆ‘å†æ¼”ç»å’Œè·¨äººå†æ¼”ç»ç»“æœå…·æœ‰æ›´é«˜çš„è§†è§‰è´¨é‡å’Œæ›´å¥½çš„æ–°è¡¨æƒ…æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å½“å‰ä¸ªæ€§åŒ–ç¥ç»å¤´éƒ¨åŒ–èº«é¢ä¸´å›°å¢ƒï¼šè½»é‡åŒ–æ¨¡å‹ç¼ºä¹ç»†èŠ‚å’Œé€¼çœŸåº¦ï¼Œé«˜è´¨é‡æ¨¡å‹åˆ™è®¡ç®—èµ„æºéœ€æ±‚å¤§ã€‚</li>
<li>æå‡ºé«˜æ–¯ç‰¹å¾æ¨¡å‹ï¼ˆGEMï¼‰è§£å†³æ­¤é—®é¢˜ï¼Œå®ç°é«˜è´¨é‡ã€è½»é‡åŒ–ä¸”æ˜“äºæ§åˆ¶çš„å¤´éƒ¨åŒ–èº«ã€‚</li>
<li>GEMåˆ©ç”¨3Dé«˜æ–¯åŸå§‹ç‰¹å¾å’Œé«˜æ–¯è´´å›¾è¿›è¡Œæ¸²æŸ“ã€‚</li>
<li>åŸºäºç½‘æ ¼çš„3Då¯å˜å½¢é¢éƒ¨æ¨¡å‹ï¼ˆ3DMMï¼‰æ„å»ºçº¿æ€§åŸºæ¥è¡¨ç¤ºå¤´éƒ¨å¤–è§‚ã€‚</li>
<li>é€šè¿‡çº¿æ€§ç»„åˆåŸºå‘é‡ç”Ÿæˆç‰¹å®šå¤´éƒ¨å½¢çŠ¶çš„é«˜æ–¯åŸå§‹ç‰¹å¾ã€‚</li>
<li>é€šè¿‡è’¸é¦é«˜è´¨é‡çš„è®¡ç®—å¯†é›†å‹CNNæ¨¡å‹æ¥æ„å»ºçº¿æ€§åŸºï¼Œèƒ½ç”Ÿæˆè¡¨æƒ…ç›¸å…³çš„å¤–è§‚å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.04545">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-07976cd43a1a8bff6afcac21df635c31.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-140cc4892ea8fc733c970da5df3eaa7b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c8a050527e7fa73a744ccffe8d9c088.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7c92d96a50e4945e497e59fb29abe24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff6dc0438e2be9f231f655bf1a4426bd.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="DreamScape-3D-Scene-Creation-via-Gaussian-Splatting-joint-Correlation-Modeling"><a href="#DreamScape-3D-Scene-Creation-via-Gaussian-Splatting-joint-Correlation-Modeling" class="headerlink" title="DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation   Modeling"></a>DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation   Modeling</h2><p><strong>Authors:Yueming Zhao, Xuening Yuan, Hongyu Yang, Di Huang</strong></p>
<p>Recent advances in text-to-3D creation integrate the potent prior of Diffusion Models from text-to-image generation into 3D domain. Nevertheless, generating 3D scenes with multiple objects remains challenging. Therefore, we present DreamScape, a method for generating 3D scenes from text. Utilizing Gaussian Splatting for 3D representation, DreamScape introduces 3D Gaussian Guide that encodes semantic primitives, spatial transformations and relationships from text using LLMs, enabling local-to-global optimization. Progressive scale control is tailored during local object generation, addressing training instability issue arising from simple blending in the global optimization stage. Collision relationships between objects are modeled at the global level to mitigate biases in LLMs priors, ensuring physical correctness. Additionally, to generate pervasive objects like rain and snow distributed extensively across the scene, we design specialized sparse initialization and densification strategy. Experiments demonstrate that DreamScape achieves state-of-the-art performance, enabling high-fidelity, controllable 3D scene generation. </p>
<blockquote>
<p>æœ€è¿‘çš„æ–‡æœ¬åˆ°3Dåˆ›å»ºæŠ€æœ¯è¿›å±•å°†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„å¼ºå¤§æ‰©æ•£æ¨¡å‹å…ˆéªŒçŸ¥è¯†æ•´åˆåˆ°3Dé¢†åŸŸã€‚ç„¶è€Œï¼Œç”Ÿæˆå…·æœ‰å¤šä¸ªå¯¹è±¡çš„3Dåœºæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†DreamScapeæ–¹æ³•ï¼Œä¸€ç§ä»æ–‡æœ¬ç”Ÿæˆ3Dåœºæ™¯çš„æ–¹æ³•ã€‚åˆ©ç”¨é«˜æ–¯æ¶‚æŠ¹æ³•è¿›è¡Œ3Dè¡¨ç¤ºï¼ŒDreamScapeå¼•å…¥äº†3Dé«˜æ–¯æŒ‡å—ï¼Œè¯¥æŒ‡å—ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹è¯­ä¹‰åŸå§‹ä¿¡æ¯ã€ç©ºé—´å˜æ¢å’Œå…³ç³»è¿›è¡Œç¼–ç ï¼Œä»è€Œå®ç°å±€éƒ¨åˆ°å…¨å±€çš„ä¼˜åŒ–ã€‚åœ¨å±€éƒ¨å¯¹è±¡ç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œäº†å®šåˆ¶çš„æ¸è¿›å¼å°ºåº¦æ§åˆ¶ï¼Œè§£å†³äº†å…¨å±€ä¼˜åŒ–é˜¶æ®µç®€å•æ··åˆæ‰€å¯¼è‡´çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚åœ¨å…¨å±€å±‚é¢å»ºç«‹å¯¹è±¡é—´çš„ç¢°æ’å…³ç³»ï¼Œä»¥å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹å…ˆéªŒä¸­çš„åè§ï¼Œç¡®ä¿ç‰©ç†æ­£ç¡®æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç”Ÿæˆå¦‚é›¨é›ªç­‰å¹¿æ³›åˆ†å¸ƒåœ¨åœºæ™¯ä¸­çš„å¸¸è§ç‰©ä½“ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸“é—¨çš„ç¨€ç–åˆå§‹åŒ–å’Œè‡´å¯†åŒ–ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼ŒDreamScapeè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸã€å¯æ§çš„3Dåœºæ™¯ç”Ÿæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.09227v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹æ½œåŠ›ï¼Œç»“åˆå…¶åœ¨ä¸‰ç»´é¢†åŸŸçš„åº”ç”¨ï¼ŒDreamScapeæ–¹æ³•å®ç°äº†ä»æ–‡æœ¬ç”Ÿæˆä¸‰ç»´åœºæ™¯çš„åŠŸèƒ½ã€‚é€šè¿‡é«˜æ–¯æ‹¼è´´è¿›è¡Œä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç¼–ç è¯­ä¹‰åŸºå…ƒã€ç©ºé—´è½¬æ¢å’Œæ–‡æœ¬ä¸­çš„å…³ç³»ï¼ŒDreamScapeå®ç°äº†å±€éƒ¨åˆ°å…¨å±€çš„ä¼˜åŒ–ã€‚è¯¥æ–¹æ³•è§£å†³äº†ç®€å•æ··åˆå¸¦æ¥çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œå¹¶åœ¨å…¨å±€ä¼˜åŒ–é˜¶æ®µé‡‡ç”¨æ¸è¿›å°ºåº¦æ§åˆ¶ã€‚é€šè¿‡å»ºæ¨¡ç‰©ä½“é—´çš„ç¢°æ’å…³ç³»ï¼Œç¡®ä¿ç‰©ç†æ­£ç¡®æ€§å¹¶å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹å…ˆéªŒçš„åè§ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç”Ÿæˆåœºæ™¯ä¸­å¹¿æ³›åˆ†å¸ƒçš„å¦‚é›¨é›ªç­‰å¸¸è§ç‰©ä½“ï¼Œè®¾è®¡äº†ä¸€ç§ç‰¹æ®Šçš„ç¨€ç–åˆå§‹åŒ–å’Œå¯†é›†åŒ–ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼ŒDreamScapeå–å¾—äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸã€å¯æ§çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DreamScapeåˆ©ç”¨æ‰©æ•£æ¨¡å‹æ•´åˆæ–‡æœ¬åˆ°ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚</li>
<li>é€šè¿‡é«˜æ–¯æ‹¼è´´è¿›è¡Œä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç¼–ç æ–‡æœ¬ä¸­çš„è¯­ä¹‰å’Œå…³ç³»ã€‚</li>
<li>å®ç°å±€éƒ¨åˆ°å…¨å±€çš„ä¼˜åŒ–ï¼Œè§£å†³ç®€å•æ··åˆå¸¦æ¥çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚</li>
<li>å»ºæ¨¡ç‰©ä½“é—´çš„ç¢°æ’å…³ç³»ä»¥ç¡®ä¿ç‰©ç†æ­£ç¡®æ€§ã€‚</li>
<li>è®¾è®¡ç‰¹æ®Šç­–ç•¥ç”Ÿæˆåœºæ™¯ä¸­çš„æ™®éç‰©ä½“ï¼Œå¦‚é›¨é›ªã€‚</li>
<li>DreamScapeå®éªŒè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.09227">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7bb46a44e19fde605abc7d5e84986cdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14f7d4c4563a1443997b4a4a5f9b4f40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-640e099afc274f23153a99cded40dd25.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2dc2dd2244e82a220d5f9fe9e00a813a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb4f731f2b0d30d20b6c3cc50828430c.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-05/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-05/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-05/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e15f469bbc5c7833fc0865375a2de227.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-05  MultiNeRF Multiple Watermark Embedding for Neural Radiance Fields
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-05/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e83781afdfdffe32dda10dac22e4bc25.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-05  F-ViTA Foundation Model Guided Visible to Thermal Translation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23251k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
