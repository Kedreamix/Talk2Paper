<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-08-05  Unraveling Hidden Representations A Multi-Modal Layer Analysis for   Better Synthetic Content Forensics">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5c6ec378f0573e36f37f75a0fe5d0198.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    25 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-05-更新"><a href="#2025-08-05-更新" class="headerlink" title="2025-08-05 更新"></a>2025-08-05 更新</h1><h2 id="Unraveling-Hidden-Representations-A-Multi-Modal-Layer-Analysis-for-Better-Synthetic-Content-Forensics"><a href="#Unraveling-Hidden-Representations-A-Multi-Modal-Layer-Analysis-for-Better-Synthetic-Content-Forensics" class="headerlink" title="Unraveling Hidden Representations: A Multi-Modal Layer Analysis for   Better Synthetic Content Forensics"></a>Unraveling Hidden Representations: A Multi-Modal Layer Analysis for   Better Synthetic Content Forensics</h2><p><strong>Authors:Tom Or, Omri Azencot</strong></p>
<p>Generative models achieve remarkable results in multiple data domains, including images and texts, among other examples. Unfortunately, malicious users exploit synthetic media for spreading misinformation and disseminating deepfakes. Consequently, the need for robust and stable fake detectors is pressing, especially when new generative models appear everyday. While the majority of existing work train classifiers that discriminate between real and fake information, such tools typically generalize only within the same family of generators and data modalities, yielding poor results on other generative classes and data domains. Towards a universal classifier, we propose the use of large pre-trained multi-modal models for the detection of generative content. Effectively, we show that the latent code of these models naturally captures information discriminating real from fake. Building on this observation, we demonstrate that linear classifiers trained on these features can achieve state-of-the-art results across various modalities, while remaining computationally efficient, fast to train, and effective even in few-shot settings. Our work primarily focuses on fake detection in audio and images, achieving performance that surpasses or matches that of strong baseline methods. </p>
<blockquote>
<p>生成模型在多个数据领域取得了显著成果，包括图像和文本等。然而，恶意用户利用合成媒体传播虚假信息和深度伪造。因此，对新生成模型的稳健和稳定虚假检测器的需求尤为迫切。虽然现有的大多数工作都是训练分类器来区分真实和虚假信息，但这些工具通常仅在相同生成器和数据模式的家族内通用化，对其他生成类和数据领域的检测结果较差。为了建立一个通用分类器，我们建议使用大型预训练多模态模型来检测生成内容。实际上，我们展示了这些模型的潜在代码自然地捕捉了区分真实和虚假信息的信息。基于这一观察，我们证明在这些特征上训练的线性分类器可以在各种模式下达到最先进的检测结果，同时保持计算效率高、训练速度快，甚至在少量样本设置中也有效。我们的工作主要集中在音频和图像的虚假检测上，性能超过了或匹配了强大的基线方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00784v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>生成模型在多数据领域取得了显著成果，包括图像和文本等。然而，恶意用户利用合成媒体传播虚假信息，因此迫切需要稳健的虚假检测器，尤其是新的生成模型不断涌现的情况下。现有的大多数工具主要通过训练分类器来区分真实和虚假信息，但它们通常只在同一生成器和数据模式家族内通用，对其他生成类别和数据领域的表现较差。本研究提出使用大型预训练多模态模型来检测生成内容，以构建通用分类器。我们观察到这些模型的潜在代码能够自然地捕捉区分真实和虚假信息的信息，并在此基础上训练线性分类器实现跨多种模式的卓越成果。该模型计算效率高、训练速度快，甚至在样本量较小的情况下依然有效。我们的工作主要集中在音频和图像的虚假检测上，性能超过了或匹配了强大的基线方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>生成模型在多数据领域表现出色，但合成媒体被恶意利用传播虚假信息，需要开发稳健的虚假检测器。</li>
<li>现有工具主要训练分类器来区分真实和虚假信息，但通用性有限，表现不佳。</li>
<li>提出使用大型预训练多模态模型检测生成内容，实现跨多种模式的优秀性能。</li>
<li>模型的潜在代码可以捕捉区分真实和虚假信息的信息。</li>
<li>通过训练线性分类器，在特征上取得了最先进的成果，同时保持了计算效率和快速训练。</li>
<li>该模型在样本量较小的情况下依然有效。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00784">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4aca585fc272c900742b8b5e6e9f89ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39136acf98e35383eb92469f70c31a8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-153c3909ea3865a87d423e6e8d8a131d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd10b49f459e97299070e183c29f2803.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GLiDRE-Generalist-Lightweight-model-for-Document-level-Relation-Extraction"><a href="#GLiDRE-Generalist-Lightweight-model-for-Document-level-Relation-Extraction" class="headerlink" title="GLiDRE: Generalist Lightweight model for Document-level Relation   Extraction"></a>GLiDRE: Generalist Lightweight model for Document-level Relation   Extraction</h2><p><strong>Authors:Robin Armingaud, Romaric Besançon</strong></p>
<p>Relation Extraction (RE) is a fundamental task in Natural Language Processing, and its document-level variant poses significant challenges, due to the need to model complex interactions between entities across sentences. Current approaches, largely based on the ATLOP architecture, are commonly evaluated on benchmarks like DocRED and Re-DocRED. However, their performance in zero-shot or few-shot settings remains largely underexplored due to the task’s complexity. Recently, the GLiNER model has shown that a compact NER model can outperform much larger Large Language Models. With a similar motivation, we introduce GLiDRE, a new model for document-level relation extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against state-of-the-art models across various data settings on the Re-DocRED dataset. Our results demonstrate that GLiDRE achieves state-of-the-art performance in few-shot scenarios. Our code is publicly available. </p>
<blockquote>
<p>关系抽取（RE）是自然语言处理中的一项基本任务，其文档级变体带来了重大挑战，因为需要建模跨句子的实体之间的复杂交互。当前的方法大多基于ATLOP架构，通常会在DocRED和Re-DocRED等基准测试集上进行评估。然而，它们在零样本或少样本设置中的性能由于任务的复杂性而尚未得到充分探索。最近，GLiNER模型显示了一个紧凑的命名实体识别模型可以表现出优于更大规模的语言模型的性能。基于同样的动机，我们介绍了GLiDRE，这是一个新的文档级关系抽取模型，它建立在GliNER的关键思想之上。我们在Re-DocRED数据集的各种数据设置上与最先进的模型对GLiDRE进行了基准测试。我们的结果表明，GLiDRE在少样本场景中达到了最先进的性能。我们的代码是公开的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00757v1">PDF</a> Submitted to ARR July</p>
<p><strong>Summary</strong></p>
<p>GLiDRE模型是一种新型的文档级关系抽取模型，基于GliNER的关键思想构建。该模型在Re-DocRED数据集上的性能表现达到了先进水平，特别是在小样本场景下。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>关系抽取（RE）是自然语言处理中的一项基本任务，其文档级变体由于需要建模跨句子的实体之间的复杂交互而具有挑战。</li>
<li>当前的方法大多基于ATLOP架构，并在DocRED和Re-DocRED等基准测试上进行评估。</li>
<li>这些方法在零样本或少样本设置下的性能由于任务的复杂性而尚未得到充分探索。</li>
<li>GLiDRE模型是一种新型的文档级关系抽取模型，借鉴了GliNER的思想。</li>
<li>在Re-DocRED数据集上，GLiDRE模型在各种数据设置下的性能达到了先进水平。</li>
<li>GLiDRE模型在小样本场景下的表现尤其突出。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00757">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-94675a1d0d65b30e27f7a57dda8d14b1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-98da164be67a9a30ec0bd493f8e7908b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1dd48fb63c782524e8d8d35bdf3ac78.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DACTYL-Diverse-Adversarial-Corpus-of-Texts-Yielded-from-Large-Language-Models"><a href="#DACTYL-Diverse-Adversarial-Corpus-of-Texts-Yielded-from-Large-Language-Models" class="headerlink" title="DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language   Models"></a>DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language   Models</h2><p><strong>Authors:Shantanu Thorat, Andrew Caines</strong></p>
<p>Existing AIG (AI-generated) text detectors struggle in real-world settings despite succeeding in internal testing, suggesting that they may not be robust enough. We rigorously examine the machine-learning procedure to build these detectors to address this. Most current AIG text detection datasets focus on zero-shot generations, but little work has been done on few-shot or one-shot generations, where LLMs are given human texts as an example. In response, we introduce the Diverse Adversarial Corpus of Texts Yielded from Language models (DACTYL), a challenging AIG text detection dataset focusing on one-shot&#x2F;few-shot generations. We also include texts from domain-specific continued-pre-trained (CPT) language models, where we fully train all parameters using a memory-efficient optimization approach. Many existing AIG text detectors struggle significantly on our dataset, indicating a potential vulnerability to one-shot&#x2F;few-shot and CPT-generated texts. We also train our own classifiers using two approaches: standard binary cross-entropy (BCE) optimization and a more recent approach, deep X-risk optimization (DXO). While BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL test set, the latter excels on out-of-distribution (OOD) texts. In our mock deployment scenario in student essay detection with an OOD student essay dataset, the best DXO classifier outscored the best BCE-trained classifier by 50.56 macro-F1 score points at the lowest false positive rates for both. Our results indicate that DXO classifiers generalize better without overfitting to the test set. Our experiments highlight several areas of improvement for AIG text detectors. </p>
<blockquote>
<p>现有的AIG（AI生成）文本检测器在现实世界环境中表现不佳，尽管它们在内部测试中取得了成功，这表明它们可能不够稳健。为了解决这个问题，我们对构建这些检测器的机器学习程序进行了严格检查。当前大多数AIG文本检测数据集都集中在零样本生成上，而对于少样本或一次生成的研究很少，后者给语言模型提供人类文本作为示例。作为回应，我们引入了来自语言模型的多样化对抗文本语料库（DACTYL），这是一个具有挑战性的AIG文本检测数据集，专注于一次&#x2F;少次生成。我们还包括来自特定领域持续预训练（CPT）语言模型的文本，其中我们使用内存高效的优化方法对所有参数进行全面训练。许多现有的AIG文本检测器在我们的数据集上表现困难，这表明它们可能容易受到一次&#x2F;少次和CPT生成的文本的攻击。我们还使用两种方法来训练自己的分类器：标准二进制交叉熵（BCE）优化和一种更新的方法——深度X风险优化（DXO）。尽管BCE训练的分类器在DACTYL测试集上略微优于DXO分类器，但后者在异常值（OOD）文本上表现出色。在我们使用异常值学生作文数据集的学生作文检测模拟部署场景中，最佳DXO分类器在最低误报率的情况下，比最佳BCE训练的分类器高出50.56个宏F1分数点。我们的结果表明，DXO分类器可以更好地泛化并不会过度拟合测试集。我们的实验突出了AIG文本检测器的几个改进领域。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00619v1">PDF</a> MPhil in Advanced Computer Science thesis for University of Cambridge</p>
<p><strong>Summary</strong></p>
<p>本文介绍了现有的人工智能生成文本检测器在现实环境中的表现问题，分析其机器学习流程并指出其可能存在的局限性。文章重点介绍了一个新的数据集DACTYL，专注于一次或少数次生成的人工智能文本检测，并发现许多现有检测器在该数据集上表现不佳。此外，文章还介绍了使用两种不同优化方法训练的分类器性能比较，并发现DXO优化方法虽然略微逊于BCE优化方法的分类器在DACTYL测试集上的表现，但在处理出分布式文本时表现出更高的能力。这些结果表明DXO分类器能够更好地推广，且不过拟合测试集。总之，文章为未来人工智能生成文本检测器的改进指明了方向。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有的人工智能生成文本检测器在现实环境中表现欠佳，存在稳健性问题。</li>
<li>引入了一个新的数据集DACTYL，专门用于一次或少数次生成的人工智能文本检测。</li>
<li>许多现有检测器在DACTYL数据集上表现不佳，表明对一次或少数次生成和CPT生成的文本存在潜在漏洞。</li>
<li>使用两种不同优化方法训练的分类器性能比较显示，DXO优化方法在出分布式文本处理方面表现出更高的能力。</li>
<li>在模拟部署场景中，DXO分类器在检测学生论文时表现出更好的泛化性能。</li>
<li>文章指出了人工智能生成文本检测器的潜在改进方向。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00619">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6bb8297e882d317fcee21b33aa659c4e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11790585d841778eafeed90e2425e1d0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Decouple-before-Align-Visual-Disentanglement-Enhances-Prompt-Tuning"><a href="#Decouple-before-Align-Visual-Disentanglement-Enhances-Prompt-Tuning" class="headerlink" title="Decouple before Align: Visual Disentanglement Enhances Prompt Tuning"></a>Decouple before Align: Visual Disentanglement Enhances Prompt Tuning</h2><p><strong>Authors:Fei Zhang, Tianfei Zhou, Jiangchao Yao, Ya Zhang, Ivor W. Tsang, Yanfeng Wang</strong></p>
<p>Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm, has showcased remarkable effectiveness in improving the task-specific transferability of vision-language models. This paper delves into a previously overlooked information asymmetry issue in PT, where the visual modality mostly conveys more context than the object-oriented textual modality. Correspondingly, coarsely aligning these two modalities could result in the biased attention, driving the model to merely focus on the context area. To address this, we propose DAPT, an effective PT framework based on an intuitive decouple-before-align concept. First, we propose to explicitly decouple the visual modality into the foreground and background representation via exploiting coarse-and-fine visual segmenting cues, and then both of these decoupled patterns are aligned with the original foreground texts and the hand-crafted background classes, thereby symmetrically strengthening the modal alignment. To further enhance the visual concentration, we propose a visual pull-push regularization tailored for the foreground-background patterns, directing the original visual representation towards unbiased attention on the region-of-interest object. We demonstrate the power of architecture-free DAPT through few-shot learning, base-to-novel generalization, and data-efficient learning, all of which yield superior performance across prevailing benchmarks. Our code will be released at <a target="_blank" rel="noopener" href="https://github.com/Ferenas/DAPT">https://github.com/Ferenas/DAPT</a>. </p>
<blockquote>
<p>摘要翻译：</p>
</blockquote>
<p>提示调整（PT）作为一种新兴的资源高效微调范式，在提高视觉语言模型的特定任务迁移性方面表现出显著的有效性。本文深入探讨了PT中以前被忽视的信息不对称问题，其中视觉模式大多传递的上下文信息多于面向对象的文本模式。相应地，粗略对齐这两种模式可能会导致偏向性注意力，使模型仅专注于上下文区域。为了解决这一问题，我们提出了基于直观“先分离再对齐”概念的DAPT有效PT框架。首先，我们提议通过利用粗细视觉分段线索显式地将视觉模式分解为前景和背景表示，然后将这两种分解的模式与原始前景文本和手工背景类别对齐，从而对称地加强模态对齐。为了进一步增强视觉集中度，我们针对前景背景模式提出了视觉推拉正则化，引导原始视觉表示在感兴趣区域上实现无偏注意。我们通过小样本学习、基础到新颖的泛化和数据高效学习展示了无架构DAPT的威力，所有这些方法在流行的基准测试中均表现出卓越的性能。我们的代码将在<a target="_blank" rel="noopener" href="https://github.com/Ferenas/DAPT%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Ferenas/DAPT发布。</a></p>
<p>详细翻译：</p>
<p>提示调整（Prompt Tuning，PT）作为一种资源高效的微调模式，其在提高视觉语言模型的特定任务迁移能力方面展现出了令人瞩目的效果。然而，在PT中存在一个被忽视的信息不对称问题。在视觉模态中，大多数情况下传递的上下文信息远多于面向对象的文本模态。因此，如果粗略地对这两种模式进行对齐，可能会导致模型过度关注上下文区域而忽略其他重要信息。为了解决这个问题，我们提出了基于直观“先分离再对齐”（Decouple-before-Align）理念的DAPT框架。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00395v1">PDF</a> 16 pages, Accepted at IEEE Transactions on Pattern Analysis and   Machine Intelligence (TPAMI)</p>
<p><strong>Summary</strong></p>
<p>本文探讨了Prompt Tuning（PT）在视觉语言模型中的任务特定迁移能力，并揭示了其中信息不对称的问题。针对视觉模态与文本模态之间的信息差异，提出了基于解耦对齐的DAPT框架。通过粗粒度视觉分割将视觉模态分为前景和背景表示，并与文本进行对齐，以改善模态对齐问题。同时，通过设计一种视觉拉推正则化方法，使模型更加关注前景背景模式的关键区域。该架构灵活的DAPT方法在少样本学习、基础到新颖的泛化能力以及数据效率学习方面表现出卓越的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Prompt Tuning（PT）在视觉语言模型中提高了任务特定迁移能力。</li>
<li>存在视觉模态与文本模态之间的信息不对称问题，其中视觉模态提供更多上下文信息。</li>
<li>DAPT框架旨在解决这一问题，通过解耦对齐改善模态间的对齐问题。</li>
<li>利用粗粒度视觉分割将视觉模态分为前景和背景表示。</li>
<li>通过前景与背景表示与文本的对应对齐来强化模态对称性。</li>
<li>提出视觉拉推正则化方法，提高模型对前景背景关键区域的关注。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00395">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-1512c5401f25e3a1174a3f0e79bf8e84.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a46613b7693ecfc798ddcad59dae2e18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-332ec089500a002821ce953ef71aa42f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad26272d434b4f4aca4827e63f0c8908.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c6ec378f0573e36f37f75a0fe5d0198.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="H-RDT-Human-Manipulation-Enhanced-Bimanual-Robotic-Manipulation"><a href="#H-RDT-Human-Manipulation-Enhanced-Bimanual-Robotic-Manipulation" class="headerlink" title="H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation"></a>H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation</h2><p><strong>Authors:Hongzhe Bi, Lingxuan Wu, Tianwei Lin, Hengkai Tan, Zhizhong Su, Hang Su, Jun Zhu</strong></p>
<p>Imitation learning for robotic manipulation faces a fundamental challenge: the scarcity of large-scale, high-quality robot demonstration data. Recent robotic foundation models often pre-train on cross-embodiment robot datasets to increase data scale, while they face significant limitations as the diverse morphologies and action spaces across different robot embodiments make unified training challenging. In this paper, we present H-RDT (Human to Robotics Diffusion Transformer), a novel approach that leverages human manipulation data to enhance robot manipulation capabilities. Our key insight is that large-scale egocentric human manipulation videos with paired 3D hand pose annotations provide rich behavioral priors that capture natural manipulation strategies and can benefit robotic policy learning. We introduce a two-stage training paradigm: (1) pre-training on large-scale egocentric human manipulation data, and (2) cross-embodiment fine-tuning on robot-specific data with modular action encoders and decoders. Built on a diffusion transformer architecture with 2B parameters, H-RDT uses flow matching to model complex action distributions. Extensive evaluations encompassing both simulation and real-world experiments, single-task and multitask scenarios, as well as few-shot learning and robustness assessments, demonstrate that H-RDT outperforms training from scratch and existing state-of-the-art methods, including Pi0 and RDT, achieving significant improvements of 13.9% and 40.5% over training from scratch in simulation and real-world experiments, respectively. The results validate our core hypothesis that human manipulation data can serve as a powerful foundation for learning bimanual robotic manipulation policies. </p>
<blockquote>
<p>模仿学习在机器人操作方面面临一个根本挑战：缺乏大规模、高质量机器人演示数据。最近的机器人基础模型通常会在跨形态机器人数据集上进行预训练，以增加数据规模，然而，由于不同机器人形态之间的形态多样性和行动空间差异，统一训练面临重大挑战。在本文中，我们提出了H-RDT（人类到机器人扩散转换器），这是一种利用人类操作数据增强机器人操作能力的新方法。我们的关键见解是，带有配对3D手姿势注释的大规模第一人称人类操作视频提供了丰富的行为先验，能够捕捉自然操作策略，并有益于机器人策略学习。我们介绍了一种两阶段训练范式：（1）在大规模第一人称人类操作数据上进行预训练；（2）使用模块化动作编码器和解码器，在机器人特定数据上进行跨形态微调。H-RDT建立在具有2B参数的扩散转换器架构上，通过流程匹配来模拟复杂的动作分布。全面的评估包括仿真和真实实验、单任务和多任务场景，以及小样本学习和稳健性评估，结果表明，H-RDT优于从头开始训练以及现有最先进的方法，包括Pi0和RDT，在仿真和真实实验中分别比从头开始训练提高了13.9%和40.5%。结果验证了我们的核心假设，即人类操作数据可以作为学习双手机器人操作策略的有力基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.23523v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了H-RDT（人类到机器人的扩散转换器），这是一种利用人类操作数据增强机器人操作能力的新方法。该方法借助大规模的第一人称人类操作视频和配套的3D手部姿态注释，通过两阶段训练模式，实现了对机器人操作策略的学习。首先，在大规模的第一人称人类操作数据上进行预训练；然后，在具有模块化动作编码器和解码器的机器人特定数据上进行跨形态微调。H-RDT建立在具有2B参数的扩散转换器架构上，使用流程匹配来模拟复杂的动作分布。实验结果显示，H-RDT在模拟和真实世界的实验中，无论是在单任务还是多任务场景下，以及少样本学习和稳健性评估中，均表现出优于从零开始训练和现有先进方法（包括Pi0和RDT）的效果，模拟和真实实验中的提升分别达到了13.9%和40.5%。验证了人类操作数据作为学习双手机器人操作策略的强大基础这一核心假设。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>H-RDT利用大规模的第一人称人类操作视频和配套的3D手部姿态注释数据，为机器人操作提供丰富的行为先验。</li>
<li>H-RDT采用两阶段训练模式，包括在大量人类操作数据上的预训练和机器人特定数据上的跨形态微调。</li>
<li>H-RDT建立在具有强大参数的扩散转换器架构上，通过流程匹配模拟复杂的动作分布。</li>
<li>H-RDT在模拟和真实世界的实验中表现出卓越性能，优于现有的训练方法。</li>
<li>H-RDT在单任务和多任务场景下均展现出强大的性能，并且在少样本学习和稳健性方面也有显著的提升。</li>
<li>借助人类操作数据作为学习双手机器人操作策略的基础被验证为有效。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.23523">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e7900f6580ab8b603070d577e7436bd1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-33102ed06f401b5ebf388546a6cc0f16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f524a50428b80a19323f081f35a829a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c44d398d320460c2ea51d2abc497e8ea.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BOOST-Bootstrapping-Strategy-Driven-Reasoning-Programs-for-Program-Guided-Fact-Checking"><a href="#BOOST-Bootstrapping-Strategy-Driven-Reasoning-Programs-for-Program-Guided-Fact-Checking" class="headerlink" title="BOOST: Bootstrapping Strategy-Driven Reasoning Programs for   Program-Guided Fact-Checking"></a>BOOST: Bootstrapping Strategy-Driven Reasoning Programs for   Program-Guided Fact-Checking</h2><p><strong>Authors:Qisheng Hu, Quanyu Long, Wenya Wang</strong></p>
<p>Large language model pipelines have improved automated fact-checking for complex claims, yet many approaches rely on few-shot in-context learning with demonstrations that require substantial human effort and domain expertise. Among these, program-guided reasoning, by decomposing claims into function calls and executing reasoning programs, which has shown particular promise, but remains limited by the need for manually crafted demonstrations. Fundamentally, the underlying principles of effective reasoning program generation still remain underexplored. In this work, we introduce BOOST, a bootstrapping approach for automated few-shot reasoning program generation. BOOST iteratively refines explicit, data-driven guidelines as meta-rules for guiding demonstration creation, using a critique-refine loop that eliminates the need for human intervention. This enables a seamless transition from zero-shot to few-shot program-guided learning, enhancing interpretability and effectiveness. Experimental results show that BOOST outperforms prior few-shot baselines in both zero-shot and few-shot settings for complex claim verification. </p>
<blockquote>
<p>大型语言模型管道已经改进了复杂声明的自动化事实核查，然而许多方法依赖于通过演示进行的小样本上下文学习，这需要大量的人力和领域专业知识。其中，程序引导推理通过将声明分解成函数调用并执行推理程序，显示出特别的潜力，但仍受限于需要手动制作的演示。从根本上说，有效推理程序生成的基本原理仍未得到充分探索。在这项工作中，我们介绍了BOOST，这是一种用于自动化小样本推理程序生成的自举方法。BOOST通过批评和修正循环来迭代完善显式、数据驱动的指导方针，将其作为引导演示制作的元规则，从而消除了对人工干预的需求。这实现了从零样本到小样本程序引导学习的无缝过渡，提高了可解释性和有效性。实验结果表明，BOOST在零样本和小样本设置中均优于先前的基线模型，用于复杂声明的验证。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02467v3">PDF</a> Work in Progress</p>
<p><strong>Summary</strong></p>
<p>大型语言模型管道改善了复杂声明的自动化事实核查，但许多方法仍依赖于需要巨大人力和领域专业知识的小样本上下文学习示范。其中，程序引导推理通过将声明分解成函数调用并执行推理程序显示出特别的前景，但受限于手工制作的示范需求。本文引入BOOST，一种用于自动化小样本推理程序生成的启动方法。BOOST通过批评和修正循环迭代优化显式、数据驱动的指导方针作为引导示范创建的元规则，消除了对人工干预的需求。这使得从零样本到小样本的程序引导学习无缝过渡，提高了可解释性和有效性。实验结果表明，BOOST在零样本和小样本设置中均优于先前的少样本基线，用于复杂声明验证。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型管道已改善复杂声明的自动化事实核查。</li>
<li>当前方法依赖小样本上下文学习示范，需要人力和领域专业知识。</li>
<li>程序引导推理通过将声明分解成函数调用进行推理显示出前景。</li>
<li>目前的方法受限于手工制作的示范需求。</li>
<li>引入BOOST方法，一种用于自动化小样本推理程序生成的启动方法。</li>
<li>BOOST通过批评和修正循环优化显式、数据驱动的指导方针，消除对人工干预的需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02467">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7227dac9560c7b2bc35c14ba3fd47d49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1c07f9d0eb8d974790c278ad314f30f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d7d02ba25e77db0e95836cec6e8ed92.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e3cb67d70b4adea49221c5b5f4a422a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-144c52a51863bac1d5b04f35535ca9fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6578e91b0923199e50ae6d65dd667eff.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-05/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-05/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-05/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-226d15d0d90474eb4074bf4f84cdc810.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-08-05  Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-05/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-9b52d6cf0dd744e4ee5028cbdcbf0318.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-08-05  Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25243.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
