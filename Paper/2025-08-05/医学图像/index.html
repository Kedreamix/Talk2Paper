<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-05  Numerical Uncertainty in Linear Registration An Experimental Study">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-96a2b224c4fec8217555faa576acc1d1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    70 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-05-æ›´æ–°"><a href="#2025-08-05-æ›´æ–°" class="headerlink" title="2025-08-05 æ›´æ–°"></a>2025-08-05 æ›´æ–°</h1><h2 id="Numerical-Uncertainty-in-Linear-Registration-An-Experimental-Study"><a href="#Numerical-Uncertainty-in-Linear-Registration-An-Experimental-Study" class="headerlink" title="Numerical Uncertainty in Linear Registration: An Experimental Study"></a>Numerical Uncertainty in Linear Registration: An Experimental Study</h2><p><strong>Authors:Niusha Mirhakimi, Yohan Chatelain, Jean-Baptiste Poline, Tristan Glatard</strong></p>
<p>While linear registration is a critical step in MRI preprocessing pipelines, its numerical uncertainty is understudied. Using Monte-Carlo Arithmetic (MCA) simulations, we assessed the most commonly used linear registration tools within major software packages (SPM, FSL, and ANTs) across multiple image similarity measures, two brain templates, and both healthy control (HC, n&#x3D;50) and Parkinsonâ€™s Disease (PD, n&#x3D;50) cohorts. Our findings highlight the influence of linear registration tools and similarity measures on numerical stability. Among the evaluated tools and with default similarity measures, SPM exhibited the highest stability. FSL and ANTs showed greater and similar ranges of variability, with ANTs demonstrating particular sensitivity to numerical perturbations that occasionally led to registration failure. Furthermore, no significant differences were observed between healthy and PD cohorts, suggesting that numerical stability analyses obtained with healthy subjects may generalise to clinical populations. Finally, we also demonstrated how numerical uncertainty measures may support automated quality control (QC) of linear registration results. Overall, our experimental results characterize the numerical stability of linear registration experimentally and can serve as a basis for future uncertainty analyses. </p>
<blockquote>
<p>è™½ç„¶çº¿æ€§é…å‡†æ˜¯MRIé¢„å¤„ç†æµç¨‹ä¸­çš„å…³é”®æ­¥éª¤ï¼Œä½†å…¶æ•°å€¼ä¸ç¡®å®šæ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æˆ‘ä»¬ä½¿ç”¨è’™ç‰¹å¡æ´›ç®—æœ¯ï¼ˆMCAï¼‰æ¨¡æ‹Ÿï¼Œè¯„ä¼°äº†ä¸»è¦è½¯ä»¶åŒ…ï¼ˆSPMã€FSLå’ŒANTsï¼‰ä¸­æœ€å¸¸ç”¨çš„çº¿æ€§é…å‡†å·¥å…·ï¼Œè·¨è¶Šå¤šç§å›¾åƒç›¸ä¼¼æ€§åº¦é‡ã€ä¸¤ä¸ªè„‘æ¨¡æ¿ä»¥åŠå¥åº·å¯¹ç…§ï¼ˆHCï¼Œn&#x3D;50ï¼‰å’Œå¸•é‡‘æ£®ç—…ï¼ˆPDï¼Œn&#x3D;50ï¼‰ç¾¤ä½“ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†çº¿æ€§é…å‡†å·¥å…·å’Œç›¸ä¼¼æ€§åº¦é‡å¯¹æ•°å€¼ç¨³å®šæ€§çš„å½±å“ã€‚åœ¨è¯„ä¼°çš„å·¥å…·å’Œé»˜è®¤çš„ç›¸ä¼¼æ€§åº¦é‡ä¸­ï¼ŒSPMè¡¨ç°å‡ºæœ€é«˜çš„ç¨³å®šæ€§ã€‚FSLå’ŒANTsçš„å˜åŠ¨èŒƒå›´è¾ƒå¤§ä¸”ç›¸ä¼¼ï¼ŒANTså¯¹æ•°å€¼æ‰°åŠ¨ç‰¹åˆ«æ•æ„Ÿï¼Œå¶å°”ä¼šå¯¼è‡´é…å‡†å¤±è´¥ã€‚æ­¤å¤–ï¼Œå¥åº·äººç¾¤å’ŒPDç¾¤ä½“ä¹‹é—´æ²¡æœ‰æ˜æ˜¾çš„å·®å¼‚ï¼Œè¿™è¡¨æ˜ç”¨å¥åº·å—è¯•è€…è·å¾—çš„æ•°å€¼ç¨³å®šæ€§åˆ†æå¯èƒ½é€‚ç”¨äºä¸´åºŠäººç¾¤ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†æ•°å€¼ä¸ç¡®å®šæ€§åº¦é‡å¦‚ä½•æ”¯æŒçº¿æ€§é…å‡†ç»“æœçš„è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶ï¼ˆQCï¼‰ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„å®éªŒç»“æœé€šè¿‡å®éªŒè¡¨å¾äº†çº¿æ€§é…å‡†çš„æ•°å€¼ç¨³å®šæ€§ï¼Œå¹¶å¯ä»¥ä½œä¸ºæœªæ¥ä¸ç¡®å®šæ€§åˆ†æçš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00781v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡åˆ©ç”¨è’™ç‰¹å¡æ´›ç®—æ³•ï¼ˆMCAï¼‰æ¨¡æ‹Ÿè¯„ä¼°äº†ä¸»è¦è½¯ä»¶åŒ…ï¼ˆSPMã€FSLå’ŒANTsï¼‰ä¸­å¸¸ç”¨çš„çº¿æ€§æ³¨å†Œå·¥å…·åœ¨å¤šç§å›¾åƒç›¸ä¼¼æ€§åº¦é‡ã€ä¸¤ä¸ªè„‘æ¨¡æ¿ä»¥åŠå¥åº·å¯¹ç…§ç»„ï¼ˆHCï¼‰å’Œå¸•é‡‘æ£®æ°ç—…ï¼ˆPDï¼‰æ‚£è€…ç¾¤ä½“ä¸­çš„æ•°å€¼ç¨³å®šæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œçº¿æ€§æ³¨å†Œå·¥å…·å’Œç›¸ä¼¼æ€§åº¦é‡å¯¹æ•°å€¼ç¨³å®šæ€§æœ‰å½±å“ã€‚é»˜è®¤ç›¸ä¼¼æ€§åº¦é‡ä¸‹ï¼ŒSPMè¡¨ç°å‡ºæœ€é«˜ç¨³å®šæ€§ï¼Œè€ŒFSLå’ŒANTsçš„å˜åŠ¨èŒƒå›´è¾ƒå¤§ä¸”ç›¸ä¼¼ï¼Œå…¶ä¸­ANTså¯¹æŸäº›æ•°å€¼æ‰°åŠ¨ç‰¹åˆ«æ•æ„Ÿï¼Œå¶å°”ä¼šå¯¼è‡´æ³¨å†Œå¤±è´¥ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œå¥åº·ç¾¤ä½“ä¸PDæ‚£è€…çš„å·®å¼‚ä¸å½±å“æ•°å€¼ç¨³å®šæ€§åˆ†æç»“æœçš„é€šç”¨æ€§ã€‚æœ€åï¼Œæ–‡ç« å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ•°å€¼ä¸ç¡®å®šæ€§åº¦é‡æ¥æ”¯æŒçº¿æ€§æ³¨å†Œç»“æœçš„è‡ªåŠ¨åŒ–è´¨é‡æ§åˆ¶ã€‚æœ¬ç ”ç©¶å®éªŒç»“æœå¯ä¸ºæœªæ¥ä¸ç¡®å®šæ€§åˆ†ææä¾›ä¾æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨è’™ç‰¹å¡æ´›ç®—æ³•æ¨¡æ‹Ÿè¯„ä¼°äº†å¤šç§çº¿æ€§æ³¨å†Œå·¥å…·çš„æ•°å€¼ç¨³å®šæ€§ã€‚</li>
<li>ç ”ç©¶æ¶‰åŠå¤šä¸ªå›¾åƒç›¸ä¼¼æ€§åº¦é‡ã€ä¸¤ä¸ªè„‘æ¨¡æ¿ä»¥åŠå¥åº·ä¸å¸•é‡‘æ£®æ°ç—…æ‚£è€…ç¾¤ä½“ã€‚</li>
<li>SPMåœ¨é»˜è®¤ç›¸ä¼¼æ€§åº¦é‡ä¸‹è¡¨ç°å‡ºæœ€é«˜ç¨³å®šæ€§ã€‚</li>
<li>FSLå’ŒANTsçš„æ•°å€¼ç¨³å®šæ€§ç›¸å¯¹è¾ƒå·®ï¼Œå…¶ä¸­ANTså°¤å…¶æ•æ„ŸäºæŸäº›æ•°å€¼æ‰°åŠ¨ã€‚</li>
<li>å¥åº·ä¸PDæ‚£è€…ç¾¤ä½“é—´çš„å·®å¼‚ä¸å½±å“æ•°å€¼ç¨³å®šæ€§åˆ†æç»“æœçš„é€šç”¨æ€§ã€‚</li>
<li>æ•°å€¼ä¸ç¡®å®šæ€§åº¦é‡å¯ç”¨äºæ”¯æŒçº¿æ€§æ³¨å†Œç»“æœçš„è´¨é‡æ§åˆ¶ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00781">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4b391f5827ab70c2adb2cdc753f6b62e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a24ee3801eb3c6ab4728854ef1e277b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-901c32576544f3ba9632407f58ebfd3a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Sample-Aware-Test-Time-Adaptation-for-Medical-Image-to-Image-Translation"><a href="#Sample-Aware-Test-Time-Adaptation-for-Medical-Image-to-Image-Translation" class="headerlink" title="Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation"></a>Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation</h2><p><strong>Authors:Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda</strong></p>
<p>Image-to-image translation has emerged as a powerful technique in medical imaging, enabling tasks such as image denoising and cross-modality conversion. However, it suffers from limitations in handling out-of-distribution samples without causing performance degradation. To address this limitation, we propose a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the translation process based on the characteristics of each test sample. Our method introduces a Reconstruction Module to quantify the domain shift and a Dynamic Adaptation Block that selectively modifies the internal features of a pretrained translation model to mitigate the shift without compromising the performance on in-distribution samples that do not require adaptation. We evaluate our approach on two medical image-to-image translation tasks: low-dose CT denoising and T1 to T2 MRI translation, showing consistent improvements over both the baseline translation model without TTA and prior TTA methods. Our analysis highlights the limitations of the state-of-the-art that uniformly apply the adaptation to both out-of-distribution and in-distribution samples, demonstrating that dynamic, sample-specific adjustment offers a promising path to improve model resilience in real-world scenarios. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/cosbidev/Sample-Aware_TTA">https://github.com/cosbidev/Sample-Aware_TTA</a>. </p>
<blockquote>
<p>å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢åœ¨åŒ»å­¦æˆåƒä¸­å·²å´­éœ²å¤´è§’ä¸ºä¸€ç§å¼ºå¤§æŠ€æœ¯ï¼Œèƒ½å¤Ÿè¿›è¡Œå›¾åƒå»å™ªå’Œè·¨æ¨¡æ€è½¬æ¢ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ƒåœ¨å¤„ç†åˆ†å¸ƒå¤–æ ·æœ¬æ—¶å­˜åœ¨å±€é™æ€§ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ ¹æ®æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªé‡å»ºæ¨¡å—æ¥é‡åŒ–åŸŸè¿ç§»å’Œä¸€ä¸ªåŠ¨æ€é€‚åº”å—ï¼Œæœ‰é€‰æ‹©åœ°ä¿®æ”¹é¢„è®­ç»ƒç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»¥å‡è½»è¿ç§»ç°è±¡ï¼ŒåŒæ—¶ä¸å½±å“ä¸éœ€è¦é€‚åº”çš„ã€åˆ†å¸ƒå†…çš„æ ·æœ¬çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŒ»å­¦å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½å‰‚é‡CTå»å™ªå’ŒT1åˆ°T2 MRIç¿»è¯‘ï¼Œä¸æ²¡æœ‰TTAçš„åŸºçº¿ç¿»è¯‘æ¨¡å‹å’Œå…ˆå‰çš„TTAæ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºäº†ä¸€è‡´çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„åˆ†æå¼ºè°ƒäº†å½“å‰æŠ€æœ¯å¯¹æ‰€æœ‰æ ·æœ¬éƒ½ç»Ÿä¸€åº”ç”¨é€‚åº”æ€§çš„å±€é™æ€§ï¼Œè¯æ˜äº†åŠ¨æ€ã€é’ˆå¯¹æ ·æœ¬çš„ç‰¹å®šè°ƒæ•´æ˜¯æé«˜æ¨¡å‹åœ¨ç°å®åœºæ™¯ä¸­é€‚åº”æ€§çš„æœ‰å‰é€”çš„é€”å¾„ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/cosbidev/Sample-Aware_TTA">https://github.com/cosbidev/Sample-Aware_TTA</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00766v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘æŠ€æœ¯åœ¨åŒ»å­¦æˆåƒä¸­çš„å¼ºå¤§åº”ç”¨ï¼Œå¦‚å›¾åƒå»å™ªå’Œè·¨æ¨¡æ€è½¬æ¢ã€‚ç„¶è€Œï¼Œå®ƒé¢ä¸´å¤„ç†ç¦»ç¾¤æ ·æœ¬æ—¶æ€§èƒ½ä¸‹é™çš„å±€é™æ€§ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ ¹æ®æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ã€‚é€šè¿‡å¼•å…¥é‡å»ºæ¨¡å—æ¥é‡åŒ–åŸŸåç§»ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é€‚åº”å—é€‰æ‹©æ€§åœ°ä¿®æ”¹é¢„è®­ç»ƒçš„ç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»¥å‡è½»åç§»ï¼ŒåŒæ—¶ä¸æŸå®³å¯¹ä¸éœ€è¦é€‚åº”çš„æ ·æœ¬çš„æ€§èƒ½ã€‚æœ¬æ–‡åœ¨ä¸¤ä¸ªåŒ»å­¦å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†ç›¸è¾ƒäºåŸºå‡†ç¿»è¯‘æ¨¡å‹å’Œå…ˆå‰çš„TTAæ–¹æ³•çš„ä¸€è‡´æ”¹è¿›ã€‚æœ¬æ–‡åˆ†æçªæ˜¾äº†å½“å‰æŠ€æœ¯å‡åŒ€åº”ç”¨é€‚åº”äºç¦»ç¾¤æ ·æœ¬å’Œåˆ†å¸ƒå†…æ ·æœ¬çš„å±€é™æ€§ï¼Œå¹¶è¡¨æ˜åŠ¨æ€ã€æ ·æœ¬ç‰¹å®šçš„è°ƒæ•´æ˜¯æé«˜æ¨¡å‹åœ¨ç°å®åœºæ™¯ä¸­çš„ç¨³å¥æ€§çš„æœ‰å‰é€”çš„è·¯å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒåˆ°å›¾åƒç¿»è¯‘æŠ€æœ¯åœ¨åŒ»å­¦æˆåƒä¸­å…·æœ‰å¹¿æ³›åº”ç”¨ï¼Œå¦‚å›¾åƒå»å™ªå’Œè·¨æ¨¡æ€è½¬æ¢ã€‚</li>
<li>å½“å‰æŠ€æœ¯é¢ä¸´å¤„ç†ç¦»ç¾¤æ ·æœ¬æ—¶æ€§èƒ½ä¸‹é™çš„å±€é™æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰æ¡†æ¶ï¼Œèƒ½æ ¹æ®æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡é‡å»ºæ¨¡å—å’ŒåŠ¨æ€é€‚åº”å—æ¥é‡åŒ–åŸŸåç§»å¹¶é€‰æ‹©æ€§ä¿®æ”¹ç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ã€‚</li>
<li>åœ¨ä¸¤ä¸ªåŒ»å­¦å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä»»åŠ¡ä¸Šè¯„ä¼°äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†ç›¸è¾ƒäºåŸºå‡†æ–¹æ³•å’Œå…ˆå‰TTAæ–¹æ³•çš„ä¸€è‡´æ”¹è¿›ã€‚</li>
<li>åˆ†æçªæ˜¾äº†å‡åŒ€é€‚åº”ç­–ç•¥çš„å±€é™æ€§ï¼Œå¼ºè°ƒäº†åŠ¨æ€ã€æ ·æœ¬ç‰¹å®šçš„è°ƒæ•´èƒ½æé«˜æ¨¡å‹åœ¨ç°å®åœºæ™¯ä¸­çš„ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00766">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-226d15d0d90474eb4074bf4f84cdc810.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d81b0e25a15ade86b94031404659b7c1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LeakyCLIP-Extracting-Training-Data-from-CLIP"><a href="#LeakyCLIP-Extracting-Training-Data-from-CLIP" class="headerlink" title="LeakyCLIP: Extracting Training Data from CLIP"></a>LeakyCLIP: Extracting Training Data from CLIP</h2><p><strong>Authors:Yunhao Chen, Shujie Wang, Xin Wang, Xingjun Ma</strong></p>
<p>Understanding the memorization and privacy leakage risks in Contrastive Languageâ€“Image Pretraining (CLIP) is critical for ensuring the security of multimodal models. Recent studies have demonstrated the feasibility of extracting sensitive training examples from diffusion models, with conditional diffusion models exhibiting a stronger tendency to memorize and leak information. In this work, we investigate data memorization and extraction risks in CLIP through the lens of CLIP inversion, a process that aims to reconstruct training images from text prompts. To this end, we introduce \textbf{LeakyCLIP}, a novel attack framework designed to achieve high-quality, semantically accurate image reconstruction from CLIP embeddings. We identify three key challenges in CLIP inversion: 1) non-robust features, 2) limited visual semantics in text embeddings, and 3) low reconstruction fidelity. To address these challenges, LeakyCLIP employs 1) adversarial fine-tuning to enhance optimization smoothness, 2) linear transformation-based embedding alignment, and 3) Stable Diffusion-based refinement to improve fidelity. Empirical results demonstrate the superiority of LeakyCLIP, achieving over 358% improvement in Structural Similarity Index Measure (SSIM) for ViT-B-16 compared to baseline methods on LAION-2B subset. Furthermore, we uncover a pervasive leakage risk, showing that training data membership can even be successfully inferred from the metrics of low-fidelity reconstructions. Our work introduces a practical method for CLIP inversion while offering novel insights into the nature and scope of privacy risks in multimodal models. </p>
<blockquote>
<p>ç†è§£å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰ä¸­çš„è®°å¿†å’Œéšç§æ³„éœ²é£é™©å¯¹äºç¡®ä¿å¤šæ¨¡æ€æ¨¡å‹çš„å®‰å…¨æ€§è‡³å…³é‡è¦ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œä»æ‰©æ•£æ¨¡å‹ä¸­æå–æ•æ„Ÿè®­ç»ƒæ ·æœ¬æ˜¯å¯è¡Œçš„ï¼Œæ¡ä»¶æ‰©æ•£æ¨¡å‹åœ¨è®°å¿†å’Œæ³„éœ²ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„å€¾å‘ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡CLIPåè½¬çš„è§†è§’æ¥ç ”ç©¶CLIPä¸­çš„æ•°æ®è®°å¿†å’Œæå–é£é™©ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä»æ–‡æœ¬æç¤ºä¸­é‡å»ºè®­ç»ƒå›¾åƒçš„è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†\textbf{LeakyCLIP}ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æ”»å‡»æ¡†æ¶ï¼Œæ—¨åœ¨ä»CLIPåµŒå…¥ä¸­å®ç°é«˜è´¨é‡ã€è¯­ä¹‰å‡†ç¡®çš„å›¾åƒé‡å»ºã€‚æˆ‘ä»¬å‘ç°CLIPåè½¬å­˜åœ¨ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼š1ï¼‰ç‰¹å¾ä¸é²æ£’ï¼Œ2ï¼‰æ–‡æœ¬åµŒå…¥ä¸­çš„è§†è§‰è¯­ä¹‰æœ‰é™ï¼Œä»¥åŠ3ï¼‰é‡å»ºä¿çœŸåº¦ä½ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒLeakyCLIPé‡‡ç”¨1ï¼‰å¯¹æŠ—æ€§å¾®è°ƒä»¥å¢å¼ºä¼˜åŒ–å¹³æ»‘åº¦ï¼Œ2ï¼‰åŸºäºçº¿æ€§å˜æ¢çš„åµŒå…¥å¯¹é½ï¼Œä»¥åŠ3ï¼‰åŸºäºç¨³å®šæ‰©æ•£çš„ç»†åŒ–ä»¥æé«˜ä¿çœŸåº¦ã€‚ç»éªŒç»“æœè¡¨æ˜LeakyCLIPçš„ä¼˜åŠ¿ï¼Œä¸åŸºçº¿æ–¹æ³•åœ¨LAION-2Bå­é›†ä¸Šè¿›è¡Œæ¯”è¾ƒï¼Œç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°åº¦é‡ï¼ˆSSIMï¼‰æé«˜äº†358%ä»¥ä¸Šï¼ˆä»¥ViT-B-16ä¸ºä¾‹ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°äº†æ™®éçš„æ³„éœ²é£é™©ï¼Œè¡¨æ˜ç”šè‡³å¯ä»¥ä»ä½ä¿çœŸé‡å»ºçš„æŒ‡æ ‡ä¸­æˆåŠŸæ¨æ–­å‡ºè®­ç»ƒæ•°æ®æˆå‘˜ã€‚æˆ‘ä»¬çš„å·¥ä½œä»‹ç»äº†ä¸€ç§å®ç”¨çš„CLIPåè½¬æ–¹æ³•ï¼ŒåŒæ—¶æä¾›äº†å…³äºå¤šæ¨¡æ€æ¨¡å‹ä¸­éšç§é£é™©æœ¬è´¨å’ŒèŒƒå›´çš„æ–°è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00756v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†Contrastive Language-Image Pretrainingï¼ˆCLIPï¼‰æ¨¡å‹ä¸­çš„è®°å¿†ä¸éšç§æ³„éœ²é£é™©ã€‚ç ”ç©¶å‘ç°ï¼Œæ‰©æ•£æ¨¡å‹å­˜åœ¨æ•æ„Ÿè®­ç»ƒæ ·æœ¬å¯è¢«æå–çš„é£é™©ï¼Œä¸”æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„è®°å¿†å’Œæ³„éœ²ä¿¡æ¯å€¾å‘æ›´å¼ºã€‚æœ¬ç ”ç©¶é€šè¿‡CLIPåæ¼”çš„è§’åº¦ï¼Œæ¢ç©¶CLIPä¸­çš„æ•°æ®è®°å¿†å’Œæå–é£é™©ï¼Œå¹¶å¼•å…¥æ–°å‹æ”»å‡»æ¡†æ¶LeakyCLIPï¼Œæ—¨åœ¨ä»CLIPåµŒå…¥ä¸­å®ç°é«˜è´¨é‡ã€è¯­ä¹‰å‡†ç¡®çš„å›¾åƒé‡å»ºã€‚ç ”ç©¶ä¸­è¯†åˆ«å‡ºCLIPåæ¼”çš„ä¸‰å¤§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç‰¹å¾ä¸ç¨³å¥ã€æ–‡æœ¬åµŒå…¥ä¸­è§†è§‰è¯­ä¹‰æœ‰é™ä»¥åŠé‡å»ºä¿çœŸåº¦ä½ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼ŒLeakyCLIPé‡‡ç”¨å¯¹æŠ—æ€§å¾®è°ƒå¢å¼ºä¼˜åŒ–å¹³ç¨³æ€§ã€åŸºäºçº¿æ€§å˜æ¢çš„åµŒå…¥å¯¹é½ä»¥åŠåŸºäºStable Diffusionçš„ç²¾ç»†åŒ–ä¸ºæ”¹è¿›ä¿çœŸåº¦ã€‚å®è¯ç ”ç©¶è¯æ˜LeakyCLIPçš„ä¼˜è¶Šæ€§ï¼Œåœ¨LAION-2Bå­é›†ä¸Šä¸åŸºå‡†æ–¹æ³•ç›¸æ¯”ï¼ŒViT-B-16çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°(SSIM)æé«˜äº†è¶…è¿‡358%ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶æ­ç¤ºäº†å¹¿æ³›çš„æ³„éœ²é£é™©ï¼Œå³ä½¿åœ¨ä½ç²¾åº¦é‡å»ºçš„æŒ‡æ ‡ä¸­ï¼Œä¹Ÿèƒ½æˆåŠŸæ¨æ–­è®­ç»ƒæ•°æ®æˆå‘˜èº«ä»½ã€‚æœ¬ç ”ç©¶ä¸ºCLIPåæ¼”æä¾›äº†å®ç”¨æ–¹æ³•ï¼Œå¹¶ä¸ºå¤šæ¨¡æ€æ¨¡å‹ä¸­çš„éšç§é£é™©æä¾›äº†æ–°çš„è§è§£ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç†è§£CLIPæ¨¡å‹ä¸­è®°å¿†å’Œéšç§æ³„éœ²é£é™©å¯¹äºç¡®ä¿å¤šæ¨¡æ€æ¨¡å‹çš„å®‰å…¨æ€§è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶é€šè¿‡CLIPåæ¼”æ¢ç©¶CLIPæ¨¡å‹ä¸­çš„æ•°æ®è®°å¿†å’Œæå–é£é™©ã€‚</li>
<li>å¼•å…¥æ–°å‹æ”»å‡»æ¡†æ¶LeakyCLIPï¼Œå®ç°é«˜è´¨é‡ã€è¯­ä¹‰å‡†ç¡®çš„å›¾åƒä»CLIPåµŒå…¥ä¸­çš„é‡å»ºã€‚</li>
<li>è¯†åˆ«å‡ºCLIPåæ¼”çš„ä¸‰å¤§æŒ‘æˆ˜ï¼šç‰¹å¾ä¸ç¨³å¥ã€æ–‡æœ¬åµŒå…¥ä¸­è§†è§‰è¯­ä¹‰æœ‰é™å’Œé‡å»ºä¿çœŸåº¦ä½ã€‚</li>
<li>LeakyCLIPé‡‡ç”¨å¤šç§æŠ€æœ¯åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯¹æŠ—æ€§å¾®è°ƒã€åµŒå…¥å¯¹é½å’ŒåŸºäºStable Diffusionçš„ç²¾ç»†åŒ–ã€‚</li>
<li>å®è¯ç ”ç©¶è¯æ˜LeakyCLIPåœ¨SSIMä¸Šè¾ƒåŸºå‡†æ–¹æ³•æœ‰æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00756">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-96a2b224c4fec8217555faa576acc1d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64a0eefcf7f259bd66e4c30339e3e1ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbb890dd60799f5e4d90b79ecab16db4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a56def90e3a3794c4e19cc07cad4730.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Review-Adaptive-Radiation-Therapy-for-Head-and-Neck-Cancer"><a href="#Review-Adaptive-Radiation-Therapy-for-Head-and-Neck-Cancer" class="headerlink" title="Review: Adaptive Radiation Therapy for Head and Neck Cancer"></a>Review: Adaptive Radiation Therapy for Head and Neck Cancer</h2><p><strong>Authors:Lucas McCullum, Sonali J. Joshi, Brandon M. Godinich, Parshawn Gerafian, Rishabh Gaur, Qusai Alakayleh, Ergys Subashi, Renjie He, Samuel L. Mulder, Zaphanlene Kaffey, Grace Murley, Natalie A. West, Saleh Ramezani, Cem Dede, Laia Humbert-Vidan, Clifton D. Fuller</strong></p>
<p>The future of ART in head and neck cancer is just beginning. Novel technologies have pushed the boundary of what is possible in terms of techniques to identify biomarkers for adaptation as well as innovative devices specialized to respond to these adaptations, sometimes in real-time. Important interdisciplinary steps must be taken moving forward to ensure the safe deployment of these new techniques, such as rigorous quality assurance evaluations from medical physicists, clinical trials from physicians, and comprehensive testing from vendors prior to release. In summary, we aimed not to provide a single correct answer for the optimal implementation of ART in the era of imaging biomarkers, but to encourage the field to collaborate and bring each idea discussed here together to overcome current barriers and deliver the best treatment possible to the patient. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒé¢†åŸŸä¸­çš„ARTï¼ˆå…ˆè¿›æ”¾ç–—æŠ€æœ¯ï¼‰åœ¨å¤´é¢ˆç™Œæ²»ç–—ä¸­çš„æœªæ¥æ‰åˆšåˆšå¼€å§‹ã€‚æ–°æŠ€æœ¯å·²ç»çªç ´äº†æŠ€æœ¯ä¸Šçš„å¯èƒ½è¾¹ç•Œï¼Œä¸ä»…åœ¨å¯»æ‰¾é€‚åº”çš„ç”Ÿç‰©æ ‡å¿—ç‰©æ–¹é¢ï¼Œè€Œä¸”è¿˜æ¨åŠ¨äº†ä¸“é—¨åº”å¯¹è¿™äº›é€‚åº”çš„å®æ—¶åˆ›æ–°è®¾å¤‡çš„å‘å±•ã€‚æœªæ¥è¦å‘å‰æ¨è¿›ï¼Œå°±å¿…é¡»é‡‡å–é‡è¦çš„è·¨å­¦ç§‘æ­¥éª¤ï¼Œä»¥ç¡®ä¿è¿™äº›æ–°æŠ€æœ¯çš„å®‰å…¨éƒ¨ç½²ï¼ŒåŒ…æ‹¬åŒ»å­¦ç‰©ç†å­¦å®¶ä¸¥æ ¼çš„è´¨é‡ä¿è¯è¯„ä¼°ã€åŒ»ç”Ÿçš„ä¸´åºŠè¯•éªŒä»¥åŠä¾›åº”å•†åœ¨å‘å¸ƒå‰çš„å…¨é¢æµ‹è¯•ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„ç›®æ ‡ä¸æ˜¯ä¸ºARTåœ¨æˆåƒç”Ÿç‰©æ ‡å¿—ç‰©æ—¶ä»£æä¾›æœ€ä½³å®æ–½çš„å•ä¸€æ­£ç¡®ç­”æ¡ˆï¼Œè€Œæ˜¯é¼“åŠ±è¯¥é¢†åŸŸåˆä½œï¼Œå°†è¿™é‡Œè®¨è®ºçš„æ¯ä¸ªæƒ³æ³•ç»“åˆèµ·æ¥ï¼Œå…‹æœå½“å‰éšœç¢ï¼Œä¸ºæ‚£è€…æä¾›æœ€ä½³æ²»ç–—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00651v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€æ–°å‹æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œå¤´é¢ˆç™Œçš„ARTï¼ˆæ”¾å°„ç–—æ³•ï¼‰æœªæ¥å‰æ™¯åˆç°ã€‚ç›®å‰ï¼Œå·²ç»å¯ä»¥åˆ©ç”¨æ–°å‹æŠ€æœ¯è¯†åˆ«ç”Ÿç‰©æ ‡è®°ç‰©å¹¶è¿›è¡Œé€‚åº”ï¼ŒåŒæ—¶è¿˜å¯ä½¿ç”¨é’ˆå¯¹è¿™äº›é€‚åº”çš„å®æ—¶åé¦ˆçš„ä¸“ä¸šè®¾å¤‡ã€‚æœªæ¥ç¡®ä¿æ–°æŠ€æœ¯å®‰å…¨éƒ¨ç½²è‡³å…³é‡è¦ï¼Œå¦‚ç‰©ç†å­¦å®¶è¿›è¡Œä¸¥æ ¼çš„è´¨é‡ä¿è¯è¯„ä¼°ã€åŒ»å¸ˆçš„ä¸´åºŠè¯•éªŒå’Œä¾›åº”å•†æä¾›çš„å…¨é¢æµ‹è¯•ç­‰è·¨å­¦ç§‘æ­¥éª¤å¿…ä¸å¯å°‘ã€‚æ€»ä¹‹ï¼Œæœ¬æ–‡æ—¨åœ¨ä¸ºARTåœ¨æˆåƒç”Ÿç‰©æ ‡å¿—ç‰©æ—¶ä»£çš„æœ€ä½³å®æ–½æ–¹å¼æä¾›ä¸€ä¸ªäº¤æµåˆä½œçš„å¹³å°ï¼Œå…±åŒå…‹æœç°æœ‰éšœç¢ï¼Œä¸ºæ‚£è€…æä¾›æœ€ä½³æ²»ç–—æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœªæ¥å¤´é¢ˆç™Œçš„ARTæ²»ç–—å‰æ™¯å¹¿é˜”ï¼Œå¾—ç›Šäºæ–°æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œåˆ›æ–°ã€‚</li>
<li>è¯†åˆ«ç”Ÿç‰©æ ‡è®°ç‰©å’Œé€‚åº”æŠ€æœ¯æ˜¯å½“å‰æ–°æŠ€æœ¯åº”ç”¨çš„å…³é”®æ–¹å‘ã€‚</li>
<li>ä¸ºç¡®ä¿æ–°æŠ€æœ¯å®‰å…¨éƒ¨ç½²ï¼Œè·¨å­¦ç§‘åˆä½œè‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬åŒ»å­¦ç‰©ç†å­¦å®¶ã€åŒ»å¸ˆå’Œä¾›åº”å•†çš„å…¨é¢å‚ä¸ã€‚</li>
<li>ç›®å‰é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚éœ€è¦å…‹æœæŠ€æœ¯å£å’å’Œåä½œéš¾é¢˜ã€‚</li>
<li>æ–°å‹æŠ€æœ¯æœ‰åŠ©äºæé«˜æ²»ç–—æ•ˆæœå’Œæ‚£è€…ç”Ÿå­˜ç‡ã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨é¼“åŠ±è·¨å­¦ç§‘åˆä½œå’Œäº¤æµï¼Œå…±åŒä¸ºå¤´é¢ˆç™Œæ‚£è€…å¯»æ‰¾æœ€ä½³æ²»ç–—æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00651">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f1bf4a1141ff40497aaeeec616e58751.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeb06b433b4195504aa27d21f19cf84d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5fc9ff8311affea441c01cb0a0de7e1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-28ca6b22530525d93172a1b22b3c5d98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bfb1530d9d904541852344bc04938f89.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Novel-Modeling-Framework-and-Data-Product-for-Extended-VIIRS-like-Artificial-Nighttime-Light-Image-Reconstruction-1986-2024"><a href="#A-Novel-Modeling-Framework-and-Data-Product-for-Extended-VIIRS-like-Artificial-Nighttime-Light-Image-Reconstruction-1986-2024" class="headerlink" title="A Novel Modeling Framework and Data Product for Extended VIIRS-like   Artificial Nighttime Light Image Reconstruction (1986-2024)"></a>A Novel Modeling Framework and Data Product for Extended VIIRS-like   Artificial Nighttime Light Image Reconstruction (1986-2024)</h2><p><strong>Authors:Yihe Tian, Kwan Man Cheng, Zhengbo Zhang, Tao Zhang, Suju Li, Dongmei Yan, Bing Xu</strong></p>
<p>Artificial Night-Time Light (NTL) remote sensing is a vital proxy for quantifying the intensity and spatial distribution of human activities. Although the NPP-VIIRS sensor provides high-quality NTL observations, its temporal coverage, which begins in 2012, restricts long-term time-series studies that extend to earlier periods. Despite the progress in extending VIIRS-like NTL time-series, current methods still suffer from two significant shortcomings: the underestimation of light intensity and the structural omission. To overcome these limitations, we propose a novel reconstruction framework consisting of a two-stage process: construction and refinement. The construction stage features a Hierarchical Fusion Decoder (HFD) designed to enhance the fidelity of the initial reconstruction. The refinement stage employs a Dual Feature Refiner (DFR), which leverages high-resolution impervious surface masks to guide and enhance fine-grained structural details. Based on this framework, we developed the Extended VIIRS-like Artificial Nighttime Light (EVAL) product for China, extending the standard data record backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL significantly outperforms existing state-of-the-art products, boosting the $\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99. Furthermore, EVAL exhibits excellent temporal consistency and maintains a high correlation with socioeconomic parameters, confirming its reliability for long-term analysis. The resulting EVAL dataset provides a valuable new resource for the research community and is publicly available at <a target="_blank" rel="noopener" href="https://doi.org/10.11888/HumanNat.tpdc.302930">https://doi.org/10.11888/HumanNat.tpdc.302930</a>. </p>
<blockquote>
<p>å¤œé—´äººå·¥å…‰ç…§ï¼ˆNTLï¼‰é¥æ„Ÿæ˜¯é‡åŒ–äººç±»æ´»åŠ¨å¼ºåº¦å’Œç©ºé—´åˆ†å¸ƒçš„é‡è¦ä»£ç†ã€‚å°½ç®¡NPP-VIIRSä¼ æ„Ÿå™¨æä¾›äº†é«˜è´¨é‡çš„NTLè§‚æµ‹æ•°æ®ï¼Œä½†å…¶å§‹äº2012å¹´çš„æ—¶é—´è¦†ç›–èŒƒå›´é™åˆ¶äº†é•¿æœŸæ—¶é—´åºåˆ—ç ”ç©¶å‘æ›´æ—©æ—¶æœŸçš„å»¶ä¼¸ã€‚å°½ç®¡åœ¨æ‰©å±•ç±»ä¼¼VIIRSçš„NTLæ—¶é—´åºåˆ—æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å½“å‰æ–¹æ³•ä»ç„¶å­˜åœ¨ä¸¤ä¸ªé‡å¤§ç¼ºé™·ï¼šå…‰çº¿å¼ºåº¦è¢«ä½ä¼°å’Œç»“æ„é—æ¼ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é‡å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šæ„å»ºå’Œç»†åŒ–ã€‚æ„å»ºé˜¶æ®µé‡‡ç”¨åˆ†å±‚èåˆè§£ç å™¨ï¼ˆHFDï¼‰è®¾è®¡ï¼Œæ—¨åœ¨æé«˜åˆå§‹é‡å»ºçš„ä¿çœŸåº¦ã€‚ç»†åŒ–é˜¶æ®µé‡‡ç”¨åŒé‡ç‰¹å¾ç»†åŒ–å™¨ï¼ˆDFRï¼‰ï¼Œåˆ©ç”¨é«˜åˆ†è¾¨ç‡çš„ä¸é€æ°´è¡¨é¢æ©è†œæ¥å¼•å¯¼å’Œå¢å¼ºç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚åŸºäºè¿™ä¸€æ¡†æ¶ï¼Œæˆ‘ä»¬ä¸ºä¸­å›½å¼€å‘äº†æ‰©å±•çš„ç±»ä¼¼VIIRSå¤œé—´äººå·¥å…‰ç…§ï¼ˆEVALï¼‰äº§å“ï¼Œå°†æ ‡å‡†æ•°æ®è®°å½•å‘åæ‰©å±•äº†26å¹´ï¼Œä»1986å¹´å¼€å§‹ã€‚å®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒEVALäº§å“åœ¨è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„åŒç±»äº§å“ï¼Œå°†RÂ²ä»0.68æé«˜åˆ°0.80ï¼ŒåŒæ—¶å°†RMSEä»1.27é™ä½åˆ°0.99ã€‚æ­¤å¤–ï¼ŒEVALè¡¨ç°å‡ºè‰¯å¥½çš„æ—¶é—´ä¸€è‡´æ€§ï¼Œå¹¶ä¸ç¤¾ä¼šç»æµå‚æ•°ä¿æŒé«˜åº¦ç›¸å…³æ€§ï¼Œè¯å®äº†å…¶é€‚ç”¨äºé•¿æœŸåˆ†æçš„å¯é æ€§ã€‚æ‰€å¾—çš„EVALæ•°æ®é›†ä¸ºç ”ç©¶é¢†åŸŸæä¾›äº†å®è´µçš„æ–°èµ„æºï¼Œå¹¶å¯åœ¨<a target="_blank" rel="noopener" href="https://doi.org/10.11888/HumanNat.tpdc.302930%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://doi.org/10.11888/HumanNat.tpdc.302930å…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00590v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬ç ”ç©¶åˆ©ç”¨æ–°å‹é‡å»ºæ¡†æ¶æ‰©å±•äº†VIIRSäººé€ å¤œé—´ç¯å…‰æ•°æ®çš„æ—¶é—´åºåˆ—ï¼Œé€šè¿‡æ„å»ºå’Œå®Œå–„ä¸¤ä¸ªé˜¶æ®µæé«˜ç¯å…‰å¼ºåº¦ä¸ç»“æ„ç»†èŠ‚çš„å¤åŸç²¾åº¦ã€‚å¼€å‘å‡ºçš„EVALäº§å“å¯å›æº¯è‡³1986å¹´ï¼Œæ˜¾è‘—æé«˜äº†RÂ²å€¼å¹¶é™ä½äº†RMSEï¼Œå…·æœ‰è‰¯å¥½çš„æ—¶é—´ä¸€è‡´æ€§å’Œä¸ç¤¾ä¼šç»æµå‚æ•°çš„é«˜ç›¸å…³æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººé€ å¤œé—´ç¯å…‰é¥æ„Ÿæ˜¯é‡åŒ–äººç±»æ´»åŠ¨å¼ºåº¦å’Œç©ºé—´åˆ†å¸ƒçš„é‡è¦ä»£ç†ã€‚</li>
<li>NPP-VIIRSä¼ æ„Ÿå™¨æä¾›é«˜è´¨é‡NTLè§‚æµ‹æ•°æ®ï¼Œä½†å…¶æ—¶é—´è¦†ç›–èŒƒå›´ä»…é™äº2012å¹´ä»¥åï¼Œé™åˆ¶äº†é•¿æœŸæ—¶é—´åºåˆ—ç ”ç©¶ã€‚</li>
<li>å½“å‰æ‰©å±•VIIRS-like NTLæ—¶é—´åºåˆ—çš„æ–¹æ³•å­˜åœ¨ä½ä¼°å…‰å¼ºåº¦å’Œç»“æ„é—æ¼çš„ç¼ºé™·ã€‚</li>
<li>æ–°å‹é‡å»ºæ¡†æ¶åŒ…æ‹¬æ„å»ºå’Œå®Œå–„ä¸¤ä¸ªé˜¶æ®µï¼Œæ—¨åœ¨æé«˜åˆå§‹é‡å»ºçš„ä¿çœŸåº¦å’Œç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚</li>
<li>EVALäº§å“å°†æ ‡å‡†æ•°æ®è®°å½•æ‰©å±•è‡³1986å¹´ï¼Œå¹¶æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„äº§å“ã€‚</li>
<li>EVALäº§å“åœ¨å®šé‡è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œå¦‚æé«˜RÂ²å€¼ã€é™ä½RMSEï¼ŒåŒæ—¶ä¿æŒé«˜åº¦çš„æ—¶é—´ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00590">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-90d5cd159792770a76c3cf514ede2016.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-342db3939d57975d950c2b41883e0048.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e27903b9a6a11fba6070869ded2b181.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Your-other-Left-Vision-Language-Models-Fail-to-Identify-Relative-Positions-in-Medical-Images"><a href="#Your-other-Left-Vision-Language-Models-Fail-to-Identify-Relative-Positions-in-Medical-Images" class="headerlink" title="Your other Left! Vision-Language Models Fail to Identify Relative   Positions in Medical Images"></a>Your other Left! Vision-Language Models Fail to Identify Relative   Positions in Medical Images</h2><p><strong>Authors:Daniel Wolf, Heiko Hillenhagen, Billurvan Taskin, Alex BÃ¤uerle, Meinrad Beer, Michael GÃ¶tz, Timo Ropinski</strong></p>
<p>Clinical decision-making relies heavily on understanding relative positions of anatomical structures and anomalies. Therefore, for Vision-Language Models (VLMs) to be applicable in clinical practice, the ability to accurately determine relative positions on medical images is a fundamental prerequisite. Despite its importance, this capability remains highly underexplored. To address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o, Llama3.2, Pixtral, and JanusPro, and find that all models fail at this fundamental task. Inspired by successful approaches in computer vision, we investigate whether visual prompts, such as alphanumeric or colored markers placed on anatomical structures, can enhance performance. While these markers provide moderate improvements, results remain significantly lower on medical images compared to observations made on natural images. Our evaluations suggest that, in medical imaging, VLMs rely more on prior anatomical knowledge than on actual image content for answering relative position questions, often leading to incorrect conclusions. To facilitate further research in this area, we introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset, designed to systematically evaluate the capability to identify relative positions in medical images. </p>
<blockquote>
<p>ä¸´åºŠå†³ç­–åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¯¹è§£å‰–ç»“æ„å’Œå¼‚å¸¸ç›¸å¯¹ä½ç½®çš„ç†è§£ã€‚å› æ­¤ï¼Œè¦ä½¿è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨ä¸´åºŠå®è·µä¸­å¾—åˆ°åº”ç”¨ï¼Œå‡†ç¡®ç¡®å®šåŒ»å­¦å›¾åƒä¸Šç›¸å¯¹ä½ç½®çš„èƒ½åŠ›æ˜¯åŸºæœ¬å‰æã€‚å°½ç®¡è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œä½†è¿™ç§èƒ½åŠ›ä»ç„¶è¢«å¤§å¤§å¿½è§†ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬è¯„ä¼°äº†æœ€å‰æ²¿çš„VLMsï¼ŒåŒ…æ‹¬GPT-4oã€Llama3.2ã€Pixtralå’ŒJanusProï¼Œå‘ç°æ‰€æœ‰è¿™äº›æ¨¡å‹åœ¨è¿™ä¸ªåŸºæœ¬ä»»åŠ¡ä¸Šéƒ½å¤±è´¥äº†ã€‚å—è®¡ç®—æœºè§†è§‰æˆåŠŸæ–¹æ³•çš„å¯å‘ï¼Œæˆ‘ä»¬è°ƒæŸ¥äº†è§†è§‰æç¤ºï¼ˆå¦‚åœ¨è§£å‰–ç»“æ„ä¸Šæ”¾ç½®å­—æ¯æ•°å­—æˆ–å½©è‰²æ ‡è®°ï¼‰æ˜¯å¦èƒ½æé«˜æ€§èƒ½ã€‚è™½ç„¶è¿™äº›æ ‡è®°æä¾›äº†é€‚åº¦çš„æ”¹è¿›ï¼Œä½†åœ¨åŒ»å­¦å›¾åƒä¸Šçš„ç»“æœä»ç„¶æ˜¾è‘—ä½äºåœ¨è‡ªç„¶å›¾åƒä¸Šè§‚å¯Ÿåˆ°çš„ç»“æœã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼Œåœ¨åŒ»å­¦æˆåƒä¸­ï¼ŒVLMsæ›´ä¾èµ–äºå…ˆéªŒè§£å‰–çŸ¥è¯†è€Œä¸æ˜¯å®é™…çš„å›¾åƒå†…å®¹æ¥å›ç­”ç›¸å¯¹ä½ç½®é—®é¢˜ï¼Œè¿™å¸¸å¸¸å¯¼è‡´é”™è¯¯çš„ç»“è®ºã€‚ä¸ºäº†ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒ»ç–—æˆåƒç›¸å¯¹å®šä½ï¼ˆMIRPï¼‰åŸºå‡†æ•°æ®é›†ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°åœ¨åŒ»å­¦å›¾åƒä¸Šè¯†åˆ«ç›¸å¯¹ä½ç½®çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00549v1">PDF</a> Accepted at the International Conference on Medical Image Computing   and Computer Assisted Intervention (MICCAI) 2025</p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦å›¾åƒåœ¨ä¸´åºŠå†³ç­–ä¸­è‡³å…³é‡è¦ï¼Œè¦æ±‚ç†è§£ç»“æ„ä¹‹é—´çš„ç›¸å¯¹ä½ç½®ã€‚å¯¹äºè¯­è¨€æ¨¡å‹åº”ç”¨äºä¸´åºŠå®è·µè€Œè¨€ï¼Œç¡®å®šåŒ»å­¦å›¾åƒä¸Šçš„ç›¸å¯¹ä½ç½®æ˜¯ä¸€ä¸ªåŸºæœ¬å‰æã€‚å°½ç®¡å…¶é‡è¦æ€§ï¼Œè¯¥èƒ½åŠ›åœ¨ç°æœ‰æ¨¡å‹ä¸­çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚æœ¬æ–‡è¯„ä¼°äº†å…ˆè¿›çš„è¯­è¨€æ¨¡å‹GPT-4oã€Llama3.2ã€Pixtralå’ŒJanusProï¼Œå‘ç°å®ƒä»¬åœ¨è¿™ä¸€åŸºæœ¬ä»»åŠ¡ä¸Šå‡å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡è¯•å›¾æ¢ç©¶é€šè¿‡è§†è§‰æç¤ºå¦‚è§£å‰–ç»“æ„ä¸Šçš„å­—æ¯æ•°å­—æ ‡è®°ç­‰æ–¹æ³•æ¥æå‡æ€§èƒ½ï¼Œç„¶è€Œè¡¨ç°ä»ä½äºé¢„æœŸã€‚æ ‡è®°ä¸»è¦ä¾èµ–äºå¯¹å…ˆå‰è§£å‰–çŸ¥è¯†çš„åˆ¤æ–­è€Œéå®é™…å›¾åƒå†…å®¹æ¥å›ç­”ç›¸å¯¹ä½ç½®é—®é¢˜ï¼Œè¿™å¸¸å¸¸å¯¼è‡´é”™è¯¯ç»“è®ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº† MIRPï¼ˆåŒ»å­¦å›¾åƒç›¸å¯¹å®šä½ï¼‰åŸºå‡†æ•°æ®é›†ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°è¯†åˆ«åŒ»å­¦å›¾åƒä¸­ç›¸å¯¹ä½ç½®çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¸´åºŠå†³ç­–é«˜åº¦ä¾èµ–å¯¹åŒ»å­¦å›¾åƒä¸Šç»“æ„ç›¸å¯¹ä½ç½®çš„ç†è§£ã€‚</li>
<li>è¯­è¨€æ¨¡å‹åº”ç”¨äºåŒ»å­¦å®è·µéœ€è¦å…·å¤‡å‡†ç¡®ç¡®å®šåŒ»å­¦å›¾åƒä¸Šçš„ç›¸å¯¹ä½ç½®çš„èƒ½åŠ›ã€‚</li>
<li>å½“å‰å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨è¿™ä¸€åŸºæœ¬ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸è¶³ã€‚</li>
<li>é€šè¿‡è§†è§‰æç¤ºå¦‚å­—æ¯æ•°å­—æ ‡è®°ç­‰æ–¹æ³•å¯ä»¥æ”¹å–„æ¨¡å‹çš„æ€§èƒ½ï¼Œä½†æå‡æœ‰é™ã€‚</li>
<li>è¯­è¨€æ¨¡å‹åœ¨å¤„ç†åŒ»å­¦å›¾åƒæ—¶ï¼Œæ›´å¤šåœ°ä¾èµ–è§£å‰–çŸ¥è¯†çš„å…ˆéªŒåˆ¤æ–­è€Œéå›¾åƒæœ¬èº«çš„å†…å®¹ã€‚</li>
<li>è¯­è¨€æ¨¡å‹åœ¨ç›¸å¯¹ä½ç½®åˆ¤æ–­ä¸Šå®¹æ˜“å¾—å‡ºé”™è¯¯ç»“è®ºã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00549">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e5132f7e99a64f865a4113ca53369585.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0821276846275441f8e82e1862a0e846.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e04e22995f7fb2dee4fe7a436bfaced.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="LesiOnTime-â€“-Joint-Temporal-and-Clinical-Modeling-for-Small-Breast-Lesion-Segmentation-in-Longitudinal-DCE-MRI"><a href="#LesiOnTime-â€“-Joint-Temporal-and-Clinical-Modeling-for-Small-Breast-Lesion-Segmentation-in-Longitudinal-DCE-MRI" class="headerlink" title="LesiOnTime â€“ Joint Temporal and Clinical Modeling for Small Breast   Lesion Segmentation in Longitudinal DCE-MRI"></a>LesiOnTime â€“ Joint Temporal and Clinical Modeling for Small Breast   Lesion Segmentation in Longitudinal DCE-MRI</h2><p><strong>Authors:Mohammed Kamran, Maria Bernathova, Raoul Varga, Christian Singer, Zsuzsanna Bago-Horvath, Thomas Helbich, Georg Langs, Philipp SeebÃ¶ck</strong></p>
<p>Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk patients. While recent deep learning methods have advanced lesion segmentation, they primarily target large lesions and neglect valuable longitudinal and clinical information routinely used by radiologists. In real-world screening, detecting subtle or emerging lesions requires radiologists to compare across timepoints and consider previous radiology assessments, such as the BI-RADS score. We propose LesiOnTime, a novel 3D segmentation approach that mimics clinical diagnostic workflows by jointly leveraging longitudinal imaging and BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA) block that dynamically integrates information from previous and current scans; and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent space alignment for scans with similar radiological assessments, thus embedding domain knowledge into the training process. Evaluated on a curated in-house longitudinal dataset of high-risk patients with DCE-MRI, our approach outperforms state-of-the-art single-timepoint and longitudinal baselines by 5% in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute complementary performance gains. These results highlight the importance of incorporating temporal and clinical context for reliable early lesion segmentation in real-world breast cancer screening. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/cirmuw/LesiOnTime">https://github.com/cirmuw/LesiOnTime</a> </p>
<blockquote>
<p>åœ¨ä¹³è…ºåŠ¨æ€å¯¹æ¯”å¢å¼ºMRIï¼ˆDCE-MRIï¼‰ä¸­å¯¹å°ç—…ç¶è¿›è¡Œç²¾ç¡®åˆ†å‰²å¯¹äºæ—©æœŸç™Œç—‡æ£€æµ‹è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜é£é™©æ‚£è€…ä¸­ã€‚è™½ç„¶æœ€è¿‘çš„æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨ç—…ç¶åˆ†å‰²æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å®ƒä»¬ä¸»è¦é’ˆå¯¹å¤§ç—…ç¶ï¼Œå¿½è§†äº†æ”¾å°„ç§‘åŒ»ç”Ÿé€šå¸¸ä½¿ç”¨çš„å®è´µçºµå‘å’Œä¸´åºŠä¿¡æ¯ã€‚åœ¨ç°å®ä¸–ç•Œç­›æŸ¥ä¸­ï¼Œæ£€æµ‹ç»†å¾®æˆ–æ–°å…´ç—…ç¶éœ€è¦æ”¾å°„ç§‘åŒ»ç”Ÿæ¯”è¾ƒä¸åŒæ—¶é—´ç‚¹å¹¶è€ƒè™‘ä¹‹å‰çš„æ”¾å°„å­¦è¯„ä¼°ï¼Œä¾‹å¦‚BI-RADSè¯„åˆ†ã€‚æˆ‘ä»¬æå‡ºäº†LesiOnTimeï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„3Dåˆ†å‰²æ–¹æ³•ï¼Œå®ƒé€šè¿‡è”åˆåˆ©ç”¨çºµå‘æˆåƒå’ŒBIRADSè¯„åˆ†æ¥æ¨¡ä»¿ä¸´åºŠè¯Šæ–­å·¥ä½œæµç¨‹ã€‚å…³é”®ç»„ä»¶åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰Temporal Prior Attentionï¼ˆTPAï¼‰å—ï¼Œå…¶åŠ¨æ€ç»“åˆäº†æ¥è‡ªä¹‹å‰å’Œå½“å‰æ‰«æçš„ä¿¡æ¯ï¼›ï¼ˆ2ï¼‰BI-RADSä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼ˆBCRï¼‰æŸå¤±ï¼Œå…¶å¼ºåˆ¶å¯¹å…·æœ‰ç›¸ä¼¼æ”¾å°„å­¦è¯„ä¼°çš„æ‰«æè¿›è¡Œæ½œåœ¨ç©ºé—´å¯¹é½ï¼Œä»è€Œå°†é¢†åŸŸçŸ¥è¯†åµŒå…¥åˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚æˆ‘ä»¬åœ¨é«˜é£é™©æ‚£è€…çš„DCE-MRIä¸“ç”¨çºµå‘æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æœ€å…ˆè¿›çš„å•æ—¶é—´ç‚¹çºµå‘åŸºå‡†æµ‹è¯•æ–¹é¢é«˜å‡º5ï¼…çš„Diceç³»æ•°ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒTPAå’ŒBCRéƒ½è´¡çŒ®å‡ºäº†è¡¥å……çš„æ€§èƒ½æå‡ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†ç»“åˆæ—¶é—´å’Œä¸´åºŠèƒŒæ™¯å¯¹äºç°å®ä¸–ç•Œä¹³è…ºç™Œç­›æŸ¥ä¸­å¯é æ—©æœŸç—…ç¶åˆ†å‰²çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨å…¬å¼€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/cirmuw/LesiOnTime%E3%80%82">https://github.com/cirmuw/LesiOnTimeã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00496v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºLesiOnTimeçš„æ–°å‹ä¸‰ç»´åˆ†å‰²æ–¹æ³•ï¼Œç”¨äºåŠ¨æ€å¯¹æ¯”å¢å¼ºç£å…±æŒ¯æˆåƒï¼ˆDCE-MRIï¼‰ä¸­ä¹³è…ºå¾®å°ç—…ç¶çš„ç²¾ç¡®åˆ†å‰²ã€‚è¯¥æ–¹æ³•æ¨¡æ‹Ÿä¸´åºŠè¯Šæ–­å·¥ä½œæµç¨‹ï¼ŒåŒæ—¶åˆ©ç”¨çºµå‘æˆåƒå’ŒBI-RADSè¯„åˆ†ã€‚å…¶æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬Temporal Prior Attentionï¼ˆTPAï¼‰å—å’ŒBI-RADS Consistency Regularizationï¼ˆBCRï¼‰æŸå¤±ã€‚åœ¨åŒ…å«DCE-MRIçš„é«˜å±æ‚£è€…çºµå‘æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œè¯¥æ–¹æ³•ä¼˜äºå•æ—¶é—´ç‚¹å’Œå¹³è¡ŒåŸºçº¿æ–¹æ³•ï¼ŒDiceç³»æ•°æé«˜5%ã€‚ç ”ç©¶å¼ºè°ƒäº†ç»“åˆæ—¶é—´å’Œä¸´åºŠèƒŒæ™¯ä¿¡æ¯åœ¨æ—©æœŸä¹³è…ºç™Œç­›æŸ¥ä¸­å¯é åˆ†å‰²å¾®å°ç—…ç¶çš„é‡è¦æ€§ã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LesiOnTimeæ˜¯ä¸€ç§é’ˆå¯¹åŠ¨æ€å¯¹æ¯”å¢å¼ºç£å…±æŒ¯æˆåƒï¼ˆDCE-MRIï¼‰ä¹³è…ºå¾®å°ç—…ç¶åˆ†å‰²çš„æ–°å‹ä¸‰ç»´åˆ†å‰²æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•æ¨¡æ‹Ÿä¸´åºŠè¯Šæ–­å·¥ä½œæµç¨‹ï¼ŒåŒæ—¶åˆ©ç”¨çºµå‘æˆåƒä¿¡æ¯å’ŒBI-RADSè¯„åˆ†ã€‚</li>
<li>LesiOnTimeåŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šTemporal Prior Attentionï¼ˆTPAï¼‰å—å’ŒBI-RADS Consistency Regularizationï¼ˆBCRï¼‰æŸå¤±ã€‚</li>
<li>åœ¨é«˜å±æ‚£è€…çºµå‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒLesiOnTimeä¼˜äºå…¶ä»–æ–¹æ³•ï¼ŒDiceç³»æ•°æé«˜5%ã€‚</li>
<li>ç ”ç©¶å¼ºè°ƒäº†ç»“åˆæ—¶é—´å’Œä¸´åºŠèƒŒæ™¯ä¿¡æ¯åœ¨æ—©æœŸä¹³è…ºç™Œè¯Šæ–­ä¸­çš„é‡è¦æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00496">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bca7f96c3cb3b631b35709a72f0c901f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-35023fb5f069b03f535e7fe06384d7cf.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Reducing-the-gap-between-general-purpose-data-and-aerial-images-in-concentrated-solar-power-plants"><a href="#Reducing-the-gap-between-general-purpose-data-and-aerial-images-in-concentrated-solar-power-plants" class="headerlink" title="Reducing the gap between general purpose data and aerial images in   concentrated solar power plants"></a>Reducing the gap between general purpose data and aerial images in   concentrated solar power plants</h2><p><strong>Authors:M. A. PÃ©rez-CutiÃ±o, J. Valverde, J. CapitÃ¡n, J. M. DÃ­az-BÃ¡Ã±ez</strong></p>
<p>In the context of Concentrated Solar Power (CSP) plants, aerial images captured by drones present a unique set of challenges. Unlike urban or natural landscapes commonly found in existing datasets, solar fields contain highly reflective surfaces, and domain-specific elements that are uncommon in traditional computer vision benchmarks. As a result, machine learning models trained on generic datasets struggle to generalize to this setting without extensive retraining and large volumes of annotated data. However, collecting and labeling such data is costly and time-consuming, making it impractical for rapid deployment in industrial applications.   To address this issue, we propose a novel approach: the creation of AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By generating synthetic data that closely mimic real-world conditions, our objective is to facilitate pretraining of models before deployment, significantly reducing the need for extensive manual labeling. Our main contributions are threefold: (1) we introduce AerialCSP, a high-quality synthetic dataset for aerial inspection of CSP plants, providing annotated data for object detection and image segmentation; (2) we benchmark multiple models on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we demonstrate that pretraining on AerialCSP significantly improves real-world fault detection, particularly for rare and small defects, reducing the need for extensive manual labeling. AerialCSP is made publicly available at <a target="_blank" rel="noopener" href="https://mpcutino.github.io/aerialcsp/">https://mpcutino.github.io/aerialcsp/</a>. </p>
<blockquote>
<p>åœ¨é›†ä¸­å¼å¤ªé˜³èƒ½å‘ç”µï¼ˆCSPï¼‰å·¥å‚çš„æƒ…å¢ƒä¸­ï¼Œæ— äººæœºæ•è·çš„èˆªç©ºå›¾åƒå‘ˆç°å‡ºä¸€ç³»åˆ—ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸åŒäºç°æœ‰æ•°æ®é›†ä¸­å¸¸è§çš„åŸå¸‚æˆ–è‡ªç„¶æ™¯è§‚ï¼Œå¤ªé˜³èƒ½ç”µåœºåŒ…å«é«˜åå°„è¡¨é¢å’Œç‰¹å®šé¢†åŸŸçš„å…ƒç´ ï¼Œè¿™äº›åœ¨ä¼ ç»Ÿè®¡ç®—æœºè§†è§‰åŸºå‡†æµ‹è¯•ä¸­å¾ˆå°‘è§ã€‚å› æ­¤ï¼Œåœ¨é€šç”¨æ•°æ®é›†ä¸Šè®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ²¡æœ‰ä»»ä½•å¤§è§„æ¨¡é‡æ–°è®­ç»ƒå’Œå¤§é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¾ˆéš¾é€‚åº”è¿™ç§ç¯å¢ƒã€‚ç„¶è€Œï¼Œæ”¶é›†å’Œæ ‡æ³¨è¿™äº›æ•°æ®æ—¢æ˜‚è´µåˆè€—æ—¶ï¼Œä½¿å¾—åœ¨å·¥ä¸šåº”ç”¨ä¸­å¿«é€Ÿéƒ¨ç½²ä¸åˆ‡å®é™…ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼šåˆ›å»ºAerialCSPï¼Œä¸€ä¸ªæ¨¡æ‹ŸCSPå·¥å‚èˆªç©ºå›¾åƒçš„è™šæ‹Ÿæ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç”Ÿæˆä¸çœŸå®ä¸–ç•Œæ¡ä»¶ç´§å¯†æ¨¡ä»¿çš„åˆæˆæ•°æ®ï¼Œä»¥ä¿ƒè¿›æ¨¡å‹åœ¨éƒ¨ç½²å‰çš„é¢„è®­ç»ƒï¼Œä»è€Œæ˜¾è‘—å‡å°‘å¯¹å¤§é‡æ‰‹åŠ¨æ ‡æ³¨çš„éœ€æ±‚ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æœ‰ä¸‰ä¸ªï¼šï¼ˆ1ï¼‰æˆ‘ä»¬å¼•å…¥äº†AerialCSPï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜è´¨é‡çš„åˆæˆæ•°æ®é›†ï¼Œç”¨äºCSPå·¥å‚çš„èˆªç©ºæ£€æŸ¥ï¼Œæä¾›ç”¨äºå¯¹è±¡æ£€æµ‹å’Œå›¾åƒåˆ†å‰²çš„æ³¨é‡Šæ•°æ®ï¼›ï¼ˆ2ï¼‰æˆ‘ä»¬åœ¨AerialCSPä¸Šè¯„ä¼°äº†å¤šä¸ªæ¨¡å‹ï¼Œä¸ºCSPç›¸å…³çš„è§†è§‰ä»»åŠ¡å»ºç«‹äº†åŸºå‡†ï¼›ï¼ˆ3ï¼‰æˆ‘ä»¬è¯æ˜åœ¨AerialCSPä¸Šçš„é¢„è®­ç»ƒèƒ½æ˜¾è‘—æé«˜ç°å®ä¸–ç•Œä¸­çš„æ•…éšœæ£€æµ‹ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç½•è§å’Œå°ç¼ºé™·çš„æ•…éšœæ£€æµ‹ï¼Œè¿›ä¸€æ­¥å‡å°‘äº†å¯¹æ‰‹åŠ¨æ ‡æ³¨çš„å¤§é‡éœ€æ±‚ã€‚AerialCSPå·²å…¬å¼€æä¾›äº<a target="_blank" rel="noopener" href="https://mpcutino.github.io/aerialcsp/%E3%80%82">https://mpcutino.github.io/aerialcsp/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00440v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤ªé˜³èƒ½å…‰ä¼ï¼ˆCSPï¼‰ç”µå‚çš„æ— äººæœºèˆªæ‹å›¾åƒä¸ºè®¡ç®—æœºè§†è§‰å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ç”±äºå¤ªé˜³èƒ½ç”°åœ°è¡¨é¢çš„é«˜åå°„æ€§å’Œç‰¹å®šé¢†åŸŸå…ƒç´ çš„å­˜åœ¨ï¼Œä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨åº”ç”¨äºæ­¤é¢†åŸŸæ—¶éš¾ä»¥å®ç°é€šç”¨åŒ–ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†AerialCSPè™šæ‹Ÿæ•°æ®é›†ï¼Œé€šè¿‡æ¨¡æ‹ŸCSPå·¥å‚çš„èˆªæ‹å›¾åƒæ¥ç”Ÿæˆåˆæˆæ•°æ®ã€‚è¯¥æ•°æ®é›†æ—¨åœ¨é™ä½å¤§é‡æ‰‹åŠ¨æ ‡æ³¨çš„éœ€æ±‚ï¼Œä¿ƒè¿›æ¨¡å‹éƒ¨ç½²å‰çš„é¢„è®­ç»ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ— äººæœºæ‹æ‘„çš„å¤ªé˜³èƒ½å…‰ä¼ï¼ˆCSPï¼‰ç”µå‚å›¾åƒå¸¦æ¥ç‹¬ç‰¹æŒ‘æˆ˜ã€‚</li>
<li>å¤ªé˜³èƒ½ç”°åœ°è¡¨é¢çš„é«˜åå°„æ€§å’Œç‰¹å®šé¢†åŸŸå…ƒç´ å½±å“æœºå™¨å­¦ä¹ æ¨¡å‹çš„é€šç”¨åŒ–ã€‚</li>
<li>æ”¶é›†ä¸æ ‡æ³¨å¤§é‡æ•°æ®æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ï¼Œä¸é€‚åˆå·¥ä¸šåº”ç”¨çš„å¿«é€Ÿéƒ¨ç½²ã€‚</li>
<li>æå‡ºAerialCSPè™šæ‹Ÿæ•°æ®é›†ï¼Œæ¨¡æ‹ŸCSPå·¥å‚çš„èˆªæ‹å›¾åƒã€‚</li>
<li>AerialCSPæä¾›æ ‡æ³¨æ•°æ®ï¼Œæ”¯æŒå¯¹è±¡æ£€æµ‹å’Œå›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>åœ¨AerialCSPä¸Šå»ºç«‹å¤šä¸ªæ¨¡å‹çš„åŸºå‡†æµ‹è¯•ï¼Œä¸ºCSPç›¸å…³è§†è§‰ä»»åŠ¡æä¾›å‚è€ƒã€‚</li>
<li>é¢„è®­ç»ƒäºAerialCSPèƒ½æ˜¾è‘—æå‡ç°å®ä¸–ç•Œçš„æ•…éšœæ£€æµ‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€æœ‰å’Œå°ç¼ºé™·çš„è¯†åˆ«ä¸Šã€‚</li>
<li>AerialCSPæ•°æ®é›†å·²å…¬å¼€å¯è®¿é—®ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00440">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fdabd182f77248c19fd6ef24fd4e73f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb2b6240bcd637b6312b51002b021b06.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="UIS-Mamba-Exploring-Mamba-for-Underwater-Instance-Segmentation-via-Dynamic-Tree-Scan-and-Hidden-State-Weaken"><a href="#UIS-Mamba-Exploring-Mamba-for-Underwater-Instance-Segmentation-via-Dynamic-Tree-Scan-and-Hidden-State-Weaken" class="headerlink" title="UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via   Dynamic Tree Scan and Hidden State Weaken"></a>UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via   Dynamic Tree Scan and Hidden State Weaken</h2><p><strong>Authors:Runmin Cong, Zongji Yu, Hao Fang, Haoyan Sun, Sam Kwong</strong></p>
<p>Underwater Instance Segmentation (UIS) tasks are crucial for underwater complex scene detection. Mamba, as an emerging state space model with inherently linear complexity and global receptive fields, is highly suitable for processing image segmentation tasks with long sequence features. However, due to the particularity of underwater scenes, there are many challenges in applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot maintain the internal continuity of scanned instances in the presence of severely underwater color distortion and blurred instance boundaries, and the hidden state of the complex underwater background can also inhibit the understanding of instance objects. In this work, we propose the first Mamba-based underwater instance segmentation model UIS-Mamba, and design two innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to migrate Mamba to the underwater task. DTS module maintains the continuity of the internal features of the instance objects by allowing the patches to dynamically offset and scale, thereby guiding the minimum spanning tree and providing dynamic local receptive fields. HSW module suppresses the interference of complex backgrounds and effectively focuses the information flow of state propagation to the instances themselves through the Ncut-based hidden state weakening mechanism. Experimental results show that UIS-Mamba achieves state-of-the-art performance on both UIIS and USIS10K datasets, while maintaining a low number of parameters and computational complexity. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Maricalce/UIS-Mamba">https://github.com/Maricalce/UIS-Mamba</a>. </p>
<blockquote>
<p>æ°´ä¸‹å®ä¾‹åˆ†å‰²ï¼ˆUISï¼‰ä»»åŠ¡å¯¹äºæ°´ä¸‹å¤æ‚åœºæ™¯æ£€æµ‹è‡³å…³é‡è¦ã€‚Mambaä½œä¸ºä¸€ç§æ–°å…´çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œå…·æœ‰å›ºæœ‰çš„çº¿æ€§å¤æ‚æ€§å’Œå…¨å±€æ„Ÿå—é‡ï¼Œéå¸¸é€‚åˆå¤„ç†å…·æœ‰é•¿åºåˆ—ç‰¹å¾çš„å›¾ç‰‡åˆ†å‰²ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç”±äºæ°´ä¸‹åœºæ™¯çš„ç‰¹æ®Šæ€§ï¼Œå°†Mambaåº”ç”¨äºUISé¢ä¸´è®¸å¤šæŒ‘æˆ˜ã€‚ç°æœ‰çš„å›ºå®šè¡¥ä¸æ‰«ææœºåˆ¶æ— æ³•åœ¨æ°´ä¸‹è‰²å½©ä¸¥é‡å¤±çœŸå’Œå®ä¾‹è¾¹ç•Œæ¨¡ç³Šçš„æƒ…å†µä¸‹ä¿æŒæ‰«æå®ä¾‹çš„å†…éƒ¨è¿ç»­æ€§ï¼Œè€Œå¤æ‚çš„æ°´ä¸‹èƒŒæ™¯çš„éšè—çŠ¶æ€ä¹Ÿå¯èƒ½é˜»ç¢å¯¹å®ä¾‹å¯¹è±¡çš„ç†è§£ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºMambaçš„æ°´ä¸‹å®ä¾‹åˆ†å‰²æ¨¡å‹UIS-Mambaï¼Œå¹¶è®¾è®¡äº†ä¸¤ä¸ªåˆ›æ–°æ¨¡å—ï¼Œå³åŠ¨æ€æ ‘æ‰«æï¼ˆDTSï¼‰å’Œéšè—çŠ¶æ€å‡å¼±ï¼ˆHSWï¼‰ï¼Œä»¥å°†Mambaè¿ç§»åˆ°æ°´ä¸‹ä»»åŠ¡ã€‚DTSæ¨¡å—é€šè¿‡å…è®¸è¡¥ä¸åŠ¨æ€åç§»å’Œç¼©æ”¾ï¼Œä»è€Œä¿æŒå®ä¾‹å¯¹è±¡å†…éƒ¨ç‰¹å¾çš„è¿ç»­æ€§ï¼Œè¿™å¼•å¯¼äº†æœ€å°ç”Ÿæˆæ ‘å¹¶æä¾›åŠ¨æ€å±€éƒ¨æ„Ÿå—é‡ã€‚HSWæ¨¡å—æŠ‘åˆ¶äº†å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œå¹¶é€šè¿‡åŸºäºNcutçš„éšè—çŠ¶æ€å‡å¼±æœºåˆ¶æœ‰æ•ˆåœ°å°†çŠ¶æ€ä¼ æ’­çš„ä¿¡æ¯æµé›†ä¸­åœ¨å®ä¾‹æœ¬èº«ä¸Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUIS-Mambaåœ¨UIISå’ŒUSIS10Kæ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/Maricalce/UIS-Mamba%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Maricalce/UIS-Mambaè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00421v1">PDF</a> ACM MM 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºMambaçš„æ°´ä¸‹å®ä¾‹åˆ†å‰²æ¨¡å‹UIS-Mambaï¼Œé’ˆå¯¹æ°´ä¸‹å¤æ‚åœºæ™¯æ£€æµ‹æå‡ºäº†åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å¼•å…¥Dynamic Tree Scanï¼ˆDTSï¼‰å’ŒHidden State Weakenï¼ˆHSWï¼‰ä¸¤å¤§æ¨¡å—ï¼Œå®ç°äº†å¯¹Mambaæ¨¡å‹çš„ä¼˜åŒ–è¿ç§»ã€‚DTSæ¨¡å—é€šè¿‡åŠ¨æ€åç§»å’Œç¼©æ”¾è¡¥ä¸ï¼Œä¿æŒå®ä¾‹å¯¹è±¡å†…éƒ¨ç‰¹å¾çš„è¿ç»­æ€§ï¼›HSWæ¨¡å—åˆ™æŠ‘åˆ¶å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œæœ‰æ•ˆèšç„¦çŠ¶æ€ä¼ æ’­çš„ä¿¡æ¯æµå‘å®ä¾‹æœ¬èº«ã€‚å®éªŒç»“æœæ˜¾æ˜ï¼ŒUIS-Mambaåœ¨UIISå’ŒUSIS10Kæ•°æ®é›†ä¸Šå–å¾—äº†é¢†å…ˆæ°´å¹³ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹å®ä¾‹åˆ†å‰²ï¼ˆUISï¼‰ä»»åŠ¡å¯¹äºæ°´ä¸‹å¤æ‚åœºæ™¯æ£€æµ‹è‡³å…³é‡è¦ã€‚</li>
<li>Mambaä½œä¸ºä¸€ç§å…·æœ‰çº¿æ€§å¤æ‚åº¦å’Œå…¨å±€æ„Ÿå—é‡çš„çš„æ–°å…´çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œé€‚ç”¨äºå¤„ç†å…·æœ‰é•¿åºåˆ—ç‰¹å¾çš„çš„å›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>å°†Mambaåº”ç”¨äºæ°´ä¸‹å®ä¾‹åˆ†å‰²é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚æ°´ä¸‹åœºæ™¯ç‰¹æ®Šæ€§å¯¼è‡´çš„è‰²å½©å¤±çœŸå’Œæ¨¡ç³Šè¾¹ç•Œé—®é¢˜ã€‚</li>
<li>æå‡ºçš„åŸºäºMambaçš„æ°´ä¸‹å®ä¾‹åˆ†å‰²æ¨¡å‹UIS-Mambaï¼Œé€šè¿‡å¼•å…¥Dynamic Tree Scanï¼ˆDTSï¼‰å’ŒHidden State Weakenï¼ˆHSWï¼‰æ¨¡å—è¿›è¡Œä¼˜åŒ–è¿ç§»ã€‚</li>
<li>DTSæ¨¡å—é€šè¿‡åŠ¨æ€åç§»å’Œç¼©æ”¾è¡¥ä¸ï¼Œä¿æŒå®ä¾‹å¯¹è±¡å†…éƒ¨ç‰¹å¾çš„è¿ç»­æ€§ã€‚</li>
<li>HSWæ¨¡å—é€šè¿‡Ncut-basedéšè—çŠ¶æ€å‡å¼±æœºåˆ¶ï¼ŒæŠ‘åˆ¶å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œèšç„¦ä¿¡æ¯æµå‘å®ä¾‹æœ¬èº«ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUIS-Mambaåœ¨UIISå’ŒUSIS10Kæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”å‚æ•°æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦è¾ƒä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00421">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f67e1c40b8f363df7242c3e62f057b2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc3637991047fc531e45c830744051fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-151ee3d3c5f01bf38a2252b5d924f382.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b37673beee8f533fd2d4ec377cb0e49.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Extreme-anisotropies-in-deep-layers-of-an-exploding-star-overabundance-of-Cr-in-the-northeastern-jet-of-Cassiopeia-A"><a href="#Extreme-anisotropies-in-deep-layers-of-an-exploding-star-overabundance-of-Cr-in-the-northeastern-jet-of-Cassiopeia-A" class="headerlink" title="Extreme anisotropies in deep layers of an exploding star: overabundance   of Cr in the northeastern jet of Cassiopeia A"></a>Extreme anisotropies in deep layers of an exploding star: overabundance   of Cr in the northeastern jet of Cassiopeia A</h2><p><strong>Authors:Vincenzo Sapienza, Marco Miceli, Masaomi Ono, Shigehiro Nagataki, Takashi Yoshida, Emanuele Greco, Salvatore Orlando, Fabrizio Bocchino</strong></p>
<p>Core-collapse supernovae drive nucleosynthesis under extreme thermodynamic conditions, and complex mechanisms are at work prompting the transport of heavy elements from deep stellar interiors into outer layers. We present spatially resolved X-ray spectroscopy of Cassiopeia Aâ€™s (Cas A) northeastern (NE) jet using the archival 1 Ms Chandra&#x2F;ACIS observations, and focusing on three fingers of the jet. We report the highest Cr&#x2F;Fe mass ratio (Cr&#x2F;Fe $\sim0.14$) ever observed in Cas A, localized in a compact region within the southernmost finger in the NE jet. Comparisons with nucleosynthesis models indicate that the NE jet originated approximately at the boundary separating the complete Si burning layer from the incomplete Si-burning layer. We also find that mixing from different layers is needed to explain the chemical composition of the three fingers in the NE jet. We also detect significant differences in the physical and chemical properties among the three fingers analyzed of the NE jet. In particular, we find that, unlike the other two, the southernmost finger originated from a slightly more peripheral region of the explosion. Moreover, while the northern and central fingers lie almost in the plane of the sky, the southernmost finger is moving in a different direction, showing a velocity along the line of sight of $\sim2100$ km s$^{-1}$ towards the observer, with a tilt angle of $\sim16$\textdegree. These findings highlight the NE jetâ€™s role in ejecting material from the deepest explosive burning layers, providing new insights into the asymmetries originating in the inner layers of core-collapse supernovae. </p>
<blockquote>
<p>æ ¸å¿ƒå´©æºƒè¶…æ–°æ˜Ÿåœ¨æç«¯çƒ­åŠ›å­¦æ¡ä»¶ä¸‹é©±åŠ¨æ ¸åˆæˆï¼Œå¤æ‚çš„æœºåˆ¶ä¿ƒä½¿é‡å…ƒç´ ä»æ·±å±‚æ’æ˜Ÿå†…éƒ¨å‘å¤–å±‚è¾“é€ã€‚æˆ‘ä»¬åˆ©ç”¨æ¡£æ¡ˆé¦†ä¸­çš„é’±å¾·æ‹‰ ACISï¼ˆChandra&#x2F;ACISï¼‰è§‚æµ‹å¾—åˆ°çš„ 1 Ms X å°„çº¿å…‰è°±æˆåƒæ•°æ®ï¼Œå¯¹ä»™ååº§çš„ä¸œåŒ—å–·å°„æµè¿›è¡Œç©ºé—´è§£æï¼Œå¹¶é‡ç‚¹å…³æ³¨å–·å°„æµçš„ä¸‰ä¸ªç‰¹å¾ã€‚æˆ‘ä»¬æŠ¥å‘Šäº†è¿„ä»Šä¸ºæ­¢åœ¨ Cas A ä¸­è§‚å¯Ÿåˆ°çš„æœ€é«˜ Cr&#x2F;Fe è´¨é‡æ¯”ï¼ˆCr&#x2F;Fe ï½ 0.14ï¼‰ï¼Œè¿™ä¸€æ¯”ä¾‹å‡ºç°åœ¨ä¸œåŒ—å–·å°„æµæœ€å—ç«¯çš„ç´§å‡‘åŒºåŸŸå†…ã€‚ä¸æ ¸åˆæˆæ¨¡å‹çš„æ¯”è¾ƒè¡¨æ˜ï¼Œä¸œåŒ—å–·å°„æµèµ·æºäºå®Œå…¨ç¡…ç‡ƒçƒ§å±‚ä¸ä¸å®Œå…¨ç¡…ç‡ƒçƒ§å±‚çš„è¾¹ç•Œé™„è¿‘ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œè¦è§£é‡Šä¸œåŒ—å–·å°„æµä¸‰ä¸ªç‰¹å¾çš„åŒ–å­¦æˆåˆ†ï¼Œéœ€è¦ä»ä¸åŒçš„å±‚æ¬¡è¿›è¡Œæ··åˆã€‚æˆ‘ä»¬è¿˜å‘ç°äº†ä¸œåŒ—å–·å°„æµæ‰€åˆ†æçš„ä¸‰ä¸ªç‰¹å¾ä¹‹é—´åœ¨ç‰©ç†å’ŒåŒ–å­¦æ€§è´¨ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä¸å…¶ä»–ä¸¤ä¸ªç‰¹å¾ä¸åŒï¼Œæœ€å—ç«¯çš„ç‰¹å¾æºäºçˆ†ç‚¸çš„ä¸€ä¸ªç¨å¾®å¤–å›´çš„åŒºåŸŸã€‚æ­¤å¤–ï¼Œå°½ç®¡åŒ—éƒ¨å’Œä¸­éƒ¨ç‰¹å¾å‡ ä¹ä½äºå¤©ç©ºå¹³é¢ä¸Šï¼Œä½†æœ€å—ç«¯çš„ç‰¹å¾ç§»åŠ¨æ–¹å‘ä¸åŒï¼Œæ²¿è§†çº¿æ–¹å‘çš„é€Ÿåº¦çº¦ä¸º 2100 å…¬é‡Œæ¯ç§’ï¼Œæœå‘è§‚å¯Ÿè€…ï¼Œå€¾æ–œè§’åº¦çº¦ä¸º 16 åº¦ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†ä¸œåŒ—å–·å°„æµåœ¨å–·å°„æœ€æ·±çˆ†ç‚¸ç‡ƒçƒ§å±‚ç‰©è´¨ä¸­çš„ä½œç”¨ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†å…³äºæ ¸å¿ƒå´©æºƒè¶…æ–°æ˜Ÿå†…å±‚èµ·æºä¸å¯¹ç§°æ€§çš„æ–°è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00376v1">PDF</a> Accepted for Publication in The Astrophysical Journal Letters, 11   Pages, 4 Figures and 1 Table</p>
<p><strong>æ‘˜è¦</strong></p>
<pre><code>æ ¸å¿ƒå¡Œç¼©è¶…æ–°æ˜Ÿåœ¨æç«¯çƒ­åŠ›å­¦æ¡ä»¶ä¸‹é©±åŠ¨æ ¸åˆæˆï¼Œå¹¶å­˜åœ¨å¤æ‚çš„æœºåˆ¶ä¿ƒä½¿ä»æ·±å±‚æ’æ˜Ÿå†…éƒ¨å‘å¤–éƒ¨å±‚æ¬¡è¾“é€é‡å…ƒç´ ã€‚é€šè¿‡å¯¹ä»™ååº§çš„ä¸œåŒ—å–·æµï¼ˆNE jetï¼‰è¿›è¡Œé«˜åˆ†è¾¨ç‡Xå°„çº¿å…‰è°±åˆ†æï¼ŒæŠ¥å‘Šäº†å†å²ä¸Šæœ€é«˜çš„Cr/Feè´¨é‡æ¯”ï¼ˆCr/Feçº¦ä¸º0.14ï¼‰ï¼Œè¯¥æ¯”å€¼å±€é™äºä¸œåŒ—å–·æµæœ€å—ç«¯çš„ç´§å‡‘åŒºåŸŸå†…ã€‚ä¸æ ¸åˆæˆæ¨¡å‹æ¯”è¾ƒè¡¨æ˜ï¼Œä¸œåŒ—å–·æµèµ·æºäºå®Œå…¨ç¡…ç‡ƒçƒ§å±‚ä¸ä¸å®Œå…¨ç¡…ç‡ƒçƒ§å±‚çš„è¾¹ç•Œã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œè¦è§£é‡Šä¸œåŒ—å–·æµä¸‰æ ¹æ‰‹æŒ‡åœ¨åŒ–å­¦ç»„æˆä¸Šçš„ä¸åŒï¼Œéœ€è¦æ¥è‡ªä¸åŒå±‚æ¬¡çš„æ··åˆã€‚æˆ‘ä»¬è¿˜å‘ç°è¿™ä¸‰æ ¹æ‰‹æŒ‡åœ¨åˆ†æä¸­åœ¨ç‰©ç†å’ŒåŒ–å­¦æ€§è´¨ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ç‰¹åˆ«æ˜¯æˆ‘ä»¬å‘ç°æœ€å—ç«¯çš„è¿™æ ¹æ‰‹æŒ‡æ¥è‡ªçˆ†ç‚¸ä¸­ä¸€ä¸ªç•¥å¾®æ›´å¤–å›´çš„åŒºåŸŸã€‚æ­¤å¤–ï¼Œä¸å…¶ä»–ä¸¤æ ¹æ‰‹æŒ‡ç›¸æ¯”ï¼Œæœ€å—ç«¯çš„è¿™æ ¹æ‰‹æŒ‡æ²¿ç€è§†çº¿æ–¹å‘ä»¥çº¦æ¯ç§’å…¬é‡Œæ•°ç§»åŠ¨è‡³è§‚å¯Ÿè€…å¤„æœå‘å‘ˆç°å‡ºå¤§çº¦16åº¦çš„å€¾æ–œè§’ã€‚è¿™äº›å‘ç°çªå‡ºäº†ä¸œåŒ—å–·æµåœ¨å–·å°„æ¥è‡ªæœ€æ·±çˆ†ç‚¸ç‡ƒçƒ§å±‚ç‰©è´¨ä¸­çš„ä½œç”¨ï¼Œä¸ºæ·±å…¥äº†è§£æ ¸å¿ƒå¡Œç¼©è¶…æ–°æ˜Ÿå†…éƒ¨å±‚æ¬¡äº§ç”Ÿçš„ä¸å¯¹ç§°æ€§æä¾›äº†æ–°çš„è§è§£ã€‚

**å…³é”®è§è§£**

1. æ ¸å¿ƒå¡Œç¼©è¶…æ–°æ˜Ÿåœ¨æç«¯æ¡ä»¶ä¸‹é©±åŠ¨æ ¸åˆæˆï¼Œæ¶‰åŠå¤æ‚çš„æœºåˆ¶è¾“é€é‡å…ƒç´ ã€‚
2. é€šè¿‡é«˜åˆ†è¾¨ç‡Xå°„çº¿å…‰è°±åˆ†æäº†ä»™ååº§ä¸œåŒ—å–·æµçš„Cr/Feè´¨é‡æ¯”ï¼Œå‘ç°å…¶å†å²æœ€é«˜å€¼ã€‚
3. ä¸œåŒ—å–·æµçš„èµ·æºä½äºç¡…ç‡ƒçƒ§å±‚çš„è¾¹ç•ŒåŒºåŸŸã€‚
4. ä¸åŒå±‚æ¬¡çš„æ··åˆè§£é‡Šäº†ä¸œåŒ—å–·æµä¸‰æ ¹æ‰‹æŒ‡åœ¨åŒ–å­¦ç»„æˆä¸Šçš„å·®å¼‚ã€‚
5. æœ€å—ç«¯çš„å–·æµæ‰‹æŒ‡æºè‡ªçˆ†ç‚¸ä¸­çš„å¤–å›´åŒºåŸŸï¼Œå…·æœ‰ç‰¹æ®Šçš„è¿åŠ¨è½¨è¿¹å’Œé€Ÿåº¦ã€‚
6. æœ€å—ç«¯çš„å–·æµæ‰‹æŒ‡è¿åŠ¨æ–¹å‘æœ‰åˆ«äºå…¶ä»–ä¸¤æ ¹æ‰‹æŒ‡ï¼Œè¡¨ç°å‡ºä¸€å®šçš„å€¾æ–œè§’åº¦ã€‚
</code></pre>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00376">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-75b4c7d1c225446e602acc38c36420c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0647d951b8bf692cf95930d3f0725e60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a11a02efc64a9b8d82f81c52270da4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57b717c22929d946353afabf0949af6d.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="On-the-Risk-of-Misleading-Reports-Diagnosing-Textual-Biases-in-Multimodal-Clinical-AI"><a href="#On-the-Risk-of-Misleading-Reports-Diagnosing-Textual-Biases-in-Multimodal-Clinical-AI" class="headerlink" title="On the Risk of Misleading Reports: Diagnosing Textual Biases in   Multimodal Clinical AI"></a>On the Risk of Misleading Reports: Diagnosing Textual Biases in   Multimodal Clinical AI</h2><p><strong>Authors:David Restrepo, Ira Ktena, Maria Vakalopoulou, Stergios Christodoulidis, Enzo Ferrante</strong></p>
<p>Clinical decision-making relies on the integrated analysis of medical images and the associated clinical reports. While Vision-Language Models (VLMs) can offer a unified framework for such tasks, they can exhibit strong biases toward one modality, frequently overlooking critical visual cues in favor of textual information. In this work, we introduce Selective Modality Shifting (SMS), a perturbation-based approach to quantify a modelâ€™s reliance on each modality in binary classification tasks. By systematically swapping images or text between samples with opposing labels, we expose modality-specific biases. We assess six open-source VLMs-four generalist models and two fine-tuned for medical data-on two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray) and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance and the calibration of every model in both unperturbed and perturbed settings, we reveal a marked dependency on text input, which persists despite the presence of complementary visual information. We also perform a qualitative attention-based analysis which further confirms that image content is often overshadowed by text details. Our findings highlight the importance of designing and evaluating multimodal medical models that genuinely integrate visual and textual cues, rather than relying on single-modality signals. </p>
<blockquote>
<p>ä¸´åºŠå†³ç­–ä¾èµ–äºåŒ»å­¦å›¾åƒå’Œç›¸å…³ä¸´åºŠæŠ¥å‘Šçš„ç»¼åˆåˆ†æã€‚å°½ç®¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å¯ä»¥ä¸ºè¿™äº›ä»»åŠ¡æä¾›ç»Ÿä¸€æ¡†æ¶ï¼Œä½†å®ƒä»¬å¯èƒ½å¯¹ä¸€ä¸ªæ¨¡æ€æœ‰å¼ºçƒˆçš„åè§ï¼Œç»å¸¸å¿½è§†å…³é”®çš„è§†è§‰çº¿ç´¢è€Œåå‘äºæ–‡æœ¬ä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†é€‰æ‹©æ€§æ¨¡æ€è½¬æ¢ï¼ˆSMSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰°åŠ¨çš„æ–¹æ³•æ¥é‡åŒ–æ¨¡å‹åœ¨äºŒå…ƒåˆ†ç±»ä»»åŠ¡ä¸­å¯¹æ¯ä¸ªæ¨¡æ€çš„ä¾èµ–ã€‚é€šè¿‡ç³»ç»Ÿäº¤æ¢å…·æœ‰ç›¸åæ ‡ç­¾çš„æ ·æœ¬ä¹‹é—´çš„å›¾åƒæˆ–æ–‡æœ¬ï¼Œæˆ‘ä»¬æ­ç¤ºäº†æ¨¡æ€ç‰¹å®šåè§ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸¤ä¸ªç”¨äºåŒ»å­¦æ•°æ®å¾®è°ƒçš„å’Œå››ä¸ªé€šç”¨æ¨¡å‹çš„å…­ä¸ªå¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œåœ¨ä¸¤ä¸ªå…·æœ‰ä¸åŒæ¨¡æ€çš„åŒ»å­¦æˆåƒæ•°æ®é›†ä¸Šï¼šMIMIC-CXRï¼ˆèƒ¸éƒ¨Xå…‰ï¼‰å’ŒFairVLMedï¼ˆæ‰«ææ¿€å…‰çœ¼ç§‘ï¼‰ã€‚é€šè¿‡è¯„ä¼°æ¨¡å‹åœ¨æœªå—å¹²æ‰°å’Œå—å¹²æ‰°ç¯å¢ƒä¸­çš„æ€§èƒ½å’Œæ ¡å‡†ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªå¯¹æ–‡æœ¬è¾“å…¥çš„æ˜æ˜¾ä¾èµ–ï¼Œå³ä½¿åœ¨æœ‰è¡¥å……è§†è§‰ä¿¡æ¯çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†åŸºäºæ³¨æ„åŠ›çš„å®šæ€§åˆ†æï¼Œè¿›ä¸€æ­¥è¯å®äº†å›¾åƒå†…å®¹ç»å¸¸è¢«æ–‡æœ¬ç»†èŠ‚æ‰€æ©ç›–ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè®¾è®¡å’Œè¯„ä¼°çœŸæ­£æ•´åˆè§†è§‰å’Œæ–‡æœ¬çº¿ç´¢çš„å¤šæ¨¡æ€åŒ»å­¦æ¨¡å‹çš„é‡è¦æ€§ï¼Œè€Œä¸æ˜¯ä¾èµ–äºå•ä¸€æ¨¡æ€ä¿¡å·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00171v1">PDF</a> Accepted to MICCAI 2025 1st Workshop on Multimodal Large Language   Models (MLLMs) in Clinical Practice</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä¸´åºŠå†³ç­–ä¸­åŒ»ç–—å›¾åƒä¸ä¸´åºŠæŠ¥å‘Šçš„ç»¼åˆåˆ†æã€‚è™½ç„¶è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸ºè¿™ç±»ä»»åŠ¡æä¾›äº†ç»Ÿä¸€æ¡†æ¶ï¼Œä½†å®ƒä»¬å¾€å¾€å¯¹æŸä¸€æ¨¡æ€æœ‰å¼ºçƒˆçš„åå‘ï¼Œå¿½è§†å…³é”®çš„è§†è§‰çº¿ç´¢è€Œè¿‡åº¦ä¾èµ–æ–‡æœ¬ä¿¡æ¯ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºæ‰°åŠ¨çš„æ–¹æ³•â€”â€”é€‰æ‹©æ€§æ¨¡æ€è½¬æ¢ï¼ˆSMSï¼‰ï¼Œä»¥é‡åŒ–æ¨¡å‹åœ¨äºŒå…ƒåˆ†ç±»ä»»åŠ¡ä¸­å¯¹å„æ¨¡æ€çš„ä¾èµ–ç¨‹åº¦ã€‚é€šè¿‡ç³»ç»Ÿæ›¿æ¢å…·æœ‰å¯¹ç«‹æ ‡ç­¾æ ·æœ¬çš„å›¾åƒæˆ–æ–‡æœ¬ï¼Œæˆ‘ä»¬æ­ç¤ºäº†æ¨¡æ€ç‰¹å®šåè§ã€‚è¯„ä¼°äº†å…­ä¸ªå¼€æºVLMsï¼ˆå››ä¸ªé€šç”¨æ¨¡å‹å’Œä¸¤ä¸ªç”¨äºåŒ»ç–—æ•°æ®çš„ç²¾ç»†è°ƒæ•´æ¨¡å‹ï¼‰åœ¨ä¸¤ä¸ªå…·æœ‰ä¸åŒæ¨¡æ€çš„åŒ»ç–—æˆåƒæ•°æ®é›†ï¼ˆMIMIC-CXRå’ŒFairVLMedï¼‰ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡è¯„ä¼°æœªå—æ‰°åŠ¨å’Œå—æ‰°åŠ¨ç¯å¢ƒä¸­æ¯ä¸ªæ¨¡å‹çš„æ€§èƒ½å’Œæ ¡å‡†ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹å¯¹æ–‡æœ¬è¾“å…¥çš„å¼ºçƒˆä¾èµ–æ€§ï¼Œå³ä½¿åœ¨æœ‰è¡¥å……è§†è§‰ä¿¡æ¯çš„æƒ…å†µä¸‹ä¹Ÿä¾ç„¶å­˜åœ¨ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†åŸºäºæ³¨æ„åŠ›çš„å®šæ€§åˆ†æï¼Œè¿›ä¸€æ­¥è¯å®å›¾åƒå†…å®¹å¾€å¾€è¢«æ–‡æœ¬ç»†èŠ‚æ‰€æ©ç›–ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè®¾è®¡è¯„ä¼°çœŸæ­£èåˆè§†è§‰å’Œæ–‡æœ¬çº¿ç´¢çš„å¤šæ¨¡æ€åŒ»ç–—æ¨¡å‹è‡³å…³é‡è¦ï¼Œè€Œä¸æ˜¯ä¾èµ–å•ä¸€æ¨¡æ€ä¿¡å·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸´åºŠå†³ç­–ä¾èµ–äºåŒ»ç–—å›¾åƒå’Œä¸´åºŠæŠ¥å‘Šçš„ç»¼åˆåˆ†æã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ä»»åŠ¡ä¸­å¯èƒ½å­˜åœ¨å¯¹æŸä¸€æ¨¡æ€çš„åå‘ã€‚</li>
<li>é€‰æ‹©æ€§æ¨¡æ€è½¬æ¢ï¼ˆSMSï¼‰æ˜¯ä¸€ç§é‡åŒ–æ¨¡å‹å¯¹æ¨¡æ€ä¾èµ–çš„æ–¹æ³•ã€‚</li>
<li>æ¨¡å‹åœ¨åŒ»ç–—æˆåƒæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¯¹æ–‡æœ¬è¾“å…¥çš„å¼ºçƒˆä¾èµ–æ€§ï¼Œå³ä½¿å­˜åœ¨è§†è§‰ä¿¡æ¯ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li>
<li>å›¾åƒå†…å®¹å¸¸å¸¸è¢«æ–‡æœ¬ç»†èŠ‚æ‰€æ©ç›–ã€‚</li>
<li>è®¾è®¡çœŸæ­£èåˆè§†è§‰å’Œæ–‡æœ¬çº¿ç´¢çš„å¤šæ¨¡æ€åŒ»ç–—æ¨¡å‹è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3df649a2ecea1d8539c820089182a40b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7161eb3762cf6504a8914216ff477be3.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Tianguan-Î¶-Tau-as-a-binary-system-consisting-of-a-Be-star-and-an-accreting-White-Dwarf-opening-a-gate-to-understanding-enigmatic-Î³-Cas-analogues"><a href="#Tianguan-Î¶-Tau-as-a-binary-system-consisting-of-a-Be-star-and-an-accreting-White-Dwarf-opening-a-gate-to-understanding-enigmatic-Î³-Cas-analogues" class="headerlink" title="TiÄnguÄn ($Î¶$ Tau) as a binary system consisting of a   Be-star and an accreting White Dwarf: opening a gate to understanding   enigmatic $Î³$ Cas analogues"></a>TiÄnguÄn ($Î¶$ Tau) as a binary system consisting of a   Be-star and an accreting White Dwarf: opening a gate to understanding   enigmatic $Î³$ Cas analogues</h2><p><strong>Authors:JesÃºs A. ToalÃ¡, Lidia M. Oskinova, Diego A. Vasquez-Torres</strong></p>
<p>The analogues of $\gamma$ Cassiopea are binary early type Be stars which are X-ray bright with hard thermal spectra. The nature of companions in these stars and mechanisms of their X-ray emission remain enigmatic. Among the proposed ideas is the presence of an accretion disc around a white dwarf (WD) companion to the Be star donor. We use radiative transfer models including reflection physics in order to calculate the synthetic spectra of such systems, and assume that the hottest plasma is thermal and is located in the accretion disc boundary layer. The models are used to analyse the XMM-Newton observations of the $\gamma$ Cas analogue $\zeta$ Tau (a.k.a. Ti={a}ngu={a}n). Comparisons with X-ray-emitting symbiotic systems, particularly $\delta$- and $\beta&#x2F;\delta$-type systems, support the idea that the hard X-ray emission in $\zeta$ Tau is best explained by a WD accreting material expelled from the Be star. The plasma temperature and luminosity of the boundary layer associated with the accretion disc are used to estimate a mass accretion rate of $\dot{M}_\mathrm{acc} \approx 4\times 10^{-10}$ M$_\odot$ yr$^{-1}$, implying a nova recurrence time above 10$^{5}$ yr. Our analysis advances the understanding the production of hard X-ray emission in $\gamma$ Cas analogues, further supporting the idea of accreting WDs as companions of Be-stars in these systems. </p>
<blockquote>
<p>ç±»æ¯”äºÎ³ Cassiopeaçš„æ’æ˜Ÿæ˜¯æ—©æœŸç±»å‹çš„BeåŒæ˜Ÿï¼Œå®ƒä»¬Xå°„çº¿äº®åº¦é«˜ä¸”å…·æœ‰ç¡¬çƒ­å…‰è°±ã€‚è¿™äº›æ’æ˜Ÿä¸­çš„åŒä¼´æ˜ŸåŠå…¶Xå°„çº¿å‘å°„æœºåˆ¶ä»ç„¶æ˜¯ä¸ªè°œã€‚å…¶ä¸­æå‡ºçš„æƒ³æ³•ä¹‹ä¸€æ˜¯åœ¨Beæ˜Ÿæèµ è€…å‘¨å›´å­˜åœ¨ä¸€ä¸ªç™½è‰²çŸ®æ˜Ÿï¼ˆWDï¼‰åŒä¼´çš„å¸ç§¯ç›˜ã€‚æˆ‘ä»¬ä½¿ç”¨åŒ…æ‹¬åå°„ç‰©ç†çš„è¾å°„ä¼ è¾“æ¨¡å‹æ¥è®¡ç®—æ­¤ç±»ç³»ç»Ÿçš„åˆæˆå…‰è°±ï¼Œå¹¶å‡è®¾æœ€çƒ­çš„ç­‰ç¦»å­ä½“æ˜¯çƒ­ç­‰ç¦»å­ä½“ï¼Œä½äºå¸ç§¯ç›˜è¾¹ç•Œå±‚ã€‚è¿™äº›æ¨¡å‹è¢«ç”¨æ¥åˆ†æÎ³ Casç±»ä¼¼ä½“Î¶ Tauï¼ˆåˆåTi={a}ngu={a}nï¼‰çš„XMM-Newtonè§‚æµ‹ç»“æœã€‚ä¸Xå°„çº¿å‘å°„çš„å…±ç”Ÿç³»ç»Ÿï¼Œç‰¹åˆ«æ˜¯Î´å‹å’ŒÎ²&#x2F;Î´å‹ç³»ç»Ÿçš„æ¯”è¾ƒï¼Œæ”¯æŒè¿™æ ·ä¸€ç§è§‚ç‚¹ï¼Œå³Î¶ Tauä¸­çš„ç¡¬Xå°„çº¿å‘å°„æœ€å¥½ç”¨ä»Beæ˜Ÿæ’å‡ºçš„ç‰©è´¨è¢«ç™½çŸ®æ˜Ÿå¸ç§¯æ¥è§£é‡Šã€‚åˆ©ç”¨ä¸å¸ç§¯ç›˜ç›¸å…³çš„è¾¹ç•Œå±‚çš„ç­‰ç¦»å­ä½“æ¸©åº¦å’Œå…‰åº¦æ¥ä¼°è®¡ç‰©è´¨å¸ç§¯ç‡$\dot{M}_\mathrm{acc} \approx 4\times 10^{-10}$ M$_âŠ™$ yr$^{-1}$ï¼Œæš—ç¤ºäº†æ–°æ˜Ÿçš„å¤å‘æ—¶é—´è¶…è¿‡10$^{5}$å¹´ã€‚æˆ‘ä»¬çš„åˆ†æåŠ æ·±äº†å¯¹Î³ Casç±»ä¼¼ä½“äº§ç”Ÿç¡¬Xå°„çº¿å‘å°„çš„ç†è§£ï¼Œè¿›ä¸€æ­¥æ”¯æŒäº†å¸ç§¯ç™½çŸ®æ˜Ÿä½œä¸ºè¿™äº›ç³»ç»Ÿä¸­Beæ˜ŸåŒä¼´çš„æƒ³æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05203v2">PDF</a> 8 pages, 6 figures, 1 table; Accepted to MNRAS</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†ç±»ä¼¼$\gamma$ Cassiopeaçš„äºŒå…ƒæ—©æœŸBeå‹æ’æ˜Ÿï¼Œè¿™äº›æ’æ˜ŸXå°„çº¿äº®åº¦é«˜ä¸”å…·æœ‰ç¡¬çƒ­å…‰è°±ã€‚å…³äºè¿™äº›æ’æ˜Ÿä¸­åŒä¼´æ˜Ÿçš„æ€§è´¨å’ŒXå°„çº¿å‘å°„çš„æœºåˆ¶ä»ç„¶æ˜¯ä¸ªè°œã€‚å…¶ä¸­æå‡ºçš„å‡è®¾ä¹‹ä¸€æ˜¯å­˜åœ¨å›´ç»•Beæ˜Ÿæèµ è€…çš„ç™½çŸ®æ˜Ÿï¼ˆWDï¼‰åŒä¼´çš„å¸ç§¯ç›˜ã€‚ä¸ºäº†è®¡ç®—æ­¤ç±»ç³»ç»Ÿçš„åˆæˆå…‰è°±ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒ…æ‹¬åå°„ç‰©ç†çš„è¾å°„ä¼ é€’æ¨¡å‹ï¼Œå¹¶å‡è®¾æœ€çƒ­çš„ç­‰ç¦»å­ä½“æ˜¯çƒ­ç­‰ç¦»å­ä½“ï¼Œä½äºå¸ç§¯ç›˜è¾¹ç•Œå±‚ã€‚è¿™äº›æ¨¡å‹è¢«ç”¨æ¥åˆ†æ$\gamma$ Casç±»ä¼¼ç‰©$\zeta$ Tauï¼ˆåˆåTi={a}ngu={a}nï¼‰çš„XMM-Newtonè§‚æµ‹ç»“æœã€‚ä¸Xå°„çº¿å‘å°„çš„å…±ç”Ÿç³»ç»Ÿçš„æ¯”è¾ƒï¼Œç‰¹åˆ«æ˜¯$\delta$å‹å’Œ$\beta&#x2F;\delta$å‹ç³»ç»Ÿï¼Œæ”¯æŒäº†ç¡¬Xå°„çº¿å‘å°„åœ¨$\zeta$ Tauä¸­çš„æœ€ä½³è§£é‡Šæ˜¯WDå¸ç§¯ä»Beæ˜Ÿå–·å‡ºçš„ç‰©è´¨ã€‚è¾¹ç•Œå±‚çš„ç­‰ç¦»å­ä½“æ¸©åº¦å’Œå…‰åº¦è¢«ç”¨æ¥ä¼°è®¡å¸ç§¯ç›˜çš„å¸ç§¯ç‡$\dot{M}_\mathrm{acc} \approx 4\times 10^{-10}$ M$_â˜€$ yr$^{-1}$ï¼Œæš—ç¤ºäº†æ–°æ˜Ÿå¤å‘æ—¶é—´è¶…è¿‡$10^{5}$å¹´ã€‚æˆ‘ä»¬çš„åˆ†ææœ‰åŠ©äºç†è§£ç±»ä¼¼$\gamma$ Casçš„æ’æ˜Ÿäº§ç”Ÿç¡¬Xå°„çº¿å‘å°„çš„è¿‡ç¨‹ï¼Œè¿›ä¸€æ­¥æ”¯æŒäº†å¸ç§¯WDä½œä¸ºè¿™äº›ç³»ç»Ÿä¸­Beæ˜ŸåŒä¼´çš„å‡è®¾ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>$\gamma$ Cassiopeaç±»ä¼¼æ˜Ÿçš„Xå°„çº¿ç‰¹æ€§å’Œç¡¬çƒ­å…‰è°±è¢«ç ”ç©¶ã€‚</li>
<li>è¿™äº›æ’æ˜Ÿå…·æœ‰äºŒå…ƒæ—©æœŸBeå‹ç‰¹å¾ï¼ŒXå°„çº¿äº®åº¦é«˜ã€‚</li>
<li>å…³äºåŒä¼´æ˜Ÿæ€§è´¨å’ŒXå°„çº¿å‘å°„æœºåˆ¶çš„å‡è®¾ä¹‹ä¸€æ˜¯å­˜åœ¨å›´ç»•Beæ˜Ÿçš„ç™½çŸ®æ˜Ÿå¸ç§¯ç›˜ã€‚</li>
<li>ä½¿ç”¨è¾å°„ä¼ é€’æ¨¡å‹åˆ†æè¿™ç±»ç³»ç»Ÿçš„åˆæˆå…‰è°±ã€‚</li>
<li>å¯¹$\gamma$ Casç±»ä¼¼ç‰©$\zeta$ Tauçš„XMM-Newtonè§‚æµ‹æ•°æ®è¿›è¡Œåˆ†æã€‚</li>
<li>ä¸å…¶ä»–Xå°„çº¿å‘å°„å…±ç”Ÿç³»ç»Ÿçš„æ¯”è¾ƒæ”¯æŒäº†ç¡¬Xå°„çº¿å‘å°„æºäºWDå¸ç§¯Beæ˜Ÿç‰©è´¨çš„è§‚ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05203">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b744fea1fb1a22ec2bfc2febdacf2de8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebef099eae7ecb6f96fc8d72c24ec54e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4cf85085eadf241d4b8ed271b0940dcc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1828c7bd43eda9e2e1315beb4b903da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de6ee143bd3d57b7c073ce369c51015e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-408378e0a7f8217e47bbd8c7a4c28f20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8774ce0f70f1083e14b79926e7de0543.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MR-CLIP-Efficient-Metadata-Guided-Learning-of-MRI-Contrast-Representations"><a href="#MR-CLIP-Efficient-Metadata-Guided-Learning-of-MRI-Contrast-Representations" class="headerlink" title="MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast   Representations"></a>MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast   Representations</h2><p><strong>Authors:Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso</strong></p>
<p>Accurate interpretation of Magnetic Resonance Imaging scans in clinical systems is based on a precise understanding of image contrast. This contrast is primarily governed by acquisition parameters, such as echo time and repetition time, which are stored in the DICOM metadata. To simplify contrast identification, broad labels such as T1-weighted or T2-weighted are commonly used, but these offer only a coarse approximation of the underlying acquisition settings. In many real-world datasets, such labels are entirely missing, leaving raw acquisition parameters as the only indicators of contrast. Adding to this challenge, the available metadata is often incomplete, noisy, or inconsistent. The lack of reliable and standardized metadata complicates tasks such as image interpretation, retrieval, and integration into clinical workflows. Furthermore, robust contrast-aware representations are essential to enable more advanced clinical applications, such as achieving modality-invariant representations and data harmonization. To address these challenges, we propose MR-CLIP, a multimodal contrastive learning framework that aligns MR images with their DICOM metadata to learn contrast-aware representations, without relying on manual labels. Trained on a diverse clinical dataset that spans various scanners and protocols, MR-CLIP captures contrast variations across acquisitions and within scans, enabling anatomy-invariant representations. We demonstrate its effectiveness in cross-modal retrieval and contrast classification, highlighting its scalability and potential for further clinical applications. The code and weights are publicly available at <a target="_blank" rel="noopener" href="https://github.com/myigitavci/MR-CLIP">https://github.com/myigitavci/MR-CLIP</a>. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒåœ¨ä¸´åºŠç³»ç»Ÿä¸­çš„å‡†ç¡®è§£è¯»åŸºäºå¯¹å›¾åƒå¯¹æ¯”åº¦çš„ç²¾ç¡®ç†è§£ã€‚è¿™ç§å¯¹æ¯”åº¦ä¸»è¦ç”±é‡‡é›†å‚æ•°å†³å®šï¼Œä¾‹å¦‚å›å£°æ—¶é—´å’Œé‡å¤æ—¶é—´ï¼Œè¿™äº›å‚æ•°éƒ½å­˜å‚¨åœ¨DICOMå…ƒæ•°æ®ä¸­ã€‚ä¸ºäº†ç®€åŒ–å¯¹æ¯”åº¦çš„è¯†åˆ«ï¼Œé€šå¸¸ä½¿ç”¨T1åŠ æƒæˆ–TTåŠ æƒç­‰å¹¿æ³›æ ‡ç­¾ï¼Œä½†è¿™äº›åªæä¾›äº†å¯¹åŸºç¡€é‡‡é›†è®¾ç½®çš„ç²—ç•¥è¿‘ä¼¼ã€‚åœ¨è®¸å¤šçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ä¸­ï¼Œè¿™äº›æ ‡ç­¾å®Œå…¨ç¼ºå¤±ï¼Œåªç•™ä¸‹åŸå§‹çš„é‡‡é›†å‚æ•°ä½œä¸ºå¯¹æ¯”åº¦çš„å”¯ä¸€æŒ‡æ ‡ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå¯ç”¨çš„å…ƒæ•°æ®é€šå¸¸ä¸å®Œæ•´ã€å˜ˆæ‚æˆ–ä¸ä¸€è‡´ã€‚ç¼ºä¹å¯é å’Œæ ‡å‡†åŒ–çš„å…ƒæ•°æ®ä½¿å›¾åƒè§£è¯»ã€æ£€ç´¢å’Œæ•´åˆåˆ°ä¸´åºŠå·¥ä½œæµç¨‹ç­‰ä»»åŠ¡å˜å¾—å¤æ‚ã€‚æ­¤å¤–ï¼Œç¨³å¥çš„å¯¹æ¯”åº¦æ„ŸçŸ¥è¡¨ç¤ºå¯¹äºå®ç°æ›´å…ˆè¿›çš„ä¸´åºŠåº”ç”¨è‡³å…³é‡è¦ï¼Œä¾‹å¦‚å®ç°æ¨¡æ€ä¸å˜è¡¨ç¤ºå’Œæ•°æ®è°ƒå’Œã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MR-CLIPï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ¨¡å¼å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå°†MRå›¾åƒä¸ä»–ä»¬çš„DICOMå…ƒæ•°æ®å¯¹é½ï¼Œå­¦ä¹ å¯¹æ¯”åº¦æ„ŸçŸ¥è¡¨ç¤ºï¼Œè€Œæ— éœ€ä¾èµ–æ‰‹åŠ¨æ ‡ç­¾ã€‚MR-CLIPåœ¨æ¶µç›–å„ç§æ‰«æå™¨å’Œåè®®çš„ä¸´åºŠæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥æ•æ‰è·¨é‡‡é›†å’Œæ‰«æå†…çš„å¯¹æ¯”åº¦å˜åŒ–ï¼Œå®ç°è§£å‰–ç»“æ„ä¸å˜çš„è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨è·¨æ¨¡æ€æ£€ç´¢å’Œå¯¹æ¯”åº¦åˆ†ç±»ä¸­è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†å…¶å¯æ‰©å±•æ€§å’Œè¿›ä¸€æ­¥ä¸´åºŠåº”ç”¨çš„æ½œåŠ›ã€‚ä»£ç å’Œæƒé‡å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/myigitavci/MR-CLIP%E4%B8%8A%E5%BC%80%E7%9A%84%E5%8F%BF%E9%9C%B8%E4%BD%BF%E7%BB%99%E5%AE%9A%E5%BC%BA%E7%AE%97ROI.md%3E">https://github.com/myigitavci/MR-CLIPä¸Šå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00043v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰åœ¨ä¸´åºŠç³»ç»Ÿä¸­çš„å‡†ç¡®è§£è¯»ä¾èµ–äºå¯¹å›¾åƒå¯¹æ¯”åº¦çš„ç²¾ç¡®ç†è§£ã€‚å¯¹æ¯”åº¦ä¸»è¦ç”±é‡‡é›†å‚æ•°ï¼ˆå¦‚å›å£°æ—¶é—´å’Œé‡å¤æ—¶é—´ï¼‰å†³å®šï¼Œè¿™äº›å‚æ•°å­˜å‚¨åœ¨DICOMå…ƒæ•°æ®ä¸­ã€‚æ–‡ç« æå‡ºMR-CLIPæ–¹æ³•ï¼Œé€šè¿‡å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶å¯¹é½MRå›¾åƒä¸DICOMå…ƒæ•°æ®ï¼Œå­¦ä¹ å¯¹æ¯”åº¦æ„ŸçŸ¥è¡¨ç¤ºï¼Œæ— éœ€ä¾èµ–æ‰‹åŠ¨æ ‡ç­¾ã€‚è¯¥æ–¹æ³•åœ¨è·¨æ¨¡æ€æ£€ç´¢å’Œå¯¹æ¯”åº¦åˆ†ç±»ä¸­è¡¨ç°å‡ºæœ‰æ•ˆæ€§ï¼Œå…·æœ‰å¯æ‰©å±•æ€§å’Œæ½œåœ¨çš„ä¸´åºŠåº”ç”¨å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„å‡†ç¡®è§£è¯»ä¾èµ–äºå¯¹å›¾åƒå¯¹æ¯”åº¦çš„ç†è§£ã€‚</li>
<li>å›¾åƒå¯¹æ¯”åº¦ä¸»è¦ç”±é‡‡é›†å‚æ•°ï¼ˆå¦‚å›å£°æ—¶é—´å’Œé‡å¤æ—¶é—´ï¼‰å†³å®šï¼Œè¿™äº›å‚æ•°å­˜å‚¨åœ¨DICOMå…ƒæ•°æ®ä¸­ã€‚</li>
<li>å¸¸è§çš„å¯¹æ¯”åº¦æ ‡è¯†ï¼ˆå¦‚T1åŠ æƒæˆ–T2åŠ æƒï¼‰ä»…æä¾›ç²—ç•¥çš„é‡‡é›†è®¾ç½®è¿‘ä¼¼å€¼ã€‚</li>
<li>ç°å®ä¸–ç•Œä¸­ï¼Œè¿™äº›æ ‡ç­¾ç»å¸¸ç¼ºå¤±ï¼Œä½¿å¾—åŸå§‹çš„é‡‡é›†å‚æ•°æˆä¸ºå¯¹æ¯”åº¦çš„å”¯ä¸€æŒ‡æ ‡ã€‚</li>
<li>DICOMå…ƒæ•°æ®çš„ä¸å¯é å’Œä¸æ ‡å‡†åŒ–ç»™å›¾åƒè§£è¯»ã€æ£€ç´¢å’Œèå…¥ä¸´åºŠæµç¨‹å¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>MR-CLIPæ–¹æ³•é€šè¿‡å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶å¯¹é½MRå›¾åƒä¸DICOMå…ƒæ•°æ®ï¼Œå®ç°å¯¹æ¯”åº¦æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00043">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b813660bdb73caa0b66f422f974854b3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-717b21b4d3b342ac76bcce9d1d03ee1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fee6d3dd8473a95b38c37cbd79c5b27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbc1954a61e8e11eb169b8dd733be977.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Core-Set-Selection-for-Data-efficient-Land-Cover-Segmentation"><a href="#Core-Set-Selection-for-Data-efficient-Land-Cover-Segmentation" class="headerlink" title="Core-Set Selection for Data-efficient Land Cover Segmentation"></a>Core-Set Selection for Data-efficient Land Cover Segmentation</h2><p><strong>Authors:Keiller Nogueira, Akram Zaytar, Wanli Ma, Ribana Roscher, Ronny HÃ¤nsch, Caleb Robinson, Anthony Ortiz, Simone Nsutezo, Rahul Dodhia, Juan M. Lavista Ferres, Oktay KarakuÅŸ, Paul L. Rosin</strong></p>
<p>The increasing accessibility of remotely sensed data and the potential of such data to inform large-scale decision-making has driven the development of deep learning models for many Earth Observation tasks. Traditionally, such models must be trained on large datasets. However, the common assumption that broadly larger datasets lead to better outcomes tends to overlook the complexities of the data distribution, the potential for introducing biases and noise, and the computational resources required for processing and storing vast datasets. Therefore, effective solutions should consider both the quantity and quality of data. In this paper, we propose six novel core-set selection methods for selecting important subsets of samples from remote sensing image segmentation datasets that rely on imagery only, labels only, and a combination of each. We benchmark these approaches against a random-selection baseline on three commonly used land cover classification datasets: DFC2022, Vaihingen, and Potsdam. In each of the datasets, we demonstrate that training on a subset of samples outperforms the random baseline, and some approaches outperform training on all available data. This result shows the importance and potential of data-centric learning for the remote sensing domain. The code is available at <a target="_blank" rel="noopener" href="https://github.com/keillernogueira/data-centric-rs-classification/">https://github.com/keillernogueira/data-centric-rs-classification/</a>. </p>
<blockquote>
<p>é¥æ„Ÿæ•°æ®çš„æ—¥ç›Šæ™®åŠåŠå…¶ä¸ºå¤§è§„æ¨¡å†³ç­–æä¾›ä¿¡æ¯çš„æ½œåŠ›ï¼Œæ¨åŠ¨äº†æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åœ°çƒè§‚æµ‹ä»»åŠ¡ä¸­çš„å‘å±•ã€‚ä¼ ç»Ÿä¸Šï¼Œæ­¤ç±»æ¨¡å‹å¿…é¡»åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œæ™®éå­˜åœ¨çš„å‡è®¾æ˜¯å¤§è§„æ¨¡æ•°æ®é›†ä¼šè·å¾—æ›´å¥½çš„ç»“æœï¼Œè¿™å¾€å¾€ä¼šå¿½è§†æ•°æ®åˆ†å¸ƒçš„å¤æ‚æ€§ã€å¼•å…¥åè§å’Œå™ªå£°çš„å¯èƒ½æ€§ï¼Œä»¥åŠå¤„ç†å­˜å‚¨å¤§é‡æ•°æ®æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚å› æ­¤ï¼Œæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆåº”åŒæ—¶è€ƒè™‘æ•°æ®çš„è´¨é‡å’Œæ•°é‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å…­ç§æ–°çš„æ ¸å¿ƒé›†é€‰æ‹©æ–¹æ³•ï¼Œç”¨äºä»é¥æ„Ÿå›¾åƒåˆ†å‰²æ•°æ®é›†ä¸­é€‰æ‹©é‡è¦çš„æ ·æœ¬å­é›†ï¼Œè¿™äº›å­é›†ä»…ä¾èµ–äºå›¾åƒã€ä»…ä¾èµ–äºæ ‡ç­¾ä»¥åŠä¸¤è€…çš„ç»„åˆã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå¸¸ç”¨çš„åœŸåœ°è¦†ç›–åˆ†ç±»æ•°æ®é›†ä¸Šå¯¹è¿™äº›æ–¹æ³•ä¸éšæœºé€‰æ‹©åŸºçº¿è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼šDFC2022ã€ç“¦ä¼Šå®æ ¹å’Œæ³¢èŒ¨å¦ã€‚åœ¨æ¯ä¸ªæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬éƒ½è¯æ˜äº†åœ¨æ ·æœ¬å­é›†ä¸Šè¿›è¡Œè®­ç»ƒä¼˜äºéšæœºåŸºçº¿ï¼Œå¹¶ä¸”æŸäº›æ–¹æ³•çš„æ€§èƒ½ä¼˜äºåœ¨æ‰€æœ‰å¯ç”¨æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¿™ä¸€ç»“æœå±•ç¤ºäº†ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å­¦ä¹ åœ¨é¥æ„Ÿé¢†åŸŸçš„é‡è¦æ€§å’Œæ½œåŠ›ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/keillernogueira/data-centric-rs-classification/%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/keillernogueira/data-centric-rs-classification/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01225v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†é¥æ„Ÿæ•°æ®åœ¨åœ°çƒè§‚æµ‹ä»»åŠ¡ä¸­åº”ç”¨æ·±åº¦å­¦ä¹ çš„æ½œåŠ›ã€‚é’ˆå¯¹ä¼ ç»Ÿå¤§æ•°æ®è®­ç»ƒæ¨¡å‹çš„ä¸è¶³ï¼Œå¦‚æ•°æ®åˆ†å¸ƒå¤æ‚æ€§ã€æ½œåœ¨çš„åè§å’Œå™ªå£°é—®é¢˜ä»¥åŠè®¡ç®—èµ„æºéœ€æ±‚ç­‰ï¼Œæœ¬æ–‡æå‡ºäº†å…­ç§æ–°çš„æ ¸å¿ƒæ ·æœ¬é€‰æ‹©æ–¹æ³•ï¼Œç”¨äºä»é¥æ„Ÿå›¾åƒåˆ†å‰²æ•°æ®é›†ä¸­é€‰æ‹©é‡è¦æ ·æœ¬å­é›†ã€‚åœ¨ä¸‰ä¸ªå¸¸ç”¨çš„åœŸåœ°è¦†ç›–åˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºå­é›†æ ·æœ¬çš„è®­ç»ƒæ•ˆæœä¼˜äºéšæœºé€‰æ‹©åŸºçº¿ï¼Œéƒ¨åˆ†æ–¹æ³•ç”šè‡³ä¼˜äºä½¿ç”¨æ‰€æœ‰å¯ç”¨æ•°æ®ã€‚è¿™å‡¸æ˜¾äº†ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å­¦ä¹ åœ¨é¥æ„Ÿé¢†åŸŸçš„é‡è¦æ€§å’Œæ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¥æ„Ÿæ•°æ®çš„æ˜“è·å–æ€§å’Œå…¶åœ¨å¤§å‹å†³ç­–ä¸­çš„ä¿¡æ¯æ½œåŠ›æ¨åŠ¨äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å‘å±•ã€‚</li>
<li>ä¼ ç»Ÿä¸Šï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹éœ€è¦åœ¨å¤§æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>å¤§æ•°æ®é›†æœªå¿…æ€»æ˜¯å¸¦æ¥æœ€ä½³ç»“æœï¼Œå¿½è§†äº†æ•°æ®åˆ†å¸ƒçš„å¤æ‚æ€§ã€æ½œåœ¨çš„åè§å’Œå™ªå£°ä»¥åŠè®¡ç®—èµ„æºçš„éœ€æ±‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†å…­ç§æ–°çš„æ ¸å¿ƒæ ·æœ¬é€‰æ‹©æ–¹æ³•ï¼Œä»é¥æ„Ÿå›¾åƒåˆ†å‰²æ•°æ®é›†ä¸­é€‰æ‹©é‡è¦æ ·æœ¬ã€‚</li>
<li>åœ¨ä¸‰ä¸ªåœŸåœ°è¦†ç›–åˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºå­é›†æ ·æœ¬çš„è®­ç»ƒæ•ˆæœä¼˜äºéšæœºé€‰æ‹©ã€‚</li>
<li>éƒ¨åˆ†æ–¹æ³•è¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³è¶…è¿‡äº†ä½¿ç”¨å…¨éƒ¨æ•°æ®è¿›è¡Œçš„è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01225">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f15fd48cb9a2fe96916cbb5ab30c6686.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f323674dab01601341094ca7b84277d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb218cabed848ea22d281ca4fef17147.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Imaging-Ultrafast-Dynamical-Diffraction-wavefronts-of-femtosecond-laser-induced-lattice-distortions-inside-crystalline-semiconductors"><a href="#Imaging-Ultrafast-Dynamical-Diffraction-wavefronts-of-femtosecond-laser-induced-lattice-distortions-inside-crystalline-semiconductors" class="headerlink" title="Imaging Ultrafast Dynamical Diffraction wavefronts of femtosecond   laser-induced lattice distortions inside crystalline semiconductors"></a>Imaging Ultrafast Dynamical Diffraction wavefronts of femtosecond   laser-induced lattice distortions inside crystalline semiconductors</h2><p><strong>Authors:Angel RodrÃ­guez-FernÃ¡ndez, Jan-Etienne Pudell, Roman Shayduk, Wonhyuk Jo, James Wrigley, Johannes MÃ¶ller, Peter Zalden, Alexey Zozulya, JÃ¶rg Hallmann, Anders Madsen, Pablo Villanueva-Perez, Zdenek Matej, Thies J. Albert, Dominik Kaczmarek, Klaus Sokolowski-Tinten, Antonowicz Jerzy, Ryszard Sobierajski, Rahimi Mosafer, Oleksii I. Liubchenko, Javier Solis, Jan Siegel</strong></p>
<p>Material processing with femtosecond lasers has attracted enormous attention because of its potential for technology and industrial applications. In parallel, time-resolved x-ray diffraction has been successfully used to study ultrafast structural distortion dynamics in semiconductor thin films or surface layers. However, real-world processing applications mostly are concerned with bulk materials, which prevents the use of x-ray surface based techniques. For processing applications, a fast and depth-sensitive probe is needed. To address this, we present a novel technique based on ultrafast x-ray dynamical diffraction (UDD) capable of imaging transient strain distributions inside bulk crystals upon laser excitation. This pump-probe technique provides a complete picture of thetemporal evolution of ultrafast distorted lattice depth profiles. We demonstrate the potential of UDD by studying a thin Si single crystal upon single pulse femtosecond optical excitation. Our study reveals that below the melting threshold strong lattice distortions not only longitudinal, but also transversal to the propagation of the strain wave appear on picosecond time scales along the single crystal. The observation of this transversal deformation after laser excitation contradicts previous work that were not able to observed it, what could be related to the high sensitivity of dynamical diffraction with respect to the lattice distortions. The speed of propagation of this ultrafast transversal strain deformation is observed to be slower to the longitudinal sound speed for Si as described in the bibliography. </p>
<blockquote>
<p>ææ–™é€šè¿‡é£ç§’æ¿€å…‰å¤„ç†å› å…¶æŠ€æœ¯å’Œå·¥ä¸šåº”ç”¨æ½œåŠ›è€Œå¤‡å—å…³æ³¨ã€‚åŒæ—¶ï¼Œæ—¶é—´åˆ†è¾¨Xå°„çº¿è¡å°„å·²æˆåŠŸåº”ç”¨äºåŠå¯¼ä½“è–„è†œæˆ–è¡¨é¢å±‚è¶…å¿«ç»“æ„ç•¸å˜åŠ¨åŠ›å­¦çš„ç ”ç©¶ã€‚ç„¶è€Œï¼Œå®é™…åº”ç”¨ä¸­çš„ææ–™å¤„ç†ä¸»è¦å…³æ³¨å—ä½“ææ–™ï¼Œè¿™ä½¿å¾—åŸºäºXå°„çº¿è¡¨é¢çš„æŠ€æœ¯æ— æ³•åº”ç”¨ã€‚å¯¹äºå¤„ç†åº”ç”¨è€Œè¨€ï¼Œéœ€è¦ä¸€ä¸ªå¿«é€Ÿä¸”å¯¹æ·±åº¦æ•æ„Ÿçš„æ¢é’ˆã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè¶…å¿«Xå°„çº¿åŠ¨åŠ›å­¦è¡å°„ï¼ˆUDDï¼‰çš„æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿåœ¨æ¿€å…‰æ¿€å‘ä¸‹å¯¹å—ä½“å†…æ™¶ä½“ç¬æ—¶åº”å˜åˆ†å¸ƒè¿›è¡Œæˆåƒã€‚è¿™ç§æ³µæµ¦æ¢é’ˆæŠ€æœ¯æä¾›äº†è¶…å¿«ç•¸å˜æ™¶æ ¼æ·±åº¦åˆ†å¸ƒçš„ä¸´æ—¶æ¼”åŒ–çš„å®Œæ•´å›¾åƒã€‚æˆ‘ä»¬é€šè¿‡ç ”ç©¶å•è„‰å†²é£ç§’å…‰å­¦æ¿€å‘ä¸‹çš„ç¡…å•æ™¶è–„è†œï¼Œå±•ç¤ºäº†UDDçš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œåœ¨ç†”ç‚¹ä»¥ä¸‹ï¼Œå¼ºçƒˆçš„æ™¶æ ¼ç•¸å˜ä¸ä»…çºµå‘å‡ºç°ï¼Œè€Œä¸”åœ¨åº”åŠ›æ³¢ä¼ æ’­çš„æ¨ªå‘ä¹Ÿä¼šå‡ºç°ï¼Œåœ¨çš®ç§’æ—¶é—´å°ºåº¦ä¸Šæ²¿ç€å•æ™¶ä¼ æ’­ã€‚æ¿€å…‰æ¿€å‘åè§‚å¯Ÿåˆ°çš„è¿™ç§æ¨ªå‘å˜å½¢ä¸ä»¥å‰çš„ç ”ç©¶ç»“æœç›¸çŸ›ç›¾ï¼Œä»¥å‰çš„ç ”ç©¶æœªèƒ½è§‚å¯Ÿåˆ°è¿™ä¸€ç°è±¡ï¼Œè¿™å¯èƒ½ä¸åŠ¨åŠ›å­¦è¡å°„å¯¹æ™¶æ ¼ç•¸å˜çš„é«˜æ•æ„Ÿæ€§æœ‰å…³ã€‚è§‚å¯Ÿåˆ°çš„è¿™ç§è¶…å¿«æ¨ªå‘åº”å˜å˜å½¢çš„ä¼ æ’­é€Ÿåº¦æ¯”æ–‡çŒ®ä¸­æè¿°çš„ç¡…çš„çºµå£°æ³¢é€Ÿåº¦æ…¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.10420v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§åŸºäºè¶…å¿«Xå°„çº¿åŠ¨åŠ›å­¦è¡å°„ï¼ˆUDDï¼‰çš„æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿæˆåƒæ¿€å…‰æ¿€å‘ä¸‹ä½“å†…ç¬æ€åº”å˜åˆ†å¸ƒã€‚è¯¥æŠ€æœ¯ä¸ºæ³µæµ¦æ¢æµ‹æŠ€æœ¯ï¼Œæä¾›äº†è¶…å¿«ç•¸å˜æ™¶æ ¼æ·±åº¦åˆ†å¸ƒçš„æš‚æ—¶æ¼”åŒ–çš„å®Œæ•´å›¾åƒã€‚é€šè¿‡å•ä¸€è„‰å†²é£ç§’å…‰å­¦æ¿€å‘ä¸‹ç¡…å•æ™¶çš„ç ”ç©¶ï¼Œæ­ç¤ºäº†æ™¶æ ¼ç•¸å˜ä¸ä»…åœ¨çºµå‘äº§ç”Ÿï¼Œè€Œä¸”åœ¨åº”åŠ›æ³¢ä¼ æ’­çš„æ¨ªå‘æ–¹å‘ä¸Šä¹Ÿå‡ºç°ã€‚è¿™ç§æ¨ªå‘å˜å½¢çš„è§‚å¯Ÿä¸ä¹‹å‰çš„ç†è®ºé¢„æµ‹ç›¸æ‚–ï¼Œå¯èƒ½æ˜¯ç”±äºåŠ¨åŠ›å­¦è¡å°„å¯¹æ™¶æ ¼ç•¸å˜çš„æ•æ„Ÿæ€§è¾ƒé«˜ã€‚è§‚å¯Ÿåˆ°è¿™ç§è¶…å¿«æ¨ªå‘åº”å˜å˜å½¢çš„ä¼ æ’­é€Ÿåº¦æ¯”ç¡…çš„çºµæ³¢å£°é€Ÿæ…¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å¿«Xå°„çº¿åŠ¨åŠ›å­¦è¡å°„æŠ€æœ¯å¯ç”¨äºæˆåƒæ¿€å…‰æ¿€å‘ä¸‹ä½“å†…ç¬æ€åº”å˜åˆ†å¸ƒã€‚</li>
<li>æ­¤æŠ€æœ¯ä¸ºç ”ç©¶è¶…å¿«ç•¸å˜æ™¶æ ¼æ·±åº¦åˆ†å¸ƒæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚</li>
<li>åœ¨é£ç§’å…‰å­¦æ¿€å‘ä¸‹ï¼Œç¡…å•æ™¶ä¸­å‡ºç°äº†æ¨ªå‘æ™¶æ ¼ç•¸å˜ã€‚</li>
<li>è¯¥å‘ç°ä¸å…ˆå‰çš„ç ”ç©¶ç»“æœç›¸æ‚–ï¼Œå¯èƒ½æ˜¯å› ä¸ºè¶…å¿«Xå°„çº¿åŠ¨åŠ›å­¦è¡å°„å¯¹æ™¶æ ¼ç•¸å˜çš„æé«˜æ•æ„Ÿæ€§ã€‚</li>
<li>è¶…å¿«æ¨ªå‘åº”å˜å˜å½¢çš„ä¼ æ’­é€Ÿåº¦è¾ƒæ…¢ï¼Œä½äºç¡…çš„çºµæ³¢å£°é€Ÿã€‚</li>
<li>è¯¥æŠ€æœ¯å¯¹äºç ”ç©¶ææ–™åœ¨æ¿€å…‰å¤„ç†ä¸­çš„å†…éƒ¨ç»“æ„å˜åŒ–å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.10420">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cc317d45019dd5728e8ce98a530d3185.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Learn2Synth-Learning-Optimal-Data-Synthesis-Using-Hypergradients-for-Brain-Image-Segmentation"><a href="#Learn2Synth-Learning-Optimal-Data-Synthesis-Using-Hypergradients-for-Brain-Image-Segmentation" class="headerlink" title="Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for   Brain Image Segmentation"></a>Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for   Brain Image Segmentation</h2><p><strong>Authors:Xiaoling Hu, Xiangrui Zeng, Oula Puonti, Juan Eugenio Iglesias, Bruce Fischl, Yael Balbastre</strong></p>
<p>Domain randomization through synthesis is a powerful strategy to train networks that are unbiased with respect to the domain of the input images. Randomization allows networks to see a virtually infinite range of intensities and artifacts during training, thereby minimizing overfitting to appearance and maximizing generalization to unseen data. Although powerful, this approach relies on the accurate tuning of a large set of hyperparameters that govern the probabilistic distribution of the synthesized images. Instead of manually tuning these parameters, we introduce Learn2Synth, a novel procedure in which synthesis parameters are learned using a small set of real labeled data. Unlike methods that impose constraints to align synthetic data with real data (e.g., contrastive or adversarial techniques), which risk misaligning the image and its label map, we tune an augmentation engine such that a segmentation network trained on synthetic data has optimal accuracy when applied to real data. This approach allows the training procedure to benefit from real labeled examples, without ever using these real examples to train the segmentation network, which avoids biasing the network towards the properties of the training set. Specifically, we develop parametric and nonparametric strategies to enhance synthetic images in a way that improves the performance of the segmentation network. We demonstrate the effectiveness of this learning strategy on synthetic and real-world brain scans. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/HuXiaoling/Learn2Synth">https://github.com/HuXiaoling/Learn2Synth</a>. </p>
<blockquote>
<p>é€šè¿‡åˆæˆè¿›è¡ŒåŸŸéšæœºåŒ–æ˜¯ä¸€ç§å¼ºå¤§çš„ç­–ç•¥ï¼Œç”¨äºè®­ç»ƒå¯¹äºè¾“å…¥å›¾åƒåŸŸä¸åè§çš„ç½‘ç»œã€‚éšæœºåŒ–å…è®¸ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°å‡ ä¹æ— é™èŒƒå›´çš„å¼ºåº¦å’Œä¼ªå½±ï¼Œä»è€Œæœ€å¤§ç¨‹åº¦åœ°å‡å°‘å¯¹å¤–è§‚çš„è¿‡æ‹Ÿåˆï¼Œå¹¶æœ€å¤§åŒ–å¯¹æœªè§æ•°æ®çš„æ³›åŒ–ã€‚å°½ç®¡è¿™ç§ç­–ç•¥å¼ºå¤§ï¼Œä½†å®ƒä¾èµ–äºå¤§é‡æ§åˆ¶åˆæˆå›¾åƒæ¦‚ç‡åˆ†å¸ƒçš„è¶…çº§å‚æ•°çš„ç²¾ç¡®è°ƒæ•´ã€‚æˆ‘ä»¬æ²¡æœ‰æ‰‹åŠ¨è°ƒæ•´è¿™äº›å‚æ•°ï¼Œè€Œæ˜¯å¼•å…¥äº†Learn2Synthè¿™ä¸€æ–°ç¨‹åºï¼Œè¯¥ç¨‹åºä½¿ç”¨å°‘é‡çœŸå®æ ‡è®°æ•°æ®æ¥å­¦ä¹ åˆæˆå‚æ•°ã€‚ä¸å…¶ä»–é€šè¿‡æ–½åŠ çº¦æŸæ¥ä½¿åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®å¯¹é½çš„æ–¹æ³•ï¼ˆä¾‹å¦‚å¯¹æ¯”æˆ–å¯¹æŠ—æŠ€æœ¯ï¼‰ä¸åŒï¼Œè¿™äº›æ–¹æ³•å¯èƒ½ä¼šè¯¯å¯¹é½å›¾åƒåŠå…¶æ ‡ç­¾æ˜ å°„ã€‚æˆ‘ä»¬è°ƒæ•´äº†å¢å¼ºå¼•æ“ï¼Œä½¿å¾—åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„åˆ†å‰²ç½‘ç»œåœ¨å®é™…æ•°æ®ä¸Šå…·æœ‰æœ€ä½³ç²¾åº¦ã€‚è¿™ç§æ–¹æ³•å…è®¸è®­ç»ƒè¿‡ç¨‹å—ç›ŠäºçœŸå®çš„æ ‡è®°ç¤ºä¾‹ï¼Œè€Œæ— éœ€ä½¿ç”¨è¿™äº›çœŸå®ç¤ºä¾‹æ¥è®­ç»ƒåˆ†å‰²ç½‘ç»œï¼Œä»è€Œé¿å…äº†ä½¿ç½‘ç»œåå‘äºè®­ç»ƒé›†çš„å±æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ¶å®šäº†å‚æ•°å’Œéå‚æ•°ç­–ç•¥æ¥å¢å¼ºåˆæˆå›¾åƒçš„æ–¹å¼ï¼Œä»¥æé«˜åˆ†å‰²ç½‘ç»œçš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„å¤§è„‘æ‰«æä¸Šè¯æ˜äº†è¿™ç§å­¦ä¹ ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯ç”¨åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/HuXiaoling/Learn2Synth%E3%80%82">https://github.com/HuXiaoling/Learn2Synthã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16719v3">PDF</a> 16 pages, 5 figures. Accepted by ICCVâ€™25</p>
<p><strong>Summary</strong><br>    åˆæˆå›¾åƒçš„æ–¹æ³•æ˜¯ä¸€ç§å¼ºå¤§çš„è®­ç»ƒç½‘ç»œç­–ç•¥ï¼Œèƒ½è®­ç»ƒå‡ºå¯¹è¾“å…¥å›¾åƒé¢†åŸŸæ— åè§çš„ç½‘ç»œã€‚æ­¤æ–¹æ³•é€šè¿‡éšæœºåŒ–æ‰‹æ®µæ‰©å¤§ç½‘ç»œçš„è§†é‡èŒƒå›´ï¼Œä½¿ç½‘ç»œé€‚åº”æ›´å¤šå˜å¼‚æƒ…å¢ƒå’Œé™ä½å¯¹å›ºæœ‰æƒ…å¢ƒçš„ä¾èµ–ï¼Œä»è€Œå‡å°‘è¿‡æ‹Ÿåˆé£é™©å¹¶å¢åŠ å¯¹æœªè§æ•°æ®çš„æ³›åŒ–èƒ½åŠ›ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ­¤æ–¹æ³•çš„è¿ç”¨å´æåº¦ä¾èµ–äºåˆæˆå›¾åƒæ¦‚ç‡åˆ†å¸ƒçš„å¤§é‡è¶…å‚æ•°ç²¾å‡†è°ƒæ•´ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºLearn2Synthè¿™ä¸€æ–°æ–¹æ³•ï¼Œé€šè¿‡å°‘é‡çœŸå®æ ‡è®°æ•°æ®å­¦ä¹ è°ƒæ•´åˆæˆå‚æ•°ã€‚ç›¸è¾ƒäºé‡‡ç”¨çº¦æŸå¯¹é½åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®çš„æ–¹æ³•ï¼ˆå¦‚å¯¹æ¯”æˆ–å¯¹æŠ—æŠ€æœ¯ï¼‰ï¼Œæˆ‘ä»¬è°ƒæ•´æ‰©å……å¼•æ“ä»¥ä¼˜åŒ–åœ¨çœŸå®æ•°æ®ä¸Šåº”ç”¨çš„åˆ†å‰²ç½‘ç»œçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä½¿å¾—è®­ç»ƒè¿‡ç¨‹å—ç›ŠäºçœŸå®æ ‡è®°ç¤ºä¾‹ï¼ŒåŒæ—¶é¿å…åˆ†å‰²ç½‘ç»œä½¿ç”¨è¿™äº›çœŸå®ç¤ºä¾‹è¿›è¡Œè®­ç»ƒçš„é£é™©ï¼Œé¿å…äº†ç½‘ç»œçš„è®­ç»ƒé›†å±æ€§åè§ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åˆ¶å®šäº†å‚æ•°å’Œéå‚æ•°ç­–ç•¥ä»¥å¢å¼ºåˆæˆå›¾åƒçš„æ–¹å¼ï¼Œä»¥æé«˜åˆ†å‰²ç½‘ç»œçš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®è„‘æ‰«æä¸ŠéªŒè¯äº†è¯¥å­¦ä¹ ç­–ç•¥çš„æ•ˆç”¨ã€‚ç›¸å…³ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/HuXiaoling/Learn2Synth%E3%80%82">https://github.com/HuXiaoling/Learn2Synthã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢†åŸŸéšæœºåŒ–é€šè¿‡åˆæˆå›¾åƒæ˜¯ä¸€ç§å¼ºå¤§çš„è®­ç»ƒç½‘ç»œç­–ç•¥ï¼Œèƒ½æé«˜ç½‘ç»œçš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•å…è®¸ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çœ‹åˆ°å‡ ä¹æ— é™å¼ºåº¦çš„å˜åŒ–å’Œä¼ªå½±ï¼Œä»è€Œæé«˜ç½‘ç»œçš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è™½ç„¶æ­¤æ–¹æ³•å¼ºå¤§ä½†ä¾èµ–å¤§é‡è¶…å‚æ•°çš„ç²¾å‡†è°ƒæ•´æ¥ç®¡ç†åˆæˆå›¾åƒçš„æ¦‚ç‡åˆ†å¸ƒã€‚</li>
<li>Learn2Synthæ–¹æ³•é‡‡ç”¨ä¸€ç§æ–°ç¨‹åºæ¥é€šè¿‡å­¦ä¹ è°ƒæ•´åˆæˆå‚æ•°æ¥é¿å…æ‰‹åŠ¨è°ƒæ•´è¶…å‚æ•°çš„ç¹çå·¥ä½œã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸“æ³¨äºè°ƒæ•´æ‰©å……å¼•æ“ä»¥æé«˜åˆ†å‰²ç½‘ç»œåœ¨çœŸå®æ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œé¿å…å¯¹è®­ç»ƒé›†çš„åè§ã€‚</li>
<li>å¼€å‘å‚æ•°å’Œéå‚æ•°ç­–ç•¥å¢å¼ºåˆæˆå›¾åƒçš„æ–¹å¼æé«˜äº†åˆ†å‰²ç½‘ç»œçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16719">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3aac90bef27c422579d760e6746d458.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40839fda636351939f7c73a43810325d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73207511372141ec4fae1d461a0af2d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-934193f89901c5b66d496432dfbe93f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27d1116ef09d705ccf2acab4006df8d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5b5ab04ac018b58afc165d1f3941042.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-05/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-05/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-05/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a450d7488bf32cefde230871f6220798.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-05  Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions   in Peptides
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-05/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fbb890dd60799f5e4d90b79ecab16db4.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-05  LeakyCLIP Extracting Training Data from CLIP
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26024.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
