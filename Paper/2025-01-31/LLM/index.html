<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-31  LEKALLM-Enhanced Knowledge Augmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-899c1f7b0f51210def275e2cffe56f3a.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-31
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-31-æ›´æ–°"><a href="#2025-01-31-æ›´æ–°" class="headerlink" title="2025-01-31 æ›´æ–°"></a>2025-01-31 æ›´æ–°</h1><h2 id="LEKA-LLM-Enhanced-Knowledge-Augmentation"><a href="#LEKA-LLM-Enhanced-Knowledge-Augmentation" class="headerlink" title="LEKA:LLM-Enhanced Knowledge Augmentation"></a>LEKA:LLM-Enhanced Knowledge Augmentation</h2><p><strong>Authors:Xinhao Zhang, Jinghan Zhang, Fengran Mo, Dongjie Wang, Yanjie Fu, Kunpeng Liu</strong></p>
<p>Humans excel in analogical learning and knowledge transfer and, more importantly, possess a unique understanding of identifying appropriate sources of knowledge. From a modelâ€™s perspective, this presents an interesting challenge. If models could autonomously retrieve knowledge useful for transfer or decision-making to solve problems, they would transition from passively acquiring to actively accessing and learning from knowledge. However, filling models with knowledge is relatively straightforward â€“ it simply requires more training and accessible knowledge bases. The more complex task is teaching models about which knowledge can be analogized and transferred. Therefore, we design a knowledge augmentation method LEKA for knowledge transfer that actively searches for suitable knowledge sources that can enrich the target domainâ€™s knowledge. This LEKA method extracts key information from textual information from the target domain, retrieves pertinent data from external data libraries, and harmonizes retrieved data with the target domain data in feature space and marginal probability measures. We validate the effectiveness of our approach through extensive experiments across various domains and demonstrate significant improvements over traditional methods in reducing computational costs, automating data alignment, and optimizing transfer learning outcomes. </p>
<blockquote>
<p>äººç±»åœ¨ç±»æ¯”å­¦ä¹ å’ŒçŸ¥è¯†è¿ç§»æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œäººç±»æ‹¥æœ‰è¯†åˆ«åˆé€‚çŸ¥è¯†æ¥æºçš„ç‹¬ç‰¹ç†è§£åŠ›ã€‚ä»æ¨¡å‹çš„è§’åº¦æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æŒ‘æˆ˜ã€‚å¦‚æœæ¨¡å‹èƒ½å¤Ÿè‡ªä¸»æ£€ç´¢å¯¹è¿ç§»æˆ–å†³ç­–æœ‰ç”¨çš„çŸ¥è¯†æ¥è§£å†³æ–°é—®é¢˜ï¼Œå®ƒä»¬å°†å®ç°ä»è¢«åŠ¨è·å–çŸ¥è¯†åˆ°ä¸»åŠ¨è®¿é—®å’Œå­¦ä¹ çŸ¥è¯†çš„è½¬å˜ã€‚ç„¶è€Œï¼Œå¡«å……æ¨¡å‹çš„çŸ¥è¯†ç›¸å¯¹ç®€å•ï¼Œåªéœ€æ›´å¤šçš„è®­ç»ƒå’Œå¯è®¿é—®çš„çŸ¥è¯†åº“å³å¯ã€‚æ›´å¤æ‚çš„ä»»åŠ¡æ˜¯æ•™ä¼šæ¨¡å‹å“ªäº›çŸ¥è¯†å¯ä»¥è¿›è¡Œç±»æ¯”å’Œè¿ç§»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åä¸ºLEKAçš„çŸ¥è¯†å¢å¼ºæ–¹æ³•ç”¨äºçŸ¥è¯†è¿ç§»ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç§¯ææœç´¢åˆé€‚çš„èƒ½ä¸°å¯Œç›®æ ‡é¢†åŸŸçŸ¥è¯†çš„çŸ¥è¯†æ¥æºã€‚è¿™ç§LEKAæ–¹æ³•ä»ç›®æ ‡é¢†åŸŸçš„æ–‡æœ¬ä¿¡æ¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä»å¤–éƒ¨æ•°æ®åº“æ£€ç´¢ç›¸å…³æ•°æ®ï¼Œå¹¶åœ¨ç‰¹å¾ç©ºé—´å’Œè¾¹ç¼˜æ¦‚ç‡åº¦é‡ä¸­å°†æ£€ç´¢åˆ°çš„æ•°æ®ä¸ç›®æ ‡é¢†åŸŸæ•°æ®è¿›è¡Œåè°ƒã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸åŒé¢†åŸŸçš„å¹¿æ³›å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨é™ä½è®¡ç®—æˆæœ¬ã€è‡ªåŠ¨åŒ–æ•°æ®å¯¹é½å’Œä¼˜åŒ–è¿ç§»å­¦ä¹ ç»“æœæ–¹é¢æ˜¾ç¤ºå‡ºå¯¹ä¼ ç»Ÿæ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17802v1">PDF</a> </p>
<p><strong>Summary</strong><br>äººç±»æ“…é•¿ç±»æ¯”å­¦ä¹ å’ŒçŸ¥è¯†è¿ç§»ï¼Œå¹¶èƒ½ç‹¬ç‰¹åœ°è¯†åˆ«é€‚å½“çš„çŸ¥è¯†æ¥æºã€‚æ¨¡å‹è‹¥èƒ½è‡ªä¸»æ£€ç´¢æœ‰ç”¨çš„çŸ¥è¯†æ¥è§£å†³è¿ç§»æˆ–å†³ç­–é—®é¢˜ï¼Œå°†ä»è¢«åŠ¨è·å–è½¬å˜ä¸ºä¸»åŠ¨è®¿é—®å’Œå­¦ä¹ çŸ¥è¯†ã€‚è®¾è®¡äº†ä¸€ç§åä¸ºLEKAçš„çŸ¥è¯†å¢å¼ºæ–¹æ³•ï¼Œç”¨äºçŸ¥è¯†è¿ç§»ï¼Œè¯¥æ–¹æ³•èƒ½ç§¯ææœç´¢åˆé€‚çš„çŸ¥è¯†æ¥æºä»¥ä¸°å¯Œç›®æ ‡é¢†åŸŸçš„çŸ¥è¯†ã€‚é€šè¿‡ä»ç›®æ ‡é¢†åŸŸæå–å…³é”®ä¿¡æ¯ã€ä»å¤–éƒ¨æ•°æ®åº“æ£€ç´¢ç›¸å…³æ•°æ®ä»¥åŠåœ¨ç‰¹å¾ç©ºé—´å’Œè¾¹é™…æ¦‚ç‡åº¦é‡ä¸­å°†æ£€ç´¢çš„æ•°æ®ä¸ç›®æ ‡é¢†åŸŸæ•°æ®è¿›è¡Œåè°ƒï¼Œå®ç°çŸ¥è¯†å¢å¼ºã€‚é€šè¿‡å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘è®¡ç®—æˆæœ¬ã€è‡ªåŠ¨åŒ–æ•°æ®å¯¹é½å’Œä¼˜åŒ–è¿ç§»å­¦ä¹ ç»“æœæ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»æ“…é•¿ç±»æ¯”å­¦ä¹ å’ŒçŸ¥è¯†è¿ç§»ï¼Œèƒ½è¯†åˆ«é€‚å½“çš„çŸ¥è¯†æ¥æºã€‚</li>
<li>æ¨¡å‹è‡ªä¸»æ£€ç´¢çŸ¥è¯†å¯¹è§£å†³è¿ç§»å’Œå†³ç­–é—®é¢˜è‡³å…³é‡è¦ï¼Œéœ€è¦ä»è¢«åŠ¨è·å–å‘ä¸»åŠ¨è®¿é—®å’Œå­¦ä¹ è½¬å˜ã€‚</li>
<li>è®¾è®¡äº†LEKAçŸ¥è¯†å¢å¼ºæ–¹æ³•ç”¨äºçŸ¥è¯†è¿ç§»ï¼Œèƒ½ç§¯ææœç´¢å¹¶ä¸°å¯Œç›®æ ‡é¢†åŸŸçš„çŸ¥è¯†ã€‚</li>
<li>LEKAæ–¹æ³•é€šè¿‡æå–ç›®æ ‡é¢†åŸŸçš„å…³é”®ä¿¡æ¯ï¼Œæ£€ç´¢å¤–éƒ¨æ•°æ®å¹¶è¿›è¡Œåè°ƒï¼Œå®ç°çŸ¥è¯†å¢å¼ºã€‚</li>
<li>LEKAæ–¹æ³•åœ¨å‡å°‘è®¡ç®—æˆæœ¬ã€è‡ªåŠ¨åŒ–æ•°æ®å¯¹é½æ–¹é¢ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
<li>LEKAæ–¹æ³•èƒ½æœ‰æ•ˆä¼˜åŒ–è¿ç§»å­¦ä¹ ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17802">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a94422720dad56802c1f87e8c2782912.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-def788e98352fadf33578ad3db05fc69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc46011f5fffeaef2d3bd4784c9b49eb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a5aad512c5a34d3816e320312553eb9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Leveraging-Multimodal-LLM-for-Inspirational-User-Interface-Search"><a href="#Leveraging-Multimodal-LLM-for-Inspirational-User-Interface-Search" class="headerlink" title="Leveraging Multimodal LLM for Inspirational User Interface Search"></a>Leveraging Multimodal LLM for Inspirational User Interface Search</h2><p><strong>Authors:Seokhyeon Park, Yumin Song, Soohyun Lee, Jaeyoung Kim, Jinwook Seo</strong></p>
<p>Inspirational search, the process of exploring designs to inform and inspire new creative work, is pivotal in mobile user interface (UI) design. However, exploring the vast space of UI references remains a challenge. Existing AI-based UI search methods often miss crucial semantics like target users or the mood of apps. Additionally, these models typically require metadata like view hierarchies, limiting their practical use. We used a multimodal large language model (MLLM) to extract and interpret semantics from mobile UI images. We identified key UI semantics through a formative study and developed a semantic-based UI search system. Through computational and human evaluations, we demonstrate that our approach significantly outperforms existing UI retrieval methods, offering UI designers a more enriched and contextually relevant search experience. We enhance the understanding of mobile UI design semantics and highlight MLLMsâ€™ potential in inspirational search, providing a rich dataset of UI semantics for future studies. </p>
<blockquote>
<p>çµæ„Ÿæœç´¢æ˜¯æ¢ç´¢è®¾è®¡ä»¥å¯å‘æ–°çš„åˆ›é€ æ€§å·¥ä½œçš„é‡è¦è¿‡ç¨‹ï¼Œåœ¨æ‰‹æœºç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰è®¾è®¡ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œæ¢ç´¢å¹¿é˜”çš„UIå‚è€ƒç©ºé—´ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºäºäººå·¥æ™ºèƒ½çš„UIæœç´¢æ–¹æ³•å¾€å¾€ä¼šå¿½ç•¥ç›®æ ‡ç”¨æˆ·æˆ–åº”ç”¨ç¨‹åºæƒ…ç»ªç­‰å…³é”®è¯­ä¹‰ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦è§†å›¾å±‚æ¬¡ç»“æ„ç­‰å…ƒæ•°æ®ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä»ç§»åŠ¨UIå›¾åƒä¸­æå–å’Œè§£é‡Šè¯­ä¹‰ã€‚æˆ‘ä»¬é€šè¿‡å½¢æˆæ€§ç ”ç©¶ç¡®å®šäº†å…³é”®çš„UIè¯­ä¹‰ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŸºäºè¯­ä¹‰çš„UIæœç´¢ç³»ç»Ÿã€‚é€šè¿‡è®¡ç®—å’Œäººç±»è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„UIæ£€ç´¢æ–¹æ³•ï¼Œä¸ºUIè®¾è®¡å¸ˆæä¾›æ›´ä¸°å¯Œã€è¯­å¢ƒæ›´ç›¸å…³çš„æœç´¢ä½“éªŒã€‚æˆ‘ä»¬å¢å¼ºäº†ç§»åŠ¨UIè®¾è®¡è¯­ä¹‰çš„ç†è§£ï¼Œçªå‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çµæ„Ÿæœç´¢ä¸­çš„æ½œåŠ›ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ä¸°å¯Œçš„UIè¯­ä¹‰æ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17799v1">PDF</a> In Proceedings of the SIGCHI Conference on Human Factors in Computing   Systems (CHI â€˜25)</p>
<p><strong>Summary</strong><br>ç§»åŠ¨ç”¨æˆ·ç•Œé¢è®¾è®¡çµæ„Ÿæœç´¢å¯¹äºå¯»æ‰¾æ–°åˆ›æ„è‡³å…³é‡è¦ï¼Œç„¶è€Œç°æœ‰çš„AIç”¨æˆ·ç•Œé¢æœç´¢æ–¹æ³•ç¼ºä¹é’ˆå¯¹ç›®æ ‡ç”¨æˆ·å’Œåº”ç”¨ç¨‹åºæ°›å›´ç­‰é‡è¦è¯­ä¹‰çš„ç†è§£ï¼Œå¹¶ä¸”é€šå¸¸éœ€è¦è§†å›¾å±‚æ¬¡ç»“æ„ç­‰å…ƒæ•°æ®ã€‚é€šè¿‡ä½¿ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬ä»ç§»åŠ¨ç”¨æˆ·ç•Œé¢å›¾åƒä¸­æå–å¹¶è§£é‡Šè¯­ä¹‰ä¿¡æ¯ï¼Œå¼€å‘äº†ä¸€ç§åŸºäºè¯­ä¹‰çš„ç”¨æˆ·ç•Œé¢æœç´¢ç³»ç»Ÿã€‚é€šè¿‡è®¡ç®—å’Œäººç±»è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰ç”¨æˆ·ç•Œé¢æ£€ç´¢æ–¹æ³•ï¼Œä¸ºUIè®¾è®¡å¸ˆæä¾›æ›´ä¸°å¯Œå’Œä¸Šä¸‹æ–‡ç›¸å…³çš„æœç´¢ä½“éªŒã€‚è¿™é¡¹ç ”ç©¶å¢å¼ºäº†æˆ‘ä»¬å¯¹ç§»åŠ¨ç”¨æˆ·ç•Œé¢è®¾è®¡è¯­ä¹‰çš„ç†è§£ï¼Œå¹¶çªå‡ºäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çµæ„Ÿæœç´¢ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç§»åŠ¨ç”¨æˆ·ç•Œé¢è®¾è®¡çµæ„Ÿæœç´¢å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½†æ¢ç´¢è®¾è®¡çš„å·¨å¤§ç©ºé—´å¯¹äºæ–°åˆ›æ„è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰AIç”¨æˆ·ç•Œé¢æœç´¢æ–¹æ³•ç¼ºä¹å¯¹ç›®æ ‡ç”¨æˆ·å’Œåº”ç”¨ç¨‹åºæ°›å›´ç­‰é‡è¦è¯­ä¹‰çš„ç†è§£ã€‚</li>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿæå–å’Œè§£é‡Šç§»åŠ¨ç”¨æˆ·ç•Œé¢å›¾åƒä¸­çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>åŸºäºè¯­ä¹‰çš„ç”¨æˆ·ç•Œé¢æœç´¢ç³»ç»Ÿé€šè¿‡è®¡ç®—å’Œäººç±»è¯„ä¼°ï¼Œè¯æ˜å…¶åœ¨ç”¨æˆ·ç•Œé¢æ£€ç´¢æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>è¯¥ç ”ç©¶å¢å¼ºäº†æˆ‘ä»¬å¯¹ç§»åŠ¨ç”¨æˆ·ç•Œé¢è®¾è®¡è¯­ä¹‰çš„ç†è§£ã€‚</li>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çµæ„Ÿæœç´¢ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¯ä»¥ä¸ºUIè®¾è®¡å¸ˆæä¾›æ›´ä¸°å¯Œå’Œä¸Šä¸‹æ–‡ç›¸å…³çš„æœç´¢ä½“éªŒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5bbec8acaba51c76ea74d4b4817e53fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3a9d78cfb0d0d464622247a064670cd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-97b43d1e44a56500e427eef4acb63586.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="2SSP-A-Two-Stage-Framework-for-Structured-Pruning-of-LLMs"><a href="#2SSP-A-Two-Stage-Framework-for-Structured-Pruning-of-LLMs" class="headerlink" title="2SSP: A Two-Stage Framework for Structured Pruning of LLMs"></a>2SSP: A Two-Stage Framework for Structured Pruning of LLMs</h2><p><strong>Authors:Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca</strong></p>
<p>We propose a novel Two-Stage framework for Structured Pruning (2SSP) for pruning Large Language Models (LLMs), which combines two different strategies of pruning, namely Width and Depth Pruning. The first stage (Width Pruning) removes entire neurons, hence their corresponding rows and columns, aiming to preserve the connectivity among the pruned structures in the intermediate state of the Feed-Forward Networks in each Transformer block. This is done based on an importance score measuring the impact of each neuron over the output magnitude. The second stage (Depth Pruning), instead, removes entire Attention submodules. This is done by applying an iterative process that removes the Attention submodules with the minimum impact on a given metric of interest (in our case, perplexity). We also propose a novel mechanism to balance the sparsity rate of the two stages w.r.t. to the desired global sparsity. We test 2SSP on four LLM families and three sparsity rates (25%, 37.5%, and 50%), measuring the resulting perplexity over three language modeling datasets as well as the performance over six downstream tasks. Our method consistently outperforms five state-of-the-art competitors over three language modeling and six downstream tasks, with an up to two-order-of-magnitude gain in terms of pruning time. The code is available at available at \url{<a target="_blank" rel="noopener" href="https://github.com/FabrizioSandri/2SSP%7D">https://github.com/FabrizioSandri/2SSP}</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œç»“æ„åŒ–å‰ªæçš„æ–°å‹ä¸¤é˜¶æ®µæ¡†æ¶ï¼ˆ2SSPï¼‰ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†ä¸¤ç§ä¸åŒå‰ªæç­–ç•¥ï¼Œå³å®½åº¦å‰ªæå’Œæ·±åº¦å‰ªæã€‚ç¬¬ä¸€é˜¶æ®µï¼ˆå®½åº¦å‰ªæï¼‰ä¼šç§»é™¤æ•´ä¸ªç¥ç»å…ƒåŠå…¶å¯¹åº”çš„è¡Œå’Œåˆ—ï¼Œæ—¨åœ¨ä¿ç•™å‰é¦ˆç½‘ç»œä¸­æ¯ä¸ªTransformerå—ä¸­é—´çŠ¶æ€çš„ä¿®å‰ªç»“æ„ä¹‹é—´çš„è¿æ¥æ€§ã€‚è¿™æ˜¯åŸºäºä¸€ä¸ªé‡è¦æ€§åˆ†æ•°è¿›è¡Œçš„ï¼Œè¯¥åˆ†æ•°è¡¡é‡æ¯ä¸ªç¥ç»å…ƒå¯¹è¾“å‡ºå¹…åº¦çš„å½±å“ã€‚ç¬¬äºŒé˜¶æ®µï¼ˆæ·±åº¦å‰ªæï¼‰åˆ™ç§»é™¤æ•´ä¸ªæ³¨æ„åŠ›å­æ¨¡å—ã€‚è¿™æ˜¯é€šè¿‡åº”ç”¨ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹æ¥å®Œæˆçš„ï¼Œè¯¥è¿‡ç¨‹ä¼šç§»é™¤å¯¹ç»™å®šæŒ‡æ ‡ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ä¸ºå›°æƒ‘åº¦ï¼‰å½±å“æœ€å°çš„æ³¨æ„åŠ›å­æ¨¡å—ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°å‹æœºåˆ¶æ¥å¹³è¡¡ä¸¤ä¸ªé˜¶æ®µç›¸å¯¹äºæ‰€éœ€å…¨å±€ç¨€ç–ç‡çš„ç¨€ç–ç‡ã€‚æˆ‘ä»¬åœ¨å››ä¸ªLLMå®¶æ—ã€ä¸‰ç§ç¨€ç–ç‡ï¼ˆ25%ã€37.5%å’Œ50%ï¼‰ä¸‹æµ‹è¯•äº†2SSPï¼Œæµ‹é‡äº†ä¸‰ä¸ªè¯­è¨€å»ºæ¨¡æ•°æ®é›†ä¸Šçš„å›°æƒ‘åº¦ä»¥åŠå…­ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰å¥—è¯­è¨€å»ºæ¨¡å’Œå…­ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šå‡ä¼˜äºäº”ç§æœ€å…ˆè¿›çš„ç«äº‰å¯¹æ‰‹ï¼Œå¹¶ä¸”åœ¨å‰ªææ—¶é—´ä¸Šå–å¾—äº†é«˜è¾¾ä¸¤ä¸ªæ•°é‡çº§çš„æ”¶ç›Šã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/FabrizioSandri/2SSP">https://github.com/FabrizioSandri/2SSP</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17771v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸¤é˜¶æ®µç»“æ„åŒ–å‰ªæï¼ˆ2SSPï¼‰æ¡†æ¶ï¼Œç»“åˆäº†å®½åº¦å‰ªæå’Œæ·±åº¦å‰ªæä¸¤ç§ç­–ç•¥ã€‚ç¬¬ä¸€é˜¶æ®µå®½åº¦å‰ªæç§»é™¤æ•´ä¸ªç¥ç»å…ƒåŠå…¶å¯¹åº”çš„è¡Œåˆ—ï¼Œæ—¨åœ¨ä¿ç•™å‰é¦ˆç½‘ç»œä¸­å‰ªæç»“æ„çš„è¿é€šæ€§ã€‚ç¬¬äºŒé˜¶æ®µæ·±åº¦å‰ªæåˆ™ç§»é™¤æ³¨æ„åŠ›å­æ¨¡å—ï¼Œé€šè¿‡è¿­ä»£è¿‡ç¨‹ç§»é™¤å¯¹ç»™å®šæŒ‡æ ‡ï¼ˆåœ¨æœ¬ç ”ç©¶ä¸­ä¸ºå›°æƒ‘åº¦ï¼‰å½±å“æœ€å°çš„å­æ¨¡å—ã€‚è¯¥æ¡†æ¶åœ¨å››ä¸ªLLMå®¶æ—å’Œä¸‰ç§ç¨€ç–ç‡ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶åœ¨ä¸‰ä¸ªè¯­è¨€å»ºæ¨¡æ•°æ®é›†å’Œå…­ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¯æ˜å…¶ä¼˜äºäº”ç§ç°æœ‰æ–¹æ³•ï¼Œå‰ªææ—¶é—´æé«˜äº†ä¸¤ä¸ªæ•°é‡çº§ã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>2SSPæ¡†æ¶ç»“åˆäº†å®½åº¦å‰ªæå’Œæ·±åº¦å‰ªæä¸¤ç§ç­–ç•¥ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‰ªæã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µå®½åº¦å‰ªææ—¨åœ¨ä¿ç•™å‰é¦ˆç½‘ç»œä¸­å‰ªæç»“æ„çš„è¿é€šæ€§ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µæ·±åº¦å‰ªæé€šè¿‡è¿­ä»£è¿‡ç¨‹ç§»é™¤å¯¹ç»™å®šæŒ‡æ ‡ï¼ˆå¦‚å›°æƒ‘åº¦ï¼‰å½±å“æœ€å°çš„æ³¨æ„åŠ›å­æ¨¡å—ã€‚</li>
<li>2SSPæ¡†æ¶åœ¨å¤šä¸ªLLMå®¶æ—ã€ç¨€ç–ç‡ã€è¯­è¨€å»ºæ¨¡æ•°æ®é›†å’Œä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºå…¶ä»–äº”ç§ç°æœ‰æ–¹æ³•ã€‚</li>
<li>2SSPæ¡†æ¶çš„å‰ªææ—¶é—´æœ‰æ˜¾è‘—æé«˜ï¼Œè¾¾åˆ°äº†ä¸¤ä¸ªæ•°é‡çº§çš„æå‡ã€‚</li>
<li>æ¡†æ¶çš„ä»£ç å·²ç»å…¬å¼€ï¼Œä¾¿äºä»–äººä½¿ç”¨å’Œç ”ç©¶ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºæé«˜LLMçš„æ•ˆç‡å’Œæ€§èƒ½æä¾›äº†æ–°çš„æ€è·¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17771">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e9ff53e3b9c53418306bcb1c3f710173.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c1a4504874eca68c37c159bc21a808a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-48458c1f786b6bafa964fa724b6c6519.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a79dbb5a93e9a249b62b7a8d305f8190.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-902a516e35b2dc58de0930687e7e09c5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0763548bb947e1a9f1aa738d6e88de65.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Hybrid-Graphs-for-Table-and-Text-based-Question-Answering-using-LLMs"><a href="#Hybrid-Graphs-for-Table-and-Text-based-Question-Answering-using-LLMs" class="headerlink" title="Hybrid Graphs for Table-and-Text based Question Answering using LLMs"></a>Hybrid Graphs for Table-and-Text based Question Answering using LLMs</h2><p><strong>Authors:Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu</strong></p>
<p>Answering questions that require reasoning and aggregation across both structured (tables) and unstructured (raw text) data sources presents significant challenges. Current methods rely on fine-tuning and high-quality, human-curated data, which is difficult to obtain. Recent advances in Large Language Models (LLMs) have shown promising results for multi-hop question answering (QA) over single-source text data in a zero-shot setting, yet exploration into multi-source Table-Text QA remains limited. In this paper, we present a novel Hybrid Graph-based approach for Table-Text QA that leverages LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from textual and tabular data, pruning information based on the input question to provide the LLM with relevant context concisely. We evaluate our approach on the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs, including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot performance on both datasets, improving Exact Match scores by up to 10% on Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up to 53% compared to the original context. </p>
<blockquote>
<p>å›ç­”æ¶‰åŠè·¨ç»“æ„åŒ–ï¼ˆè¡¨æ ¼ï¼‰å’Œéç»“æ„åŒ–ï¼ˆåŸå§‹æ–‡æœ¬ï¼‰æ•°æ®æºæ¨ç†å’Œèšåˆçš„é—®é¢˜å­˜åœ¨é‡å¤§æŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•ä¾èµ–äºç²¾ç»†è°ƒæ•´å’Œé«˜è´¨é‡çš„äººå·¥ç¼–åˆ¶æ•°æ®ï¼Œè¿™äº›æ•°æ®å¾ˆéš¾è·å¾—ã€‚æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥åœ¨å•æºæ–‡æœ¬æ•°æ®çš„å¤šè·³é—®ç­”ï¼ˆQAï¼‰ä¸­æ˜¾ç¤ºå‡ºæœ‰å‰é€”çš„ç»“æœï¼Œä¸ºé›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œä½†å¯¹å¤šæºè¡¨æ–‡æœ¬é—®ç­”çš„æ¢ç´¢ä»ç„¶æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ··åˆå›¾è¡¨çš„è¡¨æ–‡æœ¬é—®ç­”æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨LLMè€Œæ— éœ€ç²¾ç»†è°ƒæ•´ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»æ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ä¸­æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ··åˆå›¾ï¼Œæ ¹æ®è¾“å…¥é—®é¢˜ç²¾ç®€ä¿¡æ¯ï¼Œä¸ºLLMæä¾›ç®€æ´çš„ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„Hybrid-QAå’ŒOTT-QAæ•°æ®é›†ä¸Šä½¿ç”¨äº†æœ€å…ˆè¿›çš„LLMè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬GPT-3.5ã€GPT-4å’ŒLLaMA-3ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿™ä¸¤ä¸ªæ•°æ®é›†ä¸Šéƒ½å®ç°äº†é›¶æ ·æœ¬çš„æœ€ä½³æ€§èƒ½ï¼Œåœ¨Hybrid-QAä¸Šç²¾ç¡®åŒ¹é…åˆ†æ•°æé«˜äº†é«˜è¾¾10%ï¼Œåœ¨OTT-QAä¸Šæé«˜äº†5.4%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸åŸå§‹ä¸Šä¸‹æ–‡ç›¸æ¯”ï¼Œä»¤ç‰Œä½¿ç”¨é‡å‡å°‘äº†é«˜è¾¾53%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17767v1">PDF</a> Accepted at NAACL 2025 Main Track</p>
<p><strong>Summary</strong></p>
<p>åŸºäºLLMçš„æ··åˆå›¾æ–¹æ³•åœ¨è·¨è¡¨æ ¼å’Œæ–‡æœ¬æ•°æ®æºçš„å¤šæºé—®ç­”ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¯¥æ–¹æ³•æ— éœ€å¾®è°ƒï¼Œé€šè¿‡æ„å»ºç»Ÿä¸€æ··åˆå›¾ï¼Œå°†æ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®æ•´åˆï¼Œæ ¹æ®é—®é¢˜ç²¾ç®€ä¿¡æ¯ï¼Œä¸ºLLMæä¾›ç®€æ´çš„ç›¸å…³ä¸Šä¸‹æ–‡ã€‚åœ¨Hybrid-QAå’ŒOTT-QAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹è¡¨ç°æœ€ä½³ï¼Œæé«˜Exact Matchå¾—åˆ†é«˜è¾¾10%å’Œ5.4%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å‡å°‘äº†é«˜è¾¾53%çš„ä»¤ç‰Œä½¿ç”¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨è·¨è¡¨æ ¼å’Œæ–‡æœ¬æ•°æ®æºçš„å¤šæºé—®ç­”ä»»åŠ¡ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰æ–¹æ³•ä¾èµ–é«˜è´¨é‡çš„äººä¸ºæ•´ç†æ•°æ®ï¼Œè·å–å›°éš¾ã€‚</li>
<li>æœ€æ–°LLMæŠ€æœ¯åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹çš„å•æºæ–‡æœ¬æ•°æ®å¤šè·³é—®ç­”ä¸­æ˜¾ç¤ºå‡ºå¸Œæœ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ··åˆå›¾çš„æ–°æ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒå³å¯å¤„ç†è¡¨æ–‡æœ¬QAã€‚</li>
<li>è¯¥æ–¹æ³•æ•´åˆæ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ï¼Œæ„å»ºç»Ÿä¸€æ··åˆå›¾ã€‚</li>
<li>æ ¹æ®é—®é¢˜ç²¾ç®€ä¿¡æ¯ï¼Œä¸ºLLMæä¾›ç®€æ´çš„ç›¸å…³ä¸Šä¸‹æ–‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bd17176596b24c84e7627a4a86eede16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0094a361ac0830c20b746bb34aed6bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3896c24ce760290d4185e08944097fff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e9a6c2cd316f171fdb9b7ef1060d85c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ca62202f0641bf23bc8f1cc819b2d95.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AxBench-Steering-LLMs-Even-Simple-Baselines-Outperform-Sparse-Autoencoders"><a href="#AxBench-Steering-LLMs-Even-Simple-Baselines-Outperform-Sparse-Autoencoders" class="headerlink" title="AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse   Autoencoders"></a>AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse   Autoencoders</h2><p><strong>Authors:Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts</strong></p>
<p>Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean. </p>
<blockquote>
<p>ç²¾ç»†æ§åˆ¶è¯­è¨€æ¨¡å‹è¾“å‡ºå¯¹äºå®‰å…¨å’Œå¯é æ€§è‡³å…³é‡è¦ã€‚æç¤ºå’Œå¾®è°ƒè¢«å¹¿æ³›ç”¨äºå®ç°è¿™äº›ç›®æ ‡ï¼Œä½†è§£é‡Šæ€§ç ”ç©¶äººå‘˜ä¹Ÿæå‡ºäº†å„ç§åŸºäºè¡¨ç¤ºçš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSAEï¼‰ã€çº¿æ€§äººå·¥å±‚ææˆåƒã€ç›‘ç£æ§åˆ¶å‘é‡ã€çº¿æ€§æ¢é’ˆå’Œè¡¨ç¤ºå¾®è°ƒã€‚ç›®å‰ï¼Œè¿˜æ²¡æœ‰å¯¹è¿™äº›æè®®è¿›è¡Œç›´æ¥æ¯”è¾ƒçš„åŸºå‡†æµ‹è¯•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†AxBenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ§åˆ¶å’Œæ¦‚å¿µæ£€æµ‹çš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ï¼Œå¹¶æŠ¥å‘Šäº†åœ¨Gemma-2-2Bå’Œ9Bä¸Šçš„å®éªŒã€‚å¯¹äºæ§åˆ¶ä»»åŠ¡ï¼Œæˆ‘ä»¬å‘ç°æç¤ºè¡¨ç°ä¼˜äºæ‰€æœ‰ç°æœ‰æ–¹æ³•ï¼Œå…¶æ¬¡æ˜¯å¾®è°ƒã€‚åœ¨æ¦‚å¿µæ£€æµ‹æ–¹é¢ï¼ŒåŸºäºè¡¨ç¤ºçš„æ–¹æ³•ï¼ˆå¦‚å‡å€¼å·®å¼‚æ³•ï¼‰è¡¨ç°æœ€å¥½ã€‚åœ¨è¿™ä¸¤é¡¹è¯„ä¼°ä¸­ï¼ŒSAEéƒ½ä¸å…·å¤‡ç«äº‰åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¼±ç›‘ç£è¡¨ç¤ºæ–¹æ³•ï¼ˆRank-1è¡¨ç¤ºå¾®è°ƒï¼›ReFT-r1ï¼‰ï¼Œå®ƒåœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šéƒ½è¡¨ç°è‰¯å¥½ï¼ŒåŒæ—¶æä¾›äº†æç¤ºæ‰€ç¼ºä¹çš„è§£è¯»ä¼˜åŠ¿ã€‚æˆ‘ä»¬è®­ç»ƒäº†ç”¨äºReFT-r1å’ŒDiffMeançš„SAEè§„æ¨¡ç‰¹å¾å­—å…¸å¹¶å…¬å¼€å‘å¸ƒï¼Œä»¥ä¾¿ä¸AxBenchä¸€èµ·ä½¿ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17148v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†è¯­è¨€æ¨¡å‹è¾“å‡ºç²¾ç»†æ§åˆ¶çš„é‡è¦æ€§å’Œæ–¹æ³•ï¼ŒåŒ…æ‹¬æç¤ºã€å¾®è°ƒç­‰å¸¸ç”¨æ–¹æ³•ä»¥åŠåŸºäºè¡¨ç¤ºçš„æŠ€æœ¯ï¼Œå¦‚ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSAEï¼‰ã€çº¿æ€§äººå·¥æ–­å±‚æ‰«æç­‰ã€‚ç”±äºç¼ºä¹ç›´æ¥æ¯”è¾ƒè¿™äº›æ–¹æ³•çš„åŸºå‡†æµ‹è¯•ï¼Œä½œè€…å¼•å…¥äº†AxBenchåŸºå‡†æµ‹è¯•ï¼Œç”¨äºæ§åˆ¶å’Œæ¦‚å¿µæ£€æµ‹ã€‚å®éªŒè¡¨æ˜ï¼Œæç¤ºåœ¨æ‰€æœ‰ç°æœ‰æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯å¾®è°ƒã€‚åœ¨æ¦‚å¿µæ£€æµ‹æ–¹é¢ï¼ŒåŸºäºè¡¨ç¤ºçš„æ–¹æ³•å¦‚å·®å¼‚å‡å€¼è¡¨ç°æœ€ä½³ã€‚ä½œè€…è¿˜æå‡ºäº†ä¸€ç§æ–°å‹çš„å¼±ç›‘ç£è¡¨ç¤ºæ–¹æ³•â€”â€”ReFT-r1ï¼Œåœ¨ä¸¤é¡¹ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºç«äº‰åŠ›ï¼ŒåŒæ—¶æä¾›äº†æç¤ºæ‰€ç¼ºä¹çš„å¯è§£é‡Šæ€§ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€æ¨¡å‹è¾“å‡ºçš„ç²¾ç»†æ§åˆ¶å¯¹äºå®‰å…¨å’Œå¯é æ€§è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚æç¤ºå’Œå¾®è°ƒè¢«å¹¿æ³›ç”¨äºå®ç°è¿™ä¸€ç›®æ ‡ã€‚</li>
<li>åŸºäºè¡¨ç¤ºçš„æŠ€æœ¯ï¼Œå¦‚ç¨€ç–è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSAEï¼‰å’Œçº¿æ€§äººå·¥æ–­å±‚æ‰«æä¹Ÿè¢«ç”¨äºæ§åˆ¶è¯­è¨€æ¨¡å‹è¾“å‡ºã€‚</li>
<li>ç›®å‰ç¼ºä¹ç›´æ¥æ¯”è¾ƒè¿™äº›æ–¹æ³•çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>å¼•å…¥AxBenchåŸºå‡†æµ‹è¯•ç”¨äºæ§åˆ¶å’Œæ¦‚å¿µæ£€æµ‹ã€‚</li>
<li>åœ¨å®éªŒè¯„ä¼°ä¸­ï¼Œæç¤ºåœ¨ç°æœ‰æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯å¾®è°ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17148">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0f4bd11a1c19faccfbf7aa2f5e086300.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-867354169710a72b5c66e2fa4783d5b7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TAID-Temporally-Adaptive-Interpolated-Distillation-for-Efficient-Knowledge-Transfer-in-Language-Models"><a href="#TAID-Temporally-Adaptive-Interpolated-Distillation-for-Efficient-Knowledge-Transfer-in-Language-Models" class="headerlink" title="TAID: Temporally Adaptive Interpolated Distillation for Efficient   Knowledge Transfer in Language Models"></a>TAID: Temporally Adaptive Interpolated Distillation for Efficient   Knowledge Transfer in Language Models</h2><p><strong>Authors:Makoto Shing, Kou Misaki, Han Bao, Sho Yokoi, Takuya Akiba</strong></p>
<p>Causal language models have demonstrated remarkable capabilities, but their size poses significant challenges for deployment in resource-constrained environments. Knowledge distillation, a widely-used technique for transferring knowledge from a large teacher model to a small student model, presents a promising approach for model compression. A significant remaining issue lies in the major differences between teacher and student models, namely the substantial capacity gap, mode averaging, and mode collapse, which pose barriers during distillation. To address these issues, we introduce $\textit{Temporally Adaptive Interpolated Distillation (TAID)}$, a novel knowledge distillation approach that dynamically interpolates student and teacher distributions through an adaptive intermediate distribution, gradually shifting from the studentâ€™s initial distribution towards the teacherâ€™s distribution. We provide a theoretical analysis demonstrating TAIDâ€™s ability to prevent mode collapse and empirically show its effectiveness in addressing the capacity gap while balancing mode averaging and mode collapse. Our comprehensive experiments demonstrate TAIDâ€™s superior performance across various model sizes and architectures in both instruction tuning and pre-training scenarios. Furthermore, we showcase TAIDâ€™s practical impact by developing two state-of-the-art compact foundation models: $\texttt{TAID-LLM-1.5B}$ for language tasks and $\texttt{TAID-VLM-2B}$ for vision-language tasks. These results demonstrate TAIDâ€™s effectiveness in creating high-performing and efficient models, advancing the development of more accessible AI technologies. </p>
<blockquote>
<p>å› æœè¯­è¨€æ¨¡å‹å·²ç»å±•ç°å‡ºæ˜¾è‘—çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬çš„è§„æ¨¡å¯¹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æŠ€æœ¯ï¼Œå¯ä»¥ä»å¤§å‹æ•™å¸ˆæ¨¡å‹è½¬ç§»åˆ°å°å‹å­¦ç”Ÿæ¨¡å‹ï¼Œè¿™ä¸ºæ¨¡å‹å‹ç¼©æä¾›äº†æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ä¸€ä¸ªä¸»è¦çš„å‰©ä½™é—®é¢˜åœ¨äºæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„å·¨å¤§å·®å¼‚ï¼Œå³æ˜¾è‘—çš„èƒ½åŠ›å·®è·ã€æ¨¡å¼å¹³å‡å’Œæ¨¡å¼å´©æºƒï¼Œè¿™äº›åœ¨è’¸é¦è¿‡ç¨‹ä¸­æ„æˆäº†éšœç¢ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€æ—¶é—´è‡ªé€‚åº”æ’å€¼è’¸é¦æ³•ï¼ˆTAIDï¼‰â€ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„çŸ¥è¯†è’¸é¦æ–¹æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”ä¸­é—´åˆ†å¸ƒåŠ¨æ€æ’å€¼å­¦ç”Ÿå’Œæ•™å¸ˆçš„åˆ†å¸ƒï¼Œä»å­¦ç”Ÿçš„åˆå§‹åˆ†å¸ƒé€æ¸è½¬å‘æ•™å¸ˆçš„åˆ†å¸ƒã€‚æˆ‘ä»¬æä¾›äº†ç†è®ºåˆ†æï¼Œè¯æ˜äº†TAIDåœ¨é˜²æ­¢æ¨¡å¼å´©æºƒæ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡ç»éªŒè¯æ˜äº†å®ƒåœ¨è§£å†³èƒ½åŠ›å·®è·ã€å¹³è¡¡æ¨¡å¼å¹³å‡å’Œæ¨¡å¼å´©æºƒæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTAIDåœ¨å„ç§æ¨¡å‹å’Œæ¶æ„çš„å¤§å°ã€æŒ‡ä»¤è°ƒæ•´å’Œé¢„è®­ç»ƒåœºæ™¯ä¸­å‡è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å¼€å‘ä¸¤ä¸ªæœ€å…ˆè¿›çš„ç´§å‡‘åŸºç¡€æ¨¡å‹ï¼šç”¨äºè¯­è¨€ä»»åŠ¡çš„â€TAID-LLM-1.5Bâ€å’Œç”¨äºè§†è§‰è¯­è¨€ä»»åŠ¡çš„â€TAID-VLM-2Bâ€ï¼Œå±•ç¤ºäº†TAIDçš„å®é™…å½±å“ã€‚è¿™äº›ç»“æœè¯æ˜äº†TAIDåœ¨åˆ›å»ºé«˜æ€§èƒ½å’Œé«˜æ•ˆæ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨äº†æ›´å¯è®¿é—®çš„AIæŠ€æœ¯çš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16937v2">PDF</a> To appear at the 13th International Conference on Learning   Representations (ICLR 2025)</p>
<p><strong>Summary</strong></p>
<p>çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§ä»å¤§æ¨¡å‹åˆ°å°æ¨¡å‹çš„è½¬ç§»çŸ¥è¯†æŠ€æœ¯ï¼Œä½†ä»å­˜åœ¨æ˜¾è‘—çš„é—®é¢˜ï¼Œä¾‹å¦‚æ•™å¸ˆä¸å­¦ç”Ÿæ¨¡å‹é—´å·¨å¤§çš„èƒ½åŠ›å·®è·ã€æ¨¡å¼å¹³å‡åŒ–å’Œæ¨¡å¼å´©æºƒã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ–°çš„çŸ¥è¯†è’¸é¦æ–¹æ³•â€”â€”æš‚æ—¶è‡ªé€‚åº”æ’å€¼è’¸é¦ï¼ˆTAIDï¼‰ï¼Œå®ƒé€šè¿‡è‡ªé€‚åº”ä¸­é—´åˆ†å¸ƒåŠ¨æ€æ’å€¼å­¦ç”Ÿå’Œæ•™å¸ˆçš„åˆ†å¸ƒï¼Œé€æ­¥ä»å­¦ç”Ÿåˆå§‹åˆ†å¸ƒè½¬å‘æ•™å¸ˆåˆ†å¸ƒã€‚æœ¬æ–‡ç†è®ºåˆ†æäº†TAIDé˜²æ­¢æ¨¡å¼å´©æºƒçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨è§£å†³èƒ½åŠ›å·®è·ã€å¹³è¡¡æ¨¡å¼å¹³å‡å’Œæ¨¡å¼å´©æºƒæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒTAIDè¿˜åœ¨å¤šç§æ¨¡å‹å’Œæ¶æ„çš„å¤§å°ã€é¢„è®­ç»ƒåœºæ™¯ä»¥åŠå¼€å‘ä¸¤ä¸ªç´§å‡‘åŸºç¡€æ¨¡å‹TAID-LLM-1.5Bå’ŒTAID-VLM-2Bä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¿™äº›æˆæœè¯æ˜äº†TAIDåœ¨åˆ›å»ºé«˜æ€§èƒ½ã€é«˜æ•ˆæ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨äº†æ›´æ™®åŠçš„AIæŠ€æœ¯çš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŸ¥è¯†è’¸é¦åœ¨æ¨¡å‹å‹ç¼©ä¸­å…·æœ‰æ½œåŠ›ï¼Œä½†é¢ä¸´æ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹é—´çš„èƒ½åŠ›å·®è·ã€æ¨¡å¼å¹³å‡åŒ–å’Œæ¨¡å¼å´©æºƒç­‰é—®é¢˜ã€‚</li>
<li>å¼•å…¥æ–°çš„çŸ¥è¯†è’¸é¦æ–¹æ³•â€”â€”æš‚æ—¶è‡ªé€‚åº”æ’å€¼è’¸é¦ï¼ˆTAIDï¼‰ï¼Œé€šè¿‡åŠ¨æ€æ’å€¼å­¦ç”Ÿå’Œæ•™å¸ˆçš„åˆ†å¸ƒæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>TAIDå…·æœ‰é˜²æ­¢æ¨¡å¼å´©æºƒçš„ç†è®ºåˆ†æèƒ½åŠ›ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨è§£å†³èƒ½åŠ›å·®è·æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>TAIDåœ¨å¤šç§æ¨¡å‹å’Œæ¶æ„ä¸­è¡¨ç°ä¼˜è¶Šï¼Œé€‚ç”¨äºæŒ‡ä»¤è°ƒä¼˜å’Œé¢„è®­ç»ƒåœºæ™¯ã€‚</li>
<li>å¼€å‘ä¸¤ä¸ªç´§å‡‘åŸºç¡€æ¨¡å‹TAID-LLM-1.5Bå’ŒTAID-VLM-2Bï¼Œä¸ºè¯­è¨€ä»»åŠ¡å’Œè§†è§‰è¯­è¨€ä»»åŠ¡æä¾›é«˜æ€§èƒ½è§£å†³æ–¹æ¡ˆã€‚</li>
<li>TAIDåˆ›é€ äº†é«˜æ•ˆæ¨¡å‹ï¼Œæ¨åŠ¨äº†AIæŠ€æœ¯çš„å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16937">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-67e8f2ff8c16e8a039f184c5170e52c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d19b6b370cd647f9e7364ec50c82a4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65bc89ef8169783c6875b2aeb18c91a1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Online-Prompt-Selection-for-Program-Synthesis"><a href="#Online-Prompt-Selection-for-Program-Synthesis" class="headerlink" title="Online Prompt Selection for Program Synthesis"></a>Online Prompt Selection for Program Synthesis</h2><p><strong>Authors:Yixuan Li, Lewis Frampton, Federico Mora, Elizabeth Polgreen</strong></p>
<p>Large Language Models (LLMs) demonstrate impressive capabilities in the domain of program synthesis. This level of performance is not, however, universal across all tasks, all LLMs and all prompting styles. There are many areas where one LLM dominates, one prompting style dominates, or where calling a symbolic solver is a better choice than an LLM. A key challenge for the user then, is to identify not only when an LLM is the right choice of solver, and the appropriate LLM to call for a given synthesis task, but also the right way to call it. A non-expert user who makes the wrong choice, incurs a cost both in terms of results (number of tasks solved, and the time it takes to solve them) and financial cost, if using a closed-source language model via a commercial API. We frame this choice as an online learning problem. We use a multi-armed bandit algorithm to select which symbolic solver, or LLM and prompt combination to deploy in order to maximize a given reward function (which may prioritize solving time, number of synthesis tasks solved, or financial cost of solving). We implement an instance of this approach, called CYANEA, and evaluate it on synthesis queries from the literature in ranking function synthesis, from the syntax-guided synthesis competition, and fresh, unseen queries generated from SMT problems. CYANEA solves 37.2% more queries than the best single solver and achieves results within 4% of the virtual best solver. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¨‹åºåˆæˆé¢†åŸŸå±•ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§è¡¨ç°å¹¶éåœ¨æ‰€æœ‰ä»»åŠ¡ã€æ‰€æœ‰LLMä»¥åŠæ‰€æœ‰æç¤ºé£æ ¼ä¸­éƒ½æ˜¯æ™®éçš„ã€‚åœ¨è®¸å¤šé¢†åŸŸï¼Œä¸€ä¸ªLLMä¼šå æ®ä¸»å¯¼ï¼Œä¸€ç§æç¤ºé£æ ¼ä¼šå æ®ä¸»å¯¼ï¼Œæˆ–è€…è°ƒç”¨ç¬¦å·æ±‚è§£å™¨æ˜¯ä¸€ä¸ªæ¯”LLMæ›´å¥½çš„é€‰æ‹©ã€‚å› æ­¤ï¼Œç”¨æˆ·é¢ä¸´çš„å…³é”®æŒ‘æˆ˜æ˜¯ï¼Œä¸ä»…è¦è¯†åˆ«ä½•æ—¶é€‰æ‹©LLMä½œä¸ºæ±‚è§£å™¨ä»¥åŠé’ˆå¯¹ç»™å®šçš„åˆæˆä»»åŠ¡è°ƒç”¨å“ªä¸ªLLMæ˜¯æ°å½“çš„ï¼Œè€Œä¸”è¿˜è¦ä»¥æ­£ç¡®çš„æ–¹å¼è°ƒç”¨å®ƒã€‚éä¸“å®¶ç”¨æˆ·å¦‚æœåšå‡ºäº†é”™è¯¯çš„é€‰æ‹©ï¼Œä¸ä»…ä¼šä»ç»“æœï¼ˆè§£å†³çš„ä»»åŠ¡æ•°é‡å’Œæ‰€éœ€çš„æ—¶é—´ï¼‰ä¸Šä»˜å‡ºä»£ä»·ï¼Œå¦‚æœä½¿ç”¨å•†ä¸šAPIçš„é—­æºè¯­è¨€æ¨¡å‹ï¼Œè¿˜ä¼šäº§ç”Ÿç»æµæˆæœ¬ã€‚æˆ‘ä»¬å°†è¿™ç§é€‰æ‹©æ¡†æ¶ä½œä¸ºä¸€ä¸ªåœ¨çº¿å­¦ä¹ é—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šè‡‚è€è™æœºç®—æ³•æ¥é€‰æ‹©è¦éƒ¨ç½²çš„ç¬¦å·æ±‚è§£å™¨æˆ–LLMå’Œæç¤ºç»„åˆï¼Œä»¥æœ€å¤§åŒ–ç»™å®šçš„å¥–åŠ±å‡½æ•°ï¼ˆå¯èƒ½ä¼˜å…ˆè€ƒè™‘è§£å†³æ—¶é—´ã€è§£å†³çš„ä»»åŠ¡æ•°é‡æˆ–è§£å†³çš„ç»æµæˆæœ¬ï¼‰ã€‚æˆ‘ä»¬å®ç°äº†è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªå®ä¾‹ï¼Œç§°ä¸ºCYANEAï¼Œå¹¶å¯¹å…¶åœ¨æ’åå‡½æ•°åˆæˆä¸­çš„åˆæˆæŸ¥è¯¢ã€è¯­æ³•æŒ‡å¯¼çš„åˆæˆç«èµ›ä»¥åŠæ¥è‡ªSMTé—®é¢˜çš„æ–°é²œæœªè§è¿‡çš„æŸ¥è¯¢è¿›è¡Œäº†è¯„ä¼°ã€‚CYANEAæ¯”æœ€ä½³å•ä¸€æ±‚è§£å™¨è§£å†³äº†37.2%ä»¥ä¸Šçš„æŸ¥è¯¢ï¼Œå¹¶å–å¾—äº†ä¸è™šæ‹Ÿæœ€ä½³æ±‚è§£å™¨ç›¸å·®4%çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05247v2">PDF</a> Accepted at the 39th AAAI Conference on Artificial Intelligence   (AAAI-25) Main Track</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¨‹åºåˆæˆé¢†åŸŸè¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†å…¶æ€§èƒ½å¹¶éæ™®éé€‚ç”¨äºæ‰€æœ‰ä»»åŠ¡ã€æ‰€æœ‰LLMå’Œæ‰€æœ‰æç¤ºé£æ ¼ã€‚å…³é”®æŒ‘æˆ˜åœ¨äºç”¨æˆ·éœ€è¦è¯†åˆ«ä½•æ—¶ä½¿ç”¨LLMä½œä¸ºæ±‚è§£å™¨æ˜¯æœ€ä½³é€‰æ‹©ï¼Œä»¥åŠå¦‚ä½•æ­£ç¡®è°ƒç”¨é€‚å½“çš„LLMæ¥å®Œæˆç»™å®šçš„åˆæˆä»»åŠ¡ã€‚æˆ‘ä»¬å°†å…¶é€‰æ‹©ä½œä¸ºä¸€ä¸ªåœ¨çº¿å­¦ä¹ é—®é¢˜ï¼Œå¹¶ä½¿ç”¨å¤šè‡‚è€è™æœºç®—æ³•æ¥é€‰æ‹©éƒ¨ç½²å“ªç§ç¬¦å·æ±‚è§£å™¨æˆ–LLMå’Œæç¤ºç»„åˆï¼Œä»¥æœ€å¤§åŒ–ç»™å®šçš„å¥–åŠ±å‡½æ•°ã€‚æˆ‘ä»¬å®æ–½äº†ä¸€ç§ç§°ä¸ºCYANEAçš„æ–¹æ³•ï¼Œå¹¶åœ¨æ’åå‡½æ•°åˆæˆã€è¯­æ³•æŒ‡å¯¼åˆæˆç«èµ›ä»¥åŠç”±SMTé—®é¢˜ç”Ÿæˆçš„æ–°é²œæœªè§æŸ¥è¯¢ä¸Šå¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ã€‚CYANEAæ¯”æœ€ä½³å•ä¸€æ±‚è§£å™¨è§£å†³äº†æ›´å¤šçš„æŸ¥è¯¢é—®é¢˜ï¼Œå¹¶å–å¾—äº†æ¥è¿‘è™šæ‹Ÿæœ€ä½³æ±‚è§£å™¨çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMåœ¨ç¨‹åºåˆæˆé¢†åŸŸå…·æœ‰æ˜¾è‘—èƒ½åŠ›ï¼Œä½†æ€§èƒ½å› ä»»åŠ¡ã€LLMå’Œæç¤ºé£æ ¼è€Œå¼‚ã€‚</li>
<li>ç”¨æˆ·é¢ä¸´çš„æŒ‘æˆ˜æ˜¯è¯†åˆ«ä½•æ—¶ä»¥åŠå¦‚ä½•ä½¿ç”¨LLMè¿›è¡Œæœ€ä½³æ±‚è§£ã€‚</li>
<li>å°†æ­¤é€‰æ‹©è§†ä¸ºåœ¨çº¿å­¦ä¹ é—®é¢˜ï¼Œä½¿ç”¨å¤šè‡‚è€è™æœºç®—æ³•è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>CYANEAæ–¹æ³•å®æ–½ç”¨äºé€‰æ‹©é€‚å½“çš„æ±‚è§£å™¨æˆ–LLMåŠæç¤ºç»„åˆã€‚</li>
<li>CYANEAåœ¨å¤šä¸ªè¯„ä¼°ä¸­è¡¨ç°å‡ºä¼˜äºå•ä¸€æ±‚è§£å™¨çš„æ€§èƒ½ï¼Œæ¥è¿‘è™šæ‹Ÿæœ€ä½³æ±‚è§£å™¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05247">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ebf0aa281d9db16cb4cd25ba026a9b45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-926b0a4c0eb84adae1f6b0b690265944.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07e5ab2ad110d0ff87a298ea14fa8ed3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b644b64cefde02e61f0d474c29de8c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b8788e1f9c52b477f9dce3e2f7131be1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Planning-Anything-with-Rigor-General-Purpose-Zero-Shot-Planning-with-LLM-based-Formalized-Programming"><a href="#Planning-Anything-with-Rigor-General-Purpose-Zero-Shot-Planning-with-LLM-based-Formalized-Programming" class="headerlink" title="Planning Anything with Rigor: General-Purpose Zero-Shot Planning with   LLM-based Formalized Programming"></a>Planning Anything with Rigor: General-Purpose Zero-Shot Planning with   LLM-based Formalized Programming</h2><p><strong>Authors:Yilun Hao, Yang Zhang, Chuchu Fan</strong></p>
<p>While large language models (LLMs) have recently demonstrated strong potential in solving planning problems, there is a trade-off between flexibility and complexity. LLMs, as zero-shot planners themselves, are still not capable of directly generating valid plans for complex planning problems such as multi-constraint or long-horizon tasks. On the other hand, many frameworks aiming to solve complex planning problems often rely on task-specific preparatory efforts, such as task-specific in-context examples and pre-defined critics&#x2F;verifiers, which limits their cross-task generalization capability. In this paper, we tackle these challenges by observing that the core of many planning problems lies in optimization problems: searching for the optimal solution (best plan) with goals subject to constraints (preconditions and effects of decisions). With LLMsâ€™ commonsense, reasoning, and programming capabilities, this opens up the possibilities of a universal LLM-based approach to planning problems. Inspired by this observation, we propose LLMFP, a general-purpose framework that leverages LLMs to capture key information from planning problems and formally formulate and solve them as optimization problems from scratch, with no task-specific examples needed. We apply LLMFP to 9 planning problems, ranging from multi-constraint decision making to multi-step planning problems, and demonstrate that LLMFP achieves on average 83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet, significantly outperforming the best baseline (direct planning with OpenAI o1-preview) with 37.6% and 40.7% improvements. We also validate components of LLMFP with ablation experiments and analyzed the underlying success and failure reasons. Project page: <a target="_blank" rel="noopener" href="https://sites.google.com/view/llmfp">https://sites.google.com/view/llmfp</a>. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€è¿‘åœ¨è§£å†³è§„åˆ’é—®é¢˜æ–¹é¢å±•ç°å‡ºäº†å¼ºå¤§çš„æ½œåŠ›ï¼Œä½†åœ¨çµæ´»æ€§å’Œå¤æ‚æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚ä½œä¸ºé›¶å¯åŠ¨è§„åˆ’è€…æœ¬èº«ï¼ŒLLMä»ç„¶æ— æ³•ç›´æ¥ä¸ºå¤æ‚çš„è§„åˆ’é—®é¢˜ï¼ˆå¦‚å¤šçº¦æŸæˆ–é•¿æœŸä»»åŠ¡ï¼‰ç”Ÿæˆæœ‰æ•ˆçš„è®¡åˆ’ã€‚å¦ä¸€æ–¹é¢ï¼Œè®¸å¤šæ—¨åœ¨è§£å†³å¤æ‚è§„åˆ’é—®é¢˜çš„æ¡†æ¶é€šå¸¸ä¾èµ–äºç‰¹å®šä»»åŠ¡çš„å‡†å¤‡æ€§å·¥ä½œï¼Œä¾‹å¦‚ç‰¹å®šäºä»»åŠ¡çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹å’Œé¢„å…ˆå®šä¹‰çš„è¯„è®ºå®¶&#x2F;éªŒè¯å™¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è§‚å¯Ÿè®¸å¤šè§„åˆ’é—®é¢˜çš„æ ¸å¿ƒåœ¨äºä¼˜åŒ–é—®é¢˜æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼šåœ¨ç›®æ ‡å—åˆ°çº¦æŸï¼ˆå†³ç­–çš„å…ˆå†³æ¡ä»¶å’Œå½±å“ï¼‰çš„æƒ…å†µä¸‹æœç´¢æœ€ä¼˜è§£ï¼ˆæœ€ä½³è®¡åˆ’ï¼‰ã€‚åˆ©ç”¨LLMçš„å¸¸è¯†ã€æ¨ç†å’Œç¼–ç¨‹èƒ½åŠ›ï¼Œè¿™ä¸ºåŸºäºLLMçš„é€šç”¨è§„åˆ’æ–¹æ³•æ‰“å¼€äº†å¯èƒ½æ€§ã€‚å—æ­¤è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†LLMFPï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨LLMä»è§„åˆ’é—®é¢˜ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶æ­£å¼åˆ¶å®šä¸ºä¼˜åŒ–é—®é¢˜å¹¶è§£å†³ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡çš„ç¤ºä¾‹ã€‚æˆ‘ä»¬å°†LLMFPåº”ç”¨äº9ä¸ªè§„åˆ’é—®é¢˜ï¼Œä»å¤šçº¦æŸå†³ç­–åˆ¶å®šåˆ°å¤šæ­¥éª¤è§„åˆ’é—®é¢˜ï¼Œå¹¶è¯æ˜LLMFPåœ¨GPT-4oå’ŒClaude 3.5 Sonnetä¸Šå¹³å‡è¾¾åˆ°äº†83.7%å’Œ86.8%çš„æœ€ä¼˜ç‡ï¼Œæ˜¾è‘—ä¼˜äºæœ€ä½³åŸºçº¿ï¼ˆä½¿ç”¨OpenAI o1-previewçš„ç›´æ¥è§„åˆ’æ–¹æ³•ï¼‰ï¼Œæé«˜äº†37.6%å’Œ40.7%ã€‚æˆ‘ä»¬è¿˜é€šè¿‡æ¶ˆèå®éªŒéªŒè¯äº†LLMFPçš„ç»„ä»¶ï¼Œå¹¶åˆ†æäº†å…¶æˆåŠŸå’Œå¤±è´¥çš„æ ¹æœ¬åŸå› ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/llmfp%E3%80%82">https://sites.google.com/view/llmfpã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.12112v2">PDF</a> 57 pages, 25 figures, 15 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§£å†³è§„åˆ’é—®é¢˜ä¸Šå±•ç°äº†æ½œåŠ›ï¼Œä½†åœ¨çµæ´»æ€§ä¸å¤æ‚æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚LLMä½œä¸ºé›¶è§„åˆ’è€…ï¼Œå°šä¸èƒ½ç›´æ¥ä¸ºå¤æ‚è§„åˆ’é—®é¢˜ç”Ÿæˆæœ‰æ•ˆæ–¹æ¡ˆã€‚ç°æœ‰æ¡†æ¶å¸¸ä¾èµ–ç‰¹å®šä»»åŠ¡çš„é¢„å¤‡å·¥ä½œï¼Œé™åˆ¶äº†è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚æœ¬ç ”ç©¶è§‚å¯Ÿåˆ°è§„åˆ’é—®é¢˜çš„æ ¸å¿ƒåœ¨äºä¼˜åŒ–é—®é¢˜ï¼Œå¹¶æå‡ºLLMFPæ¡†æ¶ï¼Œåˆ©ç”¨LLMæ•æ‰è§„åˆ’é—®é¢˜çš„å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶å½¢å¼åŒ–ä¸ºä¼˜åŒ–é—®é¢˜ã€‚åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒLLMFPæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨è§£å†³è§„åˆ’é—®é¢˜æ—¶å­˜åœ¨çµæ´»æ€§ä¸å¤æ‚æ€§ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>LLMå°šä¸èƒ½ç›´æ¥ç”Ÿæˆå¤æ‚è§„åˆ’é—®é¢˜çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰æ¡†æ¶è§£å†³å¤æ‚è§„åˆ’é—®é¢˜å¸¸ä¾èµ–ä»»åŠ¡ç‰¹å®šé¢„å¤‡å·¥ä½œï¼Œé™åˆ¶äº†å…¶è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è§„åˆ’é—®é¢˜çš„æ ¸å¿ƒåœ¨äºå¯»æ‰¾æ»¡è¶³çº¦æŸçš„æœ€ä¼˜è§£å†³æ–¹æ¡ˆã€‚</li>
<li>LLMFPæ¡†æ¶åˆ©ç”¨LLMçš„å¸¸è¯†ã€æ¨ç†å’Œç¼–ç¨‹èƒ½åŠ›ï¼Œä»¥é€šç”¨æ–¹å¼è§£å†³è§„åˆ’é—®é¢˜ã€‚</li>
<li>LLMFPåœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„å®éªŒè¡¨ç°ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>LLMFPçš„æˆåŠŸä¸å¤±è´¥åŸå› å¾—åˆ°äº†å®éªŒéªŒè¯å’Œåˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.12112">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d0b7f0a26b569ed599b86d26357bbec5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4203b4f39d4e4fdeb98331ef7d3f8b87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cde2dc88f73f44617ade54956f161167.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="ATTNChecker-Highly-Optimized-Fault-Tolerant-Attention-for-Large-Language-Model-Training"><a href="#ATTNChecker-Highly-Optimized-Fault-Tolerant-Attention-for-Large-Language-Model-Training" class="headerlink" title="ATTNChecker: Highly-Optimized Fault Tolerant Attention for Large   Language Model Training"></a>ATTNChecker: Highly-Optimized Fault Tolerant Attention for Large   Language Model Training</h2><p><strong>Authors:Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable performance in various natural language processing tasks. However, the training of these models is computationally intensive and susceptible to faults, particularly in the attention mechanism, which is a critical component of transformer-based LLMs. In this paper, we investigate the impact of faults on LLM training, focusing on INF, NaN, and near-INF values in the computation results with systematic fault injection experiments. We observe the propagation patterns of these errors, which can trigger non-trainable states in the model and disrupt training, forcing the procedure to load from checkpoints. To mitigate the impact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault Tolerance (ABFT) technique tailored for the attention mechanism in LLMs. ATTNChecker is designed based on fault propagation patterns of LLM and incorporates performance optimization to adapt to both system reliability and model vulnerability while providing lightweight protection for fast LLM training. Evaluations on four LLMs show that ATTNChecker incurs on average 7% overhead on training while detecting and correcting all extreme errors. Compared with the state-of-the-art checkpoint&#x2F;restore approach, ATTNChecker reduces recovery overhead by up to 49x. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„è®­ç»ƒè®¡ç®—å¯†é›†ä¸”å®¹æ˜“å‡ºé”™ï¼Œç‰¹åˆ«æ˜¯åœ¨åŸºäºè½¬æ¢å™¨çš„LLMä¸­èµ·åˆ°å…³é”®ä½œç”¨çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ•…éšœå¯¹LLMè®­ç»ƒçš„å½±å“ï¼Œé‡ç‚¹å…³æ³¨è®¡ç®—ç»“æœä¸­çš„æ— ç©·å¤§ï¼ˆINFï¼‰ã€éæ•°å­—ï¼ˆNaNï¼‰å’Œæ¥è¿‘æ— ç©·å¤§çš„å€¼ï¼Œå¹¶é€šè¿‡ç³»ç»Ÿçš„æ•…éšœæ³¨å…¥å®éªŒè¿›è¡Œç ”ç©¶ã€‚æˆ‘ä»¬è§‚å¯Ÿäº†è¿™äº›é”™è¯¯çš„ä¼ æ’­æ¨¡å¼ï¼Œè¿™äº›é”™è¯¯å¯èƒ½ä¼šè§¦å‘æ¨¡å‹ä¸­çš„ä¸å¯è®­ç»ƒçŠ¶æ€å¹¶ä¸­æ–­è®­ç»ƒï¼Œè¿«ä½¿ç¨‹åºä»æ£€æŸ¥ç‚¹åŠ è½½ã€‚ä¸ºäº†å‡è½»è¿™äº›æ•…éšœçš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†ATTNCheckerï¼Œè¿™æ˜¯ç¬¬ä¸€ç§é’ˆå¯¹LLMä¸­æ³¨æ„åŠ›æœºåˆ¶çš„åŸºäºç®—æ³•çš„å®¹é”™ï¼ˆABFTï¼‰æŠ€æœ¯ã€‚ATTNCheckerçš„è®¾è®¡åŸºäºLLMçš„æ•…éšœä¼ æ’­æ¨¡å¼ï¼Œå¹¶èå…¥äº†æ€§èƒ½ä¼˜åŒ–ï¼Œä»¥é€‚åº”ç³»ç»Ÿå¯é æ€§å’Œæ¨¡å‹è„†å¼±æ€§ï¼ŒåŒæ—¶ä¸ºå¿«é€ŸLLMè®­ç»ƒæä¾›è½»é‡çº§ä¿æŠ¤ã€‚å¯¹å››ç§LLMçš„è¯„ä¼°è¡¨æ˜ï¼ŒATTNCheckeråœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¹³å‡å¼€é”€ä¸º7%ï¼ŒåŒæ—¶èƒ½å¤Ÿæ£€æµ‹å’Œçº æ­£æ‰€æœ‰æç«¯é”™è¯¯ã€‚ä¸æœ€æ–°çš„æ£€æŸ¥ç‚¹&#x2F;æ¢å¤æ–¹æ³•ç›¸æ¯”ï¼ŒATTNCheckerå°†æ¢å¤å¼€é”€å‡å°‘äº†é«˜è¾¾49å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11720v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å…¶è®­ç»ƒè®¡ç®—é‡å¤§ä¸”æ˜“å‡ºé”™ï¼Œç‰¹åˆ«æ˜¯åŸºäºtransformerçš„LLMä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚æœ¬æ–‡é€šè¿‡æ•…éšœæ³¨å…¥å®éªŒç ”ç©¶äº†æ•…éšœå¯¹LLMè®­ç»ƒçš„å½±å“ï¼Œå¹¶è§‚å¯Ÿåˆ°é”™è¯¯ä¼ æ’­æ¨¡å¼å¯èƒ½å¯¼è‡´æ¨¡å‹ä¸å¯è®­ç»ƒçŠ¶æ€å¹¶ä¸­æ–­è®­ç»ƒã€‚ä¸ºç¼“è§£è¿™äº›æ•…éšœçš„å½±å“ï¼Œæœ¬æ–‡æå‡ºäº†é’ˆå¯¹LLMæ³¨æ„åŠ›æœºåˆ¶çš„ç®—æ³•çº§å®¹é”™æŠ€æœ¯ATTNCheckerã€‚ATTNCheckeræ ¹æ®LLMçš„æ•…éšœä¼ æ’­æ¨¡å¼è®¾è®¡ï¼Œèå…¥äº†æ€§èƒ½ä¼˜åŒ–ä»¥é€‚åº”ç³»ç»Ÿå¯é æ€§å’Œæ¨¡å‹è„†å¼±æ€§ï¼ŒåŒæ—¶ä¸ºå¿«é€ŸLLMè®­ç»ƒæä¾›è½»é‡çº§ä¿æŠ¤ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒATTNCheckerå¹³å‡è®­ç»ƒå¼€é”€ä¸º7%ï¼Œå¯æ£€æµ‹å¹¶ä¿®æ­£æ‰€æœ‰æç«¯é”™è¯¯ã€‚ç›¸è¾ƒäºå½“å‰å…ˆè¿›çš„æ£€æŸ¥ç‚¹æ¢å¤æ–¹æ³•ï¼ŒATTNCheckeræ¢å¤å¼€é”€é™ä½äº†é«˜è¾¾49å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å…·æœ‰å‡ºè‰²è¡¨ç°ï¼Œä½†å…¶è®­ç»ƒè®¡ç®—é‡å¤§ä¸”å­˜åœ¨æ˜“é”™ç‚¹ï¼Œç‰¹åˆ«æ˜¯åœ¨æ³¨æ„åŠ›æœºåˆ¶æ–¹é¢ã€‚</li>
<li>æ•…éšœæ³¨å…¥å®éªŒç”¨äºç ”ç©¶æ•…éšœå¯¹LLMè®­ç»ƒçš„å½±å“ï¼Œæ­ç¤ºäº†é”™è¯¯ä¼ æ’­æ¨¡å¼å¯èƒ½å¯¼è‡´æ¨¡å‹è¿›å…¥ä¸å¯è®­ç»ƒçŠ¶æ€ã€‚</li>
<li>ATTNCheckeræ˜¯é¦–ä¸ªé’ˆå¯¹LLMæ³¨æ„åŠ›æœºåˆ¶çš„ç®—æ³•çº§å®¹é”™æŠ€æœ¯ï¼Œæ—¨åœ¨å‡è½»æ•…éšœå¯¹è®­ç»ƒçš„å½±å“ã€‚</li>
<li>ATTNCç¦CKERåŸºäºLLMçš„æ•…éšœä¼ æ’­æ¨¡å¼è®¾è®¡ï¼Œèåˆäº†æ€§èƒ½ä¼˜åŒ–ä»¥é€‚åº”ç³»ç»Ÿå¯é æ€§å’Œæ¨¡å‹è„†å¼±æ€§ã€‚</li>
<li>ATTNCç¦CKERæä¾›äº†è½»é‡çº§çš„ä¿æŠ¤ï¼Œä»¥ç¡®ä¿å¿«é€ŸLLMè®­ç»ƒã€‚</li>
<li>è¯„ä¼°æ˜¾ç¤ºï¼ŒATTNCheckeråœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¹³å‡å¼€é”€ä¸º7%ï¼Œå¹¶èƒ½æœ‰æ•ˆæ£€æµ‹åŠä¿®æ­£æ‰€æœ‰æç«¯é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-56d961e8cdd081e3cdd7739086eeb59a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2eefce84363c239d8e6eac3d037cd4aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f57e62ea90b9d63edd7c3df2bd679f34.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-899c1f7b0f51210def275e2cffe56f3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f3c1eb1925551b78084a8a9c44b6c50.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fecdd928d97b0e62c33c1292a1afaf25.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Large-Language-Models-Can-Solve-Real-World-Planning-Rigorously-with-Formal-Verification-Tools"><a href="#Large-Language-Models-Can-Solve-Real-World-Planning-Rigorously-with-Formal-Verification-Tools" class="headerlink" title="Large Language Models Can Solve Real-World Planning Rigorously with   Formal Verification Tools"></a>Large Language Models Can Solve Real-World Planning Rigorously with   Formal Verification Tools</h2><p><strong>Authors:Yilun Hao, Yongchao Chen, Yang Zhang, Chuchu Fan</strong></p>
<p>Large Language Models (LLMs) struggle to directly generate correct plans for complex multi-constraint planning problems, even with self-verification and self-critique. For example, a U.S. domestic travel planning benchmark TravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI o1-preview can only find viable travel plans with a 10% success rate given all needed information. In this work, we tackle this by proposing an LLM-based planning framework that formalizes and solves complex multi-constraint planning problems as constrained satisfiability problems, which are further consumed by sound and complete satisfiability solvers. We start with TravelPlanner as the primary use case and show that our framework achieves a success rate of 93.9% and is effective with diverse paraphrased prompts. More importantly, our framework has strong zero-shot generalizability, successfully handling unseen constraints in our newly created unseen international travel dataset and generalizing well to new fundamentally different domains. Moreover, when user input queries are infeasible, our framework can identify the unsatisfiable core, provide failure reasons, and offers personalized modification suggestions. We show that our framework can modify and solve for an average of 81.6% and 91.7% unsatisfiable queries from two datasets and prove with ablations that all key components of our framework are effective and necessary. Project page: <a target="_blank" rel="noopener" href="https://sites.google.com/view/llm-rwplanning">https://sites.google.com/view/llm-rwplanning</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§£å†³å¤æ‚çš„ã€å…·æœ‰å¤šé‡çº¦æŸçš„è§„åˆ’é—®é¢˜æ—¶ï¼Œå³ä½¿åœ¨å…·å¤‡è‡ªæˆ‘éªŒè¯å’Œè‡ªæ‰¹èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œä¹Ÿéš¾ä»¥ç›´æ¥ç”Ÿæˆæ­£ç¡®çš„è§„åˆ’æ–¹æ¡ˆã€‚ä¾‹å¦‚ï¼Œåœ¨è°¢ç­‰äººæå‡ºçš„ç¾å›½å›½å†…æ—…è¡Œè§„åˆ’åŸºå‡†æµ‹è¯•TravelPlannerä¸­ï¼ˆXie et al., 2024ï¼‰ï¼Œå³ä½¿æä¾›æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Œæœ€ä½³LLM OpenAI o1-previewä¹Ÿåªèƒ½ä»¥10%çš„æˆåŠŸç‡æ‰¾åˆ°å¯è¡Œçš„æ—…è¡Œè®¡åˆ’ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºä¸€ä¸ªåŸºäºLLMçš„è§„åˆ’æ¡†æ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¯¥æ¡†æ¶å°†å¤æ‚çš„ã€å…·æœ‰å¤šé‡çº¦æŸçš„è§„åˆ’é—®é¢˜å½¢å¼åŒ–ä¸ºçº¦æŸå¯æ»¡è¶³æ€§é—®é¢˜ï¼Œå¹¶è¿›ä¸€æ­¥é€šè¿‡å¥å…¨å’Œå®Œæ•´çš„å¯æ»¡è¶³æ€§æ±‚è§£å™¨è¿›è¡Œæ±‚è§£ã€‚æˆ‘ä»¬ä»¥TravelPlannerä½œä¸ºä¸»è¦ç”¨ä¾‹è¿›è¡Œå±•ç¤ºï¼Œè¯æ˜æˆ‘ä»¬çš„æ¡†æ¶æˆåŠŸç‡è¾¾åˆ°äº†93.9%ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„åŒä¹‰æ¢è¯æç¤ºä¸‹å–å¾—äº†è‰¯å¥½æ•ˆæœã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å…·æœ‰è¾ƒå¼ºçš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤ŸæˆåŠŸå¤„ç†æˆ‘ä»¬æ–°åˆ›å»ºçš„æœªè§å›½é™…æ—…è¡Œæ•°æ®é›†ä¸­æ‰€åŒ…å«çš„æ–°å¢æœªè§çº¦æŸï¼Œå¹¶åœ¨æ–°çš„æ ¹æœ¬ä¸åŒé¢†åŸŸè¿›è¡Œè‰¯å¥½çš„æ³›åŒ–ã€‚æ­¤å¤–ï¼Œå½“ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ä¸å¯è¡Œæ—¶ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥è¯†åˆ«å‡ºä¸æ»¡è¶³è¦æ±‚çš„æ ¸å¿ƒéƒ¨åˆ†ã€æä¾›å¤±è´¥åŸå› ä»¥åŠä¸ªæ€§åŒ–çš„ä¿®æ”¹å»ºè®®ã€‚æˆ‘ä»¬å±•ç¤ºï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥å¯¹ä¸¤ä¸ªæ•°æ®é›†çš„ä¸å¯æ»¡è¶³æŸ¥è¯¢è¿›è¡Œå¹³å‡è¾¾åˆ°81.6%å’Œ91.7%çš„ä¿®æ”¹å¹¶è§£å†³ï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒè¯æ˜æˆ‘ä»¬æ¡†æ¶çš„æ‰€æœ‰å…³é”®ç»„æˆéƒ¨åˆ†éƒ½æ˜¯æœ‰æ•ˆä¸”å¿…è¦çš„ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/llm-rwplanning%E3%80%82">https://sites.google.com/view/llm-rwplanningã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.11891v3">PDF</a> 50 pages, 6 figures, 8 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†å¤æ‚çš„å¸¦æœ‰å¤šç§çº¦æŸçš„è§„åˆ’é—®é¢˜æ—¶ï¼Œå³ä¾¿å…·å¤‡è‡ªæˆ‘éªŒè¯ä¸è‡ªæˆ‘æ‰¹åˆ¤çš„èƒ½åŠ›ï¼Œä»éš¾ä»¥ç›´æ¥ç”Ÿæˆæ­£ç¡®çš„è®¡åˆ’ã€‚ä¾‹å¦‚ï¼Œåœ¨Xieç­‰äººæå‡ºçš„TravelPlannerç¾å›½å›½å†…æ—…è¡Œè§„åˆ’åŸºå‡†æµ‹è¯•ä¸­ï¼Œæœ€ä½³LLM OpenAI o1-previewå³ä½¿è·å¾—æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Œä¹Ÿåªèƒ½ä»¥10%çš„æˆåŠŸç‡æ‰¾åˆ°å¯è¡Œçš„æ—…è¡Œè®¡åˆ’ã€‚æœ¬ç ”ç©¶é€šè¿‡æå‡ºä¸€ä¸ªåŸºäºLLMçš„è§„åˆ’æ¡†æ¶æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥æ¡†æ¶å°†å¤æ‚çš„å¸¦æœ‰å¤šç§çº¦æŸçš„è§„åˆ’é—®é¢˜å½¢å¼åŒ–ä¸ºçº¦æŸå¯æ»¡è¶³æ€§é—®é¢˜ï¼Œå¹¶ä½¿ç”¨å¥å…¨ä¸”å®Œæ•´çš„å¯æ»¡è¶³æ€§æ±‚è§£å™¨æ¥è§£å†³ã€‚ä»¥TravelPlannerä¸ºä¸»è¦ç”¨ä¾‹ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æˆåŠŸç‡ä¸º93.9%ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„æ”¹è¿°æç¤ºä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å…·æœ‰å¾ˆå¼ºçš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤ŸæˆåŠŸå¤„ç†æˆ‘ä»¬æ–°åˆ›å»ºçš„æ— çº¦æŸå›½é™…æ—…è¡Œæ•°æ®é›†ï¼Œå¹¶åœ¨å…¨æ–°ä¸”æ ¹æœ¬ä¸åŒçš„é¢†åŸŸå®ç°è‰¯å¥½çš„æ³›åŒ–ã€‚æ­¤å¤–ï¼Œåœ¨ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ä¸å¯è¡Œæ—¶ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥è¯†åˆ«å‡ºä¸æ»¡è¶³æ ¸å¿ƒæ¡ä»¶çš„åŸå› ï¼Œå¹¶æä¾›ä¸ªæ€§åŒ–çš„ä¿®æ”¹å»ºè®®ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¹³å‡å¯ä»¥è§£å†³81.6%å’Œ91.7%çš„æ¥è‡ªä¸¤ä¸ªæ•°æ®é›†çš„ä¸æ»¡è¶³è¦æ±‚çš„æŸ¥è¯¢ï¼Œå¹¶é€šè¿‡åˆ†æè¯æ˜æ¡†æ¶çš„æ‰€æœ‰å…³é”®ç»„æˆéƒ¨åˆ†éƒ½æ˜¯æœ‰æ•ˆä¸”å¿…è¦çš„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨å¤„ç†å¤æ‚çš„å¤šçº¦æŸè§„åˆ’é—®é¢˜æ—¶å­˜åœ¨å›°éš¾ï¼Œç›´æ¥ç”Ÿæˆæ­£ç¡®è®¡åˆ’çš„æˆåŠŸç‡è¾ƒä½ã€‚</li>
<li>æå‡ºä¸€ä¸ªåŸºäºLLMçš„è§„åˆ’æ¡†æ¶ï¼Œå°†å¤æ‚çš„å¤šçº¦æŸè§„åˆ’é—®é¢˜å½¢å¼åŒ–ä¸ºçº¦æŸå¯æ»¡è¶³æ€§é—®é¢˜å¹¶æ±‚è§£ã€‚</li>
<li>ä»¥TravelPlannerä¸ºä¸»è¦ç”¨ä¾‹ï¼Œæ¡†æ¶æˆåŠŸç‡é«˜ï¼Œå¹¶è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ¡†æ¶å…·å¤‡é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå¯å¤„ç†æœªè§è¿‡çš„å›½é™…æ—…è¡Œæ•°æ®é›†ã€‚</li>
<li>å½“ç”¨æˆ·æŸ¥è¯¢ä¸å¯è¡Œæ—¶ï¼Œæ¡†æ¶èƒ½è¯†åˆ«æ ¸å¿ƒé—®é¢˜å¹¶æä¾›ä¿®æ”¹å»ºè®®ã€‚</li>
<li>æ¡†æ¶å¯¹ä¸æ»¡è¶³è¦æ±‚çš„æŸ¥è¯¢å…·æœ‰è¾ƒé«˜çš„è§£å†³ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.11891">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5f996bfbd428a5dfe1ef7d03f7414faf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6929c5740a12dc68b6973921b49634ab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ccd2e78238256e079dedbc89e9f248ac.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-31/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-31/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-31/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-40fd698afd250054ea2b435a592027fa.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-31  Actions Speak Louder than Words Agent Decisions Reveal Implicit Biases   in Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-31
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e9431ea423467aa86ee279c2aa5c72f7.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-30  PackDiT Joint Human Motion and Text Generation via Mutual Prompting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">15444.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
