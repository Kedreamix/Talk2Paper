<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM 方向最新论文已更新，请持续关注 Update in 2025-01-05  RLAIF-V Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-7ed0c5e2f414879892079cedd6e44bb8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    31 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-05-更新"><a href="#2025-01-05-更新" class="headerlink" title="2025-01-05 更新"></a>2025-01-05 更新</h1><h2 id="RLAIF-V-Open-Source-AI-Feedback-Leads-to-Super-GPT-4V-Trustworthiness"><a href="#RLAIF-V-Open-Source-AI-Feedback-Leads-to-Super-GPT-4V-Trustworthiness" class="headerlink" title="RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness"></a>RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness</h2><p><strong>Authors:Tianyu Yu, Haoye Zhang, Qiming Li, Qixin Xu, Yuan Yao, Da Chen, Xiaoman Lu, Ganqu Cui, Yunkai Dang, Taiwen He, Xiaocheng Feng, Jun Song, Bo Zheng, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun</strong></p>
<p>Traditional feedback learning for hallucination reduction relies on labor-intensive manual labeling or expensive proprietary models. This leaves the community without foundational knowledge about how to build high-quality feedback with open-source MLLMs. In this work, we introduce RLAIF-V, a novel framework that aligns MLLMs in a fully open-source paradigm. RLAIF-V maximally explores open-source MLLMs from two perspectives, including high-quality feedback data generation for preference learning and self-feedback guidance for inference-time scaling. Extensive experiments on six benchmarks in both automatic and human evaluation show that RLAIF-V substantially enhances the trustworthiness of models at both preference learning and inference time. RLAIF-V 7B reduces object hallucination by 80.7% and overall hallucination by 33.7%. Remarkably, RLAIF-V 12B further reveals the self-alignment potential of open-source MLLMs, where the model can learn from feedback of itself to achieve super GPT-4V trustworthiness. </p>
<blockquote>
<p>传统的反馈学习在减少幻觉方面依赖于劳动密集的手动标注或昂贵的专有模型。这导致社区缺乏关于如何使用开源MLLM构建高质量反馈的基础知识。在这项工作中，我们介绍了RLAIF-V，这是一个全新的框架，它以完全开源的方式对齐MLLM。RLAIF-V从两个角度最大限度地挖掘开源MLLM的潜力，包括用于偏好学习的高质量反馈数据生成和用于推理时间缩放时的自我反馈指导。在六个基准测试上的自动和人类评估实验表明，RLAIF-V在偏好学习和推理时间两个方面都极大地提高了模型的可靠性。RLAIF-V 7B减少了物体幻觉达80.7%，总体幻觉减少了33.7%。值得注意的是，RLAIF-V 12B进一步揭示了开源MLLM的自我对齐潜力，模型可以从其自身的反馈中学习，达到超越GPT-4V的可信度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17220v2">PDF</a> Project Website: <a target="_blank" rel="noopener" href="https://github.com/RLHF-V/RLAIF-V">https://github.com/RLHF-V/RLAIF-V</a></p>
<p><strong>摘要</strong></p>
<p>本研究介绍了RLAIF-V，一个全新的框架，以全开源的方式对齐大型语言模型（MLLMs）。RLAIF-V从高质量反馈数据生成和自反馈指导两个方面最大限度地探索了开源MLLMs。在自动和人类评估的六个基准测试上的实验表明，RLAIF-V在偏好学习和推理时间方面都大大提高了模型的可靠性。RLAIF-V 7B将物体幻觉减少了80.7%，总体幻觉减少了33.7%。值得注意的是，RLAIF-V 12B进一步揭示了开源MLLMs的自我对齐潜力，模型可以从自身的反馈中学习，以达到超越GPT-4V的可信程度。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>RLAIF-V是一个全新的框架，用于在完全开源的情境下对齐大型语言模型（MLLMs）。</li>
<li>RLAIF-V从高质量反馈数据生成和自反馈指导两个方面探索了开源MLLMs的潜力。</li>
<li>在多个基准测试上，RLAIF-V显著提高了模型在偏好学习和推理时间方面的可靠性。</li>
<li>RLAIF-V 7B版本大幅减少了幻觉现象。</li>
<li>RLAIF-V 12B版本展示了模型从自身反馈中学习的能力，达到超卓的可信程度。</li>
<li>该研究证明了开源MLLMs的巨大潜力，特别是在自我对齐和反馈学习方面。</li>
<li>RLAIF-V框架为构建高质量反馈的开源MLLMs提供了新的方向。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17220">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c5f2991ff66afe21f4f45e54ed30f879.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58368eb398f3643d9029f3322ddb1971.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-506f3c75aaab37f5bab1f219650b650c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3afcafa3fdeb299a26888742877a4fe3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c09d41eff983cab82bd3e3b9912b9e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16e33bfb5d26eaebe3eb2444c7b241d6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ConTrans-Weak-to-Strong-Alignment-Engineering-via-Concept-Transplantation"><a href="#ConTrans-Weak-to-Strong-Alignment-Engineering-via-Concept-Transplantation" class="headerlink" title="ConTrans: Weak-to-Strong Alignment Engineering via Concept   Transplantation"></a>ConTrans: Weak-to-Strong Alignment Engineering via Concept   Transplantation</h2><p><strong>Authors:Weilong Dong, Xinwei Wu, Renren Jin, Shaoyang Xu, Deyi Xiong</strong></p>
<p>Ensuring large language models (LLM) behave consistently with human goals, values, and intentions is crucial for their safety but yet computationally expensive. To reduce the computational cost of alignment training of LLMs, especially for those with a huge number of parameters, and to reutilize learned value alignment, we propose ConTrans, a novel framework that enables weak-to-strong alignment transfer via concept transplantation. From the perspective of representation engineering, ConTrans refines concept vectors in value alignment from a source LLM (usually a weak yet aligned LLM). The refined concept vectors are then reformulated to adapt to the target LLM (usually a strong yet unaligned base LLM) via affine transformation. In the third step, ConTrans transplants the reformulated concept vectors into the residual stream of the target LLM. Experiments demonstrate the successful transplantation of a wide range of aligned concepts from 7B models to 13B and 70B models across multiple LLMs and LLM families. Remarkably, ConTrans even surpasses instruction-tuned models in terms of truthfulness. Experiment results validate the effectiveness of both inter-LLM-family and intra-LLM-family concept transplantation. Our work successfully demonstrates an alternative way to achieve weak-to-strong alignment generalization and control. </p>
<blockquote>
<p>确保大型语言模型（LLM）与人类目标、价值观和意图保持一致至关重要，这对于其安全性至关重要，但计算上却很昂贵。为了降低LLM对齐训练的计算成本，特别是对于那些具有大量参数的LLM，并为了重新利用学习到的价值对齐，我们提出了ConTrans这一新型框架，它能够通过概念移植实现弱到强的对齐转移。从表示工程的角度来看，ConTrans通过细化价值对齐中的概念向量来改进源LLM（通常是一个弱小但对齐的LLM）。然后，经过细化的概念向量通过仿射变换被重新制定以适应目标LLM（通常是一个强大但未对齐的基础LLM）。第三步中，ConTrans将重新制定的概念向量移植到目标LLM的残差流中。实验表明，从多个LLM和LLM家族中的7B模型成功移植了多种对齐的概念到更大的模型（如使用与弱对齐LLM一致的道德价值观的概念）到更大的模型（如使用与弱对齐LLM一致的道德价值观的概念）到更大的模型（如13B和70B模型）。值得注意的是，ConTrans甚至超越了指令优化模型的真实性水平。实验结果验证了跨家族内跨家族内概念移植的有效性。我们的工作成功地证明了实现弱到强对齐泛化和控制的另一种可能途径。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.13578v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）与人类目标、价值观和意图的一致性对其安全性至关重要，但计算成本高昂。为此，我们提出ConTrans框架，通过概念移植实现弱到强的对齐转移，降低LLM对齐训练的计算成本并复用已学习的价值对齐。ConTrans从表示工程的角度出发，精炼源LLM（通常是弱但对齐的LLM）中的概念向量，然后通过仿射变换适应目标LLM（通常是强但未对齐的基础LLM）。最后，将改革后的概念向量移植到目标LLM的残差流中。实验证明，从7B模型到13B和70B模型的广泛对齐概念移植成功，且在多个LLM和LLM家族中，ConTrans甚至超越了指令微调模型的真实性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ConTrans框架旨在降低LLM对齐训练的计算成本并复用已学习的价值对齐。</li>
<li>通过概念移植实现弱到强的对齐转移。</li>
<li>ConTrans从表示工程的角度出发，精炼源LLM中的概念向量，并适应目标LLM。</li>
<li>改革后的概念向量被移植到目标LLM的残差流中。</li>
<li>实验证明概念移植的成功，并展示了ConTrans在多个LLM和LLM家族中的有效性。</li>
<li>ConTrans甚至在某些方面超越了指令微调模型的真实性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.13578">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e5d1308e68bbfb459c92284699c8a820.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b8927e2c6041ef0ce5b385ed49508999.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c4b1d19e56096fc952d93620aca4681.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c7aa9b8e886110b98cdcdf10c919f55.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Aligning-the-Objective-of-LLM-based-Program-Repair"><a href="#Aligning-the-Objective-of-LLM-based-Program-Repair" class="headerlink" title="Aligning the Objective of LLM-based Program Repair"></a>Aligning the Objective of LLM-based Program Repair</h2><p><strong>Authors:Junjielong Xu, Ying Fu, Shin Hwei Tan, Pinjia He</strong></p>
<p>Large language models (LLMs) have achieved decent results on automated program repair (APR). However, the next token prediction training objective of decoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction objective of current infilling-style methods, which impedes LLMs from fully leveraging pre-trained knowledge for program repair. In addition, while some LLMs can locate and repair bugs in certain functions using the related artifacts (e.g., test cases), existing methods still depend on statement-level fault localization methods to provide a list of buggy hunks for repair. This restriction hinders LLMs from exploring potential patches beyond the given locations.   In this paper, we investigate a new approach to adapt LLMs to program repair. Our core insight is that LLM’s APR capability can be greatly improved by simply aligning the output to their training objective and allowing them to refine the whole program without first identifying faulty statements. Based on this insight, we designed D4C, a straightforward prompting framework for APR. D4C can repair 180 bugs correctly in Defects4J, with each patch being sampled only 10 times. This surpasses the SOTA APR methods with perfect fault localization by 10% and reduces the patch sampling number by 90%. Our findings reveal that (1) objective alignment is crucial for fully exploiting LLM’s pre-trained capability, and (2) replacing the traditional localize-buggy-hunks-then-repair workflow with direct debugging is more effective for LLM-based APR methods. Thus, we believe this paper introduces a new mindset for harnessing LLMs in APR. </p>
<blockquote>
<p>大型语言模型（LLM）在自动化程序修复（APR）方面取得了不错的效果。然而，解码器仅针对下一个令牌预测的训练目标（例如GPT-4）与当前填充式方法的掩码跨度预测目标之间存在不匹配，这阻碍了LLM充分利用预训练知识进行程序修复。另外，虽然一些LLM能够利用相关工件（如测试用例）定位和修复某些函数中的错误，但现有方法仍然依赖于语句级故障定位方法来提供修复错误代码块列表。这种限制阻碍了LLM探索给定位置以外的潜在补丁。在本文中，我们研究了一种适应LLM进行程序修复的新方法。我们的核心见解是，通过简单对齐输出并允许它们在没有首先确定错误语句的情况下完善整个程序，可以大大提高LLM的APR能力。基于此见解，我们设计了D4C，一个用于APR的直接提示框架。D4C能够在Defects4J中正确修复180个错误，每个补丁只需采样10次。这超越了具有完美故障定位的SOTA APR方法，提高了10%，并将补丁采样数量减少了90%。我们的研究结果表明：（1）目标对齐对于充分利用LLM的预训练能力至关重要；（2）用直接调试替换传统的定位错误代码块然后进行修复的工作流程对于基于LLM的APR方法更为有效。因此，我们相信本文为在APR中利用LLM引入了一种新的思维方式。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.08877v4">PDF</a> Accepted by ICSE’25</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在自动化程序修复（APR）方面表现良好，但其在训练目标和修复流程上仍有待改进。本研究通过调整输出以符合训练目标并允许直接修复整个程序，提出了一种新的LLM适应APR的方法。设计了一种名为D4C的简洁提示框架，能在Defects4J中修复180个错误，减少了补丁采样次数。这表明目标对齐对充分利用LLM的预训练能力至关重要，并且直接在无需定位错误语句的情况下进行调试更为有效。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在APR方面已展现良好性能，但在训练目标和修复流程上存在潜在改进空间。</li>
<li>训练目标对齐对于提升LLM在APR中的表现至关重要。</li>
<li>传统先定位错误再修复的工作流程对于LLM-based的APR方法可能不够有效。</li>
<li>直接修复整个程序的策略相较于传统的局部修复方法更为高效。</li>
<li>新提出的D4C框架能成功修复更多错误，并减少补丁采样次数。</li>
<li>LLM的潜力在于其能够利用预训练知识，通过调整输出和目标对齐进一步提升性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.08877">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-95009fe01a27ae73a8a9d4e563ebdad6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fc24aae654eb164ef4300a03ffd7460.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48754fa5d8498b6860d79baf6a9f615f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c44ca910d029c8f08cd562dd63494c13.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b8b5c6fa47c908d36733ee09d4a9eae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55e28b85808ea1ce2be533ee34e407f7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="TOTEM-TOkenized-Time-Series-EMbeddings-for-General-Time-Series-Analysis"><a href="#TOTEM-TOkenized-Time-Series-EMbeddings-for-General-Time-Series-Analysis" class="headerlink" title="TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis"></a>TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis</h2><p><strong>Authors:Sabera Talukder, Yisong Yue, Georgia Gkioxari</strong></p>
<p>This work studies the problem of time series analysis with generalist (or foundation) models, which are models trained across many data domains. Drawing inspiration from the widespread success of large language models, we consider the simple strategy of discretely tokenizing time series data drawn from a myriad of datasets via self-supervision, then using the fixed tokenization to solve a variety of tasks across many data domains. Canonically, time series models are either trained on a single dataset or built in a task-specific manner (e.g., a forecasting-only model), where many use patches of time as inputs to the model. As such, performant generalist, discrete representation time series models explored across many tasks are of value. Our method, TOkenized Time Series EMbeddings (TOTEM), produces such generalist time series models with minimal or no fine-tuning while exhibiting strong zero-shot performance. We evaluate TOTEM extensively over nearly 500 experiments on three commonly-studied time series tasks with real-world data: imputation (17 baselines, 12 datasets), anomaly detection (19 baselines, 25 datasets), and forecasting (14 baselines, 12 datasets). We conclude that TOTEM matches or outperforms existing state-of-the-art models in both the canonical specialist setting (i.e., training one model on one domain) as well as the generalist setting (i.e., training a single model on many domains), which demonstrates the efficacy of tokenization for general time series analysis. The open-source implementation is available here: <a target="_blank" rel="noopener" href="https://github.com/SaberaTalukder/TOTEM">https://github.com/SaberaTalukder/TOTEM</a>; a video summary is available here: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OqrCpdb6MJk">https://www.youtube.com/watch?v=OqrCpdb6MJk</a>. </p>
<blockquote>
<p>本文研究了使用时间序列分析通才（或基础）模型的问题，这些模型是在多个数据领域进行训练的。从大型语言模型的广泛成功中汲取灵感，我们考虑了一种简单策略，即通过自监督，从众多数据集中离散地标记时间序列数据，然后使用固定的标记法解决多个数据领域的各种任务。通常情况下，时间序列模型是在单个数据集上进行训练或以特定任务的方式构建（例如，仅用于预测的模型），其中许多人使用时间段作为模型的输入。因此，能够在多个任务上探索高性能的通才、离散表示时间序列模型是非常有价值的。我们的方法，即令牌化时间序列嵌入（TOTEM），能够产生这种通才时间序列模型，在几乎不需要微调的情况下表现出强大的零样本性能。我们在三个常见的时间序列任务上进行了近500次实验，对TOTEM进行了广泛评估，这些任务使用真实世界数据：填补（17个基准测试，12个数据集）、异常检测（19个基准测试，25个数据集）和预测（14个基准测试，12个数据集）。我们得出结论，无论是在专业设定（即在一个领域上训练一个模型）还是在通才设定（即在多个领域上训练一个模型）中，TOTEM都能与现有的最先进的模型相匹配或超越，这证明了令牌化对于一般时间序列分析的有效性。开源实现可在此处找到：<a target="_blank" rel="noopener" href="https://github.com/SaberaTalukder/TOTEM">https://github.com/SaberaTalukder/TOTEM</a>；视频摘要可在此处观看：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OqrCpdb6MJk">https://www.youtube.com/watch?v=OqrCpdb6MJk</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.16412v2">PDF</a> Accepted to TMLR (12&#x2F;24), 33 pages. TMLR link:   <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=QlTLkH6xRC">https://openreview.net/pdf?id=QlTLkH6xRC</a></p>
<p><strong>Summary</strong></p>
<p>本文研究了基于通用模型（或基础模型）的时间序列分析，这些模型在多个数据域上进行训练。文章受到大型语言模型广泛成功的启发，提出了一种简单策略，即离散地将来自多个数据集的时间序列数据进行自监督处理，然后使用固定的离散化数据解决多个数据域的各种任务。文章指出，典型的时间序列模型是在单一数据集上训练或在特定任务上构建（例如仅用于预测的模型），使用时间片段作为模型的输入。因此，研究能够跨多个任务表现优异的一般性离散表示时间序列模型具有重要意义。文章提出的TOTEM方法（Tokenized Time Series EMbeddings）即生成这样的通用时间序列模型，无需精细调整，并具有出色的零样本性能。在接近500个实验的大规模评估中，TOTEM在三个常见时间序列任务上的真实世界数据集中表现出色，匹配或超越了现有最先进的模型。无论是在特定领域的训练环境还是在多个域的通用环境设置下均展现良好性能，这证明了令牌化对于通用时间序列分析的有效性。论文还提供了开源实现和视频摘要链接。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文章研究了基于通用模型的时间序列分析策略，通过离散化的自监督处理解决多个数据域的任务。</li>
<li>TOTEM方法是一种生成通用时间序列模型的方法，无需精细调整，并具有出色的零样本性能。</li>
<li>TOTEM在三个常见时间序列任务（填补空缺、异常检测、预测）的广泛实验评估中表现出色。</li>
<li>TOTEM在多个数据集上的表现匹配或超越了现有的先进模型。</li>
<li>文章强调了离散化的时间序列分析策略对于跨多个任务的通用性表现的重要性。</li>
<li>文章提供了开源实现和视频摘要链接供读者参考和进一步了解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.16412">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-18bef6bb0d6398f838bd5542f2d07163.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-828ce51af8eaa6932ffcd58c2061f75b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10f765272f0e091fd486576ee96227e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f382f1675dd92438f6856faa2c9830c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d35cecdde9b380ff119b499412a74bd9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a309bae67a268a60ec53c8f9b12a136a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="What-if-LLMs-Have-Different-World-Views-Simulating-Alien-Civilizations-with-LLM-based-Agents"><a href="#What-if-LLMs-Have-Different-World-Views-Simulating-Alien-Civilizations-with-LLM-based-Agents" class="headerlink" title="What if LLMs Have Different World Views: Simulating Alien Civilizations   with LLM-based Agents"></a>What if LLMs Have Different World Views: Simulating Alien Civilizations   with LLM-based Agents</h2><p><strong>Authors:Zhaoqian Xue, Mingyu Jin, Beichen Wang, Suiyuan Zhu, Kai Mei, Hua Tang, Wenyue Hua, Mengnan Du, Yongfeng Zhang</strong></p>
<p>This study introduces “CosmoAgent,” an innovative artificial intelligence system that utilizes Large Language Models (LLMs) to simulate complex interactions between human and extraterrestrial civilizations. This paper introduces a mathematical model for quantifying the levels of civilization development and further employs a state transition matrix approach to evaluate their trajectories. Through this methodology, our study quantitatively analyzes the growth trajectories of civilizations, providing insights into future decision-making at critical points of growth and saturation. Furthermore, this paper acknowledges the vast diversity of potential living conditions across the universe, which could foster unique cosmologies, ethical codes, and worldviews among different civilizations. Recognizing the Earth-centric bias inherent in current LLM designs, we propose the novel concept of using LLM agents with diverse ethical paradigms and simulating interactions between entities with distinct moral principles. This innovative research not only introduces a novel method for comprehending potential inter-civilizational dynamics but also holds practical value in enabling entities with divergent value systems to strategize, prevent conflicts, and engage in games under conditions of asymmetric information. The accompanying code is available at <a target="_blank" rel="noopener" href="https://github.com/MingyuJ666/Simulating-Alien-Civilizations-with-LLM-based-Agents">https://github.com/MingyuJ666/Simulating-Alien-Civilizations-with-LLM-based-Agents</a>. </p>
<blockquote>
<p>本研究介绍了“CosmoAgent”，这是一个创新的人工智能系统，利用大型语言模型（LLM）模拟人类与外星文明之间的复杂交互。本文介绍了一个量化文明发展水平数学模型，并进一步采用状态转移矩阵方法评估其轨迹。通过这种方法，我们的研究定量分析了文明的成长轨迹，为未来在增长和饱和的关键点上提供决策依据。此外，本文承认宇宙中潜在生存条件的巨大多样性，这可能会催生独特的宇宙观、道德准则和世界观在不同的文明之间。鉴于当前LLM设计所固有的以地球为中心的偏见，我们提出了使用具有不同道德规范的LLM代理人的新概念，并模拟不同道德原则实体之间的交互。这项创新的研究不仅引入了一种理解潜在文明间动态的新方法，而且在实体中实现了不同价值体系下的策略制定、冲突预防以及在不对称信息条件下的游戏等实际应用价值。相应的代码可通过访问链接获得：<a target="_blank" rel="noopener" href="https://github.com/MingyuJ66HSSimulating-Alien-Civilizations-with-LLM-based-Agents%E3%80%82">https://github.com/MingyuJ66HSSimulating-Alien-Civilizations-with-LLM-based-Agents。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.13184v5">PDF</a> </p>
<p><strong>Summary</strong>：本研究介绍了一种名为“CosmoAgent”的创新人工智能系统，该系统利用大型语言模型（LLM）模拟人类与外星文明之间的复杂交互。研究提出了一种量化文明发展水平的方法论，并采用状态转移矩阵方法评估文明的发展轨迹。此外，该研究还考虑了宇宙中可能存在的多种多样的生存条件，可能促进形成不同的宇宙观、道德规范和世界观。因此，在利用LLM代理进行模拟时，考虑到了具有不同道德原则实体的交互情况。本研究不仅为理解潜在的文明间动态提供了新的方法，还具有实用价值，使得具有不同价值体系的实体能够在信息不对称的条件下进行策略制定、冲突预防和游戏互动。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>“CosmoAgent”是一个利用大型语言模型模拟人类与外星文明交互的人工智能系统。</li>
<li>研究提出了量化文明发展水平的数学模型，并评估其发展轨迹。</li>
<li>宇宙中存在多样的生存条件，可能催生不同的宇宙观和道德规范。</li>
<li>LLM代理在模拟中考虑了具有不同道德原则实体的交互情况。</li>
<li>该研究为理解潜在文明间动态提供了新的方法。</li>
<li>研究成果具有实用价值，有助于实体在信息不对称条件下进行策略制定和冲突预防。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.13184">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c070b13d9f337e9d072bc2c07317d11e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96dc8591f45602c89c17c5de81ec878d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9c264ded949f7e52f70fc560435d2ef.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="EA-KD-Entropy-based-Adaptive-Knowledge-Distillation"><a href="#EA-KD-Entropy-based-Adaptive-Knowledge-Distillation" class="headerlink" title="EA-KD: Entropy-based Adaptive Knowledge Distillation"></a>EA-KD: Entropy-based Adaptive Knowledge Distillation</h2><p><strong>Authors:Chi-Ping Su, Ching-Hsun Tseng, Bin Pu, Lei Zhao, Zhuangzhuang Chen, Shin-Jye Lee</strong></p>
<p>Knowledge distillation (KD) enables a smaller “student” model to mimic a larger “teacher” model by transferring knowledge from the teacher’s output or features. However, most KD methods treat all samples uniformly, overlooking the varying learning value of each sample and thereby limiting effectiveness. In this paper, we propose Entropy-based Adaptive Knowledge Distillation (EA-KD), a simple yet effective plug-and-play KD method that prioritizes learning from valuable samples. EA-KD quantifies each sample’s learning value by strategically combining the entropy of the teacher and student output, then dynamically reweights the distillation loss to place greater emphasis on high-value samples. Extensive experiments across diverse KD frameworks and tasks$\unicode{x2014}$including image classification, object detection, and large language model (LLM) distillation$\unicode{x2014}$demonstrate that EA-KD consistently enhances performance, achieving state-of-the-art results with negligible computational cost. Our code will be publicly available. </p>
<blockquote>
<p>知识蒸馏（KD）能够通过从教师模型的输出或特征转移知识，使较小的“学生”模型模仿较大的“教师”模型。然而，大多数KD方法都均匀处理所有样本，忽略了每个样本的不同学习价值，从而限制了有效性。在本文中，我们提出了基于熵的自适应知识蒸馏（EA-KD），这是一种简单而有效的即插即用KD方法，它优先从有价值的样本中学习。EA-KD通过战略性地结合教师和学生的输出熵来量化每个样本的学习价值，然后动态调整蒸馏损失，以更侧重于高价值样本。在包括图像分类、目标检测和大型语言模型（LLM）蒸馏等多种KD框架和任务上的大量实验表明，EA-KD始终提高了性能，实现了最先进的成果，且计算成本微乎其微。我们的代码将公开可用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.13621v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于熵的自适应知识蒸馏（EA-KD）是一种简单而有效的知识蒸馏方法，它结合了教师模型的输出和输出值的熵来计算样本的学习价值，并通过动态调整蒸馏损失权重，重点关注价值较高的样本进行学习。此方法在各种知识蒸馏框架和任务中都取得了最佳结果，提高了模型的性能且计算成本较低。公开可用的代码将有助于广泛采用此技术。</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.13621">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-681ea6ce7c6fc050617b08a99713d7c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2c9a169638b8b023188c2aa5aa22d74.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-54e067b85cd2e31ddd00b74b88849f85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3614abfac9a6418506c2e7af8d8382af.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d1a254319631818d4b5dc59f079ef5d4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="WizardMath-Empowering-Mathematical-Reasoning-for-Large-Language-Models-via-Reinforced-Evol-Instruct"><a href="#WizardMath-Empowering-Mathematical-Reasoning-for-Large-Language-Models-via-Reinforced-Evol-Instruct" class="headerlink" title="WizardMath: Empowering Mathematical Reasoning for Large Language Models   via Reinforced Evol-Instruct"></a>WizardMath: Empowering Mathematical Reasoning for Large Language Models   via Reinforced Evol-Instruct</h2><p><strong>Authors:Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Yansong Tang, Dongmei Zhang</strong></p>
<p>Large language models (LLMs), such as GPT-4, have shown remarkable performance in natural language processing (NLP) tasks, including challenging mathematical reasoning. However, most existing open-source models are only pre-trained on large-scale internet data and without math-related optimization. In this paper, we present WizardMath, which enhances the mathematical CoT reasoning abilities of LLMs without using external python tools, by applying our proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive experiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary capabilities of our model. Remarkably, WizardMath-Mistral 7B surpasses top-tier open-source LLMs by a substantial margin with higher data efficiency. Furthermore, WizardMath 70B even outperforms GPT-3.5-Turbo, Claude 2, Gemini Pro and GPT-4-early-version. Additionally, our preliminary exploration highlights the pivotal role of instruction evolution and process supervision in achieving exceptional math performance. For more details refer to <a target="_blank" rel="noopener" href="https://github.com/nlpxucan/WizardLM">https://github.com/nlpxucan/WizardLM</a> </p>
<blockquote>
<p>大型语言模型（LLM），如GPT-4，在自然语言处理（NLP）任务中表现出卓越的性能，包括具有挑战性的数学推理。然而，大多数现有的开源模型仅在大规模互联网数据上进行预训练，并没有进行数学相关的优化。在本文中，我们介绍了WizardMath，它通过应用我们提出的强化学习从进化指令反馈（RLEIF）方法到数学领域，提高了LLM的数学CoT推理能力，且不使用外部python工具。我们在两个数学推理基准测试GSM8k和MATH上进行了大量实验，揭示了模型的卓越能力。值得注意的是，WizardMath-Mistral 7B以更高的数据效率大幅超越了顶级开源LLM。此外，WizardMath 70B甚至超越了GPT-3.5-Turbo、Claude 2、Gemini Pro和GPT-4的早期版本。我们的初步探索突显了指令演进和过程监督在实现卓越数学性能中的关键作用。想了解更多详情，请访问 <a target="_blank" rel="noopener" href="https://github.com/nlpxucan/WizardLM">https://github.com/nlpxucan/WizardLM</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09583v2">PDF</a> LLM, Mathematical Reasoning</p>
<p><strong>Summary</strong><br>     本论文介绍了WizardMath，一种增强大型语言模型（LLM）数学推理能力的方法，无需使用外部Python工具。通过应用强化学习从演化指令反馈（RLEIF）方法，WizardMath在数学领域表现出卓越性能。实验结果显示，WizardMath-Mistral 7B在GSM8k和MATH两个数学推理基准测试上大幅超越顶尖开源LLM，且数据效率更高。此外，WizardMath 70B甚至超越了GPT-3.5-Turbo、Claude 2、Gemini Pro和GPT-4早期版本。初步探索表明，指令演化和过程监督在实现卓越数学性能中起着关键作用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WizardMath方法增强了LLM的数学推理能力，且无需外部Python工具。</li>
<li>通过应用强化学习从演化指令反馈（RLEIF）方法，WizardMath在数学领域表现出卓越性能。</li>
<li>WizardMath-Mistral 7B在GSM8k和MATH数学推理基准测试上超越顶尖开源LLM。</li>
<li>WizardMath 70B的性能超越了GPT-3.5-Turbo、Claude 2、Gemini Pro和GPT-4早期版本。</li>
<li>该方法提高了数据效率。</li>
<li>初步探索表明指令演化和过程监督对实现卓越数学性能至关重要。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.09583">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-39dc284992c141b58d4de73845dbec4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db67f959409f413cdd608d5a21a2fee5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6faa3bfccb6cc931e0d534cfdd77844b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents"><a href="#Is-ChatGPT-Good-at-Search-Investigating-Large-Language-Models-as-Re-Ranking-Agents" class="headerlink" title="Is ChatGPT Good at Search? Investigating Large Language Models as   Re-Ranking Agents"></a>Is ChatGPT Good at Search? Investigating Large Language Models as   Re-Ranking Agents</h2><p><strong>Authors:Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, Zhaochun Ren</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model’s ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at <a target="_blank" rel="noopener" href="http://www.github.com/sunnweiwei/RankGPT">www.github.com/sunnweiwei/RankGPT</a>. </p>
<blockquote>
<p>大型语言模型（LLM）在各种语言相关任务中表现出了显著的零样本泛化能力，包括搜索引擎。然而，现有工作主要利用LLM的生成能力进行信息检索（IR），而非直接进行段落排名。LLM的预训练目标与排名目标之间的差异构成了另一项挑战。在本文中，我们首先调查了用于信息检索中的相关性排名的生成式LLM，如ChatGPT和GPT-4。令人惊讶的是，我们的实验结果表明，在流行的IR基准测试中，经过适当指示的LLM可以产生具有竞争力的结果，甚至优于最先进的监督方法。此外，为了解决对LLM数据污染的担忧，我们收集了一个新的测试集，称为NovelEval，它基于最新知识，旨在验证模型对未知知识的排名能力。最后，为了提高在现实世界应用中的效率，我们深入探讨了使用置换蒸馏方案将ChatGPT的排名能力蒸馏到小型专用模型中的潜力。我们的评估结果表明，一个蒸馏后的4.4亿参数模型在BEIR基准测试中表现优于一个30亿参数监督模型。您可以在<a target="_blank" rel="noopener" href="http://www.github.com/sunnweiwei/RankGPT%E4%B8%8A%E8%8E%B7%E5%8F%96%E5%A4%8D%E5%88%B6%E6%88%91%E4%BB%AC%E7%BB%93%E6%9E%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E3%80%82">www.github.com/sunnweiwei/RankGPT上获取复制我们结果的代码。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2304.09542v3">PDF</a> EMNLP 2023</p>
<p><strong>Summary</strong></p>
<p>本文探讨了大型语言模型（LLMs）在搜索引擎信息检索（IR）中的零样本泛化能力。研究指出，通过适当指导，LLMs在IR排名任务上的表现可与最先进的监督方法相竞争，甚至更优。为验证模型对未知知识的排名能力，研究团队推出了新型测试集NovelEval。此外，研究还探索了利用permutation distillation方案将ChatGPT的排名能力蒸馏到小型专用模型中的可能性，结果显示蒸馏后的440M模型在BEIR基准测试中表现优于3B监督模型。相关代码已公开。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMs展现出强大的零样本泛化能力，可在各种语言任务中表现优异，包括搜索引擎。</li>
<li>LLMs在信息检索（IR）的排名任务中表现良好，通过适当指导，其性能可与最先进的监督方法相竞争。</li>
<li>推出新型测试集NovelEval，用于验证模型对未知知识的排名能力。</li>
<li>利用permutation distillation方案，成功将ChatGPT的排名能力蒸馏到小型专用模型中。</li>
<li>蒸馏后的440M模型在BEIR基准测试中表现优于3B监督模型。</li>
<li>公开了相关代码以供研究使用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2304.09542">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-bf3b3a611cb1f6b4beaaa62df58b7d6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b63db53fcba13e1926cd6938121a9423.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4660698e1379ae3973426cb4da344f08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46a67bbe1cf1176ce4d1e8a308c058ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7ed0c5e2f414879892079cedd6e44bb8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-05/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-05/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-06/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c6709bd6ded869bc0c876103b2853df2.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-01-06  Unifying Specialized Visual Encoders for Video Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-04/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ae413a2f4000cbd23c292098b0cca95f.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2025-01-04  Towards Expressive Video Dubbing with Multiscale Multimodal Context   Interaction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
