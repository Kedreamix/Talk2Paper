<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-11  Can open source large language models be used for tumor documentation in   Germany? -- An evaluation on urological doctors&#39; notes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1ba06e8d214bcc0ee060e128f7226eda.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-11-æ›´æ–°"><a href="#2025-08-11-æ›´æ–°" class="headerlink" title="2025-08-11 æ›´æ–°"></a>2025-08-11 æ›´æ–°</h1><h2 id="Can-open-source-large-language-models-be-used-for-tumor-documentation-in-Germany-â€“-An-evaluation-on-urological-doctorsâ€™-notes"><a href="#Can-open-source-large-language-models-be-used-for-tumor-documentation-in-Germany-â€“-An-evaluation-on-urological-doctorsâ€™-notes" class="headerlink" title="Can open source large language models be used for tumor documentation in   Germany? â€“ An evaluation on urological doctorsâ€™ notes"></a>Can open source large language models be used for tumor documentation in   Germany? â€“ An evaluation on urological doctorsâ€™ notes</h2><p><strong>Authors:Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Meike Ressing, Torsten Panholzer</strong></p>
<p>Tumor documentation in Germany is largely done manually, requiring reading patient records and entering data into structured databases. Large language models (LLMs) could potentially enhance this process by improving efficiency and reliability. This evaluation tests eleven different open source LLMs with sizes ranging from 1-70 billion model parameters on three basic tasks of the tumor documentation process: identifying tumor diagnoses, assigning ICD-10 codes, and extracting the date of first diagnosis. For evaluating the LLMs on these tasks, a dataset of annotated text snippets based on anonymized doctorsâ€™ notes from urology was prepared. Different prompting strategies were used to investigate the effect of the number of examples in few-shot prompting and to explore the capabilities of the LLMs in general. The models Llama 3.1 8B, Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks. Models with less extensive training data or having fewer than 7 billion parameters showed notably lower performance, while larger models did not display performance gains. Examples from a different medical domain than urology could also improve the outcome in few-shot prompting, which demonstrates the ability of LLMs to handle tasks needed for tumor documentation. Open source LLMs show a strong potential for automating tumor documentation. Models from 7-12 billion parameters could offer an optimal balance between performance and resource efficiency. With tailored fine-tuning and well-designed prompting, these models might become important tools for clinical documentation in the future. The code for the evaluation is available from <a target="_blank" rel="noopener" href="https://github.com/stefan-m-lenz/UroLlmEval">https://github.com/stefan-m-lenz/UroLlmEval</a>. We also release the dataset as a new valuable resource that addresses the shortage of authentic and easily accessible benchmarks in German-language medical NLP. </p>
<blockquote>
<p>å¾·å›½çš„è‚¿ç˜¤è®°å½•å¤§å¤šæ˜¯é€šè¿‡æ‰‹åŠ¨å®Œæˆçš„ï¼Œéœ€è¦é˜…è¯»æ‚£è€…ç—…å†å¹¶å°†æ•°æ®è¾“å…¥ç»“æ„åŒ–æ•°æ®åº“ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ‰æœ›é€šè¿‡æé«˜æ•ˆç‡å¯é æ€§å¢å¼ºè¿™ä¸€æµç¨‹ã€‚æœ¬æ¬¡è¯„ä¼°å¯¹ä¸‰ç§åŸºæœ¬ä»»åŠ¡ï¼ˆè¯†åˆ«è‚¿ç˜¤è¯Šæ–­ã€åˆ†é…ICD-10ä»£ç å’Œæå–é¦–æ¬¡è¯Šæ–­æ—¥æœŸï¼‰æµ‹è¯•äº†11ç§ä¸åŒè§„æ¨¡ï¼ˆä»1äº¿åˆ°70äº¿æ¨¡å‹å‚æ•°ï¼‰çš„å¼€æºLLMsã€‚ä¸ºäº†è¯„ä¼°è¿™äº›LLMsåœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæˆ‘ä»¬å‡†å¤‡äº†ä¸€ä¸ªåŸºäºæ³Œå°¿ç§‘åŒ¿ååŒ»ç”Ÿç¬”è®°çš„æ³¨é‡Šæ–‡æœ¬ç‰‡æ®µæ•°æ®é›†ã€‚ä½¿ç”¨äº†ä¸åŒçš„æç¤ºç­–ç•¥æ¥æ¢ç©¶åœ¨å°‘æ•°æ¡ˆä¾‹æç¤ºä¸­ç¤ºä¾‹æ•°é‡å¯¹æ¨¡å‹çš„å½±å“ï¼Œå¹¶æ¢ç´¢LLMsçš„ä¸€èˆ¬èƒ½åŠ›ã€‚Llama 3.1 8Bã€Mistral 7Bå’ŒMistral NeMo 12Bç­‰æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚å…·æœ‰è¾ƒå°‘è®­ç»ƒæ•°æ®æˆ–å‚æ•°å°‘äº7äº¿çš„æ¨¡å‹è¡¨ç°æ˜æ˜¾è¾ƒå·®ï¼Œè€Œæ›´å¤§çš„æ¨¡å‹å¹¶æœªæ˜¾ç¤ºå‡ºæ€§èƒ½æå‡ã€‚æ¥è‡ªä¸åŒäºæ³Œå°¿ç§‘çš„åŒ»å­¦é¢†åŸŸçš„ä¾‹å­ä¹Ÿèƒ½åœ¨å°‘æ•°æ¡ˆä¾‹æç¤ºä¸­æ”¹å–„ç»“æœï¼Œè¿™è¯æ˜äº†LLMså¤„ç†è‚¿ç˜¤è®°å½•æ‰€éœ€ä»»åŠ¡çš„èƒ½åŠ›ã€‚å¼€æºLLMsåœ¨è‡ªåŠ¨åŒ–è‚¿ç˜¤è®°å½•æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚å…·æœ‰7-12äº¿å‚æ•°çš„æ¨¡å‹å¯èƒ½åœ¨æ€§èƒ½å’Œèµ„æºæ•ˆç‡ä¹‹é—´æä¾›æœ€ä½³å¹³è¡¡ã€‚é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒå’Œç²¾å¿ƒè®¾è®¡çš„æç¤ºï¼Œè¿™äº›æ¨¡å‹å¯èƒ½ä¼šæˆä¸ºæœªæ¥ä¸´åºŠè®°å½•çš„é‡è¦å·¥å…·ã€‚è¯„ä¼°çš„ä»£ç å¯ä»<a target="_blank" rel="noopener" href="https://github.com/stefan-m-lenz/UroLlmEval%E8%8E%B7%E5%8F%96%E3%80%82%E6%88%91%E4%BB%AC%E8%BF%98%E5%8F%91%E5%B8%83%E4%BA%86%E8%AF%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%9C%E4%B8%BA%E6%96%B0%E7%9A%84%E5%AE%9D%E8%B4%B5%E8%B5%84%E6%BA%90%EF%BC%8C%E4%BB%A5%E8%A7%A3%E5%86%B3%E5%BE%B7%E5%9B%BD%E5%8C%BB%E5%AD%A6NLP%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9C%9F%E5%AE%9E%E4%B8%94%E6%98%93%E4%BA%8E%E8%AE%BF%E9%97%AE%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E4%B8%8D%E8%B6%B3%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82">https://github.com/stefan-m-lenz/UroLlmEvalè·å–ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†è¯¥æ•°æ®é›†ä½œä¸ºæ–°çš„å®è´µèµ„æºï¼Œä»¥è§£å†³å¾·å›½åŒ»å­¦NLPé¢†åŸŸä¸­çœŸå®ä¸”æ˜“äºè®¿é—®çš„åŸºå‡†æµ‹è¯•æ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12106v4">PDF</a> 53 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¾·å›½çš„è‚¿ç˜¤è®°å½•è¿‡ç¨‹ä¸­ï¼Œä¸»è¦ä¾èµ–äºæ‰‹åŠ¨æ“ä½œï¼Œæ¶‰åŠé˜…è¯»æ‚£è€…è®°å½•å¹¶è¾“å…¥ç»“æ„åŒ–æ•°æ®åº“ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ‰æ½œåŠ›é€šè¿‡æé«˜æ•ˆç‡å’Œå¯é æ€§æ¥æ”¹è¿›è¿™ä¸€è¿‡ç¨‹ã€‚æœ¬è¯„ä¼°ä½¿ç”¨åŸºäºåŒ¿åæ³Œå°¿ç§‘åŒ»ç”Ÿç¬”è®°çš„æ•°æ®é›†ï¼Œæµ‹è¯•äº†11ç§ä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä»1äº¿åˆ°70äº¿æ¨¡å‹å‚æ•°ï¼‰åœ¨è‚¿ç˜¤è®°å½•è¿‡ç¨‹ä¸­çš„ä¸‰é¡¹åŸºæœ¬ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼šè¯†åˆ«è‚¿ç˜¤è¯Šæ–­ã€åˆ†é…ICD-10ä»£ç å’Œæå–é¦–æ¬¡è¯Šæ–­æ—¥æœŸã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒLlama 3.1 8Bã€Mistral 7Bå’ŒMistral NeMo 12Bç­‰æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ã€‚è®­ç»ƒæ•°æ®ä¸è¶³æˆ–å‚æ•°å°‘äº7äº¿çš„æ¨¡å‹è¡¨ç°æ˜æ˜¾è¾ƒå·®ï¼Œè€Œæ›´å¤§çš„æ¨¡å‹å¹¶æ²¡æœ‰æ˜¾ç¤ºå‡ºæ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œä¸åŒåŒ»å­¦é¢†åŸŸçš„æ•°æ®ä¹Ÿæœ‰åŠ©äºæ”¹è¿›å°‘æ ·æœ¬æç¤ºçš„æ•ˆæœï¼Œè¯æ˜äº†å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†è‚¿ç˜¤è®°å½•ä»»åŠ¡çš„èƒ½åŠ›ã€‚å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–è‚¿ç˜¤è®°å½•æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œå…·æœ‰7-12äº¿å‚æ•°çš„æ¨¡å‹å¯èƒ½åœ¨æ€§èƒ½å’Œèµ„æºæ•ˆç‡ä¹‹é—´è¾¾åˆ°æœ€ä½³å¹³è¡¡ã€‚é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒï¼ˆfine-tuningï¼‰å’Œç²¾å¿ƒè®¾è®¡æç¤ºï¼ˆpromptingï¼‰ï¼Œè¿™äº›æ¨¡å‹å¯èƒ½æˆä¸ºæœªæ¥ä¸´åºŠè®°å½•çš„é‡è¦å·¥å…·ã€‚è¯¥è¯„ä¼°çš„ä»£ç å’Œæ•°æ®é›†å·²å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‚¿ç˜¤è®°å½•è¿‡ç¨‹ä¸­å…·æœ‰æ”¹å–„æ•ˆç‡å’Œå¯é æ€§çš„æ½œåŠ›ã€‚</li>
<li>å¯¹ä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°å…·æœ‰7-12äº¿å‚æ•°çš„æ¨¡å‹åœ¨æ€§èƒ½å’Œèµ„æºæ•ˆç‡ä¹‹é—´è¡¨ç°å‡ºæœ€ä½³å¹³è¡¡ã€‚</li>
<li>åœ¨è‚¿ç˜¤è¯Šæ–­è®°å½•ã€ICD-10ä»£ç åˆ†é…å’Œé¦–æ¬¡è¯Šæ–­æ—¥æœŸæå–ç­‰ä»»åŠ¡ä¸Šï¼Œéƒ¨åˆ†æ¨¡å‹è¡¨ç°è‰¯å¥½ã€‚</li>
<li>æ¨¡å‹åœ¨å°‘æ ·æœ¬æç¤ºåœºæ™¯ä¸‹çš„è¡¨ç°å—åˆ°æ‰€ä½¿ç”¨åŒ»å­¦é¢†åŸŸæ•°æ®çš„å½±å“ã€‚</li>
<li>é€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å¾®è°ƒï¼ˆfine-tuningï¼‰å’Œç²¾å¿ƒè®¾è®¡æç¤ºï¼ˆpromptingï¼‰ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å¯èƒ½æˆä¸ºæœªæ¥ä¸´åºŠæ–‡æ¡£å¤„ç†çš„é‡è¦å·¥å…·ã€‚</li>
<li>æ•°æ®é›†çš„å…¬å¼€æœ‰åŠ©äºè§£å†³å¾·å›½è¯­è¨€åŒ»å­¦è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸç¼ºä¹çœŸå®å’Œæ˜“äºè®¿é—®çš„åŸºå‡†æµ‹è¯•æ•°æ®çš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12106">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4fc28baf82178a13b41990142b6ed33e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8671939663ce40fac1677377a0aed781.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FedSemiDG-Domain-Generalized-Federated-Semi-supervised-Medical-Image-Segmentation"><a href="#FedSemiDG-Domain-Generalized-Federated-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image   Segmentation"></a>FedSemiDG: Domain Generalized Federated Semi-supervised Medical Image   Segmentation</h2><p><strong>Authors:Zhipeng Deng, Zhe Xu, Tsuyoshi Isshiki, Yefeng Zheng</strong></p>
<p>Medical image segmentation is challenging due to the diversity of medical images and the lack of labeled data, which motivates recent developments in federated semi-supervised learning (FSSL) to leverage a large amount of unlabeled data from multiple centers for model training without sharing raw data. However, what remains under-explored in FSSL is the domain shift problem which may cause suboptimal model aggregation and low effectivity of the utilization of unlabeled data, eventually leading to unsatisfactory performance in unseen domains. In this paper, we explore this previously ignored scenario, namely domain generalized federated semi-supervised learning (FedSemiDG), which aims to learn a model in a distributed manner from multiple domains with limited labeled data and abundant unlabeled data such that the model can generalize well to unseen domains. We present a novel framework, Federated Generalization-Aware SemiSupervised Learning (FGASL), to address the challenges in FedSemiDG by effectively tackling critical issues at both global and local levels. Globally, we introduce Generalization-Aware Aggregation (GAA), assigning adaptive weights to local models based on their generalization performance. Locally, we use a Dual-Teacher Adaptive Pseudo Label Refinement (DR) strategy to combine global and domain-specific knowledge, generating more reliable pseudo labels. Additionally, Perturbation-Invariant Alignment (PIA) enforces feature consistency under perturbations, promoting domain-invariant learning. Extensive experiments on four medical segmentation tasks (cardiac MRI, spine MRI, bladder cancer MRI and colorectal polyp) demonstrate that our method significantly outperforms state-of-the-art FSSL and domain generalization approaches, achieving robust generalization on unseen domains. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜çš„ä»»åŠ¡ï¼Œå› ä¸ºåŒ»å­¦å›¾åƒå…·æœ‰å¤šæ ·æ€§ä¸”ç¼ºä¹æ ‡è®°æ•°æ®ã€‚è¿™ä¿ƒä½¿äº†è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFSSLï¼‰çš„è¿‘æœŸå‘å±•ï¼Œä»¥åˆ©ç”¨å¤šä¸ªä¸­å¿ƒçš„å¤§é‡æœªæ ‡è®°æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œè€Œæ— éœ€å…±äº«åŸå§‹æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨FSSLä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢çš„æ˜¯åŸŸåç§»é—®é¢˜ï¼Œå®ƒå¯èƒ½å¯¼è‡´æ¨¡å‹èšåˆä¸ä½³ä»¥åŠåˆ©ç”¨æœªæ ‡è®°æ•°æ®çš„æ•ˆæœä½ä¸‹ï¼Œæœ€ç»ˆåœ¨æœªè§çš„åŸŸä¸Šå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä»¥å‰è¢«å¿½ç•¥çš„åœºæ™¯ï¼Œå³é¢†åŸŸé€šç”¨è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFedSemiDGï¼‰ï¼Œå…¶ç›®æ ‡æ˜¯ä»å¤šä¸ªé¢†åŸŸä»¥åˆ†å¸ƒå¼æ–¹å¼å­¦ä¹ æ¨¡å‹ï¼Œä½¿ç”¨æœ‰é™çš„æ ‡è®°æ•°æ®å’Œä¸°å¯Œçš„æœªæ ‡è®°æ•°æ®ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°æ¨å¹¿æœªè§é¢†åŸŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåä¸ºè”é‚¦æ³›åŒ–æ„ŸçŸ¥åŠç›‘ç£å­¦ä¹ ï¼ˆFGASLï¼‰ï¼Œä»¥è§£å†³FedSemiDGä¸­çš„æŒ‘æˆ˜ï¼Œåœ¨å…¨å±€å’Œå±€éƒ¨å±‚é¢æœ‰æ•ˆåœ°è§£å†³å…³é”®é—®é¢˜ã€‚åœ¨å…¨å±€å±‚é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ³›åŒ–æ„ŸçŸ¥èšåˆï¼ˆGAAï¼‰ï¼Œæ ¹æ®å±€éƒ¨æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½åˆ†é…è‡ªé€‚åº”æƒé‡ã€‚åœ¨å±€éƒ¨å±‚é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨åŒæ•™å¸ˆè‡ªé€‚åº”ä¼ªæ ‡ç­¾ç»†åŒ–ï¼ˆDRï¼‰ç­–ç•¥æ¥ç»“åˆå…¨å±€å’Œé¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œç”Ÿæˆæ›´å¯é çš„ä¼ªæ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæ‰°åŠ¨ä¸å˜å¯¹é½ï¼ˆPIAï¼‰å¼ºåˆ¶åœ¨æ‰°åŠ¨ä¸‹ä¿æŒç‰¹å¾ä¸€è‡´æ€§ï¼Œä¿ƒè¿›é¢†åŸŸä¸å˜å­¦ä¹ ã€‚åœ¨å››ä¸ªåŒ»å­¦åˆ†å‰²ä»»åŠ¡ï¼ˆå¿ƒè„MRIã€è„ŠæŸ±MRIã€è†€èƒ±ç™ŒMRIå’Œç»“è‚ æ¯è‚‰ï¼‰ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€æ–°çš„FSSLå’Œé¢†åŸŸé€šç”¨æ–¹æ³•ï¼Œåœ¨æœªè§çš„åŸŸä¸Šå®ç°äº†ç¨³å¥çš„æ³›åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07378v2">PDF</a> 21 pages</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFSSLï¼‰åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„åŸŸåç§»é—®é¢˜ã€‚ç”±äºåŒ»å­¦å›¾åƒçš„å¤šæ ·æ€§å’Œæ ‡è®°æ•°æ®çš„ç¼ºä¹ï¼ŒFSSLåœ¨æ¨¡å‹è®­ç»ƒæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åœºæ™¯ï¼šåŸŸæ³›åŒ–è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFedSemiDGï¼‰ï¼Œæ—¨åœ¨ä»å¤šä¸ªé¢†åŸŸä»¥åˆ†å¸ƒå¼æ–¹å¼å­¦ä¹ æ¨¡å‹ï¼Œç”¨æœ‰é™çš„æ ‡è®°æ•°æ®å’Œå¤§é‡çš„æ— æ ‡è®°æ•°æ®ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æœªè§é¢†åŸŸä¸Šè‰¯å¥½æ³›åŒ–ã€‚ä¸ºäº†è§£å†³FedSemiDGä¸­çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”è”é‚¦æ³›åŒ–æ„ŸçŸ¥åŠç›‘ç£å­¦ä¹ ï¼ˆFGASLï¼‰ï¼Œåœ¨å…¨çƒå’Œåœ°æ–¹å±‚é¢æœ‰æ•ˆåœ°è§£å†³å…³é”®é—®é¢˜ã€‚å…¨çƒå±‚é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ„ŸçŸ¥æ³›åŒ–èšåˆï¼ˆGAAï¼‰ï¼Œæ ¹æ®å±€éƒ¨æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½åˆ†é…è‡ªé€‚åº”æƒé‡ã€‚åœ°æ–¹å±‚é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨åŒæ•™å¸ˆè‡ªé€‚åº”ä¼ªæ ‡ç­¾ç»†åŒ–ï¼ˆDRï¼‰ç­–ç•¥ï¼Œç»“åˆå…¨å±€å’Œé¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œç”Ÿæˆæ›´å¯é çš„ä¼ªæ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæ‰°åŠ¨ä¸å˜å¯¹é½ï¼ˆPIAï¼‰åœ¨æ‰°åŠ¨ä¸‹å¼ºåˆ¶æ‰§è¡Œç‰¹å¾ä¸€è‡´æ€§ï¼Œä¿ƒè¿›é¢†åŸŸä¸å˜å­¦ä¹ ã€‚åœ¨å››ä¸ªåŒ»å­¦åˆ†å‰²ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€æ–°çš„FSSLå’ŒåŸŸæ³›åŒ–æ–¹æ³•ï¼Œåœ¨æœªè§é¢†åŸŸä¸Šå®ç°äº†ç¨³å¥çš„æ³›åŒ–ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´å¤šæ ·æ€§åŠæ ‡è®°æ•°æ®ç¼ºä¹çš„æŒ‘æˆ˜ã€‚</li>
<li>è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFSSLï¼‰åœ¨åˆ©ç”¨æ— æ ‡è®°æ•°æ®æ–¹é¢å±•ç°å‡ºä¼˜åŠ¿ï¼Œä½†åŸŸåç§»é—®é¢˜å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯ï¼šåŸŸæ³›åŒ–è”é‚¦åŠç›‘ç£å­¦ä¹ ï¼ˆFedSemiDGï¼‰ï¼Œæ—¨åœ¨å­¦ä¹ èƒ½é€‚åº”æœªè§é¢†åŸŸçš„æ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼šè”é‚¦æ³›åŒ–æ„ŸçŸ¥åŠç›‘ç£å­¦ä¹ ï¼ˆFGASLï¼‰æ¥è§£å†³FedSemiDGä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>åœ¨å…¨çƒå±‚é¢ï¼Œé€šè¿‡æ„ŸçŸ¥æ³›åŒ–èšåˆï¼ˆGAAï¼‰æ ¹æ®æ³›åŒ–æ€§èƒ½åˆ†é…è‡ªé€‚åº”æƒé‡ã€‚</li>
<li>åœ¨åœ°æ–¹å±‚é¢ï¼Œä½¿ç”¨åŒæ•™å¸ˆè‡ªé€‚åº”ä¼ªæ ‡ç­¾ç»†åŒ–ï¼ˆDRï¼‰ç”Ÿæˆæ›´å¯é çš„ä¼ªæ ‡ç­¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07378">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-41584b53bf9f6fb286923759627bee00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-749ade0ad50f076260a84482d211c3d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5eea2d2c074da88ec3eb22d92512fe89.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="TokenFlow-Unified-Image-Tokenizer-for-Multimodal-Understanding-and-Generation"><a href="#TokenFlow-Unified-Image-Tokenizer-for-Multimodal-Understanding-and-Generation" class="headerlink" title="TokenFlow: Unified Image Tokenizer for Multimodal Understanding and   Generation"></a>TokenFlow: Unified Image Tokenizer for Multimodal Understanding and   Generation</h2><p><strong>Authors:Liao Qu, Huichao Zhang, Yiheng Liu, Xu Wang, Yi Jiang, Yiming Gao, Hu Ye, Daniel K. Du, Zehuan Yuan, Xinglong Wu</strong></p>
<p>We present TokenFlow, a novel unified image tokenizer that bridges the long-standing gap between multimodal understanding and generation. Prior research attempt to employ a single reconstruction-targeted Vector Quantization (VQ) encoder for unifying these two tasks. We observe that understanding and generation require fundamentally different granularities of visual information. This leads to a critical trade-off, particularly compromising performance in multimodal understanding tasks. TokenFlow addresses this challenge through an innovative dual-codebook architecture that decouples semantic and pixel-level feature learning while maintaining their alignment via a shared mapping mechanism. This design enables direct access to both high-level semantic representations crucial for understanding tasks and fine-grained visual features essential for generation through shared indices. Our extensive experiments demonstrate TokenFlowâ€™s superiority across multiple dimensions. Leveraging TokenFlow, we demonstrate for the first time that discrete visual input can surpass LLaVA-1.5 13B in understanding performance, achieving a 7.2% average improvement. For image reconstruction, we achieve a strong FID score of 0.63 at 384<em>384 resolution. Moreover, TokenFlow establishes state-of-the-art performance in autoregressive image generation with a GenEval score of 0.55 at 256</em>256 resolution, achieving comparable results to SDXL. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†TokenFlowï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„ç»Ÿä¸€å›¾åƒåˆ†è¯å™¨ï¼Œå®ƒç¼©å°äº†é•¿æœŸä»¥æ¥å­˜åœ¨äºå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´çš„é¸¿æ²Ÿã€‚å…ˆå‰çš„ç ”ç©¶è¯•å›¾é‡‡ç”¨ä»¥é‡å»ºä¸ºç›®æ ‡çš„å‘é‡é‡åŒ–ï¼ˆVQï¼‰ç¼–ç å™¨æ¥ç»Ÿä¸€è¿™ä¸¤ä¸ªä»»åŠ¡ã€‚æˆ‘ä»¬å‘ç°ï¼Œç†è§£å’Œç”Ÿæˆéœ€è¦ä¸åŒç²’åº¦çš„è§†è§‰ä¿¡æ¯ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªå…³é”®çš„æƒè¡¡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ä¸­çš„æ€§èƒ½å¦¥åã€‚TokenFlowé€šè¿‡åˆ›æ–°çš„åŒç æœ¬æ¶æ„æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥æ¶æ„å°†è¯­ä¹‰å’Œåƒç´ çº§ç‰¹å¾å­¦ä¹ è§£è€¦ï¼ŒåŒæ—¶é€šè¿‡å…±äº«æ˜ å°„æœºåˆ¶ä¿æŒå®ƒä»¬çš„ä¸€è‡´æ€§ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æˆ‘ä»¬å¯ä»¥ç›´æ¥è®¿é—®å¯¹ç†è§£ä»»åŠ¡è‡³å…³é‡è¦çš„é«˜çº§è¯­ä¹‰è¡¨ç¤ºä»¥åŠé€šè¿‡å…±äº«ç´¢å¼•å¯¹ç”Ÿæˆè‡³å…³é‡è¦çš„ç²¾ç»†è§†è§‰ç‰¹å¾ã€‚æˆ‘ä»¬çš„å¹¿æ³›å®éªŒè¯æ˜äº†TokenFlowåœ¨å¤šä¸ªç»´åº¦ä¸Šçš„ä¼˜è¶Šæ€§ã€‚åˆ©ç”¨TokenFlowï¼Œæˆ‘ä»¬é¦–æ¬¡è¯æ˜ç¦»æ•£è§†è§‰è¾“å…¥å¯ä»¥åœ¨ç†è§£æ€§èƒ½ä¸Šè¶…è¶ŠLLaVA-1.5 13Bï¼Œå¹³å‡æé«˜7.2%ã€‚åœ¨å›¾åƒé‡å»ºæ–¹é¢ï¼Œæˆ‘ä»¬åœ¨384*384åˆ†è¾¨ç‡ä¸‹å–å¾—äº†0.63çš„å¼ºFIDåˆ†æ•°ã€‚æ­¤å¤–ï¼ŒTokenFlowåœ¨è‡ªå›å½’å›¾åƒç”Ÿæˆæ–¹é¢å»ºç«‹äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨256*256åˆ†è¾¨ç‡ä¸‹è¾¾åˆ°äº†GenEvalå¾—åˆ†0.55ï¼Œå®ç°äº†ä¸SDXLç›¸å½“çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03069v2">PDF</a> CVPR 2025; Code and models:   <a target="_blank" rel="noopener" href="https://github.com/ByteVisionLab/TokenFlow">https://github.com/ByteVisionLab/TokenFlow</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†TokenFlowï¼Œä¸€ç§æ–°å‹çš„ç»Ÿä¸€å›¾åƒåˆ†è¯å™¨ï¼Œèƒ½å¤Ÿå¼¥åˆé•¿ä¹…ä»¥æ¥å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´çš„é¸¿æ²Ÿã€‚TokenFlowé‡‡ç”¨åˆ›æ–°çš„åŒç æœ¬æ¶æ„ï¼Œè§£å†³äº†ç†è§£å’Œç”Ÿæˆéœ€è¦ä¸åŒç²’åº¦çš„è§†è§‰ä¿¡æ¯çš„é—®é¢˜ï¼Œå®ç°äº†è¯­ä¹‰å’Œåƒç´ çº§ç‰¹å¾å­¦ä¹ çš„è§£è€¦ï¼ŒåŒæ—¶é€šè¿‡å…±äº«æ˜ å°„æœºåˆ¶ä¿æŒå…¶å¯¹é½ã€‚å®éªŒè¡¨æ˜ï¼ŒTokenFlowåœ¨å¤šä¸ªç»´åº¦ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒç†è§£å’Œé‡å»ºæ–¹é¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TokenFlowæ˜¯ä¸€ç§æ–°å‹å›¾åƒåˆ†è¯å™¨ï¼Œèƒ½å¤Ÿå¼¥åˆå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´çš„é¸¿æ²Ÿã€‚</li>
<li>ç°æœ‰ç ”ç©¶å°è¯•ä½¿ç”¨å•ä¸€é‡å»ºç›®æ ‡çš„å‘é‡é‡åŒ–ç¼–ç å™¨æ¥ç»Ÿä¸€è¿™ä¸¤ä¸ªä»»åŠ¡ï¼Œä½†ç†è§£å’Œç”Ÿæˆéœ€è¦ä¸åŒç²’åº¦çš„è§†è§‰ä¿¡æ¯ã€‚</li>
<li>TokenFlowé€šè¿‡åŒç æœ¬æ¶æ„è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå®ç°è¯­ä¹‰å’Œåƒç´ çº§ç‰¹å¾å­¦ä¹ çš„è§£è€¦ã€‚</li>
<li>TokenFlowé€šè¿‡å…±äº«ç´¢å¼•ï¼Œå®ç°é«˜çº§è¯­ä¹‰è¡¨ç¤ºå’Œç²¾ç»†è§†è§‰ç‰¹å¾çš„ç›´æ¥è®¿é—®ã€‚</li>
<li>åœ¨å¤šä¸ªç»´åº¦ä¸Šï¼ŒTokenFlowçš„å®éªŒè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>åœ¨ç†è§£æ€§èƒ½æ–¹é¢ï¼ŒTokenFlowè¶…è¶Šäº†LLaVA-1.5 13Bï¼Œå¹³å‡æ”¹è¿›äº†7.2%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03069">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d937c3e0a789432afd13140c46700154.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-683443eced8096684d91e888647b70ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6db1b568a76a083d3509f797dd0a543b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c57f0bc793711a82a518e32e013468eb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2f14dbca7f3b0b880f3fb32d9f478a5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f711f9f5803cd935c0b27d22bec4facd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a88ed8a2f75b4acb13793c5640d2242b.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Automatic-brain-tumor-segmentation-in-2D-intra-operative-ultrasound-images-using-magnetic-resonance-imaging-tumor-annotations"><a href="#Automatic-brain-tumor-segmentation-in-2D-intra-operative-ultrasound-images-using-magnetic-resonance-imaging-tumor-annotations" class="headerlink" title="Automatic brain tumor segmentation in 2D intra-operative ultrasound   images using magnetic resonance imaging tumor annotations"></a>Automatic brain tumor segmentation in 2D intra-operative ultrasound   images using magnetic resonance imaging tumor annotations</h2><p><strong>Authors:Mathilde Faanes, Ragnhild Holden Helland, Ole Solheim, SÃ©bastien Muller, Ingerid Reinertsen</strong></p>
<p>Automatic segmentation of brain tumors in intra-operative ultrasound (iUS) images could facilitate localization of tumor tissue during resection surgery. The lack of large annotated datasets limits the current models performances. In this paper, we investigated the use of tumor annotations in magnetic resonance imaging (MRI) scans, which are more accessible than annotations in iUS images, for training of deep learning models for iUS brain tumor segmentation. We used 180 annotated MRI scans with corresponding unannotated iUS images, and 29 annotated iUS images. Image registration was performed to transfer the MRI annotations to the corresponding iUS images before training the nnU-Net model with different configurations of the data and label origins. The results showed no significant difference in Dice score for a model trained with only MRI annotated tumors compared to models trained with only iUS annotations and both, and to expert annotations, indicating that MRI tumor annotations can be used as a substitute for iUS tumor annotations to train a deep learning model for automatic brain tumor segmentation in iUS images. The best model obtained an average Dice score of $0.62\pm0.31$, compared to $0.67\pm0.25$ for an expert neurosurgeon, where the performance on larger tumors were similar, but lower for the models on smaller tumors. In addition, the results showed that removing smaller tumors from the training sets improved the results. The main models are available here: <a target="_blank" rel="noopener" href="https://github.com/mathildefaanes/us_brain_tumor_segmentation/tree/main">https://github.com/mathildefaanes/us_brain_tumor_segmentation/tree/main</a> </p>
<blockquote>
<p>åœ¨æœ¯ä¸­è¶…å£°ï¼ˆiUSï¼‰å›¾åƒä¸­è‡ªåŠ¨åˆ†å‰²è„‘è‚¿ç˜¤å¯ä»¥æœ‰åŠ©äºåœ¨åˆ‡é™¤æ‰‹æœ¯æœŸé—´å®šä½è‚¿ç˜¤ç»„ç»‡ã€‚ç¼ºä¹å¤§é‡æ ‡æ³¨æ•°æ®é›†é™åˆ¶äº†å½“å‰æ¨¡å‹çš„è¡¨ç°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ‰«æä¸­ä½¿ç”¨è‚¿ç˜¤æ ‡æ³¨çš„æ–¹æ³•ï¼Œè¿™äº›æ ‡æ³¨æ¯”iUSå›¾åƒä¸­çš„æ ‡æ³¨æ›´å®¹æ˜“è·å¾—ï¼Œç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡ŒiUSè„‘è‚¿ç˜¤åˆ†å‰²ã€‚æˆ‘ä»¬ä½¿ç”¨180ä¸ªæ ‡æ³¨çš„MRIæ‰«æå’Œç›¸åº”çš„æœªæ ‡æ³¨iUSå›¾åƒï¼Œä»¥åŠ29ä¸ªæ ‡æ³¨çš„iUSå›¾åƒã€‚åœ¨å°†MRIæ ‡æ³¨è½¬ç§»åˆ°ç›¸åº”çš„iUSå›¾åƒä¹‹å‰ï¼Œè¿›è¡Œäº†å›¾åƒé…å‡†ï¼Œç„¶åä½¿ç”¨ä¸åŒé…ç½®çš„æ•°æ®å’Œæ ‡ç­¾æ¥æºè®­ç»ƒnnU-Netæ¨¡å‹ã€‚ç»“æœè¡¨æ˜ï¼Œä¸ä»…ä½¿ç”¨iUSæ ‡æ³¨ã€åŒæ—¶ä½¿ç”¨MRIå’ŒiUSæ ‡æ³¨ä»¥åŠä¸“å®¶æ ‡æ³¨è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œä»…ä½¿ç”¨MRIæ ‡æ³¨çš„è‚¿ç˜¤è®­ç»ƒçš„æ¨¡å‹çš„Diceå¾—åˆ†æ²¡æœ‰æ˜¾è‘—å·®å¼‚ï¼Œè¿™è¡¨æ˜MRIè‚¿ç˜¤æ ‡æ³¨å¯ä»¥ä½œä¸ºæ›¿ä»£iUSè‚¿ç˜¤æ ‡æ³¨æ¥è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥è‡ªåŠ¨è¿›è¡ŒiUSå›¾åƒä¸­çš„è„‘è‚¿ç˜¤åˆ†å‰²ã€‚æœ€ä½³æ¨¡å‹è·å¾—çš„å¹³å‡Diceå¾—åˆ†ä¸º$0.62\pm0.31$ï¼Œè€Œä¸“å®¶ç¥ç»å¤–ç§‘åŒ»ç”Ÿçš„å¾—åˆ†ä¸º$0.67\pm0.25$ï¼Œå¯¹äºè¾ƒå¤§çš„è‚¿ç˜¤ï¼Œä¸¤è€…æ€§èƒ½ç›¸ä¼¼ï¼Œä½†å¯¹è¾ƒå°è‚¿ç˜¤çš„æ¨¡å‹æ€§èƒ½è¾ƒä½ã€‚æ­¤å¤–ï¼Œç»“æœè¿˜è¡¨æ˜ï¼Œä»è®­ç»ƒé›†ä¸­å»é™¤è¾ƒå°çš„è‚¿ç˜¤å¯ä»¥æé«˜ç»“æœã€‚ä¸»è¦æ¨¡å‹å¯åœ¨æ­¤å¤„æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/mathildefaanes/us_brain_tumor_segmentation/tree/main">https://github.com/mathildefaanes/us_brain_tumor_segmentation/tree/main</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.14017v2">PDF</a> 14, 5figures. This work has been submitted to the IEEE for possible   publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ‰«æä¸­çš„è‚¿ç˜¤æ³¨é‡Šä¿¡æ¯è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥åœ¨æœ¯ä¸­è¶…å£°ï¼ˆiUSï¼‰å›¾åƒä¸­å®ç°è‡ªåŠ¨è„‘è‚¿ç˜¤åˆ†å‰²çš„å¯èƒ½æ€§ã€‚ç ”ç©¶é‡‡ç”¨MRIæ‰«æä¸­çš„è‚¿ç˜¤æ³¨é‡Šä¿¡æ¯æ›¿ä»£iUSå›¾åƒä¸­çš„è‚¿ç˜¤æ³¨é‡Šä¿¡æ¯ï¼Œå¹¶å‘ç°è®­ç»ƒå‡ºçš„æ¨¡å‹æ€§èƒ½ä¸ä¸“å®¶æ³¨é‡Šç›¸å½“ã€‚æœ€ä½³æ¨¡å‹çš„å¹³å‡Diceç³»æ•°ä¸º$0.62Â±0.31$ï¼Œä¸ä¸“å®¶ç¥ç»å¤–ç§‘åŒ»ç”Ÿçš„æ€§èƒ½æ¥è¿‘ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°å»é™¤è®­ç»ƒé›†ä¸­çš„å°è‚¿ç˜¤å¯ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤é¡¹ç›®çš„ä¸»è¦æ¨¡å‹å·²åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨MRIæ‰«æä¸­çš„è‚¿ç˜¤æ³¨é‡Šä¿¡æ¯è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ä»¥å®ç°æœ¯ä¸­è¶…å£°å›¾åƒä¸­çš„è„‘è‚¿ç˜¤è‡ªåŠ¨åˆ†å‰²ã€‚</li>
<li>ä½¿ç”¨MRIè‚¿ç˜¤æ³¨é‡Šä¿¡æ¯ä½œä¸ºæ›¿ä»£iUSè‚¿ç˜¤æ³¨é‡Šä¿¡æ¯è®­ç»ƒæ¨¡å‹ï¼Œæ€§èƒ½ä¸ä¸“å®¶æ³¨é‡Šç›¸å½“ã€‚</li>
<li>æœ€ä½³æ¨¡å‹çš„å¹³å‡Diceç³»æ•°ä¸º$0.62Â±0.31$ï¼Œä¸ä¸“å®¶ç¥ç»å¤–ç§‘åŒ»ç”Ÿæ€§èƒ½æ¥è¿‘ã€‚</li>
<li>æ¨¡å‹åœ¨å¤§è‚¿ç˜¤ä¸Šçš„æ€§èƒ½è‰¯å¥½ï¼Œä½†åœ¨å°è‚¿ç˜¤ä¸Šçš„æ€§èƒ½è¾ƒä½ã€‚</li>
<li>å»é™¤è®­ç»ƒé›†ä¸­çš„å°è‚¿ç˜¤å¯ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.14017">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f51a1196393491fbbd16f1272d601a8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-557a7bab61e43d80c9e5e9708361a4d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1c00c2269b27177ccfd3a4b2c49ec5a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CAD-MLLM-Unifying-Multimodality-Conditioned-CAD-Generation-With-MLLM"><a href="#CAD-MLLM-Unifying-Multimodality-Conditioned-CAD-Generation-With-MLLM" class="headerlink" title="CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM"></a>CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM</h2><p><strong>Authors:Jingwei Xu, Chenyu Wang, Zibo Zhao, Wen Liu, Yi Ma, Shenghua Gao</strong></p>
<p>This paper aims to design a unified Computer-Aided Design (CAD) generation system that can easily generate CAD models based on the userâ€™s inputs in the form of textual description, images, point clouds, or even a combination of them. Towards this goal, we introduce the CAD-MLLM, the first system capable of generating parametric CAD models conditioned on the multimodal input. Specifically, within the CAD-MLLM framework, we leverage the command sequences of CAD models and then employ advanced large language models (LLMs) to align the feature space across these diverse multi-modalities data and CAD modelsâ€™ vectorized representations. To facilitate the model training, we design a comprehensive data construction and annotation pipeline that equips each CAD model with corresponding multimodal data. Our resulting dataset, named Omni-CAD, is the first multimodal CAD dataset that contains textual description, multi-view images, points, and command sequence for each CAD model. It contains approximately 450K instances and their CAD construction sequences. To thoroughly evaluate the quality of our generated CAD models, we go beyond current evaluation metrics that focus on reconstruction quality by introducing additional metrics that assess topology quality and surface enclosure extent. Extensive experimental results demonstrate that CAD-MLLM significantly outperforms existing conditional generative methods and remains highly robust to noises and missing points. The project page and more visualizations can be found at: <a target="_blank" rel="noopener" href="https://cad-mllm.github.io/">https://cad-mllm.github.io/</a> </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿè½»æ¾æ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘ç”šè‡³å®ƒä»¬çš„ç»„åˆå½¢å¼ç­‰è¾“å…¥æ¥ç”ŸæˆCADæ¨¡å‹ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†CAD-MLLMç³»ç»Ÿï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡å¼è¾“å…¥ç”Ÿæˆå‚æ•°åŒ–CADæ¨¡å‹çš„ç³»ç»Ÿã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨CAD-MLLMæ¡†æ¶å†…ï¼Œæˆ‘ä»¬åˆ©ç”¨CADæ¨¡å‹çš„å‘½ä»¤åºåˆ—ï¼Œç„¶åé‡‡ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å¯¹é½è¿™äº›å¤šæ ·åŒ–çš„å¤šæ¨¡å¼æ•°æ®ä»¥åŠCADæ¨¡å‹çš„å‘é‡è¡¨ç¤ºçš„ç‰¹å¾ç©ºé—´ã€‚ä¸ºäº†ä¿ƒè¿›æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç»¼åˆçš„æ•°æ®æ„å»ºå’Œæ³¨é‡Šç®¡é“ï¼Œä½¿æ¯ä¸ªCADæ¨¡å‹éƒ½é…å¤‡ç›¸åº”çš„å¤šæ¨¡å¼æ•°æ®ã€‚æˆ‘ä»¬ç”±æ­¤æ„å»ºçš„æ•°æ®é›†åä¸ºOmni-CADï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªåŒ…å«æ–‡æœ¬æè¿°ã€å¤šè§†è§’å›¾åƒã€ç‚¹å’Œæ¯ä¸ªCADæ¨¡å‹çš„å‘½ä»¤åºåˆ—çš„å¤šæ¨¡å¼CADæ•°æ®é›†ã€‚å®ƒåŒ…å«å¤§çº¦45ä¸‡å®ä¾‹åŠå…¶CADæ„å»ºåºåˆ—ã€‚ä¸ºäº†å…¨é¢è¯„ä¼°æˆ‘ä»¬ç”Ÿæˆçš„CADæ¨¡å‹çš„è´¨é‡ï¼Œæˆ‘ä»¬è¶…è¶Šäº†å½“å‰ä»¥é‡å»ºè´¨é‡ä¸ºé‡ç‚¹çš„è¯„ä»·æŒ‡æ ‡ï¼Œå¼•å…¥äº†å…¶ä»–è¯„ä¼°æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦çš„æŒ‡æ ‡ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜ï¼ŒCAD-MLLMæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶å¯¹å™ªå£°å’Œç¼ºå¤±ç‚¹å…·æœ‰é«˜åº¦é²æ£’æ€§ã€‚é¡¹ç›®é¡µé¢å’Œæ›´å¤šå¯è§†åŒ–å†…å®¹å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://cad-mllm.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://cad-mllm.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04954v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://cad-mllm.github.io/">https://cad-mllm.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç»Ÿä¸€è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘æˆ–å®ƒä»¬çš„ç»„åˆä½œä¸ºè¾“å…¥ï¼Œè½»æ¾ç”ŸæˆCADæ¨¡å‹ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œå¼•å…¥äº†CAD-MLLMç³»ç»Ÿï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡å¼è¾“å…¥ç”Ÿæˆå‚æ•°åŒ–CADæ¨¡å‹çš„ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨CADæ¨¡å‹çš„å‘½ä»¤åºåˆ—ï¼Œå¹¶é‡‡ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å¯¹é½å„ç§å¤šæ¨¡å¼æ•°æ®å’ŒCADæ¨¡å‹çš„å‘é‡è¡¨ç¤ºçš„ç‰¹å¾ç©ºé—´ã€‚ä¸ºå¸®åŠ©æ¨¡å‹è®­ç»ƒï¼Œè®¾è®¡äº†ä¸€ä¸ªå…¨é¢çš„æ•°æ®æ„å»ºå’Œæ³¨é‡Šç®¡é“ï¼Œä¸ºæ¯ä¸ªCADæ¨¡å‹é…å¤‡ç›¸åº”çš„å¤šæ¨¡å¼æ•°æ®ï¼Œæ„å»ºäº†åä¸ºOmni-CADçš„å¤šæ¨¡å¼CADæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦ç­‰è¯„ä¼°æŒ‡æ ‡æ¥å…¨é¢è¯„ä¼°ç”Ÿæˆçš„CADæ¨¡å‹çš„è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCAD-MLLMæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¯¹å™ªå£°å’Œç¼ºå¤±ç‚¹å…·æœ‰é«˜åº¦é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æ—¨åœ¨è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„CADç”Ÿæˆç³»ç»Ÿï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„å¤šç§è¾“å…¥ï¼ˆæ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘ç­‰ï¼‰è½»æ¾ç”ŸæˆCADæ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†CAD-MLLMç³»ç»Ÿï¼Œé¦–æ¬¡å®ç°åŸºäºå¤šæ¨¡å¼è¾“å…¥çš„æ¡ä»¶åŒ–CADæ¨¡å‹ç”Ÿæˆã€‚</li>
<li>CAD-MLLMåˆ©ç”¨CADæ¨¡å‹çš„å‘½ä»¤åºåˆ—ï¼Œå¹¶é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç‰¹å¾ç©ºé—´å¯¹é½ã€‚</li>
<li>ä¸ºæ”¯æŒæ¨¡å‹è®­ç»ƒï¼Œæ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„æ•°æ®æ„å»ºå’Œæ³¨é‡Šç®¡é“ï¼Œå¹¶åˆ›å»ºäº†Omni-CADå¤šæ¨¡å¼CADæ•°æ®é›†ã€‚</li>
<li>æå‡ºçš„è¯„ä¼°æ–¹æ³•ä¸ä»…å…³æ³¨é‡å»ºè´¨é‡ï¼Œè¿˜è€ƒè™‘äº†æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCAD-MLLMåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¡ä»¶ç”Ÿæˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04954">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-00ff8b1e582a8839513395ab62342581.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ba06e8d214bcc0ee060e128f7226eda.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aa8d1a1d4b31d59a0f30f7497f93921e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b47c10290fd454e4f494b72e84a48e14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fcdc14370ba9c184b9458c5bbb593106.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3fd48db3d2935b92e4ef0101272188b5.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DiffGAN-A-Test-Generation-Approach-for-Differential-Testing-of-Deep-Neural-Networks-for-Image-Analysis"><a href="#DiffGAN-A-Test-Generation-Approach-for-Differential-Testing-of-Deep-Neural-Networks-for-Image-Analysis" class="headerlink" title="DiffGAN: A Test Generation Approach for Differential Testing of Deep   Neural Networks for Image Analysis"></a>DiffGAN: A Test Generation Approach for Differential Testing of Deep   Neural Networks for Image Analysis</h2><p><strong>Authors:Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S</strong></p>
<p>Deep Neural Networks (DNNs) are increasingly deployed across applications. However, ensuring their reliability remains a challenge, and in many situations, alternative models with similar functionality and accuracy are available. Traditional accuracy-based evaluations often fail to capture behavioral differences between models, especially with limited test datasets, making it difficult to select or combine models effectively. Differential testing addresses this by generating test inputs that expose discrepancies in DNN model behavior. However, existing approaches face significant limitations: many rely on model internals or are constrained by available seed inputs. To address these challenges, we propose DiffGAN, a black-box test image generation approach for differential testing of DNN models. DiffGAN leverages a Generative Adversarial Network (GAN) and the Non-dominated Sorting Genetic Algorithm II to generate diverse and valid triggering inputs that reveal behavioral discrepancies between models. DiffGAN employs two custom fitness functions, focusing on diversity and divergence, to guide the exploration of the GAN input space and identify discrepancies between modelsâ€™ outputs. By strategically searching this space, DiffGAN generates inputs with specific features that trigger differences in model behavior. DiffGAN is black-box, making it applicable in more situations. We evaluate DiffGAN on eight DNN model pairs trained on widely used image datasets. Our results show DiffGAN significantly outperforms a SOTA baseline, generating four times more triggering inputs, with greater diversity and validity, within the same budget. Additionally, the generated inputs improve the accuracy of a machine learning-based model selection mechanism, which selects the best-performing model based on input characteristics and can serve as a smart output voting mechanism when using alternative models. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨å„åº”ç”¨é¢†åŸŸä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ã€‚ç„¶è€Œï¼Œç¡®ä¿å…¶å¯é æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè€Œä¸”åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå­˜åœ¨å…·æœ‰ç›¸ä¼¼åŠŸèƒ½å’Œå‡†ç¡®æ€§çš„æ›¿ä»£æ¨¡å‹ã€‚ä¼ ç»Ÿçš„åŸºäºå‡†ç¡®æ€§çš„è¯„ä¼°å¾€å¾€æ— æ³•æ•æ‰åˆ°æ¨¡å‹ä¹‹é—´çš„è¡Œä¸ºå·®å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é™çš„æµ‹è¯•æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œä½¿å¾—éš¾ä»¥æœ‰æ•ˆåœ°é€‰æ‹©æˆ–ç»„åˆæ¨¡å‹ã€‚å·®åˆ†æµ‹è¯•é€šè¿‡ç”Ÿæˆæµ‹è¯•è¾“å…¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™äº›è¾“å…¥èƒ½å¤Ÿæš´éœ²DNNæ¨¡å‹è¡Œä¸ºä¹‹é—´çš„å·®å¼‚ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨é‡å¤§å±€é™æ€§ï¼šè®¸å¤šæ–¹æ³•ä¾èµ–äºæ¨¡å‹å†…éƒ¨ä¿¡æ¯æˆ–å—åˆ°å¯ç”¨ç§å­è¾“å…¥çš„çº¦æŸã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DiffGANï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºDNNæ¨¡å‹å·®åˆ†æµ‹è¯•çš„é»‘è‰²ç›’å­æµ‹è¯•å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚DiffGANåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIæ¥ç”Ÿæˆå¤šæ ·ä¸”æœ‰æ•ˆçš„è§¦å‘è¾“å…¥ï¼Œè¿™äº›è¾“å…¥èƒ½å¤Ÿæ­ç¤ºæ¨¡å‹ä¹‹é—´çš„è¡Œä¸ºå·®å¼‚ã€‚DiffGANé‡‡ç”¨ä¸¤ä¸ªè‡ªå®šä¹‰çš„é€‚åº”åº¦å‡½æ•°ï¼Œä¾§é‡äºå¤šæ ·æ€§å’Œå‘æ•£æ€§ï¼Œä»¥æŒ‡å¯¼GANè¾“å…¥ç©ºé—´çš„æ¢ç´¢å¹¶è¯†åˆ«æ¨¡å‹è¾“å‡ºä¹‹é—´çš„å·®å¼‚ã€‚é€šè¿‡æœ‰é’ˆå¯¹æ€§åœ°æœç´¢è¿™ä¸ªç©ºé—´ï¼ŒDiffGANç”Ÿæˆå…·æœ‰ç‰¹å®šç‰¹å¾çš„è¾“å…¥ï¼Œè¿™äº›è¾“å…¥èƒ½å¤Ÿè§¦å‘æ¨¡å‹è¡Œä¸ºçš„å·®å¼‚ã€‚DiffGANæ˜¯é»‘è‰²ç›’å­çš„ï¼Œä½¿å…¶èƒ½åœ¨æ›´å¤šæƒ…å†µä¸‹é€‚ç”¨ã€‚æˆ‘ä»¬åœ¨ä½¿ç”¨å¹¿æ³›ä½¿ç”¨çš„å›¾åƒæ•°æ®é›†è®­ç»ƒçš„å…«ä¸ªDNNæ¨¡å‹å¯¹ä¸Šè¯„ä¼°äº†DiffGANã€‚ç»“æœè¡¨æ˜ï¼ŒDiffGANæ˜¾è‘—ä¼˜äºæœ€æ–°æŠ€æœ¯åŸºçº¿ï¼Œåœ¨ç›¸åŒçš„é¢„ç®—å†…ï¼Œç”Ÿæˆäº†å››å€å¤šçš„è§¦å‘è¾“å…¥ï¼Œå…·æœ‰æ›´å¤§çš„å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„è¾“å…¥æé«˜äº†åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹çš„é€‰å‹æœºåˆ¶çš„å‡†ç¡®æ€§ï¼Œè¯¥æœºåˆ¶æ ¹æ®è¾“å…¥ç‰¹å¾é€‰æ‹©æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ï¼Œå½“ä½¿ç”¨æ›¿ä»£æ¨¡å‹æ—¶ï¼Œå®ƒå¯ä»¥ä½œä¸ºæ™ºèƒ½è¾“å‡ºæŠ•ç¥¨æœºåˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19794v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIçš„å·®åˆ†æµ‹è¯•æ–¹æ³•ï¼ˆDiffGANï¼‰ï¼Œç”¨äºå¯¹æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨¡å‹è¿›è¡Œè¡Œä¸ºå·®å¼‚æµ‹è¯•ã€‚DiffGANæ—¨åœ¨ç”Ÿæˆèƒ½å¤Ÿæ­ç¤ºæ¨¡å‹è¡Œä¸ºå·®å¼‚çš„è§¦å‘è¾“å…¥ï¼Œé€šè¿‡ä¸¤ä¸ªè‡ªå®šä¹‰çš„é€‚åº”åº¦å‡½æ•°ï¼ˆå¤šæ ·æ€§å’Œå‘æ•£æ€§ï¼‰æ¥æŒ‡å¯¼GANè¾“å…¥ç©ºé—´çš„æ¢ç´¢ã€‚DiffGANå…·æœ‰é»‘ç›’ç‰¹æ€§ï¼Œé€‚ç”¨äºæ›´å¤šåœºæ™¯ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒçš„å…«ä¸ªDNNæ¨¡å‹å¯¹çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒDiffGANæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œç”Ÿæˆäº†æ›´å¤šè§¦å‘è¾“å…¥ï¼Œå¹¶æé«˜äº†æœºå™¨å­¦ä¹ æ¨¡å‹é€‰æ‹©æœºåˆ¶çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Deep Neural Networks (DNNs)çš„å¯é æ€§ä¿è¯æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æœ‰é™æµ‹è¯•æ•°æ®é›†çš„æƒ…å†µä¸‹ã€‚</li>
<li>å·®å¼‚æµ‹è¯•é€šè¿‡ç”Ÿæˆæµ‹è¯•è¾“å…¥æ¥æ­ç¤ºDNNæ¨¡å‹ä¹‹é—´çš„å·®å¼‚ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>DiffGANæ˜¯ä¸€ç§é’ˆå¯¹DNNæ¨¡å‹çš„å·®åˆ†æµ‹è¯•æ–°æ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIç”Ÿæˆè§¦å‘è¾“å…¥ã€‚</li>
<li>DiffGANå…·æœ‰é»‘ç›’ç‰¹æ€§ï¼Œé€‚ç”¨äºæ›´å¤šåœºæ™¯ã€‚</li>
<li>DiffGANé€šè¿‡ä¸¤ä¸ªè‡ªå®šä¹‰çš„é€‚åº”åº¦å‡½æ•°ï¼ˆå¤šæ ·æ€§å’Œå‘æ•£æ€§ï¼‰æ¥æŒ‡å¯¼GANè¾“å…¥ç©ºé—´çš„æ¢ç´¢ï¼Œä»¥å‘ç°æ¨¡å‹è¡Œä¸ºå·®å¼‚ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒDiffGANç”Ÿæˆçš„è§¦å‘è¾“å…¥æ•°é‡æ›´å¤šã€æ›´å…·å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0206045ee3e12efecdf5df2fbb5716dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e88181c6c833cb35924054350f21e65.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-12/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-4eb0c7372993f511c3987360e26ee704.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-12  MoDA Multi-modal Diffusion Architecture for Talking Head Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-11/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-42d76b246d84322f1c5364930f29a881.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-11  CRAFT Your Dataset Task-Specific Synthetic Dataset Generation Through   Corpus Retrieval and Augmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31180k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
