<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  Explaining Decentralized Multi-Agent Reinforcement Learning Policies">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-1f6452c3b68d6ea66c075c46913538e2')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    64 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-17-æ›´æ–°"><a href="#2025-11-17-æ›´æ–°" class="headerlink" title="2025-11-17 æ›´æ–°"></a>2025-11-17 æ›´æ–°</h1><h2 id="Explaining-Decentralized-Multi-Agent-Reinforcement-Learning-Policies"><a href="#Explaining-Decentralized-Multi-Agent-Reinforcement-Learning-Policies" class="headerlink" title="Explaining Decentralized Multi-Agent Reinforcement Learning Policies"></a>Explaining Decentralized Multi-Agent Reinforcement Learning Policies</h2><p><strong>Authors:Kayla Boggess, Sarit Kraus, Lu Feng</strong></p>
<p>Multi-Agent Reinforcement Learning (MARL) has gained significant interest in recent years, enabling sequential decision-making across multiple agents in various domains. However, most existing explanation methods focus on centralized MARL, failing to address the uncertainty and nondeterminism inherent in decentralized settings. We propose methods to generate policy summarizations that capture task ordering and agent cooperation in decentralized MARL policies, along with query-based explanations for When, Why Not, and What types of user queries about specific agent behaviors. We evaluate our approach across four MARL domains and two decentralized MARL algorithms, demonstrating its generalizability and computational efficiency. User studies show that our summarizations and explanations significantly improve user question-answering performance and enhance subjective ratings on metrics such as understanding and satisfaction.</p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å—åˆ°äº†å¹¿æ³›å…³æ³¨ï¼Œå®ƒèƒ½å¤Ÿåœ¨å„ä¸ªé¢†åŸŸå®ç°å¤šä¸ªæ™ºèƒ½ä½“çš„åºè´¯å†³ç­–ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è§£é‡Šæ–¹æ³•å¤§å¤šé›†ä¸­åœ¨é›†ä¸­å¼çš„MARLä¸Šï¼Œæ— æ³•è§£å†³å»ä¸­å¿ƒåŒ–è®¾ç½®ä¸­å›ºæœ‰çš„ä¸ç¡®å®šæ€§å’Œéå†³å®šæ€§ã€‚æˆ‘ä»¬æå‡ºäº†ç”Ÿæˆç­–ç•¥æ‘˜è¦çš„æ–¹æ³•ï¼Œä»¥æ•è·å»ä¸­å¿ƒåŒ–MARLç­–ç•¥ä¸­çš„ä»»åŠ¡æ’åºå’Œæ™ºèƒ½ä½“åˆä½œï¼Œä»¥åŠåŸºäºæŸ¥è¯¢çš„è§£é‡Šï¼Œç”¨äºç”¨æˆ·å…³äºç‰¹å®šæ™ºèƒ½ä½“è¡Œä¸ºçš„ä½•æ—¶ã€ä¸ºä»€ä¹ˆä¸ã€ä»€ä¹ˆç±»å‹çš„æŸ¥è¯¢ã€‚æˆ‘ä»¬åœ¨å››ä¸ªMARLé¢†åŸŸå’Œä¸¤ä¸ªå»ä¸­å¿ƒåŒ–MARLç®—æ³•ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜äº†å…¶é€šç”¨æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ‘˜è¦å’Œè§£é‡Šæ˜¾è‘—æé«˜äº†ç”¨æˆ·çš„é—®é¢˜å›ç­”æ€§èƒ½ï¼Œå¹¶åœ¨ç†è§£åº¦å’Œæ»¡æ„åº¦ç­‰æŒ‡æ ‡ä¸Šæé«˜äº†ä¸»è§‚è¯„åˆ†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10409v1">PDF</a> Accepted for oral presentation at AAAI-26</p>
<p><strong>Summary</strong>ï¼š<br>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œå¯å®ç°å¤šä¸ªæ™ºèƒ½ä½“åœ¨å„ç§é¢†åŸŸä¸­çš„åºè´¯å†³ç­–ã€‚ç„¶è€Œï¼Œç°æœ‰è§£é‡Šæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é›†ä¸­å¼çš„MARLï¼Œæ— æ³•è§£å†³å»ä¸­å¿ƒåŒ–è®¾ç½®ä¸­çš„ä¸ç¡®å®šæ€§å’Œéç¡®å®šæ€§ã€‚æœ¬æ–‡æå‡ºç”Ÿæˆç­–ç•¥æ‘˜è¦çš„æ–¹æ³•ï¼Œæ•è·å»ä¸­å¿ƒåŒ–MARLç­–ç•¥ä¸­çš„ä»»åŠ¡æ’åºå’Œæ™ºèƒ½ä½“åˆä½œï¼Œå¹¶æä¾›åŸºäºæŸ¥è¯¢çš„è§£é‡Šï¼Œå›ç­”å…³äºç‰¹å®šæ™ºèƒ½ä½“è¡Œä¸ºçš„ä½•æ—¶ã€ä½•åŸå› ä¸ã€ä½•ç§ç±»å‹çš„é—®é¢˜ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å…·æœ‰é€šç”¨æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæ‘˜è¦å’Œè§£é‡Šæ˜¾è‘—æé«˜äº†ç”¨æˆ·çš„é—®é¢˜å›ç­”æ€§èƒ½ï¼Œå¹¶æé«˜äº†ç†è§£å’Œæ»¡æ„åº¦çš„ä¸»è§‚è¯„ä»·ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å…è®¸å¤šä¸ªæ™ºèƒ½ä½“è¿›è¡Œåºè´¯å†³ç­–ï¼Œåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰åº”ç”¨æ½œåŠ›ã€‚</li>
<li>ç°æœ‰è§£é‡Šæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é›†ä¸­å¼MARLï¼Œéš¾ä»¥å¤„ç†å»ä¸­å¿ƒåŒ–ç¯å¢ƒä¸­çš„ä¸ç¡®å®šæ€§å’Œéç¡®å®šæ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºç”Ÿæˆç­–ç•¥æ‘˜è¦çš„æ–¹æ³•ï¼Œèƒ½æ•è·å»ä¸­å¿ƒåŒ–MARLä¸­çš„ä»»åŠ¡æ’åºå’Œæ™ºèƒ½ä½“åˆä½œã€‚</li>
<li>æä¾›åŸºäºæŸ¥è¯¢çš„è§£é‡Šï¼Œèƒ½å¤Ÿå›ç­”å…³äºç‰¹å®šæ™ºèƒ½ä½“è¡Œä¸ºçš„ä¸åŒé—®é¢˜ç±»å‹ã€‚</li>
<li>æ–¹æ³•åœ¨å››ä¸ªMARLé¢†åŸŸå’Œä¸¤ä¸ªå»ä¸­å¿ƒåŒ–MARLç®—æ³•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œè¯æ˜äº†å…¶é€šç”¨æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>ç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„æ‘˜è¦å’Œè§£é‡Šæé«˜äº†ç”¨æˆ·çš„é—®é¢˜å›ç­”èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bdd9c561f27f89d2eabd3d6267cc6784" align="middle">
<img src="https://picx.zhimg.com/v2-bb4a792029666d22733c01d882ec2493" align="middle">
<img src="https://picx.zhimg.com/v2-6a8759d6e8a7e2740f0a1c7e3781355a" align="middle">
<img src="https://picx.zhimg.com/v2-42827612c3a219bdfb855da28591b516" align="middle">
<img src="https://picx.zhimg.com/v2-2bb068d532081a9fc7b4d07cb9ab9246" align="middle">
<img src="https://picx.zhimg.com/v2-16ab0bbf9c028d99cefffb29ec688c47" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="VISTA-A-Vision-and-Intent-Aware-Social-Attention-Framework-for-Multi-Agent-Trajectory-Prediction"><a href="#VISTA-A-Vision-and-Intent-Aware-Social-Attention-Framework-for-Multi-Agent-Trajectory-Prediction" class="headerlink" title="VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction"></a>VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction</h2><p><strong>Authors:Stephane Da Silva Martins, Emanuel Aldea, Sylvie Le HÃ©garat-Mascle</strong></p>
<p>Multi-agent trajectory prediction is crucial for autonomous systems operating in dense, interactive environments. Existing methods often fail to jointly capture agentsâ€™ long-term goals and their fine-grained social interactions, which leads to unrealistic multi-agent futures. We propose VISTA, a recursive goal-conditioned transformer for multi-agent trajectory forecasting. VISTA combines (i) a cross-attention fusion module that integrates long-horizon intent with past motion, (ii) a social-token attention mechanism for flexible interaction modeling across agents, and (iii) pairwise attention maps that make social influence patterns interpretable at inference time. Our model turns single-agent goal-conditioned prediction into a coherent multi-agent forecasting framework. Beyond standard displacement metrics, we evaluate trajectory collision rates as a measure of joint realism. On the high-density MADRAS benchmark and on SDD, VISTA achieves state-of-the-art accuracy and substantially fewer collisions. On MADRAS, it reduces the average collision rate of strong baselines from 2.14 to 0.03 percent, and on SDD it attains zero collisions while improving ADE, FDE, and minFDE. These results show that VISTA generates socially compliant, goal-aware, and interpretable trajectories, making it promising for safety-critical autonomous systems.</p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹å¯¹äºåœ¨å¯†é›†ã€äº¤äº’ç¯å¢ƒä¸­è¿è¡Œçš„è‡ªä¸»ç³»ç»Ÿè‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¸èƒ½è”åˆæ•æ‰æ™ºèƒ½ä½“çš„é•¿æœŸç›®æ ‡å’Œç²¾ç»†çš„ç¤¾ä¼šäº’åŠ¨ï¼Œä»è€Œå¯¼è‡´ä¸åˆ‡å®é™…çš„å¤šæ™ºèƒ½ä½“æœªæ¥ã€‚æˆ‘ä»¬æå‡ºäº†VISTAï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¤šæ™ºèƒ½ä½“è½¨è¿¹é¢„æµ‹çš„é€’å½’ç›®æ ‡æ¡ä»¶å˜å‹å™¨ã€‚VISTAç»“åˆäº†ï¼ˆiï¼‰ä¸€ç§è·¨æ³¨æ„åŠ›èåˆæ¨¡å—ï¼Œè¯¥æ¨¡å—å°†é•¿æœŸæ„å›¾ä¸è¿‡å»åŠ¨ä½œç›¸ç»“åˆï¼Œï¼ˆiiï¼‰ä¸€ç§ç¤¾ä¼šä»¤ç‰Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºæ™ºèƒ½ä½“ä¹‹é—´çš„çµæ´»äº¤äº’å»ºæ¨¡ï¼Œä»¥åŠï¼ˆiiiï¼‰æˆå¯¹æ³¨æ„åŠ›å›¾ï¼Œå¯åœ¨æ¨ç†æ—¶è§£é‡Šç¤¾ä¼šå½±å“æ¨¡å¼ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†å•æ™ºèƒ½ä½“ç›®æ ‡æ¡ä»¶é¢„æµ‹è½¬åŒ–ä¸ºè¿è´¯çš„å¤šæ™ºèƒ½ä½“é¢„æµ‹æ¡†æ¶ã€‚é™¤äº†æ ‡å‡†ä½ç§»æŒ‡æ ‡å¤–ï¼Œæˆ‘ä»¬è¿˜è¯„ä¼°è½¨è¿¹ç¢°æ’ç‡ä½œä¸ºè”åˆç°å®æ€§çš„è¡¡é‡æ ‡å‡†ã€‚åœ¨é«˜å¯†åº¦çš„MADRASåŸºå‡†æµ‹è¯•å’ŒSDDä¸Šï¼ŒVISTAè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œç¢°æ’æ¬¡æ•°å¤§å¤§å‡å°‘ã€‚åœ¨MADRASä¸Šï¼Œå®ƒå°†å¼ºåŸºå‡†çš„å¹³å‡ç¢°æ’ç‡ä»2.14%é™ä½åˆ°0.03%ï¼Œåœ¨SDDä¸Šå®ç°äº†é›¶ç¢°æ’ï¼ŒåŒæ—¶æé«˜äº†ADEã€FDEå’ŒminFDEã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVISTAèƒ½å¤Ÿç”Ÿæˆç¬¦åˆç¤¾ä¼šè§„èŒƒã€å…·æœ‰ç›®æ ‡æ„è¯†å’Œå¯è§£é‡Šæ€§çš„è½¨è¿¹ï¼Œå¯¹äºå®‰å…¨å…³é”®çš„è‡ªä¸»ç³»ç»Ÿæ¥è¯´å…·æœ‰å¹¿é˜”å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10203v1">PDF</a> Paper accepted at WACV 2026</p>
<p><strong>Summary</strong></p>
<p>å¤šä»£ç†è½¨è¿¹é¢„æµ‹å¯¹äºåœ¨å¯†é›†ã€äº¤äº’ç¯å¢ƒä¸­è¿è¡Œè‡ªä¸»ç³»ç»Ÿè‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•è”åˆæ•è·ä»£ç†çš„é•¿æœŸç›®æ ‡å’Œç²¾ç»†çš„ç¤¾ä¼šäº’åŠ¨ï¼Œå¯¼è‡´æœªæ¥å¤šä»£ç†è½¨è¿¹é¢„æµ‹ä¸çœŸå®ã€‚æœ¬æ–‡æå‡ºVISTAï¼Œä¸€ç§ç”¨äºå¤šä»£ç†è½¨è¿¹é¢„æµ‹çš„é€’å½’ç›®æ ‡æ¡ä»¶å˜å‹å™¨ã€‚VISTAç»“åˆäº†è·¨æ³¨æ„åŠ›èåˆæ¨¡å—ï¼Œå°†é•¿æœŸæ„å›¾ä¸è¿‡å»åŠ¨ä½œç›¸ç»“åˆï¼Œé‡‡ç”¨ç¤¾äº¤ä»¤ç‰Œæ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œçµæ´»çš„è·¨ä»£ç†äº¤äº’å»ºæ¨¡ï¼Œä»¥åŠé…å¯¹æ³¨æ„åŠ›å›¾ï¼Œå¯åœ¨æ¨ç†æ—¶è§£é‡Šç¤¾ä¼šå½±å“æ¨¡å¼ã€‚è¯¥æ¨¡å‹å°†å•ç›®æ ‡æ¡ä»¶é¢„æµ‹è½¬åŒ–ä¸ºè¿è´¯çš„å¤šä»£ç†é¢„æµ‹æ¡†æ¶ã€‚é™¤äº†æ ‡å‡†ä½ç§»æŒ‡æ ‡å¤–ï¼Œæˆ‘ä»¬è¿˜ä»¥è½¨è¿¹ç¢°æ’ç‡ä½œä¸ºè”åˆç°å®æ€§çš„è¡¡é‡æŒ‡æ ‡ã€‚åœ¨å¯†é›†ä»£ç†æ•°æ®é›†MADRASå’ŒSDDä¸Šï¼ŒVISTAè¾¾åˆ°æœ€å…ˆè¿›çš„ç²¾åº¦ï¼Œç¢°æ’æ¬¡æ•°å¤§å¤§å‡å°‘ã€‚åœ¨MADRASä¸Šï¼Œå®ƒå°†åŸºçº¿æ¨¡å‹çš„å¹³å‡ç¢°æ’ç‡ä»2.14%é™è‡³0.03%ï¼Œåœ¨SDDä¸Šå®ç°äº†é›¶ç¢°æ’ï¼ŒåŒæ—¶æé«˜äº†ADEã€FDEå’ŒminFDEã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVISTAç”Ÿæˆçš„è½¨è¿¹å…·æœ‰ç¤¾ä¼šåˆè§„æ€§ã€ç›®æ ‡æ„è¯†å’Œå¯è§£é‡Šæ€§ï¼Œå¯¹äºå®‰å…¨å…³é”®çš„è‡ªä¸»ç³»ç»Ÿå…·æœ‰å¹¿é˜”çš„å‘å±•å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†è½¨è¿¹é¢„æµ‹å¯¹è‡ªä¸»ç³»ç»Ÿåœ¨å¯†é›†ã€äº¤äº’ç¯å¢ƒä¸­çš„è¿è¡Œè‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½ç•¥äº†é•¿æœŸç›®æ ‡å’Œç²¾ç»†ç¤¾ä¼šäº’åŠ¨çš„è”åˆæ•è·ï¼Œå¯¼è‡´é¢„æµ‹ä¸çœŸå®ã€‚</li>
<li>VISTAæ˜¯ä¸€ä¸ªé€’å½’ç›®æ ‡æ¡ä»¶å˜å‹å™¨æ¨¡å‹ï¼Œç”¨äºå¤šä»£ç†è½¨è¿¹é¢„æµ‹ã€‚</li>
<li>VISTAç»“åˆäº†è·¨æ³¨æ„åŠ›èåˆã€ç¤¾äº¤ä»¤ç‰Œæ³¨æ„åŠ›å’Œé…å¯¹æ³¨æ„åŠ›å›¾ã€‚</li>
<li>VISTAå®ç°äº†ä»å•ç›®æ ‡æ¡ä»¶é¢„æµ‹åˆ°è¿è´¯çš„å¤šä»£ç†é¢„æµ‹çš„è½¬å˜ã€‚</li>
<li>é™¤äº†æ ‡å‡†ä½ç§»æŒ‡æ ‡å¤–ï¼Œè¿˜é‡‡ç”¨è½¨è¿¹ç¢°æ’ç‡ä½œä¸ºé¢„æµ‹è´¨é‡çš„è¡¡é‡æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10203">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ea82f5e9c998eb21971794af095edd2b" align="middle">
<img src="https://picx.zhimg.com/v2-870671191af5271032956f9d8efd0d40" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Continuous-Benchmark-Generation-for-Evaluating-Enterprise-scale-LLM-Agents"><a href="#Continuous-Benchmark-Generation-for-Evaluating-Enterprise-scale-LLM-Agents" class="headerlink" title="Continuous Benchmark Generation for Evaluating Enterprise-scale LLM Agents"></a>Continuous Benchmark Generation for Evaluating Enterprise-scale LLM Agents</h2><p><strong>Authors:Divyanshu Saxena, Rishikesh Maurya, Xiaoxuan Ou, Gagan Somashekar, Shachee Mishra Gupta, Arun Iyer, Yu Kang, Chetan Bansal, Aditya Akella, Saravan Rajmohan</strong></p>
<p>The rapid adoption of AI agents across domains has made systematic evaluation crucial for ensuring their usefulness and successful production deployment. Evaluation of AI agents typically involves using a fixed set of benchmarks and computing multiple evaluation metrics for the agent. While sufficient for simple coding tasks, these benchmarks fall short for enterprise-scale agents, where services and requirements evolve continuously and ground-truth examples are sparse. We propose a process of benchmark generation that helps evolve the benchmarks as the requirements change and perform robust evaluation of evolving AI agents. We instantiate this approach for a case study of service migration from one deployment platform to another at a large public enterprise. Our approach relies on semi-structured documents where developers express the high-level intent, and uses state-of-the-art LLMs to generate benchmarks from just a small number of such documents. Overall, this process results in a maintainable evaluation framework, enabling rapid feedback on agent performance and facilitating targeted improvements.</p>
<blockquote>
<p>éšç€äººå·¥æ™ºèƒ½ä»£ç†åœ¨å„ä¸ªé¢†åŸŸä¸­çš„å¿«é€Ÿé‡‡ç”¨ï¼Œå¯¹å…¶è¿›è¡Œç³»ç»Ÿè¯„ä¼°å¯¹äºç¡®ä¿å…¶æœ‰ç”¨æ€§å’ŒæˆåŠŸçš„äº§å“éƒ¨ç½²è‡³å…³é‡è¦ã€‚å¯¹äººå·¥æ™ºèƒ½ä»£ç†çš„è¯„ä¼°é€šå¸¸æ¶‰åŠä½¿ç”¨å›ºå®šçš„åŸºå‡†æµ‹è¯•é›†å¹¶ä¸ºä»£ç†è®¡ç®—å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ã€‚è™½ç„¶è¿™å¯¹äºç®€å•çš„ç¼–ç ä»»åŠ¡æ¥è¯´å·²ç»è¶³å¤Ÿäº†ï¼Œä½†è¿™äº›åŸºå‡†æµ‹è¯•å¯¹äºä¼ä¸šçº§è§„æ¨¡çš„ä»£ç†æ¥è¯´å´ä¸è¶³å¤Ÿåº”å¯¹ï¼Œå› ä¸ºæœåŠ¡å’Œè¦æ±‚åœ¨ä¸æ–­åœ°å‘å±•å˜åŒ–ï¼Œè€ŒçœŸå®æƒ…å†µçš„ä¾‹å­å´å¾ˆå°‘è§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºå‡†æµ‹è¯•ç”Ÿæˆè¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æœ‰åŠ©äºéšç€è¦æ±‚çš„æ”¹å˜è€Œä¸æ–­å‘å±•åŸºå‡†æµ‹è¯•ï¼Œå¹¶å¯¹ä¸æ–­å˜åŒ–çš„äººå·¥æ™ºèƒ½ä»£ç†è¿›è¡Œç¨³å¥è¯„ä¼°ã€‚æˆ‘ä»¬é€šè¿‡ä¸€é¡¹æ¡ˆä¾‹ç ”ç©¶æ¥å®ä¾‹åŒ–è¿™ç§æ–¹æ³•ï¼Œè¯¥æ¡ˆä¾‹ç ”ç©¶æ˜¯å…³äºå¤§å‹å…¬å…±ä¼ä¸šä»ä¸€ä¸ªéƒ¨ç½²å¹³å°è¿ç§»åˆ°å¦ä¸€ä¸ªéƒ¨ç½²å¹³å°çš„æœåŠ¡è¿ç§»ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¾èµ–äºåŠç»“æ„åŒ–æ–‡æ¡£ï¼Œå¼€å‘è€…åœ¨å…¶ä¸­è¡¨è¾¾é«˜çº§æ„å›¾ï¼Œå¹¶ä½¿ç”¨æœ€å…ˆè¿›çš„LLMä»å°‘é‡æ­¤ç±»æ–‡æ¡£ä¸­ç”ŸæˆåŸºå‡†æµ‹è¯•ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªè¿‡ç¨‹å½¢æˆäº†ä¸€ä¸ªå¯æŒç»­çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿè¿…é€Ÿåé¦ˆä»£ç†æ€§èƒ½å¹¶è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10049v1">PDF</a> 5 pages</p>
<p><strong>Summary</strong></p>
<p>éšç€AIä»£ç†åœ¨å¤šä¸ªé¢†åŸŸçš„å¿«é€Ÿé‡‡çº³ï¼Œç³»ç»Ÿè¯„ä¼°å¯¹äºç¡®ä¿å…¶å®ç”¨æ€§å’ŒæˆåŠŸéƒ¨ç½²è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„å›ºå®šåŸºå‡†æµ‹è¯•å¯¹äºç®€å•ç¼–ç ä»»åŠ¡è¶³å¤Ÿï¼Œä½†å¯¹ä¼ä¸šçº§ä»£ç†æ¥è¯´å­˜åœ¨å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºå‡†æµ‹è¯•ç”Ÿæˆæ–¹æ³•ï¼Œæ ¹æ®éœ€æ±‚å˜åŒ–æ›´æ–°åŸºå‡†æµ‹è¯•ï¼Œå¹¶å¯¹ä¸æ–­å‘å±•çš„AIä»£ç†è¿›è¡Œç¨³å¥è¯„ä¼°ã€‚æ­¤æ–¹æ³•ä¾èµ–åŠç»“æ„åŒ–æ–‡æ¡£è¡¨è¾¾å¼€å‘è€…çš„é«˜çº§æ„å›¾ï¼Œå¹¶ä½¿ç”¨æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹ä»å°è§„æ¨¡æ–‡æ¡£ç”ŸæˆåŸºå‡†æµ‹è¯•ã€‚æ€»ä½“ä¸Šæ¥è¯´ï¼Œè¿™å»ºç«‹äº†ä¸€ä¸ªå¯æŒç»­çš„è¯„ä¼°æ¡†æ¶ï¼Œå¯å¿«é€Ÿåé¦ˆä»£ç†æ€§èƒ½å¹¶è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIä»£ç†çš„å¹¿æ³›é‡‡ç”¨ä½¿å¾—ç³»ç»Ÿè¯„ä¼°å˜å¾—è‡³å…³é‡è¦ï¼Œä»¥ç¡®ä¿å…¶å®ç”¨æ€§å’ŒæˆåŠŸéƒ¨ç½²ã€‚</li>
<li>ä¼ ç»ŸåŸºå‡†æµ‹è¯•å¯¹äºç®€å•ç¼–ç ä»»åŠ¡æœ‰æ•ˆï¼Œä½†å¯¹ä¼ä¸šçº§AIä»£ç†çš„è¯„ä¼°å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æå‡ºçš„åŸºå‡†æµ‹è¯•ç”Ÿæˆæ–¹æ³•èƒ½å¤Ÿæ ¹æ®éœ€æ±‚å˜åŒ–æ›´æ–°åŸºå‡†æµ‹è¯•ã€‚</li>
<li>æ–¹æ³•ä¾èµ–åŠç»“æ„åŒ–æ–‡æ¡£å’Œæœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹æ¥ç”ŸæˆåŸºå‡†æµ‹è¯•ã€‚</li>
<li>è¯¥è¯„ä¼°æ¡†æ¶å…è®¸å¿«é€Ÿåé¦ˆä»£ç†æ€§èƒ½å¹¶è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚</li>
<li>æ­¤æ–¹æ³•ä¸ºå°è§„æ¨¡æ–‡æ¡£ç”ŸæˆåŸºå‡†æµ‹è¯•æä¾›äº†å¯èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10049">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-00c4c9020217e94e36456a8624e44b94" align="middle">
<img src="https://picx.zhimg.com/v2-031c33a9c9d629e97f36ddc44057010f" align="middle">
<img src="https://picx.zhimg.com/v2-b66468261b7a033d9a5f81a5df03804d" align="middle">
<img src="https://picx.zhimg.com/v2-f0287c9920b8e22937bc56d9ecc49bb1" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multi-agent-In-context-Coordination-via-Decentralized-Memory-Retrieval"><a href="#Multi-agent-In-context-Coordination-via-Decentralized-Memory-Retrieval" class="headerlink" title="Multi-agent In-context Coordination via Decentralized Memory Retrieval"></a>Multi-agent In-context Coordination via Decentralized Memory Retrieval</h2><p><strong>Authors:Tao Jiang, Zichuan Lin, Lihe Li, Yi-Chen Li, Cong Guan, Lei Yuan, Zongzhang Zhang, Yang Yu, Deheng Ye</strong></p>
<p>Large transformer models, trained on diverse datasets, have demonstrated impressive few-shot performance on previously unseen tasks without requiring parameter updates. This capability has also been explored in Reinforcement Learning (RL), where agents interact with the environment to retrieve context and maximize cumulative rewards, showcasing strong adaptability in complex settings. However, in cooperative Multi-Agent Reinforcement Learning (MARL), where agents must coordinate toward a shared goal, decentralized policy deployment can lead to mismatches in task alignment and reward assignment, limiting the efficiency of policy adaptation. To address this challenge, we introduce Multi-agent In-context Coordination via Decentralized Memory Retrieval (MAICC), a novel approach designed to enhance coordination by fast adaptation. Our method involves training a centralized embedding model to capture fine-grained trajectory representations, followed by decentralized models that approximate the centralized one to obtain team-level task information. Based on the learned embeddings, relevant trajectories are retrieved as context, which, combined with the agentsâ€™ current sub-trajectories, inform decision-making. During decentralized execution, we introduce a novel memory mechanism that effectively balances test-time online data with offline memory. Based on the constructed memory, we propose a hybrid utility score that incorporates both individual- and team-level returns, ensuring credit assignment across agents. Extensive experiments on cooperative MARL benchmarks, including Level-Based Foraging (LBF) and SMAC (v1&#x2F;v2), show that MAICC enables faster adaptation to unseen tasks compared to existing methods. Code is available at <a target="_blank" rel="noopener" href="https://github.com/LAMDA-RL/MAICC">https://github.com/LAMDA-RL/MAICC</a>.</p>
<blockquote>
<p>åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè®­ç»ƒçš„çš„å¤§å‹Transformeræ¨¡å‹ï¼Œåœ¨æœªæ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹ï¼Œä»¥å‰æ‰€æœªæœ‰çš„å°‘æ•°é•œå¤´ï¼ˆfew-shotï¼‰æ€§èƒ½å±•ç°å‡ºå¯¹æœªè§ä»»åŠ¡çš„å‡ºè‰²è¡¨ç°ã€‚è¿™ä¸€èƒ½åŠ›åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­ä¹Ÿå¾—åˆ°äº†æ¢ç´¢ï¼Œå…¶ä¸­ä»£ç†é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨æ¥æ£€ç´¢ä¸Šä¸‹æ–‡å¹¶æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ï¼Œå±•ç¤ºäº†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¼ºå¤§é€‚åº”æ€§ã€‚ç„¶è€Œï¼Œåœ¨åˆä½œå‹å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œä»£ç†å¿…é¡»åè°ƒä»¥å®ç°å…±åŒç›®æ ‡ï¼Œå»ä¸­å¿ƒåŒ–ç­–ç•¥éƒ¨ç½²å¯èƒ½å¯¼è‡´ä»»åŠ¡å¯¹é½å’Œå¥–åŠ±åˆ†é…æ–¹é¢çš„ä¸åŒ¹é…ï¼Œé™åˆ¶äº†ç­–ç•¥é€‚åº”çš„æ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºå»ä¸­å¿ƒåŒ–è®°å¿†æ£€ç´¢çš„å¤šä»£ç†ä¸Šä¸‹æ–‡åè°ƒï¼ˆMAICCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é€šè¿‡å¿«é€Ÿé€‚åº”å¢å¼ºåè°ƒæ€§çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬è®­ç»ƒä¸€ä¸ªé›†ä¸­åµŒå…¥æ¨¡å‹æ¥æ•æ‰ç²¾ç»†è½¨è¿¹è¡¨ç¤ºï¼Œéšåæ˜¯é‡‡ç”¨åˆ†æ•£æ¨¡å‹æ¥è¿‘ä¼¼é›†ä¸­åµŒå…¥æ¨¡å‹ä»¥è·å¾—å›¢é˜Ÿçº§åˆ«çš„ä»»åŠ¡ä¿¡æ¯ã€‚åŸºäºå­¦ä¹ çš„åµŒå…¥ï¼Œæˆ‘ä»¬æ£€ç´¢ç›¸å…³è½¨è¿¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œç»“åˆä»£ç†å½“å‰çš„å­è½¨è¿¹ï¼Œä¸ºå†³ç­–æä¾›ä¾æ®ã€‚åœ¨å»ä¸­å¿ƒåŒ–æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„è®°å¿†æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¹³è¡¡åœ¨çº¿æ•°æ®å’Œç¦»çº¿è®°å¿†ã€‚åŸºäºæ„å»ºçš„è®°å¿†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ··åˆæ•ˆç”¨è¯„åˆ†ï¼Œè¯¥è¯„åˆ†ç»“åˆäº†ä¸ªäººå’Œå›¢é˜Ÿå›æŠ¥ï¼Œä»¥ç¡®ä¿åœ¨ä»£ç†ä¹‹é—´è¿›è¡Œä¿¡ç”¨åˆ†é…ã€‚åœ¨åŒ…æ‹¬å±‚æ¬¡åŒ–è§…é£Ÿï¼ˆLBFï¼‰å’ŒSMACï¼ˆv1&#x2F;v2ï¼‰ç­‰åˆä½œå‹MARLåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMAICCèƒ½å¤Ÿæ›´å¿«é€‚åº”æœªè§ä»»åŠ¡ç›¸æ¯”äºç°æœ‰æ–¹æ³•ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/LAMDA-RL/MAICC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LAMDA-RL/MAICCæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.10030v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è½¬æ¢æ¨¡å‹åœ¨å¤šæ ·çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå±•ç¤ºäº†å¯¹æœªè§ä»»åŠ¡çš„å¼ºå¤§æ€§èƒ½ï¼Œæ— éœ€å‚æ•°æ›´æ–°ã€‚è¿™ä¸€èƒ½åŠ›åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­ä¹Ÿå¾—åˆ°äº†æ¢ç´¢ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥æ£€ç´¢ä¸Šä¸‹æ–‡å¹¶æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§ã€‚ç„¶è€Œï¼Œåœ¨åˆä½œå‹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦åè°ƒå®ç°å…±åŒç›®æ ‡ï¼Œå»ä¸­å¿ƒåŒ–çš„ç­–ç•¥éƒ¨ç½²å¯èƒ½å¯¼è‡´ä»»åŠ¡å¯¹é½å’Œå¥–åŠ±åˆ†é…çš„ä¸åŒ¹é…ï¼Œé™åˆ¶äº†ç­–ç•¥é€‚åº”çš„æ•ˆç‡ã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå»ä¸­å¿ƒåŒ–è®°å¿†æ£€ç´¢çš„å¤šæ™ºèƒ½ä½“ä¸Šä¸‹æ–‡åè°ƒï¼ˆMAICCï¼‰æ–°æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡å¿«é€Ÿé€‚åº”å¢å¼ºåè°ƒæ€§ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬è®­ç»ƒä¸­å¤®åµŒå…¥æ¨¡å‹ä»¥æ•è·ç²¾ç»†è½¨è¿¹è¡¨ç¤ºï¼Œéšåä½¿ç”¨å»ä¸­å¿ƒåŒ–æ¨¡å‹è¿‘ä¼¼ä¸­å¤®æ¨¡å‹ä»¥è·å¾—å›¢é˜Ÿçº§ä»»åŠ¡ä¿¡æ¯ã€‚åŸºäºå­¦ä¹ çš„åµŒå…¥ï¼Œæˆ‘ä»¬æ£€ç´¢ç›¸å…³çš„è½¨è¿¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¸æ™ºèƒ½ä½“çš„å½“å‰å­è½¨è¿¹ç›¸ç»“åˆï¼Œä¸ºå†³ç­–æä¾›ä¾æ®ã€‚åœ¨å»ä¸­å¿ƒåŒ–æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ–°çš„è®°å¿†æœºåˆ¶ï¼Œæœ‰æ•ˆå¹³è¡¡äº†åœ¨çº¿æ•°æ®ä¸ç¦»çº¿è®°å¿†ã€‚åŸºäºæ„å»ºçš„è®°å¿†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ··åˆæ•ˆç”¨åˆ†æ•°ï¼Œæ—¢åŒ…æ‹¬ä¸ªä½“ä¹ŸåŒ…æ‹¬å›¢é˜Ÿå›æŠ¥ï¼Œç¡®ä¿æ™ºèƒ½ä½“ä¹‹é—´çš„ä¿¡ç”¨åˆ†é…ã€‚åœ¨åˆä½œå‹MARLåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒæ˜¾ç¤ºï¼ŒMAICCä½¿æ™ºèƒ½ä½“åœ¨æœªè§ä»»åŠ¡ä¸Šçš„é€‚åº”èƒ½åŠ›å¾—åˆ°äº†æé«˜ã€‚ä»£ç å·²åœ¨GitHubä¸Šå‘å¸ƒã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è½¬æ¢æ¨¡å‹åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„è®­ç»ƒå·²è¯æ˜å…¶åœ¨æœªè§ä»»åŠ¡ä¸Šçš„å¼ºå¤§æ€§èƒ½ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§ï¼Œé€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ£€ç´¢ä¸Šä¸‹æ–‡å¹¶æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚</li>
<li>åœ¨åˆä½œå‹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå»ä¸­å¿ƒåŒ–ç­–ç•¥éƒ¨ç½²å¯èƒ½å¯¼è‡´ä»»åŠ¡å¯¹é½å’Œå¥–åŠ±åˆ†é…çš„é—®é¢˜ã€‚</li>
<li>MAICCæ–¹æ³•é€šè¿‡å¼•å…¥ä¸­å¤®åµŒå…¥æ¨¡å‹å’Œå»ä¸­å¿ƒåŒ–è®°å¿†æ£€ç´¢å¢å¼ºäº†æ™ºèƒ½ä½“é—´çš„åè°ƒæ€§ã€‚</li>
<li>MAICCé€šè¿‡è®­ç»ƒæ™ºèƒ½ä½“åœ¨åˆä½œå‹MARLåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨ç°å‡ºäº†è¾ƒé«˜çš„é€‚åº”æ€§å’Œæ€§èƒ½æå‡ã€‚</li>
<li>MAICCç»“åˆäº†åœ¨çº¿æ•°æ®å’Œç¦»çº¿è®°å¿†ï¼Œé€šè¿‡æ–°é¢–çš„è®°å¿†æœºåˆ¶è¿›è¡Œæœ‰æ•ˆå¹³è¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.10030">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8793668defaf33d2b276010f75b2418e" align="middle">
<img src="https://picx.zhimg.com/v2-538d80731247e3448e012717732f9da2" align="middle">
<img src="https://picx.zhimg.com/v2-462fa8dd46889eb97846d38fb41bfc4c" align="middle">
<img src="https://picx.zhimg.com/v2-62b73a758993ad8102f09174f688f261" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SlideBot-A-Multi-Agent-Framework-for-Generating-Informative-Reliable-Multi-Modal-Presentations"><a href="#SlideBot-A-Multi-Agent-Framework-for-Generating-Informative-Reliable-Multi-Modal-Presentations" class="headerlink" title="SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations"></a>SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations</h2><p><strong>Authors:Eric Xie, Danielle Waterfield, Michael Kennedy, Aidong Zhang</strong></p>
<p>Large Language Models (LLMs) have shown immense potential in education, automating tasks like quiz generation and content summarization. However, generating effective presentation slides introduces unique challenges due to the complexity of multimodal content creation and the need for precise, domain-specific information. Existing LLM-based solutions often fail to produce reliable and informative outputs, limiting their educational value. To address these limitations, we introduce SlideBot - a modular, multi-agent slide generation framework that integrates LLMs with retrieval, structured planning, and code generation. SlideBot is organized around three pillars: informativeness, ensuring deep and contextually grounded content; reliability, achieved by incorporating external sources through retrieval; and practicality, which enables customization and iterative feedback through instructor collaboration. It incorporates evidence-based instructional design principles from Cognitive Load Theory (CLT) and the Cognitive Theory of Multimedia Learning (CTML), using structured planning to manage intrinsic load and consistent visual macros to reduce extraneous load and enhance dual-channel learning. Within the system, specialized agents collaboratively retrieve information, summarize content, generate figures, and format slides using LaTeX, aligning outputs with instructor preferences through interactive refinement. Evaluations from domain experts and students in AI and biomedical education show that SlideBot consistently enhances conceptual accuracy, clarity, and instructional value. These findings demonstrate SlideBotâ€™s potential to streamline slide preparation while ensuring accuracy, relevance, and adaptability in higher education.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•™è‚²é¢†åŸŸå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–ç”Ÿæˆæµ‹éªŒå’Œå†…å®¹æ‘˜è¦ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç”Ÿæˆæœ‰æ•ˆçš„æ¼”ç¤ºå¹»ç¯ç‰‡ç”±äºå¤šåª’ä½“å†…å®¹åˆ›ä½œçš„å¤æ‚æ€§å’Œå¯¹ç²¾ç¡®ã€ç‰¹å®šé¢†åŸŸä¿¡æ¯çš„éœ€æ±‚ï¼Œå¼•å…¥äº†ä¸€äº›ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºäºLLMçš„è§£å†³æ–¹æ¡ˆå¾€å¾€æ— æ³•äº§ç”Ÿå¯é å’Œå¯Œæœ‰ä¿¡æ¯é‡çš„è¾“å‡ºï¼Œä»è€Œé™åˆ¶äº†å…¶æ•™è‚²ä»·å€¼ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†SlideBotâ€”â€”ä¸€ä¸ªæ¨¡å—åŒ–çš„å¤šä»£ç†å¹»ç¯ç‰‡ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒå°†LLMsä¸æ£€ç´¢ã€ç»“æ„åŒ–è§„åˆ’å’Œä»£ç ç”Ÿæˆç›¸ç»“åˆã€‚SlideBotå›´ç»•ä¸‰ä¸ªæ”¯æŸ±æ„å»ºï¼šä¿¡æ¯æ€§ï¼Œç¡®ä¿æ·±å…¥å’ŒåŸºäºä¸Šä¸‹æ–‡çš„å†…å®¹ï¼›å¯é æ€§ï¼Œé€šè¿‡æ£€ç´¢èå…¥å¤–éƒ¨èµ„æºæ¥å®ç°ï¼›å®ç”¨æ€§ï¼Œé€šè¿‡æ•™å¸ˆåä½œå®ç°å®šåˆ¶å’Œè¿­ä»£åé¦ˆã€‚å®ƒç»“åˆäº†è®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰å’Œå¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºï¼ˆCTMLï¼‰çš„è¯æ®æ”¯æŒæ•™å­¦è®¾è®¡åŸåˆ™ï¼Œä½¿ç”¨ç»“æ„åŒ–è§„åˆ’æ¥ç®¡ç†å†…åœ¨è´Ÿè·ï¼Œå¹¶ç”¨ä¸€è‡´çš„è§†è§‰å®å…ƒç´ æ¥å‡å°‘å¤–åœ¨è´Ÿè·å¹¶å¢å¼ºåŒé€šé“å­¦ä¹ ã€‚åœ¨è¯¥ç³»ç»Ÿä¸­ï¼Œä¸“ä¸šä»£ç†ååŒæ£€ç´¢ä¿¡æ¯ã€æ€»ç»“å†…å®¹ã€ç”Ÿæˆå›¾å½¢å¹¶ä½¿ç”¨LaTeXæ ¼å¼åŒ–å¹»ç¯ç‰‡ï¼Œé€šè¿‡äº¤äº’ç»†åŒ–ä¸æ•™å¸ˆçš„åå¥½å¯¹é½è¾“å‡ºã€‚æ¥è‡ªäººå·¥æ™ºèƒ½å’Œç”Ÿç‰©åŒ»å­¦æ•™è‚²é¢†åŸŸçš„ä¸“å®¶å’Œå­¦ç”Ÿè¯„ä¼°è¡¨æ˜ï¼ŒSlideBotæŒç»­æé«˜äº†æ¦‚å¿µå‡†ç¡®æ€§ã€æ¸…æ™°åº¦å’Œæ•™å­¦ä»·å€¼ã€‚è¿™äº›å‘ç°è¯æ˜äº†SlideBotåœ¨ç®€åŒ–å¹»ç¯ç‰‡åˆ¶ä½œçš„åŒæ—¶ï¼Œç¡®ä¿å‡†ç¡®æ€§ã€ç›¸å…³æ€§å’Œé€‚åº”æ€§çš„æ½œåŠ›ï¼Œåœ¨é«˜ç­‰æ•™è‚²ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09804v1">PDF</a> 32 pages, 14 figures, accepted into EAAI 2026</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•™è‚²é¢†åŸŸçš„æ½œåŠ›ï¼Œæœ¬æ–‡ä»‹ç»äº†SlideBotè¿™ä¸€æ¨¡å—åŒ–ã€å¤šä»£ç†çš„å¹»ç¯ç‰‡ç”Ÿæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†LLMä¸æ£€ç´¢ã€ç»“æ„åŒ–è§„åˆ’å’Œä»£ç ç”Ÿæˆï¼Œä»¥è§£å†³ç”Ÿæˆæœ‰æ•ˆæ¼”ç¤ºå¹»ç¯ç‰‡æ‰€é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚SlideBotä»¥ä¿¡æ¯ä¸°å¯Œæ€§ã€å¯é æ€§å’Œå®ç”¨æ€§ä¸ºä¸‰å¤§æ”¯æŸ±ï¼Œç¡®ä¿æ·±åº¦ä¸”åŸºäºä¸Šä¸‹æ–‡çš„å†…å®¹ï¼Œé€šè¿‡æ£€ç´¢èå…¥å¤–éƒ¨èµ„æºï¼Œå¹¶é€šè¿‡æ•™å¸ˆåä½œå®ç°ä¸ªæ€§åŒ–å®šåˆ¶å’Œè¿­ä»£åé¦ˆã€‚å®ƒç»“åˆäº†è®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCLTï¼‰å’Œå¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºï¼ˆCTMLï¼‰çš„è¯æ®æŒ‡å¯¼è®¾è®¡åŸåˆ™ï¼Œé‡‡ç”¨ç»“æ„åŒ–è§„åˆ’ç®¡ç†å†…åœ¨è´Ÿè·ï¼Œä½¿ç”¨ä¸€è‡´çš„è§†è§‰å®å‡å°‘å¤–åœ¨è´Ÿè·å¹¶å¢å¼ºåŒé€šé“å­¦ä¹ ã€‚ç‰¹åˆ«ä»£ç†ååŒå·¥ä½œï¼Œè¿›è¡Œä¿¡æ¯æ£€ç´¢ã€å†…å®¹æ‘˜è¦ã€å›¾å½¢ç”Ÿæˆå’Œå¹»ç¯ç‰‡æ ¼å¼è½¬æ¢ç­‰ä»»åŠ¡ã€‚ä¸“å®¶è¯„ä¼°å’Œå­¦ç”Ÿåœ¨AIå’Œç”Ÿç‰©åŒ»å­¦æ•™è‚²ä¸­çš„åé¦ˆæ˜¾ç¤ºï¼ŒSlideBotåœ¨æ¦‚å¿µå‡†ç¡®æ€§ã€æ¸…æ™°åº¦å’Œæ•™å­¦ä»·å€¼æ–¹é¢è¡¨ç°å“è¶Šã€‚è¯¥æ¡†æ¶å…·æœ‰ç®€åŒ–å¹»ç¯ç‰‡åˆ¶ä½œæµç¨‹ã€ç¡®ä¿å‡†ç¡®æ€§ã€ç›¸å…³æ€§å’Œé«˜ç­‰æ•™è‚²é€‚åº”æ€§çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMåœ¨æ•™è‚²é¢†åŸŸå…·æœ‰æ½œåŠ›ï¼Œç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡å¦‚æµ‹éªŒç”Ÿæˆå’Œå†…å®¹æ‘˜è¦ã€‚</li>
<li>ç”Ÿæˆæ¼”ç¤ºå¹»ç¯ç‰‡é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œéœ€è¦å¤„ç†å¤šæ¨¡æ€å†…å®¹åˆ›å»ºå’Œç²¾ç¡®ã€ç‰¹å®šé¢†åŸŸçš„èµ„è®¯ã€‚</li>
<li>SlideBotæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–ã€å¤šä»£ç†çš„å¹»ç¯ç‰‡ç”Ÿæˆæ¡†æ¶ï¼Œé›†æˆLLMä¸æ£€ç´¢ã€ç»“æ„åŒ–è§„åˆ’å’Œä»£ç ç”Ÿæˆã€‚</li>
<li>SlideBotçš„ä¸‰å¤§æ”¯æŸ±æ˜¯ä¿¡æ¯ä¸°å¯Œæ€§ã€å¯é æ€§å’Œå®ç”¨æ€§ï¼Œç¡®ä¿å†…å®¹æ·±åº¦ã€ä¸Šä¸‹æ–‡ç›¸å…³ï¼Œå¹¶èå…¥å¤–éƒ¨èµ„æºã€‚</li>
<li>SlideBotç»“åˆè®¤çŸ¥è´Ÿè·ç†è®ºå’Œå¤šåª’ä½“å­¦ä¹ è®¤çŸ¥ç†è®ºçš„åŸåˆ™ï¼Œé‡‡ç”¨ç»“æ„åŒ–è§„åˆ’ç®¡ç†å­¦ä¹ è´Ÿè·ã€‚</li>
<li>SlideBotåŒ…æ‹¬ä¿¡æ¯æ£€ç´¢ã€å†…å®¹æ‘˜è¦ã€å›¾å½¢ç”Ÿæˆå’Œå¹»ç¯ç‰‡æ ¼å¼è½¬æ¢ç­‰åŠŸèƒ½çš„ç‰¹åˆ«ä»£ç†ã€‚</li>
<li>SlideBotåœ¨æ¦‚å¿µå‡†ç¡®æ€§ã€æ¸…æ™°åº¦å’Œæ•™å­¦ä»·å€¼æ–¹é¢å¾—åˆ°ä¸“å®¶å’Œå­¦ç”Ÿçš„ç§¯æåé¦ˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09804">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8ec74b0c6d10e5cdb51a55a2424549ed" align="middle">
<img src="https://picx.zhimg.com/v2-495765e1184d510345f1d12d844faf81" align="middle">
<img src="https://picx.zhimg.com/v2-1f6452c3b68d6ea66c075c46913538e2" align="middle">
<img src="https://picx.zhimg.com/v2-1c4c9eb6fad5539489da4bd3ac99f9a8" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Beyond-Monotonicity-Revisiting-Factorization-Principles-in-Multi-Agent-Q-Learning"><a href="#Beyond-Monotonicity-Revisiting-Factorization-Principles-in-Multi-Agent-Q-Learning" class="headerlink" title="Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning"></a>Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning</h2><p><strong>Authors:Tianmeng Hu, Yongzheng Cui, Rui Tang, Biao Luo, Ke Li</strong></p>
<p>Value decomposition is a central approach in multi-agent reinforcement learning (MARL), enabling centralized training with decentralized execution by factorizing the global value function into local values. To ensure individual-global-max (IGM) consistency, existing methods either enforce monotonicity constraints, which limit expressive power, or adopt softer surrogates at the cost of algorithmic complexity. In this work, we present a dynamical systems analysis of non-monotonic value decomposition, modeling learning dynamics as continuous-time gradient flow. We prove that, under approximately greedy exploration, all zero-loss equilibria violating IGM consistency are unstable saddle points, while only IGM-consistent solutions are stable attractors of the learning dynamics. Extensive experiments on both synthetic matrix games and challenging MARL benchmarks demonstrate that unconstrained, non-monotonic factorization reliably recovers IGM-optimal solutions and consistently outperforms monotonic baselines. Additionally, we investigate the influence of temporal-difference targets and exploration strategies, providing actionable insights for the design of future value-based MARL algorithms.</p>
<blockquote>
<p>å€¼åˆ†è§£æ˜¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå®ƒé€šè¿‡å…¨å±€å€¼å‡½æ•°åˆ†è§£åˆ°å±€éƒ¨å€¼æ¥å®ç°é›†ä¸­è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œã€‚ä¸ºäº†ç¡®ä¿ä¸ªä½“å…¨å±€æœ€å¤§ï¼ˆIGMï¼‰ä¸€è‡´æ€§ï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆå¼ºåˆ¶æ‰§è¡Œå•è°ƒæ€§çº¦æŸï¼Œè¿™ä¼šé™åˆ¶å…¶è¡¨è¾¾åŠ›ï¼Œè¦ä¹ˆé‡‡ç”¨æ›´å¤æ‚ä½†ä»£ä»·é«˜æ˜‚çš„æ›¿ä»£æ–¹æ³•ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¯¹éå•è°ƒå€¼åˆ†è§£è¿›è¡ŒåŠ¨æ€ç³»ç»Ÿåˆ†æï¼Œå°†å­¦ä¹ åŠ¨æ€å»ºæ¨¡ä¸ºè¿ç»­æ—¶é—´çš„æ¢¯åº¦æµã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨è¿‘ä¼¼è´ªå©ªæ¢ç´¢ä¸‹ï¼Œæ‰€æœ‰è¿åIGMä¸€è‡´æ€§çš„é›¶æŸå¤±å¹³è¡¡ç‚¹æ˜¯ä¸ç¨³å®šçš„éç‚¹ï¼Œè€Œåªæœ‰IGMä¸€è‡´çš„è§£æ‰æ˜¯å­¦ä¹ åŠ¨æ€çš„ç¨³å®šå¸å¼•å­ã€‚åœ¨åˆæˆçŸ©é˜µæ¸¸æˆå’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„MARLåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ— çº¦æŸçš„éå•è°ƒåˆ†è§£èƒ½å¤Ÿå¯é åœ°æ¢å¤IGMæœ€ä¼˜è§£ï¼Œå¹¶ä¸”å§‹ç»ˆä¼˜äºå•è°ƒåŸºçº¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†æ—¶é—´å·®åˆ†ç›®æ ‡å’Œæ¢ç´¢ç­–ç•¥çš„å½±å“ï¼Œä¸ºæœªæ¥åŸºäºä»·å€¼çš„MARLç®—æ³•è®¾è®¡æä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09792v1">PDF</a> Accepted at AAAI 2026</p>
<p><strong>Summary</strong></p>
<p>ä»·å€¼åˆ†è§£æ˜¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼Œé€šè¿‡å…¨å±€ä»·å€¼å‡½æ•°åˆ†è§£ä¸ºå±€éƒ¨ä»·å€¼å®ç°é›†ä¸­è®­ç»ƒä¸åˆ†æ•£æ‰§è¡Œã€‚ä¸ºç¡®ä¿ä¸ªä½“å…¨å±€æœ€å¤§åŒ–ï¼ˆIGMï¼‰ä¸€è‡´æ€§ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é‡‡å–å•è°ƒæ€§çº¦æŸï¼Œè¿™é™åˆ¶äº†å…¶è¡¨è¾¾åŠ›ï¼Œæˆ–åœ¨ç®—æ³•å¤æ‚åº¦ä¸Šæœ‰æ‰€ç‰ºç‰²é‡‡ç”¨è¾ƒè½¯çš„æ›¿ä»£ç‰©ã€‚æœ¬ç ”ç©¶é€šè¿‡åŠ¨æ€ç³»ç»Ÿåˆ†æéå•è°ƒä»·å€¼åˆ†è§£ï¼Œå°†å­¦ä¹ åŠ¨æ€å»ºæ¨¡ä¸ºè¿ç»­æ—¶é—´æ¢¯åº¦æµã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨è¿‘ä¼¼è´ªå©ªæ¢ç´¢ä¸‹ï¼Œæ‰€æœ‰è¿åIGMä¸€è‡´æ€§çš„é›¶æŸå¤±å¹³è¡¡ç‚¹æ˜¯ä¸ç¨³å®šéç‚¹ï¼Œåªæœ‰IGMä¸€è‡´è§£æ‰æ˜¯å­¦ä¹ åŠ¨æ€çš„ç¨³å®šå¸å¼•å­ã€‚åœ¨åˆæˆçŸ©é˜µæ¸¸æˆå’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„MARLåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæ— çº¦æŸçš„éå•è°ƒåˆ†è§£å¯é åœ°æ¢å¤äº†IGMæœ€ä¼˜è§£ï¼Œå¹¶å§‹ç»ˆä¼˜äºå•è°ƒåŸºçº¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç ”ç©¶äº†æ—¶é—´å·®åˆ†ç›®æ ‡å’Œæ¢ç´¢ç­–ç•¥çš„å½±å“ï¼Œä¸ºæœªæ¥ä»·å€¼åŸºç¡€çš„MARLç®—æ³•è®¾è®¡æä¾›äº†å¯æ“ä½œè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»·å€¼åˆ†è§£æ˜¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå®ƒå…è®¸å…¨å±€ä»·å€¼å‡½æ•°åˆ†è§£ä¸ºå±€éƒ¨ä»·å€¼ä»¥å®ç°é›†ä¸­è®­ç»ƒå’Œåˆ†æ•£æ‰§è¡Œã€‚</li>
<li>ç°è¡Œçš„ä»·å€¼åˆ†è§£æ–¹æ³•ä¸ºäº†å®ç°ä¸ªä½“å…¨å±€æœ€å¤§åŒ–ä¸€è‡´æ€§ï¼ˆIGMï¼‰ï¼Œä¼šé‡‡ç”¨å•è°ƒæ€§çº¦æŸæˆ–è€…è½¯æ›¿ä»£æ–¹æ¡ˆï¼Œè¿™åˆ†åˆ«å¯¼è‡´äº†è¡¨è¾¾èƒ½åŠ›çš„é™åˆ¶å’Œç®—æ³•å¤æ‚åº¦çš„æé«˜ã€‚</li>
<li>é€šè¿‡åŠ¨æ€ç³»ç»Ÿåˆ†æéå•è°ƒä»·å€¼åˆ†è§£ï¼Œæœ¬ç ”ç©¶å°†å­¦ä¹ åŠ¨æ€å»ºæ¨¡ä¸ºè¿ç»­æ—¶é—´æ¢¯åº¦æµã€‚</li>
<li>ç ”ç©¶è¯æ˜äº†éå•è°ƒä»·å€¼åˆ†è§£åœ¨è¿‘ä¼¼è´ªå©ªæ¢ç´¢ä¸‹èƒ½å¤Ÿè¾¾åˆ°ç¨³å®šçŠ¶æ€ï¼Œä¸”åªæœ‰ç¬¦åˆIGMä¸€è‡´æ€§çš„è§£æ‰æ˜¯ç¨³å®šçš„å¸å¼•å­ã€‚</li>
<li>å®éªŒè¡¨æ˜éå•è°ƒåˆ†è§£åœ¨å¤šç§åœºæ™¯ä¸‹è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„å•è°ƒåŸºçº¿æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶è¿˜æ¢ç´¢äº†æ—¶é—´å·®åˆ†ç›®æ ‡å’Œæ¢ç´¢ç­–ç•¥å¯¹ä»·å€¼åˆ†è§£çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09792">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d793df109431ade7356296eb3505059b" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Robust-and-Diverse-Multi-Agent-Learning-via-Rational-Policy-Gradient"><a href="#Robust-and-Diverse-Multi-Agent-Learning-via-Rational-Policy-Gradient" class="headerlink" title="Robust and Diverse Multi-Agent Learning via Rational Policy Gradient"></a>Robust and Diverse Multi-Agent Learning via Rational Policy Gradient</h2><p><strong>Authors:Niklas Lauffer, Ameesh Shah, Micah Carroll, Sanjit A. Seshia, Stuart Russell, Michael Dennis</strong></p>
<p>Adversarial optimization algorithms that explicitly search for flaws in agentsâ€™ policies have been successfully applied to finding robust and diverse policies in multi-agent settings. However, the success of adversarial optimization has been largely limited to zero-sum settings because its naive application in cooperative settings leads to a critical failure mode: agents are irrationally incentivized to self-sabotage, blocking the completion of tasks and halting further learning. To address this, we introduce Rationality-preserving Policy Optimization (RPO), a formalism for adversarial optimization that avoids self-sabotage by ensuring agents remain rationalâ€“that is, their policies are optimal with respect to some possible partner policy. To solve RPO, we develop Rational Policy Gradient (RPG), which trains agents to maximize their own reward in a modified version of the original game in which we use opponent shaping techniques to optimize the adversarial objective. RPG enables us to extend a variety of existing adversarial optimization algorithms that, no longer subject to the limitations of self-sabotage, can find adversarial examples, improve robustness and adaptability, and learn diverse policies. We empirically validate that our approach achieves strong performance in several popular cooperative and general-sum environments. Our project page can be found at <a target="_blank" rel="noopener" href="https://rational-policy-gradient.github.io/">https://rational-policy-gradient.github.io</a>.</p>
<blockquote>
<p>å¯¹æŠ—ä¼˜åŒ–ç®—æ³•æ˜¾å¼åœ°å¯»æ‰¾æ™ºèƒ½ä½“ç­–ç•¥ä¸­çš„ç¼ºé™·ï¼Œå¹¶å·²æˆåŠŸåº”ç”¨äºå¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„ç¨³å¥æ€§å’Œå¤šæ ·æ€§ç­–ç•¥çš„å‘ç°ã€‚ç„¶è€Œï¼Œå¯¹æŠ—ä¼˜åŒ–çš„æˆåŠŸå¤§å¤šå±€é™äºé›¶å’Œç¯å¢ƒä¸­ï¼Œå› ä¸ºå…¶åœ¨åˆä½œç¯å¢ƒä¸­çš„ç®€å•åº”ç”¨ä¼šå¯¼è‡´ä¸€ç§å…³é”®å¤±è´¥æ¨¡å¼ï¼šæ™ºèƒ½ä½“ä¼šå—åˆ°éç†æ€§æ¿€åŠ±æ¥è‡ªæˆ‘ç ´åï¼Œé˜»æ­¢ä»»åŠ¡çš„å®Œæˆå¹¶é˜»æ­¢è¿›ä¸€æ­¥çš„å­¦ä¹ ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç†æ€§ä¿æŒç­–ç•¥ä¼˜åŒ–ï¼ˆRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯¹æŠ—æ€§ä¼˜åŒ–çš„å½¢å¼åŒ–è¡¨è¿°ï¼Œå®ƒé€šè¿‡ç¡®ä¿æ™ºèƒ½ä½“ä¿æŒç†æ€§æ¥é¿å…è‡ªæˆ‘ç ´åï¼Œå³ä»–ä»¬çš„ç­–ç•¥ç›¸å¯¹äºæŸäº›å¯èƒ½çš„åˆä½œä¼™ä¼´ç­–ç•¥æ˜¯æœ€ä¼˜çš„ã€‚ä¸ºäº†è§£å†³RPOé—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç†æ€§ç­–ç•¥æ¢¯åº¦ï¼ˆRPGï¼‰æ–¹æ³•ï¼Œå®ƒè®­ç»ƒæ™ºèƒ½ä½“åœ¨åŸå§‹æ¸¸æˆçš„ä¿®æ”¹ç‰ˆä¸­æœ€å¤§åŒ–è‡ªå·±çš„å¥–åŠ±ï¼Œå¹¶ä½¿ç”¨å¯¹æ‰‹å¡‘é€ æŠ€æœ¯æ¥ä¼˜åŒ–å¯¹æŠ—æ€§ç›®æ ‡ã€‚RPGä½¿æˆ‘ä»¬èƒ½å¤Ÿæ‰©å±•å„ç§ç°æœ‰çš„å¯¹æŠ—ä¼˜åŒ–ç®—æ³•ï¼Œä¸å†å—è‡ªæˆ‘ç ´åçš„é™åˆ¶ï¼Œå¯ä»¥å‘ç°å¯¹æŠ—æ€§ç¤ºä¾‹ï¼Œæé«˜ç¨³å¥æ€§å’Œé€‚åº”æ€§ï¼Œå¹¶å­¦ä¹ å¤šç§ç­–ç•¥ã€‚æˆ‘ä»¬é€šè¿‡å®è¯ç ”ç©¶éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡ ç§æµè¡Œçš„åˆä½œå’Œä¸€èˆ¬æ€»å’Œç¯å¢ƒä¸­å®ç°äº†å‡ºè‰²çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://rational-policy-gradient.github.ioæ‰¾åˆ°./">https://rational-policy-gradient.github.ioæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09535v1">PDF</a> Published at NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>å¯¹æŠ—æ€§ä¼˜åŒ–ç®—æ³•é€šè¿‡å¯»æ‰¾æ™ºèƒ½ä½“ç­–ç•¥çš„ç¼ºé™·ï¼Œå·²æˆåŠŸåº”ç”¨äºå¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å¯»æ‰¾ç¨³å¥å’Œå¤šæ ·åŒ–çš„ç­–ç•¥ã€‚ç„¶è€Œï¼Œå¯¹æŠ—æ€§ä¼˜åŒ–çš„æˆåŠŸä¸»è¦å±€é™äºé›¶å’Œç¯å¢ƒä¸­ï¼Œå› ä¸ºå…¶åœ¨åˆä½œç¯å¢ƒä¸­çš„ç›´æ¥åº”ç”¨ä¼šå¯¼è‡´å…³é”®å¤±è´¥æ¨¡å¼â€”â€”æ™ºèƒ½ä½“å—åˆ°éç†æ€§æ¿€åŠ±å»è‡ªæˆ‘ç ´åï¼Œé˜»æ­¢ä»»åŠ¡å®Œæˆå¹¶é˜»æ­¢è¿›ä¸€æ­¥å­¦ä¹ ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç†æ€§ç­–ç•¥ä¼˜åŒ–ï¼ˆRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¯¹æŠ—æ€§ä¼˜åŒ–çš„å½¢å¼åŒ–æ–¹æ³•ï¼Œé€šè¿‡ç¡®ä¿æ™ºèƒ½ä½“ä¿æŒç†æ€§é¿å…è‡ªæˆ‘ç ´åâ€”â€”å³å…¶ç­–ç•¥å¯¹äºå¯èƒ½çš„å¯¹æ‰‹ç­–ç•¥æ¥è¯´æ˜¯æœ€ä½³çš„ã€‚ä¸ºè§£å†³RPOé—®é¢˜ï¼Œæˆ‘ä»¬å‘å±•äº†ç†æ€§ç­–ç•¥æ¢¯åº¦æ³•ï¼ˆRPGï¼‰ï¼Œå®ƒé€šè¿‡è®­ç»ƒæ™ºèƒ½ä½“ä»¥æœ€å¤§åŒ–å…¶è‡ªèº«å¥–åŠ±äºåŸå§‹æ¸¸æˆçš„ä¸€ç§æ”¹è¿›ç‰ˆæœ¬ä¸­å®ç°ä¼˜åŒ–å¯¹æŠ—ç›®æ ‡çš„ç›®æ ‡ã€‚RPGä½¿æˆ‘ä»¬èƒ½å¤Ÿæ‰©å±•å„ç§ç°æœ‰çš„å¯¹æŠ—æ€§ä¼˜åŒ–ç®—æ³•ï¼Œä¸å†å—åˆ¶äºè‡ªæˆ‘ç ´åçš„é™åˆ¶ï¼Œå¯ä»¥å‘ç°å¯¹æŠ—æ€§ä¾‹å­ï¼Œæé«˜ç¨³å¥æ€§å’Œé€‚åº”æ€§ï¼Œå¹¶å­¦ä¹ å¤šæ ·åŒ–çš„ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæµè¡Œçš„åˆä½œå’Œé€šç”¨ç¯å¢ƒä¸­çš„è¡¨ç°è¿›è¡Œäº†å®è¯éªŒè¯ã€‚æ¬¢è¿è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://rational-policy-gradient.github.io/">https://rational-policy-gradient.github.io</a> äº†è§£æ›´å¤šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æŠ—æ€§ä¼˜åŒ–ç®—æ³•åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å¯»æ‰¾ç¨³å¥å’Œå¤šæ ·åŒ–çš„ç­–ç•¥æ–¹é¢è¡¨ç°å‡ºæˆåŠŸåº”ç”¨ã€‚</li>
<li>å¯¹æŠ—æ€§ä¼˜åŒ–çš„æˆåŠŸä¸»è¦å±€é™äºé›¶å’Œç¯å¢ƒä¸­ã€‚</li>
<li>åœ¨åˆä½œç¯å¢ƒä¸­ç›´æ¥åº”ç”¨å¯¹æŠ—æ€§ä¼˜åŒ–å¯èƒ½å¯¼è‡´æ™ºèƒ½ä½“è‡ªæˆ‘ç ´åçš„é—®é¢˜ã€‚</li>
<li>ä¸ºè§£å†³è‡ªæˆ‘ç ´åé—®é¢˜ï¼Œæå‡ºäº†ç†æ€§ç­–ç•¥ä¼˜åŒ–ï¼ˆRPOï¼‰æ–¹æ³•ã€‚</li>
<li>å‘å±•äº†ç†æ€§ç­–ç•¥æ¢¯åº¦æ³•ï¼ˆRPGï¼‰ä»¥è§£å†³RPOé—®é¢˜ã€‚</li>
<li>RPGèƒ½å¤Ÿæ‰©å±•å¯¹æŠ—æ€§ä¼˜åŒ–ç®—æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿå‘ç°å¯¹æŠ—æ€§ä¾‹å­ï¼Œæé«˜ç¨³å¥æ€§å’Œé€‚åº”æ€§ï¼Œå¹¶å­¦ä¹ å¤šæ ·åŒ–ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09535">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8f4c776316248166198e4a6ddd4c6ccf" align="middle">
<img src="https://picx.zhimg.com/v2-d9ebc02f35ebbb60c02d88ad773be69f" align="middle">
<img src="https://picx.zhimg.com/v2-1fdaed27f1bc4cdf348249432cfc7c5c" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="From-Pixels-to-Cooperation-Multi-Agent-Reinforcement-Learning-based-on-Multimodal-World-Models"><a href="#From-Pixels-to-Cooperation-Multi-Agent-Reinforcement-Learning-based-on-Multimodal-World-Models" class="headerlink" title="From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models"></a>From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models</h2><p><strong>Authors:Sureyya Akin, Kavita Srivastava, Prateek B. Kapoor, Pradeep G. Sethi, Sunita Q. Patel, Rahu Srivastava</strong></p>
<p>Learning cooperative multi-agent policies directly from high-dimensional, multimodal sensory inputs like pixels and audio (from pixels) is notoriously sample-inefficient. Model-free Multi-Agent Reinforcement Learning (MARL) algorithms struggle with the joint challenge of representation learning, partial observability, and credit assignment. To address this, we propose a novel framework based on a shared, generative Multimodal World Model (MWM). Our MWM is trained to learn a compressed latent representation of the environmentâ€™s dynamics by fusing distributed, multimodal observations from all agents using a scalable attention-based mechanism. Subsequently, we leverage this learned MWM as a fast, â€œimaginedâ€ simulator to train cooperative MARL policies (e.g., MAPPO) entirely within its latent space, decoupling representation learning from policy learning. We introduce a new set of challenging multimodal, multi-agent benchmarks built on a 3D physics simulator. Our experiments demonstrate that our MWM-MARL framework achieves orders-of-magnitude greater sample efficiency compared to state-of-the-art model-free MARL baselines. We further show that our proposed multimodal fusion is essential for task success in environments with sensory asymmetry and that our architecture provides superior robustness to sensor-dropout, a critical feature for real-world deployment.</p>
<blockquote>
<p>ç›´æ¥ä»åƒç´ å’ŒéŸ³é¢‘ç­‰é«˜çº§ã€å¤šæ¨¡å¼æ„Ÿå®˜è¾“å…¥ä¸­å­¦ä¹ åˆä½œå¤šæ™ºèƒ½ä½“ç­–ç•¥æ˜¯éå¸¸æ ·æœ¬ä½æ•ˆçš„ã€‚æ— æ¨¡å‹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç®—æ³•åœ¨è¡¨ç¤ºå­¦ä¹ ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§å’Œä¿¡ç”¨åˆ†é…æ–¹é¢é¢ä¸´è”åˆæŒ‘æˆ˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå…±äº«ç”Ÿæˆå¼å¤šæ¨¡å¼ä¸–ç•Œæ¨¡å‹ï¼ˆMWMï¼‰çš„æ–°å‹æ¡†æ¶ã€‚æˆ‘ä»¬çš„MWMç»è¿‡è®­ç»ƒï¼Œé€šè¿‡èåˆæ‰€æœ‰æ™ºèƒ½ä½“çš„åˆ†å¸ƒå¼å¤šæ¨¡å¼è§‚å¯Ÿç»“æœï¼Œå­¦ä¹ ç¯å¢ƒçš„åŠ¨æ€å‹ç¼©æ½œåœ¨è¡¨ç¤ºï¼Œè¿™å¾—ç›Šäºä¸€ç§å¯æ‰©å±•çš„åŸºäºæ³¨æ„åŠ›çš„æœºåˆ¶ã€‚éšåï¼Œæˆ‘ä»¬åˆ©ç”¨å­¦åˆ°çš„MWMä½œä¸ºå¿«é€Ÿâ€œæƒ³è±¡â€æ¨¡æ‹Ÿå™¨ï¼Œåœ¨å…¶æ½œåœ¨ç©ºé—´å†…å®Œå…¨è®­ç»ƒåˆä½œMARLç­–ç•¥ï¼ˆä¾‹å¦‚MAPPOï¼‰ï¼Œä»è€Œå°†è¡¨ç¤ºå­¦ä¹ ä¸ç­–ç•¥å­¦ä¹ è§£è€¦ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€å¥—åŸºäº3Dç‰©ç†æ¨¡æ‹Ÿå™¨æ„å»ºçš„æŒ‘æˆ˜æ€§å¤šæ¨¡å¼å¤šæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MWM-MARLæ¡†æ¶ä¸æœ€æ–°çš„æ— æ¨¡å‹MARLåŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†æ ·æœ¬æ•ˆç‡çš„æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬è¿˜è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„å¤šæ¨¡å¼èåˆå¯¹äºæ„Ÿå®˜ä¸å¯¹ç§°ç¯å¢ƒä¸­çš„ä»»åŠ¡æˆåŠŸè‡³å…³é‡è¦ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„æ¶æ„å¯¹ä¼ æ„Ÿå™¨æ‰çº¿å…·æœ‰å‡ºè‰²çš„é²æ£’æ€§ï¼Œè¿™æ˜¯ç°å®ä¸–ç•Œéƒ¨ç½²çš„å…³é”®åŠŸèƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.01310v2">PDF</a> We have identified critical issues in the code implementation that severely deviate from Algorithm 1, invalidating all experimental results and conclusions. Despite exhaustive efforts to correct these issues, we find they fundamentally undermine the paperâ€™s core claims. To uphold academic integrity and prevent misinformation, we are withdrawing this manuscript</p>
<p><strong>Summary</strong></p>
<p>åŸºäºåƒç´ å’ŒéŸ³é¢‘ç­‰å¤šå…ƒæ„Ÿå®˜è¾“å…¥ï¼Œå­¦ä¹ å¤šæ™ºèƒ½ä½“åˆä½œç­–ç•¥çš„æŒ‘æˆ˜åœ¨äºæ ·æœ¬æ•ˆç‡ä½ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–°å‹æ¡†æ¶ï¼Œåˆ©ç”¨å…±äº«ç”Ÿæˆå¼å¤šæ¨¡æ€ä¸–ç•Œæ¨¡å‹ï¼ˆMWMï¼‰ã€‚MWMè®­ç»ƒå¾—åˆ°ç¯å¢ƒçš„å‹ç¼©æ½œåœ¨è¡¨ç°ï¼Œé€šè¿‡å¯æ‰©å±•çš„æ³¨æ„åŠ›æœºåˆ¶èåˆæ‰€æœ‰æ™ºèƒ½ä½“çš„åˆ†å¸ƒå¼å¤šæ¨¡æ€è§‚å¯Ÿã€‚éšåï¼Œæˆ‘ä»¬åœ¨MWMä¸­å­¦ä¹ åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ”¿ç­–ï¼ˆå¦‚MAPPOï¼‰ï¼Œå®Œå…¨è„±ç¦»å…¶æ½œåœ¨ç©ºé—´ï¼Œä½¿è¡¨ç°å­¦ä¹ å’Œæ”¿ç­–å­¦ä¹ è§£è€¦ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MWM-MARLæ¡†æ¶ç›¸è¾ƒäºå½“å‰å…ˆè¿›çš„æ— æ¨¡å‹MARLåŸºå‡†æµ‹è¯•ï¼Œæ ·æœ¬æ•ˆç‡æé«˜äº†æ•°å€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜åœ¨æ„Ÿå®˜ä¸å¯¹ç§°çš„ç¯å¢ƒä¸­ï¼Œæå‡ºçš„å¤šæ¨¡æ€èåˆå¯¹ä»»åŠ¡æˆåŠŸè‡³å…³é‡è¦ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„æ¶æ„å¯¹ä¼ æ„Ÿå™¨æ‰çº¿å…·æœ‰å‡ºè‰²çš„ç¨³å¥æ€§ï¼Œè¿™æ˜¯å®ç°çœŸå®ä¸–ç•Œéƒ¨ç½²çš„å…³é”®ç‰¹æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç›´æ¥ä»é«˜ç»´ã€å¤šæ¨¡æ€æ„Ÿå®˜è¾“å…¥ï¼ˆå¦‚åƒç´ å’ŒéŸ³é¢‘ï¼‰å­¦ä¹ æ”¿ç­–æ˜¯æ ·æœ¬æ•ˆç‡ä½ä¸‹çš„ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ¡†æ¶ï¼ŒåŸºäºå…±äº«ç”Ÿæˆå¼å¤šæ¨¡æ€ä¸–ç•Œæ¨¡å‹ï¼ˆMWMï¼‰ï¼Œå­¦ä¹ ç¯å¢ƒåŠ¨åŠ›å­¦å‹ç¼©æ½œåœ¨è¡¨ç°ã€‚</li>
<li>ä½¿ç”¨å¯æ‰©å±•çš„æ³¨æ„åŠ›æœºåˆ¶èåˆæ‰€æœ‰æ™ºèƒ½ä½“çš„åˆ†å¸ƒå¼å¤šæ¨¡æ€è§‚å¯Ÿã€‚</li>
<li>åˆ©ç”¨å­¦åˆ°çš„MWMä½œä¸ºå¿«é€Ÿâ€œæƒ³è±¡â€æ¨¡æ‹Ÿå™¨ï¼Œå®Œå…¨åœ¨æ½œåœ¨ç©ºé—´å†…è®­ç»ƒåˆä½œMARLæ”¿ç­–ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒMWM-MARLæ¡†æ¶ç›¸è¾ƒäºå…¶ä»–åŸºå‡†æµ‹è¯•æœ‰æ›´é«˜çš„æ ·æœ¬æ•ˆç‡ã€‚</li>
<li>å¤šæ¨¡æ€èåˆåœ¨æ„Ÿå®˜ä¸å¯¹ç§°çš„ç¯å¢ƒä¸­æ˜¯ä»»åŠ¡æˆåŠŸçš„å…³é”®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.01310">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9c4ea2c0ee5969827d548066661552d6" align="middle">
<img src="https://picx.zhimg.com/v2-72929647d0e3c8bae3e0e916bc562d60" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="HRM-Agent-Training-a-recurrent-reasoning-model-in-dynamic-environments-using-reinforcement-learning"><a href="#HRM-Agent-Training-a-recurrent-reasoning-model-in-dynamic-environments-using-reinforcement-learning" class="headerlink" title="HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning"></a>HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning</h2><p><strong>Authors:Long H Dang, David Rawlinson</strong></p>
<p>The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities given its small size, but has only been applied to supervised, static, fully-observable problems. One of HRMâ€™s strengths is its ability to adapt its computational effort to the difficulty of the problem. However, in its current form it cannot integrate and reuse computation from previous time-steps if the problem is dynamic, uncertain or partially observable, or be applied where the correct action is undefined, characteristics of many real-world problems.   This paper presents HRM-Agent, a variant of HRM trained using only reinforcement learning. We show that HRM can learn to navigate to goals in dynamic and uncertain maze environments. Recent work suggests that HRMâ€™s reasoning abilities stem from its recurrent inference process. We explore the dynamics of the recurrent inference process and find evidence that it is successfully reusing computation from earlier environment time-steps.</p>
<blockquote>
<p>å±‚æ¬¡æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰å› å…¶è§„æ¨¡å°è€Œå…·æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„æ¨ç†èƒ½åŠ›ï¼Œä½†ä»…åº”ç”¨äºç›‘ç£ã€é™æ€ã€å®Œå…¨å¯è§‚å¯Ÿçš„é—®é¢˜ã€‚HRMçš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯å…¶é€‚åº”é—®é¢˜éš¾åº¦çš„è®¡ç®—åŠªåŠ›èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨ç°æœ‰å½¢å¼ä¸‹ï¼Œå¦‚æœé—®é¢˜æ˜¯åŠ¨æ€ã€ä¸ç¡®å®šæˆ–éƒ¨åˆ†å¯è§‚å¯Ÿçš„ï¼Œæˆ–è€…æ­£ç¡®è¡ŒåŠ¨æœªå®šä¹‰ï¼ˆè®¸å¤šç°å®é—®é¢˜çš„ç‰¹å¾ï¼‰ï¼Œå®ƒæ— æ³•æ•´åˆå’Œé‡å¤ä½¿ç”¨ä¹‹å‰çš„è®¡ç®—æ­¥éª¤ä¸­çš„è®¡ç®—ã€‚æœ¬æ–‡æå‡ºäº†HRM-Agentï¼Œè¿™æ˜¯ä¸€ç§ä»…é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒçš„HRMå˜ä½“ã€‚æˆ‘ä»¬å±•ç¤ºäº†HRMå¯ä»¥åœ¨åŠ¨æ€å’Œä¸ç¡®å®šçš„è¿·å®«ç¯å¢ƒä¸­å­¦ä¹ å®ç°ç›®æ ‡å¯¼èˆªã€‚æœ€è¿‘çš„å·¥ä½œè¡¨æ˜ï¼ŒHRMçš„æ¨ç†èƒ½åŠ›æ¥æºäºå…¶é€’å½’æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬æ¢ç´¢äº†é€’å½’æ¨ç†è¿‡ç¨‹çš„åŠ¨æ€æ€§ï¼Œå¹¶å‘ç°å®ƒæˆåŠŸé‡å¤ä½¿ç”¨äº†æ—©æœŸç¯å¢ƒæ—¶é—´æ­¥çš„è®¡ç®—è¯æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.22832v1">PDF</a> 14 pages, 9 figures, 1 table</p>
<p><strong>Summary</strong>ï¼šå±‚æ¬¡åŒ–æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰å…·æœ‰å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶ä»…é€‚ç”¨äºç›‘ç£çš„ã€é™æ€çš„ã€å®Œå…¨å¯è§‚å¯Ÿçš„é—®é¢˜ã€‚HRMçš„ä¸€ä¸ªå¼ºé¡¹æ˜¯å…¶èƒ½å¤Ÿè‡ªé€‚åº”è°ƒæ•´è®¡ç®—åŠªåŠ›ä»¥åº”å¯¹é—®é¢˜çš„éš¾åº¦ã€‚ç„¶è€Œï¼Œå½“é—®é¢˜å…·æœ‰åŠ¨æ€æ€§ã€ä¸ç¡®å®šæ€§ã€éƒ¨åˆ†å¯è§‚å¯Ÿæ€§æˆ–æ­£ç¡®è¡ŒåŠ¨æœªå®šä¹‰ç­‰ç‰¹æ€§æ—¶ï¼Œå½“å‰çš„HRMæ— æ³•æ•´åˆå’Œé‡ç”¨å…ˆå‰çš„è®¡ç®—ã€‚æœ¬æ–‡ä»‹ç»äº†HRMçš„å˜ç§â€”â€”HRM-Agentï¼Œå®ƒä»…é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒHRMèƒ½å¤Ÿåœ¨åŠ¨æ€å’Œä¸ç¡®å®šçš„è¿·å®«ç¯å¢ƒä¸­å­¦ä¹ å®ç°ç›®æ ‡ã€‚æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼ŒHRMçš„æ¨ç†èƒ½åŠ›æ¥æºäºå…¶é€’å½’æ¨ç†è¿‡ç¨‹ã€‚æœ¬æ–‡æ¢è®¨äº†é€’å½’æ¨ç†è¿‡ç¨‹çš„åŠ¨æ€æ€§ï¼Œå¹¶å‘ç°HRMèƒ½å¤ŸæˆåŠŸé‡ç”¨æ—©æœŸç¯å¢ƒæ—¶é—´æ­¥çš„è®¡ç®—ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å±‚æ¬¡åŒ–æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰å…·æœ‰å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ“…é•¿å¤„ç†ç›‘ç£çš„ã€é™æ€çš„ã€å®Œå…¨å¯è§‚å¯Ÿçš„é—®é¢˜ã€‚</li>
<li>HRMèƒ½å¤Ÿè‡ªé€‚åº”è°ƒæ•´è®¡ç®—åŠªåŠ›ä»¥åº”å¯¹é—®é¢˜çš„éš¾åº¦ã€‚</li>
<li>å½“å‰HRMæ— æ³•å¤„ç†åŠ¨æ€ã€ä¸ç¡®å®šæˆ–éƒ¨åˆ†å¯è§‚å¯Ÿçš„é—®é¢˜ï¼Œä»¥åŠæ­£ç¡®è¡ŒåŠ¨æœªå®šä¹‰çš„é—®é¢˜ï¼Œè¿™æ˜¯å…¶å±€é™æ‰€åœ¨ã€‚</li>
<li>HRM-Agentæ˜¯HRMçš„ä¸€ç§å˜ç§ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚</li>
<li>HRM-Agentèƒ½å¤Ÿåœ¨åŠ¨æ€å’Œä¸ç¡®å®šçš„è¿·å®«ç¯å¢ƒä¸­å­¦ä¹ å®ç°ç›®æ ‡ã€‚</li>
<li>HRMçš„æ¨ç†èƒ½åŠ›æ¥æºäºå…¶é€’å½’æ¨ç†è¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.22832">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c2a49e98a3a23315901d2bedc73b8c56" align="middle">
<img src="https://picx.zhimg.com/v2-871dcb67a26d0686b85e3be8a639bade" align="middle">
<img src="https://picx.zhimg.com/v2-648a29a710d67b153f0977e5de0a5cd5" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="A-Brain-Cell-Type-Resource-Created-by-Large-Language-Models-and-a-Multi-Agent-AI-System-for-Collaborative-Community-Annotation"><a href="#A-Brain-Cell-Type-Resource-Created-by-Large-Language-Models-and-a-Multi-Agent-AI-System-for-Collaborative-Community-Annotation" class="headerlink" title="A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation"></a>A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation</h2><p><strong>Authors:Rongbin Li, Wenbo Chen, Zhao Li, Rodrigo Munoz-Castaneda, Jinbo Li, Neha S. Maurya, Arnav Solanki, Huan He, Hanwen Xing, Meaghan Ramlakhan, Zachary Wise, Nelson Johansen, Zhuhao Wu, Hua Xu, Michael Hawrylycz, W. Jim Zheng</strong></p>
<p>Single-cell RNA sequencing has transformed our ability to identify diverse cell types and their transcriptomic signatures. However, annotating these signatures-especially those involving poorly characterized genes-remains a major challenge. Traditional methods, such as Gene Set Enrichment Analysis (GSEA), depend on well-curated annotations and often perform poorly in these contexts. Large Language Models (LLMs) offer a promising alternative but struggle to represent complex biological knowledge within structured ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID: <a target="_blank" rel="noopener" href="https://biodataai.uth.edu/BRAINCELL-AID">https://biodataai.uth.edu/BRAINCELL-AID</a>), a novel multi-agent AI system that integrates free-text descriptions with ontology labels to enable more accurate and robust gene set annotation. By incorporating retrieval-augmented generation (RAG), we developed a robust agentic workflow that refines predictions using relevant PubMed literature, reducing hallucinations and enhancing interpretability. Using this workflow, we achieved correct annotations for 77% of mouse gene sets among their top predictions. Applying this approach, we annotated 5,322 brain cell clusters from the comprehensive mouse brain cell atlas generated by the BRAIN Initiative Cell Census Network, enabling novel insights into brain cell function by identifying region-specific gene co-expression patterns and inferring functional roles of gene ensembles. BRAINCELL-AID also identifies Basal Ganglia-related cell types with neurologically meaningful descriptions. Hence, we create a valuable resource to support community-driven cell type annotation.</p>
<blockquote>
<p>å•ç»†èƒRNAæµ‹åºæŠ€æœ¯å·²ç»æ”¹å˜äº†æˆ‘ä»¬è¯†åˆ«å¤šç§ç»†èƒç±»å‹åŠå…¶è½¬å½•ç»„ç‰¹å¾çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¯¹è¿™äº›ç‰¹å¾è¿›è¡Œæ³¨é‡Šï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠç‰¹å¾ä¸æ˜åŸºå› çš„ç‰¹å¾ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚åŸºå› é›†å¯Œé›†åˆ†æï¼ˆGSEAï¼‰ï¼Œä¾èµ–äºç²¾å¿ƒç¼–åˆ¶çš„æ³¨é‡Šï¼Œåœ¨è¿™äº›æƒ…å†µä¸‹å¾€å¾€è¡¨ç°ä¸ä½³ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›äº†æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†åœ¨ç»“æ„åŒ–æœ¬ä½“è®ºä¸­è¡¨ç¤ºå¤æ‚çš„ç”Ÿç‰©å­¦çŸ¥è¯†æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†BRAINCELL-AIDï¼ˆBRAINCELL-AIDï¼š<a target="_blank" rel="noopener" href="https://biodataai.uth.edu/BRAINCELL-AID%EF%BC%89%EF%BC%8C%E8%BF%99%E6%98%AF%E4%B8%80%E7%A7%8D%E6%96%B0%E5%9E%8B%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93AI%E7%B3%BB%E7%BB%9F%EF%BC%8C%E5%AE%83%E5%B0%86%E8%87%AA%E7%94%B1%E6%96%87%E6%9C%AC%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%9C%AC%E4%BD%93%E8%AE%BA%E6%A0%87%E7%AD%BE%E7%9B%B8%E7%BB%93%E5%90%88%EF%BC%8C%E8%83%BD%E5%A4%9F%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%87%86%E7%A1%AE%E5%92%8C%E7%A8%B3%E5%81%A5%E7%9A%84%E5%9F%BA%E5%9B%A0%E9%9B%86%E6%B3%A8%E9%87%8A%E3%80%82%E9%80%9A%E8%BF%87%E5%BC%95%E5%85%A5%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%EF%BC%88RAG%EF%BC%89%E6%8A%80%E6%9C%AF%EF%BC%8C%E6%88%91%E4%BB%AC%E5%BC%80%E5%8F%91%E4%BA%86%E4%B8%80%E4%B8%AA%E7%A8%B3%E5%81%A5%E7%9A%84%E6%99%BA%E8%83%BD%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%8C%E5%88%A9%E7%94%A8%E7%9B%B8%E5%85%B3%E7%9A%84PubMed%E6%96%87%E7%8C%AE%E6%9D%A5%E4%BC%98%E5%8C%96%E9%A2%84%E6%B5%8B%EF%BC%8C%E5%87%8F%E5%B0%91%E4%BA%86%E5%B9%BB%E8%A7%89%E5%B9%B6%E5%A2%9E%E5%BC%BA%E4%BA%86%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E3%80%82%E4%BD%BF%E7%94%A8%E8%BF%99%E4%B8%AA%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8%E9%A1%B6%E7%BA%A7%E9%A2%84%E6%B5%8B%E4%B8%AD%E5%AE%9E%E7%8E%B0%E4%BA%86%E5%AF%B977%%E7%9A%84%E8%80%81%E9%BC%A0%E5%9F%BA%E5%9B%A0%E9%9B%86%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%B3%A8%E9%87%8A%E3%80%82%E5%BA%94%E7%94%A8%E8%BF%99%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AF%B9%E7%94%B1BRAIN">https://biodataai.uth.edu/BRAINCELL-AIDï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“AIç³»ç»Ÿï¼Œå®ƒå°†è‡ªç”±æ–‡æœ¬æè¿°ä¸æœ¬ä½“è®ºæ ‡ç­¾ç›¸ç»“åˆï¼Œèƒ½å¤Ÿå®ç°æ›´å‡†ç¡®å’Œç¨³å¥çš„åŸºå› é›†æ³¨é‡Šã€‚é€šè¿‡å¼•å…¥æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç¨³å¥çš„æ™ºèƒ½å·¥ä½œæµç¨‹ï¼Œåˆ©ç”¨ç›¸å…³çš„PubMedæ–‡çŒ®æ¥ä¼˜åŒ–é¢„æµ‹ï¼Œå‡å°‘äº†å¹»è§‰å¹¶å¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚ä½¿ç”¨è¿™ä¸ªå·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬åœ¨é¡¶çº§é¢„æµ‹ä¸­å®ç°äº†å¯¹77%çš„è€é¼ åŸºå› é›†çš„æ­£ç¡®æ³¨é‡Šã€‚åº”ç”¨è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¯¹ç”±BRAIN</a> Initiativeç»†èƒæ™®æŸ¥ç½‘ç»œç”Ÿæˆçš„ç»¼åˆå°é¼ å¤§è„‘ç»†èƒå›¾è°±ä¸­çš„5322ä¸ªå¤§è„‘ç»†èƒé›†ç¾¤è¿›è¡Œäº†æ³¨é‡Šï¼Œé€šè¿‡è¯†åˆ«åŒºåŸŸç‰¹å®šçš„åŸºå› å…±è¡¨è¾¾æ¨¡å¼å¹¶æ¨æ–­åŸºå› ç»„åˆçš„åŠŸèƒ½è§’è‰²ï¼Œä¸ºå¤§è„‘ç»†èƒåŠŸèƒ½æä¾›äº†æ–°çš„è§è§£ã€‚BRAINCELL-AIDè¿˜ç¡®å®šäº†ä¸åŸºåº•èŠ‚ç›¸å…³çš„ç»†èƒç±»å‹ï¼Œå¹¶æä¾›äº†ç¥ç»å­¦ä¸Šæœ‰æ„ä¹‰çš„æè¿°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæœ‰ä»·å€¼çš„èµ„æºæ¥æ”¯æŒç¤¾åŒºé©±åŠ¨çš„ç»†èƒç±»å‹æ³¨é‡Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17064v3">PDF</a> 23 pages, 6 figures, 2 tables</p>
<p><strong>Summary</strong></p>
<p>å•ç»†èƒRNAæµ‹åºæŠ€æœ¯å·²æå¤§åœ°æå‡äº†æˆ‘ä»¬å¯¹å¤šæ ·ç»†èƒç±»å‹åŠå…¶è½¬å½•ç»„ç‰¹å¾çš„è®¤è¯†ã€‚ç„¶è€Œï¼Œå¯¹è¿™äº›ç‰¹å¾è¿›è¡Œæ³¨é‡Šï¼Œå°¤å…¶æ˜¯æ¶‰åŠè¡¨å¾ä¸ä½³çš„åŸºå› æ—¶ï¼Œä»é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚åŸºå› é›†å¯Œé›†åˆ†æï¼ˆGSEAï¼‰ä¾èµ–äºç²¾ç»†çš„æ³¨é‡Šï¼Œåœ¨è¿™äº›æƒ…å†µä¸‹å¾€å¾€è¡¨ç°ä¸ä½³ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½æä¾›æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†åœ¨ç»“æ„åŒ–æœ¬ä½“ä¸­è¡¨è¾¾å¤æ‚çš„ç”Ÿç‰©å­¦çŸ¥è¯†æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†BRAINCELL-AIDç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿæ•´åˆäº†è‡ªç”±æ–‡æœ¬æè¿°å’Œæœ¬ä½“æ ‡ç­¾ï¼Œå®ç°äº†æ›´å‡†ç¡®ã€æ›´ç¨³å¥çš„åŸºå› é›†æ³¨é‡Šã€‚é€šè¿‡å¼•å…¥æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå¼ºå¤§çš„å¤šæ™ºèƒ½ä½“å·¥ä½œæµç¨‹ï¼Œåˆ©ç”¨ç›¸å…³çš„PubMedæ–‡çŒ®å¯¹é¢„æµ‹è¿›è¡Œç²¾ç»†åŒ–ä¿®æ­£ï¼Œå‡å°‘äº†è™šå¹»æˆåˆ†å¹¶å¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚åˆ©ç”¨æ­¤å·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬åœ¨é¡¶çº§é¢„æµ‹ä¸­å¯¹77%çš„è€é¼ åŸºå› é›†è¿›è¡Œäº†æ­£ç¡®çš„æ³¨é‡Šã€‚åº”ç”¨æ­¤æ–¹æ³•ï¼Œæˆ‘ä»¬å¯¹ç”±BRAIN Initiativeç»†èƒæ™®æŸ¥ç½‘ç»œç”Ÿæˆçš„ç»¼åˆè€é¼ å¤§è„‘ç»†èƒå›¾è°±ä¸­çš„5322ä¸ªå¤§è„‘ç»†èƒç°‡è¿›è¡Œäº†æ³¨é‡Šï¼Œé€šè¿‡è¯†åˆ«åŒºåŸŸç‰¹å®šçš„åŸºå› å…±è¡¨è¾¾æ¨¡å¼å¹¶æ¨æ–­åŸºå› ç»„åˆçš„åŠŸèƒ½è§’è‰²ï¼Œä¸ºç†è§£å¤§è„‘ç»†èƒåŠŸèƒ½æä¾›äº†æ–°çš„è§è§£ã€‚BRAINCELL-AIDè¿˜è¯†åˆ«äº†ä¸åŸºåº•èŠ‚ç›¸å…³çš„ç»†èƒç±»å‹å¹¶æä¾›ç¥ç»å­¦ä¸Šæœ‰æ„ä¹‰çš„æè¿°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæœ‰ä»·å€¼çš„èµ„æºï¼Œä»¥æ”¯æŒç¤¾åŒºé©±åŠ¨çš„ç»†èƒç±»å‹æ³¨é‡Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å•ç»†èƒRNAæµ‹åºå·²æ˜¾è‘—æ”¹å–„å¯¹ç»†èƒç±»å‹å’Œè½¬å½•ç»„ç‰¹å¾çš„è®¤è¯†ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚GSEAåœ¨åŸºå› é›†æ³¨é‡Šä¸Šå—é™äºç¼ºä¹ç²¾ç»†æ³¨é‡Šã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿç‰©å­¦çŸ¥è¯†çš„ç»“æ„åŒ–è¡¨è¾¾æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>BRAINCELL-AIDç³»ç»Ÿé€šè¿‡ç»“åˆè‡ªç”±æ–‡æœ¬å’Œæœ¬ä½“æ ‡ç­¾æé«˜äº†åŸºå› é›†æ³¨é‡Šçš„å‡†ç¡®æ€§ã€‚</li>
<li>å¼•å…¥RAGæŠ€æœ¯ä¼˜åŒ–äº†é¢„æµ‹ï¼Œå‡å°‘äº†è™šå¹»æˆåˆ†ï¼Œå¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚</li>
<li>BRAINCELL-AIDåœ¨è€é¼ åŸºå› é›†æ³¨é‡Šä¸­å–å¾—äº†æ˜¾è‘—æˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17064">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8502f3dfe64fc20ac8a6ceaebef937df" align="middle">
<img src="https://picx.zhimg.com/v2-7ac365cadddc2806215bcc7641cda113" align="middle">
<img src="https://picx.zhimg.com/v2-4e507ebd268fa1f74dcd3b3bc4561b44" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Ax-Prover-A-Deep-Reasoning-Agentic-Framework-for-Theorem-Proving-in-Mathematics-and-Quantum-Physics"><a href="#Ax-Prover-A-Deep-Reasoning-Agentic-Framework-for-Theorem-Proving-in-Mathematics-and-Quantum-Physics" class="headerlink" title="Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics"></a>Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics</h2><p><strong>Authors:Benjamin Breen, Marco Del Tredici, Jacob McCarran, Javier Aspuru Mijares, Weichen Winston Yin, Kfir Sulimany, Jacob M. Taylor, Frank H. L. Koppens, Dirk Englund</strong></p>
<p>We present Ax-Prover, a multi-agent system for automated theorem proving in Lean that can solve problems across diverse scientific domains and operate either autonomously or collaboratively with human experts. To achieve this, Ax-Prover approaches scientific problem solving through formal proof generation, a process that demands both creative reasoning and strict syntactic rigor. Ax-Prover meets this challenge by equipping Large Language Models (LLMs), which provide knowledge and reasoning, with Lean tools via the Model Context Protocol (MCP), which ensure formal correctness. To evaluate its performance as an autonomous prover, we benchmark our approach against frontier LLMs and specialized prover models on two public math benchmarks and on two Lean benchmarks we introduce in the fields of abstract algebra and quantum theory. On public datasets, Ax-Prover is competitive with state-of-the-art provers, while it largely outperforms them on the new benchmarks. This shows that, unlike specialized systems that struggle to generalize, our tool-based agentic theorem prover approach offers a generalizable methodology for formal verification across diverse scientific domains. Furthermore, we demonstrate Ax-Proverâ€™s assistant capabilities in a practical use case, showing how it enabled an expert mathematician to formalize the proof of a complex cryptography theorem.</p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºAx-Proverï¼Œè¿™æ˜¯ä¸€æ¬¾ç”¨äºLeanè‡ªåŠ¨å®šç†è¯æ˜çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œèƒ½å¤Ÿè§£å†³ä¸åŒç§‘å­¦é¢†åŸŸçš„å„ç§é—®é¢˜ï¼Œå¹¶èƒ½è‡ªä¸»è¿è¡Œæˆ–ä¸äººç±»ä¸“å®¶åä½œã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼ŒAx-Proveré€šè¿‡å½¢å¼åŒ–è¯æ˜ç”Ÿæˆæ¥è§£å†³ç§‘å­¦é—®é¢˜ï¼Œè¿™ä¸€è¿‡ç¨‹æ—¢éœ€è¦åˆ›é€ æ€§æ¨ç†åˆéœ€è¦ä¸¥æ ¼çš„å¥æ³•ä¸¥è°¨æ€§ã€‚Ax-Proveré€šè¿‡è£…å¤‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œè¿™äº›æ¨¡å‹æä¾›çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸Leanå·¥å…·ç›¸ç»“åˆï¼Œç¡®ä¿å½¢å¼æ­£ç¡®æ€§ã€‚ä¸ºäº†è¯„ä¼°å…¶ä½œä¸ºè‡ªä¸»è¯æ˜å™¨çš„æ€§èƒ½ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªå…¬å…±æ•°å­¦åŸºå‡†æµ‹è¯•ä»¥åŠæˆ‘ä»¬åœ¨æŠ½è±¡ä»£æ•°å’Œé‡å­ç†è®ºé¢†åŸŸæ¨å‡ºçš„ä¸¤ä¸ªLeanåŸºå‡†æµ‹è¯•ä¸Šå¯¹å‰æ²¿LLMå’Œä¸“ç”¨è¯æ˜å™¨æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šï¼ŒAx-Proverä¸æœ€å…ˆè¿›çš„è¯æ˜å™¨ç›¸ç«äº‰ï¼Œè€Œåœ¨æ–°åŸºå‡†æµ‹è¯•ä¸­åˆ™å¤§å¤§ä¼˜äºå®ƒä»¬ã€‚è¿™è¡¨æ˜ï¼Œä¸é‚£äº›éš¾ä»¥æ¨å¹¿çš„ä¸“ç”¨ç³»ç»Ÿä¸åŒï¼Œæˆ‘ä»¬åŸºäºå·¥å…·çš„ç†è®ºè¯æ˜è€…æ–¹æ³•æä¾›äº†ä¸€ç§è·¨ä¸åŒç§‘å­¦é¢†åŸŸçš„å¯æ¨å¹¿çš„æ­£å¼éªŒè¯æ–¹æ³•è®ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†Ax-Proveråœ¨å®é™…æ¡ˆä¾‹ä¸­çš„è¾…åŠ©èƒ½åŠ›ï¼Œè¯æ˜äº†å®ƒå¦‚ä½•å¸®åŠ©ä¸€ä½ä¸“å®¶æ•°å­¦å®¶å¯¹ä¸€ä¸ªå¤æ‚çš„å¯†ç å­¦å®šç†è¿›è¡Œå½¢å¼åŒ–è¯æ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.12787v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Ax-Proveræ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“çš„å®šç†è‡ªåŠ¨è¯æ˜ç³»ç»Ÿï¼Œèƒ½å¤Ÿåœ¨Leanä¸­è§£å†³è·¨ä¸åŒç§‘å­¦é¢†åŸŸçš„é—®é¢˜ï¼Œå¹¶èƒ½è‡ªä¸»è¿è¡Œæˆ–ä¸äººç±»ä¸“å®¶åä½œã€‚å®ƒé€šè¿‡å½¢å¼åŒ–è¯æ˜ç”Ÿæˆæ¥åº”å¯¹ç§‘å­¦é—®é¢˜è§£å†³ï¼Œè¿™éœ€è¦åˆ›é€ æ€§çš„æ¨ç†å’Œä¸¥æ ¼çš„è¯­æ³•ä¸¥è°¨æ€§ã€‚Ax-Proveré€šè¿‡è£…å¤‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè¿™äº›æ¨¡å‹æä¾›çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰åˆ©ç”¨Leanå·¥å…·ç¡®ä¿å½¢å¼æ­£ç¡®æ€§ã€‚åœ¨è‡ªä¸»è¯æ˜è€…æ€§èƒ½æ–¹é¢ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªå…¬å…±æ•°å­¦åŸºå‡†æµ‹è¯•å’Œä¸¤ä¸ªæ–°æ¨å‡ºçš„æŠ½è±¡ä»£æ•°å’Œé‡å­ç†è®ºé¢†åŸŸçš„LeanåŸºå‡†æµ‹è¯•ä¸­å¯¹æˆ‘ä»¬çš„æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šï¼ŒAx-Proverä¸æœ€å…ˆè¿›çš„è¯æ˜è€…å…·æœ‰ç«äº‰åŠ›ï¼Œè€Œåœ¨æ–°åŸºå‡†æµ‹è¯•ä¸­åˆ™å¤§å¤§ä¼˜äºå®ƒä»¬ã€‚è¿™è¡¨æ˜ï¼Œä¸é‚£äº›éš¾ä»¥æ¨å¹¿çš„ä¸“ç”¨ç³»ç»Ÿä¸åŒï¼Œæˆ‘ä»¬çš„åŸºäºå·¥å…·çš„å¤šæ™ºèƒ½ä½“å®šç†è¯æ˜æ–¹æ³•æä¾›äº†ä¸€ç§è·¨ä¸åŒç§‘å­¦é¢†åŸŸçš„å¯æ¨å¹¿çš„å½¢å¼éªŒè¯æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†Ax-Proveråœ¨å®é™…æ¡ˆä¾‹ä¸­çš„åŠ©ç†èƒ½åŠ›ï¼Œè¡¨æ˜å®ƒå¦‚ä½•å¸®åŠ©æ•°å­¦å®¶å¯¹ä¸€ä¸ªå¤æ‚çš„å¯†ç å­¦å®šç†è¿›è¡Œå½¢å¼åŒ–è¯æ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ax-Proveræ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºåœ¨Leanä¸­è¿›è¡Œå®šç†è‡ªåŠ¨è¯æ˜ã€‚</li>
<li>å®ƒèƒ½å¤Ÿè§£å†³è·¨å¤šä¸ªç§‘å­¦é¢†åŸŸçš„é—®é¢˜ï¼Œå¹¶å¯ä»¥è‡ªä¸»è¿è¡Œæˆ–ä¸äººç±»ä¸“å®¶åä½œã€‚</li>
<li>Ax-Proveré€šè¿‡å½¢å¼åŒ–è¯æ˜ç”Ÿæˆæ¥åº”å¯¹ç§‘å­¦é—®é¢˜è§£å†³ï¼Œè¿™éœ€è¦åˆ›é€ æ€§æ¨ç†å’Œä¸¥æ ¼è¯­æ³•ã€‚</li>
<li>é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ŒAx-Proverç¡®ä¿äº†å½¢å¼æ­£ç¡®æ€§ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAx-Proverçš„æ€§èƒ½ä¸æœ€å…ˆè¿›çš„è¯æ˜è€…ç›¸å½“æˆ–æ›´ä¼˜ï¼Œè¡¨æ˜å…¶è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>Ax-Proverå¯ä»¥åœ¨å®é™…åœºæ™¯ä¸­åº”ç”¨ï¼Œå¸®åŠ©ä¸“å®¶è¿›è¡Œå¤æ‚å®šç†çš„å½¢å¼åŒ–è¯æ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.12787">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-854f4a3093587f94ea96dc89343946a1" align="middle">
<img src="https://picx.zhimg.com/v2-29940358fd42aef9712baf9a0d926fa6" align="middle">
<img src="https://picx.zhimg.com/v2-1ce9b53e0ed20f9e50e716abf62e6656" align="middle">
<img src="https://picx.zhimg.com/v2-f14d961f1f3edc0216573229f4e59496" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="FHIR-AgentBench-Benchmarking-LLM-Agents-for-Realistic-Interoperable-EHR-Question-Answering"><a href="#FHIR-AgentBench-Benchmarking-LLM-Agents-for-Realistic-Interoperable-EHR-Question-Answering" class="headerlink" title="FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering"></a>FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering</h2><p><strong>Authors:Gyubok Lee, Elea Bach, Eric Yang, Tom Pollard, Alistair Johnson, Edward Choi, Yugang jia, Jong Ha Lee</strong></p>
<p>The recent shift toward the Health Level Seven Fast Healthcare Interoperability Resources (HL7 FHIR) standard opens a new frontier for clinical AI, demanding LLM agents to navigate complex, resource-based data models instead of conventional structured health data. However, existing benchmarks have lagged behind this transition, lacking the realism needed to evaluate recent LLMs on interoperable clinical data. To bridge this gap, we introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical questions in the HL7 FHIR standard. Using this benchmark, we systematically evaluate agentic frameworks, comparing different data retrieval strategies (direct FHIR API calls vs. specialized tools), interaction patterns (single-turn vs. multi-turn), and reasoning strategies (natural language vs. code generation). Our experiments highlight the practical challenges of retrieving data from intricate FHIR resources and the difficulty of reasoning over them, both of which critically affect question answering performance. We publicly release the FHIR-AgentBench dataset and evaluation suite (<a target="_blank" rel="noopener" href="https://github.com/glee4810/FHIR-AgentBench">https://github.com/glee4810/FHIR-AgentBench</a>) to promote reproducible research and the development of robust, reliable LLM agents for clinical applications.</p>
<blockquote>
<p>æœ€è¿‘è½¬å‘å¥åº·æ°´å¹³ä¸ƒå¿«é€ŸåŒ»ç–—äº’é€šèµ„æºï¼ˆHL7 FHIRï¼‰æ ‡å‡†çš„è¶‹åŠ¿ä¸ºä¸´åºŠäººå·¥æ™ºèƒ½å¼€è¾Ÿäº†æ–°çš„å‰æ²¿é¢†åŸŸï¼Œè¦æ±‚LLMä»£ç†å¤„ç†å¤æ‚çš„åŸºäºèµ„æºçš„æ•°æ®æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„ç»“æ„åŒ–å¥åº·æ•°æ®ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•æœªèƒ½è·Ÿä¸Šè¿™ä¸€è½¬å˜ï¼Œç¼ºä¹è¯„ä¼°è¿‘æœŸLLMåœ¨å¯äº’æ“ä½œçš„ä¸´åºŠæ•°æ®ä¸Šçš„çœŸå®æ€§çš„éœ€æ±‚ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†FHIR-AgentBenchåŸºå‡†æµ‹è¯•ï¼Œè¯¥æµ‹è¯•ä»¥HL7 FHIRæ ‡å‡†ä¸ºåŸºç¡€ï¼Œæ¶µç›–äº†2931ä¸ªçœŸå®ä¸–ç•Œçš„ä¸´åºŠé—®é¢˜ã€‚ä½¿ç”¨è¿™ä¸ªåŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†ä»£ç†æ¡†æ¶ï¼Œæ¯”è¾ƒäº†ä¸åŒçš„æ•°æ®æ£€ç´¢ç­–ç•¥ï¼ˆç›´æ¥è°ƒç”¨FHIR APIä¸ä¸“ç”¨å·¥å…·ï¼‰ã€äº¤äº’æ¨¡å¼ï¼ˆå•è½®ä¸å¤šè½®ï¼‰å’Œæ¨ç†ç­–ç•¥ï¼ˆè‡ªç„¶è¯­è¨€ä¸ä»£ç ç”Ÿæˆï¼‰ã€‚æˆ‘ä»¬çš„å®éªŒçªå‡ºäº†ä»å¤æ‚çš„FHIRèµ„æºä¸­æ£€ç´¢æ•°æ®å’Œå¯¹å…¶è¿›è¡Œæ¨ç†çš„å®é™…æŒ‘æˆ˜ï¼Œä¸¤è€…éƒ½å¯¹é—®ç­”æ€§èƒ½äº§ç”Ÿé‡å¤§å½±å“ã€‚æˆ‘ä»¬å…¬å¼€å‘å¸ƒFHIR-AgentBenchæ•°æ®é›†å’Œè¯„ä¼°å¥—ä»¶ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/glee4810/FHIR-AgentBench%EF%BC%89%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E5%8F%AF%E9%87%8D%E5%A4%8D%E7%9A%84%E7%A0%94%E7%A9%B6%E5%92%8C%E4%B8%B4%E5%BA%8A%E5%BA%94%E7%94%A8%E4%B8%AD%E7%A8%B3%E5%81%A5%E5%8F%AF%E9%9D%A0%E7%9A%84LLM%E4%BB%A3%E7%90%86%E7%9A%84%E5%BC%80%E5%8F%91%E3%80%82">https://github.com/glee4810/FHIR-AgentBenchï¼‰ï¼Œä»¥ä¿ƒè¿›å¯é‡å¤çš„ç ”ç©¶å’Œä¸´åºŠåº”ç”¨ä¸­ç¨³å¥å¯é çš„LLMä»£ç†çš„å¼€å‘ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.19319v2">PDF</a> ML4H 2025 Proceedings</p>
<p><strong>Summary</strong></p>
<p>éšç€å‘Health Level Seven Fast Healthcare Interoperability Resourcesï¼ˆHL7 FHIRï¼‰æ ‡å‡†çš„è½¬å˜ï¼Œä¸´åºŠäººå·¥æ™ºèƒ½è¿æ¥äº†æ–°çš„å‘å±•æœºé‡ã€‚ç„¶è€Œï¼Œç°æœ‰è¯„ä¼°æ ‡å‡†å°šæœªè·Ÿä¸Šè¿™ä¸€è½¬å˜ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæ¨å‡ºåŸºäºHL7 FHIRæ ‡å‡†çš„FHIR-AgentBenchè¯„ä¼°æ ‡å‡†ã€‚è¯¥è¯„ä¼°æ ‡å‡†ç³»ç»Ÿåœ°è¯„ä¼°äº†æ•°æ®æ£€ç´¢ç­–ç•¥ã€äº¤äº’æ¨¡å¼å’Œæ¨ç†ç­–ç•¥ç­‰æ–¹é¢ï¼Œæ­ç¤ºäº†ä»å¤æ‚çš„FHIRèµ„æºä¸­æ£€ç´¢æ•°æ®å’Œè¿›è¡Œæ¨ç†çš„å®é™…æŒ‘æˆ˜ã€‚åŒæ—¶å…¬å¼€å‘å¸ƒFHIR-AgentBenchæ•°æ®é›†å’Œè¯„ä¼°å¥—ä»¶ï¼Œä»¥ä¿ƒè¿›ç¨³å¥å¯é çš„LLMä»£ç†çš„ä¸´åºŠåº”ç”¨å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HL7 FHIRæ ‡å‡†åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½é¢†åŸŸå¼€å¯æ–°çš„å‘å±•æœºé‡ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ ‡å‡†æœªèƒ½è·Ÿä¸ŠHL7 FHIRçš„è½¬å˜ï¼Œç¼ºä¹ç°å®æ€§ã€‚</li>
<li>å¼•å…¥FHIR-AgentBenchè¯„ä¼°æ ‡å‡†ï¼ŒåŸºäºçœŸå®ä¸–ç•Œä¸´åºŠé—®é¢˜å¹¶éµå¾ªHL7 FHIRæ ‡å‡†ã€‚</li>
<li>ç³»ç»Ÿè¯„ä¼°æ•°æ®æ£€ç´¢ç­–ç•¥ï¼ŒåŒ…æ‹¬ç›´æ¥FHIR APIè°ƒç”¨å’Œä¸“ç”¨å·¥å…·çš„æ¯”è¾ƒã€‚</li>
<li>äº¤äº’æ¨¡å¼å’Œæ¨ç†ç­–ç•¥çš„æ¯”è¾ƒï¼ŒåŒ…æ‹¬å•è½®å’Œå¤šè½®äº¤äº’ä»¥åŠè‡ªç„¶è¯­è¨€ä¸ä»£ç ç”Ÿæˆçš„åŒºåˆ«ã€‚</li>
<li>å®éªŒæ­ç¤ºäº†ä»å¤æ‚çš„FHIRèµ„æºä¸­æ£€ç´¢æ•°æ®å’Œè¿›è¡Œæ¨ç†çš„å®é™…æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.19319">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aaf49e2b54b154e956640874d71e77c3" align="middle">
<img src="https://picx.zhimg.com/v2-ccceba76e1c993d36c1b94b2d149d3fd" align="middle">
<img src="https://picx.zhimg.com/v2-973be61f526cd0e0c910a49667e41901" align="middle">
<img src="https://picx.zhimg.com/v2-bbe552e332c194ba7dfd3f5167833df3" align="middle">
<img src="https://picx.zhimg.com/v2-5e500f4dd1ef2ecd7e4efcd7c0b77ba3" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Depth-Matters-Multimodal-RGB-D-Perception-for-Robust-Autonomous-Agents"><a href="#Depth-Matters-Multimodal-RGB-D-Perception-for-Robust-Autonomous-Agents" class="headerlink" title="Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents"></a>Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents</h2><p><strong>Authors:Mihaela-Larisa Clement, MÃ³nika Farsang, Felix Resch, Mihai-Teodor Stanusoiu, Radu Grosu</strong></p>
<p>Autonomous agents that rely purely on perception to make real-time control decisions require efficient and robust architectures. In this work, we demonstrate that augmenting RGB input with depth information significantly enhances our agentsâ€™ ability to predict steering commands compared to using RGB alone. We benchmark lightweight recurrent controllers that leverage the fused RGB-D features for sequential decision-making. To train our models, we collect high-quality data using a small-scale autonomous car controlled by an expert driver via a physical steering wheel, capturing varying levels of steering difficulty. Our models were successfully deployed on real hardware and inherently avoided dynamic and static obstacles, under out-of-distribution conditions. Specifically, our findings reveal that the early fusion of depth data results in a highly robust controller, which remains effective even with frame drops and increased noise levels, without compromising the networkâ€™s focus on the task.</p>
<blockquote>
<p>å®Œå…¨ä¾èµ–æ„ŸçŸ¥æ¥åšå‡ºå®æ—¶æ§åˆ¶å†³ç­–çš„è‡ªæ§ä»£ç†éœ€è¦é«˜æ•ˆä¸”ç¨³å¥çš„æ¶æ„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯æ˜ä¸ä»…ä½¿ç”¨RGBç›¸æ¯”ï¼Œé€šè¿‡æ·±åº¦ä¿¡æ¯å¢å¼ºRGBè¾“å…¥ä¼šæå¤§åœ°æé«˜æˆ‘ä»¬çš„ä»£ç†é¢„æµ‹è½¬å‘æŒ‡ä»¤çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨è½»é‡çº§çš„å¾ªç¯æ§åˆ¶å™¨ï¼Œåˆ©ç”¨èåˆåçš„RGB-Dç‰¹æ€§è¿›è¡Œåºåˆ—å†³ç­–è¯„ä¼°ã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨å°å‹è‡ªåŠ¨é©¾é©¶æ±½è½¦æ”¶é›†é«˜è´¨é‡æ•°æ®ï¼Œè¯¥è½¦ç”±ä¸“ä¸šå¸æœºé€šè¿‡æ–¹å‘ç›˜æ§åˆ¶ï¼Œå¯æ•è·ä¸åŒéš¾åº¦çš„è½¬å‘çº§åˆ«ã€‚æˆ‘ä»¬çš„æ¨¡å‹æˆåŠŸéƒ¨ç½²åœ¨çœŸå®ç¡¬ä»¶ä¸Šï¼Œå¯åœ¨åˆ†å¸ƒå¤–éƒ¨æ¡ä»¶ä¸‹é¿å…åŠ¨æ€å’Œé™æ€éšœç¢ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ·±åº¦æ•°æ®çš„æ—©æœŸèåˆä¼šå¯¼è‡´ä¸€ä¸ªé«˜åº¦ç¨³å¥çš„æ§åˆ¶å™¨ï¼Œå³ä½¿åœ¨å¸§ä¸¢å¤±å’Œå™ªå£°æ°´å¹³å¢åŠ çš„æƒ…å†µä¸‹ï¼Œå®ƒä»ç„¶ä¿æŒæœ‰æ•ˆï¼Œä¸”ä¸å½±å“ç½‘ç»œå¯¹ä»»åŠ¡çš„å…³æ³¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.16711v3">PDF</a> </p>
<p><strong>Summary</strong><br>     èåˆRGBä¸æ·±åº¦ä¿¡æ¯åï¼Œè‡ªä¸»ä»£ç†çš„é¢„æµ‹è½¬å‘æŒ‡ä»¤èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œå¯¹æ¯”ä»…ä½¿ç”¨RGBä¿¡æ¯æ›´å…·ä¼˜åŠ¿ã€‚é‡‡ç”¨è½»é‡çº§å¾ªç¯æ§åˆ¶å™¨åˆ©ç”¨èåˆRGB-Dç‰¹å¾è¿›è¡Œåºåˆ—å†³ç­–ã€‚é€šè¿‡ä¸“å®¶é©¾é©¶çš„å°å‹è‡ªä¸»æ±½è½¦æ”¶é›†é«˜è´¨é‡æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå¯æˆåŠŸéƒ¨ç½²äºå®é™…ç¡¬ä»¶ä¸Šå¹¶é¿å…åŠ¨æ€ä¸é™æ€éšœç¢ã€‚æ—©æœŸèåˆæ·±åº¦æ•°æ®ä½¿æ§åˆ¶å™¨é«˜åº¦ç¨³å¥ï¼Œå³ä½¿åœ¨å¸§ä¸¢å¤±å’Œå™ªå£°å¢åŠ æ—¶ä»æœ‰æ•ˆï¼Œä¸”ä¸å½±å“ç½‘ç»œçš„ä»»åŠ¡ä¸“æ³¨åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»ä»£ç†åœ¨èåˆRGBä¸æ·±åº¦ä¿¡æ¯åï¼Œé¢„æµ‹è½¬å‘æŒ‡ä»¤èƒ½åŠ›æ˜¾è‘—æå‡ã€‚</li>
<li>å¯¹æ¯”ä»…ä½¿ç”¨RGBä¿¡æ¯ï¼Œèåˆåçš„ä¿¡æ¯èƒ½å¢å¼ºä»£ç†çš„æ€§èƒ½ã€‚</li>
<li>é‡‡ç”¨è½»é‡çº§å¾ªç¯æ§åˆ¶å™¨åˆ©ç”¨èåˆç‰¹å¾è¿›è¡Œåºåˆ—å†³ç­–ã€‚</li>
<li>é€šè¿‡ä¸“å®¶é©¾é©¶çš„å°å‹è‡ªä¸»æ±½è½¦æ”¶é›†é«˜è´¨é‡æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒã€‚</li>
<li>æ¨¡å‹å¯æˆåŠŸéƒ¨ç½²äºå®é™…ç¡¬ä»¶ä¸Šï¼Œå¹¶èƒ½é¿å…åŠ¨æ€å’Œé™æ€éšœç¢ã€‚</li>
<li>æ—©æœŸèåˆæ·±åº¦æ•°æ®ä½¿æ§åˆ¶å™¨æ›´åŠ ç¨³å¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.16711">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6b6edeb6c6f7028df532d1c663b69737" align="middle">
<img src="https://picx.zhimg.com/v2-d0fd3e722716edd3714202aac735e8cb" align="middle">
<img src="https://picx.zhimg.com/v2-49d92698da417c4dba052d9437669cc0" align="middle">
<img src="https://picx.zhimg.com/v2-e328bced29a4c430520b78f5225bec61" align="middle">
<img src="https://picx.zhimg.com/v2-00ff695c05be587c9fe9a7ac824703e0" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Surgical-AI-Copilot-Energy-Based-Fourier-Gradient-Low-Rank-Adaptation-for-Surgical-LLM-Agent-Reasoning-and-Planning"><a href="#Surgical-AI-Copilot-Energy-Based-Fourier-Gradient-Low-Rank-Adaptation-for-Surgical-LLM-Agent-Reasoning-and-Planning" class="headerlink" title="Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning"></a>Surgical AI Copilot: Energy-Based Fourier Gradient Low-Rank Adaptation for Surgical LLM Agent Reasoning and Planning</h2><p><strong>Authors:Jiayuan Huang, Runlong He, Danyal Zaman Khan, Evangelos B. Mazomenos, Danail Stoyanov, Hani Marcus, Linzhe Jiang, Matthew J Clarkson, Mobarak I. Hoque</strong></p>
<p>Image-guided surgery demands adaptive, real-time decision support, yet static AI models struggle with structured task planning and providing interactive guidance. Large language models (LLMs)-powered agents offer a promising solution by enabling dynamic task planning and predictive decision support. Despite recent advances, the absence of surgical agent datasets and robust parameter-efficient fine-tuning techniques limits the development of LLM agents capable of complex intraoperative reasoning. In this paper, we introduce Surgical AI Copilot, an LLM agent for image-guided pituitary surgery, capable of conversation, planning, and task execution in response to queries involving tasks such as MRI tumor segmentation, endoscope anatomy segmentation, overlaying preoperative imaging with intraoperative views, instrument tracking, and surgical visual question answering (VQA). To enable structured agent planning, we develop the PitAgent dataset, a surgical context-aware planning dataset covering surgical tasks like workflow analysis, instrument localization, anatomical segmentation, and query-based reasoning. Additionally, we propose DEFT-GaLore, a Deterministic Energy-based Fourier Transform (DEFT) gradient projection technique for efficient low-rank adaptation of recent LLMs (e.g., LLaMA 3.2, Qwen 2.5), enabling their use as surgical agent planners. We extensively validate our agentâ€™s performance and the proposed adaptation technique against other state-of-the-art low-rank adaptation methods on agent planning and prompt generation tasks, including a zero-shot surgical VQA benchmark, demonstrating the significant potential for truly efficient and scalable surgical LLM agents in real-time operative settings.</p>
<blockquote>
<p>å›¾åƒå¼•å¯¼æ‰‹æœ¯éœ€è¦è‡ªé€‚åº”ã€å®æ—¶çš„å†³ç­–æ”¯æŒï¼Œç„¶è€Œé™æ€çš„AIæ¨¡å‹åœ¨ç»“æ„åŒ–ä»»åŠ¡è§„åˆ’å’Œæä¾›äº¤äº’å¼æŒ‡å¯¼æ–¹é¢å­˜åœ¨å›°éš¾ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå®ç°åŠ¨æ€ä»»åŠ¡è§„åˆ’å’Œé¢„æµ‹å†³ç­–æ”¯æŒã€‚å°½ç®¡æœ€è¿‘æœ‰æ‰€è¿›å±•ï¼Œä½†ç”±äºç¼ºä¹æ‰‹æœ¯ä»£ç†æ•°æ®é›†å’Œç¨³å¥çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤æ‚æœ¯ä¸­æ¨ç†çš„LLMä»£ç†çš„å¼€å‘å—åˆ°é™åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Surgical AI Copilotï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒå¼•å¯¼å‚ä½“æ‰‹æœ¯çš„LLMä»£ç†ï¼Œèƒ½å¤Ÿé’ˆå¯¹æ¶‰åŠMRIè‚¿ç˜¤åˆ†å‰²ã€å†…çª¥é•œè§£å‰–åˆ†å‰²ã€æœ¯å‰å½±åƒä¸æœ¯ä¸­è§†å›¾çš„å åŠ ã€ä»ªå™¨è·Ÿè¸ªå’Œæ‰‹æœ¯è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ç­‰ä»»åŠ¡è¿›è¡ŒæŸ¥è¯¢çš„ä¼šè¯ã€è§„åˆ’å’Œä»»åŠ¡æ‰§è¡Œã€‚ä¸ºäº†å®ç°ç»“æ„åŒ–çš„ä»£ç†è§„åˆ’ï¼Œæˆ‘ä»¬å¼€å‘äº†PitAgentæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªæ‰‹æœ¯ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è§„åˆ’æ•°æ®é›†ï¼Œæ¶µç›–æ‰‹æœ¯ä»»åŠ¡ï¼Œå¦‚å·¥ä½œæµç¨‹åˆ†æã€ä»ªå™¨å®šä½ã€è§£å‰–åˆ†å‰²å’ŒåŸºäºæŸ¥è¯¢çš„æ¨ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†DEFT-GaLoreï¼Œä¸€ç§ç¡®å®šæ€§èƒ½é‡åŸºå‚…ç«‹å¶å˜æ¢ï¼ˆDEFTï¼‰æ¢¯åº¦æŠ•å½±æŠ€æœ¯ï¼Œç”¨äºæœ€æ–°LLMsï¼ˆä¾‹å¦‚LLaMA 3.2ï¼ŒQwen 2.5ï¼‰çš„æœ‰æ•ˆä½ç§©é€‚åº”ï¼Œä½¿å…¶å¯ä½œä¸ºæ‰‹æœ¯ä»£ç†è§„åˆ’å¸ˆä½¿ç”¨ã€‚æˆ‘ä»¬å…¨é¢éªŒè¯äº†æˆ‘ä»¬çš„ä»£ç†æ€§èƒ½ä»¥åŠæ‰€æå‡ºçš„é€‚åº”æŠ€æœ¯ä¸å…¶ä»–æœ€å…ˆè¿›çš„ä½ç§©é€‚åº”æ–¹æ³•åœ¨ä»£ç†è§„åˆ’å’Œæç¤ºç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ŒåŒ…æ‹¬é›¶å°„å‡»æ‰‹æœ¯VQAåŸºå‡†æµ‹è¯•ï¼Œè¯æ˜äº†åœ¨å®æ—¶æ“ä½œç¯å¢ƒä¸­çœŸæ­£é«˜æ•ˆå’Œå¯æ‰©å±•çš„æ‰‹æœ¯LLMä»£ç†çš„å·¨å¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09474v2">PDF</a> 11 pages</p>
<p><strong>Summary</strong><br>å®æ—¶å›¾åƒå¼•å¯¼æ‰‹æœ¯éœ€è¦è‡ªé€‚åº”ã€äº¤äº’å¼çš„å†³ç­–æ”¯æŒã€‚å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†æ™ºèƒ½ä½“å¦‚æ‰‹æœ¯AIå‰¯é©¾é©¶èƒ½å¤Ÿåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå…·å¤‡å¯¹è¯ã€è§„åˆ’å’Œæ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç¼ºä¹æ‰‹æœ¯ä»£ç†æ•°æ®é›†å’Œé²æ£’çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯é™åˆ¶äº†å¤æ‚æ‰‹æœ¯æ¨ç†èƒ½åŠ›çš„å‘å±•ã€‚æœ¬ç ”ç©¶å¼•å…¥æ‰‹æœ¯AIå‰¯é©¾é©¶ï¼Œç”¨äºå›¾åƒå¼•å¯¼å‚ä½“æ‰‹æœ¯ï¼Œå¼€å‘PitAgentæ•°æ®é›†å¹¶å®ç°DEFT-GaLoreæŠ€æœ¯ï¼Œä»¥æ¨åŠ¨é«˜æ•ˆä½ç§©é€‚åº”çš„LLMåœ¨æ‰‹æœ¯å†³ç­–æ”¯æŒä¸­çš„åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰‹æœ¯å›¾åƒå¼•å¯¼éœ€è¦è‡ªé€‚åº”ã€å®æ—¶å†³ç­–æ”¯æŒï¼Œå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†æ™ºèƒ½ä½“ä¸ºè§£å†³è¿™ä¸€é—®é¢˜æä¾›äº†æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ä»£ç†æ™ºèƒ½ä½“å¦‚æ‰‹æœ¯AIå‰¯é©¾é©¶å…·å¤‡å¯¹è¯ã€è§„åˆ’åŠä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œç”¨äºæ”¯æŒå›¾åƒå¼•å¯¼æ‰‹æœ¯ã€‚</li>
<li>ç¼ºä¹æ‰‹æœ¯ä»£ç†æ•°æ®é›†é™åˆ¶äº†å¤æ‚æ‰‹æœ¯æ¨ç†èƒ½åŠ›çš„å‘å±•ã€‚</li>
<li>ç ”ç©¶å¼•å…¥äº†Surgical AI Copilotï¼Œä¸“é—¨ç”¨äºå›¾åƒå¼•å¯¼å‚ä½“æ‰‹æœ¯çš„LLMä»£ç†ã€‚</li>
<li>å¼€å‘PitAgentæ•°æ®é›†ä»¥å®ç°ç»“æ„åŒ–ä»£ç†è§„åˆ’ï¼Œæ¶µç›–æ‰‹æœ¯ä»»åŠ¡å¦‚å·¥ä½œæµç¨‹åˆ†æã€ä»ªå™¨å®šä½ã€è§£å‰–ç»“æ„åˆ†å‰²å’ŒåŸºäºæŸ¥è¯¢çš„æ¨ç†ã€‚</li>
<li>æå‡ºDEFT-GaLoreæŠ€æœ¯ï¼Œé€šè¿‡ç¡®å®šæ€§èƒ½é‡åŸºäºå‚…é‡Œå¶å˜æ¢çš„æ¢¯åº¦æŠ•å½±æŠ€æœ¯ï¼Œå®ç°LLMçš„é«˜æ•ˆä½ç§©é€‚åº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09474">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7437ca224ed05b743eb8c3a678e940e4" align="middle">
<img src="https://picx.zhimg.com/v2-2b9199bd8510eba869903e17dacb9ad1" align="middle">
<img src="https://picx.zhimg.com/v2-0edc7e77ce272a4ecbdd3d44487a6fe5" align="middle">
<img src="https://picx.zhimg.com/v2-1ca08a14545fe879bd3ebaadb052c16a" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Agent-Journey-Beyond-RGB-Hierarchical-Semantic-Spatial-Representation-Enrichment-for-Vision-and-Language-Navigation"><a href="#Agent-Journey-Beyond-RGB-Hierarchical-Semantic-Spatial-Representation-Enrichment-for-Vision-and-Language-Navigation" class="headerlink" title="Agent Journey Beyond RGB: Hierarchical Semantic-Spatial Representation Enrichment for Vision-and-Language Navigation"></a>Agent Journey Beyond RGB: Hierarchical Semantic-Spatial Representation Enrichment for Vision-and-Language Navigation</h2><p><strong>Authors:Xuesong Zhang, Yunbo Xu, Jia Li, Ruonan Liu, Zhenzhen Hu</strong></p>
<p>Navigating unseen environments from natural language instructions remains challenging for egocentric agents in Vision-and-Language Navigation (VLN). Humans naturally ground concrete semantic knowledge within spatial layouts during indoor navigation. Although prior work has introduced diverse environment representations to improve reasoning, auxiliary modalities are often naively concatenated with RGB features, which underutilizes each modalityâ€™s distinct contribution. We propose a hierarchical Semantic Understanding and Spatial Awareness (SUSA) architecture to enable agents to perceive and ground environments at multiple scales. Specifically, the Textual Semantic Understanding (TSU) module supports local action prediction by generating view-level descriptions, capturing fine-grained semantics and narrowing the modality gap between instructions and environments. Complementarily, the Depth Enhanced Spatial Perception (DSP) module incrementally builds a trajectory-level depth exploration map, providing a coarse-grained representation of global spatial layout. Extensive experiments show that the hierarchical representation enrichment of SUSA significantly improves navigation performance over the baseline on discrete VLN benchmarks (REVERIE, R2R, and SOON) and generalizes better to the continuous R2R-CE benchmark.</p>
<blockquote>
<p>åœ¨è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰ä¸­ï¼Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“ä»è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸­å¯¼èˆªæœªçŸ¥ç¯å¢ƒä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚äººç±»åœ¨å®¤å†…å¯¼èˆªæ—¶ï¼Œè‡ªç„¶åœ°ä¼šåœ¨ç©ºé—´å¸ƒå±€ä¸­å·©å›ºå…·ä½“è¯­ä¹‰çŸ¥è¯†ã€‚å°½ç®¡ä¹‹å‰çš„å·¥ä½œå·²ç»å¼•å…¥äº†å„ç§ç¯å¢ƒè¡¨ç¤ºæ–¹æ³•æ¥æ”¹å–„æ¨ç†ï¼Œä½†è¾…åŠ©æ¨¡å¼é€šå¸¸ä»¥åŸå§‹æ–¹å¼ä¸RGBç‰¹å¾ç›¸ç»“åˆï¼Œè¿™å¹¶æ²¡æœ‰å……åˆ†åˆ©ç”¨æ¯ä¸ªæ¨¡æ€çš„ç‹¬ç‰¹è´¡çŒ®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ†å±‚çš„è¯­ä¹‰ç†è§£ä¸ç©ºé—´æ„ŸçŸ¥ï¼ˆSUSAï¼‰æ¶æ„ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å¤šä¸ªå°ºåº¦ä¸Šæ„ŸçŸ¥å’Œå·©å›ºç¯å¢ƒã€‚å…·ä½“æ¥è¯´ï¼Œæ–‡æœ¬è¯­ä¹‰ç†è§£ï¼ˆTSUï¼‰æ¨¡å—é€šè¿‡ç”Ÿæˆè§†å›¾çº§åˆ«çš„æè¿°æ¥æ”¯æŒå±€éƒ¨åŠ¨ä½œé¢„æµ‹ï¼Œæ•æ‰ç²¾ç»†è¯­ä¹‰ï¼Œç¼©å°æŒ‡ä»¤å’Œç¯å¢ƒä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚ä½œä¸ºè¡¥å……ï¼Œæ·±åº¦å¢å¼ºç©ºé—´æ„ŸçŸ¥ï¼ˆDSPï¼‰æ¨¡å—é€æ­¥æ„å»ºè½¨è¿¹çº§åˆ«çš„æ·±åº¦æ¢ç´¢åœ°å›¾ï¼Œæä¾›å…¨å±€ç©ºé—´å¸ƒå±€çš„ç²—ç²’åº¦è¡¨ç¤ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨ç¦»æ•£VLNåŸºå‡†æµ‹è¯•ï¼ˆREVERIEã€R2Rå’ŒSOONï¼‰ä¸Šï¼ŒSUSAçš„åˆ†å±‚æ¬¡è¡¨ç¤ºä¸°å¯Œæ€§æ˜¾è‘—æé«˜äº†å¯¼èˆªæ€§èƒ½ï¼Œå¹¶ä¸”åœ¨è¿ç»­çš„R2R-CEåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°æ›´å¥½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06465v5">PDF</a> AAAI2026, I14 pages, 12 figures, 11 tables</p>
<p><strong>Summary</strong>ï¼š<br>åœ¨è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰ä¸­ï¼Œä»è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¯¼èˆªæœªçŸ¥ç¯å¢ƒå¯¹äºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ä»£ç†æ¥è¯´ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚äººç±»åœ¨å®¤å†…å¯¼èˆªæ—¶ä¼šè‡ªç„¶åœ°ç»“åˆç©ºé—´å¸ƒå±€å’Œå…·ä½“è¯­ä¹‰çŸ¥è¯†ã€‚å…ˆå‰çš„å·¥ä½œè™½ç„¶å¼•å…¥äº†å¤šç§ç¯å¢ƒè¡¨ç¤ºæ–¹æ³•æ¥æ”¹å–„æ¨ç†èƒ½åŠ›ï¼Œä½†è¾…åŠ©æ¨¡æ€é€šå¸¸ä¸RGBç‰¹å¾ç®€å•ç»“åˆï¼Œè¿™å¿½ç•¥äº†æ¯ä¸ªæ¨¡æ€çš„ç‹¬ç‰¹è´¡çŒ®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–çš„è¯­ä¹‰ç†è§£ä¸ç©ºé—´æ„ŸçŸ¥ï¼ˆSUSAï¼‰æ¶æ„ï¼Œä½¿ä»£ç†èƒ½å¤Ÿåœ¨å¤šä¸ªå°ºåº¦ä¸Šæ„ŸçŸ¥å’Œå®šä½ç¯å¢ƒã€‚å…·ä½“æ¥è¯´ï¼Œæ–‡æœ¬è¯­ä¹‰ç†è§£ï¼ˆTSUï¼‰æ¨¡å—é€šè¿‡ç”Ÿæˆè§†å›¾çº§æè¿°æ¥æ”¯æŒå±€éƒ¨åŠ¨ä½œé¢„æµ‹ï¼Œæ•æ‰ç²¾ç»†è¯­ä¹‰å¹¶ç¼©å°æŒ‡ä»¤å’Œç¯å¢ƒä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚æ­¤å¤–ï¼Œæ·±åº¦å¢å¼ºç©ºé—´æ„ŸçŸ¥ï¼ˆDSPï¼‰æ¨¡å—é€æ­¥æ„å»ºè½¨è¿¹çº§æ·±åº¦æ¢ç´¢å›¾ï¼Œæä¾›å…¨å±€ç©ºé—´å¸ƒå±€çš„ç²—ç•¥è¡¨ç¤ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSUSAçš„å±‚æ¬¡åŒ–è¡¨ç¤ºä¸°å¯Œæ€§åœ¨ç¦»æ•£VLNåŸºå‡†æµ‹è¯•ï¼ˆREVERIEã€R2Rå’ŒSOONï¼‰ä¸Šçš„å¯¼èˆªæ€§èƒ½æ˜æ˜¾ä¼˜äºåŸºçº¿ï¼Œå¹¶ä¸”åœ¨è¿ç»­çš„R2R-CEåŸºå‡†æµ‹è¯•ä¸Šå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>åœ¨è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰ä¸­ï¼Œå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”¨äºå¯¼èˆªæœªçŸ¥ç¯å¢ƒå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>äººç±»åœ¨å®¤å†…å¯¼èˆªæ—¶ä¼šç»“åˆç©ºé—´å¸ƒå±€å’Œå…·ä½“è¯­ä¹‰çŸ¥è¯†ã€‚</li>
<li>å…ˆå‰çš„å·¥ä½œåœ¨ç¯å¢ƒè¡¨ç¤ºæ–¹é¢æœ‰æ‰€è¿›å±•ï¼Œä½†å¿½ç•¥äº†ä¸åŒæ¨¡æ€çš„ç‹¬ç‰¹è´¡çŒ®ã€‚</li>
<li>æå‡ºçš„SUSAæ¶æ„æ—¨åœ¨å®ç°å±‚æ¬¡åŒ–çš„è¯­ä¹‰ç†è§£ä¸ç©ºé—´æ„ŸçŸ¥ã€‚</li>
<li>TSUæ¨¡å—æ”¯æŒå±€éƒ¨åŠ¨ä½œé¢„æµ‹ï¼Œé€šè¿‡ç”Ÿæˆè§†å›¾çº§æè¿°æ¥æ•æ‰ç²¾ç»†è¯­ä¹‰ã€‚</li>
<li>DSPæ¨¡å—æ„å»ºè½¨è¿¹çº§æ·±åº¦æ¢ç´¢å›¾ï¼Œæä¾›å…¨å±€ç©ºé—´å¸ƒå±€çš„ç²—ç•¥è¡¨ç¤ºã€‚</li>
<li>SUSAæ¶æ„åœ¨å¤šä¸ªVLNåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¼˜äºåŸºçº¿ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06465">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dc76c83dcaa08ba44c82e2e245848ae8" align="middle">
<img src="https://picx.zhimg.com/v2-28289c409198859acc9429ed1df620d5" align="middle">
<img src="https://picx.zhimg.com/v2-41b810f15dbe65422db86b59fdbe703f" align="middle">
<img src="https://picx.zhimg.com/v2-77cea75f48224a6fcc23c5bb70effeec" align="middle">
<img src="https://picx.zhimg.com/v2-67f322c41163737d1b50e9af500ca888" align="middle">
<img src="https://picx.zhimg.com/v2-07ad62c9554f151492c4dfaec62d001a" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-17/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-17/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-17/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e11e35bef5f1a07f1fd5fd285a73917a" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  HI-TransPA Hearing Impairments Translation Personal Assistant
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-17/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a3763cb20c89e115fad9ba7bdd947f74" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  Prompt Tuning for Natural Language to SQL with Embedding Fine-Tuning and RAG
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33446.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
