<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-20b55b2a0407f46d189ead06a85443aa')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    33 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-17-æ›´æ–°"><a href="#2025-11-17-æ›´æ–°" class="headerlink" title="2025-11-17 æ›´æ–°"></a>2025-11-17 æ›´æ–°</h1><h2 id="Regional-Attention-Enhanced-Swin-Transformer-for-Clinically-Relevant-Medical-Image-Captioning"><a href="#Regional-Attention-Enhanced-Swin-Transformer-for-Clinically-Relevant-Medical-Image-Captioning" class="headerlink" title="Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning"></a>Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning</h2><p><strong>Authors:Zubia Naz, Farhan Asghar, Muhammad Ishfaq Hussain, Yahya Hadadi, Muhammad Aasim Rafique, Wookjin Choi, Moongu Jeon</strong></p>
<p>Automated medical image captioning translates complex radiological images into diagnostic narratives that can support reporting workflows. We present a Swin-BART encoder-decoder system with a lightweight regional attention module that amplifies diagnostically salient regions before cross-attention. Trained and evaluated on ROCO, our model achieves state-of-the-art semantic fidelity while remaining compact and interpretable. We report results as mean$\pm$std over three seeds and include $95%$ confidence intervals. Compared with baselines, our approach improves ROUGE (proposed 0.603, ResNet-CNN 0.356, BLIP2-OPT 0.255) and BERTScore (proposed 0.807, BLIP2-OPT 0.645, ResNet-CNN 0.623), with competitive BLEU, CIDEr, and METEOR. We further provide ablations (regional attention on&#x2F;off and token-count sweep), per-modality analysis (CT&#x2F;MRI&#x2F;X-ray), paired significance tests, and qualitative heatmaps that visualize the regions driving each description. Decoding uses beam search (beam size $&#x3D;4$), length penalty $&#x3D;1.1$, $no_repeat_ngram_size$ $&#x3D;3$, and max length $&#x3D;128$. The proposed design yields accurate, clinically phrased captions and transparent regional attributions, supporting safe research use with a human in the loop.</p>
<blockquote>
<p>è‡ªåŠ¨åŒ»ç–—å›¾åƒæè¿°ç”ŸæˆæŠ€æœ¯å°†å¤æ‚çš„æ”¾å°„å›¾åƒè½¬åŒ–ä¸ºè¯Šæ–­å™è¿°ï¼Œæ”¯æŒæŠ¥å‘Šå·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºSwin-BARTçš„ç¼–ç å™¨-è§£ç å™¨ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé…å¤‡äº†ä¸€ä¸ªè½»é‡çº§çš„åŒºåŸŸæ³¨æ„åŠ›æ¨¡å—ï¼Œåœ¨äº¤å‰æ³¨æ„åŠ›ä¹‹å‰æ”¾å¤§äº†è¯Šæ–­æ€§æ˜¾è‘—åŒºåŸŸã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ROCOä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„è¯­ä¹‰ä¿çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ç´§å‡‘æ€§å’Œå¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬æŠ¥å‘Šçš„ç»“æœä¸ºå¹³å‡å€¼Â±æ ‡å‡†å·®ï¼ˆæ¥è‡ªä¸‰ä¸ªç§å­ï¼‰å¹¶åŒ…æ‹¬95%ç½®ä¿¡åŒºé—´ã€‚ä¸åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ROUGEï¼ˆæå‡ºè€…å¾—åˆ†ä¸º0.603ï¼ŒResNet-CNNå¾—åˆ†ä¸º0.356ï¼ŒBLIP2-OPTå¾—åˆ†ä¸º0.255ï¼‰å’ŒBERTScoreï¼ˆæå‡ºè€…å¾—åˆ†ä¸º0.807ï¼ŒBLIP2-OPTå¾—åˆ†ä¸º0.645ï¼ŒResNet-CNNå¾—åˆ†ä¸º0.623ï¼‰ä¸Šæœ‰æ‰€æå‡ï¼ŒåŒæ—¶åœ¨BLEUã€CIDErå’ŒMETEORä¸Šè¡¨ç°å…·æœ‰ç«äº‰åŠ›ã€‚æˆ‘ä»¬è¿˜æä¾›äº†æ¶ˆèç ”ç©¶ï¼ˆåŒºåŸŸæ³¨æ„åŠ›å¼€å…³å’Œä»¤ç‰Œè®¡æ•°æ‰«æï¼‰ã€æ¨¡æ€åˆ†æï¼ˆCT&#x2F;MRI&#x2F;Xå…‰ï¼‰ã€é…å¯¹æ˜¾è‘—æ€§æ£€éªŒå’Œå®šæ€§çƒ­å›¾ï¼Œå¯è§†åŒ–é©±åŠ¨æ¯ä¸ªæè¿°çš„åŒºåŸŸã€‚è§£ç ä½¿ç”¨å®½åº¦ä¼˜å…ˆæœç´¢ï¼ˆæŸå®½&#x3D;4ï¼‰ã€é•¿åº¦æƒ©ç½š&#x3D;1.1ã€æ— é‡å¤nå…ƒè¯­æ³•å¤§å°&#x3D;3å’Œæœ€å¤§é•¿åº¦&#x3D;128ã€‚æ‰€æå‡ºçš„è®¾è®¡äº§ç”Ÿäº†å‡†ç¡®ä¸”ä¸´åºŠè¡¨è¿°æ¸…æ™°çš„æè¿°ï¼Œå¹¶å…·æœ‰é€æ˜çš„åŒºåŸŸå½’å±ï¼Œæ”¯æŒäººç±»å‚ä¸çš„å®‰å…¨ç ”ç©¶ä½¿ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09893v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šè‡ªåŠ¨åŒ–åŒ»å­¦å›¾åƒæè¿°ç”Ÿæˆèƒ½å°†å¤æ‚çš„æ”¾å°„å›¾åƒè½¬åŒ–ä¸ºè¯Šæ–­å™è¿°ï¼Œæ”¯æŒæŠ¥å‘Šå·¥ä½œæµç¨‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºSwin-BARTçš„ç¼–ç è§£ç ç³»ç»Ÿï¼Œå¸¦æœ‰è½»é‡çº§å±€éƒ¨æ³¨æ„åŠ›æ¨¡å—ï¼Œåœ¨äº¤å‰æ³¨æ„åŠ›å‰æ”¾å¤§è¯Šæ–­æ˜¾è‘—åŒºåŸŸã€‚åœ¨ROCOæ•°æ®é›†ä¸Šè®­ç»ƒå’Œè¯„ä¼°ï¼Œè¯¥æ¨¡å‹åœ¨è¯­ä¹‰ä¿çœŸåº¦æ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼ŒåŒæ—¶ä¿æŒç´§å‡‘å’Œå¯è§£é‡Šæ€§ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒéªŒè¯ï¼Œè¯¥æ¨¡å‹åœ¨ROUGEã€BERTScoreç­‰è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæä¾›å¯è§†åŒ–çƒ­å›¾å±•ç¤ºå…³é”®åŒºåŸŸã€‚è§£ç è¿‡ç¨‹é‡‡ç”¨æŸæœç´¢ç­‰å‚æ•°è®¾ç½®ï¼Œç”Ÿæˆå‡†ç¡®ã€ç¬¦åˆä¸´åºŠè¯­å¢ƒçš„æè¿°ï¼Œå¹¶æä¾›é€æ˜åŒºåŸŸå½’å› ï¼Œæ”¯æŒæœ‰äººç±»å‚ä¸çš„å®‰å…¨ç ”ç©¶ä½¿ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªåŠ¨åŒ–åŒ»å­¦å›¾åƒæè¿°ç”Ÿæˆèƒ½å¤Ÿç®€åŒ–æ”¾å°„å›¾åƒçš„è§£è¯»å’ŒæŠ¥å‘Šå·¥ä½œæµç¨‹ã€‚</li>
<li>æå‡ºçš„Swin-BARTç¼–ç è§£ç ç³»ç»Ÿå¸¦æœ‰å±€éƒ¨æ³¨æ„åŠ›æ¨¡å—ï¼Œèƒ½çªå‡ºè¯Šæ–­å…³é”®åŒºåŸŸã€‚</li>
<li>æ¨¡å‹åœ¨ROCOæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¾¾åˆ°æœ€æ–°è¯­ä¹‰ä¿çœŸåº¦æ°´å¹³ã€‚</li>
<li>æ¨¡å‹å…·å¤‡ç´§å‡‘å’Œå¯è§£é‡Šæ€§ç‰¹ç‚¹ã€‚</li>
<li>ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹åœ¨ROUGEå’ŒBERTScoreç­‰è¯„ä¼°æŒ‡æ ‡ä¸Šæœ‰æ‰€æå‡ã€‚</li>
<li>é€šè¿‡å¯è§†åŒ–çƒ­å›¾å±•ç¤ºå…³é”®åŒºåŸŸï¼Œå¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09893">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-334bdc7c2844d67f94afbc84588a15c8" align="middle">
<img src="https://picx.zhimg.com/v2-cb120bae131505db3e0d6f7490ff0155" align="middle">
<img src="https://picx.zhimg.com/v2-8551dea490c852d9b7ea906317bd5f24" align="middle">
<img src="https://picx.zhimg.com/v2-94aecc2352f4831f66dc0ab0ccdf4dae" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CrochetBench-Can-Vision-Language-Models-Move-from-Describing-to-Doing-in-Crochet-Domain"><a href="#CrochetBench-Can-Vision-Language-Models-Move-from-Describing-to-Doing-in-Crochet-Domain" class="headerlink" title="CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?"></a>CrochetBench: Can Vision-Language Models Move from Describing to Doing in Crochet Domain?</h2><p><strong>Authors:Peiyu Li, Xiaobao Huang, Nitesh V. Chawla</strong></p>
<p>We present CrochetBench, a benchmark for evaluating the ability of multimodal large language models to perform fine-grained, low-level procedural reasoning in the domain of crochet. Unlike prior benchmarks that focus on high-level description or visual question answering, CrochetBench shifts the emphasis from describing to doing: models are required to recognize stitches, select structurally appropriate instructions, and generate compilable crochet procedures. We adopt the CrochetPARADE DSL as our intermediate representation, enabling structural validation and functional evaluation via execution. The benchmark covers tasks including stitch classification, instruction grounding, and both natural language and image-to-DSL translation. Across all tasks, performance sharply declines as the evaluation shifts from surface-level similarity to executable correctness, exposing limitations in long-range symbolic reasoning and 3D-aware procedural synthesis. CrochetBench offers a new lens for assessing procedural competence in multimodal models and highlights the gap between surface-level understanding and executable precision in real-world creative domains. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Peiyu-Georgia-Li/crochetBench">https://github.com/Peiyu-Georgia-Li/crochetBench</a>.</p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†CrochetBenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é’©ç¼–é¢†åŸŸè¿›è¡Œç²¾ç»†ã€ä½çº§çš„ç¨‹åºæ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ä»¥å¾€ä¸“æ³¨äºé«˜çº§æè¿°æˆ–è§†è§‰é—®ç­”çš„åŸºå‡†æµ‹è¯•ä¸åŒï¼ŒCrochetBenchå°†é‡ç‚¹ä»æè¿°è½¬å‘æ“ä½œï¼šæ¨¡å‹éœ€è¦è¯†åˆ«é’ˆè„šã€é€‰æ‹©ç»“æ„é€‚å½“çš„æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆå¯ç¼–è¯‘çš„é’©ç¼–ç¨‹åºã€‚æˆ‘ä»¬é‡‡ç”¨CrochetPARADE DSLä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œé€šè¿‡æ‰§è¡Œæ¥æ‰§è¡Œç»“æ„éªŒè¯å’ŒåŠŸèƒ½è¯„ä¼°ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…æ‹¬é’ˆè„šåˆ†ç±»ã€æŒ‡ä»¤å®šä½ä»¥åŠè‡ªç„¶è¯­è¨€ä¸å›¾åƒåˆ°DSLçš„ç¿»è¯‘ä»»åŠ¡ã€‚éšç€è¯„ä¼°ä»è¡¨é¢ç›¸ä¼¼æ€§è½¬å‘å¯æ‰§è¡Œæ­£ç¡®æ€§ï¼Œæ‰€æœ‰ä»»åŠ¡çš„æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæš´éœ²äº†é•¿ç¨‹ç¬¦å·æ¨ç†å’Œ3Dæ„ŸçŸ¥ç¨‹åºåˆæˆä¸­çš„å±€é™æ€§ã€‚CrochetBenchä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ç¨‹åºèƒ½åŠ›æä¾›äº†æ–°è§†è§’ï¼Œå¹¶çªå‡ºäº†ç°å®ä¸–ç•Œçš„åˆ›æ„é¢†åŸŸä¸­è¡¨å±‚ç†è§£ä¸å¯æ‰§è¡Œç²¾ç¡®åº¦ä¹‹é—´çš„å·®è·ã€‚ä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/Peiyu-Georgia-Li/crochetBench">https://github.com/Peiyu-Georgia-Li/crochetBench</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09483v1">PDF</a> code available at <a target="_blank" rel="noopener" href="https://github.com/Peiyu-Georgia-Li/crochetBench">https://github.com/Peiyu-Georgia-Li/crochetBench</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†CrochetBenchï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é’©ç¼–é¢†åŸŸçš„ç²¾ç»†ã€ä½çº§åˆ«ç¨‹åºæ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚å®ƒä¸åŒäºä»¥å¾€ä¾§é‡äºé«˜çº§æè¿°æˆ–è§†è§‰é—®ç­”çš„åŸºå‡†æµ‹è¯•ï¼Œè¦æ±‚æ¨¡å‹è¯†åˆ«é’ˆè„šã€é€‰æ‹©ç»“æ„é€‚å½“çš„æŒ‡ä»¤ï¼Œå¹¶ç”Ÿæˆå¯ç¼–è¯‘çš„é’©ç¼–ç¨‹åºã€‚é‡‡ç”¨CrochetPARADE DSLä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå¯è¿›è¡Œç»“æ„éªŒè¯å’ŒåŠŸèƒ½è¯„ä¼°ã€‚è¯¥åŸºå‡†æµ‹è¯•æ¶µç›–é’ˆè„šåˆ†ç±»ã€æŒ‡ä»¤å®šä½ä»¥åŠè‡ªç„¶è¯­è¨€ä¸å›¾åƒåˆ°DSLçš„ç¿»è¯‘ä»»åŠ¡ã€‚è¯„ä¼°ä»è¡¨é¢ç›¸ä¼¼æ€§è½¬å‘å¯æ‰§è¡Œæ­£ç¡®æ€§æ—¶ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæš´éœ²äº†é•¿ç¨‹ç¬¦å·æ¨ç†å’Œ3Dç¨‹åºåˆæˆçš„å±€é™æ€§ã€‚CrochetBenchä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ç¨‹åºèƒ½åŠ›æä¾›äº†æ–°çš„è§†è§’ï¼Œå¹¶çªå‡ºäº†è¡¨é¢çº§ç†è§£ä¸å¯æ‰§è¡Œç²¾åº¦åœ¨ç°å®åˆ›æ„é¢†åŸŸä¹‹é—´çš„å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CrochetBenchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºå‡†æµ‹è¯•ï¼Œé‡ç‚¹è€ƒå¯Ÿå…¶åœ¨é’©ç¼–é¢†åŸŸçš„ç²¾ç»†ã€ä½çº§åˆ«ç¨‹åºæ¨ç†èƒ½åŠ›ã€‚</li>
<li>ä¸ä¼ ç»ŸåŸºå‡†æµ‹è¯•ä¸åŒï¼ŒCrochetBenchå¼ºè°ƒä»æè¿°åˆ°æ‰§è¡Œçš„æ“ä½œèƒ½åŠ›ï¼Œè¦æ±‚æ¨¡å‹å®Œæˆè¯†åˆ«é’ˆè„šã€é€‰æ‹©æŒ‡ä»¤å’Œç”Ÿæˆå¯ç¼–è¯‘ç¨‹åºç­‰ä»»åŠ¡ã€‚</li>
<li>é‡‡ç”¨CrochetPARADE DSLä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œæ”¯æŒç»“æ„éªŒè¯å’Œé€šè¿‡æ‰§è¡Œçš„åŠŸèƒ½è¯„ä¼°ã€‚</li>
<li>åŸºå‡†æµ‹è¯•æ¶µç›–é’ˆè„šåˆ†ç±»ã€æŒ‡ä»¤å®šä½ä»¥åŠè‡ªç„¶è¯­è¨€ä¸å›¾åƒåˆ°DSLçš„ç¿»è¯‘ä»»åŠ¡ã€‚</li>
<li>è¯„ä¼°ä»è¡¨é¢ç›¸ä¼¼æ€§è½¬å‘å¯æ‰§è¡Œæ­£ç¡®æ€§æ—¶ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæš´éœ²å‡ºé•¿ç¨‹ç¬¦å·æ¨ç†å’Œ3Dç¨‹åºåˆæˆçš„æŒ‘æˆ˜ã€‚</li>
<li>CrochetBenchä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹ä¸­çš„ç¨‹åºèƒ½åŠ›æä¾›äº†æ–°è§†è§’ã€‚</li>
<li>å¼ºè°ƒäº†è¡¨é¢çº§ç†è§£ä¸å¯æ‰§è¡Œç²¾åº¦åœ¨ç°å®åˆ›æ„é¢†åŸŸä¹‹é—´çš„å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2cab8fc5c6e274c20384aebeea9ef67" align="middle">
<img src="https://picx.zhimg.com/v2-20b55b2a0407f46d189ead06a85443aa" align="middle">
<img src="https://picx.zhimg.com/v2-4c17dab7e6c30a2c5721e8dc5618f78e" align="middle">
<img src="https://picx.zhimg.com/v2-82d6fe732c516b0b46990444a551fdc9" align="middle">
<img src="https://picx.zhimg.com/v2-b743f2a36335ed71122ab071c31b00a2" align="middle">
<img src="https://picx.zhimg.com/v2-13a9e15fe1af8d8eb26e8ee467b415cc" align="middle">
<img src="https://picx.zhimg.com/v2-259a9702de514035a2ab2dbc9c19330d" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Augment-to-Augment-Diverse-Augmentations-Enable-Competitive-Ultra-Low-Field-MRI-Enhancement"><a href="#Augment-to-Augment-Diverse-Augmentations-Enable-Competitive-Ultra-Low-Field-MRI-Enhancement" class="headerlink" title="Augment to Augment: Diverse Augmentations Enable Competitive Ultra-Low-Field MRI Enhancement"></a>Augment to Augment: Diverse Augmentations Enable Competitive Ultra-Low-Field MRI Enhancement</h2><p><strong>Authors:Felix F Zimmermann</strong></p>
<p>Ultra-low-field (ULF) MRI promises broader accessibility but suffers from low signal-to-noise ratio (SNR), reduced spatial resolution, and contrasts that deviate from high-field standards. Image-to-image translation can map ULF images to a high-field appearance, yet efficacy is limited by scarce paired training data. Working within the ULF-EnC challenge constraints (50 paired 3D volumes; no external data), we study how task-adapted data augmentations impact a standard deep model for ULF image enhancement. We show that strong, diverse augmentations, including auxiliary tasks on high-field data, substantially improve fidelity. Our submission ranked third by brain-masked SSIM on the public validation leaderboard and fourth by the official score on the final test leaderboard. Code is available at <a target="_blank" rel="noopener" href="https://github.com/fzimmermann89/low-field-enhancement">https://github.com/fzimmermann89/low-field-enhancement</a>.</p>
<blockquote>
<p>è¶…ä½åœºï¼ˆULFï¼‰MRIè™½ç„¶ä¸ºæ›´å¹¿æ³›çš„å¯ç”¨æ€§æä¾›äº†æ½œåŠ›ï¼Œä½†å´å­˜åœ¨ä¿¡å·å™ªå£°æ¯”ï¼ˆSNRï¼‰ä½ã€ç©ºé—´åˆ†è¾¨ç‡é™ä½ä»¥åŠåç¦»é«˜åœºæ ‡å‡†çš„å¯¹æ¯”åº¦ç­‰é—®é¢˜ã€‚å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘å¯ä»¥å°†ULFå›¾åƒæ˜ å°„åˆ°é«˜åœºå¤–è§‚ï¼Œä½†å…¶æœ‰æ•ˆæ€§å—é™äºç¨€ç¼ºçš„é…å¯¹è®­ç»ƒæ•°æ®ã€‚åœ¨ULF-EnCæŒ‘æˆ˜çš„é™åˆ¶æ¡ä»¶ä¸‹ï¼ˆ50å¯¹3Dä½“ç§¯ï¼›æ— å¤–éƒ¨æ•°æ®ï¼‰ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä»»åŠ¡é€‚åº”æ€§æ•°æ®å¢å¼ºå¦‚ä½•å½±å“ç”¨äºULFå›¾åƒå¢å¼ºçš„æ ‡å‡†æ·±åº¦æ¨¡å‹ã€‚æˆ‘ä»¬è¡¨æ˜ï¼ŒåŒ…æ‹¬åœ¨é«˜åœºæ•°æ®ä¸Šçš„è¾…åŠ©ä»»åŠ¡åœ¨å†…çš„å¼ºå¤§ä¸”å¤šæ ·åŒ–çš„å¢å¼ºæªæ–½ï¼Œå¯ä»¥å¤§å¤§æé«˜ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æäº¤åœ¨å…¬å…±éªŒè¯æ’è¡Œæ¦œä¸Šä»¥è„‘æ©è†œSSIMæ’åç¬¬ä¸‰ï¼Œåœ¨æœ€ç»ˆæµ‹è¯•æ’è¡Œæ¦œä¸Šä»¥å®˜æ–¹è¯„åˆ†æ’åç¬¬å››ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.comcom/fzimmermann89/low-field-enhancement%E8%8E%B7%E5%8F%96%E3%80%82">https://github.comcom/fzimmermann89/low-field-enhancementè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.09366v1">PDF</a> MICCAI 2025 ULF-EnC Challenge</p>
<p><strong>Summary</strong></p>
<p>è¶…ä½é¢‘MRIè™½æœ‰æœ›æé«˜æ™®åŠæ€§ï¼Œä½†å­˜åœ¨ä¿¡å·å™ªå£°æ¯”ä½ã€ç©ºé—´åˆ†è¾¨ç‡é™ä½åŠå¯¹æ¯”åº¦åç¦»é«˜é¢‘æ ‡å‡†ç­‰é—®é¢˜ã€‚å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢å¯å°†ä½é¢‘å›¾åƒæ˜ å°„åˆ°é«˜é¢‘å¤–è§‚ï¼Œä½†å…¶æœ‰æ•ˆæ€§å—é™äºé…å¯¹è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºæ€§ã€‚åœ¨ULF-EnCæŒ‘æˆ˜çš„é™åˆ¶æ¡ä»¶ä¸‹ï¼ˆ50å¯¹ä¸‰ç»´ä½“ç§¯æ•°æ®ï¼Œæ— å¤–éƒ¨æ•°æ®ï¼‰ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä»»åŠ¡é€‚åº”æ€§æ•°æ®å¢å¼ºå¯¹ä½é¢‘å›¾åƒå¢å¼ºæ ‡å‡†æ·±åº¦æ¨¡å‹çš„å½±å“ã€‚ç ”ç©¶æ˜¾ç¤ºï¼ŒåŒ…æ‹¬é«˜é¢‘æ•°æ®è¾…åŠ©ä»»åŠ¡åœ¨å†…çš„å¼ºå¤§ã€å¤šæ ·åŒ–çš„æ•°æ®å¢å¼ºæ˜¾è‘—æé«˜äº†ä¿çœŸåº¦ã€‚æˆ‘ä»¬çš„æäº¤åœ¨å…¬å¼€éªŒè¯æ’è¡Œæ¦œä¸Šä»¥è„‘æ©è†œSSIMæ’åç¬¬ä¸‰ï¼Œåœ¨æœ€ç»ˆæµ‹è¯•æ’è¡Œæ¦œä¸Šæ’åç¬¬å››ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/fzimmermann89/low-field-enhancement">é“¾æ¥</a>å¤„è·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¶…ä½é¢‘MRIé¢ä¸´ä¿¡å·å™ªå£°æ¯”ä½ã€ç©ºé—´åˆ†è¾¨ç‡é™ä½å’Œå¯¹æ¯”åº¦åç¦»é«˜é¢‘æ ‡å‡†ç­‰æŒ‘æˆ˜ã€‚</li>
<li>å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢æ–¹æ³•å¯å°†ä½é¢‘MRIå›¾åƒè½¬åŒ–ä¸ºé«˜é¢‘å¤–è§‚ï¼Œä½†å—é™äºé…å¯¹è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºæ€§ã€‚</li>
<li>åœ¨ULF-EnCæŒ‘æˆ˜çš„é™åˆ¶æ¡ä»¶ä¸‹ï¼Œä»»åŠ¡é€‚åº”æ€§æ•°æ®å¢å¼ºèƒ½æé«˜ä½é¢‘å›¾åƒå¢å¼ºçš„æ•ˆæœã€‚</li>
<li>å¼ºå¤§çš„æ•°æ®å¢å¼ºæ–¹æ³•åŒ…æ‹¬ä½¿ç”¨è¾…åŠ©ä»»åŠ¡å¤„ç†é«˜é¢‘æ•°æ®ï¼Œå¯æ˜¾è‘—æé«˜ä¿çœŸåº¦ã€‚</li>
<li>ç ”ç©¶æˆæœåœ¨å…¬å¼€æ’è¡Œæ¦œä¸Šè·å¾—è¾ƒé«˜æ’åï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.09366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e758f55f21f2078907fe3e41a6d4c46c" align="middle">
<img src="https://picx.zhimg.com/v2-d01349c7690485a8a85797538cb7a2ba" align="middle">
<img src="https://picx.zhimg.com/v2-a943ccad2b51bf83fca394eb7e32ee00" align="middle">
<img src="https://picx.zhimg.com/v2-eec3b40fd03acdc7d398f448f52ba16e" align="middle">
<img src="https://picx.zhimg.com/v2-0aba12bed07e5aff119cf00c84dc3b7b" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DT-NVS-Diffusion-Transformers-for-Novel-View-Synthesis"><a href="#DT-NVS-Diffusion-Transformers-for-Novel-View-Synthesis" class="headerlink" title="DT-NVS: Diffusion Transformers for Novel View Synthesis"></a>DT-NVS: Diffusion Transformers for Novel View Synthesis</h2><p><strong>Authors:Wonbong Jang, Jonathan Tremblay, Lourdes Agapito</strong></p>
<p>Generating novel views of a natural scene, e.g., every-day scenes both indoors and outdoors, from a single view is an under-explored problem, even though it is an organic extension to the object-centric novel view synthesis. Existing diffusion-based approaches focus rather on small camera movements in real scenes or only consider unnatural object-centric scenes, limiting their potential applications in real-world settings. In this paper we move away from these constrained regimes and propose a 3D diffusion model trained with image-only losses on a large-scale dataset of real-world, multi-category, unaligned, and casually acquired videos of everyday scenes. We propose DT-NVS, a 3D-aware diffusion model for generalized novel view synthesis that exploits a transformer-based architecture backbone. We make significant contributions to transformer and self-attention architectures to translate images to 3d representations, and novel camera conditioning strategies to allow training on real-world unaligned datasets. In addition, we introduce a novel training paradigm swapping the role of reference frame between the conditioning image and the sampled noisy input. We evaluate our approach on the 3D task of generalized novel view synthesis from a single input image and show improvements over state-of-the-art 3D aware diffusion models and deterministic approaches, while generating diverse outputs.</p>
<blockquote>
<p>ç”Ÿæˆè‡ªç„¶åœºæ™¯çš„æ–°è§†è§’ï¼ˆä¾‹å¦‚å®¤å†…å’Œå®¤å¤–æ—¥å¸¸åœºæ™¯ï¼‰æ˜¯ä¸€ä¸ªå°šæœªè¢«å……åˆ†ç ”ç©¶çš„é—®é¢˜ï¼Œå°½ç®¡å®ƒæ˜¯é¢å‘å¯¹è±¡çš„æ–°å‹è§†å›¾åˆæˆçš„æœ‰æœºå»¶ä¼¸ã€‚ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æ›´å¤šåœ°å…³æ³¨çœŸå®åœºæ™¯ä¸­çš„å°ç›¸æœºè¿åŠ¨ï¼Œæˆ–è€…åªè€ƒè™‘ä¸è‡ªç„¶çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„åœºæ™¯ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œè®¾ç½®ä¸­çš„æ½œåœ¨åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ‘†è„±è¿™äº›å—é™çš„åˆ¶åº¦ï¼Œå¹¶æå‡ºäº†ä¸€ç§åœ¨çœŸå®ä¸–ç•Œã€å¤šç±»åˆ«ã€æœªå¯¹é½ã€éšæ„è·å–çš„è§†é¢‘å¤§å‹æ•°æ®é›†ä¸Šï¼Œä»…é€šè¿‡å›¾åƒæŸå¤±è¿›è¡Œè®­ç»ƒçš„3Dæ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†DT-NVSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨æ–°å‹è§†å›¾åˆæˆçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨åŸºäºtransformerçš„æ¶æ„ä¸»å¹²ã€‚æˆ‘ä»¬å¯¹transformerå’Œè‡ªæˆ‘æ³¨æ„æ¶æ„åšå‡ºäº†é‡å¤§è´¡çŒ®ï¼Œä»¥å°†å›¾åƒç¿»è¯‘ä¸º3dè¡¨ç¤ºï¼Œå¹¶å¼•å…¥äº†æ–°çš„ç›¸æœºè°ƒèŠ‚ç­–ç•¥ï¼Œä»¥å…è®¸åœ¨çœŸå®ä¸–ç•Œæœªå¯¹é½çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œåœ¨æ¡ä»¶å›¾åƒå’Œé‡‡æ ·å™ªå£°è¾“å…¥ä¹‹é—´äº¤æ¢å‚è€ƒå¸§çš„è§’è‰²ã€‚æˆ‘ä»¬åœ¨ä»å•ä¸ªè¾“å…¥å›¾åƒç”Ÿæˆé€šç”¨æ–°å‹è§†å›¾çš„3Dä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶æ˜¾ç¤ºå‡ºç›¸è¾ƒäºæœ€å…ˆè¿›çš„ä¸‰ç»´æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹å’Œç¡®å®šæ€§æ–¹æ³•æœ‰æ‰€æ”¹å–„ï¼ŒåŒæ—¶äº§ç”Ÿå¤šæ ·åŒ–çš„è¾“å‡ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.08823v1">PDF</a> 14 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºDT-NVSçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¹¿ä¹‰æ–°é¢–è§†è§’åˆæˆã€‚è¯¥æ¨¡å‹åŸºäºå˜å‹å™¨æ¶æ„ï¼Œèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œå¤šç±»åˆ«ã€æœªå¯¹é½ã€éšæ„è·å–çš„è§†é¢‘æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ–‡ç« è´¡çŒ®åŒ…æ‹¬åˆ©ç”¨å˜å‹å™¨å’Œè‡ªæ³¨æ„åŠ›æ¶æ„å°†å›¾åƒç¿»è¯‘ä¸º3Dè¡¨ç¤ºï¼Œä»¥åŠæ–°å‹ç›¸æœºæ¡ä»¶ç­–ç•¥ï¼Œå…è®¸åœ¨çœŸå®ä¸–ç•Œæœªå¯¹é½æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§æ–°å‹è®­ç»ƒæ¨¡å¼ï¼Œåœ¨æ¡ä»¶å›¾åƒå’Œé‡‡æ ·å™ªå£°è¾“å…¥ä¹‹é—´äº¤æ¢å‚è€ƒå¸§çš„è§’è‰²ã€‚åœ¨å•è¾“å…¥å›¾åƒè¿›è¡Œå¹¿ä¹‰æ–°é¢–è§†è§’åˆæˆçš„3Dä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹å’Œç¡®å®šæ€§æ–¹æ³•ï¼ŒåŒæ—¶ç”Ÿæˆå¤šæ ·åŒ–çš„è¾“å‡ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºä¸€ç§åä¸ºDT-NVSçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå¹¿ä¹‰æ–°é¢–è§†è§’åˆæˆã€‚</li>
<li>æ¨¡å‹åŸºäºå˜å‹å™¨æ¶æ„ï¼Œé€‚ç”¨äºçœŸå®ä¸–ç•Œå¤šç±»åˆ«ã€æœªå¯¹é½çš„è§†é¢‘æ•°æ®é›†ã€‚</li>
<li>è´¡çŒ®åŒ…æ‹¬åˆ©ç”¨å˜å‹å™¨å’Œè‡ªæ³¨æ„åŠ›æ¶æ„å°†å›¾åƒè½¬åŒ–ä¸º3Dè¡¨ç¤ºã€‚</li>
<li>å¼•å…¥æ–°å‹ç›¸æœºæ¡ä»¶ç­–ç•¥ï¼Œé€‚åº”çœŸå®ä¸–ç•Œæœªå¯¹é½æ•°æ®é›†çš„è®­ç»ƒã€‚</li>
<li>é‡‡ç”¨æ–°å‹è®­ç»ƒæ¨¡å¼ï¼Œåœ¨æ¡ä»¶å›¾åƒå’Œå™ªå£°è¾“å…¥ä¹‹é—´äº¤æ¢å‚è€ƒå¸§è§’è‰²ã€‚</li>
<li>åœ¨å•è¾“å…¥å›¾åƒè¿›è¡Œæ–°é¢–è§†è§’åˆæˆçš„3Dä»»åŠ¡ä¸Šï¼Œè¯¥æ¨¡å‹è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.08823">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9be9190941edf51e56bffd1a4726e1ec" align="middle">
<img src="https://picx.zhimg.com/v2-d39b673bb8eebaa3ea3ab46d4c0feece" align="middle">
<img src="https://picx.zhimg.com/v2-5d001ea7131062d3bb411941b1c16f0e" align="middle">
<img src="https://picx.zhimg.com/v2-7a0df37c52ac806a6500f5e974c000e9" align="middle">
<img src="https://picx.zhimg.com/v2-878f76dfc37865d41774fe3fa0db553e" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PLUTO-4-Frontier-Pathology-Foundation-Models"><a href="#PLUTO-4-Frontier-Pathology-Foundation-Models" class="headerlink" title="PLUTO-4: Frontier Pathology Foundation Models"></a>PLUTO-4: Frontier Pathology Foundation Models</h2><p><strong>Authors:Harshith Padigela, Shima Nofallah, Atchuth Naveen Chilaparasetti, Ryun Han, Andrew Walker, Judy Shen, Chintan Shah, Blake Martin, Aashish Sood, Elliot Miller, Ben Glass, Andy Beck, Harsha Pokkalla, Syed Ashar Javed</strong></p>
<p>Foundation models trained on large-scale pathology image corpora have demonstrated strong transfer capabilities across diverse histopathology tasks. Building on this progress, we introduce PLUTO-4, our next generation of pathology foundation models that extend the Pathology-Universal Transformer (PLUTO) to frontier scale. We share two complementary Vision Transformer architectures in the PLUTO-4 family: a compact and efficient PLUTO-4S model optimized for multi-scale deployment using a FlexiViT setup with 2D-RoPE embeddings, and a frontier-scale PLUTO-4G model trained with a single patch size to maximize representation capacity and stability. Both models are pretrained using a self-supervised objective derived from DINOv2 on a large multi-institutional corpus containing 551,164 WSIs from 137,144 patients across over 50 institutions, spanning over 60 disease types and over 100 stains. Comprehensive evaluation across public and internal benchmarks demonstrates that PLUTO-4 achieves state-of-the-art performance on tasks requiring varying spatial and biological context, including tile classification, segmentation, and slide-level diagnosis. The compact PLUTO-4S provides high-throughput and robust performance for practical deployment, while PLUTO-4G establishes new performance frontiers across multiple pathology benchmarks, including an 11% improvement in dermatopathology diagnosis. These diverse improvements underscore PLUTO-4â€™s potential to transform real-world applications as a backbone for translational research and diagnostic use cases.</p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡ç—…ç†å­¦å›¾åƒè¯­æ–™åº“è®­ç»ƒçš„æ¨¡å‹å·²åœ¨å¤šç§ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„è¿ç§»èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†PLUTO-4ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸‹ä¸€ä»£ç—…ç†å­¦åŸºç¡€æ¨¡å‹ï¼Œå®ƒå°†ç—…ç†å­¦é€šç”¨è½¬æ¢å™¨ï¼ˆPLUTOï¼‰æ‰©å±•åˆ°å‰æ²¿è§„æ¨¡ã€‚æˆ‘ä»¬åˆ†äº«äº†PLUTO-4ç³»åˆ—ä¸­çš„ä¸¤ç§äº’è¡¥çš„æ„¿æ™¯è½¬æ¢å™¨æ¶æ„ï¼šä¸€ä¸ªç´§å‡‘ä¸”é«˜æ•ˆçš„PLUTO-4Sæ¨¡å‹ï¼Œé‡‡ç”¨FlexiViTè®¾ç½®å’Œ2D-RoPEåµŒå…¥æŠ€æœ¯ï¼Œæ—¨åœ¨å®ç°å¤šå°ºåº¦éƒ¨ç½²çš„ä¼˜åŒ–ï¼›ä»¥åŠä¸€ä¸ªä»¥å•ä¸€è¡¥ä¸å°ºå¯¸è®­ç»ƒçš„PLUTO-4Gæ¨¡å‹ï¼Œä»¥æœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§ã€‚è¿™ä¸¤ç§æ¨¡å‹å‡ä½¿ç”¨æ¥è‡ªDINOv2çš„è‡ªå­¦ç›®æ ‡ï¼Œåœ¨åŒ…å«æ¥è‡ª50å¤šä¸ªæœºæ„çš„137,144åæ‚£è€…çš„551,164å¼ WSIçš„å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè·¨è¶Š60å¤šç§ç–¾ç—…ç±»å‹å’Œè¶…è¿‡100ç§æŸ“è‰²ã€‚åœ¨å…¬å…±å’Œå†…éƒ¨åŸºå‡†ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒPLUTO-4åœ¨éœ€è¦ä¸åŒç©ºé—´å’Œç”Ÿç‰©å­¦èƒŒæ™¯çš„ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¡¨ç°ï¼ŒåŒ…æ‹¬ç“·ç –åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§è¯Šæ–­ã€‚ç´§å‡‘çš„PLUTO-4Sä¸ºå®é™…éƒ¨ç½²æä¾›äº†é«˜é€šé‡å’Œç¨³å¥çš„æ€§èƒ½ï¼Œè€ŒPLUTO-4Gåœ¨å¤šä¸ªç—…ç†å­¦åŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æ–°çš„æ€§èƒ½è¾¹ç•Œï¼ŒåŒ…æ‹¬çš®è‚¤ç—…ç†å­¦è¯Šæ–­æé«˜äº†11%ã€‚è¿™äº›å¤šæ ·åŒ–çš„æ”¹è¿›çªæ˜¾äº†PLUTO-4ä½œä¸ºç¿»è¯‘ç ”ç©¶å’Œè¯Šæ–­ç”¨ä¾‹åç›¾ï¼Œåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02826v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡ç—…ç†å›¾åƒè¯­æ–™åº“è®­ç»ƒçš„æ¨¡å‹åœ¨è·¨å¤šç§ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„è¿ç§»èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†PLUTO-4ï¼Œè¿™æ˜¯ç—…ç†åŸºç¡€æ¨¡å‹çš„ä¸‹ä¸€ä»£äº§å“ï¼Œå®ƒæ‰©å±•äº†ç—…ç†é€šç”¨è½¬æ¢å™¨ï¼ˆPLUTOï¼‰è‡³å‰æ²¿è§„æ¨¡ã€‚æˆ‘ä»¬åˆ†äº«äº†PLUTO-4ç³»åˆ—ä¸­çš„ä¸¤ä¸ªäº’è¡¥çš„Vision Transformeræ¶æ„ï¼šä¸€ä¸ªä¼˜åŒ–ç”¨äºå¤šå°ºåº¦éƒ¨ç½²çš„ç´§å‡‘é«˜æ•ˆçš„PLUTO-4Sæ¨¡å‹ï¼Œé‡‡ç”¨FlexiViTè®¾ç½®å’Œ2D-RoPEåµŒå…¥ï¼›ä»¥åŠä¸€ä¸ªæ—¨åœ¨æœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§çš„å‰æ²¿è§„æ¨¡PLUTO-4Gæ¨¡å‹ï¼Œä½¿ç”¨å•ä¸€è¡¥ä¸å°ºå¯¸è¿›è¡Œè®­ç»ƒã€‚ä¸¤ä¸ªæ¨¡å‹éƒ½åœ¨åŒ…å«551,164å¼ WSIçš„å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¯¥è¯­æ–™åº“æ¶µç›–è¶…è¿‡60ç§ç–¾ç—…ç±»å‹å’Œè¶…è¿‡100ç§æŸ“è‰²ï¼Œé‡‡ç”¨DINOv2çš„è‡ªæˆ‘ç›‘ç£ç›®æ ‡ã€‚åœ¨å…¬å…±å’Œå†…éƒ¨åŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒPLUTO-4åœ¨éœ€è¦ä¸åŒç©ºé—´å’Œç”Ÿç‰©èƒŒæ™¯çš„ä»»åŠ¡ä¸Šå®ç°äº†æœ€æ–°æŠ€æœ¯æ€§èƒ½ï¼ŒåŒ…æ‹¬ç“¦ç‰‡åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§è¯Šæ–­ã€‚ç´§å‡‘å‹çš„PLUTO-4Sä¸ºå®é™…éƒ¨ç½²æä¾›äº†é«˜é€šé‡å’Œç¨³å¥çš„æ€§èƒ½ï¼Œè€ŒPLUTO-4Gåœ¨å¤šä¸ªç—…ç†å­¦åŸºå‡†æµ‹è¯•ä¸Šæ ‘ç«‹äº†æ–°çš„æ€§èƒ½æ ‡æ†ï¼ŒåŒ…æ‹¬çš®è‚¤ç—…ç†å­¦è¯Šæ–­æé«˜äº†11%ã€‚è¿™äº›å¤šæ ·åŒ–çš„æ”¹è¿›çªæ˜¾äº†PLUTO-4ä½œä¸ºç¿»è¯‘ç ”ç©¶å’Œè¯Šæ–­ç”¨ä¾‹çš„åç«¯æ½œåŠ›ï¼Œæœ‰æœ›æ”¹å˜å®é™…åº”ç”¨çš„æ ¼å±€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PLUTO-4æ˜¯ç—…ç†åŸºç¡€æ¨¡å‹çš„å‡çº§ç‰ˆï¼Œæ‰©å±•è‡³å‰æ²¿è§„æ¨¡ã€‚</li>
<li>PLUTO-4å®¶æ—åŒ…æ‹¬é’ˆå¯¹å¤šå°ºåº¦éƒ¨ç½²ä¼˜åŒ–çš„ç´§å‡‘é«˜æ•ˆPLUTO-4Sæ¨¡å‹ï¼Œä»¥åŠæœ€å¤§åŒ–è¡¨ç¤ºèƒ½åŠ›å’Œç¨³å®šæ€§çš„å‰æ²¿è§„æ¨¡PLUTO-4Gæ¨¡å‹ã€‚</li>
<li>ä¸¤ä¸ªæ¨¡å‹éƒ½åœ¨å¤§å‹å¤šæœºæ„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ¶µç›–å¤šç§ç–¾ç—…å’ŒæŸ“è‰²ã€‚</li>
<li>PLUTO-4é‡‡ç”¨è‡ªæˆ‘ç›‘ç£ç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚</li>
<li>PLUTO-4åœ¨å¤šç§ç»„ç»‡ç—…ç†å­¦ä»»åŠ¡ä¸Šå®ç°æœ€æ–°æŠ€æœ¯æ€§èƒ½ï¼ŒåŒ…æ‹¬ç“¦ç‰‡åˆ†ç±»ã€åˆ†å‰²å’Œå¹»ç¯ç‰‡çº§è¯Šæ–­ã€‚</li>
<li>PLUTO-4Sé€‚åˆå®é™…éƒ¨ç½²ï¼Œå…·æœ‰é«˜é€šé‡å’Œç¨³å¥æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02826">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6988bdf87fbe9c1f6cc99b9b8a27febf" align="middle">
<img src="https://picx.zhimg.com/v2-646759529634ef89db3c9d8cc2e4d441" align="middle">
<img src="https://picx.zhimg.com/v2-7f59cc6317554bab27eb62e6937911a6" align="middle">
<img src="https://picx.zhimg.com/v2-de0e0a291fcb810621f57e96ad584c70" align="middle">
<img src="https://picx.zhimg.com/v2-02dcca386ec2a18910c90a8eab4f0791" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PISA-Bench-The-PISA-Index-as-a-Multilingual-and-Multimodal-Metric-for-the-Evaluation-of-Vision-Language-Models"><a href="#PISA-Bench-The-PISA-Index-as-a-Multilingual-and-Multimodal-Metric-for-the-Evaluation-of-Vision-Language-Models" class="headerlink" title="PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models"></a>PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models</h2><p><strong>Authors:Patrick Haller, Fabio Barth, Jonas Golde, Georg Rehm, Alan Akbik</strong></p>
<p>Vision-language models (VLMs) have demonstrated remarkable progress in multimodal reasoning. However, existing benchmarks remain limited in terms of high-quality, human-verified examples. Many current datasets rely on synthetically generated content by large language models (LLMs). Furthermore, most datasets are limited to English, as manual quality assurance of translated samples is time-consuming and costly. To fill this gap, we introduce PISA-Bench, a multilingual benchmark derived from English examples of the expert-created PISA tests, a unified framework for the assessment of student competencies in over eighty countries. Each example consists of human-extracted instructions, questions, answer options, and images, enriched with question type categories, and has been translated from English into five additional languages (Spanish, German, Chinese, French, and Italian), resulting in a fully parallel corpus covering six languages. We evaluate state-of-the-art vision-language models on PISA-Bench and find that especially small models (&lt;20B parameters) fail to achieve high test scores. We further find substantial performance degradation on non-English splits as well as high error-rates when models are tasked with spatial and geometric reasoning. By releasing the dataset and evaluation framework, we provide a resource for advancing research on multilingual multimodal reasoning.</p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šæ¨¡æ€æ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•åœ¨é«˜è´¨é‡ã€äººå·¥éªŒè¯çš„æ ·æœ¬æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚ç›®å‰è®¸å¤šæ•°æ®é›†ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åˆæˆçš„å†…å®¹ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°æ•°æ®é›†ä»…é™äºè‹±è¯­ï¼Œå› ä¸ºå¯¹ç¿»è¯‘æ ·æœ¬è¿›è¡Œæ‰‹åŠ¨è´¨é‡ä¿éšœæ—¢è€—æ—¶åˆæˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†PISA-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªä»ä¸“å®¶åˆ›å»ºçš„PISAæµ‹è¯•è‹±è¯­æ ·æœ¬ä¸­è¡ç”Ÿå‡ºæ¥çš„å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ã€‚PISAæµ‹è¯•æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å…«åå¤šä¸ªå›½å®¶å­¦ç”Ÿçš„èƒ½åŠ›ã€‚æ¯ä¸ªæ ·æœ¬éƒ½ç”±äººå·¥æå–çš„æŒ‡ä»¤ã€é—®é¢˜ã€ç­”æ¡ˆé€‰é¡¹å’Œå›¾åƒç»„æˆï¼Œå¹¶ä¸°å¯Œäº†é—®é¢˜ç±»å‹ç±»åˆ«ï¼Œå·²ä»è‹±è¯­ç¿»è¯‘æˆäº†å¦å¤–äº”ç§è¯­è¨€ï¼ˆè¥¿ç­ç‰™è¯­ã€å¾·è¯­ã€ä¸­æ–‡ã€æ³•è¯­å’Œæ„å¤§åˆ©è¯­ï¼‰ï¼Œå½¢æˆäº†ä¸€ä¸ªæ¶µç›–å…­ç§è¯­è¨€çš„å®Œå…¨å¹³è¡Œè¯­æ–™åº“ã€‚æˆ‘ä»¬åœ¨PISA-Benchä¸Šè¯„ä¼°äº†æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå‘ç°å°¤å…¶æ˜¯å°å‹æ¨¡å‹ï¼ˆ&lt;20Bå‚æ•°ï¼‰å¾ˆéš¾å–å¾—è¾ƒé«˜çš„æµ‹è¯•åˆ†æ•°ã€‚æˆ‘ä»¬è¿˜å‘ç°åœ¨éè‹±è¯­åˆ†å‰²ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå½“æ¨¡å‹è¢«èµ‹äºˆç©ºé—´å’Œå‡ ä½•æ¨ç†ä»»åŠ¡æ—¶ï¼Œé”™è¯¯ç‡å¾ˆé«˜ã€‚æˆ‘ä»¬é€šè¿‡å‘å¸ƒæ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶ï¼Œä¸ºæ¨è¿›å¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†ç ”ç©¶æä¾›äº†ä¸€é¡¹èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.24792v2">PDF</a> 8 pages, 11 tables and figures</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ä»‹ç»äº†PISA-Benchå¤šè¯­è¨€åŸºå‡†æµ‹è¯•çš„å¼€å‘èƒŒæ™¯ä¸é‡è¦æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•åŸºäºä¸“å®¶åˆ›å»ºçš„PISAæµ‹è¯•è‹±è¯­æ ·æœ¬ï¼Œè¦†ç›–äº†è¶…è¿‡å…«åä¸ªå›½å®¶çš„å­¦ç”Ÿèƒ½åŠ›è¯„ä¼°ã€‚PISA-BenchåŒ…å«äº†å¤šç§è¯­è¨€çš„æ ·æœ¬ï¼ŒåŒ…æ‹¬è‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€å¾·è¯­ã€ä¸­æ–‡ã€æ³•è¯­å’Œæ„å¤§åˆ©è¯­ç­‰å…­ç§è¯­è¨€çš„å…¨å¥—å¹³è¡Œè¯­æ–™åº“ã€‚è¯„ä¼°å‘ç°ï¼Œå°å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨éè‹±è¯­åˆ†æ”¯ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨ç©ºé—´å‡ ä½•æ¨ç†æ–¹é¢å­˜åœ¨è¾ƒé«˜é”™è¯¯ç‡ã€‚å‘å¸ƒæ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶å¯ä¸ºå¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†ç ”ç©¶æä¾›èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>PISA-Benchæ˜¯ä¸€ä¸ªå¤šè¯­è¨€åŸºå‡†æµ‹è¯•ï¼ŒåŸºäºä¸“å®¶åˆ›å»ºçš„PISAæµ‹è¯•è‹±è¯­æ ·æœ¬ã€‚</li>
<li>PISA-BenchåŒ…å«äº†å…­ç§è¯­è¨€çš„å¹³è¡Œè¯­æ–™åº“ï¼ŒåŒ…æ‹¬è‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€å¾·è¯­ã€ä¸­æ–‡ç­‰ã€‚</li>
<li>è¯„ä¼°å‘ç°å°å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨éè‹±è¯­åˆ†æ”¯ä¸Šçš„æ€§èƒ½ä¸‹é™æ˜¾è‘—ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´å‡ ä½•æ¨ç†æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>PISA-Benchä¸ºæ¨è¿›å¤šè¯­è¨€å¤šæ¨¡æ€æ¨ç†ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºã€‚</li>
<li>å½“å‰åŸºå‡†æµ‹è¯•åœ¨é«˜è´¨é‡ã€ç»è¿‡äººå·¥éªŒè¯çš„æ ·æœ¬æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.24792">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-55adffce2ed82117b298f5d703bc27e5" align="middle">
<img src="https://picx.zhimg.com/v2-c17893b4a5da046157dfd2da811e9a86" align="middle">
<img src="https://picx.zhimg.com/v2-24e69397f2b60d46dfaec1b86d7a79e8" align="middle">
<img src="https://picx.zhimg.com/v2-a91fa7f12361a809204cd2eaa081a8ef" align="middle">
<img src="https://picx.zhimg.com/v2-b6e61c619902db031dcad741b9d2db12" align="middle">
<img src="https://picx.zhimg.com/v2-cc1fa247d05beadfa78553dbe06c9090" align="middle">
<img src="https://picx.zhimg.com/v2-984c307e3d2d64ed43b69285d5e582f8" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CoCoLIT-ControlNet-Conditioned-Latent-Image-Translation-for-MRI-to-Amyloid-PET-Synthesis"><a href="#CoCoLIT-ControlNet-Conditioned-Latent-Image-Translation-for-MRI-to-Amyloid-PET-Synthesis" class="headerlink" title="CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis"></a>CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis</h2><p><strong>Authors:Alec Sargood, Lemuel Puglisi, James H. Cole, Neil P. Oxtoby, Daniele RavÃ¬, Daniel C. Alexander</strong></p>
<p>Synthesizing amyloid PET scans from the more widely available and accessible structural MRI modality offers a promising, cost-effective approach for large-scale Alzheimerâ€™s Disease (AD) screening. This is motivated by evidence that, while MRI does not directly detect amyloid pathology, it may nonetheless encode information correlated with amyloid deposition that can be uncovered through advanced modeling. However, the high dimensionality and structural complexity of 3D neuroimaging data pose significant challenges for existing MRI-to-PET translation methods. Modeling the cross-modality relationship in a lower-dimensional latent space can simplify the learning task and enable more effective translation. As such, we present CoCoLIT (ControlNet-Conditioned Latent Image Translation), a diffusion-based latent generative framework that incorporates three main innovations: (1) a novel Weighted Image Space Loss (WISL) that improves latent representation learning and synthesis quality; (2) a theoretical and empirical analysis of Latent Average Stabilization (LAS), an existing technique used in similar generative models to enhance inference consistency; and (3) the introduction of ControlNet-based conditioning for MRI-to-PET translation. We evaluate CoCoLITâ€™s performance on publicly available datasets and find that our model significantly outperforms state-of-the-art methods on both image-based and amyloid-related metrics. Notably, in amyloid-positivity classification, CoCoLIT outperforms the second-best method with improvements of +10.5% on the internal dataset and +23.7% on the external dataset. The code and models of our approach are available at <a target="_blank" rel="noopener" href="https://github.com/brAIn-science/CoCoLIT">https://github.com/brAIn-science/CoCoLIT</a>.</p>
<blockquote>
<p>é€šè¿‡å°†ä»æ›´å¹¿æ³›å’Œå¯è®¿é—®çš„ç»“æ„æ€§MRIæ¨¡æ€åˆæˆçš„æ·€ç²‰æ ·è›‹ç™½PETæ‰«æï¼Œä¸ºå¤§è§„æ¨¡é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰ç­›æŸ¥æä¾›äº†æœ‰å‰æ™¯ä¸”ç»æµå®æƒ çš„æ–¹æ³•ã€‚è¿™èƒŒåçš„åŠ¨æœºæ˜¯ï¼Œè™½ç„¶MRIä¸ç›´æ¥æ£€æµ‹æ·€ç²‰æ ·è›‹ç™½ç—…å˜ï¼Œä½†å®ƒå¯èƒ½åŒ…å«ä¸æ·€ç²‰æ ·è›‹ç™½æ²‰ç§¯ç›¸å…³çš„ä¿¡æ¯ï¼Œå¯ä»¥é€šè¿‡å…ˆè¿›çš„å»ºæ¨¡æ¥æ­ç¤ºã€‚ç„¶è€Œï¼Œ3Dç¥ç»æˆåƒæ•°æ®çš„é«˜ç»´åº¦å’Œç»“æ„æ€§å¤æ‚æ€§å¯¹ç°æœ‰MRIåˆ°PETè½¬æ¢æ–¹æ³•æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚åœ¨è¾ƒä½ç»´åº¦çš„æ½œåœ¨ç©ºé—´ä¸­å»ºæ¨¡è·¨æ¨¡æ€å…³ç³»å¯ä»¥ç®€åŒ–å­¦ä¹ ä»»åŠ¡å¹¶æ›´æœ‰æ•ˆåœ°å®ç°è½¬æ¢ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†CoCoLITï¼ˆControlNetæ§åˆ¶çš„æ½œåœ¨å›¾åƒç¿»è¯‘ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„æ½œåœ¨ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªä¸»è¦åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ä¸€ç§æ–°å‹çš„åŠ æƒå›¾åƒç©ºé—´æŸå¤±ï¼ˆWISLï¼‰ï¼Œå¯æ”¹å–„æ½œåœ¨è¡¨ç¤ºå­¦ä¹ å’Œåˆæˆè´¨é‡ï¼›ï¼ˆ2ï¼‰å¯¹æ½œåœ¨å¹³å‡ç¨³å®šåŒ–ï¼ˆLASï¼‰çš„ç†è®ºå’Œå®è¯åˆ†æï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¢å¼ºæ¨ç†ä¸€è‡´æ€§çš„ç°æœ‰æŠ€æœ¯ï¼Œç”¨äºç±»ä¼¼çš„ç”Ÿæˆæ¨¡å‹ï¼›ï¼ˆ3ï¼‰å¼•å…¥åŸºäºControlNetçš„æ¡ä»¶è¿›è¡ŒMRIåˆ°PETè½¬æ¢ã€‚æˆ‘ä»¬åœ¨å…¬å¼€æ•°æ®é›†ä¸Šè¯„ä¼°äº†CoCoLITçš„æ€§èƒ½ï¼Œå‘ç°æˆ‘ä»¬çš„æ¨¡å‹åœ¨å›¾åƒå’Œæ·€ç²‰æ ·è›‹ç™½ç›¸å…³æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨æ·€ç²‰æ ·è›‹ç™½é˜³æ€§åˆ†ç±»æ–¹é¢ï¼ŒCoCoLITåœ¨å†…éƒ¨æ•°æ®é›†ä¸Šæ¯”ç¬¬äºŒåæé«˜äº†+10.5%ï¼Œåœ¨å¤–éƒ¨æ•°æ®é›†ä¸Šæé«˜äº†+23.7%ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/brAIn-science/CoCoLIT%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/brAIn-science/CoCoLITè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01292v2">PDF</a> Article accepted at AAAI-2026</p>
<p><strong>Summary</strong><br>     åˆæˆæ·€ç²‰æ ·PETæ‰«æä¸æ›´æ™®åŠã€æ›´æ˜“è·å–çš„ç»“æ„æ€§MRIæ¨¡æ€ç›¸ç»“åˆï¼Œä¸ºå¤§è§„æ¨¡é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰ç­›æŸ¥æä¾›äº†æœ‰å‰æ™¯ä¸”ç»æµçš„è§£å†³æ–¹æ¡ˆã€‚å°½ç®¡MRIä¸ç›´æ¥æ£€æµ‹æ·€ç²‰æ ·ç—…ç†ï¼Œä½†å®ƒå¯èƒ½åŒ…å«ä¸æ·€ç²‰æ ·æ²‰ç§¯ç›¸å…³çš„ä¿¡æ¯ï¼Œå¯é€šè¿‡é«˜çº§å»ºæ¨¡æ­ç¤ºã€‚æœ¬æ–‡æå‡ºCoCoLITï¼ˆåŸºäºæ§åˆ¶ç½‘ç»œçš„æ½œåœ¨å›¾åƒç¿»è¯‘ï¼‰ï¼Œé‡‡ç”¨æ‰©æ•£å¼æ½œåœ¨ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰é¡¹ä¸»è¦åˆ›æ–°ï¼šåŠ æƒå›¾åƒç©ºé—´æŸå¤±ï¼ˆWISLï¼‰æé«˜æ½œåœ¨è¡¨ç¤ºå­¦ä¹ å’Œåˆæˆè´¨é‡ï¼›å¯¹æ½œåœ¨å¹³å‡ç¨³å®šåŒ–ï¼ˆLASï¼‰è¿›è¡Œç†è®ºå’Œå®è¯åˆ†æï¼Œç”¨äºå¢å¼ºæ¨ç†ä¸€è‡´æ€§ï¼›å¼•å…¥åŸºäºæ§åˆ¶ç½‘ç»œçš„MRI-to-PETç¿»è¯‘æ¡ä»¶ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒCoCoLITåœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·€ç²‰æ ·é˜³æ€§åˆ†ç±»æ–¹é¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆæˆæ·€ç²‰æ ·PETæ‰«æä¸MRIç»“åˆä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…ç­›æŸ¥æä¾›ç»æµæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>MRIå¯èƒ½åŒ…å«ä¸æ·€ç²‰æ ·æ²‰ç§¯ç›¸å…³çš„ä¿¡æ¯ï¼Œå¯é€šè¿‡é«˜çº§å»ºæ¨¡æ­ç¤ºã€‚</li>
<li>CoCoLITæ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„æ½œåœ¨ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…å«åŠ æƒå›¾åƒç©ºé—´æŸå¤±ï¼ˆWISLï¼‰ã€æ½œåœ¨å¹³å‡ç¨³å®šåŒ–ï¼ˆLASï¼‰å’Œæ§åˆ¶ç½‘ç»œæ¡ä»¶ç­‰ä¸‰é¡¹ä¸»è¦åˆ›æ–°ã€‚</li>
<li>CoCoLITåœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>CoCoLITåœ¨æ·€ç²‰æ ·é˜³æ€§åˆ†ç±»æ–¹é¢çš„æ”¹è¿›å°¤ä¸ºæ˜¾è‘—ï¼Œå†…éƒ¨æ•°æ®é›†ä¸Šè¾ƒç¬¬äºŒåæ–¹æ³•æé«˜10.5%ï¼Œå¤–éƒ¨æ•°æ®é›†ä¸Šæé«˜23.7%ã€‚</li>
<li>CoCoLITæ–¹æ³•å’Œä»£ç å¯åœ¨æŒ‡å®šé“¾æ¥æ‰¾åˆ°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01292">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-76e8527779667ad683b660b5e604db1c" align="middle">
<img src="https://picx.zhimg.com/v2-beb27bc3c53e56855bc036e7253f2cc3" align="middle">
<img src="https://picx.zhimg.com/v2-3e72ac3d5e3e501c84dc0480d7300f2b" align="middle">
<img src="https://picx.zhimg.com/v2-d1467e1529f544c0549416e0002e78b5" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-Unified-and-Fast-Sampling-Diffusion-Bridge-Framework-via-Stochastic-Optimal-Control"><a href="#A-Unified-and-Fast-Sampling-Diffusion-Bridge-Framework-via-Stochastic-Optimal-Control" class="headerlink" title="A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control"></a>A Unified and Fast-Sampling Diffusion Bridge Framework via Stochastic Optimal Control</h2><p><strong>Authors:Mokai Pan, Kaizhen Zhu, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi</strong></p>
<p>Recent advances in diffusion bridge models leverage Doobâ€™s $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches often produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified and fast-sampling framework for diffusion bridges based on Stochastic Optimal Control (SOC). We reformulate the problem through an SOC-based optimization, proving that existing diffusion bridges employing Doobâ€™s $h$-transform constitute a special case, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. To avoid computationally expensive costs of iterative Euler sampling methods in UniDB, we design a training-free accelerated algorithm by deriving exact closed-form solutions for UniDBâ€™s reverse-time SDE. It is further complemented by replacing conventional noise prediction with a more stable data prediction model, along with an SDE-Corrector mechanism that maintains perceptual quality for low-step regimes, effectively reducing error accumulation. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework, bridging the gap between theoretical generality and practical efficiency. Our code is available online <a target="_blank" rel="noopener" href="https://github.com/2769433owo/UniDB-plusplus">https://github.com/2769433owo/UniDB-plusplus</a>.</p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¡¥æ¨¡å‹çš„æ–°è¿›å±•åˆ©ç”¨Doobçš„$h$-å˜æ¢åœ¨åˆ†å¸ƒä¹‹é—´å»ºç«‹å›ºå®šç«¯ç‚¹ï¼Œåœ¨å›¾åƒç¿»è¯‘å’Œæ¢å¤ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿæ¨¡ç³Šæˆ–è¿‡åº¦å¹³æ»‘çš„å›¾åƒç»†èŠ‚ï¼Œå¹¶ä¸”ç¼ºä¹å…¨é¢çš„ç†è®ºåŸºç¡€æ¥è§£é‡Šè¿™äº›ç¼ºç‚¹ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºéšæœºæœ€ä¼˜æ§åˆ¶ï¼ˆSOCï¼‰çš„æ‰©æ•£æ¡¥çš„ç»Ÿä¸€å¿«é€Ÿé‡‡æ ·æ¡†æ¶UniDBã€‚æˆ‘ä»¬é€šè¿‡åŸºäºSOCçš„ä¼˜åŒ–é‡æ–°è¡¨è¿°é—®é¢˜ï¼Œè¯æ˜é‡‡ç”¨Doob $h$-å˜æ¢çš„ç°æœ‰æ‰©æ•£æ¡¥æ„æˆäº†ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œè¿™ç§æƒ…å†µå‡ºç°åœ¨SOCæˆæœ¬å‡½æ•°çš„ç»ˆç«¯æƒ©ç½šç³»æ•°è¶‹äºæ— ç©·å¤§æ—¶ã€‚é€šè¿‡å¼•å…¥å¯è°ƒç»ˆç«¯æƒ©ç½šç³»æ•°ï¼ŒUniDBåœ¨æ§åˆ¶æˆæœ¬å’Œç»ˆç«¯æƒ©ç½šä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ï¼Œå¤§å¤§æé«˜äº†ç»†èŠ‚ä¿ç•™å’Œè¾“å‡ºè´¨é‡ã€‚ä¸ºäº†é¿å…UniDBä¸­è¿­ä»£æ¬§æ‹‰é‡‡æ ·æ–¹æ³•çš„è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å…è®­ç»ƒåŠ é€Ÿç®—æ³•ï¼Œé€šè¿‡æ¨å¯¼UniDBåå‘æ—¶é—´SDEçš„ç¡®åˆ‡å°é—­å½¢å¼è§£ã€‚å®ƒè¿˜é€šè¿‡ç”¨æ›´ç¨³å®šçš„æ•°æ®é¢„æµ‹æ¨¡å‹ä»£æ›¿ä¼ ç»Ÿå™ªå£°é¢„æµ‹ï¼Œä»¥åŠé€šè¿‡SDEæ ¡æ­£å™¨æœºåˆ¶ç»´æŒä½æ­¥éª¤çŠ¶æ€ä¸‹çš„æ„ŸçŸ¥è´¨é‡ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†è¯¯å·®ç§¯ç´¯ã€‚åœ¨å¤šç§å›¾åƒæ¢å¤ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„ä¼˜è¶Šæ€§å’Œé€‚åº”æ€§ï¼Œç¼©å°äº†ç†è®ºæ™®éæ€§å’Œå®é™…æ•ˆç‡ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ç½‘ä¸Šæ‰¾åˆ° <a target="_blank" rel="noopener" href="https://github.com/27">https://github.com/27</a> 769433owo&#x2F;UniDB-plusplusã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21528v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºDoobçš„hå˜æ¢çš„æ‰©æ•£æ¡¥æ¨¡å‹åœ¨å›¾åƒç¿»è¯‘å’Œæ¢å¤ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å­˜åœ¨æ¨¡ç³Šå’Œè¿‡åº¦å¹³æ»‘çš„ç»†èŠ‚é—®é¢˜ï¼Œä¸”ç¼ºä¹å…¨é¢ç†è®ºè§£é‡Šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºåŸºäºéšæœºæœ€ä¼˜æ§åˆ¶çš„ç»Ÿä¸€å¿«é€Ÿé‡‡æ ·æ¡†æ¶UniDBï¼Œé€šè¿‡SOCä¼˜åŒ–é‡æ–°è¡¨è¿°é—®é¢˜ï¼Œè¯æ˜ç°æœ‰æ‰©æ•£æ¡¥ä¸ºç‰¹æ®Šæƒ…å½¢ã€‚UniDBé€šè¿‡è°ƒæ•´ç»ˆç«¯æƒ©ç½šç³»æ•°å®ç°æ§åˆ¶æˆæœ¬ä¸ç»ˆç«¯æƒ©ç½šä¹‹é—´çš„å¹³è¡¡ï¼Œæ”¹å–„ç»†èŠ‚ä¿ç•™å’Œè¾“å‡ºè´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡æ— éœ€è®­ç»ƒçš„åŠ é€Ÿç®—æ³•ï¼Œä¸ºUniDBçš„åå‘æ—¶é—´SDEæ¨å¯¼ç²¾ç¡®å°é—­è§£ï¼Œå¹¶ç”¨æ›´ç¨³å®šçš„æ•°æ®é¢„æµ‹æ¨¡å‹å’ŒSDEæ ¡æ­£å™¨æé«˜æ„ŸçŸ¥è´¨é‡ã€‚å®éªŒè¯æ˜UniDBåœ¨å›¾åƒæ¢å¤ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§å’Œé€‚åº”æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¡¥æ¨¡å‹åˆ©ç”¨Doobçš„hå˜æ¢åœ¨å›¾åƒç¿»è¯‘å’Œæ¢å¤ä¸­å–å¾—è¿›å±•ï¼Œä½†å­˜åœ¨ç»†èŠ‚æ¨¡ç³Šå’Œè¿‡åº¦å¹³æ»‘çš„é—®é¢˜ã€‚</li>
<li>UniDBæ¡†æ¶åŸºäºéšæœºæœ€ä¼˜æ§åˆ¶æå‡ºï¼Œä¸ºè§£å†³ç°æœ‰æ‰©æ•£æ¡¥çš„å±€é™æ€§è€Œè®¾è®¡ã€‚</li>
<li>UniDBé€šè¿‡è°ƒæ•´ç»ˆç«¯æƒ©ç½šç³»æ•°å®ç°æ§åˆ¶æˆæœ¬ä¸ç»ˆç«¯æƒ©ç½šä¹‹é—´çš„å¹³è¡¡ï¼Œæé«˜å›¾åƒè´¨é‡ã€‚</li>
<li>UniDBé‡‡ç”¨æ— éœ€è®­ç»ƒçš„åŠ é€Ÿç®—æ³•ï¼Œä¸ºåå‘æ—¶é—´SDEæä¾›ç²¾ç¡®å°é—­è§£ï¼Œæé«˜æ•ˆç‡å’Œç¨³å®šæ€§ã€‚</li>
<li>UniDBæ¡†æ¶ç»“åˆæ•°æ®é¢„æµ‹æ¨¡å‹å’ŒSDEæ ¡æ­£å™¨ï¼Œæé«˜æ„ŸçŸ¥è´¨é‡ï¼Œå¹¶æœ‰æ•ˆå‡å°‘è¯¯å·®ç§¯ç´¯ã€‚</li>
<li>å¹¿æ³›å®éªŒè¯æ˜UniDBåœ¨å›¾åƒæ¢å¤ä»»åŠ¡çš„ä¼˜è¶Šæ€§å’Œé€‚åº”æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21528">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f6efe94f422ebb182e266c3b50656b65" align="middle">
<img src="https://picx.zhimg.com/v2-9cd7899a6a4c37d925c7f1e013950f73" align="middle">
<img src="https://picx.zhimg.com/v2-160d9b8151b0a7990ea25bca1b2999a6" align="middle">
<img src="https://picx.zhimg.com/v2-792f22ea92fce452a69054746126cadc" align="middle">
<img src="https://picx.zhimg.com/v2-b07ec562494b5146eb35a781b9f39d11" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-17/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-17/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-17/Speech/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6bf208ea47f2b4ef56bfa79ac10f85cc" class="responsive-img" alt="Speech">
                        
                        <span class="card-title">Speech</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  SAC Neural Speech Codec with Semantic-Acoustic Dual-Stream Quantization
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                    Speech
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Speech/">
                        <span class="chip bg-color">Speech</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-17/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f94fc05d96989a2c6ff57ef1daa9a909" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-17  Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33446.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
