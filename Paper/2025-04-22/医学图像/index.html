<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  Towards Accurate and Interpretable Neuroblastoma Diagnosis via   Contrastive Multi-scale Pathological Image Analysis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f657e4071acf014b3f096ccdeafde015.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    58 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-22-æ›´æ–°"><a href="#2025-04-22-æ›´æ–°" class="headerlink" title="2025-04-22 æ›´æ–°"></a>2025-04-22 æ›´æ–°</h1><h2 id="Towards-Accurate-and-Interpretable-Neuroblastoma-Diagnosis-via-Contrastive-Multi-scale-Pathological-Image-Analysis"><a href="#Towards-Accurate-and-Interpretable-Neuroblastoma-Diagnosis-via-Contrastive-Multi-scale-Pathological-Image-Analysis" class="headerlink" title="Towards Accurate and Interpretable Neuroblastoma Diagnosis via   Contrastive Multi-scale Pathological Image Analysis"></a>Towards Accurate and Interpretable Neuroblastoma Diagnosis via   Contrastive Multi-scale Pathological Image Analysis</h2><p><strong>Authors:Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu</strong></p>
<p>Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the Swin Transformer architecture by integrating a Kernel Activation Network within its multilayer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics cliniciansâ€™ comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/JSLiam94/CMSwinKAN">https://github.com/JSLiam94/CMSwinKAN</a>. </p>
<blockquote>
<p>ç¥ç»æ¯ç»†èƒç˜¤è‚¾ä¸Šè…ºæ¥æºæ˜¯å„¿ç«¥æœ€å¸¸è§çš„å®ä½“æ¶æ€§è‚¿ç˜¤ä¹‹ä¸€ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠå¼‚è´¨æ€§ã€‚ä»è‹æœ¨ç²¾å’Œä¼Šçº¢æŸ“è‰²çš„å…¨åˆ‡ç‰‡å›¾åƒè¿›è¡ŒåŠæ—¶å‡†ç¡®çš„ç—…ç†è¯Šæ–­å¯¹æ‚£è€…çš„é¢„åè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå½“å‰çš„è¯Šæ–­å®è·µä¸»è¦ä¾èµ–äºç—…ç†åŒ»å¸ˆçš„ä¸»è§‚æ‰‹åŠ¨æ£€æŸ¥ï¼Œå¯¼è‡´å‡†ç¡®æ€§ä¸ä¸€è‡´ã€‚ç°æœ‰çš„å…¨è‡ªåŠ¨åˆ‡ç‰‡å›¾åƒåˆ†ç±»æ–¹æ³•é¢ä¸´å¯è§£é‡Šæ€§å·®ã€ç‰¹å¾æå–èƒ½åŠ›æœ‰é™ä»¥åŠè®¡ç®—æˆæœ¬é«˜çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠå®è·µä¸­çš„éƒ¨ç½²ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†CMSwinKANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å‹ï¼Œä¸“é—¨ç”¨äºç—…ç†å›¾åƒåˆ†ç±»ã€‚å®ƒé€šè¿‡é›†æˆå†…æ ¸æ¿€æ´»ç½‘ç»œå¢å¼ºäº†Swin Transformeræ¶æ„çš„å¤šå±‚æ„ŸçŸ¥å™¨å’Œåˆ†ç±»å¤´æ¨¡å—ï¼Œæ˜¾è‘—æé«˜äº†å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡èåˆå¤šå°ºåº¦ç‰¹å¾å’Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼ŒCMSwinKANæ¨¡ä»¿äº†ä¸´åºŠåŒ»ç”Ÿå…¨é¢çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æ•æ‰äº†å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å—ä¸´åºŠè§è§£å¯å‘å¼çš„è½¯æŠ•ç¥¨æœºåˆ¶ï¼Œæ— ç¼åœ°è¿æ¥äº†è¡¥ä¸çº§åˆ«çš„é¢„æµ‹åˆ°å…¨åˆ‡ç‰‡å›¾åƒçº§åˆ«çš„åˆ†ç±»ã€‚æˆ‘ä»¬åœ¨ä¸åˆä½œåŒ»é™¢å…±åŒå»ºç«‹çš„PpNTsæ•°æ®é›†å’Œå¯å…¬å¼€è®¿é—®çš„BreakHisæ•°æ®é›†ä¸ŠéªŒè¯äº†CMSwinKANã€‚ç»“æœè¡¨æ˜ï¼ŒCMSwinKANçš„æ€§èƒ½ä¼˜äºåœ¨å¤§å‹æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ç°æœ‰æœ€å…ˆè¿›çš„ç—…ç†å­¦ä¸“ç”¨æ¨¡å‹ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JSLiam94/CMSwinKAN%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/JSLiam94/CMSwinKANä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13754v1">PDF</a> 14pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å‹CMSwinKANï¼Œç”¨äºç¥ç»æ¯ç»†èƒç˜¤ç­‰è‚¾ä¸Šè…ºè¡ç”Ÿè‚¿ç˜¤çš„ç—…ç†å›¾åƒåˆ†ç±»ã€‚è¯¥æ¨¡å‹é€šè¿‡æ•´åˆæ ¸æ¿€æ´»ç½‘ç»œï¼Œå¢å¼ºäº†Swin Transformeræ¶æ„çš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡å¤šå°ºåº¦ç‰¹å¾èåˆå’Œå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼ŒCMSwinKANæœ‰æ•ˆæ•æ‰å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ï¼Œæ¨¡ä»¿åŒ»ç”Ÿçš„ç»¼åˆè¯Šæ–­æ–¹æ³•ã€‚åœ¨PpNTså’ŒBreakHisæ•°æ®é›†ä¸Šçš„éªŒè¯ç»“æœæ˜¾ç¤ºï¼ŒCMSwinKANè¡¨ç°ä¼˜äºç°æœ‰çš„ç—…ç†å­¦ç‰¹å®šæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»æ¯ç»†èƒç˜¤æ˜¯å¸¸è§çš„å„¿ç«¥å®ä½“æ¶æ€§è‚¿ç˜¤ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠå¼‚è´¨æ€§ï¼ŒåŠæ—¶å‡†ç¡®çš„ç—…ç†è¯Šæ–­å¯¹é¢„åè‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰è¯Šæ–­æ–¹æ³•ä¸»è¦ä¾èµ–ç—…ç†åŒ»å¸ˆçš„ä¸»è§‚æ‰‹åŠ¨æ£€æŸ¥ï¼Œå­˜åœ¨å‡†ç¡®æ€§ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>CMSwinKANæ¨¡å‹ç»“åˆå¯¹æ¯”å­¦ä¹ ä¸å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œæé«˜äº†ç—…ç†å›¾åƒåˆ†ç±»çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚</li>
<li>CMSwinKANé€šè¿‡æ•´åˆæ ¸æ¿€æ´»ç½‘ç»œï¼Œå¢å¼ºSwin Transformeræ¶æ„çš„æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹èƒ½æ•æ‰å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ï¼Œæ¨¡ä»¿åŒ»ç”Ÿçš„ç»¼åˆè¯Šæ–­æ–¹æ³•ã€‚</li>
<li>åœ¨PpNTså’ŒBreakHisæ•°æ®é›†ä¸Šçš„éªŒè¯ç»“æœæ˜¾ç¤ºCMSwinKANä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13754">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-806109825c90292eaf19535c12b3fc14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f6dbb7506a28d6fb9101b8a8b82c3a30.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-47b8c90fede5a73b53fa4573a332eb18.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b5f62ca2268c1ea6e2086d352acb3e5d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Study-of-Solar-Energetic-Particles-their-Source-Regions-Flares-and-CMEs-during-Solar-Cycles-23-24"><a href="#Study-of-Solar-Energetic-Particles-their-Source-Regions-Flares-and-CMEs-during-Solar-Cycles-23-24" class="headerlink" title="Study of Solar Energetic Particles: their Source Regions, Flares and   CMEs during Solar Cycles 23-24"></a>Study of Solar Energetic Particles: their Source Regions, Flares and   CMEs during Solar Cycles 23-24</h2><p><strong>Authors:Raj Kumar, Ramesh Chandra, Bimal Pande, Seema Pande</strong></p>
<p>In this work, we examine the association between solar active regions and 152 solar flares, coronal mass ejections, and solar energetic particle (SEP) events over solar cycles 23-24 (1997-2017). The CDAW centerâ€™s GOES data in the energy channel &gt;10 MeV (Major SEPs; solar proton events) with flux &gt;&#x3D; 10 pfu was used for our investigation. For the associated activities, we have analyzed the data from space born satellites namely: SOHO&#x2F;LASCO and SDO&#x2F;AIA. We found a moderate correlation (55 %) between SXR flux and sunspot area i.e., active regions with larger sunspot areas generally generate larger flares. We found that most of the SEPs are originated from the magnetically complex active regions i.e., hale class beta-gamma-delta and beta. Very few events were associated with unipolar active regions. Stronger GOES X-ray is linked to more impulsive events, as evidenced by the negative correlation (-0.40) between X-ray flux and SEP duration. In the active region beta-gamma-delta, the highest average SEP intensity (2051 pfu) was detected. In the data set used, only 10 % SEPs are found impulsive in nature, while the remaining 90 % are gradual in nature. All the impulsive events had SEP intensity less than 100 pfu and most of the CMEs associated with these events were decelerated CMEs. We discovered that the majority of faster CMEs are linked to the most complex magnetic active regions. This indicates that high speed CMEs are produced by magnetically complex active regions. We discovered that 58 SEP events in our data set are linked to accelerated CMEs, while 82 are linked to decelerated CMEs. The highest average CME width is found corresponding to magnetically most complex active regions beta-delta, gamma-delta, alpha-gamma-delta and beta-gamma-delta, which shows that large CMEs are the consequences of magnetically complex active regions. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¤ªé˜³æ´»åŠ¨åŒºåŸŸä¸å¤ªé˜³å‘¨æœŸä¸­çš„å¤ªé˜³è€€æ–‘ï¼ˆsolar flareï¼‰ã€æ—¥å†•ç‰©è´¨æŠ›å°„ï¼ˆcoronal mass ejectionï¼‰ä»¥åŠå¤ªé˜³é«˜èƒ½ç²’å­ï¼ˆSEPï¼‰äº‹ä»¶ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œæ¶µç›–äº†å¤ªé˜³å‘¨æœŸçš„ç¬¬23å’Œç¬¬24å‘¨æœŸï¼ˆå³å¤ªé˜³æ´»åŠ¨é«˜å¹´ï¼Œä»1997å¹´è‡³2017å¹´ï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨äº†CDAWä¸­å¿ƒçš„GOESæ•°æ®å¯¹å¤§äº10MeVçš„è´¨å­èƒ½é‡è¿›è¡Œç ”ç©¶ï¼Œå¹¶é’ˆå¯¹å…¶è´¨é‡é€‰æ‹©è¾å°„é€šé‡å¤§äºç­‰äºæ¯å¹³æ–¹å¾®ç±³åäº¿ç”µå­ä¼ï¼ˆpfuï¼‰çš„æ•°æ®è¿›è¡Œåˆ†æã€‚å¯¹äºç›¸å…³çš„æ´»åŠ¨æ•°æ®ï¼Œæˆ‘ä»¬åˆ†æäº†å¤ªç©ºæ¢æµ‹å™¨ï¼ˆå¦‚SOHO&#x2F;LASCOå’ŒSDO&#x2F;AIAï¼‰æä¾›çš„æ•°æ®ã€‚æˆ‘ä»¬å‘ç°å¤ªé˜³è½¯Xå°„çº¿è¾å°„é€šé‡ä¸å¤ªé˜³é»‘å­é¢ç§¯ä¹‹é—´å­˜åœ¨ä¸­åº¦ç›¸å…³æ€§ï¼ˆå³ç™¾åˆ†ä¹‹äº”åäº”ï¼‰ï¼Œæ´»è·ƒåŒºåŸŸçš„å¤ªé˜³é»‘å­é¢ç§¯è¶Šå¤§é€šå¸¸å¼•å‘çš„å¤§å‹çˆ†å‘è¶Šæ˜æ˜¾ã€‚å¤§å¤šæ•°å¤ªé˜³é«˜èƒ½ç²’å­æ¥è‡ªç£åœºå¤æ‚çš„æ´»è·ƒåŒºåŸŸï¼Œå¦‚beta-gamma-deltaå‹å’Œbetaå‹ï¼Œéå¸¸å°‘çš„éƒ¨åˆ†æ¥æºäºå•ææ´»åŠ¨åŒºã€‚æ­¤å¤–è¿˜å‘ç°å¼ºåŠ²çš„GOESå°„çº¿æ˜¯ä¸æ›´å¤šçš„çªå‘äº‹ä»¶ç´§å¯†è”ç³»çš„è¯æ®è¡¨ç°åœ¨è¿™ä¸¤è€…é—´çš„è´Ÿç›¸å…³æ€§ï¼ˆè´Ÿé›¶ç‚¹å››ï¼‰ï¼Œè¿™ä»£è¡¨ç€å¼ºçƒˆçš„Xå°„çº¿å°„æµä¼šå¯¼è‡´é«˜èƒ½ç²’å­æŒç»­æ—¶é—´å‡å°‘ã€‚åœ¨beta-gamma-deltaå‹çš„æ´»è·ƒåŒºåŸŸä¸­æ£€æµ‹åˆ°äº†æœ€é«˜çš„å¹³å‡SEPå¼ºåº¦ï¼ˆæ¯å¹³æ–¹å¾®ç±³ä¸¤åƒé›¶äº”åä¸€ç”µå­ä¼ï¼‰ã€‚åœ¨æ‰€ä½¿ç”¨çš„æ•°æ®é›†ä¸­ï¼Œä»…æœ‰ç™¾åˆ†ä¹‹åçš„SEPæ˜¯çªå‘æ€§çš„ï¼Œå…¶ä½™ç™¾åˆ†ä¹‹ä¹åæ˜¯é€æ¸å‘å±•çš„ã€‚æ‰€æœ‰çªå‘æ€§äº‹ä»¶çš„SEPå¼ºåº¦å‡ä½äºæ¯å¹³æ–¹å¾®ç±³ä¸€ç™¾ç”µå­ä¼ï¼Œå¹¶ä¸”ä¸è¿™äº›äº‹ä»¶ç›¸å…³çš„æ—¥å†•ç‰©è´¨æŠ›å°„å¤§å¤šæ•°æ˜¯å‡é€ŸæŠ›å°„ã€‚æˆ‘ä»¬å‘ç°å¤§å¤šæ•°é«˜é€Ÿæ—¥å†•ç‰©è´¨æŠ›å°„ä¸æœ€å¤æ‚çš„ç£åœºæ´»è·ƒåŒºåŸŸç›¸å…³è”ã€‚è¿™è¡¨æ˜é«˜é€Ÿçš„æ—¥å†•ç‰©è´¨æŠ›å°„æ˜¯ç”±ç£åœºå¤æ‚çš„æ´»è·ƒåŒºåŸŸå¼•èµ·çš„ã€‚æˆ‘ä»¬å‘ç°æ•°æ®é›†ä¸­æœ‰ç™¾åˆ†ä¹‹äº”åå…«çš„SEPäº‹ä»¶ä¸åŠ é€Ÿæ—¥å†•ç‰©è´¨æŠ›å°„ç›¸å…³ï¼Œè€Œæœ‰ç™¾åˆ†ä¹‹å…«åäºŒåˆ™ä¸å‡é€Ÿæ—¥å†•ç‰©è´¨æŠ›å°„æœ‰å…³ã€‚å¯¹åº”äºæœ€å¤æ‚çš„æ´»è·ƒåŒºåŸŸå¦‚beta-deltaå‹ã€gamma-deltaå‹ä»¥åŠalpha-gamma-deltaå‹å’Œbeta-gamma-deltaå‹æ—¶å¹³å‡æ—¥å†•ç‰©è´¨æŠ›å°„å®½åº¦æœ€é«˜ï¼Œè¿™è¡¨æ˜å¤§è§„æ¨¡çš„æ—¥å†•ç‰©è´¨æŠ›å°„æ˜¯ç£åœºå¤æ‚æ´»è·ƒåŒºåŸŸçš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13654v1">PDF</a> 26 pages, 09 figures (accepted for publication in Indian Journal of   Physics)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†ç¬¬23è‡³ç¬¬24ä¸ªå¤ªé˜³å‘¨æœŸï¼ˆå³è¿‡å»è‡ªä¸€ä¹ä¹ä¸ƒå¹´èµ·çš„äºŒåå¹´ï¼‰ä¸­å¤ªé˜³æ´»åŠ¨åŒºåŸŸä¸å¤ªé˜³è€€æ–‘çˆ†å‘ã€æ—¥å†•ç‰©è´¨å–·å°„ä»¥åŠé«˜èƒ½å¤ªé˜³ç²’å­äº‹ä»¶çš„å…³è”ã€‚åˆ©ç”¨CDAWä¸­å¿ƒçš„GOESæ•°æ®è¿›è¡Œåˆ†æï¼Œä¸»è¦å…³æ³¨äº†èƒ½é‡é€šé“å¤§äºæˆ–ç­‰äºåMeVçš„SEPäº‹ä»¶ã€‚ç»“åˆSOHO&#x2F;LASCOå’ŒSDO&#x2F;AIAç­‰å¤ªç©ºå«æ˜Ÿçš„æ•°æ®ï¼Œç ”ç©¶å‘ç°å¤ªé˜³Xå°„çº¿æµé‡ä¸å¤ªé˜³é»‘å­é¢ç§¯ä¹‹é—´å­˜åœ¨ä¸­åº¦ç›¸å…³æ€§ï¼ˆçº¦ç™¾åˆ†ä¹‹äº”åäº”ï¼‰ï¼Œè¡¨æ˜è¾ƒå¤§å¤ªé˜³é»‘å­åŒºåŸŸçš„æ´»è·ƒåŒºåŸŸé€šå¸¸äº§ç”Ÿæ›´å¤§çš„è€€æ–‘ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°SEPäº‹ä»¶æºè‡ªå¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸï¼Œå¦‚Î²-Î³-Î´å’ŒÎ²ç±»HaleåŒºåŸŸã€‚å¾ˆå°‘æœ‰äº‹ä»¶ä¸å•ææ´»è·ƒåŒºåŸŸç›¸å…³ã€‚è¿˜å‘ç°å¼ºçƒˆçš„GOES Xå°„çº¿ä¸æ›´çªå‘æ€§äº‹ä»¶æœ‰å…³ï¼Œè¡¨ç°ä¸ºXå°„çº¿æµé‡ä¸SEPæŒç»­æ—¶é—´ä¹‹é—´çš„è´Ÿç›¸å…³æ€§ï¼ˆ-é›¶ç‚¹å››ï¼‰ã€‚åœ¨Î²-Î³-Î´æ´»è·ƒåŒºåŸŸæ£€æµ‹åˆ°æœ€é«˜çš„å¹³å‡SEPå¼ºåº¦ï¼ˆä¸¤åƒé›¶äº”åä¸€pfuï¼‰ã€‚æ•°æ®é›†ä¸­ä»…æœ‰ç™¾åˆ†ä¹‹åçš„SEPå±äºçªå‘æ€§äº‹ä»¶ï¼Œå…¶ä½™ç™¾åˆ†ä¹‹ä¹ååˆ™ä¸ºæ¸è¿›æ€§äº‹ä»¶ã€‚æ‰€æœ‰çªå‘æ€§äº‹ä»¶çš„SEPå¼ºåº¦å‡ä½äºä¸€ç™¾pfuï¼Œå¹¶ä¸”å¤§å¤šæ•°ä¸ä¹‹ç›¸å…³çš„CMEéƒ½æ˜¯å‡é€Ÿçš„CMEã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œå¤§å¤šæ•°é«˜é€ŸCMEä¸æœ€å¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸæœ‰å…³ï¼Œè¡¨æ˜é«˜é€ŸCMEæ˜¯ç”±å¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸäº§ç”Ÿçš„ã€‚æ•°æ®é›†ä¸­æœ‰ç™¾åˆ†ä¹‹äº”åå…«çš„SEPäº‹ä»¶ä¸åŠ é€Ÿçš„CMEç›¸å…³ï¼Œè€Œç™¾åˆ†ä¹‹å…«åäºŒä¸å‡é€Ÿçš„CMEç›¸å…³ã€‚æœ€å¤§çš„CMEå®½åº¦é€šå¸¸å‡ºç°åœ¨æœ€å¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸï¼Œå¦‚Î²-Î´ã€Î³-Î´å’ŒÎ±-Î³-Î´ä»¥åŠÎ²-Î³-Î´åŒºåŸŸã€‚è¿™è¡¨æ˜å¤§å‹CMEæ˜¯å¤æ‚ç£æ´»è·ƒåŒºåŸŸçš„ç»“æœã€‚æ€»ç»“è€Œè¨€ï¼Œæœ¬ç ”ç©¶æ¢è®¨äº†å¤ªé˜³æ´»åŠ¨åŒºåŸŸçš„ç£åœºå¤æ‚æ€§ä¸é«˜èƒ½å¤ªé˜³ç²’å­äº‹ä»¶ä¹‹é—´çš„å…³è”æ€§åŠå…¶èƒŒåçš„ç‰©ç†æœºåˆ¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤ªé˜³æ´»åŠ¨åŒºåŸŸä¸å¤ªé˜³è€€æ–‘çˆ†å‘ã€æ—¥å†•ç‰©è´¨å–·å°„åŠé«˜èƒ½å¤ªé˜³ç²’å­äº‹ä»¶ä¹‹é—´å­˜åœ¨æ˜¾è‘—å…³è”ã€‚</li>
<li>å¤ªé˜³Xå°„çº¿æµé‡ä¸å¤ªé˜³é»‘å­é¢ç§¯ä¹‹é—´å­˜åœ¨ä¸­åº¦ç›¸å…³æ€§ï¼Œæš—ç¤ºå¤§è€€æ–‘æ›´å¯èƒ½å‡ºç°åœ¨è¾ƒå¤§å¤ªé˜³é»‘å­åŒºåŸŸçš„æ´»è·ƒåŒºåŸŸã€‚</li>
<li>å¤§éƒ¨åˆ†é«˜èƒ½å¤ªé˜³ç²’å­äº‹ä»¶æºè‡ªå¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸï¼Œå¦‚Î²-Î³-Î´ç±»åŒºåŸŸã€‚å•ææ´»è·ƒåŒºåŸŸä¸ä¹‹ç›¸å…³çš„äº‹ä»¶å¾ˆå°‘ã€‚</li>
<li>å¼ºçƒˆçš„GOES Xå°„çº¿æµé‡ä¸æ›´çªå‘æ€§çš„äº‹ä»¶æœ‰å…³ï¼Œè¡¨ç°ä¸ºXå°„çº¿æµé‡ä¸SEPæŒç»­æ—¶é—´ä¹‹é—´çš„è´Ÿç›¸å…³æ€§ã€‚</li>
<li>æ•°æ®é›†ä¸­ä»…æœ‰å°éƒ¨åˆ†SEPäº‹ä»¶ä¸ºçªå‘æ€§ï¼Œå¤§éƒ¨åˆ†å±äºæ¸è¿›æ€§äº‹ä»¶ã€‚ä¸çªå‘æ€§äº‹ä»¶ç›¸å…³çš„CMEå¤§å¤šæ˜¯å‡é€Ÿçš„ã€‚</li>
<li>é«˜é€ŸCMEå¤šä¸æœ€å¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸæœ‰å…³ã€‚è¿™è¡¨æ˜é«˜é€ŸCMEçš„äº§ç”Ÿä¸å¤æ‚çš„ç£æ´»è·ƒåŒºåŸŸå¯†åˆ‡ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13654">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-19389dcc2b0e23909ec9325175998c17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b228ba73adf98e711e887b6731576bb8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-110a95e9406e261210004bd163ff26d7.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Static-linear-density-response-from-X-ray-Thomson-scattering-measurements-a-case-study-of-warm-dense-beryllium"><a href="#Static-linear-density-response-from-X-ray-Thomson-scattering-measurements-a-case-study-of-warm-dense-beryllium" class="headerlink" title="Static linear density response from X-ray Thomson scattering   measurements: a case study of warm dense beryllium"></a>Static linear density response from X-ray Thomson scattering   measurements: a case study of warm dense beryllium</h2><p><strong>Authors:Sebastian Schwalbe, Hannah Bellenbaum, Tilo DÃ¶ppner, Maximilian BÃ¶hme, Thomas Gawne, Dominik Kraus, Michael J. MacDonald, Zhandos Moldabekov, Panagiotis Tolias, Jan Vorberger, Tobias Dornheim</strong></p>
<p>Linear response theory is ubiquitous throughout physics and plays a central role in the theoretical description of warm dense matter â€“ an extreme state that occurs within compact astrophysical objects and that is traversed on the compression path of a fuel capsule in inertial confinement fusion applications. Here we show how one can relate the static linear density response function to X-ray Thomson scattering (XRTS) measurements, which opens up new possibilities for the diagnostics of extreme states of matter, and for the rigorous assessment and verification of theoretical models and approximations. As a practical example, we consider an XRTS data set of warm dense beryllium taken at the National Ignition Facility [T.<del>D&quot;oppner \emph{et al.}, \textit{Nature} \textbf{618}, 270-275 (2023)]. The comparison with state-of-the-art \emph{ab initio} path integral Monte Carlo (PIMC) simulations [T.</del>Dornheim \emph{et al.}, \textit{Nature Commun.}~(in print), arXiv:2402.19113] gives us a best estimate of the mass density of $\rho&#x3D;18\pm6,$g&#x2F;cc, which is consistent with previous PIMC and density functional theory based studies, but rules out the original estimate of $\rho&#x3D;34\pm4,$g&#x2F;cc based on a Chihara model fit. </p>
<blockquote>
<p>çº¿æ€§å“åº”ç†è®ºåœ¨ç‰©ç†å­¦ä¸­æ— å¤„ä¸åœ¨ï¼Œå¹¶åœ¨æè¿°çƒ­å¯†ç‰©è´¨çš„ç†è®ºä¸­èµ·åˆ°æ ¸å¿ƒä½œç”¨ã€‚è¿™æ˜¯ä¸€ç§æç«¯çŠ¶æ€ï¼Œå‡ºç°åœ¨è‡´å¯†çš„å¤©ä½“ç‰©ç†å¯¹è±¡ä¸­ï¼Œä¹Ÿå‡ºç°åœ¨æƒ¯æ€§çº¦æŸèšå˜åº”ç”¨çš„ç‡ƒæ–™èƒ¶å›Šå‹ç¼©è·¯å¾„ä¸Šã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å°†é™æ€çº¿æ€§å¯†åº¦å“åº”å‡½æ•°ä¸Xå°„çº¿æ±¤å§†æ£®æ•£å°„ï¼ˆXRTSï¼‰æµ‹é‡ç›¸å…³è”ï¼Œè¿™ä¸ºæç«¯ç‰©è´¨çŠ¶æ€çš„è¯Šæ–­ã€ç†è®ºæ¨¡å‹å’Œè¿‘ä¼¼çš„ä¸¥æ ¼è¯„ä¼°å’ŒéªŒè¯æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚ä½œä¸ºä¸€ä¸ªå®é™…ä¾‹å­ï¼Œæˆ‘ä»¬è€ƒè™‘äº†åœ¨å›½å®¶ç‚¹ç«è®¾æ–½ï¼ˆT. Doppnerç­‰äººï¼Œã€Šè‡ªç„¶ã€‹æ‚å¿—ï¼Œç¬¬618æœŸï¼Œ270-275é¡µï¼ˆ2023å¹´ï¼‰ï¼‰è·å–çš„æ¸©çƒ­è‡´å¯†é“çš„XRTSæ•°æ®é›†ã€‚ä¸æœ€æ–°çš„ä»å¤´å¼€å§‹è·¯å¾„ç§¯åˆ†è’™ç‰¹å¡æ´›ï¼ˆPIMCï¼‰æ¨¡æ‹Ÿï¼ˆDornheimç­‰äººï¼Œã€Šè‡ªç„¶é€šè®¯ã€‹ï¼ˆå°åˆ·ä¸­ï¼‰ï¼ŒarXivï¼š2402.19113ï¼‰çš„æ¯”è¾ƒï¼Œä¸ºæˆ‘ä»¬æä¾›äº†æœ€ä½³è´¨é‡å¯†åº¦ä¼°è®¡å€¼Ï&#x3D;18Â±6 g&#x2F;ccã€‚è¿™ä¸ä¹‹å‰çš„PIMCå’ŒåŸºäºå¯†åº¦æ³›å‡½ç†è®ºçš„ç ”ç©¶ç›¸ä¸€è‡´ï¼Œä½†æ’é™¤äº†åŸºäºChiharaæ¨¡å‹æ‹Ÿåˆçš„åŸå§‹ä¼°è®¡å€¼Ï&#x3D;34Â±4 g&#x2F;ccã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13611v1">PDF</a> </p>
<p><strong>Summary</strong><br>     çº¿æ€§å“åº”ç†è®ºåœ¨ç‰©ç†å­¦ä¸­æ™®éå­˜åœ¨ï¼Œå¯¹äºæè¿°çƒ­å¯†ç‰©è´¨çš„ç†è®ºèµ·åˆ°äº†æ ¸å¿ƒä½œç”¨ã€‚æœ¬æ–‡é€šè¿‡å±•ç¤ºé™æ€çº¿æ€§å¯†åº¦å“åº”å‡½æ•°ä¸Xå°„çº¿æ±¤å§†æ£®æ•£å°„æµ‹é‡çš„å…³ç³»ï¼Œä¸ºæç«¯ç‰©è´¨çŠ¶æ€çš„è¯Šæ–­å’Œç†è®ºæ¨¡å‹ä¸è¿‘ä¼¼çš„ä¸¥æ ¼è¯„ä¼°éªŒè¯æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚å¯¹æ¯”å®éªŒæ•°æ®ä¸æœ€å…ˆè¿›çš„ä»å¤´è®¡ç®—è·¯å¾„ç§¯åˆ†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œå¾—åˆ°æœ€ä½³ä¼°è®¡è´¨é‡å¯†åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çº¿æ€§å“åº”ç†è®ºåœ¨æè¿°çƒ­å¯†ç‰©è´¨ä¸­èµ·åˆ°æ ¸å¿ƒä½œç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‰©ç†å’Œå¤©ä½“ç‰©ç†å­¦é¢†åŸŸã€‚</li>
<li>Xå°„çº¿æ±¤å§†æ£®æ•£å°„æµ‹é‡ä¸é™æ€çº¿æ€§å¯†åº¦å“åº”å‡½æ•°çš„å…³ç³»å¯ç”¨äºæç«¯ç‰©è´¨çŠ¶æ€çš„è¯Šæ–­ã€‚</li>
<li>é€šè¿‡å¯¹æ¯”å®éªŒæ•°æ®ä¸æœ€æ–°çš„ä»å¤´è®¡ç®—è·¯å¾„ç§¯åˆ†è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œå¯ä»¥å¯¹ç†è®ºæ¨¡å‹è¿›è¡ŒéªŒè¯å’Œè¯„ä¼°ã€‚</li>
<li>æ–‡ä¸­ä»¥çƒ­å¯†é“ä¸ºä¾‹ï¼Œç»™å‡ºäº†åŸºäºæœ€æ–°æ¨¡æ‹Ÿçš„æœ€ä½³ä¼°è®¡è´¨é‡å¯†åº¦ã€‚</li>
<li>è¿™ä¸€ä¼°è®¡ä¸ä¹‹å‰çš„PIMCå’Œå¯†åº¦æ³›å‡½ç†è®ºç ”ç©¶ä¸€è‡´ï¼Œæ’é™¤äº†åŸºäºChiharaæ¨¡å‹æ‹Ÿåˆçš„åŸå§‹ä¼°è®¡ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºæƒ¯æ€§çº¦æŸèšå˜åº”ç”¨ä¸­ç‡ƒæ–™èƒ¶å›Šçš„å‹ç¼©è·¯å¾„æä¾›äº†æ–°è§†è§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0060772abb4c3c4c2534fb3d0c3ec3fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc221e242d3621eb574c061234735577.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8fd360b6f56fe56da9d12d1074df1263.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Filter2Noise-Interpretable-Self-Supervised-Single-Image-Denoising-for-Low-Dose-CT-with-Attention-Guided-Bilateral-Filtering"><a href="#Filter2Noise-Interpretable-Self-Supervised-Single-Image-Denoising-for-Low-Dose-CT-with-Attention-Guided-Bilateral-Filtering" class="headerlink" title="Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for   Low-Dose CT with Attention-Guided Bilateral Filtering"></a>Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for   Low-Dose CT with Attention-Guided Bilateral Filtering</h2><p><strong>Authors:Yipeng Sun, Linda-Sophie Schneider, Mingxuan Gu, Siyuan Mei, Chengze Ye, Fabian Wagner, Siming Bayer, Andreas Maier</strong></p>
<p>Effective denoising is crucial in low-dose CT to enhance subtle structures and low-contrast lesions while preventing diagnostic errors. Supervised methods struggle with limited paired datasets, and self-supervised approaches often require multiple noisy images and rely on deep networks like U-Net, offering little insight into the denoising mechanism. To address these challenges, we propose an interpretable self-supervised single-image denoising framework â€“ Filter2Noise (F2N). Our approach introduces an Attention-Guided Bilateral Filter that adapted to each noisy input through a lightweight module that predicts spatially varying filter parameters, which can be visualized and adjusted post-training for user-controlled denoising in specific regions of interest. To enable single-image training, we introduce a novel downsampling shuffle strategy with a new self-supervised loss function that extends the concept of Noise2Noise to a single image and addresses spatially correlated noise. On the Mayo Clinic 2016 low-dose CT dataset, F2N outperforms the leading self-supervised single-image method (ZS-N2N) by 4.59 dB PSNR while improving transparency, user control, and parametric efficiency. These features provide key advantages for medical applications that require precise and interpretable noise reduction. Our code is demonstrated at <a target="_blank" rel="noopener" href="https://github.com/sypsyp97/Filter2Noise.git">https://github.com/sypsyp97/Filter2Noise.git</a> . </p>
<blockquote>
<p>åœ¨ä½å‰‚é‡è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­ï¼Œæœ‰æ•ˆçš„å»å™ªå¯¹äºå¢å¼ºç»†å¾®ç»“æ„å’Œä½å¯¹æ¯”åº¦ç—…å˜è‡³å…³é‡è¦ï¼ŒåŒæ—¶é˜²æ­¢è¯Šæ–­é”™è¯¯ã€‚ç›‘ç£æ–¹æ³•å—é™äºé…å¯¹æ•°æ®é›†ï¼Œè€Œè‡ªç›‘ç£æ–¹æ³•é€šå¸¸éœ€è¦å¤šä¸ªå™ªå£°å›¾åƒï¼Œå¹¶ä¾èµ–äºU-Netç­‰æ·±åº¦ç½‘ç»œï¼Œå¯¹å»å™ªæœºåˆ¶æä¾›å¾ˆå°‘çš„æ´å¯Ÿã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯è§£é‡Šçš„è‡ªç›‘ç£å•å›¾åƒå»å™ªæ¡†æ¶â€”â€”Filter2Noiseï¼ˆF2Nï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ³¨æ„åŠ›å¼•å¯¼åŒè¾¹æ»¤æ³¢å™¨ï¼Œè¯¥æ»¤æ³¢å™¨å¯é€šè¿‡è½»é‡çº§æ¨¡å—é¢„æµ‹ç©ºé—´å˜åŒ–çš„æ»¤æ³¢å™¨å‚æ•°ï¼Œä»¥é€‚åº”æ¯ä¸ªå™ªå£°è¾“å…¥ã€‚è¿™äº›å‚æ•°å¯ä»¥åœ¨è®­ç»ƒåè¿›è¡Œå¯è§†åŒ–å’Œè°ƒæ•´ï¼Œä»¥å®ç°ç”¨æˆ·æ§åˆ¶çš„ç‰¹å®šæ„Ÿå…´è¶£åŒºåŸŸçš„å»å™ªã€‚ä¸ºäº†å®ç°å•å›¾åƒè®­ç»ƒï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„ä¸‹é‡‡æ ·æ´—ç‰Œç­–ç•¥ï¼Œä»¥åŠä¸€ç§æ–°çš„è‡ªç›‘ç£æŸå¤±å‡½æ•°ï¼Œå®ƒå°†Noise2Noiseçš„æ¦‚å¿µæ‰©å±•åˆ°å•å›¾åƒå¹¶è§£å†³ç©ºé—´ç›¸å…³å™ªå£°é—®é¢˜ã€‚åœ¨æ¢…å¥¥è¯Šæ‰€2016å¹´ä½å‰‚é‡CTæ•°æ®é›†ä¸Šï¼ŒF2Nåœ¨PSNRæ–¹é¢æ¯”é¢†å…ˆçš„è‡ªç›‘ç£å•å›¾åƒæ–¹æ³•ï¼ˆZS-N2Nï¼‰é«˜å‡º4.59 dBï¼ŒåŒæ—¶æé«˜äº†é€æ˜åº¦ã€ç”¨æˆ·æ§åˆ¶åŠ›å’Œå‚æ•°æ•ˆç‡ã€‚è¿™äº›ç‰¹ç‚¹å¯¹äºè¦æ±‚ç²¾ç¡®å’Œå¯è§£é‡Šé™å™ªçš„åŒ»å­¦åº”ç”¨æä¾›äº†å…³é”®ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ä»£ç æ¼”ç¤ºåœ¨<a target="_blank" rel="noopener" href="https://github.com/sypsyp97/Filter2Noise.git">https://github.com/sypsyp97/Filter2Noise.git</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13519v1">PDF</a> preprint</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFilter2Noiseï¼ˆF2Nï¼‰çš„å¯è§£é‡Šæ€§è‡ªç›‘ç£å•å›¾åƒå»å™ªæ¡†æ¶ã€‚å®ƒé€šè¿‡å¼•å…¥æ³¨æ„åŠ›å¼•å¯¼åŒè¾¹æ»¤æ³¢å™¨ï¼Œè‡ªé€‚åº”äºæ¯ä¸ªå™ªå£°è¾“å…¥ï¼Œå¹¶é€šè¿‡è½»é‡çº§æ¨¡å—é¢„æµ‹ç©ºé—´å˜åŒ–çš„æ»¤æ³¢å™¨å‚æ•°ï¼Œå®ç°ç”¨æˆ·å¯åœ¨è®­ç»ƒåé’ˆå¯¹ç‰¹å®šæ„Ÿå…´è¶£åŒºåŸŸè¿›è¡Œå¯è§†åŒ–å¹¶è°ƒæ•´å»å™ªæ•ˆæœã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†ä¸€ç§æ–°çš„ä¸‹é‡‡æ ·æ´—ç‰Œç­–ç•¥ï¼Œé…åˆè‡ªç›‘ç£æŸå¤±å‡½æ•°ï¼Œå°†Noise2Noiseçš„æ¦‚å¿µæ‰©å±•åˆ°å•å›¾åƒä¸Šï¼Œå¹¶è§£å†³ç©ºé—´ç›¸å…³å™ªå£°é—®é¢˜ã€‚åœ¨Mayo Clinic 2016ä½å‰‚é‡CTæ•°æ®é›†ä¸Šï¼ŒF2Nè¡¨ç°å‡ºä¼˜äºç°æœ‰è‡ªç›‘ç£å•å›¾åƒæ–¹æ³•ï¼ˆZS-N2Nï¼‰çš„ä¼˜å¼‚æ€§èƒ½ï¼Œæé«˜äº†å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰4.59 dBï¼ŒåŒæ—¶æé«˜äº†é€æ˜åº¦ã€ç”¨æˆ·æ§åˆ¶å’Œå‚æ•°æ•ˆç‡ã€‚è¿™å¯¹äºéœ€è¦ç²¾ç¡®å’Œå¯è§£é‡Šæ€§é™å™ªçš„åŒ»å­¦åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ‰æ•ˆå»å™ªåœ¨ä½å‰‚é‡CTä¸­è‡³å…³é‡è¦ï¼Œèƒ½æé«˜ç»†å¾®ç»“æ„å’Œä½å¯¹æ¯”åº¦ç—…å˜çš„è¯†åˆ«åº¦ï¼Œé˜²æ­¢è¯Šæ–­é”™è¯¯ã€‚</li>
<li>ç›‘ç£æ–¹æ³•å—é™äºé…å¯¹æ•°æ®é›†ï¼Œè‡ªç›‘ç£æ–¹æ³•åˆ™éœ€è¦å¤šå™ªå£°å›¾åƒå¹¶ä¾èµ–æ·±åº¦ç½‘ç»œï¼ˆå¦‚U-Netï¼‰ï¼Œå¯¹äºå»å™ªæœºåˆ¶æä¾›è¾ƒå°‘è§è§£ã€‚</li>
<li>æå‡ºçš„Filter2Noiseï¼ˆF2Nï¼‰æ¡†æ¶æ˜¯ä¸€ç§å¯è§£é‡Šçš„è‡ªç›‘ç£å•å›¾åƒå»å™ªæ–¹æ³•ã€‚</li>
<li>F2Né€šè¿‡æ³¨æ„åŠ›å¼•å¯¼åŒè¾¹æ»¤æ³¢å™¨è‡ªé€‚åº”äºæ¯ä¸ªå™ªå£°è¾“å…¥ï¼Œå¹¶å¼•å…¥è½»é‡çº§æ¨¡å—ä»¥é¢„æµ‹ç©ºé—´å˜åŒ–çš„æ»¤æ³¢å™¨å‚æ•°ï¼Œå®ç°ç”¨æˆ·å¯æ§çš„ç‰¹å®šåŒºåŸŸå»å™ªã€‚</li>
<li>F2Né‡‡ç”¨æ–°çš„ä¸‹é‡‡æ ·æ´—ç‰Œç­–ç•¥å’Œè‡ªç›‘ç£æŸå¤±å‡½æ•°ï¼Œæ‰©å±•Noise2Noiseæ¦‚å¿µè‡³å•å›¾åƒï¼Œè§£å†³ç©ºé—´ç›¸å…³å™ªå£°é—®é¢˜ã€‚</li>
<li>åœ¨Mayo Clinic 2016ä½å‰‚é‡CTæ•°æ®é›†ä¸Šï¼ŒF2Nç›¸æ¯”ç°æœ‰è‡ªç›‘ç£å•å›¾åƒæ–¹æ³•æé«˜äº†4.59 dB PSNRï¼ŒåŒæ—¶å¢å¼ºé€æ˜åº¦ã€ç”¨æˆ·æ§åˆ¶å’Œå‚æ•°æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13519">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c912a699fc6838925628534199c6cb10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad816a6a42b79f47c49e9babc9892252.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Learning-from-Noisy-Pseudo-labels-for-All-Weather-Land-Cover-Mapping"><a href="#Learning-from-Noisy-Pseudo-labels-for-All-Weather-Land-Cover-Mapping" class="headerlink" title="Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping"></a>Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping</h2><p><strong>Authors:Wang Liu, Zhiyu Wang, Xin Guo, Puhong Duan, Xudong Kang, Shutao Li</strong></p>
<p>Semantic segmentation of SAR images has garnered significant attention in remote sensing due to the immunity of SAR sensors to cloudy weather and light conditions. Nevertheless, SAR imagery lacks detailed information and is plagued by significant speckle noise, rendering the annotation or segmentation of SAR images a formidable task. Recent efforts have resorted to annotating paired optical-SAR images to generate pseudo-labels through the utilization of an optical image segmentation network. However, these pseudo-labels are laden with noise, leading to suboptimal performance in SAR image segmentation. In this study, we introduce a more precise method for generating pseudo-labels by incorporating semi-supervised learning alongside a novel image resolution alignment augmentation. Furthermore, we introduce a symmetric cross-entropy loss to mitigate the impact of noisy pseudo-labels. Additionally, a bag of training and testing tricks is utilized to generate better land-cover mapping results. Our experiments on the GRSS data fusion contest indicate the effectiveness of the proposed method, which achieves first place. The code is available at <a target="_blank" rel="noopener" href="https://github.com/StuLiu/DFC2025Track1.git">https://github.com/StuLiu/DFC2025Track1.git</a>. </p>
<blockquote>
<p>SARå›¾åƒçš„è¯­ä¹‰åˆ†å‰²åœ¨é¥æ„Ÿé¢†åŸŸå—åˆ°äº†å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºSARä¼ æ„Ÿå™¨ä¸å—å¤©æ°”å’Œå…‰ç…§æ¡ä»¶çš„å½±å“ã€‚ç„¶è€Œï¼ŒSARå›¾åƒç¼ºä¹è¯¦ç»†ä¿¡æ¯ï¼Œå¹¶ä¸”å—åˆ°æ–‘ç‚¹å™ªå£°çš„å›°æ‰°ï¼Œè¿™ä½¿å¾—SARå›¾åƒçš„æ ‡æ³¨æˆ–åˆ†å‰²æˆä¸ºä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚è¿‘æœŸçš„ç ”ç©¶å°è¯•å¯¹é…å¯¹çš„å…‰å­¦SARå›¾åƒè¿›è¡Œæ ‡æ³¨ï¼Œä»¥åˆ©ç”¨å…‰å­¦å›¾åƒåˆ†å‰²ç½‘ç»œç”Ÿæˆä¼ªæ ‡ç­¾ã€‚ç„¶è€Œï¼Œè¿™äº›ä¼ªæ ‡ç­¾å……æ»¡äº†å™ªå£°ï¼Œå¯¼è‡´SARå›¾åƒåˆ†å‰²æ€§èƒ½ä¸ä½³ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ›´ç²¾ç¡®çš„æ–¹æ³•ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†åŠç›‘ç£å­¦ä¹ ä»¥åŠä¸€ç§æ–°å‹å›¾åƒåˆ†è¾¨ç‡å¯¹é½å¢å¼ºæŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†å¯¹ç§°äº¤å‰ç†µæŸå¤±æ¥å‡è½»å™ªå£°ä¼ªæ ‡ç­¾çš„å½±å“ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨äº†ä¸€ç³»åˆ—è®­ç»ƒå’Œæµ‹è¯•æŠ€å·§æ¥ç”Ÿæˆæ›´å¥½çš„åœŸåœ°è¦†ç›–æ˜ å°„ç»“æœã€‚æˆ‘ä»¬åœ¨GRSSæ•°æ®èåˆç«èµ›ä¸Šçš„å®éªŒè¯æ˜äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯¥æ–¹æ³•å–å¾—äº†ç¬¬ä¸€åã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/StuLiu/DFC2025Track1.git%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/StuLiu/DFC2025Track1.gitè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13458v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>SARå›¾åƒè¯­ä¹‰åˆ†å‰²å› å…¶ä¸å—å¤©æ°”å’Œå…‰ç…§æ¡ä»¶å½±å“çš„ç‰¹æ€§è€Œå—åˆ°é¥æ„Ÿé¢†åŸŸçš„å…³æ³¨ã€‚ä½†SARå›¾åƒç¼ºä¹è¯¦ç»†ä¿¡æ¯ä¸”æ˜“å—æ–‘ç‚¹å™ªå£°å½±å“ï¼Œä½¿å¾—SARå›¾åƒçš„æ ‡æ³¨æˆ–åˆ†å‰²æˆä¸ºä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚æœ¬ç ”ç©¶é€šè¿‡ç»“åˆåŠç›‘ç£å­¦ä¹ å’Œæ–°é¢–çš„å›¾åƒåˆ†è¾¨ç‡å¯¹é½å¢å¼ºæ–¹æ³•ï¼Œæå‡ºäº†ä¸€ç§æ›´ç²¾ç¡®çš„ç”Ÿæˆä¼ªæ ‡ç­¾çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œå¼•å…¥å¯¹ç§°äº¤å‰ç†µæŸå¤±ä»¥å‡è½»å™ªå£°ä¼ªæ ‡ç­¾çš„å½±å“ï¼Œå¹¶ä½¿ç”¨ä¸€ç³»åˆ—è®­ç»ƒå’Œæµ‹è¯•æŠ€å·§æ¥ç”Ÿæˆæ›´å¥½çš„åœŸåœ°è¦†ç›–æ˜ å°„ç»“æœã€‚åœ¨GRSSæ•°æ®èåˆç«èµ›ä¸Šçš„å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯¥æ–¹æ³•å–å¾—äº†ç¬¬ä¸€åï¼Œä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SARå›¾åƒè¯­ä¹‰åˆ†å‰²åœ¨é¥æ„Ÿé¢†åŸŸå…·æœ‰é‡è¦æ€§ï¼Œå› ä¸ºå®ƒä¸å—å¤©æ°”å’Œå…‰ç…§æ¡ä»¶çš„é™åˆ¶ã€‚</li>
<li>SARå›¾åƒç¼ºä¹è¯¦ç»†ä¿¡æ¯å’Œæ˜“å—æ–‘ç‚¹å™ªå£°å½±å“ï¼Œä½¿å¾—æ ‡æ³¨å’Œåˆ†å‰²å˜å¾—å›°éš¾ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆåŠç›‘ç£å­¦ä¹ å’Œå›¾åƒåˆ†è¾¨ç‡å¯¹é½å¢å¼ºæ–¹æ³•ç”Ÿæˆæ›´ç²¾ç¡®ä¼ªæ ‡ç­¾çš„æ–¹æ³•ã€‚</li>
<li>å¼•å…¥å¯¹ç§°äº¤å‰ï¿½ï¿½ç†µæŸå¤±ä»¥å‡è½»å™ªå£°ä¼ªæ ‡ç­¾å¯¹åˆ†å‰²æ€§èƒ½çš„å½±å“ã€‚</li>
<li>ä½¿ç”¨ä¸€ç³»åˆ—è®­ç»ƒå’Œæµ‹è¯•æŠ€å·§æ¥æé«˜åœŸåœ°è¦†ç›–æ˜ å°„ç»“æœçš„å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨GRSSæ•°æ®èåˆç«èµ›ä¸Šè¿›è¡Œçš„å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å–å¾—äº†ç¬¬ä¸€åçš„å¥½æˆç»©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-17ea9b8a78f2eca84b0be4c7d9dfd8a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63db662953a11e8a6b99e5c5c07935a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-59a2af4d9ecebb9aff5a74983b70b83e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6b8aa29b3b4990f5772eb852ea23b64a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Auto-FEDUS-Autoregressive-Generative-Modeling-of-Doppler-Ultrasound-Signals-from-Fetal-Electrocardiograms"><a href="#Auto-FEDUS-Autoregressive-Generative-Modeling-of-Doppler-Ultrasound-Signals-from-Fetal-Electrocardiograms" class="headerlink" title="Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound   Signals from Fetal Electrocardiograms"></a>Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound   Signals from Fetal Electrocardiograms</h2><p><strong>Authors:Alireza Rafiei, Gari D. Clifford, Nasim Katebi</strong></p>
<p>Fetal health monitoring through one-dimensional Doppler ultrasound (DUS) signals offers a cost-effective and accessible approach that is increasingly gaining interest. Despite its potential, the development of machine learning based techniques to assess the health condition of mothers and fetuses using DUS signals remains limited. This scarcity is primarily due to the lack of extensive DUS datasets with a reliable reference for interpretation and data imbalance across different gestational ages. In response, we introduce a novel autoregressive generative model designed to map fetal electrocardiogram (FECG) signals to corresponding DUS waveforms (Auto-FEDUS). By leveraging a neural temporal network based on dilated causal convolutions that operate directly on the waveform level, the model effectively captures both short and long-range dependencies within the signals, preserving the integrity of generated data. Cross-subject experiments demonstrate that Auto-FEDUS outperforms conventional generative architectures across both time and frequency domain evaluations, producing DUS signals that closely resemble the morphology of their real counterparts. The realism of these synthesized signals was further gauged using a quality assessment model, which classified all as good quality, and a heart rate estimation model, which produced comparable results for generated and real data, with a Bland-Altman limit of 4.5 beats per minute. This advancement offers a promising solution for mitigating limited data availability and enhancing the training of DUS-based fetal models, making them more effective and generalizable. </p>
<blockquote>
<p>é€šè¿‡ä¸€ç»´å¤šæ™®å‹’è¶…å£°ï¼ˆDUSï¼‰ä¿¡å·è¿›è¡Œèƒå„¿å¥åº·ç›‘æµ‹æ˜¯ä¸€ç§æˆæœ¬æ•ˆç›Šé«˜ä¸”æ˜“äºå®æ–½çš„æ–¹æ³•ï¼Œè¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚å°½ç®¡å…¶æ½œåŠ›å·¨å¤§ï¼Œä½†åˆ©ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•è¯„ä¼°æ¯äº²å’Œèƒå„¿å¥åº·çŠ¶å†µçš„DUSä¿¡å·æŠ€æœ¯ä»ç›¸å¯¹æœ‰é™ã€‚è¿™ç§ç¼ºä¹ä¸»è¦æ˜¯ç”±äºç¼ºä¹å¤§é‡å¯é çš„DUSæ•°æ®é›†è¿›è¡Œè§£è¯»ä»¥åŠä¸åŒå­•æœŸæ•°æ®å­˜åœ¨ä¸å¹³è¡¡çš„é—®é¢˜ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„autoregressiveç”Ÿæˆæ¨¡å‹ï¼ˆAuto-FEDUSï¼‰ï¼Œæ—¨åœ¨å°†èƒå„¿å¿ƒç”µå›¾ï¼ˆFECGï¼‰ä¿¡å·æ˜ å°„åˆ°ç›¸åº”çš„DUSæ³¢å½¢ä¸Šã€‚è¯¥æ¨¡å‹åˆ©ç”¨åŸºäºè†¨èƒ€å› æœå·ç§¯çš„ç¥ç»ç½‘ç»œæ—¶åºç½‘ç»œç›´æ¥åœ¨æ³¢å½¢å±‚é¢è¿›è¡Œæ“ä½œï¼Œæœ‰æ•ˆæ•æ‰ä¿¡å·ä¸­çš„çŸ­æœŸå’Œé•¿æœŸä¾èµ–å…³ç³»ï¼Œä¿æŒç”Ÿæˆæ•°æ®çš„å®Œæ•´æ€§ã€‚è·¨ä¸»ä½“å®éªŒè¡¨æ˜ï¼Œåœ¨æ—¶é—´åŸŸå’Œé¢‘åŸŸè¯„ä¼°ä¸­ï¼ŒAuto-FEDUSå‡ä¼˜äºä¼ ç»Ÿç”Ÿæˆæ¶æ„ï¼Œäº§ç”Ÿçš„DUSä¿¡å·å½¢æ€ä¸çœŸå®ä¿¡å·éå¸¸ç›¸ä¼¼ã€‚è¿™äº›åˆæˆä¿¡å·çš„é€¼çœŸæ€§è¿›ä¸€æ­¥é€šè¿‡è´¨é‡è¯„ä¼°æ¨¡å‹è¿›è¡Œäº†è¡¡é‡ï¼Œæ‰€æœ‰ä¿¡å·å‡è¢«åˆ†ç±»ä¸ºé«˜è´¨é‡ä¿¡å·ï¼›åŒæ—¶ï¼Œå¿ƒç‡ä¼°è®¡æ¨¡å‹å¯¹ç”Ÿæˆæ•°æ®å’ŒçœŸå®æ•°æ®äº§ç”Ÿçš„ç»“æœç›¸å½“ï¼ŒBland-Altmané™å€¼ä¸ºæ¯åˆ†é’Ÿ4.5æ¬¡å¿ƒè·³ã€‚è¿™ä¸€è¿›å±•ä¸ºè§£å†³æ•°æ®æœ‰é™çš„é—®é¢˜æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶æœ‰æœ›å¢å¼ºåŸºäºDUSçš„èƒå„¿æ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼Œä½¿å…¶æ›´å…·æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13233v1">PDF</a> AAAI 2025 Workshop on Large Language Models and Generative AI for   Health</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§é€šè¿‡ä¸€ç»´å¤šæ™®å‹’è¶…å£°ï¼ˆDUSï¼‰ä¿¡å·è¿›è¡Œèƒå„¿å¥åº·ç›‘æµ‹çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰æˆæœ¬æ•ˆç›Šé«˜ã€æ˜“äºè·å–çš„ç‰¹ç‚¹ï¼Œè¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¤§é‡çš„DUSæ•°æ®é›†å’Œå¯é çš„è§£é‡Šå‚è€ƒä»¥åŠä¸åŒå­•æœŸæ•°æ®çš„å¤±è¡¡ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•è¯„ä¼°æ¯å©´å¥åº·çŠ¶å†µçš„æŠ€æœ¯å‘å±•å—åˆ°é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§æ–°å‹çš„è‡ªåŠ¨å›å½’ç”Ÿæˆæ¨¡å‹Auto-FEDUSï¼Œç”¨äºå°†èƒå„¿å¿ƒç”µå›¾ï¼ˆFECGï¼‰ä¿¡å·æ˜ å°„åˆ°ç›¸åº”çš„DUSæ³¢å½¢ä¸Šã€‚è¯¥æ¨¡å‹åˆ©ç”¨åŸºäºæ‰©å¼ å› æœå·ç§¯çš„ç¥ç»ç½‘ç»œæ—¶é—´ç½‘ç»œç›´æ¥åœ¨æ³¢å½¢çº§åˆ«è¿›è¡Œæ“ä½œï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰ä¿¡å·ä¸­çš„çŸ­æœŸå’Œé•¿æœŸä¾èµ–æ€§ï¼Œä¿æŒç”Ÿæˆæ•°æ®çš„å®Œæ•´æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒAuto-FEDUSåœ¨æ—¶é—´åŸŸå’Œé¢‘åŸŸè¯„ä¼°æ–¹é¢éƒ½ä¼˜äºä¼ ç»Ÿç”Ÿæˆæ¶æ„ï¼Œç”Ÿæˆçš„DUSä¿¡å·ä¸å®é™…ä¿¡å·çš„å½¢æ€éå¸¸ç›¸ä¼¼ã€‚è¯¥ç ”ç©¶çš„è¿›å±•ä¸ºè§£å†³æ•°æ®æœ‰é™æ€§é—®é¢˜æä¾›äº†ä¸€ä¸ªæœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶æœ‰åŠ©äºæé«˜åŸºäºDUSçš„èƒå„¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸€ç»´å¤šæ™®å‹’è¶…å£°ï¼ˆDUSï¼‰ä¿¡å·ç”¨äºèƒå„¿å¥åº·ç›‘æµ‹æ˜¯ä¸€ç§ç»æµã€æ–¹ä¾¿çš„æ–¹æ³•ï¼Œå¤‡å—å…³æ³¨ã€‚</li>
<li>åŸºäºæœºå™¨å­¦ä¹ çš„DUSæŠ€æœ¯è¯„ä¼°æ¯å©´å¥åº·çŠ¶å†µä»å¤„äºèµ·æ­¥é˜¶æ®µã€‚</li>
<li>ç¼ºä¹å¤§è§„æ¨¡çš„DUSæ•°æ®é›†ä»¥åŠå¯é çš„æ•°æ®è§£é‡Šå’Œä¸å¹³è¡¡çš„å­•æœŸæ•°æ®é™åˆ¶äº†æŠ€æœ¯å‘å±•ã€‚</li>
<li>å¼•å…¥æ–°å‹è‡ªåŠ¨å›å½’ç”Ÿæˆæ¨¡å‹Auto-FEDUSï¼Œå°†èƒå„¿å¿ƒç”µå›¾ï¼ˆFECGï¼‰ä¿¡å·æ˜ å°„åˆ°DUSæ³¢å½¢ä¸Šã€‚</li>
<li>Auto-FEDUSåˆ©ç”¨ç¥ç»ç½‘ç»œæ—¶é—´ç½‘ç»œæ•æ‰ä¿¡å·ä¸­çš„çŸ­æœŸå’Œé•¿æœŸä¾èµ–æ€§ã€‚</li>
<li>Auto-FEDUSç”Ÿæˆçš„DUSä¿¡å·ä¸å®é™…ä¿¡å·çš„å½¢æ€ç›¸ä¼¼ï¼Œé€šè¿‡è´¨é‡è¯„ä¼°æ¨¡å‹å’Œå¿ƒç‡ä¼°è®¡æ¨¡å‹éªŒè¯å…¶çœŸå®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13233">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6ecbf5559718b1ced1a3fd7979c139fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b55f9540011050a45778f21566598fe3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-191bcb12cf1c95ab982d327d5d51ae75.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-790c00379ae68c7b2a3cf9c9d8d74d73.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-09e298cc99ba32448c22620eb2482a3a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficient-Brain-Tumor-Segmentation-Using-a-Dual-Decoder-3D-U-Net-with-Attention-Gates-DDUNet"><a href="#Efficient-Brain-Tumor-Segmentation-Using-a-Dual-Decoder-3D-U-Net-with-Attention-Gates-DDUNet" class="headerlink" title="Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with   Attention Gates (DDUNet)"></a>Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with   Attention Gates (DDUNet)</h2><p><strong>Authors:Mohammad Mahdi Danesh Pajouh</strong></p>
<p>Cancer remains one of the leading causes of mortality worldwide, and among its many forms, brain tumors are particularly notorious due to their aggressive nature and the critical challenges involved in early diagnosis. Recent advances in artificial intelligence have shown great promise in assisting medical professionals with precise tumor segmentation, a key step in timely diagnosis and treatment planning. However, many state-of-the-art segmentation methods require extensive computational resources and prolonged training times, limiting their practical application in resource-constrained settings. In this work, we present a novel dual-decoder U-Net architecture enhanced with attention-gated skip connections, designed specifically for brain tumor segmentation from MRI scans. Our approach balances efficiency and accuracy by achieving competitive segmentation performance while significantly reducing training demands. Evaluated on the BraTS 2020 dataset, the proposed model achieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core (TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several commonly used U-Net variants. Our model demonstrates that high-quality brain tumor segmentation is attainable even under limited computational resources, thereby offering a viable solution for researchers and clinicians operating with modest hardware. This resource-efficient model has the potential to improve early detection and diagnosis of brain tumors, ultimately contributing to better patient outcomes </p>
<blockquote>
<p>ç™Œç—‡ä»ç„¶æ˜¯å…¨çƒä¸»è¦çš„æ­»äº¡åŸå› ä¹‹ä¸€ï¼Œè€Œåœ¨å…¶å¤šç§å½¢æ€ä¸­ï¼Œè„‘è‚¿ç˜¤å› å…¶ä¾µè¢­æ€§ä»¥åŠæ—©æœŸè¯Šæ–­çš„è‰°å·¨æŒ‘æˆ˜è€Œç‰¹åˆ«æ¶åæ˜­å½°ã€‚äººå·¥æ™ºèƒ½é¢†åŸŸçš„æœ€æ–°è¿›å±•åœ¨ååŠ©åŒ»ç–—ä¸“ä¸šäººå£«è¿›è¡Œç²¾ç¡®çš„è‚¿ç˜¤åˆ†å‰²æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œè¿™æ˜¯åŠæ—¶è¯Šæ–­å’Œæ²»ç–—è®¡åˆ’çš„å…³é”®æ­¥éª¤ã€‚ç„¶è€Œï¼Œè®¸å¤šæœ€å…ˆè¿›çš„åˆ†å‰²æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œé•¿æ—¶é—´çš„è®­ç»ƒï¼Œè¿™åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­é™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŒè§£ç å™¨U-Netæ¶æ„ï¼Œè¯¥æ¶æ„å¢å¼ºäº†æ³¨æ„åŠ›é—¨æ§è·³è·ƒè¿æ¥ï¼Œä¸“é—¨ç”¨äºä»MRIæ‰«æä¸­åˆ†å‰²è„‘è‚¿ç˜¤ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å®ç°ç«äº‰æ€§çš„åˆ†å‰²æ€§èƒ½åŒæ—¶æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡æ¥å¹³è¡¡æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åœ¨BraTS 2020æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæ‰€æå‡ºæ¨¡å‹åœ¨50ä¸ªå‘¨æœŸå†…å®ç°äº†æ•´ä½“è‚¿ç˜¤ï¼ˆWTï¼‰çš„Diceå¾—åˆ†ä¸º85.06%ï¼Œè‚¿ç˜¤æ ¸å¿ƒï¼ˆTCï¼‰çš„å¾—åˆ†ä¸º80.61%ï¼Œå¢å¼ºè‚¿ç˜¤ï¼ˆETï¼‰çš„å¾—åˆ†ä¸º71.26%ï¼Œè¶…è¿‡äº†å¸¸ç”¨çš„ä¸€äº›U-Netå˜ä½“ã€‚æˆ‘ä»¬çš„æ¨¡å‹è¯æ˜äº†å³ä½¿åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹ä¹Ÿèƒ½å®ç°é«˜è´¨é‡çš„è„‘è‚¿ç˜¤åˆ†å‰²ï¼Œä»è€Œä¸ºä½¿ç”¨é€‚åº¦ç¡¬ä»¶çš„ç ”ç©¶äººå‘˜å’Œä¸´åºŠåŒ»ç”Ÿæä¾›äº†åˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§èµ„æºé«˜æ•ˆå‹çš„æ¨¡å‹æœ‰æ½œåŠ›æ”¹å–„è„‘è‚¿ç˜¤çš„æ—©æœŸæ£€æµ‹å’Œè¯Šæ–­ï¼Œæœ€ç»ˆä¸ºæ‚£è€…å¸¦æ¥æ›´å¥½çš„æ²»ç–—æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13200v1">PDF</a> </p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½åœ¨è„‘è‚¿ç˜¤åˆ†å‰²ä¸Šå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæœ‰åŠ©åŒ»å­¦ä¸“ä¸šäººå£«è¿›è¡Œç²¾ç¡®è‚¿ç˜¤åˆ†å‰²ï¼Œä½†ç°æœ‰æ–¹æ³•è®¡ç®—èµ„æºéœ€æ±‚å¤§ã€è®­ç»ƒæ—¶é—´é•¿ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ–°å‹åŒè§£ç å™¨U-Netæ¶æ„ï¼Œç»“åˆæ³¨æ„åŠ›é—¨æ§è·³è¿‡è¿æ¥ï¼Œä¸“ä¸ºä»MRIæ‰«æä¸­åˆ†å‰²è„‘è‚¿ç˜¤è€Œè®¾è®¡ã€‚è¯¥æ¨¡å‹åœ¨BraTS 2020æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œæ˜¾è‘—å‡å°‘è®­ç»ƒéœ€æ±‚ï¼Œå¹³è¡¡äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä¸ºæœ‰é™èµ„æºä¸‹ç ”ç©¶è€…ä¸ä¸´åºŠåŒ»ç”Ÿæä¾›å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç™Œç—‡ä»æ˜¯å…¨çƒä¸»è¦æ­»äº¡åŸå› ä¹‹ä¸€ï¼Œè„‘è‚¿ç˜¤å› å…¶ä¾µè¢­æ€§å’Œæ—©æœŸè¯Šæ–­çš„æŒ‘æˆ˜æ€§è€Œå¤‡å—å…³æ³¨ã€‚</li>
<li>äººå·¥æ™ºèƒ½åœ¨è„‘è‚¿ç˜¤åˆ†å‰²æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæœ‰åŠ©äºåŒ»å­¦ä¸“ä¸šäººå£«è¿›è¡Œç²¾ç¡®è¯Šæ–­ã€‚</li>
<li>ç°æœ‰åˆ†å‰²æ–¹æ³•è®¡ç®—èµ„æºéœ€æ±‚å¤§ã€è®­ç»ƒæ—¶é—´é•¿ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºæœ‰é™ç¯å¢ƒä¸‹çš„åº”ç”¨ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹åŒè§£ç å™¨U-Netæ¶æ„ï¼Œç»“åˆæ³¨æ„åŠ›é—¨æ§è·³è¿‡è¿æ¥ï¼Œä¸“ä¸ºè„‘è‚¿ç˜¤åˆ†å‰²è®¾è®¡ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨BraTS 2020æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå–å¾—äº†è¾ƒé«˜çš„åˆ†å‰²å‡†ç¡®æ€§ã€‚</li>
<li>æ¨¡å‹åœ¨ä»…50ä¸ªå‘¨æœŸï¼ˆepochsï¼‰å†…è¾¾åˆ°äº†é«˜Diceå¾—åˆ†ï¼Œå¯¹æ•´ä½“è‚¿ç˜¤ã€è‚¿ç˜¤æ ¸å¿ƒå’Œå¢å¼ºè‚¿ç˜¤çš„åˆ†å‰²å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°äº†85.06%ã€80.61%å’Œ71.26%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-988ef8b7dcf2a533006c3c8206376ec6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70d55ba7eb7c4a9059293fdacd537f26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73f28ba88fc4788b3333e2a6c933538a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Towards-Cardiac-MRI-Foundation-Models-Comprehensive-Visual-Tabular-Representations-for-Whole-Heart-Assessment-and-Beyond"><a href="#Towards-Cardiac-MRI-Foundation-Models-Comprehensive-Visual-Tabular-Representations-for-Whole-Heart-Assessment-and-Beyond" class="headerlink" title="Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular   Representations for Whole-Heart Assessment and Beyond"></a>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular   Representations for Whole-Heart Assessment and Beyond</h2><p><strong>Authors:Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan</strong></p>
<p>Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individualâ€™s disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis. </p>
<blockquote>
<p>å¿ƒè„ç£å…±æŒ¯æˆåƒï¼ˆCardiac magnetic resonance imagingï¼Œç®€ç§°CMRï¼‰æ˜¯éä¾µå…¥æ€§å¿ƒè„è¯„ä¼°çš„é‡‘æ ‡å‡†ï¼Œèƒ½å¤Ÿä¸°å¯Œåœ°å±•ç°å¿ƒè„è§£å‰–å’Œç”Ÿç†çš„æ—¶ç©ºè§†å›¾ã€‚å·²çŸ¥æ‚£è€…å±‚é¢çš„å¥åº·å› ç´ ï¼Œå¦‚äººå£ç»Ÿè®¡å­¦ç‰¹å¾ã€æ–°é™ˆä»£è°¢å’Œç”Ÿæ´»æ–¹å¼ï¼Œä¼šå¯¹å¿ƒè¡€ç®¡å¥åº·å’Œç–¾ç—…é£é™©äº§ç”Ÿé‡å¤§å½±å“ï¼Œä½†ä»…é CMRæ— æ³•è·å–è¿™äº›ä¿¡æ¯ã€‚ä¸ºäº†å…¨é¢äº†è§£å¿ƒè„å¥åº·å¹¶èƒ½å¤Ÿå¯¹ä¸ªäººçš„ç–¾ç—…é£é™©è¿›è¡Œæœ€ä½³è§£è¯»ï¼Œå¿…é¡»åœ¨ç»¼åˆæ¡†æ¶å†…å…±åŒåˆ©ç”¨CMRå’Œæ‚£è€…å±‚é¢çš„å› ç´ ã€‚æœ€è¿‘çš„å¤šæ¨¡æ€æ–¹æ³•å·²ç»å¼€å§‹å¼¥åˆè¿™ä¸€å·®è·ï¼Œä½†å®ƒä»¬å¾€å¾€ä¾èµ–äºæœ‰é™çš„æ—¶ç©ºæ•°æ®ï¼Œå¹¶ä¸“æ³¨äºå­¤ç«‹çš„ä¸´åºŠä»»åŠ¡ï¼Œä»è€Œé˜»ç¢äº†å¿ƒè„å¥åº·è¯„ä¼°çš„ç»¼åˆè¡¨ç°çš„å‘å±•ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ViTaï¼Œè¿™æ˜¯æœç€åŸºç¡€æ¨¡å‹è¿ˆå‡ºçš„ä¸€æ­¥ï¼Œå®ƒæä¾›äº†å¿ƒè„çš„å…¨é¢è¡¨å¾å’Œå¯¹ä¸ªä½“ç–¾ç—…é£é™©çš„ç²¾ç¡®è§£è¯»ã€‚ViTaåˆ©ç”¨æ¥è‡ª42,000åè‹±å›½ç”Ÿç‰©é“¶è¡Œå‚ä¸è€…çš„æ•°æ®ï¼Œèåˆäº†çŸ­è½´å’Œé•¿è½´çš„3D+Tç”µå½±å †æ ˆï¼Œèƒ½å¤Ÿå®Œæ•´æ•æ‰å¿ƒè„å‘¨æœŸã€‚ç„¶åï¼Œè¿™äº›æˆåƒæ•°æ®ä¸è¯¦ç»†çš„è¡¨æ ¼æ‚£è€…å±‚é¢å› ç´ ç›¸ç»“åˆï¼Œæä¾›æƒ…å¢ƒæ„ŸçŸ¥çš„è§è§£ã€‚è¿™ç§å¤šæ¨¡æ€èŒƒå¼æ”¯æŒå¹¿æ³›çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¿ƒè„è¡¨å‹é¢„æµ‹ã€ç”Ÿç†ç‰¹å¾é¢„æµ‹ã€åˆ†å‰²ä»¥åŠå•ä¸€ç»Ÿä¸€æ¡†æ¶å†…çš„ä»£è°¢ç–¾ç—…åˆ†ç±»ç­‰ã€‚é€šè¿‡å­¦ä¹ ä¸ä¸°å¯Œçš„æˆåƒç‰¹å¾å’Œæ‚£è€…ä¸Šä¸‹æ–‡ç›¸å…³çš„å…±äº«æ½œåœ¨è¡¨å¾ï¼ŒViTaè¶…è¶Šäº†ä¼ ç»Ÿçš„ä»»åŠ¡ç‰¹å®šæ¨¡å‹ï¼Œæœç€å…·æœ‰æ‚£è€…ç‰¹å¼‚æ€§çš„å¿ƒè„å¥åº·é€šç”¨ç†è§£çš„æ–¹å‘å‘å±•ï¼Œè¿™çªæ˜¾äº†å…¶åœ¨å¿ƒè„åˆ†æçš„ä¸´åºŠå®ç”¨æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13037v2">PDF</a> </p>
<p><strong>Summary</strong><br>     å¿ƒè„ç£å…±æŒ¯æˆåƒåœ¨éä¾µå…¥æ€§å¿ƒè„è¯„ä¼°ä¸­æ˜¯é‡‘æ ‡å‡†ï¼Œä½†æ— æ³•è·å–æ‚£è€…çº§åˆ«çš„å¥åº·å› ç´ ï¼ˆå¦‚äººå£ç»Ÿè®¡ã€ä»£è°¢å’Œç”Ÿæ´»æ–¹å¼ç­‰ï¼‰ã€‚ä¸ºäº†å…¨é¢äº†è§£å¿ƒè„å¥åº·å’Œè§£é‡Šä¸ªä½“ç–¾ç—…é£é™©ï¼Œå¿…é¡»è”åˆåˆ©ç”¨å¿ƒè„ç£å…±æŒ¯æˆåƒå’Œæ‚£è€…çº§åˆ«å› ç´ ã€‚ViTaæ¨¡å‹é€šè¿‡æ•´åˆå¿ƒè„ç£å…±æŒ¯æˆåƒæ•°æ®å’Œæ‚£è€…çº§åˆ«å› ç´ ï¼Œå®ç°äº†å¿ƒè„çš„å…¨é¢è¡¨ç¤ºå’Œä¸ªä½“ç–¾ç—…é£é™©çš„ç²¾ç¡®è§£é‡Šã€‚è¯¥æ¨¡å‹æ”¯æŒå¹¿æ³›çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¿ƒè„è¡¨å‹é¢„æµ‹ã€ç”Ÿç†ç‰¹å¾é¢„æµ‹ã€åˆ†å‰²å’Œå¿ƒè„ä»£è°¢ç–¾ç—…çš„åˆ†ç±»ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¿ƒè„ç£å…±æŒ¯æˆåƒåœ¨éä¾µå…¥æ€§å¿ƒè„è¯„ä¼°ä¸­å…·æœ‰é‡è¦åœ°ä½ï¼Œä½†ç¼ºä¹å¯¹æ‚£è€…çº§åˆ«å› ç´ çš„æ•æ‰ã€‚</li>
<li>æ‚£è€…çº§åˆ«çš„å¥åº·å› ç´ ï¼Œå¦‚äººå£ç»Ÿè®¡ã€ä»£è°¢å’Œç”Ÿæ´»æ–¹å¼ï¼Œå¯¹å¿ƒè¡€ç®¡å¥åº·æœ‰é‡è¦å½±å“ã€‚</li>
<li>ViTaæ¨¡å‹æ•´åˆäº†å¿ƒè„ç£å…±æŒ¯æˆåƒæ•°æ®å’Œæ‚£è€…çº§åˆ«å› ç´ ï¼Œä¸ºå¿ƒè„å¥åº·æä¾›äº†å…¨é¢çš„è¡¨ç¤ºã€‚</li>
<li>ViTaæ¨¡å‹åˆ©ç”¨å¤šç»´æ—¶ç©ºæ•°æ®æ”¯æŒå¹¿æ³›çš„ä¸‹æ¸¸ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¿ƒè„è¡¨å‹å’Œç”Ÿç†ç‰¹å¾é¢„æµ‹ç­‰ã€‚</li>
<li>è¯¥æ¨¡å‹å®ç°äº†ä»ä¼ ç»Ÿçš„ä»»åŠ¡ç‰¹å®šæ¨¡å‹å‘é€šç”¨æ‚£è€…ç‰¹å®šç†è§£å¿ƒè„çš„è½¬åŒ–ã€‚</li>
<li>ViTaæ¨¡å‹çš„æ½œåŠ›åœ¨äºæé«˜å¿ƒè„åˆ†æçš„ä¸´åºŠå®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13037">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f92e8639c8da09d32be8ff4c16497785.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e4d92fbcd48897fc9c621cb46f4b9bf.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="JWSTâ€™s-little-red-dots-an-emerging-population-of-young-low-mass-AGN-cocooned-in-dense-ionized-gas"><a href="#JWSTâ€™s-little-red-dots-an-emerging-population-of-young-low-mass-AGN-cocooned-in-dense-ionized-gas" class="headerlink" title="JWSTâ€™s little red dots: an emerging population of young, low-mass AGN   cocooned in dense ionized gas"></a>JWSTâ€™s little red dots: an emerging population of young, low-mass AGN   cocooned in dense ionized gas</h2><p><strong>Authors:V. Rusakov, D. Watson, G. P. Nikopoulos, G. Brammer, R. Gottumukkala, T. Harvey, K. E. Heintz, R. D. Nielsen, S. A. Sim, A. Sneppen, A. P. Vijayan, N. Adams, D. Austin, C. J. Conselice, C. M. Goolsby, S. Toft, J. Witstok</strong></p>
<p>JWST has uncovered large numbers of compact galaxies at high redshift with broad hydrogen&#x2F;helium lines. These include the enigmatic population known as â€œlittle red dotsâ€ (LRDs). Their nature is debated, but they are thought to be powered by supermassive black holes (SMBHs) or intense star formation. They exhibit unusual properties for SMBHs, such as black holes that are overmassive for their host galaxies and extremely weak X-ray and radio emission. Using the highest-quality JWST spectra, we show here that the lines are broadened by electron scattering with a narrow intrinsic line core. The data require high electron column densities and compact sizes (light days), which, when coupled with their high luminosities can only be explained by SMBH accretion. The narrow intrinsic cores of the lines imply upper limits on the black hole masses of $10^{5-7}$ $M_{\odot}$, two orders of magnitude lower than previous estimates. These are among the lowest mass SMBHs known at high redshift and suggest that this is a population of young, rapidly growing SMBHs. They are enshrouded in a dense cocoon of ionized gas, probably related to their youth, from which they are accreting close to the Eddington limit. Reprocessed nebular emission from the dense cocoon dominates the optical spectrum, explaining most LRD spectral characteristics and helping to suppress radio and X-ray emission. </p>
<blockquote>
<p>JWSTæ­ç¤ºäº†å¤§é‡é«˜çº¢ç§»çš„ç´§å‡‘æ˜Ÿç³»ï¼Œå…·æœ‰å¹¿æ³›çš„æ°¢&#x2F;æ°¦çº¿ã€‚å…¶ä¸­åŒ…æ‹¬è¢«ç§°ä¸ºâ€œå°çº¢ç‚¹â€ï¼ˆLRDsï¼‰çš„ç¥ç§˜ç¾¤ä½“ã€‚å®ƒä»¬çš„æœ¬è´¨å°šå­˜äº‰è®®ï¼Œä½†æ®è®¤ä¸ºæ˜¯ç”±è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHsï¼‰æˆ–å¼ºçƒˆçš„æ’æ˜Ÿå½¢æˆæ‰€é©±åŠ¨çš„ã€‚å®ƒä»¬å±•ç°å‡ºSMBHsçš„ä¸å¯»å¸¸ç‰¹æ€§ï¼Œä¾‹å¦‚å®¿ä¸»æ˜Ÿç³»çš„è¶…å¤§è´¨é‡é»‘æ´å’Œæå…¶å¾®å¼±çš„Xå°„çº¿å’Œæ— çº¿ç”µè¾å°„ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨é«˜è´¨é‡çš„JWSTå…‰è°±æ˜¾ç¤ºï¼Œè¿™äº›çº¿é€šè¿‡ç”µå­æ•£å°„è€Œå±•å®½ï¼Œå…·æœ‰ç‹­çª„çš„å†…åœ¨çº¿èŠ¯ã€‚æ•°æ®éœ€è¦é«˜ç”µå­æŸ±å¯†åº¦å’Œç´§å‡‘å¤§å°ï¼ˆå…‰æ—¥ï¼‰ï¼Œå½“ä¸å®ƒä»¬çš„é«˜å…‰åº¦ç›¸ç»“åˆæ—¶ï¼Œåªèƒ½ç”±SMBHå¸ç§¯æ¥è§£é‡Šã€‚çº¿æ¡çš„ç‹­çª„å†…åœ¨æ ¸å¿ƒæš—ç¤ºé»‘æ´è´¨é‡çš„ä¸Šé™ä¸º$10^{5-7}$ $M_{\odot}$ï¼Œæ¯”å…ˆå‰çš„ä¼°è®¡ä½ä¸¤ä¸ªæ•°é‡çº§ã€‚è¿™äº›æ˜¯åœ¨é«˜çº¢ç§»å¤„å·²çŸ¥çš„æœ€ä½è´¨é‡SMBHsï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ç¾¤å¹´è½»ä¸”å¿«é€Ÿç”Ÿé•¿çš„SMBHsã€‚å®ƒä»¬è¢«å¯†é›†çš„ç¦»å­åŒ–æ°”ä½“æ–—ç¯·æ‰€åŒ…å›´ï¼Œå¯èƒ½ä¸å®ƒä»¬çš„å¹´è½»æœ‰å…³ï¼Œå®ƒä»¬æ­£åœ¨æ¥è¿‘çˆ±ä¸é¡¿æé™è¿›è¡Œå¸ç§¯ã€‚æ¥è‡ªå¯†é›†æ–—ç¯·çš„å†åŠ å·¥æ˜Ÿäº‘å‘å°„ç‰©ä¸»å¯¼äº†å…‰å­¦å…‰è°±ï¼Œè§£é‡Šäº†å¤§å¤šæ•°LRDå…‰è°±ç‰¹å¾å¹¶æœ‰åŠ©äºæŠ‘åˆ¶æ— çº¿ç”µå’ŒXå°„çº¿è¾å°„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.16595v3">PDF</a> 46 pages, 25 figures, 4 tables, submitted to Nature. Updated   spectroscopic data ID convention</p>
<p><strong>Summary</strong></p>
<p>JWSTå‘ç°å¤§é‡é«˜çº¢ç§»å¤„çš„ç´§å‡‘æ˜Ÿç³»ï¼Œå…·æœ‰å®½é˜”çš„æ°¢&#x2F;æ°¦çº¿ï¼ŒåŒ…æ‹¬è¢«ç§°ä¸ºâ€œå°çº¢ç‚¹â€ï¼ˆLRDsï¼‰çš„ç¥ç§˜ç¾¤ä½“ã€‚å®ƒä»¬å¯èƒ½ç”±è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHsï¼‰æˆ–å¼ºçƒˆçš„æ’æ˜Ÿå½¢æˆæ‰€é©±åŠ¨ï¼Œå±•ç°å‡ºSMBHsçš„ä¸å¯»å¸¸ç‰¹æ€§ï¼Œå¦‚ç›¸å¯¹äºå®¿ä¸»æ˜Ÿç³»è¿‡äºå·¨å¤§çš„é»‘æ´ï¼Œä»¥åŠæå¼±çš„Xå°„çº¿å’Œæ— çº¿ç”µè¾å°„ã€‚åˆ©ç”¨JWSTæœ€é«˜è´¨é‡çš„å…‰è°±æ•°æ®ï¼Œæ˜¾ç¤ºè¿™äº›çº¿è·¯æ˜¯ç”±ç”µå­æ•£å°„æ‰€åŠ å®½ï¼Œå…·æœ‰ç‹­çª„çš„å†…åœ¨çº¿èŠ¯ã€‚æ•°æ®éœ€è¦é«˜ç”µå­æŸ±å¯†åº¦å’Œç´§å‡‘å¤§å°ï¼ˆå…‰æ—¥ï¼‰ï¼Œå½“ä¸å®ƒä»¬çš„é«˜å…‰åº¦ç›¸ç»“åˆæ—¶ï¼Œåªèƒ½ç”±SMBHå¸ç§¯æ¥è§£é‡Šã€‚ç‹­çª„çš„å†…åœ¨çº¿èŠ¯å¯¹é»‘æ´è´¨é‡è®¾å®šäº†ä¸Šé™ï¼Œä¸º$10^{5-7}$ $M_{\odot}$ï¼Œæ¯”ä¹‹å‰ä¼°è®¡ä½ä¸¤ä¸ªæ•°é‡çº§ã€‚å®ƒä»¬æ˜¯åœ¨é«˜çº¢ç§»å¤„å·²çŸ¥è´¨é‡æœ€ä½çš„SMBHsä¹‹ä¸€ï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ç¾¤å¹´è½»çš„ã€å¿«é€Ÿç”Ÿé•¿çš„SMBHsã€‚å®ƒä»¬è¢«å¯†é›†çš„ç¦»å­åŒ–æ°”ä½“åŒ…å›´ï¼Œå¯èƒ½ä¸å®ƒä»¬çš„å¹´è½»æœ‰å…³ï¼Œæ­£åœ¨æ¥è¿‘çˆ±ä¸é¡¿æé™è¿›è¡Œå¸ç§¯ã€‚é‡æ–°åŠ å·¥çš„æ˜Ÿäº‘å‘å°„ä»å¯†é›†çš„åŒ…å±‚ä¸­ä¸»å¯¼äº†å…‰å­¦å…‰è°±ï¼Œè§£é‡Šäº†å¤§å¤šæ•°LRDå…‰è°±ç‰¹å¾ï¼Œå¹¶æœ‰åŠ©äºæŠ‘åˆ¶æ— çº¿ç”µå’ŒXå°„çº¿è¾å°„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>JWSTåœ¨é«˜çº¢ç§»å¤„å‘ç°äº†å¤§é‡ç´§å‡‘æ˜Ÿç³»ï¼Œå…¶ä¸­å«æœ‰â€œå°çº¢ç‚¹â€ï¼ˆLRDsï¼‰ç­‰ç¥ç§˜ç¾¤ä½“ã€‚</li>
<li>LRDså¯èƒ½ç”±è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHsï¼‰æˆ–å¼ºçƒˆçš„æ’æ˜Ÿå½¢æˆæ‰€é©±åŠ¨ã€‚</li>
<li>SMBHså±•ç°å‡ºä¸åŒäºå¸¸è§„çš„ç‰¹æ€§ï¼Œå¦‚ç›¸å¯¹å®¿ä¸»æ˜Ÿç³»è¿‡äºå·¨å¤§å’Œå¼±Xå°„çº¿ã€æ— çº¿ç”µè¾å°„ã€‚</li>
<li>é«˜è´¨é‡çš„JWSTå…‰è°±æ•°æ®æ˜¾ç¤ºï¼Œçº¿è·¯å› ç”µå­æ•£å°„è€ŒåŠ å®½ï¼Œå…·æœ‰ç‹­çª„çš„å†…åœ¨çº¿èŠ¯ã€‚</li>
<li>éœ€è¦é«˜ç”µå­æŸ±å¯†åº¦å’Œç´§å‡‘å¤§å°æ¥è§£é‡Šæ•°æ®ï¼Œè¿™æš—ç¤ºäº†SMBHå¸ç§¯çš„å¯èƒ½æ€§ã€‚</li>
<li>ç‹­çª„çš„å†…åœ¨çº¿èŠ¯è¡¨æ˜é»‘æ´è´¨é‡ä¸Šé™è¾ƒä½ï¼Œè¯´æ˜è¿™äº›SMBHså¯èƒ½å¹´è½»ä¸”æ­£åœ¨è¿…é€Ÿå¢é•¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.16595">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f650ba3c9ce8c2f6d1a65c88263b035.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-670fdc017abcea6ce452cc8cf850829c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d0084f54add418e33dd07f4ed3e2f61.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2d9830d444922ad1976caaafac8ab071.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-Self-supervised-Contrastive-Learning-for-Multimodal-Text-Image-Analysis"><a href="#A-Survey-on-Self-supervised-Contrastive-Learning-for-Multimodal-Text-Image-Analysis" class="headerlink" title="A Survey on Self-supervised Contrastive Learning for Multimodal   Text-Image Analysis"></a>A Survey on Self-supervised Contrastive Learning for Multimodal   Text-Image Analysis</h2><p><strong>Authors:Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif</strong></p>
<p>Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of â€œpositiveâ€ and â€œnegativeâ€ samples, where positive pairs (e.g., variation of the same image&#x2F;object) are brought together in the embedding space, and negative pairs (e.g., views from different images&#x2F;objects) are pushed farther away. This methodology has shown significant improvements in image understanding and image text analysis without much reliance on labeled data. In this paper, we comprehensively discuss the terminologies, recent developments and applications of contrastive learning with respect to text-image models. Specifically, we provide an overview of the approaches of contrastive learning in text-image models in recent years. Secondly, we categorize the approaches based on different model structures. Thirdly, we further introduce and discuss the latest advances of the techniques used in the process such as pretext tasks for both images and text, architectural structures, and key trends. Lastly, we discuss the recent state-of-art applications of self-supervised contrastive learning Text-Image based models. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡å­¦ä¹ æ½œåœ¨çš„æ¨¡å¼å¹¶ä»æ— æ ‡ç­¾æ•°æ®ä¸­æå–è¾¨åˆ«ç‰¹å¾ï¼Œä»è€Œç”Ÿæˆéšå¼æ ‡ç­¾ï¼Œè€Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚å¯¹æ¯”å­¦ä¹ å¼•å…¥äº†â€œæ­£æ ·æœ¬â€å’Œâ€œè´Ÿæ ·æœ¬â€çš„æ¦‚å¿µï¼Œå…¶ä¸­æ­£æ ·æœ¬å¯¹ï¼ˆä¾‹å¦‚ï¼ŒåŒä¸€å›¾åƒ&#x2F;å¯¹è±¡çš„å˜ä½“ï¼‰è¢«èšé›†åœ¨åµŒå…¥ç©ºé—´ä¸­ï¼Œè€Œè´Ÿæ ·æœ¬å¯¹ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ªä¸åŒå›¾åƒ&#x2F;å¯¹è±¡çš„è§†å›¾ï¼‰åˆ™è¢«æ¨å¼€ã€‚è¿™ç§æ–¹æ³•åœ¨å›¾åƒç†è§£å’Œå›¾åƒæ–‡æœ¬åˆ†ææ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè€Œä¸”ä¸éœ€è¦å¤§é‡ä¾èµ–æ ‡æ³¨æ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å…¨é¢è®¨è®ºäº†ä¸æ–‡æœ¬-å›¾åƒæ¨¡å‹ç›¸å…³çš„å¯¹æ¯”å­¦ä¹ çš„æœ¯è¯­ã€æœ€æ–°å‘å±•ä»¥åŠåº”ç”¨ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬æ¦‚è¿°äº†è¿‘å¹´æ¥æ–‡æœ¬-å›¾åƒæ¨¡å‹ä¸­å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ ¹æ®ä¸åŒçš„æ¨¡å‹ç»“æ„å¯¹æ–¹æ³•è¿›è¡Œäº†åˆ†ç±»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†è®¨è®ºäº†åœ¨è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æœ€æ–°æŠ€æœ¯çš„è¿›å±•ï¼Œä¾‹å¦‚å›¾åƒå’Œæ–‡æœ¬çš„é¢„è®­ç»ƒä»»åŠ¡ã€æ¶æ„ç»“æ„å’Œå…³é”®è¶‹åŠ¿ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†åŸºäºæ–‡æœ¬-å›¾åƒæ¨¡å‹çš„è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ çš„æœ€æ–°å‰æ²¿åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11101v2">PDF</a> </p>
<p><strong>Summary</strong><br>     è‡ªç›‘ç£å­¦ä¹ é€šè¿‡ä»éæ ‡è®°æ•°æ®ä¸­å­¦ä¹ æ½œåœ¨æ¨¡å¼å’Œæå–åˆ¤åˆ«ç‰¹å¾ï¼Œç”Ÿæˆéšå¼æ ‡ç­¾ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚å¯¹æ¯”å­¦ä¹ å¼•å…¥äº†â€œæ­£æ ·æœ¬â€å’Œâ€œè´Ÿæ ·æœ¬â€çš„æ¦‚å¿µï¼Œå°†æ­£æ ·æœ¬å¯¹æ‹‰è¿‘åµŒå…¥ç©ºé—´ï¼Œå°†è´Ÿæ ·æœ¬å¯¹æ¨å¼€ã€‚æ­¤æ–¹æ³•åœ¨å›¾åƒç†è§£å’Œæ–‡æœ¬åˆ†ææ–¹é¢æ˜¾è‘—æé«˜äº†æ•ˆæœï¼Œå¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–è¾ƒå°ã€‚æœ¬æ–‡ç»¼è¿°äº†æ–‡æœ¬å›¾åƒæ¨¡å‹çš„å¯¹æ¯”å­¦ä¹ æœ¯è¯­ã€æœ€æ–°å‘å±•åŠåº”ç”¨ï¼ŒæŒ‰æ¨¡å‹ç»“æ„åˆ†ç±»ï¼Œå¹¶ä»‹ç»äº†æœ€æ–°çš„æŠ€æœ¯è¿›å±•å’Œåº”ç”¨è¶‹åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç›‘ç£å­¦ä¹ æ˜¯é€šè¿‡å­¦ä¹ æ½œåœ¨æ¨¡å¼å’Œæå–éæ ‡è®°æ•°æ®çš„åˆ¤åˆ«ç‰¹å¾æ¥ç”Ÿæˆéšå¼æ ‡ç­¾ã€‚</li>
<li>å¯¹æ¯”å­¦ä¹ åœ¨è‡ªç›‘ç£å­¦ä¹ ä¸­å¼•å…¥æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬æ¦‚å¿µï¼Œç”¨äºæ‹‰è¿‘æˆ–æ¨å¼€æ ·æœ¬å¯¹åœ¨åµŒå…¥ç©ºé—´ä¸­çš„è·ç¦»ã€‚</li>
<li>å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨å›¾åƒç†è§£å’Œæ–‡æœ¬åˆ†ææ–¹é¢æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ•ˆæœæå‡ã€‚</li>
<li>è®ºæ–‡å…¨é¢è®¨è®ºäº†æ–‡æœ¬å›¾åƒæ¨¡å‹çš„å¯¹æ¯”å­¦ä¹ æœ¯è¯­å’Œæœ€æ–°å‘å±•ã€‚</li>
<li>è®ºæ–‡æŒ‰æ¨¡å‹ç»“æ„åˆ†ç±»äº†å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ã€‚</li>
<li>è®ºæ–‡ä»‹ç»äº†æœ€æ–°çš„æŠ€æœ¯è¿›å±•ï¼ŒåŒ…æ‹¬å›¾åƒå’Œæ–‡æœ¬çš„é¢„è®­ç»ƒä»»åŠ¡ã€æ¶æ„ç»“æ„å’Œå…³é”®è¶‹åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1890949273184fcdfb967c547998d3ae.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="An-OpenMind-for-3D-medical-vision-self-supervised-learning"><a href="#An-OpenMind-for-3D-medical-vision-self-supervised-learning" class="headerlink" title="An OpenMind for 3D medical vision self-supervised learning"></a>An OpenMind for 3D medical vision self-supervised learning</h2><p><strong>Authors:Tassilo Wald, Constantin Ulrich, Jonathan Suprijadi, Sebastian Ziegler, Michal Nohel, Robin Peretzke, Gregor KÃ¶hler, Klaus H. Maier-Hein</strong></p>
<p>The field of self-supervised learning (SSL) for 3D medical images lacks consistency and standardization. While many methods have been developed, it is impossible to identify the current state-of-the-art, due to i) varying and small pretraining datasets, ii) varying architectures, and iii) being evaluated on differing downstream datasets. In this paper, we bring clarity to this field and lay the foundation for further method advancements through three key contributions: We a) publish the largest publicly available pre-training dataset comprising 114k 3D brain MRI volumes, enabling all practitioners to pre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised learning methods on this dataset for a state-of-the-art CNN and Transformer architecture, clarifying the state of 3D SSL pre-training. Among many findings, we show that pre-trained methods can exceed a strong from-scratch nnU-Net ResEnc-L baseline. Lastly, we c) publish the code of our pre-training and fine-tuning frameworks and provide the pre-trained models created during the benchmarking process to facilitate rapid adoption and reproduction. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰åœ¨3DåŒ»å­¦å›¾åƒé¢†åŸŸç¼ºä¹ä¸€è‡´æ€§å’Œæ ‡å‡†åŒ–ã€‚è™½ç„¶å·²å¼€å‘äº†è®¸å¤šæ–¹æ³•ï¼Œä½†ç”±äºiï¼‰é¢„è®­ç»ƒæ•°æ®é›†å„ä¸ç›¸åŒä¸”è§„æ¨¡è¾ƒå°ï¼Œiiï¼‰æ¶æ„å„å¼‚ï¼Œä»¥åŠiiiï¼‰åœ¨ä¸åŒçš„ä¸‹æ¸¸æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå› æ­¤æ— æ³•ç¡®å®šå½“å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸‰ä¸ªä¸»è¦è´¡çŒ®ä½¿è¯¥é¢†åŸŸæ¸…æ™°åŒ–ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥çš„æ–¹æ³•å‘å±•å¥ å®šåŸºç¡€ï¼šæˆ‘ä»¬aï¼‰å‘å¸ƒäº†æœ€å¤§çš„å…¬å¼€é¢„è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«114kä¸ª3Då¤§è„‘MRIä½“ç§¯ï¼Œä½¿æ‰€æœ‰ä»ä¸šè€…éƒ½å¯ä»¥åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚æˆ‘ä»¬bï¼‰åœ¨æ­¤æ•°æ®é›†ä¸Šå¯¹ç°æœ‰çš„3Dè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œé’ˆå¯¹æœ€å…ˆè¿›çš„äººå·¥ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformeræ¶æ„ï¼Œæ˜ç¡®äº†3D SSLé¢„è®­ç»ƒçš„çŠ¶æ€ã€‚æˆ‘ä»¬å‘ç°äº†è®¸å¤šç»“æœï¼Œå…¶ä¸­è¡¨æ˜é¢„è®­ç»ƒæ–¹æ³•è¶…è¿‡äº†ä»å¤´å¼€å§‹çš„nnU-Net ResEnc-LåŸºçº¿ã€‚æœ€åï¼Œæˆ‘ä»¬cï¼‰å‘å¸ƒæˆ‘ä»¬çš„é¢„è®­ç»ƒå’Œå¾®è°ƒæ¡†æ¶çš„ä»£ç ï¼Œå¹¶æä¾›åœ¨åŸºå‡†æµ‹è¯•è¿‡ç¨‹ä¸­åˆ›å»ºçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å¿«é€Ÿé‡‡ç”¨å’Œå¤ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17041v2">PDF</a> Pre-Print; Dataset, Benchmark and Codebase available through   <a target="_blank" rel="noopener" href="https://github.com/MIC-DKFZ/nnssl">https://github.com/MIC-DKFZ/nnssl</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹3DåŒ»å­¦å›¾åƒçš„è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰é¢†åŸŸç¼ºä¹ä¸€è‡´æ€§å’Œæ ‡å‡†åŒ–çš„é—®é¢˜ã€‚æ–‡ç« é€šè¿‡ä¸‰ä¸ªå…³é”®è´¡çŒ®æ¥æ¾„æ¸…è¯¥é¢†åŸŸå¹¶ä¸ºè¿›ä¸€æ­¥çš„æ–¹æ³•å‘å±•å¥ å®šåŸºç¡€ï¼šå‘å¸ƒæœ€å¤§çš„å…¬å¼€é¢„è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«11.4ä¸‡3Dè„‘éƒ¨MRIä½“ç§¯ï¼Œä½¿æ‰€æœ‰å®è·µè€…éƒ½å¯ä»¥åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼›åœ¨æ­¤æ•°æ®é›†ä¸Šå¯¹ç°æœ‰3Dè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥æ¾„æ¸…3D SSLé¢„è®­ç»ƒçš„å½“å‰çŠ¶æ€ï¼›æœ€åï¼Œå‘å¸ƒé¢„è®­ç»ƒå’Œå¾®è°ƒæ¡†æ¶çš„ä»£ç ï¼Œå¹¶æä¾›åœ¨åŸºå‡†æµ‹è¯•è¿‡ç¨‹ä¸­åˆ›å»ºçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å¿«é€Ÿé‡‡ç”¨å’Œå¤åˆ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DåŒ»å­¦å›¾åƒè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰é¢†åŸŸç¼ºä¹ä¸€è‡´æ€§å’Œæ ‡å‡†åŒ–ã€‚</li>
<li>æ–‡ç« å‘å¸ƒäº†åŒ…å«å¤§é‡æ•°æ®çš„æœ€å¤§å…¬å¼€é¢„è®­ç»ƒæ•°æ®é›†ã€‚</li>
<li>å¯¹ç°æœ‰3Dè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå‘ç°é¢„è®­ç»ƒçš„æ–¹æ³•å¯ä»¥è¶…è¶Šä»å¤´å¼€å§‹çš„nnU-Net ResEnc-LåŸºçº¿ã€‚</li>
<li>æ–‡ç« æä¾›äº†é¢„è®­ç»ƒå’Œå¾®è°ƒæ¡†æ¶çš„ä»£ç ä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ–¹ä¾¿å…¶ä»–ç ”ç©¶è€…ä½¿ç”¨ã€‚</li>
<li>æ–‡ç« å¼ºè°ƒäº†ä¸åŒé¢„è®­ç»ƒæ•°æ®é›†ã€æ¶æ„ä»¥åŠä¸‹æ¸¸æ•°æ®é›†å¯¹è¯„ä¼°è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•çš„å½±å“ã€‚</li>
<li>æ–‡ç« é€šè¿‡å¯¹æ¯”ä¸åŒæ¶æ„ï¼ˆCNNå’ŒTransformerï¼‰åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17041">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-77145e7037ca28f3889ddb592a284be4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ae1262078b4a0c900429142766aac1c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9acf4121acfec8e1c3b8212fe5cc23f7.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Topograph-An-efficient-Graph-Based-Framework-for-Strictly-Topology-Preserving-Image-Segmentation"><a href="#Topograph-An-efficient-Graph-Based-Framework-for-Strictly-Topology-Preserving-Image-Segmentation" class="headerlink" title="Topograph: An efficient Graph-Based Framework for Strictly Topology   Preserving Image Segmentation"></a>Topograph: An efficient Graph-Based Framework for Strictly Topology   Preserving Image Segmentation</h2><p><strong>Authors:Laurin Lux, Alexander H. Berger, Alexander Weers, Nico Stucki, Daniel Rueckert, Ulrich Bauer, Johannes C. Paetzold</strong></p>
<p>Topological correctness plays a critical role in many image segmentation tasks, yet most networks are trained using pixel-wise loss functions, such as Dice, neglecting topological accuracy. Existing topology-aware methods often lack robust topological guarantees, are limited to specific use cases, or impose high computational costs. In this work, we propose a novel, graph-based framework for topologically accurate image segmentation that is both computationally efficient and generally applicable. Our method constructs a component graph that fully encodes the topological information of both the prediction and ground truth, allowing us to efficiently identify topologically critical regions and aggregate a loss based on local neighborhood information. Furthermore, we introduce a strict topological metric capturing the homotopy equivalence between the union and intersection of prediction-label pairs. We formally prove the topological guarantees of our approach and empirically validate its effectiveness on binary and multi-class datasets. Our loss demonstrates state-of-the-art performance with up to fivefold faster loss computation compared to persistent homology methods. </p>
<blockquote>
<p>æ‹“æ‰‘æ­£ç¡®æ€§åœ¨è®¸å¤šå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œç„¶è€Œï¼Œå¤§å¤šæ•°ç½‘ç»œéƒ½æ˜¯ä½¿ç”¨åƒç´ çº§æŸå¤±å‡½æ•°ï¼ˆå¦‚Diceç³»æ•°ï¼‰è¿›è¡Œè®­ç»ƒçš„ï¼Œå¿½è§†äº†æ‹“æ‰‘å‡†ç¡®æ€§ã€‚ç°æœ‰çš„æ‹“æ‰‘æ„ŸçŸ¥æ–¹æ³•å¾€å¾€ç¼ºä¹ç¨³å¥çš„æ‹“æ‰‘ä¿è¯ï¼Œä»…é™äºç‰¹å®šç”¨ä¾‹ï¼Œæˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å›¾è®ºåŸºç¡€æ¡†æ¶ï¼Œç”¨äºæ‹“æ‰‘å‡†ç¡®çš„å›¾åƒåˆ†å‰²ï¼Œæ—¢è®¡ç®—é«˜æ•ˆåˆé€šç”¨æ€§å¼ºã€‚æˆ‘ä»¬çš„æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªç»„ä»¶å›¾ï¼Œè¯¥å›¾å®Œå…¨ç¼–ç äº†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾çš„æ‹“æ‰‘ä¿¡æ¯ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿé«˜æ•ˆåœ°è¯†åˆ«å‡ºæ‹“æ‰‘å…³é”®åŒºåŸŸï¼Œå¹¶æ ¹æ®å±€éƒ¨é‚»åŸŸä¿¡æ¯èšåˆæŸå¤±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸¥æ ¼çš„æ‹“æ‰‘åº¦é‡æ ‡å‡†ï¼Œæ•è·é¢„æµ‹æ ‡ç­¾å¯¹è”åˆä¸äº¤é›†ä¹‹é—´çš„åŒèƒšç­‰ä»·æ€§ã€‚æˆ‘ä»¬æ­£å¼è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æ‹“æ‰‘ä¿è¯ï¼Œå¹¶åœ¨äºŒè¿›åˆ¶å’Œå¤šç±»åˆ«æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®è¯éªŒè¯ã€‚æˆ‘ä»¬çš„æŸå¤±å‡½æ•°è¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ï¼Œä¸æŒä¹…åŒæ„æ–¹æ³•ç›¸æ¯”ï¼ŒæŸå¤±è®¡ç®—é€Ÿåº¦æé«˜äº†äº”å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03228v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå›¾çš„æ–°å‹æ‹“æ‰‘ç²¾ç¡®å›¾åƒåˆ†å‰²æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨æ‹“æ‰‘ä¿¡æ¯è¿›è¡Œé«˜æ•ˆè®¡ç®—å¹¶ä¸”å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ã€‚é€šè¿‡æ„å»ºç»„ä»¶å›¾æ¥å…¨é¢ç¼–ç é¢„æµ‹å’ŒçœŸå®å€¼çš„æ‹“æ‰‘ä¿¡æ¯ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¿…é€Ÿè¯†åˆ«å‡ºæ‹“æ‰‘å…³é”®åŒºåŸŸå¹¶æ ¹æ®å±€éƒ¨é‚»åŸŸä¿¡æ¯èšåˆæŸå¤±ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§ä¸¥æ ¼çš„æ‹“æ‰‘åº¦é‡æ ‡å‡†ï¼Œæ•è·é¢„æµ‹æ ‡ç­¾å¯¹å¹¶é›†å’Œäº¤é›†ä¹‹é—´çš„åŒèƒšç­‰ä»·æ€§ã€‚è¯¥æ–¹æ³•åœ¨äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œä¸”ç›¸è¾ƒäºæŒä¹…åŒæºæ€§æ–¹æ³•ï¼ŒæŸå¤±è®¡ç®—é€Ÿåº¦æé«˜äº†äº”å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‹“æ‰‘æ­£ç¡®æ€§åœ¨å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­èµ·å…³é”®ä½œç”¨ï¼Œä½†å¤§å¤šæ•°ç½‘ç»œä½¿ç”¨åƒç´ çº§æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œå¿½ç•¥äº†æ‹“æ‰‘å‡†ç¡®æ€§ã€‚</li>
<li>ç°æœ‰æ‹“æ‰‘æ„ŸçŸ¥æ–¹æ³•å¸¸å¸¸ç¼ºä¹ç¨³å¥çš„æ‹“æ‰‘ä¿è¯ï¼Œä»…é™äºç‰¹å®šç”¨ä¾‹ï¼Œæˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å›¾åŸºæ¡†æ¶ï¼Œç”¨äºæ‹“æ‰‘å‡†ç¡®çš„å›¾åƒåˆ†å‰²ï¼Œè¯¥æ¡†æ¶æ—¢è®¡ç®—é«˜æ•ˆåˆé€šç”¨æ€§å¼ºã€‚</li>
<li>é€šè¿‡æ„å»ºç»„ä»¶å›¾ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå…¨é¢ç¼–ç é¢„æµ‹å’ŒçœŸå®å€¼çš„æ‹“æ‰‘ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ä¸¥æ ¼çš„æ‹“æ‰‘åº¦é‡æ ‡å‡†ï¼Œç”¨äºæ•è·é¢„æµ‹æ ‡ç­¾å¯¹çš„æ‹“æ‰‘ç­‰ä»·æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å½¢å¼åŒ–çš„æ‹“æ‰‘ä¿è¯ï¼Œå¹¶åœ¨äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®è¯éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03228">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62d43ee8a9cda13c3b203003c7bbd07e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3de696d0a7f06aee9a527f5f383ac089.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5562bf891fc548562e732fcbdb7a09c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ea333d2705156b61a788def2d615e48.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-622cfcf7d83fc9b1295d9da35a94fb83.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MambaMIM-Pre-training-Mamba-with-State-Space-Token-Interpolation-and-its-Application-to-Medical-Image-Segmentation"><a href="#MambaMIM-Pre-training-Mamba-with-State-Space-Token-Interpolation-and-its-Application-to-Medical-Image-Segmentation" class="headerlink" title="MambaMIM: Pre-training Mamba with State Space Token Interpolation and   its Application to Medical Image Segmentation"></a>MambaMIM: Pre-training Mamba with State Space Token Interpolation and   its Application to Medical Image Segmentation</h2><p><strong>Authors:Fenghe Tang, Bingkun Nian, Yingtai Li, Zihang Jiang, Jie Yang, Wei Liu, S. Kevin Zhou</strong></p>
<p>Recently, the state space model Mamba has demonstrated efficient long-sequence modeling capabilities, particularly for addressing long-sequence visual tasks in 3D medical imaging. However, existing generative self-supervised learning methods have not yet fully unleashed Mambaâ€™s potential for handling long-range dependencies because they overlook the inherent causal properties of state space sequences in masked modeling. To address this challenge, we propose a general-purpose pre-training framework called MambaMIM, a masked image modeling method based on a novel TOKen-Interpolation strategy (TOKI) for the selective structure state space sequence, which learns causal relationships of state space within the masked sequence. Further, MambaMIM introduces a bottom-up 3D hybrid masking strategy to maintain a masking consistency across different architectures and can be used on any single or hybrid Mamba architecture to enhance its multi-scale and long-range representation capability. We pre-train MambaMIM on a large-scale dataset of 6.8K CT scans and evaluate its performance across eight public medical segmentation benchmarks. Extensive downstream experiments reveal the feasibility and advancement of using Mamba for medical image pre-training. In particular, when we apply the MambaMIM to a customized architecture that hybridizes MedNeXt and Vision Mamba, we consistently obtain the state-of-the-art segmentation performance. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/MambaMIM">https://github.com/FengheTan9/MambaMIM</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼ŒçŠ¶æ€ç©ºé—´æ¨¡å‹Mambaåœ¨é•¿æ—¶é—´åºåˆ—å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºäº†é«˜æ•ˆçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä¸‰ç»´åŒ»å­¦å½±åƒä¸­çš„é•¿æ—¶é—´åºåˆ—è§†è§‰ä»»åŠ¡æ–¹é¢ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç”Ÿæˆå¼è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å°šæœªå……åˆ†å‘æŒ¥Mambaåœ¨å¤„ç†é•¿è·ç¦»ä¾èµ–å…³ç³»æ–¹é¢çš„æ½œåŠ›ï¼Œå› ä¸ºå®ƒä»¬å¿½ç•¥äº†çŠ¶æ€ç©ºé—´åºåˆ—åœ¨æ©æ¨¡å»ºæ¨¡ä¸­çš„å›ºæœ‰å› æœç‰¹æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„é¢„è®­ç»ƒæ¡†æ¶ï¼Œç§°ä¸ºMambaMIMã€‚è¿™æ˜¯ä¸€ç§åŸºäºæ–°å‹TOKENæ’å€¼ç­–ç•¥ï¼ˆTOKIï¼‰çš„æ©æ¨¡å›¾åƒå»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºé€‰æ‹©æ€§ç»“æ„çŠ¶æ€ç©ºé—´åºåˆ—ï¼Œå­¦ä¹ æ©æ¨¡åºåˆ—ä¸­çŠ¶æ€ç©ºé—´çš„å› æœå…³ç³»ã€‚æ­¤å¤–ï¼ŒMambaMIMå¼•å…¥äº†ä¸€ç§è‡ªä¸‹è€Œä¸Šçš„ä¸‰ç»´æ··åˆæ©æ¨¡ç­–ç•¥ï¼Œä»¥åœ¨ä¸åŒæ¶æ„ä¹‹é—´ä¿æŒæ©æ¨¡çš„ä¸€è‡´æ€§ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä»»ä½•å•ä¸€æˆ–æ··åˆMambaæ¶æ„ä¸Šä½¿ç”¨ï¼Œä»¥å¢å¼ºå…¶å¤šå°ºåº¦å’Œé•¿è·ç¦»è¡¨ç¤ºèƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨åŒ…å«å…­åƒå…«ç™¾ä¸ªCTæ‰«æçš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šé¢„è®­ç»ƒäº†MambaMIMï¼Œå¹¶åœ¨å…«ä¸ªå…¬å…±åŒ»å­¦åˆ†å‰²åŸºå‡†ä¸Šè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚å¤§é‡çš„ä¸‹æ¸¸å®éªŒéªŒè¯äº†ä½¿ç”¨Mambaè¿›è¡ŒåŒ»å­¦å›¾åƒé¢„è®­ç»ƒçš„å¯è¡Œæ€§å’Œå…ˆè¿›æ€§ã€‚ç‰¹åˆ«æ˜¯å½“æˆ‘ä»¬å°†MambaMIMåº”ç”¨äºæ··åˆMedNeXtå’Œè§†è§‰Mambaçš„å®šåˆ¶æ¶æ„æ—¶ï¼Œæˆ‘ä»¬å§‹ç»ˆè·å¾—æœ€å…ˆè¿›çš„åˆ†å‰²æ€§èƒ½ã€‚ä»£ç å¯ä»ä»¥ä¸‹ç½‘ç«™è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/FengheTan9/MambaMIM">https://github.com/FengheTan9/MambaMIM</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.08070v2">PDF</a> Accepted by Medical Image Analysis. Code:   <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/MambaMIM">https://github.com/FengheTan9/MambaMIM</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>Mambaæ¨¡å‹å…·æœ‰é«˜æ•ˆçš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¤„ç†é•¿æœŸåºåˆ—è§†è§‰ä»»åŠ¡åœ¨3DåŒ»å­¦å½±åƒæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚ä½†ç°æœ‰çš„ç”Ÿæˆå¼è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•æœªèƒ½å……åˆ†å‘æŒ¥Mambaåœ¨å¤„ç†é•¿æœŸä¾èµ–å…³ç³»æ–¹é¢çš„æ½œåŠ›ï¼Œå› ä¸ºå®ƒä»¬å¿½è§†äº†çŠ¶æ€ç©ºé—´åºåˆ—çš„å†…åœ¨å› æœç‰¹æ€§åœ¨é®æ©å»ºæ¨¡ä¸­çš„ä½œç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„é¢„è®­ç»ƒæ¡†æ¶MambaMIMï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ–°å‹Tokenæ’å€¼ç­–ç•¥ï¼ˆTOKIï¼‰çš„é®æ©å›¾åƒå»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºé€‰æ‹©æ€§ç»“æ„çŠ¶æ€ç©ºé—´åºåˆ—ï¼Œå­¦ä¹ é®æ©åºåˆ—ä¸­çŠ¶æ€ç©ºé—´çš„å› æœå…³ç³»ã€‚æ­¤å¤–ï¼ŒMambaMIMå¼•å…¥äº†ä¸€ç§è‡ªä¸‹è€Œä¸Šçš„3Dæ··åˆé®æ©ç­–ç•¥ï¼Œä»¥ä¿æŒä¸åŒæ¶æ„ä¹‹é—´çš„é®æ©ä¸€è‡´æ€§ï¼Œå¯åº”ç”¨äºä»»ä½•å•ä¸€æˆ–æ··åˆMambaæ¶æ„ï¼Œä»¥å¢å¼ºå…¶å¤šå°ºåº¦å’Œé•¿æœŸè¡¨ç¤ºèƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨åŒ…å«å¤§å‹CTæ‰«ææ•°æ®é›†ä¸Šé¢„è®­ç»ƒäº†MambaMIMï¼Œå¹¶åœ¨å…«ä¸ªå…¬å…±åŒ»å­¦åˆ†å‰²åŸºå‡†ä¸Šè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚ä¸‹æ¸¸å®éªŒè¡¨æ˜ä½¿ç”¨Mambaè¿›è¡ŒåŒ»å­¦å›¾åƒé¢„è®­ç»ƒçš„å¯è¡Œæ€§å’Œå…ˆè¿›æ€§ã€‚ç‰¹åˆ«æ˜¯å°†MambaMIMåº”ç”¨äºæ··åˆMedNeXtå’ŒVision Mambaçš„å®šåˆ¶æ¶æ„æ—¶ï¼Œæˆ‘ä»¬è·å¾—äº†é¢†å…ˆçš„åˆ†å‰²æ€§èƒ½ã€‚ç›¸å…³ä»£ç å·²å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/FengheTan9/MambaMIM">https://github.com/FengheTan9/MambaMIM</a>ã€‚</p>
<pre><code>**å…³é”®è§è§£**

1. Mambaæ¨¡å‹åœ¨å¤„ç†å’Œè§£å†³é•¿æœŸåºåˆ—è§†è§‰ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»å­¦æˆåƒé¢†åŸŸã€‚
2. ç°æœ‰çš„ç”Ÿæˆå¼è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•æœªå……åˆ†åˆ©ç”¨Mambaæ¨¡å‹çš„é•¿æœŸä¾èµ–å¤„ç†æ½œåŠ›ï¼ŒåŸå› æ˜¯å¿½è§†äº†å…¶çŠ¶æ€ç©ºé—´åºåˆ—çš„å› æœç‰¹æ€§ã€‚
3. æå‡ºäº†ä¸€ç§æ–°çš„é¢„è®­ç»ƒæ¡†æ¶MambaMIMï¼Œç»“åˆäº†é®æ©å›¾åƒå»ºæ¨¡å’Œä¸€ç§æ–°å‹çš„Tokenæ’å€¼ç­–ç•¥ï¼ˆTOKIï¼‰ã€‚è¿™æœ‰åŠ©äºå­¦ä¹ çŠ¶æ€ç©ºé—´åºåˆ—ä¸­çš„å› æœå…³ç³»ã€‚
4. MambaMIMå¼•å…¥äº†æ··åˆé®æ©ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹åœ¨å¤šå°ºåº¦å’Œé•¿æœŸè¡¨ç¤ºæ–¹é¢çš„èƒ½åŠ›ï¼ŒåŒæ—¶é€‚ç”¨äºå¤šç§æ¶æ„ã€‚
5. åœ¨å¤§è§„æ¨¡åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒå®éªŒï¼ŒéªŒè¯äº†MambaMIMçš„æœ‰æ•ˆæ€§ã€‚
6. åœ¨å¤šä¸ªå…¬å…±åŒ»å­¦åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMambaMIMå±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯å½“ä¸å…¶ä»–æ¶æ„ç»“åˆæ—¶ï¼Œå…¶è¡¨ç°å°¤ä¸ºçªå‡ºã€‚
</code></pre>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.08070">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e546a179e2d49b5095f6518f38dbb5d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f657e4071acf014b3f096ccdeafde015.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ec9a7dcec5dc00db165a3da32df15c29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-621e4cbe8f7e990b5f7441c6e916a552.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-22/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-22/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-22/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-95e95cbe0fe9d96e215934157a007fad.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  ChatNekoHacker Real-Time Fan Engagement with Conversational Agents
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-22/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a2b1370e32563de59b2407f6ef45fd0a.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  Decoding Vision Transformers the Diffusion Steering Lens
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27083.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
