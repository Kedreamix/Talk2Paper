<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  ChatNekoHacker Real-Time Fan Engagement with Conversational Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-6d78f5d29a4192863c752c1cde3e5a13.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    57 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-22-æ›´æ–°"><a href="#2025-04-22-æ›´æ–°" class="headerlink" title="2025-04-22 æ›´æ–°"></a>2025-04-22 æ›´æ–°</h1><h2 id="ChatNekoHacker-Real-Time-Fan-Engagement-with-Conversational-Agents"><a href="#ChatNekoHacker-Real-Time-Fan-Engagement-with-Conversational-Agents" class="headerlink" title="ChatNekoHacker: Real-Time Fan Engagement with Conversational Agents"></a>ChatNekoHacker: Real-Time Fan Engagement with Conversational Agents</h2><p><strong>Authors:Takuya Sera, Yusuke Hamano</strong></p>
<p>ChatNekoHacker is a real-time conversational agent system that strengthens fan engagement for musicians. It integrates Amazon Bedrock Agents for autonomous dialogue, Unity for immersive 3D livestream sets, and VOICEVOX for high quality Japanese text-to-speech, enabling two virtual personas to represent the music duo Neko Hacker. In a one-hour YouTube Live with 30 participants, we evaluated the impact of the system. Regression analysis showed that agent interaction significantly elevated fan interest, with perceived fun as the dominant predictor. The participants also expressed a stronger intention to listen to the duoâ€™s music and attend future concerts. These findings highlight entertaining, interactive broadcasts as pivotal to cultivating fandom. Our work offers actionable insights for the deployment of conversational agents in entertainment while pointing to next steps: broader response diversity, lower latency, and tighter fact-checking to curb potential misinformation. </p>
<blockquote>
<p>ChatNekoHackeræ˜¯ä¸€ä¸ªå®æ—¶å¯¹è¯ä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨å¢å¼ºéŸ³ä¹å®¶çš„ç²‰ä¸å‚ä¸åº¦ã€‚å®ƒé›†æˆäº†äºšé©¬é€ŠåŸºçŸ³ä»£ç†è¿›è¡Œè‡ªä¸»å¯¹è¯ã€Unityç”¨äºæ²‰æµ¸å¼3Dç›´æ’­åœºæ™¯ï¼Œä»¥åŠVOICEVOXç”¨äºé«˜è´¨é‡æ—¥è¯­æ–‡æœ¬åˆ°è¯­éŸ³çš„è½¬æ¢ï¼Œä½¿ä¸¤ä¸ªè™šæ‹Ÿè§’è‰²èƒ½å¤Ÿä»£è¡¨éŸ³ä¹ç»„åˆNeko Hackerã€‚åœ¨ä¸€åœºæŒç»­ä¸€å°æ—¶ã€æœ‰30åå‚ä¸è€…çš„YouTubeç›´æ’­ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†è¯¥ç³»ç»Ÿçš„å½±å“ã€‚å›å½’åˆ†ææ˜¾ç¤ºï¼Œä»£ç†äº’åŠ¨æ˜¾è‘—æé«˜äº†ç²‰ä¸å…´è¶£ï¼Œå…¶ä¸­æ„ŸçŸ¥çš„ä¹è¶£æ˜¯ä¸»å¯¼å› ç´ ã€‚å‚ä¸è€…è¿˜è¡¨è¾¾äº†æ›´å¼ºçƒˆçš„æ„æ„¿å»è†å¬è¯¥ç»„åˆçš„éŸ³ä¹ä»¥åŠå‚åŠ æœªæ¥çš„éŸ³ä¹ä¼šã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†æœ‰è¶£ã€äº’åŠ¨çš„å¹¿æ’­å¯¹äºåŸ¹å…»ç²‰ä¸çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå¨±ä¹é¢†åŸŸå¯¹è¯ä»£ç†çš„éƒ¨ç½²æä¾›äº†å¯æ“ä½œæ€§çš„è§è§£ï¼ŒåŒæ—¶æŒ‡å‡ºäº†ä¸‹ä¸€æ­¥çš„æ–¹å‘ï¼šæ›´å¹¿æ³›çš„å“åº”å¤šæ ·æ€§ã€æ›´ä½çš„å»¶è¿Ÿä»¥åŠæ›´ä¸¥æ ¼çš„äº‹å®æ ¸æŸ¥ï¼Œä»¥éåˆ¶æ½œåœ¨çš„ä¿¡æ¯é”™è¯¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13793v1">PDF</a> Accepted to GenAICHI 2025: Generative AI and HCI at CHI 2025</p>
<p><strong>Summary</strong><br>     èŠå¤©æœºå™¨äººç³»ç»Ÿå¼ºåŒ–ä¹è¿·å‚ä¸åº¦ï¼Œè¯¥ç³»ç»Ÿèåˆäºšé©¬é€Šæœºå™¨äººæ™ºèƒ½å¯¹è¯å¹³å°ï¼Œå¢å¼ºè‡ªä¸»å¯¹è¯åŠŸèƒ½ï¼Œå¹¶ç»“åˆUnityæä¾›æ²‰æµ¸å¼ä¸‰ç»´ç›´æ’­ä½“éªŒï¼Œå†é…ä»¥VOICEVOXé«˜å“è´¨æ—¥è¯­è¯­éŸ³æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯åœ¨éŸ³ä¹ç»„åˆè™šæ‹Ÿäººç‰©ä¸Šçš„å®è·µæ¡ˆä¾‹è¡¨æ˜ï¼Œè¿™ç§äº’åŠ¨æ–¹å¼èƒ½æ˜¾è‘—æé«˜ç²‰ä¸å…´è¶£ï¼Œå¹¶æœ‰æœ›å¢å¼ºç²‰ä¸å¯¹éŸ³ä¹çš„å–œçˆ±å’Œå¯¹æœªæ¥æ´»åŠ¨çš„æœŸå¾…ã€‚ç ”ç©¶ä¸ºå¨±ä¹è¡Œä¸šéƒ¨ç½²èŠå¤©æœºå™¨äººæä¾›äº†å®ç”¨è§è§£ï¼ŒåŒæ—¶æŒ‡å‡ºä¸‹ä¸€æ­¥å‘å±•æ–¹å‘ï¼šæ‰©å¤§å“åº”èŒƒå›´ã€é™ä½å»¶è¿Ÿä»¥åŠåŠ å¼ºäº‹å®æ ¸æŸ¥ï¼Œé˜²æ­¢ä¼ æ’­é”™è¯¯ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ChatNekoHackeræ˜¯ä¸€ä¸ªå¢å¼ºç²‰ä¸å‚ä¸åº¦çš„å®æ—¶å¯¹è¯æœºå™¨äººç³»ç»Ÿã€‚</li>
<li>è¯¥ç³»ç»Ÿé›†æˆäº†äºšé©¬é€Šæœºå™¨äººæ™ºèƒ½å¯¹è¯å¹³å°ã€Unityæ²‰æµ¸å¼ä¸‰ç»´ç›´æ’­ä½“éªŒå’ŒVOICEVOXé«˜è´¨é‡æ—¥è¯­è¯­éŸ³æŠ€æœ¯ã€‚</li>
<li>åœ¨ä¸€å°æ—¶YouTubeç›´æ’­æµ‹è¯•ä¸­ï¼Œæœºå™¨äººäº’åŠ¨æ˜¾è‘—æé«˜äº†ç²‰ä¸å…´è¶£ã€‚</li>
<li>è¢«è§†ä¸ºæœ‰è¶£æ˜¯ä¸»è¦çš„é¢„æµ‹å› ç´ ã€‚</li>
<li>å‚ä¸è€…åœ¨æµ‹è¯•åè¡¨è¾¾äº†æ›´å¼ºçš„éŸ³ä¹å¬æ’­æ„å‘å’Œå‚åŠ æœªæ¥éŸ³ä¹ä¼šçš„æ„æ„¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13793">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f477b41f07b39aa29735ccc367f8c28b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb71b6d75a9d677d2372144fcb895621.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b8429737ebb0669a22a4e095872fcd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f62c92860574c82139699b6c811149e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-95e95cbe0fe9d96e215934157a007fad.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Task-Assignment-and-Exploration-Optimization-for-Low-Altitude-UAV-Rescue-via-Generative-AI-Enhanced-Multi-agent-Reinforcement-Learning"><a href="#Task-Assignment-and-Exploration-Optimization-for-Low-Altitude-UAV-Rescue-via-Generative-AI-Enhanced-Multi-agent-Reinforcement-Learning" class="headerlink" title="Task Assignment and Exploration Optimization for Low Altitude UAV Rescue   via Generative AI Enhanced Multi-agent Reinforcement Learning"></a>Task Assignment and Exploration Optimization for Low Altitude UAV Rescue   via Generative AI Enhanced Multi-agent Reinforcement Learning</h2><p><strong>Authors:Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato</strong></p>
<p>Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAVâ€™s capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é©±åŠ¨çš„å·ç§¯ç¥ç»ç½‘ç»œæé«˜äº†ä½ç©ºæ— äººé£è¡Œå™¨ï¼ˆUAVsï¼‰å’Œåœ°é¢è®¡ç®—èŠ‚ç‚¹ï¼ˆGCNsï¼‰åœ¨æœªçŸ¥ç¯å¢ƒä¸­æ‰§è¡Œçš„æ•‘æ´ã€æ£€æŸ¥å’Œç›‘è§†ä»»åŠ¡çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„é«˜è®¡ç®—éœ€æ±‚ç»å¸¸è¶…å‡ºå•ä¸ªæ— äººæœºçš„èƒ½åŠ›ï¼Œå¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šï¼Œè€Œåœ°é¢è®¡ç®—èŠ‚ç‚¹çš„èµ„æºæœ‰é™ä¸”åŠ¨æ€ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†è¿™ä¸€é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ¶‰åŠæ— äººæœºã€åœ°é¢åµŒå…¥å¼æœºå™¨äººï¼ˆGERsï¼‰å’Œé«˜ç©ºå¹³å°ï¼ˆHAPsï¼‰çš„æ–°å‹åˆä½œæ¡†æ¶ï¼Œé€šè¿‡æ— äººæœºåˆ°åœ°é¢æœºå™¨äººï¼ˆU2Gï¼‰å’Œæ— äººæœºåˆ°é«˜ç©ºå¹³å°ï¼ˆU2Hï¼‰çš„é€šä¿¡ï¼Œå®ç°èµ„æºæ± ï¼Œä¸ºæ— äººæœºå¸è½½çš„ä»»åŠ¡æä¾›è®¡ç®—æœåŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ— äººæœºä¸­çš„ä»»åŠ¡åˆ†é…å’Œæ¢æµ‹ä¼˜åŒ–çš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜åˆ¶å®šä¸ºåŠ¨æ€é•¿æœŸä¼˜åŒ–é—®é¢˜ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å°åŒ–ä»»åŠ¡å®Œæˆæ—¶é—´å’Œèƒ½æºæ¶ˆè€—ï¼ŒåŒæ—¶ç¡®ä¿ç³»ç»Ÿéšæ—¶é—´ç¨³å®šã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆé‡‡ç”¨Lyapunovä¼˜åŒ–æŠ€æœ¯ï¼Œå°†å¸¦ç¨³å®šæ€§çº¦æŸçš„åŸå§‹é—®é¢˜è½¬åŒ–ä¸ºæ¯ä¸ªæ—¶éš™çš„ç¡®å®šæ€§é—®é¢˜ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºHG-MADDPGçš„ç®—æ³•ï¼Œè¯¥ç®—æ³•ç»“åˆäº†åŒˆç‰™åˆ©ç®—æ³•å’ŒåŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼ˆGDMï¼‰çš„å¤šæ™ºèƒ½ä½“æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆMADDPGï¼‰æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆä»‹ç»åŒˆç‰™åˆ©ç®—æ³•ä½œä¸ºä¸€ç§æ¢æµ‹åŒºåŸŸé€‰æ‹©æ–¹æ³•ï¼Œæé«˜æ— äººæœºä¸ç¯å¢ƒäº¤äº’çš„æ•ˆç‡ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ›æ–°åœ°å°†GDMå’Œå¤šæ™ºèƒ½ä½“æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆMADDPGï¼‰ç›¸ç»“åˆï¼Œä¼˜åŒ–ä»»åŠ¡åˆ†é…å†³ç­–ï¼Œå¦‚ä»»åŠ¡å¸è½½å’Œèµ„æºåˆ†é…ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ä»»åŠ¡å¸è½½æ•ˆç‡ã€å»¶è¿Ÿå‡å°‘å’Œç³»ç»Ÿç¨³å®šæ€§æ–¹é¢ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13554v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºäººå·¥æ™ºèƒ½çš„å·ç§¯ç¥ç»ç½‘ç»œå¢å¼ºäº†ä½ç©ºæ— äººé£è¡Œå™¨ï¼ˆUAVsï¼‰å’Œåœ°é¢è®¡ç®—èŠ‚ç‚¹ï¼ˆGCNsï¼‰åœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„æ•‘æ´ã€æ£€æµ‹å’Œç›‘è§†ä»»åŠ¡æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…¶é«˜è®¡ç®—éœ€æ±‚å¸¸è¶…å‡ºå•ä¸€æ— äººæœºçš„å¤„ç†èƒ½åŠ›ï¼Œå¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šï¼Œä¸”åœ°é¢èŠ‚ç‚¹çš„èµ„æºæœ‰é™ä¸”åŠ¨æ€å˜åŒ–ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºä¸€ä¸ªæ¶‰åŠæ— äººæœºã€åœ°é¢åµŒå…¥å¼æœºå™¨äººï¼ˆGERsï¼‰å’Œé«˜ç©ºå¹³å°ï¼ˆHAPsï¼‰çš„åˆä½œæ¡†æ¶ï¼Œé€šè¿‡æ— äººæœºä¸åœ°é¢æœºå™¨äººçš„é€šä¿¡å®ç°èµ„æºæ± ï¼Œä¸ºå¸è½½çš„ä»»åŠ¡æä¾›è®¡ç®—æœåŠ¡ã€‚ä¸ºæœ€å°åŒ–ä»»åŠ¡å®Œæˆæ—¶é—´å’Œèƒ½æºæ¶ˆè€—å¹¶ç¡®ä¿ç³»ç»Ÿé•¿æœŸç¨³å®šæ€§ï¼Œé‡‡ç”¨æé›…æ™®è¯ºå¤«ä¼˜åŒ–æŠ€æœ¯å°†é—®é¢˜è½¬æ¢ä¸ºç¡®å®šæ€§é—®é¢˜ï¼Œå¹¶æå‡ºHG-MADDPGç®—æ³•ï¼Œç»“åˆåŒˆç‰™åˆ©ç®—æ³•ä¸åŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼ˆGDMï¼‰çš„å¤šæ™ºèƒ½ä½“æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ï¼ˆMADDPGï¼‰æ–¹æ³•ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæé«˜ä»»åŠ¡å¸è½½æ•ˆç‡ï¼Œé™ä½å»¶è¿Ÿï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIæŠ€æœ¯å¢å¼ºäº†UAVsåœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„æ•‘æ´ã€æ£€æµ‹å’Œç›‘è§†ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>å•ä¸ªUAVçš„è®¡ç®—èƒ½åŠ›æœ‰é™ï¼Œå¯èƒ½å¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªæ¶‰åŠUAVsã€GERså’ŒHAPsçš„åˆä½œæ¡†æ¶ï¼Œé€šè¿‡èµ„æºæ± è§£å†³è®¡ç®—éœ€æ±‚é—®é¢˜ã€‚</li>
<li>åˆ©ç”¨æé›…æ™®è¯ºå¤«ä¼˜åŒ–æŠ€æœ¯ç¡®ä¿ç³»ç»Ÿé•¿æœŸç¨³å®šæ€§ã€‚</li>
<li>é‡‡ç”¨HG-MADDPGç®—æ³•ç»“åˆåŒˆç‰™åˆ©ç®—æ³•å’ŒGDM-MADDPGè¿›è¡Œä¼˜åŒ–ä»»åŠ¡åˆ†é…ã€‚</li>
<li>ä»¿çœŸéªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æé«˜äº†ä»»åŠ¡å¸è½½æ•ˆç‡ï¼Œé™ä½äº†å»¶è¿Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13554">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1ff201ababeba0c1fca3265b760a7e4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e872cccec4cb8b291a270c2f2bb18ae2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1e1998893a10269839582aa44479e28.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SwitchMT-An-Adaptive-Context-Switching-Methodology-for-Scalable-Multi-Task-Learning-in-Intelligent-Autonomous-Agents"><a href="#SwitchMT-An-Adaptive-Context-Switching-Methodology-for-Scalable-Multi-Task-Learning-in-Intelligent-Autonomous-Agents" class="headerlink" title="SwitchMT: An Adaptive Context Switching Methodology for Scalable   Multi-Task Learning in Intelligent Autonomous Agents"></a>SwitchMT: An Adaptive Context Switching Methodology for Scalable   Multi-Task Learning in Intelligent Autonomous Agents</h2><p><strong>Authors:Avaneesh Devkota, Rachmad Vidya Wicaksana Putra, Muhammad Shafique</strong></p>
<p>The ability to train intelligent autonomous agents (such as mobile robots) on multiple tasks is crucial for adapting to dynamic real-world environments. However, state-of-the-art reinforcement learning (RL) methods only excel in single-task settings, and still struggle to generalize across multiple tasks due to task interference. Moreover, real-world environments also demand the agents to have data stream processing capabilities. Toward this, a state-of-the-art work employs Spiking Neural Networks (SNNs) to improve multi-task learning by exploiting temporal information in data stream, while enabling lowpower&#x2F;energy event-based operations. However, it relies on fixed context&#x2F;task-switching intervals during its training, hence limiting the scalability and effectiveness of multi-task learning. To address these limitations, we propose SwitchMT, a novel adaptive task-switching methodology for RL-based multi-task learning in autonomous agents. Specifically, SwitchMT employs the following key ideas: (1) a Deep Spiking Q-Network with active dendrites and dueling structure, that utilizes task-specific context signals to create specialized sub-networks; and (2) an adaptive task-switching policy that leverages both rewards and internal dynamics of the network parameters. Experimental results demonstrate that SwitchMT achieves superior performance in multi-task learning compared to state-of-the-art methods. It achieves competitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6, and Enduro: 355.2) compared to the state-of-the-art, showing its better generalized learning capability. These results highlight the effectiveness of our SwitchMT methodology in addressing task interference while enabling multi-task learning automation through adaptive task switching, thereby paving the way for more efficient generalist agents with scalable multi-task learning capabilities. </p>
<blockquote>
<p>è®­ç»ƒæ™ºèƒ½è‡ªä¸»ä»£ç†ï¼ˆå¦‚ç§»åŠ¨æœºå™¨äººï¼‰åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„èƒ½åŠ›å¯¹äºé€‚åº”åŠ¨æ€ç°å®ä¸–ç•Œç¯å¢ƒè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œæœ€å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ä»…åœ¨å•ä»»åŠ¡è®¾ç½®ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºä»»åŠ¡å¹²æ‰°ï¼Œå®ƒä»¬ä»ç„¶éš¾ä»¥åœ¨å¤šä¸ªä»»åŠ¡ä¹‹é—´è¿›è¡Œæ³›åŒ–ã€‚æ­¤å¤–ï¼Œç°å®ä¸–ç•Œç¯å¢ƒè¿˜è¦æ±‚ä»£ç†å…·æœ‰æ•°æ®æµå¤„ç†èƒ½åŠ›ã€‚é’ˆå¯¹è¿™ä¸€ç‚¹ï¼Œä¸€é¡¹æœ€å…ˆè¿›çš„å·¥ä½œé‡‡ç”¨è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰æ¥æé«˜é€šè¿‡åˆ©ç”¨æ•°æ®æµä¸­çš„æ—¶é—´ä¿¡æ¯æ¥è¿›è¡Œå¤šä»»åŠ¡å­¦ä¹ çš„èƒ½åŠ›ï¼ŒåŒæ—¶å®ç°ä½åŠŸè€—çš„äº‹ä»¶é©±åŠ¨æ“ä½œã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºè®­ç»ƒè¿‡ç¨‹ä¸­çš„å›ºå®šä¸Šä¸‹æ–‡&#x2F;ä»»åŠ¡åˆ‡æ¢é—´éš”ï¼Œä»è€Œé™åˆ¶äº†å¤šä»»åŠ¡å­¦ä¹ çš„å¯æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†SwitchMTï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªä¸»ä»£ç†å¤šä»»åŠ¡å­¦ä¹ çš„æ–°å‹è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒSwitchMTé‡‡ç”¨ä»¥ä¸‹å…³é”®æ€æƒ³ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªå…·æœ‰ä¸»åŠ¨æ ‘çªå’Œå†³æ–—ç»“æ„çš„æ·±åº¦è„‰å†²Qç½‘ç»œï¼Œå®ƒåˆ©ç”¨ç‰¹å®šäºä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¿¡å·æ¥åˆ›å»ºä¸“ä¸šåŒ–çš„å­ç½‘ç»œï¼›ï¼ˆ2ï¼‰ä¸€ç§è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢ç­–ç•¥ï¼Œå®ƒåˆ©ç”¨å¥–åŠ±å’Œç½‘ç»œå‚æ•°çš„å†…éƒ¨åŠ¨æ€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒSwitchMTåœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚åœ¨å¤šä¸ªAtariæ¸¸æˆä¸­ï¼Œå…¶å¾—åˆ†å…·æœ‰ç«äº‰åŠ›ï¼ˆå³Pongï¼š-8.8ï¼ŒBreakoutï¼š5.6ï¼ŒEnduroï¼š355.2ï¼‰ï¼Œæ˜¾ç¤ºå‡ºå…¶æ›´å¥½çš„æ³›åŒ–å­¦ä¹ èƒ½åŠ›ã€‚è¿™äº›ç»“æœçªå‡ºäº†æˆ‘ä»¬çš„SwitchMTæ–¹æ³•åœ¨è§£å†³ä»»åŠ¡å¹²æ‰°æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œé€šè¿‡è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢å®ç°å¤šä»»åŠ¡å­¦ä¹ è‡ªåŠ¨åŒ–ï¼Œä»è€Œä¸ºå…·æœ‰å¯æ‰©å±•å¤šä»»åŠ¡å­¦ä¹ èƒ½åŠ›çš„æ›´é«˜æ•ˆé€šç”¨ä»£ç†é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13541v1">PDF</a> 7 pages, 7 figures, 3 tables</p>
<p><strong>æ‘˜è¦</strong><br>    å¼ºåŒ–å­¦ä¹ å¯¹äºæ™ºèƒ½è‡ªä¸»ä»£ç†äººåœ¨å¤šå˜ç¯å¢ƒä¸‹çš„å¤šä»»åŠ¡é€‚åº”æ€§è®­ç»ƒè‡³å…³é‡è¦ã€‚å½“å‰å‰æ²¿çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ä»é¢ä¸´ä»»åŠ¡å¹²æ‰°çš„é—®é¢˜ï¼Œéš¾ä»¥åœ¨å¤šä¸ªä»»åŠ¡ä¹‹é—´æ³›åŒ–ã€‚æœ€æ–°ç ”ç©¶é‡‡ç”¨è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰æ”¹å–„å¤šä»»åŠ¡å­¦ä¹ ï¼Œä½†å—é™äºå›ºå®šä¸Šä¸‹æ–‡å’Œä»»åŠ¡åˆ‡æ¢é—´éš”ï¼Œå½±å“äº†å¤šä»»åŠ¡å­¦ä¹ çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºSwitchMTæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢ç­–ç•¥ã€‚SwitchMTåŒ…æ‹¬ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ï¼šä¸€æ˜¯æ·±åº¦è„‰å†²Qç½‘ç»œï¼Œåˆ©ç”¨ä»»åŠ¡ç‰¹å®šä¸Šä¸‹æ–‡ä¿¡å·åˆ›å»ºä¸“ä¸šåŒ–å­ç½‘ç»œï¼›äºŒæ˜¯è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢ç­–ç•¥ï¼Œåˆ©ç”¨å¥–åŠ±å’Œç½‘ç»œå‚æ•°çš„å†…éƒ¨åŠ¨æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSwitchMTåœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œåœ¨å¤šæ¬¾Atariæ¸¸æˆä¸­çš„è¡¨ç°ä¹Ÿé¢‡å…·ç«äº‰åŠ›ï¼Œè¡¨æ˜å…¶æ›´å¼ºçš„æ³›åŒ–å­¦ä¹ èƒ½åŠ›ã€‚è¿™è¡¨æ˜SwitchMTæ–¹æ³•åœ¨è§£å†³ä»»åŠ¡å¹²æ‰°çš„åŒæ—¶ï¼Œé€šè¿‡è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢å®ç°äº†å¤šä»»åŠ¡å­¦ä¹ çš„è‡ªåŠ¨åŒ–ï¼Œä¸ºå…·æœ‰å¯æ‰©å±•å¤šä»»åŠ¡å­¦ä¹ èƒ½åŠ›çš„é€šç”¨ä»£ç†é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æ™ºèƒ½è‡ªä¸»ä»£ç†äººçš„å¤šä»»åŠ¡é€‚åº”æ€§è®­ç»ƒä¸­è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•é¢ä¸´ä»»åŠ¡å¹²æ‰°çš„é—®é¢˜ï¼Œéš¾ä»¥æ³›åŒ–å¤šä¸ªä»»åŠ¡ã€‚</li>
<li>è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰è¢«ç”¨äºæ”¹å–„å¤šä»»åŠ¡å­¦ä¹ ï¼Œä½†å—é™äºå›ºå®šçš„ä¸Šä¸‹æ–‡å’Œä»»åŠ¡åˆ‡æ¢é—´éš”ã€‚</li>
<li>SwitchMTæ˜¯ä¸€ç§è‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢æ–¹æ³•ï¼Œç”¨äºå¼ºåŒ–å­¦ä¹ ä¸­çš„å¤šä»»åŠ¡å­¦ä¹ ã€‚</li>
<li>SwitchMTåŒ…æ‹¬æ·±åº¦è„‰å†²Qç½‘ç»œå’Œè‡ªé€‚åº”ä»»åŠ¡åˆ‡æ¢ç­–ç•¥ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºSwitchMTåœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>SwitchMTæ–¹æ³•åœ¨è§£å†³ä»»åŠ¡å¹²æ‰°çš„åŒæ—¶ï¼Œå®ç°äº†å¤šä»»åŠ¡å­¦ä¹ çš„è‡ªåŠ¨åŒ–ï¼Œä¸ºåˆ›å»ºå…·æœ‰æ›´å¼ºæ³›åŒ–å­¦ä¹ èƒ½åŠ›çš„æ™ºèƒ½ä»£ç†é“ºå¹³äº†é“è·¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13541">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-058c1080ac81db543b8b5ffcb9dd01b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff5afab932d3b62360d68216eeaf2fee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-51bc88258ef71ef2a7dfbbe7bd4b775b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e205c655bfc219200f0e43013be6db00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1365af45e2aa1de57fed94f489d89acc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d9991ace64ef7aeefef126ec0cd7472.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e73e00ac302a7ef8c0c639eb80f4e380.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffc7bd0b017cc1cf51b8457682df3563.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CodeVisionary-An-Agent-based-Framework-for-Evaluating-Large-Language-Models-in-Code-Generation"><a href="#CodeVisionary-An-Agent-based-Framework-for-Evaluating-Large-Language-Models-in-Code-Generation" class="headerlink" title="CodeVisionary: An Agent-based Framework for Evaluating Large Language   Models in Code Generation"></a>CodeVisionary: An Agent-based Framework for Evaluating Large Language   Models in Code Generation</h2><p><strong>Authors:Xinchen Wang, Pengfei Gao, Chao Peng, Ruida Hu, Cuiyun Gao</strong></p>
<p>Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities and superior efficiency. However, the performance of LLM-based approaches remains limited due to: (1) lack of multisource domain knowledge, and (2) insufficient comprehension of complex code.   To mitigate the limitations, we propose CodeVisionary, the first LLM-based agent framework for evaluating LLMs in code generation. CodeVisionary consists of two stages: (1) Multiscore knowledge analysis stage, which aims to gather multisource and comprehensive domain knowledge by formulating and executing a stepwise evaluation plan. (2) Negotiation-based scoring stage, which involves multiple judges engaging in discussions to better comprehend the complex code and reach a consensus on the evaluation score. Extensive experiments demonstrate that CodeVisionary achieves the best performance for evaluating LLMs in code generation, outperforming the best baseline methods with average improvements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau coefficients, respectively. Besides, CodeVisionary provides detailed evaluation reports, which assist developers in identifying shortcomings and making improvements. The resources of CodeVisionary are available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/CodeVisionary">https://anonymous.4open.science/r/CodeVisionary</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œè¿™çªæ˜¾å‡ºå¯¹ä¸¥æ ¼å’Œå…¨é¢è¯„ä¼°çš„è¿«åˆ‡éœ€æ±‚ã€‚ç°æœ‰çš„è¯„ä¼°æ–¹æ³•å¯åˆ†ä¸ºä¸‰ç±»ï¼ŒåŒ…æ‹¬ä»¥äººä¸ºä¸­å¿ƒçš„æ–¹æ³•ã€åŸºäºæŒ‡æ ‡çš„æ–¹æ³•å’ŒåŸºäºLLMçš„æ–¹æ³•ã€‚è€ƒè™‘åˆ°ä»¥äººä¸ºä¸­å¿ƒçš„æ–¹æ³•åŠ³åŠ¨å¯†é›†å‹ï¼Œè€ŒåŸºäºæŒ‡æ ‡çš„æ–¹æ³•è¿‡äºä¾èµ–å‚è€ƒç­”æ¡ˆï¼ŒåŸºäºLLMçš„æ–¹æ³•ç”±äºå…¶æ›´å¼ºçš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›å’Œé«˜æ•ˆç‡è€Œè¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼ŒåŸºäºLLMçš„æ–¹æ³•çš„æ€§èƒ½ä»ç„¶æœ‰é™ï¼ŒåŸå› æ˜¯ï¼šï¼ˆ1ï¼‰ç¼ºä¹å¤šæºé¢†åŸŸçŸ¥è¯†ï¼›ï¼ˆ2ï¼‰å¯¹å¤æ‚ä»£ç çš„ç†è§£ä¸è¶³ã€‚ä¸ºäº†ç¼“è§£è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†CodeVisionaryï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¯„ä¼°LLMä»£ç ç”Ÿæˆçš„LLMä»£ç†æ¡†æ¶ã€‚CodeVisionaryç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼šï¼ˆ1ï¼‰å¤šåˆ†æ•°çŸ¥è¯†åˆ†æé˜¶æ®µï¼Œæ—¨åœ¨é€šè¿‡åˆ¶å®šå’Œæ‰§è¡Œåˆ†æ­¥éª¤è¯„ä¼°è®¡åˆ’æ¥æ”¶é›†å¤šæºå’Œç»¼åˆé¢†åŸŸçŸ¥è¯†ã€‚ï¼ˆ2ï¼‰åŸºäºåå•†çš„è¯„åˆ†é˜¶æ®µï¼Œæ¶‰åŠå¤šä¸ªè¯„å§”è¿›è¡Œè®¨è®ºï¼Œä»¥æ›´å¥½åœ°ç†è§£å¤æ‚ä»£ç å¹¶å¯¹è¯„ä¼°åˆ†æ•°è¾¾æˆå…±è¯†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCodeVisionaryåœ¨è¯„ä¼°LLMä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°æœ€ä½³ï¼Œåœ¨Pearsonã€Spearmanå’ŒKendall-Tauç³»æ•°ä¸Šåˆ†åˆ«å¹³å‡æé«˜äº†0.202ã€0.139å’Œ0.117çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒCodeVisionaryæä¾›è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«ä¸è¶³å¹¶è¿›è¡Œæ”¹è¿›ã€‚CodeVisionaryçš„èµ„æºå¯é€šè¿‡<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/CodeVisionary%E8%8E%B7%E5%8F%96%E3%80%82">https://anonymous.4open.science/r/CodeVisionaryè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13472v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›å·²å¾—åˆ°éªŒè¯ï¼Œä½†ä»éœ€ä¸¥è°¨å…¨é¢çš„è¯„ä¼°ã€‚ç°æœ‰è¯„ä¼°æ–¹æ³•åŒ…æ‹¬ä»¥äººç±»ä¸ºä¸­å¿ƒã€åŸºäºæŒ‡æ ‡å’Œä»¥LLMä¸ºä¸­å¿ƒçš„æ–¹æ³•ã€‚ç”±äºäººç±»ä¸ºä¸­å¿ƒçš„è¯„ä¼°æ–¹æ³•åŠ³åŠ¨å¼ºåº¦å¤§ï¼ŒåŸºäºæŒ‡æ ‡çš„è¯„ä¼°è¿‡äºä¾èµ–å‚è€ƒç­”æ¡ˆï¼Œå› æ­¤ä»¥LLMä¸ºä¸­å¿ƒçš„è¯„ä¼°æ–¹æ³•å› å…·æœ‰æ›´å¼ºçš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›å’Œé«˜æ•ˆç‡è€Œå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œå…¶æ€§èƒ½å—é™äºç¼ºä¹å¤šæºé¢†åŸŸçŸ¥è¯†å’Œå¯¹å¤æ‚ä»£ç ç†è§£ä¸è¶³ã€‚ä¸ºç¼“è§£è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºCodeVisionaryï¼Œé¦–ä¸ªåŸºäºLLMçš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨å…¨é¢åˆ†æå¤šæºçŸ¥è¯†å¹¶è¿›è¡Œåå•†è¯„åˆ†ä»¥æ›´å¥½åœ°ç†è§£å¤æ‚ä»£ç ã€‚å®éªŒè¯æ˜ï¼ŒCodeVisionaryåœ¨ä»£ç ç”Ÿæˆè¯„ä¼°æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œå¹³å‡æé«˜äº†Pearsonã€Spearmanå’ŒKendall-Tauç³»æ•°åˆ†åˆ«ä¸º0.202ã€0.139å’Œ0.117ã€‚æ­¤å¤–ï¼ŒCodeVisionaryè¿˜æä¾›è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«ä¸è¶³å¹¶è¿›è¡Œæ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†éœ€è¦ä¸¥è°¨å…¨é¢çš„è¯„ä¼°ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ–¹æ³•åŒ…æ‹¬äººç±»ä¸ºä¸­å¿ƒã€åŸºäºæŒ‡æ ‡å’Œä»¥LLMä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ã€‚</li>
<li>CodeVisionaryæ˜¯é¦–ä¸ªåŸºäºLLMçš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>CodeVisionaryåŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šå¤šæºçŸ¥è¯†åˆ†æå’Œåå•†è¯„åˆ†ï¼Œä»¥æ›´å¥½åœ°ç†è§£å¤æ‚ä»£ç ã€‚</li>
<li>CodeVisionaryé€šè¿‡æ”¶é›†å¤šæºé¢†åŸŸçŸ¥è¯†å’Œæ‰§è¡Œé€æ­¥è¯„ä»·è®¡åˆ’æ¥å¼¥è¡¥LLMçš„å±€é™æ€§ã€‚</li>
<li>CodeVisionaryé€šè¿‡å¤šè¯„å§”è®¨è®ºè¾¾æˆå…±è¯†ï¼Œä»¥æé«˜è¯„ä»·å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13472">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-474f3f159d8f7b605e230e8597072813.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d3034f0db12b7f6f7da0889b76da27c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7df2f8bdad8c495ab14077a036872ba.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Towards-a-Multi-Agent-Vision-Language-System-for-Zero-Shot-Novel-Hazardous-Object-Detection-for-Autonomous-Driving-Safety"><a href="#Towards-a-Multi-Agent-Vision-Language-System-for-Zero-Shot-Novel-Hazardous-Object-Detection-for-Autonomous-Driving-Safety" class="headerlink" title="Towards a Multi-Agent Vision-Language System for Zero-Shot Novel   Hazardous Object Detection for Autonomous Driving Safety"></a>Towards a Multi-Agent Vision-Language System for Zero-Shot Novel   Hazardous Object Detection for Autonomous Driving Safety</h2><p><strong>Authors:Shashank Shriram, Srinivasa Perisetla, Aryan Keskar, Harsha Krishnaswamy, Tonko Emil Westerhof Bossen, Andreas MÃ¸gelmose, Ross Greer</strong></p>
<p>Detecting anomalous hazards in visual data, particularly in video streams, is a critical challenge in autonomous driving. Existing models often struggle with unpredictable, out-of-label hazards due to their reliance on predefined object categories. In this paper, we propose a multimodal approach that integrates vision-language reasoning with zero-shot object detection to improve hazard identification and explanation. Our pipeline consists of a Vision-Language Model (VLM), a Large Language Model (LLM), in order to detect hazardous objects within a traffic scene. We refine object detection by incorporating OpenAIâ€™s CLIP model to match predicted hazards with bounding box annotations, improving localization accuracy. To assess model performance, we create a ground truth dataset by denoising and extending the foundational COOOL (Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete natural language descriptions for hazard annotations. We define a means of hazard detection and labeling evaluation on the extended dataset using cosine similarity. This evaluation considers the semantic similarity between the predicted hazard description and the annotated ground truth for each video. Additionally, we release a set of tools for structuring and managing large-scale hazard detection datasets. Our findings highlight the strengths and limitations of current vision-language-based approaches, offering insights into future improvements in autonomous hazard detection systems. Our models, scripts, and data can be found at <a target="_blank" rel="noopener" href="https://github.com/mi3labucm/COOOLER.git">https://github.com/mi3labucm/COOOLER.git</a> </p>
<blockquote>
<p>åœ¨è§†è§‰æ•°æ®ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†é¢‘æµä¸­æ£€æµ‹å¼‚å¸¸å±é™©ï¼Œå¯¹è‡ªåŠ¨é©¾é©¶æ¥è¯´æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰æ¨¡å‹å¾€å¾€éš¾ä»¥åº”å¯¹ä¸å¯é¢„æµ‹çš„ã€è¶…å‡ºæ ‡ç­¾èŒƒå›´çš„å±é™©ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºé¢„å®šä¹‰çš„å¯¹è±¡ç±»åˆ«ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ–¹æ³•ï¼Œå°†è§†è§‰è¯­è¨€æ¨ç†ä¸é›¶å¯¹è±¡æ£€æµ‹ç›¸ç»“åˆï¼Œä»¥æé«˜å±é™©è¯†åˆ«å’Œè§£é‡Šèƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç®¡é“åŒ…æ‹¬ä¸€ä¸ªè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’Œä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥æ£€æµ‹äº¤é€šåœºæ™¯ä¸­çš„å±é™©ç‰©ä½“ã€‚æˆ‘ä»¬é€šè¿‡èå…¥OpenAIçš„CLIPæ¨¡å‹æ¥æ”¹è¿›å¯¹è±¡æ£€æµ‹ï¼Œå°†é¢„æµ‹çš„å±é™©ä¸è¾¹ç•Œæ¡†æ³¨é‡Šç›¸åŒ¹é…ï¼Œæé«˜å®šä½ç²¾åº¦ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œæˆ‘ä»¬é€šè¿‡å»å™ªå’Œæ‰©å±•åŸºç¡€COOOLï¼ˆæ ‡ç­¾å¤–æŒ‘æˆ˜ï¼‰å¼‚å¸¸æ£€æµ‹åŸºå‡†æ•°æ®é›†ï¼Œåˆ›å»ºäº†ä¸€ä¸ªçœŸå®æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å±é™©æ³¨é‡Šçš„å®Œæ•´è‡ªç„¶è¯­è¨€æè¿°ã€‚æˆ‘ä»¬ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼æ€§æ¥ç¡®å®šæ‰©å±•æ•°æ®é›†çš„å±å®³æ£€æµ‹å’Œæ ‡ç­¾è¯„ä¼°æ–¹æ³•ã€‚è¯¥è¯„ä¼°è€ƒè™‘äº†é¢„æµ‹å±å®³æè¿°ä¸æ¯ä¸ªè§†é¢‘çš„æ³¨é‡ŠçœŸå®å€¼ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†ä¸€ç³»åˆ—å·¥å…·ï¼Œç”¨äºæ„å»ºå’Œç®¡ç†å¤§è§„æ¨¡çš„å±é™©æ£€æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç ”ç©¶çªå‡ºäº†å½“å‰åŸºäºè§†è§‰è¯­è¨€çš„æ–¹æ³•çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œä¸ºæ”¹è¿›æœªæ¥çš„è‡ªåŠ¨é©¾é©¶å±é™©æ£€æµ‹ç³»ç»Ÿæä¾›äº†è§è§£ã€‚æˆ‘ä»¬çš„æ¨¡å‹ã€è„šæœ¬å’Œæ•°æ®å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/mi3labucm/COOOLER.git">https://github.com/mi3labucm/COOOLER.git</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13399v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§å¤šæ¨¡æ€æ–¹æ³•ï¼Œé›†æˆè§†è§‰è¯­è¨€æ¨ç†ä¸é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ï¼Œä»¥æé«˜å±é™©è¯†åˆ«å’Œè§£é‡Šèƒ½åŠ›ã€‚é€šè¿‡æ„å»ºåŒ…å«è§†è§‰è¯­è¨€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹çš„ç®¡é“ï¼Œæ£€æµ‹äº¤é€šåœºæ™¯ä¸­çš„å±é™©ç›®æ ‡ã€‚åˆ©ç”¨OpenAIçš„CLIPæ¨¡å‹æé«˜ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å¯¹åŸºç¡€å¼‚å¸¸æ£€æµ‹åŸºå‡†æ•°æ®é›†COOOLè¿›è¡Œäº†é™å™ªå’Œæ‰©å±•ï¼Œé‡‡ç”¨è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œå±é™©æ ‡æ³¨ï¼Œå¹¶é€šè¿‡ä½™å¼¦ç›¸ä¼¼æ€§å®šä¹‰å±é™©æ£€æµ‹å’Œæ ‡æ³¨è¯„ä¼°æ–¹æ³•ã€‚åŒæ—¶ï¼Œå‘å¸ƒä¸€å¥—å·¥å…·ç”¨äºå¤§è§„æ¨¡å±é™©æ£€æµ‹æ•°æ®é›†çš„ç»“æ„å’Œç®¡ç†ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†å½“å‰åŸºäºè§†è§‰è¯­è¨€çš„æ–¹æ³•çš„ä¼˜ç‚¹å’Œå±€é™æ€§ï¼Œä¸ºè‡ªä¸»å±é™©æ£€æµ‹ç³»ç»Ÿæœªæ¥çš„æ”¹è¿›æä¾›äº†è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»é©¾é©¶ä¸­ï¼Œæ£€æµ‹è§†è§‰æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯è§†é¢‘æµï¼‰ä¸­çš„å¼‚å¸¸å±é™©æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰æ¨¡å‹åœ¨åº”å¯¹ä¸å¯é¢„æµ‹ã€è¶…å‡ºæ ‡ç­¾èŒƒå›´çš„å±å®³æ—¶å¸¸å¸¸é™·å…¥å›°å¢ƒã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æ–¹æ³•ï¼Œç»“åˆäº†è§†è§‰è¯­è¨€æ¨ç†å’Œé›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹æ¥å¢å¼ºå±é™©è¯†åˆ«ä¸è§£é‡Šèƒ½åŠ›ã€‚</li>
<li>é€šè¿‡æ„å»ºåŒ…å«è§†è§‰è¯­è¨€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹çš„ç®¡é“æ¥æ£€æµ‹äº¤é€šåœºæ™¯ä¸­çš„å±é™©ç›®æ ‡ï¼Œæé«˜äº†æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>åˆ©ç”¨OpenAIçš„CLIPæ¨¡å‹å¯¹ç›®æ ‡æ£€æµ‹è¿›è¡Œç»†åŒ–ï¼Œä»¥åŒ¹é…é¢„æµ‹çš„å±å®³ä¸è¾¹ç•Œæ¡†æ ‡æ³¨ï¼Œæé«˜äº†å®šä½ç²¾åº¦ã€‚</li>
<li>é€šè¿‡æ‰©å±•å’Œé™å™ªåŸºç¡€å¼‚å¸¸æ£€æµ‹æ•°æ®é›†COOOLï¼Œå¹¶ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œå±é™©æ ‡æ³¨ï¼Œä»¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>å®šä¹‰äº†ä¸€ç§åŸºäºä½™å¼¦ç›¸ä¼¼æ€§çš„è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è€ƒè™‘äº†é¢„æµ‹çš„å±é™©æè¿°ä¸æ ‡æ³¨çš„åœ°é¢çœŸå®æƒ…å†µä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13399">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7dac3dfd9fd90f7546ebe68ef56e8679.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd14db692e2c921164f062a7955ffbff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2830be15d4a11d776fe76f7dcf8beb2.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Causal-Copilot-An-Autonomous-Causal-Analysis-Agent"><a href="#Causal-Copilot-An-Autonomous-Causal-Analysis-Agent" class="headerlink" title="Causal-Copilot: An Autonomous Causal Analysis Agent"></a>Causal-Copilot: An Autonomous Causal Analysis Agent</h2><p><strong>Authors:Xinyue Wang, Kun Zhou, Wenyi Wu, Har Simrat Singh, Fang Nan, Songyao Jin, Aryan Philip, Saloni Patnaik, Hou Zhu, Shivam Singh, Parjanya Prashant, Qian Shen, Biwei Huang</strong></p>
<p>Causal analysis plays a foundational role in scientific discovery and reliable decision-making, yet it remains largely inaccessible to domain experts due to its conceptual and algorithmic complexity. This disconnect between causal methodology and practical usability presents a dual challenge: domain experts are unable to leverage recent advances in causal learning, while causal researchers lack broad, real-world deployment to test and refine their methods. To address this, we introduce Causal-Copilot, an autonomous agent that operationalizes expert-level causal analysis within a large language model framework. Causal-Copilot automates the full pipeline of causal analysis for both tabular and time-series data â€“ including causal discovery, causal inference, algorithm selection, hyperparameter optimization, result interpretation, and generation of actionable insights. It supports interactive refinement through natural language, lowering the barrier for non-specialists while preserving methodological rigor. By integrating over 20 state-of-the-art causal analysis techniques, our system fosters a virtuous cycle â€“ expanding access to advanced causal methods for domain experts while generating rich, real-world applications that inform and advance causal theory. Empirical evaluations demonstrate that Causal-Copilot achieves superior performance compared to existing baselines, offering a reliable, scalable, and extensible solution that bridges the gap between theoretical sophistication and real-world applicability in causal analysis. </p>
<blockquote>
<p>å› æœåˆ†æåœ¨ç§‘å­¦å‘ç°å’Œå¯é å†³ç­–ä¸­æ‰®æ¼”ç€åŸºç¡€æ€§çš„è§’è‰²ï¼Œç„¶è€Œç”±äºå…¶æ¦‚å¿µæ€§å’Œç®—æ³•å¤æ‚æ€§ï¼Œé¢†åŸŸä¸“å®¶å¾ˆéš¾è·å¾—ç›¸å…³èƒ½åŠ›ã€‚å› æœæ–¹æ³•è®ºä¸å®è·µå¯ç”¨æ€§ä¹‹é—´çš„è„±èŠ‚å¸¦æ¥äº†åŒé‡æŒ‘æˆ˜ï¼šé¢†åŸŸä¸“å®¶æ— æ³•åˆ©ç”¨å› æœå­¦ä¹ æ–¹é¢çš„æœ€æ–°è¿›å±•ï¼Œè€Œå› æœç ”ç©¶è€…ç¼ºä¹å¹¿æ³›çš„ç°å®ä¸–ç•Œéƒ¨ç½²æ¥æµ‹è¯•å’Œå®Œå–„ä»–ä»¬çš„æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å› æœåŠ©æ‰‹ï¼ˆCausal-Copilotï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ä¸‹å®ç°ä¸“å®¶çº§å› æœåˆ†æçš„è‡ªä¸»ä»£ç†ã€‚å› æœåŠ©æ‰‹è‡ªåŠ¨åŒ–äº†å› æœåˆ†æçš„å®Œæ•´æµç¨‹ï¼Œæ— è®ºæ˜¯è¡¨æ ¼æ•°æ®è¿˜æ˜¯æ—¶é—´åºåˆ—æ•°æ®ï¼ŒåŒ…æ‹¬å› æœå‘ç°ã€å› æœæ¨æ–­ã€ç®—æ³•é€‰æ‹©ã€è¶…å‚æ•°ä¼˜åŒ–ã€ç»“æœè§£è¯»å’Œå¯å®æ–½æ´å¯ŸåŠ›çš„ç”Ÿæˆã€‚å®ƒæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œäº¤äº’å¼æ”¹è¿›ï¼Œé™ä½äº†éä¸“ä¸šäººå£«çš„é—¨æ§›ï¼ŒåŒæ—¶ä¿æŒäº†æ–¹æ³•è®ºä¸Šçš„ä¸¥è°¨æ€§ã€‚é€šè¿‡é›†æˆè¶…è¿‡20é¡¹æœ€å…ˆè¿›çš„å› æœåˆ†ææŠ€æœ¯ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿå½¢æˆäº†ä¸€ä¸ªè‰¯æ€§å¾ªç¯â€”â€”æ‰©å¤§é¢†åŸŸä¸“å®¶å¯¹é«˜çº§å› æœæ–¹æ³•çš„è®¿é—®æƒé™ï¼ŒåŒæ—¶ç”Ÿæˆä¸°å¯Œçš„ç°å®ä¸–ç•Œåº”ç”¨ï¼Œä¸ºå› æœç†è®ºæä¾›ä¿¡æ¯å’Œæ¨åŠ¨å…¶å‘å±•ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œç›¸æ¯”ç°æœ‰åŸºå‡†æµ‹è¯•ï¼Œå› æœåŠ©æ‰‹å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œæä¾›äº†ä¸€ä¸ªå¯é ã€å¯æ‰©å±•å’Œå¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œç¼©å°äº†ç†è®ºå¤æ‚æ€§å’Œç°å®ä¸–ç•Œä¸­å› æœåˆ†æé€‚ç”¨æ€§ä¹‹é—´çš„å·®è·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13263v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å› æœåˆ†æåœ¨ç§‘ç ”å’Œå†³ç­–ä¸­çš„é‡è¦æ€§ï¼Œä½†ä¸“å®¶éš¾ä»¥åˆ©ç”¨å…ˆè¿›çš„å› æœå­¦ä¹ æ–¹æ³•ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæ¨å‡ºCausal-Copilotç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå®ç°äº†è‡ªä¸»åŒ–çš„å› æœåˆ†ææµç¨‹ï¼Œæ¶µç›–å› æœå‘ç°ã€æ¨æ–­ã€ç®—æ³•é€‰æ‹©ç­‰ã€‚é€šè¿‡æ•´åˆå¤šç§å‰æ²¿å› æœåˆ†ææŠ€æœ¯ï¼Œè¯¥ç³»ç»Ÿä¸ºé¢†åŸŸä¸“å®¶æä¾›äº†ä¸°å¯Œçš„å®é™…åº”ç”¨åœºæ™¯ï¼ŒåŒæ—¶æ¨åŠ¨å› æœç†è®ºçš„å‘å±•ã€‚å®è¯è¯„ä¼°æ˜¾ç¤ºï¼ŒCausal-Copilotæ€§èƒ½å“è¶Šï¼Œå…·æœ‰å¯é æ€§ã€å¯æ‰©å±•æ€§å’Œæ‰©å±•æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å› æœåˆ†æçš„é‡è¦æ€§ï¼šå¯¹äºç§‘ç ”å‘ç°å’Œå¯é å†³ç­–æœ‰ç€é‡è¦ä½œç”¨ã€‚</li>
<li>å½“å‰æŒ‘æˆ˜ï¼šå› æœåˆ†æçš„ç†è®ºå’Œç®—æ³•å¤æ‚æ€§å¯¼è‡´ä¸“å®¶éš¾ä»¥åˆ©ç”¨æœ€æ–°è¿›å±•ã€‚</li>
<li>Causal-Copilotç³»ç»Ÿä»‹ç»ï¼šè‡ªä¸»å®Œæˆå› æœåˆ†æå…¨æµç¨‹ï¼Œæ”¯æŒè¡¨æ ¼å’Œæ—¶åºæ•°æ®ã€‚</li>
<li>ç³»ç»ŸåŠŸèƒ½ï¼šåŒ…æ‹¬å› æœå‘ç°ã€æ¨æ–­ã€ç®—æ³•é€‰æ‹©ç­‰ï¼Œæä¾›ç»“æœè§£è¯»å’Œè¡ŒåŠ¨å»ºè®®ã€‚</li>
<li>è‡ªç„¶è¯­è¨€äº¤äº’ï¼šæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œç²¾ç»†åŒ–è°ƒæ•´ï¼Œé™ä½éä¸“ä¸šäººå£«é—¨æ§›ã€‚</li>
<li>ç³»ç»Ÿæ•´åˆå¤šç§å‰æ²¿æŠ€æœ¯ï¼šä¿ƒè¿›å› æœåˆ†ææ–¹æ³•åœ¨é¢†åŸŸä¸“å®¶ä¸­çš„æ™®åŠå’Œå› æœç†è®ºçš„å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13263">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-75dd2cd77486c59ad36bc6ed6d268303.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f99dfd2abfac9a7e4bd0e837383fc470.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GUI-R1-A-Generalist-R1-Style-Vision-Language-Action-Model-For-GUI-Agents"><a href="#GUI-R1-A-Generalist-R1-Style-Vision-Language-Action-Model-For-GUI-Agents" class="headerlink" title="GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI   Agents"></a>GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI   Agents</h2><p><strong>Authors:Run Luo, Lu Wang, Wanwei He, Xiaobo Xia</strong></p>
<p>Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \name achieves superior performance using only 0.02% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks. </p>
<blockquote>
<p>ç°æœ‰æ„å»ºå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†çš„å·¥ä½œå¤§å¤šä¾èµ–äºåœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ä¸Šé‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-tuningï¼‰çš„è®­ç»ƒèŒƒå¼ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•ä¸ä»…è¦æ±‚å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œä¸”åœ¨ç†è§£GUIæˆªå›¾å’Œæ³›åŒ–åˆ°æœªè§è¿‡çš„ç•Œé¢æ–¹é¢ä¹Ÿå­˜åœ¨å›°éš¾ã€‚è¿™ä¸€é—®é¢˜æå¤§åœ°é™åˆ¶äº†å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨é«˜çº§ä»»åŠ¡ä¸­ã€‚</p>
</blockquote>
<p>å—å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆå¦‚DeepSeek-R1ï¼‰ä¸­çš„å¼ºåŒ–å¾®è°ƒï¼ˆReinforcement Fine-Tuningï¼ŒRFTï¼‰çš„å¯å‘ï¼Œè¯¥å¼ºåŒ–å¾®è°ƒæœ‰æ•ˆæé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç°å®ä¸–ç•Œç¯å¢ƒä¸­çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºåä¸ºâ€œXXXâ€çš„æ¡†æ¶ï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨é€šè¿‡ç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡æé«˜LVLMåœ¨ç°å®ä¸–ç•Œä¸­é«˜çº§ä»»åŠ¡åœºæ™¯çš„GUIèƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚é€šè¿‡åˆ©ç”¨è·¨å¤šä¸ªå¹³å°ï¼ˆåŒ…æ‹¬Windowsã€Linuxã€MacOSã€Androidå’ŒWebï¼‰çš„å°é‡ç²¾å¿ƒæŒ‘é€‰çš„é«˜è´¨é‡æ•°æ®ï¼Œå¹¶é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGroup Relative Policy Optimizationï¼ŒGRPOï¼‰ç­‰ç­–ç•¥ä¼˜åŒ–ç®—æ³•æ¥æ›´æ–°æ¨¡å‹ï¼Œâ€œXXXâ€ä»…ä½¿ç”¨0.02%ï¼ˆ3K vs. 13Mï¼‰çš„æ•°æ®ä¾¿å®ç°äº†ä¼˜äºOS-Atlasç­‰ç°æœ‰å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ï¼Œè·¨è¶Šæ¶µç›–ä¸‰ä¸ªä¸åŒå¹³å°ï¼ˆç§»åŠ¨ã€æ¡Œé¢å’Œç½‘é¡µï¼‰çš„å…«ä¸ªåŸºå‡†æµ‹è¯•ã€‚è¿™äº›ç»“æœè¯æ˜äº†åŸºäºç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡çš„å¼ºåŒ–å­¦ä¹ åœ¨æå‡LVLMæ‰§è¡Œç°å®ä¸–ç•ŒGUIä»£ç†ä»»åŠ¡çš„èƒ½åŠ›æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10458v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸º\nameçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡ï¼Œæé«˜å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨çœŸå®ä¸–ç•Œé«˜çº§ä»»åŠ¡åœºæ™¯ä¸‹çš„GUIèƒ½åŠ›ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è·¨å¤šä¸ªå¹³å°çš„å°é‡é«˜è´¨é‡æ•°æ®ï¼Œé‡‡ç”¨ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¥æ›´æ–°æ¨¡å‹ã€‚ç›¸è¾ƒäºå…¶ä»–æ–¹æ³•ï¼Œ\nameåœ¨è·¨è¶Šä¸‰ä¸ªä¸åŒå¹³å°çš„å…«ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨0.02%çš„æ•°æ®ä¾¿å®ç°äº†å“è¶Šæ€§èƒ½ã€‚è¿™è¯æ˜äº†åŸºäºç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡çš„å¼ºåŒ–å­¦ä¹ åœ¨æå‡LVLMsæ‰§è¡ŒçœŸå®ä¸–ç•ŒGUIä»»åŠ¡èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰GUIä»£ç†æ„å»ºä¸»è¦ä¾èµ–äºåœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸Šé‡‡ç”¨ç›‘ç£å¾®è°ƒè®­ç»ƒèŒƒå¼ã€‚</li>
<li>æ­¤æ–¹æ³•éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”åœ¨ç†è§£GUIæˆªå›¾å’Œæ³›åŒ–åˆ°æœªè§è¿‡çš„ç•Œé¢æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>\nameæ˜¯ç¬¬ä¸€ä¸ªä¸ºLVLMsè®¾è®¡çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å…¶åœ¨çœŸå®ä¸–ç•Œé«˜çº§ä»»åŠ¡åœºæ™¯ä¸‹çš„GUIèƒ½åŠ›ã€‚</li>
<li>\nameé€šè¿‡ç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡ï¼Œåˆ©ç”¨è·¨å¤šä¸ªå¹³å°çš„å°é‡é«˜è´¨é‡æ•°æ®ã€‚</li>
<li>\nameé‡‡ç”¨ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œæ¥æ›´æ–°æ¨¡å‹ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œ\nameä½¿ç”¨æå°‘çš„æ•°æ®é‡ï¼ˆ0.02%ï¼‰å®ç°äº†å“è¶Šæ€§èƒ½ï¼Œä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-40e44cce157ab734b1ce7aa7a91d195b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8b83a33fe04aa5f478735789bdd633d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dc1378358a130b9ffbb33425047048d0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DocAgent-A-Multi-Agent-System-for-Automated-Code-Documentation-Generation"><a href="#DocAgent-A-Multi-Agent-System-for-Automated-Code-Documentation-Generation" class="headerlink" title="DocAgent: A Multi-Agent System for Automated Code Documentation   Generation"></a>DocAgent: A Multi-Agent System for Automated Code Documentation   Generation</h2><p><strong>Authors:Dayu Yang, Antoine Simoulin, Xin Qian, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Grey Yang</strong></p>
<p>High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent collaborative system using topological code processing for incremental context building. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then collaboratively generate documentation. We also propose a multi-faceted evaluation framework assessing Completeness, Helpfulness, and Truthfulness. Comprehensive experiments show DocAgent significantly outperforms baselines consistently. Our ablation study confirms the vital role of the topological processing order. DocAgent offers a robust approach for reliable code documentation generation in complex and proprietary repositories. </p>
<blockquote>
<p>é«˜è´¨é‡çš„ä»£ç æ–‡æ¡£å¯¹è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•å¸¸å¸¸äº§ç”Ÿä¸å®Œæ•´ã€æ— å¸®åŠ©æˆ–äº‹å®é”™è¯¯çš„è¾“å‡ºã€‚æˆ‘ä»¬å¼•å…¥äº†DocAgentï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ‹“æ‰‘ä»£ç å¤„ç†çš„æ–°å‹å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œç”¨äºå¢é‡æ„å»ºä¸Šä¸‹æ–‡ã€‚ä¸“ç”¨æ™ºèƒ½ä½“ï¼ˆé˜…è¯»è€…ã€æœç´¢è€…ã€ç¼–å†™è€…ã€éªŒè¯è€…ã€åè°ƒè€…ï¼‰ååŒç”Ÿæˆæ–‡æ¡£ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªå¤šå…ƒåŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€å¸®åŠ©æ€§å’ŒçœŸå®æ€§ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒDocAgentæŒç»­ä¸”æ˜¾è‘—åœ°ä¼˜äºåŸºçº¿ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶è¯å®äº†æ‹“æ‰‘å¤„ç†é¡ºåºçš„é‡è¦ä½œç”¨ã€‚DocAgentä¸ºå¤æ‚å’Œä¸“æœ‰å­˜å‚¨åº“ä¸­çš„å¯é ä»£ç æ–‡æ¡£ç”Ÿæˆæä¾›äº†ç¨³å¥çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08725v2">PDF</a> Public Repo: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/DocAgent">https://github.com/facebookresearch/DocAgent</a></p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºäººå·¥æ™ºèƒ½æ—¶ä»£çš„éœ€æ±‚ï¼Œé«˜è´¨é‡ä»£ç æ–‡æ¡£åœ¨è½¯ä»¶å¼€å‘ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€äº§ç”Ÿä¸å®Œæ•´ã€æ— å¸®åŠ©æˆ–äº‹å®é”™è¯¯çš„è¾“å‡ºã€‚æˆ‘ä»¬æ¨å‡ºDocAgentï¼Œä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œé‡‡ç”¨æ‹“æ‰‘ä»£ç å¤„ç†è¿›è¡Œå¢é‡ä¸Šä¸‹æ–‡æ„å»ºã€‚é€šè¿‡ä¸“é—¨çš„æ™ºèƒ½ä½“ï¼ˆé˜…è¯»å™¨ã€æœç´¢å™¨ã€ç¼–å†™å™¨ã€éªŒè¯å™¨ã€åè°ƒå™¨ï¼‰ååŒç”Ÿæˆæ–‡æ¡£ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªå¤šæ–¹é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€æœ‰ç”¨æ€§å’ŒçœŸå®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDocAgentåœ¨å„ä¸ªæ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶è¯å®äº†æ‹“æ‰‘å¤„ç†é¡ºåºçš„é‡è¦æ€§ã€‚DocAgentä¸ºå¤æ‚å’Œä¸“æœ‰å­˜å‚¨åº“ä¸­çš„å¯é ä»£ç æ–‡æ¡£ç”Ÿæˆæä¾›äº†ç¨³å¥çš„æ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>é«˜è´¨é‡ä»£ç æ–‡æ¡£åœ¨è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ã€‚</li>
<li>ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆä»£ç æ–‡æ¡£çš„æŒ‘æˆ˜ï¼šè¾“å‡ºå¯èƒ½ä¸å®Œæ•´ã€æ— å¸®åŠ©æˆ–å­˜åœ¨äº‹å®é”™è¯¯ã€‚</li>
<li>DocAgentï¼šä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œé€šè¿‡æ‹“æ‰‘ä»£ç å¤„ç†è¿›è¡Œå¢é‡ä¸Šä¸‹æ–‡æ„å»ºæ¥ç”Ÿæˆæ–‡æ¡£ã€‚</li>
<li>DocAgentåŒ…å«å¤šä¸ªä¸“é—¨æ™ºèƒ½ä½“ï¼Œå¦‚é˜…è¯»å™¨ã€æœç´¢å™¨ã€ç¼–å†™å™¨ã€éªŒè¯å™¨å’Œåè°ƒå™¨ã€‚</li>
<li>DocAgenté‡‡ç”¨å¤šæ–¹é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°æ–‡æ¡£çš„å®Œæ•´æ€§ã€æœ‰ç”¨æ€§å’ŒçœŸå®æ€§ã€‚</li>
<li>å®éªŒè¯æ˜DocAgentåœ¨å„æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ¶ˆèç ”ç©¶è¯å®äº†æ‹“æ‰‘å¤„ç†é¡ºåºåœ¨DocAgentæ€§èƒ½ä¸­çš„é‡è¦ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08725">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c961904b2d4b0a387b2ed18b9a2add40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fd0534526e9f43e1ed4683ac785090c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-933e5dcbc145e1cb1361f03356dd2b34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28680bc575a8c0f69c2ab5c8868cc5f5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dcf3626f73471bc8ff67f34fdec24a66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cae1fe7424320522f3e73e14023dd673.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AgentCF-Memory-enhanced-LLM-based-Agents-for-Popularity-aware-Cross-domain-Recommendations"><a href="#AgentCF-Memory-enhanced-LLM-based-Agents-for-Popularity-aware-Cross-domain-Recommendations" class="headerlink" title="AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware   Cross-domain Recommendations"></a>AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware   Cross-domain Recommendations</h2><p><strong>Authors:Jiahao Liu, Shengkang Gu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Tun Lu, Li Shang, Ning Gu</strong></p>
<p>LLM-based user agents, which simulate user interaction behavior, are emerging as a promising approach to enhancing recommender systems. In real-world scenarios, usersâ€™ interactions often exhibit cross-domain characteristics and are influenced by others. However, the memory design in current methods causes user agents to introduce significant irrelevant information during decision-making in cross-domain scenarios and makes them unable to recognize the influence of other usersâ€™ interactions, such as popularity factors. To tackle this issue, we propose a dual-layer memory architecture combined with a two-step fusion mechanism. This design avoids irrelevant information during decision-making while ensuring effective integration of cross-domain preferences. We also introduce the concepts of interest groups and group-shared memory to better capture the influence of popularity factors on users with similar interests. Comprehensive experiments validate the effectiveness of AgentCF++. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/jhliu0807/AgentCF-plus">https://github.com/jhliu0807/AgentCF-plus</a>. </p>
<blockquote>
<p>åŸºäºLLMçš„ç”¨æˆ·ä»£ç†æ¨¡æ‹Ÿç”¨æˆ·äº¤äº’è¡Œä¸ºï¼Œæ­£åœ¨æˆä¸ºå¢å¼ºæ¨èç³»ç»Ÿçš„ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ã€‚åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œç”¨æˆ·çš„äº¤äº’å¾€å¾€è¡¨ç°å‡ºè·¨åŸŸç‰¹æ€§å¹¶å—åˆ°ä»–äººçš„å½±å“ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•çš„å†…å­˜è®¾è®¡å¯¼è‡´ç”¨æˆ·ä»£ç†åœ¨è·¨åŸŸåœºæ™¯ä¸­çš„å†³ç­–è¿‡ç¨‹ä¸­å¼•å…¥äº†å¤§é‡æ— å…³ä¿¡æ¯ï¼Œå¹¶ä¸”æ— æ³•è¯†åˆ«å…¶ä»–ç”¨æˆ·äº¤äº’çš„å½±å“ï¼Œä¾‹å¦‚æµè¡Œå› ç´ ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒå±‚å†…å­˜æ¶æ„ï¼Œå¹¶ç»“åˆäº†ä¸¤æ­¥èåˆæœºåˆ¶ã€‚è¿™ä¸€è®¾è®¡é¿å…äº†å†³ç­–è¿‡ç¨‹ä¸­çš„æ— å…³ä¿¡æ¯ï¼ŒåŒæ—¶ç¡®ä¿äº†è·¨åŸŸåå¥½çš„æœ‰æ•ˆèåˆã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†å…´è¶£å°ç»„å’Œç¾¤ç»„å…±äº«å†…å­˜çš„æ¦‚å¿µï¼Œä»¥æ›´å¥½åœ°æ•æ‰ç±»ä¼¼å…´è¶£ç”¨æˆ·å¯¹æµè¡Œå› ç´ çš„å½±å“ã€‚å…¨é¢çš„å®éªŒéªŒè¯äº†AgentCF++çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/jhliu0807/AgentCF-plus%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/jhliu0807/AgentCF-plusè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13843v2">PDF</a> Accepted by SIGIR 2025, 6 pages</p>
<p><strong>Summary</strong></p>
<p>åŸºäºLLMçš„ç”¨æˆ·ä»£ç†æ¨¡æ‹Ÿç”¨æˆ·äº¤äº’è¡Œä¸ºï¼Œä¸ºæé«˜æ¨èç³»ç»Ÿæ€§èƒ½å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•ä¸­çš„å†…å­˜è®¾è®¡åœ¨è·¨åŸŸåœºæ™¯ä¸­å¯¼è‡´ç”¨æˆ·ä»£ç†å¼•å…¥å¤§é‡æ— å…³ä¿¡æ¯ï¼Œä¸”æ— æ³•è¯†åˆ«å…¶ä»–ç”¨æˆ·äº¤äº’çš„å½±å“ï¼Œå¦‚æµè¡Œå› ç´ ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºç»“åˆåŒå±‚å†…å­˜æ¶æ„ä¸ä¸¤æ­¥èåˆæœºåˆ¶çš„è®¾è®¡ï¼ŒåŒæ—¶å¼•å…¥å…´è¶£ç¾¤ä½“å’Œç¾¤ç»„å…±äº«å†…å­˜æ¦‚å¿µï¼Œä»¥æ›´å¥½åœ°æ•æ‰æµè¡Œå› ç´ å¯¹å…·æœ‰ç›¸ä¼¼å…´è¶£ç”¨æˆ·çš„å½±å“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based user agentså¢å¼ºæ¨èç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>å½“å‰å†…å­˜è®¾è®¡åœ¨è·¨åŸŸåœºæ™¯ä¸­å¼•å…¥æ— å…³ä¿¡æ¯ã€‚</li>
<li>æ–°æ–¹æ³•èƒ½æœ‰æ•ˆé¿å…å†³ç­–è¿‡ç¨‹ä¸­çš„æ— å…³ä¿¡æ¯å¹²æ‰°ã€‚</li>
<li>æå‡ºçš„åŒå±‚å†…å­˜æ¶æ„ä¸ä¸¤æ­¥èåˆæœºåˆ¶èƒ½ç¡®ä¿è·¨åŸŸåå¥½çš„æœ‰æ•ˆèåˆã€‚</li>
<li>å…´è¶£ç¾¤ä½“å’Œç¾¤ç»„å…±äº«å†…å­˜æ¦‚å¿µèƒ½æ›´å¥½åœ°æ•æ‰æµè¡Œå› ç´ å¯¹ç›¸ä¼¼å…´è¶£ç”¨æˆ·çš„å½±å“ã€‚</li>
<li>AgentCF++æ–¹æ³•ç»è¿‡ç»¼åˆå®éªŒéªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13843">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f6b5f604f383a06df6a0ab604d6f581c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-834923f9832c96d38d657e75de017349.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22bf4fe45e64f23d8ceb95dd9e663956.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="A-MEM-Agentic-Memory-for-LLM-Agents"><a href="#A-MEM-Agentic-Memory-for-LLM-Agents" class="headerlink" title="A-MEM: Agentic Memory for LLM Agents"></a>A-MEM: Agentic Memory for LLM Agents</h2><p><strong>Authors:Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, Yongfeng Zhang</strong></p>
<p>While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systemsâ€™ fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at <a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory">https://github.com/WujiangXu/AgenticMemory</a>, while the source code of agentic memory system is available at <a target="_blank" rel="noopener" href="https://github.com/agiresearch/A-mem">https://github.com/agiresearch/A-mem</a>. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨å·¥å…·æ¥å®Œæˆå¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ï¼Œä½†å®ƒä»¬éœ€è¦è®°å¿†ç³»ç»Ÿæ¥åˆ©ç”¨å†å²ç»éªŒã€‚å½“å‰çš„è®°å¿†ç³»ç»Ÿè™½ç„¶å…·å¤‡äº†åŸºæœ¬çš„å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½ï¼Œä½†ç¼ºä¹å¤æ‚çš„è®°å¿†ç»„ç»‡ï¼Œå°½ç®¡æœ€è¿‘å°è¯•å¼•å…¥äº†å›¾æ•°æ®åº“ã€‚æ­¤å¤–ï¼Œè¿™äº›ç³»ç»Ÿçš„å›ºå®šæ“ä½œå’Œç»“æ„é™åˆ¶äº†å®ƒä»¬åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºLLMä»£ç†çš„æ–°å‹ä»£ç†è®°å¿†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä»¥ä»£ç†çš„æ–¹å¼åŠ¨æ€ç»„ç»‡è®°å¿†ã€‚æˆ‘ä»¬éµå¾ªZettelkastenæ–¹æ³•çš„åŸºæœ¬åŸåˆ™ï¼Œè®¾è®¡äº†ä¸€ä¸ªè®°å¿†ç³»ç»Ÿï¼Œé€šè¿‡åŠ¨æ€ç´¢å¼•å’Œé“¾æ¥åˆ›å»ºç›¸äº’å…³è”çš„çŸ¥è¯†ç½‘ç»œã€‚æ¯å½“æ·»åŠ æ–°è®°å¿†æ—¶ï¼Œæˆ‘ä»¬ä¼šç”Ÿæˆä¸€ä¸ªåŒ…å«å¤šä¸ªç»“æ„åŒ–å±æ€§çš„ç»¼åˆç¬”è®°ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡æè¿°ã€å…³é”®è¯å’Œæ ‡ç­¾ã€‚ç„¶åï¼Œç³»ç»Ÿåˆ†æå†å²è®°å¿†ä»¥è¯†åˆ«ç›¸å…³è¿æ¥ï¼Œåœ¨å­˜åœ¨æœ‰æ„ä¹‰çš„ç›¸ä¼¼æ€§æ—¶å»ºç«‹é“¾æ¥ã€‚æ­¤å¤–ï¼Œè¿™ä¸ªè¿‡ç¨‹ä½¿è®°å¿†å¾—ä»¥è¿›åŒ–â€”â€”æ–°è®°å¿†çš„èå…¥å¯èƒ½ä¼šè§¦å‘å¯¹ç°æœ‰å†å²è®°å¿†çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºå’Œå±æ€§çš„æ›´æ–°ï¼Œä½¿è®°å¿†ç½‘ç»œèƒ½å¤Ÿä¸æ–­åœ°è°ƒæ•´å…¶ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†Zettelkastençš„ç»“æ„åŒ–ç»„ç»‡åŸåˆ™ä¸ä»£ç†é©±åŠ¨å†³ç­–çš„çµæ´»æ€§ï¼Œä»è€Œå®ç°äº†æ›´å…·é€‚åº”æ€§å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è®°å¿†ç®¡ç†ã€‚åœ¨å…­ä¸ªåŸºç¡€æ¨¡å‹ä¸Šçš„å®è¯å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„æœ€å…ˆè¿›çš„åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰æ˜¾è‘—çš„æ”¹è¿›ã€‚æ€§èƒ½è¯„ä¼°çš„æºä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory%E4%B8%8A%E6%89%BE%E5%88%B0%EF%BC%8C%E8%80%8C%E4%BB%A3%E7%90%86%E8%AE%B0%E5%BF%86%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%BA%90%E4%BB%A3%E7%A0%81%E5%88%99%E5%8F%AF%E5%9C%A8https://github.com/agiresearch/A-mem%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82]">https://github.com/WujiangXu/AgenticMemoryä¸Šæ‰¾åˆ°ï¼Œè€Œä»£ç†è®°å¿†ç³»ç»Ÿçš„æºä»£ç åˆ™å¯åœ¨https://github.com/agiresearch/A-memä¸Šæ‰¾åˆ°ã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12110v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†å¤æ‚ç°å®ä»»åŠ¡æ—¶èƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨å·¥å…·ï¼Œä½†ä¹Ÿéœ€è¦è®°å¿†ç³»ç»Ÿæ¥å€Ÿé‰´å†å²ç»éªŒã€‚å½“å‰è®°å¿†ç³»ç»Ÿå¯å®ç°åŸºæœ¬å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½ï¼Œä½†ç¼ºä¹é«˜çº§è®°å¿†ç»„ç»‡ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸ºLLMä»£ç†è®¾è®¡çš„æ–°å‹è®°å¿†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€åœ°ä»¥ä»£ç†æ–¹å¼ç»„ç»‡è®°å¿†ã€‚å‚ç…§Zettelkastenæ–¹æ³•çš„åŸºæœ¬åŸåˆ™ï¼Œæˆ‘ä»¬è®¾è®¡äº†çŸ¥è¯†ç½‘ç»œé—´çš„äº’è”ï¼Œé€šè¿‡åŠ¨æ€ç´¢å¼•å’Œé“¾æ¥å®ç°ã€‚æ¯å½“æ·»åŠ æ–°è®°å¿†æ—¶ï¼Œç³»ç»Ÿä¼šç”ŸæˆåŒ…å«å¤šä¸ªç»“æ„åŒ–å±æ€§çš„ç»¼åˆç¬”è®°ï¼Œå¦‚ä¸Šä¸‹æ–‡æè¿°ã€å…³é”®è¯å’Œæ ‡ç­¾ã€‚ç„¶ååˆ†æå†å²è®°å¿†ä»¥è¯†åˆ«ç›¸å…³è”ç³»ï¼Œåœ¨å­˜åœ¨æœ‰æ„ä¹‰çš„ç›¸ä¼¼æ€§æ—¶å»ºç«‹é“¾æ¥ã€‚æ­¤å¤–ï¼Œè¿™ä¸€è¿‡ç¨‹ä½¿è®°å¿†å¾—ä»¥å‘å±•â€”â€”éšç€æ–°è®°å¿†çš„èå…¥ï¼Œå®ƒä»¬å¯ä»¥è§¦å‘å¯¹ç°æœ‰å†å²è®°å¿†çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºå’Œå±æ€§çš„æ›´æ–°ï¼Œä½¿è®°å¿†ç½‘ç»œä¸æ–­ç²¾ç‚¼å…¶ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†Zettelkastençš„ç»“æ„åŒ–ç»„ç»‡åŸåˆ™å’Œä»£ç†é©±åŠ¨çš„å†³ç­–çµæ´»æ€§ï¼Œå®ç°äº†æ›´é€‚åº”ä¸Šä¸‹æ–‡çš„è®°å¿†ç®¡ç†ã€‚å®è¯å®éªŒè¡¨æ˜ï¼Œåœ¨å…­ä¸ªåŸºç¡€æ¨¡å‹ä¸Šï¼Œä¸ç°æœ‰æœ€ä½³åŸºçº¿ç›¸æ¯”æœ‰æ˜æ˜¾æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶éœ€è¦è®°å¿†ç³»ç»Ÿæ¥å€Ÿé‰´å†å²ç»éªŒã€‚</li>
<li>å½“å‰è®°å¿†ç³»ç»Ÿç¼ºä¹é«˜çº§è®°å¿†ç»„ç»‡åŠŸèƒ½ã€‚</li>
<li>æ–°æå‡ºçš„ä»£ç†è®°å¿†ç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€åœ°ä»¥ä»£ç†æ–¹å¼ç»„ç»‡è®°å¿†ã€‚</li>
<li>ç³»ç»Ÿå‚ç…§Zettelkastenæ–¹æ³•è®¾è®¡ï¼Œå®ç°çŸ¥è¯†ç½‘ç»œé—´çš„äº’è”ã€‚</li>
<li>æ–°è®°å¿†é€šè¿‡ç”ŸæˆåŒ…å«ç»“æ„åŒ–å±æ€§çš„ç»¼åˆç¬”è®°æ¥æ·»åŠ åˆ°ç³»ç»Ÿä¸­ã€‚</li>
<li>ç³»ç»Ÿåˆ†æå†å²è®°å¿†ä»¥è¯†åˆ«ç›¸å…³è”ç³»ï¼Œå¹¶å»ºç«‹é“¾æ¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12110">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3311fe515375cf837dab7c870ee2d06b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43f60cff38e4f45d95c7cc2c7568c14b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d4a3e95cf2de0ecf3b48d938d5aff05.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AgentHarm-A-Benchmark-for-Measuring-Harmfulness-of-LLM-Agents"><a href="#AgentHarm-A-Benchmark-for-Measuring-Harmfulness-of-LLM-Agents" class="headerlink" title="AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents"></a>AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents</h2><p><strong>Authors:Maksym Andriushchenko, Alexandra Souly, Mateusz Dziemian, Derek Duenas, Maxwell Lin, Justin Wang, Dan Hendrycks, Andy Zou, Zico Kolter, Matt Fredrikson, Eric Winsor, Jerome Wynne, Yarin Gal, Xander Davies</strong></p>
<p>The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents â€“ which use external tools and can execute multi-stage tasks â€“ may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly compliant with malicious agent requests without jailbreaking, (2) simple universal jailbreak templates can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ai-safety-institute/AgentHarm">https://huggingface.co/datasets/ai-safety-institute/AgentHarm</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æŠµå¾¡è¶Šç‹±æ”»å‡»ï¼ˆç”¨æˆ·è®¾è®¡æç¤ºä»¥ç»•è¿‡å®‰å…¨æªæ–½å¹¶æ»¥ç”¨æ¨¡å‹åŠŸèƒ½ï¼‰çš„ç¨³å¥æ€§ï¼Œä¸»è¦æ˜¯é’ˆå¯¹ä½œä¸ºç®€å•èŠå¤©æœºå™¨äººçš„LLMsè¿›è¡Œç ”ç©¶ã€‚åŒæ—¶ï¼Œæ»¥ç”¨èƒ½å¤Ÿä½¿ç”¨å¤–éƒ¨å·¥å…·å¹¶æ‰§è¡Œå¤šé˜¶æ®µä»»åŠ¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼ˆLLM agentsï¼‰å¯èƒ½ä¼šå¸¦æ¥æ›´å¤§çš„é£é™©ï¼Œä½†å®ƒä»¬çš„ç¨³å¥æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºäº†ä¿ƒè¿›å…³äºLLMä»£ç†æ»¥ç”¨çš„ç ”ç©¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œåä¸ºAgentHarmã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«ä¸€ç»„åŒ…å«æ˜ç¡®æ¶æ„ä»£ç†ä»»åŠ¡çš„å¤šæ ·åŒ–æ•°æ®é›†ï¼ˆå…±åŒ…å«110é¡¹ä»»åŠ¡ï¼Œç»è¿‡å¢å¼ºå¤„ç†åè¾¾åˆ°440é¡¹ï¼‰ï¼Œæ¶µç›–åŒ…æ‹¬æ¬ºè¯ˆã€ç½‘ç»œçŠ¯ç½ªå’Œéªšæ‰°åœ¨å†…çš„11ç§å±å®³ç±»åˆ«ã€‚é™¤äº†è¡¡é‡æ¨¡å‹æ˜¯å¦ä¼šæ‹’ç»æœ‰å®³ä»£ç†è¯·æ±‚ä¹‹å¤–ï¼Œè¦åœ¨AgentHarmä¸Šè·å¾—å¥½æˆç»©ï¼Œè¿˜è¦æ±‚è¶Šç‹±åçš„ä»£ç†èƒ½å¤Ÿåœ¨å®Œæˆå¤šé˜¶æ®µä»»åŠ¡æ—¶ä¿æŒå…¶åŠŸèƒ½ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸€ç³»åˆ—é¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶å‘ç°ï¼šï¼ˆ1ï¼‰é¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ²¡æœ‰è¶Šç‹±çš„æƒ…å†µä¸‹ï¼Œä¼šå‡ºäººæ„æ–™åœ°éµä»æ¶æ„ä»£ç†çš„è¯·æ±‚ï¼›ï¼ˆ2ï¼‰ç®€å•çš„é€šç”¨è¶Šç‹±æ¨¡æ¿å¯ä»¥é€‚åº”æœ‰æ•ˆåœ°è¶Šç‹±ä»£ç†ï¼›ï¼ˆ3ï¼‰è¿™äº›è¶Šç‹±è¡Œä¸ºèƒ½å¤Ÿä¿æŒè¿è´¯ä¸”æ¶æ„çš„å¤šé˜¶æ®µä»£ç†è¡Œä¸ºå¹¶ä¿ç•™æ¨¡å‹åŠŸèƒ½ã€‚ä¸ºäº†æ–¹ä¾¿å¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†è¿›è¡Œç®€å•å¯é çš„æ”»å‡»å’Œé˜²å¾¡è¯„ä¼°ï¼Œæˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/ai-safety-institute/AgentHarm%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E4%BA%86AgentHarm%E3%80%82">https://huggingface.co/datasets/ai-safety-institute/AgentHarmä¸Šå…¬å¼€å‘å¸ƒäº†AgentHarmã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.09024v3">PDF</a> Accepted at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹è¶Šç‹±æ”»å‡»ï¼ˆjailbreak attacksï¼‰çš„ç¨³å¥æ€§ä¸€ç›´æ˜¯ç ”ç©¶ç„¦ç‚¹ï¼Œå°¤å…¶æ˜¯ä½œä¸ºç®€å•èŠå¤©æœºå™¨äººçš„LLMã€‚ç„¶è€Œï¼Œå¯¹äºä½¿ç”¨å¤–éƒ¨å·¥å…·å¹¶æ‰§è¡Œå¤šé˜¶æ®µä»»åŠ¡çš„LLMä»£ç†ï¼Œå…¶è¯¯ç”¨å¯èƒ½å¸¦æ¥çš„é£é™©æ›´å¤§ï¼Œä½†å…¶ç¨³å¥æ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ä¸ºäº†ç ”ç©¶LLMä»£ç†çš„è¯¯ç”¨æƒ…å†µï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åŸºå‡†æµ‹è¯•â€”â€”AgentHarmã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«æ¶µç›–æ¬ºè¯ˆã€ç½‘ç»œçŠ¯ç½ªå’Œéªšæ‰°ç­‰ç±»åˆ«çš„11ç§æœ‰å®³ä»£ç†ä»»åŠ¡ï¼ŒåŒ…æ‹¬ç”¨äºè¡¡é‡æ¨¡å‹æ˜¯å¦ä¼šæ‹’ç»æœ‰å®³ä»£ç†è¯·æ±‚çš„æµ‹è¯•ä»¥åŠé’ˆå¯¹è¶Šç‹±åä»èƒ½å®Œæˆä»»åŠ¡èƒ½åŠ›çš„æµ‹è¯•ã€‚ç ”ç©¶å‘ç°ç°æœ‰LLMæ„å¤–é¡ºä»æ¶æ„ä»£ç†è¯·æ±‚çš„ç°è±¡å€¼å¾—è­¦æƒ•ï¼Œå¹¶æå‡ºäº†é€‚ç”¨äºæµ‹è¯•çš„ç®€å•é€šç”¨è¶Šç‹±æ¨¡æ¿ã€‚ä¸ºäº†ç®€ä¾¿å¯é åœ°è¯„ä¼°LLMä»£ç†çš„æ”»å‡»å’Œé˜²å¾¡æªæ–½ï¼Œå…¬å¼€å‘å¸ƒäº†AgentHarmã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMsé¢ä¸´ç”¨æˆ·é€šè¿‡è®¾è®¡æç¤ºæ¥ç»•è¿‡å®‰å…¨æªæ–½å’Œæ»¥ç”¨æ¨¡å‹èƒ½åŠ›çš„è¶Šç‹±æ”»å‡»é£é™©ã€‚</li>
<li>ç›®å‰å¯¹äºLLMä»£ç†ï¼ˆä½¿ç”¨å¤–éƒ¨å·¥å…·æ‰§è¡Œå¤šé˜¶æ®µä»»åŠ¡ï¼‰çš„ç¨³å¥æ€§ç ”ç©¶ä¸è¶³ï¼Œå…¶è¯¯ç”¨é£é™©æ›´å¤§ã€‚</li>
<li>AgentHarmæ˜¯ä¸€ä¸ªæ–°æå‡ºçš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºç ”ç©¶LLMä»£ç†çš„è¯¯ç”¨æƒ…å†µï¼Œæ¶µç›–äº†å¤šæ ·åŒ–çš„æ¶æ„ä»£ç†ä»»åŠ¡ï¼ŒåŒ…æ‹¬å¤šç§æœ‰å®³ç±»åˆ«ã€‚</li>
<li>ç ”ç©¶å‘ç°LLMså¯èƒ½æ„å¤–é¡ºä»æ¶æ„ä»£ç†è¯·æ±‚ï¼Œè¡¨æ˜å…¶æ½œåœ¨é£é™©ã€‚</li>
<li>å­˜åœ¨ç®€å•çš„é€šç”¨è¶Šç‹±æ¨¡æ¿å¯ä»¥æˆåŠŸæ”»å‡»LLMä»£ç†ï¼Œä½¿å…¶æ‰§è¡Œæ¶æ„å¤šé˜¶æ®µä»»åŠ¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.09024">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db41364dbd99ce6983305dff10413b6f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e0cb3dd538576c02d7596c429bb7374.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6f2f0b3d37feba41ef30c22a7bf9de9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d78f5d29a4192863c752c1cde3e5a13.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="NeuroNAS-Enhancing-Efficiency-of-Neuromorphic-In-Memory-Computing-for-Intelligent-Mobile-Agents-through-Hardware-Aware-Spiking-Neural-Architecture-Search"><a href="#NeuroNAS-Enhancing-Efficiency-of-Neuromorphic-In-Memory-Computing-for-Intelligent-Mobile-Agents-through-Hardware-Aware-Spiking-Neural-Architecture-Search" class="headerlink" title="NeuroNAS: Enhancing Efficiency of Neuromorphic In-Memory Computing for   Intelligent Mobile Agents through Hardware-Aware Spiking Neural Architecture   Search"></a>NeuroNAS: Enhancing Efficiency of Neuromorphic In-Memory Computing for   Intelligent Mobile Agents through Hardware-Aware Spiking Neural Architecture   Search</h2><p><strong>Authors:Rachmad Vidya Wicaksana Putra, Muhammad Shafique</strong></p>
<p>Intelligent mobile agents (e.g., UGVs and UAVs) typically demand low power&#x2F;energy consumption when solving their machine learning (ML)-based tasks, since they are usually powered by portable batteries with limited capacity. A potential solution is employing neuromorphic computing with Spiking Neural Networks (SNNs), which leverages event-based computation to enable ultra-low power&#x2F;energy ML algorithms. To maximize the performance efficiency of SNN inference, the In-Memory Computing (IMC)-based hardware accelerators with emerging device technologies (e.g., RRAM) can be employed. However, SNN models are typically developed without considering constraints from the application and the underlying IMC hardware, thereby hindering SNNs from reaching their full potential in performance and efficiency. To address this, we propose NeuroNAS, a novel framework for developing energyefficient neuromorphic IMC for intelligent mobile agents using hardware-aware spiking neural architecture search (NAS), i.e., by quickly finding an SNN architecture that offers high accuracy under the given constraints (e.g., memory, area, latency, and energy consumption). Its key steps include: optimizing SNN operations to enable efficient NAS, employing quantization to minimize the memory footprint, developing an SNN architecture that facilitates an effective learning, and devising a systematic hardware-aware search algorithm to meet the constraints. Compared to the state-of-the-art techniques, NeuroNAS quickly finds SNN architectures (with 8bit weight precision) that maintain high accuracy by up to 6.6x search time speed-ups, while achieving up to 92% area savings, 1.2x latency improvements, 84% energy savings across different datasets (i.e., CIFAR-10, CIFAR-100, and TinyImageNet-200); while the state-of-the-art fail to meet all constraints at once. </p>
<blockquote>
<p>æ™ºèƒ½ç§»åŠ¨ä»£ç†ï¼ˆä¾‹å¦‚æ— äººåœ°é¢è½¦è¾†å’Œæ— äººæœºï¼‰åœ¨è§£å†³åŸºäºæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰çš„ä»»åŠ¡æ—¶ï¼Œé€šå¸¸è¦æ±‚ä½åŠŸè€—&#x2F;ä½èƒ½è€—ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸ç”±å®¹é‡æœ‰é™çš„ä¾¿æºå¼ç”µæ± ä¾›ç”µã€‚ä¸€ä¸ªæ½œåœ¨çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨ç¥ç»å½¢æ€è®¡ç®—ï¼Œåˆ©ç”¨è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰è¿›è¡Œäº‹ä»¶è®¡ç®—ï¼Œä»è€Œå®ç°è¶…ä½åŠŸè€—&#x2F;ä½èƒ½è€—çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ä¸ºäº†æœ€å¤§åŒ–SNNæ¨ç†çš„æ€§èƒ½æ•ˆç‡ï¼Œå¯ä»¥ä½¿ç”¨åŸºäºå†…å­˜è®¡ç®—ï¼ˆIMCï¼‰çš„ç¡¬ä»¶åŠ é€Ÿå™¨ï¼Œåˆ©ç”¨æ–°å…´è®¾å¤‡æŠ€æœ¯ï¼ˆå¦‚RRAMï¼‰ã€‚ç„¶è€Œï¼ŒSNNæ¨¡å‹çš„å¼€å‘é€šå¸¸æ²¡æœ‰è€ƒè™‘åˆ°åº”ç”¨å’Œåº•å±‚IMCç¡¬ä»¶çš„é™åˆ¶ï¼Œä»è€Œé˜»ç¢äº†SNNåœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢å‘æŒ¥å…¨éƒ¨æ½œåŠ›ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NeuroNASï¼Œè¿™æ˜¯ä¸€ç§ä¸ºæ™ºèƒ½ç§»åŠ¨ä»£ç†å¼€å‘èƒ½æºé«˜æ•ˆçš„ç¥ç»å½¢æ€IMCçš„æ–°å‹æ¡†æ¶ï¼Œé‡‡ç”¨ç¡¬ä»¶æ„ŸçŸ¥çš„è„‰å†²ç¥ç»ç½‘ç»œç»“æ„æœç´¢ï¼ˆNASï¼‰ï¼Œå³é€šè¿‡å¿«é€Ÿæ‰¾åˆ°åœ¨æ»¡è¶³ç»™å®šçº¦æŸæ¡ä»¶ä¸‹æä¾›é«˜ç²¾åº¦çš„SNNæ¶æ„ï¼ˆå¦‚å†…å­˜ã€é¢ç§¯ã€å»¶è¿Ÿå’Œèƒ½è€—ï¼‰ã€‚å…¶å…³é”®æ­¥éª¤åŒ…æ‹¬ï¼šä¼˜åŒ–SNNæ“ä½œä»¥å®ç°é«˜æ•ˆçš„NASï¼Œé‡‡ç”¨é‡åŒ–æ¥æœ€å°åŒ–å†…å­˜å ç”¨ï¼Œå¼€å‘ä¸€ç§æœ‰åˆ©äºæœ‰æ•ˆå­¦ä¹ çš„SNNæ¶æ„ï¼Œå¹¶è®¾è®¡ä¸€ç§æ»¡è¶³çº¦æŸçš„ç¡¬ä»¶æ„ŸçŸ¥æœç´¢ç®—æ³•ã€‚ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼ŒNeuroNASå¯ä»¥å¿«é€Ÿæ‰¾åˆ°SNNæ¶æ„ï¼ˆå…·æœ‰8ä½æƒé‡ç²¾åº¦ï¼‰ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œæœ€å¤šå¯å®ç°6.6å€çš„æœç´¢æ—¶é—´åŠ é€Ÿï¼ŒåŒæ—¶åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾92%çš„é¢ç§¯èŠ‚çœã€1.2å€çš„å»¶è¿Ÿæ”¹è¿›å’Œ84%çš„èƒ½è€—èŠ‚çœï¼ˆå³CIFAR-10ã€CIFAR-100å’ŒTinyImageNet-200ï¼‰ï¼›è€Œæœ€å…ˆè¿›çš„æ— æ³•åŒæ—¶æ»¡è¶³æ‰€æœ‰çº¦æŸæ¡ä»¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.00641v3">PDF</a> 9 pages, 14 figures, 2 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç§»åŠ¨æ™ºèƒ½ä»£ç†ï¼ˆå¦‚UGVså’ŒUAVsï¼‰è§£å†³æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡æ—¶é€šå¸¸å¯¹ä½åŠŸè€—æœ‰è¾ƒé«˜è¦æ±‚ï¼Œç”±äºå®ƒä»¬é€šå¸¸ç”±å®¹é‡æœ‰é™çš„ä¾¿æºå¼ç”µæ± ä¾›ç”µã€‚ä¸€ç§å¯èƒ½çš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨ç¥ç»å½¢æ€è®¡ç®—ï¼Œé€šè¿‡è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰è¿›è¡Œäº‹ä»¶åŸºç¡€è®¡ç®—ï¼Œä»¥å®ç°è¶…ä½åŠŸè€—çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ä¸ºäº†æœ€å¤§åŒ–SNNæ¨ç†çš„æ€§èƒ½æ•ˆç‡ï¼Œå¯ä»¥é‡‡ç”¨åŸºäºå†…å­˜è®¡ç®—ï¼ˆIMCï¼‰çš„ç¡¬ä»¶åŠ é€Ÿå™¨ï¼Œå¹¶åˆ©ç”¨æ–°å…´è®¾å¤‡æŠ€æœ¯ï¼ˆå¦‚RRAMï¼‰ã€‚ç„¶è€Œï¼ŒSNNæ¨¡å‹çš„å¼€å‘é€šå¸¸æ²¡æœ‰è€ƒè™‘åˆ°åº”ç”¨ç¨‹åºå’Œåº•å±‚IMCç¡¬ä»¶çš„é™åˆ¶ï¼Œä»è€Œé˜»ç¢äº†å…¶åœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢çš„æ½œåŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NeuroNASæ¡†æ¶ï¼Œé€šè¿‡ç¡¬ä»¶æ„ŸçŸ¥çš„è„‰å†²ç¥ç»ç½‘ç»œç»“æ„æœç´¢ï¼ˆNASï¼‰ä¸ºæ™ºèƒ½ç§»åŠ¨ä»£ç†å¼€å‘èƒ½æºé«˜æ•ˆçš„ç¥ç»å½¢æ€IMCã€‚ä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒNeuroNASèƒ½å¤Ÿè¿…é€Ÿæ‰¾åˆ°æ»¡è¶³ç»™å®šçº¦æŸï¼ˆå¦‚å†…å­˜ã€é¢ç§¯ã€å»¶è¿Ÿå’Œèƒ½è€—ï¼‰çš„é«˜ç²¾åº¦SNNæ¶æ„ï¼ŒåŒæ—¶å®ç°äº†æœ€é«˜è¾¾6.6å€æœç´¢æ—¶é—´åŠ é€Ÿã€é«˜è¾¾92%çš„é¢ç§¯èŠ‚çœã€1.2å€çš„å»¶è¿Ÿæ”¹è¿›ä»¥åŠè·¨ä¸åŒæ•°æ®é›†ï¼ˆå¦‚CIFAR-10ã€CIFAR-100å’ŒTinyImageNet-200ï¼‰é«˜è¾¾84%çš„èƒ½è€—èŠ‚çœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç§»åŠ¨æ™ºèƒ½ä»£ç†åœ¨è§£å†³æœºå™¨å­¦ä¹ ä»»åŠ¡æ—¶éœ€è¦ä½èƒ½è€—è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒä»¬çš„ç”µæ± é€šå¸¸æœ‰é™ã€‚</li>
<li>ç¥ç»å½¢æ€è®¡ç®—å’Œè„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰æ˜¯å®ç°è¶…ä½åŠŸè€—æœºå™¨å­¦ä¹ ç®—æ³•çš„ä¸€ç§æ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åŸºäºå†…å­˜è®¡ç®—ï¼ˆIMCï¼‰çš„ç¡¬ä»¶åŠ é€Ÿå™¨å¯ä»¥æœ€å¤§åŒ–SNNæ¨ç†çš„æ€§èƒ½æ•ˆç‡ã€‚</li>
<li>SNNæ¨¡å‹çš„å¼€å‘é€šå¸¸æœªè€ƒè™‘åº”ç”¨ç¨‹åºå’Œåº•å±‚ç¡¬ä»¶çš„é™åˆ¶ï¼Œè¿™é™åˆ¶äº†å…¶æ€§èƒ½å’Œæ•ˆç‡ã€‚</li>
<li>NeuroNASæ¡†æ¶é€šè¿‡ç¡¬ä»¶æ„ŸçŸ¥çš„NASæŠ€æœ¯ä¸ºæ™ºèƒ½ç§»åŠ¨ä»£ç†å¼€å‘èƒ½æºé«˜æ•ˆçš„ç¥ç»å½¢æ€IMCã€‚</li>
<li>NeuroNASèƒ½å¤Ÿè¿…é€Ÿæ‰¾åˆ°æ»¡è¶³å¤šç§çº¦æŸæ¡ä»¶çš„é«˜ç²¾åº¦SNNæ¶æ„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.00641">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3ea770c5fce0ec1a68ce99f3e58d9a7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4379518cddc19149a0f3bc018192ce49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-671ac7daca3a95e1a15c8ae3b2caf2ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-215f14437f9313471ff2a83d1f58bb90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc184d5237c95924af2a72eb8facd401.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-215253e66fb77912dc3ab31f40996a05.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Chemist-X-Large-Language-Model-empowered-Agent-for-Reaction-Condition-Recommendation-in-Chemical-Synthesis"><a href="#Chemist-X-Large-Language-Model-empowered-Agent-for-Reaction-Condition-Recommendation-in-Chemical-Synthesis" class="headerlink" title="Chemist-X: Large Language Model-empowered Agent for Reaction Condition   Recommendation in Chemical Synthesis"></a>Chemist-X: Large Language Model-empowered Agent for Reaction Condition   Recommendation in Chemical Synthesis</h2><p><strong>Authors:Kexin Chen, Jiamin Lu, Junyou Li, Xiaoran Yang, Yuyang Du, Kunyi Wang, Qiannuan Shi, Jiahui Yu, Lanqing Li, Jiezhong Qiu, Jianzhang Pan, Yi Huang, Qun Fang, Pheng Ann Heng, Guangyong Chen</strong></p>
<p>Recent AI research plots a promising future of automatic chemical reactions within the chemistry society. This study proposes Chemist-X, a comprehensive AI agent that automates the reaction condition optimization (RCO) task in chemical synthesis with retrieval-augmented generation (RAG) technology and AI-controlled wet-lab experiment executions. To begin with, as an emulation on how chemical experts solve the RCO task, Chemist-X utilizes a novel RAG scheme to interrogate available molecular and literature databases to narrow the searching space for later processing. The agent then leverages a computer-aided design (CAD) tool we have developed through a large language model (LLM) supervised programming interface. With updated chemical knowledge obtained via RAG, as well as the ability in using CAD tools, our agent significantly outperforms conventional RCO AIs confined to the fixed knowledge within its training data. Finally, Chemist-X interacts with the physical world through an automated robotic system, which can validate the suggested chemical reaction condition without human interventions. The control of the robotic system was achieved with a novel algorithm we have developed for the equipment, which relies on LLMs for reliable script generation. Results of our automatic wet-lab experiments, achieved by fully LLM-supervised end-to-end operation with no human in the lope, prove Chemist-Xâ€™s ability in self-driving laboratories. </p>
<blockquote>
<p>è¿‘æœŸçš„äººå·¥æ™ºèƒ½ç ”ç©¶ä¸ºåŒ–å­¦ç•Œå†…çš„è‡ªåŠ¨åŒ–å­¦ååº”æç»˜äº†ä¸€ä¸ªå……æ»¡å¸Œæœ›çš„æœªæ¥ã€‚æœ¬ç ”ç©¶æå‡ºäº†Chemist-Xè¿™ä¸€å…¨é¢çš„AIä»£ç†ï¼Œå®ƒé€šè¿‡é‡‡ç”¨å¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯å’ŒAIæ§åˆ¶çš„æ¹¿å¼å®éªŒæ‰§è¡Œï¼Œè‡ªåŠ¨åŒ–äº†åŒ–å­¦åˆæˆä¸­çš„ååº”æ¡ä»¶ä¼˜åŒ–ï¼ˆRCOï¼‰ä»»åŠ¡ã€‚é¦–å…ˆï¼Œä½œä¸ºå¯¹åŒ–å­¦ä¸“å®¶è§£å†³RCOä»»åŠ¡æ–¹å¼çš„æ¨¡æ‹Ÿï¼ŒChemist-Xåˆ©ç”¨æ–°é¢–RAGæ–¹æ¡ˆæ¥æŸ¥è¯¢ç°æœ‰çš„åˆ†å­å’Œæ–‡çŒ®æ•°æ®åº“ï¼Œç¼©å°åç»­å¤„ç†æ—¶çš„æœç´¢ç©ºé—´ã€‚ç„¶åï¼Œè¯¥ä»£ç†åˆ©ç”¨æˆ‘ä»¬é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç›‘ç£ç¼–ç¨‹æ¥å£å¼€å‘çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰å·¥å…·ã€‚å‡­å€Ÿé€šè¿‡RAGè·å¾—çš„æœ€æ–°åŒ–å­¦çŸ¥è¯†ä»¥åŠä½¿ç”¨CADå·¥å…·çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬çš„ä»£ç†åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—è¶…è¶Šäº†ä»…é™äºå…¶è®­ç»ƒæ•°æ®çš„ä¼ ç»ŸRCO AIã€‚æœ€åï¼ŒChemist-Xé€šè¿‡ä¸è‡ªåŠ¨åŒ–æœºå™¨äººç³»ç»Ÿçš„äº¤äº’ä¸ç‰©ç†ä¸–ç•Œè¿›è¡Œäº¤äº’ï¼Œè¯¥ç³»ç»Ÿå¯ä»¥éªŒè¯å»ºè®®çš„åŒ–å­¦ååº”æ¡ä»¶è€Œæ— éœ€äººå·¥å¹²é¢„ã€‚è¯¥æœºå™¨äººç³»ç»Ÿçš„æ§åˆ¶æ˜¯é€šè¿‡æˆ‘ä»¬ä¸ºè®¾å¤‡å¼€å‘çš„æ–°å‹ç®—æ³•å®ç°çš„ï¼Œè¯¥ç®—æ³•ä¾èµ–äºLLMè¿›è¡Œå¯é çš„è„šæœ¬ç”Ÿæˆã€‚é€šè¿‡å®Œå…¨ç”±LLMç›‘ç£çš„ç«¯åˆ°ç«¯æ“ä½œå®ç°çš„è‡ªåŠ¨æ¹¿å¼å®éªŒçš„ç»“æœï¼ˆæ— éœ€äººå·¥å‚ä¸ï¼‰ï¼Œè¯æ˜äº†Chemist-Xåœ¨è‡ªåŠ¨é©¾é©¶å®éªŒå®¤ä¸­çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.10776v6">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ€è¿‘äººå·¥æ™ºèƒ½ç ”ç©¶æ¨åŠ¨åŒ–å­¦ç¤¾ä¼šå®ç°è‡ªåŠ¨åŒ–å­¦ååº”çš„æœªæ¥å‘å±•ã€‚ç ”ç©¶æå‡ºChemist-Xï¼Œä¸€ä¸ªå…¨é¢çš„äººå·¥æ™ºèƒ½ä»£ç†ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯å’ŒAIæ§åˆ¶çš„æ¹¿å®éªŒå®¤å®éªŒæ‰§è¡Œï¼Œè‡ªåŠ¨åŒ–å®ŒæˆåŒ–å­¦åˆæˆä¸­çš„ååº”æ¡ä»¶ä¼˜åŒ–ä»»åŠ¡ã€‚Chemist-Xæ¨¡ä»¿åŒ–å­¦ä¸“å®¶è§£å†³ååº”æ¡ä»¶ä¼˜åŒ–ä»»åŠ¡çš„æ–¹å¼ï¼Œåˆ©ç”¨æ–°å‹æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ¡ˆæŸ¥è¯¢åˆ†å­å’Œæ–‡çŒ®æ•°æ®åº“ï¼Œç¼©å°åç»­å¤„ç†æœç´¢ç©ºé—´ã€‚è¯¥ä»£ç†è¿˜ä½¿ç”¨é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ç›‘ç£å¼€å‘çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡å·¥å…·ã€‚å€ŸåŠ©æ›´æ–°åçš„åŒ–å­¦çŸ¥è¯†å’Œä½¿ç”¨CADå·¥å…·çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬çš„ä»£ç†æ˜¾è‘—ä¼˜äºä»…é™äºè®­ç»ƒæ•°æ®çš„å¸¸è§„ååº”æ¡ä»¶ä¼˜åŒ–äººå·¥æ™ºèƒ½ã€‚æ­¤å¤–ï¼ŒChemist-Xé€šè¿‡è‡ªåŠ¨åŒ–æœºå™¨äººç³»ç»Ÿä¸ç°å®ä¸–ç•Œäº’åŠ¨ï¼Œæ— éœ€äººä¸ºå¹²é¢„å³å¯éªŒè¯å»ºè®®çš„åŒ–å­¦ååº”æ¡ä»¶ã€‚æœºå™¨äººç³»ç»Ÿçš„æ§åˆ¶ä¾èµ–äºæˆ‘ä»¬ä¸ºè®¾å¤‡å¼€å‘çš„æ–°å‹ç®—æ³•ï¼Œè¯¥ç®—æ³•ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯é è„šæœ¬ç”Ÿæˆã€‚å…¨è‡ªåŠ¨æ¹¿å®éªŒçš„ç»“æœè¯æ˜Chemist-Xåœ¨æ— äººå€¼å®ˆçš„æƒ…å†µä¸‹å®ç°è‡ªæˆ‘é©±åŠ¨å®éªŒå®¤çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Chemist-Xæ˜¯ä¸€ä¸ªå…¨é¢çš„äººå·¥æ™ºèƒ½ä»£ç†ï¼Œå¯è‡ªåŠ¨åŒ–å®ŒæˆåŒ–å­¦åˆæˆä¸­çš„ååº”æ¡ä»¶ä¼˜åŒ–ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æŸ¥è¯¢åˆ†å­å’Œæ–‡çŒ®æ•°æ®åº“ï¼Œç¼©å°æœç´¢ç©ºé—´ã€‚</li>
<li>Chemist-Xé€šè¿‡è®¡ç®—æœºè¾…åŠ©è®¾è®¡å·¥å…·åŠæ›´æ–°åçš„åŒ–å­¦çŸ¥è¯†æ˜¾è‘—ä¼˜äºå¸¸è§„AIã€‚</li>
<li>æœºå™¨äººç³»ç»Ÿé€šè¿‡ä¸AIä»£ç†äº’åŠ¨å®ç°è‡ªåŠ¨éªŒè¯åŒ–å­¦ååº”æ¡ä»¶ã€‚</li>
<li>AIæ§åˆ¶æ¹¿å®éªŒå®¤å®éªŒæ‰§è¡Œï¼Œæ— éœ€äººä¸ºå¹²é¢„ã€‚</li>
<li>åˆ©ç”¨æ–°å‹ç®—æ³•æ§åˆ¶æœºå™¨äººç³»ç»Ÿï¼Œå®ç°å¯é è„šæœ¬ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.10776">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f0129302cd21e9cc1b82bd8208bc2889.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f826efe94d417eef464d2da2762988f4.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-22/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-22/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-22/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-cb21d596a538b2a51ce163b83a32f9d1.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  Meta-Learning and Knowledge Discovery based Physics-Informed Neural   Network for Remaining Useful Life Prediction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-22/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bbed99f1971aa9a935920c070ed7910e.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-22  Does Reinforcement Learning Really Incentivize Reasoning Capacity in   LLMs Beyond the Base Model?
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18723.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
