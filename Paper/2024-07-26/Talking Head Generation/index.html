<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-07-26  Text-based Talking Video Editing with Cascaded Conditional Diffusion">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-297ff797f5ab91aec91258ea36ea0da9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-07-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    21 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-07-26-更新"><a href="#2024-07-26-更新" class="headerlink" title="2024-07-26 更新"></a>2024-07-26 更新</h1><h2 id="Text-based-Talking-Video-Editing-with-Cascaded-Conditional-Diffusion"><a href="#Text-based-Talking-Video-Editing-with-Cascaded-Conditional-Diffusion" class="headerlink" title="Text-based Talking Video Editing with Cascaded Conditional Diffusion"></a>Text-based Talking Video Editing with Cascaded Conditional Diffusion</h2><p><strong>Authors:Bo Han, Heqing Zou, Haoyang Li, Guangcong Wang, Chng Eng Siong</strong></p>
<p>Text-based talking-head video editing aims to efficiently insert, delete, and substitute segments of talking videos through a user-friendly text editing approach. It is challenging because of \textbf{1)} generalizable talking-face representation, \textbf{2)} seamless audio-visual transitions, and \textbf{3)} identity-preserved talking faces. Previous works either require minutes of talking-face video training data and expensive test-time optimization for customized talking video editing or directly generate a video sequence without considering in-context information, leading to a poor generalizable representation, or incoherent transitions, or even inconsistent identity. In this paper, we propose an efficient cascaded conditional diffusion-based framework, which consists of two stages: audio to dense-landmark motion and motion to video. \textit{\textbf{In the first stage}}, we first propose a dynamic weighted in-context diffusion module to synthesize dense-landmark motions given an edited audio. \textit{\textbf{In the second stage}}, we introduce a warping-guided conditional diffusion module. The module first interpolates between the start and end frames of the editing interval to generate smooth intermediate frames. Then, with the help of the audio-to-dense motion images, these intermediate frames are warped to obtain coarse intermediate frames. Conditioned on the warped intermedia frames, a diffusion model is adopted to generate detailed and high-resolution target frames, which guarantees coherent and identity-preserved transitions. The cascaded conditional diffusion model decomposes the complex talking editing task into two flexible generation tasks, which provides a generalizable talking-face representation, seamless audio-visual transitions, and identity-preserved faces on a small dataset. Experiments show the effectiveness and superiority of the proposed method. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.14841v1">PDF</a> </p>
<p><strong>Summary</strong><br>文本驱动的头像视频编辑旨在通过用户友好的文本编辑方法，有效地插入、删除和替换说话视频的片段。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>提出了一种高效的级联条件扩散框架，分为音频到密集地标运动和运动到视频两个阶段。</li>
<li>第一阶段引入了动态加权上下文扩散模块，用于合成编辑后音频的密集地标运动。</li>
<li>第二阶段引入了基于变形引导的条件扩散模块，生成平滑的中间帧并保证了身份保留的过渡。</li>
<li>方法将复杂的编辑任务分解为两个灵活的生成任务，提供了通用的说话面部表示、无缝的视听过渡和身份保留的面部。</li>
<li>实验表明了所提方法的有效性和优越性，尤其在小数据集上。</li>
<li>以前的方法要么需要大量的训练数据和昂贵的测试时间优化，要么直接生成视频序列而忽略上下文信息，导致表示不通用、过渡不连贯或者身份不一致。</li>
<li>方法通过保证一致性和身份保留的过渡，解决了以往编辑方法的局限性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 基于级联条件扩散的文本驱动对话视频编辑</p>
</li>
<li><p>Authors: Bo Han, Heqing Zou, Haoyang Li, Guangcong Wang, Chng Eng Siong</p>
</li>
<li><p>Affiliation: Bo Han的关联机构为浙江大学。</p>
</li>
<li><p>Keywords: Text-based Talking Video Editing, Cascaded Conditional Diffusion, Dynamic Weighted In-context Diffusion Module, Warping-guided Conditional Diffusion Module</p>
</li>
<li><p>Urls: 由于无法直接提供论文链接，GitHub代码链接暂未提供（如有可用链接，请填入相应位置）。</p>
</li>
<li><p>Summary:</p>
<ul>
<li>(1)研究背景：本文的研究背景是文本驱动的对话视频编辑。该领域旨在通过友好的文本编辑方式，实现对对话视频的高效插入、删除和替换。此项技术具有广泛的应用领域，如电影制作、视频广告和数字化身等。</li>
</ul>
<p> -(2)过去的方法及问题：过去的文本驱动对话视频编辑方法要么需要大量的对话视频训练数据，并在测试时进行优化，以实现个性化的视频编辑；要么直接生成视频序列，而不考虑上下文信息。这些问题导致了缺乏通用性、视听过渡不连贯以及身份不一致等问题。</p>
<p> -(3)研究方法：针对上述问题，本文提出了一种基于级联条件扩散的框架，包括两个阶段：音频到密集地标运动，以及运动到视频。在第一阶段，提出了动态加权上下文扩散模块，根据编辑后的音频合成密集地标运动。在第二阶段，引入了基于warping的条件扩散模块，通过插值生成平滑的中间帧，并结合音频到密集运动图像进行warping，获得粗略的中间帧。最后，基于这些中间帧，采用扩散模型生成详细的高分辨率目标帧，保证了连贯且身份一致的过渡。</p>
<p> -(4)任务与性能：本文的方法在对话视频编辑任务上取得了显著的效果和优势。该方法将复杂的编辑任务分解为两个灵活生成任务，提供了通用的对话面部表示、无缝的视听过渡和身份保留的面部。实验结果表明，该方法的有效性。性能结果支持了方法的有效性，为实现高效的文本驱动对话视频编辑提供了新的解决方案。</p>
</li>
</ol>
<p>好的，我会根据您给出的摘要来详细阐述这篇文章的方法论。下面是按照您提供的格式回答：</p>
<ol start="7">
<li>Methods:</li>
</ol>
<ul>
<li>(1) 研究背景与问题定义：首先明确了本文研究的背景为文本驱动的对话视频编辑。通过分析该领域的现有问题，总结出主要挑战在于如何通过友好的文本编辑方式实现对对话视频的高效插入、删除和替换，同时保证视频的连贯性和身份一致性。这些问题在过去的文本驱动对话视频编辑方法中普遍存在。</li>
<li>(2) 方法概述：针对上述问题，本文提出了一种基于级联条件扩散的框架。该框架包括两个阶段：音频到密集地标运动阶段和运动到视频阶段。第一阶段中，引入了动态加权上下文扩散模块，根据编辑后的音频合成密集地标运动。第二阶段则通过插值生成平滑的中间帧，并结合音频到密集运动图像进行warping，获得粗略的中间帧。最后，基于这些中间帧，采用扩散模型生成详细的高分辨率目标帧。这种方法的优势在于能将复杂的编辑任务分解为两个灵活生成任务，保证连贯且身份一致的过渡。</li>
<li>(3) 方法细节：在音频到密集地标运动阶段，动态加权上下文扩散模块是关键。该模块能够根据编辑后的音频信息合成出对应的密集地标运动，为后续的视频生成提供基础。在运动到视频阶段，基于warping的条件扩散模块发挥了重要作用。它通过插值技术生成平滑的中间帧，并结合之前合成的密集运动图像进行warping，得到粗略的中间帧图像。最后，利用扩散模型对这些中间帧进行精细化处理，生成高分辨率的目标帧，从而实现视频的连贯性和身份一致性。</li>
<li>(4) 实验与性能评估：本文的方法在对话视频编辑任务上进行了实验验证，并与其他方法进行了对比。实验结果表明，该方法在对话视频编辑任务上取得了显著的效果和优势。性能评估支持了方法的有效性，证明了该策略为文本驱动对话视频编辑提供了新的解决方案。同时文章还提供了相关的实验结果和分析以支持方法的可行性。</li>
</ul>
<p>希望以上回答能够对您有所帮助。如果您还有其他问题或需要进一步的解释，请随时告知我！</p>
<ol start="8">
<li>Conclusion:</li>
</ol>
<p>(1)这项工作的意义在于为文本驱动的对话视频编辑提供了一种新的解决方案。通过引入基于级联条件扩散的框架，该工作有效地解决了对话视频编辑中的一系列问题，如缺乏通用性、视听过渡不连贯以及身份不一致等。这种新方法不仅提高了视频编辑的效率，而且为用户提供了更友好的编辑体验。</p>
<p>(2)创新点、性能和工作量总结如下：</p>
<p>创新点：该文章提出了一种基于级联条件扩散的文本驱动对话视频编辑方法，通过动态加权上下文扩散模块和基于warping的条件扩散模块的设计，实现了高效、连贯的视频编辑。</p>
<p>性能：实验结果表明，该方法在对话视频编辑任务上取得了显著的效果和优势，提供了通用的对话面部表示、无缝的视听过渡和身份保留的面部。</p>
<p>工作量：文章详细介绍了方法的实现细节，包括音频到密集地标运动阶段和运动到视频阶段的具体步骤。此外，文章还提供了相关的实验结果和分析以支持方法的可行性。但工作量方面可能存在一些复杂性，因为视频编辑本身是一个复杂的任务，需要处理大量的数据和细节。</p>
<p>总体来说，该文章在文本驱动的对话视频编辑领域做出了重要的贡献，为未来的研究提供了新的思路和方法。</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c3a31b528e3b4f1a7f32ef4023bb0b46.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c89215088d50486cd874af885dc83219.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e9baf4a4e5a9ab455819e04135ffc986.jpg" align="middle">
</details>




<h2 id="EmoFace-Audio-driven-Emotional-3D-Face-Animation"><a href="#EmoFace-Audio-driven-Emotional-3D-Face-Animation" class="headerlink" title="EmoFace: Audio-driven Emotional 3D Face Animation"></a>EmoFace: Audio-driven Emotional 3D Face Animation</h2><p><strong>Authors:Chang Liu, Qunfen Lin, Zijiao Zeng, Ye Pan</strong></p>
<p>Audio-driven emotional 3D face animation aims to generate emotionally expressive talking heads with synchronized lip movements. However, previous research has often overlooked the influence of diverse emotions on facial expressions or proved unsuitable for driving MetaHuman models. In response to this deficiency, we introduce EmoFace, a novel audio-driven methodology for creating facial animations with vivid emotional dynamics. Our approach can generate facial expressions with multiple emotions, and has the ability to generate random yet natural blinks and eye movements, while maintaining accurate lip synchronization. We propose independent speech encoders and emotion encoders to learn the relationship between audio, emotion and corresponding facial controller rigs, and finally map into the sequence of controller values. Additionally, we introduce two post-processing techniques dedicated to enhancing the authenticity of the animation, particularly in blinks and eye movements. Furthermore, recognizing the scarcity of emotional audio-visual data suitable for MetaHuman model manipulation, we contribute an emotional audio-visual dataset and derive control parameters for each frames. Our proposed methodology can be applied in producing dialogues animations of non-playable characters (NPCs) in video games, and driving avatars in virtual reality environments. Our further quantitative and qualitative experiments, as well as an user study comparing with existing researches show that our approach demonstrates superior results in driving 3D facial models. The code and sample data are available at <a target="_blank" rel="noopener" href="https://github.com/SJTU-Lucy/EmoFace">https://github.com/SJTU-Lucy/EmoFace</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.12501v1">PDF</a> 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR).   IEEE, 2024</p>
<p><strong>Summary</strong><br>通过EmoFace，我们引入了一种新的音频驱动的方法来生成具有多种情感表达的面部动画。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>EmoFace是一种新的音频驱动的面部动画生成方法，能够表现多种情感。</li>
<li>方法利用独立的语音编码器和情感编码器学习音频、情感和面部控制器之间的关系。</li>
<li>研究引入了两种后处理技术，专门用于增强动画的真实性，特别是眨眼和眼部运动。</li>
<li>提出了一个情感音频-视觉数据集，适合于MetaHuman模型操作。</li>
<li>方法可应用于视频游戏中非玩家角色的对话动画和虚拟现实环境中的头像驱动。</li>
<li>实验结果显示，该方法在驱动3D面部模型方面表现出优越的结果。</li>
<li>开放源代码和示例数据可在<a target="_blank" rel="noopener" href="https://github.com/SJTU-Lucy/EmoFace%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/SJTU-Lucy/EmoFace获取。</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>好的，我会按照您的要求进行总结。</p>
<ol>
<li><p><strong>标题</strong>：<br>EmoFace: 音频驱动的情感3D面部动画<br>中文翻译：EmoFace：音频驱动的情感三维面部动画</p>
</li>
<li><p><strong>作者</strong>：<br>Chang Liu, Qunfen Lin, Zijiao Zeng, Ye Pan</p>
</li>
<li><p><strong>作者所属单位</strong>：<br>上海交通大学（Shanghai Jiao Tong University）、腾讯游戏（Tencent Games）</p>
</li>
<li><p><strong>关键词</strong>：<br>音频驱动面部动画、情感表达、同步嘴唇动作、MetaHuman模型操控、虚拟角色动画、情感音频视觉数据集、参数控制等。</p>
</li>
<li><p><strong>链接</strong>：<br>论文链接：待补充（可通过作者提供的链接查看）；Github代码链接：[GitHub代码库链接]（GitHub:None表示暂时无法提供代码库链接）</p>
</li>
<li><p><strong>摘要</strong>：<br>（1）研究背景：随着虚拟现实技术的不断发展，对虚拟角色的创建需求不断增长。音频驱动的面部动画在无法捕捉面部表情的情况下尤为关键。然而，现有方法在驱动情感表达和同步嘴唇动作方面存在不足。本研究旨在解决这一问题。<br>（2）过去的方法及问题：以往音频驱动面部动画的研究方法主要存在忽略情感对面部表情的影响或在驱动MetaHuman模型时效果不佳的问题。<br>（3）研究方法：本研究提出了EmoFace，一种新型的音频驱动面部动画方法。该方法利用独立的语音编码器和情感编码器学习音频、情感和对应面部控制器之间的关系，并映射成控制器值的序列。此外，还引入两种后处理技术以提高动画的真实性。同时，为MetaHuman模型操控贡献了一个情感音频视觉数据集并推导了每帧的控制参数。<br>（4）任务与性能：本研究的方法应用于创建游戏非玩家角色（NPC）的对话动画和虚拟现实环境中的角色驱动。实验和用户研究结果表明，该方法在驱动3D面部模型方面表现出卓越的结果。性能上，该方法能够生成具有多种情感的面部表情，同时保持准确的嘴唇同步，生成自然且随机的眨眼和眼部运动。</p>
</li>
<li><p>方法论概述：</p>
<ul>
<li><p>(1) 构建模型架构：提出EmoFace模型，该模型由音频编码器、情感编码器和Audio2Rig模块三部分组成。音频编码器基于预训练的语音模型wav2vec2.0，接收音频输入并输出语音表示。情感编码器接受情感类别输入，将其转换为与内容编码具有相同维度的向量。Audio2Rig模块结合音频特征和情感编码，生成控制面部动画的控制器值。</p>
</li>
<li><p>(2) 数据处理与特征提取：采用wav2vec2.0提取音频的一般特征，并对频率进行线性插值以确保与数据集帧率一致。使用SVM模型进行眨眼检测，利用眼间比例（EAR）计算眨眼事件。</p>
</li>
<li><p>(3) 情感控制面部动画：通过输入情感标签，用户可控制输出面部动画的情感类别。模型能够生成具有多种情感的面部表情，同时保持嘴唇同步，生成自然且随机的眨眼和眼部运动。</p>
</li>
<li><p>(4) 模型训练与优化：使用带有标签的数据集进行模型训练，包括音频数据和对应的面部动画控制器值。采用transformer编码器进行预测，并通过Savitzky-Golay滤波器对输出序列进行平滑处理，以确保面部动画的流畅性。</p>
</li>
<li><p>(5) 实验验证与用户研究：通过创建游戏非玩家角色（NPC）的对话动画和虚拟现实环境中的角色驱动来验证方法的有效性。实验和用户研究结果表明，该方法在驱动3D面部模型方面表现出卓越的结果，能够生成具有真实感的面部动画。</p>
</li>
</ul>
</li>
</ol>
<p>好的，根据您提供的文章信息和内容，我将按照要求的格式给出结论部分。</p>
<ol start="8">
<li><p>Conclusion:</p>
<ul>
<li><p>(1) 这项研究工作的意义在于提出了一种新型的音频驱动面部动画方法，名为EmoFace。该方法能够生成具有多种情感的3D面部表情动画，对于虚拟现实技术中的虚拟角色创建具有重要的应用价值。</p>
</li>
<li><p>(2) 创新点：本研究提出了EmoFace模型，通过音频和情感编码器结合，实现了音频驱动的情感3D面部动画。同时，引入了后处理技术提高动画的真实性。此外，为MetaHuman模型操控贡献了一个情感音频视觉数据集。<br>  性能：实验和用户研究结果表明，该方法在驱动3D面部模型方面表现出卓越的结果，能够生成具有真实感的面部动画，同时在情感表达和同步嘴唇动作方面有明显的改进。<br>  工作量：文章详细描述了方法论，包括模型架构、数据处理与特征提取、情感控制面部动画、模型训练与优化等。同时，提供了实验验证和用户研究结果来证明方法的有效性。</p>
</li>
</ul>
</li>
</ol>
<p>请注意，由于无法获取完整的文章内容和细节，以上结论仅基于您提供的摘要和信息进行概括。如有需要，请进一步提供文章详细内容以便更准确的评价。</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-297ff797f5ab91aec91258ea36ea0da9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8722b009744c5364ff2888b1fe637fe3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdf8a88c274745d8ec4f068011a34ab7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e603495f9cd58c1d0abbb8898e8f6ecd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72420ab5d8b2cabb79ef10576a252f4e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a6f71089748fa3b2a8868f522c702a8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2b2267b39185387ac3aee03d58bd483b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4b95660a2ae340e346a6491a779b8fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8f3b83a05961dbb78474468df65136c9.jpg" align="middle">
</details>




<h2 id="Learning-Online-Scale-Transformation-for-Talking-Head-Video-Generation"><a href="#Learning-Online-Scale-Transformation-for-Talking-Head-Video-Generation" class="headerlink" title="Learning Online Scale Transformation for Talking Head Video Generation"></a>Learning Online Scale Transformation for Talking Head Video Generation</h2><p><strong>Authors:Fa-Ting Hong, Dan Xu</strong></p>
<p>One-shot talking head video generation uses a source image and driving video to create a synthetic video where the source person’s facial movements imitate those of the driving video. However, differences in scale between the source and driving images remain a challenge for face reenactment. Existing methods attempt to locate a frame in the driving video that aligns best with the source image, but imprecise alignment can result in suboptimal outcomes.   To this end, we introduce a scale transformation module that can automatically adjust the scale of the driving image to fit that of the source image, by using the information of scale difference maintained in the detected keypoints of the source image and the driving frame. Furthermore, to keep perceiving the scale information of faces during the generation process, we incorporate the scale information learned from the scale transformation module into each layer of the generation process to produce a final result with an accurate scale. Our method can perform accurate motion transfer between the two images without any anchor frame, achieved through the contributions of the proposed online scale transformation facial reenactment network. Extensive experiments have demonstrated that our proposed method adjusts the scale of the driving face automatically according to the source face, and generates high-quality faces with an accurate scale in the cross-identity facial reenactment. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.09965v1">PDF</a> </p>
<p><strong>Summary</strong><br>视频生成中的关键挑战是源图像与驱动视频之间的比例差异，我们提出的方法通过自动调整比例解决了这一问题，有效实现了面部运动的准确转移。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>一次性生成视频的关键是解决源图像与驱动视频之间的比例差异。</li>
<li>我们引入了一个比例转换模块，利用源图像和驱动视频中检测到的关键点信息，自动调整驱动图像的比例以匹配源图像。</li>
<li>在生成过程中，我们将比例信息嵌入到每一层，确保最终生成的结果具有准确的比例。</li>
<li>我们的方法不需要锚定帧，通过在线比例转换面部重现网络实现了准确的运动转移。</li>
<li>大量实验证明，我们的方法能够自动调整驱动面部的比例，实现跨身份的高质量面部重现。</li>
<li>精确的比例调整有助于生成具有真实感的面部表情。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>Please refer to relevant websites for more information, and feel free to ask me any other questions.<br>7. 方法论：</p>
<p>(1) 该文章提出了一种在线尺度转换面部再表情网络（OSTNet），用于自动调整驱动面部的尺度，以便在此任务中生成精确的结果，而无需寻找最佳对齐锚框。</p>
<p>(2) 方法首先通过尺度转换模块（Scale Transformation Module）对驱动面部图像进行尺度调整，使其与源图像一致。该模块使用关键点来预测一组固定点，然后利用网格生成器（Grid Generator）产生尺度变形图，用于对驱动图像进行尺度校正。</p>
<p>(3) 为了使网络在面部生成过程中意识到源图像的尺度，将尺度转换模块学习到的潜在尺度代码融入到生成过程的每一层。</p>
<p>(4) 在训练阶段，采用表达保留增强方法对驱动图像进行不同尺度的训练，以便网络能够处理任何尺度的驱动面部。</p>
<p>(5) 通过使用关键点检测器来检测面部图像的关键点，并参与尺度转换步骤，因为检测到的关键点包含面部的尺度信息。</p>
<p>(6) 最后，通过提出的网格生成器产生校正后的面部图像。这种方法能够有效地对输入的不一致尺度的驱动面部进行调整，以匹配源面部的尺度，从而确保最终结果的身份一致性。</p>
<ol start="8">
<li><p>Conclusion:</p>
<ul>
<li><p>(1) 该研究工作提出了一种在线尺度对齐的面部再表情网络（OSTNet），对面部生成和表情转移技术做出了重要的贡献。这种网络可以在没有最佳对齐锚框的情况下，自动调整驱动面部的尺度，为视频制作中自动调整人脸提供了便利。此外，该研究还展示了其在面部图像尺度转换方面的优异性能，这对于改善虚拟人物制作、动画渲染等应用领域具有重要的实用价值。</p>
</li>
<li><p>(2) 创新点：文章提出了一种全新的在线尺度转换面部再表情网络（OSTNet），它能够在线实时调整驱动面部的尺度，以匹配源面部，从而确保最终结果的身份一致性。此外，该研究还将尺度转换模块学习到的潜在尺度代码融入到生成过程的每一层，进一步提高了模型的性能。<br>性能：实验结果表明，OSTNet能够正确地对驱动面部进行尺度调整，以匹配源面部，从而生成高质量的视频。与现有的先进技术相比，OSTNet产生的结果更加真实、自然。<br>工作量：文章详细描述了OSTNet的设计和实现过程，包括尺度转换模块、网格生成器等的构建和训练。此外，文章还进行了大量的实验来验证其性能，并进行了消融研究以证明尺度转换的重要性。因此，该文章的工作量较大，需要较高的研究成本和技术水平。</p>
</li>
</ul>
</li>
</ol>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5acf47853b5d17c67549f1042fb2fe6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23abc00e37d87ece2f4c6a2471fd0aa7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7464316ca63b1ab0122b51fef32eb658.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fab1af3538b50b4d8bcaacc927991b9.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-07-26/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-07-26/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-07-26/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-355665cbb72ae67f4cc54016e50fe767.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2024-07-26  DHGS Decoupled Hybrid Gaussian Splatting for Driving Scene
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-07-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-07-26/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b7ff7c6e89adbcaf8b33955c5029e9a5.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-07-26  Self-supervised pre-training with diffusion model for few-shot landmark   detection in x-ray images
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-07-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">9690.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
