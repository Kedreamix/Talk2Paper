<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="元宇宙/虚拟人">
    <meta name="description" content="元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2024-09-27  DreamWaltz-G Expressive 3D Gaussian Avatars from Skeleton-Guided 2D   Diffusion">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>元宇宙/虚拟人 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-41ce0c960b001c3433e8f53f14598019.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">元宇宙/虚拟人</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                <span class="chip bg-color">元宇宙/虚拟人</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                元宇宙/虚拟人
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-09-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    22 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-09-27-更新"><a href="#2024-09-27-更新" class="headerlink" title="2024-09-27 更新"></a>2024-09-27 更新</h1><h2 id="DreamWaltz-G-Expressive-3D-Gaussian-Avatars-from-Skeleton-Guided-2D-Diffusion"><a href="#DreamWaltz-G-Expressive-3D-Gaussian-Avatars-from-Skeleton-Guided-2D-Diffusion" class="headerlink" title="DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D   Diffusion"></a>DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D   Diffusion</h2><p><strong>Authors:Yukun Huang, Jianan Wang, Ailing Zeng, Zheng-Jun Zha, Lei Zhang, Xihui Liu</strong></p>
<p>Leveraging pretrained 2D diffusion models and score distillation sampling (SDS), recent methods have shown promising results for text-to-3D avatar generation. However, generating high-quality 3D avatars capable of expressive animation remains challenging. In this work, we present DreamWaltz-G, a novel learning framework for animatable 3D avatar generation from text. The core of this framework lies in Skeleton-guided Score Distillation and Hybrid 3D Gaussian Avatar representation. Specifically, the proposed skeleton-guided score distillation integrates skeleton controls from 3D human templates into 2D diffusion models, enhancing the consistency of SDS supervision in terms of view and human pose. This facilitates the generation of high-quality avatars, mitigating issues such as multiple faces, extra limbs, and blurring. The proposed hybrid 3D Gaussian avatar representation builds on the efficient 3D Gaussians, combining neural implicit fields and parameterized 3D meshes to enable real-time rendering, stable SDS optimization, and expressive animation. Extensive experiments demonstrate that DreamWaltz-G is highly effective in generating and animating 3D avatars, outperforming existing methods in both visual quality and animation expressiveness. Our framework further supports diverse applications, including human video reenactment and multi-subject scene composition. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.17145v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://yukun-huang.github.io/DreamWaltz-G/">https://yukun-huang.github.io/DreamWaltz-G/</a></p>
<p><strong>Summary</strong><br>利用预训练的2D扩散模型和分数蒸馏采样，提出DreamWaltz-G框架，实现从文本到可动3D虚拟人生成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>结合2D扩散模型和SDS，实现文本到3D虚拟人生成。</li>
<li>DreamWaltz-G框架基于骨骼引导的分数蒸馏和混合3D高斯虚拟人表示。</li>
<li>骨骼引导的分数蒸馏增强SDS监督的视角和姿态一致性。</li>
<li>混合3D高斯虚拟人表示结合神经隐式场和参数化3D网格，实现实时渲染。</li>
<li>实验证明DreamWaltz-G在生成和动画3D虚拟人方面优于现有方法。</li>
<li>框架支持人视频重演和多主题场景合成等应用。</li>
<li>提升了动画表达性和视觉质量。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>标题：DreamWaltz-G：基于文本驱动的动画3D角色生成学习框架</p>
</li>
<li><p>作者：黄玉坤、王建安、曾爱玲、IEEE会员、郑俊杰、IEEE会员、张磊、IEEE资深会员、刘希辉、IEEE会员</p>
</li>
<li><p>所属机构：（按顺序）香港大学（HKU）、Astribot公司、腾讯公司、中国科学技术大学（USTC）、国际数字经济学院（IDEA）。</p>
</li>
<li><p>关键词：3D角色生成、3D人类模型、动态动画、扩散模型、分数蒸馏、3D高斯。</p>
</li>
<li><p>链接：论文链接（待补充），GitHub代码链接（如有）。</p>
</li>
<li><p>摘要：</p>
<p> (1) 研究背景：随着电影制作、游戏设计、虚拟现实等技术的快速发展，对高质量的3D角色生成的需求日益增长。传统的3D角色创建方法耗时耗力，而基于文本的3D角色生成成为了一种新的趋势。本文提出了一种基于文本驱动的零样本学习框架DreamWaltz-G，用于高质量的动画3D角色生成。</p>
<p> (2) 过往方法与问题：虽然现有方法利用预训练的二维扩散模型和分数蒸馏采样（SDS）在文本到三维角色的生成上取得了显著成果，但在生成高质量且能进行动态动画的三维角色方面仍面临挑战。问题包括几何结构的不准确，纹理细节的缺失，以及动态姿态下的变形问题等。</p>
<p> (3) 研究方法：本文提出的DreamWaltz-G框架通过Skeleton-guided Score Distillation（SkelSD）和Hybrid 3D Gaussian Avatars（H3GA）解决了上述问题。SkelSD通过将三维人体模板的骨架控制引入二维扩散模型，增强了SDS的稳定性并保持了三维一致性。H3GA则是一种混合的三维表示方法，旨在适应SDS优化并实现动态动画。具体来说，H3GA结合了神经隐式场和参数化三维网格，以实现实时渲染、稳定的SDS优化和动态动画。</p>
<p> (4) 任务与性能：本文在文本驱动的3D角色生成任务上进行了实验验证，DreamWaltz-G框架在视觉质量和动画表现力方面均表现出卓越的性能，超过了现有方法。此外，该框架还支持多种应用，如人类视频重演和多主体场景组合等。实验结果证明了其有效性和实用性。</p>
</li>
</ol>
<p>希望这个概括符合您的要求！如有任何修改或进一步的需求，请告知。<br>7. 方法论：</p>
<p>（1）研究背景：随着电影制作、游戏设计、虚拟现实等技术的快速发展，对高质量的3D角色生成的需求日益增长。传统的3D角色创建方法耗时耗力，因此，研究出一种基于文本驱动的零样本学习框架DreamWaltz-G用于高质量的动画3D角色生成显得尤为重要。</p>
<p>（2）现有问题与挑战：现有方法虽然已经在文本到三维角色的生成上取得显著成果，但仍存在几何结构不准确、纹理细节缺失以及在动态姿态下的变形问题等挑战。</p>
<p>（3）研究方法介绍：针对上述问题与挑战，本文提出了基于文本驱动的零样本学习框架DreamWaltz-G。该框架主要包括两个部分：Skeleton-guided Score Distillation（SkelSD）和Hybrid 3D Gaussian Avatars（H3GA）。SkelSD通过将三维人体模板的骨架控制引入二维扩散模型，增强了SDS的稳定性并保持了三维一致性。H3GA则是一种混合的三维表示方法，旨在适应SDS优化并实现动态动画。具体来说，H3GA结合了神经隐式场和参数化三维网格，以实现实时渲染、稳定的SDS优化和动态动画。</p>
<p>（4）实验验证与性能表现：本文在文本驱动的3D角色生成任务上进行了实验验证，结果显示DreamWaltz-G框架在视觉质量和动画表现力方面均表现出卓越的性能，超过了现有方法。此外，该框架还支持多种应用，如人类视频重演和多主体场景组合等。实验结果证明了其有效性和实用性。</p>
<p>以上就是这篇论文的方法论部分的详细介绍。希望符合您的要求。<br>8. Conclusion:</p>
<p>(1) 这项工作的意义在于提出了一种基于文本驱动的零样本学习框架DreamWaltz-G，用于高质量的动画3D角色生成。该框架的应用能够简化3D角色创建流程，满足电影制作、游戏设计、虚拟现实等领域对高质量3D角色的需求。</p>
<p>(2) 创新点：文章提出了Skeleton-guided Score Distillation（SkelSD）和Hybrid 3D Gaussian Avatars（H3GA）方法，解决了现有方法在3D角色生成中的几何结构不准确、纹理细节缺失以及在动态姿态下的变形问题。<br>性能：实验验证显示，DreamWaltz-G框架在视觉质量和动画表现力方面表现出卓越的性能，超过了现有方法。<br>工作量：文章涉及的实验和验证工作量大，证明了该框架的有效性和实用性。</p>
<p>总体而言，这篇文章在3D角色生成领域具有一定的创新性和实用性，对于相关领域的研究者和从业人员具有一定的参考和借鉴意义。</p>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-46a505fa4b2507a447461e4be7fc391d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-2973cbb3e36d49ef1f3e15f1a0f4b9f1.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2db9d9f5f928ad1d410198eae8af56b9.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-eae97248119c175e5de4631c7bd39e08.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9a55f7407de4159e931c08bc20ba1e01.jpg" align="middle">
</details>




<h2 id="Gaussian-Deja-vu-Creating-Controllable-3D-Gaussian-Head-Avatars-with-Enhanced-Generalization-and-Personalization-Abilities"><a href="#Gaussian-Deja-vu-Creating-Controllable-3D-Gaussian-Head-Avatars-with-Enhanced-Generalization-and-Personalization-Abilities" class="headerlink" title="Gaussian Déjà-vu: Creating Controllable 3D Gaussian Head-Avatars   with Enhanced Generalization and Personalization Abilities"></a>Gaussian Déjà-vu: Creating Controllable 3D Gaussian Head-Avatars   with Enhanced Generalization and Personalization Abilities</h2><p><strong>Authors:Peizhi Yan, Rabab Ward, Qiang Tang, Shan Du</strong></p>
<p>Recent advancements in 3D Gaussian Splatting (3DGS) have unlocked significant potential for modeling 3D head avatars, providing greater flexibility than mesh-based methods and more efficient rendering compared to NeRF-based approaches. Despite these advancements, the creation of controllable 3DGS-based head avatars remains time-intensive, often requiring tens of minutes to hours. To expedite this process, we here introduce the &#96;&#96;Gaussian D&#39;ej`a-vu” framework, which first obtains a generalized model of the head avatar and then personalizes the result. The generalized model is trained on large 2D (synthetic and real) image datasets. This model provides a well-initialized 3D Gaussian head that is further refined using a monocular video to achieve the personalized head avatar. For personalizing, we propose learnable expression-aware rectification blendmaps to correct the initial 3D Gaussians, ensuring rapid convergence without the reliance on neural networks. Experiments demonstrate that the proposed method meets its objectives. It outperforms state-of-the-art 3D Gaussian head avatars in terms of photorealistic quality as well as reduces training time consumption to at least a quarter of the existing methods, producing the avatar in minutes. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.16147v1">PDF</a> 11 pages, Accepted by WACV 2025 in Round 1</p>
<p><strong>Summary</strong><br>3DGS头像建模技术升级，提出“Gaussian D&#39;ej`a-vu”框架，缩短个性化建模时间。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGS技术提升3D头像建模灵活性，渲染效率高。</li>
<li>创建3DGS头像需耗时，新框架旨在加速此过程。</li>
<li>框架包括通用模型训练和个性化定制。</li>
<li>通用模型基于大型2D图像数据集训练。</li>
<li>个性化定制通过单目视频实现，优化3D Gaussians。</li>
<li>使用可学习的表达感知混合图校正，提高收敛速度。</li>
<li>新方法在真实感质量和训练时间上优于现有技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 高斯戴贾维：创建可控的3D高斯头部化身的方法<br>Abstract: 该论文提出了一种创建可控的3D高斯头部化身的方法，通过训练一个重建模型在大型人脸图像数据集上获得通用模型，并将其用于初始化个性化的头部化身。该方法使用合成和真实图像数据集进行训练，并通过单目视频进一步细化得到个性化的头部化身。实验表明，该方法在达到目标的同时，在逼真度和训练时间消耗方面优于现有的最先进的3D高斯头化身技术。</p>
</li>
<li><p>Authors: PeiZhi Yan（皮志燕）, Rabab Ward（拉巴卜·沃德）, Qiang Tang（唐强）, Shan Du（单杜）等。</p>
</li>
<li><p>Affiliation: 隶属于英国哥伦比亚大学（Yan和Ward）以及华为加拿大研究中心（Tang）。Du来自英国哥伦比亚大学奥肯根校区。</p>
</li>
<li><p>Keywords: 3D Gaussian Head Avatar, Gaussian D´ej&#96;a-vu, Controllable Avatars, 3D Face Reconstruction, Personalized Avatars。</p>
</li>
<li><p>Urls: 请查看原文提供的链接。关于GitHub代码链接，由于我无法直接访问GitHub或其他在线数据库来查找信息，所以无法提供具体的链接。如果论文中有提及具体的GitHub链接，请直接在论文中查找。</p>
</li>
<li><p>Summary: </p>
<ul>
<li>(1)研究背景：随着视频游戏、虚拟现实和增强现实、电影制作、远程出席等行业的快速发展，创建逼真的三维头部化身变得越来越重要。现有的方法虽然取得了一定的成果，但在效率、质量和可控性方面仍存在挑战。因此，本文提出了一种创建可控的3D高斯头部化身的新方法。</li>
<li>(2)过去的方法及其问题：现有的方法主要基于网格或NeRF技术创建三维头部化身。这些方法虽然可以实现一定程度的逼真度，但在效率、渲染速度和控制方面存在问题。此外，个性化头部化身创建通常需要大量的时间和计算资源。因此，需要一种新的方法来克服这些问题。</li>
<li>(3)研究方法：本文提出了高斯戴贾维（Gaussian Deja-vu）框架来创建可控的3D高斯头部化身。首先，通过训练一个重建模型在大型人脸图像数据集上获得通用模型。然后，使用合成和真实图像数据集进行训练，并通过单目视频进一步细化得到个性化的头部化身。为了个性化，本文提出了可学习的表情感知校正映射图（learnable expression-aware rectification blendmaps），用于纠正初始的3D高斯模型，确保快速收敛且不依赖神经网络。</li>
<li>(4)任务与性能：实验表明，该方法在创建逼真的三维头部化身方面表现出优异的性能，不仅提高了质量，而且大大减少了训练时间消耗。与传统方法相比，该方法的训练时间至少减少了四分之一，能够在几分钟内生成头部化身。这些成果支持了该方法的有效性。</li>
</ul>
</li>
</ol>
<p>希望以上内容符合您的要求。<br>7. Methods:</p>
<pre><code>- (1) 研究背景分析：随着视频游戏、虚拟现实和增强现实等行业的快速发展，创建逼真的三维头部化身变得越来越重要。现有的方法在效率、质量和可控性方面存在挑战。

- (2) 数据准备：首先，研究团队使用大型人脸图像数据集训练了一个重建模型，获得了通用模型。接着，使用合成和真实图像数据集进行训练。

- (3) 个性化头部化身创建：通过单目视频进一步细化，得到个性化的头部化身。为了实现个性化，研究团队提出了可学习的表情感知校正映射图（learnable expression-aware rectification blendmaps），用于纠正初始的3D高斯模型。

- (4) 方法优化：该研究采用的高斯戴贾维（Gaussian Deja-vu）框架确保了快速收敛，并且不依赖神经网络，从而大大提高了创建个性化头部化身的效率。

- (5) 实验验证：实验结果表明，该方法在创建逼真的三维头部化身方面表现出优异的性能，不仅提高了质量，而且大大减少了训练时间消耗。与传统方法相比，该方法的训练时间至少减少了四分之一，能够在几分钟内生成头部化身。
</code></pre>
<ol start="8">
<li><p>Conclusion:</p>
<ul>
<li><p>(1) 这项工作的意义在于提出了一种创建可控的3D高斯头部化身的新方法，具有重要的应用价值。随着视频游戏、虚拟现实和增强现实等行业的快速发展，创建逼真的三维头部化身的需求越来越迫切。该研究提出的D´ej&#96;a-vu框架能够基于单张图像进行三维重建，并通过学习和调整实现个性化表达，具有广泛的应用前景。</p>
</li>
<li><p>(2) 创新点：该研究提出了一种新的创建可控的3D高斯头部化身的方法，具有显著的创新性。与传统的三维头部化身创建方法相比，该研究采用了先进的深度学习技术，并结合图像合成和真实图像数据集进行训练，实现了较高的逼真度和训练效率。同时，该研究还提出了可学习的表情感知校正映射图（learnable expression-aware rectification blendmaps），用于纠正初始的3D高斯模型，确保了快速收敛且不依赖神经网络。性能：实验结果表明，该方法在创建逼真的三维头部化身方面表现出优异的性能，不仅提高了质量，而且大大减少了训练时间消耗。与传统方法相比，该方法的训练时间至少减少了四分之一。工作量：该研究的工作量较大，涉及到大量的数据准备、模型训练和实验验证等工作。但研究结果具有显著的成效，为后续的相关研究提供了有益的参考和启示。</p>
</li>
</ul>
</li>
</ol>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-802802d534cf5037688351f162caf1cf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-41ce0c960b001c3433e8f53f14598019.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6fcd3ef7a1064ac1787a3a9488d68df8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-35ca8870fea42c6b9c3feb32de431d47.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-14cc411449649510fb55a247aa080e88.jpg" align="middle">
</details>




<h2 id="Barbie-Text-to-Barbie-Style-3D-Avatars"><a href="#Barbie-Text-to-Barbie-Style-3D-Avatars" class="headerlink" title="Barbie: Text to Barbie-Style 3D Avatars"></a>Barbie: Text to Barbie-Style 3D Avatars</h2><p><strong>Authors:Xiaokun Sun, Zhenyu Zhang, Ying Tai, Qian Wang, Hao Tang, Zili Yi, Jian Yang</strong></p>
<p>Recent advances in text-guided 3D avatar generation have made substantial progress by distilling knowledge from diffusion models. Despite the plausible generated appearance, existing methods cannot achieve fine-grained disentanglement or high-fidelity modeling between inner body and outfit. In this paper, we propose Barbie, a novel framework for generating 3D avatars that can be dressed in diverse and high-quality Barbie-like garments and accessories. Instead of relying on a holistic model, Barbie achieves fine-grained disentanglement on avatars by semantic-aligned separated models for human body and outfits. These disentangled 3D representations are then optimized by different expert models to guarantee the domain-specific fidelity. To balance geometry diversity and reasonableness, we propose a series of losses for template-preserving and human-prior evolving. The final avatar is enhanced by unified texture refinement for superior texture consistency. Extensive experiments demonstrate that Barbie outperforms existing methods in both dressed human and outfit generation, supporting flexible apparel combination and animation. The code will be released for research purposes. Our project page is: <a target="_blank" rel="noopener" href="https://xiaokunsun.github.io/Barbie.github.io/">https://xiaokunsun.github.io/Barbie.github.io/</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09126v4">PDF</a> 9 pages, 7 figures, Project page:   <a target="_blank" rel="noopener" href="https://xiaokunsun.github.io/Barbie.github.io/">https://xiaokunsun.github.io/Barbie.github.io/</a></p>
<p><strong>Summary</strong><br>提出Barbie框架，实现精细解耦的3D虚拟人生成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文章提出Barbie框架，用于生成可穿戴多样化服装的3D虚拟人。</li>
<li>通过语义对齐的分离模型实现人体和服装的精细解耦。</li>
<li>采用不同专家模型优化解耦的3D表示，确保特定领域的高保真度。</li>
<li>设计一系列损失函数，平衡几何多样性和合理性。</li>
<li>统一纹理细化提升纹理一致性。</li>
<li>实验证明Barbie在服装组合和动画方面优于现有方法。</li>
<li>代码将公开发布，方便研究。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 基于文本指导的Barbie风格3D虚拟人生成研究</p>
</li>
<li><p>Authors: Xiaokun Sun, Zhenyu Zhang, Ying Tai, Qian Wang, Hao Tang, Zili Yi, Jian Yang</p>
</li>
<li><p>Affiliation: 南京大学教授Sun Xiaokun等</p>
</li>
<li><p>Keywords: Text-to-Avatar Generation; 3D Avatar; Text-Guided; Fine-grained Disentanglement; Domain-Specific Fidelity</p>
</li>
<li><p>Urls: <a target="_blank" rel="noopener" href="https://xiaokunsun.github.io/Barbie.github.io/%EF%BC%9BGithub">https://xiaokunsun.github.io/Barbie.github.io/；Github</a>: None</p>
</li>
<li><p>Summary:</p>
</li>
</ol>
<p>(1) 研究背景：近年来，随着AR&#x2F;VR技术的普及，创建3D数字人类引起了广泛关注。自动生成3D虚拟人的方法需要大规模的三维人类数据用于训练，这极大地限制了其应用范围。得益于文本到图像和文本到3D领域的快速发展，利用自然语言输入进行虚拟人生成已成为越来越受欢迎的研究方向。</p>
<p>(2) 过去的方法及问题：现有的文本到虚拟人的工作大致分为两类：生成整体虚拟人和生成身体与服装的解耦模型。整体虚拟人的生成方法虽然可以实现较高的逼真度，但缺乏灵活性，无法自由更换服装或进行服装转移等应用。解耦方法的目的是将身体和衣物分别建模，但存在精细度不足、服装和配饰生成不真实等问题。</p>
<p>(3) 研究方法：本研究提出了一种新型的基于文本指导的Barbie风格3D虚拟人生成框架。该框架通过语义对齐的分离模型实现身体和服装的精细解耦。使用不同的专家模型对解耦后的3D表示进行优化，以保证领域特定的保真度。通过一系列损失函数平衡几何多样性和合理性，同时采用统一的纹理优化算法提高纹理一致性。</p>
<p>(4) 任务与性能：本研究的方法在着装人类生成和服装生成方面表现出优异的性能，支持灵活的服装组合和动画。实验结果表明，Barbie在几何多样性、纹理逼真度和细节精细度等方面均优于现有方法。性能结果支持该研究的目标，即生成具有高度逼真度、多样性和解耦度的Barbie风格3D虚拟人。<br>7. 方法论：</p>
<pre><code>- (1) 研究背景：近年来，随着AR/VR技术的普及，创建3D数字人类引起了广泛关注。自动生成3D虚拟人的方法需要大规模的三维人类数据用于训练，这极大地限制了其应用范围。该研究提出了一种基于文本指导的Barbie风格3D虚拟人生成框架，旨在解决现有方法的问题。

- (2) 研究方法：该研究采用了一种新型的基于文本指导的Barbie风格3D虚拟人生成框架。首先，利用SMPL-X参数化人体模型表示全身的形状、姿态和表情。然后，采用Score Distillation Sampling方法，借助预训练的T2I模型指导3D表示与输入文本对齐。此外，研究采用了DMTet混合表示法，能够高效表示隐式签名距离函数（SDF）和可微分的四面体层。

- (3) 流程设计：研究流程分为三个关键阶段。第一阶段是生成高质量的人体，采用有针对性的专家扩散模型进行特定正则化，产生高质量和合理的人体（Sec. 3.3）。第二阶段是生成服装，采用对象特定的扩散模型进行纹理建模（Sec. 3.4）。最后是组成虚拟人的微调阶段，采用统一的纹理优化算法提高纹理的一致性（Sec. 3.5）。

- (4) 技术细节：在人体生成方面，研究采用SMPL-X网格进行准确的初始输入，并采用可微分渲染器和SDS损失来优化形状参数β，根据输入的基本人体描述确定基本人体形状。在几何建模方面，研究利用人类特定的扩散模型进行几何优化，包括正常适应扩散模型、深度适应扩散模型和纹理创建模型。此外，研究还引入了一种自我进化的人类先验损失，通过周期性地适应网格Minit来平衡生成的多样性和合理性。在纹理建模方面，利用正常对齐的扩散模型创建真实和高质量的纹理。

- (5) 创新点：该研究的主要创新在于实现了身体和服装的精细解耦，通过领域特定的保真度优化和统一的纹理优化算法，生成具有高度逼真度、多样性和解耦度的Barbie风格3D虚拟人。同时，该研究的方法在着装人类生成和服装生成方面表现出优异的性能，支持灵活的服装组合和动画。

总的来说，该研究的方法为创建高度逼真、多样且解耦的3D虚拟人提供了一种有效的解决方案。
</code></pre>
<ol start="8">
<li>Conclusion:</li>
</ol>
<ul>
<li><p>(1) 这项工作的意义在于提出了一种基于文本指导的Barbie风格3D虚拟人生成方法，具有广泛的应用前景。它能够根据自然语言输入生成具有高度逼真度、多样性和解耦度的虚拟人，为创建个性化的虚拟角色提供了新的可能性。同时，该方法还展示了在服装生成和组合方面的优异性能，为虚拟时尚、虚拟世界等领域的开发提供了有力支持。</p>
</li>
<li><p>(2) 创新点：该文章的创新之处在于实现了身体和服装的精细解耦，通过领域特定的保真度优化和统一的纹理优化算法，生成了具有高度逼真度、多样性和解耦度的Barbie风格3D虚拟人。其技术细节中的SMPL-X参数化人体模型表示、Score Distillation Sampling方法、DMTet混合表示法等均体现了作者的技术水平与创新思维。但现有的工作可能仍然存在对于复杂纹理和细节的处理不够完善的问题，未来的研究可以进一步探索如何进一步提高生成虚拟人的逼真度和细节质量。性能上，该文章的方法在几何多样性、纹理逼真度和细节精细度等方面均优于现有方法，体现了其优越的性能表现。工作量上，该文章对方法论进行了详细的阐述和实验验证，展示了作者们丰富的工作量和技术积累。</p>
</li>
</ul>
<details>
  <summary>点此查看论文截图</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-9fe2afd4718a4a603a9059c758303dbc.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-82aef8d8f1aed2ceef69e20d1f2aeaca.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d05a0aab7c3ee1cb21c6111b8ce45bf2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-10380f66381cdb3f0d26a35da5d2c482.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a66b9f1c3e5e087c1b363bb26b124d4e.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-09-27/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">https://kedreamix.github.io/Talk2Paper/Paper/2024-09-27/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                    <span class="chip bg-color">元宇宙/虚拟人</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-09-27/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b0cf5c7e6a853321218751ea3fc0a113.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-09-27  TalkinNeRF Animatable Neural Fields for Full-Body Talking Humans
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-09-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-09-24/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-7611346411aa2d885ee691080836d8c3.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-09-24  Brain-Streams fMRI-to-Image Reconstruction with Multi-modal Guidance
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">7483.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
