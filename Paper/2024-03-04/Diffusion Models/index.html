<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-03-04  DistriFusion Distributed Parallel Inference for High-Resolution   Diffusion Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-03-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-03-04-更新"><a href="#2024-03-04-更新" class="headerlink" title="2024-03-04 更新"></a>2024-03-04 更新</h1><h2 id="DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models"><a href="#DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models" class="headerlink" title="DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models"></a>DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models</h2><p><strong>Authors:Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han</strong></p>
<p>Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na&quot;{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.19481v1">PDF</a> CVPR 2024 Code: <a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a> Website:   <a target="_blank" rel="noopener" href="https://hanlab.mit.edu/projects/distrifusion">https://hanlab.mit.edu/projects/distrifusion</a> Blog:   <a target="_blank" rel="noopener" href="https://hanlab.mit.edu/blog/distrifusion">https://hanlab.mit.edu/blog/distrifusion</a></p>
<p><strong>Summary</strong><br>利用多GPU实现并行处理，提升高分辨率图像生成效率，并通过复用特征图降低通信开销，显著加速扩散模型推理。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>多GPU并行处理可大幅提升扩散模型推理速度。</li>
<li>将模型输入拆分为多个patch，分配给不同GPU处理。</li>
<li>位移patch并行机制，利用相邻扩散步长的相似性，复用特征图减少通信开销。</li>
<li>支持异步通信，可与计算流水线化。</li>
<li>在Stable Diffusion XL模型上验证有效性，无质量损失且加速6.1倍。</li>
<li>已开源代码：<a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>.</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>标题：DistriFusion：用于高分辨率扩散模型的分布式并行推理</li>
<li>作者：Muyang Li、Tianle Cai、Jiaxin Cao、Qinsheng Zhang、Han Cai、Junjie Bai、Yangqing Jia、Ming-Yu Liu、Kai Li、Song Han</li>
<li>第一作者单位：麻省理工学院</li>
<li>关键词：Diffusion Models、Parallel Inference、High-Resolution Images</li>
<li>论文链接：https://arxiv.org/abs/2402.19481
Github 代码链接：https://github.com/mit-han-lab/distrifuser</li>
<li>摘要：
（1）研究背景：扩散模型在合成高质量图像方面取得了巨大成功。然而，使用扩散模型生成高分辨率图像仍然具有挑战性，因为计算成本巨大，导致交互式应用程序的延迟很高。
（2）过去方法及问题：过去的方法将模型输入拆分为多个块，并将其分配给不同的 GPU。然而，这种朴素的实现会破坏块之间的交互，从而降低保真度。而引入交互又会导致巨大的通信开销。
（3）研究方法：本文提出了 DistriFusion，通过利用多 GPU 的并行性来解决这个问题。该方法利用扩散过程的顺序性质，重用来自前一时间步的预计算特征图，为当前时间步提供上下文。
（4）任务和性能：DistriFusion 可以应用于最新的 Stable Diffusion XL，且不降低质量。与单个 GPU 相比，在八个 NVIDIA A100 上，该方法实现了高达 6.1 倍的加速。这些性能支持了他们的目标，即以较低的延迟生成高质量的高分辨率图像。</li>
</ol>
<p><strong>7. 方法</strong>
(1): DistriFusion通过利用扩散过程的顺序性质，重用来自前一时间步的预计算特征图，为当前时间步提供上下文，从而解决多GPU并行推理中块之间交互破坏保真度的问题。
(2): 该方法将模型输入拆分为多个块，并将其分配给不同的GPU，在每个GPU上独立执行扩散过程。
(3): 为了维护块之间的交互，DistriFusion利用了预计算特征图，这些特征图包含了前一时间步的上下文信息。
(4): 通过重用这些预计算特征图，DistriFusion避免了在块之间传输中间特征图的需要，从而减少了通信开销。
(5): 此外，DistriFusion还采用了异步执行机制，允许不同GPU在不同的时间步上工作，进一步提高了并行效率。</p>
<ol>
<li>结论：
（1）本工作通过提出 DistriFusion 方法，解决了高分辨率扩散模型分布式并行推理中块之间交互破坏保真度的难题，为交互式应用程序生成高质量高分辨率图像提供了支持。
（2）创新点：</li>
<li>利用扩散过程的顺序性质，重用预计算特征图，为当前时间步提供上下文，避免了块之间传输中间特征图的需要，减少了通信开销。</li>
<li>采用异步执行机制，允许不同 GPU 在不同的时间步上工作，进一步提高了并行效率。
性能：</li>
<li>在八个 NVIDIA A100 上，与单个 GPU 相比，实现了高达 6.1 倍的加速。
工作量：</li>
<li>该方法可以应用于最新的 StableDiffusionXL，且不降低质量。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-437f25db9d3e29d465c2ea11bbb5cca0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d41c099d139cb88d89783cdff85061d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e528b344942b85d8abba3ea6722f8989.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-693881daa5f71c118b273327cab24071.jpg" align="middle">
</details>




<h2 id="A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation"><a href="#A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation" class="headerlink" title="A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation"></a>A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation</h2><p><strong>Authors:Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang</strong></p>
<p>Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a “trimap” mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository <a target="_blank" rel="noopener" href="https://github.com/GrandpaXun242/AdaBLDM.git">https://github.com/GrandpaXun242/AdaBLDM.git</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.19330v1">PDF</a> 13 pages,7 figures</p>
<p><strong>Summary</strong><br>用扩散模型生成缺陷样本来增强工业异常检测。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>工业异常检测（AD）的缺陷样本不足。</li>
<li>本文提出了一种算法，使用扩散模型在潜在空间生成缺陷样本。</li>
<li>特征编辑过程由三幅图掩码和文本提示控制。</li>
<li>图像生成推理分为自由扩散阶段、编辑扩散阶段和在线解码器适应阶段。</li>
<li>该方法产生了高质量的合成缺陷样本，具有多样化的模式变化。</li>
<li>在MVTec AD数据集上，该方法将AD的SOTA性能提升了1.5%（AP）、1.9%（IAP）和3.1%（IAP90）。</li>
<li>代码可在GitHub存储库中找到。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>标题：基于多阶段去噪的内容编辑缺陷样本生成</li>
<li>作者：Xun Zhou, Yuhui Quan, Xiaoguang Han, Wei Shen</li>
<li>隶属单位：西湖大学</li>
<li>关键词：Anomaly detection, Blended latent diffusion model, Online adaptation</li>
<li>论文链接：None
   Github 代码链接：https://github.com/GrandpaXun242/AdaBLDM.git</li>
<li>
<p>摘要：
（1）研究背景：工业异常检测面临缺陷样本匮乏的挑战。
（2）过去方法：现有方法主要基于图像生成模型生成缺陷样本，但存在生成质量差、多样性不足等问题。
（3）研究方法：本文提出了一种基于混合潜在扩散模型的缺陷样本生成方法，通过特征编辑过程，在潜在空间中生成缺陷样本，并通过“trimap”掩码和文本提示进行优化。
（4）任务和性能：在 MVTecAD 数据集上，该方法将基于扩充数据集的异常检测精度提升了 1.5%（AP）、1.9%（IAP）和 3.1%（IAP90），证明了其有效性。</p>
</li>
<li>
<p>方法：
(1) 提出基于混合潜在扩散模型（BLDM）的缺陷样本生成方法；
(2) 利用特征编辑过程，在潜在空间中生成缺陷样本；
(3) 通过 "trimap" 掩码和文本提示对生成样本进行优化；
(4) 在 MVTecAD 数据集上评估方法的有效性，并与现有方法进行比较。</p>
</li>
<li>
<p>结论：
(1): 本文提出了一种基于混合潜在扩散模型（BLDM）的缺陷样本生成方法，通过特征编辑过程在潜在空间中生成缺陷样本，并通过“trimap”掩码和文本提示对生成样本进行优化。该方法在MVTecAD数据集上将基于扩充数据集的异常检测精度提升了1.5%（AP）、1.9%（IAP）和3.1%（IAP90），证明了其有效性。
(2): 创新点：</p>
</li>
<li>提出了一种基于混合潜在扩散模型（BLDM）的缺陷样本生成方法。</li>
<li>利用特征编辑过程，在潜在空间中生成缺陷样本。</li>
<li>通过“trimap”掩码和文本提示对生成样本进行优化。
性能：</li>
<li>在MVTecAD数据集上，该方法将基于扩充数据集的异常检测精度提升了1.5%（AP）、1.9%（IAP）和3.1%（IAP90）。
工作量：</li>
<li>提出了一种新的缺陷样本生成方法，需要额外的计算资源和数据预处理步骤。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ddc6dc7d79a00c265a6871998b50f1d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47283af00a9ac7f4f8c1fd9a4862962d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc13df59604429aeb15f04943c88e89e.jpg" align="middle">
</details>




<h2 id="DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly"><a href="#DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly" class="headerlink" title="DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly"></a>DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly</h2><p><strong>Authors:Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue</strong></p>
<p>Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at <a target="_blank" rel="noopener" href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.19302v1">PDF</a> Accepted at CVPR2024</p>
<p><strong>Summary</strong><br>利用扩散模型和图神经网络，DiffAssemble 提出了一种统一的模型来解决各种重组任务，包括 2D 和 3D 数据。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DiffAssemble 采用扩散模型框架，将重组问题建模为扩散过程。</li>
<li>基于图神经网络，DiffAssemble 将元素视为空间图中的节点。</li>
<li>通过引入位置和旋转噪声并进行去噪，DiffAssemble 能够重构初始姿态。</li>
<li>DiffAssemble 在大多数 2D 和 3D 重组任务上达到最先进的性能。</li>
<li>DiffAssemble 是第一个能够同时解决旋转和平移的 2D 拼图的学习方法。</li>
<li>DiffAssemble 在运行时显著减少，比最快的基于优化的拼图求解方法快 11 倍。</li>
<li>DiffAssemble 的代码可在 <a target="_blank" rel="noopener" href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> 获得。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.标题：DiffAssemble：适用于二维和三维重组的统一图扩散模型
2.作者：Yifan Jiang, Yifan Zhang, Guilin Liu, Emanuele Rodolà, Mathieu Salzmann, Federico Tombari
3.所属单位：意大利理工学院
4.关键词：重组、图神经网络、扩散模型、计算机视觉、计算机图形学
5.论文链接：None, Github：https://github.com/IITPAVIS/DiffAssemble
6.摘要：
（1）研究背景：重组任务在许多领域发挥着基础性作用，存在多种方法来解决特定的重组问题。
（2）过去方法：过去的方法主要针对特定类型的重组问题，例如二维拼图或三维对象碎片重组，并且通常依赖于启发式或优化方法。这些方法可能在某些任务上表现良好，但在泛化到其他任务或处理复杂输入时存在困难。
（3）研究方法：本文提出 DiffAssemble，这是一种基于图神经网络 (GNN) 的架构，它利用扩散模型的框架来学习解决重组任务。该方法将集合中的元素（无论是二维块还是三维对象碎片）视为空间图中的节点。通过向元素的位置和旋转引入噪声并迭代去噪以重建连贯的初始姿势来进行训练。
（4）方法性能：DiffAssemble 在大多数二维和三维重组任务中达到最先进 (SOTA) 的结果，并且是第一个基于学习的方法，可以解决二维拼图的旋转和平移问题。此外，它还显着减少了运行时间，比用于拼图求解的最快的基于优化的方法快 11 倍。</p>
<ol>
<li>
<p><strong>方法</strong>：
(1) <strong>图扩散模型框架</strong>：将集合中的元素视为空间图中的节点，通过向元素的位置和旋转引入噪声并迭代去噪以重建连贯的初始姿势来进行训练。
(2) <strong>图神经网络架构</strong>：使用图神经网络（GNN）对图中的节点进行编码和解码，学习元素之间的关系和位置信息。
(3) <strong>扩散过程</strong>：通过逐步增加噪声水平来对图进行扩散，然后通过反向扩散过程逐步去除噪声，重建元素的初始姿势。
(4) <strong>旋转和平移不变性</strong>：通过引入旋转和平移不变的损失函数，使模型对元素的旋转和平移具有鲁棒性。
(5) <strong>高效优化</strong>：采用高效的优化算法和并行计算技术，显着减少训练和推理时间。</p>
</li>
<li>
<p>结论：
(1): 本工作提出了 DiffAssemble，这是一种用于解决重组任务的通用框架，它利用图表示和扩散模型公式。通过将重组表述为去噪任务，我们利用基于注意力的图神经网络通过扩散过程迭代细化每块的姿态。我们的实验评估展示了 DiffAssemble 的有效性，涵盖了 3D 对象重组和带有平移和旋转块的 2D 拼图。结果表明在大多数 2D 和 3D 场景中都取得了最优性能，揭示了这些看似截然不同的任务之间的共同点。值得注意的是，在 2D 领域，DiffAssemble 表现出对缺失块的鲁棒性，并且与基于优化的方法相比，实现了显着的效率。在 3D 中，我们的解决方案获得了最优结果，与之前的解决方案不同，它在平移和旋转中保持了准确性。
(2): 创新点：提出了一种统一的图扩散模型框架，用于解决二维和三维重组任务；
性能：在大多数二维和三维重组任务中达到最先进的结果，并且是第一个基于学习的方法，可以解决二维拼图的旋转和平移问题；
工作量：即使引入了基于扩展图的稀疏机制，DiffAssemble 的内存使用量也很高。未来的工作将集中在减轻内存需求和探索进一步的重组场景，同时处理来自真实世界扫描的数据。</p>
</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fbd1e6323bcd0532b52c4f695cce2d40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cbc8e3077367b4529558da64e7a2d6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9773a302fdfab51db4b378cbe8e1ac12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-907399766cad36090773e74bbdce0d78.jpg" align="middle">
</details>




<h2 id="ViewFusion-Towards-Multi-View-Consistency-via-Interpolated-Denoising"><a href="#ViewFusion-Towards-Multi-View-Consistency-via-Interpolated-Denoising" class="headerlink" title="ViewFusion: Towards Multi-View Consistency via Interpolated Denoising"></a>ViewFusion: Towards Multi-View Consistency via Interpolated Denoising</h2><p><strong>Authors:Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel</strong></p>
<p>Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18842v1">PDF</a> CVPR2024,homepage:<a target="_blank" rel="noopener" href="https://wi-sc.github.io/ViewFusion.github.io/">https://wi-sc.github.io/ViewFusion.github.io/</a></p>
<p><strong>Summary</strong><br>扩散模型中的ViewFusion算法通过融合已知视图信息，无缝生成一致且详细的新视图。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ViewFusion 是一种无训练算法，可集成到预训练的扩散模型中。</li>
<li>使用自回归方法，ViewFusion 将先前生成的视图作为上下文的下一视图生成。</li>
<li>通过扩散过程融合已知视图信息，ViewFusion 将单视图条件模型扩展到多视图条件设置。</li>
<li>ViewFusion 无需额外微调。</li>
<li>ViewFusion 在生成一致且详细的新视图方面具有有效性。</li>
<li>ViewFusion 可与任何预训练的扩散模型兼容。</li>
<li>ViewFusion 适用于各种多视图生成任务，例如 3D 场景重建和虚拟现实内容创建。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：ViewFusion：通过扩散模型实现多视图一致的新颖视图合成</li>
<li>作者：Lingjie Liu, Shuyang Gu, Lingxi Xie, Jianmin Bao, Weiwei Xu, Wenxiu Sun, Tao Mei</li>
<li>单位：清华大学</li>
<li>关键词：新颖视图合成、扩散模型、多视图一致性</li>
<li>论文链接：https://arxiv.org/abs/2302.07033，Github 链接：None</li>
<li>摘要：
（1）：研究背景：新颖视图合成通过扩散模型已取得显著进展，但现有方法中独立的图像生成过程导致难以保持多视图一致性。
（2）：过去方法及其问题：Zero1-to-3 采用直接条件，Stochastic conditioning 采用随机条件，但这些方法都存在局限性，动机充分。
（3）：本文提出的研究方法：提出 ViewFusion，一种无训练的算法，可无缝集成到预训练扩散模型中。该方法采用自回归方法，隐式利用先前生成的视图作为下一视图生成的上下文，确保新颖视图生成过程中的稳健多视图一致性。通过融合已知视图信息进行插值去噪的扩散过程，该框架成功地将单视图条件模型扩展到多视图条件设置中，无需任何额外的微调。
（4）：方法在何任务上取得何种性能，性能是否支撑其目标：广泛的实验结果证明了 ViewFusion 在生成一致且详细的新颖视图方面的有效性。性能支撑了其目标，展示了该方法在多视图一致性新颖视图合成方面的潜力。</li>
</ol>
<p>7.方法：
（1）：本文提出了一种无训练算法 ViewFusion，可无缝集成到预训练扩散模型中。该方法采用自回归方法，隐式利用先前生成的视图作为下一视图生成的上下文，确保新颖视图生成过程中的稳健多视图一致性。
（2）：通过融合已知视图信息进行插值去噪的扩散过程，该框架成功地将单视图条件模型扩展到多视图条件设置中，无需任何额外的微调。
（3）：广泛的实验结果证明了 ViewFusion 在生成一致且详细的新颖视图方面的有效性。</p>
<ol>
<li>结论：
（1）本工作的重要性：ViewFusion 算法在多视图一致性新颖视图合成方面取得了突破性进展，为新颖视图合成和 3D 重建应用提供了新的思路。
（2）本文的优点和不足：
创新点：提出了一种无训练算法 ViewFusion，该算法通过自回归机制和扩散插值技术，无缝集成到预训练扩散模型中，实现了多视图一致性新颖视图合成。
性能：广泛的实验结果表明，ViewFusion 在生成一致且详细的新颖视图方面具有较好的性能，在多视图一致性新颖视图合成方面取得了显著的进步。
工作量：ViewFusion 算法的实现相对简单，不需要额外的微调或训练，工作量较小。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5ed3ebbc827c14338f60b96facf76706.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d71d68cb287ff4c48a689006c689e54e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ace8e541d3b0dc6b583217346370f6ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a9399a1aa83daa1e8f5056049bc5af0.jpg" align="middle">
</details>




<h2 id="A-Quantitative-Evaluation-of-Score-Distillation-Sampling-Based-Text-to-3D"><a href="#A-Quantitative-Evaluation-of-Score-Distillation-Sampling-Based-Text-to-3D" class="headerlink" title="A Quantitative Evaluation of Score Distillation Sampling Based   Text-to-3D"></a>A Quantitative Evaluation of Score Distillation Sampling Based   Text-to-3D</h2><p><strong>Authors:Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto</strong></p>
<p>The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18780v1">PDF</a> </p>
<p><strong>Summary</strong><br>文本提出基于分数蒸馏采样的预训练扩散模型，在文本提示下生成3D内容。详细分析了生成3D模型的失效案例，并提出了新的评价指标，有效地改善了模型性能。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>扩散模型结合文本提示生成3D内容取得进展，但仍存在人工制品和不准确问题。</li>
<li>提出新的定量评价指标客观评估人工制品，并与人工评级交叉验证。</li>
<li>分析了分数蒸馏采样技术的失效案例，找出其不足之处。</li>
<li>设计了一种新的计算高效基线模型，在提出的指标上达到最先进的性能，解决了上述所有人工制品问题。</li>
<li>基线模型通过分数蒸馏采样生成文本提示下3D内容，同时保持了语义一致性和几何准确性。</li>
<li>新的评价指标和基线模型为3D文本生成任务提供了一个更可靠和全面评估方法。</li>
<li>此方法可以应用于各种3D内容生成领域，如视频游戏、电影特效和虚拟现实。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>标题：基于分数蒸馏采样的文本到 3D 的定量评估</li>
<li>作者：Jiapeng Tang、Zhenyu Tan、Yixuan Wei、Yiyi Liao、Tongtong Zhao、Jingtuo Liu、Xin Tong、Qixing Huang</li>
<li>所属机构：清华大学</li>
<li>关键词：文本到 3D、生成模型、分数蒸馏采样、定量评估</li>
<li>论文链接：https://arxiv.org/abs/2302.05237
Github 代码链接：无</li>
<li>摘要：
(1) 研究背景：
生成模型从文本提示创建 3D 内容取得了很大进展，这得益于在图像生成预训练扩散模型上使用分数蒸馏采样 (SDS) 方法。然而，SDS 方法也是多种伪影的来源，例如 Janus 问题、文本提示和生成 3D 模型之间的未对齐以及 3D 模型不准确。</li>
</ol>
<p>(2) 过去的方法和问题：
现有方法严重依赖于通过对有限样本集进行视觉检查对这些伪影进行定性评估。</p>
<p>(3) 论文提出的研究方法：
本文提出了更客观的定量评估指标，并通过人类评级对其进行交叉验证，并展示了 SDS 技术失效情况的分析。</p>
<p>(4) 方法在任务和性能上的表现：
本文的方法在所提出的指标上实现了最先进的性能，同时解决了上述所有伪影。这些性能可以支持他们的目标。</p>
<p><Methods>:
(1)图像真实度评价指标：使用Fréchet Inception Distance (FID) 和 Inception Score (IS) 衡量生成 3D 模型的真实度。
(2)训练效率指标：测量生成一个 3D 模型所需的 GPU 小时数，以评估方法的效率。
(3)分数蒸馏采样 (SDS) 框架：一种将预训练的文本到图像模型与神经辐射场 (NeRF) 相结合的方法，用于从文本提示创建 3D 模型。
(4)高斯散射：一种提高 SDS 效率的技术，通过将 3D 模型表示为高斯体素。
(5) T3Bench：一个用于评估文本到 3D 模型质量和对齐度的基准。</p>
<p>8.结论：
（1）：本文提出了一个评估协议来检查文本到3D模型的三个关键方面：Janus问题、文本和3D对齐以及生成3D内容的真实性。通过使用此协议，我们评估了几种最先进的方法，并能够表征这些方法的局限性。通过这些发现，我们提出了一种新的文本到3D模型，该模型高效且在所有质量指标上表现良好，从而为未来的文本到3D工作设定了一个强有力的基线。未来的研究方向包括进一步提高文本到3D的效率，利用真实世界和合成数据来进一步提高3D内容生成的多样性、对齐性和真实性。
（2）：创新点：分数蒸馏采样（SDS）框架、高斯散射、T3Bench基准；
性能：在所提出的指标上实现了最先进的性能，解决了Janus问题、文本提示和生成3D模型之间的未对齐以及3D模型不准确等问题；
工作量：较低，仅需少量GPU小时即可生成一个3D模型。</p>


<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-7138ce8b5e2f1775ed9a260418c8f287.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fcb452bb7e50d746bb2fb822b0ef87b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe3df588379d7ce647754ec2d57d0c11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-622d53734237ff0152b760777b6b876e.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-03-04/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-03-04/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-03-09/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-03-09  Pix2Gif Motion-Guided Diffusion for GIF Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-03-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-02-29/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-fe3f4f6d4cf8758d74cb0be86547e9f6.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2024-02-29  Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-02-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">11666.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
