<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  CS-FLEURS A Massively Multilingual and Code-Switched Speech Dataset">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-19-æ›´æ–°"><a href="#2025-09-19-æ›´æ–°" class="headerlink" title="2025-09-19 æ›´æ–°"></a>2025-09-19 æ›´æ–°</h1><h2 id="CS-FLEURS-A-Massively-Multilingual-and-Code-Switched-Speech-Dataset"><a href="#CS-FLEURS-A-Massively-Multilingual-and-Code-Switched-Speech-Dataset" class="headerlink" title="CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset"></a>CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset</h2><p><strong>Authors:Brian Yan, Injy Hamed, Shuichiro Shimizu, Vasista Lodagala, William Chen, Olga Iakovenko, Bashar Talafha, Amir Hussein, Alexander Polok, Kalvin Chang, Dominik Klement, Sara Althubaiti, Puyuan Peng, Matthew Wiesner, Thamar Solorio, Ahmed Ali, Sanjeev Khudanpur, Shinji Watanabe, Chih-Chen Chen, Zhen Wu, Karim Benharrak, Anuj Diwan, Samuele Cornell, Eunjung Yeo, Kwanghee Choi, Carlos Carvalho, Karen Rosero</strong></p>
<p>We present CS-FLEURS, a new dataset for developing and evaluating code-switched speech recognition and translation systems beyond high-resourced languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique code-switched language pairs across 52 languages: 1) a 14 X-English language pair set with real voices reading synthetically generated code-switched sentences, 2) a 16 X-English language pair set with generative text-to-speech 3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the generative text-to-speech, and 4) a 45 X-English lower-resourced language pair test set with concatenative text-to-speech. Besides the four test sets, CS-FLEURS also provides a training set with 128 hours of generative text-to-speech data across 16 X-English language pairs. Our hope is that CS-FLEURS helps to broaden the scope of future code-switched speech research. Dataset link: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/byan/cs-fleurs">https://huggingface.co/datasets/byan/cs-fleurs</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºCS-FLEURSæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘å’Œè¯„ä¼°è·¨é«˜èµ„æºè¯­è¨€ä»£ç åˆ‡æ¢çš„è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ç³»ç»Ÿçš„æ–°æ•°æ®é›†ã€‚CS-FLEURSåŒ…å«å››ä¸ªæµ‹è¯•é›†ï¼Œæ€»å…±è¦†ç›–113ç§ç‹¬ç‰¹çš„ä»£ç åˆ‡æ¢è¯­è¨€å¯¹å’Œ52ç§è¯­è¨€ï¼š1ï¼‰åŒ…å«çœŸå®è¯­éŸ³æœ—è¯»åˆæˆä»£ç åˆ‡æ¢å¥å­çš„14ç§è‹±è¯­å¯¹å¤–çš„è¯­è¨€å¯¹é›†ï¼›2ï¼‰ç”Ÿæˆæ€§æ–‡æœ¬è¯­éŸ³åˆæˆçš„å…·æœ‰åˆ›é€ æ€§æ–‡æœ¬çš„å¸¦æœ‰è¯­è¨€å€¾å‘çš„å£éŸ³è‹±è¯­çš„å¦ä¸€ç§æµ‹è¯•é›†ï¼›åŒ…å«å…·æœ‰ç”Ÿæˆæ€§æ–‡æœ¬è¯­éŸ³åˆæˆå£éŸ³çš„é˜¿æ‹‰ä¼¯ã€æ™®é€šè¯ã€å°åº¦å’Œè¥¿ç­ç‰™è¯­å¯¹å¤–å£éŸ³çš„æµ‹è¯•é›†ï¼Œä»¥åŠä¸€ç§å¸¦æœ‰æ‹¼æ¥æ–‡æœ¬è¯­éŸ³çš„å£éŸ³è‹±è¯­çš„æµ‹è¯•é›†ã€‚é™¤äº†è¿™å››ä¸ªæµ‹è¯•é›†å¤–ï¼ŒCS-FLEURSè¿˜æä¾›åŒ…å«å…·æœ‰åˆ›é€ æ€§æ–‡æœ¬çš„å£éŸ³è‹±è¯­çš„åˆæˆè¯­éŸ³æ•°æ®çš„è®­ç»ƒé›†ï¼Œå…±è®¡æ—¶é•¿ä¸ºCS-FLEURSå¸Œæœ›æ‹“å®½æœªæ¥ä»£ç åˆ‡æ¢è¯­éŸ³è¯†åˆ«çš„ç ”ç©¶èŒƒå›´ã€‚æ•°æ®é›†é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/byan/cs-fleurs">https://huggingface.co/datasets/byan/cs-fleurs</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14161v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>CS-FLEURSæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘å’Œè¯„ä¼°è·¨è¯­è¨€ä»£ç åˆ‡æ¢è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ç³»ç»Ÿçš„æ–°æ•°æ®é›†ã€‚å®ƒåŒ…å«å››ä¸ªæµ‹è¯•é›†ï¼Œæ¶µç›–113ç§ç‹¬ç‰¹çš„ä»£ç åˆ‡æ¢è¯­è¨€å¯¹å’Œ52ç§è¯­è¨€ã€‚è¯¥æ•°æ®é›†å¯ç”¨äºæ”¯æŒå¤šç§è¯­è¨€çš„ä»£ç åˆ‡æ¢åœºæ™¯ï¼Œå¹¶æä¾›è®­ç»ƒé›†ä»¥æ”¯æŒæœªæ¥ä»£ç åˆ‡æ¢è¯­éŸ³ç ”ç©¶çš„æ‹“å®½ã€‚æ•°æ®é›†é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/byan/cs-fleurs%E3%80%82">https://huggingface.co/datasets/byan/cs-fleursã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CS-FLEURSæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘è¯„ä¼°è·¨è¯­è¨€ä»£ç åˆ‡æ¢è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ç³»ç»Ÿçš„æ–°æ•°æ®é›†ã€‚</li>
<li>æ•°æ®é›†åŒ…å«å››ä¸ªæµ‹è¯•é›†ï¼Œæ¶µç›–113ç§ç‹¬ç‰¹çš„ä»£ç åˆ‡æ¢è¯­è¨€å¯¹å’Œ52ç§è¯­è¨€ã€‚</li>
<li>æ•°æ®é›†æ”¯æŒå¤šç§åœºæ™¯çš„è·¨è¯­è¨€ä»£ç åˆ‡æ¢åº”ç”¨ã€‚</li>
<li>æ•°æ®é›†åŒ…å«128å°æ—¶çš„ç”Ÿæˆå¼æ–‡æœ¬åˆ°è¯­éŸ³æ•°æ®çš„è®­ç»ƒé›†ã€‚</li>
<li>CS-FLEURSæä¾›äº†å¹¿æ³›çš„è¯­ç§è¦†ç›–ï¼ŒåŒ…æ‹¬è‹±è¯­ä¸å…¶ä»–è¯­è¨€çš„ç»„åˆã€‚</li>
<li>æ•°æ®é›†å¯ä»¥ç”¨äºæœªæ¥çš„ä»£ç åˆ‡æ¢è¯­éŸ³ç ”ç©¶æ‹“å®½é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14161">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14161v1/page_3_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Canary-1B-v2-Parakeet-TDT-0-6B-v3-Efficient-and-High-Performance-Models-for-Multilingual-ASR-and-AST"><a href="#Canary-1B-v2-Parakeet-TDT-0-6B-v3-Efficient-and-High-Performance-Models-for-Multilingual-ASR-and-AST" class="headerlink" title="Canary-1B-v2 &amp; Parakeet-TDT-0.6B-v3: Efficient and High-Performance   Models for Multilingual ASR and AST"></a>Canary-1B-v2 &amp; Parakeet-TDT-0.6B-v3: Efficient and High-Performance   Models for Multilingual ASR and AST</h2><p><strong>Authors:Monica Sekoyan, Nithin Rao Koluguri, Nune Tadevosyan, Piotr Zelasko, Travis Bartley, Nick Karpov, Jagadeesh Balam, Boris Ginsburg</strong></p>
<p>This report introduces Canary-1B-v2, a fast, robust multilingual model for Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built with a FastConformer encoder and Transformer decoder, it supports 25 languages primarily European. The model was trained on 1.7M hours of total data samples, including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce hallucinations for ASR and AST. We describe its two-stage pre-training and fine-tuning process with dynamic data balancing, as well as experiments with an nGPT encoder. Results show nGPT scales well with massive data, while FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2 outperforms Whisper-large-v3 on English ASR while being 10x faster, and delivers competitive multilingual ASR and AST performance against larger models like Seamless-M4T-v2-large and LLM-based systems. We also release Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the same 25 languages with just 600M parameters. </p>
<blockquote>
<p>è¿™ä»½æŠ¥å‘Šä»‹ç»äº†Canary-1B-v2ï¼Œè¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿã€ç¨³å¥çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³åˆ°æ–‡æœ¬çš„ç¿»è¯‘ï¼ˆASTï¼‰ã€‚è¯¥æ¨¡å‹é‡‡ç”¨FastConformerç¼–ç å™¨å’ŒTransformerè§£ç å™¨æ„å»ºï¼Œä¸»è¦æ”¯æŒ25ç§æ¬§æ´²è¯­è¨€ã€‚è¯¥æ¨¡å‹åœ¨170ä¸‡å°æ—¶çš„æ€»æ•°æ®æ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬Granaryå’ŒNeMo ASR Set 3.0ï¼Œå¹¶æ·»åŠ äº†éè¯­éŸ³éŸ³é¢‘ï¼Œä»¥å‡å°‘ASRå’ŒASTçš„å¹»è§‰ã€‚æˆ‘ä»¬æè¿°äº†å…¶ä¸¤é˜¶æ®µé¢„è®­ç»ƒå’Œå¾®è°ƒè¿‡ç¨‹ï¼Œé‡‡ç”¨åŠ¨æ€æ•°æ®å¹³è¡¡ï¼Œä»¥åŠä½¿ç”¨nGPTç¼–ç å™¨çš„å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒnGPTåœ¨å¤§é‡æ•°æ®ä¸­è¡¨ç°è‰¯å¥½ï¼Œè€ŒFastConformeråœ¨å¾®è°ƒåè¡¨ç°å‡ºè‰²ã€‚å¯¹äºæ—¶é—´æˆ³ï¼ŒCanary-1B-v2ä½¿ç”¨NeMoå¼ºåˆ¶å¯¹é½å™¨ï¼ˆNFAï¼‰å’Œè¾…åŠ©CTCæ¨¡å‹ï¼Œä¸ºASRå’ŒASTæä¾›å¯é çš„åˆ†æ®µçº§æ—¶é—´æˆ³ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒCanary-1B-v2åœ¨è‹±è¯­ASRæ–¹é¢è¶…è¶Šäº†Whisper-large-v3ï¼Œè€Œä¸”é€Ÿåº¦æ›´å¿«ï¼ŒåŒæ—¶åœ¨å¤šè¯­è¨€ASRå’ŒASTæ–¹é¢ä¸æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚æ— ç¼M4T-v2å¤§å‹æ¨¡å‹ï¼‰å’ŒåŸºäºLLMçš„ç³»ç»Ÿè¡¨ç°ç«äº‰ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†Parakeet-TDT-0.6B-v3ï¼Œè¿™æ˜¯v2çš„åç»­ç‰ˆæœ¬ï¼Œä½¿ç”¨ä»…6äº¿ä¸ªå‚æ•°å³å¯æä¾›ç›¸åŒ25ç§è¯­è¨€çš„å¤šè¯­è¨€ASRã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14128v1">PDF</a> Mini Version of it Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>è¿™ä»½æŠ¥å‘Šä»‹ç»äº†Canary-1B-v2æ¨¡å‹ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¿«é€Ÿã€ç¨³å¥çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œä¸»è¦ç”¨äºè¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³åˆ°æ–‡æœ¬çš„ç¿»è¯‘ï¼ˆASTï¼‰ã€‚è¯¥æ¨¡å‹é‡‡ç”¨FastConformerç¼–ç å™¨å’ŒTransformerè§£ç å™¨ï¼Œæ”¯æŒ25ç§ä¸»è¦æ¬§æ´²è¯­è¨€ã€‚ç»è¿‡å¤§è§„æ¨¡æ•°æ®æ ·æœ¬çš„è®­ç»ƒå’Œä¸¤é˜¶æ®µé¢„è®­ç»ƒä¸å¾®è°ƒï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ã€‚Canary-1B-v2ä½¿ç”¨NeMoå¼ºåˆ¶å¯¹é½å™¨ï¼ˆNFAï¼‰æä¾›å¯é çš„æ—¶æ®µçº§æ—¶é—´æˆ³ï¼Œå¹¶åœ¨è‹±è¯­ASRä¸Šè¡¨ç°ä¼˜äºWhisper-large-v3ï¼ŒåŒæ—¶å¤„ç†é€Ÿåº¦æ›´å¿«ã€‚å®ƒè¿˜æ¨å‡ºäº†Parakeet-TDT-0.6B-v3æ¨¡å‹ï¼Œå…·æœ‰æ›´å°çš„å‚æ•°è§„æ¨¡ï¼Œä½†ä¾ç„¶èƒ½è¿›è¡Œå¤šè¯­è¨€ASRã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Canary-1B-v2æ˜¯ä¸€ä¸ªé’ˆå¯¹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ï¼ˆASTï¼‰çš„å¿«é€Ÿã€ç¨³å¥çš„å¤šè¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹é‡‡ç”¨FastConformerç¼–ç å™¨å’ŒTransformerè§£ç å™¨ï¼Œæ”¯æŒ25ç§ä¸»è¦æ¬§æ´²è¯­è¨€ã€‚</li>
<li>æ¨¡å‹ç»è¿‡ä¸¤é˜¶æ®µé¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œä½¿ç”¨åŠ¨æ€æ•°æ®å¹³è¡¡æ¥æé«˜æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹ä½¿ç”¨NeMoå¼ºåˆ¶å¯¹é½å™¨ï¼ˆNFAï¼‰æä¾›å¯é çš„æ—¶é—´æˆ³ã€‚</li>
<li>åœ¨è‹±è¯­ASRæ–¹é¢ï¼ŒCanary-1B-v2ä¼˜äºWhisper-large-v3æ¨¡å‹ï¼ŒåŒæ—¶å¤„ç†é€Ÿåº¦æ›´å¿«ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡æ•°æ®ï¼Œå¹¶ä¸”FastConformeråœ¨å¾®è°ƒåè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14128">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14128v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14128v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14128v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14128v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14128v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Lightweight-Fourier-based-Network-for-Binaural-Speech-Enhancement-with-Spatial-Cue-Preservation"><a href="#A-Lightweight-Fourier-based-Network-for-Binaural-Speech-Enhancement-with-Spatial-Cue-Preservation" class="headerlink" title="A Lightweight Fourier-based Network for Binaural Speech Enhancement with   Spatial Cue Preservation"></a>A Lightweight Fourier-based Network for Binaural Speech Enhancement with   Spatial Cue Preservation</h2><p><strong>Authors:Xikun Lu, Yujian Ma, Xianquan Jiang, Xuelong Wang, Jinqiu Sang</strong></p>
<p>Binaural speech enhancement faces a severe trade-off challenge, where state-of-the-art performance is achieved by computationally intensive architectures, while lightweight solutions often come at the cost of significant performance degradation. To bridge this gap, we propose the Global Adaptive Fourier Network (GAF-Net), a lightweight deep complex network that aims to establish a balance between performance and computational efficiency. The GAF-Net architecture consists of three components. First, a dual-feature encoder combining short-time Fourier transform and gammatone features enhances the robustness of acoustic representation. Second, a channel-independent globally adaptive Fourier modulator efficiently captures long-term temporal dependencies while preserving the spatial cues. Finally, a dynamic gating mechanism is implemented to reduce processing artifacts. Experimental results show that GAF-Net achieves competitive performance, particularly in terms of binaural cues (ILD and IPD error) and objective intelligibility (MBSTOI), with fewer parameters and computational cost. These results confirm that GAF-Net provides a feasible way to achieve high-fidelity binaural processing on resource-constrained devices. </p>
<blockquote>
<p>åŒè€³è¯­éŸ³å¢å¼ºé¢ä¸´ç€ä¸¥é‡çš„æƒè¡¡æŒ‘æˆ˜ï¼Œç°æœ‰æŠ€æœ¯æ€§èƒ½çš„å®ç°ä¾èµ–äºè®¡ç®—å¯†é›†å‹çš„æ¶æ„ï¼Œè€Œè½»é‡çº§è§£å†³æ–¹æ¡ˆå¾€å¾€ä»¥æ€§èƒ½æ˜¾è‘—ä¸‹é™ä¸ºä»£ä»·ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†å…¨çƒè‡ªé€‚åº”å‚…é‡Œå¶ç½‘ç»œï¼ˆGAF-Netï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ·±åº¦å¤æ•°ç½‘ç»œï¼Œæ—¨åœ¨åœ¨æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚GAF-Netæ¶æ„ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆã€‚é¦–å…ˆï¼Œç»“åˆçŸ­æ—¶å‚…é‡Œå¶å˜æ¢å’Œä¼½é©¬é€šç‰¹å¾çš„åŒé‡ç‰¹å¾ç¼–ç å™¨å¢å¼ºäº†å£°éŸ³è¡¨ç¤ºçš„é²æ£’æ€§ã€‚å…¶æ¬¡ï¼Œé€šé“ç‹¬ç«‹çš„å…¨å±€è‡ªé€‚åº”å‚…é‡Œå¶è°ƒåˆ¶å™¨æœ‰æ•ˆåœ°æ•è·äº†é•¿æœŸæ—¶é—´ä¾èµ–æ€§ï¼ŒåŒæ—¶ä¿ç•™äº†ç©ºé—´çº¿ç´¢ã€‚æœ€åï¼Œå®ç°äº†åŠ¨æ€é—¨æ§æœºåˆ¶ä»¥å‡å°‘å¤„ç†è¿‡ç¨‹ä¸­çš„ä¼ªå½±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGAF-Netåœ¨åŒè€³çº¿ç´¢ï¼ˆILDå’ŒIPDè¯¯å·®ï¼‰å’Œå®¢è§‚æ¸…æ™°åº¦ï¼ˆMBSTOIï¼‰æ–¹é¢å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½è¡¨ç°ï¼ŒåŒæ—¶å‡å°‘äº†å‚æ•°å’Œè®¡ç®—æˆæœ¬ã€‚è¿™äº›ç»“æœè¯å®ï¼ŒGAF-Netåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°é«˜ä¿çœŸåŒè€³å¤„ç†æä¾›äº†ä¸€ç§å¯è¡Œçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.14076v1">PDF</a> Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>GAF-Netæ˜¯ä¸€ç§ç»“åˆäº†å…¨çƒè‡ªé€‚åº”å‚…ç«‹å¶ç½‘ç»œæ¶æ„çš„è½»é‡çº§æ·±åº¦å¤æ‚ç½‘ç»œï¼Œæ—¨åœ¨å¹³è¡¡æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚å®ƒé‡‡ç”¨åŒç‰¹å¾ç¼–ç å™¨ã€å…¨å±€è‡ªé€‚åº”å‚…ç«‹å¶è°ƒåˆ¶å™¨å’ŒåŠ¨æ€é—¨æ§æœºåˆ¶ç­‰æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ€§èƒ½å’Œè½»é‡çº§çš„è¯­éŸ³å¢å¼ºæ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGAF-Netåœ¨åŒè€³çº¿ç´¢ã€å®¢è§‚å¯æ‡‚åº¦å’Œå‚æ•°è®¡ç®—æˆæœ¬ç­‰æ–¹é¢å‡è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GAF-Netæ˜¯ä¸€ç§é’ˆå¯¹è¯­éŸ³å¢å¼ºçš„è½»é‡çº§æ·±åº¦å¤æ‚ç½‘ç»œã€‚</li>
<li>è¯¥ç½‘ç»œç»“åˆäº†åŒç‰¹å¾ç¼–ç å™¨ã€å…¨å±€è‡ªé€‚åº”å‚…ç«‹å¶è°ƒåˆ¶å™¨å’ŒåŠ¨æ€é—¨æ§æœºåˆ¶ç­‰æŠ€æœ¯ã€‚</li>
<li>GAF-Netæ—¨åœ¨å¹³è¡¡é«˜æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGAF-Netåœ¨è¯­éŸ³å¢å¼ºæ–¹é¢è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
<li>GAF-Netå¯¹äºèµ„æºå—é™çš„è®¾å¤‡å®ç°é«˜ä¿çœŸåŒè€³å¤„ç†å…·æœ‰å¯è¡Œæ€§ã€‚</li>
<li>GAF-Netç‰¹åˆ«ä¼˜åŒ–äº†åŒè€³çº¿ç´¢ï¼ˆILDå’ŒIPDè¯¯å·®ï¼‰å’Œå®¢è§‚å¯æ‡‚åº¦ï¼ˆMBSTOIï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.14076">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14076v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14076v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14076v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14076v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.14076v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Mixture-of-Low-Rank-Adapter-Experts-in-Generalizable-Audio-Deepfake-Detection"><a href="#Mixture-of-Low-Rank-Adapter-Experts-in-Generalizable-Audio-Deepfake-Detection" class="headerlink" title="Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake   Detection"></a>Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake   Detection</h2><p><strong>Authors:Janne Laakkonen, Ivan Kukanov, Ville HautamÃ¤ki</strong></p>
<p>Foundation models such as Wav2Vec2 excel at representation learning in speech tasks, including audio deepfake detection. However, after being fine-tuned on a fixed set of bonafide and spoofed audio clips, they often fail to generalize to novel deepfake methods not represented in training. To address this, we propose a mixture-of-LoRA-experts approach that integrates multiple low-rank adapters (LoRA) into the modelâ€™s attention layers. A routing mechanism selectively activates specialized experts, enhancing adaptability to evolving deepfake attacks. Experimental results show that our method outperforms standard fine-tuning in both in-domain and out-of-domain scenarios, reducing equal error rates relative to baseline models. Notably, our best MoE-LoRA model lowers the average out-of-domain EER from 8.55% to 6.08%, demonstrating its effectiveness in achieving generalizable audio deepfake detection. </p>
<blockquote>
<p>Wave2Vec2ç­‰åŸºç¡€æ¨¡å‹åœ¨è¯­éŸ³ä»»åŠ¡ï¼ˆåŒ…æ‹¬éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼‰ä¸­æ“…é•¿è¡¨ç¤ºå­¦ä¹ ã€‚ç„¶è€Œï¼Œåœ¨å¯¹å›ºå®šçš„çœŸå®å’Œå‡å†’éŸ³é¢‘ç‰‡æ®µè¿›è¡Œå¾®è°ƒåï¼Œå®ƒä»¬é€šå¸¸æ— æ³•æ¨å¹¿åˆ°è®­ç»ƒä¸­æ²¡æœ‰å‡ºç°çš„æ–°å‹æ·±åº¦ä¼ªé€ æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆLoRAä¸“å®¶æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†å¤šä¸ªä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰é›†æˆåˆ°æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­ã€‚è·¯ç”±æœºåˆ¶æœ‰é€‰æ‹©åœ°æ¿€æ´»ä¸“ä¸šä¸“å®¶ï¼Œæé«˜å¯¹ä¸æ–­å‘å±•çš„æ·±åº¦ä¼ªé€ æ”»å‡»çš„é€‚åº”æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ ‡å‡†å¾®è°ƒç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸŸå†…å’ŒåŸŸå¤–åœºæ™¯ä¸­è¡¨ç°æ›´å¥½ï¼Œç›¸å¯¹äºåŸºçº¿æ¨¡å‹é™ä½äº†ç­‰è¯¯ç ç‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬æœ€å¥½çš„MoE-LoRAæ¨¡å‹å°†åŸŸå¤–å¹³å‡EERä»8.55%é™ä½åˆ°6.08%ï¼Œè¡¨æ˜å…¶åœ¨å®ç°å¯æ³›åŒ–çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13878v1">PDF</a> 6 pages, 3 figures, 1 table</p>
<p><strong>Summary</strong></p>
<p>æ¨¡å‹å¦‚Wav2Vec2åœ¨è¯­éŸ³ä»»åŠ¡ä¸­çš„è¡¨ç¤ºå­¦ä¹ è¡¨ç°å“è¶Šï¼Œå°¤å…¶åœ¨éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹é¢ã€‚ç„¶è€Œï¼Œåœ¨å›ºå®šçš„ä¸€ç»„çœŸå®å’Œä¼ªé€ éŸ³é¢‘ç‰‡æ®µä¸Šè¿›è¡Œå¾®è°ƒåï¼Œå®ƒä»¬å¾€å¾€æ— æ³•æ¨å¹¿åˆ°è®­ç»ƒä¸­æ²¡æœ‰ä»£è¡¨çš„æ–°å‹æ·±åº¦ä¼ªé€ æ–¹æ³•ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆLoRAä¸“å®¶æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†å¤šä¸ªä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰é›†æˆåˆ°æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­ã€‚è·¯ç”±æœºåˆ¶èƒ½å¤Ÿé€‰æ‹©æ€§åœ°æ¿€æ´»ä¸“ä¸šä¸“å®¶ï¼Œå¢å¼ºå¯¹ä¸æ–­å‘å±•çš„æ·±åº¦ä¼ªé€ æ”»å‡»çš„é€‚åº”æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸŸå†…å’ŒåŸŸå¤–åœºæ™¯ä¸­éƒ½ä¼˜äºæ ‡å‡†å¾®è°ƒï¼Œç›¸å¯¹äºåŸºçº¿æ¨¡å‹é™ä½äº†ç­‰é”™è¯¯ç‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æœ€å¥½çš„MoE-LoRAæ¨¡å‹å°†å¹³å‡åŸŸå¤–EERä»8.55%é™ä½åˆ°6.08%ï¼Œè¯æ˜äº†å…¶åœ¨å®ç°å¯æ¨å¹¿çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Wav2Vec2ç­‰æ¨¡å‹åœ¨è¯­éŸ³è¡¨ç¤ºå­¦ä¹ ï¼Œå°¤å…¶æ˜¯éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨å›ºå®šéŸ³é¢‘é›†ä¸Šå¾®è°ƒåï¼Œéš¾ä»¥é€‚åº”æ–°å‹æ·±åº¦ä¼ªé€ æ–¹æ³•ã€‚</li>
<li>æå‡ºçš„æ··åˆLoRAä¸“å®¶æ–¹æ³•é€šè¿‡é›†æˆå¤šä¸ªä½ç§©é€‚é…å™¨å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§ã€‚</li>
<li>è·¯ç”±æœºåˆ¶èƒ½é€‰æ‹©æ€§åœ°æ¿€æ´»ç‰¹å®šä¸“å®¶ï¼Œä»¥åº”å¯¹ä¸æ–­æ¼”å˜çš„æ·±åº¦ä¼ªé€ æ”»å‡»ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åŸŸå†…å’ŒåŸŸå¤–åœºæ™¯ä¸­éƒ½ä¼˜äºæ ‡å‡†å¾®è°ƒã€‚</li>
<li>MoE-LoRAæ¨¡å‹é™ä½äº†å¹³å‡åŸŸå¤–ç­‰é”™è¯¯ç‡ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13878">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13878v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13878v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13878v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13878v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Conducting-Mission-Critical-Voice-Experiments-with-Automated-Speech-Recognition-and-Crowdsourcing"><a href="#Conducting-Mission-Critical-Voice-Experiments-with-Automated-Speech-Recognition-and-Crowdsourcing" class="headerlink" title="Conducting Mission-Critical Voice Experiments with Automated Speech   Recognition and Crowdsourcing"></a>Conducting Mission-Critical Voice Experiments with Automated Speech   Recognition and Crowdsourcing</h2><p><strong>Authors:Jan Janak, Kahlil Dozier, Lauren Berny, Liang Hu, Dan Rubenstein, Charles Jennings, Henning Schulzrinne</strong></p>
<p>Mission-critical voice (MCV) communications systems have been a critical tool for the public safety community for over eight decades. Public safety users expect MCV systems to operate reliably and consistently, particularly in challenging conditions. Because of these expectations, the Public Safety Communications Research (PSCR) Division of the National Institute of Standards and Technology (NIST) has been interested in correlating impairments in MCV communication systems and public safety user quality of experience (QoE). Previous research has studied MCV voice quality and intelligibility in a controlled environment. However, such research has been limited by the challenges inherent in emulating real-world environmental conditions. Additionally, there is the question of the best metric to use to reflect QoE accurately.   This paper describes our efforts to develop the methodology and tools for human-subject experiments with MCV. We illustrate their use in human-subject experiments in emulated real-world environments. The tools include a testbed for emulating real-world MCV systems and an automated speech recognition (ASR) robot approximating human subjects in transcription tasks. We evaluate QoE through a Levenshtein Distance-based metric, arguing it is a suitable proxy for measuring comprehension and the QoE. We conducted human-subject studies with Amazon MTurk volunteers to understand the influence of selected system parameters and impairments on human subject performance and end-user QoE. We also compare the performance of several ASR system configurations with human-subject performance. We find that humans generally perform better than ASR in accuracy-related MCV tasks and that the codec significantly influences the end-user QoE and ASR performance. </p>
<blockquote>
<p>ä»»åŠ¡å…³é”®è¯­éŸ³ï¼ˆMCVï¼‰é€šä¿¡ç³»ç»Ÿå·²ä½œä¸ºå…¬å…±å®‰å…¨ç¤¾åŒºçš„é‡è¦å·¥å…·é•¿è¾¾å…«åå¤šå¹´ã€‚å…¬å…±å®‰å…¨ç”¨æˆ·æœŸæœ›MCVç³»ç»Ÿèƒ½å¤Ÿå¯é ä¸”ç¨³å®šåœ°è¿è¡Œï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ã€‚ç”±äºè¿™äº›æœŸæœ›ï¼Œç¾å›½å›½å®¶æŠ€æœ¯æ ‡å‡†ç ”ç©¶æ‰€ï¼ˆNISTï¼‰çš„å…¬å…±å®‰å…¨é€šä¿¡ç ”ç©¶ï¼ˆPSCRï¼‰éƒ¨é—¨å¯¹MCVé€šä¿¡ç³»ç»Ÿçš„ç¼ºé™·ä¸å…¬å…±å®‰å…¨ç”¨æˆ·çš„è´¨é‡ä½“éªŒï¼ˆQoEï¼‰ä¹‹é—´çš„ç›¸å…³æ€§éå¸¸æ„Ÿå…´è¶£ã€‚ä»¥å¾€çš„ç ”ç©¶å·²åœ¨å—æ§ç¯å¢ƒä¸­ç ”ç©¶äº†MCVçš„è¯­éŸ³è´¨é‡å’Œæ¸…æ™°åº¦ã€‚ç„¶è€Œï¼Œè¿™ç±»ç ”ç©¶å—é™äºæ¨¡æ‹Ÿç°å®ç¯å¢ƒæ¡ä»¶çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè¿˜å­˜åœ¨ç”¨äºå‡†ç¡®åæ˜ QoEçš„æœ€ä½³æŒ‡æ ‡çš„é—®é¢˜ã€‚æœ¬æ–‡æè¿°äº†æˆ‘ä»¬åœ¨å¼€å‘MCVäººç±»ä¸»ä½“å®éªŒçš„æ–¹æ³•å’Œå·¥å…·æ–¹é¢çš„åŠªåŠ›ã€‚æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿç°å®ç¯å¢ƒçš„äººç±»ä¸»ä½“å®éªŒä¸­è¯´æ˜äº†å®ƒä»¬çš„ä½¿ç”¨ã€‚è¿™äº›å·¥å…·åŒ…æ‹¬ä¸€ä¸ªæ¨¡æ‹Ÿç°å®MCVç³»ç»Ÿçš„æµ‹è¯•å¹³å°å’Œä¸€ä¸ªåœ¨è½¬å½•ä»»åŠ¡ä¸­è¿‘ä¼¼äººç±»ä¸»ä½“çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æœºå™¨äººã€‚æˆ‘ä»¬é€šè¿‡åŸºäºLevenshteinè·ç¦»çš„åº¦é‡æ¥è¯„ä¼°QoEï¼Œè®¤ä¸ºå®ƒæ˜¯è¡¡é‡ç†è§£å’ŒQoEçš„åˆé€‚ä»£ç†ã€‚æˆ‘ä»¬ä½¿ç”¨äºšé©¬é€ŠMTurkå¿—æ„¿è€…è¿›è¡Œäººç±»ä¸»ä½“ç ”ç©¶ï¼Œä»¥äº†è§£æ‰€é€‰ç³»ç»Ÿå‚æ•°å’Œç¼ºé™·å¯¹äººç±»ä¸»ä½“æ€§èƒ½å’Œæœ€ç»ˆç”¨æˆ·QoEçš„å½±å“ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†ä¸åŒASRç³»ç»Ÿé…ç½®ä¸äººç±»ä¸»ä½“æ€§èƒ½çš„è¡¨ç°ã€‚æˆ‘ä»¬å‘ç°ï¼Œåœ¨å‡†ç¡®æ€§ç›¸å…³çš„MCVä»»åŠ¡ä¸­ï¼Œäººç±»çš„è¡¨ç°é€šå¸¸ä¼˜äºASRï¼Œå¹¶ä¸”ç¼–ç å™¨å¯¹æœ€ç»ˆç”¨æˆ·çš„QoEå’ŒASRæ€§èƒ½å…·æœ‰é‡å¤§å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13724v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬è®ºæ–‡å…³æ³¨å…¬å…±å®‰å…¨é—®é¢˜ä¸­è‡³å…³é‡è¦çš„è¯­éŸ³é€šä¿¡ç³»ç»Ÿï¼ˆMCVï¼‰ã€‚ä¸ºè§£å†³MCVç³»ç»Ÿåœ¨å®é™…ç¯å¢ƒä¸­çš„æŒ‘æˆ˜åŠå…¶å¯¹å…¬å…±å®‰å…¨ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰çš„å½±å“ï¼Œå›½å®¶æ ‡å‡†æŠ€æœ¯ç ”ç©¶æ‰€å…¬å…±ç ”ç©¶éƒ¨è‡´åŠ›äºæ¢ç©¶MCVé€šä¿¡ç³»ç»Ÿä¸­çš„æŸå®³ä¸QoEçš„ç›¸å…³æ€§ã€‚æ­¤å‰çš„å®éªŒä¸»è¦åœ¨å—æ§ç¯å¢ƒä¸­ç ”ç©¶MCVçš„è¯­éŸ³è´¨é‡å’Œæ¸…æ™°åº¦ï¼Œä½†åœ¨æ¨¡æ‹ŸçœŸå®ç¯å¢ƒæ—¶é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚åŒæ—¶ï¼Œå¯¹æœ€ä½³åº¦é‡QoEçš„æ ‡å‡†ä¹Ÿå­˜åœ¨ç–‘é—®ã€‚æœ¬æ–‡æè¿°äº†ä¸ºMCVè¿›è¡Œäººä½“å®éªŒçš„æ–¹æ³•å’Œå·¥å…·å¼€å‘ï¼ŒåŒ…æ‹¬æ¨¡æ‹ŸçœŸå®ä¸–ç•Œç¯å¢ƒçš„æµ‹è¯•å¹³å°å’Œæ¨¡æ‹Ÿäººç±»è½¬å½•ä»»åŠ¡çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æœºå™¨äººã€‚é€šè¿‡åŸºäºLevenshteinè·ç¦»çš„åº¦é‡è¯„ä¼°QoEï¼Œè®¤ä¸ºå…¶é€‚åˆè¡¡é‡ç†è§£å’ŒQoEã€‚é€šè¿‡äºšé©¬é€ŠMTurkå¿—æ„¿è€…è¿›è¡Œäººä½“å®éªŒï¼Œç ”ç©¶é€‰å®šç³»ç»Ÿå‚æ•°å’ŒæŸå®³å¯¹äººä½“è¡¨ç°å’Œç”¨æˆ·ä½“éªŒçš„å½±å“ï¼Œå¹¶å°†å¤šç§ASRç³»ç»Ÿé…ç½®ä¸äººä½“æ€§èƒ½è¿›è¡Œæ¯”è¾ƒã€‚å‘ç°äººç±»åœ¨å‡†ç¡®æ€§ç›¸å…³çš„MCVä»»åŠ¡ä¸­é€šå¸¸è¡¨ç°ä¼˜äºASRï¼Œå¹¶ä¸”ç¼–ç å™¨å¯¹ç”¨æˆ·ä½“éªŒå’ŒASRæ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>MCVç³»ç»Ÿæ˜¯å…¬å…±å®‰å…¨ç¤¾åŒºçš„é‡è¦å·¥å…·ï¼Œå…¶å¯é æ€§å’Œä¸€è‡´æ€§è‡³å…³é‡è¦ã€‚</li>
<li>NISTå¯¹MCVç³»ç»ŸæŸå®³ä¸å…¬å…±å®‰å…¨æ€§ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰çš„ç›¸å…³æ€§æ„Ÿå…´è¶£ã€‚</li>
<li>ä¹‹å‰çš„ç ”ç©¶ä¸»è¦åœ¨å—æ§ç¯å¢ƒä¸­è¿›è¡Œï¼Œéš¾ä»¥æ¨¡æ‹ŸçœŸå®ç¯å¢ƒã€‚</li>
<li>é€‰æ‹©Levenshteinè·ç¦»ä½œä¸ºè¯„ä¼°QoEçš„åº¦é‡æ ‡å‡†ï¼Œèƒ½æœ‰æ•ˆè¡¡é‡ç†è§£å’Œç”¨æˆ·ä½“éªŒã€‚</li>
<li>äººä½“å®éªŒæ˜¾ç¤ºäººç±»åœ¨å‡†ç¡®æ€§ç›¸å…³çš„MCVä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºASRç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿå‚æ•°å’ŒæŸå®³å½±å“äººä½“è¡¨ç°å’Œç”¨æˆ·ä½“éªŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13724">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13724v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13724v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13724v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13724v1/page_2_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Invisible-Ears-at-Your-Fingertips-Acoustic-Eavesdropping-via-Mouse-Sensors"><a href="#Invisible-Ears-at-Your-Fingertips-Acoustic-Eavesdropping-via-Mouse-Sensors" class="headerlink" title="Invisible Ears at Your Fingertips: Acoustic Eavesdropping via Mouse   Sensors"></a>Invisible Ears at Your Fingertips: Acoustic Eavesdropping via Mouse   Sensors</h2><p><strong>Authors:Mohamad Fakih, Rahul Dharmaji, Youssef Mahmoud, Halima Bouzidi, Mohammad Abdullah Al Faruque</strong></p>
<p>Modern optical mouse sensors, with their advanced precision and high responsiveness, possess an often overlooked vulnerability: they can be exploited for side-channel attacks. This paper introduces Mic-E-Mouse, the first-ever side-channel attack that targets high-performance optical mouse sensors to covertly eavesdrop on users. We demonstrate that audio signals can induce subtle surface vibrations detectable by a mouseâ€™s optical sensor. Remarkably, user-space software on popular operating systems can collect and broadcast this sensitive side channel, granting attackers access to raw mouse data without requiring direct system-level permissions. Initially, the vibration signals extracted from mouse data are of poor quality due to non-uniform sampling, a non-linear frequency response, and significant quantization. To overcome these limitations, Mic-E-Mouse employs a sophisticated end-to-end data filtering pipeline that combines Wiener filtering, resampling corrections, and an innovative encoder-only spectrogram neural filtering technique. We evaluate the attackâ€™s efficacy across diverse conditions, including speaking volume, mouse polling rate and DPI, surface materials, speaker languages, and environmental noise. In controlled environments, Mic-E-Mouse improves the signal-to-noise ratio (SNR) by up to +19 dB for speech reconstruction. Furthermore, our results demonstrate a speech recognition accuracy of roughly 42% to 61% on the AudioMNIST and VCTK datasets. All our code and datasets are publicly accessible on <a target="_blank" rel="noopener" href="https://sites.google.com/view/mic-e-mouse">https://sites.google.com/view/mic-e-mouse</a>. </p>
<blockquote>
<p>ç°ä»£å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨å…·æœ‰é«˜ç²¾åº¦å’Œé«˜å“åº”æ€§çš„ç‰¹æ€§ï¼Œä½†å¾€å¾€ä¼šè¢«å¿½ç•¥å…¶å­˜åœ¨çš„æ¼æ´ï¼šå®ƒä»¬å¯èƒ½è¢«ç”¨äºä¾§ä¿¡é“æ”»å‡»ã€‚æœ¬æ–‡ä»‹ç»äº†Mic-E-Mouseï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é«˜æ€§èƒ½å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨çš„æ–°å‹ä¾§ä¿¡é“æ”»å‡»ï¼Œå¯ä»¥éšç§˜åœ°çªƒå¬ç”¨æˆ·ä¿¡æ¯ã€‚æˆ‘ä»¬è¯æ˜äº†éŸ³é¢‘ä¿¡å·ä¼šå¼•å‘é¼ æ ‡å…‰å­¦ä¼ æ„Ÿå™¨å¯æ£€æµ‹åˆ°çš„ç»†å¾®è¡¨é¢æŒ¯åŠ¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæµè¡Œæ“ä½œç³»ç»Ÿä¸Šçš„ç”¨æˆ·ç©ºé—´è½¯ä»¶å¯ä»¥æ”¶é›†å’Œå¹¿æ’­è¿™ç§æ•æ„Ÿçš„ä¾§ä¿¡é“ä¿¡æ¯ï¼Œä½¿æ”»å‡»è€…æ— éœ€è·å¾—ç³»ç»Ÿçº§æƒé™å³å¯è®¿é—®åŸå§‹é¼ æ ‡æ•°æ®ã€‚ç”±äºé‡‡æ ·ä¸å‡åŒ€ã€é¢‘ç‡å“åº”éçº¿æ€§ä»¥åŠé‡åŒ–æ˜¾è‘—ï¼Œæœ€åˆä»é¼ æ ‡æ•°æ®ä¸­æå–çš„æŒ¯åŠ¨ä¿¡å·è´¨é‡è¾ƒå·®ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼ŒMic-E-Mouseé‡‡ç”¨äº†ä¸€ç§å…ˆè¿›çš„ç«¯åˆ°ç«¯æ•°æ®è¿‡æ»¤ç®¡é“ï¼Œç»“åˆäº†Wienerè¿‡æ»¤ã€é‡é‡‡æ ·æ ¡æ­£ä»¥åŠåˆ›æ–°çš„ä»…ç¼–ç å™¨å…‰è°±ç¥ç»è¿‡æ»¤æŠ€æœ¯ã€‚æˆ‘ä»¬è¯„ä¼°äº†æ”»å‡»åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬è¯´è¯éŸ³é‡ã€é¼ æ ‡è½®è¯¢ç‡å’ŒDPIã€è¡¨é¢ææ–™ã€è¯´è¯äººçš„è¯­è¨€å’Œç¯å¢ƒå™ªéŸ³ã€‚åœ¨å—æ§ç¯å¢ƒä¸­ï¼ŒMic-E-Mouseæé«˜äº†ä¿¡å·å™ªå£°æ¯”ï¼ˆSNRï¼‰ï¼Œè¯­éŸ³é‡å»ºæé«˜äº†é«˜è¾¾+19åˆ†è´ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœåœ¨AudioMNISTå’ŒVCTKæ•°æ®é›†ä¸Šè¾¾åˆ°äº†çº¦42%è‡³61%çš„è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡ã€‚æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†å‡å¯åœ¨<a target="_blank" rel="noopener" href="https://sites.google.com/view/mic-e-mouse%E4%B8%8A%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://sites.google.com/view/mic-e-mouseä¸Šå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13581v1">PDF</a> Appearing in the Annual Computer Security Applications Conference   (ACSAC 2025)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç°ä»£é«˜æ€§èƒ½å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨å­˜åœ¨ä¸€ç§å¸¸è¢«å¿½è§†çš„æ¼æ´ï¼šå®ƒä»¬å¯èƒ½å—åˆ°ä¾§ä¿¡é“æ”»å‡»çš„å½±å“ã€‚æœ¬æ–‡ä»‹ç»äº†Mic-E-Mouseï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é«˜æ€§èƒ½å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨çš„æ–°å‹ä¾§ä¿¡é“æ”»å‡»ï¼Œå¯ä»¥éšç§˜åœ°çªƒå¬ç”¨æˆ·ä¿¡æ¯ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒéŸ³é¢‘ä¿¡å·ä¼šè¯±å¯¼é¼ æ ‡å…‰å­¦ä¼ æ„Ÿå™¨å¯æ£€æµ‹åˆ°çš„å¾®å°è¡¨é¢æŒ¯åŠ¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæµè¡Œæ“ä½œç³»ç»Ÿä¸Šçš„ç”¨æˆ·ç©ºé—´è½¯ä»¶å¯ä»¥æ”¶é›†å’Œå¹¿æ’­è¿™ç§æ•æ„Ÿä¾§ä¿¡é“ä¿¡æ¯ï¼Œä½¿æ”»å‡»è€…æ— éœ€è·å¾—ç³»ç»Ÿçº§æƒé™å³å¯è®¿é—®åŸå§‹é¼ æ ‡æ•°æ®ã€‚ä¸ºè§£å†³ä»é¼ æ ‡æ•°æ®ä¸­æå–çš„æŒ¯åŠ¨ä¿¡å·è´¨é‡å·®çš„é—®é¢˜ï¼ˆå¦‚éå‡åŒ€é‡‡æ ·ã€éçº¿æ€§é¢‘ç‡å“åº”å’Œæ˜¾è‘—é‡åŒ–ï¼‰ï¼ŒMic-E-Mouseé‡‡ç”¨äº†ä¸€ç§å…ˆè¿›çš„ç«¯åˆ°ç«¯æ•°æ®è¿‡æ»¤ç®¡é“ï¼Œç»“åˆäº†ç»´çº³æ»¤æ³¢ã€é‡é‡‡æ ·æ ¡æ­£å’Œåˆ›æ–°çš„ä»…ç¼–ç å™¨å…‰è°±ç¥ç»è¿‡æ»¤æŠ€æœ¯ã€‚æˆ‘ä»¬åœ¨ä¸åŒæ¡ä»¶ä¸‹è¯„ä¼°äº†æ”»å‡»çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬è®²è¯éŸ³é‡ã€é¼ æ ‡è½®è¯¢ç‡å’ŒDPIã€è¡¨é¢ææ–™ã€è®²è¯è¯­è¨€å’Œç¯å¢ƒå™ªéŸ³ã€‚åœ¨æ§åˆ¶ç¯å¢ƒä¸‹ï¼ŒMic-E-Mouseå°†ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰æé«˜äº†é«˜è¾¾+19åˆ†è´ï¼Œç”¨äºè¯­éŸ³é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç»“æœåœ¨AudioMNISTå’ŒVCTKæ•°æ®é›†ä¸Šè¾¾åˆ°äº†çº¦42%è‡³61%çš„è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†å‡å¯åœ¨<a target="_blank" rel="noopener" href="https://sites.google.com/view/mic-e-mouse%E4%B8%8A%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://sites.google.com/view/mic-e-mouseä¸Šå…¬å¼€è®¿é—®ã€‚</a></p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>ç°ä»£å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨å­˜åœ¨ä¾§ä¿¡é“æ”»å‡»æ¼æ´ï¼Œå¯é€šè¿‡Mic-E-Mouseè¿›è¡Œéšç§˜çªƒå¬ã€‚</li>
<li>éŸ³é¢‘ä¿¡å·èƒ½è¯±å¯¼å…‰å­¦é¼ æ ‡ä¼ æ„Ÿå™¨æ£€æµ‹å¾®å°è¡¨é¢æŒ¯åŠ¨ã€‚</li>
<li>ç”¨æˆ·ç©ºé—´è½¯ä»¶èƒ½æ”¶é›†å’Œå¹¿æ’­é¼ æ ‡çš„ä¾§ä¿¡é“ä¿¡æ¯ï¼Œä½¿æ”»å‡»è€…æ— éœ€ç³»ç»Ÿçº§æƒé™å³å¯è·å–æ•°æ®ã€‚</li>
<li>Mic-E-Mouseé‡‡ç”¨å…ˆè¿›çš„æ•°æ®è¿‡æ»¤ç®¡é“å¤„ç†æŒ¯åŠ¨ä¿¡å·çš„è´¨é‡é—®é¢˜ã€‚</li>
<li>è¯¥æ”»å‡»åœ¨å¤šç§æ¡ä»¶ä¸‹æœ‰æ•ˆï¼ŒåŒ…æ‹¬è®²è¯éŸ³é‡ã€é¼ æ ‡å‚æ•°ã€è¡¨é¢ææ–™ã€è¯­è¨€å’Œç¯å¢ƒå™ªéŸ³ã€‚</li>
<li>åœ¨æ§åˆ¶ç¯å¢ƒä¸‹ï¼ŒMic-E-Mouseèƒ½æé«˜è¯­éŸ³é‡å»ºçš„ä¿¡å™ªæ¯”è¾¾+19åˆ†è´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13581v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Enhancing-Speaker-Independent-Dysarthric-Speech-Severity-Classification-with-DSSCNet-and-Cross-Corpus-Adaptation"><a href="#Enhancing-Speaker-Independent-Dysarthric-Speech-Severity-Classification-with-DSSCNet-and-Cross-Corpus-Adaptation" class="headerlink" title="Enhancing Speaker-Independent Dysarthric Speech Severity Classification   with DSSCNet and Cross-Corpus Adaptation"></a>Enhancing Speaker-Independent Dysarthric Speech Severity Classification   with DSSCNet and Cross-Corpus Adaptation</h2><p><strong>Authors:Arnab Kumar Roy, Hemant Kumar Kathania, Paban Sapkota</strong></p>
<p>Dysarthric speech severity classification is crucial for objective clinical assessment and progress monitoring in individuals with motor speech disorders. Although prior methods have addressed this task, achieving robust generalization in speaker-independent (SID) scenarios remains challenging. This work introduces DSSCNet, a novel deep neural architecture that combines Convolutional, Squeeze-Excitation (SE), and Residual network, helping it extract discriminative representations of dysarthric speech from mel spectrograms. The addition of SE block selectively focuses on the important features of the dysarthric speech, thereby minimizing loss and enhancing overall model performance. We also propose a cross-corpus fine-tuning framework for severity classification, adapted from detection-based transfer learning approaches. DSSCNet is evaluated on two benchmark dysarthric speech corpora: TORGO and UA-Speech under speaker-independent evaluation protocols: One-Speaker-Per-Severity (OSPS) and Leave-One-Speaker-Out (LOSO) protocols. DSSCNet achieves accuracies of 56.84% and 62.62% under OSPS and 63.47% and 64.18% under LOSO setting on TORGO and UA-Speech respectively outperforming existing state-of-the-art methods. Upon fine-tuning, the performance improves substantially, with DSSCNet achieving up to 75.80% accuracy on TORGO and 68.25% on UA-Speech in OSPS, and up to 77.76% and 79.44%, respectively, in LOSO. These results demonstrate the effectiveness and generalizability of DSSCNet for fine-grained severity classification across diverse dysarthric speech datasets. </p>
<blockquote>
<p>è¯­è¨€éšœç¢è¯­éŸ³ä¸¥é‡æ€§åˆ†ç±»å¯¹äºæ‚£æœ‰è¿åŠ¨æ€§è¯­è¨€éšœç¢è€…çš„å®¢è§‚ä¸´åºŠè¯„ä¼°å’Œè¿›åº¦ç›‘æµ‹è‡³å…³é‡è¦ã€‚å°½ç®¡ä¹‹å‰çš„æ–¹æ³•å·²ç»è§£å†³äº†æ­¤ä»»åŠ¡ï¼Œä½†åœ¨ç‹¬ç«‹äºè¯´è¯äººçš„åœºæ™¯ä¸­å®ç°ç¨³å¥çš„æ³›åŒ–ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†DSSCNetï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç»“åˆäº†å·ç§¯ã€æŒ¤å‹æ¿€åŠ±ï¼ˆSEï¼‰å’Œæ®‹å·®ç½‘ç»œï¼Œæœ‰åŠ©äºä»æ¢…å°”é¢‘è°±å›¾ä¸­æå–è¯­è¨€éšœç¢è¯­éŸ³çš„åˆ¤åˆ«è¡¨ç¤ºã€‚SEå—çš„æ·»åŠ æœ‰é€‰æ‹©åœ°å…³æ³¨è¯­è¨€éšœç¢è¯­éŸ³çš„é‡è¦ç‰¹å¾ï¼Œä»è€Œå‡å°æŸå¤±å¹¶æé«˜æ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åŸºäºæ£€æµ‹è¿ç§»å­¦ä¹ æ–¹æ³•çš„ä¸¥é‡æ€§åˆ†ç±»è·¨è¯­æ–™å¾®è°ƒæ¡†æ¶ã€‚DSSCNetåœ¨ä¸¤ä¸ªåŸºå‡†è¯­è¨€éšœç¢è¯­éŸ³è¯­æ–™åº“TORGOå’ŒUA-Speechä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œé‡‡ç”¨ç‹¬ç«‹äºè¯´è¯äººçš„è¯„ä¼°åè®®ï¼šæ¯ä¸¥é‡æ€§ä¸€ä½è¯´è¯äººï¼ˆOSPSï¼‰å’Œç•™ä¸€è¯´è¯äººå‡ºï¼ˆLOSOï¼‰åè®®ã€‚DSSCNetåœ¨TORGOå’ŒUA-Speechä¸Šçš„OSPSåè®®ä¸‹åˆ†åˆ«è¾¾åˆ°56.84%å’Œ62.62%çš„å‡†ç¡®ç‡ï¼Œåœ¨LOSOè®¾ç½®ä¸‹åˆ†åˆ«è¾¾åˆ°63.47%å’Œ64.18%ï¼Œè¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç»è¿‡å¾®è°ƒåï¼Œæ€§èƒ½å¤§å¤§æé«˜ï¼Œåœ¨TORGOçš„OSPSä¸­ï¼ŒDSSCNetçš„å‡†ç¡®ç‡é«˜è¾¾75.80%ï¼Œåœ¨UA-Speechä¸­é«˜è¾¾68.25%ï¼Œè€Œåœ¨LOSOä¸­åˆ†åˆ«é«˜è¾¾77.76%å’Œ79.44%ã€‚è¿™äº›ç»“æœè¯æ˜äº†DSSCNetåœ¨è·¨å¤šç§è¯­è¨€éšœç¢è¯­éŸ³æ•°æ®é›†ä¸Šè¿›è¡Œç²¾ç»†ä¸¥é‡æ€§åˆ†ç±»çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13442v1">PDF</a> Speaker-independent experiments on classification of dysarthric   speech severity</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†è¿åŠ¨æ€§è¨€è¯­éšœç¢æ‚£è€…çš„è¯­è¨€éšœç¢ç¨‹åº¦åˆ†ç±»é—®é¢˜ã€‚å°½ç®¡å·²æœ‰æ–¹æ³•å¯¹æ­¤è¿›è¡Œäº†æ¢ç´¢ï¼Œä½†åœ¨ç‹¬ç«‹äºè¯´è¯äººçš„åœºæ™¯ä¸‹å®ç°ç¨³å¥çš„æ³›åŒ–ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„DSSCNetï¼Œå®ƒç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œã€æŒ¤å‹æ¿€åŠ±ç½‘ç»œå’Œæ®‹å·®ç½‘ç»œï¼Œèƒ½å¤Ÿä»æ¢…å°”é¢‘è°±å›¾ä¸­æå–è¿åŠ¨æ€§è¨€è¯­éšœç¢çš„åˆ¤åˆ«ç‰¹å¾è¡¨ç¤ºã€‚æŒ¤å‹æ¿€åŠ±æ¨¡å—èƒ½å¤Ÿæœ‰é€‰æ‹©åœ°å…³æ³¨è¿åŠ¨æ€§è¨€è¯­éšœç¢çš„é‡è¦ç‰¹å¾ï¼Œä»è€Œå‡å°‘æŸå¤±å¹¶æé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚åŒæ—¶ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºæ£€æµ‹è¿ç§»å­¦ä¹ çš„è·¨è¯­æ–™åº“å¾®è°ƒæ¡†æ¶ï¼Œç”¨äºä¸¥é‡ç¨‹åº¦åˆ†ç±»ã€‚åœ¨TORGOå’ŒUA-Speechä¸¤ä¸ªåŸºå‡†è¿åŠ¨æ€§è¨€è¯­éšœç¢è¯­æ–™åº“ä¸­ï¼Œå¯¹DSSCNetè¿›è¡Œäº†è¯´è¯äººç‹¬ç«‹è¯„ä¼°åè®®ä¸‹çš„è¯„ä¼°ï¼ŒåŒ…æ‹¬å•è¯´è¯äººå•ä¸¥é‡ç¨‹åº¦å’Œç•™ä¸€è¯´è¯äººå‡ºåè®®ã€‚DSSCNetåœ¨TORGOå’ŒUA-Speechä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«åœ¨OPSå’ŒLOSOè®¾ç½®ä¸‹è¾¾åˆ°56.84%å’Œ62.62%ï¼Œä»¥åŠ63.47%å’Œ64.18%ï¼Œè¶…è¿‡äº†ç°æœ‰æœ€æ–°æ–¹æ³•ã€‚ç»è¿‡å¾®è°ƒåï¼ŒDSSCNetçš„æ€§èƒ½å¾—åˆ°æ˜¾è‘—æé«˜ï¼Œåœ¨TORGOå’ŒUA-Speechä¸Šçš„OPSå‡†ç¡®ç‡åˆ†åˆ«æé«˜åˆ°75.80%å’Œ68.25%ï¼ŒLOSOä¸­çš„å‡†ç¡®ç‡åˆ†åˆ«æé«˜åˆ°77.76%å’Œ79.44%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒDSSCNetåœ¨ç²¾ç»†ç²’åº¦çš„ä¸¥é‡ç¨‹åº¦åˆ†ç±»ä¸­å¯¹äºä¸åŒçš„è¿åŠ¨æ€§è¨€è¯­éšœç¢æ•°æ®é›†å…·æœ‰è‰¯å¥½çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>DSSCNetç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œã€æŒ¤å‹æ¿€åŠ±ç½‘ç»œå’Œæ®‹å·®ç½‘ç»œï¼Œèƒ½æœ‰æ•ˆæå–è¿åŠ¨æ€§è¨€è¯­éšœç¢çš„åˆ¤åˆ«ç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>æŒ¤å‹æ¿€åŠ±æ¨¡å—èƒ½å…³æ³¨è¿åŠ¨æ€§è¨€è¯­éšœç¢çš„é‡è¦ç‰¹å¾ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†åŸºäºæ£€æµ‹è¿ç§»å­¦ä¹ çš„è·¨è¯­æ–™åº“å¾®è°ƒæ¡†æ¶ï¼Œç”¨äºä¸¥é‡ç¨‹åº¦åˆ†ç±»ã€‚</li>
<li>DSSCNetåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾ç¤ºå…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡å¾®è°ƒï¼ŒDSSCNetçš„æ€§èƒ½å¾—åˆ°æ˜¾è‘—æé«˜ã€‚</li>
<li>ç ”ç©¶ç»“æœå¯¹äºå¼€å‘æ›´ç²¾ç¡®çš„è¯­éŸ³è¯†åˆ«å’Œè¿åŠ¨æ€§è¨€è¯­éšœç¢è¯Šæ–­å·¥å…·å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13442">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13442v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13442v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13442v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13442v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2509.13442v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CAMEO-Collection-of-Multilingual-Emotional-Speech-Corpora"><a href="#CAMEO-Collection-of-Multilingual-Emotional-Speech-Corpora" class="headerlink" title="CAMEO: Collection of Multilingual Emotional Speech Corpora"></a>CAMEO: Collection of Multilingual Emotional Speech Corpora</h2><p><strong>Authors:Iwona Christop, Maciej Czajka</strong></p>
<p>This paper presents CAMEO â€“ a curated collection of multilingual emotional speech datasets designed to facilitate research in emotion recognition and other speech-related tasks. The main objectives were to ensure easy access to the data, to allow reproducibility of the results, and to provide a standardized benchmark for evaluating speech emotion recognition (SER) systems across different emotional states and languages. The paper describes the dataset selection criteria, the curation and normalization process, and provides performance results for several models. The collection, along with metadata, and a leaderboard, is publicly available via the Hugging Face platform. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†CAMEOâ€”â€”ä¸€ä¸ªç²¾é€‰çš„å¤šè¯­è¨€æƒ…æ„Ÿè¯­éŸ³æ•°æ®é›†åˆé›†ï¼Œæ—¨åœ¨ä¿ƒè¿›æƒ…æ„Ÿè¯†åˆ«å’Œå…¶ä»–ç›¸å…³è¯­éŸ³ä»»åŠ¡çš„ç ”ç©¶ã€‚ä¸»è¦ç›®æ ‡æ˜¯ç¡®ä¿æ•°æ®çš„è½»æ¾è®¿é—®ï¼Œä»¥ä¾¿ç»“æœçš„å¤ç°æ€§ï¼Œä»¥åŠä¸ºè¯„ä¼°ä¸åŒæƒ…æ„ŸçŠ¶æ€å’Œè¯­è¨€çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰ç³»ç»Ÿæä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„åŸºå‡†ã€‚æœ¬æ–‡æè¿°äº†æ•°æ®é›†çš„é€‰æ‹©æ ‡å‡†ã€ç¼–çº‚å’Œå½’ä¸€åŒ–è¿‡ç¨‹ï¼Œå¹¶ä¸ºå‡ ä¸ªæ¨¡å‹æä¾›äº†æ€§èƒ½ç»“æœã€‚è¯¥é›†åˆä¸å…ƒæ•°æ®ä»¥åŠæ’è¡Œæ¦œå¯é€šè¿‡Hugging Faceå¹³å°å…¬å¼€è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11051v2">PDF</a> Under review at ICASSP</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†CAMEOâ€”â€”ä¸€ä¸ªç²¾é€‰çš„å¤šè¯­è¨€æƒ…æ„Ÿè¯­éŸ³æ•°æ®é›†åˆé›†ï¼Œæ—¨åœ¨ä¿ƒè¿›æƒ…æ„Ÿè¯†åˆ«å’Œå…¶ä»–è¯­éŸ³ç›¸å…³ä»»åŠ¡çš„ç ”ç©¶ã€‚å…¶ä¸»è¦ç›®æ ‡åŒ…æ‹¬ç¡®ä¿æ•°æ®çš„è½»æ¾è®¿é—®ã€å…è®¸ç»“æœçš„å¯é‡å¤æ€§ï¼Œä»¥åŠä¸ºä¸åŒæƒ…æ„ŸçŠ¶æ€å’Œè¯­è¨€çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰ç³»ç»Ÿæä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„åŸºå‡†æµ‹è¯•ã€‚æœ¬æ–‡æè¿°äº†æ•°æ®é›†çš„é€‰æ‹©æ ‡å‡†ã€æ•´ç†å’Œæ ‡å‡†åŒ–æµç¨‹ï¼Œå¹¶æä¾›äº†å¤šä¸ªæ¨¡å‹çš„è¡¨ç°ç»“æœã€‚è¯¥åˆé›†ä¸å…ƒæ•°æ®ä»¥åŠæ’è¡Œæ¦œå·²é€šè¿‡Hugging Faceå¹³å°å…¬å¼€æä¾›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CAMEOæ˜¯ä¸€ä¸ªå¤šè¯­è¨€æƒ…æ„Ÿè¯­éŸ³æ•°æ®é›†åˆé›†ï¼Œç”¨äºä¿ƒè¿›æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶ã€‚</li>
<li>æ•°æ®é›†çš„ä¸»è¦ç›®æ ‡æ˜¯ç¡®ä¿æ•°æ®è½»æ¾è®¿é—®ã€ç»“æœå¯é‡å¤ï¼Œå¹¶ä¸ºè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿæä¾›æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•ã€‚</li>
<li>æ•°æ®é›†çš„é€‰æ‹©æ ‡å‡†ã€æ•´ç†å’Œæ ‡å‡†åŒ–æµç¨‹åœ¨æ–‡ä¸­å¾—åˆ°è¯¦ç»†æè¿°ã€‚</li>
<li>æä¾›äº†å¤šä¸ªæ¨¡å‹åœ¨CAMEOä¸Šçš„è¡¨ç°ç»“æœã€‚</li>
<li>è¯¥æ•°æ®é›†åˆé›†ä¸å…ƒæ•°æ®å·²å…¬å¼€åœ¨Hugging Faceå¹³å°ä¸Šã€‚</li>
<li>æœ‰ä¸€ä¸ªå…¬å¼€çš„æ’è¡Œæ¦œï¼Œå¯ä»¥æ¯”è¾ƒä¸åŒç³»ç»Ÿçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11051">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2505.11051v2/page_3_1.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="COMI-LINGUA-Expert-Annotated-Large-Scale-Dataset-for-Multitask-NLP-in-Hindi-English-Code-Mixing"><a href="#COMI-LINGUA-Expert-Annotated-Large-Scale-Dataset-for-Multitask-NLP-in-Hindi-English-Code-Mixing" class="headerlink" title="COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in   Hindi-English Code-Mixing"></a>COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in   Hindi-English Code-Mixing</h2><p><strong>Authors:Rajvee Sheth, Himanshu Beniwal, Mayank Singh</strong></p>
<p>We introduce COMI-LINGUA, the largest manually annotated Hindi-English code-mixed dataset, comprising 125K+ high-quality instances across five core NLP tasks: Matrix Language Identification, Token-level Language Identification, Part-Of-Speech Tagging, Named Entity Recognition, and Machine Translation. Each instance is annotated by three bilingual annotators, yielding over 376K expert annotations with strong inter-annotator agreement (Fleissâ€™ Kappa $\geq$ 0.81). The rigorously preprocessed and filtered dataset covers both Devanagari and Roman scripts and spans diverse domains, ensuring real-world linguistic coverage. Evaluation reveals that closed-source LLMs significantly outperform traditional tools and open-source models in zero-shot settings. Notably, one-shot prompting consistently boosts performance across tasks, especially in structure-sensitive predictions like POS and NER. Fine-tuning state-of-the-art LLMs on COMI-LINGUA demonstrates substantial improvements, achieving up to 95.25 F1 in NER, 98.77 F1 in MLI, and competitive MT performance, setting new benchmarks for Hinglish code-mixed text. COMI-LINGUA is publicly available at this URL: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA">https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»COMI-LINGUAï¼Œè¿™æ˜¯æœ€å¤§çš„æ‰‹åŠ¨æ ‡æ³¨çš„å°åœ°è¯­-è‹±è¯­æ··åˆä»£ç æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡12.5ä¸‡ä¸ªé«˜è´¨é‡å®ä¾‹ï¼Œæ¶‰åŠäº”ä¸ªæ ¸å¿ƒNLPä»»åŠ¡ï¼šçŸ©é˜µè¯­è¨€è¯†åˆ«ã€æ ‡è®°çº§è¯­è¨€è¯†åˆ«ã€è¯æ€§æ ‡æ³¨ã€å‘½åå®ä½“è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ã€‚æ¯ä¸ªå®ä¾‹å‡ç”±ä¸‰ååŒè¯­æ³¨é‡Šè€…è¿›è¡Œæ ‡æ³¨ï¼Œäº§ç”Ÿäº†è¶…è¿‡37.6ä¸‡ä¸ªä¸“å®¶æ³¨é‡Šï¼Œæ³¨é‡Šè€…ä¹‹é—´çš„å¼ºä¸€è‡´æ€§ï¼ˆFleissâ€™ Kappa $\geq$ 0.81ï¼‰ã€‚è¯¥æ•°æ®é›†ç»è¿‡ä¸¥æ ¼é¢„å¤„ç†å’Œè¿‡æ»¤ï¼Œæ¶µç›–Devanagariå’ŒRomanä¸¤ç§è„šæœ¬ï¼Œæ¶‰åŠå¤šä¸ªé¢†åŸŸï¼Œç¡®ä¿ç°å®ä¸–ç•Œçš„è¯­è¨€è¦†ç›–ã€‚è¯„ä¼°è¡¨æ˜ï¼Œå°é—­æºä»£ç çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå·¥å…·å’Œå¼€æºæ¨¡å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸€æ¬¡æ€§æç¤ºä»»åŠ¡å§‹ç»ˆæé«˜äº†æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»“æ„æ•æ„Ÿçš„é¢„æµ‹ä¸­ï¼Œå¦‚POSå’ŒNERã€‚åœ¨COMI-LINGUAä¸Šå¯¹æœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå‘½åå®ä½“è¯†åˆ«çš„F1å¾—åˆ†é«˜è¾¾95.25ï¼ŒçŸ©é˜µè¯­è¨€è¯†åˆ«çš„F1å¾—åˆ†é«˜è¾¾98.77ï¼Œæœºå™¨ç¿»è¯‘æ€§èƒ½å…·æœ‰ç«äº‰åŠ›ï¼Œä¸ºå°åœ°è¯­æ··åˆæ–‡æœ¬æ ‘ç«‹äº†æ–°åŸºå‡†ã€‚COMI-LINGUAå¯åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/LingoIITGN/COMI-LINGUA%E3%80%82">https://huggingface.co/datasets/LingoIITGN/COMI-LINGUAã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21670v3">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>COMI-LINGUAæ˜¯æœ€å¤§è§„æ¨¡çš„æ‰‹åŠ¨æ ‡æ³¨å°åœ°è¯­-è‹±è¯­æ··åˆä»£ç æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡12.5ä¸‡ä¸ªé«˜è´¨é‡å®ä¾‹ï¼Œæ¶µç›–äº”å¤§æ ¸å¿ƒNLPä»»åŠ¡ã€‚è¯¥æ•°æ®é›†ç”±ä¸‰ä½åŒè¯­æ ‡æ³¨è€…è¿›è¡Œæ ‡æ³¨ï¼Œå…·æœ‰å¼ºå¤§çš„æ ‡æ³¨è€…é—´ä¸€è‡´æ€§ã€‚æ•°æ®é›†ç»è¿‡ä¸¥æ ¼é¢„å¤„ç†å’Œç­›é€‰ï¼Œè¦†ç›–å¤šç§é¢†åŸŸå’Œè„šæœ¬ï¼Œç¡®ä¿çœŸå®ä¸–ç•Œè¯­è¨€è¦†ç›–åº¦ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œå°é—­æºä»£ç çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå·¥å…·å’Œå¼€æºæ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ä¸€æ­¥æç¤ºæ³•åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°ä¸€è‡´ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»“æ„æ•æ„Ÿçš„é¢„æµ‹å¦‚POSå’ŒNERä¸Šæ•ˆæœæ˜¾è‘—ã€‚å¯¹æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨COMI-LINGUAä¸Šè¿›è¡Œå¾®è°ƒï¼Œå®ç°äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œåœ¨NERä¸Šè¾¾åˆ°95.25 F1ï¼ŒMLIè¾¾åˆ°98.77 F1ï¼Œå¹¶ä¸”åœ¨æœºå™¨ç¿»è¯‘æ€§èƒ½ä¸Šå…·æœ‰ç«äº‰åŠ›ï¼Œä¸ºå°åœ°è¯­æ··åˆæ–‡æœ¬è®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>COMI-LINGUAæ˜¯æœ€å¤§è§„æ¨¡çš„æ‰‹åŠ¨æ ‡æ³¨å°åœ°è¯­-è‹±è¯­æ··åˆä»£ç æ•°æ®é›†ã€‚</li>
<li>æ•°æ®é›†æ¶µç›–äº”å¤§æ ¸å¿ƒNLPä»»åŠ¡ï¼ŒåŒ…æ‹¬çŸ©é˜µè¯­è¨€è¯†åˆ«ã€ä»¤ç‰Œçº§è¯­è¨€è¯†åˆ«ã€è¯æ€§æ ‡æ³¨ã€å®ä½“å‘½åè¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ã€‚</li>
<li>æ•°æ®é›†ç”±ä¸‰ä½åŒè¯­æ ‡æ³¨è€…è¿›è¡Œæ ‡æ³¨ï¼Œå…·æœ‰å¼ºå¤§çš„æ ‡æ³¨è€…é—´ä¸€è‡´æ€§ï¼ˆFleissâ€™ Kappa â‰¥ 0.81ï¼‰ã€‚</li>
<li>æ•°æ®é›†è¦†ç›–å¤šç§é¢†åŸŸå’Œè„šæœ¬ï¼Œç¡®ä¿çœŸå®ä¸–ç•Œè¯­è¨€è¦†ç›–åº¦ã€‚</li>
<li>å°é—­æºä»£ç çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå·¥å…·å’Œå¼€æºæ¨¡å‹ã€‚</li>
<li>ä¸€æ­¥æç¤ºæ³•åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°ä¸€è‡´ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»“æ„æ•æ„Ÿçš„é¢„æµ‹å¦‚POSå’ŒNERä¸Šæ•ˆæœæ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21670">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Speech/2503.21670v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/GAN/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_GAN/2410.19794v4/page_0_0.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  DiffGAN A Test Generation Approach for Differential Testing of Deep   Neural Networks for Image Analysis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å½±åƒ_Breast Ultrasound/2509.13508v1/page_3_0.jpg" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  FunKAN Functional Kolmogorov-Arnold Network for Medical Image   Enhancement and Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31686.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
