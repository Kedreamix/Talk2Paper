<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  LamiGauss Pitching Radiative Gaussian for Sparse-View X-ray   Laminography Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_0_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    65 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-19-æ›´æ–°"><a href="#2025-09-19-æ›´æ–°" class="headerlink" title="2025-09-19 æ›´æ–°"></a>2025-09-19 æ›´æ–°</h1><h2 id="LamiGauss-Pitching-Radiative-Gaussian-for-Sparse-View-X-ray-Laminography-Reconstruction"><a href="#LamiGauss-Pitching-Radiative-Gaussian-for-Sparse-View-X-ray-Laminography-Reconstruction" class="headerlink" title="LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray   Laminography Reconstruction"></a>LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray   Laminography Reconstruction</h2><p><strong>Authors:Chu Chen, Ander Biguri, Jean-Michel Morel, Raymond H. Chan, Carola-Bibiane SchÃ¶nlieb, Jizhou Li</strong></p>
<p>X-ray Computed Laminography (CL) is essential for non-destructive inspection of plate-like structures in applications such as microchips and composite battery materials, where traditional computed tomography (CT) struggles due to geometric constraints. However, reconstructing high-quality volumes from laminographic projections remains challenging, particularly under highly sparse-view acquisition conditions. In this paper, we propose a reconstruction algorithm, namely LamiGauss, that combines Gaussian Splatting radiative rasterization with a dedicated detector-to-world transformation model incorporating the laminographic tilt angle. LamiGauss leverages an initialization strategy that explicitly filters out common laminographic artifacts from the preliminary reconstruction, preventing redundant Gaussians from being allocated to false structures and thereby concentrating model capacity on representing the genuine object. Our approach effectively optimizes directly from sparse projections, enabling accurate and efficient reconstruction with limited data. Extensive experiments on both synthetic and real datasets demonstrate the effectiveness and superiority of the proposed method over existing techniques. LamiGauss uses only 3$%$ of full views to achieve superior performance over the iterative method optimized on a full dataset. </p>
<blockquote>
<p>Xå°„çº¿è®¡ç®—å±‚ææˆåƒï¼ˆCLï¼‰å¯¹äºå¾®èŠ¯ç‰‡å’Œå¤åˆç”µæ± ææ–™ç­‰æ¿çŠ¶ç»“æ„çš„éç ´åæ€§æ£€æµ‹è‡³å…³é‡è¦ã€‚ç”±äºå‡ ä½•çº¦æŸï¼Œä¼ ç»Ÿè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰åœ¨è¿™äº›åº”ç”¨ä¸­é¢ä¸´å›°éš¾ã€‚ç„¶è€Œï¼Œä»å±‚ææŠ•å½±é‡å»ºé«˜è´¨é‡ä½“ç§¯ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åº¦ç¨€ç–è§†å›¾é‡‡é›†æ¡ä»¶ä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é‡å»ºç®—æ³•ï¼Œå³LamiGaussï¼Œå®ƒå°†é«˜æ–¯Splattingè¾å°„å…‰æ …åŒ–ä¸ç»“åˆå±‚æå€¾æ–œè§’çš„ä¸“ç”¨æ£€æµ‹å™¨åˆ°ä¸–ç•Œè½¬æ¢æ¨¡å‹ç›¸ç»“åˆã€‚LamiGaussåˆ©ç”¨åˆå§‹åŒ–ç­–ç•¥ï¼Œæ˜ç¡®è¿‡æ»¤å‡ºå¸¸è§çš„å±‚æä¼ªå½±ï¼Œé˜²æ­¢å†—ä½™é«˜æ–¯å€¼è¢«åˆ†é…åˆ°é”™è¯¯çš„ç»“æ„ä¸Šï¼Œä»è€Œå°†æ¨¡å‹å®¹é‡é›†ä¸­åœ¨è¡¨ç¤ºçœŸå®ç‰©ä½“ä¸Šã€‚æˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥ä»ç¨€ç–æŠ•å½±ä¸­è¿›è¡Œä¼˜åŒ–ï¼Œå¯ç”¨æœ‰é™çš„æ•°æ®å®ç°å‡†ç¡®é«˜æ•ˆçš„é‡å»ºã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚LamiGaussä»…ä½¿ç”¨3%çš„å…¨è§†å›¾å³å¯å®ç°ä¼˜äºå…¨æ•°æ®é›†ä¼˜åŒ–è¿­ä»£æ–¹æ³•çš„é«˜æ€§èƒ½è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13863v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Xå…‰è®¡ç®—å±‚ææˆåƒï¼ˆCLï¼‰å¯¹äºå¾®èŠ¯ç‰‡å’Œå¤åˆç”µæ± ææ–™ç­‰æ¿çŠ¶ç»“æ„çš„éç ´åæ€§æ£€æµ‹è‡³å…³é‡è¦ï¼Œä¼ ç»Ÿè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰å› å‡ ä½•çº¦æŸè€Œéš¾ä»¥åº”ç”¨ã€‚æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆé«˜æ–¯æº…å°„è¾å°„å…‰æ …åŒ–å’ŒåŒ…å«å±‚æå€¾æ–œè§’çš„ä¸“ç”¨æ£€æµ‹å™¨åˆ°ä¸–ç•Œè½¬æ¢æ¨¡å‹çš„é‡å»ºç®—æ³•LamiGaussã€‚è¯¥ç®—æ³•é€šè¿‡åˆæ­¥é‡å»ºè¿‡æ»¤æ‰å¸¸è§çš„å±‚ææˆåƒä¼ªå½±ï¼Œé¿å…å†—ä½™é«˜æ–¯åˆ†é…äºé”™è¯¯ç»“æ„ï¼Œä»è€Œä¸“æ³¨äºçœŸå®ç‰©ä½“çš„è¡¨ç¤ºã€‚æ­¤ç®—æ³•ç›´æ¥ä»ç¨€ç–æŠ•å½±è¿›è¡Œä¼˜åŒ–ï¼Œåœ¨æœ‰é™æ•°æ®ä¸‹å®ç°å‡†ç¡®é«˜æ•ˆçš„é‡å»ºã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°æœ‰æŠ€æœ¯ä¸Šçš„æ•ˆæœå’Œä¼˜è¶Šæ€§ã€‚ä»…ä½¿ç”¨å…¨éƒ¨è§†å›¾çš„3%ï¼Œä¾¿å¯è¶…è¶Šåœ¨å…¨æ•°æ®é›†ä¸Šä¼˜åŒ–çš„è¿­ä»£æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>X-ray Computed Laminography (CL)å¯¹äºéç ´åæ€§æ£€æµ‹æ¿çŠ¶ç»“æ„éå¸¸é‡è¦ï¼Œå°¤å…¶é€‚ç”¨äºå¾®èŠ¯ç‰‡å’Œå¤åˆç”µæ± ææ–™ç­‰åº”ç”¨ã€‚</li>
<li>ä¼ ç»Ÿè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ç”±äºå‡ ä½•çº¦æŸåœ¨æŸäº›é¢†åŸŸéš¾ä»¥åº”ç”¨ã€‚</li>
<li>LamiGaussç®—æ³•ç»“åˆäº†Gaussian Splattingå’Œæ£€æµ‹å™¨åˆ°ä¸–ç•Œçš„è½¬æ¢æ¨¡å‹ã€‚</li>
<li>LamiGaussé€šè¿‡è¿‡æ»¤å±‚ææˆåƒä¼ªå½±ï¼Œä¼˜åŒ–æ¨¡å‹å®¹é‡ä»¥è¡¨ç¤ºçœŸå®ç‰©ä½“ã€‚</li>
<li>è¯¥ç®—æ³•å¯ç›´æ¥ä»ç¨€ç–æŠ•å½±è¿›è¡Œä¼˜åŒ–ï¼Œå®ç°æœ‰é™æ•°æ®ä¸‹çš„å‡†ç¡®é«˜æ•ˆé‡å»ºã€‚</li>
<li>åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜LamiGaussæ–¹æ³•å’Œç°æœ‰æŠ€æœ¯çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13863v1/page_3_1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Consistent-View-Alignment-Improves-Foundation-Models-for-3D-Medical-Image-Segmentation"><a href="#Consistent-View-Alignment-Improves-Foundation-Models-for-3D-Medical-Image-Segmentation" class="headerlink" title="Consistent View Alignment Improves Foundation Models for 3D Medical   Image Segmentation"></a>Consistent View Alignment Improves Foundation Models for 3D Medical   Image Segmentation</h2><p><strong>Authors:Puru Vaish, Felix Meister, Tobias Heimann, Christoph Brune, Jelmer M. Wolterink</strong></p>
<p>Many recent approaches in representation learning implicitly assume that uncorrelated views of a data point are sufficient to learn meaningful representations for various downstream tasks. In this work, we challenge this assumption and demonstrate that meaningful structure in the latent space does not emerge naturally. Instead, it must be explicitly induced. We propose a method that aligns representations from different views of the data to align complementary information without inducing false positives. Our experiments show that our proposed self-supervised learning method, Consistent View Alignment, improves performance for downstream tasks, highlighting the critical role of structured view alignment in learning effective representations. Our method achieved first and second place in the MICCAI 2025 SSL3D challenge when using a Primus vision transformer and ResEnc convolutional neural network, respectively. The code and pretrained model weights are released at <a target="_blank" rel="noopener" href="https://github.com/Tenbatsu24/LatentCampus">https://github.com/Tenbatsu24/LatentCampus</a>. </p>
<blockquote>
<p>åœ¨è¡¨ç¤ºå­¦ä¹ çš„è¯¸å¤šæœ€æ–°æ–¹æ³•ä¸­ï¼Œéšå«åœ°å‡è®¾ä¸€ä¸ªæ•°æ®ç‚¹çš„éç›¸å…³è§†å›¾è¶³ä»¥ä¸ºå„ç§ä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ æœ‰æ„ä¹‰çš„è¡¨ç¤ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è´¨ç–‘è¿™ä¸€å‡è®¾ï¼Œå¹¶è¯æ˜æ½œåœ¨ç©ºé—´ä¸­çš„æœ‰æ„ä¹‰ç»“æ„å¹¶ä¸ä¼šè‡ªç„¶å‡ºç°ã€‚ç›¸åï¼Œå®ƒå¿…é¡»æ˜¾å¼åœ°è¯±å¯¼äº§ç”Ÿã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ•°æ®ä¸åŒè§†å›¾çš„è¡¨ç¤ºè¿›è¡Œå¯¹é½ï¼Œä»¥å¯¹é½äº’è¡¥ä¿¡æ¯ï¼Œè€Œä¸ä¼šäº§ç”Ÿè¯¯æŠ¥ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•â€”â€”ä¸€è‡´è§†å›¾å¯¹é½ï¼Œæé«˜äº†ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼Œå‡¸æ˜¾äº†ç»“æ„åŒ–è§†å›¾å¯¹é½åœ¨å­¦ä¹ æœ‰æ•ˆè¡¨ç¤ºä¸­çš„å…³é”®ä½œç”¨ã€‚å½“ä½¿ç”¨Primusè§†è§‰å˜å‹å™¨å’ŒResEncå·ç§¯ç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨MICCAI 2025 SSL3DæŒ‘æˆ˜ä¸­åˆ†åˆ«å–å¾—ç¬¬ä¸€å’Œç¬¬äºŒåã€‚ç›¸å…³ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹æƒé‡å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/Tenbatsu24/LatentCampus">https://github.com/Tenbatsu24/LatentCampus</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13846v1">PDF</a> MICCAI 2025: 1st Place in Transformer track and 2nd Place in   Convolution track of SSL3D-OpenMind challenge</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æŒ‘æˆ˜äº†ç°æœ‰è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¸­æ— å…³æ•°æ®ç‚¹è§†å›¾èƒ½è‡ªç„¶å½¢æˆæœ‰æ„ä¹‰ç»“æ„çš„å‡è®¾ï¼Œå¹¶æå‡ºä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡å¯¹ä¸åŒè§†å›¾çš„æ•°æ®è¡¨ç¤ºè¿›è¡Œå¯¹é½ï¼Œä»¥è·å–äº’è¡¥ä¿¡æ¯ï¼Œé¿å…äº§ç”Ÿè¯¯æŠ¥ã€‚å®éªŒè¯æ˜ï¼Œå…¶æå‡ºçš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•Consistent View Alignmentå¯¹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æœ‰æ‰€æå‡ã€‚åœ¨MICCAI 2025 SSL3DæŒ‘æˆ˜èµ›ä¸­ï¼Œä½¿ç”¨Primus Vision Transformerå’ŒResEncå·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•åˆ†åˆ«è·å¾—ç¬¬ä¸€å’Œç¬¬äºŒåã€‚ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹æƒé‡å·²å‘å¸ƒåœ¨LatentCampusä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰è¡¨ç¤ºå­¦ä¹ æ–¹æ³•å­˜åœ¨å‡è®¾ï¼šæ— å…³æ•°æ®ç‚¹è§†å›¾è¶³ä»¥å½¢æˆæœ‰æ„ä¹‰ç»“æ„ï¼Œæœ¬æ–‡å¯¹æ­¤æå‡ºè´¨ç–‘ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡æ˜¾å¼è¯±å¯¼å½¢æˆæœ‰æ„ä¹‰ç»“æ„ï¼Œè€Œéå‡è®¾å…¶ä¼šè‡ªç„¶å‡ºç°ã€‚</li>
<li>æ–¹æ³•åä¸ºConsistent View Alignmentï¼Œæ—¨åœ¨å¯¹é½ä¸åŒè§†å›¾çš„æ•°æ®è¡¨ç¤ºï¼Œè·å–äº’è¡¥ä¿¡æ¯å¹¶é¿å…è¯¯æŠ¥ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æé«˜ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>åœ¨MICCAI 2025 SSL3DæŒ‘æˆ˜èµ›ä¸­ï¼Œä½¿ç”¨æ­¤æ–¹æ³•åœ¨ä¸¤ç§ä¸åŒç½‘ç»œæ¶æ„ä¸Šå–å¾—ä¼˜å¼‚æˆç»©ã€‚</li>
<li>ä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹æƒé‡å·²å…¬å¼€å‘å¸ƒåœ¨LatentCampusä¸Šï¼Œæ–¹ä¾¿ç ”ç©¶è€…å’Œå¼€å‘è€…ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13846">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13846v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13846v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Semi-MoE-Mixture-of-Experts-meets-Semi-Supervised-Histopathology-Segmentation"><a href="#Semi-MoE-Mixture-of-Experts-meets-Semi-Supervised-Histopathology-Segmentation" class="headerlink" title="Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology   Segmentation"></a>Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology   Segmentation</h2><p><strong>Authors:Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Thien Nguyen, Daisuke Kihara, Tianyang Wang, Xingjian Li, Min Xu</strong></p>
<p>Semi-supervised learning has been employed to alleviate the need for extensive labeled data for histopathology image segmentation, but existing methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and morphological misclassification. This paper introduces Semi-MOE, to the best of our knowledge, the first multi-task Mixture-of-Experts framework for semi-supervised histopathology image segmentation. Our approach leverages three specialized expert networks: A main segmentation expert, a signed distance field regression expert, and a boundary prediction expert, each dedicated to capturing distinct morphological features. Subsequently, the Multi-Gating Pseudo-labeling module dynamically aggregates expert features, enabling a robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate manual tuning while dynamically balancing multiple learning objectives, we propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and CRAG benchmarks show that our method outperforms state-of-the-art approaches in low-label settings, highlighting the potential of MoE-based architectures in advancing semi-supervised segmentation. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/vnlvi2k3/Semi-MoE">https://github.com/vnlvi2k3/Semi-MoE</a>. </p>
<blockquote>
<p>åŠç›‘ç£å­¦ä¹ å·²è¢«åº”ç”¨äºç¼“è§£ç—…ç†å­¦å›¾åƒåˆ†å‰²å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç”±äºè…ºä½“è¾¹ç•Œæ¨¡ç³Šå’Œå½¢æ€è¯¯åˆ†ç±»è€Œäº§ç”Ÿçš„å™ªå£°ä¼ªæ ‡ç­¾æ—¶é‡åˆ°äº†å›°éš¾ã€‚æœ¬æ–‡å¼•å…¥äº†Semi-MOEï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºåŠç›‘ç£ç—…ç†å­¦å›¾åƒåˆ†å‰²çš„å¤šä»»åŠ¡æ··åˆä¸“å®¶æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨ä¸‰ä¸ªä¸“ä¸šçš„ä¸“å®¶ç½‘ç»œï¼šä¸»è¦åˆ†å‰²ä¸“å®¶ã€å¸¦ç¬¦å·è·ç¦»åœºå›å½’ä¸“å®¶å’Œè¾¹ç•Œé¢„æµ‹ä¸“å®¶ï¼Œæ¯ä¸ªä¸“å®¶ç½‘ç»œéƒ½ä¸“æ³¨äºæ•è·ä¸åŒçš„å½¢æ€ç‰¹å¾ã€‚éšåï¼Œå¤šé—¨æ§ä¼ªæ ‡ç­¾æ¨¡å—åŠ¨æ€èšåˆä¸“å®¶ç‰¹å¾ï¼Œå®ç°ç¨³å¥çš„èåˆå’Œç»†åŒ–ä¼ªæ ‡ç­¾æœºåˆ¶ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ¶ˆé™¤æ‰‹åŠ¨è°ƒæ•´ï¼ŒåŒæ—¶åŠ¨æ€å¹³è¡¡å¤šä¸ªå­¦ä¹ ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”å¤šç›®æ ‡æŸå¤±ã€‚åœ¨GlaSå’ŒCRAGåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä½æ ‡ç­¾è®¾ç½®ä¸‹ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†åŸºäºMoEæ¶æ„çš„æ½œåŠ›åœ¨æ¨è¿›åŠç›‘ç£åˆ†å‰²æ–¹é¢çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/vnlvi2k3/Semi-MoE%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/vnlvi2k3/Semi-MoEè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13834v1">PDF</a> Accepted to BMVC 2025</p>
<p><strong>Summary</strong></p>
<p>åŠç›‘ç£å­¦ä¹ è¢«åº”ç”¨äºç¼“è§£åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ï¼Œä½†ç°æœ‰æ–¹æ³•å› è…ºä½“è¾¹ç•Œæ¨¡ç³Šå’Œå½¢æ€è¯¯åˆ†ç±»è€Œé¢ä¸´å™ªå£°ä¼ªæ ‡ç­¾çš„é—®é¢˜ã€‚æœ¬æ–‡å¼•å…¥Semi-MOEï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªç”¨äºåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²çš„å¤šä»»åŠ¡æ··åˆä¸“å®¶æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸‰ä¸ªä¸“ä¸šä¸“å®¶ç½‘ç»œï¼šä¸»åˆ†å‰²ä¸“å®¶ã€ç¬¦å·è·ç¦»åœºå›å½’ä¸“å®¶å’Œè¾¹ç•Œé¢„æµ‹ä¸“å®¶ï¼Œåˆ†åˆ«ä¸“æ³¨äºæ•æ‰ä¸åŒçš„å½¢æ€ç‰¹å¾ã€‚éšåï¼Œå¤šé—¨æ§ä¼ªæ ‡ç­¾æ¨¡å—åŠ¨æ€èšåˆä¸“å®¶ç‰¹å¾ï¼Œå®ç°ç¨³å¥çš„èåˆå’Œç»†åŒ–ä¼ªæ ‡ç­¾æœºåˆ¶ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ¶ˆé™¤æ‰‹åŠ¨è°ƒæ•´å¹¶åŠ¨æ€å¹³è¡¡å¤šä¸ªå­¦ä¹ ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”å¤šç›®æ ‡æŸå¤±ã€‚åœ¨GlaSå’ŒCRAGåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä½æ ‡ç­¾è®¾ç½®ä¸‹ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†åŸºäºMoEæ¶æ„çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶è§£å†³åŠç›‘ç£å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­é¢ä¸´å™ªå£°ä¼ªæ ‡ç­¾çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥Semi-MOEï¼Œæ®ç§°é¦–ä¸ªå¤šä»»åŠ¡æ··åˆä¸“å®¶æ¡†æ¶ç”¨äºåŠç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</li>
<li>åˆ©ç”¨ä¸‰ä¸ªä¸“ä¸šä¸“å®¶ç½‘ç»œè¿›è¡Œç‰¹å¾æ•æ‰ï¼šä¸»åˆ†å‰²ã€ç¬¦å·è·ç¦»åœºå›å½’å’Œè¾¹ç•Œé¢„æµ‹ã€‚</li>
<li>å¤šé—¨æ§ä¼ªæ ‡ç­¾æ¨¡å—åŠ¨æ€èšåˆä¸“å®¶ç‰¹å¾ï¼Œå®ç°ç¨³å¥ä¼ªæ ‡ç­¾æœºåˆ¶ã€‚</li>
<li>æå‡ºè‡ªé€‚åº”å¤šç›®æ ‡æŸå¤±ä»¥æ¶ˆé™¤æ‰‹åŠ¨è°ƒæ•´å¹¶åŠ¨æ€å¹³è¡¡å¤šä¸ªå­¦ä¹ ç›®æ ‡ã€‚</li>
<li>åœ¨GlaSå’ŒCRAGåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ ‡ç­¾è®¾ç½®ä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13834">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13834v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13834v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13834v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="VocSegMRI-Multimodal-Learning-for-Precise-Vocal-Tract-Segmentation-in-Real-time-MRI"><a href="#VocSegMRI-Multimodal-Learning-for-Precise-Vocal-Tract-Segmentation-in-Real-time-MRI" class="headerlink" title="VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in   Real-time MRI"></a>VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in   Real-time MRI</h2><p><strong>Authors:Daiqi Liu, TomÃ¡s Arias-Vergara, Johannes Enk, Fangxu Xing, Maureen Stone, Jerry L. Prince, Jana Hutter, Andreas Maier, Jonghye Woo, Paula Andrea PÃ©rez-Toro</strong></p>
<p>Accurately segmenting articulatory structures in real-time magnetic resonance imaging (rtMRI) remains challenging, as most existing methods rely almost entirely on visual cues. Yet synchronized acoustic and phonological signals provide complementary context that can enrich visual information and improve precision. In this paper, we introduce VocSegMRI, a multimodal framework that integrates video, audio, and phonological inputs through cross-attention fusion for dynamic feature alignment. To further enhance cross-modal representation, we incorporate a contrastive learning objective that improves segmentation performance even when the audio modality is unavailable at inference. Evaluated on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance (HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines. Ablation studies confirm the contributions of cross-attention and contrastive learning to segmentation precision and robustness. These results highlight the value of integrative multimodal modeling for accurate vocal tract analysis. </p>
<blockquote>
<p>å®æ—¶ç£å…±æŒ¯æˆåƒï¼ˆrtMRIï¼‰ä¸­ç²¾ç¡®åˆ†å‰²å‘éŸ³ç»“æ„ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºå¤§å¤šæ•°ç°æœ‰æ–¹æ³•å‡ ä¹å®Œå…¨ä¾èµ–äºè§†è§‰çº¿ç´¢ã€‚ç„¶è€Œï¼ŒåŒæ­¥çš„å£°å­¦å’Œè¯­éŸ³ä¿¡å·æä¾›äº†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ä»¥ä¸°å¯Œè§†è§‰ä¿¡æ¯å¹¶æé«˜ç²¾åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†VocSegMRIï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ¨¡å¼æ¡†æ¶ï¼Œé€šè¿‡è·¨æ³¨æ„èåˆæ•´åˆè§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³è¾“å…¥ï¼Œå®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºè·¨æ¨¡å¼è¡¨ç¤ºï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯¹æ¯”å­¦ä¹ ç›®æ ‡ï¼Œå³ä½¿åœ¨æ¨ç†æ—¶éŸ³é¢‘æ¨¡å¼ä¸å¯ç”¨ï¼Œä¹Ÿèƒ½æé«˜åˆ†å‰²æ€§èƒ½ã€‚åœ¨USC-75 rtMRIæ•°æ®é›†çš„ä¸€ä¸ªå­é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒDiceå¾—åˆ†ä¸º0.95ï¼Œ95thç™¾åˆ†ä½Hausdorffè·ç¦»ï¼ˆHD_95ï¼‰ä¸º4.20æ¯«ç±³ï¼Œè¶…è¿‡äº†å•æ¨¡æ€å’Œå¤šæ¨¡æ€åŸºçº¿ã€‚æ¶ˆèç ”ç©¶è¯å®äº†è·¨æ³¨æ„åŠ›å’Œå¯¹æ¯”å­¦ä¹ å¯¹åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§çš„è´¡çŒ®ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æ•´åˆå¤šæ¨¡å¼å»ºæ¨¡åœ¨å‡†ç¡®åˆ†æå£°å¸¦ç»“æ„ä¸­çš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13767v1">PDF</a> Preprint submitted to ICASSP</p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡æå‡ºVocSegMRIçš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œé€šè¿‡èåˆè§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³ä¿¡å·ï¼Œåˆ©ç”¨è·¨æ³¨æ„åŠ›èåˆå®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ï¼Œæé«˜å®æ—¶ç£å…±æŒ¯æˆåƒï¼ˆrtMRIï¼‰ä¸­å¯¹å‘éŸ³ç»“æ„çš„å‡†ç¡®åˆ†å‰²ã€‚å³ä½¿åœ¨æ²¡æœ‰éŸ³é¢‘æ¨¡æ€çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ç›®æ ‡ï¼Œè¯¥æ¡†æ¶ä¹Ÿèƒ½æé«˜åˆ†å‰²æ€§èƒ½ã€‚åœ¨USC-75 rtMRIæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°é¢†å…ˆæ°´å¹³ï¼ŒDiceç³»æ•°ä¸º0.95ï¼ŒHausdorff Distanceï¼ˆHD_95ï¼‰ä¸º4.20mmã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VocSegMRIæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¡†æ¶ï¼Œèƒ½å¤Ÿæ•´åˆè§†é¢‘ã€éŸ³é¢‘å’Œè¯­éŸ³ä¿¡å·ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨è·¨æ³¨æ„åŠ›èåˆå®ç°åŠ¨æ€ç‰¹å¾å¯¹é½ã€‚</li>
<li>å¯¹æ¯”å­¦ä¹ ç›®æ ‡çš„å¼•å…¥æé«˜äº†åˆ†å‰²æ€§èƒ½çš„é²æ£’æ€§ï¼Œå³ä½¿åœ¨æ²¡æœ‰éŸ³é¢‘æ¨¡æ€çš„æƒ…å†µä¸‹ã€‚</li>
<li>åœ¨USC-75 rtMRIæ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒVocSegMRIè¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•çš„Diceç³»æ•°è¾¾åˆ°0.95ï¼Œæ˜¾ç¤ºå‡ºè¾ƒé«˜çš„åˆ†å‰²å‡†ç¡®æ€§ã€‚</li>
<li>æ¡†æ¶çš„Ablationç ”ç©¶è¯å®äº†è·¨æ³¨æ„åŠ›å’Œå¯¹æ¯”å­¦ä¹ å¯¹åˆ†å‰²ç²¾åº¦å’Œç¨³å¥æ€§çš„è´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13767v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13767v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13767v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13767v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13767v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SAMIR-an-efficient-registration-framework-via-robust-feature-learning-from-SAM"><a href="#SAMIR-an-efficient-registration-framework-via-robust-feature-learning-from-SAM" class="headerlink" title="SAMIR, an efficient registration framework via robust feature learning   from SAM"></a>SAMIR, an efficient registration framework via robust feature learning   from SAM</h2><p><strong>Authors:Yue He, Min Liu, Qinghao Liu, Jiazheng Wang, Yaonan Wang, Hang Zhang, Xiang Chen</strong></p>
<p>Image registration is a fundamental task in medical image analysis. Deformations are often closely related to the morphological characteristics of tissues, making accurate feature extraction crucial. Recent weakly supervised methods improve registration by incorporating anatomical priors such as segmentation masks or landmarks, either as inputs or in the loss function. However, such weak labels are often not readily available, limiting their practical use. Motivated by the strong representation learning ability of visual foundation models, this paper introduces SAMIR, an efficient medical image registration framework that utilizes the Segment Anything Model (SAM) to enhance feature extraction. SAM is pretrained on large-scale natural image datasets and can learn robust, general-purpose visual representations. Rather than using raw input images, we design a task-specific adaptation pipeline using SAMâ€™s image encoder to extract structure-aware feature embeddings, enabling more accurate modeling of anatomical consistency and deformation patterns. We further design a lightweight 3D head to refine features within the embedding space, adapting to local deformations in medical images. Additionally, we introduce a Hierarchical Feature Consistency Loss to guide coarse-to-fine feature matching and improve anatomical alignment. Extensive experiments demonstrate that SAMIR significantly outperforms state-of-the-art methods on benchmark datasets for both intra-subject cardiac image registration and inter-subject abdomen CT image registration, achieving performance improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code will be publicly available on GitHub following the acceptance of this paper. </p>
<blockquote>
<p>å›¾åƒé…å‡†æ˜¯åŒ»å­¦å›¾åƒåˆ†æä¸­çš„åŸºæœ¬ä»»åŠ¡ã€‚å˜å½¢é€šå¸¸ä¸ç»„ç»‡çš„å½¢æ€ç‰¹å¾å¯†åˆ‡ç›¸å…³ï¼Œå› æ­¤å‡†ç¡®çš„ç‰¹å¾æå–è‡³å…³é‡è¦ã€‚æœ€è¿‘å‡ºç°çš„å¼±ç›‘ç£æ–¹æ³•é€šè¿‡èå…¥è§£å‰–å­¦å…ˆéªŒï¼ˆå¦‚åˆ†å‰²æ©è†œæˆ–æ ‡è®°ç‚¹ï¼‰æ¥æ”¹å–„é…å‡†æ•ˆæœï¼Œæ— è®ºæ˜¯ä½œä¸ºè¾“å…¥è¿˜æ˜¯ç”¨äºæŸå¤±å‡½æ•°ã€‚ç„¶è€Œï¼Œæ­¤ç±»å¼±æ ‡ç­¾é€šå¸¸éš¾ä»¥è·å–ï¼Œä»è€Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚å—è§†è§‰åŸºç¡€æ¨¡å‹å¼ºå¤§è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›çš„å½±å“ï¼Œæœ¬æ–‡ä»‹ç»äº†SAMIRï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„åŒ»å­¦å›¾åƒé…å‡†æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨â€œä»»æ„åˆ†å‰²æ¨¡å‹â€ï¼ˆSAMï¼‰å¢å¼ºç‰¹å¾æå–ã€‚SAMåœ¨å¤§è§„æ¨¡è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¯å­¦ä¹ ç¨³å¥çš„é€šç”¨è§†è§‰è¡¨ç¤ºã€‚æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨åŸå§‹è¾“å…¥å›¾åƒï¼Œè€Œæ˜¯è®¾è®¡äº†ä¸€ä¸ªç‰¹å®šä»»åŠ¡çš„é€‚åº”ç®¡é“ï¼Œä½¿ç”¨SAMçš„å›¾åƒç¼–ç å™¨æ¥æå–ç»“æ„æ„ŸçŸ¥ç‰¹å¾åµŒå…¥ï¼Œä»è€Œæ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿè§£å‰–ä¸€è‡´æ€§å’Œå˜å½¢æ¨¡å¼ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„3Då¤´éƒ¨ï¼Œåœ¨åµŒå…¥ç©ºé—´å†…ç»†åŒ–ç‰¹å¾ï¼Œä»¥é€‚åº”åŒ»å­¦å›¾åƒä¸­çš„å±€éƒ¨å˜å½¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åˆ†å±‚ç‰¹å¾ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥å¼•å¯¼ä»ç²—ç³™åˆ°ç²¾ç»†çš„ç‰¹å¾åŒ¹é…å¹¶æ”¹å–„è§£å‰–å­¦å¯¹é½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼ŒSAMIRåœ¨å—è¯•è€…å†…éƒ¨å¿ƒè„å›¾åƒé…å‡†å’Œå—è¯•è€…ä¹‹é—´è…¹éƒ¨CTå›¾åƒé…å‡†æ–¹é¢éƒ½æ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œåœ¨ACDCä¸Šå®ç°äº†2.68%çš„æ€§èƒ½æå‡ï¼Œåœ¨è…¹éƒ¨æ•°æ®é›†ä¸Šå®ç°äº†6.44%çš„æ€§èƒ½æå‡ã€‚è®ºæ–‡è¢«æ¥å—åï¼Œæºä»£ç å°†åœ¨GitHubä¸Šå…¬å¼€æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13629v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åŒ»å­¦å›¾åƒæ³¨å†Œæ¡†æ¶SAMIRï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒåœ¨å¤§å‹è‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šçš„Segment Anything Modelï¼ˆSAMï¼‰å¢å¼ºç‰¹å¾æå–ã€‚é€šè¿‡è®¾è®¡ä»»åŠ¡ç‰¹å®šçš„é€‚åº”ç®¡é“å’Œ3Då¤´ï¼ŒSAMIRèƒ½æ›´å‡†ç¡®åœ°å»ºæ¨¡è§£å‰–ç»“æ„çš„ä¸€è‡´æ€§å’Œå˜å½¢æ¨¡å¼ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†åˆ†å±‚ç‰¹å¾ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥æŒ‡å¯¼ç²—åˆ°ç»†çš„ç‰¹å¾åŒ¹é…ï¼Œæé«˜è§£å‰–å¯¹é½ã€‚å®éªŒè¡¨æ˜ï¼ŒSAMIRåœ¨å¿ƒè„å›¾åƒæ³¨å†Œçš„åŸºå‡†æ•°æ®é›†ä¸Šæ¯”æœ€æ–°æŠ€æœ¯é¢†å…ˆäº†é«˜è¾¾2.68%ï¼Œåœ¨è…¹éƒ¨CTå›¾åƒæ³¨å†Œçš„åŸºå‡†æ•°æ®é›†ä¸Šé¢†å…ˆäº†é«˜è¾¾6.44%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒæ³¨å†Œä¸­ï¼Œç‰¹å¾æå–çš„é‡è¦æ€§åœ¨äºå…¶ä¸ç»„ç»‡å½¢æ€çš„ç´§å¯†å…³è”ã€‚</li>
<li>é¢„è®­ç»ƒçš„Segment Anything Modelï¼ˆSAMï¼‰ç”¨äºå¢å¼ºåŒ»å­¦å›¾åƒçš„ç‰¹å¾æå–ã€‚</li>
<li>SAMIRæ¡†æ¶é€šè¿‡ä»»åŠ¡ç‰¹å®šé€‚åº”ç®¡é“å’Œ3Då¤´è®¾è®¡ï¼Œå®ç°æ›´å‡†ç¡®çš„ç»“æ„æ„ŸçŸ¥ç‰¹å¾åµŒå…¥æå–ã€‚</li>
<li>å¼•å…¥åˆ†å±‚ç‰¹å¾ä¸€è‡´æ€§æŸå¤±ä»¥æ”¹å–„ç²—åˆ°ç»†çš„ç‰¹å¾åŒ¹é…å’Œè§£å‰–å¯¹é½ã€‚</li>
<li>SAMIRåœ¨å¿ƒè„å’Œè…¹éƒ¨CTå›¾åƒæ³¨å†Œçš„åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>SAMIRæ¡†æ¶æºä»£ç å°†åœ¨è®ºæ–‡è¢«æ¥å—åå…¬å¼€åœ¨GitHubä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13629">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Cross-Distribution-Diffusion-Priors-Driven-Iterative-Reconstruction-for-Sparse-View-CT"><a href="#Cross-Distribution-Diffusion-Priors-Driven-Iterative-Reconstruction-for-Sparse-View-CT" class="headerlink" title="Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for   Sparse-View CT"></a>Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for   Sparse-View CT</h2><p><strong>Authors:Haodong Li, Shuo Han, Haiyang Mao, Yu Shi, Changsheng Fang, Jianjia Zhang, Weiwen Wu, Hengyong Yu</strong></p>
<p>Sparse-View CT (SVCT) reconstruction enhances temporal resolution and reduces radiation dose, yet its clinical use is hindered by artifacts due to view reduction and domain shifts from scanner, protocol, or anatomical variations, leading to performance degradation in out-of-distribution (OOD) scenarios. In this work, we propose a Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction (CDPIR) framework to tackle the OOD problem in SVCT. CDPIR integrates cross-distribution diffusion priors, derived from a Scalable Interpolant Transformer (SiT), with model-based iterative reconstruction methods. Specifically, we train a SiT backbone, an extension of the Diffusion Transformer (DiT) architecture, to establish a unified stochastic interpolant framework, leveraging Classifier-Free Guidance (CFG) across multiple datasets. By randomly dropping the conditioning with a null embedding during training, the model learns both domain-specific and domain-invariant priors, enhancing generalizability. During sampling, the globally sensitive transformer-based diffusion model exploits the cross-distribution prior within the unified stochastic interpolant framework, enabling flexible and stable control over multi-distribution-to-noise interpolation paths and decoupled sampling strategies, thereby improving adaptation to OOD reconstruction. By alternating between data fidelity and sampling updates, our model achieves state-of-the-art performance with superior detail preservation in SVCT reconstructions. Extensive experiments demonstrate that CDPIR significantly outperforms existing approaches, particularly under OOD conditions, highlighting its robustness and potential clinical value in challenging imaging scenarios. </p>
<blockquote>
<p>ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰é‡å»ºæé«˜äº†æ—¶é—´åˆ†è¾¨ç‡å¹¶é™ä½äº†è¾å°„å‰‚é‡ï¼Œä½†å…¶ä¸´åºŠåº”ç”¨å—åˆ°è§†å›¾å‡å°‘å’Œæ¥è‡ªæ‰«æä»ªã€åè®®æˆ–è§£å‰–ç»“æ„å˜åŒ–æ‰€å¯¼è‡´çš„åŸŸåç§»æ‰€äº§ç”Ÿçš„ä¼ªå½±çš„é˜»ç¢ï¼Œè¿™å¯¼è‡´åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰åœºæ™¯ä¸­æ€§èƒ½ä¸‹é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒé©±åŠ¨è¿­ä»£é‡å»ºï¼ˆCDPIRï¼‰æ¡†æ¶ï¼Œä»¥è§£å†³SVCTä¸­çš„OODé—®é¢˜ã€‚CDPIRå°†è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸åŸºäºæ¨¡å‹çš„è¿­ä»£é‡å»ºæ–¹æ³•ç›¸ç»“åˆï¼Œè¿™äº›å…ˆéªŒæ˜¯ç”±å¯æ‰©å±•æ’å€¼è½¬æ¢å™¨ï¼ˆSiTï¼‰å¾—å‡ºçš„ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªSiTéª¨å¹²ç½‘ï¼Œè¿™æ˜¯æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„çš„æ‰©å±•ï¼Œä»¥å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶ï¼Œåˆ©ç”¨å¤šä¸ªæ•°æ®é›†ä¹‹é—´çš„æ— åˆ†ç±»æŒ‡å¯¼ï¼ˆCFGï¼‰ã€‚é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒç©ºåµŒå…¥ä½œä¸ºæ¡ä»¶ï¼Œæ¨¡å‹å­¦ä¼šäº†ç‰¹å®šé¢†åŸŸå’Œè·¨é¢†åŸŸçš„å…ˆéªŒçŸ¥è¯†ï¼Œå¢å¼ºäº†å…¶é€šç”¨æ€§ã€‚åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œå…¨å±€æ•æ„Ÿæ€§çš„åŸºäºå˜å‹å™¨çš„æ‰©æ•£æ¨¡å‹åœ¨ç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶å†…åˆ©ç”¨è·¨åˆ†å¸ƒå…ˆéªŒï¼Œå®ç°å¯¹å¤šåˆ†å¸ƒåˆ°å™ªå£°æ’å€¼è·¯å¾„å’Œè§£è€¦é‡‡æ ·ç­–ç•¥çš„çµæ´»ç¨³å®šæ§åˆ¶ï¼Œä»è€Œæé«˜äº†å¯¹OODé‡å»ºçš„é€‚åº”æ€§ã€‚é€šè¿‡æ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°ä¹‹é—´çš„äº¤æ›¿ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨SVCTé‡å»ºä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å‡ºè‰²åœ°ä¿ç•™äº†ç»†èŠ‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCDPIRæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨OODæ¡ä»¶ä¸‹ï¼Œçªæ˜¾å…¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆåƒåœºæ™¯ä¸­çš„ç¨³å¥æ€§å’Œæ½œåœ¨çš„ä¸´åºŠä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13576v1">PDF</a> 11 pages, 8 figures, under reviewing of IEEE TMI</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºCDPIRçš„è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒé©±åŠ¨è¿­ä»£é‡å»ºæ¡†æ¶ï¼Œä»¥è§£å†³ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰ä¸­çš„è·¨åˆ†å¸ƒé—®é¢˜ã€‚CDPIRç»“åˆäº†æ¥è‡ªå¯æ‰©å±•æ’å€¼å˜æ¢å™¨ï¼ˆSiTï¼‰çš„è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸æ¨¡å‹é©±åŠ¨çš„è¿­ä»£é‡å»ºæ–¹æ³•ã€‚é€šè¿‡è®­ç»ƒSiTéª¨å¹²â€”â€”ä¸€ä¸ªåŸºäºæ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„çš„æ‰©å±•ï¼Œå»ºç«‹ç»Ÿä¸€éšæœºæ’å€¼æ¡†æ¶ï¼Œåˆ©ç”¨å¤šä¸ªæ•°æ®é›†çš„æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ã€‚æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡éšæœºä¸¢å¼ƒæ¡ä»¶å¹¶ä½¿ç”¨ç©ºåµŒå…¥ï¼Œå­¦ä¹ ç‰¹å®šé¢†åŸŸå’Œè·¨é¢†åŸŸçš„å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚é‡‡æ ·æ—¶ï¼ŒåŸºäºå…¨å±€æ•æ„Ÿå˜æ¢çš„æ‰©æ•£æ¨¡å‹åœ¨ç»Ÿä¸€éšæœºæ’å€¼æ¡†æ¶å†…åˆ©ç”¨è·¨åˆ†å¸ƒå…ˆéªŒï¼Œå®ç°å¤šåˆ†å¸ƒåˆ°å™ªå£°æ’å€¼è·¯å¾„çš„çµæ´»ç¨³å®šæ§åˆ¶å’Œè§£è€¦é‡‡æ ·ç­–ç•¥ï¼Œé€‚åº”è·¨åˆ†å¸ƒé‡å»ºã€‚é€šè¿‡äº¤æ›¿è¿›è¡Œæ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨SVCTé‡å»ºä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨ç»†èŠ‚ä¿ç•™æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CDPIRæ¡†æ¶è¢«æå‡ºä»¥è§£å†³ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰ä¸­çš„è·¨åˆ†å¸ƒé—®é¢˜ã€‚</li>
<li>è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸æ¨¡å‹é©±åŠ¨çš„è¿­ä»£é‡å»ºæ–¹æ³•çš„ç»“åˆæé«˜äº†SVCTçš„æ€§èƒ½ã€‚</li>
<li>SiTéª¨å¹²çš„å»ºç«‹ç»“åˆäº†æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„ï¼Œå¹¶å¼•å…¥äº†æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å­¦ä¹ ç‰¹å®šé¢†åŸŸå’Œè·¨é¢†åŸŸçš„å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹åˆ©ç”¨è·¨åˆ†å¸ƒå…ˆéªŒå®ç°çµæ´»ç¨³å®šçš„æ’å€¼è·¯å¾„å’Œé‡‡æ ·ç­–ç•¥ã€‚</li>
<li>CDPIRæ¡†æ¶é€šè¿‡äº¤æ›¿è¿›è¡Œæ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°ï¼Œå®ç°äº†SVCTé‡å»ºä¸­çš„æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13576">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13576v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13576v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13576v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Semantic-3D-Reconstructions-with-SLAM-for-Central-Airway-Obstruction"><a href="#Semantic-3D-Reconstructions-with-SLAM-for-Central-Airway-Obstruction" class="headerlink" title="Semantic 3D Reconstructions with SLAM for Central Airway Obstruction"></a>Semantic 3D Reconstructions with SLAM for Central Airway Obstruction</h2><p><strong>Authors:Ayberk Acar, Fangjie Li, Hao Li, Lidia Al-Zogbi, Kanyifeechukwu Jane Oguine, Susheela Sharma Stern, Jesse F. dâ€™Almeida, Robert J. Webster III, Ipek Oguz, Jie Ying Wu</strong></p>
<p>Central airway obstruction (CAO) is a life-threatening condition with increasing incidence, caused by tumors in and outside of the airway. Traditional treatment methods such as bronchoscopy and electrocautery can be used to remove the tumor completely; however, these methods carry a high risk of complications. Recent advances allow robotic interventions with lesser risk. The combination of robot interventions with scene understanding and mapping also opens up the possibilities for automation. We present a novel pipeline that enables real-time, semantically informed 3D reconstructions of the central airway using monocular endoscopic video.   Our approach combines DROID-SLAM with a segmentation model trained to identify obstructive tissues. The SLAM module reconstructs the 3D geometry of the airway in real time, while the segmentation masks guide the annotation of obstruction regions within the reconstructed point cloud. To validate our pipeline, we evaluate the reconstruction quality using ex vivo models.   Qualitative and quantitative results show high similarity between ground truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By integrating segmentation directly into the SLAM workflow, our system produces annotated 3D maps that highlight clinically relevant regions in real time. High-speed capabilities of the pipeline allows quicker reconstructions compared to previous work, reflecting the surgical scene more accurately.   To the best of our knowledge, this is the first work to integrate semantic segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our framework is modular and can generalize to other anatomies or procedures with minimal changes, offering a promising step toward autonomous robotic interventions. </p>
<blockquote>
<p>ä¸­å¤®æ°”é“æ¢—é˜»ï¼ˆCAOï¼‰æ˜¯ä¸€ç§ç”Ÿå‘½å¨èƒæ€§ç–¾ç—…ï¼Œå‘ç—…ç‡ä¸æ–­ä¸Šå‡ï¼Œç”±æ°”é“å†…å¤–è‚¿ç˜¤å¼•èµ·ã€‚ä¼ ç»Ÿæ²»ç–—æ–¹æ³•å¦‚æ”¯æ°”ç®¡é•œæ£€å’Œç”µçƒ™æœ¯å¯å®Œå…¨åˆ‡é™¤è‚¿ç˜¤ï¼›ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¹¶å‘ç—‡é£é™©è¾ƒé«˜ã€‚æœ€è¿‘çš„è¿›å±•ä½¿å¾—æœºå™¨äººå¹²é¢„çš„é£é™©é™ä½ã€‚æœºå™¨äººå¹²é¢„ä¸åœºæ™¯ç†è§£å’Œæ˜ å°„çš„ç»“åˆä¹Ÿä¸ºè‡ªåŠ¨åŒ–æ‰“å¼€äº†å¯èƒ½æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹ç®¡é“ï¼Œèƒ½å¤Ÿå®ç°ä½¿ç”¨å•çœ¼å†…çª¥é•œè§†é¢‘è¿›è¡Œä¸­å¤®æ°”é“çš„å®æ—¶ã€è¯­ä¹‰ä¿¡æ¯3Dé‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†DROID-SLAMå’Œä¸€ä¸ªç»è¿‡è®­ç»ƒç”¨äºè¯†åˆ«é˜»å¡æ€§ç»„ç»‡çš„åˆ†å‰²æ¨¡å‹ã€‚SLAMæ¨¡å—å®æ—¶é‡å»ºæ°”é“çš„3Då‡ ä½•ç»“æ„ï¼Œè€Œåˆ†å‰²æ©è†œå¼•å¯¼é‡å»ºç‚¹äº‘ä¸­æ¢—é˜»åŒºåŸŸçš„æ³¨é‡Šã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„ç®¡é“ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¦»ä½“æ¨¡å‹è¯„ä¼°é‡å»ºè´¨é‡ã€‚å®šæ€§å’Œå®šé‡ç»“æœè¡¨æ˜ï¼Œåœ°é¢çœŸå®CTæ‰«æå’Œ3Dé‡å»ºä¹‹é—´å…·æœ‰é«˜åº¦ç›¸ä¼¼æ€§ï¼ˆ0.62æ¯«ç±³Chamferè·ç¦»ï¼‰ã€‚é€šè¿‡å°†åˆ†å‰²ç›´æ¥é›†æˆåˆ°SLAMå·¥ä½œæµç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿäº§ç”Ÿæ³¨é‡Šçš„3Dåœ°å›¾ï¼Œå¯å®æ—¶çªå‡ºæ˜¾ç¤ºä¸´åºŠä¸Šç›¸å…³çš„åŒºåŸŸã€‚ç®¡é“çš„é«˜é€Ÿèƒ½åŠ›å¯å®ç°ä¸å…ˆå‰å·¥ä½œç›¸æ¯”æ›´å¿«çš„é‡å»ºï¼Œæ›´å‡†ç¡®åœ°åæ˜ æ‰‹æœ¯åœºæ™¯ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†è¯­ä¹‰åˆ†å‰²ä¸å®æ—¶å•çœ¼SLAMç›¸ç»“åˆç”¨äºå†…çª¥é•œCAOåœºæ™¯çš„å·¥ä½œã€‚æˆ‘ä»¬çš„æ¡†æ¶æ˜¯æ¨¡å—åŒ–çš„ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æœ€å°çš„æ›´æ”¹æ¦‚æ‹¬åˆ°å…¶ä»–è§£å‰–ç»“æ„æˆ–ç¨‹åºï¼Œæ˜¯æœç€è‡ªä¸»æœºå™¨äººå¹²é¢„çš„æœ‰å¸Œæœ›çš„ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13541v1">PDF</a> 5 pages, 2 figures, 1 table</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå•ç›®å†…çª¥é•œè§†é¢‘è¿›è¡Œä¸­å¤®æ°”é“å®æ—¶ã€è¯­ä¹‰ä¿¡æ¯ä¸°å¯Œçš„ä¸‰ç»´é‡å»ºçš„æ–°å‹ç®¡é“ã€‚è¯¥ç®¡é“ç»“åˆäº†DROID-SLAMå’Œä¸€ä¸ªç”¨äºè¯†åˆ«é˜»å¡æ€§ç»„ç»‡çš„åˆ†å‰²æ¨¡å‹ï¼Œå®ç°äº†æ°”é“çš„å®æ—¶ä¸‰ç»´å‡ ä½•é‡å»ºï¼Œå¹¶é€šè¿‡åˆ†å‰²æ©è†œæŒ‡å¯¼é˜»å¡åŒºåŸŸçš„æ ‡æ³¨ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œè¯¥ç®¡é“é‡å»ºç»“æœä¸çœŸå®CTæ‰«æé«˜åº¦ç›¸ä¼¼ã€‚æ­¤å¤–ï¼Œè¯¥ç®¡é“è¿˜å…·æœ‰æ¨¡å—åŒ–ç‰¹ç‚¹ï¼Œå¯å¹¿æ³›åº”ç”¨äºå…¶ä»–è§£å‰–ç»“æ„æˆ–æ‰‹æœ¯åœºæ™¯ï¼Œä¸ºè‡ªä¸»æœºå™¨äººå¹²é¢„æä¾›äº†æœ‰å‰é€”çš„ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸­å¤®æ°”é“é˜»å¡ï¼ˆCAOï¼‰æ˜¯å¨èƒç”Ÿå‘½çš„ç–¾ç—…ï¼Œå…¶å‘ç—…ç‡æ­£åœ¨ä¸Šå‡ï¼Œé€šå¸¸ç”±æ°”é“å†…å¤–è‚¿ç˜¤å¼•èµ·ã€‚</li>
<li>ä¼ ç»Ÿæ²»ç–—æ–¹æ³•å¦‚æ”¯æ°”ç®¡é•œå’Œç”µçƒ™æœ¯å¯ä»¥å®Œå…¨å»é™¤è‚¿ç˜¤ï¼Œä½†å¹¶å‘ç—‡é£é™©è¾ƒé«˜ã€‚</li>
<li>æ–°å‹æœºå™¨äººå¹²é¢„æŠ€æœ¯é£é™©è¾ƒä½ï¼Œå¹¶ä¸åœºæ™¯ç†è§£å’Œæ˜ å°„ç»“åˆï¼Œä¸ºè‡ªåŠ¨åŒ–æä¾›äº†å¯èƒ½æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå•ç›®å†…çª¥é•œè§†é¢‘è¿›è¡Œä¸­å¤®æ°”é“å®æ—¶ä¸‰ç»´é‡å»ºçš„ç®¡é“ï¼Œç»“åˆDROID-SLAMå’Œåˆ†å‰²æ¨¡å‹å®ç°ç²¾å‡†é‡å»ºã€‚</li>
<li>é‡å»ºç»“æœä¸çœŸå®CTæ‰«æé«˜åº¦ç›¸ä¼¼ï¼Œå®šé‡è¯„ä¼°æ˜¾ç¤ºChamferè·ç¦»ä¸º0.62æ¯«ç±³ã€‚</li>
<li>è¯¥ç®¡é“é€šè¿‡å°†åˆ†å‰²ç›´æ¥é›†æˆåˆ°SLAMå·¥ä½œæµç¨‹ä¸­ï¼Œäº§ç”Ÿæ³¨é‡Šçš„ä¸‰ç»´åœ°å›¾ï¼Œå®æ—¶çªå‡ºæ˜¾ç¤ºä¸´åºŠç›¸å…³åŒºåŸŸã€‚</li>
<li>ç®¡é“çš„é«˜é€Ÿç‰¹æ€§å…è®¸æ›´å¿«çš„é‡å»ºï¼Œæ›´å‡†ç¡®åœ°åæ˜ æ‰‹æœ¯åœºæ™¯ï¼Œå¹¶ä¸”æ˜¯æ¨¡å—åŒ–çš„ï¼Œå¯è½»æ¾åº”ç”¨äºå…¶ä»–è§£å‰–ç»“æ„æˆ–æ‰‹æœ¯ç¨‹åºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13541">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13541v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13541v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13541v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13541v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="FunKAN-Functional-Kolmogorov-Arnold-Network-for-Medical-Image-Enhancement-and-Segmentation"><a href="#FunKAN-Functional-Kolmogorov-Arnold-Network-for-Medical-Image-Enhancement-and-Segmentation" class="headerlink" title="FunKAN: Functional Kolmogorov-Arnold Network for Medical Image   Enhancement and Segmentation"></a>FunKAN: Functional Kolmogorov-Arnold Network for Medical Image   Enhancement and Segmentation</h2><p><strong>Authors:Maksim Penkin, Andrey Krylov</strong></p>
<p>Medical image enhancement and segmentation are critical yet challenging tasks in modern clinical practice, constrained by artifacts and complex anatomical variations. Traditional deep learning approaches often rely on complex architectures with limited interpretability. While Kolmogorov-Arnold networks offer interpretable solutions, their reliance on flattened feature representations fundamentally disrupts the intrinsic spatial structure of imaging data. To address this issue we propose a Functional Kolmogorov-Arnold Network (FunKAN) â€“ a novel interpretable neural framework, designed specifically for image processing, that formally generalizes the Kolmogorov-Arnold representation theorem onto functional spaces and learns inner functions using Fourier decomposition over the basis Hermite functions. We explore FunKAN on several medical image processing tasks, including Gibbs ringing suppression in magnetic resonance images, benchmarking on IXI dataset. We also propose U-FunKAN as state-of-the-art binary medical segmentation model with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS (histological structures) and CVC-ClinicDB (colonoscopy videos), detecting breast cancer, glands and polyps, respectively. Experiments on those diverse datasets demonstrate that our approach outperforms other KAN-based backbones in both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work bridges the gap between theoretical function approximation and medical image analysis, offering a robust, interpretable solution for clinical applications. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒå¢å¼ºå’Œåˆ†å‰²æ˜¯ç°ä»£ä¸´åºŠå®è·µä¸­æ—¢é‡è¦åˆå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå—åˆ°ä¼ªå½±å’Œå¤æ‚è§£å‰–ç»“æ„å˜åŒ–çš„å½±å“ã€‚ä¼ ç»Ÿçš„æ·±åº¦å­¦ä¹ æ–¹æ³•å¾€å¾€ä¾èµ–äºå…·æœ‰æœ‰é™è§£é‡Šæ€§çš„å¤æ‚æ¶æ„ã€‚å°½ç®¡Kolmogorov-Arnoldç½‘ç»œæä¾›äº†å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆï¼Œä½†å®ƒä»¬å¯¹æ‰å¹³ç‰¹å¾è¡¨ç¤ºçš„ä¾èµ–ä»æ ¹æœ¬ä¸Šç ´åäº†æˆåƒæ•°æ®çš„å†…åœ¨ç©ºé—´ç»“æ„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠŸèƒ½Kolmogorov-Arnoldç½‘ç»œï¼ˆFunKANï¼‰â€”â€”ä¸€ç§ä¸“é—¨ç”¨äºå›¾åƒå¤„ç†çš„å…¨æ–°å¯è§£é‡Šç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œå®ƒæ­£å¼å°†Kolmogorov-Arnoldè¡¨ç¤ºå®šç†æ¨å¹¿åˆ°åŠŸèƒ½ç©ºé—´ï¼Œå¹¶ä½¿ç”¨Hermiteå‡½æ•°çš„åŸºå‡½æ•°çš„å‚…é‡Œå¶åˆ†è§£æ¥å­¦ä¹ å†…éƒ¨å‡½æ•°ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªåŒ»å­¦å›¾åƒå¤„ç†ä»»åŠ¡ä¸Šæ¢ç´¢äº†FunKANï¼ŒåŒ…æ‹¬å¯¹ç£å…±æŒ¯å›¾åƒä¸­çš„GibbsæŒ¯é“ƒè¿›è¡ŒæŠ‘åˆ¶ï¼Œå¹¶åœ¨IXIæ•°æ®é›†ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†U-FunKANï¼Œè¿™æ˜¯æœ€å…ˆè¿›çš„äºŒå…ƒåŒ»å­¦åˆ†å‰²æ¨¡å‹ï¼Œåœ¨ä¸‰ä¸ªåŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼šBUSIï¼ˆè¶…å£°å›¾åƒï¼‰ã€GlaSï¼ˆç»„ç»‡ç»“æ„ï¼‰å’ŒCVC-ClinicDBï¼ˆç»“è‚ é•œæ£€æŸ¥è§†é¢‘ï¼‰ï¼Œåˆ†åˆ«æ£€æµ‹ä¹³è…ºç™Œã€è…ºä½“å’Œå¤šå‘æ€§æ¯è‚‰ã€‚åœ¨è¿™äº›ä¸åŒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒ»å­¦å›¾åƒå¢å¼ºï¼ˆPSNRï¼ŒTVï¼‰å’Œåˆ†å‰²ï¼ˆIoUï¼ŒF1ï¼‰æ–¹é¢éƒ½ä¼˜äºå…¶ä»–KANåŸºç¡€æ–¹æ³•ã€‚æˆ‘ä»¬çš„å·¥ä½œç¼©å°äº†ç†è®ºå‡½æ•°é€¼è¿‘å’ŒåŒ»å­¦å›¾åƒåˆ†æä¹‹é—´çš„å·®è·ï¼Œä¸ºä¸´åºŠåº”ç”¨æä¾›äº†ç¨³å¥ã€å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13508v1">PDF</a> 9 pages, 5 figures, submitted to the Fortieth AAAI Conference on   Artificial Intelligence (AAAI-26)</p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦å›¾åƒå¢å¼ºä¸åˆ†å‰²æ˜¯ç°ä»£ä¸´åºŠå®è·µä¸­é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå—åˆ°ä¼ªå½±å’Œå¤æ‚è§£å‰–ç»“æ„å˜åŒ–çš„å½±å“ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFunctional Kolmogorov-Arnold Networkï¼ˆFunKANï¼‰çš„æ–°å‹ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨åŠŸèƒ½ç©ºé—´ä¸Šæ¨å¹¿äº†Kolmogorov-Arnoldè¡¨ç¤ºå®šç†ï¼Œå¹¶åˆ©ç”¨Hermiteå‡½æ•°çš„å‚…ç«‹å¶åˆ†è§£æ¥å­¦ä¹ å†…åœ¨å‡½æ•°ã€‚è¯¥æ¡†æ¶ç”¨äºç£å…±æŒ¯å›¾åƒä¸­çš„Gibbsä¼ªå½±æŠ‘åˆ¶ç­‰åŒ»å­¦å›¾åƒå¤„ç†ä»»åŠ¡ï¼Œå¹¶åœ¨IXIæ•°æ®é›†ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†U-FunKANä½œä¸ºæœ€å…ˆè¿›çš„äºŒå…ƒåŒ»å­¦åˆ†å‰²æ¨¡å‹ï¼Œå¹¶åœ¨BUSIï¼ˆè¶…å£°å›¾åƒï¼‰ã€GlaSï¼ˆç»„ç»‡ç»“æ„ï¼‰å’ŒCVC-ClinicDBï¼ˆç»“è‚ é•œæ£€æŸ¥è§†é¢‘ï¼‰ä¸‰ä¸ªåŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œåˆ†åˆ«æ£€æµ‹ä¹³è…ºç™Œã€è…ºä½“å’Œå¤šå‘æ€§æ¯è‚‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŒ»å­¦å›¾åƒå¢å¼ºï¼ˆPSNRï¼ŒTVï¼‰å’Œåˆ†å‰²ï¼ˆIoUï¼ŒF1ï¼‰æ–¹é¢ä¼˜äºå…¶ä»–KANåŸºç¡€æ¨¡å‹ã€‚æœ¬æ–‡ç¼©å°äº†ç†è®ºå‡½æ•°é€¼è¿‘ä¸åŒ»å­¦å›¾åƒåˆ†æä¹‹é—´çš„å·®è·ï¼Œä¸ºä¸´åºŠåº”ç”¨æä¾›äº†ç¨³å¥ã€å¯è§£é‡Šçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒå¢å¼ºä¸åˆ†å‰²æ˜¯ä¸´åºŠå®è·µä¸­é‡è¦çš„ä»»åŠ¡ï¼Œé¢ä¸´ä¼ªå½±å’Œå¤æ‚è§£å‰–ç»“æ„å˜åŒ–çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•ä¾èµ–å¤æ‚æ¶æ„ï¼Œè€ŒKolmogorov-Arnoldç½‘ç»œè™½ç„¶å…·æœ‰è§£é‡Šæ€§ï¼Œä½†ä¼šç ´åæˆåƒæ•°æ®çš„å†…åœ¨ç©ºé—´ç»“æ„ã€‚</li>
<li>æå‡ºäº†Functional Kolmogorov-Arnold Network (FunKAN) æ–°å‹ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒå¤„ç†é—®é¢˜ã€‚</li>
<li>FunKANèƒ½å¤Ÿåœ¨ç£å…±æŒ¯å›¾åƒä¸­æŠ‘åˆ¶Gibbsä¼ªå½±ï¼Œå¹¶åœ¨IXIæ•°æ®é›†ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚</li>
<li>U-FunKANä½œä¸ºæœ€å…ˆè¿›çš„äºŒå…ƒåŒ»å­¦åˆ†å‰²æ¨¡å‹æå‡ºï¼Œç”¨äºæ£€æµ‹ä¹³è…ºç™Œã€è…ºä½“å’Œå¤šå‘æ€§æ¯è‚‰ã€‚</li>
<li>U-FunKANåœ¨BUSIã€GlaSå’ŒCVC-ClinicDBä¸‰ä¸ªåŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13508">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13508v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="PREDICT-GBM-Platform-for-Robust-Evaluation-and-Development-of-Individualized-Computational-Tumor-Models-in-Glioblastoma"><a href="#PREDICT-GBM-Platform-for-Robust-Evaluation-and-Development-of-Individualized-Computational-Tumor-Models-in-Glioblastoma" class="headerlink" title="PREDICT-GBM: Platform for Robust Evaluation and Development of   Individualized Computational Tumor Models in Glioblastoma"></a>PREDICT-GBM: Platform for Robust Evaluation and Development of   Individualized Computational Tumor Models in Glioblastoma</h2><p><strong>Authors:L. Zimmer, J. Weidner, M. Balcerak, F. Kofler, I. Ezhov, B. Menze, B. Wiestler</strong></p>
<p>Glioblastoma is the most prevalent primary brain malignancy, distinguished by its highly invasive behavior and exceptionally high rates of recurrence. Conventional radiation therapy, which employs uniform treatment margins, fails to account for patient-specific anatomical and biological factors that critically influence tumor cell migration. To address this limitation, numerous computational models of glioblastoma growth have been developed, enabling generation of tumor cell distribution maps extending beyond radiographically visible regions and thus informing more precise treatment strategies. However, despite encouraging preliminary findings, the clinical adoption of these growth models remains limited. To bridge this translational gap and accelerate both model development and clinical validation, we introduce PREDICT-GBM, a comprehensive integrated pipeline and dataset for modeling and evaluation. This platform enables systematic benchmarking of state-of-the-art tumor growth models using an expert-curated clinical dataset comprising 255 subjects with complete tumor segmentations and tissue characterization maps. Our analysis demonstrates that personalized radiation treatment plans derived from tumor growth predictions achieved superior recurrence coverage compared to conventional uniform margin approaches for two of the evaluated models. This work establishes a robust platform for advancing and systematically evaluating cutting-edge tumor growth modeling approaches, with the ultimate goal of facilitating clinical translation and improving patient outcomes. </p>
<blockquote>
<p>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯æœ€å¸¸è§çš„ä¸»è¦è„‘æ¶æ€§è‚¿ç˜¤ï¼Œå…¶ç‰¹ç‚¹æ˜¯å…·æœ‰é«˜åº¦ä¾µè¢­æ€§å’Œæé«˜çš„å¤å‘ç‡ã€‚ä¼ ç»Ÿçš„æ”¾å°„æ²»ç–—é‡‡ç”¨å‡åŒ€çš„æ²»ç–—è¾¹ç•Œï¼Œå¿½è§†äº†ç‰¹å®šæ‚£è€…çš„è§£å‰–å’Œç”Ÿç‰©å­¦å› ç´ ï¼Œè¿™äº›å› ç´ å¯¹è‚¿ç˜¤ç»†èƒè¿ç§»æœ‰é‡è¦å½±å“ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œå·²ç»å¼€å‘äº†è®¸å¤šèƒ¶è´¨æ¯ç»†èƒç˜¤ç”Ÿé•¿çš„è®¡ç®—æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆè¶…è¶Šæ”¾å°„å­¦å¯è§åŒºåŸŸçš„è‚¿ç˜¤ç»†èƒåˆ†å¸ƒå›¾ï¼Œä»è€Œä¸ºæ›´ç²¾ç¡®çš„æ²»ç–—ç­–ç•¥æä¾›ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå°½ç®¡åˆæ­¥å‘ç°ä»¤äººé¼“èˆï¼Œä½†è¿™äº›ç”Ÿé•¿æ¨¡å‹çš„ä¸´åºŠåº”ç”¨ä»ç„¶æœ‰é™ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€è½¬åŒ–å·®è·å¹¶åŠ é€Ÿæ¨¡å‹å¼€å‘å’Œä¸´åºŠéªŒè¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†PREDICT-GBMï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå»ºæ¨¡å’Œè¯„ä¼°çš„ç»¼åˆé›†æˆç®¡é“å’Œæ•°æ®é›†ã€‚è¯¥å¹³å°ä½¿ç”¨ä¸“å®¶ç¼–åˆ¶çš„ä¸´åºŠæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬255åæ‚£è€…çš„å®Œæ•´è‚¿ç˜¤åˆ†å‰²å’Œç»„ç»‡ç‰¹å¾å›¾ï¼Œèƒ½å¤Ÿå¯¹æœ€å…ˆè¿›çš„è‚¿ç˜¤ç”Ÿé•¿æ¨¡å‹è¿›è¡Œç³»ç»Ÿæ€§çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ ¹æ®è‚¿ç˜¤ç”Ÿé•¿é¢„æµ‹åˆ¶å®šçš„ä¸ªæ€§åŒ–æ”¾å°„æ²»ç–—è®¡åˆ’ï¼Œå¯¹äºæ‰€è¯„ä¼°çš„ä¸¤ä¸ªæ¨¡å‹æ¥è¯´ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå‡åŒ€è¾¹ç•Œæ–¹æ³•å®ç°äº†æ›´é«˜çš„å¤å‘è¦†ç›–ã€‚è¿™é¡¹å·¥ä½œå»ºç«‹äº†ä¸€ä¸ªç¨³å¥çš„å¹³å°ï¼Œç”¨äºæ¨è¿›å’Œç³»ç»Ÿè¯„ä¼°å‰æ²¿çš„è‚¿ç˜¤ç”Ÿé•¿å»ºæ¨¡æ–¹æ³•ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯é€šè¿‡æ”¹å–„ä¸´åºŠç¿»è¯‘å’Œæé«˜æ‚£è€…ç–—æ•ˆæ¥å®ç°çªç ´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13360v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯ä¸€ç§å¸¸è§ä¸”æ˜“äºå¤å‘çš„åŸå‘æ€§è„‘æ¶æ€§è‚¿ç˜¤ã€‚ä¼ ç»Ÿçš„æ”¾å°„æ²»ç–—æ— æ³•è€ƒè™‘åˆ°æ‚£è€…ç‰¹å®šçš„è§£å‰–å’Œç”Ÿç‰©å­¦å› ç´ ï¼Œå½±å“æ²»ç–—æ•ˆæœã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå·²ç»å¼€å‘äº†è®¸å¤šèƒ¶è´¨æ¯ç»†èƒç˜¤ç”Ÿé•¿çš„è®¡ç®—æ¨¡å‹ï¼Œä»¥ç”Ÿæˆè‚¿ç˜¤ç»†èƒçš„åˆ†å¸ƒå›¾å¹¶é¢„æµ‹è‚¿ç˜¤ç”Ÿé•¿ï¼Œä»è€Œä¸ºæ›´ç²¾ç¡®çš„æ²»ç–—ç­–ç•¥æä¾›ä¾æ®ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„ä¸´åºŠåº”ç”¨ä»ç„¶æœ‰é™ã€‚ä¸ºäº†ç¼©å°å·®è·å¹¶åŠ é€Ÿæ¨¡å‹å¼€å‘å’Œä¸´åºŠéªŒè¯ï¼Œå¼•å…¥äº†ä¸€ä¸ªåä¸ºPREDICT-GBMçš„ç»¼åˆç®¡é“å’Œæ•°æ®é›†ã€‚æ­¤å¹³å°èƒ½å¤Ÿç³»ç»Ÿåœ°è¯„ä¼°æœ€å…ˆè¿›çš„è‚¿ç˜¤ç”Ÿé•¿æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨åŒ…å«255åæ‚£è€…çš„ä¸“å®¶åˆ†ç±»ä¸´åºŠæ•°æ®é›†è¿›è¡ŒéªŒè¯ã€‚åˆ†æè¡¨æ˜ï¼ŒåŸºäºè‚¿ç˜¤ç”Ÿé•¿é¢„æµ‹åˆ¶å®šçš„ä¸ªæ€§åŒ–æ”¾å°„æ²»ç–—è®¡åˆ’åœ¨æŸäº›æ¨¡å‹ä¸­å®ç°äº†ä¼˜äºä¼ ç»Ÿå‡åŒ€è¾¹ç•Œæ–¹æ³•çš„å¤å‘è¦†ç›–ç‡ã€‚è¿™ä¸ºæ¨è¿›å’Œç³»ç»Ÿè¯„ä¼°å‰æ²¿çš„è‚¿ç˜¤ç”Ÿé•¿å»ºæ¨¡æ–¹æ³•æä¾›äº†ä¸€ä¸ªç¨³å¥çš„å¹³å°ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯ä¸ºä¸´åºŠç¿»è¯‘å’Œæ”¹å–„æ‚£è€…é¢„åæä¾›ä¾¿åˆ©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯å¸¸è§ä¸”æ˜“å¤å‘çš„åŸå‘æ€§è„‘æ¶æ€§è‚¿ç˜¤ã€‚</li>
<li>ä¼ ç»Ÿæ”¾å°„æ²»ç–—æœªè€ƒè™‘æ‚£è€…ç‰¹å®šçš„è§£å‰–å’Œç”Ÿç‰©å­¦å› ç´ ã€‚</li>
<li>è®¡ç®—æ¨¡å‹ç”¨äºé¢„æµ‹èƒ¶è´¨æ¯ç»†èƒç˜¤çš„ç”Ÿé•¿ï¼Œä»¥æä¾›æ›´ç²¾ç¡®çš„æ²»ç–—ç­–ç•¥ã€‚</li>
<li>PREDICT-GBMå¹³å°æ—¨åœ¨æ¨è¿›å’Œç³»ç»Ÿè¯„ä¼°è‚¿ç˜¤ç”Ÿé•¿å»ºæ¨¡æ–¹æ³•ã€‚</li>
<li>è¯¥å¹³å°ä½¿ç”¨äº†åŒ…å«255åæ‚£è€…çš„ä¸“å®¶åˆ†ç±»ä¸´åºŠæ•°æ®é›†è¿›è¡ŒéªŒè¯ã€‚</li>
<li>åŸºäºè‚¿ç˜¤ç”Ÿé•¿é¢„æµ‹åˆ¶å®šçš„ä¸ªæ€§åŒ–æ”¾å°„æ²»ç–—è®¡åˆ’åœ¨æŸäº›æ¨¡å‹ä¸­æ˜¾ç¤ºå‡ºæ›´é«˜çš„å¤å‘è¦†ç›–ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13360">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13360v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13360v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13360v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Data-Efficient-Fine-Tuning-of-Vision-Language-Models-for-Diagnosis-of-Alzheimerâ€™s-Disease"><a href="#Data-Efficient-Fine-Tuning-of-Vision-Language-Models-for-Diagnosis-of-Alzheimerâ€™s-Disease" class="headerlink" title="Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of   Alzheimerâ€™s Disease"></a>Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of   Alzheimerâ€™s Disease</h2><p><strong>Authors:Fangqi Cheng, Surajit Ray, Xiaochen Yang</strong></p>
<p>Medical vision-language models (Med-VLMs) have shown impressive results in tasks such as report generation and visual question answering, but they still face several limitations. Most notably, they underutilize patient metadata and lack integration of clinical diagnostic knowledge. Moreover, most existing models are typically trained from scratch or fine-tuned on large-scale 2D image-text pairs, requiring extensive computational resources, and their effectiveness on 3D medical imaging is often limited due to the absence of structural information. To address these gaps, we propose a data-efficient fine-tuning pipeline to adapt 3D CT-based Med-VLMs for 3D MRI and demonstrate its application in Alzheimerâ€™s disease (AD) diagnosis. Our system introduces two key innovations. First, we convert structured metadata into synthetic reports, enriching textual input for improved image-text alignment. Second, we add an auxiliary token trained to predict the mini-mental state examination (MMSE) score, a widely used clinical measure of cognitive function that correlates with AD severity. This provides additional supervision for fine-tuning. Applying lightweight prompt tuning to both image and text modalities, our approach achieves state-of-the-art performance on two AD datasets using 1,500 training images, outperforming existing methods fine-tuned on 10,000 images. Code will be released upon publication. </p>
<blockquote>
<p>åŒ»ç–—è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆMed-VLMsï¼‰åœ¨æŠ¥å‘Šç”Ÿæˆå’Œè§†è§‰é—®ç­”ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†å®ƒä»¬ä»ç„¶é¢ä¸´ä¸€äº›å±€é™æ€§ã€‚æœ€æ˜¾è‘—çš„æ˜¯ï¼Œå®ƒä»¬å¯¹ç—…äººå…ƒæ•°æ®çš„åˆ©ç”¨ä¸è¶³ï¼Œä¸”ç¼ºä¹ä¸´åºŠè¯Šæ–­çŸ¥è¯†çš„æ•´åˆã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°ç°æœ‰æ¨¡å‹é€šå¸¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒæˆ–åœ¨å¤§é‡2Då›¾åƒæ–‡æœ¬å¯¹ä¸Šå¾®è°ƒï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œå®ƒä»¬åœ¨3DåŒ»å­¦æˆåƒä¸Šçš„åº”ç”¨æ•ˆæœå¾€å¾€ç”±äºç¼ºå°‘ç»“æ„ä¿¡æ¯è€Œå—é™ã€‚ä¸ºäº†è§£å†³è¿™äº›å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•°æ®é«˜æ•ˆå¾®è°ƒç®¡é“ï¼Œä»¥é€‚åº”åŸºäº3D CTçš„Med-VLMsç”¨äº3D MRIï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰è¯Šæ–­ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ç»“æ„åŒ–å…ƒæ•°æ®è½¬æ¢ä¸ºåˆæˆæŠ¥å‘Šï¼Œä¸°å¯Œæ–‡æœ¬è¾“å…¥ï¼Œä»¥æ”¹è¿›å›¾åƒæ–‡æœ¬å¯¹é½ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªè¾…åŠ©ä»¤ç‰Œï¼Œç”¨äºé¢„æµ‹è¿·ä½ ç²¾ç¥çŠ¶æ€æ£€æŸ¥è¡¨ï¼ˆMMSEï¼‰å¾—åˆ†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¹¿æ³›åº”ç”¨äºä¸´åºŠçš„è®¤çŸ¥åŠŸèƒ½æµ‹é‡è¡¨ï¼Œä¸ADä¸¥é‡ç¨‹åº¦ç›¸å…³ã€‚è¿™ä¸ºå¾®è°ƒæä¾›äº†é¢å¤–çš„ç›‘ç£ã€‚é€šè¿‡å¯¹å›¾åƒå’Œæ–‡æœ¬æ¨¡æ€åº”ç”¨è½»é‡çº§æç¤ºè°ƒæ•´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸¤ä¸ªADæ•°æ®é›†ä¸Šä½¿ç”¨1500å¼ è®­ç»ƒå›¾åƒè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºåœ¨10000å¼ å›¾åƒä¸Šå¾®è°ƒçš„ç°æœ‰æ–¹æ³•ã€‚ä»£ç å°†åœ¨å‘å¸ƒæ—¶å…¬å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.07613v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆMed-VLMsï¼‰åœ¨æŠ¥å‘Šç”Ÿæˆå’Œè§†è§‰é—®ç­”ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†ä»å­˜åœ¨å‡ ä¸ªå±€é™æ€§ã€‚æœ€ä¸»è¦çš„æ˜¯ï¼Œå®ƒä»¬æœªå……åˆ†åˆ©ç”¨æ‚£è€…å…ƒæ•°æ®å¹¶ç¼ºä¹ä¸´åºŠè¯Šæ–­çŸ¥è¯†çš„æ•´åˆã€‚é’ˆå¯¹è¿™äº›ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ•°æ®é«˜æ•ˆçš„å¾®è°ƒç®¡é“ï¼Œä»¥é€‚åº”åŸºäº3D CTçš„Med-VLMsç”¨äº3D MRIï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰è¯Šæ–­ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„ç³»ç»ŸåŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å°†ç»“æ„åŒ–å…ƒæ•°æ®è½¬æ¢ä¸ºåˆæˆæŠ¥å‘Šï¼Œä¸°å¯Œæ–‡æœ¬è¾“å…¥ä»¥æé«˜å›¾åƒæ–‡æœ¬å¯¹é½ï¼›å…¶æ¬¡ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªç”¨äºé¢„æµ‹å¾®å°ç²¾ç¥çŠ¶æ€æ£€æŸ¥ï¼ˆMMSEï¼‰å¾—åˆ†çš„è¾…åŠ©æ ‡è®°ç¬¦å·è¿›è¡Œå¾®è°ƒç›‘ç£ï¼Œä½œä¸ºè¡¡é‡è®¤çŸ¥åŠŸèƒ½çš„å¸¸ç”¨æŒ‡æ ‡ï¼Œå®ƒä¸ADçš„ä¸¥é‡ç¨‹åº¦å¯†åˆ‡ç›¸å…³ã€‚è¿™ç§æ–¹æ³•ä»…åœ¨æ•°åƒä¸ªè®­ç»ƒå›¾åƒä¸Šå®ç°äº†ä¸€é¡¹åº”ç”¨æ–¹é¢çš„æœ€å‰æ²¿æˆæœï¼Œå¯é¢„æµ‹æ›´é«˜çº§çš„å›¾åƒå¤„ç†æŠ€æœ¯è¦æ±‚ç²¾ç»†æ¨ç†çš„æ•°æ®é›†çš„è¡¨ç°ï¼Œè¶…è¶Šåœ¨ç°æœ‰æ–¹æ³•çš„åå€è®­ç»ƒæ•°æ®ä¸Šçš„è¡¨ç°ã€‚è¯¥æ–¹æ³•çš„å®ç°ä»£ç å°†åœ¨å‡ºç‰ˆæ—¶å…¬å¼€å‘å¸ƒã€‚å¯¹äºæ³¨æ„åŠ›æœºåˆ¶å’Œç»“æ„åŒ–çš„å…ƒæ•°æ®çš„ä»·å€¼æœ‰äº†æ›´æ·±å…¥çš„è§è§£ã€‚è¿™ç§ç²¾ç»†è°ƒæ•´çš„è¯­è¨€æ¨¡å‹èƒ½æ›´å‡†ç¡®åœ°è§£é‡Šå’Œç†è§£å¤æ‚çš„åŒ»å­¦å›¾åƒæ•°æ®ï¼Œè¿™å¯¹äºè¯Šæ–­å’ŒåŒ»ç–—å†³ç­–å…·æœ‰è‡³å…³é‡è¦çš„æ„ä¹‰ã€‚å®ƒæä¾›äº†æ›´å¤§çš„å¯èƒ½æ€§ï¼Œå³é€šè¿‡æœºå™¨å­¦ä¹ æ¨¡å‹æ›´ç²¾ç¡®åœ°åˆ†æé˜¿å°”èŒ¨æµ·é»˜ç—…ç­‰ç¥ç»æ€§ç–¾ç—…çš„æ—©æœŸç—‡çŠ¶ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æé«˜äº†å¯¹åŒ»å­¦å›¾åƒä¿¡æ¯çš„ç†è§£å‡†ç¡®æ€§å¹¶å‡å°‘äº†è®­ç»ƒæˆæœ¬ã€‚å› æ­¤å®ƒæœ‰åŠ©äºæ›´æœ‰æ•ˆåœ°åˆ©ç”¨èµ„æºå¹¶æä¾›æ›´å¥½çš„åŒ»ç–—æœåŠ¡ã€‚è¿™å¼€å¯äº†äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦é¢†åŸŸçš„æ–°çš„é‡Œç¨‹ç¢‘ã€‚åŒ»å­¦å›¾åƒç†è§£å’ŒæŠ¥å‘Šç”Ÿæˆç­‰ä»»åŠ¡çš„ç²¾ç¡®åº¦å’Œæ•ˆç‡éƒ½è·å¾—äº†æ˜¾è‘—çš„æå‡å’Œå‰æ™¯æ˜æœ—çš„åº”ç”¨å‘å±•è½¨è¿¹éƒ½æŒ‡æ˜äº†æˆ‘ä»¬çš„è¿›æ­¥å¯¹æœªæ¥ç²¾ç¡®è¯Šæ–­å’Œç›¸å…³ä¸´åºŠåº”ç”¨äº§ç”Ÿçš„å½±å“æ„ä¹‰é‡å¤§å€¼å¾—æœŸå¾…é€šè¿‡å‡è½»å…¶é¢å¯¹çš„å„ç§é™åˆ¶å› ç´ çš„æªæ–½å°†å…¶å®é™…åº”ç”¨å¾—åˆ°è¿›ä¸€æ­¥æ‰©å¤§æ˜¯æˆ‘ä»¬åç»­çš„ç ”ç©¶æ–¹å‘å°†å……åˆ†å‘æŒ¥å‡ºå…¶æ›´å¤§çš„æ½œåŠ›æ¨è¿›åŒ»ç–—ä¿å¥æŠ€æœ¯çš„è¿›æ­¥ä»è€Œä¸ºæœªæ¥çš„æ‚£è€…æä¾›æ›´é«˜æ•ˆçš„æœåŠ¡å‡å°‘æ²»ç–—æˆæœ¬å’Œæé«˜æ²»ç–—æ•ˆç‡ã€‚åŒæ—¶æˆ‘ä»¬è¿˜å°†è‡´åŠ›äºå¼€å‘æ›´åŠ æ™ºèƒ½çš„ç®—æ³•ä»¥åº”å¯¹æœªæ¥å¯èƒ½å‡ºç°çš„æŒ‘æˆ˜å’Œæœºé‡æé«˜è¯Šæ–­çš„å‡†ç¡®æ€§åŒæ—¶ä¹Ÿè¿›ä¸€æ­¥æ‹“å±•å…¶åº”ç”¨èŒƒå›´ä»¥å®ç°æ›´åŠ å¹¿æ³›çš„åŒ»ç–—æœåŠ¡ä»è€Œä¸ºå¹¿å¤§æ‚£è€…å¸¦æ¥å®å®åœ¨åœ¨çš„åˆ©ç›Šè¿™ä¹Ÿæ˜¯æˆ‘ä»¬çš„ç›®æ ‡æ‰€åœ¨ã€‚â€è¿™æ˜¯å¯¹æˆ‘ä»¬æœªæ¥ç ”ç©¶å’Œå·¥ä½œçš„ä¸€ç§å¼ºæœ‰åŠ›çš„é­ç­–ã€‚â€æ¥ä¸‹æ¥æˆ‘å°†æ ¹æ®è¿™äº›ä¿¡æ¯æå–å…³é”®è¦ç‚¹å¹¶è¿›è¡Œç®€æ˜æ‰¼è¦çš„è§£é‡Šä»¥å¸®åŠ©ç†è§£ã€‚è™½ç„¶è¿™ä¸ªè¿‡ç¨‹éå¸¸å¤æ‚éœ€è¦å„ç§æŠ€èƒ½å’ŒçŸ¥è¯†èƒŒæ™¯çŸ¥è¯†çš„æ”¯æ’‘ä½†æˆ‘ä»ç„¶èƒ½å¤Ÿç¡®ä¿åˆ†æå’Œè§£é‡Šçš„å‡†ç¡®æ€§å’Œæ¸…æ™°æ€§ä»¥æ»¡è¶³ä½ çš„éœ€æ±‚å¹¶åŠªåŠ›è¾¾æˆä½ çš„æœŸæœ›ç›®æ ‡ã€‚<strong>Key Takeaways</strong>:</p>
<ol>
<li>Med-VLMsåœ¨åŒ»å­¦å›¾åƒç›¸å…³ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åˆ©ç”¨æ‚£è€…å…ƒæ•°æ®å’Œæ•´åˆä¸´åºŠçŸ¥è¯†æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>æå‡ºçš„å¾®è°ƒç®¡é“é€‚åº”äº†åŸºäº3D CTçš„Med-VLMsç”¨äºå¤„ç†3D MRIæ•°æ®ï¼Œç”¨äºé˜¿å°”èŒ¨æµ·é»˜ç—…çš„è¯Šæ–­ã€‚</li>
<li>ç³»ç»Ÿåˆ›æ–°ç‚¹åŒ…æ‹¬åˆ©ç”¨ç»“æ„åŒ–å…ƒæ•°æ®ç”ŸæˆåˆæˆæŠ¥å‘Šä»¥å¢å¼ºå›¾åƒæ–‡æœ¬å¯¹é½ï¼Œä»¥åŠé€šè¿‡é¢„æµ‹MMSEå¾—åˆ†æä¾›å¾®è°ƒç›‘ç£ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…æ•°æ®é›†ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ï¼Œä½¿ç”¨è¾ƒå°‘çš„è®­ç»ƒå›¾åƒè¶…è¶Šäº†ä½¿ç”¨æ›´å¤šå›¾åƒè¿›è¡Œè®­ç»ƒçš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•æœ‰åŠ©äºæ›´å‡†ç¡®åœ°ç†è§£å’Œè§£é‡ŠåŒ»å­¦å›¾åƒæ•°æ®ï¼Œå¯¹äºç²¾ç¡®è¯Šæ–­å’ŒåŒ»ç–—å†³ç­–è‡³å…³é‡è¦ã€‚</li>
<li>æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬æ‰©å¤§æ¨¡å‹çš„å®é™…åº”ç”¨èŒƒå›´å’Œå¼€å‘æ›´æ™ºèƒ½çš„ç®—æ³•ä»¥æé«˜è¯Šæ–­å‡†ç¡®æ€§åŠæ‹“å±•åº”ç”¨èŒƒå›´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.07613">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.07613v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.07613v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Sample-Aware-Test-Time-Adaptation-for-Medical-Image-to-Image-Translation"><a href="#Sample-Aware-Test-Time-Adaptation-for-Medical-Image-to-Image-Translation" class="headerlink" title="Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation"></a>Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation</h2><p><strong>Authors:Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda</strong></p>
<p>Image-to-image translation has emerged as a powerful technique in medical imaging, enabling tasks such as image denoising and cross-modality conversion. However, it suffers from limitations in handling out-of-distribution samples without causing performance degradation. To address this limitation, we propose a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the translation process based on the characteristics of each test sample. Our method introduces a Reconstruction Module to quantify the domain shift and a Dynamic Adaptation Block that selectively modifies the internal features of a pretrained translation model to mitigate the shift without compromising the performance on in-distribution samples that do not require adaptation. We evaluate our approach on two medical image-to-image translation tasks: low-dose CT denoising and T1 to T2 MRI translation, showing consistent improvements over both the baseline translation model without TTA and prior TTA methods. Our analysis highlights the limitations of the state-of-the-art that uniformly apply the adaptation to both out-of-distribution and in-distribution samples, demonstrating that dynamic, sample-specific adjustment offers a promising path to improve model resilience in real-world scenarios. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/Sample-Aware-TTA/Code">https://github.com/Sample-Aware-TTA/Code</a>. </p>
<blockquote>
<p>å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢æŠ€æœ¯å·²æˆä¸ºåŒ»å­¦æˆåƒä¸­çš„ä¸€é¡¹å¼ºå¤§æŠ€æœ¯ï¼Œèƒ½å¤Ÿå®Œæˆå›¾åƒå»å™ªå’Œè·¨æ¨¡æ€è½¬æ¢ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ƒåœ¨å¤„ç†ç¦»ç¾¤æ ·æœ¬æ—¶å­˜åœ¨å±€é™ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ ¹æ®æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªé‡å»ºæ¨¡å—æ¥é‡åŒ–åŸŸå·®å¼‚å’Œä¸€ä¸ªåŠ¨æ€é€‚åº”å—ï¼Œè¯¥å—æœ‰é€‰æ‹©åœ°ä¿®æ”¹é¢„è®­ç»ƒç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»¥å‡è½»åŸŸå·®å¼‚çš„å½±å“ï¼ŒåŒæ—¶ä¸æŸå®³å¯¹ä¸éœ€è¦é€‚åº”çš„ç¦»ç¾¤æ ·æœ¬çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŒ»å­¦å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼šä½å‰‚é‡CTå»å™ªå’ŒT1åˆ°T2 MRIç¿»è¯‘ï¼Œæ˜¾ç¤ºå‡ºç›¸è¾ƒäºæ²¡æœ‰TTAçš„åŸºçº¿ç¿»è¯‘æ¨¡å‹å’Œå…ˆå‰çš„TTAæ–¹æ³•çš„ä¸€è‡´æ”¹è¿›ã€‚æˆ‘ä»¬çš„åˆ†æå¼ºè°ƒäº†å½“å‰ä¸»æµæŠ€æœ¯çš„å±€é™æ€§ï¼Œå³å¯¹ç¦»ç¾¤æ ·æœ¬å’Œç¦»ç¾¤æ ·æœ¬ç»Ÿä¸€åº”ç”¨é€‚åº”ç­–ç•¥ï¼Œè¡¨æ˜åŠ¨æ€ã€é’ˆå¯¹æ ·æœ¬çš„ç‰¹å®šè°ƒæ•´æ˜¯æé«˜æ¨¡å‹åœ¨ç°å®åœºæ™¯ä¸­çš„ç¨³å¥æ€§çš„æœ‰å‰é€”çš„é€”å¾„ã€‚ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/Sample-Aware-TTA/Code%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Sample-Aware-TTA/Codeè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00766v2">PDF</a> </p>
<p><strong>Summary</strong><br>     åŒ»å­¦å›¾åƒé¢†åŸŸä¸­çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘æŠ€æœ¯è™½å¯å®ç°å›¾åƒå»å™ªå’Œè·¨æ¨¡æ€è½¬æ¢ç­‰ä»»åŠ¡ï¼Œä½†åœ¨å¤„ç†ç¦»ç¾¤æ ·æœ¬æ—¶å­˜åœ¨æ€§èƒ½ä¸‹é™çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–°é¢–çš„Test-Time Adaptationï¼ˆTTAï¼‰æ¡†æ¶ï¼Œå¯åŸºäºæ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ã€‚é€šè¿‡å¼•å…¥é‡å»ºæ¨¡å—æ¥è¡¡é‡åŸŸåç§»ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é€‚é…å—é€‰æ‹©æ€§ä¿®æ”¹é¢„è®­ç»ƒç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»¥å‡è½»åç§»å½±å“ï¼ŒåŒæ—¶ä¸æŸå®³å¯¹ä¸éœ€è¦é€‚é…çš„ç¦»ç¾¤æ ·æœ¬çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒç¿»è¯‘æŠ€æœ¯é¢ä¸´å¤„ç†ç¦»ç¾¤æ ·æœ¬æ—¶çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚</li>
<li>æå‡ºTest-Time Adaptationï¼ˆTTAï¼‰æ¡†æ¶ï¼Œå¯åŠ¨æ€è°ƒæ•´ç¿»è¯‘è¿‡ç¨‹ä»¥é€‚åº”ä¸åŒæµ‹è¯•æ ·æœ¬ã€‚</li>
<li>å¼•å…¥é‡å»ºæ¨¡å—æ¥è¡¡é‡åŸŸåç§»ã€‚</li>
<li>é€šè¿‡åŠ¨æ€é€‚é…å—é€‰æ‹©æ€§ä¿®æ”¹é¢„è®­ç»ƒç¿»è¯‘æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ï¼Œä»¥å‡è½»åç§»å½±å“ã€‚</li>
<li>åœ¨ä½å‰‚é‡CTå»å™ªå’ŒT1åˆ°T2 MRIç¿»è¯‘ä¸¤ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¾ƒåŸºçº¿ç¿»è¯‘æ¨¡å‹å’Œç°æœ‰TTAæ–¹æ³•æœ‰æ‰€æ”¹è¿›ã€‚</li>
<li>åˆ†ææŒ‡å‡ºç»Ÿä¸€é€‚é…ç¦»ç¾¤æ ·æœ¬å’Œç¦»ç¾¤æ ·æœ¬çš„ç°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00766">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2508.00766v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2508.00766v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MEGANet-W-A-Wavelet-Driven-Edge-Guided-Attention-Framework-for-Weak-Boundary-Polyp-Detection"><a href="#MEGANet-W-A-Wavelet-Driven-Edge-Guided-Attention-Framework-for-Weak-Boundary-Polyp-Detection" class="headerlink" title="MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak   Boundary Polyp Detection"></a>MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak   Boundary Polyp Detection</h2><p><strong>Authors:Zhe Yee Tan, Ashwaq Qasem</strong></p>
<p>Colorectal polyp segmentation is critical for early detection of colorectal cancer, yet weak and low contrast boundaries significantly limit automated accuracy. Existing deep models either blur fine edge details or rely on handcrafted filters that perform poorly under variable imaging conditions. We propose MEGANet-W, a Wavelet Driven Edge Guided Attention Network that injects directional, parameter free Haar wavelet edge maps into each decoder stage to recalibrate semantic features. The key novelties of MEGANet-W include a two-level Haar wavelet head for multi-orientation edge extraction; and Wavelet Edge Guided Attention (W-EGA) modules that fuse wavelet cues with boundary and input branches. On five public polyp datasets, MEGANet-W consistently outperforms existing methods, improving mIoU by up to 2.3% and mDice by 1.2%, while introducing no additional learnable parameters. This approach improves reliability in difficult cases and offers a robust solution for medical image segmentation tasks requiring precise boundary detection. </p>
<blockquote>
<p>ç»“è‚ æ¯è‚‰åˆ†å‰²å¯¹ç»“ç›´è‚ ç™Œçš„æ—©æœŸæ£€æµ‹è‡³å…³é‡è¦ï¼Œä½†å¼±è¾¹ç•Œå’Œä½å¯¹æ¯”åº¦è¾¹ç•Œæ˜¾è‘—é™åˆ¶äº†è‡ªåŠ¨åŒ–ç²¾åº¦ã€‚ç°æœ‰çš„æ·±åº¦æ¨¡å‹è¦ä¹ˆæ¨¡ç³Šç²¾ç»†è¾¹ç¼˜ç»†èŠ‚ï¼Œè¦ä¹ˆä¾èµ–äºåœ¨å¯å˜æˆåƒæ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³çš„æ‰‹å·¥è¿‡æ»¤å™¨ã€‚æˆ‘ä»¬æå‡ºäº†MEGANet-Wï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå°æ³¢é©±åŠ¨çš„è¾¹ç¼˜å¼•å¯¼æ³¨æ„åŠ›ç½‘ç»œï¼Œå®ƒå°†æ–¹å‘æ€§ã€æ— å‚æ•°çš„Haarå°æ³¢è¾¹ç¼˜å›¾æ³¨å…¥åˆ°æ¯ä¸ªè§£ç å™¨é˜¶æ®µä»¥é‡æ–°æ ¡å‡†è¯­ä¹‰ç‰¹å¾ã€‚MEGANet-Wçš„ä¸»è¦æ–°é¢–æ€§åŒ…æ‹¬ç”¨äºå¤šæ–¹å‘è¾¹ç¼˜æå–çš„ä¸¤çº§Haarå°æ³¢å¤´ï¼›ä»¥åŠå°æ³¢è¾¹ç¼˜å¼•å¯¼æ³¨æ„åŠ›ï¼ˆW-EGAï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†å°æ³¢çº¿ç´¢ä¸è¾¹ç•Œå’Œè¾“å…¥åˆ†æ”¯èåˆã€‚åœ¨äº”ä¸ªå…¬å…±æ¯è‚‰æ•°æ®é›†ä¸Šï¼ŒMEGANet-Wå§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒmIoUæé«˜æœ€å¤šè¾¾2.3%ï¼ŒmDiceæé«˜1.2%ï¼ŒåŒæ—¶æ²¡æœ‰å¼•å…¥ä»»ä½•é¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚è¯¥æ–¹æ³•åœ¨å›°éš¾æƒ…å†µä¸‹æé«˜äº†å¯é æ€§ï¼Œå¹¶ä¸ºéœ€è¦ç²¾ç¡®è¾¹ç•Œæ£€æµ‹çš„åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02668v4">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒä¸­ç»“è‚ æ¯è‚‰åˆ†å‰²å¯¹äºæ—©æœŸæ£€æµ‹ç»“ç›´è‚ ç™Œè‡³å…³é‡è¦ï¼Œä½†è¾¹ç•Œæ¨¡ç³Šå’Œå¯¹æ¯”åº¦ä½å½±å“è‡ªåŠ¨åŒ–åˆ†å‰²ç²¾åº¦ã€‚ç°æœ‰æ·±åº¦æ¨¡å‹å­˜åœ¨è¾¹ç¼˜ç»†èŠ‚æ¨¡ç³Šæˆ–åœ¨ä¸åŒæˆåƒæ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³çš„é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºMEGANet-Wæ¨¡å‹ï¼Œé€šè¿‡å°æ³¢é©±åŠ¨çš„è¾¹å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶æ¥æ”¹è¿›åˆ†å‰²æ•ˆæœã€‚è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤çº§Haarå°æ³¢å¤´è¿›è¡Œå¤šæ–¹å‘è¾¹ç¼˜æå–ï¼Œä»¥åŠå°æ³¢è¾¹å¼•å¯¼æ³¨æ„åŠ›æ¨¡å—èåˆå°æ³¢çº¿ç´¢ä¸è¾¹ç•Œå’Œè¾“å…¥åˆ†æ”¯ã€‚åœ¨äº”ä¸ªå…¬å…±æ¯è‚‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMEGANet-Wæ˜¾è‘—æé«˜äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œå¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰æé«˜æœ€å¤šè¾¾2.3%ï¼Œå¹³å‡Diceç³»æ•°æé«˜1.2%ï¼Œä¸”æ²¡æœ‰å¢åŠ é¢å¤–çš„å¯å­¦ä¹ å‚æ•°ã€‚æ­¤æ–¹æ³•æé«˜äº†å›°éš¾ç—…ä¾‹çš„å¯é æ€§ï¼Œå¹¶ä¸ºéœ€è¦ç²¾ç¡®è¾¹ç•Œæ£€æµ‹çš„åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡æä¾›äº†ç¨³å¥è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒä¸­ç»“è‚ æ¯è‚‰çš„è‡ªåŠ¨åˆ†å‰²å¯¹æ—©æœŸç»“ç›´è‚ ç™Œæ£€æµ‹è‡³å…³é‡è¦ï¼Œä½†è¾¹ç•Œæ¨¡ç³Šå’Œå¯¹æ¯”åº¦ä½é™åˆ¶äº†è‡ªåŠ¨åŒ–åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚</li>
<li>ç°æœ‰æ·±åº¦æ¨¡å‹åœ¨åº”å¯¹æ¨¡ç³Šè¾¹ç•Œå’Œå¤šå˜æˆåƒæ¡ä»¶æ—¶è¡¨ç°æ¬ ä½³ã€‚</li>
<li>MEGANet-Wæ¨¡å‹é€šè¿‡ç»“åˆå°æ³¢ç†è®ºå’Œè¾¹å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶æ¥æé«˜åŒ»å­¦å›¾åƒåˆ†å‰²çš„ç²¾åº¦å’Œå¯é æ€§ã€‚</li>
<li>MEGANet-Wé‡‡ç”¨ä¸¤çº§Haarå°æ³¢å¤´è¿›è¡Œå¤šæ–¹å‘è¾¹ç¼˜æå–ï¼Œå¢å¼ºæ¨¡å‹å¯¹è¾¹ç¼˜ç»†èŠ‚çš„æ•æ‰èƒ½åŠ›ã€‚</li>
<li>å°æ³¢è¾¹å¼•å¯¼æ³¨æ„åŠ›æ¨¡å—èåˆå°æ³¢çº¿ç´¢ã€è¾¹ç•Œä¿¡æ¯å’Œè¾“å…¥æ•°æ®ï¼Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMEGANet-Wåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ‰€æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02668">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2507.02668v4/page_5_1.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="A-Unified-Benchmark-of-Federated-Learning-with-Kolmogorov-Arnold-Networks-for-Medical-Imaging"><a href="#A-Unified-Benchmark-of-Federated-Learning-with-Kolmogorov-Arnold-Networks-for-Medical-Imaging" class="headerlink" title="A Unified Benchmark of Federated Learning with Kolmogorov-Arnold   Networks for Medical Imaging"></a>A Unified Benchmark of Federated Learning with Kolmogorov-Arnold   Networks for Medical Imaging</h2><p><strong>Authors:Youngjoon Lee, Jinu Gong, Joonhyuk Kang</strong></p>
<p>Federated Learning (FL) enables model training across decentralized devices without sharing raw data, thereby preserving privacy in sensitive domains like healthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN) architectures against traditional MLP across six state-of-the-art FL algorithms on a blood cell classification dataset. Notably, our experiments demonstrate that KAN can effectively replace MLP in federated environments, achieving superior performance with simpler architectures. Furthermore, we analyze the impact of key hyperparameters-grid size and network architecture-on KAN performance under varying degrees of Non-IID data distribution. In addition, our ablation studies reveal that optimizing KAN width while maintaining minimal depth yields the best performance in federated settings. As a result, these findings establish KAN as a promising alternative for privacy-preserving medical imaging applications in distributed healthcare. To the best of our knowledge, this is the first comprehensive benchmark of KAN in FL settings for medical imaging task. </p>
<blockquote>
<p>è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰èƒ½å¤Ÿåœ¨åˆ†æ•£çš„è®¾å¤‡ä¸Šè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ— éœ€å…±äº«åŸå§‹æ•°æ®ï¼Œä»è€Œä¿æŠ¤åŒ»ç–—ç­‰æ•æ„Ÿé¢†åŸŸçš„éšç§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰æ¶æ„ä¸ä¼ ç»Ÿå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åœ¨å…­ç§æœ€å…ˆè¿›çš„è”é‚¦å­¦ä¹ ç®—æ³•ä¸Šçš„è¡¨ç°ï¼Œè¿™äº›ç®—æ³•æ˜¯åŸºäºè¡€ç»†èƒåˆ†ç±»æ•°æ®é›†ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œåœ¨è”é‚¦ç¯å¢ƒä¸­ï¼ŒKANå¯ä»¥æœ‰æ•ˆåœ°æ›¿ä»£MLPï¼Œåœ¨æ¶æ„æ›´ç®€å•çš„æƒ…å†µä¸‹å®ç°å“è¶Šçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†å…³é”®è¶…å‚æ•°â€”â€”ç½‘æ ¼å¤§å°å’Œç½‘ç»œæ¶æ„åœ¨ä¸åŒç¨‹åº¦çš„éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰æ•°æ®åˆ†å¸ƒä¸‹å¯¹KANæ€§èƒ½çš„å½±å“ã€‚å¦å¤–ï¼Œæˆ‘ä»¬çš„æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œåœ¨ä¿æŒæ·±åº¦æœ€å°çš„æƒ…å†µä¸‹ä¼˜åŒ–KANçš„å®½åº¦ï¼Œåœ¨è”é‚¦ç¯å¢ƒä¸­å¯ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚å› æ­¤ï¼Œè¿™äº›å‘ç°è¯æ˜äº†KANåœ¨åˆ†å¸ƒå¼åŒ»ç–—æŠ¤ç†çš„éšç§ä¿æŠ¤åŒ»å­¦å½±åƒåº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸‹å¯¹KANè¿›è¡ŒåŒ»å­¦å½±åƒä»»åŠ¡çš„å…¨é¢åŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19639v2">PDF</a> Accepted to AI&#x2F;ML for Edge&#x2F;Fog Networks Workshop - IEEE GLOBECOM 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºè”é‚¦å­¦ä¹ ï¼ˆFLï¼‰çš„Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰åœ¨è¡€æ¶²ç»†èƒåˆ†ç±»æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç›¸æ¯”ï¼ŒKANåœ¨è”é‚¦ç¯å¢ƒä¸­è¡¨ç°æ›´ä¼˜ï¼Œä¸”æ¶æ„æ›´ç®€å•ã€‚ç ”ç©¶è¿˜åˆ†æäº†å…³é”®è¶…å‚æ•°å¯¹KANæ€§èƒ½çš„å½±å“ï¼Œå¹¶å‘ç°ä¼˜åŒ–KANå®½åº¦åŒæ—¶ä¿æŒæ·±åº¦æœ€å°èƒ½åœ¨è”é‚¦ç¯å¢ƒä¸­è·å¾—æœ€ä½³æ€§èƒ½ã€‚è¿™äº›å‘ç°ä½¿KANæˆä¸ºåˆ†å¸ƒå¼åŒ»ç–—ä¿å¥ä¸­éšç§ä¿æŠ¤åŒ»å­¦å½±åƒåº”ç”¨çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡é’ˆå¯¹åŒ»å­¦æˆåƒä»»åŠ¡åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­å…¨é¢è¯„ä¼°KANã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å…è®¸åœ¨ä¸å…±äº«åŸå§‹æ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œä¿æŠ¤éšç§ã€‚<br>2.Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰åœ¨è¡€æ¶²ç»†èƒåˆ†ç±»æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºä¼ ç»Ÿå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ã€‚</li>
<li>åœ¨è”é‚¦ç¯å¢ƒä¸­ï¼ŒKANæ¶æ„æ›´ç®€å•ï¼Œå¯å®ç°ä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>å…³é”®è¶…å‚æ•°å¦‚ç½‘æ ¼å¤§å°å’Œç½‘ç»œæ¶æ„å¯¹KANæ€§èƒ½æœ‰å½±å“ã€‚</li>
<li>åœ¨éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰æ•°æ®ç¯å¢ƒä¸‹ï¼Œä¼˜åŒ–KANå®½åº¦å¹¶ä¿æŒæ·±åº¦æœ€å°å¯è·å¾—æœ€ä½³æ€§èƒ½ã€‚</li>
<li>KANåœ¨éšç§ä¿æŠ¤çš„åŒ»å­¦å½±åƒåº”ç”¨ä¸­æœ‰æ½œåŠ›æˆä¸ºåˆ†å¸ƒå¼åŒ»ç–—ä¿å¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19639">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2504.19639v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2504.19639v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2504.19639v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2504.19639v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2504.19639v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Y-AR-A-Mixed-Reality-CAD-Tool-for-3D-Wire-Bending"><a href="#Y-AR-A-Mixed-Reality-CAD-Tool-for-3D-Wire-Bending" class="headerlink" title="Y-AR: A Mixed Reality CAD Tool for 3D Wire Bending"></a>Y-AR: A Mixed Reality CAD Tool for 3D Wire Bending</h2><p><strong>Authors:Shuo Feng, Bo Liu,  Yifan,  Shan, Roy Zunder, Wei-Che Lin, Tri Dinh, Harald Haraldsson, Ofer Berman, Thijs Roumen</strong></p>
<p>Wire bending is a technique used in manufacturing to mass-produce items such as clips, mounts, and braces. Recent advances in programmable wire bending have made this process increasingly accessible for custom fabrication. However, CNC wire benders are controlled using Computer Aided Manufacturing (CAM) software, without design tools, making custom designs challenging to produce. We present Y-AR, a Computer Aided Design (CAD) interface for 3D wire bending. Y-AR uses mixed reality to let designers create clips, mounts, and braces to physically connect objects to their surrounding environment. The interface incorporates springs as design primitives which (1) apply forces to hold objects, and (2) counter-act dimensional inaccuracies inherently caused by mid-air modeling and measurement errors in AR. Springs are a natural design element when working with metal wire-bending given its specific material properties. We demonstrate workflows to design and fabricate a range of mechanisms in Y-AR as well as structures made using free-hand design tools. We found that combining gesture-based interaction with fabrication-aware design principles allowed novice users to create functional wire connectors, even when using imprecise XR-based input. In our usability evaluation, all 12 participants successfully designed and fabricated a functional bottle holder using Y-AR. </p>
<blockquote>
<p>å¼¯æ›²é‡‘å±çº¿åˆ¶é€ æ˜¯ä¸€ç§åœ¨åˆ¶é€ ä¸šä¸­ç”¨äºæ‰¹é‡ç”Ÿäº§å¤¹å­ã€æ”¯æ¶å’Œç®çš„æŠ€æœ¯ã€‚éšç€å¯ç¼–ç¨‹å¼¯æ›²é‡‘å±çº¿æŠ€æœ¯çš„æœ€æ–°å‘å±•ï¼Œè¿™ä¸€è¿‡ç¨‹å¯¹äºå®šåˆ¶åˆ¶é€ å˜å¾—è¶Šæ¥è¶Šå®¹æ˜“æ¥è¿‘ã€‚ç„¶è€Œï¼ŒCNCé‡‘å±çº¿å¼¯æ›²æœºæ˜¯é€šè¿‡è®¡ç®—æœºè¾…åŠ©åˆ¶é€ ï¼ˆCAMï¼‰è½¯ä»¶æ§åˆ¶çš„ï¼Œæ²¡æœ‰è®¾è®¡å·¥å…·ï¼Œä½¿å¾—å®šåˆ¶è®¾è®¡çš„ç”Ÿäº§å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºäº†Y-ARï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº3Dé‡‘å±çº¿å¼¯æ›²çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç•Œé¢ã€‚Y-ARä½¿ç”¨æ··åˆç°å®æŠ€æœ¯ï¼Œè®©è®¾è®¡å¸ˆèƒ½å¤Ÿåˆ›å»ºå¤¹å­ã€æ”¯æ¶å’Œç®ï¼Œä»¥å°†ç‰©ä½“ç‰©ç†è¿æ¥åˆ°å…¶å‘¨å›´ç¯å¢ƒã€‚è¯¥ç•Œé¢é‡‡ç”¨å¼¹ç°§ä½œä¸ºè®¾è®¡å…ƒç´ ï¼Œå¼¹ç°§ï¼ˆ1ï¼‰æ–½åŠ åŠ›æ¥å›ºå®šç‰©ä½“ï¼Œï¼ˆ2ï¼‰æŠµæ¶ˆç”±äºç©ºä¸­å»ºæ¨¡å’Œæµ‹é‡è¯¯å·®å›ºæœ‰äº§ç”Ÿçš„å°ºå¯¸è¯¯å·®ã€‚åœ¨ä¸é‡‘å±çº¿å¼¯æ›²ç›¸ç»“åˆå·¥ä½œæ—¶ï¼Œå¼¹ç°§ä½œä¸ºä¸€ç§è‡ªç„¶è®¾è®¡å…ƒç´ å› å…¶ç‰¹å®šçš„ææ–™ç‰¹æ€§è€Œå‘æŒ¥ä½œç”¨ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨Y-ARä¸­è®¾è®¡å’Œåˆ¶ä½œä¸€ç³»åˆ—æœºåˆ¶çš„å·¥ä½œæµç¨‹ï¼Œä»¥åŠä½¿ç”¨è‡ªç”±æ‰‹ç»˜å·¥å…·åˆ¶ä½œçš„ç»“æ„ã€‚æˆ‘ä»¬å‘ç°ï¼Œå°†åŸºäºæ‰‹åŠ¿çš„äº¤äº’ä¸é¢å‘åˆ¶é€ çš„è®¾è®¡åŸåˆ™ç›¸ç»“åˆï¼Œå³ä½¿ä½¿ç”¨ä¸ç²¾ç¡®çš„XRè¾“å…¥ï¼Œæ–°æ‰‹ç”¨æˆ·ä¹Ÿèƒ½åˆ›å»ºå‡ºåŠŸèƒ½æ€§çš„é‡‘å±çº¿è¿æ¥å™¨ã€‚åœ¨æˆ‘ä»¬çš„å¯ç”¨æ€§è¯„ä¼°ä¸­ï¼Œæ‰€æœ‰12åå‚ä¸è€…éƒ½æˆåŠŸä½¿ç”¨Y-ARè®¾è®¡å’Œåˆ¶ä½œäº†ä¸€ä¸ªåŠŸèƒ½æ€§çš„ç“¶æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.23540v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç« ä»‹ç»äº†ç”¨äºåˆ¶é€ ä¸šçš„å¤§è§„æ¨¡ç”Ÿäº§ç‰©å“ï¼ˆå¦‚å¤¹å­ã€æ”¯æ¶å’Œæ’‘æ¶ï¼‰çš„ä¸€ç§å¼¯æ›²é‡‘å±ä¸æŠ€æœ¯â€”â€”Y-ARã€‚è¿‘å¹´æ¥ï¼Œå¯ç¼–ç¨‹çš„é‡‘å±ä¸å¼¯æ›²æŠ€æœ¯è®©è¿™ä¸€å·¥è‰ºå¯¹äºå®šåˆ¶åˆ¶é€ å˜å¾—æ›´å…·å¯è®¿é—®æ€§ã€‚ç„¶è€Œï¼Œæ•°æ§é‡‘å±ä¸å¼¯æ›²å™¨é€šè¿‡è®¡ç®—æœºè¾…åŠ©åˆ¶é€ è½¯ä»¶è¿›è¡Œæ§åˆ¶ï¼Œæ²¡æœ‰è®¾è®¡å·¥å…·ï¼Œå› æ­¤åˆ¶ä½œå®šåˆ¶è®¾è®¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºY-ARçš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ç•Œé¢ï¼Œè¯¥ç•Œé¢ç»“åˆäº†å¢å¼ºç°å®æŠ€æœ¯ï¼Œå…è®¸è®¾è®¡å¸ˆåˆ›å»ºç”¨äºå°†ç‰©ä½“ä¸å…¶å‘¨å›´ç¯å¢ƒè¿æ¥çš„å¤¹å­ã€æ”¯æ¶å’Œæ’‘æ†ã€‚è¯¥ç•Œé¢é‡‡ç”¨å¼¹ç°§ä½œä¸ºè®¾è®¡å…ƒç´ ï¼Œé€šè¿‡å¼¹ç°§åŠ›æ¥å›ºå®šç‰©ä½“å¹¶æŠµæ¶ˆå› ç©ºä¸­å»ºæ¨¡å’Œæµ‹é‡è¯¯å·®é€ æˆçš„å°ºå¯¸è¯¯å·®ã€‚æ­¤å¤–ï¼Œæ–‡ç« å±•ç¤ºäº†åœ¨Y-ARä¸­è¿›è¡Œè®¾è®¡å’Œåˆ¶ä½œçš„ä¸€ç³»åˆ—å·¥ä½œæµç¨‹ï¼Œä»¥åŠä½¿ç”¨è‡ªç”±æ‰‹ç»˜å·¥å…·æ„å»ºçš„ç»“æ„ã€‚æœ€åï¼Œé€šè¿‡å¯ç”¨æ€§è¯„ä¼°å‘ç°ï¼Œç»“åˆäº†åŸºäºæ‰‹åŠ¿çš„äº¤äº’å’Œåˆ¶é€ æ„è¯†çš„è®¾è®¡åŸåˆ™åï¼Œå³ä½¿æ˜¯æ–°æ‰‹ç”¨æˆ·ä¹Ÿèƒ½åˆ›é€ å‡ºå®ç”¨çš„é‡‘å±ä¸è¿æ¥å™¨ã€‚æ‰€æœ‰å‚ä¸è€…éƒ½æˆåŠŸä½¿ç”¨Y-ARè®¾è®¡å’Œåˆ¶ä½œäº†ä¸€ä¸ªå®ç”¨çš„ç“¶æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Y-ARæ˜¯ä¸€ä¸ªç»“åˆäº†å¢å¼ºç°å®æŠ€æœ¯çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ç•Œé¢ï¼Œä¸»è¦ç”¨äºåˆ›å»ºç”¨äºç‰©ä½“è¿æ¥çš„é‡‘å±ä¸äº§å“ï¼ˆå¦‚å¤¹å­ã€æ”¯æ¶å’Œæ’‘æ†ï¼‰ã€‚</li>
<li>è¯¥ç•Œé¢åˆ©ç”¨å¼¹ç°§ä½œä¸ºè®¾è®¡å…ƒç´ ï¼Œåˆ©ç”¨å…¶ç‰©ç†ç‰¹æ€§åº”å¯¹åˆ¶ä½œè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„è¯¯å·®ã€‚</li>
<li>Y-ARå…è®¸è®¾è®¡è€…è¿›è¡Œè‡ªç”±æ‰‹ç»˜è®¾è®¡ï¼Œå¹¶å±•ç¤ºäº†å¤šç§å·¥ä½œæµç¨‹æ¥åˆ›å»ºå„ç§æœºåˆ¶ç»“æ„ã€‚</li>
<li>æ–‡ç« å¼ºè°ƒäº†å¯ç¼–ç¨‹é‡‘å±ä¸å¼¯æ›²æŠ€æœ¯çš„æœ€æ–°è¿›å±•åŠå…¶åœ¨å®šåˆ¶åˆ¶é€ ä¸­çš„åº”ç”¨ã€‚</li>
<li>ç»“åˆæ‰‹åŠ¿äº¤äº’å’Œåˆ¶é€ æ„è¯†çš„è®¾è®¡åŸåˆ™ï¼Œæ–°æ‰‹ç”¨æˆ·ä¹Ÿèƒ½ä½¿ç”¨Y-ARåˆ›å»ºå®ç”¨çš„é‡‘å±ä¸è¿æ¥å™¨ã€‚</li>
<li>Y-ARçš„å¯ç”¨æ€§å¾—åˆ°äº†éªŒè¯ï¼Œæ‰€æœ‰å‚ä¸è€…å‡æˆåŠŸè®¾è®¡å’Œåˆ¶ä½œäº†ä¸€ä¸ªç“¶æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.23540">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.23540v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="DiffGAN-A-Test-Generation-Approach-for-Differential-Testing-of-Deep-Neural-Networks-for-Image-Analysis"><a href="#DiffGAN-A-Test-Generation-Approach-for-Differential-Testing-of-Deep-Neural-Networks-for-Image-Analysis" class="headerlink" title="DiffGAN: A Test Generation Approach for Differential Testing of Deep   Neural Networks for Image Analysis"></a>DiffGAN: A Test Generation Approach for Differential Testing of Deep   Neural Networks for Image Analysis</h2><p><strong>Authors:Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, Ramesh S</strong></p>
<p>Deep Neural Networks (DNNs) are increasingly deployed across applications. However, ensuring their reliability remains a challenge, and in many situations, alternative models with similar functionality and accuracy are available. Traditional accuracy-based evaluations often fail to capture behavioral differences between models, especially with limited test datasets, making it difficult to select or combine models effectively. Differential testing addresses this by generating test inputs that expose discrepancies in DNN model behavior. However, existing approaches face significant limitations: many rely on model internals or are constrained by available seed inputs. To address these challenges, we propose DiffGAN, a black-box test image generation approach for differential testing of DNN models. DiffGAN leverages a Generative Adversarial Network (GAN) and the Non-dominated Sorting Genetic Algorithm II to generate diverse and valid triggering inputs that reveal behavioral discrepancies between models. DiffGAN employs two custom fitness functions, focusing on diversity and divergence, to guide the exploration of the GAN input space and identify discrepancies between modelsâ€™ outputs. By strategically searching this space, DiffGAN generates inputs with specific features that trigger differences in model behavior. DiffGAN is black-box, making it applicable in more situations. We evaluate DiffGAN on eight DNN model pairs trained on widely used image datasets. Our results show DiffGAN significantly outperforms a SOTA baseline, generating four times more triggering inputs, with greater diversity and validity, within the same budget. Additionally, the generated inputs improve the accuracy of a machine learning-based model selection mechanism, which selects the best-performing model based on input characteristics and can serve as a smart output voting mechanism when using alternative models. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨å„ç§åº”ç”¨ä¸­éƒ¨ç½²å¾—è¶Šæ¥è¶Šå¹¿æ³›ã€‚ç„¶è€Œï¼Œç¡®ä¿å®ƒä»¬çš„å¯é æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œè€Œä¸”åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå­˜åœ¨å…·æœ‰ç›¸ä¼¼åŠŸèƒ½å’Œå‡†ç¡®æ€§çš„æ›¿ä»£æ¨¡å‹ã€‚ä¼ ç»Ÿçš„åŸºäºå‡†ç¡®æ€§çš„è¯„ä¼°å¾€å¾€æ— æ³•æ•æ‰æ¨¡å‹ä¹‹é—´çš„è¡Œä¸ºå·®å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é™çš„æµ‹è¯•æ•°æ®é›†ä¸‹ï¼Œè¿™ä½¿å¾—æœ‰æ•ˆé€‰æ‹©æˆ–ç»„åˆæ¨¡å‹å˜å¾—å›°éš¾ã€‚å·®å¼‚æµ‹è¯•é€šè¿‡ç”Ÿæˆæš´éœ²DNNæ¨¡å‹è¡Œä¸ºå·®å¼‚çš„æµ‹è¯•è¾“å…¥æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨é‡å¤§å±€é™æ€§ï¼šè®¸å¤šæ–¹æ³•ä¾èµ–äºæ¨¡å‹å†…éƒ¨ï¼Œæˆ–å—åˆ°å¯ç”¨ç§å­è¾“å…¥çš„çº¦æŸã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DiffGANï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºDNNæ¨¡å‹å·®å¼‚æµ‹è¯•çš„é»‘ç›’æµ‹è¯•å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚DiffGANåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIæ¥ç”Ÿæˆå¤šæ ·ä¸”æœ‰æ•ˆçš„è§¦å‘è¾“å…¥ï¼Œè¿™äº›è¾“å…¥æ­ç¤ºäº†æ¨¡å‹ä¹‹é—´çš„è¡Œä¸ºå·®å¼‚ã€‚DiffGANé‡‡ç”¨ä¸¤ä¸ªè‡ªå®šä¹‰çš„é€‚åº”åº¦å‡½æ•°ï¼Œä¸“æ³¨äºå¤šæ ·æ€§å’Œå‘æ•£æ€§ï¼Œä»¥æŒ‡å¯¼GANè¾“å…¥ç©ºé—´çš„æ¢ç´¢ï¼Œå¹¶è¯†åˆ«æ¨¡å‹è¾“å‡ºä¹‹é—´çš„å·®å¼‚ã€‚é€šè¿‡æœ‰é’ˆå¯¹æ€§åœ°æœç´¢è¿™ä¸ªç©ºé—´ï¼ŒDiffGANç”Ÿæˆå…·æœ‰ç‰¹å®šç‰¹å¾çš„è¾“å…¥ï¼Œè¿™äº›ç‰¹å¾ä¼šå¼•å‘æ¨¡å‹è¡Œä¸ºçš„å·®å¼‚ã€‚DiffGANæ˜¯é»‘ç›’å¼çš„ï¼Œä½¿å…¶é€‚ç”¨äºæ›´å¤šåœºæ™¯ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›ä½¿ç”¨çš„å›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒçš„8å¯¹DNNæ¨¡å‹ä¸Šè¯„ä¼°DiffGANã€‚ç»“æœè¡¨æ˜ï¼ŒDiffGANæ˜¾è‘—ä¼˜äºæœ€æ–°åŸºçº¿ï¼Œåœ¨ç›¸åŒçš„é¢„ç®—ä¸‹ï¼Œç”Ÿæˆäº†è§¦å‘è¾“å…¥çš„æ•°é‡æ˜¯åŸºçº¿æ–¹æ³•çš„å››å€ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¤§çš„å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„è¾“å…¥æé«˜äº†åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹çš„é€‰å‹æœºåˆ¶çš„å‡†ç¡®æ€§ï¼Œè¯¥æœºåˆ¶æ ¹æ®è¾“å…¥ç‰¹æ€§é€‰æ‹©æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ï¼Œå½“ä½¿ç”¨æ›¿ä»£æ¨¡å‹æ—¶ï¼Œå®ƒå¯ä»¥ä½œä¸ºæ™ºèƒ½è¾“å‡ºæŠ•ç¥¨æœºåˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19794v4">PDF</a> Accepted into IEEE Transactions on Software Engineering</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIçš„å·®åˆ†æµ‹è¯•æ–¹æ³•DiffGANï¼Œç”¨äºå¯¹æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨¡å‹è¿›è¡Œé»‘ç›’æµ‹è¯•å›¾åƒç”Ÿæˆã€‚DiffGANæ—¨åœ¨é€šè¿‡ç”Ÿæˆå…·æœ‰ç‰¹å®šç‰¹å¾çš„è¾“å…¥æ¥æ­ç¤ºä¸åŒæ¨¡å‹é—´çš„è¡Œä¸ºå·®å¼‚ï¼Œé€‚ç”¨äºå¤šç§åœºæ™¯ä¸‹çš„æ¨¡å‹å¯é æ€§éªŒè¯ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºå½“å‰æœ€ä½³å®è·µæ–¹æ³•ï¼ŒDiffGANæ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼Œèƒ½ç”Ÿæˆæ›´ä¸°å¯Œå¤šæ ·çš„è§¦å‘è¾“å…¥ã€‚åŒæ—¶ï¼ŒDiffGANæœ‰åŠ©äºæ›´ç²¾å‡†åœ°é€‰æ‹©å’Œç»„åˆæ¨¡å‹ï¼Œè¿›è€Œä¼˜åŒ–æ¨¡å‹é€‰æ‹©æœºåˆ¶ä¸æ™ºèƒ½è¾“å‡ºæŠ•ç¥¨æœºåˆ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DiffGANæ–¹æ³•æ—¨åœ¨è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹å¯é æ€§çš„éªŒè¯é—®é¢˜ï¼Œé€šè¿‡ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œéæ”¯é…æ’åºé—ä¼ ç®—æ³•IIç”Ÿæˆæµ‹è¯•å›¾åƒã€‚</li>
<li>DiffGANèšç„¦äºæ­ç¤ºæ¨¡å‹é—´è¡Œä¸ºå·®å¼‚ï¼Œåœ¨æœ‰é™çš„æµ‹è¯•æ•°æ®é›†æ¡ä»¶ä¸‹å…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ã€‚</li>
<li>æ–¹æ³•å¯åº”ç”¨äºé»‘ç›’æµ‹è¯•ï¼Œé€‚ç”¨èŒƒå›´æ›´å¹¿ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒDiffGANèƒ½ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„è§¦å‘è¾“å…¥ã€‚</li>
<li>DiffGANèƒ½ä¼˜åŒ–æ¨¡å‹é€‰æ‹©æœºåˆ¶ï¼Œæé«˜æ¨¡å‹æ€§èƒ½è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.19794v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2410.19794v4/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/TTS/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_TTS/2509.14161v1/page_2_1.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  CS-FLEURS A Massively Multilingual and Code-Switched Speech Dataset
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13576v1/page_4_0.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  Noise-Level Diffusion Guidance Well Begun is Half Done
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
