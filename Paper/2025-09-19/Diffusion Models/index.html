<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  Noise-Level Diffusion Guidance Well Begun is Half Done">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13576v1/page_4_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-19-æ›´æ–°"><a href="#2025-09-19-æ›´æ–°" class="headerlink" title="2025-09-19 æ›´æ–°"></a>2025-09-19 æ›´æ–°</h1><h2 id="Noise-Level-Diffusion-Guidance-Well-Begun-is-Half-Done"><a href="#Noise-Level-Diffusion-Guidance-Well-Begun-is-Half-Done" class="headerlink" title="Noise-Level Diffusion Guidance: Well Begun is Half Done"></a>Noise-Level Diffusion Guidance: Well Begun is Half Done</h2><p><strong>Authors:Harvey Mannering, Zhiwu Huang, Adam Prugel-Bennett</strong></p>
<p>Diffusion models have achieved state-of-the-art image generation. However, the random Gaussian noise used to start the diffusion process influences the final output, causing variations in image quality and prompt adherence. Existing noise-level optimization approaches generally rely on extra dataset construction, additional networks, or backpropagation-based optimization, limiting their practicality. In this paper, we propose Noise Level Guidance (NLG), a simple, efficient, and general noise-level optimization approach that refines initial noise by increasing the likelihood of its alignment with general guidance - requiring no additional training data, auxiliary networks, or backpropagation. The proposed NLG approach provides a unified framework generalizable to both conditional and unconditional diffusion models, accommodating various forms of diffusion-level guidance. Extensive experiments on five standard benchmarks demonstrate that our approach enhances output generation quality and input condition adherence. By seamlessly integrating with existing guidance methods while maintaining computational efficiency, our method establishes NLG as a practical and scalable enhancement to diffusion models. Code can be found at <a target="_blank" rel="noopener" href="https://github.com/harveymannering/NoiseLevelGuidance">https://github.com/harveymannering/NoiseLevelGuidance</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å·²ç»è¾¾åˆ°äº†å‰æ²¿æ°´å¹³ã€‚ç„¶è€Œï¼Œç”¨äºå¯åŠ¨æ‰©æ•£è¿‡ç¨‹çš„éšæœºé«˜æ–¯å™ªå£°ä¼šå½±å“æœ€ç»ˆè¾“å‡ºï¼Œå¯¼è‡´å›¾åƒè´¨é‡å’Œæç¤ºéµå¾ªæ–¹é¢çš„å˜åŒ–ã€‚ç°æœ‰çš„å™ªå£°æ°´å¹³ä¼˜åŒ–æ–¹æ³•ä¸€èˆ¬ä¾èµ–äºé¢å¤–æ•°æ®é›†çš„å»ºè®¾ã€é™„åŠ ç½‘ç»œï¼Œæˆ–åŸºäºåå‘ä¼ æ’­çš„ä¼˜åŒ–ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„å®ç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å™ªå£°æ°´å¹³æŒ‡å¯¼ï¼ˆNLGï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•ã€é«˜æ•ˆä¸”é€šç”¨çš„å™ªå£°æ°´å¹³ä¼˜åŒ–æ–¹æ³•ï¼Œå®ƒé€šè¿‡æé«˜åˆå§‹å™ªå£°ä¸é€šç”¨æŒ‡å¯¼å¯¹é½çš„å¯èƒ½æ€§æ¥ä¼˜åŒ–åˆå§‹å™ªå£°ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®ã€è¾…åŠ©ç½‘ç»œæˆ–åå‘ä¼ æ’­ã€‚æ‰€æå‡ºçš„NLGæ–¹æ³•ä¸ºæœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„æ‰©æ•£æ¨¡å‹æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å¯æ¨å¹¿æ¡†æ¶ï¼Œå¯é€‚åº”å„ç§æ‰©æ•£æ°´å¹³çš„æŒ‡å¯¼ã€‚åœ¨äº”ä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†è¾“å‡ºç”Ÿæˆçš„è´¨é‡å’Œè¾“å…¥æ¡ä»¶çš„éµå¾ªæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ— ç¼é›†æˆåˆ°ç°æœ‰çš„æŒ‡å¯¼æ–¹æ³•ä¸­ï¼ŒåŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ï¼Œè¿™ä½¿å¾—NLGæˆä¸ºæ‰©æ•£æ¨¡å‹çš„å®ç”¨å’Œå¯æ‰©å±•å¢å¼ºã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/harveymannering/NoiseLevelGuidance%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/harveymannering/NoiseLevelGuidanceæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13936v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºå™ªå£°æ°´å¹³å¼•å¯¼ï¼ˆNLGï¼‰çš„ç®€å•ã€é«˜æ•ˆä¸”é€šç”¨çš„å™ªå£°æ°´å¹³ä¼˜åŒ–æ–¹æ³•ï¼Œç”¨äºæ”¹è¿›æ‰©æ•£è¿‡ç¨‹çš„åˆå§‹å™ªå£°ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®ã€è¾…åŠ©ç½‘ç»œæˆ–åå‘ä¼ æ’­ï¼Œé€šè¿‡å¢åŠ åˆå§‹å™ªå£°ä¸é€šç”¨å¼•å¯¼å¯¹é½çš„å¯èƒ½æ€§æ¥ä¼˜åŒ–å™ªå£°æ°´å¹³ã€‚NLGæ–¹æ³•é€‚ç”¨äºæ¡ä»¶å’Œæ— æ¡ä»¶çš„æ‰©æ•£æ¨¡å‹ï¼Œå¯å®¹çº³å„ç§æ‰©æ•£æ°´å¹³å¼•å¯¼å½¢å¼ã€‚åœ¨äº”ä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æé«˜äº†è¾“å‡ºç”Ÿæˆè´¨é‡å’Œè¾“å…¥æ¡ä»¶éµå®ˆæ€§ï¼Œä¸”è®¡ç®—æ•ˆç‡é«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œä½†åˆå§‹å™ªå£°å½±å“æœ€ç»ˆè¾“å‡ºï¼Œå¯¼è‡´å›¾åƒè´¨é‡å’Œæç¤ºéµå®ˆæ€§æœ‰æ‰€å·®å¼‚ã€‚</li>
<li>ç°æœ‰å™ªå£°æ°´å¹³ä¼˜åŒ–æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢å¤–æ•°æ®é›†æ„å»ºã€è¾…åŠ©ç½‘ç»œæˆ–åå‘ä¼ æ’­ä¼˜åŒ–ï¼Œé™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚</li>
<li>æå‡ºäº†å™ªå£°æ°´å¹³å¼•å¯¼ï¼ˆNLGï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•ã€é«˜æ•ˆä¸”é€šç”¨çš„å™ªå£°æ°´å¹³ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>NLGæ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®ã€è¾…åŠ©ç½‘ç»œæˆ–åå‘ä¼ æ’­ï¼Œé€šè¿‡å¢åŠ åˆå§‹å™ªå£°ä¸é€šç”¨å¼•å¯¼å¯¹é½çš„å¯èƒ½æ€§æ¥å·¥ä½œã€‚</li>
<li>NLGæ–¹æ³•é€‚ç”¨äºæ¡ä»¶å’Œæ— æ¡ä»¶çš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶æä¾›äº†å¹¿æ³›çš„æ‰©æ•£çº§åˆ«æŒ‡å¯¼å½¢å¼ã€‚</li>
<li>åœ¨äº”ä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šï¼ŒNLGæ–¹æ³•æé«˜äº†è¾“å‡ºç”Ÿæˆè´¨é‡å’Œè¾“å…¥æ¡ä»¶çš„éµå®ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13936">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13936v1/page_5_1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Towards-Robust-Defense-against-Customization-via-Protective-Perturbation-Resistant-to-Diffusion-based-Purification"><a href="#Towards-Robust-Defense-against-Customization-via-Protective-Perturbation-Resistant-to-Diffusion-based-Purification" class="headerlink" title="Towards Robust Defense against Customization via Protective Perturbation   Resistant to Diffusion-based Purification"></a>Towards Robust Defense against Customization via Protective Perturbation   Resistant to Diffusion-based Purification</h2><p><strong>Authors:Wenkui Yang, Jie Cao, Junxian Duan, Ran He</strong></p>
<p>Diffusion models like Stable Diffusion have become prominent in visual synthesis tasks due to their powerful customization capabilities, which also introduce significant security risks, including deepfakes and copyright infringement. In response, a class of methods known as protective perturbation emerged, which mitigates image misuse by injecting imperceptible adversarial noise. However, purification can remove protective perturbations, thereby exposing images again to the risk of malicious forgery. In this work, we formalize the anti-purification task, highlighting challenges that hinder existing approaches, and propose a simple diagnostic protective perturbation named AntiPure. AntiPure exposes vulnerabilities of purification within the â€œpurification-customizationâ€ workflow, owing to two guidance mechanisms: 1) Patch-wise Frequency Guidance, which reduces the modelâ€™s influence over high-frequency components in the purified image, and 2) Erroneous Timestep Guidance, which disrupts the modelâ€™s denoising strategy across different timesteps. With additional guidance, AntiPure embeds imperceptible perturbations that persist under representative purification settings, achieving effective post-customization distortion. Experiments show that, as a stress test for purification, AntiPure achieves minimal perceptual discrepancy and maximal distortion, outperforming other protective perturbation methods within the purification-customization workflow. </p>
<blockquote>
<p>ç”±äºå¼ºå¤§çš„å®šåˆ¶åŒ–èƒ½åŠ›ï¼ŒåƒStable Diffusionè¿™æ ·çš„æ‰©æ•£æ¨¡å‹åœ¨è§†è§‰åˆæˆä»»åŠ¡ä¸­è„±é¢–è€Œå‡ºï¼Œä½†åŒæ—¶ä¹Ÿå¼•å…¥äº†å·¨å¤§çš„å®‰å…¨é£é™©ï¼ŒåŒ…æ‹¬æ·±åº¦ä¼ªé€ å’Œç‰ˆæƒä¾µçŠ¯ç­‰ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€é—®é¢˜ï¼Œä¸€ç±»åä¸ºä¿æŠ¤æ‰°åŠ¨çš„æ–¹æ³•åº”è¿è€Œç”Ÿï¼Œé€šè¿‡æ³¨å…¥å‡ ä¹æ— æ³•å¯Ÿè§‰çš„å¯¹ç«‹å™ªå£°æ¥å‡è½»å›¾åƒæ»¥ç”¨é—®é¢˜ã€‚ç„¶è€Œï¼Œå‡€åŒ–æ–¹æ³•å¯ä»¥æ¶ˆé™¤ä¿æŠ¤æ€§æ‰°åŠ¨ï¼Œä»è€Œä½¿å›¾åƒå†æ¬¡é¢ä¸´æ¶æ„ç¯¡æ”¹çš„é£é™©ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¯¹æŠ—å‡€åŒ–ä»»åŠ¡è¿›è¡Œäº†å½¢å¼åŒ–è¡¨è¿°ï¼Œå¼ºè°ƒäº†é˜»ç¢ç°æœ‰æ–¹æ³•çš„å„ç§æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•çš„è¯Šæ–­æ€§ä¿æŠ¤æ‰°åŠ¨æ–¹æ³•AntiPureã€‚AntiPureåœ¨â€œå‡€åŒ–-å®šåˆ¶â€å·¥ä½œæµä¸­æš´éœ²äº†å‡€åŒ–æ–¹æ³•çš„æ¼æ´ï¼Œè¿™å¾—ç›Šäºä¸¤ç§å¼•å¯¼æœºåˆ¶ï¼š1ï¼‰æ–‘å—é¢‘ç‡å¼•å¯¼ï¼Œé™ä½äº†æ¨¡å‹å¯¹å‡€åŒ–å›¾åƒä¸­é«˜é¢‘æˆåˆ†çš„å½±å“ï¼›2ï¼‰é”™è¯¯æ—¶é—´æ­¥å¼•å¯¼ï¼Œç ´åäº†æ¨¡å‹åœ¨ä¸åŒæ—¶é—´æ­¥çš„é™å™ªç­–ç•¥ã€‚é€šè¿‡é¢å¤–çš„å¼•å¯¼ï¼ŒAntiPureèƒ½å¤Ÿåœ¨å…¸å‹çš„å‡€åŒ–è®¾ç½®ä¸‹åµŒå…¥å‡ ä¹æ— æ³•å¯Ÿè§‰çš„æ‰°åŠ¨ï¼Œå®ç°äº†æœ‰æ•ˆçš„å®šåˆ¶åå¤±çœŸã€‚å®éªŒè¡¨æ˜ï¼Œä½œä¸ºå¯¹å‡€åŒ–æ–¹æ³•çš„å‹åŠ›æµ‹è¯•ï¼ŒAntiPureå®ç°äº†æœ€å°çš„æ„ŸçŸ¥å·®å¼‚å’Œæœ€å¤§çš„å¤±çœŸï¼Œåœ¨å‡€åŒ–å®šåˆ¶å·¥ä½œæµä¸­ä¼˜äºå…¶ä»–ä¿æŠ¤æ‰°åŠ¨æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13922v1">PDF</a> Accepted to ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>Stable Diffusionç­‰æ‰©æ•£æ¨¡å‹åœ¨è§†è§‰åˆæˆä»»åŠ¡ä¸­å› å¼ºå¤§çš„å®šåˆ¶èƒ½åŠ›è€Œå¤‡å—ç©ç›®ï¼Œä½†ä¹Ÿå¸¦æ¥æ·±ä¼ªã€ç‰ˆæƒä¾µçŠ¯ç­‰å®‰å…¨é£é™©ã€‚ä¸ºåº”å¯¹è¿™äº›é—®é¢˜ï¼Œå‡ºç°äº†ä¿æŠ¤æ‰°åŠ¨ç­‰æ–¹æ³•æ¥å‡è½»å›¾åƒæ»¥ç”¨é£é™©ã€‚ç„¶è€Œï¼Œå‡€åŒ–æŠ€æœ¯å¯ä»¥æ¶ˆé™¤ä¿æŠ¤æ‰°åŠ¨ï¼Œä½¿å›¾åƒå†æ¬¡é¢ä¸´æ¶æ„ç¯¡æ”¹é£é™©ã€‚æœ¬æ–‡æ­£å¼æå‡ºæŠ—å‡€åŒ–ä»»åŠ¡ï¼Œå¼ºè°ƒå½“å‰æ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºä¸€ç§åä¸ºAntiPureçš„ç®€å•è¯Šæ–­ä¿æŠ¤æ‰°åŠ¨ã€‚AntiPureé€šè¿‡ä¸¤ç§å¼•å¯¼æœºåˆ¶æ­éœ²å‡€åŒ–æŠ€æœ¯çš„æ¼æ´ï¼šâ€œå‡€åŒ–å®šåˆ¶â€å·¥ä½œæµç¨‹ä¸­çš„è¡¥ä¸é¢‘ç‡å¼•å¯¼å’Œé”™è¯¯æ—¶åºå¼•å¯¼ã€‚å®ƒåµŒå…¥çœ‹ä¸è§çš„ä¿æŠ¤æ‰°åŠ¨ï¼Œåœ¨ä»£è¡¨æ€§å‡€åŒ–è®¾ç½®ä¸‹æŒç»­å­˜åœ¨ï¼Œå®ç°äº†æœ‰æ•ˆçš„åå®šåˆ¶å¤±çœŸã€‚å®éªŒè¡¨æ˜ï¼Œä½œä¸ºå‡€åŒ–å‹åŠ›æµ‹è¯•ï¼ŒAntiPureå®ç°äº†æœ€å°çš„æ„ŸçŸ¥å·®å¼‚å’Œæœ€å¤§çš„å¤±çœŸï¼Œåœ¨å‡€åŒ–å®šåˆ¶å·¥ä½œæµä¸­ä¼˜äºå…¶ä»–ä¿æŠ¤æ‰°åŠ¨æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å¦‚Stable Diffusionåœ¨è§†è§‰åˆæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„å®šåˆ¶åŒ–èƒ½åŠ›ï¼Œä½†è¿™ä¹Ÿå¼•å‘äº†æ·±ä¼ªå’Œç‰ˆæƒä¾µçŠ¯ç­‰å®‰å…¨é£é™©ã€‚</li>
<li>ä¿æŠ¤æ‰°åŠ¨æ–¹æ³•è¢«æå‡ºæ¥å‡è½»å›¾åƒæ»¥ç”¨é£é™©ï¼Œä½†ç°æœ‰çš„å‡€åŒ–æŠ€æœ¯å¯ä»¥æ¶ˆé™¤è¿™äº›ä¿æŠ¤æ‰°åŠ¨ã€‚</li>
<li>AntiPureæ˜¯ä¸€ç§æ–°çš„è¯Šæ–­ä¿æŠ¤æ‰°åŠ¨ï¼Œå®ƒé€šè¿‡ä¸¤ç§å¼•å¯¼æœºåˆ¶æ­éœ²å‡€åŒ–æŠ€æœ¯çš„æ¼æ´ã€‚</li>
<li>AntiPureé€šè¿‡åœ¨å‡€åŒ–åç»´æŒå¿…è¦çš„å¤±çœŸæ¥å¼ºåŒ–å›¾åƒçš„ä¿æŠ¤èƒ½åŠ›ã€‚</li>
<li>ä½œä¸ºä¸€é¡¹é’ˆå¯¹å‡€åŒ–çš„å‹åŠ›æµ‹è¯•ï¼ŒAntiPureå±•ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œèƒ½å¤Ÿåœ¨æœ€å°æ„ŸçŸ¥å·®å¼‚ä¸‹å®ç°æœ€å¤§å¤±çœŸã€‚</li>
<li>AntiPureåœ¨å‡€åŒ–å®šåˆ¶å·¥ä½œæµä¸­çš„è¡¨ç°ä¼˜äºå…¶ä»–ä¿æŠ¤æ‰°åŠ¨æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13922v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13922v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13922v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13922v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EDITS-Enhancing-Dataset-Distillation-with-Implicit-Textual-Semantics"><a href="#EDITS-Enhancing-Dataset-Distillation-with-Implicit-Textual-Semantics" class="headerlink" title="EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics"></a>EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics</h2><p><strong>Authors:Qianxin Xia, Jiawei Du, Guoming Lu, Zhiyong Shu, Jielei Wang</strong></p>
<p>Dataset distillation aims to synthesize a compact dataset from the original large-scale one, enabling highly efficient learning while preserving competitive model performance. However, traditional techniques primarily capture low-level visual features, neglecting the high-level semantic and structural information inherent in images. In this paper, we propose EDITS, a novel framework that exploits the implicit textual semantics within the image data to achieve enhanced distillation. First, external texts generated by a Vision Language Model (VLM) are fused with image features through a Global Semantic Query module, forming the prior clustered buffer. Local Semantic Awareness then selects representative samples from the buffer to construct image and text prototypes, with the latter produced by guiding a Large Language Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype Guidance strategy generates the final synthetic dataset through a diffusion model. Extensive experiments confirm the effectiveness of our method.Source code is available in: <a target="_blank" rel="noopener" href="https://github.com/einsteinxia/EDITS">https://github.com/einsteinxia/EDITS</a>. </p>
<blockquote>
<p>æ•°æ®é›†è’¸é¦çš„ç›®æ ‡æ˜¯ä»åŸå§‹çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸­åˆæˆä¸€ä¸ªç´§å‡‘çš„æ•°æ®é›†ï¼Œä»¥å®ç°é«˜æ•ˆå­¦ä¹ ï¼ŒåŒæ—¶ä¿æŒç«äº‰æ€§çš„æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¼ ç»ŸæŠ€æœ¯ä¸»è¦æ•æ‰å›¾åƒçš„ä½çº§è§†è§‰ç‰¹å¾ï¼Œå¿½ç•¥äº†å›¾åƒä¸­å›ºæœ‰çš„é«˜çº§è¯­ä¹‰å’Œç»“æ„ä¿¡æ¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†EDITSï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å›¾åƒæ•°æ®ä¸­çš„éšå«æ–‡æœ¬è¯­ä¹‰æ¥å®ç°å¢å¼ºè’¸é¦çš„æ–°å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œé€šè¿‡å…¨å±€è¯­ä¹‰æŸ¥è¯¢æ¨¡å—ï¼Œå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç”Ÿæˆçš„å¤–éƒ¨æ–‡æœ¬ä¸å›¾åƒç‰¹å¾ç›¸èåˆï¼Œå½¢æˆå…ˆéªŒèšç±»ç¼“å†²åŒºã€‚ç„¶åï¼Œå±€éƒ¨è¯­ä¹‰æ„è¯†ä»ç¼“å†²åŒºä¸­é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼Œæ„å»ºå›¾åƒå’Œæ–‡æœ¬åŸå‹ï¼Œåè€…æ˜¯é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºæ¥å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è€Œäº§ç”Ÿçš„ã€‚æœ€ç»ˆï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹é‡‡ç”¨åŒé‡åŸå‹æŒ‡å¯¼ç­–ç•¥ç”Ÿæˆæœ€ç»ˆçš„åˆæˆæ•°æ®é›†ã€‚å¤§é‡å®éªŒè¯å®äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/einsteinxia/EDITS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/einsteinxia/EDITSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13858v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEDITSçš„æ–°å‹æ•°æ®é›†è’¸é¦æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨å›¾åƒæ•°æ®ä¸­çš„éšå«æ–‡æœ¬è¯­ä¹‰æ¥å®ç°å¢å¼ºçš„è’¸é¦æ•ˆæœã€‚é€šè¿‡å…¨çƒè¯­ä¹‰æŸ¥è¯¢æ¨¡å—å°†å¤–éƒ¨æ–‡æœ¬ä¸å›¾åƒç‰¹å¾èåˆå½¢æˆå…ˆéªŒèšç±»ç¼“å†²åŒºï¼Œç„¶åä½¿ç”¨å±€éƒ¨è¯­ä¹‰æ„è¯†ä»ä¸­é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬æ„å»ºå›¾åƒå’Œæ–‡æœ¬åŸå‹ï¼Œæœ€åé€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®é›†ã€‚è¯¥æ–¹æ³•ä¸ä»…æé«˜äº†å­¦ä¹ æ•ˆç‡ï¼Œè¿˜ä¿æŒäº†æ¨¡å‹æ€§èƒ½ã€‚æºä»£ç å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EDITSæ¡†æ¶é€šè¿‡èåˆå¤–éƒ¨æ–‡æœ¬å’Œå›¾åƒç‰¹å¾å®ç°æ•°æ®é›†è’¸é¦ã€‚</li>
<li>å…¨çƒè¯­ä¹‰æŸ¥è¯¢æ¨¡å—æ˜¯EDITSçš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œè´Ÿè´£å°†å¤–éƒ¨æ–‡æœ¬ä¸å›¾åƒç‰¹å¾ç»“åˆå½¢æˆå…ˆéªŒèšç±»ç¼“å†²åŒºã€‚</li>
<li>å±€éƒ¨è¯­ä¹‰æ„è¯†ä»ç¼“å†²åŒºä¸­é€‰æ‹©ä»£è¡¨æ€§æ ·æœ¬ï¼Œæ„å»ºå›¾åƒå’Œæ–‡æœ¬åŸå‹ã€‚</li>
<li>Large Language Model (LLM)åœ¨ç”Ÿæˆæ–‡æœ¬åŸå‹æ—¶èµ·åˆ°å…³é”®ä½œç”¨ã€‚</li>
<li>EDITSä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®é›†ï¼Œè¿™æœ‰åŠ©äºæé«˜å­¦ä¹ æ•ˆç‡å¹¶ç»´æŒæ¨¡å‹æ€§èƒ½ã€‚</li>
<li>EDITSåœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13858">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13858v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13858v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13858v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13858v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Generative-Image-Coding-with-Diffusion-Prior"><a href="#Generative-Image-Coding-with-Diffusion-Prior" class="headerlink" title="Generative Image Coding with Diffusion Prior"></a>Generative Image Coding with Diffusion Prior</h2><p><strong>Authors:Jianhui Chang</strong></p>
<p>As generative technologies advance, visual content has evolved into a complex mix of natural and AI-generated images, driving the need for more efficient coding techniques that prioritize perceptual quality. Traditional codecs and learned methods struggle to maintain subjective quality at high compression ratios, while existing generative approaches face challenges in visual fidelity and generalization. To this end, we propose a novel generative coding framework leveraging diffusion priors to enhance compression performance at low bitrates. Our approach employs a pre-optimized encoder to generate generalized compressed-domain representations, integrated with the pretrained modelâ€™s internal features via a lightweight adapter and an attentive fusion module. This framework effectively leverages existing pretrained diffusion models and enables efficient adaptation to different pretrained models for new requirements with minimal retraining costs. We also introduce a distribution renormalization method to further enhance reconstruction fidelity. Extensive experiments show that our method (1) outperforms existing methods in visual fidelity across low bitrates, (2) improves compression performance by up to 79% over H.266&#x2F;VVC, and (3) offers an efficient solution for AI-generated content while being adaptable to broader content types. </p>
<blockquote>
<p>éšç€ç”ŸæˆæŠ€æœ¯çš„è¿›æ­¥ï¼Œè§†è§‰å†…å®¹å·²ç»æ¼”å˜ä¸ºè‡ªç„¶å›¾åƒå’ŒAIç”Ÿæˆå›¾åƒçš„å¤æ‚æ··åˆä½“ï¼Œè¿™æ¨åŠ¨äº†éœ€è¦æ›´æœ‰æ•ˆçš„ç¼–ç æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯éœ€è¦ä¼˜å…ˆé‡è§†æ„ŸçŸ¥è´¨é‡ã€‚ä¼ ç»Ÿç¼–ç å™¨å’Œå­¦ä¹ æ–¹æ³•åœ¨è¾ƒé«˜çš„å‹ç¼©ç‡ä¸‹å¾ˆéš¾ä¿æŒä¸»è§‚è´¨é‡ï¼Œè€Œç°æœ‰çš„ç”Ÿæˆæ–¹æ³•åˆ™åœ¨è§†è§‰ä¿çœŸåº¦å’Œé€šç”¨æ€§æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨æ‰©æ•£å…ˆéªŒçŸ¥è¯†çš„æ–°å‹ç”Ÿæˆç¼–ç æ¡†æ¶ï¼Œä»¥æé«˜åœ¨ä½ç ç‡ä¸‹çš„å‹ç¼©æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨é¢„ä¼˜åŒ–çš„ç¼–ç å™¨ç”Ÿæˆé€šç”¨çš„å‹ç¼©åŸŸè¡¨ç¤ºï¼Œé€šè¿‡è½»é‡çº§é€‚é…å™¨å’Œæ³¨æ„åŠ›èåˆæ¨¡å—ä¸é¢„è®­ç»ƒæ¨¡å‹çš„å†…éƒ¨ç‰¹å¾ç›¸ç»“åˆã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç°æœ‰çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶èƒ½å¤Ÿå®ç°é’ˆå¯¹ä¸åŒé¢„è®­ç»ƒæ¨¡å‹çš„é«˜æ•ˆé€‚é…ï¼Œä»¥æ»¡è¶³æ–°çš„éœ€æ±‚ä¸”æœ€å°åŒ–å†è®­ç»ƒæˆæœ¬ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åˆ†å¸ƒå½’ä¸€åŒ–æ–¹æ³•ï¼Œä»¥è¿›ä¸€æ­¥æé«˜é‡å»ºä¿çœŸåº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ï¼ˆ1ï¼‰åœ¨ä½ç ç‡ä¸‹åœ¨è§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œï¼ˆ2ï¼‰ä¸H.266&#x2F;VVCç›¸æ¯”ï¼Œå‹ç¼©æ€§èƒ½æé«˜äº†é«˜è¾¾79%ï¼Œï¼ˆ3ï¼‰ä¸ºAIç”Ÿæˆå†…å®¹æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶å¯é€‚åº”æ›´å¹¿æ³›çš„å†…å®¹ç±»å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13768v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€ç”ŸæˆæŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œè§†è§‰å†…å®¹å·²æ¼”å˜ä¸ºè‡ªç„¶å›¾åƒå’ŒAIç”Ÿæˆå›¾åƒçš„ç»¼åˆä½“ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬éœ€è¦æ›´é«˜æ•ˆçš„ç¼–ç æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡è§†æ„ŸçŸ¥è´¨é‡æ–¹é¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨æ‰©æ•£å…ˆéªŒçš„æ–°å‹ç”Ÿæˆç¼–ç æ¡†æ¶ï¼Œä»¥æé«˜ä½æ¯”ç‰¹ç‡ä¸‹çš„å‹ç¼©æ€§èƒ½ã€‚è¯¥æ¡†æ¶é‡‡ç”¨é¢„ä¼˜åŒ–ç¼–ç å™¨ç”Ÿæˆé€šç”¨å‹ç¼©åŸŸè¡¨ç¤ºï¼Œé€šè¿‡è½»é‡çº§é€‚é…å™¨å’Œæ³¨æ„åŠ›èåˆæ¨¡å—ä¸é¢„è®­ç»ƒæ¨¡å‹çš„å†…ç‰¹å¾ç›¸èåˆã€‚æ­¤å¤–ï¼Œå¼•å…¥åˆ†å¸ƒé‡å½’ä¸€åŒ–æ–¹æ³•è¿›ä¸€æ­¥æé«˜é‡å»ºä¿çœŸåº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨è¾ƒä½æ¯”ç‰¹ç‡ä¸‹è¡¨ç°å°¤ä¸ºå‡ºè‰²ï¼Œå¹¶å¯æœ‰æ•ˆé€‚åº”AIç”Ÿæˆå†…å®¹å’Œå…¶ä»–æ›´å¹¿æ³›çš„å†…å®¹ç±»å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”ŸæˆæŠ€æœ¯çš„è¿›æ­¥ä¿ƒä½¿è§†è§‰å†…å®¹æ¼”å˜ä¸ºè‡ªç„¶å’ŒAIç”Ÿæˆå›¾åƒçš„ç»¼åˆä½“ã€‚</li>
<li>éœ€è¦æ›´é«˜æ•ˆçš„ç¼–ç æŠ€æœ¯æ¥é€‚åº”å¤æ‚çš„è§†è§‰å†…å®¹ï¼Œç‰¹åˆ«æ˜¯é‡è§†æ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„ç”Ÿæˆç¼–ç æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£å…ˆéªŒæé«˜ä½æ¯”ç‰¹ç‡ä¸‹çš„å‹ç¼©æ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶é‡‡ç”¨é¢„ä¼˜åŒ–ç¼–ç å™¨ç”Ÿæˆé€šç”¨å‹ç¼©åŸŸè¡¨ç¤ºï¼Œå¹¶ä¸é¢„è®­ç»ƒæ¨¡å‹èåˆã€‚</li>
<li>å¼•å…¥åˆ†å¸ƒé‡å½’ä¸€åŒ–æ–¹æ³•æ¥æé«˜é‡å»ºå›¾åƒçš„ä¿çœŸåº¦ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ¯”ç‰¹ç‡ä¸‹è¡¨ç°æ›´å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13768v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Cross-Distribution-Diffusion-Priors-Driven-Iterative-Reconstruction-for-Sparse-View-CT"><a href="#Cross-Distribution-Diffusion-Priors-Driven-Iterative-Reconstruction-for-Sparse-View-CT" class="headerlink" title="Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for   Sparse-View CT"></a>Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for   Sparse-View CT</h2><p><strong>Authors:Haodong Li, Shuo Han, Haiyang Mao, Yu Shi, Changsheng Fang, Jianjia Zhang, Weiwen Wu, Hengyong Yu</strong></p>
<p>Sparse-View CT (SVCT) reconstruction enhances temporal resolution and reduces radiation dose, yet its clinical use is hindered by artifacts due to view reduction and domain shifts from scanner, protocol, or anatomical variations, leading to performance degradation in out-of-distribution (OOD) scenarios. In this work, we propose a Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction (CDPIR) framework to tackle the OOD problem in SVCT. CDPIR integrates cross-distribution diffusion priors, derived from a Scalable Interpolant Transformer (SiT), with model-based iterative reconstruction methods. Specifically, we train a SiT backbone, an extension of the Diffusion Transformer (DiT) architecture, to establish a unified stochastic interpolant framework, leveraging Classifier-Free Guidance (CFG) across multiple datasets. By randomly dropping the conditioning with a null embedding during training, the model learns both domain-specific and domain-invariant priors, enhancing generalizability. During sampling, the globally sensitive transformer-based diffusion model exploits the cross-distribution prior within the unified stochastic interpolant framework, enabling flexible and stable control over multi-distribution-to-noise interpolation paths and decoupled sampling strategies, thereby improving adaptation to OOD reconstruction. By alternating between data fidelity and sampling updates, our model achieves state-of-the-art performance with superior detail preservation in SVCT reconstructions. Extensive experiments demonstrate that CDPIR significantly outperforms existing approaches, particularly under OOD conditions, highlighting its robustness and potential clinical value in challenging imaging scenarios. </p>
<blockquote>
<p>ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰é‡å»ºæé«˜äº†æ—¶é—´åˆ†è¾¨ç‡å¹¶é™ä½äº†è¾å°„å‰‚é‡ï¼Œä½†å…¶ä¸´åºŠåº”ç”¨å—åˆ°ç”±è§†å›¾å‡å°‘ã€æ‰«æä»ªã€åè®®æˆ–è§£å‰–ç»“æ„å˜åŒ–å¼•èµ·çš„åŸŸæ¼‚ç§»æ‰€å¯¼è‡´çš„ä¼ªå½±çš„é˜»ç¢ï¼Œè¿™å¯¼è‡´åœ¨è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰çš„åœºæ™¯ä¸­å‡ºç°æ€§èƒ½ä¸‹é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒé©±åŠ¨è¿­ä»£é‡å»ºï¼ˆCDPIRï¼‰æ¡†æ¶ï¼Œä»¥è§£å†³SVCTä¸­çš„OODé—®é¢˜ã€‚CDPIRå°†æºäºå¯æ‰©å±•æ’å€¼è½¬æ¢å™¨ï¼ˆSiTï¼‰çš„è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸åŸºäºæ¨¡å‹çš„è¿­ä»£é‡å»ºæ–¹æ³•ç›¸ç»“åˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªSiTéª¨å¹²ç½‘ï¼Œè¿™æ˜¯æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„çš„æ‰©å±•ï¼Œä»¥å»ºç«‹ç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶ï¼Œåˆ©ç”¨å¤šä¸ªæ•°æ®é›†ä¹‹é—´çš„æ— åˆ†ç±»å™¨æŒ‡å¯¼ï¼ˆCFGï¼‰ã€‚é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒæ¡ä»¶å¹¶ä½¿ç”¨ç©ºåµŒå…¥ï¼Œæ¨¡å‹å­¦ä¼šäº†ç‰¹å®šåŸŸå’Œè·¨åŸŸçš„å…ˆéªŒçŸ¥è¯†ï¼Œå¢å¼ºäº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œå…¨å±€æ•æ„Ÿæ€§çš„åŸºäºè½¬æ¢å™¨çš„æ‰©æ•£æ¨¡å‹åœ¨ç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶å†…åˆ©ç”¨è·¨åˆ†å¸ƒå…ˆéªŒï¼Œå®ç°å¯¹å¤šåˆ†å¸ƒåˆ°å™ªå£°æ’å€¼è·¯å¾„å’Œç‹¬ç«‹é‡‡æ ·ç­–ç•¥çš„çµæ´»ç¨³å®šæ§åˆ¶ï¼Œä»è€Œæé«˜äº†å¯¹OODé‡å»ºçš„é€‚åº”æ€§ã€‚é€šè¿‡äº¤æ›¿è¿›è¡Œæ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨SVCTé‡å»ºä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä»¥å“è¶Šçš„ç»†èŠ‚ä¿ç•™è€Œè„±é¢–è€Œå‡ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCDPIRæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨OODæ¡ä»¶ä¸‹ï¼Œå‡¸æ˜¾äº†å…¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆåƒåœºæ™¯ä¸­çš„ç¨³å¥æ€§å’Œæ½œåœ¨çš„çš„ä¸´åºŠä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13576v1">PDF</a> 11 pages, 8 figures, under reviewing of IEEE TMI</p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰é‡å»ºæé«˜äº†æ—¶é—´åˆ†è¾¨ç‡å¹¶é™ä½äº†è¾å°„å‰‚é‡ï¼Œä½†å…¶ä¸´åºŠåº”ç”¨å—åˆ°è§†å›¾å‡å°‘å’Œæ¥è‡ªæ‰«æä»ªã€åè®®æˆ–è§£å‰–ç»“æ„å˜åŒ–å¯¼è‡´çš„åŸŸæ¼‚ç§»æ‰€äº§ç”Ÿçš„ä¼ªå½±çš„é˜»ç¢ï¼Œè¿™åœ¨è¶…å‡ºåˆ†å¸ƒèŒƒå›´ï¼ˆOODï¼‰çš„åœºæ™¯ä¸­ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒé©±åŠ¨è¿­ä»£é‡å»ºï¼ˆCDPIRï¼‰æ¡†æ¶æ¥è§£å†³SVCTä¸­çš„OODé—®é¢˜ã€‚CDPIRç»“åˆäº†æ¥è‡ªå¯æ‰©å±•æ’å€¼è½¬æ¢å™¨ï¼ˆSiTï¼‰çš„è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸åŸºäºæ¨¡å‹çš„è¿­ä»£é‡å»ºæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªSiTéª¨å¹²ç½‘ï¼Œè¿™æ˜¯æ‰©æ•£è½¬æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„çš„æ‰©å±•ï¼Œä»¥å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶ï¼Œåˆ©ç”¨è·¨å¤šä¸ªæ•°æ®é›†çš„Classifier-Free Guidanceï¼ˆCFGï¼‰ã€‚é€šè¿‡åœ¨è®­ç»ƒæœŸé—´éšæœºä¸¢å¼ƒæ¡ä»¶åµŒå…¥ä½œä¸ºnullåµŒå…¥ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ ç‰¹å®šé¢†åŸŸå’Œä¸ç‰¹å®šé¢†åŸŸçš„å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œå…¨å±€æ•æ„Ÿæ€§çš„åŸºäºè½¬æ¢å™¨çš„æ‰©æ•£æ¨¡å‹åœ¨ç»Ÿä¸€çš„éšæœºæ’å€¼æ¡†æ¶å†…åˆ©ç”¨è·¨åˆ†å¸ƒå…ˆéªŒï¼Œå®ç°çµæ´»ç¨³å®šçš„æ§åˆ¶å¤šåˆ†å¸ƒåˆ°å™ªå£°çš„æ’å€¼è·¯å¾„å’Œç‹¬ç«‹çš„é‡‡æ ·ç­–ç•¥ï¼Œä»è€Œæé«˜äº†å¯¹OODé‡å»ºçš„é€‚åº”æ€§ã€‚é€šè¿‡äº¤æ›¿è¿›è¡Œæ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨SVCTé‡å»ºä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶å‡ºè‰²åœ°ä¿ç•™äº†ç»†èŠ‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCDPIRæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨OODæ¡ä»¶ä¸‹ï¼Œçªæ˜¾äº†å…¶ç¨³å¥æ€§å’Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆåƒåœºæ™¯ä¸­çš„æ½œåœ¨ä¸´åºŠä»·å€¼ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>CDPIRæ¡†æ¶è§£å†³äº†ç¨€ç–è§†å›¾CTï¼ˆSVCTï¼‰é‡å»ºä¸­çš„OODé—®é¢˜ã€‚</li>
<li>ç»“åˆäº†è·¨åˆ†å¸ƒæ‰©æ•£å…ˆéªŒä¸è¿­ä»£é‡å»ºæ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨å¯æ‰©å±•æ’å€¼è½¬æ¢å™¨ï¼ˆSiTï¼‰è®­ç»ƒæ¨¡å‹ä»¥å­¦ä¹ é¢†åŸŸç‰¹å®šå’Œé¢†åŸŸä¸å˜çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>æ¨¡å‹é€šè¿‡ç»“åˆæ•°æ®ä¿çœŸåº¦å’Œé‡‡æ ·æ›´æ–°å®ç°äº†å…ˆè¿›æ€§èƒ½ã€‚</li>
<li>CDPIRåœ¨SVCTé‡å»ºä¸­è¡¨ç°å‡ºå“è¶Šçš„ç»†èŠ‚ä¿ç•™èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºCDPIRåœ¨OODæ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13576">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13576v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13576v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13576v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DEFT-VTON-Efficient-Virtual-Try-On-with-Consistent-Generalised-H-Transform"><a href="#DEFT-VTON-Efficient-Virtual-Try-On-with-Consistent-Generalised-H-Transform" class="headerlink" title="DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised   H-Transform"></a>DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised   H-Transform</h2><p><strong>Authors:Xingzi Xu, Qi Li, Shuwen Qiu, Julien Han, Karim Bouyarmane</strong></p>
<p>Diffusion models enable high-quality virtual try-on (VTO) with their established image synthesis abilities. Despite the extensive end-to-end training of large pre-trained models involved in current VTO methods, real-world applications often prioritize limited training and inference, serving, and deployment budgets for VTO. To solve this obstacle, we apply Doobâ€™s h-transform efficient fine-tuning (DEFT) for adapting large pre-trained unconditional models for downstream image-conditioned VTO abilities. DEFT freezes the pre-trained modelâ€™s parameters and trains a small h-transform network to learn a conditional h-transform. The h-transform network allows training only 1.42 percent of the frozen parameters, compared to a baseline of 5.52 percent in traditional parameter-efficient fine-tuning (PEFT).   To further improve DEFTâ€™s performance and decrease existing modelsâ€™ inference time, we additionally propose an adaptive consistency loss. Consistency training distills slow but high-performing diffusion models into a fast one while retaining performance by enforcing consistencies along the inference path. Inspired by constrained optimization, instead of distillation, we combine the consistency loss and the denoising score matching loss in a data-adaptive manner for fine-tuning existing VTO models at a low cost. Empirical results show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO tasks, with as few as 15 denoising steps, while maintaining competitive results. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹å‡­å€Ÿå…¶æˆç†Ÿçš„å›¾åƒåˆæˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°é«˜è´¨é‡çš„è™šæ‹Ÿè¯•ç©¿ï¼ˆVTOï¼‰ã€‚å°½ç®¡ç›®å‰çš„VTOæ–¹æ³•æ¶‰åŠå¯¹å¤§å‹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯çš„å¹¿æ³›è®­ç»ƒï¼Œä½†ç°å®ä¸–ç•Œçš„åº”ç”¨å¾€å¾€ä¼˜å…ˆè€ƒè™‘æœ‰é™çš„è®­ç»ƒã€æ¨ç†ã€æœåŠ¡å’Œéƒ¨ç½²é¢„ç®—ï¼Œç”¨äºVTOã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åº”ç”¨Doobçš„h-transformé«˜æ•ˆå¾®è°ƒï¼ˆDEFTï¼‰æŠ€æœ¯ï¼Œä»¥é€‚åº”å¤§å‹é¢„è®­ç»ƒæ— æ¡ä»¶æ¨¡å‹è¿›è¡Œä¸‹æ¸¸å›¾åƒè°ƒèŠ‚çš„VTOèƒ½åŠ›ã€‚DEFTå†»ç»“é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªå°å‹çš„h-transformç½‘ç»œæ¥å­¦ä¹ æ¡ä»¶h-transformã€‚ä¸ä¼ ç»Ÿå‚æ•°æœ‰æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„åŸºçº¿ç›¸æ¯”ï¼Œh-transformç½‘ç»œåªå…è®¸å†»ç»“å‚æ•°çš„1.42%è¿›è¡Œè®­ç»ƒï¼Œè€ŒåŸºçº¿åˆ™éœ€è¦è®­ç»ƒ5.52%çš„å‚æ•°ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜DEFTçš„æ€§èƒ½å¹¶å‡å°‘ç°æœ‰æ¨¡å‹çš„æ¨ç†æ—¶é—´ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è‡ªé€‚åº”ä¸€è‡´æ€§æŸå¤±ã€‚ä¸€è‡´æ€§è®­ç»ƒå°†ç¼“æ…¢ä½†é«˜æ€§èƒ½çš„æ‰©æ•£æ¨¡å‹è’¸é¦ä¸ºå¿«é€Ÿæ¨¡å‹ï¼ŒåŒæ—¶é€šè¿‡æ‰§è¡Œæ¨ç†è·¯å¾„ä¸Šçš„ä¸€è‡´æ€§æ¥ä¿ç•™æ€§èƒ½ã€‚å—çº¦æŸä¼˜åŒ–çš„å¯å‘ï¼Œæˆ‘ä»¬ä¸æ˜¯é‡‡ç”¨è’¸é¦çš„æ–¹æ³•ï¼Œè€Œæ˜¯å°†ä¸€è‡´æ€§æŸå¤±å’Œå»å™ªè¯„åˆ†åŒ¹é…æŸå¤±ä»¥æ•°æ®è‡ªé€‚åº”çš„æ–¹å¼ç»“åˆèµ·æ¥ï¼Œä»¥ä½æˆæœ¬å¾®è°ƒç°æœ‰çš„VTOæ¨¡å‹ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„DEFT-VTONæ–¹æ³•åœ¨VTOä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³çš„æ€§èƒ½ï¼Œä»…ä½¿ç”¨15ä¸ªå»å™ªæ­¥éª¤ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13506v1">PDF</a> Published in 2025 CVPR Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä½¿ç”¨æ‰©æ•£æ¨¡å‹å®ç°é«˜è´¨é‡è™šæ‹Ÿè¯•ç©¿ï¼ˆVTOï¼‰çš„æ–¹æ³•ã€‚ä¸ºè§£å†³å®é™…åº”ç”¨ä¸­è®­ç»ƒã€æ¨ç†ã€éƒ¨ç½²é¢„ç®—æœ‰é™çš„é—®é¢˜ï¼Œé‡‡ç”¨Doobçš„h-transformé«˜æ•ˆå¾®è°ƒï¼ˆDEFTï¼‰æŠ€æœ¯ï¼Œä½¿å¤§å‹é¢„è®­ç»ƒæ— æ¡ä»¶æ¨¡å‹é€‚åº”ä¸‹æ¸¸å›¾åƒæ¡ä»¶VTOèƒ½åŠ›ã€‚DEFTé€šè¿‡å†»ç»“é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å¹¶è®­ç»ƒå°å‹h-transformç½‘ç»œå­¦ä¹ æ¡ä»¶h-transformæ¥è§£å†³æ­¤é—®é¢˜ï¼Œä»…è®­ç»ƒ1.42%çš„å†»ç»“å‚æ•°ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå‚æ•°æ•ˆç‡å¾®è°ƒï¼ˆPEFTï¼‰çš„5.52%æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ä¸ºè¿›ä¸€æ­¥æ”¹å–„DEFTæ€§èƒ½å¹¶å‡å°‘ç°æœ‰æ¨¡å‹çš„æ¨ç†æ—¶é—´ï¼Œæå‡ºäº†è‡ªé€‚åº”ä¸€è‡´æ€§æŸå¤±ã€‚ä¸€è‡´æ€§è®­ç»ƒå°†ç¼“æ…¢ä½†é«˜æ€§èƒ½çš„æ‰©æ•£æ¨¡å‹è½¬åŒ–ä¸ºå¿«é€Ÿæ¨¡å‹ï¼ŒåŒæ—¶ä¿ç•™æ€§èƒ½ï¼Œé€šè¿‡åœ¨æ¨ç†è·¯å¾„ä¸Šå¼ºåˆ¶æ‰§è¡Œä¸€è‡´æ€§æ¥å®ç°ã€‚é€šè¿‡ç»“åˆä¸€è‡´æ€§æŸå¤±å’Œå»å™ªåˆ†æ•°åŒ¹é…æŸå¤±ï¼Œä»¥æ•°æ®è‡ªé€‚åº”æ–¹å¼å¾®è°ƒç°æœ‰VTOæ¨¡å‹ï¼Œæˆæœ¬ä½ï¼Œä¸”åªéœ€å°‘æ•°å‡ æ­¥å»å™ªå³å¯è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿå®ç°é«˜è´¨é‡çš„è™šæ‹Ÿè¯•ç©¿ï¼ˆVTOï¼‰ã€‚</li>
<li>å½“å‰VTOæ–¹æ³•è™½ç„¶æ¶‰åŠå¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä½†å®é™…åº”ç”¨ä¸­æ›´å¼ºè°ƒæœ‰é™çš„è®­ç»ƒã€æ¨ç†ã€éƒ¨ç½²é¢„ç®—ã€‚</li>
<li>Doobçš„h-transformé«˜æ•ˆå¾®è°ƒï¼ˆDEFTï¼‰æŠ€æœ¯è¢«åº”ç”¨äºé€‚åº”ä¸‹æ¸¸å›¾åƒæ¡ä»¶VTOèƒ½åŠ›ï¼Œé€šè¿‡å†»ç»“é¢„è®­ç»ƒæ¨¡å‹çš„å¤§éƒ¨åˆ†å‚æ•°å¹¶ä»…è®­ç»ƒå°éƒ¨åˆ†h-transformç½‘ç»œæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>DEFTç›¸è¾ƒäºä¼ ç»Ÿå‚æ•°æ•ˆç‡å¾®è°ƒï¼ˆPEFTï¼‰æœ‰æ›´ä¼˜çš„å‚æ•°è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>ä¸ºæé«˜DEFTæ€§èƒ½å¹¶å‡å°‘æ¨¡å‹æ¨ç†æ—¶é—´ï¼Œæå‡ºäº†è‡ªé€‚åº”ä¸€è‡´æ€§æŸå¤±ã€‚</li>
<li>ä¸€è‡´æ€§è®­ç»ƒèƒ½å°†æ…¢ä½†é«˜æ€§èƒ½çš„æ‰©æ•£æ¨¡å‹è½¬åŒ–ä¸ºå¿«é€Ÿæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13506">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13506v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13506v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13506v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13506v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2509.13506v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DPDEdit-Detail-Preserved-Diffusion-Models-for-Multimodal-Fashion-Image-Editing"><a href="#DPDEdit-Detail-Preserved-Diffusion-Models-for-Multimodal-Fashion-Image-Editing" class="headerlink" title="DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image   Editing"></a>DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image   Editing</h2><p><strong>Authors:Xiaolong Wang, Zhi-Qi Cheng, Jue Wang, Xiaojiang Peng</strong></p>
<p>Fashion image editing is a crucial tool for designers to convey their creative ideas by visualizing design concepts interactively. Current fashion image editing techniques, though advanced with multimodal prompts and powerful diffusion models, often struggle to accurately identify editing regions and preserve the desired garment texture detail. To address these challenges, we introduce a new multimodal fashion image editing architecture based on latent diffusion models, called Detail-Preserved Diffusion Models (DPDEdit). DPDEdit guides the fashion image generation of diffusion models by integrating text prompts, region masks, human pose images, and garment texture images. To precisely locate the editing region, we first introduce Grounded-SAM to predict the editing region based on the userâ€™s textual description, and then combine it with other conditions to perform local editing. To transfer the detail of the given garment texture into the target fashion image, we propose a texture injection and refinement mechanism. Specifically, this mechanism employs a decoupled cross-attention layer to integrate textual descriptions and texture images, and incorporates an auxiliary U-Net to preserve the high-frequency details of generated garment texture. Additionally, we extend the VITON-HD dataset using a multimodal large language model to generate paired samples with texture images and textual descriptions. Extensive experiments show that our DPDEdit outperforms state-of-the-art methods in terms of image fidelity and coherence with the given multimodal inputs. </p>
<blockquote>
<p>æ—¶å°šå›¾åƒç¼–è¾‘æ˜¯è®¾è®¡å¸ˆé€šè¿‡äº¤äº’å¼å¯è§†åŒ–è®¾è®¡æ¦‚å¿µæ¥è¡¨è¾¾åˆ›æ„æƒ³æ³•çš„é‡è¦å·¥å…·ã€‚å°½ç®¡å½“å‰çš„æ—¶å°šå›¾åƒç¼–è¾‘æŠ€æœ¯å·²ç»å…·å¤‡å¤šæ¨¡å¼æç¤ºå’Œå¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ï¼Œä½†å®ƒä»¬ä»ç„¶éš¾ä»¥å‡†ç¡®è¯†åˆ«ç¼–è¾‘åŒºåŸŸå¹¶ä¿ç•™æ‰€éœ€çš„æœè£…çº¹ç†ç»†èŠ‚ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹å¼•å…¥äº†ä¸€ç§æ–°çš„å¤šæ¨¡å¼æ—¶å°šå›¾åƒç¼–è¾‘æ¶æ„ï¼Œç§°ä¸ºç»†èŠ‚ä¿ç•™æ‰©æ•£æ¨¡å‹ï¼ˆDPDEditï¼‰ã€‚DPDEdité€šè¿‡æ•´åˆæ–‡æœ¬æç¤ºã€åŒºåŸŸæ©ç ã€äººä½“å§¿åŠ¿å›¾åƒå’Œæœè£…çº¹ç†å›¾åƒæ¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ—¶å°šå›¾åƒç”Ÿæˆã€‚ä¸ºäº†ç²¾ç¡®å®šä½ç¼–è¾‘åŒºåŸŸï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥åŸºäºç”¨æˆ·æ–‡æœ¬æè¿°çš„Grounded-SAMè¿›è¡Œé¢„æµ‹ç¼–è¾‘åŒºåŸŸï¼Œç„¶åç»“åˆå…¶ä»–æ¡ä»¶è¿›è¡Œå±€éƒ¨ç¼–è¾‘ã€‚ä¸ºäº†å°†ç»™å®šçš„æœè£…çº¹ç†ç»†èŠ‚è½¬ç§»åˆ°ç›®æ ‡æ—¶å°šå›¾åƒä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†çº¹ç†æ³¨å…¥å’Œç»†åŒ–æœºåˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æœºåˆ¶é‡‡ç”¨è§£è€¦çš„äº¤å‰æ³¨æ„å±‚æ¥æ•´åˆæ–‡æœ¬æè¿°å’Œçº¹ç†å›¾åƒï¼Œå¹¶å¼•å…¥è¾…åŠ©U-Netæ¥ä¿ç•™ç”Ÿæˆæœè£…çº¹ç†çš„é«˜é¢‘ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹æ‰©å±•äº†VITON-HDæ•°æ®é›†ï¼Œç”Ÿæˆå…·æœ‰çº¹ç†å›¾åƒå’Œæ–‡æœ¬æè¿°çš„åŒæ ·æœ¬ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„DPDEditåœ¨å›¾åƒä¿çœŸåº¦å’Œä¸ç»™å®šå¤šæ¨¡å¼è¾“å…¥çš„è¿è´¯æ€§æ–¹é¢ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.01086v3">PDF</a> 13 pages,12 figures</p>
<p><strong>Summary</strong><br>     åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å¤šæ¨¡æ€æ—¶å°šå›¾åƒç¼–è¾‘æ¶æ„DPDEditï¼Œé€šè¿‡ç»“åˆæ–‡æœ¬æç¤ºã€åŒºåŸŸæ©è†œã€äººä½“å§¿æ€å›¾åƒå’Œæœè£…çº¹ç†å›¾åƒï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„æ—¶å°šå›¾åƒç”Ÿæˆã€‚æå‡ºGrounded-SAMç²¾ç¡®å®šä½ç¼–è¾‘åŒºåŸŸï¼Œå¹¶ç»“åˆå…¶ä»–æ¡ä»¶è¿›è¡Œå±€éƒ¨ç¼–è¾‘ã€‚é€šè¿‡çº¹ç†æ³¨å…¥å’Œç»†åŒ–æœºåˆ¶ï¼Œå°†ç»™å®šçš„æœè£…çº¹ç†ç»†èŠ‚è½¬ç§»åˆ°ç›®æ ‡æ—¶å°šå›¾åƒä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¶å°šå›¾åƒç¼–è¾‘æ˜¯è®¾è®¡å¸ˆä¼ è¾¾åˆ›æ„çš„é‡è¦å·¥å…·ï¼Œå½“å‰æŠ€æœ¯é¢ä¸´å‡†ç¡®è¯†åˆ«ç¼–è¾‘åŒºåŸŸå’Œä¿ç•™æœè£…çº¹ç†ç»†èŠ‚çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å¤šæ¨¡æ€æ—¶å°šå›¾åƒç¼–è¾‘æ¶æ„DPDEditï¼Œç»“åˆå¤šç§è¾“å…¥è¿›è¡Œæ—¶å°šå›¾åƒç”Ÿæˆã€‚</li>
<li>DPDEdité€šè¿‡Grounded-SAMé¢„æµ‹ç¼–è¾‘åŒºåŸŸï¼Œå®ç°ç²¾ç¡®å®šä½ã€‚</li>
<li>çº¹ç†æ³¨å…¥å’Œç»†åŒ–æœºåˆ¶é‡‡ç”¨è§£è€¦äº¤å‰æ³¨æ„å±‚æ¥é›†æˆæ–‡æœ¬æè¿°å’Œçº¹ç†å›¾åƒï¼Œå¹¶è¾…ä»¥U-Netä¿ç•™ç”Ÿæˆæœè£…çº¹ç†çš„é«˜é¢‘ç»†èŠ‚ã€‚</li>
<li>DPDEditæ‰©å±•äº†VITON-HDæ•°æ®é›†ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆé…å¯¹æ ·æœ¬ï¼ˆçº¹ç†å›¾åƒå’Œæ–‡æœ¬æè¿°ï¼‰ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDPDEditåœ¨å›¾åƒä¿çœŸåº¦å’Œä¸ç»™å®šå¤šæ¨¡æ€è¾“å…¥çš„ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.01086">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Diffusion Models/2409.01086v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_åŒ»å­¦å›¾åƒ/2509.13629v1/page_0_0.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  LamiGauss Pitching Radiative Gaussian for Sparse-View X-ray   Laminography Reconstruction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/NeRF/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_NeRF/2509.13686v1/page_0_0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-19  RF-LSCM Pushing Radiance Fields to Multi-Domain Localized Statistical   Channel Modeling for Cellular Network Optimization
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31180k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
