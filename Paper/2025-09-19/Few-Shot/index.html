<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-09-19  White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic   Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_3_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-19-更新"><a href="#2025-09-19-更新" class="headerlink" title="2025-09-19 更新"></a>2025-09-19 更新</h1><h2 id="White-Aggregation-and-Restoration-for-Few-shot-3D-Point-Cloud-Semantic-Segmentation"><a href="#White-Aggregation-and-Restoration-for-Few-shot-3D-Point-Cloud-Semantic-Segmentation" class="headerlink" title="White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic   Segmentation"></a>White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic   Segmentation</h2><p><strong>Authors:Jiyun Im, SuBeen Lee, Miso Lee, Jae-Pil Heo</strong></p>
<p>Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point labels for an unlabeled point cloud, given only a few labeled examples. To extract discriminative representations from the limited support set, existing methods have constructed prototypes using conventional algorithms such as farthest point sampling. However, we point out that its initial randomness significantly affects FS-PCS performance and that the prototype generation process remains underexplored despite its prevalence. This motivates us to investigate an advanced prototype generation method based on attention mechanism. Despite its potential, we found that vanilla module suffers from the distributional gap between learnable prototypical tokens and support features. To overcome this, we propose White Aggregation and Restoration Module (WARM), which resolves the misalignment by sandwiching cross-attention between whitening and coloring transformations. Specifically, whitening aligns the support features to prototypical tokens before attention process, and subsequently coloring restores the original distribution to the attended tokens. This simple yet effective design enables robust attention, thereby generating representative prototypes by capturing the semantic relationships among support features. Our method achieves state-of-the-art performance with a significant margin on multiple FS-PCS benchmarks, demonstrating its effectiveness through extensive experiments. </p>
<blockquote>
<p>少数射击三维点云分割（FS-PCS）旨在利用有限的几个标记样本对未标记的点云进行每个点的标签预测。为了从有限的支撑集中提取出有判别力的表示，现有方法已经构建了原型，使用了诸如最远点采样等传统算法。然而，我们指出其初始随机性对FS-PCS性能的影响很大，尽管原型生成过程很普遍，但至今仍未得到充分研究。这促使我们基于注意力机制来调查先进的原型生成方法。尽管它潜力巨大，但我们发现原型化标记令牌和支持特征之间仍然存在分布差距。为了克服这一问题，我们提出了白化聚合与恢复模块（WARM），它通过夹带白化与着色转换之间的交叉注意力来解决不匹配问题。具体来说，白化在注意力处理之前将支持特征对齐到原型标记令牌上，随后的着色将原始分布恢复到注意力集中的令牌上。这种简单而有效的设计实现了稳健的注意力机制，从而通过捕捉支持特征之间的语义关系生成具有代表性的原型。我们的方法在多个FS-PCS基准测试上实现了业界领先的性能，并通过广泛的实验证明了其有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13907v1">PDF</a> 9 pages, 5 figures</p>
<p><strong>Summary</strong><br>少量样本点云分割（FS-PCS）旨在利用少量标注样本预测未标注点云的每个点的标签。现有方法使用常规算法（如最远点采样）构建原型，但初始随机性对性能有很大影响，且原型生成过程尚未得到充分研究。为此，我们基于注意力机制提出了一种先进的原型生成方法。虽然这很有潜力，但我们发现典型的标记原型令牌与支持特征之间的分布差距是一个问题。为解决这一问题，我们提出了白聚集和恢复模块（WARM），它通过夹心白化和着色转换来解决注意力不匹配的问题。白化将支持特征对齐到原型令牌上，然后进行注意力处理，着色将原始分布恢复到关注的令牌上。这种简单而有效的设计实现了稳健的注意力，通过捕捉支持特征之间的语义关系生成具有代表性的原型。我们的方法在多个FS-PCS基准测试中实现了显著的性能提升。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-Shot 3D Point Cloud Segmentation (FS-PCS)的目标是仅使用少量标注样本预测未标注点云的每个点的标签。</li>
<li>现有方法使用常规算法构建原型，但初始随机性和原型生成过程的不足限制了性能。</li>
<li>基于注意力机制的先进原型生成方法具有潜力，但需要解决典型标记原型令牌与支持特征之间的分布差距问题。</li>
<li>提出的White Aggregation and Restoration Module (WARM)通过夹心白化和着色转换解决注意力不匹配的问题，提升了原型的质量。</li>
<li>WARM通过白化对齐支持特征和原型令牌，然后通过着色恢复原始分布，实现稳健的注意力机制。</li>
<li>该方法通过捕捉支持特征之间的语义关系生成具有代表性的原型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13907">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13907v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Are-Prompts-All-You-Need-Evaluating-Prompt-Based-Large-Language-Models-LLM-s-for-Software-Requirements-Classification"><a href="#Are-Prompts-All-You-Need-Evaluating-Prompt-Based-Large-Language-Models-LLM-s-for-Software-Requirements-Classification" class="headerlink" title="Are Prompts All You Need? Evaluating Prompt-Based Large Language Models   (LLM)s for Software Requirements Classification"></a>Are Prompts All You Need? Evaluating Prompt-Based Large Language Models   (LLM)s for Software Requirements Classification</h2><p><strong>Authors:Manal Binkhonain, Reem Alfayaz</strong></p>
<p>Requirements classification assigns natural language requirements to predefined classes, such as functional and non functional. Accurate classification reduces risk and improves software quality. Most existing models rely on supervised learning, which needs large labeled data that are costly, slow to create, and domain dependent; they also generalize poorly and often require retraining for each task. This study tests whether prompt based large language models can reduce data needs. We benchmark several models and prompting styles (zero shot, few shot, persona, and chain of thought) across multiple tasks on two English datasets, PROMISE and SecReq. For each task we compare model prompt configurations and then compare the best LLM setups with a strong fine tuned transformer baseline. Results show that prompt based LLMs, especially with few shot prompts, can match or exceed the baseline. Adding a persona, or persona plus chain of thought, can yield further gains. We conclude that prompt based LLMs are a practical and scalable option that reduces dependence on large annotations and can improve generalizability across tasks. </p>
<blockquote>
<p>需求分类将自然语言要求分配给预定义的类别，如功能性和非功能性。准确的分类可以降低风险并提高软件质量。大多数现有模型依赖于监督学习，这需要大量标签数据，而这些数据的创建成本高、速度慢并且依赖于领域；它们还通用性较差，并且经常需要为每个任务进行重新训练。本研究测试了基于提示的大型语言模型是否可以减少数据需求。我们在两个英语数据集PROMISE和SecReq上的多个任务上基准测试了几种模型和提示风格（零次射击、少数射击、人格思维和思维链）。对于每个任务，我们比较模型的提示配置，然后将最佳的LLM设置与经过精细调整的变换器基准进行比较。结果表明，基于提示的LLM，尤其是具有少量提示的LLM，可以匹配或超过基准。添加人格或人格思维链可以产生进一步的收益。我们得出结论，基于提示的LLM是一个实用且可扩展的选择，可以减少对大量注释的依赖，并可以提高跨任务的通用性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13868v1">PDF</a> 33 pages, 12 figures</p>
<p><strong>Summary</strong></p>
<p>自然语言要求分类是将自然语言要求分配给预定义类别（如功能和非功能）的过程。准确分类可降低风险并改善软件质量。大多数现有模型依赖于需要大量标注数据监督学习，而这些数据成本高昂、创建缓慢并且依赖于特定领域；它们通用性较差，通常需要为每个任务重新训练。本研究测试基于提示的大型语言模型是否能减少数据需求。我们在两个英语数据集PROMISE和SecReq上对多个任务进行基准测试，包括几种提示风格（零样本、少样本、人格化和思维链）。对于每个任务，我们比较模型提示配置，然后将最佳大型语言模型设置与经过精细调整的转换器基线进行对比。结果表明，基于提示的大型语言模型，尤其是少样本提示，可以匹配或超过基线。增加人格化或人格化加上思维链可以产生进一步的收益。我们得出结论，基于提示的大型语言模型是一个实用且可扩展的选择，可以减少对大量注释的依赖，并可以提高跨任务的通用性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>要求分类有助于降低风险并提高软件质量。</li>
<li>现有模型依赖于大量标注数据的监督学习，存在成本高、创建慢、领域依赖等缺点。</li>
<li>基于提示的大型语言模型可减少数据需求。</li>
<li>少样本提示在基于大型语言模型的分类中表现良好。</li>
<li>人格化和思维链的加入可能进一步提高模型性能。</li>
<li>基于提示的大型语言模型是实用且可扩展的选择，减少对大量注释的依赖。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13868">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13868v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-Data-and-Parameter-Efficient-Strategies-for-Arabic-Dialect-Identifications"><a href="#Exploring-Data-and-Parameter-Efficient-Strategies-for-Arabic-Dialect-Identifications" class="headerlink" title="Exploring Data and Parameter Efficient Strategies for Arabic Dialect   Identifications"></a>Exploring Data and Parameter Efficient Strategies for Arabic Dialect   Identifications</h2><p><strong>Authors:Vani Kanjirangat, Ljiljana Dolamic, Fabio Rinaldi</strong></p>
<p>This paper discusses our exploration of different data-efficient and parameter-efficient approaches to Arabic Dialect Identification (ADI). In particular, we investigate various soft-prompting strategies, including prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA reparameterizations. For the data-efficient strategy, we analyze hard prompting with zero-shot and few-shot inferences to analyze the dialect identification capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT approaches, we conducted our experiments using Arabic-specific encoder models on several major datasets. We also analyzed the n-shot inferences on open-source decoder-only models, a general multilingual model (Phi-3.5), and an Arabic-specific one(SILMA). We observed that the LLMs generally struggle to differentiate the dialectal nuances in the few-shot or zero-shot setups. The soft-prompted encoder variants perform better, while the LoRA-based fine-tuned models perform best, even surpassing full fine-tuning. </p>
<blockquote>
<p>本文探讨了我们在阿拉伯语方言识别（ADI）方面对不同数据高效和参数高效方法的探索。我们研究了各种软提示策略，包括前缀调整、提示调整、P-tuning和P-tuning V2以及LoRA重新参数化。对于数据高效策略，我们分析了零样本和少样本推断中的硬提示，以分析大型语言模型（LLM）的方言识别能力。对于参数高效的PEFT方法，我们在几个主要数据集上使用了阿拉伯特定编码器模型进行实验。我们还分析了开源解码器模型、通用多语言模型（Phi-3.</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13775v1">PDF</a> 4 main pages, 4 additional, 5 figures</p>
<p><strong>Summary</strong></p>
<p>本文探讨了数据高效和参数高效的阿拉伯语方言识别（ADI）方法。研究了多种软提示策略，如前缀调整、提示调整、P-tuning和P-tuning V2，以及LoRA重新参数化。对于数据高效策略，我们分析了零样本和少样本推断下的硬提示，以评估大语言模型（LLM）的方言识别能力。在参数高效的PEFT方法中，我们在多个主要数据集上使用了阿拉伯特定的编码器模型进行实验。还分析了开源解码器模型、一般的多语言模型（Phi-3.5）和阿拉伯特定的模型（SILMA）的n次抽样推断结果。发现大语言模型在少样本或零样本环境中方言辨识表现不佳，软提示编码器变体表现更好，基于LoRA的精细调整模型表现最佳，甚至超越全量精细调整。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>论文探讨了数据高效和参数高效的阿拉伯语方言识别方法。</li>
<li>研究了多种软提示策略包括前缀调整、提示调整等。</li>
<li>对于数据高效策略，分析了零样本和少样本推断下的大语言模型方言识别能力。</li>
<li>在参数高效的PEFT方法中，实验使用了阿拉伯特定的编码器模型和多数据集。</li>
<li>n次抽样推断分析涵盖开源解码器模型、多语言模型和阿拉伯特定模型。</li>
<li>大语言模型在少样本或零样本环境下方言辨识能力受限。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13775">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13775v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13775v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13775v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Gender-Neutral-Rewriting-in-Italian-Models-Approaches-and-Trade-offs"><a href="#Gender-Neutral-Rewriting-in-Italian-Models-Approaches-and-Trade-offs" class="headerlink" title="Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs"></a>Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs</h2><p><strong>Authors:Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli</strong></p>
<p>Gender-neutral rewriting (GNR) aims to reformulate text to eliminate unnecessary gender specifications while preserving meaning, a particularly challenging task in grammatical-gender languages like Italian. In this work, we conduct the first systematic evaluation of state-of-the-art large language models (LLMs) for Italian GNR, introducing a two-dimensional framework that measures both neutrality and semantic fidelity to the input. We compare few-shot prompting across multiple LLMs, fine-tune selected models, and apply targeted cleaning to boost task relevance. Our findings show that open-weight LLMs outperform the only existing model dedicated to GNR in Italian, whereas our fine-tuned models match or exceed the best open-weight LLM’s performance at a fraction of its size. Finally, we discuss the trade-off between optimizing the training data for neutrality and meaning preservation. </p>
<blockquote>
<p>性别中立重写（GNR）旨在重新制定文本，消除不必要的性别特定表述，同时保留原有含义，这在如意大利语等具有语法性别的语言中是一项特别具有挑战性的任务。在这项工作中，我们对最先进的意大利语GNR大型语言模型（LLM）进行了首次系统评估，并引入了一个二维框架来衡量中立度和语义忠实度。我们比较了多个LLM的少量提示，对选定模型进行了微调，并应用有针对性的清理措施以提高任务相关性。我们的研究结果表明，开放式权重LLM在意大利语性别中立重写任务上的表现优于唯一现有的专用模型，而我们经过调整的模型能在体积远小于开放式权重LLM的情况下达到或超过其最佳性能。最后，我们讨论了为中立和保留意义优化训练数据之间的权衡。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.13480v1">PDF</a> Accepted at CLiC-it 2025</p>
<p><strong>Summary</strong></p>
<p>本摘要对性别中立重写（GNR）进行了系统评价，重点研究大型语言模型（LLMs）在意大利语中的表现。研究引入了一个二维框架，同时测量语言的中立性和语义的忠实度。通过跨多个LLM进行少量提示，对选定模型进行微调，并应用目标清洗以提高任务相关性。研究结果表明，开放式大型语言模型在意大利语性别中立重写任务上的表现优于现有模型，微调模型性能与最佳开放式大型语言模型相当甚至更优，但模型规模更小。最后，本文讨论了训练数据中对中立性和意义保留之间的权衡。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>本研究针对大型语言模型在意大利语中的性别中立重写能力进行了首次系统评价。</li>
<li>引入了一个二维框架来评估语言的中立性和语义忠实度。</li>
<li>通过少量提示跨多个大型语言模型进行比较和微调模型。</li>
<li>应用目标清洗技术提高任务相关性。</li>
<li>开放式大型语言模型在意大利语性别中立重写任务上表现优越。</li>
<li>微调后的模型性能与最佳开放式大型语言模型相当或更优，但规模更小。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.13480">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.13480v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Singular-Value-Few-shot-Adaptation-of-Vision-Language-Models"><a href="#Singular-Value-Few-shot-Adaptation-of-Vision-Language-Models" class="headerlink" title="Singular Value Few-shot Adaptation of Vision-Language Models"></a>Singular Value Few-shot Adaptation of Vision-Language Models</h2><p><strong>Authors:Taha Koleilat, Hassan Rivaz, Yiming Xiao</strong></p>
<p>Vision-language models (VLMs) like CLIP have shown impressive zero-shot and few-shot learning capabilities across diverse applications. However, adapting these models to new fine-grained domains remains difficult due to reliance on prompt engineering and the high cost of full model fine-tuning. Existing adaptation approaches rely on augmented components, such as prompt tokens and adapter modules, which could limit adaptation quality, destabilize the model, and compromise the rich knowledge learned during pretraining. In this work, we present CLIP-SVD, a novel multi-modal and parameter-efficient adaptation technique that leverages Singular Value Decomposition (SVD) to modify the internal parameter space of CLIP without injecting additional modules. Specifically, we fine-tune only the singular values of the CLIP parameter matrices to rescale the basis vectors for domain adaptation while retaining the pretrained model. This design enables enhanced adaptation performance using only 0.04% of the model’s total parameters and better preservation of its generalization ability. CLIP-SVD achieves state-of-the-art classification results on 11 natural and 10 biomedical datasets, outperforming previous methods in both accuracy and generalization under few-shot settings. Additionally, we leverage a natural language-based approach to analyze the effectiveness and dynamics of the CLIP adaptation to allow interpretability of CLIP-SVD. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/HealthX-Lab/CLIP-SVD">https://github.com/HealthX-Lab/CLIP-SVD</a>. </p>
<blockquote>
<p>视觉语言模型（如CLIP）在多种应用中表现出了令人印象深刻的零样本和少样本学习能力。然而，由于这些模型依赖于提示工程和高昂的全模型微调成本，将其适应新的细粒度领域仍然具有挑战性。现有的适应方法依赖于增强组件，如提示令牌和适配器模块，这可能会限制适应质量，使模型不稳定，并损害预训练期间学到的丰富知识。在这项工作中，我们提出了CLIP-SVD，这是一种新型的多模态和参数高效的适应技术，它利用奇异值分解（SVD）来修改CLIP的内部参数空间，而无需注入额外的模块。具体来说，我们只微调CLIP参数矩阵的奇异值，以重新缩放基础向量进行域适应，同时保留预训练模型。这种设计仅使用模型总参数的0.04%即可实现增强的适应性能，并更好地保持其泛化能力。CLIP-SVD在11个自然和10个生物医学数据集上实现了最先进的分类结果，在少样本设置下在准确性和泛化方面均优于以前的方法。此外，我们还利用基于自然语言的方法来分析CLIP适应的有效性动力学，以实现CLIP-SVD的可解释性。代码可在<a target="_blank" rel="noopener" href="https://github.com/HealthX-Lab/CLIP-SVD%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HealthX-Lab/CLIP-SVD公开获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03740v2">PDF</a> 10 pages, 2 figures, 8 tables</p>
<p><strong>Summary</strong></p>
<p>本文提出了CLIP-SVD，这是一种新的多模态和参数效率高的CLIP模型适配技术。它通过利用奇异值分解（SVD）修改CLIP的内部参数空间，进行领域适配，无需引入额外的模块。只需微调CLIP参数矩阵的奇异值，即可重新调整基础向量以适应领域，同时保留预训练模型的特性。这种方法实现了卓越的分类结果，在多个数据集上优于其他方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CLIP-SVD是一种基于奇异值分解（SVD）的多模态和参数效率高的CLIP模型适配技术。</li>
<li>该方法通过修改CLIP的内部参数空间进行领域适配，无需引入额外的模块或组件。</li>
<li>CLIP-SVD通过微调参数矩阵的奇异值来调整基础向量，以适应新的领域，同时保留预训练模型的特性。</li>
<li>CLIP-SVD实现了卓越的分类结果，在多个数据集上优于其他方法，特别是在少样本设置下。</li>
<li>该方法实现了对CLIP模型的有效适应，并更好地保留了其泛化能力。</li>
<li>CLIP-SVD的代码已公开可用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03740">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.03740v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.03740v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2509.03740v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Deep-Learning-for-Crack-Detection-A-Review-of-Learning-Paradigms-Generalizability-and-Datasets"><a href="#Deep-Learning-for-Crack-Detection-A-Review-of-Learning-Paradigms-Generalizability-and-Datasets" class="headerlink" title="Deep Learning for Crack Detection: A Review of Learning Paradigms,   Generalizability, and Datasets"></a>Deep Learning for Crack Detection: A Review of Learning Paradigms,   Generalizability, and Datasets</h2><p><strong>Authors:Xinan Zhang, Haolin Wang, Yung-An Hsieh, Zhongyu Yang, Anthony Yezzi, Yi-Chang Tsai</strong></p>
<p>Crack detection plays a crucial role in civil infrastructures, including inspection of pavements, buildings, etc., and deep learning has significantly advanced this field in recent years. While numerous technical and review papers exist in this domain, emerging trends are reshaping the landscape. These shifts include transitions in learning paradigms (from fully supervised learning to semi-supervised, weakly-supervised, unsupervised, few-shot, domain adaptation and fine-tuning foundation models), improvements in generalizability (from single-dataset performance to cross-dataset evaluation), and diversification in dataset acquisition (from RGB images to specialized sensor-based data). In this review, we systematically analyze these trends and highlight representative works. Additionally, we introduce a new annotated dataset collected with 3D laser scans, 3DCrack, to support future research and conduct extensive benchmarking experiments to establish baselines for commonly used deep learning methodologies, including recent foundation models. Our findings provide insights into the evolving methodologies and future directions in deep learning-based crack detection. Project page: <a target="_blank" rel="noopener" href="https://github.com/nantonzhang/Awesome-Crack-Detection">https://github.com/nantonzhang/Awesome-Crack-Detection</a> </p>
<blockquote>
<p>裂缝检测在土木基础设施中扮演着至关重要的角色，包括路面、建筑物等的检测，而深度学习近年来已在此领域取得了重大进展。尽管该领域存在大量的技术和综述性论文，但新兴趋势正在改变这一领域的格局。这些变化包括学习范式上的转变（从全监督学习到半监督、弱监督、无监督、小样本、域适应和微调基础模型），通用性的提高（从单一数据集的性能到跨数据集的评价），以及数据集采集的多样化（从RGB图像到基于专用传感器的数据）。在这篇综述中，我们系统地分析了这些趋势，并重点介绍了具有代表性的工作。此外，我们还介绍了一个使用3D激光扫描收集的新注释数据集“3DCrack”，以支持未来的研究，并对常用的深度学习方法进行广泛的基准测试，包括最近的基础模型。我们的研究结果提供了对不断发展的方法和未来深度学习裂缝检测方向的新见解。项目页面：<a target="_blank" rel="noopener" href="https://github.com/nantonzhang/Awesome-Crack-Detection">https://github.com/nantonzhang/Awesome-Crack-Detection</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10256v2">PDF</a> under review</p>
<p><strong>Summary</strong></p>
<p>深度学习方法在裂缝检测领域的应用已经取得了显著进展，本文系统地分析了当前趋势，包括学习范式的转变、泛化性能的改进和数据集采集方式的多样化。此外，本文还介绍了新收集的3D激光扫描数据集3DCrack，并对常用的深度学习方法进行了基准测试。本文的见解为裂缝检测领域的方法演变和未来方向提供了深入洞察。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习方法在裂缝检测中扮演重要角色，应用于民事基础设施的多个领域。</li>
<li>学习范式的转变是当前的趋势，包括从全监督学习到多种其他学习方式的转变。</li>
<li>泛化性能的改进使得模型能够在跨数据集评价中表现良好。</li>
<li>数据集采集方式的多样化，从RGB图像到基于特殊传感器的数据。</li>
<li>介绍了新的3D激光扫描数据集3DCrack，为未来的研究提供支持。</li>
<li>进行了广泛的基准测试实验，为常用的深度学习方法建立了基准。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10256">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_1_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2508.10256v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Sarc7-Evaluating-Sarcasm-Detection-and-Generation-with-Seven-Types-and-Emotion-Informed-Techniques"><a href="#Sarc7-Evaluating-Sarcasm-Detection-and-Generation-with-Seven-Types-and-Emotion-Informed-Techniques" class="headerlink" title="Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and   Emotion-Informed Techniques"></a>Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and   Emotion-Informed Techniques</h2><p><strong>Authors:Lang Xiong, Raina Gao, Alyssa Jeong, Yicheng Fu, Sean O’Brien, Vasu Sharma, Kevin Zhu</strong></p>
<p>Sarcasm is a form of humor where expressions convey meanings opposite to their literal interpretations. Classifying and generating sarcasm using large language models is vital for interpreting human communication. Sarcasm poses challenges for computational models, due to its nuanced nature. We introduce Sarc7, a benchmark that classifies 7 types of sarcasm: self-deprecating, brooding, deadpan, polite, obnoxious, raging, and manic by annotating entries of the MUStARD dataset. Classification was evaluated using zero-shot, few-shot, chain-of-thought (CoT), and a novel emotion-based prompting technique. We propose an emotion-based generation method developed by identifying key components of sarcasm-incongruity, shock value, and context dependency. Our classification experiments show that Gemini 2.5, using emotion-based prompting, outperforms other setups with an F1 score of 0.3664. Human evaluators preferred our emotion-based prompting, with 38.46% more successful generations than zero-shot prompting. </p>
<blockquote>
<p>讽刺是一种幽默形式，其表达的意思与其字面意思相反。使用大型语言模型对讽刺进行分类和生成，对于解释人类交流至关重要。由于讽刺具有微妙的性质，对计算模型来说构成了挑战。我们介绍了Sarc7，这是一个通过标注MUStARD数据集条目来分类7种讽刺类型的基准测试：自嘲、忧郁、面无表情、礼貌、令人不悦、愤怒和狂躁。分类评估使用了零样本、少样本、链式思维（CoT）和一种基于情绪的新型提示技术。我们提出了一种基于情绪的产生方法，该方法通过识别讽刺的关键成分——不一致性、冲击值和上下文依赖性而开发。我们的分类实验表明，使用基于情绪的提示的Gemini 2.5在F1分数上优于其他设置，达到了0.3664。人类评估者更喜欢我们的基于情绪的提示，其生成成功的比例比零样本提示高出38.46%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00658v3">PDF</a> Accepted to EMNLP WiNLP and COLM Melt, Solar, PragLM, and Origen</p>
<p><strong>Summary</strong></p>
<p>本文介绍了名为Sarc7的基准测试，该测试对7种不同类型的讽刺（包括自我贬低、阴郁、冷淡、礼貌、粗鲁、愤怒和狂热）进行了分类。文章还评估了零样本、少样本、思维链和基于情感提示的分类技术，并提出了一种基于情感的生成方法，通过识别讽刺的关键成分（如不一致性、震撼值和上下文依赖性）来生成内容。实验结果展示了使用情感提示的Gemini 2.5系统的优越性，其F1分数为0.3664。人类评估者也更倾向于使用基于情感的提示方法，其生成内容的成功率比零样本提示高出38.46%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sarc7是一个用于分类7种不同讽刺类型的基准测试。</li>
<li>文章评估了多种分类技术，包括零样本、少样本、思维链和基于情感提示的方法。</li>
<li>基于情感的生成方法通过识别讽刺的关键成分（如不一致性、震撼值和上下文依赖性）来生成内容。</li>
<li>Gemini 2.5系统使用情感提示取得了最佳分类效果，F1分数为0.3664。</li>
<li>人类评估者更倾向于基于情感的提示方法，其生成内容的成功率较高。</li>
<li>讽刺对计算模型构成挑战，因其具有微妙的特性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00658">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_3_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2506.00658v3/page_4_1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Benchmarking-Large-Language-Models-for-Cryptanalysis-and-Side-Channel-Vulnerabilities"><a href="#Benchmarking-Large-Language-Models-for-Cryptanalysis-and-Side-Channel-Vulnerabilities" class="headerlink" title="Benchmarking Large Language Models for Cryptanalysis and Side-Channel   Vulnerabilities"></a>Benchmarking Large Language Models for Cryptanalysis and Side-Channel   Vulnerabilities</h2><p><strong>Authors:Utsav Maskey, Chencheng Zhu, Usman Naseem</strong></p>
<p>Recent advancements in large language models (LLMs) have transformed natural language understanding and generation, leading to extensive benchmarking across diverse tasks. However, cryptanalysis - a critical area for data security and its connection to LLMs’ generalization abilities - remains underexplored in LLM evaluations. To address this gap, we evaluate the cryptanalytic potential of state-of-the-art LLMs on ciphertexts produced by a range of cryptographic algorithms. We introduce a benchmark dataset of diverse plaintexts, spanning multiple domains, lengths, writing styles, and topics, paired with their encrypted versions. Using zero-shot and few-shot settings along with chain-of-thought prompting, we assess LLMs’ decryption success rate and discuss their comprehension abilities. Our findings reveal key insights into LLMs’ strengths and limitations in side-channel scenarios and raise concerns about their susceptibility to under-generalization-related attacks. This research highlights the dual-use nature of LLMs in security contexts and contributes to the ongoing discussion on AI safety and security. </p>
<blockquote>
<p>近期大型语言模型（LLM）的进展已经改变了自然语言的理解和生成方式，并在各种任务上进行了广泛的基准测试。然而，在LLM评估中，密码分析作为一个对数据安全至关重要的领域以及其与LLM的泛化能力之间的联系仍然被探索得不够深入。为了弥补这一空白，我们评估了最先进的大型语言模型在由多种加密算法产生的密文上的密码分析潜力。我们引入了一个包含多种普通文本及其加密版本的基准数据集，这些普通文本跨越了多个领域、长度、写作风格和主题。通过使用零样本和少样本设置以及思维链提示，我们评估了LLM的解密成功率并讨论了它们的理解能力。我们的研究结果揭示了LLM在侧通道场景中的优势和局限性，并对它们容易受到与泛化不足相关的攻击表示担忧。该研究强调了LLM在安全上下文中的双重用途性质，并为关于人工智能安全和安全的持续讨论做出了贡献。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24621v2">PDF</a> EMNLP’25 Findings</p>
<p><strong>Summary</strong><br>大型语言模型（LLMs）在自然语言理解和生成方面的最新进展已经在各种任务上进行了广泛的基准测试。然而，对于数据安全和LLMs泛化能力的关键领域——密码分析，在LLM评估中仍然被忽视。本研究首次评估了最先进的LLMs在多种加密算法生成的密文上的密码分析潜力。通过引入包含多种领域的明文及其加密版本的基准数据集，本研究在零样本和少样本环境中评估LLMs的解密成功率，并讨论其理解能力。研究发现揭示了LLMs在侧信道场景下的优势和局限性，并对与泛化不足相关的攻击提出了担忧。本研究强调了LLMs在安全上下文中的双重用途性质，并为人工智能安全和安全性讨论做出了贡献。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）在自然语言理解和生成方面的能力已经得到广泛验证，但在密码分析领域的研究仍然不足。</li>
<li>研究者评估了LLMs在多种加密算法生成的密文上的密码分析潜力。</li>
<li>通过引入包含多种领域的明文及其加密版本的基准数据集，该研究评估了LLMs的解密能力。</li>
<li>研究发现揭示了LLMs在侧信道场景下的优势与局限性。</li>
<li>LLMs可能存在泛化不足的问题，容易受到某些攻击的影响。</li>
<li>此研究强调了LLMs在安全上下文中的双重用途性质，既可以用于安全目的，也可能被用于威胁安全的活动。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24621">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.24621v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MAFA-A-multi-agent-framework-for-annotation"><a href="#MAFA-A-multi-agent-framework-for-annotation" class="headerlink" title="MAFA: A multi-agent framework for annotation"></a>MAFA: A multi-agent framework for annotation</h2><p><strong>Authors:Mahmood Hegazy, Aaron Rodrigues, Azzam Naeem</strong></p>
<p>Modern consumer banking applications require accurate and efficient retrieval of information in response to user queries. Mapping user utterances to the most relevant Frequently Asked Questions (FAQs) is a crucial component of these systems. Traditional approaches often rely on a single model or technique, which may not capture the nuances of diverse user inquiries. In this paper, we introduce a multi-agent framework for FAQ annotation that combines multiple specialized agents with different approaches and a judge agent that reranks candidates to produce optimal results. Our agents utilize a structured reasoning approach inspired by Attentive Reasoning Queries (ARQs), which guides them through systematic reasoning steps using targeted, task-specific JSON queries. Our framework features a few-shot example strategy, where each agent receives different few-shots, enhancing ensemble diversity and coverage of the query space. We evaluate our framework on a real-world major bank dataset as well as public benchmark datasets (LCQMC and FiQA), demonstrating significant improvements over single-agent approaches across multiple metrics, including a 14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12% improvement in Mean Reciprocal Rank on our dataset, and similar gains on public benchmarks when compared with traditional and single-agent annotation techniques. Our framework is particularly effective at handling ambiguous queries, making it well-suited for deployment in production banking applications while showing strong generalization capabilities across different domains and languages. </p>
<blockquote>
<p>现代消费银行应用程序需要准确高效地检索用户查询的信息。将用户的话语映射到最相关的常见问题（FAQ）是这些系统的关键组成部分。传统方法通常依赖于单个模型或技术，这可能无法捕捉到各种用户查询的细微差别。在本文中，我们介绍了一种结合多个专业代理和法官代理进行重新排名的多智能体框架，以产生最佳结果的常见问题标注框架。我们的智能体利用受注意力推理查询（ARQ）启发的结构化推理方法，通过有针对性的任务特定JSON查询指导他们进行系统化的推理步骤。我们的框架采用少量示例策略，每个智能体接收不同的几个示例，增强了集体多样性和查询空间的覆盖性。我们在现实世界的某大银行数据集以及公共基准数据集（LCQMC和FiQA）上评估了我们的框架，与传统单智能体方法相比，在多个指标上取得了显著改进，包括准确率提高14%，前五个结果准确率提高18%，以及我们数据集上的平均倒数排名提高12%，并且在公共基准测试上与传统的单智能体标注技术相比也取得了类似的成果。我们的框架在处理模糊查询方面特别有效，因此非常适合在生产银行应用程序中部署，并且在不同领域和语言中显示出强大的泛化能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13668v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种多代理框架用于FAQ标注，结合了多个专业代理与不同方法和一个裁判代理进行重排，以产生最优结果。该框架采用受ARQ启发的结构化推理方法，通过目标化、任务特定的JSON查询引导系统推理步骤。框架采用少量样本策略，每个代理接收不同的样本，增强集合多样性和查询空间覆盖。在真实银行数据集和公共基准数据集上的评估表明，与传统和单一代理标注技术相比，该框架在多指标上实现了显著改进，包括Top-1准确率提高14%，Top-5准确率提高18%，以及数据集上的平均倒数排名改善12%。该框架特别擅长处理模糊查询，适用于生产环境中的银行业务应用，并在不同领域和语言中显示出强大的泛化能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种多代理框架用于FAQ标注，结合多种方法和一个裁判代理进行结果优化。</li>
<li>采用了受ARQ启发的结构化推理方法，通过任务特定JSON查询进行系统性推理。</li>
<li>框架采用少量样本策略，增强集合多样性和查询空间覆盖。</li>
<li>在真实银行数据集和公共基准数据集上的评估表现优异。</li>
<li>与传统和单一代理方法相比，该框架在多指标上实现了显著改进。</li>
<li>框架特别擅长处理模糊查询，适用于生产环境中的银行业务应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13668">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.13668v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.13668v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.13668v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.13668v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_Few-Shot/2505.13668v2/page_4_1.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-19/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_I2I Translation/2507.04758v2/page_3_0.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-09-19  Gaussian Alignment for Relative Camera Pose Estimation via Single-View   Reconstruction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-19/MMT/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-19\./crop_MMT/2506.07032v2/page_4_0.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-09-19  A Culturally-diverse Multilingual Multimodal Video Benchmark & Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30341.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
