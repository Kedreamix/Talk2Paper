<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-25  GRAND-SLAM Local Optimization for Globally Consistent Large-Scale   Multi-Agent Gaussian SLAM">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-d90e373654d245c35acece531a9185b7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-25-æ›´æ–°"><a href="#2025-06-25-æ›´æ–°" class="headerlink" title="2025-06-25 æ›´æ–°"></a>2025-06-25 æ›´æ–°</h1><h2 id="GRAND-SLAM-Local-Optimization-for-Globally-Consistent-Large-Scale-Multi-Agent-Gaussian-SLAM"><a href="#GRAND-SLAM-Local-Optimization-for-Globally-Consistent-Large-Scale-Multi-Agent-Gaussian-SLAM" class="headerlink" title="GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale   Multi-Agent Gaussian SLAM"></a>GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale   Multi-Agent Gaussian SLAM</h2><p><strong>Authors:Annika Thomas, Aneesa Sonawalla, Alex Rose, Jonathan P. How</strong></p>
<p>3D Gaussian splatting has emerged as an expressive scene representation for RGB-D visual SLAM, but its application to large-scale, multi-agent outdoor environments remains unexplored. Multi-agent Gaussian SLAM is a promising approach to rapid exploration and reconstruction of environments, offering scalable environment representations, but existing approaches are limited to small-scale, indoor environments. To that end, we propose Gaussian Reconstruction via Multi-Agent Dense SLAM, or GRAND-SLAM, a collaborative Gaussian splatting SLAM method that integrates i) an implicit tracking module based on local optimization over submaps and ii) an approach to inter- and intra-robot loop closure integrated into a pose-graph optimization framework. Experiments show that GRAND-SLAM provides state-of-the-art tracking performance and 28% higher PSNR than existing methods on the Replica indoor dataset, as well as 91% lower multi-agent tracking error and improved rendering over existing multi-agent methods on the large-scale, outdoor Kimera-Multi dataset. </p>
<blockquote>
<p>ä¸‰ç»´é«˜æ–¯æ’é“ºæŠ€æœ¯å·²å‘å±•ä¸ºRGB-Dè§†è§‰SLAMçš„ä¸€ç§è¡¨ç°ä¸°å¯Œçš„åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œä½†å…¶åœ¨å¤§è§„æ¨¡ã€å¤šæ™ºèƒ½ä½“å®¤å¤–ç¯å¢ƒçš„åº”ç”¨å°šæœªè¢«æ¢ç´¢ã€‚å¤šæ™ºèƒ½ä½“é«˜æ–¯SLAMæ˜¯ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œå¯ä»¥å¿«é€Ÿæ¢ç´¢å¹¶é‡å»ºç¯å¢ƒï¼Œæä¾›å¯æ‰©å±•çš„ç¯å¢ƒè¡¨ç¤ºï¼Œä½†ç°æœ‰æ–¹æ³•ä»…é™äºå°è§„æ¨¡å®¤å†…ç¯å¢ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¤šæ™ºèƒ½ä½“å¯†é›†SLAMçš„é«˜æ–¯é‡å»ºï¼ˆç®€ç§°GRAND-SLAMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åä½œå¼é«˜æ–¯æ’é“ºSLAMæ–¹æ³•ï¼Œå®ƒèåˆäº†i)åŸºäºå­å›¾å±€éƒ¨ä¼˜åŒ–çš„éšå¼è·Ÿè¸ªæ¨¡å—å’Œii)ä¸€ç§é›†æˆåˆ°å§¿æ€å›¾ä¼˜åŒ–æ¡†æ¶ä¸­çš„æœºå™¨äººå†…å¤–å›è·¯é—­åˆæ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼ŒGRAND-SLAMåœ¨Replicaå®¤å†…æ•°æ®é›†ä¸Šæä¾›äº†æœ€å…ˆè¿›çš„è·Ÿè¸ªæ€§èƒ½ï¼Œè¾ƒç°æœ‰æ–¹æ³•æé«˜äº†28%çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ï¼ŒåŒæ—¶åœ¨å¤§è§„æ¨¡å®¤å¤–Kimera-Multiæ•°æ®é›†ä¸Šï¼Œå¤šæ™ºèƒ½ä½“è·Ÿè¸ªè¯¯å·®é™ä½äº†91%ï¼Œæ¸²æŸ“æ•ˆæœä¹Ÿæœ‰æ‰€æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18885v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å°†å¤šæ™ºèƒ½ä½“é«˜æ–¯SLAMæŠ€æœ¯åº”ç”¨äºå¤§è§„æ¨¡æˆ·å¤–ç¯å¢ƒçš„é—®é¢˜ã€‚æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯å–·ç»˜çš„åä½œSLAMæ–¹æ³•â€”â€”GRAND-SLAMï¼Œå®ƒåœ¨å­å›¾å±€éƒ¨ä¼˜åŒ–åŸºç¡€ä¸Šå»ºç«‹äº†éšå¼è·Ÿè¸ªæ¨¡å—ï¼Œå¹¶å°†æœºå™¨äººé—´å’Œæœºå™¨äººå†…éƒ¨é—­ç¯é›†æˆåˆ°å§¿æ€å›¾ä¼˜åŒ–æ¡†æ¶ä¸­ã€‚å®éªŒè¡¨æ˜ï¼ŒGRAND-SLAMåœ¨Replicaå®¤å†…æ•°æ®é›†ä¸Šæä¾›äº†å…ˆè¿›çš„è·Ÿè¸ªæ€§èƒ½å’Œæ›´é«˜çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ï¼Œè€Œåœ¨å¤§è§„æ¨¡æˆ·å¤–Kimera-Multiæ•°æ®é›†ä¸Šï¼Œå…¶å¤šæ™ºèƒ½ä½“è·Ÿè¸ªè¯¯å·®é™ä½äº†91%ï¼Œæ¸²æŸ“æ•ˆæœä¹Ÿæœ‰æ‰€æ”¹å–„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé«˜æ–¯å–·ç»˜åœ¨RGB-Dè§†è§‰SLAMä¸­çš„åœºæ™¯è¡¨ç¤ºå¾—åˆ°äº†å‘å±•ï¼Œä½†å…¶åœ¨å¤šæ™ºèƒ½ä½“æˆ·å¤–å¤§è§„æ¨¡ç¯å¢ƒä¸­çš„åº”ç”¨å°šæœªå¾—åˆ°æ¢ç´¢ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“é«˜æ–¯SLAMæ˜¯å®ç°ç¯å¢ƒå¿«é€Ÿæ¢ç´¢å’Œé‡å»ºçš„æœ‰å‰é€”çš„æ–¹æ³•ï¼Œæä¾›å¯ä¼¸ç¼©çš„ç¯å¢ƒè¡¨ç¤ºã€‚</li>
<li>GRAND-SLAMæ˜¯ä¸€ç§åä½œå¼é«˜æ–¯å–·ç»˜SLAMæ–¹æ³•ï¼Œç»“åˆäº†éšå¼è·Ÿè¸ªæ¨¡å—å’Œå§¿æ€å›¾ä¼˜åŒ–æ¡†æ¶ä¸­çš„æœºå™¨äººé—´å’Œæœºå™¨äººå†…éƒ¨é—­ç¯æ–¹æ³•ã€‚</li>
<li>å®éªŒè¡¨æ˜GRAND-SLAMåœ¨è·Ÿè¸ªæ€§èƒ½å’Œå›¾åƒè´¨é‡æ–¹é¢è¾¾åˆ°äº†å…ˆè¿›æ°´å¹³ã€‚</li>
<li>GRAND-SLAMåœ¨å®¤å†…æ•°æ®é›†ä¸Šæä¾›äº†è¾ƒé«˜çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚</li>
<li>åœ¨æˆ·å¤–å¤§è§„æ¨¡æ•°æ®é›†ä¸Šï¼ŒGRAND-SLAMçš„å¤šæ™ºèƒ½ä½“è·Ÿè¸ªè¯¯å·®è¾ƒä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18885">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9054e4c345eab596e4d061bbe486775d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52b9af6db973294039e24f9bc0227e29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba88ddff43ef2cbb13b015a13ea93a22.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c18cbcbfe3e922ebae7c3b5dfff30d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-781a0fd4554b18bebacec2c65e9509d2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="4Real-Video-V2-Fused-View-Time-Attention-and-Feedforward-Reconstruction-for-4D-Scene-Generation"><a href="#4Real-Video-V2-Fused-View-Time-Attention-and-Feedforward-Reconstruction-for-4D-Scene-Generation" class="headerlink" title="4Real-Video-V2: Fused View-Time Attention and Feedforward Reconstruction   for 4D Scene Generation"></a>4Real-Video-V2: Fused View-Time Attention and Feedforward Reconstruction   for 4D Scene Generation</h2><p><strong>Authors:Chaoyang Wang, Ashkan Mirzaei, Vidit Goel, Willi Menapace, Aliaksandr Siarohin, Avalon Vinella, Michael Vasilkovsky, Ivan Skorokhodov, Vladislav Shakhrai, Sergey Korolev, Sergey Tulyakov, Peter Wonka</strong></p>
<p>We propose the first framework capable of computing a 4D spatio-temporal grid of video frames and 3D Gaussian particles for each time step using a feed-forward architecture. Our architecture has two main components, a 4D video model and a 4D reconstruction model. In the first part, we analyze current 4D video diffusion architectures that perform spatial and temporal attention either sequentially or in parallel within a two-stream design. We highlight the limitations of existing approaches and introduce a novel fused architecture that performs spatial and temporal attention within a single layer. The key to our method is a sparse attention pattern, where tokens attend to others in the same frame, at the same timestamp, or from the same viewpoint. In the second part, we extend existing 3D reconstruction algorithms by introducing a Gaussian head, a camera token replacement algorithm, and additional dynamic layers and training. Overall, we establish a new state of the art for 4D generation, improving both visual quality and reconstruction capability. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé¦–åˆ›çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨å‰é¦ˆæ¶æ„è®¡ç®—è§†é¢‘å¸§çš„4Dæ—¶ç©ºç½‘æ ¼å’Œæ¯ä¸ªæ—¶é—´æ­¥çš„3Dé«˜æ–¯ç²’å­ã€‚æˆ‘ä»¬çš„æ¶æ„ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªéƒ¨åˆ†ï¼š4Dè§†é¢‘æ¨¡å‹å’Œ4Dé‡å»ºæ¨¡å‹ã€‚ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬åˆ†æäº†å½“å‰çš„4Dè§†é¢‘æ‰©æ•£æ¶æ„ï¼Œè¿™äº›æ¶æ„åœ¨ä¸¤æµè®¾è®¡ä¸­æŒ‰é¡ºåºæˆ–å¹¶è¡Œæ‰§è¡Œç©ºé—´å’Œæ—¶é—´æ³¨æ„åŠ›ã€‚æˆ‘ä»¬å¼ºè°ƒäº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶ä»‹ç»äº†ä¸€ç§æ–°å‹èåˆæ¶æ„ï¼Œè¯¥æ¶æ„èƒ½åœ¨å•ä¸ªå›¾å±‚å†…æ‰§è¡Œç©ºé—´å’Œæ—¶é—´æ³¨æ„åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å…³é”®åœ¨äºç¨€ç–æ³¨æ„åŠ›æ¨¡å¼ï¼Œå…¶ä¸­æ ‡è®°ä¼šåœ¨åŒä¸€å¸§ã€åŒä¸€æ—¶é—´æˆ³æˆ–åŒä¸€è§‚ç‚¹ä¸­å…³æ³¨å…¶ä»–æ ‡è®°ã€‚åœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥é«˜æ–¯å¤´ã€ç›¸æœºæ ‡è®°æ›¿æ¢ç®—æ³•ä»¥åŠé¢å¤–çš„åŠ¨æ€å±‚å’Œè®­ç»ƒï¼Œæ‰©å±•äº†ç°æœ‰çš„3Dé‡å»ºç®—æ³•ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨4Dç”Ÿæˆæ–¹é¢å»ºç«‹äº†æ–°çš„æŠ€æœ¯æ ‡æ†ï¼Œæé«˜äº†è§†è§‰è´¨é‡å’Œé‡å»ºèƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18839v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18839">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-21331c4516bb796ce162976795bdebc0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d90e373654d245c35acece531a9185b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-534e59ec77665fbdef32247ea2a7e2be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b63a269dbebf14c1f93bdc690adf6799.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc66480e0476bec25487e82f172e10bf.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="ViDAR-Video-Diffusion-Aware-4D-Reconstruction-From-Monocular-Inputs"><a href="#ViDAR-Video-Diffusion-Aware-4D-Reconstruction-From-Monocular-Inputs" class="headerlink" title="ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs"></a>ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs</h2><p><strong>Authors:Michal Nazarczuk, Sibi Catley-Chandar, Thomas Tanay, Zhensong Zhang, Gregory Slabaugh, Eduardo PÃ©rez-Pellitero</strong></p>
<p>Dynamic Novel View Synthesis aims to generate photorealistic views of moving subjects from arbitrary viewpoints. This task is particularly challenging when relying on monocular video, where disentangling structure from motion is ill-posed and supervision is scarce. We introduce Video Diffusion-Aware Reconstruction (ViDAR), a novel 4D reconstruction framework that leverages personalised diffusion models to synthesise a pseudo multi-view supervision signal for training a Gaussian splatting representation. By conditioning on scene-specific features, ViDAR recovers fine-grained appearance details while mitigating artefacts introduced by monocular ambiguity. To address the spatio-temporal inconsistency of diffusion-based supervision, we propose a diffusion-aware loss function and a camera pose optimisation strategy that aligns synthetic views with the underlying scene geometry. Experiments on DyCheck, a challenging benchmark with extreme viewpoint variation, show that ViDAR outperforms all state-of-the-art baselines in visual quality and geometric consistency. We further highlight ViDARâ€™s strong improvement over baselines on dynamic regions and provide a new benchmark to compare performance in reconstructing motion-rich parts of the scene. Project page: <a target="_blank" rel="noopener" href="https://vidar-4d.github.io/">https://vidar-4d.github.io</a> </p>
<blockquote>
<p>åŠ¨æ€åœºæ™¯æ–°é¢–è§†è§’åˆæˆæ—¨åœ¨ä»ä»»æ„è§†è§’ç”ŸæˆåŠ¨æ€ç‰©ä½“çš„é€¼çœŸçš„è§†å›¾ã€‚å½“ä¾èµ–å•ç›®è§†é¢‘æ—¶ï¼Œè¿™ä¸ªä»»åŠ¡å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå…¶ä¸­ä»è¿åŠ¨ä¸­åˆ†ç¦»ç»“æ„çš„é—®é¢˜è¡¨è¿°ä¸æ¸…ï¼Œå¹¶ä¸”ç¼ºä¹ç›‘ç£ä¿¡æ¯ã€‚æˆ‘ä»¬å¼•å…¥äº†è§†é¢‘æ‰©æ•£æ„ŸçŸ¥é‡å»ºï¼ˆViDARï¼‰è¿™ä¸€æ–°é¢–çš„å››ç»´é‡å»ºæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹åˆæˆä¸€ä¸ªä¼ªå¤šè§†è§’ç›‘ç£ä¿¡å·æ¥è®­ç»ƒé«˜æ–¯è´´å›¾è¡¨ç¤ºã€‚é€šè¿‡åœºæ™¯ç‰¹å®šç‰¹å¾çš„è°ƒèŠ‚ï¼ŒViDARå¯ä»¥æ¢å¤ç²¾ç»†çš„å¤–è§‚ç»†èŠ‚ï¼ŒåŒæ—¶å‡å°‘ç”±å•ç›®æ¨¡ç³Šæ€§å¼•èµ·çš„ä¼ªå½±ã€‚ä¸ºäº†è§£å†³åŸºäºæ‰©æ•£çš„ç›‘ç£åœ¨æ—¶ç©ºä¸Šä¸ä¸€è‡´çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ‰©æ•£æ„ŸçŸ¥çš„æŸå¤±å‡½æ•°å’Œæ‘„åƒæœºå§¿æ€ä¼˜åŒ–ç­–ç•¥ï¼Œä½¿åˆæˆè§†å›¾ä¸åº•å±‚åœºæ™¯å‡ ä½•å¯¹é½ã€‚åœ¨å…·æœ‰æç«¯è§†è§’å˜åŒ–çš„æŒ‘æˆ˜åŸºå‡†æ•°æ®é›†DyCheckä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒViDARåœ¨è§†è§‰è´¨é‡å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºæ‰€æœ‰æœ€æ–°åŸºçº¿æŠ€æœ¯ã€‚æˆ‘ä»¬è¿˜é‡ç‚¹ä»‹ç»äº†ViDARåœ¨åŠ¨æ€åŒºåŸŸçš„æ”¹è¿›æ•ˆæœï¼Œå¹¶æä¾›äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æ•°æ®é›†æ¥æ¯”è¾ƒé‡å»ºè¿åŠ¨ä¸°å¯Œåœºæ™¯éƒ¨åˆ†çš„æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://vidar-4d.github.io/">https://vidar-4d.github.io</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18792v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŠ¨æ€åœºæ™¯çš„æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯æ—¨åœ¨ä»ä»»æ„è§†è§’ç”Ÿæˆé€¼çœŸçš„ç§»åŠ¨ç‰©ä½“è§†å›¾ã€‚è¿™é¡¹ä»»åŠ¡åœ¨ä¾èµ–å•ç›®è§†é¢‘æ—¶å°¤ä¸ºå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºéœ€è¦ä»è¿åŠ¨ä¸­åˆ†ç¦»ç»“æ„æ˜¯éš¾åº¦å¾ˆå¤§ä¸”ç¼ºä¹ç›‘ç£ã€‚æˆ‘ä»¬å¼•å…¥äº†Video Diffusion-Aware Reconstructionï¼ˆViDARï¼‰è¿™ä¸€æ–°å‹4Dé‡å»ºæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹åˆæˆä¼ªå¤šè§†å›¾ç›‘ç£ä¿¡å·æ¥è®­ç»ƒé«˜æ–¯å±•å¸ƒè¡¨ç¤ºã€‚é€šè¿‡åœºæ™¯ç‰¹å®šç‰¹å¾çš„æ¡ä»¶è®¾å®šï¼ŒViDARåœ¨ç»†åŒ–çº¹ç†ç»†èŠ‚çš„åŒæ—¶ï¼Œå‡å°‘äº†å› å•ç›®æ­§ä¹‰äº§ç”Ÿçš„ä¼ªåƒã€‚ä¸ºè§£å†³æ‰©æ•£ç›‘ç£çš„æ—¶ç©ºä¸ä¸€è‡´é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ‰©æ•£æ„ŸçŸ¥çš„æŸå¤±å‡½æ•°å’Œç›¸æœºå§¿æ€ä¼˜åŒ–ç­–ç•¥ï¼Œä½¿åˆæˆè§†å›¾ä¸åº•å±‚åœºæ™¯å‡ ä½•å¯¹é½ã€‚åœ¨å…·æœ‰æç«¯è§†è§’å˜åŒ–çš„DyCheckåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒViDARåœ¨è§†è§‰è´¨é‡å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºæ‰€æœ‰æœ€æ–°åŸºçº¿æŠ€æœ¯ã€‚æˆ‘ä»¬è¿˜é‡ç‚¹ä»‹ç»äº†ViDARåœ¨åŠ¨æ€åŒºåŸŸçš„æ˜¾è‘—æ”¹è¿›å¹¶æä¾›äº†ä¸€ä¸ªæ–°åŸºå‡†ï¼Œä»¥æ¯”è¾ƒé‡å»ºè¿åŠ¨ä¸°å¯ŒåŒºåŸŸæ€§èƒ½çš„æ¯”è¾ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Dynamic Novel View Synthesis æ—¨åœ¨ä»ä»»æ„è§†è§’ç”Ÿæˆç§»åŠ¨ç‰©ä½“çš„é€¼çœŸè§†å›¾ã€‚</li>
<li>Video Diffusion-Aware Reconstructionï¼ˆViDARï¼‰æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œå®ƒè§£å†³äº†å•ç›®è§†é¢‘ä¸­çš„ç»“æ„è¿åŠ¨åˆ†ç¦»é—®é¢˜ã€‚</li>
<li>ViDAR åˆ©ç”¨ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹åˆæˆä¼ªå¤šè§†å›¾ç›‘ç£ä¿¡å·è¿›è¡Œè®­ç»ƒã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ç‰¹å®šåœºæ™¯ç‰¹å¾çš„æ¡ä»¶è®¾å®šæ¢å¤ç»†èŠ‚å¹¶å‡å°‘ä¼ªåƒã€‚</li>
<li>ä¸ºè§£å†³æ—¶ç©ºä¸ä¸€è‡´é—®é¢˜ï¼Œæå‡ºäº†æ‰©æ•£æ„ŸçŸ¥æŸå¤±å‡½æ•°å’Œç›¸æœºå§¿æ€ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>ViDAR åœ¨DyCheckåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æœ€æ–°æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18792">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d0a0b3fd48a2ccf39be5fcb3a225272.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f7215338ae3f011dc8e1b71c23080f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78ac46571764f0c01d41ad0658a8af1f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="3D-Arena-An-Open-Platform-for-Generative-3D-Evaluation"><a href="#3D-Arena-An-Open-Platform-for-Generative-3D-Evaluation" class="headerlink" title="3D Arena: An Open Platform for Generative 3D Evaluation"></a>3D Arena: An Open Platform for Generative 3D Evaluation</h2><p><strong>Authors:Dylan Ebert</strong></p>
<p>Evaluating Generative 3D models remains challenging due to misalignment between automated metrics and human perception of quality. Current benchmarks rely on image-based metrics that ignore 3D structure or geometric measures that fail to capture perceptual appeal and real-world utility. To address this gap, we present 3D Arena, an open platform for evaluating image-to-3D generation models through large-scale human preference collection using pairwise comparisons.   Since launching in June 2024, the platform has collected 123,243 votes from 8,096 users across 19 state-of-the-art models, establishing the largest human preference evaluation for Generative 3D. We contribute the iso3d dataset of 100 evaluation prompts and demonstrate quality control achieving 99.75% user authenticity through statistical fraud detection. Our ELO-based ranking system provides reliable model assessment, with the platform becoming an established evaluation resource.   Through analysis of this preference data, we present insights into human preference patterns. Our findings reveal preferences for visual presentation features, with Gaussian splat outputs achieving a 16.6 ELO advantage over meshes and textured models receiving a 144.1 ELO advantage over untextured models. We provide recommendations for improving evaluation methods, including multi-criteria assessment, task-oriented evaluation, and format-aware comparison. The platformâ€™s community engagement establishes 3D Arena as a benchmark for the field while advancing understanding of human-centered evaluation in Generative 3D. </p>
<blockquote>
<p>å¯¹ç”Ÿæˆå¼3Dæ¨¡å‹çš„è¯„ä¼°ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè‡ªåŠ¨åº¦é‡æŒ‡æ ‡ä¸äººç±»å¯¹è´¨é‡çš„æ„ŸçŸ¥ä¹‹é—´å­˜åœ¨ä¸åŒ¹é…ã€‚ç›®å‰çš„åŸºå‡†æµ‹è¯•ä¾èµ–äºåŸºäºå›¾åƒçš„åº¦é‡æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡å¿½ç•¥äº†3Dç»“æ„æˆ–å‡ ä½•åº¦é‡ï¼Œè€Œè¿™äº›åº¦é‡æŒ‡æ ‡åˆæ— æ³•æ•æ‰æ„ŸçŸ¥æ•ˆæœå’Œç°å®ä¸–ç•Œçš„å®ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†åä¸ºâ€œä¸‰ç»´ç«æŠ€åœºâ€ï¼ˆ3D Arenaï¼‰çš„å¼€æ”¾å¹³å°ï¼Œè¯¥å¹³å°é€šè¿‡æˆå¯¹çš„æ¯”è¾ƒæ¥è¯„ä¼°å›¾åƒåˆ°ä¸‰ç»´ç”Ÿæˆæ¨¡å‹çš„å¤§è§„æ¨¡äººç±»åå¥½æ”¶é›†ã€‚è‡ª2024å¹´6æœˆä¸Šçº¿ä»¥æ¥ï¼Œè¯¥å¹³å°å·²ä»è¶…è¿‡å…«åƒåç”¨æˆ·æ”¶é›†äº†è¶…è¿‡åäºŒä¸‡ä¸‰åƒäºŒç™¾å››åä¸‰ç¥¨çš„æ•°æ®ï¼Œæ¶µç›–äº†åä¹ç§æœ€æ–°æ¨¡å‹ï¼Œæˆä¸ºç”Ÿæˆå¼ä¸‰ç»´é¢†åŸŸæœ€å¤§çš„åŸºäºäººç±»åå¥½çš„è¯„ä¼°ã€‚æˆ‘ä»¬è´¡çŒ®äº†iso3dæ•°æ®é›†çš„ä¸€ç™¾ä¸ªè¯„ä¼°æç¤ºï¼Œå¹¶é€šè¿‡ç»Ÿè®¡æ¬ºè¯ˆæ£€æµ‹å®ç°äº†å¯¹ç”¨æˆ·çœŸå®æ€§çš„æ§åˆ¶ï¼Œè¾¾åˆ°ç™¾åˆ†ä¹‹ä¹åä¹ç‚¹ä¸ƒäº”çš„å¯é æ€§ã€‚æˆ‘ä»¬çš„åŸºäºELOçš„æ’åç³»ç»Ÿæä¾›äº†å¯é çš„æ¨¡å‹è¯„ä¼°åŠŸèƒ½ï¼Œä½¿å¾—è¯¥å¹³å°æˆä¸ºé‡è¦çš„è¯„ä¼°èµ„æºã€‚é€šè¿‡å¯¹è¿™äº›åå¥½æ•°æ®çš„åˆ†æï¼Œæˆ‘ä»¬æ·±å…¥äº†è§£äº†äººç±»åå¥½æ¨¡å¼ã€‚æˆ‘ä»¬å‘ç°é«˜æ–¯å±•å¸ƒè¾“å‡ºå½¢å¼åœ¨æ¨¡å‹ä¸­å æ®ä¼˜åŠ¿åœ°ä½ï¼Œæ‹¥æœ‰é«˜è¾¾åå…­ç‚¹å…­çš„ELOä¼˜åŠ¿ï¼Œç½‘æ ¼å½¢å¼ç›¸è¾ƒä¹‹ä¸‹é€Šè‰²ä¸å°‘ï¼›çº¹ç†æ¨¡å‹åœ¨æ— çº¹ç†æ¨¡å‹ä¸­æ‹¥æœ‰é«˜è¾¾ä¸€ç™¾å››åå››ç‚¹ä¸€çš„ELOä¼˜åŠ¿ã€‚æˆ‘ä»¬ä¸ºæ”¹è¿›è¯„ä¼°æ–¹æ³•æä¾›äº†å»ºè®®ï¼ŒåŒ…æ‹¬å¤šæ ‡å‡†è¯„ä¼°ã€é¢å‘ä»»åŠ¡çš„è¯„ä¼°å’Œæ ¼å¼æ„ŸçŸ¥æ¯”è¾ƒç­‰ã€‚å¹³å°ç¤¾åŒºå‚ä¸åº¦æå‡äº†ä¸‰ç»´ç«æŠ€åœºåœ¨è¯¥é¢†åŸŸçš„åœ°ä½ï¼Œå¹¶æ¨åŠ¨äº†ç”Ÿæˆå¼ä¸‰ç»´é¢†åŸŸä¸­ä»¥äººä¸ºä¸­å¿ƒè¯„ä¼°çš„ç†è§£å’Œå‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18787v1">PDF</a> 9 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¯„ä¼°ç”Ÿæˆå¼3Dæ¨¡å‹çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºä¸€ä¸ªå¼€æ”¾å¹³å°3D Arenaæ¥è¯„ä¼°å›¾åƒåˆ°3Dç”Ÿæˆæ¨¡å‹ã€‚å¹³å°é€šè¿‡å¤§è§„æ¨¡çš„äººç±»åå¥½æ”¶é›†ï¼Œä½¿ç”¨æˆå¯¹æ¯”è¾ƒæ–¹å¼ï¼Œè‡ª2024å¹´6æœˆä¸Šçº¿ä»¥æ¥ï¼Œå·²æ”¶é›†æ¥è‡ª8096åç”¨æˆ·çš„123243å¼ æŠ•ç¥¨ï¼Œå»ºç«‹äº†æœ€å¤§çš„ç”Ÿæˆå¼3Däººç±»åå¥½è¯„ä¼°æ•°æ®é›†ã€‚åŒæ—¶ï¼Œä»‹ç»äº†iso3dæ•°æ®é›†å’Œè´¨é‡æ§åˆ¶æªæ–½ã€‚é€šè¿‡å¯¹åå¥½æ•°æ®çš„åˆ†æï¼Œæ­ç¤ºäº†äººç±»å¯¹è§†è§‰å‘ˆç°ç‰¹å¾ç­‰çš„åå¥½ï¼Œå¹¶ä¸ºæ”¹è¿›è¯„ä»·æ–¹æ³•æä¾›äº†å»ºè®®ã€‚æœ€åï¼Œå¼ºè°ƒäº†å¹³å°ä½œä¸ºç¤¾åŒºå‚ä¸è€…çš„ä½œç”¨åŠå…¶å¯¹ç”Ÿæˆå¼3Dé¢†åŸŸçš„å½±å“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯„ä¼°ç”Ÿæˆå¼3Dæ¨¡å‹å­˜åœ¨æŒ‘æˆ˜ï¼Œå› ä¸ºè‡ªåŠ¨åŒ–æŒ‡æ ‡ä¸äººç±»æ„ŸçŸ¥è´¨é‡çš„å·®å¼‚ã€‚</li>
<li>å½“å‰åŸºå‡†æµ‹è¯•æ–¹æ³•å­˜åœ¨ç¼ºé™·ï¼Œå¿½ç•¥äº†3Dç»“æ„æˆ–æ— æ³•æ•æ‰æ„ŸçŸ¥é­…åŠ›å’Œç°å®ä¸–ç•Œçš„å®ç”¨æ€§ã€‚</li>
<li>ä»‹ç»äº†æ–°çš„è¯„ä¼°å¹³å°3D Arenaï¼Œé€šè¿‡å¤§è§„æ¨¡çš„äººç±»åå¥½æ”¶é›†æ¥è¯„ä¼°å›¾åƒåˆ°3Dçš„ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>å¹³å°å·²æ”¶é›†å¤§é‡æ•°æ®ï¼Œå»ºç«‹äº†æœ€å¤§çš„ç”Ÿæˆå¼3Däººç±»åå¥½è¯„ä¼°æ•°æ®é›†ã€‚</li>
<li>é€šè¿‡ç»Ÿè®¡æ¬ºè¯ˆæ£€æµ‹å®ç°äº†ç”¨æˆ·çœŸå®æ€§çš„é«˜è´¨é‡æ§åˆ¶ã€‚</li>
<li>å¹³å°æ­ç¤ºäº†äººç±»å¯¹è§†è§‰å‘ˆç°ç‰¹å¾çš„åå¥½ï¼Œå¦‚Gaussian splatè¾“å‡ºçš„ä¼˜åŠ¿ã€‚</li>
<li>å¹³å°ä¸ºæ”¹è¿›è¯„ä»·æ–¹æ³•æä¾›äº†å»ºè®®ï¼Œå¦‚å¤šæ ‡å‡†è¯„ä¼°ã€ä»»åŠ¡å¯¼å‘è¯„ä¼°å’Œæ ¼å¼æ„ŸçŸ¥æ¯”è¾ƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18787">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b9f36284e73468cf8f246668fa5b8f66.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6ffbef304d0d8cc44495f1a0684b85eb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8deef79daf7b502e8a1a74e25b85f250.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="2D-Triangle-Splatting-for-Direct-Differentiable-Mesh-Training"><a href="#2D-Triangle-Splatting-for-Direct-Differentiable-Mesh-Training" class="headerlink" title="2D Triangle Splatting for Direct Differentiable Mesh Training"></a>2D Triangle Splatting for Direct Differentiable Mesh Training</h2><p><strong>Authors:Kaifeng Sheng, Zheng Zhou, Yingliang Peng, Qianwei Wang</strong></p>
<p>Differentiable rendering with 3D Gaussian primitives has emerged as a powerful method for reconstructing high-fidelity 3D scenes from multi-view images. While it offers improvements over NeRF-based methods, this representation still encounters challenges with rendering speed and advanced rendering effects, such as relighting and shadow rendering, compared to mesh-based models. In this paper, we propose 2D Triangle Splatting (2DTS), a novel method that replaces 3D Gaussian primitives with 2D triangle facelets. This representation naturally forms a discrete mesh-like structure while retaining the benefits of continuous volumetric modeling. By incorporating a compactness parameter into the triangle primitives, we enable direct training of photorealistic meshes. Our experimental results demonstrate that our triangle-based method, in its vanilla version (without compactness tuning), achieves higher fidelity compared to state-of-the-art Gaussian-based methods. Furthermore, our approach produces reconstructed meshes with superior visual quality compared to existing mesh reconstruction methods. </p>
<blockquote>
<p>ä½¿ç”¨ä¸‰ç»´é«˜æ–¯åŸå§‹æ•°æ®çš„å¯å¾®åˆ†æ¸²æŸ“å·²ç»æˆä¸ºä»å¤šè§†è§’å›¾åƒé‡å»ºé«˜ä¿çœŸä¸‰ç»´åœºæ™¯çš„ä¸€ç§å¼ºå¤§æ–¹æ³•ã€‚è™½ç„¶å®ƒåœ¨åŸºäºNeRFçš„æ–¹æ³•çš„åŸºç¡€ä¸Šæœ‰æ‰€æ”¹è¿›ï¼Œä½†è¿™ç§è¡¨ç¤ºæ–¹æ³•ä»ç„¶é¢ä¸´æ¸²æŸ“é€Ÿåº¦å’ŒåŸºäºç½‘æ ¼æ¨¡å‹çš„å…ˆè¿›æ¸²æŸ“æ•ˆæœï¼ˆå¦‚é‡æ–°ç…§æ˜å’Œé˜´å½±æ¸²æŸ“ï¼‰çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†äºŒç»´ä¸‰è§’å‰–åˆ†ï¼ˆ2DTSï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œç”¨äºŒç»´ä¸‰è§’å½¢é¢ç‰‡ä»£æ›¿ä¸‰ç»´é«˜æ–¯åŸå§‹æ•°æ®ã€‚è¿™ç§è¡¨ç¤ºæ–¹æ³•èƒ½å¤Ÿè‡ªç„¶åœ°å½¢æˆç¦»æ•£ç½‘æ ¼çŠ¶ç»“æ„ï¼ŒåŒæ—¶ä¿ç•™è¿ç»­ä½“ç§¯å»ºæ¨¡çš„ä¼˜ç‚¹ã€‚é€šè¿‡å°†ç´§å‡‘å‚æ•°èå…¥ä¸‰è§’å½¢åŸå§‹æ•°æ®ä¸­ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®ç°å…‰æ …åŒ–ç½‘æ ¼çš„ç›´æ¥è®­ç»ƒã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åŸºäºä¸‰è§’å½¢çš„æ–¹æ³•åœ¨åŸºç¡€ç‰ˆæœ¬ï¼ˆæ— ç´§å‡‘æ€§è°ƒæ•´ï¼‰ä¸­å®ç°äº†ä¸æœ€å…ˆè¿›çš„é«˜æ–¯æ–¹æ³•ç›¸æ¯”æ›´é«˜çš„ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„é‡å»ºç½‘æ ¼åœ¨è§†è§‰è´¨é‡ä¸Šä¼˜äºç°æœ‰çš„ç½‘æ ¼é‡å»ºæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18575v1">PDF</a> 13 pages, 8 figures</p>
<p><strong>Summary</strong><br>åŸºäºäºŒç»´ä¸‰è§’å‰–åˆ†æŠ€æœ¯çš„å¯å¾®æ¸²æŸ“æ–¹æ³•å·²ç»å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿä»å¤šè§†è§’å›¾åƒé‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯ã€‚ç›¸è¾ƒäºåŸºäºé«˜æ–¯åŸè¯­çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“é€Ÿåº¦å’Œé«˜çº§æ¸²æŸ“æ•ˆæœæ–¹é¢æ›´å…·ä¼˜åŠ¿ï¼Œå¦‚é‡æ–°æ‰“å…‰ä¸é˜´å½±æ¸²æŸ“ç­‰ã€‚ç›¸è¾ƒäºåŸºäºç½‘æ ¼çš„æ¨¡å‹ï¼Œæœ¬æ–‡æå‡ºçš„åŸºäºäºŒç»´ä¸‰è§’å‰–åˆ†ï¼ˆ2DTSï¼‰çš„æ–°æ–¹æ³•ä»¥äºŒç»´ä¸‰è§’é¢ç‰‡æ›¿ä»£ä¸‰ç»´é«˜æ–¯åŸè¯­ï¼Œæ—¢ä¿ç•™äº†è¿ç»­ä½“ç§¯å»ºæ¨¡çš„ä¼˜åŠ¿ï¼Œåˆè‡ªç„¶å½¢æˆäº†ç¦»æ•£ç½‘æ ¼ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ— éœ€ç´§å‡‘åº¦è°ƒæ•´çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•ç›¸è¾ƒäºå…¶ä»–åŸºäºé«˜æ–¯çš„æ–¹æ³•èƒ½å¤Ÿå®ç°æ›´é«˜çš„ä¿çœŸåº¦ï¼Œå¹¶ç”Ÿæˆå…·æœ‰ä¼˜è‰¯è§†è§‰è´¨é‡çš„é‡å»ºç½‘æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯å¾®æ¸²æŸ“æ–¹æ³•å·²ç»å‘å±•æˆä¸ºé‡å»ºé«˜è´¨é‡ä¸‰ç»´åœºæ™¯çš„å¼ºå¤§å·¥å…·ï¼Œèƒ½å¤Ÿä½¿ç”¨äºŒç»´ä¸‰è§’å‰–åˆ†æŠ€æœ¯è¿›è¡Œå›¾åƒæ¸²æŸ“å’Œé‡å»ºã€‚</li>
<li>äºŒç»´ä¸‰è§’å‰–åˆ†æ–¹æ³•å…‹æœäº†åŸºäºé«˜æ–¯åŸè¯­æ–¹æ³•çš„æŸäº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ›´å¿«çš„æ¸²æŸ“é€Ÿåº¦å’Œæ›´é«˜çº§åˆ«çš„æ¸²æŸ“æ•ˆæœã€‚</li>
<li>ä¸å…¶ä»–ç½‘æ ¼é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼ŒäºŒç»´ä¸‰è§’å‰–åˆ†æ–¹æ³•ç”Ÿæˆçš„é‡å»ºç½‘æ ¼å…·æœ‰æ›´é«˜çš„è§†è§‰è´¨é‡ã€‚</li>
<li>é€šè¿‡å¼•å…¥ç´§å‡‘åº¦å‚æ•°ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¿æŒè¿ç»­ä½“ç§¯å»ºæ¨¡ä¼˜åŠ¿çš„åŒæ—¶å½¢æˆç¦»æ•£ç½‘æ ¼ç»“æ„ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¸è°ƒæ•´ç´§å‡‘åº¦çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•ç›¸è¾ƒäºå…¶ä»–åŸºäºé«˜æ–¯çš„æ–¹æ³•å…·æœ‰æ›´é«˜çš„ä¿çœŸåº¦ã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›äº†å¯¹ä¼ ç»Ÿç½‘æ ¼å»ºæ¨¡æ–¹æ³•çš„æ”¹è¿›ï¼Œå®ç°äº†æ›´å¥½çš„å›¾åƒé‡å»ºæ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18575">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-67c31ca5a958f891df0a70b10d1af191.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c622d0cf74a34f589b40161f87f0f35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edd1485fbf7329d6942e201c5f8d0f62.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ef027bfadb5dc3fb90e68352ae1d44d3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Splatting-for-Fine-Detailed-Surface-Reconstruction-in-Large-Scale-Scene"><a href="#3D-Gaussian-Splatting-for-Fine-Detailed-Surface-Reconstruction-in-Large-Scale-Scene" class="headerlink" title="3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in   Large-Scale Scene"></a>3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in   Large-Scale Scene</h2><p><strong>Authors:Shihan Chen, Zhaojin Li, Zeyu Chen, Qingsong Yan, Gaoyang Shen, Ran Duan</strong></p>
<p>Recent developments in 3D Gaussian Splatting have made significant advances in surface reconstruction. However, scaling these methods to large-scale scenes remains challenging due to high computational demands and the complex dynamic appearances typical of outdoor environments. These challenges hinder the application in aerial surveying and autonomous driving. This paper proposes a novel solution to reconstruct large-scale surfaces with fine details, supervised by full-sized images. Firstly, we introduce a coarse-to-fine strategy to reconstruct a coarse model efficiently, followed by adaptive scene partitioning and sub-scene refining from image segments. Additionally, we integrate a decoupling appearance model to capture global appearance variations and a transient mask model to mitigate interference from moving objects. Finally, we expand the multi-view constraint and introduce a single-view regularization for texture-less areas. Our experiments were conducted on the publicly available dataset GauU-Scene V2, which was captured using unmanned aerial vehicles. To the best of our knowledge, our method outperforms existing NeRF-based and Gaussian-based methods, achieving high-fidelity visual results and accurate surface from full-size image optimization. Open-source code will be available on GitHub. </p>
<blockquote>
<p>åœ¨ä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3D Gaussian Splattingï¼‰çš„æœ€æ–°å‘å±•ä¸­ï¼Œè¡¨é¢é‡å»ºæŠ€æœ¯å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºå®¤å¤–ç¯å¢ƒçš„é«˜è®¡ç®—éœ€æ±‚å’Œå¤æ‚çš„åŠ¨æ€å¤–è§‚ï¼Œå°†è¿™äº›æ–¹æ³•æ‰©å±•åˆ°å¤§è§„æ¨¡åœºæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™äº›æŒ‘æˆ˜é˜»ç¢äº†å…¶åœ¨èˆªç©ºå‹˜å¯Ÿå’Œè‡ªåŠ¨é©¾é©¶ä¸­çš„åº”ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”±å…¨å°ºå¯¸å›¾åƒç›‘ç£çš„é‡å»ºå¤§è§„æ¨¡è¡¨é¢ç»†èŠ‚çš„æ–°æ–¹æ³•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é‡‡ç”¨ä»ç²—åˆ°ç»†çš„ç­–ç•¥é«˜æ•ˆé‡å»ºç²—ç•¥æ¨¡å‹ï¼Œéšåè¿›è¡Œè‡ªé€‚åº”åœºæ™¯åˆ†å‰²å’Œå›¾åƒåˆ†æ®µçš„å­åœºæ™¯ç»†åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é›†æˆäº†ä¸€ä¸ªåˆ†ç¦»çš„å¤–è§‚æ¨¡å‹æ¥æ•æ‰å…¨å±€å¤–è§‚å˜åŒ–å’Œä¸€ä¸ªç¬æ€æ©è†œæ¨¡å‹æ¥ç¼“è§£ç§»åŠ¨ç‰©ä½“çš„å¹²æ‰°ã€‚æœ€åï¼Œæˆ‘ä»¬æ‰©å±•äº†å¤šè§†è§’çº¦æŸï¼Œå¹¶ä¸ºæ— çº¹ç†åŒºåŸŸå¼•å…¥å•è§†è§’æ­£åˆ™åŒ–ã€‚æˆ‘ä»¬çš„å®éªŒæ˜¯åœ¨å…¬å¼€å¯ç”¨çš„GauU-Scene V2æ•°æ®é›†ä¸Šè¿›è¡Œçš„ï¼Œè¯¥æ•°æ®é›†æ˜¯ä½¿ç”¨æ— äººæœºæ•è·çš„ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºäºNeRFå’ŒåŸºäºé«˜æ–¯çš„æ–¹æ³•ï¼Œé€šè¿‡å…¨å°ºå¯¸å›¾åƒä¼˜åŒ–å®ç°äº†é«˜ä¿çœŸè§†è§‰ç»“æœå’Œç²¾ç¡®çš„è¡¨é¢é‡å»ºã€‚å¼€æºä»£ç å°†åœ¨GitHubä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.17636v1">PDF</a> IROS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäº3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œé’ˆå¯¹å¤§è§„æ¨¡åœºæ™¯è¡¨é¢é‡å»ºæå‡ºäº†åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å¼•å…¥ä»ç²—åˆ°ç»†çš„é‡å»ºç­–ç•¥ã€è‡ªé€‚åº”åœºæ™¯åˆ†å‰²ã€å­åœºæ™¯ç»†åŒ–ä»¥åŠå¤–è§‚æ¨¡å‹ä¸ç¬æ€æ©æ¨¡æ¨¡å‹çš„é›†æˆï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å…¨å°ºå¯¸å›¾åƒç›‘ç£ä¸‹é‡å»ºå…·æœ‰ç²¾ç»†ç»†èŠ‚çš„å¤§è§„æ¨¡åœºæ™¯ã€‚å®éªŒåœ¨å…¬å¼€æ•°æ®é›†GauU-Scene V2ä¸Šè¿›è¡Œï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„NeRFå’ŒGaussianæ–¹æ³•ï¼Œå®ç°äº†é«˜ä¿çœŸè§†è§‰ç»“æœå’Œå‡†ç¡®çš„è¡¨é¢é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„å¤§è§„æ¨¡åœºæ™¯è¡¨é¢é‡å»ºæ–¹æ³•ï¼ŒåŸºäº3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä»ç²—åˆ°ç»†çš„é‡å»ºç­–ç•¥ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚</li>
<li>é€šè¿‡è‡ªé€‚åº”åœºæ™¯åˆ†å‰²å’Œå­åœºæ™¯ç»†åŒ–ï¼Œåˆ©ç”¨å›¾åƒæ®µè¿›è¡Œæ›´ç²¾ç»†çš„é‡å»ºã€‚</li>
<li>é‡‡ç”¨äº†è„±è€¦å¤–è§‚æ¨¡å‹æ¥æ•æ‰å…¨å±€å¤–è§‚å˜åŒ–ï¼Œä»¥åŠç¬æ€æ©æ¨¡æ¨¡å‹æ¥å‡è½»ç§»åŠ¨ç‰©ä½“çš„å¹²æ‰°ã€‚</li>
<li>æ‰©å±•äº†å¤šè§†è§’çº¦æŸï¼Œä¸ºæ— çº¹ç†åŒºåŸŸå¼•å…¥äº†å•è§†è§’æ­£åˆ™åŒ–ã€‚</li>
<li>åœ¨å…¬å¼€æ•°æ®é›†GauU-Scene V2ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„NeRFå’ŒGaussianæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.17636">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-917d91332db2f4f889f2b653ab3fdaa4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-281b760caaf47a0df09c8ae2a3256d5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51ecf064cf59084f294efe5d69b55db7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bec757883c541dfa018962c7a9b610f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe541c80d2da629920a802aebb8ca679.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d9045b2c3dc1e9e80afdb668c6a9b41.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4eac93e27e3554d76e18e7836c6895f7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="R3eVision-A-Survey-on-Robust-Rendering-Restoration-and-Enhancement-for-3D-Low-Level-Vision"><a href="#R3eVision-A-Survey-on-Robust-Rendering-Restoration-and-Enhancement-for-3D-Low-Level-Vision" class="headerlink" title="R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement   for 3D Low-Level Vision"></a>R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement   for 3D Low-Level Vision</h2><p><strong>Authors:Weeyoung Kwon, Jeahun Sung, Minkyu Jeon, Chanho Eom, Jihyong Oh</strong></p>
<p>Neural rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved significant progress in photorealistic 3D scene reconstruction and novel view synthesis. However, most existing models assume clean and high-resolution (HR) multi-view inputs, which limits their robustness under real-world degradations such as noise, blur, low-resolution (LR), and weather-induced artifacts. To address these limitations, the emerging field of 3D Low-Level Vision (3D LLV) extends classical 2D Low-Level Vision tasks including super-resolution (SR), deblurring, weather degradation removal, restoration, and enhancement into the 3D spatial domain. This survey, referred to as R\textsuperscript{3}eVision, provides a comprehensive overview of robust rendering, restoration, and enhancement for 3D LLV by formalizing the degradation-aware rendering problem and identifying key challenges related to spatio-temporal consistency and ill-posed optimization. Recent methods that integrate LLV into neural rendering frameworks are categorized to illustrate how they enable high-fidelity 3D reconstruction under adverse conditions. Application domains such as autonomous driving, AR&#x2F;VR, and robotics are also discussed, where reliable 3D perception from degraded inputs is critical. By reviewing representative methods, datasets, and evaluation protocols, this work positions 3D LLV as a fundamental direction for robust 3D content generation and scene-level reconstruction in real-world environments. </p>
<blockquote>
<p>ç¥ç»æ¸²æŸ“æ–¹æ³•ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰ï¼Œåœ¨é€¼çœŸä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ¨¡å‹å‡è®¾è¾“å…¥æ˜¯å¹²å‡€ä¸”é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰çš„å¤šè§†è§’ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œé€€åŒ–ï¼ˆä¾‹å¦‚å™ªå£°ã€æ¨¡ç³Šã€ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å’Œå¤©æ°”å¼•èµ·çš„ä¼ªå½±ï¼‰å½±å“ä¸‹çš„ç¨³å¥æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæ–°å…´çš„ä¸‰ç»´ä½çº§è§†è§‰ï¼ˆ3D LLVï¼‰é¢†åŸŸå°†ä¼ ç»Ÿçš„äºŒç»´ä½çº§è§†è§‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰ã€å»æ¨¡ç³Šã€å»é™¤å¤©æ°”é€€åŒ–ã€ä¿®å¤å’Œå¢å¼ºä»»åŠ¡æ‰©å±•åˆ°ä¸‰ç»´ç©ºé—´åŸŸã€‚è¿™ç¯‡ç»¼è¿°è¢«ç§°ä¸ºR\textsuperscript{3}eVisionï¼Œå®ƒä¸ºä¸‰ç»´LLVçš„ç¨³å¥æ¸²æŸ“ã€ä¿®å¤å’Œå¢å¼ºæä¾›äº†å…¨é¢çš„æ¦‚è¿°ï¼Œé€šè¿‡å½¢å¼åŒ–é€€åŒ–æ„ŸçŸ¥æ¸²æŸ“é—®é¢˜å¹¶ç¡®å®šä¸æ—¶ç©ºä¸€è‡´æ€§å’Œä¸é€‚å®šä¼˜åŒ–ç›¸å…³çš„å…³é”®æŒ‘æˆ˜ã€‚å°†LLVé›†æˆåˆ°ç¥ç»æ¸²æŸ“æ¡†æ¶ä¸­çš„æœ€è¿‘çš„æ–¹æ³•è¢«åˆ†ç±»ï¼Œä»¥è¯´æ˜å®ƒä»¬åœ¨ä¸è‰¯æ¡ä»¶ä¸‹å®ç°é«˜ä¿çœŸä¸‰ç»´é‡å»ºçš„èƒ½åŠ›ã€‚è¿˜è®¨è®ºäº†è‡ªåŠ¨é©¾é©¶ã€AR&#x2F;VRå’Œæœºå™¨äººç­‰é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä»é€€åŒ–è¾“å…¥ä¸­è¿›è¡Œå¯é çš„3Dæ„ŸçŸ¥è‡³å…³é‡è¦ã€‚é€šè¿‡å¯¹ä»£è¡¨æ€§æ–¹æ³•ã€æ•°æ®é›†å’Œè¯„ä¼°åè®®çš„å›é¡¾ï¼Œè¿™é¡¹å·¥ä½œå°†3D LLVå®šä½ä¸ºç°å®ä¸–ç•Œä¸­é²æ£’ä¸‰ç»´å†…å®¹ç”Ÿæˆå’Œåœºæ™¯çº§åˆ«é‡å»ºçš„æ ¹æœ¬æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16262v2">PDF</a> Please visit our project page at   <a target="_blank" rel="noopener" href="https://github.com/CMLab-Korea/Awesome-3D-Low-Level-Vision">https://github.com/CMLab-Korea/Awesome-3D-Low-Level-Vision</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¥ç»æ¸²æŸ“æ–¹æ³•å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯æ¶‚æ–‘ï¼ˆ3DGSï¼‰åœ¨çœŸå®æ„Ÿä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ¨¡å‹å¤§å¤šå‡è®¾å¹²å‡€çš„é«˜åˆ†è¾¨ç‡å¤šè§†è§’è¾“å…¥ï¼Œè¿™åœ¨ç°å®ä¸–ç•Œçš„å™ªå£°ã€æ¨¡ç³Šã€ä½åˆ†è¾¨ç‡å’Œå¤©æ°”å¼•èµ·çš„ä¼ªå½±ç­‰é€€åŒ–æ¡ä»¶ä¸‹ï¼Œå…¶ç¨³å¥æ€§å—åˆ°é™åˆ¶ã€‚ä¸ºè§£å†³è¿™äº›å±€é™æ€§ï¼Œæ–°å…´çš„ä¸‰ç»´ä½çº§è§†è§‰ï¼ˆ3D LLVï¼‰é¢†åŸŸå°†ä¼ ç»Ÿçš„äºŒç»´ä½çº§è§†è§‰ä»»åŠ¡æ‰©å±•åˆ°ä¸‰ç»´ç©ºé—´åŸŸï¼ŒåŒ…æ‹¬è¶…åˆ†è¾¨ç‡ã€å»æ¨¡ç³Šã€å»é™¤å¤©æ°”é€€åŒ–ã€ä¿®å¤å’Œå¢å¼ºç­‰ã€‚æœ¬æ–‡ç»¼è¿°äº†R\textsuperscript{3}eVisionä¸­çš„ç¨³å¥æ¸²æŸ“ã€ä¿®å¤å’Œå¢å¼ºæŠ€æœ¯ï¼Œå½¢å¼åŒ–é€€åŒ–æ„ŸçŸ¥æ¸²æŸ“é—®é¢˜ï¼Œå¹¶è¯†åˆ«ä¸æ—¶ç©ºä¸€è‡´æ€§å’Œç—…æ€ä¼˜åŒ–ç›¸å…³çš„å…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡è¿˜ä»‹ç»äº†å°†LLVé›†æˆåˆ°ç¥ç»æ¸²æŸ“æ¡†æ¶ä¸­çš„æœ€æ–°æ–¹æ³•ï¼Œè¯´æ˜äº†å®ƒä»¬åœ¨ä¸è‰¯æ¡ä»¶ä¸‹å®ç°é«˜ä¿çœŸä¸‰ç»´é‡å»ºçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†è‡ªä¸»é©¾é©¶ã€å¢å¼ºç°å®&#x2F;è™šæ‹Ÿç°å®å’Œæœºå™¨äººç­‰é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä»é€€åŒ–è¾“å…¥å®ç°å¯é çš„ä¸‰ç»´æ„ŸçŸ¥è‡³å…³é‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»æ¸²æŸ“æ–¹æ³•åœ¨ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°è§†è§’åˆæˆæ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨ç°å®ä¸–ç•Œé€€åŒ–æ¡ä»¶ä¸‹ï¼ˆå¦‚å™ªå£°ã€æ¨¡ç³Šç­‰ï¼‰çš„ç¨³å¥æ€§å—é™ã€‚</li>
<li>ä¸‰ç»´ä½çº§è§†è§‰ï¼ˆ3D LLVï¼‰æ˜¯æ‰©å±•ä¼ ç»ŸäºŒç»´ä½çº§è§†è§‰ä»»åŠ¡åˆ°ä¸‰ç»´ç©ºé—´åŸŸçš„æ–°é¢†åŸŸã€‚</li>
<li>R\textsuperscript{3}eVisionæä¾›äº†å¯¹3D LLVä¸­ç¨³å¥æ¸²æŸ“ã€ä¿®å¤å’Œå¢å¼ºçš„å…¨é¢æ¦‚è¿°ã€‚</li>
<li>é€€åŒ–æ„ŸçŸ¥æ¸²æŸ“é—®é¢˜è¢«å½¢å¼åŒ–ï¼Œå¹¶è¯†åˆ«å‡ºä¸æ—¶ç©ºä¸€è‡´æ€§å’Œç—…æ€ä¼˜åŒ–ç›¸å…³çš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>ä»‹ç»äº†å°†LLVé›†æˆåˆ°ç¥ç»æ¸²æŸ“æ¡†æ¶ä¸­çš„æœ€æ–°æ–¹æ³•ï¼Œä»¥åº”å¯¹ä¸è‰¯æ¡ä»¶ä¸‹çš„é«˜ä¿çœŸä¸‰ç»´é‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16262">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7aab4fb76393877bbfeedeb7236a410c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f539f679a475ae8cddb515af1915a28a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d98e96726900ad5db41bf549eec201c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9024d639736efa6c12b2da7ef0a6467c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd54095a3a0f6c964810393a28b3eeac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fbd4da6357b9b3969feb4164ed3bb70.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="GAF-Gaussian-Action-Field-as-a-Dynamic-World-Model-for-Robotic-Manipulation"><a href="#GAF-Gaussian-Action-Field-as-a-Dynamic-World-Model-for-Robotic-Manipulation" class="headerlink" title="GAF: Gaussian Action Field as a Dynamic World Model for Robotic   Manipulation"></a>GAF: Gaussian Action Field as a Dynamic World Model for Robotic   Manipulation</h2><p><strong>Authors:Ying Chai, Litao Deng, Ruizhi Shao, Jiajun Zhang, Liangjun Xing, Hongwen Zhang, Yebin Liu</strong></p>
<p>Accurate action inference is critical for vision-based robotic manipulation. Existing approaches typically follow either a Vision-to-Action (V-A) paradigm, predicting actions directly from visual inputs, or a Vision-to-3D-to-Action (V-3D-A) paradigm, leveraging intermediate 3D representations. However, these methods often struggle with action inaccuracies due to the complexity and dynamic nature of manipulation scenes. In this paper, we propose a Vision-to-4D-to-Action (V-4D-A) framework that enables direct action reasoning from motion-aware 4D representations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian Splatting (3DGS) by incorporating learnable motion attributes, allowing simultaneous modeling of dynamic scenes and manipulation actions. To learn time-varying scene geometry and action-aware robot motion, GAF supports three key query types: reconstruction of the current scene, prediction of future frames, and estimation of initial action via robot motion. Furthermore, the high-quality current and future frames generated by GAF facilitate manipulation action refinement through a GAF-guided diffusion model. Extensive experiments demonstrate significant improvements, with GAF achieving +11.5385 dB PSNR and -0.5574 LPIPS improvements in reconstruction quality, while boosting the average success rate in robotic manipulation tasks by 10.33% over state-of-the-art methods. Project page: <a target="_blank" rel="noopener" href="http://chaiying1.github.io/GAF.github.io/project_page/">http://chaiying1.github.io/GAF.github.io/project_page/</a> </p>
<blockquote>
<p>åœ¨åŸºäºè§†è§‰çš„æœºå™¨äººæ“æ§ä¸­ï¼Œç²¾ç¡®çš„åŠ¨ä½œæ¨ç†è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨è§†è§‰åˆ°åŠ¨ä½œï¼ˆV-Aï¼‰èŒƒå¼ï¼Œç›´æ¥ä»è§†è§‰è¾“å…¥é¢„æµ‹åŠ¨ä½œï¼Œæˆ–è€…è§†è§‰åˆ°ä¸‰ç»´åˆ°åŠ¨ä½œï¼ˆV-3D-Aï¼‰èŒƒå¼ï¼Œåˆ©ç”¨ä¸­é—´ä¸‰ç»´è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ç”±äºæ“æ§åœºæ™¯çš„å¤æ‚æ€§å’ŒåŠ¨æ€æ€§ï¼Œå¾€å¾€å­˜åœ¨åŠ¨ä½œä¸å‡†ç¡®çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§†è§‰åˆ°å››ç»´åˆ°åŠ¨ä½œï¼ˆV-4D-Aï¼‰æ¡†æ¶ï¼Œé€šè¿‡é«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰å®ç°ä»åŠ¨æ€æ„ŸçŸ¥çš„4Dè¡¨ç¤ºä¸­ç›´æ¥è¿›è¡ŒåŠ¨ä½œæ¨ç†ã€‚GAFé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„è¿åŠ¨å±æ€§æ‰©å±•äº†ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ï¼Œèƒ½å¤Ÿå®ç°åŠ¨æ€åœºæ™¯å’Œæ“æ§åŠ¨ä½œçš„åŒæ—¶å»ºæ¨¡ã€‚ä¸ºäº†å­¦ä¹ éšæ—¶é—´å˜åŒ–çš„åœºæ™¯å‡ ä½•å’ŒåŠ¨ä½œæ„ŸçŸ¥çš„æœºå™¨äººè¿åŠ¨ï¼ŒGAFæ”¯æŒä¸‰ç§å…³é”®æŸ¥è¯¢ç±»å‹ï¼šé‡å»ºå½“å‰åœºæ™¯ã€é¢„æµ‹æœªæ¥å¸§ä»¥åŠé€šè¿‡æœºå™¨äººè¿åŠ¨ä¼°è®¡åˆå§‹åŠ¨ä½œã€‚æ­¤å¤–ï¼ŒGAFç”Ÿæˆçš„é«˜è´¨é‡å½“å‰å’Œæœªæ¥å¸§é€šè¿‡GAFå¼•å¯¼æ‰©æ•£æ¨¡å‹ä¿ƒè¿›äº†æ“æ§åŠ¨ä½œçš„ä¼˜åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGAFåœ¨é‡å»ºè´¨é‡ä¸Šå®ç°äº†+11.5385åˆ†è´å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œ-0.5574å›¾åƒæ„ŸçŸ¥ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼ˆLPIPSï¼‰çš„æ˜¾è‘—æå‡ï¼ŒåŒæ—¶åœ¨æœºå™¨äººæ“æ§ä»»åŠ¡ä¸­å°†å¹³å‡æˆåŠŸç‡æé«˜äº†10.33%ï¼Œè¶…è¿‡äº†æœ€æ–°æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="http://chaiying1.github.io/GAF.github.io/project_page/">http://chaiying1.github.io/GAF.github.io/project_page/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.14135v2">PDF</a> <a target="_blank" rel="noopener" href="http://chaiying1.github.io/GAF.github.io/project_page/">http://chaiying1.github.io/GAF.github.io/project_page/</a></p>
<p><strong>Summary</strong><br>     è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰çš„æœºå™¨äººæ“ä½œæ–°æ¡†æ¶ï¼Œå³Vision-to-4D-to-Actionï¼ˆV-4D-Aï¼‰æ¡†æ¶ï¼Œé€šè¿‡é«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰ç›´æ¥ä»è¿åŠ¨æ„ŸçŸ¥çš„4Dè¡¨ç¤ºä¸­è¿›è¡ŒåŠ¨ä½œæ¨ç†ã€‚GAFé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„è¿åŠ¨å±æ€§ï¼Œæ‰©å±•äº†3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ï¼Œèƒ½åŒæ—¶å»ºæ¨¡åŠ¨æ€åœºæ™¯å’Œæ“ä½œåŠ¨ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><p>ç°æœ‰æ–¹æ³•ï¼šå¤§å¤šæ•°ç°æœ‰çš„æ–¹æ³•åŸºäºè§†è§‰è¿›è¡Œæœºå™¨äººæ“ä½œé‡‡ç”¨Vision-to-Action (V-A) æˆ– Vision-to-3D-to-Action (V-3D-A) èŒƒå¼ã€‚å®ƒä»¬é¢ä¸´ç€ç”±äºæ“ä½œåœºæ™¯çš„å¤æ‚æ€§å’ŒåŠ¨æ€æ€§è€Œå¯¼è‡´çš„åŠ¨ä½œä¸å‡†ç¡®çš„é—®é¢˜ã€‚</p>
</li>
<li><p>æ–°æ¡†æ¶æå‡ºï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶Vision-to-4D-to-Action (V-4D-A)ï¼Œå®ƒåˆ©ç”¨è¿åŠ¨æ„ŸçŸ¥çš„4Dè¡¨ç¤ºè¿›è¡Œç›´æ¥åŠ¨ä½œæ¨ç†ã€‚è¿™ä¸ªæ¡†æ¶é€šè¿‡é«˜æ–¯åŠ¨ä½œåœºï¼ˆGAFï¼‰å®ç°ï¼Œæ‰©å±•äº†3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ã€‚</p>
</li>
<li><p>GAFçš„ç‰¹ç‚¹ï¼šGAFé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„è¿åŠ¨å±æ€§ï¼Œèƒ½åŒæ—¶å»ºæ¨¡åŠ¨æ€åœºæ™¯å’Œæœºå™¨äººæ“ä½œåŠ¨ä½œã€‚å®ƒæ”¯æŒä¸‰ç§å…³é”®æŸ¥è¯¢ç±»å‹ï¼šå½“å‰åœºæ™¯çš„é‡å»ºã€æœªæ¥å¸§çš„é¢„æµ‹ä»¥åŠé€šè¿‡æœºå™¨äººè¿åŠ¨å¯¹åˆå§‹åŠ¨ä½œçš„ä¼°è®¡ã€‚</p>
</li>
<li><p>å­¦ä¹ å’Œä¼˜åŒ–ï¼šGAFäº§ç”Ÿçš„é«˜è´¨é‡å½“å‰å’Œæœªæ¥å¸§ï¼Œé€šè¿‡GAFå¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œæœ‰åŠ©äºä¼˜åŒ–æœºå™¨äººæ“ä½œåŠ¨ä½œã€‚</p>
</li>
<li><p>å®éªŒç»“æœï¼šå®éªŒè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒGAFåœ¨é‡å»ºè´¨é‡æ–¹é¢æé«˜äº†+11.5385 dB PSNRå’Œ-0.5574 LPIPSï¼ŒåŒæ—¶åœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å°†æˆåŠŸç‡æé«˜äº†10.33%ã€‚</p>
</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.14135">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-239510b7eeda6c6cd84804726edfa1a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca909a6be98754d4eec57ec2f2e302c8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1bf057b05d638f2f468455cd61d4a35f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6a4dad1ccdbc771401e009a9f1a79ef9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CGS-GAN-3D-Consistent-Gaussian-Splatting-GANs-for-High-Resolution-Human-Head-Synthesis"><a href="#CGS-GAN-3D-Consistent-Gaussian-Splatting-GANs-for-High-Resolution-Human-Head-Synthesis" class="headerlink" title="CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human   Head Synthesis"></a>CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human   Head Synthesis</h2><p><strong>Authors:Florian Barthel, Wieland Morgenstern, Paul Hinzer, Anna Hilsmann, Peter Eisert</strong></p>
<p>Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high quality synthesis of human heads. However, existing methods stabilize training and enhance rendering quality from steep viewpoints by conditioning the random latent vector on the current camera position. This compromises 3D consistency, as we observe significant identity changes when re-synthesizing the 3D head with each camera shift. Conversely, fixing the camera to a single viewpoint yields high-quality renderings for that perspective but results in poor performance for novel views. Removing view-conditioning typically destabilizes GAN training, often causing the training to collapse. In response to these challenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework that enables stable training and high-quality 3D-consistent synthesis of human heads without relying on view-conditioning. To ensure training stability, we introduce a multi-view regularization technique that enhances generator convergence with minimal computational overhead. Additionally, we adapt the conditional loss used in existing 3D Gaussian splatting GANs and propose a generator architecture designed to not only stabilize training but also facilitate efficient rendering and straightforward scaling, enabling output resolutions up to $2048^2$. To evaluate the capabilities of CGS-GAN, we curate a new dataset derived from FFHQ. This dataset enables very high resolutions, focuses on larger portions of the human head, reduces view-dependent artifacts for improved 3D consistency, and excludes images where subjects are obscured by hands or other objects. As a result, our approach achieves very high rendering quality, supported by competitive FID scores, while ensuring consistent 3D scene generation. Check our our project page here: <a target="_blank" rel="noopener" href="https://fraunhoferhhi.github.io/cgs-gan/">https://fraunhoferhhi.github.io/cgs-gan/</a> </p>
<blockquote>
<p>æœ€è¿‘ï¼ŒåŸºäºä¸‰ç»´é«˜æ–¯è´´å›¾çš„3D GANså·²è¢«æå‡ºç”¨äºé«˜è´¨é‡çš„äººå¤´åˆæˆã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šè¿‡æ ¹æ®å½“å‰ç›¸æœºä½ç½®å¯¹éšæœºæ½œåœ¨å‘é‡è¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»è€Œç¨³å®šè®­ç»ƒå¹¶æé«˜äº†ä»é™¡å³­è§†è§’çš„å‘ˆç°è´¨é‡ã€‚è¿™æŸå®³äº†ä¸‰ç»´ä¸€è‡´æ€§ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨é‡æ–°åˆæˆä¸‰ç»´å¤´éƒ¨æ—¶è§‚å¯Ÿåˆ°èº«ä»½å‘ç”Ÿæ˜¾è‘—å˜åŒ–ï¼Œæ¯æ¬¡ç›¸æœºç§»åŠ¨æ—¶éƒ½æ˜¯å¦‚æ­¤ã€‚ç›¸åï¼Œå°†ç›¸æœºå›ºå®šåœ¨ä¸€ä¸ªè§†è§’ä¸Šï¼Œå¯ä»¥ä¸ºè¯¥è§†è§’äº§ç”Ÿé«˜è´¨é‡çš„æ¸²æŸ“ï¼Œä½†å¯¹äºæ–°è§†è§’åˆ™è¡¨ç°ä¸ä½³ã€‚ç§»é™¤è§†å›¾æ¡ä»¶é€šå¸¸ä¼šä½¿GANè®­ç»ƒä¸ç¨³å®šï¼Œå¹¶ç»å¸¸å¯¼è‡´è®­ç»ƒå´©æºƒã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CGS-GANï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸‰ç»´é«˜æ–¯è´´å›¾GANæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–è§†å›¾æ¡ä»¶çš„æƒ…å†µä¸‹å®ç°ç¨³å®šè®­ç»ƒä»¥åŠé«˜è´¨é‡çš„ä¸‰ç»´ä¸€è‡´äººå¤´åˆæˆã€‚ä¸ºäº†ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šè§†å›¾æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å¯å¢å¼ºç”Ÿæˆå™¨çš„æ”¶æ•›æ€§ï¼ŒåŒæ—¶è®¡ç®—å¼€é”€æœ€å°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€‚åº”äº†ç°æœ‰ä¸‰ç»´é«˜æ–¯è´´å›¾GANä¸­çš„æ¡ä»¶æŸå¤±ï¼Œå¹¶æå‡ºäº†ä¸€ç§è®¾è®¡å·§å¦™çš„ç”Ÿæˆå™¨æ¶æ„ï¼Œä¸ä»…å¯ä»¥ç¨³å®šè®­ç»ƒï¼Œè¿˜å¯ä»¥ä¿ƒè¿›é«˜æ•ˆæ¸²æŸ“å’Œç®€æ´æ‰©å±•ï¼Œæ”¯æŒé«˜è¾¾$ 2048^2 $çš„è¾“å‡ºåˆ†è¾¨ç‡ã€‚ä¸ºäº†è¯„ä¼°CGS-GANçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬ä»FFHQä¸­æ•´ç†äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†å¯å®ç°éå¸¸é«˜çš„åˆ†è¾¨ç‡ï¼Œä¾§é‡äºäººç±»å¤´éƒ¨çš„å¤§éƒ¨åˆ†åŒºåŸŸï¼Œå‡å°‘äº†è§†å›¾ç›¸å…³çš„ä¼ªå½±ä»¥æ”¹å–„ä¸‰ç»´ä¸€è‡´æ€§ï¼Œå¹¶æ’é™¤äº†ä¸»ä½“è¢«æ‰‹æˆ–å…¶ä»–ç‰©ä½“é®æŒ¡çš„å›¾åƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†éå¸¸é«˜çš„å‘ˆç°è´¨é‡ï¼Œè¾…ä»¥æœ‰ç«äº‰åŠ›çš„FIDåˆ†æ•°ï¼ŒåŒæ—¶ç¡®ä¿äº†ä¸€è‡´çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢äº†è§£æ›´å¤šä¿¡æ¯ï¼š<a target="_blank" rel="noopener" href="https://fraunhoferhhi.github.io/cgs-gan/%E3%80%82">https://fraunhoferhhi.github.io/cgs-gan/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.17590v2">PDF</a> Main paper 12 pages, supplementary materials 8 pages</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„ä¸‰ç»´é«˜æ–¯å±•å¹³GANï¼ˆCGS-GANï¼‰æ¡†æ¶ï¼Œç”¨äºè§£å†³ç°æœ‰æŠ€æœ¯ä¸­è§†è§’è°ƒæ•´å¯¹è®­ç»ƒç¨³å®šæ€§å’Œå¤´éƒ¨æ¸²æŸ“è´¨é‡çš„å½±å“é—®é¢˜ã€‚é€šè¿‡å¼•å…¥å¤šè§†è§’æ­£åˆ™åŒ–æŠ€æœ¯å’Œæ”¹è¿›çš„æ¡ä»¶æŸå¤±å‡½æ•°ï¼ŒCGS-GANåœ¨ä¸ä¾èµ–è§†è§’è°ƒæ•´çš„æƒ…å†µä¸‹å®ç°äº†ç¨³å®šçš„è®­ç»ƒå’Œé«˜è´¨é‡çš„ä¸‰ç»´ä¸€è‡´æ€§å¤´éƒ¨åˆæˆã€‚æ­¤å¤–ï¼Œè¿˜é€šè¿‡ä¼˜åŒ–ç”Ÿæˆå™¨æ¶æ„ï¼Œæé«˜äº†æ¸²æŸ“æ•ˆç‡å’Œè¾“å‡ºåˆ†è¾¨ç‡ã€‚å®éªŒè¯æ˜ï¼ŒCGS-GANåœ¨é«˜åˆ†è¾¨ç‡æ¸²æŸ“è´¨é‡æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯äº†ä¸‰ç»´åœºæ™¯çš„ä¸€è‡´æ€§ç”Ÿæˆã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç°æœ‰åŸºäºä¸‰ç»´é«˜æ–¯å±•å¹³çš„GANæŠ€æœ¯åœ¨å¤„ç†å¤´éƒ¨åˆæˆæ—¶é¢ä¸´è§†è§’è°ƒæ•´å¸¦æ¥çš„é—®é¢˜ï¼Œå½±å“æ¸²æŸ“è´¨é‡å’Œä¸‰ç»´ä¸€è‡´æ€§ã€‚</li>
<li>CGS-GANæ¡†æ¶è¢«å¼•å…¥ä»¥è§£å†³è¿™äº›é—®é¢˜ï¼Œé€šè¿‡å¤šè§†è§’æ­£åˆ™åŒ–æŠ€æœ¯ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼ŒåŒæ—¶å®ç°é«˜è´¨é‡çš„ä¸‰ç»´ä¸€è‡´æ€§å¤´éƒ¨åˆæˆã€‚</li>
<li>CGS-GANæ”¹è¿›äº†ç°æœ‰æŠ€æœ¯ä¸­çš„æ¡ä»¶æŸå¤±å‡½æ•°ï¼Œä¿ƒè¿›ç”Ÿæˆå™¨çš„æ”¶æ•›ï¼ŒåŒæ—¶æé«˜æ¸²æŸ“æ•ˆç‡å’Œè¾“å‡ºåˆ†è¾¨ç‡ã€‚</li>
<li>ä¸ºè¯„ä¼°CGS-GANæ€§èƒ½ï¼Œå¼€å‘äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œä¸“æ³¨äºäººç±»å¤´éƒ¨çš„å¤§éƒ¨ä½ï¼Œå‡å°‘è§†è§’ç›¸å…³çš„ä¼ªå½±ï¼Œå¹¶æ’é™¤è¢«æ‰‹æˆ–å…¶ä»–ç‰©ä½“é®æŒ¡çš„å›¾åƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCGS-GANåœ¨é«˜åˆ†è¾¨ç‡æ¸²æŸ“è´¨é‡æ–¹é¢å…·æœ‰ä¼˜å¼‚è¡¨ç°ï¼Œä¿è¯ä¸‰ç»´åœºæ™¯çš„ä¸€è‡´ç”Ÿæˆã€‚</li>
<li>CGS-GANæ¡†æ¶å…·æœ‰æ½œåŠ›è§£å†³å½“å‰æŠ€æœ¯åœ¨å¤´éƒ¨åˆæˆä¸­çš„å…³é”®é—®é¢˜ï¼Œä¸ºæœªæ¥ç›¸å…³å·¥ä½œæä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚</li>
<li>é€šè¿‡å¼•å…¥æ–°å‹æŠ€æœ¯å’Œä¼˜åŒ–ç­–ç•¥ï¼ŒCGS-GANæœ‰æœ›æ¨åŠ¨ä¸‰ç»´é«˜æ–¯å±•å¹³GANçš„ç ”ç©¶è¿›å±•ï¼Œå¹¶æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„åº”ç”¨å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.17590">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-11fa15bca380aa3bf5fc8d1e0c8a8007.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08124573fc86493b9dfb2d48d5d3917b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d53008d8bcac44d52ab6807cbf170cf5.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="CLIP-GS-CLIP-Informed-Gaussian-Splatting-for-View-Consistent-3D-Indoor-Semantic-Understanding"><a href="#CLIP-GS-CLIP-Informed-Gaussian-Splatting-for-View-Consistent-3D-Indoor-Semantic-Understanding" class="headerlink" title="CLIP-GS: CLIP-Informed Gaussian Splatting for View-Consistent 3D Indoor   Semantic Understanding"></a>CLIP-GS: CLIP-Informed Gaussian Splatting for View-Consistent 3D Indoor   Semantic Understanding</h2><p><strong>Authors:Guibiao Liao, Jiankun Li, Zhenyu Bao, Xiaoqing Ye, Qing Li, Kanglin Liu</strong></p>
<p>Exploiting 3D Gaussian Splatting (3DGS) with Contrastive Language-Image Pre-Training (CLIP) models for open-vocabulary 3D semantic understanding of indoor scenes has emerged as an attractive research focus. Existing methods typically attach high-dimensional CLIP semantic embeddings to 3D Gaussians and leverage view-inconsistent 2D CLIP semantics as Gaussian supervision, resulting in efficiency bottlenecks and deficient 3D semantic consistency. To address these challenges, we present CLIP-GS, efficiently achieving a coherent semantic understanding of 3D indoor scenes via the proposed Semantic Attribute Compactness (SAC) and 3D Coherent Regularization (3DCR). SAC approach exploits the naturally unified semantics within objects to learn compact, yet effective, semantic Gaussian representations, enabling highly efficient rendering (&gt;100 FPS). 3DCR enforces semantic consistency in 2D and 3D domains: In 2D, 3DCR utilizes refined view-consistent semantic outcomes derived from 3DGS to establish cross-view coherence constraints; in 3D, 3DCR encourages features similar among 3D Gaussian primitives associated with the same object, leading to more precise and coherent segmentation results. Extensive experimental results demonstrate that our method remarkably suppresses existing state-of-the-art approaches, achieving mIoU improvements of 21.20% and 13.05% on ScanNet and Replica datasets, respectively, while maintaining real-time rendering speed. Furthermore, our approach exhibits superior performance even with sparse input data, substantiating its robustness. </p>
<blockquote>
<p>åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰ä¸å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹ï¼Œå®ç°å¯¹å®¤å†…åœºæ™¯å¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´è¯­ä¹‰ç†è§£ï¼Œå·²æˆä¸ºä¸€ä¸ªå¸å¼•äººçš„ç ”ç©¶ç„¦ç‚¹ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å°†é«˜ç»´CLIPè¯­ä¹‰åµŒå…¥åˆ°ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒä¸­ï¼Œå¹¶åˆ©ç”¨è§†å›¾ä¸ä¸€è‡´çš„äºŒç»´CLIPè¯­ä¹‰ä½œä¸ºé«˜æ–¯åˆ†å¸ƒçš„ç›‘ç£ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ•ˆç‡ç“¶é¢ˆå’Œä¸‰ç»´è¯­ä¹‰ä¸€è‡´æ€§ä¸è¶³ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†CLIP-GSæ–¹æ³•ï¼Œé€šè¿‡æå‡ºçš„è¯­ä¹‰å±æ€§ç´§å‡‘æ€§ï¼ˆSACï¼‰å’Œä¸‰ç»´ä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼ˆ3DCRï¼‰æœ‰æ•ˆåœ°å®ç°å¯¹ä¸‰ç»´å®¤å†…åœºæ™¯çš„ä¸€è‡´è¯­ä¹‰ç†è§£ã€‚SACæ–¹æ³•åˆ©ç”¨å¯¹è±¡å†…éƒ¨çš„è‡ªç„¶ç»Ÿä¸€è¯­ä¹‰æ¥å­¦ä¹ ç´§å‡‘è€Œæœ‰æ•ˆçš„è¯­ä¹‰é«˜æ–¯è¡¨ç¤ºï¼Œä»è€Œå®ç°é«˜æ•ˆæ¸²æŸ“ï¼ˆ&gt;100å¸§æ¯ç§’ï¼‰ã€‚3DCRåœ¨äºŒç»´å’Œä¸‰ç»´åŸŸä¸­å¼ºåˆ¶å®æ–½è¯­ä¹‰ä¸€è‡´æ€§ï¼šåœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œ3DCRåˆ©ç”¨æ¥è‡ª3DGSçš„ç²¾ç»†åŒ–è§†å›¾ä¸€è‡´è¯­ä¹‰ç»“æœå»ºç«‹è·¨è§†å›¾ä¸€è‡´æ€§çº¦æŸï¼›åœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œ3DCRé¼“åŠ±ä¸åŒä¸€å¯¹è±¡ç›¸å…³çš„ä¸‰ç»´é«˜æ–¯åŸºå…ƒä¹‹é—´çš„ç‰¹å¾ç›¸ä¼¼æ€§ï¼Œä»è€Œå¾—åˆ°æ›´ç²¾ç¡®å’Œä¸€è‡´çš„åˆ†å‰²ç»“æœã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—åœ°æŠ‘åˆ¶äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ¡ˆï¼Œåœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†å¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰çš„æ”¹è¿›ä¸º21.20%å’Œ13.05%ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¨€ç–è¾“å…¥æ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶ç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14249v2">PDF</a> ACM TOMM 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åˆ©ç”¨ä¸‰ç»´é«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰ä¸å¯¹æ¯”è¯­è¨€å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹è¿›è¡Œå®¤å†…åœºæ™¯å¼€æ”¾è¯æ±‡ä¸‰ç»´è¯­ä¹‰ç†è§£çš„æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é«˜ç»´CLIPè¯­ä¹‰åµŒå…¥å’Œè§†å›¾ä¸ä¸€è‡´çš„2D CLIPè¯­ä¹‰æ—¶å‡ºç°çš„æ•ˆç‡ç“¶é¢ˆå’Œä¸‰ç»´è¯­ä¹‰ä¸€è‡´æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†CLIP-GSæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¯­ä¹‰å±æ€§ç´§å‡‘æ€§ï¼ˆSACï¼‰å’Œä¸‰ç»´ä¸€è‡´æ­£åˆ™åŒ–ï¼ˆ3DCRï¼‰å®ç°äº†å¯¹ä¸‰ç»´å®¤å†…åœºæ™¯çš„ä¸€è‡´è¯­ä¹‰ç†è§£ã€‚SACæ–¹æ³•åˆ©ç”¨å¯¹è±¡å†…éƒ¨è‡ªç„¶ç»Ÿä¸€çš„è¯­ä¹‰æ¥å­¦ä¹ ç´§å‡‘è€Œæœ‰æ•ˆçš„è¯­ä¹‰é«˜æ–¯è¡¨ç¤ºï¼Œå®ç°äº†é«˜æ•ˆæ¸²æŸ“ï¼ˆ&gt;100å¸§&#x2F;ç§’ï¼‰ã€‚3DCRåœ¨äºŒç»´å’Œä¸‰ç»´é¢†åŸŸéƒ½å¼ºåˆ¶å®æ–½è¯­ä¹‰ä¸€è‡´æ€§ï¼šåœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œ3DCRåˆ©ç”¨ç”±3DGSæ´¾ç”Ÿçš„ç²¾ç»†è§†å›¾ä¸€è‡´è¯­ä¹‰ç»“æœæ¥å»ºç«‹è·¨è§†å›¾ä¸€è‡´æ€§çº¦æŸï¼›åœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œ3DCRé¼“åŠ±ä¸åŒä¸€å¯¹è±¡ç›¸å…³çš„ä¸‰ç»´é«˜æ–¯åŸå§‹ç‰¹å¾ç›¸ä¼¼ï¼Œä»è€Œè·å¾—æ›´ç²¾ç¡®å’Œä¸€è‡´çš„åˆ†å‰²ç»“æœã€‚å¤§é‡å®éªŒç»“æœè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†mIoUæ”¹è¿›21.20%å’Œ13.05%ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚å³ä½¿åœ¨ç¨€ç–è¾“å…¥æ•°æ®ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶ç¨³å¥æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åˆ©ç”¨3DGSä¸CLIPæ¨¡å‹ç»“åˆï¼Œå®ç°å®¤å†…åœºæ™¯å¼€æ”¾è¯æ±‡çš„ä¸‰ç»´è¯­ä¹‰ç†è§£ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é«˜ç»´CLIPè¯­ä¹‰åµŒå…¥å’Œè§†å›¾ä¸ä¸€è‡´çš„2D CLIPè¯­ä¹‰æ—¶å­˜åœ¨æŒ‘æˆ˜ï¼Œå¯¼è‡´æ•ˆç‡ç“¶é¢ˆå’Œä¸‰ç»´è¯­ä¹‰ä¸€è‡´æ€§ä¸è¶³ã€‚</li>
<li>æå‡ºäº†SACå’Œ3DCRæ–¹æ³•æ¥è§£å†³ä¸Šè¿°æŒ‘æˆ˜ã€‚SACå®ç°äº†ç´§å‡‘è€Œæœ‰æ•ˆçš„è¯­ä¹‰é«˜æ–¯è¡¨ç¤ºï¼Œè€Œ3DCRåœ¨äºŒç»´å’Œä¸‰ç»´ç©ºé—´ä¸­å¼ºåˆ¶å®æ–½è¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>SACæ–¹æ³•ä½¿é«˜æ•ˆæ¸²æŸ“æˆä¸ºå¯èƒ½ï¼ˆ&gt;100å¸§&#x2F;ç§’ï¼‰ã€‚</li>
<li>3DCRåœ¨è·¨è§†å›¾ä¸€è‡´æ€§å’Œä¸‰ç»´åˆ†å‰²ç²¾åº¦æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.14249">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-848cf18f2cbdd32f572814e8d3fb78fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2662ccf8bb11b00f0d6efc0ad45a6e8e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aec5d31b8304790ea84020bd4d59aaec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d8a810c0f22ee3a3f55b0ffc81fdfa72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6069504a51125b3c0c8c964f946bf601.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-25/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-25/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-25/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-56ca28009d5260476c56072194780a5b.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-25  MCN-SLAM Multi-Agent Collaborative Neural SLAM with Hybrid Implicit   Neural Scene Representation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-25/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0a8a9da78340c84f964d5fc6cb328317.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-25  OmniAvatar Efficient Audio-Driven Avatar Video Generation with Adaptive   Body Animation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
