<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  RSFR A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor   Cardiac MRI with Semantic-Aware Refinement">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-0c7c2a2d7f366b6cf266a0da24959227.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    39 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-29-æ›´æ–°"><a href="#2025-04-29-æ›´æ–°" class="headerlink" title="2025-04-29 æ›´æ–°"></a>2025-04-29 æ›´æ–°</h1><h2 id="RSFR-A-Coarse-to-Fine-Reconstruction-Framework-for-Diffusion-Tensor-Cardiac-MRI-with-Semantic-Aware-Refinement"><a href="#RSFR-A-Coarse-to-Fine-Reconstruction-Framework-for-Diffusion-Tensor-Cardiac-MRI-with-Semantic-Aware-Refinement" class="headerlink" title="RSFR: A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor   Cardiac MRI with Semantic-Aware Refinement"></a>RSFR: A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor   Cardiac MRI with Semantic-Aware Refinement</h2><p><strong>Authors:Jiahao Huang, Fanwen Wang, Pedro F. Ferreira, Haosen Zhang, Yinzhe Wu, Zhifan Gao, Lei Zhu, Angelica I. Aviles-Rivero, Carola-Bibiane Schonlieb, Andrew D. Scott, Zohya Khalique, Maria Dwornik, Ramyah Rajakulasingam, Ranil De Silva, Dudley J. Pennell, Guang Yang, Sonia Nielles-Vallespin</strong></p>
<p>Cardiac diffusion tensor imaging (DTI) offers unique insights into cardiomyocyte arrangements, bridging the gap between microscopic and macroscopic cardiac function. However, its clinical utility is limited by technical challenges, including a low signal-to-noise ratio, aliasing artefacts, and the need for accurate quantitative fidelity. To address these limitations, we introduce RSFR (Reconstruction, Segmentation, Fusion &amp; Refinement), a novel framework for cardiac diffusion-weighted image reconstruction. RSFR employs a coarse-to-fine strategy, leveraging zero-shot semantic priors via the Segment Anything Model and a robust Vision Mamba-based reconstruction backbone. Our framework integrates semantic features effectively to mitigate artefacts and enhance fidelity, achieving state-of-the-art reconstruction quality and accurate DT parameter estimation under high undersampling rates. Extensive experiments and ablation studies demonstrate the superior performance of RSFR compared to existing methods, highlighting its robustness, scalability, and potential for clinical translation in quantitative cardiac DTI. </p>
<blockquote>
<p>å¿ƒè„æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰ä¸ºå¿ƒè‚Œç»†èƒæ’åˆ—æä¾›äº†ç‹¬ç‰¹çš„è§è§£ï¼Œæ¶èµ·äº†å¾®è§‚å’Œå®è§‚å¿ƒè„åŠŸèƒ½ä¹‹é—´çš„æ¡¥æ¢ã€‚ç„¶è€Œï¼Œç”±äºå…¶ä¿¡å·å™ªå£°æ¯”è¾ƒä½ã€å­˜åœ¨æ··å ä¼ªå½±ä»¥åŠéœ€è¦å‡†ç¡®çš„å®šé‡ä¿çœŸç­‰æŠ€æœ¯æŒ‘æˆ˜ï¼Œå…¶ä¸´åºŠåº”ç”¨å—åˆ°é™åˆ¶ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†RSFRï¼ˆé‡å»ºã€åˆ†å‰²ã€èåˆä¸ç»†åŒ–ï¼‰â€”â€”ä¸€ç§ç”¨äºå¿ƒè„æ‰©æ•£åŠ æƒå›¾åƒé‡å»ºçš„æ–°å‹æ¡†æ¶ã€‚RSFRé‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œåˆ©ç”¨åŸºäºSegment Anythingæ¨¡å‹çš„é›¶æ ·æœ¬è¯­ä¹‰å…ˆéªŒå’ŒåŸºäºVision Mambaçš„ç¨³å¥é‡å»ºä¸»å¹²ã€‚æˆ‘ä»¬çš„æ¡†æ¶æœ‰æ•ˆåœ°é›†æˆäº†è¯­ä¹‰ç‰¹å¾ï¼Œä»¥å‡è½»ä¼ªå½±å¹¶æé«˜ä¿çœŸåº¦ï¼Œå®ç°äº†åœ¨é«˜æ¬ é‡‡æ ·ç‡ä¸‹çš„æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡å’Œå‡†ç¡®çš„DTå‚æ•°ä¼°è®¡ã€‚å¹¿æ³›çš„å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†RSFRç›¸è¾ƒäºç°æœ‰æ–¹æ³•çš„å“è¶Šæ€§èƒ½ï¼Œå‡¸æ˜¾äº†å…¶ç¨³å¥æ€§ã€å¯æ‰©å±•æ€§ä»¥åŠå®šé‡å¿ƒè„DTIä¸´åºŠè½¬åŒ–çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18520v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¿ƒè„æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰èƒ½å¤Ÿæ·±å…¥äº†è§£å¿ƒè‚Œç»„ç»‡æ’åˆ—ï¼Œä¸ºå¾®è§‚å’Œå®è§‚å¿ƒè„åŠŸèƒ½ä¹‹é—´çš„è”ç³»æä¾›æ¡¥æ¢ã€‚ç„¶è€Œï¼Œå…¶ä¸´åºŠåº”ç”¨å—é™äºæŠ€æœ¯æŒ‘æˆ˜ï¼Œå¦‚ä½ä¿¡å™ªæ¯”ã€æ··å ä¼ªå½±å’Œå®šé‡å‡†ç¡®æ€§éœ€æ±‚ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†RSFRï¼ˆé‡å»ºã€åˆ†å‰²ã€èåˆä¸ç»†åŒ–ï¼‰è¿™ä¸€æ–°å‹å¿ƒè„æ‰©æ•£åŠ æƒå›¾åƒé‡å»ºæ¡†æ¶ã€‚RSFRé‡‡ç”¨ç”±ç²—åˆ°ç»†çš„ç­–ç•¥ï¼Œé€šè¿‡Segment Anythingæ¨¡å‹å’ŒåŸºäºVision Mambaçš„ç¨³å¥é‡å»ºåç›¾ï¼Œæœ‰æ•ˆåˆ©ç”¨è¯­ä¹‰ç‰¹å¾æ¥å‡å°‘ä¼ªå½±å¹¶å¢å¼ºå‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶å®ç°äº†æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡å’Œå‡†ç¡®çš„DTå‚æ•°ä¼°è®¡ï¼Œåœ¨é«˜æ¬ é‡‡æ ·ç‡ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚å¹¿æ³›å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†RSFRç›¸è¾ƒäºç°æœ‰æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œå‡¸æ˜¾äº†å…¶ç¨³å¥æ€§ã€å¯æ‰©å±•æ€§å’Œåœ¨å®šé‡å¿ƒè„DTIä¸­ä¸´åºŠè½¬åŒ–çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¿ƒè„æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰å¯æ­ç¤ºå¿ƒè‚Œç»„ç»‡æ’åˆ—ï¼Œä¸ºå¾®è§‚ä¸å®è§‚å¿ƒè„åŠŸèƒ½ç ”ç©¶æä¾›æ¡¥æ¢ã€‚</li>
<li>å½“å‰ä¸´åºŠåº”ç”¨å—é™äºæŠ€æœ¯æŒ‘æˆ˜ï¼Œå¦‚ä½ä¿¡å™ªæ¯”å’Œæ··å ä¼ªå½±ã€‚</li>
<li>RSFRæ¡†æ¶æ—¨åœ¨è§£å†³è¿™äº›æŠ€æœ¯æŒ‘æˆ˜ï¼Œé€šè¿‡é‡å»ºã€åˆ†å‰²ã€èåˆä¸ç»†åŒ–è¿‡ç¨‹ä¼˜åŒ–å›¾åƒè´¨é‡ã€‚</li>
<li>RSFRåˆ©ç”¨è¯­ä¹‰ç‰¹å¾å‡å°‘ä¼ªå½±ï¼Œå¢å¼ºå›¾åƒå‡†ç¡®æ€§ã€‚</li>
<li>RSFRæ¡†æ¶å®ç°äº†å…ˆè¿›çš„é‡å»ºè´¨é‡å’ŒDTå‚æ•°ä¼°è®¡ã€‚</li>
<li>å¤§é‡å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†RSFRçš„ä¼˜è¶Šæ€§ï¼Œå‡¸æ˜¾å…¶ä¸´åºŠè½¬åŒ–çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18520">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0657f851d4825bf0b6f566afb90996c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-066cff8f689078a2e1b723c1ab305a3d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de0eaf1b663688c7a91737b21ff8e537.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MROP-Modulated-Rank-One-Projections-for-compressive-radio-interferometric-imaging"><a href="#MROP-Modulated-Rank-One-Projections-for-compressive-radio-interferometric-imaging" class="headerlink" title="MROP: Modulated Rank-One Projections for compressive radio   interferometric imaging"></a>MROP: Modulated Rank-One Projections for compressive radio   interferometric imaging</h2><p><strong>Authors:Olivier Leblanc, Chung San Chu, Laurent Jacques, Yves Wiaux</strong></p>
<p>The emerging generation of radio-interferometric (RI) arrays are set to form images of the sky with a new regime of sensitivity and resolution. This implies a significant increase in visibility data volumes, scaling as $\mathcal{O}(Q^{2}B)$ for $Q$ antennas and $B$ short-time integration intervals (or batches), calling for efficient data dimensionality reduction techniques. This paper proposes a new approach to data compression during acquisition, coined modulated rank-one projection (MROP). MROP compresses the $Q\times Q$ batchwise covariance matrix into a smaller number $P$ of random rank-one projections and compresses across time by trading $B$ for a smaller number $M$ of random modulations of the ROP measurement vectors. Firstly, we introduce a dual perspective on the MROP acquisition, which can either be understood as random beamforming, or as a post-correlation compression. Secondly, we analyse the noise statistics of MROPs and demonstrate that the random projections induce a uniform noise level across measurements independently of the visibility-weighting scheme used. Thirdly, we propose a detailed analysis of the memory and computational cost requirements across the data acquisition and image reconstruction stages, with comparison to state-of-the-art dimensionality reduction approaches. Finally, the MROP model is validated in simulation for monochromatic intensity imaging, with comparison to the classical and baseline-dependent averaging (BDA) models, and using the uSARA optimisation algorithm for image formation. An extensive experimental setup is considered, with ground-truth images containing diffuse and faint emission and spanning a wide variety of dynamic ranges, and for a range of $uv$-coverages corresponding to VLA and MeerKAT observation. </p>
<blockquote>
<p>æ–°ä¸€ä»£å°„ç”µå¹²æ¶‰æµ‹é‡ï¼ˆRIï¼‰é˜µåˆ—å°†ä»¥æ–°çš„çµæ•åº¦å’Œåˆ†è¾¨ç‡æœºåˆ¶å½¢æˆå¤©ç©ºå›¾åƒã€‚è¿™æ„å‘³ç€å¯è§æ•°æ®é‡å¤§å¹…å¢åŠ ï¼Œéšç€å¤©çº¿æ•°é‡Qå’ŒçŸ­æ—¶é—´ç§¯åˆ†é—´éš”ï¼ˆæˆ–æ‰¹æ¬¡ï¼‰Bçš„å¢åŠ ï¼Œæ•°æ®é‡çš„å¢é•¿é‡çº§ä¸º$\mathcal{O}(Q^{2}B)$ï¼Œå› æ­¤éœ€è¦é«˜æ•ˆçš„æ•°æ®é™ç»´æŠ€æœ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å‹ç¼©é‡‡é›†æ–¹æ³•ï¼Œç§°ä¸ºè°ƒåˆ¶ç§©ä¸€æŠ•å½±ï¼ˆMROPï¼‰ã€‚MROPå°†$Q\times Q$æ‰¹å¤„ç†åæ–¹å·®çŸ©é˜µå‹ç¼©æˆè¾ƒå°æ•°é‡çš„éšæœºç§©ä¸€æŠ•å½±Pï¼Œå¹¶é€šè¿‡ç”¨è¾ƒå°çš„è°ƒåˆ¶æ•°Mä»£æ›¿æ—¶é—´å‹ç¼©ï¼Œå¯¹éšæœºè°ƒåˆ¶çš„ROPæµ‹é‡å‘é‡è¿›è¡Œå‹ç¼©ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¹MROPé‡‡é›†è¿›è¡Œäº†åŒé‡è§’åº¦çš„ä»‹ç»ï¼Œå¯ä»¥å°†å…¶ç†è§£ä¸ºéšæœºæ³¢æŸå½¢æˆï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸ºåå…³è”å‹ç¼©ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åˆ†æäº†MROPçš„å™ªå£°ç»Ÿè®¡ï¼Œå¹¶è¯æ˜éšæœºæŠ•å½±ä¼šåœ¨æµ‹é‡ä¸­å¼•èµ·å‡åŒ€å™ªå£°æ°´å¹³ï¼Œä¸ä½¿ç”¨å¯è§æ€§åŠ æƒæ–¹æ¡ˆæ— å…³ã€‚å†æ¬¡ï¼Œæˆ‘ä»¬è¯¦ç»†åˆ†æäº†æ•°æ®é‡‡é›†å’Œå›¾åƒé‡å»ºé˜¶æ®µæ‰€éœ€çš„å†…å­˜å’Œè®¡ç®—æˆæœ¬è¦æ±‚ï¼Œå¹¶ä¸æœ€æ–°çš„é™ç»´æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚æœ€åï¼Œé€šè¿‡æ¨¡æ‹Ÿå¯¹MROPæ¨¡å‹è¿›è¡Œäº†å•è‰²å¼ºåº¦æˆåƒçš„éªŒè¯ï¼Œå¹¶ä¸ç»å…¸æ¨¡å‹å’ŒåŸºçº¿ä¾èµ–å¹³å‡ï¼ˆBDAï¼‰æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒï¼Œä½¿ç”¨uSARAä¼˜åŒ–ç®—æ³•è¿›è¡Œæˆåƒã€‚å®éªŒè€ƒè™‘äº†å¹¿æ³›çš„è®¾ç½®ï¼ŒåŒ…æ‹¬åŒ…å«æ¼«å°„å’Œå¾®å¼±å‘å°„çš„çœŸå®å›¾åƒä»¥åŠå„ç§å„æ ·çš„åŠ¨æ€èŒƒå›´ï¼Œä»¥åŠå¯¹åº”äºVLAå’ŒMeerKATè§‚æµ‹çš„ä¸€ç³»åˆ—uvè¦†ç›–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18446v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æ–°ä¸€ä»£å°„ç”µå¹²æ¶‰æµ‹é‡é˜µåˆ—ï¼ˆRI arraysï¼‰å°†å½¢æˆå¤©ç©ºå›¾åƒï¼Œå…·æœ‰æ–°çš„æ•æ„Ÿæ€§å’Œåˆ†è¾¨ç‡ã€‚éšç€æ•°æ®é‡çš„å¢é•¿ï¼Œéœ€è¦é«˜æ•ˆçš„æ•°æ®é™ç»´æŠ€æœ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å‹ç¼©é‡‡é›†æ–¹æ³•â€”â€”è°ƒåˆ¶ç§©ä¸€æŠ•å½±ï¼ˆMROPï¼‰ã€‚MROPå°†QQæ‰¹å¤„ç†åæ–¹å·®çŸ©é˜µå‹ç¼©æˆè¾ƒå°çš„éšæœºç§©ä¸€æŠ•å½±ï¼Œå¹¶é€šè¿‡æ—¶é—´äº¤æ¢å‹ç¼©ã€‚æœ¬æ–‡ä»‹ç»äº†MROPé‡‡é›†çš„åŒé‡è§†è§’ï¼Œåˆ†æäº†MROPçš„å™ªå£°ç»Ÿè®¡ï¼Œå¹¶ä¸å…¶ä»–é™ç»´æ–¹æ³•æ¯”è¾ƒäº†å†…å­˜å’Œè®¡ç®—æˆæœ¬è¦æ±‚ã€‚æœ€åï¼Œé€šè¿‡æ¨¡æ‹ŸéªŒè¯äº†MROPæ¨¡å‹åœ¨å•è‰²å¼ºåº¦æˆåƒä¸­çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–°ä¸€ä»£RI arrayså°†æé«˜å›¾åƒæ•æ„Ÿæ€§å’Œåˆ†è¾¨ç‡ï¼Œå¯¼è‡´æ•°æ®é‡å¤§å¹…å¢åŠ ã€‚</li>
<li>æ•°æ®é™ç»´æŠ€æœ¯å¯¹äºå¤„ç†å¤§è§„æ¨¡æ•°æ®è‡³å…³é‡è¦ã€‚</li>
<li>MROPæ˜¯ä¸€ç§æ–°çš„æ•°æ®å‹ç¼©é‡‡é›†æ–¹æ³•ï¼Œé€šè¿‡éšæœºç§©ä¸€æŠ•å½±å’Œè°ƒåˆ¶æ¥å‹ç¼©æ•°æ®ã€‚</li>
<li>MROPé‡‡é›†å…·æœ‰åŒé‡è§†è§’ï¼šéšæœºæ³¢æŸå½¢æˆæˆ–åå…³è”å‹ç¼©ã€‚</li>
<li>MROPçš„å™ªå£°ç»Ÿè®¡ç‰¹æ€§è¢«åˆ†æï¼Œè¡¨æ˜éšæœºæŠ•å½±åœ¨æ‰€æœ‰æµ‹é‡ä¸­äº§ç”Ÿå‡åŒ€å™ªå£°æ°´å¹³ã€‚</li>
<li>ç›¸è¾ƒäºå…¶ä»–é™ç»´æ–¹æ³•ï¼ŒMROPåœ¨å†…å­˜å’Œè®¡ç®—æˆæœ¬æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18446">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9ba7ef76613e0125503a51fae144c7af.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f3032e84d47d054cbb8ce322ff2fba8b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HepatoGEN-Generating-Hepatobiliary-Phase-MRI-with-Perceptual-and-Adversarial-Models"><a href="#HepatoGEN-Generating-Hepatobiliary-Phase-MRI-with-Perceptual-and-Adversarial-Models" class="headerlink" title="HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and   Adversarial Models"></a>HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and   Adversarial Models</h2><p><strong>Authors:Jens Hooge, Gerard Sanroma-Guell, Faidra Stavropoulou, Alexander Ullmann, Gesine Knobloch, Mark Klemens, Carola Schmidt, Sabine Weckbach, Andreas Bolz</strong></p>
<p>Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) plays a crucial role in the detection and characterization of focal liver lesions, with the hepatobiliary phase (HBP) providing essential diagnostic information. However, acquiring HBP images requires prolonged scan times, which may compromise patient comfort and scanner throughput. In this study, we propose a deep learning based approach for synthesizing HBP images from earlier contrast phases (precontrast and transitional) and compare three generative models: a perceptual U-Net, a perceptual GAN (pGAN), and a denoising diffusion probabilistic model (DDPM). We curated a multi-site DCE-MRI dataset from diverse clinical settings and introduced a contrast evolution score (CES) to assess training data quality, enhancing model performance. Quantitative evaluation using pixel-wise and perceptual metrics, combined with qualitative assessment through blinded radiologist reviews, showed that pGAN achieved the best quantitative performance but introduced heterogeneous contrast in out-of-distribution cases. In contrast, the U-Net produced consistent liver enhancement with fewer artifacts, while DDPM underperformed due to limited preservation of fine structural details. These findings demonstrate the feasibility of synthetic HBP image generation as a means to reduce scan time without compromising diagnostic utility, highlighting the clinical potential of deep learning for dynamic contrast enhancement in liver MRI. A project demo is available at: <a target="_blank" rel="noopener" href="https://jhooge.github.io/hepatogen">https://jhooge.github.io/hepatogen</a> </p>
<blockquote>
<p>åŠ¨æ€å¢å¼ºç£å…±æŒ¯æˆåƒï¼ˆDCE-MRIï¼‰åœ¨æ£€æµ‹å’Œè¯†åˆ«å±€éƒ¨è‚è„ç—…å˜ä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œå…¶ä¸­è‚èƒ†ç›¸ï¼ˆHBPï¼‰æä¾›äº†å…³é”®çš„è¯Šæ–­ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè·å–HBPå›¾åƒéœ€è¦é•¿æ—¶é—´çš„æ‰«æï¼Œå¯èƒ½ä¼šå½±å“æ‚£è€…çš„èˆ’é€‚åº¦å’Œæ‰«æå™¨çš„é€šè¿‡ç‡ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œç”¨äºä»æ—©æœŸçš„å¯¹æ¯”é˜¶æ®µï¼ˆé¢„å¯¹æ¯”å’Œè¿‡æ¸¡é˜¶æ®µï¼‰åˆæˆHBPå›¾åƒï¼Œå¹¶æ¯”è¾ƒäº†ä¸‰ç§ç”Ÿæˆæ¨¡å‹ï¼šæ„ŸçŸ¥U-Netã€æ„ŸçŸ¥GANï¼ˆpGANï¼‰å’Œå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ã€‚æˆ‘ä»¬ä»ä¸åŒçš„ä¸´åºŠç¯å¢ƒä¸­æ•´ç†äº†ä¸€ä¸ªå¤šç«™ç‚¹DCE-MRIæ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªå¯¹æ¯”æ¼”åŒ–åˆ†æ•°ï¼ˆCESï¼‰æ¥è¯„ä¼°è®­ç»ƒæ•°æ®çš„è´¨é‡ï¼Œä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚åˆ©ç”¨åƒç´ çº§å’Œæ„ŸçŸ¥æŒ‡æ ‡çš„å®šé‡è¯„ä¼°ï¼Œç»“åˆé€šè¿‡ç›²æ”¾å°„ç§‘åŒ»ç”Ÿå®¡æŸ¥çš„å®šæ€§è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºpGANåœ¨å®šé‡æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œä½†åœ¨éåˆ†å¸ƒæ¡ˆä¾‹ä¸­å¼•å…¥äº†å¼‚è´¨å¯¹æ¯”ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒU-Netäº§ç”Ÿçš„è‚è„å¢å¼ºæ•ˆæœä¸€è‡´ä¸”ä¼ªå½±è¾ƒå°‘ï¼Œè€ŒDDPMç”±äºç²¾ç»†ç»“æ„ç»†èŠ‚ä¿å­˜æœ‰é™è€Œè¡¨ç°ä¸ä½³ã€‚è¿™äº›å‘ç°è¯æ˜äº†åˆæˆHBPå›¾åƒç”Ÿæˆçš„å¯è¡Œæ€§ï¼Œä½œä¸ºä¸€ç§å‡å°‘æ‰«ææ—¶é—´è€Œä¸å½±å“è¯Šæ–­æ•ˆç”¨çš„æ‰‹æ®µï¼Œçªå‡ºäº†æ·±åº¦å­¦ä¹ åœ¨è‚è„MRIåŠ¨æ€å¯¹æ¯”å¢å¼ºä¸­çš„ä¸´åºŠæ½œåŠ›ã€‚é¡¹ç›®æ¼”ç¤ºå¯åœ¨ï¼š[<a target="_blank" rel="noopener" href="https://jhooge.github.io/hepatogen]">https://jhooge.github.io/hepatogen]</a> å¤„æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18405v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åŠ¨æ€å¯¹æ¯”å¢å¼ºç£å…±æŒ¯æˆåƒï¼ˆDCE-MRIï¼‰ä¸­è‚èƒ†ç›¸ï¼ˆHBPï¼‰å›¾åƒåˆæˆçš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ä»æ—©æœŸå¯¹æ¯”ç›¸åˆæˆHBPå›¾åƒã€‚ç ”ç©¶ä¸­æ¯”è¾ƒäº†ä¸‰ç§ç”Ÿæˆæ¨¡å‹ï¼šæ„ŸçŸ¥U-Netã€æ„ŸçŸ¥GANï¼ˆpGANï¼‰å’Œå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ã€‚é€šè¿‡å¯¹æ¯”å®šé‡è¯„ä¼°å’Œæ”¾å°„ç§‘åŒ»ç”Ÿç›²å®¡ç»“æœï¼Œå‘ç°pGANåœ¨å®šé‡æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œä½†åœ¨å¼‚å¸¸æƒ…å†µä¸‹å¼•å…¥äº†å¼‚è´¨å¯¹æ¯”ã€‚U-Netåœ¨ä¿æŒè‚è„å¢å¼ºä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ï¼ŒDDPMåˆ™å› ç»†èŠ‚ä¿ç•™ä¸è¶³è€Œè¡¨ç°è¾ƒå·®ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåˆæˆHBPå›¾åƒæ˜¯å‡å°‘æ‰«ææ—¶é—´è€Œä¸æŸå¤±è¯Šæ–­ä»·å€¼çš„æœ‰æ•ˆæ‰‹æ®µï¼Œçªæ˜¾æ·±åº¦å­¦ä¹ åœ¨è‚è„MRIåŠ¨æ€å¯¹æ¯”å¢å¼ºä¸­çš„ä¸´åºŠæ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DCE-MRIä¸­HBPå›¾åƒå¯¹ç„¦ç‚¹è‚ç—…å˜çš„æ£€æµ‹å’Œç‰¹å¾è¡¨å¾è‡³å…³é‡è¦ã€‚</li>
<li>HBPå›¾åƒçš„è·å–éœ€è¦é•¿æ—¶é—´æ‰«æï¼Œå¯èƒ½å½±å“æ‚£è€…èˆ’é€‚åº¦å’Œæ‰«ææ•ˆç‡ã€‚</li>
<li>æ·±åº¦å­¦ä¹ å¯ç”¨äºä»æ—©æœŸå¯¹æ¯”é˜¶æ®µåˆæˆHBPå›¾åƒï¼Œå‡å°‘æ‰«ææ—¶é—´ã€‚</li>
<li>å¯¹æ¯”äº†ä¸‰ç§ç”Ÿæˆæ¨¡å‹ï¼šæ„ŸçŸ¥U-Netã€æ„ŸçŸ¥GANï¼ˆpGANï¼‰å’ŒDDPMã€‚</li>
<li>pGANåœ¨å®šé‡æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œä½†åœ¨å¼‚å¸¸æƒ…å†µä¸‹å¼•å…¥å¼‚è´¨å¯¹æ¯”ã€‚</li>
<li>U-Netåœ¨ä¿æŒè‚è„å¢å¼ºä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œä¸”è¾ƒå°‘å‡ºç°ä¼ªå½±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18405">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-547cef32d1f32460f8232c19f800711d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9bef3cff7c330ba392a0ee5f6493c04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf76e504ce111178bf9a726ed6afb24f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2750d63ee69b4b95686a9dde45922b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ac6191106ca499bf8cd26e7bec987cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24327b92d9ea00cb6f12f199f2069f3a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-Multimodal-Deep-Learning-Approach-for-White-Matter-Shape-Prediction-in-Diffusion-MRI-Tractography"><a href="#A-Multimodal-Deep-Learning-Approach-for-White-Matter-Shape-Prediction-in-Diffusion-MRI-Tractography" class="headerlink" title="A Multimodal Deep Learning Approach for White Matter Shape Prediction in   Diffusion MRI Tractography"></a>A Multimodal Deep Learning Approach for White Matter Shape Prediction in   Diffusion MRI Tractography</h2><p><strong>Authors:Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Fan Zhang, Weidong Cai, Lauren J. Oâ€™Donnell</strong></p>
<p>Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) features to predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model to predict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearsonâ€™s r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearsonâ€™s r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis. </p>
<blockquote>
<p>å½¢æ€æµ‹é‡å·²ä½œä¸ºæœ‰å‰é€”çš„ç™½è´¨è½¨è¿¹æè¿°æ–¹æ³•å‡ºç°ï¼Œä¸ºè§£å‰–å˜å¼‚æ€§æä¾›äº†è¡¥å……è§è§£ï¼Œå¹¶ä¸è®¤çŸ¥å’Œä¸´åºŠè¡¨å‹ç›¸å…³è”ã€‚ç„¶è€Œï¼Œç”±äºä¼ ç»Ÿè®¡ç®—å½¢æ€æµ‹é‡çš„æ–¹æ³•ä¾èµ–äºåŸºäºä½“ç´ ï¼ˆvoxel-basedï¼‰çš„è¡¨ç¤ºï¼Œå› æ­¤åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚æˆ‘ä»¬æå‡ºäº†Tract2Shapeï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ¨¡å¼æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å‡ ä½•ï¼ˆç‚¹äº‘ï¼‰å’Œæ ‡é‡ï¼ˆè¡¨æ ¼ï¼‰ç‰¹å¾æ¥é¢„æµ‹åä¸ªç™½è´¨è½¨è¿¹å½¢æ€æµ‹é‡æ–¹æ³•ã€‚ä¸ºäº†æé«˜æ¨¡å‹æ•ˆç‡ï¼Œæˆ‘ä»¬ä½¿ç”¨é™ç»´ç®—æ³•æ¥é¢„æµ‹äº”ä¸ªä¸»è¦å½¢æ€æˆåˆ†ã€‚è¯¥æ¨¡å‹åœ¨ä¸¤ä¸ªç‹¬ç«‹è·å–çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œå³HCP-YAæ•°æ®é›†å’ŒPPMIæ•°æ®é›†ã€‚æˆ‘ä»¬é€šè¿‡è®­ç»ƒTract2Shapeå¹¶åœ¨HCP-YAæ•°æ®é›†ä¸Šæµ‹è¯•å®ƒï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„æ¨¡å‹æ¯”è¾ƒç»“æœæ¥è¯„ä¼°å…¶æ€§èƒ½ã€‚ä¸ºäº†è¿›ä¸€æ­¥è¯„ä¼°å…¶ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæˆ‘ä»¬è¿˜å¯¹æœªè§è¿‡çš„PPMIæ•°æ®é›†è¿›è¡Œäº†Tract2Shapeæµ‹è¯•ã€‚Tract2Shapeåœ¨æ‰€æœ‰åä¸ªå½¢æ€æµ‹é‡æŒ‡æ ‡ä¸Šå‡ä¼˜äºSOTAæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œåœ¨HCP-YAæ•°æ®é›†ä¸Šå–å¾—äº†æœ€é«˜çš„å¹³å‡Pearson rå€¼å’Œæœ€ä½çš„å¹³å‡å¹³æ–¹è¯¯å·®ï¼ˆnMSEï¼‰ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œå¤šæ¨¡å¼è¾“å…¥å’Œä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰éƒ½æœ‰åŠ©äºæ€§èƒ½æå‡ã€‚åœ¨æœªè§çš„æµ‹è¯•æ•°æ®é›†PPMIä¸Šï¼ŒTract2Shapeä¿æŒäº†è¾ƒé«˜çš„Pearson rå€¼å’Œè¾ƒä½çš„nMSEå€¼ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„è·¨æ•°æ®é›†è¯„ä¼°æ³›åŒ–èƒ½åŠ›ã€‚Tract2Shapeèƒ½å¤Ÿä»è½¨è¿¹æ•°æ®å¿«é€Ÿã€å‡†ç¡®ã€é€šç”¨åœ°é¢„æµ‹ç™½è´¨å½¢æ€æµ‹é‡æŒ‡æ ‡ï¼Œæ”¯æŒè·¨æ•°æ®é›†çš„å¯æ‰©å±•æ€§åˆ†æã€‚è¿™ä¸€æ¡†æ¶ä¸ºæœªæ¥å¤§è§„æ¨¡ç™½è´¨å½¢æ€åˆ†æå¥ å®šäº†æœ‰å‰é€”çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18400v1">PDF</a> 21 pages, 3 figures, 6 tables</p>
<p><strong>Summary</strong><br>     æå‡ºä¸€ç§åä¸ºTract2Shapeçš„å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨å‡ ä½•ç‚¹äº‘å’Œæ ‡é‡ç‰¹å¾é¢„æµ‹ç™½è´¨è½¨è¿¹å›¾å½¢çŠ¶æŒ‡æ ‡ã€‚é€šè¿‡é™ä½ç»´åº¦çš„æ–¹æ³•æå‡æ¨¡å‹æ•ˆç‡å¹¶é¢„æµ‹ä¸»è¦å½¢çŠ¶æˆåˆ†ã€‚è¯¥æ¨¡å‹åœ¨ä¸¤ä¸ªç‹¬ç«‹æ•°æ®é›†ä¸Šçš„è®­ç»ƒå’Œè¯„ä¼°è¡¨ç°ä¼˜å¼‚ï¼Œä¸”åœ¨æœªè§æ•°æ®é›†ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚Tract2Shapeä¸ºå¿«é€Ÿã€å‡†ç¡®å’Œé€šç”¨çš„ç™½è´¨å½¢çŠ¶æŒ‡æ ‡é¢„æµ‹æä¾›äº†æ”¯æŒï¼Œä¸ºå¤§è§„æ¨¡æ•°æ®é›†çš„ç™½è´¨å½¢çŠ¶åˆ†ææä¾›äº†å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç™½è´¨è½¨è¿¹å›¾å½¢çŠ¶æŒ‡æ ‡ä½œä¸ºè®¤çŸ¥å’Œä¸´åºŠç°è±¡çš„é‡è¦è¡¥å……ä¿¡æ¯ã€‚</li>
<li>å¸¸è§„è®¡ç®—å½¢çŠ¶æŒ‡æ ‡çš„æ–¹æ³•å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†å­˜åœ¨è®¡ç®—æ˜‚è´µå’Œæ—¶é—´æ¶ˆè€—çš„é—®é¢˜ã€‚</li>
<li>æå‡ºTract2Shapeå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨ç‚¹äº‘å’Œæ ‡é‡ç‰¹å¾é¢„æµ‹ç™½è´¨è½¨è¿¹å›¾å½¢çŠ¶æŒ‡æ ‡ã€‚</li>
<li>é€šè¿‡é™ä½ç»´åº¦æé«˜æ¨¡å‹æ•ˆç‡ï¼Œé¢„æµ‹ä¸»è¦å½¢çŠ¶æˆåˆ†ã€‚</li>
<li>åœ¨ä¸¤ä¸ªç‹¬ç«‹æ•°æ®é›†ä¸Šçš„è®­ç»ƒå’Œè¯„ä¼°è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>Tract2Shapeåœ¨æœªè§æ•°æ®é›†ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18400">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0c7c2a2d7f366b6cf266a0da24959227.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e305238ba42c7dc7b1b0f7787cedf57.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Towards-a-deep-learning-approach-for-classifying-treatment-response-in-glioblastomas"><a href="#Towards-a-deep-learning-approach-for-classifying-treatment-response-in-glioblastomas" class="headerlink" title="Towards a deep learning approach for classifying treatment response in   glioblastomas"></a>Towards a deep learning approach for classifying treatment response in   glioblastomas</h2><p><strong>Authors:Ana Matoso, Catarina Passarinho, Marta P. Loureiro, JosÃ© Maria Moreira, PatrÃ­cia Figueiredo, Rita G. Nunes</strong></p>
<p>Glioblastomas are the most aggressive type of glioma, having a 5-year survival rate of 6.9%. Treatment typically involves surgery, followed by radiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI) scans to monitor disease progression. To assess treatment response, radiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to categorize the tumor into one of four labels based on imaging and clinical features: complete response, partial response, stable disease, and progressive disease. This assessment is very complex and time-consuming. Since deep learning (DL) has been widely used to tackle classification problems, this work aimed to implement the first DL pipeline for the classification of RANO criteria based on two consecutive MRI acquisitions. The models were trained and tested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction of input images, 2) different combinations of modalities, 3) different model architectures, 4) different pretraining tasks, and 5) adding clinical data. The pipeline that achieved the best performance used a Densenet264 considering only T1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR) images as input without any pretraining. A median Balanced Accuracy of 50.96% was achieved. Additionally, explainability methods were applied. Using Saliency Maps, the tumor region was often successfully highlighted. In contrast, Grad-CAM typically failed to highlight the tumor region, with some exceptions observed in the Complete Response and Progressive Disease classes, where it effectively identified the tumor region. These results set a benchmark for future studies on glioblastoma treatment response assessment based on the RANO criteria while emphasizing the heterogeneity of factors that might play a role when assessing the tumorâ€™s response to treatment. </p>
<blockquote>
<p>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯æœ€å…·ä¾µè¢­æ€§çš„èƒ¶è´¨ç˜¤ç±»å‹ï¼Œ5å¹´å­˜æ´»ç‡ä¸º6.9%ã€‚æ²»ç–—é€šå¸¸åŒ…æ‹¬æ‰‹æœ¯ï¼Œç„¶åæ˜¯æ”¾ç–—å’ŒåŒ–ç–—ï¼Œä»¥åŠç»å¸¸è¿›è¡Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ‰«æä»¥ç›‘æµ‹ç–¾ç—…è¿›å±•ã€‚ä¸ºäº†è¯„ä¼°æ²»ç–—ååº”ï¼Œæ”¾å°„ç§‘åŒ»ç”Ÿä½¿ç”¨ç¥ç»è‚¿ç˜¤å­¦ååº”è¯„ä¼°ï¼ˆRANOï¼‰æ ‡å‡†ï¼Œæ ¹æ®å½±åƒå­¦å’Œä¸´åºŠç‰¹å¾å°†è‚¿ç˜¤åˆ†ä¸ºå››ç§æ ‡ç­¾ï¼šå®Œå…¨ååº”ã€éƒ¨åˆ†ååº”ã€ç¨³å®šæ€§ç–¾ç—…å’Œè¿›å±•æ€§ç–¾ç—…ã€‚è¿™ç§è¯„ä¼°éå¸¸å¤æ‚ä¸”è€—æ—¶ã€‚ç”±äºæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰å·²å¹¿æ³›åº”ç”¨äºè§£å†³åˆ†ç±»é—®é¢˜ï¼Œå› æ­¤ï¼Œè¿™é¡¹å·¥ä½œæ—¨åœ¨å®æ–½åŸºäºä¸¤æ¬¡è¿ç»­MRIé‡‡é›†çš„RANOæ ‡å‡†åˆ†ç±»çš„ç¬¬ä¸€ä¸ªDLç®¡é“ã€‚æ¨¡å‹åœ¨å…¬å¼€æ•°æ®é›†LUMIEREä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚æµ‹è¯•äº†äº”ç§æ–¹æ³•ï¼š1ï¼‰è¾“å…¥å›¾åƒçš„å‡æ³•ï¼Œ2ï¼‰ä¸åŒæ¨¡æ€çš„ç»„åˆï¼Œ3ï¼‰ä¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œ4ï¼‰ä¸åŒçš„é¢„è®­ç»ƒä»»åŠ¡ï¼Œä»¥åŠ5ï¼‰æ·»åŠ ä¸´åºŠæ•°æ®ã€‚è¡¨ç°æœ€ä½³çš„ç®¡é“ä»…ä½¿ç”¨Densenet264ï¼Œä»…è€ƒè™‘T1åŠ æƒã€T2åŠ æƒå’Œæ¶²ä½“è¡°å‡åè½¬æ¢å¤ï¼ˆFLAIRï¼‰å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæ— éœ€ä»»ä½•é¢„è®­ç»ƒã€‚å–å¾—äº†50.96%çš„ä¸­ä½æ•°å¹³è¡¡ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¿˜åº”ç”¨äº†å¯è§£é‡Šæ€§æ–¹æ³•ã€‚ä½¿ç”¨æ˜¾è‘—æ€§å›¾ï¼ˆSaliency Mapsï¼‰ï¼Œè‚¿ç˜¤åŒºåŸŸé€šå¸¸è¢«æˆåŠŸçªå‡ºæ˜¾ç¤ºã€‚ç›¸åï¼ŒGrad-CAMé€šå¸¸æœªèƒ½çªå‡ºæ˜¾ç¤ºè‚¿ç˜¤åŒºåŸŸï¼Œä½†åœ¨å®Œå…¨ååº”å’Œè¿›å±•æ€§ç–¾ç—…ç±»åˆ«ä¸­è§‚å¯Ÿåˆ°ä¸€äº›ä¾‹å¤–ï¼Œåœ¨è¿™äº›ç±»åˆ«ä¸­ï¼Œå®ƒæœ‰æ•ˆåœ°è¯†åˆ«äº†è‚¿ç˜¤åŒºåŸŸã€‚è¿™äº›ç»“æœä¸ºåŸºäºRANOæ ‡å‡†çš„èƒ¶è´¨æ¯ç»†èƒç˜¤æ²»ç–—ååº”è¯„ä¼°çš„æœªæ¥ç ”ç©¶è®¾å®šäº†åŸºå‡†ï¼ŒåŒæ—¶å¼ºè°ƒäº†è¯„ä¼°è‚¿ç˜¤å¯¹æ²»ç–—ååº”æ—¶å¯èƒ½èµ·ä½œç”¨çš„å› ç´ çš„å¼‚è´¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18268v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†èƒ¶è´¨æ¯ç»†èƒç˜¤çš„æ²»ç–—ååº”è¯„ä¼°ã€‚ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•å¤æ‚è€—æ—¶ï¼Œç°é‡‡ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯å»ºç«‹åˆ†ç±»æ¨¡å‹ã€‚æœ€ä½³æ¨¡å‹åŸºäºDensenet264æ¶æ„ï¼Œä½¿ç”¨T1åŠ æƒã€T2åŠ æƒå’ŒFLAIRå›¾åƒä¸ºè¾“å…¥ï¼Œæ— éœ€é¢„è®­ç»ƒï¼Œè¾¾åˆ°å¹³è¡¡ç²¾åº¦ä¸º50.96%ã€‚åˆ©ç”¨è§£é‡Šæ€§æ–¹æ³•ï¼Œå¦‚æ˜¾è‘—æ€§å›¾ï¼ˆSaliency Mapsï¼‰ï¼ŒæˆåŠŸçªå‡ºè‚¿ç˜¤åŒºåŸŸã€‚ä¸è¿‡ï¼ŒGrad-CAMåœ¨å¤šæ•°æƒ…å†µä¸‹æœªèƒ½æœ‰æ•ˆæ ‡è¯†è‚¿ç˜¤åŒºåŸŸï¼Œä½†åœ¨å®Œå…¨ååº”å’Œç–¾ç—…è¿›å±•ç±»åˆ«ä¸­æœ‰è¾ƒå¥½è¡¨ç°ã€‚è¿™ä¸ºåŸºäºRANOæ ‡å‡†çš„èƒ¶è´¨æ¯ç»†èƒç˜¤æ²»ç–—ååº”è¯„ä¼°æä¾›äº†åŸºå‡†ï¼Œå¹¶å¼ºè°ƒäº†è¯„ä¼°è‚¿ç˜¤ååº”æ—¶å¯èƒ½å­˜åœ¨çš„å› ç´ å¼‚è´¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>èƒ¶è´¨æ¯ç»†èƒç˜¤æ˜¯èƒ¶è´¨ç˜¤ä¸­æœ€å…·ä¾µè¢­æ€§çš„ç±»å‹ï¼Œå…¶äº”å¹´å­˜æ´»ç‡ä¸º6.9%ã€‚</li>
<li>æ²»ç–—é€šå¸¸åŒ…æ‹¬æ‰‹æœ¯ã€æ”¾ç–—å’ŒåŒ–ç–—ï¼Œä»¥åŠé€šè¿‡MRIæ‰«æç›‘æµ‹ç–¾ç—…è¿›å±•ã€‚</li>
<li>ä½¿ç”¨RANOæ ‡å‡†è¯„ä¼°æ²»ç–—ååº”æ¶‰åŠå¤æ‚çš„åˆ†ç±»é—®é¢˜ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯å»ºç«‹æ¨¡å‹ï¼Œä»¥MRIå›¾åƒä¸ºåŸºç¡€è¿›è¡ŒRANOæ ‡å‡†çš„åˆ†ç±»ã€‚</li>
<li>æœ€ä½³æ¨¡å‹ä½¿ç”¨Densenet264æ¶æ„ï¼Œä»…è€ƒè™‘T1ã€T2åŠ æƒå’ŒFLAIRå›¾åƒä½œä¸ºè¾“å…¥ï¼Œæ— éœ€é¢„è®­ç»ƒï¼Œè¾¾åˆ°å¹³è¡¡ç²¾åº¦ä¸º50.96%ã€‚</li>
<li>é€šè¿‡è§£é‡Šæ€§æ–¹æ³•ï¼Œå¦‚æ˜¾è‘—æ€§å›¾ï¼ˆSaliency Mapsï¼‰ï¼Œèƒ½å¤Ÿçªå‡ºè‚¿ç˜¤åŒºåŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18268">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-da258d68152885ac494ca45a9309992e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-476a19b4c02c9e7bf9f145d1382e764c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-033f995ca453573766e995c7a519d5d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e7e121ad2f411c9ac565468950d6445.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8956dcd16381af8d5f241161e0a753e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Physics-Driven-Neural-Compensation-For-Electrical-Impedance-Tomography"><a href="#Physics-Driven-Neural-Compensation-For-Electrical-Impedance-Tomography" class="headerlink" title="Physics-Driven Neural Compensation For Electrical Impedance Tomography"></a>Physics-Driven Neural Compensation For Electrical Impedance Tomography</h2><p><strong>Authors:Chuyu Wang, Huiting Deng, Dong Liu</strong></p>
<p>Electrical Impedance Tomography (EIT) provides a non-invasive, portable imaging modality with significant potential in medical and industrial applications. Despite its advantages, EIT encounters two primary challenges: the ill-posed nature of its inverse problem and the spatially variable, location-dependent sensitivity distribution. Traditional model-based methods mitigate ill-posedness through regularization but overlook sensitivity variability, while supervised deep learning approaches require extensive training data and lack generalization. Recent developments in neural fields have introduced implicit regularization techniques for image reconstruction, but these methods typically neglect the physical principles underlying EIT, thus limiting their effectiveness. In this study, we propose PhyNC (Physics-driven Neural Compensation), an unsupervised deep learning framework that incorporates the physical principles of EIT. PhyNC addresses both the ill-posed inverse problem and the sensitivity distribution by dynamically allocating neural representational capacity to regions with lower sensitivity, ensuring accurate and balanced conductivity reconstructions. Extensive evaluations on both simulated and experimental data demonstrate that PhyNC outperforms existing methods in terms of detail preservation and artifact resistance, particularly in low-sensitivity regions. Our approach enhances the robustness of EIT reconstructions and provides a flexible framework that can be adapted to other imaging modalities with similar challenges. </p>
<blockquote>
<p>ç”µé˜»æŠ—æ–­å±‚æ‰«æï¼ˆEITï¼‰æä¾›äº†ä¸€ç§éä¾µå…¥æ€§ã€ä¾¿æºå¼çš„æˆåƒæ–¹å¼ï¼Œåœ¨åŒ»ç–—å’Œå·¥ä¸šåº”ç”¨ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚å°½ç®¡å…·æœ‰ä¼˜åŠ¿ï¼Œä½†EITé¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šå…¶åé—®é¢˜çš„ç—…æ€æ€§è´¨å’Œç©ºé—´å˜åŒ–ã€ä½ç½®ä¾èµ–çš„çµæ•åº¦åˆ†å¸ƒã€‚ä¼ ç»ŸåŸºäºæ¨¡å‹çš„æ–¹æ³•é€šè¿‡æ­£åˆ™åŒ–æ¥ç¼“è§£ä¸é€‚å®šæ€§ï¼Œä½†å¿½ç•¥äº†çµæ•åº¦çš„å˜åŒ–ï¼Œè€Œç›‘ç£æ·±åº¦å­¦ä¹ çš„æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ä¸”ç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚æœ€è¿‘ç¥ç»ç½‘ç»œé¢†åŸŸçš„å‘å±•å¼•å…¥äº†éšå¼æ­£åˆ™åŒ–æŠ€æœ¯ç”¨äºå›¾åƒé‡å»ºï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸å¿½ç•¥äº†EITèƒŒåçš„ç‰©ç†åŸç†ï¼Œä»è€Œé™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†PhyNCï¼ˆç‰©ç†é©±åŠ¨ç¥ç»ç½‘ç»œè¡¥å¿ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆäº†EITç‰©ç†åŸç†çš„æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚PhyNCé€šè¿‡åŠ¨æ€åˆ†é…ç¥ç»è¡¨å¾å®¹é‡åˆ°çµæ•åº¦è¾ƒä½çš„åŒºåŸŸï¼Œè§£å†³äº†ä¸é€‚å®šçš„åé—®é¢˜å’Œçµæ•åº¦åˆ†å¸ƒé—®é¢˜ï¼Œç¡®ä¿äº†ç²¾ç¡®ä¸”å¹³è¡¡çš„å¯¼ç”µç‡é‡å»ºã€‚å¯¹æ¨¡æ‹Ÿå’Œå®éªŒæ•°æ®çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒPhyNCåœ¨ç»†èŠ‚ä¿ç•™å’ŒæŠ—ä¼ªå½±æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½çµæ•åº¦åŒºåŸŸã€‚æˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†EITé‡å»ºçš„ç¨³å¥æ€§ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥é€‚åº”å…·æœ‰ç±»ä¼¼æŒ‘æˆ˜çš„å…¶ä»–æˆåƒæ¨¡å¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18067v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>EITé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šå…¶åé—®é¢˜çš„ç—…æ€æ€§å’Œçµæ•åº¦åˆ†å¸ƒçš„ç©ºé—´å˜åŒ–æ€§ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§èåˆç‰©ç†åŸç†çš„æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶PhyNCï¼Œè§£å†³EITçš„è¿™ä¸¤ä¸ªé—®é¢˜ã€‚PhyNCé€šè¿‡åŠ¨æ€åˆ†é…ç¥ç»ç½‘ç»œè¡¨å¾å®¹é‡æ¥åº”å¯¹ä½çµæ•åº¦åŒºåŸŸçš„éœ€æ±‚ï¼Œç¡®ä¿å¯¼ç”µç‡é‡å»ºçš„å‡†ç¡®æ€§å’Œå¹³è¡¡æ€§ã€‚è¯„ä¼°å’Œå®éªŒæ•°æ®è¡¨æ˜ï¼ŒPhyNCåœ¨ç»†èŠ‚ä¿ç•™å’ŒæŠ—ä¼ªå½±æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½çµæ•åº¦åŒºåŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EITé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šåé—®é¢˜çš„ç—…æ€æ€§å’Œçµæ•åº¦åˆ†å¸ƒçš„ç©ºé—´å˜åŒ–æ€§ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•é€šè¿‡æ­£åˆ™åŒ–è§£å†³ç—…æ€æ€§é—®é¢˜ï¼Œä½†å¿½ç•¥çµæ•åº¦å˜åŒ–ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œå¹¶ç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æœ€è¿‘ç¥ç»åœºçš„å‘å±•å¼•å…¥äº†éšå¼æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä½†å¿½ç•¥äº†EITçš„ç‰©ç†åŸç†ã€‚</li>
<li>PhyNCæ˜¯ä¸€ç§æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆEITçš„ç‰©ç†åŸç†ã€‚</li>
<li>PhyNCé€šè¿‡åŠ¨æ€åˆ†é…ç¥ç»ç½‘ç»œè¡¨å¾å®¹é‡ï¼Œåº”å¯¹ä½çµæ•åº¦åŒºåŸŸï¼Œç¡®ä¿å¯¼ç”µç‡é‡å»ºçš„å‡†ç¡®æ€§å’Œå¹³è¡¡æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18067">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-07fca6d6a1f4ea7407923e6864254d6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a605a63bc21d33aa1c38145ea7fd1c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-173fa8df783555d04f9e9da8c531b58d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ed6939d700cd994ab588a4f988905a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66c17d7c27908ba31f21bd4fd4234ea9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Federated-Client-tailored-Adapter-for-Medical-Image-Segmentation"><a href="#Federated-Client-tailored-Adapter-for-Medical-Image-Segmentation" class="headerlink" title="Federated Client-tailored Adapter for Medical Image Segmentation"></a>Federated Client-tailored Adapter for Medical Image Segmentation</h2><p><strong>Authors:Guyue Hu, Siyuan Song, Yukun Kang, Zhu Yin, Gangming Zhao, Chenglong Li, Jin Tang</strong></p>
<p>Medical image segmentation in X-ray images is beneficial for computer-aided diagnosis and lesion localization. Existing methods mainly fall into a centralized learning paradigm, which is inapplicable in the practical medical scenario that only has access to distributed data islands. Federated Learning has the potential to offer a distributed solution but struggles with heavy training instability due to client-wise domain heterogeneity (including distribution diversity and class imbalance). In this paper, we propose a novel Federated Client-tailored Adapter (FCA) framework for medical image segmentation, which achieves stable and client-tailored adaptive segmentation without sharing sensitive local data. Specifically, the federated adapter stirs universal knowledge in off-the-shelf medical foundation models to stabilize the federated training process. In addition, we develop two client-tailored federated updating strategies that adaptively decompose the adapter into common and individual components, then globally and independently update the parameter groups associated with common client-invariant and individual client-specific units, respectively. They further stabilize the heterogeneous federated learning process and realize optimal client-tailored instead of sub-optimal global-compromised segmentation models. Extensive experiments on three large-scale datasets demonstrate the effectiveness and superiority of the proposed FCA framework for federated medical segmentation. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒä¸­çš„Xå…‰å›¾åƒåˆ†å‰²å¯¹äºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­å’Œç—…ç¶å®šä½éå¸¸æœ‰ç›Šã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦éµå¾ªé›†ä¸­å¼å­¦ä¹ æ¨¡å¼ï¼Œè¿™åœ¨åªèƒ½è®¿é—®åˆ†å¸ƒå¼æ•°æ®å­¤å²›çš„å®é™…åŒ»ç–—åœºæ™¯ä¸­å¹¶ä¸é€‚ç”¨ã€‚è”é‚¦å­¦ä¹ ï¼ˆFederated Learningï¼‰æœ‰æ½œåŠ›æä¾›åˆ†å¸ƒå¼è§£å†³æ–¹æ¡ˆï¼Œä½†ç”±äºå®¢æˆ·ç«¯åŸŸå¼‚æ„æ€§ï¼ˆåŒ…æ‹¬åˆ†å¸ƒå¤šæ ·æ€§å’Œç±»åˆ«ä¸å¹³è¡¡ï¼‰è€Œé¢ä¸´è®­ç»ƒä¸ç¨³å®šçš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„é’ˆå¯¹åŒ»ç–—å›¾åƒåˆ†å‰²çš„è”é‚¦å®¢æˆ·ç«¯å®šåˆ¶é€‚é…å™¨ï¼ˆFCAï¼‰æ¡†æ¶ï¼Œå®ç°äº†åœ¨ä¸å…±äº«æ•æ„Ÿæœ¬åœ°æ•°æ®çš„æƒ…å†µä¸‹ç¨³å®šå’Œé€‚åº”å®¢æˆ·ç«¯çš„å®šåˆ¶åŒ–åˆ†å‰²ã€‚å…·ä½“æ¥è¯´ï¼Œè”é‚¦é€‚é…å™¨å°†ç°æˆçš„åŒ»å­¦åŸºç¡€æ¨¡å‹ä¸­çš„é€šç”¨çŸ¥è¯†æ··åˆåœ¨ä¸€èµ·ï¼Œä»¥ç¨³å®šè”é‚¦è®­ç»ƒè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸¤é¡¹é’ˆå¯¹å®¢æˆ·ç«¯å®šåˆ¶çš„è”é‚¦æ›´æ–°ç­–ç•¥ï¼Œè‡ªé€‚åº”åœ°å°†é€‚é…å™¨åˆ†è§£ä¸ºé€šç”¨å’Œä¸ªæ€§åŒ–ç»„ä»¶ï¼Œç„¶ååˆ†åˆ«å…¨å±€å’Œç‹¬ç«‹åœ°æ›´æ–°ä¸é€šç”¨å®¢æˆ·ç«¯ä¸å˜å’Œä¸ªæ€§åŒ–å®¢æˆ·ç«¯ç›¸å…³çš„å‚æ•°ç»„ã€‚å®ƒä»¬è¿›ä¸€æ­¥ç¨³å®šäº†å¼‚æ„çš„è”é‚¦å­¦ä¹ è¿‡ç¨‹ï¼Œå®ç°äº†é’ˆå¯¹å®¢æˆ·ç«¯çš„æœ€ä¼˜è€Œéæ¬¡ä¼˜å…¨å±€å¦¥ååˆ†å‰²æ¨¡å‹ã€‚åœ¨ä¸‰ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†æ‰€æå‡ºçš„FCAæ¡†æ¶åœ¨åŒ»å­¦å›¾åƒè”é‚¦åˆ†å‰²ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18020v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨Xå…‰å›¾åƒä¸­æœ‰åŠ©äºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­å’Œç—…ç¶å®šä½ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é‡‡ç”¨é›†ä¸­å¼å­¦ä¹ èŒƒå¼ï¼Œä¸é€‚ç”¨äºä»…è®¿é—®åˆ†å¸ƒå¼æ•°æ®å²›çš„å®é™…åŒ»å­¦åœºæ™¯ã€‚è”é‚¦å­¦ä¹ æœ‰æ½œåŠ›æä¾›åˆ†å¸ƒå¼è§£å†³æ–¹æ¡ˆï¼Œä½†ç”±äºå®¢æˆ·ç«¯é¢†åŸŸå¼‚è´¨æ€§ï¼ˆåŒ…æ‹¬åˆ†å¸ƒå¤šæ ·æ€§å’Œç±»åˆ«ä¸å¹³è¡¡ï¼‰è€Œé¢ä¸´è®­ç»ƒä¸ç¨³å®šçš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„æ–°å‹è”é‚¦å®¢æˆ·ç«¯å®šåˆ¶é€‚é…å™¨ï¼ˆFCAï¼‰æ¡†æ¶ï¼Œå¯åœ¨ä¸å…±äº«æ•æ„Ÿæœ¬åœ°æ•°æ®çš„æƒ…å†µä¸‹å®ç°ç¨³å®šä¸”å®¢æˆ·å®šåˆ¶çš„é€‚åº”æ€§åˆ†å‰²ã€‚å…·ä½“æ¥è¯´ï¼Œè”é‚¦é€‚é…å™¨æ…æ‹Œç°æˆçš„åŒ»å­¦åŸºç¡€æ¨¡å‹ä¸­çš„é€šç”¨çŸ¥è¯†ä»¥ç¨³å®šè”é‚¦è®­ç»ƒè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸¤ç§å®¢æˆ·å®šåˆ¶çš„è”é‚¦æ›´æ–°ç­–ç•¥ï¼Œè‡ªé€‚åº”åœ°å°†é€‚é…å™¨åˆ†è§£ä¸ºé€šç”¨å’Œä¸ªä½“ç»„ä»¶ï¼Œç„¶åå…¨å±€å’Œç‹¬ç«‹åœ°æ›´æ–°ä¸é€šç”¨å®¢æˆ·ç«¯ä¸å˜å’Œä¸ªä½“å®¢æˆ·ç«¯ç‰¹å®šå•å…ƒç›¸å…³çš„å‚æ•°ç»„ï¼Œè¿›ä¸€æ­¥ç¨³å®šäº†å¼‚æ„è”é‚¦å­¦ä¹ è¿‡ç¨‹ï¼Œå®ç°äº†ä¼˜åŒ–çš„å®¢æˆ·å®šåˆ¶è€Œéæ¬¡ä¼˜çš„å…¨å±€å¦¥ååˆ†å‰²æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨Xå…‰å›¾åƒä¸­æœ‰åŠ©äºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­å’Œç—…ç¶å®šä½ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦é‡‡ç”¨é›†ä¸­å¼å­¦ä¹ èŒƒå¼ï¼Œä¸é€‚ç”¨äºåˆ†å¸ƒå¼æ•°æ®ç¯å¢ƒã€‚</li>
<li>è”é‚¦å­¦ä¹ é¢ä¸´å› å®¢æˆ·ç«¯é¢†åŸŸå¼‚è´¨æ€§å¯¼è‡´çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚</li>
<li>æå‡ºäº†è”é‚¦å®¢æˆ·ç«¯å®šåˆ¶é€‚é…å™¨ï¼ˆFCAï¼‰æ¡†æ¶ï¼Œå®ç°ç¨³å®šä¸”å®¢æˆ·å®šåˆ¶çš„é€‚åº”æ€§åˆ†å‰²ã€‚</li>
<li>è”é‚¦é€‚é…å™¨åˆ©ç”¨é€šç”¨çŸ¥è¯†ç¨³å®šè”é‚¦è®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>å¼€å‘ä¸¤ç§å®¢æˆ·å®šåˆ¶çš„è”é‚¦æ›´æ–°ç­–ç•¥ï¼Œè‡ªé€‚åº”åˆ†è§£é€‚é…å™¨å¹¶æ›´æ–°å‚æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18020">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d5a3d55d6083e2699431a396402a623a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b656546ecfbfdc349aad0a0b08dbca62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-10216fcb7e8f08646bc4afa64b97784d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42615c12a1aaab45d51dcdb1aa8d2a82.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85607ab0518d0d30b0281c94f619257b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29b52789ea917a6c66cf7f04e9d7948f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DCFormer-Efficient-3D-Vision-Language-Modeling-with-Decomposed-Convolutions"><a href="#DCFormer-Efficient-3D-Vision-Language-Modeling-with-Decomposed-Convolutions" class="headerlink" title="DCFormer: Efficient 3D Vision-Language Modeling with Decomposed   Convolutions"></a>DCFormer: Efficient 3D Vision-Language Modeling with Decomposed   Convolutions</h2><p><strong>Authors:Gorkem Can Ates, Yu Xin, Kuang Gong, Wei Shao</strong></p>
<p>Vision-language models (VLMs) have been widely applied to 2D medical image analysis due to their ability to align visual and textual representations. However, extending VLMs to 3D imaging remains computationally challenging. Existing 3D VLMs often rely on Vision Transformers (ViTs), which are computationally expensive due to the quadratic complexity of self-attention, or on 3D convolutions, which require large numbers of parameters and FLOPs as kernel size increases. We introduce DCFormer, an efficient 3D image encoder that factorizes 3D convolutions into three parallel 1D convolutions along the depth, height, and width dimensions. This design preserves spatial information while significantly reducing computational cost. Integrated into a CLIP-based vision-language framework, DCFormer is trained and evaluated on CT-RATE, a dataset of 50,188 paired 3D chest CT volumes and radiology reports. In zero-shot and fine-tuned detection of 18 pathologies, as well as in image-text retrieval tasks, DCFormer consistently outperforms state-of-the-art 3D vision encoders, including CT-ViT, ViT, ConvNeXt, PoolFormer, and TransUNet. These results highlight DCFormerâ€™s potential for scalable, clinically deployable 3D medical VLMs. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/mirthAI/DCFormer">https://github.com/mirthAI/DCFormer</a>. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ç”±äºå…¶è§†è§‰å’Œæ–‡æœ¬è¡¨ç¤ºå¯¹é½çš„èƒ½åŠ›ï¼Œå·²å¹¿æ³›åº”ç”¨äºäºŒç»´åŒ»å­¦å›¾åƒåˆ†æã€‚ç„¶è€Œï¼Œå°†VLMsæ‰©å±•åˆ°ä¸‰ç»´æˆåƒåœ¨è®¡ç®—ä¸Šä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰çš„ä¸‰ç»´VLMsé€šå¸¸ä¾èµ–äºè§†è§‰è½¬æ¢å™¨ï¼ˆViTsï¼‰ï¼Œç”±äºè‡ªæ³¨æ„åŠ›çš„äºŒæ¬¡å¤æ‚æ€§ï¼Œå…¶è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæˆ–è€…ä¾èµ–äºä¸‰ç»´å·ç§¯ï¼Œéšç€å†…æ ¸å¤§å°çš„å¢åŠ ï¼Œéœ€è¦å¤§é‡çš„å‚æ•°å’Œæµ®ç‚¹è¿ç®—ï¼ˆFLOPsï¼‰ã€‚æˆ‘ä»¬å¼•å…¥äº†DCFormerï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„ä¸‰ç»´å›¾åƒç¼–ç å™¨ï¼Œå®ƒå°†ä¸‰ç»´å·ç§¯åˆ†è§£ä¸ºæ²¿æ·±åº¦ã€é«˜åº¦å’Œå®½åº¦æ–¹å‘çš„ä¸‰ä¸ªå¹¶è¡Œä¸€ç»´å·ç§¯ã€‚è¿™ç§è®¾è®¡ä¿ç•™äº†ç©ºé—´ä¿¡æ¯ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ã€‚DCFormerè¢«é›†æˆåˆ°ä¸€ä¸ªåŸºäºCLIPçš„è§†è§‰è¯­è¨€æ¡†æ¶ä¸­ï¼Œå¹¶åœ¨CT-RATEæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ï¼Œè¯¥æ•°æ®é›†åŒ…å«50,188å¯¹ä¸‰ç»´èƒ¸éƒ¨CTä½“ç§¯å’Œæ”¾å°„å­¦æŠ¥å‘Šã€‚åœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒæ£€æµ‹18ç§ç—…ç†æƒ…å†µä»¥åŠå›¾åƒæ–‡æœ¬æ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒDCFormeræŒç»­ä¼˜äºæœ€æ–°çš„ä¸‰ç»´è§†è§‰ç¼–ç å™¨ï¼ŒåŒ…æ‹¬CT-ViTã€ViTã€ConvNeXtã€PoolFormerå’ŒTransUNetã€‚è¿™äº›ç»“æœçªå‡ºäº†DCFormeråœ¨å¯æ‰©å±•ã€å¯éƒ¨ç½²çš„ä¸´åºŠä¸‰ç»´åŒ»å­¦VLMsä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç ä½äºï¼š<a target="_blank" rel="noopener" href="https://github.com/mirthAI/DCFormer%E3%80%82">https://github.com/mirthAI/DCFormerã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05091v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å¯¹äºŒç»´åŒ»å­¦å½±åƒåˆ†æçš„å¹¿æ³›åº”ç”¨åŠå…¶å¼ºå¤§çš„è§†è§‰ä¸æ–‡æœ¬å¯¹é½èƒ½åŠ›ï¼Œäººä»¬æ­£è¯•å›¾å°†å…¶æ‰©å±•åˆ°ä¸‰ç»´æˆåƒé¢†åŸŸã€‚ç„¶è€Œï¼Œç”±äºè®¡ç®—ä¸Šçš„æŒ‘æˆ˜ï¼Œç°æœ‰ä¸‰ç»´VLMsé€šå¸¸é‡‡ç”¨è§†è§‰è½¬æ¢å™¨ï¼ˆViTsï¼‰ï¼Œå…¶è‡ªæ³¨æ„åŠ›çš„äºŒæ¬¡å¤æ‚æ€§å¯¼è‡´è®¡ç®—é‡å¤§ï¼›æˆ–æ˜¯é‡‡ç”¨ä¸‰ç»´å·ç§¯ï¼Œéšç€å†…æ ¸å¤§å°å¢åŠ ï¼Œå…¶æ‰€éœ€çš„å‚æ•°å’Œæµ®ç‚¹è¿ç®—é‡ä¹Ÿæ€¥å‰§å¢é•¿ã€‚æœ¬æ–‡æå‡ºDCFormerï¼Œä¸€ç§é«˜æ•ˆçš„ä¸‰ç»´å›¾åƒç¼–ç å™¨ï¼Œå°†ä¸‰ç»´å·ç§¯åˆ†è§£ä¸ºæ²¿æ·±åº¦ã€é«˜åº¦å’Œå®½åº¦æ–¹å‘çš„ä¸‰ä¸ªå¹¶è¡Œä¸€ç»´å·ç§¯ã€‚è¿™ç§è®¾è®¡åœ¨ä¿ç•™ç©ºé—´ä¿¡æ¯çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚DCFormerè¢«é›†æˆåˆ°ä¸€ä¸ªåŸºäºCLIPçš„è§†é‡è¯­è¨€æ¡†æ¶ä¸­ï¼Œå¹¶åœ¨CT-RATEæ•°æ®é›†ï¼ˆåŒ…å«50,188å¯¹ä¸‰ç»´èƒ¸éƒ¨CTä½“ç§¯å’Œæ”¾å°„å­¦æŠ¥å‘Šï¼‰ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚åœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒæ£€æµ‹18ç§ç—…ç†æƒ…å†µä»¥åŠå›¾åƒæ–‡æœ¬æ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒDCFormerå§‹ç»ˆä¼˜äºæœ€æ–°çš„ä¸‰ç»´è§†è§‰ç¼–ç å™¨ï¼ŒåŒ…æ‹¬CT-ViTã€ViTã€ConvNeXtã€PoolFormerå’ŒTransUNetã€‚è¿™äº›ç»“æœçªæ˜¾äº†DCFormeråœ¨å¯æ‰©å±•çš„ä¸´åºŠéƒ¨ç½²ä¸‰ç»´åŒ»å­¦VLMsæ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>VLMså·²å¹¿æ³›åº”ç”¨äºäºŒç»´åŒ»å­¦å½±åƒåˆ†æï¼Œä½†æ‰©å±•åˆ°ä¸‰ç»´æˆåƒä»å­˜åœ¨è®¡ç®—æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰ä¸‰ç»´VLMså¤šé‡‡ç”¨ViTsæˆ–ä¸‰ç»´å·ç§¯ï¼Œå‰è€…è‡ªæ³¨æ„åŠ›æœºåˆ¶è®¡ç®—é‡å¤§ï¼Œåè€…å‚æ•°å’Œè®¡ç®—é‡å¤§ã€‚</li>
<li>DCFormeræ˜¯ä¸€ç§é«˜æ•ˆçš„ä¸‰ç»´å›¾åƒç¼–ç å™¨ï¼Œé€šè¿‡åˆ†è§£ä¸‰ç»´å·ç§¯ä»¥é™ä½è®¡ç®—æˆæœ¬å¹¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚</li>
<li>DCFormeråœ¨CLIPåŸºç¡€ä¸Šè¢«é›†æˆåˆ°è§†é‡è¯­è¨€æ¡†æ¶ä¸­ï¼Œå¹¶åœ¨å¤§è§„æ¨¡CT-RATEæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
<li>åœ¨é›¶æ ·æœ¬å­¦ä¹ å’Œå¾®è°ƒæ£€æµ‹ç—…ç†æƒ…å†µï¼Œä»¥åŠå›¾åƒæ–‡æœ¬æ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒDCFormerè¡¨ç°ä¼˜äºå…¶ä»–å…ˆè¿›çš„ä¸‰ç»´è§†è§‰ç¼–ç å™¨ã€‚</li>
<li>DCFormerå…·æœ‰æ½œåŠ›æˆä¸ºå¯æ‰©å±•çš„ã€å¯ä¸´åºŠéƒ¨ç½²çš„ä¸‰ç»´åŒ»å­¦VLMsè§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05091">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0173403a8b9f8356896654b82ef9bc45.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a46abe86d41b8d0e78204771e3cd65d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e498c7700b4337837aae0345363f49a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b297226edd815280e93e0610b483807.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96bfd104c3d3841e529821b9c83f15a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b54cd4e09288a221ff50c3f742dbb572.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86a13eb956e6aa9358b755623906e2ee.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Towards-Synchronous-Memorizability-and-Generalizability-with-Site-Modulated-Diffusion-Replay-for-Cross-Site-Continual-Segmentation"><a href="#Towards-Synchronous-Memorizability-and-Generalizability-with-Site-Modulated-Diffusion-Replay-for-Cross-Site-Continual-Segmentation" class="headerlink" title="Towards Synchronous Memorizability and Generalizability with   Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation"></a>Towards Synchronous Memorizability and Generalizability with   Site-Modulated Diffusion Replay for Cross-Site Continual Segmentation</h2><p><strong>Authors:Dunyuan Xu, Xi Wang, Jingyang Zhang, Pheng-Ann Heng</strong></p>
<p>The ability to learn sequentially from different data sites is crucial for a deep network in solving practical medical image diagnosis problems due to privacy restrictions and storage limitations. However, adapting on incoming site leads to catastrophic forgetting on past sites and decreases generalizablity on unseen sites. Existing Continual Learning (CL) and Domain Generalization (DG) methods have been proposed to solve these two challenges respectively, but none of them can address both simultaneously. Recognizing this limitation, this paper proposes a novel training paradigm, learning towards Synchronous Memorizability and Generalizability (SMG-Learning). To achieve this, we create the orientational gradient alignment to ensure memorizability on previous sites, and arbitrary gradient alignment to enhance generalizability on unseen sites. This approach is named as Parallel Gradient Alignment (PGA). Furthermore, we approximate the PGA as dual meta-objectives using the first-order Taylor expansion to reduce computational cost of aligning gradients. Considering that performing gradient alignments, especially for previous sites, is not feasible due to the privacy constraints, we design a Site-Modulated Diffusion (SMD) model to generate images with site-specific learnable prompts, replaying images have similar data distributions as previous sites. We evaluate our method on two medical image segmentation tasks, where data from different sites arrive sequentially. Experimental results show that our method efficiently enhances both memorizability and generalizablity better than other state-of-the-art methods, delivering satisfactory performance across all sites. Our code will be available at: <a target="_blank" rel="noopener" href="https://github.com/dyxu-cuhkcse/SMG-Learning">https://github.com/dyxu-cuhkcse/SMG-Learning</a>. </p>
<blockquote>
<p>èƒ½å¤Ÿä»ä¸åŒçš„æ•°æ®ç«™ç‚¹è¿›è¡Œé¡ºåºå­¦ä¹ å¯¹äºæ·±åº¦ç½‘ç»œè§£å†³å®é™…çš„åŒ»å­¦å›¾åƒè¯Šæ–­é—®é¢˜è‡³å…³é‡è¦ï¼Œå› ä¸ºå­˜åœ¨éšç§é™åˆ¶å’Œå­˜å‚¨é™åˆ¶ã€‚ç„¶è€Œï¼Œé€‚åº”æ–°ç«™ç‚¹ä¼šå¯¼è‡´å¯¹è¿‡å»ç«™ç‚¹çš„ç¾éš¾æ€§é—å¿˜ï¼Œå¹¶é™ä½å¯¹æœªè§ç«™ç‚¹çš„æ³›åŒ–èƒ½åŠ›ã€‚ç°æœ‰çš„æŒç»­å­¦ä¹ ï¼ˆCLï¼‰å’ŒåŸŸæ³›åŒ–ï¼ˆDGï¼‰æ–¹æ³•åˆ†åˆ«è¢«æå‡ºæ¥è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œä½†æ²¡æœ‰ä»»ä½•ä¸€ç§æ–¹æ³•å¯ä»¥åŒæ—¶è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚æœ¬æ–‡è®¤è¯†åˆ°äº†è¿™ä¸€å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œå³å­¦ä¹ é¢å‘åŒæ­¥è®°å¿†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼ˆSMG-Learningï¼‰ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬åˆ›å»ºæ–¹å‘æ¢¯åº¦å¯¹é½ä»¥ç¡®ä¿å¯¹è¿‡å»ç«™ç‚¹çš„è®°å¿†èƒ½åŠ›ï¼Œå¹¶åˆ›å»ºä»»æ„æ¢¯åº¦å¯¹é½ä»¥å¢å¼ºå¯¹æœªè§ç«™ç‚¹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºå¹¶è¡Œæ¢¯åº¦å¯¹é½ï¼ˆPGAï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†PGAè¿‘ä¼¼ä¸ºåŒå…ƒç›®æ ‡ä½¿ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€ï¼Œä»¥å‡å°‘æ¢¯åº¦å¯¹é½çš„è®¡ç®—æˆæœ¬ã€‚è€ƒè™‘åˆ°è¿›è¡Œæ¢¯åº¦å¯¹é½ï¼Œå°¤å…¶æ˜¯å¯¹ä»¥å‰çš„ç«™ç‚¹ï¼Œç”±äºéšç§çº¦æŸè€Œä¸å¯è¡Œï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç«™ç‚¹è°ƒåˆ¶æ‰©æ•£ï¼ˆSMDï¼‰æ¨¡å‹ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç«™ç‚¹ç‰¹å®šå¯å­¦ä¹ æç¤ºçš„å›¾åƒï¼Œå›æ”¾å›¾åƒçš„ æ•°æ®åˆ†å¸ƒä¸ä»¥å‰çš„ç«™ç‚¹ç›¸ä¼¼ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¥è‡ªä¸åŒç«™ç‚¹çš„æ•°æ®ä¼šé¡ºåºåˆ°è¾¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å¢å¼ºäº†è®°å¿†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæ¯”å…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•è¡¨ç°æ›´å¥½ï¼Œå¹¶åœ¨æ‰€æœ‰ç«™ç‚¹ä¸Šè¡¨ç°å‡ºä»¤äººæ»¡æ„çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/dyxu-cuhkcse/SMG-Learning">https://github.com/dyxu-cuhkcse/SMG-Learning</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.18037v3">PDF</a> This paper is not proper to be published on arXiv, since we think   some method are quite similar with one other paper</p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿™ç¯‡è®ºæ–‡é’ˆå¯¹å› éšç§é™åˆ¶å’Œå­˜å‚¨é™åˆ¶å¯¼è‡´çš„åŒ»å­¦å›¾åƒè¯Šæ–­é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼â€”â€”åŒæ­¥è®°å¿†æ€§å’Œæ³›åŒ–æ€§å­¦ä¹ ï¼ˆSMG-Learningï¼‰ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåˆ›å»ºäº†æ–¹å‘æ¢¯åº¦å¯¹é½ä»¥ç¡®ä¿å¯¹ä¹‹å‰ç«™ç‚¹çš„è®°å¿†èƒ½åŠ›ï¼Œä»»æ„æ¢¯åº¦å¯¹é½ä»¥å¢å¼ºå¯¹æœªè§ç«™ç‚¹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºå¹¶è¡Œæ¢¯åº¦å¯¹é½ï¼ˆPGAï¼‰ã€‚æ­¤å¤–ï¼Œé€šè¿‡å°†PGAè¿‘ä¼¼ä¸ºåŒé‡å…ƒç›®æ ‡ä½¿ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€ï¼Œå‡å°‘äº†æ¢¯åº¦å¯¹é½çš„è®¡ç®—æˆæœ¬ã€‚è€ƒè™‘åˆ°æ¢¯åº¦å¯¹é½ç‰¹åˆ«æ˜¯é’ˆå¯¹ä¹‹å‰ç«™ç‚¹ä¸å¯è¡Œæ˜¯ç”±äºéšç§çº¦æŸï¼Œè®¾è®¡äº†ä¸€ç§åä¸ºSite-Modulated Diffusionï¼ˆSMDï¼‰çš„æ¨¡å‹æ¥ç”Ÿæˆå…·æœ‰ç‰¹å®šå­¦ä¹ æç¤ºçš„å›¾åƒå›æ”¾ï¼Œè¿™äº›å›¾åƒå…·æœ‰ä¸ä¹‹å‰ç«™ç‚¹ç›¸ä¼¼çš„æ•°æ®åˆ†å¸ƒã€‚åœ¨ä¸¤é¡¹åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œä¸åŒç«™ç‚¹çš„æ•°æ®æŒ‰é¡ºåºåˆ°è¾¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è®°å¿†æ€§å’Œæ³›åŒ–æ€§æ–¹é¢å‡ä¼˜äºå…¶ä»–æœ€æ–°æ–¹æ³•ï¼Œåœ¨æ‰€æœ‰ç«™ç‚¹ä¸Šå‡è¡¨ç°å‡ºä»¤äººæ»¡æ„çš„æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è®ºæ–‡å¼ºè°ƒäº†ä»å¤šä¸ªæ•°æ®ç«™ç‚¹é¡ºåºå­¦ä¹ å¯¹äºè§£å†³å› éšç§å’Œå­˜å‚¨é™åˆ¶å¯¼è‡´çš„åŒ»å­¦å›¾åƒè¯Šæ–­é—®é¢˜çš„æ·±åº¦ç½‘ç»œçš„é‡è¦æ€§ã€‚</li>
<li>å­˜åœ¨æŒç»­å­¦ä¹ ï¼ˆCLï¼‰å’ŒåŸŸæ³›åŒ–ï¼ˆDGï¼‰æ–¹æ³•åˆ†åˆ«åº”å¯¹é¡ºåºå­¦ä¹ å’Œæ³›åŒ–æŒ‘æˆ˜ï¼Œä½†æ²¡æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åŒæ—¶è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼â€”â€”åŒæ­¥è®°å¿†æ€§å’Œæ³›åŒ–æ€§å­¦ä¹ ï¼ˆSMG-Learningï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>é€šè¿‡åˆ›å»ºæ–¹å‘æ¢¯åº¦å¯¹é½å’Œä»»æ„æ¢¯åº¦å¯¹é½æ¥æå‡è®°å¿†æ€§å’Œæ³›åŒ–æ€§ï¼Œæå‡ºäº†å¹¶è¡Œæ¢¯åº¦å¯¹é½ï¼ˆPGAï¼‰æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€å°†PGAè¿‘ä¼¼ä¸ºåŒé‡å…ƒç›®æ ‡ä»¥é™ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>è€ƒè™‘éšç§çº¦æŸï¼Œè®¾è®¡äº†ä¸€ç§åä¸ºSite-Modulated Diffusionï¼ˆSMDï¼‰çš„æ¨¡å‹æ¥ç”Ÿæˆå…·æœ‰ç‰¹å®šå­¦ä¹ æç¤ºçš„å›¾åƒå›æ”¾ã€‚</li>
<li>åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è®°å¿†æ€§å’Œæ³›åŒ–æ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.18037">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9eb07fa660a2a1c0a519395ce796a17b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d89db0cf234eb6597cf1b4dd7c956fdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64c7a8e2544aef3ba38e54f42dd6002b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-06a94f68e8019bc8288835cd50632db8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-29/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a156ef5944afd968a789ed1ad5fc32cd.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  Generative Induction of Dialogue Task Schemas with Streaming Refinement   and Simulated Interactions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-29/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-48564c5809f4b7117d483ec581a40f88.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  Optimizing Multi-Round Enhanced Training in Diffusion Models for   Improved Preference Understanding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">20064.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
