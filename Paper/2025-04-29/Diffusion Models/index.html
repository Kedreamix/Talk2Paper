<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  Optimizing Multi-Round Enhanced Training in Diffusion Models for   Improved Preference Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-48564c5809f4b7117d483ec581a40f88.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-01
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-29-æ›´æ–°"><a href="#2025-04-29-æ›´æ–°" class="headerlink" title="2025-04-29 æ›´æ–°"></a>2025-04-29 æ›´æ–°</h1><h2 id="Optimizing-Multi-Round-Enhanced-Training-in-Diffusion-Models-for-Improved-Preference-Understanding"><a href="#Optimizing-Multi-Round-Enhanced-Training-in-Diffusion-Models-for-Improved-Preference-Understanding" class="headerlink" title="Optimizing Multi-Round Enhanced Training in Diffusion Models for   Improved Preference Understanding"></a>Optimizing Multi-Round Enhanced Training in Diffusion Models for   Improved Preference Understanding</h2><p><strong>Authors:Kun Li, Jianhui Wang, Yangfan He, Xinyuan Song, Ruoyu Wang, Hongyang He, Wenxin Zhang, Jiaqi Chen, Keqin Li, Sida Li, Miao Zhang, Tianyu Shi, Xueqian Wang</strong></p>
<p>Generative AI has significantly changed industries by enabling text-driven image generation, yet challenges remain in achieving high-resolution outputs that align with fine-grained user preferences. Consequently, multi-round interactions are necessary to ensure the generated images meet expectations. Previous methods enhanced prompts via reward feedback but did not optimize over a multi-round dialogue dataset. In this work, we present a Visual Co-Adaptation (VCA) framework incorporating human-in-the-loop feedback, leveraging a well-trained reward model aligned with human preferences. Using a diverse multi-turn dialogue dataset, our framework applies multiple reward functions, such as diversity, consistency, and preference feedback, while fine-tuning the diffusion model through LoRA, thus optimizing image generation based on user input. We also construct multi-round dialogue datasets of prompts and image pairs aligned with user intent. Experiments demonstrate that our method outperforms state-of-the-art baselines, significantly improving image consistency and alignment with user intent. Our approach consistently surpasses competing models in user satisfaction, especially in multi-turn dialogue scenarios. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å·²ç»é€šè¿‡æ–‡æœ¬é©±åŠ¨çš„å›¾ç‰‡ç”Ÿæˆæ˜¾è‘—æ”¹å˜äº†å„è¡Œå„ä¸šï¼Œç„¶è€Œï¼Œåœ¨å®ç°ä¸ç”¨æˆ·ç²¾ç»†åå¥½å¯¹é½çš„é«˜åˆ†è¾¨ç‡è¾“å‡ºæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œå¤šè½®äº¤äº’æ˜¯å¿…è¦çš„ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å›¾åƒæ»¡è¶³æœŸæœ›ã€‚ä¹‹å‰çš„æ–¹æ³•é€šè¿‡å¥–åŠ±åé¦ˆæ¥å¢å¼ºæç¤ºï¼Œä½†å¹¶æ²¡æœ‰åœ¨å¤šä¸ªè½®æ¬¡å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œä¼˜åŒ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè§†è§‰ååŒé€‚åº”ï¼ˆVCAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†äººç±»åé¦ˆå›è·¯ï¼Œåˆ©ç”¨è®­ç»ƒè‰¯å¥½çš„å¥–åŠ±æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½ã€‚ä½¿ç”¨å¤šæ ·åŒ–çš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åº”ç”¨å¤šä¸ªå¥–åŠ±å‡½æ•°ï¼Œå¦‚å¤šæ ·æ€§ã€ä¸€è‡´æ€§å’Œåå¥½åé¦ˆç­‰ï¼ŒåŒæ—¶é€šè¿‡LoRAå¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œä»è€ŒåŸºäºç”¨æˆ·è¾“å…¥ä¼˜åŒ–å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸ç”¨æˆ·æ„å›¾å¯¹é½çš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼ŒåŒ…å«æç¤ºå’Œå›¾åƒå¯¹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†å›¾åƒçš„ä¸€è‡´æ€§å’Œä¸ç”¨æˆ·æ„å›¾çš„å¯¹é½ç¨‹åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”¨æˆ·æ»¡æ„åº¦æ–¹é¢å§‹ç»ˆè¶…è¿‡ç«äº‰æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šè½®å¯¹è¯åœºæ™¯ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18204v1">PDF</a> arXiv admin note: substantial text overlap with arXiv:2503.17660</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ç”Ÿæˆå¼AIå¦‚ä½•é€šè¿‡æ–‡æœ¬é©±åŠ¨å›¾åƒç”Ÿæˆæ¥æ”¹å˜è¡Œä¸šï¼Œä½†ä»ç„¶å­˜åœ¨å®ç°é«˜åˆ†è¾¨ç‡è¾“å‡ºå’Œæ»¡è¶³ç²¾ç»†ç”¨æˆ·åå¥½æ–¹é¢çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œéœ€è¦å¤šè½®äº¤äº’æ¥ç¡®ä¿ç”Ÿæˆçš„å›¾åƒç¬¦åˆé¢„æœŸã€‚ä¹‹å‰çš„æ–¹æ³•é€šè¿‡å¥–åŠ±åé¦ˆå¢å¼ºäº†æç¤ºï¼Œä½†å¹¶æ²¡æœ‰åœ¨ä¸€ä¸ªå¤šè½®å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œä¼˜åŒ–ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè§†è§‰ååŒé€‚åº”ï¼ˆVCAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†äººç±»åé¦ˆå¾ªç¯ï¼Œåˆ©ç”¨è®­ç»ƒè‰¯å¥½çš„å¥–åŠ±æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½ã€‚ä½¿ç”¨å¤šæ ·åŒ–çš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åº”ç”¨äº†å¤šä¸ªå¥–åŠ±å‡½æ•°ï¼Œå¦‚å¤šæ ·æ€§ã€ä¸€è‡´æ€§å’Œåå¥½åé¦ˆï¼ŒåŒæ—¶é€šè¿‡LoRAå¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œä»è€ŒåŸºäºç”¨æˆ·è¾“å…¥ä¼˜åŒ–å›¾åƒç”Ÿæˆã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒä¸€è‡´æ€§ã€ç”¨æˆ·æ„å›¾å¯¹é½æ–¹é¢ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯åœ¨å¤šè½®å¯¹è¯åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”¨æˆ·æ»¡æ„åº¦æ–¹é¢å§‹ç»ˆè¶…è¶Šç«äº‰å¯¹æ‰‹æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼AIé€šè¿‡æ–‡æœ¬é©±åŠ¨å›¾åƒç”Ÿæˆæ”¹å˜äº†è¡Œä¸šï¼Œä½†ä»é¢ä¸´å®ç°é«˜åˆ†è¾¨ç‡è¾“å‡ºå’Œæ»¡è¶³ç²¾ç»†ç”¨æˆ·åå¥½çš„æŒ‘æˆ˜ã€‚</li>
<li>å¤šè½®äº¤äº’æ˜¯å¿…è¦çš„ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å›¾åƒç¬¦åˆç”¨æˆ·æœŸæœ›å’Œéœ€æ±‚ã€‚</li>
<li>ä¹‹å‰çš„æ–¹æ³•ä¸»è¦ä¾§é‡äºé€šè¿‡å¥–åŠ±åé¦ˆå¢å¼ºæç¤ºï¼Œä½†æ²¡æœ‰åœ¨å¤šè½®å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>æå‡ºçš„è§†è§‰ååŒé€‚åº”ï¼ˆVCAï¼‰æ¡†æ¶ç»“åˆäº†äººç±»åé¦ˆå¾ªç¯ï¼Œåˆ©ç”¨è®­ç»ƒè‰¯å¥½çš„å¥–åŠ±æ¨¡å‹ä¸äººç±»åå¥½å¯¹é½ã€‚</li>
<li>è¯¥æ¡†æ¶ä½¿ç”¨å¤šä¸ªå¥–åŠ±å‡½æ•°ï¼ˆå¦‚å¤šæ ·æ€§ã€ä¸€è‡´æ€§å’Œåå¥½åé¦ˆï¼‰ï¼Œå¹¶é€šè¿‡LoRAå¾®è°ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒä¸€è‡´æ€§ã€ç”¨æˆ·æ„å›¾å¯¹é½æ–¹é¢ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18204">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-14dc3b23b29b905ebce9f68056a6155d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18f883335208dd67635b17478941be23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f902e8f9d365ea97005d5e50ee543456.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4081a9344132c11648479f5f52492f6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-54b3213f4f3d571f3d79be8021e61541.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66eaaa6d51421f4656a0d7b625757cb9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30ea5d398c0c9730489667b1a39ebe77.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-Privacy-Utility-Trade-offs-to-Mitigate-Memorization-in-Diffusion-Models"><a href="#Enhancing-Privacy-Utility-Trade-offs-to-Mitigate-Memorization-in-Diffusion-Models" class="headerlink" title="Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in   Diffusion Models"></a>Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in   Diffusion Models</h2><p><strong>Authors:Chen Chen, Daochang Liu, Mubarak Shah, Chang Xu</strong></p>
<p>Text-to-image diffusion models have demonstrated remarkable capabilities in creating images highly aligned with user prompts, yet their proclivity for memorizing training set images has sparked concerns about the originality of the generated images and privacy issues, potentially leading to legal complications for both model owners and users, particularly when the memorized images contain proprietary content. Although methods to mitigate these issues have been suggested, enhancing privacy often results in a significant decrease in the utility of the outputs, as indicated by text-alignment scores. To bridge the research gap, we introduce a novel method, PRSS, which refines the classifier-free guidance approach in diffusion models by integrating prompt re-anchoring (PR) to improve privacy and incorporating semantic prompt search (SS) to enhance utility. Extensive experiments across various privacy levels demonstrate that our approach consistently improves the privacy-utility trade-off, establishing a new state-of-the-art. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨åˆ›å»ºä¸ç”¨æˆ·æç¤ºé«˜åº¦åŒ¹é…çš„å›¾ç‰‡æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬å€¾å‘äºè®°å¿†è®­ç»ƒé›†å›¾ç‰‡ï¼Œå¼•å‘äº†äººä»¬å¯¹ç”Ÿæˆå›¾ç‰‡åŸåˆ›æ€§å’Œéšç§é—®é¢˜çš„æ‹…å¿§ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¨¡å‹æ‰€æœ‰è€…ä¸ç”¨æˆ·åŒæ–¹é¢ä¸´æ³•å¾‹å’Œéšç§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å½“è®°å¿†çš„å›¾ç‰‡åŒ…å«ä¸“æœ‰å†…å®¹æ—¶ã€‚è™½ç„¶å·²æœ‰æ–¹æ³•å»ºè®®ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†å¢å¼ºéšç§å¾€å¾€ä¼šå¯¼è‡´è¾“å‡ºç»“æœçš„å®ç”¨æ€§æ˜¾è‘—é™ä½ï¼Œå¦‚æ–‡æœ¬å¯¹é½åˆ†æ•°æ‰€ç¤ºã€‚ä¸ºäº†å¼¥è¡¥ç ”ç©¶ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•PRSSï¼Œå®ƒé€šè¿‡æ•´åˆæç¤ºé‡æ–°é”šå®šï¼ˆPRï¼‰æ¥æé«˜éšç§ï¼Œå¹¶èå…¥è¯­ä¹‰æç¤ºæœç´¢ï¼ˆSSï¼‰ä»¥å¢å¼ºå®ç”¨æ€§ï¼Œå¯¹æ‰©æ•£æ¨¡å‹ä¸­çš„æ— åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚åœ¨ä¸åŒéšç§çº§åˆ«çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒç»­æ”¹å–„äº†éšç§ä¸å®ç”¨æ€§çš„æƒè¡¡ï¼Œåˆ›ä¸‹äº†æ–°çš„æœ€å…ˆè¿›çš„è®°å½•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18032v1">PDF</a> Accepted at CVPR 2025. Project page:   <a target="_blank" rel="noopener" href="https://chenchen-usyd.github.io/PRSS-Project-Page/">https://chenchen-usyd.github.io/PRSS-Project-Page/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨åˆ›å»ºä¸ç”¨æˆ·æç¤ºé«˜åº¦åŒ¹é…çš„å›¾ç‰‡æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶å€¾å‘äºè®°å¿†è®­ç»ƒé›†å›¾ç‰‡çš„é—®é¢˜å¼•å‘äº†äººä»¬å¯¹ç”Ÿæˆå›¾ç‰‡åŸåˆ›æ€§å’Œéšç§çš„æ‹…å¿§ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹æ‰€æœ‰è€…ä¸ç”¨æˆ·é¢ä¸´æ³•å¾‹å’Œéšç§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å½“è®°å¿†ä¸­çš„å›¾ç‰‡åŒ…å«ä¸“æœ‰å†…å®¹æ—¶ã€‚è™½ç„¶å·²æœ‰æ–¹æ³•å»ºè®®ç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†å¢å¼ºéšç§å¾€å¾€ä¼šå¯¼è‡´è¾“å‡ºæ•ˆç”¨æ˜¾è‘—é™ä½ï¼Œå¦‚æ–‡æœ¬å¯¹é½åˆ†æ•°æ‰€ç¤ºã€‚ä¸ºäº†å¼¥è¡¥ç ”ç©¶ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•PRSSï¼Œå®ƒé€šè¿‡æ”¹è¿›æ‰©æ•£æ¨¡å‹ä¸­çš„æ— åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡é›†æˆæç¤ºé‡æ–°é”šå®šï¼ˆPRï¼‰æé«˜éšç§æ€§ï¼Œå¹¶ç»“åˆè¯­ä¹‰æç¤ºæœç´¢ï¼ˆSSï¼‰æé«˜å®ç”¨æ€§ã€‚è·¨è¶Šå„ç§éšç§çº§åˆ«çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒç»­æ”¹å–„äº†éšç§ä¸å®ç”¨æ€§çš„æƒè¡¡ï¼Œå»ºç«‹äº†æ–°çš„æŠ€æœ¯å‰æ²¿ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹å…·å¤‡å‡ºè‰²çš„åˆ›å»ºä¸ç”¨æˆ·æç¤ºåŒ¹é…å›¾åƒçš„èƒ½åŠ›ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å­˜åœ¨è®°å¿†è®­ç»ƒé›†å›¾ç‰‡çš„é—®é¢˜ï¼Œå¼•å‘å…³äºåŸåˆ›æ€§å’Œéšç§çš„æ‹…å¿§ã€‚</li>
<li>å¢å¼ºéšç§å¯èƒ½ä¼šå¯¼è‡´è¾“å‡ºæ•ˆç”¨æ˜¾è‘—é™ä½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•PRSSï¼Œé€šè¿‡é›†æˆæç¤ºé‡æ–°é”šå®šå’Œè¯­ä¹‰æç¤ºæœç´¢ï¼Œæ”¹è¿›æ‰©æ•£æ¨¡å‹çš„éšç§æ€§å’Œå®ç”¨æ€§ã€‚</li>
<li>PRSSæ–¹æ³•æé«˜äº†éšç§ä¸å®ç”¨æ€§çš„æƒè¡¡ã€‚</li>
<li>PRSSæ–¹æ³•å»ºç«‹äº†æ–°çš„æŠ€æœ¯å‰æ²¿ã€‚</li>
<li>é€šè¿‡å¹¿æ³›å®éªŒéªŒè¯äº†PRSSæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18032">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-927da7066ccecda6d2679380d1a4887d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-36b1f59075f2f45345219e7f8831a9fa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa292bc17745392834ca8a6080f42b33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbe5ebecc5f77558200d869b8b70de6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a825d7f998831ccade728aea7b959981.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Diffusion-Driven-Universal-Model-Inversion-Attack-for-Face-Recognition"><a href="#Diffusion-Driven-Universal-Model-Inversion-Attack-for-Face-Recognition" class="headerlink" title="Diffusion-Driven Universal Model Inversion Attack for Face Recognition"></a>Diffusion-Driven Universal Model Inversion Attack for Face Recognition</h2><p><strong>Authors:Hanrui Wang, Shuo Wang, Chun-Shien Lu, Isao Echizen</strong></p>
<p>Facial recognition technology poses significant privacy risks, as it relies on biometric data that is inherently sensitive and immutable if compromised. To mitigate these concerns, face recognition systems convert raw images into embeddings, traditionally considered privacy-preserving. However, model inversion attacks pose a significant privacy threat by reconstructing these private facial images, making them a crucial tool for evaluating the privacy risks of face recognition systems. Existing methods usually require training individual generators for each target model, a computationally expensive process. In this paper, we propose DiffUMI, a training-free diffusion-driven universal model inversion attack for face recognition systems. DiffUMI is the first approach to apply a diffusion model for unconditional image generation in model inversion. Unlike other methods, DiffUMI is universal, eliminating the need for training target-specific generators. It operates within a fixed framework and pretrained diffusion model while seamlessly adapting to diverse target identities and models. DiffUMI breaches privacy-preserving face recognition systems with state-of-the-art success, demonstrating that an unconditional diffusion model, coupled with optimized adversarial search, enables efficient and high-fidelity facial reconstruction. Additionally, we introduce a novel application of out-of-domain detection (OODD), marking the first use of model inversion to distinguish non-face inputs from face inputs based solely on embeddings. </p>
<blockquote>
<p>äººè„¸è¯†åˆ«æŠ€æœ¯å­˜åœ¨é‡å¤§çš„éšç§é£é™©ï¼Œå› ä¸ºå®ƒä¾èµ–äºç”Ÿç‰©ç‰¹å¾æ•°æ®ï¼Œè¿™äº›æ•°æ®æœ¬è´¨ä¸Šæ˜¯æ•æ„Ÿçš„ï¼Œä¸€æ—¦æ³„éœ²ï¼Œå…·æœ‰ä¸å¯å˜æ€§ã€‚ä¸ºäº†ç¼“è§£è¿™äº›æ‹…å¿§ï¼Œäººè„¸è¯†åˆ«ç³»ç»Ÿå°†åŸå§‹å›¾åƒè½¬åŒ–ä¸ºåµŒå…¥å½¢å¼ï¼Œè¿™è¢«è®¤ä¸ºæ˜¯éšç§ä¿æŠ¤çš„ã€‚ç„¶è€Œï¼Œæ¨¡å‹åè½¬æ”»å‡»é€šè¿‡é‡å»ºè¿™äº›ç§æœ‰é¢éƒ¨å›¾åƒæ„æˆé‡å¤§éšç§å¨èƒï¼Œæˆä¸ºè¯„ä¼°äººè„¸è¯†åˆ«ç³»ç»Ÿéšç§é£é™©çš„é‡è¦å·¥å…·ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹è¿›è¡Œä¸ªä½“ç”Ÿæˆå™¨çš„è®­ç»ƒï¼Œè¿™æ˜¯ä¸€ä¸ªè®¡ç®—æˆæœ¬é«˜æ˜‚çš„è¿‡ç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†DiffUMIï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„äººè„¸è¯†åˆ«ç³»ç»Ÿæ‰©æ•£é©±åŠ¨é€šç”¨æ¨¡å‹åè½¬æ”»å‡»ã€‚DiffUMIæ˜¯ç¬¬ä¸€ä¸ªå°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºæ— æ¡ä»¶å›¾åƒç”Ÿæˆçš„æ–¹æ³•ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼ŒDiffUMIå…·æœ‰é€šç”¨æ€§ï¼Œæ— éœ€é’ˆå¯¹ç›®æ ‡è¿›è¡Œè®­ç»ƒç”Ÿæˆå™¨ã€‚å®ƒåœ¨å›ºå®šçš„æ¡†æ¶å’Œé¢„å…ˆè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å†…è¿è¡Œï¼Œæ— ç¼é€‚åº”ä¸åŒçš„ç›®æ ‡èº«ä»½å’Œæ¨¡å‹ã€‚DiffUMIä»¥æœ€å…ˆè¿›çš„æˆåŠŸç‡çªç ´äº†éšç§ä¿æŠ¤äººè„¸è¯†åˆ«ç³»ç»Ÿï¼Œè¯æ˜æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹ç»“åˆä¼˜åŒ–çš„å¯¹æŠ—æ€§æœç´¢å¯å®ç°é«˜æ•ˆã€é«˜ä¿çœŸåº¦çš„é¢éƒ¨é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸŸå¤–æ£€æµ‹ï¼ˆOODDï¼‰çš„æ–°åº”ç”¨ï¼Œé¦–æ¬¡ä½¿ç”¨æ¨¡å‹åè½¬æ¥ä»…æ ¹æ®åµŒå…¥æ¥åŒºåˆ†éé¢éƒ¨è¾“å…¥å’Œé¢éƒ¨è¾“å…¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18015v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¢éƒ¨è¯†åˆ«æŠ€æœ¯å­˜åœ¨é‡å¤§éšç§é£é™©ï¼Œå› ä¸ºè¯¥æŠ€æœ¯ä¾èµ–äºç”Ÿç‰©ç‰¹å¾æ•°æ®ï¼Œä¸€æ—¦æ³„éœ²å³å¯èƒ½é€ æˆæ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚ä¸ºç¼“è§£è¿™äº›æ‹…å¿§ï¼Œé¢éƒ¨è¯†åˆ«ç³»ç»Ÿå°†åŸå§‹å›¾åƒè½¬åŒ–ä¸ºåµŒå…¥æ•°æ®ï¼Œä¸€èˆ¬è®¤ä¸ºè¿™ä¸€è¿‡ç¨‹èƒ½ä¿æŠ¤éšç§ã€‚ç„¶è€Œï¼Œæ¨¡å‹é€†å‘æ”»å‡»é€šè¿‡é‡å»ºè¿™äº›ç§äººé¢éƒ¨å›¾åƒï¼Œå¯¹éšç§æ„æˆä¸¥é‡å¨èƒï¼Œæˆä¸ºè¯„ä¼°é¢éƒ¨è¯†åˆ«ç³»ç»Ÿéšç§é£é™©çš„é‡è¦å·¥å…·ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹è¿›è¡Œä¸ªä½“ç”Ÿæˆå™¨è®­ç»ƒï¼Œè¿™ä¸€è¿‡ç¨‹è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ— éœ€è®­ç»ƒçš„æ‰©æ•£é©±åŠ¨é€šç”¨æ¨¡å‹é€†å‘æ”»å‡»æ–¹æ³•DiffUMIã€‚DiffUMIé¦–æ¬¡å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºæ— æ¡ä»¶å›¾åƒç”Ÿæˆä¸­çš„æ¨¡å‹é€†å‘ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼ŒDiffUMIå…·æœ‰é€šç”¨æ€§ï¼Œæ— éœ€é’ˆå¯¹ç›®æ ‡è¿›è¡Œç‰¹å®šç”Ÿæˆå™¨è®­ç»ƒã€‚å®ƒåœ¨å›ºå®šæ¡†æ¶å’Œé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å†…è¿è¡Œï¼Œå¹¶èƒ½è½»æ¾é€‚åº”ä¸åŒç›®æ ‡èº«ä»½å’Œæ¨¡å‹ã€‚DiffUMIä»¥é«˜æˆåŠŸç‡çªç ´äº†éšç§ä¿æŠ¤é¢éƒ¨è¯†åˆ«ç³»ç»Ÿï¼Œè¯æ˜æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹ç»“åˆä¼˜åŒ–çš„å¯¹æŠ—æœç´¢å¯å®ç°é«˜æ•ˆã€é«˜ä¿çœŸåº¦çš„é¢éƒ¨é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†åŸŸå¤–æ£€æµ‹çš„æ–°åº”ç”¨ï¼ˆOODDï¼‰ï¼Œé¦–æ¬¡ä½¿ç”¨æ¨¡å‹é€†å‘æŠ€æœ¯ä»…æ ¹æ®åµŒå…¥æ¥åŒºåˆ†éé¢éƒ¨è¾“å…¥å’Œé¢éƒ¨è¾“å…¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢éƒ¨è¯†åˆ«æŠ€æœ¯å­˜åœ¨éšç§æ³„éœ²é£é™©ï¼Œå› ä¸ºä¾èµ–çš„ç”Ÿç‰©ç‰¹å¾æ•°æ®æ•æ„Ÿä¸”ä¸€æ—¦æ³„éœ²åæœä¸¥é‡ã€‚</li>
<li>ä¸ºä¿æŠ¤éšç§ï¼Œé¢éƒ¨è¯†åˆ«ç³»ç»Ÿé€šå¸¸å°†åŸå§‹å›¾åƒè½¬åŒ–ä¸ºåµŒå…¥æ•°æ®ã€‚</li>
<li>æ¨¡å‹é€†å‘æ”»å‡»èƒ½é‡å»ºé¢éƒ¨å›¾åƒï¼Œæˆä¸ºè¯„ä¼°é¢éƒ¨è¯†åˆ«ç³»ç»Ÿéšç§é£é™©çš„é‡è¦å·¥å…·ã€‚</li>
<li>ç°æœ‰æ¨¡å‹é€†å‘æ”»å‡»æ–¹æ³•è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦é’ˆå¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹è¿›è¡Œä¸ªä½“ç”Ÿæˆå™¨è®­ç»ƒã€‚</li>
<li>DiffUMIæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ‰©æ•£é©±åŠ¨é€šç”¨æ¨¡å‹é€†å‘æ”»å‡»æ–¹æ³•ï¼Œé¦–æ¬¡å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºæ— æ¡ä»¶å›¾åƒç”Ÿæˆã€‚</li>
<li>DiffUMIå…·æœ‰é€šç”¨æ€§ï¼Œèƒ½åœ¨å›ºå®šæ¡†æ¶å’Œé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å†…è¿è¡Œï¼Œé€‚åº”ä¸åŒç›®æ ‡èº«ä»½å’Œæ¨¡å‹ã€‚</li>
<li>DiffUMIæˆåŠŸçªç ´äº†éšç§ä¿æŠ¤é¢éƒ¨è¯†åˆ«ç³»ç»Ÿï¼Œå¹¶å¼•å…¥äº†åŸŸå¤–æ£€æµ‹çš„æ–°åº”ç”¨ï¼ˆOODDï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18015">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2622eab451ae9986e0f158dacad0e4ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1e0b01c5c6c4809eea98aaaf3122fbf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf3b3bd0fde15f3f484445c00f5ca855.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-af736918611795d8d53839a090c1dd44.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Dual-Prompting-Image-Restoration-with-Diffusion-Transformers"><a href="#Dual-Prompting-Image-Restoration-with-Diffusion-Transformers" class="headerlink" title="Dual Prompting Image Restoration with Diffusion Transformers"></a>Dual Prompting Image Restoration with Diffusion Transformers</h2><p><strong>Authors:Dehong Kong, Fan Li, Zhixin Wang, Jiaqi Xu, Renjing Pei, Wenbo Li, WenQi Ren</strong></p>
<p>Recent state-of-the-art image restoration methods mostly adopt latent diffusion models with U-Net backbones, yet still facing challenges in achieving high-quality restoration due to their limited capabilities. Diffusion transformers (DiTs), like SD3, are emerging as a promising alternative because of their better quality with scalability. In this paper, we introduce DPIR (Dual Prompting Image Restoration), a novel image restoration method that effectivly extracts conditional information of low-quality images from multiple perspectives. Specifically, DPIR consits of two branches: a low-quality image conditioning branch and a dual prompting control branch. The first branch utilizes a lightweight module to incorporate image priors into the DiT with high efficiency. More importantly, we believe that in image restoration, textual description alone cannot fully capture its rich visual characteristics. Therefore, a dual prompting module is designed to provide DiT with additional visual cues, capturing both global context and local appearance. The extracted global-local visual prompts as extra conditional control, alongside textual prompts to form dual prompts, greatly enhance the quality of the restoration. Extensive experimental results demonstrate that DPIR delivers superior image restoration performance. </p>
<blockquote>
<p>æœ€æ–°çš„å…ˆè¿›å›¾åƒæ¢å¤æ–¹æ³•ä¸»è¦é‡‡ç”¨äº†åŸºäºU-Netçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œä½†ç”±äºå…¶èƒ½åŠ›æœ‰é™ï¼Œä»é¢ä¸´ç€å®ç°é«˜è´¨é‡æ¢å¤çš„æŒ‘æˆ˜ã€‚æ‰©æ•£å˜å‹å™¨ï¼ˆDiTsï¼‰å¦‚SD3å› å…¶å¯æ‰©å±•æ€§å’Œæ›´å¥½çš„è´¨é‡è€Œæˆä¸ºæœ‰å‰é€”çš„æ›¿ä»£å“ã€‚æœ¬æ–‡ä»‹ç»äº†DPIRï¼ˆåŒæç¤ºå›¾åƒæ¢å¤ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å›¾åƒæ¢å¤æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å¤šä¸ªè§’åº¦æœ‰æ•ˆåœ°æå–ä½è´¨é‡å›¾åƒçš„æ¡ä»¶ä¿¡æ¯ã€‚å…·ä½“æ¥è¯´ï¼ŒDPIRåŒ…æ‹¬ä¸¤ä¸ªåˆ†æ”¯ï¼šä½è´¨é‡å›¾åƒæ¡ä»¶åˆ†æ”¯å’ŒåŒæç¤ºæ§åˆ¶åˆ†æ”¯ã€‚ç¬¬ä¸€ä¸ªåˆ†æ”¯åˆ©ç”¨è½»é‡çº§æ¨¡å—é«˜æ•ˆåœ°å°†å›¾åƒå…ˆéªŒçŸ¥è¯†èå…¥åˆ°DiTä¸­ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è®¤ä¸ºåœ¨å›¾åƒæ¢å¤ä¸­ï¼Œå•çº¯çš„æ–‡æœ¬æè¿°æ— æ³•å……åˆ†æ•æ‰å…¶ä¸°å¯Œçš„è§†è§‰ç‰¹å¾ã€‚å› æ­¤ï¼Œè®¾è®¡äº†åŒæç¤ºæ¨¡å—ï¼Œä¸ºDiTæä¾›é¢å¤–çš„è§†è§‰çº¿ç´¢ï¼Œæ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨å¤–è§‚ã€‚æå–çš„å…¨å±€-å±€éƒ¨è§†è§‰æç¤ºä½œä¸ºé¢å¤–çš„æ¡ä»¶æ§åˆ¶ï¼Œä¸æ–‡æœ¬æç¤ºä¸€èµ·å½¢æˆåŒæç¤ºï¼Œæå¤§åœ°æé«˜äº†æ¢å¤çš„è´¨é‡ã€‚å¤§é‡çš„å®éªŒç»“æœè¯æ˜ï¼ŒDPIRåœ¨å›¾åƒæ¢å¤æ€§èƒ½æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17825v1">PDF</a> CVPR2025</p>
<p><strong>Summary</strong></p>
<p>æœ€æ–°å›¾åƒä¿®å¤æ–¹æ³•ä¸»è¦é‡‡ç”¨äº†å¸¦æœ‰U-Netéª¨å¹²çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œä½†ä»é¢ä¸´å› èƒ½åŠ›æœ‰é™è€Œæ— æ³•å®ç°é«˜è´¨é‡ä¿®å¤çš„éš¾é¢˜ã€‚æ‰©æ•£å˜å‹å™¨ï¼ˆDiTsï¼‰å¦‚SD3å› å…¶è¾ƒå¥½çš„è´¨é‡å’Œå¯æ‰©å±•æ€§è€Œå´­éœ²å¤´è§’ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹å›¾åƒä¿®å¤æ–¹æ³•DPIRï¼ˆåŒæç¤ºå›¾åƒä¿®å¤ï¼‰ï¼Œå®ƒé€šè¿‡å¤šä¸ªè§’åº¦æœ‰æ•ˆåœ°æå–ä½è´¨é‡å›¾åƒçš„æ¡ä»¶ä¿¡æ¯ã€‚DPIRåŒ…æ‹¬ä¸¤ä¸ªåˆ†æ”¯ï¼šä½è´¨é‡å›¾åƒæ¡ä»¶åˆ†æ”¯å’ŒåŒæç¤ºæ§åˆ¶åˆ†æ”¯ã€‚ç¬¬ä¸€ä¸ªåˆ†æ”¯åˆ©ç”¨è½»é‡çº§æ¨¡å—é«˜æ•ˆåœ°å°†å›¾åƒå…ˆéªŒçŸ¥è¯†èå…¥DiTã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è®¤ä¸ºåœ¨å›¾åƒä¿®å¤ä¸­ï¼Œä»…ä¾é æ–‡æœ¬æè¿°æ— æ³•å®Œå…¨æ•æ‰å…¶ä¸°å¯Œçš„è§†è§‰ç‰¹å¾ã€‚å› æ­¤ï¼Œè®¾è®¡äº†åŒæç¤ºæ¨¡å—ï¼Œä¸ºDiTæä¾›é¢å¤–çš„è§†è§‰çº¿ç´¢ï¼Œæ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨å¤–è§‚ã€‚ç»“åˆæ–‡æœ¬æç¤ºå½¢æˆåŒé‡æç¤ºï¼Œæå¤§åœ°æé«˜äº†ä¿®å¤è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDPIRåœ¨å›¾åƒä¿®å¤æ–¹é¢å…·æœ‰å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤é¢†åŸŸå¹¿æ³›åº”ç”¨ï¼Œä½†ä»å­˜åœ¨é«˜è´¨é‡ä¿®å¤çš„æŒ‘æˆ˜ã€‚</li>
<li>ä»‹ç»äº†DPIRæ–¹æ³•ï¼ŒåŒ…å«ä¸¤ä¸ªåˆ†æ”¯ï¼šä½è´¨é‡å›¾åƒæ¡ä»¶åˆ†æ”¯å’ŒåŒæç¤ºæ§åˆ¶åˆ†æ”¯ã€‚</li>
<li>ä½è´¨é‡å›¾åƒæ¡ä»¶åˆ†æ”¯åˆ©ç”¨è½»é‡çº§æ¨¡å—é«˜æ•ˆèå…¥å›¾åƒå…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>ä»…ä¾é æ–‡æœ¬æè¿°åœ¨å›¾åƒä¿®å¤ä¸­æ— æ³•å®Œå…¨æ•æ‰è§†è§‰ç‰¹å¾ã€‚</li>
<li>åŒæç¤ºæ¨¡å—æä¾›é¢å¤–çš„è§†è§‰çº¿ç´¢ï¼ŒåŒæ—¶æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨å¤–è§‚ã€‚</li>
<li>ç»“åˆæ–‡æœ¬æç¤ºå½¢æˆçš„åŒé‡æç¤ºèƒ½æ˜¾è‘—æé«˜å›¾åƒä¿®å¤çš„è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17825">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-093bf89a3068a75212a5fa48c89fb324.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-48564c5809f4b7117d483ec581a40f88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e9d6b16b869624a185252336c771e02.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a478ac22623c490ba220499c246d3f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43bfc7efb6eb886fa47e4f32c63d3acb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a384da7b536cda2a4b63486b78c33dc5.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DreamID-High-Fidelity-and-Fast-diffusion-based-Face-Swapping-via-Triplet-ID-Group-Learning"><a href="#DreamID-High-Fidelity-and-Fast-diffusion-based-Face-Swapping-via-Triplet-ID-Group-Learning" class="headerlink" title="DreamID: High-Fidelity and Fast diffusion-based Face Swapping via   Triplet ID Group Learning"></a>DreamID: High-Fidelity and Fast diffusion-based Face Swapping via   Triplet ID Group Learning</h2><p><strong>Authors:Fulong Ye, Miao Hua, Pengze Zhang, Xinghui Li, Qichao Sun, Songtao Zhao, Qian He, Xinglong Wu</strong></p>
<p>In this paper, we introduce DreamID, a diffusion-based face swapping model that achieves high levels of ID similarity, attribute preservation, image fidelity, and fast inference speed. Unlike the typical face swapping training process, which often relies on implicit supervision and struggles to achieve satisfactory results. DreamID establishes explicit supervision for face swapping by constructing Triplet ID Group data, significantly enhancing identity similarity and attribute preservation. The iterative nature of diffusion models poses challenges for utilizing efficient image-space loss functions, as performing time-consuming multi-step sampling to obtain the generated image during training is impractical. To address this issue, we leverage the accelerated diffusion model SD Turbo, reducing the inference steps to a single iteration, enabling efficient pixel-level end-to-end training with explicit Triplet ID Group supervision. Additionally, we propose an improved diffusion-based model architecture comprising SwapNet, FaceNet, and ID Adapter. This robust architecture fully unlocks the power of the Triplet ID Group explicit supervision. Finally, to further extend our method, we explicitly modify the Triplet ID Group data during training to fine-tune and preserve specific attributes, such as glasses and face shape. Extensive experiments demonstrate that DreamID outperforms state-of-the-art methods in terms of identity similarity, pose and expression preservation, and image fidelity. Overall, DreamID achieves high-quality face swapping results at 512*512 resolution in just 0.6 seconds and performs exceptionally well in challenging scenarios such as complex lighting, large angles, and occlusions. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†DreamIDï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäºæ‰©æ•£çš„é¢è²Œæ›¿æ¢æ¨¡å‹ï¼Œå®ç°äº†é«˜æ°´å¹³çš„èº«ä»½ç›¸ä¼¼æ€§ã€å±æ€§ä¿ç•™ã€å›¾åƒä¿çœŸåº¦å’Œå¿«é€Ÿæ¨ç†é€Ÿåº¦ã€‚ä¸åŒäºå…¸å‹çš„é¢è²Œæ›¿æ¢è®­ç»ƒè¿‡ç¨‹ï¼Œå®ƒé€šå¸¸ä¾èµ–äºéšå¼ç›‘ç£ï¼Œä¸”éš¾ä»¥å®ç°ä»¤äººæ»¡æ„çš„ç»“æœã€‚DreamIDé€šè¿‡æ„å»ºTriplet ID Groupæ•°æ®å®ç°å¯¹é¢è²Œæ›¿æ¢çš„æ˜¾å¼ç›‘ç£ï¼Œä»è€Œæ˜¾è‘—æé«˜èº«ä»½ç›¸ä¼¼æ€§å’Œå±æ€§ä¿ç•™ã€‚æ‰©æ•£æ¨¡å‹çš„è¿­ä»£æ€§è´¨ç»™åˆ©ç”¨é«˜æ•ˆçš„å›¾åƒç©ºé—´æŸå¤±å‡½æ•°å¸¦æ¥äº†æŒ‘æˆ˜ï¼Œå› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œè€—æ—¶çš„å¤šæ­¥é‡‡æ ·ä»¥è·å¾—ç”Ÿæˆå›¾åƒæ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†åŠ é€Ÿæ‰©æ•£æ¨¡å‹SD Turboï¼Œå°†æ¨ç†æ­¥éª¤å‡å°‘åˆ°å•æ¬¡è¿­ä»£ï¼Œèƒ½å¤Ÿåœ¨æ˜¾å¼Triplet ID Groupç›‘ç£ä¸‹è¿›è¡Œé«˜æ•ˆçš„åƒç´ çº§ç«¯åˆ°ç«¯è®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ”¹è¿›çš„åŸºäºæ‰©æ•£çš„æ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬SwapNetã€FaceNetå’ŒIDé€‚é…å™¨ã€‚è¿™ä¸€ç¨³å¥çš„æ¶æ„å……åˆ†é‡Šæ”¾äº†Triplet ID Groupæ˜¾å¼ç›‘ç£çš„å¨åŠ›ã€‚æœ€åï¼Œä¸ºäº†è¿›ä¸€æ­¥å®Œå–„æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å¼ä¿®æ”¹äº†Triplet ID Groupæ•°æ®ï¼Œä»¥å¾®è°ƒå¹¶ä¿ç•™ç‰¹å®šå±æ€§ï¼Œå¦‚çœ¼é•œå’Œè„¸å‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDreamIDåœ¨èº«ä»½ç›¸ä¼¼æ€§ã€å§¿åŠ¿å’Œè¡¨æƒ…ä¿ç•™ä»¥åŠå›¾åƒä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºæœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚æ€»çš„æ¥è¯´ï¼ŒDreamIDåœ¨512*512åˆ†è¾¨ç‡ä¸‹å®ç°äº†é«˜è´¨é‡çš„é¢è²Œæ›¿æ¢ç»“æœï¼Œä»…éœ€0.6ç§’ï¼Œä¸”åœ¨å¤æ‚å…‰ç…§ã€å¤§è§’åº¦å’Œé®æŒ¡ç­‰æŒ‘æˆ˜åœºæ™¯ä¸‹è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14509v3">PDF</a> Project: <a target="_blank" rel="noopener" href="https://superhero-7.github.io/DreamID/">https://superhero-7.github.io/DreamID/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†DreamIDï¼Œä¸€ç§åŸºäºæ‰©æ•£æŠ€æœ¯çš„æ¢è„¸æ¨¡å‹ï¼Œå…·æœ‰èº«ä»½ç›¸ä¼¼åº¦é«˜ã€å±æ€§ä¿ç•™å®Œæ•´ã€å›¾åƒä¿çœŸåº¦é«˜å’Œæ¨ç†é€Ÿåº¦å¿«çš„ç‰¹ç‚¹ã€‚ä¸ä¼ ç»Ÿçš„æ¢è„¸è®­ç»ƒè¿‡ç¨‹ä¸åŒï¼ŒDreamIDé€šè¿‡æ„å»ºTriplet ID Groupæ•°æ®å®ç°æ˜¾å¼ç›‘ç£ï¼Œæ˜¾è‘—æé«˜äº†èº«ä»½ç›¸ä¼¼æ€§å’Œå±æ€§ä¿ç•™ã€‚ä¸ºè§£å†³æ‰©æ•£æ¨¡å‹çš„è¿­ä»£æ€§è´¨å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é‡‡ç”¨åŠ é€Ÿæ‰©æ•£æ¨¡å‹SD Turboï¼Œå°†æ¨ç†æ­¥éª¤å‡å°‘åˆ°å•æ¬¡è¿­ä»£ï¼Œå®ç°äº†é«˜æ•ˆçš„åƒç´ çº§ç«¯åˆ°ç«¯è®­ç»ƒï¼ŒåŒæ—¶è¾…ä»¥Triplet ID Groupçš„æ˜¾å¼ç›‘ç£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ”¹è¿›å‹çš„åŸºäºæ‰©æ•£çš„æ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬SwapNetã€FaceNetå’ŒID Adapterï¼Œå……åˆ†å‘æŒ¥Triplet ID Groupæ˜¾å¼ç›‘ç£çš„å¨åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜ç¡®ä¿®æ”¹äº†Triplet ID Groupæ•°æ®ï¼Œä»¥ç²¾ç»†è°ƒæ•´å¹¶ä¿ç•™ç‰¹å®šå±æ€§ï¼Œå¦‚çœ¼é•œå’Œè„¸å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒDreamIDåœ¨èº«ä»½ç›¸ä¼¼æ€§ã€å§¿åŠ¿å’Œè¡¨æƒ…ä¿ç•™ä»¥åŠå›¾åƒä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚æ€»çš„æ¥è¯´ï¼ŒDreamIDåœ¨512*512åˆ†è¾¨ç‡ä¸‹å®ç°äº†é«˜è´¨é‡æ¢è„¸ï¼Œåªéœ€0.6ç§’å³å¯å®Œæˆï¼Œå¹¶åœ¨å¤æ‚å…‰ç…§ã€å¤§è§’åº¦å’Œé®æŒ¡ç­‰æŒ‘æˆ˜åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>DreamIDæ˜¯åŸºäºæ‰©æ•£æŠ€æœ¯çš„æ¢è„¸æ¨¡å‹ï¼Œå®ç°é«˜èº«ä»½ç›¸ä¼¼æ€§ã€å±æ€§ä¿ç•™ã€å›¾åƒä¿çœŸåº¦å’Œå¿«é€Ÿæ¨ç†ã€‚</li>
<li>é€šè¿‡æ„å»ºTriplet ID Groupæ•°æ®å®ç°æ˜¾å¼ç›‘ç£ï¼Œæé«˜èº«ä»½ç›¸ä¼¼æ€§å’Œå±æ€§ä¿ç•™ã€‚</li>
<li>é‡‡ç”¨åŠ é€Ÿæ‰©æ•£æ¨¡å‹SD Turboï¼Œå‡å°‘æ¨ç†æ­¥éª¤è‡³å•æ¬¡è¿­ä»£ï¼Œå®ç°é«˜æ•ˆåƒç´ çº§ç«¯åˆ°ç«¯è®­ç»ƒã€‚</li>
<li>æ”¹è¿›çš„åŸºäºæ‰©æ•£çš„æ¨¡å‹æ¶æ„åŒ…æ‹¬SwapNetã€FaceNetå’ŒID Adapterï¼Œå……åˆ†å‘æŒ¥æ˜¾å¼ç›‘ç£çš„å¨åŠ›ã€‚</li>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿®æ”¹Triplet ID Groupæ•°æ®ï¼Œä»¥ä¿ç•™å’Œè°ƒæ•´ç‰¹å®šå±æ€§ï¼Œå¦‚çœ¼é•œå’Œè„¸å‹ã€‚</li>
<li>DreamIDåœ¨å¤šé¡¹å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨èº«ä»½ç›¸ä¼¼æ€§ã€å§¿åŠ¿å’Œè¡¨æƒ…ä¿ç•™ä»¥åŠå›¾åƒè´¨é‡æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14509">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7314fb6321a58289a81fae1eb843e45b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d048785f516ac3def442343aa72cec92.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3df1305be8367a6cc18f035376700d60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5c2281c747ef6711f0bef06217fa92f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d83efa0a045974afbd481f4861decccf.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Importance-Based-Token-Merging-for-Efficient-Image-and-Video-Generation"><a href="#Importance-Based-Token-Merging-for-Efficient-Image-and-Video-Generation" class="headerlink" title="Importance-Based Token Merging for Efficient Image and Video Generation"></a>Importance-Based Token Merging for Efficient Image and Video Generation</h2><p><strong>Authors:Haoyu Wu, Jingyi Xu, Hieu Le, Dimitris Samaras</strong></p>
<p>Token merging can effectively accelerate various vision systems by processing groups of similar tokens only once and sharing the results across them. However, existing token grouping methods are often ad hoc and random, disregarding the actual content of the samples. We show that preserving high-information tokens during merging - those essential for semantic fidelity and structural details - significantly improves sample quality, producing finer details and more coherent, realistic generations. Despite being simple and intuitive, this approach remains underexplored.   To do so, we propose an importance-based token merging method that prioritizes the most critical tokens in computational resource allocation, leveraging readily available importance scores, such as those from classifier-free guidance in diffusion models. Experiments show that our approach significantly outperforms baseline methods across multiple applications, including text-to-image synthesis, multi-view image generation, and video generation with various model architectures such as Stable Diffusion, Zero123++, AnimateDiff, or PixArt-$\alpha$. </p>
<blockquote>
<p>ä»¤ç‰Œåˆå¹¶é€šè¿‡ä»…å¤„ç†ä¸€æ¬¡ç›¸ä¼¼çš„ä»¤ç‰Œç»„å¹¶åœ¨å®ƒä»¬ä¹‹é—´å…±äº«ç»“æœï¼Œå¯ä»¥æœ‰æ•ˆåœ°åŠ é€Ÿå„ç§è§†è§‰ç³»ç»Ÿã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä»¤ç‰Œåˆ†ç»„æ–¹æ³•å¾€å¾€æ˜¯ä¸´æ—¶çš„å’Œéšæœºçš„ï¼Œå¿½ç•¥äº†æ ·æœ¬çš„å®é™…å†…å®¹ã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨åˆå¹¶è¿‡ç¨‹ä¸­ä¿ç•™é«˜ä¿¡æ¯ä»¤ç‰Œâ€”â€”å¯¹è¯­ä¹‰ä¿çœŸå’Œç»“æ„ç»†èŠ‚è‡³å…³é‡è¦çš„ä»¤ç‰Œâ€”â€”å¯ä»¥æ˜¾è‘—æé«˜æ ·æœ¬è´¨é‡ï¼Œäº§ç”Ÿæ›´ç²¾ç»†çš„ç»†èŠ‚å’Œæ›´è¿è´¯ã€æ›´é€¼çœŸçš„ç”Ÿæˆå†…å®¹ã€‚å°½ç®¡è¿™ç§æ–¹æ³•ç®€å•ç›´è§‚ï¼Œä½†ä»è¢«ç ”ç©¶å¾—ä¸å¤Ÿæ·±å…¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé‡è¦æ€§çš„ä»¤ç‰Œåˆå¹¶æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†é…è®¡ç®—èµ„æºæ—¶ä¼˜å…ˆè€ƒè™‘æœ€é‡è¦çš„ä»¤ç‰Œï¼Œå¹¶åˆ©ç”¨ç°æœ‰çš„é‡è¦æ€§è¯„åˆ†ï¼Œå¦‚æ‰©æ•£æ¨¡å‹ä¸­çš„æ— åˆ†ç±»å™¨å¼•å¯¼çš„é‡è¦æ€§è¯„åˆ†ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªåº”ç”¨ç¨‹åºä¸Šçš„è¡¨ç°éƒ½ä¼˜äºåŸºå‡†æ–¹æ³•ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å¤šè§†å›¾å›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”Ÿæˆï¼Œä»¥åŠä½¿ç”¨å„ç§æ¨¡å‹æ¶æ„ï¼ˆå¦‚Stable Diffusionã€Zero123++ã€AnimateDiffæˆ–PixArt-Î±ï¼‰çš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16720v2">PDF</a> </p>
<p><strong>Summary</strong><br>     é€šè¿‡åˆ©ç”¨åˆ†ç»„çš„é‡è¦æ€§åˆ†æ•°å®ç°ä»¤ç‰Œåˆå¹¶æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜å„ç±»è§†è§‰ç³»ç»Ÿçš„å¤„ç†é€Ÿåº¦ã€‚ç°æœ‰çš„ä»¤ç‰Œåˆå¹¶æ–¹æ³•å¸¸å¸¸å¿½è§†æ ·æœ¬çš„å®é™…å†…å®¹ï¼Œä»…éšæœºå¤„ç†ä»¤ç‰Œåˆ†ç»„ã€‚æˆ‘ä»¬æå‡ºä¸€ç§åŸºäºé‡è¦æ€§çš„ä»¤ç‰Œåˆå¹¶æ–¹æ³•ï¼Œåœ¨èµ„æºåˆ†é…ä¸­ä¼˜å…ˆå¤„ç†æœ€å…³é”®çš„ä»¤ç‰Œï¼Œå¹¶å€ŸåŠ©ç°æˆçš„æ‰©æ•£æ¨¡å‹ä¸­çš„åˆ†ç±»å™¨å…è´¹æŒ‡å¯¼æ¥å®ç°ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåº”ç”¨é¢†åŸŸä¸­å‡ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å¤šè§†å›¾å›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”Ÿæˆç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»¤ç‰Œåˆå¹¶æŠ€æœ¯å¯ä»¥åŠ é€Ÿè§†è§‰ç³»ç»Ÿçš„å¤„ç†é€Ÿåº¦ã€‚</li>
<li>å½“å‰ä»¤ç‰Œåˆ†ç»„æ–¹æ³•å¸¸å¸¸å¿½è§†æ ·æœ¬çš„å®é™…å†…å®¹ï¼Œå¯¼è‡´éšæœºå¤„ç†ä»¤ç‰Œåˆ†ç»„ã€‚</li>
<li>é€šè¿‡ä¿ç•™é«˜ä¿¡æ¯ä»¤ç‰Œï¼ˆå¯¹è¯­ä¹‰ä¿çœŸå’Œç»“æ„ç»†èŠ‚è‡³å…³é‡è¦çš„ä»¤ç‰Œï¼‰åœ¨åˆå¹¶è¿‡ç¨‹ä¸­å¯ä»¥æé«˜æ ·æœ¬è´¨é‡ã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé‡è¦æ€§çš„ä»¤ç‰Œåˆå¹¶æ–¹æ³•ï¼Œåˆ©ç”¨ç°æœ‰æ¨¡å‹ä¸­çš„é‡è¦æ€§åˆ†æ•°è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šç§åº”ç”¨é¢†åŸŸä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å¤šè§†å›¾å›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”Ÿæˆç­‰ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºå¤šç§æ¨¡å‹æ¶æ„ï¼Œå¦‚Stable Diffusionã€Zero123++ã€AnimateDiffå’ŒPixArt-$\alpha$ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8fc3584a9470f5103f702f13cad82b6d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fc216558a2439132a301104fc642a339.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86dee26d33974aa2d067aa31d2e3f3ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d31a5dfc884ad28c62373492831c0773.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d5ca38362ba6327a6f357b2a9bbfca7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Investigating-Memorization-in-Video-Diffusion-Models"><a href="#Investigating-Memorization-in-Video-Diffusion-Models" class="headerlink" title="Investigating Memorization in Video Diffusion Models"></a>Investigating Memorization in Video Diffusion Models</h2><p><strong>Authors:Chen Chen, Enhuai Liu, Daochang Liu, Mubarak Shah, Chang Xu</strong></p>
<p>Diffusion models, widely used for image and video generation, face a significant limitation: the risk of memorizing and reproducing training data during inference, potentially generating unauthorized copyrighted content. While prior research has focused on image diffusion models (IDMs), video diffusion models (VDMs) remain underexplored. To address this gap, we first formally define the two types of memorization in VDMs (content memorization and motion memorization) in a practical way that focuses on privacy preservation and applies to all generation types. We then introduce new metrics specifically designed to separately assess content and motion memorization in VDMs. Additionally, we curate a dataset of text prompts that are most prone to triggering memorization when used as conditioning in VDMs. By leveraging these prompts, we generate diverse videos from various open-source VDMs, successfully extracting numerous training videos from each tested model. Through the application of our proposed metrics, we systematically analyze memorization across various pretrained VDMs, including text-conditional and unconditional models, on a variety of datasets. Our comprehensive study reveals that memorization is widespread across all tested VDMs, indicating that VDMs can also memorize image training data in addition to video datasets. Finally, we propose efficient and effective detection strategies for both content and motion memorization, offering a foundational approach for improving privacy in VDMs. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹å¹¿æ³›åº”ç”¨äºå›¾åƒå’Œè§†é¢‘ç”Ÿæˆï¼Œä½†å®ƒä»¬é¢ä¸´ä¸€ä¸ªé‡å¤§å±€é™ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨è®°å¿†å’Œé‡ç°è®­ç»ƒæ•°æ®çš„é£é™©ï¼Œå¯èƒ½ä¼šç”Ÿæˆæœªç»æˆæƒçš„ç‰ˆæƒå†…å®¹ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆIDMsï¼‰ä¸Šï¼Œä½†è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬é¦–å…ˆä»¥å®ç”¨æ–¹å¼æ­£å¼å®šä¹‰VDMsä¸­çš„ä¸¤ç§è®°å¿†ç±»å‹ï¼ˆå†…å®¹è®°å¿†å’Œè¿åŠ¨è®°å¿†ï¼‰ï¼Œé‡ç‚¹å…³æ³¨éšç§ä¿æŠ¤å¹¶é€‚ç”¨äºæ‰€æœ‰ç”Ÿæˆç±»å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸“é—¨ç”¨äºå•ç‹¬è¯„ä¼°VDMsä¸­å†…å®¹å’Œè¿åŠ¨è®°å¿†çš„æ–°æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ•´ç†äº†ä¸€ç»„æ–‡æœ¬æç¤ºï¼Œå½“ç”¨ä½œVDMsçš„æ¡ä»¶æ—¶ï¼Œæœ€æœ‰å¯èƒ½è§¦å‘è®°å¿†ã€‚é€šè¿‡åˆ©ç”¨è¿™äº›æç¤ºï¼Œæˆ‘ä»¬ä»å„ç§å¼€æºVDMsç”Ÿæˆäº†å¤šæ ·åŒ–çš„è§†é¢‘ï¼ŒæˆåŠŸåœ°ä»æ¯ä¸ªæµ‹è¯•æ¨¡å‹ä¸­æå–äº†å¤§é‡è®­ç»ƒè§†é¢‘ã€‚é€šè¿‡åº”ç”¨æˆ‘ä»¬æå‡ºçš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†å„ç§é¢„è®­ç»ƒVDMsä¸­çš„è®°å¿†æƒ…å†µï¼ŒåŒ…æ‹¬æ–‡æœ¬æ¡ä»¶å’Œæ— æ¡ä»¶æ¨¡å‹ï¼Œä»¥åŠå„ç§æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç»¼åˆç ”ç©¶è¡¨æ˜ï¼Œæ‰€æœ‰æµ‹è¯•è¿‡çš„VDMséƒ½å­˜åœ¨å¹¿æ³›çš„è®°å¿†é—®é¢˜ï¼Œè¿™è¡¨æ˜VDMsé™¤äº†è§†é¢‘æ•°æ®é›†å¤–ï¼Œè¿˜èƒ½è®°ä½å›¾åƒè®­ç»ƒæ•°æ®ã€‚æœ€åï¼Œæˆ‘ä»¬ä¸ºå†…å®¹å’Œè¿åŠ¨è®°å¿†æå‡ºäº†é«˜æ•ˆä¸”æœ‰æ•ˆçš„æ£€æµ‹ç­–ç•¥ï¼Œä¸ºæ”¹å–„VDMsä¸­çš„éšç§æä¾›äº†åŸºç¡€æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.21669v2">PDF</a> Accepted at DATA-FM Workshop @ ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰ä¸­çš„è®°å¿†åŒ–é—®é¢˜ï¼ŒåŒ…æ‹¬å†…å®¹è®°å¿†åŒ–å’ŒåŠ¨ä½œè®°å¿†åŒ–ã€‚æ–‡ç« æ­£å¼å®šä¹‰äº†è¿™ä¸¤ç§è®°å¿†åŒ–ç±»å‹ï¼Œå¹¶å¼•å…¥ä¸“é—¨è¯„ä¼°VDMsä¸­å†…å®¹å’ŒåŠ¨ä½œè®°å¿†åŒ–çš„æ–°æŒ‡æ ‡ã€‚é€šè¿‡åˆ©ç”¨ç‰¹å®šæ–‡æœ¬æç¤ºï¼Œæ–‡ç« æˆåŠŸä»å„ç§é¢„è®­ç»ƒVDMsä¸­æå–äº†è®­ç»ƒè§†é¢‘ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè®°å¿†åŒ–åœ¨å„ç±»é¢„è®­ç»ƒVDMsä¸­æ™®éå­˜åœ¨ï¼Œä¸ä»…å­˜åœ¨äºè§†é¢‘æ•°æ®é›†ï¼Œä¹Ÿå­˜åœ¨äºå›¾åƒè®­ç»ƒæ•°æ®ä¸­ã€‚æœ€åï¼Œæ–‡ç« æå‡ºäº†é’ˆå¯¹å†…å®¹å’ŒåŠ¨ä½œè®°å¿†åŒ–çš„é«˜æ•ˆæ£€æµ‹ç­–ç•¥ï¼Œä¸ºæé«˜VDMsçš„éšç§æ€§æä¾›äº†åŸºç¡€æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å­˜åœ¨è®°å¿†åŒ–é£é™©ï¼Œå¯èƒ½ç”Ÿæˆæœªç»æˆæƒç‰ˆæƒå†…å®¹ã€‚</li>
<li>è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆVDMsï¼‰é¢ä¸´å†…å®¹è®°å¿†åŒ–å’ŒåŠ¨ä½œè®°å¿†åŒ–é—®é¢˜ï¼Œè¿™ä¸¤ç§ç±»å‹è¢«æ­£å¼å®šä¹‰å¹¶å¼•å…¥æ–°æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>é€šè¿‡ç‰¹å®šæ–‡æœ¬æç¤ºæˆåŠŸä»é¢„è®­ç»ƒVDMsä¸­æå–è®­ç»ƒè§†é¢‘ï¼Œè¡¨æ˜è®°å¿†åŒ–é—®é¢˜æ™®éå­˜åœ¨ã€‚</li>
<li>è®°å¿†åŒ–ä¸ä»…å­˜åœ¨äºè§†é¢‘æ•°æ®é›†ï¼Œä¹Ÿå­˜åœ¨äºå›¾åƒè®­ç»ƒæ•°æ®ä¸­ã€‚</li>
<li>å¼•å…¥è¯„ä¼°æŒ‡æ ‡åå‘ç°è®°å¿†åŒ–ç°è±¡åœ¨å„ç§é¢„è®­ç»ƒVDMsä¸­æ™®éå­˜åœ¨ã€‚</li>
<li>æ–‡ç« æä¾›äº†é’ˆå¯¹å†…å®¹å’ŒåŠ¨ä½œè®°å¿†åŒ–çš„é«˜æ•ˆæ£€æµ‹ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.21669">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1cc134d8c895dca306eb705642449eac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b8d2f54a37e0eb2b887de2bf20f98daa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b49dce5b8edb24533db87bd5fc36a078.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-16fc4055e9fef12aeaf5ac939d359b9b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Exploring-Local-Memorization-in-Diffusion-Models-via-Bright-Ending-Attention"><a href="#Exploring-Local-Memorization-in-Diffusion-Models-via-Bright-Ending-Attention" class="headerlink" title="Exploring Local Memorization in Diffusion Models via Bright Ending   Attention"></a>Exploring Local Memorization in Diffusion Models via Bright Ending   Attention</h2><p><strong>Authors:Chen Chen, Daochang Liu, Mubarak Shah, Chang Xu</strong></p>
<p>Text-to-image diffusion models have achieved unprecedented proficiency in generating realistic images. However, their inherent tendency to memorize and replicate training data during inference raises significant concerns, including potential copyright infringement. In response, various methods have been proposed to evaluate, detect, and mitigate memorization. Our analysis reveals that existing approaches significantly underperform in handling local memorization, where only specific image regions are memorized, compared to global memorization, where the entire image is replicated. Also, they cannot locate the local memorization regions, making it hard to investigate locally. To address these, we identify a novel â€œbright endingâ€ (BE) anomaly in diffusion models prone to memorizing training images. BE refers to a distinct cross-attention pattern observed in text-to-image diffusion models, where memorized image patches exhibit significantly greater attention to the final text token during the last inference step than non-memorized patches. This pattern highlights regions where the generated image replicates training data and enables efficient localization of memorized regions. Equipped with this, we propose a simple yet effective method to integrate BE into existing frameworks, significantly improving their performance by narrowing the performance gap caused by local memorization. Our results not only validate the successful execution of the new localization task but also establish new state-of-the-art performance across all existing tasks, underscoring the significance of the BE phenomenon. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨ç”ŸæˆçœŸå®å›¾åƒæ–¹é¢å–å¾—äº†å‰æ‰€æœªæœ‰çš„ç†Ÿç»ƒåº¦ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­å›ºæœ‰åœ°å€¾å‘äºè®°å¿†å’Œå¤åˆ¶è®­ç»ƒæ•°æ®ï¼Œè¿™å¼•å‘äº†é‡å¤§æ‹…å¿§ï¼ŒåŒ…æ‹¬æ½œåœ¨çš„çŸ¥è¯†äº§æƒä¾µçŠ¯ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€é—®é¢˜ï¼Œå·²ç»æå‡ºäº†å„ç§æ–¹æ³•æ¥è¯„ä¼°ã€æ£€æµ‹å’Œç¼“è§£è®°å¿†é—®é¢˜ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œä¸å…¨å±€è®°å¿†ç›¸æ¯”ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å±€éƒ¨è®°å¿†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå…¨å±€è®°å¿†æ˜¯æŒ‡å¤åˆ¶æ•´ä¸ªå›¾åƒï¼Œè€Œå±€éƒ¨è®°å¿†ä»…æŒ‡ç‰¹å®šå›¾åƒåŒºåŸŸçš„è®°å¿†ã€‚æ­¤å¤–ï¼Œå®ƒä»¬æ— æ³•å®šä½å±€éƒ¨è®°å¿†åŒºåŸŸï¼Œä½¿å¾—éš¾ä»¥è¿›è¡Œå±€éƒ¨è°ƒæŸ¥ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬ç¡®å®šäº†æ‰©æ•£æ¨¡å‹ä¸­å®¹æ˜“è®°å¿†è®­ç»ƒå›¾åƒçš„ä¸€ç§æ–°å‹â€œæ˜äº®ç»“æŸâ€ï¼ˆBEï¼‰å¼‚å¸¸ã€‚BEæ˜¯æŒ‡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°çš„ä¸€ç§ç‰¹æ®Šçš„è·¨æ³¨æ„åŠ›æ¨¡å¼ï¼Œå…¶ä¸­è®°å¿†çš„å›¾åƒæ–‘å—åœ¨æœ€åä¸€æ­¥æ¨ç†ä¸­å¯¹æœ€ç»ˆæ–‡æœ¬æ ‡è®°çš„æ³¨æ„åŠ›æ˜¾è‘—å¤§äºéè®°å¿†æ–‘å—ã€‚è¿™ç§æ¨¡å¼çªå‡ºäº†ç”Ÿæˆå›¾åƒå¤åˆ¶è®­ç»ƒæ•°æ®çš„åœ°æ–¹ï¼Œå¹¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å®šä½è®°å¿†çš„å›¾åƒåŒºåŸŸã€‚é€šè¿‡è¿ç”¨è¿™ä¸€æ¨¡å¼ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå°†BEæ•´åˆåˆ°ç°æœ‰æ¡†æ¶ä¸­ï¼Œé€šè¿‡ç¼©å°å±€éƒ¨è®°å¿†é€ æˆçš„æ€§èƒ½å·®è·ï¼Œæ˜¾è‘—æé«˜ç°æœ‰æ¡†æ¶çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœä¸ä»…éªŒè¯äº†æ–°å®šä½ä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œï¼Œè€Œä¸”ç¡®ç«‹äº†æ‰€æœ‰ç°æœ‰ä»»åŠ¡ä¸­çš„æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œçªæ˜¾äº†BEç°è±¡çš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.21665v2">PDF</a> Accepted at ICLR 2025 (Spotlight). Project page:   <a target="_blank" rel="noopener" href="https://chenchen-usyd.github.io/BE-Project-Page/">https://chenchen-usyd.github.io/BE-Project-Page/</a></p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬è½¬å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”ŸæˆçœŸå®å›¾åƒæ–¹é¢å–å¾—äº†å‰æ‰€æœªæœ‰çš„ç†Ÿç»ƒç¨‹åº¦ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„å›ºæœ‰å€¾å‘æ˜¯è®°å¿†å’Œå¤åˆ¶è®­ç»ƒæ•°æ®ï¼Œè¿™å¼•å‘äº†åŒ…æ‹¬æ½œåœ¨ç‰ˆæƒä¾µçŠ¯åœ¨å†…çš„æ‹…å¿§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œå·²ç»æå‡ºäº†å„ç§æ–¹æ³•æ¥è¯„ä¼°ã€æ£€æµ‹å’Œç¼“è§£è®°å¿†é—®é¢˜ã€‚æˆ‘ä»¬çš„åˆ†æå‘ç°ï¼Œç°æœ‰æ–¹æ³•åœ¨å±€éƒ¨è®°å¿†æ–¹é¢çš„è¡¨ç°æ˜¾è‘—è¾ƒå·®ï¼Œå…¶ä¸­åªæœ‰ç‰¹å®šçš„å›¾åƒåŒºåŸŸè¢«è®°å¿†ï¼Œä¸æ•´ä¸ªå›¾åƒéƒ½è¢«å¤åˆ¶çš„å…¨å±€è®°å¿†ç›¸æ¯”ã€‚æ­¤å¤–ï¼Œå®ƒä»¬æ— æ³•å®šä½å±€éƒ¨è®°å¿†åŒºåŸŸï¼Œä½¿å¾—æœ¬åœ°è°ƒæŸ¥å˜å¾—å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬ç¡®å®šäº†æ‰©æ•£æ¨¡å‹ä¸­æ˜“äºè®°å¿†è®­ç»ƒå›¾åƒçš„ä¸€ç§æ–°å‹â€œæ˜äº®ç»“æŸâ€ï¼ˆBEï¼‰å¼‚å¸¸ç°è±¡ã€‚BEæŒ‡çš„æ˜¯æ–‡æœ¬è½¬å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°çš„äº¤å‰æ³¨æ„åŠ›æ¨¡å¼çš„ç‹¬ç‰¹ç°è±¡ï¼Œå…¶ä¸­è®°å¿†çš„å›¾åƒæ–‘å—åœ¨æœ€åæ¨ç†æ­¥éª¤ä¸­å¯¹æœ€ç»ˆæ–‡æœ¬ä»¤ç‰Œçš„æ³¨æ„åŠ›æ˜¾è‘—é«˜äºéè®°å¿†æ–‘å—ã€‚è¿™ç§æ¨¡å¼çªå‡ºäº†ç”Ÿæˆå›¾åƒå¤åˆ¶è®­ç»ƒæ•°æ®çš„åŒºåŸŸï¼Œå¹¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å®šä½è®°å¿†åŒºåŸŸã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå°†BEé›†æˆåˆ°ç°æœ‰æ¡†æ¶ä¸­ï¼Œé€šè¿‡ç¼©å°å±€éƒ¨è®°å¿†é€ æˆçš„æ€§èƒ½å·®è·ï¼Œæ˜¾è‘—æé«˜å®ƒä»¬çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœä¸ä»…éªŒè¯äº†æ–°å®šä½ä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œï¼Œè€Œä¸”åœ¨æ‰€æœ‰ç°æœ‰ä»»åŠ¡ä¸­å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œçªæ˜¾äº†BEç°è±¡çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬è½¬å›¾åƒæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜åº¦é€¼çœŸçš„å›¾åƒï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨è®°å¿†å’Œå¤åˆ¶è®­ç»ƒæ•°æ®çš„å€¾å‘ã€‚</li>
<li>è¿™ç§å€¾å‘å¯èƒ½å¯¼è‡´ç‰ˆæƒé—®é¢˜å’Œå…¶ä»–ç›¸å…³é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹å’Œå¤„ç†å±€éƒ¨è®°å¿†é—®é¢˜æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œæ— æ³•å®šä½å±€éƒ¨è®°å¿†åŒºåŸŸã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºâ€œæ˜äº®ç»“æŸâ€ï¼ˆBEï¼‰çš„æ–°ç°è±¡ï¼Œè¡¨ç°ä¸ºä¸€ç§ç‹¬ç‰¹çš„äº¤å‰æ³¨æ„åŠ›æ¨¡å¼ï¼Œæœ‰åŠ©äºè¯†åˆ«è®°å¿†çš„å›¾åƒåŒºåŸŸã€‚</li>
<li>é€šè¿‡å°†BEé›†æˆåˆ°ç°æœ‰æ¡†æ¶ä¸­ï¼Œå¯ä»¥æœ‰æ•ˆå®šä½å’Œç¼“è§£å±€éƒ¨è®°å¿†é—®é¢˜ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ–°æ–¹æ³•çš„æ€§èƒ½åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›çš„æ°´å¹³ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.21665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2a4edb13fdd90b3c79b08e52226a7a93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d59cc7c3c51556fccefb5890ac0b2c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc5a29051210962c3498696fd9f87627.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33d44aae5db2b60b6c97e6709deb000a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51e8b80ce082ced56e8e375608d1bc9f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Improving-Consistency-in-Diffusion-Models-for-Image-Super-Resolution"><a href="#Improving-Consistency-in-Diffusion-Models-for-Image-Super-Resolution" class="headerlink" title="Improving Consistency in Diffusion Models for Image Super-Resolution"></a>Improving Consistency in Diffusion Models for Image Super-Resolution</h2><p><strong>Authors:Junhao Gu, Peng-Tao Jiang, Hao Zhang, Mi Zhou, Jinwei Chen, Wenming Yang, Bo Li</strong></p>
<p>Recent methods exploit the powerful text-to-image (T2I) diffusion models for real-world image super-resolution (Real-ISR) and achieve impressive results compared to previous models. However, we observe two kinds of inconsistencies in diffusion-based methods which hinder existing models from fully exploiting diffusion priors. The first is the semantic inconsistency arising from diffusion guidance. T2I generation focuses on semantic-level consistency with text prompts, while Real-ISR emphasizes pixel-level reconstruction from low-quality (LQ) images, necessitating more detailed semantic guidance from LQ inputs. The second is the training-inference inconsistency stemming from the DDPM, which improperly assumes high-quality (HQ) latent corrupted by Gaussian noise as denoising inputs for each timestep. To address these issues, we introduce ConsisSR to handle both semantic and training-inference consistencies. On the one hand, to address the semantic inconsistency, we proposed a Hybrid Prompt Adapter (HPA). Instead of text prompts with coarse-grained classification information, we leverage the more powerful CLIP image embeddings to explore additional color and texture guidance. On the other hand, we introduce Time-Aware Latent Augmentation (TALA) to bridge the training-inference inconsistency. Based on the probability function p(t), we accordingly enhance the SDSR training strategy. With LQ latent with Gaussian noise as inputs, our TALA not only focuses on diffusion noise but also refine the LQ latent towards the HQ counterpart. Our method demonstrates state-of-the-art performance among existing diffusion models. The code will be made publicly available. </p>
<blockquote>
<p>æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨å¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹è¿›è¡Œç°å®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰å¤„ç†ï¼Œä¸ä¹‹å‰çš„æ¨¡å‹ç›¸æ¯”å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ‰©æ•£æ¨¡å‹ä¸­å­˜åœ¨ä¸¤ç§ä¸ä¸€è‡´æ€§ï¼Œé˜»ç¢äº†ç°æœ‰æ¨¡å‹å……åˆ†åˆ©ç”¨æ‰©æ•£å…ˆéªŒçŸ¥è¯†ã€‚ç¬¬ä¸€ç§æ˜¯æ‰©æ•£å¼•å¯¼äº§ç”Ÿçš„è¯­ä¹‰ä¸ä¸€è‡´æ€§ã€‚T2Iç”Ÿæˆä¾§é‡äºä¸æ–‡æœ¬æç¤ºçš„è¯­ä¹‰çº§åˆ«ä¸€è‡´æ€§ï¼Œè€ŒReal-ISRå¼ºè°ƒä»ä½è´¨é‡ï¼ˆLQï¼‰å›¾åƒè¿›è¡Œåƒç´ çº§é‡å»ºï¼Œéœ€è¦LQè¾“å…¥æä¾›æ›´è¯¦ç»†çš„è¯­ä¹‰å¼•å¯¼ã€‚ç¬¬äºŒç§æ˜¯DDPMäº§ç”Ÿçš„è®­ç»ƒæ¨ç†ä¸ä¸€è‡´æ€§ï¼Œå®ƒé”™è¯¯åœ°å‡è®¾é«˜è´¨é‡ï¼ˆHQï¼‰æ½œåœ¨å˜é‡å—åˆ°é«˜æ–¯å™ªå£°çš„ç ´åï¼Œä½œä¸ºæ¯ä¸ªæ—¶é—´æ­¥é•¿çš„å»å™ªè¾“å…¥ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ConsisSRæ¥å¤„ç†è¯­ä¹‰å’Œè®­ç»ƒæ¨ç†ä¸€è‡´æ€§ã€‚ä¸€æ–¹é¢ï¼Œä¸ºäº†è§£å†³è¯­ä¹‰ä¸ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆæç¤ºé€‚é…å™¨ï¼ˆHPAï¼‰ã€‚æˆ‘ä»¬ä¸å†ä½¿ç”¨å¸¦æœ‰ç²—ç²’åº¦åˆ†ç±»ä¿¡æ¯çš„æ–‡æœ¬æç¤ºï¼Œè€Œæ˜¯åˆ©ç”¨æ›´å¼ºå¤§çš„CLIPå›¾åƒåµŒå…¥æ¥æ¢ç´¢é¢å¤–çš„é¢œè‰²å’Œçº¹ç†æŒ‡å¯¼ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥æ—¶é—´æ„ŸçŸ¥æ½œåœ¨å¢å¼ºï¼ˆTALAï¼‰æ¥å¼¥åˆè®­ç»ƒæ¨ç†ä¸ä¸€è‡´æ€§çš„é¸¿æ²Ÿã€‚åŸºäºæ¦‚ç‡å‡½æ•°p(t)ï¼Œæˆ‘ä»¬ç›¸åº”åœ°å¢å¼ºäº†SDSRè®­ç»ƒç­–ç•¥ã€‚ä½¿ç”¨LQæ½œåœ¨å¸¦æœ‰é«˜æ–¯å™ªå£°ä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬çš„TALAä¸ä»…å…³æ³¨æ‰©æ•£å™ªå£°ï¼Œè€Œä¸”è¿˜ä½¿LQæ½œåœ¨å‘HQå¯¹åº”ç‰©è¿›è¡Œç²¾ç‚¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å°†å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13807v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ€æ–°æ–¹æ³•åˆ©ç”¨å¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹è¿›è¡Œç°å®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰ï¼Œä¸ä¹‹å‰çš„æ¨¡å‹ç›¸æ¯”å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ‰©æ•£æ¨¡å‹ä¸­çš„ä¸¤ç§ä¸ä¸€è‡´æ€§ï¼Œé˜»ç¢äº†ç°æœ‰æ¨¡å‹å……åˆ†åˆ©ç”¨æ‰©æ•£å…ˆéªŒã€‚é¦–å…ˆæ˜¯è¯­ä¹‰ä¸ä¸€è‡´æ€§ï¼Œæºäºæ‰©æ•£æŒ‡å¯¼ã€‚T2Iç”Ÿæˆä¾§é‡äºä¸æ–‡æœ¬æç¤ºçš„è¯­ä¹‰çº§ä¸€è‡´æ€§ï¼Œè€ŒReal-ISRå¼ºè°ƒä»ä½è´¨é‡ï¼ˆLQï¼‰å›¾åƒè¿›è¡Œåƒç´ çº§é‡å»ºï¼Œéœ€è¦æ›´å¤šè¯¦ç»†çš„è¯­ä¹‰æŒ‡å¯¼æ¥è‡ªLQè¾“å…¥ã€‚å…¶æ¬¡æ˜¯DDPMäº§ç”Ÿçš„è®­ç»ƒæ¨ç†ä¸ä¸€è‡´æ€§ï¼Œå®ƒé”™è¯¯åœ°å‡è®¾é«˜è´¨é‡ï¼ˆHQï¼‰æ½œåœ¨å˜é‡è¢«é«˜æ–¯å™ªå£°è…èš€ä½œä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„é™å™ªè¾“å…¥ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ConsisSRæ¥å¤„ç†è¯­ä¹‰å’Œè®­ç»ƒæ¨ç†çš„ä¸€è‡´æ€§ã€‚ä¸€æ–¹é¢ï¼Œä¸ºäº†è§£å†³è¯­ä¹‰ä¸ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆæç¤ºé€‚é…å™¨ï¼ˆHPAï¼‰ã€‚æˆ‘ä»¬åˆ©ç”¨æ›´å¼ºå¤§çš„CLIPå›¾åƒåµŒå…¥æ¥æ¢ç´¢é¢å¤–çš„é¢œè‰²å’Œçº¹ç†æŒ‡å¯¼ï¼Œè€Œä¸æ˜¯å¸¦æœ‰ç²—ç•¥åˆ†ç±»ä¿¡æ¯çš„æ–‡æœ¬æç¤ºã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥æ—¶é—´æ„ŸçŸ¥æ½œåœ¨å¢å¼ºï¼ˆTALAï¼‰æ¥å¼¥åˆè®­ç»ƒæ¨ç†çš„ä¸ä¸€è‡´æ€§ã€‚åŸºäºæ¦‚ç‡å‡½æ•°p(t)ï¼Œæˆ‘ä»¬ç›¸åº”åœ°å¢å¼ºäº†SDSRè®­ç»ƒç­–ç•¥ã€‚ä½¿ç”¨LQæ½œåœ¨å¸¦æœ‰é«˜æ–¯å™ªå£°ä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬çš„TALAä¸ä»…å…³æ³¨æ‰©æ•£å™ªå£°ï¼Œè¿˜ä¼˜åŒ–LQæ½œåœ¨å˜é‡å‘HQå¯¹åº”ç‰©é è¿‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰æ‰©æ•£æ¨¡å‹ä¸­è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ï¼Œç›¸å…³ä»£ç å°†å…¬å¼€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹åœ¨ç°å®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰ä»»åŠ¡ä¸­å–å¾—æ˜¾è‘—æˆæœã€‚</li>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹å­˜åœ¨è¯­ä¹‰ä¸ä¸€è‡´å’Œè®­ç»ƒæ¨ç†ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>ConsisSRè¢«æå‡ºæ¥å¤„ç†è¿™ä¸¤ç§ä¸ä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬æ··åˆæç¤ºé€‚é…å™¨ï¼ˆHPAï¼‰å’Œæ—¶é—´æ„ŸçŸ¥æ½œåœ¨å¢å¼ºï¼ˆTALAï¼‰ã€‚</li>
<li>HPAåˆ©ç”¨CLIPå›¾åƒåµŒå…¥æ¥æä¾›é¢å¤–çš„é¢œè‰²å’Œçº¹ç†æŒ‡å¯¼ï¼Œè§£å†³è¯­ä¹‰ä¸ä¸€è‡´é—®é¢˜ã€‚</li>
<li>TALAåŸºäºæ¦‚ç‡å‡½æ•°å¢å¼ºSDSRè®­ç»ƒç­–ç•¥ï¼Œä»¥ç¼©å°è®­ç»ƒä¸æ¨ç†ä¹‹é—´çš„å·®è·ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ä»…åœ¨åƒç´ çº§é‡å»ºæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨å¤„ç†ä½è´¨é‡å›¾åƒæ—¶æä¾›äº†å¼ºå¤§çš„è¯­ä¹‰æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13807">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e346da3e4319c31fc71877bc65d72d8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd03653aa4185212c3b445c5dba58733.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f48d10b9c78f5008be9a10ecb91567d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1e60b4a23846bdc9ef2a2bb4d396f76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5b8b0030aa0d3ff2484f1300b5ecd16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e6f7bca529fbe5dcbdf7d2c96c35fb2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1653cda80b8d0781cf2a9a641f80c613.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60b30a9f2144f294f13c1024cd533337.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-29/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-29/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-29/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-0c7c2a2d7f366b6cf266a0da24959227.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  RSFR A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor   Cardiac MRI with Semantic-Aware Refinement
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-29/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-636de62659fd962c181f7bd36cdeb9d9.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-29  RGS-DR Reflective Gaussian Surfels with Deferred Rendering for Shiny   Objects
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17012.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
