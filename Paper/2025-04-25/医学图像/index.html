<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors   and Cross-Model Attention Mechanism">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2de2ab782bb738a685dc213474d3390b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    48 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-25-æ›´æ–°"><a href="#2025-04-25-æ›´æ–°" class="headerlink" title="2025-04-25 æ›´æ–°"></a>2025-04-25 æ›´æ–°</h1><h2 id="Advanced-Chest-X-Ray-Analysis-via-Transformer-Based-Image-Descriptors-and-Cross-Model-Attention-Mechanism"><a href="#Advanced-Chest-X-Ray-Analysis-via-Transformer-Based-Image-Descriptors-and-Cross-Model-Attention-Mechanism" class="headerlink" title="Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors   and Cross-Model Attention Mechanism"></a>Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors   and Cross-Model Attention Mechanism</h2><p><strong>Authors:Lakshita Agarwal, Bindu Verma</strong></p>
<p>The examination of chest X-ray images is a crucial component in detecting various thoracic illnesses. This study introduces a new image description generation model that integrates a Vision Transformer (ViT) encoder with cross-modal attention and a GPT-4-based transformer decoder. The ViT captures high-quality visual features from chest X-rays, which are fused with text data through cross-modal attention to improve the accuracy, context, and richness of image descriptions. The GPT-4 decoder transforms these fused features into accurate and relevant captions. The model was tested on the National Institutes of Health (NIH) and Indiana University (IU) Chest X-ray datasets. On the IU dataset, it achieved scores of 0.854 (B-1), 0.883 (CIDEr), 0.759 (METEOR), and 0.712 (ROUGE-L). On the NIH dataset, it achieved the best performance on all metrics: BLEU 1â€“4 (0.825, 0.788, 0.765, 0.752), CIDEr (0.857), METEOR (0.726), and ROUGE-L (0.705). This framework has the potential to enhance chest X-ray evaluation, assisting radiologists in more precise and efficient diagnosis. </p>
<blockquote>
<p>èƒ¸éƒ¨Xå°„çº¿å›¾åƒçš„æ£€æŸ¥æ˜¯æ£€æµ‹å„ç§èƒ¸éƒ¨ç–¾ç—…çš„å…³é”®ç¯èŠ‚ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ–°çš„å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é›†æˆäº†Vision Transformerï¼ˆViTï¼‰ç¼–ç å™¨ã€è·¨æ¨¡æ€æ³¨æ„åŠ›å’ŒåŸºäºGPT-4çš„å˜å‹å™¨è§£ç å™¨ã€‚ViTä»èƒ¸éƒ¨Xå°„çº¿å›¾åƒä¸­æ•è·é«˜è´¨é‡è§†è§‰ç‰¹å¾ï¼Œé€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›ä¸æ–‡æœ¬æ•°æ®èåˆï¼Œæé«˜äº†å›¾åƒæè¿°çš„å‡†ç¡®æ€§ã€ä¸Šä¸‹æ–‡å…³è”åº¦å’Œä¸°å¯Œæ€§ã€‚GPT-4è§£ç å™¨å°†è¿™äº›èåˆçš„ç‰¹å¾è½¬åŒ–ä¸ºå‡†ç¡®ä¸”ç›¸å…³çš„æ ‡é¢˜ã€‚è¯¥æ¨¡å‹åœ¨ç¾å›½å›½ç«‹å«ç”Ÿç ”ç©¶é™¢ï¼ˆNIHï¼‰å’Œå°ç¬¬å®‰çº³å¤§å­¦ï¼ˆIUï¼‰çš„èƒ¸éƒ¨Xå°„çº¿æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚åœ¨IUæ•°æ®é›†ä¸Šï¼Œå®ƒå®ç°äº†B-1å¾—åˆ†0.854ã€CIDErå¾—åˆ†0.883ã€METEORå¾—åˆ†0.759å’ŒROUGE-Lå¾—åˆ†0.712ã€‚åœ¨NIHæ•°æ®é›†ä¸Šï¼Œå®ƒåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼šBLEU 1-4ï¼ˆ0.825ã€0.788ã€0.765ã€0.752ï¼‰ï¼ŒCIDErï¼ˆ0.857ï¼‰ï¼ŒMETEORï¼ˆ0.726ï¼‰å’ŒROUGE-Lï¼ˆ0.705ï¼‰ã€‚è¯¥æ¡†æ¶æœ‰æ½œåŠ›å¢å¼ºèƒ¸éƒ¨Xå°„çº¿çš„è¯„ä¼°èƒ½åŠ›ï¼Œå¸®åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®å’Œé«˜æ•ˆçš„è¯Šæ–­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16774v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ–°çš„èƒ¸Xå…‰å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ã€‚è¯¥æ¨¡å‹ç»“åˆäº†Vision Transformerï¼ˆViTï¼‰ç¼–ç å™¨å’ŒåŸºäºGPT-4çš„è½¬æ¢å™¨è§£ç å™¨ï¼Œå¹¶é€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å®ç°å›¾åƒä¸æ–‡æœ¬çš„èåˆã€‚ViTä»èƒ¸Xå…‰å›¾åƒä¸­æå–é«˜è´¨é‡è§†è§‰ç‰¹å¾ï¼Œé€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›ä¸æ–‡æœ¬æ•°æ®èåˆï¼Œæé«˜äº†å›¾åƒæè¿°çš„å‡†ç¡®æ€§ã€ä¸Šä¸‹æ–‡å…³è”æ€§å’Œä¸°å¯Œæ€§ã€‚GPT-4è§£ç å™¨å°†è¿™äº›èåˆçš„ç‰¹å¾è½¬åŒ–ä¸ºå‡†ç¡®ä¸”ç›¸å…³çš„æè¿°ã€‚è¯¥æ¨¡å‹åœ¨å›½ç«‹å«ç”Ÿç ”ç©¶é™¢ï¼ˆNIHï¼‰å’Œå°ç¬¬å®‰çº³å¤§å­¦ï¼ˆIUï¼‰çš„èƒ¸Xå…‰å°„çº¿æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶åœ¨IUæ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„BLEUã€CIDErã€METEORå’ŒROUGE-Lç­‰æŒ‡æ ‡åˆ†æ•°ã€‚åœ¨NIHæ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚è¯¥æ¡†æ¶å…·æœ‰æé«˜èƒ¸Xå…‰è¯„ä»·ï¼ŒååŠ©æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œæ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„è¯Šæ–­çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>èƒ¸Xå…‰å›¾åƒåˆ†æå¯¹äºæ£€æµ‹èƒ¸éƒ¨ç–¾ç—…è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼Œç»“åˆäº†ViTç¼–ç å™¨å’ŒGPT-4è§£ç å™¨ã€‚</li>
<li>ViTç¼–ç å™¨ä»èƒ¸Xå…‰å›¾åƒä¸­æå–è§†è§‰ç‰¹å¾ï¼Œé€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›ä¸æ–‡æœ¬æ•°æ®èåˆã€‚</li>
<li>GPT-4è§£ç å™¨å°†èåˆçš„ç‰¹å¾è½¬åŒ–ä¸ºå‡†ç¡®çš„æè¿°ã€‚</li>
<li>æ¨¡å‹åœ¨NIHå’ŒIUæ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†è‰¯å¥½æˆç»©ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šçš„æ€§èƒ½å‡ä¼˜äºå…ˆå‰çš„ç ”ç©¶ã€‚</li>
<li>è¯¥æ¡†æ¶æœ‰æ½œåŠ›æé«˜èƒ¸Xå…‰çš„è¯„ä¼°æ•ˆç‡ï¼Œè¾…åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œæ›´ç²¾ç¡®çš„è¯Šæ–­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2939bae2037d6e04c7ecacce576d0468.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a673af6a856e82bb9f463302dd0c6f53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-814d6825852c1dcf8309345cd1c24bfa.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SAIP-Net-Enhancing-Remote-Sensing-Image-Segmentation-via-Spectral-Adaptive-Information-Propagation"><a href="#SAIP-Net-Enhancing-Remote-Sensing-Image-Segmentation-via-Spectral-Adaptive-Information-Propagation" class="headerlink" title="SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral   Adaptive Information Propagation"></a>SAIP-Net: Enhancing Remote Sensing Image Segmentation via Spectral   Adaptive Information Propagation</h2><p><strong>Authors:Zhongtao Wang, Xizhe Cao, Yisong Chen, Guoping Wang</strong></p>
<p>Semantic segmentation of remote sensing imagery demands precise spatial boundaries and robust intra-class consistency, challenging conventional hierarchical models. To address limitations arising from spatial domain feature fusion and insufficient receptive fields, this paper introduces SAIP-Net, a novel frequency-aware segmentation framework that leverages Spectral Adaptive Information Propagation. SAIP-Net employs adaptive frequency filtering and multi-scale receptive field enhancement to effectively suppress intra-class feature inconsistencies and sharpen boundary lines. Comprehensive experiments demonstrate significant performance improvements over state-of-the-art methods, highlighting the effectiveness of spectral-adaptive strategies combined with expanded receptive fields for remote sensing image segmentation. </p>
<blockquote>
<p>é¥æ„Ÿå½±åƒçš„è¯­ä¹‰åˆ†å‰²è¦æ±‚ç²¾ç¡®çš„ç©ºé—´è¾¹ç•Œå’Œç¨³å¥çš„ç±»å†…ä¸€è‡´æ€§ï¼Œè¿™æŒ‘æˆ˜äº†ä¼ ç»Ÿçš„åˆ†å±‚æ¨¡å‹ã€‚ä¸ºäº†è§£å†³ç”±ç©ºé—´åŸŸç‰¹å¾èåˆå’Œæ„Ÿå—é‡ä¸è¶³è€Œäº§ç”Ÿçš„å±€é™æ€§ï¼Œæœ¬æ–‡å¼•å…¥äº†SAIP-Netï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å…‰è°±è‡ªé€‚åº”ä¿¡æ¯ä¼ æ’­çš„æ–°å‹é¢‘ç‡æ„ŸçŸ¥åˆ†å‰²æ¡†æ¶ã€‚SAIP-Neté‡‡ç”¨è‡ªé€‚åº”é¢‘ç‡æ»¤æ³¢å’Œå¤šå°ºåº¦æ„Ÿå—é‡å¢å¼ºï¼Œæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†ç±»å†…ç‰¹å¾çš„ä¸ä¸€è‡´æ€§ï¼Œæé«˜äº†è¾¹ç•Œçº¿çš„æ¸…æ™°åº¦ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æœ€æ–°æ–¹æ³•çš„åŸºç¡€ä¸Šæ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼Œçªå‡ºäº†ç»“åˆæ‰©å±•æ„Ÿå—é‡çš„å…‰è°±è‡ªé€‚åº”ç­–ç•¥åœ¨é¥æ„Ÿå›¾åƒåˆ†å‰²ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16564v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºè°±è‡ªé€‚åº”ä¿¡æ¯ä¼ æ’­çš„é¢‘ç‡æ„ŸçŸ¥åˆ†å‰²æ¡†æ¶SAIP-Netï¼Œç”¨äºé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²ã€‚é’ˆå¯¹ç©ºé—´åŸŸç‰¹å¾èåˆå’Œæ„Ÿå—é‡ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç½‘ç»œé‡‡ç”¨è‡ªé€‚åº”é¢‘ç‡æ»¤æ³¢å’Œå¤šå°ºåº¦æ„Ÿå—é‡å¢å¼ºæŠ€æœ¯ï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº†ç±»å†…ç‰¹å¾ä¸ä¸€è‡´æ€§ï¼Œæé«˜äº†è¾¹ç•Œçº¿çš„æ¸…æ™°åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥ç½‘ç»œåœ¨é¥æ„Ÿå›¾åƒåˆ†å‰²æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²éœ€è¦ç²¾ç¡®çš„ç©ºé—´è¾¹ç•Œå’Œç¨³å¥çš„ç±»å†…ä¸€è‡´æ€§ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿå±‚æ¬¡æ¨¡å‹ã€‚</li>
<li>SAIP-Netæ˜¯ä¸€ç§æ–°å‹é¢‘ç‡æ„ŸçŸ¥åˆ†å‰²æ¡†æ¶ï¼Œåˆ©ç”¨è°±è‡ªé€‚åº”ä¿¡æ¯ä¼ æ’­æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>SAIP-Neté€šè¿‡è‡ªé€‚åº”é¢‘ç‡æ»¤æ³¢å’Œå¤šå°ºåº¦æ„Ÿå—é‡å¢å¼ºæŠ€æœ¯ï¼Œæœ‰æ•ˆæé«˜äº†é¥æ„Ÿå›¾åƒåˆ†å‰²çš„æ€§èƒ½ã€‚</li>
<li>è‡ªé€‚åº”é¢‘ç‡æ»¤æ³¢æœ‰åŠ©äºæŠ‘åˆ¶ç±»å†…ç‰¹å¾çš„ä¸ä¸€è‡´æ€§ã€‚</li>
<li>å¤šå°ºåº¦æ„Ÿå—é‡å¢å¼ºå¯ä»¥æ‰©å¤§ç½‘ç»œå¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•è·èƒ½åŠ›ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯†åˆ«è¾¹ç•Œã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSAIP-Netåœ¨é¥æ„Ÿå›¾åƒåˆ†å‰²æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16564">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-405fecb1bfb3eb59ce2c20d8444a38cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84334e8ae0002cf31231c8b89c6aff68.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2e04599d980ba3079900431170f3a1e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ffef3813c40a0c21d339a6e1b01bb0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bda3f5dbd5c3b3948ceb0a4ccdec05e6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8feaa1c1a4c55cc04b4275aac39afcd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Cross-Paradigm-Representation-and-Alignment-Transformer-for-Image-Deraining"><a href="#Cross-Paradigm-Representation-and-Alignment-Transformer-for-Image-Deraining" class="headerlink" title="Cross Paradigm Representation and Alignment Transformer for Image   Deraining"></a>Cross Paradigm Representation and Alignment Transformer for Image   Deraining</h2><p><strong>Authors:Shun Zou, Yi Zou, Juncheng Li, Guangwei Gao, Guojun Qi</strong></p>
<p>Transformer-based networks have achieved strong performance in low-level vision tasks like image deraining by utilizing spatial or channel-wise self-attention. However, irregular rain patterns and complex geometric overlaps challenge single-paradigm architectures, necessitating a unified framework to integrate complementary global-local and spatial-channel representations. To address this, we propose a novel Cross Paradigm Representation and Alignment Transformer (CPRAformer). Its core idea is the hierarchical representation and alignment, leveraging the strengths of both paradigms (spatial-channel and global-local) to aid image reconstruction. It bridges the gap within and between paradigms, aligning and coordinating them to enable deep interaction and fusion of features. Specifically, we use two types of self-attention in the Transformer blocks: sparse prompt channel self-attention (SPC-SA) and spatial pixel refinement self-attention (SPR-SA). SPC-SA enhances global channel dependencies through dynamic sparsity, while SPR-SA focuses on spatial rain distribution and fine-grained texture recovery. To address the feature misalignment and knowledge differences between them, we introduce the Adaptive Alignment Frequency Module (AAFM), which aligns and interacts with features in a two-stage progressive manner, enabling adaptive guidance and complementarity. This reduces the information gap within and between paradigms. Through this unified cross-paradigm dynamic interaction framework, we achieve the extraction of the most valuable interactive fusion information from the two paradigms. Extensive experiments demonstrate that our model achieves state-of-the-art performance on eight benchmark datasets and further validates CPRAformerâ€™s robustness in other image restoration tasks and downstream applications. </p>
<blockquote>
<p>åŸºäºTransformerçš„ç½‘ç»œé€šè¿‡åˆ©ç”¨ç©ºé—´æˆ–é€šé“çº§çš„è‡ªæ³¨æ„åŠ›åœ¨ä½çº§åˆ«è§†è§‰ä»»åŠ¡ï¼ˆå¦‚å›¾åƒå»é›¨ï¼‰ä¸­å–å¾—äº†å¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œä¸è§„åˆ™çš„é›¨å‹å’Œå¤æ‚çš„å‡ ä½•é‡å å¯¹å•ä¸€èŒƒå¼æ¶æ„æå‡ºäº†æŒ‘æˆ˜ï¼Œéœ€è¦ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶æ¥æ•´åˆäº’è¡¥çš„å…¨å±€-å±€éƒ¨å’Œç©ºé—´-é€šé“è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è·¨èŒƒå¼è¡¨ç¤ºå’Œå¯¹é½Transformerï¼ˆCPRAformerï¼‰ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ†å±‚è¡¨ç¤ºå’Œå¯¹é½ï¼Œåˆ©ç”¨ä¸¤ç§èŒƒå¼ï¼ˆç©ºé—´é€šé“å’Œå…¨å±€å±€éƒ¨ï¼‰çš„ä¼˜åŠ¿æ¥è¾…åŠ©å›¾åƒé‡å»ºã€‚å®ƒå¼¥åˆäº†èŒƒå¼å†…éƒ¨å’Œä¹‹é—´çš„é¸¿æ²Ÿï¼Œå¯¹é½å¹¶åè°ƒå®ƒä»¬ï¼Œä»¥å®ç°ç‰¹å¾çš„æ·±åº¦äº¤äº’å’Œèåˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨Transformerå—ä¸­ä½¿ç”¨äº†ä¸¤ç§ç±»å‹çš„è‡ªæ³¨æ„åŠ›ï¼šç¨€ç–æç¤ºé€šé“è‡ªæ³¨æ„åŠ›ï¼ˆSPC-SAï¼‰å’Œç©ºé—´åƒç´ ç»†åŒ–è‡ªæ³¨æ„åŠ›ï¼ˆSPR-SAï¼‰ã€‚SPC-SAé€šè¿‡åŠ¨æ€ç¨€ç–æ€§å¢å¼ºå…¨å±€é€šé“ä¾èµ–æ€§ï¼Œè€ŒSPR-SAä¸“æ³¨äºç©ºé—´é›¨åˆ†å¸ƒå’Œç»†ç²’åº¦çº¹ç†æ¢å¤ã€‚ä¸ºäº†è§£å†³ç‰¹å¾ä¸å¯¹é½å’Œä»–ä»¬ä¹‹é—´çŸ¥è¯†å·®å¼‚çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†è‡ªé€‚åº”å¯¹é½é¢‘ç‡æ¨¡å—ï¼ˆAAFMï¼‰ï¼Œä»¥ä¸¤é˜¶æ®µæ¸è¿›çš„æ–¹å¼ä¸ç‰¹å¾å¯¹é½å’Œäº¤äº’ï¼Œå®ç°è‡ªé€‚åº”æŒ‡å¯¼å’Œäº’è¡¥æ€§ã€‚è¿™å‡å°‘äº†èŒƒå¼å†…éƒ¨å’Œä¹‹é—´çš„ä¿¡æ¯é¸¿æ²Ÿã€‚é€šè¿‡è¿™ä¸ªç»Ÿä¸€çš„è·¨èŒƒå¼åŠ¨æ€äº¤äº’æ¡†æ¶ï¼Œæˆ‘ä»¬ä»ä¸¤ä¸ªèŒƒå¼ä¸­æå–äº†æœ€æœ‰ä»·å€¼çš„äº¤äº’å¼èåˆä¿¡æ¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å…«ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶è¿›ä¸€æ­¥éªŒè¯äº†CPRAformeråœ¨å…¶ä»–å›¾åƒæ¢å¤ä»»åŠ¡å’Œä¸‹æ¸¸åº”ç”¨ä¸­çš„ç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16455v1">PDF</a> code: <a target="_blank" rel="noopener" href="https://github.com/zs1314/CPRAformer">https://github.com/zs1314/CPRAformer</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„è·¨èŒƒå¼è¡¨ç¤ºä¸å¯¹é½Transformerï¼ˆCPRAformerï¼‰ï¼Œç”¨äºè§£å†³å›¾åƒå»é›¨ç­‰ä½çº§åˆ«è§†è§‰ä»»åŠ¡ä¸­çš„æŒ‘æˆ˜ã€‚CPRAformerèåˆäº†å…¨å±€-å±€éƒ¨å’Œç©ºé—´-é€šé“ä¸¤ç§äº’è¡¥è¡¨ç¤ºï¼Œé€šè¿‡å±‚æ¬¡è¡¨ç¤ºä¸å¯¹é½æŠ€æœ¯ï¼Œå®ç°äº†è·¨èŒƒå¼åŠ¨æ€äº¤äº’ã€‚ä½¿ç”¨ä¸¤ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œæé«˜äº†ç‰¹å¾æå–å’Œèåˆçš„æ•ˆæœã€‚å®éªŒè¯æ˜ï¼ŒCPRAformeråœ¨å…«ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œå¹¶åœ¨å…¶ä»–å›¾åƒæ¢å¤ä»»åŠ¡å’Œä¸‹æ¸¸åº”ç”¨ä¸­éªŒè¯äº†å…¶ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformerç½‘ç»œåœ¨å›¾åƒå»é›¨ç­‰ä½çº§åˆ«è§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºæ€§èƒ½ï¼Œä½†é¢ä¸´ä¸è§„åˆ™é›¨å‹å’Œå¤æ‚å‡ ä½•é‡å çš„æŒ‘æˆ˜ã€‚</li>
<li>å•ä¸€èŒƒå¼æ¶æ„æ— æ³•åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œéœ€è¦æ•´åˆå…¨å±€-å±€éƒ¨å’Œç©ºé—´-é€šé“è¡¨ç¤ºçš„ç»Ÿä¸€æ¡†æ¶ã€‚</li>
<li>CPRAformeræå‡ºå±‚æ¬¡è¡¨ç¤ºä¸å¯¹é½æŠ€æœ¯ï¼Œç»“åˆä¸¤ç§èŒƒå¼çš„ä¼˜ç‚¹ï¼Œæé«˜å›¾åƒé‡å»ºæ•ˆæœã€‚</li>
<li>CPRAformerä½¿ç”¨ä¸¤ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼šç¨€ç–æç¤ºé€šé“è‡ªæ³¨æ„åŠ›ï¼ˆSPC-SAï¼‰å’Œç©ºé—´åƒç´ ç»†åŒ–è‡ªæ³¨æ„åŠ›ï¼ˆSPR-SAï¼‰ï¼Œåˆ†åˆ«å¢å¼ºé€šé“ä¾èµ–æ€§å’Œç©ºé—´é›¨åˆ†å¸ƒçš„æ¢å¤ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”å¯¹é½é¢‘ç‡æ¨¡å—ï¼ˆAAFMï¼‰ï¼Œå®ç°ç‰¹å¾å¯¹é½å’Œäº¤äº’ï¼Œç¼©å°èŒƒå¼å†…çš„ä¿¡æ¯å·®è·ã€‚</li>
<li>CPRAformeråœ¨å…«ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—æœ€ä½³æ€§èƒ½ï¼Œè¯æ˜äº†å…¶è·¨èŒƒå¼çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16455">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2de2ab782bb738a685dc213474d3390b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-77d75a25a5c277abaab4aceb7dbacb56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e1f92a401699402185e6d3c695f5226.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50b0e9a17dc99780626b3e3f4663106e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ef003fae5859520b5248f232e38f619.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3cd9bf294eaa41f078fc87c0d80c305a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Evolution-of-QPO-during-Rising-Phase-of-Discovery-Outburst-of-Swift-J1727-8-1613-Estimation-of-Mass-from-Spectro-Temporal-Study"><a href="#Evolution-of-QPO-during-Rising-Phase-of-Discovery-Outburst-of-Swift-J1727-8-1613-Estimation-of-Mass-from-Spectro-Temporal-Study" class="headerlink" title="Evolution of QPO during Rising Phase of Discovery Outburst of Swift   J1727.8-1613: Estimation of Mass from Spectro-Temporal Study"></a>Evolution of QPO during Rising Phase of Discovery Outburst of Swift   J1727.8-1613: Estimation of Mass from Spectro-Temporal Study</h2><p><strong>Authors:Dipak Debnath, Hsiang-Kuang Chang, Sujoy Kumar Nath, Lev Titarchuk</strong></p>
<p>The rising phase of the 2023-24 outburst of the recently discovered bright transient black hole candidate Swift J1727.8-1613 was monitored by \textit{Insight}-HXMT. We study the evolution of hard ($4$-$150$ keV) and soft ($2$-$4$ keV) band photon count rates, the hardness ratio (HR), and QPO frequencies using daily observations from the HXMT&#x2F;LE, ME, and HE instruments between August 25 and October 5, 2023. The QPO frequency is found to be strongly correlated with the soft-band X-ray count rates, and spectral photon indices. In contrast, a strong anti-correlation is observed between HR and QPO frequency, as well as between HR and photon index. Based on the evolution of the QPO frequency, the rising phase of the outburst is subdivided into six parts, with parts 1-5 fitted using the propagating oscillatory shock (POS) solution to understand the nature of the evolution from a physical perspective. The best-fitted POS model is obtained with a black hole mass of $13.34\pm0.02<del>M_\odot$. An inward-propagating shock with weakening strength (except in part 4) is observed during the period of our study. The POS model-fitted mass of the source is further confirmed using the QPO frequency ($\nu$)-photon index ($\Gamma$) scaling method. From this method, the estimated probable mass of Swift J1727.8-1613 is obtained to be $13.54\pm1.87</del>M_\odot$. </p>
<blockquote>
<p>æ´å¯Ÿå·HXMTç›‘æµ‹äº†æœ€è¿‘å‘ç°çš„æ˜äº®ç¬æ€é»‘æ´å€™é€‰ä½“Swift J1727.8-1613åœ¨2023-24å¹´çˆ†å‘æœŸçš„ä¸Šå‡é˜¶æ®µã€‚æˆ‘ä»¬ç ”ç©¶äº†ç¡¬åº¦æ¯”ä¸ºHRä»¥åŠQPOé¢‘ç‡çš„å˜åŒ–æƒ…å†µã€‚è¿™äº›ç ”ç©¶åŸºäºHXMT&#x2F;LEã€MEå’ŒHEä»ªå™¨åœ¨2023å¹´8æœˆ25æ—¥è‡³10æœˆ5æ—¥ä¹‹é—´çš„æ¯æ—¥è§‚æµ‹æ•°æ®ï¼Œæ¶‰åŠç¡¬æ³¢æ®µï¼ˆ4-150åƒç”µå­ä¼ï¼‰å’Œè½¯æ³¢æ®µï¼ˆ2-4åƒç”µå­ä¼ï¼‰å…‰å­è®¡æ•°ç‡çš„æ¼”åŒ–ã€‚æˆ‘ä»¬å‘ç°QPOé¢‘ç‡ä¸è½¯æ³¢æ®µXå°„çº¿è®¡æ•°ç‡å’Œå…‰è°±å…‰å­æŒ‡æ•°ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸å…³æ€§ã€‚ç›¸åï¼ŒHRä¸QPOé¢‘ç‡å’Œå…‰å­æŒ‡æ•°ä¹‹é—´åˆ™æ˜¾ç¤ºå‡ºå¼ºçƒˆçš„åç›¸å…³æ€§ã€‚åŸºäºQPOé¢‘ç‡çš„æ¼”åŒ–ï¼Œçˆ†å‘çš„ä¸Šå‡é˜¶æ®µè¢«åˆ†ä¸ºå…­ä¸ªéƒ¨åˆ†ï¼Œå…¶ä¸­ç¬¬1è‡³ç¬¬5éƒ¨åˆ†ä½¿ç”¨ä¼ æ’­æŒ¯è¡å†²å‡»ï¼ˆPOSï¼‰è§£å†³æ–¹æ¡ˆè¿›è¡Œæ‹Ÿåˆï¼Œä»¥ä»ç‰©ç†è§’åº¦äº†è§£æ¼”åŒ–çš„æ€§è´¨ã€‚ä½¿ç”¨POSæ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆé»‘æ´è´¨é‡ä¸º13.34Â±0.02å¤ªé˜³è´¨é‡ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶æœŸé—´è§‚å¯Ÿåˆ°å‘å†…ä¼ æ’­çš„å†²å‡»æ³¢å¼ºåº¦å‡å¼±ï¼ˆé™¤ç¬¬4éƒ¨åˆ†å¤–ï¼‰ã€‚ä½¿ç”¨QPOé¢‘ç‡ï¼ˆÎ½ï¼‰-å…‰å­æŒ‡æ•°ï¼ˆÎ“ï¼‰æ ‡åº¦æ–¹æ³•è¿›ä¸€æ­¥è¯å®äº†æºå¤´çš„POSæ¨¡å‹æ‹Ÿåˆè´¨é‡ã€‚ç”±æ­¤ä¼°è®¡ï¼ŒSwift J1727.8-1613çš„å¯èƒ½è´¨é‡ä¸º13.54Â±1.87å¤ªé˜³è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16391v1">PDF</a> 11 Pages, 4 Figures, 1 Table (In-communication to ApJ)</p>
<p><strong>Summary</strong><br>     åŸºäºInsight-HXMTçš„è§‚æµ‹ï¼Œå‘ç°2023å¹´è‡³2024å¹´çŸ­æš‚çˆ†å‘ä¸­Sw J1727.8-1613ç¡¬å’Œè½¯å…‰å­è®¡æ•°ç‡çš„æ¼”åŒ–ç‰¹ç‚¹åŠå…¶å˜åŒ–ç‰¹å¾ã€‚å‘ç°QPOé¢‘ç‡ä¸è½¯æ³¢æ®µXå°„çº¿è®¡æ•°ç‡å’Œå…‰å­æŒ‡æ•°å­˜åœ¨å¼ºç›¸å…³æ€§ï¼Œè€Œç¡¬åº¦æ¯”ä¸QPOé¢‘ç‡å’Œå…‰å­æŒ‡æ•°ä¹‹é—´å­˜åœ¨å¼ºåç›¸å…³å…³ç³»ã€‚åŸºäºQPOé¢‘ç‡æ¼”åŒ–ï¼Œçˆ†å‘ä¸Šå‡é˜¶æ®µå¯åˆ†ä¸ºå…­éƒ¨åˆ†ï¼Œå…¶ä¸­éƒ¨åˆ†é˜¶æ®µé‡‡ç”¨ä¼ æ’­æŒ¯è¡å†²å‡»ï¼ˆPOSï¼‰è§£å†³æ–¹æ¡ˆè¿›è¡Œæ‹Ÿåˆåˆ†æã€‚é€šè¿‡POSæ¨¡å‹ä¼°è®¡æºè´¨é‡çº¦ä¸º$13.34\pm0.02M_\odot$ï¼Œå¹¶é€šè¿‡QPOé¢‘ç‡ä¸å…‰å­æŒ‡æ•°å…³è”å¾—åˆ°éªŒè¯ã€‚ä¼°ç®—Sw J1727.8-1613çš„å¯èƒ½è´¨é‡å¤§çº¦ä¸º$13.54\pm1.87M_\odot$ã€‚ç»“æœå¯¹äºç†è§£ç¬æ€é»‘æ´å€™é€‰ç‰©çš„æ€§è´¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Insight-HXMTç›‘æµ‹äº†Swift J1727.8-1613é»‘æ´å€™é€‰ä½“çš„çˆ†å‘è¿‡ç¨‹ã€‚</li>
<li>ç¡¬æ³¢æ®µå’Œè½¯æ³¢æ®µå…‰å­è®¡æ•°ç‡éšè§‚æµ‹æ—¶é—´å˜åŒ–è€Œå˜åŒ–ã€‚</li>
<li>QPOé¢‘ç‡ä¸è½¯æ³¢æ®µXå°„çº¿è®¡æ•°ç‡å’Œå…‰å­æŒ‡æ•°å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚</li>
<li>HRä¸QPOé¢‘ç‡å’Œå…‰å­æŒ‡æ•°ä¹‹é—´å­˜åœ¨åç›¸å…³å…³ç³»ã€‚</li>
<li>åŸºäºQPOé¢‘ç‡æ¼”åŒ–ï¼Œçˆ†å‘ä¸Šå‡é˜¶æ®µå¯åˆ†ä¸ºå…­ä¸ªéƒ¨åˆ†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16391">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9068121d6ebf4b4ba5512d5baeff4b00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee5a5f4afc77f1bbb667af8daf287f3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e3a438789c6273b43244b85ed5b26fe.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Environmental-Dependence-of-X-Ray-Emission-From-The-Least-Massive-Galaxies"><a href="#Environmental-Dependence-of-X-Ray-Emission-From-The-Least-Massive-Galaxies" class="headerlink" title="Environmental Dependence of X-Ray Emission From The Least Massive   Galaxies"></a>Environmental Dependence of X-Ray Emission From The Least Massive   Galaxies</h2><p><strong>Authors:Marko MiÄ‡iÄ‡, Xinyu Dai, Nick Shumate, Khoa Nguyen Tran, Heechan Yuk</strong></p>
<p>The low-mass end of low-mass galaxies is largely unexplored in AGN studies, but it is essential for extending our understanding of the black hole-galaxy coevolution. We surveyed the 3D-HST catalog and collected a sample of 546 dwarf galaxies with stellar masses log(M$<em>*$&#x2F;(M_\odot))$&lt;$8.7, residing in the GOODS-South deep field. We then used the unprecedented depth of Chandra available in the GOODS-South field to search for AGN. We carefully investigated the factors that could play roles in the AGN detectability, such as Chandraâ€™s point-spread function and the redshift- and off-axis-dependent detection limits. We identified 16 X-ray sources that are likely associated with AGN activity. Next, we evaluated the environment density of each galaxy by computing tidal indices. We uncovered a dramatic impact of the environment on AGN triggering as dwarfs from high-density environments showed an AGN fraction of 22.5%, while the median stellar mass of this subset of dwarfs is only log(M$</em>*$&#x2F;(M_\odot))&#x3D;8.1. In contrast, the low-density environment dwarfs showed an AGN fraction of only 1.4%, in line with typically reported values from the literature. This highlights the fact that massive central black holes are ubiquitous even at the lowest mass scales and demonstrates the importance of the environment in triggering black hole accretion, as well as the necessity for deep X-ray data and proper evaluation of the X-ray data quality. Alternatively, even if the detected X-ray sources are related to stellar mass accretors rather than AGN, the environmental dependence persists, signaling the impact of the environment on galaxy evolution and star formation processes at the lowest mass scales. Additionally, we stacked the X-ray images of non-detected galaxies from high- and low-density environments, revealing similar trends. </p>
<blockquote>
<p>åœ¨å¤©æ–‡ç ”ç©¶é¢†åŸŸä¸­ï¼Œå¯¹äºä½è´¨é‡æ˜Ÿç³»çš„å°è´¨é‡ç«¯éƒ¨åˆ†çš„ç ”ç©¶å°šå¤„äºæœªå¼€å‘çŠ¶æ€ï¼Œä½†æ˜¯ä¸ºäº†æ·±å…¥äº†è§£é»‘æ´ä¸æ˜Ÿç³»çš„å…±æ¼”åŒ–è¿‡ç¨‹ï¼Œè¿™éƒ¨åˆ†ç ”ç©¶æ˜¯è‡³å…³é‡è¦çš„ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†3D-HSTç›®å½•ï¼Œæ”¶é›†äº†ä¸€ä¸ªæ ·æœ¬ï¼Œå…¶ä¸­åŒ…æ‹¬å±…ä½åœ¨GOODS-Southæ·±åœºçš„546ä¸ªæ’æ˜Ÿè´¨é‡ä¸ºlog(M*_*&#x2F;MâŠ™)&lt;8.7çš„çŸ®æ˜Ÿç³»ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨GOODS-SouthåŒºåŸŸä¸­å‰æ‰€æœªæœ‰çš„æ·±åº¦è§‚å¯Ÿæ¥å¯»æ‰¾æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆActive Galactic Nucleusï¼Œç®€ç§°AGNsï¼‰ã€‚æˆ‘ä»¬ä»”ç»†ç ”ç©¶äº†å¯èƒ½å½±å“æ´»åŠ¨æ˜Ÿç³»æ ¸æ¢æµ‹çš„å› ç´ ï¼Œå¦‚é’±å¾·æ‹‰æœ›è¿œé•œçš„ç‚¹æ‰©æ•£å‡½æ•°ä»¥åŠçº¢ç§»å’Œç¦»è½´è·ç¦»ç›¸å…³çš„æ£€æµ‹æé™ã€‚æˆ‘ä»¬ç¡®å®šäº†å¯èƒ½ä¸æ´»åŠ¨æ˜Ÿç³»æ ¸æ´»åŠ¨ç›¸å…³çš„16ä¸ªXå°„çº¿æºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡è®¡ç®—æ½®æ±æŒ‡æ•°æ¥è¯„ä¼°æ¯ä¸ªæ˜Ÿç³»çš„ç¯å¢ƒå¯†åº¦ã€‚æˆ‘ä»¬å‘ç°ç¯å¢ƒå¯¹è§¦å‘æ´»åŠ¨æ˜Ÿç³»æ ¸çš„å½±å“éå¸¸æ˜¾è‘—ï¼Œå› ä¸ºæ¥è‡ªé«˜å¯†åº¦çš„çŸ®æ˜Ÿç³»è¡¨ç°å‡ºé«˜è¾¾22.5%çš„æ´»åŠ¨æ˜Ÿç³»æ ¸æ¯”ä¾‹ï¼Œè€Œè¿™ä¸€çŸ®æ˜Ÿç³»å­é›†çš„ä¸­ç­‰æ’æ˜Ÿè´¨é‡ä»…ä¸ºlog(M*_*&#x2F;MâŠ™)&#x3D;8.1ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä½å¯†åº¦ç¯å¢ƒä¸­çš„çŸ®æ˜Ÿç³»ä»…æ˜¾ç¤ºå‡º1.4%çš„æ´»åŠ¨æ˜Ÿç³»æ ¸æ¯”ä¾‹ï¼Œè¿™ä¸æ–‡çŒ®ä¸­é€šå¸¸æŠ¥é“çš„å€¼ç›¸ç¬¦ã€‚è¿™å¼ºè°ƒäº†å³ä½¿åœ¨æœ€ä½è´¨é‡å°ºåº¦ä¸Šï¼Œå·¨å¤§çš„ä¸­å¿ƒé»‘æ´ä¹Ÿæ˜¯æ™®éå­˜åœ¨çš„ï¼Œå¹¶è¯æ˜äº†ç¯å¢ƒåœ¨è§¦å‘é»‘æ´å¸ç§¯ä¸­çš„é‡è¦æ€§ï¼Œä»¥åŠæ·±åº¦Xå°„çº¿æ•°æ®å’Œæ­£ç¡®è¯„ä¼°Xå°„çº¿æ•°æ®è´¨é‡çš„é‡è¦æ€§ã€‚å³ä½¿æ£€æµ‹åˆ°çš„Xå°„çº¿æºä¸æ’æ˜Ÿè´¨é‡å¸ç§¯ä½“æœ‰å…³è€Œéæ´»åŠ¨æ˜Ÿç³»æ ¸ï¼Œç¯å¢ƒçš„ä¾èµ–æ€§ä»ç„¶å­˜åœ¨ï¼Œè¿™é¢„ç¤ºç€ç¯å¢ƒå¯¹æœ€ä½è´¨é‡å°ºåº¦ä¸Šçš„æ˜Ÿç³»æ¼”åŒ–åŠæ’æ˜Ÿå½¢æˆè¿‡ç¨‹çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å åŠ äº†é«˜å¯†åº¦å’Œä½å¯†åº¦ç¯å¢ƒä¸­æœªæ£€æµ‹åˆ°Xå°„çº¿çš„æ˜Ÿç³»å›¾åƒï¼Œæ˜¾ç¤ºå‡ºç›¸ä¼¼çš„è¶‹åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16285v1">PDF</a> Six pages, eight figures. Submitted to MNRAS. Comments are welcome</p>
<p><strong>Summary</strong></p>
<p>åœ¨æ·±å…¥ç ”ç©¶ä½è´¨é‡æ˜Ÿç³»ä½è´¨é‡ç«¯å¯¹æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆAGNï¼‰çš„ç†è§£æ—¶ï¼Œæˆ‘ä»¬å¯¹GOODS-Southæ·±åœºçš„çŸ®æ˜Ÿç³»è¿›è¡Œäº†è°ƒæŸ¥ã€‚ç»“åˆå…ˆè¿›æ·±åº¦çš„Chandraæ•°æ®æœç´¢ç›¸å…³æ˜Ÿç³»æ ¸ï¼Œå¹¶å¯¹æ¢æµ‹å½±å“å› ç´ è¿›è¡Œäº†ç ”ç©¶ã€‚ç»“æœè¡¨æ˜ï¼Œç¯å¢ƒå¯†åº¦æ˜¾è‘—å½±å“æ˜Ÿç³»æ ¸æ´»åŠ¨è§¦å‘ï¼Œé«˜å¯†åº¦ç¯å¢ƒä¸‹çš„çŸ®æ˜Ÿç³»è¡¨ç°å‡ºæ›´é«˜çš„æ˜Ÿç³»æ ¸æ´»åŠ¨ç‡ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†ç¯å¢ƒåœ¨è§¦å‘é»‘æ´å¸ç§¯è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ï¼Œå¹¶å‡¸æ˜¾å‡ºæ·±å…¥Xå°„çº¿æ•°æ®å’Œæ­£ç¡®è¯„ä¼°å…¶è´¨é‡çš„é‡è¦æ€§ã€‚æ— è®ºXå°„çº¿æºæ˜¯å¦ä¸æ’æ˜Ÿè´¨é‡å¸ç§¯æœ‰å…³ï¼Œç¯å¢ƒå¯¹æœ€ä½è´¨é‡å°ºåº¦ä¸Šçš„æ˜Ÿç³»æ¼”åŒ–å’Œæ’æ˜Ÿå½¢æˆè¿‡ç¨‹çš„å½±å“éƒ½æ˜¯æ˜¾è‘—çš„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä½è´¨é‡æ˜Ÿç³»çš„ä½è´¨é‡ç«¯å¯¹äºç†è§£é»‘æ´ä¸æ˜Ÿç³»çš„ååŒæ¼”åŒ–è‡³å…³é‡è¦ã€‚</li>
<li>åˆ©ç”¨3D-HSTç›®å½•æ”¶é›†äº†GOODS-Southæ·±åœºçš„546ä¸ªçŸ®æ˜Ÿç³»æ ·æœ¬ã€‚</li>
<li>é€šè¿‡æ·±å…¥çš„Chandraæ•°æ®å¯»æ‰¾ç›¸å…³æ˜Ÿç³»æ ¸æ´»åŠ¨ã€‚</li>
<li>æ¢æµ‹å› ç´ åŒ…æ‹¬Chandraçš„ç‚¹æ‰©æ•£å‡½æ•°å’Œä¸çº¢ç§»åŠç¦»è½´è·ç¦»ç›¸å…³çš„æ£€æµ‹é™åˆ¶ã€‚</li>
<li>é«˜å¯†åº¦ç¯å¢ƒä¸‹çš„çŸ®æ˜Ÿç³»è¡¨ç°å‡ºæ›´é«˜çš„æ˜Ÿç³»æ ¸æ´»åŠ¨ç‡ï¼ˆ22.5%ï¼‰ï¼Œè€Œä½å¯†åº¦çš„ç¯å¢ƒåˆ™è¡¨ç°å‡ºè¾ƒä½çš„æ´»åŠ¨ç‡ï¼ˆä»…1.4%ï¼‰ã€‚</li>
<li>ç¯å¢ƒåœ¨è§¦å‘é»‘æ´å¸ç§¯è¿‡ç¨‹ä¸­çš„ä½œç”¨æ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16285">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3d4b060320f837120404dea312c72de5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-43116246431db7456aa88900538d71b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65bcee06e53634eb53925b97bf8b29ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-660eea652fdf205e544b41df256985c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19a988551ec57aded247342e58310cd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4044e470ae22723b149520d9cdfbf1fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63ff47686940458a847f8e415a5326b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2b20bcd88de8b6eead365b8f4b5cdfb.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multiobjective-optimization-for-scattering-mitigation-and-scattering-screen-reconstruction-in-VLBI-observations-of-the-Galactic-Center"><a href="#Multiobjective-optimization-for-scattering-mitigation-and-scattering-screen-reconstruction-in-VLBI-observations-of-the-Galactic-Center" class="headerlink" title="Multiobjective optimization for scattering mitigation and scattering   screen reconstruction in VLBI observations of the Galactic Center"></a>Multiobjective optimization for scattering mitigation and scattering   screen reconstruction in VLBI observations of the Galactic Center</h2><p><strong>Authors:Alejandro Mus, Teresa Toscano, Hendrik MÃ¼ller, Guang-Yao Zhao, Andrei Lobanov, Ciriaco Goddi</strong></p>
<p>Imaging reconstruction of interferometric data is a hard ill-posed inverse problem. Its difficulty is increased when observing the Galactic Center, which is obscured by a scattering screen. This is because the scattering breaks the one-to-one correspondence between images and visibilities. Solving the scattering problem is one of the biggest challenges in radio imaging of the Galactic Center. In this work we present a novel strategy to mitigate its effect and constrain the screen itself using multiobjective optimization. We exploit the potential of evolutionary algorithms to describe the optimization landscape to recover the intrinsic source structure and the scattering screen affecting the data. We successfully recover both the screen and the source in a wide range of simulated cases, including the speed of a moving screen at 230 GHz. Particularly, we can recover a ring structure in scattered data at 86 GHz. Our analysis demonstrates the huge potential that recent advancements in imaging and optimization algorithms offer to recover image structures, even in weakly constrained and degenerated, possibly multi-modal settings. The successful reconstruction of the scattering screen opens the window to event horizon scale works on the Galactic Center at 86G Hz up to 116 GHz, and the study of the scattering screen itself. </p>
<blockquote>
<p>æˆåƒé‡å»ºå¹²æ¶‰æ•°æ®æ˜¯ä¸€ä¸ªéš¾ä»¥è§£å†³çš„é€†å‘é—®é¢˜ã€‚å½“è§‚æµ‹é“¶æ²³ä¸­å¿ƒæ—¶ï¼Œéš¾åº¦ä¼šå¢åŠ ï¼Œå› ä¸ºé“¶æ²³ä¸­å¿ƒè¢«ä¸€ä¸ªæ•£å°„å±é®è”½ã€‚è¿™æ˜¯å› ä¸ºæ•£å°„ç ´åäº†å›¾åƒå’Œå¯è§åº¦ä¹‹é—´çš„ä¸€ä¸€å¯¹åº”å…³ç³»ã€‚è§£å†³æ•£å°„é—®é¢˜æ˜¯é“¶æ²³ä¸­å¿ƒå°„ç”µæˆåƒé¢ä¸´çš„æœ€å¤§æŒ‘æˆ˜ä¹‹ä¸€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç­–ç•¥æ¥ç¼“è§£å…¶å½±å“ï¼Œå¹¶ä½¿ç”¨å¤šç›®æ ‡ä¼˜åŒ–æ¥çº¦æŸå±å¹•æœ¬èº«ã€‚æˆ‘ä»¬åˆ©ç”¨è¿›åŒ–ç®—æ³•æè¿°ä¼˜åŒ–æ™¯è§‚çš„æ½œåŠ›ï¼Œä»¥æ¢å¤å†…åœ¨æºç»“æ„å’Œå½±å“æ•°æ®çš„æ•£å°„å±ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›çš„æ¨¡æ‹Ÿæ¡ˆä¾‹ä¸­æˆåŠŸåœ°æ¢å¤äº†å±å¹•å’Œæºï¼ŒåŒ…æ‹¬ç§»åŠ¨å±å¹•çš„é€Ÿåº¦åœ¨230 GHzæ—¶çš„æƒ…å†µã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ•£å°„æ•°æ®ä¸­æ¢å¤ç¯å½¢ç»“æ„ï¼Œé¢‘ç‡ä¸º86 GHzã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæˆåƒå’Œä¼˜åŒ–ç®—æ³•çš„æœ€æ–°è¿›å±•åœ¨æ¢å¤å›¾åƒç»“æ„æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå³ä½¿åœ¨å¼±çº¦æŸå’Œé€€åŒ–ã€å¯èƒ½æ˜¯å¤šæ¨¡å¼è®¾ç½®çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆåŠŸé‡å»ºæ•£å°„å±ä¸ºåœ¨86 GHzè‡³116 GHzä¸Šå¯¹é“¶æ²³ä¸­å¿ƒçš„äº‹ä»¶è§†ç•Œè§„æ¨¡è¿›è¡Œç ”ç©¶æ‰“å¼€äº†çª—å£ï¼Œä»¥åŠç ”ç©¶æ•£å°„å±æœ¬èº«ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16257v1">PDF</a> To appear in A&amp;A</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹ç­–ç•¥ï¼Œåˆ©ç”¨å¤šç›®æ ‡ä¼˜åŒ–è§£å†³å¹²æ¶‰æ•°æ®æˆåƒçš„é€†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è§‚æµ‹é“¶æ²³ç³»ä¸­å¿ƒæ—¶é‡åˆ°çš„æ•£å°„å±é—®é¢˜ã€‚é€šè¿‡è¿›åŒ–ç®—æ³•æè¿°ä¼˜åŒ–æ™¯è§‚ï¼Œæ¢å¤å½±å“æ•°æ®çš„å›ºæœ‰æºç»“æ„å’Œæ•£å°„å±ã€‚åœ¨æ¨¡æ‹Ÿæ¡ˆä¾‹ä¸­æˆåŠŸæ¢å¤äº†å±å¹•å’Œæºï¼ŒåŒ…æ‹¬ç§»åŠ¨å±å¹•çš„é€Ÿåº¦ã€‚å¯¹æ•£å°„æ•°æ®çš„ç¯å½¢ç»“æ„çš„æ¢å¤æ˜¾ç¤ºäº†åœ¨å›¾åƒå’Œä¼˜åŒ–ç®—æ³•æ–¹é¢çš„æœ€æ–°è¿›å±•åœ¨æ¢å¤å›¾åƒç»“æ„æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œå³ä½¿åœ¨æœ€å¼±çš„çº¦æŸå’Œé€€åŒ–çš„å¤šæ¨¡æ€è®¾ç½®ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆåŠŸé‡å»ºæ•£å°„å±ä¸ºåœ¨86Gè‡³116åƒå…†èµ«é¢‘ç‡ä¸Šå¯¹é“¶æ²³ç³»ä¸­å¿ƒçš„äº‹ä»¶è§†ç•Œè§„æ¨¡å·¥ä½œæ‰“å¼€äº†çª—å£ï¼Œå¹¶å¯¹æ•£å°„å±æœ¬èº«è¿›è¡Œäº†ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¹²æ¶‰æ•°æ®æˆåƒæ˜¯ä¸€ä¸ªå›°éš¾çš„é€†é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨è§‚æµ‹é“¶æ²³ç³»ä¸­å¿ƒæ—¶ã€‚</li>
<li>æ•£å°„å±çš„å­˜åœ¨æ‰“ç ´äº†å›¾åƒä¸å¯è§åº¦ä¹‹é—´çš„ä¸€ä¸€å¯¹åº”å…³ç³»ï¼Œå¢åŠ äº†é—®é¢˜çš„éš¾åº¦ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤šç›®æ ‡ä¼˜åŒ–ç­–ç•¥æ¥è§£å†³æ•£å°„é—®é¢˜çš„æ–°æ–¹æ³•ã€‚</li>
<li>è¿›åŒ–ç®—æ³•è¢«ç”¨æ¥æè¿°ä¼˜åŒ–æ™¯è§‚ï¼Œä»¥æ¢å¤å›ºæœ‰æºç»“æ„å’Œå½±å“æ•°æ®çš„æ•£å°„å±ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿæ¡ˆä¾‹ä¸­æˆåŠŸæ¢å¤äº†å±å¹•å’Œæºï¼ŒåŒ…æ‹¬ç§»åŠ¨å±å¹•çš„é€Ÿåº¦ã€‚</li>
<li>èƒ½å¤Ÿæ¢å¤æ•£å°„æ•°æ®ä¸­çš„ç¯å½¢ç»“æ„ï¼Œæ˜¾ç¤ºå‡ºå›¾åƒå’Œä¼˜åŒ–ç®—æ³•æœ€æ–°è¿›å±•çš„å·¨å¤§æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16257">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-36d2410d9654267eb597a45024d53bf9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Comprehensive-Evaluation-of-Quantitative-Measurements-from-Automated-Deep-Segmentations-of-PSMA-PET-CT-Images"><a href="#Comprehensive-Evaluation-of-Quantitative-Measurements-from-Automated-Deep-Segmentations-of-PSMA-PET-CT-Images" class="headerlink" title="Comprehensive Evaluation of Quantitative Measurements from Automated   Deep Segmentations of PSMA PET&#x2F;CT Images"></a>Comprehensive Evaluation of Quantitative Measurements from Automated   Deep Segmentations of PSMA PET&#x2F;CT Images</h2><p><strong>Authors:Obed Korshie Dzikunu, Amirhossein Toosi, Shadab Ahamed, Sara Harsini, Francois Benard, Xiaoxiao Li, Arman Rahmim</strong></p>
<p>This study performs a comprehensive evaluation of quantitative measurements as extracted from automated deep-learning-based segmentation methods, beyond traditional Dice Similarity Coefficient assessments, focusing on six quantitative metrics, namely SUVmax, SUVmean, total lesion activity (TLA), tumor volume (TMTV), lesion count, and lesion spread. We analyzed 380 prostate-specific membrane antigen (PSMA) targeted [18F]DCFPyL PET&#x2F;CT scans of patients with biochemical recurrence of prostate cancer, training deep neural networks, U-Net, Attention U-Net and SegResNet with four loss functions: Dice Loss, Dice Cross Entropy, Dice Focal Loss, and our proposed L1 weighted Dice Focal Loss (L1DFL). Evaluations indicated that Attention U-Net paired with L1DFL achieved the strongest correlation with the ground truth (concordance correlation &#x3D; 0.90-0.99 for SUVmax and TLA), whereas models employing the Dice Loss and the other two compound losses, particularly with SegResNet, underperformed. Equivalence testing (TOST, alpha &#x3D; 0.05, Delta &#x3D; 20%) confirmed high performance for SUV metrics, lesion count and TLA, with L1DFL yielding the best performance. By contrast, tumor volume and lesion spread exhibited greater variability. Bland-Altman, Coverage Probability, and Total Deviation Index analyses further highlighted that our proposed L1DFL minimizes variability in quantification of the ground truth clinical measures. The code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/ObedDzik/pca/_segment.git">https://github.com/ObedDzik/pca\_segment.git</a>. </p>
<blockquote>
<p>æœ¬ç ”ç©¶å¯¹åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åŒ–åˆ†å‰²æ–¹æ³•æ‰€æå–çš„å®šé‡æµ‹é‡å€¼è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¿™äº›è¯„ä¼°è¶…è¶Šäº†ä¼ ç»Ÿçš„Diceç›¸ä¼¼ç³»æ•°è¯„ä¼°ï¼Œä¸»è¦å…³æ³¨å…­ä¸ªå®šé‡æŒ‡æ ‡ï¼Œå³SUVmaxã€SUVmeanã€æ€»ç—…ç¶æ´»æ€§ï¼ˆTLAï¼‰ã€è‚¿ç˜¤ä½“ç§¯ï¼ˆTMTVï¼‰ã€ç—…ç¶æ•°é‡å’Œç—…ç¶æ‰©æ•£ã€‚æˆ‘ä»¬åˆ†æäº†380ä¾‹å‰åˆ—è…ºç‰¹å¼‚æ€§è†œæŠ—åŸï¼ˆPSMAï¼‰é¶å‘[18F]DCFPyL PET&#x2F;CTæ‰«æçš„ç”ŸåŒ–å¤å‘å‰åˆ—è…ºç™Œæ‚£è€…ï¼Œè®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬U-Netã€Attention U-Netå’ŒSegResNetï¼Œé‡‡ç”¨å››ç§æŸå¤±å‡½æ•°ï¼šDice Lossã€Dice Cross Entropyã€Dice Focal Lossä»¥åŠæˆ‘ä»¬æå‡ºçš„L1åŠ æƒDice Focal Lossï¼ˆL1DFLï¼‰ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒAttention U-Netä¸L1DFLçš„ç»“åˆä¸çœŸå®å€¼ä¹‹é—´çš„ç›¸å…³æ€§æœ€å¼ºï¼ˆSUVmaxå’ŒTLAçš„ç¬¦åˆåº¦ç›¸å…³æ€§ä¸º0.90-0.99ï¼‰ï¼Œè€Œé‡‡ç”¨Dice Losså’Œå…¶ä»–ä¸¤ç§å¤åˆæŸå¤±çš„æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯ä¸SegResNetç»“åˆçš„æ¨¡å‹ï¼Œè¡¨ç°è¾ƒå·®ã€‚ç­‰æ•ˆæ€§æ£€éªŒï¼ˆTOSTï¼ŒÎ±&#x3D;0.05ï¼ŒÎ”&#x3D;20%ï¼‰è¯å®äº†SUVæŒ‡æ ‡ã€ç—…ç¶è®¡æ•°å’ŒTLAçš„é«˜æ€§èƒ½è¡¨ç°ï¼Œå…¶ä¸­L1DFLè¡¨ç°æœ€ä½³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè‚¿ç˜¤ä½“ç§¯å’Œç—…ç¶æ‰©æ•£è¡¨ç°å‡ºæ›´å¤§çš„å˜åŒ–æ€§ã€‚Bland-Altmanåˆ†æã€è¦†ç›–æ¦‚ç‡å’Œæ€»åå·®æŒ‡æ•°åˆ†æè¿›ä¸€æ­¥å¼ºè°ƒäº†æˆ‘ä»¬æå‡ºçš„L1DFLåœ¨é‡åŒ–çœŸå®ä¸´åºŠæŒ‡æ ‡æ–¹é¢çš„å˜åŒ–æ€§æœ€å°åŒ–ã€‚ç›¸å…³ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/ObedDzik/pca_segment.git%E3%80%82">https://github.com/ObedDzik/pca_segment.gitã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16237v1">PDF</a> 12 pages, 8 figures</p>
<p><strong>æ‘˜è¦</strong><br>     æœ¬ç ”ç©¶å¯¹åŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å‰²æ–¹æ³•æå–çš„å®šé‡æµ‹é‡è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¿™äº›æµ‹é‡åŒ…æ‹¬SUVmaxã€SUVmeanã€æ€»ç—…å˜æ´»æ€§ï¼ˆTLAï¼‰ã€è‚¿ç˜¤ä½“ç§¯ï¼ˆTMTVï¼‰ã€ç—…å˜è®¡æ•°å’Œç—…å˜æ‰©æ•£ç­‰å…­ä¸ªå®šé‡æŒ‡æ ‡ï¼Œå¹¶åˆ†æäº†380ä¾‹å‰åˆ—è…ºç‰¹å¼‚æ€§è†œæŠ—åŸï¼ˆPSMAï¼‰é¶å‘[18F]DCFPyL PET&#x2F;CTæ‰«æçš„å‰åˆ—è…ºç™Œç”ŸåŒ–å¤å‘æ‚£è€…æ•°æ®ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨Attention U-Netä¸L1DFLç»“åˆçš„æ¨¡å‹ä¸çœŸå®å€¼çš„ç›¸å…³æ€§æœ€å¼ºï¼ˆSUVmaxå’ŒTLAçš„ç¬¦åˆåº¦ç›¸å…³æ€§ä¸º0.90-0.99ï¼‰ï¼Œè€Œé‡‡ç”¨Dice Losså’Œå…¶ä»–å¤åˆæŸå¤±çš„æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯ä¸SegResNetç»“åˆçš„æ¨¡å‹è¡¨ç°è¾ƒå·®ã€‚ç­‰ä»·æµ‹è¯•è¡¨æ˜SUVæŒ‡æ ‡ã€ç—…å˜è®¡æ•°å’ŒTLAæ€§èƒ½è¾ƒé«˜ï¼Œå…¶ä¸­L1DFLè¡¨ç°æœ€ä½³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè‚¿ç˜¤ä½“ç§¯å’Œç—…å˜æ‰©æ•£çš„å˜å¼‚æ€§è¾ƒå¤§ã€‚Bland-Altmanåˆ†æã€è¦†ç›–æ¦‚ç‡å’Œæ€»åå·®æŒ‡æ•°åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ‰€æå‡ºçš„L1DFLèƒ½æœ€å°åŒ–å¯¹çœŸå®ä¸´åºŠæŒ‡æ ‡çš„é‡åŒ–å·®å¼‚ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€äºï¼š<a target="_blank" rel="noopener" href="https://github.com/ObedDzik/pca_segment.git%E3%80%82">https://github.com/ObedDzik/pca_segment.gitã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶å¯¹åŸºäºæ·±åº¦å­¦ä¹ çš„åˆ†å‰²æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„å®šé‡æµ‹é‡è¯„ä¼°ï¼Œæ¶‰åŠSUVmaxã€SUVmeanç­‰å…­ä¸ªæŒ‡æ ‡ã€‚</li>
<li>Attention U-Netä¸L1DFLç»“åˆæ¨¡å‹åœ¨SUVmaxå’ŒTLAæŒ‡æ ‡ä¸Šä¸çœŸå®å€¼çš„ç¬¦åˆåº¦ç›¸å…³æ€§æœ€é«˜ã€‚</li>
<li>L1DFLåœ¨SUVæŒ‡æ ‡ã€ç—…å˜è®¡æ•°å’ŒTLAçš„ç­‰ä»·æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
<li>è‚¿ç˜¤ä½“ç§¯å’Œç—…å˜æ‰©æ•£çš„é‡åŒ–ç»“æœè¡¨ç°å‡ºè¾ƒå¤§çš„å˜å¼‚æ€§ã€‚</li>
<li>å…¬å¼€çš„ä»£ç æœ‰åŠ©äºå…¶ä»–ç ”ç©¶è€…åˆ©ç”¨æ­¤ç ”ç©¶çš„æ¨¡å‹å’Œæ•°æ®è¿›è¡Œè¿›ä¸€æ­¥çš„åˆ†æå’Œç ”ç©¶ã€‚</li>
<li>æå‡ºçš„L1DFLèƒ½æœ€å°åŒ–çœŸå®ä¸´åºŠæŒ‡æ ‡é‡åŒ–çš„å·®å¼‚ï¼Œå¾—åˆ°äº†Bland-Altmanåˆ†æç­‰çš„æ”¯æŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16237">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d2a2cfcbc6bb8da206c1c49a73dbf8cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3964a7eadbe4f0550b16c04c26a1d7e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c4e6911c1b783137d0f40bcc68766a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ac63dc524f2128dc8455fb91cede65b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1fc713f9fbe03a17426653c5ba40a1d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Automatically-Detecting-Numerical-Instability-in-Machine-Learning-Applications-via-Soft-Assertions"><a href="#Automatically-Detecting-Numerical-Instability-in-Machine-Learning-Applications-via-Soft-Assertions" class="headerlink" title="Automatically Detecting Numerical Instability in Machine Learning   Applications via Soft Assertions"></a>Automatically Detecting Numerical Instability in Machine Learning   Applications via Soft Assertions</h2><p><strong>Authors:Shaila Sharmin, Anwar Hossain Zahid, Subhankar Bhattacharjee, Chiamaka Igwilo, Miryung Kim, Wei Le</strong></p>
<p>Machine learning (ML) applications have become an integral part of our lives. ML applications extensively use floating-point computation and involve very large&#x2F;small numbers; thus, maintaining the numerical stability of such complex computations remains an important challenge. Numerical bugs can lead to system crashes, incorrect output, and wasted computing resources. In this paper, we introduce a novel idea, namely soft assertions (SA), to encode safety&#x2F;error conditions for the places where numerical instability can occur. A soft assertion is an ML model automatically trained using the dataset obtained during unit testing of unstable functions. Given the values at the unstable function in an ML application, a soft assertion reports how to change these values in order to trigger the instability. We then use the output of soft assertions as signals to effectively mutate inputs to trigger numerical instability in ML applications. In the evaluation, we used the GRIST benchmark, a total of 79 programs, as well as 15 real-world ML applications from GitHub. We compared our tool with 5 state-of-the-art (SOTA) fuzzers. We found all the GRIST bugs and outperformed the baselines. We found 13 numerical bugs in real-world code, one of which had already been confirmed by the GitHub developers. While the baselines mostly found the bugs that report NaN and INF, our tool \tool found numerical bugs with incorrect output. We showed one case where the Tumor Detection Model, trained on Brain MRI images, should have predicted â€œtumorâ€, but instead, it incorrectly predicted â€œno tumorâ€ due to the numerical bugs. Our replication package is located at <a target="_blank" rel="noopener" href="https://figshare.com/s/6528d21ccd28bea94c32">https://figshare.com/s/6528d21ccd28bea94c32</a>. </p>
<blockquote>
<p>æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰åº”ç”¨å·²æˆä¸ºæˆ‘ä»¬ç”Ÿæ´»ä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ã€‚æœºå™¨å­¦ä¹ åº”ç”¨å¹¿æ³›åœ°ä½¿ç”¨æµ®ç‚¹è®¡ç®—å¹¶æ¶‰åŠéå¸¸å¤§çš„æ•°å­—æˆ–éå¸¸å°çš„æ•°å­—ï¼›å› æ­¤ï¼Œä¿æŒæ­¤ç±»å¤æ‚è®¡ç®—çš„æ•°å€¼ç¨³å®šæ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚æ•°å€¼é”™è¯¯å¯èƒ½å¯¼è‡´ç³»ç»Ÿå´©æºƒã€è¾“å‡ºé”™è¯¯å’Œè®¡ç®—èµ„æºæµªè´¹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°çš„æ¦‚å¿µï¼Œå³è½¯æ–­è¨€ï¼ˆSAï¼‰ï¼Œç”¨äºç¼–ç å¯èƒ½å‘ç”Ÿæ•°å€¼ä¸ç¨³å®šçš„åœ°æ–¹çš„å®‰å…¨&#x2F;é”™è¯¯æ¡ä»¶ã€‚è½¯æ–­è¨€æ˜¯ä¸€ç§ä½¿ç”¨åœ¨ä¸ç¨³å®šå‡½æ•°å•å…ƒæµ‹è¯•æœŸé—´è·å¾—çš„æ•°æ®é›†è‡ªåŠ¨è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç»™å®šæœºå™¨å­¦ä¹ åº”ç”¨ä¸­ä¸ç¨³å®šå‡½æ•°çš„å€¼ï¼Œè½¯æ–­è¨€ä¼šæŠ¥å‘Šå¦‚ä½•æ›´æ”¹è¿™äº›å€¼ä»¥è§¦å‘ä¸ç¨³å®šã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è½¯æ–­è¨€çš„è¾“å‡ºä½œä¸ºä¿¡å·æ¥æœ‰æ•ˆåœ°æ›´æ”¹è¾“å…¥ï¼Œä»¥è§¦å‘æœºå™¨å­¦ä¹ åº”ç”¨ä¸­çš„æ•°å€¼ä¸ç¨³å®šã€‚åœ¨è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒ…å«æ€»å…±79ä¸ªç¨‹åºçš„GRISTåŸºå‡†æµ‹è¯•ä»¥åŠæ¥è‡ªGitHubçš„15ä¸ªçœŸå®ä¸–ç•Œçš„æœºå™¨å­¦ä¹ åº”ç”¨ã€‚æˆ‘ä»¬å°†å·¥å…·ä¸äº”ç§æœ€æ–°ï¼ˆSOTAï¼‰æ¨¡ç³Šæµ‹è¯•å·¥å…·è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬å‘ç°æ‰€æœ‰GRISTé”™è¯¯å¹¶è¶…è¶Šäº†åŸºçº¿å·¥å…·ã€‚æˆ‘ä»¬åœ¨çœŸå®ä¸–ç•Œä»£ç ä¸­å‘ç°äº†13ä¸ªæ•°å€¼é”™è¯¯ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯GitHubå¼€å‘äººå‘˜å·²ç»ç¡®è®¤çš„ã€‚è™½ç„¶åŸºçº¿å·¥å…·å¤§å¤šå‘ç°äº†æŠ¥å‘ŠNaNå’ŒINFçš„é”™è¯¯ï¼Œä½†æˆ‘ä»¬çš„å·¥å…·å‘ç°äº†å…·æœ‰é”™è¯¯è¾“å‡ºçš„æ•°å€¼é”™è¯¯ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªæ¡ˆä¾‹ï¼Œå³åŸºäºè„‘éƒ¨MRIå›¾åƒè®­ç»ƒçš„è‚¿ç˜¤æ£€æµ‹æ¨¡å‹åº”è¯¥é¢„æµ‹ä¸ºâ€œæœ‰è‚¿ç˜¤â€ï¼Œä½†ç”±äºæ•°å€¼é”™è¯¯ï¼Œå´é”™è¯¯åœ°é¢„æµ‹ä¸ºâ€œæ— è‚¿ç˜¤â€ã€‚æˆ‘ä»¬çš„å¤åˆ¶åŒ…ä½äº<a target="_blank" rel="noopener" href="https://figshare.com/s/6528d21ccd28bea94c32%E3%80%82">https://figshare.com/s/6528d21ccd28bea94c32ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15507v2">PDF</a> 22 pages, 5 figures. Accepted at FSE 2025</p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”è½¯æ–­è¨€ï¼ˆSAï¼‰ï¼Œç”¨äºç¼–ç å¯èƒ½å‡ºç°æ•°å€¼ä¸ç¨³å®šæƒ…å†µçš„å®‰å…¨&#x2F;é”™è¯¯æ¡ä»¶ã€‚è½¯æ–­è¨€æ˜¯ä¸€ç§è‡ªåŠ¨è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒä½¿ç”¨åœ¨ä¸ç¨³å®šå‡½æ•°å•å…ƒæµ‹è¯•æœŸé—´è·å¾—çš„æ•°æ®é›†ã€‚ç»™å®šæœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºä¸­ä¸ç¨³å®šå‡½æ•°çš„å€¼ï¼Œè½¯æ–­è¨€æŠ¥å‘Šå¦‚ä½•æ”¹å˜è¿™äº›å€¼ä»¥è§¦å‘ä¸ç¨³å®šã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è½¯æ–­è¨€çš„è¾“å‡ºä½œä¸ºä¿¡å·ï¼Œæœ‰æ•ˆåœ°æ”¹å˜è¾“å…¥ï¼Œä»¥è§¦å‘æœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºä¸­çš„æ•°å€¼ä¸ç¨³å®šã€‚è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†GRISTåŸºå‡†æµ‹è¯•ä¸­çš„79ä¸ªç¨‹åºä»¥åŠGitHubä¸Šçš„15ä¸ªçœŸå®ä¸–ç•Œæœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºã€‚ä¸äº”ä¸ªæœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ¨¡ç³Šæµ‹è¯•å·¥å…·ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„å·¥å…·å‘ç°äº†æ‰€æœ‰GRISTä¸­çš„é”™è¯¯ï¼Œå¹¶ä¸”è¡¨ç°ä¼˜äºåŸºçº¿å·¥å…·ã€‚åœ¨çœŸå®ä¸–ç•Œçš„ä»£ç ä¸­å‘ç°äº†13ä¸ªæ•°å€¼é”™è¯¯ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯GitHubå¼€å‘è€…å·²ç»ç¡®è®¤çš„é”™è¯¯ã€‚ä¸å…¶ä»–å·¥å…·ä¸»è¦å‘ç°æŠ¥å‘ŠNaNå’ŒINFçš„é”™è¯¯ä¸åŒï¼Œæˆ‘ä»¬çš„å·¥å…·è¿˜èƒ½å‘ç°è¾“å‡ºé”™è¯¯çš„æ•°å€¼é”™è¯¯ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™æ ·ä¸€ä¸ªæ¡ˆä¾‹ï¼šåŸºäºè„‘éƒ¨MRIå›¾åƒè®­ç»ƒçš„è‚¿ç˜¤æ£€æµ‹æ¨¡å‹æœ¬åº”é¢„æµ‹ä¸ºâ€œè‚¿ç˜¤â€ï¼Œä½†ç”±äºæ•°å€¼é”™è¯¯è€Œé”™è¯¯åœ°é¢„æµ‹ä¸ºâ€œæ— è‚¿ç˜¤â€ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ol>
<li>å¼•å…¥è½¯æ–­è¨€ï¼ˆSAï¼‰æ¦‚å¿µï¼Œç”¨äºæœºå™¨å­¦ä¹ ä¸­çš„æ•°å€¼ç¨³å®šæ€§æŒ‘æˆ˜ã€‚</li>
<li>è½¯æ–­è¨€æ˜¯ä¸€ç§è‡ªåŠ¨è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºè¯†åˆ«å’ŒæŠ¥å‘Šæ•°å€¼ä¸ç¨³å®šçš„æƒ…å†µã€‚</li>
<li>é€šè¿‡è½¯æ–­è¨€çš„è¾“å‡ºä½œä¸ºä¿¡å·æ¥è§¦å‘æœºå™¨å­¦ä¹ åº”ç”¨ä¸­çš„æ•°å€¼ä¸ç¨³å®šã€‚</li>
<li>ä½¿ç”¨GRISTåŸºå‡†æµ‹è¯•å’ŒçœŸå®ä¸–ç•Œæœºå™¨å­¦ä¹ åº”ç”¨è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>ä¸å…¶ä»–å…ˆè¿›å·¥å…·ç›¸æ¯”ï¼Œè¯¥å·¥å…·èƒ½å¤Ÿå‘ç°æ‰€æœ‰GRISTä¸­çš„é”™è¯¯ä»¥åŠæ›´å¤šçš„çœŸå®ä¸–ç•Œä»£ç ä¸­çš„æ•°å€¼é”™è¯¯ã€‚</li>
<li>è¯¥å·¥å…·ä¸ä»…èƒ½å‘ç°æŠ¥å‘ŠNaNå’ŒINFçš„é”™è¯¯ï¼Œè¿˜èƒ½å‘ç°è¾“å‡ºé”™è¯¯çš„æ•°å€¼é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15507">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c1f79c751bcad32d6d164b2dac5e483f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bfca7e08be3d065fde427f89b00f208.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Embedding-Radiomics-into-Vision-Transformers-for-Multimodal-Medical-Image-Classification"><a href="#Embedding-Radiomics-into-Vision-Transformers-for-Multimodal-Medical-Image-Classification" class="headerlink" title="Embedding Radiomics into Vision Transformers for Multimodal Medical   Image Classification"></a>Embedding Radiomics into Vision Transformers for Multimodal Medical   Image Classification</h2><p><strong>Authors:Zhenyu Yang, Haiming Zhu, Rihui Zhang, Haipeng Zhang, Jianliang Wang, Chunhao Wang, Minbin Chen, Fang-Fang Yin</strong></p>
<p>Background: Deep learning has significantly advanced medical image analysis, with Vision Transformers (ViTs) offering a powerful alternative to convolutional models by modeling long-range dependencies through self-attention. However, ViTs are inherently data-intensive and lack domain-specific inductive biases, limiting their applicability in medical imaging. In contrast, radiomics provides interpretable, handcrafted descriptors of tissue heterogeneity but suffers from limited scalability and integration into end-to-end learning frameworks. In this work, we propose the Radiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features with data-driven visual embeddings within a ViT backbone.   Purpose: To develop a hybrid RE-ViT framework that integrates radiomics and patch-wise ViT embeddings through early fusion, enhancing robustness and performance in medical image classification.   Methods: Following the standard ViT pipeline, images were divided into patches. For each patch, handcrafted radiomic features were extracted and fused with linearly projected pixel embeddings. The fused representations were normalized, positionally encoded, and passed to the ViT encoder. A learnable [CLS] token aggregated patch-level information for classification. We evaluated RE-ViT on three public datasets (including BUSI, ChestXray2017, and Retinal OCT) using accuracy, macro AUC, sensitivity, and specificity. RE-ViT was benchmarked against CNN-based (VGG-16, ResNet) and hybrid (TransMed) models.   Results: RE-ViT achieved state-of-the-art results: on BUSI, AUC&#x3D;0.950+&#x2F;-0.011; on ChestXray2017, AUC&#x3D;0.989+&#x2F;-0.004; on Retinal OCT, AUC&#x3D;0.986+&#x2F;-0.001, which outperforms other comparison models.   Conclusions: The RE-ViT framework effectively integrates radiomics with ViT architectures, demonstrating improved performance and generalizability across multimodal medical image classification tasks. </p>
<blockquote>
<p>èƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†ææ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œè€ŒVision Transformersï¼ˆViTsï¼‰é€šè¿‡è‡ªæ³¨æ„åŠ›å»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œä¸ºå·ç§¯æ¨¡å‹æä¾›äº†ä¸€ç§å¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼ŒViTsæœ¬è´¨ä¸Šéœ€è¦å¤§é‡çš„æ•°æ®ï¼Œå¹¶ä¸”ç¼ºä¹é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å½’çº³åè§ï¼Œè¿™åœ¨åŒ»å­¦æˆåƒä¸­é™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ”¾å°„ç»„å­¦æä¾›äº†ç»„ç»‡å¼‚è´¨æ€§çš„å¯è§£é‡Šã€æ‰‹å·¥æè¿°å™¨ï¼Œä½†å—é™äºå¯æ‰©å±•æ€§å’Œé›†æˆåˆ°ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶çš„èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Radiomics-Embedded Vision Transformerï¼ˆRE-ViTï¼‰ï¼Œå®ƒå°†æ”¾å°„ç»„å­¦ç‰¹å¾ä¸æ•°æ®é©±åŠ¨çš„è§†è§‰åµŒå…¥ç›¸ç»“åˆï¼Œåœ¨ä¸€ä¸ªViTä¸»å¹²ä¸­ã€‚ç›®çš„ï¼šå¼€å‘ä¸€ä¸ªæ··åˆRE-ViTæ¡†æ¶ï¼Œé€šè¿‡æ—©æœŸèåˆé›†æˆæ”¾å°„ç»„å­¦å’Œè¡¥ä¸å¼ViTåµŒå…¥ï¼Œæé«˜åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚æ–¹æ³•ï¼šéµå¾ªæ ‡å‡†çš„ViTç®¡é“ï¼Œå°†å›¾åƒåˆ†æˆè¡¥ä¸ã€‚å¯¹äºæ¯ä¸ªè¡¥ä¸ï¼Œæå–æ‰‹å·¥åˆ¶ä½œçš„æ”¾å°„ç»„å­¦ç‰¹å¾ï¼Œå¹¶ä¸çº¿æ€§æŠ•å½±çš„åƒç´ åµŒå…¥ç›¸èåˆã€‚èåˆåçš„è¡¨ç¤ºç»è¿‡å½’ä¸€åŒ–ã€ä½ç½®ç¼–ç ï¼Œç„¶åä¼ é€’ç»™ViTç¼–ç å™¨ã€‚ä¸€ä¸ªå¯å­¦ä¹ çš„[CLS]æ ‡è®°èšåˆäº†è¡¥ä¸çº§åˆ«çš„ä¿¡æ¯ç”¨äºåˆ†ç±»ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ï¼ˆåŒ…æ‹¬BUSIã€ChestXray2017å’ŒRetinal OCTï¼‰ä¸Šè¯„ä¼°äº†RE-ViTï¼Œä½¿ç”¨äº†å‡†ç¡®ç‡ã€å®AUCã€çµæ•åº¦å’Œç‰¹å¼‚æ€§ã€‚RE-ViTä¸åŸºäºCNNï¼ˆVGG-16ã€ResNetï¼‰å’Œæ··åˆï¼ˆTransMedï¼‰æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”è¯„ä¼°ã€‚ç»“æœï¼šRE-ViTè¾¾åˆ°äº†æœ€æ–°çš„ç»“æœï¼šåœ¨BUSIä¸Šï¼ŒAUC&#x3D;0.950Â±0.011ï¼›åœ¨ChestXray2017ä¸Šï¼ŒAUC&#x3D;0.989Â±0.004ï¼›åœ¨è§†ç½‘è†œOCTä¸Šï¼ŒAUC&#x3D;0.986Â±0.001ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚ç»“è®ºï¼šRE-ViTæ¡†æ¶æœ‰æ•ˆåœ°å°†æ”¾å°„ç»„å­¦ä¸ViTæ¶æ„ç›¸ç»“åˆï¼Œå±•ç¤ºäº†åœ¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„æ”¹è¿›æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10916v2">PDF</a> 27 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§èåˆæ”¾å°„ç»„å­¦ä¸Vision Transformerï¼ˆViTï¼‰çš„æ··åˆæ¡†æ¶RE-ViTï¼Œé€šè¿‡æ—©æœŸèåˆæ”¾å°„ç»„å­¦ç‰¹å¾å’ŒViTæ•°æ®é©±åŠ¨è§†è§‰åµŒå…¥ï¼Œæé«˜äº†åœ¨åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒRE-ViTå–å¾—äº†å…ˆè¿›çš„ç»“æœï¼Œè¯æ˜å…¶åœ¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RE-ViTç»“åˆäº†æ”¾å°„ç»„å­¦ç‰¹å¾å’ŒVision Transformerï¼ˆViTï¼‰æ•°æ®é©±åŠ¨è§†è§‰åµŒå…¥ï¼Œæä¾›äº†ä¸€ä¸ªæ–°çš„åŒ»å­¦å›¾åƒåˆ†ææ¡†æ¶ã€‚</li>
<li>é€šè¿‡æ—©æœŸèåˆæ”¾å°„ç»„å­¦ç‰¹å¾å’ŒViTåµŒå…¥ï¼ŒRE-ViTå¢å¼ºäº†åŒ»å­¦å›¾åƒåˆ†ç±»çš„ç¨³å¥æ€§å’Œæ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒRE-ViTè¾¾åˆ°äº†å…ˆè¿›æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>RE-ViTæ¡†æ¶é€šè¿‡èåˆæ”¾å°„ç»„å­¦ç‰¹å¾ä¸ViTæ¶æ„ï¼Œæé«˜äº†åŒ»å­¦å›¾åƒåˆ†ç±»çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†å¯¹å¤šæ¨¡æ€åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡çš„ä¼˜ç§€è¡¨ç°ã€‚</li>
<li>RE-ViTç›¸å¯¹äºä¼ ç»Ÿçš„CNNæ¨¡å‹å’Œæ··åˆæ¨¡å‹è¡¨ç°å‡ºäº†ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10916">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6d0a5afd995995fc6811059576260981.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Solving-Inverse-Problems-in-Protein-Space-Using-Diffusion-Based-Priors"><a href="#Solving-Inverse-Problems-in-Protein-Space-Using-Diffusion-Based-Priors" class="headerlink" title="Solving Inverse Problems in Protein Space Using Diffusion-Based Priors"></a>Solving Inverse Problems in Protein Space Using Diffusion-Based Priors</h2><p><strong>Authors:Axel Levy, Eric R. Chan, Sara Fridovich-Keil, FrÃ©dÃ©ric Poitevin, Ellen D. Zhong, Gordon Wetzstein</strong></p>
<p>The interaction of a protein with its environment can be understood and controlled via its 3D structure. Experimental methods for protein structure determination, such as X-ray crystallography or cryogenic electron microscopy, shed light on biological processes but introduce challenging inverse problems. Learning-based approaches have emerged as accurate and efficient methods to solve these inverse problems for 3D structure determination, but are specialized for a predefined type of measurement. Here, we introduce a versatile framework to turn biophysical measurements, such as cryo-EM density maps, into 3D atomic models. Our method combines a physics-based forward model of the measurement process with a pretrained generative model providing a task-agnostic, data-driven prior. Our method outperforms posterior sampling baselines on linear and non-linear inverse problems. In particular, it is the first diffusion-based method for refining atomic models from cryo-EM maps and building atomic models from sparse distance matrices. </p>
<blockquote>
<p>è›‹ç™½è´¨ä¸å…¶ç¯å¢ƒçš„ç›¸äº’ä½œç”¨å¯ä»¥é€šè¿‡å…¶ä¸‰ç»´ç»“æ„æ¥ç†è§£å¹¶æ§åˆ¶ã€‚ç”¨äºç¡®å®šè›‹ç™½è´¨ç»“æ„çš„å®éªŒæ–¹æ³•ï¼Œå¦‚Xå°„çº¿æ™¶ä½“å­¦æˆ–å†·å†»ç”µå­æ˜¾å¾®é•œï¼Œä¸ºç†è§£ç”Ÿç‰©è¿‡ç¨‹æä¾›äº†å¯ç¤ºï¼Œä½†åŒæ—¶ä¹Ÿå¸¦æ¥äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„åé—®é¢˜ã€‚åŸºäºå­¦ä¹ çš„æ–¹æ³•å·²ç»ä½œä¸ºå‡†ç¡®é«˜æ•ˆçš„æ–¹æ³•æ¥è§£å†³è¿™äº›åé—®é¢˜ä»¥è¿›è¡Œä¸‰ç»´ç»“æ„æµ‹å®šï¼Œä½†è¿™äº›æ–¹æ³•ä»…é™äºç‰¹å®šç±»å‹çš„æµ‹é‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯å°†ç”Ÿç‰©ç‰©ç†æµ‹é‡ï¼ˆå¦‚å†·å†»ç”µå­æ˜¾å¾®é•œå¯†åº¦å›¾ï¼‰è½¬åŒ–ä¸ºä¸‰ç»´åŸå­æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†åŸºäºç‰©ç†çš„æµ‹é‡è¿‡ç¨‹å‰å‘æ¨¡å‹ä¸é¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥ç”Ÿæˆæ¨¡å‹æä¾›äº†ä»»åŠ¡æ— å…³çš„æ•°æ®é©±åŠ¨å…ˆéªŒã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è§£å†³çº¿æ€§å’Œéçº¿æ€§åé—®é¢˜ä¸Šä¼˜äºåé‡‡æ ·åŸºçº¿ã€‚å°¤å…¶æ˜¯ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªåŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œç”¨äºä»å†·å†»ç”µå­æ˜¾å¾®é•œå›¾è°±ä¸­ä¼˜åŒ–åŸå­æ¨¡å‹å¹¶ä»ç¨€ç–è·ç¦»çŸ©é˜µæ„å»ºåŸå­æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.04239v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è›‹ç™½è´¨ä¸å…¶ç¯å¢ƒä¹‹é—´çš„ç›¸äº’ä½œç”¨å¯é€šè¿‡å…¶ä¸‰ç»´ç»“æ„è¿›è¡Œç†è§£å’Œæ§åˆ¶ã€‚å®éªŒæ–¹æ³•å¦‚Xå°„çº¿æ™¶ä½“å­¦æˆ–å†·å†»ç”µå­æ˜¾å¾®é•œä¸ºç”Ÿç‰©è¿‡ç¨‹æä¾›äº†è§è§£ï¼Œä½†å¸¦æ¥äº†é€†å‘é—®é¢˜çš„æŒ‘æˆ˜ã€‚åŸºäºå­¦ä¹ çš„æ–¹æ³•å·²å‡†ç¡®é«˜æ•ˆåœ°è§£å†³äº†è¿™äº›é€†å‘é—®é¢˜ä»¥å®ç°ä¸‰ç»´ç»“æ„æµ‹å®šï¼Œä½†ä»…é™äºç‰¹å®šç±»å‹çš„æµ‹é‡ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯å°†ç”Ÿç‰©ç‰©ç†æµ‹é‡ï¼ˆå¦‚å†·å†»ç”µå­æ˜¾å¾®é•œå¯†åº¦å›¾ï¼‰è½¬åŒ–ä¸ºä¸‰ç»´åŸå­æ¨¡å‹ã€‚è¯¥æ–¹æ³•ç»“åˆäº†æµ‹é‡è¿‡ç¨‹çš„ç‰©ç†å‰å‘æ¨¡å‹ä¸é¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹ï¼Œæä¾›äº†ä¸€é¡¹ä»»åŠ¡æ— å…³çš„æ•°æ®é©±åŠ¨å…ˆéªŒã€‚è¯¥æ–¹æ³•åœ¨çº¿æ€§å’Œéçº¿æ€§é€†å‘é—®é¢˜ä¸Šä¼˜äºåé‡‡æ ·åŸºçº¿ï¼Œå°¤å…¶æ˜¯ç¬¬ä¸€ä¸ªåŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œå¯ä¼˜åŒ–å†·å†»ç”µå­æ˜¾å¾®é•œåœ°å›¾çš„åŸå­æ¨¡å‹å¹¶ä»ç¨€ç–è·ç¦»çŸ©é˜µæ„å»ºåŸå­æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è›‹ç™½è´¨ä¸å…¶ç¯å¢ƒäº’åŠ¨å¯é€šè¿‡å…¶ä¸‰ç»´ç»“æ„ç†è§£å¹¶æ§åˆ¶ã€‚</li>
<li>å®éªŒæ–¹æ³•å¦‚Xå°„çº¿æ™¶ä½“å­¦å’Œå†·å†»ç”µå­æ˜¾å¾®é•œä¸ºç”Ÿç‰©è¿‡ç¨‹ç ”ç©¶æä¾›äº†å·¥å…·ï¼Œä½†å­˜åœ¨é€†å‘é—®é¢˜çš„æŒ‘æˆ˜ã€‚</li>
<li>åŸºäºå­¦ä¹ çš„æ–¹æ³•å·²è§£å†³é€†å‘é—®é¢˜ç”¨äºä¸‰ç»´ç»“æ„æµ‹å®šï¼Œä½†å±€é™äºç‰¹å®šç±»å‹æµ‹é‡ã€‚</li>
<li>ä»‹ç»äº†ä¸€ä¸ªé€šç”¨æ¡†æ¶æ¥è½¬åŒ–ç”Ÿç‰©ç‰©ç†æµ‹é‡åˆ°ä¸‰ç»´åŸå­æ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆäº†ç‰©ç†å‰å‘æ¨¡å‹å’Œé¢„è®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹ï¼ˆä»»åŠ¡æ— å…³çš„æ•°æ®é©±åŠ¨å…ˆéªŒï¼‰ã€‚</li>
<li>æ­¤æ–¹æ³•åœ¨å¤šç§é€†å‘é—®é¢˜ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.04239">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f4e5f13e44d9e6edf66fc5f3a01df68a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd86b05bddbcab767e11b36e32ad0a96.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Effective-Lymph-Nodes-Detection-in-CT-Scans-Using-Location-Debiased-Query-Selection-and-Contrastive-Query-Representation-in-Transformer"><a href="#Effective-Lymph-Nodes-Detection-in-CT-Scans-Using-Location-Debiased-Query-Selection-and-Contrastive-Query-Representation-in-Transformer" class="headerlink" title="Effective Lymph Nodes Detection in CT Scans Using Location Debiased   Query Selection and Contrastive Query Representation in Transformer"></a>Effective Lymph Nodes Detection in CT Scans Using Location Debiased   Query Selection and Contrastive Query Representation in Transformer</h2><p><strong>Authors:Yirui Wang, Qinji Yu, Ke Yan, Haoshen Li, Dazhou Guo, Li Zhang, Le Lu, Na Shen, Qifeng Wang, Xiaowei Ding, Xianghua Ye, Dakai Jin</strong></p>
<p>Lymph node (LN) assessment is a critical, indispensable yet very challenging task in the routine clinical workflow of radiology and oncology. Accurate LN analysis is essential for cancer diagnosis, staging, and treatment planning. Finding scatteredly distributed, low-contrast clinically relevant LNs in 3D CT is difficult even for experienced physicians under high inter-observer variations. Previous automatic LN detection works typically yield limited recall and high false positives (FPs) due to adjacent anatomies with similar image intensities, shapes, or textures (vessels, muscles, esophagus, etc). In this work, we propose a new LN DEtection TRansformer, named LN-DETR, to achieve more accurate performance. By enhancing the 2D backbone with a multi-scale 2.5D feature fusion to incorporate 3D context explicitly, more importantly, we make two main contributions to improve the representation quality of LN queries. 1) Considering that LN boundaries are often unclear, an IoU prediction head and a location debiased query selection are proposed to select LN queries of higher localization accuracy as the decoder queryâ€™s initialization. 2) To reduce FPs, query contrastive learning is employed to explicitly reinforce LN queries towards their best-matched ground-truth queries over unmatched query predictions. Trained and tested on 3D CT scans of 1067 patients (with 10,000+ labeled LNs) via combining seven LN datasets from different body parts (neck, chest, and abdomen) and pathologies&#x2F;cancers, our method significantly improves the performance of previous leading methods by &gt; 4-5% average recall at the same FP rates in both internal and external testing. We further evaluate on the universal lesion detection task using NIH DeepLesion benchmark, and our method achieves the top performance of 88.46% averaged recall across 0.5 to 4 FPs per image, compared with other leading reported results. </p>
<blockquote>
<p>æ·‹å·´ç»“ï¼ˆLNï¼‰è¯„ä¼°æ˜¯æ”¾å°„å­¦å’Œè‚¿ç˜¤å­¦å¸¸è§„ä¸´åºŠå·¥ä½œä¸­ä¸å¯æˆ–ç¼ºä¸”æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å‡†ç¡®çš„æ·‹å·´ç»“åˆ†æå¯¹äºç™Œç—‡çš„è¯Šæ–­ã€åˆ†æœŸå’Œæ²»ç–—è®¡åˆ’è‡³å…³é‡è¦ã€‚å³ä½¿åœ¨ç»éªŒä¸°å¯Œçš„åŒ»ç”Ÿä¹‹é—´ä¹Ÿå­˜åœ¨è¾ƒé«˜çš„è§‚å¯Ÿè€…é—´å˜å¼‚ï¼Œåœ¨3Dè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­å¯»æ‰¾åˆ†æ•£ã€ä½å¯¹æ¯”åº¦çš„ä¸´åºŠç›¸å…³æ·‹å·´ç»“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¹‹å‰çš„è‡ªåŠ¨æ·‹å·´ç»“æ£€æµ‹å·¥ä½œé€šå¸¸ç”±äºç›¸é‚»ç»“æ„å…·æœ‰ç›¸ä¼¼çš„å›¾åƒå¼ºåº¦ã€å½¢çŠ¶æˆ–çº¹ç†ï¼ˆå¦‚è¡€ç®¡ã€è‚Œè‚‰ã€é£Ÿç®¡ç­‰ï¼‰è€Œå¬å›ç‡æœ‰é™ï¼Œè¯¯æŠ¥ç‡é«˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ·‹å·´ç»“æ£€æµ‹è½¬æ¢å™¨ï¼Œåä¸ºLN-DETRï¼Œä»¥å®ç°æ›´å‡†ç¡®çš„æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡å¢å¼º2Dä¸»å¹²ç½‘ç»œï¼Œé‡‡ç”¨å¤šå°ºåº¦2.5Dç‰¹å¾èåˆæ¥æ˜¾å¼åœ°èå…¥3Dä¸Šä¸‹æ–‡ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨æé«˜æ·‹å·´ç»“æŸ¥è¯¢çš„è¡¨ç¤ºè´¨é‡æ–¹é¢åšå‡ºäº†ä¸¤ä¸ªä¸»è¦è´¡çŒ®ã€‚1ï¼‰è€ƒè™‘åˆ°æ·‹å·´ç»“è¾¹ç•Œé€šå¸¸ä¸æ¸…æ™°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªIoUé¢„æµ‹å¤´å’Œä½ç½®åå·®æŸ¥è¯¢é€‰æ‹©ï¼Œä»¥é€‰æ‹©å…·æœ‰è¾ƒé«˜å®šä½ç²¾åº¦çš„æ·‹å·´ç»“æŸ¥è¯¢ä½œä¸ºè§£ç å™¨æŸ¥è¯¢çš„åˆå§‹åŒ–ã€‚2ï¼‰ä¸ºäº†å‡å°‘è¯¯æŠ¥ï¼Œé‡‡ç”¨æŸ¥è¯¢å¯¹æ¯”å­¦ä¹ ï¼Œæ˜ç¡®åŠ å¼ºæ·‹å·´ç»“æŸ¥è¯¢ä¸å…¶æœ€ä½³åŒ¹é…çš„çœŸå®æŸ¥è¯¢ï¼Œè¶…è¿‡æœªåŒ¹é…çš„æŸ¥è¯¢é¢„æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨1067åæ‚£è€…çš„3D CTæ‰«æå›¾åƒä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼ˆåŒ…å«10,000å¤šä¸ªæ ‡è®°æ·‹å·´ç»“ï¼‰ï¼Œç»“åˆäº†æ¥è‡ªä¸åŒéƒ¨ä½ï¼ˆé¢ˆéƒ¨ã€èƒ¸éƒ¨å’Œè…¹éƒ¨ï¼‰å’Œç—…ç†&#x2F;ç™Œç—‡çš„ä¸ƒä¸ªæ·‹å·´ç»“æ•°æ®é›†ï¼Œåœ¨å†…éƒ¨å’Œå¤–éƒ¨æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒä¸€è¯¯æŠ¥ç‡ä¸‹å°†ä¹‹å‰é¢†å…ˆæ–¹æ³•å¹³å‡å¬å›ç‡æé«˜äº†4-5%ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åœ¨NIH DeepLesionåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œé€šç”¨ç—…å˜æ£€æµ‹ä»»åŠ¡è¯„ä¼°ï¼Œä¸å…¶ä»–æŠ¥å‘Šçš„æœ€ä½³ç»“æœç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¹³å‡æ¯å¼ å›¾åƒ0.5åˆ°4ä¸ªå‡é˜³æ€§çš„æƒ…å†µä¸‹è¾¾åˆ°äº†88.46%çš„å¬å›ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.03819v2">PDF</a> Accepted by ECCV24</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºLN-DETRçš„æ–°æ–¹æ³•ï¼Œç”¨äºæ›´ç²¾ç¡®åœ°æ£€æµ‹æ·‹å·´èŠ‚ç‚¹ï¼ˆLNsï¼‰ã€‚æ­¤æ–¹æ³•é‡‡ç”¨å¤šå°ºåº¦æ··åˆç‰¹å¾çš„èåˆç­–ç•¥ï¼Œé€šè¿‡èå…¥3Dä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥å¢å¼ºäºŒç»´ä¸»å¹²ç‰¹å¾çš„è¡¨è¾¾æ•ˆæœã€‚ä¸ºæé«˜å®šä½ç²¾åº¦å¹¶é™ä½è¯¯æŠ¥ç‡ï¼Œè®ºæ–‡æå‡ºäº†IoUé¢„æµ‹å¤´ä¸ä½ç½®åå·®æŸ¥è¯¢é€‰æ‹©æœºåˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡æŸ¥è¯¢å¯¹æ¯”å­¦ä¹ å¼ºåŒ–åŒ¹é…åº¦ï¼Œå‡å°‘äº†è¯¯æŠ¥ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ·‹å·´ç»“æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·‹å·´èŠ‚ç‚¹æ£€æµ‹åœ¨ä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è®¡åˆ’ä¸­è‡³å…³é‡è¦ä¸”æå…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>LN-DETRæ–¹æ³•é€šè¿‡èåˆå¤šå°ºåº¦ç‰¹å¾å’Œå¤šç»´åº¦ä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜äº†æ£€æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>é‡‡ç”¨IoUé¢„æµ‹å¤´ä¸ä½ç½®åå·®æŸ¥è¯¢é€‰æ‹©æœºåˆ¶æé«˜äº†å®šä½ç²¾åº¦ã€‚</li>
<li>æŸ¥è¯¢å¯¹æ¯”å­¦ä¹ æŠ€æœ¯ç”¨äºå¼ºåŒ–åŒ¹é…åº¦å¹¶é™ä½è¯¯æŠ¥ç‡ã€‚</li>
<li>åœ¨å¤šä¸ªæ·‹å·´ç»“æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†æ£€æµ‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.03819">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5db1570717a6b907a4ca12a9af051b4a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c9de5004dfe536ab852148217041afa.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-678dae6a5a73578c56cc62201304accf.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  Planning with Diffusion Models for Target-Oriented Dialogue Systems
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f096359489037ae35bd135190185b633.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  VideoMark A Distortion-Free Robust Watermarking Framework for Video   Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28315.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
