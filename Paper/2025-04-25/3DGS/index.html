<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-04-25  Gaussian Splatting is an Effective Data Generator for 3D Object   Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-262bc6506c7b3beaf2f419f3f70498d5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    25 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-25-更新"><a href="#2025-04-25-更新" class="headerlink" title="2025-04-25 更新"></a>2025-04-25 更新</h1><h2 id="Gaussian-Splatting-is-an-Effective-Data-Generator-for-3D-Object-Detection"><a href="#Gaussian-Splatting-is-an-Effective-Data-Generator-for-3D-Object-Detection" class="headerlink" title="Gaussian Splatting is an Effective Data Generator for 3D Object   Detection"></a>Gaussian Splatting is an Effective Data Generator for 3D Object   Detection</h2><p><strong>Authors:Farhad G. Zanjani, Davide Abati, Auke Wiggers, Dimitris Kalatzis, Jens Petersen, Hong Cai, Amirhossein Habibian</strong></p>
<p>We investigate data augmentation for 3D object detection in autonomous driving. We utilize recent advancements in 3D reconstruction based on Gaussian Splatting for 3D object placement in driving scenes. Unlike existing diffusion-based methods that synthesize images conditioned on BEV layouts, our approach places 3D objects directly in the reconstructed 3D space with explicitly imposed geometric transformations. This ensures both the physical plausibility of object placement and highly accurate 3D pose and position annotations.   Our experiments demonstrate that even by integrating a limited number of external 3D objects into real scenes, the augmented data significantly enhances 3D object detection performance and outperforms existing diffusion-based 3D augmentation for object detection. Extensive testing on the nuScenes dataset reveals that imposing high geometric diversity in object placement has a greater impact compared to the appearance diversity of objects. Additionally, we show that generating hard examples, either by maximizing detection loss or imposing high visual occlusion in camera images, does not lead to more efficient 3D data augmentation for camera-based 3D object detection in autonomous driving. </p>
<blockquote>
<p>我们对自动驾驶中的3D目标检测数据增强进行了研究。我们利用基于高斯平铺的3D重建的最新进展，在驾驶场景中放置3D物体。与现有的基于扩散的方法不同，这些方法根据BEV布局合成图像，我们的方法直接在重建的3D空间中放置3D物体，并明确施加几何变换。这确保了物体放置的物理可行性以及高度准确的3D姿态和位置注释。我们的实验表明，即使只将有限数量的外部3D物体集成到真实场景中，增强数据也能显著提高3D目标检测性能，并优于现有的基于扩散的3D目标检测数据增强。在nuScenes数据集上的大量测试表明，在物体放置中施加高几何多样性比物体的外观多样性具有更大的影响。此外，我们还表明，通过最大化检测损失或在相机图像中施加高视觉遮挡来生成困难样本，并不会导致更有效的基于摄像头的自动驾驶3D目标检测的数据增强。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16740v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了基于高斯贴图技术的三维重建在自动驾驶领域的应用，特别是在数据增强方面的应用。该研究通过直接在重建的三维空间中放置三维物体，实现了物体放置的物理可行性和高度精确的3D姿态和位置标注。实验表明，即使只整合少量外部三维物体到真实场景中，增强数据也能显著提高三维物体检测性能，并优于现有的基于扩散的三维数据增强方法。在nuScenes数据集上的测试显示，在物体放置中引入高几何多样性比物体的外观多样性更具影响力。此外，本研究发现通过最大化检测损失或提高相机图像中的视觉遮挡来生成困难样本，并不会更有效地增强基于相机的三维物体检测性能。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>研究利用高斯贴图技术的三维重建进行自动驾驶中的数据增强。</li>
<li>在重建的三维空间中直接放置三维物体，确保了物体放置的物理可行性和精确的3D姿态和位置标注。</li>
<li>增强数据能提高三维物体检测性能，并优于现有扩散式三维数据增强方法。</li>
<li>在物体放置中引入高几何多样性对提升检测性能的影响更大。</li>
<li>生成困难样本（如最大化检测损失或高视觉遮挡）并不一定能有效增强基于相机的三维物体检测性能。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16740">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-a22ad4655a8ede9f672dcfaa9699969b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e1e217dbef9f2ee0328eb8b34a2e83b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-262bc6506c7b3beaf2f419f3f70498d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb629cb7605325fd5519f5b4a4c6c7e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-15ad44da3ea25f887c8d6b1073c7eb98.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation"><a href="#PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation" class="headerlink" title="PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation"></a>PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation</h2><p><strong>Authors:Wenxuan Li, Hang Zhao, Zhiyuan Yu, Yu Du, Qin Zou, Ruizhen Hu, Kai Xu</strong></p>
<p>While non-prehensile manipulation (e.g., controlled pushing&#x2F;poking) constitutes a foundational robotic skill, its learning remains challenging due to the high sensitivity to complex physical interactions involving friction and restitution. To achieve robust policy learning and generalization, we opt to learn a world model of the 3D rigid body dynamics involved in non-prehensile manipulations and use it for model-based reinforcement learning. We propose PIN-WM, a Physics-INformed World Model that enables efficient end-to-end identification of a 3D rigid body dynamical system from visual observations. Adopting differentiable physics simulation, PIN-WM can be learned with only few-shot and task-agnostic physical interaction trajectories. Further, PIN-WM is learned with observational loss induced by Gaussian Splatting without needing state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM into a group of Digital Cousins via physics-aware randomizations which perturb physics and rendering parameters to generate diverse and meaningful variations of the PIN-WM. Extensive evaluations on both simulation and real-world tests demonstrate that PIN-WM, enhanced with physics-aware digital cousins, facilitates learning robust non-prehensile manipulation skills with Sim2Real transfer, surpassing the Real2Sim2Real state-of-the-arts. </p>
<blockquote>
<p>非抓取操作（例如，受控的推动&#x2F;戳刺）构成了基础机器人技能的一部分，但由于其对涉及摩擦和恢复力的复杂物理交互的高度敏感性，其学习仍然具有挑战性。为了实现稳健的策略学习和泛化，我们选择学习涉及非抓取操作的三维刚体动力学世界模型，并将其用于基于模型的强化学习。我们提出了PIN-WM，即物理信息世界模型，能够实现从视觉观察中高效端到端地识别三维刚体动力学系统。通过采用可微分物理模拟，PIN-WM仅通过少量且任务无关的物理交互轨迹即可进行学习。此外，PIN-WM通过高斯投影(Splatting)产生的观测损失进行学习，无需进行状态估计。为了缩小模拟到现实的差距，我们将学到的PIN-WM通过物理感知随机化转化为一组数字同胞。物理感知随机化会干扰物理和渲染参数，从而生成PIN-WM多样且具意义的变体。在模拟和真实世界测试中的广泛评估表明，辅以物理感知的数字同胞的PIN-WM，能够促进学习具有模拟到现实迁移能力的稳健非抓取操作技能，超越当前最佳的Real2Sim2Real方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16693v1">PDF</a> </p>
<p><strong>Summary</strong><br>     针对非抓取操作（如控制推动&#x2F;戳刺）的机器人技能学习，面临复杂物理交互中的摩擦和恢复等挑战。我们提出一种基于物理信息的世界模型PIN-WM，通过视觉观察实现3D刚体动力学系统的端到端识别。采用可微分物理仿真，PIN-WM仅通过少量任务无关的物理解算轨迹进行学习。此外，我们通过高斯喷溅技术引入观测损失，无需状态估计。为解决模拟到现实的差距，我们将学到的PIN-WM转化为一系列物理感知的“数字分身”，通过扰动物理和渲染参数生成多样而有意义的模型变体。在模拟和真实世界测试中的广泛评估表明，增强物理感知的数字分身后的PIN-WM，在模拟到现实的转移学习中，能学习稳健的非抓取操作技能，超越当前最新的Real2Sim2Real技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>非抓取操作的机器人技能学习面临多种物理交互的挑战，如摩擦和恢复等。</li>
<li>提出一种基于物理信息的世界模型PIN-WM，实现从视觉观察的3D刚体动力学系统的端到端识别。</li>
<li>仅通过少量任务无关的物理解算轨迹，利用可微分物理仿真进行学习。</li>
<li>引入观测损失，无需状态估计，采用高斯喷溅技术。</li>
<li>将学到的PIN-WM转化为数字分身，通过物理感知的随机化缩小模拟与现实的差距。</li>
<li>在模拟和真实世界测试中的评估显示，PIN-WM能学习稳健的非抓取操作技能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16693">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6c6bac654c6fe6374ea09970c5f0ce40.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-650dc498b4b6715cc538deb1c022f2e5.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HUG-Hierarchical-Urban-Gaussian-Splatting-with-Block-Based-Reconstruction"><a href="#HUG-Hierarchical-Urban-Gaussian-Splatting-with-Block-Based-Reconstruction" class="headerlink" title="HUG: Hierarchical Urban Gaussian Splatting with Block-Based   Reconstruction"></a>HUG: Hierarchical Urban Gaussian Splatting with Block-Based   Reconstruction</h2><p><strong>Authors:Zhongtao Wang, Mai Su, Huishan Au, Yilong Li, Xizhe Cao, Chengwei Pan, Yisong Chen, Guoping Wang</strong></p>
<p>As urban 3D scenes become increasingly complex and the demand for high-quality rendering grows, efficient scene reconstruction and rendering techniques become crucial. We present HUG, a novel approach to address inefficiencies in handling large-scale urban environments and intricate details based on 3D Gaussian splatting. Our method optimizes data partitioning and the reconstruction pipeline by incorporating a hierarchical neural Gaussian representation. We employ an enhanced block-based reconstruction pipeline focusing on improving reconstruction quality within each block and reducing the need for redundant training regions around block boundaries. By integrating neural Gaussian representation with a hierarchical architecture, we achieve high-quality scene rendering at a low computational cost. This is demonstrated by our state-of-the-art results on public benchmarks, which prove the effectiveness and advantages in large-scale urban scene representation. </p>
<blockquote>
<p>随着城市三维场景日益复杂和对高质量渲染的需求不断增长，高效的场景重建和渲染技术变得至关重要。我们提出了HUG，这是一种基于3D高斯散斑处理大规模城市环境和复杂细节中的低效问题的新型方法。我们的方法通过融入分层神经高斯表示来优化数据分区和重建流程。我们采用基于块的重建流程，重点关注提高每个块内的重建质量，减少块边界周围冗余训练区域的需求。通过结合神经高斯表示和分层架构，我们在较低的计算成本下实现了高质量的场景渲染。我们在公共基准测试上的最新结果证明了我们的方法在大规模城市场景表示中的有效性和优势。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16606v1">PDF</a> </p>
<p><strong>Summary</strong><br>高复杂度城市三维场景渲染需求日益增长，提出一种基于三维高斯涂抹技术的高效场景重建和渲染方法HUG。该方法通过神经网络高斯表示的层次架构优化数据分区和重建流程，实现高质量场景渲染的低成本计算。在公共基准测试上的最新成果证明了其在大规模城市场景表示中的优势和有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>高效场景重建和渲染方法对于处理大规模城市环境和高复杂度细节至关重要。</li>
<li>HUG方法采用三维高斯涂抹技术，针对大规模城市环境处理的低效率问题提供全新解决方案。</li>
<li>通过神经网络高斯表示的层次架构，优化数据分区和重建流程。</li>
<li>增强块重建流程以提高每个块的重构质量并减少边界处冗余训练区域的必要。</li>
<li>实现高质量场景渲染的低成本计算。</li>
<li>在公共基准测试上的成果处于领先地位，证明了其在大规模城市场景表示中的优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16606">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a8298a18a90752599132ec8226095b14.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70f235e3339a23bac395cb28f5a4da6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e4077314f287148b5363373adced284a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ToF-Splatting-Dense-SLAM-using-Sparse-Time-of-Flight-Depth-and-Multi-Frame-Integration"><a href="#ToF-Splatting-Dense-SLAM-using-Sparse-Time-of-Flight-Depth-and-Multi-Frame-Integration" class="headerlink" title="ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and   Multi-Frame Integration"></a>ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and   Multi-Frame Integration</h2><p><strong>Authors:Andrea Conti, Matteo Poggi, Valerio Cambareri, Martin R. Oswald, Stefano Mattoccia</strong></p>
<p>Time-of-Flight (ToF) sensors provide efficient active depth sensing at relatively low power budgets; among such designs, only very sparse measurements from low-resolution sensors are considered to meet the increasingly limited power constraints of mobile and AR&#x2F;VR devices. However, such extreme sparsity levels limit the seamless usage of ToF depth in SLAM. In this work, we propose ToF-Splatting, the first 3D Gaussian Splatting-based SLAM pipeline tailored for using effectively very sparse ToF input data. Our approach improves upon the state of the art by introducing a multi-frame integration module, which produces dense depth maps by merging cues from extremely sparse ToF depth, monocular color, and multi-view geometry. Extensive experiments on both synthetic and real sparse ToF datasets demonstrate the viability of our approach, as it achieves state-of-the-art tracking and mapping performances on reference datasets. </p>
<blockquote>
<p>飞行时间（ToF）传感器能够在相对较低功耗预算下提供高效的主动深度感知；在这些设计中，只有从低分辨率传感器获取的极少数测量值被认为是满足移动设备和AR&#x2F;VR设备日益有限的电源约束。然而，这种极端的稀疏性限制了ToF深度在SLAM中的无缝使用。在这项工作中，我们提出了ToF-Splatting，这是第一个基于3D高斯Splatting的SLAM管道，专为有效利用非常稀疏的ToF输入数据而设计。我们的方法通过引入多帧集成模块改进了当前技术，该模块通过合并来自极稀疏的ToF深度、单目颜色和多视角几何的线索，生成密集的深度图。在合成和真实的稀疏ToF数据集上的大量实验证明了我们的方法的可行性，因为在参考数据集上，它实现了最先进的跟踪和映射性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16545v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ToF传感器能在较低的功耗下提供高效的主动深度感知，但其极度稀疏的测量数据限制了其在SLAM中的无缝应用。本文提出了ToF-Splatting，一种基于高斯分布的3D SLAM处理管道，可以有效利用极稀疏的ToF数据。该方法通过引入多帧融合模块，结合极稀疏的ToF深度、单目颜色和多视角几何信息生成密集的深度图，提高了现有方法的性能。在合成和真实稀疏ToF数据集上的实验验证了该方法的可行性，其在参考数据集上实现了最先进的跟踪和映射性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ToF传感器能在低功耗下提供深度感知，但稀疏测量限制了其在SLAM中的应用。</li>
<li>提出了一种新的方法ToF-Splatting，适用于极稀疏ToF数据的3D SLAM处理。</li>
<li>ToF-Splatting通过多帧融合模块生成密集深度图，结合ToF深度、单目颜色和多视角几何信息。</li>
<li>该方法在合成和真实稀疏ToF数据集上进行了广泛实验。</li>
<li>ToF-Splatting实现了在参考数据集上的最佳跟踪和映射性能。</li>
<li>此方法改善了现有技术的不足，为使用稀疏ToF数据提供了有效解决方案。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16545">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-55e766c3845573a16a28e3ef352d99b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-534a6c650e060bbaaabdb2ad73b2c7b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-41169244801f02e0bb6461efea874d43.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SEGA-Drivable-3D-Gaussian-Head-Avatar-from-a-Single-Image"><a href="#SEGA-Drivable-3D-Gaussian-Head-Avatar-from-a-Single-Image" class="headerlink" title="SEGA: Drivable 3D Gaussian Head Avatar from a Single Image"></a>SEGA: Drivable 3D Gaussian Head Avatar from a Single Image</h2><p><strong>Authors:Chen Guo, Zhuo Su, Jian Wang, Shuang Li, Xu Chang, Zhaohu Li, Yang Zhao, Guidong Wang, Ruqi Huang</strong></p>
<p>Creating photorealistic 3D head avatars from limited input has become increasingly important for applications in virtual reality, telepresence, and digital entertainment. While recent advances like neural rendering and 3D Gaussian splatting have enabled high-quality digital human avatar creation and animation, most methods rely on multiple images or multi-view inputs, limiting their practicality for real-world use. In this paper, we propose SEGA, a novel approach for Single-imagE-based 3D drivable Gaussian head Avatar creation that combines generalized prior models with a new hierarchical UV-space Gaussian Splatting framework. SEGA seamlessly combines priors derived from large-scale 2D datasets with 3D priors learned from multi-view, multi-expression, and multi-ID data, achieving robust generalization to unseen identities while ensuring 3D consistency across novel viewpoints and expressions. We further present a hierarchical UV-space Gaussian Splatting framework that leverages FLAME-based structural priors and employs a dual-branch architecture to disentangle dynamic and static facial components effectively. The dynamic branch encodes expression-driven fine details, while the static branch focuses on expression-invariant regions, enabling efficient parameter inference and precomputation. This design maximizes the utility of limited 3D data and achieves real-time performance for animation and rendering. Additionally, SEGA performs person-specific fine-tuning to further enhance the fidelity and realism of the generated avatars. Experiments show our method outperforms state-of-the-art approaches in generalization ability, identity preservation, and expression realism, advancing one-shot avatar creation for practical applications. </p>
<blockquote>
<p>创建具有真实感的3D头像化身从有限的输入在虚拟现实、远程出席和数字娱乐等应用中变得越来越重要。尽管最近的神经渲染和3D高斯延展等技术进步使得高质量数字人类化身创建和动画成为可能，但大多数方法仍依赖于多张图像或多视角输入，这限制了它们在现实世界应用中的实用性。在本文中，我们提出了SEGA，这是一种基于单图像的新型3D驾驶高斯头部化身创建方法，它将通用先验模型与新的层次化UV空间高斯延展框架相结合。SEGA无缝地将从大规模二维数据集推导出的先验与从多角度、多表情和多身份数据中学习的三维先验相结合，实现了对未见身份的稳健泛化，同时确保新型视角和表情下的三维一致性。我们还提出了一种层次化的UV空间高斯延展框架，它利用基于FLAME的结构先验，并采用双分支架构有效地分离动态和静态面部组件。动态分支编码表情驱动的精细细节，而静态分支则专注于表情不变的区域，从而实现有效的参数推断和预计算。这种设计最大限度地提高了有限三维数据的效用，实现了动画和渲染的实时性能。此外，SEGA还执行针对个人的微调，以进一步提高生成的化身的真实感和逼真度。实验表明，我们的方法在泛化能力、身份保留和表情逼真度方面优于最先进的方法，推动了单次拍摄化身创建的实际应用。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14373v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于单张图像创建3D可驱动高斯头像的技术SEGA。该技术结合了通用先验模型和新层次UV空间高斯溅落框架，实现了对未见身份的稳健泛化，同时确保在不同视角和表情下的3D一致性。SEGA利用大型二维数据集得出的先验知识和从多角度、多表情和多身份数据中学习的三维先验知识无缝结合，实现了高效参数推断和预计算。此外，SEGA还支持个性化微调，进一步提升生成的头像的逼真度和真实感。实验表明，该方法在泛化能力、身份保留和表情逼真方面优于现有技术，推动了一次性头像创建的实际应用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SEGA技术实现了基于单张图像创建3D可驱动高斯头像的新方法。</li>
<li>结合了通用先验模型与新层次UV空间高斯溅落框架。</li>
<li>技术实现了对未见身份的稳健泛化，确保了在不同视角和表情下的3D一致性。</li>
<li>利用大型二维数据集及多视角、多表情和多身份数据结合的先验知识。</li>
<li>采用高效参数推断和预计算设计，支持实时动画和渲染。</li>
<li>SEGA支持个性化微调，提高生成的头像的逼真度和真实感。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14373">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-88404abcf64ae55e8a7d8597cb0ea6ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ad034cfb49f39d4815618d104d0e58e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Luminance-GS-Adapting-3D-Gaussian-Splatting-to-Challenging-Lighting-Conditions-with-View-Adaptive-Curve-Adjustment"><a href="#Luminance-GS-Adapting-3D-Gaussian-Splatting-to-Challenging-Lighting-Conditions-with-View-Adaptive-Curve-Adjustment" class="headerlink" title="Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting   Conditions with View-Adaptive Curve Adjustment"></a>Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting   Conditions with View-Adaptive Curve Adjustment</h2><p><strong>Authors:Ziteng Cui, Xuangeng Chu, Tatsuya Harada</strong></p>
<p>Capturing high-quality photographs under diverse real-world lighting conditions is challenging, as both natural lighting (e.g., low-light) and camera exposure settings (e.g., exposure time) significantly impact image quality. This challenge becomes more pronounced in multi-view scenarios, where variations in lighting and image signal processor (ISP) settings across viewpoints introduce photometric inconsistencies. Such lighting degradations and view-dependent variations pose substantial challenges to novel view synthesis (NVS) frameworks based on Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). To address this, we introduce Luminance-GS, a novel approach to achieving high-quality novel view synthesis results under diverse challenging lighting conditions using 3DGS. By adopting per-view color matrix mapping and view-adaptive curve adjustments, Luminance-GS achieves state-of-the-art (SOTA) results across various lighting conditions – including low-light, overexposure, and varying exposure – while not altering the original 3DGS explicit representation. Compared to previous NeRF- and 3DGS-based baselines, Luminance-GS provides real-time rendering speed with improved reconstruction quality. </p>
<blockquote>
<p>在多样化的真实世界照明条件下捕捉高质量照片是一项挑战，因为自然光照（例如低光环境）和相机曝光设置（例如曝光时间）都会显著影响图像质量。这一挑战在多视角场景中尤为突出，其中不同视角的光照和图像信号处理器（ISP）设置变化会引入光度不一致性。这种光照退化和视角相关的变化给基于神经辐射场（NeRF）和3D高斯展布（3DGS）的新视角合成（NVS）框架带来了巨大挑战。为了解决这一问题，我们引入了Luminance-GS，这是一种利用3DGS在多样且具有挑战性的光照条件下实现高质量新视角合成结果的新方法。通过采用每视图颜色矩阵映射和视图自适应曲线调整，Luminance-GS在各种光照条件下实现了最先进的成果，包括低光、过曝和曝光变化，同时不改变原始3DGS显式表示。与之前的NeRF和3DGS基线相比，Luminance-GS提供了实时渲染速度并改善了重建质量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01503v2">PDF</a> CVPR 2025, project page:   <a target="_blank" rel="noopener" href="https://cuiziteng.github.io/Luminance_GS_web/">https://cuiziteng.github.io/Luminance_GS_web/</a></p>
<p><strong>Summary</strong><br>     针对真实世界多种光照条件下拍摄高质量照片的挑战，提出一种基于3DGS的Luminance-GS方法，通过采用视图色彩矩阵映射和视图自适应曲线调整，实现不同光照条件下的高质量视图合成。该方法在不改变原始3DGS显式表示的前提下，实现了跨各种光照条件，包括低光、过曝光和曝光变化等状态下的先进结果，同时提高了实时渲染速度和重建质量。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>真实世界多种光照条件对拍摄高质量照片带来挑战。</li>
<li>自然光照和相机曝光设置对图像质量有重要影响。</li>
<li>多视角场景中的光照变化和ISP设置会导致光度学不一致性。</li>
<li>光照退化和视角相关的变化给基于NeRF和3DGS的新视角合成（NVS）框架带来重大挑战。</li>
<li>提出一种基于3DGS的Luminance-GS方法，实现多种光照条件下的高质量视图合成。</li>
<li>通过视图色彩矩阵映射和视图自适应曲线调整，Luminance-GS在不同光照条件下达到先进结果。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01503">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-912d9426e6f1c9773207ac642fa6022a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d178aa2c017ef369fb2414f73a079403.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0d77b7cade783144fb29ae6054c1885.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8064f88da9ae906527cf71cbf1d9a992.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c2ded93e6712755127a771f8516b4c3.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GFreeDet-Exploiting-Gaussian-Splatting-and-Foundation-Models-for-Model-free-Unseen-Object-Detection-in-the-BOP-Challenge-2024"><a href="#GFreeDet-Exploiting-Gaussian-Splatting-and-Foundation-Models-for-Model-free-Unseen-Object-Detection-in-the-BOP-Challenge-2024" class="headerlink" title="GFreeDet: Exploiting Gaussian Splatting and Foundation Models for   Model-free Unseen Object Detection in the BOP Challenge 2024"></a>GFreeDet: Exploiting Gaussian Splatting and Foundation Models for   Model-free Unseen Object Detection in the BOP Challenge 2024</h2><p><strong>Authors:Xingyu Liu, Gu Wang, Chengxi Li, Yingyue Li, Chenyangguang Zhang, Ziqin Huang, Xiangyang Ji</strong></p>
<p>We present GFreeDet, an unseen object detection approach that leverages Gaussian splatting and vision Foundation models under model-free setting. Unlike existing methods that rely on predefined CAD templates, GFreeDet reconstructs objects directly from reference videos using Gaussian splatting, enabling robust detection of novel objects without prior 3D models. Evaluated on the BOP-H3 benchmark, GFreeDet achieves comparable performance to CAD-based methods, demonstrating the viability of model-free detection for mixed reality (MR) applications. Notably, GFreeDet won the best overall method and the best fast method awards in the model-free 2D detection track at BOP Challenge 2024. </p>
<blockquote>
<p>我们介绍了GFreeDet，这是一种无需特定模型背景的新对象检测法，该方法利用高斯平铺（Gaussian splatting）和视觉基础模型（vision Foundation models）。不同于依赖预先定义的CAD模板的现有方法，GFreeDet直接从参考视频重建对象并使用高斯平铺法实现无预设的鲁棒型新对象检测。在BOP-H3基准测试中评估，GFreeDet的性能与基于CAD的方法相当，证明了无模型检测在混合现实（MR）应用中的可行性。值得注意的是，GFreeDet在BOP Challenge 2024模型无关二维检测赛道上荣获最佳总体方法和最佳快速方法奖。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01552v4">PDF</a> CVPR 2025 CV4MR Workshop (citation style changed)</p>
<p><strong>Summary</strong></p>
<pre><code>GFreeDet是一种无预设对象检测新方法，其基于高斯渲染技术以及视觉模型模式来实现未定义物体检测。区别于以往依赖于CAD模板的方法，GFreeDet可直接通过参考视频重建物体，无需预先定义三维模型即可实现稳健的新物体检测。在BOP-H3标准的测试上表现优秀，甚至获得了BOP挑战模型无预设对象检测的杰出成绩与速度第一的佳绩，对于混合现实（MR）应用具有良好的前景。 
</code></pre>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GFreeDet利用高斯渲染技术实现了无需预设模型的物体检测。 </li>
<li>通过参考视频重建物体而非依赖预先定义的三维模型进行物体检测。 </li>
<li>GFreeDet在BOP-H3标准测试中表现优秀，与基于CAD的方法相比具有竞争力。 </li>
<li>GFreeDet为混合现实应用提供可行性模型无需预设检测方法的新选择。 </li>
<li>该方法在物体识别的应用创新上有突破性成果。 </li>
<li>GFreeDet获得模型无预设对象检测的最佳整体方法和最佳快速方法奖。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01552">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bd1673e729a2d5a818ccdc7574b38905.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9f2833dd016f196e88ced3de5e2b180d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-03cb8b28c5be75a23d04075d13d209b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5945b88821122f99f941a7612a7c93e5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69d2d1de50e4243a3221efa70d52c2ae.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-a83428bcc86901c8752a2d9cc90bd0e2.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-04-25  Beyond Anonymization Object Scrubbing for Privacy-Preserving 2D and 3D   Vision Tasks
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-88404abcf64ae55e8a7d8597cb0ea6ad.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-04-25  SEGA Drivable 3D Gaussian Head Avatar from a Single Image
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29774.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
