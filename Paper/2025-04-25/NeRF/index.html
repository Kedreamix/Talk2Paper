<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF 方向最新论文已更新，请持续关注 Update in 2025-04-25  Beyond Anonymization Object Scrubbing for Privacy-Preserving 2D and 3D   Vision Tasks">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-a83428bcc86901c8752a2d9cc90bd0e2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    21 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-25-更新"><a href="#2025-04-25-更新" class="headerlink" title="2025-04-25 更新"></a>2025-04-25 更新</h1><h2 id="Beyond-Anonymization-Object-Scrubbing-for-Privacy-Preserving-2D-and-3D-Vision-Tasks"><a href="#Beyond-Anonymization-Object-Scrubbing-for-Privacy-Preserving-2D-and-3D-Vision-Tasks" class="headerlink" title="Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D   Vision Tasks"></a>Beyond Anonymization: Object Scrubbing for Privacy-Preserving 2D and 3D   Vision Tasks</h2><p><strong>Authors:Murat Bilgehan Ertan, Ronak Sahu, Phuong Ha Nguyen, Kaleel Mahmood, Marten van Dijk</strong></p>
<p>We introduce ROAR (Robust Object Removal and Re-annotation), a scalable framework for privacy-preserving dataset obfuscation that eliminates sensitive objects instead of modifying them. Our method integrates instance segmentation with generative inpainting to remove identifiable entities while preserving scene integrity. Extensive evaluations on 2D COCO-based object detection show that ROAR achieves 87.5% of the baseline detection average precision (AP), whereas image dropping achieves only 74.2% of the baseline AP, highlighting the advantage of scrubbing in preserving dataset utility. The degradation is even more severe for small objects due to occlusion and loss of fine-grained details. Furthermore, in NeRF-based 3D reconstruction, our method incurs a PSNR loss of at most 1.66 dB while maintaining SSIM and improving LPIPS, demonstrating superior perceptual quality. Our findings establish object removal as an effective privacy framework, achieving strong privacy guarantees with minimal performance trade-offs. The results highlight key challenges in generative inpainting, occlusion-robust segmentation, and task-specific scrubbing, setting the foundation for future advancements in privacy-preserving vision systems. </p>
<blockquote>
<p>我们介绍了ROAR（Robust Object Removal and Re-annotation，鲁棒性对象移除与重新标注），这是一个用于隐私保护数据集模糊处理的可扩展框架，它能够消除敏感对象，而不是修改它们。我们的方法将实例分割与生成性补全相结合，以消除可识别实体，同时保留场景完整性。在基于COCO的二维目标检测上的广泛评估表明，ROAR实现了基线检测平均精度（AP）的87.5%，而图像丢弃仅实现了基线AP的74.2%，这突显了在保留数据集效用方面擦洗的优势。由于遮挡和丢失细节，小目标的退化更为严重。此外，在基于NeRF的三维重建中，我们的方法造成的峰值信噪比损失最多为1.66 dB，同时保持结构相似性度量指标，并改进了学习感知图像相似性度量指标，证明了其卓越的感知质量。我们的研究结果证明了对象移除作为一种有效的隐私保护框架，能够在实现强大的隐私保证的同时实现最小的性能折衷。结果突出了生成补全、遮挡稳健性分割和任务特定擦洗的关键挑战，为隐私保护视觉系统的未来进步奠定了基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16557v1">PDF</a> Submitted to ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出了一个名为ROAR的框架，用于实现隐私保护数据集混淆中的对象移除和重新标注。该框架结合了实例分割和生成填充技术，以消除可识别的实体同时保持场景完整性。在二维COCO目标检测上的评估显示，ROAR框架可实现基线检测平均精度的87.5%，而图像丢弃方法仅能达到基线AP的74.2%，突显了擦除方法在保持数据集效用方面的优势。在基于NeRF的三维重建中，该方法可实现最多PSNR损失的仅增加1.66dB，同时保持SSIM并改善LPIPS，展现出出色的感知质量。研究结果显示对象移除作为一种有效的隐私保护框架，在达到强隐私保证的同时实现了最小的性能权衡，为后续研究在保护隐私的视觉系统中取得了良好的推进基础。此外提出了众多关键的挑战性问题有待进一步研究如生成性填充、遮挡鲁棒分割和特定任务的擦除技术。这一技术将为保护敏感数据带来突破性的进展。总的来说，该研究为解决隐私保护和数据安全等问题提供了重要的参考和启示。其前瞻性和创新性强，前景广阔。本文中的技术和观点对未来数据处理和保护技术都将带来重大影响和贡献。   （请注意这段摘要总结了研究的核心内容和亮点，语言凝练、内容全面。） </p>
<p><strong>Key Takeaways</strong></p>
<p>以下是本论文的关键要点：</p>
<ul>
<li>ROAR框架结合了实例分割和生成填充技术，实现了隐私保护数据集混淆中的对象移除和重新标注。</li>
<li>ROAR框架在二维COCO目标检测上的评估中表现出较高的性能，相较于图像丢弃方法更具优势。</li>
<li>在基于NeRF的三维重建中，ROAR框架在保证感知质量的同时，可实现较高的隐私保护效果。然而对小物体的效果较为显著且易出现遮挡问题以及精细粒度细节的损失。因此仍存在需要解决的挑战性问题如生成性填充、遮挡鲁棒分割等。这一研究为后续保护隐私的视觉系统研究提供了重要的参考和启示。总体来说，该研究具有前瞻性和创新性，对解决隐私保护和数据安全等问题具有重要意义。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16557">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-e8c08ea0459addfec1a3fce121e5dace.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66269ce4085cd7631e93a71c9d6337c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c432ab8b9b6895cc422bc4d7ac57883.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SaENeRF-Suppressing-Artifacts-in-Event-based-Neural-Radiance-Fields"><a href="#SaENeRF-Suppressing-Artifacts-in-Event-based-Neural-Radiance-Fields" class="headerlink" title="SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields"></a>SaENeRF: Suppressing Artifacts in Event-based Neural Radiance Fields</h2><p><strong>Authors:Yuanjian Wang, Yufei Deng, Rong Xiao, Jiahao Fan, Chenwei Tang, Deng Xiong, Jiancheng Lv</strong></p>
<p>Event cameras are neuromorphic vision sensors that asynchronously capture changes in logarithmic brightness changes, offering significant advantages such as low latency, low power consumption, low bandwidth, and high dynamic range. While these characteristics make them ideal for high-speed scenarios, reconstructing geometrically consistent and photometrically accurate 3D representations from event data remains fundamentally challenging. Current event-based Neural Radiance Fields (NeRF) methods partially address these challenges but suffer from persistent artifacts caused by aggressive network learning in early stages and the inherent noise of event cameras. To overcome these limitations, we present SaENeRF, a novel self-supervised framework that effectively suppresses artifacts and enables 3D-consistent, dense, and photorealistic NeRF reconstruction of static scenes solely from event streams. Our approach normalizes predicted radiance variations based on accumulated event polarities, facilitating progressive and rapid learning for scene representation construction. Additionally, we introduce regularization losses specifically designed to suppress artifacts in regions where photometric changes fall below the event threshold and simultaneously enhance the light intensity difference of non-zero events, thereby improving the visual fidelity of the reconstructed scene. Extensive qualitative and quantitative experiments demonstrate that our method significantly reduces artifacts and achieves superior reconstruction quality compared to existing methods. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Mr-firework/SaENeRF">https://github.com/Mr-firework/SaENeRF</a>. </p>
<blockquote>
<p>事件相机是一种神经形态视觉传感器，能异步捕获对数亮度变化的改变，具有低延迟、低功耗、低带宽和高动态范围等显著优势。尽管这些特性使它们在高速场景下非常理想，但从事件数据中重建几何一致且光度准确的3D表示仍然具有根本性的挑战。当前的基于事件的神隐辐射场（NeRF）方法部分解决了这些挑战，但仍然存在由于早期网络学习的过度激烈和事件相机固有的噪声而导致的持久性伪影。为了克服这些局限性，我们提出了SaENeRF，这是一种新型的自监督框架，能够有效地抑制伪影，并仅从事件流中实现3D一致、密集且逼真的NeRF静态场景重建。我们的方法基于累积的事件极性对预测的辐射率变化进行归一化，促进了场景表示构建的渐进和快速学习。此外，我们引入了专门设计的正则化损失，以抑制在光度变化低于事件阈值的区域中的伪影，同时增强非零事件的亮度差异，从而提高重建场景的可视保真度。广泛的定性和定量实验表明，我们的方法显著减少了伪影，与现有方法相比实现了更高的重建质量。代码可在<a target="_blank" rel="noopener" href="https://github.com/Mr-firework/SaENeRF%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Mr-firework/SaENeRF上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16389v1">PDF</a> Accepted by IJCNN 2025</p>
<p><strong>Summary</strong></p>
<p>事件相机是一种神经形态视觉传感器，能异步捕捉对数亮度变化，具有低延迟、低功耗、低带宽和高动态范围等优点。尽管这些特点使事件相机在高速场景中表现出色，但从事件数据中重建几何一致且光度准确的3D表示仍然具有根本挑战性。当前的事件基础神经辐射场（NeRF）方法部分解决了这些挑战，但受限于早期网络学习的过度激烈和事件相机的固有噪声，导致重建结果出现持久性伪影。为了克服这些局限性，我们提出了SaENeRF，这是一种新型自监督框架，能有效抑制伪影，并能从事件流中重建出几何一致、密集且逼真的静态场景。我们的方法基于累积事件极性标准化预测辐射率变化，促进了场景表示结构的渐进和快速学习。此外，我们还引入了专门设计的正则化损失，以抑制低于事件阈值的区域中的伪影，同时增强非零事件的亮度差异，从而提高重建场景的视觉逼真度。实验证明，我们的方法显著减少了伪影，与现有方法相比实现了更高的重建质量。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>事件相机能异步捕捉对数亮度变化，具有多项优势如低延迟和低功耗等。</li>
<li>从事件数据中重建3D表示具有挑战，尤其是保持几何一致性和光度准确性。</li>
<li>当前NeRF方法在事件数据重建中面临网络过度学习和事件相机噪声导致的伪影问题。</li>
<li>SaENeRF是一种自监督框架，能有效抑制伪影并实现从事件流中重建出高质量的静态场景。</li>
<li>SaENeRF通过基于累积事件极性的预测辐射率变化标准化来改进场景重建。</li>
<li>引入正则化损失来抑制伪影并增强重建场景的视觉逼真度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16389">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-0188a19e6b1ed7320d9d68d024eca884.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0108d8b16bdf9276da35feeb496af7c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-daf877378b4d6e8db2099704d4b34f4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3d5637cddf5061ce7befec675708950.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-40a3d4674636ad6708259e429cdfa744.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="NeRF-APT-A-New-NeRF-Framework-for-Wireless-Channel-Prediction"><a href="#NeRF-APT-A-New-NeRF-Framework-for-Wireless-Channel-Prediction" class="headerlink" title="NeRF-APT: A New NeRF Framework for Wireless Channel Prediction"></a>NeRF-APT: A New NeRF Framework for Wireless Channel Prediction</h2><p><strong>Authors:Jingzhou Shen, Tianya Zhao, Yanzhao Wu, Xuyu Wang</strong></p>
<p>Neural radiance fields (NeRFs) have recently attracted significant attention in the field of wireless channel prediction, primarily due to their capability for high-fidelity reconstruction of complex wireless measurement environments. However, the ray-tracing component of NeRF-based methods faces challenges in realistically representing wireless scenarios, mainly due to the limited expressive power of multilayer perceptrons (MLPs). To overcome this issue, in this paper, we propose NeRF-APT, an encoder-decoder architecture integrated within a NeRF-based wireless channel prediction framework. Our architecture leverages the strengths of NeRF-like models in learning environmental features and exploits encoder-decoder modules’ capabilities for critical information extraction. Additionally, we incorporate an attention mechanism within the skip connections between encoder and decoder layers, significantly enhancing contextual understanding across layers. Extensive experimental evaluations conducted on several realistic and synthetic datasets demonstrate that our proposed method outperforms existing state-of-the-art approaches in wireless channel prediction. </p>
<blockquote>
<p>神经辐射场（NeRF）最近在无线信道预测领域引起了广泛关注，主要是由于其能够高保真地重建复杂的无线测量环境。然而，NeRF方法中的光线追踪部分在真实表示无线场景时面临挑战，这主要是由于多层感知器（MLP）的表达能力有限。为了克服这一问题，本文提出了NeRF-APT，这是一种集成在基于NeRF的无线信道预测框架中的编码器-解码器架构。我们的架构利用NeRF类模型在学习环境特征方面的优势，并探索编码器-解码器模块在提取关键信息方面的能力。此外，我们在编码器与解码器层之间的跳过连接中加入了注意力机制，显著增强了跨层上下文理解。在多个真实和合成数据集上进行的广泛实验评估表明，我们提出的方法在无线信道预测方面优于现有最先进的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16094v1">PDF</a> Accepted by IEEE INFOCOM WKSHPS: DeepWireless 2025: Deep Learning for   Wireless Communications, Sensing, and Security, to appear. 6 pages, 6   figures, 2 tables</p>
<p><strong>Summary</strong></p>
<p>本文介绍了NeRF技术在无线信道预测领域的应用。虽然NeRF能够重建复杂的无线测量环境，但其射线追踪部分在表示无线场景时面临挑战。为此，本文提出了NeRF-APT架构，将编码器解码器与NeRF结合，利用NeRF模型学习环境特征的能力，同时借助编码器解码器模块提取关键信息。此外，在编码器与解码器层之间的跳过连接中引入了注意力机制，显著提高了跨层上下文理解。实验评估表明，该方法在无线信道预测方面优于现有先进技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRF技术在无线信道预测中受到关注，因其能重建复杂的无线测量环境。</li>
<li>NeRF的射线追踪部分在表示无线场景时存在挑战，主要是由于多层感知机的表达力有限。</li>
<li>本文提出了NeRF-APT架构，结合了编码器解码器与NeRF技术。</li>
<li>NeRF-APT利用NeRF模型的学习环境特征能力，并借助编码器解码器模块提取关键信息。</li>
<li>在编码器与解码器层之间引入了注意力机制，提高了跨层上下文理解。</li>
<li>实验评估显示，NeRF-APT在无线信道预测方面优于现有技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16094">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8697ad43ebcdd30dca49252974aeca24.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f0b498577e5d623c18d1dfab3c93f2f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e25a1cec85d12cfd237de8fe2b41b0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-977c907ebd5ebbc80694e6777f5f138d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f1e50c206034d69d964d33b219dac92.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-56eff5c235fa9f990bcac0e9070c1ba1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2e885b718c9cfc9741d3855a3cd05a6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Luminance-GS-Adapting-3D-Gaussian-Splatting-to-Challenging-Lighting-Conditions-with-View-Adaptive-Curve-Adjustment"><a href="#Luminance-GS-Adapting-3D-Gaussian-Splatting-to-Challenging-Lighting-Conditions-with-View-Adaptive-Curve-Adjustment" class="headerlink" title="Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting   Conditions with View-Adaptive Curve Adjustment"></a>Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting   Conditions with View-Adaptive Curve Adjustment</h2><p><strong>Authors:Ziteng Cui, Xuangeng Chu, Tatsuya Harada</strong></p>
<p>Capturing high-quality photographs under diverse real-world lighting conditions is challenging, as both natural lighting (e.g., low-light) and camera exposure settings (e.g., exposure time) significantly impact image quality. This challenge becomes more pronounced in multi-view scenarios, where variations in lighting and image signal processor (ISP) settings across viewpoints introduce photometric inconsistencies. Such lighting degradations and view-dependent variations pose substantial challenges to novel view synthesis (NVS) frameworks based on Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). To address this, we introduce Luminance-GS, a novel approach to achieving high-quality novel view synthesis results under diverse challenging lighting conditions using 3DGS. By adopting per-view color matrix mapping and view-adaptive curve adjustments, Luminance-GS achieves state-of-the-art (SOTA) results across various lighting conditions – including low-light, overexposure, and varying exposure – while not altering the original 3DGS explicit representation. Compared to previous NeRF- and 3DGS-based baselines, Luminance-GS provides real-time rendering speed with improved reconstruction quality. </p>
<blockquote>
<p>在多样化的真实世界光照条件下捕捉高质量照片是一个挑战，因为自然光照（例如，低光环境）和相机曝光设置（例如，曝光时间）都会显著影响图像质量。这一挑战在多视角场景中更加突出，其中不同视角的光照和图像信号处理器（ISP）设置变化会导致光度不一致。这种光照退化和视角相关的变化给基于神经辐射场（NeRF）和三维高斯拼贴（3DGS）的新视角合成（NVS）框架带来了巨大挑战。为解决这一问题，我们引入了Luminance-GS这一新方法，通过采用每视图色彩矩阵映射和视图自适应曲线调整，实现在多样化挑战光照条件下高质量的新视角合成结果。Luminance-GS在各种光照条件下均取得了最新结果，包括低光、过曝光和可变曝光等，同时不改变原始的3DGS显式表示。与之前的NeRF和3DGS基线相比，Luminance-GS提供了实时渲染速度并改善了重建质量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01503v2">PDF</a> CVPR 2025, project page:   <a target="_blank" rel="noopener" href="https://cuiziteng.github.io/Luminance_GS_web/">https://cuiziteng.github.io/Luminance_GS_web/</a></p>
<p><strong>Summary</strong></p>
<p>这是一篇关于在多种真实世界光照条件下使用Neural Radiance Fields（NeRF）技术进行高质量视图合成的文章。为了解决因自然光照和相机曝光设置差异引起的照片质量问题和视图合成中的光度不一致问题，文章提出了一种名为Luminance-GS的新方法。该方法通过采用视图色彩矩阵映射和视图自适应曲线调整，实现了在不同光照条件下的高质量视图合成结果。Luminance-GS不仅达到了业界最佳性能，而且保持了原始的3DGS显式表示，同时提供了实时的渲染速度和更高的重建质量。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是文本的关键见解摘要：</p>
<ul>
<li>该文本探讨了在各种真实世界光照条件下实现高质量视图合成的挑战。</li>
<li>自然光照和相机曝光设置对图像质量有重要影响，特别是在多视角场景中。</li>
<li>一种名为Luminance-GS的新方法被提出来解决这一问题。</li>
<li>Luminance-GS通过采用视图色彩矩阵映射和视图自适应曲线调整，实现了在各种光照条件下的高质量视图合成结果。</li>
<li>与之前的NeRF和3DGS基线相比，Luminance-GS达到了业界最佳性能，同时保持了原始的3DGS显式表示。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01503">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-912d9426e6f1c9773207ac642fa6022a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d178aa2c017ef369fb2414f73a079403.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0d77b7cade783144fb29ae6054c1885.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8064f88da9ae906527cf71cbf1d9a992.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c2ded93e6712755127a771f8516b4c3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Dynamic-EventNeRF-Reconstructing-General-Dynamic-Scenes-from-Multi-view-RGB-and-Event-Streams"><a href="#Dynamic-EventNeRF-Reconstructing-General-Dynamic-Scenes-from-Multi-view-RGB-and-Event-Streams" class="headerlink" title="Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view   RGB and Event Streams"></a>Dynamic EventNeRF: Reconstructing General Dynamic Scenes from Multi-view   RGB and Event Streams</h2><p><strong>Authors:Viktor Rudnev, Gereon Fox, Mohamed Elgharib, Christian Theobalt, Vladislav Golyanik</strong></p>
<p>Volumetric reconstruction of dynamic scenes is an important problem in computer vision. It is especially challenging in poor lighting and with fast motion. This is partly due to limitations of RGB cameras: To capture frames under low lighting, the exposure time needs to be increased, which leads to more motion blur. In contrast, event cameras, which record changes in pixel brightness asynchronously, are much less dependent on lighting, making them more suitable for recording fast motion. We hence propose the first method to spatiotemporally reconstruct a scene from sparse multi-view event streams and sparse RGB frames. We train a sequence of cross-faded time-conditioned NeRF models, one per short recording segment. The individual segments are supervised with a set of event- and RGB-based losses and sparse-view regularisation. We assemble a real-world multi-view camera rig with six static event cameras around the object and record a benchmark multi-view event stream dataset of challenging motions. Our work outperforms RGB-based baselines, producing state-of-the-art results, and opens up the topic of multi-view event-based reconstruction as a new path for fast scene capture beyond RGB cameras. The code and the data will be released soon at <a target="_blank" rel="noopener" href="https://4dqv.mpi-inf.mpg.de/DynEventNeRF/">https://4dqv.mpi-inf.mpg.de/DynEventNeRF/</a> </p>
<blockquote>
<p>动态场景的体积重建是计算机视觉领域的一个重要问题。在光线不足和快速运动的情况下，这一问题尤为具有挑战性。这在一定程度上是由于RGB相机的局限性所致：在低光照条件下拍摄帧时，需要增加曝光时间，从而导致运动模糊。与之相比，事件相机能够异步记录像素亮度的变化，对光线的依赖程度较低，因此更适合记录快速运动。因此，我们提出了第一种从稀疏的多视角事件流和稀疏的RGB帧中进行时空重建场景的方法。我们对每段短记录分段训练了一系列交叉淡入的时间条件NeRF模型。各个分段在事件和RGB基于损失的稀疏视图正则化集下进行监督。我们使用六个静态事件相机围绕对象组装了一个现实世界的多视角相机支架，并记录了一个具有挑战性运动的多视角事件流基准数据集。我们的工作在基于RGB的基准线上表现出色，取得了最新结果，并开启了基于多视角事件重建的主题作为超越RGB相机进行快速场景捕获的新途径。代码和数据将很快在<a target="_blank" rel="noopener" href="https://4dqv.mpi-inf.mpg.de/DynEventNeRF/%E5%8F%91%E5%B8%83%E3%80%82">https://4dqv.mpi-inf.mpg.de/DynEventNeRF/发布。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06770v2">PDF</a> 17 pages, 13 figures, 7 tables; CVPRW 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于事件相机与稀疏RGB帧结合的方法，实现了动态场景的时空重建。该方法利用跨淡入时间条件NeRF模型序列进行训练，通过对一系列短记录段进行监督，并结合事件和RGB基损失以及稀疏视图正则化进行场景重建。本文还建立了一套用于记录挑战性运动的真实世界多视角相机装置，并发布了多视角事件流数据集。该方法优于基于RGB的基线方法，取得了最新结果，并开启了多视角事件重建作为超越RGB相机的快速场景捕获的新途径。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>动态场景的时空重建是计算机视觉领域的重要问题，特别是在光线不足和快速运动的情况下具有挑战性。</li>
<li>RGB相机在光线不足时存在局限性，而事件相机由于其能够异步记录像素亮度变化的特性，更适合记录快速运动场景。</li>
<li>本文首次提出结合稀疏多视角事件流和稀疏RGB帧进行场景重建的方法。</li>
<li>利用跨淡入时间条件的NeRF模型序列进行训练，每个短记录段一个模型。</li>
<li>通过事件和RGB基损失以及稀疏视图正则化来监督单独的片段。</li>
<li>建立了一套真实世界多视角相机装置，并记录了具有挑战性运动的多视角事件流数据集。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06770">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-a83428bcc86901c8752a2d9cc90bd0e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b52b4db702e2304ef97caddb6682d458.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ccb98073aa1dc95d023d152b45736bcc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f096359489037ae35bd135190185b633.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-25  VideoMark A Distortion-Free Robust Watermarking Framework for Video   Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-262bc6506c7b3beaf2f419f3f70498d5.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-04-25  Gaussian Splatting is an Effective Data Generator for 3D Object   Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23667.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
