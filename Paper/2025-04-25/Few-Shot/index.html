<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  GreenMind A Next-Generation Vietnamese Large Language Model for   Structured and Logical Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-480c930456ca8586b28e7967335f3609.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-28
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    37 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-25-æ›´æ–°"><a href="#2025-04-25-æ›´æ–°" class="headerlink" title="2025-04-25 æ›´æ–°"></a>2025-04-25 æ›´æ–°</h1><h2 id="GreenMind-A-Next-Generation-Vietnamese-Large-Language-Model-for-Structured-and-Logical-Reasoning"><a href="#GreenMind-A-Next-Generation-Vietnamese-Large-Language-Model-for-Structured-and-Logical-Reasoning" class="headerlink" title="GreenMind: A Next-Generation Vietnamese Large Language Model for   Structured and Logical Reasoning"></a>GreenMind: A Next-Generation Vietnamese Large Language Model for   Structured and Logical Reasoning</h2><p><strong>Authors:Luu Quy Tung, Hoang Quoc Viet, Vo Trong Thu</strong></p>
<p>Chain-of-Thought (CoT) is a robust approach for tackling LLM tasks that require intermediate reasoning steps prior to generating a final answer. In this paper, we present GreenMind-Medium-14B-R1, the Vietnamese reasoning model inspired by the finetuning strategy based on Group Relative Policy Optimization. We also leverage a high-quality Vietnamese synthesized reasoning dataset and design two reward functions to tackle the main limitations of this technique: (i) language mixing, where we explicitly detect the presence of biased language characters during the process of sampling tokens, and (ii) we leverage Sentence Transformer-based models to ensure that the generated reasoning content maintains factual correctness and does not distort the final output. Experimental results on the Vietnamese dataset from the VLSP 2023 Challenge demonstrate that our model outperforms prior works and enhances linguistic consistency in its responses. Furthermore, we extend our evaluation to SeaExam-a multilingual multiple-choice dataset, showing the effectiveness of our reasoning method compared to few-shot prompting techniques. </p>
<blockquote>
<p>é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„æ–¹æ³•ï¼Œç”¨äºè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¹‹å‰éœ€è¦ä¸­é—´æ¨ç†æ­¥éª¤ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GreenMind-Medium-14B-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè¶Šå—è¯­å’ŒåŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–å¾®è°ƒç­–ç•¥çš„æ¨ç†æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨é«˜è´¨é‡çš„è¶Šå—è¯­åˆæˆæ¨ç†æ•°æ®é›†ï¼Œå¹¶è®¾è®¡ä¸¤ç§å¥–åŠ±å‡½æ•°æ¥è§£å†³è¿™é¡¹æŠ€æœ¯çš„ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šï¼ˆiï¼‰è¯­è¨€æ··åˆé—®é¢˜ï¼Œå³åœ¨é‡‡æ ·æ ‡è®°è¿‡ç¨‹ä¸­æ˜ç¡®æ£€æµ‹æ˜¯å¦å­˜åœ¨æœ‰åè§çš„è¯­è¨€å­—ç¬¦ï¼›ï¼ˆiiï¼‰æˆ‘ä»¬åˆ©ç”¨åŸºäºå¥å­è½¬æ¢å™¨çš„æ¨¡å‹ç¡®ä¿ç”Ÿæˆçš„æ¨ç†å†…å®¹ä¿æŒäº‹å®æ­£ç¡®æ€§ï¼Œå¹¶ä¸æ­ªæ›²æœ€ç»ˆè¾“å‡ºã€‚åœ¨VLSP 2023æŒ‘æˆ˜èµ›æä¾›çš„è¶Šå—æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºå…ˆå‰çš„å·¥ä½œï¼Œå¹¶æé«˜äº†å“åº”çš„è¯­è¨€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è¯„ä¼°æ‰©å±•åˆ°SeaExamå¤šè¯­è¨€é€‰æ‹©é¢˜æ•°æ®é›†ï¼Œä»¥å±•ç¤ºæˆ‘ä»¬çš„æ¨ç†æ–¹æ³•ä¸å°‘æ ·æœ¬æç¤ºæŠ€æœ¯ç›¸æ¯”çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16832v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§æ¨¡å‹åœ¨é¢å¯¹éœ€è¦ä¸­é—´æ¨ç†æ­¥éª¤çš„ä»»åŠ¡æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚è¯­è¨€æ··åˆç­‰é—®é¢˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªè¶Šå—æ¨ç†æ¨¡å‹GreenMind-Medium-14B-R1ï¼Œå®ƒç»“åˆäº†é›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ç­–ç•¥è¿›è¡Œå¾®è°ƒã€‚åŒæ—¶åˆ©ç”¨é«˜è´¨é‡è¶Šå—åˆæˆæ¨ç†æ•°æ®é›†å’Œè®¾è®¡äº†ä¸¤ä¸ªå¥–åŠ±å‡½æ•°æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¶Šå—æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå…ˆå‰çš„å·¥ä½œï¼Œå¢å¼ºäº†è¯­è¨€ä¸€è‡´æ€§ï¼Œå¹¶åœ¨å¤šè¯­è¨€é€‰æ‹©é¢˜æ•°æ®é›†SeaExamä¸Šçš„è¯„ä¼°ä¸­ä¹ŸéªŒè¯äº†å…¶æ¨ç†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GreenMind-Medium-14B-R1æ˜¯ä¸€ä¸ªç”¨äºè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»»åŠ¡çš„è¶Šå—æ¨ç†æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹åŸºäºé›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ç­–ç•¥è¿›è¡Œå¾®è°ƒã€‚</li>
<li>åˆ©ç”¨äº†é«˜è´¨é‡è¶Šå—åˆæˆæ¨ç†æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>è®¾è®¡äº†ä¸¤ä¸ªå¥–åŠ±å‡½æ•°æ¥è§£å†³è¯­è¨€æ··åˆé—®é¢˜ï¼Œç¡®ä¿ç”Ÿæˆçš„æ¨ç†å†…å®¹ä¿æŒäº‹å®æ­£ç¡®æ€§å¹¶ä¸æ‰­æ›²æœ€ç»ˆè¾“å‡ºã€‚</li>
<li>åœ¨è¶Šå—æ•°æ®é›†VLSP 2023æŒ‘æˆ˜ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹è¡¨ç°ä¼˜äºå…ˆå‰çš„å·¥ä½œå¹¶å¢å¼ºäº†è¯­è¨€ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨å¤šè¯­è¨€é€‰æ‹©é¢˜æ•°æ®é›†SeaExamä¸Šçš„è¯„ä¼°éªŒè¯äº†å…¶æ¨ç†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16832">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-120fe8321b6ca7f69943f097207e9573.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91a207c19aeb0f019583136ae6f11b78.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d8be04f2bedb17ef2ecac18a332b022.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-683e0f869ff59f9ba7110afbb57bbe00.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation"><a href="#PIN-WM-Learning-Physics-INformed-World-Models-for-Non-Prehensile-Manipulation" class="headerlink" title="PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation"></a>PIN-WM: Learning Physics-INformed World Models for Non-Prehensile   Manipulation</h2><p><strong>Authors:Wenxuan Li, Hang Zhao, Zhiyuan Yu, Yu Du, Qin Zou, Ruizhen Hu, Kai Xu</strong></p>
<p>While non-prehensile manipulation (e.g., controlled pushing&#x2F;poking) constitutes a foundational robotic skill, its learning remains challenging due to the high sensitivity to complex physical interactions involving friction and restitution. To achieve robust policy learning and generalization, we opt to learn a world model of the 3D rigid body dynamics involved in non-prehensile manipulations and use it for model-based reinforcement learning. We propose PIN-WM, a Physics-INformed World Model that enables efficient end-to-end identification of a 3D rigid body dynamical system from visual observations. Adopting differentiable physics simulation, PIN-WM can be learned with only few-shot and task-agnostic physical interaction trajectories. Further, PIN-WM is learned with observational loss induced by Gaussian Splatting without needing state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM into a group of Digital Cousins via physics-aware randomizations which perturb physics and rendering parameters to generate diverse and meaningful variations of the PIN-WM. Extensive evaluations on both simulation and real-world tests demonstrate that PIN-WM, enhanced with physics-aware digital cousins, facilitates learning robust non-prehensile manipulation skills with Sim2Real transfer, surpassing the Real2Sim2Real state-of-the-arts. </p>
<blockquote>
<p>éæ¡æŒæ“ä½œï¼ˆä¾‹å¦‚ï¼Œå—æ§æ¨åŠ¨&#x2F;æˆ³åˆºï¼‰æ„æˆäº†ä¸€é¡¹åŸºæœ¬çš„æœºå™¨äººæŠ€èƒ½ï¼Œä½†å…¶å­¦ä¹ ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå…¶å¯¹æ¶‰åŠæ‘©æ“¦å’Œæ¢å¤åŠ›çš„å¤æ‚ç‰©ç†äº¤äº’çš„é«˜åº¦æ•æ„Ÿæ€§ã€‚ä¸ºäº†å®ç°ç¨³å¥çš„ç­–ç•¥å­¦ä¹ å’Œæ³›åŒ–ï¼Œæˆ‘ä»¬é€‰æ‹©å­¦ä¹ æ¶‰åŠéæ¡æŒæ“ä½œä¸­çš„3Dåˆšä½“åŠ¨åŠ›å­¦çš„ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶å°†å…¶ç”¨äºåŸºäºæ¨¡å‹å¢å¼ºå­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºPIN-WMï¼Œè¿™æ˜¯ä¸€ä¸ªPhysics-INformedä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°ä»è§†è§‰è§‚å¯Ÿä¸­ç«¯åˆ°ç«¯åœ°è¯†åˆ«å‡ºç”¨äºéæ¡æŒæ“ä½œçš„3Dåˆšä½“åŠ¨åŠ›å­¦ç³»ç»Ÿã€‚é€šè¿‡é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†æ¨¡æ‹Ÿï¼ŒPIN-WMä»…é€šè¿‡å°‘é‡å’Œä»»åŠ¡æ— å…³çš„ç‰©ç†äº¤äº’è½¨è¿¹å°±å¯ä»¥å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒPIN-WMé€šè¿‡é«˜æ–¯å¹³é“ºäº§ç”Ÿçš„è§‚æµ‹æŸå¤±è¿›è¡Œå­¦ä¹ ï¼Œæ— éœ€çŠ¶æ€ä¼°è®¡ã€‚ä¸ºäº†å¼¥ä»¿çœŸä¸ç°å®ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬é€šè¿‡ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–å°†å­¦ä¹ åˆ°çš„PIN-WMè½¬åŒ–ä¸ºä¸€ç»„æ•°å­—åˆ†èº«ï¼Œé€šè¿‡æ‰°åŠ¨ç‰©ç†å’Œæ¸²æŸ“å‚æ•°æ¥ç”ŸæˆPIN-WMçš„å¤šæ ·åŒ–å’Œæœ‰æ„ä¹‰çš„å˜ä½“ã€‚åœ¨ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå¢å¼ºä»¥ç‰©ç†æ„ŸçŸ¥çš„æ•°å­—åˆ†èº«åï¼ŒPIN-WMèƒ½å¤Ÿå€ŸåŠ©Sim2Realè½¬æ¢å­¦ä¹ ç¨³å¥çš„éæ¡æŒæ“ä½œæŠ€èƒ½ï¼Œè¶…è¶Šäº†æœ€æ–°çš„Real2Sim2RealæŠ€æœ¯æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16693v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éæ¡æŒå¼æ“ä½œï¼ˆå¦‚æ§åˆ¶æ¨åŠ¨&#x2F;æˆ³åˆºï¼‰æ˜¯æœºå™¨äººæŠ€æœ¯çš„åŸºæœ¬æŠ€èƒ½ä¹‹ä¸€ï¼Œä½†å…¶å­¦ä¹ ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°æ‘©æ“¦å’Œæ¢å¤ç­‰å¤æ‚ç‰©ç†äº¤äº’çš„é«˜åº¦æ•æ„Ÿæ€§ã€‚ä¸ºäº†å®ç°ç¨³å¥çš„ç­–ç•¥å­¦ä¹ å’Œæ³›åŒ–ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸€ä¸ªéæ¡æŒæ“ä½œæ‰€æ¶‰åŠçš„ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶å°†å…¶ç”¨äºåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬æå‡ºäº†PIN-WMï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç‰©ç†ä¿¡æ¯çš„ä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°ä»è§†è§‰è§‚å¯Ÿä¸­ç«¯åˆ°ç«¯åœ°è¯†åˆ«ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦ç³»ç»Ÿã€‚é€šè¿‡é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†ä»¿çœŸï¼ŒPIN-WMä»…é€šè¿‡å°‘é‡ä»»åŠ¡æ— å…³çš„å®ç‰©äº¤äº’è½¨è¿¹å³å¯å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒPIN-WMé€šè¿‡é«˜æ–¯æ–‘ç‚¹ï¼ˆGaussian Splattingï¼‰äº§ç”Ÿçš„è§‚æµ‹æŸå¤±è¿›è¡Œå­¦ä¹ ï¼Œæ— éœ€è¿›è¡ŒçŠ¶æ€ä¼°è®¡ã€‚ä¸ºäº†ç¼©çŸ­ä»¿çœŸä¸çœŸå®ä¸–ç•Œä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åˆ°çš„PIN-WMè½¬åŒ–ä¸ºä¸€ç³»åˆ—ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–çš„æ•°å­—åŒèƒã€‚åœ¨ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©ç‰©ç†æ„ŸçŸ¥çš„æ•°å­—åŒèƒå¢å¼ºçš„PIN-WMï¼Œèƒ½å­¦ä¹ åˆ°å…·æœ‰ä»¿çœŸåˆ°çœŸå®ä¸–ç•Œè¿ç§»èƒ½åŠ›çš„ç¨³å¥çš„éæ¡æŒå¼æ“ä½œæŠ€èƒ½ï¼Œè¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„çŠ¶æ€æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éæ¡æŒå¼æ“ä½œæ˜¯æœºå™¨äººæŠ€æœ¯ä¸­çš„é‡è¦åŸºç¡€æŠ€èƒ½ï¼Œä½†å¯¹å¤æ‚ç‰©ç†äº¤äº’çš„æ•æ„Ÿæ€§ä½¿å…¶å­¦ä¹ å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æå‡ºäº†PIN-WMæ¨¡å‹ï¼Œä¸€ä¸ªåŸºäºç‰©ç†ä¿¡æ¯çš„ä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºé«˜æ•ˆè¯†åˆ«ä¸‰ç»´åˆšä½“åŠ¨åŠ›å­¦ç³»ç»Ÿã€‚</li>
<li>é€šè¿‡é‡‡ç”¨å¯å¾®åˆ†ç‰©ç†ä»¿çœŸå’Œä»…ä½¿ç”¨å°‘é‡ä»»åŠ¡æ— å…³çš„å®ç‰©äº¤äº’è½¨è¿¹ï¼ŒPIN-WMèƒ½å¤Ÿå®ç°å­¦ä¹ ã€‚</li>
<li>PIN-WMé€šè¿‡é«˜æ–¯æ–‘ç‚¹äº§ç”Ÿçš„è§‚æµ‹æŸå¤±è¿›è¡Œå­¦ä¹ ï¼Œæ— éœ€è¿›è¡ŒçŠ¶æ€ä¼°è®¡ã€‚</li>
<li>ä¸ºäº†ç¼©çŸ­ä»¿çœŸä¸çœŸå®ä¸–ç•Œä¹‹é—´çš„å·®è·ï¼Œå°†PIN-WMè½¬åŒ–ä¸ºä¸€ç³»åˆ—ç‰©ç†æ„ŸçŸ¥éšæœºåŒ–çš„æ•°å­—åŒèƒã€‚</li>
<li>é€šè¿‡å¹¿æ³›è¯„ä¼°è¯æ˜ï¼ŒPIN-WMåœ¨ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œæµ‹è¯•ä¸­å‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16693">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6c6bac654c6fe6374ea09970c5f0ce40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-650dc498b4b6715cc538deb1c022f2e5.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Less-is-More-Enhancing-Structured-Multi-Agent-Reasoning-via-Quality-Guided-Distillation"><a href="#Less-is-More-Enhancing-Structured-Multi-Agent-Reasoning-via-Quality-Guided-Distillation" class="headerlink" title="Less is More: Enhancing Structured Multi-Agent Reasoning via   Quality-Guided Distillation"></a>Less is More: Enhancing Structured Multi-Agent Reasoning via   Quality-Guided Distillation</h2><p><strong>Authors:Jiahao Yuan, Xingzhe Sun, Xing Yu, Jingwen Wang, Dehui Du, Zhiqing Cui, Zixiang Di</strong></p>
<p>The XLLM@ACL2025 Shared Task-III formulates a low-resource structural reasoning task that challenges LLMs to generate interpretable, step-by-step rationales with minimal labeled data. We present Less is More, the third-place winning approach in the XLLM@ACL2025 Shared Task-III, which focuses on structured reasoning from only 24 labeled examples. Our approach leverages a multi-agent framework with reverse-prompt induction, retrieval-augmented reasoning synthesis via GPT-4o, and dual-stage reward-guided filtering to distill high-quality supervision across three subtasks: question parsing, CoT parsing, and step-level verification. All modules are fine-tuned from Meta-Llama-3-8B-Instruct under a unified LoRA+ setup. By combining structure validation with reward filtering across few-shot and zero-shot prompts, our pipeline consistently improves structure reasoning quality. These results underscore the value of controllable data distillation in enhancing structured inference under low-resource constraints. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/Jiahao-Yuan/Less-is-More">https://github.com/Jiahao-Yuan/Less-is-More</a>. </p>
<blockquote>
<p>XLLM@ACL2025å…±äº«ä»»åŠ¡IIIå»ºç«‹äº†ä¸€ä¸ªä½èµ„æºç»“æ„æ¨ç†ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æŒ‘æˆ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å°‘é‡æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ç”Ÿæˆå¯è§£é‡Šçš„ã€é€æ­¥çš„åˆç†æ€§è§£é‡Šã€‚æˆ‘ä»¬æå‡ºäº†â€æ›´å°‘å³æ˜¯æ›´å¤šâ€çš„æ–¹æ³•ï¼Œè¿™æ˜¯XLLM@ACL2025å…±äº«ä»»åŠ¡IIIçš„ç¬¬ä¸‰åè·å¥–æ–¹æ¡ˆï¼Œé‡ç‚¹æ˜¯ä»ä»…æœ‰çš„24ä¸ªæ ‡æ³¨æ ·æœ¬ä¸­è¿›è¡Œç»“æ„åŒ–æ¨ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶è¿›è¡Œé€†å‘æç¤ºå½’çº³ï¼Œé€šè¿‡GPT-4oå¢å¼ºæ£€ç´¢æ¨ç†åˆæˆï¼Œä»¥åŠä¸¤é˜¶æ®µå¥–åŠ±å¼•å¯¼è¿‡æ»¤ï¼Œä»¥æç‚¼å‡ºä¸‰ä¸ªå­ä»»åŠ¡çš„é«˜è´¨é‡ç›‘ç£ä¿¡æ¯ï¼šé—®é¢˜è§£æã€è®¤çŸ¥è½¨è¿¹è§£æå’Œæ­¥éª¤çº§éªŒè¯ã€‚æ‰€æœ‰æ¨¡å—éƒ½åœ¨ç»Ÿä¸€çš„LoRA+è®¾ç½®ä¸‹ï¼Œä»¥Meta-Llama-3-8B-Instructä¸ºåŸºç¡€è¿›è¡Œå¾®è°ƒã€‚é€šè¿‡ç»“åˆå°‘æ•°æ ·æœ¬å’Œé›¶æ ·æœ¬æç¤ºçš„ç»“æ„éªŒè¯ä¸å¥–åŠ±è¿‡æ»¤ï¼Œæˆ‘ä»¬çš„ç®¡é“åœ¨ç»“æ„æ¨ç†è´¨é‡ä¸ŠæŒç»­æé«˜ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åœ¨ä½èµ„æºçº¦æŸä¸‹å¯æ§æ•°æ®è’¸é¦åœ¨å¢å¼ºç»“æ„åŒ–æ¨æ–­ä¸­çš„ä»·å€¼ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Jiahao-Yuan/Less-is-More%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Jiahao-Yuan/Less-is-Moreæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16408v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ¨XLLM@ACL2025å…±äº«ä»»åŠ¡IIIä¸­ï¼Œä¸€ç§åä¸ºâ€œLess is Moreâ€çš„ç¬¬ä¸‰åèƒœå‡ºç­–ç•¥ã€‚è¯¥ç­–ç•¥åœ¨ä»…æœ‰24ä¸ªæ ‡æ³¨æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œè¿ç”¨å¤šä»£ç†æ¡†æ¶ã€åå‘æç¤ºè¯±å¯¼ã€æ£€ç´¢å¢å¼ºæ¨ç†åˆæˆå’ŒåŒé‡å¥–åŠ±å¼•å¯¼è¿‡æ»¤ç­‰æŠ€æœ¯ï¼Œå®ç°ç»“æ„åŒ–æ¨ç†ã€‚é€šè¿‡ç²¾ç»†è°ƒæ•´å„ä¸ªæ¨¡å—å¹¶ç»Ÿä¸€äºLoRA+è®¾ç½®ä¸‹ï¼Œç»“åˆç»“æ„éªŒè¯å’Œå¥–åŠ±è¿‡æ»¤ï¼Œè¯¥ç­–ç•¥åœ¨å°‘é‡æ ·æœ¬å’Œé›¶æ ·æœ¬æç¤ºä¸‹ä¸æ–­æé«˜ç»“æ„æ¨ç†è´¨é‡ï¼Œçªæ˜¾å¯æ§æ•°æ®è’¸é¦åœ¨å¢å¼ºä½èµ„æºçº¦æŸä¸‹çš„ç»“æ„åŒ–æ¨æ–­çš„ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XLLM@ACL2025 Shared Task-IIIæå‡ºäº†ä¸€ä¸ªä½èµ„æºç»“æ„æ¨ç†ä»»åŠ¡ï¼ŒæŒ‘æˆ˜LLMsåœ¨æœ€å°æ ‡æ³¨æ•°æ®ä¸‹ç”Ÿæˆé€æ­¥çš„ã€å¯è§£é‡Šçš„ç†ç”±ã€‚</li>
<li>â€œLess is Moreâ€ç­–ç•¥ä»…ä½¿ç”¨24ä¸ªæ ‡æ³¨æ ·æœ¬ï¼Œå¼ºè°ƒç»“æ„åŒ–æ¨ç†ã€‚</li>
<li>è¯¥ç­–ç•¥é‡‡ç”¨å¤šä»£ç†æ¡†æ¶ï¼Œç»“åˆåå‘æç¤ºè¯±å¯¼ã€æ£€ç´¢å¢å¼ºæ¨ç†åˆæˆå’ŒåŒé‡å¥–åŠ±å¼•å¯¼è¿‡æ»¤æŠ€æœ¯ã€‚</li>
<li>ä½¿ç”¨Meta-Llama-3-8B-Instructå¯¹å„ä¸ªæ¨¡å—è¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨ç»Ÿä¸€LoRA+è®¾ç½®ä¸‹è¿ä½œã€‚</li>
<li>é€šè¿‡ç»“æ„éªŒè¯å’Œå¥–åŠ±è¿‡æ»¤ï¼Œè¯¥ç­–ç•¥åœ¨å°‘é‡æ ·æœ¬å’Œé›¶æ ·æœ¬æç¤ºä¸‹æé«˜ç»“æ„æ¨ç†è´¨é‡ã€‚</li>
<li>è¯¥ç­–ç•¥çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Jiahao-Yuan/Less-is-More">https://github.com/Jiahao-Yuan/Less-is-More</a>å¤„è·å–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16408">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8645278a22cf2cf6e3f6962e9e256bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d18922a55dba8e7096aa4eaa35157bd9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c1266e302aa68a292d589d7247c120c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76c8df71fc8d5131af3b83050508ac25.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-712f7c0ec721062da8b311031b9b6f25.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Detecting-Actionable-Requests-and-Offers-on-Social-Media-During-Crises-Using-LLMs"><a href="#Detecting-Actionable-Requests-and-Offers-on-Social-Media-During-Crises-Using-LLMs" class="headerlink" title="Detecting Actionable Requests and Offers on Social Media During Crises   Using LLMs"></a>Detecting Actionable Requests and Offers on Social Media During Crises   Using LLMs</h2><p><strong>Authors:Ahmed El Fekih Zguir, Ferda Ofli, Muhammad Imran</strong></p>
<p>Natural disasters often result in a surge of social media activity, including requests for assistance, offers of help, sentiments, and general updates. To enable humanitarian organizations to respond more efficiently, we propose a fine-grained hierarchical taxonomy to systematically organize crisis-related information about requests and offers into three critical dimensions: supplies, emergency personnel, and actions. Leveraging the capabilities of Large Language Models (LLMs), we introduce Query-Specific Few-shot Learning (QSF Learning) that retrieves class-specific labeled examples from an embedding database to enhance the modelâ€™s performance in detecting and classifying posts. Beyond classification, we assess the actionability of messages to prioritize posts requiring immediate attention. Extensive experiments demonstrate that our approach outperforms baseline prompting strategies, effectively identifying and prioritizing actionable requests and offers. </p>
<blockquote>
<p>è‡ªç„¶ç¾å®³å¾€å¾€å¯¼è‡´ç¤¾äº¤åª’ä½“æ´»åŠ¨æ¿€å¢ï¼ŒåŒ…æ‹¬æ±‚åŠ©è¯·æ±‚ã€å¸®åŠ©æä¾›ã€æƒ…æ„Ÿå’Œä¸€èˆ¬æ›´æ–°ã€‚ä¸ºäº†ä½¿äººé“ä¸»ä¹‰ç»„ç»‡èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åº”å¯¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç²¾ç»†çš„å±‚æ¬¡åˆ†ç±»ä½“ç³»ï¼Œå°†å…³äºè¯·æ±‚å’Œæä¾›çš„å±æœºç›¸å…³ä¿¡æ¯ç³»ç»Ÿåœ°ç»„ç»‡ä¸ºä¸‰ä¸ªå…³é”®ç»´åº¦ï¼šç‰©èµ„ã€ç´§æ€¥äººå‘˜å’Œè¡ŒåŠ¨ã€‚æˆ‘ä»¬å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ï¼Œå¼•å…¥äº†æŸ¥è¯¢ç‰¹å®šå°‘æ ·æœ¬å­¦ä¹ ï¼ˆQSFå­¦ä¹ ï¼‰ï¼Œä»åµŒå…¥æ•°æ®åº“ä¸­æ£€ç´¢ç±»åˆ«ç‰¹å®šçš„æ ‡è®°ç¤ºä¾‹ï¼Œä»¥æé«˜æ¨¡å‹æ£€æµ‹å’Œåˆ†ç±»å¸–å­çš„æ€§èƒ½ã€‚é™¤äº†åˆ†ç±»ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜è¯„ä¼°äº†æ¶ˆæ¯çš„å¯æ“ä½œæ€§ï¼Œä»¥ä¼˜å…ˆå¤„ç†éœ€è¦ç«‹å³å…³æ³¨çš„å¸–å­ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºåŸºçº¿æç¤ºç­–ç•¥ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œä¼˜å…ˆå¤„ç†å¯æ“ä½œæ€§çš„è¯·æ±‚å’Œæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16144v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç²¾ç»†ç²’åº¦å±‚æ¬¡åˆ†ç±»çš„å±æœºç›¸å…³ä¿¡æ¯ç»„ç»‡æ–¹æ³•ï¼Œå°†æ•‘æ´éœ€æ±‚å’Œæ´åŠ©ä¿¡æ¯åˆ†ä¸ºä¾›åº”ã€ç´§æ€¥äººå‘˜å’Œè¡ŒåŠ¨ä¸‰ä¸ªå…³é”®ç»´åº¦ã€‚å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ï¼Œå¼•å…¥æŸ¥è¯¢ç‰¹å®šå°‘æ ·æœ¬å­¦ä¹ ï¼ˆQSF Learningï¼‰æŠ€æœ¯ï¼Œä»åµŒå…¥æ•°æ®åº“ä¸­æ£€ç´¢ç‰¹å®šç±»åˆ«çš„æ ‡ç­¾æ ·æœ¬ï¼Œä»¥æé«˜æ¨¡å‹å¯¹å¸–å­è¿›è¡Œæ£€æµ‹å’Œåˆ†ç±»çš„æ€§èƒ½ã€‚åŒæ—¶è¯„ä¼°ä¿¡æ¯çš„å¯æ“ä½œæ€§ï¼Œä»¥ä¼˜å…ˆå¤„ç†éœ€è¦ç«‹å³å…³æ³¨çš„å¸–å­ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºåŸºçº¿æç¤ºç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆè¯†åˆ«å’Œä¼˜å…ˆå¤„ç†å¯æ“ä½œçš„è¦æ±‚å’Œæ´åŠ©ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç„¶ç¾å®³ä¼šå¯¼è‡´ç¤¾äº¤åª’ä½“æ´»åŠ¨æ¿€å¢ï¼ŒåŒ…æ‹¬æ•‘æ´è¯·æ±‚ã€æ´åŠ©æä¾›ã€æƒ…æ„Ÿå’Œä¸€èˆ¬æ›´æ–°ç­‰ä¿¡æ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç²¾ç»†ç²’åº¦å±‚æ¬¡çš„å±æœºä¿¡æ¯åˆ†ç±»æ–¹æ³•ï¼Œå°†ç›¸å…³ä¿¡æ¯åˆ†ä¸ºä¾›åº”ã€ç´§æ€¥äººå‘˜å’Œè¡ŒåŠ¨ä¸‰ä¸ªç»´åº¦ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›è¿›è¡Œå±æœºä¿¡æ¯çš„åˆ†ç±»å’Œå¤„ç†ã€‚</li>
<li>å¼•å…¥æŸ¥è¯¢ç‰¹å®šå°‘æ ·æœ¬å­¦ä¹ ï¼ˆQSF Learningï¼‰ä»¥æé«˜æ¨¡å‹åœ¨æ£€æµ‹å’Œåˆ†ç±»å¸–å­æ–¹é¢çš„æ€§èƒ½ã€‚</li>
<li>é™¤äº†åˆ†ç±»å¤–ï¼Œè¿˜è¯„ä¼°äº†ä¿¡æ¯çš„å¯æ“ä½œæ€§ï¼Œä»¥ä¼˜å…ˆå¤„ç†éœ€è¦ç«‹å³å…³æ³¨çš„æ¶ˆæ¯ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯†åˆ«å’Œä¼˜å…ˆå¤„ç†å¯æ“ä½œè¦æ±‚å’Œæ´åŠ©ä¿¡æ¯æ–¹é¢ä¼˜äºåŸºçº¿æç¤ºç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16144">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-723fae82311b714d69d1ce08b69265af.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c86efc2b755aa63c8a55f2b90d6d2fc9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5fb38280df04f93bc9c8fb71ec25502.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CAPO-Cost-Aware-Prompt-Optimization"><a href="#CAPO-Cost-Aware-Prompt-Optimization" class="headerlink" title="CAPO: Cost-Aware Prompt Optimization"></a>CAPO: Cost-Aware Prompt Optimization</h2><p><strong>Authors:Tom Zehle, Moritz Schlager, Timo HeiÃŸ, Matthias Feurer</strong></p>
<p>Large language models (LLMs) have revolutionized natural language processing by solving a wide range of tasks simply guided by a prompt. Yet their performance is highly sensitive to prompt formulation. While automated prompt optimization addresses this challenge by finding optimal prompts, current methods require a substantial number of LLM calls and input tokens, making prompt optimization expensive. We introduce CAPO (Cost-Aware Prompt Optimization), an algorithm that enhances prompt optimization efficiency by integrating AutoML techniques. CAPO is an evolutionary approach with LLMs as operators, incorporating racing to save evaluations and multi-objective optimization to balance performance with prompt length. It jointly optimizes instructions and few-shot examples while leveraging task descriptions for improved robustness. Our extensive experiments across diverse datasets and LLMs demonstrate that CAPO outperforms state-of-the-art discrete prompt optimization methods in 11&#x2F;15 cases with improvements up to 21%p. Our algorithm achieves better performances already with smaller budgets, saves evaluations through racing, and decreases average prompt length via a length penalty, making it both cost-efficient and cost-aware. Even without few-shot examples, CAPO outperforms its competitors and generally remains robust to initial prompts. CAPO represents an important step toward making prompt optimization more powerful and accessible by improving cost-efficiency. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡ç®€å•çš„æç¤ºæŒ‡å¯¼è§£å†³äº†å¤šç§ä»»åŠ¡ï¼Œä»è€Œå½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†çš„æ ¼å±€ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æ€§èƒ½å¯¹æç¤ºçš„æ„æ€éå¸¸æ•æ„Ÿã€‚è™½ç„¶è‡ªåŠ¨æç¤ºä¼˜åŒ–å¯ä»¥é€šè¿‡æ‰¾åˆ°æœ€ä½³æç¤ºæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†å½“å‰çš„æ–¹æ³•éœ€è¦å¤§é‡çš„LLMè°ƒç”¨å’Œè¾“å…¥ä»¤ç‰Œï¼Œè¿™ä½¿å¾—æç¤ºä¼˜åŒ–æˆæœ¬é«˜æ˜‚ã€‚æˆ‘ä»¬å¼•å…¥äº†CAPOï¼ˆåŸºäºæˆæœ¬çš„æç¤ºä¼˜åŒ–ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é›†æˆAutoMLæŠ€æœ¯æé«˜æç¤ºä¼˜åŒ–æ•ˆç‡çš„ç®—æ³•ã€‚CAPOæ˜¯ä¸€ç§è¿›åŒ–æ–¹æ³•ï¼Œä»¥LLMä½œä¸ºæ“ä½œå‘˜ï¼Œç»“åˆæ¯”èµ›æ¥èŠ‚çœè¯„ä¼°å’Œå¤šç›®æ ‡ä¼˜åŒ–æ¥å¹³è¡¡æ€§èƒ½å’Œæç¤ºé•¿åº¦ã€‚å®ƒè”åˆä¼˜åŒ–æŒ‡ä»¤å’Œå°‘é‡ç¤ºä¾‹ï¼Œå¹¶åˆ©ç”¨ä»»åŠ¡æè¿°æ¥æé«˜ç¨³å¥æ€§ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†å’ŒLLMä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œåœ¨15ä¸ªæ¡ˆä¾‹ä¸­ï¼ŒCAPOåœ¨11ä¸ªæ¡ˆä¾‹ä¸­çš„æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„ç¦»æ•£æç¤ºä¼˜åŒ–æ–¹æ³•ï¼Œæ”¹è¿›å¹…åº¦é«˜è¾¾21%ã€‚æˆ‘ä»¬çš„ç®—æ³•åœ¨è¾ƒå°çš„é¢„ç®—ä¸‹å°±è¾¾åˆ°äº†æ›´å¥½çš„æ€§èƒ½ï¼Œé€šè¿‡æ¯”èµ›èŠ‚çœäº†è¯„ä¼°å·¥ä½œï¼Œå¹¶é€šè¿‡é•¿åº¦æƒ©ç½šå‡å°‘äº†å¹³å‡æç¤ºé•¿åº¦ï¼Œè¿™ä½¿å¾—å®ƒæ—¢ç»æµåˆæ³¨é‡æˆæœ¬æ•ˆç›Šã€‚å³ä½¿æ²¡æœ‰å°‘é‡ç¤ºä¾‹ï¼ŒCAPOä¹Ÿèƒ½è¶…è¶Šç«äº‰å¯¹æ‰‹ï¼Œå¹¶ä¸”å¯¹åˆå§‹æç¤ºä¿æŒç¨³å¥ã€‚CAPOä»£è¡¨ç€é€šè¿‡æé«˜æˆæœ¬æ•ˆç›Šï¼Œæœç€ä½¿æç¤ºä¼˜åŒ–æ›´å…·åŠ›é‡å’Œå¯è®¿é—®æ€§çš„é‡è¦ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16005v2">PDF</a> Submitted to AutoML 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡æç¤ºå¼•å¯¼è§£å†³å¤šç§ä»»åŠ¡ï¼Œä½†æ€§èƒ½å¯¹æç¤ºåˆ¶å®šéå¸¸æ•æ„Ÿã€‚å½“å‰è‡ªåŠ¨åŒ–æç¤ºä¼˜åŒ–æ–¹æ³•éœ€è¦å¤§é‡LLMè°ƒç”¨å’Œè¾“å…¥ä»¤ç‰Œï¼Œä½¿å¾—æç¤ºä¼˜åŒ–æˆæœ¬é«˜æ˜‚ã€‚æˆ‘ä»¬å¼•å…¥CAPOï¼ˆæˆæœ¬æ„ŸçŸ¥æç¤ºä¼˜åŒ–ï¼‰ï¼Œé€šè¿‡é›†æˆAutoMLæŠ€æœ¯æé«˜æç¤ºä¼˜åŒ–æ•ˆç‡ã€‚CAPOé‡‡ç”¨è¿›åŒ–æ–¹æ³•ï¼Œä»¥LLMä½œä¸ºæ“ä½œå‘˜ï¼Œèå…¥ç«èµ›ä»¥èŠ‚çœè¯„ä¼°å’Œå¤šç›®æ ‡ä¼˜åŒ–ä»¥å¹³è¡¡æ€§èƒ½ä¸æç¤ºé•¿åº¦ã€‚å®ƒè”åˆä¼˜åŒ–æŒ‡ä»¤å’Œå°‘é‡ç¤ºä¾‹ï¼Œå¹¶åˆ©ç”¨ä»»åŠ¡æè¿°æé«˜ç¨³å¥æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒCAPOåœ¨å¤šæ•°æƒ…å†µä¸‹ä¼˜äºæœ€æ–°ç¦»æ•£æç¤ºä¼˜åŒ–æ–¹æ³•ï¼Œå¹¶åœ¨é¢„ç®—è¾ƒå°çš„æƒ…å†µä¸‹å®ç°æ›´å¥½çš„æ€§èƒ½ï¼Œé€šè¿‡ç«èµ›èŠ‚çœè¯„ä¼°ï¼Œå¹¶é€šè¿‡é•¿åº¦æƒ©ç½šå‡å°‘å¹³å‡æç¤ºé•¿åº¦ï¼Œæ—¢èŠ‚çº¦æˆæœ¬åˆé«˜æ•ˆã€‚å³ä½¿ä¸ä¾èµ–å°‘é‡ç¤ºä¾‹ï¼ŒCAPOä¹Ÿèƒ½ç¨³å¥åº”å¯¹åˆå§‹æç¤ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡æç¤ºå¼•å¯¼å®Œæˆå¤šç§ä»»åŠ¡ï¼Œä½†æç¤ºåˆ¶å®šå¯¹å…¶æ€§èƒ½å½±å“æ˜¾è‘—ã€‚</li>
<li>å½“å‰è‡ªåŠ¨åŒ–æç¤ºä¼˜åŒ–æ–¹æ³•æˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦æ”¹è¿›æ•ˆç‡ã€‚</li>
<li>CAPOç®—æ³•é€šè¿‡é›†æˆAutoMLæŠ€æœ¯æé«˜æç¤ºä¼˜åŒ–æ•ˆç‡ï¼Œé‡‡ç”¨è¿›åŒ–æ–¹æ³•å¹¶ç»“åˆç«èµ›ä»¥èŠ‚çœè¯„ä¼°å’Œå¤šç›®æ ‡ä¼˜åŒ–ã€‚</li>
<li>CAPOè”åˆä¼˜åŒ–æŒ‡ä»¤å’Œå°‘é‡ç¤ºä¾‹ï¼Œåˆ©ç”¨ä»»åŠ¡æè¿°å¢å¼ºç¨³å¥æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒCAPOåœ¨å¤šæ•°æƒ…å†µä¸‹ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå¹¶åœ¨é¢„ç®—æœ‰é™çš„æƒ…å†µä¸‹å®ç°æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>CAPOé€šè¿‡èŠ‚çœè¯„ä¼°ã€å‡å°‘å¹³å‡æç¤ºé•¿åº¦ç­‰æ–¹å¼é™ä½æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16005">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-96d2b66d95ef53b3c1effb07481879e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b116fd3254b73260dad8b5aba0aa636b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fba975ea5ea648e831c5bf75967937cd.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Chain-of-Thought-Textual-Reasoning-for-Few-shot-Temporal-Action-Localization"><a href="#Chain-of-Thought-Textual-Reasoning-for-Few-shot-Temporal-Action-Localization" class="headerlink" title="Chain-of-Thought Textual Reasoning for Few-shot Temporal Action   Localization"></a>Chain-of-Thought Textual Reasoning for Few-shot Temporal Action   Localization</h2><p><strong>Authors:Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma</strong></p>
<p>Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the modelâ€™s ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark. </p>
<blockquote>
<p>ä¼ ç»Ÿçš„æ—¶é—´åŠ¨ä½œå®šä½ï¼ˆTALï¼‰æ–¹æ³•ä¾èµ–äºå¤§é‡çš„è¯¦ç»†æ ‡æ³¨æ•°æ®ï¼Œè€Œå°‘æ ·æœ¬TALé€šè¿‡ä»…ä½¿ç”¨å°‘é‡çš„è®­ç»ƒæ ·æœ¬æ¥å‡å°‘æœªè§åŠ¨ä½œç±»åˆ«çš„è¯†åˆ«ä¾èµ–ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å°‘æ ·æœ¬TALæ–¹æ³•é€šå¸¸åªå…³æ³¨è§†é¢‘å±‚é¢çš„ä¿¡æ¯ï¼Œå¿½ç•¥äº†æ–‡æœ¬ä¿¡æ¯ï¼Œè¿™äº›æ–‡æœ¬ä¿¡æ¯å¯ä»¥ä¸ºå®šä½ä»»åŠ¡æä¾›æœ‰ä»·å€¼çš„è¯­ä¹‰æ”¯æŒã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡Chain-of-Thoughtçš„æ–‡æœ¬æ¨ç†æå‡ºäº†ä¸€ç§æ–°çš„å°‘æ ·æœ¬æ—¶é—´åŠ¨ä½œå®šä½æ–¹æ³•ï¼Œä»¥æé«˜å®šä½æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„åŸºäºæ–‡æœ¬è¯­ä¹‰ä¿¡æ¯çš„å°‘æ ·æœ¬å­¦ä¹ æ¡†æ¶ï¼Œä»¥æé«˜æ¨¡å‹æ•æ‰åŠ¨ä½œå…±æ€§å’Œå˜åŒ–çš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªè¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬è§†è§‰å¯¹é½æ¨¡å—ï¼Œæ—¨åœ¨åœ¨ä¸åŒå±‚æ¬¡ä¸Šå¯¹é½æŸ¥è¯¢å’Œæ”¯æŒè§†é¢‘ã€‚åŒæ—¶ï¼Œä¸ºäº†æ›´å¥½åœ°è¡¨è¾¾æ–‡æœ¬å±‚é¢åŠ¨ä½œçš„æ—¶ç©ºä¾èµ–å’Œå› æœå…³ç³»ï¼Œè¾…åŠ©åŠ¨ä½œå®šä½ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç±»ä¼¼Chain of Thoughtï¼ˆCoTï¼‰çš„æ¨ç†æ–¹æ³•ï¼Œé€æ­¥å¼•å¯¼è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆé’ˆå¯¹è§†é¢‘çš„CoTæ–‡æœ¬æè¿°ã€‚ç”Ÿæˆçš„æ–‡æœ¬å¯ä»¥æ•è·æ¯”è§†è§‰ç‰¹å¾æ›´å¤šçš„åŠ¨ä½œå˜åŒ–ã€‚æˆ‘ä»¬åœ¨å…¬å¼€å¯ç”¨çš„ActivityNet1.3å’ŒTHUMOS14æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†åä¸ºHuman-related Anomaly Localizationçš„æ–°æ•°æ®é›†ï¼Œå¹¶æ¢è®¨äº†TALä»»åŠ¡åœ¨äººç±»å¼‚å¸¸æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å•å®ä¾‹å’Œå¤šå®ä¾‹åœºæ™¯ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æˆ‘ä»¬å°†å…¬å¼€æˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’ŒåŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13460v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºChain-of-Thoughtæ–‡æœ¬æ¨ç†çš„æ–°çš„å°‘æ ·æœ¬æ—¶åºåŠ¨ä½œå®šä½æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªè¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬è§†è§‰å¯¹é½æ¨¡å—ï¼Œå¹¶åœ¨æŸ¥è¯¢å’Œæ”¯æŒè§†é¢‘çš„ä¸åŒå±‚æ¬¡ä¸Šè¿›è¡Œå¯¹é½ã€‚åŒæ—¶ï¼Œä¸ºäº†æ›´å¥½åœ°åœ¨æ–‡æœ¬å±‚é¢è¡¨è¾¾åŠ¨ä½œçš„æ—¶ç©ºä¾èµ–å’Œå› æœå…³ç³»ï¼Œè®¾è®¡äº†ä¸€ç§ç±»ä¼¼Chain of Thoughtï¼ˆCoTï¼‰çš„æ¨ç†æ–¹æ³•ï¼Œé€æ­¥å¼•å¯¼è§†è§‰è¯­è¨€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆè§†é¢‘çš„CoTæ–‡æœ¬æè¿°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•å®ä¾‹å’Œå¤šå®ä¾‹åœºæ™¯ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å°‘æ ·æœ¬æ—¶åºåŠ¨ä½œå®šä½æ–¹æ³•ï¼Œç»“åˆChain-of-Thoughtæ–‡æœ¬æ¨ç†ï¼Œé™ä½å¯¹å¤§é‡è¯¦ç»†æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚</li>
<li>è®¾è®¡äº†è¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬è§†è§‰å¯¹é½æ¨¡å—ï¼Œåˆ©ç”¨æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯æé«˜æ¨¡å‹æ•æ‰åŠ¨ä½œå…±æ€§å’Œå˜åŒ–çš„èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥äº†ç±»ä¼¼Chain of Thoughtï¼ˆCoTï¼‰çš„æ¨ç†æ–¹æ³•ï¼Œæ›´å¥½åœ°åœ¨æ–‡æœ¬å±‚é¢è¡¨è¾¾åŠ¨ä½œçš„æ—¶ç©ºä¾èµ–å’Œå› æœå…³ç³»ã€‚</li>
<li>ç”Ÿæˆçš„æ–‡æœ¬æè¿°èƒ½æ•æ‰æ¯”è§†è§‰ç‰¹å¾æ›´å¤šçš„åŠ¨ä½œå˜åŒ–ã€‚</li>
<li>åœ¨å…¬å¼€æ•°æ®é›†ActivityNet1.3å’ŒTHUMOS14ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æ„å»ºäº†åä¸ºHuman-related Anomaly Localizationçš„æ–°æ•°æ®é›†ï¼Œæ¢ç´¢äº†æ—¶åºåŠ¨ä½œå®šä½åœ¨äººä½“å¼‚å¸¸æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13460">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c82b1047594130439a760a575b62acce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-531c4a7812ecaeccde9b4e989a71d861.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7c213dbbcc1e0229555b467cf4aa97d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="7B-Fully-Open-Source-Moxin-LLM-â€“-From-Pretraining-to-GRPO-based-Reinforcement-Learning-Enhancement"><a href="#7B-Fully-Open-Source-Moxin-LLM-â€“-From-Pretraining-to-GRPO-based-Reinforcement-Learning-Enhancement" class="headerlink" title="7B Fully Open Source Moxin-LLM â€“ From Pretraining to GRPO-based   Reinforcement Learning Enhancement"></a>7B Fully Open Source Moxin-LLM â€“ From Pretraining to GRPO-based   Reinforcement Learning Enhancement</h2><p><strong>Authors:Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang</strong></p>
<p>Recently, Large Language Models (LLMs) have undergone a significant transformation, marked by a rapid rise in both their popularity and capabilities. Leading this evolution are proprietary LLMs like GPT-4 and GPT-o1, which have captured widespread attention in the AI community due to their remarkable performance and versatility. Simultaneously, open-source LLMs, such as LLaMA, have made great contributions to the ever-increasing popularity of LLMs due to the ease to customize and deploy the models across diverse applications. Although open-source LLMs present unprecedented opportunities for innovation and research, the commercialization of LLMs has raised concerns about transparency, reproducibility, and safety. Many open-source LLMs fail to meet fundamental transparency requirements by withholding essential components like training code and data, which may hinder further innovations on LLMs. To mitigate this issue, we introduce Moxin 7B, a fully open-source LLM developed, adhering to principles of open science, open source, open data, and open access. We release the pre-training code and configurations, training and fine-tuning datasets, and intermediate and final checkpoints, aiming to make continuous commitments to fully open-source LLMs. After pre-training and obtaining the base model, we finetune the Moxin Base model with SOTA post-training framework and instruction data to obtain Moxin Instruct model. To improve the reasoning capability, we further finetune our Instruct model with chain-of-thought data distilled from DeepSeek R1, and then use Group Relative Policy Optimization (GRPO), an efficient and effective reinforcement learning algorithm following DeepSeek R1, to finetune our model, leading to the Moxin Reasoning model. Experiments show that our models achieve superior performance in various evaluations such as zero-shot evaluation, few-shot evaluation, and CoT evaluation. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»å†äº†é‡å¤§è½¬å˜ï¼Œå…¶å—æ¬¢è¿ç¨‹åº¦å’Œèƒ½åŠ›éƒ½è¿…é€Ÿä¸Šå‡ã€‚å¼•é¢†è¿™ä¸€å˜é©çš„æ˜¯åƒGPT-4å’ŒGPT-o1è¿™æ ·çš„ä¸“æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”±äºå®ƒä»¬å‡ºè‰²çš„æ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§ï¼Œå®ƒä»¬åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚åŒæ—¶ï¼Œå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚LLaMAï¼Œç”±äºå¯¹æ¨¡å‹è¿›è¡Œå®šåˆ¶å’Œè·¨ä¸åŒåº”ç”¨ç¨‹åºéƒ¨ç½²çš„ä¾¿åˆ©æ€§ï¼Œä¹Ÿä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æ—¥ç›Šæ™®åŠåšå‡ºäº†å·¨å¤§è´¡çŒ®ã€‚ç„¶è€Œï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å•†ä¸šåŒ–å¼•å‘äº†å…³äºé€æ˜åº¦ã€å¯å¤åˆ¶æ€§å’Œå®‰å…¨çš„æ‹…å¿§ã€‚è®¸å¤šå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹æœªèƒ½æ»¡è¶³åŸºæœ¬çš„é€æ˜åº¦è¦æ±‚ï¼Œå› ä¸ºä»–ä»¬éšç’äº†å…³é”®çš„ç»„æˆéƒ¨åˆ†ï¼Œå¦‚è®­ç»ƒä»£ç å’Œæ•°æ®ï¼Œè¿™å¯èƒ½é˜»ç¢å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥åˆ›æ–°ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†å®Œå…¨ç¬¦åˆå…¬å¼€ç§‘å­¦åŸåˆ™çš„å¤§å‹è¯­è¨€æ¨¡å‹â€”â€”å¢¨å¿ƒ7Bã€‚è¯¥æ¨¡å‹é‡‡ç”¨å¼€æºã€å¼€æ”¾æ•°æ®ã€å¼€æ”¾è®¿é—®çš„åŸåˆ™ã€‚æˆ‘ä»¬å…¬å¼€äº†é¢„è®­ç»ƒä»£ç å’Œé…ç½®ã€è®­ç»ƒå’Œå¾®è°ƒæ•°æ®é›†ä»¥åŠä¸­é—´å’Œæœ€ç»ˆæ£€æŸ¥ç‚¹ï¼Œè‡´åŠ›äºå®Œå…¨å¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚åœ¨é¢„è®­ç»ƒå’Œè·å–åŸºç¡€æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€æ–°çš„åè®­ç»ƒæ¡†æ¶å’ŒæŒ‡ä»¤æ•°æ®å¯¹å¢¨å¿ƒåŸºç¡€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥è·å–å¢¨å¿ƒæŒ‡ä»¤æ¨¡å‹ã€‚ä¸ºäº†æé«˜æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥ä½¿ç”¨æ¥è‡ªDeepSeek R1çš„è’¸é¦æ€ç»´é“¾æ•°æ®å¯¹æŒ‡ä»¤æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶é‡‡ç”¨è·ŸéšDeepSeek R1çš„é«˜æ•ˆæœ‰æ•ˆå¼ºåŒ–å­¦ä¹ ç®—æ³•â€”â€”ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¥å¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œä»è€Œå¾—åˆ°å¢¨å¿ƒæ¨ç†æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨é›¶æ ·æœ¬è¯„ä¼°ã€å°‘æ ·æœ¬è¯„ä¼°å’Œæ€ç»´é“¾è¯„ä¼°ç­‰å„ä¸ªæ–¹é¢éƒ½å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06845v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢†åŸŸæ­£ç»å†ä¸€æ¬¡é‡å¤§å˜é©ï¼Œä»¥GPT-4å’ŒGPT-o1ä¸ºä»£è¡¨çš„ä¸“æœ‰LLMä»¥åŠLLaMAç­‰å¼€æºLLMçš„å…´èµ·æ¨åŠ¨äº†è¿™ä¸€å˜é©ã€‚ç„¶è€Œï¼Œå•†ä¸šåŒ–çš„åŒæ—¶ï¼Œä¹Ÿå­˜åœ¨é€æ˜åº¦ã€å¯é‡å¤æ€§å’Œå®‰å…¨æ€§ç­‰æ–¹é¢çš„æ‹…å¿§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†éµå¾ªå…¬å¼€ç§‘å­¦ã€å¼€æºã€å¼€æ”¾æ•°æ®å’Œå¼€æ”¾è®¿é—®åŸåˆ™çš„å…¨æ–°å¼€æºLLMâ€”â€”Moxin 7Bã€‚è¯¥æ¨¡å‹å…¬å¼€äº†é¢„è®­ç»ƒä»£ç å’Œé…ç½®ã€è®­ç»ƒå’Œå¾®è°ƒæ•°æ®é›†ä»¥åŠä¸­é—´å’Œæœ€ç»ˆæ£€æŸ¥ç‚¹ã€‚é€šè¿‡ä¸€ç³»åˆ—çš„è®­ç»ƒå’Œä¼˜åŒ–è¿‡ç¨‹ï¼ŒMoxinæ¨¡å‹è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨ç»å†é‡å¤§å˜é©ï¼Œä¸“æœ‰å’Œå¼€æºLLMçš„å…´èµ·æ¨åŠ¨äº†è¿™ä¸€å˜é©ã€‚</li>
<li>å•†ä¸šåŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹å¼•å‘äº†é€æ˜åº¦ã€å¯é‡å¤æ€§å’Œå®‰å…¨æ€§çš„æ‹…å¿§ã€‚</li>
<li>Moxin 7Bæ˜¯ä¸€ä¸ªå…¨æ–°çš„å¼€æºLLMï¼Œéµå¾ªå…¬å¼€ç§‘å­¦ã€å¼€æºã€å¼€æ”¾æ•°æ®å’Œå¼€æ”¾è®¿é—®åŸåˆ™ã€‚</li>
<li>Moxin 7Bå…¬å¼€äº†é¢„è®­ç»ƒä»£ç å’Œé…ç½®ã€è®­ç»ƒå’Œå¾®è°ƒæ•°æ®é›†ã€‚</li>
<li>Moxinæ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—çš„è®­ç»ƒå’Œä¼˜åŒ–è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä½¿ç”¨SOTAåè®­ç»ƒæ¡†æ¶ã€æŒ‡ä»¤æ•°æ®ã€æ€ç»´é“¾æ•°æ®å’ŒGroup Relative Policy Optimizationï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œå¾®è°ƒã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒMoxinæ¨¡å‹åœ¨é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œæ€ç»´é“¾è¯„ä¼°ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹æœ‰åŠ©äºæ¨åŠ¨åˆ›æ–°å’Œç ”ç©¶çš„è¿›æ­¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06845">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-480c930456ca8586b28e7967335f3609.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b06a6046dedb172c22ce330e93623dc8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Synthetic-Lyrics-Detection-Across-Languages-and-Genres"><a href="#Synthetic-Lyrics-Detection-Across-Languages-and-Genres" class="headerlink" title="Synthetic Lyrics Detection Across Languages and Genres"></a>Synthetic Lyrics Detection Across Languages and Genres</h2><p><strong>Authors:Yanis Labrak, Markus Frohmann, Gabriel Meseguer-Brocal, Elena V. Epure</strong></p>
<p>In recent years, the use of large language models (LLMs) to generate music content, particularly lyrics, has gained in popularity. These advances provide valuable tools for artists and enhance their creative processes, but they also raise concerns about copyright violations, consumer satisfaction, and content spamming. Previous research has explored content detection in various domains. However, no work has focused on the text modality, lyrics, in music. To address this gap, we curated a diverse dataset of real and synthetic lyrics from multiple languages, music genres, and artists. The generation pipeline was validated using both humans and automated methods. We performed a thorough evaluation of existing synthetic text detection approaches on lyrics, a previously unexplored data type. We also investigated methods to adapt the best-performing features to lyrics through unsupervised domain adaptation. Following both music and industrial constraints, we examined how well these approaches generalize across languages, scale with data availability, handle multilingual language content, and perform on novel genres in few-shot settings. Our findings show promising results that could inform policy decisions around AI-generated music and enhance transparency for users. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”ŸæˆéŸ³ä¹å†…å®¹ï¼Œç‰¹åˆ«æ˜¯æ­Œè¯ï¼Œè¶Šæ¥è¶Šå—æ¬¢è¿ã€‚è¿™äº›è¿›æ­¥ä¸ºè‰ºæœ¯å®¶æä¾›äº†æœ‰ä»·å€¼çš„å·¥å…·ï¼Œå¢å¼ºäº†ä»–ä»¬çš„åˆ›ä½œè¿‡ç¨‹ï¼Œä½†ä¹Ÿå¼•å‘äº†å…³äºç‰ˆæƒä¾µçŠ¯ã€æ¶ˆè´¹è€…æ»¡æ„åº¦å’Œå†…å®¹åƒåœ¾å¹¿å‘Šçš„æ‹…å¿§ã€‚ä¹‹å‰çš„ç ”ç©¶å·²ç»åœ¨å„ä¸ªé¢†åŸŸæ¢ç´¢äº†å†…å®¹æ£€æµ‹ã€‚ç„¶è€Œï¼Œæ²¡æœ‰ç ”ç©¶ä¸“æ³¨äºéŸ³ä¹ä¸­çš„æ–‡æœ¬æ¨¡å¼â€”â€”æ­Œè¯ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬ä»å¤šç§è¯­è¨€ã€éŸ³ä¹æµæ´¾å’Œè‰ºæœ¯å®¶ä¸­ç²¾å¿ƒç­–åˆ’äº†ä¸€ä¸ªçœŸå®å’Œåˆæˆæ­Œè¯çš„å¤šæ ·åŒ–æ•°æ®é›†ã€‚ç”Ÿæˆç®¡é“é€šè¿‡äººå·¥å’Œè‡ªåŠ¨åŒ–æ–¹æ³•è¿›è¡Œäº†éªŒè¯ã€‚æˆ‘ä»¬å¯¹æ­Œè¯çš„ç°æœ‰åˆæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¿™æ˜¯ä¸€ç§ä»¥å‰æœªè¢«æ¢ç´¢è¿‡çš„æ•°æ®ç±»å‹ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†é€šè¿‡æ— ç›‘ç£åŸŸé€‚åº”è°ƒæ•´æœ€ä½³æ€§èƒ½ç‰¹å¾ä»¥é€‚åº”æ­Œè¯çš„æ–¹æ³•ã€‚éµå¾ªéŸ³ä¹å’Œå·¥ä¸šçº¦æŸï¼Œæˆ‘ä»¬ç ”ç©¶äº†è¿™äº›æ–¹æ³•åœ¨ä¸åŒè¯­è¨€ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€éšç€æ•°æ®å¯ç”¨æ€§è€Œæ‰©å±•çš„èƒ½åŠ›ã€å¤„ç†å¤šè¯­è¨€ç¯å¢ƒå†…å®¹å’Œåœ¨å°‘æ•°æƒ…å†µä¸‹çš„æ–°æµæ´¾è¡¨ç°èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå‘ˆç°å‡ºå¯å–œçš„ç»“æœï¼Œå¯ä»¥ä¸ºå…³äºäººå·¥æ™ºèƒ½ç”ŸæˆéŸ³ä¹çš„æ”¿ç­–å†³ç­–æä¾›ä¿¡æ¯ï¼Œå¹¶å¢å¼ºç”¨æˆ·çš„é€æ˜åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15231v3">PDF</a> Published in the workshop TrustNLP @ NAACL</p>
<p><strong>æ‘˜è¦</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éŸ³ä¹å†…å®¹ç”Ÿæˆä¸­çš„åº”ç”¨æ—¥ç›Šæ™®åŠï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆæ­Œè¯æ–¹é¢ã€‚è¿™äº›è¿›å±•ä¸ºè‰ºæœ¯å®¶æä¾›äº†æœ‰ä»·å€¼çš„å·¥å…·å¹¶ä¿ƒè¿›äº†ä»–ä»¬çš„åˆ›é€ æ€§è¿‡ç¨‹ï¼Œä½†åŒæ—¶ä¹Ÿå¼•å‘äº†å…³äºç‰ˆæƒä¾µçŠ¯ã€æ¶ˆè´¹è€…æ»¡æ„åº¦å’Œå†…å®¹æ»¥ç”¨çš„æ‹…å¿§ã€‚ä»¥å‰çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†ä¸åŒé¢†åŸŸçš„å†…å®¹æ£€æµ‹ï¼Œä½†å°šæœªå…³æ³¨éŸ³ä¹ä¸­çš„æ–‡æœ¬æ¨¡å¼â€”â€”æ­Œè¯ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬ç¼–çº‚äº†ä¸€ä¸ªåŒ…å«å¤šç§è¯­è¨€ã€éŸ³ä¹æµæ´¾å’Œè‰ºæœ¯å®¶åˆ›ä½œçš„çœŸå®å’Œåˆæˆæ­Œè¯çš„å¤šæ ·åŒ–æ•°æ®é›†ã€‚åˆ©ç”¨äººç±»å’Œè‡ªåŠ¨åŒ–æ–¹æ³•éªŒè¯äº†ç”Ÿæˆç®¡é“çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å¯¹ç°æœ‰åˆæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œé’ˆå¯¹æ­Œè¯è¿™ä¸€ä»¥å‰æœªè¢«æ¢ç´¢çš„æ•°æ®ç±»å‹ï¼Œæˆ‘ä»¬è¿˜è°ƒæŸ¥äº†é€šè¿‡æ— ç›‘ç£åŸŸé€‚åº”è°ƒæ•´æœ€ä½³æ€§èƒ½ç‰¹å¾çš„æ–¹æ³•ã€‚éµå¾ªéŸ³ä¹å’Œå·¥ä¸šçº¦æŸï¼Œæˆ‘ä»¬ç ”ç©¶äº†è¿™äº›æ–¹æ³•åœ¨å¤šè¯­è¨€ã€æ•°æ®å¯ç”¨æ€§ã€å¤„ç†å¤šè¯­è¨€å†…å®¹å’Œå°‘æ•°é•œå¤´è®¾ç½®ä¸­è¡¨ç°æ–°æµæ´¾æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœä¸ºäººå·¥æ™ºèƒ½ç”Ÿæˆçš„éŸ³ä¹çš„æ”¿ç­–å†³ç­–æä¾›äº†ä¿¡æ¯ï¼Œå¹¶æé«˜äº†å¯¹ç”¨æˆ·çš„é€æ˜åº¦ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éŸ³ä¹å†…å®¹ç”Ÿæˆä¸­çš„åº”ç”¨æ­£åœ¨æ™®åŠï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆæ­Œè¯æ–¹é¢ã€‚</li>
<li>æ­Œè¯ç”Ÿæˆå¸¦æ¥äº†ç‰ˆæƒä¾µçŠ¯ç­‰æ‹…å¿§ã€‚</li>
<li>ç›®å‰å°šæœªæœ‰é’ˆå¯¹æ­Œè¯çš„æ–‡æœ¬åˆæˆæ£€æµ‹ç ”ç©¶ã€‚</li>
<li>ç¼–çº‚äº†ä¸€ä¸ªåŒ…å«çœŸå®å’Œåˆæˆæ­Œè¯çš„å¤šæ ·åŒ–æ•°æ®é›†ï¼Œæ¶µç›–å¤šç§è¯­è¨€å’ŒéŸ³ä¹æµæ´¾ã€‚</li>
<li>å¯¹ç°æœ‰åˆæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•è¿›è¡Œäº†æ­Œè¯ä¸Šçš„å…¨é¢è¯„ä¼°ã€‚</li>
<li>æ¢è®¨äº†å¦‚ä½•é€šè¿‡æ— ç›‘ç£åŸŸé€‚åº”è°ƒæ•´æœ€ä½³æ€§èƒ½ç‰¹å¾çš„æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶å‘ç°è¡¨æ˜ï¼Œå¯¹äºäººå·¥æ™ºèƒ½ç”Ÿæˆçš„éŸ³ä¹çš„æ”¿ç­–å†³ç­–å’Œç”¨æˆ·é€æ˜åº¦æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15231">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6fe3fd6026add57d3e1c612bd5075438.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec2c466c35d546e3e826f88641b2b6fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c919f86581e5fce6e0c5fdfcce47b56.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-27a26204eb36c3479255134958020fb4.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CLAP-Isolating-Content-from-Style-through-Contrastive-Learning-with-Augmented-Prompts"><a href="#CLAP-Isolating-Content-from-Style-through-Contrastive-Learning-with-Augmented-Prompts" class="headerlink" title="CLAP: Isolating Content from Style through Contrastive Learning with   Augmented Prompts"></a>CLAP: Isolating Content from Style through Contrastive Learning with   Augmented Prompts</h2><p><strong>Authors:Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi</strong></p>
<p>Contrastive vision-language models, such as CLIP, have garnered considerable attention for various downstream tasks, mainly due to the remarkable ability of the learned features for generalization. However, the features they learned often blend content and style information, which somewhat limits their generalization capabilities under distribution shifts. To address this limitation, we adopt a causal generative perspective for multimodal data and propose contrastive learning with data augmentation to disentangle content features from the original representations. To achieve this, we begin with exploring image augmentation techniques and develop a method to seamlessly integrate them into pre-trained CLIP-like models to extract pure content features. Taking a step further, recognizing the inherent semantic richness and logical structure of text data, we explore the use of text augmentation to isolate latent content from style features. This enables CLIP-like modelâ€™s encoders to concentrate on latent content information, refining the learned representations by pre-trained CLIP-like models. Our extensive experiments across diverse datasets demonstrate significant improvements in zero-shot and few-shot classification tasks, alongside enhanced robustness to various perturbations. These results underscore the effectiveness of our proposed methods in refining vision-language representations and advancing the state-of-the-art in multimodal learning. </p>
<blockquote>
<p>å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¦‚CLIPï¼Œåœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å—åˆ°äº†æå¤§çš„å…³æ³¨ï¼Œè¿™ä¸»è¦å½’åŠŸäºå…¶å­¦ä¹ ç‰¹å¾çš„å‡ºè‰²æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å­¦ä¹ çš„ç‰¹å¾å¾€å¾€ä¼šæ··åˆå†…å®¹å’Œé£æ ¼ä¿¡æ¯ï¼Œè¿™åœ¨æŸç§ç¨‹åº¦ä¸Šé™åˆ¶äº†å®ƒä»¬åœ¨åˆ†å¸ƒè½¬ç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨å› æœç”Ÿæˆè§†è§’è¿›è¡Œå¤šæ¨¡æ€æ•°æ®ç ”ç©¶ï¼Œå¹¶æå‡ºç»“åˆæ•°æ®å¢å¼ºçš„å¯¹æ¯”å­¦ä¹ æ¥ä»åŸå§‹è¡¨ç¤ºä¸­åˆ†ç¦»å†…å®¹ç‰¹å¾ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆæ¢ç´¢å›¾åƒå¢å¼ºæŠ€æœ¯ï¼Œå¹¶å¼€å‘äº†ä¸€ç§æ–¹æ³•ï¼Œå°†å…¶æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒçš„CLIPç±»æ¨¡å‹ä¸­ï¼Œä»¥æå–çº¯å†…å®¹ç‰¹å¾ã€‚æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°æ–‡æœ¬æ•°æ®å›ºæœ‰çš„è¯­ä¹‰ä¸°å¯Œæ€§å’Œé€»è¾‘ç»“æ„ï¼Œæ¢ç´¢ä½¿ç”¨æ–‡æœ¬å¢å¼ºæ¥åˆ†ç¦»æ½œåœ¨å†…å®¹ä¸é£æ ¼ç‰¹å¾ã€‚è¿™å¯ä»¥è®©CLIPç±»æ¨¡å‹çš„ç¼–ç å™¨ä¸“æ³¨äºæ½œåœ¨å†…å®¹ä¿¡æ¯ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„CLIPç±»æ¨¡å‹ä¼˜åŒ–å­¦ä¹ è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œå¯¹å„ç§æ‰°åŠ¨çš„é²æ£’æ€§ä¹Ÿæœ‰æ‰€å¢å¼ºã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨ä¼˜åŒ–è§†è§‰è¯­è¨€è¡¨ç¤ºå’Œå¤šæ¨¡æ€å­¦ä¹ æ–¹é¢çš„å…ˆè¿›æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.16445v6">PDF</a> Accepted as a conference paper at ECCV 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨å¤„ç†ä¸‹æ¸¸ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œå…¶å­¦åˆ°çš„ç‰¹å¾å¾€å¾€èåˆäº†å†…å®¹å’Œé£æ ¼ä¿¡æ¯ï¼Œé™åˆ¶äº†å…¶åœ¨åˆ†å¸ƒå˜åŒ–ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡é‡‡ç”¨å› æœç”Ÿæˆè§†è§’å’Œå¤šæ¨¡æ€æ•°æ®ï¼Œæå‡ºä½¿ç”¨å¯¹æ¯”å­¦ä¹ å’Œæ•°æ®å¢å¼ºæ¥åˆ†ç¦»å†…å®¹ç‰¹å¾ã€‚é€šè¿‡æ¢ç´¢å›¾åƒå¢å¼ºæŠ€æœ¯å’Œå°†å…¶æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒCLIPæ¨¡å‹ä¸­ï¼Œæå–çº¯å†…å®¹ç‰¹å¾ã€‚åŒæ—¶ï¼Œåˆ©ç”¨æ–‡æœ¬å¢å¼ºæ¥éš”ç¦»æ½œåœ¨å†…å®¹ä¸é£æ ¼ç‰¹å¾ï¼Œä½¿CLIPæ¨¡å‹çš„ç¼–ç å™¨ä¸“æ³¨äºæ½œåœ¨å†…å®¹ä¿¡æ¯ï¼Œä»è€Œä¼˜åŒ–é¢„è®­ç»ƒCLIPæ¨¡å‹çš„è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶å¢å¼ºäº†å¯¹å„ç§æ‰°åŠ¨çš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚</li>
<li>é—®é¢˜æºäºæ¨¡å‹å­¦åˆ°çš„ç‰¹å¾èåˆäº†å†…å®¹å’Œé£æ ¼ä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨å› æœç”Ÿæˆè§†è§’å’Œå¤šæ¨¡æ€æ•°æ®ï¼Œæå‡ºä½¿ç”¨å¯¹æ¯”å­¦ä¹ å’Œæ•°æ®å¢å¼ºæ¥åˆ†ç¦»å†…å®¹ç‰¹å¾ã€‚</li>
<li>é€šè¿‡å›¾åƒå¢å¼ºæŠ€æœ¯æå–çº¯å†…å®¹ç‰¹å¾ï¼Œå¹¶æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒCLIPæ¨¡å‹ä¸­ã€‚</li>
<li>åˆ©ç”¨æ–‡æœ¬å¢å¼ºæ¥éš”ç¦»æ½œåœ¨å†…å®¹ä¸é£æ ¼ç‰¹å¾ï¼Œä¼˜åŒ–CLIPæ¨¡å‹çš„è¡¨ç¤ºå­¦ä¹ ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.16445">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-da491de90cd83a2e7e9a5113c3d92b5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-446e6ccc083ed653e398a47c6d8c386e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d262133074fb44db337ef4127a68261.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-25/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-4b49c639be684822e53da3e9ba6000a3.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  Pix2Next Leveraging Vision Foundation Models for RGB to NIR Image   Translation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-221bd3f73cedfd92fa5f7929a7829834.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  OptimAI Optimization from Natural Language Using LLM-Powered AI Agents
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">16668k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
