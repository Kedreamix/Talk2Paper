<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-16  Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using   Implicit Neural Representations">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-8f5d2e549b25260ab6ee45b2743d90b4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    53 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-16-æ›´æ–°"><a href="#2025-05-16-æ›´æ–°" class="headerlink" title="2025-05-16 æ›´æ–°"></a>2025-05-16 æ›´æ–°</h1><h2 id="Meta-learning-Slice-to-Volume-Reconstruction-in-Fetal-Brain-MRI-using-Implicit-Neural-Representations"><a href="#Meta-learning-Slice-to-Volume-Reconstruction-in-Fetal-Brain-MRI-using-Implicit-Neural-Representations" class="headerlink" title="Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using   Implicit Neural Representations"></a>Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using   Implicit Neural Representations</h2><p><strong>Authors:Maik Dannecker, Thomas Sanchez, Meritxell Bach Cuadra, Ã–zgÃ¼n Turgut, Anthony N. Price, Lucilio Cordero-Grande, Vanessa Kyriakopoulou, Joseph V. Hajnal, Daniel Rueckert</strong></p>
<p>High-resolution slice-to-volume reconstruction (SVR) from multiple motion-corrupted low-resolution 2D slices constitutes a critical step in image-based diagnostics of moving subjects, such as fetal brain Magnetic Resonance Imaging (MRI). Existing solutions struggle with image artifacts and severe subject motion or require slice pre-alignment to achieve satisfying reconstruction performance. We propose a novel SVR method to enable fast and accurate MRI reconstruction even in cases of severe image and motion corruption. Our approach performs motion correction, outlier handling, and super-resolution reconstruction with all operations being entirely based on implicit neural representations. The model can be initialized with task-specific priors through fully self-supervised meta-learning on either simulated or real-world data. In extensive experiments including over 480 reconstructions of simulated and clinical MRI brain data from different centers, we prove the utility of our method in cases of severe subject motion and image artifacts. Our results demonstrate improvements in reconstruction quality, especially in the presence of severe motion, compared to state-of-the-art methods, and up to 50% reduction in reconstruction time. </p>
<blockquote>
<p>ä»å¤šä¸ªå—è¿åŠ¨å½±å“çš„ä½åˆ†è¾¨ç‡2Dåˆ‡ç‰‡è¿›è¡Œé«˜åˆ†è¾¨ç‡åˆ‡ç‰‡åˆ°ä½“ç§¯é‡å»ºï¼ˆSVRï¼‰ï¼Œæ˜¯åœ¨ç§»åŠ¨ä¸»ä½“çš„å›¾åƒè¯Šæ–­ä¸­ï¼Œå¦‚èƒå„¿è„‘éƒ¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„ä¸€ä¸ªå…³é”®æ­¥éª¤ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆåœ¨å›¾åƒä¼ªå½±å’Œä¸¥é‡ä¸»ä½“è¿åŠ¨æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œæˆ–è€…éœ€è¦åˆ‡ç‰‡é¢„å¯¹é½ä»¥å®ç°ä»¤äººæ»¡æ„çš„é‡å»ºæ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹SVRæ–¹æ³•ï¼Œå³ä½¿åœ¨å›¾åƒå’Œè¿åŠ¨ä¸¥é‡å—æŸçš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å®ç°å¿«é€Ÿã€å‡†ç¡®çš„MRIé‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•æ‰§è¡Œè¿åŠ¨æ ¡æ­£ã€å¼‚å¸¸å€¼å¤„ç†ä»¥åŠè¶…åˆ†è¾¨ç‡é‡å»ºï¼Œæ‰€æœ‰æ“ä½œéƒ½å®Œå…¨åŸºäºéšå¼ç¥ç»è¡¨ç¤ºã€‚è¯¥æ¨¡å‹å¯ä»¥é€šè¿‡æ¨¡æ‹Ÿæˆ–çœŸå®æ•°æ®çš„å®Œå…¨è‡ªç›‘ç£å…ƒå­¦ä¹ ï¼Œä»¥ç‰¹å®šä»»åŠ¡çš„å…ˆéªŒçŸ¥è¯†æ¥è¿›è¡Œåˆå§‹åŒ–ã€‚åœ¨åŒ…æ‹¬ä»ä¸åŒä¸­å¿ƒè·å–çš„ä¸´åºŠå’Œæ¨¡æ‹ŸMRIè„‘éƒ¨æ•°æ®çš„è¶…è¿‡480æ¬¡é‡å»ºçš„å¹¿æ³›å®éªŒä¸­ï¼Œæˆ‘ä»¬éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸¥é‡ä¸»ä½“è¿åŠ¨å’Œå›¾åƒä¼ªå½±æƒ…å†µä¸‹çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨å­˜åœ¨ä¸¥é‡è¿åŠ¨çš„æƒ…å†µä¸‹ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„é‡å»ºè´¨é‡æœ‰æ‰€æé«˜ï¼Œå¹¶ä¸”é‡å»ºæ—¶é—´å‡å°‘äº†é«˜è¾¾50%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09565v1">PDF</a> 10 pages, 6 figures</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹åŠ¨æ€ä¸»ä½“ï¼ˆå¦‚èƒå„¿è„‘éƒ¨ç£å…±æŒ¯æˆåƒï¼‰çš„å›¾åƒè¯Šæ–­ä¸­çš„é«˜åˆ†è¾¨ç‡åˆ‡ç‰‡åˆ°ä½“ç§¯é‡å»ºï¼ˆSVRï¼‰ï¼Œç°æœ‰è§£å†³æ–¹æ¡ˆå­˜åœ¨å›¾åƒä¼ªå½±å’Œä¸»ä½“ä¸¥é‡è¿åŠ¨é—®é¢˜æˆ–éœ€è¦åˆ‡ç‰‡é¢„å¯¹é½ä»¥è·å¾—æ»¡æ„çš„é‡å»ºæ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹SVRæ–¹æ³•ï¼Œå¯åœ¨å›¾åƒå’Œè¿åŠ¨ä¸¥é‡å¤±çœŸæƒ…å†µä¸‹å®ç°å¿«é€Ÿå‡†ç¡®çš„MRIé‡å»ºã€‚è¯¥æ–¹æ³•åŸºäºéšç¥ç»è¡¨ç¤ºè¿›è¡Œè¿åŠ¨æ ¡æ­£ã€å¼‚å¸¸å€¼å¤„ç†å’Œè¶…åˆ†è¾¨ç‡é‡å»ºã€‚æ¨¡å‹å¯é€šè¿‡æ¨¡æ‹Ÿæˆ–çœŸå®æ•°æ®çš„å…¨è‡ªç›‘ç£å…ƒå­¦ä¹ è¿›è¡Œç‰¹å®šä»»åŠ¡å…ˆéªŒåˆå§‹åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¥é‡ä¸»ä½“è¿åŠ¨å’Œå›¾åƒä¼ªå½±æƒ…å†µä¸‹å…·æœ‰å®ç”¨æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œé‡å»ºè´¨é‡æœ‰æ‰€æé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸¥é‡è¿åŠ¨æƒ…å†µä¸‹ï¼Œé‡å»ºæ—¶é—´å‡å°‘é«˜è¾¾50%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜åˆ†è¾¨ç‡åˆ‡ç‰‡åˆ°ä½“ç§¯é‡å»ºï¼ˆSVRï¼‰åœ¨åŠ¨æ€ä¸»ä½“çš„å›¾åƒè¯Šæ–­ä¸­è‡³å…³é‡è¦ï¼Œå¦‚èƒå„¿è„‘éƒ¨ç£å…±æŒ¯æˆåƒã€‚</li>
<li>ç°æœ‰SVRè§£å†³æ–¹æ¡ˆåœ¨åº”å¯¹å›¾åƒä¼ªå½±å’Œä¸¥é‡ä¸»ä½“è¿åŠ¨é—®é¢˜æ—¶è¡¨ç°ä¸è¶³ï¼Œæˆ–éœ€è¦åˆ‡ç‰‡é¢„å¯¹é½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹SVRæ–¹æ³•ï¼Œå¯å¤„ç†å›¾åƒå’Œè¿åŠ¨ä¸¥é‡å¤±çœŸæƒ…å†µä¸‹çš„MRIé‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•åŸºäºéšç¥ç»è¡¨ç¤ºè¿›è¡Œè¿åŠ¨æ ¡æ­£ã€å¼‚å¸¸å€¼å¤„ç†å’Œè¶…åˆ†è¾¨ç‡é‡å»ºã€‚</li>
<li>æ¨¡å‹å¯é€šè¿‡æ¨¡æ‹Ÿæˆ–çœŸå®æ•°æ®çš„å…¨è‡ªç›‘ç£å…ƒå­¦ä¹ è¿›è¡Œä»»åŠ¡ç‰¹å®šå…ˆéªŒåˆå§‹åŒ–ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¥é‡ä¸»ä½“è¿åŠ¨å’Œå›¾åƒä¼ªå½±æƒ…å†µä¸‹å…·æœ‰å®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09565">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2d7562578495b91c2b00f88cfed0df06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-215ae4d551fde728bd18444c3e40c0b9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Conformal-Bounds-on-Full-Reference-Image-Quality-for-Imaging-Inverse-Problems"><a href="#Conformal-Bounds-on-Full-Reference-Image-Quality-for-Imaging-Inverse-Problems" class="headerlink" title="Conformal Bounds on Full-Reference Image Quality for Imaging Inverse   Problems"></a>Conformal Bounds on Full-Reference Image Quality for Imaging Inverse   Problems</h2><p><strong>Authors:Jeffrey Wen, Rizwan Ahmad, Philip Schniter</strong></p>
<p>In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc. This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis. But since we donâ€™t know the true image, computing FRIQ is non-trivial. In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability. We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems. Code is available at <a target="_blank" rel="noopener" href="https://github.com/jwen307/quality_uq">https://github.com/jwen307/quality_uq</a>. </p>
<blockquote>
<p>åœ¨æˆåƒåé—®é¢˜ä¸­ï¼Œæˆ‘ä»¬æƒ³çŸ¥é“æ ¹æ®å…¨å‚è€ƒå›¾åƒè´¨é‡ï¼ˆFRIQï¼‰æŒ‡æ ‡ï¼ˆå¦‚PSNRã€SSIMã€LPIPSç­‰ï¼‰ï¼Œæ¢å¤çš„å›¾åƒä¸çœŸå®å›¾åƒæœ‰å¤šæ¥è¿‘ã€‚è¿™åœ¨åŒ»ç–—æˆåƒç­‰å®‰å…¨å…³é”®åº”ç”¨ä¸­å°¤ä¸ºé‡è¦ï¼Œä¾‹å¦‚çŸ¥é“SSIMæŒ‡æ ‡ä¸ä½³å¯èƒ½ä¼šé¿å…å‘ç”Ÿæ˜‚è´µçš„è¯¯è¯Šã€‚ä½†æ˜¯å› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“çœŸå®çš„å›¾åƒï¼Œè®¡ç®—FRIQæ˜¯éå¸¸å›°éš¾çš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†åˆè§„é¢„æµ‹ä¸è¿‘ä¼¼åé‡‡æ ·ç›¸ç»“åˆï¼Œæ„å»ºå¯¹FRIQçš„ç•Œé™ï¼Œä¿è¯è¾¾åˆ°ç”¨æˆ·æŒ‡å®šçš„é”™è¯¯æ¦‚ç‡ã€‚æˆ‘ä»¬åœ¨å›¾åƒå»å™ªå’ŒåŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰é—®é¢˜ä¸Šå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚ä»£ç å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/jwen307/quality_uq">https://github.com/jwen307/quality_uq</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09528v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨æˆåƒåé—®é¢˜ä¸­æ¢å¤å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å…¨å‚è€ƒå›¾åƒè´¨é‡ï¼ˆFRIQï¼‰æŒ‡æ ‡æ¥è¿‘ç¨‹åº¦çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—æˆåƒç­‰å®‰å…¨å…³é”®åº”ç”¨ä¸­å°¤ä¸ºé‡è¦ã€‚ç”±äºä¸çŸ¥é“çœŸå®å›¾åƒï¼Œè®¡ç®—FRIQå…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶ç»“åˆconformalé¢„æµ‹å’Œè¿‘ä¼¼åé‡‡æ ·æ„å»ºFRIQçš„ç•Œé™ï¼Œå¯ä¿è¯è¾¾åˆ°ç”¨æˆ·æŒ‡å®šçš„é”™è¯¯æ¦‚ç‡ã€‚è¯¥æ–¹æ³•åœ¨å›¾åƒå»å™ªå’ŒåŠ é€Ÿç£å…±æŒ¯æˆåƒé—®é¢˜ä¸­å¾—åˆ°äº†éªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æˆåƒåé—®é¢˜ä¸­ï¼Œæ¢å¤å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å…¨å‚è€ƒå›¾åƒè´¨é‡ï¼ˆFRIQï¼‰æŒ‡æ ‡æ¥è¿‘ç¨‹åº¦æ˜¯å…³é”®ï¼Œå°¤å…¶åœ¨åŒ»ç–—æˆåƒç­‰å®‰å…¨åº”ç”¨ä¸­å°¤ä¸ºé‡è¦ã€‚</li>
<li>ç”±äºä¸çŸ¥é“çœŸå®å›¾åƒï¼Œè®¡ç®—FRIQå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æœ¬ç ”ç©¶ç»“åˆconformalé¢„æµ‹å’Œè¿‘ä¼¼åé‡‡æ ·æ„å»ºFRIQçš„ç•Œé™ã€‚</li>
<li>æ–¹æ³•å¯ä¿è¯è¾¾åˆ°ç”¨æˆ·æŒ‡å®šçš„é”™è¯¯æ¦‚ç‡ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å›¾åƒå»å™ªå’ŒåŠ é€Ÿç£å…±æŒ¯æˆåƒé—®é¢˜ä¸­å¾—åˆ°äº†éªŒè¯ã€‚</li>
<li>ä»£ç å·²å…¬å¼€ï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09528">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2f47a1732123856806eeb9851040f527.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Bayesian-Treatment-Selection-Design-for-Phase-II-Randomised-Cancer-Clinical-Trials"><a href="#A-Bayesian-Treatment-Selection-Design-for-Phase-II-Randomised-Cancer-Clinical-Trials" class="headerlink" title="A Bayesian Treatment Selection Design for Phase II Randomised Cancer   Clinical Trials"></a>A Bayesian Treatment Selection Design for Phase II Randomised Cancer   Clinical Trials</h2><p><strong>Authors:Moka Komaki, Satoru Shinoda, Haiyan Zheng, Kouji Yamamoto</strong></p>
<p>It is crucial to design Phase II cancer clinical trials that balance the efficiency of treatment selection with clinical practicality. Sargent and Goldberg proposed a frequentist design that allow decision-making even when the primary endpoint is ambiguous. However, frequentist approaches rely on fixed thresholds and long-run frequency properties, which can limit flexibility in practical applications. In contrast, the Bayesian decision rule, based on posterior probabilities, enables transparent decision-making by incorporating prior knowledge and updating beliefs with new data, addressing some of the inherent limitations of frequentist designs. In this study, we propose a novel Bayesian design, allowing selection of a best-performing treatment. Specifically, concerning phase II clinical trials with a binary outcome, our decision rule employs posterior interval probability by integrating the joint distribution over all values, for which the â€˜success rateâ€™ of the bester-performing treatment is greater than that of the other(s). This design can then determine which a treatment should proceed to the next phase, given predefined decision thresholds. Furthermore, we propose two sample size determination methods to empower such treatment selection designs implemented in a Bayesian framework. Through simulation studies and real-data applications, we demonstrate how this approach can overcome challenges related to sample size constraints in randomised trials. In addition, we present a user-friendly R Shiny application, enabling clinicians to Bayesian designs. Both our methodology and the software application can advance the design and analysis of clinical trials for evaluating cancer treatments. </p>
<blockquote>
<p>åœ¨è®¾è®¡ç¬¬äºŒé˜¶æ®µç™Œç—‡ä¸´åºŠè¯•éªŒæ—¶ï¼Œéœ€è¦åœ¨æ²»ç–—é€‰æ‹©æ•ˆç‡å’Œä¸´åºŠå®ç”¨æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚Sargentå’ŒGoldbergæå‡ºäº†ä¸€ç§åŸºäºé¢‘ç¹ç»Ÿè®¡çš„å†³ç­–è®¾è®¡ï¼Œå³ä½¿ä¸»è¦ç»ˆç‚¹ä¸æ˜ç¡®ä¹Ÿèƒ½åšå‡ºå†³ç­–ã€‚ç„¶è€Œï¼Œé¢‘ç¹çš„æ–¹æ³•ä¾èµ–äºå›ºå®šçš„é˜ˆå€¼å’Œé•¿æœŸé¢‘ç‡å±æ€§ï¼Œè¿™é™åˆ¶äº†åœ¨å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäºåéªŒæ¦‚ç‡çš„è´å¶æ–¯å†³ç­–è§„åˆ™å¯ä»¥é€šè¿‡æ•´åˆå…ˆéªŒçŸ¥è¯†å’Œåˆ©ç”¨æ–°æ•°æ®æ›´æ–°ä¿¡å¿µæ¥å®ç°é€æ˜çš„å†³ç­–è¿‡ç¨‹ï¼Œä»è€Œè§£å†³äº†é¢‘ç¹è®¾è®¡çš„ä¸€äº›å›ºæœ‰å±€é™æ€§ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è´å¶æ–¯è®¾è®¡ï¼Œå…è®¸é€‰æ‹©è¡¨ç°æœ€ä½³çš„æ²»ç–—æ–¹æ¡ˆã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºå…·æœ‰äºŒå…ƒç»“æœçš„ç¬¬äºŒé˜¶æ®µä¸´åºŠè¯•éªŒï¼Œæˆ‘ä»¬çš„å†³ç­–è§„åˆ™é‡‡ç”¨åéªŒåŒºé—´æ¦‚ç‡ï¼Œé€šè¿‡æ•´åˆæ‰€æœ‰å€¼çš„è”åˆåˆ†å¸ƒæ¥ç¡®å®šå“ªç§æ²»ç–—æ–¹æ¡ˆçš„â€œæˆåŠŸç‡â€é«˜äºå…¶ä»–æ–¹æ¡ˆã€‚è¿™ç§è®¾è®¡å¯ä»¥æ ¹æ®é¢„å…ˆè®¾å®šçš„å†³ç­–é˜ˆå€¼æ¥ç¡®å®šå“ªç§æ²»ç–—æ–¹æ¡ˆåº”è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸¤ç§æ ·æœ¬é‡ç¡®å®šæ–¹æ³•ï¼Œä»¥æ”¯æŒåœ¨è´å¶æ–¯æ¡†æ¶ä¸­å®ç°çš„æ²»ç–—é€‰æ‹©è®¾è®¡ã€‚é€šè¿‡æ¨¡æ‹Ÿç ”ç©¶å’Œå®é™…åº”ç”¨æ•°æ®çš„åˆ†æï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¿™ç§æ–¹æ³•å¦‚ä½•å…‹æœéšæœºè¯•éªŒä¸­ä¸æ ·æœ¬è§„æ¨¡æœ‰å…³çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„R Shinyåº”ç”¨ç¨‹åºï¼Œä½¿ä¸´åºŠåŒ»ç”Ÿèƒ½å¤Ÿä½¿ç”¨è´å¶æ–¯è®¾è®¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å’Œè½¯ä»¶åº”ç”¨ç¨‹åºéƒ½èƒ½æ¨åŠ¨ä¸´åºŠè¯•éªŒçš„è®¾è®¡å’Œåˆ†æï¼Œä»¥è¯„ä¼°ç™Œç—‡æ²»ç–—æ–¹æ³•çš„æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09460v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹äºŒæœŸç™Œç—‡ä¸´åºŠè¯•éªŒçš„è®¾è®¡ï¼Œéœ€è¦åœ¨æ²»ç–—é€‰æ‹©æ•ˆç‡å’Œä¸´åºŠå®è·µä¹‹é—´å–å¾—å¹³è¡¡ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ–°å‹è´å¶æ–¯è®¾è®¡ï¼Œé‡‡ç”¨åéªŒåŒºé—´æ¦‚ç‡å†³ç­–è§„åˆ™ï¼Œç”¨äºé€‰æ‹©è¡¨ç°æœ€ä½³çš„æ²»ç–—æ–¹æ¡ˆã€‚è¯¥è®¾è®¡é€šè¿‡è”åˆåˆ†å¸ƒå¯¹æ‰€æœ‰å€¼è¿›è¡Œç§¯åˆ†ï¼Œç¡®å®šæœ€ä½³æ²»ç–—æ–¹æ¡ˆçš„â€œæˆåŠŸç‡â€é«˜äºå…¶ä»–æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºä¸¤ç§æ ·æœ¬é‡ç¡®å®šæ–¹æ³•ï¼Œä»¥æ”¯æŒåœ¨è´å¶æ–¯æ¡†æ¶ä¸‹å®æ–½æ­¤ç±»æ²»ç–—é€‰æ‹©è®¾è®¡ã€‚é€šè¿‡æ¨¡æ‹Ÿç ”ç©¶å’Œå®é™…åº”ç”¨ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å…‹æœéšæœºè¯•éªŒä¸­çš„æ ·æœ¬é‡çº¦æŸæŒ‘æˆ˜æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>äºŒæœŸç™Œç—‡ä¸´åºŠè¯•éªŒè®¾è®¡éœ€å¹³è¡¡æ²»ç–—é€‰æ‹©æ•ˆç‡å’Œä¸´åºŠå®è·µã€‚</li>
<li>Sargentå’ŒGoldbergæå‡ºçš„é¢‘ç¹ä¸»ä¹‰è®¾è®¡åœ¨ä¸»è¦ç»ˆç‚¹æ¨¡ç³Šæ—¶ä»å…è®¸å†³ç­–ã€‚</li>
<li>é¢‘ç¹ä¸»ä¹‰æ–¹æ³•ä¾èµ–äºå›ºå®šçš„é˜ˆå€¼å’Œé•¿æœŸé¢‘ç‡å±æ€§ï¼Œè¿™å¯èƒ½é™åˆ¶äº†å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§ã€‚</li>
<li>è´å¶æ–¯å†³ç­–è§„åˆ™åŸºäºåéªŒæ¦‚ç‡ï¼Œé€šè¿‡èå…¥å…ˆéªŒçŸ¥è¯†å’Œæ–°æ•°æ®çš„ä¿¡å¿µæ›´æ–°ï¼Œè§£å†³äº†é¢‘ç¹ä¸»ä¹‰è®¾è®¡çš„ä¸€äº›å›ºæœ‰å±€é™æ€§ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹è´å¶æ–¯è®¾è®¡ï¼Œé‡‡ç”¨åéªŒåŒºé—´æ¦‚ç‡å†³ç­–è§„åˆ™æ¥é€‰æ‹©æœ€ä½³æ²»ç–—æ–¹æ¡ˆã€‚</li>
<li>é€šè¿‡æ¨¡æ‹Ÿç ”ç©¶å’Œå®é™…åº”ç”¨ï¼Œè¯æ˜äº†è¯¥è®¾è®¡æ–¹æ³•åœ¨å…‹æœæ ·æœ¬é‡çº¦æŸæ–¹é¢çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09460">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-573c1ab7967f8e5ccd18ec59a75f8993.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94f35ff42b452d96cac1c7ccf5dce615.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24592ac59313a12714b5ad27a27e5a2a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-278f82e78b66940b89024869f0c73cbb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MrTrack-Register-Mamba-for-Needle-Tracking-with-Rapid-Reciprocating-Motion-during-Ultrasound-Guided-Aspiration-Biopsy"><a href="#MrTrack-Register-Mamba-for-Needle-Tracking-with-Rapid-Reciprocating-Motion-during-Ultrasound-Guided-Aspiration-Biopsy" class="headerlink" title="MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating   Motion during Ultrasound-Guided Aspiration Biopsy"></a>MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating   Motion during Ultrasound-Guided Aspiration Biopsy</h2><p><strong>Authors:Yuelin Zhang, Qingpeng Ding, Long Lei, Yongxuan Feng, Raymond Shing-Yan Tang, Shing Shin Cheng</strong></p>
<p>Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally invasive diagnostic procedure. However, an aspiration needle tracker addressing rapid reciprocating motion is still missing. MrTrack, an aspiration needle tracker with a mamba-based register mechanism, is proposed. MrTrack leverages a Mamba-based register extractor to sequentially distill global context from each historical search map, storing these temporal cues in a register bank. The Mamba-based register retriever then retrieves temporal prompts from the register bank to provide external cues when current vision features are temporarily unusable due to rapid reciprocating motion and imaging degradation. A self-supervised register diversify loss is proposed to encourage feature diversity and dimension independence within the learned register, mitigating feature collapse. Comprehensive experiments conducted on both motorized and manual aspiration datasets demonstrate that MrTrack not only outperforms state-of-the-art trackers in accuracy and robustness but also achieves superior inference efficiency. </p>
<blockquote>
<p>è¶…å£°å¼•å¯¼ä¸‹ç»†é’ˆç©¿åˆºæ´»æ£€ï¼ˆFNAï¼‰æ˜¯ä¸€ç§å¸¸è§çš„å¾®åˆ›è¯Šæ–­ç¨‹åºã€‚ç„¶è€Œï¼Œé’ˆå¯¹å¿«é€Ÿå¾€å¤è¿åŠ¨çš„ç©¿åˆºé’ˆè·Ÿè¸ªå™¨ä»ç„¶ç¼ºå¤±ã€‚æœ¬æ–‡æå‡ºäº†MrTrackç©¿åˆºé’ˆè·Ÿè¸ªå™¨ï¼Œå®ƒé‡‡ç”¨åŸºäºèŸ’è›‡çš„æ³¨å†Œæœºåˆ¶ã€‚MrTrackåˆ©ç”¨åŸºäºèŸ’è›‡çš„æ³¨å†Œæå–å™¨ï¼Œä»æ¯ä¸ªå†å²æœç´¢å›¾ä¸­é¡ºåºæå–å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå°†è¿™äº›æ—¶åºçº¿ç´¢å­˜å‚¨åœ¨å¯„å­˜å™¨é“¶è¡Œä¸­ã€‚ç„¶åï¼ŒåŸºäºèŸ’è›‡çš„å¯„å­˜å™¨æ£€ç´¢å™¨ä»å¯„å­˜å™¨é“¶è¡Œä¸­æå–æ—¶åºæç¤ºï¼Œåœ¨å½“å‰è§†è§‰ç‰¹å¾å› å¿«é€Ÿå¾€å¤è¿åŠ¨å’Œå›¾åƒé€€åŒ–è€Œæš‚æ—¶æ— æ³•ä½¿ç”¨çš„æƒ…å†µä¸‹ï¼Œæä¾›å¤–éƒ¨çº¿ç´¢ã€‚æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å¯„å­˜å™¨å¤šæ ·åŒ–æŸå¤±ï¼Œä»¥ä¿ƒè¿›å­¦ä¹ å¯„å­˜å™¨å†…çš„ç‰¹å¾å¤šæ ·æ€§å’Œç»´åº¦ç‹¬ç«‹æ€§ï¼Œå‡è½»ç‰¹å¾å´©æºƒã€‚åœ¨æœºåŠ¨å’Œæ‰‹åŠ¨ç©¿åˆºæ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒMrTrackä¸ä»…åœ¨å‡†ç¡®æ€§å’Œç¨³å¥æ€§æ–¹é¢ä¼˜äºæœ€æ–°è·Ÿè¸ªæŠ€æœ¯ï¼Œè€Œä¸”å®ç°äº†æ›´é«˜çš„æ¨ç†æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09450v1">PDF</a> Early Accepted by MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>è¶…å£°å¼•å¯¼ä¸‹ç»†é’ˆç©¿åˆºæ´»æ£€ï¼ˆFNAï¼‰æ˜¯ä¸€ç§å¸¸è§çš„å¾®åˆ›è¯Šæ–­ç¨‹åºã€‚ä¸ºè§£å†³å¿«é€Ÿå¾€å¤è¿åŠ¨ä¸­çš„ç©¿åˆºé’ˆè·Ÿè¸ªé—®é¢˜ï¼Œæå‡ºäº†MrTrackç©¿åˆºé’ˆè·Ÿè¸ªå™¨ï¼Œé‡‡ç”¨åŸºäºmambaçš„å¯„å­˜å™¨æœºåˆ¶ã€‚å®ƒé€šè¿‡å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯è’¸é¦å’Œå¯„å­˜å™¨é“¶è¡Œä¸­çš„æ—¶åºçº¿ç´¢å­˜å‚¨ï¼Œä¸ºå½“å‰è§†è§‰ç‰¹å¾å› å¿«é€Ÿå¾€å¤è¿åŠ¨å’Œå›¾åƒé€€åŒ–è€Œæš‚æ—¶æ— æ³•ä½¿ç”¨çš„æƒ…å†µæä¾›å¤–éƒ¨çº¿ç´¢ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å¯„å­˜å™¨å¤šæ ·åŒ–æŸå¤±ï¼Œä»¥é¼“åŠ±å­¦ä¹ åˆ°çš„å¯„å­˜å™¨å†…çš„ç‰¹å¾å¤šæ ·æ€§å’Œç»´åº¦ç‹¬ç«‹æ€§ï¼Œå‡è½»ç‰¹å¾å´©æºƒã€‚å®éªŒè¯æ˜ï¼ŒMrTrackä¸ä»…å‡†ç¡®åº¦å’Œç¨³å¥æ€§ä¼˜äºç°æœ‰è·Ÿè¸ªå™¨ï¼Œè€Œä¸”æ¨ç†æ•ˆç‡æ›´é«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MrTrackæ˜¯ä¸€ç§è§£å†³è¶…å£°å¼•å¯¼ä¸‹ç»†é’ˆç©¿åˆºæ´»æ£€ä¸­å¿«é€Ÿå¾€å¤è¿åŠ¨é—®é¢˜çš„ç©¿åˆºé’ˆè·Ÿè¸ªå™¨ã€‚</li>
<li>MrTracké‡‡ç”¨åŸºäºmambaçš„å¯„å­˜å™¨æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œæ—¶åºçº¿ç´¢ã€‚</li>
<li>å¯„å­˜å™¨é“¶è¡Œç”¨äºå­˜å‚¨å†å²æœç´¢å›¾çš„æ—¶é—´çº¿ç´¢ï¼Œä¸ºå½“å‰è§†è§‰ç‰¹å¾çš„ç¼ºå¤±æä¾›å¤–éƒ¨çº¿ç´¢ã€‚</li>
<li>è‡ªç›‘ç£å¯„å­˜å™¨å¤šæ ·åŒ–æŸå¤±é¼“åŠ±ç‰¹å¾å¤šæ ·æ€§å’Œç»´åº¦ç‹¬ç«‹æ€§ï¼Œæé«˜è·Ÿè¸ªå™¨çš„æ€§èƒ½ã€‚</li>
<li>MrTrackåœ¨ç”µæœºé©±åŠ¨å’Œæ‰‹åŠ¨ç©¿åˆºæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜å…¶å‡†ç¡®æ€§å’Œç¨³å¥æ€§ä¼˜äºæœ€æ–°è·Ÿè¸ªæŠ€æœ¯ã€‚</li>
<li>MrTrackè¿˜å®ç°äº†è¾ƒé«˜çš„æ¨ç†æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09450">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-da0e6c037e9976ad0cd418058afe144a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36fd6dcc13ed6617a1a6673987c0f497.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18a738150716ef7baf91c43778c514d4.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Marigold-Affordable-Adaptation-of-Diffusion-Based-Image-Generators-for-Image-Analysis"><a href="#Marigold-Affordable-Adaptation-of-Diffusion-Based-Image-Generators-for-Image-Analysis" class="headerlink" title="Marigold: Affordable Adaptation of Diffusion-Based Image Generators for   Image Analysis"></a>Marigold: Affordable Adaptation of Diffusion-Based Image Generators for   Image Analysis</h2><p><strong>Authors:Bingxin Ke, Kevin Qu, Tianfu Wang, Nando Metzger, Shengyu Huang, Bo Li, Anton Obukhov, Konrad Schindler</strong></p>
<p>The success of deep learning in computer vision over the past decade has hinged on large labeled datasets and strong pretrained models. In data-scarce settings, the quality of these pretrained models becomes crucial for effective transfer learning. Image classification and self-supervised learning have traditionally been the primary methods for pretraining CNNs and transformer-based architectures. Recently, the rise of text-to-image generative models, particularly those using denoising diffusion in a latent space, has introduced a new class of foundational models trained on massive, captioned image datasets. These modelsâ€™ ability to generate realistic images of unseen content suggests they possess a deep understanding of the visual world. In this work, we present Marigold, a family of conditional generative models and a fine-tuning protocol that extracts the knowledge from pretrained latent diffusion models like Stable Diffusion and adapts them for dense image analysis tasks, including monocular depth estimation, surface normals prediction, and intrinsic decomposition. Marigold requires minimal modification of the pre-trained latent diffusion modelâ€™s architecture, trains with small synthetic datasets on a single GPU over a few days, and demonstrates state-of-the-art zero-shot generalization. Project page: <a target="_blank" rel="noopener" href="https://marigoldcomputervision.github.io/">https://marigoldcomputervision.github.io</a> </p>
<blockquote>
<p>è¿‡å»åå¹´ï¼Œæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—çš„æˆåŠŸåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§è§„æ¨¡æœ‰æ ‡ç­¾æ•°æ®é›†å’Œå¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åœ¨æ•°æ®ç¨€ç¼ºçš„ç¯å¢ƒä¸­ï¼Œè¿™äº›é¢„è®­ç»ƒæ¨¡å‹çš„è´¨é‡å¯¹äºæœ‰æ•ˆçš„è¿ç§»å­¦ä¹ è‡³å…³é‡è¦ã€‚å›¾åƒåˆ†ç±»å’Œè‡ªç›‘ç£å­¦ä¹ ä¸€ç›´æ˜¯é¢„è®­ç»ƒCNNå’ŒåŸºäºtransformeræ¶æ„çš„ä¸»è¦æ–¹æ³•ã€‚æœ€è¿‘ï¼Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å…´èµ·ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åœ¨æ½œåœ¨ç©ºé—´ä½¿ç”¨å»å™ªæ‰©æ•£çš„æ¨¡å‹ï¼Œå¼•å…¥äº†ä¸€ç±»æ–°çš„åŸºç¡€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨å¤§å‹æœ‰æ ‡æ³¨å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¿™äº›æ¨¡å‹ç”Ÿæˆæœªè§å†…å®¹çš„é€¼çœŸå›¾åƒçš„èƒ½åŠ›è¡¨æ˜å®ƒä»¬å¯¹è§†è§‰ä¸–ç•Œæœ‰æ·±åˆ»çš„ç†è§£ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Marigoldï¼Œè¿™æ˜¯ä¸€ç³»åˆ—æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œå¾®è°ƒåè®®ï¼Œå®ƒä»é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚Stable Diffusionï¼‰ä¸­æå–çŸ¥è¯†ï¼Œå¹¶é€‚åº”å¯†é›†å›¾åƒåˆ†æä»»åŠ¡ï¼ŒåŒ…æ‹¬å•ç›®æ·±åº¦ä¼°è®¡ã€è¡¨é¢æ³•çº¿é¢„æµ‹å’Œå†…åœ¨åˆ†è§£ã€‚Marigoldå¯¹é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ¶æ„è¿›è¡Œäº†æœ€å°çš„ä¿®æ”¹ï¼Œå¯ä»¥åœ¨å•ä¸ªGPUä¸Šä½¿ç”¨å°å‹åˆæˆæ•°æ®é›†è¿›è¡Œå‡ å¤©çš„è®­ç»ƒï¼Œå¹¶å±•ç¤ºäº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://marigoldcomputervision.github.io/">https://marigoldcomputervision.github.io</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09358v1">PDF</a> Journal extension of our CVPR 2024 paper, featuring new tasks,   improved efficiency, high-resolution capabilities, and enhanced accessibility</p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æˆåŠŸä¾èµ–äºå¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†å’Œå¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„è´¨é‡å¯¹è¿ç§»å­¦ä¹ è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿå›¾åƒåˆ†ç±»å’Œè‡ªç›‘ç£å­¦ä¹ æ˜¯é¢„è®­ç»ƒCNNå’ŒåŸºäºè½¬æ¢å™¨æ¶æ„çš„ä¸»è¦æ–¹æ³•ã€‚è¿‘æœŸæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å…´èµ·ï¼Œç‰¹åˆ«æ˜¯æ½œåœ¨ç©ºé—´ä¸­é™å™ªæ‰©æ•£æ¨¡å‹çš„å‡ºç°ï¼Œå¼•å…¥äº†ä¸€ç§æ–°å‹åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨å·¨å¤§çš„æœ‰æ ‡é¢˜å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œèƒ½ç”Ÿæˆé€¼çœŸçš„æœªè§å†…å®¹å›¾åƒï¼Œè¡¨æ˜å…¶å¯¹è§†è§‰ä¸–ç•Œçš„æ·±åº¦ç†è§£ã€‚æœ¬ç ”ç©¶æå‡ºMarigoldï¼Œä¸€ç³»åˆ—æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œå¾®è°ƒåè®®ï¼Œä»é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹å¦‚Stable Diffusionä¸­æå–çŸ¥è¯†ï¼Œå¹¶é€‚åº”å¯†é›†å›¾åƒåˆ†æä»»åŠ¡ï¼ŒåŒ…æ‹¬å•çœ¼æ·±åº¦ä¼°è®¡ã€è¡¨é¢æ³•çº¿é¢„æµ‹å’Œå†…åœ¨åˆ†è§£ã€‚Marigoldå¯¹é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ¶æ„è¿›è¡Œäº†æœ€å°çš„ä¿®æ”¹ï¼Œå¯åœ¨å•ä¸ªGPUä¸Šä½¿ç”¨å°å‹åˆæˆæ•°æ®é›†è¿›è¡Œå‡ å¤©çš„è®­ç»ƒï¼Œå¹¶å±•ç¤ºäº†é›¶æ ·æœ¬æ³›åŒ–çš„æœ€æ–°æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æˆåŠŸä¾èµ–äºå¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†å’Œå¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„è´¨é‡å¯¹è¿ç§»å­¦ä¹ è‡³å…³é‡è¦ã€‚</li>
<li>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å…´èµ·å¼•å…¥äº†ä¸€ç§æ–°å‹åŸºç¡€æ¨¡å‹ï¼Œèƒ½ç”Ÿæˆæœªè§å†…å®¹å›¾åƒã€‚</li>
<li>Marigoldæ˜¯ä¸€ç§æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œå¾®è°ƒåè®®ï¼Œé€‚ç”¨äºå¯†é›†å›¾åƒåˆ†æä»»åŠ¡ã€‚</li>
<li>Marigoldèƒ½å¤Ÿä»é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸­æå–çŸ¥è¯†å¹¶é€‚åº”å¤šç§å›¾åƒåˆ†æä»»åŠ¡ã€‚</li>
<li>Marigoldåœ¨é¢„è®­ç»ƒæ¨¡å‹æ¶æ„ä¸Šè¿›è¡Œäº†æœ€å°ä¿®æ”¹ï¼Œå¯åœ¨æœ‰é™èµ„æºä¸‹é«˜æ•ˆè®­ç»ƒã€‚</li>
<li>Marigoldå±•ç¤ºäº†é›¶æ ·æœ¬æ³›åŒ–çš„æœ€æ–°æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09358">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d3de22ae0cbf338a3345997508b1b2b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b611e75ea40d8505a66ea37f1d329e4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-64ca6acc61ce14531551d6ca4a3f2400.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BioVFM-21M-Benchmarking-and-Scaling-Self-Supervised-Vision-Foundation-Models-for-Biomedical-Image-Analysis"><a href="#BioVFM-21M-Benchmarking-and-Scaling-Self-Supervised-Vision-Foundation-Models-for-Biomedical-Image-Analysis" class="headerlink" title="BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation   Models for Biomedical Image Analysis"></a>BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation   Models for Biomedical Image Analysis</h2><p><strong>Authors:Jiarun Liu, Hong-Yu Zhou, Weijian Huang, Hao Yang, Dongning Song, Tao Tan, Yong Liang, Shanshan Wang</strong></p>
<p>Scaling up model and data size have demonstrated impressive performance improvement over a wide range of tasks. Despite extensive studies on scaling behaviors for general-purpose tasks, medical images exhibit substantial differences from natural data. It remains unclear the key factors in developing medical vision foundation models at scale due to the absence of an extensive understanding of scaling behavior in the medical domain. In this paper, we explored the scaling behavior across model sizes, training algorithms, data sizes, and imaging modalities in developing scalable medical vision foundation models by self-supervised learning. To support scalable pretraining, we introduce BioVFM-21M, a large-scale biomedical image dataset encompassing a wide range of biomedical image modalities and anatomies. We observed that scaling up does provide benefits but varies across tasks. Additional analysis reveals several factors correlated with scaling benefits. Finally, we propose BioVFM, a large-scale medical vision foundation model pretrained on 21 million biomedical images, which outperforms the previous state-of-the-art foundation models across 12 medical benchmarks. Our results highlight that while scaling up is beneficial for pursuing better performance, task characteristics, data diversity, pretraining methods, and computational efficiency remain critical considerations for developing scalable medical foundation models. </p>
<blockquote>
<p>éšç€æ¨¡å‹å’Œæ•°æ®è§„æ¨¡çš„æ‰©å¤§ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸Šå‡å®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½æå‡ã€‚å°½ç®¡é’ˆå¯¹é€šç”¨ä»»åŠ¡çš„æ‰©å±•è¡Œä¸ºå·²ç»è¿›è¡Œäº†å¹¿æ³›çš„ç ”ç©¶ï¼Œä½†åŒ»å­¦å›¾åƒä¸è‡ªç„¶æ•°æ®ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ç”±äºç¼ºä¹åœ¨åŒ»å­¦é¢†åŸŸå¯¹æ‰©å±•è¡Œä¸ºçš„æ·±å…¥äº†è§£ï¼Œå› æ­¤åœ¨å¼€å‘å¤§è§„æ¨¡åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹æ—¶ï¼Œå…³é”®å› ç´ å°šä¸æ¸…æ¥šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œæ¢ç´¢äº†æ¨¡å‹å¤§å°ã€è®­ç»ƒç®—æ³•ã€æ•°æ®å¤§å°å’Œæˆåƒæ–¹å¼åœ¨å¼€å‘å¯æ‰©å±•åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹æ—¶çš„æ‰©å±•è¡Œä¸ºã€‚ä¸ºäº†æ”¯æŒå¯æ‰©å±•çš„é¢„è®­ç»ƒï¼Œæˆ‘ä»¬å¼•å…¥äº†BioVFM-21Mï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–å¹¿æ³›ç”Ÿç‰©åŒ»å­¦å›¾åƒæ¨¡å¼å’Œè§£å‰–ç»“æ„çš„çš„å¤§è§„æ¨¡ç”Ÿç‰©åŒ»å­¦å›¾åƒæ•°æ®é›†ã€‚æˆ‘ä»¬å‘ç°æ‰©å¤§è§„æ¨¡ç¡®å®æœ‰ç›Šï¼Œä½†ä¸åŒä»»åŠ¡é—´çš„æ•ˆç›Šæœ‰æ‰€ä¸åŒã€‚é¢å¤–çš„åˆ†ææ­ç¤ºäº†ä¸æ‰©å±•æ•ˆç›Šç›¸å…³çš„å‡ ä¸ªå› ç´ ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†BioVFMï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨2100ä¸‡ç”Ÿç‰©åŒ»å­¦å›¾åƒä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„å¤§è§„æ¨¡åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œåœ¨12é¡¹åŒ»å­¦åŸºå‡†æµ‹è¯•ä¸­è¶…è¿‡äº†ä¹‹å‰çš„å…ˆè¿›åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒï¼Œè™½ç„¶æ‰©å¤§è§„æ¨¡å¯¹è¿½æ±‚æ›´å¥½æ€§èƒ½æœ‰ç›Šï¼Œä½†ä»»åŠ¡ç‰¹å¾ã€æ•°æ®å¤šæ ·æ€§ã€é¢„è®­ç»ƒæ–¹æ³•å’Œè®¡ç®—æ•ˆç‡ä»æ˜¯å¼€å‘å¯æ‰©å±•åŒ»å­¦åŸºç¡€æ¨¡å‹çš„å…³é”®è€ƒè™‘å› ç´ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09329v1">PDF</a> 11 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢ç´¢äº†é€šè¿‡è‡ªç›‘ç£å­¦ä¹ åœ¨å¼€å‘å¯æ‰©å±•åŒ»ç–—è§†è§‰åŸºç¡€æ¨¡å‹æ—¶çš„æ¨¡å‹å¤§å°ã€è®­ç»ƒç®—æ³•ã€æ•°æ®é‡ä»¥åŠæˆåƒæ¨¡å¼ç­‰æ‰©å±•è¡Œä¸ºã€‚ä¸ºæ”¯æŒå¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œå¼•å…¥äº†åŒ…å«å¹¿æ³›ç”Ÿç‰©åŒ»å­¦å›¾åƒæ¨¡æ€å’Œè§£å‰–ç»“æ„çš„å¤§å‹ç”Ÿç‰©åŒ»å­¦å›¾åƒæ•°æ®é›†BioVFM-21Mã€‚è§‚å¯Ÿåˆ°æ‰©å±•è§„æ¨¡ç¡®å®æœ‰ç›Šäºæå‡æ€§èƒ½ï¼Œä½†ä¸åŒä»»åŠ¡ä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚ç»¼åˆåˆ†ææ­ç¤ºäº†ä¸€äº›ä¸æ‰©å±•æ•ˆç›Šç›¸å…³çš„å› ç´ ã€‚æœ€åï¼Œæå‡ºäº†åœ¨2100ä¸‡ç”Ÿç‰©åŒ»å­¦å›¾åƒä¸Šé¢„è®­ç»ƒçš„å¤§å‹åŒ»ç–—è§†è§‰åŸºç¡€æ¨¡å‹BioVFMï¼Œåœ¨12é¡¹åŒ»ç–—åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè™½ç„¶æ‰©å±•è§„æ¨¡æœ‰åŠ©äºæé«˜æ€§èƒ½ï¼Œä½†ä»»åŠ¡ç‰¹æ€§ã€æ•°æ®å¤šæ ·æ€§ã€é¢„è®­ç»ƒæ–¹æ³•å’Œè®¡ç®—æ•ˆç‡ä»æ˜¯å¼€å‘å¯æ‰©å±•åŒ»ç–—åŸºç¡€æ¨¡å‹çš„å…³é”®è€ƒè™‘å› ç´ ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©å±•æ¨¡å‹å’Œæ•°æ®è§„æ¨¡åœ¨å¤šç§ä»»åŠ¡ä¸Šå±•ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
<li>åŒ»ç–—å›¾åƒä¸å¤©ç„¶æ•°æ®åœ¨æ‰©å±•è¡Œä¸ºä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>å¼€å‘åŒ»ç–—è§†è§‰åŸºç¡€æ¨¡å‹çš„å¤§è§„æ¨¡æ‰©å±•é¢ä¸´å…³é”®å› ç´ çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯¹åŒ»å­¦é¢†åŸŸæ‰©å±•è¡Œä¸ºçš„å¹¿æ³›ç†è§£ä¸è¶³ã€‚</li>
<li>é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œæœ¬æ–‡ç ”ç©¶äº†æ¨¡å‹å¤§å°ã€è®­ç»ƒç®—æ³•ã€æ•°æ®é‡ä»¥åŠæˆåƒæ¨¡å¼åœ¨å¼€å‘å¯æ‰©å±•åŒ»ç–—è§†è§‰åŸºç¡€æ¨¡å‹ä¸­çš„æ‰©å±•è¡Œä¸ºã€‚</li>
<li>å¼•å…¥çš„å¤§å‹ç”Ÿç‰©åŒ»å­¦å›¾åƒæ•°æ®é›†BioVFM-21Mæ”¯æŒå¤§è§„æ¨¡é¢„è®­ç»ƒï¼ŒåŒ…å«å¤šç§ç”Ÿç‰©åŒ»å­¦å›¾åƒæ¨¡æ€å’Œè§£å‰–ç»“æ„ã€‚</li>
<li>æ‰©å±•è§„æ¨¡æœ‰ç›Šäºæ€§èƒ½æå‡ï¼Œä½†ä¸åŒä»»åŠ¡ä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œä»»åŠ¡ç‰¹æ€§æ˜¯å…³é”®è€ƒè™‘å› ç´ ä¹‹ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09329">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e5233965f7cf5fcff7f18f1564a34b1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a9b62abcdbf60ed7b3308523d136c576.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9844b90263f7b395ea95dc343a6a2f3f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-59b3e31d1bf469055984104945ed3a35.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Q-space-Guided-Collaborative-Attention-Translation-Network-for-Flexible-Diffusion-Weighted-Images-Synthesis"><a href="#Q-space-Guided-Collaborative-Attention-Translation-Network-for-Flexible-Diffusion-Weighted-Images-Synthesis" class="headerlink" title="Q-space Guided Collaborative Attention Translation Network for Flexible   Diffusion-Weighted Images Synthesis"></a>Q-space Guided Collaborative Attention Translation Network for Flexible   Diffusion-Weighted Images Synthesis</h2><p><strong>Authors:Pengli Zhu, Yingji Fu, Nanguang Chen, Anqi Qiu</strong></p>
<p>This study, we propose a novel Q-space Guided Collaborative Attention Translation Networks (Q-CATN) for multi-shell, high-angular resolution DWI (MS-HARDI) synthesis from flexible q-space sampling, leveraging the commonly acquired structural MRI data. Q-CATN employs a collaborative attention mechanism to effectively extract complementary information from multiple modalities and dynamically adjust its internal representations based on flexible q-space information, eliminating the need for fixed sampling schemes. Additionally, we introduce a range of task-specific constraints to preserve anatomical fidelity in DWI, enabling Q-CATN to accurately learn the intrinsic relationships between directional DWI signal distributions and q-space. Extensive experiments on the Human Connectome Project (HCP) dataset demonstrate that Q-CATN outperforms existing methods, including 1D-qDL, 2D-qDL, MESC-SD, and QGAN, in estimating parameter maps and fiber tracts both quantitatively and qualitatively, while preserving fine-grained details. Notably, its ability to accommodate flexible q-space sampling highlights its potential as a promising toolkit for clinical and research applications. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/Idea89560041/Q-CATN">https://github.com/Idea89560041/Q-CATN</a>. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„Qç©ºé—´å¼•å¯¼ååŒæ³¨æ„åŠ›è½¬æ¢ç½‘ç»œï¼ˆQ-CATNï¼‰ï¼Œç”¨äºä»çµæ´»çš„qç©ºé—´é‡‡æ ·ä¸­åˆæˆå¤šå£³ã€é«˜åˆ†è¾¨ç‡æ‰©æ•£åŠ æƒæˆåƒï¼ˆMS-HARDIï¼‰ï¼Œå¹¶åˆ©ç”¨å¸¸è§çš„ç»“æ„ç£å…±æŒ¯æˆåƒæ•°æ®è¿›è¡Œè¾…åŠ©ã€‚Q-CATNé‡‡ç”¨ååŒæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆæå–å¤šæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶æ ¹æ®çµæ´»çš„qç©ºé—´ä¿¡æ¯åŠ¨æ€è°ƒæ•´å…¶å†…éƒ¨è¡¨ç¤ºï¼Œä»è€Œæ— éœ€å›ºå®šçš„é‡‡æ ·æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç³»åˆ—ç‰¹å®šä»»åŠ¡çš„çº¦æŸä»¥ä¿æŒDWIçš„è§£å‰–ä¿çœŸåº¦ï¼Œä½¿Q-CATNèƒ½å¤Ÿå‡†ç¡®å­¦ä¹ æ–¹å‘æ€§DWIä¿¡å·åˆ†å¸ƒä¸qç©ºé—´ä¹‹é—´çš„å†…åœ¨å…³ç³»ã€‚åœ¨äººç±»è¿æ¥ç»„é¡¹ç›®ï¼ˆHuman Connectome Projectï¼Œç®€ç§°HCPï¼‰æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°å‚æ•°æ˜ å°„å’Œçº¤ç»´æŸä¼°è®¡æ–¹é¢ï¼ŒQ-CATNä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬1D-qDLã€2D-qDLã€MESC-SDå’ŒQGANï¼ŒåŒæ—¶ä¿ç•™äº†ç²¾ç»†çš„ç»†èŠ‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå…¶é€‚åº”çµæ´»qç©ºé—´é‡‡æ ·çš„èƒ½åŠ›å‡¸æ˜¾äº†å…¶åœ¨ä¸´åºŠå’Œç ”ç©¶åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/Idea89560041/Q-CATN%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Idea89560041/Q-CATNè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09323v1">PDF</a> MICCAI 2025</p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„Qç©ºé—´å¼•å¯¼ååŒæ³¨æ„åŠ›ç¿»è¯‘ç½‘ç»œï¼ˆQ-CATNï¼‰ï¼Œç”¨äºä»çµæ´»çš„qç©ºé—´é‡‡æ ·ä¸­åˆæˆå¤šå£³ã€é«˜è§’åˆ†è¾¨ç‡DWIï¼ˆMS-HARDIï¼‰ã€‚å€ŸåŠ©å¸¸è§ç»“æ„MRIæ•°æ®ï¼ŒQ-CATNé‡‡ç”¨ååŒæ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆæå–å¤šæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶æ ¹æ®çµæ´»çš„qç©ºé—´ä¿¡æ¯åŠ¨æ€è°ƒæ•´å…¶å†…éƒ¨è¡¨ç¤ºï¼Œæ— éœ€å›ºå®šé‡‡æ ·æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç³»åˆ—ä»»åŠ¡ç‰¹å®šçº¦æŸä»¥ä¿ç•™DWIä¸­çš„è§£å‰–ä¿çœŸåº¦ï¼Œä½¿Q-CATNèƒ½å¤Ÿå‡†ç¡®å­¦ä¹ æ–¹å‘æ€§DWIä¿¡å·åˆ†å¸ƒä¸qç©ºé—´ä¹‹é—´çš„å†…åœ¨å…³ç³»ã€‚åœ¨Human Connectome Projectæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒQ-CATNåœ¨ä¼°è®¡å‚æ•°æ˜ å°„å’Œçº¤ç»´æŸæ–¹é¢å®šé‡å’Œå®šæ€§ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬1D-qDLã€2D-qDLã€MESC-SDå’ŒQGANï¼ŒåŒæ—¶ä¿ç•™ç²¾ç»†ç»†èŠ‚ã€‚å…¶é€‚åº”çµæ´»qç©ºé—´é‡‡æ ·çš„èƒ½åŠ›å‡¸æ˜¾äº†å…¶åœ¨ä¸´åºŠå’Œç ”ç©¶åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†Q-CATNç½‘ç»œï¼Œæ—¨åœ¨ç”¨äºä»çµæ´»çš„qç©ºé—´é‡‡æ ·ä¸­åˆæˆMS-HARDIã€‚</li>
<li>Q-CATNåˆ©ç”¨ååŒæ³¨æ„åŠ›æœºåˆ¶èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶åŸºäºçµæ´»çš„qç©ºé—´ä¿¡æ¯åŠ¨æ€è°ƒæ•´å†…éƒ¨è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥ä»»åŠ¡ç‰¹å®šçº¦æŸä»¥ç»´æŒDWIçš„è§£å‰–ä¿çœŸåº¦ã€‚</li>
<li>Q-CATNåœ¨Human Connectome Projectæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–ç°æœ‰æ–¹æ³•ã€‚</li>
<li>Q-CATNèƒ½å¤Ÿå‡†ç¡®å­¦ä¹ DWIä¿¡å·åˆ†å¸ƒä¸qç©ºé—´ä¹‹é—´çš„å†…åœ¨å…³ç³»ã€‚</li>
<li>Q-CATNå…·æœ‰é€‚åº”çµæ´»qç©ºé—´é‡‡æ ·çš„èƒ½åŠ›ï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¸´åºŠå’Œç ”ç©¶åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09323">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-84f8767898841777c676899cd6301f27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6c830090554065fc0c5d490e61529da.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Recent-Advances-in-Medical-Imaging-Segmentation-A-Survey"><a href="#Recent-Advances-in-Medical-Imaging-Segmentation-A-Survey" class="headerlink" title="Recent Advances in Medical Imaging Segmentation: A Survey"></a>Recent Advances in Medical Imaging Segmentation: A Survey</h2><p><strong>Authors:Fares Bougourzi, Abdenour Hadid</strong></p>
<p>Medical imaging is a cornerstone of modern healthcare, driving advancements in diagnosis, treatment planning, and patient care. Among its various tasks, segmentation remains one of the most challenging problem due to factors such as data accessibility, annotation complexity, structural variability, variation in medical imaging modalities, and privacy constraints. Despite recent progress, achieving robust generalization and domain adaptation remains a significant hurdle, particularly given the resource-intensive nature of some proposed models and their reliance on domain expertise. This survey explores cutting-edge advancements in medical image segmentation, focusing on methodologies such as Generative AI, Few-Shot Learning, Foundation Models, and Universal Models. These approaches offer promising solutions to longstanding challenges. We provide a comprehensive overview of the theoretical foundations, state-of-the-art techniques, and recent applications of these methods. Finally, we discuss inherent limitations, unresolved issues, and future research directions aimed at enhancing the practicality and accessibility of segmentation models in medical imaging. We are maintaining a \href{<a target="_blank" rel="noopener" href="https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation%7D%7BGitHub">https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation}{GitHub</a> Repository} to continue tracking and updating innovations in this field. </p>
<blockquote>
<p>åŒ»å­¦å½±åƒæ˜¯ç°ä»£åŒ»ç–—çš„åŸºçŸ³ï¼Œæ¨åŠ¨äº†è¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œæ‚£è€…æŠ¤ç†çš„è¿›æ­¥ã€‚åœ¨å¤šç§ä»»åŠ¡ä¸­ï¼Œåˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªæœ€å…·æŒ‘æˆ˜æ€§çš„éš¾é¢˜ï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°æ•°æ®å¯è®¿é—®æ€§ã€æ ‡æ³¨å¤æ‚æ€§ã€ç»“æ„å˜åŒ–æ€§ã€åŒ»å­¦å½±åƒæ¨¡å¼çš„å˜åŒ–ä»¥åŠéšç§é™åˆ¶ç­‰å› ç´ ã€‚å°½ç®¡å–å¾—äº†æœ€æ–°çš„è¿›å±•ï¼Œå®ç°ç¨³å¥çš„æ³›åŒ–å’ŒåŸŸé€‚åº”ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„éšœç¢ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°æŸäº›æ¨¡å‹çš„èµ„æºå¯†é›†å‹å’Œå®ƒä»¬å¯¹ä¸“ä¸šçŸ¥è¯†çš„ä¾èµ–ã€‚è¿™ç¯‡ç»¼è¿°æ¢è®¨äº†åŒ»å­¦å½±åƒåˆ†å‰²çš„æœ€æ–°è¿›å±•ï¼Œé‡ç‚¹å…³æ³¨äººå·¥æ™ºèƒ½ç”ŸæˆæŠ€æœ¯ã€å°‘æ ·æœ¬å­¦ä¹ ã€åŸºç¡€æ¨¡å‹å’Œé€šç”¨æ¨¡å‹ç­‰ç ”ç©¶æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•ä¸ºè§£å†³é•¿æœŸå­˜åœ¨çš„æŒ‘æˆ˜æä¾›äº†å¾ˆæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å…¨é¢æ¦‚è¿°äº†è¿™äº›æ–¹æ³•çš„ç†è®ºåŸºç¡€ã€æœ€æ–°æŠ€æœ¯å’Œæœ€æ–°åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å›ºæœ‰çš„å±€é™æ€§ã€æœªè§£å†³çš„é—®é¢˜ä»¥åŠæœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨æé«˜åŒ»å­¦å½±åƒåˆ†å‰²æ¨¡å‹çš„å®ç”¨æ€§å’Œå¯è®¿é—®æ€§ã€‚æˆ‘ä»¬æ­£åœ¨ç»´æŠ¤ä¸€ä¸ªGitHubä»“åº“ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation%EF%BC%89%EF%BC%8C%E4%BB%A5%E7%BB%A7%E7%BB%AD%E8%B7%9F%E8%B8%AA%E5%92%8C%E6%9B%B4%E6%96%B0%E8%BF%99%E4%B8%80%E9%A2%86%E5%9F%9F%E7%9A%84%E5%88%9B%E6%96%B0%E3%80%82">https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentationï¼‰ï¼Œä»¥ç»§ç»­è·Ÿè¸ªå’Œæ›´æ–°è¿™ä¸€é¢†åŸŸçš„åˆ›æ–°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.09274v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦æˆåƒåœ¨ç°ä»£åŒ»ç–—ä¸­å æ®é‡è¦åœ°ä½ï¼Œæ˜¯æ¨åŠ¨è¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œæ‚£è€…æŠ¤ç†å‘å±•çš„å…³é”®åŠ›é‡ã€‚æœ¬æ–‡ç»¼è¿°äº†åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œæ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ã€å°æ ·æœ¬å­¦ä¹ ã€åŸºç¡€æ¨¡å‹å’Œé€šç”¨æ¨¡å‹ç­‰å‰æ²¿æ–¹æ³•ï¼Œä¸ºè§£å†³é•¿æœŸå­˜åœ¨çš„æŒ‘æˆ˜æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚æ–‡ç« å…¨é¢æ¦‚è¿°äº†è¿™äº›æ–¹æ³•çš„ç†è®ºåŸºç¡€ã€æœ€æ–°æŠ€æœ¯å’Œå®é™…åº”ç”¨ï¼Œå¹¶è®¨è®ºäº†å…¶å†…åœ¨å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨æé«˜åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹çš„å®ç”¨æ€§å’Œå¯è®¿é—®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦æˆåƒåœ¨è¯Šæ–­ã€æ²»ç–—è®¡åˆ’å’Œæ‚£è€…æŠ¤ç†ä¸­èµ·å…³é”®ä½œç”¨ã€‚</li>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯åŒ»å­¦æˆåƒé¢†åŸŸæœ€å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ä¹‹ä¸€ï¼Œæ¶‰åŠæ•°æ®è·å–ã€æ ‡æ³¨å¤æ‚æ€§ã€ç»“æ„å˜å¼‚ã€æˆåƒæ¨¡å¼å˜å¼‚å’Œéšç§çº¦æŸç­‰å› ç´ ã€‚</li>
<li>æœ€æ–°çš„æŠ€æœ¯è¿›å±•åŒ…æ‹¬ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ã€å°æ ·æœ¬å­¦ä¹ ã€åŸºç¡€æ¨¡å‹å’Œé€šç”¨æ¨¡å‹ç­‰ã€‚</li>
<li>è¿™äº›æ–¹æ³•ä¸ºè§£å†³åŒ»å­¦å›¾åƒåˆ†å‰²é—®é¢˜æä¾›äº†æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>æ–‡ç« å…¨é¢æ¦‚è¿°äº†è¿™äº›æ–¹æ³•çš„ç†è®ºåŸºç¡€å’Œå®é™…åº”ç”¨ã€‚</li>
<li>æ–‡ç« è®¨è®ºäº†åŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„å†…åœ¨å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.09274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-feb293c06d36967684142f388e00cdbb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-529cf2506bf165ad55bb6e8870ac4b64.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-718ab768ace3b76cdedc02d79c162486.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-813cd56fbf5517fac6133291421128b0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="On-the-X-ray-Emission-From-Supernovae-and-Implications-for-the-Mass-Loss-Rates-of-their-Progenitor-Stars"><a href="#On-the-X-ray-Emission-From-Supernovae-and-Implications-for-the-Mass-Loss-Rates-of-their-Progenitor-Stars" class="headerlink" title="On the X-ray Emission From Supernovae, and Implications for the   Mass-Loss Rates of their Progenitor Stars"></a>On the X-ray Emission From Supernovae, and Implications for the   Mass-Loss Rates of their Progenitor Stars</h2><p><strong>Authors:Vikram V. Dwarkadas</strong></p>
<p>We summarize the X-ray emission from young SNe. Having accumulated data on most observed X-ray SNe, we display the X-ray lightcurves of young SNe. We also explore the X-ray spectra of various SN types. The X-ray emission from Type Ib&#x2F;c SNe is non-thermal. It is also likely that the emission from Type IIP SNe with low mass-loss rates (around 10$^{-7} , Msun ,$ yr$^{-1}$) is non-thermal. As the mass-loss rate increases, thermal emission begins to dominate. Type IIn SNe have the highest X-ray luminosities, and are clearly thermal. We do not find evidence of non-thermal emission from Type IIb SNe. The aggregated data are used to obtain approximate mass-loss rates of the progenitor stars of these SNe. Type IIPâ€™s have progenitors with mass-loss rates $&lt; 10^{-5}, Msun ,$ yr$^{-1}$, while Type IIn progenitors generally have mass-loss rates $&gt; 10^{-3}, Msun $ yr$^{-1}$. However, we emphasize that the density of the ambient medium is the important parameter, and if it is due to a non-steady outflow solution, it can not be translated into a mass-loss rate. </p>
<blockquote>
<p>æˆ‘ä»¬æ€»ç»“äº†å¹´è½»è¶…æ–°æ˜Ÿï¼ˆSNeï¼‰çš„Xå°„çº¿å‘å°„ã€‚åœ¨ç§¯ç´¯äº†å¤§å¤šæ•°è§‚å¯Ÿåˆ°çš„Xå°„çº¿è¶…æ–°æ˜Ÿæ•°æ®åï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¹´è½»è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰åº¦æ›²çº¿ã€‚æˆ‘ä»¬è¿˜æ¢è®¨äº†å„ç§SNç±»å‹çš„Xå°„çº¿å…‰è°±ã€‚Ib&#x2F;cå‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å‘å°„æ˜¯éçƒ­æ€§çš„ã€‚IIPå‹è¶…æ–°æ˜Ÿåœ¨è´¨é‡æŸå¤±ç‡è¾ƒä½ï¼ˆçº¦ä¸º10$^{-7} , Msun ,$ yr$^{-1}$ï¼‰çš„æƒ…å†µä¸‹ï¼Œå…¶å‘å°„ä¹Ÿå¯èƒ½æ˜¯éçƒ­æ€§çš„ã€‚éšç€è´¨é‡æŸå¤±ç‡çš„å¢åŠ ï¼Œçƒ­å‘å°„å¼€å§‹å æ®ä¸»å¯¼åœ°ä½ã€‚IInå‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰åº¦æœ€é«˜ï¼Œæ˜¾ç„¶æ˜¯çƒ­æ€§çš„ã€‚æˆ‘ä»¬æ²¡æœ‰å‘ç°IIbå‹è¶…æ–°æ˜Ÿå­˜åœ¨éçƒ­å‘å°„çš„è¯æ®ã€‚è¿™äº›æ•°æ®æ±‡æ€»åç”¨äºè·å¾—è¿™äº›è¶…æ–°æ˜Ÿç¥–æ˜Ÿçš„å¤§è‡´è´¨é‡æŸå¤±ç‡ã€‚IIPå‹çš„ç¥–æ˜Ÿè´¨é‡æŸå¤±ç‡å°äº10$^{-5}, Msun ,$ yr$^{-1}$ï¼Œè€ŒIInå‹çš„ç¥–æ˜Ÿè´¨é‡æŸå¤±ç‡ä¸€èˆ¬å¤§äº10$^{-3}, Msun , \text{yr}^{-1}$ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¼ºè°ƒç¯å¢ƒä»‹è´¨çš„å¯†åº¦æ˜¯é‡è¦å‚æ•°ï¼Œå¦‚æœå®ƒæ˜¯ç”±äºéç¨³æ€æµå‡ºè§£å†³æ–¹æ¡ˆå¯¼è‡´çš„ï¼Œé‚£ä¹ˆä¸èƒ½å°†å…¶è½¬åŒ–ä¸ºè´¨é‡æŸå¤±ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08946v1">PDF</a> 33 Pages, 12 Figures, 2 Tables. To be published in the journal   â€œUniverseâ€, in the special issue â€œA Multiwavelength View of Supernovaeâ€. The   figures in this paper update those in Dwarkadas &amp; Gruszko (2012) and should   be used preferably. Please let me know by email of any supernovae that I am   missing, I will update in subsequent plots</p>
<p><strong>Summary</strong></p>
<p>å¹´è½»çš„è¶…æ–°æ˜Ÿï¼ˆSNeï¼‰çš„Xå°„çº¿å‘å°„æ¦‚è¿°ã€‚é€šè¿‡ç§¯ç´¯å¤§å¤šæ•°è§‚å¯Ÿåˆ°çš„Xå°„çº¿è¶…æ–°æ˜Ÿæ•°æ®ï¼Œå±•ç¤ºäº†å¹´è½»è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰åº¦æ›²çº¿ã€‚è¿˜æ¢è®¨äº†ä¸åŒç±»å‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰è°±ã€‚å‘ç°æŸäº›ç±»å‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å‘å°„æ˜¯éçƒ­æ€§çš„ï¼Œå¦‚æŸäº›ä½è´¨é‡æŸå¤±ç‡çš„IIPå‹è¶…æ–°æ˜Ÿã€‚éšç€è´¨é‡æŸå¤±ç‡çš„å¢åŠ ï¼Œçƒ­å‘å°„å¼€å§‹å æ®ä¸»å¯¼åœ°ä½ã€‚IInå‹è¶…æ–°æ˜Ÿå…·æœ‰æœ€é«˜çš„Xå°„çº¿å…‰åº¦ï¼Œå¹¶ä¸”æ˜¾ç„¶æ˜¯çƒ­æ€§çš„ã€‚æ²¡æœ‰å‘ç°IIbå‹è¶…æ–°æ˜Ÿå­˜åœ¨éçƒ­æ€§å‘å°„çš„è¯æ®ã€‚åˆ©ç”¨ç»¼åˆæ•°æ®æ¨æµ‹äº†è¿™äº›è¶…æ–°æ˜Ÿå‰èº«æ˜Ÿçš„å¤§è‡´è´¨é‡æŸå¤±ç‡ã€‚å‘ç°æŸäº›è¶…æ–°æ˜Ÿå¯èƒ½é€‚åˆè½¬åŒ–ä¸ºæ…¢é€Ÿè„‰åŠ¨å™¨ï¼ˆåªæœ‰å­˜åœ¨æ—¶æ‰ä¼šæœ‰å¿«é€Ÿæˆ–æ…¢é€Ÿçš„è¯´æ³•ï¼‰ã€‚é‡è¦çš„æ˜¯æŒ‡å‡ºå‘¨å›´ä»‹è´¨çš„å¯†åº¦æ˜¯å…³é”®å‚æ•°ï¼Œè€Œéæ’å®šå¤–æµçš„æƒ…å†µä¸‹ä¸èƒ½å°†å…¶è½¬åŒ–ä¸ºè´¨é‡æŸå¤±ç‡ã€‚è¿™äº›ä¿¡æ¯å¯ä»¥å¸®åŠ©æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹è¶…æ–°æ˜Ÿçˆ†å‘çš„è¡Œä¸ºä»¥åŠæ—©æœŸæ¼”åŒ–æ¨¡å‹ã€‚è¿™äº›ç ”ç©¶å¯¹äºç†è§£è¶…æ–°æ˜Ÿçˆ†ç‚¸çš„ç‰©ç†è¿‡ç¨‹ä»¥åŠæ—©æœŸå®‡å®™æ¼”åŒ–æ¨¡å‹å…·æœ‰é‡è¦çš„ç§‘å­¦ä»·å€¼ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™æ˜¯ä¸€é¡¹å…³äºå¹´è½»è¶…æ–°æ˜ŸXå°„çº¿å‘å°„ç‰¹æ€§çš„é‡è¦ç ”ç©¶ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¹´è½»è¶…æ–°æ˜Ÿçš„Xå°„çº¿å‘å°„æ•°æ®è¢«æ€»ç»“å¹¶å±•ç¤ºäº†å…¶å…‰åº¦æ›²çº¿ã€‚</li>
<li>ä¸åŒç±»å‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰è°±è¢«æ¢è®¨ã€‚</li>
<li>ä¸€äº›ä½è´¨é‡æŸå¤±ç‡çš„è¶…æ–°æ˜ŸXå°„çº¿å‘å°„å¯èƒ½æ˜¯éçƒ­æ€§çš„ã€‚</li>
<li>éšç€è´¨é‡æŸå¤±ç‡å¢åŠ ï¼Œçƒ­å‘å°„åœ¨è¶…æ–°æ˜ŸXå°„çº¿å‘å°„ä¸­çš„åœ°ä½é€æ¸ä¸Šå‡ã€‚</li>
<li>IInå‹è¶…æ–°æ˜Ÿçš„Xå°„çº¿å…‰åº¦æœ€é«˜ï¼Œä¸”å…¶å‘å°„æ˜¯çƒ­æ€§çš„ã€‚</li>
<li>æ²¡æœ‰è¯æ®æ˜¾ç¤ºIIbå‹è¶…æ–°æ˜Ÿå­˜åœ¨éçƒ­æ€§å‘å°„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08946">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9b3ed7ae0ad6773ddac4ca9dbd0fba6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc8aa1c8114c1b3f926fb2dcda884cc5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a96f7cfa41a3503ebb9b7de580c5324b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-724e94f664a16317fdefada7d1efd231.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ada30ce5aba41ad57bd30a03339cabe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c5e82214a5938a26718342e6042fa6d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Physics-informed-machine-learning-applied-to-the-identification-of-high-pressure-elusive-phases-from-spatially-resolved-X-ray-diffraction-large-datasets"><a href="#Physics-informed-machine-learning-applied-to-the-identification-of-high-pressure-elusive-phases-from-spatially-resolved-X-ray-diffraction-large-datasets" class="headerlink" title="Physics-informed machine learning applied to the identification of   high-pressure elusive phases from spatially resolved X-ray diffraction large   datasets"></a>Physics-informed machine learning applied to the identification of   high-pressure elusive phases from spatially resolved X-ray diffraction large   datasets</h2><p><strong>Authors:Lucas H. Francisco, Camila M. AraÃºjo, AndrÃ© A. M. C. Silva, Ulisses F. Kaneko, Jairo Fonseca Jr, Guilherme A. Calligaris, Audrey D. Grockowiak, Danusa do Carmo, Ricardo D. dos Reis, Narcizo M. Souza-Neto</strong></p>
<p>Multi-technique high resolution X-ray mapping enhanced by the recent advent of 4th generation synchrotron facilities can produce colossal datasets, challenging traditional analysis methods. Such difficulty is clearly materialized when probing crystal structure of inhomogeneous samples, where the number of diffraction patterns quickly increases with map resolution, making the identification of crystal phases within a vast collection of reflections unfeasibly challenging by direct human inspection. Here we develop a novel analysis approach based on unsupervised clustering algorithms for identifying independent phases within a diffraction spatial map, which allowed us to identify the material distribution across a high-pressure cerium hydride. By investigating the specific compound, we also contribute to the understanding of synthesis inhomogeneities among the superhydrides, a prominent superconductor class in condensed matter physics whose characterization is highly challenging even for state-of-the-art materials techniques. The analysis framework we present may be readily extended to any correlated set of curves whose features are tied to specific entities, such as structural phases. </p>
<blockquote>
<p>å€ŸåŠ©ç¬¬å››ä»£åŒæ­¥åŠ é€Ÿå™¨è®¾æ–½çš„æœ€æ–°å‘å±•ï¼Œå¤šæŠ€æœ¯é«˜åˆ†è¾¨ç‡Xå°„çº¿æ˜ å°„èƒ½å¤Ÿäº§ç”Ÿå·¨å¤§çš„æ•°æ®é›†ï¼Œå¯¹ä¼ ç»Ÿåˆ†ææ–¹æ³•æ„æˆæŒ‘æˆ˜ã€‚å½“æ¢æµ‹ä¸å‡åŒ€æ ·å“çš„æ™¶ä½“ç»“æ„æ—¶ï¼Œè¿™ç§å›°éš¾å˜å¾—å°¤ä¸ºæ˜æ˜¾ï¼Œéšç€æ˜ å°„åˆ†è¾¨ç‡çš„æé«˜ï¼Œè¡å°„å›¾è°±çš„æ•°é‡è¿…é€Ÿå¢åŠ ï¼Œä½¿å¾—åœ¨å¤§é‡åå°„ä¸­ç›´æ¥é€šè¿‡äººå·¥æ£€æŸ¥è¯†åˆ«æ™¶ä½“ç›¸å˜å¾—ä¸åˆ‡å®é™…ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºæ— ç›‘ç£èšç±»ç®—æ³•çš„æ–°å‹åˆ†ææ–¹æ³•ï¼Œç”¨äºè¯†åˆ«è¡å°„ç©ºé—´å›¾ä¸­çš„ç‹¬ç«‹ç›¸ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¯†åˆ«é«˜å‹æ°¢åŒ–é“ˆä¸­çš„ææ–™åˆ†å¸ƒã€‚é€šè¿‡å¯¹ç‰¹å®šåŒ–åˆç‰©çš„ç ”ç©¶ï¼Œæˆ‘ä»¬è¿˜ä¸ºç†è§£åˆæˆä¸å‡åŒ€æ€§å¯¹è¶…æ°¢åŒ–ç‰©ï¼ˆå‡èšæ€ç‰©ç†å­¦ä¸­çš„ä¸€ç§é‡è¦è¶…å¯¼ä½“ï¼Œå…¶è¡¨å¾å³ä½¿æ˜¯å¯¹äºæœ€å…ˆè¿›çš„ææ–™æŠ€æœ¯ä¹Ÿæ˜¯æå…·æŒ‘æˆ˜æ€§çš„ï¼‰çš„å½±å“åšå‡ºäº†è´¡çŒ®ã€‚æˆ‘ä»¬æå‡ºçš„åˆ†ææ¡†æ¶å¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰©å±•åˆ°ä»»ä½•ä¸ç‰¹å®šå®ä½“ï¼ˆå¦‚ç»“æ„ç›¸ï¼‰ç›¸å…³çš„æ›²çº¿é›†åˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08922v1">PDF</a> 14 pages, 4 figures,</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨ç¬¬å››ä»£åŒæ­¥åŠ é€Ÿå™¨è®¾æ–½çš„é«˜åˆ†è¾¨ç‡Xå°„çº¿æ˜ å°„æŠ€æœ¯äº§ç”Ÿçš„åºå¤§æ•°æ®é›†ï¼Œå¯¹äºæ¢æµ‹éå‡åŒ€æ ·å“çš„æ™¶ä½“ç»“æ„å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºæ— ç›‘ç£èšç±»ç®—æ³•çš„æ–°å‹åˆ†ææ–¹æ³•ï¼Œç”¨äºè¯†åˆ«è¡å°„ç©ºé—´å›¾ä¸­çš„ç‹¬ç«‹ç›¸ï¼Œé€šè¿‡è°ƒæŸ¥ç‰¹å®šåŒ–åˆç‰©ä¸ºç†è§£åˆæˆè¶…æ°¢ä¸­çš„ä¸å‡åŒ€æ€§åšå‡ºäº†è´¡çŒ®ã€‚è¿™ç§åˆ†ææ–¹æ³•æ¡†æ¶å¯è½»æ¾æ‰©å±•åˆ°ä»»ä½•ä¸ç‰¹å®šå®ä½“ç›¸å…³çš„æ›²çº¿é›†ï¼Œå¦‚ç»“æ„ç›¸ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜åˆ†è¾¨ç‡Xå°„çº¿æ˜ å°„æŠ€æœ¯é¢ä¸´å¤„ç†åºå¤§æ•°æ®é›†çš„æŒ‘æˆ˜ã€‚</li>
<li>æ— ç›‘ç£èšç±»ç®—æ³•å¯ç”¨äºè¯†åˆ«è¡å°„ç©ºé—´å›¾ä¸­çš„ç‹¬ç«‹ç›¸ã€‚</li>
<li>é€šè¿‡åˆ†æç‰¹å®šåŒ–åˆç‰©ï¼Œå¯¹ç†è§£åˆæˆè¶…æ°¢çš„ä¸å‡åŒ€æ€§æœ‰æ‰€è´¡çŒ®ã€‚</li>
<li>åˆ†ææ–¹æ³•æ¡†æ¶å¯åº”ç”¨äºä»»ä½•ä¸ç‰¹å®šå®ä½“ç›¸å…³çš„æ›²çº¿é›†ï¼Œå¦‚ç»“æ„ç›¸ã€‚</li>
<li>è¿™ç§æ–°æ–¹æ³•åœ¨è¯†åˆ«é«˜å‹åŠ›ä¸‹çš„ææ–™åˆ†å¸ƒæ–¹é¢å…·æœ‰åº”ç”¨æ½œåŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶å¯¹å‡èšæ€ç‰©ç†å­¦ä¸­çš„è¶…å¯¼ææ–™è¡¨å¾æå‡ºäº†æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2b5dea0f439bea249dfb7c4f6c69c0df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f26126b6add87144e964f351b6ee9e18.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5c10e13c0dc787d70d7ed91220433c4d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8f5d2e549b25260ab6ee45b2743d90b4.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="In-Context-Learning-for-Label-Efficient-Cancer-Image-Classification-in-Oncology"><a href="#In-Context-Learning-for-Label-Efficient-Cancer-Image-Classification-in-Oncology" class="headerlink" title="In-Context Learning for Label-Efficient Cancer Image Classification in   Oncology"></a>In-Context Learning for Label-Efficient Cancer Image Classification in   Oncology</h2><p><strong>Authors:Mobina Shrestha, Bishwas Mandal, Vishal Mandal, Asis Shrestha</strong></p>
<p>The application of AI in oncology has been limited by its reliance on large, annotated datasets and the need for retraining models for domain-specific diagnostic tasks. Taking heed of these limitations, we investigated in-context learning as a pragmatic alternative to model retraining by allowing models to adapt to new diagnostic tasks using only a few labeled examples at inference, without the need for retraining. Using four vision-language models (VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across three oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our knowledge, this is the first study to compare the performance of multiple VLMs on different oncology classification tasks. Without any parameter updates, all models showed significant gains with few-shot prompting, with GPT-4o reaching an F1 score of 0.81 in binary classification and 0.60 in multi-class classification settings. While these results remain below the ceiling of fully fine-tuned systems, they highlight the potential of ICL to approximate task-specific behavior using only a handful of examples, reflecting how clinicians often reason from prior cases. Notably, open-source models like Paligemma and CLIP demonstrated competitive gains despite their smaller size, suggesting feasibility for deployment in computing constrained clinical environments. Overall, these findings highlight the potential of ICL as a practical solution in oncology, particularly for rare cancers and resource-limited contexts where fine-tuning is infeasible and annotated data is difficult to obtain. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½åœ¨è‚¿ç˜¤å­¦é¢†åŸŸçš„åº”ç”¨å—é™äºå…¶å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†å’Œé’ˆå¯¹ç‰¹å®šè¯Šæ–­ä»»åŠ¡é‡æ–°è®­ç»ƒæ¨¡å‹çš„ä¾èµ–ã€‚è€ƒè™‘åˆ°è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸Šä¸‹æ–‡å­¦ä¹ ä½œä¸ºä¸€ç§å®ç”¨çš„æ›¿ä»£æ¨¡å‹å†è®­ç»ƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•å…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä»…ä½¿ç”¨å°‘é‡æ ‡æ³¨ç¤ºä¾‹æ¥é€‚åº”æ–°è¯Šæ–­ä»»åŠ¡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æˆ‘ä»¬ä½¿ç”¨äº†å››ç§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰â€”â€”Paligemmaã€CLIPã€ALIGNå’ŒGPT-4oï¼Œå¹¶åœ¨ä¸‰ä¸ªè‚¿ç˜¤å­¦æ•°æ®é›†ï¼ˆMHISTã€PatchCamelyonå’ŒHAM10000ï¼‰ä¸Šè¯„ä¼°äº†å®ƒä»¬çš„æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€é¡¹æ¯”è¾ƒå¤šä¸ªVLMåœ¨ä¸åŒè‚¿ç˜¤åˆ†ç±»ä»»åŠ¡ä¸Šæ€§èƒ½çš„ç ”ç©¶ã€‚åœ¨ä¸æ›´æ–°ä»»ä½•å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹é€šè¿‡å°‘æ ·æœ¬æç¤ºéƒ½å–å¾—äº†æ˜¾è‘—çš„æå‡ï¼ŒGPT-4oåœ¨äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»è®¾ç½®ä¸­çš„F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°äº†0.81å’Œ0.60ã€‚è™½ç„¶è¿™äº›ç»“æœä»ä½äºå®Œå…¨å¾®è°ƒç³»ç»Ÿçš„ä¸Šé™ï¼Œä½†å®ƒä»¬çªå‡ºäº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ä»…ä½¿ç”¨å°‘æ•°å‡ ä¸ªä¾‹å­å°±èƒ½è¿‘ä¼¼ç‰¹å®šä»»åŠ¡è¡Œä¸ºçš„æ½œåŠ›ï¼Œåæ˜ äº†ä¸´åºŠåŒ»ç”Ÿç»å¸¸æ ¹æ®ä»¥å¾€ç—…ä¾‹è¿›è¡Œæ¨ç†çš„æ–¹å¼ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒåƒPaligemmaå’ŒCLIPè¿™æ ·çš„å¼€æºæ¨¡å‹å°½ç®¡è§„æ¨¡è¾ƒå°ï¼Œä½†ä¹Ÿè¡¨ç°å‡ºäº†ç«äº‰åŠ›ï¼Œè¿™è¡¨æ˜å®ƒä»¬å¯ä»¥åœ¨è®¡ç®—èµ„æºå—é™çš„ä¸´åºŠç¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½²æ˜¯å¯è¡Œçš„ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ åœ¨è‚¿ç˜¤å­¦é¢†åŸŸå…·æœ‰å®é™…åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ç½•è§ç™Œç—‡å’Œèµ„æºæœ‰é™çš„ç¯å¢ƒä¸­ï¼Œå¾®è°ƒä¸å¯è¡Œä¸”éš¾ä»¥è·å¾—æ ‡æ³¨æ•°æ®æ—¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08798v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æ¢ç´¢äº†åœ¨è‚¿ç˜¤å­¦é¢†åŸŸåº”ç”¨äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®é›†å’Œéœ€è¦é’ˆå¯¹ç‰¹å®šè¯Šæ–­ä»»åŠ¡é‡æ–°è®­ç»ƒæ¨¡å‹çš„é—®é¢˜ã€‚é€šè¿‡é‡‡ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆIn-Context Learningï¼ŒICLï¼‰æ–¹æ³•ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å››ç§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ä¸‰ä¸ªè‚¿ç˜¤æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡å°‘æ ·æœ¬æç¤ºï¼Œæ‰€æœ‰æ¨¡å‹æ— éœ€å‚æ•°æ›´æ–°å³å¯è·å¾—æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å°½ç®¡è¿™äº›ç»“æœä»ä½äºå®Œå…¨å¾®è°ƒç³»ç»Ÿçš„ä¸Šé™ï¼Œä½†ç ”ç©¶è¡¨æ˜ICLå…·æœ‰ä»…ä½¿ç”¨å°‘é‡ç¤ºä¾‹å³å¯è¿‘ä¼¼ç‰¹å®šä»»åŠ¡è¡Œä¸ºçš„æ½œåŠ›ï¼Œåæ˜ äº†ä¸´åºŠåŒ»ç”Ÿå¸¸æ ¹æ®ä»¥å¾€ç—…ä¾‹è¿›è¡Œæ¨ç†çš„æ–¹å¼ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶çªæ˜¾äº†ICLåœ¨è‚¿ç˜¤å­¦ä¸­çš„å®é™…åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨ç½•è§ç™Œç—‡å’Œèµ„æºæœ‰é™çš„ç¯å¢ƒä¸­ï¼Œå¾®è°ƒä¸å¯è¡Œä¸”è·å–æ ‡æ³¨æ•°æ®å›°éš¾æ—¶ï¼Œå…·æœ‰å®ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AIåœ¨è‚¿ç˜¤å­¦ä¸­çš„åº”ç”¨å—é™äºå¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†å’Œé’ˆå¯¹ç‰¹å®šè¯Šæ–­ä»»åŠ¡é‡æ–°è®­ç»ƒæ¨¡å‹çš„éœ€æ±‚ã€‚</li>
<li>é‡‡ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ–¹æ³•ï¼Œæ— éœ€å‚æ•°æ›´æ–°å³å¯é€šè¿‡å°‘é‡æ ‡æ³¨ç¤ºä¾‹æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸‰ä¸ªè‚¿ç˜¤æ•°æ®é›†ä¸Šè¯„ä¼°äº†å››ç§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„æ€§èƒ½ã€‚</li>
<li>GPT-4oåœ¨äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»è®¾ç½®ä¸‹åˆ†åˆ«è¾¾åˆ°F1åˆ†æ•°0.81å’Œ0.60ã€‚</li>
<li>å°½ç®¡ç»“æœä½äºå®Œå…¨å¾®è°ƒçš„ç³»ç»Ÿï¼Œä½†ICLæ˜¾ç¤ºå‡ºè¿‘ä¼¼ä»»åŠ¡ç‰¹å®šè¡Œä¸ºçš„æ½œåŠ›ï¼Œåæ˜ ä¸´åºŠæ¨ç†æ–¹å¼ã€‚</li>
<li>å¼€æºæ¨¡å‹å¦‚Paligemmaå’ŒCLIPè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œé€‚åˆåœ¨è®¡ç®—èµ„æºæœ‰é™çš„ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08798">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2be42e1ae4f196d172b5587f5a34b165.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1192247bc1865ade4d78b0ae13880463.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e89ce206be82dcd9c4dd1adbd45f13d9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7ebb3c457a7899d10d8edba41b806bcf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b33e7dc359e4b193f3f526ce83486611.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8d7cd9e9e7d1f15941efaa55d7bc6a7b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7c81c52d750dd125310c7f345c3f0fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-346191590c4f5b23648d8d1354d10051.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="KTaO3-001-Preparation-Methods-in-Vacuum-Effects-on-Surface-Stoichiometry-Crystallography-and-in-gap-States"><a href="#KTaO3-001-Preparation-Methods-in-Vacuum-Effects-on-Surface-Stoichiometry-Crystallography-and-in-gap-States" class="headerlink" title="KTaO3(001) Preparation Methods in Vacuum: Effects on Surface   Stoichiometry, Crystallography, and in-gap States"></a>KTaO3(001) Preparation Methods in Vacuum: Effects on Surface   Stoichiometry, Crystallography, and in-gap States</h2><p><strong>Authors:Andrea M. Lucero Manzano, Esteban D. Cantero, Emanuel A. MartÃ­nez, F. Y. Bruno, Esteban A. SÃ¡nchez, Oscar Grizzi</strong></p>
<p>KTaO3 single crystals with different orientations are used as substrates for the epitaxial growth of thin films and&#x2F;or as hosts for two-dimensional electron gases. Due to the polar nature of the KTaO3(001) surface, one can expect difficulties and challenges to arise in its preparation. Maintaining good insulating characteristics without adding undesirable in-gap electronic states, obtaining good crystalline order up to the top surface layer, a sufficiently flat surface, and complete cleanliness of the surface (without water, C or OH contaminants), are in general difficult conditions to accomplish simultaneously. Cleaving in vacuum is likely the best option for obtaining a clean surface. However, since KTaO3 is cubic and lacks a well-defined cleavage plane, this method is notsuitable for sample growth or reproducible device fabrication. Here, we systematically evaluate the effect of typical preparation methods applied on the surfaces of KTaO3(001) single crystals. In particular, we used annealing in vacuum at different temperatures, light sputtering with Ar+ ions at low energy (500 eV) followed by annealing, heavy Ar+ ion bombardment and annealing, and grazing Ar+ ion bombardment under continuous azimuthal rotation combined with both annealing in vacuum and in O2 atmosphere. Possible side effects after each treatment are evaluated by a combination of techniques, including low-energy ion scattering at forward angles, Auger electron spectroscopy, low-energy electron energy loss, X-ray photoelectron spectroscopy, low-energy electron diffraction, and time of flightsecondary ion mass spectrometry. Advantages and shortcomings of each preparation method are discussed in detail. </p>
<blockquote>
<p>KTaO3å•æ™¶å…·æœ‰ä¸åŒçš„å–å‘ï¼Œå¯ä½œä¸ºå¤–å»¶ç”Ÿé•¿è–„è†œçš„è¡¬åº•æˆ–äºŒç»´ç”µå­æ°”ä½“çš„å®¿ä¸»ã€‚ç”±äºKTaO3ï¼ˆ001ï¼‰è¡¨é¢çš„ææ€§ç‰¹å¾ï¼Œå…¶åˆ¶å¤‡è¿‡ç¨‹ä¸­å¯èƒ½ä¼šå‡ºç°ä¸€äº›å›°éš¾å’ŒæŒ‘æˆ˜ã€‚åœ¨ä¿æŒè‰¯å¥½çš„ç»ç¼˜ç‰¹æ€§è€Œä¸å¢åŠ ä¸éœ€è¦çš„å¸¦å†…ç”µå­æ€ã€è·å¾—è‰¯å¥½çš„æ™¶ä½“åºè¾¾åˆ°è¡¨å±‚ã€è¡¨é¢è¶³å¤Ÿå¹³å¦ä»¥åŠè¡¨é¢å®Œå…¨æ¸…æ´ï¼ˆæ— æ°´åˆ†ã€ç¢³æˆ–ç¾ŸåŸºæ±¡æŸ“ç‰©ï¼‰çš„åŒæ—¶ï¼Œä¸€èˆ¬å¾ˆéš¾åŒæ—¶å®ç°è¿™äº›æ¡ä»¶ã€‚çœŸç©ºä¸­çš„åŠˆè£‚å¾ˆå¯èƒ½æ˜¯è·å¾—æ¸…æ´è¡¨é¢çš„æœ€ä½³æ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äºKTaO3æ˜¯ç«‹æ–¹çš„å¹¶ä¸”ç¼ºä¹æ˜ç¡®çš„åŠˆè£‚å¹³é¢ï¼Œè¿™ç§æ–¹æ³•ä¸é€‚ç”¨äºæ ·å“ç”Ÿé•¿æˆ–å¯é‡å¤çš„å™¨ä»¶åˆ¶é€ ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†å…¸å‹åˆ¶å¤‡æ–¹æ³•å¯¹KTaO3ï¼ˆ001ï¼‰å•æ™¶è¡¨é¢çš„å½±å“ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åœ¨çœŸç©ºä¸­çš„ä¸åŒæ¸©åº¦é€€ç«ã€ä½èƒ½é‡ï¼ˆ500ç”µå­ä¼ç‰¹ï¼‰çš„æ°©ç¦»å­è½»åº¦æº…å°„åç»“åˆé€€ç«ã€é‡æ°©ç¦»å­è½°å‡»å’Œé€€ç«ã€ä»¥åŠè¿ç»­æ–¹ä½æ—‹è½¬ä¸‹çš„å€¾æ–œæ°©ç¦»å­è½°å‡»ï¼Œå¹¶ç»“åˆçœŸç©ºå’Œæ°§æ°”æ°›å›´ä¸­çš„é€€ç«å¤„ç†ã€‚é€šè¿‡ä¸€ç³»åˆ—æŠ€æœ¯è¯„ä¼°æ¯ç§å¤„ç†åçš„å¯èƒ½å‰¯ä½œç”¨ï¼ŒåŒ…æ‹¬å‰å‘è§’åº¦ä¸‹çš„ä½èƒ½ç¦»å­æ•£å°„ã€ä¿„æ­‡ç”µå­å…‰è°±ã€ä½èƒ½ç”µå­èƒ½é‡æŸå¤±ã€Xå°„çº¿å…‰ç”µå­å…‰è°±ã€ä½èƒ½ç”µå­è¡å°„ä»¥åŠé£è¡Œæ—¶é—´äºŒæ¬¡ç¦»å­è´¨è°±ä»ªã€‚æ¯ç§åˆ¶å¤‡æ–¹æ³•çš„ä¼˜ç‚¹å’Œç¼ºç‚¹éƒ½è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01590v2">PDF</a> 30 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>KTaO3å•æ™¶å› å…¶ææ€§è¡¨é¢åœ¨åˆ¶å¤‡è¿‡ç¨‹ä¸­é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚ä¿æŒè‰¯å¥½ç»ç¼˜æ€§ã€è·å¾—è‰¯å¥½ç»“æ™¶åºã€å¹³å¦ä¸”æ— æ±¡æŸ“çš„è¡¨å±‚ç­‰ã€‚ä¸åŒåˆ¶å¤‡æ–¹æ³•å¯¹å…¶è¡¨é¢çš„å½±å“ä¸åŒï¼Œé€šè¿‡çœŸç©ºé€€ç«ã€è½»ç¦»å­è½°å‡»ä¸çœŸç©ºé€€ç«ç­‰å¤„ç†æ–¹å¼åï¼Œåˆ©ç”¨å¤šç§æŠ€æœ¯è¯„ä¼°å¤„ç†æ•ˆæœåŠå¯èƒ½äº§ç”Ÿçš„å‰¯ä½œç”¨ã€‚æœ¬æ–‡è¯¦ç»†è®¨è®ºäº†å„ç§åˆ¶å¤‡æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KTaO3å•æ™¶ç”¨ä½œå¤–å»¶è–„è†œç”Ÿé•¿æˆ–äºŒç»´ç”µå­æ°”å®¿ä¸»ææ–™ï¼Œä½†å…¶ææ€§è¡¨é¢å¸¦æ¥åˆ¶å¤‡æŒ‘æˆ˜ã€‚</li>
<li>åˆ¶å¤‡è¿‡ç¨‹ä¸­éœ€åŒæ­¥å®ç°è‰¯å¥½ç»ç¼˜æ€§ã€ç»“æ™¶åºã€å¹³å¦è¡¨é¢åŠæ— æ±¡æŸ“ç‰©ç­‰æ¡ä»¶ã€‚</li>
<li>çœŸç©ºè£‚è§£å¯èƒ½æ˜¯è·å¾—å¹²å‡€è¡¨é¢çš„æœ€ä½³æ–¹æ³•ï¼Œä½†KTaO3æ— æ˜ç¡®è§£ç†é¢ï¼Œä¸é€‚ç”¨äºæ ·å“ç”Ÿé•¿å’Œå¯å¤åˆ¶å™¨ä»¶åˆ¶é€ ã€‚</li>
<li>ç³»ç»Ÿè¯„ä¼°äº†ä¸åŒè¡¨é¢å¤„ç†æ–¹æ³•å¯¹KTaO3(001)å•æ™¶è¡¨é¢çš„å½±å“ã€‚</li>
<li>å¤„ç†æ–¹æ³•åŒ…æ‹¬çœŸç©ºé€€ç«ã€ä½èƒ½Ar+ç¦»å­æº…å°„åé€€ç«ã€é‡ç¦»å­è½°å‡»åŠåœ¨çœŸç©ºå’Œæ°§æ°”ç¯å¢ƒä¸‹çš„æ—‹è½¬å¼Ar+ç¦»å­è½°å‡»ç­‰ã€‚</li>
<li>åˆ©ç”¨å¤šç§æŠ€æœ¯è¯„ä¼°å„ç§å¤„ç†æ–¹æ³•çš„æ•ˆæœåŠå¯èƒ½äº§ç”Ÿçš„å‰¯ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01590">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6e9884e7392ffe6336f5e9f97f0f046f.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MCP-MedSAM-A-Powerful-Lightweight-Medical-Segment-Anything-Model-Trained-with-a-Single-GPU-in-Just-One-Day"><a href="#MCP-MedSAM-A-Powerful-Lightweight-Medical-Segment-Anything-Model-Trained-with-a-Single-GPU-in-Just-One-Day" class="headerlink" title="MCP-MedSAM: A Powerful Lightweight Medical Segment Anything Model   Trained with a Single GPU in Just One Day"></a>MCP-MedSAM: A Powerful Lightweight Medical Segment Anything Model   Trained with a Single GPU in Just One Day</h2><p><strong>Authors:Donghang Lyu, Ruochen Gao, Marius Staring</strong></p>
<p>Medical image segmentation involves partitioning medical images into meaningful regions, with a focus on identifying anatomical structures and lesions. It has broad applications in healthcare, and deep learning methods have enabled significant advancements in automating this process. Recently, the introduction of the Segmentation Anything Model (SAM), the first foundation model for segmentation task, has prompted researchers to adapt it for the medical domain to improve performance across various tasks. However, SAMâ€™s large model size and high GPU requirements hinder its scalability and development in the medical domain. In this work, we propose MCP-MedSAM, a powerful and lightweight medical SAM model designed to be trainable on a single A100 GPU with 40GB of memory within one day while delivering superior segmentation performance. Recognizing the significant internal differences between modalities and the need for direct segmentation target information within bounding boxes, we introduce two kinds of prompts: the modality prompt and the content prompt. After passing through the prompt encoder, their embedding representations can further improve the segmentation performance by incorporating more relevant information without adding significant training overhead. Additionally, we adopt an effective modality-based data sampling strategy to address data imbalance between modalities, ensuring more balanced performance across all modalities. Our method was trained and evaluated using a large-scale challenge dataset, compared to top-ranking methods on the challenge leaderboard, MCP-MedSAM achieved superior performance while requiring only one day of training on a single GPU. The code is publicly available at \textcolor{blue}{<a target="_blank" rel="noopener" href="https://github.com/dong845/MCP-MedSAM%7D.%7D">https://github.com/dong845/MCP-MedSAM}.}</a> </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ¶‰åŠå°†åŒ»å­¦å›¾åƒåˆ†å‰²æˆæœ‰æ„ä¹‰çš„åŒºåŸŸï¼Œé‡ç‚¹å…³æ³¨è§£å‰–ç»“æ„å’Œç—…å˜çš„è¯†åˆ«ã€‚å®ƒåœ¨åŒ»ç–—ä¿å¥é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•å·²ç»èƒ½å¤Ÿå®ç°è¿™ä¸ªè¿‡ç¨‹çš„è‡ªåŠ¨åŒ–ï¼Œå¹¶å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚æœ€è¿‘ï¼Œåˆ†å‰²ä»»åŠ¡çš„ç¬¬ä¸€åŸºç¡€æ¨¡å‹â€”â€”Segmentation Anything Modelï¼ˆSAMï¼‰çš„å¼•å…¥ï¼Œä¿ƒä½¿ç ”ç©¶è€…å°†å…¶é€‚åº”äºåŒ»å­¦é¢†åŸŸï¼Œä»¥æé«˜å„ç§ä»»åŠ¡çš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒSAMçš„å¤§å‹æ¨¡å‹å°ºå¯¸å’Œé«˜GPUè¦æ±‚é™åˆ¶äº†å…¶åœ¨åŒ»å­¦é¢†åŸŸçš„å¯æ‰©å±•æ€§å’Œå‘å±•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MCP-MedSAMï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§ä¸”è½»é‡çº§çš„åŒ»å­¦SAMæ¨¡å‹ï¼Œæ—¨åœ¨èƒ½å¤Ÿåœ¨å•ä¸ªA100 GPUä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨ä¸€å¤©å†…ä½¿ç”¨40GBå†…å­˜æä¾›å“è¶Šçš„åˆ†å‰²æ€§èƒ½ã€‚è€ƒè™‘åˆ°ä¸åŒæ¨¡æ€ä¹‹é—´çš„æ˜¾è‘—å†…éƒ¨å·®å¼‚ä»¥åŠéœ€è¦åœ¨è¾¹ç•Œæ¡†å†…è¿›è¡Œç›´æ¥åˆ†å‰²ç›®æ ‡ä¿¡æ¯çš„éœ€è¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§æç¤ºï¼šæ¨¡æ€æç¤ºå’Œå†…å®¹æç¤ºã€‚ç»è¿‡æç¤ºç¼–ç å™¨çš„å¤„ç†ï¼Œå®ƒä»¬çš„åµŒå…¥è¡¨ç¤ºå¯ä»¥è¿›ä¸€æ­¥é€šè¿‡èå…¥æ›´å¤šç›¸å…³ä¿¡æ¯æ¥æé«˜åˆ†å‰²æ€§èƒ½ï¼Œè€Œä¸ä¼šå¢åŠ æ˜¾è‘—çš„è®­ç»ƒå¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æœ‰æ•ˆçš„åŸºäºæ¨¡æ€çš„æ•°æ®é‡‡æ ·ç­–ç•¥ï¼Œä»¥è§£å†³ä¸åŒæ¨¡æ€ä¹‹é—´çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œç¡®ä¿æ‰€æœ‰æ¨¡æ€çš„æ€§èƒ½æ›´åŠ å¹³è¡¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨å¤§è§„æ¨¡æŒ‘æˆ˜æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚ä¸æ’è¡Œæ¦œä¸Šçš„é¡¶å°–æ–¹æ³•ç›¸æ¯”ï¼ŒMCP-MedSAMåœ¨å•ä¸ªGPUä¸Šä»…éœ€è¦ä¸€å¤©çš„è®­ç»ƒæ—¶é—´å°±å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚ä»£ç å·²å…¬å¼€å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/dong845/MCP-MedSAM%E3%80%82">https://github.com/dong845/MCP-MedSAMã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05888v2">PDF</a> Accepted for publication at the Journal of Machine Learning for   Biomedical Imaging (MELBA)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŒ»ç–—å›¾åƒåˆ†å‰²çš„é‡è¦æ€§å’Œåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ã€‚é’ˆå¯¹Segmentation Anything Modelï¼ˆSAMï¼‰åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨æ—¶å­˜åœ¨çš„æ¨¡å‹ä½“ç§¯å¤§ã€GPUéœ€æ±‚é«˜ç­‰é—®é¢˜ï¼Œæå‡ºäº†MCP-MedSAMè¿™ä¸€è½»é‡çº§åŒ»ç–—SAMæ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½åœ¨å•å—A100 GPUä¸Šå®Œæˆè®­ç»ƒï¼Œä¸”æ€§èƒ½å“è¶Šã€‚é€šè¿‡å¼•å…¥æ¨¡æ€æç¤ºå’Œå†…å®¹æç¤ºï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†ä¸åŒæ¨¡æ€ä¹‹é—´çš„å·®å¼‚å¹¶ç›´æ¥åˆ†å‰²ç›®æ ‡ä¿¡æ¯ã€‚åŒæ—¶ï¼Œé‡‡ç”¨åŸºäºæ¨¡æ€çš„æ•°æ®é‡‡æ ·ç­–ç•¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œç¡®ä¿è·¨æ‰€æœ‰æ¨¡æ€çš„æ€§èƒ½æ›´å¹³è¡¡ã€‚å®éªŒè¯æ˜ï¼ŒMCP-MedSAMåœ¨å¤§å‹æŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–é¡¶å°–æ–¹æ³•ï¼Œä¸”è®­ç»ƒæ—¶é—´ä»…éœ€ä¸€å¤©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŒ»ç–—å›¾åƒåˆ†å‰²æ—¨åœ¨å°†åŒ»å­¦å›¾åƒåˆ†å‰²æˆæœ‰æ„ä¹‰çš„åŒºåŸŸï¼Œé‡ç‚¹è¯†åˆ«è§£å‰–ç»“æ„å’Œç—…å˜ã€‚</li>
<li>Segmentation Anything Modelï¼ˆSAMï¼‰åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨å­˜åœ¨æ¨¡å‹ä½“ç§¯å¤§ã€GPUéœ€æ±‚é«˜ç­‰é—®é¢˜ã€‚</li>
<li>MCP-MedSAMæ˜¯ä¸€ä¸ªè½»é‡çº§çš„åŒ»ç–—SAMæ¨¡å‹ï¼Œèƒ½åœ¨å•å—A100 GPUä¸Šå®Œæˆè®­ç»ƒï¼Œä¸”æ€§èƒ½å“è¶Šã€‚</li>
<li>MCP-MedSAMé€šè¿‡å¼•å…¥æ¨¡æ€æç¤ºå’Œå†…å®¹æç¤ºï¼Œæ›´æœ‰æ•ˆåœ°å¤„ç†ä¸åŒæ¨¡æ€é—´çš„å·®å¼‚å¹¶ç›´æ¥åˆ†å‰²ç›®æ ‡ä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨åŸºäºæ¨¡æ€çš„æ•°æ®é‡‡æ ·ç­–ç•¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
<li>MCP-MedSAMåœ¨å¤§å‹æŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–é¡¶å°–æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.05888">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7f32f3053b0f066e95d8dfce367d47a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb53a96d46674f638cd1c0a978857b40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c52caef12e8b4a75837db1f314520c54.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-390ee44311faf18411fb2f99c935463f.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-16/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c4362b45acf8b37b5353e03dfb1e8564.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-16  DPN-GAN Inducing Periodic Activations in Generative Adversarial   Networks for High-Fidelity Audio Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-16/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-243254f4484c2472f04d1cfb478cff57.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-16  LightLab Controlling Light Sources in Images with Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33297.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
