<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-26  DeepDistill Enhancing LLM Reasoning Capabilities via Large-Scale   Difficulty-Graded Data Training">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-1935b781154349fb0918b181e49aa7d7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    32 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-26-æ›´æ–°"><a href="#2025-04-26-æ›´æ–°" class="headerlink" title="2025-04-26 æ›´æ–°"></a>2025-04-26 æ›´æ–°</h1><h2 id="DeepDistill-Enhancing-LLM-Reasoning-Capabilities-via-Large-Scale-Difficulty-Graded-Data-Training"><a href="#DeepDistill-Enhancing-LLM-Reasoning-Capabilities-via-Large-Scale-Difficulty-Graded-Data-Training" class="headerlink" title="DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale   Difficulty-Graded Data Training"></a>DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale   Difficulty-Graded Data Training</h2><p><strong>Authors:Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li</strong></p>
<p>Although large language models (LLMs) have recently achieved remarkable performance on various complex reasoning benchmarks, the academic community still lacks an in-depth understanding of base model training processes and data quality. To address this, we construct a large-scale, difficulty-graded reasoning dataset containing approximately 3.34 million unique queries of varying difficulty levels and about 40 million distilled responses generated by multiple models over several passes. Leveraging pass rate and Coefficient of Variation (CV), we precisely select the most valuable training data to enhance reasoning capability. Notably, we observe a training pattern shift, indicating that reasoning-focused training based on base models requires higher learning rates for effective training. Using this carefully selected data, we significantly improve the reasoning capabilities of the base model, achieving a pass rate of 79.2% on the AIME2024 mathematical reasoning benchmark. This result surpasses most current distilled models and closely approaches state-of-the-art performance. We provide detailed descriptions of our data processing, difficulty assessment, and training methodology, and have publicly released all datasets and methods to promote rapid progress in open-source long-reasoning LLMs. The dataset is available at: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M">https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M</a> </p>
<blockquote>
<p>å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€è¿‘åœ¨å„ç§å¤æ‚çš„æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ï¼Œä½†å­¦æœ¯ç•Œä»ç„¶ç¼ºä¹å¯¹åŸºç¡€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å’Œæ•°æ®è´¨é‡çš„æ·±å…¥äº†è§£ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€éš¾åº¦åˆ†çº§çš„æ¨ç†æ•°æ®é›†ï¼ŒåŒ…å«çº¦334ä¸‡ä¸ªç‹¬ç‰¹æŸ¥è¯¢å’Œå¤§çº¦40ä¸‡ä¸ªè’¸é¦å“åº”ï¼Œè¿™äº›å“åº”æ˜¯ç”±å¤šä¸ªæ¨¡å‹ç»è¿‡å¤šæ¬¡è¿­ä»£ç”Ÿæˆçš„ã€‚æˆ‘ä»¬åˆ©ç”¨é€šè¿‡ç‡å’Œå˜å¼‚ç³»æ•°ï¼ˆCVï¼‰ç²¾ç¡®é€‰æ‹©æœ€æœ‰ä»·å€¼çš„è®­ç»ƒæ•°æ®ï¼Œä»¥æé«˜æ¨ç†èƒ½åŠ›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è®­ç»ƒæ¨¡å¼çš„è½¬å˜ï¼Œè¿™è¡¨æ˜åŸºäºåŸºç¡€æ¨¡å‹çš„æ¨ç†å¯¼å‘è®­ç»ƒéœ€è¦æ›´é«˜çš„å­¦ä¹ ç‡æ‰èƒ½è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚ä½¿ç”¨è¿™äº›ç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®ï¼Œæˆ‘ä»¬æ˜¾è‘—æé«˜äº†åŸºç¡€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œåœ¨AIME2024æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„é€šè¿‡ç‡è¾¾åˆ°79.2%ã€‚è¿™ä¸€ç»“æœè¶…è¿‡äº†å¤§å¤šæ•°å½“å‰çš„è’¸é¦æ¨¡å‹ï¼Œå¹¶æ¥è¿‘æœ€æ–°æŠ€æœ¯æ€§èƒ½ã€‚æˆ‘ä»¬æä¾›äº†å…³äºæ•°æ®å¤„ç†ã€éš¾åº¦è¯„ä¼°å’ŒåŸ¹è®­æ–¹æ³•çš„è¯¦ç»†æè¿°ï¼Œå¹¶å·²å…¬å¼€å‘å¸ƒæ‰€æœ‰æ•°æ®é›†å’Œæ–¹æ³•ï¼Œä»¥ä¿ƒè¿›å¼€æºé•¿æ¨ç†LLMçš„å¿«é€Ÿå‘å±•ã€‚æ•°æ®é›†å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M">https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M</a> è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17565v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†ä»ç¼ºä¹å¯¹åŸºç¡€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å’Œæ•°æ®è´¨é‡æ·±å…¥çš„ç†è§£ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€éš¾åº¦åˆ†çº§çš„æ¨ç†æ•°æ®é›†ï¼ŒåŒ…å«çº¦33ä¸‡ç‹¬ç‰¹æŸ¥è¯¢å’Œå¤§çº¦æ•°åƒä¸‡æ¬¡ç²¾ç‚¼åçš„å›å¤ã€‚é€šè¿‡åˆ©ç”¨é€šè¿‡ç‡ä¸å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰ï¼Œæˆ‘ä»¬ç²¾ç¡®ç­›é€‰å‡ºæœ€æœ‰ä»·å€¼çš„è®­ç»ƒæ•°æ®ä»¥æå‡æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å‘ç°è®­ç»ƒæ¨¡å¼å‘ç”Ÿè½¬å˜ï¼ŒåŸºäºåŸºç¡€æ¨¡å‹çš„æ¨ç†è®­ç»ƒéœ€è¦æ›´é«˜çš„å­¦ä¹ ç‡æ‰èƒ½æœ‰æ•ˆè®­ç»ƒã€‚ä½¿ç”¨è¿™äº›æ•°æ®é›†ï¼Œæˆ‘ä»¬æ˜¾è‘—æå‡äº†åŸºç¡€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œåœ¨AIME 2024æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°79.2%çš„é€šè¿‡ç‡ï¼Œè¶…è¶Šå¤§å¤šæ•°ç°æœ‰è’¸é¦æ¨¡å‹å¹¶æ¥è¿‘æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬å…¬å¼€äº†æ‰€æœ‰æ•°æ®é›†å’Œæ–¹æ³•ï¼Œä»¥ä¿ƒè¿›å¼€æºé•¿æ¨ç†LLMsçš„å¿«é€Ÿå‘å±•ã€‚æ•°æ®é›†å¯é€šè¿‡ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/a-m-team/AM-DeepSeek-Distilled-40M">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€éš¾åº¦åˆ†çº§çš„æ¨ç†æ•°æ®é›†ï¼Œæ—¨åœ¨æ·±å…¥ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹å’Œæ•°æ®è´¨é‡å¯¹æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚</li>
<li>é€šè¿‡ç‡å’Œå˜å¼‚ç³»æ•°è¢«ç”¨æ¥è¯„ä¼°å’Œç­›é€‰è®­ç»ƒæ•°æ®çš„æœ‰æ•ˆæ€§ï¼Œç”¨äºæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œä¸åŸºç¡€æ¨¡å‹çš„æ¨ç†è®­ç»ƒç›¸æ¯”ï¼Œéœ€è¦æ›´é«˜çš„å­¦ä¹ ç‡æ‰èƒ½æœ‰æ•ˆè®­ç»ƒæ¨¡å‹ã€‚</li>
<li>ä½¿ç”¨æ­¤æ•°æ®é›†æ˜¾è‘—æå‡äº†åŸºç¡€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œåœ¨AIME 2024æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†è¾ƒé«˜çš„é€šè¿‡ç‡ã€‚</li>
<li>æ­¤ç ”ç©¶æˆæœè¶…è¶Šå¤§å¤šæ•°ç°æœ‰è’¸é¦æ¨¡å‹å¹¶æ¥è¿‘æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>æ‰€æœ‰æ•°æ®é›†å’Œæ–¹æ³•å·²å…¬å¼€ï¼Œä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„å¿«é€Ÿå‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17565">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-440dee1fa035bcf8da74a5fc55aba2d3.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="RefVNLI-Towards-Scalable-Evaluation-of-Subject-driven-Text-to-image-Generation"><a href="#RefVNLI-Towards-Scalable-Evaluation-of-Subject-driven-Text-to-image-Generation" class="headerlink" title="RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image   Generation"></a>RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image   Generation</h2><p><strong>Authors:Aviv Slobodkin, Hagai Taitelbaum, Yonatan Bitton, Brian Gordon, Michal Sokolik, Nitzan Bitton Guetta, Almog Gueta, Royi Rassin, Itay Laish, Dani Lischinski, Idan Szpektor</strong></p>
<p>Subject-driven text-to-image (T2I) generation aims to produce images that align with a given textual description, while preserving the visual identity from a referenced subject image. Despite its broad downstream applicability â€“ ranging from enhanced personalization in image generation to consistent character representation in video rendering â€“ progress in this field is limited by the lack of reliable automatic evaluation. Existing methods either assess only one aspect of the task (i.e., textual alignment or subject preservation), misalign with human judgments, or rely on costly API-based evaluation. To address this, we introduce RefVNLI, a cost-effective metric that evaluates both textual alignment and subject preservation in a single prediction. Trained on a large-scale dataset derived from video-reasoning benchmarks and image perturbations, RefVNLI outperforms or matches existing baselines across multiple benchmarks and subject categories (e.g., \emph{Animal}, \emph{Object}), achieving up to 6.4-point gains in textual alignment and 8.5-point gains in subject consistency. It also excels with lesser-known concepts, aligning with human preferences at over 87% accuracy. </p>
<blockquote>
<p>ä¸»é¢˜é©±åŠ¨çš„æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ç”Ÿæˆæ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒï¼ŒåŒæ—¶ä¿ç•™å‚è€ƒä¸»é¢˜å›¾åƒçš„å¯è§†åŒ–æ ‡è¯†ã€‚å°½ç®¡å…¶åœ¨ä¸‹æ¸¸åº”ç”¨çš„å¹¿æ³›æ€§ä»å¢å¼ºå›¾åƒç”Ÿæˆçš„ä¸ªæ€§åŒ–åˆ°è§†é¢‘æ¸²æŸ“ä¸­çš„ä¸€è‡´å­—ç¬¦è¡¨ç¤ºéƒ½é€‚ç”¨ï¼Œä½†æ­¤é¢†åŸŸçš„è¿›å±•å´å—é™äºå¯é çš„è‡ªåŠ¨è¯„ä¼°çš„ç¼ºä¹ã€‚ç°æœ‰æ–¹æ³•åªè¯„ä¼°ä»»åŠ¡çš„æŸä¸€æ–¹é¢ï¼ˆå¦‚æ–‡æœ¬å¯¹é½æˆ–ä¸»é¢˜ä¿ç•™ï¼‰ï¼Œä¸äººç±»åˆ¤æ–­ä¸ç¬¦ï¼Œæˆ–ä¾èµ–äºæˆæœ¬é«˜æ˜‚çš„åŸºäºAPIçš„è¯„ä¼°ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RefVNLIï¼Œè¿™æ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„æŒ‡æ ‡ï¼Œå¯ä»¥åœ¨ä¸€æ¬¡é¢„æµ‹ä¸­å¯¹æ–‡æœ¬å¯¹é½å’Œä¸»é¢˜ä¿ç•™è¿›è¡Œè¯„ä¼°ã€‚RefVNLIç»è¿‡è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•å’Œå›¾åƒæ‰°åŠ¨è¡ç”Ÿçš„å¤§è§„æ¨¡æ•°æ®é›†çš„è®­ç»ƒï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œä¸»é¢˜ç±»åˆ«ï¼ˆå¦‚â€œåŠ¨ç‰©â€ã€â€œç‰©ä½“â€ï¼‰ä¸­çš„è¡¨ç°ä¼˜äºæˆ–åŒ¹é…ç°æœ‰åŸºçº¿ï¼Œåœ¨æ–‡æœ¬å¯¹é½æ–¹é¢å®ç°äº†é«˜è¾¾6.4ç‚¹çš„å¢ç›Šï¼Œåœ¨ä¸»é¢˜ä¸€è‡´æ€§æ–¹é¢å®ç°äº†é«˜è¾¾8.5ç‚¹çš„å¢ç›Šã€‚æ­¤å¤–ï¼Œåœ¨å¤„ç†è¾ƒä¸ºé™Œç”Ÿçš„æ¦‚å¿µæ—¶ï¼Œå®ƒä»¥è¶…è¿‡87%çš„å‡†ç¡®ç‡ä¸äººç±»åå¥½ä¿æŒä¸€è‡´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17502v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ä»»åŠ¡æ—¨åœ¨æ ¹æ®ç»™å®šçš„æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒï¼ŒåŒæ—¶ä¿ç•™å‚è€ƒä¸»ä½“å›¾åƒçš„å¯è§†èº«ä»½ã€‚å°½ç®¡è¯¥æŠ€æœ¯åœ¨ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€è§†é¢‘æ¸²æŸ“ä¸­çš„è§’è‰²ä¸€è‡´æ€§ç­‰æ–¹é¢æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä½†å…¶è¿›å±•å—é™äºç¼ºä¹å¯é çš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†RefVNLIï¼Œè¿™æ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¯ä»¥åœ¨ä¸€æ¬¡é¢„æµ‹ä¸­å¯¹æ–‡æœ¬å¯¹é½å’Œä¸»é¢˜ä¿ç•™è¿›è¡Œè¯„ä¼°ã€‚è¯¥æŒ‡æ ‡ç»è¿‡å¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒï¼Œæ¥æºäºè§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•å’Œå›¾åƒæ‰°åŠ¨ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œä¸»é¢˜ç±»åˆ«ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå®ç°äº†æ–‡æœ¬å¯¹é½é«˜è¾¾6.4ç‚¹çš„å¢ç›Šå’Œä¸»é¢˜ä¸€è‡´æ€§é«˜è¾¾8.5ç‚¹çš„å¢ç›Šã€‚å®ƒè¿˜èƒ½å¾ˆå¥½åœ°å¤„ç†è¾ƒä¸ºé™Œç”Ÿçš„æ¦‚å¿µï¼Œä¸äººç±»åå¥½å¯¹é½çš„å‡†ç¡®ç‡è¶…è¿‡87%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡æ—¨åœ¨æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒï¼ŒåŒæ—¶ä¿ç•™å‚è€ƒå›¾åƒçš„ä¸»ä½“èº«ä»½ã€‚</li>
<li>è¯¥é¢†åŸŸçš„è¿›å±•å—é™äºç¼ºä¹å¯é çš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ–¹æ³•å¾€å¾€åªè¯„ä¼°ä»»åŠ¡çš„ä¸€ä¸ªæ–¹é¢ï¼Œä¸äººç±»åˆ¤æ–­ä¸ä¸€è‡´ï¼Œä¸”ä¾èµ–äºæ˜‚è´µçš„APIè¯„ä¼°ã€‚</li>
<li>RefVNLIæ˜¯ä¸€ç§ç»æµé«˜æ•ˆçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¯ä»¥åŒæ—¶è¯„ä¼°æ–‡æœ¬å¯¹é½å’Œä¸»é¢˜ä¿ç•™ã€‚</li>
<li>RefVNLIåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å’Œä¸»é¢˜ç±»åˆ«ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå®ç°äº†æ–‡æœ¬å¯¹é½å’Œä¸»é¢˜ä¸€è‡´æ€§çš„æ˜¾è‘—å¢ç›Šã€‚</li>
<li>RefVNLIå¤„ç†è¾ƒä¸ºé™Œç”Ÿçš„æ¦‚å¿µæ—¶è¡¨ç°è‰¯å¥½ï¼Œä¸äººç±»åå¥½å¯¹é½çš„å‡†ç¡®ç‡è¶…è¿‡87%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17502">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9b8c489d7bcc9b86e6e962dbb53b11bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc47404e4035a901e18a9dac548c0966.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1935b781154349fb0918b181e49aa7d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc6656c5a1c1e86a6b2848de11e00b0f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-59f4e66fa5033ef25a17f4a3480dad5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ec355885488a101d2fc35160973703c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a515a4c16d910545106e629932cdfa1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7175d069acd24b22a53acccb826afe7.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Perspective-Aware-Reasoning-in-Vision-Language-Models-via-Mental-Imagery-Simulation"><a href="#Perspective-Aware-Reasoning-in-Vision-Language-Models-via-Mental-Imagery-Simulation" class="headerlink" title="Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery   Simulation"></a>Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery   Simulation</h2><p><strong>Authors:Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung</strong></p>
<p>We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡å¿ƒç†å›¾åƒæ¨¡æ‹Ÿåœ¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸­è¿›è¡Œè§†è§’æ„ŸçŸ¥æ¨ç†çš„æ¡†æ¶ã€‚è§†è§’æ„ŸçŸ¥èƒ½åŠ›æ˜¯ä»ä¸åŒè§’åº¦æ„ŸçŸ¥ç¯å¢ƒæˆ–æƒ…å¢ƒçš„èƒ½åŠ›ï¼Œæ˜¯äººç±»è§†è§‰ç†è§£çš„å…³é”®åŸºå‡†ï¼Œå¯¹äºç¯å¢ƒäº¤äº’ä»¥åŠä¸è‡ªä¸»å®ä½“çš„åä½œè‡³å…³é‡è¦ã€‚å°½ç®¡VLMåœ¨è§†è§‰æ¨ç†æ–¹é¢æœ‰æ‰€è¿›æ­¥ï¼Œä½†æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œç°ä»£VLMä¸¥é‡ç¼ºä¹è§†è§’æ„ŸçŸ¥æ¨ç†èƒ½åŠ›ï¼Œå¹¶è¡¨ç°å‡ºå¼ºçƒˆçš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§£è¯»åè§ã€‚ä¸ºäº†å¼¥è¡¥VLMä¸äººç±»æ„ŸçŸ¥ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬å…³æ³¨å¿ƒç†å›¾åƒçš„ä½œç”¨ï¼Œäººç±»é€šè¿‡æŠ½è±¡çš„è¡¨ç¤ºæ¥æ„ŸçŸ¥ä¸–ç•Œï¼Œè¿™æœ‰åŠ©äºè§†è§’å˜åŒ–ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºæŠ½è±¡è§†è§’å˜åŒ–ï¼ˆAPCï¼‰çš„è§†è§’æ„ŸçŸ¥æ¨ç†æ¡†æ¶ï¼Œå®ƒæœ‰æ•ˆåœ°åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œå¦‚ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²å’Œæ–¹ä½ä¼°è®¡æ¥æ„å»ºåœºæ™¯æŠ½è±¡ï¼Œå®ç°è§†è§’è½¬æ¢ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®å›¾åƒåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒä¸å„ç§VLMç›¸æ¯”ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨è§†è§’æ„ŸçŸ¥æ¨ç†æ–¹é¢çš„æ˜¾è‘—æ”¹è¿›ï¼Œè¿›ä¸€æ­¥è¶…è¶Šäº†å¾®è°ƒçš„ç©ºé—´æ¨ç†æ¨¡å‹å’ŒåŸºäºæ–°è§†å›¾åˆæˆçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17207v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://apc-vlm.github.io/">https://apc-vlm.github.io/</a></p>
<p><strong>Summary</strong><br>åŸºäºäººç±»å¿ƒæ™ºæ¨¡æ‹Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢å‘è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„è§†è§’æ„ŸçŸ¥æ¨ç†æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼ºè°ƒè§†è§’è½¬æ¢çš„é‡è¦æ€§ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»ä»ä¸åŒè§’åº¦æ„ŸçŸ¥ç¯å¢ƒå’Œæƒ…å¢ƒçš„èƒ½åŠ›ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„è§†è§‰åŸºç¡€æ¨¡å‹å¦‚ç›®æ ‡æ£€æµ‹ã€åˆ†å‰²å’Œæ–¹ä½ä¼°è®¡ç­‰ï¼Œæ„å»ºåœºæ™¯æŠ½è±¡å¹¶å¯ç”¨è§†è§’è½¬æ¢ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†VLMsåœ¨è§†è§’æ„ŸçŸ¥æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»‹ç»äº†è§†è§’æ„ŸçŸ¥æ¨ç†åœ¨è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>å¼ºè°ƒäº†æ¨¡æ‹Ÿäººç±»å¿ƒæ™ºçš„é‡è¦æ€§ï¼Œä»¥ä»ä¸åŒè§’åº¦ç†è§£ç¯å¢ƒå’Œæƒ…å¢ƒã€‚</li>
<li>åˆ©ç”¨å…ˆè¿›çš„è§†è§‰åŸºç¡€æ¨¡å‹æ„å»ºåœºæ™¯æŠ½è±¡ã€‚</li>
<li>æå‡ºçš„Abstract Perspective Changeï¼ˆAPCï¼‰æ¡†æ¶èƒ½æœ‰æ•ˆæé«˜VLMsåœ¨è§†è§’æ„ŸçŸ¥æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>åœ¨åˆæˆå’ŒçœŸå®å›¾åƒåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜APCæ¡†æ¶çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>APCæ¡†æ¶ç›¸æ¯”å…¶ä»–ç©ºé—´æ¨ç†æ¨¡å‹å’ŒåŸºäºæ–°è§†è§’åˆæˆçš„æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17207">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b915cbfb0ec6eb19fdddf0781f9da142.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9475581e23339f09045698d9f237e75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76ab0850ad6c5980209bf5ccf4fd95c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c5115ecc6ed9fdc7b17793402bd77a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7aefc1a8f7cb5bd8d150904e2d09a0b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c80b80153f6fc6f68810763e0953be1.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Nemotron-CrossThink-Scaling-Self-Learning-beyond-Math-Reasoning"><a href="#Nemotron-CrossThink-Scaling-Self-Learning-beyond-Math-Reasoning" class="headerlink" title="Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning"></a>Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning</h2><p><strong>Authors:Syeda Nahida Akter, Shrimai Prabhumoye, Matvei Novikov, Seungju Han, Ying Lin, Evelina Bakhturina, Eric Nyberg, Yejin Choi, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro</strong></p>
<p>Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning â€“ where rules and correctness are well-defined â€“ generalizing these methods to broader reasoning domains remains challenging due to limited data, the lack of verifiable reward structures, and diverse task requirements. In this work, we propose NEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain corpora, including both synthetic and real-world question-answer pairs, into RL training to improve generalization across diverse reasoning tasks. NEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from varied sources spanning STEM, humanities, social sciences, etc.; (2) applying structured templates (e.g., multiple-choice and open-ended) to control answer-space complexity; (3) filtering for verifiable answers; and (4) optimizing data blending strategies that utilizes data from multiple sources effectively. Our approach enables scalable and verifiable reward modeling beyond mathematics and demonstrates improved accuracies on both math (MATH-500: +30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%, GPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover, NEMOTRON-CROSSTHINK exhibits significantly improved response efficiency â€“ using 28% fewer tokens for correct answers â€“ highlighting more focused and effective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that integrating multi-domain, multi-format data in RL leads to more accurate, efficient, and generalizable LLMs. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¢å¼ºçš„æƒ…å†µä¸‹ã€‚å°½ç®¡å…ˆå‰çš„å·¥ä½œå·²æˆåŠŸå°†RLåº”ç”¨äºæ•°å­¦æ¨ç†â€”â€”è§„åˆ™å’Œæ­£ç¡®æ€§å®šä¹‰æ˜ç¡®â€”â€”ä½†ç”±äºæ•°æ®æœ‰é™ã€å¯éªŒè¯çš„å¥–åŠ±ç»“æ„ç¼ºå¤±ä»¥åŠå¤šæ ·åŒ–çš„ä»»åŠ¡è¦æ±‚ï¼Œå°†è¿™äº›æ–¹æ³•æ¨å¹¿åˆ°æ›´å¹¿æ³›çš„æ¨ç†é¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†NEMOTRON-CROSSTHINKæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç³»ç»Ÿåœ°ç»“åˆäº†å¤šé¢†åŸŸè¯­æ–™åº“ï¼ŒåŒ…æ‹¬åˆæˆå’Œç°å®ä¸–ç•Œçš„é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œç”¨äºRLè®­ç»ƒï¼Œä»¥æé«˜åœ¨ä¸åŒæ¨ç†ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚NEMOTRON-CROSSTHINKé€šè¿‡ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰èå…¥æ¶µç›–STEMã€äººæ–‡ã€ç¤¾ä¼šç§‘å­¦ç­‰é¢†åŸŸçš„å¤šå…ƒæ•°æ®æ¥æºï¼›ï¼ˆ2ï¼‰åº”ç”¨ç»“æ„åŒ–æ¨¡æ¿ï¼ˆå¦‚é€‰æ‹©é¢˜å’Œå¼€æ”¾å¼é—®é¢˜ï¼‰æ¥æ§åˆ¶ç­”æ¡ˆç©ºé—´çš„å¤æ‚æ€§ï¼›ï¼ˆ3ï¼‰ç­›é€‰å¯éªŒè¯çš„ç­”æ¡ˆï¼›ï¼ˆ4ï¼‰ä¼˜åŒ–æ•°æ®æ··åˆç­–ç•¥ï¼Œæœ‰æ•ˆåˆ©ç”¨å¤šæºæ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æ•°å­¦ä¹‹å¤–å®ç°å¯æ‰©å±•å’Œå¯éªŒè¯çš„å¥–åŠ±å»ºæ¨¡ï¼Œå¹¶åœ¨æ•°å­¦ï¼ˆMATH-500ï¼š+30.1%ï¼ŒAMC23ï¼š+27.5%ï¼‰å’Œéæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆMMLU-PROï¼š+12.8%ï¼ŒGPQA-DIAMONDï¼š+11.3%ï¼ŒAGIEVALï¼š+15.1%ï¼ŒSUPERGPQAï¼š+3.8%ï¼‰ä¸Šæ˜¾ç¤ºå‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒNEMOTRON-CROSSTHINKçš„å“åº”æ•ˆç‡æ˜¾è‘—æé«˜â€”â€”æ­£ç¡®ç­”æ¡ˆä½¿ç”¨çš„ä»¤ç‰Œå‡å°‘äº†28%ï¼Œçªæ˜¾å‡ºæ›´é›†ä¸­ã€æ›´æœ‰æ•ˆçš„æ¨ç†ã€‚é€šè¿‡NEMOTRON-CROSSTHINKï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨RLä¸­æ•´åˆå¤šé¢†åŸŸã€å¤šæ ¼å¼æ•°æ®ä¼šå¯¼è‡´æ›´å‡†ç¡®ã€é«˜æ•ˆå’Œå¯æ¨å¹¿çš„LLMã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13941v2">PDF</a> 18 pages, 7 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚å°½ç®¡å…ˆå‰çš„å·¥ä½œå·²æˆåŠŸå°†RLåº”ç”¨äºæ•°å­¦æ¨ç†ï¼Œä½†å°†è¿™äº›æ–¹æ³•æ¨å¹¿åˆ°æ›´å¹¿æ³›çš„æ¨ç†é¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå­˜åœ¨æ•°æ®æœ‰é™ã€å¯éªŒè¯çš„å¥–åŠ±ç»“æ„ç¼ºä¹ä»¥åŠä»»åŠ¡è¦æ±‚å¤šæ ·åŒ–ç­‰é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºNEMOTRON-CROSSTHINKæ¡†æ¶ï¼Œé€šè¿‡èå…¥å¤šé¢†åŸŸè¯­æ–™åº“ï¼ŒåŒ…æ‹¬åˆæˆå’Œç°å®ä¸–ç•Œçš„é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œæ¥æ”¹å–„RLè®­ç»ƒåœ¨å¤šæ ·åŒ–æ¨ç†ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚NEMOTRON-CROSSTHINKé€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³å…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰èå…¥æ¶µç›–STEMã€äººæ–‡ã€ç¤¾ä¼šç§‘å­¦ç­‰é¢†åŸŸçš„å¤šå…ƒæ•°æ®æ¥æºï¼›ï¼ˆ2ï¼‰åº”ç”¨ç»“æ„åŒ–çš„æ¨¡æ¿ï¼ˆå¦‚é€‰æ‹©é¢˜å’Œå¼€æ”¾æ€§é—®é¢˜ï¼‰æ¥æ§åˆ¶ç­”æ¡ˆç©ºé—´çš„å¤æ‚æ€§ï¼›ï¼ˆ3ï¼‰ç­›é€‰å¯éªŒè¯çš„ç­”æ¡ˆï¼›ï¼ˆ4ï¼‰ä¼˜åŒ–æ•°æ®æ··åˆç­–ç•¥ï¼Œæœ‰æ•ˆåˆ©ç”¨å¤šæ¥æºæ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿å¥–åŠ±æ¨¡å‹èƒ½å¤Ÿåœ¨æ•°å­¦ä¹‹å¤–è¿›è¡Œæ‰©å±•å’ŒéªŒè¯ï¼Œå¹¶åœ¨æ•°å­¦ï¼ˆMATH-500ï¼š+30.1%ï¼ŒAMC23ï¼š+27.5%ï¼‰å’Œéæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆMMLU-PROï¼š+12.8%ï¼ŒGPQA-DIAMONDï¼š+11.3%ï¼ŒAGIEVALï¼š+15.1%ï¼ŒSUPERGPQAï¼š+3.8%ï¼‰ä¸Šæ˜¾ç¤ºå‡ºæ›´é«˜çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒNEMOTRON-CROSSTHINKçš„å“åº”æ•ˆç‡æ˜¾è‘—æé«˜ï¼Œæ­£ç¡®ç­”æ¡ˆä½¿ç”¨çš„ä»¤ç‰Œå‡å°‘äº†28%ï¼Œæ˜¾ç¤ºå‡ºæ›´åŠ é›†ä¸­å’Œæœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡NEMOTRON-CROSSTHINKï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨RLä¸­æ•´åˆå¤šé¢†åŸŸã€å¤šæ ¼å¼æ•°æ®ä¼šå¯¼è‡´æ›´å‡†ç¡®ã€é«˜æ•ˆå’Œå¯æ³›åŒ–çš„LLMsã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šé¢†åŸŸæ¨ç†æ–¹é¢ã€‚</li>
<li>NEMOTRON-CROSSTHINKæ¡†æ¶é€šè¿‡èå…¥å¤šé¢†åŸŸè¯­æ–™åº“ï¼ŒåŒ…æ‹¬åˆæˆå’Œç°å®ä¸–ç•Œçš„é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œæ¥æ”¹å–„RLè®­ç»ƒåœ¨å¤šæ ·åŒ–æ¨ç†ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>NEMOTRON-CROSSTHINKè§£å†³äº†å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºæ›´å¹¿æ³›æ¨ç†é¢†åŸŸçš„å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®æœ‰é™ã€å¯éªŒè¯å¥–åŠ±ç»“æ„çš„ç¼ºä¹ä»¥åŠä»»åŠ¡è¦æ±‚çš„å¤šæ ·åŒ–ã€‚</li>
<li>NEMOTRON-CROSSTHINKé€šè¿‡èå…¥å¤šå…ƒæ•°æ®æ¥æºã€åº”ç”¨ç»“æ„åŒ–æ¨¡æ¿ã€ç­›é€‰å¯éªŒè¯ç­”æ¡ˆä»¥åŠä¼˜åŒ–æ•°æ®æ··åˆç­–ç•¥ç­‰æ–¹æ³•æ¥æé«˜LLMsçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>NEMOTRON-CROSSTHINKåœ¨å¤šä¸ªæ•°å­¦å’Œéæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¸”åœ¨å“åº”æ•ˆç‡ä¸Šæ˜¾è‘—æé«˜ã€‚</li>
<li>NEMOTRON-CROSSTHINKæ–¹æ³•ä½¿å¾—å¥–åŠ±æ¨¡å‹èƒ½å¤Ÿæ‰©å±•åˆ°æ•°å­¦é¢†åŸŸä¹‹å¤–ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¯¹éæ•°å­¦æ¨ç†ä»»åŠ¡è¿›è¡ŒéªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13941">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0c15b0028bf70f31228c98f3d66f2d39.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3fe186f528135c2a02915541714230a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7728e11fcdcfd2d0ea86564ef83fd0da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3fb5f2d740bd181cd509b9eb7cc8968.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CheatAgent-Attacking-LLM-Empowered-Recommender-Systems-via-LLM-Agent"><a href="#CheatAgent-Attacking-LLM-Empowered-Recommender-Systems-via-LLM-Agent" class="headerlink" title="CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent"></a>CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent</h2><p><strong>Authors:Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang</strong></p>
<p>Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the systemâ€™s inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èµ‹èƒ½çš„æ¨èç³»ç»Ÿï¼ˆRecSysï¼‰åœ¨ä¸ªæ€§åŒ–ç”¨æˆ·ä½“éªŒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¹¶å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚å°½ç®¡å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¿›æ­¥ï¼Œä½†å…³äºLLMèµ‹èƒ½çš„RecSysçš„å®‰å…¨æ¼æ´çš„ç ”ç©¶é—®é¢˜ä»ç„¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè¢«å¿½è§†ã€‚è€ƒè™‘åˆ°å®‰å…¨å’Œéšç§çš„æ‹…å¿§ï¼Œæ›´å®é™…çš„æ˜¯å…³æ³¨æ”»å‡»é»‘ç›’RecSysï¼Œæ”»å‡»è€…åªèƒ½è§‚å¯Ÿç³»ç»Ÿçš„è¾“å…¥å’Œè¾“å‡ºã€‚ç„¶è€Œï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†çš„ä¼ ç»Ÿæ”»å‡»æ–¹æ³•ç”±äºå¤„ç†å¤æ‚æ–‡æœ¬è¾“å…¥ã€è§„åˆ’å’Œæ¨ç†çš„èƒ½åŠ›æœ‰é™ï¼Œå› æ­¤æ”»å‡»LLMèµ‹èƒ½çš„RecSyså¹¶ä¸æœ‰æ•ˆã€‚å¦ä¸€æ–¹é¢ï¼ŒLLMç”±äºåœ¨æ¨¡æ‹Ÿäººç±»å†³ç­–è¿‡ç¨‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæä¾›äº†ä½œä¸ºæ”»å‡»RecSysä»£ç†çš„ç©ºå‰æœºä¼šã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»æ¡†æ¶ï¼Œåä¸ºCheatAgentï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMçš„äººç±»åŒ–èƒ½åŠ›ï¼Œå¼€å‘äº†ä¸€ä¸ªåŸºäºLLMçš„ä»£ç†æ¥æ”»å‡»LLMèµ‹èƒ½çš„RecSysã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆç¡®å®šæ’å…¥ä½ç½®ï¼Œä»¥åœ¨æœ€å°è¾“å…¥ä¿®æ”¹çš„æƒ…å†µä¸‹å®ç°æœ€å¤§å½±å“ã€‚ç„¶åï¼ŒLLMä»£ç†è¢«è®¾è®¡æˆåœ¨ç›®æ ‡ä½ç½®æ’å…¥å¯¹æŠ—æ€§æ‰°åŠ¨ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ç”Ÿæˆæ‰°åŠ¨çš„è´¨é‡ï¼Œæˆ‘ä»¬åˆ©ç”¨æç¤ºè°ƒæ•´æŠ€æœ¯ï¼Œé€šè¿‡æ¥è‡ªå—å®³è€…RecSysçš„åé¦ˆæ¥æ”¹è¿›æ”»å‡»ç­–ç•¥ã€‚åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜äº†æˆ‘ä»¬æå‡ºçš„æ”»å‡»æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13192v2">PDF</a> Accepted by KDD 2024;</p>
<p><strong>Summary</strong>ï¼š<br>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èµ‹èƒ½çš„æ¨èç³»ç»Ÿï¼ˆRecSysï¼‰åœ¨ä¸ªæ€§åŒ–ç”¨æˆ·ä½“éªŒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¹¶å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå…³äºLLMèµ‹èƒ½çš„RecSysçš„å®‰å…¨æ¼æ´çš„ç ”ç©¶é—®é¢˜ä»ç„¶è¢«å¤§å¤§å¿½è§†ã€‚è€ƒè™‘åˆ°å®‰å…¨å’Œéšç§é—®é¢˜ï¼Œæ›´å®é™…çš„æ˜¯å…³æ³¨æ”»å‡»é»‘ç®±RecSysï¼Œæ”»å‡»è€…åªèƒ½è§‚å¯Ÿç³»ç»Ÿçš„è¾“å…¥å’Œè¾“å‡ºã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»æ¡†æ¶ï¼Œåä¸ºCheatAgentï¼Œåˆ©ç”¨LLMçš„äººç±»åŒ–èƒ½åŠ›æ¥æ”»å‡»LLMèµ‹èƒ½çš„RecSysã€‚é€šè¿‡è¯†åˆ«æœ€å¤§å½±å“çš„æœ€å°è¾“å…¥ä¿®æ”¹ä½ç½®ï¼ŒLLMä»£ç†ç”Ÿæˆå¯¹æŠ—æ€§æ‰°åŠ¨å¹¶æ’å…¥ç›®æ ‡ä½ç½®ã€‚åˆ©ç”¨æç¤ºè°ƒæ•´æŠ€æœ¯ï¼Œé€šè¿‡å—å®³RecSysçš„åé¦ˆè¿­ä»£æ”¹è¿›æ”»å‡»ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLMèµ‹èƒ½çš„æ¨èç³»ç»Ÿï¼ˆRecSysï¼‰åœ¨ä¸ªæ€§åŒ–ä½“éªŒæ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å®‰å…¨æ¼æ´é—®é¢˜äºŸå¾…ç ”ç©¶ã€‚</li>
<li>ä¼ ç»Ÿé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ”»å‡»æ–¹æ³•å¯¹äºLLMèµ‹èƒ½çš„RecSysæ•ˆæœä¸ä½³ã€‚</li>
<li>LLMå…·æœ‰æ¨¡æ‹Ÿäººç±»å†³ç­–è¿‡ç¨‹çš„å¼ºå¤§èƒ½åŠ›ï¼Œå¯æœåŠ¡äºæ”»å‡»RecSysã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»æ¡†æ¶CheatAgentï¼Œåˆ©ç”¨LLMä»£ç†æ”»å‡»LLMèµ‹èƒ½çš„RecSysã€‚</li>
<li>CheatAgenté€šè¿‡è¯†åˆ«æœ€å¤§å½±å“çš„æœ€å°è¾“å…¥ä¿®æ”¹ä½ç½®æ¥å®æ–½æ”»å‡»ã€‚</li>
<li>åˆ©ç”¨æç¤ºè°ƒæ•´æŠ€æœ¯é€šè¿‡å—å®³RecSysçš„åé¦ˆæ”¹è¿›æ”»å‡»ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13192">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-775288518611024853cab145a144f22b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d51821e0080fffa8a4f5d94567282240.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c6ed2d611c426ca35592c79d4696ec3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GeoSense-Evaluating-Identification-and-Application-of-Geometric-Principles-in-Multimodal-Reasoning"><a href="#GeoSense-Evaluating-Identification-and-Application-of-Geometric-Principles-in-Multimodal-Reasoning" class="headerlink" title="GeoSense: Evaluating Identification and Application of Geometric   Principles in Multimodal Reasoning"></a>GeoSense: Evaluating Identification and Application of Geometric   Principles in Multimodal Reasoning</h2><p><strong>Authors:Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng</strong></p>
<p>Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of $65.3$. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSenseâ€™s potential to guide future advancements in MLLMsâ€™ geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence. </p>
<blockquote>
<p>å‡ ä½•é—®é¢˜è§£å†³ï¼ˆGPSï¼‰æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œè¦æ±‚è§†è§‰ç†è§£å’Œç¬¦å·æ¨ç†ï¼Œèƒ½æœ‰æ•ˆè¡¡é‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚äººç±»åœ¨æ­¤ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½åœ¨è§†è§‰ç¯å¢ƒä¸­å‡†ç¡®è¯†åˆ«å¹¶çµæ´»åº”ç”¨å‡ ä½•åŸç†ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•æœªèƒ½åŒæ—¶è¯„ä¼°äººç±»ç±»ä¼¼çš„å‡ ä½•æ¨ç†æœºåˆ¶åœ¨MLLMsä¸­çš„ä¸¤ä¸ªç»´åº¦ï¼Œè¿™åœ¨è¯„ä¼°MLLMså¤„ç†GPSçš„èƒ½åŠ›æ—¶å­˜åœ¨å…³é”®å·®è·ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†GeoSenseï¼Œè¿™æ˜¯é¦–ä¸ªå…¨é¢çš„åŒè¯­åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é€šè¿‡å‡ ä½•åŸç†çš„è§†è§’ï¼Œç³»ç»Ÿåœ°è¯„ä¼°MLLMsçš„å‡ ä½•æ¨ç†èƒ½åŠ›ã€‚GeoSenseå…·æœ‰æ¶µç›–å¹³é¢å’Œç«‹ä½“å‡ ä½•çš„äº”çº§åˆ†å±‚å‡ ä½•åŸç†æ¡†æ¶ã€ç»è¿‡ç²¾å¿ƒæ³¨é‡Šçš„1789ä¸ªé—®é¢˜é›†å’Œåˆ›æ–°çš„è¯„ä¼°ç­–ç•¥ã€‚é€šè¿‡åœ¨GeoSenseä¸Šä¸å„ç§å¼€æºå’Œé—­æºçš„MLLMsè¿›è¡Œå¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°Gemini-2.0-pro-flashè¡¨ç°æœ€ä½³ï¼Œæ€»ä½“å¾—åˆ†ä¸º65.3åˆ†ã€‚æˆ‘ä»¬çš„æ·±å…¥åˆ†æè¡¨æ˜ï¼Œå‡ ä½•åŸç†çš„è¯†åˆ«å’Œåº”ç”¨ä»ç„¶æ˜¯é¢†å…ˆMLLMsçš„ç“¶é¢ˆï¼Œå…±åŒåˆ¶çº¦äº†å®ƒä»¬çš„æ¨ç†èƒ½åŠ›ã€‚è¿™äº›å‘ç°çªå‡ºäº†GeoSenseåœ¨æŒ‡å¯¼æœªæ¥MLLMså‡ ä½•æ¨ç†èƒ½åŠ›è¿›æ­¥æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºäººå·¥æ™ºèƒ½ä¸­æ›´ç¨³å¥ã€æ›´ç¬¦åˆäººç±»æ¨ç†æ–¹å¼çš„å¼€å‘å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12597v2">PDF</a> 10 pages, 8 figures</p>
<p><strong>Summary</strong>ï¼šå¼•å…¥äº†ä¸€ä¸ªç»¼åˆçš„åŒè¯­åŸºå‡†æµ‹è¯•GeoSenseï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å‡ ä½•æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œè§‚å¯Ÿåˆ°Gemini-2.0-pro-flashè¡¨ç°æœ€ä½³ï¼Œè¾¾åˆ°æ€»ä½“å¾—åˆ†65.3ã€‚åˆ†æè¡¨æ˜ï¼Œå‡ ä½•åŸåˆ™çš„è¯†åˆ«å’Œåº”ç”¨ä»æ˜¯MLLMsçš„ç“¶é¢ˆã€‚GeoSenseæœ‰æœ›æŒ‡å¯¼MLLMsåœ¨å‡ ä½•æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœªæ¥å‘å±•ï¼Œä¸ºäººå·¥æ™ºèƒ½å¸¦æ¥æ›´ç¨³å¥å’Œäººæ€§åŒ–çš„æ¨ç†ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å‡ ä½•é—®é¢˜è§£å†³ï¼ˆGPSï¼‰æ˜¯è¯„ä¼°æ¨ç†èƒ½åŠ›çš„é‡è¦ä»»åŠ¡ï¼Œæ¶‰åŠè§†è§‰ç†è§£å’Œç¬¦å·æ¨ç†ã€‚</li>
<li>äººç±»åœ¨GPSä»»åŠ¡ä¸­é€šè¿‡å‡†ç¡®è¯†åˆ«å’Œé€‚åº”æ€§åœ°åº”ç”¨å‡ ä½•åŸåˆ™å±•ç¤ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰åŸºå‡†æµ‹è¯•æœªèƒ½è”åˆè¯„ä¼°MLLMsçš„äººç±»å¼å‡ ä½•æ¨ç†æœºåˆ¶çš„ä¸¤ä¸ªæ–¹é¢ã€‚</li>
<li>GeoSenseæ˜¯é¦–ä¸ªå…¨é¢çš„åŒè¯­åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsçš„å‡ ä½•æ¨ç†èƒ½åŠ›ã€‚</li>
<li>GeoSenseå…·æœ‰æ¶µç›–å¹³é¢å’Œç«‹ä½“å‡ ä½•çš„äº”ä¸ªå±‚æ¬¡çš„åŸåˆ™æ¡†æ¶ã€ç²¾å¿ƒæ³¨é‡Šçš„é—®é¢˜é›†å’Œåˆ›æ–°è¯„ä¼°ç­–ç•¥ã€‚</li>
<li>åœ¨GeoSenseä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒGemini-2.0-pro-flashè¡¨ç°æœ€ä½³ï¼Œæ€»ä½“å¾—åˆ†ä¸º65.3ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12597">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62264de97f2e94ba8434ea2ba284aaa0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1248f789a0525ec8f4a0da82c7b3ce0f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dc2cb82d62d4f765bd5f967cd7ed1646.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be16d49e97b7b4b82cab328c2f4189a9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a209b682d46f01bfbd7b332c7049eaf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7fa74d74ca62fb103cf841e68d0a1906.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Teaching-Large-Language-Models-to-Reason-through-Learning-and-Forgetting"><a href="#Teaching-Large-Language-Models-to-Reason-through-Learning-and-Forgetting" class="headerlink" title="Teaching Large Language Models to Reason through Learning and Forgetting"></a>Teaching Large Language Models to Reason through Learning and Forgetting</h2><p><strong>Authors:Tianwei Ni, Allen Nie, Sapana Chaudhary, Yao Liu, Huzefa Rangwala, Rasool Fakoor</strong></p>
<p>Leveraging inference-time search in large language models has proven effective in further enhancing a trained modelâ€™s capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the modelâ€™s search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\times$. </p>
<blockquote>
<p>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†æ—¶é—´æœç´¢ï¼Œå·²è¢«è¯æ˜å¯ä»¥è¿›ä¸€æ­¥å¢å¼ºè®­ç»ƒæ¨¡å‹è§£å†³å¤æ‚æ•°å­¦å’Œæ¨ç†é—®é¢˜çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—å¢åŠ äº†è®¡ç®—æˆæœ¬å’Œæ¨ç†æ—¶é—´ï¼Œå› ä¸ºæ¨¡å‹å¿…é¡»ç”Ÿæˆå¹¶è¯„ä¼°å¤šä¸ªå€™é€‰è§£å†³æ–¹æ¡ˆæ¥è¯†åˆ«å¯è¡Œçš„æ¨ç†è·¯å¾„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡å¾®è°ƒæ¨¡å‹ç›´æ¥é›†æˆæœç´¢èƒ½åŠ›ï¼Œä½¿ç”¨æ¥è‡ªä¸åŒæœç´¢æ–¹æ³•çš„æˆåŠŸï¼ˆå­¦ä¹ ï¼‰å’Œå¤±è´¥æ¨ç†è·¯å¾„ï¼ˆé—å¿˜ï¼‰ã€‚è™½ç„¶ç”¨è¿™äº›æ•°æ®å¾®è°ƒæ¨¡å‹çœ‹ä¼¼ç®€å•ï¼Œä½†æˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šå¦‚æœç›²ç›®è¿›è¡Œå¾®è°ƒï¼Œæ¨¡å‹çš„æœç´¢èƒ½åŠ›å¾€å¾€ä¼šè¿…é€Ÿä¸‹é™ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œé€šè¿‡é‡‡ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œå¯ä»¥å¤§å¤§ç¼“è§£è¿™ç§é€€åŒ–ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„24ç‚¹æ¸¸æˆå’Œå€’è®¡æ—¶æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•çš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…ä¼˜äºæ ‡å‡†å¾®è°ƒæ–¹æ³•å’Œæ¨ç†æ—¶é—´æœç´¢åŸºå‡†æµ‹è¯•ï¼Œè€Œä¸”é€šè¿‡å‡å°‘æ¨ç†æ—¶é—´é«˜è¾¾180å€ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11364v2">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/twni2016/llm-reasoning-uft">https://github.com/twni2016/llm-reasoning-uft</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¼•å…¥æ¨ç†æ—¶é—´æœç´¢å¯å¢å¼ºæ¨¡å‹è§£å†³å¤æ‚æ•°å­¦å’Œæ¨ç†é—®é¢˜çš„èƒ½åŠ›ï¼Œä½†è®¡ç®—æˆæœ¬å’Œæ¨ç†æ—¶é—´æ˜¾è‘—å¢åŠ ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†æœç´¢èƒ½åŠ›ç›´æ¥é›†æˆåˆ°æ¨¡å‹ä¸­çš„æ–¹æ³•ï¼Œé€šè¿‡ç²¾ç»†è°ƒæ•´æ¨¡å‹ï¼Œä½¿ç”¨æˆåŠŸå’Œå¤±è´¥çš„æ¨ç†è·¯å¾„æ•°æ®ã€‚è™½ç„¶çœ‹ä¼¼ç®€å•çš„æ¨¡å‹è°ƒæ•´å´å­˜åœ¨å…³é”®é—®é¢˜ï¼Œå³å¦‚æœè¿›è¡Œç®€å•çš„è°ƒæ•´åˆ™æ¨¡å‹çš„æœç´¢èƒ½åŠ›ä¼šè¿…é€Ÿä¸‹é™ã€‚æœ¬æ–‡å±•ç¤ºäº†ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œå³é€šè¿‡å‡å°å­¦ä¹ ç‡å¯ä»¥å¤§å¹…ç¼“è§£æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…ä¼˜äºæ ‡å‡†ç²¾ç»†è°ƒæ•´å’Œæ¨ç†æ—¶é—´æœç´¢åŸºçº¿ï¼Œè¿˜èƒ½æ˜¾è‘—å‡å°‘æ¨ç†æ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥æ¨ç†æ—¶é—´æœç´¢å¯ä»¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è§£å†³å¤æ‚æ•°å­¦å’Œæ¨ç†é—®é¢˜çš„èƒ½åŠ›ã€‚</li>
<li>è¿™ç§æ–¹æ³•ä¼šå¢åŠ è®¡ç®—æˆæœ¬å’Œæ¨ç†æ—¶é—´ã€‚</li>
<li>é€šè¿‡ç²¾ç»†è°ƒæ•´æ¨¡å‹å¹¶é›†æˆæœç´¢èƒ½åŠ›ï¼Œå¯ä»¥åˆ©ç”¨æˆåŠŸå’Œå¤±è´¥çš„æ¨ç†è·¯å¾„æ•°æ®ã€‚</li>
<li>ç®€å•çš„æ¨¡å‹ç²¾ç»†è°ƒæ•´å¯èƒ½å¯¼è‡´æ¨¡å‹çš„æœç´¢èƒ½åŠ›è¿…é€Ÿä¸‹é™ã€‚</li>
<li>é€šè¿‡å‡å°å­¦ä¹ ç‡å¯ä»¥æ˜¾è‘—ç¼“è§£æ¨¡å‹æ€§èƒ½çš„ä¸‹é™ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨Game-of-24å’ŒCountdownæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11364">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-680b4394d313ea443864aea7a3431b62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c501d76cb21910ad64c9e86f93fe7ace.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-41adb84ed68e74a63a8994dc0aace7f8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Digital-Twin-Buildings-3D-Modeling-GIS-Integration-and-Visual-Descriptions-Using-Gaussian-Splatting-ChatGPT-Deepseek-and-Google-Maps-Platform"><a href="#Digital-Twin-Buildings-3D-Modeling-GIS-Integration-and-Visual-Descriptions-Using-Gaussian-Splatting-ChatGPT-Deepseek-and-Google-Maps-Platform" class="headerlink" title="Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual   Descriptions Using Gaussian Splatting, ChatGPT&#x2F;Deepseek, and Google Maps   Platform"></a>Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual   Descriptions Using Gaussian Splatting, ChatGPT&#x2F;Deepseek, and Google Maps   Platform</h2><p><strong>Authors:Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li</strong></p>
<p>Urban digital twins are virtual replicas of cities that use multi-source data and data analytics to optimize urban planning, infrastructure management, and decision-making. Towards this, we propose a framework focused on the single-building scale. By connecting to cloud mapping platforms such as Google Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language Models data analysis using ChatGPT(4o) and Deepseek-V3&#x2F;R1, and by using our Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings framework can retrieve a buildingâ€™s 3D model, visual descriptions, and achieve cloud-based mapping integration with large language model-based data analytics using a buildingâ€™s address, postal code, or geographic coordinates. </p>
<blockquote>
<p>åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åˆ©ç”¨å¤šæºæ•°æ®å’Œæ•°æ®åˆ†æä¼˜åŒ–åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œå†³ç­–åˆ¶å®šçš„åŸå¸‚è™šæ‹Ÿå‰¯æœ¬ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä»¥å•ä½“å»ºç­‘ä¸ºå°ºåº¦çš„æ¡†æ¶ã€‚é€šè¿‡è¿æ¥åˆ°è°·æ­Œåœ°å›¾å¹³å°APIç­‰äº‘åœ°å›¾å¹³å°ï¼Œåˆ©ç”¨æœ€æ–°çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä½¿ç”¨ChatGPTï¼ˆç¬¬4ç‰ˆï¼‰å’ŒDeepseek-V3&#x2F;R1è¿›è¡Œæ•°æ®åˆ†æï¼‰ï¼Œä»¥åŠåŸºäºé«˜æ–¯æº…æ¸çš„ç½‘æ ¼æå–ç®¡é“ï¼Œæˆ‘ä»¬çš„æ•°å­—åŒèƒèƒå»ºç­‘æ¡†æ¶å¯ä»¥æ£€ç´¢å»ºç­‘çš„3Dæ¨¡å‹å’Œè§†è§‰æè¿°ï¼Œå®ç°åŸºäºäº‘çš„åœ°å›¾é›†æˆä¸ä»¥å»ºç­‘åœ°å€ã€é‚®æ”¿ç¼–ç æˆ–åœ°ç†åæ ‡çš„å¤§å‹è¯­è¨€æ¨¡å‹æ•°æ®åˆ†æã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05769v3">PDF</a> -Fixed minor typo</p>
<p><strong>Summary</strong><br>åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åŸå¸‚çš„è™šæ‹Ÿå‰¯æœ¬ï¼Œåˆ©ç”¨å¤šæºæ•°æ®å’Œæ•°æ®åˆ†æä¼˜åŒ–åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œå†³ç­–åˆ¶å®šã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªä¸“æ³¨äºå•ä½“å»ºç­‘å°ºåº¦çš„æ¡†æ¶ï¼Œé€šè¿‡è¿æ¥äº‘è®¡ç®—å¹³å°ã€åˆ©ç”¨å…ˆè¿›çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹æ•°æ®åˆ†ææŠ€æœ¯ï¼Œå®ç°å»ºç­‘çš„ä¸‰ç»´æ¨¡å‹è·å–ã€è§†è§‰æè¿°ä»¥åŠä¸åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„äº‘è®¡ç®—é›†æˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åŸå¸‚çš„è™šæ‹Ÿå‰¯æœ¬ï¼Œç”¨äºä¼˜åŒ–åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œå†³ç­–åˆ¶å®šã€‚</li>
<li>æå‡ºçš„æ¡†æ¶ä¸“æ³¨äºå•ä½“å»ºç­‘å°ºåº¦ã€‚</li>
<li>é€šè¿‡è¿æ¥äº‘è®¡ç®—å¹³å°ï¼Œå¦‚Google Map Platforms APIsï¼Œè·å–å»ºç­‘æ•°æ®ã€‚</li>
<li>åˆ©ç”¨å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹æ•°æ®åˆ†ææŠ€æœ¯ï¼Œå¦‚ChatGPT(4o)å’ŒDeepseek-V3&#x2F;R1ï¼Œè¿›è¡Œåˆ†æã€‚</li>
<li>é‡‡ç”¨é«˜æ–¯æ’å€¼æ³•åŸºäºç½‘æ ¼æå–ç®¡é“æŠ€æœ¯ï¼Œå®ç°å»ºç­‘çš„ä¸‰ç»´æ¨¡å‹è·å–å’Œè§†è§‰æè¿°ã€‚</li>
<li>æ¡†æ¶èƒ½å¤Ÿå®ç°ä¸åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„äº‘è®¡ç®—é›†æˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05769">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62dacfbdeefb0f9fc0dd3a79766f2a5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5ecc6427fbe8bec581b6686f010decd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-12b2f95e8e829eb8767ae6fb471e782f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f3d2b3b35ffaaa212c18e54dab7e23cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b6a47cec1f153dfa2ff4d795c8b069c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d5743d9c232a5d49f6fef2e78990f76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6763660a6a78dec49ec6480d4cd9dd1f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-26/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-26/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-26/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ac18c8327b85eb1266e60f8882f07ace.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-26  The Sparse Frontier Sparse Attention Trade-offs in Transformer LLMs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-25/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ad4fd38429316b081ae30de4107501c9.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-25  FREAK Frequency-modulated High-fidelity and Real-time Audio-driven   Talking Portrait Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23154.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
