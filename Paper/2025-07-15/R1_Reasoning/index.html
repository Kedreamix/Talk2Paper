<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-15  One Token to Fool LLM-as-a-Judge">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-1c388731392af5f3642be6b0ee85e3b6.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    22.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    108 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-15-æ›´æ–°"><a href="#2025-07-15-æ›´æ–°" class="headerlink" title="2025-07-15 æ›´æ–°"></a>2025-07-15 æ›´æ–°</h1><h2 id="One-Token-to-Fool-LLM-as-a-Judge"><a href="#One-Token-to-Fool-LLM-as-a-Judge" class="headerlink" title="One Token to Fool LLM-as-a-Judge"></a>One Token to Fool LLM-as-a-Judge</h2><p><strong>Authors:Yulai Zhao, Haolin Liu, Dian Yu, S. Y. Kung, Haitao Mi, Dong Yu</strong></p>
<p>Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are increasingly adopted in reinforcement learning with verifiable rewards (RLVR). They are often preferred over rigid rule-based metrics, especially for complex reasoning tasks involving free-form outputs. In this paradigm, an LLM is typically prompted to compare a candidate answer against a ground-truth reference and assign a binary reward indicating correctness. Despite the seeming simplicity of this comparison task, we find that generative reward models exhibit surprising vulnerabilities to superficial manipulations: non-word symbols (e.g., â€œ:â€ or â€œ.â€) or reasoning openers like â€œThought process:â€ and â€œLetâ€™s solve this problem step by step.â€ can often lead to false positive rewards. We demonstrate that this weakness is widespread across LLMs, datasets, and prompt formats, posing a serious threat for core algorithmic paradigms that rely on generative reward models, such as rejection sampling, preference optimization, and RLVR. To mitigate this issue, we introduce a simple yet effective data augmentation strategy and train a new generative reward model with substantially improved robustness. Our findings highlight the urgent need for more reliable LLM-based evaluation methods. We release our robust, general-domain reward model and its synthetic training data at <a target="_blank" rel="noopener" href="https://huggingface.co/sarosavo/Master-RM">https://huggingface.co/sarosavo/Master-RM</a> and <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/sarosavo/Master-RM">https://huggingface.co/datasets/sarosavo/Master-RM</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è¯„ä¼°ç­”æ¡ˆè´¨é‡çš„ç”Ÿæˆå¥–åŠ±æ¨¡å‹ï¼ˆä¹Ÿç§°ä¸ºLLMåˆ¤æ–­ï¼‰ï¼Œåœ¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ä¸­è¶Šæ¥è¶Šè¢«é‡‡ç”¨ã€‚å¯¹äºæ¶‰åŠè‡ªç”±å½¢å¼è¾“å‡ºçš„å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œå®ƒä»¬é€šå¸¸æ›´å—é’çï¼Œè€Œä¸æ˜¯åŸºäºä¸¥æ ¼è§„åˆ™çš„åº¦é‡æ ‡å‡†ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œé€šå¸¸ä¼šæç¤ºLLMå°†å€™é€‰ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶åˆ†é…ä¸€ä¸ªäºŒè¿›åˆ¶å¥–åŠ±æ¥è¡¨ç¤ºæ­£ç¡®æ€§ã€‚å°½ç®¡è¿™ç§æ¯”è¾ƒä»»åŠ¡çœ‹ä¼¼ç®€å•ï¼Œä½†æˆ‘ä»¬å‘ç°ç”Ÿæˆå¥–åŠ±æ¨¡å‹å¯¹è¡¨é¢æ“çºµè¡¨ç°å‡ºæƒŠäººçš„æ¼æ´ï¼šéè¯è¯­ç¬¦å·ï¼ˆä¾‹å¦‚ï¼šâ€œï¼šâ€æˆ–â€œã€‚â€ï¼‰æˆ–æ¨ç†å¼€åœºç™½ï¼ˆä¾‹å¦‚ï¼šâ€œæ€è€ƒè¿‡ç¨‹ï¼šâ€å’Œâ€œè®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚â€ï¼‰å¸¸å¸¸ä¼šå¯¼è‡´é”™è¯¯çš„é˜³æ€§å¥–åŠ±ã€‚æˆ‘ä»¬è¯æ˜è¿™ç§å¼±ç‚¹åœ¨LLMã€æ•°æ®é›†å’Œæç¤ºæ ¼å¼ä¸­æ™®éå­˜åœ¨ï¼Œå¯¹ä¾èµ–äºç”Ÿæˆå¥–åŠ±æ¨¡å‹çš„æ ¸å¿ƒç®—æ³•èŒƒå¼æ„æˆä¸¥é‡å¨èƒï¼Œä¾‹å¦‚æ‹’ç»é‡‡æ ·ã€åå¥½ä¼˜åŒ–å’ŒRLVRã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¹¶ä½¿ç”¨å…·æœ‰æ˜¾è‘—æé«˜ç¨³å¥æ€§çš„æ–°ç”Ÿæˆå¥–åŠ±æ¨¡å‹è¿›è¡Œäº†è®­ç»ƒã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿«åˆ‡éœ€è¦æ›´å¯é çš„åŸºäºLLMçš„è¯„ä¼°æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/sarosavo/Master-RM">https://huggingface.co/sarosavo/Master-RM</a>å’Œ<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/sarosavo/Master-RM">https://huggingface.co/datasets/sarosavo/Master-RM</a>å‘å¸ƒäº†æˆ‘ä»¬ç¨³å¥çš„é€šç”¨å¥–åŠ±æ¨¡å‹å’Œåˆæˆè®­ç»ƒæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08794v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„åˆ¤è€…ï¼Œè¢«å¹¿æ³›ç”¨äºå¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰ä¸­è¯„ä¼°ç­”æ¡ˆè´¨é‡ã€‚å°½ç®¡è¿™ç§æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œä½†å®ƒå®¹æ˜“å—åˆ°è¡¨é¢æ“çºµçš„å½±å“ï¼Œå¦‚éå•è¯ç¬¦å·å’Œæ¨ç†å¼€åœºè¯å¯èƒ½å¯¼è‡´é”™è¯¯å¥–åŠ±ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…ä»¬æå‡ºä¸€ç§æ–°çš„æ•°æ®å¢å¼ºç­–ç•¥å¹¶è®­ç»ƒäº†ä¸€ä¸ªæ›´ä¸ºç¨³å¥çš„å¥–åŠ±æ¨¡å‹ã€‚æœ¬æ–‡å‘¼åæ›´ä¸ºå¯é çš„LLMè¯„ä¼°æ–¹æ³•çš„å¼€å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¥–åŠ±æ¨¡å‹ï¼ˆLLM-as-judgesï¼‰è¢«å¹¿æ³›ç”¨äºå¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰ï¼Œç”¨ä»¥è¯„ä¼°ç­”æ¡ˆè´¨é‡ã€‚</li>
<li>åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ï¼ŒLLM-as-judgesè¡¨ç°å‡ºå¯¹æŸäº›è¡¨é¢æ“çºµçš„è„†å¼±æ€§ï¼Œå¦‚éå•è¯ç¬¦å·å’Œæ¨ç†å¼€åœºè¯å¯èƒ½å¯¼è‡´é”™è¯¯å¥–åŠ±ã€‚</li>
<li>è¿™ç§è„†å¼±æ€§ä¸ä»…é™äºç‰¹å®šçš„LLMã€æ•°æ®é›†å’Œæç¤ºæ ¼å¼ï¼Œå¯¹æ ¸å¿ƒç®—æ³•èŒƒå¼æ„æˆä¸¥é‡å¨èƒã€‚</li>
<li>ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¹¶è®­ç»ƒäº†ä¸€ä¸ªæ›´ä¸ºç¨³å¥çš„å¥–åŠ±æ¨¡å‹ã€‚</li>
<li>ç°æœ‰çš„LLM-basedè¯„ä»·æ–¹æ³•çš„å¯é æ€§é—®é¢˜äºŸå¾…è§£å†³ã€‚</li>
<li>å…¬å¼€äº†ç ”ç©¶è€…çš„ç¨³å¥å¥–åŠ±æ¨¡å‹å’Œåˆæˆè®­ç»ƒæ•°æ®ä»¥ä¾›å…¬ä¼—ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ffad66e2acee4b44c1665bca67858df9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa0de9f4e66f4c6bf33aedbe167e4723.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f47710730fdca2a4825394e8b95b0c8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Leanabell-Prover-V2-Verifier-integrated-Reasoning-for-Formal-Theorem-Proving-via-Reinforcement-Learning"><a href="#Leanabell-Prover-V2-Verifier-integrated-Reasoning-for-Formal-Theorem-Proving-via-Reinforcement-Learning" class="headerlink" title="Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem   Proving via Reinforcement Learning"></a>Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem   Proving via Reinforcement Learning</h2><p><strong>Authors:Xingguang Ji, Yahui Liu, Qi Wang, Jingyuan Zhang, Yang Yue, Rui Shi, Chenxi Sun, Fuzheng Zhang, Guorui Zhou, Kun Gai</strong></p>
<p>We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that can produce formal theorem proofs in Lean 4, with verifier-integrated Long Chain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we continual to choose to posttrain existing strong prover models for further performance improvement. In our V2 version, we mainly upgrade the Reinforcement Learning (RL) with feedback provided by the Lean 4 verifier. Crucially, verifier feedback, such as indicating success or detailing specific errors, allows the LLM to become &#96;&#96;self-awareâ€™â€™ of the correctness of its own reasoning process and learn to reflexively correct errors. Leanabell-Prover-V2 directly optimizes LLM reasoning trajectories with multi-turn verifier interactions, together with feedback token masking for stable RL training and a simple reward strategy. Experiments show that Leanabell-Prover-V2 improves performance by 3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with DeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data and models are available at: <a target="_blank" rel="noopener" href="https://github.com/Leanabell-LM/Leanabell-Prover-V2">https://github.com/Leanabell-LM/Leanabell-Prover-V2</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†Leanabell-Prover-V2ï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäº7Bå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç²¾ç›Šè¯æ˜ç”Ÿæˆå·¥å…·ï¼Œèƒ½å¤Ÿåœ¨Lean 4ç¯å¢ƒä¸­ç”Ÿæˆæ­£å¼å®šç†è¯æ˜ï¼Œå¹¶é›†æˆäº†éªŒè¯å™¨ï¼ˆVerifierï¼‰çš„é•¿é“¾æ€ç»´ï¼ˆCoTï¼‰ã€‚ç»§ä¹‹å‰çš„å·¥ä½œLeanabell-Prover-V1ä¹‹åï¼Œæˆ‘ä»¬ä¾ç„¶é€‰æ‹©å¯¹ç°æœ‰çš„å¼ºå¤§è¯æ˜æ¨¡å‹è¿›è¡Œåè®­ç»ƒï¼Œä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚åœ¨V2ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å‡çº§äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰éƒ¨åˆ†ï¼Œé€šè¿‡Lean 4éªŒè¯å™¨æä¾›çš„åé¦ˆæ¥ä¼˜åŒ–æ¨¡å‹ã€‚å…³é”®çš„æ˜¯ï¼ŒéªŒè¯å™¨çš„åé¦ˆï¼Œå¦‚è¡¨ç¤ºæˆåŠŸæˆ–è¯¦ç»†æŒ‡å‡ºç‰¹å®šé”™è¯¯ï¼Œå…è®¸LLMå¯¹å…¶è‡ªèº«æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§æœ‰â€œè‡ªæˆ‘æ„è¯†â€ï¼Œå¹¶å­¦ä¼šåå°„æ€§åœ°çº æ­£é”™è¯¯ã€‚Leanabell-Prover-V2é€šè¿‡å¤šè½®éªŒè¯å™¨äº¤äº’ç›´æ¥ä¼˜åŒ–LLMçš„æ¨ç†è½¨è¿¹ï¼ŒåŒæ—¶ç»“åˆåé¦ˆä»¤ç‰Œé®è”½ä»¥è¿›è¡Œç¨³å®šçš„RLè®­ç»ƒä»¥åŠç®€å•çš„å¥–åŠ±ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨MiniF2Fæµ‹è¯•é›†ä¸Šï¼ŒLeanabell-Prover-V2ä½¿ç”¨Kimina-Prover-Preview-Distill-7Bæé«˜äº†3.2%ï¼ˆpass@128ï¼‰çš„æ€§èƒ½ï¼Œä½¿ç”¨DeepSeek-Prover-V2-7Bæé«˜äº†2.0%ï¼ˆpass@128ï¼‰çš„æ€§èƒ½ã€‚ç›¸å…³æºä»£ç ã€ç²¾é€‰æ•°æ®å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Leanabell-LM/Leanabell-%E5%AE%9E%E9%AA%8C-%E7%AC%AC%E4%BA%8C%E7%89%88">https://github.com/Leanabell-LM/Leanabell-Prover-V2ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08649v1">PDF</a> 23 pages, 13 figures</p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£çš„äººå·¥æ™ºèƒ½æ•°å­¦è¯æ˜æ¨¡å‹Leanabell-Prover-V2é—®ä¸–ï¼Œè¯¥æ¨¡å‹å…·å¤‡éªŒè¯å™¨é›†æˆé•¿é“¾æ€ç»´çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨Lean 4ç¯å¢ƒä¸­ç”Ÿæˆå½¢å¼åŒ–å®šç†è¯æ˜ã€‚ç›¸è¾ƒäºå‰ä¸€ä»£æ¨¡å‹ï¼ŒV2ç‰ˆæœ¬é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸Lean 4éªŒè¯å™¨åé¦ˆç»“åˆï¼Œå®ç°äº†æ¨¡å‹çš„è‡ªæˆ‘çº é”™èƒ½åŠ›ã€‚é€šè¿‡å¤šå›åˆéªŒè¯å™¨äº¤äº’ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è½¨è¿¹ï¼ŒåŒæ—¶å¼•å…¥åé¦ˆä»¤ç‰Œé®è”½å’Œç®€å•å¥–åŠ±ç­–ç•¥ä»¥å¢å¼ºæ¨¡å‹çš„ç¨³å®šæ€§ã€‚å®éªŒæ˜¾ç¤ºï¼Œåœ¨MiniF2Fæµ‹è¯•é›†ä¸Šï¼ŒLeanabell-Prover-V2çš„æ€§èƒ½ç›¸è¾ƒäºä¹‹å‰çš„æ¨¡å‹æœ‰æ‰€æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Leanabell-Prover-V2æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒåœ¨Lean 4ç¯å¢ƒä¸­ç”Ÿæˆå½¢å¼åŒ–å®šç†è¯æ˜ã€‚</li>
<li>ä¸å‰ä¸€ä»£æ¨¡å‹ç›¸æ¯”ï¼ŒV2ç‰ˆæœ¬é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸éªŒè¯å™¨åé¦ˆç›¸ç»“åˆï¼Œæé«˜äº†æ¨¡å‹çš„è‡ªæˆ‘çº é”™èƒ½åŠ›ã€‚</li>
<li>V2æ¨¡å‹å…·å¤‡éªŒè¯å™¨é›†æˆé•¿é“¾æ€ç»´çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è½¨è¿¹ã€‚</li>
<li>é€šè¿‡å¤šå›åˆéªŒè¯å™¨äº¤äº’ã€åé¦ˆä»¤ç‰Œé®è”½å’Œç®€å•å¥–åŠ±ç­–ç•¥ç­‰æŠ€æœ¯ï¼Œå¢å¼ºäº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨MiniF2Fæµ‹è¯•é›†ä¸Šï¼ŒLeanabell-Prover-V2ç›¸è¾ƒäºä¹‹å‰çš„æ¨¡å‹æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>è¯¥æ¨¡å‹çš„æºä»£ç ã€ç²¾é€‰æ•°æ®å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Leanabell-LM/Leanabell-Prover-V2%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Leanabell-LM/Leanabell-Prover-V2ä¸Šè·å–ã€‚</a></li>
<li>Leanabell-Prover-V2çš„æ¨å‡ºæ ‡å¿—ç€äººå·¥æ™ºèƒ½åœ¨æ•°å­¦è¯æ˜é¢†åŸŸçš„è¿›æ­¥åˆè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08649">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d7ba44307128eaf43c22c10fed3ac552.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2bc562050867aac4277b26a8ac88d470.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8430de49304e62c86535ef4072c5387d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-comprehensive-study-of-LLM-based-argument-classification-from-LLAMA-through-GPT-4o-to-Deepseek-R1"><a href="#A-comprehensive-study-of-LLM-based-argument-classification-from-LLAMA-through-GPT-4o-to-Deepseek-R1" class="headerlink" title="A comprehensive study of LLM-based argument classification: from LLAMA   through GPT-4o to Deepseek-R1"></a>A comprehensive study of LLM-based argument classification: from LLAMA   through GPT-4o to Deepseek-R1</h2><p><strong>Authors:Marcin PietroÅ„, RafaÅ‚ Olszowski, Jakub GomuÅ‚ka, Filip Gampel, Andrzej Tomski</strong></p>
<p>Argument mining (AM) is an interdisciplinary research field that integrates insights from logic, philosophy, linguistics, rhetoric, law, psychology, and computer science. It involves the automatic identification and extraction of argumentative components, such as premises and claims, and the detection of relationships between them, such as support, attack, or neutrality. Recently, the field has advanced significantly, especially with the advent of large language models (LLMs), which have enhanced the efficiency of analyzing and extracting argument semantics compared to traditional methods and other deep learning models. There are many benchmarks for testing and verifying the quality of LLM, but there is still a lack of research and results on the operation of these models in publicly available argument classification databases. This paper presents a study of a selection of LLMâ€™s, using diverse datasets such as Args.me and UKP. The models tested include versions of GPT, Llama, and DeepSeek, along with reasoning-enhanced variants incorporating the Chain-of-Thoughts algorithm. The results indicate that ChatGPT-4o outperforms the others in the argument classification benchmarks. In case of models incorporated with reasoning capabilities, the Deepseek-R1 shows its superiority. However, despite their superiority, GPT-4o and Deepseek-R1 still make errors. The most common errors are discussed for all models. To our knowledge, the presented work is the first broader analysis of the mentioned datasets using LLM and prompt algorithms. The work also shows some weaknesses of known prompt algorithms in argument analysis, while indicating directions for their improvement. The added value of the work is the in-depth analysis of the available argument datasets and the demonstration of their shortcomings. </p>
<blockquote>
<p>è®ºè¯æŒ–æ˜ï¼ˆAMï¼‰æ˜¯ä¸€ä¸ªè·¨å­¦ç§‘çš„ç ”ç©¶é¢†åŸŸï¼Œèåˆäº†é€»è¾‘ã€å“²å­¦ã€è¯­è¨€å­¦ã€ä¿®è¾å­¦ã€æ³•å¾‹ã€å¿ƒç†å­¦å’Œè®¡ç®—æœºç§‘å­¦ç­‰å­¦ç§‘ã€‚å®ƒæ¶‰åŠè‡ªåŠ¨è¯†åˆ«å’Œæå–è®ºè¯æ€§æˆåˆ†ï¼Œå¦‚å‰æå’Œè®ºç‚¹ï¼Œä»¥åŠæ£€æµ‹å®ƒä»¬ä¹‹é—´çš„å…³ç³»ï¼Œå¦‚æ”¯æŒã€æ”»å‡»æˆ–ä¸­ç«‹ã€‚è¿‘å¹´æ¥ï¼Œè¯¥é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œä¸ä¼ ç»Ÿçš„åˆ†ææ–¹æ³•å’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œå¤§å¤§æé«˜äº†åˆ†æè®ºè¯è¯­ä¹‰çš„æ•ˆç‡ã€‚å°½ç®¡å­˜åœ¨è®¸å¤šæµ‹è¯•LLMè´¨é‡çš„åŸºå‡†æµ‹è¯•é›†ï¼Œä½†åœ¨å…¬å¼€å¯ç”¨çš„è®ºè¯åˆ†ç±»æ•°æ®åº“ä¸­å…³äºè¿™äº›æ¨¡å‹è¿è¡Œçš„ç ”ç©¶å’Œç»“æœä»ç„¶ç¼ºä¹ã€‚æœ¬æ–‡ä½¿ç”¨Args.meå’ŒUKPç­‰å¤šæ ·åŒ–æ•°æ®é›†å¯¹ä¸€ç³»åˆ—LLMè¿›è¡Œäº†ç ”ç©¶ã€‚æµ‹è¯•è¿‡çš„æ¨¡å‹åŒ…æ‹¬GPTã€Llamaå’ŒDeepSeekçš„ç‰ˆæœ¬ï¼Œä»¥åŠé‡‡ç”¨Chain-of-Thoughtsç®—æ³•çš„æ¨ç†å¢å¼ºå˜ä½“ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨è®ºè¯åˆ†ç±»åŸºå‡†æµ‹è¯•ä¸­ChatGPT-4oçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚å¯¹äºèåˆæ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼ŒDeepseek-R1è¡¨ç°æœ€ä¸ºä¼˜è¶Šã€‚ç„¶è€Œï¼Œå°½ç®¡GPT-4oå’ŒDeepseek-R1å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å®ƒä»¬ä»ç„¶ä¼šå‡ºç°é”™è¯¯ã€‚æœ¬æ–‡å¯¹æ‰€æœ‰æ¨¡å‹æœ€å¸¸è§çš„é”™è¯¯è¿›è¡Œäº†è®¨è®ºã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæ‰€å‘ˆç°çš„å·¥ä½œæ˜¯ä½¿ç”¨LLMå’Œæç¤ºç®—æ³•å¯¹æåˆ°çš„æ•°æ®é›†è¿›è¡Œçš„é¦–æ¬¡æ›´å¹¿æ³›çš„åˆ†æã€‚è¿™é¡¹å·¥ä½œè¿˜å±•ç¤ºäº†å·²çŸ¥æç¤ºç®—æ³•åœ¨è®ºè¯åˆ†æä¸­çš„æŸäº›å¼±ç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†æ”¹è¿›æ–¹å‘ã€‚è¯¥å·¥ä½œçš„é™„åŠ å€¼æ˜¯å¯¹ç°æœ‰è®ºè¯æ•°æ®é›†è¿›è¡Œæ·±å…¥åˆ†æå’Œå±•ç¤ºå…¶ä¸è¶³ä¹‹å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08621v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è·¨å­¦ç§‘çš„è®ºè¯æŒ–æ˜ï¼ˆAMï¼‰é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¯¥é¢†åŸŸçš„åº”ç”¨ã€‚æ–‡ç« è¯¦ç»†æ¢è®¨äº†LLMåœ¨è®ºè¯åˆ†ç±»æ•°æ®åº“ä¸­çš„è¡¨ç°ï¼Œå¹¶é€šè¿‡ä½¿ç”¨Args.meå’ŒUKPç­‰æ•°æ®é›†å¯¹åŒ…æ‹¬GPTã€Llamaå’ŒDeepSeekç­‰åœ¨å†…çš„æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼ŒChatGPT-4oåœ¨è®ºè¯åˆ†ç±»åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œè€ŒDeepseek-R1ç­‰èå…¥æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ä¹Ÿå±•ç°å‡ºä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä»å­˜åœ¨é”™è¯¯ï¼Œæ–‡ç« å¯¹æ­¤è¿›è¡Œäº†è®¨è®ºã€‚è¿™é¡¹å·¥ä½œæ˜¯å¯¹ä½¿ç”¨LLMå’Œæç¤ºç®—æ³•è¿›è¡Œæ•°æ®é›†åˆ†æçš„é¦–æ¬¡å¹¿æ³›å°è¯•ï¼Œå±•ç¤ºäº†ä¸€äº›å·²çŸ¥æç¤ºç®—æ³•åœ¨è®ºè¯åˆ†æä¸­çš„å¼±ç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†æ”¹è¿›æ–¹å‘ã€‚æ–‡ç« è¿˜æ·±å…¥åˆ†æäº†ç°æœ‰è®ºè¯æ•°æ®é›†ï¼Œå¹¶æ­ç¤ºäº†å…¶ä¸è¶³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºè¯æŒ–æ˜ï¼ˆAMï¼‰æ˜¯ä¸€ä¸ªè·¨å­¦ç§‘çš„é¢†åŸŸï¼Œç»“åˆäº†é€»è¾‘ã€å“²å­¦ã€è¯­è¨€å­¦ã€ä¿®è¾å­¦ã€æ³•å¾‹ã€å¿ƒç†å­¦å’Œè®¡ç®—æœºç§‘å­¦ç­‰å¤šä¸ªå­¦ç§‘çš„è§è§£ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è®ºè¯è¯­ä¹‰åˆ†ææ–¹é¢ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•å’Œå…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹æœ‰ç€æ›´é«˜çš„æ•ˆç‡ã€‚</li>
<li>ä½¿ç”¨Args.meå’ŒUKPç­‰æ•°æ®é›†è¿›è¡Œçš„æµ‹è¯•è¡¨æ˜ï¼ŒChatGPT-4oåœ¨è®ºè¯åˆ†ç±»åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
<li>èå…¥æ¨ç†èƒ½åŠ›çš„æ¨¡å‹å¦‚Deepseek-R1å±•ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>è¿™äº›æ¨¡å‹åœ¨è®ºè¯åˆ†æä¸­ä»å­˜åœ¨é”™è¯¯ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„æ”¹è¿›ã€‚</li>
<li>å·²çŸ¥æç¤ºç®—æ³•åœ¨è®ºè¯åˆ†æä¸­å­˜åœ¨å¼±ç‚¹ï¼Œè¿™ä¸ºè¿›ä¸€æ­¥æ”¹è¿›æä¾›äº†æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08621">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2e0a2f2c4e0ba75f82ee862f3be60c93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-38837f646b5db2769cef3d1544aebc1d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0579b27eb1e01f570afb7c7b01fbd383.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4acad64027623ebb875a4a95a2819e99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e8a5ba02f99b5ae503ab7983f1b0f82.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="From-Language-to-Logic-A-Bi-Level-Framework-for-Structured-Reasoning"><a href="#From-Language-to-Logic-A-Bi-Level-Framework-for-Structured-Reasoning" class="headerlink" title="From Language to Logic: A Bi-Level Framework for Structured Reasoning"></a>From Language to Logic: A Bi-Level Framework for Structured Reasoning</h2><p><strong>Authors:Keying Yang, Hao Wang, Kai Yang</strong></p>
<p>Structured reasoning over natural language inputs remains a core challenge in artificial intelligence, as it requires bridging the gap between unstructured linguistic expressions and formal logical representations. In this paper, we propose a novel \textbf{bi-level framework} that maps language to logic through a two-stage process: high-level task abstraction and low-level logic generation. At the upper level, a large language model (LLM) parses natural language queries into intermediate structured representations specifying the problem type, objectives, decision variables, and symbolic constraints. At the lower level, the LLM uses these representations to generate symbolic workflows or executable reasoning programs for accurate and interpretable decision making. The framework supports modular reasoning, enforces explicit constraints, and generalizes across domains such as mathematical problem solving, question answering, and logical inference. We further optimize the framework with an end-to-end {bi-level} optimization approach that jointly refines both the high-level abstraction and low-level logic generation stages. Experiments on multiple realistic reasoning benchmarks demonstrate that our approach significantly outperforms existing baselines in accuracy, with accuracy gains reaching as high as 40%. Moreover, the bi-level design enhances transparency and error traceability, offering a promising step toward trustworthy and systematic reasoning with LLMs. </p>
<blockquote>
<p>è‡ªç„¶è¯­è¨€ç»“æ„åŒ–æ¨ç†ä»ç„¶æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­çš„ä¸€é¡¹æ ¸å¿ƒæŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒéœ€è¦å¼¥åˆæ— ç»“æ„è¯­è¨€è¡¨è¿°å’Œå½¢å¼é€»è¾‘è¡¨ç¤ºä¹‹é—´çš„å·®è·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„<strong>ä¸¤çº§æ¡†æ¶</strong>ï¼Œé€šè¿‡ä¸¤ä¸ªé˜¶æ®µå°†è¯­è¨€æ˜ å°„åˆ°é€»è¾‘ï¼šé«˜çº§ä»»åŠ¡æŠ½è±¡å’Œä½çº§é€»è¾‘ç”Ÿæˆã€‚åœ¨é«˜çº§é˜¶æ®µï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æä¸ºä¸­é—´ç»“æ„åŒ–è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºæŒ‡å®šäº†é—®é¢˜ç±»å‹ã€ç›®æ ‡ã€å†³ç­–å˜é‡å’Œç¬¦å·çº¦æŸã€‚åœ¨ä½çº§é˜¶æ®µï¼ŒLLMä½¿ç”¨è¿™äº›è¡¨ç¤ºæ¥ç”Ÿæˆç¬¦å·å·¥ä½œæµæˆ–å¯æ‰§è¡Œæ¨ç†ç¨‹åºï¼Œä»¥è¿›è¡Œå‡†ç¡®å’Œå¯è§£é‡Šæ€§çš„å†³ç­–ã€‚è¯¥æ¡†æ¶æ”¯æŒæ¨¡å—åŒ–æ¨ç†ã€å¼ºåˆ¶æ˜¾å¼çº¦æŸï¼Œå¹¶ä¸”åœ¨æ•°å­¦é—®é¢˜è§£å†³ã€é—®ç­”å’Œé€»è¾‘æ¨ç†ç­‰å„ä¸ªé¢†åŸŸå…·æœ‰é€šç”¨æ€§ã€‚æˆ‘ä»¬é€šè¿‡ç«¯åˆ°ç«¯çš„ä¸¤çº§ä¼˜åŒ–æ–¹æ³•è¿›ä¸€æ­¥ä¼˜åŒ–è¯¥æ¡†æ¶ï¼Œè¯¥æ–¹æ³•è”åˆæ”¹è¿›é«˜çº§æŠ½è±¡å’Œä½çº§é€»è¾‘ç”Ÿæˆé˜¶æ®µã€‚åœ¨å¤šä¸ªå®é™…æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æµ‹è¯•ï¼Œå‡†ç¡®ç‡æé«˜é«˜è¾¾40%ã€‚æ­¤å¤–ï¼Œä¸¤çº§è®¾è®¡æé«˜äº†é€æ˜åº¦å’Œé”™è¯¯å¯è¿½æº¯æ€§ï¼Œä¸ºä½¿ç”¨LLMå®ç°å¯ä¿¡å’Œç³»ç»ŸåŒ–çš„æ¨ç†æä¾›äº†æœ‰å¸Œæœ›çš„ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08501v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬æå‡ºäº†ä¸€ä¸ªåŒå‘æ˜ å°„çš„è¯­è¨€é€»è¾‘æ¡†æ¶ï¼ŒåŒ…æ‹¬ä»»åŠ¡æŠ½è±¡å’Œé€»è¾‘ç”Ÿæˆä¸¤ä¸ªé˜¶æ®µï¼Œä»¥å®ç°è‡ªç„¶è¯­è¨€ä¸æ­£å¼é€»è¾‘ä¹‹é—´çš„äº¤äº’ä¸ç†è§£ã€‚é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè§£æï¼Œç”Ÿæˆç¬¦å·å·¥ä½œæµæˆ–å¯æ‰§è¡Œçš„æ¨ç†ç¨‹åºè¿›è¡Œå†³ç­–ã€‚è¯¥æ¡†æ¶ä¼˜åŒ–äº†æ¨¡å—åŒ–æ¨ç†ï¼Œå¢åŠ äº†æ˜ç¡®çº¦æŸçš„è¡¨è¿°æ–¹å¼ï¼Œèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºæ•°å­¦é—®é¢˜è§£ç­”ã€é—®ç­”ä»¥åŠé€»è¾‘æ¨ç†ç­‰å¤šä¸ªé¢†åŸŸã€‚å®éªŒç»“æœè¯å®å…¶å‡†ç¡®æ€§æ˜¾è‘—æå‡ï¼Œæœ€é«˜æå‡å¹…åº¦è¾¾åˆ°40%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æé«˜äº†é€æ˜åº¦å’Œé”™è¯¯è¿½è¸ªèƒ½åŠ›ï¼Œä¸ºæ„å»ºå¯ä¿¡å’Œç³»ç»Ÿçš„è¯­è¨€æ¨¡å‹æ¨ç†æä¾›äº†æœ‰åŠ›çš„æ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç„¶è¯­è¨€ä¸é€»è¾‘æ¡†æ¶çš„åŒå‘æ˜ å°„æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹åŒå‘æ˜ å°„çš„è¯­è¨€é€»è¾‘æ¡†æ¶ï¼ŒåŒ…æ‹¬ä»»åŠ¡æŠ½è±¡å’Œé€»è¾‘ç”Ÿæˆä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¡†æ¶ä¸­è¢«ç”¨æ¥è§£æè‡ªç„¶è¯­è¨€æŸ¥è¯¢å’Œç”Ÿæˆç»“æ„åŒ–è¡¨ç¤ºã€‚</li>
<li>ç¬¦å·å·¥ä½œæµæˆ–å¯æ‰§è¡Œæ¨ç†ç¨‹åºè¢«ç”¨æ¥è¿›è¡Œå‡†ç¡®ä¸”å¯è§£é‡Šçš„å†³ç­–ã€‚</li>
<li>è¯¥æ¡†æ¶æ”¯æŒæ¨¡å—åŒ–æ¨ç†å’Œæ˜ç¡®çº¦æŸè¡¨è¿°ï¼Œèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå¤šä¸ªé¢†åŸŸã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜è¯¥æ¡†æ¶åœ¨å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ€é«˜æå‡å¹…åº¦è¾¾åˆ°40%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-25dd65025530fca72ecad9e42e1807a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c388731392af5f3642be6b0ee85e3b6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LLaPa-A-Vision-Language-Model-Framework-for-Counterfactual-Aware-Procedural-Planning"><a href="#LLaPa-A-Vision-Language-Model-Framework-for-Counterfactual-Aware-Procedural-Planning" class="headerlink" title="LLaPa: A Vision-Language Model Framework for Counterfactual-Aware   Procedural Planning"></a>LLaPa: A Vision-Language Model Framework for Counterfactual-Aware   Procedural Planning</h2><p><strong>Authors:Shibo Sun, Xue Li, Donglin Di, Mingjie Wei, Lanshun Nie, Wei-Nan Zhang, Dechen Zhan, Yang Song, Lei Fan</strong></p>
<p>While large language models (LLMs) have advanced procedural planning for embodied AI systems through strong reasoning abilities, the integration of multimodal inputs and counterfactual reasoning remains underexplored. To tackle these challenges, we introduce LLaPa, a vision-language model framework designed for multimodal procedural planning. LLaPa generates executable action sequences from textual task descriptions and visual environmental images using vision-language models (VLMs). Furthermore, we enhance LLaPa with two auxiliary modules to improve procedural planning. The first module, the Task-Environment Reranker (TER), leverages task-oriented segmentation to create a task-sensitive feature space, aligning textual descriptions with visual environments and emphasizing critical regions for procedural execution. The second module, the Counterfactual Activities Retriever (CAR), identifies and emphasizes potential counterfactual conditions, enhancing the modelâ€™s reasoning capability in counterfactual scenarios. Extensive experiments on ActPlan-1K and ALFRED benchmarks demonstrate that LLaPa generates higher-quality plans with superior LCS and correctness, outperforming advanced models. The code and models are available <a target="_blank" rel="noopener" href="https://github.com/sunshibo1234/LLaPa">https://github.com/sunshibo1234/LLaPa</a>. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å¼ºå¤§çš„æ¨ç†èƒ½åŠ›æ¨åŠ¨äº†å®ä½“AIç³»ç»Ÿçš„è¿‡ç¨‹è§„åˆ’å‘å±•ï¼Œä½†å¤šæ¨¡å¼è¾“å…¥å’Œåå‘æ¨ç†çš„æ•´åˆä»ç„¶è¢«è¾ƒå°‘æ¢ç´¢ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†LLaPaï¼Œä¸€ä¸ªä¸ºå¤šæ¨¡å¼è¿‡ç¨‹è§„åˆ’è®¾è®¡çš„è§†è§‰è¯­è¨€æ¨¡å‹æ¡†æ¶ã€‚LLaPaä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œä»æ–‡æœ¬ä»»åŠ¡æè¿°å’Œè§†è§‰ç¯å¢ƒå›¾åƒç”Ÿæˆå¯æ‰§è¡Œçš„åŠ¨ä½œåºåˆ—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸ºLLaPaå¢åŠ äº†ä¸¤ä¸ªè¾…åŠ©æ¨¡å—ï¼Œä»¥æ”¹å–„è¿‡ç¨‹è§„åˆ’ã€‚ç¬¬ä¸€ä¸ªæ¨¡å—æ˜¯ä»»åŠ¡ç¯å¢ƒé‡æ–°æ’åºå™¨ï¼ˆTERï¼‰ï¼Œå®ƒåˆ©ç”¨ä»»åŠ¡å¯¼å‘åˆ†æ®µæ¥åˆ›å»ºä»»åŠ¡æ•æ„Ÿç‰¹å¾ç©ºé—´ï¼Œå°†æ–‡æœ¬æè¿°ä¸è§†è§‰ç¯å¢ƒå¯¹é½ï¼Œå¹¶å¼ºè°ƒè¿‡ç¨‹æ‰§è¡Œçš„å…³é”®åŒºåŸŸã€‚ç¬¬äºŒä¸ªæ¨¡å—æ˜¯åå‘æ´»åŠ¨æ£€ç´¢å™¨ï¼ˆCARï¼‰ï¼Œå®ƒè¯†åˆ«å’Œå¼ºè°ƒå¯èƒ½çš„åå‘æ¡ä»¶ï¼Œæé«˜æ¨¡å‹åœ¨åå‘åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚åœ¨ActPlan-1Kå’ŒALFREDåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLLaPaç”Ÿæˆçš„è®¡åˆ’è´¨é‡æ›´é«˜ï¼ŒLCSå’Œæ­£ç¡®æ€§æ›´ä¼˜è¶Šï¼Œè¶…è¶Šäº†å…ˆè¿›æ¨¡å‹ã€‚ä»£ç å’Œæ¨¡å‹å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/sunshibo1234/LLaPa%E3%80%82">https://github.com/sunshibo1234/LLaPaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08496v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨åŠ¨AIç³»ç»Ÿçš„ç¨‹åºåŒ–è§„åˆ’æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å¯¹å¤šæ¨¡å¼è¾“å…¥å’Œå‡è®¾æ€§æ¨ç†çš„æ•´åˆå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†LLaPaï¼Œä¸€ä¸ªé¢å‘å¤šæ¨¡å¼ç¨‹åºè§„åˆ’çš„è§†è§‰è¯­è¨€æ¨¡å‹æ¡†æ¶ã€‚LLaPaèƒ½å¤Ÿä»æ–‡æœ¬ä»»åŠ¡æè¿°å’Œè§†è§‰ç¯å¢ƒå›¾åƒä¸­ç”Ÿæˆå¯æ‰§è¡Œçš„åŠ¨ä½œåºåˆ—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡ä¸¤ä¸ªè¾…åŠ©æ¨¡å—å¢å¼ºäº†LLaPaçš„ç¨‹åºè§„åˆ’èƒ½åŠ›ã€‚ä¸€æ˜¯ä»»åŠ¡ç¯å¢ƒé‡æ–°æ’åºå™¨ï¼ˆTERï¼‰ï¼Œå®ƒåˆ©ç”¨ä»»åŠ¡å¯¼å‘çš„åˆ†å‰²æŠ€æœ¯åˆ›å»ºä»»åŠ¡æ•æ„Ÿç‰¹å¾ç©ºé—´ï¼Œå°†æ–‡æœ¬æè¿°ä¸è§†è§‰ç¯å¢ƒå¯¹é½ï¼Œå¹¶å¼ºè°ƒæ‰§è¡Œç¨‹åºçš„å…³é”®åŒºåŸŸã€‚äºŒæ˜¯å‡è®¾æ´»åŠ¨æ£€ç´¢å™¨ï¼ˆCARï¼‰ï¼Œèƒ½å¤Ÿè¯†åˆ«å’Œå¼ºè°ƒæ½œåœ¨çš„å‡è®¾æ¡ä»¶ï¼Œæé«˜æ¨¡å‹åœ¨å‡è®¾åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚åœ¨ActPlan-1Kå’ŒALFREDåŸºå‡†æµ‹è¯•çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLLaPaç”Ÿæˆçš„è®¡åˆ’è´¨é‡æ›´é«˜ï¼ŒLCSå’Œæ­£ç¡®æ€§æ›´ä¼˜è¶Šï¼Œè¶…è¶Šäº†å…ˆè¿›æ¨¡å‹çš„è¡¨ç°ã€‚ç›¸å…³ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sunshibo1234/LLaPa%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/sunshibo1234/LLaPaè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è¯­è¨€æ¨¡å‹åœ¨AIç³»ç»Ÿç¨‹åºè§„åˆ’ä¸­çš„å¼ºå¤§æ¨ç†èƒ½åŠ›ï¼Œä½†å¯¹å¤šæ¨¡å¼è¾“å…¥å’Œå‡è®¾æ€§æ¨ç†æ•´åˆå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>LLaPaæ¡†æ¶ç”¨äºå¤šæ¨¡å¼ç¨‹åºè§„åˆ’ï¼Œå¯ä»æ–‡æœ¬ä»»åŠ¡æè¿°å’Œè§†è§‰ç¯å¢ƒå›¾åƒç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œåºåˆ—ã€‚</li>
<li>LLaPaé…å¤‡äº†ä¸¤ä¸ªè¾…åŠ©æ¨¡å—ï¼šä»»åŠ¡ç¯å¢ƒé‡æ–°æ’åºå™¨ï¼ˆTERï¼‰å’Œå‡è®¾æ´»åŠ¨æ£€ç´¢å™¨ï¼ˆCARï¼‰ã€‚</li>
<li>TERæ¨¡å—åˆ©ç”¨ä»»åŠ¡å¯¼å‘çš„åˆ†å‰²æŠ€æœ¯åˆ›å»ºä»»åŠ¡æ•æ„Ÿç‰¹å¾ç©ºé—´ï¼Œå¯¹é½æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œå¼ºè°ƒå…³é”®åŒºåŸŸã€‚</li>
<li>CARæ¨¡å—èƒ½å¤Ÿè¯†åˆ«å’Œå¼ºè°ƒæ½œåœ¨å‡è®¾æ¡ä»¶ï¼Œæé«˜æ¨¡å‹åœ¨å‡è®¾åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>åœ¨ActPlan-1Kå’ŒALFREDåŸºå‡†æµ‹è¯•ä¸­ï¼ŒLLaPaè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œç”Ÿæˆçš„è®¡åˆ’è´¨é‡æ›´é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08496">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-67828b382a5738b44526a2a2fffba195.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8251581892649b46c36e70c5cbcad92b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d1dca765c1e9616a061185f8020be5c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac1ef461914b69fbfe034966b538f415.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="ChainEdit-Propagating-Ripple-Effects-in-LLM-Knowledge-Editing-through-Logical-Rule-Guided-Chains"><a href="#ChainEdit-Propagating-Ripple-Effects-in-LLM-Knowledge-Editing-through-Logical-Rule-Guided-Chains" class="headerlink" title="ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through   Logical Rule-Guided Chains"></a>ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through   Logical Rule-Guided Chains</h2><p><strong>Authors:Zilu Dong, Xiangqing Shen, Zinong Yang, Rui Xia</strong></p>
<p>Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable systematic chain updates. By automatically extracting logical patterns from structured knowledge bases and aligning them with LLMsâ€™ internal logics, ChainEdit dynamically generates and edits logically connected knowledge clusters. Experiments demonstrate an improvement of more than 30% in logical generalization over baselines while preserving editing reliability and specificity. We further address evaluation biases in existing benchmarks through knowledge-aware protocols that disentangle external dependencies. This work establishes new state-of-the-art performance on ripple effect while ensuring internal logical consistency after knowledge editing. </p>
<blockquote>
<p>å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•åœ¨ä¼ æ’­æ¶Ÿæ¼ªæ•ˆåº”åˆ°ç›¸å…³äº‹å®æ—¶ï¼Œå¾ˆéš¾ä¿æŒé€»è¾‘ä¸€è‡´æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ChainEditæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†çŸ¥è¯†å›¾è°±è¡ç”Ÿçš„é€»è¾‘è§„åˆ™ä¸LLMçš„é€»è¾‘æ¨ç†èƒ½åŠ›ç›¸ç»“åˆï¼Œä»¥å®ç°ç³»ç»Ÿçš„é“¾å¼æ›´æ–°ã€‚ChainEditèƒ½å¤Ÿè‡ªåŠ¨ä»ç»“æ„åŒ–çŸ¥è¯†åº“ä¸­æå–é€»è¾‘æ¨¡å¼ï¼Œå¹¶ä¸LLMçš„å†…éƒ¨é€»è¾‘å¯¹é½ï¼Œä»è€ŒåŠ¨æ€ç”Ÿæˆå’Œç¼–è¾‘é€»è¾‘å…³è”çš„çŸ¥è¯†é›†ç¾¤ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨åŸºçº¿æµ‹è¯•ä¸Šï¼Œé€»è¾‘æ³›åŒ–èƒ½åŠ›æé«˜äº†30%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†ç¼–è¾‘çš„å¯é æ€§å’Œç‰¹å¼‚æ€§ã€‚æˆ‘ä»¬è¿˜é€šè¿‡çŸ¥è¯†æ„ŸçŸ¥åè®®è§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°åè§ï¼Œè¯¥åè®®å¯ä»¥è§£å¼€å¤–éƒ¨ä¾èµ–å…³ç³»ã€‚è¿™é¡¹å·¥ä½œåœ¨æ¶Ÿæ¼ªæ•ˆåº”æ–¹é¢å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯äº†çŸ¥è¯†ç¼–è¾‘åçš„å†…éƒ¨é€»è¾‘ä¸€è‡´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08427v1">PDF</a> Accepted to ACL 2025 (main)</p>
<p><strong>Summary</strong>ï¼šå½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¼ æ’­çŸ¥è¯†ç¼–è¾‘çš„æ¶Ÿæ¼ªæ•ˆåº”æ—¶ï¼Œéš¾ä»¥ä¿æŒé€»è¾‘ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºChainEditæ¡†æ¶ï¼Œç»“åˆçŸ¥è¯†å›¾è°±è¡ç”Ÿçš„é€»è¾‘è§„åˆ™ä¸LLMçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå®ç°ç³»ç»Ÿæ€§çŸ¥è¯†é“¾æ›´æ–°ã€‚è¯¥æ¡†æ¶ä»ç»“æ„åŒ–çŸ¥è¯†åº“ä¸­è‡ªåŠ¨æå–é€»è¾‘æ¨¡å¼ï¼Œå¹¶ä¸LLMçš„å†…éƒ¨é€»è¾‘å¯¹é½ï¼ŒåŠ¨æ€ç”Ÿæˆå’Œç¼–è¾‘é€»è¾‘å…³è”çš„çŸ¥è¯†é›†ç¾¤ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºåŸºå‡†æµ‹è¯•ï¼ŒChainEditåœ¨é€»è¾‘æ³›åŒ–èƒ½åŠ›ä¸Šæé«˜äº†è¶…è¿‡30%ï¼ŒåŒæ—¶ä¿æŒäº†ç¼–è¾‘çš„å¯é æ€§å’Œç‰¹å¼‚æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é€šè¿‡çŸ¥è¯†æ„ŸçŸ¥åè®®è§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•çš„è¯„ä»·åè§é—®é¢˜ï¼Œç¡®ä¿äº†çŸ¥è¯†ç¼–è¾‘åçš„å†…éƒ¨é€»è¾‘ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¼ æ’­æ¶Ÿæ¼ªæ•ˆåº”æ—¶é¢ä¸´é€»è¾‘ä¸€è‡´æ€§é—®é¢˜ã€‚</li>
<li>ChainEditæ¡†æ¶ç»“åˆçŸ¥è¯†å›¾è°±çš„é€»è¾‘è§„åˆ™å’ŒLLMçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ChainEditæ¡†æ¶å®ç°äº†ç³»ç»Ÿæ€§çŸ¥è¯†é“¾æ›´æ–°ï¼Œé€šè¿‡è‡ªåŠ¨æå–é€»è¾‘æ¨¡å¼å¹¶ä¸LLMå†…éƒ¨é€»è¾‘å¯¹é½ã€‚</li>
<li>å®éªŒè¡¨æ˜ChainEditæé«˜äº†è¶…è¿‡30%çš„é€»è¾‘æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†ç¼–è¾‘çš„å¯é æ€§å’Œç‰¹å¼‚æ€§ã€‚</li>
<li>çŸ¥è¯†æ„ŸçŸ¥åè®®ç”¨äºè§£å†³ç°æœ‰åŸºå‡†æµ‹è¯•çš„è¯„ä»·åè§é—®é¢˜ã€‚</li>
<li>ChainEditæ¡†æ¶åœ¨ç¡®ä¿çŸ¥è¯†ç¼–è¾‘åçš„å†…éƒ¨é€»è¾‘ä¸€è‡´æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08427">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e7748dba06c072389e18f07f3373aa37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a421ccdd0025910cd79d30c50ec17269.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83753e05c25c5ed4a4c9f1c031b79f7c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="M2-Reasoning-Empowering-MLLMs-with-Unified-General-and-Spatial-Reasoning"><a href="#M2-Reasoning-Empowering-MLLMs-with-Unified-General-and-Spatial-Reasoning" class="headerlink" title="M2-Reasoning: Empowering MLLMs with Unified General and Spatial   Reasoning"></a>M2-Reasoning: Empowering MLLMs with Unified General and Spatial   Reasoning</h2><p><strong>Authors:Inclusion AI,  :, Fudong Wang, Jiajia Liu, Jingdong Chen, Jun Zhou, Kaixiang Ji, Lixiang Ru, Qingpei Guo, Ruobing Zheng, Tianqi Li, Yi Yuan, Yifan Mao, Yuting Xiao, Ziping Ma</strong></p>
<p>Recent advancements in Multimodal Large Language Models (MLLMs), particularly through Reinforcement Learning with Verifiable Rewards (RLVR), have significantly enhanced their reasoning abilities. However, a critical gap persists: these models struggle with dynamic spatial interactions, a capability essential for real-world applications. To bridge this gap, we introduce M2-Reasoning-7B, a model designed to excel in both general and spatial reasoning. Our approach integrates two key innovations: (1) a novel data pipeline that generates 294.2K high-quality data samples (168K for cold-start fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning trajectories and have undergone comprehensive assessment; and (2) a dynamic multi-task training strategy with step-wise optimization to mitigate conflicts between data, and task-specific rewards for delivering tailored incentive signals. This combination of curated data and advanced training allows M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks, showcasing superior performance in both general and spatial reasoning domains. </p>
<blockquote>
<p>è¿‘æœŸå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»å­˜åœ¨ä¸€ä¸ªå…³é”®å·®è·ï¼šè¿™äº›æ¨¡å‹åœ¨åŠ¨æ€ç©ºé—´äº¤äº’æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œè¿™æ˜¯ç°å®ä¸–ç•Œåº”ç”¨æ‰€å¿…éœ€çš„èƒ½åŠ›ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†M2-Reasoning-7Bæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨åœ¨é€šç”¨å’Œç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ä¸€ç§æ–°å‹æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†294,200ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­ç”¨äºå†·å¯åŠ¨å¾®è°ƒçš„æœ‰16ä¸‡å…«åƒä¸ªæ ·æœ¬ï¼Œç”¨äºRLVRçš„æœ‰12ä¸‡å…­åƒäºŒç™¾ä¸ªæ ·æœ¬ï¼‰ï¼Œè¿™äº›æ ·æœ¬å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢çš„è¯„ä¼°ï¼›ï¼ˆ2ï¼‰é‡‡ç”¨åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥è¿›è¡Œåˆ†æ­¥ä¼˜åŒ–ï¼Œä»¥ç¼“è§£æ•°æ®ä¹‹é—´çš„å†²çªï¼Œå¹¶ä¸ºç‰¹å®šä»»åŠ¡æä¾›å¥–åŠ±ï¼Œå‘å‡ºæœ‰é’ˆå¯¹æ€§çš„æ¿€åŠ±ä¿¡å·ã€‚ç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®ä¸å…ˆè¿›çš„è®­ç»ƒç›¸ç»“åˆï¼Œä½¿å¾—M2-Reasoning-7Båœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›ä¸‹æœ€æ–°æŠ€æœ¯è®°å½•ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08306v1">PDF</a> 31pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰çš„æ¨åŠ¨ï¼Œæ˜¾è‘—å¢å¼ºäº†å…¶æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»å­˜åœ¨ä¸€ä¸ªå…³é”®å·®è·ï¼šè¿™äº›æ¨¡å‹åœ¨åŠ¨æ€ç©ºé—´äº¤äº’æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œè¿™æ˜¯å®ç°ç°å®åº”ç”¨æ‰€å¿…éœ€çš„èƒ½åŠ›ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†M2-Reasoning-7Bæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ“…é•¿é€šç”¨å’Œç©ºé—´æ¨ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯æ–°å‹æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†294,200ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­168,000ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œå…¶ä½™ç”¨äºRLVRï¼‰ï¼Œè¿™äº›æ ·æœ¬å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ï¼›äºŒæ˜¯åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œå…·æœ‰åˆ†æ­¥ä¼˜åŒ–åŠŸèƒ½ï¼Œå¯ä»¥ç¼“è§£æ•°æ®ä¹‹é—´çš„å†²çªï¼Œå¹¶ä¸ºç‰¹å®šä»»åŠ¡æä¾›å¥–åŠ±ä¿¡å·ã€‚æ•°æ®å’Œå…ˆè¿›è®­ç»ƒçš„ç»“åˆä½¿M2-Reasoning-7Båœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰çš„æ¨åŠ¨ä¸‹ï¼Œå¢å¼ºäº†æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç›®å‰æ¨¡å‹åœ¨åŠ¨æ€ç©ºé—´äº¤äº’æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå½±å“äº†ç°å®åº”ç”¨ã€‚</li>
<li>M2-Reasoning-7Bæ¨¡å‹æ—¨åœ¨å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæ“…é•¿é€šç”¨å’Œç©ºé—´æ¨ç†ã€‚</li>
<li>è¯¥æ¨¡å‹é‡‡ç”¨æ–°å‹æ•°æ®ç®¡é“ç”Ÿæˆé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼Œç”¨äºå†·å¯åŠ¨å¾®è°ƒå’ŒRLVRã€‚</li>
<li>M2-Reasoning-7Bé‡‡ç”¨åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬åˆ†æ­¥ä¼˜åŒ–å’Œç‰¹å®šä»»åŠ¡å¥–åŠ±ä¿¡å·ã€‚</li>
<li>M2-Reasoning-7Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œè¾¾åˆ°æœ€æ–°æ°´å¹³ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b1112233b3d3c26094bb9353a9357c1c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="KAT-V1-Kwai-AutoThink-Technical-Report"><a href="#KAT-V1-Kwai-AutoThink-Technical-Report" class="headerlink" title="KAT-V1: Kwai-AutoThink Technical Report"></a>KAT-V1: Kwai-AutoThink Technical Report</h2><p><strong>Authors:Zizheng Zhan, Ken Deng, Huaixi Tang, Wen Xiang, Kun Wu, Weihao Li, Wenqiang Zhu, Jingxuan Xu, Lecheng Huang, Zongxian Feng, Shaojie Wang, Shangpeng Yan, Jiaheng Liu, Zhongyuan Peng, Zuchen Gao, Haoyang Huang, Ziqi Zhan, Yanan Wu, Yuanxing Zhang, Jian Yang, Guang Chen, Haotian Zhang, Bin Chen, Bing Yu</strong></p>
<p>We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage by up to approximately 30%. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishouâ€™s internal coding assistant), and improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) with 40B activation parameters, where the early-stage results already demonstrate promising improvements in performance and efficiency, further showing the scalability of the AutoThink paradigm. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†Kwaipilot-AutoThinkï¼ˆKATï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºäº†è§£å†³æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¿‡åº¦æ€è€ƒé—®é¢˜è€Œå¼€å‘çš„40Bå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…¶ä¸­æå‡ºäº†ä¸€ç§è‡ªåŠ¨æ€è€ƒè®­ç»ƒæ¨¡å¼ï¼Œèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§åœ¨æ¨ç†å’Œéæ¨ç†æ¨¡å¼ä¹‹é—´è¿›è¡ŒåŠ¨æ€åˆ‡æ¢ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬åŸºäºä¸€ç§æ–°é¢–çš„æ ‡ç­¾å¤„ç†ç®¡é“å’Œå¤šä»£ç†åˆæˆç­–ç•¥æ„å»ºäº†åŒä½“åˆ¶æ•°æ®é›†ï¼Œç„¶ååº”ç”¨å¢å¼ºäº†çš„å¤šä»¤ç‰Œé¢„æµ‹ï¼ˆMTPï¼‰çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆçš„ç²¾ç»†æ¨ç†è½¬ç§»ï¼ŒåŒæ—¶æœ€å°åŒ–äº†é¢„è®­ç»ƒæˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç§å†·å¯åŠ¨åˆå§‹åŒ–ç­–ç•¥ï¼Œåˆ©ç”¨å¤šæ•°æŠ•ç¥¨ä¿¡å·å’Œæ„å›¾æ„ŸçŸ¥æç¤ºæ¥å¼•å…¥æ¨¡å¼é€‰æ‹©å…ˆéªŒã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†Step-SRPOï¼Œè¿™æ˜¯ä¸€ç§å¢å¼ºå­¦ä¹ ç®—æ³•ï¼Œå®ƒå°†ä¸­é—´ç›‘ç£èå…¥GRPOæ¡†æ¶ï¼Œä¸ºæ¨ç†æ¨¡å¼é€‰æ‹©å’Œå“åº”å‡†ç¡®æ€§æä¾›ç»“æ„åŒ–æŒ‡å¯¼ã€‚åœ¨å¤šåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒKATåœ¨å¤šç§æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸Šè¡¨ç°ä¸€ç›´ä¸å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹ä¿æŒä¸€è‡´ç”šè‡³è¡¨ç°æ›´å¥½ï¼ŒåŒ…æ‹¬DeepSeek-R1-0528å’ŒQwen3-235B-A22Bç­‰æ¨¡å‹ï¼ŒåŒæ—¶æœ€å¤šèƒ½å‡å°‘çº¦30%çš„ä»¤ç‰Œä½¿ç”¨é‡ã€‚é™¤äº†å­¦æœ¯è¯„ä¼°ä¹‹å¤–ï¼ŒKATå·²ç»åœ¨Kwaipilotï¼ˆå³å¿«æ‰‹çš„å†…éƒ¨ç¼–ç åŠ©æ‰‹ï¼‰ä¸­å¾—åˆ°æˆåŠŸéƒ¨ç½²ï¼Œé€šè¿‡é«˜å‡†ç¡®æ€§ã€é«˜æ•ˆç‡å’Œæ§åˆ¶æ¨ç†è¡Œä¸ºæ¥æ”¹è¿›ç°å®å·¥ä½œæµç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ­£åœ¨ç§¯æè®­ç»ƒä¸€ä¸ªæ‹¥æœ‰200Bçš„ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆMoEï¼‰ï¼Œå…¶ä¸­åŒ…å«é«˜è¾¾æ¿€æ´»å‚æ•°çš„æ¿€æ´»å‚æ•°é«˜è¾¾å››åäº¿æ¯”ç‰¹ã€‚æ—©æœŸé˜¶æ®µçš„ç»“æœå·²ç»æ˜¾ç¤ºå‡ºåœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢çš„æ˜æ˜¾æ”¹è¿›ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†AutoThinkæ¨¡å¼çš„å¯æ‰©å±•æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08297v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ±Ÿå±±è”åˆæ¨å‡ºäº†ä¸€æ¬¾åä¸ºKwaipilot-AutoThinkçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨è§£å†³æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¿‡åº¦æ€è€ƒé—®é¢˜ã€‚å®ƒé‡‡ç”¨è‡ªåŠ¨æ€è€ƒè®­ç»ƒèŒƒå¼ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€åˆ‡æ¢æ¨ç†å’Œéæ¨ç†æ¨¡å¼ã€‚è¯¥æ¨¡å‹é€šè¿‡æ„å»ºåŒä½“åˆ¶æ•°æ®é›†ã€åº”ç”¨å¤šä»¤ç‰Œé¢„æµ‹çŸ¥è¯†è’¸é¦æŠ€æœ¯ã€å®ç°å†·å¯åŠ¨åˆå§‹åŒ–ç­–ç•¥ä»¥åŠæå‡ºç»“åˆä¸­é—´ç›‘ç£çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•Step-SRPOï¼Œæé«˜äº†æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæ±Ÿå±±æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨å¿«æ‰‹å†…éƒ¨ç¼–ç åŠ©æ‰‹Kwaipilotä¸­å¾—åˆ°æˆåŠŸéƒ¨ç½²ã€‚æ­¤å¤–ï¼Œå›¢é˜Ÿæ­£åœ¨ç§¯æè®­ç»ƒä¸€ä¸ªæ··åˆä¸“å®¶æ¨¡å‹ï¼Œåˆæ­¥ç»“æœä¹Ÿæ˜¾ç¤ºå‡ºåœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢çš„æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Kwaipilot-AutoThinkæ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸­è¿‡åº¦æ€è€ƒé—®é¢˜çš„40Bå¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹é‡‡ç”¨è‡ªåŠ¨æ€è€ƒè®­ç»ƒèŒƒå¼ï¼Œèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€åˆ‡æ¢æ¨ç†å’Œéæ¨ç†æ¨¡å¼ã€‚</li>
<li>é€šè¿‡æ„å»ºåŒä½“åˆ¶æ•°æ®é›†å’Œå¤šä»¤ç‰Œé¢„æµ‹çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œæé«˜äº†æ¨¡å‹çš„æ¨ç†æ•ˆç‡å’Œç²¾ç»†åº¦ã€‚</li>
<li>æ¨¡å‹å®æ–½äº†å†·å¯åŠ¨åˆå§‹åŒ–ç­–ç•¥ï¼Œé€šè¿‡å¼•å…¥æ¨¡å¼é€‰æ‹©å…ˆéªŒå’Œæ„å›¾æ„ŸçŸ¥æç¤ºæ¥æå‡æ€§èƒ½ã€‚</li>
<li>Step-SRPOå¼ºåŒ–å­¦ä¹ ç®—æ³•ç»“åˆäº†ä¸­é—´ç›‘ç£ï¼Œä¸ºæ¨ç†æ¨¡å¼é€‰æ‹©å’Œå“åº”å‡†ç¡®æ€§æä¾›äº†ç»“æ„åŒ–æŒ‡å¯¼ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒKwaipilot-AutoThinkåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ¨¡å‹æœ‰æ‰€è¶…è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ef1866cbd914bc1f66a0bbc2915cad28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-444ce838166649257f8fabdaad9bdff6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abda2051a7c393becccd43e06eb39869.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-284b1b56022a12b08884e752f15ae756.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a7e7dc4fb8a22cb2e53c8c4528e3b19.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="A-Practical-Two-Stage-Recipe-for-Mathematical-LLMs-Maximizing-Accuracy-with-SFT-and-Efficiency-with-Reinforcement-Learning"><a href="#A-Practical-Two-Stage-Recipe-for-Mathematical-LLMs-Maximizing-Accuracy-with-SFT-and-Efficiency-with-Reinforcement-Learning" class="headerlink" title="A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy   with SFT and Efficiency with Reinforcement Learning"></a>A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy   with SFT and Efficiency with Reinforcement Learning</h2><p><strong>Authors:Hiroshi Yoshihara, Taiki Yamaguchi, Yuichi Inoue</strong></p>
<p>Enhancing the mathematical reasoning of Large Language Models (LLMs) is a pivotal challenge in advancing AI capabilities. While Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are the dominant training paradigms, a systematic methodology for combining them to maximize both accuracy and efficiency remains largely unexplored. This paper introduces a practical and effective training recipe that strategically integrates extended SFT with RL from online inference (GRPO). We posit that these methods play complementary, not competing, roles: a prolonged SFT phase first pushes the modelâ€™s accuracy to its limits, after which a GRPO phase dramatically improves token efficiency while preserving this peak performance. Our experiments reveal that extending SFT for as many as 10 epochs is crucial for performance breakthroughs, and that the primary role of GRPO in this framework is to optimize solution length. The efficacy of our recipe is rigorously validated through top-tier performance on challenging benchmarks, including a high rank among over 2,200 teams in the strictly leak-free AI Mathematical Olympiad (AIMO). This work provides the community with a battle-tested blueprint for developing state-of-the-art mathematical reasoners that are both exceptionally accurate and practically efficient. To ensure full reproducibility and empower future research, we will open-source our entire framework, including all code, model checkpoints, and training configurations at <a target="_blank" rel="noopener" href="https://github.com/analokmaus/kaggle-aimo2-fast-math-r1">https://github.com/analokmaus/kaggle-aimo2-fast-math-r1</a>. </p>
<blockquote>
<p>å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ˜¯æå‡äººå·¥æ™ºèƒ½èƒ½åŠ›çš„é‡è¦æŒ‘æˆ˜ã€‚å°½ç®¡æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ˜¯ä¸»è¦çš„è®­ç»ƒèŒƒå¼ï¼Œä½†å°†å®ƒä»¬ç»“åˆèµ·æ¥ä»¥æœ€å¤§åŒ–å‡†ç¡®æ€§å’Œæ•ˆç‡çš„ç³»ç»Ÿæ€§æ–¹æ³•ä»ç„¶å¾ˆå¤§ç¨‹åº¦ä¸Šæœªè¢«æ¢ç´¢ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å®ç”¨æœ‰æ•ˆçš„è®­ç»ƒé…æ–¹ï¼Œå®ƒæˆ˜ç•¥æ€§åœ°ç»“åˆäº†æ‰©å±•çš„SFTä¸æ¥è‡ªåœ¨çº¿æ¨ç†çš„RLï¼ˆGRPOï¼‰ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™äº›æ–¹æ³•èµ·åˆ°çš„æ˜¯äº’è¡¥ä½œç”¨ï¼Œè€Œéç«äº‰ä½œç”¨ï¼šé¦–å…ˆï¼Œå»¶é•¿çš„SFTé˜¶æ®µä¼šå°†æ¨¡å‹çš„å‡†ç¡®æ€§æ¨è‡³æé™ï¼ŒéšåGRPOé˜¶æ®µåœ¨ä¿æŒè¿™ç§å³°å€¼æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜ä»¤ç‰Œæ•ˆç‡ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå°†SFTå»¶é•¿å¤šè¾¾10ä¸ªå‘¨æœŸå¯¹äºæ€§èƒ½çªç ´è‡³å…³é‡è¦ï¼Œè€ŒGRPOåœ¨æ­¤æ¡†æ¶ä¸­çš„ä¸»è¦ä½œç”¨æ˜¯ä¼˜åŒ–è§£å†³æ–¹æ¡ˆé•¿åº¦ã€‚è¯¥é…æ–¹çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨ä¸€æµæ€§èƒ½çš„æŒ‘æˆ˜åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†ä¸¥æ ¼éªŒè¯ï¼ŒåŒ…æ‹¬åœ¨ä¸¥æ ¼æ— æ³„æ¼çš„äººå·¥æ™ºèƒ½æ•°å­¦å¥¥æ—åŒ¹å…‹ç«èµ›ï¼ˆAIMOï¼‰ä¸­ååˆ—å‰èŒ…çš„è¶…è¿‡2,200æ”¯å›¢é˜Ÿä¸­ååˆ—å‰èŒ…ã€‚è¿™é¡¹å·¥ä½œä¸ºç¤¾åŒºæä¾›äº†ä¸€ä¸ªç»è¿‡å®æˆ˜æ£€éªŒçš„è“å›¾ï¼Œç”¨äºå¼€å‘æ—¢ç²¾ç¡®åˆå®ç”¨çš„æœ€æ–°æ•°å­¦æ¨ç†å™¨ã€‚ä¸ºç¡®ä¿å¯é‡å¤æ€§å’Œä¿ƒè¿›æœªæ¥ç ”ç©¶ï¼Œæˆ‘ä»¬å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/analokmaus/kaggle-aimo2-fast-math-r1">https://github.com/analokmaus/kaggle-aimo2-fast-math-r1</a>ä¸Šå…¬å¼€æ•´ä¸ªæ¡†æ¶çš„æ‰€æœ‰ä»£ç ã€æ¨¡å‹æ£€æŸ¥ç‚¹å’Œè®­ç»ƒé…ç½®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08267v1">PDF</a> Presented at ICML 2025 Workshop on The second AI for MATH</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ˜¯æå‡äººå·¥æ™ºèƒ½èƒ½åŠ›çš„é‡è¦æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œåœ¨çº¿æ¨ç†å¼ºåŒ–å­¦ä¹ ï¼ˆGRPOï¼‰çš„æœ‰æ•ˆè®­ç»ƒç­–ç•¥ã€‚ç ”ç©¶è®¤ä¸ºè¿™ä¸¤ç§æ–¹æ³•å…·æœ‰äº’è¡¥ä½œç”¨è€Œéç«äº‰å…³ç³»ï¼šå…ˆè¿›è¡Œé•¿æ—¶é—´çš„SFTè®­ç»ƒä»¥æå‡æ¨¡å‹ç²¾åº¦ï¼Œç„¶åé‡‡ç”¨GRPOè®­ç»ƒä»¥æ˜¾è‘—æ”¹è¿›tokenæ•ˆç‡åŒæ—¶ä¿æŒé¡¶å°–æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œè¿›è¡Œå¤šè¾¾10ä¸ªepochçš„SFTè®­ç»ƒå¯¹æ€§èƒ½è‡³å…³é‡è¦ï¼Œè€ŒGRPOçš„ä¸»è¦ä½œç”¨æ˜¯åœ¨è¿™ä¸ªæ¡†æ¶ä¸­ä¼˜åŒ–è§£å†³æ–¹æ¡ˆé•¿åº¦ã€‚æœ¬æ–‡æä¾›çš„è“å›¾å·²åœ¨é¡¶çº§æŒ‘æˆ˜èµ›ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬åœ¨ä¸¥æ ¼æ— æ³„æ¼çš„AIæ•°å­¦å¥¥æ—åŒ¹å…‹ç«èµ›ï¼ˆAIMOï¼‰ä¸­ååˆ—å‰èŒ…ã€‚ç ”ç©¶å°†å…¬å¼€æ•´ä¸ªæ¡†æ¶ï¼ŒåŒ…æ‹¬ä»£ç ã€æ¨¡å‹æ£€æŸ¥ç‚¹å’Œè®­ç»ƒé…ç½®ï¼Œä»¥ç¡®ä¿å¯é‡å¤æ€§å’Œæœªæ¥ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡æ˜¯AIå‘å±•çš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡ç»“åˆäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œåœ¨çº¿æ¨ç†å¼ºåŒ–å­¦ä¹ ï¼ˆGRPOï¼‰ä¸¤ç§è®­ç»ƒèŒƒå¼ã€‚</li>
<li>SFTå’ŒGRPOå…·æœ‰äº’è¡¥æ€§ï¼Œè€Œéç«äº‰æ€§ï¼Œå…¶ä¸­SFTç”¨äºæé«˜æ¨¡å‹ç²¾åº¦ï¼ŒGRPOç”¨äºæ”¹å–„tokenæ•ˆç‡å¹¶ä¿æŒé«˜æ€§èƒ½ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œè¿›è¡Œæ›´å¤šepochçš„SFTè®­ç»ƒå¯¹æ€§èƒ½è‡³å…³é‡è¦ï¼Œè€ŒGRPOä¸»è¦ä¼˜åŒ–è§£å†³æ–¹æ¡ˆé•¿åº¦ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨é¡¶çº§æŒ‘æˆ˜èµ›ä¸­è¡¨ç°å“è¶Šï¼ŒåŒ…æ‹¬åœ¨AIæ•°å­¦å¥¥æ—åŒ¹å…‹ç«èµ›ä¸­ååˆ—å‰èŒ…ã€‚</li>
<li>ç ”ç©¶å°†å…¬å¼€æ¡†æ¶ã€ä»£ç ã€æ¨¡å‹æ£€æŸ¥ç‚¹å’Œè®­ç»ƒé…ç½®ï¼Œä»¥ä¿ƒè¿›æœªæ¥ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08267">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d209973f2ae164a0e9755b9c1ed33a7b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a5c528a06f5e41139deb0f888775a78.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-310ca78dfee0251c32b521d1fd5990d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d20877f259da79ccc5cefff2ef89d5c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Making-VLMs-More-Robot-Friendly-Self-Critical-Distillation-of-Low-Level-Procedural-Reasoning"><a href="#Making-VLMs-More-Robot-Friendly-Self-Critical-Distillation-of-Low-Level-Procedural-Reasoning" class="headerlink" title="Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level   Procedural Reasoning"></a>Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level   Procedural Reasoning</h2><p><strong>Authors:Chan Young Park, Jillian Fisher, Marius Memmel, Dipika Khullar, Andy Yun, Abhishek Gupta, Yejin Choi</strong></p>
<p>Large language models (LLMs) have shown promise in robotic procedural planning, yet their human-centric reasoning often omits the low-level, grounded details needed for robotic execution. Vision-language models (VLMs) offer a path toward more perceptually grounded plans, but current methods either rely on expensive, large-scale models or are constrained to narrow simulation settings. We introduce SelfReVision, a lightweight and scalable self-improvement framework for vision-language procedural planning. SelfReVision enables small VLMs to iteratively critique, revise, and verify their own plans-without external supervision or teacher models-drawing inspiration from chain-of-thought prompting and self-instruct paradigms. Through this self-distillation loop, models generate higher-quality, execution-ready plans that can be used both at inference and for continued fine-tuning. Using models varying from 3B to 72B, our results show that SelfReVision not only boosts performance over weak base VLMs but also outperforms models 100X the size, yielding improved control in downstream embodied tasks. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æœºå™¨äººç¨‹åºè§„åˆ’æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬ä»¥äººä¸ºä¸­å¿ƒçš„æ¨ç†å¾€å¾€ä¼šå¿½ç•¥æœºå™¨äººæ‰§è¡Œæ‰€éœ€çš„ä½çº§ã€å…·ä½“ç»†èŠ‚ã€‚è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºæ›´æ„ŸçŸ¥å…·ä½“çš„è®¡åˆ’æä¾›äº†é€”å¾„ï¼Œä½†å½“å‰çš„æ–¹æ³•è¦ä¹ˆä¾èµ–äºæ˜‚è´µçš„å¤§è§„æ¨¡æ¨¡å‹ï¼Œè¦ä¹ˆä»…é™äºç‹­çª„çš„ä»¿çœŸç¯å¢ƒã€‚æˆ‘ä»¬å¼•å…¥äº†SelfReVisionï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè§†è§‰è¯­è¨€ç¨‹åºè§„åˆ’çš„è½»é‡çº§å’Œå¯æ‰©å±•çš„è‡ªæˆ‘æ”¹è¿›æ¡†æ¶ã€‚SelfReVisionä½¿å°å‹VLMèƒ½å¤Ÿè¿­ä»£åœ°è¯„ä¼°ã€ä¿®æ”¹å’ŒéªŒè¯è‡ªå·±çš„è®¡åˆ’ï¼Œè€Œæ— éœ€å¤–éƒ¨ç›‘ç£æˆ–æ•™å¸ˆæ¨¡å‹ï¼Œè¿™å¾—ç›Šäºæ€ç»´é“¾æç¤ºå’Œè‡ªæˆ‘æŒ‡å¯¼èŒƒå¼çš„å¯å‘ã€‚é€šè¿‡è¿™ä¸ªè‡ªæˆ‘æç‚¼å¾ªç¯ï¼Œæ¨¡å‹ç”Ÿæˆäº†é«˜è´¨é‡ã€å¯æ‰§è¡Œçš„è®¡åˆ’ï¼Œè¿™äº›è®¡åˆ’æ—¢å¯ç”¨äºæ¨ç†ï¼Œä¹Ÿå¯ç”¨äºæŒç»­å¾®è°ƒã€‚ä½¿ç”¨ä»3Båˆ°72Bä¸ç­‰çš„æ¨¡å‹ï¼Œæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSelfReVisionä¸ä»…æå‡äº†åŸºç¡€è¾ƒå¼±VLMçš„æ€§èƒ½ï¼Œè€Œä¸”è¶…è¶Šäº†è§„æ¨¡å¤§100å€çš„æ¨¡å‹ï¼Œåœ¨ä¸‹æ¸¸å®ä½“ä»»åŠ¡ä¸­å®ç°äº†æ›´å¥½çš„æ§åˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08224v1">PDF</a> Code Available: <a target="_blank" rel="noopener" href="https://github.com/chan0park/SelfReVision">https://github.com/chan0park/SelfReVision</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººç¨‹åºè§„åˆ’ä¸Šå±•ç°å‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬ä»¥äººç±»ä¸ºä¸­å¿ƒçš„æ¨ç†å¾€å¾€å¿½ç•¥äº†æœºå™¨äººæ‰§è¡Œæ‰€éœ€çš„ä½çº§ã€å…·ä½“ç»†èŠ‚ã€‚è§†è§‰è¯­è¨€æ¨¡å‹ä¸ºæ›´æ„ŸçŸ¥å…·ä½“çš„è®¡åˆ’æä¾›äº†é€”å¾„ï¼Œä½†å½“å‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºæ˜‚è´µçš„å¤§è§„æ¨¡æ¨¡å‹ï¼Œè¦ä¹ˆä»…é™äºç‹­çª„çš„æ¨¡æ‹Ÿç¯å¢ƒã€‚æœ¬æ–‡æå‡ºäº†SelfReVisionï¼Œä¸€ä¸ªç”¨äºè§†è§‰è¯­è¨€ç¨‹åºè§„åˆ’çš„è½»é‡çº§å’Œå¯æ‰©å±•çš„è‡ªæˆ‘æ”¹è¿›æ¡†æ¶ã€‚SelfReVisionä½¿å°å‹VLMèƒ½å¤Ÿè‡ªæˆ‘æ‰¹åˆ¤ã€ä¿®è®¢å’ŒéªŒè¯å…¶è®¡åˆ’ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£æˆ–æ•™å¸ˆæ¨¡å‹ï¼Œçµæ„Ÿæ¥æºäºæ€ç»´é“¾æç¤ºå’Œè‡ªæˆ‘æŒ‡å¯¼èŒƒå¼ã€‚é€šè¿‡è¿™ä¸ªè‡ªæˆ‘è’¸é¦å¾ªç¯ï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ã€é€‚åˆæ‰§è¡Œçš„è®¡åˆ’ï¼Œè¿™äº›è®¡åˆ’æ—¢å¯ç”¨äºæ¨ç†ï¼Œä¹Ÿå¯ç”¨äºæŒç»­å¾®è°ƒã€‚ä½¿ç”¨ä»3Båˆ°72Bä¸ç­‰çš„æ¨¡å‹ï¼Œç»“æœè¡¨æ˜ï¼ŒSelfReVisionä¸ä»…æé«˜äº†åŸºç¡€VLMçš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨ä¸‹æ¸¸å®ä½“ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºè§„æ¨¡å¤§100å€çš„æ¨¡å‹ï¼Œå®ç°äº†ä¸‹æ¸¸ä»»åŠ¡æ§åˆ¶èƒ½åŠ›çš„æå‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºå™¨äººç¨‹åºè§„åˆ’ä¸­æœ‰æ½œåŠ›ï¼Œä½†éœ€å¼¥è¡¥å…¶ç¼ºä¹ä½çº§ã€å…·ä½“ç»†èŠ‚çš„é—®é¢˜ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)æ˜¯å‘æ›´æ„ŸçŸ¥å…·ä½“åŒ–çš„è®¡åˆ’è¿ˆè¿›çš„é€”å¾„ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨æ¨¡å‹è§„æ¨¡å¤§æˆ–åº”ç”¨ç¯å¢ƒå—é™çš„é—®é¢˜ã€‚</li>
<li>SelfReVisionæ˜¯ä¸€ä¸ªè½»é‡çº§å’Œå¯æ‰©å±•çš„è‡ªæˆ‘æ”¹è¿›æ¡†æ¶ï¼Œç”¨äºè§†è§‰è¯­è¨€ç¨‹åºè§„åˆ’ã€‚</li>
<li>SelfReVisionä½¿å°å‹VLMèƒ½å¤Ÿè‡ªæˆ‘æ‰¹åˆ¤ã€ä¿®è®¢å’ŒéªŒè¯è®¡åˆ’ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£æˆ–æ•™å¸ˆæ¨¡å‹ã€‚</li>
<li>SelfReVisioné€šè¿‡è‡ªæˆ‘è’¸é¦å¾ªç¯ç”Ÿæˆé«˜è´¨é‡ã€é€‚åˆæ‰§è¡Œçš„è®¡åˆ’ï¼Œè¿™äº›è®¡åˆ’å¯ç”¨äºæ¨ç†å’ŒæŒç»­å¾®è°ƒã€‚</li>
<li>SelfReVisionä¸ä»…æé«˜äº†åŸºç¡€VLMçš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨ä¸‹æ¸¸å®ä½“ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08224">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8d8ed474c1cefafab78a0ef93e6cdacd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2c121ccaf6f854c55172e54b83ee549.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-698c16ce6628c8d5d714532328fcf93f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-09c9bfaa47a9282f42899765646f1db2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfba0ba59a6ae8c1bd7da972d301c526.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GRASP-Generic-Reasoning-And-SPARQL-Generation-across-Knowledge-Graphs"><a href="#GRASP-Generic-Reasoning-And-SPARQL-Generation-across-Knowledge-Graphs" class="headerlink" title="GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs"></a>GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs</h2><p><strong>Authors:Sebastian Walter, Hannah Bast</strong></p>
<p>We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»è‡ªç„¶è¯­è¨€é—®é¢˜æˆ–å…³é”®å­—æŸ¥è¯¢ç”ŸæˆRDFçŸ¥è¯†å›¾ä¸Šçš„SPARQLæŸ¥è¯¢ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦å¾®è°ƒã€‚ç›¸åï¼Œå®ƒä½¿ç”¨è¯­è¨€æ¨¡å‹é€šè¿‡æˆ˜ç•¥æ€§åœ°æ‰§è¡ŒSPARQLæŸ¥è¯¢å¹¶æœç´¢ç›¸å…³çš„IRIå’Œæ–‡å­—æ¥æ¢ç´¢çŸ¥è¯†å›¾ã€‚æˆ‘ä»¬åœ¨å„ç§åŸºå‡†æµ‹è¯•ï¼ˆé’ˆå¯¹ä¸åŒç±»å‹å’Œå¤§å°çš„çŸ¥è¯†å›¾ï¼‰å’Œè¯­è¨€æ¨¡å‹ï¼ˆä¸åŒè§„æ¨¡å’Œç±»å‹ï¼ŒåŒ…æ‹¬å•†ä¸šå’Œå¼€æºï¼‰ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚åœ¨WikiDataä¸Šï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œå°½ç®¡æˆ‘ä»¬å¤„äºé›¶æ ·æœ¬ç¯å¢ƒã€‚åœ¨Freebaseä¸Šï¼Œæˆ‘ä»¬æ¥è¿‘æœ€ä½³å°‘æ ·æœ¬æ–¹æ³•çš„è¡¨ç°ã€‚åœ¨å…¶ä»–è¾ƒå°‘è¯„ä¼°çš„çŸ¥è¯†å›¾å’ŒåŸºå‡†æµ‹è¯•ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ€»ä½“ä¸Šä¹Ÿæœ‰è‰¯å¥½çš„è¡¨ç°ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†å…¶ä»–ä¸€äº›ç ”ç©¶ï¼Œå¦‚æ¯”è¾ƒæœç´¢å›¾å½¢çš„ä¸åŒæ–¹å¼ã€å¼•å…¥åé¦ˆæœºåˆ¶æˆ–åˆ©ç”¨å°‘æ ·æœ¬ç¤ºä¾‹ç­‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08107v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç”¨äºä»è‡ªç„¶è¯­è¨€é—®é¢˜æˆ–å…³é”®è¯æŸ¥è¯¢ç”ŸæˆRDFçŸ¥è¯†å›¾è°±ä¸Šçš„SPARQLæŸ¥è¯¢ï¼Œæ— éœ€å¾®è°ƒã€‚å®ƒé€šè¿‡æˆ˜ç•¥æ€§åœ°æ‰§è¡ŒSPARQLæŸ¥è¯¢å¹¶æœç´¢ç›¸å…³çš„IRIså’Œæ–‡å­—æ¥æ¢ç´¢çŸ¥è¯†å›¾è°±ã€‚æˆ‘ä»¬åœ¨å¤šç§åŸºå‡†æµ‹è¯•ï¼ˆé’ˆå¯¹ä¸åŒç±»å‹å’Œå¤§å°çš„çŸ¥è¯†å›¾è°±ï¼‰å’Œè¯­è¨€æ¨¡å‹ï¼ˆåŒ…æ‹¬å•†ä¸šå’Œå¼€æºçš„ä¸åŒè§„æ¨¡å’Œç±»å‹ï¼‰ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬åœ¨WikiDataä¸Šå–å¾—äº†å¤šä¸ªåŸºå‡†æµ‹è¯•çš„æœ€ä½³ç»“æœï¼Œå°½ç®¡æˆ‘ä»¬æ˜¯åœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹å®ç°çš„ã€‚åœ¨Freebaseä¸Šï¼Œæˆ‘ä»¬çš„è¡¨ç°æ¥è¿‘æœ€ä½³çš„å‡ æ¬¡ç¤ºä¾‹æ–¹æ³•ã€‚åœ¨å…¶ä»–è¾ƒå°‘è¯„ä¼°çš„çŸ¥è¯†å›¾è°±å’ŒåŸºå‡†æµ‹è¯•ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ€»ä½“ä¸Šè¡¨ç°è‰¯å¥½ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†å…¶ä»–é¢å¤–ç ”ç©¶ï¼Œå¦‚æ¯”è¾ƒä¸åŒçš„å›¾å½¢æœç´¢æ–¹å¼ã€å¼•å…¥åé¦ˆæœºåˆ¶æˆ–åˆ©ç”¨å‡ æ¬¡ç¤ºä¾‹ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„SPARQLæŸ¥è¯¢ç”Ÿæˆæ–¹æ³•ï¼Œç”¨äºä»RDFçŸ¥è¯†å›¾è°±ç”ŸæˆæŸ¥è¯¢ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€å¾®è°ƒï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¢ç´¢çŸ¥è¯†å›¾è°±ã€‚</li>
<li>åœ¨å¤šç§çŸ¥è¯†å›¾è°±å’ŒåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬WikiDataå’ŒFreebaseã€‚</li>
<li>åœ¨WikiDataä¸Šå–å¾—äº†å¤šä¸ªåŸºå‡†æµ‹è¯•çš„æœ€ä½³ç»“æœï¼Œè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>åœ¨Freebaseä¸Šçš„è¡¨ç°æ¥è¿‘æœ€ä½³å‡ æ¬¡ç¤ºä¾‹æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å…¶ä»–çŸ¥è¯†å›¾è°±å’ŒåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°æ€»ä½“ä¸Šè‰¯å¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08107">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2ae9d15fd27a99ee08c2e4df0d79369b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3c8181573066225406325d63f882f51.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="TableReasoner-Advancing-Table-Reasoning-Framework-with-Large-Language-Models"><a href="#TableReasoner-Advancing-Table-Reasoning-Framework-with-Large-Language-Models" class="headerlink" title="TableReasoner: Advancing Table Reasoning Framework with Large Language   Models"></a>TableReasoner: Advancing Table Reasoning Framework with Large Language   Models</h2><p><strong>Authors:Sishi Xiong, Dakai Wang, Yu Zhao, Jie Zhang, Changzai Pan, Haowei He, Xiangyu Li, Wenhan Chang, Zhongjiang He, Shuangyong Song, Yongxiang Li</strong></p>
<p>The paper presents our system developed for table question answering (TQA). TQA tasks face challenges due to the characteristics of real-world tabular data, such as large size, incomplete column semantics, and entity ambiguity. To address these issues, we propose a large language model (LLM)-powered and programming-based table reasoning framework, named TableReasoner. It models a table using the schema that combines structural and semantic representations, enabling holistic understanding and efficient processing of large tables. We design a multi-step schema linking plan to derive a focused table schema that retains only query-relevant information, eliminating ambiguity and alleviating hallucinations. This focused table schema provides precise and sufficient table details for query refinement and programming. Furthermore, we integrate the reasoning workflow into an iterative thinking architecture, allowing incremental cycles of thinking, reasoning and reflection. Our system achieves first place in both subtasks of SemEval-2025 Task 8. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†æˆ‘ä»¬ä¸ºè¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰ä»»åŠ¡å¼€å‘çš„ç³»ç»Ÿã€‚TQAä»»åŠ¡ç”±äºç°å®ä¸–ç•Œè¡¨æ ¼æ•°æ®çš„ç‰¹ç‚¹è€Œé¢ä¸´æŒ‘æˆ˜ï¼Œä¾‹å¦‚è¡¨æ ¼æ•°æ®é‡å¤§ã€åˆ—è¯­ä¹‰ä¸å®Œæ•´å’Œå®ä½“æ­§ä¹‰ç­‰ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œç¼–ç¨‹çš„è¡¨æ ¼æ¨ç†æ¡†æ¶ï¼Œåä¸ºTableReasonerã€‚å®ƒä½¿ç”¨ç»“åˆç»“æ„å’Œè¯­ä¹‰è¡¨ç¤ºçš„æ¶æ„å¯¹è¡¨æ ¼è¿›è¡Œå»ºæ¨¡ï¼Œå®ç°å¯¹å¤§è¡¨æ ¼çš„æ•´ä½“ç†è§£å’Œé«˜æ•ˆå¤„ç†ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¤šæ­¥éª¤æ¶æ„é“¾æ¥è®¡åˆ’ï¼Œä»¥æ¨å¯¼å‡ºä¸“æ³¨äºæŸ¥è¯¢çš„è¡¨æ ¼æ¶æ„ï¼Œè¯¥æ¶æ„åªä¿ç•™ä¸æŸ¥è¯¢ç›¸å…³çš„ä¿¡æ¯ï¼Œæ¶ˆé™¤æ­§ä¹‰å¹¶å‡è½»è™šæ„ç°è±¡ã€‚æ­¤ä¸“æ³¨äºæŸ¥è¯¢çš„è¡¨æ ¼æ¶æ„ä¸ºæŸ¥è¯¢ä¼˜åŒ–å’Œç¼–ç¨‹æä¾›äº†ç²¾ç¡®ä¸”è¶³å¤Ÿçš„è¡¨æ ¼ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ¨ç†å·¥ä½œæµç¨‹æ•´åˆåˆ°è¿­ä»£æ€ç»´æ¶æ„ä¸­ï¼Œå…è®¸æ€è€ƒã€æ¨ç†å’Œåæ€çš„å¢é‡å¾ªç¯ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿåœ¨SemEval-2025ä»»åŠ¡8çš„ä¸¤ä¸ªå­ä»»åŠ¡ä¸­å‡è·å¾—ç¬¬ä¸€åã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08046v1">PDF</a> </p>
<p><strong>Summary</strong>:<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªä¸ºè¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰ç³»ç»Ÿæ‰€å¼€å‘çš„ç³»ç»Ÿã€‚é¢å¯¹ç°å®ä¸–ç•Œä¸­è¡¨æ ¼æ•°æ®çš„ç‰¹ç‚¹ï¼Œå¦‚å¤§è§„æ¨¡ã€åˆ—è¯­ä¹‰ä¸å®Œæ•´å’Œå®ä½“æ­§ä¹‰ç­‰æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç¼–ç¨‹å¼è¡¨æ ¼æ¨ç†æ¡†æ¶â€”â€”TableReasonerã€‚å®ƒé€šè¿‡ç»“åˆç»“æ„æ€§å’Œè¯­ä¹‰è¡¨ç¤ºæ¥å»ºæ¨¡è¡¨æ ¼ï¼Œå®ç°å¯¹å¤§å‹è¡¨æ ¼çš„æ•´ä½“ç†è§£å’Œé«˜æ•ˆå¤„ç†ã€‚è®¾è®¡äº†ä¸€ä¸ªå¤šæ­¥éª¤çš„æ¶æ„é“¾æ¥è®¡åˆ’ï¼Œä»¥æ¨å¯¼å‡ºä¸“æ³¨äºæŸ¥è¯¢ç›¸å…³ä¿¡æ¯çš„è¡¨æ ¼æ¶æ„ï¼Œæ¶ˆé™¤æ­§ä¹‰å¹¶å‡è½»è™šæ„ç°è±¡ã€‚æ•´åˆæ¨ç†å·¥ä½œæµç¨‹åˆ°è¿­ä»£æ€ç»´æ¶æ„ä¸­ï¼Œå…è®¸æ€è€ƒã€æ¨ç†å’Œåæ€çš„å¢é‡å¾ªç¯ã€‚è¯¥ç³»ç»Ÿåœ¨SemEval-2025ä»»åŠ¡8çš„ä¸¤ä¸ªå­ä»»åŠ¡ä¸­å‡è·å¾—ç¬¬ä¸€åã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>ç³»ç»Ÿé’ˆå¯¹è¡¨æ ¼é—®ç­”ï¼ˆTQAï¼‰ä»»åŠ¡å¼€å‘ã€‚</li>
<li>é¢å¯¹è¡¨æ ¼æ•°æ®å¤§è§„æ¨¡ã€åˆ—è¯­ä¹‰ä¸å®Œæ•´å’Œå®ä½“æ­§ä¹‰ç­‰æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç¼–ç¨‹å¼è¡¨æ ¼æ¨ç†æ¡†æ¶â€”â€”TableReasonerã€‚</li>
<li>TableReasoneré€šè¿‡ç»“åˆç»“æ„æ€§å’Œè¯­ä¹‰è¡¨ç¤ºæ¥å»ºæ¨¡è¡¨æ ¼ã€‚</li>
<li>è®¾è®¡äº†å¤šæ­¥éª¤æ¶æ„é“¾æ¥è®¡åˆ’ä»¥æ¶ˆé™¤æ­§ä¹‰å¹¶å‡è½»è™šæ„ç°è±¡ã€‚</li>
<li>ç³»ç»Ÿæ•´åˆäº†æ¨ç†å·¥ä½œæµç¨‹åˆ°è¿­ä»£æ€ç»´æ¶æ„ä¸­ã€‚</li>
<li>ç³»ç»Ÿåœ¨SemEval-2025ä»»åŠ¡8çš„ä¸¤ä¸ªå­ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08046">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ed6f9cef647e5d17306d346e23766f3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84b027276622257cbbad259397535365.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b92a5b094c85be04beb2b6c4690d195a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2f9fe55850db7436cd2dc0cce84420e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-052a2e57efe44f48fb36ba362a2269f5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-deb63613156cc9184095838de1f94eef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4798e70373a01133feefb70e4cfd9460.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Measuring-AI-Alignment-with-Human-Flourishing"><a href="#Measuring-AI-Alignment-with-Human-Flourishing" class="headerlink" title="Measuring AI Alignment with Human Flourishing"></a>Measuring AI Alignment with Human Flourishing</h2><p><strong>Authors:Elizabeth Hilliard, Akshaya Jagadeesh, Alex Cook, Steele Billings, Nicholas Skytland, Alicia Llewellyn, Jackson Paull, Nathan Paull, Nolan Kurylo, Keatra Nesbitt, Robert Gruenewald, Anthony Jantzi, Omar Chavez</strong></p>
<p>This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72&#x2F;100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ç¹è£äººå·¥æ™ºèƒ½åŸºå‡†ï¼ˆFAIåŸºå‡†ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°äººå·¥æ™ºèƒ½ä¸äººç±»ç¹è£çš„å¥‘åˆç¨‹åº¦ï¼Œæ¶µç›–ä¸ƒä¸ªç»´åº¦ï¼šæ€§æ ¼ä¸ç¾å¾·ã€äº²å¯†ç¤¾ä¼šå…³ç³»ã€å¹¸ç¦ä¸ç”Ÿæ´»æ»¡æ„åº¦ã€æ„ä¹‰ä¸ç›®çš„ã€èº«å¿ƒå¥åº·ã€è´¢åŠ¡ä¸ç‰©è´¨ç¨³å®šã€ä¿¡ä»°ä¸çµæ€§ã€‚ä¸ä¼ ç»Ÿçš„ä¸“æ³¨äºæŠ€æœ¯èƒ½åŠ›æˆ–ä¼¤å®³é¢„é˜²çš„åŸºå‡†ä¸åŒï¼ŒFAIåŸºå‡†è¡¡é‡çš„æ˜¯äººå·¥æ™ºèƒ½åœ¨è¿™äº›ç»´åº¦ä¸Šå¦‚ä½•æœ‰æ•ˆåœ°ä¿ƒè¿›äººçš„ç¹è£ã€‚è¯¥åŸºå‡†é€šè¿‡ä¸€ç§ç»¼åˆæ–¹æ³•ï¼ˆåŒ…å«1229ä¸ªå®¢è§‚å’Œä¸»è§‚é—®é¢˜ï¼‰æ¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹AIç³»ç»Ÿå¦‚ä½•æœ‰æ•ˆåœ°ä¸å½“å‰çš„æ•´ä½“äººç±»ç¦ç¥‰ç ”ç©¶æ¨¡å‹ç›¸å»åˆã€‚ä½¿ç”¨ä¸“ä¸šçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè·¨ç»´åº¦è¯„ä¼°ï¼ŒFAIåŸºå‡†é‡‡ç”¨å‡ ä½•å‡å€¼è¯„åˆ†æ³•ï¼Œä»¥ç¡®ä¿åœ¨æ‰€æœ‰ç¹è£ç»´åº¦ä¸Šçš„å‡è¡¡è¡¨ç°ã€‚å¯¹28ç§é¢†å…ˆçš„è¯­è¨€æ¨¡å‹çš„åˆæ­¥æµ‹è¯•è¡¨æ˜ï¼Œå°½ç®¡ä¸€äº›æ¨¡å‹æ¥è¿‘æ•´ä½“å¯¹é½ï¼ˆå¾—åˆ†æœ€é«˜çš„æ¨¡å‹è¾¾åˆ°72&#x2F;100ï¼‰ï¼Œä½†æ²¡æœ‰æ¨¡å‹èƒ½åœ¨æ‰€æœ‰ç»´åº¦ä¸Šå®ç°å¯æ¥å—çš„å¥‘åˆåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¿¡ä»°ä¸çµæ€§ã€æ€§æ ¼ä¸ç¾å¾·ã€æ„ä¹‰ä¸ç›®çš„æ–¹é¢ã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘ç§¯ææ”¯æŒäººç±»ç¹è£çš„AIç³»ç»Ÿå»ºç«‹äº†æ¡†æ¶ï¼Œè€Œä¸æ˜¯ä»…ä»…é¿å…ä¼¤å®³ï¼Œå¯¹AIå¼€å‘ã€ä¼¦ç†å’Œè¯„ä¼°äº§ç”Ÿäº†é‡å¤§å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07787v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æ­¤è®ºæ–‡ä»‹ç»äº†ç¹è£äººå·¥æ™ºèƒ½åŸºå‡†ï¼ˆFAI Benchmarkï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°äººå·¥æ™ºèƒ½åœ¨ä¸ƒä¸ªç»´åº¦ä¸Šå¯¹äººç±»ç¹è£çš„å¥‘åˆåº¦ï¼šæ€§æ ¼ä¸ç¾å¾·ã€äº²å¯†ç¤¾ä¼šå…³ç³»ã€å¹¸ç¦ä¸ç”Ÿæ´»æ»¡æ„åº¦ã€æ„ä¹‰ä¸ç›®çš„ã€èº«å¿ƒå¥åº·ã€è´¢åŠ¡ä¸ç‰©è´¨ç¨³å®šã€ä¿¡ä»°ä¸çµæ€§ã€‚ä¸ä¼ ç»Ÿçš„ä»¥æŠ€æœ¯èƒ½åŠ›æˆ–ä¼¤å®³é¢„é˜²ä¸ºé‡ç‚¹çš„åŸºå‡†ä¸åŒï¼ŒFAI Benchmarkè¡¡é‡çš„æ˜¯äººå·¥æ™ºèƒ½æ¨¡å‹å¦‚ä½•æœ‰æ•ˆåœ°ä¿ƒè¿›ä¸ªäººåœ¨è¿™äº›ç»´åº¦ä¸Šçš„ç¹è£ã€‚è¯¥åŸºå‡†é€šè¿‡åŒ…å«1,229ä¸ªå®¢è§‚å’Œä¸»è§‚é—®é¢˜çš„ç»¼åˆæ–¹æ³•ï¼Œè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¦‚ä½•ä¸æ•´ä½“äººç±»ç¦ç¥‰çš„å½“å‰ç ”ç©¶æ¨¡å‹ç›¸å»åˆã€‚åˆæ­¥æµ‹è¯•æ˜¾ç¤ºï¼Œå°½ç®¡ä¸€äº›æ¨¡å‹æ¥è¿‘æ•´ä½“å¯¹é½ï¼ˆå¾—åˆ†æœ€é«˜çš„æ¨¡å‹è¾¾åˆ°72&#x2F;100ï¼‰ï¼Œä½†æ²¡æœ‰æ¨¡å‹åœ¨æ‰€æœ‰ç»´åº¦ä¸Šéƒ½èƒ½æ¥å—å¯¹é½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¿¡ä»°ä¸çµæ€§ã€æ€§æ ¼ä¸ç¾å¾·ä»¥åŠæ„ä¹‰ä¸ç›®çš„æ–¹é¢ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¼€å‘ç§¯ææ”¯æŒäººç±»ç¹è£è€Œéä»…ä»…é¿å…ä¼¤å®³çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿå»ºç«‹äº†åŸºå‡†ï¼Œå¯¹äººå·¥æ™ºèƒ½çš„å‘å±•ã€ä¼¦ç†å’Œè¯„ä¼°å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Flourishing AI Benchmarkï¼ˆFAI Benchmarkï¼‰æ˜¯ä¸€ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°AIå¦‚ä½•ä¿ƒè¿›äººç±»çš„å…¨é¢ç¹è£ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…å«ä¸ƒä¸ªå…³é”®ç»´åº¦ï¼Œæ¶µç›–æ€§æ ¼ä¸ç¾å¾·ã€äººé™…å…³ç³»ã€å¹¸ç¦ä¸æ»¡è¶³ã€æ„ä¹‰ä¸ç›®çš„ç­‰æ–¹é¢ã€‚</li>
<li>FAI Benchmarké‡‡ç”¨ç»¼åˆæ–¹æ³•è¯„ä¼°AIæ¨¡å‹çš„è¡¨ç°ï¼ŒåŒ…æ‹¬å¤§é‡å®¢è§‚å’Œä¸»è§‚é—®é¢˜ã€‚</li>
<li>åˆæ­¥æµ‹è¯•è¡¨æ˜ï¼Œå°½ç®¡æŸäº›AIæ¨¡å‹åœ¨æŸäº›ç»´åº¦ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†è¿˜æ²¡æœ‰æ¨¡å‹åœ¨æ‰€æœ‰ç»´åº¦ä¸Šéƒ½è¾¾åˆ°ç†æƒ³çš„å¯¹é½çŠ¶æ€ã€‚</li>
<li>åœ¨ä¿¡ä»°ä¸çµæ€§ã€æ€§æ ¼ä¸ç¾å¾·ä»¥åŠæ„ä¹‰ä¸ç›®çš„æ–¹é¢ï¼ŒAIæ¨¡å‹çš„å¯¹é½å°¤å…¶å­˜åœ¨é—®é¢˜ã€‚</li>
<li>æ­¤ç ”ç©¶å¼ºè°ƒäº†å¼€å‘æ”¯æŒäººç±»ç¹è£çš„AIç³»ç»Ÿçš„é‡è¦æ€§ï¼Œè€Œä¸ä»…ä»…æ˜¯é¿å…ä¼¤å®³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07787">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-81f3b28e7ed373df7f4a235debe96782.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Squeeze-the-Soaked-Sponge-Efficient-Off-policy-Reinforcement-Finetuning-for-Large-Language-Model"><a href="#Squeeze-the-Soaked-Sponge-Efficient-Off-policy-Reinforcement-Finetuning-for-Large-Language-Model" class="headerlink" title="Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning   for Large Language Model"></a>Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning   for Large Language Model</h2><p><strong>Authors:Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao</strong></p>
<p>Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%&#x2F;64.39% (for 7B model) with 0.007M&#x2F;0.011M response rollouts, 50&#x2F;75 training steps, on five math reasoning benchmarks (i.e., AIMEâ€™24, AMCâ€™23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç»æ˜¾ç¤ºå‡ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›çš„æ½œåŠ›ã€‚å¤§å¤šæ•°ç°æœ‰å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰æ–¹æ³•çš„ä¸€ä¸ªä¸»è¦å±€é™æ€§åœ¨äºå®ƒä»¬æœ¬è´¨ä¸Šæ˜¯åŸºäºæœ‰ç­–ç•¥å¼ºåŒ–å­¦ä¹ ï¼Œå³è¿‡å»å­¦ä¹ è¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ•°æ®æ²¡æœ‰å¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚è¿™ä¸å¯é¿å…åœ°éœ€è¦å·¨å¤§çš„è®¡ç®—å’Œæ—¶é—´çš„æŠ•å…¥ï¼Œæˆä¸ºç»æµé«˜æ•ˆæ‰©å±•çš„ä¸¥æ ¼ç“¶é¢ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼€å¯äº†ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„å¤å…´ï¼Œå¹¶æå‡ºäº†å†ç”Ÿçš„æ··åˆç­–ç•¥è¿‘ç«¯ç­–ç•¥æ¢¯åº¦ï¼ˆReMixï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨æ–¹æ³•ï¼Œä½¿åƒPPOå’ŒGRPOè¿™æ ·çš„åœ¨çº¿ç­–ç•¥RFTæ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨ç¦»çº¿ç­–ç•¥æ•°æ®ã€‚ReMixç”±ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†æ„æˆï¼šï¼ˆ1ï¼‰æ··åˆç­–ç•¥è¿‘ç«¯ç­–ç•¥æ¢¯åº¦ï¼Œé€šè¿‡å¢åŠ æ›´æ–°åˆ°æ•°æ®ï¼ˆUTDï¼‰æ¯”ç‡ä»¥å®ç°é«˜æ•ˆè®­ç»ƒï¼›ï¼ˆ2ï¼‰KL-å‡¸ç­–ç•¥çº¦æŸä»¥å¹³è¡¡ç¨³å®šæ€§å’Œçµæ´»æ€§çš„æƒè¡¡ï¼›ï¼ˆ3ï¼‰ç­–ç•¥å†ç”Ÿä»¥å®ç°ä»é«˜æ•ˆæ—©æœŸå­¦ä¹ åˆ°ç¨³å®šæ¸è¿›æ”¹è¿›çš„æ— ç¼è¿‡æ¸¡ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬åœ¨PPOã€GRPOå’ŒåŸºäº1.5Bã€7Bçš„æ¨¡å‹ä¸Šè®­ç»ƒäº†ä¸€ç³»åˆ—ReMixæ¨¡å‹ã€‚ReMixåœ¨äº”ä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆå³AIMEâ€™24ã€AMCâ€™23ã€Minervaã€OlympiadBenchå’ŒMATH500ï¼‰ä¸Šæ˜¾ç¤ºå‡ºå¹³å‡Pass@1å‡†ç¡®ç‡ä¸º52.1%ï¼ˆé’ˆå¯¹1.5Bæ¨¡å‹ï¼‰ï¼Œä½¿ç”¨0.079Må“åº”å›æ”¾ï¼Œè®­ç»ƒæ­¥éª¤ä¸º350æ­¥ï¼›å¯¹äº7Bæ¨¡å‹ï¼Œå‡†ç¡®ç‡ä¸º63.27%&#x2F;64.39%ï¼Œä½¿ç”¨åˆ†åˆ«ä¸º0.007Må’Œ0.011Mçš„å“åº”å›æ”¾ï¼Œè®­ç»ƒæ­¥éª¤ä¸º50æ­¥å’Œ75æ­¥ã€‚ä¸æœ€è¿‘çš„å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼ŒReMixå±•ç°å‡ºé¡¶å°–çš„æ€§èƒ½æ°´å¹³ï¼Œåœ¨å›æ”¾æ•°æ®é‡æ–¹é¢å°†è®­ç»ƒæˆæœ¬å‡å°‘äº†30å€è‡³450å€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å¤šæ–¹é¢çš„åˆ†ææ­ç¤ºäº†æ·±åˆ»çš„è§è§£ï¼ŒåŒ…æ‹¬ç¦»çº¿ç­–ç•¥å·®å¼‚çš„é­æ‰“æ•ˆåº”å¯¼è‡´çš„å¯¹è¾ƒçŸ­ç­”æ¡ˆçš„éšæ€§åå¥½ã€åœ¨ä¸¥é‡ç¦»çº¿ç­–ç•¥æƒ…å†µä¸‹è‡ªæˆ‘åæ€è¡Œä¸ºçš„å´©æºƒæ¨¡å¼ç­‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06892v3">PDF</a> Preliminary version, v3, added the missing name of x-axis in the left   part of Fig.1 and corrected a wrong number in Fig.3. Project page:   <a target="_blank" rel="noopener" href="https://anitaleungxx.github.io/ReMix">https://anitaleungxx.github.io/ReMix</a></p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚ç°æœ‰å¤§éƒ¨åˆ†å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œå› ä¸ºå®ƒä»¬æœ¬è´¨ä¸Šæ˜¯åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨è¿‡å»å­¦ä¹ è¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ•°æ®ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†æ··åˆç­–ç•¥çš„å¤å…´ï¼Œå¹¶æå‡ºäº†ReMixæ–¹æ³•ï¼Œä½¿PPOå’ŒGRPOç­‰åŸºäºç­–ç•¥çš„RFTæ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨éç­–ç•¥æ•°æ®ã€‚ReMixåŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šï¼ˆ1ï¼‰æ··åˆç­–ç•¥è¿‘ç«¯ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œé€šè¿‡æé«˜æ›´æ–°åˆ°æ•°æ®çš„æ¯”ä¾‹å®ç°é«˜æ•ˆè®­ç»ƒï¼›ï¼ˆ2ï¼‰KLæ•£åº¦å‡¸ç­–ç•¥çº¦æŸä»¥å®ç°ç¨³å®šæ€§å’Œçµæ´»æ€§ä¹‹é—´çš„å¹³è¡¡ï¼›ï¼ˆ3ï¼‰ç­–ç•¥é‡ç”Ÿæœºåˆ¶å®ç°ä»æ—©æœŸé«˜æ•ˆå­¦ä¹ åˆ°æŒç»­æ¸è¿›æ”¹è¿›çš„æ— ç¼è¿‡æ¸¡ã€‚å®éªŒè¡¨æ˜ï¼ŒReMixæ¨¡å‹åœ¨äº”ä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ¨¡å‹å¤§å¹…é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡å¤šå…ƒåˆ†ææ­ç¤ºäº†æœ‰è¶£çš„å‘ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æœ‰æœ›æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>å½“å‰å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œä¸»è¦åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨å†å²æ•°æ®ã€‚</li>
<li>ReMixæ–¹æ³•ç»“åˆäº†æ··åˆç­–ç•¥è¿‘ç«¯ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>ReMixåŒ…æ‹¬ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ··åˆç­–ç•¥ã€KLæ•£åº¦å‡¸ç­–ç•¥çº¦æŸå’Œç­–ç•¥é‡ç”Ÿæœºåˆ¶ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºReMixæ¨¡å‹åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å“è¶Šï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>ReMixæ¨¡å‹çš„è®­ç»ƒæˆæœ¬å¤§å¹…é™ä½ï¼Œè¾¾åˆ°30å€è‡³450å€çš„æ•°æ®å·é‡ç¼©å‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06892">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-793a64bd79f1efa6407e41e34e1a101d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92edb873573c38ef0a70e10e297ca239.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Gemini-2-5-Pushing-the-Frontier-with-Advanced-Reasoning-Multimodality-Long-Context-and-Next-Generation-Agentic-Capabilities"><a href="#Gemini-2-5-Pushing-the-Frontier-with-Advanced-Reasoning-Multimodality-Long-Context-and-Next-Generation-Agentic-Capabilities" class="headerlink" title="Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality,   Long Context, and Next Generation Agentic Capabilities"></a>Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality,   Long Context, and Next Generation Agentic Capabilities</h2><p><strong>Authors:Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, IlaÃ¯ Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre RamÃ©, Sagar Waghmare, Helen Miller, Vaishakh Keshava, Ying Jian, Xiaofan Zhang, Raluca Ada Popa, Kedar Dhamdhere, BlaÅ¾ BrataniÄ, Kyuyeun Kim, Terry Koo, Ferran Alet, Yi-ting Chen, Arsha Nagrani, Hannah Muckenhirn, Zhiyuan Zhang, Corbin Quick, Filip PavetiÄ‡, Duc Dung Nguyen, Joao Carreira, Michael Elabd, Haroon Qureshi, Fabian Mentzer, Yao-Yuan Yang, Danielle Eisenbud, Anmol Gulati, Ellie Talius, Eric Ni, Sahra Ghalebikesabi, Edouard Yvinec, Alaa Saade, Thatcher Ulrich, Lorenzo Blanco, Dan A. Calian, Muhuan Huang, AÃ¤ron van den Oord, Naman Goyal, Terry Chen, Praynaa Rawlani, Christian Schallhart, Swachhand Lokhande, Xianghong Luo, Jyn Shan, Ceslee Montgomery, Victoria Krakovna, Federico Piccinini, Omer Barak, Jingyu Cui, Yiling Jia, Mikhail Dektiarev, Alexey Kolganov, Shiyu Huang, Zhe Chen, Xingyu Wang, Jessica Austin, Peter de Boursac, Evgeny Sluzhaev, Frank Ding, Huijian Li, Surya Bhupatiraju, Mohit Agarwal, SÅ‚awek Kwasiborski, Paramjit Sandhu, Patrick Siegler, Ahmet Iscen, Eyal Ben-David, Shiraz Butt, Miltos Allamanis, Seth Benjamin, Robert Busa-Fekete, Felix Hernandez-Campos, Sasha Goldshtein, Matt Dibb, Weiyang Zhang, Annie Marsden, Carey Radebaugh, Stephen Roller, Abhishek Nayyar, Jacob Austin, Tayfun Terzi, Bhargav Kanagal Shamanna, Pete Shaw, Aayush Singh, Florian Luisier, Artur MendonÃ§a, Vaibhav Aggarwal, Larisa Markeeva, Claudio Fantacci, Sergey Brin, HyunJeong Choe, Guanyu Wang, Hartwig Adam, Avigail Dabush, Tatsuya Kiyono, Eyal Marcus, Jeremy Cole, Theophane Weber, Hongrae Lee, Ronny Huang, Alex Muzio, Leandro Kieliger, Maigo Le, Courtney Biles, Long Le, Archit Sharma, Chengrun Yang, Avery Lamp, Dave Dopson, Nate Hurley, Katrina Xinyi Xu, Zhihao Shan, Shuang Song, Jiewen Tan, Alexandre Senges, George Zhang, Chong You, Yennie Jun, David Raposo, Susanna Ricco, Xuan Yang, Weijie Chen, Prakhar Gupta, Arthur Szlam, Kevin Villela, Chun-Sung Ferng, Daniel Kasenberg, Chen Liang, Rui Zhu, Arunachalam Narayanaswamy, Florence Perot, Paul Pucciarelli, Anna Shekhawat, Alexey Stern, Rishikesh Ingale, Stefani Karp, Sanaz Bahargam, Adrian Goedeckemeyer, Jie Han, Sicheng Li, Andrea Tacchetti, Dian Yu, Abhishek Chakladar, Zhiying Zhang, Mona El Mahdy, Xu Gao, Dale Johnson, Samrat Phatale, AJ Piergiovanni, Hyeontaek Lim, Clement Farabet, Carl Lebsack, Theo Guidroz, John Blitzer, Nico Duduta, David Madras, Steve Li, Daniel von Dincklage, Xin Li, Mahdis Mahdieh, George Tucker, Ganesh Jawahar, Owen Xiao, Danny Tarlow, Robert Geirhos, Noam Velan, Daniel Vlasic, Kalesha Bullard, SK Park, Nishesh Gupta, Kellie Webster, Ayal Hitron, Jieming Mao, Julian Eisenschlos, Laurel Prince, Nina Dâ€™Souza, Kelvin Zheng, Sara Nasso, Gabriela Botea, Carl Doersch, Caglar Unlu, Chris Alberti, Alexey Svyatkovskiy, Ankita Goel, Krzysztof Choromanski, Pan-Pan Jiang, Richard Nguyen, Four Flynn, Daria Ä†urko, Peter Chen, Nicholas Roth, Kieran Milan, Caleb Habtegebriel, Shashi Narayan, Michael Moffitt, Jake Marcus, Thomas Anthony, Brendan McMahan, Gowoon Cheon, Ruibo Liu, Megan Barnes, Lukasz Lew, Rebeca Santamaria-Fernandez, Mayank Upadhyay, Arjun Akula, Arnar Mar Hrafnkelsson, Alvaro Caceres, Andrew Bunner, Michal Sokolik, Subha Puttagunta, Lawrence Moore, Berivan Isik, Jay Hartford, Lawrence Chan, Pradeep Shenoy, Dan Holtmann-Rice, Jane Park, Fabio Viola, Alex Salcianu, Sujeevan Rajayogam, Ian Stewart-Binks, Zelin Wu, Richard Everett, Xi Xiong, Pierre-Antoine Manzagol, Gary Leung, Carl Saroufim, Bo Pang, Dawid Wegner, George Papamakarios, Jennimaria Palomaki, Helena Pankov, Guangda Lai, Guilherme Tubone, Shubin Zhao, Theofilos Strinopoulos, Seth Neel, Mingqiu Wang, Joe Kelley, Li Li, Pingmei Xu, Anitha Vijayakumar, Andrea Dâ€™olimpio, Omer Levy, Massimo Nicosia, Grigory Rozhdestvenskiy, Ni Lao, Sirui Xie, Yash Katariya, Jon Simon, Sanjiv Kumar, Florian Hartmann, Michael Kilgore, Jinhyuk Lee, Aroma Mahendru, Roman Ring, Tom Hennigan, Fiona Lang, Colin Cherry, David Steiner, Dawsen Hwang, Ray Smith, Pidong Wang, Jeremy Chen, Ming-Hsuan Yang, Sam Kwei, Philippe Schlattner, Donnie Kim, Ganesh Poomal Girirajan, Nikola Momchev, Ayushi Agarwal, Xingyi Zhou, Ilkin Safarli, Zachary Garrett, AJ Pierigiovanni, Sarthak Jauhari, Alif Raditya Rochman, Shikhar Vashishth, Quan Yuan, Christof Angermueller, Jon Blanton, Xinying Song, Nitesh Bharadwaj Gundavarapu, Thi Avrahami, Maxine Deines, Subhrajit Roy, Manish Gupta, Christopher Semturs, Shobha Vasudevan, Aditya Srikanth Veerubhotla, Shriya Sharma, Josh Jacob, Zhen Yang, Andreas Terzis, Dan Karliner, Auriel Wright, Tania Rojas-Esponda, Ashley Brown, Abhijit Guha Roy, Pawan Dogra, Andrei Kapishnikov, Peter Young, Wendy Kan, Vinodh Kumar Rajendran, Maria Ivanova, Salil Deshmukh, Chia-Hua Ho, Mike Kwong, Stav Ginzburg, Annie Louis, KP Sawhney, Slav Petrov, Jing Xie, Yunfei Bai, Georgi Stoyanov, Alex Fabrikant, Rajesh Jayaram, Yuqi Li, Joe Heyward, Justin Gilmer, Yaqing Wang, Radu Soricut, Luyang Liu, Qingnan Duan, Jamie Hayes, Maura Oâ€™Brien, Gaurav Singh Tomar, Sivan Eiger, Bahar Fatemi, Jeffrey Hui, Catarina Barros, Adaeze Chukwuka, Alena Butryna, Saksham Thakur, Austin Huang, Zhufeng Pan, Haotian Tang, Serkan Cabi, Tulsee Doshi, Michiel Bakker, Sumit Bagri, Ruy Ley-Wild, Adam Lelkes, Jennie Lees, Patrick Kane, David Greene, Shimu Wu, JÃ¶rg Bornschein, Gabriela Surita, Sarah Hodkinson, Fangtao Li, Chris Hidey, SÃ©bastien Pereira, Sean Ammirati, Phillip Lippe, Adam Kraft, Pu Han, Sebastian Gerlach, Zifeng Wang, Liviu Panait, Feng Han, Brian Farris, Yingying Bi, Hannah DeBalsi, Miaosen Wang, Gladys Tyen, James Cohan, Susan Zhang, Jarred Barber, Da-Woon Chung, Jaeyoun Kim, Markus Kunesch, Steven Pecht, Nami Akazawa, Abe Friesen, James Lyon, Ali Eslami, Junru Wu, Jie Tan, Yue Song, Ravi Kumar, Chris Welty, Ilia Akolzin, Gena Gibson, Sean Augenstein, Arjun Pillai, Nancy Yuen, Du Phan, Xin Wang, Iain Barr, Heiga Zen, Nan Hua, Casper Liu, Jilei Jerry Wang, Tanuj Bhatia, Hao Xu, Oded Elyada, Pushmeet Kohli, Mirek OlÅ¡Ã¡k, Ke Chen, Azalia Mirhoseini, Noam Shazeer, Shoshana Jakobovits, Maggie Tran, Nolan Ramsden, Tarun Bharti, Fred Alcober, Yunjie Li, Shilpa Shetty, Jing Chen, Dmitry Kalashnikov, Megha Nawhal, Sercan Arik, Hanwen Chen, Michiel Blokzijl, Shubham Gupta, James Rubin, Rigel Swavely, Sophie Bridgers, Ian Gemp, Chen Su, Arun Suggala, Juliette Pluto, Mary Cassin, Alain Vaucher, Kaiyang Ji, Jiahao Cai, Andrew Audibert, Animesh Sinha, David Tian, Efrat Farkash, Amy Hua, Jilin Chen, Duc-Hieu Tran, Edward Loper, Nicole Brichtova, Lara McConnaughey, Ballie Sandhu, Robert Leland, Doug DeCarlo, Andrew Over, James Huang, Xing Wu, Connie Fan, Eric Li, Yun Lei, Deepak Sharma, Cosmin Paduraru, Luo Yu, Matko BoÅ¡njak, Phuong Dao, Min Choi, Sneha Kudugunta, Jakub Adamek, Carlos GuÃ­a, Ali Khodaei, Jie Feng, Wenjun Zeng, David Welling, Sandeep Tata, Christina Butterfield, Andrey Vlasov, Seliem El-Sayed, Swaroop Mishra, Tara Sainath, Shentao Yang, RJ Skerry-Ryan, Jeremy Shar, Robert Berry, Arunkumar Rajendran, Arun Kandoor, Andrea Burns, Deepali Jain, Tom Stone, Wonpyo Park, Shibo Wang, Albin Cassirer, Guohui Wang, Hayato Kobayashi, Sergey Rogulenko, Vineetha Govindaraj, MikoÅ‚aj RybiÅ„ski, Nadav Olmert, Colin Evans, Po-Sen Huang, Kelvin Xu, Premal Shah, Terry Thurk, Caitlin Sikora, Mu Cai, Jin Xie, Elahe Dabir, Saloni Shah, Norbert Kalb, Carrie Zhang, Shruthi Prabhakara, Amit Sabne, Artiom Myaskovsky, Vikas Raunak, Blanca Huergo, Behnam Neyshabur, Jon Clark, Ye Zhang, Shankar Krishnan, Eden Cohen, Dinesh Tewari, James Lottes, Yumeya Yamamori, Hui Elena Li, Mohamed Elhawaty, Ada Maksutaj Oflazer, AdriÃ  Recasens, Sheryl Luo, Duy Nguyen, Taylor Bos, Kalyan Andra, Ana Salazar, Ed Chi, Jeongwoo Ko, Matt Ginsberg, Anders Andreassen, Anian Ruoss, Todor Davchev, Elnaz Davoodi, Chenxi Liu, Min Kim, Santiago Ontanon, Chi Ming To, Dawei Jia, Rosemary Ke, Jing Wang, Anna Korsun, Moran Ambar, Ilya Kornakov, Irene Giannoumis, Toni Creswell, Denny Zhou, Yi Su, Ishaan Watts, Aleksandr Zaks, Evgenii Eltyshev, Ziqiang Feng, Sidharth Mudgal, Alex Kaskasoli, Juliette Love, Kingshuk Dasgupta, Sam Shleifer, Richard Green, Sungyong Seo, Chansoo Lee, Dale Webster, Prakash Shroff, Ganna Raboshchuk, Isabel Leal, James Manyika, Sofia Erell, Daniel Murphy, Zhisheng Xiao, Anton Bulyenov, Julian Walker, Mark Collier, Matej Kastelic, Nelson George, Sushant Prakash, Sailesh Sidhwani, Alexey Frolov, Steven Hansen, Petko Georgiev, Tiberiu Sosea, Chris Apps, Aishwarya Kamath, David Reid, Emma Cooney, Charlotte Magister, Oriana Riva, Alec Go, Pu-Chin Chen, Sebastian Krause, Nir Levine, Marco Fornoni, Ilya Figotin, Nick Roy, Parsa Mahmoudieh, Vladimir Magay, Mukundan Madhavan, Jin Miao, Jianmo Ni, Yasuhisa Fujii, Ian Chou, George Scrivener, Zak Tsai, Siobhan Mcloughlin, Jeremy Selier, Sandra Lefdal, Jeffrey Zhao, Abhijit Karmarkar, Kushal Chauhan, Shivanker Goel, Zhaoyi Zhang, Vihan Jain, Parisa Haghani, Mostafa Dehghani, Jacob Scott, Erin Farnese, Anastasija IliÄ‡, Steven Baker, Julia Pawar, Li Zhong, Josh Camp, Yoel Zeldes, Shravya Shetty, Anand Iyer, VÃ­t ListÃ­k, Jiaxian Guo, Luming Tang, Mark Geller, Simon Bucher, Yifan Ding, Hongzhi Shi, Carrie Muir, Dominik Grewe, Ramy Eskander, Octavio Ponce, Boqing Gong, Derek Gasaway, Samira Khan, Umang Gupta, Angelos Filos, Weicheng Kuo, Klemen Kloboves, Jennifer Beattie, Christian Wright, Leon Li, Alicia Jin, Sandeep Mariserla, Miteyan Patel, Jens Heitkaemper, Dilip Krishnan, Vivek Sharma, David Bieber, Christian Frank, John Lambert, Paul Caron, Martin Polacek, Mai GimÃ©nez, Himadri Choudhury, Xing Yu, Sasan Tavakkol, Arun Ahuja, Franz Och, Rodolphe Jenatton, Wojtek Skut, Bryan Richter, David Gaddy, Andy Ly, Misha Bilenko, Megh Umekar, Ethan Liang, Martin Sevenich, Mandar Joshi, Hassan Mansoor, Rebecca Lin, Sumit Sanghai, Abhimanyu Singh, Xiaowei Li, Sudheendra Vijayanarasimhan, Zaheer Abbas, Yonatan Bitton, Hansa Srinivasan, Manish Reddy Vuyyuru, Alexander FrÃ¶mmgen, Yanhua Sun, Ralph Leith, Alfonso CastaÃ±o, DJ Strouse, Le Yan, Austin Kyker, Satish Kambala, Mary Jasarevic, Thibault Sellam, Chao Jia, Alexander Pritzel, Raghavender R, Huizhong Chen, Natalie Clay, Sudeep Gandhe, Sean Kirmani, Sayna Ebrahimi, Hannah Kirkwood, Jonathan Mallinson, Chao Wang, Adnan Ozturel, Kuo Lin, Shyam Upadhyay, Vincent Cohen-Addad, Sean Purser-haskell, Yichong Xu, Ebrahim Songhori, Babi Seal, Alberto Magni, Almog Gueta, Tingting Zou, Guru Guruganesh, Thais Kagohara, Hung Nguyen, Khalid Salama, Alejandro Cruzado Ruiz, Justin Frye, Zhenkai Zhu, Matthias Lochbrunner, Simon Osindero, Wentao Yuan, Lisa Lee, Aman Prasad, Lam Nguyen Thiet, Daniele Calandriello, Victor Stone, Qixuan Feng, Han Ke, Maria Voitovich, Geta Sampemane, Lewis Chiang, Ling Wu, Alexander Bykovsky, Matt Young, Luke Vilnis, Ishita Dasgupta, Aditya Chawla, Qin Cao, Bowen Liang, Daniel Toyama, Szabolcs Payrits, Anca Stefanoiu, Dimitrios Vytiniotis, Ankesh Anand, Tianxiao Shen, Blagoj Mitrevski, Michael Tschannen, Sreenivas Gollapudi, Aishwarya P S, JosÃ© Leal, Zhe Shen, Han Fu, Wei Wang, Arvind Kannan, Doron Kukliansky, Sergey Yaroshenko, Svetlana Grant, Umesh Telang, David Wood, Alexandra Chronopoulou, Alexandru Å¢ifrea, Tao Zhou, Tony Tu&#39;Ã¢n Nguy~Ãªn, Muge Ersoy, Anima Singh, Meiyan Xie, Emanuel Taropa, Woohyun Han, Eirikur Agustsson, Andrei Sozanschi, Hui Peng, Alex Chen, Yoel Drori, Efren Robles, Yang Gao, Xerxes Dotiwalla, Ying Chen, Anudhyan Boral, Alexei Bendebury, John Nham, Chris Tar, Luis Castro, Jiepu Jiang, Canoee Liu, Felix Halim, Jinoo Baek, Andy Wan, Jeremiah Liu, Yuan Cao, Shengyang Dai, Trilok Acharya, Ruoxi Sun, Fuzhao Xue, Saket Joshi, Morgane Lustman, Yongqin Xian, Rishabh Joshi, Deep Karkhanis, Nora Kassner, Jamie Hall, Xiangzhuo Ding, Gan Song, Gang Li, Chen Zhu, Yana Kulizhskaya, Bin Ni, Alexey Vlaskin, Solomon Demmessie, Lucio Dery, Salah Zaiem, Yanping Huang, Cindy Fan, Felix Gimeno, Ananth Balashankar, Koji Kojima, Hagai Taitelbaum, Maya Meng, Dero Gharibian, Sahil Singla, Wei Chen, Ambrose Slone, Guanjie Chen, Sujee Rajayogam, Max Schumacher, Suyog Kotecha, Rory Blevins, Qifei Wang, Mor Hazan Taege, Alex Morris, Xin Liu, Fayaz Jamil, Richard Zhang, Pratik Joshi, Ben Ingram, Tyler Liechty, Ahmed Eleryan, Scott Baird, Alex Grills, Gagan Bansal, Shan Han, Kiran Yalasangi, Shawn Xu, Majd Al Merey, Isabel Gao, Felix Weissenberger, Igor Karpov, Robert Riachi, Ankit Anand, Gautam Prasad, Kay Lamerigts, Reid Hayes, Jamie Rogers, Mandy Guo, Ashish Shenoy, Qiong Q Hu, Kyle He, Yuchen Liu, Polina Zablotskaia, Sagar Gubbi, Yifan Chang, Jay Pavagadhi, Kristian Kjems, Archita Vadali, Diego Machado, Yeqing Li, Renshen Wang, Dipankar Ghosh, Aahil Mehta, Dana Alon, George Polovets, Alessio Tonioni, Nate Kushman, Joel Dâ€™sa, Lin Zhuo, Allen Wu, Rohin Shah, John Youssef, Jiayu Ye, Justin Snyder, Karel Lenc, Senaka Buthpitiya, Matthew Tung, Jichuan Chang, Tao Chen, David Saxton, Jenny Lee, Lydia Lihui Zhang, James Qin, Prabakar Radhakrishnan, Maxwell Chen, Piotr Ambroszczyk, Metin Toksoz-Exley, Yan Zhong, Nitzan Katz, Brendan Oâ€™Donoghue, Tamara von Glehn, Adi Gerzi Rosenthal, Aga Åšwietlik, Xiaokai Zhao, Nick Fernando, Jinliang Wei, Jieru Mei, Sergei Vassilvitskii, Diego Cedillo, Pranjal Awasthi, Hui Zheng, Koray Kavukcuoglu, Itay Laish, Joseph Pagadora, Marc Brockschmidt, Christopher A. Choquette-Choo, Arunkumar Byravan, Yifeng Lu, Xu Chen, Mia Chen, Kenton Lee, Rama Pasumarthi, Sijal Bhatnagar, Aditya Shah, Qiyin Wu, Zhuoyuan Chen, Zack Nado, Bartek Perz, Zixuan Jiang, David Kao, Ganesh Mallya, Nino Vieillard, Lantao Mei, Sertan Girgin, Mandy Jordan, Yeongil Ko, Alekh Agarwal, Yaxin Liu, Yasemin Altun, Raoul de Liedekerke, Anastasios Kementsietsidis, Daiyi Peng, Dangyi Liu, Utku Evci, Peter Humphreys, Austin Tarango, Xiang Deng, Yoad Lewenberg, Kevin Aydin, Chengda Wu, Bhavishya Mittal, Tsendsuren Munkhdalai, Kleopatra Chatziprimou, Rodrigo Benenson, Uri First, Xiao Ma, Jinning Li, Armand Joulin, Hamish Tomlinson, Tingnan Zhang, Milad Nasr, Zhi Hong, MichaÃ«l Sander, Lisa Anne Hendricks, Anuj Sharma, Andrew Bolt, Eszter VÃ©rtes, Jiri Simsa, Tomer Levinboim, Olcan Sercinoglu, Divyansh Shukla, Austin Wu, Craig Swanson, Danny Vainstein, Fan Bu, Bo Wang, Ryan Julian, Charles Yoon, Sergei Lebedev, Antonious Girgis, Bernd Bandemer, David Du, Todd Wang, Xi Chen, Ying Xiao, Peggy Lu, Natalie Ha, Vlad Ionescu, Simon Rowe, Josip Matak, Federico Lebron, Andreas Steiner, Lalit Jain, Manaal Faruqui, Nicolas Lacasse, Georgie Evans, Neesha Subramaniam, Dean Reich, Giulia Vezzani, Aditya Pandey, Joe Stanton, Tianhao Zhou, Liam McCafferty, Henry Griffiths, Verena Rieser, Soheil Hassas Yeganeh, Eleftheria Briakou, Lu Huang, Zichuan Wei, Liangchen Luo, Erik Jue, Gabby Wang, Victor Cotruta, Myriam Khan, Jongbin Park, Qiuchen Guo, Peiran Li, Rong Rong, Diego Antognini, Anastasia Petrushkina, Chetan Tekur, Eli Collins, Parul Bhatia, Chester Kwak, Wenhu Chen, Arvind Neelakantan, Immanuel Odisho, Sheng Peng, Vincent Nallatamby, Vaibhav Tulsyan, Fabian Pedregosa, Peng Xu, Raymond Lin, Yulong Wang, Emma Wang, Sholto Douglas, Reut Tsarfaty, Elena Gribovskaya, Renga Aravamudhan, Manu Agarwal, Mara Finkelstein, Qiao Zhang, Elizabeth Cole, Phil Crone, Sarmishta Velury, Anil Das, Chris Sauer, Luyao Xu, Danfeng Qin, Chenjie Gu, Dror Marcus, CJ Zheng, Wouter Van Gansbeke, Sobhan Miryoosefi, Haitian Sun, YaGuang Li, Charlie Chen, Jae Yoo, Pavel Dubov, Alex Tomala, Adams Yu, PaweÅ‚ WesoÅ‚owski, Alok Gunjan, Eddie Cao, Jiaming Luo, Nikhil Sethi, Arkadiusz Socala, Laura Graesser, Tomas Kocisky, Arturo BC, Minmin Chen, Edward Lee, Sophie Wang, Weize Kong, Qiantong Xu, Nilesh Tripuraneni, Yiming Li, Xinxin Yu, Allen Porter, Paul Voigtlaender, Biao Zhang, Arpi Vezer, Sarah York, Qing Wei, Geoffrey Cideron, Mark Kurzeja, Seungyeon Kim, Benny Li, AngÃ©line Pouget, Hyo Lee, Kaspar Daugaard, Yang Li, Dave Uthus, Aditya Siddhant, Paul Cavallaro, Sriram Ganapathy, Maulik Shah, Rolf Jagerman, Jeff Stanway, Piermaria Mendolicchio, Li Xiao, Kayi Lee, Tara Thompson, Shubham Milind Phal, Jason Chase, Sun Jae Lee, Adrian N Reyes, Disha Shrivastava, Zhen Qin, Roykrong Sukkerd, Seth Odoom, Lior Madmoni, John Aslanides, Jonathan Herzig, Elena Pochernina, Sheng Zhang, Parker Barnes, Daisuke Ikeda, Qiujia Li, Shuo-yiin Chang, Shakir Mohamed, Jim Sproch, Richard Powell, Bidisha Samanta, Domagoj Ä†evid, Anton Kovsharov, Shrestha Basu Mallick, Srinivas Tadepalli, Anne Zheng, Kareem Ayoub, Andreas Noever, Christian Reisswig, Zhuo Xu, Junhyuk Oh, Martin Matysiak, Tim Blyth, Shereen Ashraf, Julien Amelot, Boone Severson, Michele Bevilacqua, Motoki Sano, Ethan Dyer, Ofir Roval, Anu Sinha, Yin Zhong, Sagi Perel, Tea SaboliÄ‡, Johannes Mauerer, Willi Gierke, Mauro Verzetti, Rodrigo Cabrera, Alvin Abdagic, Steven Hemingray, Austin Stone, Jong Lee, Farooq Ahmad, Karthik Raman, Lior Shani, Jonathan Lai, Orhan Firat, Nathan Waters, Eric Ge, Mo Shomrat, Himanshu Gupta, Rajeev Aggarwal, Tom Hudson, Bill Jia, Simon Baumgartner, Palak Jain, Joe Kovac, Junehyuk Jung, Ante Å½uÅ¾ul, Will Truong, Morteza Zadimoghaddam, Songyou Peng, Marco Liang, Rachel Sterneck, Balaji Lakshminarayanan, Machel Reid, Oliver Woodman, Tong Zhou, Jianling Wang, Vincent Coriou, Arjun Narayanan, Jay Hoover, Yenai Ma, Apoorv Jindal, Clayton Sanford, Doug Reid, Swaroop Ramaswamy, Alex Kurakin, Roland Zimmermann, Yana Lunts, Dragos Dena, ZalÃ¡n Borsos, Vered Cohen, Shujian Zhang, Will Grathwohl, Robert Dadashi, Morgan Redshaw, Joshua Kessinger, Julian Odell, Silvano Bonacina, Zihang Dai, Grace Chen, Ayush Dubey, Pablo Sprechmann, Mantas Pajarskas, Wenxuan Zhou, Niharika Ahuja, Tara Thomas, Martin Nikoltchev, Matija Kecman, Bharath Mankalale, Andrey Ryabtsev, Jennifer She, Christian Walder, Jiaming Shen, Lu Li, Carolina Parada, Sheena Panthaplackel, Okwan Kwon, Matt Lawlor, Utsav Prabhu, Yannick Schroecker, Marcâ€™aurelio Ranzato, Pete Blois, Iurii Kemaev, Ting Yu, Dmitry Lepikhin, Hao Xiong, Sahand Sharifzadeh, Oleaser Johnson, Jeremiah Willcock, Rui Yao, Greg Farquhar, Sujoy Basu, Hidetoshi Shimokawa, Nina Anderson, Haiguang Li, Khiem Pham, Yizhong Liang, Sebastian Borgeaud, Alexandre Moufarek, Hideto Kazawa, Blair Kutzman, Marcin Sieniek, Sara Smoot, Ruth Wang, Natalie Axelsson, Nova Fallen, Prasha Sundaram, Yuexiang Zhai, Varun Godbole, Petros Maniatis, Alek Wang, Ilia Shumailov, Santhosh Thangaraj, Remi Crocker, Nikita Gupta, Gang Wu, Phil Chen, GellÃ©rt Weisz, Celine Smith, Mojtaba Seyedhosseini, Boya Fang, Xiyang Luo, Roey Yogev, Zeynep Cankara, Andrew Hard, Helen Ran, Rahul Sukthankar, George Necula, GaÃ«l Liu, Honglong Cai, Praseem Banzal, Daniel Keysers, Sanjay Ghemawat, Connie Tao, Emma Dunleavy, Aditi Chaudhary, Wei Li, Maciej MikuÅ‚a, Chen-Yu Lee, Tiziana Refice, Krishna Somandepalli, Alexandre FrÃ©chette, Dan Bahir, John Karro, Keith Rush, Sarah Perrin, Bill Rosgen, Xiaomeng Yang, Clara Huiyi Hu, Mahmoud Alnahlawi, Justin Mao-Jones, Roopal Garg, Hoang Nguyen, Bat-Orgil Batsaikhan, IÃ±aki Iturrate, Anselm Levskaya, Avi Singh, Ashyana Kachra, Tony Lu, Denis Petek, Zheng Xu, Mark Graham, Lukas Zilka, Yael Karov, Marija Kostelac, Fangyu Liu, Yaohui Guo, Weiyue Wang, Bernd Bohnet, Emily Pitler, Tony Bruguier, Keisuke Kinoshita, Chrysovalantis Anastasiou, Nilpa Jha, Ting Liu, Jerome Connor, Phil Wallis, Philip Pham, Eric Bailey, Shixin Li, Heng-Tze Cheng, Sally Ma, Haiqiong Li, Akanksha Maurya, Kate Olszewska, Manfred Warmuth, Christy Koh, Dominik Paulus, Siddhartha Reddy Jonnalagadda, Enrique Piqueras, Ali Elqursh, Geoff Brown, Hadar Shemtov, Loren Maggiore, Fei Xia, Ryan Foley, Beka Westberg, George van den Driessche, Livio Baldini Soares, Arjun Kar, Michael Quinn, Siqi Zuo, Jialin Wu, Kyle Kastner, Anna Bortsova, Aijun Bai, Ales Mikhalap, Luowei Zhou, Jennifer Brennan, Vinay Ramasesh, Honglei Zhuang, John Maggs, Johan Schalkwyk, Yuntao Xu, Hui Huang, Andrew Howard, Sasha Brown, Linting Xue, Gloria Shen, Brian Albert, Neha Jha, Daniel Zheng, Varvara Krayvanova, Spurthi Amba Hombaiah, Olivier Lacombe, Gautam Vasudevan, Dan Graur, Tian Xie, Meet Gandhi, Bangju Wang, Dustin Zelle, Harman Singh, Dahun Kim, SÃ©bastien Cevey, Victor Ungureanu, Natasha Noy, Fei Liu, Annie Xie, Fangxiaoyu Feng, Katerina Tsihlas, Daniel Formoso, Neera Vats, Quentin Wellens, Yinan Wang, Niket Kumar Bhumihar, Samrat Ghosh, Matt Hoffman, Tom Lieber, Oran Lang, Kush Bhatia, Tom Paine, Aroonalok Pyne, Ronny Votel, Madeleine Clare Elish, Benoit Schillings, Alex Panagopoulos, Haichuan Yang, Adam Raveret, Zohar Yahav, Shuang Liu, Dalia El Badawy, Nishant Agrawal, Mohammed Badawi, Mahdi Mirzazadeh, Carla Bromberg, Fan Ye, Chang Liu, Tatiana Sholokhova, George-Cristian Muraru, Gargi Balasubramaniam, Jonathan Malmaud, Alen Carin, Danilo Martins, Irina Jurenka, Pankil Botadra, Dave Lacey, Richa Singh, Mariano Schain, Dan Zheng, Isabelle Guyon, Victor Lavrenko, Seungji Lee, Xiang Zhou, Demis Hassabis, Jeshwanth Challagundla, Derek Cheng, Nikhil Mehta, Matthew Mauger, Michela Paganini, Pushkar Mishra, Kate Lee, Zhang Li, Lexi Baugher, Ondrej Skopek, Max Chang, Amir Zait, Gaurav Menghani, Lizzetth Bellot, Guangxing Han, Jean-Michel Sarr, Sharat Chikkerur, Himanshu Sahni, Rohan Anil, Arun Narayanan, Chandu Thekkath, Daniele Pighin, Hana StrejÄek, Marko Velic, Fred Bertsch, Manuel Tragut, Keran Rong, Alicia Parrish, Kai Bailey, Jiho Park, Isabela Albuquerque, Abhishek Bapna, Rajesh Venkataraman, Alec Kosik, Johannes Griesser, Zhiwei Deng, Alek Andreev, Qingyun Dou, Kevin Hui, Fanny Wei, Xiaobin Yu, Lei Shu, Avia Aharon, David Barker, Badih Ghazi, Sebastian Flennerhag, Chris Breaux, Yuchuan Liu, Matthew Bilotti, Josh Woodward, Uri Alon, Stephanie Winkler, Tzu-Kuo Huang, Kostas Andriopoulos, JoÃ£o Gabriel Oliveira, Penporn Koanantakool, Berkin Akin, Michael Wunder, Cicero Nogueira dos Santos, Mohammad Hossein Bateni, Lin Yang, Dan Horgan, Beer Changpinyo, Keyvan Amiri, Min Ma, Dayeong Lee, Lihao Liang, Anirudh Baddepudi, Tejasi Latkar, Raia Hadsell, Jun Xu, Hairong Mu, Michael Han, Aedan Pope, Snchit Grover, Frank Kim, Ankit Bhagatwala, Guan Sun, Yamini Bansal, Amir Globerson, Alireza Nazari, Samira Daruki, Hagen Soltau, Jane Labanowski, Laurent El Shafey, Matt Harvey, Yanif Ahmad, Elan Rosenfeld, William Kong, Etienne Pot, Yi-Xuan Tan, Aurora Wei, Victoria Langston, Marcel Prasetya, Petar VeliÄkoviÄ‡, Richard Killam, Robin Strudel, Darren Ni, Zhenhai Zhu, Aaron Archer, Kavya Kopparapu, Lynn Nguyen, Emilio Parisotto, Hussain Masoom, Sravanti Addepalli, Jordan Grimstad, Hexiang Hu, Joss Moore, Avinatan Hassidim, Le Hou, Mukund Raghavachari, Jared Lichtarge, Adam R. Brown, Hilal Dib, Natalia Ponomareva, Justin Fu, Yujing Zhang, Altaf Rahman, Joana Iljazi, Edouard Leurent, Gabriel Dulac-Arnold, Cosmo Du, Chulayuth Asawaroengchai, Larry Jin, Ela Gruzewska, Ziwei Ji, Benigno Uria, Daniel De Freitas, Paul Barham, Lauren Beltrone, VÃ­ctor Campos, Jun Yan, Neel Kovelamudi, Arthur Nguyen, Elinor Davies, Zhichun Wu, Zoltan Egyed, Kristina Toutanova, Nithya Attaluri, Hongliang Fei, Peter Stys, Siddhartha Brahma, Martin Izzard, Siva Velusamy, Scott Lundberg, Vincent Zhuang, Kevin Sequeira, Adam Santoro, Ehsan Amid, Ophir Aharoni, Shuai Ye, Mukund Sundararajan, Lijun Yu, Yu-Cheng Ling, Stephen Spencer, Hugo Song, Josip Djolonga, Christo Kirov, Sonal Gupta, Alessandro Bissacco, Clemens Meyer, Mukul Bhutani, Andrew Dai, Weiyi Wang, Siqi Liu, Ashwin Sreevatsa, Qijun Tan, Maria Wang, Lucy Kim, Yicheng Wang, Alex Irpan, Yang Xiao, Stanislav Fort, Yifan He, Alex Gurney, Bryan Gale, Yue Ma, Monica Roy, Viorica Patraucean, Taylan Bilal, Golnaz Ghiasi, Anahita Hosseini, Melvin Johnson, Zhuowan Li, Yi Tay, Benjamin Beyret, Katie Millican, Josef Broder, Mayank Lunayach, Danny Swisher, Eugen VuÅ¡ak, David Parkinson, MH Tessler, Adi Mayrav Gilady, Richard Song, Allan Dafoe, Yves Raimond, Masa Yamaguchi, Itay Karo, Elizabeth Nielsen, Kevin Kilgour, Mike Dusenberry, Rajiv Mathews, Jiho Choi, Siyuan Qiao, Harsh Mehta, Sahitya Potluri, Chris Knutsen, Jialu Liu, Tat Tan, Kuntal Sengupta, Keerthana Gopalakrishnan, Abodunrinwa Toki, Mencher Chiang, Mike Burrows, Grace Vesom, Zafarali Ahmed, Ilia Labzovsky, Siddharth Vashishtha, Preeti Singh, Ankur Sharma, Ada Ma, Jinyu Xie, Pranav Talluri, Hannah Forbes-Pollard, Aarush Selvan, Joel Wee, Loic Matthey, Tom Funkhouser, Parthasarathy Gopavarapu, Lev Proleev, Cheng Li, Matt Thomas, Kashyap Kolipaka, Zhipeng Jia, Ashwin Kakarla, Srinivas Sunkara, Joan Puigcerver, Suraj Satishkumar Sheth, Emily Graves, Chen Wang, Sadh MNM Khan, Kai Kang, Shyamal Buch, Fred Zhang, Omkar Savant, David Soergel, Kevin Lee, Linda Friso, Xuanyi Dong, Rahul Arya, Shreyas Chandrakaladharan, Connor Schenck, Greg Billock, Tejas Iyer, Anton Bakalov, Leslie Baker, Alex Ruiz, Angad Chandorkar, Trieu Trinh, Matt Miecnikowski, Yanqi Zhou, Yangsibo Huang, Jiazhong Nie, Ali Shah, Ashish Thapliyal, Sam Haves, Lun Wang, Uri Shaham, Patrick Morris-Suzuki, Soroush Radpour, Leonard Berrada, Thomas Strohmann, Chaochao Yan, Jingwei Shen, Sonam Goenka, Tris Warkentin, Petar DeviÄ‡, Dan Belov, Albert Webson, Madhavi Yenugula, Puranjay Datta, Jerry Chang, Nimesh Ghelani, Aviral Kumar, Vincent Perot, Jessica Lo, Yang Song, Herman Schmit, Jianmin Chen, Vasilisa Bashlovkina, Xiaoyue Pan, Diana Mincu, Paul Roit, Isabel Edkins, Andy Davis, Yujia Li, Ben Horn, Xinjian Li, Pradeep Kumar S, Eric Doi, Wanzheng Zhu, Sri Gayatri Sundara Padmanabhan, Siddharth Verma, Jasmine Liu, Heng Chen, Mihajlo VelimiroviÄ‡, Malcolm Reynolds, Priyanka Agrawal, Nick Sukhanov, Abhinit Modi, Siddharth Goyal, John Palowitch, Nima Khajehnouri, Wing Lowe, David Klinghoffer, Sharon Silver, Vinh Tran, Candice Schumann, Francesco Piccinno, Xi Liu, Mario LuÄiÄ‡, Xiaochen Yang, Sandeep Kumar, Ajay Kannan, Ragha Kotikalapudi, Mudit Bansal, Fabian Fuchs, Mohammad Javad Hosseini, Abdelrahman Abdelhamed, Dawn Bloxwich, Tianhe Yu, Ruoxin Sang, Gregory Thornton, Karan Gill, Yuchi Liu, Virat Shejwalkar, Jason Lin, Zhipeng Yan, Kehang Han, Thomas Buschmann, Michael Pliskin, Zhi Xing, Susheel Tatineni, Junlin Zhang, Sissie Hsiao, Gavin Buttimore, Marcus Wu, Zefei Li, Geza Kovacs, Legg Yeung, Tao Huang, Aaron Cohen, Bethanie Brownfield, Averi Nowak, Mikel Rodriguez, Tianze Shi, Hado van Hasselt, Kevin Cen, Deepanway Ghoshal, Kushal Majmundar, Weiren Yu, Warren Weilun Chen, Danila Sinopalnikov, Hao Zhang, Vlado GaliÄ‡, Di Lu, Zeyu Zheng, Maggie Song, Gary Wang, Gui Citovsky, Swapnil Gawde, Isaac Galatzer-Levy, David Silver, Ivana Balazevic, Dipanjan Das, Kingshuk Majumder, Yale Cong, Praneet Dutta, Dustin Tran, Hui Wan, Junwei Yuan, Daniel Eppens, Alanna Walton, Been Kim, Harry Ragan, James Cobon-Kerr, Lu Liu, Weijun Wang, Bryce Petrini, Jack Rae, Rakesh Shivanna, Yan Xiong, Chace Lee, Pauline Coquinot, Yiming Gu, Lisa Patel, Blake Hechtman, Aviel Boag, Orion Jankowski, Alex Wertheim, Alex Lee, Paul Covington, Hila Noga, Sam Sobell, Shanthal Vasanth, William Bono, Chirag Nagpal, Wei Fan, Xavier Garcia, Kedar Soparkar, Aybuke Turker, Nathan Howard, Sachit Menon, Yuankai Chen, Vikas Verma, Vladimir Pchelin, Harish Rajamani, Valentin Dalibard, Ana Ramalho, Yang Guo, Kartikeya Badola, Seojin Bang, Nathalie Rauschmayr, Julia Proskurnia, Sudeep Dasari, Xinyun Chen, Mikhail Sushkov, Anja Hauth, Pauline Sho, Abhinav Singh, Bilva Chandra, Allie Culp, Max Dylla, Olivier Bachem, James Besley, Heri Zhao, Timothy Lillicrap, Wei Wei, Wael Al Jishi, Ning Niu, Alban Rrustemi, RaphaÃ«l Lopez Kaufman, Ryan Poplin, Jewel Zhao, Minh Truong, Shikhar Bharadwaj, Ester Hlavnova, Eli Stickgold, Cordelia Schmid, Georgi Stephanov, Zhaoqi Leng, Frederick Liu, LÃ©onard Hussenot, Shenil Dodhia, Juliana Vicente Franco, Lesley Katzen, Abhanshu Sharma, Sarah Cogan, Zuguang Yang, Aniket Ray, Sergi Caelles, Shen Yan, Ravin Kumar, Daniel Gillick, Renee Wong, Joshua Ainslie, Jonathan Hoech, SÃ©b Arnold, Dan Abolafia, Anca Dragan, Ben Hora, Grace Hu, Alexey Guseynov, Yang Lu, Chas Leichner, Jinmeng Rao, Abhimanyu Goyal, Nagabhushan Baddi, Daniel Hernandez Diaz, Tim McConnell, Max Bain, Jake Abernethy, Qiqi Yan, Rylan Schaeffer, Paul Vicol, Will Thompson, Montse Gonzalez Arenas, Mathias Bellaiche, Pablo Barrio, Stefan Zinke, Riccardo Patana, Pulkit Mehta, JK Kearns, Avraham Ruderman, Scott Pollom, David Dâ€™Ambrosio, Cath Hope, Yang Yu, Andrea Gesmundo, Kuang-Huei Lee, Aviv Rosenberg, Yiqian Zhou, Yaoyiran Li, Drew Garmon, Yonghui Wu, Safeen Huda, Gil Fidel, Martin Baeuml, Jian Li, Phoebe Kirk, Rhys May, Tao Tu, Sara Mc Carthy, Toshiyuki Fukuzawa, Miranda Aperghis, Chih-Kuan Yeh, Toshihiro Yoshino, Bo Li, Austin Myers, Kaisheng Yao, Ben Limonchik, Changwan Ryu, Rohun Saxena, Alex Goldin, Ruizhe Zhao, Rocky Rhodes, Tao Zhu, Divya Tyam, Heidi Howard, Nathan Byrd, Hongxu Ma, Yan Wu, Ryan Mullins, Qingze Wang, Aida Amini, Sebastien Baur, Yiran Mao, Subhashini Venugopalan, Will Song, Wen Ding, Paul Collins, Sashank Reddi, Megan Shum, Andrei Rusu, Luisa Zintgraf, Kelvin Chan, Sheela Goenka, Mathieu Blondel, Michael Collins, Renke Pan, Marissa Giustina, Nikolai Chinaev, Christian Schuler, Ce Zheng, Jonas Valfridsson, Alyssa Loo, Alex Yakubovich, Jamie Smith, Tao Jiang, Rich Munoz, Gabriel Barcik, Rishabh Bansal, Mingyao Yang, Yilun Du, Pablo Duque, Mary Phuong, Alexandra Belias, Kunal Lad, Zeyu Liu, Tal Schuster, Karthik Duddu, Jieru Hu, Paige Kunkle, Matthew Watson, Jackson Tolins, Josh Smith, Denis Teplyashin, Garrett Bingham, Marvin Ritter, Marco Andreetto, Divya Pitta, Mohak Patel, Shashank Viswanadha, Trevor Strohman, Catalin Ionescu, Jincheng Luo, Yogesh Kalley, Jeremy Wiesner, Dan Deutsch, Derek Lockhart, Peter Choy, Rumen Dangovski, Chawin Sitawarin, Cat Graves, Tanya Lando, Joost van Amersfoort, Ndidi Elue, Zhouyuan Huo, Pooya Moradi, Jean Tarbouriech, Henryk Michalewski, Wenting Ye, Eunyoung Kim, Alex Druinsky, Florent AltchÃ©, Xinyi Chen, Artur Dwornik, Da-Cheng Juan, Rivka Moroshko, Horia Toma, Jarrod Kahn, Hai Qian, Maximilian Sieb, Irene Cai, Roman Goldenberg, Praneeth Netrapalli, Sindhu Raghuram, Yuan Gong, Lijie Fan, Evan Palmer, Yossi Matias, Valentin Gabeur, Shreya Pathak, Tom Ouyang, Don Metzler, Geoff Bacon, Srinivasan Venkatachary, Sridhar Thiagarajan, Alex Cullum, Eran Ofek, Vytenis Sakenas, Mohamed Hammad, Cesar Magalhaes, Mayank Daswani, Oscar Chang, Ashok Popat, Ruichao Li, Komal Jalan, Yanhan Hou, Josh Lipschultz, Antoine He, Wenhao Jia, Pier Giuseppe Sessa, Prateek Kolhar, William Wong, Sumeet Singh, Lukas Haas, Jay Whang, Hanna Klimczak-PluciÅ„ska, Georges Rotival, Grace Chung, Yiqing Hua, Anfal Siddiqui, Nicolas Serrano, Dongkai Chen, Billy Porter, Libin Bai, Keshav Shivam, Sho Arora, Partha Talukdar, Tom Cobley, Sangnie Bhardwaj, Evgeny Gladchenko, Simon Green, Kelvin Guu, Felix Fischer, Xiao Wu, Eric Wang, Achintya Singhal, Tatiana Matejovicova, James Martens, Hongji Li, Roma Patel, Elizabeth Kemp, Jiaqi Pan, Lily Wang, Blake JianHang Chen, Jean-Baptiste Alayrac, Navneet Potti, Erika Gemzer, Eugene Ie, Kay McKinney, Takaaki Saeki, Edward Chou, Pascal Lamblin, SQ Mah, Zach Fisher, Martin Chadwick, Jon Stritar, Obaid Sarvana, Andrew Hogue, Artem Shtefan, Hadi Hashemi, Yang Xu, Jindong Gu, Sharad Vikram, Chung-Ching Chang, Sabela Ramos, Logan Kilpatrick, Weijuan Xi, Jenny Brennan, Yinghao Sun, Abhishek Jindal, Ionel Gog, Dawn Chen, Felix Wu, Jason Lee, Sudhindra Kopalle, Srinadh Bhojanapalli, Oriol Vinyals, Natan Potikha, Burcu Karagol Ayan, Yuan Yuan, Michael Riley, Piotr Stanczyk, Sergey Kishchenko, Bing Wang, Dan Garrette, Antoine Yang, Vlad Feinberg, CJ Carey, Javad Azizi, Viral Shah, Erica Moreira, Chongyang Shi, Josh Feldman, Elizabeth Salesky, Thomas Lampe, Aneesh Pappu, Duhyeon Kim, Jonas Adler, Avi Caciularu, Brian Walker, Yunhan Xu, Yochai Blau, Dylan Scandinaro, Terry Huang, Sam El-Husseini, Abhishek Sinha, Lijie Ren, Taylor Tobin, Patrik Sundberg, Tim Sohn, Vikas Yadav, Mimi Ly, Emily Xue, Jing Xiong, Afzal Shama Soudagar, Sneha Mondal, Nikhil Khadke, Qingchun Ren, Ben Vargas, Stan Bileschi, Sarah Chakera, Cindy Wang, Boyu Wang, Yoni Halpern, Joe Jiang, Vikas Sindhwani, Petre Petrov, Pranavaraj Ponnuramu, Sanket Vaibhav Mehta, Yu Watanabe, Betty Chan, Matheus Wisniewski, Trang Pham, Jingwei Zhang, Conglong Li, Dario de Cesare, Art Khurshudov, Alex Vasiloff, Melissa Tan, Zoe Ashwood, Bobak Shahriari, Maryam Majzoubi, Garrett Tanzer, Olga Kozlova, Robin Alazard, James Lee-Thorp, Nguyet Minh Phu, Isaac Tian, Junwhan Ahn, Andy Crawford, Lauren Lax, Yuan Shangguan, Iftekhar Naim, David Ross, Oleksandr Ferludin, Tongfei Guo, Andrea Banino, Hubert Soyer, Xiaoen Ju, Dominika RogoziÅ„ska, Ishaan Malhi, Marcella Valentine, Daniel Balle, Apoorv Kulshreshtha, Maciej Kula, Yiwen Song, Sophia Austin, John Schultz, Roy Hirsch, Arthur Douillard, Apoorv Reddy, Michael Fink, Summer Yue, Khyatti Gupta, Adam Zhang, Norman Rink, Daniel McDuff, Lei Meng, AndrÃ¡s GyÃ¶rgy, Yasaman Razeghi, Ricky Liang, Kazuki Osawa, Aviel Atias, Matan Eyal, Tyrone Hill, Nikolai Grigorev, Zhengdong Wang, Nitish Kulkarni, Rachel Soh, Ivan Lobov, Zachary Charles, Sid Lall, Kazuma Hashimoto, Ido Kessler, Victor Gomes, Zelda Mariet, Danny Driess, Alessandro Agostini, Canfer Akbulut, Jingcao Hu, Marissa Ikonomidis, Emily Caveness, Kartik Audhkhasi, Saurabh Agrawal, Ioana Bica, Evan Senter, Jayaram Mudigonda, Kelly Chen, Jingchen Ye, Xuanhui Wang, James Svensson, Philipp FrÃ¤nken, Josh Newlan, Li Lao, Eva Schnider, Sami Alabed, Joseph Kready, Jesse Emond, Afief Halumi, Tim Zaman, Chengxi Ye, Naina Raisinghani, Vilobh Meshram, Bo Chang, Ankit Singh Rawat, Axel Stjerngren, Sergey Levi, Rui Wang, Xiangzhu Long, Mitchelle Rasquinha, Steven Hand, Aditi Mavalankar, Lauren Agubuzu, Sudeshna Roy, Junquan Chen, Jarek Wilkiewicz, Hao Zhou, Michal Jastrzebski, Qiong Hu, Agustin Dal Lago, Ramya Sree Boppana, Wei-Jen Ko, Jennifer Prendki, Yao Su, Zhi Li, Eliza Rutherford, Girish Ramchandra Rao, Ramona Comanescu, AdriÃ  PuigdomÃ¨nech, Qihang Chen, Dessie Petrova, Christine Chan, Vedrana Milutinovic, Felipe Tiengo Ferreira, Chin-Yi Cheng, Ming Zhang, Tapomay Dey, Sherry Yang, Ramesh Sampath, Quoc Le, Howard Zhou, Chu-Cheng Lin, Hoi Lam, Christine Kaeser-Chen, Kai Hui, Dean Hirsch, Tom Eccles, Basil Mustafa, Shruti Rijhwani, Morgane RiviÃ¨re, Yuanzhong Xu, Junjie Wang, Xinyang Geng, Xiance Si, Arjun Khare, Cheolmin Kim, Vahab Mirrokni, Kamyu Lee, Khuslen Baatarsukh, Nathaniel Braun, Lisa Wang, Pallavi LV, Richard Tanburn, Yonghao Zhu, Fangda Li, Setareh Ariafar, Dan Goldberg, Ken Burke, Daniil Mirylenka, Meiqi Guo, Olaf Ronneberger, Hadas Natalie Vogel, Liqun Cheng, Nishita Shetty, Johnson Jia, Thomas Jimma, Corey Fry, Ted Xiao, Martin Sundermeyer, Ryan Burnell, Yannis Assael, Mario Pinto, JD Chen, Rohit Sathyanarayana, Donghyun Cho, Jing Lu, Rishabh Agarwal, Sugato Basu, Lucas Gonzalez, Dhruv Shah, Meng Wei, Dre Mahaarachchi, Rohan Agrawal, Tero Rissa, Yani Donchev, Ramiro Leal-Cavazos, Adrian Hutter, Markus Mircea, Alon Jacovi, Faruk Ahmed, Jiageng Zhang, Shuguang Hu, Bo-Juen Chen, Jonni Kanerva, Guillaume Desjardins, Andrew Lee, Nikos Parotsidis, Asier Mujika, Tobias Weyand, Jasper Snoek, Jo Chick, Kai Chen, Paul Chang, Ethan Mahintorabi, Zi Wang, Tolly Powell, Orgad Keller, Abhirut Gupta, Claire Sha, Kanav Garg, Nicolas Heess, Ãgoston Weisz, Cassidy Hardin, Bartek Wydrowski, Ben Coleman, Karina Zainullina, Pankaj Joshi, Alessandro Epasto, Terry Spitz, Binbin Xiong, Kai Zhao, Arseniy Klimovskiy, Ivy Zheng, Johan Ferret, Itay Yona, Waleed Khawaja, Jean-Baptiste Lespiau, Maxim Krikun, Siamak Shakeri, Timothee Cour, Bonnie Li, Igor Krivokon, Dan Suh, Alex Hofer, Jad Al Abdallah, Nikita Putikhin, Oscar Akerlund, Silvio Lattanzi, Anurag Kumar, Shane Settle, Himanshu Srivastava, Folawiyo Campbell-Ajala, Edouard Rosseel, Mihai Dorin Istin, Nishanth Dikkala, Anand Rao, Nick Young, Kate Lin, Dhruva Bhaswar, Yiming Wang, Jaume Sanchez Elias, Kritika Muralidharan, James Keeling, Dayou Du, Siddharth Gopal, Gregory Dibb, Charles Blundell, Manolis Delakis, Jacky Liang, Marco Tulio Ribeiro, Georgi Karadzhov, Guillermo Garrido, Ankur Bapna, Jiawei Cao, Adam Sadovsky, Pouya Tafti, Arthur Guez, Coline Devin, Yixian Di, Jinwei Xing, Chuqiao Joyce Xu, Hanzhao Lin, Chun-Te Chu, Sameera Ponda, Wesley Helmholz, Fan Yang, Yue Gao, Sara Javanmardi, Wael Farhan, Alex Ramirez, Ricardo Figueira, Khe Chai Sim, Yuval Bahat, Ashwin Vaswani, Liangzhe Yuan, Gufeng Zhang, Leland Rechis, Hanjun Dai, Tayo Oguntebi, Alexandra Cordell, EugÃ©nie Rives, Kaan Tekelioglu, Naveen Kumar, Bing Zhang, Aurick Zhou, Nikolay Savinov, Andrew Leach, Alex Tudor, Sanjay Ganapathy, Yanyan Zheng, Mirko Rossini, Vera Axelrod, Arnaud Autef, Yukun Zhu, Zheng Zheng, Mingda Zhang, Baochen Sun, Jie Ren, Nenad Tomasev, Nithish Kannen, Amer Sinha, Charles Chen, Louis Oâ€™Bryan, Alex Pak, Aditya Kusupati, Weel Yang, Deepak Ramachandran, Patrick Griffin, Seokhwan Kim, Philipp Neubeck, Craig Schiff, Tammo Spalink, Mingyang Ling, Arun Nair, Ga-Young Joung, Linda Deng, Avishkar Bhoopchand, Lora Aroyo, Tom Duerig, Jordan Griffith, Gabe Barth-Maron, Jake Ades, Alex Haig, Ankur Taly, Yunting Song, Paul Michel, Dave Orr, Dean Weesner, Corentin Tallec, Carrie Grimes Bostock, Paul Niemczyk, Andy Twigg, Mudit Verma, Rohith Vallu, Henry Wang, Marco Gelmi, Kiranbir Sodhia, Aleksandr Chuklin, Omer Goldman, Jasmine George, Liang Bai, Kelvin Zhang, Petar Sirkovic, Efrat Nehoran, Golan Pundak, Jiaqi Mu, Alice Chen, Alex Greve, Paulo Zacchello, David Amos, Heming Ge, Eric Noland, Colton Bishop, Jeffrey Dudek, Youhei Namiki, Elena Buchatskaya, Jing Li, Dorsa Sadigh, Masha Samsikova, Dan Malkin, Damien Vincent, Robert David, Rob Willoughby, Phoenix Meadowlark, Shawn Gao, Yan Li, Raj Apte, Amit Jhindal, Stein Xudong Lin, Alex Polozov, Zhicheng Wang, Tomas Mery, Anirudh GP, Varun Yerram, Sage Stevens, Tianqi Liu, Noah Fiedel, Charles Sutton, Matthew Johnson, Xiaodan Song, Kate Baumli, Nir Shabat, Muqthar Mohammad, Hao Liu, Marco Selvi, Yichao Zhou, Mehdi Hafezi Manshadi, Chu-ling Ko, Anthony Chen, Michael Bendersky, Jorge Gonzalez Mendez, Nisarg Kothari, Amir Zandieh, Yiling Huang, Daniel Andor, Ellie Pavlick, Idan Brusilovsky, Jitendra Harlalka, Sally Goldman, Andrew Lampinen, Guowang Li, Asahi Ushio, Somit Gupta, Lei Zhang, Chuyuan Kelly Fu, Madhavi Sewak, Timo Denk, Jed Borovik, Brendan Jou, Avital Zipori, Prateek Jain, Junwen Bai, Thang Luong, Jonathan Tompson, Alice Li, Li Liu, George Powell, Jiajun Shen, Alex Feng, Grishma Chole, Da Yu, Yinlam Chow, Tongxin Yin, Eric Malmi, Kefan Xiao, Yash Pande, Shachi Paul, NiccolÃ² Dal Santo, Adil Dostmohamed, Sergio Guadarrama, Aaron Phillips, Thanumalayan Sankaranarayana Pillai, Gal Yona, Amin Ghafouri, Preethi Lahoti, Benjamin Lee, Dhruv Madeka, Eren Sezener, Simon Tokumine, Adrian Collister, Nicola De Cao, Richard Shin, Uday Kalra, Parker Beak, Emily Nottage, Ryo Nakashima, Ivan Jurin, Vikash Sehwag, Meenu Gaba, Junhao Zeng, Kevin R. McKee, Fernando Pereira, Tamar Yakar, Amayika Panda, Arka Dhar, Peilin Zhong, Daniel Sohn, Mark Brand, Lars Lowe Sjoesund, Viral Carpenter, Sharon Lin, Shantanu Thakoor, Marcus Wainwright, Ashwin Chaugule, Pranesh Srinivasan, Muye Zhu, Bernett Orlando, Jack Weber, Ayzaan Wahid, Gilles Baechler, Apurv Suman, Jovana MitroviÄ‡, Gabe Taubman, Honglin Yu, Helen King, Josh Dillon, Cathy Yip, Dhriti Varma, Tomas Izo, Levent Bolelli, Borja De Balle Pigem, Julia Di Trapani, Fotis Iliopoulos, Adam Paszke, Nishant Ranka, Joe Zou, Francesco Pongetti, Jed McGiffin, Alex Siegman, Rich Galt, Ross Hemsley, Goran Å½uÅ¾iÄ‡, Victor Carbune, Tao Li, Myle Ott, FÃ©lix de Chaumont Quitry, David Vilar Torres, Yuri Chervonyi, Tomy Tsai, Prem Eruvbetine, Samuel Yang, Matthew Denton, Jake Walker, Slavica AndaÄiÄ‡, Idan Heimlich Shtacher, Vittal Premachandran, Harshal Tushar Lehri, Cip Baetu, Damion Yates, Lampros Lamprou, Mariko Iinuma, Ioana Mihailescu, Ben Albrecht, Shachi Dave, Susie Sargsyan, Bryan Perozzi, Lucas Manning, Chiyuan Zhang, Denis Vnukov, Igor Mordatch, Raia Hadsell Wolfgang Macherey, Ryan Kappedal, Jim Stephan, Aditya Tripathi, Klaus Macherey, Jun Qian, Abhishek Bhowmick, Shekoofeh Azizi, RÃ©mi Leblond, Shiva Mohan Reddy Garlapati, Timothy Knight, Matthew Wiethoff, Wei-Chih Hung, Anelia Angelova, Georgios Evangelopoulos, Pawel Janus, Dimitris Paparas, Matthew Rahtz, Ken Caluwaerts, Vivek Sampathkumar, Daniel Jarrett, Shadi Noghabi, Antoine Miech, Chak Yeung, Geoff Clark, Henry Prior, Fei Zheng, Jean Pouget-Abadie, Indro Bhattacharya, Kalpesh Krishna, Will Bishop, Zhe Yuan, Yunxiao Deng, Ashutosh Sathe, Kacper Krasowiak, Ciprian Chelba, Cho-Jui Hsieh, Kiran Vodrahalli, Buhuang Liu, Thomas KÃ¶ppe, Amr Khalifa, Lubo Litchev, Pichi Charoenpanit, Reed Roberts, Sachin Yadav, Yasumasa Onoe, Desi Ivanov, Megha Mohabey, Vighnesh Birodkar, Nemanja RakiÄ‡eviÄ‡, Pierre Sermanet, Vaibhav Mehta, Krishan Subudhi, Travis Choma, Will Ng, Luheng He, Kathie Wang, Tasos Kementsietsidis, Shane Gu, Mansi Gupta, Andrew Nystrom, Mehran Kazemi, Timothy Chung, Nacho Cano, Nikhil Dhawan, Yufei Wang, Jiawei Xia, Trevor Yacovone, Eric Jia, Mingqing Chen, Simeon Ivanov, Ashrith Sheshan, Sid Dalmia, PaweÅ‚ Stradomski, Pengcheng Yin, Salem Haykal, Congchao Wang, Dennis Duan, Neslihan Bulut, Greg Kochanski, Liam MacDermed, Namrata Godbole, Shitao Weng, Jingjing Chen, Rachana Fellinger, Ramin Mehran, Daniel Suo, Hisham Husain, Tong He, Kaushal Patel, Joshua Howland, Randall Parker, Kelvin Nguyen, Sharath Maddineni, Chris Rawles, Mina Khan, Shlomi Cohen-Ganor, Amol Mandhane, Xinyi Wu, Chenkai Kuang, Iulia ComÅŸa, Ramya Ganeshan, Hanie Sedghi, Adam Bloniarz, Nuo Wang Pierse, Anton Briukhov, Petr Mitrichev, Anita Gergely, Serena Zhan, Allan Zhou, Nikita Saxena, Eva Lu, Josef Dean, Ashish Gupta, Nicolas Perez-Nieves, Renjie Wu, Cory McLean, Wei Liang, Disha Jindal, Anton Tsitsulin, Wenhao Yu, Kaiz Alarakyia, Tom Schaul, Piyush Patil, Peter Sung, Elijah Peake, Hongkun Yu, Feryal Behbahani, JD Co-Reyes, Alan Ansell, Sean Sun, Clara Barbu, Jonathan Lee, Seb Noury, James Allingham, Bilal Piot, Mohit Sharma, Christopher Yew, Ivan Korotkov, Bibo Xu, Demetra Brady, Goran Petrovic, Shibl Mourad, Claire Cui, Aditya Gupta, Parker Schuh, Saarthak Khanna, Anna Goldie, Abhinav Arora, Vadim Zubov, Amy Stuart, Mark Epstein, Yun Zhu, Jianqiao Liu, Yury Stuken, Ziyue Wang, Karolis Misiunas, Dee Guo, Ashleah Gill, Ale Hartman, Zaid Nabulsi, Aurko Roy, Aleksandra Faust, Jason Riesa, Ben Withbroe, Mengchao Wang, Marco Tagliasacchi, Andreea Marzoca, James Noraky, Serge Toropov, Malika Mehrotra, Bahram Raad, Sanja Deur, Steve Xu, Marianne Monteiro, Zhongru Wu, Yi Luan, Sam Ritter, Nick Li, HÃ¥vard Garnes, Yanzhang He, Martin Zlocha, Jifan Zhu, Matteo Hessel, Will Wu, Spandana Raj Babbula, Chizu Kawamoto, Yuanzhen Li, Mehadi Hassen, Yan Wang, Brian Wieder, James Freedman, Yin Zhang, Xinyi Bai, Tianli Yu, David Reitter, XiangHai Sheng, Mateo Wirth, Aditya Kini, Dima Damen, Mingcen Gao, Rachel Hornung, Michael Voznesensky, Brian Roark, Adhi Kuncoro, Yuxiang Zhou, Rushin Shah, Anthony Brohan, Kuangyuan Chen, James Wendt, David Rim, Paul Kishan Rubenstein, Jonathan Halcrow, Michelle Liu, Ty Geri, Yunhsuan Sung, Jane Shapiro, Shaan Bijwadia, Chris Duvarney, Christina Sorokin, Paul Natsev, Reeve Ingle, Pramod Gupta, Young Maeng, Ndaba Ndebele, Kexin Zhu, Valentin Anklin, Katherine Lee, Yuan Liu, Yaroslav Akulov, Shaleen Gupta, Guolong Su, Flavien Prost, Tianlin Liu, Vitaly Kovalev, Pol Moreno, Martin Scholz, Sam Redmond, Zongwei Zhou, Alex Castro-Ros, AndrÃ© Susano Pinto, Dia Kharrat, Michal Yarom, Rachel Saputro, Jannis Bulian, Ben Caine, Ji Liu, Abbas Abdolmaleki, Shariq Iqbal, Tautvydas Misiunas, Mikhail Sirotenko, Shefali Garg, Guy Bensky, Huan Gui, Xuezhi Wang, Raphael Koster, Mike Bernico, Da Huang, Romal Thoppilan, Trevor Cohn, Ben Golan, Wenlei Zhou, Andrew Rosenberg, Markus Freitag, Tynan Gangwani, Vincent Tsang, Anand Shukla, Xiaoqi Ren, Minh Giang, Chi Zou, Andre Elisseeff, Charline Le Lan, Dheeru Dua, Shuba Lall, Pranav Shyam, Frankie Garcia, Sarah Nguyen, Michael Guzman, AJ Maschinot, Marcello Maggioni, Ming-Wei Chang, Karol Gregor, Lotte Weerts, Kumaran Venkatesan, Bogdan Damoc, Leon Liu, Jan Wassenberg, Lewis Ho, Becca Roelofs, Majid Hadian, FranÃ§ois-Xavier Aubet, Yu Liang, Sami Lachgar, Danny Karmon, Yong Cheng, Amelio VÃ¡zquez-Reina, Angie Chen, Zhuyun Dai, Andy Brock, Shubham Agrawal, Chenxi Pang, Peter Garst, Mariella Sanchez-Vargas, Ivor Rendulic, Aditya Ayyar, Andrija RaÅ¾natoviÄ‡, Olivia Ma, Roopali Vij, Neha Sharma, Ashwin Balakrishna, Bingyuan Liu, Ian Mackinnon, Sorin Baltateanu, Petra Poklukar, Gabriel Ibagon, Colin Ji, Hongyang Jiao, Isaac Noble, Wojciech Stokowiec, Zhihao Li, Jeff Dean, David Lindner, Mark Omernick, Kristen Chiafullo, Mason Dimarco, Vitor Rodrigues, Vittorio Selo, Garrett Honke, Xintian Cindy Wu, Wei He, Adam Hillier, Anhad Mohananey, Vihari Piratla, Chang Ye, Chase Malik, Sebastian Riedel, Samuel Albanie, Zi Yang, Kenny Vassigh, Maria Bauza, Sheng Li, Yiqing Tao, Nevan Wichers, Andrii Maksai, Abe Ittycheriah, Ross Mcilroy, Bryan Seybold, Noah Goodman, Romina Datta, Steven M. Hernandez, Tian Shi, Yony Kochinski, Anna Bulanova, Ken Franko, Mikita Sazanovich, Nicholas FitzGerald, Praneeth Kacham, Shubha Srinivas Raghvendra, Vincent Hellendoorn, Alexander Grushetsky, Julian Salazar, Angeliki Lazaridou, Jason Chang, Jan-Thorsten Peter, Sushant Kafle, Yann Dauphin, Abhishek Rao, Filippo Graziano, Izhak Shafran, Yuguo Liao, Tianli Ding, Geng Yan, Grace Chu, Zhao Fu, Vincent Roulet, Gabriel Rasskin, Duncan Williams, Shahar Drath, Alex Mossin, Raphael Hoffmann, Jordi Orbay, Francesco Bertolini, Hila Sheftel, Justin Chiu, Siyang Xue, Yuheng Kuang, Ferjad Naeem, Swaroop Nath, Nana Nti, Phil Culliton, Kashyap Krishnakumar, Michael Isard, Pei Sun, Ayan Chakrabarti, Nathan Clement, Regev Cohen, Arissa Wongpanich, GS Oh, Ashwin Murthy, Hao Zheng, Jessica Hamrick, Oskar Bunyan, Suhas Ganesh, Nitish Gupta, Roy Frostig, John Wieting, Yury Malkov, Pierre Marcenac, Zhixin Lucas Lai, Xiaodan Tang, Mohammad Saleh, Fedir Zubach, Chinmay Kulkarni, Huanjie Zhou, Vicky Zayats, Nan Ding, Anshuman Tripathi, Arijit Pramanik, Patrik Zochbauer, Harish Ganapathy, Vedant Misra, Zach Behrman, Hugo Vallet, Mingyang Zhang, Mukund Sridhar, Ye Jin, Mohammad Babaeizadeh, Siim PÃµder, Megha Goel, Divya Jain, Tajwar Nasir, Shubham Mittal, Tim Dozat, Diego Ardila, Aliaksei Severyn, Fabio Pardo, Sammy Jerome, Siyang Qin, Louis Rouillard, Amir Yazdanbakhsh, Zizhao Zhang, Shivani Agrawal, Kaushik Shivakumar, Caden Lu, Praveen Kallakuri, Rachita Chhaparia, Kanishka Rao, Charles Kwong, Asya Fadeeva, Shitij Nigam, Yan Virin, Yuan Zhang, Balaji Venkatraman, Beliz Gunel, Marc Wilson, Huiyu Wang, Abhinav Gupta, Xiaowei Xu, Adrien Ali TaÃ¯ga, Kareem Mohamed, Doug Fritz, Daniel Rodriguez, Zoubin Ghahramani, Harry Askham, Lior Belenki, James Zhao, Rahul Gupta, Krzysztof JastrzÄ™bski, Takahiro Kosakai, Kaan Katircioglu, Jon Schneider, Rina Panigrahy, Konstantinos Bousmalis, Peter Grabowski, Prajit Ramachandran, Chaitra Hegde, Mihaela Rosca, Angelo Scorza Scarpati, Kyriakos Axiotis, Ying Xu, Zach Gleicher, Assaf Hurwitz Michaely, Mandar Sharma, Sanil Jain, Christoph Hirnschall, Tal Marian, Xuhui Jia, Kevin Mather, Kilol Gupta, Linhai Qiu, Nigamaa Nayakanti, Lucian Ionita, Steven Zheng, Lucia Loher, Kurt Shuster, Igor Petrovski, Roshan Sharma, Rahma Chaabouni, Angel Yeh, James An, Arushi Gupta, Steven Schwarcz, Seher Ellis, Sam Conway-Rahman, Javier Snaider, Alex Zhai, James Atwood, Daniel Golovin, Liqian Peng, Te I, Vivian Xia, Salvatore Scellato, Mahan Malihi, Arthur BraÅ¾inskas, Vlad-Doru Ion, Younghoon Jun, James Swirhun, Soroosh Mariooryad, Jiao Sun, Steve Chien, Rey Coaguila, Ariel Brand, Yi Gao, Tom Kwiatkowski, Roee Aharoni, Cheng-Chun Lee, Mislav Å½aniÄ‡, Yichi Zhang, Dan Ethier, Vitaly Nikolaev, Pranav Nair, Yoav Ben Shalom, Hen Fitoussi, Jai Gupta, Hongbin Liu, Dee Cattle, Tolga Bolukbasi, Ben Murdoch, Fantine Huot, Yin Li, Chris Hahn</strong></p>
<p>In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving. </p>
<blockquote>
<p>åœ¨è¿™ä»½æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Gemini 2.Xæ¨¡å‹å®¶æ—ï¼šåŒ…æ‹¬Gemini 2.5 Proå’ŒGemini 2.5 Flashï¼Œä»¥åŠæˆ‘ä»¬ä¹‹å‰çš„Gemini 2.0 Flashå’ŒFlash-Liteæ¨¡å‹ã€‚Gemini 2.5 Proæ˜¯æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢åŠŸèƒ½æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œåœ¨å‰æ²¿ç¼–ç å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚é™¤äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç¼–ç å’Œæ¨ç†æŠ€èƒ½å¤–ï¼ŒGemini 2.5 Proè¿˜æ˜¯ä¸€ç§æ“…é•¿å¤šæ¨¡å¼ç†è§£çš„æ€è€ƒæ¨¡å‹ï¼Œç°åœ¨èƒ½å¤Ÿå¤„ç†é•¿è¾¾3å°æ—¶çš„è§†é¢‘å†…å®¹ã€‚å…¶ç‹¬ç‰¹çš„é•¿æœŸä¸Šä¸‹æ–‡ã€å¤šæ¨¡å¼ä¸æ¨ç†èƒ½åŠ›çš„ç»“åˆå¯ä»¥è§£é”æ–°çš„æ™ºèƒ½å·¥ä½œæµç¨‹ã€‚Gemini 2.5 Flashåœ¨è®¡ç®—å’Œå»¶è¿Ÿè¦æ±‚æ–¹é¢æä¾›äº†ä¸€æµçš„æ¨ç†èƒ½åŠ›çš„ä¸€å°éƒ¨åˆ†ï¼›è€ŒGemini 2.0 Flashå’ŒFlash-Liteåœ¨ä½å»¶è¿Ÿå’Œä½æˆæœ¬çš„æƒ…å†µä¸‹æä¾›äº†é«˜æ€§èƒ½ã€‚æ€»çš„æ¥è¯´ï¼ŒGemini 2.Xæ¨¡å‹ä¸–ä»£æ¶µç›–äº†æ¨¡å‹èƒ½åŠ›ä¸æˆæœ¬ä¹‹é—´çš„å…¨é¢å¸•ç´¯æ‰˜å‰æ²¿ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ¢ç´¢é€šè¿‡å¤æ‚çš„æ™ºèƒ½é—®é¢˜è§£å†³å¯èƒ½æ€§çš„è¾¹ç•Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06261v2">PDF</a> 72 pages, 17 figures</p>
<p><strong>Summary</strong></p>
<p>å…¨æ–°ç³»åˆ—æŠ¥å‘Šä»‹ç»äº†Gemini 2.Xæ¨¡å‹å®¶æ—ï¼ŒåŒ…æ‹¬Gemini 2.5 Proå’ŒGemini 2.5 Flashç­‰ã€‚å…¶ä¸­ï¼ŒGemini 2.5 Proæ˜¯è¿„ä»Šä¸ºæ­¢æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ï¼Œèƒ½åœ¨å‰æ²¿ç¼–ç å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®ƒè¿˜å…·æœ‰å‡ºè‰²çš„å¤šæ¨¡å¼ç†è§£èƒ½åŠ›ï¼Œå¹¶èƒ½å¤„ç†é•¿è¾¾3å°æ—¶çš„è§†é¢‘å†…å®¹ã€‚Gemini 2.Xæ¨¡å‹ç³»åˆ—çš„ç”Ÿæˆè·¨è¶Šäº†æ¨¡å‹èƒ½åŠ›ä¸æˆæœ¬ä¹‹é—´çš„å…¨Paretoå‰æ²¿ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ¢ç´¢å¤æ‚çš„ä»£ç†é—®é¢˜è§£å†³çš„å¯èƒ½æ€§è¾¹ç•Œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Gemini 2.Xæ¨¡å‹å®¶æ—åŒ…å«Gemini 2.5 Proå’ŒGemini 2.5 Flashç­‰å¤šä¸ªå‹å·ã€‚</li>
<li>Gemini 2.5 Proæ˜¯ç›®å‰æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ï¼Œå…·æœ‰å‡ºè‰²çš„ç¼–ç å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>Gemini 2.5 Proå…·å¤‡å¤šæ¨¡å¼ç†è§£èƒ½åŠ›ï¼Œå¹¶èƒ½å¤„ç†é•¿è¾¾3å°æ—¶çš„è§†é¢‘å†…å®¹ã€‚</li>
<li>Gemini 2.5 Flashåœ¨æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶é™ä½äº†è®¡ç®—å’Œå»¶è¿Ÿè¦æ±‚ã€‚</li>
<li>Gemini 2.0 Flashå’ŒFlash-Liteæä¾›ä½å»¶è¿Ÿå’Œæˆæœ¬ä¸‹çš„é«˜æ€§èƒ½è¡¨ç°ã€‚</li>
<li>Gemini 2.Xæ¨¡å‹å®¶æ—è¦†ç›–äº†æ¨¡å‹èƒ½åŠ›ä¸æˆæœ¬ä¹‹é—´çš„å…¨Paretoå‰æ²¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06261">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-43b8e0d7d1e834dbb8ccba2577ff962f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4321eb6fef0a8502476c2ba71f560b1d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6eb40d6816cfb4a8cbd7a1aa5b0a0a08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac384cd35790aa9348cedb348afdc439.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ebbf938067c74feb76c4a288e8fd861c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da22ec7125b2e2c1673700753687782e.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="One-Pass-to-Reason-Token-Duplication-and-Block-Sparse-Mask-for-Efficient-Fine-Tuning-on-Multi-Turn-Reasoning"><a href="#One-Pass-to-Reason-Token-Duplication-and-Block-Sparse-Mask-for-Efficient-Fine-Tuning-on-Multi-Turn-Reasoning" class="headerlink" title="One-Pass to Reason: Token Duplication and Block-Sparse Mask for   Efficient Fine-Tuning on Multi-Turn Reasoning"></a>One-Pass to Reason: Token Duplication and Block-Sparse Mask for   Efficient Fine-Tuning on Multi-Turn Reasoning</h2><p><strong>Authors:Ritesh Goru, Shanay Mehta, Prateek Jain</strong></p>
<p>Fine-tuning Large Language Models (LLMs) on multi-turn reasoning datasets requires N (number of turns) separate forward passes per conversation due to reasoning token visibility constraints, as reasoning tokens for a turn are discarded in subsequent turns. We propose duplicating response tokens along with a custom attention mask to enable single-pass processing of entire conversations. We prove our method produces identical losses to the N-pass approach while reducing time complexity from $O\bigl(N^{3}\bigl)$ to $O\bigl(N^{2}\bigl)$ and maintaining the same memory complexity for a transformer based model. Our approach achieves significant training speedup while preserving accuracy. Our implementation is available online (<a target="_blank" rel="noopener" href="https://github.com/devrev/One-Pass-to-Reason">https://github.com/devrev/One-Pass-to-Reason</a>). </p>
<blockquote>
<p>å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šè½®æ¨ç†æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œç”±äºæ¨ç†æ ‡è®°å¯è§æ€§çš„é™åˆ¶ï¼Œæ¯ä¸€è½®å¯¹è¯éƒ½éœ€è¦è¿›è¡ŒNæ¬¡å•ç‹¬çš„å‰å‘ä¼ é€’ã€‚æˆ‘ä»¬æå‡ºå¤åˆ¶å“åº”æ ‡è®°å¹¶ä½¿ç”¨è‡ªå®šä¹‰æ³¨æ„åŠ›æ©ç ï¼Œä»¥å®ç°å¯¹æ•´ä¸ªå¯¹è¯çš„å•æ¬¡ä¼ é€’å¤„ç†ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•äº§ç”Ÿçš„æŸå¤±ä¸Næ¬¡ä¼ é€’æ–¹æ³•ç›¸åŒï¼ŒåŒæ—¶å°†æ—¶é—´å¤æ‚åº¦ä»O(N^3)é™ä½åˆ°O(N^2)ï¼Œå¹¶ä¿æŒäº†åŸºäºå˜å‹å™¨çš„æ¨¡å‹çš„ç›¸åŒå†…å­˜å¤æ‚åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶å®ç°äº†æ˜¾è‘—çš„è®­ç»ƒåŠ é€Ÿã€‚æˆ‘ä»¬çš„å®ç°å·²åœ¨çº¿å‘å¸ƒï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/devrev/One-Pass-to-Reason%EF%BC%89%E3%80%82">https://github.com/devrev/One-Pass-to-Reasonï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18246v2">PDF</a> 9 pages, 3 figures</p>
<p><strong>Summary</strong>ï¼šé’ˆå¯¹å¤šè½®æ¨ç†æ•°æ®é›†å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œç”±äºæ¨ç†ä»¤ç‰Œå¯è§æ€§çš„é™åˆ¶ï¼Œéœ€è¦è¿›è¡ŒNæ¬¡å•ç‹¬çš„è½¬å‘æ“ä½œã€‚æˆ‘ä»¬æå‡ºé€šè¿‡å¤åˆ¶å“åº”ä»¤ç‰Œå’Œè‡ªå®šä¹‰æ³¨æ„åŠ›æ©ç æ¥å®ç°æ•´ä¸ªå¯¹è¯çš„å•æ¬¡ä¼ é€’å¤„ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•äº§ç”Ÿçš„æŸå¤±ä¸Næ¬¡ä¼ é€’æ–¹æ³•ç›¸åŒï¼ŒåŒæ—¶å°†æ—¶é—´å¤æ‚åº¦ä»O(NÂ³)é™ä½åˆ°O(NÂ²)ï¼Œå¯¹äºåŸºäºè½¬æ¢å™¨çš„æ¨¡å‹ï¼Œä¿æŒç›¸åŒçš„å†…å­˜å¤æ‚åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿è¯å‡†ç¡®æ€§çš„åŒæ—¶å®ç°äº†æ˜¾è‘—çš„è®­ç»ƒé€Ÿåº¦æå‡ã€‚ç›¸å…³å®ç°å·²åœ¨çº¿å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè½®æ¨ç†æ•°æ®é›†ä¸Šçš„å¾®è°ƒéœ€è¦é’ˆå¯¹æ¯è½®å¯¹è¯è¿›è¡Œå•ç‹¬çš„è½¬å‘å¤„ç†ã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡å¤åˆ¶å“åº”ä»¤ç‰Œå’Œè‡ªå®šä¹‰æ³¨æ„åŠ›æ©ç ï¼Œå®ç°äº†æ•´ä¸ªå¯¹è¯çš„å•æ¬¡ä¼ é€’å¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•äº§ç”Ÿçš„æŸå¤±ä¸å¤šæ¬¡ä¼ é€’æ–¹æ³•ç›¸åŒã€‚</li>
<li>è¯¥æ–¹æ³•é™ä½äº†è®­ç»ƒçš„æ—¶é—´å¤æ‚åº¦ï¼Œä»O(NÂ³)é™ä½åˆ°O(NÂ²)ï¼Œå¹¶ä¸”ä¿æŒäº†ç›¸åŒçš„å†…å­˜å¤æ‚åº¦ã€‚</li>
<li>æ­¤æ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶ä¿è¯äº†å‡†ç¡®æ€§ã€‚</li>
<li>å…·ä½“çš„å®ç°ç»†èŠ‚å·²ç»åœ¨çº¿å‘å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18246">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4d9530212025c2bae8a7f463a86efc1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62bc6fd41a7b55c01c4859c194d4d0ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-047fe2ecbc1329347471b208956d9906.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ec402585417af7ef8edeed8a6adbe66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c32b329c3fd8aac8827f2631a6a929b.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-15/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-0516b4c33873e7226f7ba21e7a9a7be8.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-15  Lumos-1 On Autoregressive Video Generation from a Unified Model   Perspective
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-14/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e1a0ab595a25e11703980e518bc7b74c.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-14  UWarp A Whole Slide Image Registration Pipeline to Characterize   Scanner-Induced Local Domain Shift
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
