<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-15  MIDI-VALLE Improving Expressive Piano Performance Synthesis Through   Neural Codec Language Modelling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-91d1847feafaa6c1fd0fa7687a0d373e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    23 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-15-æ›´æ–°"><a href="#2025-07-15-æ›´æ–°" class="headerlink" title="2025-07-15 æ›´æ–°"></a>2025-07-15 æ›´æ–°</h1><h2 id="MIDI-VALLE-Improving-Expressive-Piano-Performance-Synthesis-Through-Neural-Codec-Language-Modelling"><a href="#MIDI-VALLE-Improving-Expressive-Piano-Performance-Synthesis-Through-Neural-Codec-Language-Modelling" class="headerlink" title="MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through   Neural Codec Language Modelling"></a>MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through   Neural Codec Language Modelling</h2><p><strong>Authors:Jingjing Tang, Xin Wang, Zhe Zhang, Junichi Yamagishi, Geraint Wiggins, George Fazekas</strong></p>
<p>Generating expressive audio performances from music scores requires models to capture both instrument acoustics and human interpretation. Traditional music performance synthesis pipelines follow a two-stage approach, first generating expressive performance MIDI from a score, then synthesising the MIDI into audio. However, the synthesis models often struggle to generalise across diverse MIDI sources, musical styles, and recording environments. To address these challenges, we propose MIDI-VALLE, a neural codec language model adapted from the VALLE framework, which was originally designed for zero-shot personalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio synthesis, we improve the architecture to condition on a reference audio performance and its corresponding MIDI. Unlike previous TTS-based systems that rely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens, facilitating a more consistent and robust modelling of piano performances. Furthermore, the modelâ€™s generalisation ability is enhanced by training on an extensive and diverse piano performance dataset. Evaluation results show that MIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving over 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the listening test, MIDI-VALLE received 202 votes compared to 58 for the baseline, demonstrating improved synthesis quality and generalisation across diverse performance MIDI inputs. </p>
<blockquote>
<p>ä»ä¹è°±ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„éŸ³é¢‘è¡¨æ¼”éœ€è¦æ¨¡å‹æ•æ‰ä¹å™¨çš„å£°å­¦ç‰¹æ€§å’Œäººç±»è§£é‡Šã€‚ä¼ ç»ŸéŸ³ä¹è¡¨æ¼”åˆæˆç®¡é“éµå¾ªä¸¤é˜¶æ®µæ–¹æ³•ï¼Œé¦–å…ˆæ ¹æ®ä¹è°±ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„æ€§èƒ½MIDIï¼Œç„¶åå°†MIDIåˆæˆéŸ³é¢‘ã€‚ç„¶è€Œï¼Œåˆæˆæ¨¡å‹å¾€å¾€éš¾ä»¥åœ¨ä¸åŒMIDIæºã€éŸ³ä¹é£æ ¼å’Œå½•éŸ³ç¯å¢ƒä¹‹é—´è¿›è¡Œæ³›åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MIDI-VALLEï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºVALLEæ¡†æ¶çš„ç¥ç»ç½‘ç»œç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ã€‚VALLEæ¡†æ¶æœ€åˆæ˜¯ä¸ºé›¶æ ·æœ¬ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆè€Œè®¾è®¡çš„ã€‚å¯¹äºæ€§èƒ½MIDIåˆ°éŸ³é¢‘åˆæˆï¼Œæˆ‘ä»¬æ”¹è¿›äº†æ¶æ„ï¼Œä½¿å…¶ä¾èµ–äºå‚è€ƒéŸ³é¢‘è¡¨æ¼”åŠå…¶å¯¹åº”çš„MIDIã€‚ä¸ä¹‹å‰çš„åŸºäºTTSçš„ç³»ç»Ÿä¸åŒï¼ŒMIDI-VALLEå°†MIDIå’ŒéŸ³é¢‘éƒ½ç¼–ç ä¸ºç¦»æ•£ä»¤ç‰Œï¼Œä»è€Œæ›´ä¸€è‡´ã€æ›´ç¨³å¥åœ°å»ºæ¨¡é’¢ç´æ¼”å¥ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨å¹¿æ³›ä¸”å¤šæ ·çš„é’¢ç´è¡¨æ¼”æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMIDI-VALLEæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œåœ¨ATEPPå’ŒMaestroæ•°æ®é›†ä¸Šçš„FrechetéŸ³é¢‘è·ç¦»é™ä½äº†75%ä»¥ä¸Šã€‚åœ¨è†å¬æµ‹è¯•ä¸­ï¼ŒMIDI-VALLEè·å¾—äº†202ç¥¨ï¼Œè€ŒåŸºçº¿æ¨¡å‹ä»…è·å¾—58ç¥¨ï¼Œè¿™è¯æ˜äº†å…¶åœ¨åˆæˆè´¨é‡å’Œä¸åŒæ€§èƒ½MIDIè¾“å…¥çš„æ³›åŒ–æ–¹é¢çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08530v1">PDF</a> Accepted by ISMIR 2025</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æå‡ºäº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„è¯­è¨€æ¨¡å‹MIDI-VALLEï¼Œç”¨äºä»ä¹è°±ç”Ÿæˆè¡¨è¾¾æ€§éŸ³é¢‘è¡¨æ¼”ã€‚è¯¥æ¨¡å‹é€‚åº”äºVALLEæ¡†æ¶ï¼Œå¹¶æ”¹è¿›äº†æ¶æ„ä»¥å‚è€ƒéŸ³é¢‘è¡¨æ¼”å’Œå…¶å¯¹åº”çš„MIDIã€‚MIDI-VALLEåœ¨æ€§èƒ½MIDIåˆ°éŸ³é¢‘åˆæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ•ˆæœï¼Œé€šè¿‡ç¼–ç MIDIå’ŒéŸ³é¢‘ä½œä¸ºç¦»æ•£ç¬¦å·ï¼Œå®ç°äº†æ›´ä¸€è‡´å’Œç¨³å¥çš„é’¢ç´è¡¨æ¼”å»ºæ¨¡ã€‚æ¨¡å‹åœ¨å¤§é‡å’Œå¤šæ ·åŒ–çš„é’¢ç´è¡¨æ¼”æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¢å¼ºäº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>MIDI-VALLEæ˜¯ä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„è¯­è¨€æ¨¡å‹ï¼Œç”¨äºä»éŸ³ä¹ä¹è°±ç”Ÿæˆè¡¨è¾¾æ€§éŸ³é¢‘è¡¨æ¼”ã€‚</li>
<li>è¯¥æ¨¡å‹é‡‡ç”¨VALLEæ¡†æ¶ï¼Œå¹¶è¿›è¡Œäº†æ”¹è¿›ï¼Œä»¥å‚è€ƒéŸ³é¢‘è¡¨æ¼”å’Œå…¶å¯¹åº”çš„MIDIã€‚</li>
<li>MIDI-VALLEé€šè¿‡å°†MIDIå’ŒéŸ³é¢‘ç¼–ç ä¸ºç¦»æ•£ç¬¦å·ï¼Œå®ç°äº†æ›´ä¸€è‡´å’Œç¨³å¥çš„é’¢ç´è¡¨æ¼”å»ºæ¨¡ã€‚</li>
<li>æ¨¡å‹åœ¨å¹¿æ³›çš„å¤šæ ·åŒ–é’¢ç´è¡¨æ¼”æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¢å¼ºäº†å…¶æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>MIDI-VALLEæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯åŸºçº¿ï¼Œåœ¨ATEPPå’ŒMaestroæ•°æ®é›†ä¸Šçš„Frechet Audio Distanceé™ä½äº†75%ä»¥ä¸Šã€‚</li>
<li>å¬è§‰æµ‹è¯•è¡¨æ˜ï¼ŒMIDI-VALLEçš„åˆæˆè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æé«˜ï¼Œè·å¾—äº†202ç¥¨ç›¸å¯¹äºåŸºçº¿çš„58ç¥¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08530">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3c93c74d72de36bd1b8d363a7e3ae663.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edcc70467f3a9f18b1ac61847e5017d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-afd55da3c99e80e0f22508f2328f15b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80d49da0e4516c6cfac71a7a17c7c702.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91d1847feafaa6c1fd0fa7687a0d373e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6bae166c75251b2a218fa23012d2e6f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ILT-Iterative-LoRA-Training-through-Focus-Feedback-Fix-for-Multilingual-Speech-Recognition"><a href="#ILT-Iterative-LoRA-Training-through-Focus-Feedback-Fix-for-Multilingual-Speech-Recognition" class="headerlink" title="ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual   Speech Recognition"></a>ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual   Speech Recognition</h2><p><strong>Authors:Qingliang Meng, Hao Wu, Wei Liang, Wei Xu, Qing Zhao</strong></p>
<p>The deep integration of large language models and automatic speech recognition systems has become a promising research direction with high practical value. To address the overfitting issue commonly observed in Low-Rank Adaptation (LoRA) during the supervised fine-tuning (SFT) stage, this work proposes an innovative training paradigm Iterative LoRA Training (ILT) in combination with an Iterative Pseudo Labeling strategy, effectively enhancing the theoretical upper bound of model performance. Based on Whisper-large-v3 and Qwen2-Audio, we conduct systematic experiments using a three-stage training process: Focus Training, Feed Back Training, and Fix Training. Experimental results demonstrate the effectiveness of the proposed method. Furthermore, the MegaAIS research team applied this technique in the Interspeech 2025 Multilingual Conversational Speech Language Modeling Challenge (MLC-SLM), achieving 4th in Track 1 (Multilingual ASR Task) and 1st place in Track 2 (Speech Separation and Recognition Task), showcasing the practical feasibility and strong application potential of our approach. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„æ·±åº¦èåˆå·²æˆä¸ºå…·æœ‰æé«˜å®ç”¨ä»·å€¼çš„ç ”ç©¶æ–¹å‘ã€‚é’ˆå¯¹ä½ç§©é€‚é…ï¼ˆLoRAï¼‰åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰é˜¶æ®µç»å¸¸å‡ºç°çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ›æ–°çš„è®­ç»ƒèŒƒå¼â€”â€”è¿­ä»£LoRAè®­ç»ƒï¼ˆILTï¼‰ï¼Œå¹¶ç»“åˆè¿­ä»£ä¼ªæ ‡ç­¾ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°æé«˜äº†æ¨¡å‹æ€§èƒ½çš„ç†è®ºä¸Šé™ã€‚åŸºäºWhisper-large-v3å’ŒQwen2-Audioï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒè¿‡ç¨‹è¿›è¡Œç³»ç»Ÿå®éªŒï¼šä¸“æ³¨è®­ç»ƒã€åé¦ˆè®­ç»ƒå’Œå›ºå®šè®­ç»ƒã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒMegaAISç ”ç©¶å›¢é˜Ÿåœ¨Interspeech 2025å¤šè¯­ç§å¯¹è¯è¯­éŸ³è¯­è¨€å»ºæ¨¡æŒ‘æˆ˜èµ›ï¼ˆMLC-SLMï¼‰ä¸­åº”ç”¨äº†è¿™ä¸€æŠ€æœ¯ï¼Œåœ¨èµ›é“1ï¼ˆå¤šè¯­ç§ASRä»»åŠ¡ï¼‰ä¸­è·å¾—ç¬¬4åï¼Œèµ›é“2ï¼ˆè¯­éŸ³åˆ†ç¦»ä¸è¯†åˆ«ä»»åŠ¡ï¼‰ä¸­è·å¾—ç¬¬1åï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„å®é™…å¯è¡Œæ€§å’Œå¼ºå¤§çš„åº”ç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08477v1">PDF</a> Accepted By Interspeech 2025 MLC-SLM workshop as a Research Paper</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„æ·±åº¦æ•´åˆå·²æˆä¸ºå…·æœ‰å®é™…ä»·å€¼çš„ç ”ç©¶æ–¹å‘ã€‚ä¸ºè§£å†³ä½ç§©é€‚é…ï¼ˆLoRAï¼‰åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰é˜¶æ®µå¸¸è§çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºè¿­ä»£ä½ç§©é€‚é…è®­ç»ƒï¼ˆILTï¼‰ç»“åˆè¿­ä»£ä¼ªæ ‡ç­¾ç­–ç•¥ï¼Œæœ‰æ•ˆæé«˜äº†æ¨¡å‹æ€§èƒ½çš„ç†è®ºä¸Šé™ã€‚åŸºäºWhisper-large-v3å’ŒQwen2-Audioï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒè¿‡ç¨‹è¿›è¡Œç³»ç»ŸåŒ–å®éªŒï¼šä¸“æ³¨è®­ç»ƒã€åé¦ˆè®­ç»ƒå’Œå›ºå®šè®­ç»ƒã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒMegaAISç ”ç©¶å›¢é˜Ÿåœ¨Interspeech 2025å¤šè¯­è¨€å¯¹è¯è¯­éŸ³è¯†åˆ«è¯­è¨€å»ºæ¨¡æŒ‘æˆ˜èµ›ï¼ˆMLC-SLMï¼‰ä¸­åº”ç”¨æ­¤æŠ€æœ¯ï¼Œåˆ†åˆ«åœ¨å¤šè¯­è¨€ASRä»»åŠ¡å’Œè¯­éŸ³åˆ†ç¦»ä¸è¯†åˆ«ä»»åŠ¡ä¸­å–å¾—ç¬¬4åå’Œç¬¬1åçš„æˆç»©ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„å®é™…åº”ç”¨æ½œåŠ›å’Œå¼ºå¤§ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„æ·±åº¦æ•´åˆå…·æœ‰å®é™…ä»·å€¼ã€‚</li>
<li>è¿­ä»£ä½ç§©é€‚é…è®­ç»ƒï¼ˆILTï¼‰ç»“åˆè¿­ä»£ä¼ªæ ‡ç­¾ç­–ç•¥è§£å†³äº†ä½ç§©é€‚é…ï¼ˆLoRAï¼‰åœ¨ç›‘ç£å¾®è°ƒé˜¶æ®µçš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>ä¸‰é˜¶æ®µè®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸“æ³¨è®­ç»ƒã€åé¦ˆè®­ç»ƒå’Œå›ºå®šè®­ç»ƒã€‚</li>
<li>åŸºäºWhisper-large-v3å’ŒQwen2-Audioçš„ç³»ç»ŸåŒ–å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>MegaAISç ”ç©¶å›¢é˜Ÿåœ¨MLC-SLMæ¯”èµ›ä¸­å–å¾—äº†æ˜¾è‘—æˆç»©ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šè¯­è¨€ASRä»»åŠ¡ä¸­å–å¾—äº†ç¬¬4åçš„æˆç»©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08477">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fa0a70581c20bf0808b15299a341648f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-11e1811f371ee9727b9f328519c36bb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab1099b778b1fa9609bb529706a7b6ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ee977f5e4157cbe18d7ae5740dc6abe.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RawTFNet-A-Lightweight-CNN-Architecture-for-Speech-Anti-spoofing"><a href="#RawTFNet-A-Lightweight-CNN-Architecture-for-Speech-Anti-spoofing" class="headerlink" title="RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing"></a>RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing</h2><p><strong>Authors:Yang Xiao, Ting Dang, Rohan Kumar Das</strong></p>
<p>Automatic speaker verification (ASV) systems are often affected by spoofing attacks. Recent transformer-based models have improved anti-spoofing performance by learning strong feature representations. However, these models usually need high computing power. To address this, we introduce RawTFNet, a lightweight CNN model designed for audio signals. The RawTFNet separates feature processing along time and frequency dimensions, which helps to capture the fine-grained details of synthetic speech. We tested RawTFNet on the ASVspoof 2021 LA and DF evaluation datasets. The results show that RawTFNet reaches comparable performance to that of the state-of-the-art models, while also using fewer computing resources. The code and models will be made publicly available. </p>
<blockquote>
<p>è‡ªåŠ¨è¯´è¯äººéªŒè¯ï¼ˆASVï¼‰ç³»ç»Ÿç»å¸¸å—åˆ°æ¬ºéª—æ”»å‡»çš„å½±å“ã€‚æœ€è¿‘åŸºäºTransformerçš„æ¨¡å‹é€šè¿‡å­¦ä¹ å¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºï¼Œæé«˜äº†é˜²æ¬ºéª—æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡çš„è®¡ç®—èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†RawTFNetï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºéŸ³é¢‘ä¿¡å·è®¾è®¡çš„è½»é‡çº§CNNæ¨¡å‹ã€‚RawTFNetåœ¨æ—¶é—´ç»´åº¦å’Œé¢‘ç‡ç»´åº¦ä¸Šåˆ†ç¦»ç‰¹å¾å¤„ç†ï¼Œæœ‰åŠ©äºæ•æ‰åˆæˆè¯­éŸ³çš„ç²¾ç»†ç»†èŠ‚ã€‚æˆ‘ä»¬åœ¨ASVspoof 2021 LAå’ŒDFè¯„ä¼°æ•°æ®é›†ä¸Šæµ‹è¯•äº†RawTFNetã€‚ç»“æœè¡¨æ˜ï¼ŒRawTFNetçš„æ€§èƒ½è¾¾åˆ°äº†æœ€æ–°æ¨¡å‹çš„æ°´å¹³ï¼ŒåŒæ—¶ä½¿ç”¨çš„è®¡ç®—èµ„æºæ›´å°‘ã€‚ä»£ç å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08227v1">PDF</a> Submitted to APSIPA ASC 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è‡ªåŠ¨è¯´è¯äººéªŒè¯ï¼ˆASVï¼‰ç³»ç»Ÿé¢ä¸´çš„æ–°å‹æ¬ºéª—æ”»å‡»é—®é¢˜ã€‚ä¸ºäº†æ”¹å–„å¯¹æ¬ºéª—è¡Œä¸ºçš„é˜²å¾¡èƒ½åŠ›å¹¶å‡å°‘è®¡ç®—éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºRawTFNetçš„è½»é‡çº§CNNæ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ²¿æ—¶é—´å’Œé¢‘ç‡ç»´åº¦åˆ†ç¦»ç‰¹å¾å¤„ç†ï¼Œä»¥æ•æ‰åˆæˆè¯­éŸ³çš„ç²¾ç»†ç»†èŠ‚ã€‚åœ¨ASVspoof 2021 LAå’ŒDFè¯„ä¼°æ•°æ®é›†ä¸Šçš„æµ‹è¯•æ˜¾ç¤ºï¼ŒRawTFNetä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”è¡¨ç°ç›¸å½“ï¼ŒåŒæ—¶ä½¿ç”¨çš„è®¡ç®—èµ„æºæ›´å°‘ã€‚ä»£ç å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨è¯´è¯äººéªŒè¯ï¼ˆASVï¼‰ç³»ç»Ÿæ˜“å—æ¬ºéª—æ”»å‡»çš„å½±å“ã€‚</li>
<li>æœ€æ–°åŸºäºTransformerçš„æ¨¡å‹é€šè¿‡å¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºæé«˜äº†æŠ—æ¬ºéª—æ€§èƒ½ã€‚</li>
<li>RawTFNetæ˜¯ä¸€ä¸ªè½»é‡çº§çš„CNNæ¨¡å‹ï¼Œé’ˆå¯¹éŸ³é¢‘ä¿¡å·è®¾è®¡ï¼Œæ—¨åœ¨è§£å†³è®¡ç®—èµ„æºéœ€æ±‚é«˜çš„é—®é¢˜ã€‚</li>
<li>RawTFNetèƒ½å¤Ÿæ²¿æ—¶é—´å’Œé¢‘ç‡ç»´åº¦åˆ†ç¦»ç‰¹å¾å¤„ç†ï¼Œä»¥æ•æ‰åˆæˆè¯­éŸ³çš„ç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>åœ¨ASVspoof 2021 LAå’ŒDFè¯„ä¼°æ•°æ®é›†ä¸Šçš„æµ‹è¯•æ˜¾ç¤ºï¼ŒRawTFNetæ€§èƒ½ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸å½“ã€‚</li>
<li>RawTFNetä½¿ç”¨è¾ƒå°‘çš„è®¡ç®—èµ„æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08227">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-67f3036ab2994f288b72e5665efb600b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47e23a3ce8958916e78152bd4534195b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-93f90270ea58cf2fdbf53a84cf1b51b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b3ecd41c2f65d168bc9731b36cb98ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-217b405c2ac5bb700f5ea2941d1ae499.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DARAS-Dynamic-Audio-Room-Acoustic-Synthesis-for-Blind-Room-Impulse-Response-Estimation"><a href="#DARAS-Dynamic-Audio-Room-Acoustic-Synthesis-for-Blind-Room-Impulse-Response-Estimation" class="headerlink" title="DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse   Response Estimation"></a>DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse   Response Estimation</h2><p><strong>Authors:Chunxi Wang, Maoshen Jia, Wenyu Jin</strong></p>
<p>Room Impulse Responses (RIRs) accurately characterize acoustic properties of indoor environments and play a crucial role in applications such as speech enhancement, speech recognition, and audio rendering in augmented reality (AR) and virtual reality (VR). Existing blind estimation methods struggle to achieve practical accuracy. To overcome this challenge, we propose the dynamic audio-room acoustic synthesis (DARAS) model, a novel deep learning framework that is explicitly designed for blind RIR estimation from monaural reverberant speech signals. First, a dedicated deep audio encoder effectively extracts relevant nonlinear latent space features. Second, the Mamba-based self-supervised blind room parameter estimation (MASS-BRPE) module, utilizing the efficient Mamba state space model (SSM), accurately estimates key room acoustic parameters and features. Third, the system incorporates a hybrid-path cross-attention feature fusion module, enhancing deep integration between audio and room acoustic features. Finally, our proposed dynamic acoustic tuning (DAT) decoder adaptively segments early reflections and late reverberation to improve the realism of synthesized RIRs. Experimental results, including a MUSHRA-based subjective listening study, demonstrate that DARAS substantially outperforms existing baseline models, providing a robust and effective solution for practical blind RIR estimation in real-world acoustic environments. </p>
<blockquote>
<p>å®¤å†…ç¯å¢ƒçš„å£°å­¦ç‰¹æ€§å¯ä»¥é€šè¿‡æˆ¿é—´è„‰å†²å“åº”ï¼ˆRIRsï¼‰æ¥å‡†ç¡®è¡¨å¾ï¼Œå…¶åœ¨è¯­éŸ³å¢å¼ºã€è¯­éŸ³è¯†åˆ«ä»¥åŠå¢å¼ºç°å®ï¼ˆARï¼‰å’Œè™šæ‹Ÿç°å®ï¼ˆVRï¼‰ä¸­çš„éŸ³é¢‘æ¸²æŸ“ç­‰åº”ç”¨ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç°æœ‰çš„ç›²ä¼°è®¡æ–¹æ³•å¾ˆéš¾è¾¾åˆ°å®ç”¨çš„å‡†ç¡®åº¦ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€éŸ³é¢‘æˆ¿é—´å£°å­¦åˆæˆï¼ˆDARASï¼‰æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºä»å•å£°é“æ··å“è¯­éŸ³ä¿¡å·ä¸­ç›²ä¼°è®¡RIRsè€Œè®¾è®¡çš„æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚é¦–å…ˆï¼Œä¸“ç”¨çš„æ·±åº¦éŸ³é¢‘ç¼–ç å™¨æœ‰æ•ˆåœ°æå–äº†ç›¸å…³çš„éçº¿æ€§æ½œåœ¨ç©ºé—´ç‰¹å¾ã€‚å…¶æ¬¡ï¼ŒåŸºäºMambaçš„è‡ªç›‘ç£ç›²æˆ¿é—´å‚æ•°ä¼°è®¡ï¼ˆMASS-BRPEï¼‰æ¨¡å—ï¼Œåˆ©ç”¨é«˜æ•ˆçš„MambaçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ï¼Œå‡†ç¡®ä¼°è®¡äº†å…³é”®çš„æˆ¿é—´å£°å­¦å‚æ•°å’Œç‰¹å¾ã€‚ç¬¬ä¸‰ï¼Œç³»ç»Ÿç»“åˆäº†ä¸€ä¸ªæ··åˆè·¯å¾„äº¤å‰æ³¨æ„ç‰¹å¾èåˆæ¨¡å—ï¼Œå¢å¼ºäº†éŸ³é¢‘å’Œæˆ¿é—´å£°å­¦ç‰¹å¾ä¹‹é—´çš„æ·±åº¦é›†æˆã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºçš„åŠ¨æ€å£°å­¦è°ƒæ•´ï¼ˆDATï¼‰è§£ç å™¨è‡ªé€‚åº”åœ°åˆ†å‰²æ—©æœŸåå°„å’ŒåæœŸå›å“ï¼Œæé«˜äº†åˆæˆRIRsçš„çœŸå®æ€§ã€‚åŒ…æ‹¬åŸºäºMUSHRAçš„ä¸»è§‚å¬è§‰ç ”ç©¶åœ¨å†…çš„å®éªŒç»“æœè¯æ˜ï¼ŒDARASåœ¨çœŸå®ä¸–ç•Œå£°å­¦ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œä¸ºå®ç”¨ç›²RIRä¼°è®¡æä¾›äº†ç¨³å¥æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08135v1">PDF</a> 14 pages, 9 figures, submitted to IEEE&#x2F;ACM Transactions on Audio,   Speech, and Language Processing</p>
<p><strong>Summary</strong></p>
<p>å®¤å†…ç¯å¢ƒå£°éŸ³ç‰¹æ€§çš„ç²¾å‡†æè¿°å¯¹äºè¯­éŸ³å¢å¼ºã€è¯­éŸ³è¯†åˆ«ä»¥åŠå¢å¼ºç°å®ï¼ˆARï¼‰å’Œè™šæ‹Ÿç°å®ï¼ˆVRï¼‰ä¸­çš„éŸ³é¢‘æ¸²æŸ“ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚ç°æœ‰ç›²ä¼°è®¡æ–¹æ³•éš¾ä»¥è¾¾åˆ°å®ç”¨ç²¾åº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€éŸ³é¢‘æˆ¿é—´å£°å­¦åˆæˆï¼ˆDARASï¼‰æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡ç”¨äºä»å•å£°é“æ··å“è¯­éŸ³ä¿¡å·ä¸­ç›²ä¼°è®¡RIRçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚å®ƒé€šè¿‡æ·±åº¦éŸ³é¢‘ç¼–ç å™¨æå–éçº¿æ€§æ½œåœ¨ç©ºé—´ç‰¹å¾ï¼Œåˆ©ç”¨åŸºäºMambaçš„SSMæ¨¡å—ä¼°è®¡æˆ¿é—´å£°å­¦å‚æ•°ï¼ŒèåˆéŸ³é¢‘ä¸æˆ¿é—´å£°å­¦ç‰¹å¾ï¼Œå¹¶é€šè¿‡åŠ¨æ€å£°å­¦è°ƒéŸ³è§£ç å™¨æé«˜åˆæˆRIRçš„çœŸå®æ„Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDARASåœ¨çœŸå®ä¸–ç•Œå£°å­¦ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RIRsåœ¨å®¤å†…ç¯å¢ƒå£°éŸ³ç‰¹æ€§è¡¨å¾ä¸­èµ·å…³é”®ä½œç”¨ï¼Œå¯¹è¯­éŸ³å¢å¼ºå’Œè¯†åˆ«ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰ç›²ä¼°è®¡æ–¹æ³•å­˜åœ¨å®è·µä¸­çš„å‡†ç¡®æ€§æŒ‘æˆ˜ã€‚</li>
<li>DARASæ¨¡å‹æ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨ä»æ··å“çš„è¯­éŸ³ä¿¡å·ä¸­ç›²ä¼°è®¡RIRã€‚</li>
<li>DARASåŒ…å«æ·±åº¦éŸ³é¢‘ç¼–ç å™¨ã€åŸºäºMambaçš„SSMæ¨¡å—ã€ç‰¹å¾èåˆæ¨¡å—å’ŒåŠ¨æ€å£°å­¦è°ƒéŸ³è§£ç å™¨ã€‚</li>
<li>æ·±åº¦éŸ³é¢‘ç¼–ç å™¨èƒ½æœ‰æ•ˆæå–éçº¿æ€§æ½œåœ¨ç©ºé—´ç‰¹å¾ã€‚</li>
<li>åŸºäºMambaçš„SSMæ¨¡å—ç”¨äºå‡†ç¡®ä¼°è®¡å…³é”®æˆ¿é—´å£°å­¦å‚æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08135">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f46350f9f60ed11f1a6f552945584bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7eccd25906e072f0ade3804e976dfc24.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fb2a9eeb69047b6fc8f3d76477b9bba9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55dd36aeda90d58f8bb74d816e8c030f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Modele-physique-variationnel-pour-lâ€™estimation-de-reponses-impulsionnelles-de-salles"><a href="#Modele-physique-variationnel-pour-lâ€™estimation-de-reponses-impulsionnelles-de-salles" class="headerlink" title="ModÃ¨le physique variationnel pour lâ€™estimation de rÃ©ponses   impulsionnelles de salles"></a>ModÃ¨le physique variationnel pour lâ€™estimation de rÃ©ponses   impulsionnelles de salles</h2><p><strong>Authors:Louis Lalay, Mathieu Fontaine, Roland Badeau</strong></p>
<p>Room impulse response estimation is essential for tasks like speech dereverberation, which improves automatic speech recognition. Most existing methods rely on either statistical signal processing or deep neural networks designed to replicate signal processing principles. However, combining statistical and physical modeling for RIR estimation remains largely unexplored. This paper proposes a novel approach integrating both aspects through a theoretically grounded model. The RIR is decomposed into interpretable parameters: white Gaussian noise filtered by a frequency-dependent exponential decay (e.g. modeling wall absorption) and an autoregressive filter (e.g. modeling microphone response). A variational free-energy cost function enables practical parameter estimation. As a proof of concept, we show that given dry and reverberant speech signals, the proposed method outperforms classical deconvolution in noisy environments, as validated by objective metrics. </p>
<blockquote>
<p>æˆ¿é—´è„‰å†²å“åº”ï¼ˆRoom Impulse Responseï¼Œç®€ç§°RIRï¼‰ä¼°è®¡æ˜¯è¯­éŸ³å»æ··å“ä»»åŠ¡çš„å…³é”®ï¼Œè¯¥ä»»åŠ¡èƒ½æé«˜è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ•ˆæœã€‚ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•ä¾èµ–äºç»Ÿè®¡ä¿¡å·å¤„ç†æˆ–æ¨¡æ‹Ÿä¿¡å·å¤„ç†åŸç†çš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œå°†ç»Ÿè®¡å’Œç‰©ç†å»ºæ¨¡ç»“åˆç”¨äºRIRä¼°è®¡ä»ç„¶æ˜¯ä¸€ä¸ªæœªè¢«å……åˆ†ç ”ç©¶çš„é¢†åŸŸã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»“åˆè¿™ä¸¤æ–¹é¢ç†è®ºçš„æ–°æ–¹æ³•ã€‚RIRè¢«åˆ†è§£ä¸ºå¯è§£é‡Šçš„å‚æ•°ï¼šç»è¿‡é¢‘ç‡ç›¸å…³æŒ‡æ•°è¡°å‡ï¼ˆå¦‚æ¨¡æ‹Ÿå¢™å£å¸æ”¶ï¼‰å’Œç™½é«˜æ–¯å™ªå£°æ»¤æ³¢çš„ä»¥åŠä¸€ä¸ªè‡ªå›å½’æ»¤æ³¢å™¨ï¼ˆå¦‚æ¨¡æ‹Ÿéº¦å…‹é£å“åº”ï¼‰ã€‚ä¸€ä¸ªå˜åˆ†è‡ªç”±èƒ½ä»£ä»·å‡½æ•°å®ç°äº†å®é™…çš„å‚æ•°ä¼°è®¡ã€‚ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç»™å®šå¹²ç‡¥å’Œæ··å“è¯­éŸ³ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œåœ¨å™ªå£°ç¯å¢ƒä¸­ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å®¢è§‚æŒ‡æ ‡ä¸Šçš„è¡¨ç°ä¼˜äºç»å…¸çš„å»å·ç§¯æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08051v1">PDF</a> in French language. GRETSI, Aug 2025, Strasbourg (67000), France</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆç»Ÿè®¡å’Œç‰©ç†å»ºæ¨¡çš„æˆ¿é—´è„‰å†²å“åº”ï¼ˆRoom Impulse Responseï¼ŒRIRï¼‰ä¼°è®¡æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†RIRåˆ†è§£æˆå¯è§£é‡Šçš„å‚æ•°ï¼ŒåŒ…æ‹¬é€šè¿‡é¢‘ç‡ç›¸å…³æŒ‡æ•°è¡°å‡æ¨¡æ‹Ÿå¢™å£å¸æ”¶å’Œé€šè¿‡è‡ªå›å½’æ»¤æ³¢å™¨æ¨¡æ‹Ÿéº¦å…‹é£å“åº”çš„ç™½è‰²é«˜æ–¯å™ªå£°ã€‚é‡‡ç”¨å˜åˆ†è‡ªç”±èƒ½æˆæœ¬å‡½æ•°å®ç°å‚æ•°ä¼°è®¡ã€‚ç›¸è¾ƒäºç»å…¸å»å·ç§¯æ–¹æ³•ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å™ªå£°ç¯å¢ƒä¸‹è¡¨ç°æ›´ä¼˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡å¼ºè°ƒäº†æˆ¿é—´è„‰å†²å“åº”ä¼°è®¡åœ¨è¯­éŸ³å»æ··å“ä»»åŠ¡ä¸­çš„é‡è¦æ€§ï¼Œè¯¥ä»»åŠ¡èƒ½æé«˜è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ•ˆæœã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ç»Ÿè®¡ä¿¡å·å¤„ç†æˆ–æ·±åº¦ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿä¿¡å·å¤„ç†åŸç†ï¼Œä½†ç»“åˆç»Ÿè®¡å’Œç‰©ç†å»ºæ¨¡çš„RIRä¼°è®¡å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆç»Ÿè®¡å’Œç‰©ç†å»ºæ¨¡çš„æ–°æ–¹æ³•ï¼Œå°†RIRåˆ†è§£æˆå¯è§£é‡Šçš„å‚æ•°ï¼ŒåŒ…æ‹¬æ¨¡æ‹Ÿå¢™å£å¸æ”¶å’Œéº¦å…‹é£å“åº”çš„æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨å˜åˆ†è‡ªç”±èƒ½æˆæœ¬å‡½æ•°è¿›è¡Œå‚æ•°ä¼°è®¡ï¼Œå®ç°ç†è®ºæ”¯æ’‘å’Œå®è·µåº”ç”¨çš„æœ‰æ•ˆç»“åˆã€‚</li>
<li>ä¸ç»å…¸å»å·ç§¯æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„è¡¨ç°æ›´ä¼˜è¶Šã€‚</li>
<li>æœ¬æ–‡ä¸ä»…æä¾›äº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œè¿˜æœ‰å…·ä½“çš„å®éªŒç»“æœï¼Œé€šè¿‡å®¢è§‚åº¦é‡éªŒè¯äº†å…¶æ€§èƒ½ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08051">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c9e48079e2512a3d9af16d9b1095355f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3102a99b97345b570b82db859f4fa83c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1ded785586bd4b7f90d0ef013e2f559.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Riemannian-Time-Warping-Multiple-Sequence-Alignment-in-Curved-Spaces"><a href="#Riemannian-Time-Warping-Multiple-Sequence-Alignment-in-Curved-Spaces" class="headerlink" title="Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces"></a>Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces</h2><p><strong>Authors:Julian Richter, Christopher ErdÃ¶s, Christian Scheurer, Jochen J. Steil, Niels Dehio</strong></p>
<p>Temporal alignment of multiple signals through time warping is crucial in many fields, such as classification within speech recognition or robot motion learning. Almost all related works are limited to data in Euclidean space. Although an attempt was made in 2011 to adapt this concept to unit quaternions, a general extension to Riemannian manifolds remains absent. Given its importance for numerous applications in robotics and beyond, we introduce Riemannian Time Warping (RTW). This novel approach efficiently aligns multiple signals by considering the geometric structure of the Riemannian manifold in which the data is embedded. Extensive experiments on synthetic and real-world data, including tests with an LBR iiwa robot, demonstrate that RTW consistently outperforms state-of-the-art baselines in both averaging and classification tasks. </p>
<blockquote>
<p>å¤šä¿¡å·çš„æ—¶é—´æ‰­æ›²çš„æ—¶é—´å¯¹é½åœ¨å¤šä¸ªé¢†åŸŸï¼ˆå¦‚è¯­éŸ³è¯†åˆ«æˆ–æœºå™¨äººè¿åŠ¨å­¦ä¹ ä¸­çš„åˆ†ç±»ï¼‰ä¸­è‡³å…³é‡è¦ã€‚å‡ ä¹æ‰€æœ‰ç›¸å…³å·¥ä½œéƒ½å±€é™äºæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æ•°æ®ã€‚å°½ç®¡åœ¨2011å¹´æœ‰äººè¯•å›¾å°†æ­¤æ¦‚å¿µé€‚åº”äºå•ä½å››å…ƒæ•°ï¼Œä½†å°šæœªå°†å…¶æ¨å¹¿åˆ°é»æ›¼æµå½¢ã€‚è€ƒè™‘åˆ°å…¶åœ¨æœºå™¨äººæŠ€æœ¯ç­‰å¤šä¸ªé¢†åŸŸçš„é‡è¦æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†é»æ›¼æ—¶é—´æ‰­æ›²ï¼ˆRTWï¼‰ã€‚è¿™ç§æ–¹æ³•é€šè¿‡è€ƒè™‘æ•°æ®åµŒå…¥çš„é»æ›¼æµå½¢çš„å‡ ä½•ç»“æ„æ¥æœ‰æ•ˆåœ°å¯¹é½å¤šä¸ªä¿¡å·ã€‚åœ¨åˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„å¹¿æ³›å®éªŒä»¥åŠå¯¹LBR iiwaæœºå™¨äººçš„æµ‹è¯•è¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨å¹³å‡ä»»åŠ¡è¿˜æ˜¯åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒRTWå§‹ç»ˆä¼˜äºæœ€æ–°çš„åŸºå‡†æµ‹è¯•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01635v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†é’ˆå¯¹é»æ›¼æµå½¢ä¸Šçš„æ—¶é—´åºåˆ—æ•°æ®çš„æ—¶é—´æ‹‰ä¼¸æ–¹æ³•ï¼ˆRiemannian Time Warpingï¼ŒRTWï¼‰ã€‚è€ƒè™‘åˆ°æ•°æ®å†…åµŒçš„é»æ›¼æµå½¢çš„å‡ ä½•ç»“æ„ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°å¯¹é½å¤šä¸ªä¿¡å·ï¼Œä¸”åœ¨åˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„å¤§é‡å®éªŒä»¥åŠå¯¹LBR iiwaæœºå™¨äººçš„æµ‹è¯•å‡è¯æ˜äº†å…¶åœ¨å¹³å‡å’Œåˆ†ç±»ä»»åŠ¡ä¸Šçš„ä¸€è‡´ä¼˜ç§€è¡¨ç°ã€‚è¯¥æ–¹æ³•çš„å¼•å…¥å¯¹æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>è¦ç‚¹æç‚¼</strong></p>
<ol>
<li>æ—¶é—´æ‹‰ä¼¸æŠ€æœ¯åœ¨è®¸å¤šé¢†åŸŸå¦‚è¯­éŸ³è¯†åˆ«æˆ–æœºå™¨äººè¿åŠ¨å­¦ä¹ ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>ç›®å‰ç›¸å…³å·¥ä½œå¤§å¤šå±€é™äºæ¬§å‡ é‡Œå¾—ç©ºé—´çš„æ•°æ®å¤„ç†ã€‚</li>
<li>è™½ç„¶å·²æœ‰å°è¯•å°†æ—¶é—´æ‹‰ä¼¸æ¦‚å¿µé€‚åº”äºå•ä½å››å…ƒæ•°ï¼Œä½†å…¶åœ¨é»æ›¼æµå½¢ä¸Šçš„é€šç”¨æ‰©å±•ä»ç„¶ç¼ºå¤±ã€‚</li>
<li>å¼•å…¥çš„Riemannian Time Warpingï¼ˆRTWï¼‰æ–¹æ³•è€ƒè™‘åˆ°æ•°æ®å†…åµŒçš„é»æ›¼æµå½¢çš„å‡ ä½•ç»“æ„ï¼Œæœ‰æ•ˆå¯¹é½å¤šä¸ªä¿¡å·ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒRTWåœ¨å¹³å‡å’Œåˆ†ç±»ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¸”è¡¨ç°ç¨³å®šã€‚</li>
<li>RTWæ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨äººæŠ€æœ¯é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2e5f74c62ee6bce420abda027b9d7faa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83ae0378cbf3da662aecbd7a75af4895.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19b4aef7943e0bf946ecfb0942eb60c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8edf569a39679f1d05b6f32c032f3104.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3b6a9ee7f143c78e36bedd816a53046.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-171135d0842e0bea48b3d3981853b3fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d612bf694e16f7e4fe76604d00050cd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-850b38fd781563baf865fb4c81ce0712.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c3f2f01f840277aabb6cd8c43d49675.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="End-to-end-multi-channel-speaker-extraction-and-binaural-speech-synthesis"><a href="#End-to-end-multi-channel-speaker-extraction-and-binaural-speech-synthesis" class="headerlink" title="End-to-end multi-channel speaker extraction and binaural speech   synthesis"></a>End-to-end multi-channel speaker extraction and binaural speech   synthesis</h2><p><strong>Authors:Cheng Chi, Xiaoyu Li, Yuxuan Ke, Qunping Ni, Yao Ge, Xiaodong Li, Chengshi Zheng</strong></p>
<p>Speech clarity and spatial audio immersion are the two most critical factors in enhancing remote conferencing experiences. Existing methods are often limited: either due to the lack of spatial information when using only one microphone, or because their performance is highly dependent on the accuracy of direction-of-arrival estimation when using microphone array. To overcome this issue, we introduce an end-to-end deep learning framework that has the capacity of mapping multi-channel noisy and reverberant signals to clean and spatialized binaural speech directly. This framework unifies source extraction, noise suppression, and binaural rendering into one network. In this framework, a novel magnitude-weighted interaural level difference loss function is proposed that aims to improve the accuracy of spatial rendering. Extensive evaluations show that our method outperforms established baselines in terms of both speech quality and spatial fidelity. </p>
<blockquote>
<p>è¯­éŸ³æ¸…æ™°åº¦ä¸ç©ºé—´éŸ³é¢‘æ²‰æµ¸æ„Ÿæ˜¯æå‡è¿œç¨‹ä¼šè®®ä½“éªŒçš„ä¸¤ä¸ªå…³é”®å› ç´ ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å­˜åœ¨å±€é™æ€§ï¼šæœ‰çš„å› ä¸ºåªä½¿ç”¨å•ä¸ªéº¦å…‹é£è€Œç¼ºä¹ç©ºé—´ä¿¡æ¯ï¼›æœ‰çš„åœ¨é¢å¯¹å™ªéŸ³å’Œä½¿ç”¨å›å£°ä¿¡å·æ—¶ï¼Œå…¶æ€§èƒ½é«˜åº¦ä¾èµ–äºåˆ°è¾¾æ–¹å‘ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰å°†å¤šé€šé“å™ªéŸ³å’Œå›å£°ä¿¡å·ç›´æ¥æ˜ å°„ä¸ºå¹²å‡€ä¸”ç©ºé—´åŒ–çš„åŒè€³è¯­éŸ³çš„èƒ½åŠ›ã€‚è¯¥æ¡†æ¶å°†å£°æºæå–ã€é™å™ªå’ŒåŒè€³æ¸²æŸ“é›†æˆåˆ°ä¸€ä¸ªç½‘ç»œä¸­ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¹…åº¦åŠ æƒåŒè€³æ°´å¹³å·®æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨æé«˜ç©ºé—´æ¸²æŸ“çš„å‡†ç¡®æ€§ã€‚å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¯­éŸ³è´¨é‡å’Œç©ºé—´ä¿çœŸåº¦æ–¹é¢éƒ½ä¼˜äºæ—¢å®šçš„åŸºçº¿æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.05739v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå°†ä»å¤šé€šé“å™ªå£°å’Œæ··å“ä¿¡å·æ˜ å°„åˆ°å¹²å‡€ä¸”ç©ºé—´åŒ–çš„åŒè€³è¯­éŸ³ã€‚æ­¤æ¡†æ¶èåˆäº†æºæå–ã€å™ªå£°æŠ‘åˆ¶å’ŒåŒè€³æ¸²æŸ“ï¼Œæ—¨åœ¨æé«˜è¿œç¨‹ä¼šè®®ä½“éªŒçš„å…³é”®è¦ç´ â€”â€”è¯­éŸ³æ¸…æ™°åº¦å’Œç©ºé—´éŸ³é¢‘æ²‰æµ¸æ„Ÿã€‚é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„å¹…åº¦åŠ æƒè€³é—´æ°´å¹³å·®æŸå¤±å‡½æ•°ï¼Œæé«˜äº†ç©ºé—´æ¸²æŸ“çš„å‡†ç¡®æ€§ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯­éŸ³è´¨é‡å’Œç©ºé—´ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³æ¸…æ™°åº¦å’Œç©ºé—´éŸ³é¢‘æ²‰æµ¸æ„Ÿæ˜¯å¢å¼ºè¿œç¨‹ä¼šè®®ä½“éªŒçš„ä¸¤ä¸ªå…³é”®å› ç´ ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å› åªä½¿ç”¨å•ä¸€éº¦å…‹é£ç¼ºä¹ç©ºé—´ä¿¡æ¯ï¼Œæˆ–å› ä½¿ç”¨éº¦å…‹é£é˜µåˆ—æ—¶æ–¹å‘åˆ°è¾¾ä¼°è®¡çš„å‡†ç¡®æ€§è€Œå—é™ã€‚</li>
<li>æå‡ºä¸€ç§ç«¯åˆ°ç«¯çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ•´åˆæºæå–ã€å™ªå£°æŠ‘åˆ¶å’ŒåŒè€³æ¸²æŸ“ã€‚</li>
<li>å¼•å…¥æ–°çš„å¹…åº¦åŠ æƒè€³é—´æ°´å¹³å·®æŸå¤±å‡½æ•°ï¼Œä»¥æé«˜ç©ºé—´æ¸²æŸ“çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½æé«˜è¯­éŸ³è´¨é‡å’Œç©ºé—´ä¿çœŸåº¦ã€‚</li>
<li>ç›¸æ¯”ç°æœ‰åŸºçº¿ï¼Œæ­¤æ¡†æ¶åœ¨å¤šä¸ªæ–¹é¢çš„æ€§èƒ½è¡¨ç°æ›´ä¼˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.05739">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f128e0475f362abe26b1a5a2427cf86.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b81546d22e7e63f29f9a28eb8ba66617.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df0e74fc052fdaa4a796d4eb8b9564c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06e65c06a7862cfa0083c49f9653cb62.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-15/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1747f79b835510c7748e17d50823c705.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-15  Image Translation with Kernel Prediction Networks for Semantic   Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-15/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1cf4f2ef235a1b3be34ad7fc00fb35f2.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-15  DArFace Deformation Aware Robustness for Low Quality Face Recognition
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23827k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
