<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-07-15  CRMAgent A Multi-Agent LLM System for E-Commerce CRM Message Template   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-7dd653e6498b2fddf65cee6e9b4b88a5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    27 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-15-更新"><a href="#2025-07-15-更新" class="headerlink" title="2025-07-15 更新"></a>2025-07-15 更新</h1><h2 id="CRMAgent-A-Multi-Agent-LLM-System-for-E-Commerce-CRM-Message-Template-Generation"><a href="#CRMAgent-A-Multi-Agent-LLM-System-for-E-Commerce-CRM-Message-Template-Generation" class="headerlink" title="CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template   Generation"></a>CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template   Generation</h2><p><strong>Authors:Yinzhu Quan, Xinrui Li, Ying Chen</strong></p>
<p>In e-commerce private-domain channels such as instant messaging and e-mail, merchants engage customers directly as part of their Customer Relationship Management (CRM) programmes to drive retention and conversion. While a few top performers excel at crafting outbound messages, most merchants struggle to write persuasive copy because they lack both expertise and scalable tools. We introduce CRMAgent, a multi-agent system built on large language models (LLMs) that generates high-quality message templates and actionable writing guidance through three complementary modes. First, group-based learning enables the agent to learn from a merchant’s own top-performing messages within the same audience segment and rewrite low-performing ones. Second, retrieval-and-adaptation fetches templates that share the same audience segment and exhibit high similarity in voucher type and product category, learns their successful patterns, and adapts them to the current campaign. Third, a rule-based fallback provides a lightweight zero-shot rewrite when no suitable references are available. Extensive experiments show that CRMAgent consistently outperforms merchants’ original templates, delivering significant gains in both audience-match and marketing-effectiveness metrics. </p>
<blockquote>
<p>在电子商务私域渠道，如即时通讯和电子邮件中，商家会将其作为客户关系管理（CRM）计划的一部分，直接与客户进行互动，以促进客户留存和转化。虽然一些表现突出的商家擅长制作外发消息，但大多数商家在撰写有说服力的文案时感到困难，因为他们既缺乏专业知识，又没有可规模化使用的工具。我们在此介绍CRMAgent，这是一个基于大型语言模型（LLM）的多智能体系统，它通过三种互补模式生成高质量的消息模板和可操作的写作指导。首先，基于群体学习可以让智能体从同一受众群体内部商家表现最佳的消息中学习，并改写表现不佳的消息。其次，检索与适应模式会检索与当前受众群体相同、优惠券类型和商品类别高度相似的模板，学习它们的成功模式并适应当前活动。最后，基于规则的备用方案在没有合适的参考可用时提供一种轻便的零样本重写方法。大量实验表明，CRMAgent始终优于商家的原始模板，在受众匹配和营销有效性指标上取得了显著的提升。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08325v1">PDF</a> </p>
<p><strong>Summary</strong><br>电商私域渠道如即时通讯和电子邮件中，商家通过CRM计划直接与客户沟通以驱动用户留存和转化。虽然顶级商家擅长编写外发消息，但多数商家由于缺乏专业和可扩展工具在撰写说服性文案方面面临挑战。我们推出CRMAgent多智能体系统，基于大型语言模型生成高质量信息模板和可操作的写作指导，通过三种模式进行互补。实验证明，CRMAgent在受众匹配和营销有效性指标上表现优于商家原始模板，实现了显著增长。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>商家在CRM计划中通过私域渠道直接与客户沟通以提高用户留存和转化。</li>
<li>虽然部分顶级商家擅长撰写外发消息，但大多数商家面临编写说服性文案的挑战。</li>
<li>缺乏专业和可扩展的文案工具是商家面临的主要问题。</li>
<li>CRMAgent是一个多智能体系统，基于大型语言模型生成高质量信息模板和写作指导。</li>
<li>CRMAgent通过三种模式进行互补：基于群组学习、检索和适应以及规则基础回退。</li>
<li>实验证明CRMAgent在受众匹配和营销有效性方面表现优于商家原始模板。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08325">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-37e3937499e385fa584090a20b63c127.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8419a0f18472589540c8500fc7d69732.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-75c6f6720f9928aed80bf152c162302e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ad38b82d1dee86f6f8fa1f1456ada12.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce0c08965746275f5932bc1d48395b2a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61312efc4fd97e0a334c794ff4eb115f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-817e245f65248f6e27360d68ceb4eeba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-35a15a268e0eb48ba1e9d712ea97ff03.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Transfer-Learning-and-Mixup-for-Fine-Grained-Few-Shot-Fungi-Classification"><a href="#Transfer-Learning-and-Mixup-for-Fine-Grained-Few-Shot-Fungi-Classification" class="headerlink" title="Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi   Classification"></a>Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi   Classification</h2><p><strong>Authors:Jason Kahei Tam, Murilo Gustineli, Anthony Miyaguchi</strong></p>
<p>Accurate identification of fungi species presents a unique challenge in computer vision due to fine-grained inter-species variation and high intra-species variation. This paper presents our approach for the FungiCLEF 2025 competition, which focuses on few-shot fine-grained visual categorization (FGVC) using the FungiTastic Few-Shot dataset. Our team (DS@GT) experimented with multiple vision transformer models, data augmentation, weighted sampling, and incorporating textual information. We also explored generative AI models for zero-shot classification using structured prompting but found them to significantly underperform relative to vision-based models. Our final model outperformed both competition baselines and highlighted the effectiveness of domain specific pretraining and balanced sampling strategies. Our approach ranked 35&#x2F;74 on the private test set in post-completion evaluation, this suggests additional work can be done on metadata selection and domain-adapted multi-modal learning. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/dsgt-arc/fungiclef-2025">https://github.com/dsgt-arc/fungiclef-2025</a>. </p>
<blockquote>
<p>真菌物种的精确识别在计算机视觉领域是一项独特的挑战，因为存在物种间的细微差异和物种内部的巨大差异。本文针对FungiCLEF 2025竞赛提出了一种方法，该方法聚焦于使用FungiTastic Few-Shot数据集的少样本精细粒度视觉分类（FGVC）。我们团队（DS@GT）对多种视觉转换器模型、数据增强、加权采样和文本信息融合进行了实验。我们还探索了基于生成式人工智能模型的零样本分类，使用结构化提示，但发现与基于视觉的模型相比，其性能显著较差。我们的最终模型超越了竞赛基线，突显了领域特定预训练和平衡采样策略的有效性。在完成后评估的私有测试集上，我们的方法排名第35&#x2F;74，这表明可以在元数据选择和领域适应的多模式学习方面做进一步的工作。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/dsgt-arc/fungiclef-2025%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/dsgt-arc/fungiclef-2025找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08248v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>这篇论文针对FungiCLEF 2025竞赛提出了一种基于视觉的少样本精细分类方法。研究团队尝试使用多种视觉Transformer模型、数据增强、加权采样和文本信息融合等技术。尽管探索了基于生成式AI的零样本分类方法，但发现其性能显著落后于视觉模型。最终模型在竞赛中的表现优于基线模型，突显了领域特定预训练和平衡采样策略的有效性。排名为第35名，表明在元数据选择和领域自适应多模态学习方面还有提升空间。代码已公开。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>论文针对FungiCLEF 2025竞赛，提出了基于视觉的少样本精细分类方法。</li>
<li>研究团队使用了多种视觉Transformer模型进行尝试。</li>
<li>数据增强和加权采样技术被用于提升模型性能。</li>
<li>融合了文本信息，但基于生成式AI的零样本分类方法表现不佳。</li>
<li>最终模型表现优于竞赛基线，凸显了领域特定预训练和平衡采样策略的重要性。</li>
<li>模型在私有测试集上的排名为第35名，提示需要在元数据选择和领域自适应多模态学习方面进行进一步的研究。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08248">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d467179ee25fcabfe505ae7dd6f0480d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27031bb84067593a7e0eed9e272f48e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2042db1aefbd1f9f5d9534201f03951c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f343a4c0ad283fb82f06a2e9d7edac24.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1985e9288d3a156d9738b293341a174.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dbb8e0d6ae58fb09de07e6bb1e50487.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-036ae0abf1e72f606c48ada92a7d1c62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-64e07e2540a0fa0b0a6b74f4a83fde41.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GRASP-Generic-Reasoning-And-SPARQL-Generation-across-Knowledge-Graphs"><a href="#GRASP-Generic-Reasoning-And-SPARQL-Generation-across-Knowledge-Graphs" class="headerlink" title="GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs"></a>GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs</h2><p><strong>Authors:Sebastian Walter, Hannah Bast</strong></p>
<p>We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples. </p>
<blockquote>
<p>我们提出了一种新的基于大规模语言模型的自然语言的SPARQL查询生成方法，用于在RDF知识图上构建查询。我们的方法无需精细调整。相反，它通过策略性地执行SPARQL查询并搜索相关的IRI和字面量来探索知识图谱。我们在各种基准测试集（针对不同类型和规模的知识图谱）和语言模型（不同规模和类型，包括商业和开源）上评估了我们的方法，并将其与现有方法进行了比较。在WikiData上，尽管我们采用了零样本设置，但在多个基准测试集上取得了最新结果。在Freebase上，我们的表现接近最佳的小样本方法。在其他较少评估的知识图谱和基准测试集上，我们的方法总体上表现良好。我们还进行了其他额外研究，如比较不同的图形搜索方式、引入反馈机制或利用小样本示例等。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08107v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新的方法，利用大型语言模型从自然语言问题或关键词查询生成SPARQL查询语句，对RDF知识图谱进行查询。该方法无需精细调整，而是通过执行战略性的SPARQL查询和搜索相关的IRI和字面量来探索知识图谱。该方法在不同的知识图谱和多种语言模型上进行了评估，并与现有方法进行了比较。在Wikidata上，该方法在多个基准测试上达到了最新的技术成果水平；在Freebase上的性能也接近最先进的几种技术；对于其他知识图谱和基准测试的表现整体也较好。本研究还包括各种额外的研究分析，比如对比不同图谱搜索方式、加入反馈机制和利用少数样例进行学习等。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种基于大型语言模型的生成SPARQL查询的新方法，适用于RDF知识图谱的自然语言查询。</li>
<li>方法无需精细调整，而是通过执行战略性SPARQL查询和探索知识图谱来工作。</li>
<li>在多种基准测试上进行了评估，包括不同类型和规模的知识图谱以及不同规模和类型的语言模型。</li>
<li>在Wikidata上的性能达到了最新的技术成果水平。</li>
<li>在Freebase上的性能接近最先进的少数技术。</li>
<li>对于其他知识图谱的查询性能整体表现良好。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08107">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-2ae9d15fd27a99ee08c2e4df0d79369b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3c8181573066225406325d63f882f51.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Beyond-Scale-Small-Language-Models-are-Comparable-to-GPT-4-in-Mental-Health-Understanding"><a href="#Beyond-Scale-Small-Language-Models-are-Comparable-to-GPT-4-in-Mental-Health-Understanding" class="headerlink" title="Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental   Health Understanding"></a>Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental   Health Understanding</h2><p><strong>Authors:Hong Jia, Shiya Fu, Vassilis Kostakos, Feng Xia, Ting Dang</strong></p>
<p>The emergence of Small Language Models (SLMs) as privacy-preserving alternatives for sensitive applications raises a fundamental question about their inherent understanding capabilities compared to Large Language Models (LLMs). This paper investigates the mental health understanding capabilities of current SLMs through systematic evaluation across diverse classification tasks. Employing zero-shot and few-shot learning paradigms, we benchmark their performance against established LLM baselines to elucidate their relative strengths and limitations in this critical domain. We assess five state-of-the-art SLMs (Phi-3, Phi-3.5, Qwen2.5, Llama-3.2, Gemma2) against three LLMs (GPT-4, FLAN-T5-XXL, Alpaca-7B) on six mental health understanding tasks. Our findings reveal that SLMs achieve mean performance within 2% of LLMs on binary classification tasks (F1 scores of 0.64 vs 0.66 in zero-shot settings), demonstrating notable competence despite orders of magnitude fewer parameters. Both model categories experience similar degradation on multi-class severity tasks (a drop of over 30%), suggesting that nuanced clinical understanding challenges transcend model scale. Few-shot prompting provides substantial improvements for SLMs (up to 14.6%), while LLM gains are more variable. Our work highlights the potential of SLMs in mental health understanding, showing they can be effective privacy-preserving tools for analyzing sensitive online text data. In particular, their ability to quickly adapt and specialize with minimal data through few-shot learning positions them as promising candidates for scalable mental health screening tools. </p>
<blockquote>
<p>随着小型语言模型（SLMs）作为敏感应用的隐私保护替代方案的出现，关于它们与大型语言模型（LLMs）的内在理解能力的比较，提出了一个根本性的问题。本文通过系统评估各种分类任务来研究当前SLMs在心理健康理解方面的能力。我们采用零样本学习和小样本学习范式，以既定的LLM基线为标准来衡量它们在关键领域的性能表现，以阐明它们在心理健康领域的相对优势和局限性。我们评估了五个最先进的小型语言模型（Phi-3、Phi-3.5、Qwen2.5、Llama-3.2、Gemma2）与三个大型语言模型（GPT-4、FLAN-T5-XXL、Alpaca-7B）在六个心理健康理解任务上的表现。研究结果显示，小型语言模型在二元分类任务上的平均性能表现接近大型语言模型，二者的零样本模式下F1得分分别为0.64和0.66，表现出显著的竞争力，尽管参数数量方面差距巨大。在多元严重程度分类任务上，两个模型类别的表现均出现类似下降（下降幅度超过30%），这表明微妙的临床理解挑战超越了模型规模。小样本提示为小型语言模型提供了实质性的改进（最多提高了14.6%），而大型语言模型的收益则更加多变。我们的工作突出了小型语言模型在心理健康理解方面的潜力，表明它们可以作为分析敏感在线文本数据的有效隐私保护工具。尤其值得一提的是，它们通过小样本学习快速适应和专门化的能力，使它们成为可扩展心理健康筛查工具的绝佳候选者。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.08031v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>当前文本探讨了小型语言模型（SLMs）在心理健康理解方面的能力，通过与大型语言模型（LLMs）的对比研究，发现SLMs在二元分类任务中表现出较强的性能，并在少样本学习场景下实现了显著的提升。研究结果表明，SLMs在心理健康领域具有潜在的应用价值，尤其在于其能够快速适应并专业化处理少量数据的能力，使其成为心理健康筛查工具的有力候选者。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SLMs作为隐私保护工具在敏感应用中的兴起，与LLMs相比具有内在理解能力的挑战。</li>
<li>通过系统评价，研究了SLMs在心理健康理解方面的能力。</li>
<li>在二元分类任务中，SLMs性能与LLMs相近，F1分数在零样本场景中达到0.64。</li>
<li>少样本学习范式为SLMs带来了显著的性能提升。</li>
<li>在多类严重性任务中，两类模型都出现了类似的性能下降，表明临床理解的复杂性超越了模型规模。</li>
<li>SLMs在心理健康领域具有潜在应用价值，尤其在快速适应和处理少量数据方面表现突出。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.08031">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-0cb97af949cee6a999dca7f4f828f9ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7dd653e6498b2fddf65cee6e9b4b88a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7f81875b75bf5187e5f2e2364b229a2.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Doodle-Your-Keypoints-Sketch-Based-Few-Shot-Keypoint-Detection"><a href="#Doodle-Your-Keypoints-Sketch-Based-Few-Shot-Keypoint-Detection" class="headerlink" title="Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection"></a>Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection</h2><p><strong>Authors:Subhajit Maity, Ayan Kumar Bhunia, Subhadeep Koley, Pinaki Nath Chowdhury, Aneeshan Sain, Yi-Zhe Song</strong></p>
<p>Keypoint detection, integral to modern machine perception, faces challenges in few-shot learning, particularly when source data from the same distribution as the query is unavailable. This gap is addressed by leveraging sketches, a popular form of human expression, providing a source-free alternative. However, challenges arise in mastering cross-modal embeddings and handling user-specific sketch styles. Our proposed framework overcomes these hurdles with a prototypical setup, combined with a grid-based locator and prototypical domain adaptation. We also demonstrate success in few-shot convergence across novel keypoints and classes through extensive experiments. </p>
<blockquote>
<p>关键点检测是现代机器感知的核心，在少样本学习中面临挑战，尤其是在无法获取与查询相同分布的源数据时。为解决这一空白，本研究利用流行的人类表达形式——草图，提供一种无源的替代方案。然而，掌握跨模态嵌入和处理用户特定的草图风格存在挑战。我们提出的框架通过原型设置与基于网格的定位器和原型域适应相结合，克服了这些障碍。我们还通过大量实验证明了在新关键点和新类别上的少样本收敛成功。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07994v2">PDF</a> Accepted at ICCV 2025. Project Page: <a target="_blank" rel="noopener" href="https://subhajitmaity.me/DYKp">https://subhajitmaity.me/DYKp</a></p>
<p><strong>Summary</strong><br>在现代化机器感知中，关键点检测在面临少量学习数据挑战时尤其重要。由于缺乏与查询数据分布相同的来源数据，这一领域存在问题。本研究采用草图（一种常见的人类表达方式）作为无源的替代方案来解决此问题。然而，存在掌握跨模态嵌入和处理用户特定草图风格方面的挑战。本研究提出的框架通过原型设置、网格定位器和原型域适应克服了这些障碍，并通过大量实验成功实现了跨新型关键点和类别的少量收敛。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现代机器感知中的关键点检测面临了少数情况下的学习挑战。</li>
<li>缺乏与查询数据分布相同的来源数据成为了主要难题。</li>
<li>草图作为一种人类表达形式被用作解决此问题的无源的替代方案。</li>
<li>存在掌握跨模态嵌入和处理用户特定草图风格的挑战。</li>
<li>研究提出了一种基于原型的框架来解决这些挑战。</li>
<li>该框架结合了网格定位器和原型域适应技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07994">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a62804445456b6bd451f71a070c1a9a2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b6956a2cd400538e97c5a19d28bdc5bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7800874675488123f5524a13531d87f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69996e32d6d73a0e13c0d807d83a82d2.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Embedding-Space-Allocation-with-Angle-Norm-Joint-Classifiers-for-Few-Shot-Class-Incremental-Learning"><a href="#Embedding-Space-Allocation-with-Angle-Norm-Joint-Classifiers-for-Few-Shot-Class-Incremental-Learning" class="headerlink" title="Embedding Space Allocation with Angle-Norm Joint Classifiers for   Few-Shot Class-Incremental Learning"></a>Embedding Space Allocation with Angle-Norm Joint Classifiers for   Few-Shot Class-Incremental Learning</h2><p><strong>Authors:Dunwei Tu, Huiyu Yi, Tieyi Zhang, Ruotong Li, Furao Shen, Jian Zhao</strong></p>
<p>Few-shot class-incremental learning (FSCIL) aims to continually learn new classes from only a few samples without forgetting previous ones, requiring intelligent agents to adapt to dynamic environments. FSCIL combines the characteristics and challenges of class-incremental learning and few-shot learning: (i) Current classes occupy the entire feature space, which is detrimental to learning new classes. (ii) The small number of samples in incremental rounds is insufficient for fully training. In existing mainstream virtual class methods, for addressing the challenge (i), they attempt to use virtual classes as placeholders. However, new classes may not necessarily align with the virtual classes. For the challenge (ii), they replace trainable fully connected layers with Nearest Class Mean (NCM) classifiers based on cosine similarity, but NCM classifiers do not account for sample imbalance issues. To address these issues in previous methods, we propose the class-center guided embedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning framework, which provides balanced space for all classes and leverages norm differences caused by sample imbalance to enhance classification criteria. Specifically, for challenge (i), SAAN divides the feature space into multiple subspaces and allocates a dedicated subspace for each session by guiding samples with the pre-set category centers. For challenge (ii), SAAN establishes a norm distribution for each class and generates angle-norm joint logits. Experiments demonstrate that SAAN can achieve state-of-the-art performance and it can be directly embedded into other SOTA methods as a plug-in, further enhancing their performance. </p>
<blockquote>
<p>少量样本类增量学习（FSCIL）旨在从仅有的少量样本中持续学习新的类别，同时不遗忘之前学过的内容，这需要智能代理适应动态环境。FSCIL结合了类增量学习和少量样本学习的特性和挑战：（i）当前类别占据了整个特征空间，这对学习新类别是不利的。（ii）增量轮次中的样本数量很少，不足以进行充分训练。在现有的主流虚拟类方法中，为了解决挑战（i），他们尝试使用虚拟类作为占位符。然而，新类别并不一定与虚拟类别对齐。对于挑战（ii），他们基于余弦相似性，用可训练的全连接层替换最近类均值（NCM）分类器，但NCM分类器并没有解决样本不平衡问题。为了解决之前方法中的这些问题，我们提出了类中心引导嵌入空间分配与角度范数联合分类器（SAAN）学习框架，它为所有类别提供了平衡的空间，并利用样本不平衡引起的范数差异来增强分类标准。具体来说，对于挑战（i），SAAN将特征空间划分为多个子空间，并通过预设的类别中心引导样本，为每一轮分配一个专用的子空间。对于挑战（ii），SAAN为每一类建立范数分布，并生成角度-范数联合逻辑。实验表明，SAAN可以达到最先进的性能，并且可以作为插件直接嵌入到其他SOTA方法中，进一步提高其性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.09250v2">PDF</a> This paper has been accepted to Neural Networks</p>
<p><strong>Summary</strong>：<br>本文介绍了面向持续学习的Few-Shot类增量学习（FSCIL）技术，该技术旨在从少量样本中持续学习新类别而又不遗忘已学类别。针对当前类别占据整个特征空间不利于学习新类别以及样本量不足的问题，本文提出了一个名为SAAN的学习框架，通过划分特征空间为多个子空间并为每个会话分配专用子空间来解决第一个问题；通过建立每个类别的范数分布并生成角度范数联合对数来解决第二个问题。实验表明，SAAN可以达到最新技术水平，并且可以嵌入到其他先进方法中作为插件来提高性能。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>Few-shot class-incremental learning (FSCIL)的目标是在不断变化的动态环境中，从有限的样本中学习新的类别，同时保留对旧类别的知识。</li>
<li>当前的主流方法使用虚拟类作为占位符来解决特征空间占用问题，但新类别可能与虚拟类不匹配。</li>
<li>现有方法采用基于余弦相似度的最近类均值（NCM）分类器解决样本数量不足的问题，但忽略了样本不平衡的问题。</li>
<li>SAAN学习框架通过划分特征空间并引导样本到预设的类别中心来解决特征空间占用问题。</li>
<li>SAAN建立每个类别的范数分布并生成角度范数联合对数来解决样本不平衡和数量不足的问题。</li>
<li>实验表明SAAN在性能上达到了最新技术水平，并且可以与其他先进方法结合使用以提高性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.09250">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-845c83dcc802c5a36e23cfff9ff5da03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa1b6cd4ac6446bf099bd6e1ae49ba74.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SQLNet-Scale-Modulated-Query-and-Localization-Network-for-Few-Shot-Class-Agnostic-Counting"><a href="#SQLNet-Scale-Modulated-Query-and-Localization-Network-for-Few-Shot-Class-Agnostic-Counting" class="headerlink" title="SQLNet: Scale-Modulated Query and Localization Network for Few-Shot   Class-Agnostic Counting"></a>SQLNet: Scale-Modulated Query and Localization Network for Few-Shot   Class-Agnostic Counting</h2><p><strong>Authors:Hefeng Wu, Yandong Chen, Lingbo Liu, Tianshui Chen, Keze Wang, Liang Lin</strong></p>
<p>The class-agnostic counting (CAC) task has recently been proposed to solve the problem of counting all objects of an arbitrary class with several exemplars given in the input image. To address this challenging task, existing leading methods all resort to density map regression, which renders them impractical for downstream tasks that require object locations and restricts their ability to well explore the scale information of exemplars for supervision. To address the limitations, we propose a novel localization-based CAC approach, termed Scale-modulated Query and Localization Network (SQLNet). It fully explores the scales of exemplars in both the query and localization stages and achieves effective counting by accurately locating each object and predicting its approximate size. Specifically, during the query stage, rich discriminative representations of the target class are acquired by the Hierarchical Exemplars Collaborative Enhancement (HECE) module from the few exemplars through multi-scale exemplar cooperation with equifrequent size prompt embedding. These representations are then fed into the Exemplars-Unified Query Correlation (EUQC) module to interact with the query features in a unified manner and produce the correlated query tensor. In the localization stage, the Scale-aware Multi-head Localization (SAML) module utilizes the query tensor to predict the confidence, location, and size of each potential object. Moreover, a scale-aware localization loss is introduced, which exploits flexible location associations and exemplar scales for supervision to optimize the model performance. Extensive experiments demonstrate that SQLNet outperforms state-of-the-art methods on popular CAC benchmarks, achieving excellent performance not only in counting accuracy but also in localization and bounding box generation. Our codes will be available at <a target="_blank" rel="noopener" href="https://github.com/HCPLab-SYSU/SQLNet">https://github.com/HCPLab-SYSU/SQLNet</a> </p>
<blockquote>
<p>类不可知计数（CAC）任务最近被提出，以解决在输入图像中给定多个范例时计数任意类所有对象的问题。针对这一具有挑战性的任务，现有的领先方法都依赖于密度图回归，这使得它们对于需要对象位置的下游任务不实用，并限制了它们探索范例规模信息的能力以进行监督。为了解决这些局限性，我们提出了一种基于定位的新颖CAC方法，称为Scale-modulated Query and Localization Network（SQLNet）。它在查询和定位阶段充分探索了范例的规模，并通过准确定位每个对象和预测其近似大小来实现有效的计数。具体来说，在查询阶段，通过多层次范例协同增强（HECE）模块从少量范例中获取目标类的丰富判别表示，通过多尺度范例合作和等频大小提示嵌入获得这些表示。然后，这些表示被送入范例统一查询关联（EUQC）模块，以统一的方式与查询特征进行交互，并产生相关查询张量。在定位阶段，规模感知多头定位（SAML）模块利用查询张量来预测每个潜在对象的置信度、位置和大小。此外，引入了一种规模感知定位损失，它利用灵活的定位关联和范例规模进行监督，以优化模型性能。大量实验表明，SQLNet在流行的CAC基准测试中优于最新方法，不仅在计数精度方面表现出色，而且在定位和边界框生成方面也表现出色。我们的代码将在<a target="_blank" rel="noopener" href="https://github.com/HCPLab-SYSU/SQLNet%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/HCPLab-SYSU/SQLNet上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.10011v2">PDF</a> Accepted by IEEE Transactions on Image Processing</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于定位的经典无关计数（CAC）任务新方法，名为Scale-modulated Query and Localization Network（SQLNet）。该方法在查询和定位阶段充分利用了范例的尺度信息，通过精准定位每个对象并预测其大致尺寸，实现了有效的计数。实验表明，SQLNet在流行的CAC基准测试上优于现有方法，不仅在计数精度上表现优异，而且在定位和生成边界框方面也表现出色。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>经典无关计数（CAC）任务旨在解决在输入图像中计数任意类所有对象的问题。</li>
<li>现有领先方法主要依赖密度图回归，这不适用于需要对象位置的下游任务，且限制了范例尺度信息的探索。</li>
<li>SQLNet方法提出一种基于定位的解决方案，在查询和定位阶段充分利用范例的尺度信息。</li>
<li>SQLNet通过精准定位每个对象并预测其大小来实现有效计数。</li>
<li>Hierarchical Exemplars Collaborative Enhancement（HECE）模块通过多尺度范例合作和等频尺寸提示嵌入，获取目标类的丰富判别表示。</li>
<li>Exemplars-Unified Query Correlation（EUQC）模块以统一的方式与查询特征进行交互，产生相关的查询张量。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.10011">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-6bcf32f2f8ef54e6677ee1ba062df27d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc84b6c23472ba91fc3510f1c462168d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cfbbc7f0cccebeab3681ffb761c338f7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7fdb1b55ad2fef552c1605e64565c496.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-15/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-15/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-06141ec7d553d036b4c79353a4e0fe89.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-07-15  Image Translation with Kernel Prediction Networks for Semantic   Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-15/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-da22ec7125b2e2c1673700753687782e.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-07-15  Introspection of Thought Helps AI Agents
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25691.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
