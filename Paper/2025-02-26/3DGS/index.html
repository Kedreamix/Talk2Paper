<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-fd176e18b81a2c84abb8d2ea93fa1eed.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    64 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-26-æ›´æ–°"><a href="#2025-02-26-æ›´æ–°" class="headerlink" title="2025-02-26 æ›´æ–°"></a>2025-02-26 æ›´æ–°</h1><h2 id="Graph-Guided-Scene-Reconstruction-from-Images-with-3D-Gaussian-Splatting"><a href="#Graph-Guided-Scene-Reconstruction-from-Images-with-3D-Gaussian-Splatting" class="headerlink" title="Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting"></a>Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting</h2><p><strong>Authors:Chong Cheng, Gaochao Song, Yiyang Yao, Qinzheng Zhou, Gangjian Zhang, Hao Wang</strong></p>
<p>This paper investigates an open research challenge of reconstructing high-quality, large 3D open scenes from images. It is observed existing methods have various limitations, such as requiring precise camera poses for input and dense viewpoints for supervision. To perform effective and efficient 3D scene reconstruction, we propose a novel graph-guided 3D scene reconstruction framework, GraphGS. Specifically, given a set of images captured by RGB cameras on a scene, we first design a spatial prior-based scene structure estimation method. This is then used to create a camera graph that includes information about the camera topology. Further, we propose to apply the graph-guided multi-view consistency constraint and adaptive sampling strategy to the 3D Gaussian Splatting optimization process. This greatly alleviates the issue of Gaussian points overfitting to specific sparse viewpoints and expedites the 3D reconstruction process. We demonstrate GraphGS achieves high-fidelity 3D reconstruction from images, which presents state-of-the-art performance through quantitative and qualitative evaluation across multiple datasets. Project Page: <a target="_blank" rel="noopener" href="https://3dagentworld.github.io/graphgs">https://3dagentworld.github.io/graphgs</a>. </p>
<blockquote>
<p>æœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªå¼€æ”¾çš„ç ”ç©¶æŒ‘æˆ˜ï¼Œå³ä»å›¾åƒé‡å»ºé«˜è´¨é‡çš„å¤§å‹3Då¼€æ”¾åœºæ™¯ã€‚è§‚å¯Ÿåˆ°ç°æœ‰æ–¹æ³•å­˜åœ¨å„ç§å±€é™æ€§ï¼Œä¾‹å¦‚éœ€è¦ç²¾ç¡®çš„ç›¸æœºå§¿æ€ä½œä¸ºè¾“å…¥å’Œå¯†é›†çš„è§†ç‚¹è¿›è¡Œç›‘æ§ã€‚ä¸ºäº†è¿›è¡Œæœ‰æ•ˆçš„3Dåœºæ™¯é‡å»ºï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾å½¢å¼•å¯¼å¼é‡å»ºæ¡†æ¶GraphGSã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ç»„ç”±RGBç›¸æœºæ•æ‰çš„åœºæ™¯å›¾åƒï¼Œæˆ‘ä»¬é¦–å…ˆè®¾è®¡äº†ä¸€ç§åŸºäºç©ºé—´å…ˆéªŒçš„åœºæ™¯ç»“æ„ä¼°è®¡æ–¹æ³•ã€‚ç„¶åï¼Œè¯¥æ–¹æ³•è¢«ç”¨æ¥åˆ›å»ºä¸€ä¸ªåŒ…å«ç›¸æœºæ‹“æ‰‘ä¿¡æ¯çš„ç›¸æœºå›¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºå°†å›¾å½¢å¼•å¯¼çš„å¤šè§†è§’ä¸€è‡´æ€§çº¦æŸå’Œè‡ªé€‚åº”é‡‡æ ·ç­–ç•¥åº”ç”¨äº3Dé«˜æ–¯æ‹¼è´´ä¼˜åŒ–è¿‡ç¨‹ã€‚è¿™æå¤§åœ°å‡è½»äº†é«˜æ–¯ç‚¹å¯¹ç‰¹å®šç¨€ç–è§†ç‚¹çš„è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶åŠ é€Ÿäº†3Dé‡å»ºè¿‡ç¨‹ã€‚æˆ‘ä»¬è¯æ˜äº†GraphGSèƒ½å¤Ÿä»å›¾åƒå®ç°é«˜ä¿çœŸåº¦çš„3Dé‡å»ºï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šé€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°å±•ç°äº†å…¶å“è¶Šæ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://3dagentworld.github.io/graphgs">https://3dagentworld.github.io/graphgs</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17377v1">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong><br>åŸºäºå›¾åƒçš„é«˜è´¨é‡ä¸‰ç»´åœºæ™¯é‡å»ºæ˜¯ä¸€é¡¹å…¬å¼€çš„ç ”ç©¶æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„åŸºäºå›¾å¼•å¯¼çš„ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶GraphGSã€‚å®ƒèƒ½æœ‰æ•ˆåœ°ä»RGBç›¸æœºæ‹æ‘„çš„ä¸€ç»„å›¾åƒä¸­é‡å»ºåœºæ™¯ç»“æ„ï¼Œé€šè¿‡ç©ºé—´å…ˆéªŒä¼°è®¡åœºæ™¯ç»“æ„å¹¶å»ºç«‹ç›¸æœºå›¾ï¼Œåˆ©ç”¨å›¾å¼•å¯¼çš„å¤šè§†è§’ä¸€è‡´æ€§çº¦æŸå’Œè‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼Œå¯¹é«˜æ–¯æ¨¡ç³Šä¼˜åŒ–è¿‡ç¨‹è¿›è¡Œæ”¹è¿›ï¼Œå®ç°äº†é«˜è´¨é‡çš„ä¸‰ç»´é‡å»ºæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡é’ˆå¯¹ç°æœ‰ä¸‰ç»´åœºæ™¯é‡å»ºæ–¹æ³•å­˜åœ¨çš„å±€é™æ€§ï¼ˆå¦‚éœ€è¦ç²¾ç¡®ç›¸æœºå§¿æ€å’Œå¯†é›†è§†è§’è¿›è¡Œè¾“å…¥å’Œç›‘ç®¡ï¼‰æå‡ºäº†æ”¹è¿›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºå›¾å¼•å¯¼çš„ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶GraphGSã€‚</li>
<li>é€šè¿‡ç©ºé—´å…ˆéªŒä¼°è®¡åœºæ™¯ç»“æ„å¹¶å»ºç«‹ç›¸æœºå›¾ã€‚</li>
<li>åº”ç”¨äº†å›¾å¼•å¯¼çš„å¤šè§†è§’ä¸€è‡´æ€§çº¦æŸå’Œè‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼Œæ”¹å–„äº†é«˜æ–¯æ¨¡ç³Šä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä»·ï¼ŒGraphGSåœ¨å¤šæ•°æ®é›†ä¸Šå®ç°äº†å…ˆè¿›çš„ä¸‰ç»´é‡å»ºæ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½æœ‰æ•ˆåœ°ä»RGBç›¸æœºæ‹æ‘„çš„ä¸€ç»„å›¾åƒä¸­é‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17377">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ada5a6fa70b25b5c83afa0e07d57c856.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a76d0b4c71cc7807274aa8f6eaa4468.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa023889ab69a0cb8d684b6075e1dd13.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91fa0658467b9ccc3f1eaad30f11659a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GaussianFlowOcc-Sparse-and-Weakly-Supervised-Occupancy-Estimation-using-Gaussian-Splatting-and-Temporal-Flow"><a href="#GaussianFlowOcc-Sparse-and-Weakly-Supervised-Occupancy-Estimation-using-Gaussian-Splatting-and-Temporal-Flow" class="headerlink" title="GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using   Gaussian Splatting and Temporal Flow"></a>GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using   Gaussian Splatting and Temporal Flow</h2><p><strong>Authors:Simon Boeder, Fabian Gigengack, Benjamin Risse</strong></p>
<p>Occupancy estimation has become a prominent task in 3D computer vision, particularly within the autonomous driving community. In this paper, we present a novel approach to occupancy estimation, termed GaussianFlowOcc, which is inspired by Gaussian Splatting and replaces traditional dense voxel grids with a sparse 3D Gaussian representation. Our efficient model architecture based on a Gaussian Transformer significantly reduces computational and memory requirements by eliminating the need for expensive 3D convolutions used with inefficient voxel-based representations that predominantly represent empty 3D spaces. GaussianFlowOcc effectively captures scene dynamics by estimating temporal flow for each Gaussian during the overall network training process, offering a straightforward solution to a complex problem that is often neglected by existing methods. Moreover, GaussianFlowOcc is designed for scalability, as it employs weak supervision and does not require costly dense 3D voxel annotations based on additional data (e.g., LiDAR). Through extensive experimentation, we demonstrate that GaussianFlowOcc significantly outperforms all previous methods for weakly supervised occupancy estimation on the nuScenes dataset while featuring an inference speed that is 50 times faster than current SOTA. </p>
<blockquote>
<p>å ç”¨ä¼°è®¡å·²æˆä¸ºä¸‰ç»´è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªé‡è¦ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å ç”¨ä¼°è®¡æ–¹æ³•ï¼Œç§°ä¸ºGaussianFlowOccï¼Œå®ƒå—åˆ°é«˜æ–¯æ¶‚æŠ¹çš„å¯å‘ï¼Œç”¨ç¨€ç–çš„ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºæ›¿æ¢äº†ä¼ ç»Ÿçš„å¯†é›†ä½“ç´ ç½‘æ ¼ã€‚æˆ‘ä»¬åŸºäºé«˜æ–¯å˜æ¢å™¨çš„æœ‰æ•ˆæ¨¡å‹æ¶æ„ï¼Œé€šè¿‡æ¶ˆé™¤ä¸»è¦è¡¨ç¤ºç©ºä¸‰ç»´ç©ºé—´çš„ä½æ•ˆä½“ç´ è¡¨ç¤ºå½¢å¼æ‰€ä½¿ç”¨çš„é«˜æˆæœ¬ä¸‰ç»´å·ç§¯ï¼Œå¤§å¤§å‡å°‘äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚GaussianFlowOccé€šè¿‡åœ¨ç½‘ç»œæ•´ä½“è®­ç»ƒè¿‡ç¨‹ä¸­ä¼°è®¡æ¯ä¸ªé«˜æ–¯çš„æ—¶é—´æµæ¥æœ‰æ•ˆåœ°æ•æ‰åœºæ™¯åŠ¨æ€ï¼Œä¸ºè§£å†³ç°æœ‰æ–¹æ³•ç»å¸¸å¿½ç•¥çš„å¤æ‚é—®é¢˜æä¾›äº†ç›´æ¥è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼ŒGaussianFlowOccè®¾è®¡ç”¨äºå¯æ‰©å±•æ€§ï¼Œå› ä¸ºå®ƒé‡‡ç”¨å¼±ç›‘ç£ï¼Œå¹¶ä¸”ä¸éœ€è¦åŸºäºé¢å¤–æ•°æ®ï¼ˆä¾‹å¦‚æ¿€å…‰é›·è¾¾ï¼‰çš„æ˜‚è´µå¯†é›†ä¸‰ç»´ä½“ç´ æ³¨é‡Šã€‚é€šè¿‡å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯æ˜GaussianFlowOccåœ¨nuScenesæ•°æ®é›†ä¸Šçš„å¼±ç›‘ç£å ç”¨ä¼°è®¡æ–¹é¢å¤§å¤§ä¼˜äºæ‰€æœ‰ä»¥å‰çš„æ–¹æ³•ï¼ŒåŒæ—¶å…¶æ¨ç†é€Ÿåº¦æ¯”å½“å‰æœ€ä½³æŠ€æœ¯å¿«50å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17288v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å ç”¨ç‡ä¼°è®¡æ–¹æ³•ï¼Œç§°ä¸ºGaussianFlowOccã€‚è¯¥æ–¹æ³•å—åˆ°é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„å¯å‘ï¼Œé‡‡ç”¨ç¨€ç–çš„3Dé«˜æ–¯è¡¨ç¤ºæ›¿æ¢ä¼ ç»Ÿçš„å¯†é›†ä½“ç´ ç½‘æ ¼ã€‚åŸºäºé«˜æ–¯è½¬æ¢å™¨çš„æœ‰æ•ˆæ¨¡å‹æ¶æ„ï¼Œæ— éœ€ä½¿ç”¨è€—æ—¶çš„3Då·ç§¯å’Œæ•ˆç‡ä½ä¸‹çš„åŸºäºä½“ç´ çš„è¡¨ç¤ºæ–¹æ³•ï¼Œä»è€Œå¤§å¤§å‡å°‘äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚GaussianFlowOccé€šè¿‡åœ¨ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­ä¼°è®¡æ¯ä¸ªé«˜æ–¯çš„æ—¶é—´æµæ¥æœ‰æ•ˆåœ°æ•æ‰åœºæ™¯åŠ¨æ€ï¼Œä¸ºè§£å†³ç°æœ‰æ–¹æ³•ç»å¸¸å¿½ç•¥çš„å¤æ‚é—®é¢˜æä¾›äº†ç®€å•ç›´æ¥çš„è§£å†³æ–¹æ¡ˆã€‚æ­¤å¤–ï¼ŒGaussianFlowOccè®¾è®¡ç”¨äºå¯æ‰©å±•æ€§ï¼Œé‡‡ç”¨å¼±ç›‘ç£ï¼Œæ— éœ€åŸºäºé¢å¤–æ•°æ®ï¼ˆä¾‹å¦‚æ¿€å…‰é›·è¾¾ï¼‰çš„æ˜‚è´µå¯†é›†3Dä½“ç´ æ³¨é‡Šã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬åœ¨nuScenesæ•°æ®é›†ä¸Šè¯æ˜äº†GaussianFlowOccåœ¨å¼±ç›‘ç£å ç”¨ç‡ä¼°è®¡æ–¹é¢æ˜¾è‘—ä¼˜äºæ‰€æœ‰å…ˆå‰çš„æ–¹æ³•ï¼ŒåŒæ—¶å…¶æ¨ç†é€Ÿåº¦æ˜¯ç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹çš„50å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GaussianFlowOccæ˜¯ä¸€ç§åŸºäºç¨€ç–3Dé«˜æ–¯è¡¨ç¤ºçš„å ç”¨ç‡ä¼°è®¡æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å—åˆ°é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„å¯å‘ï¼Œå¹¶æ›¿ä»£äº†ä¼ ç»Ÿçš„å¯†é›†ä½“ç´ ç½‘æ ¼ã€‚</li>
<li>åŸºäºé«˜æ–¯è½¬æ¢å™¨çš„æ¨¡å‹æ¶æ„ï¼Œé™ä½äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚ã€‚</li>
<li>GaussianFlowOccé€šè¿‡ä¼°è®¡åœºæ™¯åŠ¨æ€çš„æ—¶é—´æµæ¥è§£å†³å¤æ‚é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨å¼±ç›‘ç£è®¾è®¡ï¼Œæ— éœ€æ˜‚è´µçš„å¯†é›†3Dä½“ç´ æ³¨é‡Šã€‚</li>
<li>åœ¨nuScenesæ•°æ®é›†ä¸Šï¼ŒGaussianFlowOccåœ¨å¼±ç›‘ç£å ç”¨ç‡ä¼°è®¡æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17288">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0bc7b1ec8bb1c729bf836c12408697b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a395241736171aa45ad97b892035b419.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8bb2923bc91e485ef305a2bdee3af592.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f049a432e44646f0d33a656d0dd072b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="VR-Pipe-Streamlining-Hardware-Graphics-Pipeline-for-Volume-Rendering"><a href="#VR-Pipe-Streamlining-Hardware-Graphics-Pipeline-for-Volume-Rendering" class="headerlink" title="VR-Pipe: Streamlining Hardware Graphics Pipeline for Volume Rendering"></a>VR-Pipe: Streamlining Hardware Graphics Pipeline for Volume Rendering</h2><p><strong>Authors:Junseo Lee, Jaisung Kim, Junyong Park, Jaewoong Sim</strong></p>
<p>Graphics rendering that builds on machine learning and radiance fields is gaining significant attention due to its outstanding quality and speed in generating photorealistic images from novel viewpoints. However, prior work has primarily focused on evaluating its performance through software-based rendering on programmable shader cores, leaving its performance when exploiting fixed-function graphics units largely unexplored.   In this paper, we investigate the performance implications of performing radiance field rendering on the hardware graphics pipeline. In doing so, we implement the state-of-the-art radiance field method, 3D Gaussian splatting, using graphics APIs and evaluate it across synthetic and real-world scenes on todayâ€™s graphics hardware. Based on our analysis, we present VR-Pipe, which seamlessly integrates two innovations into graphics hardware to streamline the hardware pipeline for volume rendering, such as radiance field methods. First, we introduce native hardware support for early termination by repurposing existing special-purpose hardware in modern GPUs. Second, we propose multi-granular tile binning with quad merging, which opportunistically blends fragments in shader cores before passing them to fixed-function blending units. Our evaluation shows that VR-Pipe greatly improves rendering performance, achieving up to a 2.78x speedup over the conventional graphics pipeline with negligible hardware overhead. </p>
<blockquote>
<p>åŸºäºæœºå™¨å­¦ä¹ å’Œè¾å°„åœºï¼ˆradiance fieldsï¼‰çš„å›¾å½¢æ¸²æŸ“å› å…¶ä»æ–°é¢–è§†è§’ç”Ÿæˆé€¼çœŸå›¾åƒæ—¶çš„å‡ºè‰²è´¨é‡å’Œé€Ÿåº¦è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œæ—©æœŸçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨é€šè¿‡å¯ç¼–ç¨‹ç€è‰²å™¨æ ¸å¿ƒçš„è½¯ä»¶æ¸²æŸ“æ¥è¯„ä¼°å…¶æ€§èƒ½ï¼Œè€Œå‡ ä¹æ²¡æœ‰æ¢ç´¢å…¶åœ¨åˆ©ç”¨å›ºå®šåŠŸèƒ½å›¾å½¢å•å…ƒæ—¶çš„æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ç¡¬ä»¶å›¾å½¢ç®¡é“ä¸Šæ‰§è¡Œè¾å°„åœºæ¸²æŸ“çš„æ€§èƒ½å½±å“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨å›¾å½¢APIå®ç°äº†æœ€å…ˆè¿›çš„è¾å°„åœºæ–¹æ³•â€”â€”3Dé«˜æ–¯æ‹¼è´´ï¼ˆsplattingï¼‰ï¼Œå¹¶åœ¨å½“ä»Šçš„å›¾å½¢ç¡¬ä»¶ä¸Šå¯¹åˆæˆåœºæ™¯å’ŒçœŸå®ä¸–ç•Œåœºæ™¯è¿›è¡Œäº†è¯„ä¼°ã€‚åŸºäºåˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†VR-Pipeï¼Œå®ƒæ— ç¼åœ°å°†ä¸¤é¡¹åˆ›æ–°é›†æˆåˆ°å›¾å½¢ç¡¬ä»¶ä¸­ï¼Œä»¥ä¼˜åŒ–ä½“ç§¯æ¸²æŸ“ï¼ˆå¦‚è¾å°„åœºæ–¹æ³•ï¼‰çš„ç¡¬ä»¶ç®¡é“ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡é‡æ–°åˆ©ç”¨ç°ä»£GPUä¸­çš„ä¸“ç”¨ç¡¬ä»¶æ¥å¼•å…¥å¯¹æ—©æœŸç»ˆæ­¢çš„æœ¬åœ°ç¡¬ä»¶æ”¯æŒã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†å…·æœ‰å››å…ƒåˆå¹¶çš„å¤šç²’åº¦å¹³é“ºè£…ç®±ï¼ˆmulti-granular tile binningï¼‰ï¼Œè¯¥æŠ€æœ¯åœ¨å°†ç‰‡æ®µä¼ é€’ç»™å›ºå®šåŠŸèƒ½æ··åˆå•å…ƒä¹‹å‰åœ¨ç€è‰²å™¨æ ¸å¿ƒä¸­æœ‰æœºæ··åˆç‰‡æ®µã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼ŒVR-Pipeæå¤§åœ°æé«˜äº†æ¸²æŸ“æ€§èƒ½ï¼Œä¸ä¼ ç»Ÿå›¾å½¢ç®¡é“ç›¸æ¯”ï¼Œæœ€é«˜å¯å®ç°2.78å€çš„é€Ÿåº¦æå‡ï¼Œä¸”ç¡¬ä»¶å¼€é”€å¾®ä¹å…¶å¾®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17078v1">PDF</a> To appear at the 31st International Symposium on High-Performance   Computer Architecture (HPCA 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦ä¸»è¦æ¢è®¨æœºå™¨å­¦ä¹ é©±åŠ¨çš„æ¸²æŸ“æŠ€æœ¯ä»¥åŠåŸºäºè¾å°„åœºçš„æ¸²æŸ“åœ¨å›¾å½¢æ¸²æŸ“é¢†åŸŸçš„è¿›å±•å’Œåº”ç”¨ã€‚æœ¬æ–‡ä¸»è¦åˆ†æäº†ç°ä»£å›¾å½¢ç¡¬ä»¶ä¸Šçš„å…‰çº¿æŠ•å°„ç®—æ³•æ€§èƒ½ï¼Œå¹¶é¦–æ¬¡å®ç°äº†åŸºäºç¡¬ä»¶æ”¯æŒçš„æ—©æœŸç»ˆæ­¢æŠ€æœ¯å’Œå¤šç²’åº¦ç“¦ç‰‡åˆå¹¶æŠ€æœ¯ï¼Œä»¥æé«˜æ¸²æŸ“æ€§èƒ½ã€‚è¿™äº›æŠ€æœ¯ä¸ºè¾å°„åœºæ–¹æ³•æä¾›äº†ä¼˜åŒ–çš„ç¡¬ä»¶æ”¯æŒï¼Œå®ç°äº†é«˜è¾¾2.78å€çš„æ¸²æŸ“é€Ÿåº¦æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯åŸºäºæ–‡æœ¬çš„å…³é”®è§è§£ï¼š</p>
<ol>
<li>ç°ä»£å›¾å½¢æ¸²æŸ“ç»“åˆæœºå™¨å­¦ä¹ å’Œè¾å°„åœºæŠ€æœ¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œä½†è¯¥é¢†åŸŸä»å­˜åœ¨å¯¹ä¼ ç»Ÿå¯ç¼–ç¨‹ç€è‰²å™¨æ€§èƒ½è¯„ä»·è¿‡é«˜çš„é—®é¢˜ï¼Œå¿½ç•¥äº†åœ¨å›ºå®šåŠŸèƒ½å›¾å½¢å•å…ƒä¸­çš„è¡¨ç°è¯„ä»·ã€‚æœ¬æ–‡ç€çœ¼äºç¡¬ä»¶è®¾å¤‡çš„å…‰çº¿æŠ•å°„æŠ€æœ¯è¡¨ç°çš„ç ”ç©¶å’Œè¯„ä»·ã€‚</li>
<li>é€šè¿‡æœ€æ–°çš„å…‰çº¿æŠ•å°„æ–¹æ³•åˆ†ææ¸²æŸ“æŠ€æœ¯åœ¨ç¡¬ä»¶ä¸Šçš„æ€§èƒ½ï¼Œä¾‹å¦‚åŸºäºè¾å°„åœºçš„3Dé«˜æ–¯é£æº…æŠ€æœ¯ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†ç°æœ‰çš„å›¾å½¢APIï¼Œå¯¹åˆæˆåœºæ™¯å’ŒçœŸå®ä¸–ç•Œåœºæ™¯è¿›è¡Œäº†è¯„ä»·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17078">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b4c098e0b07247bec86ee2256f2a58b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f5994d6001281c5f3e7791dcaf3a65a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f40ecca23042bb4e96303bc637d12ac7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba2a582a3abbc7d66ab8d312a237af18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e96a58fa9e4f3d4d58eaf3e78ef82f3c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ad682801d61b11546a51794a9fea6e82.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GS-TransUNet-Integrated-2D-Gaussian-Splatting-and-Transformer-UNet-for-Accurate-Skin-Lesion-Analysis"><a href="#GS-TransUNet-Integrated-2D-Gaussian-Splatting-and-Transformer-UNet-for-Accurate-Skin-Lesion-Analysis" class="headerlink" title="GS-TransUNet: Integrated 2D Gaussian Splatting and Transformer UNet for   Accurate Skin Lesion Analysis"></a>GS-TransUNet: Integrated 2D Gaussian Splatting and Transformer UNet for   Accurate Skin Lesion Analysis</h2><p><strong>Authors:Anand Kumar, Kavinder Roghit Kanthen, Josna John</strong></p>
<p>We can achieve fast and consistent early skin cancer detection with recent developments in computer vision and deep learning techniques. However, the existing skin lesion segmentation and classification prediction models run independently, thus missing potential efficiencies from their integrated execution. To unify skin lesion analysis, our paper presents the Gaussian Splatting - Transformer UNet (GS-TransUNet), a novel approach that synergistically combines 2D Gaussian splatting with the Transformer UNet architecture for automated skin cancer diagnosis. Our unified deep learning model efficiently delivers dual-function skin lesion classification and segmentation for clinical diagnosis. Evaluated on ISIC-2017 and PH2 datasets, our network demonstrates superior performance compared to existing state-of-the-art models across multiple metrics through 5-fold cross-validation. Our findings illustrate significant advancements in the precision of segmentation and classification. This integration sets new benchmarks in the field and highlights the potential for further research into multi-task medical image analysis methodologies, promising enhancements in automated diagnostic systems. </p>
<blockquote>
<p>æˆ‘ä»¬å¯ä»¥å€ŸåŠ©è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„æœ€æ–°å‘å±•ï¼Œå®ç°å¿«é€Ÿä¸”ä¸€è‡´çš„æ—©æœŸçš®è‚¤ç™Œæ£€æµ‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„çš®è‚¤ç—…å˜åˆ†å‰²å’Œåˆ†ç±»é¢„æµ‹æ¨¡å‹æ˜¯ç‹¬ç«‹è¿è¡Œçš„ï¼Œå› æ­¤é”™è¿‡äº†é€šè¿‡é›†æˆæ‰§è¡Œæé«˜æ•ˆç‡çš„æ½œåœ¨æœºä¼šã€‚ä¸ºäº†ç»Ÿä¸€çš®è‚¤ç—…å˜åˆ†æï¼Œæˆ‘ä»¬çš„è®ºæ–‡æå‡ºäº†é«˜æ–¯ç‚¹æŸ“â€”â€”Transformer UNetï¼ˆGS-TransUNetï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒå°†äºŒç»´é«˜æ–¯ç‚¹æŸ“ä¸Transformer UNetæ¶æ„ååŒç»“åˆï¼Œç”¨äºè‡ªåŠ¨åŒ–çš®è‚¤ç™Œè¯Šæ–­ã€‚æˆ‘ä»¬ç»Ÿä¸€çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æœ‰æ•ˆåœ°å®ç°äº†ç”¨äºä¸´åºŠè¯Šæ–­çš„åŒé‡åŠŸèƒ½çš®è‚¤ç—…å˜åˆ†ç±»å’Œåˆ†å‰²ã€‚åœ¨ISIC-2017å’ŒPH2æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„ç½‘ç»œåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹çš„æ€§èƒ½ï¼Œé€šè¿‡5å€äº¤å‰éªŒè¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨åˆ†å‰²å’Œåˆ†ç±»çš„ç²¾ç¡®åº¦æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚è¿™ä¸€æ•´åˆä¸ºé¢†åŸŸè®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œå¹¶å¼ºè°ƒäº†å¤šä»»åŠ¡åŒ»å­¦å›¾åƒåˆ†ææ–¹æ³•çš„è¿›ä¸€æ­¥ç ”ç©¶æ½œåŠ›ï¼Œæœ‰æœ›åœ¨è‡ªåŠ¨åŒ–è¯Šæ–­ç³»ç»Ÿä¸­å®ç°æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16748v1">PDF</a> 12 pages, 7 figures, SPIE Medical Imaging 2025</p>
<p><strong>Summary</strong><br>çš®è‚¤ç™Œçš„æ—©æœŸå¿«é€Ÿä¸”ä¸€è‡´æ£€æµ‹å¯é€šè¿‡è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„æœ€æ–°å‘å±•å®ç°ã€‚ç°æœ‰çš®è‚¤ç—…ç¶åˆ†å‰²å’Œåˆ†ç±»é¢„æµ‹æ¨¡å‹ç‹¬ç«‹è¿è¡Œï¼Œé”™è¿‡é€šè¿‡é›†æˆæ‰§è¡Œæé«˜æ•ˆç‡çš„æ½œåœ¨æœºä¼šã€‚ä¸ºç»Ÿä¸€çš®è‚¤ç—…ç¶åˆ†æï¼Œæœ¬æ–‡æå‡ºé«˜æ–¯å±•å¸ƒ-Transformer UNetï¼ˆGS-TransUNetï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å°†äºŒç»´é«˜æ–¯å±•å¸ƒä¸Transformer UNetæ¶æ„ååŒç»“åˆï¼Œå®ç°è‡ªåŠ¨åŒ–çš®è‚¤ç™Œè¯Šæ–­çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬ç»Ÿä¸€çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æœ‰æ•ˆåœ°å®ç°äº†ç”¨äºä¸´åºŠè¯Šæ–­çš„çš®è‚¤ç—…ç¶åˆ†ç±»å’Œåˆ†å‰²çš„åŒé‡åŠŸèƒ½ã€‚åœ¨ISIC-2017å’ŒPH2æ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„ç½‘ç»œåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹çš„æ€§èƒ½ï¼Œé€šè¿‡äº”æŠ˜äº¤å‰éªŒè¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨åˆ†å‰²å’Œåˆ†ç±»ç²¾åº¦æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚è¿™ç§é›†æˆæ ‘ç«‹äº†è¯¥é¢†åŸŸçš„æ–°åŸºå‡†ï¼Œå¹¶å¼ºè°ƒäº†å¤šä»»åŠ¡åŒ»ç–—å›¾åƒåˆ†ææ–¹æ³•çš„ç ”ç©¶æ½œåŠ›ï¼Œæœ‰æœ›åœ¨è‡ªåŠ¨åŒ–è¯Šæ–­ç³»ç»Ÿä¸­å¾—åˆ°æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ€æ–°è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯å¯å®ç°å¿«é€Ÿä¸”ä¸€è‡´çš„çš®è‚¤ç™Œæ—©æœŸæ£€æµ‹ã€‚</li>
<li>ç°æœ‰çš®è‚¤ç—…ç¶åˆ†å‰²å’Œåˆ†ç±»æ¨¡å‹ç‹¬ç«‹è¿è¡Œï¼Œå­˜åœ¨æ•ˆç‡æå‡ç©ºé—´ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ–¹æ³•GS-TransUNetï¼Œç»“åˆäºŒç»´é«˜æ–¯å±•å¸ƒä¸Transformer UNetæ¶æ„ã€‚</li>
<li>GS-TransUNetå®ç°çš®è‚¤ç—…ç¶åˆ†ç±»å’Œåˆ†å‰²çš„åŒé‡åŠŸèƒ½ï¼Œç”¨äºè‡ªåŠ¨åŒ–çš®è‚¤ç™Œè¯Šæ–­ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒGS-TransUNetæ€§èƒ½ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
<li>ç ”ç©¶ç»“æœæ˜¾è‘—æé«˜äº†çš®è‚¤ç—…ç¶åˆ†å‰²å’Œåˆ†ç±»çš„ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16748">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-aec2c6d036a82334416eccfb4ca2e21c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a0262ef1aae621edb987b813734c300.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0cb9f901566e05126527d5921d40596.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab87213b5d8cc6e4f950f08023d1415f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Dr-Splat-Directly-Referring-3D-Gaussian-Splatting-via-Direct-Language-Embedding-Registration"><a href="#Dr-Splat-Directly-Referring-3D-Gaussian-Splatting-via-Direct-Language-Embedding-Registration" class="headerlink" title="Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language   Embedding Registration"></a>Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language   Embedding Registration</h2><p><strong>Authors:Kim Jun-Seong, GeonU Kim, Kim Yu-Ji, Yu-Chiang Frank Wang, Jaesung Choe, Tae-Hyun Oh</strong></p>
<p>We introduce Dr. Splat, a novel approach for open-vocabulary 3D scene understanding leveraging 3D Gaussian Splatting. Unlike existing language-embedded 3DGS methods, which rely on a rendering process, our method directly associates language-aligned CLIP embeddings with 3D Gaussians for holistic 3D scene understanding. The key of our method is a language feature registration technique where CLIP embeddings are assigned to the dominant Gaussians intersected by each pixel-ray. Moreover, we integrate Product Quantization (PQ) trained on general large-scale image data to compactly represent embeddings without per-scene optimization. Experiments demonstrate that our approach significantly outperforms existing approaches in 3D perception benchmarks, such as open-vocabulary 3D semantic segmentation, 3D object localization, and 3D object selection tasks. For video results, please visit : <a target="_blank" rel="noopener" href="https://drsplat.github.io/">https://drsplat.github.io/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Dr. Splatï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰è¿›è¡Œå¼€æ”¾è¯æ±‡è¡¨3Dåœºæ™¯ç†è§£çš„æ–°æ–¹æ³•ã€‚ä¸åŒäºç°æœ‰çš„åµŒå…¥è¯­è¨€çš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæ¸²æŸ“è¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥å°†è¯­è¨€å¯¹é½çš„CLIPåµŒå…¥ä¸ä¸‰ç»´é«˜æ–¯å…³è”èµ·æ¥ï¼Œç”¨äºå…¨é¢çš„ä¸‰ç»´åœºæ™¯ç†è§£ã€‚æˆ‘ä»¬æ–¹æ³•çš„å…³é”®åœ¨äºè¯­è¨€ç‰¹å¾æ³¨å†ŒæŠ€æœ¯ï¼Œå…¶ä¸­CLIPåµŒå…¥è¢«åˆ†é…ç»™æ¯ä¸ªåƒç´ å°„çº¿æ‰€ç›¸äº¤çš„ä¸»è¦é«˜æ–¯åˆ†å¸ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é›†æˆäº†åœ¨é€šç”¨å¤§è§„æ¨¡å›¾åƒæ•°æ®ä¸Šè®­ç»ƒçš„äº§å“é‡åŒ–ï¼ˆPQï¼‰ï¼Œä»¥ç´§å‡‘åœ°è¡¨ç¤ºåµŒå…¥ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ç»´æ„ŸçŸ¥åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨å¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´è¯­ä¹‰åˆ†å‰²ã€ä¸‰ç»´å¯¹è±¡å®šä½å’Œä¸‰ç»´å¯¹è±¡é€‰æ‹©ä»»åŠ¡ä¸­ã€‚è§†é¢‘ç»“æœè¯·è®¿é—®ï¼š[<a target="_blank" rel="noopener" href="https://drsplat.github.io/]">https://drsplat.github.io/]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16652v1">PDF</a> 20 pages</p>
<p><strong>Summary</strong><br>    åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯ï¼ˆ3D Gaussian Splattingï¼‰æ¨å‡ºDr. Splatæ–°æ–¹æ³•ï¼Œå®ç°å¼€æ”¾è¯æ±‡è¡¨çš„åœºæ™¯ä¸‰ç»´ç†è§£ã€‚ä¸ç°æœ‰è¯­è¨€åµŒå…¥ä¸‰ç»´åˆ†å‰²æ³•ä¸åŒï¼Œæ­¤æ³•é€šè¿‡è¯­è¨€å¯¹é½CLIPåµŒå…¥ç›´æ¥ä¸ä¸‰ç»´é«˜æ–¯ç›¸å…³è”ï¼Œä»¥å®ç°å…¨é¢åœºæ™¯ç†è§£ã€‚åˆ©ç”¨è¯­è¨€ç‰¹å¾æ³¨å†ŒæŠ€æœ¯ä¸ºæ¯ä¸ªåƒç´ ç‚¹åˆ†é…ä¸»å¯¼é«˜æ–¯å¹¶èµ‹äºˆCLIPåµŒå…¥å€¼ã€‚é›†æˆProduct QuantizationæŠ€æœ¯ç´§å‡‘è¡¨ç¤ºåµŒå…¥å€¼ï¼Œæ— éœ€åœºæ™¯ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ç»´æ„ŸçŸ¥åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¦‚å¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´è¯­ä¹‰åˆ†å‰²ã€ä¸‰ç»´ç›®æ ‡å®šä½å’Œä¸‰ç»´ç›®æ ‡é€‰æ‹©ä»»åŠ¡ç­‰ã€‚å…·ä½“è§†é¢‘ç»“æœè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://drsplat.github.io/">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»‹ç»äº†ä¸€ç§åä¸ºDr. Splatçš„æ–°æ–¹æ³•ï¼Œç”¨äºåŸºäºå¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´åœºæ™¯ç†è§£ã€‚</li>
<li>Dr. Splaté‡‡ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯ï¼ˆ3D Gaussian Splattingï¼‰ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”æ›´ç›´è§‚åœ°è¿›è¡Œä¸‰ç»´æ„ŸçŸ¥åˆ†æã€‚</li>
<li>é€šè¿‡è¯­è¨€å¯¹é½CLIPåµŒå…¥ç›´æ¥å…³è”è‡³ä¸‰ç»´é«˜æ–¯çš„æ–¹æ³•ç†è§£å…¨é¢åœºæ™¯ã€‚</li>
<li>åˆ©ç”¨è¯­è¨€ç‰¹å¾æ³¨å†ŒæŠ€æœ¯ä¸ºæ¯ä¸ªåƒç´ ç‚¹åˆ†é…ä¸»å¯¼é«˜æ–¯å¹¶èµ‹äºˆCLIPåµŒå…¥å€¼ï¼Œå®ç°ç²¾å‡†åˆ†æã€‚</li>
<li>é›†æˆProduct QuantizationæŠ€æœ¯ï¼Œæ— éœ€ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–å³å¯ç´§å‡‘è¡¨ç¤ºåµŒå…¥å€¼ã€‚</li>
<li>å®éªŒè¯æ˜Dr. Splatåœ¨ä¸‰ç»´æ„ŸçŸ¥åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“æ¶µç›–å¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´è¯­ä¹‰åˆ†å‰²ã€ä¸‰ç»´ç›®æ ‡å®šä½å’Œé€‰æ‹©ä»»åŠ¡ç­‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ec8a951fca1eaf04f046598a7a170f10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d3f9a755609e9ca050d62aab20de53e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-540d400609eef2abc3b21e50791b0cbb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e27eb0794e0d05edc187bd375bff974a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a9040604e940baac4fcb06e40190b83.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4113a326f1fc6e5185947dd685ebb341.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70bf70c441d4bb86c5947484b9857b48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57ac4f8a7b9e8ea7874f039c2e543c57.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Efficient-4D-Gaussian-Stream-with-Low-Rank-Adaptation"><a href="#Efficient-4D-Gaussian-Stream-with-Low-Rank-Adaptation" class="headerlink" title="Efficient 4D Gaussian Stream with Low Rank Adaptation"></a>Efficient 4D Gaussian Stream with Low Rank Adaptation</h2><p><strong>Authors:Zhenhuan Liu, Shuai Liu, Yidong Lu, Yirui Chen, Jie Yang, Wei Liu</strong></p>
<p>Recent methods have made significant progress in synthesizing novel views with long video sequences. This paper proposes a highly scalable method for dynamic novel view synthesis with continual learning. We leverage the 3D Gaussians to represent the scene and a low-rank adaptation-based deformation model to capture the dynamic scene changes. Our method continuously reconstructs the dynamics with chunks of video frames, reduces the streaming bandwidth by $90%$ while maintaining high rendering quality comparable to the off-line SOTA methods. </p>
<blockquote>
<p>è¿‘æœŸçš„æ–¹æ³•åœ¨åˆ©ç”¨é•¿è§†é¢‘åºåˆ—åˆæˆæ–°å‹è§†è§’æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å…·æœ‰å¯æ‰©å±•æ€§çš„åŠ¨æ€æ–°å‹è§†è§’åˆæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰æŒç»­å­¦ä¹ èƒ½åŠ›ã€‚æˆ‘ä»¬åˆ©ç”¨3Dé«˜æ–¯æ¥è¡¨ç¤ºåœºæ™¯ï¼Œå¹¶é‡‡ç”¨åŸºäºä½é˜¶é€‚åº”çš„å˜å½¢æ¨¡å‹æ¥æ•æ‰åŠ¨æ€åœºæ™¯å˜åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿè¿ç»­é‡æ„è§†é¢‘å¸§çš„åŠ¨æ€æ•ˆæœï¼Œåœ¨ä¿æŒä¸ç¦»çº¿SOTAæ–¹æ³•ç›¸å½“çš„é«˜æ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼Œå°†æµåª’ä½“å¸¦å®½å‡å°‘äº†90%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16575v1">PDF</a> 3 pages draft</p>
<p><strong>Summary</strong>ï¼š<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€åœºæ™¯è¡¨ç¤ºå’Œè¿ç»­å­¦ä¹ çš„åŠ¨æ€æ–°è§†è§’åˆæˆæ–¹æ³•ã€‚åˆ©ç”¨ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œå¹¶é‡‡ç”¨åŸºäºä½ç§©é€‚åº”çš„å˜å½¢æ¨¡å‹æ•æ‰åŠ¨æ€åœºæ™¯å˜åŒ–ã€‚è¯¥æ–¹æ³•å¯è¿ç»­é‡å»ºè§†é¢‘å¸§ç‰‡æ®µï¼Œé™ä½æµå¸¦å®½è¾¾90%ï¼ŒåŒæ—¶ä¿æŒä¸ç¦»çº¿å…ˆè¿›æ–¹æ³•ç›¸å½“çš„é«˜æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>æœ¬æ–‡æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯åˆ†å¸ƒçš„åœºè¿åŠ¨æ€è¡¨ç¤ºæ–¹æ³•ï¼Œæœ‰æ•ˆæ•æ‰åœºæ™¯çš„åŠ¨æ€å˜åŒ–ã€‚</li>
<li>åˆ©ç”¨ä½ç§©é€‚åº”å˜å½¢æ¨¡å‹å¯¹åŠ¨æ€åœºæ™¯å˜åŒ–è¿›è¡Œå»ºæ¨¡ã€‚</li>
<li>è¯¥æ–¹æ³•å¯è¿ç»­é‡å»ºè§†é¢‘å¸§ç‰‡æ®µï¼Œæœ‰åŠ©äºæé«˜è§†é¢‘å¤„ç†çš„æ•ˆç‡å’Œæµç•…æ€§ã€‚</li>
<li>ä¸ç¦»çº¿å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜æ¸²æŸ“è´¨é‡çš„åŒæ—¶é™ä½äº†æµå¸¦å®½è¾¾90%ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºé•¿è§†é¢‘åºåˆ—çš„åˆæˆæ–°è§†è§’ä»»åŠ¡ã€‚</li>
<li>æœ¬æ–‡çš„åˆæˆæ–°è§†è§’æŠ€æœ¯åŸºäºè¿ç»­å­¦ä¹ ï¼Œèƒ½å¤Ÿé€‚åº”åŠ¨æ€åœºæ™¯çš„å˜åŒ–ï¼Œå…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16575">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8c8bb6ebe18a8209c2afb6206fabae83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d556a3180e2cf59cf3ce1ac21fa81c0f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8505b3822a06a422e50f1d3f9373015b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Dragen3D-Multiview-Geometry-Consistent-3D-Gaussian-Generation-with-Drag-Based-Control"><a href="#Dragen3D-Multiview-Geometry-Consistent-3D-Gaussian-Generation-with-Drag-Based-Control" class="headerlink" title="Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with   Drag-Based Control"></a>Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with   Drag-Based Control</h2><p><strong>Authors:Jinbo Yan, Alan Zhao, Yixin Hu</strong></p>
<p>Single-image 3D generation has emerged as a prominent research topic, playing a vital role in virtual reality, 3D modeling, and digital content creation. However, existing methods face challenges such as a lack of multi-view geometric consistency and limited controllability during the generation process, which significantly restrict their usability. % To tackle these challenges, we introduce Dragen3D, a novel approach that achieves geometrically consistent and controllable 3D generation leveraging 3D Gaussian Splatting (3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GS VAE), which encodes a point cloud and a single image into anchor latents and decode these latents into 3DGS, enabling efficient latent-space generation. To enable multi-view geometry consistent and controllable generation, we propose a Seed-Point-Driven strategy: first generate sparse seed points as a coarse geometry representation, then map them to anchor latents via the Seed-Anchor Mapping Module. Geometric consistency is ensured by the easily learned sparse seed points, and users can intuitively drag the seed points to deform the final 3DGS geometry, with changes propagated through the anchor latents. To the best of our knowledge, we are the first to achieve geometrically controllable 3D Gaussian generation and editing without relying on 2D diffusion priors, delivering comparable 3D generation quality to state-of-the-art methods. </p>
<blockquote>
<p>å•å›¾åƒ3Dç”Ÿæˆå·²æˆä¸ºä¸€ä¸ªçªå‡ºçš„ç ”ç©¶ä¸»é¢˜ï¼Œåœ¨è™šæ‹Ÿç°å®ã€3Då»ºæ¨¡å’Œæ•°å­—å†…å®¹åˆ›å»ºä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ç¼ºä¹å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§å’Œç”Ÿæˆè¿‡ç¨‹ä¸­å¯æ§æ€§æœ‰é™çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¾è‘—é™åˆ¶äº†å…¶å¯ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Dragen3Dï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨3Dé«˜æ–¯æ‹¼è´´(3DGS)å®ç°å‡ ä½•ä¸€è‡´æ€§å’Œå¯æ§æ€§çš„3Dç”Ÿæˆæ–°æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥äº†é”šç‚¹é«˜æ–¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆAnchor-GS VAEï¼‰ï¼Œå®ƒå°†ç‚¹äº‘å’Œå•å›¾åƒç¼–ç ä¸ºé”šç‚¹æ½œåœ¨ç©ºé—´ï¼Œå¹¶å°†è¿™äº›æ½œåœ¨ç©ºé—´è§£ç ä¸º3DGSï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ½œåœ¨ç©ºé—´ç”Ÿæˆã€‚ä¸ºäº†å®ç°å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§å’Œå¯æ§æ€§ç”Ÿæˆï¼Œæˆ‘ä»¬æå‡ºäº†ç§å­ç‚¹é©±åŠ¨ç­–ç•¥ï¼šé¦–å…ˆç”Ÿæˆç¨€ç–ç§å­ç‚¹ä½œä¸ºç²—ç•¥çš„å‡ ä½•è¡¨ç¤ºï¼Œç„¶åé€šè¿‡ç§å­ç‚¹é”šæ˜ å°„æ¨¡å—å°†å®ƒä»¬æ˜ å°„åˆ°é”šç‚¹æ½œåœ¨ç©ºé—´ã€‚å‡ ä½•ä¸€è‡´æ€§ç”±æ˜“äºå­¦ä¹ çš„ç¨€ç–ç§å­ç‚¹ä¿è¯ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥æ‹–åŠ¨ç§å­ç‚¹æ¥å˜å½¢æœ€ç»ˆçš„3DGSå‡ ä½•å½¢çŠ¶ï¼Œå˜åŒ–ä¼šé€šè¿‡é”šç‚¹æ½œåœ¨ç©ºé—´è¿›è¡Œä¼ æ’­ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªåœ¨ä¸ä¾èµ–2Dæ‰©æ•£å…ˆéªŒçš„æƒ…å†µä¸‹å®ç°å‡ ä½•å¯æ§çš„3Dé«˜æ–¯ç”Ÿæˆå’Œç¼–è¾‘çš„å›¢é˜Ÿï¼Œæä¾›äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„3Dç”Ÿæˆè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16475v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å•è§†è§’å›¾åƒä¸‰ç»´é‡å»ºæŠ€æœ¯å·²æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼Œåœ¨è™šæ‹Ÿç°å®ã€ä¸‰ç»´å»ºæ¨¡å’Œæ•°å­—å†…å®¹åˆ›å»ºç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ä»·å€¼ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ç¼ºä¹å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§ä»¥åŠç”Ÿæˆè¿‡ç¨‹ä¸­å¯æ§æ€§æœ‰é™ç­‰æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„å‡ ä½•ä¸€è‡´æ€§å’Œå¯æ§æ€§ä¸‰ç»´é‡å»ºæ–°æ–¹æ³•â€”â€”Dragen3Dã€‚é€šè¿‡å¼•å…¥é”šç‚¹é«˜æ–¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆAnchor-GS VAEï¼‰ï¼Œå°†ç‚¹äº‘å’Œå•è§†è§’å›¾åƒç¼–ç ä¸ºé”šç‚¹æ½œåœ¨ç©ºé—´ï¼Œå†è§£ç ä¸ºä¸‰ç»´é«˜æ–¯æ‹¼è´´ã€‚ä¸ºå®ç°å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§å’Œå¯æ§æ€§ç”Ÿæˆï¼Œæœ¬æ–‡é‡‡ç”¨ç§å­ç‚¹é©±åŠ¨ç­–ç•¥ï¼šé¦–å…ˆç”Ÿæˆç¨€ç–ç§å­ç‚¹ä½œä¸ºç²—ç•¥å‡ ä½•è¡¨ç¤ºï¼Œç„¶åé€šè¿‡ç§å­ç‚¹æ˜ å°„æ¨¡å—å°†å…¶æ˜ å°„åˆ°é”šç‚¹æ½œåœ¨ç©ºé—´ã€‚é€šè¿‡æ˜“äºå­¦ä¹ çš„ç¨€ç–ç§å­ç‚¹ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œç”¨æˆ·å¯ç›´è§‚æ‹–åŠ¨ç§å­ç‚¹æ”¹å˜æœ€ç»ˆçš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´å‡ ä½•å½¢çŠ¶ï¼Œå˜åŒ–å°†é€šè¿‡é”šç‚¹æ½œåœ¨ç©ºé—´ä¼ æ’­ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæœ¬æ–‡é¦–æ¬¡å®ç°äº†æ— éœ€ä¾èµ–äºŒç»´æ‰©æ•£å…ˆéªŒçš„å‡ ä½•å¯æ§ä¸‰ç»´é«˜æ–¯ç”Ÿæˆå’Œç¼–è¾‘ï¼Œæä¾›äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„ä¸‰ç»´ç”Ÿæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å•è§†è§’å›¾åƒä¸‰ç»´é‡å»ºæŠ€æœ¯çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜ã€‚</li>
<li>Dragen3Dæ–¹æ³•åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰è§£å†³ç°æœ‰é—®é¢˜ã€‚</li>
<li>å¼•å…¥é”šç‚¹é«˜æ–¯å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆAnchor-GS VAEï¼‰å®ç°é«˜æ•ˆæ½œåœ¨ç©ºé—´ç”Ÿæˆã€‚</li>
<li>é‡‡ç”¨ç§å­ç‚¹é©±åŠ¨ç­–ç•¥å®ç°å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§å’Œå¯æ§æ€§ç”Ÿæˆã€‚</li>
<li>ç¨€ç–ç§å­ç‚¹ç”¨äºç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œå¹¶æ”¯æŒç›´è§‚ç¼–è¾‘ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†å‡ ä½•å¯æ§çš„ä¸‰ç»´é«˜æ–¯ç”Ÿæˆå’Œç¼–è¾‘ï¼Œæ— éœ€ä¾èµ–äºŒç»´æ‰©æ•£å…ˆéªŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16475">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c878200f2a90e45af997a2ac14c4f6b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac514e8d0672e6c1ec2e1eae3938ef68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-671d26e8a2874333ec59e50a8c1c19cf.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Pointmap-Association-and-Piecewise-Plane-Constraint-for-Consistent-and-Compact-3D-Gaussian-Segmentation-Field"><a href="#Pointmap-Association-and-Piecewise-Plane-Constraint-for-Consistent-and-Compact-3D-Gaussian-Segmentation-Field" class="headerlink" title="Pointmap Association and Piecewise-Plane Constraint for Consistent and   Compact 3D Gaussian Segmentation Field"></a>Pointmap Association and Piecewise-Plane Constraint for Consistent and   Compact 3D Gaussian Segmentation Field</h2><p><strong>Authors:Wenhao Hu, Wenhao Chai, Shengyu Hao, Xiaotong Cui, Xuexiang Wen, Jenq-Neng Hwang, Gaoang Wang</strong></p>
<p>Achieving a consistent and compact 3D segmentation field is crucial for maintaining semantic coherence across views and accurately representing scene structures. Previous 3D scene segmentation methods rely on video segmentation models to address inconsistencies across views, but the absence of spatial information often leads to object misassociation when object temporarily disappear and reappear. Furthermore, in the process of 3D scene reconstruction, segmentation and optimization are often treated as separate tasks. As a result, optimization typically lacks awareness of semantic category information, which can result in floaters with ambiguous segmentation. To address these challenges, we introduce CCGS, a method designed to achieve both view consistent 2D segmentation and a compact 3D Gaussian segmentation field. CCGS incorporates pointmap association and a piecewise-plane constraint. First, we establish pixel correspondence between adjacent images by minimizing the Euclidean distance between their pointmaps. We then redefine object mask overlap accordingly. The Hungarian algorithm is employed to optimize mask association by minimizing the total matching cost, while allowing for partial matches. To further enhance compactness, the piecewise-plane constraint restricts point displacement within local planes during optimization, thereby preserving structural integrity. Experimental results on ScanNet and Replica datasets demonstrate that CCGS outperforms existing methods in both 2D panoptic segmentation and 3D Gaussian segmentation. </p>
<blockquote>
<p>å®ç°ä¸€è‡´ä¸”ç´§å‡‘çš„3Dåˆ†å‰²åœºå¯¹äºä¿æŒè·¨è§†å›¾çš„è¯­ä¹‰è¿è´¯æ€§å¹¶å‡†ç¡®è¡¨ç¤ºåœºæ™¯ç»“æ„è‡³å…³é‡è¦ã€‚ä»¥å¾€çš„3Dåœºæ™¯åˆ†å‰²æ–¹æ³•ä¾èµ–äºè§†é¢‘åˆ†å‰²æ¨¡å‹æ¥è§£å†³è·¨è§†å›¾çš„ä¸ä¸€è‡´æ€§ï¼Œä½†å¯¹è±¡æš‚æ—¶æ¶ˆå¤±å¹¶é‡æ–°å‡ºç°æ—¶ï¼Œç¼ºä¹ç©ºé—´ä¿¡æ¯å¾€å¾€ä¼šå¯¼è‡´å¯¹è±¡è¯¯å…³è”ã€‚æ­¤å¤–ï¼Œåœ¨3Dåœºæ™¯é‡å»ºè¿‡ç¨‹ä¸­ï¼Œåˆ†å‰²å’Œä¼˜åŒ–é€šå¸¸è¢«è§†ä¸ºå•ç‹¬çš„ä»»åŠ¡ã€‚å› æ­¤ï¼Œä¼˜åŒ–é€šå¸¸ç¼ºä¹è¯­ä¹‰ç±»åˆ«ä¿¡æ¯çš„æ„è¯†ï¼Œè¿™å¯èƒ½å¯¼è‡´å…·æœ‰æ¨¡ç³Šåˆ†å‰²çš„æµ®åŠ¨å¯¹è±¡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CCGSæ–¹æ³•ï¼Œå®ƒæ—¨åœ¨å®ç°è·¨è§†å›¾ä¸€è‡´çš„2Dåˆ†å‰²å’Œç´§å‡‘çš„3Dé«˜æ–¯åˆ†å‰²åœºã€‚CCGSç»“åˆäº†ç‚¹å›¾å…³è”å’Œåˆ†æ®µå¹³é¢çº¦æŸã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡æœ€å°åŒ–ç‚¹å›¾ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ¥å»ºç«‹ç›¸é‚»å›¾åƒä¹‹é—´çš„åƒç´ å¯¹åº”å…³ç³»ã€‚ç„¶åï¼Œæˆ‘ä»¬ç›¸åº”åœ°é‡æ–°å®šä¹‰å¯¹è±¡æ©æ¨¡é‡å ã€‚é‡‡ç”¨åŒˆç‰™åˆ©ç®—æ³•ä¼˜åŒ–æ©æ¨¡å…³è”ï¼Œé€šè¿‡æœ€å°åŒ–æ€»åŒ¹é…æˆæœ¬æ¥å®ç°ä¼˜åŒ–ï¼ŒåŒæ—¶å…è®¸éƒ¨åˆ†åŒ¹é…ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ç´§å‡‘æ€§ï¼Œåˆ†æ®µå¹³é¢çº¦æŸåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­é™åˆ¶äº†ç‚¹åœ¨å±€éƒ¨å¹³é¢å†…çš„ä½ç§»ï¼Œä»è€Œä¿æŒäº†ç»“æ„çš„å®Œæ•´æ€§ã€‚åœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCCGSåœ¨2Då…¨æ™¯åˆ†å‰²å’Œ3Dé«˜æ–¯åˆ†å‰²æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16303v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬æå‡ºä¸€ç§è§£å†³3Dåœºæ™¯åˆ†å‰²çš„æ–°æ–¹æ³•CCGSï¼Œé€šè¿‡å¼•å…¥ç‚¹äº‘æ˜ å°„å…³è”ä¸åˆ†æ®µå¹³é¢çº¦æŸæŠ€æœ¯ï¼Œå®ç°äº†è§†è§’ä¸€è‡´çš„2Dåˆ†å‰²ä¸ç´§å‡‘çš„3Dé«˜æ–¯åˆ†å‰²åœºã€‚æ­¤æ–¹æ³•èƒ½å¤Ÿè§£å†³ä¼ ç»Ÿæ–¹æ³•ä¸­å› ç¼ºå°‘ç©ºé—´ä¿¡æ¯å¯¼è‡´çš„å¯¹è±¡è¯¯å…³è”é—®é¢˜ï¼Œä»¥åŠåœ¨åœºæ™¯é‡å»ºè¿‡ç¨‹ä¸­ä¼˜åŒ–ä¸è¯­ä¹‰ç±»åˆ«ä¿¡æ¯è„±èŠ‚çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCCGSåœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ç°è§†è§’ä¸€è‡´çš„3Dåˆ†å‰²åœºå¯¹äºç»´æŒè¯­ä¹‰è¿è´¯æ€§å’Œå‡†ç¡®è¡¨ç¤ºåœºæ™¯ç»“æ„è‡³å…³é‡è¦ã€‚</li>
<li>ä»¥å¾€æ–¹æ³•ä¾èµ–è§†é¢‘åˆ†å‰²æ¨¡å‹è§£å†³è§†è§’ä¸ä¸€è‡´é—®é¢˜ï¼Œä½†ç¼ºä¹ç©ºé—´ä¿¡æ¯å¯¼è‡´å¯¹è±¡æš‚æ—¶æ¶ˆå¤±å’Œé‡æ–°å‡ºç°æ—¶å‘ç”Ÿå¯¹è±¡è¯¯å…³è”ã€‚</li>
<li>CCGSæ–¹æ³•é€šè¿‡å¼•å…¥ç‚¹äº‘æ˜ å°„å…³è”æŠ€æœ¯ï¼Œå»ºç«‹ç›¸é‚»å›¾åƒé—´çš„åƒç´ å¯¹åº”å…³ç³»ï¼Œä¼˜åŒ–å¯¹è±¡æ©è†œå…³è”ã€‚</li>
<li>CCGSé‡‡ç”¨åˆ†æ®µå¹³é¢çº¦æŸæŠ€æœ¯ï¼Œä¼˜åŒ–è¿‡ç¨‹ä¸­é™åˆ¶ç‚¹åœ¨å±€éƒ¨å¹³é¢å†…çš„ä½ç§»ï¼Œä¿æŒç»“æ„å®Œæ•´æ€§ã€‚</li>
<li>CCGSæ–¹æ³•å®ç°äº†ç´§å‡‘çš„3Dé«˜æ–¯åˆ†å‰²åœºï¼Œæé«˜äº†åœºæ™¯åˆ†å‰²çš„æ•ˆæœã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCCGSåœ¨ScanNetå’ŒReplicaæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16303">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c2acecda29176d60590a4da404756635.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97592c00df1fbc8b36c314e484c5ee4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16743a5a822dafa7738e82ef43526ce7.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Para-Lane-Multi-Lane-Dataset-Registering-Parallel-Scans-for-Benchmarking-Novel-View-Synthesis"><a href="#Para-Lane-Multi-Lane-Dataset-Registering-Parallel-Scans-for-Benchmarking-Novel-View-Synthesis" class="headerlink" title="Para-Lane: Multi-Lane Dataset Registering Parallel Scans for   Benchmarking Novel View Synthesis"></a>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for   Benchmarking Novel View Synthesis</h2><p><strong>Authors:Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang</strong></p>
<p>To evaluate end-to-end autonomous driving systems, a simulation environment based on Novel View Synthesis (NVS) techniques is essential, which synthesizes photo-realistic images and point clouds from previously recorded sequences under new vehicle poses, particularly in cross-lane scenarios. Therefore, the development of a multi-lane dataset and benchmark is necessary. While recent synthetic scene-based NVS datasets have been prepared for cross-lane benchmarking, they still lack the realism of captured images and point clouds. To further assess the performance of existing methods based on NeRF and 3DGS, we present the first multi-lane dataset registering parallel scans specifically for novel driving view synthesis dataset derived from real-world scans, comprising 25 groups of associated sequences, including 16,000 front-view images, 64,000 surround-view images, and 16,000 LiDAR frames. All frames are labeled to differentiate moving objects from static elements. Using this dataset, we evaluate the performance of existing approaches in various testing scenarios at different lanes and distances. Additionally, our method provides the solution for solving and assessing the quality of multi-sensor poses for multi-modal data alignment for curating such a dataset in real-world. We plan to continually add new sequences to test the generalization of existing methods across different scenarios. The dataset is released publicly at the project page: <a target="_blank" rel="noopener" href="https://nizqleo.github.io/paralane-dataset/">https://nizqleo.github.io/paralane-dataset/</a>. </p>
<blockquote>
<p>ä¸ºäº†è¯„ä¼°ç«¯åˆ°ç«¯çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼ŒåŸºäºæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰æŠ€æœ¯çš„æ¨¡æ‹Ÿç¯å¢ƒè‡³å…³é‡è¦ã€‚è¯¥æŠ€æœ¯èƒ½ä»æ–°çš„è½¦è¾†å§¿æ€ä¸‹å¯¹å…ˆå‰è®°å½•çš„åºåˆ—åˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ï¼Œç‰¹åˆ«æ˜¯åœ¨è·¨è½¦é“åœºæ™¯ä¸­ã€‚å› æ­¤ï¼Œå¼€å‘å¤šè½¦é“æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•æ˜¯å¿…è¦çš„ã€‚å°½ç®¡æœ€è¿‘ä¸ºè·¨è½¦é“åŸºå‡†æµ‹è¯•å‡†å¤‡äº†åŸºäºåˆæˆåœºæ™¯çš„NVSæ•°æ®é›†ï¼Œä½†å®ƒä»¬ä»ç„¶ç¼ºä¹æ•è·å›¾åƒå’Œç‚¹äº‘çš„é€¼çœŸæ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥è¯„ä¼°åŸºäºNeRFå’Œ3DGSçš„ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œæˆ‘ä»¬é¦–æ¬¡æ¨å‡ºäº†å¤šè½¦é“æ•°æ®é›†ï¼Œä¸“é—¨æ³¨å†Œå¹³è¡Œæ‰«æç”¨äºæ–°å‹é©¾é©¶è§†å›¾åˆæˆæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æºè‡ªçœŸå®ä¸–ç•Œæ‰«æï¼ŒåŒ…å«25ç»„ç›¸å…³åºåˆ—ï¼ŒåŒ…æ‹¬1.6ä¸‡å¼ å‰è§†å›¾åƒã€6.4ä¸‡å¼ ç¯è§†å›¾åƒå’Œ1.6ä¸‡å¼ æ¿€å…‰é›·è¾¾å¸§ã€‚æ‰€æœ‰å¸§éƒ½è¿›è¡Œäº†æ ‡æ³¨ï¼Œä»¥åŒºåˆ†ç§»åŠ¨ç‰©ä½“å’Œé™æ€å…ƒç´ ã€‚ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬åœ¨ä¸åŒè½¦é“å’Œè·ç¦»çš„å„ç§æµ‹è¯•åœºæ™¯ä¸­è¯„ä¼°äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†è§£å†³å’Œè¯„ä¼°å¤šä¼ æ„Ÿå™¨å§¿æ€è´¨é‡çš„è§£å†³æ–¹æ¡ˆï¼Œç”¨äºæ­¤ç±»æ•°æ®é›†çš„å¤šå…ƒæ•°æ®å¯¹é½ã€‚æˆ‘ä»¬è®¡åˆ’ä¸æ–­æ·»åŠ æ–°çš„åºåˆ—ï¼Œä»¥æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹çš„ç°æœ‰æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚æ•°æ®é›†å·²åœ¨é¡¹ç›®é¡µé¢å…¬å¼€å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://nizqleo.github.io/paralane-dataset/">https://nizqleo.github.io/paralane-dataset/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15635v2">PDF</a> Accepted by International Conference on 3D Vision (3DV) 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåŸºäºNovel View Synthesisï¼ˆNVSï¼‰æŠ€æœ¯çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œç”¨äºè¯„ä¼°ç«¯åˆ°ç«¯çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿã€‚è¯¥ç¯å¢ƒåˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ï¼Œç”¨äºè·¨è½¦é“åœºæ™¯ä¸‹çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿè¯„ä¼°ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜ç°æœ‰æ–¹æ³•ï¼ˆåŸºäºNeRFå’Œ3DGSï¼‰çš„è¯„ä¼°æ€§èƒ½ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å¤šè½¦é“æ•°æ®é›†æ³¨å†Œå¹¶è¡Œæ‰«æçš„æ–°å‹é©¾é©¶è§†å›¾åˆæˆæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªçœŸå®ä¸–ç•Œæ‰«æçš„å…³è”åºåˆ—ï¼ŒåŒ…æ‹¬æ ‡æ³¨çš„ç§»åŠ¨ç‰©ä½“å’Œé™æ€å…ƒç´ ã€‚æ•°æ®é›†å…¬å¼€å¯ä¾›ä½¿ç”¨ï¼Œä»¥ä¿ƒè¿›è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„è¯„ä¼°å’Œæ¯”è¾ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§åŸºäºNVSæŠ€æœ¯çš„æ¨¡æ‹Ÿç¯å¢ƒåœ¨è¯„ä¼°ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„é‡è¦æ€§ã€‚</li>
<li>æ­¤ç¯å¢ƒå¯ä»¥åˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ï¼Œä»¥æ¨¡æ‹Ÿä¸åŒè½¦é“çš„åœºæ™¯ã€‚</li>
<li>ç›®å‰è™½ç„¶å­˜åœ¨åŸºäºåˆæˆåœºæ™¯çš„NVSæ•°æ®é›†ï¼Œä½†å®ƒä»¬ç¼ºä¹çœŸå®å›¾åƒçš„é€¼çœŸæ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šè½¦é“æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”±çœŸå®ä¸–ç•Œæ‰«æå¾—æ¥ï¼ŒåŒ…å«æ ‡æ³¨çš„ç§»åŠ¨ç‰©ä½“å’Œé™æ€å…ƒç´ ï¼Œä¸“é—¨ç”¨äºé©¾é©¶è§†å›¾åˆæˆã€‚</li>
<li>æ•°æ®é›†åŒ…å«å¤šç§æµ‹è¯•åœºæ™¯å’Œä¸åŒè½¦é“ã€è·ç¦»çš„æ•°æ®ï¼Œæ—¨åœ¨è¯„ä¼°ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†å¤šä¼ æ„Ÿå™¨å§¿æ€çš„è´¨é‡é—®é¢˜ï¼Œä¸ºè¿™æ ·çš„æ•°æ®é›†å®ç°äº†å¤šæ¨¡æ€æ•°æ®å¯¹é½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1ca95a423af7a29326fdaed5e3470b6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45cd14112a0a5c0d4c8d5188e2c7ae74.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-428f0f524e2b5fc8a5aa00b67602255a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d465441539851e165d4e7cacffbb636e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90021fd7e8f0ed4629412b4e75e74a59.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RGB-Only-Gaussian-Splatting-SLAM-for-Unbounded-Outdoor-Scenes"><a href="#RGB-Only-Gaussian-Splatting-SLAM-for-Unbounded-Outdoor-Scenes" class="headerlink" title="RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes"></a>RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes</h2><p><strong>Authors:Sicheng Yu, Chong Cheng, Yifan Zhou, Xiaojun Yang, Hao Wang</strong></p>
<p>3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenesâ€“OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Compared to commonly used depth maps, pointmaps include spatial relationships and scene geometry across multiple views, enabling robust camera pose estimation. Then, we propose integrating the estimated camera poses with 3DGS rendering as an end-to-end differentiable pipeline. Our method achieves simultaneous optimization of camera poses and 3DGS scene parameters, significantly enhancing system tracking accuracy. Specifically, we also design an adaptive scale mapper for the pointmap regression network, which provides more accurate pointmap mapping to the 3DGS map representation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis. Project Page: <a target="_blank" rel="noopener" href="https://3dagentworld.github.io/opengs-slam/">https://3dagentworld.github.io/opengs-slam/</a> </p>
<blockquote>
<p>3D Gaussian Splattingï¼ˆ3DGSï¼‰å·²ç»æˆä¸ºSLAMä¸­çš„çƒ­é—¨è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºå®ƒå¯ä»¥ç”Ÿæˆé«˜ä¿çœŸåº¦çš„æ–°è§†å›¾ã€‚ç„¶è€Œï¼ŒåŸºäºGSçš„å…ˆå‰æ–¹æ³•ä¸»è¦é’ˆå¯¹å®¤å†…åœºæ™¯ï¼Œå¹¶ä¾èµ–äºRGB-Dä¼ æ„Ÿå™¨æˆ–é¢„è®­ç»ƒçš„æ·±åº¦ä¼°è®¡æ¨¡å‹ï¼Œå› æ­¤åœ¨å®¤å¤–åœºæ™¯ä¸­çš„è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨RGBçš„Gaussian Splatting SLAMæ–¹æ³•ï¼Œé€‚ç”¨äºæ— ç•Œé™çš„å®¤å¤–åœºæ™¯â€”â€”OpenGS-SLAMã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15633v1">PDF</a> ICRA 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹æˆ·å¤–åœºæ™¯æå‡ºçš„RGB-onlyé«˜æ–¯èåˆSLAMæ–¹æ³•â€”â€”OpenGS-SLAMã€‚è¯¥æ–¹æ³•é€šè¿‡ç‚¹å›¾å›å½’ç½‘ç»œç”Ÿæˆè¿ç»­å¸§ä¹‹é—´çš„ç‚¹å›¾è¿›è¡Œå§¿æ€ä¼°è®¡ï¼Œå¹¶æ•´åˆä¼°è®¡çš„ç›¸æœºå§¿æ€ä¸3DGSæ¸²æŸ“ï¼Œå®ç°ç³»ç»Ÿè·Ÿè¸ªç²¾åº¦çš„æ˜¾è‘—æé«˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOpenGS-SLAMåœ¨Waymoæ•°æ®é›†ä¸Šçš„è·Ÿè¸ªè¯¯å·®è¾ƒä¹‹å‰çš„3DGSæ–¹æ³•é™ä½äº†9.8%ï¼Œå¹¶åœ¨æ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OpenGS-SLAMæ˜¯ä¸€ç§é’ˆå¯¹æˆ·å¤–åœºæ™¯çš„RGB-onlyé«˜æ–¯èåˆSLAMæ–¹æ³•ã€‚</li>
<li>é€šè¿‡ç‚¹å›¾å›å½’ç½‘ç»œç”Ÿæˆç‚¹å›¾è¿›è¡Œå§¿æ€ä¼°è®¡ï¼Œè€ƒè™‘ç©ºé—´å…³ç³»å’Œåœºæ™¯å‡ ä½•ã€‚</li>
<li>æ•´åˆä¼°è®¡çš„ç›¸æœºå§¿æ€ä¸3DGSæ¸²æŸ“ï¼Œå®ç°ç³»ç»Ÿè·Ÿè¸ªç²¾åº¦çš„æ˜¾è‘—æé«˜ã€‚</li>
<li>è®¾è®¡äº†è‡ªé€‚åº”å°ºåº¦æ˜ å°„å™¨ï¼Œä¸ºç‚¹å›¾å›å½’ç½‘ç»œæä¾›æ›´å‡†ç¡®çš„ç‚¹å›¾æ˜ å°„åˆ°3DGSåœ°å›¾è¡¨ç¤ºã€‚</li>
<li>åœ¨Waymoæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒOpenGS-SLAMè¾ƒä¹‹å‰çš„3DGSæ–¹æ³•åœ¨è·Ÿè¸ªè¯¯å·®ä¸Šæœ‰æ‰€é™ä½ã€‚</li>
<li>OpenGS-SLAMåœ¨æ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15633">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d6693979169843a7573dc727360a497a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd8a6a9e797706d62473fe42f6c86bf3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f72b25d3ac037722acbeb514f8d82e3d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-48ed969b160d12603ea4a11af5d8fcb5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91f983deb59c75bc6eafae5ae20e39c9.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="DynamicGSG-Dynamic-3D-Gaussian-Scene-Graphs-for-Environment-Adaptation"><a href="#DynamicGSG-Dynamic-3D-Gaussian-Scene-Graphs-for-Environment-Adaptation" class="headerlink" title="DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation"></a>DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation</h2><p><strong>Authors:Luzhou Ge, Xiangyu Zhu, Zhuo Yang, Xuesong Li</strong></p>
<p>In real-world scenarios, environment changes caused by human or agent activities make it extremely challenging for robots to perform various long-term tasks. Recent works typically struggle to effectively understand and adapt to dynamic environments due to the inability to update their environment representations in memory according to environment changes and lack of fine-grained reconstruction of the environments. To address these challenges, we propose DynamicGSG, a dynamic, high-fidelity, open-vocabulary scene graph construction system leveraging Gaussian splatting. DynamicGSG builds hierarchical scene graphs using advanced vision language models to represent the spatial and semantic relationships between objects in the environments, utilizes a joint feature loss we designed to supervise Gaussian instance grouping while optimizing the Gaussian maps, and locally updates the Gaussian scene graphs according to real environment changes for long-term environment adaptation. Experiments and ablation studies demonstrate the performance and efficacy of our proposed method in terms of semantic segmentation, language-guided object retrieval, and reconstruction quality. Furthermore, we validate the dynamic updating capabilities of our system in real laboratory environments. The source code and supplementary experimental materials will be released at:~\href{<a target="_blank" rel="noopener" href="https://github.com/GeLuzhou/Dynamic-GSG%7D%7Bhttps://github.com/GeLuzhou/Dynamic-GSG%7D">https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/Dynamic-GSG}</a>. </p>
<blockquote>
<p>åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œç”±äºäººç±»æˆ–ä»£ç†æ´»åŠ¨å¼•èµ·çš„ç¯å¢ƒå˜åŒ–ä½¿å¾—æœºå™¨äººæ‰§è¡Œå„ç§é•¿æœŸä»»åŠ¡æå…·æŒ‘æˆ˜æ€§ã€‚è¿‘æœŸçš„å·¥ä½œå¾€å¾€éš¾ä»¥æœ‰æ•ˆåœ°ç†è§£å’Œé€‚åº”åŠ¨æ€ç¯å¢ƒï¼Œå› ä¸ºå®ƒä»¬æ— æ³•æ ¹æ®ç¯å¢ƒå˜åŒ–æ›´æ–°å†…å­˜ä¸­çš„ç¯å¢ƒè¡¨ç¤ºï¼Œå¹¶ä¸”ç¼ºä¹å¯¹ç¯å¢ƒçš„ç²¾ç»†ç²’åº¦é‡å»ºã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DynamicGSGï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„åŠ¨æ€ã€é«˜ä¿çœŸã€å¼€æ”¾è¯æ±‡åœºæ™¯å›¾æ„å»ºç³»ç»Ÿã€‚DynamicGSGä½¿ç”¨å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹æ„å»ºå±‚æ¬¡åœºæ™¯å›¾ï¼Œè¡¨ç¤ºç¯å¢ƒä¸­å¯¹è±¡ä¹‹é—´çš„ç©ºé—´å’Œè¯­ä¹‰å…³ç³»ï¼Œåˆ©ç”¨æˆ‘ä»¬è®¾è®¡çš„è”åˆç‰¹å¾æŸå¤±æ¥ç›‘ç£é«˜æ–¯å®ä¾‹åˆ†ç»„ï¼ŒåŒæ—¶ä¼˜åŒ–é«˜æ–¯åœ°å›¾ï¼Œå¹¶æ ¹æ®çœŸå®çš„ç¯å¢ƒå˜åŒ–å±€éƒ¨æ›´æ–°é«˜æ–¯åœºæ™¯å›¾ï¼Œä»¥å®ç°é•¿æœŸç¯å¢ƒé€‚åº”ã€‚å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜äº†æˆ‘ä»¬åœ¨è¯­ä¹‰åˆ†å‰²ã€è¯­è¨€å¼•å¯¼çš„å¯¹è±¡æ£€ç´¢å’Œé‡å»ºè´¨é‡æ–¹é¢æ‰€æå‡ºæ–¹æ³•çš„æ€§èƒ½å’Œæ•ˆæœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨çœŸå®çš„å®éªŒå®¤ç¯å¢ƒä¸­éªŒè¯äº†ç³»ç»Ÿçš„åŠ¨æ€æ›´æ–°èƒ½åŠ›ã€‚æºä»£ç å’Œè¡¥å……å®éªŒææ–™å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/GeLuzhou/Dynamic-GSG">https://github.com/GeLuzhou/Dynamic-GSG</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15309v2">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹ç°å®ä¸–ç•Œä¸­äººç±»æˆ–ä»£ç†æ´»åŠ¨å¼•èµ·çš„ç¯å¢ƒå˜åŒ–ï¼Œæœºå™¨äººæ‰§è¡Œé•¿æœŸä»»åŠ¡é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚è¿‘æœŸç ”ç©¶é€šå¸¸å› æ— æ³•æ ¹æ®ç¯å¢ƒå˜åŒ–æ›´æ–°å†…å­˜ä¸­çš„ç¯å¢ƒè¡¨ç¤ºä»¥åŠç¼ºä¹ç¯å¢ƒçš„ç²¾ç»†é‡å»ºï¼Œè€Œæ— æ³•æœ‰æ•ˆç†è§£å’Œé€‚åº”åŠ¨æ€ç¯å¢ƒã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºDynamicGSGç³»ç»Ÿï¼Œåˆ©ç”¨é«˜æ–¯å–·å°„æŠ€æœ¯æ„å»ºåŠ¨æ€ã€é«˜ä¿çœŸã€å¼€æ”¾è¯æ±‡åœºæ™¯å›¾ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹å»ºç«‹ç¯å¢ƒç‰©ä½“é—´çš„ç©ºé—´ä¸è¯­ä¹‰å…³ç³»ï¼Œè®¾è®¡è”åˆç‰¹å¾æŸå¤±ä»¥ç›‘ç£é«˜æ–¯å®ä¾‹åˆ†ç»„å¹¶ä¼˜åŒ–é«˜æ–¯å›¾ï¼Œæ ¹æ®çœŸå®ç¯å¢ƒå˜åŒ–å±€éƒ¨æ›´æ–°é«˜æ–¯åœºæ™¯å›¾ï¼Œå®ç°é•¿æœŸç¯å¢ƒé€‚åº”ã€‚å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜è¯¥æ–¹æ³•åœ¨è¯­ä¹‰åˆ†å‰²ã€è¯­è¨€å¼•å¯¼ç›®æ ‡æ£€ç´¢å’Œé‡å»ºè´¨é‡æ–¹é¢çš„æ€§èƒ½å’Œæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°å®ä¸–ç•Œä¸­ï¼Œç¯å¢ƒå˜åŒ–å¯¹æœºå™¨äººæ‰§è¡Œé•¿æœŸä»»åŠ¡æ„æˆæŒ‘æˆ˜ã€‚</li>
<li>è¿‘æœŸç ”ç©¶åœ¨ç†è§£å’Œé€‚åº”åŠ¨æ€ç¯å¢ƒæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œä¸»è¦åŸå› åŒ…æ‹¬æ— æ³•æ›´æ–°ç¯å¢ƒè¡¨ç¤ºå’Œç¼ºä¹ç²¾ç»†é‡å»ºã€‚</li>
<li>DynamicGSGç³»ç»Ÿåˆ©ç”¨é«˜æ–¯å–·å°„æŠ€æœ¯æ„å»ºåœºæ™¯å›¾ï¼Œå®ç°åŠ¨æ€ã€é«˜ä¿çœŸè¡¨ç¤ºã€‚</li>
<li>è¯¥ç³»ç»Ÿåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¡¨ç°ç‰©ä½“é—´çš„ç©ºé—´ä¸è¯­ä¹‰å…³ç³»ã€‚</li>
<li>é€šè¿‡è®¾è®¡çš„è”åˆç‰¹å¾æŸå¤±ç›‘ç£é«˜æ–¯å®ä¾‹åˆ†ç»„å¹¶ä¼˜åŒ–é«˜æ–¯å›¾ã€‚</li>
<li>DynamicGSGèƒ½æ ¹æ®å®é™…ç¯å¢ƒå˜åŒ–å±€éƒ¨æ›´æ–°åœºæ™¯å›¾ï¼Œå®ç°é•¿æœŸç¯å¢ƒé€‚åº”ã€‚</li>
<li>å®éªŒå’Œæ¶ˆèç ”ç©¶è¯æ˜è¯¥ç³»ç»Ÿåœ¨è¯­ä¹‰åˆ†å‰²ã€è¯­è¨€å¼•å¯¼ç›®æ ‡æ£€ç´¢å’Œé‡å»ºè´¨é‡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15309">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f2ebb2580cd7db49572c53f150366e77.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0737e2eb404c99655cc1419cd34bd9d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c5d42c5e189ed26b8751663b561d1bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-761c872fce30173dc03ae6071b4afa9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42fced7bd4741892a94cabe705f3ffe1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Hier-SLAM-Neuro-Symbolic-Semantic-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting"><a href="#Hier-SLAM-Neuro-Symbolic-Semantic-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting" class="headerlink" title="Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically   Categorical Gaussian Splatting"></a>Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically   Categorical Gaussian Splatting</h2><p><strong>Authors:Boying Li, Vuong Chi Hao, Peter J. Stuckey, Ian Reid, Hamid Rezatofighi</strong></p>
<p>We propose Hier-SLAM++, a comprehensive Neuro-Symbolic semantic 3D Gaussian Splatting SLAM method with both RGB-D and monocular input featuring an advanced hierarchical categorical representation, which enables accurate pose estimation as well as global 3D semantic mapping. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making scene understanding particularly challenging and costly. To address this problem, we introduce a novel and general hierarchical representation that encodes both semantic and geometric information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs) as well as the 3D generative model. By utilizing the proposed hierarchical tree structure, semantic information is symbolically represented and learned in an end-to-end manner. We further introduce a novel semantic loss designed to optimize hierarchical semantic information through both inter-level and cross-level optimization. Additionally, we propose an improved SLAM system to support both RGB-D and monocular inputs using a feed-forward model. To the best of our knowledge, this is the first semantic monocular Gaussian Splatting SLAM system, significantly reducing sensor requirements for 3D semantic understanding and broadening the applicability of semantic Gaussian SLAM system. We conduct experiments on both synthetic and real-world datasets, demonstrating superior or on-par performance with state-of-the-art NeRF-based and Gaussian-based SLAM systems, while significantly reducing storage and training time requirements. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†Hier-SLAM++æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å…¨é¢çš„ç¥ç»ç¬¦å·è¯­ä¹‰3Dé«˜æ–¯æ··åˆSLAMæ–¹æ³•ï¼Œå®ƒæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå¹¶é‡‡ç”¨äº†é«˜çº§åˆ†å±‚ç±»åˆ«è¡¨ç¤ºï¼Œèƒ½å¤Ÿå®ç°å‡†ç¡®çš„å§¿æ€ä¼°è®¡å’Œå…¨å±€3Dè¯­ä¹‰æ˜ å°„ã€‚éšç€ç¯å¢ƒå¤æ‚æ€§çš„å¢åŠ ï¼Œè¯­ä¹‰SLAMç³»ç»Ÿä¸­çš„å‚æ•°ä½¿ç”¨é‡ä¹Ÿæ˜¾è‘—å¢åŠ ï¼Œè¿™ä½¿å¾—åœºæ™¯ç†è§£å˜å¾—ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§å’Œæˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„åˆ†å±‚è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒä»¥ç´§å‡‘çš„å½¢å¼å°†è¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ç¼–ç åˆ°3Dé«˜æ–¯æ··åˆä¸­ï¼ŒåŒæ—¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œ3Dç”Ÿæˆæ¨¡å‹çš„çš„èƒ½åŠ›ã€‚é€šè¿‡åˆ©ç”¨æ‰€æå‡ºçš„å±‚æ¬¡æ ‘ç»“æ„ï¼Œè¯­ä¹‰ä¿¡æ¯ä»¥ç¬¦å·æ–¹å¼è¡¨ç¤ºå¹¶ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§æ–°å‹è¯­ä¹‰æŸå¤±ï¼Œæ—¨åœ¨é€šè¿‡è·¨çº§åˆ«ä¼˜åŒ–æ¥ä¼˜åŒ–åˆ†å±‚è¯­ä¹‰ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æ”¹è¿›å‹çš„SLAMç³»ç»Ÿï¼Œæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå¹¶ä½¿ç”¨å‰é¦ˆæ¨¡å‹ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè¯­ä¹‰å•ç›®é«˜æ–¯æ··åˆSLAMç³»ç»Ÿï¼Œå®ƒå¤§å¤§é™ä½äº†3Dè¯­ä¹‰ç†è§£çš„ä¼ æ„Ÿå™¨è¦æ±‚ï¼Œå¹¶æ‹“å®½äº†è¯­ä¹‰é«˜æ–¯SLAMç³»ç»Ÿçš„åº”ç”¨èŒƒå›´ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œè¡¨ç°å‡ºä¸æœ€æ–°åŸºäºNeRFå’Œé«˜æ–¯çš„æ–¹æ³•ç›¸åª²ç¾ç”šè‡³æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†å­˜å‚¨å’Œè®­ç»ƒæ—¶é—´è¦æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14931v1">PDF</a> 15 pages. Under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†Hier-SLAM++æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å…¨é¢çš„ç¥ç»ç¬¦å·è¯­ä¹‰3Dé«˜æ–¯å–·æ¶‚SLAMæ–¹æ³•ï¼Œæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå…·æœ‰å…ˆè¿›åˆ†å±‚ç±»åˆ«è¡¨ç¤ºã€‚è¯¥æ–¹æ³•é€šè¿‡ç»“åˆè¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œ3Dç”Ÿæˆæ¨¡å‹çš„æ½œåŠ›ï¼Œå®ç°äº†å‡†ç¡®å§¿æ€ä¼°è®¡å’Œå…¨å±€3Dè¯­ä¹‰æ˜ å°„ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§æ–°å‹çš„è¯­ä¹‰æŸå¤±ï¼Œé€šè¿‡è·¨çº§åˆ«ä¼˜åŒ–æ¥ä¼˜åŒ–å±‚æ¬¡è¯­ä¹‰ä¿¡æ¯ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºå“è¶Šæˆ–ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†å­˜å‚¨å’Œè®­ç»ƒæ—¶é—´è¦æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Hier-SLAM++æ˜¯ä¸€ç§å…¨é¢çš„ç¥ç»ç¬¦å·è¯­ä¹‰3Dé«˜æ–¯å–·æ¶‚SLAMæ–¹æ³•ï¼Œæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å…ˆè¿›çš„åˆ†å±‚ç±»åˆ«è¡¨ç¤ºï¼Œç»“åˆè¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œ3Dç”Ÿæˆæ¨¡å‹çš„æ½œåŠ›ï¼Œå®ç°å‡†ç¡®å§¿æ€ä¼°è®¡å’Œå…¨å±€3Dè¯­ä¹‰æ˜ å°„ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„è¯­ä¹‰æŸå¤±ï¼Œé€šè¿‡è·¨çº§åˆ«ä¼˜åŒ–å±‚æ¬¡è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>Hier-SLAM++èƒ½å¤Ÿå®ç°å±‚æ¬¡åŒ–è¯­ä¹‰ä¿¡æ¯çš„ç¬¦å·è¡¨ç¤ºå’Œå­¦ä¹ ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„æ€§èƒ½å“è¶Šï¼Œä¸åŸºäºNeRFå’Œé«˜æ–¯çš„æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-904acb442b6b3f202eef0441a750234f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77e84d60de5adc565e68889da8f969ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5623cf893b1044bf74f414a024477cef.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Sparse-Voxels-Rasterization-Real-time-High-fidelity-Radiance-Field-Rendering"><a href="#Sparse-Voxels-Rasterization-Real-time-High-fidelity-Radiance-Field-Rendering" class="headerlink" title="Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field   Rendering"></a>Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field   Rendering</h2><p><strong>Authors:Cheng Sun, Jaesung Choe, Charles Loop, Wei-Chiu Ma, Yu-Chiang Frank Wang</strong></p>
<p>We propose an efficient radiance field rendering algorithm that incorporates a rasterization process on adaptive sparse voxels without neural networks or 3D Gaussians. There are two key contributions coupled with the proposed system. The first is to adaptively and explicitly allocate sparse voxels to different levels of detail within scenes, faithfully reproducing scene details with $65536^3$ grid resolution while achieving high rendering frame rates. Second, we customize a rasterizer for efficient adaptive sparse voxels rendering. We render voxels in the correct depth order by using ray direction-dependent Morton ordering, which avoids the well-known popping artifact found in Gaussian splatting. Our method improves the previous neural-free voxel model by over 4db PSNR and more than 10x FPS speedup, achieving state-of-the-art comparable novel-view synthesis results. Additionally, our voxel representation is seamlessly compatible with grid-based 3D processing techniques such as Volume Fusion, Voxel Pooling, and Marching Cubes, enabling a wide range of future extensions and applications. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è¾å°„åœºæ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯¹è‡ªé€‚åº”ç¨€ç–ä½“ç´ è¿›è¡Œäº†æ …æ ¼åŒ–å¤„ç†ï¼Œæ— éœ€ç¥ç»ç½‘ç»œæˆ–3Dé«˜æ–¯ã€‚è¯¥ç³»ç»Ÿçš„å…³é”®è´¡çŒ®æœ‰ä¸¤ç‚¹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è‡ªé€‚åº”ä¸”æ˜ç¡®åœ°åˆ†é…ç¨€ç–ä½“ç´ ä»¥å‘ˆç°åœºæ™¯ä¸­çš„ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œä»¥$65536^3$çš„ç½‘æ ¼åˆ†è¾¨ç‡å¿ å®å†ç°åœºæ™¯ç»†èŠ‚ï¼ŒåŒæ—¶å®ç°é«˜å¸§ç‡æ¸²æŸ“ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬ä¸ºè‡ªé€‚åº”ç¨€ç–ä½“ç´ æ¸²æŸ“å®šåˆ¶äº†ä¸€ä¸ªæ …æ ¼åŒ–å™¨ã€‚é€šè¿‡ä½¿ç”¨ä¸å°„çº¿æ–¹å‘ç›¸å…³çš„Mortonæ’åºï¼Œæˆ‘ä»¬ä»¥æ­£ç¡®çš„æ·±åº¦é¡ºåºå‘ˆç°ä½“ç´ ï¼Œè¿™é¿å…äº†é«˜æ–¯æ¶‚æŠ¹ä¸­å‡ºç°çš„å·²çŸ¥é—ªçƒä¼ªå½±ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ”¹è¿›äº†ä¹‹å‰æ— ç¥ç»å…ƒçš„ä½“ç´ æ¨¡å‹ï¼Œæé«˜äº†è¶…è¿‡4dbçš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œè¶…è¿‡10å€çš„å¸§ç‡åŠ é€Ÿï¼Œå®ç°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ä½“ç´ è¡¨ç¤ºä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯ï¼ˆå¦‚ä½“ç§¯èåˆã€ä½“ç´ æ± åŒ–å’Œé­”æ–¹ç½‘ï¼‰æ— ç¼å…¼å®¹ï¼Œä¸ºæœªæ¥çš„æ‰©å±•å’Œåº”ç”¨æä¾›äº†å¹¿æ³›çš„å¯èƒ½æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04459v2">PDF</a> Project page at <a target="_blank" rel="noopener" href="https://svraster.github.io/">https://svraster.github.io/</a> Code at   <a target="_blank" rel="noopener" href="https://github.com/NVlabs/svraster">https://github.com/NVlabs/svraster</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è¾å°„åœºæ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯¹è‡ªé€‚åº”ç¨€ç–ä½“ç´ è¿›è¡Œäº†æ …æ ¼åŒ–å¤„ç†ï¼Œæ— éœ€ç¥ç»ç½‘ç»œæˆ–3Dé«˜æ–¯ã€‚è¯¥ç³»ç»Ÿæœ‰ä¸¤é¡¹å…³é”®è´¡çŒ®ï¼šä¸€æ˜¯è‡ªé€‚åº”æ˜¾å¼åˆ†é…ç¨€ç–ä½“ç´ ä»¥å‘ˆç°åœºæ™¯ä¸­çš„ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œä»¥$65536^3$ç½‘æ ¼åˆ†è¾¨ç‡å¿ å®å†ç°åœºæ™¯ç»†èŠ‚ï¼ŒåŒæ—¶å®ç°é«˜å¸§ç‡æ¸²æŸ“ï¼›äºŒæ˜¯ä¸ºè‡ªé€‚åº”ç¨€ç–ä½“ç´ æ¸²æŸ“å®šåˆ¶äº†æ …æ ¼åŒ–å™¨ï¼Œé€šè¿‡é‡‡ç”¨ä¸å°„çº¿æ–¹å‘ç›¸å…³çš„Mortonæ’åºå¯¹ä½“ç´ è¿›è¡Œæ­£ç¡®çš„æ·±åº¦æ’åºï¼Œé¿å…äº†é«˜æ–¯æº…å°„ä¸­çš„å¼¹å‡ºä¼ªå½±ã€‚è¯¥æ–¹æ³•æ”¹è¿›äº†ä¹‹å‰çš„æ— ç¥ç»ç½‘ç»œä½“ç´ æ¨¡å‹ï¼Œæé«˜äº†4db PSNRä»¥ä¸Šï¼Œå¹¶å®ç°äº†è¶…è¿‡10å€FPSçš„åŠ é€Ÿï¼Œè¾¾åˆ°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆæ•ˆæœã€‚æ­¤å¤–ï¼Œå…¶ä½“ç´ è¡¨ç¤ºä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯ï¼ˆå¦‚ä½“ç§¯èåˆã€ä½“ç´ æ± åŒ–å’Œè¡Œèµ°ç«‹æ–¹ä½“ï¼‰æ— ç¼å…¼å®¹ï¼Œä¸ºæœªæ¥æ‰©å±•å’Œåº”ç”¨æä¾›äº†å¹¿æ³›çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ä¸ªé«˜æ•ˆçš„è¾å°„åœºæ¸²æŸ“ç®—æ³•ï¼Œç»“åˆäº†æ …æ ¼åŒ–å¤„ç†å’Œè‡ªé€‚åº”ç¨€ç–ä½“ç´ ã€‚</li>
<li>è‡ªé€‚åº”åˆ†é…ç¨€ç–ä½“ç´ ä»¥å‘ˆç°ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œè¾¾åˆ°$65536^3$ç½‘æ ¼åˆ†è¾¨ç‡ï¼ŒåŒæ—¶ä¿æŒé«˜å¸§ç‡æ¸²æŸ“ã€‚</li>
<li>å®šåˆ¶äº†æ …æ ¼åŒ–å™¨ï¼Œå¯¹ä½“ç´ è¿›è¡Œæ­£ç¡®çš„æ·±åº¦æ’åºï¼Œé¿å…äº†å¼¹å‡ºä¼ªå½±ã€‚</li>
<li>æ”¹è¿›äº†æ— ç¥ç»ç½‘ç»œä½“ç´ æ¨¡å‹ï¼Œæé«˜äº†æ¸²æŸ“æ•ˆæœã€‚</li>
<li>ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆæ•ˆæœã€‚</li>
<li>ä½“ç´ è¡¨ç¤ºä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯å…¼å®¹ï¼Œä¸ºæœªæ¥æ‰©å±•æä¾›äº†å¹¿æ³›çš„å¯èƒ½æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.04459">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e0f18e0de6e7da52ca70232b4e12be10.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-23324b63348569dbc19df11978ade553.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5ffe7a0d584080719e00c16399fc129.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aaed7d1f8b988755acf557e77e9591bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-98780617d1b9a37e72dd8c80afa1cefa.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="SplatOverflow-Asynchronous-Hardware-Troubleshooting"><a href="#SplatOverflow-Asynchronous-Hardware-Troubleshooting" class="headerlink" title="SplatOverflow: Asynchronous Hardware Troubleshooting"></a>SplatOverflow: Asynchronous Hardware Troubleshooting</h2><p><strong>Authors:Amritansh Kwatra, Tobias Weinberg, Ilan Mandel, Ritik Batra, Peter He, Francois Guimbretiere, Thijs Roumen</strong></p>
<p>As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware. However, processes for supporting end-user hardware troubleshooting or routine maintenance arenâ€™t well defined. As a result, providing technical support for hardware remains ad-hoc and challenging to scale. Inspired by patterns that helped scale software troubleshooting, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow.   SplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware. A scene comprises a 3D Gaussian Splat of the userâ€™s hardware registered onto the hardwareâ€™s CAD model. The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions. With SplatOverflow, remote maintainers can directly address issues and author instructions in the userâ€™s workspace. Workflows containing multiple instructions can easily be shared between users and recontextualized in new environments.   In this paper, we describe the design of SplatOverflow, the workflows it enables, and its utility to different kinds of users. We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a usability study.   Project Page: <a target="_blank" rel="noopener" href="https://amritkwatra.com/research/splatoverflow">https://amritkwatra.com/research/splatoverflow</a>. </p>
<blockquote>
<p>éšç€è®¾è®¡å’Œåˆ¶é€ ç¡¬ä»¶çš„å·¥å…·è¶Šæ¥è¶Šå®¹æ˜“è·å–ï¼Œå°å‹ç”Ÿäº§å•†å¯ä»¥å¼€å‘å’Œåˆ†å‘æ–°å‹ç¡¬ä»¶ã€‚ç„¶è€Œï¼Œæ”¯æŒæœ€ç»ˆç”¨æˆ·ç¡¬ä»¶æ•…éšœæ’é™¤æˆ–å¸¸è§„ç»´æŠ¤çš„æµç¨‹å¹¶æœªå¾—åˆ°å¾ˆå¥½çš„å®šä¹‰ã€‚å› æ­¤ï¼Œä¸ºç¡¬ä»¶æä¾›æŠ€æœ¯æ”¯æŒä»ç„¶æ˜¯ä¸´æ—¶æ€§çš„ï¼Œå¹¶ä¸”éš¾ä»¥æ‰©å±•ã€‚å—è½¯ä»¶æ•…éšœæ’é™¤æ¨¡å¼çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¼‚æ­¥ç¡¬ä»¶æ•…éšœæ’é™¤çš„å·¥ä½œæµç¨‹ï¼šSplatOverflowã€‚SplatOverflowåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„è¾¹ç•Œå¯¹è±¡â€”â€”SplatOverflowåœºæ™¯ï¼Œç”¨æˆ·å‚è€ƒè¯¥åœºæ™¯æ¥äº¤æµç¡¬ä»¶é—®é¢˜ã€‚ä¸€ä¸ªåœºæ™¯åŒ…å«äº†ç”¨æˆ·çš„ç¡¬ä»¶çš„3Dé«˜æ–¯Splatï¼Œè¯¥Splatè¢«æ³¨å†Œåˆ°ç¡¬ä»¶çš„CADæ¨¡å‹ä¸Šã€‚Splatæ•æ‰ç¡¬ä»¶çš„å½“å‰çŠ¶æ€ï¼Œè€Œæ³¨å†Œçš„CADæ¨¡å‹åˆ™ä½œä¸ºæ•…éšœæ’é™¤æŒ‡ä»¤çš„å‚è€ƒé”šç‚¹ã€‚é€šè¿‡SplatOverflowï¼Œè¿œç¨‹ç»´æŠ¤äººå‘˜å¯ä»¥ç›´æ¥åœ¨ç”¨æˆ·çš„å·¥ä½œç©ºé—´ä¸­è§£å†³é—®é¢˜å¹¶å‘å¸ƒæŒ‡ä»¤ã€‚åŒ…å«å¤šä¸ªæŒ‡ä»¤çš„å·¥ä½œæµç¨‹å¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ç”¨æˆ·ä¹‹é—´å…±äº«ï¼Œå¹¶åœ¨æ–°çš„ç¯å¢ƒä¸­é‡æ–°ä¸Šä¸‹æ–‡åŒ–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SplatOverflowçš„è®¾è®¡ã€å®ƒä½¿èƒ½çš„å·¥ä½œæµç¨‹ï¼Œä»¥åŠå®ƒå¯¹ä¸åŒç±»å‹ç”¨æˆ·çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸€é¡¹å¯ç”¨æ€§ç ”ç©¶éªŒè¯äº†éä¸“å®¶å¯ä»¥ä½¿ç”¨SplatOverflowæ¥æ’é™¤3Dæ‰“å°æœºçš„ä¸€èˆ¬é—®é¢˜ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://amritkwatra.com/research/splatoverflow%E3%80%82">https://amritkwatra.com/research/splatoverflowã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.02332v3">PDF</a> Our accompanying video figure is available at:   <a target="_blank" rel="noopener" href="https://youtu.be/rdtaUo2Lo38">https://youtu.be/rdtaUo2Lo38</a></p>
<p><strong>Summary</strong><br>     éšç€è®¾è®¡ä¸åˆ¶é€ ç¡¬ä»¶çš„å·¥å…·æ—¥ç›Šæ™®åŠï¼Œå°å‹ç”Ÿäº§å•†å¯å¼€å‘å¹¶åˆ†å‘æ–°å‹ç¡¬ä»¶ã€‚ç„¶è€Œï¼Œæ”¯æŒç»ˆç«¯ç”¨æˆ·ç¡¬ä»¶æ•…éšœæ’é™¤æˆ–å¸¸è§„ç»´æŠ¤çš„æµç¨‹å°šæœªæ˜ç¡®ï¼Œä¸ºç¡¬ä»¶æä¾›æŠ€æœ¯æ”¯æŒä»æ˜¯ä¸´æ—¶æ€§çš„ï¼Œéš¾ä»¥æ‰©å±•ã€‚å—è½¯ä»¶æ•…éšœæ’é™¤æ¨¡å¼çš„å¯å‘ï¼Œæå‡ºä¸€ç§å¼‚æ­¥ç¡¬ä»¶æ•…éšœæ’é™¤çš„å·¥ä½œæµç¨‹ï¼šSplatOverflowã€‚SplatOverflowåˆ›å»ºäº†ä¸€ç§æ–°å‹è¾¹ç•Œå¯¹è±¡â€”â€”SplatOverflowåœºæ™¯ï¼Œç”¨æˆ·å¯é€šè¿‡æ­¤åœºæ™¯äº¤æµç¡¬ä»¶æƒ…å†µã€‚åœºæ™¯åŒ…å«ç”¨æˆ·ç¡¬ä»¶çš„3Dé«˜æ–¯Splatï¼Œå¹¶æ³¨å†Œåˆ°ç¡¬ä»¶çš„CADæ¨¡å‹ä¸Šã€‚Splatè®°å½•ç¡¬ä»¶çš„å½“å‰çŠ¶æ€ï¼Œæ³¨å†Œçš„CADæ¨¡å‹åˆ™ä¸ºæ•…éšœæ’é™¤è¯´æ˜æä¾›å‚ç…§é”šç‚¹ã€‚å€ŸåŠ©SplatOverflowï¼Œè¿œç¨‹ç»´æŠ¤äººå‘˜å¯ç›´æ¥é’ˆå¯¹ç”¨æˆ·é—®é¢˜å‘è¡¨è¯´æ˜ï¼Œå¹¶åœ¨ç”¨æˆ·å·¥ä½œç©ºé—´ä¸­æ‰§è¡Œå·¥ä½œæµã€‚åŒ…å«å¤šä¸ªè¯´æ˜çš„å·¥ä½œæµç¨‹å¯è½»æ¾åœ¨ç”¨æˆ·ä¹‹é—´å…±äº«ï¼Œå¹¶é€‚åº”æ–°ç¯å¢ƒã€‚æœ¬æ–‡ä»‹ç»äº†SplatOverflowçš„è®¾è®¡ã€å…¶æ”¯æŒçš„å·¥ä½œæµç¨‹ä»¥åŠå…¶å¯¹ä¸åŒç±»å‹ç”¨æˆ·çš„å®ç”¨æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¸€é¡¹å¯ç”¨æ€§ç ”ç©¶éªŒè¯äº†éä¸“å®¶ä½¿ç”¨SplatOverflowå¯¹3Dæ‰“å°æœºè¿›è¡Œæ•…éšœæ’é™¤çš„å¯è¡Œæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¾ƒå°ç”Ÿäº§å•†å¯å€ŸåŠ©æ—¥ç›Šæ™®åŠçš„è®¾è®¡å·¥å…·å¼€å‘æ–°å‹ç¡¬ä»¶ã€‚</li>
<li>ç›®å‰ç¡¬ä»¶æŠ€æœ¯æ”¯æŒå­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚æ•…éšœæ’é™¤å’Œå¸¸è§„ç»´æŠ¤æµç¨‹ä¸æ˜ç¡®ã€‚</li>
<li>SplatOverflowå€Ÿé‰´è½¯ä»¶æ•…éšœæ’é™¤æ¨¡å¼ï¼Œæä¾›ä¸€ç§å¼‚æ­¥ç¡¬ä»¶æ•…éšœæ’é™¤è§£å†³æ–¹æ¡ˆã€‚</li>
<li>SplatOverflowåˆ›å»ºæ–°å‹è¾¹ç•Œå¯¹è±¡â€”â€”SplatOverflowåœºæ™¯ï¼Œç”¨äºç”¨æˆ·é—´çš„ç¡¬ä»¶äº¤æµã€‚</li>
<li>è¯¥ç³»ç»Ÿç»“åˆ3Dé«˜æ–¯Splatå’Œç”¨æˆ·ç¡¬ä»¶çš„CADæ¨¡å‹ï¼Œæä¾›ç¡¬ä»¶çŠ¶æ€çš„ç›´è§‚å±•ç¤ºå’Œå‚ç…§ã€‚</li>
<li>SplatOverflowå…è®¸è¿œç¨‹ç»´æŠ¤äººå‘˜ç›´æ¥å‚ä¸ç”¨æˆ·é—®é¢˜å¤„ç†ï¼Œå¹¶åœ¨ç”¨æˆ·å·¥ä½œç©ºé—´ä¸­æ‰§è¡Œå·¥ä½œæµã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.02332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5f36a2ee3ebc6ee4985a9d2462913c01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78a05cf37cce108b9abda447c0a7a5fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fd176e18b81a2c84abb8d2ea93fa1eed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf684aa9edac53139c717e88777f6d98.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85312db9b8cc072a245fd4d1c4ca17d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ded62d018b4f6a1b30109b8638d61571.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e865e937860939f44a8351515024970.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="GSORB-SLAM-Gaussian-Splatting-SLAM-benefits-from-ORB-features-and-Transmittance-information"><a href="#GSORB-SLAM-Gaussian-Splatting-SLAM-benefits-from-ORB-features-and-Transmittance-information" class="headerlink" title="GSORB-SLAM: Gaussian Splatting SLAM benefits from ORB features and   Transmittance information"></a>GSORB-SLAM: Gaussian Splatting SLAM benefits from ORB features and   Transmittance information</h2><p><strong>Authors:Wancai Zheng, Xinyi Yu, Jintao Rong, Linlin Ou, Yan Wei, Libo Zhou</strong></p>
<p>The emergence of 3D Gaussian Splatting (3DGS) has recently ignited a renewed wave of research in dense visual SLAM. However, existing approaches encounter challenges, including sensitivity to artifacts and noise, suboptimal selection of training viewpoints, and the absence of global optimization. In this paper, we propose GSORB-SLAM, a dense SLAM framework that integrates 3DGS with ORB features through a tightly coupled optimization pipeline. To mitigate the effects of noise and artifacts, we propose a novel geometric representation and optimization method for tracking, which significantly enhances localization accuracy and robustness. For high-fidelity mapping, we develop an adaptive Gaussian expansion and regularization method that facilitates compact yet expressive scene modeling while suppressing redundant primitives. Furthermore, we design a hybrid graph-based viewpoint selection mechanism that effectively reduces overfitting and accelerates convergence. Extensive evaluations across various datasets demonstrate that our system achieves state-of-the-art performance in both tracking precision-improving RMSE by 16.2% compared to ORB-SLAM2 baselines-and reconstruction quality-improving PSNR by 3.93 dB compared to 3DGS-SLAM baselines. The project: <a target="_blank" rel="noopener" href="https://aczheng-cai.github.io/gsorb-slam.github.io/">https://aczheng-cai.github.io/gsorb-slam.github.io/</a> </p>
<blockquote>
<p>3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰çš„å‡ºç°ï¼Œå¼•å‘äº†å¯†é›†è§†è§‰SLAMé¢†åŸŸçš„æ–°ä¸€è½®ç ”ç©¶çƒ­æ½®ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å®¹æ˜“å—åˆ°ä¼ªå½±å’Œå™ªå£°çš„å½±å“ã€è®­ç»ƒè§†è§’é€‰æ‹©ä¸ä½³ä»¥åŠç¼ºä¹å…¨å±€ä¼˜åŒ–ç­‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GSORB-SLAMï¼Œè¿™æ˜¯ä¸€ä¸ªå¯†é›†SLAMæ¡†æ¶ï¼Œå®ƒé€šè¿‡ç´§å¯†è€¦åˆçš„ä¼˜åŒ–ç®¡é“å°†3DGSä¸ORBç‰¹å¾ç›¸ç»“åˆã€‚ä¸ºäº†å‡è½»å™ªå£°å’Œä¼ªå½±çš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å‡ ä½•è¡¨ç¤ºå’Œä¼˜åŒ–æ–¹æ³•ç”¨äºè·Ÿè¸ªï¼Œè¿™æ˜¾è‘—æé«˜äº†å®šä½ç²¾åº¦å’Œç¨³å¥æ€§ã€‚ä¸ºäº†å®ç°é«˜ä¿çœŸæ˜ å°„ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è‡ªé€‚åº”é«˜æ–¯æ‰©å±•å’Œæ­£åˆ™åŒ–æ–¹æ³•ï¼Œä¾¿äºç´§å‡‘è€Œå¯Œæœ‰è¡¨ç°åŠ›çš„åœºæ™¯å»ºæ¨¡ï¼ŒåŒæ—¶æŠ‘åˆ¶å†—ä½™åŸºæœ¬å…ƒç´ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºæ··åˆå›¾çš„è§†è§’é€‰æ‹©æœºåˆ¶ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†è¿‡åº¦æ‹Ÿåˆå¹¶åŠ é€Ÿäº†æ”¶æ•›ã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåœ¨è·Ÿè¸ªç²¾åº¦ä¸Šå®ç°äº†æœ€æ–°æ€§èƒ½ï¼Œä¸ORB-SLAM2åŸºå‡†ç›¸æ¯”ï¼ŒRMSEæé«˜äº†16.2%ï¼Œåœ¨é‡å»ºè´¨é‡ä¸Šä¹Ÿå®ç°äº†æ”¹è¿›ï¼Œä¸3DGS-SLAMåŸºå‡†ç›¸æ¯”ï¼ŒPSNRæé«˜äº†3.93 dBã€‚é¡¹ç›®ç½‘å€ï¼š[<a target="_blank" rel="noopener" href="https://aczheng-cai.github.io/gsorb-slam.github.io/]">https://aczheng-cai.github.io/gsorb-slam.github.io/]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11356v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆä¸‰ç»´é«˜æ–¯å–·å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰ä¸ORBç‰¹å¾çš„å¯†é›†SLAMæ¡†æ¶â€”â€”GSORB-SLAMã€‚é€šè¿‡ç´§å¯†è€¦åˆçš„ä¼˜åŒ–ç®¡é“ï¼Œè§£å†³äº†å™ªå£°å’Œä¼ªå½±é—®é¢˜ï¼Œæé«˜äº†è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡è‡ªé€‚åº”é«˜æ–¯æ‰©å±•å’Œæ­£åˆ™åŒ–æ–¹æ³•å®ç°é«˜ä¿çœŸåº¦æ˜ å°„ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§åŸºäºæ··åˆå›¾çš„è§†ç‚¹é€‰æ‹©æœºåˆ¶ï¼Œæœ‰æ•ˆå‡å°‘è¿‡æ‹Ÿåˆå¹¶åŠ é€Ÿæ”¶æ•›ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨è·Ÿè¸ªç²¾åº¦å’Œé‡å»ºè´¨é‡æ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥ä¸‰ç»´é«˜æ–¯å–·å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰äºå¯†é›†SLAMæ¡†æ¶ä¸­ï¼Œä¸ORBç‰¹å¾ç»“åˆã€‚</li>
<li>æå‡ºæ–°å‹å‡ ä½•è¡¨ç¤ºå’Œä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æé«˜è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œå¹¶å‡å°‘å™ªå£°å’Œä¼ªå½±çš„å½±å“ã€‚</li>
<li>é€šè¿‡è‡ªé€‚åº”é«˜æ–¯æ‰©å±•å’Œæ­£åˆ™åŒ–æ–¹æ³•å®ç°ç´§å‡‘è€Œè¡¨ç°ä¸°å¯Œçš„åœºæ™¯å»ºæ¨¡ï¼ŒåŒæ—¶æŠ‘åˆ¶å†—ä½™å…ƒç´ ã€‚</li>
<li>è®¾è®¡åŸºäºæ··åˆå›¾çš„è§†ç‚¹é€‰æ‹©æœºåˆ¶ï¼Œæœ‰æ•ˆå‡å°‘è¿‡æ‹Ÿåˆï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚</li>
<li>ç³»ç»Ÿåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè·Ÿè¸ªç²¾åº¦å’Œé‡å»ºè´¨é‡å‡è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>ç³»ç»Ÿæ€§èƒ½ç›¸è¾ƒäºORB-SLAM2åŸºçº¿æé«˜äº†RMSEçš„16.2%ï¼Œç›¸è¾ƒäº3DGS-SLAMåŸºçº¿æé«˜äº†PSNRçš„3.93dBã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11356">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-020aa1580a8801d25215dcc67c1c2f71.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d2c33ec362c46ded957ae862f74607e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2709170f8399e6380de4e174f9485fd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3167f2530a7fd9f948c7937c783d46d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-85dc378941b928aa49a09023b0e7e618.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f27992f729c4800cbdf7bd0b78850c58.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aedae076d7b61ff0b57d5c2fe9f410b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-13f3d11f625be5491e6f94fdade2b01e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1987d58185774077e38daab136589e0d.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="LayerPano3D-Layered-3D-Panorama-for-Hyper-Immersive-Scene-Generation"><a href="#LayerPano3D-Layered-3D-Panorama-for-Hyper-Immersive-Scene-Generation" class="headerlink" title="LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation"></a>LayerPano3D: Layered 3D Panorama for Hyper-Immersive Scene Generation</h2><p><strong>Authors:Shuai Yang, Jing Tan, Mengchen Zhang, Tong Wu, Yixuan Li, Gordon Wetzstein, Ziwei Liu, Dahua Lin</strong></p>
<p>3D immersive scene generation is a challenging yet critical task in computer vision and graphics. A desired virtual 3D scene should 1) exhibit omnidirectional view consistency, and 2) allow for free exploration in complex scene hierarchies. Existing methods either rely on successive scene expansion via inpainting or employ panorama representation to represent large FOV scene environments. However, the generated scene suffers from semantic drift during expansion and is unable to handle occlusion among scene hierarchies. To tackle these challenges, we introduce Layerpano3D, a novel framework for full-view, explorable panoramic 3D scene generation from a single text prompt. Our key insight is to decompose a reference 2D panorama into multiple layers at different depth levels, where each layer reveals the unseen space from the reference views via diffusion prior. Layerpano3D comprises multiple dedicated designs: 1) We introduce a new panorama dataset Upright360, comprising 9k high-quality and upright panorama images, and finetune the advanced Flux model on Upright360 for high-quality, upright and consistent panorama generation. 2) We pioneer the Layered 3D Panorama as underlying representation to manage complex scene hierarchies and lift it into 3D Gaussians to splat detailed 360-degree omnidirectional scenes with unconstrained viewing paths. Extensive experiments demonstrate that our framework generates state-of-the-art 3D panoramic scene in both full view consistency and immersive exploratory experience. We believe that Layerpano3D holds promise for advancing 3D panoramic scene creation with numerous applications. </p>
<blockquote>
<p>3Dæ²‰æµ¸å¼åœºæ™¯ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­å…·æœ‰æŒ‘æˆ˜æ€§å’Œé‡è¦æ€§çš„ä»»åŠ¡ã€‚ç†æƒ³çš„è™šæ‹Ÿ3Dåœºæ™¯åº”è¯¥1ï¼‰è¡¨ç°å‡ºå…¨æ–¹ä½çš„è§†å›¾ä¸€è‡´æ€§ï¼Œå¹¶ä¸”2ï¼‰å…è®¸åœ¨å¤æ‚çš„åœºæ™¯å±‚æ¬¡ç»“æ„ä¸­è‡ªç”±æ¢ç´¢ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºé€šè¿‡æ’å€¼è¿›è¡Œçš„è¿ç»­åœºæ™¯æ‰©å±•ï¼Œè¦ä¹ˆä½¿ç”¨å…¨æ™¯è¡¨ç¤ºæ¥è¡¨ç¤ºå¤§è§†åœºåœºæ™¯ç¯å¢ƒã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„åœºæ™¯åœ¨æ‰©å±•è¿‡ç¨‹ä¸­ä¼šå‡ºç°è¯­ä¹‰æ¼‚ç§»ï¼Œå¹¶ä¸”æ— æ³•å¤„ç†åœºæ™¯å±‚æ¬¡ç»“æ„ä¹‹é—´çš„é®æŒ¡é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Layerpano3Dï¼Œè¿™æ˜¯ä¸€ç§ä»å•ä¸ªæ–‡æœ¬æç¤ºç”Ÿæˆå…¨æ–¹ä½å¯æ¢ç´¢å…¨æ™¯3Dåœºæ™¯çš„æ–°æ¡†æ¶ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯å°†å‚è€ƒçš„2Då…¨æ™¯å›¾åˆ†è§£æˆä¸åŒæ·±åº¦çº§åˆ«çš„å¤šä¸ªå›¾å±‚ï¼Œæ¯ä¸ªå›¾å±‚é€šè¿‡æ‰©æ•£å…ˆéªŒä»å‚è€ƒè§†å›¾ä¸­æ­ç¤ºæœªè§ç©ºé—´ã€‚Layerpano3DåŒ…å«å¤šä¸ªä¸“ç”¨è®¾è®¡ï¼š1ï¼‰æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å…¨æ™¯æ•°æ®é›†Upright360ï¼ŒåŒ…å«9kä¸ªé«˜è´¨é‡å’Œç›´ç«‹å…¨æ™¯å›¾åƒï¼Œå¹¶åœ¨Upright360ä¸Šå¯¹å…ˆè¿›çš„Fluxæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥å®ç°é«˜è´¨é‡ã€ç›´ç«‹å’Œä¸€è‡´çš„å…¨æ™¯ç”Ÿæˆã€‚2ï¼‰æˆ‘ä»¬é¦–åˆ›åˆ†å±‚3Då…¨æ™¯å›¾ä½œä¸ºåº•å±‚è¡¨ç¤ºæ¥ç®¡ç†å¤æ‚çš„åœºæ™¯å±‚æ¬¡ç»“æ„ï¼Œå¹¶å°†å…¶æå‡åˆ°3Dé«˜æ–¯å‡½æ•°ï¼Œä»¥æç»˜å…·æœ‰æ— çº¦æŸè§‚çœ‹è·¯å¾„çš„360åº¦å…¨æ–¹ä½åœºæ™¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å…¨æ™¯ä¸€è‡´æ€§ä»¥åŠæ²‰æµ¸å¼æ¢ç´¢ä½“éªŒæ–¹é¢éƒ½ç”Ÿæˆäº†æœ€å…ˆè¿›çš„3Då…¨æ™¯åœºæ™¯ã€‚æˆ‘ä»¬ç›¸ä¿¡Layerpano3Dåœ¨æ¨è¿›3Då…¨æ™¯åœºæ™¯åˆ›å»ºæ–¹é¢å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.13252v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://ys-imtech.github.io/projects/LayerPano3D/">https://ys-imtech.github.io/projects/LayerPano3D/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Layerpano3Dæ¡†æ¶ï¼Œè¯¥æ¡†æ¶è§£å†³äº†å…¨æ™¯ä¸‰ç»´åœºæ™¯ç”Ÿæˆä¸­çš„æŒ‘æˆ˜æ€§é—®é¢˜ã€‚é€šè¿‡åˆ†è§£å‚è€ƒå…¨æ™¯å›¾åƒä¸ºä¸åŒæ·±åº¦å±‚æ¬¡çš„å¤šä¸ªå›¾å±‚ï¼Œå¹¶é‡‡ç”¨æ‰©æ•£å…ˆéªŒæŠ€æœ¯æ­ç¤ºæœªè§‚å¯Ÿåˆ°çš„ç©ºé—´ï¼Œå®ç°äº†ä»å•ä¸ªæ–‡æœ¬æç¤ºç”Ÿæˆå…¨æ™¯ä¸‰ç»´åœºæ™¯ã€‚æ¡†æ¶åŒ…æ‹¬ä¸“é—¨è®¾è®¡çš„é«˜å“è´¨å…¨æ™¯æ•°æ®é›†Upright360å’ŒåŸºäºè¯¥æ•°æ®é›†çš„å…ˆè¿›Fluxæ¨¡å‹çš„å¾®è°ƒã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å…¨æ™¯ä¸€è‡´æ€§åŠæ²‰æµ¸å¼æ¢ç´¢ä½“éªŒæ–¹é¢è¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Layerpano3Dæ¡†æ¶è§£å†³äº†å…¨æ™¯ä¸‰ç»´åœºæ™¯ç”Ÿæˆä¸­çš„æŒ‘æˆ˜æ€§é—®é¢˜ã€‚</li>
<li>é€šè¿‡åˆ†è§£å…¨æ™¯å›¾åƒä¸ºå¤šä¸ªæ·±åº¦å±‚æ¬¡çš„å›¾å±‚ï¼Œå¹¶é‡‡ç”¨æ‰©æ•£å…ˆéªŒæŠ€æœ¯æ­ç¤ºæœªè§‚å¯Ÿåˆ°çš„ç©ºé—´ã€‚</li>
<li>åˆ©ç”¨æ–‡æœ¬æç¤ºç”Ÿæˆå…¨æ™¯ä¸‰ç»´åœºæ™¯ã€‚</li>
<li>Upright360æ•°æ®é›†ç”¨äºé«˜è´¨é‡å…¨æ™¯å›¾åƒç”Ÿæˆã€‚</li>
<li>é‡‡ç”¨å…ˆè¿›Fluxæ¨¡å‹è¿›è¡Œå…¨æ™¯å›¾åƒç”Ÿæˆã€‚</li>
<li>Layerpano3Dæ¡†æ¶å®ç°äº†å…¨æ™¯ä¸€è‡´æ€§åŠæ²‰æµ¸å¼æ¢ç´¢ä½“éªŒçš„å…¨æ™¯ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.13252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9b2cbbcf9e005dc580071bdd456332da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b90518982b5ed73b88044bd09c1f5e5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-476db1de01c13d0daab20af8dd94eda9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a7ef3bbb3c36c7392d2e2cdac4b45590.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5b7e3819346853529b491aca42eb6bc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-692b1c1e4b2e81e667f14d557ec5fd7a.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Rethinking-Open-Vocabulary-Segmentation-of-Radiance-Fields-in-3D-Space"><a href="#Rethinking-Open-Vocabulary-Segmentation-of-Radiance-Fields-in-3D-Space" class="headerlink" title="Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space"></a>Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space</h2><p><strong>Authors:Hyunjee Lee, Youngsik Yun, Jeongmin Bae, Seoha Kim, Youngjung Uh</strong></p>
<p>Understanding the 3D semantics of a scene is a fundamental problem for various scenarios such as embodied agents. While NeRFs and 3DGS excel at novel-view synthesis, previous methods for understanding their semantics have been limited to incomplete 3D understanding: their segmentation results are rendered as 2D masks that do not represent the entire 3D space. To address this limitation, we redefine the problem to segment the 3D volume and propose the following methods for better 3D understanding. We directly supervise the 3D points to train the language embedding field, unlike previous methods that anchor supervision at 2D pixels. We transfer the learned language field to 3DGS, achieving the first real-time rendering speed without sacrificing training time or accuracy. Lastly, we introduce a 3D querying and evaluation protocol for assessing the reconstructed geometry and semantics together. Code, checkpoints, and annotations are available at the project page. </p>
<blockquote>
<p>ç†è§£åœºæ™¯çš„3Dè¯­ä¹‰æ˜¯å„ç§åœºæ™¯ï¼ˆå¦‚å®ä½“ä»£ç†ï¼‰ä¸­çš„åŸºæœ¬é—®é¢˜ã€‚è™½ç„¶NeRFå’Œ3DGSåœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä¹‹å‰çš„æ–¹æ³•åœ¨ç†è§£å…¶è¯­ä¹‰æ–¹é¢ä»…é™äºä¸å®Œæ•´çš„3Dç†è§£ï¼šä»–ä»¬çš„åˆ†å‰²ç»“æœå‘ˆç°ä¸ºäºŒç»´æ©è†œï¼Œå¹¶ä¸èƒ½ä»£è¡¨æ•´ä¸ªä¸‰ç»´ç©ºé—´ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é‡æ–°å®šä¹‰äº†ä¸‰ç»´ä½“ç§¯åˆ†å‰²çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä»¥ä¸‹æ–¹æ³•æ¥æ›´å¥½åœ°è¿›è¡Œä¸‰ç»´ç†è§£ã€‚æˆ‘ä»¬ç›´æ¥ç›‘ç£ä¸‰ç»´ç‚¹æ¥è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œä¸åŒäºä»¥å‰çš„æ–¹æ³•åœ¨äºŒç»´åƒç´ ä¸Šè¿›è¡Œé”šç‚¹ç›‘ç£ã€‚æˆ‘ä»¬å°†å­¦åˆ°çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSä¸Šï¼Œåœ¨ä¸ç‰ºç‰²è®­ç»ƒæ—¶é—´æˆ–ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†å®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç”¨äºè¯„ä¼°é‡å»ºå‡ ä½•å’Œè¯­ä¹‰çš„ä¸‰ç»´æŸ¥è¯¢å’Œè¯„ä¼°åè®®ã€‚ä»£ç ã€æ£€æŸ¥ç‚¹å’Œæ³¨é‡Šå¯åœ¨é¡¹ç›®é¡µé¢æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.07416v3">PDF</a> AAAI 2025. Project page: <a target="_blank" rel="noopener" href="https://hyunji12.github.io/Open3DRF">https://hyunji12.github.io/Open3DRF</a></p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡è§£å†³äº†ä¸‰ç»´åœºæ™¯è¯­ä¹‰ç†è§£çš„é—®é¢˜ï¼Œé’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨ä¸‰ç»´ç†è§£ä¸Šçš„å±€é™æ€§ï¼Œé‡æ–°å®šä¹‰äº†ä¸‰ç»´ä½“ç§¯åˆ†å‰²çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†æ›´å¥½çš„ä¸‰ç»´ç†è§£æ–¹æ³•ã€‚é€šè¿‡ç›´æ¥ç›‘ç£ä¸‰ç»´ç‚¹æ¥è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œå°†å­¦ä¹ åˆ°çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSï¼Œå®ç°äº†å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ŒåŒæ—¶ä¸ç‰ºç‰²è®­ç»ƒæ—¶é—´æˆ–å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªä¸‰ç»´æŸ¥è¯¢å’Œè¯„ä¼°åè®®ï¼Œä»¥å…±åŒè¯„ä¼°é‡å»ºçš„å‡ ä½•å’Œè¯­ä¹‰ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æå‡ºäº†é’ˆå¯¹ä¸‰ç»´åœºæ™¯è¯­ä¹‰ç†è§£çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†ä»¥å¾€æ–¹æ³•ä»…å±€é™äºäºŒç»´ç†è§£çš„å±€é™æ€§ã€‚</li>
<li>é€šè¿‡ç›´æ¥ç›‘ç£ä¸‰ç»´ç‚¹è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œä¸åŒäºä»¥å¾€åœ¨äºŒç»´åƒç´ ä¸Šé”šå®šç›‘ç£çš„æ–¹æ³•ã€‚</li>
<li>å°†è®­ç»ƒå¥½çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSï¼Œå®ç°å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ŒåŒæ—¶ä¿è¯è®­ç»ƒæ—¶é—´å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å¼•å…¥äº†æ–°çš„ä¸‰ç»´æŸ¥è¯¢å’Œè¯„ä¼°åè®®ï¼Œç”¨äºè¯„ä¼°é‡å»ºçš„å‡ ä½•å’Œè¯­ä¹‰è´¨é‡ã€‚</li>
<li>ä»£ç ã€æ£€æŸ¥ç‚¹å’Œæ³¨é‡Šå¯åœ¨é¡¹ç›®é¡µé¢è·å–ã€‚</li>
<li>æå‡ºçš„æ–¹æ³•é€‚ç”¨äºå¤šç§åœºæ™¯ï¼Œå¦‚æœºå™¨äººç­‰è‡ªä¸»ä»£ç†çš„ä¸‰ç»´åœºæ™¯ç†è§£ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.07416">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2dbf41d65c6e570b7ab4ead5100b5d27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-287376b313db1f97072224b9ff303a7e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-44700f9ebd6a851a8603398704fcb598.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8f582db3946e1be72f6db3f087faa55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d40cb9e5628aa99de9fb9123a25149d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2cc0fa281a1f9adba38e8c2dd43b9b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ec01678df8f5cf63890b9f1d6ab87de.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-26/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-26/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-26/NeRF/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.14931v1/page_4_0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Semantic Neural Radiance Fields for Multi-Date Satellite Data
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-26/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a4b58cc8de72b3d79241204b05c21b74.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Na'vi or Knave Jailbreaking Language Models via Metaphorical Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28879.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
