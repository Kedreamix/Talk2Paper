<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Semantic Neural Radiance Fields for Multi-Date Satellite Data">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.14931v1/page_4_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-26-æ›´æ–°"><a href="#2025-02-26-æ›´æ–°" class="headerlink" title="2025-02-26 æ›´æ–°"></a>2025-02-26 æ›´æ–°</h1><h2 id="Semantic-Neural-Radiance-Fields-for-Multi-Date-Satellite-Data"><a href="#Semantic-Neural-Radiance-Fields-for-Multi-Date-Satellite-Data" class="headerlink" title="Semantic Neural Radiance Fields for Multi-Date Satellite Data"></a>Semantic Neural Radiance Fields for Multi-Date Satellite Data</h2><p><strong>Authors:Valentin Wagner, Sebastian Bullinger, Christoph Bodensteiner, Michael Arens</strong></p>
<p>In this work we propose a satellite specific Neural Radiance Fields (NeRF) model capable to obtain a three-dimensional semantic representation (neural semantic field) of the scene. The model derives the output from a set of multi-date satellite images with corresponding pixel-wise semantic labels. We demonstrate the robustness of our approach and its capability to improve noisy input labels. We enhance the color prediction by utilizing the semantic information to address temporal image inconsistencies caused by non-stationary categories such as vehicles. To facilitate further research in this domain, we present a dataset comprising manually generated labels for popular multi-view satellite images. Our code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/wagnva/semantic-nerf-for-satellite-data">https://github.com/wagnva/semantic-nerf-for-satellite-data</a>. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹å«æ˜Ÿæ•°æ®çš„ç‰¹å®šNeural Radiance Fieldsï¼ˆNeRFï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè·å¾—åœºæ™¯çš„ä¸‰ç»´è¯­ä¹‰è¡¨ç¤ºï¼ˆç¥ç»è¯­ä¹‰åœºï¼‰ã€‚è¯¥æ¨¡å‹ä»ä¸€ç³»åˆ—å¤šæ—¶ç›¸å«æ˜Ÿå›¾åƒåŠå…¶å¯¹åº”çš„åƒç´ çº§è¯­ä¹‰æ ‡ç­¾ä¸­å¾—å‡ºç»“æœã€‚æˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•çš„ç¨³å¥æ€§åŠå…¶æ”¹è¿›è¾“å…¥æ ‡ç­¾ä¸­å™ªå£°çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯æ¥æé«˜é¢œè‰²é¢„æµ‹ï¼Œè§£å†³ç”±éé™æ­¢ç±»åˆ«ï¼ˆå¦‚è½¦è¾†ï¼‰å¼•èµ·çš„å›¾åƒæ—¶é—´ä¸ä¸€è‡´é—®é¢˜ã€‚ä¸ºäº†ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç»„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«é’ˆå¯¹æµè¡Œå¤šè§†è§’å«æ˜Ÿå›¾åƒçš„æ‰‹åŠ¨ç”Ÿæˆæ ‡ç­¾ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/wagnva/semantic-nerf-for-satellite-data%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/wagnva/semantic-nerf-for-satellite-dataæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16992v1">PDF</a> Accepted at the CV4EO Workshop at WACV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å«æ˜Ÿæ•°æ®çš„ç‰¹å®šNeural Radiance Fieldsï¼ˆNeRFï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»å¤šæœŸå«æ˜Ÿå›¾åƒä¸­è·å¾—åœºæ™¯çš„ä¸‰ç»´è¯­ä¹‰è¡¨ç¤ºï¼ˆç¥ç»è¯­ä¹‰åœºï¼‰ã€‚æ¨¡å‹åˆ©ç”¨å¸¦æœ‰ç›¸åº”åƒç´ çº§è¯­ä¹‰æ ‡ç­¾çš„å›¾åƒé›†ç”Ÿæˆè¾“å‡ºï¼Œå±•ç¤ºå‡ºå…¶ç¨³å¥æ€§ï¼Œå¹¶èƒ½åœ¨å™ªå£°è¾“å…¥æ ‡ç­¾ä¸­æ”¹è¿›è¡¨ç°ã€‚é€šè¿‡åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯ï¼Œæ¨¡å‹æé«˜äº†é¢œè‰²é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œè§£å†³äº†ç”±éé™æ€ç±»åˆ«ï¼ˆå¦‚è½¦è¾†ï¼‰å¼•èµ·çš„ä¸´æ—¶å›¾åƒä¸ä¸€è‡´é—®é¢˜ã€‚ä¸ºæ¨è¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç»„é’ˆå¯¹æµè¡Œå¤šè§†è§’å«æ˜Ÿå›¾åƒçš„æ‰‹åŠ¨ç”Ÿæˆæ ‡ç­¾æ•°æ®é›†ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/wagnva/semantic-nerf-for-satellite-data">é“¾æ¥</a>ä¸­æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å«æ˜Ÿç‰¹å®šNeRFæ¨¡å‹èƒ½å¤Ÿè·å–åœºæ™¯çš„ä¸‰ç»´è¯­ä¹‰è¡¨ç¤ºã€‚</li>
<li>æ¨¡å‹ä½¿ç”¨å¤šæœŸå«æ˜Ÿå›¾åƒå’Œç›¸åº”çš„åƒç´ çº§è¯­ä¹‰æ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•å±•ç°å‡ºç¨³å¥æ€§ï¼Œå¹¶èƒ½æ”¹è¿›å™ªå£°è¾“å…¥æ ‡ç­¾çš„è¡¨ç°ã€‚</li>
<li>åˆ©ç”¨è¯­ä¹‰ä¿¡æ¯æé«˜äº†é¢œè‰²é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>æ¨¡å‹è§£å†³äº†ç”±éé™æ€ç±»åˆ«å¼•èµ·çš„ä¸´æ—¶å›¾åƒä¸ä¸€è‡´é—®é¢˜ã€‚</li>
<li>ä¸ºç ”ç©¶æä¾›äº†åŒ…å«æ‰‹åŠ¨ç”Ÿæˆæ ‡ç­¾çš„æµè¡Œå¤šè§†è§’å«æ˜Ÿå›¾åƒæ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16992">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-26206272cd34e53b4a1ead5d5b1bba1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b601bc3ce740d33111562768fe19f96.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48e103cd324526fe22368c451daf64ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa53e652c8d4ae1242d8d3580a6f213b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ViSNeRF-Efficient-Multidimensional-Neural-Radiance-Field-Representation-for-Visualization-Synthesis-of-Dynamic-Volumetric-Scenes"><a href="#ViSNeRF-Efficient-Multidimensional-Neural-Radiance-Field-Representation-for-Visualization-Synthesis-of-Dynamic-Volumetric-Scenes" class="headerlink" title="ViSNeRF: Efficient Multidimensional Neural Radiance Field Representation   for Visualization Synthesis of Dynamic Volumetric Scenes"></a>ViSNeRF: Efficient Multidimensional Neural Radiance Field Representation   for Visualization Synthesis of Dynamic Volumetric Scenes</h2><p><strong>Authors:Siyuan Yao, Yunfei Lu, Chaoli Wang</strong></p>
<p>Domain scientists often face I&#x2F;O and storage challenges when keeping raw data from large-scale simulations. Saving visualization images, albeit practical, is limited to preselected viewpoints, transfer functions, and simulation parameters. Recent advances in scientific visualization leverage deep learning techniques for visualization synthesis by offering effective ways to infer unseen visualizations when only image samples are given during training. However, due to the lack of 3D geometry awareness, existing methods typically require many training images and significant learning time to generate novel visualizations faithfully. To address these limitations, we propose ViSNeRF, a novel 3D-aware approach for visualization synthesis using neural radiance fields. Leveraging a multidimensional radiance field representation, ViSNeRF efficiently reconstructs visualizations of dynamic volumetric scenes from a sparse set of labeled image samples with flexible parameter exploration over transfer functions, isovalues, timesteps, or simulation parameters. Through qualitative and quantitative comparative evaluation, we demonstrate ViSNeRFâ€™s superior performance over several representative baseline methods, positioning it as the state-of-the-art solution. The code is available at <a target="_blank" rel="noopener" href="https://github.com/JCBreath/ViSNeRF">https://github.com/JCBreath/ViSNeRF</a>. </p>
<blockquote>
<p>é¢†åŸŸç§‘å­¦å®¶åœ¨ä¿å­˜å¤§è§„æ¨¡æ¨¡æ‹Ÿçš„åŸå§‹æ•°æ®æ—¶ï¼Œç»å¸¸é¢ä¸´I&#x2F;Oå’Œå­˜å‚¨æŒ‘æˆ˜ã€‚è™½ç„¶ä¿å­˜å¯è§†åŒ–å›¾åƒæ˜¯å®ç”¨çš„ï¼Œä½†å®ƒä»…é™äºé¢„é€‰çš„è§†è§’ã€ä¼ è¾“åŠŸèƒ½å’Œæ¨¡æ‹Ÿå‚æ•°ã€‚æœ€è¿‘çš„ç§‘å­¦å¯è§†åŒ–è¿›å±•åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯è¿›è¡Œå¯è§†åŒ–åˆæˆï¼Œæä¾›äº†ä¸€ç§åœ¨ä»…ç»™è®­ç»ƒè¿‡ç¨‹æä¾›å›¾åƒæ ·æœ¬çš„æƒ…å†µä¸‹æ¨æ–­æœªè§å¯è§†åŒ–çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹3Då‡ ä½•æ„ŸçŸ¥èƒ½åŠ›ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒå›¾åƒå’Œæ˜¾è‘—çš„å­¦ä¹ æ—¶é—´æ¥ç”Ÿæˆæ–°çš„å¯è§†åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ViSNeRFï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç¥ç»è¾å°„åœºè¿›è¡Œå¯è§†åŒ–åˆæˆçš„æ–°é¢–3Dæ„ŸçŸ¥æ–¹æ³•ã€‚å€ŸåŠ©å¤šç»´è¾å°„åœºè¡¨ç¤ºï¼ŒViSNeRFå¯ä»¥ä»ç¨€ç–çš„æ ‡è®°å›¾åƒæ ·æœ¬é›†ä¸­æœ‰æ•ˆåœ°é‡å»ºåŠ¨æ€ä½“ç§¯åœºæ™¯çš„å¯è§†åŒ–ï¼Œå¹¶åœ¨ä¼ è¾“åŠŸèƒ½ã€ç­‰å€¼ã€æ—¶é—´æ­¥é•¿æˆ–æ¨¡æ‹Ÿå‚æ•°æ–¹é¢æä¾›çµæ´»çš„å‚æ•°æ¢ç´¢ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡æ¯”è¾ƒè¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†ViSNeRFç›¸è¾ƒäºå‡ ç§ä»£è¡¨æ€§çš„åŸºçº¿æ–¹æ³•å…·æœ‰å“è¶Šæ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºæœ€å…ˆè¿›è§£å†³æ–¹æ¡ˆã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JCBreath/ViSNeRF%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/JCBreath/ViSNeRFæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16731v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰åœ¨å¯è§†åŒ–åˆæˆé¢†åŸŸçš„åº”ç”¨ï¼Œè§£å†³äº†å¤§è§„æ¨¡ä»¿çœŸä¸­é¢ä¸´çš„I&#x2F;Oå’Œå­˜å‚¨æŒ‘æˆ˜ã€‚ViSNeRFä½œä¸ºä¸€ç§æ–°å‹çš„ä¸‰ç»´å¯è§†åŒ–åˆæˆæ–¹æ³•ï¼Œåˆ©ç”¨ç¥ç»ç½‘ç»œè¾å°„åœºï¼Œèƒ½å¤Ÿä»å°‘é‡çš„æ ‡è®°å›¾åƒæ ·æœ¬ä¸­é«˜æ•ˆåœ°é‡å»ºåŠ¨æ€ä½“ç§¯åœºæ™¯çš„å¯è§†åŒ–ã€‚å®ƒå…·å¤‡çµæ´»çš„å‚æ•°æ¢ç´¢èƒ½åŠ›ï¼Œå¯è°ƒæ•´ä¼ è¾“å‡½æ•°ã€ç­‰å€¼çº¿ã€æ—¶é—´æ­¥é•¿æˆ–ä»¿çœŸå‚æ•°ã€‚å®éªŒè¯æ˜ï¼ŒViSNeRFç›¸è¾ƒäºå…¶ä»–ä»£è¡¨æ€§æ–¹æ³•ï¼Œå…·æœ‰å“è¶Šçš„æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ViSNeRFåˆ©ç”¨ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰è§£å†³å¤§è§„æ¨¡ä»¿çœŸä¸­çš„I&#x2F;Oå’Œå­˜å‚¨æŒ‘æˆ˜ã€‚</li>
<li>ViSNeRFèƒ½å¤Ÿä»å°‘é‡çš„æ ‡è®°å›¾åƒæ ·æœ¬ä¸­é‡å»ºåŠ¨æ€ä½“ç§¯åœºæ™¯çš„å¯è§†åŒ–ã€‚</li>
<li>ViSNeRFå…·å¤‡çµæ´»çš„å‚æ•°æ¢ç´¢èƒ½åŠ›ï¼Œå¯è°ƒæ•´ä¼ è¾“å‡½æ•°ã€ç­‰å€¼çº¿ã€æ—¶é—´æ­¥é•¿ç­‰ã€‚</li>
<li>ViSNeRFå…·å¤‡å‡ºè‰²çš„æ€§èƒ½è¡¨ç°ï¼Œç›¸è¾ƒäºå…¶ä»–ä»£è¡¨æ€§æ–¹æ³•å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>ViSNeRFæ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å¯è§†åŒ–åˆæˆï¼Œå…·å¤‡æ½œåœ¨çš„å¤§è§„æ¨¡åº”ç”¨å‰æ™¯ã€‚</li>
<li>ä»£ç å·²å…¬å¼€ï¼Œæ–¹ä¾¿ç ”ç©¶è€…å’Œå¼€å‘è€…ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16731">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-111bee6155c5a1725f96e71e400851c0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fcb3c995f630cf3956cb8ab37dea58cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44e7d577be69d025802693984ba5394d.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16731v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16731v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16731v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="AquaNeRF-Neural-Radiance-Fields-in-Underwater-Media-with-Distractor-Removal"><a href="#AquaNeRF-Neural-Radiance-Fields-in-Underwater-Media-with-Distractor-Removal" class="headerlink" title="AquaNeRF: Neural Radiance Fields in Underwater Media with Distractor   Removal"></a>AquaNeRF: Neural Radiance Fields in Underwater Media with Distractor   Removal</h2><p><strong>Authors:Luca Gough, Adrian Azzarelli, Fan Zhang, Nantheera Anantrasirichai</strong></p>
<p>Neural radiance field (NeRF) research has made significant progress in modeling static video content captured in the wild. However, current models and rendering processes rarely consider scenes captured underwater, which are useful for studying and filming ocean life. They fail to address visual artifacts unique to underwater scenes, such as moving fish and suspended particles. This paper introduces a novel NeRF renderer and optimization scheme for an implicit MLP-based NeRF model. Our renderer reduces the influence of floaters and moving objects that interfere with static objects of interest by estimating a single surface per ray. We use a Gaussian weight function with a small offset to ensure that the transmittance of the surrounding media remains constant. Additionally, we enhance our model with a depth-based scaling function to upscale gradients for near-camera volumes. Overall, our method outperforms the baseline Nerfacto by approximately 7.5% and SeaThru-NeRF by 6.2% in terms of PSNR. Subjective evaluation also shows a significant reduction of artifacts while preserving details of static targets and background compared to the state of the arts. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç ”ç©¶åœ¨å»ºæ¨¡é‡å¤–æ•æ‰çš„é™æ€è§†é¢‘å†…å®¹ä¸Šå–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼Œå½“å‰æ¨¡å‹å’Œæ¸²æŸ“è¿‡ç¨‹å¾ˆå°‘è€ƒè™‘æ°´ä¸‹åœºæ™¯çš„æ•æ‰ï¼Œè¿™å¯¹äºç ”ç©¶å’Œæ‹æ‘„æµ·æ´‹ç”Ÿç‰©éå¸¸æœ‰ç”¨ã€‚å®ƒä»¬æ— æ³•è§£å†³æ°´ä¸‹åœºæ™¯ç‰¹æœ‰çš„è§†è§‰ä¼ªå½±ï¼Œå¦‚ç§»åŠ¨çš„é±¼ç±»å’Œæ‚¬æµ®é¢—ç²’ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„NeRFæ¸²æŸ“å™¨å’Œé’ˆå¯¹åŸºäºéšå¼å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰çš„NeRFæ¨¡å‹çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„æ¸²æŸ“å™¨é€šè¿‡ä¼°ç®—æ¯æ¡å°„çº¿çš„å•ä¸ªè¡¨é¢ï¼Œå‡å°‘äº†æ¼‚æµ®ç‰©å’Œç§»åŠ¨ç‰©ä½“å¯¹æ„Ÿå…´è¶£é™æ€ç‰©ä½“çš„å¹²æ‰°ã€‚æˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰å°åç§»çš„é«˜æ–¯æƒé‡å‡½æ•°ï¼Œä»¥ç¡®ä¿å‘¨å›´ä»‹è´¨çš„é€å°„ç‡ä¿æŒä¸å˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åŸºäºæ·±åº¦çš„ç¼©æ”¾å‡½æ•°å¢å¼ºæˆ‘ä»¬çš„æ¨¡å‹ï¼Œä»¥æ”¾å¤§è¿‘ç›¸æœºä½“ç§¯çš„æ¢¯åº¦ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢æ¯”åŸºçº¿Nerfactoé«˜å‡ºçº¦7.5%ï¼Œæ¯”SeaThru-NeRFé«˜å‡º6.2%ã€‚ä¸»è§‚è¯„ä»·è¿˜è¡¨æ˜ï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡å°‘ä¼ªå½±çš„åŒæ—¶ï¼Œä¿ç•™äº†é™æ€ç›®æ ‡å’ŒèƒŒæ™¯çš„ç»†èŠ‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16351v1">PDF</a> Accepted by 2025 IEEE International Symposium on Circuits and Systems</p>
<p><strong>æ‘˜è¦</strong></p>
<p>NeRFæŠ€æœ¯åœ¨æ°´ä¸‹åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“æ–¹é¢å–å¾—äº†çªç ´ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„NeRFæ¸²æŸ“å™¨å’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œè§£å†³äº†æ°´ä¸‹åœºæ™¯ç‰¹æœ‰çš„è§†è§‰ä¼ªå½±é—®é¢˜ï¼Œå¦‚ç§»åŠ¨ç”Ÿç‰©å’Œæ‚¬æµ®é¢—ç²’çš„å½±å“ã€‚é€šè¿‡ä¼°ç®—æ¯æ¡å°„çº¿çš„å•ä¸€è¡¨é¢ï¼Œå‡å°‘äº†æµ®ç”Ÿç‰©å’Œç§»åŠ¨ç‰©ä½“å¯¹é™æ€ç›®æ ‡ç‰©ä½“çš„å¹²æ‰°ã€‚ä½¿ç”¨é«˜æ–¯æƒé‡å‡½æ•°å’Œå°åç§»ç¡®ä¿äº†å‘¨å›´ä»‹è´¨çš„é€å°„ç‡ä¿æŒä¸å˜ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ·±åº¦åŸºç¡€ç¼©æ”¾åŠŸèƒ½å¢å¼ºæ¨¡å‹ï¼Œä»¥æ”¾å¤§è¿‘ç›¸æœºä½“ç§¯çš„æ¢¯åº¦ã€‚ç›¸è¾ƒäºåŸºå‡†çš„Nerfactoå’ŒSeaThru-NeRFï¼Œè¯¥æ–¹æ³•åœ¨PSNRä¸Šåˆ†åˆ«æé«˜äº†çº¦7.5%å’Œ6.2%ã€‚ä¸»è§‚è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘ä¼ªå½±çš„åŒæ—¶ï¼Œè¿˜èƒ½ä¿ç•™é™æ€ç›®æ ‡å’ŒèƒŒæ™¯çš„ç»†èŠ‚ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>NeRFæŠ€æœ¯åœ¨æ°´ä¸‹åœºæ™¯çš„å»ºæ¨¡å’Œæ¸²æŸ“æ–¹é¢å…·æœ‰æ˜¾è‘—è¿›å±•ã€‚</li>
<li>æ–°å‹NeRFæ¸²æŸ“å™¨å’Œä¼˜åŒ–æ–¹æ¡ˆè§£å†³äº†æ°´ä¸‹åœºæ™¯ç‰¹æœ‰çš„è§†è§‰ä¼ªå½±é—®é¢˜ã€‚</li>
<li>é€šè¿‡ä¼°ç®—å•ä¸€è¡¨é¢å‡å°‘ç§»åŠ¨ç”Ÿç‰©å’Œæ‚¬æµ®é¢—ç²’å¯¹é™æ€ç‰©ä½“çš„å¹²æ‰°ã€‚</li>
<li>åˆ©ç”¨é«˜æ–¯æƒé‡å‡½æ•°ç¡®ä¿å‘¨å›´åª’ä½“é€å°„ç‡æ’å®šã€‚</li>
<li>ä½¿ç”¨æ·±åº¦åŸºç¡€ç¼©æ”¾åŠŸèƒ½å¢å¼ºæ¨¡å‹æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿‘ç›¸æœºåŒºåŸŸã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨PSNRä¸Šæ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16351">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16351v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16351v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16351v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16351v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DualNeRF-Text-Driven-3D-Scene-Editing-via-Dual-Field-Representation"><a href="#DualNeRF-Text-Driven-3D-Scene-Editing-via-Dual-Field-Representation" class="headerlink" title="DualNeRF: Text-Driven 3D Scene Editing via Dual-Field Representation"></a>DualNeRF: Text-Driven 3D Scene Editing via Dual-Field Representation</h2><p><strong>Authors:Yuxuan Xiong, Yue Shi, Yishun Dou, Bingbing Ni</strong></p>
<p>Recently, denoising diffusion models have achieved promising results in 2D image generation and editing. Instruct-NeRF2NeRF (IN2N) introduces the success of diffusion into 3D scene editing through an â€œIterative dataset updateâ€ (IDU) strategy. Though achieving fascinating results, IN2N suffers from problems of blurry backgrounds and trapping in local optima. The first problem is caused by IN2Nâ€™s lack of efficient guidance for background maintenance, while the second stems from the interaction between image editing and NeRF training during IDU. In this work, we introduce DualNeRF to deal with these problems. We propose a dual-field representation to preserve features of the original scene and utilize them as additional guidance to the model for background maintenance during IDU. Moreover, a simulated annealing strategy is embedded into IDU to endow our model with the power of addressing local optima issues. A CLIP-based consistency indicator is used to further improve the editing quality by filtering out low-quality edits. Extensive experiments demonstrate that our method outperforms previous methods both qualitatively and quantitatively. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå»å™ªæ‰©æ•£æ¨¡å‹åœ¨2Då›¾åƒç”Ÿæˆå’Œç¼–è¾‘æ–¹é¢å–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœã€‚Instruct-NeRF2NeRFï¼ˆIN2Nï¼‰é€šè¿‡â€œè¿­ä»£æ•°æ®é›†æ›´æ–°â€ï¼ˆIDUï¼‰ç­–ç•¥ï¼Œå°†æ‰©æ•£çš„æˆåŠŸå¼•å…¥3Dåœºæ™¯ç¼–è¾‘ã€‚å°½ç®¡å–å¾—äº†ä»¤äººç€è¿·çš„ç»“æœï¼Œä½†IN2Nä»å­˜åœ¨èƒŒæ™¯æ¨¡ç³Šå’Œé™·å…¥å±€éƒ¨æœ€ä¼˜çš„é—®é¢˜ã€‚ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ç”±IN2Nå¯¹èƒŒæ™¯ç»´æŠ¤ç¼ºä¹æœ‰æ•ˆæŒ‡å¯¼æ‰€é€ æˆçš„ï¼Œè€Œç¬¬äºŒä¸ªé—®é¢˜åˆ™æºäºå›¾åƒç¼–è¾‘å’ŒNeRFè®­ç»ƒåœ¨IDUè¿‡ç¨‹ä¸­çš„ç›¸äº’ä½œç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥DualNeRFæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒåœºè¡¨ç¤ºæ³•æ¥ä¿ç•™åŸå§‹åœºæ™¯çš„ç‰¹å¾ï¼Œå¹¶å°†å…¶ä½œä¸ºé™„åŠ æŒ‡å¯¼ï¼Œç”¨äºåœ¨IDUæœŸé—´è¿›è¡ŒèƒŒæ™¯ç»´æŠ¤ã€‚æ­¤å¤–ï¼Œå°†æ¨¡æ‹Ÿé€€ç«ç­–ç•¥åµŒå…¥åˆ°IDUä¸­ï¼Œä½¿æˆ‘ä»¬çš„æ¨¡å‹å…·æœ‰è§£å†³å±€éƒ¨æœ€ä¼˜é—®é¢˜çš„èƒ½åŠ›ã€‚ä½¿ç”¨åŸºäºCLIPçš„ä¸€è‡´æ€§æŒ‡æ ‡ï¼Œè¿›ä¸€æ­¥æé«˜äº†ç¼–è¾‘è´¨é‡ï¼Œé€šè¿‡è¿‡æ»¤æ‰ä½è´¨é‡çš„ç¼–è¾‘ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šå‡ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.16302v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Instruct-NeRF2NeRFï¼ˆIN2Nï¼‰åœ¨ä¸‰ç»´åœºæ™¯ç¼–è¾‘ä¸­åº”ç”¨æ‰©æ•£æ¨¡å‹çš„å°è¯•åŠå…¶æ‰€é¢ä¸´çš„èƒŒæ™¯æ¨¡ç³Šå’Œé™·å…¥å±€éƒ¨æœ€ä¼˜çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†DualNeRFæ–¹æ³•ï¼Œé‡‡ç”¨åŒåœºè¡¨ç¤ºæ³•ä¿ç•™åŸå§‹åœºæ™¯ç‰¹å¾ï¼Œä½œä¸ºæ¨¡å‹åœ¨è¿­ä»£æ•°æ®é›†æ›´æ–°ï¼ˆIDUï¼‰è¿‡ç¨‹ä¸­çš„èƒŒæ™¯ç»´æŠ¤çš„é¢å¤–æŒ‡å¯¼ã€‚åŒæ—¶ï¼Œå°†æ¨¡æ‹Ÿé€€ç«ç­–ç•¥èå…¥IDUï¼Œä»¥è§£å†³å±€éƒ¨æœ€ä¼˜é—®é¢˜ã€‚ä½¿ç”¨CLIPåŸºäºä¸€è‡´æ€§æŒ‡æ ‡è¿›ä¸€æ­¥æé«˜ç¼–è¾‘è´¨é‡ï¼Œé€šè¿‡è¿‡æ»¤ä½è´¨é‡ç¼–è¾‘æ¥æ”¹å–„æ•ˆæœã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è´¨é‡å’Œæ•°é‡ä¸Šå‡ä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Instruct-NeRF2NeRF (IN2N) å¼•å…¥æ‰©æ•£æ¨¡å‹è‡³ 3D åœºæ™¯ç¼–è¾‘ï¼Œé€šè¿‡ â€œè¿­ä»£æ•°æ®é›†æ›´æ–°â€ (IDU) ç­–ç•¥å–å¾—æˆæœã€‚</li>
<li>IN2N å­˜åœ¨èƒŒæ™¯æ¨¡ç³Šå’Œé™·å…¥å±€éƒ¨æœ€ä¼˜çš„é—®é¢˜ã€‚</li>
<li>DualNeRF å¼•å…¥åŒåœºè¡¨ç¤ºæ³•ï¼Œæ—¨åœ¨ä¿ç•™åŸå§‹åœºæ™¯ç‰¹å¾ï¼Œä½œä¸ºæ¨¡å‹åœ¨ IDU è¿‡ç¨‹ä¸­çš„èƒŒæ™¯ç»´æŠ¤æŒ‡å¯¼ã€‚</li>
<li>DualNeRF é‡‡ç”¨æ¨¡æ‹Ÿé€€ç«ç­–ç•¥èå…¥ IDUï¼Œè§£å†³å±€éƒ¨æœ€ä¼˜é—®é¢˜ã€‚</li>
<li>ä½¿ç”¨ CLIP åŸºäºä¸€è‡´æ€§æŒ‡æ ‡æé«˜ç¼–è¾‘è´¨é‡ï¼Œé€šè¿‡è¿‡æ»¤ä½è´¨é‡ç¼–è¾‘æ”¹å–„æ•ˆæœã€‚</li>
<li>å®éªŒè¯æ˜ DualNeRF åœ¨è´¨é‡å’Œæ•°é‡ä¸Šå‡ä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.16302">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16302v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16302v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16302v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.16302v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Para-Lane-Multi-Lane-Dataset-Registering-Parallel-Scans-for-Benchmarking-Novel-View-Synthesis"><a href="#Para-Lane-Multi-Lane-Dataset-Registering-Parallel-Scans-for-Benchmarking-Novel-View-Synthesis" class="headerlink" title="Para-Lane: Multi-Lane Dataset Registering Parallel Scans for   Benchmarking Novel View Synthesis"></a>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for   Benchmarking Novel View Synthesis</h2><p><strong>Authors:Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang</strong></p>
<p>To evaluate end-to-end autonomous driving systems, a simulation environment based on Novel View Synthesis (NVS) techniques is essential, which synthesizes photo-realistic images and point clouds from previously recorded sequences under new vehicle poses, particularly in cross-lane scenarios. Therefore, the development of a multi-lane dataset and benchmark is necessary. While recent synthetic scene-based NVS datasets have been prepared for cross-lane benchmarking, they still lack the realism of captured images and point clouds. To further assess the performance of existing methods based on NeRF and 3DGS, we present the first multi-lane dataset registering parallel scans specifically for novel driving view synthesis dataset derived from real-world scans, comprising 25 groups of associated sequences, including 16,000 front-view images, 64,000 surround-view images, and 16,000 LiDAR frames. All frames are labeled to differentiate moving objects from static elements. Using this dataset, we evaluate the performance of existing approaches in various testing scenarios at different lanes and distances. Additionally, our method provides the solution for solving and assessing the quality of multi-sensor poses for multi-modal data alignment for curating such a dataset in real-world. We plan to continually add new sequences to test the generalization of existing methods across different scenarios. The dataset is released publicly at the project page: <a target="_blank" rel="noopener" href="https://nizqleo.github.io/paralane-dataset/">https://nizqleo.github.io/paralane-dataset/</a>. </p>
<blockquote>
<p>ä¸ºäº†è¯„ä¼°ç«¯åˆ°ç«¯çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿï¼ŒåŸºäºæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰æŠ€æœ¯çš„æ¨¡æ‹Ÿç¯å¢ƒè‡³å…³é‡è¦ã€‚è¯¥ç¯å¢ƒèƒ½å¤Ÿåœ¨æ–°è½¦è¾†å§¿æ€ä¸‹ï¼Œä»å…ˆå‰è®°å½•çš„åºåˆ—ä¸­åˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ï¼Œç‰¹åˆ«æ˜¯åœ¨è·¨è½¦é“åœºæ™¯ä¸­ã€‚å› æ­¤ï¼Œå¼€å‘å¤šè½¦é“æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•æ˜¯å¿…è¦çš„ã€‚è™½ç„¶æœ€è¿‘å·²ç»ä¸ºè·¨è½¦é“åŸºå‡†æµ‹è¯•å‡†å¤‡äº†åŸºäºåˆæˆåœºæ™¯ çš„NVSæ•°æ®é›†ï¼Œä½†å®ƒä»¬ä»ç„¶ç¼ºä¹æ•è·çš„å›¾åƒå’Œç‚¹äº‘çš„é€¼çœŸæ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–åŸºäºNeRFå’Œ3DGSçš„ç°æœ‰æ–¹æ³•çš„æ€§èƒ½è¯„ä¼°ï¼Œæˆ‘ä»¬é¦–æ¬¡æ¨å‡ºäº†å¤šè½¦é“æ•°æ®é›†æ³¨å†Œå¹¶è¡Œæ‰«æï¼Œä¸“é—¨é’ˆå¯¹ä»çœŸå®ä¸–ç•Œæ‰«æä¸­æ´¾ç”Ÿçš„æ–°å‹é©¾é©¶è§†å›¾åˆæˆæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«25ç»„ç›¸å…³åºåˆ—ï¼ŒåŒ…æ‹¬16,000å¼ å‰è§†å›¾å›¾åƒã€64,000å¼ ç¯ç»•è§†å›¾å›¾åƒå’Œ16,000å¼ æ¿€å…‰é›·è¾¾å¸§ã€‚æ‰€æœ‰å¸§éƒ½è¿›è¡Œäº†æ ‡è®°ï¼Œä»¥åŒºåˆ†ç§»åŠ¨ç‰©ä½“å’Œé™æ€å…ƒç´ ã€‚ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬åœ¨ä¸åŒè½¦é“å’Œè·ç¦»çš„å„ç§æµ‹è¯•åœºæ™¯ä¸­è¯„ä¼°äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜æä¾›äº†è§£å†³å’Œè¯„ä¼°å¤šä¼ æ„Ÿå™¨å§¿æ€è´¨é‡çš„è§£å†³æ–¹æ¡ˆï¼Œç”¨äºæ­¤ç±»æ•°æ®é›†çš„å¤šæ¨¡æ€æ•°æ®å¯¹é½åœ¨çœŸå®ä¸–ç•Œä¸­çš„å®ç°ã€‚æˆ‘ä»¬è®¡åˆ’ä¸æ–­æ·»åŠ æ–°çš„åºåˆ—ï¼Œä»¥æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹ç°æœ‰æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†å·²åœ¨é¡¹ç›®é¡µé¢å…¬å¼€å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://nizqleo.github.io/paralane-dataset/">https://nizqleo.github.io/paralane-dataset/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15635v2">PDF</a> Accepted by International Conference on 3D Vision (3DV) 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºNovel View Synthesisï¼ˆNVSï¼‰æŠ€æœ¯çš„æ¨¡æ‹Ÿç¯å¢ƒå¯¹äºè¯„ä¼°ç«¯åˆ°ç«¯çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œå®ƒèƒ½åˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ï¼Œä»æ–°è½¦è¾†å§¿æ€ä¸‹è®°å½•çš„åºåˆ—ä¸­ç”Ÿæˆã€‚ä¸ºæ­¤ï¼Œå¼€å‘ä¸€ä¸ªå¤šè½¦é“æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•æ˜¯å¿…è¦çš„ã€‚è™½ç„¶å·²æœ‰åŸºäºåˆæˆåœºæ™¯çš„NVSæ•°æ®é›†ç”¨äºè½¦é“é—´åŸºå‡†æµ‹è¯•ï¼Œä½†å®ƒä»¬ä»ç¼ºä¹æ•è·å›¾åƒçš„é€¼çœŸæ€§ã€‚ä¸ºäº†è¯„ä¼°åŸºäºNeRFå’Œ3DGSçš„æ–¹æ³•çš„æ€§èƒ½ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºäº†ä¸€ä¸ªæ³¨å†Œå¹³è¡Œæ‰«æçš„å¤šè½¦é“æ•°æ®é›†ï¼Œä¸“ä¸ºæ–°å‹é©¾é©¶è§†å›¾åˆæˆæ•°æ®é›†è€Œè®¾è®¡ï¼ŒæºäºçœŸå®ä¸–ç•Œæ‰«æã€‚æ•°æ®é›†åŒ…å«25ç»„ç›¸å…³åºåˆ—ï¼ŒåŒ…æ‹¬1.6ä¸‡å¼ å‰è§†å›¾å›¾åƒã€6.4ä¸‡å¼ ç¯ç»•è§†å›¾å›¾åƒå’Œ1.6ä¸‡å¼ æ¿€å…‰é›·è¾¾å¸§ã€‚æ‰€æœ‰å¸§éƒ½è¿›è¡Œäº†æ ‡è®°ï¼Œä»¥åŒºåˆ†ç§»åŠ¨ç‰©ä½“å’Œé™æ€å…ƒç´ ã€‚ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸åŒè½¦é“å’Œè·ç¦»çš„å„ç§æµ‹è¯•åœºæ™¯ä¸­ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜æä¾›è§£å†³æ–¹æ¡ˆï¼Œä»¥è§£å†³å’Œè¯„ä¼°å¤šä¼ æ„Ÿå™¨å§¿æ€çš„è´¨é‡ï¼Œç”¨äºå¤šæ¨¡æ€æ•°æ®å¯¹é½ï¼Œä»¥åˆ›å»ºæ­¤ç±»çœŸå®ä¸–ç•Œæ•°æ®é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NVSæŠ€æœ¯å¯¹äºè¯„ä¼°è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„ç«¯åˆ°ç«¯æ€§èƒ½è‡³å…³é‡è¦ï¼Œå¯ä»¥åˆæˆé€¼çœŸçš„å›¾åƒå’Œç‚¹äº‘ã€‚</li>
<li>å¤šè½¦é“æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•å¯¹äºè¯„ä¼°è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„è·¨è½¦é“æ€§èƒ½æ˜¯å¿…è¦çš„ã€‚</li>
<li>å½“å‰åˆæˆåœºæ™¯æ•°æ®é›†ç¼ºä¹çœŸå®æ„Ÿï¼Œéš¾ä»¥å‡†ç¡®è¯„ä¼°è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>æå‡ºé¦–ä¸ªåŸºäºçœŸå®ä¸–ç•Œæ‰«æçš„å¤šè½¦é“æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§è§†å›¾å›¾åƒå’Œæ¿€å…‰é›·è¾¾å¸§ã€‚</li>
<li>æ•°æ®é›†ç”¨äºè¯„ä¼°ä¸åŒè½¦é“å’Œè·ç¦»ä¸‹ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›è§£å†³æ–¹æ¡ˆæ¥è§£å†³å¤šä¼ æ„Ÿå™¨å§¿æ€çš„è´¨é‡é—®é¢˜ï¼Œå®ç°å¤šæ¨¡æ€æ•°æ®å¯¹é½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.15635v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.15635v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.15635v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.15635v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.15635v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Hier-SLAM-Neuro-Symbolic-Semantic-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting"><a href="#Hier-SLAM-Neuro-Symbolic-Semantic-SLAM-with-a-Hierarchically-Categorical-Gaussian-Splatting" class="headerlink" title="Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically   Categorical Gaussian Splatting"></a>Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically   Categorical Gaussian Splatting</h2><p><strong>Authors:Boying Li, Vuong Chi Hao, Peter J. Stuckey, Ian Reid, Hamid Rezatofighi</strong></p>
<p>We propose Hier-SLAM++, a comprehensive Neuro-Symbolic semantic 3D Gaussian Splatting SLAM method with both RGB-D and monocular input featuring an advanced hierarchical categorical representation, which enables accurate pose estimation as well as global 3D semantic mapping. The parameter usage in semantic SLAM systems increases significantly with the growing complexity of the environment, making scene understanding particularly challenging and costly. To address this problem, we introduce a novel and general hierarchical representation that encodes both semantic and geometric information in a compact form into 3D Gaussian Splatting, leveraging the capabilities of large language models (LLMs) as well as the 3D generative model. By utilizing the proposed hierarchical tree structure, semantic information is symbolically represented and learned in an end-to-end manner. We further introduce a novel semantic loss designed to optimize hierarchical semantic information through both inter-level and cross-level optimization. Additionally, we propose an improved SLAM system to support both RGB-D and monocular inputs using a feed-forward model. To the best of our knowledge, this is the first semantic monocular Gaussian Splatting SLAM system, significantly reducing sensor requirements for 3D semantic understanding and broadening the applicability of semantic Gaussian SLAM system. We conduct experiments on both synthetic and real-world datasets, demonstrating superior or on-par performance with state-of-the-art NeRF-based and Gaussian-based SLAM systems, while significantly reducing storage and training time requirements. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†Hier-SLAM++ï¼Œè¿™æ˜¯ä¸€ç§å…¨é¢çš„ç¥ç»ç¬¦å·è¯­ä¹‰3Dé«˜æ–¯æ‹¼æ¥SLAMæ–¹æ³•ï¼Œå®ƒæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå¹¶å…·å¤‡å…ˆè¿›çš„å±‚æ¬¡åŒ–ç±»åˆ«è¡¨ç¤ºèƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°å‡†ç¡®çš„å§¿æ€ä¼°è®¡å’Œå…¨å±€3Dè¯­ä¹‰æ˜ å°„ã€‚éšç€ç¯å¢ƒå¤æ‚æ€§çš„å¢åŠ ï¼Œè¯­ä¹‰SLAMç³»ç»Ÿä¸­çš„å‚æ•°ä½¿ç”¨é‡ä¹Ÿæ˜¾è‘—å¢åŠ ï¼Œè¿™ä½¿å¾—åœºæ™¯ç†è§£å˜å¾—ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§å’Œæˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„å±‚æ¬¡åŒ–è¡¨ç¤ºæ–¹æ³•ï¼Œä»¥ç´§å‡‘çš„å½¢å¼å°†è¯­ä¹‰å’Œå‡ ä½•ä¿¡æ¯ç¼–ç åˆ°3Dé«˜æ–¯æ‹¼æ¥ä¸­ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œ3Dç”Ÿæˆæ¨¡å‹çš„å¼ºå¤§åŠŸèƒ½ã€‚é€šè¿‡åˆ©ç”¨æ‰€æå‡ºçš„å±‚æ¬¡æ ‘ç»“æ„ï¼Œè¯­ä¹‰ä¿¡æ¯ä»¥ç¬¦å·å½¢å¼è¡¨ç¤ºå¹¶ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ç§æ–°å‹è¯­ä¹‰æŸå¤±ï¼Œæ—¨åœ¨é€šè¿‡è·¨çº§åˆ«ä¼˜åŒ–æ¥ä¼˜åŒ–å±‚æ¬¡åŒ–è¯­ä¹‰ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ”¹è¿›çš„SLAMç³»ç»Ÿï¼Œæ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå¹¶ä½¿ç”¨å‰é¦ˆæ¨¡å‹ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè¯­ä¹‰å•ç›®é«˜æ–¯æ‹¼æ¥SLAMç³»ç»Ÿï¼Œå¤§å¤§é™ä½äº†å¯¹3Dè¯­ä¹‰ç†è§£çš„ä¼ æ„Ÿå™¨è¦æ±‚ï¼Œå¹¶æ‹“å®½äº†è¯­ä¹‰é«˜æ–¯SLAMç³»ç»Ÿçš„åº”ç”¨èŒƒå›´ã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œè¯æ˜äº†ä¸æœ€æ–°çš„åŸºäºNeRFå’Œé«˜æ–¯çš„SLAMç³»ç»Ÿç›¸æ¯”å…·æœ‰å“è¶Šæˆ–ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†å­˜å‚¨å’Œè®­ç»ƒæ—¶é—´è¦æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14931v1">PDF</a> 15 pages. Under review</p>
<p><strong>Summary</strong><br>åŸºäºå±‚æ¬¡ç»“æ„çš„é«˜çº§è¯­ä¹‰æ˜ å°„æŠ€æœ¯æ”¹è¿›ç ”ç©¶ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å…ˆè¿›çš„ç»¼åˆç¥ç»ç¬¦å·è¯­ä¹‰çš„SLAMæ–¹æ³•â€”â€”Hier-SLAM++ã€‚æ­¤æ–¹æ³•ç»“åˆRGB-Då’Œå•ç›®è¾“å…¥ï¼Œå…·æœ‰é«˜çº§å±‚æ¬¡ç±»åˆ«è¡¨ç¤ºåŠŸèƒ½ï¼Œèƒ½è¿›è¡Œå‡†ç¡®çš„å§¿æ€ä¼°è®¡å’Œå…¨å±€ä¸‰ç»´è¯­ä¹‰åœ°å›¾æ„å»ºã€‚æ­¤æ–¹æ³•åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹çš„ç´§å‡‘ä¸‰ç»´é«˜æ–¯æ‹¼å›¾ç»“æ„è¿›è¡Œé«˜çº§è¯­ä¹‰è¡¨ç¤ºå­¦ä¹ ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¼˜åŠ¿ä¸3Dç”Ÿæˆæ¨¡å‹å®ç°å¼ºå¤§çš„è¯­è¨€ç”Ÿæˆå’Œæ¨¡å‹åº”ç”¨æ½œåŠ›ã€‚å¼•å…¥ä¸€ç§æ–°å‹çš„è¯­ä¹‰æŸå¤±ï¼Œä¼˜åŒ–å±‚æ¬¡è¯­ä¹‰ä¿¡æ¯ã€‚æ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥çš„æ–°å‹SLAMç³»ç»Ÿé¦–æ¬¡å®ç°äº†å¯¹å•ç›®é«˜æ–¯æ‹¼å›¾çš„è¯­ä¹‰ç†è§£ï¼Œæ˜¾è‘—é™ä½äº†å¯¹ä¸‰ç»´è¯­ä¹‰ç†è§£çš„ä¼ æ„Ÿå™¨è¦æ±‚ï¼Œå¹¶æ‰©å¤§äº†é«˜æ–¯SLAMç³»ç»Ÿçš„åº”ç”¨èŒƒå›´ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ç°æœ‰é¢†å…ˆçš„åŸºäºNeRFçš„SLAMç³»ç»Ÿåœ¨æ€§èƒ½å’Œå‚æ•°è¦æ±‚æ–¹é¢æœ‰æ‰€çªç ´ã€‚é€šè¿‡ç²¾ç¡®æ§åˆ¶å’Œå¹¿æ³›è¯„ä¼°å„ç§æ–¹æ³•å’ŒæŠ€æœ¯çš„æ ¸å¿ƒå…ƒç´ ä»¥åŠå¯¹è¯¥é¢†åŸŸæœ€å‰æ²¿çš„æ·±åº¦åˆ†æï¼Œè¿›ä¸€æ­¥æ¨è¿›äº†è¯¥é¢†åŸŸçš„è®¤çŸ¥ç•Œé™ã€‚æ€»ç»“æ¥è¯´ï¼Œè¯¥ç ”ç©¶å®ç°äº†è¯­ä¹‰ç†è§£çš„é«˜æ•ˆå’Œå‡†ç¡®æ€§æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Hier-SLAM++æ˜¯ä¸€ä¸ªç»“åˆäº†RGB-Då’Œå•ç›®è¾“å…¥çš„ç»¼åˆç¥ç»ç¬¦å·è¯­ä¹‰çš„ä¸‰ç»´é«˜æ–¯Splatting SLAMæ–¹æ³•ï¼Œå¯å®ç°ç²¾ç¡®å§¿æ€ä¼°è®¡å’Œå…¨å±€ä¸‰ç»´è¯­ä¹‰æ˜ å°„ã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸‰ç»´ç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œå®ç°å±‚æ¬¡ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯çš„ç´§å‡‘è¡¨ç¤ºå­¦ä¹ ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹çš„è¯­ä¹‰æŸå¤±æœºåˆ¶ï¼Œä¼˜åŒ–äº†å±‚æ¬¡ç»“æ„ä¸­çš„è¯­ä¹‰ä¿¡æ¯ä¼˜åŒ–ã€‚è¿™ä¸€åˆ›æ–°ç­–ç•¥ä¸ºæ”¹è¿›é«˜çº§ç‰¹å¾æ˜ å°„æä¾›äº†ä¸€ç§æœ‰æ•ˆæ–¹æ³•ã€‚ </li>
<li>è¯¥æ–¹æ³•æ”¯æŒRGB-Då’Œå•ç›®è¾“å…¥çš„æ–°å‹SLAMç³»ç»Ÿé¦–æ¬¡å®ç°äº†å•ç›®é«˜æ–¯æ‹¼å›¾çš„è¯­ä¹‰ç†è§£ï¼Œæ˜¾è‘—é™ä½äº†ä¼ æ„Ÿå™¨éœ€æ±‚ã€‚ </li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºæˆ–ç›¸å½“äºæ˜¯ç°æœ‰é¢†å…ˆçš„åŸºäºNeRFçš„SLAMç³»ç»Ÿï¼ŒåŒæ—¶åœ¨å­˜å‚¨å’Œè®­ç»ƒæ—¶é—´æ–¹é¢æœ‰æ‰€å‡å°‘ã€‚è¿™æ ‡å¿—ç€åœ¨ä¸‰ç»´è¯­ä¹‰ç†è§£é¢†åŸŸçš„é‡å¤§è¿›æ­¥ã€‚ </li>
<li>é€šè¿‡å±‚æ¬¡ç»“æ„çš„åˆ©ç”¨å’Œç´§å‡‘è¡¨ç¤ºå­¦ä¹ ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨åœºæ™¯ç†è§£å’Œåœ°å›¾æ„å»ºæ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.14931v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.14931v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.14931v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="HumanGif-Single-View-Human-Diffusion-with-Generative-Prior"><a href="#HumanGif-Single-View-Human-Diffusion-with-Generative-Prior" class="headerlink" title="HumanGif: Single-View Human Diffusion with Generative Prior"></a>HumanGif: Single-View Human Diffusion with Generative Prior</h2><p><strong>Authors:Shoukang Hu, Takuya Narihira, Kazumi Fukuda, Ryosuke Sawata, Takashi Shibuya, Yuki Mitsufuji</strong></p>
<p>Previous 3D human creation methods have made significant progress in synthesizing view-consistent and temporally aligned results from sparse-view images or monocular videos. However, it remains challenging to produce perpetually realistic, view-consistent, and temporally coherent human avatars from a single image, as limited information is available in the single-view input setting. Motivated by the success of 2D character animation, we propose HumanGif, a single-view human diffusion model with generative prior. Specifically, we formulate the single-view-based 3D human novel view and pose synthesis as a single-view-conditioned human diffusion process, utilizing generative priors from foundational diffusion models to complement the missing information. To ensure fine-grained and consistent novel view and pose synthesis, we introduce a Human NeRF module in HumanGif to learn spatially aligned features from the input image, implicitly capturing the relative camera and human pose transformation. Furthermore, we introduce an image-level loss during optimization to bridge the gap between latent and image spaces in diffusion models. Extensive experiments on RenderPeople and DNA-Rendering datasets demonstrate that HumanGif achieves the best perceptual performance, with better generalizability for novel view and pose synthesis. </p>
<blockquote>
<p>ä¹‹å‰çš„3Däººç‰©åˆ›å»ºæ–¹æ³•åœ¨ä»ç¨€ç–è§†å›¾å›¾åƒæˆ–å•ç›®è§†é¢‘ä¸­åˆæˆè§†è§’ä¸€è‡´å’Œæ—¶é—´ä¸Šå¯¹é½çš„ç»“æœæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œä»å•å¼ å›¾åƒä¸­ç”Ÿæˆæ°¸ä¹…é€¼çœŸçš„ã€è§†è§’ä¸€è‡´å’Œæ—¶é—´ä¸Šè¿è´¯çš„äººç‰©åŒ–èº«ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºåœ¨å•è§†å›¾è¾“å…¥è®¾ç½®ä¸­å¯ç”¨ä¿¡æ¯æœ‰é™ã€‚å—åˆ°äºŒç»´è§’è‰²åŠ¨ç”»æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†HumanGifï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¦æœ‰ç”Ÿæˆå…ˆéªŒçš„å•è§†å›¾äººç±»æ‰©æ•£æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†åŸºäºå•è§†å›¾çš„3Däººç‰©æ–°é¢–è§†å›¾å’Œå§¿æ€åˆæˆåˆ¶å®šä¸ºå—å•è§†å›¾æ¡ä»¶çº¦æŸçš„äººç±»æ‰©æ•£è¿‡ç¨‹ï¼Œåˆ©ç”¨åŸºç¡€æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå…ˆéªŒæ¥è¡¥å……ç¼ºå¤±ä¿¡æ¯ã€‚ä¸ºäº†ç¡®ä¿ç²¾ç»†ä¸”ä¸€è‡´çš„å…¨æ–°è§†å›¾å’Œå§¿æ€åˆæˆï¼Œæˆ‘ä»¬åœ¨HumanGifä¸­å¼•å…¥äº†Human NeRFæ¨¡å—ï¼Œä»è¾“å…¥å›¾åƒä¸­å­¦ä¹ ç©ºé—´å¯¹é½çš„ç‰¹å¾ï¼Œéšå¼æ•è·ç›¸å¯¹ç›¸æœºå’Œäººç‰©å§¿æ€å˜æ¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥äº†å›¾åƒçº§æŸå¤±ï¼Œä»¥å¼¥åˆæ‰©æ•£æ¨¡å‹ä¸­æ½œåœ¨ç©ºé—´å’Œå›¾åƒç©ºé—´ä¹‹é—´çš„å·®è·ã€‚åœ¨RenderPeopleå’ŒDNA-Renderingæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHumanGifåœ¨æ„ŸçŸ¥æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œå¯¹äºæ–°é¢–è§†å›¾å’Œå§¿æ€åˆæˆå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12080v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://skhu101.github.io/HumanGif/">https://skhu101.github.io/HumanGif/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå•è§†è§’çš„æ‰©æ•£æ¨¡å‹HumanGifï¼Œç”¨äºåˆ›å»ºäººç±»è§’è‰²åŠ¨ç”»ã€‚è¯¥æ¨¡å‹åˆ©ç”¨ç”Ÿæˆå…ˆéªŒä¿¡æ¯æ¥è¡¥å……å•è§†è§’è¾“å…¥ä¸­çš„ç¼ºå¤±ä¿¡æ¯ï¼Œå®ç°äº†ä»å•å¼ å›¾åƒç”Ÿæˆé«˜è´¨é‡ã€é€¼çœŸã€è§†è§’ä¸€è‡´ä¸”æ—¶é—´è¿è´¯çš„äººç±»è§’è‰²åŠ¨ç”»ã€‚é€šè¿‡å¼•å…¥Human NeRFæ¨¡å—ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ è¾“å…¥å›¾åƒä¸­çš„ç©ºé—´å¯¹é½ç‰¹å¾ï¼Œå¹¶éšå¼æ•è·ç›¸å¯¹ç›¸æœºå’Œäººç±»å§¿æ€çš„å˜æ¢ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„å›¾åƒçº§æŸå¤±ï¼Œç¼©å°äº†æ½œåœ¨ç©ºé—´å’Œå›¾åƒç©ºé—´ä¹‹é—´çš„å·®è·ã€‚åœ¨RenderPeopleå’ŒDNA-Renderingæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒHumanGifåœ¨æ„ŸçŸ¥æ€§èƒ½ä¸Šå–å¾—äº†æœ€ä½³è¡¨ç°ï¼Œå¹¶åœ¨æ–°è§†è§’å’Œå§¿æ€åˆæˆæ–¹é¢è¡¨ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HumanGifæ˜¯ä¸€ç§åŸºäºå•è§†è§’çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåˆ›å»ºäººç±»è§’è‰²åŠ¨ç”»ã€‚</li>
<li>è¯¥æ¨¡å‹åˆ©ç”¨ç”Ÿæˆå…ˆéªŒä¿¡æ¯è¡¥å……å•è§†è§’è¾“å…¥ä¸­çš„ç¼ºå¤±ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡å¼•å…¥Human NeRFæ¨¡å—ï¼Œå®ç°äº†é«˜è´¨é‡ã€é€¼çœŸã€è§†è§’ä¸€è‡´ä¸”æ—¶é—´è¿è´¯çš„äººç±»è§’è‰²åŠ¨ç”»åˆæˆã€‚</li>
<li>è¯¥æ¨¡å‹éšå¼æ•è·ç›¸å¯¹ç›¸æœºå’Œäººç±»å§¿æ€çš„å˜æ¢ï¼Œä¿è¯åˆæˆçš„æ–°è§†è§’å’Œå§¿æ€æ›´ä¸ºç²¾ç»†å’Œä¸€è‡´ã€‚</li>
<li>ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„å›¾åƒçº§æŸå¤±æœ‰åŠ©äºç¼©å°æ½œåœ¨ç©ºé—´å’Œå›¾åƒç©ºé—´ä¹‹é—´çš„å·®è·ã€‚</li>
<li>åœ¨RenderPeopleå’ŒDNA-Renderingæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜HumanGifçš„ä¼˜å¼‚è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.12080v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.12080v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2502.12080v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Bringing-NeRFs-to-the-Latent-Space-Inverse-Graphics-Autoencoder"><a href="#Bringing-NeRFs-to-the-Latent-Space-Inverse-Graphics-Autoencoder" class="headerlink" title="Bringing NeRFs to the Latent Space: Inverse Graphics Autoencoder"></a>Bringing NeRFs to the Latent Space: Inverse Graphics Autoencoder</h2><p><strong>Authors:Antoine Schnepf, Karim Kassab, Jean-Yves Franceschi, Laurent Caraffa, Flavian Vasile, Jeremie Mary, Andrew Comport, Valerie Gouet-Brunet</strong></p>
<p>While pre-trained image autoencoders are increasingly utilized in computer vision, the application of inverse graphics in 2D latent spaces has been under-explored. Yet, besides reducing the training and rendering complexity, applying inverse graphics in the latent space enables a valuable interoperability with other latent-based 2D methods. The major challenge is that inverse graphics cannot be directly applied to such image latent spaces because they lack an underlying 3D geometry. In this paper, we propose an Inverse Graphics Autoencoder (IG-AE) that specifically addresses this issue. To this end, we regularize an image autoencoder with 3D-geometry by aligning its latent space with jointly trained latent 3D scenes. We utilize the trained IG-AE to bring NeRFs to the latent space with a latent NeRF training pipeline, which we implement in an open-source extension of the Nerfstudio framework, thereby unlocking latent scene learning for its supported methods. We experimentally confirm that Latent NeRFs trained with IG-AE present an improved quality compared to a standard autoencoder, all while exhibiting training and rendering accelerations with respect to NeRFs trained in the image space. Our project page can be found at <a target="_blank" rel="noopener" href="https://ig-ae.github.io/">https://ig-ae.github.io</a> . </p>
<blockquote>
<p>è™½ç„¶é¢„è®­ç»ƒçš„å›¾åƒè‡ªç¼–ç å™¨åœ¨è®¡ç®—æœºè§†è§‰ä¸­å¾—åˆ°äº†è¶Šæ¥è¶Šå¤šçš„åº”ç”¨ï¼Œä½†åœ¨äºŒç»´æ½œåœ¨ç©ºé—´ä¸­åº”ç”¨åå‘å›¾å½¢æŠ€æœ¯å´å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç„¶è€Œï¼Œé™¤äº†åœ¨è®­ç»ƒå’Œæ¸²æŸ“æ–¹é¢é™ä½å¤æ‚æ€§ä¹‹å¤–ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­åº”ç”¨åå‘å›¾å½¢æŠ€æœ¯è¿˜å®ç°äº†ä¸å…¶ä»–åŸºäºæ½œåœ¨ç©ºé—´çš„äºŒç»´æ–¹æ³•çš„å®è´µäº’æ“ä½œæ€§ã€‚ä¸»è¦æŒ‘æˆ˜æ˜¯åå‘å›¾å½¢æ— æ³•ç›´æ¥åº”ç”¨äºè¿™ç§å›¾åƒæ½œåœ¨ç©ºé—´ï¼Œå› ä¸ºå®ƒä»¬ç¼ºä¹åŸºæœ¬çš„ä¸‰ç»´å‡ ä½•ç»“æ„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸“é—¨è§£å†³æ­¤é—®é¢˜çš„åå‘å›¾å½¢è‡ªç¼–ç å™¨ï¼ˆIG-AEï¼‰ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿å›¾åƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸è”åˆè®­ç»ƒçš„æ½œåœ¨ä¸‰ç»´åœºæ™¯å¯¹é½æ¥å¯¹å…¶è¿›è¡Œäº†ä¸‰ç»´å‡ ä½•æ­£åˆ™åŒ–ã€‚æˆ‘ä»¬åˆ©ç”¨è®­ç»ƒå¥½çš„IG-AEå°†NeRFå¸¦å…¥æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬åœ¨Nerfstudioæ¡†æ¶çš„å¼€æºæ‰©å±•ä¸­å®ç°çš„æ½œåœ¨NeRFè®­ç»ƒç®¡é“æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»è€Œä¸ºæ‰€æ”¯æŒçš„æ–¹æ³•è§£é”äº†æ½œåœ¨åœºæ™¯å­¦ä¹ ã€‚é€šè¿‡å®éªŒï¼Œæˆ‘ä»¬è¯å®äº†ä¸æ ‡å‡†è‡ªç¼–ç å™¨ç›¸æ¯”ï¼Œä½¿ç”¨IG-AEè®­ç»ƒçš„æ½œåœ¨NeRFå‘ˆç°å‡ºæ›´é«˜çš„è´¨é‡ï¼ŒåŒæ—¶åœ¨å›¾åƒç©ºé—´è®­ç»ƒçš„NeRFæ–¹é¢è¡¨ç°å‡ºè®­ç»ƒå’Œæ¸²æŸ“çš„åŠ é€Ÿã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ä½äº<a target="_blank" rel="noopener" href="https://ig-ae.github.io./">https://ig-ae.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.22936v2">PDF</a> Accepted at ICLR 2025. Available at   <a target="_blank" rel="noopener" href="https://openreview.net/forum?id=LTDtjrv02Y">https://openreview.net/forum?id=LTDtjrv02Y</a></p>
<p><strong>Summary</strong></p>
<p>é¢„è®­ç»ƒå›¾åƒè‡ªç¼–ç å™¨åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸåº”ç”¨å¹¿æ³›ï¼Œä½†å…¶åœ¨äºŒç»´æ½œåœ¨ç©ºé—´å†…å¯¹é€†å‘å›¾å½¢å­¦çš„åº”ç”¨å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡å°†é€†å‘å›¾å½¢å­¦ä¸å›¾åƒæ½œåœ¨ç©ºé—´ç›¸ç»“åˆï¼Œä»¥å‡å°‘è®­ç»ƒå’Œæ¸²æŸ“å¤æ‚åº¦ï¼Œå¹¶ä¸å…¶ä»–æ½œåœ¨ç©ºé—´çš„äºŒç»´æ–¹æ³•å®ç°è‰¯å¥½çš„äº’æ“ä½œæ€§ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºé€†å‘å›¾å½¢å­¦æ— æ³•ç›´æ¥åº”ç”¨äºç¼ºä¹ä¸‰ç»´å‡ ä½•çš„å›¾åƒæ½œåœ¨ç©ºé—´ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€†å‘å›¾å½¢è‡ªç¼–ç å™¨ï¼ˆIG-AEï¼‰ï¼Œé€šè¿‡ç”¨ä¸‰ç»´å‡ ä½•å¯¹å›¾åƒè‡ªç¼–ç å™¨è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä½¿å…¶æ½œåœ¨ç©ºé—´ä¸è”åˆè®­ç»ƒçš„æ½œåœ¨ä¸‰ç»´åœºæ™¯å¯¹é½ã€‚åˆ©ç”¨è®­ç»ƒçš„IG-AEå°†NeRFå¼•å…¥æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†ä¸€ç§æ½œåœ¨NeRFè®­ç»ƒç®¡é“ï¼Œæˆ‘ä»¬åœ¨Nerfstudioæ¡†æ¶çš„å¼€æºæ‰©å±•ä¸­å®ç°äº†è¿™ä¸€æ–¹æ³•ï¼Œä»è€Œè§£é”äº†å…¶æ”¯æŒæ–¹æ³•çš„æ½œåœ¨åœºæ™¯å­¦ä¹ ã€‚å®éªŒè¯å®ï¼Œä¸æ ‡å‡†è‡ªç¼–ç å™¨ç›¸æ¯”ï¼Œä½¿ç”¨IG-AEè®­ç»ƒçš„æ½œåœ¨NeRFå‘ˆç°å‡ºæ›´é«˜çš„è´¨é‡ï¼ŒåŒæ—¶åœ¨å›¾åƒç©ºé—´è®­ç»ƒçš„NeRFå…·æœ‰è®­ç»ƒå’Œæ¸²æŸ“åŠ é€Ÿçš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒå›¾åƒè‡ªç¼–ç å™¨å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œé€†å‘å›¾å½¢å­¦åœ¨äºŒç»´æ½œåœ¨ç©ºé—´çš„åº”ç”¨å°šæœªå……åˆ†æ¢ç´¢ã€‚</li>
<li>é€†å‘å›¾å½¢å­¦ä¸èƒ½ç›´æ¥åº”ç”¨äºç¼ºä¹ä¸‰ç»´å‡ ä½•çš„å›¾åƒæ½œåœ¨ç©ºé—´æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„é€†å‘å›¾å½¢è‡ªç¼–ç å™¨ï¼ˆIG-AEï¼‰è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡æ­£åˆ™åŒ–å›¾åƒè‡ªç¼–ç å™¨ä¸ä¸‰ç»´å‡ ä½•å¯¹é½ã€‚</li>
<li>IG-AEè¢«ç”¨äºå°†NeRFå¼•å…¥æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ½œåœ¨NeRFè®­ç»ƒç®¡é“ã€‚</li>
<li>ç›¸æ¯”æ ‡å‡†è‡ªç¼–ç å™¨ï¼Œä½¿ç”¨IG-AEè®­ç»ƒçš„æ½œåœ¨NeRFå…·æœ‰æ›´é«˜çš„è´¨é‡ã€‚</li>
<li>æ½œåœ¨NeRFå…·æœ‰è®­ç»ƒå’Œæ¸²æŸ“åŠ é€Ÿçš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.22936">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2410.22936v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2410.22936v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2410.22936v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2410.22936v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Rethinking-Open-Vocabulary-Segmentation-of-Radiance-Fields-in-3D-Space"><a href="#Rethinking-Open-Vocabulary-Segmentation-of-Radiance-Fields-in-3D-Space" class="headerlink" title="Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space"></a>Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space</h2><p><strong>Authors:Hyunjee Lee, Youngsik Yun, Jeongmin Bae, Seoha Kim, Youngjung Uh</strong></p>
<p>Understanding the 3D semantics of a scene is a fundamental problem for various scenarios such as embodied agents. While NeRFs and 3DGS excel at novel-view synthesis, previous methods for understanding their semantics have been limited to incomplete 3D understanding: their segmentation results are rendered as 2D masks that do not represent the entire 3D space. To address this limitation, we redefine the problem to segment the 3D volume and propose the following methods for better 3D understanding. We directly supervise the 3D points to train the language embedding field, unlike previous methods that anchor supervision at 2D pixels. We transfer the learned language field to 3DGS, achieving the first real-time rendering speed without sacrificing training time or accuracy. Lastly, we introduce a 3D querying and evaluation protocol for assessing the reconstructed geometry and semantics together. Code, checkpoints, and annotations are available at the project page. </p>
<blockquote>
<p>ç†è§£åœºæ™¯çš„3Dè¯­ä¹‰æ˜¯å„ç§åœºæ™¯ï¼ˆå¦‚å®ä½“ä»£ç†ï¼‰ä¸­çš„åŸºæœ¬é—®é¢˜ã€‚è™½ç„¶NeRFå’Œ3DGSåœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ä¹‹å‰å¯¹äºç†è§£å…¶è¯­ä¹‰çš„æ–¹æ³•ä»…é™äºä¸å®Œæ•´çš„3Dç†è§£ï¼šä»–ä»¬çš„åˆ†å‰²ç»“æœå‘ˆç°ä¸º2Dé®ç½©ï¼Œå¹¶ä¸èƒ½ä»£è¡¨æ•´ä¸ª3Dç©ºé—´ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é‡æ–°å®šä¹‰äº†åˆ†å‰²3Dä½“ç§¯çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä»¥ä¸‹æ–¹æ³•æ¥æ›´å¥½åœ°è¿›è¡Œ3Dç†è§£ã€‚æˆ‘ä»¬ç›´æ¥ç›‘ç£3Dç‚¹æ¥è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œä¸åŒäºä»¥å‰çš„æ–¹æ³•åªåœ¨2Dåƒç´ ä¸Šè¿›è¡Œç›‘ç£ã€‚æˆ‘ä»¬å°†å­¦åˆ°çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSï¼Œåœ¨ä¸ç‰ºç‰²è®­ç»ƒæ—¶é—´æˆ–å‡†ç¡®åº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†é¦–æ¬¡å®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ª3DæŸ¥è¯¢å’Œè¯„ä¼°åè®®ï¼Œä»¥å…±åŒè¯„ä¼°é‡å»ºçš„å‡ ä½•å’Œè¯­ä¹‰ã€‚ä»£ç ã€æ£€æŸ¥ç‚¹å’Œæ³¨é‡Šå¯åœ¨é¡¹ç›®é¡µé¢æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.07416v3">PDF</a> AAAI 2025. Project page: <a target="_blank" rel="noopener" href="https://hyunji12.github.io/Open3DRF">https://hyunji12.github.io/Open3DRF</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸ºäº†è§£å†³ç°æœ‰NeRFæ¨¡å‹åœ¨ç†è§£åœºæ™¯ä¸‰ç»´è¯­ä¹‰æ–¹é¢å­˜åœ¨çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç³»åˆ—æ”¹è¿›æ–¹æ³•ã€‚é¦–å…ˆï¼Œå¯¹é—®é¢˜è¿›è¡Œäº†é‡æ–°å®šä¹‰ï¼Œä»¥å®ç°å¯¹ä¸‰ç»´ä½“ç§¯çš„åˆ†å‰²ï¼Œè¿›è€Œæé«˜ä¸‰ç»´ç†è§£èƒ½åŠ›ã€‚é€šè¿‡ç›´æ¥ç›‘ç£ä¸‰ç»´ç‚¹æ¥è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œè€Œéåƒä¹‹å‰çš„æ–¹æ³•é‚£æ ·åœ¨äºŒç»´åƒç´ ä¸Šè¿›è¡Œé”šç‚¹ç›‘ç£ã€‚å°†å­¦ä¹ åˆ°çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSï¼Œå®ç°äº†åœ¨ä¸ç‰ºç‰²è®­ç»ƒæ—¶é—´å’Œå‡†ç¡®æ€§çš„æƒ…å†µä¸‹å®æ—¶æ¸²æŸ“é€Ÿåº¦çš„æå‡ã€‚æœ€åï¼Œå¼•å…¥äº†ä¸€ä¸ªä¸‰ç»´æŸ¥è¯¢å’Œè¯„ä¼°åè®®ï¼Œä»¥è¯„ä¼°é‡å»ºçš„å‡ ä½•ç»“æ„å’Œè¯­ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡æ–°å®šä¹‰äº†é—®é¢˜ä»¥å®ç°å¯¹ä¸‰ç»´ä½“ç§¯çš„åˆ†å‰²ï¼Œä»¥æé«˜å¯¹åœºæ™¯çš„ä¸‰ç»´ç†è§£èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡ç›´æ¥ç›‘ç£ä¸‰ç»´ç‚¹æ¥è®­ç»ƒè¯­è¨€åµŒå…¥åœºï¼Œè€Œä¸æ˜¯åœ¨äºŒç»´åƒç´ ä¸Šè¿›è¡Œé”šç‚¹ç›‘ç£ã€‚</li>
<li>å°†å­¦ä¹ åˆ°çš„è¯­è¨€åœºè½¬ç§»åˆ°3DGSï¼Œå®ç°äº†å®æ—¶æ¸²æŸ“é€Ÿåº¦çš„æå‡ï¼ŒåŒæ—¶ä¸ç‰ºç‰²è®­ç»ƒæ—¶é—´å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªä¸‰ç»´æŸ¥è¯¢å’Œè¯„ä¼°åè®®ï¼Œç”¨äºè¯„ä¼°é‡å»ºçš„å‡ ä½•ç»“æ„å’Œè¯­ä¹‰ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä»…èƒ½æä¾›ä¸å®Œæ•´çš„ä¸‰ç»´ç†è§£ï¼Œè€Œæœ¬æ–‡æ–¹æ³•å¯ä»¥æ›´å…¨é¢åœ°ç†è§£åœºæ™¯çš„ä¸‰ç»´è¯­ä¹‰ã€‚</li>
<li>æœ¬æ–‡æ–¹æ³•è§£å†³äº†ä»¥å¾€æ–¹æ³•åœ¨åœºæ™¯ä¸‰ç»´è¯­ä¹‰ç†è§£æ–¹é¢çš„å±€é™æ€§ï¼Œå¦‚æ–°å‹è§†å›¾åˆæˆç­‰åº”ç”¨åœºæ™¯ä¸­çš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.07416">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-26\./crop_NeRF/2408.07416v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-26/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-26/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-26/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-728e0cefbefe5b2e1745f9050740922c.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  GCC Generative Color Constancy via Diffusing a Color Checker
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-26/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-fd176e18b81a2c84abb8d2ea93fa1eed.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26522.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
