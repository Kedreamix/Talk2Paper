<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-12  GN-FRGeneralizable Neural Radiance Fields for Flare Removal">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-000e979692aa4c8d8f144717029a4813.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    55 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-12-æ›´æ–°"><a href="#2024-12-12-æ›´æ–°" class="headerlink" title="2024-12-12 æ›´æ–°"></a>2024-12-12 æ›´æ–°</h1><h2 id="GN-FR-Generalizable-Neural-Radiance-Fields-for-Flare-Removal"><a href="#GN-FR-Generalizable-Neural-Radiance-Fields-for-Flare-Removal" class="headerlink" title="GN-FR:Generalizable Neural Radiance Fields for Flare Removal"></a>GN-FR:Generalizable Neural Radiance Fields for Flare Removal</h2><p><strong>Authors:Gopi Raju Matta, Rahul Siddartha, Rongali Simhachala Venkata Girish, Sumit Sharma, Kaushik Mitra</strong></p>
<p>Flare, an optical phenomenon resulting from unwanted scattering and reflections within a lens system, presents a significant challenge in imaging. The diverse patterns of flares, such as halos, streaks, color bleeding, and haze, complicate the flare removal process. Existing traditional and learning-based methods have exhibited limited efficacy due to their reliance on single-image approaches, where flare removal is highly ill-posed. We address this by framing flare removal as a multi-view image problem, taking advantage of the view-dependent nature of flare artifacts. This approach leverages information from neighboring views to recover details obscured by flare in individual images. Our proposed framework, GN-FR (Generalizable Neural Radiance Fields for Flare Removal), can render flare-free views from a sparse set of input images affected by lens flare and generalizes across different scenes in an unsupervised manner. GN-FR incorporates several modules within the Generalizable NeRF Transformer (GNT) framework: Flare-occupancy Mask Generation (FMG), View Sampler (VS), and Point Sampler (PS). To overcome the impracticality of capturing both flare-corrupted and flare-free data, we introduce a masking loss function that utilizes mask information in an unsupervised setting. Additionally, we present a 3D multi-view flare dataset, comprising 17 real flare scenes with 782 images, 80 real flare patterns, and their corresponding annotated flare-occupancy masks. To our knowledge, this is the first work to address flare removal within a Neural Radiance Fields (NeRF) framework. </p>
<blockquote>
<p>ç‚«å…‰ä½œä¸ºä¸€ç§ç”±é•œå¤´ç³»ç»Ÿå†…çš„ä¸å¿…è¦æ•£å°„å’Œåå°„å¼•èµ·çš„å…‰å­¦ç°è±¡ï¼Œåœ¨æˆåƒä¸­æ„æˆé‡å¤§æŒ‘æˆ˜ã€‚ç‚«å…‰å›¾æ¡ˆå¤šç§å¤šæ ·ï¼Œä¾‹å¦‚å…‰æ™•ã€æ¡çº¹ã€è‰²å½©æº¢å‡ºå’Œæœ¦èƒ§ï¼Œè¿™äº›éƒ½ä½¿ç‚«å…‰å»é™¤è¿‡ç¨‹å¤æ‚åŒ–ã€‚ç”±äºä¾èµ–äºå•å›¾åƒæ–¹æ³•ï¼Œç°æœ‰çš„ä¼ ç»Ÿå’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨ç‚«å…‰å»é™¤æ–¹é¢çš„è¡¨ç°å¾€å¾€æœ‰é™ï¼Œè€Œç‚«å…‰å»é™¤æ˜¯ä¸€ä¸ªé«˜åº¦ä¸é€‚å®šçš„é—®é¢˜ã€‚æˆ‘ä»¬é€šè¿‡å°†ç‚«å…‰å»é™¤æ„é€ æˆå¤šè§†å›¾å›¾åƒé—®é¢˜æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œåˆ©ç”¨ç‚«å…‰ä¼ªå½±çš„è§†å›¾ç›¸å…³æ€§ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨ç›¸é‚»è§†å›¾çš„è¯¦ç»†ä¿¡æ¯æ¥æ¢å¤è¢«ç‚«å…‰é®æŒ¡çš„å•å¹…å›¾åƒä¸­çš„ç»†èŠ‚ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶GN-FRï¼ˆç”¨äºç‚«å…‰å»é™¤çš„å¯æ³›åŒ–ç¥ç»è¾å°„åœºï¼‰èƒ½å¤Ÿä»å—é•œå¤´ç‚«å…‰å½±å“çš„ç¨€ç–è¾“å…¥å›¾åƒé›†ä¸­å‘ˆç°æ— ç‚«å…‰çš„è§†å›¾ï¼Œå¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼åœ¨ä¸åŒçš„åœºæ™¯ä¸­æ³›åŒ–ã€‚GN-FRåœ¨å¯æ³›åŒ–NeRFè½¬æ¢å™¨ï¼ˆGNTï¼‰æ¡†æ¶å†…ç»“åˆäº†å¤šä¸ªæ¨¡å—ï¼šç‚«å…‰å ç”¨æ©æ¨¡ç”Ÿæˆå™¨ï¼ˆFMGï¼‰ã€è§†å›¾é‡‡æ ·å™¨ï¼ˆVSï¼‰å’Œç‚¹é‡‡æ ·å™¨ï¼ˆPSï¼‰ã€‚ä¸ºäº†å…‹æœåŒæ—¶è·å–å—ç‚«å…‰ç ´åå’Œæœªå—ç ´åçš„æ•°æ®çš„ä¸å®é™…æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ©æ¨¡æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨æ— ç›‘ç£ç¯å¢ƒä¸­åˆ©ç”¨æ©æ¨¡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ä¸€ä¸ª3Då¤šè§†å›¾ç‚«å…‰æ•°æ®é›†ï¼ŒåŒ…å«17ä¸ªçœŸå®ç‚«å…‰åœºæ™¯ã€åŒ…å«å…±782å¹…å›¾åƒçš„å›¾åƒä»¥åŠä¸å…¶ç›¸å¯¹åº”çš„å¸¦æ³¨é‡Šçš„ç‚«å…‰å ç”¨æ©æ¨¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¡†æ¶å†…è§£å†³ç‚«å…‰å»é™¤é—®é¢˜çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.08200v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å…‰å­¦ç°è±¡ä¸­çš„è€€æ–‘ï¼Œç”±äºé•œå¤´ç³»ç»Ÿä¸­çš„æ„å¤–æ•£å°„å’Œåå°„è€Œäº§ç”Ÿï¼Œå¯¹æˆåƒé€ æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚è€€æ–‘çš„å¤šæ ·è¡¨ç°å½¢æ€ï¼Œå¦‚å…‰æ™•ã€æ¡çº¹ã€è‰²å½©æº¢å‡ºå’Œé›¾éœ¾ç­‰ï¼Œä½¿å¾—è€€æ–‘å»é™¤è¿‡ç¨‹å˜å¾—å¤æ‚ã€‚ç°æœ‰çš„ä¼ ç»Ÿå’ŒåŸºäºå­¦ä¹ çš„æ–¹æ³•è¡¨ç°å‡ºæœ‰é™çš„æ•ˆç‡ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–äºå•å›¾åƒæ–¹æ³•ï¼Œè€Œè€€æ–‘å»é™¤åœ¨æ­¤æƒ…å†µä¸‹é«˜åº¦ä¸é€‚å®šã€‚æˆ‘ä»¬é€šè¿‡å°†è€€æ–‘å»é™¤ä½œä¸ºå¤šè§†å›¾å›¾åƒé—®é¢˜æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œåˆ©ç”¨è€€æ–‘ä¼ªå½±çš„è§†å›¾ç›¸å…³æ€§ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨é‚»è¿‘è§†å›¾çš„èµ„è®¯æ¥æ¢å¤è¢«è€€æ–‘é®æŒ¡çš„å•å¹…å›¾åƒä¸­çš„ç»†èŠ‚ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶GN-FRï¼ˆç”¨äºè€€æ–‘å»é™¤çš„å¯æ³›åŒ–ç¥ç»è¾å°„åœºï¼‰ï¼Œå¯ä»¥ä»ä¸€ç»„ç¨€ç–çš„å—é•œå¤´è€€æ–‘å½±å“çš„è¾“å…¥å›¾åƒä¸­æ¸²æŸ“æ— è€€æ–‘çš„è§†å›¾ï¼Œå¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼æ³›åŒ–åˆ°ä¸åŒçš„åœºæ™¯ã€‚GN-FRåœ¨Generalizable NeRF Transformerï¼ˆGNTï¼‰æ¡†æ¶å†…ç»“åˆäº†å¤šä¸ªæ¨¡å—ï¼šè€€æ–‘å ç”¨æ©æ¨¡ç”Ÿæˆï¼ˆFMGï¼‰ã€è§†å›¾é‡‡æ ·å™¨ï¼ˆVSï¼‰å’Œç‚¹é‡‡æ ·å™¨ï¼ˆPSï¼‰ã€‚ä¸ºäº†å…‹æœåŒæ—¶æ•è·å—è€€æ–‘æŸåå’Œæ— è€€æ–‘æ•°æ®çš„ä¸åˆ‡å®é™…æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ©æ¨¡æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°åœ¨æ— ç›‘ç£è®¾ç½®ä¸­ä½¿ç”¨æ©æ¨¡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ä¸€ä¸ªåŒ…å«17ä¸ªçœŸå®è€€æ–‘åœºæ™¯ã€åŒ…å«782å¼ å›¾åƒå’Œ80ä¸ªçœŸå®è€€æ–‘æ¨¡å¼åŠå…¶ç›¸åº”çš„æ ‡æ³¨è€€æ–‘å ç”¨æ©æ¨¡çš„3Då¤šè§†å›¾è€€æ–‘æ•°æ®é›†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡åœ¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¡†æ¶å†…è§£å†³è€€æ–‘å»é™¤é—®é¢˜çš„ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³é•œå¤´ä¸­çš„è€€æ–‘é—®é¢˜ï¼Œé€šè¿‡å°†å…¶è§†ä¸ºå¤šè§†å›¾å›¾åƒé—®é¢˜å¹¶åˆ©ç”¨è§†å›¾é—´çš„ç›¸å…³æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„æ¡†æ¶GN-FRï¼Œå¯ä»å—å½±å“çš„ç¨€ç–å›¾åƒé›†ä¸­æœ‰æ•ˆå»é™¤è€€æ–‘ï¼Œå¹¶å¯åœ¨ä¸åŒåœºæ™¯ä¸­æ³›åŒ–ã€‚</li>
<li>GN-FRæ¡†æ¶ç»“åˆäº†å¤šä¸ªæ¨¡å—ï¼ŒåŒ…æ‹¬ç”¨äºç”Ÿæˆè€€æ–‘å ç”¨æ©æ¨¡çš„FMGæ¨¡å—ã€è§†å›¾é‡‡æ ·å™¨VSå’Œç‚¹é‡‡æ ·å™¨PSæ¨¡å—ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªç”¨äºè®­ç»ƒå’Œè¯„ä¼°GN-FRçš„æ–°çš„æ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ä¸ªæ¶µç›–å¹¿æ³›è€€æ–‘æ¨¡å¼çš„å…¨é¢æ•°æ®é›†ï¼Œé€‚åˆæ”¯æŒå¯¹è¯¥é—®é¢˜çš„æ·±å…¥ç ”ç©¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ©æ¨¡æŸå¤±å‡½æ•°ï¼Œå¯ä»¥åœ¨æ²¡æœ‰é…å¯¹æ— è€€æ–‘æ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e38e0e09c2122c1a141338bb8dd78188.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-865539fc727c81c8f18cb19e5f5784aa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b9409dca8aeca45aa30b12b65e1f5e88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fff4e385e9c0cbb536f55f17aa8764ed.jpg" align="middle">
</details>




<h2 id="NeRF-NQA-No-Reference-Quality-Assessment-for-Scenes-Generated-by-NeRF-and-Neural-View-Synthesis-Methods"><a href="#NeRF-NQA-No-Reference-Quality-Assessment-for-Scenes-Generated-by-NeRF-and-Neural-View-Synthesis-Methods" class="headerlink" title="NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF   and Neural View Synthesis Methods"></a>NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF   and Neural View Synthesis Methods</h2><p><strong>Authors:Qiang Qu, Hanxue Liang, Xiaoming Chen, Yuk Ying Chung, Yiran Shen</strong></p>
<p>Neural View Synthesis (NVS) has demonstrated efficacy in generating high-fidelity dense viewpoint videos using a image set with sparse views. However, existing quality assessment methods like PSNR, SSIM, and LPIPS are not tailored for the scenes with dense viewpoints synthesized by NVS and NeRF variants, thus, they often fall short in capturing the perceptual quality, including spatial and angular aspects of NVS-synthesized scenes. Furthermore, the lack of dense ground truth views makes the full reference quality assessment on NVS-synthesized scenes challenging. For instance, datasets such as LLFF provide only sparse images, insufficient for complete full-reference assessments. To address the issues above, we propose NeRF-NQA, the first no-reference quality assessment method for densely-observed scenes synthesized from the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment strategy, integrating both viewwise and pointwise approaches, to evaluate the quality of NVS-generated scenes. The viewwise approach assesses the spatial quality of each individual synthesized view and the overall inter-views consistency, while the pointwise approach focuses on the angular qualities of scene surface points and their compound inter-point quality. Extensive evaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality assessment methods (from fields of image, video, and light-field assessment). The results demonstrate NeRF-NQA outperforms the existing assessment methods significantly and it shows substantial superiority on assessing NVS-synthesized scenes without references. An implementation of this paper are available at <a target="_blank" rel="noopener" href="https://github.com/VincentQQu/NeRF-NQA">https://github.com/VincentQQu/NeRF-NQA</a>. </p>
<blockquote>
<p>ç¥ç»è§†å›¾åˆæˆï¼ˆNVSï¼‰å·²ç»æ˜¾ç¤ºå‡ºä½¿ç”¨ç¨€ç–è§†å›¾å›¾åƒé›†ç”Ÿæˆé«˜ä¿çœŸå¯†é›†è§†ç‚¹è§†é¢‘çš„æ•ˆèƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œå¦‚PSNRã€SSIMå’ŒLPIPSï¼Œå¹¶ä¸é€‚ç”¨äºç”±NVSå’ŒNeRFå˜ä½“åˆæˆçš„å¯†é›†è§†ç‚¹åœºæ™¯ï¼Œå› æ­¤ï¼Œå®ƒä»¬åœ¨æ•æ‰æ„ŸçŸ¥è´¨é‡æ–¹é¢å¸¸å¸¸ä¸è¶³ï¼ŒåŒ…æ‹¬NVSåˆæˆåœºæ™¯çš„ç©ºé—´å’Œè§’åº¦æ–¹é¢ã€‚æ­¤å¤–ï¼Œç¼ºä¹å¯†é›†çš„åœ°é¢çœŸå®è§†å›¾ä½¿å¾—å¯¹NVSåˆæˆåœºæ™¯è¿›è¡Œå…¨å‚è€ƒè´¨é‡è¯„ä¼°å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¾‹å¦‚ï¼ŒLLFFç­‰æ•°æ®é›†åªæä¾›ç¨€ç–å›¾åƒï¼Œä¸è¶³ä»¥è¿›è¡Œå®Œæ•´çš„å…¨å‚è€ƒè¯„ä¼°ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†NeRF-NQAï¼Œè¿™æ˜¯ç¬¬ä¸€ç§ç”¨äºç”±NVSå’ŒNeRFå˜ä½“åˆæˆçš„å¯†é›†è§‚å¯Ÿåœºæ™¯çš„æ— å‚è€ƒè´¨é‡è¯„ä¼°æ–¹æ³•ã€‚NeRF-NQAé‡‡ç”¨è”åˆè´¨é‡è¯„ä¼°ç­–ç•¥ï¼Œç»“åˆäº†è§†å›¾æ–¹æ³•å’Œç‚¹æ–¹æ³•ï¼Œä»¥è¯„ä¼°NVSç”Ÿæˆåœºæ™¯çš„è´¨é‡ã€‚è§†å›¾æ–¹æ³•è¯„ä¼°æ¯ä¸ªå•ç‹¬åˆæˆè§†å›¾çš„ç©ºè´¨é‡ä»¥åŠæ•´ä½“è§†å›¾é—´çš„ä¸€è‡´æ€§ï¼Œè€Œç‚¹æ–¹æ³•åˆ™ä¾§é‡äºåœºæ™¯è¡¨é¢ç‚¹çš„è§’åº¦è´¨é‡ä»¥åŠå®ƒä»¬çš„å¤åˆç‚¹é—´è´¨é‡ã€‚è¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œå°†NeRF-NQAä¸23ç§ä¸»æµè§†è§‰è´¨é‡è¯„ä¼°æ–¹æ³•ï¼ˆæ¥è‡ªå›¾åƒã€è§†é¢‘å’Œå…‰åœºè¯„ä¼°é¢†åŸŸï¼‰è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼ŒNeRF-NQAåœ¨è¯„ä¼°NVSåˆæˆåœºæ™¯æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰è¯„ä¼°æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æ— å‚è€ƒè¯„ä¼°æ–¹é¢è¡¨ç°å‡ºæå¤§çš„ä¼˜åŠ¿ã€‚è¯¥è®ºæ–‡çš„å®ç°å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/VincentQQu/NeRF-NQA%E3%80%82">https://github.com/VincentQQu/NeRF-NQAã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.08029v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>NeRF-NQAä½œä¸ºä¸€ç§æ— å‚è€ƒè´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œé’ˆå¯¹å¯†é›†è§‚æµ‹åœºæ™¯åˆæˆçš„è´¨é‡è¯„ä¼°é—®é¢˜è¿›è¡Œäº†åˆ›æ–°ã€‚è¯¥æ–¹æ³•ç»“åˆäº†è§†ç‚¹æ–¹æ³•å’Œç‚¹æ–¹æ³•ï¼Œæ—¨åœ¨è¯„ä¼°NVSç”Ÿæˆçš„åœºæ™¯è´¨é‡ã€‚ä¸ä¼ ç»Ÿçš„è´¨é‡è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼ŒNeRF-NQAèƒ½æ›´å¥½åœ°æ•æ‰åˆæˆåœºæ™¯çš„æ„ŸçŸ¥è´¨é‡ï¼ŒåŒ…æ‹¬ç©ºé—´ä¸è§’åº¦æ–¹é¢ã€‚ç ”ç©¶æˆæœåœ¨å¹¿æ³›è¯„ä¼°ä¸­éªŒè¯äº†å…¶ä¼˜è¶Šæ€§ã€‚å…·ä½“å®ç°å¯å‚è§ç›¸å…³GitHubä»“åº“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRF-NQAæ˜¯é¦–ä¸ªé’ˆå¯¹ç”±NVSå’ŒNeRFå˜ä½“åˆæˆçš„å¯†é›†è§‚æµ‹åœºæ™¯çš„æ— å‚è€ƒè´¨é‡è¯„ä¼°æ–¹æ³•ã€‚</li>
<li>NeRF-NQAé‡‡ç”¨è”åˆè´¨é‡è¯„ä¼°ç­–ç•¥ï¼ŒåŒ…æ‹¬è§†ç‚¹æ–¹æ³•å’Œç‚¹æ–¹æ³•ï¼Œä»¥å…¨é¢è¯„ä¼°NVSç”Ÿæˆçš„åœºæ™¯è´¨é‡ã€‚</li>
<li>NeRF-NQAèƒ½å¤Ÿè¯„ä¼°æ¯ä¸ªåˆæˆè§†ç‚¹çš„ç©ºé—´è´¨é‡å’Œè§†ç‚¹é—´çš„æ•´ä½“ä¸€è‡´æ€§ã€‚</li>
<li>NeRF-NQAå¯ä»¥å…³æ³¨åœºæ™¯è¡¨é¢ç‚¹çš„è§’åº¦è´¨é‡ä»¥åŠå„ç‚¹ä¹‹é—´çš„å¤åˆè´¨é‡ã€‚</li>
<li>ä¸ä¸»æµè§†è§‰è´¨é‡è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼ŒNeRF-NQAåœ¨è¯„ä¼°NVSåˆæˆçš„åœºæ™¯æ—¶è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
<li>ç¼ºä¹å¯†é›†åœ°é¢çœŸå®è§†å›¾ç»™NVSåˆæˆçš„åœºæ™¯å…¨å‚è€ƒè´¨é‡è¯„ä¼°å¸¦æ¥æŒ‘æˆ˜ï¼Œè€ŒNeRF-NQAè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-000e979692aa4c8d8f144717029a4813.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-775ff7b6a460a7114cf693b922a4bd06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78219cb1d384ca8d12dbd03ce6eedf46.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-abb5c891b1930a5afba3f2ee8b69ede5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-347f43769b5127f2924204f680331dde.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e06e2865f8f7f4232268634bd5d071bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cef61c5ce79d5b8b606d40762f67d11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34e0eff78638dad61378f2ff30c22917.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-731036771f824acedc6fe22837474de9.jpg" align="middle">
</details>




<h2 id="EventSplat-3D-Gaussian-Splatting-from-Moving-Event-Cameras-for-Real-time-Rendering"><a href="#EventSplat-3D-Gaussian-Splatting-from-Moving-Event-Cameras-for-Real-time-Rendering" class="headerlink" title="EventSplat: 3D Gaussian Splatting from Moving Event Cameras for   Real-time Rendering"></a>EventSplat: 3D Gaussian Splatting from Moving Event Cameras for   Real-time Rendering</h2><p><strong>Authors:Toshiya Yura, Ashkan Mirzaei, Igor Gilitschenski</strong></p>
<p>We introduce a method for using event camera data in novel view synthesis via Gaussian Splatting. Event cameras offer exceptional temporal resolution and a high dynamic range. Leveraging these capabilities allows us to effectively address the novel view synthesis challenge in the presence of fast camera motion. For initialization of the optimization process, our approach uses prior knowledge encoded in an event-to-video model. We also use spline interpolation for obtaining high quality poses along the event camera trajectory. This enhances the reconstruction quality from fast-moving cameras while overcoming the computational limitations traditionally associated with event-based Neural Radiance Field (NeRF) methods. Our experimental evaluation demonstrates that our results achieve higher visual fidelity and better performance than existing event-based NeRF approaches while being an order of magnitude faster to render. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆ©ç”¨äº‹ä»¶ç›¸æœºæ•°æ®é€šè¿‡é«˜æ–¯ç‚¹ç§¯è¿›è¡Œæ–°é¢–è§†è§’åˆæˆçš„æ–¹æ³•ã€‚äº‹ä»¶ç›¸æœºæä¾›å“è¶Šçš„æ—¶é—´åˆ†è¾¨ç‡å’Œé«˜åŠ¨æ€èŒƒå›´ã€‚åˆ©ç”¨è¿™äº›åŠŸèƒ½ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³å¿«é€Ÿæ‘„åƒæœºè¿åŠ¨ä¸‹çš„æ–°é¢–è§†è§’åˆæˆæŒ‘æˆ˜ã€‚ä¸ºäº†ä¼˜åŒ–è¿‡ç¨‹çš„åˆå§‹åŒ–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨äº‹ä»¶åˆ°è§†é¢‘çš„æ¨¡å‹ä¸­çš„å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨æ ·æ¡æ’å€¼æ¥è·å¾—äº‹ä»¶ç›¸æœºè½¨è¿¹çš„é«˜è´¨é‡å§¿æ€ã€‚è¿™æé«˜äº†ä»å¿«é€Ÿç§»åŠ¨çš„ç›¸æœºè¿›è¡Œé‡å»ºçš„è´¨é‡ï¼ŒåŒæ—¶å…‹æœäº†ä¼ ç»Ÿä¸Šä¸åŸºäºäº‹ä»¶çš„ç¥è§†è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•ç›¸å…³çš„è®¡ç®—é™åˆ¶ã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç»“æœè¾¾åˆ°äº†æ›´é«˜çš„è§†è§‰ä¿çœŸåº¦å’Œæ€§èƒ½ï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æ¯”ç°æœ‰çš„åŸºäºäº‹ä»¶çš„NeRFæ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07293v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨äº‹ä»¶ç›¸æœºæ•°æ®è¿›è¡Œæ–°å‹è§†å›¾åˆæˆçš„æ–¹æ³•ï¼Œé€šè¿‡é«˜æ–¯ç‚¹äº‘æŠ€æœ¯å®ç°ã€‚äº‹ä»¶ç›¸æœºå…·æœ‰å‡ºè‰²çš„æ—¶é—´åˆ†è¾¨ç‡å’Œé«˜åŠ¨æ€èŒƒå›´ï¼Œä½¿å¾—åœ¨å¿«é€Ÿç›¸æœºè¿åŠ¨çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åº”å¯¹è§†å›¾åˆæˆæŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•ä½¿ç”¨äº‹ä»¶åˆ°è§†é¢‘çš„æ¨¡å‹ç¼–ç å…ˆéªŒçŸ¥è¯†æ¥è¿›è¡Œä¼˜åŒ–è¿‡ç¨‹çš„åˆå§‹åŒ–ï¼Œå¹¶ä½¿ç”¨æ ·æ¡æ’å€¼æ¥è·å¾—äº‹ä»¶ç›¸æœºè½¨è¿¹çš„é«˜è´¨é‡å§¿æ€ã€‚è¿™æé«˜äº†å¿«é€Ÿç§»åŠ¨ç›¸æœºçš„é‡å»ºè´¨é‡ï¼Œå¹¶å…‹æœäº†ä¼ ç»Ÿäº‹ä»¶åŸºç¡€ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•çš„è®¡ç®—é™åˆ¶ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•çš„ç»“æœå…·æœ‰æ›´é«˜çš„è§†è§‰ä¿çœŸåº¦å’Œæ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æ¯”ç°æœ‰äº‹ä»¶åŸºç¡€NeRFæ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨äº‹ä»¶ç›¸æœºçš„ä¼˜ç§€æ—¶é—´åˆ†è¾¨ç‡å’Œé«˜åŠ¨æ€èŒƒå›´è¿›è¡Œæ–°å‹è§†å›¾åˆæˆã€‚</li>
<li>ä½¿ç”¨äº‹ä»¶åˆ°è§†é¢‘çš„æ¨¡å‹ç¼–ç å…ˆéªŒçŸ¥è¯†ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡æ ·æ¡æ’å€¼è·å¾—é«˜è´¨é‡å§¿æ€ï¼Œæé«˜å¿«é€Ÿç§»åŠ¨ç›¸æœºçš„é‡å»ºè´¨é‡ã€‚</li>
<li>å…‹æœäº†ä¼ ç»Ÿäº‹ä»¶åŸºç¡€ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•çš„è®¡ç®—é™åˆ¶ã€‚</li>
<li>å®ç°é«˜è§†è§‰ä¿çœŸåº¦å’Œè‰¯å¥½æ€§èƒ½çš„ç»“æœã€‚</li>
<li>ç›¸æ¯”ç°æœ‰äº‹ä»¶åŸºç¡€NeRFæ–¹æ³•ï¼Œæ¸²æŸ“é€Ÿåº¦æ›´å¿«ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d334757298e3a609e928d5ed7294448e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-19e5b8ae6652639ff3b16a241816277d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d149ec977c9fe15354931880a088b743.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb0e3141278ff281d9541c89ddc28abc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e40e4fc8211446e76a71bf1452fa8ae9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-637fa5732e7af15df7f6e821040e650f.jpg" align="middle">
</details>




<h2 id="Diffusing-Differentiable-Representations"><a href="#Diffusing-Differentiable-Representations" class="headerlink" title="Diffusing Differentiable Representations"></a>Diffusing Differentiable Representations</h2><p><strong>Authors:Yash Savani, Marc Finzi, J. Zico Kolter</strong></p>
<p>We introduce a novel, training-free method for sampling differentiable representations (diffreps) using pretrained diffusion models. Rather than merely mode-seeking, our method achieves sampling by â€œpulling backâ€ the dynamics of the reverse-time processâ€“from the image space to the diffrep parameter spaceâ€“and updating the parameters according to this pulled-back process. We identify an implicit constraint on the samples induced by the diffrep and demonstrate that addressing this constraint significantly improves the consistency and detail of the generated objects. Our method yields diffreps with substantially improved quality and diversity for images, panoramas, and 3D NeRFs compared to existing techniques. Our approach is a general-purpose method for sampling diffreps, expanding the scope of problems that diffusion models can tackle. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¯å¾®åˆ†è¡¨ç¤ºï¼ˆdiffrepï¼‰é‡‡æ ·çš„æ–°å‹æ— è®­ç»ƒæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯å•çº¯åœ°å¯»æ±‚æ¨¡å¼ï¼Œè€Œæ˜¯é€šè¿‡â€œæ‹‰å›â€åå‘æ—¶é—´è¿‡ç¨‹çš„åŠ¨æ€æ¥å®ç°é‡‡æ ·â€”â€”ä»å›¾åƒç©ºé—´åˆ°diffrepå‚æ•°ç©ºé—´ï¼Œå¹¶æ ¹æ®æ‹‰å›çš„æµç¨‹æ›´æ–°å‚æ•°ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºç”±diffrepå¼•èµ·çš„æ ·æœ¬çš„éšå¼çº¦æŸï¼Œå¹¶è¯æ˜è§£å†³è¿™ä¸€çº¦æŸå¯ä»¥æ˜¾è‘—æé«˜ç”Ÿæˆå¯¹è±¡çš„è¿è´¯æ€§å’Œç»†èŠ‚ã€‚ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒã€å…¨æ™¯å›¾å’Œ3D NeRFçš„diffrepç”Ÿæˆæ–¹é¢ï¼Œå…·æœ‰æ›´é«˜è´¨é‡å’Œå¤šæ ·æ€§çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯é€šç”¨çš„diffrepé‡‡æ ·æ–¹æ³•ï¼Œæ‰©å¤§äº†æ‰©æ•£æ¨¡å‹æ‰€èƒ½è§£å†³çš„é—®é¢˜èŒƒå›´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06981v1">PDF</a> Published at NeurIPS 2024</p>
<p><strong>æ‘˜è¦</strong><br>åŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„å¯é‡‡æ ·å¯å¾®è¡¨ç¤ºï¼ˆdiffrepï¼‰çš„æ–°æ–¹æ³•ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡â€œæ‹‰å›â€åå‘æ—¶é—´è¿‡ç¨‹çš„åŠ¨æ€æ¥å®ç°é‡‡æ ·ï¼Œä»å›¾åƒç©ºé—´åˆ°diffrepå‚æ•°ç©ºé—´ï¼Œå¹¶æ ¹æ®æ‹‰å›çš„è¿‡ç¨‹æ›´æ–°å‚æ•°ã€‚æˆ‘ä»¬ç¡®å®šäº†diffrepæ‰€éšå«çš„æ ·æœ¬çº¦æŸï¼Œå¹¶è¯æ˜è§£å†³è¿™ä¸€çº¦æŸèƒ½æ˜¾è‘—æé«˜ç”Ÿæˆå¯¹è±¡çš„è¿è´¯æ€§å’Œç»†èŠ‚ã€‚ç›¸æ¯”äºç°æœ‰æŠ€æœ¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒã€å…¨æ™¯å’Œä¸‰ç»´NeRFçš„diffrepç”Ÿæˆæ–¹é¢æœ‰ç€æ˜¾è‘—çš„è´¨é‡æå‡å’Œå¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºé‡‡æ ·diffrepæä¾›äº†ä¸€ç§é€šç”¨æ–¹æ³•ï¼Œæ‰©å¤§äº†æ‰©æ•£æ¨¡å‹å¯è§£å†³çš„é—®é¢˜èŒƒå›´ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ— éœ€è®­ç»ƒçš„å¯é‡‡æ ·å¯å¾®è¡¨ç¤ºï¼ˆdiffrepï¼‰æ–¹æ³•ã€‚</li>
<li>é€šè¿‡â€œæ‹‰å›â€åå‘æ—¶é—´è¿‡ç¨‹çš„åŠ¨æ€å®ç°ä»å›¾åƒç©ºé—´åˆ°diffrepå‚æ•°ç©ºé—´çš„é‡‡æ ·ã€‚</li>
<li>ç¡®å®šå¹¶è§£å†³äº†diffrepé‡‡æ ·ä¸­çš„éšå«çº¦æŸé—®é¢˜ã€‚</li>
<li>åœ¨å›¾åƒã€å…¨æ™¯å’Œä¸‰ç»´NeRFçš„diffrepç”Ÿæˆæ–¹é¢ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆå¯¹è±¡çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚</li>
<li>é€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°äº†é«˜è´¨é‡çš„diffrepé‡‡æ ·ï¼Œæ‰©å±•äº†å…¶åº”ç”¨èŒƒå›´ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¸ºé‡‡æ ·diffrepæä¾›äº†ä¸€ç§é€šç”¨æ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a6baeb493ba47cd67e8aa3e97f6481b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc293729eac042afd34df15350e3572d.jpg" align="middle">
</details>




<h2 id="Enhancing-operational-wind-downscaling-capabilities-over-Canada-Application-of-a-Conditional-Wasserstein-GAN-methodology"><a href="#Enhancing-operational-wind-downscaling-capabilities-over-Canada-Application-of-a-Conditional-Wasserstein-GAN-methodology" class="headerlink" title="Enhancing operational wind downscaling capabilities over Canada:   Application of a Conditional Wasserstein GAN methodology"></a>Enhancing operational wind downscaling capabilities over Canada:   Application of a Conditional Wasserstein GAN methodology</h2><p><strong>Authors:Jorge Guevara, Victor Nascimento, Johannes Schmude, Daniel Salles, Simon Corbeil-LÃ©tourneau, Madalina Surcel, Dominique Brunet</strong></p>
<p>Wind downscaling is essential for improving the spatial resolution of weather forecasts, particularly in operational Numerical Weather Prediction (NWP). This study advances wind downscaling by extending the DownGAN framework introduced by Annau et al.,to operational datasets from the Global Deterministic Prediction System (GDPS) and High-Resolution Deterministic Prediction System (HRDPS), covering the entire Canadian domain. We enhance the model by incorporating high-resolution static covariates, such as HRDPS-derived topography, into a Conditional Wasserstein Generative Adversarial Network with Gradient Penalty, implemented using a UNET-based generator. Following the DownGAN framework, our methodology integrates low-resolution GDPS forecasts (15 km, 10-day horizon) and high-resolution HRDPS forecasts (2.5 km, 48-hour horizon) with Frequency Separation techniques adapted from computer vision. Through robust training and inference over the Canadian region, we demonstrate the operational scalability of our approach, achieving significant improvements in wind downscaling accuracy. Statistical validation highlights reductions in root mean square error (RMSE) and log spectral distance (LSD) metrics compared to the original DownGAN. High-resolution conditioning covariates and Frequency Separation strategies prove instrumental in enhancing model performance. This work underscores the potential for extending high-resolution wind forecasts beyond the 48-hour horizon, bridging the gap to the 10-day low resolution global forecast window. </p>
<blockquote>
<p>é£åœºé™å°ºåº¦åŒ–å¯¹äºæé«˜å¤©æ°”é¢„æŠ¥çš„ç©ºé—´åˆ†è¾¨ç‡è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸šåŠ¡æ•°å€¼å¤©æ°”é¢„æŠ¥ï¼ˆNWPï¼‰ä¸­ã€‚æœ¬ç ”ç©¶é€šè¿‡æ‰©å±•Annauç­‰äººä»‹ç»çš„DownGANæ¡†æ¶ï¼Œå°†é£åœºé™å°ºåº¦åŒ–æŠ€æœ¯åº”ç”¨äºå…¨çƒç¡®å®šæ€§é¢„æµ‹ç³»ç»Ÿï¼ˆGDPSï¼‰å’Œé«˜åˆ†è¾¨ç‡ç¡®å®šæ€§é¢„æµ‹ç³»ç»Ÿï¼ˆHRDPSï¼‰çš„ä¸šåŠ¡æ•°æ®é›†ï¼Œè¦†ç›–æ•´ä¸ªåŠ æ‹¿å¤§åŒºåŸŸã€‚æˆ‘ä»¬é€šè¿‡å°†é«˜åˆ†è¾¨ç‡é™æ€åå˜é‡ï¼ˆå¦‚HRDPSè¡ç”Ÿçš„åœ°å½¢ï¼‰çº³å…¥å¸¦æœ‰æ¢¯åº¦æƒ©ç½šçš„æ¡ä»¶Wassersteinç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œå¢å¼ºäº†æ¨¡å‹çš„åŠŸèƒ½ã€‚è¯¥ç½‘ç»œé‡‡ç”¨åŸºäºUNETçš„ç”Ÿæˆå™¨å®ç°ã€‚éµå¾ªDownGANæ¡†æ¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†ä½åˆ†è¾¨ç‡GDPSé¢„æµ‹ï¼ˆ15å…¬é‡Œï¼Œ10å¤©è§†é‡ï¼‰å’Œé«˜åˆ†è¾¨ç‡HRDPSé¢„æµ‹ï¼ˆ2.5å…¬é‡Œï¼Œ48å°æ—¶è§†é‡ï¼‰ï¼Œå¹¶é‡‡ç”¨äº†ä»è®¡ç®—æœºè§†è§‰ä¸­æ”¹ç¼–çš„é¢‘ç‡åˆ†ç¦»æŠ€æœ¯ã€‚é€šè¿‡åœ¨åŠ æ‹¿å¤§åœ°åŒºçš„ç¨³å¥è®­ç»ƒå’Œæ¨ç†ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨ä¸šåŠ¡è§„æ¨¡ä¸Šçš„å¯æ‰©å±•æ€§ï¼Œåœ¨é£åœºé™å°ºåº¦åŒ–ç²¾åº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æé«˜ã€‚ç»Ÿè®¡éªŒè¯ç»“æœæ˜¾ç¤ºï¼Œä¸åŸå§‹DownGANç›¸æ¯”ï¼Œå‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰å’Œå¯¹æ•°è°±è·ç¦»ï¼ˆLSDï¼‰æŒ‡æ ‡æœ‰æ‰€é™ä½ã€‚é«˜åˆ†è¾¨ç‡æ¡ä»¶åå˜é‡å’Œé¢‘ç‡åˆ†ç¦»ç­–ç•¥å¯¹äºæé«˜æ¨¡å‹æ€§èƒ½èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚è¿™é¡¹å·¥ä½œçªå‡ºäº†å°†é«˜åˆ†è¾¨ç‡é£åœºé¢„æµ‹æ‰©å±•åˆ°48å°æ—¶è§†é‡ä¹‹å¤–çš„å¯èƒ½æ€§ï¼Œç¼©å°äº†ä¸10å¤©ä½åˆ†è¾¨ç‡å…¨çƒé¢„æµ‹çª—å£çš„å·®è·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06958v1">PDF</a> </p>
<p><strong>Summary</strong><br>è¯¥æ–‡æœ¬ä¸»è¦ä»‹ç»äº†å¯¹å¤©æ°”é¢„æµ‹çš„é£åœºç²¾ç»†åŒ–çš„ç ”ç©¶ã€‚é€šè¿‡æ‰©å±•DownGANæ¡†æ¶å¹¶èåˆé™æ€åå˜é‡å’Œé«˜åˆ†è¾¨ç‡åœ°å½¢æ•°æ®ï¼Œç ”ç©¶äººå‘˜æé«˜äº†é£åœºç²¾ç»†åŒ–çš„å‡†ç¡®æ€§ã€‚è¯¥æ¨¡å‹åœ¨åŠ æ‹¿å¤§åŒºåŸŸè¿›è¡Œäº†ç¨³å¥çš„è®­ç»ƒå’Œæ¨ç†ï¼Œæ˜¾è‘—æå‡äº†é•¿æœŸå¤©æ°”é¢„æŠ¥çš„ç²¾ç»†åŒ–æ°´å¹³ï¼Œå¹¶é™ä½äº†é¢„æµ‹è¯¯å·®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶äººå‘˜æ‰©å±•äº†DownGANæ¡†æ¶ï¼Œå°†å…¶åº”ç”¨äºå…¨çƒç¡®å®šæ€§é¢„æµ‹ç³»ç»Ÿå’Œé«˜åˆ†è¾¨ç‡ç¡®å®šæ€§é¢„æµ‹ç³»ç»Ÿçš„æ“ä½œæ•°æ®é›†ã€‚</li>
<li>é€šè¿‡èåˆé«˜åˆ†è¾¨ç‡é™æ€åå˜é‡å¦‚åœ°å½¢æ•°æ®ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨æ¡ä»¶ç“¦ç‘Ÿæ–¯å¦ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œç»“åˆäº†æ¢¯åº¦æƒ©ç½šï¼Œæé«˜äº†ç²¾ç»†åŒ–æ°´å¹³ã€‚</li>
<li>åœ¨åŠ æ‹¿å¤§åŒºåŸŸå†…è¿›è¡Œäº†æ¨¡å‹çš„ç¨³å¥è®­ç»ƒå’Œæ¨ç†ï¼Œå±•ç¤ºäº†æ–¹æ³•åœ¨å®é™…æ“ä½œä¸­çš„å¯æ‰©å±•æ€§ã€‚</li>
<li>é€šè¿‡é¢‘ç‡åˆ†ç¦»æŠ€æœ¯æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œä¸è®¡ç®—æœºè§†è§‰ä¸­çš„æŠ€æœ¯ç›¸ç»“åˆï¼Œé™ä½äº†æ ¹å‡æ–¹è¯¯å·®å’Œå¯¹æ•°è°±è·ç¦»æŒ‡æ ‡ã€‚</li>
<li>é«˜åˆ†è¾¨ç‡åå˜é‡å’Œé¢‘ç‡åˆ†ç¦»ç­–ç•¥å¯¹äºæé«˜æ¨¡å‹æ€§èƒ½èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-23348f6549c3cbaff32b630d8a7b8b6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-73a9fce5db263ff4f008c491d71257fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-533fac644ef9b0c641f7c4e040b6977f.jpg" align="middle">
</details>




<h2 id="MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting"><a href="#MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting" class="headerlink" title="MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting"></a>MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting</h2><p><strong>Authors:Peng Chen, Xiaobao Wei, Qingpo Wuwu, Xinyi Wang, Xingyu Xiao, Ming Lu</strong></p>
<p>Reconstructing high-fidelity 3D head avatars is crucial in various applications such as virtual reality. The pioneering methods reconstruct realistic head avatars with Neural Radiance Fields (NeRF), which have been limited by training and rendering speed. Recent methods based on 3D Gaussian Splatting (3DGS) significantly improve the efficiency of training and rendering. However, the surface inconsistency of 3DGS results in subpar geometric accuracy; later, 2DGS uses 2D surfels to enhance geometric accuracy at the expense of rendering fidelity. To leverage the benefits of both 2DGS and 3DGS, we propose a novel method named MixedGaussianAvatar for realistically and geometrically accurate head avatar reconstruction. Our main idea is to utilize 2D Gaussians to reconstruct the surface of the 3D head, ensuring geometric accuracy. We attach the 2D Gaussians to the triangular mesh of the FLAME model and connect additional 3D Gaussians to those 2D Gaussians where the rendering quality of 2DGS is inadequate, creating a mixed 2D-3D Gaussian representation. These 2D-3D Gaussians can then be animated using FLAME parameters. We further introduce a progressive training strategy that first trains the 2D Gaussians and then fine-tunes the mixed 2D-3D Gaussians. We demonstrate the superiority of MixedGaussianAvatar through comprehensive experiments. The code will be released at: <a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>. </p>
<blockquote>
<p>é‡å»ºé«˜ä¿çœŸ3Då¤´åƒå¯¹äºè™šæ‹Ÿç°å®ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚å¼€åˆ›æ€§çš„æ–¹æ³•ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é‡å»ºé€¼çœŸçš„å¤´åƒï¼Œä½†å—é™äºè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„æœ€è¿‘çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“çš„æ•ˆç‡ã€‚ç„¶è€Œï¼Œ3DGSçš„è¡¨é¢ä¸ä¸€è‡´å¯¼è‡´å‡ ä½•ç²¾åº¦ä¸ä½³ï¼›åæ¥çš„2DGSä½¿ç”¨2D surfelsæ¥æé«˜å‡ ä½•ç²¾åº¦ï¼Œä½†ç‰ºç‰²äº†æ¸²æŸ“ä¿çœŸåº¦ã€‚ä¸ºäº†ç»“åˆ2DGSå’Œ3DGSçš„ä¼˜ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMixedGaussianAvatarçš„æ–°æ–¹æ³•ï¼Œç”¨äºçœŸå®ä¸”å‡ ä½•ç²¾ç¡®çš„å¤´åƒé‡å»ºã€‚æˆ‘ä»¬çš„ä¸»è¦æƒ³æ³•æ˜¯ä½¿ç”¨2Dé«˜æ–¯é‡å»º3Då¤´åƒçš„è¡¨é¢ï¼Œä»¥ç¡®ä¿å‡ ä½•ç²¾åº¦ã€‚æˆ‘ä»¬å°†2Dé«˜æ–¯é™„åŠ åˆ°FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼ä¸Šï¼Œå¹¶åœ¨2DGSçš„æ¸²æŸ“è´¨é‡ä¸è¶³çš„åœ°æ–¹è¿æ¥åˆ°é¢å¤–çš„3Dé«˜æ–¯ï¼Œåˆ›å»ºæ··åˆçš„2D-3Dé«˜æ–¯è¡¨ç¤ºã€‚è¿™äº›2D-3Dé«˜æ–¯å¯ä»¥ä½¿ç”¨FLAMEå‚æ•°è¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ¸è¿›çš„è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒ2Dé«˜æ–¯ï¼Œç„¶åå¯¹æ··åˆçš„2D-3Dé«˜æ–¯è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡å…¨é¢çš„å®éªŒå±•ç¤ºäº†MixedGaussianAvatarçš„ä¼˜åŠ¿ã€‚ä»£ç å°†åœ¨ä»¥ä¸‹ç½‘å€å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04955v2">PDF</a> Project: <a target="_blank" rel="noopener" href="https://chenvoid.github.io/MGA/">https://chenvoid.github.io/MGA/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºMixedGaussianAvatarçš„æ–°æ–¹æ³•ï¼Œç”¨äºåŸºäºNeural Radiance Fieldsï¼ˆNeRFï¼‰æŠ€æœ¯é‡å»ºé«˜ä¿çœŸä¸‰ç»´å¤´åƒã€‚è¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´Gaussianså’Œä¸‰ç»´Gaussiansçš„ä¼˜ç‚¹ï¼Œç¡®ä¿äº†å‡ ä½•å‡†ç¡®æ€§å¹¶æé«˜äº†æ¸²æŸ“è´¨é‡ã€‚é€šè¿‡å°†äºŒç»´Gaussiansé™„ç€åœ¨FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼ä¸Šï¼Œå¹¶åœ¨éœ€è¦æ—¶æ·»åŠ é¢å¤–çš„ä¸‰ç»´Gaussiansï¼Œåˆ›å»ºäº†ä¸€ä¸ªæ··åˆçš„äºŒç»´-ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè¿˜é‡‡ç”¨äº†ä¸€ç§æ¸è¿›å¼çš„è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒäºŒç»´Gaussiansï¼Œç„¶åå¯¹æ··åˆçš„äºŒç»´-ä¸‰ç»´Gaussiansè¿›è¡Œå¾®è°ƒã€‚MixedGaussianAvataré€šè¿‡ä¸€ç³»åˆ—å®éªŒè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MixedGaussianAvataræ–¹æ³•ç»“åˆäº†äºŒç»´Gaussianså’Œä¸‰ç»´Gaussiansçš„ä¼˜åŠ¿ï¼Œæ—¨åœ¨é‡å»ºé«˜ä¿çœŸä¸‰ç»´å¤´åƒã€‚</li>
<li>æ–¹æ³•åˆ©ç”¨äºŒç»´Gaussiansé‡å»ºä¸‰ç»´å¤´éƒ¨çš„è¡¨é¢ï¼Œç¡®ä¿å‡ ä½•å‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡å°†äºŒç»´Gaussiansé™„ç€åœ¨FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼ä¸Šï¼Œå¹¶åœ¨å¿…è¦æ—¶æ·»åŠ é¢å¤–çš„ä¸‰ç»´Gaussiansï¼Œåˆ›å»ºäº†æ··åˆçš„äºŒç»´-ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥äº†æ¸è¿›å¼çš„è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒäºŒç»´Gaussiansï¼Œå†å¯¹æ··åˆçš„äºŒç»´-ä¸‰ç»´Gaussiansè¿›è¡Œå¾®è°ƒã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æé«˜æ¸²æŸ“é€Ÿåº¦å¹¶æ”¹å–„å‡ ä½•å‡†ç¡®æ€§ã€‚</li>
<li>MixedGaussianAvatarçš„ä¼˜è¶Šæ€§é€šè¿‡ä¸€ç³»åˆ—å®éªŒå¾—åˆ°äº†éªŒè¯ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fee7aa56253f4eb6856f0bdf9d9655e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ef5787956810f1e111d21adf0bdcf5c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce4f964cf25207a6db5a28f7f85bd755.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a7e93cc4f1cccfe010d043da886dc390.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-43282ee6f05919c0b760a138b7ff6c40.jpg" align="middle">
</details>




<h2 id="Learning-based-Multi-View-Stereo-A-Survey"><a href="#Learning-based-Multi-View-Stereo-A-Survey" class="headerlink" title="Learning-based Multi-View Stereo: A Survey"></a>Learning-based Multi-View Stereo: A Survey</h2><p><strong>Authors:Fangjinhua Wang, Qingtian Zhu, Di Chang, Quankai Gao, Junlin Han, Tong Zhang, Richard Hartley, Marc Pollefeys</strong></p>
<p>3D reconstruction aims to recover the dense 3D structure of a scene. It plays an essential role in various applications such as Augmented&#x2F;Virtual Reality (AR&#x2F;VR), autonomous driving and robotics. Leveraging multiple views of a scene captured from different viewpoints, Multi-View Stereo (MVS) algorithms synthesize a comprehensive 3D representation, enabling precise reconstruction in complex environments. Due to its efficiency and effectiveness, MVS has become a pivotal method for image-based 3D reconstruction. Recently, with the success of deep learning, many learning-based MVS methods have been proposed, achieving impressive performance against traditional methods. We categorize these learning-based methods as: depth map-based, voxel-based, NeRF-based, 3D Gaussian Splatting-based, and large feed-forward methods. Among these, we focus significantly on depth map-based methods, which are the main family of MVS due to their conciseness, flexibility and scalability. In this survey, we provide a comprehensive review of the literature at the time of this writing. We investigate these learning-based methods, summarize their performances on popular benchmarks, and discuss promising future research directions in this area. </p>
<blockquote>
<p>ä¸‰ç»´é‡å»ºæ—¨åœ¨æ¢å¤åœºæ™¯çš„å¯†é›†ä¸‰ç»´ç»“æ„ã€‚å®ƒåœ¨å¢å¼º&#x2F;è™šæ‹Ÿç°å®ï¼ˆAR&#x2F;VRï¼‰ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯ç­‰å„ç§åº”ç”¨ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚åˆ©ç”¨ä»ä¸åŒè§†è§’æ•æ‰çš„åœºæ™¯çš„å¤šä¸ªè§†å›¾ï¼Œå¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰ç®—æ³•åˆæˆå…¨é¢çš„ä¸‰ç»´è¡¨ç¤ºï¼Œå®ç°åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç²¾ç¡®é‡å»ºã€‚ç”±äºå…¶æ•ˆç‡å’Œæœ‰æ•ˆæ€§ï¼ŒMVSå·²æˆä¸ºåŸºäºå›¾åƒçš„3Dé‡å»ºçš„å…³é”®æ–¹æ³•ã€‚æœ€è¿‘ï¼Œéšç€æ·±åº¦å­¦ä¹ å–å¾—çš„æˆåŠŸï¼Œå·²ç»æå‡ºäº†è®¸å¤šåŸºäºå­¦ä¹ çš„MVSæ–¹æ³•ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›æ–¹æ³•å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœã€‚æˆ‘ä»¬å°†è¿™äº›åŸºäºå­¦ä¹ çš„æ–¹æ³•åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼šåŸºäºæ·±åº¦å›¾çš„æ–¹æ³•ã€åŸºäºä½“ç´ çš„æ–¹æ³•ã€åŸºäºNeRFçš„æ–¹æ³•ã€åŸºäºä¸‰ç»´é«˜æ–¯è´´å›¾çš„æ–¹æ³•å’Œå¤§å‹å‰é¦ˆæ–¹æ³•ã€‚å…¶ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨åŸºäºæ·±åº¦å›¾çš„æ–¹æ³•ï¼Œç”±äºå…¶ç®€æ´æ€§ã€çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå®ƒä»¬æˆä¸ºMVSçš„ä¸»è¦å®¶æ—ã€‚åœ¨æœ¬æ–‡ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬å…¨é¢å›é¡¾äº†æˆªè‡³å½“å‰æ–‡çŒ®çš„æƒ…å†µã€‚æˆ‘ä»¬è°ƒæŸ¥äº†è¿™äº›åŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œæ€»ç»“äº†å®ƒä»¬åœ¨æµè¡ŒåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ï¼Œå¹¶è®¨è®ºäº†è¯¥é¢†åŸŸæœªæ¥ç ”ç©¶çš„å¯Œæœ‰å¸Œæœ›çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.15235v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰æ–¹æ³•åœ¨3Dé‡å»ºé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚æœ¬æ–‡ä¸»è¦å…³æ³¨åŸºäºæ·±åº¦å›¾çš„MVSæ–¹æ³•ï¼Œå®ƒä»¬å…·æœ‰ç®€æ´æ€§ã€çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œæ˜¯MVSçš„ä¸»è¦å®¶æ—ã€‚æœ¬æ–‡æä¾›äº†å¯¹è¿™äº›å­¦ä¹ æ–¹æ³•çš„å…¨é¢ç»¼è¿°ï¼Œæ€»ç»“äº†å®ƒä»¬åœ¨æµè¡ŒåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ï¼Œå¹¶è®¨è®ºäº†è¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé‡å»ºæ—¨åœ¨æ¢å¤åœºæ™¯çš„å¯†é›†3Dç»“æ„ï¼Œåœ¨å¢å¼º&#x2F;è™šæ‹Ÿç°å®ã€è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰ç®—æ³•é€šè¿‡ä»ä¸åŒè§†è§’æ•æ‰åœºæ™¯çš„å¤šè§†è§’å›¾åƒï¼Œåˆæˆå…¨é¢çš„3Dè¡¨ç¤ºï¼Œå®ç°åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç²¾ç¡®é‡å»ºã€‚</li>
<li>MVSå·²æˆä¸ºå›¾åƒ3Dé‡å»ºçš„å…³é”®æ–¹æ³•ï¼Œå› å…¶é«˜æ•ˆæ€§å’Œæ•ˆæœæ€§ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨MVSæ–¹æ³•ä¸­çš„åº”ç”¨å·²ç»å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œäº§ç”Ÿäº†å¤šç§å­¦ä¹ åŸºäºçš„æ–¹æ³•ï¼Œå¦‚æ·±åº¦å›¾åŸºäºã€ä½“ç´ åŸºäºã€NeRFåŸºäºç­‰ã€‚</li>
<li>æ·±åº¦å›¾åŸºäºçš„æ–¹æ³•æ˜¯MVSçš„ä¸»è¦å®¶æ—ï¼Œå› å…¶ç®€æ´æ€§ã€çµæ´»æ€§å’Œå¯æ‰©å±•æ€§è€Œå—åˆ°å…³æ³¨ã€‚</li>
<li>æœ¬æ–‡æä¾›äº†å­¦ä¹ åŸºäºçš„MVSæ–¹æ³•çš„å…¨é¢ç»¼è¿°ï¼Œæ€»ç»“äº†å®ƒä»¬åœ¨æµè¡ŒåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a5e5346a998309aa296c8385f856de80.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-22ada0555da5fef891a724a431157d98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03bb12f1f648696bd6045b65e15edfd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6a69c8889a02a0a54adc1f576279f164.jpg" align="middle">
</details>




<h2 id="Rethinking-Score-Distillation-as-a-Bridge-Between-Image-Distributions"><a href="#Rethinking-Score-Distillation-as-a-Bridge-Between-Image-Distributions" class="headerlink" title="Rethinking Score Distillation as a Bridge Between Image Distributions"></a>Rethinking Score Distillation as a Bridge Between Image Distributions</h2><p><strong>Authors:David McAllister, Songwei Ge, Jia-Bin Huang, David W. Jacobs, Alexei A. Efros, Aleksander Holynski, Angjoo Kanazawa</strong></p>
<p>Score distillation sampling (SDS) has proven to be an important tool, enabling the use of large-scale diffusion priors for tasks operating in data-poor domains. Unfortunately, SDS has a number of characteristic artifacts that limit its usefulness in general-purpose applications. In this paper, we make progress toward understanding the behavior of SDS and its variants by viewing them as solving an optimal-cost transport path from a source distribution to a target distribution. Under this new interpretation, these methods seek to transport corrupted images (source) to the natural image distribution (target). We argue that current methodsâ€™ characteristic artifacts are caused by (1) linear approximation of the optimal path and (2) poor estimates of the source distribution. We show that calibrating the text conditioning of the source distribution can produce high-quality generation and translation results with little extra overhead. Our method can be easily applied across many domains, matching or beating the performance of specialized methods. We demonstrate its utility in text-to-2D, text-based NeRF optimization, translating paintings to real images, optical illusion generation, and 3D sketch-to-real. We compare our method to existing approaches for score distillation sampling and show that it can produce high-frequency details with realistic colors. </p>
<blockquote>
<p>å¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰å·²è¢«è¯æ˜æ˜¯æ‰§è¡Œæ•°æ®è´«ä¹åŸŸä»»åŠ¡æ—¶ä½¿ç”¨å¤§è§„æ¨¡æ‰©æ•£å…ˆéªŒçš„é‡è¦å·¥å…·ã€‚ç„¶è€Œï¼ŒSDSå­˜åœ¨è®¸å¤šç‰¹å¾æ€§ä¼ªå½±ï¼Œé™åˆ¶äº†å…¶åœ¨é€šç”¨åº”ç”¨ä¸­çš„å®ç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°†å…¶è§†ä¸ºä»æºåˆ†å¸ƒåˆ°ç›®æ ‡åˆ†å¸ƒçš„æœ€ä½³æˆæœ¬ä¼ è¾“è·¯å¾„çš„è§£å†³æ–¹å¼ï¼Œå–å¾—äº†ç†è§£SDSåŠå…¶å˜ä½“è¡Œä¸ºçš„è¿›å±•ã€‚åœ¨è¿™ç§æ–°è§£é‡Šä¸‹ï¼Œè¿™äº›æ–¹æ³•è¯•å›¾å°†æŸåçš„å›¾åƒï¼ˆæºï¼‰ä¼ è¾“åˆ°è‡ªç„¶å›¾åƒåˆ†å¸ƒï¼ˆç›®æ ‡ï¼‰ã€‚æˆ‘ä»¬è®¤ä¸ºå½“å‰æ–¹æ³•çš„ç‰¹å¾æ€§ä¼ªå½±æ˜¯ç”±ï¼ˆ1ï¼‰æœ€ä½³è·¯å¾„çš„çº¿æ€§è¿‘ä¼¼å’Œï¼ˆ2ï¼‰æºåˆ†å¸ƒä¼°è®¡ä¸ä½³å¼•èµ·çš„ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œæ ¡å‡†æºåˆ†å¸ƒçš„æ–‡æœ¬æ¡ä»¶å¯ä»¥åœ¨å‡ ä¹ä¸å¢åŠ é¢å¤–å¼€é”€çš„æƒ…å†µä¸‹äº§ç”Ÿé«˜è´¨é‡ç”Ÿæˆå’Œç¿»è¯‘ç»“æœã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è½»æ¾åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œè¾¾åˆ°æˆ–è¶…è¿‡ä¸“ä¸šæ–¹æ³•çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨æ–‡æœ¬åˆ°2Dã€åŸºäºæ–‡æœ¬çš„NeRFä¼˜åŒ–ã€ç»˜ç”»åˆ°ç°å®å›¾åƒçš„ç¿»è¯‘ã€å…‰å­¦å¹»è§‰ç”Ÿæˆå’Œ3Dè‰å›¾åˆ°ç°å®ç­‰ä»»åŠ¡ä¸­å±•ç¤ºäº†å…¶å®ç”¨æ€§ã€‚æˆ‘ä»¬å°†æ–¹æ³•ä¸ç°æœ‰çš„åˆ†æ•°è’¸é¦é‡‡æ ·æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œå¹¶è¯æ˜å®ƒå¯ä»¥ç”Ÿæˆå…·æœ‰é€¼çœŸé¢œè‰²çš„é«˜é¢‘ç»†èŠ‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.09417v2">PDF</a> NeurIPS 2024. Project webpage: <a target="_blank" rel="noopener" href="https://sds-bridge.github.io/">https://sds-bridge.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºè¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰çš„æŠ€æœ¯åœ¨æ•°æ®ç¨€ç¼ºé¢†åŸŸçš„åº”ç”¨ã€‚é€šè¿‡å°†å…¶è§†ä¸ºä»æºåˆ†å¸ƒåˆ°ç›®æ ‡åˆ†å¸ƒçš„æœ€ä½³æˆæœ¬ä¼ è¾“è·¯å¾„çš„è§£å†³æ–¹æ³•ï¼Œæœ¬æ–‡æ·±å…¥ç†è§£äº†SDSåŠå…¶å˜ä½“åœ¨å›¾åƒè½¬æ¢æ–¹é¢çš„è¡Œä¸ºã€‚æ–‡ç« æŒ‡å‡ºå½“å‰æ–¹æ³•çš„ç‰¹å¾ç¼ºé™·æºäºçº¿æ€§è¿‘ä¼¼æœ€ä¼˜è·¯å¾„å’Œæºåˆ†å¸ƒä¼°è®¡ä¸ä½³ï¼Œå¹¶æå‡ºé€šè¿‡æ ¡å‡†æºåˆ†å¸ƒçš„æ–‡æœ¬æ¡ä»¶æ¥æé«˜ç”Ÿæˆå’Œè½¬æ¢è´¨é‡ã€‚æ­¤æ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œä¸ä¸“é¡¹æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶åœ¨æ–‡æœ¬åˆ°äºŒç»´å›¾åƒè½¬æ¢ã€åŸºäºæ–‡æœ¬çš„NeRFä¼˜åŒ–ã€ç»˜ç”»åˆ°ç°å®å›¾åƒç¿»è¯‘ã€å…‰å­¦å¹»è§‰ç”Ÿæˆå’Œä¸‰ç»´è‰å›¾åˆ°ç°å®åœºæ™¯ç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚æœ¬æ–‡è¿˜ä¸ç°æœ‰è¯„åˆ†è’¸é¦é‡‡æ ·æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œæ˜¾ç¤ºå‡ºåœ¨é«˜é¢‘ç»†èŠ‚å’ŒçœŸå®è‰²å½©ç”Ÿæˆæ–¹é¢çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰å·²æˆä¸ºè§£å†³æ•°æ®ç¨€ç¼ºé¢†åŸŸé—®é¢˜çš„å…³é”®å·¥å…·ã€‚</li>
<li>SDSå’Œå…¶ä»–æ–¹æ³•å¯è§†ä¸ºä»æºåˆ†å¸ƒåˆ°ç›®æ ‡åˆ†å¸ƒçš„æœ€ä½³æˆæœ¬ä¼ è¾“è·¯å¾„çš„è§£å†³æ–¹æ³•ã€‚</li>
<li>å½“å‰SDSæ–¹æ³•çš„ç‰¹å¾ç¼ºé™·æºäºçº¿æ€§è¿‘ä¼¼æœ€ä¼˜è·¯å¾„å’Œæºåˆ†å¸ƒä¼°è®¡ä¸ä½³ã€‚</li>
<li>é€šè¿‡æ ¡å‡†æºåˆ†å¸ƒçš„æ–‡æœ¬æ¡ä»¶ï¼Œå¯ä»¥æé«˜ç”Ÿæˆå’Œè½¬æ¢è´¨é‡ï¼Œä¸”å‡ ä¹æ— éœ€é¢å¤–å¼€é”€ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ€§ï¼Œå¯åœ¨å¤šä¸ªé¢†åŸŸè¿›è¡Œåº”ç”¨ï¼Œå¦‚æ–‡æœ¬åˆ°äºŒç»´å›¾åƒè½¬æ¢ã€åŸºäºæ–‡æœ¬çš„NeRFä¼˜åŒ–ç­‰ã€‚</li>
<li>ä¸ç°æœ‰è¯„åˆ†è’¸é¦é‡‡æ ·æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨é«˜é¢‘ç»†èŠ‚å’ŒçœŸå®è‰²å½©ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6ab688bcbe79403b9dc0a82fa87e55b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-583f9aab3efdf9acf3d30ae12a8d5845.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd2ee8b180e521f6c21caaa035b7cc5f.jpg" align="middle">
</details>




<h2 id="Mirror-3DGS-Incorporating-Mirror-Reflections-into-3D-Gaussian-Splatting"><a href="#Mirror-3DGS-Incorporating-Mirror-Reflections-into-3D-Gaussian-Splatting" class="headerlink" title="Mirror-3DGS: Incorporating Mirror Reflections into 3D Gaussian Splatting"></a>Mirror-3DGS: Incorporating Mirror Reflections into 3D Gaussian Splatting</h2><p><strong>Authors:Jiarui Meng, Haijie Li, Yanmin Wu, Qiankun Gao, Shuzhou Yang, Jian Zhang, Siwei Ma</strong></p>
<p>3D Gaussian Splatting (3DGS) has significantly advanced 3D scene reconstruction and novel view synthesis. However, like Neural Radiance Fields (NeRF), 3DGS struggles with accurately modeling physical reflections, particularly in mirrors, leading to incorrect reconstructions and inconsistent reflective properties. To address this challenge, we introduce Mirror-3DGS, a novel framework designed to accurately handle mirror geometries and reflections, thereby generating realistic mirror reflections. By incorporating mirror attributes into 3DGS and leveraging plane mirror imaging principles, Mirror-3DGS simulates a mirrored viewpoint from behind the mirror, enhancing the realism of scene renderings. Extensive evaluations on both synthetic and real-world scenes demonstrate that our method can render novel views with improved fidelity in real-time, surpassing the state-of-the-art Mirror-NeRF, especially in mirror regions. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰åœ¨ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œä¸ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä¸€æ ·ï¼Œ3DGSåœ¨å‡†ç¡®æ¨¡æ‹Ÿç‰©ç†åå°„æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨é•œå­ä¸­ï¼Œå¯¼è‡´é‡å»ºä¸å‡†ç¡®å’Œåå°„å±æ€§ä¸ä¸€è‡´ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Mirror-3DGSï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå‡†ç¡®å¤„ç†é•œå­å‡ ä½•å½¢çŠ¶å’Œåå°„è€Œè®¾è®¡çš„æ–°å‹æ¡†æ¶ï¼Œä»è€Œç”Ÿæˆé€¼çœŸçš„é•œå­åå°„ã€‚é€šè¿‡å°†é•œå­å±æ€§èå…¥3DGSå¹¶åˆ©ç”¨å¹³é¢é•œåƒæˆåƒåŸç†ï¼ŒMirror-3DGSå¯ä»¥æ¨¡æ‹Ÿé•œå­åé¢çš„è§†è§’ï¼Œå¢å¼ºåœºæ™¯æ¸²æŸ“çš„é€¼çœŸåº¦ã€‚å¯¹åˆæˆåœºæ™¯å’ŒçœŸå®åœºæ™¯çš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨å®æ—¶ä¸­ä»¥æ›´é«˜çš„ä¿çœŸåº¦å‘ˆç°æ–°é¢–è§‚ç‚¹ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„Mirror-NeRFï¼Œç‰¹åˆ«æ˜¯åœ¨é•œå­åŒºåŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.01168v2">PDF</a> IEEE International Conference on Visual Communications and Image   Processing (VCIP 2024, Oral)</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†é’ˆå¯¹ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°å‹è§†è§’åˆæˆä¸­çš„åå°„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMirror-3DGSçš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡èå…¥é•œåƒå±æ€§å¹¶åˆ©ç”¨å¹³é¢é•œåƒæˆåƒåŸç†ï¼Œå‡†ç¡®å¤„ç†é•œåƒå‡ ä½•å’Œåå°„ï¼Œç”Ÿæˆé€¼çœŸçš„é•œé¢åå°„æ•ˆæœã€‚ç›¸è¾ƒäºå½“å‰æœ€å…ˆè¿›çš„Mirror-NeRFï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®åœºæ™¯ä¸‹çš„è¯„ä¼°è¡¨ç°æ›´ä¼˜ç§€ï¼Œç‰¹åˆ«æ˜¯åœ¨é•œåƒåŒºåŸŸçš„å®æ—¶æ¸²æŸ“ä¸­æé«˜äº†ä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Mirror-3DGSæ¡†æ¶è¢«è®¾è®¡ç”¨äºè§£å†³ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°å‹è§†è§’åˆæˆä¸­çš„é•œåƒåå°„é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶ç»“åˆé•œåƒå±æ€§ï¼Œåˆ©ç”¨å¹³é¢é•œåƒæˆåƒåŸç†ï¼Œæ¨¡æ‹Ÿäº†é•œå­åçš„è§†è§’ï¼Œå¢å¼ºäº†åœºæ™¯æ¸²æŸ“çš„é€¼çœŸåº¦ã€‚</li>
<li>Mirror-3DGSèƒ½å¤Ÿåœ¨å®æ—¶æ¸²æŸ“ä¸­ç”Ÿæˆæ›´é«˜ä¿çœŸçš„é•œåƒåŒºåŸŸï¼Œè¶…è¶Šå½“å‰æœ€å…ˆè¿›çš„Mirror-NeRFæ–¹æ³•ã€‚</li>
<li>é€šè¿‡åœ¨åˆæˆå’ŒçœŸå®åœºæ™¯ä¸‹çš„å¹¿æ³›è¯„ä¼°ï¼ŒéªŒè¯äº†Mirror-3DGSçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºæ”¹è¿›ä¸‰ç»´åœºæ™¯é‡å»ºå’Œè§†è§’åˆæˆçš„è´¨é‡å…·æœ‰é‡å¤§æ„ä¹‰ã€‚</li>
<li>Mirror-3DGSçš„å¼•å…¥è¿›ä¸€æ­¥æ¨åŠ¨äº†ä¸‰ç»´åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“æŠ€æœ¯çš„å‘å±•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dd7869e208d9fb8d79482f7e49bf8dfd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-547b2159e15ad9259a5f5758f4258655.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc1bfa303ba582248284272ab2f58d3c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c71cd65107819c859fa830f5e804483d.jpg" align="middle">
</details>




<h2 id="UniSDF-Unifying-Neural-Representations-for-High-Fidelity-3D-Reconstruction-of-Complex-Scenes-with-Reflections"><a href="#UniSDF-Unifying-Neural-Representations-for-High-Fidelity-3D-Reconstruction-of-Complex-Scenes-with-Reflections" class="headerlink" title="UniSDF: Unifying Neural Representations for High-Fidelity 3D   Reconstruction of Complex Scenes with Reflections"></a>UniSDF: Unifying Neural Representations for High-Fidelity 3D   Reconstruction of Complex Scenes with Reflections</h2><p><strong>Authors:Fangjinhua Wang, Marie-Julie Rakotosaona, Michael Niemeyer, Richard Szeliski, Marc Pollefeys, Federico Tombari</strong></p>
<p>Neural 3D scene representations have shown great potential for 3D reconstruction from 2D images. However, reconstructing real-world captures of complex scenes still remains a challenge. Existing generic 3D reconstruction methods often struggle to represent fine geometric details and do not adequately model reflective surfaces of large-scale scenes. Techniques that explicitly focus on reflective surfaces can model complex and detailed reflections by exploiting better reflection parameterizations. However, we observe that these methods are often not robust in real scenarios where non-reflective as well as reflective components are present. In this work, we propose UniSDF, a general purpose 3D reconstruction method that can reconstruct large complex scenes with reflections. We investigate both camera view as well as reflected view-based color parameterization techniques and find that explicitly blending these representations in 3D space enables reconstruction of surfaces that are more geometrically accurate, especially for reflective surfaces. We further combine this representation with a multi-resolution grid backbone that is trained in a coarse-to-fine manner, enabling faster reconstructions than prior methods. Extensive experiments on object-level datasets DTU, Shiny Blender as well as unbounded datasets Mip-NeRF 360 and Ref-NeRF real demonstrate that our method is able to robustly reconstruct complex large-scale scenes with fine details and reflective surfaces, leading to the best overall performance. Project page: \url{<a target="_blank" rel="noopener" href="https://fangjinhuawang.github.io/UniSDF%7D">https://fangjinhuawang.github.io/UniSDF}</a>. </p>
<blockquote>
<p>ç¥ç»ä¸‰ç»´åœºæ™¯è¡¨ç¤ºåœ¨ä»æ— åˆ°æœ‰æ„å»ºä»äºŒç»´å›¾åƒä¸­è·å¾—äº†å·¨å¤§æ½œåŠ›çš„ä¸‰ç»´é‡å»ºã€‚ç„¶è€Œï¼Œé‡å»ºç°å®ä¸–ç•Œä¸­çš„å¤æ‚åœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰çš„é€šç”¨ä¸‰ç»´é‡å»ºæ–¹æ³•å¾€å¾€éš¾ä»¥è¡¨ç¤ºç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ï¼Œå¹¶ä¸”åœ¨å¤§è§„æ¨¡åœºæ™¯çš„åå°„è¡¨é¢å»ºæ¨¡æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸“æ³¨äºåå°„è¡¨é¢çš„æŠ€æœ¯å¯ä»¥é€šè¿‡åˆ©ç”¨æ›´å¥½çš„åå°„å‚æ•°åŒ–æ¥æ¨¡æ‹Ÿå¤æ‚å’Œè¯¦ç»†çš„åå°„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è¿™äº›æ–¹æ³•åœ¨éåå°„å’Œåå°„æˆåˆ†éƒ½å­˜åœ¨çš„çœŸå®åœºæ™¯ä¸­å¹¶ä¸ç¨³å¥ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨ç›®çš„çš„ä¸‰ç»´é‡å»ºæ–¹æ³•UniSDFï¼Œèƒ½å¤Ÿé‡å»ºå¸¦æœ‰åå°„çš„å¤§å‹å¤æ‚åœºæ™¯ã€‚æˆ‘ä»¬ç ”ç©¶äº†åŸºäºç›¸æœºè§†è§’å’Œåå°„è§†è§’çš„é¢œè‰²å‚æ•°åŒ–æŠ€æœ¯ï¼Œå¹¶å‘ç°é€šè¿‡åœ¨ä¸‰ç»´ç©ºé—´ä¸­æ˜¾å¼æ··åˆè¿™äº›è¡¨ç¤ºï¼Œèƒ½å¤Ÿé‡å»ºå‡ºæ›´å‡†ç¡®çš„å‡ ä½•è¡¨é¢ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåå°„è¡¨é¢ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†è¿™ç§è¡¨ç¤ºä¸ä»¥ä»ç²—ç³™åˆ°ç²¾ç»†çš„æ–¹å¼è®­ç»ƒçš„å¤šåˆ†è¾¨ç‡ç½‘æ ¼ä¸»å¹²ç›¸ç»“åˆï¼Œä½¿å¾—æ¯”ç°æœ‰æ–¹æ³•æ›´å¿«çš„é‡å»ºé€Ÿåº¦ã€‚åœ¨å¯¹è±¡çº§åˆ«çš„æ•°æ®é›†DTUå’ŒShiny Blenderä»¥åŠæ— è¾¹ç•Œæ•°æ®é›†Mip-NeRF 360å’ŒRef-NeRF realä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç¨³å¥åœ°é‡å»ºå…·æœ‰ç²¾ç»†ç»†èŠ‚å’Œåå°„è¡¨é¢çš„å¤æ‚å¤§è§„æ¨¡åœºæ™¯ï¼Œå–å¾—äº†æœ€ä½³çš„æ•´ä½“æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://fangjinhuawang.github.io/UniSDF">https://fangjinhuawang.github.io/UniSDF</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.13285v2">PDF</a> NeurIPS 2024 camera ready</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æå‡ºä¸€ç§åä¸ºUniSDFçš„é€šç”¨ä¸‰ç»´é‡å»ºæ–¹æ³•ï¼Œå¯é‡å»ºå…·æœ‰åå°„ç‰¹æ€§çš„å¤§å‹å¤æ‚åœºæ™¯ã€‚è¯¥æ–¹æ³•ç»“åˆç›¸æœºè§†è§’å’Œåå°„è§†è§’çš„é¢œè‰²å‚æ•°åŒ–æŠ€æœ¯ï¼Œèƒ½åœ¨ä¸‰ç»´ç©ºé—´ä¸­æ˜¾å¼èåˆè¿™äº›è¡¨ç¤ºï¼Œä»è€Œæ›´ç²¾ç¡®åœ°é‡å»ºå‡ ä½•è¡¨é¢ï¼Œå°¤å…¶é€‚ç”¨äºåå°„è¡¨é¢ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†å¤šåˆ†è¾¨ç‡ç½‘æ ¼ä¸»å¹²ï¼Œé‡‡ç”¨ç”±ç²—åˆ°ç»†çš„è®­ç»ƒæ–¹å¼ï¼Œå®ç°äº†æ¯”ç°æœ‰æ–¹æ³•æ›´å¿«çš„é‡å»ºé€Ÿåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ä½“çº§åˆ«æ•°æ®é›†DTUã€Shiny Blenderä»¥åŠæ— ç•Œæ•°æ®é›†Mip-NeRF 360å’ŒRef-NeRF realä¸Šè¡¨ç°æœ€ä½³ï¼Œèƒ½å¤Ÿç¨³å¥åœ°é‡å»ºå…·æœ‰ç²¾ç»†ç»†èŠ‚å’Œåå°„ç‰¹æ€§çš„å¤§å‹åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UniSDFæ˜¯ä¸€ç§ç”¨äºé‡å»ºå…·æœ‰åå°„ç‰¹æ€§çš„å¤§å‹å¤æ‚åœºæ™¯çš„ä¸‰ç»´é‡å»ºæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆç›¸æœºè§†è§’å’Œåå°„è§†è§’çš„é¢œè‰²å‚æ•°åŒ–æŠ€æœ¯ï¼Œä»¥æé«˜å‡ ä½•è¡¨é¢çš„é‡å»ºç²¾åº¦ã€‚</li>
<li>UniSDFé‡‡ç”¨å¤šåˆ†è¾¨ç‡ç½‘æ ¼ä¸»å¹²ï¼Œå®ç°äº†å¿«é€Ÿçš„ä¸‰ç»´é‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜ç§€ï¼Œèƒ½å¤Ÿç¨³å¥åœ°é‡å»ºå…·æœ‰ç²¾ç»†ç»†èŠ‚å’Œåå°„ç‰¹æ€§çš„åœºæ™¯ã€‚</li>
<li>UniSDFæ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œé€‚ç”¨äºä¸åŒçš„å¤æ‚åœºæ™¯ã€‚</li>
<li>æ˜¾å¼èåˆåå°„å’Œéåå°„ç»„ä»¶åœ¨ç°å®åœºæ™¯ä¸­çš„è¡¨ç°æ˜¯è¯¥æ–¹æ³•çš„ä¸€ä¸ªå…³é”®ä¼˜ç‚¹ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-44ad05589092be4a2ce220e1e63f9eea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42cb3052d279bf31b0971c292f0b5ce8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-56725227a346517f56bf4697cd76f5dc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df5b2dd7ca8cc571de05d576959e4b3c.jpg" align="middle">
</details>




<h2 id="Unpaired-Optical-Coherence-Tomography-Angiography-Image-Super-Resolution-via-Frequency-Aware-Inverse-Consistency-GAN"><a href="#Unpaired-Optical-Coherence-Tomography-Angiography-Image-Super-Resolution-via-Frequency-Aware-Inverse-Consistency-GAN" class="headerlink" title="Unpaired Optical Coherence Tomography Angiography Image Super-Resolution   via Frequency-Aware Inverse-Consistency GAN"></a>Unpaired Optical Coherence Tomography Angiography Image Super-Resolution   via Frequency-Aware Inverse-Consistency GAN</h2><p><strong>Authors:Weiwen Zhang, Dawei Yang, Haoxuan Che, An Ran Ran, Carol Y. Cheung, Hao Chen</strong></p>
<p>For optical coherence tomography angiography (OCTA) images, a limited scanning rate leads to a trade-off between field-of-view (FOV) and imaging resolution. Although larger FOV images may reveal more parafoveal vascular lesions, their application is greatly hampered due to lower resolution. To increase the resolution, previous works only achieved satisfactory performance by using paired data for training, but real-world applications are limited by the challenge of collecting large-scale paired images. Thus, an unpaired approach is highly demanded. Generative Adversarial Network (GAN) has been commonly used in the unpaired setting, but it may struggle to accurately preserve fine-grained capillary details, which are critical biomarkers for OCTA. In this paper, our approach aspires to preserve these details by leveraging the frequency information, which represents details as high-frequencies ($\textbf{hf}$) and coarse-grained backgrounds as low-frequencies ($\textbf{lf}$). In general, we propose a GAN-based unpaired super-resolution method for OCTA images and exceptionally emphasize $\textbf{hf}$ fine capillaries through a dual-path generator. To facilitate a precise spectrum of the reconstructed image, we also propose a frequency-aware adversarial loss for the discriminator and introduce a frequency-aware focal consistency loss for end-to-end optimization. Experiments show that our method outperforms other state-of-the-art unpaired methods both quantitatively and visually. </p>
<blockquote>
<p>å¯¹äºå…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æè¡€ç®¡é€ å½±ï¼ˆOCTAï¼‰å›¾åƒï¼Œæœ‰é™çš„æ‰«æé€Ÿç‡å¯¼è‡´è§†é‡ï¼ˆFOVï¼‰ä¸æˆåƒåˆ†è¾¨ç‡ä¹‹é—´çš„æƒè¡¡ã€‚è™½ç„¶è¾ƒå¤§çš„FOVå›¾åƒå¯èƒ½ä¼šæ­ç¤ºæ›´å¤šçš„æ—ä¸­å¿ƒå‡¹è¡€ç®¡ç—…å˜ï¼Œä½†ç”±äºåˆ†è¾¨ç‡è¾ƒä½ï¼Œå…¶åº”ç”¨å—åˆ°å¾ˆå¤§é˜»ç¢ã€‚ä¸ºäº†æå‡åˆ†è¾¨ç‡ï¼Œä¹‹å‰çš„å·¥ä½œåªæœ‰åœ¨ä½¿ç”¨é…å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒæ—¶æ‰èƒ½è¾¾åˆ°ä»¤äººæ»¡æ„çš„æ•ˆæœï¼Œä½†ç°å®ä¸–ç•Œçš„å®é™…åº”ç”¨å—é™äºæ”¶é›†å¤§è§„æ¨¡é…å¯¹å›¾åƒçš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œå¯¹æœªé…å¯¹çš„æ–¹æ³•æœ‰ç€æé«˜çš„éœ€æ±‚ã€‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å·²åœ¨æœªé…å¯¹è®¾ç½®ä¸­å¹¿æ³›ä½¿ç”¨ï¼Œä½†åœ¨å‡†ç¡®ä¿ç•™ç²¾ç»†æ¯›ç»†è¡€ç®¡ç»†èŠ‚æ–¹é¢å¯èƒ½é¢ä¸´å›°éš¾ï¼Œè¿™å¯¹äºOCTAæ¥è¯´æ˜¯éå¸¸é‡è¦çš„ç”Ÿç‰©æ ‡å¿—ç‰©ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨é€šè¿‡åˆ©ç”¨é¢‘ç‡ä¿¡æ¯æ¥ä¿ç•™è¿™äº›è¯¦ç»†ä¿¡æ¯ï¼Œå°†ç²¾ç»†çš„æ¯›ç»†è¡€ç®¡ä½œä¸ºé«˜é¢‘ï¼ˆhfï¼‰å’Œç²—ç²’åº¦çš„èƒŒæ™¯ä½œä¸ºä½é¢‘ï¼ˆlfï¼‰æ¥è¡¨ç¤ºã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºGANçš„æœªé…å¯¹è¶…åˆ†è¾¨ç‡æ–¹æ³•ç”¨äºOCTAå›¾åƒï¼Œå¹¶é€šè¿‡åŒè·¯å¾„ç”Ÿæˆå™¨ç‰¹åˆ«å¼ºè°ƒäº†é«˜é¢‘çš„ç²¾ç»†æ¯›ç»†è¡€ç®¡ã€‚ä¸ºäº†ä¿ƒè¿›é‡å»ºå›¾åƒçš„ç²¾ç¡®å…‰è°±ï¼Œæˆ‘ä»¬è¿˜ä¸ºé‰´åˆ«å™¨æå‡ºäº†é¢‘ç‡æ„ŸçŸ¥å¯¹æŠ—æ€§æŸå¤±ï¼Œå¹¶å¼•å…¥äº†é¢‘ç‡æ„ŸçŸ¥ç„¦ç‚¹ä¸€è‡´æ€§æŸå¤±æ¥è¿›è¡Œç«¯åˆ°ç«¯çš„ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šé‡å’Œè§†è§‰ä¸Šè¶…è¶Šäº†å…¶ä»–æœ€å…ˆè¿›çš„æœªé…å¯¹æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.17269v2">PDF</a> 11 pages, 10 figures, in IEEE J-BHI, 2024</p>
<p><strong>Summary</strong></p>
<p>é’ˆå¯¹å…‰å­¦ç›¸å¹²æ–­å±‚æ‰«æè¡€ç®¡é€ å½±ï¼ˆOCTAï¼‰å›¾åƒï¼Œå› æ‰«æé€Ÿç‡æœ‰é™ï¼Œéœ€åœ¨è§†é‡ï¼ˆFOVï¼‰ä¸æˆåƒåˆ†è¾¨ç‡ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚ä¸ºæå‡åˆ†è¾¨ç‡ï¼Œå…ˆå‰ç ”ç©¶ä»…é€šè¿‡å¯¹é…å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒè·å¾—æ»¡æ„ç»“æœï¼Œä½†å®é™…åº”ç”¨å—é™äºå¤§è§„æ¨¡é…å¯¹å›¾åƒé‡‡é›†çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œå¯¹æ— éœ€é…å¯¹çš„æ–¹æ³•æœ‰è¿«åˆ‡éœ€æ±‚ã€‚æœ¬æ–‡åˆ©ç”¨é¢‘ç‡ä¿¡æ¯ï¼Œé‡‡ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è¿›è¡ŒOCTAå›¾åƒçš„æ— éœ€é…å¯¹è¶…åˆ†è¾¨ç‡å¤„ç†ï¼Œå¹¶ç‰¹åˆ«å¼ºè°ƒé«˜é¢‘ç»†èŠ‚æ¯›ç»†è¡€ç®¡çš„ä¿ç•™ã€‚é€šè¿‡åŒè·¯å¾„ç”Ÿæˆå™¨ã€é¢‘ç‡æ„ŸçŸ¥å¯¹æŠ—æŸå¤±å’Œç«¯åˆ°ç«¯ä¼˜åŒ–çš„é¢‘ç‡æ„ŸçŸ¥ç„¦ç‚¹ä¸€è‡´æ€§æŸå¤±ç­‰æ–¹æ³•ï¼Œå®ç°äº†ç²¾ç¡®çš„å›¾åƒé‡å»ºã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€é…å¯¹çš„æ–¹æ³•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OCTAå›¾åƒé¢ä¸´æ‰«æé€Ÿç‡ä¸è§†é‡å’Œæˆåƒåˆ†è¾¨ç‡ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>å…ˆå‰æ–¹æ³•ä¾èµ–é…å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½†é…å¯¹å›¾åƒé‡‡é›†å›°éš¾ï¼Œæ•…éœ€æ±‚æ— éœ€é…å¯¹çš„æ–¹æ³•ã€‚</li>
<li>æœ¬æ–‡é‡‡ç”¨GANè¿›è¡ŒOCTAå›¾åƒè¶…åˆ†è¾¨ç‡å¤„ç†ï¼Œå¹¶ç‰¹åˆ«å…³æ³¨é«˜é¢‘ç»†èŠ‚æ¯›ç»†è¡€ç®¡çš„ä¿ç•™ã€‚</li>
<li>æå‡ºåŒè·¯å¾„ç”Ÿæˆå™¨ã€é¢‘ç‡æ„ŸçŸ¥å¯¹æŠ—æŸå¤±å’Œé¢‘ç‡æ„ŸçŸ¥ç„¦ç‚¹ä¸€è‡´æ€§æŸå¤±ç­‰æ–¹æ³•æå‡å›¾åƒé‡å»ºç²¾åº¦ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8a7d2dacbfa04387e19bffb611cddd3e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-37207abe4a6a009c6c161251db6a0dc7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0dc134bb1beea380f62fe84bb2cb6682.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78a06df289a30d0915c38a304ff0732a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-46d39c0c7ae0f29f88c8af6d66816c47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-811b53fc9884b14c64110c9698ed318d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8c5b27ba5f5430f411959f118701cd9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-833009dbaad71b8fe443d1578e47e112.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b31d7d25c3842dd3c4d8bc5b8a631ae5.jpg" align="middle">
</details>




<h2 id="MC-NeRF-Multi-Camera-Neural-Radiance-Fields-for-Multi-Camera-Image-Acquisition-Systems"><a href="#MC-NeRF-Multi-Camera-Neural-Radiance-Fields-for-Multi-Camera-Image-Acquisition-Systems" class="headerlink" title="MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image   Acquisition Systems"></a>MC-NeRF: Multi-Camera Neural Radiance Fields for Multi-Camera Image   Acquisition Systems</h2><p><strong>Authors:Yu Gao, Lutong Su, Hao Liang, Yufeng Yue, Yi Yang, Mengyin Fu</strong></p>
<p>Neural Radiance Fields (NeRF) use multi-view images for 3D scene representation, demonstrating remarkable performance. As one of the primary sources of multi-view images, multi-camera systems encounter challenges such as varying intrinsic parameters and frequent pose changes. Most previous NeRF-based methods assume a unique camera and rarely consider multi-camera scenarios. Besides, some NeRF methods that can optimize intrinsic and extrinsic parameters still remain susceptible to suboptimal solutions when these parameters are poor initialized. In this paper, we propose MC-NeRF, a method that enables joint optimization of both intrinsic and extrinsic parameters alongside NeRF. The method also supports each image corresponding to independent camera parameters. First, we tackle coupling issue and the degenerate case that arise from the joint optimization between intrinsic and extrinsic parameters. Second, based on the proposed solutions, we introduce an efficient calibration image acquisition scheme for multi-camera systems, including the design of calibration object. Finally, we present an end-to-end network with training sequence that enables the estimation of intrinsic and extrinsic parameters, along with the rendering network. Furthermore, recognizing that most existing datasets are designed for a unique camera, we construct a real multi-camera image acquisition system and create a corresponding new dataset, which includes both simulated data and real-world captured images. Experiments confirm the effectiveness of our method when each image corresponds to different camera parameters. Specifically, we use multi-cameras, each with different intrinsic and extrinsic parameters in real-world system, to achieve 3D scene representation without providing initial poses. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åˆ©ç”¨å¤šè§†è§’å›¾åƒè¿›è¡Œä¸‰ç»´åœºæ™¯è¡¨ç¤ºï¼Œå¹¶è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä½œä¸ºå¤šè§†è§’å›¾åƒçš„ä¸»è¦æ¥æºä¹‹ä¸€ï¼Œå¤šç›¸æœºç³»ç»Ÿé¢ä¸´ç€è¯¸å¦‚å†…åœ¨å‚æ•°å˜åŒ–ä»¥åŠå§¿æ€å˜åŒ–é¢‘ç¹ç­‰æŒ‘æˆ˜ã€‚å¤§å¤šæ•°åŸºäºNeRFçš„æ–¹æ³•éƒ½å‡è®¾æœ‰ä¸€ä¸ªç‹¬ç‰¹çš„ç›¸æœºï¼Œå¾ˆå°‘è€ƒè™‘å¤šç›¸æœºåœºæ™¯ã€‚æ­¤å¤–ï¼Œæœ‰äº›NeRFæ–¹æ³•å¯ä»¥ä¼˜åŒ–å†…åœ¨å’Œå¤–åœ¨å‚æ•°ï¼Œä½†å½“è¿™äº›å‚æ•°åˆå§‹åŒ–ä¸ä½³æ—¶ï¼Œä»ç„¶å®¹æ˜“é™·å…¥æ¬¡ä¼˜è§£ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MC-NeRFæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶ä¼˜åŒ–å†…åœ¨å’Œå¤–åœ¨å‚æ•°ï¼Œå¹¶ä¸NeRFç›¸ç»“åˆã€‚è¯¥æ–¹æ³•è¿˜æ”¯æŒæ¯å¼ å›¾åƒå¯¹åº”ç‹¬ç«‹çš„ç›¸æœºå‚æ•°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è§£å†³äº†ç”±å†…åœ¨å’Œå¤–åœ¨å‚æ•°çš„è”åˆä¼˜åŒ–äº§ç”Ÿçš„è€¦åˆé—®é¢˜å’Œé€€åŒ–æƒ…å†µã€‚å…¶æ¬¡ï¼ŒåŸºäºè¿™äº›è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬ä¸ºå¤šç›¸æœºç³»ç»Ÿå¼•å…¥äº†æœ‰æ•ˆçš„æ ¡å‡†å›¾åƒé‡‡é›†æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ ¡å‡†å¯¹è±¡çš„è®¾è®¡ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç½‘ç»œè®­ç»ƒåºåˆ—ï¼Œè¯¥åºåˆ—èƒ½å¤Ÿä¼°è®¡å†…åœ¨å’Œå¤–åœ¨å‚æ•°ï¼Œä»¥åŠæ¸²æŸ“ç½‘ç»œã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°å¤§å¤šæ•°ç°æœ‰æ•°æ®é›†éƒ½æ˜¯ä¸ºå•ä¸€ç›¸æœºè®¾è®¡çš„ï¼Œå› æ­¤æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªçœŸæ­£çš„å¤šç›¸æœºå›¾åƒé‡‡é›†ç³»ç»Ÿï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªç›¸åº”çš„æ–°æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬æ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•è·çš„å›¾åƒã€‚å®éªŒè¯å®ï¼Œå½“æ¯å¼ å›¾åƒå¯¹åº”ä¸åŒçš„ç›¸æœºå‚æ•°æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•éå¸¸æœ‰æ•ˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨å…·æœ‰ä¸åŒå†…åœ¨å’Œå¤–åœ¨å‚æ•°çš„å¤šç›¸æœºçœŸå®ç³»ç»Ÿï¼Œæ— éœ€æä¾›åˆå§‹å§¿æ€å³å¯å®ç°ä¸‰ç»´åœºæ™¯è¡¨ç¤ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07846v4">PDF</a> This manuscript is currently under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†MC-NeRFæ–¹æ³•ï¼Œå®ç°äº†å¯¹NeRFä¸­çš„å†…åœ¨å‚æ•°å’Œå¤–åœ¨å‚æ•°çš„è”åˆä¼˜åŒ–æ”¯æŒï¼Œæ¯ä¸€å¼ å›¾åƒéƒ½æœ‰ç‹¬ç«‹çš„ç›¸æœºå‚æ•°ã€‚é€šè¿‡è§£å†³å†…åœ¨å’Œå¤–åœ¨å‚æ•°è”åˆä¼˜åŒ–å¸¦æ¥çš„è€¦åˆé—®é¢˜å’Œé€€åŒ–æƒ…å†µï¼Œå¼•å…¥äº†é«˜æ•ˆçš„å¤šç›¸æœºç³»ç»Ÿæ ¡å‡†å›¾åƒé‡‡é›†æ–¹æ¡ˆã€‚åŒæ—¶ï¼Œæ„å»ºäº†ä¸€ä¸ªçœŸå®çš„å¤šç›¸æœºå›¾åƒé‡‡é›†ç³»ç»Ÿå¹¶åˆ›å»ºäº†å¯¹åº”çš„æ–°æ•°æ®é›†ï¼Œå®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MC-NeRFæ–¹æ³•å®ç°äº†å¯¹NeRFçš„å†…åœ¨å‚æ•°å’Œå¤–åœ¨å‚æ•°çš„è”åˆä¼˜åŒ–ï¼Œä½¿å¾—æ¯ä¸€å¼ å›¾åƒéƒ½å¯ä»¥æœ‰ç‹¬ç«‹çš„ç›¸æœºå‚æ•°ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†åœ¨è”åˆä¼˜åŒ–å†…åœ¨å’Œå¤–åœ¨å‚æ•°æ—¶å‡ºç°çš„è€¦åˆé—®é¢˜å’Œé€€åŒ–æƒ…å†µã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§é«˜æ•ˆçš„å¤šç›¸æœºç³»ç»Ÿæ ¡å‡†å›¾åƒé‡‡é›†æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ ¡å‡†å¯¹è±¡çš„è®¾è®¡ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªçœŸå®çš„å¤šç›¸æœºå›¾åƒé‡‡é›†ç³»ç»Ÿå¹¶åˆ›å»ºäº†å¯¹åº”çš„æ–°æ•°æ®é›†ï¼ŒåŒ…å«æ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•è·çš„å›¾åƒã€‚</li>
<li>å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨çœŸå®ä¸–ç•Œç³»ç»Ÿä¸­ä½¿ç”¨å¤šç›¸æœºï¼Œæ¯ä¸ªç›¸æœºå…·æœ‰ä¸åŒçš„å†…åœ¨å’Œå¤–åœ¨å‚æ•°ï¼Œå®ç°3Dåœºæ™¯è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸æä¾›åˆå§‹å§¿æ€çš„æƒ…å†µä¸‹å®ç°3Dåœºæ™¯è¡¨ç¤ºã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-101df8512aee8de8d27c2059897a721f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c79cf2eacdceafe52fb024a2637ea6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-835ea170edfc01ed5516e9fe57f34cd0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-688c42b03634426b1c3218e979797176.jpg" align="middle">
</details>




<h2 id="ChromaDistill-Colorizing-Monochrome-Radiance-Fields-with-Knowledge-Distillation"><a href="#ChromaDistill-Colorizing-Monochrome-Radiance-Fields-with-Knowledge-Distillation" class="headerlink" title="ChromaDistill: Colorizing Monochrome Radiance Fields with Knowledge   Distillation"></a>ChromaDistill: Colorizing Monochrome Radiance Fields with Knowledge   Distillation</h2><p><strong>Authors:Ankit Dhiman, R Srinath, Srinjay Sarkar, Lokesh R Boregowda, R Venkatesh Babu</strong></p>
<p>Colorization is a well-explored problem in the domains of image and video processing. However, extending colorization to 3D scenes presents significant challenges. Recent Neural Radiance Field (NeRF) and Gaussian-Splatting(3DGS) methods enable high-quality novel-view synthesis for multi-view images. However, the question arises: How can we colorize these 3D representations? This work presents a method for synthesizing colorized novel views from input grayscale multi-view images. Using image or video colorization methods to colorize novel views from these 3D representations naively will yield output with severe inconsistencies. We introduce a novel method to use powerful image colorization models for colorizing 3D representations. We propose a distillation-based method that transfers color from these networks trained on natural images to the target 3D representation. Notably, this strategy does not add any additional weights or computational overhead to the original representation during inference. Extensive experiments demonstrate that our method produces high-quality colorized views for indoor and outdoor scenes, showcasing significant cross-view consistency advantages over baseline approaches. Our method is agnostic to the underlying 3D representation and easily generalizable to NeRF and 3DGS methods. Further, we validate the efficacy of our approach in several diverse applications: 1.) Infra-Red (IR) multi-view images and 2.) Legacy grayscale multi-view image sequences. Project Webpage: <a target="_blank" rel="noopener" href="https://val.cds.iisc.ac.in/chroma-distill.github.io/">https://val.cds.iisc.ac.in/chroma-distill.github.io/</a> </p>
<blockquote>
<p>ç€è‰²æ˜¯å›¾åƒå’Œè§†é¢‘å¤„ç†é¢†åŸŸå·²ç»å¾—åˆ°å¾ˆå¥½ç ”ç©¶çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå°†ç€è‰²æŠ€æœ¯æ‰©å±•åˆ°ä¸‰ç»´åœºæ™¯é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯æ¨¡æ¿ï¼ˆGaussian Splattingï¼Œç®€ç§°3DGSï¼‰æ–¹æ³•èƒ½å¤Ÿå®ç°é«˜è´¨é‡çš„å¤šè§†è§’å›¾åƒæ–°è§†è§’åˆæˆã€‚ä½†é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•å¯¹è¿™äº›ä¸‰ç»´è¡¨ç¤ºè¿›è¡Œç€è‰²ï¼Ÿè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§ä»è¾“å…¥ç°åº¦å¤šè§†è§’å›¾åƒåˆæˆå½©è‰²æ–°è§†è§’çš„æ–¹æ³•ã€‚ä½¿ç”¨å›¾åƒæˆ–è§†é¢‘ç€è‰²æ–¹æ³•æ¥ç›´è§‚åœ°å¯¹ç€è¿™äº›ä¸‰ç»´è¡¨ç¤ºçš„æ–°è§†è§’è¿›è¡Œç€è‰²ä¼šå¯¼è‡´è¾“å‡ºå…·æœ‰ä¸¥é‡çš„è‰²å·®ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä½¿ç”¨å¼ºå¤§çš„å›¾åƒç€è‰²æ¨¡å‹ä¸ºä¸‰ç»´è¡¨ç¤ºç€è‰²çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè’¸é¦çš„æ–¹æ³•ï¼Œå°†è‡ªç„¶å›¾åƒè®­ç»ƒçš„ç½‘ç»œä¸­çš„é¢œè‰²è½¬ç§»åˆ°ç›®æ ‡ä¸‰ç»´è¡¨ç¤ºä¸Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™ç§ç­–ç•¥åœ¨æ¨ç†æœŸé—´ä¸ä¼šç»™åŸå§‹è¡¨ç¤ºå¢åŠ ä»»ä½•é¢å¤–çš„æƒé‡æˆ–è®¡ç®—å¼€é”€ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºå®¤å†…å’Œå®¤å¤–åœºæ™¯ç”Ÿæˆäº†é«˜è´¨é‡å½©è‰²è§†å›¾ï¼Œç›¸è¾ƒäºåŸºå‡†æ–¹æ³•å±•ç°å‡ºæ˜¾è‘—çš„è·¨è§†å›¾ä¸€è‡´æ€§ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯¹äºåº•å±‚çš„ä¸‰ç»´è¡¨ç¤ºæŒä¸­ç«‹æ€åº¦ï¼Œå¹¶æ˜“äºæ¨å¹¿åˆ°NeRFå’Œ3DGSæ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å‡ ä¸ªä¸åŒçš„åº”ç”¨éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼šåŒ…æ‹¬çº¢å¤–ï¼ˆIRï¼‰å¤šè§†è§’å›¾åƒå’Œé—ç•™ç°åº¦å¤šè§†è§’å›¾åƒåºåˆ—çš„åº”ç”¨åœºæ™¯ã€‚é¡¹ç›®ç½‘é¡µé“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://val.cds.iisc.ac.in/chroma-distill.github.io/%EF%BC%88%E4%B8%AD%E6%96%87%E5%AE%98%E7%BD%91%E9%93%BE%E6%8E%A5%E5%8F%AF%E8%83%BD%E6%97%A0%E6%B3%95%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%EF%BC%8C%E8%AF%B7%E5%B0%9D%E8%AF%95%E5%85%B6%E4%BB%96%E9%80%94%E5%BE%84%E8%8E%B7%E5%8F%96%E6%9B%B4%E5%A4%9A%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF%E3%80%82%EF%BC%89">https://val.cds.iisc.ac.in/chroma-distill.github.io/ï¼ˆä¸­æ–‡å®˜ç½‘é“¾æ¥å¯èƒ½æ— æ³•ç›´æ¥æ‰“å¼€ï¼Œè¯·å°è¯•å…¶ä»–é€”å¾„è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚ï¼‰</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07668v2">PDF</a> WACV 2025, AI3DCC @ ICCV 2023</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å°†é¢œè‰²åŒ–æŠ€æœ¯åº”ç”¨äºä¸‰ç»´åœºæ™¯çš„é—®é¢˜ã€‚å°½ç®¡Neural Radiance Fieldï¼ˆNeRFï¼‰å’ŒGaussian-Splattingï¼ˆ3DGSï¼‰ç­‰æ–¹æ³•èƒ½å¤Ÿå®ç°å¤šè§†è§’å›¾åƒçš„é«˜è´¨é‡æ–°å‹è§†å›¾åˆæˆï¼Œä½†å¦‚ä½•åœ¨è¿™äº›ä¸‰ç»´è¡¨ç¤ºä¸­è¿›è¡Œé¢œè‰²åŒ–ä»æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä»è¾“å…¥ç°åº¦å¤šè§†è§’å›¾åƒåˆæˆå½©è‰²æ–°å‹è§†å›¾çš„æ–¹æ³•ã€‚ç›´æ¥ä½¿ç”¨å›¾åƒæˆ–è§†é¢‘é¢œè‰²åŒ–æ–¹æ³•å¯¹ä¸‰ç»´è¡¨ç¤ºè¿›è¡Œé¢œè‰²åŒ–ä¼šå¯¼è‡´è¾“å‡ºå­˜åœ¨ä¸¥é‡çš„ä¸ä¸€è‡´æ€§ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºè’¸é¦çš„æ–¹æ³•ï¼Œå°†ä»è‡ªç„¶å›¾åƒè®­ç»ƒçš„å›¾åƒé¢œè‰²åŒ–æ¨¡å‹ä¸­çš„é¢œè‰²è½¬ç§»åˆ°ç›®æ ‡ä¸‰ç»´è¡¨ç¤ºä¸­ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ­¤ç­–ç•¥ä¸ä¼šç»™åŸå§‹è¡¨ç¤ºå¢åŠ ä»»ä½•é¢å¤–çš„æƒé‡æˆ–è®¡ç®—å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯çš„é¢œè‰²åŒ–è§†å›¾ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸åŸºå‡†æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—çš„è·¨è§†å›¾ä¸€è‡´æ€§ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•å¯¹åº•å±‚ä¸‰ç»´è¡¨ç¤ºå…·æœ‰é€šç”¨æ€§ï¼Œå¯è½»æ¾æ¨å¹¿åˆ°NeRFå’Œ3DGSæ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨çº¢å¤–å¤šè§†è§’å›¾åƒå’Œé—ç•™ç°åº¦å¤šè§†è§’å›¾åƒåºåˆ—ç­‰å¤šæ ·åŒ–åº”ç”¨ä¸­éªŒè¯äº†å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡è§£å†³äº†åœ¨ä¸‰ç»´åœºæ™¯ä¸­é¢œè‰²åŒ–çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹Neural Radiance Fieldï¼ˆNeRFï¼‰å’ŒGaussian-Splattingï¼ˆ3DGSï¼‰æ–¹æ³•ç”Ÿæˆçš„ä¸‰ç»´è¡¨ç¤ºã€‚</li>
<li>ç›´æ¥ä½¿ç”¨å›¾åƒæˆ–è§†é¢‘é¢œè‰²åŒ–æ–¹æ³•å¯¹ä¸‰ç»´è¡¨ç¤ºè¿›è¡Œé¢œè‰²åŒ–ä¼šå¯¼è‡´è¾“å‡ºå­˜åœ¨ä¸¥é‡çš„ä¸ä¸€è‡´æ€§ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè’¸é¦çš„æ–¹æ³•ï¼Œå°†ä»è‡ªç„¶å›¾åƒè®­ç»ƒçš„é¢œè‰²åŒ–æ¨¡å‹ä¸­çš„é¢œè‰²è½¬ç§»åˆ°ç›®æ ‡ä¸‰ç»´è¡¨ç¤ºä¸­ï¼Œæé«˜äº†é¢œè‰²åŒ–è´¨é‡å¹¶ä¿æŒäº†è·¨è§†å›¾çš„ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯çš„é¢œè‰²åŒ–è§†å›¾ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸æ¯”åŸºå‡†æ–¹æ³•å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
<li>æ–¹æ³•å¯¹åº•å±‚ä¸‰ç»´è¡¨ç¤ºå…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚ç”¨äºå¤šç§ä¸‰ç»´è¡¨ç¤ºæ–¹æ³•ï¼ŒåŒ…æ‹¬NeRFå’Œ3DGSã€‚</li>
<li>ç ”ç©¶åœ¨å¤šç§åº”ç”¨ä¸­éªŒè¯äº†å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬çº¢å¤–å¤šè§†è§’å›¾åƒå’Œé—ç•™ç°åº¦å¤šè§†è§’å›¾åƒåºåˆ—ç­‰ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f55c89070e6b20b7fa1fb91b960a64d1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-68a542cf75dab4c514d896440e5f6784.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0fee3ef8eb02763ac0e262c36d2324bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d53fe9bb1b08659516504f156fc15c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-994a03b85c48a19dcb7fa3c8c745338a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-84c6da1255580971a1b76ca9b966593b.jpg" align="middle">
</details>




<h2 id="Diverse-Similarity-Encoder-for-Deep-GAN-Inversion"><a href="#Diverse-Similarity-Encoder-for-Deep-GAN-Inversion" class="headerlink" title="Diverse Similarity Encoder for Deep GAN Inversion"></a>Diverse Similarity Encoder for Deep GAN Inversion</h2><p><strong>Authors:Cheng Yu, Wenmin Wang, Roberto Bugiolacchi</strong></p>
<p>Current deep generative adversarial networks (GANs) can synthesize high-quality (HQ) images, so learning representation with GANs is favorable. GAN inversion is one of emerging approaches that study how to invert images into latent space. Existing GAN encoders can invert images on StyleGAN, but cannot adapt to other deep GANs. We propose a novel approach to address this issue. By evaluating diverse similarity in latent vectors and images, we design an adaptive encoder, named diverse similarity encoder (DSE), that can be expanded to a variety of state-of-the-art GANs. DSE makes GANs reconstruct higher fidelity images from HQ images, no matter whether they are synthesized or real images. DSE has unified convolutional blocks and adapts well to mainstream deep GANs, e.g., PGGAN, StyleGAN, and BigGAN. </p>
<blockquote>
<p>å½“å‰æ·±åº¦ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰èƒ½å¤Ÿåˆæˆé«˜è´¨é‡ï¼ˆHQï¼‰å›¾åƒï¼Œå› æ­¤ä½¿ç”¨GANså­¦ä¹ è¡¨ç¤ºæ˜¯æœ‰åˆ©çš„ã€‚GANåæ¼”æ˜¯æ–°å…´æ–¹æ³•ä¹‹ä¸€ï¼Œç ”ç©¶å¦‚ä½•å°†å›¾åƒåæ¼”åˆ°æ½œåœ¨ç©ºé—´ã€‚ç°æœ‰çš„GANç¼–ç å™¨å¯ä»¥åœ¨StyleGANä¸Šåæ¼”å›¾åƒï¼Œä½†ä¸èƒ½é€‚åº”å…¶ä»–æ·±åº¦GANã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è§£å†³æ­¤é—®é¢˜çš„æ–°æ–¹æ³•ã€‚é€šè¿‡è¯„ä¼°æ½œåœ¨å‘é‡å’Œå›¾åƒä¸­çš„å¤šç§ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è‡ªé€‚åº”ç¼–ç å™¨ï¼Œåä¸ºå¤šæ ·åŒ–ç›¸ä¼¼æ€§ç¼–ç å™¨ï¼ˆDSEï¼‰ï¼Œå¯ä»¥æ‰©å±•åˆ°å¤šç§æœ€æ–°GANæŠ€æœ¯ã€‚DSEæ— è®ºå›¾åƒæ˜¯åˆæˆè¿˜æ˜¯çœŸå®å›¾åƒï¼Œéƒ½èƒ½ä½¿GANä»é«˜è´¨é‡å›¾åƒä¸­é‡å»ºæ›´é«˜ä¿çœŸåº¦çš„å›¾åƒã€‚DSEå…·æœ‰ç»Ÿä¸€çš„å·ç§¯å—ï¼Œèƒ½å¾ˆå¥½åœ°é€‚åº”ä¸»æµæ·±åº¦GANï¼Œä¾‹å¦‚PGGANã€StyleGANå’ŒBigGANã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2108.10201v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºDSEï¼ˆå¤šæ ·ç›¸ä¼¼æ€§ç¼–ç å™¨ï¼‰çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰GANç¼–ç å™¨ä¸èƒ½é€‚åº”å¤šç§å…ˆè¿›çš„GANsçš„é—®é¢˜ã€‚DSEé€šè¿‡è¯„ä¼°æ½œåœ¨å‘é‡å’Œå›¾åƒä¹‹é—´çš„å¤šæ ·ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿæ‰©å±•åˆ°å„ç§æœ€å…ˆè¿›çš„GANsã€‚DSEæé«˜äº†GANsä»é«˜è´¨é‡å›¾åƒï¼ˆæ— è®ºæ˜¯åˆæˆè¿˜æ˜¯çœŸå®å›¾åƒï¼‰é‡å»ºé«˜ä¿çœŸå›¾åƒçš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æ·±åº¦ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å¯ä»¥åˆæˆé«˜è´¨é‡å›¾åƒï¼Œä½¿ç”¨GANså­¦ä¹ è¡¨ç¤ºå—åˆ°é’çã€‚</li>
<li>GANåæ¼”æ˜¯æ–°å…´æ–¹æ³•ä¹‹ä¸€ï¼Œç ”ç©¶å¦‚ä½•å°†å›¾åƒåæ¼”åˆ°æ½œåœ¨ç©ºé—´ã€‚</li>
<li>ç°æœ‰GANç¼–ç å™¨å¯ä»¥åœ¨StyleGANä¸Šè¿›è¡Œå›¾åƒåæ¼”ï¼Œä½†ä¸èƒ½é€‚åº”å…¶ä»–æ·±åº¦GANsã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”å¤šæ ·ç›¸ä¼¼æ€§ç¼–ç å™¨ï¼ˆDSEï¼‰ï¼Œå¯ä»¥è§£å†³æ­¤é—®é¢˜ã€‚</li>
<li>DSEé€šè¿‡è¯„ä¼°æ½œåœ¨å‘é‡å’Œå›¾åƒä¹‹é—´çš„å¤šæ ·ç›¸ä¼¼æ€§è¿›è¡Œè®¾è®¡ã€‚</li>
<li>DSEå¯ä»¥æ‰©å±•åˆ°å„ç§æœ€å…ˆè¿›çš„GANsï¼Œå¦‚PGGANã€StyleGANå’ŒBigGANã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2c0940fc7f9e47f7ef709ff59469c9b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26229e3100c8c64811dfe13fae729ff8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96c2092a822b7eb9c5a94f13ea3f45e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-991864f280fa90ecd2fc3e0b5b8d9de9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-849a0bfe560207f45ea80d5eb85b9501.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-12/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-12/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-12/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a5ffa6182763bc6e4bde526a15db0e11.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-12  Enhancing 3D Object Detection in Autonomous Vehicles Based on Synthetic   Virtual Environment Analysis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-12/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cb832b722defb2458c803f27c3a4903a.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-12  SLGaussian Fast Language Gaussian Splatting in Sparse Views
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">7975.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
