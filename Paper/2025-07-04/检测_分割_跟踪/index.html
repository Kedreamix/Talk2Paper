<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="检测/分割/跟踪">
    <meta name="description" content="检测/分割/跟踪 方向最新论文已更新，请持续关注 Update in 2025-07-04  A Gift from the Integration of Discriminative and Diffusion-based   Generative Learning Boundary Refinement Remote Sensing Semantic Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>检测/分割/跟踪 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-dd30b6d037260d00604c6b308e77b738.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">检测/分割/跟踪</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">检测/分割/跟踪</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                检测/分割/跟踪
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-04-更新"><a href="#2025-07-04-更新" class="headerlink" title="2025-07-04 更新"></a>2025-07-04 更新</h1><h2 id="A-Gift-from-the-Integration-of-Discriminative-and-Diffusion-based-Generative-Learning-Boundary-Refinement-Remote-Sensing-Semantic-Segmentation"><a href="#A-Gift-from-the-Integration-of-Discriminative-and-Diffusion-based-Generative-Learning-Boundary-Refinement-Remote-Sensing-Semantic-Segmentation" class="headerlink" title="A Gift from the Integration of Discriminative and Diffusion-based   Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation"></a>A Gift from the Integration of Discriminative and Diffusion-based   Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation</h2><p><strong>Authors:Hao Wang, Keyan Hu, Xin Guo, Haifeng Li, Chao Tao</strong></p>
<p>Remote sensing semantic segmentation must address both what the ground objects are within an image and where they are located. Consequently, segmentation models must ensure not only the semantic correctness of large-scale patches (low-frequency information) but also the precise localization of boundaries between patches (high-frequency information). However, most existing approaches rely heavily on discriminative learning, which excels at capturing low-frequency features, while overlooking its inherent limitations in learning high-frequency features for semantic segmentation. Recent studies have revealed that diffusion generative models excel at generating high-frequency details. Our theoretical analysis confirms that the diffusion denoising process significantly enhances the model’s ability to learn high-frequency features; however, we also observe that these models exhibit insufficient semantic inference for low-frequency features when guided solely by the original image. Therefore, we integrate the strengths of both discriminative and generative learning, proposing the Integration of Discriminative and diffusion-based Generative learning for Boundary Refinement (IDGBR) framework. The framework first generates a coarse segmentation map using a discriminative backbone model. This map and the original image are fed into a conditioning guidance network to jointly learn a guidance representation subsequently leveraged by an iterative denoising diffusion process refining the coarse segmentation. Extensive experiments across five remote sensing semantic segmentation datasets (binary and multi-class segmentation) confirm our framework’s capability of consistent boundary refinement for coarse results from diverse discriminative architectures. The source code will be available at <a target="_blank" rel="noopener" href="https://github.com/KeyanHu-git/IDGBR">https://github.com/KeyanHu-git/IDGBR</a>. </p>
<blockquote>
<p>遥感语义分割必须解决图像内地面对象是什么以及它们位置的问题。因此，分割模型必须确保大规模斑块（低频信息）的语义正确性，同时还要确保斑块之间边界的精确定位（高频信息）。然而，大多数现有方法都严重依赖于判别学习，这种方法在捕获低频特征方面非常出色，但却忽视了在学习语义分割高频特征方面的固有局限性。最近的研究表明，扩散生成模型在生成高频细节方面表现出色。我们的理论分析证实，扩散去噪过程显著增强了模型学习高频特征的能力；然而，我们也观察到，当仅由原始图像引导时，这些模型对低频特征的语义推断不足。因此，我们结合了判别学习和生成学习的优点，提出了融合判别和基于扩散的生成学习以进行边界细化（IDGBR）的框架。该框架首先使用判别骨干模型生成一个粗略的分割图。然后，将这个图与原始图像一起输入条件引导网络，共同学习一个引导表示，随后由迭代去噪扩散过程利用该表示来细化粗略的分割。在五个遥感语义分割数据集（二进制和多类分割）上进行的广泛实验证实，我们的框架能够对来自各种判别架构的粗略结果进行一致的边界细化。源代码将发布在<a target="_blank" rel="noopener" href="https://github.com/KeyanHu-git/IDGBR%E3%80%82">https://github.com/KeyanHu-git/IDGBR。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01573v1">PDF</a> 20 pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>本文探讨了遥感语义分割中面临的问题，包括既要识别地面物体的种类，又要确定其位置。现有的分割模型大多侧重于低频信息的语义正确性，而忽视了高频信息的精确边界定位。为此，本文结合了判别学习和扩散生成模型的优势，提出了IDGBR框架。该框架首先使用判别骨干模型生成粗略分割图，然后与原始图像一起输入条件引导网络，共同学习引导表示，再通过迭代去噪扩散过程对粗略分割进行细化。实验证明，该框架能够细化不同判别架构的粗略结果，提高遥感语义分割的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>遥感语义分割需同时识别地面物体的种类和位置。</li>
<li>现有模型侧重于低频信息的语义正确性，忽视了高频信息的精确边界定位。</li>
<li>扩散生成模型擅长生成高频细节。</li>
<li>IDGBR框架结合了判别学习和扩散生成模型的优势。</li>
<li>IDGBR框架使用判别骨干模型生成粗略分割图，并通过条件引导网络和迭代去噪扩散过程进行细化。</li>
<li>在五个遥感语义分割数据集上的实验证明了IDGBR框架的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01573">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8377299b4634e48e147903b7dcd578bc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5ec9bc7076dee12d8eeb4d09ab9641f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0371b78ecb782fe47514cda3d9dac020.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec7cb7c48b21fee293ea9eb4d69a4a03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6456d211ab1e87805d6d7e55224ac246.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="TrackingMiM-Efficient-Mamba-in-Mamba-Serialization-for-Real-time-UAV-Object-Tracking"><a href="#TrackingMiM-Efficient-Mamba-in-Mamba-Serialization-for-Real-time-UAV-Object-Tracking" class="headerlink" title="TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV   Object Tracking"></a>TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV   Object Tracking</h2><p><strong>Authors:Bingxi Liu, Calvin Chen, Junhao Li, Guyang Yu, Haoqian Song, Xuchen Liu, Jinqiang Cui, Hong Zhang</strong></p>
<p>The Vision Transformer (ViT) model has long struggled with the challenge of quadratic complexity, a limitation that becomes especially critical in unmanned aerial vehicle (UAV) tracking systems, where data must be processed in real time. In this study, we explore the recently proposed State-Space Model, Mamba, leveraging its computational efficiency and capability for long-sequence modeling to effectively process dense image sequences in tracking tasks. First, we highlight the issue of temporal inconsistency in existing Mamba-based methods, specifically the failure to account for temporal continuity in the Mamba scanning mechanism. Secondly, building upon this insight,we propose TrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model for handling image sequence of tracking problem. In our framework, the mamba scan is performed in a nested way while independently process temporal and spatial coherent patch tokens. While the template frame is encoded as query token and utilized for tracking in every scan. Extensive experiments conducted on five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves state-of-the-art precision while offering noticeable higher speed in UAV tracking. </p>
<blockquote>
<p>Vision Transformer（ViT）模型长期以来一直面临着二次复杂度的挑战，这一限制在无人飞行器（UAV）跟踪系统中尤其关键，因为这些系统中的数据必须实时处理。在这项研究中，我们探索了最近提出的State-Space Model（Mamba），利用它的计算效率和长序列建模能力，以有效处理跟踪任务中的密集图像序列。首先，我们强调了基于Mamba的方法中存在的时间不一致性问题，特别是Mamba扫描机制未能考虑时间连续性。其次，基于这一认识，我们提出了TrackingMiM，这是一个Mamba-in-Mamba架构，是一个用于处理跟踪问题图像序列的低计算负担模型。在我们的框架中，mamba扫描以嵌套的方式进行，同时独立处理时间和空间连贯的补丁令牌。模板帧被编码为查询令牌，并在每次扫描中用于跟踪。在五个UAV跟踪基准测试上进行的广泛实验证实，所提出的TrackingMiM实现了最先进的精度，同时在UAV跟踪中提供了明显的更高速度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01535v1">PDF</a> 12 pages</p>
<p><strong>Summary</strong></p>
<p>ViT模型在处理跟踪任务时面临二次复杂性挑战，尤其在无人机跟踪系统中。研究探讨了新近提出的Mamba状态空间模型，发现其计算效率高、适合处理长序列数据。但现有Mamba方法存在时间不一致性问题，未能充分考虑时间连续性。因此，研究提出了TrackingMiM模型，利用Mamba-in-Mamba架构处理跟踪问题的图像序列，实现了高效且高精度的无人机跟踪。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Vision Transformer (ViT)模型在处理跟踪任务时面临二次复杂性挑战。</li>
<li>Mamba状态空间模型具有计算效率高、适合处理长序列数据的优点。</li>
<li>现有Mamba方法存在时间不一致性问题，未能充分考虑时间连续性。</li>
<li>TrackingMiM模型利用Mamba-in-Mamba架构处理跟踪问题的图像序列。</li>
<li>TrackingMiM模型实现了高效且高精度的无人机跟踪。</li>
<li>TrackingMiM模型在五个无人机跟踪基准测试上达到了最先进的精度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01535">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-82de78257fa2fb913a03c5199a1290ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd30b6d037260d00604c6b308e77b738.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Active-Control-Points-based-6DoF-Pose-Tracking-for-Industrial-Metal-Objects"><a href="#Active-Control-Points-based-6DoF-Pose-Tracking-for-Industrial-Metal-Objects" class="headerlink" title="Active Control Points-based 6DoF Pose Tracking for Industrial Metal   Objects"></a>Active Control Points-based 6DoF Pose Tracking for Industrial Metal   Objects</h2><p><strong>Authors:Chentao Shen, Ding Pan, Mingyu Mei, Zaixing He, Xinyue Zhao</strong></p>
<p>Visual pose tracking is playing an increasingly vital role in industrial contexts in recent years. However, the pose tracking for industrial metal objects remains a challenging task especially in the real world-environments, due to the reflection characteristic of metal objects. To address this issue, we propose a novel 6DoF pose tracking method based on active control points. The method uses image control points to generate edge feature for optimization actively instead of 6DoF pose-based rendering, and serve them as optimization variables. We also introduce an optimal control point regression method to improve robustness. The proposed tracking method performs effectively in both dataset evaluation and real world tasks, providing a viable solution for real-time tracking of industrial metal objects. Our source code is made publicly available at: <a target="_blank" rel="noopener" href="https://github.com/tomatoma00/ACPTracking">https://github.com/tomatoma00/ACPTracking</a>. </p>
<blockquote>
<p>近年来，视觉姿态跟踪在工业领域的应用越来越重要。然而，对于工业金属物体的姿态跟踪，在真实世界环境下仍然是一项具有挑战性的任务，尤其是由于金属物体的反射特性。为了解决这一问题，我们提出了一种基于主动控制点的新型6DoF姿态跟踪方法。该方法使用图像控制点来主动生成边缘特征进行优化，而不是基于6DoF姿态的渲染，并将其作为优化变量。我们还引入了一种最优控制点回归方法，以提高其稳健性。所提出的跟踪方法在数据集评估和真实世界任务中都表现有效，为工业金属物体的实时跟踪提供了可行的解决方案。我们的源代码已公开在：<a target="_blank" rel="noopener" href="https://github.com/tomatoma00/ACPTracking%E3%80%82">https://github.com/tomatoma00/ACPTracking。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01478v1">PDF</a> preprint version</p>
<p><strong>Summary</strong></p>
<p>视觉姿态跟踪近年来在工业领域的作用越来越重要。然而，对于工业金属物体的姿态跟踪，尤其是在真实世界环境中，由于金属物体的反射特性，仍是一项具有挑战性的任务。为此，我们提出了一种基于主动控制点的新型6DoF姿态跟踪方法。该方法使用图像控制点来主动生成边缘特征进行优化，而不是基于6DoF姿态的渲染，并将其作为优化变量。我们还引入了一种优化控制点回归方法，以提高稳健性。所提出的方法在数据集评估和真实世界任务中都表现有效，为工业金属物体的实时跟踪提供了可行的解决方案。源代码已公开发布在：<a target="_blank" rel="noopener" href="https://github.com/tomatoma00/ACPTracking%E3%80%82">https://github.com/tomatoma00/ACPTracking。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视觉姿态跟踪在工业领域的重要性日益凸显。</li>
<li>工业金属物体的姿态跟踪在真实世界环境中具有挑战性，主要因为金属物体的反射特性。</li>
<li>提出了一种基于主动控制点的新型6DoF姿态跟踪方法。</li>
<li>该方法通过图像控制点生成边缘特征并进行优化。</li>
<li>所提出的方法不仅适用于数据集评估，也在真实世界任务中表现良好。</li>
<li>引入优化控制点回归方法以提高稳健性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01478">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5e92a0e210aa57e432cf3502d66e726f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-34e3c9af90fcc33da37e72940873c00d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b5061780024159bec60c85c0935bac37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d42e6e4cb76dd4e6e58cd90f37e4b9a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce5eb251ab7c7da24759c96e802c11da.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="NOCTIS-Novel-Object-Cyclic-Threshold-based-Instance-Segmentation"><a href="#NOCTIS-Novel-Object-Cyclic-Threshold-based-Instance-Segmentation" class="headerlink" title="NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation"></a>NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation</h2><p><strong>Authors:Max Gandyra, Alessandro Santonicola, Michael Beetz</strong></p>
<p>Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed, for all kinds of novel objects, without (re-) training, has proven to be a difficult task. To handle this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). This work stems from and improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also leverages on recent vision foundation models, namely: Grounded-SAM 2 and DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise bounding boxes and their corresponding segmentation masks; while DINOv2’s zero-shot capabilities are employed to generate the image embeddings. The quality of those masks, together with their embeddings, is of vital importance to our approach; as the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings. Differently to SAM-6D, calculating the latter involves a prior patch filtering based on the distance between each patch and its corresponding cyclic&#x2F;roundtrip patch in the image grid. Furthermore, the average confidence of the proposals’ bounding box and mask is used as an additional weighting factor for the object matching score. We empirically show that NOCTIS, without further training&#x2F;fine tuning, outperforms the best RGB and RGB-D methods on the seven core datasets of the BOP 2023 challenge for the “Model-based 2D segmentation of unseen objects” task. </p>
<blockquote>
<p>在RGB图像中对新型物体实例进行实例分割是一个众所周知的计算机视觉问题。给定每个物体的示例图像，设计一种足够通用的模型，能够应用于所有新型物体，而无需（重新）训练，已被证明是一项艰巨的任务。为了处理这个问题，我们提出了一种简单而强大的框架，称为：基于新型物体循环阈值的实例分割（NOCTIS）。这项工作源于并改进了先前的CNOS、SAM-6D和NIDS-Net等研究；因此，它也依赖于最近的视觉基础模型，即Grounded-SAM 2和DINOv2。它利用Grounded-SAM 2获得精确的对象提议边界框及其相应的分割掩模；而DINOv2的零样本能力则用于生成图像嵌入。这些掩模的质量以及它们的嵌入对我们的方法至关重要；因为提议对象匹配是通过确定基于类别嵌入的相似性以及与补丁嵌入的平均最大相似性的对象匹配分数来实现的。与SAM-6D不同，计算后者涉及基于每个补丁与其在图像网格中的循环&#x2F;往返补丁之间的距离的先验补丁过滤。此外，提案边界框和掩模的平均置信度被用作对象匹配分数的附加加权因子。我们通过实验证明，NOCTIS无需进一步的训练或微调，在BOP 2023挑战的七个核心数据集上，对于“未见过物体的基于模型的2D分割”任务，表现优于最佳的RGB和RGB-D方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01463v1">PDF</a> 10 pages, 3 figures, 3 tables, NeurIPS 2025 preprint</p>
<p><strong>Summary</strong></p>
<p>该文本介绍了一种处理RGB图像中新型对象实例实例分割问题的简单而强大的框架——基于循环阈值的新型对象实例分割（NOCTIS）。该框架借助了之前的模型如CNOS、SAM-6D和NIDS-Net，并借助了最近的视觉基础模型Grounded-SAM 2和DINOv2。NOCTIS利用Grounded-SAM 2获得精确的目标提案及其对应的分割掩码，并利用DINOv2的零样本能力生成图像嵌入。通过计算类别嵌入和补丁嵌入的平均最大相似性的对象匹配分数，实现提案对象匹配。与SAM-6D不同，计算后者涉及基于每个补丁与其在图像网格中的循环对应补丁之间的距离的先验补丁过滤。此外，提案边界框和掩模的平均置信度被用作对象匹配分数的附加加权因子。实证结果表明，无需进一步训练或微调，NOCTIS在BOP 2023挑战的七个核心数据集上的“基于模型的未见对象二维分割”任务中表现优于最佳RGB和RGB-D方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NOCTIS框架是一个用于处理RGB图像中新型对象实例分割的模型，可在不同类型的未见对象上应用而无需重新训练。</li>
<li>该框架利用Grounded-SAM 2模型获得精确的目标提案和对应的分割掩码。</li>
<li>DINOv2模型的零样本能力被用于生成图像嵌入，对于目标匹配至关重要。</li>
<li>NOCTIS通过计算类别嵌入和补丁嵌入的相似性来确定对象匹配分数，实现提案对象匹配。</li>
<li>与SAM-6D相比，NOCTIS在计算对象匹配分数时考虑了补丁过滤的先验信息。</li>
<li>提案的边界框和掩模的平均置信度作为对象匹配分数的附加加权因子。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01463">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d8833d1d458c35e33d52e367ed349d09.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7bdc794796a61d46e113f2b6d61f57f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87065cd837f505be1f7357c8ed547f43.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Rapid-Salient-Object-Detection-with-Difference-Convolutional-Neural-Networks"><a href="#Rapid-Salient-Object-Detection-with-Difference-Convolutional-Neural-Networks" class="headerlink" title="Rapid Salient Object Detection with Difference Convolutional Neural   Networks"></a>Rapid Salient Object Detection with Difference Convolutional Neural   Networks</h2><p><strong>Authors:Zhuo Su, Li Liu, Matthias Müller, Jiehua Zhang, Diana Wofk, Ming-Ming Cheng, Matti Pietikäinen</strong></p>
<p>This paper addresses the challenge of deploying salient object detection (SOD) on resource-constrained devices with real-time performance. While recent advances in deep neural networks have improved SOD, existing top-leading models are computationally expensive. We propose an efficient network design that combines traditional wisdom on SOD and the representation power of modern CNNs. Like biologically-inspired classical SOD methods relying on computing contrast cues to determine saliency of image regions, our model leverages Pixel Difference Convolutions (PDCs) to encode the feature contrasts. Differently, PDCs are incorporated in a CNN architecture so that the valuable contrast cues are extracted from rich feature maps. For efficiency, we introduce a difference convolution reparameterization (DCR) strategy that embeds PDCs into standard convolutions, eliminating computation and parameters at inference. Additionally, we introduce SpatioTemporal Difference Convolution (STDC) for video SOD, enhancing the standard 3D convolution with spatiotemporal contrast capture. Our models, SDNet for image SOD and STDNet for video SOD, achieve significant improvements in efficiency-accuracy trade-offs. On a Jetson Orin device, our models with $&lt;$ 1M parameters operate at 46 FPS and 150 FPS on streamed images and videos, surpassing the second-best lightweight models in our experiments by more than $2\times$ and $3\times$ in speed with superior accuracy. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/hellozhuo/stdnet.git">https://github.com/hellozhuo/stdnet.git</a>. </p>
<blockquote>
<p>本文旨在应对在资源受限设备上以实时性能执行显著性目标检测（SOD）的挑战。尽管深度神经网络领域的最新进展改进了SOD，但现有的顶尖模型计算成本高昂。我们提出了一种有效的网络设计，它将传统的SOD智慧和现代CNN的表示能力相结合。我们的模型借鉴了生物学启发的经典SOD方法，依靠计算对比线索来确定图像区域的显著性，利用像素差异卷积（PDC）对特征对比进行编码。不同之处在于，PDC被集成到CNN架构中，以便从丰富的特征图中提取有价值的对比线索。为了提高效率，我们引入了差异卷积重新参数化（DCR）策略，将PDC嵌入到标准卷积中，从而在推理过程中消除了计算和参数。此外，我们为视频SOD引入了时空差异卷积（STDC），通过时空对比捕获增强标准3D卷积。我们的模型SDNet用于图像SOD，STDNet用于视频SOD，在效率与准确性之间取得了显著改进。在Jetson Orin设备上，我们的模型使用＜1M参数在流式图像和视频上分别以46FPS和150FPS运行，在我们的实验中，其速度超过第二好的轻量级模型2倍以上，同时保持更高的准确性。代码将在<a target="_blank" rel="noopener" href="https://github.com/hellozhuo/stdnet.git%E4%B8%8A%E6%8F%9B%E4%BA%A7%E3%80%82">https://github.com/hellozhuo/stdnet.git上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.01182v1">PDF</a> 16 pages, accepted in TPAMI</p>
<p><strong>Summary</strong><br>     本文解决的是在资源受限设备上部署显著目标检测（SOD）的挑战，同时实现实时性能。文章结合传统显著目标检测的智慧和现代卷积神经网络（CNN）的表征能力，提出了有效的网络设计。模型利用像素差异卷积（PDC）编码特征对比，并通过时空差异卷积（STDC）提高视频SOD的效能。所提出的方法实现了高效率与准确性的良好平衡，可在Jetson Orin设备上实现高帧率运行。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>文章主要解决资源受限设备上的实时显著目标检测（SOD）挑战。</li>
<li>结合传统显著目标检测方法和现代卷积神经网络（CNN）的表征能力，提出高效网络设计。</li>
<li>引入像素差异卷积（PDC）编码特征对比，并将其融入CNN架构中。</li>
<li>通过差异卷积重参数化（DCR）策略提高模型效率，减少推理时的计算和参数。</li>
<li>引入时空差异卷积（STDC）以提高视频SOD性能，结合3D卷积进行时空对比捕捉。</li>
<li>提出SDNet和STDNet模型分别用于图像和视频SOD，实现了效率和准确性的良好平衡。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.01182">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9805394254ecffed0a421b99e064e9e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7b023b90c5a325370bde47fb84b900e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c631ca537009585e25077449a71ad5eb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30c63a7f365a22e1b6a9a2fb605098f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-972029ff13c32b366b162a14baf3e837.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="UPRE-Zero-Shot-Domain-Adaptation-for-Object-Detection-via-Unified-Prompt-and-Representation-Enhancement"><a href="#UPRE-Zero-Shot-Domain-Adaptation-for-Object-Detection-via-Unified-Prompt-and-Representation-Enhancement" class="headerlink" title="UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified   Prompt and Representation Enhancement"></a>UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified   Prompt and Representation Enhancement</h2><p><strong>Authors:Xiao Zhang, Fei Wei, Yong Wang, Wenda Zhao, Feiyi Li, Xiangxiang Chu</strong></p>
<p>Zero-shot domain adaptation (ZSDA) presents substantial challenges due to the lack of images in the target domain. Previous approaches leverage Vision-Language Models (VLMs) to tackle this challenge, exploiting their zero-shot learning capabilities. However, these methods primarily address domain distribution shifts and overlook the misalignment between the detection task and VLMs, which rely on manually crafted prompts. To overcome these limitations, we propose the unified prompt and representation enhancement (UPRE) framework, which jointly optimizes both textual prompts and visual representations. Specifically, our approach introduces a multi-view domain prompt that combines linguistic domain priors with detection-specific knowledge, and a visual representation enhancement module that produces domain style variations. Furthermore, we introduce multi-level enhancement strategies, including relative domain distance and positive-negative separation, which align multi-modal representations at the image level and capture diverse visual representations at the instance level, respectively. Extensive experiments conducted on nine benchmark datasets demonstrate the superior performance of our framework in ZSDA detection scenarios. Code is available at <a target="_blank" rel="noopener" href="https://github.com/AMAP-ML/UPRE">https://github.com/AMAP-ML/UPRE</a>. </p>
<blockquote>
<p>零样本域自适应（ZSDA）由于缺乏目标域的图像而面临巨大挑战。之前的方法利用视觉语言模型（VLMs）来解决这一挑战，发挥它们的零样本学习能力。然而，这些方法主要解决域分布偏移问题，忽视了检测任务和依赖于手工制作的提示的VLM之间的不匹配。为了克服这些局限性，我们提出了统一提示和表示增强（UPRE）框架，该框架联合优化文本提示和视觉表示。具体来说，我们的方法引入了一种多视角域提示，它将语言域先验知识与检测特定知识相结合，以及一个视觉表示增强模块，用于生成域风格变化。此外，我们引入了多层次增强策略，包括相对域距离和正负分离，分别在图像层面实现对多模态表示的对齐和在实例层面捕获多样化的视觉表示。在九个基准数据集上进行的广泛实验表明，我们的框架在ZSDA检测场景中具有卓越的性能。代码可访问<a target="_blank" rel="noopener" href="https://github.com/AMAP-ML/UPRE%E3%80%82">https://github.com/AMAP-ML/UPRE。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00721v1">PDF</a> ICCV2025</p>
<p><strong>Summary</strong></p>
<p>零样本领域自适应（ZSDA）面临缺乏目标域图像的挑战。先前的方法利用视觉语言模型（VLMs）解决此挑战，但主要关注领域分布转移，忽略了检测任务与依赖手工提示的VLMs之间的不匹配。为克服这些限制，我们提出了统一提示和表示增强（UPRE）框架，联合优化文本提示和视觉表示。通过引入结合语言领域先验知识和检测特定知识的多视图领域提示，以及生成领域风格变化的视觉表示增强模块，该框架提高了性能。此外，我们介绍了多层次增强策略，包括相对领域距离和正负分离，分别对齐图像级别的多模态表示并捕获实例级别的多样视觉表示。在九个基准数据集上的广泛实验表明，我们的框架在ZSDA检测场景中表现优异。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ZSDA面临缺乏目标域图像的挑战。</li>
<li>之前的解决方案主要利用VLMs处理领域分布转移，但忽略了检测任务与VLMs之间的不匹配。</li>
<li>UPRE框架通过联合优化文本提示和视觉表示来提高性能。</li>
<li>UPRE引入多视图领域提示，结合语言领域知识和检测特定知识。</li>
<li>视觉表示增强模块生成领域风格变化。</li>
<li>多层次增强策略包括相对领域距离和正负分离，提高多模态表示的对齐和实例级别的视觉表示捕获。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00721">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-273b5981ed51e8d18776b2fde2a8c49b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3bbdd914ef07f98a2ab2538d3c00b878.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7870f451037050b4697fea48b540040f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9c032ab5a02805d35639010b0cad6e5.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-04/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-04/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">检测/分割/跟踪</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-04/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-89da2562429820f5ab2e08a26b26a814.jpg" class="responsive-img" alt="人脸相关">
                        
                        <span class="card-title">人脸相关</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            人脸相关 方向最新论文已更新，请持续关注 Update in 2025-07-04  Survivability of Backdoor Attacks on Unconstrained Face Recognition   Systems
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    人脸相关
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">人脸相关</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-04/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ae2a53d0e4b1c20d126622245d3b15e1.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2025-07-04  evMLP An Efficient Event-Driven MLP Architecture for Vision
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23251k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
