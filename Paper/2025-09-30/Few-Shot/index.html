<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  Death of the Novel(ty) Beyond n-Gram Novelty as a Metric for Textual   Creativity">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-e72ff3da1265d6f5e0eda57f81bf15fb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061064&auth_key=1760061064-0-0-5f514d8957011e02a69e304ddb10d74d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    54 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-30-æ›´æ–°"><a href="#2025-09-30-æ›´æ–°" class="headerlink" title="2025-09-30 æ›´æ–°"></a>2025-09-30 æ›´æ–°</h1><h2 id="Death-of-the-Novel-ty-Beyond-n-Gram-Novelty-as-a-Metric-for-Textual-Creativity"><a href="#Death-of-the-Novel-ty-Beyond-n-Gram-Novelty-as-a-Metric-for-Textual-Creativity" class="headerlink" title="Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual   Creativity"></a>Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual   Creativity</h2><p><strong>Authors:Arkadiy Saakyan, Najoung Kim, Smaranda Muresan, Tuhin Chakrabarty</strong></p>
<p>N-gram novelty is widely used to evaluate language modelsâ€™ ability to generate text outside of their training data. More recently, it has also been adopted as a metric for measuring textual creativity. However, theoretical work on creativity suggests that this approach may be inadequate, as it does not account for creativityâ€™s dual nature: novelty (how original the text is) and appropriateness (how sensical and pragmatic it is). We investigate the relationship between this notion of creativity and n-gram novelty through 7542 expert writer annotations (n&#x3D;26) of novelty, pragmaticality, and sensicality via close reading of human and AI-generated text. We find that while n-gram novelty is positively associated with expert writer-judged creativity, ~91% of top-quartile expressions by n-gram novelty are not judged as creative, cautioning against relying on n-gram novelty alone. Furthermore, unlike human-written text, higher n-gram novelty in open-source LLMs correlates with lower pragmaticality. In an exploratory study with frontier close-source models, we additionally confirm that they are less likely to produce creative expressions than humans. Using our dataset, we test whether zero-shot, few-shot, and finetuned models are able to identify creative expressions (a positive aspect of writing) and non-pragmatic ones (a negative aspect). Overall, frontier LLMs exhibit performance much higher than random but leave room for improvement, especially struggling to identify non-pragmatic expressions. We further find that LLM-as-a-Judge novelty scores from the best-performing model were predictive of expert writer preferences. </p>
<blockquote>
<p>N-gramæ–°é¢–æ€§è¢«å¹¿æ³›ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ç”Ÿæˆè®­ç»ƒæ•°æ®ä¹‹å¤–æ–‡æœ¬çš„èƒ½åŠ›ã€‚æœ€è¿‘ï¼Œå®ƒä¹Ÿè¢«ç”¨ä½œè¡¡é‡æ–‡æœ¬åˆ›é€ åŠ›çš„æŒ‡æ ‡ã€‚ç„¶è€Œï¼Œå…³äºåˆ›é€ åŠ›çš„ç†è®ºå·¥ä½œè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¸è¶³ï¼Œå› ä¸ºå®ƒæ²¡æœ‰è€ƒè™‘åˆ°åˆ›é€ åŠ›çš„åŒé‡æ€§è´¨ï¼šæ–°é¢–æ€§ï¼ˆæ–‡æœ¬çš„æ–°é¢–ç¨‹åº¦ï¼‰å’Œé€‚ç”¨æ€§ï¼ˆæ–‡æœ¬çš„å®ç”¨æ€§å’Œé€»è¾‘æ€§ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡ç»†è¯»äººç±»å’ŒAIç”Ÿæˆçš„æ–‡æœ¬ï¼Œè¿›è¡Œäº†7542æ¬¡ä¸“å®¶æ³¨é‡Šï¼ˆn&#x3D;26ï¼‰ï¼Œä»¥ç ”ç©¶è¿™ç§åˆ›é€ åŠ›æ¦‚å¿µä¸n-gramæ–°é¢–æ€§ä¹‹é—´çš„å…³ç³»ã€‚æˆ‘ä»¬å‘ç°ï¼Œè™½ç„¶n-gramæ–°é¢–æ€§ä¸ä¸“å®¶ä½œå®¶åˆ¤æ–­çš„åˆ›é€ åŠ›å‘ˆæ­£ç›¸å…³ï¼Œä½†çº¦91%çš„n-gramæ–°é¢–æ€§æœ€é«˜çš„å››åˆ†ä¹‹ä¸€è¡¨è¾¾å¹¶ä¸è¢«è®¤ä¸ºå…·æœ‰åˆ›é€ åŠ›ï¼Œè¿™æé†’äººä»¬ä¸è¦ä»…ä»…ä¾èµ–n-gramæ–°é¢–æ€§ã€‚æ­¤å¤–ï¼Œä¸äººç±»æ’°å†™çš„æ–‡æœ¬ä¸åŒï¼Œå¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ›´é«˜n-gramæ–°é¢–æ€§ä¸è¾ƒä½çš„å®ç”¨æ€§ç›¸å…³ã€‚åœ¨ä¸€é¡¹å‰æ²¿çš„å°é—­æ¨¡å‹æ¢ç´¢æ€§ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¿˜è¯å®å®ƒä»¬äº§ç”Ÿåˆ›é€ æ€§è¡¨è¾¾çš„å¯èƒ½æ€§æ¯”äººç±»æ›´ä½ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®é›†æµ‹è¯•äº†é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿè¯†åˆ«åˆ›é€ æ€§è¡¨è¾¾ï¼ˆå†™ä½œçš„ä¸€ä¸ªç§¯ææ–¹é¢ï¼‰å’Œéå®ç”¨è¡¨è¾¾ï¼ˆä¸€ä¸ªæ¶ˆææ–¹é¢ï¼‰ã€‚æ€»ä½“è€Œè¨€ï¼Œå‰æ²¿çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½è¿œé«˜äºéšæœºæ°´å¹³ï¼Œä½†ä»æœ‰ä¸€å®šçš„æ”¹è¿›ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨è¯†åˆ«éå®ç”¨è¡¨è¾¾æ–¹é¢ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å‘ç°ï¼Œæœ€ä½³æ€§èƒ½æ¨¡å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæ³•å®˜çš„æ–°é¢–æ€§è¯„åˆ†èƒ½å¤Ÿé¢„æµ‹ä¸“å®¶ä½œå®¶çš„åå¥½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22641v1">PDF</a> 26 pages, 10 figures, under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç”¨N-gramæ–°é¢–æ€§è¯„ä¼°è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„èƒ½åŠ›ï¼Œä»¥åŠè¯„ä¼°æ–‡æœ¬åˆ›é€ åŠ›çš„æŒ‡æ ‡é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡N-gramæ–°é¢–æ€§ä¸ä¸“å®¶è¯„åˆ¤çš„åˆ›é€ åŠ›æœ‰ä¸€å®šå…³è”ï¼Œä½†å•çº¯ä¾èµ–N-gramæ–°é¢–æ€§å¹¶ä¸è¶³ä»¥è¡¡é‡åˆ›é€ åŠ›ï¼Œå› ä¸ºåˆ›é€ åŠ›åŒ…å«æ–°é¢–æ€§å’Œé€‚å½“æ€§ä¸¤ä¸ªè¦ç´ ã€‚ç ”ç©¶è¡¨æ˜ï¼Œé«˜è¾¾91%çš„N-gramæ–°é¢–æ€§å¤„äºé¡¶éƒ¨çš„å››åˆ†ä¹‹ä¸€çš„è¡¨è¾¾å¹¶æœªè¢«åˆ¤æ–­ä¸ºå…·æœ‰åˆ›é€ åŠ›ã€‚æ­¤å¤–ï¼Œä¸äººå·¥æ™ºèƒ½ç”Ÿæˆçš„æ–‡æœ¬ç›¸æ¯”ï¼Œäººç±»å†™ä½œçš„æ–‡æœ¬ä¸­è¾ƒé«˜çš„N-gramæ–°é¢–æ€§ä¸è¾ƒä½çš„å®ç”¨æ€§ç›¸å…³è”ã€‚åŒæ—¶ï¼Œæ¢ç´¢æ€§ç ”ç©¶è¿˜å‘ç°å‰æ²¿çš„å°é—­æºæ¨¡å‹äº§ç”Ÿåˆ›é€ æ€§è¡¨è¾¾çš„å¯èƒ½æ€§è¾ƒä½ã€‚ä½¿ç”¨æ•°æ®é›†æµ‹è¯•äº†é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå¾®è°ƒæ¨¡å‹è¯†åˆ«åˆ›é€ æ€§è¡¨è¾¾å’Œä¸åˆé€»è¾‘è¡¨è¾¾çš„èƒ½åŠ›ï¼Œç»“æœæ˜¾ç¤ºè™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºä¸€å®šæ€§èƒ½ï¼Œä½†ä»éœ€æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>N-gramæ–°é¢–æ€§è¢«ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼Œä½†åœ¨è¡¡é‡æ–‡æœ¬åˆ›é€ åŠ›æ–¹é¢å¯èƒ½å­˜åœ¨ä¸è¶³ã€‚</li>
<li>åˆ›é€ åŠ›åŒ…å«æ–°é¢–æ€§å’Œé€‚å½“æ€§ä¸¤ä¸ªè¦ç´ ï¼Œå•çº¯ä¾èµ–N-gramæ–°é¢–æ€§è¯„ä¼°åˆ›é€ åŠ›æ˜¯ä¸å…¨é¢çš„ã€‚</li>
<li>é«˜è¾¾91%çš„N-gramæ–°é¢–æ€§é«˜çš„è¡¨è¾¾æœªè¢«ä¸“å®¶åˆ¤æ–­ä¸ºå…·æœ‰åˆ›é€ åŠ›ã€‚</li>
<li>åœ¨äººç±»å†™ä½œçš„æ–‡æœ¬ä¸­ï¼Œè¾ƒé«˜çš„N-gramæ–°é¢–æ€§ä¸è¾ƒä½çš„å®ç”¨æ€§æœ‰å…³è”ã€‚</li>
<li>å‰æ²¿çš„å¼€æ”¾æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰äº§ç”Ÿåˆ›é€ æ€§è¡¨è¾¾çš„å¯èƒ½æ€§è¾ƒä½ã€‚</li>
<li>ä½¿ç”¨æ•°æ®é›†æµ‹è¯•äº†ä¸åŒæ¨¡å‹è¯†åˆ«åˆ›é€ æ€§è¡¨è¾¾å’Œä¸åˆé€»è¾‘è¡¨è¾¾çš„èƒ½åŠ›ï¼Œæ˜¾ç¤ºå‡ºå¤§å‹è¯­è¨€æ¨¡å‹ä»éœ€æ”¹è¿›çš„ç©ºé—´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22641">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3559525296e0214577bb2ef68c046cf0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061071&auth_key=1760061071-0-0-f8e16ea04a89dca438833b14b9f2c618&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9e32f717a050d95aafe300c12e1eb50b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061078&auth_key=1760061078-0-0-6fcc9733630930a93a4c30e6ef1c9a02&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e8a64b398f321a612806c5ce9acda9e1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061085&auth_key=1760061085-0-0-4ed3451b0c4341e316d1a3abfa19d716&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fb21d86b8e8fdca6c1a00cef4e8443ca~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061092&auth_key=1760061092-0-0-88539c51241d98894ac10805f614f896&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ce5d84155b0b52e3048ce7f1c0095dba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061099&auth_key=1760061099-0-0-2a48a446c10813dc83fb3468f1ffe8fb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Training-Free-Synthetic-Data-Generation-with-Dual-IP-Adapter-Guidance"><a href="#Training-Free-Synthetic-Data-Generation-with-Dual-IP-Adapter-Guidance" class="headerlink" title="Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance"></a>Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance</h2><p><strong>Authors:Luc Boudier, Loris Manganelli, Eleftherios Tsonis, Nicolas Dufour, Vicky Kalogeiton</strong></p>
<p>Few-shot image classification remains challenging due to the limited availability of labeled examples. Recent approaches have explored generating synthetic training data using text-to-image diffusion models, but often require extensive model fine-tuning or external information sources. We present a novel training-free approach, called DIPSY, that leverages IP-Adapter for image-to-image translation to generate highly discriminative synthetic images using only the available few-shot examples. DIPSY introduces three key innovations: (1) an extended classifier-free guidance scheme that enables independent control over positive and negative image conditioning; (2) a class similarity-based sampling strategy that identifies effective contrastive examples; and (3) a simple yet effective pipeline that requires no model fine-tuning or external captioning and filtering. Experiments across ten benchmark datasets demonstrate that our approach achieves state-of-the-art or comparable performance, while eliminating the need for generative model adaptation or reliance on external tools for caption generation and image filtering. Our results highlight the effectiveness of leveraging dual image prompting with positive-negative guidance for generating class-discriminative features, particularly for fine-grained classification tasks. </p>
<blockquote>
<p>é’ˆå¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„å°æ ·æœ¬å›¾åƒåˆ†ç±»é—®é¢˜ï¼Œç”±äºå…¶å¯ç”¨çš„æ ‡æ³¨æ ·æœ¬æ•°é‡æœ‰é™ï¼Œæœ€è¿‘çš„ç ”ç©¶æ–¹æ³•å¼€å§‹å°è¯•ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®ï¼Œä½†è¿™é€šå¸¸éœ€è¦å¤§é‡çš„æ¨¡å‹å¾®è°ƒæˆ–å¤–éƒ¨ä¿¡æ¯æºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ— è®­ç»ƒæ–¹æ³•ï¼Œç§°ä¸ºDIPSYï¼Œå®ƒåˆ©ç”¨IP-Adapterè¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ï¼Œä»…ä½¿ç”¨å¯ç”¨çš„å°æ ·æœ¬ç¤ºä¾‹ç”Ÿæˆå…·æœ‰é«˜åº¦åŒºåˆ†æ€§çš„åˆæˆå›¾åƒã€‚DIPSYå¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šï¼ˆ1ï¼‰æ‰©å±•çš„æ— åˆ†ç±»å™¨å¼•å¯¼æ–¹æ¡ˆï¼Œå®ç°å¯¹æ­£ä¾‹å’Œè´Ÿä¾‹å›¾åƒæ¡ä»¶çš„ç‹¬ç«‹æ§åˆ¶ï¼›ï¼ˆ2ï¼‰åŸºäºç±»åˆ«ç›¸ä¼¼æ€§çš„é‡‡æ ·ç­–ç•¥ï¼Œç”¨äºè¯†åˆ«æœ‰æ•ˆçš„å¯¹æ¯”ç¤ºä¾‹ï¼›ï¼ˆ3ï¼‰æ— éœ€æ¨¡å‹å¾®è°ƒæˆ–å¤–éƒ¨å­—å¹•æ ‡æ³¨å’Œè¿‡æ»¤çš„ç®€å•æœ‰æ•ˆçš„æµç¨‹ã€‚åœ¨åä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€æ–°æˆ–ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼ŒåŒæ—¶æ¶ˆé™¤äº†å¯¹ç”Ÿæˆæ¨¡å‹é€‚åº”æˆ–ä¾èµ–å¤–éƒ¨å·¥å…·è¿›è¡Œå­—å¹•ç”Ÿæˆå’Œå›¾åƒè¿‡æ»¤çš„éœ€æ±‚ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†åœ¨ç”Ÿæˆå…·æœ‰ç±»åˆ«åŒºåˆ†æ€§çš„ç‰¹å¾æ—¶ï¼Œåˆ©ç”¨å¸¦æœ‰æ­£è´Ÿå¼•å¯¼çš„åŒé‡å›¾åƒæç¤ºçš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»†ç²’åº¦åˆ†ç±»ä»»åŠ¡ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22635v1">PDF</a> BMVC 2025. Project page:   <a target="_blank" rel="noopener" href="https://www.lix.polytechnique.fr/vista/projects/2025_bmvc_dipsy/">https://www.lix.polytechnique.fr/vista/projects/2025_bmvc_dipsy/</a></p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä¸»è¦ä»‹ç»äº†é’ˆå¯¹å°‘æ ·æœ¬å›¾åƒåˆ†ç±»é—®é¢˜çš„ä¸€ç§æ–°é¢–çš„è®­ç»ƒå¤–æ–¹æ³•ï¼Œç§°ä¸ºDIPSYã€‚è¯¥æ–¹æ³•åˆ©ç”¨IP-Adapterè¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ï¼Œä»…ä½¿ç”¨æœ‰é™çš„æ ·æœ¬ç”Ÿæˆé«˜åº¦åŒºåˆ†æ€§çš„åˆæˆå›¾åƒã€‚DIPSYå¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šæ‰©å±•çš„åˆ†ç±»å™¨å¤–æŒ‡å¯¼æ–¹æ¡ˆï¼ŒåŸºäºç±»åˆ«ç›¸ä¼¼æ€§çš„é‡‡æ ·ç­–ç•¥ï¼Œä»¥åŠæ— éœ€æ¨¡å‹å¾®è°ƒæˆ–å¤–éƒ¨æè¿°çš„ç®€å•æœ‰æ•ˆç®¡é“ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æˆ–ç›¸å½“çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DIPSYæ˜¯ä¸€ç§æ–°é¢–çš„é’ˆå¯¹å°‘æ ·æœ¬å›¾åƒåˆ†ç±»çš„è®­ç»ƒå¤–æ–¹æ³•ã€‚</li>
<li>DIPSYåˆ©ç”¨IP-Adapterè¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ï¼Œç”Ÿæˆåˆæˆå›¾åƒã€‚</li>
<li>DIPSYå¼•å…¥äº†æ‰©å±•çš„åˆ†ç±»å™¨å¤–æŒ‡å¯¼æ–¹æ¡ˆï¼Œå®ç°å¯¹æ­£è´Ÿå›¾åƒæ¡ä»¶çš„ç‹¬ç«‹æ§åˆ¶ã€‚</li>
<li>åŸºäºç±»åˆ«ç›¸ä¼¼æ€§çš„é‡‡æ ·ç­–ç•¥ç”¨äºè¯†åˆ«æœ‰æ•ˆçš„å¯¹æ¯”æ ·æœ¬ã€‚</li>
<li>DIPSYçš„æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œæ— éœ€æ¨¡å‹å¾®è°ƒæˆ–å¤–éƒ¨æè¿°å’Œè¿‡æ»¤ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒDIPSYåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æˆ–ç›¸å½“çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4fc3c2f0390661f536be62273fa4060d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061107&auth_key=1760061107-0-0-3017507fba0e90dfcb247609ddcc8476&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49adb471e62d380087b33b0edd341444~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061114&auth_key=1760061114-0-0-fb9819912b8077635035fc2aa87657df&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4359506f5699b825c24dee9ba7f4298a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061120&auth_key=1760061120-0-0-8b7db2c3c0f2dd1323cb065fb4faf8cc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="FoodSEM-Large-Language-Model-Specialized-in-Food-Named-Entity-Linking"><a href="#FoodSEM-Large-Language-Model-Specialized-in-Food-Named-Entity-Linking" class="headerlink" title="FoodSEM: Large Language Model Specialized in Food Named-Entity Linking"></a>FoodSEM: Large Language Model Specialized in Food Named-Entity Linking</h2><p><strong>Authors:Ana Gjorgjevikj, Matej Martinc, Gjorgjina Cenikj, SaÅ¡o DÅ¾eroski, Barbara KorouÅ¡iÄ‡ Seljak, Tome Eftimov</strong></p>
<p>This paper introduces FoodSEM, a state-of-the-art fine-tuned open-source large language model (LLM) for named-entity linking (NEL) to food-related ontologies. To the best of our knowledge, food NEL is a task that cannot be accurately solved by state-of-the-art general-purpose (large) language models or custom domain-specific models&#x2F;systems. Through an instruction-response (IR) scenario, FoodSEM links food-related entities mentioned in a text to several ontologies, including FoodOn, SNOMED-CT, and the Hansard taxonomy. The FoodSEM model achieves state-of-the-art performance compared to related models&#x2F;systems, with F1 scores even reaching 98% on some ontologies and datasets. The presented comparative analyses against zero-shot, one-shot, and few-shot LLM prompting baselines further highlight FoodSEMâ€™s superior performance over its non-fine-tuned version. By making FoodSEM and its related resources publicly available, the main contributions of this article include (1) publishing a food-annotated corpora into an IR format suitable for LLM fine-tuning&#x2F;evaluation, (2) publishing a robust model to advance the semantic understanding of text in the food domain, and (3) providing a strong baseline on food NEL for future benchmarking. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†FoodSEMï¼Œè¿™æ˜¯ä¸€ä¸ªæœ€æ–°ç²¾ç»†è°ƒæ•´çš„å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œç”¨äºå‘½åå®ä½“é“¾æ¥ï¼ˆNELï¼‰åˆ°é£Ÿå“ç›¸å…³æœ¬ä½“ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œé£Ÿå“NELæ˜¯ä¸€é¡¹ä»»åŠ¡ï¼Œæ— æ³•ç”±æœ€æ–°é€šç”¨ï¼ˆå¤§å‹ï¼‰è¯­è¨€æ¨¡å‹æˆ–å®šåˆ¶é¢†åŸŸç‰¹å®šæ¨¡å‹&#x2F;ç³»ç»Ÿå‡†ç¡®è§£å†³ã€‚é€šè¿‡æŒ‡ä»¤å“åº”ï¼ˆIRï¼‰åœºæ™¯ï¼ŒFoodSEMå°†æ–‡æœ¬ä¸­æåˆ°çš„é£Ÿå“ç›¸å…³å®ä½“é“¾æ¥åˆ°å‡ ä¸ªæœ¬ä½“ï¼ŒåŒ…æ‹¬FoodOnã€SNOMED-CTå’ŒHansardåˆ†ç±»æ³•ã€‚FoodSEMæ¨¡å‹ä¸ç›¸å…³æ¨¡å‹&#x2F;ç³»ç»Ÿç›¸æ¯”å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨æŸäº›æœ¬ä½“å’Œæ•°æ®é›†ä¸ŠF1åˆ†æ•°ç”šè‡³è¾¾åˆ°98%ã€‚ä¸é›¶é•œå¤´ã€ä¸€é•œå¤´å’Œå°‘é•œå¤´LLMæç¤ºåŸºå‡†ç‚¹çš„æ¯”è¾ƒåˆ†æè¿›ä¸€æ­¥çªå‡ºäº†FoodSEMåœ¨å¾®è°ƒç‰ˆæœ¬ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚é€šè¿‡å…¬å¼€æä¾›FoodSEMåŠå…¶ç›¸å…³èµ„æºï¼Œæœ¬æ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰å°†é£Ÿå“æ³¨é‡Šè¯­æ–™åº“å‘å¸ƒä¸ºé€‚åˆLLMå¾®è°ƒ&#x2F;è¯„ä¼°çš„IRæ ¼å¼ï¼Œï¼ˆ2ï¼‰å‘å¸ƒä¸€ä¸ªç¨³å¥çš„æ¨¡å‹ï¼Œä»¥æ¨è¿›é£Ÿå“é¢†åŸŸçš„æ–‡æœ¬è¯­ä¹‰ç†è§£ï¼Œï¼ˆ3ï¼‰ä¸ºæœªæ¥çš„åŸºå‡†æµ‹è¯•æä¾›é£Ÿå“NELçš„å¼ºåŸºå‡†çº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22125v1">PDF</a> To appear in the Proceedings of the 28th International Conference on   Discovery Science (DS 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†ä¸€ä¸ªé’ˆå¯¹é£Ÿå“é¢†åŸŸå‘½åå®ä½“é“¾æ¥ï¼ˆNELï¼‰ä»»åŠ¡çš„å…ˆè¿›å¤§å‹è¯­è¨€æ¨¡å‹â€”â€”FoodSEMã€‚è¯¥æ¨¡å‹é€šè¿‡ç²¾ç»†è°ƒæ•´ï¼Œå®ç°äº†å¯¹é£Ÿå“ç›¸å…³å®ä½“çš„æ–‡æœ¬é“¾æ¥åˆ°å¤šä¸ªé£Ÿå“æœ¬ä½“ï¼Œå¦‚FoodOnã€SNOMED-CTå’ŒHansardåˆ†ç±»æ³•ã€‚FoodSEMæ¨¡å‹åœ¨ç›¸å…³æ¨¡å‹&#x2F;ç³»ç»Ÿä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œéƒ¨åˆ†æ•°æ®é›†ä¸Šçš„F1åˆ†æ•°é«˜è¾¾98%ã€‚æœ¬æ–‡ä¸»è¦è´¡çŒ®åŒ…æ‹¬å‘å¸ƒé£Ÿå“æ³¨é‡Šè¯­æ–™åº“ã€é€‚ç”¨äºLLMå¾®è°ƒ&#x2F;è¯„ä¼°çš„IRæ ¼å¼ï¼Œå‘å¸ƒä¸€ä¸ªç”¨äºå¢å¼ºæ–‡æœ¬è¯­ä¹‰ç†è§£çš„ç¨³å¥æ¨¡å‹ï¼Œå¹¶ä¸ºæœªæ¥çš„åŸºå‡†æµ‹è¯•æä¾›å¼ºå¤§çš„é£Ÿå“NELåŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FoodSEMæ˜¯ä¸€ä¸ªé’ˆå¯¹é£Ÿå“é¢†åŸŸå‘½åå®ä½“é“¾æ¥ï¼ˆNELï¼‰çš„å…ˆè¿›å¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>FoodSEMé€šè¿‡ç²¾ç»†è°ƒæ•´ï¼Œå®ç°äº†å¯¹é£Ÿå“ç›¸å…³å®ä½“åœ¨æ–‡æœ¬ä¸­çš„é“¾æ¥åˆ°å¤šä¸ªé£Ÿå“æœ¬ä½“ã€‚</li>
<li>FoodSEMæ¨¡å‹åœ¨ç›¸å…³æ¨¡å‹&#x2F;ç³»ç»Ÿä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒF1åˆ†æ•°é«˜è¾¾98%ã€‚</li>
<li>FoodSEMçš„å‘å¸ƒå¯¹äºæ¨åŠ¨é£Ÿå“é¢†åŸŸçš„è¯­ä¹‰ç†è§£å…·æœ‰é‡å¤§æ„ä¹‰ã€‚</li>
<li>æœ¬æ–‡ä¸»è¦è´¡çŒ®åŒ…æ‹¬å‘å¸ƒé£Ÿå“æ³¨é‡Šè¯­æ–™åº“ã€é€‚ç”¨äºLLMå¾®è°ƒ&#x2F;è¯„ä¼°çš„IRæ ¼å¼ã€‚</li>
<li>FoodSEMçš„å‘å¸ƒä¸ºæœªæ¥çš„åŸºå‡†æµ‹è¯•æä¾›äº†å¼ºå¤§çš„é£Ÿå“NELåŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22125">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f5e6c28920b031814fb129b4e8dc3abf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061128&auth_key=1760061128-0-0-7d8a9b073fbed4ca30aaf0fdcab7405c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-21bc9e197f564cb1eb686eedc3f5c2ad~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061135&auth_key=1760061135-0-0-b6f4e85e6718fab389057b63ff2b2414&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-503ffa1f0488c2533b94aac7d65cee61~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061142&auth_key=1760061142-0-0-e097c0095060ebc3d581cc3b50b02ad4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Geo-R1-Improving-Few-Shot-Geospatial-Referring-Expression-Understanding-with-Reinforcement-Fine-Tuning"><a href="#Geo-R1-Improving-Few-Shot-Geospatial-Referring-Expression-Understanding-with-Reinforcement-Fine-Tuning" class="headerlink" title="Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding   with Reinforcement Fine-Tuning"></a>Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding   with Reinforcement Fine-Tuning</h2><p><strong>Authors:Zilun Zhang, Zian Guan, Tiancheng Zhao, Haozhan Shen, Tianyu Li, Yuxiang Cai, Zhonggen Su, Zhaojun Liu, Jianwei Yin, Xiang Li</strong></p>
<p>Referring expression understanding in remote sensing poses unique challenges, as it requires reasoning over complex object-context relationships. While supervised fine-tuning (SFT) on multimodal large language models achieves strong performance with massive labeled datasets, they struggle in data-scarce scenarios, leading to poor generalization. To address this limitation, we propose Geo-R1, a reasoning-centric reinforcement fine-tuning (RFT) paradigm for few-shot geospatial referring. Geo-R1 enforces the model to first generate explicit, interpretable reasoning chains that decompose referring expressions, and then leverage these rationales to localize target objects. This â€œreason first, then actâ€ process enables the model to make more effective use of limited annotations, enhances generalization, and provides interpretability. We validate Geo-R1 on three carefully designed few-shot geospatial referring benchmarks, where our model consistently and substantially outperforms SFT baselines. It also demonstrates strong cross-dataset generalization, highlighting its robustness. Code and data will be released at <a target="_blank" rel="noopener" href="http://geo-r1.github.io/">http://geo-r1.github.io</a>. </p>
<blockquote>
<p>é¥æ„Ÿä¸­çš„æŒ‡ä»£è¡¨è¾¾å¼ç†è§£é¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒéœ€è¦å¯¹å¤æ‚çš„å¯¹è±¡ä¸Šä¸‹æ–‡å…³ç³»è¿›è¡Œæ¨ç†ã€‚è™½ç„¶åŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨å¤§é‡æ ‡è®°æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬ä¼šé‡åˆ°å›°éš¾ï¼Œå¯¼è‡´æ³›åŒ–æ€§èƒ½å·®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Geo-R1ï¼Œè¿™æ˜¯ä¸€ç§ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰èŒƒå¼ï¼Œç”¨äºå°æ ·æœ¬åœ°ç†ç©ºé—´æŒ‡ä»£ã€‚Geo-R1å¼ºåˆ¶æ¨¡å‹é¦–å…ˆç”Ÿæˆæ˜ç¡®ã€å¯è§£é‡Šçš„æ¨ç†é“¾ï¼Œå¯¹æŒ‡ä»£è¡¨è¾¾å¼è¿›è¡Œåˆ†è§£ï¼Œç„¶ååˆ©ç”¨è¿™äº›ç†æ€§æ¥å®šä½ç›®æ ‡å¯¹è±¡ã€‚è¿™ç§â€œå…ˆæ¨ç†ï¼Œåè¡ŒåŠ¨â€çš„è¿‡ç¨‹ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„æ³¨é‡Šï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æä¾›å¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªç²¾å¿ƒè®¾è®¡çš„å°æ ·æœ¬åœ°ç†ç©ºé—´æŒ‡ä»£åŸºå‡†æµ‹è¯•ä¸Šå¯¹Geo-R1è¿›è¡Œäº†éªŒè¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å§‹ç»ˆä¸”å¤§å¹…åº¦åœ°ä¼˜äºSFTåŸºå‡†æµ‹è¯•ã€‚å®ƒè¿˜è¡¨ç°å‡ºäº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œçªå‡ºäº†å…¶ç¨³å¥æ€§ã€‚ä»£ç å’Œæ•°æ®å°†åœ¨<a target="_blank" rel="noopener" href="http://geo-r1.github.ioå‘å¸ƒ./">http://geo-r1.github.ioå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21976v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿œç¨‹æ„Ÿåº”ä¸­çš„æŒ‡ä»£è¡¨è¾¾ç†è§£é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œéœ€å¯¹å¤æ‚çš„ç‰©ä½“ä¸Šä¸‹æ–‡å…³ç³»è¿›è¡Œæ¨ç†ã€‚è™½ç„¶ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šçš„è¡¨ç°å¼ºåŠ²ï¼Œä½†åœ¨æ•°æ®ç¨€ç¼ºçš„åœºæ™¯ä¸‹å´è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å¼±ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºGeo-R1ï¼Œä¸€ç§ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰èŒƒå¼ï¼Œç”¨äºå°‘æ•°åœ°ç†ç©ºé—´æŒ‡ä»£ã€‚Geo-R1å¼ºåˆ¶æ¨¡å‹é¦–å…ˆç”Ÿæˆæ˜ç¡®ã€å¯è§£é‡Šçš„æ¨ç†é“¾ï¼Œåˆ†è§£æŒ‡ä»£è¡¨è¾¾å¼ï¼Œç„¶ååˆ©ç”¨è¿™äº›ç†æ€§æ¥å®šä½ç›®æ ‡å¯¹è±¡ã€‚è¿™ç§â€œå…ˆæ¨ç†ï¼Œåè¡ŒåŠ¨â€çš„è¿‡ç¨‹ä½¿æ¨¡å‹æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„æ³¨é‡Šï¼Œå¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æä¾›äº†å¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªç²¾å¿ƒè®¾è®¡çš„å°‘æ•°åœ°ç†ç©ºé—´æŒ‡ä»£åŸºå‡†æµ‹è¯•ä¸ŠéªŒè¯äº†Geo-R1ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å§‹ç»ˆä¸”å¤§å¹…åº¦åœ°ä¼˜äºSFTåŸºå‡†æµ‹è¯•ã€‚å®ƒè¿˜å±•ç¤ºäº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œå‡¸æ˜¾äº†å…¶ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿œç¨‹æ„Ÿåº”ä¸­çš„æŒ‡ä»£è¡¨è¾¾ç†è§£å…·æœ‰ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œéœ€åº”å¯¹å¤æ‚çš„ç‰©ä½“ä¸Šä¸‹æ–‡å…³ç³»ã€‚</li>
<li>ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨æ•°æ®ä¸°å¯Œçš„æƒ…å†µä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ•°æ®ç¨€ç¼ºæ—¶æ³›åŒ–èƒ½åŠ›å¼±ã€‚</li>
<li>Geo-R1æ˜¯ä¸€ç§æ–°çš„å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰æ–¹æ³•ï¼Œé€‚ç”¨äºå°‘æ•°åœ°ç†ç©ºé—´æŒ‡ä»£åœºæ™¯ã€‚</li>
<li>Geo-R1é€šè¿‡ç”Ÿæˆæ˜ç¡®ã€å¯è§£é‡Šçš„æ¨ç†é“¾æ¥åˆ†è§£æŒ‡ä»£è¡¨è¾¾å¼ã€‚</li>
<li>â€œå…ˆæ¨ç†ï¼Œåè¡ŒåŠ¨â€çš„è¿‡ç¨‹ä½¿æ¨¡å‹æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™æ•°æ®ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>Geo-R1åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œä¸”å…·å¤‡å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-49f0a798e3b720600edee6d1d1a06562~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061150&auth_key=1760061150-0-0-c770c2fa17b21ee8341e87f1265e4c74&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-994db49426bf0366cabd4d19111fa23b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061157&auth_key=1760061157-0-0-c500603562dfa100997e93e5282bcf20&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7821f1f8223ce5a782bbe37b2b9682c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061164&auth_key=1760061164-0-0-82d281f61dcdd4fe36fae912daffba4d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c712fe35903eb4dcf028fa8f5c1c9c4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061171&auth_key=1760061171-0-0-c615973a5a2044e4f837d5def0f329c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c73613c190cee85accb10e9ea1075930~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061178&auth_key=1760061178-0-0-e263d34d81477356136b8024368a7d78&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ChaosNexus-A-Foundation-Model-for-Universal-Chaotic-System-Forecasting-with-Multi-scale-Representations"><a href="#ChaosNexus-A-Foundation-Model-for-Universal-Chaotic-System-Forecasting-with-Multi-scale-Representations" class="headerlink" title="ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting   with Multi-scale Representations"></a>ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting   with Multi-scale Representations</h2><p><strong>Authors:Chang Liu, Bohao Zhao, Jingtao Ding, Yong Li</strong></p>
<p>Accurately forecasting chaotic systems, prevalent in domains such as weather prediction and fluid dynamics, remains a significant scientific challenge. The inherent sensitivity of these systems to initial conditions, coupled with a scarcity of observational data, severely constrains traditional modeling approaches. Since these models are typically trained for a specific system, they lack the generalization capacity necessary for real-world applications, which demand robust zero-shot or few-shot forecasting on novel or data-limited scenarios. To overcome this generalization barrier, we propose ChaosNexus, a foundation model pre-trained on a diverse corpus of chaotic dynamics. ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented with Mixture-of-Experts layers, to capture both universal patterns and system-specific behaviors. The model demonstrates state-of-the-art zero-shot generalization across both synthetic and real-world benchmarks. On a large-scale testbed comprising over 9,000 synthetic chaotic systems, it improves the fidelity of long-term attractor statistics by more than 40% compared to the leading baseline. This robust performance extends to real-world applications with exceptional data efficiency. For instance, in 5-day global weather forecasting, ChaosNexus achieves a competitive zero-shot mean error below 1 degree, a result that further improves with few-shot fine-tuning. Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding principle for scientific foundation models: cross-system generalization stems from the diversity of training systems, rather than sheer data volume. </p>
<blockquote>
<p>ç²¾ç¡®é¢„æµ‹æ··æ²Œç³»ç»Ÿï¼Œè¿™åœ¨å¤©æ°”é¢„æŠ¥å’Œæµä½“åŠ¨åŠ›å­¦ç­‰é¢†åŸŸæ™®éå­˜åœ¨ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§çš„ç§‘å­¦æŒ‘æˆ˜ã€‚è¿™äº›ç³»ç»Ÿå¯¹åˆå§‹æ¡ä»¶çš„å›ºæœ‰æ•æ„Ÿæ€§ï¼Œä»¥åŠè§‚æµ‹æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œä¸¥é‡åˆ¶çº¦äº†ä¼ ç»Ÿå»ºæ¨¡æ–¹æ³•ã€‚ç”±äºè¿™äº›æ¨¡å‹é€šå¸¸é’ˆå¯¹ç‰¹å®šç³»ç»Ÿè®­ç»ƒï¼Œå®ƒä»¬ç¼ºä¹ç°å®ä¸–ç•Œåº”ç”¨æ‰€éœ€çš„ä¸€èˆ¬åŒ–èƒ½åŠ›ï¼Œè¿™è¦æ±‚åœ¨æ–°å‹æˆ–æ•°æ®æœ‰é™åœºæ™¯ä¸Šè¿›è¡Œç¨³å¥çš„é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬é¢„æµ‹ã€‚ä¸ºäº†å…‹æœè¿™ä¸€æ³›åŒ–éšœç¢ï¼Œæˆ‘ä»¬æå‡ºäº†ChaosNexusï¼Œä¸€ä¸ªé¢„è®­ç»ƒåœ¨å¤šæ ·æ··æ²ŒåŠ¨åŠ›å­¦è¯­æ–™åº“ä¸Šçš„åŸºç¡€æ¨¡å‹ã€‚ChaosNexusé‡‡ç”¨äº†ä¸€ç§æ–°å‹çš„å¤šå°ºåº¦æ¶æ„ï¼Œåä¸ºScaleFormerï¼Œå¹¶è¾…ä»¥Mixture-of-Expertså±‚ï¼Œä»¥æ•æ‰é€šç”¨æ¨¡å¼å’Œç³»ç»Ÿç‰¹å®šè¡Œä¸ºã€‚è¯¥æ¨¡å‹åœ¨åˆæˆå’Œç°å®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ä¸€ä¸ªåŒ…å«è¶…è¿‡9000ä¸ªåˆæˆæ··æ²Œç³»ç»Ÿçš„å¤§è§„æ¨¡æµ‹è¯•åºŠä¸Šï¼Œä¸é¢†å…ˆçš„åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒåœ¨é•¿æœŸå¸å¼•å­ç»Ÿè®¡çš„ä¿çœŸåº¦ä¸Šæé«˜äº†40%ä»¥ä¸Šã€‚è¿™ç§ç¨³å¥æ€§èƒ½åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­å…·æœ‰å‡ºè‰²çš„æ•°æ®æ•ˆç‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸ºæœŸ5å¤©çš„å…¨çƒå¤©æ°”é¢„æŠ¥ä¸­ï¼ŒChaosNexuså®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„é›¶æ ·æœ¬å¹³å‡è¯¯å·®ä½äº1åº¦ï¼Œå¹¶ä¸”è¯¥ç»“æœé€šè¿‡å°‘é‡æ ·æœ¬å¾®è°ƒå¾—åˆ°äº†è¿›ä¸€æ­¥æ”¹å–„ã€‚æ­¤å¤–ï¼ŒChaosNexusçš„å¯æ‰©å±•æ€§è¡Œä¸ºçš„å®éªŒä¸ºç§‘å­¦åŸºç¡€æ¨¡å‹æä¾›äº†æŒ‡å¯¼åŸåˆ™ï¼šè·¨ç³»ç»Ÿæ³›åŒ–æºäºè®­ç»ƒç³»ç»Ÿçš„å¤šæ ·æ€§ï¼Œè€Œéå•çº¯çš„æ•°æ®é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21802v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é¢„æµ‹æ··æ²Œç³»ç»Ÿçš„æ–°æ–¹æ³•ï¼Œå¦‚å¤©æ°”é¢„æŠ¥å’Œæµä½“åŠ¨åŠ›å­¦ã€‚ç”±äºä¼ ç»Ÿå»ºæ¨¡æ–¹æ³•å—é™äºåˆå§‹æ¡ä»¶çš„æ•æ„Ÿæ€§å’Œè§‚æµ‹æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œéš¾ä»¥åº”ç”¨äºç°å®ä¸–ç•Œçš„å¤æ‚åœºæ™¯ã€‚å› æ­¤ï¼Œæå‡ºäº†ChaosNexusï¼Œä¸€ç§åœ¨å¤šæ ·æ··æ²ŒåŠ¨æ€è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒçš„é€šç”¨æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ–°å‹çš„å¤šå°ºåº¦æ¶æ„ScaleFormerå’Œæ··åˆä¸“å®¶å±‚ï¼Œèƒ½æ•æ‰é€šç”¨æ¨¡å¼å’Œç³»ç»Ÿç‰¹å®šè¡Œä¸ºã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šï¼Œå®ç°äº†é›¶æ ·æœ¬æ³›åŒ–çš„æœ€æ–°æ°´å¹³ã€‚åœ¨å¤§è§„æ¨¡æµ‹è¯•åºŠä¸Šå¯¹è¶…è¿‡9000ä¸ªåˆæˆæ··æ²Œç³»ç»Ÿçš„æµ‹è¯•æ˜¾ç¤ºï¼Œä¸é¢†å…ˆçš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œé•¿æœŸå¸å¼•ç»Ÿè®¡é‡çš„ä¿çœŸåº¦æé«˜äº†è¶…è¿‡40%ã€‚åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­ï¼Œè¡¨ç°å‡ºæé«˜çš„æ•°æ®æ•ˆç‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å…¨çƒå¤©æ°”é¢„æµ‹çš„äº”å¤©å†…ï¼Œæ— éœ€ä»»ä½•æ•°æ®å³å®ç°äº†å¹³å‡è¯¯å·®ä½äºä¸€åº¦çš„ä¼˜ç§€é›¶æ ·æœ¬é¢„æµ‹æ•ˆæœã€‚éšç€å°‘é‡çš„å¾®è°ƒæ ·æœ¬ï¼Œæ€§èƒ½è¿›ä¸€æ­¥å¾—åˆ°æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ³›åŒ–æ€§èƒ½æºäºè®­ç»ƒç³»ç»Ÿçš„å¤šæ ·æ€§ï¼Œè€Œéå¤§é‡æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ChaosNexusæ˜¯ä¸€ç§ç”¨äºé¢„æµ‹æ··æ²Œç³»ç»Ÿçš„é€šç”¨æ¨¡å‹ï¼Œé€‚ç”¨äºå¤©æ°”é¢„æŠ¥å’Œæµä½“åŠ¨åŠ›å­¦ç­‰é¢†åŸŸã€‚</li>
<li>ä¼ ç»Ÿå»ºæ¨¡æ–¹æ³•å—åˆ°åˆå§‹æ¡ä»¶æ•æ„Ÿæ€§å’Œè§‚æµ‹æ•°æ®ç¨€ç¼ºæ€§çš„é™åˆ¶ï¼Œéš¾ä»¥åº”ç”¨äºç°å®ä¸–ç•Œçš„å¤æ‚åœºæ™¯ã€‚</li>
<li>ChaosNexusé€šè¿‡é¢„è®­ç»ƒåœ¨å¤šæ ·æ··æ²ŒåŠ¨æ€è¯­æ–™åº“ä¸Šï¼Œé‡‡ç”¨æ–°å‹çš„å¤šå°ºåº¦æ¶æ„ScaleFormerå’Œæ··åˆä¸“å®¶å±‚æ¥æ•æ‰é€šç”¨æ¨¡å¼å’Œç³»ç»Ÿç‰¹å®šè¡Œä¸ºã€‚</li>
<li>è¯¥æ¨¡å‹å®ç°äº†é›¶æ ·æœ¬æ³›åŒ–çš„æœ€æ–°æ°´å¹³ï¼Œåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>åœ¨å¤§è§„æ¨¡æµ‹è¯•åºŠä¸Šï¼Œä¸é¢†å…ˆçš„åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒChaosNexusé•¿æœŸå¸å¼•ç»Ÿè®¡é‡çš„ä¿çœŸåº¦æé«˜äº†è¶…è¿‡40%ã€‚</li>
<li>ChaosNexusåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­è¡¨ç°å‡ºæé«˜çš„æ•°æ®æ•ˆç‡ï¼Œä¾‹å¦‚åœ¨å…¨çƒå¤©æ°”é¢„æµ‹ä¸­å®ç°äº†ä¼˜ç§€çš„é›¶æ ·æœ¬é¢„æµ‹æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21802">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a0ecc1f2b446001df5ec5f85cb47f25a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061185&auth_key=1760061185-0-0-3892e535e8ebc480d0e527a0bf231c83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6a72f9b009a9cca836259c092468fd1f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061193&auth_key=1760061193-0-0-3c5b31809dceb34432e5d0e798e7f5cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b1e9c65c1a6ee693451d6cd33b742cda~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061199&auth_key=1760061199-0-0-64f9e7f2326d40e9136783fe5f933ea0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Vision-Language-Models-Cannot-Plan-but-Can-They-Formalize"><a href="#Vision-Language-Models-Cannot-Plan-but-Can-They-Formalize" class="headerlink" title="Vision Language Models Cannot Plan, but Can They Formalize?"></a>Vision Language Models Cannot Plan, but Can They Formalize?</h2><p><strong>Authors:Muyu He, Yuxi Zheng, Yuchen Liu, Zijian An, Bill Cai, Jiani Huang, Lifeng Zhou, Feng Liu, Ziyang Li, Li Zhang</strong></p>
<p>The advancement of vision language models (VLMs) has empowered embodied agents to accomplish simple multimodal planning tasks, but not long-horizon ones requiring long sequences of actions. In text-only simulations, long-horizon planning has seen significant improvement brought by repositioning the role of LLMs. Instead of directly generating action sequences, LLMs translate the planning domain and problem into a formal planning language like the Planning Domain Definition Language (PDDL), which can call a formal solver to derive the plan in a verifiable manner. In multimodal environments, research on VLM-as-formalizer remains scarce, usually involving gross simplifications such as predefined object vocabulary or overly similar few-shot examples. In this work, we present a suite of five VLM-as-formalizer pipelines that tackle one-shot, open-vocabulary, and multimodal PDDL formalization. We evaluate those on an existing benchmark while presenting another two that for the first time account for planning with authentic, multi-view, and low-quality images. We conclude that VLM-as-formalizer greatly outperforms end-to-end plan generation. We reveal the bottleneck to be vision rather than language, as VLMs often fail to capture an exhaustive set of necessary object relations. While generating intermediate, textual representations such as captions or scene graphs partially compensate for the performance, their inconsistent gain leaves headroom for future research directions on multimodal planning formalization. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è¿›æ­¥ä½¿å¾—å®ä½“ä»£ç†èƒ½å¤Ÿå®Œæˆç®€å•çš„å¤šæ¨¡æ€è§„åˆ’ä»»åŠ¡ï¼Œä½†è¿˜ä¸èƒ½å®Œæˆéœ€è¦ä¸€ç³»åˆ—é•¿æœŸè¡ŒåŠ¨çš„ä»»åŠ¡ã€‚åœ¨ä»…æ–‡æœ¬æ¨¡æ‹Ÿä¸­ï¼Œé•¿æœŸè§„åˆ’åœ¨é‡æ–°å®šä½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§’è‰²åå–å¾—äº†é‡å¤§æ”¹è¿›ã€‚LLMä¸ç›´æ¥ç”Ÿæˆè¡ŒåŠ¨åºåˆ—ï¼Œè€Œæ˜¯å°†è§„åˆ’é¢†åŸŸå’Œé—®é¢˜è½¬åŒ–ä¸ºæ­£å¼çš„è§„åˆ’è¯­è¨€ï¼ˆå¦‚è§„åˆ’é¢†åŸŸå®šä¹‰è¯­è¨€ï¼ˆPDDLï¼‰ï¼‰ï¼Œè¿™æ ·å¯ä»¥è°ƒç”¨å½¢å¼åŒ–æ±‚è§£å™¨ä»¥å¯éªŒè¯çš„æ–¹å¼åˆ¶å®šè®¡åˆ’ã€‚åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­ï¼Œå…³äºVLMä½œä¸ºå½¢å¼åŒ–å™¨çš„ç ”ç©¶ä»ç„¶å¾ˆå°‘ï¼Œé€šå¸¸æ¶‰åŠç²—ç•¥ç®€åŒ–ï¼Œä¾‹å¦‚é¢„è®¾å¯¹è±¡è¯æ±‡æˆ–è¿‡äºç›¸ä¼¼çš„å°‘æ•°æ¡ˆä¾‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†äº”ä¸ªVLMä½œä¸ºå½¢å¼åŒ–å™¨çš„ç®¡é“ï¼Œè§£å†³å•é•œå¤´ã€å¼€æ”¾è¯æ±‡å’Œå¤šæ¨¡æ€PDDLå½¢å¼åŒ–é—®é¢˜ã€‚æˆ‘ä»¬åœ¨ç°æœ‰çš„åŸºå‡†æµ‹è¯•ä¸­å¯¹è¿™äº›è¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒæ—¶æå‡ºäº†å¦å¤–ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ï¼Œé¦–æ¬¡è€ƒè™‘ä½¿ç”¨çœŸå®ã€å¤šè§†è§’å’Œä½è´¨é‡çš„å›¾åƒè¿›è¡Œè§„åˆ’ã€‚æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼ŒVLMä½œä¸ºå½¢å¼åŒ–å™¨å¤§å¤§ä¼˜äºç«¯åˆ°ç«¯çš„è®¡åˆ’ç”Ÿæˆã€‚æˆ‘ä»¬å‘ç°ç“¶é¢ˆåœ¨äºè§†è§‰è€Œéè¯­è¨€ï¼Œå› ä¸ºVLMé€šå¸¸æ— æ³•æ•è·å¿…è¦çš„å¯¹è±¡å…³ç³»çš„å®Œæ•´é›†åˆã€‚è™½ç„¶ç”Ÿæˆä¸­é—´æ–‡æœ¬è¡¨ç¤ºï¼ˆå¦‚æ ‡é¢˜æˆ–åœºæ™¯å›¾ï¼‰éƒ¨åˆ†å¼¥è¡¥äº†æ€§èƒ½ä¸è¶³ï¼Œä½†å…¶ä¸ä¸€è‡´çš„å¢ç›Šä¸ºæœªæ¥å¤šæ¨¡æ€è§„åˆ’å½¢å¼åŒ–çš„ç ”ç©¶æ–¹å‘ç•™ä¸‹äº†ç©ºé—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21576v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åº”ç”¨äºå½¢å¼åŒ–è§„åˆ’çš„æ–¹æ³•ï¼Œè§£å†³åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸‹è¿›è¡Œé•¿æœŸè§„åˆ’çš„é—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸€å¥—äº”ä¸ªVLM-as-formalizerç®¡é“ï¼Œå®ç°äº†ä¸€æ¬¡æ€§ã€å¼€æ”¾è¯æ±‡å’Œå¤šæ¨¡æ€çš„PDDLå½¢å¼åŒ–ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒVLM-as-formalizeråœ¨è§„åˆ’ç”Ÿæˆæ–¹é¢è¡¨ç°ä¼˜äºç«¯åˆ°ç«¯æ–¹æ³•ã€‚ç“¶é¢ˆåœ¨äºè§†è§‰è€Œéè¯­è¨€ï¼Œå› ä¸ºVLMså¾€å¾€æ— æ³•æ•æ‰æ‰€æœ‰å¿…è¦çš„å¯¹è±¡å…³ç³»ã€‚è™½ç„¶ç”Ÿæˆä¸­é—´æ–‡æœ¬è¡¨ç¤ºï¼ˆå¦‚æ ‡é¢˜æˆ–åœºæ™¯å›¾ï¼‰å¯ä»¥éƒ¨åˆ†å¼¥è¡¥æ€§èƒ½ä¸è¶³ï¼Œä½†å…¶ä¸ä¸€è‡´çš„å¢ç›Šä¸ºæœªæ¥å¤šæ¨¡æ€è§„åˆ’å½¢å¼åŒ–çš„ç ”ç©¶æ–¹å‘ç•™ä¸‹äº†ç©ºé—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLMsçš„è¿›æ­¥ä½¿å¾—å®ä½“ä»£ç†èƒ½å¤Ÿå®Œæˆç®€å•çš„å¤šæ¨¡æ€è§„åˆ’ä»»åŠ¡ï¼Œä½†å¯¹äºéœ€è¦é•¿æœŸåºåˆ—åŠ¨ä½œçš„é•¿è¿œè§„åˆ’ä»»åŠ¡ä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>åœ¨æ–‡æœ¬æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼ŒLLMsåœ¨é•¿è¿œè§„åˆ’æ–¹é¢çš„ä½œç”¨è¢«é‡æ–°å®šä½ï¼Œé€šè¿‡å°†è§„åˆ’é¢†åŸŸå’Œé—®é¢˜è½¬åŒ–ä¸ºæ­£å¼çš„è§„åˆ’è¯­è¨€ï¼ˆå¦‚PDDLï¼‰ï¼Œå†è°ƒç”¨æ­£å¼çš„æ±‚è§£å™¨ä»¥å¯éªŒè¯çš„æ–¹å¼æ¨å¯¼è®¡åˆ’ã€‚</li>
<li>åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­ï¼Œå…³äºVLM-as-formalizerçš„ç ”ç©¶ä»ç„¶ç¨€ç¼ºï¼Œå­˜åœ¨è¯¸å¦‚é¢„è®¾å¯¹è±¡è¯æ±‡æˆ–è¿‡äºç›¸ä¼¼çš„å°‘æ•°æ¡ˆä¾‹ç­‰ç®€åŒ–æƒ…å†µã€‚</li>
<li>ç ”ç©¶æå‡ºäº†äº”ä¸ªVLM-as-formalizerç®¡é“ï¼Œè§£å†³äº†ä¸€æ¬¡æ€§ã€å¼€æ”¾è¯æ±‡å’Œå¤šæ¨¡æ€çš„PDDLå½¢å¼åŒ–é—®é¢˜ã€‚</li>
<li>è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒVLM-as-formalizeråœ¨è§„åˆ’ç”Ÿæˆæ–¹é¢ä¼˜äºç«¯åˆ°ç«¯æ–¹æ³•ã€‚</li>
<li>VLMsçš„ç“¶é¢ˆåœ¨äºè§†è§‰èƒ½åŠ›ï¼Œå¾€å¾€æ— æ³•æ•æ‰æ‰€æœ‰å¿…è¦çš„å¯¹è±¡å…³ç³»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21576">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a987685bbcfbc143c88b6dfcbc7c1bcc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061207&auth_key=1760061207-0-0-e8145c89356beb76a82402e4455d2327&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8ebe0aee94eb5b49b7e15dd0e06117cf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061214&auth_key=1760061214-0-0-e0a8d4986d436330117c38647f483d92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-58cc4ae00f02b3f0548f045cd6845aca~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061221&auth_key=1760061221-0-0-b996bae73f4224c6579bb3c8ab8b9e1a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-78624c3815c2692d3a74f0b6c0b6fe4d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061228&auth_key=1760061228-0-0-35445df449e0cd7255dcb23853a13afb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="pFedMMA-Personalized-Federated-Fine-Tuning-with-Multi-Modal-Adapter-for-Vision-Language-Models"><a href="#pFedMMA-Personalized-Federated-Fine-Tuning-with-Multi-Modal-Adapter-for-Vision-Language-Models" class="headerlink" title="pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for   Vision-Language Models"></a>pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for   Vision-Language Models</h2><p><strong>Authors:Sajjad Ghiasvand, Mahnoosh Alizadeh, Ramtin Pedarsani</strong></p>
<p>Vision-Language Models (VLMs) like CLIP have demonstrated remarkable generalization in zero- and few-shot settings, but adapting them efficiently to decentralized, heterogeneous data remains a challenge. While prompt tuning has emerged as a popular parameter-efficient approach in personalized federated learning, existing methods often sacrifice generalization in favor of personalization, struggling particularly on unseen classes or domains. In this work, we propose pFedMMA, the first personalized federated learning framework that leverages multi-modal adapters for vision-language tasks. Each adapter contains modality-specific up- and down-projection layers alongside a globally shared projection that aligns cross-modal features. Our optimization strategy allows clients to locally adapt to personalized data distributions while collaboratively training the shared projection to improve global generalization. This design is also communication-efficient, as only the shared component is exchanged during communication rounds. Through extensive experiments across eleven datasets, including domain- and label-shift scenarios, we show that pFedMMA achieves state-of-the-art trade-offs between personalization and generalization, outperforming recent federated prompt tuning methods. </p>
<blockquote>
<p>å¯¹äºCLIPç­‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è€Œè¨€ï¼Œå®ƒä»¬åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç¯å¢ƒä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨åˆ†æ•£ã€å¼‚æ„æ•°æ®ä¸Šæœ‰æ•ˆåœ°é€‚åº”å®ƒä»¬ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è™½ç„¶æç¤ºè°ƒæ•´ï¼ˆprompt tuningï¼‰ä½œä¸ºä¸€ç§ä¸ªæ€§åŒ–çš„è”é‚¦å­¦ä¹ ä¸­çš„å‚æ•°é«˜æ•ˆæ–¹æ³•å·²ç»å´­éœ²å¤´è§’ï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€ç‰ºç‰²æ³›åŒ–èƒ½åŠ›ä»¥æ¢å–ä¸ªæ€§åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æœªè§ç±»åˆ«æˆ–é¢†åŸŸä¸Šè¡¨ç°å°¤ä¸ºå›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†pFedMMAï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåˆ©ç”¨å¤šæ¨¡æ€é€‚é…å™¨çš„ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè§†è§‰è¯­è¨€ä»»åŠ¡ã€‚æ¯ä¸ªé€‚é…å™¨åŒ…å«ç‰¹å®šæ¨¡æ€çš„ä¸Šä¸‹æŠ•å½±å±‚ä»¥åŠä¸€ä¸ªå…¨å±€å…±äº«æŠ•å½±ï¼Œç”¨äºå¯¹é½è·¨æ¨¡æ€ç‰¹å¾ã€‚æˆ‘ä»¬çš„ä¼˜åŒ–ç­–ç•¥å…è®¸å®¢æˆ·ç«¯é€‚åº”ä¸ªæ€§åŒ–çš„æ•°æ®åˆ†å¸ƒï¼ŒåŒæ—¶è®­ç»ƒå…±äº«æŠ•å½±ä»¥æé«˜å…¨å±€æ³›åŒ–èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡è¿˜å…·æœ‰é€šä¿¡æ•ˆç‡é«˜çš„ä¼˜ç‚¹ï¼Œå› ä¸ºé€šä¿¡è½®æœŸé—´åªäº¤æ¢å…±äº«ç»„ä»¶ã€‚é€šè¿‡æ¶µç›–åŒ…æ‹¬é¢†åŸŸå’Œæ ‡ç­¾è½¬ç§»åœºæ™¯åœ¨å†…çš„åä¸€ä¸ªæ•°æ®é›†çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†pFedMMAåœ¨ä¸ªæ€§åŒ–å’Œæ³›åŒ–ä¹‹é—´è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æƒè¡¡ï¼Œè¶…è¶Šäº†æœ€æ–°çš„è”é‚¦æç¤ºè°ƒæ•´æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05394v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºCLIPç­‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åœºæ™¯ä¸‹çš„å‡ºè‰²æ³›åŒ–èƒ½åŠ›ï¼Œæœ¬å·¥ä½œæå‡ºpFedMMAï¼Œä¸€ä¸ªåˆ©ç”¨å¤šæ¨¡æ€é€‚é…å™¨çš„ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹åˆ†å¸ƒå¼å¼‚æ„æ•°æ®çš„é€‚åº”æ•ˆç‡é—®é¢˜ã€‚pFedMMAé€šè¿‡ä¼˜åŒ–ç­–ç•¥å®ç°æœ¬åœ°ä¸ªæ€§åŒ–æ•°æ®åˆ†å¸ƒçš„é€‚åº”ï¼ŒåŒæ—¶ååŒè®­ç»ƒå…±äº«æŠ•å½±å±‚ä»¥æå‡å…¨å±€æ³›åŒ–èƒ½åŠ›ã€‚è¯¥è®¾è®¡å…·æœ‰é€šä¿¡æ•ˆç‡ä¼˜åŠ¿ï¼Œä»…äº¤æ¢å…±äº«ç»„ä»¶ã€‚å®éªŒæ˜¾ç¤ºï¼ŒpFedMMAåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†ä¸ªæ€§åŒ–ä¸æ³›åŒ–ä¹‹é—´çš„æœ€ä½³å¹³è¡¡ï¼Œä¼˜äºç°æœ‰çš„è”é‚¦æç¤ºè°ƒæ•´æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>pFedMMAæ˜¯é¦–ä¸ªé’ˆå¯¹è§†è§‰è¯­è¨€ä»»åŠ¡åˆ©ç”¨å¤šæ¨¡æ€é€‚é…å™¨çš„ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ æ¡†æ¶ã€‚</li>
<li>pFedMMAç»“åˆä¸ªæ€§åŒ–æ•°æ®åˆ†å¸ƒé€‚åº”å’Œå…¨å±€æ³›åŒ–èƒ½åŠ›çš„æå‡ã€‚</li>
<li>å¤šæ¨¡æ€é€‚é…å™¨åŒ…å«é’ˆå¯¹ç‰¹å®šæ¨¡æ€çš„ä¸Šä¸‹æŠ•å½±å±‚åŠå…¨å±€å…±äº«æŠ•å½±å±‚ï¼Œç”¨äºå¯¹é½è·¨æ¨¡æ€ç‰¹å¾ã€‚</li>
<li>pFedMMAçš„ä¼˜åŒ–ç­–ç•¥å…è®¸æœ¬åœ°ä¸ªæ€§åŒ–è°ƒæ•´ï¼ŒåŒæ—¶ååŒè®­ç»ƒå…±äº«æŠ•å½±å±‚ã€‚</li>
<li>pFedMMAè®¾è®¡é€šä¿¡æ•ˆç‡é«˜ï¼Œä»…äº¤æ¢å…±äº«ç»„ä»¶ã€‚</li>
<li>å®éªŒè¯æ˜pFedMMAåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†ä¸ªæ€§åŒ–ä¸æ³›åŒ–çš„æœ€ä½³å¹³è¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05394">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e8eac8303a87cbbdc50a2c07e2562345~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061237&auth_key=1760061237-0-0-666d88d81eff8a5633aeed65b20a0880&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b32d232ffea92e26a37a7c79e04606ca~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061244&auth_key=1760061244-0-0-e7b1a7a30387fafea85eff65a4d9b9fd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9640312117cf9c7f84da03282e2c369c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061252&auth_key=1760061252-0-0-861ac7aa57806a4ab1fa72fd01ab1911&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Intercept-Cancer-Cancer-Pre-Screening-with-Large-Scale-Healthcare-Foundation-Models"><a href="#Intercept-Cancer-Cancer-Pre-Screening-with-Large-Scale-Healthcare-Foundation-Models" class="headerlink" title="Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare   Foundation Models"></a>Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare   Foundation Models</h2><p><strong>Authors:Liwen Sun, Hao-Ren Yao, Gary Gao, Ophir Frieder, Chenyan Xiong</strong></p>
<p>Cancer screening, leading to early detection, saves lives. Unfortunately, existing screening techniques require expensive and intrusive medical procedures, not globally available, resulting in too many lost would-be-saved lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation Models, a cancer pre-screening methodology that identifies high-risk patients for further screening solely based on their historical medical records. With millions of electronic healthcare records (EHR), we establish the scaling law of EHR foundation models pretrained on medical code sequences, pretrain compute-optimal foundation models of up to 2.4 billion parameters, and finetune them on clinician-curated cancer risk prediction cohorts. In our retrospective evaluation comprising of thirty thousand patients, CATCH-FM achieves strong efficacy, with 50% sensitivity in predicting first cancer risks at 99% specificity cutoff, and outperforming feature-based tree models and both general and medical LLMs by up to 20% AUPRC. Despite significant demographic, healthcare system, and EHR coding differences, CATCH-FM achieves state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot leaderboard, outperforming EHR foundation models pretrained using on-site patient data. Our analysis demonstrates the robustness of CATCH-FM in various patient distributions, the benefits of operating in the ICD code space, and its ability to capture non-trivial cancer risk factors. Our code will be open-sourced. </p>
<blockquote>
<p>ç™Œç—‡ç­›æŸ¥èƒ½å¤Ÿå®ç°æ—©æœŸå‘ç°ï¼Œä»è€ŒæŒ½æ•‘ç”Ÿå‘½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç­›æŸ¥æŠ€æœ¯éœ€è¦æ˜‚è´µä¸”ä¾µå…¥æ€§çš„åŒ»ç–—ç¨‹åºï¼Œå¹¶éå…¨çƒé€šç”¨ï¼Œå¯¼è‡´è®¸å¤šæœ¬å¯æŒ½æ•‘çš„ç”Ÿå‘½ä¸§å¤±ã€‚æˆ‘ä»¬æå‡ºCATCH-FMï¼Œå³ä½¿ç”¨åŒ»ç–—åŸºç¡€æ¨¡å‹æ—©æœŸå‘ç°ç™Œç—‡ï¼ˆCATch Cancer early with Healthcare Foundation Modelsï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç™Œç—‡é¢„ç­›æŸ¥æ–¹æ³•ï¼Œä»…åŸºäºæ‚£è€…çš„å†å²åŒ»ç–—è®°å½•è¯†åˆ«å‡ºéœ€è¦è¿›è¡Œè¿›ä¸€æ­¥ç­›æŸ¥çš„é«˜é£é™©æ‚£è€…ã€‚æˆ‘ä»¬åˆ©ç”¨æ•°ç™¾ä¸‡ä»½ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰ï¼Œå»ºç«‹åŸºäºåŒ»ç–—ä»£ç åºåˆ—çš„EHRåŸºç¡€æ¨¡å‹çš„å¯æ‰©å±•æ€§æ³•åˆ™ï¼Œè®­ç»ƒå‚æ•°é«˜è¾¾2.4äº¿çš„é¢„è®­ç»ƒä¼˜åŒ–åŸºç¡€æ¨¡å‹ï¼Œå¹¶åœ¨åŒ»ç”Ÿç­–åˆ’çš„ç™Œç—‡é£é™©é¢„æµ‹é˜Ÿåˆ—ä¸­è¿›è¡Œå¾®è°ƒã€‚åœ¨æˆ‘ä»¬çš„åŒ…å«ä¸‰ä¸‡åæ‚£è€…çš„å›é¡¾æ€§è¯„ä¼°ä¸­ï¼ŒCATCH-FMè¡¨ç°å‡ºå¼ºå¤§çš„æœ‰æ•ˆæ€§ï¼Œåœ¨99%çš„ç‰¹å¼‚æ€§æˆªæ­¢å€¼ä¸‹ï¼Œé¢„æµ‹é¦–æ¬¡ç™Œç—‡é£é™©çš„æ•æ„Ÿæ€§è¾¾åˆ°50%ï¼Œå¹¶ä¸”ç›¸è¾ƒäºåŸºäºç‰¹å¾æ ‘æ¨¡å‹å’Œä¸€èˆ¬åŠåŒ»ç–—é¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œåœ¨æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUPRCï¼‰ä¸Šé«˜å‡ºæœ€å¤šè¾¾20%ã€‚å°½ç®¡å­˜åœ¨æ˜¾è‘—çš„ç§æ—ã€åŒ»ç–—ä¿å¥ç³»ç»Ÿå’ŒEHRç¼–ç å·®å¼‚ï¼ŒCATCH-FMåœ¨EHRSHOTå°‘æ ·æœ¬é¢†å¯¼è€…æ¦œä¸Šå®ç°äº†èƒ°è…ºç™Œé£é™©é¢„æµ‹çš„ä¸šç•Œé¢†å…ˆæ°´å¹³ï¼Œä¼˜äºä½¿ç”¨ç°åœºæ‚£è€…æ•°æ®é¢„è®­ç»ƒçš„EHRåŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬çš„åˆ†æè¯æ˜äº†CATCH-FMåœ¨å„ç§æ‚£è€…åˆ†å¸ƒä¸­çš„ç¨³å¥æ€§ã€åœ¨ICDä»£ç ç©ºé—´å†…æ“ä½œçš„ä¼˜åŠ¿ä»¥åŠæ•æ‰éæ˜¾è‘—æ€§ç™Œç—‡é£é™©å› ç´ çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å°†å¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00209v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå†å²åŒ»ç–—è®°å½•æ•°æ®ï¼Œæå‡ºä¸€ç§åä¸ºCATCH-FMçš„ç™Œç—‡é¢„ç­›æŸ¥æ–¹æ³•ï¼Œç”¨äºæ—©æœŸå‘ç°ç™Œç—‡é£é™©æ‚£è€…å¹¶æ¨èç»™è¿›ä¸€æ­¥çš„ç­›æŸ¥ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æ•°æ®å»ºç«‹åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡è®­ç»ƒè®¡ç®—ä¼˜åŒ–æ¨¡å‹ï¼Œå¹¶åœ¨åŒ»ç”Ÿæ•´ç†çš„é£é™©é¢„æµ‹é˜Ÿåˆ—ä¸­è¿›è¡Œå¾®è°ƒã€‚åœ¨åŒ…å«ä¸‰ä¸‡åæ‚£è€…çš„å›é¡¾æ€§è¯„ä¼°ä¸­ï¼ŒCATCH-FMå±•ç°å‡ºå¼ºå¤§çš„æ•ˆèƒ½ï¼Œå¯¹é¦–æ¬¡ç™Œç—‡é£é™©çš„é¢„æµ‹å…·æœ‰é«˜è¾¾50%çš„æ•æ„Ÿåº¦å’Œå‡ºè‰²çš„ç‰¹å¼‚æ€§ï¼Œä¸”åœ¨èƒ°è…ºç™Œé£é™©é¢„æµ‹æ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚CATCH-FMå…·æœ‰åœ¨å„ç§æ‚£è€…åˆ†å¸ƒä¸­çš„ç¨³å¥æ€§ï¼Œå¹¶å±•ç°å‡ºæ•æ‰éæ˜¾è‘—ç™Œç—‡é£é™©å› ç´ çš„èƒ½åŠ›ã€‚ä»£ç å°†å¼€æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CATCH-FMæ˜¯ä¸€ç§åŸºäºå†å²åŒ»ç–—è®°å½•çš„ç™Œç—‡é¢„ç­›æŸ¥æ–¹æ³•ï¼Œæ—©æœŸè¯†åˆ«é«˜é£é™©çš„ç™Œç—‡æ‚£è€…ä»¥ä¾›è¿›ä¸€æ­¥ç­›æŸ¥ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æ•°æ®å»ºç«‹åŸºç¡€æ¨¡å‹ï¼Œå¹¶é€šè¿‡è®¡ç®—ä¼˜åŒ–è¿›è¡Œè®­ç»ƒã€‚</li>
<li>CATCH-FMåœ¨å›é¡¾æ€§è¯„ä¼°ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ•ˆèƒ½ï¼Œå¯¹é¦–æ¬¡ç™Œç—‡é£é™©çš„é¢„æµ‹å…·æœ‰é«˜æ•æ„Ÿåº¦å’Œç‰¹å¼‚æ€§ã€‚</li>
<li>CATCH-FMåœ¨èƒ°è…ºç™Œé£é™©é¢„æµ‹æ–¹é¢è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ï¼Œå±•ç°å‡ºåœ¨å„ç§æ‚£è€…åˆ†å¸ƒä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>CATCH-FMå…·æœ‰æ•æ‰éæ˜¾è‘—ç™Œç—‡é£é™©å› ç´ çš„èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00209">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-eb6a67a1c1ce63c43b73469445dc6528~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061259&auth_key=1760061259-0-0-01745bb373bc7960f3b69add7c338f9c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1ff56c7f7bcbae0023e86492e773fe28~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061267&auth_key=1760061267-0-0-abbbb4ab7bb2cd15af71d04481ea0725&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-af3ae5e0748f75600133aaee9d6dc014~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061274&auth_key=1760061274-0-0-b8ba184a7fa1611c44aa228d31c756f8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a7901f4c6589304f3e8bf9dfc3240416~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061280&auth_key=1760061280-0-0-b5b57c8350dd8bd32b6e1772cf197dfe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Few-Shot-Adversarial-Low-Rank-Fine-Tuning-of-Vision-Language-Models"><a href="#Few-Shot-Adversarial-Low-Rank-Fine-Tuning-of-Vision-Language-Models" class="headerlink" title="Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models"></a>Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models</h2><p><strong>Authors:Sajjad Ghiasvand, Haniyeh Ehsani Oskouie, Mahnoosh Alizadeh, Ramtin Pedarsani</strong></p>
<p>Vision-Language Models (VLMs) such as CLIP have shown remarkable performance in cross-modal tasks through large-scale contrastive pre-training. To adapt these large transformer-based models efficiently for downstream tasks, Parameter-Efficient Fine-Tuning (PEFT) techniques like (Low-Rank Adaptation) LoRA have emerged as scalable alternatives to full fine-tuning, especially in few-shot scenarios. However, like traditional deep neural networks, VLMs are highly vulnerable to adversarial attacks, where imperceptible perturbations can significantly degrade model performance. Adversarial training remains the most effective strategy for improving model robustness in PEFT. In this work, we propose AdvCLIP-LoRA, to our knowledge the first method designed to enhance the adversarial robustness of CLIP models fine-tuned with LoRA in few-shot settings. Our method formulates training as a minimax optimization over low-rank adapters and adversarial perturbations, enabling robust adaptation with a small trainable footprint. Across eight datasets and two backbones (ViT-B&#x2F;16 and ViT-B&#x2F;32), AdvCLIP-LoRA achieves state-of-the-art performance in few-shot classification, adversarial base-to-new generalization, and cross-dataset transfer, delivering higher adversarial robustness than prompt tuning baselines without sacrificing much clean accuracy. These findings highlight AdvCLIP-LoRA as a practical approach for robust adaptation of VLMs in resource-constrained settings. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡å¯¹æ¯”é¢„è®­ç»ƒï¼ŒCLIPç­‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è·¨æ¨¡æ€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å°†è¿™äº›åŸºäºå˜å‹å™¨çš„çš„å¤§å‹æ¨¡å‹é€‚åº”åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼Œå‡ºç°äº†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ï¼Œå¦‚LoRAï¼ˆä½ç§©é€‚åº”ï¼‰ç­‰ï¼Œå¯ä½œä¸ºå…¨å¾®è°ƒçš„å¯æ‰©å±•æ›¿ä»£æ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ ·æœ¬åœºæ™¯ä¸­ã€‚ç„¶è€Œï¼Œä¸ä¼ ç»Ÿçš„æ·±åº¦ç¥ç»ç½‘ç»œä¸€æ ·ï¼ŒVLMséå¸¸å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼Œå¾®å°çš„ä¸å¯å¯Ÿè§‰çš„æ‰°åŠ¨ä¹Ÿå¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚å¯¹æŠ—æ€§è®­ç»ƒä»ç„¶æ˜¯PEFTä¸­æé«˜æ¨¡å‹ç¨³å¥æ€§çš„æœ€æœ‰æ•ˆç­–ç•¥ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†AdvCLIP-LoRAï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ç§æ—¨åœ¨æé«˜åœ¨LoRAå¾®è°ƒä¸‹å°æ ·æœ¬è®¾ç½®ä¸­CLIPæ¨¡å‹çš„å¯¹æŠ—æ€§ç¨³å¥æ€§çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†è®­ç»ƒåˆ¶å®šä¸ºä½ç§©é€‚é…å™¨å’Œå¯¹æŠ—æ€§æ‰°åŠ¨ä¹‹é—´çš„æœ€å°æœ€å¤§ä¼˜åŒ–é—®é¢˜ï¼Œä»¥è¾ƒå°çš„å¯è®­ç»ƒè¶³è¿¹å®ç°äº†ç¨³å¥çš„é€‚é…ã€‚åœ¨å…«ä¸ªæ•°æ®é›†å’Œä¸¤ä¸ªä¸»å¹²ç½‘ç»œï¼ˆViT-B&#x2F;16å’ŒViT-B&#x2F;32ï¼‰ä¸Šï¼ŒAdvCLIP-LoRAåœ¨å°‘æ ·æœ¬åˆ†ç±»ã€å¯¹æŠ—æ€§åŸºæœ¬åˆ°æ–°çš„æ³›åŒ–ä»¥åŠè·¨æ•°æ®é›†ä¼ è¾“æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ä¸å¦¨ç¢æ¸…æ´å‡†ç¡®åº¦çš„å‰æä¸‹æé«˜äº†å¯¹æŠ—æ€§ç¨³å¥æ€§ã€‚è¿™äº›å‘ç°çªå‡ºäº†AdvCLIP-LoRAåœ¨èµ„æºå—é™ç¯å¢ƒä¸­ç¨³å¥é€‚åº”VLMsçš„å®é™…ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15130v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†é’ˆå¯¹å¤§å‹è·¨æ¨¡æ€ä»»åŠ¡ä¸­é¢„è®­ç»ƒçš„CLIPæ¨¡å‹çš„é²æ£’æ€§é—®é¢˜ï¼Œæå‡ºä¸€ç§æ–°å‹çš„å¢å¼ºæ–¹æ³•AdvCLIP-LoRAã€‚æ­¤æ–¹æ³•åœ¨ä½ç§©é€‚é…å™¨å¯¹æŠ—æ‰°åŠ¨å’Œæœ€å°åŒ–æœ€åç»“æœçš„åŸºç¡€ä¸Šè¿›è¡Œä¼˜åŒ–è®­ç»ƒï¼Œæé«˜äº†CLIPæ¨¡å‹åœ¨å°‘æ ·æœ¬ç¯å¢ƒä¸‹çš„å¯¹æŠ—é²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAdvCLIP-LoRAåœ¨å¤šä¸ªæ•°æ®é›†å’Œä¸¤ç§ä¸åŒæ¶æ„ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨ä¸ç‰ºç‰²æ¸…æ´ç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†å¯¹åŸºçº¿æç¤ºè°ƒä¼˜çš„é«˜å¯¹æŠ—é²æ£’æ€§ã€‚è¿™ä¸€å‘ç°ä½¿å¾—AdvCLIP-LoRAæˆä¸ºèµ„æºå—é™ç¯å¢ƒä¸­å®ç°VLMç¨³å¥é€‚åº”çš„ä¸€ç§å®ç”¨æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Vision-Language Models (VLMs) å¦‚CLIPåœ¨è·¨æ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>ä¸ºäº†é«˜æ•ˆé€‚åº”ä¸‹æ¸¸ä»»åŠ¡ï¼Œå‡ºç°äº†ä¸€ç§å‚æ•°æœ‰æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œå¦‚ä½ç§©è‡ªé€‚åº”ï¼ˆLoRAï¼‰ã€‚å°¤å…¶åœ¨å°‘æ ·æœ¬åœºæ™¯ä¸­ã€‚</li>
<li>å°½ç®¡å¼ºå¤§ï¼Œä½†VLMå¯¹å¯¹æŠ—æ”»å‡»é«˜åº¦æ•æ„Ÿï¼Œå¾®å°çš„æ‰°åŠ¨å¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚å¯¹æŠ—è®­ç»ƒæ˜¯æé«˜æ¨¡å‹é²æ£’æ€§çš„æœ‰æ•ˆç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8f05d89fd417ec3758b173a800037303~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061287&auth_key=1760061287-0-0-3e136b8e3b4936671442d4dd765797a7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-433fe95458055515b05350d52850178d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061295&auth_key=1760061295-0-0-6bc62ee69e5cb290dab8803c3059dba2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bdb22bf802247ee23a16a7863c35ef46~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061301&auth_key=1760061301-0-0-fc41d8fb29733f6b5b9aa2267607df4b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Texture-or-Semantics-Vision-Language-Models-Get-Lost-in-Font-Recognition"><a href="#Texture-or-Semantics-Vision-Language-Models-Get-Lost-in-Font-Recognition" class="headerlink" title="Texture or Semantics? Vision-Language Models Get Lost in Font   Recognition"></a>Texture or Semantics? Vision-Language Models Get Lost in Font   Recognition</h2><p><strong>Authors:Zhecheng Li, Guoxian Song, Yujun Cai, Zhen Xiong, Junsong Yuan, Yiwei Wang</strong></p>
<p>Modern Vision-Language Models (VLMs) exhibit remarkable visual and linguistic capabilities, achieving impressive performance in various tasks such as image recognition and object localization. However, their effectiveness in fine-grained tasks remains an open question. In everyday scenarios, individuals encountering design materials, such as magazines, typography tutorials, research papers, or branding content, may wish to identify aesthetically pleasing fonts used in the text. Given their multimodal capabilities and free accessibility, many VLMs are often considered potential tools for font recognition. This raises a fundamental question: Do VLMs truly possess the capability to recognize fonts? To investigate this, we introduce the Font Recognition Benchmark (FRB), a compact and well-structured dataset comprising 15 commonly used fonts. FRB includes two versions: (i) an easy version, where 10 sentences are rendered in different fonts, and (ii) a hard version, where each text sample consists of the names of the 15 fonts themselves, introducing a stroop effect that challenges model perception. Through extensive evaluation of various VLMs on font recognition tasks, we arrive at the following key findings: (i) Current VLMs exhibit limited font recognition capabilities, with many state-of-the-art models failing to achieve satisfactory performance and being easily affected by the stroop effect introduced by textual information. (ii) Few-shot learning and Chain-of-Thought (CoT) prompting provide minimal benefits in improving font recognition accuracy across different VLMs. (iii) Attention analysis sheds light on the inherent limitations of VLMs in capturing semantic features. </p>
<blockquote>
<p>ç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å±•ç°å‡ºæ˜¾è‘—è§†è§‰å’Œè¯­è¨€èƒ½åŠ›ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€ç›®æ ‡å®šä½ç­‰ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨ç²¾ç»†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚åœ¨æ—¥å¸¸åœºæ™¯ä¸­ï¼Œä¸ªäººé‡åˆ°è®¾è®¡ææ–™ï¼Œå¦‚æ‚å¿—ã€æ’ç‰ˆæ•™ç¨‹ã€ç ”ç©¶è®ºæ–‡æˆ–å“ç‰Œå†…å®¹ï¼Œå¯èƒ½ä¼šå¸Œæœ›è¯†åˆ«æ–‡æœ¬ä¸­è§†è§‰ä¸Šä»¤äººæ„‰æ‚¦çš„å­—ä½“ã€‚è€ƒè™‘åˆ°å®ƒä»¬çš„å¤šæ¨¡å¼èƒ½åŠ›å’Œè‡ªç”±è®¿é—®æ€§ï¼Œè®¸å¤šVLMsé€šå¸¸è¢«è®¤ä¸ºæ˜¯å­—ä½“è¯†åˆ«çš„æ½œåœ¨å·¥å…·ã€‚è¿™å¼•å‘äº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„é—®é¢˜ï¼šVLMsçœŸçš„å…·å¤‡è¯†åˆ«å­—ä½“çš„èƒ½åŠ›å—ï¼Ÿä¸ºäº†è°ƒæŸ¥è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†å­—ä½“è¯†åˆ«åŸºå‡†æµ‹è¯•ï¼ˆFRBï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«15ç§å¸¸ç”¨å­—ä½“çš„ç´§å‡‘ä¸”ç»“æ„è‰¯å¥½çš„æ•°æ®é›†ã€‚FRBåŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬ï¼šï¼ˆiï¼‰ä¸€ä¸ªç®€å•ç‰ˆæœ¬ï¼Œå…¶ä¸­10ä¸ªå¥å­ä»¥ä¸åŒå­—ä½“å‘ˆç°ï¼›ï¼ˆiiï¼‰ä¸€ä¸ªå›°éš¾ç‰ˆæœ¬ï¼Œå…¶ä¸­æ¯ä¸ªæ–‡æœ¬æ ·æœ¬ç”±è¿™15ç§å­—ä½“çš„åç§°ç»„æˆï¼Œå¼•å…¥ä¸€ç§æ–¯ç‰¹é²æ™®æ•ˆåº”ï¼ŒæŒ‘æˆ˜æ¨¡å‹çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚é€šè¿‡å¯¹å„ç§VLMsåœ¨å­—ä½“è¯†åˆ«ä»»åŠ¡ä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹å…³é”®å‘ç°ï¼šï¼ˆiï¼‰å½“å‰VLMsåœ¨å­—ä½“è¯†åˆ«æ–¹é¢çš„èƒ½åŠ›æœ‰é™ï¼Œè®¸å¤šæœ€å…ˆè¿›çš„æ¨¡å‹æ— æ³•è¾¾åˆ°ä»¤äººæ»¡æ„çš„æ€§èƒ½ï¼Œå¹¶å®¹æ˜“å—åˆ°æ–‡æœ¬ä¿¡æ¯å¼•å…¥çš„æ–¯ç‰¹é²æ™®æ•ˆåº”çš„å½±å“ã€‚ï¼ˆiiï¼‰åœ¨VLMsä¸­ï¼Œå°æ ·æœ¬å­¦ä¹ å’Œæ€ç»´é“¾æç¤ºå¯¹æ”¹å–„å­—ä½“è¯†åˆ«ç²¾åº¦æä¾›æœ€å°çš„å¸®åŠ©ã€‚ï¼ˆiiiï¼‰æ³¨æ„åŠ›åˆ†ææ­ç¤ºäº†VLMsåœ¨æ•è·è¯­ä¹‰ç‰¹å¾æ–¹é¢çš„å†…åœ¨å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.23768v4">PDF</a> Accepted to COLM 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç°ä»£è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å›¾åƒè¯†åˆ«ã€ç‰©ä½“å®šä½ç­‰æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„è§†è§‰å’Œè¯­è¨€èƒ½åŠ›ï¼Œä½†åœ¨ç²¾ç»†ä»»åŠ¡ä¸Šçš„æ•ˆæœä»æœ‰å¾…æ¢è®¨ã€‚é’ˆå¯¹æ—¥å¸¸åœºæ™¯ä¸­è¯†åˆ«è®¾è®¡ææ–™ä¸­çš„å­—ä½“éœ€æ±‚ï¼Œæˆ‘ä»¬æå‡ºäº†å­—ä½“è¯†åˆ«åŸºå‡†æµ‹è¯•ï¼ˆFRBï¼‰ï¼ŒåŒ…å«15ç§å¸¸è§å­—ä½“ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰VLMsåœ¨å­—ä½“è¯†åˆ«æ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚æƒ…å¢ƒï¼Œä¸”å°‘æ ·æœ¬å­¦ä¹ å’Œé“¾å¼æ€ç»´æç¤ºå¯¹æå‡å­—ä½“è¯†åˆ«å‡†ç¡®ç‡çš„ä½œç”¨æœ‰é™ã€‚æ³¨æ„åŠ›åˆ†ææ­ç¤ºäº†VLMsåœ¨æ•æ‰è¯­ä¹‰ç‰¹å¾æ–¹é¢çš„å†…åœ¨å±€é™ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰VLMsåœ¨å­—ä½“è¯†åˆ«æ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥æ»¡è¶³ç²¾ç»†ä»»åŠ¡éœ€æ±‚ã€‚</li>
<li>FRBåŸºå‡†æµ‹è¯•åŒ…å«ä¸¤ç§ç‰ˆæœ¬ï¼Œåˆ†åˆ«è€ƒå¯Ÿæ¨¡å‹åœ¨ä¸åŒéš¾åº¦ä¸‹çš„è¡¨ç°ã€‚</li>
<li>å°‘æ ·æœ¬å­¦ä¹ å’ŒChain-of-Thoughtï¼ˆCoTï¼‰æç¤ºåœ¨æ”¹å–„å­—ä½“è¯†åˆ«å‡†ç¡®ç‡æ–¹é¢æ•ˆæœç”šå¾®ã€‚</li>
<li>VLMsåœ¨å¤„ç†å«æœ‰å­—ä½“åç§°çš„æ–‡æœ¬æ ·æœ¬æ—¶æ˜“å—åˆ°å¹²æ‰°ï¼Œè¡¨æ˜å…¶å®¹æ˜“å—åˆ°â€œæ–¯ç‰¹é²æ™®æ•ˆåº”â€çš„å½±å“ã€‚</li>
<li>æ³¨æ„åŠ›åˆ†ææ­ç¤ºäº†VLMsåœ¨æ•æ‰è¯­ä¹‰ç‰¹å¾æ–¹é¢çš„ä¸è¶³ã€‚</li>
<li>ç°ä»£VLMséœ€è¦è¿›ä¸€æ­¥åŠ å¼ºåœ¨å­—ä½“è¯†åˆ«ç­‰ç²¾ç»†ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.23768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-39abcbd5f7bd73377d2cc39477d3cc89~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061309&auth_key=1760061309-0-0-d88f09805d5c618c288f453cbdfc84b3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-09797cf823fa1543e9098f0df2c1abe6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061316&auth_key=1760061316-0-0-5012fb15e9c62e65b152e8e2ef6cdc6a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-689f255139b611ef5d349dcc73baf099~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061323&auth_key=1760061323-0-0-71812b151306734a6f8aeebf9699002a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4b1762f058803084a1ee7e44e85449d1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061330&auth_key=1760061330-0-0-b8ab330f6dbbe7819fb21db116a58f32&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a03b1cc5ec100ec4471fd1b3babfc9be~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061337&auth_key=1760061337-0-0-46c29d888d049a869aa588dba915c491&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Improving-the-Language-Understanding-Capabilities-of-Large-Language-Models-Using-Reinforcement-Learning"><a href="#Improving-the-Language-Understanding-Capabilities-of-Large-Language-Models-Using-Reinforcement-Learning" class="headerlink" title="Improving the Language Understanding Capabilities of Large Language   Models Using Reinforcement Learning"></a>Improving the Language Understanding Capabilities of Large Language   Models Using Reinforcement Learning</h2><p><strong>Authors:Bokai Hu, Sai Ashish Somayajula, Xin Pan, Pengtao Xie</strong></p>
<p>Instruction-fine-tuned large language models (LLMs) under 14B parameters continue to underperform on natural language understanding (NLU) tasks, often trailing smaller models like BERT-base on benchmarks such as GLUE and SuperGLUE. Motivated by the success of reinforcement learning in reasoning tasks (e.g., DeepSeek), we explore Proximal Policy Optimization (PPO) as a framework to improve the NLU capabilities of LLMs. We frame NLU as a reinforcement learning environment, treating token generation as a sequence of actions and optimizing for reward signals based on alignment with ground-truth labels. PPO consistently outperforms supervised fine-tuning, yielding an average improvement of 6.3 points on GLUE, and surpasses zero-shot and few-shot prompting by 38.7 and 26.1 points, respectively. Notably, PPO-tuned models outperform GPT-4o by over 4% on average across sentiment and natural language inference tasks, including gains of 7.3% on the Mental Health dataset and 10.9% on SIGA-nli. This work highlights a promising direction for adapting LLMs to new tasks by reframing them as reinforcement learning problems, enabling learning through simple end-task rewards rather than extensive data curation. </p>
<blockquote>
<p>æŒ‡ä»¤å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å°‘äº14Bå‚æ•°çš„æƒ…å†µä¸‹ï¼Œåœ¨ç†è§£è‡ªç„¶è¯­è¨€ï¼ˆNLUï¼‰çš„ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¾€å¾€åœ¨GLUEå’ŒSuperGLUEç­‰åŸºå‡†æµ‹è¯•ä¸Šè½åäºè¾ƒå°çš„æ¨¡å‹ï¼Œå¦‚BERT-baseã€‚å—åˆ°å¼ºåŒ–å­¦ä¹ åœ¨æ¨ç†ä»»åŠ¡ä¸­æˆåŠŸåº”ç”¨çš„å¯å‘ï¼ˆä¾‹å¦‚DeepSeekï¼‰ï¼Œæˆ‘ä»¬æ¢ç´¢ä½¿ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰æ¡†æ¶æ¥æé«˜LLMçš„NLUèƒ½åŠ›ã€‚æˆ‘ä»¬å°†NLUæ„å»ºä¸ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå°†ä»¤ç‰Œç”Ÿæˆè§†ä¸ºä¸€ç³»åˆ—åŠ¨ä½œï¼Œå¹¶åŸºäºä¸çœŸå®æ ‡ç­¾çš„å¯¹é½æƒ…å†µä¼˜åŒ–å¥–åŠ±ä¿¡å·ã€‚PPOå§‹ç»ˆåœ¨ç›‘ç£å¾®è°ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨GLUEä¸Šçš„å¹³å‡æé«˜äº†6.3åˆ†ï¼Œå¹¶ä¸”ç›¸å¯¹äºé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æç¤ºåˆ†åˆ«æé«˜äº†38.7åˆ†å’Œ26.1åˆ†ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé€šè¿‡PPOè°ƒæ•´çš„æ¨¡å‹åœ¨æƒ…æ„Ÿå’Œè‡ªç„¶è¯­è¨€æ¨ç†ä»»åŠ¡ä¸Šçš„å¹³å‡è¡¨ç°è¶…è¿‡äº†GPT-4oè¶…è¿‡4%ï¼ŒåŒ…æ‹¬åœ¨å¿ƒç†å¥åº·æ•°æ®é›†ä¸Šæé«˜7.3%å’Œåœ¨SIGA-nliä¸Šæé«˜10.9%ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†é€šè¿‡é‡æ–°æ„å»ºä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜æ¥é€‚åº”LLMçš„æ–°ä»»åŠ¡æ–¹å‘ï¼Œä½¿å…¶èƒ½å¤Ÿé€šè¿‡ç®€å•çš„ç»ˆç«¯ä»»åŠ¡å¥–åŠ±è¿›è¡Œå­¦ä¹ ï¼Œè€Œä¸æ˜¯å¤§é‡æ•°æ®æ•´ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.11020v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæŒ‡ä»¤å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å°äº14Bå‚æ•°çš„æƒ…å†µä¸‹ï¼Œåœ¨è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸åœ¨GLUEå’ŒSuperGLUEç­‰åŸºå‡†æµ‹è¯•ä¸­è½åäºè¾ƒå°çš„æ¨¡å‹ï¼Œå¦‚BERT-baseã€‚å—å¼ºåŒ–å­¦ä¹ åœ¨æ¨ç†ä»»åŠ¡ï¼ˆå¦‚DeepSeekï¼‰ä¸­æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢ä½¿ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰æ¡†æ¶æ¥æå‡LLMçš„NLUèƒ½åŠ›ã€‚æˆ‘ä»¬å°†NLUä»»åŠ¡è§†ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå°†ä»¤ç‰Œç”Ÿæˆè§†ä¸ºä¸€ç³»åˆ—åŠ¨ä½œï¼Œå¹¶åŸºäºä¸çœŸå®æ ‡ç­¾çš„å¯¹é½æƒ…å†µä¼˜åŒ–å¥–åŠ±ä¿¡å·ã€‚PPOåœ¨GLUEä¸Šçš„å¹³å‡è¡¨ç°ä¼˜äºç›‘ç£å¾®è°ƒï¼Œæå‡6.3åˆ†ï¼›å¹¶ä¸”åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æç¤ºä¸‹çš„è¡¨ç°åˆ†åˆ«æå‡38.7å’Œ26.1åˆ†ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒPPOä¼˜åŒ–çš„æ¨¡å‹åœ¨æƒ…æ„Ÿå’Œè¯­è¨€æ¨ç†ä»»åŠ¡ä¸Šçš„å¹³å‡è¡¨ç°ä¼˜äºGPT-4oè¶…è¿‡4%ï¼ŒåŒ…æ‹¬åœ¨å¿ƒç†å¥åº·æ•°æ®é›†ä¸Šæå‡7.3%å’Œåœ¨SIGA-nliä¸Šæå‡10.9%ã€‚æœ¬ç ”ç©¶ä¸ºé€šè¿‡é‡æ–°æ„å»ºä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜æ¥é€‚åº”LLMçš„æ–°ä»»åŠ¡æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ï¼Œå¯ä»¥é€šè¿‡ç®€å•çš„ç»ˆç«¯ä»»åŠ¡å¥–åŠ±è¿›è¡Œå­¦ä¹ ï¼Œè€Œæ— éœ€å¤§é‡æ•°æ®æ•´ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æŒ‡ä»¤å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨NLUä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå°¤å…¶åœ¨GLUEå’ŒSuperGLUEåŸºå‡†æµ‹è¯•ä¸­ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ ä¸­çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰æ¡†æ¶è¢«æ¢ç´¢ç”¨äºæå‡LLMçš„NLUèƒ½åŠ›ã€‚</li>
<li>å°†NLUä»»åŠ¡è§†ä¸ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå°†ä»¤ç‰Œç”Ÿæˆè§†ä¸ºä¸€ç³»åˆ—åŠ¨ä½œã€‚</li>
<li>PPOä¼˜åŒ–åœ¨GLUEåŸºå‡†æµ‹è¯•ä¸­å¹³å‡è¡¨ç°ä¼˜äºç›‘ç£å¾®è°ƒï¼Œå¹¶åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æƒ…å¢ƒä¸‹è¡¨ç°æ˜¾è‘—ã€‚</li>
<li>PPOä¼˜åŒ–çš„æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šè¶…è¶Šäº†GPT-4oçš„è¡¨ç°ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿåˆ†æå’Œè¯­è¨€æ¨ç†ä»»åŠ¡ã€‚</li>
<li>PPOæ¡†æ¶ä½¿LLMèƒ½å¤Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œé€šè¿‡ç®€å•çš„ç»ˆç«¯ä»»åŠ¡å¥–åŠ±è¿›è¡Œå­¦ä¹ ï¼Œæ— éœ€å¤§é‡æ•°æ®æ•´ç†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.11020">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-71c208ec7a4bcfd35274e7f57fda4529~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061344&auth_key=1760061344-0-0-ae0cdc83ad0bc634057f6f7ee9f9dcde&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8a73b6b8d4ec8cea0934860804e83f13~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061351&auth_key=1760061351-0-0-b7e5e2648b99348b96184f12d4a10469&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-29a99190c93ae475a00394b2c24b62be~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061358&auth_key=1760061358-0-0-c661e927df75568e22f0e020a8a3103b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fc8d39dd4cf00801afab245356e4e699~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061365&auth_key=1760061365-0-0-48cb3a845dd199519ae3e64cd61e00c0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5055ea03e2204adb4d4eab8e7d1d41a7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061372&auth_key=1760061372-0-0-e292b97179b935e50525ed5e52c6feed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Leveraging-Model-Guidance-to-Extract-Training-Data-from-Personalized-Diffusion-Models"><a href="#Leveraging-Model-Guidance-to-Extract-Training-Data-from-Personalized-Diffusion-Models" class="headerlink" title="Leveraging Model Guidance to Extract Training Data from Personalized   Diffusion Models"></a>Leveraging Model Guidance to Extract Training Data from Personalized   Diffusion Models</h2><p><strong>Authors:Xiaoyu Wu, Jiaru Zhang, Zhiwei Steven Wu</strong></p>
<p>Diffusion Models (DMs) have become powerful image generation tools, especially for few-shot fine-tuning where a pretrained DM is fine-tuned on a small image set to capture specific styles or objects. Many people upload these personalized checkpoints online, fostering communities such as Civitai and HuggingFace. However, model owners may overlook the data leakage risks when releasing fine-tuned checkpoints. Moreover, concerns regarding copyright violations arise when unauthorized data is used during fine-tuning. In this paper, we ask: â€œCan training data be extracted from these fine-tuned DMs shared online?â€ A successful extraction would present not only data leakage threats but also offer tangible evidence of copyright infringement. To answer this, we propose FineXtract, a framework for extracting fine-tuning data. Our method approximates fine-tuning as a gradual shift in the modelâ€™s learned distribution â€“ from the original pretrained DM toward the fine-tuning data. By extrapolating the models before and after fine-tuning, we guide the generation toward high-probability regions within the fine-tuned data distribution. We then apply a clustering algorithm to extract the most probable images from those generated using this extrapolated guidance. Experiments on DMs fine-tuned with datasets including WikiArt, DreamBooth, and real-world checkpoints posted online validate the effectiveness of our method, extracting about 20% of fine-tuning data in most cases. The code is available <a target="_blank" rel="noopener" href="https://github.com/Nicholas0228/FineXtract">https://github.com/Nicholas0228/FineXtract</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰å·²ç»æˆä¸ºå¼ºå¤§çš„å›¾åƒç”Ÿæˆå·¥å…·ï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ ·æœ¬å¾®è°ƒé¢†åŸŸï¼Œé¢„è®­ç»ƒçš„DMé€šè¿‡åœ¨å°å›¾åƒé›†ä¸Šè¿›è¡Œå¾®è°ƒä»¥æ•æ‰ç‰¹å®šçš„é£æ ¼æˆ–å¯¹è±¡ã€‚è®¸å¤šäººåœ¨çº¿ä¸Šä¼ è¿™äº›ä¸ªæ€§åŒ–çš„æ£€æŸ¥ç‚¹ï¼Œå½¢æˆäº†å¦‚Civitaiå’ŒHuggingFaceç­‰ç¤¾åŒºã€‚ç„¶è€Œï¼Œåœ¨å‘å¸ƒå¾®è°ƒæ£€æŸ¥ç‚¹æ—¶ï¼Œæ¨¡å‹æ‰€æœ‰è€…å¯èƒ½ä¼šå¿½ç•¥æ•°æ®æ³„éœ²çš„é£é™©ã€‚æ­¤å¤–ï¼Œå½“å¾®è°ƒè¿‡ç¨‹ä¸­ä½¿ç”¨æœªç»æˆæƒçš„æ•°æ®æ—¶ï¼Œä¼šå‡ºç°ç‰ˆæƒè¿è§„çš„æ‹…å¿§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºçš„é—®é¢˜ï¼šâ€œå¯ä»¥ä»åœ¨çº¿å…±äº«çš„è¿™äº›å¾®è°ƒåçš„DMsä¸­æå–è®­ç»ƒæ•°æ®å—ï¼Ÿâ€æˆåŠŸçš„æå–ä¸ä»…ä¼šå¸¦æ¥æ•°æ®æ³„éœ²çš„å¨èƒï¼Œè€Œä¸”ä¼šæˆä¸ºç‰ˆæƒä¾µæƒçš„åˆ‡å®è¯æ®ã€‚ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†FineXtractï¼Œä¸€ä¸ªç”¨äºæå–å¾®è°ƒæ•°æ®çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¾®è°ƒè¿‘ä¼¼ä¸ºæ¨¡å‹å­¦ä¹ åˆ†å¸ƒçš„ä¸€ä¸ªé€æ¸å˜åŒ–â€”â€”ä»åŸå§‹çš„é¢„è®­ç»ƒDMå‘å¾®è°ƒæ•°æ®è½¬å˜ã€‚é€šè¿‡åœ¨å¾®è°ƒå‰åå¯¹æ¨¡å‹è¿›è¡Œå¤–æ¨ï¼Œæˆ‘ä»¬å¼•å¯¼ç”Ÿæˆèµ°å‘å¾®è°ƒæ•°æ®åˆ†å¸ƒå†…çš„é«˜æ¦‚ç‡åŒºåŸŸã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨èšç±»ç®—æ³•ä»ä½¿ç”¨è¿™ç§å¤–æ¨æŒ‡å¯¼ç”Ÿæˆçš„å›¾åƒä¸­æå–æœ€å¯èƒ½çš„å›¾åƒã€‚åœ¨ä½¿ç”¨WikiArtã€DreamBoothå’Œåœ¨çº¿å‘å¸ƒçš„ç°å®ä¸–ç•Œæ£€æŸ¥ç‚¹å¯¹DMsè¿›è¡Œå¾®è°ƒçš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæå–çº¦20%çš„å¾®è°ƒæ•°æ®ã€‚ä»£ç å¯ç”¨åœ¨<a target="_blank" rel="noopener" href="https://github.com/Nicholas0228/FineXtract%E3%80%82">https://github.com/Nicholas0228/FineXtractã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.03039v3">PDF</a> Accepted at the International Conference on Machine Learning (ICML)   2025</p>
<p><strong>Summary</strong><br>     æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å°‘é‡æ ·æœ¬å¾®è°ƒä¸Šå±•ç°å‡ºå¼ºå¤§çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”ç‰¹å®šé£æ ¼æˆ–å¯¹è±¡ã€‚ä½†å…±äº«è¿™äº›å¾®è°ƒæ¨¡å‹æ—¶ï¼Œå¯èƒ½æ³„éœ²è®­ç»ƒæ•°æ®å¹¶ä¾µçŠ¯ç‰ˆæƒã€‚æœ¬æ–‡æå‡ºâ€œFineXtractâ€æ¡†æ¶ï¼Œæ—¨åœ¨ä»åœ¨çº¿å…±äº«çš„å¾®è°ƒDMä¸­æå–è®­ç»ƒæ•°æ®ã€‚é€šè¿‡æ¨¡æ‹Ÿå¾®è°ƒè¿‡ç¨‹ä¸­çš„åˆ†å¸ƒå˜åŒ–ï¼Œä»¥åŠä½¿ç”¨èšç±»ç®—æ³•å¯¹ç”Ÿæˆå›¾åƒè¿›è¡Œèšç±»ï¼Œè¯¥æ–¹æ³•åœ¨WikiArtã€DreamBoothåŠåœ¨çº¿ç°å®æ£€æŸ¥ç‚¹ç­‰æ•°æ®é›†ä¸Šæœ‰æ•ˆï¼Œå¤šæ•°æƒ…å†µå¯æå–çº¦20%çš„è®­ç»ƒæ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å°‘é‡æ ·æœ¬å¾®è°ƒæ–¹é¢å…·æœ‰å¼ºå¤§èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨é€‚åº”ç‰¹å®šé£æ ¼æˆ–å¯¹è±¡æ—¶ã€‚</li>
<li>å…±äº«å¾®è°ƒæ¨¡å‹å­˜åœ¨æ•°æ®æ³„éœ²å’Œç‰ˆæƒä¾µçŠ¯çš„é£é™©ã€‚</li>
<li>æœ¬æ–‡æå‡ºâ€œFineXtractâ€æ¡†æ¶ï¼Œå¯ä»¥ä»åœ¨çº¿å…±äº«çš„å¾®è°ƒDMä¸­æå–è®­ç»ƒæ•°æ®ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æ¨¡æ‹Ÿå¾®è°ƒè¿‡ç¨‹ä¸­çš„åˆ†å¸ƒå˜åŒ–æ¥å·¥ä½œã€‚</li>
<li>ä½¿ç”¨èšç±»ç®—æ³•å¯¹ç”Ÿæˆå›¾åƒè¿›è¡Œèšç±»ï¼Œä»¥æå–æœ€å¯èƒ½çš„å›¾åƒã€‚</li>
<li>åœ¨WikiArtã€DreamBoothåŠåœ¨çº¿ç°å®æ£€æŸ¥ç‚¹ç­‰æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.03039">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-963bd81c0e90c4fa631023d63528e38a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061380&auth_key=1760061380-0-0-e445902b79b8addc52ecc5faf0e49d3f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-047444c29093d83d621f6da7d5f18204~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061387&auth_key=1760061387-0-0-d4152388306e481de18b669e79e99151&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e72ff3da1265d6f5e0eda57f81bf15fb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061394&auth_key=1760061394-0-0-1f22af9e0132b6109022f95584886613&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6db9f14c842ba720d8dbc940384c989d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061400&auth_key=1760061400-0-0-20d4b2e790464c9c7f8e7d7981947741&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0fdae84b7aebafa3d5dd896d67520803~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061407&auth_key=1760061407-0-0-870494b374ff6e6b0339c75593103d8f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="TEXT2AFFORD-Probing-Object-Affordance-Prediction-abilities-of-Language-Models-solely-from-Text"><a href="#TEXT2AFFORD-Probing-Object-Affordance-Prediction-abilities-of-Language-Models-solely-from-Text" class="headerlink" title="TEXT2AFFORD: Probing Object Affordance Prediction abilities of Language   Models solely from Text"></a>TEXT2AFFORD: Probing Object Affordance Prediction abilities of Language   Models solely from Text</h2><p><strong>Authors:Sayantan Adak, Daivik Agrawal, Animesh Mukherjee, Somak Aditya</strong></p>
<p>We investigate the knowledge of object affordances in pre-trained language models (LMs) and pre-trained Vision-Language models (VLMs). A growing body of literature shows that PTLMs fail inconsistently and non-intuitively, demonstrating a lack of reasoning and grounding. To take a first step toward quantifying the effect of grounding (or lack thereof), we curate a novel and comprehensive dataset of object affordances â€“ Text2Afford, characterized by 15 affordance classes. Unlike affordance datasets collected in vision and language domains, we annotate in-the-wild sentences with objects and affordances. Experimental results reveal that PTLMs exhibit limited reasoning abilities when it comes to uncommon object affordances. We also observe that pre-trained VLMs do not necessarily capture object affordances effectively. Through few-shot fine-tuning, we demonstrate improvement in affordance knowledge in PTLMs and VLMs. Our research contributes a novel dataset for language grounding tasks, and presents insights into LM capabilities, advancing the understanding of object affordances. Codes and data are available at <a target="_blank" rel="noopener" href="https://github.com/sayantan11995/Text2Afford">https://github.com/sayantan11995/Text2Afford</a> </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰å’Œé¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å¯¹ç‰©ä½“åŠŸèƒ½çš„çŸ¥è¯†ã€‚è¶Šæ¥è¶Šå¤šçš„æ–‡çŒ®æ˜¾ç¤ºï¼ŒPTLMsçš„è¡¨ç°å­˜åœ¨ä¸ä¸€è‡´å’Œéç›´è§‰æ€§çš„å¤±è´¥ï¼Œæ˜¾ç¤ºå‡ºç¼ºä¹æ¨ç†å’Œæ¥åœ°èƒ½åŠ›ã€‚ä¸ºäº†åˆæ­¥é‡åŒ–æ¥åœ°æ•ˆæœï¼ˆæˆ–ç¼ºä¹æ¥åœ°çš„å½±å“ï¼‰ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå…¨æ–°çš„ç»¼åˆç‰©ä½“åŠŸèƒ½æ•°æ®é›†â€”â€”Text2Affordï¼ŒåŒ…å«15ä¸ªåŠŸèƒ½ç±»åˆ«ã€‚ä¸è§†è§‰å’Œè¯­è¨€é¢†åŸŸæ”¶é›†çš„åŠŸèƒ½æ•°æ®é›†ä¸åŒï¼Œæˆ‘ä»¬å¯¹é‡å¤–å¥å­ä¸­çš„ç‰©ä½“å’ŒåŠŸèƒ½è¿›è¡Œäº†æ³¨é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“æ¶‰åŠåˆ°ä¸å¸¸è§çš„ç‰©ä½“åŠŸèƒ½æ—¶ï¼ŒPTLMsçš„æ¨ç†èƒ½åŠ›æœ‰é™ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼Œé¢„è®­ç»ƒçš„VLMså¹¶ä¸ä¸€å®šèƒ½æœ‰æ•ˆåœ°æ•è·ç‰©ä½“åŠŸèƒ½ã€‚é€šè¿‡å°‘æ ·æœ¬å¾®è°ƒï¼Œæˆ‘ä»¬å±•ç¤ºäº†PTLMså’ŒVLMsåœ¨åŠŸèƒ½çŸ¥è¯†æ–¹é¢çš„æ”¹è¿›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºè¯­è¨€æ¥åœ°ä»»åŠ¡æä¾›äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œå¹¶æ·±å…¥äº†è§£äº†LMçš„èƒ½åŠ›ï¼Œæ¨è¿›äº†å¯¹ç‰©ä½“åŠŸèƒ½çš„ç†è§£ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sayantan11995/Text2Afford%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sayantan11995/Text2Affordæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12881v3">PDF</a> Accepted at Conference on Computational Natural Language Learning   2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢ç©¶äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPTLMsï¼‰å’Œé¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å¯¹ç‰©ä½“åŠŸèƒ½æ€§çš„ç†è§£ç¨‹åº¦ã€‚ç ”ç©¶å‘ç°åœ¨å¤„ç†éç›´è§‚ã€ä¸ä¸€è‡´çš„ç‰©ä½“åŠŸèƒ½æ€§æ—¶ï¼ŒPTLMsè¡¨ç°å‡ºæ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ä¸ºäº†é‡åŒ–è¿™ç§ç°è±¡ï¼Œç ”ç©¶è€…åˆ›å»ºäº†ä¸€ä¸ªå…¨æ–°çš„ç‰©ä½“åŠŸèƒ½æ€§æ•°æ®é›†â€”â€”Text2Affordï¼ŒåŒ…å«15ç±»åŠŸèƒ½æ€§æ ‡æ³¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPTLMsåœ¨å¤„ç†ç½•è§ç‰©ä½“åŠŸèƒ½æ€§æ—¶èƒ½åŠ›æœ‰é™ï¼Œè€Œé¢„è®­ç»ƒVLMsä¹Ÿæœªèƒ½æœ‰æ•ˆæ•æ‰ç‰©ä½“åŠŸèƒ½æ€§ã€‚é€šè¿‡å°‘æ ·æœ¬å¾®è°ƒçš„æ–¹æ³•ï¼Œå¯ä»¥æ”¹è¿›PTLMså’ŒVLMså¯¹ç‰©ä½“åŠŸèƒ½æ€§çš„ç†è§£èƒ½åŠ›ã€‚æœ¬ç ”ç©¶ä¸ä»…æä¾›äº†è¯­è¨€å®šä½ä»»åŠ¡çš„æ–°æ•°æ®é›†ï¼Œè¿˜ä¸ºç†è§£PTLMsçš„åŠŸèƒ½æ€§æä¾›äº†æ·±å…¥è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶è°ƒæŸ¥äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹å¯¹ç‰©ä½“åŠŸèƒ½æ€§çš„äº†è§£ç¨‹åº¦ã€‚</li>
<li>å‘ç°é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨å¤„ç†éç›´è§‚å’Œéä¸€è‡´çš„ç‰©ä½“åŠŸèƒ½æ€§ä»»åŠ¡æ—¶å­˜åœ¨æ¨ç†èƒ½åŠ›ä¸è¶³çš„ç¼ºé™·ã€‚</li>
<li>åˆ›å»ºäº†ä¸€ä¸ªå…¨æ–°çš„ç‰©ä½“åŠŸèƒ½æ€§æ•°æ®é›†Text2Affordï¼ŒåŒ…å«15ç±»æ ‡æ³¨ã€‚</li>
<li>è¯¥æ•°æ®é›†çš„ç‰¹ç‚¹æ˜¯æ ‡æ³¨äº†åŒ…å«ç‰©ä½“å’ŒåŠŸèƒ½æ€§ä¿¡æ¯çš„è‡ªç„¶è¯­å¥ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç½•è§ç‰©ä½“åŠŸèƒ½æ€§æ—¶è¡¨ç°æœ‰é™ã€‚</li>
<li>é€šè¿‡å°‘æ ·æœ¬å¾®è°ƒçš„æ–¹æ³•å¯ä»¥æ”¹å–„é¢„è®­ç»ƒæ¨¡å‹å¯¹ç‰©ä½“åŠŸèƒ½æ€§çš„ç†è§£èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.12881">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6f04630af8c4701ee4ae2b544c8627b9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061414&auth_key=1760061414-0-0-4795e2fbc6ff117ba11d4a12f85fa2f7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7267e89aee330fe50d881141b16b444c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061422&auth_key=1760061422-0-0-b9c01ee25afa1fc91bde3f2bdfc01292&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d6203bb2c1f3cabb71d40fef879527b3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061428&auth_key=1760061428-0-0-df7652488af022c2a30dd581db220ac7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4de3b9e2dd25d88a7d239f42287ec38~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061436&auth_key=1760061436-0-0-e14dc3b1bc0707eeca68ddbdfad0bdf2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8a6d125fe894941a610ac875573ae5b1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061442&auth_key=1760061442-0-0-8e74503b6bd1e941fd43ae2a4d6d1d6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3931330642861d15868ce22af5d8b44d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061449&auth_key=1760061449-0-0-322ccb190016333d7e19d4974ce83c86&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-30/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-30/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-30/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-9966b945e7f0985eb94af5a0636b6f2d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760061456&auth_key=1760061456-0-0-7dab10769021dd5ba7ef5a0ba1e340a6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-30/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-b5d4cb9dd69de1340b9e28863182047e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760060660&auth_key=1760060660-0-0-6bae5ae869c2a3fd22d839dc13ed122e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  Effective Policy Learning for Multi-Agent Online Coordination Beyond   Submodular Objectives
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30806.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
