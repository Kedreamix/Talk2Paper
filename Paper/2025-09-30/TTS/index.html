<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  Dynamic Experts Search Enhancing Reasoning in Mixture-of-Experts LLMs   at Test Time">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-35b3070b82351a29fedfee6d7197dc78~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826516&auth_key=1760826516-0-0-ff192380129ea88a78ce15928eda4d57&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    37 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-30-æ›´æ–°"><a href="#2025-09-30-æ›´æ–°" class="headerlink" title="2025-09-30 æ›´æ–°"></a>2025-09-30 æ›´æ–°</h1><h2 id="Dynamic-Experts-Search-Enhancing-Reasoning-in-Mixture-of-Experts-LLMs-at-Test-Time"><a href="#Dynamic-Experts-Search-Enhancing-Reasoning-in-Mixture-of-Experts-LLMs-at-Test-Time" class="headerlink" title="Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs   at Test Time"></a>Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs   at Test Time</h2><p><strong>Authors:Yixuan Han, Fan Ma, Ruijie Quan, Yi Yang</strong></p>
<p>Test-Time Scaling (TTS) enhances the reasoning ability of large language models (LLMs) by allocating additional computation during inference. However, existing approaches primarily rely on output-level sampling while overlooking the role of model architecture. In mainstream Mixture-of-Experts (MoE) LLMs, we observe that varying the number of activated experts yields complementary solution sets with stable accuracy, revealing a new and underexplored source of diversity. Motivated by this observation, we propose Dynamic Experts Search (DES), a TTS strategy that elevates expert activation into a controllable dimension of the search space. DES integrates two key components: (1) Dynamic MoE, which enables direct control of expert counts during inference to generate diverse reasoning trajectories without additional cost; and (2) Expert Configuration Inheritance, which preserves consistent expert counts within a reasoning path while varying them across runs, thereby balancing stability and diversity throughout the search. Extensive experiments across MoE architectures, verifiers and reasoning benchmarks (i.e., math, code and knowledge) demonstrate that DES reliably outperforms TTS baselines, enhancing accuracy and stability without additional cost. These results highlight DES as a practical and scalable form of architecture-aware TTS, illustrating how structural flexibility in modern LLMs can advance reasoning. </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰é€šè¿‡æ¨ç†è¿‡ç¨‹ä¸­çš„é¢å¤–è®¡ç®—æ¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºè¾“å‡ºçº§åˆ«çš„é‡‡æ ·ï¼Œè€Œå¿½ç•¥äº†æ¨¡å‹æ¶æ„çš„ä½œç”¨ã€‚åœ¨ä¸»æµæ··åˆä¸“å®¶ï¼ˆMoEï¼‰LLMä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ”¹å˜æ¿€æ´»çš„ä¸“å®¶æ•°é‡ä¼šäº§ç”Ÿå…·æœ‰ç¨³å®šå‡†ç¡®ç‡çš„äº’è¡¥è§£å†³æ–¹æ¡ˆé›†ï¼Œæ­ç¤ºäº†ä¸€ç§æ–°çš„ä¸”å°šæœªè¢«å……åˆ†æ¢ç´¢çš„å¤šæ ·æ€§æ¥æºã€‚å—æ­¤è§‚å¯Ÿç»“æœçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€ä¸“å®¶æœç´¢ï¼ˆDESï¼‰ï¼Œè¿™æ˜¯ä¸€ç§TTSç­–ç•¥ï¼Œå®ƒå°†ä¸“å®¶æ¿€æ´»æå‡ä¸ºæœç´¢ç©ºé—´çš„å¯æ§ç»´åº¦ã€‚DESé›†æˆäº†ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šï¼ˆ1ï¼‰åŠ¨æ€MoEï¼Œå®ƒèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­ç›´æ¥æ§åˆ¶ä¸“å®¶æ•°é‡ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„æ¨ç†è½¨è¿¹ï¼Œæ— éœ€é¢å¤–æˆæœ¬ï¼›ï¼ˆ2ï¼‰ä¸“å®¶é…ç½®ç»§æ‰¿ï¼Œå®ƒèƒ½å¤Ÿåœ¨æ¨ç†è·¯å¾„å†…ä¿æŒä¸€è‡´çš„ä¸“å®¶æ•°é‡ï¼ŒåŒæ—¶åœ¨å„æ¬¡è¿è¡Œä¸­å˜åŒ–å®ƒä»¬ï¼Œä»è€Œåœ¨æœç´¢è¿‡ç¨‹ä¸­å¹³è¡¡ç¨³å®šæ€§å’Œå¤šæ ·æ€§ã€‚åœ¨MoEæ¶æ„ã€éªŒè¯å™¨å’Œæ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆä¾‹å¦‚æ•°å­¦ã€ä»£ç å’ŒçŸ¥è¯†ï¼‰çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDESå¯é åœ°ä¼˜äºTTSåŸºçº¿ï¼Œæé«˜äº†å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œä¸”æ— éœ€é¢å¤–æˆæœ¬ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†DESä½œä¸ºä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„æ¶æ„æ„ŸçŸ¥TTSå½¢å¼ï¼Œå±•ç¤ºäº†ç°ä»£LLMä¸­çš„ç»“æ„çµæ´»æ€§å¦‚ä½•æ¨åŠ¨æ¨ç†çš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22572v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä¸­æåˆ°çš„Test-Time Scalingï¼ˆTTSï¼‰é€šè¿‡æ¨ç†æ—¶åˆ†é…é¢å¤–çš„è®¡ç®—èµ„æºå¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºè¾“å‡ºçº§åˆ«çš„é‡‡æ ·ï¼Œè€Œå¿½ç•¥äº†æ¨¡å‹æ¶æ„çš„ä½œç”¨ã€‚æœ¬æ–‡è§‚å¯Ÿåˆ°ä¸»æµæ··åˆä¸“å®¶ï¼ˆMoEï¼‰LLMä¸­æ¿€æ´»çš„ä¸“å®¶æ•°é‡ä¸åŒä¼šäº§ç”Ÿäº’è¡¥çš„è§£å†³æ–¹æ¡ˆé›†ï¼Œå¹¶å…·æœ‰ç¨³å®šçš„å‡†ç¡®æ€§ï¼Œæ­ç¤ºäº†ä¸€ç§æ–°çš„æœªè¢«å……åˆ†æ¢ç´¢çš„å¤šæ ·æ€§æ¥æºã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œæœ¬æ–‡æå‡ºäº†Dynamic Experts Searchï¼ˆDESï¼‰çš„TTSç­–ç•¥ï¼Œå°†ä¸“å®¶æ¿€æ´»æå‡ä¸ºæœç´¢ç©ºé—´çš„å¯æ§ç»´åº¦ã€‚DESåŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŠ¨æ€MoEå’Œä¸“å®¶é…ç½®ç»§æ‰¿ã€‚åŠ¨æ€MoEèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­ç›´æ¥æ§åˆ¶ä¸“å®¶æ•°é‡ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„æ¨ç†è½¨è¿¹è€Œæ— éœ€é¢å¤–æˆæœ¬ï¼›ä¸“å®¶é…ç½®ç»§æ‰¿åˆ™èƒ½å¤Ÿåœ¨æ¨ç†è·¯å¾„å†…ä¿æŒä¸€è‡´çš„ä¸“å®¶æ•°é‡ï¼ŒåŒæ—¶åœ¨å¤šæ¬¡è¿è¡Œä¸­å˜åŒ–å®ƒä»¬ï¼Œä»è€Œåœ¨æœç´¢ä¸­å¹³è¡¡ç¨³å®šæ€§å’Œå¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDESåœ¨MoEæ¶æ„ã€éªŒè¯å™¨å’Œæ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆä¾‹å¦‚æ•°å­¦ã€ä»£ç å’ŒçŸ¥è¯†ï¼‰ä¸Šå¯é åœ°ä¼˜äºTTSåŸºçº¿ï¼Œæé«˜äº†å‡†ç¡®æ€§å’Œç¨³å®šæ€§ä¸”æ— éœ€é¢å¤–æˆæœ¬ã€‚è¿™äº›ç»“æœçªå‡ºäº†DESä½œä¸ºå®ç”¨ä¸”å¯æ‰©å±•çš„æ¶æ„æ„ŸçŸ¥TTSå½¢å¼çš„ç‰¹ç‚¹ï¼Œå±•ç¤ºäº†ç°ä»£LLMä¸­ç»“æ„çµæ´»æ€§åœ¨æ¨ç†æ–¹é¢çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Test-Time Scaling (TTS) é€šè¿‡åœ¨æ¨ç†æ—¶åˆ†é…é¢å¤–è®¡ç®—èµ„æºï¼Œæé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰TTSæ–¹æ³•ä¸»è¦å…³æ³¨è¾“å‡ºçº§åˆ«çš„é‡‡æ ·ï¼Œå¿½ç•¥äº†æ¨¡å‹æ¶æ„çš„ä½œç”¨ã€‚</li>
<li>åœ¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰LLMsä¸­ï¼Œæ¿€æ´»çš„ä¸“å®¶æ•°é‡ä¸åŒä¼šäº§ç”Ÿä¸åŒçš„è§£å†³æ–¹æ¡ˆé›†ï¼Œè¡¨ç°å‡ºç¨³å®šçš„å‡†ç¡®æ€§ã€‚</li>
<li>Dynamic Experts Search (DES) æ˜¯ä¸€ç§æ–°çš„TTSç­–ç•¥ï¼Œå°†ä¸“å®¶æ¿€æ´»ä½œä¸ºæœç´¢ç©ºé—´çš„å¯æ§ç»´åº¦ã€‚</li>
<li>DESåŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŠ¨æ€MoEå’Œä¸“å®¶é…ç½®ç»§æ‰¿ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­ç›´æ¥æ§åˆ¶ä¸“å®¶æ•°é‡å¹¶ç”Ÿæˆå¤šæ ·åŒ–è½¨è¿¹ï¼ŒåŒæ—¶ä¿æŒæ¨ç†è·¯å¾„å†…çš„ä¸“å®¶æ•°é‡ä¸€è‡´æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜DESåœ¨å¤šç§MoEæ¶æ„å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šä¼˜äºç°æœ‰TTSæ–¹æ³•ï¼Œæé«˜äº†å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œä¸”æ— éœ€é¢å¤–æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22572">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c6eb411d6309d9fa6012c40fb742c8f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826525&auth_key=1760826525-0-0-a515f6f8fd0e0cc01c182ae10b0f58db&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d84d1070476f742f5eca80724d899519~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826553&auth_key=1760826553-0-0-f4214aaed53c6198a3378909a476d54a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-df408d6615225b002a326d82d15e2cf8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826559&auth_key=1760826559-0-0-c0dbe305398a0b101e599cb011bda77f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e2c75eb1fd550f071622b564bd8bc2a3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826566&auth_key=1760826566-0-0-2e12fd84ee7826ddc29e26384e5cdcd1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-61d527f5dfa72b4247df0be816b64da4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826573&auth_key=1760826573-0-0-9fe12d3b1121db08ea3742ad37932b09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Kernel-Regression-of-Multi-Way-Data-via-Tensor-Trains-with-Hadamard-Overparametrization-The-Dynamic-Graph-Flow-Case"><a href="#Kernel-Regression-of-Multi-Way-Data-via-Tensor-Trains-with-Hadamard-Overparametrization-The-Dynamic-Graph-Flow-Case" class="headerlink" title="Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard   Overparametrization: The Dynamic Graph Flow Case"></a>Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard   Overparametrization: The Dynamic Graph Flow Case</h2><p><strong>Authors:Duc Thien Nguyen, Konstantinos Slavakis, Eleftherios Kofidis, Dimitris Pados</strong></p>
<p>A regression-based framework for interpretable multi-way data imputation, termed Kernel Regression via Tensor Trains with Hadamard overparametrization (KReTTaH), is introduced. KReTTaH adopts a nonparametric formulation by casting imputation as regression via reproducing kernel Hilbert spaces. Parameter efficiency is achieved through tensors of fixed tensor-train (TT) rank, which reside on low-dimensional Riemannian manifolds, and is further enhanced via Hadamard overparametrization, which promotes sparsity within the TT parameter space. Learning is accomplished by solving a smooth inverse problem posed on the Riemannian manifold of fixed TT-rank tensors. As a representative application, the estimation of dynamic graph flows is considered. In this setting, KReTTaH exhibits flexibility by seamlessly incorporating graph-based (topological) priors via its inverse problem formulation. Numerical tests on real-world graph datasets demonstrate that KReTTaH consistently outperforms state-of-the-art alternatives-including a nonparametric tensor- and a neural-network-based methods-for imputing missing, time-varying edge flows. </p>
<blockquote>
<p>ä»‹ç»äº†ä¸€ç§åŸºäºå›å½’çš„å¯è§£é‡Šå¤šå…ƒæ•°æ®è¡¥å…¨æ¡†æ¶ï¼Œç§°ä¸ºé€šè¿‡å¼ é‡åˆ—è½¦å’Œå“ˆè¾¾ç›è¶…å‚æ•°åŒ–å®ç°çš„æ ¸å›å½’ï¼ˆKReTTaHï¼‰ã€‚KReTTaHé‡‡ç”¨éå‚æ•°å…¬å¼ï¼Œé€šè¿‡å°†è¡¥å…¨è¡¨ç¤ºä¸ºé€šè¿‡å†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´çš„å›å½’æ¥å®ç°ã€‚é€šè¿‡å›ºå®šå¼ é‡åˆ—è½¦ï¼ˆTTï¼‰ç§©çš„å¼ é‡ï¼Œå®ƒä»¬åœ¨ä½ç»´é»æ›¼æµå½¢ä¸Šå®ç°å‚æ•°æ•ˆç‡ï¼Œå¹¶é€šè¿‡å“ˆè¾¾ç›è¶…å‚æ•°åŒ–è¿›ä¸€æ­¥å¢å¼ºï¼Œè¿™ä¿ƒè¿›äº†TTå‚æ•°ç©ºé—´å†…çš„ç¨€ç–æ€§ã€‚å­¦ä¹ æ˜¯é€šè¿‡è§£å†³å›ºå®šTTç§©å¼ é‡ä¸Šçš„é»æ›¼æµå½¢ä¸Šçš„å¹³æ»‘åé—®é¢˜æ¥å®ç°çš„ã€‚ä½œä¸ºä¸€ä¸ªå…¸å‹çš„åº”ç”¨ï¼Œè€ƒè™‘äº†åŠ¨æ€å›¾æµçš„ä¼°è®¡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒKReTTaHé€šè¿‡å…¶åé—®é¢˜å…¬å¼çµæ´»åœ°èå…¥äº†åŸºäºå›¾çš„ï¼ˆæ‹“æ‰‘ï¼‰å…ˆéªŒçŸ¥è¯†ã€‚å¯¹çœŸå®ä¸–ç•Œå›¾æ•°æ®é›†è¿›è¡Œçš„æ•°å€¼æµ‹è¯•è¡¨æ˜ï¼ŒKReTTaHå§‹ç»ˆä¼˜äºæœ€æ–°çš„æ›¿ä»£æ–¹æ¡ˆâ€”â€”åŒ…æ‹¬ä¸€ç§ç”¨äºè¡¥å…¨ç¼ºå¤±çš„ã€æ—¶é—´å˜åŒ–çš„è¾¹ç¼˜æµçš„éå‚æ•°å¼ é‡å’ŒåŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22197v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå›å½’çš„å¤šæ–¹å¼æ•°æ®å¡«å……æ¡†æ¶Kernel Regression via Tensor Trains with Hadamard overparametrizationï¼ˆç®€ç§°KReTTaHï¼‰è¢«å¼•å…¥ã€‚KReTTaHé€šè¿‡å°†æ•°æ®å¡«å……ä½œä¸ºå›å½’è½¬æ¢ä¸ºå†ç”Ÿæ ¸å¸Œå°”ä¼¯ç‰¹ç©ºé—´çš„æ–¹å¼å®ç°éå‚æ•°åŒ–å…¬å¼åŒ–è¡¨è¾¾ã€‚å®ƒé€šè¿‡åœ¨å›ºå®šå¼ é‡åˆ—è½¦ï¼ˆTTï¼‰ç­‰çº§å¼ é‡ä¸Šå®ç°çš„å‚æ•°æ•ˆç‡è¾¾åˆ°é«˜æ•ˆçŠ¶æ€ï¼Œåœ¨ç›¸å¯¹ç®€å•çš„ä½ç»´æµå½¢ä¸Šäº§ç”ŸçŸ©é˜µç©ºé—´çš„éšå±‚æ•ˆåº”ï¼›ç„¶åé€šè¿‡å“ˆè¾¾ç›è¶…å‚æ•°åŒ–è¿›ä¸€æ­¥å¢å¼ºäº†å…¶æ•ˆæœï¼Œåœ¨TTå‚æ•°ç©ºé—´ä¸­ä¿ƒè¿›äº†ç¨€ç–æ€§ã€‚å­¦ä¹ æ˜¯é€šè¿‡è§£å†³å›ºå®šTTç­‰çº§å¼ é‡ä¸Šçš„æµå½¢å¹³æ»‘åé—®é¢˜æ¥å®ç°çš„ã€‚ä½œä¸ºå…¸å‹åº”ç”¨ï¼Œè€ƒè™‘äº†åŠ¨æ€å›¾æµçš„ä¼°è®¡é—®é¢˜ã€‚åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼ŒKReTTaHå±•ç°å‡ºäº†çµæ´»æ€§ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°é€šè¿‡å…¶åé—®é¢˜å½¢å¼èå…¥åŸºäºå›¾çš„å…ˆéªŒçŸ¥è¯†ã€‚åœ¨çœŸå®å›¾å½¢æ•°æ®é›†ä¸Šçš„æ•°å€¼æµ‹è¯•è¡¨æ˜ï¼Œç›¸è¾ƒäºæœ€æ–°çš„éå‚æ•°å¼ é‡æ–¹æ³•ä»¥åŠç¥ç»ç½‘ç»œæ–¹æ³•ï¼ŒKReTTaHå…·æœ‰å‡ºè‰²çš„ç¼ºå¤±ã€æ—¶é—´åŠ¨æ€è¾¹ç¼˜æµé¢„æµ‹æ€§èƒ½ã€‚åœ¨è¡¥é½ç¼ºå¤±æ•°æ®æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KReTTaHæ˜¯ä¸€ç§åŸºäºå›å½’çš„å¤šæ–¹å¼æ•°æ®å¡«å……æ¡†æ¶ï¼Œé€šè¿‡éå‚æ•°åŒ–å…¬å¼å®ç°æ•°æ®å¡«å……ã€‚</li>
<li>KReTTaHåˆ©ç”¨å›ºå®šå¼ é‡åˆ—è½¦ï¼ˆTTï¼‰ç­‰çº§å¼ é‡çš„å‚æ•°æ•ˆç‡è¿›è¡Œè¿ç®—ä¼˜åŒ–ã€‚</li>
<li>å“ˆè¾¾ç›è¶…å‚æ•°åŒ–å¢å¼ºäº†KReTTaHçš„æ€§èƒ½ï¼Œä¿ƒè¿›äº†TTå‚æ•°ç©ºé—´ä¸­çš„ç¨€ç–æ€§ã€‚</li>
<li>å­¦ä¹ è¿‡ç¨‹æ˜¯é€šè¿‡è§£å†³å›ºå®šTTç­‰çº§å¼ é‡ä¸Šçš„æµå½¢å¹³æ»‘åé—®é¢˜æ¥å®ç°çš„ã€‚</li>
<li>KReTTaHåœ¨åŠ¨æ€å›¾æµä¼°è®¡ä¸­å…·æœ‰çµæ´»æ€§ï¼Œèƒ½å¤Ÿèå…¥åŸºäºå›¾çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>åœ¨çœŸå®å›¾å½¢æ•°æ®é›†ä¸Šçš„æ•°å€¼æµ‹è¯•ä¸­ï¼ŒKReTTaHç›¸è¾ƒäºå…¶ä»–æ–¹æ³•è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22197">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e6f757793f3baee5664853d473767103~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826581&auth_key=1760826581-0-0-bde8eeaf61e4796f623d5f27b90a64d4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8296be470f286114e44a8305ec28ac12~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826589&auth_key=1760826589-0-0-8646f8607d1650771d8a3cb649049845&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b6fa4a896f5b300871b9db623fbef733~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826595&auth_key=1760826595-0-0-aed8ddccdcf4af239daff226a540cd51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Semantic-VAE-Semantic-Alignment-Latent-Representation-for-Better-Speech-Synthesis"><a href="#Semantic-VAE-Semantic-Alignment-Latent-Representation-for-Better-Speech-Synthesis" class="headerlink" title="Semantic-VAE: Semantic-Alignment Latent Representation for Better Speech   Synthesis"></a>Semantic-VAE: Semantic-Alignment Latent Representation for Better Speech   Synthesis</h2><p><strong>Authors:Zhikang Niu, Shujie Hu, Jeongsoo Choi, Yushen Chen, Peining Chen, Pengcheng Zhu, Yunting Yang, Bowen Zhang, Jian Zhao, Chunhui Wang, Xie Chen</strong></p>
<p>While mel-spectrograms have been widely utilized as intermediate representations in zero-shot text-to-speech (TTS), their inherent redundancy leads to inefficiency in learning text-speech alignment. Compact VAE-based latent representations have recently emerged as a stronger alternative, but they also face a fundamental optimization dilemma: higher-dimensional latent spaces improve reconstruction quality and speaker similarity, but degrade intelligibility, while lower-dimensional spaces improve intelligibility at the expense of reconstruction fidelity. To overcome this dilemma, we propose Semantic-VAE, a novel VAE framework that utilizes semantic alignment regularization in the latent space. This design alleviates the reconstruction-generation trade-off by capturing semantic structure in high-dimensional latent representations. Extensive experiments demonstrate that Semantic-VAE significantly improves synthesis quality and training efficiency. When integrated into F5-TTS, our method achieves 2.10% WER and 0.64 speaker similarity on LibriSpeech-PC, outperforming mel-based systems (2.23%, 0.60) and vanilla acoustic VAE baselines (2.65%, 0.59). We also release the code and models to facilitate further research. </p>
<blockquote>
<p>è™½ç„¶æ¢…å°”é¢‘è°±å›¾å·²å¹¿æ³›åº”ç”¨äºé›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰çš„ä¸­é—´è¡¨ç¤ºï¼Œä½†å…¶å›ºæœ‰çš„å†—ä½™æ€§å¯¼è‡´æ–‡æœ¬è¯­éŸ³å¯¹é½å­¦ä¹ çš„ä¸é«˜æ•ˆã€‚åŸºäºç´§å‡‘å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰çš„æ½œåœ¨è¡¨ç¤ºæœ€è¿‘ä½œä¸ºä¸€ç§æ›´å¼ºçš„æ›¿ä»£æ–¹æ¡ˆå‡ºç°ï¼Œä½†å®ƒä»¬ä¹Ÿé¢ä¸´ä¸€ä¸ªåŸºæœ¬çš„ä¼˜åŒ–å›°å¢ƒï¼šé«˜ç»´æ½œåœ¨ç©ºé—´æé«˜äº†é‡å»ºè´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§ï¼Œä½†é™ä½äº†å¯æ‡‚åº¦ï¼Œè€Œä½ç»´ç©ºé—´æé«˜äº†å¯æ‡‚åº¦å´ä»¥ç‰ºç‰²é‡å»ºä¿çœŸåº¦ä¸ºä»£ä»·ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å›°å¢ƒï¼Œæˆ‘ä»¬æå‡ºäº†Semantic-VAEï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹VAEæ¡†æ¶ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ä½¿ç”¨è¯­ä¹‰å¯¹é½æ­£åˆ™åŒ–ã€‚è¿™ç§è®¾è®¡é€šè¿‡æ•è·é«˜ç»´æ½œåœ¨è¡¨ç¤ºä¸­çš„è¯­ä¹‰ç»“æ„ï¼Œç¼“è§£äº†é‡å»º-ç”Ÿæˆä¹‹é—´çš„æƒè¡¡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSemantic-VAEæ˜¾è‘—æé«˜äº†åˆæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ã€‚å½“é›†æˆåˆ°F5-TTSä¸­æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨LibriSpeech-PCä¸Šå®ç°äº†2.10%çš„å•è¯é”™è¯¯ç‡å’Œ0.64çš„è¯´è¯äººç›¸ä¼¼æ€§ï¼Œä¼˜äºåŸºäºæ¢…å°”çš„ç³»ç»Ÿï¼ˆ2.23%ï¼Œ0.60ï¼‰å’Œæ™®é€šçš„å£°å­¦VAEåŸºçº¿ï¼ˆ2.65%ï¼Œ0.59ï¼‰ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†ä»£ç å’Œæ¨¡å‹ï¼Œä»¥ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22167v1">PDF</a> Submitted to ICASSP2026</p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä¸»è¦æ¢è®¨äº†åœ¨é›¶æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰è½¬æ¢ä¸­ï¼Œmel-spectrogramsä½œä¸ºä¸­é—´è¡¨ç¤ºå½¢å¼çš„å¹¿æ³›åº”ç”¨åŠå…¶å­˜åœ¨çš„å†—ä½™é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°å‹çš„VAEæ¡†æ¶â€”â€”Semantic-VAEï¼Œå®ƒé€šè¿‡åœ¨é«˜ç»´æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œè¯­ä¹‰å¯¹é½æ­£åˆ™åŒ–ï¼Œæ”¹å–„äº†é‡å»ºç”Ÿæˆä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒSemantic-VAEèƒ½æ˜¾è‘—æé«˜åˆæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>mel-spectrogramsåœ¨TTSä¸­çš„å¹¿æ³›åº”ç”¨å­˜åœ¨å†—ä½™é—®é¢˜ï¼Œå¯¼è‡´æ–‡æœ¬è¯­éŸ³å¯¹é½å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚</li>
<li>ç´§å‡‘å‹VAEåŸºæ½œåœ¨è¡¨ç¤ºä½œä¸ºä¸€ç§æ›´å¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆå‡ºç°ï¼Œä½†å®ƒä»¬é¢ä¸´ä¼˜åŒ–å›°å¢ƒï¼šé«˜ç»´æ½œåœ¨ç©ºé—´å¯æé«˜é‡å»ºè´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§ï¼Œä½†ä¼šé™ä½å¯ç†è§£æ€§ï¼›ä½ç»´ç©ºé—´åˆ™åä¹‹ã€‚</li>
<li>Semantic-VAEæ˜¯ä¸€ç§æ–°å‹çš„VAEæ¡†æ¶ï¼Œé€šè¿‡åœ¨é«˜ç»´æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œè¯­ä¹‰å¯¹é½æ­£åˆ™åŒ–ï¼Œè§£å†³äº†é‡å»ºç”Ÿæˆä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚</li>
<li>Semantic-VAEæ˜¾è‘—æé«˜äº†åˆæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ã€‚</li>
<li>åœ¨LibriSpeech-PCä¸Šï¼Œå°†Semantic-VAEé›†æˆåˆ°F5-TTSä¸­ï¼Œå®ç°äº†2.10%çš„WERï¼ˆè¯é”™è¯¯ç‡ï¼‰å’Œ0.64çš„è¯´è¯äººç›¸ä¼¼æ€§ï¼Œä¼˜äºåŸºäºmelçš„ç³»ç»Ÿï¼ˆ2.23%ï¼Œ0.60ï¼‰å’Œæ™®é€šçš„å£°å­¦VAEåŸºçº¿ï¼ˆ2.65%ï¼Œ0.59ï¼‰ã€‚</li>
<li>ç ”ç©¶è€…å…¬å¼€äº†ä»£ç å’Œæ¨¡å‹ï¼Œä»¥æ–¹ä¾¿è¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22167">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9bba48842c04ad3101ce690643583519~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826604&auth_key=1760826604-0-0-6cf4cd0ff47373ef74d9705bc8174584&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cdeeb1996b3c8c5223d91ef4264e1ec6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826610&auth_key=1760826610-0-0-ef49853dc55fa0850234d3686f5418e3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-eb4e9f69197bb90cf2cec7792be33c4d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826617&auth_key=1760826617-0-0-7ceb47327d8aaab1f3b58d3191869d8d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8f0ed2cd7b49d19e886ee268f866750b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826624&auth_key=1760826624-0-0-e06b408f78a56053fc09005cb40e7362&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0165b270309f7fcda4b7ded249ae2796~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826631&auth_key=1760826631-0-0-a236208d3713e647f3079e11b5262bd3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Think-Right-Not-More-Test-Time-Scaling-for-Numerical-Claim-Verification"><a href="#Think-Right-Not-More-Test-Time-Scaling-for-Numerical-Claim-Verification" class="headerlink" title="Think Right, Not More: Test-Time Scaling for Numerical Claim   Verification"></a>Think Right, Not More: Test-Time Scaling for Numerical Claim   Verification</h2><p><strong>Authors:Primakov Chungkham, V Venktesh, Vinay Setty, Avishek Anand</strong></p>
<p>Fact-checking real-world claims, particularly numerical claims, is inherently complex that require multistep reasoning and numerical reasoning for verifying diverse aspects of the claim. Although large language models (LLMs) including reasoning models have made tremendous advances, they still fall short on fact-checking real-world claims that require a combination of compositional and numerical reasoning. They are unable to understand nuance of numerical aspects, and are also susceptible to the reasoning drift issue, where the model is unable to contextualize diverse information resulting in misinterpretation and backtracking of reasoning process. In this work, we systematically explore scaling test-time compute (TTS) for LLMs on the task of fact-checking complex numerical claims, which entails eliciting multiple reasoning paths from an LLM. We train a verifier model (VERIFIERFC) to navigate this space of possible reasoning paths and select one that could lead to the correct verdict. We observe that TTS helps mitigate the reasoning drift issue, leading to significant performance gains for fact-checking numerical claims. To improve compute efficiency in TTS, we introduce an adaptive mechanism that performs TTS selectively based on the perceived complexity of the claim. This approach achieves 1.8x higher efficiency than standard TTS, while delivering a notable 18.8% performance improvement over single-shot claim verification methods. Our code and data can be found at <a target="_blank" rel="noopener" href="https://github.com/VenkteshV/VerifierFC">https://github.com/VenkteshV/VerifierFC</a> </p>
<blockquote>
<p>äº‹å®æ ¸æŸ¥ç°å®ä¸–ç•Œä¸­çš„é™ˆè¿°ï¼Œç‰¹åˆ«æ˜¯æ•°å­—é™ˆè¿°ï¼Œæœ¬è´¨ä¸Šæ˜¯å¤æ‚çš„ï¼Œéœ€è¦å¤šæ­¥éª¤æ¨ç†å’Œæ•°å€¼æ¨ç†æ¥éªŒè¯é™ˆè¿°çš„å„ä¸ªæ–¹é¢ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆåŒ…æ‹¬æ¨ç†æ¨¡å‹ï¼‰å·²ç»å–å¾—äº†å·¨å¤§çš„è¿›æ­¥ï¼Œä½†å®ƒä»¬ä»ç„¶ä¸è¶³ä»¥æ ¸æŸ¥ç°å®ä¸–ç•Œä¸­éœ€è¦ç»“åˆç»„åˆå’Œæ•°å€¼æ¨ç†çš„é™ˆè¿°ã€‚å®ƒä»¬æ— æ³•ç†è§£æ•°å­—æ–¹é¢çš„ç»†å¾®å·®åˆ«ï¼Œä¹Ÿå®¹æ˜“å‡ºç°æ¨ç†æ¼‚ç§»é—®é¢˜ï¼Œå³æ¨¡å‹æ— æ³•æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£å¤šæ ·åŒ–çš„ä¿¡æ¯ï¼Œå¯¼è‡´è¯¯è§£å’Œæ¨ç†è¿‡ç¨‹å›æº¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22101v1">PDF</a> Accepted to EMNLP 2025, 19 pages</p>
<p><strong>æ‘˜è¦</strong></p>
<p>é’ˆå¯¹äº‹å®æ ¸æŸ¥ä¸­çš„å¤æ‚æ•°å€¼ä¸»å¼ ï¼Œç‰¹åˆ«æ˜¯éœ€è¦å¤šæ­¥éª¤æ¨ç†å’Œæ•°å€¼æ¨ç†çš„ä¸»å¼ ï¼Œå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŒ…æ‹¬æ¨ç†æ¨¡å‹å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸è¶³ã€‚æœ¬å·¥ä½œç³»ç»Ÿåœ°æ¢ç´¢äº†åˆ©ç”¨æµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆTTSï¼‰å¯¹LLMè¿›è¡Œæ‰©å±•ï¼Œä»¥åº”å¯¹äº‹å®æ ¸æŸ¥å¤æ‚æ•°å€¼ä¸»å¼ çš„ä»»åŠ¡ã€‚æˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªéªŒè¯å™¨æ¨¡å‹ï¼ˆVERIFIERFCï¼‰ï¼Œä»¥åœ¨å¯èƒ½çš„æ¨ç†è·¯å¾„ä¸­å¯¼èˆªå¹¶é€‰æ‹©å¯èƒ½å¯¼è‡´æ­£ç¡®ç»“è®ºçš„è·¯å¾„ã€‚è§‚å¯Ÿå‘ç°ï¼ŒTTSæœ‰åŠ©äºç¼“è§£æ¨ç†æ¼‚ç§»é—®é¢˜ï¼Œæ˜¾è‘—æé«˜äº‹å®æ ¸æŸ¥æ•°å€¼ä¸»å¼ çš„æ€§èƒ½ã€‚ä¸ºæé«˜TTSçš„è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”æœºåˆ¶ï¼Œæ ¹æ®ä¸»å¼ çš„å¤æ‚æ€§æœ‰é€‰æ‹©åœ°è¿›è¡ŒTTSã€‚è¯¥æ–¹æ³•å®ç°äº†æ¯”æ ‡å‡†TTSé«˜å‡º1.8å€çš„è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åœ¨å•æ¬¡ä¸»å¼ éªŒè¯æ–¹æ³•ä¸Šå®ç°äº†18.8%çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>äº‹å®æ ¸æŸ¥ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå¤æ‚æ•°å€¼ä¸»å¼ çš„æ ¸æŸ¥ï¼Œéœ€è¦å¤šæ­¥éª¤å’Œæ•°å€¼æ¨ç†ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸­ä»æœ‰å±€é™ï¼Œéš¾ä»¥å¤„ç†ç»„åˆäº†ç»„åˆå’Œæ•°å€¼æ¨ç†çš„ä¸»å¼ ã€‚</li>
<li>æµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆTTSï¼‰æœ‰åŠ©äºç¼“è§£æ¨ç†æ¼‚ç§»é—®é¢˜ï¼Œæé«˜äº‹å®æ ¸æŸ¥æ€§èƒ½ã€‚</li>
<li>VERIFIERFCæ¨¡å‹èƒ½å¤Ÿåœ¨å¯èƒ½çš„æ¨ç†è·¯å¾„ä¸­å¯¼èˆªå¹¶é€‰æ‹©æœ€ä½³è·¯å¾„ã€‚</li>
<li>è‡ªé€‚åº”TTSæœºåˆ¶æ ¹æ®ä¸»å¼ çš„å¤æ‚æ€§è¿›è¡Œé€‰æ‹©ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡ã€‚</li>
<li>ä¸æ ‡å‡†TTSç›¸æ¯”ï¼Œè‡ªé€‚åº”æœºåˆ¶å®ç°äº†æ›´é«˜çš„æ•ˆç‡ã€‚</li>
<li>ä¸å•æ¬¡ä¸»å¼ éªŒè¯æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3285c48225e3b2c5709dd75281002166~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826639&auth_key=1760826639-0-0-58c883fc12e25946ca35c016cc2ba473&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bd1b3b09625da150d5948392a14631f1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826646&auth_key=1760826646-0-0-8469435fb36e068c8be8af74a518bc83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Comprehend-and-Talk-Text-to-Speech-Synthesis-via-Dual-Language-Modeling"><a href="#Comprehend-and-Talk-Text-to-Speech-Synthesis-via-Dual-Language-Modeling" class="headerlink" title="Comprehend and Talk: Text to Speech Synthesis via Dual Language Modeling"></a>Comprehend and Talk: Text to Speech Synthesis via Dual Language Modeling</h2><p><strong>Authors:Junjie Cao, Yichen Han, Ruonan Zhang, Xiaoyang Hao, Hongxiang Li, Shuaijiang Zhao, Yue Liu, Xiao-Ping Zhng</strong></p>
<p>Existing Large Language Model (LLM) based autoregressive (AR) text-to-speech (TTS) systems, while achieving state-of-the-art quality, still face critical challenges. The foundation of this LLM-based paradigm is the discretization of the continuous speech waveform into a sequence of discrete tokens by neural audio codec. However, single codebook modeling is well suited to text LLMs, but suffers from significant information loss; hierarchical acoustic tokens, typically generated via Residual Vector Quantization (RVQ), often lack explicit semantic structure, placing a heavy learning burden on the model. Furthermore, the autoregressive process is inherently susceptible to error accumulation, which can degrade generation stability. To address these limitations, we propose CaT-TTS, a novel framework for robust and semantically-grounded zero-shot synthesis. First, we introduce S3Codec, a split RVQ codec that injects explicit linguistic features into its primary codebook via semantic distillation from a state-of-the-art ASR model, providing a structured representation that simplifies the learning task. Second, we propose an <code>Understand-then-Generate&#39;&#39; dual-Transformer architecture that decouples comprehension from rendering. An initial </code>Understandingâ€™â€™ Transformer models the cross-modal relationship between text and the audioâ€™s semantic tokens to form a high-level utterance plan. A subsequent &#96;&#96;Generationâ€™â€™ Transformer then executes this plan, autoregressively synthesizing hierarchical acoustic tokens. Finally, to enhance generation stability, we introduce Masked Audio Parallel Inference (MAPI), a nearly parameter-free inference strategy that dynamically guides the decoding process to mitigate local errors. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨å›å½’ï¼ˆARï¼‰æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿè™½ç„¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„å“è´¨ï¼Œä½†ä»ç„¶é¢ä¸´å…³é”®æŒ‘æˆ˜ã€‚åŸºäºLLMçš„èŒƒå¼çš„åŸºç¡€æ˜¯å°†è¿ç»­çš„è¯­éŸ³æ³¢å½¢ç¦»æ•£åŒ–ä¸ºä¸€ç³»åˆ—ç¦»æ•£ä»¤ç‰Œï¼Œé€šè¿‡ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨å®ç°ã€‚ç„¶è€Œï¼Œå•ç æœ¬å»ºæ¨¡éå¸¸é€‚åˆæ–‡æœ¬LLMï¼Œä½†å­˜åœ¨ä¿¡æ¯æŸå¤±ä¸¥é‡çš„é—®é¢˜ï¼›é€šè¿‡æ®‹å·®å‘é‡é‡åŒ–ï¼ˆRVQï¼‰é€šå¸¸äº§ç”Ÿå±‚æ¬¡åŒ–çš„éŸ³é¢‘ä»¤ç‰Œï¼Œä½†å¾€å¾€ç¼ºä¹æ˜ç¡®çš„è¯­ä¹‰ç»“æ„ï¼Œç»™æ¨¡å‹å¸¦æ¥äº†æ²‰é‡çš„å­¦ä¹ è´Ÿæ‹…ã€‚æ­¤å¤–ï¼Œè‡ªåŠ¨å›å½’è¿‡ç¨‹æœ¬è´¨ä¸Šå®¹æ˜“å‡ºé”™ç´¯ç§¯ï¼Œå¯èƒ½ä¼šé™ä½ç”Ÿæˆç¨³å®šæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Cat-TTSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¨³å¥å’Œè¯­ä¹‰åŸºç¡€é›¶å°„å‡»åˆæˆçš„å…¨æ–°æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†S3ç¼–è§£ç å™¨ï¼Œè¿™æ˜¯ä¸€ç§åˆ†è£‚çš„RVQç¼–è§£ç å™¨ï¼Œå®ƒé€šè¿‡æ¥è‡ªæœ€å…ˆè¿›çš„ASRæ¨¡å‹çš„è¯­ä¹‰è’¸é¦å°†å…¶ä¸»è¦ç æœ¬æ³¨å…¥æ˜¾å¼è¯­è¨€ç‰¹å¾ï¼Œæä¾›ç»“æ„åŒ–è¡¨ç¤ºï¼Œä»è€Œç®€åŒ–å­¦ä¹ ä»»åŠ¡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§â€œç†è§£ç„¶åç”Ÿæˆâ€çš„åŒTransformeræ¶æ„ï¼Œè¯¥æ¶æ„å°†ç†è§£ä¸æ¸²æŸ“è§£è€¦ã€‚åˆå§‹çš„â€œç†è§£â€Transformerå¯¹æ–‡æœ¬å’ŒéŸ³é¢‘è¯­ä¹‰ä»¤ç‰Œä¹‹é—´çš„è·¨æ¨¡æ€å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œä»¥å½¢æˆé«˜çº§è¯è¯­è®¡åˆ’ã€‚éšåçš„â€œç”Ÿæˆâ€Transformeråˆ™æ‰§è¡Œæ­¤è®¡åˆ’ï¼Œé€šè¿‡è‡ªåŠ¨å›å½’çš„æ–¹å¼åˆæˆå±‚æ¬¡åŒ–çš„éŸ³é¢‘ä»¤ç‰Œã€‚æœ€åï¼Œä¸ºäº†æé«˜ç”Ÿæˆçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†å‡ ä¹æ— éœ€å‚æ•°çš„Masked Audio Parallel Inferenceï¼ˆMAPIï¼‰æ¨ç†ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŠ¨æ€æŒ‡å¯¼è§£ç è¿‡ç¨‹ï¼Œç¼“è§£å±€éƒ¨é”™è¯¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22062v1">PDF</a> conference paper about TTS</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨å›å½’ï¼ˆARï¼‰æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿè™½ç„¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œä½†ä»é¢ä¸´å…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºCaT-TTSæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥S3Codecå’Œâ€œç†è§£åç”Ÿæˆâ€çš„åŒTransformeræ¶æ„ä»¥åŠå¸¦æœ‰Masked Audio Parallel Inferenceï¼ˆMAPIï¼‰çš„è§£ç è¿‡ç¨‹ï¼Œå®ç°äº†ç¨³å¥ä¸”è¯­ä¹‰åŸºç¡€çš„é›¶æ ·æœ¬åˆæˆã€‚S3Codecå°†æ˜¾å¼è¯­è¨€ç‰¹å¾æ³¨å…¥ä¸»è¦ç ç°¿ï¼Œæä¾›ç»“æ„åŒ–è¡¨ç¤ºä»¥ç®€åŒ–å­¦ä¹ ä»»åŠ¡ã€‚â€œç†è§£åç”Ÿæˆâ€æ¶æ„å°†ç†è§£å’Œæ¸²æŸ“è¿‡ç¨‹è§£è€¦ï¼Œå…ˆé€šè¿‡â€œç†è§£â€Transformerå»ºæ¨¡æ–‡æœ¬ä¸éŸ³é¢‘è¯­ä¹‰æ ‡è®°çš„è·¨æ¨¡æ€å…³ç³»ï¼Œå½¢æˆé«˜çº§è¯è¯­è®¡åˆ’ï¼Œç„¶åé€šè¿‡â€œç”Ÿæˆâ€Transformeræ‰§è¡Œè¯¥è®¡åˆ’ï¼Œè‡ªåŠ¨å›å½’åˆæˆå±‚æ¬¡åŒ–çš„å£°å­¦æ ‡è®°ã€‚æœ€åï¼Œé€šè¿‡å¼•å…¥MAPIç­–ç•¥å¢å¼ºç”Ÿæˆç¨³å®šæ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LLM-based AR-TTSç³»ç»Ÿè™½è¾¾åˆ°å…ˆè¿›è´¨é‡ï¼Œä½†ä»é¢ä¸´ä¿¡æ¯æŸå¤±ã€æ¨¡å‹å­¦ä¹ è´Ÿæ‹…é‡å’Œé”™è¯¯ç´¯ç§¯çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥S3Codecï¼šé‡‡ç”¨åˆ†è£‚RVQç ç»„æŠ€æœ¯ï¼Œé€šè¿‡æ¥è‡ªå…ˆè¿›ASRæ¨¡å‹çš„è¯­ä¹‰è’¸é¦æ³¨å…¥æ˜¾å¼è¯­è¨€ç‰¹å¾ï¼Œæä¾›ç»“æ„åŒ–è¡¨ç¤ºã€‚</li>
<li>æå‡ºâ€œç†è§£åç”Ÿæˆâ€åŒTransformeræ¶æ„ï¼šè§£è€¦ç†è§£å’Œæ¸²æŸ“è¿‡ç¨‹ï¼Œå½¢æˆé«˜çº§è¯è¯­è®¡åˆ’å¹¶æ‰§è¡Œã€‚</li>
<li>å¼•å…¥Masked Audio Parallel Inference (MAPI)ï¼šä¸€ç§å‡ ä¹æ— éœ€å‚æ•°çš„æ¨ç†ç­–ç•¥ï¼Œå¯åŠ¨æ€æŒ‡å¯¼è§£ç è¿‡ç¨‹ï¼Œå‡å°‘å±€éƒ¨é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22062">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-821b0a2ee5f764bf107f34fbe736c85a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826654&auth_key=1760826654-0-0-abaab567faa315a98ca7656e6543ad9a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5356647aa1b9972f1ee004b862dc2ad9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826661&auth_key=1760826661-0-0-abf8e6ac3e1d374b5a8a8e3b83019c62&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-891bc7cd2fc1a606f38558852114be48~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826667&auth_key=1760826667-0-0-199177cc68b30711bc337346f9e0155c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d5adbdfee431fd4ecb0553547272c81d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826673&auth_key=1760826673-0-0-3ba8d332ec777936087093cc49433bb3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Redefining-Machine-Simultaneous-Interpretation-From-Incremental-Translation-to-Human-Like-Strategies"><a href="#Redefining-Machine-Simultaneous-Interpretation-From-Incremental-Translation-to-Human-Like-Strategies" class="headerlink" title="Redefining Machine Simultaneous Interpretation: From Incremental   Translation to Human-Like Strategies"></a>Redefining Machine Simultaneous Interpretation: From Incremental   Translation to Human-Like Strategies</h2><p><strong>Authors:Qianen Zhang, Satoshi Nakamura</strong></p>
<p>Simultaneous Machine Translation (SiMT) requires high-quality translations under strict real-time constraints, which traditional encoder-decoder policies with only READ&#x2F;WRITE actions cannot fully address. We extend the action space of SiMT with four adaptive actions: SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION and PRONOMINALIZATION, which enable real-time restructuring, omission, and simplification while preserving semantic fidelity. We implement these actions in a decoder-only large language model (LLM) framework and construct training references through action-aware prompting. To evaluate both quality and latency, we further develop a latency-aware TTS pipeline that maps textual outputs to speech with realistic timing. Experiments on the ACL60&#x2F;60 English-Chinese and English-German benchmarks show that our framework consistently improves semantic metrics (e.g., COMET-KIWI) and achieves lower delay (measured by Average Lagging) compared to reference translations and salami-based baselines. Notably, combining DROP and SENTENCE_CUT yields the best overall balance between fluency and latency. These results demonstrate that enriching the action space of LLM-based SiMT provides a promising direction for bridging the gap between human and machine interpretation. </p>
<blockquote>
<p>åŒæ—¶æœºå™¨ç¿»è¯‘ï¼ˆSiMTï¼‰éœ€è¦åœ¨ä¸¥æ ¼çš„å®æ—¶çº¦æŸä¸‹å®ç°é«˜è´¨é‡çš„ç¿»è¯‘ï¼Œè€Œä¼ ç»Ÿçš„ä»…ä½¿ç”¨READ&#x2F;WRITEæ“ä½œçš„ç¼–ç å™¨-è§£ç å™¨ç­–ç•¥æ— æ³•å®Œå…¨æ»¡è¶³è¿™ä¸€éœ€æ±‚ã€‚æˆ‘ä»¬æ‰©å±•äº†SiMTçš„åŠ¨ä½œç©ºé—´ï¼Œå¢åŠ äº†å››ç§è‡ªé€‚åº”åŠ¨ä½œï¼šå¥å­åˆ‡å‰²ï¼ˆSENTENCE_CUTï¼‰ã€çœç•¥ï¼ˆDROPï¼‰ã€éƒ¨åˆ†æ‘˜è¦ï¼ˆPARTIAL_SUMMARIZATIONï¼‰å’Œä»£è¯åŒ–ï¼ˆPRONOMINALIZATIONï¼‰ï¼Œè¿™äº›åŠ¨ä½œèƒ½å¤Ÿåœ¨ä¿æŒè¯­ä¹‰å¿ å®åº¦çš„åŒæ—¶ï¼Œå®ç°å®æ—¶é‡ç»„ã€çœç•¥å’Œç®€åŒ–ã€‚æˆ‘ä»¬åœ¨ä»…è§£ç å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ä¸­å®ç°è¿™äº›åŠ¨ä½œï¼Œå¹¶é€šè¿‡åŠ¨ä½œæ„ŸçŸ¥æç¤ºæ„å»ºè®­ç»ƒå‚è€ƒã€‚ä¸ºäº†è¯„ä¼°è´¨é‡å’Œå»¶è¿Ÿï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ä¸ªå»¶è¿Ÿæ„ŸçŸ¥çš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç®¡é“ï¼Œå°†æ–‡æœ¬è¾“å‡ºæ˜ å°„ä¸ºå…·æœ‰ç°å®æ—¶é—´å®‰æ’çš„è¯­éŸ³ã€‚åœ¨ACL60&#x2F;60è‹±è¯­-ä¸­æ–‡å’Œè‹±è¯­-å¾·è¯­åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨è¯­ä¹‰æŒ‡æ ‡ï¼ˆå¦‚COMET-KIWIï¼‰ä¸ŠæŒç»­æé«˜ï¼Œä¸å‚è€ƒç¿»è¯‘å’ŒåŸºäºæ²™æ‹‰çš„åŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†æ›´ä½çš„å»¶è¿Ÿï¼ˆé€šè¿‡å¹³å‡æ»åæ—¶é—´æµ‹é‡ï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç»“åˆDROPå’ŒSENTENCE_CUTåŠ¨ä½œåœ¨æµç•…æ€§å’Œå»¶è¿Ÿä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚è¿™äº›ç»“æœè¯æ˜ï¼Œä¸°å¯ŒåŸºäºLLMçš„SiMTçš„åŠ¨ä½œç©ºé—´ä¸ºå¼¥åˆäººæœºè§£é‡Šä¹‹é—´çš„å·®è·æä¾›äº†ä¸€ä¸ªæœ‰å‰é€”çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21801v1">PDF</a> </p>
<p><strong>Summary</strong><br>     åŒæ­¥æœºå™¨ç¿»è¯‘ï¼ˆSiMTï¼‰éœ€è¦åœ¨ä¸¥æ ¼çš„æ—¶é—´çº¦æŸä¸‹æä¾›é«˜è´¨é‡çš„ç¿»è¯‘ï¼Œä¼ ç»Ÿçš„ä»…ä½¿ç”¨READ&#x2F;WRITEåŠ¨ä½œçš„ç¼–ç å™¨-è§£ç å™¨ç­–ç•¥æ— æ³•å®Œå…¨æ»¡è¶³è¿™ä¸€éœ€æ±‚ã€‚ç ”ç©¶å›¢é˜Ÿæ‰©å±•äº†SiMTçš„åŠ¨ä½œç©ºé—´ï¼Œå¢åŠ äº†å››ç§è‡ªé€‚åº”åŠ¨ä½œï¼šSENTENCE_CUTã€DROPã€PARTIAL_SUMMARIZATIONå’ŒPRONOMINALIZATIONï¼Œè¿™äº›åŠ¨ä½œèƒ½å¤Ÿåœ¨ä¿æŒè¯­ä¹‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå®ç°å®æ—¶é‡æ„ã€çœç•¥å’Œç®€åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä»…åŒ…å«è§£ç å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ä¸­å®ç°è¿™äº›åŠ¨ä½œï¼Œå¹¶é€šè¿‡åŠ¨ä½œæ„ŸçŸ¥æç¤ºæ„å»ºè®­ç»ƒå‚è€ƒã€‚ä¸ºäº†è¯„ä¼°ç¿»è¯‘è´¨é‡å’Œå»¶è¿Ÿï¼Œç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å¼€å‘äº†ä¸€ä¸ªå»¶è¿Ÿæ„ŸçŸ¥çš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç®¡é“ï¼Œå°†æ–‡æœ¬è¾“å‡ºæ˜ å°„ä¸ºå…·æœ‰ç°å®æ—¶é—´èŠ‚å¥çš„è¯­éŸ³ã€‚åœ¨ACL60&#x2F;60è‹±è¯­-ä¸­æ–‡å’Œè‹±è¯­-å¾·è¯­åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç ”ç©¶æ¡†æ¶åœ¨è¯­ä¹‰æŒ‡æ ‡ï¼ˆå¦‚COMET-KIWIï¼‰ä¸ŠæŒç»­æé«˜ï¼Œä¸å‚è€ƒç¿»è¯‘å’ŒåŸºäºæ²™æ‹‰çš„åŸºçº¿ç›¸æ¯”ï¼Œå®ç°äº†æ›´ä½çš„å»¶è¿Ÿï¼ˆé€šè¿‡å¹³å‡æ»åæµ‹é‡ï¼‰ã€‚ç‰¹åˆ«æ˜¯ï¼Œç»“åˆDROPå’ŒSENTENCE_CUTåŠ¨ä½œåœ¨æµç•…æ€§å’Œå»¶è¿Ÿä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚è¿™ä¸€ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸°å¯ŒLLMåŸºäºSiMTçš„åŠ¨ä½œç©ºé—´ä¸ºç¼©å°äººæœºè§£é‡Šä¹‹é—´çš„å·®è·æä¾›äº†æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿç¼–ç å™¨-è§£ç å™¨ç­–ç•¥æ— æ³•æ»¡è¶³ä¸¥æ ¼å®æ—¶çº¦æŸä¸‹çš„é«˜è´¨é‡ç¿»è¯‘éœ€æ±‚ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæ‰©å±•äº†SiMTçš„åŠ¨ä½œç©ºé—´ï¼ŒåŒ…æ‹¬SENTENCE_CUTã€DROPã€PARTIAL_SUMMARIZATIONå’ŒPRONOMINALIZATIONç­‰è‡ªé€‚åº”åŠ¨ä½œã€‚</li>
<li>è¿™äº›åŠ¨ä½œèƒ½å¤Ÿåœ¨ä¿æŒè¯­ä¹‰ä¿çœŸåº¦çš„åŒæ—¶ï¼Œå®ç°å®æ—¶é‡æ„ã€çœç•¥å’Œç®€åŒ–ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿåœ¨å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ä¸­å®ç°è¿™äº›åŠ¨ä½œå¹¶é€šè¿‡åŠ¨ä½œæ„ŸçŸ¥æç¤ºæ„å»ºè®­ç»ƒå‚è€ƒã€‚</li>
<li>ä¸ºè¯„ä¼°ç¿»è¯‘è´¨é‡å’Œå»¶è¿Ÿï¼Œå¼€å‘äº†ä¸€ä¸ªå»¶è¿Ÿæ„ŸçŸ¥çš„TTSç®¡é“ã€‚</li>
<li>åœ¨åŸºå‡†æµ‹è¯•ä¸Šï¼Œè¯¥æ¡†æ¶åœ¨è¯­ä¹‰æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¹¶å®ç°è¾ƒä½å»¶è¿Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21801">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-35b3070b82351a29fedfee6d7197dc78~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826681&auth_key=1760826681-0-0-1d32ac6487b4e446a90a0d6cf00c6b01&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d512202a68aeb9e11e055f06e78be7ff~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826688&auth_key=1760826688-0-0-8967c4a1bf8c430026f592b45eed87a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-67e137a857f40f613d5e3deac20a7728~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826694&auth_key=1760826694-0-0-0bcc2f1a995a5aaca6aa952aee2a3fd6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Align2Speak-Improving-TTS-for-Low-Resource-Languages-via-ASR-Guided-Online-Preference-Optimization"><a href="#Align2Speak-Improving-TTS-for-Low-Resource-Languages-via-ASR-Guided-Online-Preference-Optimization" class="headerlink" title="Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided   Online Preference Optimization"></a>Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided   Online Preference Optimization</h2><p><strong>Authors:Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Roy Fejgin, Ryan Langman, Mikyas Desta, Leili Tavabi, Jason Li</strong></p>
<p>Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owing to large-scale multilingual pre-training efforts. We propose a framework based on Group Relative Policy Optimization (GRPO) to adapt an autoregressive, multilingual TTS model to new languages. Our method first establishes a language-agnostic foundation for TTS synthesis by training a multilingual baseline with International Phonetic Alphabet (IPA) tokens. Next, we fine-tune this model on limited paired data of the new languages to capture the target languageâ€™s prosodic features. Finally, we apply GRPO to optimize the model using only unpaired text and speaker prompts, guided by a multi-objective reward from pretrained ASR, speaker verification, and audio quality estimation models. Experiments demonstrate that this pipeline produces intelligible and speaker-consistent speech in low-resource languages, substantially outperforming fine-tuning alone. Furthermore, our GRPO-based framework also improves TTS performance in high-resource languages, surpassing offline alignment methods such as Direct Preference Optimization (DPO) yielding superior intelligibility, speaker similarity, and audio quality. </p>
<blockquote>
<p>é’ˆå¯¹ä½èµ„æºè¯­è¨€çš„ä¼˜è´¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿå‘å±•é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºæ–‡æœ¬å’Œè¯­éŸ³æ•°æ®é…å¯¹ç¨€ç¼ºã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç”±äºå¤§è§„æ¨¡å¤šè¯­ç§é¢„è®­ç»ƒçš„åŠªåŠ›ï¼Œæ­¤ç±»è¯­è¨€çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹å¾€å¾€æ›´å®¹æ˜“è·å¾—ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„æ¡†æ¶ï¼Œä»¥é€‚åº”æ–°çš„è¯­è¨€çš„è‡ªå›å½’å¤šè¯­ç§TTSæ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé€šè¿‡ä¸å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰ç¬¦å·ä¸€èµ·è®­ç»ƒå¤šè¯­ç§åŸºçº¿ï¼Œä¸ºTTSåˆæˆå»ºç«‹ä¸€ç§è¯­è¨€æ— å…³çš„åŸºç¡€ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åœ¨æ–°è¯­è¨€çš„æœ‰é™é…å¯¹æ•°æ®ä¸Šå¯¹æ­¤æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æ•è·ç›®æ ‡è¯­è¨€çš„éŸµå¾‹ç‰¹å¾ã€‚æœ€åï¼Œæˆ‘ä»¬åº”ç”¨GRPOä»…ä½¿ç”¨æœªé…å¯¹çš„æ–‡æœ¬å’Œè¯´è¯äººæç¤ºæ¥ä¼˜åŒ–æ¨¡å‹ï¼Œç”±é¢„è®­ç»ƒçš„ASRã€è¯´è¯äººéªŒè¯å’ŒéŸ³é¢‘è´¨é‡ä¼°è®¡æ¨¡å‹çš„å¤šç›®æ ‡å¥–åŠ±æ¥æŒ‡å¯¼ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç®¡é“åœ¨èµ„æºè´«ä¹çš„è¯­è¨€ä¸­äº§ç”Ÿå¯ç†è§£çš„ã€ä¸è¯´è¯äººä¸€è‡´çš„è¯­éŸ³ï¼Œæ˜æ˜¾ä¼˜äºå•çº¯çš„å¾®è°ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºGRPOçš„æ¡†æ¶è¿˜æé«˜äº†é«˜èµ„æºè¯­è¨€çš„TTSæ€§èƒ½ï¼Œè¶…è¶Šäº†ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ç­‰ç¦»çº¿å¯¹é½æ–¹æ³•ï¼Œäº§ç”Ÿäº†æ›´é«˜çš„å¯ç†è§£æ€§ã€è¯´è¯äººç›¸ä¼¼æ€§å’ŒéŸ³é¢‘è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21718v1">PDF</a> Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºGroup Relative Policy Optimization (GRPO)çš„æ–¹æ³•ï¼Œç”¨äºé€‚åº”æ–°çš„ä½èµ„æºè¯­è¨€çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿã€‚è¯¥æ–¹æ³•é¦–å…ˆå»ºç«‹ä¸€ä¸ªè·¨è¯­è¨€çš„TTSåˆæˆåŸºç¡€ï¼Œé€šè¿‡å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰ç¬¦å·è®­ç»ƒå¤šè¯­è¨€åŸºçº¿æ¨¡å‹ã€‚ç„¶åï¼Œåœ¨æ–°è¯­è¨€çš„æœ‰é™é…å¯¹æ•°æ®ä¸Šå¾®è°ƒæ­¤æ¨¡å‹ï¼Œä»¥æ•è·ç›®æ ‡è¯­è¨€çš„éŸµå¾‹ç‰¹å¾ã€‚æœ€åï¼Œåˆ©ç”¨GRPOä¼˜åŒ–æ¨¡å‹ï¼Œä»…ä½¿ç”¨æœªé…å¯¹çš„æ–‡æœ¬å’Œæ¼”è®²æç¤ºï¼Œç”±é¢„è®­ç»ƒçš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯´è¯äººéªŒè¯å’ŒéŸ³é¢‘è´¨é‡ä¼°è®¡æ¨¡å‹çš„å¤šå…ƒå¥–åŠ±å¼•å¯¼ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç®¡é“åœ¨èµ„æºåŒ®ä¹çš„è¯­è¨€ä¸­äº§ç”Ÿå¯ç†è§£å’Œå…·æœ‰è¯´è¯äººç‰¹è‰²çš„è¯­éŸ³ï¼Œæ˜æ˜¾ä¼˜äºä»…è¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒåŸºäºGRPOçš„æ¡†æ¶è¿˜æé«˜äº†é«˜èµ„æºè¯­è¨€çš„TTSæ€§èƒ½ï¼Œè¶…è¶Šäº†å¦‚Direct Preference Optimization (DPO)çš„ç¦»çº¿å¯¹é½æ–¹æ³•ï¼Œåœ¨å¯ç†è§£æ€§ã€è¯´è¯äººç›¸ä¼¼æ€§å’ŒéŸ³é¢‘è´¨é‡æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬æå‡ºä¸€ç§åŸºäºGRPOçš„æ¡†æ¶æ¥é€‚åº”ä½èµ„æºè¯­è¨€çš„TTSç³»ç»Ÿã€‚</li>
<li>é€šè¿‡IPAç¬¦å·å»ºç«‹è·¨è¯­è¨€çš„TTSåŸºç¡€ã€‚</li>
<li>åœ¨æ–°è¯­è¨€çš„æœ‰é™æ•°æ®ä¸Šå¾®è°ƒæ¨¡å‹ä»¥æ•è·ç›®æ ‡è¯­è¨€çš„éŸµå¾‹ç‰¹å¾ã€‚</li>
<li>ä½¿ç”¨GRPOä¼˜åŒ–æ¨¡å‹ï¼Œç»“åˆASRã€è¯´è¯äººéªŒè¯å’ŒéŸ³é¢‘è´¨é‡ä¼°è®¡æ¨¡å‹çš„å¤šå…ƒå¥–åŠ±ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ¡†æ¶åœ¨èµ„æºåŒ®ä¹çš„è¯­è¨€ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æé«˜TTSæ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶åŒæ ·é€‚ç”¨äºé«˜èµ„æºè¯­è¨€ï¼Œåœ¨å¯ç†è§£æ€§ã€è¯´è¯äººç›¸ä¼¼æ€§å’ŒéŸ³é¢‘è´¨é‡ä¸Šè¶…è¶ŠDPOæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21718">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c6b5c43704a64dd7a50c181c720d9e2c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826702&auth_key=1760826702-0-0-c808a0eb00ec738fe0ad7998918d3664&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3ce0e7b0c70f9121b0fe793905ee00f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826709&auth_key=1760826709-0-0-93814b7cbbfa8c6efac518649cb9e05d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-db2fc50a670cf665e8debd74954a1d3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826716&auth_key=1760826716-0-0-401b80184f7108a6c0404a1819f65c80&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-da6e73540d28fc38ba50fbf9d0c843e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826722&auth_key=1760826722-0-0-310ccf5e0d74fbcd84599545a28a9413&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c8b78ef6dcc3a27d4d97ff490c592b7d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826729&auth_key=1760826729-0-0-2925afe655369817ed883d3132303096&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SPADE-Structured-Pruning-and-Adaptive-Distillation-for-Efficient-LLM-TTS"><a href="#SPADE-Structured-Pruning-and-Adaptive-Distillation-for-Efficient-LLM-TTS" class="headerlink" title="SPADE: Structured Pruning and Adaptive Distillation for Efficient   LLM-TTS"></a>SPADE: Structured Pruning and Adaptive Distillation for Efficient   LLM-TTS</h2><p><strong>Authors:Tan Dat Nguyen, Jaehun Kim, Ji-Hoon Kim, Shukjae Choi, Youshin Lim, Joon Son Chung</strong></p>
<p>The goal of this paper is to introduce SPADE, a framework for Structured Pruning and Adaptive Distillation for Efficient Large Language Model-based text-to-speech (LLM-TTS). Recent LLM-TTS systems achieve strong controllability and zero-shot generalization, but their large parameter counts and high latency limit real-world deployment. SPADE addresses this by combining (i) a pruning step guided by a word-error-rate-based layer importance index to remove non-essential Transformer layers, with (ii) multi-level knowledge distillation to restore autoregressive coherence. On zero-shot benchmarks, SPADE preserves near-parity perceptual quality while halving Transformer depth, reducing VRAM usage by up to 20%, and achieving up to 1.7x faster real-time factor with less than 5% of the original training data. These results show that compact LLM-TTS models can maintain naturalness and speaker similarity while enabling practical real-time speech generation. Audio samples are available at <a target="_blank" rel="noopener" href="https://mm.kaist.ac.kr/projects/SPADE/">https://mm.kaist.ac.kr/projects/SPADE/</a>. </p>
<blockquote>
<p>æœ¬æ–‡çš„ç›®æ ‡æ˜¯ä»‹ç»SPADEï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆLLM-TTSï¼‰çš„ç»“æ„åŒ–å‰ªæå’Œè‡ªé€‚åº”è’¸é¦æ¡†æ¶ã€‚æœ€è¿‘çš„LLM-TTSç³»ç»Ÿå®ç°äº†å¼ºå¤§çš„å¯æ§æ€§å’Œé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œä½†å®ƒä»¬çš„å‚æ•°æ•°é‡åºå¤§å’Œå»¶è¿Ÿè¾ƒé«˜ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„éƒ¨ç½²ã€‚SPADEé€šè¿‡ç»“åˆï¼ˆiï¼‰ä»¥åŸºäºè¯é”™è¯¯ç‡çš„å±‚é‡è¦æ€§æŒ‡æ•°ä¸ºæŒ‡å¯¼çš„å‰ªææ­¥éª¤ï¼Œä»¥å»é™¤éå¿…è¦çš„Transformerå±‚ï¼Œä»¥åŠï¼ˆiiï¼‰å¤šå±‚æ¬¡çŸ¥è¯†è’¸é¦æ¥æ¢å¤è‡ªå›å½’ä¸€è‡´æ€§ï¼Œè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚åœ¨é›¶æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPADEåœ¨ä¿æŒè¿‘ä¹ç›¸å½“çš„æ„ŸçŸ¥è´¨é‡çš„åŒæ—¶ï¼Œå°†Transformerçš„æ·±åº¦å‡åŠï¼Œå°†VRAMä½¿ç”¨é‡å‡å°‘äº†é«˜è¾¾20%ï¼Œå¹¶ä¸”ä½¿ç”¨ä¸åˆ°5%çš„åŸå§‹è®­ç»ƒæ•°æ®å®ç°äº†é«˜è¾¾1.7å€çš„å®æ—¶å› å­ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç´§å‡‘çš„LLM-TTSæ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒè‡ªç„¶åº¦å’Œè¯­éŸ³è€…ç›¸ä¼¼æ€§çš„åŒæ—¶ï¼Œå®ç°å®ç”¨çš„å®æ—¶è¯­éŸ³ç”Ÿæˆã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://mm.kaist.ac.kr/projects/SPADE/%E6%89%BE%E5%88%B0%E3%80%82">https://mm.kaist.ac.kr/projects/SPADE/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20802v2">PDF</a> Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SPADEæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨å®ç°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰çš„ç»“æ„åŒ–å‰ªæå’Œè‡ªé€‚åº”è’¸é¦ã€‚SPADEé€šè¿‡ç»“åˆï¼ˆiï¼‰åŸºäºè¯é”™è¯¯ç‡çš„å±‚é‡è¦æ€§æŒ‡æ•°å¼•å¯¼çš„å‰ªææ­¥éª¤ï¼Œä»¥å»é™¤éå¿…è¦çš„Transformerå±‚ï¼Œï¼ˆiiï¼‰å¤šå±‚æ¬¡çŸ¥è¯†è’¸é¦ï¼Œä»¥æ¢å¤è‡ªå›å½’ä¸€è‡´æ€§ï¼Œæ¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„é«˜å‚æ•°è®¡æ•°å’Œé«˜å»¶è¿Ÿé—®é¢˜ã€‚SPADEèƒ½å¤Ÿåœ¨é›¶æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸­ä¿æŒè¿‘ä¹ç›¸ç­‰çš„æ„ŸçŸ¥è´¨é‡ï¼ŒåŒæ—¶ä½¿Transformeræ·±åº¦å‡åŠï¼Œå°†VRAMä½¿ç”¨é‡å‡å°‘é«˜è¾¾20%ï¼Œå¹¶ä»¥ä¸åˆ°åŸå§‹è®­ç»ƒæ•°æ®5%çš„æ•°æ®å®ç°é«˜è¾¾1.7å€çš„å®æ—¶å› å­ã€‚ç»“æœè¡¨æ˜ï¼Œç´§å‡‘çš„LLM-TTSæ¨¡å‹å¯ä»¥åœ¨ä¿æŒè‡ªç„¶æ€§å’Œè¯­éŸ³ç›¸ä¼¼æ€§çš„åŒæ—¶ï¼Œå®ç°å®ç”¨çš„å®æ—¶è¯­éŸ³ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SPADEæ˜¯ä¸€ä¸ªé’ˆå¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢ï¼ˆTTSï¼‰ç³»ç»Ÿçš„ç»“æ„åŒ–å‰ªæå’Œè‡ªé€‚åº”è’¸é¦æ¡†æ¶ã€‚</li>
<li>SPADEæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹é«˜å‚æ•°è®¡æ•°å’Œé«˜å»¶è¿Ÿé—®é¢˜ï¼Œé™åˆ¶å…¶åœ¨ç°å®ä¸–ç•Œçš„éƒ¨ç½²ã€‚</li>
<li>é€šè¿‡ç»“åˆå‰ªææ­¥éª¤å’Œå¤šå±‚æ¬¡çŸ¥è¯†è’¸é¦ï¼ŒSPADEèƒ½å¤Ÿå»é™¤éå¿…è¦çš„Transformerå±‚å¹¶æ¢å¤è‡ªå›å½’ä¸€è‡´æ€§ã€‚</li>
<li>åœ¨é›¶æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPADEåœ¨ä¿æŒè¿‘ä¹ç›¸ç­‰çš„æ„ŸçŸ¥è´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†Transformeræ·±åº¦çš„å‡åŠã€‚</li>
<li>SPADEæ–¹æ³•é™ä½äº†VRAMçš„ä½¿ç”¨é‡ï¼Œæé«˜äº†å®æ—¶è¯­éŸ³ç”Ÿæˆçš„æ•ˆç‡ã€‚</li>
<li>ä½¿ç”¨SPADEæ¡†æ¶ï¼Œå¯ä»¥å®ç°ä½¿ç”¨å°‘äºåŸå§‹è®­ç»ƒæ•°æ®5%çš„æ•°æ®è¾¾åˆ°é«˜è¾¾1.7å€çš„å®æ—¶å› å­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20802">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-eaef2ae54c54114870abd66b94ebc809~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826736&auth_key=1760826736-0-0-9fa68bdba3227d8a742af48aa76cab3e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b9098df3c5f5397b83d8f81e5b6afeee~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826743&auth_key=1760826743-0-0-92c049e1b52959d451dd495a2c5f90c3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d568c733eec88d9d70e7eac2fd141b4e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826750&auth_key=1760826750-0-0-b3a25273602ddbc27f85e43b7a0f935e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1face85ddeb2ea42c7bfca1ef2f29348~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826756&auth_key=1760826756-0-0-4954e34fefa9fa0051e9c35cd909a179&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CapSpeech-Enabling-Downstream-Applications-in-Style-Captioned-Text-to-Speech"><a href="#CapSpeech-Enabling-Downstream-Applications-in-Style-Captioned-Text-to-Speech" class="headerlink" title="CapSpeech: Enabling Downstream Applications in Style-Captioned   Text-to-Speech"></a>CapSpeech: Enabling Downstream Applications in Style-Captioned   Text-to-Speech</h2><p><strong>Authors:Helin Wang, Jiarui Hai, Dading Chong, Karan Thakkar, Tiantian Feng, Dongchao Yang, Junhyeok Lee, Thomas Thebaud, Laureano Moro Velazquez, Jesus Villalba, Zengyi Qin, Shrikanth Narayanan, Mounya Elhiali, Najim Dehak</strong></p>
<p>Recent advancements in generative artificial intelligence have significantly transformed the field of style-captioned text-to-speech synthesis (CapTTS). However, adapting CapTTS to real-world applications remains challenging due to the lack of standardized, comprehensive datasets and limited research on downstream tasks built upon CapTTS. To address these gaps, we introduce CapSpeech, a new benchmark designed for a series of CapTTS-related tasks, including style-captioned text-to-speech synthesis with sound events (CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS (EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech comprises over 10 million machine-annotated audio-caption pairs and nearly 0.36 million human-annotated audio-caption pairs. In addition, we introduce two new datasets collected and recorded by a professional voice actor and experienced audio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside the datasets, we conduct comprehensive experiments using both autoregressive and non-autoregressive models on CapSpeech. Our results demonstrate high-fidelity and highly intelligible speech synthesis across a diverse range of speaking styles. To the best of our knowledge, CapSpeech is the largest available dataset offering comprehensive annotations for CapTTS-related tasks. The experiments and findings further provide valuable insights into the challenges of developing CapTTS systems. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æœ€æ–°è¿›å±•ä¸ºå¸¦é£æ ¼æ ‡æ³¨çš„æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆCapTTSï¼‰é¢†åŸŸå¸¦æ¥äº†æ˜¾è‘—å˜é©ã€‚ç„¶è€Œï¼Œç”±äºç¼ºå°‘æ ‡å‡†åŒ–ã€å…¨é¢çš„æ•°æ®é›†ä»¥åŠåŸºäºCapTTSçš„ä¸‹æ¸¸ä»»åŠ¡ç ”ç©¶æœ‰é™ï¼Œå› æ­¤å°†CapTTSé€‚åº”äºç°å®åº”ç”¨ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†CapSpeechï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºä¸€ç³»åˆ—CapTTSç›¸å…³ä»»åŠ¡è®¾è®¡çš„æ–°åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬å¸¦æœ‰å£°éŸ³äº‹ä»¶çš„é£æ ¼æ ‡æ³¨æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆCapTTS-SEï¼‰ã€å£éŸ³æ ‡æ³¨çš„TTSï¼ˆAccCapTTSï¼‰ã€æƒ…æ„Ÿæ ‡æ³¨çš„TTSï¼ˆEmoCapTTSï¼‰ä»¥åŠç”¨äºèŠå¤©ä»£ç†çš„æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆAgentTTSï¼‰ã€‚CapSpeechåŒ…å«è¶…è¿‡10ä¸‡ä¸ªæœºå™¨æ ‡æ³¨çš„éŸ³é¢‘å­—å¹•å¯¹å’Œè¿‘36ä¸‡ä¸ªäººå·¥æ ‡æ³¨çš„éŸ³é¢‘å­—å¹•å¯¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä¸“é—¨æ”¶é›†å¹¶è®°å½•äº†ç”±ä¸“ä¸šé…éŸ³æ¼”å‘˜å’Œç»éªŒä¸°å¯Œçš„éŸ³é¢‘å·¥ç¨‹å¸ˆé’ˆå¯¹AgentTTSå’ŒCapTTS-SEä»»åŠ¡çš„æ•°æ®é›†ã€‚é™¤äº†æ•°æ®é›†ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨è‡ªå›å½’å’Œéè‡ªå›å½’æ¨¡å‹åœ¨CapSpeechä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨å„ç§ä¸åŒçš„è®²è¯é£æ ¼ä¸­ï¼Œè¯­éŸ³åˆæˆå…·æœ‰å¾ˆé«˜çš„ä¿çœŸåº¦å’Œé«˜åº¦å¯ç†è§£æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒCapSpeechæ˜¯ç›®å‰ä¸ºæ­¢ä¸ºCapTTSç›¸å…³ä»»åŠ¡æä¾›å…¨é¢æ ‡æ³¨çš„æœ€å¤§å¯ç”¨æ•°æ®é›†ã€‚å®éªŒå’Œå‘ç°è¿›ä¸€æ­¥ä¸ºå¼€å‘CapTTSç³»ç»Ÿæä¾›äº†å®è´µçš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02863v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è¿›å±•ä¸ºé£æ ¼æ ‡æ³¨æ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼ˆCapTTSï¼‰é¢†åŸŸå¸¦æ¥äº†é‡å¤§å˜é©ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ ‡å‡†åŒ–ç»¼åˆæ•°æ®é›†å’Œå¯¹åŸºäºCapTTSçš„ä¸‹æ¸¸ä»»åŠ¡çš„ç ”ç©¶æœ‰é™ï¼Œå°†å…¶åº”ç”¨äºå®é™…åœºæ™¯ä»å…·æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†CapSpeechï¼Œä¸€ä¸ªä¸ºCapTTSç›¸å…³ä»»åŠ¡è®¾è®¡çš„æ–°åŸºå‡†ï¼ŒåŒ…æ‹¬å¸¦æœ‰å£°éŸ³äº‹ä»¶çš„é£æ ¼æ ‡æ³¨æ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼ˆCapTTS-SEï¼‰ã€å£éŸ³æ ‡æ³¨TTSï¼ˆAccCapTTSï¼‰ã€æƒ…æ„Ÿæ ‡æ³¨TTSï¼ˆEmoCapTTSï¼‰å’Œç”¨äºèŠå¤©ä»£ç†çš„æ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼ˆAgentTTSï¼‰ã€‚CapSpeechåŒ…å«è¶…è¿‡10äº¿æœºå™¨æ ‡æ³¨çš„éŸ³é¢‘å­—å¹•å¯¹å’Œè¿‘ç™¾ä¸‡äººç±»æ ‡æ³¨çš„éŸ³é¢‘å­—å¹•å¯¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ”¶é›†å¹¶è®°å½•äº†ä¸“ä¸šé…éŸ³æ¼”å‘˜å’ŒéŸ³é¢‘å·¥ç¨‹å¸ˆé’ˆå¯¹AgentTTSå’ŒCapTTS-SEä»»åŠ¡çš„æ•°æ®é›†ã€‚åœ¨CapSpeechä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è‡ªå›å½’å’Œéè‡ªå›å½’æ¨¡å‹è¿›è¡Œäº†å…¨é¢çš„å®éªŒã€‚ç»“æœè¯æ˜äº†è·¨å¤šç§è¯´è¯é£æ ¼çš„é«˜ä¿çœŸåº¦å’Œé«˜åº¦å¯ç†è§£çš„è¯­éŸ³åˆæˆã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒCapSpeechæ˜¯ç›®å‰æœ€å¤§çš„ä¸ºCapTTSç›¸å…³ä»»åŠ¡æä¾›å…¨é¢æ³¨é‡Šçš„æ•°æ®é›†ã€‚å®éªŒå’Œå‘ç°ä¸ºå¼€å‘CapTTSç³»ç»Ÿæä¾›äº†å®è´µçš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è¿›æ­¥å·²ç»æ˜¾è‘—å½±å“äº†é£æ ¼æ ‡æ³¨æ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼ˆCapTTSï¼‰é¢†åŸŸã€‚</li>
<li>CapSpeechæ•°æ®é›†çš„æ¨å‡ºå¡«è¡¥äº†CapTTSç›¸å…³ä»»åŠ¡çš„æ ‡å‡†åŒ–ç»¼åˆæ•°æ®é›†çš„ç©ºç™½ã€‚</li>
<li>CapSpeechåŒ…å«å¤§é‡æœºå™¨å’Œäººç±»æ ‡æ³¨çš„éŸ³é¢‘å­—å¹•å¯¹ï¼Œé€‚ç”¨äºå¤šç§CapTTSç›¸å…³ä»»åŠ¡ã€‚</li>
<li>æ¨å‡ºæ–°æ•°æ®é›†ä»¥æ”¯æŒAgentTTSå’ŒCapTTS-SEä»»åŠ¡çš„ç ”ç©¶ã€‚</li>
<li>å…¨é¢çš„å®éªŒè¯æ˜äº†CapSpeechæ•°æ®é›†çš„é«˜è´¨é‡å’Œæœ‰æ•ˆæ€§ã€‚</li>
<li>å®éªŒç»“æœå±•ç¤ºäº†è·¨å¤šç§è¯´è¯é£æ ¼çš„é«˜ä¿çœŸåº¦å’Œé«˜åº¦å¯ç†è§£çš„è¯­éŸ³åˆæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f1e0065ab5460dd79c78be2491b4eeea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826765&auth_key=1760826765-0-0-e387c21683ecf15d2fe565be66f0eef3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2994167902a2a92e02f61b024e6505cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826772&auth_key=1760826772-0-0-dba0a75a5e314eb11dab260e8ec7f6b6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a48729e8f970353cfed675b263197c02~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826779&auth_key=1760826779-0-0-84fe6db67ac79329c705b08ed3b031bf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-276e3aa01391da5a19238425bc61e326~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826786&auth_key=1760826786-0-0-e9630ad217ead798d25ffa25d6e73e0c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9b19c810c2f20bd49e5ec1215a3c572a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826793&auth_key=1760826793-0-0-812182fe0bb01cd32f9f6a3a10df8eb4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-82ec2a09c410482cafbd83236be194e7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826799&auth_key=1760826799-0-0-1febcb8aab6336f6b377ce2593f0c0af&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-30/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-30/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-30/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-abcd9fd41b15a121aa3e125d188b2dde~resize:0:q75.jpg?source=1f5c5e47&expiration=1760826807&auth_key=1760826807-0-0-9d99a7b38f7b4b21a456523b5fd42e1c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  VoiceAssistant-Eval Benchmarking AI Assistants across Listening,   Speaking, and Viewing
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-30/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-253247c48e5f4fe4758606f516fd9b41~resize:0:q75.jpg?source=1f5c5e47&expiration=1759995016&auth_key=1759995016-0-0-29fe2500fd9b953740a2298b6fb0d6be&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-30  Orochi Versatile Biomedical Image Processor
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31373.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
