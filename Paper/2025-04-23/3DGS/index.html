<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-23  StyleMe3D Stylization with Disentangled Priors by Multiple Encoders on   3D Gaussians">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-a47a6d6839ed1eb3862ddd567a25382d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    56 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-23-æ›´æ–°"><a href="#2025-04-23-æ›´æ–°" class="headerlink" title="2025-04-23 æ›´æ–°"></a>2025-04-23 æ›´æ–°</h1><h2 id="StyleMe3D-Stylization-with-Disentangled-Priors-by-Multiple-Encoders-on-3D-Gaussians"><a href="#StyleMe3D-Stylization-with-Disentangled-Priors-by-Multiple-Encoders-on-3D-Gaussians" class="headerlink" title="StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on   3D Gaussians"></a>StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on   3D Gaussians</h2><p><strong>Authors:Cailin Zhuang, Yaoqi Hu, Xuanyang Zhang, Wei Cheng, Jiacheng Bao, Shengqi Liu, Yiying Yang, Xianfang Zeng, Gang Yu, Ming Li</strong></p>
<p>3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction but struggles with stylized scenarios (e.g., cartoons, games) due to fragmented textures, semantic misalignment, and limited adaptability to abstract aesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer that integrates multi-modal style conditioning, multi-level semantic alignment, and perceptual quality enhancement. Our key insights include: (1) optimizing only RGB attributes preserves geometric integrity during stylization; (2) disentangling low-, medium-, and high-level semantics is critical for coherent style transfer; (3) scalability across isolated objects and complex scenes is essential for practical deployment. StyleMe3D introduces four novel components: Dynamic Style Score Distillation (DSSD), leveraging Stable Diffusionâ€™s latent space for semantic alignment; Contrastive Style Descriptor (CSD) for localized, content-aware texture transfer; Simultaneously Optimized Scale (SOS) to decouple style details and structural coherence; and 3D Gaussian Quality Assessment (3DG-QA), a differentiable aesthetic prior trained on human-rated data to suppress artifacts and enhance visual harmony. Evaluated on NeRF synthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D outperforms state-of-the-art methods in preserving geometric details (e.g., carvings on sculptures) and ensuring stylistic consistency across scenes (e.g., coherent lighting in landscapes), while maintaining real-time rendering. This work bridges photorealistic 3D GS and artistic stylization, unlocking applications in gaming, virtual worlds, and digital art. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰åœ¨çœŸå®æ„Ÿåœºæ™¯é‡å»ºæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é£æ ¼åŒ–åœºæ™¯ï¼ˆå¦‚å¡é€šã€æ¸¸æˆï¼‰æ–¹é¢å´é‡åˆ°å›°éš¾ï¼ŒåŸå› åœ¨äºçº¹ç†ç¢ç‰‡åŒ–ã€è¯­ä¹‰ä¸åŒ¹é…ä»¥åŠå¯¹æŠ½è±¡ç¾å­¦çš„é€‚åº”æ€§æœ‰é™ã€‚æˆ‘ä»¬æå‡ºStyleMe3Dï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº3D GSé£æ ¼è½¬æ¢çš„æ•´ä½“æ¡†æ¶ï¼Œå®ƒé›†æˆäº†å¤šæ¨¡å¼é£æ ¼æ¡ä»¶ã€å¤šçº§è¯­ä¹‰å¯¹é½å’Œæ„ŸçŸ¥è´¨é‡å¢å¼ºã€‚æˆ‘ä»¬çš„å…³é”®è§è§£åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰ä»…ä¼˜åŒ–RGBå±æ€§å¯ä»¥åœ¨é£æ ¼åŒ–è¿‡ç¨‹ä¸­ä¿æŒå‡ ä½•å®Œæ•´æ€§ï¼›ï¼ˆ2ï¼‰åˆ†ç¦»ä½ã€ä¸­ã€é«˜çº§è¯­ä¹‰å¯¹äºè¿è´¯çš„é£æ ¼è½¬æ¢è‡³å…³é‡è¦ï¼›ï¼ˆ3ï¼‰åœ¨å­¤ç«‹å¯¹è±¡å’Œå¤æ‚åœºæ™¯ä¹‹é—´çš„å¯æ‰©å±•æ€§å¯¹äºå®é™…éƒ¨ç½²è‡³å…³é‡è¦ã€‚StyleMe3Då¼•å…¥äº†å››ä¸ªæ–°é¢–ç»„ä»¶ï¼šåŠ¨æ€é£æ ¼åˆ†æ•°è’¸é¦ï¼ˆDSSDï¼‰ï¼Œåˆ©ç”¨Stable Diffusionçš„æ½œåœ¨ç©ºé—´è¿›è¡Œè¯­ä¹‰å¯¹é½ï¼›å¯¹æ¯”é£æ ¼æè¿°ç¬¦ï¼ˆCSDï¼‰ç”¨äºå±€éƒ¨ã€å†…å®¹æ„ŸçŸ¥çš„çº¹ç†ä¼ è¾“ï¼›åŒæ—¶ä¼˜åŒ–æ¯”ä¾‹ï¼ˆSOSï¼‰ä»¥è§£å¼€é£æ ¼ç»†èŠ‚å’Œç»“æ„è¿è´¯æ€§ï¼›ä»¥åŠ3Dé«˜æ–¯è´¨é‡è¯„ä¼°ï¼ˆ3DG-QAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºäººç±»è¯„åˆ†æ•°æ®è®­ç»ƒçš„å¯åŒºåˆ†ç¾å­¦å…ˆéªŒï¼Œç”¨äºæŠ‘åˆ¶ä¼ªå½±å¹¶å¢å¼ºè§†è§‰å’Œè°ã€‚åœ¨NeRFåˆæˆæ•°æ®é›†ï¼ˆå¯¹è±¡ï¼‰å’Œtandt dbï¼ˆåœºæ™¯ï¼‰æ•°æ®é›†ä¸Šè¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒStyleMe3Dåœ¨ä¿æŒå‡ ä½•ç»†èŠ‚ï¼ˆå¦‚é›•å¡‘ä¸Šçš„é›•åˆ»ï¼‰å’Œç¡®ä¿åœºæ™¯ä¹‹é—´çš„é£æ ¼ä¸€è‡´æ€§ï¼ˆå¦‚æ™¯è§‚ä¸­çš„ä¸€è‡´ç…§æ˜ï¼‰æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“ã€‚è¿™é¡¹å·¥ä½œæ¶èµ·äº†çœŸå®æ„Ÿ3D GSå’Œè‰ºæœ¯é£æ ¼åŒ–ä¹‹é—´çš„æ¡¥æ¢ï¼Œä¸ºæ¸¸æˆã€è™šæ‹Ÿä¸–ç•Œå’Œæ•°å­—è‰ºæœ¯ç­‰é¢†åŸŸè§£é”äº†åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15281v1">PDF</a> 16 pages; Project page: <a target="_blank" rel="noopener" href="https://styleme3d.github.io/">https://styleme3d.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†StyleMe3Dæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é’ˆå¯¹3D Gaussian Splattingåœ¨é£æ ¼åŒ–åœºæ™¯ï¼ˆå¦‚å¡é€šã€æ¸¸æˆï¼‰ä¸­çš„ä¸è¶³ï¼Œæä¾›äº†å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶èåˆäº†å¤šæ¨¡æ€é£æ ¼æ¡ä»¶ã€å¤šçº§åˆ«è¯­ä¹‰å¯¹é½å’Œæ„ŸçŸ¥è´¨é‡å¢å¼ºç­‰å…³é”®æŠ€æœ¯ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ä¼˜åŒ–RGBå±æ€§ä»¥ä¿ç•™å‡ ä½•å®Œæ•´æ€§ï¼Œä»¥åŠè§£è€¦ä¸åŒçº§åˆ«çš„è¯­ä¹‰ä»¥å®ç°è¿è´¯çš„é£æ ¼è½¬æ¢ã€‚StyleMe3Dçš„å››å¤§æ–°ç»„ä»¶åˆ†åˆ«æ˜¯åŠ¨æ€é£æ ¼å¾—åˆ†è’¸é¦ï¼ˆDSSDï¼‰ã€å¯¹æ¯”é£æ ¼æè¿°ç¬¦ï¼ˆCSDï¼‰ã€åŒæ­¥ä¼˜åŒ–å°ºåº¦ï¼ˆSOSï¼‰å’Œ3Dé«˜æ–¯è´¨é‡è¯„ä¼°ï¼ˆ3DG-QAï¼‰ã€‚è¯¥æ¡†æ¶åœ¨NeRFåˆæˆæ•°æ®é›†å’Œtandt dbåœºæ™¯æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜å¼‚ï¼Œä¸ä»…èƒ½ä¿ç•™å‡ ä½•ç»†èŠ‚ï¼Œè¿˜èƒ½ç¡®ä¿åœºæ™¯çš„è§†è§‰å’Œè°ä¸è¿è´¯æ€§ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å…·å¤‡å®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œå¯åº”ç”¨äºæ¸¸æˆã€è™šæ‹Ÿä¸–ç•Œå’Œæ•°å­—è‰ºæœ¯ç­‰é¢†åŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>StyleMe3Dæ˜¯ä¸€ä¸ªç”¨äº3D Gaussian Splattingé£æ ¼è½¬æ¢çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¶åœ¨é£æ ¼åŒ–åœºæ™¯ä¸­çš„ä¸è¶³ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ä¼˜åŒ–RGBå±æ€§æ¥ä¿ç•™å‡ ä½•å®Œæ•´æ€§ï¼Œå¼ºè°ƒè§£è€¦ä¸åŒçº§åˆ«çš„è¯­ä¹‰ä»¥å®ç°è¿è´¯çš„é£æ ¼è½¬æ¢ã€‚</li>
<li>StyleMe3DåŒ…å«å››å¤§æ–°ç»„ä»¶ï¼šDSSDã€CSDã€SOSå’Œ3DG-QAï¼Œåˆ†åˆ«è´Ÿè´£ä¸åŒçš„åŠŸèƒ½ï¼Œå¦‚é£æ ¼å¾—åˆ†çš„è’¸é¦ã€å¯¹æ¯”é£æ ¼æè¿°ç¬¦çš„ç”Ÿæˆç­‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15281">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-296dd9e8c2b15496ed4d32f515960f7e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b0206f92e0f9c850890070970b7ee30e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9e7b049f13f2c4bf60c6b81b27e5772.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-782c789163ada284cd4bfc5663e2bca6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MoBGS-Motion-Deblurring-Dynamic-3D-Gaussian-Splatting-for-Blurry-Monocular-Video"><a href="#MoBGS-Motion-Deblurring-Dynamic-3D-Gaussian-Splatting-for-Blurry-Monocular-Video" class="headerlink" title="MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry   Monocular Video"></a>MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry   Monocular Video</h2><p><strong>Authors:Minh-Quan Viet Bui, Jongmin Park, Juan Luis Gonzalez Bello, Jaeho Moon, Jihyong Oh, Munchurl Kim</strong></p>
<p>We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner. Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality. While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects. To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for effective latent camera trajectory estimation, improving global camera motion deblurring. In addition, we propose a physically-inspired Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both global camera and local object motion. Our MoBGS framework ensures the temporal consistency of unseen latent timestamps and robust motion decomposition of static and dynamic regions. Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent advanced methods (DyBluRF and Deblur4DGS), achieving state-of-the-art performance for dynamic NVS under motion blur. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†MoBGSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å»æ¨¡ç³ŠåŠ¨æ€ä¸‰ç»´é«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼ä»æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­é‡å»ºæ¸…æ™°ã€é«˜è´¨é‡çš„æ–°æ—¶ç©ºè§†å›¾ã€‚ç°æœ‰çš„åŠ¨æ€æ–°è§†å›¾åˆæˆï¼ˆNVSï¼‰æ–¹æ³•å¯¹äºéšæ„æ‹æ‘„çš„è§†é¢‘ä¸­çš„è¿åŠ¨æ¨¡ç³Šéå¸¸æ•æ„Ÿï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡æ˜¾è‘—ä¸‹é™ã€‚è™½ç„¶æœ€è¿‘çš„æ–¹æ³•è§£å†³äº†è¿åŠ¨æ¨¡ç³Šè¾“å…¥å¯¹äºNVSçš„é—®é¢˜ï¼Œä½†å®ƒä»¬ä¸»è¦å…³æ³¨é™æ€åœºæ™¯çš„é‡å»ºï¼Œç¼ºä¹é’ˆå¯¹åŠ¨æ€å¯¹è±¡çš„ä¸“ç”¨è¿åŠ¨å»ºæ¨¡ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬çš„MoBGSå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ¨¡ç³Šè‡ªé€‚åº”æ½œåœ¨ç›¸æœºä¼°è®¡ï¼ˆBLCEï¼‰æ–¹æ³•ï¼Œç”¨äºæœ‰æ•ˆåœ°ä¼°è®¡æ½œåœ¨ç›¸æœºè½¨è¿¹ï¼Œæ”¹è¿›å…¨å±€ç›¸æœºè¿åŠ¨å»æ¨¡ç³Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å—ç‰©ç†å¯å‘çš„æ½œåœ¨ç›¸æœºè¯±å¯¼æ›å…‰ä¼°è®¡ï¼ˆLCEEï¼‰æ–¹æ³•ï¼Œä»¥ç¡®ä¿å…¨å±€ç›¸æœºå’Œå±€éƒ¨å¯¹è±¡è¿åŠ¨çš„æŒç»­å»æ¨¡ç³Šã€‚æˆ‘ä»¬çš„MoBGSæ¡†æ¶ç¡®ä¿äº†æœªè§æ½œåœ¨æ—¶é—´æˆ³çš„æ—¶ç©ºä¸€è‡´æ€§ä»¥åŠé™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„ç¨³å¥è¿åŠ¨åˆ†è§£ã€‚åœ¨ç«‹ä½“æ¨¡ç³Šæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œçš„æ¨¡ç³Šè§†é¢‘ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MoBGSæ˜¾è‘—ä¼˜äºæœ€è¿‘çš„é«˜çº§æ–¹æ³•ï¼ˆDyBluRFå’ŒDeblur4DGSï¼‰ï¼Œåœ¨è¿åŠ¨æ¨¡ç³Šçš„åŠ¨æ€NVSä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15122v1">PDF</a> The first two authors contributed equally to this work (equal   contribution). The last two authors advised equally to this work</p>
<p><strong>æ‘˜è¦</strong><br>    æå‡ºä¸€ç§æ–°å‹åŠ¨æ€3Dé«˜æ–¯å±•å¼€ï¼ˆMoBGSï¼‰æ¡†æ¶ï¼Œèƒ½å¤Ÿä»æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­é‡å»ºæ¸…æ™°ã€é«˜è´¨é‡çš„æ–°æ—¶ç©ºè§†å›¾ã€‚ç°æœ‰åŠ¨æ€æ–°è§†å›¾åˆæˆï¼ˆNVSï¼‰æ–¹æ³•å¯¹è¿åŠ¨æ¨¡ç³Šæ•æ„Ÿï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚MoBGSå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ¨¡ç³Šè‡ªé€‚åº”æ½œåœ¨ç›¸æœºä¼°è®¡ï¼ˆBLCEï¼‰æ–¹æ³•ï¼Œç”¨äºæœ‰æ•ˆçš„æ½œåœ¨ç›¸æœºè½¨è¿¹ä¼°è®¡ï¼Œå¹¶æ”¹è¿›å…¨å±€ç›¸æœºè¿åŠ¨å»æ¨¡ç³Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§å—ç‰©ç†å¯å‘çš„æ½œåœ¨ç›¸æœºè¯±å¯¼æ›å…‰ä¼°è®¡ï¼ˆLCEEï¼‰æ–¹æ³•ï¼Œä»¥ç¡®ä¿å…¨å±€ç›¸æœºå’Œå±€éƒ¨å¯¹è±¡è¿åŠ¨çš„æŒç»­å»æ¨¡ç³Šã€‚MoBGSæ¡†æ¶ç¡®ä¿æœªè§æ½œåœ¨æ—¶é—´æˆ³çš„æ—¶ç©ºä¸€è‡´æ€§ä»¥åŠé™æ€å’ŒåŠ¨æ€åŒºåŸŸçš„ç¨³å¥è¿åŠ¨åˆ†è§£ã€‚åœ¨ç«‹ä½“æ¨¡ç³Šæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œæ¨¡ç³Šè§†é¢‘ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMoBGSæ˜¾è‘—ä¼˜äºæœ€è¿‘çš„é«˜çº§æ–¹æ³•ï¼ˆDyBluRFå’ŒDeblur4DGSï¼‰ï¼Œåœ¨è¿åŠ¨æ¨¡ç³Šæƒ…å†µä¸‹å®ç°åŠ¨æ€NVSçš„å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>MoBGSæ˜¯ä¸€ä¸ªæ–°å‹åŠ¨æ€3Dé«˜æ–¯å±•å¸ƒæ¡†æ¶ï¼Œå¯ä»æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­é‡å»ºæ¸…æ™°çš„é«˜è´¨é‡æ—¶ç©ºè§†å›¾ã€‚</li>
<li>ç°æœ‰åŠ¨æ€NVSæ–¹æ³•å¯¹è¿åŠ¨æ¨¡ç³Šæ•æ„Ÿï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚</li>
<li>MoBGSå¼•å…¥BLCEæ–¹æ³•ï¼Œæœ‰æ•ˆä¼°è®¡æ½œåœ¨ç›¸æœºè½¨è¿¹å¹¶æ”¹è¿›å…¨å±€ç›¸æœºè¿åŠ¨å»æ¨¡ç³Šã€‚</li>
<li>LCEEæ–¹æ³•ç¡®ä¿å…¨å±€å’Œå±€éƒ¨è¿åŠ¨çš„æŒç»­å»æ¨¡ç³Šã€‚</li>
<li>MoBGSæ¡†æ¶å…·æœ‰æ—¶ç©ºä¸€è‡´æ€§ï¼Œå¯ç¨³å¥åœ°åˆ†è§£é™æ€å’ŒåŠ¨æ€åŒºåŸŸã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMoBGSæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå…·æœ‰å“è¶Šæ€§èƒ½ã€‚</li>
<li>MoBGSæ¡†æ¶ç‰¹åˆ«é€‚ç”¨äºå¤„ç†åŒ…å«è¿åŠ¨æ¨¡ç³Šçš„åŠ¨æ€åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15122">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-627f9f3a12606d3b797709fb10374e97.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4b2f822ca78b858889e9c6392df4a31.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RoboOcc-Enhancing-the-Geometric-and-Semantic-Scene-Understanding-for-Robots"><a href="#RoboOcc-Enhancing-the-Geometric-and-Semantic-Scene-Understanding-for-Robots" class="headerlink" title="RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for   Robots"></a>RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for   Robots</h2><p><strong>Authors:Zhang Zhang, Qiang Zhang, Wei Cui, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang</strong></p>
<p>3D occupancy prediction enables the robots to obtain spatial fine-grained geometry and semantics of the surrounding scene, and has become an essential task for embodied perception. Existing methods based on 3D Gaussians instead of dense voxels do not effectively exploit the geometry and opacity properties of Gaussians, which limits the networkâ€™s estimation of complex environments and also limits the description of the scene by 3D Gaussians. In this paper, we propose a 3D occupancy prediction method which enhances the geometric and semantic scene understanding for robots, dubbed RoboOcc. It utilizes the Opacity-guided Self-Encoder (OSE) to alleviate the semantic ambiguity of overlapping Gaussians and the Geometry-aware Cross-Encoder (GCE) to accomplish the fine-grained geometric modeling of the surrounding scene. We conduct extensive experiments on Occ-ScanNet and EmbodiedOcc-ScanNet datasets, and our RoboOcc achieves state-of the-art performance in both local and global camera settings. Further, in ablation studies of Gaussian parameters, the proposed RoboOcc outperforms the state-of-the-art methods by a large margin of (8.47, 6.27) in IoU and mIoU metric, respectively. The codes will be released soon. </p>
<blockquote>
<p>3Då ç”¨é¢„æµ‹ä½¿æœºå™¨äººèƒ½å¤Ÿè·å¾—å‘¨å›´åœºæ™¯çš„ç²¾ç»†å‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå·²æˆä¸ºä½“æ„Ÿæ„ŸçŸ¥çš„é‡è¦ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•åŸºäº3Dé«˜æ–¯åˆ†å¸ƒè€Œéå¯†é›†ä½“ç´ ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨é«˜æ–¯åˆ†å¸ƒçš„å‡ ä½•å’Œé€æ˜åº¦å±æ€§ï¼Œè¿™é™åˆ¶äº†ç½‘ç»œå¯¹å¤æ‚ç¯å¢ƒçš„ä¼°ç®—ä»¥åŠå¯¹åœºæ™¯çš„æè¿°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºRoboOccçš„æœºå™¨äººä¸‰ç»´å ç”¨é¢„æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºæœºå™¨äººçš„å‡ ä½•å’Œè¯­ä¹‰åœºæ™¯ç†è§£ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é€æ˜åº¦å¼•å¯¼è‡ªç¼–ç å™¨ï¼ˆOSEï¼‰ç¼“è§£é‡å é«˜æ–¯åˆ†å¸ƒçš„è¯­ä¹‰æ¨¡ç³Šé—®é¢˜ï¼Œå¹¶åˆ©ç”¨å‡ ä½•æ„ŸçŸ¥äº¤å‰ç¼–ç å™¨ï¼ˆGCEï¼‰å®Œæˆå‘¨å›´åœºæ™¯çš„ç²¾ç»†å‡ ä½•å»ºæ¨¡ã€‚æˆ‘ä»¬åœ¨Occ-ScanNetå’ŒEmbodiedOcc-ScanNetæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼ŒRoboOccåœ¨å±€éƒ¨å’Œå…¨å±€ç›¸æœºè®¾ç½®ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨é«˜æ–¯å‚æ•°æ¶ˆèç ”ç©¶ä¸­ï¼ŒRoboOccåœ¨IoUå’ŒmIoUæŒ‡æ ‡ä¸Šå¤§å¤§è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼ˆåˆ†åˆ«ä¸º8.47å’Œ6.27ï¼‰ã€‚ä»£ç å°†å¾ˆå¿«å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14604v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æå‡ºäº†ä¸€ç§åä¸ºRoboOccçš„3Då ç”¨é¢„æµ‹æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨Opacity-guided Self-Encoderï¼ˆOSEï¼‰è§£å†³é‡å é«˜æ–¯å€¼çš„è¯­ä¹‰æ¨¡ç³Šé—®é¢˜ï¼Œå¹¶åˆ©ç”¨Geometry-aware Cross-Encoderï¼ˆGCEï¼‰å®Œæˆåœºæ™¯çš„ç²¾ç»†å‡ ä½•å»ºæ¨¡ï¼Œæå‡äº†æœºå™¨äººåœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„åœºæ™¯ç†è§£ä¸è¯­ä¹‰æ„ŸçŸ¥ï¼Œä¸”åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°äº†å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Då ç”¨é¢„æµ‹å¯¹æœºå™¨äººå‘¨å›´åœºæ™¯çš„ç²¾ç»†å‡ ä½•å’Œè¯­ä¹‰ç†è§£è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åŸºäº3Dé«˜æ–¯çš„æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨å‡ ä½•å’Œé€æ˜åº¦ç‰¹æ€§ï¼Œé™åˆ¶äº†å¤æ‚ç¯å¢ƒçš„ä¼°è®¡å’Œåœºæ™¯æè¿°ã€‚</li>
<li>RoboOccæ–¹æ³•é€šè¿‡Opacity-guided Self-Encoder (OSE) å‡è½»é‡å é«˜æ–¯å€¼çš„è¯­ä¹‰æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>Geometry-aware Cross-Encoder (GCE) ç”¨äºå®Œæˆåœºæ™¯çš„ç²¾ç»†å‡ ä½•å»ºæ¨¡ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒRoboOccè¾¾åˆ°äº†å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶åœ¨é«˜æ–¯å‚æ•°æ¶ˆèç ”ç©¶ä¸­å¤§å¹…è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
<li>RoboOccçš„IoUå’ŒmIoUæŒ‡æ ‡ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå…·ä½“ä¼˜åŠ¿ä¸ºï¼ˆ8.47ï¼Œ6.27ï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14604">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-24a00f75ecfa0d240a96fb7e29a227cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cdc1998e19b0dad08973dd9e82776fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f381e796b91ed674f896e6f9ae3a799.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="VGNC-Reducing-the-Overfitting-of-Sparse-view-3DGS-via-Validation-guided-Gaussian-Number-Control"><a href="#VGNC-Reducing-the-Overfitting-of-Sparse-view-3DGS-via-Validation-guided-Gaussian-Number-Control" class="headerlink" title="VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided   Gaussian Number Control"></a>VGNC: Reducing the Overfitting of Sparse-view 3DGS via Validation-guided   Gaussian Number Control</h2><p><strong>Authors:Lifeng Lin, Rongfeng Lu, Quan Chen, Haofan Ren, Ming Lu, Yaoqi Sun, Chenggang Yan, Anke Xue</strong></p>
<p>Sparse-view 3D reconstruction is a fundamental yet challenging task in practical 3D reconstruction applications. Recently, many methods based on the 3D Gaussian Splatting (3DGS) framework have been proposed to address sparse-view 3D reconstruction. Although these methods have made considerable advancements, they still show significant issues with overfitting. To reduce the overfitting, we introduce VGNC, a novel Validation-guided Gaussian Number Control (VGNC) approach based on generative novel view synthesis (NVS) models. To the best of our knowledge, this is the first attempt to alleviate the overfitting issue of sparse-view 3DGS with generative validation images. Specifically, we first introduce a validation image generation method based on a generative NVS model. We then propose a Gaussian number control strategy that utilizes generated validation images to determine the optimal Gaussian numbers, thereby reducing the issue of overfitting. We conducted detailed experiments on various sparse-view 3DGS baselines and datasets to evaluate the effectiveness of VGNC. Extensive experiments show that our approach not only reduces overfitting but also improves rendering quality on the test set while decreasing the number of Gaussian points. This reduction lowers storage demands and accelerates both training and rendering. The code will be released. </p>
<blockquote>
<p>ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºæ˜¯å®é™…ä¸‰ç»´é‡å»ºåº”ç”¨ä¸­çš„ä¸€é¡¹åŸºæœ¬ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚æœ€è¿‘ï¼ŒåŸºäºä¸‰ç»´é«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰æ¡†æ¶çš„æ–¹æ³•å·²ç»è¢«æå‡ºæ¥è§£å†³ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºé—®é¢˜ã€‚å°½ç®¡è¿™äº›æ–¹æ³•å·²ç»å–å¾—äº†å¾ˆå¤§çš„è¿›æ­¥ï¼Œä½†å®ƒä»¬ä»ç„¶æ˜¾ç¤ºå‡ºä¸¥é‡çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†å‡å°‘è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬å¼•å…¥äº†VGNCï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç”Ÿæˆæ–°å‹è§†è§’åˆæˆï¼ˆNVSï¼‰æ¨¡å‹çš„éªŒè¯å¼•å¯¼é«˜æ–¯æ•°é‡æ§åˆ¶ï¼ˆVGNCï¼‰æ–¹æ³•ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°è¯•ä½¿ç”¨ç”ŸæˆéªŒè¯å›¾åƒæ¥ç¼“è§£ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é«˜æ–¯å»¶å±•è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåŸºäºç”Ÿæˆå‹NVSæ¨¡å‹å¼•å…¥äº†ä¸€ç§éªŒè¯å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ–¯æ•°é‡æ§åˆ¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨ç”Ÿæˆçš„éªŒè¯å›¾åƒæ¥ç¡®å®šæœ€ä½³é«˜æ–¯æ•°é‡ï¼Œä»è€Œå‡å°‘è¿‡æ‹Ÿåˆé—®é¢˜ã€‚æˆ‘ä»¬åœ¨å„ç§ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºåŸºå‡†æ–¹æ³•å’Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯¦ç»†çš„å®éªŒï¼Œä»¥è¯„ä¼°VGNCçš„æœ‰æ•ˆæ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å‡å°‘äº†è¿‡æ‹Ÿåˆï¼Œè€Œä¸”æé«˜äº†æµ‹è¯•é›†çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶å‡å°‘äº†é«˜æ–¯ç‚¹çš„æ•°é‡ã€‚è¿™ç§å‡å°‘é™ä½äº†å­˜å‚¨éœ€æ±‚å¹¶åŠ é€Ÿäº†è®­ç»ƒå’Œæ¸²æŸ“è¿‡ç¨‹ã€‚ä»£ç å°†ä¼šå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14548v1">PDF</a> 10 pages,8 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¨€ç–è§†è§’çš„3Dé‡å»ºæ˜¯å®é™…åº”ç”¨ä¸­çš„ä¸€é¡¹åŸºæœ¬ä¸”å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚è¿‘æœŸï¼Œè®¸å¤šåŸºäºä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰æ¡†æ¶çš„æ–¹æ³•è¢«æå‡ºæ¥è§£å†³ç¨€ç–è§†è§’çš„3Dé‡å»ºé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•è™½ç„¶å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ï¼Œä½†ä»å­˜åœ¨è¿‡åº¦æ‹Ÿåˆçš„é—®é¢˜ã€‚ä¸ºäº†å‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†VGNCï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç”Ÿæˆå¼æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰æ¨¡å‹çš„éªŒè¯å¼•å¯¼é«˜æ–¯æ•°é‡æ§åˆ¶ï¼ˆVGNCï¼‰æ–¹æ³•ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°è¯•åˆ©ç”¨ç”ŸæˆéªŒè¯å›¾åƒæ¥ç¼“è§£ç¨€ç–è§†è§’çš„3DGSçš„è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»äº†ä¸€ç§åŸºäºç”Ÿæˆå¼NVSæ¨¡å‹çš„éªŒè¯å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ–¯æ•°é‡æ§åˆ¶ç­–ç•¥ï¼Œåˆ©ç”¨ç”Ÿæˆçš„éªŒè¯å›¾åƒæ¥ç¡®å®šæœ€ä½³é«˜æ–¯æ•°é‡ï¼Œä»è€Œå‡å°‘è¿‡åº¦æ‹Ÿåˆçš„é—®é¢˜ã€‚æˆ‘ä»¬åœ¨å„ç§ç¨€ç–è§†è§’çš„3DGSåŸºå‡†å’Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯¦ç»†çš„å®éªŒï¼Œä»¥è¯„ä¼°VGNCçš„æœ‰æ•ˆæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å‡å°‘äº†è¿‡åº¦æ‹Ÿåˆï¼Œè€Œä¸”æé«˜äº†æµ‹è¯•é›†çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶å‡å°‘äº†é«˜æ–¯ç‚¹çš„æ•°é‡ã€‚è¿™é™ä½äº†å­˜å‚¨éœ€æ±‚å¹¶åŠ é€Ÿäº†è®­ç»ƒå’Œæ¸²æŸ“è¿‡ç¨‹ã€‚ä»£ç å³å°†å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¨€ç–è§†è§’çš„3Dé‡å»ºæ˜¯å®é™…åº”ç”¨ä¸­çš„æŒ‘æˆ˜æ€§é—®é¢˜ã€‚</li>
<li>åŸºäºä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰çš„æ–¹æ³•è™½ç„¶æœ‰æ‰€è¿›å±•ï¼Œä½†å­˜åœ¨è¿‡åº¦æ‹Ÿåˆçš„é—®é¢˜ã€‚</li>
<li>VGNCæ˜¯ä¸€ç§æ–°å‹çš„éªŒè¯å¼•å¯¼é«˜æ–¯æ•°é‡æ§åˆ¶æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç¨€ç–è§†è§’çš„3Dé‡å»ºä¸­çš„è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>VGNCé€šè¿‡å¼•å…¥ç”Ÿæˆå¼æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰æ¨¡å‹æ¥ç”ŸæˆéªŒè¯å›¾åƒã€‚</li>
<li>VGNCåˆ©ç”¨ç”Ÿæˆçš„éªŒè¯å›¾åƒæ¥ç¡®å®šæœ€ä½³é«˜æ–¯æ•°é‡ï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡å¹¶é™ä½å­˜å‚¨éœ€æ±‚ã€‚</li>
<li>å®éªŒè¯æ˜VGNCæ–¹æ³•æœ‰æ•ˆå‡å°‘è¿‡åº¦æ‹Ÿåˆï¼Œæé«˜æµ‹è¯•é›†æ¸²æŸ“è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63e52c48d982f2837b8f0633c6465c98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-954447a618cecc0600ab707f167f59c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48c1dd2485a10dd4574a3b6f6f1755fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-125982da9abd93ab40740edd25c02705.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a75ae8d11237490152f54e13abbfd22.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1aeb9c710773b19543302505b3765ef0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SEGA-Drivable-3D-Gaussian-Head-Avatar-from-a-Single-Image"><a href="#SEGA-Drivable-3D-Gaussian-Head-Avatar-from-a-Single-Image" class="headerlink" title="SEGA: Drivable 3D Gaussian Head Avatar from a Single Image"></a>SEGA: Drivable 3D Gaussian Head Avatar from a Single Image</h2><p><strong>Authors:Chen Guo, Zhuo Su, Jian Wang, Shuang Li, Xu Chang, Zhaohu Li, Yang Zhao, Guidong Wang, Ruqi Huang</strong></p>
<p>Creating photorealistic 3D head avatars from limited input has become increasingly important for applications in virtual reality, telepresence, and digital entertainment. While recent advances like neural rendering and 3D Gaussian splatting have enabled high-quality digital human avatar creation and animation, most methods rely on multiple images or multi-view inputs, limiting their practicality for real-world use. In this paper, we propose SEGA, a novel approach for Single-imagE-based 3D drivable Gaussian head Avatar creation that combines generalized prior models with a new hierarchical UV-space Gaussian Splatting framework. SEGA seamlessly combines priors derived from large-scale 2D datasets with 3D priors learned from multi-view, multi-expression, and multi-ID data, achieving robust generalization to unseen identities while ensuring 3D consistency across novel viewpoints and expressions. We further present a hierarchical UV-space Gaussian Splatting framework that leverages FLAME-based structural priors and employs a dual-branch architecture to disentangle dynamic and static facial components effectively. The dynamic branch encodes expression-driven fine details, while the static branch focuses on expression-invariant regions, enabling efficient parameter inference and precomputation. This design maximizes the utility of limited 3D data and achieves real-time performance for animation and rendering. Additionally, SEGA performs person-specific fine-tuning to further enhance the fidelity and realism of the generated avatars. Experiments show our method outperforms state-of-the-art approaches in generalization ability, identity preservation, and expression realism, advancing one-shot avatar creation for practical applications. </p>
<blockquote>
<p>åˆ›å»ºå…·æœ‰çœŸå®æ„Ÿçš„3Då¤´åƒåŒ–èº«ä»æœ‰é™è¾“å…¥çš„è§’åº¦æ¥è®¨è®ºåœ¨è™šæ‹Ÿç°å®ã€è¿œç¨‹å­˜åœ¨å’Œæ•°å­—å¨±ä¹åº”ç”¨ä¸­è¶Šæ¥è¶Šé‡è¦ã€‚è™½ç„¶ç¥ç»æ¸²æŸ“å’Œ3Dé«˜æ–¯æ‹¼è´´ç­‰æœ€æ–°è¿›å±•å·²ç»å®ç°äº†é«˜è´¨é‡æ•°å­—äººç±»åŒ–èº«åˆ›å»ºå’ŒåŠ¨ç”»ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä»ç„¶ä¾èµ–äºå¤šå¼ å›¾åƒæˆ–å¤šè§†è§’è¾“å…¥ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„å®ç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SEGAï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå•å›¾åƒæŠ€æœ¯çš„3Dé©¾é©¶é«˜æ–¯å¤´åƒåŒ–èº«åˆ›å»ºæ–°æ–¹æ³•ï¼Œå®ƒç»“åˆäº†å¹¿ä¹‰å…ˆéªŒæ¨¡å‹å’Œæ–°å±‚æ¬¡åŒ–çš„UVç©ºé—´é«˜æ–¯æ‹¼è´´æ¡†æ¶ã€‚SEGAæ— ç¼åœ°ç»“åˆäº†ä»å¤§è§„æ¨¡äºŒç»´æ•°æ®é›†æ´¾ç”Ÿçš„å…ˆéªŒçŸ¥è¯†å’Œä»å¤šè§†è§’ã€å¤šè¡¨æƒ…å’Œå¤šèº«ä»½æ•°æ®ä¸­å­¦ä¹ çš„ä¸‰ç»´å…ˆéªŒçŸ¥è¯†ï¼Œå®ç°å¯¹æœªè§èº«ä»½çš„ç¨³å¥æ³›åŒ–ï¼ŒåŒæ—¶ç¡®ä¿æ–°å‹è§†è§’å’Œè¡¨æƒ…ä¸‹çš„ä¸‰ç»´ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–çš„UVç©ºé—´é«˜æ–¯æ‹¼è´´æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨åŸºäºFLAMEçš„ç»“æ„å…ˆéªŒçŸ¥è¯†å¹¶é‡‡ç”¨åŒåˆ†æ”¯æ¶æ„ï¼Œæœ‰æ•ˆåœ°åˆ†ç¦»åŠ¨æ€å’Œé™æ€é¢éƒ¨ç»„ä»¶ã€‚åŠ¨æ€åˆ†æ”¯ç¼–ç è¡¨æƒ…é©±åŠ¨çš„ç²¾ç»†ç»†èŠ‚ï¼Œè€Œé™æ€åˆ†æ”¯åˆ™ä¸“æ³¨äºè¡¨æƒ…ä¸å˜åŒºåŸŸï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„å‚æ•°æ¨æ–­å’Œé¢„è®¡ç®—ã€‚è¿™ç§è®¾è®¡æœ€å¤§é™åº¦åœ°æé«˜äº†æœ‰é™ä¸‰ç»´æ•°æ®çš„å®ç”¨æ€§ï¼Œå¹¶å®ç°äº†åŠ¨ç”»å’Œæ¸²æŸ“çš„å®æ—¶æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒSEGAæ‰§è¡Œé’ˆå¯¹ä¸ªäººçš„å¾®è°ƒï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºç”Ÿæˆçš„åŒ–èº«çš„çœŸå®æ„Ÿå’Œé€¼çœŸåº¦ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›ã€èº«ä»½ä¿ç•™å’Œè¡¨æƒ…ç°å®æ€§æ–¹é¢ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œæ¨åŠ¨äº†ä¸€ç«™å¼åŒ–èº«åˆ›å»ºåœ¨å®ç”¨é¢†åŸŸçš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14373v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå•å¼ å›¾åƒåˆ›å»º3Då¯é©±åŠ¨é«˜æ–¯å¤´åƒçš„æŠ€æœ¯SEGAã€‚è¯¥æŠ€æœ¯ç»“åˆäº†é€šç”¨å…ˆéªŒæ¨¡å‹å’Œæ–°å±‚æ¬¡UVç©ºé—´é«˜æ–¯æº…è½æ¡†æ¶ï¼Œå®ç°äº†å¯¹æœªè§èº«ä»½çš„ç¨³å¥æ³›åŒ–ï¼ŒåŒæ—¶ç¡®ä¿äº†åœ¨æ–°å‹è§†è§’å’Œè¡¨æƒ…ä¸‹çš„3Dä¸€è‡´æ€§ã€‚SEGAåˆ©ç”¨åˆ†å±‚UVç©ºé—´é«˜æ–¯æº…è½æ¡†æ¶ï¼Œé‡‡ç”¨åŒåˆ†æ”¯æ¶æ„æœ‰æ•ˆåˆ†ç¦»åŠ¨æ€å’Œé™æ€é¢éƒ¨ç»„ä»¶ï¼Œå®ç°å®æ—¶åŠ¨ç”»å’Œæ¸²æŸ“æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒSEGAåœ¨æ³›åŒ–èƒ½åŠ›ã€èº«ä»½ä¿ç•™å’Œè¡¨æƒ…çœŸå®æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œæ¨åŠ¨äº†å•é•œå¤´å¤´åƒåˆ›ä½œçš„å®é™…åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SEGAæŠ€æœ¯ç»“åˆäº†é€šç”¨å…ˆéªŒæ¨¡å‹å’Œæ–°å±‚æ¬¡UVç©ºé—´é«˜æ–¯æº…è½æ¡†æ¶ï¼Œç”¨äºåˆ›å»ºåŸºäºå•å¼ å›¾åƒçš„3Då¯é©±åŠ¨é«˜æ–¯å¤´åƒã€‚</li>
<li>SEGAå®ç°äº†å¯¹æœªè§èº«ä»½çš„ç¨³å¥æ³›åŒ–ï¼ŒåŒæ—¶ç¡®ä¿åœ¨æ–°å‹è§†è§’å’Œè¡¨æƒ…ä¸‹çš„3Dä¸€è‡´æ€§ã€‚</li>
<li>åˆ†å±‚UVç©ºé—´é«˜æ–¯æº…è½æ¡†æ¶ç»“åˆäº†FLAMEç»“æ„å…ˆéªŒä¿¡æ¯å¹¶é‡‡ç”¨åŒåˆ†æ”¯æ¶æ„åˆ†ç¦»åŠ¨æ€å’Œé™æ€é¢éƒ¨ç»„ä»¶ï¼Œå®ç°é«˜æ•ˆå‚æ•°æ¨æ–­å’Œé¢„è®¡ç®—ã€‚</li>
<li>SEGAå¯å®ç°å®æ—¶æ€§èƒ½ç”¨äºåŠ¨ç”»å’Œæ¸²æŸ“ï¼Œå¹¶å¯é€šè¿‡ä¸ªäººå¾®è°ƒå¢å¼ºå¤´åƒçš„çœŸå®æ€§å’Œé€¼çœŸåº¦ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14373">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3d5b7ecad0dc417ed569d45cf2de784a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7ad034cfb49f39d4815618d104d0e58e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="LL-Gaussian-Low-Light-Scene-Reconstruction-and-Enhancement-via-Gaussian-Splatting-for-Novel-View-Synthesis"><a href="#LL-Gaussian-Low-Light-Scene-Reconstruction-and-Enhancement-via-Gaussian-Splatting-for-Novel-View-Synthesis" class="headerlink" title="LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis"></a>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian   Splatting for Novel View Synthesis</h2><p><strong>Authors:Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou</strong></p>
<p>Novel view synthesis (NVS) in low-light scenes remains a significant challenge due to degraded inputs characterized by severe noise, low dynamic range (LDR) and unreliable initialization. While recent NeRF-based approaches have shown promising results, most suffer from high computational costs, and some rely on carefully captured or pre-processed dataâ€“such as RAW sensor inputs or multi-exposure sequencesâ€“which severely limits their practicality. In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering with competitive visual fidelity; however, existing 3DGS-based methods struggle with low-light sRGB inputs, resulting in unstable Gaussian initialization and ineffective noise suppression. To address these challenges, we propose LL-Gaussian, a novel framework for 3D reconstruction and enhancement from low-light sRGB images, enabling pseudo normal-light novel view synthesis. Our method introduces three key innovations: 1) an end-to-end Low-Light Gaussian Initialization Module (LLGIM) that leverages dense priors from learning-based MVS approach to generate high-quality initial point clouds; 2) a dual-branch Gaussian decomposition model that disentangles intrinsic scene properties (reflectance and illumination) from transient interference, enabling stable and interpretable optimization; 3) an unsupervised optimization strategy guided by both physical constrains and diffusion prior to jointly steer decomposition and enhancement. Additionally, we contribute a challenging dataset collected in extreme low-light environments and demonstrate the effectiveness of LL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussian achieves up to 2,000 times faster inference and reduces training time to just 2%, while delivering superior reconstruction and rendering quality. </p>
<blockquote>
<p>ä½å…‰åœºæ™¯ä¸­çš„æ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰ä»ç„¶å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºè¾“å…¥é€€åŒ–è¡¨ç°ä¸ºä¸¥é‡å™ªå£°ã€ä½åŠ¨æ€èŒƒå›´ï¼ˆLDRï¼‰å’Œä¸å¯é çš„åˆå§‹åŒ–ã€‚è™½ç„¶æœ€è¿‘çš„åŸºäºNeRFçš„æ–¹æ³•å·²ç»æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æœï¼Œä½†å¤§å¤šæ•°æ–¹æ³•çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œè€Œä¸”æœ‰äº›æ–¹æ³•ä¾èµ–äºç²¾å¿ƒæ•è·æˆ–é¢„å¤„ç†çš„æ•°æ®ï¼Œå¦‚RAWä¼ æ„Ÿå™¨è¾“å…¥æˆ–å¤šæ›å…‰åºåˆ—ï¼Œè¿™ä¸¥é‡é™åˆ¶äº†å®ƒä»¬çš„å®ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°å…·æœ‰ç«äº‰åŠ›çš„è§†è§‰ä¿çœŸåº¦çš„å®æ—¶æ¸²æŸ“ï¼›ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº3DGSçš„æ–¹æ³•åœ¨å¤„ç†ä½å…‰sRGBè¾“å…¥æ—¶é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´é«˜æ–¯åˆå§‹åŒ–ä¸ç¨³å®šä¸”å™ªå£°æŠ‘åˆ¶æ— æ•ˆã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LL-Gaussianï¼Œè¿™æ˜¯ä¸€ç§ä»ä½å…‰sRGBå›¾åƒè¿›è¡Œ3Dé‡å»ºå’Œå¢å¼ºçš„æ–°å‹æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°ä¼ªæ­£å¸¸å…‰æ–°é¢–è§†å›¾åˆæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼š1ï¼‰ç«¯åˆ°ç«¯çš„ä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ï¼ˆLLGIMï¼‰ï¼Œå®ƒåˆ©ç”¨åŸºäºå­¦ä¹ çš„MVSæ–¹æ³•çš„å¯†é›†å…ˆéªŒæ¥ç”Ÿæˆé«˜è´¨é‡åˆå§‹ç‚¹äº‘ï¼›2ï¼‰åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹ï¼Œèƒ½å¤Ÿå°†å†…åœ¨åœºæ™¯å±æ€§ï¼ˆåå°„ç‡å’Œç…§æ˜ï¼‰ä»ç¬æ€å¹²æ‰°ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä»è€Œå®ç°ç¨³å®šå’Œå¯è§£é‡Šçš„ä¼˜åŒ–ï¼›3ï¼‰ä¸€ç§å—ç‰©ç†çº¦æŸå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„æ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥å…±åŒå¼•å¯¼åˆ†è§£å’Œå¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è´¡çŒ®äº†åœ¨æç«¯ä½å…‰ç¯å¢ƒä¸­æ”¶é›†çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†LL-Gaussiançš„æœ‰æ•ˆæ€§ã€‚ä¸æœ€å…ˆè¿›çš„åŸºäºNeRFçš„æ–¹æ³•ç›¸æ¯”ï¼ŒLL-Gaussianå®ç°äº†é«˜è¾¾2000å€æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œå¹¶å°†è®­ç»ƒæ—¶é—´å‡å°‘åˆ°ä»…2%ï¼ŒåŒæ—¶æä¾›ä¼˜è¶Šçš„é‡å»ºå’Œæ¸²æŸ“è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10331v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://sunhao242.github.io/LL-Gaussian_web.github.io/">https://sunhao242.github.io/LL-Gaussian_web.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†åœ¨ä½å…‰ç…§åœºæ™¯ä¸­å®ç°æ–°é¢–è§†å›¾åˆæˆï¼ˆNVSï¼‰çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è¾“å…¥è´¨é‡ä¸‹é™ã€å™ªå£°ä¸¥é‡ã€åŠ¨æ€èŒƒå›´ä½å’Œåˆå§‹åŒ–ä¸å¯é ç­‰é—®é¢˜ã€‚æœ€è¿‘åŸºäºNeRFçš„æ–¹æ³•è™½ç„¶å–å¾—äº†æœ‰å¸Œæœ›çš„æˆæœï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”ä¾èµ–äºç²¾å¿ƒæ•è·æˆ–é¢„å¤„ç†çš„æ•°æ®ï¼Œè¿™é™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°å®æ—¶æ¸²æŸ“å¹¶å…·æœ‰ç«äº‰åŠ›è§†è§‰ä¿çœŸåº¦ï¼Œä½†ç°æœ‰åŸºäº3DGSçš„æ–¹æ³•åœ¨å¤„ç†ä½å…‰ç…§sRGBè¾“å…¥æ—¶é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´é«˜æ–¯åˆå§‹åŒ–ä¸ç¨³å®šä¸”å™ªå£°æŠ‘åˆ¶æ— æ•ˆã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†LL-Gaussianæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å®ç°äº†ä»ä½å…‰ç…§sRGBå›¾åƒè¿›è¡Œ3Dé‡å»ºå’Œå¢å¼ºçš„æ–°é¢–æ–¹æ³•ï¼Œå®ç°äº†ä¼ªæ­£å¸¸å…‰æ–°é¢–è§†å›¾åˆæˆã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šç«¯å¯¹ç«¯ä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ï¼ˆLLGIMï¼‰ã€åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹å’Œå—ç‰©ç†çº¦æŸå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„æ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä½å…‰ç…§åœºæ™¯ä¸­çš„æ–°é¢–è§†å›¾åˆæˆé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è¾“å…¥è´¨é‡ä¸‹é™å’Œå™ªå£°é—®é¢˜ã€‚</li>
<li>ç°æœ‰åŸºäºNeRFçš„æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†è®¡ç®—æˆæœ¬é«˜ä¸”ä¾èµ–ç²¾å¿ƒå¤„ç†çš„æ•°æ®ï¼Œé™åˆ¶äº†å®ç”¨æ€§ã€‚</li>
<li>3DGSèƒ½å¤Ÿå®ç°å®æ—¶æ¸²æŸ“ï¼Œä½†åœ¨å¤„ç†ä½å…‰ç…§sRGBè¾“å…¥æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>LL-Gaussianæ¡†æ¶é€šè¿‡ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹è§£å†³äº†è¿™äº›é—®é¢˜ï¼šä½å…‰é«˜æ–¯åˆå§‹åŒ–æ¨¡å—ã€åŒåˆ†æ”¯é«˜æ–¯åˆ†è§£æ¨¡å‹å’Œæ— ç›‘ç£ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>LL-Gaussianæ¡†æ¶å®ç°äº†ä»ä½å…‰ç…§sRGBå›¾åƒè¿›è¡Œ3Dé‡å»ºå’Œå¢å¼ºçš„åŠŸèƒ½ï¼Œèƒ½å¤Ÿå®ç°ä¼ªæ­£å¸¸å…‰æ–°é¢–è§†å›¾åˆæˆã€‚</li>
<li>LL-Gaussianæ¡†æ¶å¼•å…¥äº†å­¦ä¹ åŸºäºå¯†é›†å…ˆéªŒçš„MVSæ–¹æ³•æ¥ç”Ÿæˆé«˜è´¨é‡åˆå§‹ç‚¹äº‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10331">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc3e010f839dfba9beb5bb49f4e34377.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa6dbd3823e337d4c4527cfe396fdf2c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de11ea7140d240861a6ee879dd40aea2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e9b78a90cb6210c12dffc9e19c56fe2.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Scene4U-Hierarchical-Layered-3D-Scene-Reconstruction-from-Single-Panoramic-Image-for-Your-Immerse-Exploration"><a href="#Scene4U-Hierarchical-Layered-3D-Scene-Reconstruction-from-Single-Panoramic-Image-for-Your-Immerse-Exploration" class="headerlink" title="Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single   Panoramic Image for Your Immerse Exploration"></a>Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single   Panoramic Image for Your Immerse Exploration</h2><p><strong>Authors:Zilong Huang, Jun He, Junyan Ye, Lihan Jiang, Weijia Li, Yiping Chen, Ting Han</strong></p>
<p>The reconstruction of immersive and realistic 3D scenes holds significant practical importance in various fields of computer vision and computer graphics. Typically, immersive and realistic scenes should be free from obstructions by dynamic objects, maintain global texture consistency, and allow for unrestricted exploration. The current mainstream methods for image-driven scene construction involves iteratively refining the initial image using a moving virtual camera to generate the scene. However, previous methods struggle with visual discontinuities due to global texture inconsistencies under varying camera poses, and they frequently exhibit scene voids caused by foreground-background occlusions. To this end, we propose a novel layered 3D scene reconstruction framework from panoramic image, named Scene4U. Specifically, Scene4U integrates an open-vocabulary segmentation model with a large language model to decompose a real panorama into multiple layers. Then, we employs a layered repair module based on diffusion model to restore occluded regions using visual cues and depth information, generating a hierarchical representation of the scene. The multi-layer panorama is then initialized as a 3D Gaussian Splatting representation, followed by layered optimization, which ultimately produces an immersive 3D scene with semantic and structural consistency that supports free exploration. Scene4U outperforms state-of-the-art method, improving by 24.24% in LPIPS and 24.40% in BRISQUE, while also achieving the fastest training speed. Additionally, to demonstrate the robustness of Scene4U and allow users to experience immersive scenes from various landmarks, we build WorldVista3D dataset for 3D scene reconstruction, which contains panoramic images of globally renowned sites. The implementation code and dataset will be released at <a target="_blank" rel="noopener" href="https://github.com/LongHZ140516/Scene4U">https://github.com/LongHZ140516/Scene4U</a> . </p>
<blockquote>
<p>å…¨æ™¯ä¸‰ç»´åœºæ™¯é‡å»ºåœ¨è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦é¢†åŸŸå…·æœ‰é‡å¤§å®é™…æ„ä¹‰ã€‚é€šå¸¸ï¼Œæ²‰æµ¸å¼ä¸”é€¼çœŸçš„åœºæ™¯åº”è¯¥ä¸å—åŠ¨æ€ç‰©ä½“çš„é˜»æŒ¡ï¼Œä¿æŒå…¨å±€çº¹ç†ä¸€è‡´æ€§ï¼Œå¹¶å…è®¸ä¸å—é™åˆ¶çš„æ¢ç´¢ã€‚å½“å‰ä¸»æµçš„å›¾åƒé©±åŠ¨åœºæ™¯æ„å»ºæ–¹æ³•é€šè¿‡ç§»åŠ¨è™šæ‹Ÿç›¸æœºå¯¹åˆå§‹å›¾åƒè¿›è¡Œè¿­ä»£ä¼˜åŒ–ä»¥ç”Ÿæˆåœºæ™¯ã€‚ç„¶è€Œï¼Œä»¥å‰çš„æ–¹æ³•åœ¨å¤„ç†ç”±äºä¸åŒç›¸æœºå§¿æ€ä¸‹çš„å…¨å±€çº¹ç†ä¸ä¸€è‡´å¯¼è‡´çš„è§†è§‰ä¸è¿ç»­æ—¶é‡åˆ°å›°éš¾ï¼Œå¹¶ä¸”å®ƒä»¬ç»å¸¸ç”±äºå‰æ™¯èƒŒæ™¯é®æŒ¡è€Œå¯¼è‡´åœºæ™¯ç©ºæ´ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºScene4Uçš„æ–°å‹åˆ†å±‚ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼ŒScene4Uå°†å¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ä¸å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆï¼Œå°†çœŸå®å…¨æ™¯å›¾åƒåˆ†è§£ä¸ºå¤šä¸ªå±‚æ¬¡ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ†å±‚ä¿®å¤æ¨¡å—ï¼Œåˆ©ç”¨è§†è§‰çº¿ç´¢å’Œæ·±åº¦ä¿¡æ¯æ¢å¤é®æŒ¡åŒºåŸŸï¼Œç”Ÿæˆåœºæ™¯çš„å±‚æ¬¡è¡¨ç¤ºã€‚å¤šå±‚å…¨æ™¯å›¾åƒè¢«åˆå§‹åŒ–ä¸ºä¸‰ç»´é«˜æ–¯å–·å°„è¡¨ç¤ºï¼Œç„¶åè¿›è¡Œåˆ†å±‚ä¼˜åŒ–ï¼Œæœ€ç»ˆç”Ÿæˆå…·æœ‰è¯­ä¹‰å’Œç»“æ„ä¸€è‡´æ€§çš„æ²‰æµ¸å¼ä¸‰ç»´åœºæ™¯ï¼Œæ”¯æŒè‡ªç”±æ¢ç´¢ã€‚Scene4Uåœ¨LPIPSä¸Šæé«˜äº†24.24%ï¼Œåœ¨BRISQUEä¸Šæé«˜äº†24.4%ï¼Œå¹¶ä¸”å…·æœ‰æœ€å¿«çš„è®­ç»ƒé€Ÿåº¦ã€‚æ­¤å¤–ï¼Œä¸ºäº†è¯æ˜Scene4Uçš„é²æ£’æ€§å¹¶å…è®¸ç”¨æˆ·ä»å„ç§åœ°æ ‡ä½“éªŒæ²‰æµ¸å¼åœºæ™¯ï¼Œæˆ‘ä»¬å»ºç«‹äº†ç”¨äºä¸‰ç»´åœºæ™¯é‡å»ºçš„WorldVista3Dæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å…¨çƒçŸ¥åæ™¯ç‚¹çš„å…¨æ™¯å›¾åƒã€‚å®æ–½ä»£ç å’Œæ•°æ®é›†å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/LongHZ140516/Scene4U%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/LongHZ140516/Scene4Uå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00387v2">PDF</a> CVPR 2025, 11 pages, 7 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºScene4Uçš„æ–°å‹åˆ†å±‚3Dåœºæ™¯é‡å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»å…¨æ™¯å›¾åƒå‡ºå‘ï¼Œé€šè¿‡é›†æˆå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå°†çœŸå®å…¨æ™¯å›¾åƒåˆ†è§£æˆå¤šä¸ªå±‚æ¬¡ã€‚åˆ©ç”¨åŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ†å±‚ä¿®å¤æ¨¡å—ï¼Œé€šè¿‡è§†è§‰çº¿ç´¢å’Œæ·±åº¦ä¿¡æ¯æ¢å¤é®æŒ¡åŒºåŸŸï¼Œç”Ÿæˆåœºæ™¯çš„å±‚æ¬¡è¡¨ç¤ºã€‚è¯¥æ¡†æ¶åˆå§‹åŒ–å¤šå±‚å…¨æ™¯å›¾åƒä¸º3Dé«˜æ–¯Splattingè¡¨ç¤ºï¼Œéšåè¿›è¡Œåˆ†å±‚ä¼˜åŒ–ï¼Œæœ€ç»ˆç”Ÿæˆå…·æœ‰è¯­ä¹‰å’Œç»“æ„ä¸€è‡´æ€§çš„æ²‰æµ¸å¼3Dåœºæ™¯ï¼Œæ”¯æŒè‡ªç”±æ¢ç´¢ã€‚Scene4Uåœ¨LPIPSå’ŒBRISQUEæŒ‡æ ‡ä¸Šåˆ†åˆ«æé«˜äº†24.24%å’Œ24.40%ï¼Œä¸”è®­ç»ƒé€Ÿåº¦æœ€å¿«ã€‚æ­¤å¤–ï¼Œä¸ºäº†å±•ç¤ºScene4Uçš„é²æ£’æ€§å¹¶è®©ç”¨æˆ·ä½“éªŒæ¥è‡ªä¸åŒåœ°æ ‡çš„æ²‰æµ¸å¼åœºæ™¯ï¼Œå»ºç«‹äº†WorldVista3Dæ•°æ®é›†ç”¨äº3Dåœºæ™¯é‡å»ºã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>Scene4Uæ¡†æ¶åˆ©ç”¨å…¨æ™¯å›¾åƒè¿›è¡Œåˆ†å±‚3Dåœºæ™¯é‡å»ºï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†åŠ¨æ€å¯¹è±¡é®æŒ¡å’Œå…¨å±€çº¹ç†ä¸ä¸€è‡´æ€§æ–¹é¢çš„è§†è§‰æ–­å±‚é—®é¢˜ã€‚</li>
<li>Scene4Ué›†æˆäº†å¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæœ‰æ•ˆåˆ†è§£å…¨æ™¯å›¾åƒä¸ºå¤šä¸ªå±‚æ¬¡ï¼Œå¢å¼ºäº†åœºæ™¯çš„ç»†èŠ‚å’ŒçœŸå®æ„Ÿã€‚</li>
<li>åŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ†å±‚ä¿®å¤æ¨¡å—ç”¨äºæ¢å¤è¢«é®æŒ¡åŒºåŸŸï¼Œåˆ©ç”¨è§†è§‰çº¿ç´¢å’Œæ·±åº¦ä¿¡æ¯ç”Ÿæˆåœºæ™¯çš„å±‚æ¬¡è¡¨ç¤ºï¼Œæé«˜äº†åœºæ™¯çš„è¿è´¯æ€§å’Œå®Œæ•´æ€§ã€‚</li>
<li>Scene4Ué‡‡ç”¨å¤šå±‚å…¨æ™¯å›¾åƒçš„3Dé«˜æ–¯Splattingè¡¨ç¤ºå’Œåˆ†å±‚ä¼˜åŒ–æŠ€æœ¯ï¼Œç”Ÿæˆå…·æœ‰è¯­ä¹‰å’Œç»“æ„ä¸€è‡´æ€§çš„æ²‰æµ¸å¼3Dåœºæ™¯ï¼Œæ”¯æŒè‡ªç”±æ¢ç´¢ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒã€‚</li>
<li>Scene4Uåœ¨LPIPSå’ŒBRISQUEè¯„ä»·æŒ‡æ ‡ä¸Šå–å¾—æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸”åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šè¡¨ç°æœ€å¿«ã€‚</li>
<li>ä¸ºäº†æ¨å¹¿Scene4Uçš„åº”ç”¨ï¼Œå»ºç«‹äº†WorldVista3Dæ•°æ®é›†ï¼ŒåŒ…å«å…¨çƒçŸ¥åæ™¯ç‚¹çš„å…¨æ™¯å›¾åƒï¼Œç”¨äº3Dåœºæ™¯é‡å»ºã€‚</li>
<li>Scene4Uçš„å®æ–½ä»£ç å’Œæ•°æ®é›†å°†å…¬å¼€å‘å¸ƒï¼Œä¾¿äºç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00387">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d05a9c8420aec71ed6761b3ca36ee789.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c000e424f6f3499c0851eeff16e9c85.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8da3d3a6f4bf349f279be234eecfb8bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c27882cb9476477fe54a896f92c60d8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HRAvatar-High-Quality-and-Relightable-Gaussian-Head-Avatar"><a href="#HRAvatar-High-Quality-and-Relightable-Gaussian-Head-Avatar" class="headerlink" title="HRAvatar: High-Quality and Relightable Gaussian Head Avatar"></a>HRAvatar: High-Quality and Relightable Gaussian Head Avatar</h2><p><strong>Authors:Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Kangjie Chen, Minghan Qin, Yu Li, Haoqian Wang</strong></p>
<p>Reconstructing animatable and high-quality 3D head avatars from monocular videos, especially with realistic relighting, is a valuable task. However, the limited information from single-view input, combined with the complex head poses and facial movements, makes this challenging. Previous methods achieve real-time performance by combining 3D Gaussian Splatting with a parametric head model, but the resulting head quality suffers from inaccurate face tracking and limited expressiveness of the deformation model. These methods also fail to produce realistic effects under novel lighting conditions. To address these issues, we propose HRAvatar, a 3DGS-based method that reconstructs high-fidelity, relightable 3D head avatars. HRAvatar reduces tracking errors through end-to-end optimization and better captures individual facial deformations using learnable blendshapes and learnable linear blend skinning. Additionally, it decomposes head appearance into several physical properties and incorporates physically-based shading to account for environmental lighting. Extensive experiments demonstrate that HRAvatar not only reconstructs superior-quality heads but also achieves realistic visual effects under varying lighting conditions. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºå¯åŠ¨ç”»å’Œé«˜è´¨é‡çš„3Då¤´åƒï¼Œå°¤å…¶æ˜¯å…·æœ‰é€¼çœŸçš„é‡æ–°ç…§æ˜æ•ˆæœï¼Œæ˜¯ä¸€é¡¹æœ‰ä»·å€¼çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå•è§†å›¾è¾“å…¥çš„æœ‰é™ä¿¡æ¯ï¼Œä»¥åŠå¤æ‚çš„å¤´éƒ¨å§¿åŠ¿å’Œé¢éƒ¨è¿åŠ¨ï¼Œä½¿å¾—è¿™é¡¹ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¹‹å‰çš„æ–¹æ³•æ˜¯é€šè¿‡ç»“åˆ3Dé«˜æ–¯æ‹¼è´´å’Œå‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹æ¥å®ç°å®æ—¶æ€§èƒ½çš„ï¼Œä½†å¤´éƒ¨è´¨é‡çš„ç»“æœå—åˆ°é¢éƒ¨è·Ÿè¸ªä¸å‡†ç¡®å’Œå˜å½¢æ¨¡å‹çš„è¡¨è¾¾æœ‰é™çš„å›°æ‰°ã€‚è¿™äº›æ–¹æ³•åœ¨æ–°çš„å…‰ç…§æ¡ä»¶ä¸‹ä¹Ÿæ— æ³•äº§ç”Ÿé€¼çœŸçš„æ•ˆæœã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†HRAvatarï¼Œä¸€ç§åŸºäº3DGSçš„æ–¹æ³•ï¼Œç”¨äºé‡å»ºé«˜ä¿çœŸã€å¯é‡æ–°ç…§æ˜çš„3Då¤´åƒã€‚HRAvataré€šè¿‡ç«¯åˆ°ç«¯ä¼˜åŒ–å‡å°‘äº†è·Ÿè¸ªè¯¯å·®ï¼Œå¹¶ä½¿ç”¨å¯å­¦ä¹ çš„blendshapeså’Œå¯å­¦ä¹ çš„çº¿æ€§æ··åˆè’™çš®æŠ€æœ¯æ›´å¥½åœ°æ•æ‰äº†ä¸ªäººé¢éƒ¨å˜å½¢ã€‚æ­¤å¤–ï¼Œå®ƒå°†å¤´éƒ¨å¤–è§‚åˆ†è§£æˆå¤šç§ç‰©ç†å±æ€§ï¼Œå¹¶èå…¥åŸºäºç‰©ç†çš„ç€è‰²æŠ€æœ¯æ¥è€ƒè™‘ç¯å¢ƒç…§æ˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHRAvatarä¸ä»…é‡å»ºäº†é«˜è´¨é‡çš„å¤´éƒ¨ï¼Œè€Œä¸”åœ¨ä¸åŒçš„å…‰ç…§æ¡ä»¶ä¸‹å®ç°äº†é€¼çœŸçš„è§†è§‰æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08224v2">PDF</a> Accepted to CVPR 2025,Project page:   <a target="_blank" rel="noopener" href="https://eastbeanzhang.github.io/HRAvatar">https://eastbeanzhang.github.io/HRAvatar</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäº3DGSçš„æ–¹æ³•ï¼Œå³HRAvatarï¼Œç”¨äºä»å•è§†è§’è§†é¢‘ä¸­é‡å»ºé«˜è´¨é‡ã€å¯é‡æ–°ç…§æ˜çš„3Då¤´åƒã€‚è¯¥æ–¹æ³•é€šè¿‡ç«¯åˆ°ç«¯ä¼˜åŒ–å‡å°‘è·Ÿè¸ªè¯¯å·®ï¼Œä½¿ç”¨å¯å­¦ä¹ çš„blendshapeså’Œçº¿æ€§çš®è‚¤æ··åˆæŠ€æœ¯æ›´å¥½åœ°æ•æ‰é¢éƒ¨å˜å½¢ï¼Œå¹¶å°†å¤´éƒ¨å¤–è§‚åˆ†è§£æˆå¤šä¸ªç‰©ç†å±æ€§ï¼Œç»“åˆåŸºäºç‰©ç†çš„ç€è‰²æ¥æ¨¡æ‹Ÿç¯å¢ƒç…§æ˜ï¼Œä»è€Œåœ¨ä¸åŒç…§æ˜æ¡ä»¶ä¸‹å®ç°çœŸå®çš„è§†è§‰æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HRAvataræ˜¯ä¸€ç§åŸºäº3DGSçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å•è§†è§’è§†é¢‘é‡å»ºé«˜è´¨é‡ã€å¯é‡æ–°ç…§æ˜çš„3Då¤´åƒã€‚</li>
<li>é€šè¿‡ç«¯åˆ°ç«¯ä¼˜åŒ–å‡å°‘è·Ÿè¸ªè¯¯å·®ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚</li>
<li>ä½¿ç”¨å¯å­¦ä¹ çš„blendshapeså’Œçº¿æ€§çš®è‚¤æ··åˆæŠ€æœ¯ï¼Œæ›´å¥½åœ°æ•æ‰é¢éƒ¨å˜å½¢ã€‚</li>
<li>å°†å¤´éƒ¨å¤–è§‚åˆ†è§£æˆå¤šä¸ªç‰©ç†å±æ€§ï¼Œå¦‚å½¢çŠ¶ã€çº¹ç†ã€åå°„å±æ€§ç­‰ã€‚</li>
<li>ç»“åˆåŸºäºç‰©ç†çš„ç€è‰²æŠ€æœ¯ï¼Œæ¨¡æ‹Ÿç¯å¢ƒç…§æ˜ï¼Œå®ç°çœŸå®æ„Ÿè§†è§‰æ•ˆæœã€‚</li>
<li>HRAvataråœ¨å¤šç§ç…§æ˜æ¡ä»¶ä¸‹è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œé‡å»ºçš„å¤´åƒè´¨é‡é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08224">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e9653e27e020d829a561c38f775c1d6f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a9403e693b6592db9f3d419b43d3503.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a0c9188aea80735f0293e57ed43e0fe.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Digital-Twin-Buildings-3D-Modeling-GIS-Integration-and-Visual-Descriptions-Using-Gaussian-Splatting-ChatGPT-Deepseek-and-Google-Maps-Platform"><a href="#Digital-Twin-Buildings-3D-Modeling-GIS-Integration-and-Visual-Descriptions-Using-Gaussian-Splatting-ChatGPT-Deepseek-and-Google-Maps-Platform" class="headerlink" title="Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual   Descriptions Using Gaussian Splatting, ChatGPT&#x2F;Deepseek, and Google Maps   Platform"></a>Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual   Descriptions Using Gaussian Splatting, ChatGPT&#x2F;Deepseek, and Google Maps   Platform</h2><p><strong>Authors:Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li</strong></p>
<p>Urban digital twins are virtual replicas of cities that use multi-source data and data analytics to optimize urban planning, infrastructure management, and decision-making. Towards this, we propose a framework focused on the single-building scale. By connecting to cloud mapping platforms such as Google Map Platforms APIs, by leveraging state-of-the-art multi-agent Large Language Models data analysis using ChatGPT(4o) and Deepseek-V3&#x2F;R1, and by using our Gaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildings framework can retrieve a buildingâ€™s 3D model, visual descriptions, and achieve cloud-based mapping integration with large language model-based data analytics using a buildingâ€™s address, postal code, or geographic coordinates. </p>
<blockquote>
<p>åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åˆ©ç”¨å¤šæºæ•°æ®å’Œæ•°æ®åˆ†æä¼˜åŒ–åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œå†³ç­–åˆ¶å®šçš„åŸå¸‚è™šæ‹Ÿå‰¯æœ¬ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä»¥å•æ ‹å»ºç­‘è§„æ¨¡ä¸ºé‡ç‚¹çš„æ¡†æ¶ã€‚é€šè¿‡è¿æ¥åˆ°è°·æ­Œåœ°å›¾å¹³å°APIç­‰äº‘åœ°å›¾å¹³å°ï¼Œåˆ©ç”¨æœ€å…ˆè¿›çš„åŸºäºå¤šæ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹ï¼ˆä½¿ç”¨ChatGPTï¼ˆç¬¬4ä»£ï¼‰å’ŒDeepseek-V3&#x2F;R1è¿›è¡Œæ•°æ®åˆ†æï¼‰ï¼Œä»¥åŠåˆ©ç”¨æˆ‘ä»¬çš„åŸºäºé«˜æ–¯æ··åˆç½‘æ ¼æå–æµç¨‹ï¼Œæˆ‘ä»¬çš„æ•°å­—åŒèƒèƒå»ºç­‘æ¡†æ¶å¯ä»¥æ£€ç´¢å»ºç­‘ç‰©çš„ä¸‰ç»´æ¨¡å‹ã€è§†è§‰æè¿°ä¿¡æ¯ï¼Œå®ç°åŸºäºäº‘ç«¯çš„åœ°å›¾é›†æˆï¼Œä»¥å»ºç­‘ç‰©çš„åœ°å€ã€é‚®æ”¿ç¼–ç æˆ–åœ°ç†åæ ‡è¿›è¡Œå¤§æ•°æ®é‡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®åˆ†æã€‚è¿™ä¸ä»…åŒ…æ‹¬ä½ç½®ç»´åº¦ã€åœ°æ ‡å’Œæ–‡åŒ–ç‰¹ç‚¹ç­‰å¤šç§è§’åº¦çš„æ„å»ºä¿¡æ¯é‡‡é›†ä¸åˆ†æåŠŸèƒ½ã€‚å› æ­¤è¯¥æ¡†æ¶çš„åº”ç”¨éå¸¸çµæ´»å’Œå¤šæ ·ã€‚é€šè¿‡ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·å’Œäº‘è®¡ç®—å¹³å°è¿æ¥å¤šä¸ªæ•°æ®æºçš„æŠ€æœ¯æ–¹æ³•æ¥å®ç°ï¼Œæ•´ä¸ªç³»ç»Ÿçš„ç¨³å®šæ€§å’Œæ•°æ®å¤„ç†èƒ½åŠ›éƒ½æœ‰å¾ˆå¤§æé«˜ã€‚é€šè¿‡è¿™ç§æ–°å‹æ•°å­—æŠ€æœ¯æ•´åˆç­–ç•¥å®ç°çš„ä¸‰ç»´ä»¿çœŸæ¨¡å‹å’Œå¤æ‚è®¡ç®—æ¨ç†å·¥ä½œå°†è¿›ä¸€æ­¥ä¼˜åŒ–æœªæ¥åŸå¸‚å»ºè®¾å·¥ä½œçš„è¿›ç¨‹ä¸ç²¾å‡†åº¦æ°´å¹³æå‡çš„é‡è¦æœºé‡ã€‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05769v3">PDF</a> -Fixed minor typo</p>
<p><strong>Summary</strong><br>     åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åˆ©ç”¨å¤šæºæ•°æ®å’Œæ•°æ®åˆ†æä¼˜åŒ–åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œå†³ç­–åˆ¶å®šçš„è™šæ‹ŸåŸå¸‚æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªä»¥å•æ ‹å»ºç­‘ä¸ºå°ºåº¦çš„æ¡†æ¶ï¼Œé€šè¿‡è¿æ¥è°·æ­Œåœ°å›¾å¹³å°APIç­‰äº‘åœ°å›¾å¹³å°ï¼Œåˆ©ç”¨æœ€å…ˆè¿›çš„åŸºäºå¤šæ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹ChatGPTï¼ˆ4ä»£ï¼‰ã€Deepseek V3æˆ–Rç‰ˆè¿›è¡Œåˆ†æï¼Œå¹¶é€šè¿‡é«˜æ–¯èšåˆï¼ˆé«˜æ–¯ç¾½åŒ–ï¼‰æŠ€æœ¯æå–å»ºç­‘ä¸‰ç»´æ¨¡å‹çš„æ•°æ®é›†æˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ£€ç´¢å»ºç­‘ç‰©çš„ä¸‰ç»´æ¨¡å‹ã€è§†è§‰æè¿°ï¼Œå¹¶å®ç°åŸºäºäº‘çš„å¤§å‹è¯­è¨€æ¨¡å‹æ•°æ®åˆ†æä¸åœ°å›¾é›†æˆï¼Œä½¿ç”¨å»ºç­‘ç‰©çš„åœ°å€ã€é‚®æ”¿ç¼–ç æˆ–åœ°ç†åæ ‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŸå¸‚æ•°å­—åŒèƒèƒæ˜¯åŸå¸‚çš„è™šæ‹Ÿå‰¯æœ¬ï¼Œåˆ©ç”¨æ•°æ®å’Œæ•°æ®åˆ†æä¼˜åŒ–åŸå¸‚å„ä¸ªæ–¹é¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä»¥å•æ ‹å»ºç­‘ä¸ºå°ºåº¦çš„æ¡†æ¶æ¥è¿›è¡Œæ•°å­—åŒèƒèƒæ„å»ºã€‚</li>
<li>é€šè¿‡äº‘åœ°å›¾å¹³å°å’Œå…ˆè¿›çš„è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šæºæ•°æ®è¿æ¥å’Œåˆ†æã€‚</li>
<li>ä½¿ç”¨é«˜æ–¯èšåˆæŠ€æœ¯æå–å»ºç­‘ç‰©çš„ä¸‰ç»´æ¨¡å‹å’Œè§†è§‰æè¿°ã€‚</li>
<li>æ¡†æ¶èƒ½å¤Ÿå®ç°åŸºäºäº‘çš„å¤§å‹è¯­è¨€æ¨¡å‹æ•°æ®åˆ†æä¸åœ°å›¾é›†æˆã€‚</li>
<li>è¯¥æ¡†æ¶å¯ä»¥é€šè¿‡å»ºç­‘ç‰©çš„åœ°å€ã€é‚®æ”¿ç¼–ç æˆ–åœ°ç†åæ ‡è¿›è¡Œæ£€ç´¢å’Œé›†æˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05769">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62dacfbdeefb0f9fc0dd3a79766f2a5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5ecc6427fbe8bec581b6686f010decd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-12b2f95e8e829eb8767ae6fb471e782f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f3d2b3b35ffaaa212c18e54dab7e23cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b6a47cec1f153dfa2ff4d795c8b069c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3d5743d9c232a5d49f6fef2e78990f76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6763660a6a78dec49ec6480d4cd9dd1f.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AuraFusion360-Augmented-Unseen-Region-Alignment-for-Reference-based-360Â°-Unbounded-Scene-Inpainting"><a href="#AuraFusion360-Augmented-Unseen-Region-Alignment-for-Reference-based-360Â°-Unbounded-Scene-Inpainting" class="headerlink" title="AuraFusion360: Augmented Unseen Region Alignment for Reference-based   360Â° Unbounded Scene Inpainting"></a>AuraFusion360: Augmented Unseen Region Alignment for Reference-based   360Â° Unbounded Scene Inpainting</h2><p><strong>Authors:Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, Jie-Ying Lee, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu</strong></p>
<p>Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes. </p>
<blockquote>
<p>ä¸‰ç»´åœºæ™¯è¡¥å…¨å¯¹äºä»è™šæ‹Ÿç°å®åˆ°å»ºç­‘å¯è§†åŒ–ç­‰åº”ç”¨è‡³å…³é‡è¦ï¼Œç„¶è€Œç°æœ‰æ–¹æ³•åœ¨360Â°æ— ç•Œåœºæ™¯çš„è§†å›¾ä¸€è‡´æ€§åŠå‡ ä½•ç²¾åº¦æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚æˆ‘ä»¬æ¨å‡ºäº†AuraFusion360ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå‚è€ƒçš„æ–°æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä»¥é«˜æ–¯æ‹¼æ¥è¡¨ç¤ºçš„ä¸‰ç»´åœºæ™¯ä¸­å®ç°é«˜è´¨é‡çš„å¯¹è±¡ç§»é™¤å’Œç©ºæ´å¡«å……ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ï¼ˆ1ï¼‰æ·±åº¦æ„ŸçŸ¥æœªè§æ©æ¨¡ç”Ÿæˆï¼Œç”¨äºå‡†ç¡®è¯†åˆ«é®æŒ¡ï¼Œï¼ˆ2ï¼‰è‡ªé€‚åº”å¼•å¯¼æ·±åº¦æ‰©æ•£ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„é›¶æ ·æœ¬æ–¹æ³•ï¼Œå¯å‡†ç¡®æ”¾ç½®åˆå§‹ç‚¹ï¼Œï¼ˆ3ï¼‰åŸºäºSDEditçš„ç»†èŠ‚å¢å¼ºï¼Œä»¥å®ç°å¤šè§†å›¾ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†é¦–ä¸ªå…¨é¢çš„æ•°æ®é›†360-USIDï¼Œç”¨äºè¯„ä¼°360Â°æ— ç•Œåœºæ™¯è¡¥å…¨çš„çœŸå®æƒ…å†µã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAuraFusion360åœ¨è§†è§‰æ„ŸçŸ¥è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶åœ¨è§†ç‚¹å¤§å¹…å˜åŒ–æ—¶ä¿æŒå‡ ä½•ç²¾åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05176v3">PDF</a> Paper accepted to CVPR 2025. Project page:   <a target="_blank" rel="noopener" href="https://kkennethwu.github.io/aurafusion360/">https://kkennethwu.github.io/aurafusion360/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†AuraFusion360ï¼Œä¸€ç§åŸºäºå‚è€ƒçš„3Dåœºæ™¯ä¿®å¤æ–°æ–¹æ³•ï¼Œç”¨äºé«˜è´¨é‡åœ°ç§»é™¤å’Œå¡«å……é«˜æ–¯æ‹¼è´´è¡¨ç¤ºçš„3Dåœºæ™¯ä¸­çš„ç‰©ä½“ç©ºæ´ã€‚è¯¥æ–¹æ³•å…·æœ‰æ·±åº¦æ„ŸçŸ¥çš„æœªè§æ©è†œç”Ÿæˆã€è‡ªé€‚åº”å¼•å¯¼æ·±åº¦æ‰©æ•£å’ŒSDEditç»†èŠ‚å¢å¼ºç­‰æŠ€æœ¯ï¼Œå¯åœ¨è§†ç‚¹å˜åŒ–æ—¶ä¿æŒå‡ ä½•ç²¾åº¦ï¼Œæ˜¾è‘—æé«˜åœºæ™¯ä¿®å¤çš„è´¨é‡å’Œè¿è´¯æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AuraFusion360æ˜¯ä¸€ç§é’ˆå¯¹3Dåœºæ™¯çš„ä¿®å¤æ–°æ–¹æ³•ï¼Œé€‚ç”¨äºè™šæ‹Ÿç°å®å’Œå»ºç­‘å¯è§†åŒ–ç­‰åº”ç”¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é¢ä¸´è§†è§’ä¸€è‡´æ€§å’Œå‡ ä½•ç²¾åº¦çš„é—®é¢˜ï¼Œè€ŒAuraFusion360é€šè¿‡æ·±åº¦æ„ŸçŸ¥æœªè§æ©è†œç”ŸæˆæŠ€æœ¯è§£å†³äº†è¿™äº›é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•å¼•å…¥è‡ªé€‚åº”å¼•å¯¼æ·±åº¦æ‰©æ•£æŠ€æœ¯ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯å‡†ç¡®æ”¾ç½®åˆå§‹ç‚¹ã€‚</li>
<li>SDEditç»†èŠ‚å¢å¼ºæŠ€æœ¯å¢å¼ºäº†å¤šè§†è§’è¿è´¯æ€§ã€‚</li>
<li>å¼•å…¥äº†é¦–ä¸ªå…¨é¢çš„360Â°æ— ç•Œåœºæ™¯ä¿®å¤æ•°æ®é›†360-USIDï¼ŒåŒ…å«çœŸå®åœºæ™¯çš„åœ°é¢çœŸå®æ•°æ®ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒAuraFusion360æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨æ„ŸçŸ¥è´¨é‡å’Œå‡ ä½•ç²¾åº¦æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05176">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-539d64d1678b556cb03c2cca7f57e8db.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d463224f10868c6c86ed287261edeeb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc67871e8574ddcaf04a30559721e16d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3bc21a1850452758875ca1677cda6f17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c9b4fae92ab66deb55d1fdcff1e7ecd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-674fab30757a99480954618780007088.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GFreeDet-Exploiting-Gaussian-Splatting-and-Foundation-Models-for-Model-free-Unseen-Object-Detection-in-the-BOP-Challenge-2024"><a href="#GFreeDet-Exploiting-Gaussian-Splatting-and-Foundation-Models-for-Model-free-Unseen-Object-Detection-in-the-BOP-Challenge-2024" class="headerlink" title="GFreeDet: Exploiting Gaussian Splatting and Foundation Models for   Model-free Unseen Object Detection in the BOP Challenge 2024"></a>GFreeDet: Exploiting Gaussian Splatting and Foundation Models for   Model-free Unseen Object Detection in the BOP Challenge 2024</h2><p><strong>Authors:Xingyu Liu, Gu Wang, Chengxi Li, Yingyue Li, Chenyangguang Zhang, Ziqin Huang, Xiangyang Ji</strong></p>
<p>We present GFreeDet, an unseen object detection approach that leverages Gaussian splatting and vision Foundation models under model-free setting. Unlike existing methods that rely on predefined CAD templates, GFreeDet reconstructs objects directly from reference videos using Gaussian splatting, enabling robust detection of novel objects without prior 3D models. Evaluated on the BOP-H3 benchmark, GFreeDet achieves comparable performance to CAD-based methods, demonstrating the viability of model-free detection for mixed reality (MR) applications. Notably, GFreeDet won the best overall method and the best fast method awards in the model-free 2D detection track at BOP Challenge 2024. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†GFreeDetï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€æ¨¡å‹è®¾ç½®çš„æƒ…å†µä¸‹åˆ©ç”¨é«˜æ–¯è´´å›¾å’Œè§†è§‰åŸºç¡€æ¨¡å‹è¿›è¡Œæœªè§å¯¹è±¡æ£€æµ‹çš„æ–¹æ³•ã€‚ä¸åŒäºä¾èµ–é¢„è®¾CADæ¨¡æ¿çš„ç°æœ‰æ–¹æ³•ï¼ŒGFreeDetç›´æ¥ä½¿ç”¨å‚è€ƒè§†é¢‘é€šè¿‡é«˜æ–¯è´´å›¾é‡å»ºå¯¹è±¡ï¼Œå®ç°äº†æ— éœ€äº‹å…ˆ3Dæ¨¡å‹çš„ç¨³å¥æ–°å‹å¯¹è±¡æ£€æµ‹ã€‚åœ¨BOP-H3åŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°ï¼ŒGFreeDetçš„æ€§èƒ½ä¸åŸºäºCADçš„æ–¹æ³•ç›¸å½“ï¼Œè¯æ˜äº†æ— æ¨¡å‹æ£€æµ‹åœ¨æ··åˆç°å®ï¼ˆMRï¼‰åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒGFreeDetåœ¨BOP Challenge 2024çš„æ— æ¨¡å‹äºŒç»´æ£€æµ‹èµ›é“ä¸Šè£è·äº†æœ€ä½³æ€»ä½“æ–¹æ³•å’Œæœ€ä½³å¿«é€Ÿæ–¹æ³•å¥–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01552v3">PDF</a> CVPR 2025 CV4MR Workshop</p>
<p><strong>Summary</strong></p>
<p>GFreeDetæ˜¯ä¸€ç§æ— éœ€é¢„è®¾æ¨¡å‹çš„å¯¹è±¡æ£€æµ‹æ–¹æ³•ï¼Œå®ƒé€šè¿‡é«˜æ–¯è´´å›¾å’Œè§†è§‰åŸºç¡€æ¨¡å‹å®ç°æ–°é¢–çš„å¯¹è±¡æ£€æµ‹ã€‚ç›¸è¾ƒäºä¾èµ–é¢„å…ˆå®šä¹‰çš„CADæ¨¡æ¿çš„ä¼ ç»Ÿæ–¹æ³•ï¼ŒGFreeDetèƒ½ç›´æ¥æ ¹æ®å‚è€ƒè§†é¢‘é‡æ„å¯¹è±¡å¹¶å®ç°æœªè§å¯¹è±¡çš„ç¨³å¥æ£€æµ‹ã€‚åœ¨BOP-H3æ ‡å‡†ä¸Šçš„æµ‹è¯•æ˜¾ç¤ºï¼ŒGFreeDetä¸åŸºäºCADçš„æ–¹æ³•æ€§èƒ½ç›¸å½“ï¼Œä¸ºæ··åˆç°å®ï¼ˆMRï¼‰åº”ç”¨å±•ç¤ºäº†æ— æ¨¡å‹æ£€æµ‹æ–¹æ³•çš„å¯è¡Œæ€§ã€‚GFreeDetè£è·BOP Challenge 2024æ¨¡å‹è‡ªç”±äºŒç»´æ£€æµ‹èµ›é“æœ€ä½³æ€»ä½“æ–¹æ³•å’Œæœ€ä½³å¿«é€Ÿæ–¹æ³•å¥–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GFreeDetæ˜¯ä¸€ç§æ— éœ€é¢„è®¾æ¨¡å‹çš„å¯¹è±¡æ£€æµ‹æ–¹æ³•ã€‚</li>
<li>GFreeDetä½¿ç”¨é«˜æ–¯è´´å›¾å’Œè§†è§‰åŸºç¡€æ¨¡å‹å®ç°æ–°é¢–çš„å¯¹è±¡æ£€æµ‹ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒGFreeDetæ— éœ€ä¾èµ–é¢„å…ˆå®šä¹‰çš„CADæ¨¡æ¿ã€‚</li>
<li>GFreeDetèƒ½å¤Ÿä»å‚è€ƒè§†é¢‘ä¸­é‡æ„å¯¹è±¡å¹¶å®ç°æœªè§å¯¹è±¡çš„ç¨³å¥æ£€æµ‹ã€‚</li>
<li>åœ¨BOP-H3æ ‡å‡†ä¸Šçš„æµ‹è¯•æ˜¾ç¤ºï¼ŒGFreeDetæ€§èƒ½ä¼˜å¼‚ï¼Œä¸åŸºäºCADçš„æ–¹æ³•ç›¸å½“ã€‚</li>
<li>GFreeDetå¯¹äºæ··åˆç°å®ï¼ˆMRï¼‰åº”ç”¨å…·æœ‰å¯è¡Œæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01552">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a47a6d6839ed1eb3862ddd567a25382d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9f2833dd016f196e88ced3de5e2b180d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a93d04e5505158b75f705400618c003e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-daa4aa25d888e81666fc3470d1b1b9df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3794b57f6e90bd3112a24e1821dac27.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="ULSR-GS-Ultra-Large-scale-Surface-Reconstruction-Gaussian-Splatting-with-Multi-View-Geometric-Consistency"><a href="#ULSR-GS-Ultra-Large-scale-Surface-Reconstruction-Gaussian-Splatting-with-Multi-View-Geometric-Consistency" class="headerlink" title="ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting   with Multi-View Geometric Consistency"></a>ULSR-GS: Ultra Large-scale Surface Reconstruction Gaussian Splatting   with Multi-View Geometric Consistency</h2><p><strong>Authors:Zhuoxiao Li, Shanliang Yao, Yong Yue, Wufan Zhao, Rongjun Qin, Angel F. Garcia-Fernandez, Andrew Levers, Xiaohui Zhu</strong></p>
<p>While Gaussian Splatting (GS) demonstrates efficient and high-quality scene rendering and small area surface extraction ability, it falls short in handling large-scale aerial image surface extraction tasks. To overcome this, we present ULSR-GS, a framework dedicated to high-fidelity surface extraction in ultra-large-scale scenes, addressing the limitations of existing GS-based mesh extraction methods. Specifically, we propose a point-to-photo partitioning approach combined with a multi-view optimal view matching principle to select the best training images for each sub-region. Additionally, during training, ULSR-GS employs a densification strategy based on multi-view geometric consistency to enhance surface extraction details. Experimental results demonstrate that ULSR-GS outperforms other state-of-the-art GS-based works on large-scale aerial photogrammetry benchmark datasets, significantly improving surface extraction accuracy in complex urban environments. Project page: <a target="_blank" rel="noopener" href="https://ulsrgs.github.io/">https://ulsrgs.github.io</a>. </p>
<blockquote>
<p>è™½ç„¶é«˜æ–¯æ¶‚æŠ¹ï¼ˆGSï¼‰åœ¨åœºæ™¯æ¸²æŸ“å’Œå°åŒºåŸŸè¡¨é¢æå–æ–¹é¢è¡¨ç°å‡ºé«˜æ•ˆä¸”é«˜è´¨é‡çš„èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡èˆªç©ºå›¾åƒè¡¨é¢æå–ä»»åŠ¡æ—¶å´è¡¨ç°ä¸è¶³ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç¼ºé™·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ULSR-GSï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¶…å¤§è§„æ¨¡åœºæ™¯é«˜ä¿çœŸè¡¨é¢æå–çš„æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰åŸºäºGSçš„ç½‘æ ¼æå–æ–¹æ³•çš„å±€é™æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‚¹-ç…§ç‰‡åˆ†åŒºæ–¹æ³•ï¼Œç»“åˆå¤šè§†è§’æœ€ä½³è§†è§’åŒ¹é…åŸåˆ™ï¼Œä¸ºæ¯ä¸ªå­åŒºåŸŸé€‰æ‹©æœ€ä½³çš„è®­ç»ƒå›¾åƒã€‚æ­¤å¤–ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒULSR-GSé‡‡ç”¨åŸºäºå¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§çš„å¯†é›†åŒ–ç­–ç•¥ï¼Œä»¥æé«˜è¡¨é¢æå–çš„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒULSR-GSåœ¨å¤§å‹èˆªç©ºæ‘„å½±æµ‹é‡åŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„åŸºäºGSçš„å·¥ä½œï¼Œåœ¨å¤æ‚çš„åŸå¸‚ç¯å¢ƒä¸­æ˜¾è‘—æé«˜è¡¨é¢æå–çš„å‡†ç¡®æ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://ulsrgs.github.io./">https://ulsrgs.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01402v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://ulsrgs.github.io/">https://ulsrgs.github.io</a></p>
<p><strong>Summary</strong></p>
<p>GSåœ¨é«˜æ•ˆç‡å’Œé«˜è´¨é‡çš„åœºæ™¯æ¸²æŸ“ä»¥åŠå°èŒƒå›´è¡¨é¢æå–æ–¹é¢è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡èˆªç©ºå›¾åƒè¡¨é¢æå–ä»»åŠ¡æ—¶å­˜åœ¨ä¸è¶³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ULSR-GSæ¡†æ¶ï¼Œè‡´åŠ›äºè¶…å¤§è§„æ¨¡åœºæ™¯çš„é«˜ä¿çœŸè¡¨é¢æå–ï¼Œè§£å†³äº†ç°æœ‰åŸºäºGSçš„ç½‘æ ¼æå–æ–¹æ³•çš„å±€é™æ€§ã€‚ULSR-GSé€šè¿‡ç‚¹-ç…§ç‰‡åˆ†å‰²æ–¹æ³•ä¸å¤šè§†è§’æœ€ä½³è§†å›¾åŒ¹é…åŸåˆ™ç›¸ç»“åˆï¼Œé€‰æ‹©æ¯ä¸ªå­åŒºåŸŸçš„æœ€ä½³è®­ç»ƒå›¾åƒã€‚æ­¤å¤–ï¼ŒULSR-GSåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨åŸºäºå¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§çš„è‡´å¯†åŒ–ç­–ç•¥ï¼Œä»¥æé«˜è¡¨é¢æå–çš„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒULSR-GSåœ¨å¤§å‹èˆªç©ºæ‘„å½±æµ‹é‡åŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–æœ€æ–°åŸºäºGSçš„å·¥ä½œï¼Œåœ¨å¤æ‚çš„åŸå¸‚ç¯å¢ƒä¸­æ˜¾è‘—æé«˜è¡¨é¢æå–çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Gaussian Splatting (GS)åœ¨åœºæ™¯æ¸²æŸ“å’Œå°èŒƒå›´è¡¨é¢æå–æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤§è§„æ¨¡èˆªç©ºå›¾åƒè¡¨é¢æå–ä»»åŠ¡ä¸­å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>ULSR-GSæ¡†æ¶æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå®ç°é«˜ä¿çœŸè¡¨é¢æå–åœ¨è¶…å¤§è§„æ¨¡åœºæ™¯ä¸­çš„åº”ç”¨ã€‚</li>
<li>ULSR-GSé‡‡ç”¨ç‚¹-ç…§ç‰‡åˆ†å‰²æ–¹æ³•ä¸å¤šè§†è§’æœ€ä½³è§†å›¾åŒ¹é…åŸåˆ™ï¼Œä¼˜åŒ–è®­ç»ƒå›¾åƒé€‰æ‹©ã€‚</li>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒULSR-GSåˆ©ç”¨å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§çš„è‡´å¯†åŒ–ç­–ç•¥æ¥æé«˜è¡¨é¢æå–çš„ç»†èŠ‚ã€‚</li>
<li>ULSR-GSåœ¨å¤§å‹èˆªç©ºæ‘„å½±æµ‹é‡åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æœ€æ–°åŸºäºGSçš„æ–¹æ³•ã€‚</li>
<li>ULSR-GSåœ¨å¤æ‚çš„åŸå¸‚ç¯å¢ƒä¸­æ˜¾è‘—æé«˜è¡¨é¢æå–çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01402">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-80f338f510bd4a116576f00d6052ac2b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-07cd9c61f70c85f831ecab41b36d29dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-816944b7ef830bcd39054de9e62cc164.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7fede778cfa7a4b2bfbb83d6cbde9872.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="OmniRe-Omni-Urban-Scene-Reconstruction"><a href="#OmniRe-Omni-Urban-Scene-Reconstruction" class="headerlink" title="OmniRe: Omni Urban Scene Reconstruction"></a>OmniRe: Omni Urban Scene Reconstruction</h2><p><strong>Authors:Ziyu Chen, Jiawei Yang, Jiahui Huang, Riccardo de Lutio, Janick Martinez Esturo, Boris Ivanovic, Or Litany, Zan Gojcic, Sanja Fidler, Marco Pavone, Li Song, Yue Wang</strong></p>
<p>We introduce OmniRe, a comprehensive system for efficiently creating high-fidelity digital twins of dynamic real-world scenes from on-device logs. Recent methods using neural fields or Gaussian Splatting primarily focus on vehicles, hindering a holistic framework for all dynamic foregrounds demanded by downstream applications, e.g., the simulation of human behavior. OmniRe extends beyond vehicle modeling to enable accurate, full-length reconstruction of diverse dynamic objects in urban scenes. Our approach builds scene graphs on 3DGS and constructs multiple Gaussian representations in canonical spaces that model various dynamic actors, including vehicles, pedestrians, cyclists, and others. OmniRe allows holistically reconstructing any dynamic object in the scene, enabling advanced simulations (~60Hz) that include human-participated scenarios, such as pedestrian behavior simulation and human-vehicle interaction. This comprehensive simulation capability is unmatched by existing methods. Extensive evaluations on the Waymo dataset show that our approach outperforms prior state-of-the-art methods quantitatively and qualitatively by a large margin. We further extend our results to 5 additional popular driving datasets to demonstrate its generalizability on common urban scenes. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†OmniReï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°ä»è®¾å¤‡æ—¥å¿—åˆ›å»ºåŠ¨æ€ç°å®ä¸–ç•Œåœºæ™¯çš„é«˜ä¿çœŸæ•°å­—å­ªç”Ÿã€‚æœ€è¿‘ä½¿ç”¨ç¥ç»åœºæˆ–é«˜æ–¯æ‹¼è´´çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è½¦è¾†ä¸Šï¼Œé˜»ç¢äº†ä¸ºä¸‹æ¸¸åº”ç”¨ï¼ˆä¾‹å¦‚æ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼‰æ‰€è¦æ±‚çš„æ‰€æœ‰åŠ¨æ€å‰æ™¯çš„å…¨å±€æ¡†æ¶ã€‚OmniReè¶…è¶Šäº†è½¦è¾†å»ºæ¨¡ï¼Œå®ç°äº†åŸå¸‚åœºæ™¯ä¸­å„ç§åŠ¨æ€å¯¹è±¡çš„ç²¾ç¡®ã€å…¨é•¿é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨ä¸‰ç»´å‡ ä½•æ‰«æç³»ç»Ÿï¼ˆ3DGSï¼‰ä¸Šï¼Œåœ¨æ ‡å‡†ç©ºé—´ä¸­æ„å»ºå¤šä¸ªé«˜æ–¯è¡¨ç¤ºï¼Œå¯¹åŒ…æ‹¬è½¦è¾†ã€è¡Œäººã€éª‘è¡Œè€…ç­‰åœ¨å†…çš„å„ç§åŠ¨æ€å‚ä¸è€…è¿›è¡Œå»ºæ¨¡ã€‚OmniReå…è®¸å…¨é¢é‡å»ºåœºæ™¯ä¸­çš„ä»»ä½•åŠ¨æ€å¯¹è±¡ï¼Œèƒ½å¤Ÿè¿›è¡Œé«˜çº§æ¨¡æ‹Ÿï¼ˆ~60Hzï¼‰ï¼ŒåŒ…æ‹¬äººç±»å‚ä¸çš„åœºæ™¯ï¼Œå¦‚è¡Œäººè¡Œä¸ºæ¨¡æ‹Ÿå’Œäººæœºäº’åŠ¨ã€‚è¿™ç§å…¨é¢çš„æ¨¡æ‹Ÿèƒ½åŠ›æ˜¯ç°æœ‰æ–¹æ³•æ— æ³•æ¯”æ‹Ÿçš„ã€‚åœ¨Waymoæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ— è®ºåœ¨æ•°é‡ä¸Šè¿˜æ˜¯è´¨é‡ä¸Šéƒ½å¤§å¤§ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°†ç»“æœæ‰©å±•åˆ°äº”ä¸ªå…¶ä»–æµè¡Œçš„é©¾é©¶æ•°æ®é›†ä¸Šï¼Œä»¥è¯æ˜å…¶åœ¨å¸¸è§åŸå¸‚åœºæ™¯ä¸Šçš„é€šç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.16760v2">PDF</a> See the project page for code, video results and demos:   <a target="_blank" rel="noopener" href="https://ziyc.github.io/omnire/">https://ziyc.github.io/omnire/</a></p>
<p><strong>Summary</strong></p>
<p>OmniReç³»ç»Ÿæ˜¯ä¸€ä¸ªå…¨é¢çš„é«˜æ•ˆåˆ›å»ºåŠ¨æ€ç°å®ä¸–ç•Œåœºæ™¯é«˜ä¿çœŸæ•°å­—åŒèƒèƒçš„ç³»ç»Ÿã€‚å®ƒé€šè¿‡æ„å»ºåœºæ™¯å›¾å’Œåœ¨æ ‡å‡†ç©ºé—´ä¸­çš„å¤šä¸ªé«˜æ–¯è¡¨ç¤ºæ¨¡å‹ï¼Œå®ç°å¯¹åŸå¸‚åœºæ™¯ä¸­å„ç§åŠ¨æ€å¯¹è±¡çš„ç²¾ç¡®ã€å…¨é¢é‡å»ºï¼ŒåŒ…æ‹¬è½¦è¾†ã€è¡Œäººã€éª‘è¡Œè€…ç­‰ã€‚OmniReç³»ç»Ÿæä¾›é«˜çº§æ¨¡æ‹ŸåŠŸèƒ½ï¼ˆ~60Hzï¼‰ï¼ŒåŒ…æ‹¬äººç±»å‚ä¸çš„åœºæ™¯ï¼Œå¦‚è¡Œäººè¡Œä¸ºæ¨¡æ‹Ÿå’Œäººæœºäº’åŠ¨ã€‚åœ¨Waymoæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢å‡å¤§å¤§ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨äº”ä¸ªæµè¡Œçš„é©¾é©¶æ•°æ®é›†ä¸Šçš„ç»“æœå±•ç¤ºäº†å…¶åœ¨å¸¸è§åŸå¸‚åœºæ™¯ä¸­çš„é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OmniReç³»ç»Ÿæ˜¯ä¸€ä¸ªç”¨äºåˆ›å»ºé«˜ä¿çœŸæ•°å­—åŒèƒèƒçš„å…¨é¢ç³»ç»Ÿï¼Œé€‚ç”¨äºåŠ¨æ€ç°å®ä¸–ç•Œåœºæ™¯çš„é‡å»ºã€‚</li>
<li>è¯¥ç³»ç»Ÿé€šè¿‡æ„å»ºåœºæ™¯å›¾å’Œåœ¨æ ‡å‡†ç©ºé—´ä¸­çš„å¤šä¸ªé«˜æ–¯è¡¨ç¤ºæ¨¡å‹ï¼Œå®ç°äº†åŸå¸‚åœºæ™¯ä¸­å„ç§åŠ¨æ€å¯¹è±¡çš„ç²¾ç¡®ã€å…¨é¢é‡å»ºã€‚</li>
<li>OmniReç³»ç»Ÿæ”¯æŒé«˜çº§æ¨¡æ‹ŸåŠŸèƒ½ï¼ˆ~60Hzï¼‰ï¼ŒåŒ…æ‹¬äººç±»å‚ä¸çš„å„ç§åœºæ™¯ï¼Œå¦‚è¡Œäººè¡Œä¸ºæ¨¡æ‹Ÿå’Œäººæœºäº’åŠ¨ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒOmniReç³»ç»Ÿåœ¨Waymoæ•°æ®é›†ä¸Šçš„è¡¨ç°å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå®šé‡å’Œå®šæ€§è¯„ä¼°å‡æ›´èƒœä¸€ç­¹ã€‚</li>
<li>OmniReç³»ç»Ÿçš„è¡¨ç°å…·æœ‰é€šç”¨æ€§ï¼Œä¸ä»…åœ¨Waymoæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜ç§€ï¼Œè€Œä¸”åœ¨äº”ä¸ªæµè¡Œçš„é©¾é©¶æ•°æ®é›†ä¸Šå‡å±•ç¤ºäº†è‰¯å¥½çš„ç»“æœã€‚</li>
<li>è¯¥ç³»ç»Ÿèƒ½å¤Ÿå®ç°å¯¹å¤šæ ·åŠ¨æ€å¯¹è±¡çš„å»ºæ¨¡ï¼ŒåŒ…æ‹¬è½¦è¾†ã€è¡Œäººã€éª‘è¡Œè€…ç­‰ï¼Œä¸ºä¸‹æ¸¸åº”ç”¨æä¾›äº†æ›´å…¨é¢çš„æ¨¡æ‹Ÿèƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.16760">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b261d0c2a71f67a343c4b063393c7745.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f8bbae460a472a5a732d1f0365e053e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bdae0d70f9370c44e0068a0c750ca0b.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Improving-Gaussian-Splatting-with-Localized-Points-Management"><a href="#Improving-Gaussian-Splatting-with-Localized-Points-Management" class="headerlink" title="Improving Gaussian Splatting with Localized Points Management"></a>Improving Gaussian Splatting with Localized Points Management</h2><p><strong>Authors:Haosen Yang, Chenhao Zhang, Wenqing Wang, Marco Volino, Adrian Hilton, Li Zhang, Xiatian Zhu</strong></p>
<p>Point management is critical for optimizing 3D Gaussian Splatting models, as point initiation (e.g., via structure from motion) is often distributionally inappropriate. Typically, Adaptive Density Control (ADC) algorithm is adopted, leveraging view-averaged gradient magnitude thresholding for point densification, opacity thresholding for pruning, and regular all-points opacity reset. We reveal that this strategy is limited in tackling intricate&#x2F;special image regions (e.g., transparent) due to inability of identifying all 3D zones requiring point densification, and lacking an appropriate mechanism to handle ill-conditioned points with negative impacts (e.g., occlusion due to false high opacity). To address these limitations, we propose a Localized Point Management (LPM) strategy, capable of identifying those error-contributing zones in greatest need for both point addition and geometry calibration. Zone identification is achieved by leveraging the underlying multiview geometry constraints, subject to image rendering errors. We apply point densification in the identified zones and then reset the opacity of the points in front of these regions, creating a new opportunity to correct poorly conditioned points. Serving as a versatile plugin, LPM can be seamlessly integrated into existing static 3D and dynamic 4D Gaussian Splatting models with minimal additional cost. Experimental evaluations validate the efficacy of our LPM in boosting a variety of existing 3D&#x2F;4D models both quantitatively and qualitatively. Notably, LPM improves both static 3DGS and dynamic SpaceTimeGS to achieve state-of-the-art rendering quality while retaining real-time speeds, excelling on challenging datasets such as Tanks &amp; Temples and the Neural 3D Video dataset. </p>
<blockquote>
<p>ç‚¹ç®¡ç†å¯¹äºä¼˜åŒ–3Dé«˜æ–¯å±•é“ºæ¨¡å‹è‡³å…³é‡è¦ï¼Œå› ä¸ºç‚¹çš„å¯åŠ¨ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡è¿åŠ¨ç»“æ„ï¼‰é€šå¸¸åˆ†å¸ƒä¸å½“ã€‚é€šå¸¸é‡‡ç”¨çš„æ˜¯è‡ªé€‚åº”å¯†åº¦æ§åˆ¶ï¼ˆADCï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨è§†å›¾å¹³å‡æ¢¯åº¦å¹…åº¦é˜ˆå€¼è¿›è¡Œç‚¹åŠ å¯†ï¼Œåˆ©ç”¨ä¸é€æ˜åº¦é˜ˆå€¼è¿›è¡Œä¿®å‰ªï¼Œä»¥åŠå¸¸è§„çš„æ‰€æœ‰ç‚¹ä¸é€æ˜åº¦é‡ç½®ã€‚æˆ‘ä»¬å‘ç°ï¼Œç”±äºæ— æ³•è¯†åˆ«æ‰€æœ‰éœ€è¦ç‚¹åŠ å¯†çš„3DåŒºåŸŸï¼Œä»¥åŠç¼ºä¹é€‚å½“æœºåˆ¶æ¥å¤„ç†å…·æœ‰è´Ÿé¢å½±å“çš„ç—…æ€ç‚¹ï¼ˆä¾‹å¦‚ï¼Œç”±äºè™šå‡çš„é«˜ä¸é€æ˜åº¦å¯¼è‡´çš„é®æŒ¡ï¼‰ï¼Œæ­¤ç­–ç•¥åœ¨å¤„ç†å¤æ‚&#x2F;ç‰¹æ®Šå›¾åƒåŒºåŸŸï¼ˆä¾‹å¦‚ï¼Œé€æ˜åŒºåŸŸï¼‰æ—¶å—åˆ°é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å±€éƒ¨ç‚¹ç®¡ç†ï¼ˆLPMï¼‰ç­–ç•¥ï¼Œèƒ½å¤Ÿè¯†åˆ«æœ€éœ€è¦æ·»åŠ ç‚¹å’Œå‡ ä½•æ ¡æ­£çš„è¯¯å·®è´¡çŒ®åŒºåŸŸã€‚åŒºåŸŸè¯†åˆ«æ˜¯é€šè¿‡åˆ©ç”¨åº•å±‚çš„å¤šè§†å›¾å‡ ä½•çº¦æŸæ¥å®ç°çš„ï¼ŒåŒæ—¶å—åˆ°å›¾åƒæ¸²æŸ“è¯¯å·®çš„å½±å“ã€‚æˆ‘ä»¬åœ¨ç¡®å®šçš„åŒºåŸŸä¸­åº”ç”¨ç‚¹åŠ å¯†ï¼Œç„¶åé‡ç½®è¿™äº›åŒºåŸŸå‰æ–¹ç‚¹çš„é€æ˜åº¦ï¼Œä¸ºæ ¡æ­£ä¸è‰¯çŠ¶å†µçš„ç‚¹åˆ›é€ äº†æ–°æœºä¼šã€‚ä½œä¸ºé€šç”¨çš„æ’ä»¶ï¼ŒLPMå¯ä»¥æ— ç¼åœ°é›†æˆåˆ°ç°æœ‰çš„é™æ€3Då’ŒåŠ¨æ€4Dé«˜æ–¯å±•é“ºæ¨¡å‹ä¸­ï¼Œä¸”æ— éœ€é¢å¤–çš„æˆæœ¬ã€‚å®éªŒè¯„ä¼°éªŒè¯äº†æˆ‘ä»¬LPMåœ¨æé«˜å„ç§ç°æœ‰3D&#x2F;4Dæ¨¡å‹çš„æ•ˆæœæ–¹é¢ï¼Œæ— è®ºæ˜¯å®šé‡è¿˜æ˜¯å®šæ€§éƒ½æ˜¯æœ‰æ•ˆçš„ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLPMæ”¹è¿›äº†é™æ€3DGSå’ŒåŠ¨æ€SpaceTimeGSï¼Œåœ¨ä¿æŒå®æ—¶é€Ÿåº¦çš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼ˆå¦‚Tanks &amp; Templeså’ŒNeural 3D Videoæ•°æ®é›†ï¼‰ä¸Šè¡¨ç°å‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.04251v3">PDF</a> CVPR 2025 (Highlight). Github:   <a target="_blank" rel="noopener" href="https://happy-hsy.github.io/projects/LPM/">https://happy-hsy.github.io/projects/LPM/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æŒ‡å‡ºåœ¨ä¼˜åŒ–3Dé«˜æ–¯å±•é“ºæ¨¡å‹æ—¶ï¼Œç‚¹ç®¡ç†è‡³å…³é‡è¦ã€‚ç°æœ‰çš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶ï¼ˆADCï¼‰ç®—æ³•åœ¨å¤„ç†å¤æ‚æˆ–ç‰¹æ®Šå›¾åƒåŒºåŸŸæ—¶å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å±€éƒ¨ç‚¹ç®¡ç†ï¼ˆLPMï¼‰ç­–ç•¥ï¼Œé€šè¿‡è¯†åˆ«æœ€éœ€è¦å¢åŠ ç‚¹å’Œè¿›è¡Œå‡ ä½•æ ¡æ­£çš„è¯¯å·®è´¡çŒ®åŒºåŸŸï¼Œæ¥æ”¹å–„æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒLPMèƒ½æœ‰æ•ˆæå‡å„ç§ç°æœ‰3D&#x2F;4Dæ¨¡å‹çš„æ•ˆæœï¼Œå¹¶ä¸”åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå®ç°äº†å®æ—¶çš„é«˜å“è´¨æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç‚¹ç®¡ç†å¯¹äºä¼˜åŒ–3Dé«˜æ–¯å±•é“ºæ¨¡å‹è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰ADCç®—æ³•åœ¨å¤„ç†å¤æ‚æˆ–ç‰¹æ®Šå›¾åƒåŒºåŸŸæ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>LPMç­–ç•¥é€šè¿‡è¯†åˆ«éœ€è¦å¢åŠ ç‚¹å’Œè¿›è¡Œå‡ ä½•æ ¡æ­£çš„è¯¯å·®è´¡çŒ®åŒºåŸŸï¼Œæ”¹è¿›äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>LPMç­–ç•¥åˆ©ç”¨å¤šè§†è§’å‡ ä½•çº¦æŸæ¥å®ç°åŒºåŸŸè¯†åˆ«ã€‚</li>
<li>LPMç­–ç•¥åœ¨è¯†åˆ«åŒºåŸŸè¿›è¡Œç‚¹åŠ å¯†ï¼Œå¹¶é‡ç½®è¿™äº›åŒºåŸŸå‰æ²¿ç‚¹çš„é€æ˜åº¦ï¼Œçº æ­£ä¸è‰¯çŠ¶å†µç‚¹ã€‚</li>
<li>LPMå¯æ— ç¼é›†æˆåˆ°ç°æœ‰çš„é™æ€3Då’ŒåŠ¨æ€4Dé«˜æ–¯å±•é“ºæ¨¡å‹ä¸­ï¼Œä¸”é¢å¤–æˆæœ¬è¾ƒä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.04251">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-547dce360e08f98fffa08b5b4cd950d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2148d2c39ab923e1c5fe8f1e6cca1de8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e829a5e71f29bc84c5facf3e0d72cf7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fc1188ba27f56ab0627bcc933c6ec660.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-23/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-23/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-23/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-bc3e010f839dfba9beb5bb49f4e34377.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-23  StyleMe3D Stylization with Disentangled Priors by Multiple Encoders on   3D Gaussians
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-23/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-35c91d90cebfa90340cc6439ccc9e159.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-23  SEGA Drivable 3D Gaussian Head Avatar from a Single Image
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29474.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
