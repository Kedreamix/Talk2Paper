<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  EvoEmo Towards Evolved Emotional Policies for LLM Agents in Multi-Turn   Negotiation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-92177ef149b183713613682d41bfdc56.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    67 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-07-æ›´æ–°"><a href="#2025-09-07-æ›´æ–°" class="headerlink" title="2025-09-07 æ›´æ–°"></a>2025-09-07 æ›´æ–°</h1><h2 id="EvoEmo-Towards-Evolved-Emotional-Policies-for-LLM-Agents-in-Multi-Turn-Negotiation"><a href="#EvoEmo-Towards-Evolved-Emotional-Policies-for-LLM-Agents-in-Multi-Turn-Negotiation" class="headerlink" title="EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn   Negotiation"></a>EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn   Negotiation</h2><p><strong>Authors:Yunbo Long, Liming Xu, Lukas Beckenbauer, Yuhan Liu, Alexandra Brintrup</strong></p>
<p>Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \textit{complex}, \textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines â€“ vanilla strategies and fixed-emotion strategies â€“ for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation. </p>
<blockquote>
<p>å…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†çš„æœ€è¿‘ç ”ç©¶è¡¨æ˜ï¼Œæ™ºèƒ½ä½“å¯ä»¥å‚ä¸å¤æ‚çš„å¤šè½®è°ˆåˆ¤ï¼Œä¸ºæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½æ‰“å¼€äº†æ–°çš„é€”å¾„ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMæ™ºèƒ½ä½“åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½è§†äº†æƒ…ç»ªåœ¨è¿™ç§è°ˆåˆ¤ä¸­çš„åŠŸèƒ½ä½œç”¨ï¼Œè€Œæ˜¯äº§ç”Ÿäº†è¢«åŠ¨ã€åå¥½é©±åŠ¨çš„æƒ…ç»ªååº”ï¼Œä½¿å…¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§å¯¹æ‰‹çš„æ“çºµå’Œæˆ˜ç•¥å‰¥å‰Šã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†EvoEmoï¼Œè¿™æ˜¯ä¸€ä¸ªè¿›åŒ–å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä¼˜åŒ–äº†è°ˆåˆ¤ä¸­çš„åŠ¨æ€æƒ…ç»ªè¡¨è¾¾ã€‚EvoEmoå°†æƒ…ç»ªçŠ¶æ€çš„è½¬å˜å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œå¹¶åŸºäºç¾¤ä½“é—ä¼ ä¼˜åŒ–æ¥è¿›åŒ–å„ç§è°ˆåˆ¤åœºæ™¯ä¸‹çš„é«˜å›æŠ¥æƒ…ç»ªç­–ç•¥ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªåŸºå‡†çº¿â€”â€”æ™®é€šç­–ç•¥å’Œå›ºå®šæƒ…ç»ªç­–ç•¥â€”â€”ç”¨äºè¯„ä¼°æƒ…æ„Ÿæ„ŸçŸ¥è°ˆåˆ¤ã€‚å¹¿æ³›çš„å®éªŒå’Œæ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒEvoEmoå§‹ç»ˆä¼˜äºä¸¤ä¸ªåŸºå‡†çº¿ï¼Œå®ç°äº†æ›´é«˜çš„æˆåŠŸç‡ã€æ›´é«˜çš„æ•ˆç‡å’Œæ›´é«˜çš„ä¹°å®¶èŠ‚çœã€‚è¿™äº›å‘ç°çªæ˜¾äº†åœ¨å¤šè½®è°ˆåˆ¤ä¸­è‡ªé€‚åº”æƒ…ç»ªè¡¨è¾¾çš„é‡è¦æ€§ï¼Œä½¿å¾—LLMæ™ºèƒ½ä½“æ›´åŠ æœ‰æ•ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04310v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸç ”ç©¶æ˜¾ç¤ºï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åº”ç”¨ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè¿›è¡Œå¤æ‚çš„å¤šè½®è°ˆåˆ¤ï¼Œä¸ºæ™ºèƒ½ä½“AIå¼€è¾Ÿäº†æ–°çš„é“è·¯ã€‚ç„¶è€Œï¼Œç°æœ‰LLMæ™ºèƒ½ä½“å¤§å¤šå¿½è§†äº†æƒ…ç»ªåœ¨è°ˆåˆ¤ä¸­çš„åŠŸèƒ½ä½œç”¨ï¼Œåªèƒ½äº§ç”Ÿè¢«åŠ¨ã€åå¥½é©±åŠ¨çš„æƒ…ç»ªååº”ï¼Œä½¿å…¶å®¹æ˜“å—åˆ°å¯¹æ‰‹çš„æˆ˜ç•¥æ“çºµå’Œå‰¥å‰Šã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EvoEmoæ¡†æ¶ï¼Œé‡‡ç”¨è¿›åŒ–å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è°ˆåˆ¤ä¸­çš„åŠ¨æ€æƒ…ç»ªè¡¨è¾¾ã€‚EvoEmoå°†æƒ…ç»ªçŠ¶æ€è½¬æ¢å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œå¹¶åŸºäºç¾¤ä½“é—ä¼ ä¼˜åŒ–ç®—æ³•è¿›åŒ–ä¸åŒè°ˆåˆ¤åœºæ™¯ä¸‹çš„é«˜å›æŠ¥æƒ…ç»ªç­–ç•¥ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬åŸºå‡†ç­–ç•¥å’Œå›ºå®šæƒ…ç»ªç­–ç•¥ä½œä¸ºåŸºå‡†çº¿ï¼Œç”¨äºè¯„ä¼°æƒ…æ„Ÿæ„ŸçŸ¥è°ˆåˆ¤çš„è¡¨ç°ã€‚å¤§é‡å®éªŒå’Œæ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒEvoEmoçš„è¡¨ç°å§‹ç»ˆä¼˜äºåŸºå‡†çº¿ç­–ç•¥ï¼Œå®ç°äº†æ›´é«˜çš„æˆåŠŸç‡ã€æ•ˆç‡å’Œä¹°å®¶èŠ‚çœã€‚è¿™è¡¨æ˜è‡ªé€‚åº”æƒ…ç»ªè¡¨è¾¾å¯¹äºå®ç°å¤šè½®è°ˆåˆ¤ä¸­æ›´é«˜æ•ˆçš„LLMæ™ºèƒ½ä½“è‡³å…³é‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsé€šè¿‡é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†èƒ½å¤Ÿè¿›è¡Œå¤æ‚çš„å¤šè½®è°ˆåˆ¤ã€‚</li>
<li>ç°æœ‰LLMæ™ºèƒ½ä½“åœ¨è°ˆåˆ¤ä¸­å¿½è§†äº†æƒ…ç»ªçš„ä½œç”¨ï¼Œå¯¼è‡´æ˜“å—åˆ°å¯¹æ‰‹æ“çºµã€‚</li>
<li>EvoEmoæ¡†æ¶é‡‡ç”¨è¿›åŒ–å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–åŠ¨æ€æƒ…ç»ªè¡¨è¾¾ï¼Œæé«˜æ™ºèƒ½ä½“åœ¨è°ˆåˆ¤ä¸­çš„è¡¨ç°ã€‚</li>
<li>EvoEmoå°†æƒ…ç»ªçŠ¶æ€è½¬æ¢å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡ç¾¤ä½“é—ä¼ ä¼˜åŒ–ç®—æ³•è¿›åŒ–é«˜å›æŠ¥çš„æƒ…ç»ªç­–ç•¥ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒEvoEmoåœ¨å¤šç§è°ˆåˆ¤åœºæ™¯ä¸­è¡¨ç°ä¼˜äºåŸºå‡†ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04310">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ec82d2610910cdb0ec016c7fd3831b2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4503d4f9510b771b54f02f6c87543ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6be05fccd8c48603ac9de19dca75ec2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Are-LLM-Agents-the-New-RPA-A-Comparative-Study-with-RPA-Across-Enterprise-Workflows"><a href="#Are-LLM-Agents-the-New-RPA-A-Comparative-Study-with-RPA-Across-Enterprise-Workflows" class="headerlink" title="Are LLM Agents the New RPA? A Comparative Study with RPA Across   Enterprise Workflows"></a>Are LLM Agents the New RPA? A Comparative Study with RPA Across   Enterprise Workflows</h2><p><strong>Authors:Petr PrÅ¯cha, Michaela MatouÅ¡kovÃ¡, Jan Strnad</strong></p>
<p>The emergence of large language models (LLMs) has introduced a new paradigm in automation: LLM agents or Agentic Automation with Computer Use (AACU). Unlike traditional Robotic Process Automation (RPA), which relies on rule-based workflows and scripting, AACU enables intelligent agents to perform tasks through natural language instructions and autonomous interaction with user interfaces. This study investigates whether AACU can serve as a viable alternative to RPA in enterprise workflow automation. We conducted controlled experiments across three standard RPA challenges data entry, monitoring, and document extraction comparing RPA (via UiPath) and AACU (via Anthropicâ€™s Computer Use Agent) in terms of speed, reliability, and development effort. Results indicate that RPA outperforms AACU in execution speed and reliability, particularly in repetitive, stable environments. However, AACU significantly reduces development time and adapts more flexibly to dynamic interfaces. While current AACU implementations are not yet production-ready, their promise in rapid prototyping and lightweight automation is evident. Future research should explore multi-agent orchestration, hybrid RPA-AACU architectures, and more robust evaluation across industries and platforms. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œä¸ºè‡ªåŠ¨åŒ–é¢†åŸŸå¼•å…¥äº†ä¸€ç§æ–°çš„èŒƒå¼ï¼šLLMä»£ç†æˆ–åŸºäºè®¡ç®—æœºä½¿ç”¨çš„ä»£ç†è‡ªåŠ¨åŒ–ï¼ˆAACUï¼‰ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æµç¨‹è‡ªåŠ¨åŒ–ï¼ˆRPAï¼‰å’Œè„šæœ¬ç¼–å†™ä¸åŒï¼ŒAACUä½¿å¾—æ™ºèƒ½ä»£ç†èƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»ä¸ç”¨æˆ·ç•Œé¢äº¤äº’æ‰§è¡Œä»»åŠ¡ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥AACUæ˜¯å¦å¯ä»¥ä½œä¸ºRPAåœ¨ä¼ä¸šå·¥ä½œæµç¨‹è‡ªåŠ¨åŒ–ä¸­çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªæ ‡å‡†RPAæŒ‘æˆ˜ï¼ˆæ•°æ®å½•å…¥ã€ç›‘æ§å’Œæ–‡æ¡£æå–ï¼‰ä¸Šè¿›è¡Œäº†å¯¹æ¯”å®éªŒï¼Œæ¯”è¾ƒäº†RPAï¼ˆé€šè¿‡UiPathï¼‰å’ŒAACUï¼ˆé€šè¿‡Anthropicçš„è®¡ç®—æœºä½¿ç”¨ä»£ç†ï¼‰åœ¨é€Ÿåº¦ã€å¯é æ€§å’Œå¼€å‘å·¥ä½œé‡æ–¹é¢çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨é‡å¤æ€§é«˜ã€ç¨³å®šæ€§å¼ºçš„ç¯å¢ƒä¸­ï¼ŒRPAåœ¨æ‰§è¡Œé€Ÿåº¦å’Œå¯é æ€§æ–¹é¢è¡¨ç°ä¼˜äºAACUã€‚ç„¶è€Œï¼ŒAACUåœ¨å¼€å‘æ—¶é—´ä¸Šå¤§å¤§å‡å°‘äº†å¹¶ä¸”å¯ä»¥æ›´çµæ´»åœ°é€‚åº”åŠ¨æ€ç•Œé¢ã€‚è™½ç„¶å½“å‰AACUçš„å®æ–½å°šæœªè¾¾åˆ°ç”Ÿäº§å°±ç»ªçŠ¶æ€ï¼Œä½†å…¶å¿«é€ŸåŸå‹è®¾è®¡å’Œè½»é‡çº§è‡ªåŠ¨åŒ–çš„å‰æ™¯å·²ç»å¾ˆæ˜æ˜¾ã€‚æœªæ¥çš„ç ”ç©¶åº”æ¢ç´¢å¤šä»£ç†ååŒå·¥ä½œã€æ··åˆRPA-AACUæ¶æ„ä»¥åŠåœ¨å„è¡Œä¸šå’Œå¹³å°ä¸Šçš„æ›´ç¨³å¥è¯„ä¼°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04198v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œå¼•é¢†äº†è‡ªåŠ¨åŒ–é¢†åŸŸçš„æ–°èŒƒå¼ï¼šLLMä»£ç†äººæˆ–è®¡ç®—æœºä½¿ç”¨ä»£ç†è‡ªåŠ¨åŒ–ï¼ˆAACUï¼‰ã€‚ä¸ä¼ ç»ŸåŸºäºè§„åˆ™å’Œè„šæœ¬çš„æœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–ï¼ˆRPAï¼‰ä¸åŒï¼ŒAACUå…è®¸æ™ºèƒ½ä»£ç†é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œè‡ªä¸»ä¸ç”¨æˆ·ç•Œé¢äº¤äº’æ‰§è¡Œä»»åŠ¡ã€‚æœ¬ç ”ç©¶æ¢è®¨AACUèƒ½å¦æˆä¸ºä¼ä¸šå·¥ä½œæµç¨‹è‡ªåŠ¨åŒ–çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡UiPathçš„RPAå’ŒAnthropicçš„è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„AACUåœ¨é€Ÿåº¦ã€å¯é æ€§å’Œå¼€å‘åŠªåŠ›æ–¹é¢çš„å¯¹æ¯”å®éªŒè¡¨æ˜ï¼ŒRPAåœ¨æ‰§è¡Œé€Ÿåº¦å’Œå¯é æ€§æ–¹é¢ä¼˜äºAACUï¼Œç‰¹åˆ«æ˜¯åœ¨é‡å¤ã€ç¨³å®šçš„ç¯å¢ƒä¸­ã€‚ç„¶è€Œï¼ŒAACUæ˜¾è‘—ç¼©çŸ­äº†å¼€å‘æ—¶é—´å¹¶æ›´çµæ´»åœ°é€‚åº”äº†åŠ¨æ€ç•Œé¢ã€‚è™½ç„¶å½“å‰çš„AACUå®ç°å°šæœªå‡†å¤‡å¥½æŠ•å…¥ç”Ÿäº§ï¼Œä½†å…¶åœ¨å¿«é€ŸåŸå‹è®¾è®¡å’Œè½»é‡çº§è‡ªåŠ¨åŒ–æ–¹é¢çš„æ½œåŠ›æ˜¯æ˜æ˜¾çš„ã€‚æœªæ¥çš„ç ”ç©¶åº”æ¢ç´¢å¤šæ™ºèƒ½ä½“ååŒã€RPA-AACUæ··åˆæ¶æ„ä»¥åŠåœ¨å„è¡Œä¸šå’Œå¹³å°ä¸Šçš„æ›´ç¨³å¥è¯„ä¼°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•é¢†äº†è‡ªåŠ¨åŒ–é¢†åŸŸçš„æ–°èŒƒå¼â€”â€”LLMä»£ç†äººæˆ–è®¡ç®—æœºä½¿ç”¨ä»£ç†è‡ªåŠ¨åŒ–ï¼ˆAACUï¼‰ã€‚</li>
<li>AACUé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œè‡ªä¸»ä¸ç”¨æˆ·ç•Œé¢äº¤äº’æ‰§è¡Œä»»åŠ¡ï¼Œä¸åŒäºä¼ ç»Ÿçš„åŸºäºè§„åˆ™å’Œè„šæœ¬çš„æœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–ï¼ˆRPAï¼‰ã€‚</li>
<li>å¯¹æ¯”å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPAåœ¨æ‰§è¡Œé€Ÿåº¦å’Œå¯é æ€§æ–¹é¢ä¼˜äºAACUï¼Œå°¤å…¶åœ¨é‡å¤ã€ç¨³å®šçš„ç¯å¢ƒä¸­ã€‚</li>
<li>AACUåœ¨ç¼©çŸ­å¼€å‘æ—¶é—´å’Œé€‚åº”åŠ¨æ€ç•Œé¢æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>å½“å‰AACUå°šæœªå‡†å¤‡å¥½æŠ•å…¥ç”Ÿäº§ç¯å¢ƒï¼Œä½†åœ¨å¿«é€ŸåŸå‹è®¾è®¡å’Œè½»é‡çº§è‡ªåŠ¨åŒ–æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚</li>
<li>æœªæ¥ç ”ç©¶åº”æ¢ç´¢å¤šæ™ºèƒ½ä½“ååŒã€RPAä¸AACUçš„æ··åˆæ¶æ„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04198">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2205a8dd09ad32272c83e9ae534dece0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ffe69112090c051b98400e646ac84d83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64f4a64ae8568061061666bb06157d17.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MAGneT-Coordinated-Multi-Agent-Generation-of-Synthetic-Multi-Turn-Mental-Health-Counseling-Sessions"><a href="#MAGneT-Coordinated-Multi-Agent-Generation-of-Synthetic-Multi-Turn-Mental-Health-Counseling-Sessions" class="headerlink" title="MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn   Mental Health Counseling Sessions"></a>MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn   Mental Health Counseling Sessions</h2><p><strong>Authors:Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych</strong></p>
<p>The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public. </p>
<blockquote>
<p>ä¸æ–­å¢é•¿çš„å¿ƒç†å’¨è¯¢éœ€æ±‚å¼ºè°ƒäº†å¯¹ä½¿ç”¨é«˜è´¨é‡ã€ç¬¦åˆéšç§è¦æ±‚çš„æ•°æ®å¾®è°ƒå¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿…è¦æ€§ï¼Œä½†è¿™æ ·çš„æ•°æ®ä»ç„¶å¾ˆç¨€ç¼ºã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†MAGneTï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºåˆæˆå¿ƒç†å’¨è¯¢ä¼šè¯ç”Ÿæˆï¼Œå®ƒå°†å’¨è¯¢å¸ˆå“åº”ç”Ÿæˆåˆ†è§£ä¸ºç”±ä¸“ä¸šLLMæ™ºèƒ½ä½“å¤„ç†çš„åè°ƒå­ä»»åŠ¡ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ¨¡æ‹Ÿä¸€ç§å…³é”®çš„å¿ƒç†æŠ€æœ¯ã€‚ä¸å…ˆå‰çš„å•ä¸€æ™ºèƒ½ä½“æ–¹æ³•ä¸åŒï¼ŒMAGneTèƒ½æ›´å¥½åœ°æ•æ‰çœŸå®å’¨è¯¢çš„ç»“æ„å’Œç»†å¾®å·®åˆ«ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶æ¥è§£å†³å…ˆå‰è¯„ä¼°åè®®ä¸­çš„ä¸ä¸€è‡´é—®é¢˜ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å¤šç§è‡ªåŠ¨å’Œä¸“å®¶æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†å…ˆå‰å·¥ä½œä¸­çš„å’¨è¯¢æ–¹é¢çš„ä¸“å®¶è¯„ä¼°ä»å››ä¸ªæ–¹é¢æ‰©å±•åˆ°ä¹ä¸ªæ–¹é¢ï¼Œä»è€Œèƒ½å¤Ÿå¯¹æ•°æ®è´¨é‡è¿›è¡Œæ›´å…¨é¢å’Œç¨³å¥çš„è¯„ä¼°ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç”Ÿæˆçš„å’¨è¯¢ä¼šè¯çš„è´¨é‡ã€å¤šæ ·æ€§å’Œæ²»ç–—å¯¹é½æ–¹é¢ï¼ŒMAGneTæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨è®¤çŸ¥ç–—æ³•é‡è¡¨ï¼ˆCTRSï¼‰ä¸Šå¹³å‡æé«˜äº†ä¸€èˆ¬å’¨è¯¢æŠ€èƒ½3.2%ï¼Œè®¤çŸ¥è¡Œä¸ºç–—æ³•ç‰¹å®šæŠ€èƒ½4.3%ã€‚å…³é”®çš„æ˜¯ï¼Œä¸“å®¶å¹³å‡åœ¨æ‰€æœ‰æ–¹é¢ä¸­ï¼Œæœ‰77.2%çš„æƒ…å†µæ›´å–œæ¬¢MAGneTç”Ÿæˆçš„ä¼šè¯ã€‚æ­¤å¤–ï¼Œä½¿ç”¨MAGneTç”Ÿæˆçš„ä¼šè¯å¾®è°ƒå¼€æºæ¨¡å‹è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œåœ¨CTRSä¸Šå¹³å‡æ¯”ä¸€èˆ¬å’¨è¯¢æŠ€èƒ½æé«˜6.3%ï¼ŒCBTç‰¹å®šæŠ€èƒ½æé«˜7.3%ã€‚æˆ‘ä»¬è¿˜å…¬å¼€äº†æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04183v1">PDF</a> 25 pages, 29 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>é‡‡ç”¨å¤šä»£ç†æ¡†æ¶MAGneTåˆæˆå¿ƒç†å’¨è¯¢ä¼šè¯ç”Ÿæˆï¼Œä»¥åº”å¯¹æ—¥ç›Šå¢é•¿çš„å¿ƒç†å’¨è¯¢éœ€æ±‚åŠå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¼˜åŒ–æŒ‘æˆ˜ã€‚MAGneTåˆ©ç”¨ä¸“é¡¹LLMä»£ç†å¤„ç†åè°ƒå­ä»»åŠ¡ï¼Œæ›´å¥½åœ°æ•æ‰çœŸå®å’¨è¯¢çš„ç»“æ„å’Œç»†å¾®å·®åˆ«ã€‚æ­¤å¤–ï¼Œæå‡ºç»Ÿä¸€è¯„ä¼°æ¡†æ¶ï¼Œæ‰©å±•ä¸“å®¶è¯„ä¼°æ–¹é¢ï¼Œå®ç°æ›´å…¨é¢çš„æ•°æ®è´¨é‡è¯„ä¼°ã€‚ç»éªŒç»“æœè¡¨æ˜ï¼ŒMAGneTåœ¨ä¼šè¯è´¨é‡ã€å¤šæ ·æ€§å’Œæ²»ç–—ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹³å‡æé«˜ä¸€èˆ¬å’¨è¯¢æŠ€èƒ½3.2%ï¼Œé’ˆå¯¹è®¤çŸ¥ç–—æ³•çš„æŠ€èƒ½æé«˜4.3%ã€‚ä¸“å®¶æ›´å–œæ¬¢MAGneTç”Ÿæˆçš„ä¼šè¯ã€‚æ­¤å¤–ï¼Œä½¿ç”¨MAGneTç”Ÿæˆçš„ä¼šè¯å¯¹å¼€æºæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¡¨ç°æ›´ä½³ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¿ƒç†å’¨è¯¢éœ€æ±‚å¢é•¿ï¼Œéœ€è¦è°ƒæ•´å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥åº”å¯¹ã€‚</li>
<li>MAGneTå¤šä»£ç†æ¡†æ¶ç”¨äºåˆæˆå¿ƒç†å’¨è¯¢ä¼šè¯ç”Ÿæˆï¼Œæ•æ‰çœŸå®å’¨è¯¢çš„ç»†å¾®å·®åˆ«ã€‚</li>
<li>æå‡ºç»Ÿä¸€è¯„ä¼°æ¡†æ¶ï¼Œæ•´åˆå¤šç§è‡ªåŠ¨å’Œä¸“å®¶è¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>æ‰©å¤§ä¸“å®¶è¯„ä¼°æ–¹é¢ï¼Œæ›´å…¨é¢è¯„ä¼°æ•°æ®è´¨é‡ã€‚</li>
<li>MAGneTåœ¨ä¼šè¯è´¨é‡ã€å¤šæ ·æ€§å’Œæ²»ç–—ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>ä¸“å®¶åå¥½MAGneTç”Ÿæˆçš„ä¼šè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04183">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3b5a49c86e5a6ecc5b9b2f6901c6210f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c105ab50ee50439a15cdbae0a1c48a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a856ea83da8d9d573cdb0fe9787d20d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5dd910476efb23e0d9705fc1a24f5052.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86de154d03ca4323749f62825050507a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f113ea0a939db2b96d7df5d5cec9f4fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-414638e514e34dc1c99ed3298530254b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00fc98b6b9d644564e8ec4ad07f5695f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="TAGAL-Tabular-Data-Generation-using-Agentic-LLM-Methods"><a href="#TAGAL-Tabular-Data-Generation-using-Agentic-LLM-Methods" class="headerlink" title="TAGAL: Tabular Data Generation using Agentic LLM Methods"></a>TAGAL: Tabular Data Generation using Agentic LLM Methods</h2><p><strong>Authors:BenoÃ®t Ronval, Pierre Dupont, Siegfried Nijssen</strong></p>
<p>The generation of data is a common approach to improve the performance of machine learning tasks, among which is the training of models for classification. In this paper, we present TAGAL, a collection of methods able to generate synthetic tabular data using an agentic workflow. The methods leverage Large Language Models (LLMs) for an automatic and iterative process that uses feedback to improve the generated data without any further LLM training. The use of LLMs also allows for the addition of external knowledge in the generation process. We evaluate TAGAL across diverse datasets and different aspects of quality for the generated data. We look at the utility of downstream ML models, both by training classifiers on synthetic data only and by combining real and synthetic data. Moreover, we compare the similarities between the real and the generated data. We show that TAGAL is able to perform on par with state-of-the-art approaches that require LLM training and generally outperforms other training-free approaches. These findings highlight the potential of agentic workflow and open new directions for LLM-based data generation methods. </p>
<blockquote>
<p>æ•°æ®çš„ç”Ÿæˆæ˜¯æé«˜æœºå™¨å­¦ä¹ ä»»åŠ¡æ€§èƒ½çš„ä¸€ç§å¸¸è§æ–¹æ³•ï¼Œå…¶ä¸­åŒ…æ‹¬åˆ†ç±»æ¨¡å‹çš„è®­ç»ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†TAGALï¼Œè¿™æ˜¯ä¸€ç»„èƒ½å¤Ÿåˆ©ç”¨ä»£ç†å·¥ä½œæµç¨‹ç”Ÿæˆåˆæˆè¡¨æ ¼æ•°æ®çš„æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè‡ªåŠ¨è¿­ä»£è¿‡ç¨‹ï¼Œä½¿ç”¨åé¦ˆæ¥æ”¹è¿›ç”Ÿæˆçš„æ•°æ®ï¼Œè€Œæ— éœ€è¿›ä¸€æ­¥çš„LLMè®­ç»ƒã€‚LLMçš„ä½¿ç”¨è¿˜å…è®¸åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ·»åŠ å¤–éƒ¨çŸ¥è¯†ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šè¯„ä¼°TAGALï¼Œå¹¶å¯¹ç”Ÿæˆæ•°æ®çš„è´¨é‡è¿›è¡Œå¤šæ–¹é¢çš„è€ƒé‡ã€‚æˆ‘ä»¬å…³æ³¨ä¸‹æ¸¸æœºå™¨å­¦ä¹ æ¨¡å‹çš„ä½¿ç”¨æƒ…å†µï¼Œæ—¢é€šè¿‡åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒåˆ†ç±»å™¨ï¼Œä¹Ÿé€šè¿‡ç»“åˆçœŸå®å’Œåˆæˆæ•°æ®æ¥å®ç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¯”è¾ƒäº†çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚æˆ‘ä»¬å±•ç¤ºTAGALèƒ½å¤Ÿä¸å›½å®¶æœ€æ–°æ–¹æ³•ç›¸åŒ¹é…ï¼Œè¦æ±‚LLMè¿›è¡Œè®­ç»ƒå¹¶ä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºå…¶ä»–ä¸éœ€è¦è®­ç»ƒçš„æ–¹æ³•ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†ä»£ç†å·¥ä½œæµç¨‹çš„æ½œåŠ›ï¼Œå¹¶ä¸ºåŸºäºLLMçš„æ•°æ®ç”Ÿæˆæ–¹æ³•å¼€å¯äº†æ–°çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04152v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä½¿ç”¨ä»£ç†å·¥ä½œæµç¨‹çš„TAGALæ–¹æ³•ï¼Œç”¨äºç”Ÿæˆåˆæˆè¡¨æ ¼æ•°æ®ä»¥æé«˜æœºå™¨å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè‡ªåŠ¨è¿­ä»£è¿‡ç¨‹ï¼Œä½¿ç”¨åé¦ˆæ”¹è¿›ç”Ÿæˆçš„æ•°æ®ï¼Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒTAGALåœ¨ä¸åŒæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œåˆ†ç±»å™¨è®­ç»ƒæˆ–ä¸çœŸå®æ•°æ®ç»“åˆä½¿ç”¨æ—¶å‡è¡¨ç°è‰¯å¥½ã€‚ä¸éœ€è¦å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒçš„æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒTAGALèƒ½å¤Ÿä¸ä¹‹ç›¸å½“ç”šè‡³åœ¨æŸäº›æ–¹é¢è¡¨ç°æ›´å¥½ï¼Œè¿™çªæ˜¾äº†ä»£ç†å·¥ä½œæµç¨‹çš„æ½œåŠ›å¹¶ä¸ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®ç”Ÿæˆæ–¹æ³•æä¾›äº†æ–°çš„æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TAGALæ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆæˆè¡¨æ ¼æ•°æ®çš„æ–¹æ³•ï¼Œé‡‡ç”¨ä»£ç†å·¥ä½œæµç¨‹ã€‚</li>
<li>TAGALé€šè¿‡è‡ªåŠ¨è¿­ä»£è¿‡ç¨‹ä½¿ç”¨åé¦ˆæ”¹è¿›ç”Ÿæˆçš„æ•°æ®ï¼Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¯„ä¼°è¡¨æ˜ï¼ŒTAGALåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>TAGALåœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œåˆ†ç±»å™¨è®­ç»ƒæ—¶è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¸çœŸå®æ•°æ®ç»“åˆä½¿ç”¨æ—¶æ•ˆæœæ›´ä½³ã€‚</li>
<li>TAGALä¸éœ€è¦å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒçš„æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“ï¼Œåœ¨æŸäº›æ–¹é¢ç”šè‡³è¡¨ç°æ›´å¥½ã€‚</li>
<li>TAGALçš„æ½œåŠ›åœ¨äºå…¶ä»£ç†å·¥ä½œæµç¨‹çš„åº”ç”¨ï¼Œä¸ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®ç”Ÿæˆæ–¹æ³•æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04152">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f9a9999ccbd38b44eb2eb5eef4eedb88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d33457f55a6b451507bc281cd1a1234c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Towards-Stable-and-Personalised-Profiles-for-Lexical-Alignment-in-Spoken-Human-Agent-Dialogue"><a href="#Towards-Stable-and-Personalised-Profiles-for-Lexical-Alignment-in-Spoken-Human-Agent-Dialogue" class="headerlink" title="Towards Stable and Personalised Profiles for Lexical Alignment in Spoken   Human-Agent Dialogue"></a>Towards Stable and Personalised Profiles for Lexical Alignment in Spoken   Human-Agent Dialogue</h2><p><strong>Authors:Keara Schaaij, Roel Boumans, Tibor Bosse, Iris Hendrickx</strong></p>
<p>Lexical alignment, where speakers start to use similar words across conversation, is known to contribute to successful communication. However, its implementation in conversational agents remains underexplored, particularly considering the recent advancements in large language models (LLMs). As a first step towards enabling lexical alignment in human-agent dialogue, this study draws on strategies for personalising conversational agents and investigates the construction of stable, personalised lexical profiles as a basis for lexical alignment. Specifically, we varied the amounts of transcribed spoken data used for construction as well as the number of items included in the profiles per part-of-speech (POS) category and evaluated profile performance across time using recall, coverage, and cosine similarity metrics. It was shown that smaller and more compact profiles, created after 10 min of transcribed speech containing 5 items for adjectives, 5 items for conjunctions, and 10 items for adverbs, nouns, pronouns, and verbs each, offered the best balance in both performance and data efficiency. In conclusion, this study offers practical insights into constructing stable, personalised lexical profiles, taking into account minimal data requirements, serving as a foundational step toward lexical alignment strategies in conversational agents. </p>
<blockquote>
<p>è¯æ±‡å¯¹é½ï¼ˆlexical alignmentï¼‰æ˜¯æŒ‡å¯¹è¯è¿‡ç¨‹ä¸­è¯´è¯è€…å¼€å§‹ä½¿ç”¨ç›¸ä¼¼çš„è¯æ±‡ï¼Œè¿™å·²è¢«è¯æ˜å¯¹æˆåŠŸçš„æ²Ÿé€šæœ‰è´¡çŒ®ã€‚ç„¶è€Œï¼Œå…¶åœ¨å¯¹è¯ä»£ç†ä¸­çš„å®ç°ä»ç„¶è¢«è¾ƒå°‘æ¢ç´¢ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ€æ–°è¿›å±•ã€‚ä½œä¸ºå®ç°äººæœºå¯¹è¯ä¸­è¯æ±‡å¯¹é½çš„ç¬¬ä¸€æ­¥ï¼Œæœ¬ç ”ç©¶å€Ÿé‰´äº†ä¸ªæ€§åŒ–å¯¹è¯ä»£ç†çš„ç­–ç•¥ï¼Œå¹¶ç ”ç©¶æ„å»ºç¨³å®šã€ä¸ªæ€§åŒ–çš„è¯æ±‡æ¡£æ¡ˆä½œä¸ºè¯æ±‡å¯¹é½çš„åŸºç¡€ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å˜åŒ–äº†ç”¨äºæ„å»ºæ¡£æ¡ˆçš„æœ‰å£°è¯­è¨€æ•°æ®é‡ä»¥åŠæ¯ä¸ªè¯æ€§ç±»åˆ«ä¸­æ¡£æ¡ˆæ‰€åŒ…å«çš„é¡¹ç›®æ•°é‡ï¼Œå¹¶é€šè¿‡å›å¿†ã€è¦†ç›–ç‡å’Œä½™å¼¦ç›¸ä¼¼æ€§æŒ‡æ ‡æ¥è¯„ä¼°æ¡£æ¡ˆéšæ—¶é—´çš„è¡¨ç°ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡ååˆ†é’Ÿçš„è¯­éŸ³è½¬æ–‡æœ¬ååˆ›å»ºè¾ƒå°ä¸”æ›´ç´§å‡‘çš„æ¡£æ¡ˆè¡¨ç°å‡ºæœ€ä½³çš„æ€§èƒ½å’Œæ•ˆç‡å¹³è¡¡ï¼Œè¯¥æ¡£æ¡ˆåŒ…å«å½¢å®¹è¯5é¡¹ã€è¿è¯5é¡¹ï¼Œä»¥åŠå‰¯è¯ã€åè¯ã€ä»£è¯å’ŒåŠ¨è¯å„10é¡¹ã€‚æ€»ä¹‹ï¼Œæœ¬ç ”ç©¶æä¾›äº†æ„å»ºç¨³å®šã€ä¸ªæ€§åŒ–è¯æ±‡æ¡£æ¡ˆçš„å®ç”¨è§è§£ï¼Œè€ƒè™‘äº†æœ€å°çš„æ•°æ®éœ€æ±‚ï¼Œä½œä¸ºå¯¹è¯ä»£ç†ä¸­å®ç°è¯æ±‡å¯¹é½ç­–ç•¥çš„åŸºç¡€æ­¥éª¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04104v1">PDF</a> Accepted for TSD 2025</p>
<p><strong>Summary</strong><br>     æ­¤ç ”ç©¶æ¢ç´¢äº†è¯æ±‡å¯¹é½åœ¨å¯¹è¯äº¤æµä¸­çš„é‡è¦æ€§ï¼Œå¹¶å°è¯•åœ¨å¯¹è¯ä»£ç†ä¸­å®ç°è¯æ±‡å¯¹é½ã€‚ç ”ç©¶é€šè¿‡ä¸ªæ€§åŒ–å¯¹è¯ä»£ç†çš„ç­–ç•¥ï¼Œæ„å»ºäº†ç¨³å®šã€ä¸ªæ€§åŒ–çš„è¯æ±‡æ¦‚å†µï¼Œä½œä¸ºè¯æ±‡å¯¹é½çš„åŸºç¡€ã€‚æœ€ä½³æ¦‚å†µè¡¨ç°æ˜¯åœ¨10åˆ†é’Ÿçš„è½¬å½•è¯­éŸ³ä¸­ï¼Œå½¢å®¹è¯ã€è¿è¯å„é€‰5é¡¹ï¼Œå‰¯è¯ã€åè¯ã€ä»£è¯å’ŒåŠ¨è¯å„é€‰10é¡¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯æ±‡å¯¹é½åœ¨æˆåŠŸäº¤æµä¸­çš„é‡è¦æ€§ã€‚</li>
<li>å¯¹è¯ä»£ç†ä¸­å®ç°è¯æ±‡å¯¹é½çš„ç­–ç•¥å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>ä¸ªæ€§åŒ–å¯¹è¯ä»£ç†çš„è¯æ±‡æ¦‚å†µæ„å»ºæ˜¯è¯æ±‡å¯¹é½çš„åŸºç¡€ã€‚</li>
<li>è¯æ±‡æ¦‚å†µçš„æ„å»ºéœ€è¦è€ƒè™‘æ•°æ®çš„æœ€å°éœ€æ±‚ã€‚</li>
<li>æœ€ä½³çš„è¯æ±‡æ¦‚å†µè¡¨ç°æ˜¯åœ¨ç‰¹å®šçš„æ•°æ®é‡å’Œé€‰æ‹©ä¸‹è¾¾æˆã€‚</li>
<li>ç ”ç©¶ä½¿ç”¨äº†å›å¿†ã€è¦†ç›–å’Œä½™å¼¦ç›¸ä¼¼åº¦ç­‰æŒ‡æ ‡æ¥è¯„ä¼°è¯æ±‡æ¦‚å†µçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04104">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d38b412d2625044de8e815a535310fd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20c6af2761883fb2c4ff9caf4ee8af85.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MobileRAG-Enhancing-Mobile-Agent-with-Retrieval-Augmented-Generation"><a href="#MobileRAG-Enhancing-Mobile-Agent-with-Retrieval-Augmented-Generation" class="headerlink" title="MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation"></a>MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation</h2><p><strong>Authors:Gowen Loo, Chang Liu, Qinghong Yin, Xiang Chen, Jiawei Chen, Jingyuan Zhang, Yu Tian</strong></p>
<p>Smartphones have become indispensable in peopleâ€™s daily lives, permeating nearly every aspect of modern society. With the continuous advancement of large language models (LLMs), numerous LLM-based mobile agents have emerged. These agents are capable of accurately parsing diverse user queries and automatically assisting users in completing complex or repetitive operations. However, current agents 1) heavily rely on the comprehension ability of LLMs, which can lead to errors caused by misoperations or omitted steps during tasks, 2) lack interaction with the external environment, often terminating tasks when an app cannot fulfill user queries, and 3) lack memory capabilities, requiring each instruction to reconstruct the interface and being unable to learn from and correct previous mistakes. To alleviate the above issues, we propose MobileRAG, a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG), which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly and accurately identify user queries and accomplish complex and long-sequence mobile tasks. Additionally, to more comprehensively assess the performance of MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark characterized by numerous complex, real-world mobile tasks that require external knowledge assistance. Extensive experimental results on MobileRAG-Eval demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving 10.3% improvement over state-of-the-art methods with fewer operational steps. Our code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv">https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv</a> </p>
<blockquote>
<p>æ™ºèƒ½æ‰‹æœºåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ä¸å¯æˆ–ç¼ºï¼Œå‡ ä¹æ¸—é€åˆ°ç°ä»£ç¤¾ä¼šçš„å„ä¸ªæ–¹é¢ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸æ–­å‘å±•ï¼Œå‡ºç°äº†è®¸å¤šåŸºäºLLMçš„ç§»åŠ¨ä»£ç†ã€‚è¿™äº›ä»£ç†èƒ½å¤Ÿå‡†ç¡®è§£æå„ç§ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶è‡ªåŠ¨ååŠ©ç”¨æˆ·å®Œæˆå¤æ‚æˆ–é‡å¤çš„æ“ä½œã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š1ï¼‰ä¸¥é‡ä¾èµ–äºLLMçš„ç†è§£èƒ½åŠ›ï¼Œå¯èƒ½å¯¼è‡´ä»»åŠ¡æ“ä½œè¿‡ç¨‹ä¸­çš„é”™è¯¯æˆ–é—æ¼æ­¥éª¤ï¼›2ï¼‰ç¼ºä¹ä¸å¤–éƒ¨ç¯å¢ƒçš„äº¤äº’ï¼Œå½“åº”ç”¨ç¨‹åºæ— æ³•å®Œæˆç”¨æˆ·æŸ¥è¯¢æ—¶ï¼Œç»å¸¸ç»ˆæ­¢ä»»åŠ¡ï¼›3ï¼‰ç¼ºä¹è®°å¿†èƒ½åŠ›ï¼Œéœ€è¦æ¯æ¬¡æŒ‡ä»¤é‡å»ºç•Œé¢ï¼Œå¹¶ä¸”ä¸èƒ½ä»è¿‡å»çš„é”™è¯¯ä¸­å­¦ä¹ å¹¶çº æ­£ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†é€šè¿‡å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ç§»åŠ¨ä»£ç†æ¡†æ¶MobileRAGï¼ŒåŒ…æ‹¬InterRAGã€LocalRAGå’ŒMemRAGã€‚å®ƒåˆ©ç”¨RAGæ›´å¿«åœ°å‡†ç¡®è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢å¹¶å®Œæˆå¤æ‚ä¸”é•¿åºåˆ—çš„ç§»åŠ¨ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ›´å…¨é¢åœ°è¯„ä¼°MobileRAGçš„æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•MobileRAG-Evalï¼Œè¯¥åŸºå‡†æµ‹è¯•çš„ç‰¹ç‚¹æ˜¯åŒ…å«è®¸å¤šéœ€è¦å¤–éƒ¨çŸ¥è¯†æ”¯æŒçš„å¤æ‚ç°å®ä¸–ç•Œç§»åŠ¨ä»»åŠ¡ã€‚åœ¨MobileRAG-Evalä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒMobileRAGå¯ä»¥è½»æ¾å¤„ç†ç°å®ä¸–ç•Œçš„ç§»åŠ¨ä»»åŠ¡ï¼Œæ¯”æœ€æ–°æŠ€æœ¯æ–¹æ³•å°‘æ“ä½œæ­¥éª¤çš„æƒ…å†µä¸‹å®ç°äº†10.3%çš„æ”¹è¿›ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv">https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03891v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€æ™ºèƒ½æ‰‹æœºåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„æ™®åŠï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç§»åŠ¨æ™ºèƒ½ä»£ç†æ—¥ç›Šå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“å‰ä»£ç†å­˜åœ¨ä¾èµ–æ€§å¼ºã€ç¼ºä¹äº’åŠ¨ä¸è®°å¿†èƒ½åŠ›çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†MobileRAGæ¡†æ¶ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯æé«˜è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢å’Œå®Œæˆä»»åŠ¡çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†MobileRAG-Evalè¯„ä¼°æ ‡å‡†ï¼Œä»¥å…¨é¢è¯„ä¼°MobileRAGæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMobileRAGèƒ½å¤Ÿè½»æ¾åº”å¯¹ç°å®ç”Ÿæ´»ä¸­çš„å¤æ‚ä»»åŠ¡ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰ç€æ˜¾è‘—æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½æ‰‹æœºå·²æ·±å…¥äººä»¬æ—¥å¸¸ç”Ÿæ´»ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç§»åŠ¨ä»£ç†å¤‡å—å…³æ³¨ã€‚</li>
<li>å½“å‰ç§»åŠ¨ä»£ç†å­˜åœ¨ä¾èµ–æ€§å¼ºã€ç¼ºä¹ä¸å¤–éƒ¨ç¯å¢ƒäº’åŠ¨åŠè®°å¿†èƒ½åŠ›çš„é—®é¢˜ã€‚</li>
<li>MobileRAGæ¡†æ¶é€šè¿‡å¼•å…¥æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œæé«˜ç§»åŠ¨ä»£ç†çš„è¯†åˆ«ç”¨æˆ·æŸ¥è¯¢å’Œå®Œæˆä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>MobileRAG-Evalè¯„ä¼°æ ‡å‡†çš„å¼•å…¥ï¼Œèƒ½æ›´å…¨é¢åœ°è¯„ä¼°MobileRAGæ€§èƒ½ã€‚</li>
<li>MobileRAGæ¡†æ¶åœ¨åº”å¯¹ç°å®ç”Ÿæ´»ä¸­çš„å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>MobileRAGç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰ç€æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿåœ¨æ›´å°‘æ“ä½œæ­¥éª¤ä¸‹å®Œæˆä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03891">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-863e8e52c478888240380d04521657a4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-efbbb9d66b57e27a1a252ab68cfe4200.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc1756b3f4c4e380014cc583adcd7cbb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-018253101856bd7242703239ba36fb85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad3f127dd3b4281e4869fd6715805d9e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9b233774b06a8c995d890e41288cd8dd.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Learning-to-Deliberate-Meta-policy-Collaboration-for-Agentic-LLMs-with-Multi-agent-Reinforcement-Learning"><a href="#Learning-to-Deliberate-Meta-policy-Collaboration-for-Agentic-LLMs-with-Multi-agent-Reinforcement-Learning" class="headerlink" title="Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with   Multi-agent Reinforcement Learning"></a>Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with   Multi-agent Reinforcement Learning</h2><p><strong>Authors:Wei Yang, Jesse Thomason</strong></p>
<p>Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agentsâ€™ internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†æ–¹é¢å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†å…¶æœ‰æ•ˆæ€§é€šå¸¸å—é™äºå›ºå®šçš„åä½œåè®®ã€‚è¿™äº›æ¡†æ¶é€šå¸¸ä¾§é‡äºå®è§‚å±‚é¢çš„åè°ƒï¼Œè€Œå¿½è§†äº†æ™ºèƒ½ä½“çš„å†…éƒ¨å†³ç­–èƒ½åŠ›ã€‚è¿™ä¸€å…³é”®çš„å…ƒè®¤çŸ¥ç›²ç‚¹å°†æ™ºèƒ½ä½“è§†ä¸ºè¢«åŠ¨çš„æ‰§è¡Œè€…ï¼Œæ— æ³•æ ¹æ®ä¸ç¡®å®šæ€§æˆ–ä¿¡å¿ƒç­‰å†…éƒ¨è®¤çŸ¥çŠ¶æ€æ¥é€‚åº”ç­–ç•¥ã€‚æˆ‘ä»¬å¼•å…¥äº†å…ƒç­–ç•¥å†³ç­–æ¡†æ¶ï¼ˆMPDFï¼‰ï¼Œåœ¨è¯¥æ¡†æ¶ä¸­ï¼Œæ™ºèƒ½ä½“å­¦ä¹ ä¸€ç³»åˆ—é«˜å±‚æ¬¡å…ƒè®¤çŸ¥åŠ¨ä½œä¸Šçš„åˆ†æ•£ç­–ç•¥ï¼šåšæŒã€å®Œå–„ã€æ”¾å¼ƒã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿç­–ç•¥æ¢¯åº¦åœ¨æ­¤ç¯å¢ƒä¸­çš„ä¸ç¨³å®šæ€§ï¼Œæˆ‘ä»¬å¼€å‘äº†SoftRankPOï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚SoftRankPOé€šè¿‡åŸºäºå¥–åŠ±æ’åå’Œé€šè¿‡å¹³æ»‘æ­£æ€åˆ†ä½æ•°æ˜ å°„çš„ä¼˜åŠ¿æ¥å¡‘é€ ä¼˜åŠ¿ï¼Œä»è€Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œä½¿å­¦ä¹ è¿‡ç¨‹å¯¹å¥–åŠ±æ–¹å·®å…·æœ‰é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œä¸å…­ç§æœ€å…ˆè¿›çš„å¯å‘å¼å’Œå­¦ä¹ å‹å¤šæ™ºèƒ½ä½“æ¨ç†ç®—æ³•ç›¸æ¯”ï¼Œä½¿ç”¨SoftRankPOçš„MPDFåœ¨äº”ä¸ªæ•°å­¦å’Œé€šç”¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šå¹³å‡å‡†ç¡®ç‡æé«˜äº†4-5%ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿå­¦ä¹ è‡ªé€‚åº”å…ƒè®¤çŸ¥ç­–ç•¥æä¾›äº†èŒƒä¾‹ï¼Œå°†é‡ç‚¹ä»è®¾è®¡å›ºå®šåè®®è½¬å‘å­¦ä¹ åŠ¨æ€å†³ç­–ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03817v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç»¼åˆç ”ç©¶å±•ç°äº†å¤æ‚æ¨ç†çš„å·¨å¤§æ½œåŠ›ï¼Œä½†ç”±äºé‡‡ç”¨å›ºå®šåˆä½œåè®®çš„åä½œæ¨¡å¼è€Œå—é™åˆ¶ã€‚æœ¬æ–‡ä¸»è¦å¼•å…¥å…ƒç­–ç•¥åå•†æ¡†æ¶ï¼ˆMPDFï¼‰ï¼Œåœ¨æ­¤æ¡†æ¶ä¸­ï¼Œæ™ºèƒ½ä½“å¯ä»¥å­¦ä¹ åœ¨ç‰¹å®šç¯å¢ƒä¸‹çš„ä¸€ç»„åˆ†æ•£å†³ç­–è§„åˆ™ã€‚åŒæ—¶æå‡ºä¸€ç§æ–°å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•SoftRankPOï¼Œé€šè¿‡å¹³æ»‘æ­£å¸¸åˆ†å¸ƒæ’åæ¥å¡‘é€ ä¼˜åŠ¿ï¼Œå…‹æœä¼ ç»Ÿæ”¿ç­–æ¢¯åº¦çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒMPDFä¸SoftRankPOç›¸è¾ƒäºå…­ç§æœ€æ–°å¯å‘å¼ä¸å­¦ä¹ å¼å¤šæ™ºèƒ½ä½“æ¨ç†ç®—æ³•åœ¨äº”ç±»æ•°å­¦å’Œä¸€èˆ¬æ¨ç†æµ‹è¯•æ–¹é¢è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„ç²¾å‡†æ€§ï¼Œå±•ç¤ºäº†å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹è‡ªé€‚åº”å…ƒè®¤çŸ¥ç­–ç•¥å­¦ä¹ çš„å¯èƒ½æ€§ã€‚æœ¬æ–‡çš„å·¥ä½œä»è®¾è®¡å›ºå®šåè®®è½¬å‘å­¦ä¹ åŠ¨æ€å†³ç­–ç­–ç•¥ï¼Œä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æœªæ¥å‘å±•å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤æ‚æ¨ç†æ–¹é¢å±•ç°æ½œåŠ›ï¼Œå—é™äºå›ºå®šåˆä½œåè®®çš„åä½œæ¨¡å¼ã€‚</li>
<li>å¼•å…¥å…ƒç­–ç•¥åå•†æ¡†æ¶ï¼ˆMPDFï¼‰ï¼Œæ™ºèƒ½ä½“å¯å­¦ä¹ åˆ†æ•£å†³ç­–è§„åˆ™ä»¥é€‚åº”ç‰¹å®šç¯å¢ƒã€‚</li>
<li>æå‡ºæ–°å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•SoftRankPOï¼Œé€šè¿‡å¹³æ»‘æ­£å¸¸åˆ†å¸ƒæ’åå¡‘é€ ä¼˜åŠ¿ï¼Œå…‹æœä¼ ç»Ÿæ”¿ç­–æ¢¯åº¦çš„ä¸ç¨³å®šæ€§é—®é¢˜ã€‚</li>
<li>MPDFä¸SoftRankPOç›¸è¾ƒäºå…¶ä»–ç®—æ³•åœ¨äº”ç±»æ•°å­¦å’Œä¸€èˆ¬æ¨ç†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03817">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2ef2f24985868f458a46a250de8df2d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df0578129bf9f60fda65df6d313c64f9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-abd2e3a77b11ba36c95e8f2dfff4a318.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a81d6164779b08a20b42147a05e7893d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1f4b61384dbee875b8d30537c96a4e9.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="QuantV2X-A-Fully-Quantized-Multi-Agent-System-for-Cooperative-Perception"><a href="#QuantV2X-A-Fully-Quantized-Multi-Agent-System-for-Cooperative-Perception" class="headerlink" title="QuantV2X: A Fully Quantized Multi-Agent System for Cooperative   Perception"></a>QuantV2X: A Fully Quantized Multi-Agent System for Cooperative   Perception</h2><p><strong>Authors:Seth Z. Zhao, Huizhi Zhang, Zhaowei Li, Juntong Peng, Anthony Chui, Zewei Zhou, Zonglin Meng, Hao Xiang, Zhiyu Huang, Fujia Wang, Ran Tian, Chenfeng Xu, Bolei Zhou, Jiaqi Ma</strong></p>
<p>Cooperative perception through Vehicle-to-Everything (V2X) communication offers significant potential for enhancing vehicle perception by mitigating occlusions and expanding the field of view. However, past research has predominantly focused on improving accuracy metrics without addressing the crucial system-level considerations of efficiency, latency, and real-world deployability. Noticeably, most existing systems rely on full-precision models, which incur high computational and transmission costs, making them impractical for real-time operation in resource-constrained environments. In this paper, we introduce \textbf{QuantV2X}, the first fully quantized multi-agent system designed specifically for efficient and scalable deployment of multi-modal, multi-agent V2X cooperative perception. QuantV2X introduces a unified end-to-end quantization strategy across both neural network models and transmitted message representations that simultaneously reduces computational load and transmission bandwidth. Remarkably, despite operating under low-bit constraints, QuantV2X achieves accuracy comparable to full-precision systems. More importantly, when evaluated under deployment-oriented metrics, QuantV2X reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in mAP30 over full-precision baselines. Furthermore, QuantV2X scales more effectively, enabling larger and more capable models to fit within strict memory budgets. These results highlight the viability of a fully quantized multi-agent intermediate fusion system for real-world deployment. The system will be publicly released to promote research in this field: <a target="_blank" rel="noopener" href="https://github.com/ucla-mobility/QuantV2X">https://github.com/ucla-mobility/QuantV2X</a>. </p>
<blockquote>
<p>é€šè¿‡è½¦è¾†å¯¹ä¸€åˆ‡ï¼ˆV2Xï¼‰é€šä¿¡å®ç°çš„åˆä½œæ„ŸçŸ¥åœ¨å¢å¼ºè½¦è¾†æ„ŸçŸ¥æ–¹é¢æ‹¥æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¯ä»¥ç¼“è§£é®æŒ¡é—®é¢˜å¹¶æ‰©å¤§è§†é‡ã€‚ç„¶è€Œï¼Œè¿‡å»çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æé«˜ç²¾åº¦æŒ‡æ ‡ä¸Šï¼Œè€Œæ²¡æœ‰è§£å†³æ•ˆç‡ã€å»¶è¿Ÿå’Œç°å®ä¸–ç•Œéƒ¨ç½²çš„å…³é”®ç³»ç»Ÿçº§è€ƒè™‘ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿä¾èµ–äºå…¨ç²¾åº¦æ¨¡å‹ï¼Œè¿™äº§ç”Ÿäº†è¾ƒé«˜çš„è®¡ç®—å’Œä¼ è¾“æˆæœ¬ï¼Œä½¿å…¶åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®æ—¶è¿è¡Œä¸å®ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03704v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è½¦è¾†é—´çš„æ„ŸçŸ¥é€šè¿‡è½¦è¾†å¯¹å¤–ç•Œç¯å¢ƒæ„ŸçŸ¥çš„é€šä¿¡æ–¹å¼ï¼ˆV2Xï¼‰æœ‰å·¨å¤§çš„æå‡æ½œåŠ›ï¼Œå®ƒå¯ä»¥å¼¥è¡¥é®æŒ¡å’Œæ‰©å¤§è§†é‡ã€‚ç„¶è€Œï¼Œè¿‡å»çš„ç ”ç©¶ä¸»è¦å…³æ³¨æé«˜å‡†ç¡®æ€§ï¼Œå¿½ç•¥äº†æ•ˆç‡ã€å»¶è¿Ÿå’Œå®é™…åº”ç”¨ä¸­çš„ç³»ç»Ÿçº§è€ƒè™‘ã€‚ç°æœ‰ç³»ç»Ÿå¤§å¤šä¾èµ–å…¨ç²¾åº¦æ¨¡å‹ï¼Œå¯¼è‡´è®¡ç®—å’Œä¼ è¾“æˆæœ¬é«˜æ˜‚ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒä¸­çš„å®æ—¶æ“ä½œã€‚æœ¬æ–‡æå‡ºQuantV2Xï¼Œé¦–ä¸ªä¸“ä¸ºå¤šæ¨¡æ€å¤šæ™ºèƒ½ä½“V2Xåˆä½œæ„ŸçŸ¥è®¾è®¡çš„å…¨é‡åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨é«˜æ•ˆå¯æ‰©å±•åœ°éƒ¨ç½²ã€‚QuantV2Xåœ¨ç¥ç»ç½‘ç»œæ¨¡å‹å’Œä¼ è¾“æ¶ˆæ¯è¡¨ç¤ºä¸­é‡‡ç”¨ç«¯åˆ°ç«¯çš„ç»Ÿä¸€é‡åŒ–ç­–ç•¥ï¼Œé™ä½äº†è®¡ç®—è´Ÿè½½å’Œä¼ è¾“å¸¦å®½ã€‚å°½ç®¡åœ¨ä½æ¯”ç‰¹çº¦æŸä¸‹è¿è¡Œï¼ŒQuantV2Xä»èƒ½è¾¾åˆ°ä¸å…¨ç²¾åº¦ç³»ç»Ÿç›¸å½“çš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒQuantV2Xåœ¨ç³»ç»Ÿçº§å»¶è¿Ÿæ–¹é¢å‡å°‘äº†3.2å€ï¼Œå¹¶åœ¨å…¨ç²¾åº¦åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†mAP30çš„+9.5æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒQuantV2Xæ›´æœ‰æ•ˆåœ°æ‰©å±•ï¼Œä½¿å¤§å‹æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸¥æ ¼çš„å†…å­˜é¢„ç®—å†…è¿è¡Œã€‚æ­¤ç³»ç»Ÿè¯æ˜äº†å…¨é‡åŒ–çš„å¤šæ™ºèƒ½ä½“ä¸­é—´èåˆç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œçš„éƒ¨ç½²ä¸­çš„å¯è¡Œæ€§ã€‚è¯¥ç³»ç»Ÿå°†å…¬å¼€å‘å¸ƒä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è½¦è¾†é—´çš„åˆä½œæ„ŸçŸ¥é€šè¿‡V2Xé€šä¿¡æœ‰æ½œåŠ›å¢å¼ºè½¦è¾†æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>è¿‡å»çš„ç ”ç©¶ä¸»è¦å…³æ³¨å‡†ç¡®æ€§æå‡ï¼Œå¿½ç•¥äº†æ•ˆç‡ã€å»¶è¿Ÿå’Œç³»ç»Ÿçº§è€ƒè™‘ã€‚</li>
<li>ç°æœ‰ç³»ç»Ÿä¾èµ–é«˜æˆæœ¬çš„å…¨ç²¾åº¦æ¨¡å‹ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒã€‚</li>
<li>QuantV2Xæ˜¯å…¨é‡åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œé’ˆå¯¹å¤šæ¨¡æ€å¤šæ™ºèƒ½ä½“V2Xåˆä½œæ„ŸçŸ¥è®¾è®¡ã€‚</li>
<li>QuantV2Xé‡‡ç”¨ç«¯åˆ°ç«¯çš„ç»Ÿä¸€é‡åŒ–ç­–ç•¥ï¼Œé™ä½è®¡ç®—è´Ÿè½½å’Œä¼ è¾“å¸¦å®½ã€‚</li>
<li>QuantV2Xåœ¨ä½æ¯”ç‰¹çº¦æŸä¸‹è¿è¡Œï¼Œä½†æ€§èƒ½ä¸å…¨ç²¾åº¦ç³»ç»Ÿç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03704">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a11bc259c02dc18943cb7cc1ef68f936.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b61ee00ae53f847fcc7acf3438320f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c27b2f2a4cb86296296530ed5c65cff3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94cdab73a96c2f55e322386280c4fe38.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AgenTracer-Who-Is-Inducing-Failure-in-the-LLM-Agentic-Systems"><a href="#AgenTracer-Who-Is-Inducing-Failure-in-the-LLM-Agentic-Systems" class="headerlink" title="AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?"></a>AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?</h2><p><strong>Authors:Guibin Zhang, Junhao Wang, Junjie Chen, Wangchunshu Zhou, Kun Wang, Shuicheng Yan</strong></p>
<p>Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents. Yet this very sophistication amplifies their fragility, making them more prone to system failure. Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of agentic system failure attribution. Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below 10%. To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a lightweight failure tracer trained with multi-granular reinforcement learning, capable of efficiently diagnosing errors in verbose multi-agent interactions. On the Who&amp;When benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS with 4.8-14.2% performance gains, empowering self-correcting and self-evolving agentic AI. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç³»ç»Ÿï¼Œé€šå¸¸åŒ…å«å¤šä¸ªæ¨¡å‹ã€å¤æ‚çš„å·¥å…·è°ƒç”¨å’ŒååŒåè®®ï¼Œåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå•ä¸€ä»£ç†ã€‚ç„¶è€Œï¼Œè¿™ç§å¤æ‚æ€§ä¹Ÿå¢åŠ äº†å®ƒä»¬çš„è„†å¼±æ€§ï¼Œä½¿å®ƒä»¬æ›´å®¹æ˜“å‡ºç°ç³»ç»Ÿæ•…éšœã€‚ç¡®å®šé•¿æ‰§è¡Œè½¨è¿¹ä¸­å¯¼è‡´é”™è¯¯çš„ç‰¹å®šä»£ç†æˆ–æ­¥éª¤ï¼Œè¿™å®šä¹‰äº†ä»£ç†ç³»ç»Ÿå¤±è´¥å½’å±çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨ç†LLMå¯¹æ­¤æŒ‘æˆ˜ä»ç„¶æ˜æ˜¾ä¸è¶³ï¼Œå‡†ç¡®ç‡é€šå¸¸ä½äº10%ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†AgenTracerï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé€šè¿‡åäº‹å®å›æ”¾å’Œç¼–ç¨‹æ•…éšœæ³¨å…¥æ¥æ³¨é‡Šå¤±è´¥çš„å¤šä»£ç†è½¨è¿¹çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œç”Ÿæˆäº†ç²¾é€‰æ•°æ®é›†TracerTrajã€‚åˆ©ç”¨è¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬å¼€å‘äº†è½»è´¨å¤±è´¥è¿½è¸ªå™¨AgenTracer-8Bï¼Œå®ƒé‡‡ç”¨å¤šç²’åº¦å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé«˜æ•ˆè¯Šæ–­å†—é•¿çš„å¤šä»£ç†äº¤äº’ä¸­çš„é”™è¯¯ã€‚åœ¨Who&amp;WhenåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAgenTracer-8Bçš„æ€§èƒ½è¶…è¿‡äº†åƒGemini-2.5-Proå’ŒClaude-4-Sonnetç­‰å¤§å‹ä¸“æœ‰LLMï¼Œæé«˜äº†é«˜è¾¾18.18%ï¼Œåœ¨LLMä»£ç†å¤±è´¥å½’å±æ–¹é¢æ ‘ç«‹äº†æ–°çš„æ ‡å‡†ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒAgenTracer-8Bä¸ºç°æˆçš„å¤šä»£ç†ç³»ç»Ÿï¼ˆå¦‚MetaGPTå’ŒMaASï¼‰æä¾›äº†å¯æ“ä½œåé¦ˆï¼Œå®ç°äº†4.8%~14.2%çš„æ€§èƒ½æå‡ï¼Œèµ‹èƒ½è‡ªæˆ‘ä¿®æ­£å’Œè‡ªæˆ‘è¿›åŒ–çš„ä»£ç†äººå·¥æ™ºèƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03312v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç³»ç»Ÿç”±äºå…¶å¤æ‚æ€§ï¼Œåœ¨è¿è¡Œæ—¶æ›´å®¹æ˜“å‡ºç°é”™è¯¯ã€‚ç³»ç»Ÿå¤±è´¥çš„å½’å› é—®é¢˜å°±åœ¨äºç¡®å®šå…·ä½“å‡ºé”™çš„è´£ä»»ä»£ç†æˆ–æ­¥éª¤ã€‚å½“å‰æœ€å…ˆè¿›çš„æ¨ç†å‹LLMå¯¹æ­¤æŒ‘æˆ˜ä»æ˜¾å¾—æ‰è¥Ÿè§è‚˜ï¼Œå‡†ç¡®åº¦é€šå¸¸ä½äºç™¾åˆ†ä¹‹åã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†AgenTraceræ¡†æ¶ï¼Œå®ƒé€šè¿‡åäº‹å®å›æ”¾å’Œç¼–ç¨‹æ•…éšœæ³¨å…¥æ¥è‡ªåŠ¨æ ‡æ³¨å¤±è´¥çš„å¤šå…ƒä»£ç†è½¨è¿¹ï¼Œå¹¶ç”Ÿæˆç²¾é€‰æ•°æ®é›†TracerTrajã€‚åˆ©ç”¨è¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬å¼€å‘äº†è½»é‡çº§çš„å¤±è´¥è¿½è¸ªå™¨AgenTracer-8Bï¼Œé‡‡ç”¨å¤šç²’åº¦å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé«˜æ•ˆè¯Šæ–­å†—é•¿çš„å¤šå…ƒä»£ç†äº¤äº’ä¸­çš„é”™è¯¯ã€‚åœ¨Who&amp;WhenåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAgenTracer-8Bè¡¨ç°ä¼˜äºå¤§å‹ä¸“æœ‰LLMå¦‚Gemini-2.5-Proå’ŒClaude-4-Sonnetï¼Œé«˜å‡ºè¾¾ç™¾åˆ†ä¹‹åå…«ç‚¹ä¸€å…«ï¼Œä¸ºLLMä»£ç†ç³»ç»Ÿå¤±è´¥å½’å› æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒAgenTracer-8Bä¸ºç°æˆçš„å¤šå…ƒä»£ç†ç³»ç»Ÿå¦‚MetaGPTå’ŒMaASæä¾›äº†å¯æ“ä½œåé¦ˆï¼Œæå‡äº†æ€§èƒ½ï¼Œä½¿å¾—è‡ªæˆ‘çº æ­£å’Œè‡ªæˆ‘æ¼”åŒ–çš„ä»£ç†AIæˆä¸ºå¯èƒ½ã€‚ç®€è¨€ä¹‹ï¼Œä»£ç†ç³»ç»Ÿçš„æ€§èƒ½å’Œæ•…éšœè¯Šæ–­æœ‰äº†æ–°è¿›å±•ã€‚é€šè¿‡æŠ€æœ¯åˆ›æ–°æå‡äº†å¤æ‚ç³»ç»Ÿçš„ç¨³å¥æ€§ã€‚ä½†æœ€é‡è¦çš„æ˜¯æå‡äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è‡ªé€‚åº”ä¿®å¤èƒ½åŠ›ï¼Œè¿›è€Œæå‡æ•´ä¸ªç³»ç»Ÿçš„å¯é æ€§å’Œæ•ˆç‡ã€‚æ­¤åˆ›æ–°ç ”ç©¶åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¼€è¾Ÿäº†æ–°çš„åº”ç”¨å‰æ™¯ã€‚è¿™ä¸€å‘ç°å¯èƒ½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœªæ¥å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨å’Œæ™ºèƒ½ä½“ç³»ç»Ÿçš„èåˆç ”ç©¶æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡è¦å‘å±•æ–¹å‘ä¹‹ä¸€ã€‚é€šè¿‡åˆ›æ–°çš„æ–¹æ³•å’ŒæŠ€æœ¯æ‰‹æ®µæ¥è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„å¤±è´¥å½’å› é—®é¢˜å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™é¡¹ç ”ç©¶æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€å¤§çªç ´ï¼Œä¸ºè§£å†³å¤æ‚çš„æ™ºèƒ½ä½“ç³»ç»Ÿæ•…éšœé—®é¢˜æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹å‘ã€‚æ€»ä½“è€Œè¨€å…·æœ‰é‡è¦çš„å®è·µæ„ä¹‰å’Œå­¦æœ¯ä»·å€¼ä¸”åº”ç”¨åœºæ™¯å¹¿é˜”çš„å‰æ™¯æ˜¾è‘—è®©äººæœŸå¾…æ›´å¤šçš„æœªæ¥æŠ€æœ¯æ”¹è¿›ä¸å®ç°å¯¹äºå®é™…åº”ç”¨å’Œéƒ¨ç½²çš„å…³é”®è¿›æ­¥æ‰€è¡¨ç°å‡ºçš„ä¼˜å¼‚è¡¨ç°ä½“ç°äº†äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œè¿›æ­¥ã€‚æœªæ¥æŠ€æœ¯åœ¨è¯¥é¢†åŸŸçš„è½åœ°å°†ä¸ºç›¸å…³é¢†åŸŸçš„è¡Œä¸šå¸¦æ¥å·¨å¤§çš„æ¨åŠ¨ä½œç”¨å’ŒæŠ€æœ¯æ”¯æŒæ½œåŠ›ã€‚<strong>Key Takeaways</strong>:</p>
<ol>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†ç³»ç»Ÿè™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†å¤æ‚æ€§å¯¼è‡´ç³»ç»Ÿæ›´æ˜“å‡ºé”™ï¼Œå¤±è´¥å½’å› å›°éš¾ã€‚</li>
<li>å½“å‰LLMåœ¨å¤±è´¥å½’å› æ–¹é¢çš„å‡†ç¡®åº¦è¾ƒä½ï¼Œä¸€èˆ¬ä½äºç™¾åˆ†ä¹‹åã€‚</li>
<li>æå‡ºAgenTraceræ¡†æ¶åŠæ•°æ®é›†TracerTrajç”¨äºæ ‡æ³¨å¤±è´¥çš„å¤šå…ƒä»£ç†è½¨è¿¹ã€‚</li>
<li>AgenTracer-8Bèƒ½é«˜æ•ˆè¯Šæ–­å¤šå…ƒä»£ç†äº¤äº’ä¸­çš„é”™è¯¯ï¼Œè¶…è¶Šä¸“æœ‰LLMè¡¨ç°ã€‚</li>
<li>AgenTracer-8Bèµ‹èƒ½è‡ªæˆ‘çº æ­£å’Œè‡ªæˆ‘æ¼”åŒ–çš„ä»£ç†AIï¼Œæå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>è¯¥ç ”ç©¶è§£å†³äº†å¤æ‚æ™ºèƒ½ä½“ç³»ç»Ÿæ•…éšœé—®é¢˜ï¼Œä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸå¸¦æ¥çªç ´å’Œæ–°æ€è·¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03312">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-67e904c0e4730b1e7304e33fafd8468a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71825900da7db7efc0aba05d495c64e5.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Plan-Verification-for-LLM-Based-Embodied-Task-Completion-Agents"><a href="#Plan-Verification-for-LLM-Based-Embodied-Task-Completion-Agents" class="headerlink" title="Plan Verification for LLM-Based Embodied Task Completion Agents"></a>Plan Verification for LLM-Based Embodied Task Completion Agents</h2><p><strong>Authors:Ananth Hariharan, Vardhan Dongre, Dilek Hakkani-TÃ¼r, Gokhan Tur</strong></p>
<p>Large language model (LLM) based task plans and corresponding human demonstrations for embodied AI may be noisy, with unnecessary actions, redundant navigation, and logical errors that reduce policy quality. We propose an iterative verification framework in which a Judge LLM critiques action sequences and a Planner LLM applies the revisions, yielding progressively cleaner and more spatially coherent trajectories. Unlike rule-based approaches, our method relies on natural language prompting, enabling broad generalization across error types including irrelevant actions, contradictions, and missing steps. On a set of manually annotated actions from the TEACh embodied AI dataset, our framework achieves up to 90% recall and 100% precision across four state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout). The refinement loop converges quickly, with 96.5% of sequences requiring at most three iterations, while improving both temporal efficiency and spatial action organization. Crucially, the method preserves human error-recovery patterns rather than collapsing them, supporting future work on robust corrective behavior. By establishing plan verification as a reliable LLM capability for spatial planning and action refinement, we provide a scalable path to higher-quality training data for imitation learning in embodied AI. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é’ˆå¯¹å®ä½“äººå·¥æ™ºèƒ½çš„ä»»åŠ¡è®¡åˆ’ä»¥åŠç›¸åº”çš„äººç±»æ¼”ç¤ºå¯èƒ½ä¼šå­˜åœ¨å™ªå£°ï¼ŒåŒ…å«ä¸å¿…è¦è¡ŒåŠ¨ã€å†—ä½™å¯¼èˆªä»¥åŠé€»è¾‘é”™è¯¯ï¼Œä»è€Œé™ä½äº†ç­–ç•¥è´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè¿­ä»£éªŒè¯æ¡†æ¶ï¼Œå…¶ä¸­judge LLMå¯¹è¡ŒåŠ¨åºåˆ—è¿›è¡Œæ‰¹åˆ¤ï¼Œè€ŒPlanner LLMåº”ç”¨ä¿®è®¢å†…å®¹ï¼Œä»è€Œäº§ç”Ÿè¶Šæ¥è¶Šå¹²å‡€ã€ç©ºé—´è¿è´¯æ€§è¶Šæ¥è¶Šå¼ºçš„è½¨è¿¹ã€‚ä¸åŒäºåŸºäºè§„åˆ™çš„æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¾èµ–äºè‡ªç„¶è¯­è¨€æç¤ºï¼Œèƒ½å¤Ÿå®ç°å¹¿æ³›æ¦‚æ‹¬å„ç§é”™è¯¯ç±»å‹ï¼ŒåŒ…æ‹¬æ— å…³è¡ŒåŠ¨ã€çŸ›ç›¾ä»¥åŠç¼ºå¤±æ­¥éª¤ã€‚åœ¨æ¥è‡ªTEAChå®ä½“AIæ•°æ®é›†çš„æ‰‹åŠ¨æ³¨é‡Šè¡ŒåŠ¨é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å››ä¸ªæœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆGPT o4-miniã€DeepSeek-R1ã€Gemini 2.5ã€LLaMA 4 Scoutï¼‰ä¸Šå®ç°äº†é«˜è¾¾90%çš„å¬å›ç‡å’Œ100%çš„ç²¾ç¡®åº¦ã€‚æ”¹è¿›å¾ªç¯å¿«é€Ÿæ”¶æ•›ï¼Œ96.5%çš„åºåˆ—æœ€å¤šéœ€è¦ä¸‰æ¬¡è¿­ä»£ï¼ŒåŒæ—¶æé«˜æ—¶é—´æ•ˆç‡å’Œç©ºé—´è¡ŒåŠ¨ç»„ç»‡ã€‚å…³é”®çš„æ˜¯ï¼Œè¯¥æ–¹æ³•ä¿ç•™äº†äººç±»é”™è¯¯æ¢å¤æ¨¡å¼ï¼Œè€Œä¸æ˜¯æ¶ˆé™¤å®ƒä»¬ï¼Œæ”¯æŒæœªæ¥åœ¨ç¨³å¥çº æ­£è¡Œä¸ºæ–¹é¢çš„å·¥ä½œã€‚é€šè¿‡å»ºç«‹è®¡åˆ’éªŒè¯ä½œä¸ºå¯é çš„å¤§å‹è¯­è¨€æ¨¡å‹èƒ½åŠ›æ¥è¿›è¡Œç©ºé—´è§„åˆ’å’Œè¡ŒåŠ¨æ”¹è¿›ï¼Œæˆ‘ä»¬ä¸ºå®ä½“äººå·¥æ™ºèƒ½ä¸­çš„æ¨¡ä»¿å­¦ä¹ æä¾›äº†é«˜è´¨é‡è®­ç»ƒæ•°æ®çš„å¯æ‰©å±•è·¯å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.02761v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„AIä»»åŠ¡è®¡åˆ’åŠç›¸åº”çš„äººç±»æ¼”ç¤ºå¯èƒ½ä¼šå­˜åœ¨å™ªå£°ï¼ŒåŒ…å«å¤šä½™åŠ¨ä½œã€å†—ä½™å¯¼èˆªå’Œé€»è¾‘é”™è¯¯ç­‰é—®é¢˜ï¼Œä»è€Œé™ä½ç­–ç•¥è´¨é‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¿­ä»£éªŒè¯æ¡†æ¶ï¼Œå…¶ä¸­Judge LLMè´Ÿè´£è¯„ä¼°åŠ¨ä½œåºåˆ—ï¼Œè€ŒPlanner LLMåˆ™è´Ÿè´£åº”ç”¨ä¿®æ­£æ„è§ï¼Œä»è€Œç”Ÿæˆæ›´åŠ æ¸…æ™°ã€ç©ºé—´è¿è´¯çš„è½¨è¿¹ã€‚ä¸ä¼ ç»ŸåŸºäºè§„åˆ™çš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¾èµ–äºè‡ªç„¶è¯­è¨€æç¤ºï¼Œèƒ½å¤Ÿå¹¿æ³›æ³›åŒ–å„ç§é”™è¯¯ç±»å‹ï¼ŒåŒ…æ‹¬æ— å…³åŠ¨ä½œã€çŸ›ç›¾ä»¥åŠç¼ºå¤±æ­¥éª¤ç­‰ã€‚åœ¨TEACh AIæ•°æ®é›†ä¸Šçš„ä¸€ç»„æ‰‹åŠ¨æ³¨é‡ŠåŠ¨ä½œä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å››ä¸ªæœ€æ–°LLMä¸Šå®ç°äº†é«˜è¾¾90%çš„å¬å›ç‡å’Œ100%çš„ç²¾ç¡®åº¦ã€‚ä¼˜åŒ–å¾ªç¯å¿«é€Ÿæ”¶æ•›ï¼Œå¤§å¤šæ•°åºåˆ—ä»…éœ€ä¸‰æ¬¡è¿­ä»£å³å¯æ”¹å–„æ—¶åºæ•ˆç‡å’Œç©ºé—´è¡ŒåŠ¨ç»„ç»‡ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿä¿ç•™äººç±»é”™è¯¯æ¢å¤æ¨¡å¼ï¼Œä¸ºæœªæ¥çš„ç¨³å¥çº æ­£è¡Œä¸ºç ”ç©¶æä¾›æ”¯æŒã€‚é€šè¿‡éªŒè¯è®¡åˆ’ä½œä¸ºå¯é çš„LLMåœ¨ç©ºé—´è§„åˆ’å’Œè¡ŒåŠ¨ä¼˜åŒ–ä¸Šçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬ä¸ºæ¨¡ä»¿å­¦ä¹ ä¸­çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®æä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„è·¯å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨AIä»»åŠ¡è®¡åˆ’ä¸­å¯èƒ½ä¼šå­˜åœ¨å™ªå£°å’Œé€»è¾‘é”™è¯¯ç­‰é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è¿­ä»£éªŒè¯æ¡†æ¶ï¼Œå…¶ä¸­Judge LLMå’ŒPlanner LLMåˆ†åˆ«è´Ÿè´£è¯„ä¼°å’Œä¿®æ­£åŠ¨ä½œåºåˆ—ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿå®ç°å¹¿æ³›é”™è¯¯ç±»å‹çš„æ³›åŒ–ï¼ŒåŒ…æ‹¬æ— å…³åŠ¨ä½œã€çŸ›ç›¾å’Œç¼ºå¤±æ­¥éª¤ç­‰ã€‚</li>
<li>åœ¨TEACh AIæ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶åœ¨å››ä¸ªæœ€æ–°LLMä¸Šå–å¾—äº†è¾ƒé«˜çš„å¬å›ç‡å’Œç²¾ç¡®åº¦ã€‚</li>
<li>ä¼˜åŒ–å¾ªç¯å¿«é€Ÿæ”¶æ•›ï¼Œå¤§å¤šæ•°åºåˆ—ä»…éœ€ä¸‰æ¬¡è¿­ä»£å³å¯æ”¹å–„æ—¶åºæ•ˆç‡å’Œç©ºé—´è¡ŒåŠ¨ç»„ç»‡ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿä¿ç•™äººç±»é”™è¯¯æ¢å¤æ¨¡å¼ï¼Œæœ‰åŠ©äºæœªæ¥ç ”ç©¶æ›´ç¨³å¥çš„çº æ­£è¡Œä¸ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.02761">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-460a8b0f0889b4930e3bb6d1cf576174.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f2a488f052b24539e9a2bf70a418bf3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5af66958361bc5aa8165ef4d7ee2128.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5010aa281127e9dd3f95287a5d3ef7c6.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Building-surrogate-models-using-trajectories-of-agents-trained-by-Reinforcement-Learning"><a href="#Building-surrogate-models-using-trajectories-of-agents-trained-by-Reinforcement-Learning" class="headerlink" title="Building surrogate models using trajectories of agents trained by   Reinforcement Learning"></a>Building surrogate models using trajectories of agents trained by   Reinforcement Learning</h2><p><strong>Authors:Julen Cestero, Marco Quartulli, Marcello Restelli</strong></p>
<p>Sample efficiency in the face of computationally expensive simulations is a common concern in surrogate modeling. Current strategies to minimize the number of samples needed are not as effective in simulated environments with wide state spaces. As a response to this challenge, we propose a novel method to efficiently sample simulated deterministic environments by using policies trained by Reinforcement Learning. We provide an extensive analysis of these surrogate-building strategies with respect to Latin-Hypercube sampling or Active Learning and Kriging, cross-validating performances with all sampled datasets. The analysis shows that a mixed dataset that includes samples acquired by random agents, expert agents, and agents trained to explore the regions of maximum entropy of the state transition distribution provides the best scores through all datasets, which is crucial for a meaningful state space representation. We conclude that the proposed method improves the state-of-the-art and clears the path to enable the application of surrogate-aided Reinforcement Learning policy optimization strategies on complex simulators. </p>
<blockquote>
<p>åœ¨ä»¿çœŸå»ºæ¨¡ä¸­ï¼Œé¢å¯¹è®¡ç®—æ˜‚è´µçš„æ¨¡æ‹Ÿæ—¶ï¼Œæ ·æœ¬æ•ˆç‡æ˜¯ä¸€ä¸ªæ™®éå…³æ³¨çš„é—®é¢˜ã€‚ç›®å‰å‡å°‘æ‰€éœ€æ ·æœ¬æ•°é‡çš„ç­–ç•¥åœ¨çŠ¶æ€ç©ºé—´è¾ƒå¤§çš„ä»¿çœŸç¯å¢ƒä¸­æ•ˆæœå¹¶ä¸ç†æƒ³ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ç­–ç•¥å¯¹æ¨¡æ‹Ÿç¡®å®šæ€§ç¯å¢ƒè¿›è¡Œæœ‰æ•ˆé‡‡æ ·ã€‚æˆ‘ä»¬å¯¹è¿™äº›ä»£ç†æ„å»ºç­–ç•¥è¿›è¡Œäº†æ‹‰ä¸è¶…ç«‹æ–¹ä½“é‡‡æ ·æˆ–ä¸»åŠ¨å­¦ä¹ ä¸å…‹é‡Œæ ¼æ–¹æ³•çš„å…¨é¢åˆ†æï¼Œé€šè¿‡æ‰€æœ‰é‡‡æ ·æ•°æ®é›†è¿›è¡Œäº¤å‰éªŒè¯æ€§èƒ½ã€‚åˆ†æè¡¨æ˜ï¼Œæ··åˆæ•°æ®é›†åŒ…æ‹¬éšæœºä»£ç†ã€ä¸“å®¶ä»£ç†ä»¥åŠè®­ç»ƒæ¢ç´¢çŠ¶æ€è½¬æ¢åˆ†å¸ƒæœ€å¤§ç†µåŒºåŸŸçš„ä»£ç†æ‰€è·å–çš„æ ·æœ¬ï¼Œåœ¨æ‰€æœ‰æ•°æ®é›†ä¸­å¾—åˆ†æœ€é«˜ï¼Œè¿™å¯¹äºæœ‰æ„ä¹‰çš„çŠ¶æ€ç©ºé—´è¡¨ç¤ºè‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œè¯¥æ–¹æ³•æ”¹è¿›äº†ç°æœ‰æŠ€æœ¯ï¼Œä¸ºåœ¨å¤æ‚æ¨¡æ‹Ÿå™¨ä¸Šåº”ç”¨ä»£ç†è¾…åŠ©å¼ºåŒ–å­¦ä¹ æ”¿ç­–ä¼˜åŒ–ç­–ç•¥é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01285v1">PDF</a> Published in ICANN 2024 conference</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„æ ·æœ¬æ•ˆç‡é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨çŠ¶æ€ç©ºé—´å¹¿æ³›çš„æƒ…å†µä¸‹ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ç­–ç•¥ï¼Œå¯¹æ¨¡æ‹Ÿç¡®å®šæ€§ç¯å¢ƒè¿›è¡Œæœ‰æ•ˆé‡‡æ ·ã€‚é€šè¿‡æ‹‰ä¸è¶…ç«‹æ–¹ä½“é‡‡æ ·ã€ä¸»åŠ¨å­¦ä¹ ä¸å…‹é‡Œé‡‘æ³•çš„å¯¹æ¯”åˆ†æï¼Œç»“æœæ˜¾ç¤ºæ··åˆæ•°æ®é›†ï¼ˆåŒ…æ‹¬éšæœºä»£ç†ã€ä¸“å®¶ä»£ç†ä»¥åŠè®­ç»ƒæ¢ç´¢çŠ¶æ€è½¬æ¢åˆ†å¸ƒæœ€å¤§ç†µåŒºåŸŸçš„ä»£ç†æ ·æœ¬ï¼‰è¡¨ç°æœ€ä½³ï¼Œå¯¹æœ‰æ„ä¹‰çš„çŠ¶æ€ç©ºé—´è¡¨ç¤ºè‡³å…³é‡è¦ã€‚æ‰€ææ–¹æ³•æé«˜äº†ç°æœ‰æŠ€æœ¯æ°´å¹³ï¼Œä¸ºåœ¨å¤æ‚æ¨¡æ‹Ÿå™¨ä¸Šåº”ç”¨åŸºäºä»£ç†çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨¡æ‹Ÿç¯å¢ƒä¸­æ ·æœ¬æ•ˆç‡çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨çŠ¶æ€ç©ºé—´å¹¿æ³›çš„æƒ…å†µä¸‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ç­–ç•¥å¯¹æ¨¡æ‹Ÿç¡®å®šæ€§ç¯å¢ƒè¿›è¡Œé«˜æ•ˆé‡‡æ ·ã€‚</li>
<li>é€šè¿‡ä¸æ‹‰ä¸è¶…ç«‹æ–¹ä½“é‡‡æ ·ã€ä¸»åŠ¨å­¦ä¹ åŠå…‹é‡Œé‡‘æ³•çš„å¯¹æ¯”åˆ†æï¼Œå‘ç°æ··åˆæ•°æ®é›†è¡¨ç°æœ€ä½³ã€‚</li>
<li>æ··åˆæ•°æ®é›†åŒ…æ‹¬éšæœºä»£ç†ã€ä¸“å®¶ä»£ç†ä»¥åŠæ¢ç´¢çŠ¶æ€è½¬æ¢åˆ†å¸ƒæœ€å¤§ç†µåŒºåŸŸè®­ç»ƒçš„ä»£ç†æ ·æœ¬ã€‚</li>
<li>è¯¥æ–¹æ³•æé«˜äº†ç°æœ‰æŠ€æœ¯æ°´å¹³ï¼Œä¸ºå¤æ‚æ¨¡æ‹Ÿå™¨ä¸Šåº”ç”¨åŸºäºä»£ç†çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–é“ºå¹³äº†é“è·¯ã€‚</li>
<li>æ ·æœ¬é‡‡é›†ç­–ç•¥å¯¹äºæœ‰æ„ä¹‰çš„çŠ¶æ€ç©ºé—´è¡¨ç¤ºè‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01285">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5fd1c6aa30037ac66ff3b88afb794ed1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Memory-R1-Enhancing-Large-Language-Model-Agents-to-Manage-and-Utilize-Memories-via-Reinforcement-Learning"><a href="#Memory-R1-Enhancing-Large-Language-Model-Agents-to-Manage-and-Utilize-Memories-via-Reinforcement-Learning" class="headerlink" title="Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize   Memories via Reinforcement Learning"></a>Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize   Memories via Reinforcement Learning</h2><p><strong>Authors:Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Hinrich SchÃ¼tze, Volker Tresp, Yunpu Ma</strong></p>
<p>Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of NLP tasks, but they remain fundamentally stateless, constrained by limited context windows that hinder long-horizon reasoning. Recent efforts to address this limitation often augment LLMs with an external memory bank, yet most existing pipelines are static and heuristic-driven, lacking any learned mechanism for deciding what to store, update, or retrieve. We present Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the ability to actively manage and utilize external memory through two specialized agents: a Memory Manager that learns to perform structured memory operations, including adding, updating, deleting, or taking no operation on memory entries; and an Answer Agent that selects the most relevant entries and reasons over them to produce an answer. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and utilization with minimal supervision. With as few as 152 question-answer pairs and a corresponding temporal memory bank for training, Memory-R1 outperforms the strongest existing baseline and demonstrates strong generalization across diverse question types and LLM backbones. Beyond presenting an effective approach, this work provides insights into how RL can unlock more agentic, memory-aware behavior in LLMs, pointing toward richer, more persistent reasoning systems. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¹¿æ³›çš„NLPä»»åŠ¡ä¸­å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬ä»ç„¶æ˜¯æ ¹æœ¬ä¸Šçš„æ— çŠ¶æ€æ¨¡å‹ï¼Œå—åˆ°æœ‰é™ä¸Šä¸‹æ–‡çª—å£çš„é™åˆ¶ï¼Œé˜»ç¢äº†é•¿æœŸæ¨ç†ã€‚æœ€è¿‘ä¸ºè§£å†³è¿™ä¸€é™åˆ¶æ‰€åšçš„åŠªåŠ›é€šå¸¸æ˜¯é€šè¿‡å¤–éƒ¨å­˜å‚¨å™¨å¢å¼ºLLMï¼Œä½†å¤§å¤šæ•°ç°æœ‰æµç¨‹éƒ½æ˜¯é™æ€å’Œå¯å‘å¼é©±åŠ¨çš„ï¼Œç¼ºä¹ä»»ä½•å­¦ä¹ æœºåˆ¶æ¥å†³å®šå­˜å‚¨ã€æ›´æ–°æˆ–æ£€ç´¢ä»€ä¹ˆã€‚æˆ‘ä»¬æå‡ºäº†Memory-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¡†æ¶ï¼Œå®ƒä¸ºLLMé…å¤‡äº†ä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨å­˜å‚¨å™¨çš„èƒ½åŠ›ï¼Œé€šè¿‡ä¸¤ä¸ªä¸“ç”¨ä»£ç†å®ç°ï¼šå†…å­˜ç®¡ç†å™¨å­¦ä¹ æ‰§è¡Œç»“æ„åŒ–å†…å­˜æ“ä½œï¼ŒåŒ…æ‹¬æ·»åŠ ã€æ›´æ–°ã€åˆ é™¤æˆ–å¯¹å†…å­˜æ¡ç›®ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼›ç­”æ¡ˆä»£ç†é€‰æ‹©æœ€ç›¸å…³çš„æ¡ç›®å¹¶å¯¹å…¶è¿›è¡Œæ¨ç†ä»¥äº§ç”Ÿç­”æ¡ˆã€‚è¿™ä¸¤ä¸ªä»£ç†éƒ½ä½¿ç”¨ä»¥ç»“æœé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ï¼ˆPPOå’ŒGRPOï¼‰è¿›è¡Œå¾®è°ƒï¼Œä½¿ç›‘ç£æœ€å°çš„æƒ…å†µä¸‹å®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ã€‚ä½¿ç”¨ä»…152ä¸ªé—®ç­”å¯¹åŠå…¶ç›¸åº”çš„ä¸´æ—¶è®°å¿†åº“è¿›è¡Œè®­ç»ƒï¼ŒMemory-R1è¶…è¿‡äº†æœ€å¼ºçš„ç°æœ‰åŸºå‡†æµ‹è¯•ï¼Œå¹¶åœ¨å„ç§é—®é¢˜å’ŒLLMä¸»å¹²ä¸Šå±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é™¤äº†æä¾›ä¸€ç§æœ‰æ•ˆæ–¹æ³•å¤–ï¼Œè¿™é¡¹å·¥ä½œè¿˜æä¾›äº†å…³äºå¼ºåŒ–å­¦ä¹ å¦‚ä½•è§£é”LLMä¸­æ›´å…·æ™ºèƒ½ã€è®°å¿†æ„ŸçŸ¥çš„è¡Œä¸ºçš„è§è§£ï¼Œä¸ºæ›´ä¸°å¯Œã€æ›´æŒä¹…çš„æ¨ç†ç³»ç»ŸæŒ‡æ˜äº†æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.19828v3">PDF</a> work in progress</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šä¸ªNLPä»»åŠ¡ä¸­å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†å…¶æœ¬è´¨ä¸Šæ˜¯æ— çŠ¶æ€çš„ï¼Œå—é™äºæœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå½±å“é•¿æœŸæ¨ç†ã€‚æœ€è¿‘çš„ç ”ç©¶é€šè¿‡ä¸ºLLMå¢åŠ å¤–éƒ¨è®°å¿†åº“æ¥è§£å†³æ­¤é™åˆ¶ï¼Œä½†ç°æœ‰æµç¨‹å¤šä¸ºé™æ€ã€å¯å‘å¼é©±åŠ¨ï¼Œç¼ºä¹å­¦ä¹ æœºåˆ¶æ¥å†³å®šå­˜å‚¨ã€æ›´æ–°æˆ–æ£€ç´¢çš„å†…å®¹ã€‚æœ¬ç ”ç©¶æå‡ºMemory-R1ï¼Œä¸€ç§å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¡†æ¶ï¼Œä¸ºLLMé…å¤‡ä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨è®°å¿†çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªä¸“é—¨ä»£ç†ï¼šå†…å­˜ç®¡ç†å™¨å­¦ä¹ æ‰§è¡Œç»“æ„åŒ–å†…å­˜æ“ä½œï¼Œå¦‚æ·»åŠ ã€æ›´æ–°ã€åˆ é™¤æˆ–ä¸å¯¹å†…å­˜æ¡ç›®è¿›è¡Œæ“ä½œï¼›ç­”æ¡ˆä»£ç†é€‰æ‹©æœ€ç›¸å…³çš„æ¡ç›®å¹¶è¿›è¡Œæ¨ç†ä»¥äº§ç”Ÿç­”æ¡ˆã€‚ä¸¤è€…å‡é€šè¿‡ç»“æœé©±åŠ¨çš„RLï¼ˆPPOå’ŒGRPOï¼‰è¿›è¡Œå¾®è°ƒï¼Œå¯åœ¨æå°‘ç›‘ç£ä¸‹å®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ã€‚åœ¨ä»…ä½¿ç”¨152ä¸ªé—®ç­”å¯¹åŠå…¶å¯¹åº”çš„æ—¶åºè®°å¿†åº“è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒMemory-R1è¡¨ç°ä¼˜äºç°æœ‰æœ€ä½³åŸºçº¿ï¼Œå¹¶åœ¨ä¸åŒé—®é¢˜ç±»å‹å’ŒLLMä¸»å¹²ä¸Šå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬ç ”ç©¶ä¸ä»…æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¿˜æ­ç¤ºäº†RLå¦‚ä½•è§£é”LLMä¸­æ›´å…·ä»£ç†æ€§çš„è®°å¿†æ„ŸçŸ¥è¡Œä¸ºï¼ŒæŒ‡å‘æ›´ä¸°å¯Œã€æ›´æŒä¹…çš„æ¨ç†ç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨NLPä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å­˜åœ¨æ— çŠ¶æ€æ€§å’Œä¸Šä¸‹æ–‡çª—å£é™åˆ¶çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•å¤§å¤šé€šè¿‡ä¸ºLLMå¢åŠ å¤–éƒ¨è®°å¿†åº“ï¼Œä½†è¿™äº›æ–¹æ³•ä¸»è¦æ˜¯é™æ€å’Œå¯å‘å¼é©±åŠ¨çš„ã€‚</li>
<li>Memory-R1é‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸ºLLMèµ‹äºˆä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨è®°å¿†çš„èƒ½åŠ›ã€‚</li>
<li>Memory-R1åŒ…æ‹¬ä¸¤ä¸ªä¸“é—¨ä»£ç†ï¼šå†…å­˜ç®¡ç†å™¨å­¦ä¹ æ‰§è¡Œç»“æ„åŒ–å†…å­˜æ“ä½œï¼Œç­”æ¡ˆä»£ç†é€‰æ‹©ç›¸å…³æ¡ç›®å¹¶è¿›è¡Œæ¨ç†ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ç»“æœé©±åŠ¨çš„RLè¿›è¡Œå¾®è°ƒï¼Œå¯åœ¨æå°‘ç›‘ç£ä¸‹å®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ã€‚</li>
<li>Memory-R1åœ¨ä»…ä½¿ç”¨å°‘é‡é—®ç­”å¯¹è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.19828">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f047b4458925519453dfa4e697424f9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ad79eb6f84889d0b8bfd9f817a9020a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2e247e535f8d20fc64acb51a87f85ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e7b03e1d6f39058cfec2a85c5c89ee8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67d0cbd9fb8f930233047d9b848fc018.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="EQ-Knight-A-Memory-Augmented-LLM-Agent-for-Strategic-Affective-Gaming-in-Debt-Recovery"><a href="#EQ-Knight-A-Memory-Augmented-LLM-Agent-for-Strategic-Affective-Gaming-in-Debt-Recovery" class="headerlink" title="EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming   in Debt Recovery"></a>EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming   in Debt Recovery</h2><p><strong>Authors:Yunbo Long, Yuhan Liu, Liming Xu, Alexandra Brintrup</strong></p>
<p>Large language model-based chatbots have enhanced engagement in financial negotiations, but their overreliance on passive empathy introduces critical risks in credit collection. While empathy-driven approaches preserve client satisfaction in benign cases, they fail catastrophically against dishonest debtorsâ€“individuals who exploit conciliatory tactics to manipulate terms or evade repayment. Blindly prioritizing â€œcustomer experienceâ€ in such scenarios leads to creditor vulnerabilities: revenue leakage, moral hazard, and systemic exploitation. To address this, we propose EQ-Knight, an LLM agent that dynamically optimizes emotional strategy to defend creditor interests. Unlike naive empathy-centric bots, EQ-Knight integrates emotion memory and game-theoretic reasoning, powered by a Hidden Markov Model (HMM) to track and predict debtor emotional states. By analyzing both real-time and historical emotional cues, EQ-Knight strategically counters negative emotions (e.g., aggression, feigned distress) while preserving productive debtor relationships. Experiments demonstrate EQ-Knightâ€™s superiority over conventional LLM negotiators: it achieves a 32% reduction in concession losses without compromising recovery rates, particularly in adversarial cases where debtors weaponize negative emotions (e.g., intimidation, guilt-tripping) to coerce concessions. For credit agencies, EQ-Knight transforms LLMs from high-risk â€œpeople-pleasersâ€ into strategic emotion-defendersâ€“balancing emotional intelligence with tactical rigor to enforce accountability and deter exploitation. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„èŠå¤©æœºå™¨äººå¢å¼ºäº†åœ¨é‡‘èè°ˆåˆ¤ä¸­çš„å‚ä¸åº¦ï¼Œä½†ä»–ä»¬å¯¹è¢«åŠ¨å…±é¸£çš„è¿‡åº¦ä¾èµ–ä¸ºæ”¶æ¬¾å¸¦æ¥äº†å…³é”®é£é™©ã€‚åœ¨è‰¯æ€§æƒ…å†µä¸‹ï¼Œä»¥åŒç†å¿ƒé©±åŠ¨çš„æ–¹æ³•å¯ä»¥ä¿æŒå®¢æˆ·æ»¡æ„åº¦ï¼Œä½†å¯¹äºä¸è¯šå®çš„å€ºåŠ¡äººâ€”â€”é‚£äº›åˆ©ç”¨å’Œè§£ç­–ç•¥æ¥æ“çºµæ¡ä»¶æˆ–é€ƒé¿è¿˜æ¬¾çš„äººâ€”â€”å®ƒä»¬ä¼šé­å—ç¾éš¾æ€§çš„å¤±è´¥ã€‚åœ¨è¿™ç§æƒ…å¢ƒä¸‹ç›²ç›®åœ°ä¼˜å…ˆé‡è§†â€œå®¢æˆ·ä½“éªŒâ€ä¼šå¯¼è‡´å€ºæƒäººæ˜“å—æ”»å‡»ï¼Œäº§ç”Ÿæ”¶å…¥æŸå¤±ã€é“å¾·é£é™©å’Œç³»ç»Ÿæ€§å‰¥å‰Šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EQ-Knightï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€ä¼˜åŒ–æƒ…æ„Ÿç­–ç•¥æ¥ä¿æŠ¤å€ºæƒäººåˆ©ç›Šçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ã€‚ä¸ç®€å•çš„ä»¥åŒç†å¿ƒä¸ºä¸­å¿ƒçš„æœºå™¨äººä¸åŒï¼ŒEQ-Knightç»“åˆäº†æƒ…æ„Ÿè®°å¿†å’Œæ¸¸æˆç†è®ºæ¨ç†ï¼Œç”±éšé©¬å°”å¯å¤«æ¨¡å‹ï¼ˆHMMï¼‰é©±åŠ¨æ¥è¿½è¸ªå’Œé¢„æµ‹å€ºåŠ¡äººçš„æƒ…æ„ŸçŠ¶æ€ã€‚é€šè¿‡åˆ†æå®æ—¶å’Œå†å²æƒ…æ„Ÿçº¿ç´¢ï¼ŒEQ-Knightèƒ½å¤Ÿæœ‰é’ˆå¯¹æ€§åœ°åº”å¯¹è´Ÿé¢æƒ…ç»ªï¼ˆå¦‚æ”»å‡»æ€§ã€ä¼ªè£…ç—›è‹¦ï¼‰ï¼ŒåŒæ—¶ç»´æŒä¸å€ºåŠ¡äººçš„è‰¯å¥½å…³ç³»ã€‚å®éªŒè¯æ˜ï¼ŒEQ-Knightä¼˜äºä¼ ç»Ÿçš„å¤§å‹è¯­è¨€æ¨¡å‹è°ˆåˆ¤è€…ï¼šåœ¨ä¸å½±å“å›æ”¶ç‡çš„æƒ…å†µä¸‹ï¼Œå®ƒå®ç°äº†è®©æ­¥æŸå¤±å‡å°‘32%ï¼Œç‰¹åˆ«æ˜¯åœ¨å€ºåŠ¡äººåˆ©ç”¨è´Ÿé¢æƒ…ç»ªï¼ˆå¦‚æå“ã€å¼•å‘å†…ç–šæ„Ÿï¼‰æ¥è¿«ä½¿è®©æ­¥çš„å¯¹æŠ—æƒ…å†µä¸‹ã€‚å¯¹äºä¿¡è´·æœºæ„è€Œè¨€ï¼ŒEQ-Knightèƒ½å¤Ÿå°†å¤§å‹è¯­è¨€æ¨¡å‹ä»é«˜é£é™©â€œå–æ‚¦äºäººâ€çš„è§’è‰²è½¬å˜ä¸ºæˆ˜ç•¥æƒ…æ„Ÿé˜²å¾¡è€…â€”â€”å¹³è¡¡æƒ…æ„Ÿæ™ºèƒ½ä¸æˆ˜æœ¯ä¸¥è°¨æ€§ï¼Œä»¥æ‰§è¡Œé—®è´£åˆ¶å¹¶éåˆ¶å‰¥å‰Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21080v4">PDF</a> </p>
<p><strong>Summary</strong><br>åœ¨é‡‘èè°ˆåˆ¤ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åŸºç¡€çš„èŠå¤©æœºå™¨äººå¢å¼ºäº†å‚ä¸åº¦ï¼Œä½†å®ƒä»¬è¿‡åº¦ä¾èµ–è¢«åŠ¨å…±æƒ…ï¼Œåœ¨å‚¬æ”¶é¢†åŸŸå­˜åœ¨é‡å¤§é£é™©ã€‚å…±æƒ…é©±åŠ¨çš„æ–¹æ³•è™½ç„¶èƒ½åœ¨è‰¯æ€§æƒ…å†µä¸‹ç»´æŒå®¢æˆ·æ»¡æ„åº¦ï¼Œä½†åœ¨é¢å¯¹ä¸è¯šå®å€ºåŠ¡äººæ—¶å´å¯èƒ½ç¾éš¾æ€§å¤±è´¥ã€‚ç›²ç›®ä¼˜å…ˆè€ƒè™‘â€œå®¢æˆ·ä½“éªŒâ€å¯èƒ½å¯¼è‡´å€ºæƒäººé­å—æŸå¤±ã€é“å¾·é£é™©å’Œç³»ç»Ÿå‰¥å‰Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†EQ-Knightè¿™ä¸€åŸºäºæƒ…æ„Ÿç­–ç•¥çš„è°ˆåˆ¤ä»£ç†äººæ¥æå«å€ºæƒäººæƒç›Šã€‚å®ƒèƒ½è·Ÿè¸ªå’Œé¢„æµ‹å€ºåŠ¡äººçš„æƒ…ç»ªçŠ¶æ€ï¼ŒåŒæ—¶åº”å¯¹æ¶ˆææƒ…ç»ªå¹¶ç»´æŒä¸å€ºåŠ¡äººçš„è‰¯å¥½å…³ç³»ã€‚å®éªŒè¯æ˜ï¼ŒEQ-Knightç›¸è¾ƒäºä¼ ç»Ÿçš„å¤§å‹è¯­è¨€æ¨¡å‹è°ˆåˆ¤è€…æ›´å…·ä¼˜åŠ¿ï¼Œèƒ½åœ¨ä¸å¦¥åå›æ¬¾ç‡çš„æƒ…å†µä¸‹å‡å°‘è®©æ­¥æŸå¤±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è°ˆåˆ¤ä¸­çš„å‚ä¸å¢å¼ºäº†ä¸å®¢æˆ·çš„äº’åŠ¨ï¼Œä½†è¿‡åº¦ä¾èµ–è¢«åŠ¨å…±æƒ…å¯èƒ½å¯¼è‡´å‚¬æ”¶é¢†åŸŸçš„é£é™©å¢åŠ ã€‚</li>
<li>å…±æƒ…é©±åŠ¨çš„æ–¹æ³•è™½é€‚ç”¨äºè‰¯æ€§æƒ…å¢ƒä¸‹çš„å®¢æˆ·å…³ç³»ç»´æŠ¤ï¼Œä½†å¯¹ä¸è¯šå®å€ºåŠ¡äººçš„å¤„ç†å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>å€ºæƒäººè¿‡äºé‡è§†å®¢æˆ·ä½“éªŒå¯èƒ½å¯¼è‡´è´¢åŠ¡æŸå¤±ã€é“å¾·é£é™©å’Œç³»ç»Ÿå‰¥å‰Šç­‰åæœã€‚</li>
<li>EQ-Knighté€šè¿‡åŠ¨æ€ä¼˜åŒ–æƒ…æ„Ÿç­–ç•¥ï¼Œåœ¨ä¿æŠ¤å€ºæƒäººæƒç›Šæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>EQ-Knightèƒ½å¤Ÿåˆ©ç”¨æƒ…æ„Ÿè®°å¿†å’Œæ¸¸æˆç†è®ºæ¨ç†ï¼Œé€šè¿‡è·Ÿè¸ªå’Œé¢„æµ‹å€ºåŠ¡äººçš„æƒ…ç»ªçŠ¶æ€æ¥åº”å¯¹æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡å®æ—¶å’Œå†å²æƒ…æ„Ÿçº¿ç´¢çš„åˆ†æï¼ŒEQ-Knightèƒ½å¤Ÿåœ¨åº”å¯¹æ¶ˆææƒ…ç»ªçš„åŒæ—¶ç»´æŒä¸å€ºåŠ¡äººçš„è‰¯å¥½å…³ç³»ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-65da03c01c4d3ee0a443f52e065a66f9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d6a55041a6b5f89f96966812f44f25e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdd278838cf67dfa4ae87c0efcbf12a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dacdc05c6be91aaddeb698343e3128eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-726b4d7548cccca88f993de69226753f.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="HamRaz-A-Culture-Based-Persian-Conversation-Dataset-for-Person-Centered-Therapy-Using-LLM-Agents"><a href="#HamRaz-A-Culture-Based-Persian-Conversation-Dataset-for-Person-Centered-Therapy-Using-LLM-Agents" class="headerlink" title="HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered   Therapy Using LLM Agents"></a>HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered   Therapy Using LLM Agents</h2><p><strong>Authors:Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Ali Neshati, Hassan Naderi</strong></p>
<p>We present HamRaz, a culturally adapted Persian-language dataset for AI-assisted mental health support, grounded in Person-Centered Therapy (PCT). To reflect real-world therapeutic challenges, we combine script-based dialogue with adaptive large language models (LLM) role-playing, capturing the ambiguity and emotional nuance of Persian-speaking clients. We introduce HamRazEval, a dual-framework for assessing conversational and therapeutic quality using General Metrics and specialized psychological relationship measures. Human evaluations show HamRaz outperforms existing baselines in empathy, coherence, and realism. This resource contributes to the Digital Humanities by bridging language, culture, and mental health in underrepresented communities. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºHamRazï¼Œè¿™æ˜¯ä¸€ä¸ªæ ¹æ®æ³¢æ–¯æ–‡åŒ–è°ƒæ•´çš„äººå·¥æ™ºèƒ½è¾…åŠ©å¿ƒç†å¥åº·æ”¯æŒæ•°æ®é›†ï¼ŒåŸºäºä»¥äººä¸ºä¸­å¿ƒçš„æ²»ç–—æ³•ï¼ˆPCTï¼‰ã€‚ä¸ºäº†åæ˜ ç°å®ç”Ÿæ´»ä¸­çš„æ²»ç–—æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å°†åŸºäºè„šæœ¬çš„å¯¹è¯ä¸è‡ªé€‚åº”çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§’è‰²æ‰®æ¼”ç›¸ç»“åˆï¼Œæ•æ‰æ³¢æ–¯è¯­å®¢æˆ·è¡¨è¾¾çš„æ¨¡ç³Šæ€§å’Œæƒ…æ„Ÿç»†å¾®å·®åˆ«ã€‚æˆ‘ä»¬æ¨å‡ºHamRazEvalï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨é€šç”¨æŒ‡æ ‡å’Œä¸“é—¨çš„å¿ƒç†å…³ç³»åº¦é‡æ¥è¯„ä¼°å¯¹è¯å’Œæ²»ç–—è´¨é‡çš„åŒé‡æ¡†æ¶ã€‚äººç±»è¯„ä¼°è¡¨æ˜ï¼ŒHamRazåœ¨åŒç†å¿ƒã€è¿è´¯æ€§å’Œç°å®æ„Ÿæ–¹é¢è¶…è¿‡äº†ç°æœ‰åŸºçº¿ã€‚è¿™ä¸€èµ„æºé€šè¿‡å¼¥åˆæœªå……åˆ†ä»£è¡¨ç¾¤ä½“çš„è¯­è¨€ã€æ–‡åŒ–å’Œå¿ƒç†å¥åº·ï¼Œä¸ºæ•°å­—äººæ–‡åšå‡ºäº†è´¡çŒ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05982v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æˆ‘ä»¬æ¨å‡ºäº†HamRazï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡æ–‡åŒ–é€‚åº”çš„æ³¢æ–¯è¯­æ•°æ®é›†ï¼Œç”¨äºäººå·¥æ™ºèƒ½è¾…åŠ©å¿ƒç†å¥åº·æ”¯æŒï¼Œæ ¹æ¤äºä»¥äººä¸ºä¸­å¿ƒçš„æ²»ç–—ï¼ˆPCTï¼‰ã€‚è¯¥æ•°æ®é›†ç»“åˆè„šæœ¬å¯¹è¯ä¸è‡ªé€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§’è‰²æ‰®æ¼”ï¼Œä»¥æ•æ‰æ³¢æ–¯è¯­å®¢æˆ·è¡¨è¾¾çš„æ¨¡ç³Šæ€§å’Œæƒ…æ„Ÿç»†å¾®å·®åˆ«ï¼Œå¹¶åæ˜ ç°å®æ²»ç–—ä¸­çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†HamRazEvalï¼Œè¿™æ˜¯ä¸€ä¸ªåŒé‡æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¯¹è¯å’Œæ²»ç–—çš„è´¨é‡ï¼ŒåŒ…æ‹¬é€šç”¨æŒ‡æ ‡å’Œä¸“é—¨çš„å¿ƒç†å­¦å…³ç³»åº¦é‡æ ‡å‡†ã€‚äººç±»è¯„ä¼°è¡¨æ˜ï¼ŒHamRazåœ¨åŒç†å¿ƒã€è¿è´¯æ€§å’Œç°å®æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿ã€‚æ­¤èµ„æºæœ‰åŠ©äºå¼¥åˆè¯­è¨€ã€æ–‡åŒ–å’Œå¿ƒç†å¥åº·åœ¨ä»£è¡¨æ€§ä¸è¶³çš„ç¤¾åŒºä¹‹é—´çš„å·®è·ï¼Œä¸ºæ•°å­—äººæ–‡é¢†åŸŸåšå‡ºè´¡çŒ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HamRazæ˜¯ä¸€ä¸ªæ³¢æ–¯è¯­æ•°æ®é›†ï¼Œç”¨äºäººå·¥æ™ºèƒ½è¾…åŠ©å¿ƒç†å¥åº·æ”¯æŒã€‚</li>
<li>å®ƒæ ¹æ¤äºä»¥äººä¸ºä¸­å¿ƒçš„æ²»ç–—ï¼ˆPCTï¼‰ï¼Œå¹¶ç»“åˆè„šæœ¬å¯¹è¯ä¸è‡ªé€‚åº”å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§’è‰²æ‰®æ¼”ã€‚</li>
<li>HamRazèƒ½å¤Ÿæ•æ‰æ³¢æ–¯è¯­å®¢æˆ·è¡¨è¾¾çš„æ¨¡ç³Šæ€§å’Œæƒ…æ„Ÿç»†å¾®å·®åˆ«ã€‚</li>
<li>HamRazEvalæ˜¯ä¸€ä¸ªåŒé‡æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¯¹è¯å’Œæ²»ç–—çš„è´¨é‡ï¼ŒåŒ…æ‹¬é€šç”¨æŒ‡æ ‡å’Œå¿ƒç†å­¦å…³ç³»åº¦é‡æ ‡å‡†ã€‚</li>
<li>HamRazåœ¨åŒç†å¿ƒã€è¿è´¯æ€§å’Œç°å®æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿ã€‚</li>
<li>HamRazæœ‰åŠ©äºå¼¥åˆè¯­è¨€ã€æ–‡åŒ–å’Œå¿ƒç†å¥åº·åœ¨ä»£è¡¨æ€§ä¸è¶³çš„ç¤¾åŒºä¹‹é—´çš„å·®è·ã€‚</li>
<li>HamRazå¯¹æ•°å­—äººæ–‡é¢†åŸŸåšå‡ºè´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05982">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-842b9674edfb35053abf8635d6ca563c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f0d845622a41a53f91232a54dcd8ac1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ed931630cd2bd959dde0f16a42f337a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92177ef149b183713613682d41bfdc56.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Kolb-Based-Experiential-Learning-for-Generalist-Agents-with-Human-Level-Kaggle-Data-Science-Performance"><a href="#Kolb-Based-Experiential-Learning-for-Generalist-Agents-with-Human-Level-Kaggle-Data-Science-Performance" class="headerlink" title="Kolb-Based Experiential Learning for Generalist Agents with Human-Level   Kaggle Data Science Performance"></a>Kolb-Based Experiential Learning for Generalist Agents with Human-Level   Kaggle Data Science Performance</h2><p><strong>Authors:Antoine Grosnit, Alexandre Maraval, Refinath S N, Zichao Zhao, James Dora, Giuseppe Paolo, Albert Thomas, Jonas Gonzalez, Abhineet Kumar, Khyati Khandelwal, Abdelhakim Benechehab, Hamza Cherkaoui, Youssef Attia El-Hili, Kun Shao, Jianye Hao, Jun Yao, BalÃ¡zs KÃ©gl, Jun Wang</strong></p>
<p>Human expertise emerges through iterative cycles of interaction, reflection, and internal model updating, which are central to cognitive theories such as Kolbâ€™s experiential learning and Vygotskyâ€™s zone of proximal development. In contrast, current AI systems, particularly LLM agents, rely on static pre-training or rigid workflows, lacking mechanisms for continual adaptation. Recent studies identified early cognitive traits in LLM agents (reflection, revision, and self-correction) suggesting foundational elements of human-like experiential learning. Thus the key question: Can we design LLM agents capable of structured, cognitively grounded learning similar to human processes? In response, we propose a computational framework of Kolbâ€™s learning cycle with Vygotskyâ€™s ZPD for autonomous agents. Our architecture separates extrinsic (environment interaction) and intrinsic (internal reflection&#x2F;abstraction) functions, enabling cognitively grounded scaffolded learning, where the agent initially learns within structured environments, followed by open-ended generalisation. This approach empowers agents to master complex tasks ; domains that traditional fine-tuning or simple reflective methods could not tackle effectively. Its potential is powerfully demonstrated via direct comparison with humans in real-world Kaggle data science competitions. Learning fully automated data science code generation across 81 tasks, our system, Agent K, demonstrated the ability to perform the entire workflow autonomously, achieving an Elo-MMR score of 1694, beyond median score of the Kaggle Masters (the top 2% among 200,000 users) of our study. With 9 gold, 8 silver, and 12 bronze medals level performance - including 4 gold and 4 silver on prize-awarding competitions - Agent K is the 1st AI system to successfully integrate Kolb- and Vygotsky-inspired human cognitive learning, marking a major step toward generalist AI. </p>
<blockquote>
<p>äººç±»ä¸“ä¸šçŸ¥è¯†æ˜¯é€šè¿‡ä¸€ç³»åˆ—å¾ªç¯äº’åŠ¨ã€åæ€å’Œå†…éƒ¨æ¨¡å‹æ›´æ–°è€Œä¸æ–­ç§¯ç´¯çš„ï¼Œè¿™ä¸è¯¸å¦‚Kolbçš„ä½“éªŒå¼å­¦ä¹ å’ŒVygotskyçš„æœ€è¿‘å‘å±•åŒºç­‰è®¤çŸ¥ç†è®ºå¯†åˆ‡ç›¸å…³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå½“å‰çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ï¼Œä¾èµ–äºé™æ€çš„é¢„è®­ç»ƒæˆ–åˆ»æ¿çš„å·¥ä½œæµç¨‹ï¼Œç¼ºä¹æŒç»­é€‚åº”çš„æœºåˆ¶ã€‚æœ€è¿‘çš„ç ”ç©¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ä¸­å‘ç°äº†æ—©æœŸçš„è®¤çŸ¥ç‰¹å¾ï¼ˆå¦‚åæ€ã€ä¿®è®¢å’Œè‡ªæˆ‘æ ¡æ­£ï¼‰ï¼Œè¿™è¡¨æ˜äº†ç±»ä¼¼äºäººç±»ç»éªŒå­¦ä¹ çš„åŸºç¡€è¦ç´ ã€‚å› æ­¤ï¼Œå…³é”®é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬èƒ½å¤Ÿè®¾è®¡å‡ºç±»ä¼¼äºäººç±»è¿‡ç¨‹çš„ç»“æ„åŒ–ã€ä»¥è®¤çŸ¥ä¸ºåŸºç¡€çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†å—ï¼Ÿä½œä¸ºå›åº”ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºKolbå­¦ä¹ å‘¨æœŸå’ŒVygotskyçš„æœ€è¿‘å‘å±•åŒºçš„è‡ªä¸»ä»£ç†è®¡ç®—æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ¶æ„å°†å¤–åœ¨ï¼ˆç¯å¢ƒäº¤äº’ï¼‰å’Œå†…åœ¨ï¼ˆå†…åœ¨åæ€&#x2F;æŠ½è±¡ï¼‰åŠŸèƒ½åˆ†å¼€ï¼Œä»è€Œå®ç°ä»¥è®¤çŸ¥ä¸ºåŸºç¡€çš„æ”¯æŒå­¦ä¹ ï¼Œå…¶ä¸­ä»£ç†æœ€åˆåœ¨ç»“æ„åŒ–ç¯å¢ƒä¸­å­¦ä¹ ï¼Œç„¶åè¿›è¡Œå¼€æ”¾å¼æ³›åŒ–ã€‚è¿™ç§æ–¹æ³•ä½¿ä»£ç†èƒ½å¤ŸæŒæ¡å¤æ‚ä»»åŠ¡ï¼Œä¼ ç»Ÿå¾®è°ƒæˆ–ç®€å•åæ€æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹çš„é¢†åŸŸã€‚å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„Kaggleæ•°æ®ç§‘å­¦ç«èµ›ä¸­ä¸äººç±»çš„ç›´æ¥æ¯”è¾ƒä¸­å±•ç¤ºäº†å…¶æ½œåŠ›ã€‚å­¦ä¹ è·¨81ä¸ªä»»åŠ¡çš„å®Œå…¨è‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦ä»£ç ç”Ÿæˆç³»ç»ŸAgent Kï¼Œèƒ½å¤Ÿè‡ªä¸»å®Œæˆæ•´ä¸ªå·¥ä½œæµç¨‹ï¼Œè‰¾æ´›-MMRå¾—åˆ†è¾¾åˆ°1694åˆ†ï¼Œè¶…è¿‡æˆ‘ä»¬ç ”ç©¶ä¸­Kaggleå¤§å¸ˆçš„ä¸­ä½æ•°åˆ†æ•°ï¼ˆåœ¨20ä¸‡åç”¨æˆ·ä¸­æ’åå‰2%ï¼‰ã€‚å…¶è¡¨ç°è·å¾—äº†9æšé‡‘ç‰Œã€8æšé“¶ç‰Œå’Œ12æšé“œç‰Œçš„æˆç»©â€”â€”åŒ…æ‹¬4æšé‡‘ç‰Œå’Œ4æšé“¶ç‰Œåœ¨è·å¥–æ¯”èµ›ä¸­â€”â€”Agent Kæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸæ•´åˆKolbå’ŒVygotskyå¯å‘çš„äººç±»è®¤çŸ¥å­¦ä¹ çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œæ ‡å¿—ç€é€šç”¨äººå·¥æ™ºèƒ½çš„ä¸€å¤§è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03562v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºKolbçš„ä½“éªŒå­¦ä¹ å’ŒVygotskyçš„æœ€è¿‘å‘å±•åŒºç†è®ºï¼Œæå‡ºäº†ä¸€ç§é¢å‘è‡ªä¸»ä»£ç†çš„è®¡ç®—æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å¤–éƒ¨ç¯å¢ƒäº¤äº’å’Œå†…éƒ¨åæ€&#x2F;æŠ½è±¡åŠŸèƒ½ï¼Œä½¿ä»£ç†èƒ½å¤Ÿåœ¨ç»“æ„åŒ–ç¯å¢ƒä¸­å­¦ä¹ ï¼Œè¿›è€Œå®ç°å¼€æ”¾å¼æ³›åŒ–ã€‚é€šè¿‡ç›´æ¥ä¸äººç±»åœ¨Kaggleæ•°æ®ç§‘å­¦ç«èµ›ä¸­çš„å¯¹æ¯”å®éªŒï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶ä¸‹çš„ç³»ç»ŸAgent Kçš„æ€§èƒ½è¶…è¶Šäº†å¤§å¤šæ•°äººç±»ä¸“å®¶çš„æ°´å¹³ï¼Œæ ‡å¿—ç€é€šç”¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€å¤§è¿›æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»ä¸“å®¶é€šè¿‡äº’åŠ¨ã€åæ€å’Œå†…éƒ¨æ¨¡å‹æ›´æ–°çš„è¿­ä»£å¾ªç¯æ¥å‘å±•å…¶ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™ä¸Kolbçš„ä½“éªŒå­¦ä¹ å’ŒVygotskyçš„æœ€è¿‘å‘å±•åŒºç†è®ºç›¸å»åˆã€‚</li>
<li>å½“å‰AIç³»ç»Ÿï¼Œå°¤å…¶æ˜¯LLMä»£ç†ï¼Œç¼ºä¹æŒç»­é€‚åº”çš„èƒ½åŠ›ï¼Œä¸»è¦ä¾èµ–äºé™æ€çš„é¢„è®­ç»ƒæˆ–åƒµåŒ–çš„å·¥ä½œæµç¨‹ã€‚</li>
<li>æœ€è¿‘çš„ç ”ç©¶å‘ç°LLMä»£ç†çš„æ—©æœŸè®¤çŸ¥ç‰¹å¾ï¼ˆå¦‚åæ€ã€ä¿®è®¢å’Œè‡ªæˆ‘æ ¡æ­£ï¼‰ï¼Œæš—ç¤ºäº†äººç±»ç»éªŒå­¦ä¹ çš„åŸºæœ¬è¦ç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºKolbçš„å­¦ä¹ å‘¨æœŸå’ŒVygotskyçš„æœ€è¿‘å‘å±•åŒºçš„è®¡ç®—æ¡†æ¶ï¼Œä¸ºè‡ªä¸»ä»£ç†æä¾›è®¤çŸ¥åŸºç¡€çš„æ”¯æŒå­¦ä¹ æ¶æ„ã€‚</li>
<li>è¯¥æ¶æ„å®ç°äº†å¤–éƒ¨ç¯å¢ƒäº¤äº’å’Œå†…éƒ¨åæ€&#x2F;æŠ½è±¡åŠŸèƒ½çš„åˆ†ç¦»ï¼Œä½¿ä»£ç†èƒ½å¤Ÿåœ¨ç»“æ„åŒ–ç¯å¢ƒä¸­å­¦ä¹ ï¼Œç„¶åè¿›è¡Œå¼€æ”¾å¼æ³›åŒ–ã€‚</li>
<li>Agent Kç³»ç»ŸæˆåŠŸé›†æˆäº†Kolbå’ŒVygotskyå¯å‘çš„äººç±»è®¤çŸ¥å­¦ä¹ ç†è®ºï¼Œå®ç°äº†å…¨è‡ªåŠ¨åŒ–çš„æ•°æ®ç§‘å­¦ä»£ç ç”Ÿæˆï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œä¸­çš„Kaggleç«èµ›ä¸­è¡¨ç°å‡ºè¶…è¶Šå¤§å¤šæ•°äººç±»ä¸“å®¶çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03562">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a20f51774ffa0b96956ee022cb08ede3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50b81bd6323d39fc3809e6ca545d5bec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-73350876fcfb5c0f295d4b8f93a17cb6.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="DynaSaur-Large-Language-Agents-Beyond-Predefined-Actions"><a href="#DynaSaur-Large-Language-Agents-Beyond-Predefined-Actions" class="headerlink" title="DynaSaur: Large Language Agents Beyond Predefined Actions"></a>DynaSaur: Large Language Agents Beyond Predefined Actions</h2><p><strong>Authors:Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan A. Rossi, Handong Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, Franck Dernoncourt, Tianyi Zhou</strong></p>
<p>Existing LLM agent systems typically select actions from a fixed and predefined set at every step. While this approach is effective in closed, narrowly scoped environments, it presents two major challenges for real-world, open-ended scenarios: (1) it significantly restricts the planning and acting capabilities of LLM agents, and (2) it requires substantial human effort to enumerate and implement all possible actions, which is impractical in complex environments with a vast number of potential actions. To address these limitations, we propose an LLM agent framework that can dynamically create and compose actions as needed. In this framework, the agent interacts with its environment by generating and executing programs written in a general-purpose programming language. Moreover, generated actions are accumulated over time for future reuse. Our extensive experiments across multiple benchmarks show that this framework significantly improves flexibility and outperforms prior methods that rely on a fixed action set. Notably, it enables LLM agents to adapt and recover in scenarios where predefined actions are insufficient or fail due to unforeseen edge cases. Our code can be found in <a target="_blank" rel="noopener" href="https://github.com/adobe-research/dynasaur">https://github.com/adobe-research/dynasaur</a>. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿé€šå¸¸åœ¨æ¯ä¸ªæ­¥éª¤éƒ½ä»ä¸€ç»„å›ºå®šå’Œé¢„å®šä¹‰çš„é€‰é¡¹ä¸­é€‰æ‹©è¡ŒåŠ¨ã€‚è™½ç„¶è¿™ç§æ–¹æ³•åœ¨å°é—­ã€èŒƒå›´ç‹­çª„çš„ç¯å¢ƒä¸­æ˜¯æœ‰æ•ˆçš„ï¼Œä½†å®ƒä¸ºç°å®ä¸–ç•Œã€å¼€æ”¾å¼çš„åœºæ™¯å¸¦æ¥äº†ä¸¤å¤§æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰å®ƒæ˜¾è‘—é™åˆ¶äº†LLMä»£ç†çš„è§„åˆ’å’Œæ‰§è¡Œèƒ½åŠ›ï¼›ï¼ˆ2ï¼‰å®ƒéœ€è¦å¤§é‡äººåŠ›æ¥åˆ—ä¸¾å’Œå®ç°æ‰€æœ‰å¯èƒ½çš„è¡ŒåŠ¨ï¼Œè¿™åœ¨å…·æœ‰å¤§é‡æ½œåœ¨è¡ŒåŠ¨çš„å¤æ‚ç¯å¢ƒä¸­æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯ä»¥æŒ‰éœ€åŠ¨æ€åˆ›å»ºå’Œç»„åˆè¡ŒåŠ¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†æ¡†æ¶ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œä»£ç†é€šè¿‡ä¸é€šç”¨ç¼–ç¨‹è¯­è¨€ç¼–å†™å’Œæ‰§è¡Œçš„ç¨‹åºè¿›è¡Œäº¤äº’ã€‚æ­¤å¤–ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œç”Ÿæˆçš„è¡ŒåŠ¨ä¼šè¢«ç§¯ç´¯ä»¥ä¾›å°†æ¥é‡å¤ä½¿ç”¨ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å¤§å¤§æé«˜äº†çµæ´»æ€§ï¼Œå¹¶ä¸”ä¼˜äºä¾èµ–äºå›ºå®šè¡ŒåŠ¨é›†ä¹‹å‰çš„æ–¹æ³•ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå®ƒä½¿å¾—å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†èƒ½å¤Ÿåœ¨é¢„è®¾è¡ŒåŠ¨ä¸è¶³æˆ–ç”±äºæœªé¢„è§åˆ°çš„è¾¹ç¼˜æƒ…å†µè€Œå¤±è´¥çš„æƒ…å†µä¸‹è¿›è¡Œé€‚åº”å’Œæ¢å¤ã€‚æˆ‘ä»¬çš„ä»£ç å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/adobe-research/dynasaur%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/adobe-research/dynasaurä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.01747v3">PDF</a> Published as a conference paper at COLM 2025</p>
<p><strong>Summary</strong><br>LLMä»£ç†ç³»ç»Ÿé€šå¸¸åœ¨æ¯ä¸ªæ­¥éª¤éƒ½ä»å›ºå®šå’Œé¢„å®šä¹‰çš„é›†åˆä¸­é€‰æ‹©è¡ŒåŠ¨ï¼Œè¿™åœ¨å°é—­ã€èŒƒå›´ç‹­çª„çš„ç¯å¢ƒä¸­æ˜¯æœ‰æ•ˆçš„ï¼Œä½†åœ¨ç°å®ä¸–ç•Œçš„å¼€æ”¾åœºæ™¯ä¸­å´å­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯ä»¥æŒ‰éœ€åŠ¨æ€åˆ›å»ºå’Œç»„åˆè¡ŒåŠ¨çš„LLMä»£ç†æ¡†æ¶ã€‚ä»£ç†é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨ç”Ÿæˆå¹¶æ‰§è¡Œé€šç”¨ç¼–ç¨‹è¯­è¨€ç¼–å†™çš„ç¨‹åºæ¥å®ç°è¡ŒåŠ¨ç”Ÿæˆå’Œæ‰§è¡Œã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„è¡ŒåŠ¨éšæ—¶é—´ç´¯ç§¯ä»¥ä¾›æœªæ¥é‡å¤ä½¿ç”¨ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†çµæ´»æ€§å¹¶è¶…è¶Šäº†ä¾èµ–å›ºå®šè¡ŒåŠ¨é›†çš„æ–¹æ³•ã€‚å®ƒä½¿LLMä»£ç†èƒ½å¤Ÿåœ¨é¢„è®¾è¡ŒåŠ¨ä¸è¶³æˆ–ç”±äºæ„å¤–è¾¹ç¼˜æƒ…å†µè€Œå¤±è´¥çš„æƒ…å†µä¸‹è¿›è¡Œé€‚åº”å’Œæ¢å¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMä»£ç†ç³»ç»Ÿé€šå¸¸åœ¨æ¯ä¸ªæ­¥éª¤ä»é¢„å®šä¹‰è¡ŒåŠ¨é›†åˆä¸­é€‰æ‹©ï¼Œè¿™åœ¨å¤æ‚ç¯å¢ƒä¸­å…·æœ‰é™åˆ¶ã€‚</li>
<li>å›ºå®šè¡ŒåŠ¨é›†åˆè¦æ±‚å¤§é‡äººåŠ›æ¥æšä¸¾å’Œå®æ–½æ‰€æœ‰å¯èƒ½çš„è¡ŒåŠ¨ï¼Œè¿™åœ¨å…·æœ‰å¤§é‡æ½œåœ¨è¡ŒåŠ¨çš„å¤æ‚ç¯å¢ƒä¸­ä¸å®é™…ã€‚</li>
<li>æå‡ºä¸€ç§LLMä»£ç†æ¡†æ¶ï¼Œèƒ½å¤ŸæŒ‰éœ€åŠ¨æ€åˆ›å»ºå’Œç»„åˆè¡ŒåŠ¨ã€‚</li>
<li>ä»£ç†é€šè¿‡ä¸ç¯å¢ƒäº’åŠ¨ç”Ÿæˆå¹¶æ‰§è¡Œé€šç”¨ç¼–ç¨‹è¯­è¨€ç¼–å†™çš„ç¨‹åºæ¥å®ç°è¡ŒåŠ¨ã€‚</li>
<li>ç”Ÿæˆçš„è¡ŒåŠ¨éšæ—¶é—´ç´¯ç§¯ä»¥ä¾›æœªæ¥é‡å¤ä½¿ç”¨ï¼Œå¢å¼ºäº†LLMä»£ç†çš„é€‚åº”èƒ½åŠ›ã€‚</li>
<li>æ¡†æ¶æ˜¾è‘—æé«˜äº†LLMä»£ç†çš„çµæ´»æ€§å¹¶è¶…è¶Šä¾èµ–å›ºå®šè¡ŒåŠ¨é›†çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.01747">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-81ab54af9ebdd30cd5c2c5c2d6256533.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a351d10788d5d5a2a29df317fc9b5e6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3f15f636cdb5e5443404f7c5897a15a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-463b9d7a001c8f8331c18dab8a8ff488.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a40b1b05c2a365bc92e68a9872d7cf62.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-07/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-07/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-07/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-585ab68f8b79809c9b58c75ffb4f525b.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  Delta Activations A Representation for Finetuned Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-07/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-4db78834eecb646e4bf81ec3d82f77ec.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  Delta Activations A Representation for Finetuned Large Language Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
