<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  SSGaussian Semantic-Aware and Structure-Preserving 3D Style Transfer">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-69f2bfe6f45af1301fb21137b1b7cd75.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-30
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    81 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-07-æ›´æ–°"><a href="#2025-09-07-æ›´æ–°" class="headerlink" title="2025-09-07 æ›´æ–°"></a>2025-09-07 æ›´æ–°</h1><h2 id="SSGaussian-Semantic-Aware-and-Structure-Preserving-3D-Style-Transfer"><a href="#SSGaussian-Semantic-Aware-and-Structure-Preserving-3D-Style-Transfer" class="headerlink" title="SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer"></a>SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer</h2><p><strong>Authors:Jimin Xu, Bosheng Qin, Tao Jin, Zhou Zhao, Zhenhui Ye, Jun Yu, Fei Wu</strong></p>
<p>Recent advancements in neural representations, such as Neural Radiance Fields and 3D Gaussian Splatting, have increased interest in applying style transfer to 3D scenes. While existing methods can transfer style patterns onto 3D-consistent neural representations, they struggle to effectively extract and transfer high-level style semantics from the reference style image. Additionally, the stylized results often lack structural clarity and separation, making it difficult to distinguish between different instances or objects within the 3D scene. To address these limitations, we propose a novel 3D style transfer pipeline that effectively integrates prior knowledge from pretrained 2D diffusion models. Our pipeline consists of two key stages: First, we leverage diffusion priors to generate stylized renderings of key viewpoints. Then, we transfer the stylized key views onto the 3D representation. This process incorporates two innovative designs. The first is cross-view style alignment, which inserts cross-view attention into the last upsampling block of the UNet, allowing feature interactions across multiple key views. This ensures that the diffusion model generates stylized key views that maintain both style fidelity and instance-level consistency. The second is instance-level style transfer, which effectively leverages instance-level consistency across stylized key views and transfers it onto the 3D representation. This results in a more structured, visually coherent, and artistically enriched stylization. Extensive qualitative and quantitative experiments demonstrate that our 3D style transfer pipeline significantly outperforms state-of-the-art methods across a wide range of scenes, from forward-facing to challenging 360-degree environments. Visit our project page <a target="_blank" rel="noopener" href="https://jm-xu.github.io/SSGaussian">https://jm-xu.github.io/SSGaussian</a> for immersive visualization. </p>
<blockquote>
<p>è¿‘æœŸç¥ç»è¡¨å¾é¢†åŸŸçš„è¿›å±•ï¼Œå¦‚ç¥ç»è¾å°„åœºå’Œ3Dé«˜æ–¯å–·ç»˜ï¼Œå¢åŠ äº†å°†é£æ ¼è¿ç§»åº”ç”¨äº3Dåœºæ™¯çš„å…´è¶£ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•èƒ½å¤Ÿå°†é£æ ¼æ¨¡å¼è½¬ç§»åˆ°ä¸€è‡´çš„3Dç¥ç»è¡¨å¾ä¸Šï¼Œä½†å®ƒä»¬éš¾ä»¥æœ‰æ•ˆåœ°ä»å‚è€ƒé£æ ¼å›¾åƒä¸­æå–å¹¶è½¬ç§»é«˜çº§é£æ ¼è¯­ä¹‰ã€‚æ­¤å¤–ï¼Œé£æ ¼åŒ–çš„ç»“æœé€šå¸¸ç¼ºä¹ç»“æ„æ¸…æ™°åº¦å’Œåˆ†ç¦»åº¦ï¼Œä½¿å¾—éš¾ä»¥åŒºåˆ†3Dåœºæ™¯ä¸­çš„ä¸åŒå®ä¾‹æˆ–å¯¹è±¡ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„3Dé£æ ¼è¿ç§»ç®¡é“ï¼Œè¯¥ç®¡é“æœ‰æ•ˆåœ°ç»“åˆäº†æ¥è‡ªé¢„è®­ç»ƒçš„2Dæ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬çš„ç®¡é“åŒ…æ‹¬ä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šé¦–å…ˆï¼Œæˆ‘ä»¬åˆ©ç”¨æ‰©æ•£å…ˆéªŒçŸ¥è¯†ç”Ÿæˆå…³é”®è§†ç‚¹çš„é£æ ¼åŒ–æ¸²æŸ“ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†é£æ ¼åŒ–çš„å…³é”®è§†å›¾è½¬ç§»åˆ°3Dè¡¨å¾ä¸Šã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…å«ä¸¤ä¸ªåˆ›æ–°çš„è®¾è®¡ã€‚ç¬¬ä¸€ä¸ªæ˜¯è·¨è§†å›¾é£æ ¼å¯¹é½ï¼Œå®ƒå°†è·¨è§†å›¾æ³¨æ„åŠ›æ’å…¥åˆ°UNetçš„æœ€åä¸€ä¸ªä¸Šé‡‡æ ·å—ä¸­ï¼Œå…è®¸è·¨å¤šä¸ªå…³é”®è§†å›¾è¿›è¡Œç‰¹å¾äº¤äº’ã€‚è¿™ç¡®ä¿æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é£æ ¼åŒ–å…³é”®è§†å›¾æ—¢ä¿æŒé£æ ¼å¿ å®åº¦åˆä¿æŒå®ä¾‹çº§ä¸€è‡´æ€§ã€‚ç¬¬äºŒä¸ªæ˜¯å®ä¾‹çº§é£æ ¼è¿ç§»ï¼Œå®ƒæœ‰æ•ˆåœ°åˆ©ç”¨é£æ ¼åŒ–å…³é”®è§†å›¾ä¹‹é—´çš„å®ä¾‹çº§ä¸€è‡´æ€§å¹¶å°†å…¶è½¬ç§»åˆ°3Dè¡¨å¾ä¸Šã€‚è¿™äº§ç”Ÿäº†ä¸€ä¸ªæ›´å…·ç»“æ„æ€§çš„ã€è§†è§‰è¿è´¯çš„ã€è‰ºæœ¯æ„Ÿå¢å¼ºçš„é£æ ¼åŒ–ç»“æœã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„3Dé£æ ¼è¿ç§»ç®¡é“åœ¨å¹¿æ³›çš„åœºæ™¯ä¸Šæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä»æ­£é¢åˆ°å…·æœ‰æŒ‘æˆ˜æ€§çš„360åº¦ç¯å¢ƒã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢<a target="_blank" rel="noopener" href="https://jm-xu.github.io/SSGaussian%E4%BB%A5%E8%8E%B7%E5%8F%96%E6%B2%89%E6%B5%B8%E5%BC%8F%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BD%93%E9%AA%8C%E3%80%82">https://jm-xu.github.io/SSGaussianä»¥è·å–æ²‰æµ¸å¼å¯è§†åŒ–ä½“éªŒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04379v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°†é£æ ¼è¿ç§»åº”ç”¨äº3Dåœºæ™¯çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†é¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„3Dé£æ ¼è¿ç§»ç®¡é“ï¼Œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆåˆ©ç”¨æ‰©æ•£å…ˆéªŒç”Ÿæˆå…³é”®è§†è§’çš„é£æ ¼åŒ–æ¸²æŸ“ï¼Œç„¶åå°†é£æ ¼åŒ–çš„å…³é”®è§†å›¾è½¬ç§»åˆ°3Dè¡¨ç¤ºä¸Šã€‚è¯¥ç®¡é“åŒ…æ‹¬ä¸¤ä¸ªåˆ›æ–°è®¾è®¡ï¼šè·¨è§†å›¾é£æ ¼å¯¹é½å’Œå®ä¾‹çº§é£æ ¼è¿ç§»ã€‚è·¨è§†å›¾é£æ ¼å¯¹é½ç¡®ä¿æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é£æ ¼åŒ–å…³é”®è§†å›¾æ—¢ä¿æŒé£æ ¼å¿ å®åº¦åˆä¿æŒå®ä¾‹çº§ä¸€è‡´æ€§ï¼›å®ä¾‹çº§é£æ ¼è¿ç§»åˆ™å°†å®ä¾‹çº§ä¸€è‡´æ€§åº”ç”¨åˆ°é£æ ¼åŒ–çš„å…³é”®è§†å›¾ä¸Šï¼Œå®ç°æ›´ç»“æ„åŒ–ã€è§†è§‰è¿è´¯å’Œè‰ºæœ¯ä¸°å¯Œçš„é£æ ¼åŒ–æ•ˆæœã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åœºæ™¯ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é£æ ¼è¿ç§»æŠ€æœ¯å·²åº”ç”¨äº3Dåœºæ™¯ï¼Œä½†ä»é¢ä¸´æå–å’Œè½¬ç§»é«˜å±‚æ¬¡é£æ ¼è¯­ä¹‰çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„3Dé£æ ¼è¿ç§»ç®¡é“ï¼Œç»“åˆäº†é¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>ç®¡é“åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç”Ÿæˆå…³é”®è§†è§’çš„é£æ ¼åŒ–æ¸²æŸ“ï¼Œç„¶åå°†é£æ ¼åŒ–çš„å…³é”®è§†å›¾è½¬ç§»åˆ°3Dè¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨äº†ä¸¤ä¸ªåˆ›æ–°è®¾è®¡ï¼šè·¨è§†å›¾é£æ ¼å¯¹é½å’Œå®ä¾‹çº§é£æ ¼è¿ç§»ã€‚</li>
<li>è·¨è§†å›¾é£æ ¼å¯¹é½ç¡®ä¿é£æ ¼åŒ–å…³é”®è§†å›¾çš„é£æ ¼å¿ å®åº¦å’Œå®ä¾‹çº§ä¸€è‡´æ€§ã€‚</li>
<li>å®ä¾‹çº§é£æ ¼è¿ç§»å¢å¼ºäº†é£æ ¼åŒ–çš„ç»“æ„åŒ–ã€è§†è§‰è¿è´¯æ€§å’Œè‰ºæœ¯æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šç§åœºæ™¯ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ab201b9002d3043f3c2fa757a2486aec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-51fbc68971f9c30676eea8e9113a3621.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa55afde79abd9b66db45961165ae60b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e5209a07d609d95b6437c0e0fb21acab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4f2fc2a761bda7a794279a51053eaaf3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f0820592e385239ef4b2825c3a2a9c03.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GRMM-Real-Time-High-Fidelity-Gaussian-Morphable-Head-Model-with-Learned-Residuals"><a href="#GRMM-Real-Time-High-Fidelity-Gaussian-Morphable-Head-Model-with-Learned-Residuals" class="headerlink" title="GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned   Residuals"></a>GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned   Residuals</h2><p><strong>Authors:Mohit Mendiratta, Mayur Deshmukh, Kartik Teotia, Vladislav Golyanik, Adam Kortylewski, Christian Theobalt</strong></p>
<p>3D Morphable Models (3DMMs) enable controllable facial geometry and expression editing for reconstruction, animation, and AR&#x2F;VR, but traditional PCA-based mesh models are limited in resolution, detail, and photorealism. Neural volumetric methods improve realism but remain too slow for interactive use. Recent Gaussian Splatting (3DGS) based facial models achieve fast, high-quality rendering but still depend solely on a mesh-based 3DMM prior for expression control, limiting their ability to capture fine-grained geometry, expressions, and full-head coverage. We introduce GRMM, the first full-head Gaussian 3D morphable model that augments a base 3DMM with residual geometry and appearance components, additive refinements that recover high-frequency details such as wrinkles, fine skin texture, and hairline variations. GRMM provides disentangled control through low-dimensional, interpretable parameters (e.g., identity shape, facial expressions) while separately modelling residuals that capture subject- and expression-specific detail beyond the base modelâ€™s capacity. Coarse decoders produce vertex-level mesh deformations, fine decoders represent per-Gaussian appearance, and a lightweight CNN refines rasterised images for enhanced realism, all while maintaining 75 FPS real-time rendering. To learn consistent, high-fidelity residuals, we present EXPRESS-50, the first dataset with 60 aligned expressions across 50 identities, enabling robust disentanglement of identity and expression in Gaussian-based 3DMMs. Across monocular 3D face reconstruction, novel-view synthesis, and expression transfer, GRMM surpasses state-of-the-art methods in fidelity and expression accuracy while delivering interactive real-time performance. </p>
<blockquote>
<p>3Då¯å˜æ¨¡å‹ï¼ˆ3DMMï¼‰å¯å®ç°é¢éƒ¨å‡ ä½•å½¢çŠ¶å’Œè¡¨æƒ…ç¼–è¾‘çš„é‡å»ºã€åŠ¨ç”»ä»¥åŠAR&#x2F;VRã€‚ä½†ä¼ ç»Ÿçš„åŸºäºPCAçš„ç½‘æ ¼æ¨¡å‹åœ¨åˆ†è¾¨ç‡ã€ç»†èŠ‚å’Œé€¼çœŸåº¦æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚ç¥ç»ä½“ç§¯æ³•æé«˜äº†é€¼çœŸåº¦ï¼Œä½†ç”¨äºäº¤äº’çš„é€Ÿç‡ä»ç„¶å¤ªæ…¢ã€‚æœ€è¿‘åŸºäºé«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰çš„é¢éƒ¨æ¨¡å‹å®ç°äº†å¿«é€Ÿé«˜è´¨é‡æ¸²æŸ“ï¼Œä½†ä»ç„¶ä»…ä¾èµ–äºåŸºäºç½‘æ ¼çš„3DMMå…ˆéªŒè¿›è¡Œè¡¨æƒ…æ§åˆ¶ï¼Œè¿™é™åˆ¶äº†å…¶æ•æ‰ç²¾ç»†å‡ ä½•å½¢çŠ¶ã€è¡¨æƒ…å’Œå…¨å¤´è¦†ç›–çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä»‹ç»äº†GRMMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¨å¤´é«˜æ–¯3Då¯å˜æ¨¡å‹ï¼Œå®ƒé€šè¿‡åŸºç¡€3DMMä¸æ®‹ä½™å‡ ä½•å’Œå¤–è§‚ç»„ä»¶ç›¸ç»“åˆï¼Œå¢åŠ äº†é™„åŠ ç²¾ç»†åº¦ï¼Œå¯ä»¥æ¢å¤é«˜é¢‘ç»†èŠ‚ï¼Œå¦‚çš±çº¹ã€çš®è‚¤çº¹ç†å’Œå‘é™…çº¿å˜åŒ–ã€‚GRMMé€šè¿‡ä½ç»´åº¦ã€å¯è§£é‡Šçš„å‚æ•°ï¼ˆä¾‹å¦‚èº«ä»½å½¢çŠ¶ã€é¢éƒ¨è¡¨æƒ…ï¼‰æä¾›äº†è§£è€¦æ§åˆ¶ï¼ŒåŒæ—¶åˆ†åˆ«å¯¹è¶…å‡ºåŸºç¡€æ¨¡å‹å®¹é‡çš„ç‰¹å®šä¸»ä½“å’Œè¡¨æƒ…ç»†èŠ‚è¿›è¡Œå»ºæ¨¡ã€‚ç²—ç³™è§£ç å™¨äº§ç”Ÿé¡¶ç‚¹çº§ç½‘æ ¼å˜å½¢ï¼Œç²¾ç»†è§£ç å™¨è¡¨ç¤ºæ¯ä¸ªé«˜æ–¯çš„å¤–è§‚ï¼Œä¸€ä¸ªè½»é‡çº§çš„CNNå¯¹æ¸²æŸ“çš„å›¾åƒè¿›è¡Œç»†åŒ–ï¼Œä»¥å¢å¼ºé€¼çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒ75 FPSçš„å®æ—¶æ¸²æŸ“ã€‚ä¸ºäº†å­¦ä¹ ä¸€è‡´çš„é«˜ä¿çœŸæ®‹å·®ï¼Œæˆ‘ä»¬æ¨å‡ºäº†EXPRESS-50æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«50ä¸ªèº«ä»½çš„60ä¸ªå¯¹é½è¡¨æƒ…ï¼Œèƒ½å¤Ÿåœ¨åŸºäºé«˜æ–¯åˆ†å¸ƒçš„3DMMä¸­å®ç°èº«ä»½å’Œè¡¨æƒ…çš„ç¨³å¥è§£è€¦ã€‚åœ¨å•çœ¼3Dé¢éƒ¨é‡å»ºã€æ–°è§†è§’åˆæˆå’Œè¡¨æƒ…è½¬ç§»æ–¹é¢ï¼ŒGRMMåœ¨ä¿çœŸåº¦å’Œè¡¨æƒ…å‡†ç¡®æ€§æ–¹é¢è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶æä¾›äº†äº¤äº’å¼å®æ—¶æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.02141v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://mohitm1994.github.io/GRMM/">https://mohitm1994.github.io/GRMM/</a></p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§å…¨æ–°çš„å…¨å¤´é«˜æ–¯ä¸‰ç»´å¯å˜å½¢æ¨¡å‹GRMMï¼Œå®ƒé€šè¿‡å¢åŠ åŸºç¡€ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æ®‹ä½™å‡ ä½•å’Œå¤–è§‚æˆåˆ†ï¼Œå®ç°äº†å¿«é€Ÿé«˜è´¨é‡æ¸²æŸ“ï¼Œå¹¶èƒ½æ§åˆ¶é¢éƒ¨å‡ ä½•å½¢çŠ¶å’Œè¡¨æƒ…ã€‚GRMMèƒ½å¤Ÿæ•æ‰é«˜é¢‘ç»†èŠ‚ï¼Œå¦‚çš±çº¹ã€çš®è‚¤çº¹ç†å’Œå¤´å‘çº¿å˜åŒ–ç­‰ã€‚å®ƒé€šè¿‡ä½ç»´åº¦ã€å¯è§£é‡Šçš„å‚æ•°ï¼ˆå¦‚èº«ä»½å½¢çŠ¶ã€é¢éƒ¨è¡¨æƒ…ï¼‰æä¾›äº†è§£è€¦æ§åˆ¶ï¼ŒåŒæ—¶å»ºç«‹è¶…å‡ºåŸºç¡€æ¨¡å‹èƒ½åŠ›çš„æ®‹ä½™æ¨¡å‹ã€‚ç²—è§£ç å™¨äº§ç”Ÿé¡¶ç‚¹çº§ç½‘æ ¼å˜å½¢ï¼Œç²¾ç»†è§£ç å™¨è¡¨ç¤ºæ¯ä¸ªé«˜æ–¯çš„å¤–è§‚ï¼Œè½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œå¯¹æ¸²æŸ“å›¾åƒè¿›è¡Œå¾®è°ƒï¼Œä»¥å¢å¼ºçœŸå®æ„Ÿã€‚æ­¤å¤–ï¼Œä¸ºäº†å­¦ä¹ ä¸€è‡´çš„é«˜ä¿çœŸæ®‹ä½™æ¨¡å‹ï¼Œæœ¬æ–‡å¼•å…¥äº†EXPRESS-50æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«50ä¸ªèº«ä»½çš„60ä¸ªå¯¹é½è¡¨æƒ…ï¼Œä½¿é«˜æ–¯åŸºç¡€ä¸‰ç»´å¯å˜å½¢æ¨¡å‹çš„èº«ä»½å’Œè¡¨æƒ…è§£è€¦æ›´åŠ ç¨³å¥ã€‚åœ¨å•ç›®ä¸‰ç»´äººè„¸é‡å»ºã€æ–°è§†è§’åˆæˆå’Œè¡¨æƒ…è½¬ç§»ç­‰æ–¹é¢ï¼ŒGRMMåœ¨ä¿çœŸåº¦å’Œè¡¨æƒ…å‡†ç¡®æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶å®ç°äº†äº¤äº’å¼å®æ—¶æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†å…¨æ–°çš„å…¨å¤´é«˜æ–¯ä¸‰ç»´å¯å˜å½¢æ¨¡å‹GRMMï¼Œç»“åˆäº†åŸºç¡€ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰å’Œæ®‹ä½™å‡ ä½•åŠå¤–è§‚æˆåˆ†ã€‚</li>
<li>GRMMèƒ½å¤Ÿå®ç°å¿«é€Ÿé«˜è´¨é‡æ¸²æŸ“ï¼Œå¹¶æ§åˆ¶é¢éƒ¨å‡ ä½•å½¢çŠ¶å’Œè¡¨æƒ…ã€‚</li>
<li>GRMMå¯ä»¥æ•æ‰é«˜é¢‘ç»†èŠ‚ï¼Œå¦‚çš±çº¹ã€çš®è‚¤çº¹ç†å’Œå¤´å‘çº¿å˜åŒ–ã€‚</li>
<li>é€šè¿‡ä½ç»´åº¦ã€å¯è§£é‡Šçš„å‚æ•°è¿›è¡Œè§£è€¦æ§åˆ¶ï¼ŒåŒæ—¶å»ºç«‹æ®‹ä½™æ¨¡å‹ä»¥æ•æ‰è¶…å‡ºåŸºç¡€æ¨¡å‹èƒ½åŠ›çš„ç»†èŠ‚ã€‚</li>
<li>å¼•å…¥äº†EXPRESS-50æ•°æ®é›†ï¼Œç”¨äºå­¦ä¹ ä¸€è‡´çš„é«˜ä¿çœŸæ®‹ä½™æ¨¡å‹ï¼Œå®ç°èº«ä»½å’Œè¡¨æƒ…çš„ç¨³å¥è§£è€¦ã€‚</li>
<li>åœ¨å¤šé¡¹å®éªŒå¦‚å•ç›®ä¸‰ç»´äººè„¸é‡å»ºã€æ–°è§†è§’åˆæˆå’Œè¡¨æƒ…è½¬ç§»ä¸­ï¼ŒGRMMçš„æ€§èƒ½è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.02141">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3ad4b98a68565320484f26a6a7416c5d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6290eb981238c0771e3c1502084e92b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GaussianGAN-Real-Time-Photorealistic-controllable-Human-Avatars"><a href="#GaussianGAN-Real-Time-Photorealistic-controllable-Human-Avatars" class="headerlink" title="GaussianGAN: Real-Time Photorealistic controllable Human Avatars"></a>GaussianGAN: Real-Time Photorealistic controllable Human Avatars</h2><p><strong>Authors:Mohamed Ilyes Lakhal, Richard Bowden</strong></p>
<p>Photorealistic and controllable human avatars have gained popularity in the research community thanks to rapid advances in neural rendering, providing fast and realistic synthesis tools. However, a limitation of current solutions is the presence of noticeable blurring. To solve this problem, we propose GaussianGAN, an animatable avatar approach developed for photorealistic rendering of people in real-time. We introduce a novel Gaussian splatting densification strategy to build Gaussian points from the surface of cylindrical structures around estimated skeletal limbs. Given the camera calibration, we render an accurate semantic segmentation with our novel view segmentation module. Finally, a UNet generator uses the rendered Gaussian splatting features and the segmentation maps to create photorealistic digital avatars. Our method runs in real-time with a rendering speed of 79 FPS. It outperforms previous methods regarding visual perception and quality, achieving a state-of-the-art results in terms of a pixel fidelity of 32.94db on the ZJU Mocap dataset and 33.39db on the Thuman4 dataset. </p>
<blockquote>
<p>çœŸå®æ„Ÿå’Œå¯æ§çš„äººç±»åŒ–èº«ç”±äºç¥ç»æ¸²æŸ“çš„å¿«é€Ÿå‘å±•è€Œæä¾›äº†å¿«é€Ÿå’ŒçœŸå®çš„åˆæˆå·¥å…·ï¼Œå› æ­¤åœ¨ç ”ç©¶ç¤¾åŒºä¸­å—åˆ°äº†æ¬¢è¿ã€‚ç„¶è€Œï¼Œå½“å‰è§£å†³æ–¹æ¡ˆçš„ä¸€ä¸ªé™åˆ¶æ˜¯å­˜åœ¨æ˜æ˜¾çš„æ¨¡ç³Šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†GaussianGANï¼Œè¿™æ˜¯ä¸€ç§ä¸ºå®æ—¶çœŸäººç…§ç‰‡æ¸²æŸ“è€Œå¼€å‘çš„å¯åŠ¨æ€åŒ–èº«æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„é«˜æ–¯å–·å°„ç‚¹å¯†åŒ–ç­–ç•¥ï¼Œç”¨äºä»ä¼°è®¡çš„éª¨éª¼è‚¢ä½“å‘¨å›´çš„æŸ±çŠ¶ç»“æ„è¡¨é¢æ„å»ºé«˜æ–¯ç‚¹ã€‚ç»™å®šç›¸æœºæ ¡å‡†ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¨æ–°çš„è§†å›¾åˆ†å‰²æ¨¡å—è¿›è¡Œå‡†ç¡®çš„è¯­ä¹‰åˆ†å‰²ã€‚æœ€åï¼ŒUNetç”Ÿæˆå™¨ä½¿ç”¨æ¸²æŸ“çš„é«˜æ–¯å–·å°„ç‰¹å¾å’Œåˆ†å‰²å›¾æ¥åˆ›å»ºçœŸå®æ„Ÿçš„æ•°å­—åŒ–èº«ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®æ—¶è¿è¡Œï¼Œæ¸²æŸ“é€Ÿåº¦ä¸º79 FPSã€‚åœ¨è§†è§‰æ„ŸçŸ¥å’Œè´¨é‡æ–¹é¢ï¼Œå®ƒä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œåœ¨ZJU Mocapæ•°æ®é›†ä¸Šå®ç°äº†åƒç´ ä¿çœŸåº¦32.94dbï¼Œåœ¨Thuman4æ•°æ®é›†ä¸Šå®ç°äº†33.39dbï¼Œè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³çš„æˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01681v1">PDF</a> IEEE conference series on Automatic Face and Gesture Recognition 2025</p>
<p><strong>Summary</strong></p>
<p>ç¥ç»æ¸²æŸ“æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºäººç±»æä¾›äº†å¿«é€Ÿè€Œé€¼çœŸçš„åˆæˆå·¥å…·ï¼Œæ¨åŠ¨äº†é€¼çœŸå¯æ§çš„äººç±»è§’è‰²ï¼ˆavatarsï¼‰çš„ç ”ç©¶ã€‚ç„¶è€Œï¼Œå½“å‰è§£å†³æ–¹æ¡ˆå­˜åœ¨æ˜æ˜¾çš„æ¨¡ç³Šé—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºGaussianGANæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”¨äºå®æ—¶æ¸²æŸ“é€¼çœŸçš„äººç‰©è§’è‰²ã€‚é€šè¿‡å¼•å…¥é«˜æ–¯ç‚¹ç”Ÿæˆç­–ç•¥ï¼Œç»“åˆç›¸æœºæ ¡å‡†å’Œæ–°å‹è§†å›¾åˆ†å‰²æ¨¡å—ï¼Œå®ç°äº†å‡†ç¡®æ¸²æŸ“ã€‚ä½¿ç”¨UNetç”Ÿæˆå™¨ç»“åˆæ¸²æŸ“çš„é«˜æ–¯ç‚¹å’Œåˆ†å‰²å›¾ï¼Œç”Ÿæˆé€¼çœŸçš„æ•°å­—è§’è‰²ã€‚è¯¥æ–¹æ³•å®æ—¶è¿è¡Œï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ°79 FPSï¼Œåœ¨ZJU Mocapå’ŒThuman4æ•°æ®é›†ä¸Šçš„åƒç´ ä¿çœŸåº¦è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»æ¸²æŸ“æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¿ƒè¿›äº†é€¼çœŸå¯æ§çš„äººç±»è§’è‰²çš„ç ”ç©¶ã€‚</li>
<li>å½“å‰è§£å†³æ–¹æ¡ˆå­˜åœ¨æ˜æ˜¾çš„æ¨¡ç³Šé—®é¢˜ï¼Œéœ€è¦æ–°æ–¹æ³•è§£å†³ã€‚</li>
<li>GaussianGANæ–¹æ³•ç”¨äºå®æ—¶æ¸²æŸ“é€¼çœŸçš„äººç‰©è§’è‰²ã€‚</li>
<li>GaussianGANå¼•å…¥äº†é«˜æ–¯ç‚¹ç”Ÿæˆç­–ç•¥æ¥è§£å†³æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>ç»“åˆç›¸æœºæ ¡å‡†å’Œæ–°å‹è§†å›¾åˆ†å‰²æ¨¡å—ï¼Œå®ç°äº†å‡†ç¡®æ¸²æŸ“ã€‚</li>
<li>ä½¿ç”¨UNetç”Ÿæˆå™¨ç»“åˆæ¸²æŸ“çš„é«˜æ–¯ç‚¹å’Œåˆ†å‰²å›¾ï¼Œç”Ÿæˆæ•°å­—è§’è‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01681">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1f7b676141f63ff1d15275c7f91fa9c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-204ca48c59e1cdfb974db2a1305f5680.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df57ded81908c67c95640c9f5ef8431e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e1ff40271780e7d4a36c17ccb0a9bfd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-38222ed290d3951369e340488f2ef745.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbb1aa7e7edd6eb0dbed22c153990927.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4be3b80635361b110517e16e7005ec4.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="FGO-SLAM-Enhancing-Gaussian-SLAM-with-Globally-Consistent-Opacity-Radiance-Field"><a href="#FGO-SLAM-Enhancing-Gaussian-SLAM-with-Globally-Consistent-Opacity-Radiance-Field" class="headerlink" title="FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity   Radiance Field"></a>FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity   Radiance Field</h2><p><strong>Authors:Fan Zhu, Yifan Zhao, Ziyu Chen, Biao Yu, Hui Zhu</strong></p>
<p>Visual SLAM has regained attention due to its ability to provide perceptual capabilities and simulation test data for Embodied AI. However, traditional SLAM methods struggle to meet the demands of high-quality scene reconstruction, and Gaussian SLAM systems, despite their rapid rendering and high-quality mapping capabilities, lack effective pose optimization methods and face challenges in geometric reconstruction. To address these issues, we introduce FGO-SLAM, a Gaussian SLAM system that employs an opacity radiance field as the scene representation to enhance geometric mapping performance. After initial pose estimation, we apply global adjustment to optimize camera poses and sparse point cloud, ensuring robust tracking of our approach. Additionally, we maintain a globally consistent opacity radiance field based on 3D Gaussians and introduce depth distortion and normal consistency terms to refine the scene representation. Furthermore, after constructing tetrahedral grids, we identify level sets to directly extract surfaces from 3D Gaussians. Results across various real-world and large-scale synthetic datasets demonstrate that our method achieves state-of-the-art tracking accuracy and mapping performance. </p>
<blockquote>
<p>è§†è§‰SLAMå› å…¶èƒ½ä¸ºåµŒå…¥å¼äººå·¥æ™ºèƒ½æä¾›æ„ŸçŸ¥èƒ½åŠ›å’Œæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®è€Œé‡æ–°å—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œä¼ ç»ŸSLAMæ–¹æ³•éš¾ä»¥æ»¡è¶³é«˜è´¨é‡åœºæ™¯é‡å»ºçš„éœ€æ±‚ï¼Œè€Œé«˜æ–¯SLAMç³»ç»Ÿå°½ç®¡å…·æœ‰å¿«é€Ÿæ¸²æŸ“å’Œé«˜å“è´¨æ˜ å°„èƒ½åŠ›ï¼Œä½†ç¼ºä¹æœ‰æ•ˆçš„å§¿æ€ä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨å‡ ä½•é‡å»ºæ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†FGO-SLAMï¼Œè¿™æ˜¯ä¸€ä¸ªé‡‡ç”¨ä¸é€æ˜åº¦è¾å°„åœºä½œä¸ºåœºæ™¯è¡¨ç¤ºçš„é«˜æ–¯SLAMç³»ç»Ÿï¼Œä»¥æé«˜å‡ ä½•æ˜ å°„æ€§èƒ½ã€‚åœ¨å®Œæˆåˆå§‹å§¿æ€ä¼°è®¡åï¼Œæˆ‘ä»¬åº”ç”¨å…¨å±€è°ƒæ•´æ¥ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œç¨€ç–ç‚¹äº‘ï¼Œç¡®ä¿æˆ‘ä»¬çš„æ–¹æ³•çš„ç¨³å¥è·Ÿè¸ªã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºä¸‰ç»´é«˜æ–¯ç»´æŒå…¨å±€ä¸€è‡´çš„ä¸é€æ˜åº¦è¾å°„åœºï¼Œå¹¶å¼•å…¥æ·±åº¦å¤±çœŸå’Œæ­£å¸¸ä¸€è‡´æ€§æœ¯è¯­æ¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œåœ¨æ„å»ºå››é¢ä½“ç½‘æ ¼åï¼Œæˆ‘ä»¬ç¡®å®šæ°´å¹³é›†ä»¥ç›´æ¥ä»ä¸‰ç»´é«˜æ–¯æå–è¡¨é¢ã€‚åœ¨å„ç§ç°å®ä¸–ç•Œå’Œå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ä¸Šçš„ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„è·Ÿè¸ªç²¾åº¦å’Œæ˜ å°„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01547v1">PDF</a> ICRA 2025</p>
<p><strong>Summary</strong><br>     è§†è§‰SLAMå› å…¶èƒ½ä¸ºåµŒå…¥å¼äººå·¥æ™ºèƒ½æä¾›æ„ŸçŸ¥èƒ½åŠ›å’Œæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®è€Œå¤‡å—å…³æ³¨ã€‚é’ˆå¯¹ä¼ ç»ŸSLAMæ–¹æ³•éš¾ä»¥æ»¡è¶³é«˜è´¨é‡åœºæ™¯é‡å»ºéœ€æ±‚ï¼Œä»¥åŠé«˜æ–¯SLAMç³»ç»Ÿåœ¨å§¿æ€ä¼˜åŒ–å’Œå‡ ä½•é‡å»ºæ–¹é¢å­˜åœ¨çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºFGO-SLAMï¼Œé‡‡ç”¨åŸºäºé«˜æ–¯åˆ†å¸ƒçš„é€æ˜åº¦è¾å°„åœºä½œä¸ºåœºæ™¯è¡¨ç¤ºï¼Œå¢å¼ºå‡ ä½•æ˜ å°„æ€§èƒ½ã€‚é€šè¿‡åˆå§‹å§¿æ€ä¼°è®¡ã€å…¨å±€è°ƒæ•´ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œç¨€ç–ç‚¹äº‘ï¼Œå®ç°ç¨³å¥çš„è·Ÿè¸ªã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºé«˜æ–¯åˆ†å¸ƒç»´æŒå…¨å±€ä¸€è‡´çš„é€æ˜åº¦è¾å°„åœºï¼Œå¼•å…¥æ·±åº¦å¤±çœŸå’Œæ³•çº¿ä¸€è‡´æ€§é¡¹ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚åœ¨æ„å»ºå››é¢ä½“æ ¼ç½‘åï¼Œæˆ‘ä»¬é€šè¿‡è¯†åˆ«ç­‰å€¼çº¿ç›´æ¥ä»é«˜æ–¯åˆ†å¸ƒä¸­æå–è¡¨é¢ã€‚å®éªŒç»“æœåœ¨å¤šç»„çœŸå®å’Œå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæœ¬æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„è·Ÿè¸ªç²¾åº¦å’Œæ˜ å°„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†è§‰SLAMå› å…¶å¯¹Embodied AIçš„æ„ŸçŸ¥èƒ½åŠ›å’Œæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®çš„è´¡çŒ®è€Œå¤‡å—å…³æ³¨ã€‚</li>
<li>ä¼ ç»ŸSLAMæ–¹æ³•éš¾ä»¥æ»¡è¶³é«˜è´¨é‡åœºæ™¯é‡å»ºéœ€æ±‚ã€‚</li>
<li>é«˜æ–¯SLAMç³»ç»Ÿè™½å…·æœ‰å¿«é€Ÿæ¸²æŸ“å’Œé«˜ç²¾åº¦æ˜ å°„èƒ½åŠ›ï¼Œä½†åœ¨å§¿æ€ä¼˜åŒ–å’Œå‡ ä½•é‡å»ºæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>FGO-SLAMæ˜¯ä¸€ä¸ªé‡‡ç”¨é€æ˜åº¦è¾å°„åœºçš„é«˜æ–¯SLAMç³»ç»Ÿï¼Œæ—¨åœ¨å¢å¼ºå‡ ä½•æ˜ å°„æ€§èƒ½ã€‚</li>
<li>FGO-SLAMé€šè¿‡åˆå§‹å§¿æ€ä¼°è®¡å’Œå…¨å±€è°ƒæ•´ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œç¨€ç–ç‚¹äº‘ï¼Œå®ç°ç¨³å¥çš„è·Ÿè¸ªã€‚</li>
<li>æ–¹æ³•å¼•å…¥æ·±åº¦å¤±çœŸå’Œæ³•çº¿ä¸€è‡´æ€§é¡¹ï¼Œä»¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºå¹¶åŸºäºé«˜æ–¯åˆ†å¸ƒç›´æ¥æå–è¡¨é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01547">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-04ae9d5fbd202881a263d4a783f319ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c10b5d3e4b0522ba8b67892bb829722.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e031bb6626e67fb0386a0fbc7457a40.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df461480de62e1a384a23e68b8224ff3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a45cf5393c66945ece6a343511dae60f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a887c3b462f056f42b0cd8ba0b476bc.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Im2Haircut-Single-view-Strand-based-Hair-Reconstruction-for-Human-Avatars"><a href="#Im2Haircut-Single-view-Strand-based-Hair-Reconstruction-for-Human-Avatars" class="headerlink" title="Im2Haircut: Single-view Strand-based Hair Reconstruction for Human   Avatars"></a>Im2Haircut: Single-view Strand-based Hair Reconstruction for Human   Avatars</h2><p><strong>Authors:Vanessa Sklyarova, Egor Zakharov, Malte Prinzler, Giorgio Becherini, Michael J. Black, Justus Thies</strong></p>
<p>We present a novel approach for 3D hair reconstruction from single photographs based on a global hair prior combined with local optimization. Capturing strand-based hair geometry from single photographs is challenging due to the variety and geometric complexity of hairstyles and the lack of ground truth training data. Classical reconstruction methods like multi-view stereo only reconstruct the visible hair strands, missing the inner structure of hairstyles and hampering realistic hair simulation. To address this, existing methods leverage hairstyle priors trained on synthetic data. Such data, however, is limited in both quantity and quality since it requires manual work from skilled artists to model the 3D hairstyles and create near-photorealistic renderings. To address this, we propose a novel approach that uses both, real and synthetic data to learn an effective hairstyle prior. Specifically, we train a transformer-based prior model on synthetic data to obtain knowledge of the internal hairstyle geometry and introduce real data in the learning process to model the outer structure. This training scheme is able to model the visible hair strands depicted in an input image, while preserving the general 3D structure of hairstyles. We exploit this prior to create a Gaussian-splatting-based reconstruction method that creates hairstyles from one or more images. Qualitative and quantitative comparisons with existing reconstruction pipelines demonstrate the effectiveness and superior performance of our method for capturing detailed hair orientation, overall silhouette, and backside consistency. For additional results and code, please refer to <a target="_blank" rel="noopener" href="https://im2haircut.is.tue.mpg.de/">https://im2haircut.is.tue.mpg.de</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»å•å¼ ç…§ç‰‡é‡å»ºä¸‰ç»´å¤´å‘çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºå…¨å±€å¤´å‘å…ˆéªŒç»“åˆå±€éƒ¨ä¼˜åŒ–ã€‚ä»å•å¼ ç…§ç‰‡æ•æ‰åŸºäºå‘ä¸çš„å‘å‡ ä½•ç»“æ„æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºå‘å‹çš„å¤šæ ·æ€§å’Œå‡ ä½•å¤æ‚æ€§ä»¥åŠç¼ºä¹çœŸå®è®­ç»ƒæ•°æ®ã€‚ä¼ ç»Ÿçš„é‡å»ºæ–¹æ³•ï¼Œå¦‚å¤šè§†è§’ç«‹ä½“æ³•ï¼Œåªèƒ½é‡å»ºå¯è§çš„å‘ä¸ï¼Œå¿½ç•¥äº†å‘å‹çš„å†…éƒ¨ç»“æ„å¹¶é˜»ç¢äº†çœŸå®æ„Ÿçš„å¤´å‘æ¨¡æ‹Ÿã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åˆ©ç”¨åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„å‘å‹å…ˆéªŒã€‚ç„¶è€Œï¼Œè¿™ç§æ•°æ®åœ¨æ•°é‡å’Œè´¨é‡ä¸Šéƒ½æ˜¯æœ‰é™çš„ï¼Œå› ä¸ºå®ƒéœ€è¦ç†Ÿç»ƒè‰ºæœ¯å®¶çš„æ‰‹å·¥å·¥ä½œæ¥å»ºç«‹ä¸‰ç»´å‘å‹å¹¶åˆ›å»ºæ¥è¿‘ç…§ç‰‡çº§çš„æ¸²æŸ“ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆçœŸå®å’Œåˆæˆæ•°æ®çš„æœ‰æ•ˆå‘å‹å…ˆéªŒå­¦ä¹ æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒåŸºäºè½¬æ¢å™¨çš„å…ˆéªŒæ¨¡å‹ï¼Œä»¥è·å¾—å‘å‹å†…éƒ¨å‡ ä½•çš„çŸ¥è¯†ï¼Œå¹¶åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¼•å…¥çœŸå®æ•°æ®æ¥æ¨¡æ‹Ÿå¤–éƒ¨ç»“æ„ã€‚è¿™ç§è®­ç»ƒæ–¹æ¡ˆèƒ½å¤Ÿæ¨¡æ‹Ÿè¾“å…¥å›¾åƒä¸­æç»˜çš„å¯è§å‘ä¸ï¼ŒåŒæ—¶ä¿ç•™å‘å‹çš„ä¸€èˆ¬ä¸‰ç»´ç»“æ„ã€‚æˆ‘ä»¬åˆ©ç”¨è¿™ä¸€å…ˆéªŒä¿¡æ¯åˆ›å»ºäº†ä¸€ç§åŸºäºé«˜æ–¯å¹³é“ºçš„é‡å»ºæ–¹æ³•ï¼Œå¯ä»¥ä»ä¸€å¼ æˆ–å¤šå¼ å›¾åƒåˆ›å»ºå‘å‹ã€‚ä¸ç°æœ‰é‡å»ºç®¡é“çš„è´¨é‡å’Œæ•°é‡æ¯”è¾ƒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•æ‰è¯¦ç»†çš„å¤´å‘æ–¹å‘ã€æ•´ä½“è½®å»“å’ŒèƒŒé¢ä¸€è‡´æ€§æ–¹é¢éå¸¸æœ‰æ•ˆä¸”æ€§èƒ½ä¼˜è¶Šã€‚æ›´å¤šç»“æœå’Œä»£ç è¯·å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://im2haircut.is.tue.mpg.de./">https://im2haircut.is.tue.mpg.deã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01469v1">PDF</a> For more results please refer to the project page   <a target="_blank" rel="noopener" href="https://im2haircut.is.tue.mpg.de/">https://im2haircut.is.tue.mpg.de</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå…¨çƒå¤´å‘å…ˆéªŒä¸å±€éƒ¨ä¼˜åŒ–ç›¸ç»“åˆçš„å•ç…§ç‰‡3Då¤´å‘é‡å»ºæ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†çœŸå®å’Œåˆæˆæ•°æ®æ¥è®­ç»ƒå‘å‹å…ˆéªŒæ¨¡å‹ï¼Œèƒ½æ•æ‰å‘å‹å†…éƒ¨å‡ ä½•ç»“æ„ï¼Œå¹¶é€šè¿‡é«˜æ–¯è´´å›¾æŠ€æœ¯ä»ä¸€å¼ æˆ–å¤šå¼ ç…§ç‰‡é‡å»ºå‘å‹ã€‚ç›¸æ¯”ç°æœ‰é‡å»ºæµç¨‹ï¼Œè¯¥æ–¹æ³•æ›´æœ‰æ•ˆåœ°æ•æ‰å¤´å‘ç»†èŠ‚æ–¹å‘ã€æ•´ä½“è½®å»“å’ŒèƒŒé¢ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„3Då¤´å‘é‡å»ºæ–¹æ³•ï¼Œç»“åˆå…¨çƒå¤´å‘å…ˆéªŒå’Œå±€éƒ¨ä¼˜åŒ–ã€‚</li>
<li>é€šè¿‡ç»“åˆçœŸå®å’Œåˆæˆæ•°æ®ï¼Œè®­ç»ƒå‘å‹å…ˆéªŒæ¨¡å‹ã€‚</li>
<li>æ¨¡å‹èƒ½æ•æ‰å‘å‹å†…éƒ¨å‡ ä½•ç»“æ„ã€‚</li>
<li>é‡‡ç”¨é«˜æ–¯è´´å›¾æŠ€æœ¯ä»ä¸€å¼ ç…§ç‰‡æˆ–å¤šå¼ ç…§ç‰‡é‡å»ºå‘å‹ã€‚</li>
<li>æ–¹æ³•èƒ½æœ‰æ•ˆæ•æ‰å¤´å‘ç»†èŠ‚æ–¹å‘ã€æ•´ä½“è½®å»“å’ŒèƒŒé¢ä¸€è‡´æ€§ã€‚</li>
<li>æä¾›äº†å®šé‡å’Œå®šæ€§çš„è¯„ä¼°ï¼Œè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰é‡å»ºæµç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01469">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-63d7d4ef87df38c81cb089a39aa6a32c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cdfb67f320a14d1f03c293af4cc52b01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9705821fabd9cf760524fc5b5b233ae2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eefc3d01957892ce2b3a00c0bd60490f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Towards-Integrating-Multi-Spectral-Imaging-with-Gaussian-Splatting"><a href="#Towards-Integrating-Multi-Spectral-Imaging-with-Gaussian-Splatting" class="headerlink" title="Towards Integrating Multi-Spectral Imaging with Gaussian Splatting"></a>Towards Integrating Multi-Spectral Imaging with Gaussian Splatting</h2><p><strong>Authors:Josef GrÃ¼n, Lukas Meyer, Maximilian Weiherer, Bernhard Egger, Marc Stamminger, Linus Franke</strong></p>
<p>We present a study of how to integrate color (RGB) and multi-spectral imagery (red, green, red-edge, and near-infrared) into the 3D Gaussian Splatting (3DGS) framework, a state-of-the-art explicit radiance-field-based method for fast and high-fidelity 3D reconstruction from multi-view images. While 3DGS excels on RGB data, naive per-band optimization of additional spectra yields poor reconstructions due to inconsistently appearing geometry in the spectral domain. This problem is prominent, even though the actual geometry is the same, regardless of spectral modality. To investigate this, we evaluate three strategies: 1) Separate per-band reconstruction with no shared structure. 2) Splitting optimization, in which we first optimize RGB geometry, copy it, and then fit each new band to the model by optimizing both geometry and band representation. 3) Joint, in which the modalities are jointly optimized, optionally with an initial RGB-only phase. We showcase through quantitative metrics and qualitative novel-view renderings on multi-spectral datasets the effectiveness of our dedicated optimized Joint strategy, increasing overall spectral reconstruction as well as enhancing RGB results through spectral cross-talk. We therefore suggest integrating multi-spectral data directly into the spherical harmonics color components to compactly model each Gaussianâ€™s multi-spectral reflectance. Moreover, our analysis reveals several key trade-offs in when and how to introduce spectral bands during optimization, offering practical insights for robust multi-modal 3DGS reconstruction. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶å¦‚ä½•å°†é¢œè‰²ï¼ˆRGBï¼‰å’Œå¤šå…‰è°±å›¾åƒï¼ˆçº¢è‰²ã€ç»¿è‰²ã€çº¢è¾¹å’Œè¿‘çº¢å¤–ï¼‰é›†æˆåˆ°ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ¡†æ¶ä¸­ã€‚3DGSæ˜¯ä¸€ç§åŸºäºæ˜¾å¼è¾å°„åœºçš„å…ˆè¿›æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å¤šè§†è§’å›¾åƒå¿«é€Ÿè¿›è¡Œé«˜ä¿çœŸä¸‰ç»´é‡å»ºã€‚è™½ç„¶3DGSåœ¨RGBæ•°æ®ä¸Šè¡¨ç°å“è¶Šï¼Œä½†å¯¹é¢å¤–å…‰è°±çš„ç›²ç›®æ³¢æ®µä¼˜åŒ–ä¼šå¯¼è‡´é‡å»ºæ•ˆæœè¾ƒå·®ï¼Œå› ä¸ºåœ¨å…‰è°±åŸŸä¸­å‡ ä½•å½¢çŠ¶ä¼šå‡ºç°ä¸ä¸€è‡´ã€‚å³ä½¿å®é™…å‡ ä½•å½¢çŠ¶ç›¸åŒï¼Œæ— è®ºå…‰è°±æ¨¡å¼å¦‚ä½•ï¼Œè¿™ä¸ªé—®é¢˜ä»ç„¶çªå‡ºã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸‰ç§ç­–ç•¥ï¼š1ï¼‰æ— å…±äº«ç»“æ„çš„å•ç‹¬æ³¢æ®µé‡å»ºã€‚2ï¼‰åˆ†å‰²ä¼˜åŒ–ï¼Œæˆ‘ä»¬é¦–å…ˆä¼˜åŒ–RGBå‡ ä½•å½¢çŠ¶ï¼Œè¿›è¡Œå¤åˆ¶ï¼Œç„¶åé€šè¿‡ä¼˜åŒ–å‡ ä½•å½¢çŠ¶å’Œæ³¢æ®µè¡¨ç¤ºæ¥é€‚åº”æ¯ä¸ªæ–°æ³¢æ®µã€‚3ï¼‰è”åˆä¼˜åŒ–ï¼Œå…¶ä¸­æ¨¡æ€è”åˆä¼˜åŒ–ï¼Œå¯é€‰æ‹©åˆå§‹çš„ä»…RGBé˜¶æ®µã€‚æˆ‘ä»¬é€šè¿‡å¤šå…‰è°±æ•°æ®é›†ä¸Šçš„å®šé‡æŒ‡æ ‡å’Œå®šæ€§æ–°é¢–è§†å›¾æ¸²æŸ“ï¼Œå±•ç¤ºäº†æˆ‘ä»¬ä¸“é—¨ä¼˜åŒ–çš„è”åˆç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œå®ƒæé«˜äº†æ•´ä½“å…‰è°±é‡å»ºæ•ˆæœï¼Œå¹¶é€šè¿‡å…‰è°±äº¤å‰å¢å¼ºäº†RGBç»“æœã€‚å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®åœ¨çƒå½¢è°æ³¢é¢œè‰²ç»„ä»¶ä¸­ç›´æ¥é›†æˆå¤šå…‰è°±æ•°æ®ï¼Œä»¥ç´§å‡‘åœ°æ¨¡æ‹Ÿæ¯ä¸ªé«˜æ–¯çš„å¤šå…‰è°±åå°„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ä½•æ—¶ä»¥åŠå¦‚ä½•åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥å…‰è°±æ³¢æ®µçš„å‡ ä¸ªå…³é”®æƒè¡¡ï¼Œä¸ºç¨³å¥çš„å¤šæ¨¡å¼3DGSé‡å»ºæä¾›äº†å®ç”¨è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00989v1">PDF</a> for project page, see   <a target="_blank" rel="noopener" href="https://meyerls.github.io/towards_multi_spec_splat/">https://meyerls.github.io/towards_multi_spec_splat/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†é¢œè‰²ï¼ˆRGBï¼‰å’Œå¤šå…‰è°±å›¾åƒï¼ˆçº¢ã€ç»¿ã€çº¢è¾¹å’Œè¿‘çº¢å¤–ï¼‰é›†æˆåˆ°åŸºäºä¸‰ç»´é«˜æ–¯å±•å¹³çš„æ¡†æ¶ä¸­ï¼Œå®ç°å¯¹å¤šè§†è§’å›¾åƒè¿›è¡Œå¿«é€Ÿè€Œé«˜ç²¾åº¦çš„ä¸‰ç»´é‡å»ºã€‚é’ˆå¯¹å¤šå…‰è°±æ•°æ®åœ¨é›†æˆæ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸‰ç§ç­–ç•¥ï¼Œæœ€ç»ˆé€šè¿‡ä¼˜åŒ–è”åˆç­–ç•¥å®ç°äº†å¤šå…‰è°±é‡å»ºçš„æœ‰æ•ˆæ€§ï¼Œæé«˜äº†RGBç»“æœçš„å…‰è°±äº¤å‰æ•ˆæœã€‚å»ºè®®ç›´æ¥é›†æˆå¤šå…‰è°±æ•°æ®åˆ°çƒé¢è°æ³¢é¢œè‰²æˆåˆ†ä¸­ï¼Œä¸ºæ¯ä¸ªé«˜æ–¯å…‰è°±åå°„æä¾›ç´§å‡‘æ¨¡å‹ã€‚åŒæ—¶ï¼Œåˆ†ææä¾›äº†åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¼•å…¥å…‰è°±å¸¦çš„æ—¶æœºå’Œæ–¹æ³•çš„å…³é”®æƒè¡¡ï¼Œä¸ºç¨³å¥çš„å¤šæ¨¡æ€ä¸‰ç»´é‡å»ºæä¾›äº†å®è·µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•å°†å¤šå…‰è°±æ•°æ®é›†æˆåˆ°ä¸‰ç»´é«˜æ–¯å±•å¹³æ¡†æ¶ä¸­ï¼Œä»¥å®ç°é«˜ç²¾åº¦ä¸‰ç»´é‡å»ºã€‚</li>
<li>åœ¨å¤„ç†å¤šå…‰è°±æ•°æ®æ—¶é¢ä¸´äº†ä¸ä¸€è‡´å‡ ä½•çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸‰ç§ç­–ç•¥æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œå¹¶é€šè¿‡å®éªŒè¯„ä¼°äº†å®ƒä»¬çš„æ€§èƒ½ã€‚</li>
<li>ä¼˜åŒ–è”åˆç­–ç•¥èƒ½æœ‰æ•ˆæé«˜å¤šå…‰è°±é‡å»ºæ•ˆæœï¼Œå¹¶å¢å¼ºRGBç»“æœçš„å…‰è°±äº¤å‰æ•ˆæœã€‚</li>
<li>å»ºè®®å°†å¤šå…‰è°±æ•°æ®ç›´æ¥é›†æˆåˆ°çƒé¢è°æ³¢é¢œè‰²æˆåˆ†ä¸­ï¼Œä¸ºé«˜æ–¯å…‰è°±åå°„æä¾›ç´§å‡‘æ¨¡å‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00989">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-941162dad54dd95104b5255ce85f58bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c32635e803601560d693f524a353502e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a796e47f4ecee9efb6f43fd2f9ba4e9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5e1c5213c1b20c17888a41b8b6c7bf7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c52555ab089cd9af17c0814b130528d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b13196e81647b066922085e1cc61ed8.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GS-TG-3D-Gaussian-Splatting-Accelerator-with-Tile-Grouping-for-Reducing-Redundant-Sorting-while-Preserving-Rasterization-Efficiency"><a href="#GS-TG-3D-Gaussian-Splatting-Accelerator-with-Tile-Grouping-for-Reducing-Redundant-Sorting-while-Preserving-Rasterization-Efficiency" class="headerlink" title="GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing   Redundant Sorting while Preserving Rasterization Efficiency"></a>GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing   Redundant Sorting while Preserving Rasterization Efficiency</h2><p><strong>Authors:Joongho Jo, Jongsun Park</strong></p>
<p>3D Gaussian Splatting (3D-GS) has emerged as a promising alternative to neural radiance fields (NeRF) as it offers high speed as well as high image quality in novel view synthesis. Despite these advancements, 3D-GS still struggles to meet the frames per second (FPS) demands of real-time applications. In this paper, we introduce GS-TG, a tile-grouping-based accelerator that enhances 3D-GS rendering speed by reducing redundant sorting operations and preserving rasterization efficiency. GS-TG addresses a critical trade-off issue in 3D-GS rendering: increasing the tile size effectively reduces redundant sorting operations, but it concurrently increases unnecessary rasterization computations. So, during sorting of the proposed approach, GS-TG groups small tiles (for making large tiles) to share sorting operations across tiles within each group, significantly reducing redundant computations. During rasterization, a bitmask assigned to each Gaussian identifies relevant small tiles, to enable efficient sharing of sorting results. Consequently, GS-TG enables sorting to be performed as if a large tile size is used by grouping tiles during the sorting stage, while allowing rasterization to proceed with the original small tiles by using bitmasks in the rasterization stage. GS-TG is a lossless method requiring no retraining or fine-tuning and it can be seamlessly integrated with previous 3D-GS optimization techniques. Experimental results show that GS-TG achieves an average speed-up of 1.54 times over state-of-the-art 3D-GS accelerators. </p>
<blockquote>
<p>ä¸‰ç»´é«˜æ–¯æ¸²æŸ“ï¼ˆ3D-GSï¼‰ä½œä¸ºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„ä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆå·²ç»å‡ºç°ï¼Œå› ä¸ºå®ƒåœ¨æ–°å‹è§†å›¾åˆæˆä¸­æä¾›äº†é«˜é€Ÿå’Œé«˜å›¾åƒè´¨é‡ã€‚å°½ç®¡æœ‰äº†è¿™äº›è¿›å±•ï¼Œä½†3D-GSä»ç„¶éš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨ä¸­çš„æ¯ç§’å¸§æ•°ï¼ˆFPSï¼‰éœ€æ±‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GS-TGï¼Œä¸€ç§åŸºäºç“¦ç‰‡åˆ†ç»„æŠ€æœ¯çš„åŠ é€Ÿå™¨ï¼Œå®ƒé€šè¿‡å‡å°‘å†—ä½™æ’åºæ“ä½œå¹¶ä¿æŒå…‰æ …åŒ–æ•ˆç‡æ¥æé«˜3D-GSçš„æ¸²æŸ“é€Ÿåº¦ã€‚GS-TGè§£å†³äº†åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­å­˜åœ¨çš„å…³é”®é—®é¢˜ï¼Œå³å¯¹äºå®ç°ä¼˜åŒ–çš„è¿è¡Œé€Ÿåº¦æœ‰ç€å¹³è¡¡éœ€æ±‚çš„å†²çªé—®é¢˜ã€‚GS-TGæå‡ºäº†ä¸€ç§åˆ›æ–°çš„ç­–ç•¥ï¼šå¢å¤§ç“¦ç‰‡å°ºå¯¸èƒ½æœ‰æ•ˆå‡å°‘å†—ä½™æ’åºæ“ä½œï¼Œä½†åŒæ—¶ä¹Ÿä¼šå¢åŠ ä¸å¿…è¦çš„å…‰æ …åŒ–è®¡ç®—é‡ã€‚å› æ­¤ï¼Œåœ¨æ’åºè¿‡ç¨‹ä¸­ï¼ŒGS-TGä¼šå°†å°ç“¦ç‰‡åˆ†ç»„ï¼ˆç”¨äºåˆ¶ä½œå¤§ç“¦ç‰‡ï¼‰ï¼Œä½¿æ¯ç»„ç“¦ç‰‡å…±äº«æ’åºæ“ä½œï¼Œä»è€Œæ˜¾è‘—å‡å°‘å†—ä½™è®¡ç®—ã€‚åœ¨å…‰æ …åŒ–è¿‡ç¨‹ä¸­ï¼Œåˆ†é…ç»™æ¯ä¸ªé«˜æ–¯å€¼çš„ä½æ©ç ç”¨äºè¯†åˆ«ç›¸å…³çš„å°ç“¦ç‰‡ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ’åºç»“æœå…±äº«ã€‚å› æ­¤ï¼Œé€šè¿‡åˆ†ç»„ç“¦ç‰‡è¿›è¡Œæ’åºé˜¶æ®µï¼Œå°±å¥½åƒä½¿ç”¨è¾ƒå¤§çš„ç“¦ç‰‡å°ºå¯¸è¿›è¡Œæ’åºä¸€æ ·å¿«ï¼ŒåŒæ—¶é€šè¿‡ä½æ©ç åœ¨å…‰æ …åŒ–é˜¶æ®µè¿›è¡Œå°ç“¦ç‰‡çš„å¤„ç†æ¥ä¿æŒåŸæœ‰çš„æ€§èƒ½ä¼˜åŠ¿ã€‚GS-TGæ˜¯ä¸€ç§æ— æŸæ–¹æ³•ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œå®ƒå¯ä»¥æ— ç¼é›†æˆåˆ°å…ˆå‰çš„3D-GSä¼˜åŒ–æŠ€æœ¯ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGS-TGç›¸å¯¹äºå…ˆè¿›çš„åŠ é€Ÿå™¨çš„é€Ÿåº¦æé«˜äº†å¹³å‡å¤§çº¦ä¸€å€ä»¥ä¸Šï¼ˆé€Ÿåº¦ä¸ºåŸæ¥1.54å€ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00911v2">PDF</a> DAC 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†GS-TGï¼Œä¸€ç§åŸºäºç“¦ç‰‡åˆ†ç»„æŠ€æœ¯çš„åŠ é€Ÿå™¨ï¼Œç”¨äºæå‡3Dé«˜æ–¯å–·ç»˜ï¼ˆ3D-GSï¼‰çš„æ¸²æŸ“é€Ÿåº¦ã€‚GS-TGé€šè¿‡å‡å°‘å†—ä½™æ’åºæ“ä½œå¹¶ä¿æŒå…‰æ …åŒ–æ•ˆç‡ï¼Œè§£å†³äº†3D-GSåœ¨å®æ—¶åº”ç”¨ä¸­é¢ä¸´çš„å¸§ç‡éœ€æ±‚æŒ‘æˆ˜ã€‚å®ƒé€šè¿‡åˆ†ç»„ç“¦ç‰‡å…±äº«æ’åºæ“ä½œæ¥å‡å°‘å†—ä½™è®¡ç®—ï¼Œå¹¶åœ¨å…‰æ …åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨ä½æ©ç è¯†åˆ«ç›¸å…³ç“¦ç‰‡ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆçš„æ’åºç»“æœå…±äº«ã€‚è¯¥æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œå¯æ— ç¼é›†æˆåˆ°å…ˆå‰çš„3D-GSä¼˜åŒ–æŠ€æœ¯ä¸­ï¼Œå¹³å‡æé€Ÿè¾¾åˆ°1.54å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GS-TGæ˜¯ä¸€ç§åŸºäºç“¦ç‰‡åˆ†ç»„æŠ€æœ¯çš„åŠ é€Ÿå™¨ï¼Œæ—¨åœ¨æé«˜3Dé«˜æ–¯å–·ç»˜ï¼ˆ3D-GSï¼‰çš„æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>GS-TGè§£å†³äº†3D-GSåœ¨å®æ—¶åº”ç”¨ä¸­é¢ä¸´çš„å¸§ç‡éœ€æ±‚æŒ‘æˆ˜ï¼Œæ»¡è¶³äº†é«˜é€Ÿå’Œé«˜å›¾åƒè´¨é‡çš„è¦æ±‚ã€‚</li>
<li>GS-TGé€šè¿‡å‡å°‘å†—ä½™æ’åºæ“ä½œå’Œä¼˜åŒ–å…‰æ …åŒ–æ•ˆç‡æ¥æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>GS-TGé€šè¿‡åˆ†ç»„ç“¦ç‰‡å…±äº«æ’åºæ“ä½œæ¥å‡å°‘è®¡ç®—é‡ï¼Œå¹¶åˆ©ç”¨ä½æ©ç åœ¨å…‰æ …åŒ–è¿‡ç¨‹ä¸­è¯†åˆ«ç›¸å…³ç“¦ç‰‡ï¼Œå®ç°é«˜æ•ˆçš„æ’åºç»“æœå…±äº«ã€‚</li>
<li>GS-TGå¯ä»¥æ— ç¼é›†æˆåˆ°ç°æœ‰çš„3D-GSä¼˜åŒ–æŠ€æœ¯ä¸­ï¼Œå¹¶ä¸”ä¸éœ€è¦é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒGS-TGç›¸æ¯”ç°æœ‰çš„3D-GSåŠ é€Ÿå™¨å®ç°äº†å¹³å‡1.54å€çš„æé€Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1fa4ffd586de6cf482702a4fd8fd00a6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-213e736ada0c8b20cd25b6d15cfcb506.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6baf94b8955eef41c666d74c18a27e46.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0110abdbe4a146dab31b7fa8ed065cd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a178121b5f3d6a3ec22cfa4b3bbe16bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76188bd1a8110ee792767fc4e1cb1779.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1883d5d2ff2a8d39d8c9818a8825fc4.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SWAGSplatting-Semantic-guided-Water-scene-Augmented-Gaussian-Splatting"><a href="#SWAGSplatting-Semantic-guided-Water-scene-Augmented-Gaussian-Splatting" class="headerlink" title="SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting"></a>SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting</h2><p><strong>Authors:Zhuodong Jiang, Haoran Wang, Guoxi Huang, Brett Seymour, Nantheera Anantrasirichai</strong></p>
<p>Accurate 3D reconstruction in underwater environments remains a complex challenge due to issues such as light distortion, turbidity, and limited visibility. AI-based techniques have been applied to address these issues, however, existing methods have yet to fully exploit the potential of AI, particularly in integrating language models with visual processing. In this paper, we propose a novel framework that leverages multimodal cross-knowledge to create semantic-guided 3D Gaussian Splatting for robust and high-fidelity deep-sea scene reconstruction. By embedding an extra semantic feature into each Gaussian primitive and supervised by the CLIP extracted semantic feature, our method enforces semantic and structural awareness throughout the training. The dedicated semantic consistency loss ensures alignment with high-level scene understanding. Besides, we propose a novel stage-wise training strategy, combining coarse-to-fine learning with late-stage parameter refinement, to further enhance both stability and reconstruction quality. Extensive results show that our approach consistently outperforms state-of-the-art methods on SeaThru-NeRF and Submerged3D datasets across three metrics, with an improvement of up to 3.09 dB on average in terms of PSNR, making it a strong candidate for applications in underwater exploration and marine perception. </p>
<blockquote>
<p>åœ¨æ°´ä¸‹ç¯å¢ƒä¸­å®ç°ç²¾ç¡®çš„3Dé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå¤æ‚çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå­˜åœ¨å…‰ç•¸å˜ã€æµ‘æµŠå’Œèƒ½è§åº¦æœ‰é™ç­‰é—®é¢˜ã€‚è™½ç„¶åŸºäºäººå·¥æ™ºèƒ½çš„æŠ€æœ¯å·²åº”ç”¨äºè§£å†³è¿™äº›é—®é¢˜ï¼Œä½†ç°æœ‰æ–¹æ³•å°šæœªå……åˆ†åˆ©ç”¨äººå·¥æ™ºèƒ½çš„æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å°†è¯­è¨€æ¨¡å‹ä¸è§†è§‰å¤„ç†ç›¸ç»“åˆæ–¹é¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨è·¨æ¨¡æ€äº¤å‰çŸ¥è¯†åˆ›å»ºè¯­ä¹‰å¼•å¯¼çš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´çš„æ–°æ¡†æ¶ï¼Œä»¥å®ç°ç¨³å¥å’Œé«˜ä¿çœŸæ·±æµ·åœºæ™¯é‡å»ºã€‚é€šè¿‡å°†é¢å¤–çš„è¯­ä¹‰ç‰¹å¾åµŒå…¥æ¯ä¸ªé«˜æ–¯åŸºæœ¬å•ä½ï¼Œå¹¶åœ¨CLIPæå–çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­å¼ºåˆ¶è¿›è¡Œè¯­ä¹‰å’Œç»“æ„æ„ŸçŸ¥ã€‚ä¸“ç”¨çš„è¯­ä¹‰ä¸€è‡´æ€§æŸå¤±ç¡®ä¿ä¸é«˜çº§åœºæ™¯ç†è§£çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œç»“åˆä»ç²—åˆ°ç»†çš„å­¦ä¹ ä¸åæœŸå‚æ•°ä¼˜åŒ–ï¼Œä»¥è¿›ä¸€æ­¥æé«˜ç¨³å®šæ€§å’Œé‡å»ºè´¨é‡ã€‚å¤§é‡ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æµ·é€šé€NeRFå’Œæ·¹æ²¡ä¸‰ç»´æ•°æ®é›†ä¸Šä¸‰é¡¹æŒ‡æ ‡çš„è¡¨ç°å‡ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œåœ¨å³°å€¼ä¿¡å™ªæ¯”æ–¹é¢å¹³å‡æé«˜äº†é«˜è¾¾3.09åˆ†è´ï¼Œä½¿å…¶æˆä¸ºæ°´ä¸‹æ¢ç´¢å’Œæµ·æ´‹æ„ŸçŸ¥åº”ç”¨çš„æœ‰åŠ›å€™é€‰è€…ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00800v1">PDF</a> Submitted to SIGGRAPH Asia 2025 Technical Communications</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œç»“åˆå¤šæ¨¡æ€è·¨çŸ¥è¯†ï¼Œåˆ©ç”¨è¯­ä¹‰å¼•å¯¼çš„ä¸‰ç»´é«˜æ–¯SplattingæŠ€æœ¯ï¼Œå®ç°äº†æ·±æµ·åœºæ™¯çš„ç¨³å¥ä¸é«˜ä¿çœŸé‡å»ºã€‚è¯¥æ–¹æ³•é€šè¿‡åµŒå…¥é¢å¤–çš„è¯­ä¹‰ç‰¹å¾ï¼Œç›‘ç£CLIPæå–çš„è¯­ä¹‰ç‰¹å¾ï¼Œå®ç°äº†è¯­ä¹‰å’Œç»“æ„æ„ŸçŸ¥çš„è®­ç»ƒè¿‡ç¨‹ã€‚åŒæ—¶ï¼Œæå‡ºäº†é˜¶æ®µå¼è®­ç»ƒç­–ç•¥ï¼Œç»“åˆç²—åˆ°ç»†å­¦ä¹ ä¸åæœŸå‚æ•°ä¼˜åŒ–ï¼Œæé«˜äº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œé‡å»ºè´¨é‡ã€‚åœ¨SeaThru-NeRFå’ŒSubmerged3Dæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹³å‡å³°å€¼ä¿¡å™ªæ¯”æé«˜äº†é«˜è¾¾3.09 dBï¼Œä¸ºæ°´ä¸‹æ¢ç´¢å’Œæµ·æ´‹æ„ŸçŸ¥åº”ç”¨æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬è®ºæ–‡é’ˆå¯¹æ°´ä¸‹ç¯å¢ƒçš„ä¸‰ç»´é‡å»ºæå‡ºäº†ä¸€ä¸ªæ–°å‹æ¡†æ¶ã€‚</li>
<li>åˆ©ç”¨AIæŠ€æœ¯è§£å†³æ°´ä¸‹ç¯å¢ƒçš„å…‰ç•¸å˜ã€æ··æµŠå’Œæœ‰é™å¯è§æ€§é—®é¢˜ã€‚</li>
<li>é€šè¿‡ç»“åˆå¤šæ¨¡æ€çŸ¥è¯†å’Œè¯­ä¹‰å¼•å¯¼çš„ä¸‰ç»´é«˜æ–¯SplattingæŠ€æœ¯ï¼Œå®ç°äº†ç¨³å¥å’Œé«˜ä¿çœŸçš„é‡å»ºã€‚</li>
<li>é€šè¿‡åµŒå…¥è¯­ä¹‰ç‰¹å¾å¹¶ç»“åˆCLIPæŠ€æœ¯ï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è·å¾—è¯­ä¹‰å’Œç»“æ„æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„é˜¶æ®µå¼è®­ç»ƒç­–ç•¥ï¼Œç»“åˆäº†ç²—åˆ°ç»†çš„å­¦ä¹ å’ŒåæœŸå‚æ•°ä¼˜åŒ–ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-527338f237c068f7f42502182a7e2bf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-faeb12ef2aabe853912ccf23564fc3a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e0781ceb513940107b1c78e652d4b21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-707e4becebcb951d0926bf1e27248df8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07f0ade90f6d6a8751dbc9073d6681ba.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MarkSplatter-Generalizable-Watermarking-for-3D-Gaussian-Splatting-Model-via-Splatter-Image-Structure"><a href="#MarkSplatter-Generalizable-Watermarking-for-3D-Gaussian-Splatting-Model-via-Splatter-Image-Structure" class="headerlink" title="MarkSplatter: Generalizable Watermarking for 3D Gaussian Splatting Model   via Splatter Image Structure"></a>MarkSplatter: Generalizable Watermarking for 3D Gaussian Splatting Model   via Splatter Image Structure</h2><p><strong>Authors:Xiufeng Huang, Ziyuan Luo, Qi Song, Ruofei Wang, Renjie Wan</strong></p>
<p>The growing popularity of 3D Gaussian Splatting (3DGS) has intensified the need for effective copyright protection. Current 3DGS watermarking methods rely on computationally expensive fine-tuning procedures for each predefined message. We propose the first generalizable watermarking framework that enables efficient protection of Splatter Image-based 3DGS models through a single forward pass. We introduce GaussianBridge that transforms unstructured 3D Gaussians into Splatter Image format, enabling direct neural processing for arbitrary message embedding. To ensure imperceptibility, we design a Gaussian-Uncertainty-Perceptual heatmap prediction strategy for preserving visual quality. For robust message recovery, we develop a dense segmentation-based extraction mechanism that maintains reliable extraction even when watermarked objects occupy minimal regions in rendered views. Project page: <a target="_blank" rel="noopener" href="https://kevinhuangxf.github.io/marksplatter">https://kevinhuangxf.github.io/marksplatter</a>. </p>
<blockquote>
<p>éšç€ä¸‰ç»´é«˜æ–¯æ¨¡ç³Šï¼ˆ3DGSï¼‰çš„æ—¥ç›Šæ™®åŠï¼Œå¯¹æœ‰æ•ˆç‰ˆæƒä¿æŠ¤çš„éœ€æ±‚ä¹Ÿæ—¥ç›Šè¿«åˆ‡ã€‚å½“å‰çš„3DGSæ°´å°æ–¹æ³•ä¾èµ–äºé’ˆå¯¹æ¯æ¡é¢„è®¾ä¿¡æ¯è¿›è¡Œçš„è®¡ç®—å¯†é›†å‹çš„å¾®è°ƒç¨‹åºã€‚æˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ä¸ªé€šç”¨æ°´å°æ¡†æ¶ï¼Œé€šè¿‡å•æ¬¡å‰å‘ä¼ é€’å®ç°äº†åŸºäºSplatterå›¾åƒæ ¼å¼çš„3DGSæ¨¡å‹çš„æœ‰æ•ˆä¿æŠ¤ã€‚æˆ‘ä»¬å¼•å…¥äº†GaussianBridgeï¼Œå®ƒå°†éç»“æ„åŒ–çš„ä¸‰ç»´é«˜æ–¯è½¬æ¢ä¸ºSplatterå›¾åƒæ ¼å¼ï¼Œå®ç°äº†ä»»æ„æ¶ˆæ¯çš„åµŒå…¥å¼ç›´æ¥ç¥ç»ç½‘ç»œå¤„ç†ã€‚ä¸ºç¡®ä¿ä¸å¯å¯Ÿè§‰æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºé«˜æ–¯ä¸ç¡®å®šæ€§æ„ŸçŸ¥å›¾çš„é¢„æµ‹ç­–ç•¥ï¼Œä»¥ä¿ç•™è§†è§‰æ•ˆæœã€‚ä¸ºç¡®ä¿å¯é åœ°æ¢å¤æ¶ˆæ¯ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºå¯†é›†åˆ†å‰²çš„æå–æœºåˆ¶ï¼Œå³ä½¿åœ¨æ¸²æŸ“è§†å›¾ä¸­æ°´å°å¯¹è±¡å æ®å¾ˆå°çš„åŒºåŸŸæ—¶ä¹Ÿèƒ½ä¿æŒå¯é çš„æå–æ•ˆæœã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://kevinhuangxf.github.io/marksplatter%E3%80%82">https://kevinhuangxf.github.io/marksplatterã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00757v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡å…³æ³¨äºä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•ä¿æŠ¤æµè¡ŒæŠ€æœ¯å¦‚ä¸‰ç»´é«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰ä¸­çš„ç‰ˆæƒé—®é¢˜ã€‚ç°æœ‰çš„æ°´å°æŠ€æœ¯å¤æ‚ä¸”è®¡ç®—é‡å¤§ï¼Œéœ€é’ˆå¯¹æ¯æ¡é¢„è®¾ä¿¡æ¯è°ƒæ•´ä¼˜åŒ–ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é€šç”¨çš„æ°´å°æ¡†æ¶ï¼Œé€šè¿‡å•æ¬¡å‰å‘ä¼ é€’å³å¯é«˜æ•ˆä¿æŠ¤åŸºäºSplatter Imageæ ¼å¼çš„3DGSæ¨¡å‹ã€‚è¯¥ç ”ç©¶å¼•å…¥GaussianBridgeæŠ€æœ¯å°†éç»“æ„åŒ–çš„ä¸‰ç»´é«˜æ–¯è½¬åŒ–ä¸ºSplatter Imageæ ¼å¼ï¼Œä½¿ç¥ç»å¤„ç†å¾—ä»¥åµŒå…¥ä»»æ„ä¿¡æ¯æˆä¸ºå¯èƒ½ã€‚ä¸ºä¿ç•™è§†è§‰æ•ˆæœåŒæ—¶ä¿è¯ä¸è¢«è§‰å¯Ÿæ€§ï¼Œå…¶æå‡ºäº†åˆ©ç”¨é«˜æ–¯ä¸ç¡®å®šæ€§é¢„æµ‹ç­–ç•¥ä¿éšœå›¾åƒè´¨é‡ã€‚å¹¶ä¸”å»ºç«‹äº†ä¸€å¥—å¯†åº¦åˆ†å‰²æŠ€æœ¯ä»¥ä¿éšœæ°´å°åœ¨å¾®å¼±ä¿¡æ¯è¦†ç›–ç¯å¢ƒä¸‹ä»èƒ½å¤Ÿè¢«å®Œæ•´æå–ã€‚é¡¹ç›®é¡µé¢é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://kevinhuangxf.github.io/marksplatter">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹ä»æ–‡æœ¬ä¸­æ€»ç»“å‡ºå…³é”®çš„ä¸ƒç‚¹å†…å®¹ï¼š</p>
<ul>
<li>ä¸‰ç»´é«˜æ–¯æ˜ å°„ï¼ˆ3DGSï¼‰é€æ¸æˆä¸ºçƒ­ç‚¹ï¼Œå› æ­¤ç‰ˆæƒä¿æŠ¤çš„éœ€æ±‚åŠ å¤§ã€‚å½“å‰çš„æ°´å°æŠ€æœ¯éš¾ä»¥æ»¡è¶³ç°å®éœ€æ±‚ï¼Œå…¶éœ€è¿‡äºå¤æ‚ç²¾ç»†çš„é¢„å¤„ç†ã€‚æ­¤é¡¹ç ”ç©¶åˆ™åˆ›æ–°æ€§åœ°æ¨å‡ºäº†å¯ä¸€èˆ¬åŒ–çš„è§£å†³æ–¹æ¡ˆç”¨äºåº”å¯¹è¿™ä¸ªé—®é¢˜ã€‚ </li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ°´å°æ¡†æ¶æŠ€æœ¯â€”â€”GaussianBridgeï¼Œèƒ½å¤Ÿå°†éç»“æ„åŒ–ä¸‰ç»´é«˜æ–¯æ•°æ®è½¬åŒ–ä¸ºSplatter Imageæ ¼å¼è¿›è¡Œä¾¿æ·å¤„ç†ã€‚è¿™æé«˜äº†ä¿¡æ¯åµŒå…¥çš„æ•ˆç‡å¹¶æ‹“å®½äº†å…¶åº”ç”¨èŒƒå›´ã€‚ </li>
<li>ä¸ºäº†ç¡®ä¿æ°´å°çš„éšè”½æ€§ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†åŸºäºé«˜æ–¯ä¸ç¡®å®šæ€§æ„ŸçŸ¥å›¾çš„é¢„æµ‹ç­–ç•¥æ¥ä¿æŒå›¾åƒè´¨é‡ä¸å˜ã€‚è¿™ç¡®ä¿äº†æ°´å°çš„åµŒå…¥ä¸ä¼šç ´ååŸå§‹å›¾åƒçš„è§†è§‰è´¨é‡ã€‚ </li>
<li>ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§åŸºäºå¯†é›†åˆ†å‰²çš„æ°´å°æå–æœºåˆ¶ï¼Œè¿™ä¸€æœºåˆ¶åœ¨å³ä½¿æ˜¯å¾®å°åŒºåŸŸå†…ä¾ç„¶å¯ä»¥ç¨³å®šåœ°æå–æ°´å°ä¿¡æ¯ã€‚è¿™å¯¹äºåœ¨å„ç§è§†è§’è·å–å›¾åƒçš„è§†è§‰æ•ˆæœè¿›è¡Œäº†åŠ å¼ºä¼˜åŒ–ï¼Œä¸”ä¸æ˜“å› å˜æ¢è§†è§’å¯¼è‡´æ°´å°å¤±æ•ˆæˆ–éš¾ä»¥æå–çš„é—®é¢˜ã€‚ </li>
<li>é¡¹ç›®æä¾›äº†ä¸€ä¸ªè¯¦ç»†çš„é¡¹ç›®é¡µé¢ï¼Œå…¶ä¸­åŒ…æ‹¬è¯¥ç ”ç©¶çš„è¯¦ç»†ä¿¡æ¯ã€æˆæœå±•ç¤ºç­‰ä»¥ä¾›ç ”ç©¶è€…å’Œå…¬ä¼—å‚è€ƒã€‚è¯¥é¡µé¢åŒ…å«äº†è¿›ä¸€æ­¥çš„å®éªŒç»“æœå’Œåº”ç”¨ç¤ºä¾‹é“¾æ¥ç­‰èµ„æºä»¥ä¾›å…±äº«ä¸æŸ¥è¯¢åˆ©ç”¨ã€‚ </li>
<li>ä¸Šè¿°æ–¹æ³•çš„ä¼˜ç‚¹ä½“ç°åœ¨ç®€å•æœ‰æ•ˆçš„ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆå’Œèƒ½åœ¨å‡ ä¹ä¸å—è§†åœºé™åˆ¶çš„å¤æ‚åœºæ™¯ä¸­å‘æŒ¥æ•ˆæœçš„èƒ½åŠ›ä¸Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00757">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-69f2bfe6f45af1301fb21137b1b7cd75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b77b0f531da135587a342515d212b91c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ae90a4bf09d7b7712b59829ba0b83b1.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DyPho-SLAM-Real-time-Photorealistic-SLAM-in-Dynamic-Environments"><a href="#DyPho-SLAM-Real-time-Photorealistic-SLAM-in-Dynamic-Environments" class="headerlink" title="DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments"></a>DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments</h2><p><strong>Authors:Yi Liu, Keyu Fan, Bin Lan, Houde Liu</strong></p>
<p>Visual SLAM algorithms have been enhanced through the exploration of Gaussian Splatting representations, particularly in generating high-fidelity dense maps. While existing methods perform reliably in static environments, they often encounter camera tracking drift and fuzzy mapping when dealing with the disturbances caused by moving objects. This paper presents DyPho-SLAM, a real-time, resource-efficient visual SLAM system designed to address the challenges of localization and photorealistic mapping in environments with dynamic objects. Specifically, the proposed system integrates prior image information to generate refined masks, effectively minimizing noise from mask misjudgment. Additionally, to enhance constraints for optimization after removing dynamic obstacles, we devise adaptive feature extraction strategies significantly improving the systemâ€™s resilience. Experiments conducted on publicly dynamic RGB-D datasets demonstrate that the proposed system achieves state-of-the-art performance in camera pose estimation and dense map reconstruction, while operating in real-time in dynamic scenes. </p>
<blockquote>
<p>è§†è§‰SLAMç®—æ³•é€šè¿‡æ¢ç´¢é«˜æ–¯åˆ†å¸ƒå›¾ï¼ˆGaussian Splattingï¼‰è¡¨ç¤ºæ–¹æ³•å¾—åˆ°äº†å¢å¼ºï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆé«˜ä¿çœŸç¨ å¯†åœ°å›¾æ–¹é¢ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•åœ¨é™æ€ç¯å¢ƒä¸­è¡¨ç°å¯é ï¼Œä½†åœ¨å¤„ç†ç§»åŠ¨ç‰©ä½“å¼•èµ·çš„å¹²æ‰°æ—¶ï¼Œå®ƒä»¬ç»å¸¸é‡åˆ°æ‘„åƒæœºè·Ÿè¸ªæ¼‚ç§»å’Œæ¨¡ç³Šæ˜ å°„çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†DyPho-SLAMï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè§£å†³åŠ¨æ€å¯¹è±¡ç¯å¢ƒä¸­å®šä½å’Œé€¼çœŸåº¦æ˜ å°„æŒ‘æˆ˜çš„å®æ—¶ã€èµ„æºé«˜æ•ˆçš„è§†è§‰SLAMç³»ç»Ÿã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†å…ˆå‰çš„å›¾åƒä¿¡æ¯æ¥ç”Ÿæˆç²¾ç»†çš„æ©è†œï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†å› æ©è†œè¯¯åˆ¤è€Œäº§ç”Ÿçš„å™ªå£°ã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜å»é™¤åŠ¨æ€éšœç¢åçš„ä¼˜åŒ–çº¦æŸï¼Œæˆ‘ä»¬è®¾è®¡äº†è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥ï¼Œå¤§å¤§æé«˜äº†ç³»ç»Ÿçš„æ¢å¤èƒ½åŠ›ã€‚åœ¨å…¬å¼€çš„åŠ¨æ€RGB-Dæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œå¯†é›†åœ°å›¾é‡å»ºæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ŒåŒæ—¶åœ¨åŠ¨æ€åœºæ™¯ä¸­å®ç°äº†å®æ—¶è¿è¡Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00741v1">PDF</a> Accepted by ICME 2025(Oral)</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºDyPho-SLAMç³»ç»Ÿï¼Œåˆ©ç”¨é«˜æ–¯Splattingè¡¨ç¤ºæ³•å¢å¼ºè§†è§‰SLAMç®—æ³•ï¼Œä»¥åº”å¯¹åŠ¨æ€ç¯å¢ƒä¸‹çš„å®šä½å’ŒçœŸå®æ„Ÿæ˜ å°„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆå…ˆå‰å›¾åƒä¿¡æ¯ç”Ÿæˆç²¾ç»†é®ç½©ï¼Œå‡å°‘æ¥è‡ªé®ç½©è¯¯åˆ¤çš„å™ªå£°ï¼Œå¹¶é‡‡ç”¨è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥ï¼Œæé«˜ç³»ç»Ÿå¯¹åŠ¨æ€éšœç¢å»é™¤åçš„ä¼˜åŒ–çº¦æŸçš„é€‚åº”æ€§ã€‚åœ¨å…¬å¼€åŠ¨æ€RGB-Dæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œå¯†é›†åœ°å›¾é‡å»ºæ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¯åœ¨åŠ¨æ€åœºæ™¯ä¸­å®æ—¶è¿è¡Œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DyPho-SLAMç³»ç»Ÿåˆ©ç”¨é«˜æ–¯Splattingè¡¨ç¤ºæ³•å¢å¼ºè§†è§‰SLAMç®—æ³•ã€‚</li>
<li>ç³»ç»Ÿæ—¨åœ¨è§£å†³åŠ¨æ€ç¯å¢ƒä¸‹çš„å®šä½å’ŒçœŸå®æ„Ÿæ˜ å°„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡æ•´åˆå…ˆå‰å›¾åƒä¿¡æ¯ç”Ÿæˆç²¾ç»†é®ç½©ï¼Œå‡å°‘æ¥è‡ªé®ç½©è¯¯åˆ¤çš„å™ªå£°ã€‚</li>
<li>é‡‡ç”¨è‡ªé€‚åº”ç‰¹å¾æå–ç­–ç•¥ï¼Œæé«˜ç³»ç»Ÿå¯¹åŠ¨æ€éšœç¢å»é™¤åçš„ä¼˜åŒ–çº¦æŸçš„é€‚åº”æ€§ã€‚</li>
<li>ç³»ç»Ÿåœ¨ç›¸æœºå§¿æ€ä¼°è®¡å’Œå¯†é›†åœ°å›¾é‡å»ºæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>å®éªŒç»“æœåœ¨å…¬å¼€åŠ¨æ€RGB-Dæ•°æ®é›†ä¸ŠéªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00741">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c0c197c21de0477c9d6f11446d711cb5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c4b78e40e5504315309b2e08ba5c33a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d7f67bd8b805199f233c072ec19ebb48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f6056f790c523a980168e32aa48be17.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33c1d9ebcd339fb81bc952be19d9c155.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b8abbe580610bf34da8524dc1ba0500.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-802ec0cc4e02ce40829f146e310cfb2e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AGS-Accelerating-3D-Gaussian-Splatting-SLAM-via-CODEC-Assisted-Frame-Covisibility-Detection"><a href="#AGS-Accelerating-3D-Gaussian-Splatting-SLAM-via-CODEC-Assisted-Frame-Covisibility-Detection" class="headerlink" title="AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame   Covisibility Detection"></a>AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame   Covisibility Detection</h2><p><strong>Authors:Houshu He, Naifeng Jing, Li Jiang, Xiaoyao Liang, Zhuoran Song</strong></p>
<p>Simultaneous Localization and Mapping (SLAM) is a critical task that enables autonomous vehicles to construct maps and localize themselves in unknown environments. Recent breakthroughs combine SLAM with 3D Gaussian Splatting (3DGS) to achieve exceptional reconstruction fidelity. However, existing 3DGS-SLAM systems provide insufficient throughput due to the need for multiple training iterations per frame and the vast number of Gaussians.   In this paper, we propose AGS, an algorithm-hardware co-design framework to boost the efficiency of 3DGS-SLAM based on the intuition that SLAM systems process frames in a streaming manner, where adjacent frames exhibit high similarity that can be utilized for acceleration. On the software level: 1) We propose a coarse-then-fine-grained pose tracking method with respect to the robotâ€™s movement. 2) We avoid redundant computations of Gaussians by sharing their contribution information across frames. On the hardware level, we propose a frame covisibility detection engine to extract intermediate data from the video CODEC. We also implement a pose tracking engine and a mapping engine with workload schedulers to efficiently deploy the AGS algorithm. Our evaluation shows that AGS achieves up to $17.12\times$, $6.71\times$, and $5.41\times$ speedups against the mobile and high-end GPUs, and a state-of-the-art 3DGS accelerator, GSCore. </p>
<blockquote>
<p>åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰æ˜¯ä¸€é¡¹å…³é”®ä»»åŠ¡ï¼Œå®ƒä½¿è‡ªä¸»è½¦è¾†èƒ½å¤Ÿåœ¨æœªçŸ¥ç¯å¢ƒä¸­æ„å»ºåœ°å›¾å¹¶å®šä½è‡ªèº«ã€‚æœ€è¿‘çš„çªç ´ç»“åˆäº†SLAMä¸ä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œå®ç°äº†å“è¶Šçš„é‡å»ºä¿çœŸåº¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº3DGSçš„SLAMç³»ç»Ÿç”±äºæ¯å¸§éœ€è¦å¤šæ¬¡è®­ç»ƒè¿­ä»£å’Œå¤§é‡çš„é«˜æ–¯æ•°æ®ï¼Œå¯¼è‡´ååé‡ä¸è¶³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†AGSç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§è½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜åŸºäº3DGSçš„SLAMçš„æ•ˆç‡ã€‚æˆ‘ä»¬çš„ç›´è§‰æ˜¯SLAMç³»ç»Ÿä»¥æµå¼æ–¹å¼å¤„ç†å¸§ï¼Œç›¸é‚»å¸§ä¹‹é—´å…·æœ‰é«˜åº¦çš„ç›¸ä¼¼æ€§ï¼Œè¿™å¯ä»¥ç”¨äºåŠ é€Ÿã€‚åœ¨è½¯ä»¶å±‚é¢ï¼šé¦–å…ˆæå‡ºä¸€ç§ç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„æœºå™¨äººè¿åŠ¨å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼›å…¶æ¬¡ï¼Œæˆ‘ä»¬é€šè¿‡å…±äº«é«˜æ–¯å‡½æ•°çš„è´¡çŒ®ä¿¡æ¯æ¥é¿å…å†—ä½™è®¡ç®—ã€‚åœ¨ç¡¬ä»¶å±‚é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¸§å…±å¯è§æ€§æ£€æµ‹å¼•æ“ï¼Œèƒ½å¤Ÿä»è§†é¢‘ç¼–è§£ç å™¨ä¸­æå–ä¸­é—´æ•°æ®ã€‚æˆ‘ä»¬è¿˜å®ç°äº†ä¸€ä¸ªå¸¦æœ‰å·¥ä½œè´Ÿè½½è°ƒåº¦å™¨çš„å§¿æ€è·Ÿè¸ªå¼•æ“å’Œæ˜ å°„å¼•æ“ï¼Œä»¥æœ‰æ•ˆåœ°éƒ¨ç½²AGSç®—æ³•ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä¸ç§»åŠ¨å’Œé«˜ç«¯GPUä»¥åŠæœ€å…ˆè¿›çš„3DGSåŠ é€Ÿå™¨GSCoreç›¸æ¯”ï¼ŒAGSåˆ†åˆ«å®ç°äº†æœ€é«˜è¾¾17.12å€ã€6.71å€å’Œ5.41å€çš„åŠ é€Ÿæ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00433v1">PDF</a> 15 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºAGSçš„ç®—æ³•-ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜åŸºäºä¸‰ç»´é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆ3DGSï¼‰çš„åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰ç³»ç»Ÿçš„æ•ˆç‡ã€‚é€šè¿‡åˆ©ç”¨ç›¸é‚»å¸§çš„é«˜ç›¸ä¼¼æ€§è¿›è¡ŒåŠ é€Ÿï¼Œè½¯ä»¶å±‚é¢é‡‡ç”¨ç²—åˆ°ç»†ç²’åº¦çš„å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œé¿å…å†—ä½™è®¡ç®—ï¼Œå¹¶åˆ†äº«é«˜æ–¯è´¡çŒ®ä¿¡æ¯è·¨å¸§ä¼ é€’ï¼›ç¡¬ä»¶å±‚é¢ï¼Œæå‡ºåˆ©ç”¨è§†é¢‘ç¼–è§£ç å™¨çš„å¸§å…±è§†æ£€æµ‹å¼•æ“ï¼Œå¹¶é…ä»¥å§¿æ€è·Ÿè¸ªå¼•æ“å’Œæ˜ å°„å¼•æ“ä¸ä»»åŠ¡è°ƒåº¦å™¨è¿›è¡Œé«˜æ•ˆéƒ¨ç½²ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ç§»åŠ¨ä¸é«˜ç«¯GPUä»¥åŠå½“å‰ä¸»æµçš„ä¸‰ç»´é«˜æ–¯åŠ é€Ÿå™¨GSCoreä¸Šå®ç°äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AGSç®—æ³•ç»“åˆäº†è½¯ç¡¬ä»¶è®¾è®¡æé«˜åŸºäº3DGSçš„SLAMç³»ç»Ÿæ•ˆç‡ã€‚</li>
<li>åˆ©ç”¨ç›¸é‚»å¸§çš„é«˜ç›¸ä¼¼æ€§è¿›è¡ŒåŠ é€Ÿï¼Œæå‡äº†ç³»ç»Ÿçš„å®æ—¶æ€§èƒ½ã€‚</li>
<li>è½¯ä»¶å±‚é¢é‡‡ç”¨ç²—åˆ°ç»†ç²’åº¦çš„å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œé¿å…å†—ä½™è®¡ç®—ã€‚</li>
<li>é€šè¿‡åˆ†äº«é«˜æ–¯è´¡çŒ®ä¿¡æ¯è·¨å¸§ä¼ é€’ï¼Œä¼˜åŒ–äº†è®¡ç®—èµ„æºçš„ä½¿ç”¨ã€‚</li>
<li>ç¡¬ä»¶å±‚é¢åˆ©ç”¨è§†é¢‘ç¼–è§£ç å™¨çš„å¸§å…±è§†æ£€æµ‹å¼•æ“æå–ä¸­é—´æ•°æ®ã€‚</li>
<li>å®ç°äº†é«˜æ•ˆçš„å§¿æ€è·Ÿè¸ªå¼•æ“å’Œæ˜ å°„å¼•æ“é…åˆä»»åŠ¡è°ƒåº¦å™¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00433">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5449e922265caea3466230f494185d31.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab9c6fab24ad9f1df5d2c6d99848349a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2b4beadadd9643481cd90251b087912.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40f2b19ad912889d082efe481ca6ba37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ba0abf8723a3344bd9e282536fde8e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32511861fb578f60ccd54f9d96586fc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb8c2ab5361be0448d431fcc0764bac7.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Scale-GS-Efficient-Scalable-Gaussian-Splatting-via-Redundancy-filtering-Training-on-Streaming-Content"><a href="#Scale-GS-Efficient-Scalable-Gaussian-Splatting-via-Redundancy-filtering-Training-on-Streaming-Content" class="headerlink" title="Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering   Training on Streaming Content"></a>Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering   Training on Streaming Content</h2><p><strong>Authors:Jiayu Yang, Weijian Su, Songqian Zhang, Yuqi Han, Jinli Suo, Qiang Zhang</strong></p>
<p>3D Gaussian Splatting (3DGS) enables high-fidelity real-time rendering, a key requirement for immersive applications. However, the extension of 3DGS to dynamic scenes remains limitations on the substantial data volume of dense Gaussians and the prolonged training time required for each frame. This paper presents \M, a scalable Gaussian Splatting framework designed for efficient training in streaming tasks. Specifically, Gaussian spheres are hierarchically organized by scale within an anchor-based structure. Coarser-level Gaussians represent the low-resolution structure of the scene, while finer-level Gaussians, responsible for detailed high-fidelity rendering, are selectively activated by the coarser-level Gaussians. To further reduce computational overhead, we introduce a hybrid deformation and spawning strategy that models motion of inter-frame through Gaussian deformation and triggers Gaussian spawning to characterize wide-range motion. Additionally, a bidirectional adaptive masking mechanism enhances training efficiency by removing static regions and prioritizing informative viewpoints. Extensive experiments demonstrate that \M~ achieves superior visual quality while significantly reducing training time compared to state-of-the-art methods. </p>
<blockquote>
<p>3Dé«˜æ–¯ç»˜åˆ¶ï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°é«˜ä¿çœŸå®æ—¶æ¸²æŸ“ï¼Œè¿™æ˜¯æ²‰æµ¸å¼åº”ç”¨çš„å…³é”®è¦æ±‚ã€‚ç„¶è€Œï¼Œå°†3DGSæ‰©å±•åˆ°åŠ¨æ€åœºæ™¯æ—¶ï¼Œå¯†é›†é«˜æ–¯çš„å¤§é‡æ•°æ®ä½“ç§¯å’Œæ¯å¸§æ‰€éœ€çš„å»¶é•¿è®­ç»ƒæ—¶é—´ä»å­˜åœ¨é™åˆ¶ã€‚æœ¬æ–‡æå‡ºäº†\Mï¼Œä¸€ç§é¢å‘æµå¼ä»»åŠ¡é«˜æ•ˆè®­ç»ƒçš„å¯æ‰©å±•é«˜æ–¯ç»˜åˆ¶æ¡†æ¶ã€‚å…·ä½“è€Œè¨€ï¼Œé«˜æ–¯çƒæ˜¯æŒ‰å°ºåº¦åœ¨é”šç‚¹åŸºç¡€ä¸Šè¿›è¡Œå±‚æ¬¡ç»“æ„ç»„ç»‡çš„ã€‚è¾ƒç²—çº§åˆ«çš„é«˜æ–¯è¡¨ç¤ºåœºæ™¯çš„ä½åˆ†è¾¨ç‡ç»“æ„ï¼Œè€Œè¾ƒç»†çº§åˆ«çš„é«˜æ–¯è´Ÿè´£è¯¦ç»†çš„é«˜ä¿çœŸæ¸²æŸ“ï¼Œå¹¶ç”±è¾ƒç²—çº§åˆ«çš„é«˜æ–¯é€‰æ‹©æ€§åœ°æ¿€æ´»ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–è®¡ç®—å¼€é”€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ··åˆå˜å½¢å’Œç”Ÿæˆç­–ç•¥ï¼Œé€šè¿‡é«˜æ–¯å˜å½¢å¯¹å¸§é—´è¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è§¦å‘é«˜æ–¯ç”Ÿæˆä»¥è¡¨å¾å¤§èŒƒå›´è¿åŠ¨ã€‚æ­¤å¤–ï¼ŒåŒå‘è‡ªé€‚åº”æ©ç æœºåˆ¶é€šè¿‡å»é™¤é™æ€åŒºåŸŸå¹¶ä¼˜å…ˆå¤„ç†ä¿¡æ¯ä¸°å¯Œçš„è§†ç‚¹ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œ\M~åœ¨è¾¾åˆ°ä¼˜è¶Šè§†è§‰è´¨é‡çš„åŒæ—¶ï¼Œä¸æœ€æ–°æ–¹æ³•ç›¸æ¯”æ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.21444v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹åŠ¨æ€åœºæ™¯çš„é«˜æ•ˆæ¸²æŸ“æŠ€æœ¯ï¼Œæå‡ºäº†åŸºäºé”šç‚¹çš„åˆ†å±‚é«˜æ–¯çƒä½“æ¡†æ¶ï¼Œå¹¶ç»“åˆæ··åˆå˜å½¢ä¸ç¹æ®–ç­–ç•¥ï¼Œå®ç°é«˜æ•ˆè®­ç»ƒã€‚è¯¥æŠ€æœ¯æé«˜äº†å®æ—¶æ¸²æŸ“çš„è§†è§‰æ•ˆæœï¼ŒåŒæ—¶æ˜¾è‘—ç¼©çŸ­äº†è®­ç»ƒæ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSå¯ç”¨äºå®ç°é«˜ä¿çœŸå®æ—¶æ¸²æŸ“ï¼Œé€‚ç”¨äºæ²‰æµ¸å¼åº”ç”¨ã€‚</li>
<li>ç°æœ‰çš„åŠ¨æ€åœºæ™¯æ¸²æŸ“æŠ€æœ¯åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦é•¿æ—¶é—´è®­ç»ƒã€‚</li>
<li>æå‡ºçš„åˆ†å±‚é«˜æ–¯çƒä½“æ¡†æ¶èƒ½å¤Ÿé«˜æ•ˆå¤„ç†åŠ¨æ€åœºæ™¯ï¼Œé€šè¿‡ç²—ç²’åº¦é«˜æ–¯è¡¨ç¤ºä½åˆ†è¾¨ç‡åœºæ™¯ç»“æ„ï¼Œç»†ç²’åº¦é«˜æ–¯è´Ÿè´£é«˜ä¿çœŸæ¸²æŸ“ã€‚</li>
<li>æ··åˆå˜å½¢å’Œç¹æ®–ç­–ç•¥ç”¨äºå‡å°‘è®¡ç®—å¼€é”€ï¼Œé€šè¿‡é«˜æ–¯å˜å½¢æ¨¡æ‹Ÿå¸§é—´è¿åŠ¨ï¼Œé€šè¿‡é«˜æ–¯ç¹æ®–è¡¨å¾å¤§èŒƒå›´è¿åŠ¨ã€‚</li>
<li>åŒå‘è‡ªé€‚åº”æ©ç æœºåˆ¶æé«˜è®­ç»ƒæ•ˆç‡ï¼Œå»é™¤é™æ€åŒºåŸŸå¹¶ä¼˜å…ˆå…³æ³¨ä¿¡æ¯ä¸°å¯Œçš„è§†ç‚¹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.21444">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-14edddc3c635b44f92c72780bfc1320c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98b8488ef434dcd9f080a7b50a5debd9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59acfda108644776cc82d84de07f29d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-984ec9b9ee68dfa3f7b9d8e40644ed55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14eca08e364bff0c825c5ff46983d533.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="DrivingGaussian-Towards-Realistic-Reconstruction-and-Editable-Simulation-for-Surrounding-Dynamic-Driving-Scenes"><a href="#DrivingGaussian-Towards-Realistic-Reconstruction-and-Editable-Simulation-for-Surrounding-Dynamic-Driving-Scenes" class="headerlink" title="DrivingGaussian++: Towards Realistic Reconstruction and Editable   Simulation for Surrounding Dynamic Driving Scenes"></a>DrivingGaussian++: Towards Realistic Reconstruction and Editable   Simulation for Surrounding Dynamic Driving Scenes</h2><p><strong>Authors:Yajiao Xiong, Xiaoyu Zhou, Yongtao Wan, Deqing Sun, Ming-Hsuan Yang</strong></p>
<p>We present DrivingGaussian++, an efficient and effective framework for realistic reconstructing and controllable editing of surrounding dynamic autonomous driving scenes. DrivingGaussian++ models the static background using incremental 3D Gaussians and reconstructs moving objects with a composite dynamic Gaussian graph, ensuring accurate positions and occlusions. By integrating a LiDAR prior, it achieves detailed and consistent scene reconstruction, outperforming existing methods in dynamic scene reconstruction and photorealistic surround-view synthesis. DrivingGaussian++ supports training-free controllable editing for dynamic driving scenes, including texture modification, weather simulation, and object manipulation, leveraging multi-view images and depth priors. By integrating large language models (LLMs) and controllable editing, our method can automatically generate dynamic object motion trajectories and enhance their realism during the optimization process. DrivingGaussian++ demonstrates consistent and realistic editing results and generates dynamic multi-view driving scenarios, while significantly enhancing scene diversity. More results and code can be found at the project site: <a target="_blank" rel="noopener" href="https://xiong-creator.github.io/DrivingGaussian_plus.github.io">https://xiong-creator.github.io/DrivingGaussian_plus.github.io</a> </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†DrivingGaussian++ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜æ•ˆä¸”å®ç”¨çš„æ¡†æ¶ï¼Œç”¨äºç°å®ä¸»ä¹‰çš„é‡å»ºå’Œå¯æ§ç¼–è¾‘å‘¨å›´çš„åŠ¨æ€è‡ªåŠ¨é©¾é©¶åœºæ™¯ã€‚DrivingGaussian++ä½¿ç”¨å¢é‡3Dé«˜æ–¯å¯¹é™æ€èƒŒæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ç”¨å¤åˆåŠ¨æ€é«˜æ–¯å›¾é‡å»ºç§»åŠ¨ç‰©ä½“ï¼Œç¡®ä¿å‡†ç¡®çš„ä½ç½®å’Œé®æŒ¡ã€‚é€šè¿‡é›†æˆæ¿€å…‰é›·è¾¾å…ˆéªŒä¿¡æ¯ï¼Œå®ƒå®ç°äº†è¯¦ç»†ä¸”ä¸€è‡´çš„åœºæ™¯é‡å»ºï¼Œåœ¨åŠ¨æ€åœºæ™¯é‡å»ºå’ŒçœŸå®æ„Ÿç¯ç»•è§†å›¾åˆæˆæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚DrivingGaussian++æ”¯æŒå¯¹åŠ¨æ€é©¾é©¶åœºæ™¯è¿›è¡Œæ— è®­ç»ƒæ§åˆ¶ç¼–è¾‘ï¼ŒåŒ…æ‹¬çº¹ç†ä¿®æ”¹ã€å¤©æ°”æ¨¡æ‹Ÿå’Œå¯¹è±¡æ“ä½œï¼Œåˆ©ç”¨å¤šè§†å›¾å›¾åƒå’Œæ·±åº¦å…ˆéªŒä¿¡æ¯ã€‚é€šè¿‡é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ§åˆ¶ç¼–è¾‘ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è‡ªåŠ¨ç”ŸæˆåŠ¨æ€å¯¹è±¡è¿åŠ¨è½¨è¿¹ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¢å¼ºå®ƒä»¬çš„çœŸå®æ€§ã€‚DrivingGaussian++å±•ç¤ºäº†è¿è´¯å’Œç°å®çš„ç¼–è¾‘ç»“æœï¼Œç”ŸæˆåŠ¨æ€å¤šè§†å›¾é©¾é©¶åœºæ™¯ï¼ŒåŒæ—¶æ˜¾è‘—å¢å¼ºäº†åœºæ™¯å¤šæ ·æ€§ã€‚æ›´å¤šç»“æœå’Œä»£ç å¯åœ¨é¡¹ç›®ç½‘ç«™æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://xiong-creator.github.io/DrivingGaussian_plus.github.io%E3%80%82">https://xiong-creator.github.io/DrivingGaussian_plus.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20965v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é©¾é©¶åœºæ™¯é‡å»ºä¸ç¼–è¾‘çš„æ–°æ¡†æ¶DrivingGaussian++èƒ½å¤Ÿæœ‰æ•ˆæ¨¡æ‹Ÿå¹¶æ§åˆ¶è‡ªä¸»é©¾é©¶å‘¨å›´åŠ¨æ€åœºæ™¯çš„é‡å»ºã€‚å®ƒåˆ©ç”¨å¢é‡3Dé«˜æ–¯æ¨¡å‹èƒŒæ™¯ï¼Œå¹¶é€šè¿‡åŠ¨æ€é«˜æ–¯å›¾é‡å»ºç§»åŠ¨ç‰©ä½“ï¼Œç¡®ä¿å‡†ç¡®çš„ä½ç½®ä¸é®æŒ¡å¤„ç†ã€‚ç»“åˆLiDARå…ˆéªŒä¿¡æ¯ï¼Œå®ç°è¯¦ç»†ä¸”ä¸€è‡´çš„åœºæ™¯é‡å»ºï¼Œå¹¶åœ¨åŠ¨æ€åœºæ™¯é‡å»ºå’ŒçœŸå®æ„Ÿç¯ç»•è§†å›¾åˆæˆæ–¹é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚DrivingGaussian++æ”¯æŒæ— è®­ç»ƒå¯æ§ç¼–è¾‘åŠ¨æ€é©¾é©¶åœºæ™¯ï¼ŒåŒ…æ‹¬çº¹ç†ä¿®æ”¹ã€å¤©æ°”æ¨¡æ‹Ÿå’Œç‰©ä½“æ“ä½œç­‰ï¼Œåˆ©ç”¨å¤šè§†è§’å›¾åƒå’Œæ·±åº¦å…ˆéªŒä¿¡æ¯ã€‚æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¯æ§ç¼–è¾‘åŠŸèƒ½ï¼Œèƒ½å¤Ÿè‡ªåŠ¨äº§ç”ŸåŠ¨æ€ç‰©ä½“è¿åŠ¨è½¨è¿¹ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æå‡çœŸå®æ„Ÿã€‚DrivingGaussian++èƒ½ç”Ÿæˆè¿è´¯ä¸”çœŸå®çš„ç¼–è¾‘ç»“æœå’ŒåŠ¨æ€å¤šè§†è§’é©¾é©¶åœºæ™¯ï¼Œå¤§å¹…å¢å¼ºåœºæ™¯å¤šæ ·æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DrivingGaussian++èƒ½æœ‰æ•ˆé‡å»ºè‡ªä¸»é©¾é©¶å‘¨å›´çš„åŠ¨æ€åœºæ™¯ã€‚</li>
<li>ä½¿ç”¨å¢é‡3Dé«˜æ–¯å»ºæ¨¡é™æ€èƒŒæ™¯ï¼Œé€šè¿‡åŠ¨æ€é«˜æ–¯å›¾é‡å»ºç§»åŠ¨ç‰©ä½“ã€‚</li>
<li>ç»“åˆLiDARå…ˆéªŒä¿¡æ¯å®ç°è¯¦ç»†ä¸”ä¸€è‡´çš„åœºæ™¯é‡å»ºã€‚</li>
<li>æ”¯æŒæ— è®­ç»ƒå¯æ§ç¼–è¾‘ï¼ŒåŒ…æ‹¬çº¹ç†ä¿®æ”¹ã€å¤©æ°”æ¨¡æ‹Ÿå’Œç‰©ä½“æ“ä½œã€‚</li>
<li>åˆ©ç”¨å¤šè§†è§’å›¾åƒå’Œæ·±åº¦å…ˆéªŒä¿¡æ¯æå‡ç¼–è¾‘çš„çœŸå®æ„Ÿã€‚</li>
<li>æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥è‡ªåŠ¨ç”ŸæˆåŠ¨æ€ç‰©ä½“è¿åŠ¨è½¨è¿¹ã€‚</li>
<li>ç”Ÿæˆè¿è´¯ä¸”çœŸå®çš„ç¼–è¾‘ç»“æœå’ŒåŠ¨æ€å¤šè§†è§’é©¾é©¶åœºæ™¯ï¼Œå¢å¼ºåœºæ™¯å¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20965">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-616e2a17571b35953a69959ac1cc0423.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3e2984ae8a31dccc79156cc21287099.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0b742b571c034ef2859818730fefde3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b67ed725dafc8fb9c0e15147c53a77a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10bb00fab3755d94f5f6e51e625c3aaa.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Communication-Efficient-Robotic-Mixed-Reality-with-Gaussian-Splatting-Cross-Layer-Optimization"><a href="#Communication-Efficient-Robotic-Mixed-Reality-with-Gaussian-Splatting-Cross-Layer-Optimization" class="headerlink" title="Communication Efficient Robotic Mixed Reality with Gaussian Splatting   Cross-Layer Optimization"></a>Communication Efficient Robotic Mixed Reality with Gaussian Splatting   Cross-Layer Optimization</h2><p><strong>Authors:Chenxuan Liu, He Li, Zongze Li, Shuai Wang, Wei Xu, Kejiang Ye, Derrick Wing Kwan Ng, Chengzhong Xu</strong></p>
<p>Realizing low-cost communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSMR), which enables the simulator to opportunistically render a photo-realistic view from the robotâ€™s pose by calling &#96;&#96;memoryâ€™â€™ from a GS model, thus reducing the need for excessive image uploads. However, the GS model may involve discrepancies compared to the actual environments. To this end, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation (i.e., adjusting to content profiles) across different frames by minimizing a newly derived GSMR loss function. The GSCLO problem is addressed by an accelerated penalty optimization (APO) algorithm that reduces computational complexity by over $10$x compared to traditional branch-and-bound and search algorithms. Moreover, variants of GSCLO are presented to achieve robust, low-power, and multi-robot GSMR. Extensive experiments demonstrate that the proposed GSMR paradigm and GSCLO method achieve significant improvements over existing benchmarks on both wheeled and legged robots in terms of diverse metrics in various scenarios. For the first time, it is found that RoboMR can be achieved with ultra-low communication costs, and mixture of data is useful for enhancing GS performance in dynamic scenarios. </p>
<blockquote>
<p>åœ¨æœºå™¨äººæ··åˆç°å®ï¼ˆRoboMRï¼‰ç³»ç»Ÿä¸­å®ç°ä½æˆæœ¬é€šä¿¡æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºéœ€è¦é€šè¿‡æ— çº¿ä¿¡é“ä¸Šä¼ é«˜åˆ†è¾¨ç‡å›¾åƒã€‚æœ¬æ–‡æå‡ºäº†é«˜æ–¯å–·æº…ï¼ˆGSï¼‰RoboMRï¼ˆGSMRï¼‰ï¼Œä½¿æ¨¡æ‹Ÿå™¨èƒ½å¤Ÿé€šè¿‡ä»GSæ¨¡å‹ä¸­è°ƒç”¨â€œå†…å­˜â€æ¥éšæœºå‘ˆç°æœºå™¨äººçš„é€¼çœŸè§†å›¾ï¼Œä»è€Œå‡å°‘å¯¹è¿‡å¤šå›¾åƒä¸Šä¼ çš„éœ€æ±‚ã€‚ç„¶è€Œï¼Œä¸çœŸå®ç¯å¢ƒç›¸æ¯”ï¼ŒGSæ¨¡å‹å¯èƒ½å­˜åœ¨å·®å¼‚ã€‚ä¸ºæ­¤ï¼Œè¿›ä¸€æ­¥æå‡ºäº†GSè·¨å±‚ä¼˜åŒ–ï¼ˆGSCLOï¼‰æ¡†æ¶ï¼Œé€šè¿‡æœ€å°åŒ–æ–°æ¨å‡ºçš„GSMRæŸå¤±å‡½æ•°ï¼Œè”åˆä¼˜åŒ–å†…å®¹åˆ‡æ¢ï¼ˆå³å†³å®šæ˜¯å¦ä¸Šä¼ å›¾åƒï¼‰å’ŒåŠŸç‡åˆ†é…ï¼ˆå³é€‚åº”å†…å®¹é…ç½®æ–‡ä»¶ï¼‰ã€‚ä¸åŒå¸§çš„GSCLOé—®é¢˜é€šè¿‡åŠ é€Ÿæƒ©ç½šä¼˜åŒ–ï¼ˆAPOï¼‰ç®—æ³•æ¥è§£å†³ï¼Œè¯¥ç®—æ³•çš„è®¡ç®—å¤æ‚åº¦æ¯”ä¼ ç»Ÿçš„åˆ†æ”¯ç•Œå®šå’Œæœç´¢ç®—æ³•é™ä½äº†è¶…è¿‡10å€ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†å¤šç§GSCLOå˜ä½“ï¼Œä»¥å®ç°ç¨³å¥ã€ä½åŠŸè€—å’Œå¤šæœºå™¨äººGSMRã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„GSMRèŒƒå¼å’ŒGSCLOæ–¹æ³•åœ¨è½®å¼æœºå™¨äººå’Œæ­¥è¡Œæœºå™¨äººä¸Šï¼Œåœ¨å„ç§åœºæ™¯çš„å¤šä¸ªæŒ‡æ ‡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚é¦–æ¬¡å‘ç°ï¼ŒRoboMRå¯ä»¥å®ç°è¶…ä½é€šä¿¡æˆæœ¬ï¼Œå¹¶ä¸”æ•°æ®çš„æ··åˆå¯¹äºæé«˜åŠ¨æ€åœºæ™¯ä¸­çš„GSæ€§èƒ½å¾ˆæœ‰ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08624v2">PDF</a> 14 pages, 18 figures, to appear in IEEE Transactions on Cognitive   Communications and Networking</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‚¹äº‘æŠ€æœ¯ï¼ˆGSï¼‰çš„æœºå™¨äººæ··åˆç°å®ï¼ˆRoboMRï¼‰ç³»ç»Ÿä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡è°ƒç”¨GSæ¨¡å‹çš„â€œè®°å¿†â€åŠŸèƒ½ï¼Œå®ç°æ¨¡æ‹Ÿå™¨çš„å®æ—¶æ¸²æŸ“ï¼Œå‡å°‘äº†å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šä¼ çš„ä¾èµ–ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œæå‡ºäº†GSè·¨å±‚ä¼˜åŒ–ï¼ˆGSCLOï¼‰æ¡†æ¶ï¼Œè”åˆä¼˜åŒ–å†…å®¹åˆ‡æ¢å’ŒåŠŸç‡åˆ†é…ï¼Œå¹¶é€šè¿‡åŠ é€Ÿæƒ©ç½šä¼˜åŒ–ï¼ˆAPOï¼‰ç®—æ³•è§£å†³è®¡ç®—å¤æ‚åº¦é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è½®å¼å’Œæ­¥è¡Œæœºå™¨äººä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æµ‹è¯•ï¼Œå®ç°äº†è¶…ä½é€šä¿¡æˆæœ¬çš„æ··åˆç°å®åº”ç”¨ã€‚é¦–æ¬¡å‘ç°æ•°æ®æ··åˆå¯¹åŠ¨æ€åœºæ™¯ä¸­GSæ€§èƒ½çš„æå‡æœ‰å¸®åŠ©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯ç‚¹äº‘æŠ€æœ¯ï¼ˆGSï¼‰ç”¨äºæœºå™¨äººæ··åˆç°å®ï¼ˆRoboMRï¼‰ç³»ç»Ÿï¼Œå®ç°å®æ—¶æ¸²æŸ“ã€‚</li>
<li>GSæ¨¡å‹è°ƒç”¨â€œè®°å¿†â€åŠŸèƒ½ï¼Œé™ä½å¯¹é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šä¼ çš„ä¾èµ–ã€‚</li>
<li>æå‡ºGSè·¨å±‚ä¼˜åŒ–ï¼ˆGSCLOï¼‰æ¡†æ¶ï¼Œè”åˆä¼˜åŒ–å†…å®¹åˆ‡æ¢å’ŒåŠŸç‡åˆ†é…ã€‚</li>
<li>ä½¿ç”¨åŠ é€Ÿæƒ©ç½šä¼˜åŒ–ï¼ˆAPOï¼‰ç®—æ³•è§£å†³è®¡ç®—å¤æ‚åº¦é—®é¢˜ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨è½®å¼å’Œæ­¥è¡Œæœºå™¨äººä¸Šå‡ä¼˜äºç°æœ‰åŸºå‡†æµ‹è¯•ã€‚</li>
<li>å®ç°è¶…ä½é€šä¿¡æˆæœ¬çš„æ··åˆç°å®åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08624">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-116871a54f0d39b133b0fc2d624a568c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-252e52d8730fbbadf96527fa63820018.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf05c64c09bde372a1a001d47c6d0f13.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-01325c51bf515f42e40301a4bdc4da1b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9172430e978ed4cea9f0b482e6af28b9.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit"><a href="#DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit" class="headerlink" title="DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of   Fruit"></a>DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of   Fruit</h2><p><strong>Authors:Aiden Swann, Alex Qiu, Matthew Strong, Angelina Zhang, Samuel Morstein, Kai Rayle, Monroe Kennedy III</strong></p>
<p>DexFruit is a robotic manipulation framework that enables gentle, autonomous handling of fragile fruit and precise evaluation of damage. Many fruits are fragile and prone to bruising, thus requiring humans to manually harvest them with care. In this work, we demonstrate by using optical tactile sensing, autonomous manipulation of fruit with minimal damage can be achieved. We show that our tactile informed diffusion policies outperform baselines in both reduced bruising and pick-and-place success rate across three fruits: strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat, a novel technique to represent and quantify visual damage in high-resolution 3D representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring damage lack quantitative rigor or require expensive equipment. With FruitSplat, we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into the 3DGS representation. Furthermore, this representation is modular and general, compatible with any relevant 2D model. Overall, we demonstrate a 92% grasping policy success rate, up to a 20% reduction in visual bruising, and up to an 31% improvement in grasp success rate on challenging fruit compared to our baselines across our three tested fruits. We rigorously evaluate this result with over 630 trials. Please checkout our website at <a target="_blank" rel="noopener" href="https://dex-fruit.github.io/">https://dex-fruit.github.io</a> . </p>
<blockquote>
<p>DexFruitæ˜¯ä¸€ä¸ªæœºå™¨äººæ“ä½œæ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°è„†å¼±æ°´æœçš„è½»æŸ”è‡ªä¸»å¤„ç†å’ŒæŸä¼¤çš„ç²¾ç¡®è¯„ä¼°ã€‚è®¸å¤šæ°´æœéƒ½æ˜¯è„†å¼±çš„ï¼Œå®¹æ˜“æ“¦ä¼¤ï¼Œå› æ­¤éœ€è¦äººä»¬å°å¿ƒåœ°æ‰‹å·¥é‡‡æ‘˜å®ƒä»¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨å…‰å­¦è§¦è§‰æ„Ÿåº”æŠ€æœ¯ï¼Œå±•ç¤ºäº†å¯ä»¥å¯¹æ°´æœè¿›è¡Œè‡ªä¸»æ“ä½œï¼Œä¸”èƒ½å¤Ÿå°½é‡å‡å°‘æŸä¼¤ã€‚æˆ‘ä»¬å±•ç¤ºæˆ‘ä»¬çš„è§¦è§‰æ„ŸçŸ¥æ‰©æ•£ç­–ç•¥åœ¨å‡å°‘æ“¦ä¼¤å’Œå–æ”¾æˆåŠŸç‡æ–¹é¢è¶…è¿‡äº†åŸºçº¿æ ‡å‡†ï¼Œè¿™ä¸€ä¼˜åŠ¿åœ¨è‰è“ã€ç•ªèŒ„å’Œé»‘è“ä¸‰ç§æ°´æœä¸Šéƒ½å¾—åˆ°äº†ä½“ç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ä¸€ç§åä¸ºFruitSplatçš„æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯é€šè¿‡3Dé«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰ä»¥é«˜åˆ†è¾¨ç‡çš„3Dè¡¨ç°å½¢å¼æ¥å‘ˆç°å’Œé‡åŒ–è§†è§‰æŸä¼¤ã€‚ç°æœ‰çš„æŸä¼¤æµ‹é‡æŒ‡æ ‡ç¼ºä¹å®šé‡ä¸¥è°¨æ€§æˆ–éœ€è¦æ˜‚è´µçš„è®¾å¤‡ã€‚å€ŸåŠ©FruitSplatï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªäºŒç»´è‰è“æ©è†œä»¥åŠä¸€ä¸ªäºŒç»´æ“¦ä¼¤åˆ†å‰²æ©è†œè’¸é¦åˆ°3DGSè¡¨ç¤ºä¸­ã€‚æ­¤å¤–ï¼Œè¿™ç§è¡¨ç¤ºæ˜¯æ¨¡å—åŒ–å’Œé€šç”¨çš„ï¼Œä¸ä»»ä½•ç›¸å…³çš„äºŒç»´æ¨¡å‹éƒ½å…¼å®¹ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é«˜è¾¾92%çš„æŠ“å–ç­–ç•¥æˆåŠŸç‡ï¼Œè§†è§‰æ“¦ä¼¤å‡å°‘äº†20%ï¼Œä¸æˆ‘ä»¬åŸºçº¿æ ‡å‡†ç›¸æ¯”ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ°´æœä¸ŠæŠ“å–æˆåŠŸç‡æé«˜äº†31%ã€‚æˆ‘ä»¬åœ¨è¶…è¿‡630æ¬¡çš„è¯•éªŒä¸­å¯¹è¿™ä¸€ç»“æœè¿›è¡Œäº†ä¸¥æ ¼è¯„ä¼°ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™ <a target="_blank" rel="noopener" href="https://dex-fruit.github.io/">https://dex-fruit.github.io</a> äº†è§£æ›´å¤šä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07118v2">PDF</a> 8 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>DexFruitæ¡†æ¶å®ç°äº†å¯¹è„†å¼±æ°´æœçš„è½»æŸ”è‡ªä¸»æ“ä½œä¸æŸä¼¤ç²¾ç¡®è¯„ä¼°ã€‚è¯¥ç ”ç©¶åˆ©ç”¨å…‰å­¦è§¦è§‰æ„ŸçŸ¥æŠ€æœ¯ï¼Œå®ç°äº†è‡ªä¸»æ“ä½œæ°´æœæ—¶å‡å°‘æŸä¼¤çš„ç›®æ ‡ã€‚åœ¨è‰è“ã€ç•ªèŒ„å’Œé»‘è“ä¸‰ç§æ°´æœä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå…¶è§¦è§‰æ„ŸçŸ¥å¼•å¯¼çš„ç­–ç•¥ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•åœ¨å‡å°‘ç ´æŸå’Œæé«˜æ‹¾å–æ”¾ç½®æˆåŠŸç‡ä¸Šå‡æœ‰æ‰€è¶…è¶Šã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¨å‡ºäº†FruitSplatæŠ€æœ¯ï¼Œé€šè¿‡3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰å®ç°é«˜åˆ†è¾¨ç‡çš„3DæŸä¼¤è¡¨ç¤ºå’Œé‡åŒ–ã€‚è¯¥æŠ€æœ¯å¯å°†äºŒç»´æ°´æœæ©è†œå’ŒäºŒç»´æŸä¼¤åˆ†å‰²æ©è†œè½¬åŒ–ä¸º3DGSè¡¨ç¤ºï¼Œæ¨¡å—åŒ–ä¸”é€šç”¨æ€§å¼ºï¼Œé€‚ç”¨äºä»»ä½•ç›¸å…³äºŒç»´æ¨¡å‹ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶å®ç°äº†é«˜è¾¾92%çš„æŠ“å–ç­–ç•¥æˆåŠŸç‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æœ€å¤šå‡å°‘20%çš„è§†è§‰ç ´æŸå’Œæé«˜äº†31%çš„æŒ‘æˆ˜æ€§æ°´æœæŠ“å–æˆåŠŸç‡ã€‚è¯¥ç ”ç©¶é€šè¿‡äº†è¶…è¿‡630æ¬¡è¯•éªŒçš„ä¸¥æ ¼è¯„ä¼°ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è®¿é—®å…¶å®˜ç½‘é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://dex-fruit.github.io./">https://dex-fruit.github.ioã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DexFruitæ¡†æ¶èƒ½å¤Ÿå®ç°è„†å¼±æ°´æœçš„è‡ªä¸»æ“ä½œå’ŒæŸä¼¤è¯„ä¼°ã€‚</li>
<li>åˆ©ç”¨å…‰å­¦è§¦è§‰æ„ŸçŸ¥æŠ€æœ¯å®ç°æ°´æœçš„ä½æŸä¼¤è‡ªä¸»æ“ä½œã€‚</li>
<li>åœ¨ä¸‰ç§æ°´æœä¸Šçš„å®éªŒæ˜¾ç¤ºDexFruitç­–ç•¥ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å‡å°‘äº†ç ´æŸå¹¶æé«˜äº†æ‹¾å–æ”¾ç½®æˆåŠŸç‡ã€‚</li>
<li>å¼•å…¥FruitSplatæŠ€æœ¯ï¼Œåˆ©ç”¨3Dé«˜æ–¯å–·æº…å®ç°é«˜åˆ†è¾¨ç‡çš„3DæŸä¼¤è¡¨ç¤ºå’Œé‡åŒ–ã€‚</li>
<li>FruitSplatæŠ€æœ¯å¯å°†äºŒç»´æ©è†œè½¬åŒ–ä¸ºä¸‰ç»´è¡¨ç¤ºï¼Œå…·æœ‰æ¨¡å—åŒ–ã€é€šç”¨æ€§å¼ºçš„ç‰¹ç‚¹ã€‚</li>
<li>ç ”ç©¶å®ç°äº†é«˜æˆåŠŸç‡æŠ“å–ç­–ç•¥ï¼Œæ˜¾è‘—å‡å°‘äº†è§†è§‰ç ´æŸï¼Œæé«˜äº†æŒ‘æˆ˜æ€§æ°´æœçš„æŠ“å–æˆåŠŸç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fbf10bb064403e5ff88cb36595be330a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6cb5244ac7b8af32d639069dbfb64ce9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-165bede88284c6fb8fd546b635ea54e7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5b33761ddd9ba659d9618badce184ec4.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="CF3-Compact-and-Fast-3D-Feature-Fields"><a href="#CF3-Compact-and-Fast-3D-Feature-Fields" class="headerlink" title="CF3: Compact and Fast 3D Feature Fields"></a>CF3: Compact and Fast 3D Feature Fields</h2><p><strong>Authors:Hyunjoon Lee, Joonkyu Min, Jaesik Park</strong></p>
<p>3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D foundation models. However, most approaches rely on a bottom-up optimization process that treats raw 2D features as ground truth, incurring increased computational costs. We propose a top-down pipeline for constructing compact and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast weighted fusion of multi-view 2D features with pre-trained Gaussians. This approach enables training a per-Gaussian autoencoder directly on the lifted features, instead of training autoencoders in the 2D domain. As a result, the autoencoder better aligns with the feature distribution. More importantly, we introduce an adaptive sparsification method that optimizes the Gaussian attributes of the feature field while pruning and merging the redundant Gaussians, constructing an efficient representation with preserved geometric details. Our approach achieves a competitive 3D feature field using as little as 5% of the Gaussians compared to Feature-3DGS. </p>
<blockquote>
<p>3Dé«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰å·²ç»å¼€å§‹èå…¥æ¥è‡ªäºŒç»´åŸºç¡€æ¨¡å‹çš„ä¸°å¯Œä¿¡æ¯ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•ä¾èµ–äºè‡ªä¸‹è€Œä¸Šçš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œå°†åŸå§‹äºŒç»´ç‰¹å¾è§†ä¸ºçœŸå®ä¾æ®ï¼Œä»è€Œå¢åŠ äº†è®¡ç®—æˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ„å»ºç´§å‡‘ä¸”å¿«é€Ÿçš„3Dé«˜æ–¯ç‰¹å¾åœºçš„è‡ªä¸Šè€Œä¸‹æµç¨‹ï¼Œå³CF3ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨é¢„è®­ç»ƒçš„é«˜æ–¯å¯¹å¤šè§†è§’äºŒç»´ç‰¹å¾è¿›è¡Œå¿«é€ŸåŠ æƒèåˆã€‚è¿™ç§æ–¹æ³•å¯ä»¥ç›´æ¥åœ¨æå–çš„ç‰¹å¾ä¸Šè®­ç»ƒæ¯ä¸ªé«˜æ–¯è‡ªç¼–ç å™¨ï¼Œè€Œä¸æ˜¯åœ¨äºŒç»´åŸŸä¸­è®­ç»ƒè‡ªç¼–ç å™¨ã€‚å› æ­¤ï¼Œè‡ªç¼–ç å™¨èƒ½æ›´å¥½åœ°ä¸ç‰¹å¾åˆ†å¸ƒå¯¹é½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”ç¨€ç–åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å‰”é™¤å’Œåˆå¹¶å†—ä½™é«˜æ–¯çš„åŒæ—¶ä¼˜åŒ–ç‰¹å¾åœºçš„é«˜æ–¯å±æ€§ï¼Œä»è€Œæ„å»ºäº†ä¸€ä¸ªä¿ç•™å‡ ä½•ç»†èŠ‚çš„æœ‰æ•ˆè¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨ä¸Feature-3DGSç›¸æ¯”çš„5%çš„é«˜æ–¯æ•°å°±èƒ½å®ç°å…·æœ‰ç«äº‰åŠ›çš„3Dç‰¹å¾åœºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05254v3">PDF</a> ICCV 2025, Project Page: <a target="_blank" rel="noopener" href="https://jjoonii.github.io/cf3-website/">https://jjoonii.github.io/cf3-website/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°†äºŒç»´ç‰¹å¾æ¨¡å‹ä¿¡æ¯èå…¥ä¸‰ç»´é«˜æ–¯èåˆæŠ€æœ¯ï¼ˆ3DGSï¼‰çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–è‡ªä¸‹è€Œä¸Šçš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œå°†åŸå§‹äºŒç»´ç‰¹å¾è§†ä¸ºçœŸå®å€¼ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªä¸Šè€Œä¸‹çš„æ„å»ºç´§å‡‘å¿«é€Ÿä¸‰ç»´é«˜æ–¯ç‰¹å¾åœºçš„æ–¹æ³•ï¼Œå³CF3ã€‚è¯¥æ–¹æ³•é€šè¿‡å¿«é€ŸåŠ æƒèåˆå¤šè§’åº¦äºŒç»´ç‰¹å¾ä¸é¢„è®­ç»ƒé«˜æ–¯æ¨¡å‹ï¼Œç›´æ¥åœ¨æå‡çš„ç‰¹å¾ä¸Šè®­ç»ƒæ¯ä¸ªé«˜æ–¯è‡ªç¼–ç å™¨ï¼Œä½¿è‡ªç¼–ç å™¨æ›´å¥½åœ°é€‚åº”ç‰¹å¾åˆ†å¸ƒã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”ç¨€ç–åŒ–æ–¹æ³•ï¼Œåœ¨ä¼˜åŒ–ç‰¹å¾åœºçš„é«˜æ–¯å±æ€§æ—¶èƒ½å¤Ÿå‰”é™¤å¹¶åˆå¹¶å†—ä½™é«˜æ–¯ï¼Œå®ç°é«˜æ•ˆè¡¨ç¤ºå¹¶ä¿ç•™å‡ ä½•ç»†èŠ‚ã€‚ä¸Feature-3DGSç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨5%çš„é«˜æ–¯å³å¯è·å¾—å…·æœ‰ç«äº‰åŠ›çš„ä¸‰ç»´ç‰¹å¾åœºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸‰ç»´é«˜æ–¯èåˆæŠ€æœ¯ï¼ˆ3DGSï¼‰èå…¥äºŒç»´ç‰¹å¾æ¨¡å‹ä¿¡æ¯çš„æ–°å‘å±•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–è‡ªä¸‹è€Œä¸Šçš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªä¸Šè€Œä¸‹çš„æ„å»ºç´§å‡‘å¿«é€Ÿä¸‰ç»´é«˜æ–¯ç‰¹å¾åœºçš„æ–¹æ³•â€”â€”CF3ã€‚</li>
<li>é€šè¿‡å¿«é€ŸåŠ æƒèåˆå¤šè§’åº¦äºŒç»´ç‰¹å¾ä¸é¢„è®­ç»ƒé«˜æ–¯æ¨¡å‹æ¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡ã€‚</li>
<li>ç›´æ¥åœ¨æå‡çš„ç‰¹å¾ä¸Šè®­ç»ƒæ¯ä¸ªé«˜æ–¯è‡ªç¼–ç å™¨ï¼Œæé«˜è‡ªç¼–ç å™¨ä¸ç‰¹å¾åˆ†å¸ƒçš„é€‚åº”æ€§ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”ç¨€ç–åŒ–æ–¹æ³•ï¼Œä¼˜åŒ–ç‰¹å¾åœºçš„é«˜æ–¯å±æ€§å¹¶ä¿ç•™å‡ ä½•ç»†èŠ‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05254">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5992406d047344fb39f8a0fc671c0b32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c341ffeddc7c87f0fcd8450a2024e39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f1a44a443dbd154b23d0222fb4c7865.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-50ffd272e1efeb95596ff3470d57589e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d8d462d95d6e0dcde2e01f737af5d8f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19e4c8492a5e76b7cffa6cc499304124.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="LOD-GS-Level-of-Detail-Sensitive-3D-Gaussian-Splatting-for-Detail-Conserved-Anti-Aliasing"><a href="#LOD-GS-Level-of-Detail-Sensitive-3D-Gaussian-Splatting-for-Detail-Conserved-Anti-Aliasing" class="headerlink" title="LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail   Conserved Anti-Aliasing"></a>LOD-GS: Level-of-Detail-Sensitive 3D Gaussian Splatting for Detail   Conserved Anti-Aliasing</h2><p><strong>Authors:Zhenya Yang, Bingchen Gong, Kai Chen</strong></p>
<p>Despite the advancements in quality and efficiency achieved by 3D Gaussian Splatting (3DGS) in 3D scene rendering, aliasing artifacts remain a persistent challenge. Existing approaches primarily rely on low-pass filtering to mitigate aliasing. However, these methods are not sensitive to the sampling rate, often resulting in under-filtering and over-smoothing renderings. To address this limitation, we propose LOD-GS, a Level-of-Detail-sensitive filtering framework for Gaussian Splatting, which dynamically predicts the optimal filtering strength for each 3D Gaussian primitive. Specifically, we introduce a set of basis functions to each Gaussian, which take the sampling rate as input to model appearance variations, enabling sampling-rate-sensitive filtering. These basis function parameters are jointly optimized with the 3D Gaussian in an end-to-end manner. The sampling rate is influenced by both focal length and camera distance. However, existing methods and datasets rely solely on down-sampling to simulate focal length changes for anti-aliasing evaluation, overlooking the impact of camera distance. To enable a more comprehensive assessment, we introduce a new synthetic dataset featuring objects rendered at varying camera distances. Extensive experiments on both public datasets and our newly collected dataset demonstrate that our method achieves SOTA rendering quality while effectively eliminating aliasing. The code and dataset have been open-sourced. </p>
<blockquote>
<p>å°½ç®¡ä¸‰ç»´é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆ3DGSï¼‰åœ¨ä¸‰ç»´åœºæ™¯æ¸²æŸ“æ–¹é¢å–å¾—äº†è´¨é‡å’Œæ•ˆç‡çš„æå‡ï¼Œä½†æ··å ä¼ªå½±ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­å­˜åœ¨çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–ä½é€šæ»¤æ³¢æ¥å‡è½»æ··å ç°è±¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯¹é‡‡æ ·ç‡å¹¶ä¸æ•æ„Ÿï¼Œå¾€å¾€å¯¼è‡´æ»¤æ³¢ä¸è¶³å’Œè¿‡åº¦å¹³æ»‘çš„æ¸²æŸ“ç»“æœã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†LOD-GSï¼Œä¸€ç§é’ˆå¯¹é«˜æ–¯è´´å›¾çš„ç»†èŠ‚å±‚æ¬¡æ•æ„Ÿæ»¤æ³¢æ¡†æ¶ï¼Œå®ƒèƒ½åŠ¨æ€é¢„æµ‹æ¯ä¸ªä¸‰ç»´é«˜æ–¯åŸºå…ƒçš„æœ€ä½³æ»¤æ³¢å¼ºåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªé«˜æ–¯å¼•å…¥äº†ä¸€ç»„åŸºå‡½æ•°ï¼Œä»¥é‡‡æ ·ç‡ä½œä¸ºè¾“å…¥æ¥æ¨¡æ‹Ÿå¤–è§‚å˜åŒ–ï¼Œä»è€Œå®ç°é‡‡æ ·ç‡æ•æ„Ÿæ»¤æ³¢ã€‚è¿™äº›åŸºå‡½æ•°çš„å‚æ•°ä¸ä¸‰ç»´é«˜æ–¯ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè”åˆä¼˜åŒ–ã€‚é‡‡æ ·ç‡å—åˆ°ç„¦è·å’Œç›¸æœºè·ç¦»çš„å½±å“ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å’Œæ•°æ®é›†ä»…ä¾èµ–ä¸‹é‡‡æ ·æ¥æ¨¡æ‹Ÿç„¦è·å˜åŒ–ä»¥è¿›è¡ŒæŠ—æ··å è¯„ä¼°ï¼Œå¿½ç•¥äº†ç›¸æœºè·ç¦»çš„å½±å“ã€‚ä¸ºäº†è¿›è¡Œæ›´å…¨é¢çš„è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åˆæˆæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åœ¨ä¸åŒç›¸æœºè·ç¦»ä¸‹æ¸²æŸ“çš„ç‰©ä½“ã€‚åœ¨å…¬å…±æ•°æ®é›†å’Œæˆ‘ä»¬æ–°æ”¶é›†çš„æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æœ‰æ•ˆåœ°æ¶ˆé™¤äº†æ··å ã€‚ä»£ç å’Œæ•°æ®é›†å·²ç»å¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00554v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨ä¸‰ç»´åœºæ™¯æ¸²æŸ“ä¸­ï¼Œå°½ç®¡æœ‰3Dé«˜æ–¯ç»˜åˆ¶æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„åº”ç”¨å¤§å¤§æé«˜äº†è´¨é‡å’Œæ•ˆç‡ï¼Œä½†å­˜åœ¨èµ°æ ·ç°è±¡ä¸€ç›´æ˜¯ä¸ªéš¾é¢˜ã€‚ç›®å‰é€šå¸¸é‡‡ç”¨ä½é€šæ»¤æ³¢æ–¹æ³•æ¥ç¼“è§£èµ°æ ·ç°è±¡ï¼Œç„¶è€Œè¿™äº›åŠæ³•ç¼ºä¹å¯¹é‡‡æ ·ç‡çš„æ•æ„Ÿåº¦ï¼Œæ˜“å¯¼è‡´èµ°æ ·æˆ–è¿‡åº¦å¹³æ»‘çš„ç»“æœã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„Level of Detailæ•æ„Ÿçš„é«˜æ–¯ç»˜åˆ¶æ»¤æ³¢å™¨æ¡†æ¶LOD-GSã€‚æ­¤æ¡†æ¶ä¼šé’ˆå¯¹æ¯ä¸ªä¸‰ç»´é«˜æ–¯å‡ ä½•å›¾å½¢é¢„æµ‹æœ€ä¼˜æ»¤æ³¢å¼ºåº¦ã€‚ç‰¹åˆ«çš„æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºé‡‡æ ·ç‡çš„åŸºå‡½æ•°æ¥è°ƒæ•´æ¯ä¸ªé«˜æ–¯æ¨¡å‹çš„è¡¨ç°å·®å¼‚ï¼Œä½¿æ»¤æ³¢æ›´åŠ æ•æ„Ÿäºé‡‡æ ·ç‡ã€‚å‚æ•°é€šè¿‡ç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ–¹å¼è”åˆä¼˜åŒ–ä¸‰ç»´é«˜æ–¯å’ŒåŸºå‡½æ•°ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæ–°åˆæˆæ•°æ®é›†ï¼Œç”¨äºå…¨é¢è¯„ä¼°ç›¸æœºè·ç¦»å¯¹å›¾åƒçš„å½±å“ï¼Œå¹¶å®éªŒè¯æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¶ˆé™¤èµ°æ ·ç°è±¡çš„åŒæ—¶å®ç°äº†ä¸šç•Œé¢†å…ˆçš„æ¸²æŸ“è´¨é‡ã€‚ä»£ç å’Œæ•°æ®é›†å·²å¼€æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæŠ€æœ¯åœ¨æ¸²æŸ“è´¨é‡æå‡æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†èµ°æ ·ç°è±¡ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>å½“å‰é‡‡ç”¨ä½é€šæ»¤æ³¢çš„æ–¹æ³•ç¼“è§£èµ°æ ·é—®é¢˜ï¼Œä½†è¿™ç§æ–¹æ³•ç¼ºä¹å¯¹é‡‡æ ·ç‡çš„æ•æ„Ÿåº¦ã€‚</li>
<li>LOD-GSæ¡†æ¶å¼•å…¥äº†å¯¹é‡‡æ ·ç‡æ•æ„Ÿçš„åŸºå‡½æ•°æ¥è°ƒæ•´é«˜æ–¯æ¨¡å‹çš„æ€§èƒ½ã€‚æ¯ä¸ªé«˜æ–¯æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé¢„æµ‹çš„è¿‡æ»¤å¼ºåº¦å‚æ•°é›†ç”¨äºåº”å¯¹é‡‡æ ·ç‡çš„åŠ¨æ€å˜åŒ–ã€‚æ­¤æ¡†æ¶èƒ½æœ‰æ•ˆå¤„ç†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§å¹¶å¢å¼ºæŠ—èµ°æ ·èƒ½åŠ›ã€‚</li>
<li>åŸºå‡½æ•°å‚æ•°ä¸ä¸‰ç»´é«˜æ–¯æ¨¡å‹é€šè¿‡ç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ–¹å¼è”åˆä¼˜åŒ–ï¼Œæå‡äº†æ¸²æŸ“è´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00554">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-aadde0027f2050da3f9617017e2afcb5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-58a6719e5c59fa994bde854272e46cb5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a275bed375fb08efc5adbcd12d72a1ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da4e1beb76d13e54fbd22fad21c2e666.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c7bd06e99888047a39bdc722e5b3161.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="RUSplatting-Robust-3D-Gaussian-Splatting-for-Sparse-View-Underwater-Scene-Reconstruction"><a href="#RUSplatting-Robust-3D-Gaussian-Splatting-for-Sparse-View-Underwater-Scene-Reconstruction" class="headerlink" title="RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater   Scene Reconstruction"></a>RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater   Scene Reconstruction</h2><p><strong>Authors:Zhuodong Jiang, Haoran Wang, Guoxi Huang, Brett Seymour, Nantheera Anantrasirichai</strong></p>
<p>Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption, scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme. Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured specifically in deep-sea environments. Experimental results demonstrate that our framework consistently outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality and robustness, and offering promising directions for marine robotics and underwater visual analytics. The code of RUSplatting is available at <a target="_blank" rel="noopener" href="https://github.com/theflash987/RUSplatting">https://github.com/theflash987/RUSplatting</a> and the dataset Submerged3D can be downloaded at <a target="_blank" rel="noopener" href="https://zenodo.org/records/15482420">https://zenodo.org/records/15482420</a>. </p>
<blockquote>
<p>é‡å»ºé«˜ä¿çœŸæ°´ä¸‹åœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜çš„ä»»åŠ¡ï¼Œè¿™æ˜¯ç”±äºæ°´ä¸‹ç¯å¢ƒå›ºæœ‰çš„å…‰å¸æ”¶ã€æ•£å°„å’Œæœ‰é™çš„å¯è§åº¦é€ æˆçš„ã€‚æœ¬æ–‡é’ˆå¯¹åŸºäºé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„æ¡†æ¶è¿›è¡Œå¢å¼ºï¼Œæé«˜äº†æ°´ä¸‹æ·±åº¦æ¸²æŸ“çš„è§†è§‰è´¨é‡å’Œå‡ ä½•ç²¾åº¦ã€‚æˆ‘ä»¬æå‡ºäº†é’ˆå¯¹RGBé€šé“çš„è§£è€¦å­¦ä¹ ï¼Œä»¥æ°´ä¸‹è¡°å‡çš„ç‰©ç†ç‰¹æ€§ä¸ºæŒ‡å¯¼ï¼Œä»¥å®ç°æ›´å‡†ç¡®çš„é¢œè‰²æ¢å¤ã€‚ä¸ºäº†è§£å†³ç¨€ç–è§†å›¾é™åˆ¶å¹¶æé«˜è§†å›¾ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¸¦æœ‰æ–°å‹è‡ªé€‚åº”åŠ æƒæ–¹æ¡ˆçš„æ–°å¸§æ’å€¼ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨å‡å°‘å™ªå£°çš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼Œè¿™å¯¹äºæ·±æµ·å†…å®¹è‡³å…³é‡è¦ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†ä¸€ä¸ªæ–°æ”¶é›†çš„ç‰¹å®šäºæ·±æµ·ç¯å¢ƒçš„æ•°æ®é›†Submerged3Dã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å§‹ç»ˆä¼˜äºæœ€æ–°æŠ€æœ¯ï¼ŒPSNRå¢ç›Šé«˜è¾¾1.90dBï¼Œæä¾›å“è¶Šçš„æ„ŸçŸ¥è´¨é‡å’Œç¨³å¥æ€§ï¼Œå¹¶ä¸ºæµ·æ´‹æœºå™¨äººæŠ€æœ¯å’Œæ°´ä¸‹è§†è§‰åˆ†ææä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚RUSplattingçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/theflash987/RUSplatting%E4%B8%8A%E8%8E%B7%E5%8F%96%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%9B%86Submerged3D%E5%8F%AF%E5%9C%A8https://zenodo.org/records/15482420%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/theflash987/RUSplattingä¸Šè·å–ï¼Œæ•°æ®é›†Submerged3Då¯åœ¨https://zenodo.org/records/15482420ä¸Šä¸‹è½½ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15737v2">PDF</a> Accepted by BMVC 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºé«˜æ–¯æ‘Šé“ºçš„å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ°´ä¸‹åœºæ™¯çš„æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ç²¾åº¦ã€‚é€šè¿‡è§£è€¦RGBé€šé“å­¦ä¹ ã€å¼•å…¥åŸºäºç‰©ç†çš„æ°´ä¸‹è¡°å‡æŒ‡å¯¼ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„é¢œè‰²å¤åŸã€‚é’ˆå¯¹ç¨€ç–è§†å›¾çš„é—®é¢˜ï¼Œé‡‡å–å¸§æ’å€¼ç­–ç•¥å¹¶ç»“åˆæ–°å‹è‡ªé€‚åº”åŠ æƒæ–¹æ¡ˆï¼Œæå‡äº†è§†å›¾çš„è¿è´¯æ€§ã€‚åŒæ—¶ï¼Œè®¾è®¡æ–°çš„æŸå¤±å‡½æ•°ï¼Œæ—¨åœ¨é™å™ªçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼Œè¿™å¯¹æ·±æµ·å†…å®¹è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†ä¸€ä¸ªä¸“é—¨åœ¨æ·±æµ·ç¯å¢ƒä¸­é‡‡é›†çš„æ–°æ•°æ®é›†Submerged3Dã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶è¾ƒç°æœ‰æŠ€æœ¯æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå³°å€¼ä¿¡å™ªæ¯”æå‡è¾¾1.90dBï¼Œæ„ŸçŸ¥è´¨é‡å’Œç¨³å¥æ€§ä¸Šä¹˜ï¼Œä¸ºæµ·æ´‹æœºå™¨äººå’Œæ°´ä¸‹è§†è§‰åˆ†ææä¾›äº†æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºçš„å¢å¼ºé«˜æ–¯æ‘Šé“ºæ¡†æ¶æé«˜äº†æ°´ä¸‹åœºæ™¯çš„æ¸²æŸ“è´¨é‡å’Œå‡ ä½•ç²¾åº¦ã€‚</li>
<li>é€šè¿‡è§£è€¦RGBé€šé“å­¦ä¹ ï¼Œç»“åˆæ°´ä¸‹è¡°å‡çš„ç‰©ç†æŒ‡å¯¼ï¼Œå®ç°æ›´å‡†ç¡®çš„é¢œè‰²å¤åŸã€‚</li>
<li>é‡‡ç”¨å¸§æ’å€¼ç­–ç•¥åŠè‡ªé€‚åº”åŠ æƒæ–¹æ¡ˆåº”å¯¹ç¨€ç–è§†å›¾é—®é¢˜ï¼Œå¢å¼ºè§†å›¾è¿è´¯æ€§ã€‚</li>
<li>æ–°è®¾è®¡çš„æŸå¤±å‡½æ•°èƒ½åœ¨é™å™ªçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼Œé€‚ç”¨äºæ·±æµ·å†…å®¹å¤„ç†ã€‚</li>
<li>å‘å¸ƒäº†ä¸“é—¨åœ¨æ·±æµ·ç¯å¢ƒä¸‹é‡‡é›†çš„æ–°æ•°æ®é›†Submerged3Dã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶è¾ƒç°æœ‰æŠ€æœ¯æœ‰æ˜¾è‘—æå‡ï¼Œå³°å€¼ä¿¡å™ªæ¯”æœ€é«˜æå‡è¾¾1.90dBã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15737">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-63f79d54a073dfc59abcbf893139a922.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac505d50d8208c627cb2aed4bd6fd318.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Micro-splatting-Multistage-Isotropy-informed-Covariance-Regularization-Optimization-for-High-Fidelity-3D-Gaussian-Splatting"><a href="#Micro-splatting-Multistage-Isotropy-informed-Covariance-Regularization-Optimization-for-High-Fidelity-3D-Gaussian-Splatting" class="headerlink" title="Micro-splatting: Multistage Isotropy-informed Covariance Regularization   Optimization for High-Fidelity 3D Gaussian Splatting"></a>Micro-splatting: Multistage Isotropy-informed Covariance Regularization   Optimization for High-Fidelity 3D Gaussian Splatting</h2><p><strong>Authors:Jee Won Lee, Hansol Lim, Sooyeun Yang, Jongseong Brad Choi</strong></p>
<p>High-fidelity 3D Gaussian Splatting methods excel at capturing fine textures but often overlook model compactness, resulting in massive splat counts, bloated memory, long training, and complex post-processing. We present Micro-Splatting: Two-Stage Adaptive Growth and Refinement, a unified, in-training pipeline that preserves visual detail while drastically reducing model complexity without any post-processing or auxiliary neural modules. In Stage I (Growth), we introduce a trace-based covariance regularization to maintain near-isotropic Gaussians, mitigating low-pass filtering in high-frequency regions and improving spherical-harmonic color fitting. We then apply gradient-guided adaptive densification that subdivides splats only in visually complex regions, leaving smooth areas sparse. In Stage II (Refinement), we prune low-impact splats using a simple opacity-scale importance score and merge redundant neighbors via lightweight spatial and feature thresholds, producing a lean yet detail-rich model. On four object-centric benchmarks, Micro-Splatting reduces splat count and model size by up to 60% and shortens training by 20%, while matching or surpassing state-of-the-art PSNR, SSIM, and LPIPS in real-time rendering. These results demonstrate that Micro-Splatting delivers both compactness and high fidelity in a single, efficient, end-to-end framework. </p>
<blockquote>
<p>é«˜ä¿çœŸ3Dé«˜æ–¯æ‘Šé“ºæ–¹æ³•æ“…é•¿æ•æ‰ç²¾ç»†çº¹ç†ï¼Œä½†å¾€å¾€ä¼šå¿½ç•¥æ¨¡å‹ç´§å‡‘æ€§ï¼Œå¯¼è‡´å¤§é‡çš„æ‘Šé“ºè®¡æ•°ã€å†…å­˜è†¨èƒ€ã€è®­ç»ƒæ—¶é—´é•¿å’Œå¤æ‚çš„åæœŸå¤„ç†ã€‚æˆ‘ä»¬æå‡ºäº†Micro-Splattingï¼šä¸¤é˜¶æ®µè‡ªé€‚åº”å¢é•¿ä¸ç»†åŒ–ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ã€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç®¡é“ï¼Œèƒ½å¤Ÿä¿ç•™è§†è§‰ç»†èŠ‚ï¼ŒåŒæ—¶å¤§å¹…åº¦å‡å°‘æ¨¡å‹å¤æ‚æ€§ï¼Œæ— éœ€ä»»ä½•åæœŸå¤„ç†æˆ–è¾…åŠ©ç¥ç»ç½‘ç»œæ¨¡å—ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ˆå¢é•¿é˜¶æ®µï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥åŸºäºè½¨è¿¹çš„åæ–¹å·®æ­£åˆ™åŒ–ï¼Œä»¥ç»´æŒæ¥è¿‘ç­‰å‘çš„é«˜æ–¯åˆ†å¸ƒï¼Œç¼“è§£é«˜é¢‘åŒºåŸŸçš„ä½é€šæ»¤æ³¢ï¼Œå¹¶æ”¹è¿›çƒé¢è°æ³¢é¢œè‰²æ‹Ÿåˆã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨æ¢¯åº¦å¼•å¯¼çš„è‡ªé€‚åº”å¯†é›†åŒ–ï¼Œåªåœ¨è§†è§‰å¤æ‚åŒºåŸŸç»†åˆ†æ‘Šé“ºï¼Œè€Œè®©å¹³æ»‘åŒºåŸŸä¿æŒç¨€ç–ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼ˆç»†åŒ–é˜¶æ®µï¼‰ï¼Œæˆ‘ä»¬åˆ©ç”¨ç®€å•çš„é€æ˜åº¦å°ºåº¦é‡è¦æ€§è¯„åˆ†å‰”é™¤å½±å“è¾ƒå°çš„æ‘Šé“ºï¼Œå¹¶é€šè¿‡è½»é‡çº§çš„ç©ºé—´å’Œç‰¹å¾é˜ˆå€¼åˆå¹¶å†—ä½™çš„é‚»å±…ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªç²¾ç®€è€Œç»†èŠ‚ä¸°å¯Œçš„æ¨¡å‹ã€‚åœ¨å››ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMicro-Splattingå°†æ‘Šé“ºè®¡æ•°å’Œæ¨¡å‹å¤§å°å‡å°‘äº†é«˜è¾¾60%ï¼Œå°†è®­ç»ƒæ—¶é—´ç¼©çŸ­äº†20%ï¼ŒåŒæ—¶åœ¨å®æ—¶æ¸²æŸ“ä¸­åŒ¹é…æˆ–è¶…è¶Šäº†æœ€å…ˆè¿›çš„PSNRã€SSIMå’ŒLPIPSã€‚è¿™äº›ç»“æœè¯æ˜ï¼ŒMicro-Splattingåœ¨å•ä¸€ã€é«˜æ•ˆã€ç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­å®ç°äº†ç´§å‡‘æ€§å’Œé«˜ä¿çœŸåº¦çš„å…¼é¡¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05740v2">PDF</a> This work has been submitted to journal for potential publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Micro-SplattingæŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»Ÿä¸€çš„ä¸¤é˜¶æ®µè‡ªé€‚åº”å¢é•¿ä¸ç»†åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨ä¿ç•™è§†è§‰ç»†èŠ‚çš„åŒæ—¶å¤§å¹…é™ä½æ¨¡å‹å¤æ‚åº¦ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼ˆå¢é•¿é˜¶æ®µï¼‰ï¼Œé€šè¿‡å¼•å…¥åŸºäºè½¨è¿¹çš„åæ–¹å·®æ­£åˆ™åŒ–æ¥ç»´æŒæ¥è¿‘ç­‰å‘çš„é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶åº”ç”¨æ¢¯åº¦å¼•å¯¼çš„è‡ªé€‚åº”å¯†é›†åŒ–ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼ˆç»†åŒ–é˜¶æ®µï¼‰ï¼Œé€šè¿‡ç®€å•çš„é€æ˜åº¦å°ºåº¦é‡è¦æ€§è¯„åˆ†å‰”é™¤ä½å½±å“çš„é«˜æ–¯ç‚¹ï¼Œå¹¶é€šè¿‡è½»é‡çº§çš„ç©ºé—´å’Œç‰¹å¾é˜ˆå€¼åˆå¹¶å†—ä½™é‚»å±…ã€‚Micro-Splattingåœ¨å››ä¸ªä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œå‡å°‘äº†é«˜è¾¾60%çš„é«˜æ–¯ç‚¹æ•°å’Œæ¨¡å‹å¤§å°ï¼Œç¼©çŸ­äº†20%çš„è®­ç»ƒæ—¶é—´ï¼ŒåŒæ—¶åœ¨å®æ—¶æ¸²æŸ“ä¸­åŒ¹é…æˆ–è¶…è¶Šäº†æœ€å…ˆè¿›çš„æŠ€æœ¯æŒ‡æ ‡ã€‚è¯æ˜Micro-Splattingåœ¨ä¸€ä¸ªé«˜æ•ˆã€ç«¯åˆ°ç«¯çš„æ¡†æ¶ä¸­åŒæ—¶å®ç°äº†ç´§å‡‘æ€§å’Œé«˜ä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Micro-Splattingæ˜¯ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»Ÿä¸€çš„ä¸¤é˜¶æ®µè‡ªé€‚åº”å¢é•¿ä¸ç»†åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ3Dé«˜æ–¯åˆ†è£‚æ–¹æ³•åœ¨æ¨¡å‹ç´§å‡‘æ€§å’Œçº¹ç†æ•æ‰ä¸Šçš„ä¸è¶³ã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µï¼ˆå¢é•¿é˜¶æ®µï¼‰é€šè¿‡å¼•å…¥åŸºäºè½¨è¿¹çš„åæ–¹å·®æ­£åˆ™åŒ–å’Œæ¢¯åº¦å¼•å¯¼çš„è‡ªé€‚åº”å¯†é›†åŒ–ï¼Œç»´æŒäº†é«˜æ–¯åˆ†å¸ƒçš„ç­‰å‘æ€§å¹¶æé«˜äº†è§†è§‰å¤æ‚æ€§åŒºåŸŸçš„æ¨¡å‹ç²¾åº¦ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µï¼ˆç»†åŒ–é˜¶æ®µï¼‰é€šè¿‡å‰”é™¤ä½å½±å“çš„é«˜æ–¯ç‚¹å’Œåˆå¹¶å†—ä½™é‚»å±…ï¼Œå®ç°äº†æ¨¡å‹çš„å¤§å°å’Œå¤æ‚åº¦çš„æ˜¾è‘—é™ä½ã€‚</li>
<li>Micro-Splattingåœ¨å››ä¸ªç‰©ä½“ä¸ºä¸­å¿ƒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ˜¾è‘—å‡å°‘äº†é«˜æ–¯ç‚¹æ•°ã€æ¨¡å‹å¤§å°ä»¥åŠè®­ç»ƒæ—¶é—´ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¿è¯æ¨¡å‹ç´§å‡‘æ€§çš„åŒæ—¶ï¼Œè¾¾åˆ°äº†é«˜ä¿çœŸåº¦çš„æ•ˆæœï¼ŒåŒ¹é…æˆ–è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯çš„å®æ—¶æ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>Micro-Splattingæä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€ç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ¨¡å‹çš„ä¼˜åŒ–å’Œæ€§èƒ½çš„æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05740">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b96ec2847b429fe648ef324eea36a6f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cbae6cf59b6d3763acd8d647ab5e434c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ec6f6e7f2fee1adb1b783b1a6650e68c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8eb57c061dd849aa9e0a2afd758d3b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eab09f90710dd053b6d92387d86a31a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7fcc3806ed9acebb7b26d92887e88504.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="BloomScene-Lightweight-Structured-3D-Gaussian-Splatting-for-Crossmodal-Scene-Generation"><a href="#BloomScene-Lightweight-Structured-3D-Gaussian-Splatting-for-Crossmodal-Scene-Generation" class="headerlink" title="BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal   Scene Generation"></a>BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal   Scene Generation</h2><p><strong>Authors:Xiaolu Hou, Mingcheng Li, Dingkang Yang, Jiawei Chen, Ziyun Qian, Xiao Zhao, Yue Jiang, Jinjie Wei, Qingyao Xu, Lihua Zhang</strong></p>
<p>With the widespread use of virtual reality applications, 3D scene generation has become a new challenging research frontier. 3D scenes have highly complex structures and need to ensure that the output is dense, coherent, and contains all necessary structures. Many current 3D scene generation methods rely on pre-trained text-to-image diffusion models and monocular depth estimators. However, the generated scenes occupy large amounts of storage space and often lack effective regularisation methods, leading to geometric distortions. To this end, we propose BloomScene, a lightweight structured 3D Gaussian splatting for crossmodal scene generation, which creates diverse and high-quality 3D scenes from text or image inputs. Specifically, a crossmodal progressive scene generation framework is proposed to generate coherent scenes utilizing incremental point cloud reconstruction and 3D Gaussian splatting. Additionally, we propose a hierarchical depth prior-based regularization mechanism that utilizes multi-level constraints on depth accuracy and smoothness to enhance the realism and continuity of the generated scenes. Ultimately, we propose a structured context-guided compression mechanism that exploits structured hash grids to model the context of unorganized anchor attributes, which significantly eliminates structural redundancy and reduces storage overhead. Comprehensive experiments across multiple scenes demonstrate the significant potential and advantages of our framework compared with several baselines. </p>
<blockquote>
<p>éšç€è™šæ‹Ÿç°å®åº”ç”¨çš„å¹¿æ³›ä½¿ç”¨ï¼Œ3Dåœºæ™¯ç”Ÿæˆå·²æˆä¸ºä¸€ä¸ªæ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶å‰æ²¿ã€‚3Dåœºæ™¯å…·æœ‰å¤æ‚çš„ç»“æ„ï¼Œéœ€è¦ç¡®ä¿è¾“å‡ºæ˜¯å¯†é›†çš„ã€è¿è´¯çš„ï¼Œå¹¶åŒ…å«æ‰€æœ‰å¿…è¦çš„ç»“æ„ã€‚ç›®å‰è®¸å¤š3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•ä¾èµ–äºé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹å’Œå•ç›®æ·±åº¦ä¼°è®¡å™¨ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„åœºæ™¯å ç”¨å¤§é‡çš„å­˜å‚¨ç©ºé—´ï¼Œå¹¶ä¸”å¸¸å¸¸ç¼ºä¹æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå¯¼è‡´å‡ ä½•å¤±çœŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†BloomSceneï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§çš„3Dé«˜æ–¯é£æº…ç»“æ„åŒ–æ–¹æ³•ï¼Œç”¨äºè·¨æ¨¡æ€åœºæ™¯ç”Ÿæˆï¼Œå¯ä»¥ä»æ–‡æœ¬æˆ–å›¾åƒè¾“å…¥åˆ›å»ºå¤šæ ·ä¸”é«˜è´¨é‡çš„3Dåœºæ™¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€æ¸è¿›åœºæ™¯ç”Ÿæˆæ¡†æ¶ï¼Œåˆ©ç”¨å¢é‡ç‚¹äº‘é‡å»ºå’Œ3Dé«˜æ–¯é£æº…ç”Ÿæˆè¿è´¯åœºæ™¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå±‚æ¬¡æ·±åº¦å…ˆéªŒçš„æ­£åˆ™åŒ–æœºåˆ¶ï¼Œåˆ©ç”¨æ·±åº¦ç²¾åº¦å’Œå¹³æ»‘åº¦çš„å¤šçº§çº¦æŸï¼Œæé«˜ç”Ÿæˆåœºæ™¯çš„çœŸå®æ„Ÿå’Œè¿ç»­æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“æ„åŒ–ä¸Šä¸‹æ–‡å¼•å¯¼å‹ç¼©æœºåˆ¶ï¼Œåˆ©ç”¨ç»“æ„åŒ–å“ˆå¸Œç½‘æ ¼å¯¹æœªç»„ç»‡é”šç‚¹å±æ€§è¿›è¡Œå»ºæ¨¡ï¼Œè¿™æå¤§åœ°æ¶ˆé™¤äº†ç»“æ„å†—ä½™å¹¶é™ä½äº†å­˜å‚¨å¼€é”€ã€‚åœ¨å¤šä¸ªåœºæ™¯çš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä¸å‡ ä¸ªåŸºå‡†ç›¸æ¯”å…·æœ‰æ˜¾è‘—æ½œåŠ›å’Œä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10462v2">PDF</a> Accepted by AAAI 2025. Code: <a target="_blank" rel="noopener" href="https://github.com/SparklingH/BloomScene">https://github.com/SparklingH/BloomScene</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†éšç€è™šæ‹Ÿç°å®çš„å¹¿æ³›åº”ç”¨ï¼Œ3Dåœºæ™¯ç”Ÿæˆæˆä¸ºæ–°çš„ç ”ç©¶å‰æ²¿ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç»“æ„åŒ–3Dé«˜æ–¯æç‚¹æ³•â€”â€”BloomSceneï¼Œç”¨äºè·¨æ¨¡æ€åœºæ™¯ç”Ÿæˆï¼Œå¯ä»¥ä»æ–‡æœ¬æˆ–å›¾åƒåˆ›å»ºå¤šæ ·åŒ–ã€é«˜è´¨é‡çš„3Dåœºæ™¯ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¢é‡ç‚¹äº‘é‡å»ºå’Œ3Dé«˜æ–¯æç‚¹æŠ€æœ¯æ„å»ºè¿è´¯åœºæ™¯ï¼Œå¹¶æå‡ºå±‚æ¬¡æ·±åº¦å…ˆéªŒæ­£åˆ™åŒ–æœºåˆ¶å’Œå¤šçº§æ·±åº¦çº¦æŸå¢å¼ºåœºæ™¯çœŸå®æ€§å’Œè¿ç»­æ€§ã€‚æœ€åï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§ç»“æ„åŒ–ä¸Šä¸‹æ–‡å¼•å¯¼å‹ç¼©æœºåˆ¶ï¼Œåˆ©ç”¨ç»“æ„åŒ–å“ˆå¸Œç½‘æ ¼å»ºæ¨¡æ— åºé”šç‚¹å±æ€§ä¸Šä¸‹æ–‡ï¼Œå‡å°‘ç»“æ„å†—ä½™å¹¶é™ä½å­˜å‚¨å¼€é”€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è™šæ‹Ÿç°å®çš„å¹¿æ³›åº”ç”¨æ¨åŠ¨äº†3Dåœºæ™¯ç”Ÿæˆæˆä¸ºæ–°çš„ç ”ç©¶çƒ­ç‚¹ã€‚</li>
<li>å½“å‰3Dåœºæ™¯ç”Ÿæˆæ–¹æ³•å­˜åœ¨çš„é—®é¢˜åŒ…æ‹¬åœºæ™¯ç»“æ„å¤æ‚åº¦é«˜ã€å­˜å‚¨ç©ºé—´å ç”¨å¤§ä»¥åŠç¼ºä¹æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ–¹æ³•å¯¼è‡´çš„å‡ ä½•å¤±çœŸã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è·¨æ¨¡æ€åœºæ™¯ç”Ÿæˆæ–¹æ³•â€”â€”BloomSceneï¼Œç»“åˆæ–‡æœ¬æˆ–å›¾åƒåˆ›å»ºé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„3Dåœºæ™¯ã€‚</li>
<li>BloomSceneé‡‡ç”¨å¢é‡ç‚¹äº‘é‡å»ºå’Œ3Dé«˜æ–¯æç‚¹æŠ€æœ¯æ„å»ºè¿è´¯åœºæ™¯ï¼Œç¡®ä¿åœºæ™¯çš„è¿è´¯æ€§å’Œå®Œæ•´æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å±‚æ¬¡æ·±åº¦å…ˆéªŒæ­£åˆ™åŒ–æœºåˆ¶ï¼Œé€šè¿‡å¤šçº§æ·±åº¦çº¦æŸå¢å¼ºåœºæ™¯çš„çœŸå®æ„Ÿå’Œè¿ç»­æ€§ã€‚</li>
<li>é‡‡ç”¨äº†ç»“æ„åŒ–ä¸Šä¸‹æ–‡å¼•å¯¼å‹ç¼©æœºåˆ¶æ¥å‡å°‘ç»“æ„å†—ä½™å¹¶é™ä½å­˜å‚¨å¼€é”€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10462">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c0b03ba256e03c7eb54d6565789d9be6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c63b535208228229fbba93e409bc12e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-817ee426981cfa097d4189187141ccf0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-07/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-07/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-07/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cf5693abbe3c3c025881e809c9791603.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  SSGaussian Semantic-Aware and Structure-Preserving 3D Style Transfer
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-07/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-cf62327d584f9334a71420e5574fb1e5.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-07  Hyper Diffusion Avatars Dynamic Human Avatar Generation using Network   Weight Space Diffusion
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29058.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
