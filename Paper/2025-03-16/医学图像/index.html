<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-16  Quenching and recovery of persistent X-ray emission during a superburst   in 4U 1820$-$30">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-be9edefd2530b672c1b1316199272d95.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-16-æ›´æ–°"><a href="#2025-03-16-æ›´æ–°" class="headerlink" title="2025-03-16 æ›´æ–°"></a>2025-03-16 æ›´æ–°</h1><h2 id="Quenching-and-recovery-of-persistent-X-ray-emission-during-a-superburst-in-4U-1820-30"><a href="#Quenching-and-recovery-of-persistent-X-ray-emission-during-a-superburst-in-4U-1820-30" class="headerlink" title="Quenching and recovery of persistent X-ray emission during a superburst   in 4U 1820$-$30"></a>Quenching and recovery of persistent X-ray emission during a superburst   in 4U 1820$-$30</h2><p><strong>Authors:Zhijiao Peng, Zhaosheng Li, Yuanyue Pan, Tao Fu, Wenhui Yu, Yupeng Chen, Shu Zhang, Maurizio Falanga, Shuang-Nan Zhang</strong></p>
<p>We report the superburst from 4U 1820â€“30 in 2021 observed by the Monitor of All-sky X-ray Image and Neutron star Interior Composition Explorer (NICER). During the tail of the superburst, we found that the NICER light curve unexpectedly increased from 1080 to 2204 ${\rm counts<del>s^{-1}}$ over 6.89 hr. From the time-resolved superburst spectra, we estimated the burst decay time of $\approx2.5$ hr, the ignition column depth of $\approx0.3\times 10^{12}</del>{\rm g <del>cm^{-2}}$, the energy release per unit mass of $\approx2.4\times 10^{17}</del>{\rm erg<del>g^{-1}}$, the fluence of $\approx4.1\times 10^{-4}</del>{\rm erg<del>cm^{-2}}$, and the total energy release of $\approx3.5\times10^{42}$ erg. Notably, we found a gradual increase in the Componization flux from $8.9\times 10^{-10}</del>{\rm erg<del>s^{-1}</del>cm^{-2}}$ to the preburst level during the superburst. This increase can be interpreted as a consequence of superburst radiation depleting the inner accretion disk, leading to a near-complete quenching of the persistent emission. As the burst radiation decayed, the inner accretion disk gradually returned to its preburst state, as evidenced by the best-fit spectral parameters. Additionally, we observed a prominent absorption line that exhibited a gravitational redshift, shifting from 4.15 to 3.62 keV during the recovery phase of persistent emission. This absorption feature likely originates from the inner accretion disk rather than from burst emission on the neutron star (NS) surface. The observed changes in the absorption line energy suggest that the inner disk approached the NS to a distance as close as $\approx17$ km. </p>
<blockquote>
<p>æˆ‘ä»¬æŠ¥å‘Šäº†åˆ©ç”¨å…¨å¤©ç©ºXå°„çº¿å›¾åƒç›‘è§†å™¨å’Œä¸­å­æ˜Ÿå†…éƒ¨ç»“æ„æ¢æµ‹å™¨ï¼ˆNICERï¼‰è§‚æµ‹åˆ°çš„æ¥è‡ª4U 1820-30çš„è¶…è¶…çˆ†å‘äº‹ä»¶ã€‚åœ¨è¶…çˆ†å‘çš„å°¾éƒ¨ï¼Œæˆ‘ä»¬å‘ç°NICERçš„å…‰åº¦æ›²çº¿åœ¨é•¿è¾¾6.89å°æ—¶å†…æ„å¤–ä»æ¯ç§’çš„1080è®¡æ•°ä¸Šå‡è‡³æ¯ç§’çš„2204è®¡æ•°ã€‚æ ¹æ®æ—¶é—´è§£æçš„è¶…çˆ†å‘å…‰è°±ï¼Œæˆ‘ä»¬ä¼°è®¡äº†å¤§çº¦2.5å°æ—¶çš„çˆ†å‘è¡°å‡æ—¶é—´ã€å¤§çº¦æ·±åº¦ä¸º$0.3\times 10^{12}$å…‹æ¯ç«‹æ–¹å˜ç±³çš„ç‚¹ç«æŸ±ã€æ¯å•ä½è´¨é‡çš„èƒ½é‡é‡Šæ”¾çº¦ä¸º$2.4\times 10^{17}$å°”æ ¼æ¯å…‹ã€æµå¼ºåº¦çº¦ä¸º$4.1\times æˆåˆ†æµé‡çš„é€æ¸å¢åŠ å¯è§£è¯»ä¸ºè¶…çˆ†å‘è¾å°„è€—å°½äº†å†…ç›˜ç§¯ç‰©è´¨ï¼Œå¯¼è‡´æŒä¹…æ€§å‘å°„å‡ ä¹å®Œå…¨ç†„ç­ã€‚éšç€çˆ†å‘è¾å°„çš„è¡°å‡ï¼Œå†…ç›˜ç§¯ç‰©è´¨é€æ¸æ¢å¤åˆ°çˆ†å‘å‰çš„çŠ¶æ€ï¼Œæœ€ä½³æ‹Ÿåˆå…‰è°±å‚æ•°å¯ä»¥è¯æ˜è¿™ä¸€ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸€æ¡æ˜æ˜¾çš„å¸æ”¶çº¿å±•ç°å‡ºé‡åŠ›çº¢ç§»ç°è±¡ï¼Œåœ¨æŒä¹…æ€§å‘å°„çš„æ¢å¤é˜¶æ®µä»4.15 keVé™è‡³3.62 keVã€‚è¿™ä¸€å¸æ”¶ç‰¹å¾å¯èƒ½æºè‡ªå†…ç›˜ç§¯ç‰©è´¨è€Œéä¸­å­æ˜Ÿè¡¨é¢ä¸Šçš„çˆ†å‘å‘å°„ã€‚è§‚å¯Ÿåˆ°çš„å¸æ”¶çº¿èƒ½é‡çš„å˜åŒ–è¡¨æ˜å†…ç›˜æ¥è¿‘ä¸­å­æ˜Ÿè‡³çº¦17å…¬é‡Œçš„è·ç¦»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05785v2">PDF</a> published in ApJ</p>
<p><strong>Summary</strong></p>
<p>æ–‡ä¸­æŠ¥é“äº†åˆ©ç”¨å…¨å¤©ç©ºXå°„çº¿å›¾åƒç›‘è§†å™¨å’Œä¸­å­æ˜Ÿå†…éƒ¨ç»“æ„æ¢æµ‹å™¨ï¼ˆNICERï¼‰è§‚æµ‹åˆ°çš„æ¥è‡ª4U 1820-30çš„è¶…çˆ†å‘äº‹ä»¶ã€‚è¶…çˆ†å‘å°¾æœŸå‡ºç°æ„å¤–çš„å…‰å˜æ›²çº¿å¢é•¿ï¼Œä¸”å…‰è°±ç‰¹å¾æ­ç¤ºäº†ä¸€ç³»åˆ—é‡è¦å‚æ•°å’Œç°è±¡ã€‚åŒ…æ‹¬è¶…çˆ†å‘çš„è¡°å‡æ—¶é—´ã€ç‚¹ç«æŸ±æ·±åº¦ã€å•ä½è´¨é‡çš„èƒ½é‡é‡Šæ”¾ç­‰å‚æ•°çš„ä¼°ç®—ï¼Œä»¥åŠæŒä¹…å‘å°„é€æ¸è¢«è¶…çº§çˆ†å‘è¾å°„è€—å°½åçš„æ¢å¤è¿‡ç¨‹ï¼Œéƒ½å±•ç°äº†ä¸­å­æ˜ŸåŠå…¶ç¯å¢ƒçš„å¤æ‚è¡Œä¸ºã€‚æ–‡ä¸­è¿˜è§‚å¯Ÿåˆ°ç”±é‡åŠ›çº¢ç§»äº§ç”Ÿçš„æ˜¾è‘—å¸æ”¶çº¿ï¼Œå…¶èƒ½é‡çš„å˜åŒ–è¡¨æ˜å†…ç›˜é è¿‘ä¸­å­æ˜Ÿçš„è·ç¦»è¾¾åˆ°äº†è¿‘ä¼¼å€¼ã€‚æ­¤è¶…çˆ†å‘äº‹ä»¶æ­ç¤ºäº†ä¸­å­æ˜Ÿå†…éƒ¨ç»“æ„å’Œç‰©ç†è¿‡ç¨‹çš„å®è´µä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>2021å¹´åˆ©ç”¨Monitor of All-sky X-ray Imageå’ŒNICERè§‚æµ‹äº†æ¥è‡ª4U 1820-30çš„è¶…çˆ†å‘äº‹ä»¶ã€‚</li>
<li>è¶…çˆ†å‘å°¾æœŸè§‚å¯Ÿåˆ°NICERå…‰å˜æ›²çº¿æ„å¤–å¢é•¿ã€‚</li>
<li>é€šè¿‡æ—¶é—´è§£æè¶…çˆ†å‘å…‰è°±ï¼Œä¼°ç®—äº†è¶…çˆ†å‘çš„è¡°å‡æ—¶é—´ã€ç‚¹ç«æŸ±æ·±åº¦ç­‰å‚æ•°ã€‚</li>
<li>è§‚å¯Ÿåˆ°æŒä¹…å‘å°„åœ¨è¶…çˆ†å‘è¿‡ç¨‹ä¸­é€æ¸å‡å¼±ï¼Œå¹¶åœ¨è¶…çˆ†å‘åæ¢å¤æœŸé€æ¸æ¢å¤çš„ç°è±¡ã€‚</li>
<li>æ­ç¤ºäº†è¶…çˆ†å‘è¾å°„å¯èƒ½è€—å°½å†…ç§¯ç›˜ï¼Œå¯¼è‡´æŒä¹…å‘å°„å‡ ä¹å®Œå…¨ç†„ç­çš„è§£é‡Šã€‚</li>
<li>æ¢å¤é˜¶æ®µçš„æ˜¾è‘—å¸æ”¶çº¿å±•ç¤ºé‡åŠ›çº¢ç§»ï¼Œè¡¨æ˜å†…ç›˜å¯èƒ½é è¿‘ä¸­å­æ˜Ÿè‡³è¿‘è·ç¦»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.05785">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-22adf6c2815d8d6a31069f19d78794eb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cf9d44fc102054d42c87fb52f5fc372c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-577bcd74a88b5b2f36bce31c17755501.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be9edefd2530b672c1b1316199272d95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30431c83b9d87ab283711b7bc5024bb6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa28b0c8cb071210153c4b14e0ccd828.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90ab0ee2060f9a37d85d2165a94801be.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Continuous-K-space-Recovery-Network-with-Image-Guidance-for-Fast-MRI-Reconstruction"><a href="#Continuous-K-space-Recovery-Network-with-Image-Guidance-for-Fast-MRI-Reconstruction" class="headerlink" title="Continuous K-space Recovery Network with Image Guidance for Fast MRI   Reconstruction"></a>Continuous K-space Recovery Network with Image Guidance for Fast MRI   Reconstruction</h2><p><strong>Authors:Yucong Meng, Zhiwei Yang, Minghong Duan, Yonghong Shi, Zhijian Song</strong></p>
<p>Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis while facing the challenge of long scanning time. To reduce the acquisition time, fast MRI reconstruction aims to restore high-quality images from the undersampled k-space. Existing methods typically train deep learning models to map the undersampled data to artifact-free MRI images. However, these studies often overlook the unique properties of k-space and directly apply general networks designed for image processing to k-space recovery, leaving the precise learning of k-space largely underexplored. In this work, we propose a continuous k-space recovery network from a new perspective of implicit neural representation with image domain guidance, which boosts the performance of MRI reconstruction. Specifically, (1) an implicit neural representation based encoder-decoder structure is customized to continuously query unsampled k-values. (2) an image guidance module is designed to mine the semantic information from the low-quality MRI images to further guide the k-space recovery. (3) a multi-stage training strategy is proposed to recover dense k-space progressively. Extensive experiments conducted on CC359, fastMRI, and IXI datasets demonstrate the effectiveness of our method and its superiority over other competitors. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸´åºŠè¯Šæ–­ä¸­çš„é‡è¦å·¥å…·ï¼Œä½†åŒæ—¶ä¹Ÿé¢ä¸´ç€æ‰«ææ—¶é—´é•¿è¿™ä¸€æŒ‘æˆ˜ã€‚ä¸ºäº†ç¼©çŸ­é‡‡é›†æ—¶é—´ï¼Œå¿«é€ŸMRIé‡å»ºæ—¨åœ¨ä»æ¬ é‡‡æ ·çš„kç©ºé—´ä¸­æ¢å¤é«˜è´¨é‡å›¾åƒã€‚ç°æœ‰æ–¹æ³•é€šå¸¸è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå°†æ¬ é‡‡æ ·æ•°æ®æ˜ å°„åˆ°æ— ä¼ªå½±çš„MRIå›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›ç ”ç©¶å¾€å¾€å¿½è§†äº†kç©ºé—´çš„ç‹¬ç‰¹å±æ€§ï¼Œå¹¶ç›´æ¥ä½¿ç”¨ä¸ºå›¾åƒå¤„ç†è®¾è®¡çš„é€šç”¨ç½‘ç»œè¿›è¡Œkç©ºé—´æ¢å¤ï¼Œä½¿å¾—kç©ºé—´çš„ç²¾ç¡®å­¦ä¹ åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè¢«å¿½è§†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»éšå¼ç¥ç»è¡¨ç¤ºçš„æ–°è§’åº¦æå‡ºäº†ä¸€ä¸ªè¿ç»­çš„kç©ºé—´æ¢å¤ç½‘ç»œï¼Œå¹¶ç»“åˆå›¾åƒåŸŸæŒ‡å¯¼æé«˜äº†MRIé‡å»ºçš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆ1ï¼‰åŸºäºéšå¼ç¥ç»è¡¨ç¤ºçš„ç¼–ç å™¨-è§£ç å™¨ç»“æ„è¢«å®šåˆ¶ä¸ºè¿ç»­æŸ¥è¯¢æœªé‡‡æ ·çš„kå€¼ã€‚ï¼ˆ2ï¼‰è®¾è®¡äº†ä¸€ä¸ªå›¾åƒå¼•å¯¼æ¨¡å—ï¼Œä»ä½è´¨é‡çš„MRIå›¾åƒä¸­æå–è¯­ä¹‰ä¿¡æ¯ï¼Œè¿›ä¸€æ­¥æŒ‡å¯¼kç©ºé—´çš„æ¢å¤ã€‚ï¼ˆ3ï¼‰æå‡ºäº†ä¸€ç§å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä»¥é€æ­¥æ¢å¤å¯†é›†çš„kç©ºé—´ã€‚åœ¨CC359ã€fastMRIå’ŒIXIæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§åŠå…¶å¯¹å…¶ä»–ç«äº‰å¯¹æ‰‹çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.11282v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æå‡ºäº†åŸºäºéšå¼ç¥ç»è¡¨ç¤ºçš„æ–°è§†è§’çš„è¿ç»­k-ç©ºé—´æ¢å¤ç½‘ç»œï¼Œç”¨äºåŠ é€Ÿç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰é‡å»ºã€‚è¯¥ç½‘ç»œç»“åˆå›¾åƒåŸŸæŒ‡å¯¼ï¼Œæå‡äº†MRIé‡å»ºæ€§èƒ½ã€‚é€šè¿‡é‡‡ç”¨éšå¼ç¥ç»è¡¨ç¤ºç¼–ç å™¨-è§£ç å™¨ç»“æ„ã€è®¾è®¡å›¾åƒæŒ‡å¯¼æ¨¡å—ä»¥åŠé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œå®ç°äº†å¯¹æœªé‡‡æ ·kå€¼çš„è¿ç»­æŸ¥è¯¢å’Œå¯†é›†k-ç©ºé—´çš„é€æ­¥æ¢å¤ã€‚åœ¨CC359ã€fastMRIå’ŒIXIæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§åŠä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰é¢ä¸´é•¿æ—¶é—´æ‰«æçš„æŒ‘æˆ˜ï¼Œå¿«é€ŸMRIé‡å»ºæ—¨åœ¨ä»æ¬ é‡‡æ ·çš„k-ç©ºé—´æ¢å¤é«˜è´¨é‡å›¾åƒã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šå¸¸è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹å°†æ¬ é‡‡æ ·æ•°æ®æ˜ å°„åˆ°æ— ä¼ªå½±çš„MRIå›¾åƒï¼Œä½†å¿½ç•¥äº†k-ç©ºé—´çš„ç‹¬ç‰¹å±æ€§ã€‚</li>
<li>æœ¬ç ”ç©¶ä»éšå¼ç¥ç»è¡¨ç¤ºçš„æ–°è§†è§’æå‡ºäº†è¿ç»­k-ç©ºé—´æ¢å¤ç½‘ç»œï¼Œå¯å®ç°å¯¹æœªé‡‡æ ·kå€¼çš„è¿ç»­æŸ¥è¯¢ã€‚</li>
<li>è®¾è®¡ä¸­åŒ…å«äº†å›¾åƒåŸŸæŒ‡å¯¼æ¨¡å—ï¼ŒæŒ–æ˜ä½è´¨é‡MRIå›¾åƒä¸­çš„è¯­ä¹‰ä¿¡æ¯ä»¥æŒ‡å¯¼k-ç©ºé—´æ¢å¤ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œæ—¨åœ¨é€æ­¥æ¢å¤å¯†é›†k-ç©ºé—´ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§åŠä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.11282">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-01c5ab4d24a3068d487ca04b0dc92c6b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a3f85ffe5a51b812219e1d887cf73f35.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3aa89e39a6468eb19e893ad341771cf6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa21df63ddc1babe8a7d98fa0f3c202b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-733908e8baaa4e1988ce290a080e278a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CAD-MLLM-Unifying-Multimodality-Conditioned-CAD-Generation-With-MLLM"><a href="#CAD-MLLM-Unifying-Multimodality-Conditioned-CAD-Generation-With-MLLM" class="headerlink" title="CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM"></a>CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM</h2><p><strong>Authors:Jingwei Xu, Zibo Zhao, Chenyu Wang, Wen Liu, Yi Ma, Shenghua Gao</strong></p>
<p>This paper aims to design a unified Computer-Aided Design (CAD) generation system that can easily generate CAD models based on the userâ€™s inputs in the form of textual description, images, point clouds, or even a combination of them. Towards this goal, we introduce the CAD-MLLM, the first system capable of generating parametric CAD models conditioned on the multimodal input. Specifically, within the CAD-MLLM framework, we leverage the command sequences of CAD models and then employ advanced large language models (LLMs) to align the feature space across these diverse multi-modalities data and CAD modelsâ€™ vectorized representations. To facilitate the model training, we design a comprehensive data construction and annotation pipeline that equips each CAD model with corresponding multimodal data. Our resulting dataset, named Omni-CAD, is the first multimodal CAD dataset that contains textual description, multi-view images, points, and command sequence for each CAD model. It contains approximately 450K instances and their CAD construction sequences. To thoroughly evaluate the quality of our generated CAD models, we go beyond current evaluation metrics that focus on reconstruction quality by introducing additional metrics that assess topology quality and surface enclosure extent. Extensive experimental results demonstrate that CAD-MLLM significantly outperforms existing conditional generative methods and remains highly robust to noises and missing points. The project page and more visualizations can be found at: <a target="_blank" rel="noopener" href="https://cad-mllm.github.io/">https://cad-mllm.github.io/</a> </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘æˆ–å®ƒä»¬çš„ç»„åˆç­‰è¾“å…¥å½¢å¼ï¼Œè½»æ¾ç”ŸæˆCADæ¨¡å‹ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†CAD-MLLMç³»ç»Ÿï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡å¼è¾“å…¥ç”Ÿæˆå‚æ•°åŒ–CADæ¨¡å‹çš„ç³»ç»Ÿã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨CAD-MLLMæ¡†æ¶å†…ï¼Œæˆ‘ä»¬åˆ©ç”¨CADæ¨¡å‹çš„å‘½ä»¤åºåˆ—ï¼Œç„¶åé‡‡ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥å¯¹é½è¿™äº›å¤šæ ·åŒ–çš„å¤šæ¨¡å¼æ•°æ®ä»¥åŠCADæ¨¡å‹çš„å‘é‡è¡¨ç¤ºä¹‹é—´çš„ç‰¹å¾ç©ºé—´ã€‚ä¸ºäº†ä¿ƒè¿›æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå…¨é¢çš„æ•°æ®æ„å»ºå’Œæ³¨é‡Šç®¡é“ï¼Œä¸ºæ¯ä¸ªCADæ¨¡å‹é…å¤‡ç›¸åº”çš„å¤šæ¨¡å¼æ•°æ®ã€‚æˆ‘ä»¬æ„å»ºçš„æ•°æ®é›†åä¸ºOmni-CADï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤šæ¨¡å¼CADæ•°æ®é›†ï¼ŒåŒ…å«æ¯ä¸ªCADæ¨¡å‹çš„æ–‡æœ¬æè¿°ã€å¤šè§†å›¾å›¾åƒã€ç‚¹å’Œå‘½ä»¤åºåˆ—ã€‚å®ƒåŒ…å«å¤§çº¦45ä¸‡ä¸ªå®ä¾‹åŠå…¶CADæ„å»ºåºåˆ—ã€‚ä¸ºäº†å…¨é¢è¯„ä¼°æˆ‘ä»¬ç”Ÿæˆçš„CADæ¨¡å‹çš„è´¨é‡ï¼Œæˆ‘ä»¬è¶…è¶Šäº†å½“å‰ä»¥é‡å»ºè´¨é‡ä¸ºä¸­å¿ƒçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¼•å…¥äº†å…¶ä»–è¯„ä¼°æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦çš„æŒ‡æ ‡ã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCAD-MLLMæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶ä¸”å¯¹å™ªå£°å’Œç¼ºå¤±ç‚¹å…·æœ‰é«˜åº¦é²æ£’æ€§ã€‚é¡¹ç›®é¡µé¢å’Œæ›´å¤šå¯è§†åŒ–å†…å®¹å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://cad-mllm.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://cad-mllm.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04954v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://cad-mllm.github.io/">https://cad-mllm.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç»Ÿä¸€è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„æ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘ç­‰å¤šç§è¾“å…¥å½¢å¼ï¼Œè½»æ¾ç”ŸæˆCADæ¨¡å‹ã€‚ä¸ºè¾¾æˆæ­¤ç›®æ ‡ï¼Œå¼•å…¥CAD-MLLMç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤ŸåŸºäºå¤šæ¨¡æ€è¾“å…¥ç”Ÿæˆå‚æ•°åŒ–CADæ¨¡å‹ã€‚é€šè¿‡è®¾è®¡ç»¼åˆæ•°æ®æ„å»ºå’Œæ ‡æ³¨ç®¡é“ï¼Œä¸ºæ¯ä¸ªCADæ¨¡å‹é…å¤‡å¯¹åº”çš„å¤šæ¨¡æ€æ•°æ®ï¼Œåˆ›å»ºåä¸ºOmni-CADçš„å¤šæ¨¡æ€CADæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦ç­‰è¯„ä¼°æŒ‡æ ‡æ¥å…¨é¢è¯„ä¼°ç”Ÿæˆçš„CADæ¨¡å‹è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCAD-MLLMæ˜¾è‘—ä¼˜äºç°æœ‰æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¯¹å™ªå£°å’Œç¼ºå¤±ç‚¹å…·æœ‰é«˜åº¦çš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„CADç”Ÿæˆç³»ç»Ÿï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„å¤šç§è¾“å…¥å½¢å¼ï¼ˆæ–‡æœ¬æè¿°ã€å›¾åƒã€ç‚¹äº‘ç­‰ï¼‰è½»æ¾ç”ŸæˆCADæ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†CAD-MLLMç³»ç»Ÿï¼Œèƒ½å¤ŸåŸºäºå¤šæ¨¡æ€è¾“å…¥ç”Ÿæˆå‚æ•°åŒ–CADæ¨¡å‹ã€‚</li>
<li>åˆ›å»ºäº†åä¸ºOmni-CADçš„å¤šæ¨¡æ€CADæ•°æ®é›†ï¼ŒåŒ…å«æ–‡æœ¬æè¿°ã€å¤šè§†è§’å›¾åƒã€ç‚¹äº‘å’ŒCADæ¨¡å‹çš„å‘½ä»¤åºåˆ—ã€‚</li>
<li>ä¸ºè¯„ä¼°ç”Ÿæˆçš„CADæ¨¡å‹è´¨é‡ï¼Œå¼•å…¥äº†æ‹“æ‰‘è´¨é‡å’Œè¡¨é¢å°é—­ç¨‹åº¦çš„è¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>CAD-MLLMç³»ç»Ÿæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>CAD-MLLMç³»ç»Ÿå¯¹å™ªå£°å’Œç¼ºå¤±ç‚¹å…·æœ‰é«˜åº¦çš„é²æ£’æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04954">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7088fbcd552e1bf2507a0edf0ee73286.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b2ecdff10c7d53be81da25427c5b376.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-689a6a8af7d9ef00a7a19d214791ca36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48d1788ce71122afadf4360588aff38d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cc2e3d3875f434e1813e6e0307bdc627.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-155a346409c29e6a0e7d4a2355c4db36.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LLM-HDR-Bridging-LLM-based-Perception-and-Self-Supervision-for-Unpaired-LDR-to-HDR-Image-Reconstruction"><a href="#LLM-HDR-Bridging-LLM-based-Perception-and-Self-Supervision-for-Unpaired-LDR-to-HDR-Image-Reconstruction" class="headerlink" title="LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired   LDR-to-HDR Image Reconstruction"></a>LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired   LDR-to-HDR Image Reconstruction</h2><p><strong>Authors:Hrishav Bakul Barua, Kalin Stefanov, Lemuel Lai En Che, Abhinav Dhall, KokSheik Wong, Ganesh Krishnasamy</strong></p>
<p>The translation of Low Dynamic Range (LDR) to High Dynamic Range (HDR) images is an important computer vision task. There is a significant amount of research utilizing both conventional non-learning methods and modern data-driven approaches, focusing on using both single-exposed and multi-exposed LDR for HDR image reconstruction. However, most current state-of-the-art methods require high-quality paired {LDR,HDR} datasets for model training. In addition, there is limited literature on using unpaired datasets for this task, that is, the model learns a mapping between domains, i.e., {LDR,HDR}. This paper proposes LLM-HDR, a method that integrates the perception of Large Language Models (LLM) into a modified semantic- and cycle-consistent adversarial architecture that utilizes unpaired {LDR,HDR} datasets for training. The method introduces novel artifact- and exposure-aware generators to address visual artifact removal and an encoder and loss to address semantic consistency, another under-explored topic. LLM-HDR is the first to use an LLM for the {LDR,HDR} translation task in a self-supervised setup. The method achieves state-of-the-art performance across several benchmark datasets and reconstructs high-quality HDR images. The official website of this work is available at: <a target="_blank" rel="noopener" href="https://github.com/HrishavBakulBarua/LLM-HDR">https://github.com/HrishavBakulBarua/LLM-HDR</a> </p>
<blockquote>
<p>ä»ä½åŠ¨æ€èŒƒå›´ï¼ˆLDRï¼‰å›¾åƒç¿»è¯‘åˆ°é«˜åŠ¨æ€èŒƒå›´ï¼ˆHDRï¼‰å›¾åƒæ˜¯ä¸€é¡¹é‡è¦çš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚è®¸å¤šç ”ç©¶éƒ½åˆ©ç”¨ä¼ ç»Ÿçš„éå­¦ä¹ æ–¹æ³•å’Œç°ä»£çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œä¾§é‡äºä½¿ç”¨å•æ›å…‰å’Œå¤šæ›å…‰çš„LDRè¿›è¡ŒHDRå›¾åƒé‡å»ºã€‚ç„¶è€Œï¼Œç›®å‰å¤§å¤šæ•°æœ€å…ˆè¿›çš„æ–¹æ³•éƒ½éœ€è¦é«˜è´¨é‡é…å¯¹çš„{LDRï¼ŒHDR}æ•°æ®é›†æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚æ­¤å¤–ï¼Œå…³äºä½¿ç”¨æœªé…å¯¹æ•°æ®é›†è¿›è¡Œæ­¤ä»»åŠ¡çš„æ–‡çŒ®å¾ˆå°‘ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å‹å­¦ä¹ åŸŸä¹‹é—´çš„æ˜ å°„ï¼Œå³{LDRï¼ŒHDR}ã€‚æœ¬æ–‡æå‡ºäº†LLM-HDRæ–¹æ³•ï¼Œå®ƒå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ„ŸçŸ¥èƒ½åŠ›é›†æˆåˆ°ä¸€ä¸ªç»è¿‡ä¿®æ”¹çš„è¯­ä¹‰å’Œå¾ªç¯ä¸€è‡´çš„å¯¹æŠ—æ€§æ¶æ„ä¸­ï¼Œè¯¥æ¶æ„åˆ©ç”¨æœªé…å¯¹çš„{LDRï¼ŒHDR}æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚è¯¥æ–¹æ³•å¼•å…¥äº†æ–°å‹ä¼ªå½±å’Œæ›å…‰æ„ŸçŸ¥ç”Ÿæˆå™¨æ¥è§£å†³è§†è§‰ä¼ªå½±å»é™¤é—®é¢˜ï¼Œä»¥åŠè§£å†³è¯­ä¹‰ä¸€è‡´æ€§è¿™ä¸€å°šæœªè¢«æ·±å…¥æ¢è®¨çš„è¯é¢˜çš„ç¼–ç å™¨å’ŒæŸå¤±å‡½æ•°ã€‚LLM-HDRæ˜¯ç¬¬ä¸€ä¸ªåœ¨è‡ªç›‘ç£è®¾ç½®ä¸­ä½¿ç”¨LLMè¿›è¡Œ{LDRï¼ŒHDR}ç¿»è¯‘ä»»åŠ¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶é‡å»ºäº†é«˜è´¨é‡çš„HDRå›¾åƒã€‚è¯¥å·¥ä½œçš„å®˜æ–¹ç½‘ç«™åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/HrishavBakulBarua/LLM-HDR">https://github.com/HrishavBakulBarua/LLM-HDR</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.15068v2">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§åä¸ºLLM-HDRçš„æ–¹æ³•ï¼Œå®ƒå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„ŸçŸ¥èå…¥ä¿®æ”¹åçš„è¯­ä¹‰å’Œå¾ªç¯ä¸€è‡´å¯¹æŠ—æ¶æ„ä¸­ï¼Œåˆ©ç”¨æ— é…å¯¹{LDRï¼ŒHDR}æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚è¯¥æ–¹æ³•å¼•å…¥æ–°å‹ä¼ªå½±å’Œæ›å…‰æ„ŸçŸ¥ç”Ÿæˆå™¨ä»¥è§£å†³è§†è§‰ä¼ªå½±å»é™¤é—®é¢˜ï¼Œå¹¶è§£å†³äº†è¯­ä¹‰ä¸€è‡´æ€§çš„å¦ä¸€ä¸ªæœªæ¢è®¨è¯é¢˜ã€‚LLM-HDRæ˜¯é¦–ä¸ªåœ¨è‡ªç›‘ç£è®¾ç½®ä¸­åˆ©ç”¨LLMè¿›è¡Œ{LDRï¼ŒHDR}ç¿»è¯‘ä»»åŠ¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶èƒ½é‡å»ºé«˜è´¨é‡HDRå›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLM-HDRæ–¹æ³•ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„ŸçŸ¥æŠ€æœ¯ã€‚</li>
<li>æ–¹æ³•é‡‡ç”¨ä¿®æ”¹åçš„è¯­ä¹‰å’Œå¾ªç¯ä¸€è‡´å¯¹æŠ—æ¶æ„ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨æ— é…å¯¹{LDRï¼ŒHDR}æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>LLM-HDRå¼•å…¥ä¼ªå½±å’Œæ›å…‰æ„ŸçŸ¥ç”Ÿæˆå™¨è§£å†³è§†è§‰ä¼ªå½±é—®é¢˜ã€‚</li>
<li>æ–¹æ³•è§£å†³äº†è¯­ä¹‰ä¸€è‡´æ€§çš„æœªæ¢è®¨è¯é¢˜ã€‚</li>
<li>LLM-HDRæ˜¯é¦–ä¸ªåœ¨è‡ªç›‘ç£è®¾ç½®ä¸­åº”ç”¨LLMè¿›è¡ŒHDRå›¾åƒç¿»è¯‘çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.15068">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ed0943f3f67423ae0c92ddaeb82166ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c796c8b662950542046b576ea2142a76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f7d1f0997d46770f2f236f98bb63377.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Co-learning-Single-Step-Diffusion-Upsampler-and-Downsampler-with-Two-Discriminators-and-Distillation"><a href="#Co-learning-Single-Step-Diffusion-Upsampler-and-Downsampler-with-Two-Discriminators-and-Distillation" class="headerlink" title="Co-learning Single-Step Diffusion Upsampler and Downsampler with Two   Discriminators and Distillation"></a>Co-learning Single-Step Diffusion Upsampler and Downsampler with Two   Discriminators and Distillation</h2><p><strong>Authors:Sohwi Kim, Tae-Kyun Kim</strong></p>
<p>Super-resolution (SR) aims to reconstruct high-resolution (HR) images from their low-resolution (LR) counterparts, often relying on effective downsampling to generate diverse and realistic training pairs. In this work, we propose a co-learning framework that jointly optimizes a single-step diffusion-based upsampler and a learnable downsampler, enhanced by two discriminators and a cyclic distillation strategy. Our learnable downsampler is designed to better capture realistic degradation patterns while preserving structural details in the LR domain, which is crucial for enhancing SR performance. By leveraging a diffusion-based approach, our model generates diverse LR-HR pairs during training, enabling robust learning across varying degradations. We demonstrate the effectiveness of our method on both general real-world and domain-specific face SR tasks, achieving state-of-the-art performance in both fidelity and perceptual quality. Our approach not only improves efficiency with a single inference step but also ensures high-quality image reconstruction, bridging the gap between synthetic and real-world SR scenarios. </p>
<blockquote>
<p>è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æ—¨åœ¨ä»ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒé‡å»ºé«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å›¾åƒï¼Œé€šå¸¸ä¾èµ–äºæœ‰æ•ˆçš„ä¸‹é‡‡æ ·æ¥ç”Ÿæˆå¤šæ ·ä¸”ç°å®çš„è®­ç»ƒå¯¹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è”åˆä¼˜åŒ–ä¸€æ­¥æ‰©æ•£å¼ä¸Šé‡‡æ ·å™¨å’Œå¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨çš„ååŒå­¦ä¹ æ¡†æ¶ï¼Œå®ƒç”±ä¸¤ä¸ªé‰´åˆ«å™¨å’Œå¾ªç¯è’¸é¦ç­–ç•¥å¢å¼ºã€‚æˆ‘ä»¬çš„å¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨æ—¨åœ¨æ›´å¥½åœ°æ•æ‰ç°å®çš„é€€åŒ–æ¨¡å¼ï¼ŒåŒæ—¶ä¿ç•™ä½åˆ†è¾¨ç‡åŸŸä¸­çš„ç»“æ„ç»†èŠ‚ï¼Œè¿™å¯¹äºæé«˜è¶…åˆ†è¾¨ç‡æ€§èƒ½è‡³å…³é‡è¦ã€‚é€šè¿‡åˆ©ç”¨åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆå¤šæ ·çš„LR-HRå¯¹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§é€€åŒ–æƒ…å†µä¸‹è¿›è¡Œç¨³å¥å­¦ä¹ ã€‚æˆ‘ä»¬åœ¨ä¸€èˆ¬çš„ç°å®ä¸–ç•Œå’Œç‰¹å®šé¢†åŸŸçš„é¢éƒ¨SRä»»åŠ¡ä¸Šéƒ½è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¿çœŸåº¦å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…é€šè¿‡ä¸€æ¬¡æ¨ç†æ­¥éª¤æé«˜äº†æ•ˆç‡ï¼Œè€Œä¸”ç¡®ä¿äº†é«˜è´¨é‡çš„å›¾åƒé‡å»ºï¼Œç¼©å°äº†åˆæˆå’Œç°å®ä¸–ç•ŒSRåœºæ™¯ä¹‹é—´çš„å·®è·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07663v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è”åˆä¼˜åŒ–å•æ­¥æ‰©æ•£å¼ä¸Šé‡‡æ ·å™¨å’Œå¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨çš„ååŒå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªé‰´åˆ«å™¨å’Œå¾ªç¯è’¸é¦ç­–ç•¥è¿›è¡Œå¢å¼ºã€‚å¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨èƒ½å¤Ÿæ›´å¥½æ•æ‰ç°å®é€€åŒ–æ¨¡å¼ï¼ŒåŒæ—¶åœ¨ä½åˆ†è¾¨ç‡é¢†åŸŸä¿ç•™ç»“æ„ç»†èŠ‚ï¼Œå¯¹æå‡è¶…åˆ†è¾¨ç‡æ€§èƒ½è‡³å…³é‡è¦ã€‚åˆ©ç”¨æ‰©æ•£å¼æ–¹æ³•ï¼Œè¯¥æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆå¤šæ ·çš„ä½åˆ†è¾¨ç‡-é«˜åˆ†è¾¨ç‡å›¾åƒå¯¹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§é€€åŒ–æƒ…å†µä¸‹è¿›è¡Œç¨³å¥å­¦ä¹ ã€‚åœ¨é€šç”¨ç°å®ä¸–ç•Œå’Œç‰¹å®šé¢†åŸŸçš„é¢éƒ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å–å¾—äº†å…ˆè¿›æ€§èƒ½ï¼Œåœ¨ä¿çœŸåº¦å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡è¡¨ç°ä¼˜å¼‚ã€‚æ­¤æ–¹æ³•ä¸ä»…æé«˜äº†æ•ˆç‡ï¼Œåªéœ€å•æ­¥æ¨ç†ï¼Œè€Œä¸”ä¿è¯äº†é«˜è´¨é‡å›¾åƒé‡å»ºï¼Œç¼©å°äº†åˆæˆå’ŒçœŸå®ä¸–ç•Œè¶…åˆ†è¾¨ç‡åœºæ™¯ä¹‹é—´çš„å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ä¸ªè”åˆä¼˜åŒ–å•æ­¥æ‰©æ•£å¼ä¸Šé‡‡æ ·å™¨å’Œå¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨çš„ååŒå­¦ä¹ æ¡†æ¶ã€‚</li>
<li>å¯å­¦ä¹ ä¸‹é‡‡æ ·å™¨èƒ½æ•æ‰ç°å®é€€åŒ–æ¨¡å¼å¹¶ä¿ç•™ä½åˆ†è¾¨ç‡é¢†åŸŸçš„ç»“æ„ç»†èŠ‚ã€‚</li>
<li>åˆ©ç”¨æ‰©æ•£å¼æ–¹æ³•ç”Ÿæˆå¤šæ ·çš„ä½åˆ†è¾¨ç‡-é«˜åˆ†è¾¨ç‡å›¾åƒå¯¹ï¼Œæå‡æ¨¡å‹çš„ç¨³å¥æ€§ã€‚</li>
<li>åœ¨é¢éƒ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šå–å¾—äº†å…ˆè¿›æ€§èƒ½ã€‚</li>
<li>æ–¹æ³•æé«˜äº†æ•ˆç‡ï¼Œåªéœ€å•æ­¥æ¨ç†ã€‚</li>
<li>ä¿è¯äº†é«˜è´¨é‡å›¾åƒé‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07663">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cbcb729ba1d1f944a7aad21a46ad84b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9d39eebd9daafa28fc17aa0d2cd8d8d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7ec83d9c00fde7426985c6d2de4fbdd7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-64437cde0ef2285269cce6e541833750.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-84ecd6186390d0134d3742512ac0a5f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-74d7e08c8950d604cd0cf2cec7aef7c4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Brain-Tumor-Classification-on-MRI-in-Light-of-Molecular-Markers"><a href="#Brain-Tumor-Classification-on-MRI-in-Light-of-Molecular-Markers" class="headerlink" title="Brain Tumor Classification on MRI in Light of Molecular Markers"></a>Brain Tumor Classification on MRI in Light of Molecular Markers</h2><p><strong>Authors:Jun Liu, Geng Yuan, Weihao Zeng, Hao Tang, Wenbin Zhang, Xue Lin, XiaoLin Xu, Dong Huang, Yanzhi Wang</strong></p>
<p>In research findings, co-deletion of the 1p&#x2F;19q gene is associated with clinical outcomes in low-grade gliomas. The ability to predict 1p19q status is critical for treatment planning and patient follow-up. This study aims to utilize a specially MRI-based convolutional neural network for brain cancer detection. Although public networks such as RestNet and AlexNet can effectively diagnose brain cancers using transfer learning, the model includes quite a few weights that have nothing to do with medical images. As a result, the diagnostic results are unreliable by the transfer learning model. To deal with the problem of trustworthiness, we create the model from the ground up, rather than depending on a pre-trained model. To enable flexibility, we combined convolution stacking with a dropout and full connect operation, it improved performance by reducing overfitting. During model training, we also supplement the given dataset and inject Gaussian noise. We use threeâ€“fold cross-validation to train the best selection model. Comparing InceptionV3, VGG16, and MobileNetV2 fine-tuned with pre-trained models, our model produces better results. On an validation set of 125 codeletion vs. 31 not codeletion images, the proposed network achieves 96.37% percent F1-score, 97.46% percent precision, and 96.34% percent recall when classifying 1p&#x2F;19q codeletion and not codeletion images. </p>
<blockquote>
<p>åœ¨ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç°ï¼Œ1p&#x2F;19qåŸºå› çš„è”åˆç¼ºå¤±ä¸ä½çº§åˆ«èƒ¶è´¨ç˜¤çš„ä¸´åºŠç»“æœæœ‰å…³ã€‚é¢„æµ‹1p19qçŠ¶æ€å¯¹äºæ²»ç–—è®¡åˆ’å’Œæ‚£è€…éšè®¿è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨åŸºäºMRIçš„å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œè„‘ç™Œæ£€æµ‹ã€‚è™½ç„¶RestNetå’ŒAlexNetç­‰å…¬å…±ç½‘ç»œå¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ æœ‰æ•ˆåœ°è¯Šæ–­è„‘ç™Œï¼Œä½†æ¨¡å‹ä¸­æœ‰å¾ˆå¤šæƒé‡ä¸åŒ»å­¦å›¾åƒæ— å…³ã€‚å› æ­¤ï¼Œè¿ç§»å­¦ä¹ æ¨¡å‹çš„è¯Šæ–­ç»“æœä¸å¯é ã€‚ä¸ºäº†è§£å†³å¯ä¿¡åº¦é—®é¢˜ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹æ„å»ºæ¨¡å‹ï¼Œè€Œä¸æ˜¯ä¾èµ–äºé¢„è®­ç»ƒæ¨¡å‹ã€‚ä¸ºäº†å®ç°çµæ´»æ€§ï¼Œæˆ‘ä»¬å°†å·ç§¯å †å ä¸ä¸¢å¼ƒå’Œå®Œå…¨è¿æ¥æ“ä½œç›¸ç»“åˆï¼Œé€šè¿‡å‡å°‘è¿‡æ‹Ÿåˆæé«˜äº†æ€§èƒ½ã€‚åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è¿˜è¡¥å……äº†ç»™å®šçš„æ•°æ®é›†å¹¶æ³¨å…¥äº†é«˜æ–¯å™ªå£°ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸‰æŠ˜äº¤å‰éªŒè¯æ¥è®­ç»ƒæœ€ä½³é€‰æ‹©æ¨¡å‹ã€‚å°†InceptionV3ã€VGG16å’ŒMobileNetV2ä¸é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹äº§ç”Ÿäº†æ›´å¥½çš„ç»“æœã€‚åœ¨125å¼ ä»£ç ç¼ºå¤±ä¸31å¼ éä»£ç ç¼ºå¤±å›¾åƒçš„éªŒè¯é›†ä¸Šï¼Œæ‰€æå‡ºçš„ç½‘ç»œåœ¨åˆ†ç±»1p&#x2F;19qä»£ç ç¼ºå¤±å’Œéä»£ç ç¼ºå¤±å›¾åƒæ—¶ï¼Œè¾¾åˆ°äº†96.37%çš„F1åˆ†æ•°ã€97.46%çš„ç²¾ç¡®åº¦å’Œ96.34%çš„å¬å›ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.19583v2">PDF</a> ICAIâ€™22 - The 24th International Conference on Artificial   Intelligence, The 2022 World Congress in Computer Science, Computer   Engineering, &amp; Applied Computing (CSCEâ€™22), Las Vegas, USA. The paper   acceptance rate 17% for regular papers. The publication of the CSCE 2022   conference proceedings has been delayed due to the pandemic</p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡ç£å…±æŒ¯æˆåƒæŠ€æœ¯æ„å»ºçš„å·ç§¯ç¥ç»ç½‘ç»œå¯¹ä½çº§èƒ¶è´¨ç˜¤è¿›è¡Œè¯Šæ–­çš„æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰è½¬ç§»å­¦ä¹ æ¨¡å‹å­˜åœ¨çš„å¯é æ€§é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†å…¨æ–°çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡å·ç§¯å †å ã€dropoutæ“ä½œå’Œå…¨è¿æ¥æ“ä½œç›¸ç»“åˆçš„æ–¹å¼æé«˜äº†æ€§èƒ½å¹¶é™ä½äº†è¿‡æ‹Ÿåˆç°è±¡ã€‚åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜è¡¥å……äº†æ•°æ®é›†å¹¶åŠ å…¥äº†é«˜æ–¯å™ªå£°ä»¥å¢å¼ºæ¨¡å‹çš„çµæ´»æ€§ã€‚æœ€ç»ˆï¼Œè¯¥æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„åˆ†ç±»æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å‘ç°å…±åŒç¼ºå¤±çš„1p&#x2F;19qåŸºå› ä¸ä½çº§åˆ«èƒ¶è´¨ç˜¤çš„ä¸´åºŠç»“æœæœ‰å…³ã€‚</li>
<li>é¢„æµ‹1p&#x2F;19qçŠ¶æ€å¯¹æ²»ç–—è®¡åˆ’å’Œæ‚£è€…éšè®¿è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶æ—¨åœ¨åˆ©ç”¨åŸºäºMRIçš„å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œè„‘ç™Œæ£€æµ‹ã€‚</li>
<li>è™½ç„¶å…¬å…±ç½‘ç»œå¦‚RestNetå’ŒAlexNetå¯é€šè¿‡è½¬ç§»å­¦ä¹ æœ‰æ•ˆè¯Šæ–­è„‘ç™Œï¼Œä½†å…¶è¯Šæ–­ç»“æœå­˜åœ¨å¯é æ€§é—®é¢˜ã€‚</li>
<li>ä¸ºè§£å†³å¯é æ€§é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†å…¨æ–°çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å·ç§¯å †å ã€dropoutå’Œå…¨è¿æ¥æ“ä½œæ¥æé«˜æ€§èƒ½å¹¶é™ä½è¿‡æ‹Ÿåˆç°è±¡ã€‚</li>
<li>åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¡¥å……æ•°æ®é›†å¹¶æ³¨å…¥é«˜æ–¯å™ªå£°ä»¥å¢å¼ºæ¨¡å‹çš„çµæ´»æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.19583">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-27f88ee8cdaadbee2c03db7351299ceb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5ff84d93aef756890e2e355e419c0227.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b66ed32d7df1eac87cb1528592ebee8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2465ace51409c291120c1b39011ea43e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4247b1dbc3cb7bc0c6315c37e9155e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f8830741816d921c0895e0b9be5429c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="QueryCAD-Grounded-Question-Answering-for-CAD-Models"><a href="#QueryCAD-Grounded-Question-Answering-for-CAD-Models" class="headerlink" title="QueryCAD: Grounded Question Answering for CAD Models"></a>QueryCAD: Grounded Question Answering for CAD Models</h2><p><strong>Authors:Claudius Kienle, Benjamin Alt, Darko Katic, Rainer JÃ¤kel, Jan Peters</strong></p>
<p>CAD models are widely used in industry and are essential for robotic automation processes. However, these models are rarely considered in novel AI-based approaches, such as the automatic synthesis of robot programs, as there are no readily available methods that would allow CAD models to be incorporated for the analysis, interpretation, or extraction of information. To address these limitations, we propose QueryCAD, the first system designed for CAD question answering, enabling the extraction of precise information from CAD models using natural language queries. QueryCAD incorporates SegCAD, an open-vocabulary instance segmentation model we developed to identify and select specific parts of the CAD model based on part descriptions. We further propose a CAD question answering benchmark to evaluate QueryCAD and establish a foundation for future research. Lastly, we integrate QueryCAD within an automatic robot program synthesis framework, validating its ability to enhance deep-learning solutions for robotics by enabling them to process CAD models (<a target="_blank" rel="noopener" href="https://claudius-kienle.github.com/querycad">https://claudius-kienle.github.com/querycad</a>). </p>
<blockquote>
<p>CADæ¨¡å‹åœ¨å·¥ä¸šä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œæ˜¯æœºå™¨äººè‡ªåŠ¨åŒ–æµç¨‹ä¸­çš„å…³é”®ã€‚ç„¶è€Œï¼Œåœ¨åŸºäºAIçš„æ–°æ–¹æ³•ä¸­ï¼Œå¦‚æœºå™¨äººç¨‹åºçš„è‡ªåŠ¨åˆæˆï¼Œè¿™äº›æ¨¡å‹å¾ˆå°‘è¢«è€ƒè™‘åœ¨å†…ã€‚å› ä¸ºæ²¡æœ‰ç°æˆçš„æ–¹æ³•å¯ä»¥è®©CADæ¨¡å‹ç”¨äºåˆ†æã€è§£é‡Šæˆ–æå–ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†QueryCADç³»ç»Ÿï¼Œè¿™æ˜¯é¦–ä¸ªä¸ºCADé—®ç­”è®¾è®¡çš„ç³»ç»Ÿï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢èƒ½å¤Ÿä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ã€‚QueryCADé›†æˆäº†æˆ‘ä»¬å¼€å‘çš„SegCADæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§å¼€æ”¾å¼è¯æ±‡å®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œèƒ½å¤Ÿæ ¹æ®é›¶ä»¶æè¿°æ¥è¯†åˆ«å’Œé€‰æ‹©CADæ¨¡å‹ä¸­çš„ç‰¹å®šéƒ¨åˆ†ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªCADé—®ç­”åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°QueryCADï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚æœ€åï¼Œæˆ‘ä»¬å°†QueryCADé›†æˆåˆ°ä¸€ä¸ªè‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ï¼ŒéªŒè¯äº†å…¶é€šè¿‡å¤„ç†CADæ¨¡å‹æå‡æœºå™¨äººæ·±åº¦å­¦ä¹ èƒ½åŠ›çš„èƒ½åŠ›ï¼ˆ<a target="_blank" rel="noopener" href="https://claudius-kienle.github.com/querycad%EF%BC%89%E3%80%82">https://claudius-kienle.github.com/querycadï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08704v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>CADæ¨¡å‹åœ¨å·¥ä¸šä¸­å¹¿æ³›åº”ç”¨ï¼Œå¯¹æœºå™¨äººè‡ªåŠ¨åŒ–æµç¨‹è‡³å…³é‡è¦ã€‚ä½†åœ¨åŸºäºAIçš„è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆç­‰æ–°å‹æ–¹æ³•ä¸­ï¼ŒCADæ¨¡å‹çš„åº”ç”¨å—é™ï¼Œç¼ºä¹å¯¹å…¶åˆ†æã€è§£è¯»æˆ–ä¿¡æ¯æå–çš„æ–¹æ³•ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºQueryCADç³»ç»Ÿï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ã€‚è¯¥ç³»ç»ŸåŒ…å«SegCADï¼Œä¸€ä¸ªåŸºäºå¼€æ”¾è¯æ±‡çš„å®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œå¯åŸºäºéƒ¨åˆ†æè¿°è¯†åˆ«å¹¶é€‰æ‹©CADæ¨¡å‹çš„å…·ä½“éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œå»ºç«‹CADé—®ç­”åŸºå‡†æµ‹è¯•è¯„ä¼°QueryCADå¹¶ä¸ºæœªæ¥ç ”ç©¶å¥ å®šåŸºç¡€ã€‚æœ€åï¼Œå°†QueryCADé›†æˆåˆ°è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ï¼ŒéªŒè¯å…¶å¤„ç†CADæ¨¡å‹çš„èƒ½åŠ›ï¼Œä»è€Œæå‡æœºå™¨äººæ·±åº¦å­¦ä¹ çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CADæ¨¡å‹åœ¨å·¥ä¸šæœºå™¨äººè‡ªåŠ¨åŒ–ä¸­å æ®é‡è¦åœ°ä½ï¼Œä½†åœ¨æ–°å‹AIæ–¹æ³•ä¸­çš„åº”ç”¨å—é™ã€‚</li>
<li>QueryCADç³»ç»Ÿå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢å®ç°ä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ã€‚</li>
<li>QueryCADåŒ…å«SegCADå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œå¯è¯†åˆ«å¹¶é€‰æ‹©CADæ¨¡å‹ä¸­çš„ç‰¹å®šéƒ¨åˆ†ã€‚</li>
<li>å»ºç«‹CADé—®ç­”åŸºå‡†æµ‹è¯•ä»¥è¯„ä¼°QueryCADçš„æ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶æä¾›åŸºç¡€ã€‚</li>
<li>QueryCADæˆåŠŸé›†æˆåˆ°è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ã€‚</li>
<li>QueryCADèƒ½å¢å¼ºæ·±åº¦å­¦ä¹ çš„æœºå™¨äººè§£å†³æ–¹æ¡ˆï¼Œä½¿å…¶å…·å¤‡å¤„ç†CADæ¨¡å‹çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08704">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7eb1f7155e0452be853ffc181abd7855.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29adb0073e32ff46033fb5d49ff2b915.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0b6301907af5000996e8cc3ce2f6561.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a81371ae65ddacaac35e798e62c9b66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1a740930cdbf321cef797795942e8b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a77f863fe4e44736d43a4e997df58e07.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction"><a href="#Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction" class="headerlink" title="Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction"></a>Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction</h2><p><strong>Authors:Youness Mellak, Alexandre Bousse, Thibaut Merlin, Debora Giovagnoli, Dimitris Visvikis</strong></p>
<p>This paper presents a novel image reconstruction pipeline for three-gamma (3-{\gamma}) positron emission tomography (PET) aimed at improving spatial resolution and reducing noise in nuclear medicine. The proposed Direct3{\gamma} pipeline addresses the inherent challenges in 3-{\gamma} PET systems, such as detector imperfections and uncertainty in photon interaction points. A key feature of the pipeline is its ability to determine the order of interactions through a model trained on Monte Carlo (MC) simulations using the Geant4 Application for Tomography Emission (GATE) toolkit, thus providing the necessary information to construct Compton cones which intersect with the line of response (LOR) to provide an estimate of the emission point. The pipeline processes 3-{\gamma} PET raw data, reconstructs histoimages by propagating energy and spatial uncertainties along the LOR, and applies a 3-D convolutional neural network (CNN) to refine these intermediate images into high-quality reconstructions. To further enhance image quality, the pipeline leverages both supervised learning and adversarial losses, with the latter preserving fine structural details. Experimental results demonstrate that Direct3{\gamma} consistently outperforms conventional 200-ps time-of-flight (TOF) PET in terms of SSIM and PSNR. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰çš„æ–°å‹å›¾åƒé‡å»ºæµç¨‹ï¼Œæ—¨åœ¨æé«˜æ ¸åŒ»å­¦ä¸­çš„ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚æ‰€æå‡ºçš„Direct3Î³æµç¨‹è§£å†³äº†3-Î³ PETç³»ç»Ÿå›ºæœ‰çš„æŒ‘æˆ˜ï¼Œå¦‚æ¢æµ‹å™¨ç¼ºé™·å’Œå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚è¯¥æµç¨‹çš„ä¸€ä¸ªå…³é”®åŠŸèƒ½æ˜¯ï¼Œå®ƒèƒ½å¤Ÿé€šè¿‡ä½¿ç”¨Geant4å‘å°„æ–­å±‚æ‰«æåº”ç”¨ç¨‹åºï¼ˆGATEï¼‰å·¥å…·åŒ…è¿›è¡Œè’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å‹æ¥ç¡®å®šäº¤äº’çš„é¡ºåºï¼Œä»è€Œæä¾›æ„å»ºäº¤äºå“åº”çº¿ï¼ˆLORï¼‰çš„åº·æ™®é¡¿é”¥æ‰€éœ€çš„ä¿¡æ¯ï¼Œä»¥ä¼°è®¡å‘å°„ç‚¹ã€‚è¯¥æµç¨‹å¤„ç†3-Î³ PETåŸå§‹æ•°æ®ï¼Œé€šè¿‡ä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§æ²¿LORé‡å»ºç›´æ–¹å›¾åƒï¼Œå¹¶åº”ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å°†è¿™äº›ä¸­é—´å›¾åƒç²¾ç»†åŒ–ä¸ºé«˜è´¨é‡é‡å»ºã€‚ä¸ºäº†è¿›ä¸€æ­¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œè¯¥æµç¨‹ç»“åˆäº†ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æ€§æŸå¤±ï¼Œåè€…èƒ½å¤Ÿä¿ç•™ç²¾ç»†çš„ç»“æ„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDirect3Î³åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„200çš®ç§’é£è¡Œæ—¶é—´ï¼ˆTOFï¼‰PETã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.18337v3">PDF</a> 10 pages, 11 figures, 2 tables</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰å›¾åƒé‡å»ºçš„æ–°æµç¨‹ï¼Œæ—¨åœ¨æ”¹å–„ç©ºé—´åˆ†è¾¨ç‡å¹¶å‡å°‘æ ¸åŒ»å­¦ä¸­çš„å™ªå£°ã€‚Direct3Î³æµç¨‹è§£å†³äº†3-Î³ PETç³»ç»Ÿçš„å›ºæœ‰æŒ‘æˆ˜ï¼Œå¦‚æ¢æµ‹å™¨çš„ä¸å®Œç¾å’Œå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚è¯¥æµç¨‹é€šè¿‡è®­ç»ƒæ¨¡å‹ä½¿ç”¨è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿç¡®å®šäº¤äº’é¡ºåºï¼Œæ„å»ºäº¤äºå“åº”çº¿ï¼ˆLORï¼‰çš„åº·æ™®é¡¿é”¥ä»¥ä¼°ç®—å‘å°„ç‚¹ã€‚è¯¥æµç¨‹å¤„ç†3-Î³ PETåŸå§‹æ•°æ®ï¼Œé€šè¿‡ä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§æ²¿LORé‡å»ºç»„ç»‡å›¾åƒï¼Œå¹¶åº”ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯¹ä¸­é—´å›¾åƒè¿›è¡Œé«˜è´¨é‡é‡å»ºã€‚ä¸ºè¿›ä¸€æ­¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œè¯¥æµç¨‹ç»“åˆäº†ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æŸå¤±ï¼Œåè€…ä¿ç•™äº†ç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDirect3Î³åœ¨ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„200çš®ç§’é£è¡Œæ—¶é—´ï¼ˆTOFï¼‰PETã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰PETçš„æ–°å‹å›¾åƒé‡å»ºæµç¨‹ã€‚</li>
<li>Direct3Î³æµç¨‹æ—¨åœ¨æé«˜ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½æ ¸åŒ»å­¦ä¸­çš„å™ªå£°ã€‚</li>
<li>è¯¥æµç¨‹è§£å†³äº†æ¢æµ‹å™¨ä¸å®Œç¾å’Œå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ç­‰3-Î³ PETç³»ç»Ÿçš„å›ºæœ‰æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡è®­ç»ƒæ¨¡å‹å¹¶ä½¿ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿç¡®å®šäº¤äº’é¡ºåºï¼Œæ„å»ºåº·æ™®é¡¿é”¥æ¥ä¼°ç®—å‘å°„ç‚¹ã€‚</li>
<li>è¯¥æµç¨‹åˆ©ç”¨CNNå¯¹å›¾åƒè¿›è¡Œé«˜è´¨é‡é‡å»ºï¼Œå¹¶é€šè¿‡ä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§æ²¿LORç”Ÿæˆç»„ç»‡å›¾åƒã€‚</li>
<li>Direct3Î³æµç¨‹ç»“åˆäº†ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æŸå¤±æ¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œä¿ç•™ç²¾ç»†ç»“æ„ç»†èŠ‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.18337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cc5ecdf31bc8ba51be1fa0028a0c32af.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f597977d942388305fafd98bb0fe2260.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-36a87e8dd81f7cd8c896f7ddf66864fb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4c2c099135b66d5c49b3c1fce146fdc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29caeeb92e880f4aab286063404de0e0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="LiteNeXt-A-Novel-Lightweight-ConvMixer-based-Model-with-Self-embedding-Representation-Parallel-for-Medical-Image-Segmentation"><a href="#LiteNeXt-A-Novel-Lightweight-ConvMixer-based-Model-with-Self-embedding-Representation-Parallel-for-Medical-Image-Segmentation" class="headerlink" title="LiteNeXt: A Novel Lightweight ConvMixer-based Model with Self-embedding   Representation Parallel for Medical Image Segmentation"></a>LiteNeXt: A Novel Lightweight ConvMixer-based Model with Self-embedding   Representation Parallel for Medical Image Segmentation</h2><p><strong>Authors:Ngoc-Du Tran, Thi-Thao Tran, Quang-Huy Nguyen, Manh-Hung Vu, Van-Truong Pham</strong></p>
<p>The emergence of deep learning techniques has advanced the image segmentation task, especially for medical images. Many neural network models have been introduced in the last decade bringing the automated segmentation accuracy close to manual segmentation. However, cutting-edge models like Transformer-based architectures rely on large scale annotated training data, and are generally designed with densely consecutive layers in the encoder, decoder, and skip connections resulting in large number of parameters. Additionally, for better performance, they often be pretrained on a larger data, thus requiring large memory size and increasing resource expenses. In this study, we propose a new lightweight but efficient model, namely LiteNeXt, based on convolutions and mixing modules with simplified decoder, for medical image segmentation. The model is trained from scratch with small amount of parameters (0.71M) and Giga Floating Point Operations Per Second (0.42). To handle boundary fuzzy as well as occlusion or clutter in objects especially in medical image regions, we propose the Marginal Weight Loss that can help effectively determine the marginal boundary between object and background. Additionally, the Self-embedding Representation Parallel technique is proposed as an innovative data augmentation strategy that utilizes the network architecture itself for self-learning augmentation, enhancing feature extraction robustness without external data. Experiments on public datasets including Data Science Bowls, GlaS, ISIC2018, PH2, Sunnybrook, and Lung X-ray data show promising results compared to other state-of-the-art CNN-based and Transformer-based architectures. Our code is released at: <a target="_blank" rel="noopener" href="https://github.com/tranngocduvnvp/LiteNeXt">https://github.com/tranngocduvnvp/LiteNeXt</a>. </p>
<blockquote>
<p>éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å…´èµ·ï¼Œå›¾åƒåˆ†å‰²ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œå·²ç»å¾—åˆ°äº†æå¤§çš„æ¨è¿›ã€‚è¿‡å»åå¹´ä¸­ï¼Œå·²ç»å¼•å…¥äº†è®¸å¤šç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œä½¿è‡ªåŠ¨åŒ–åˆ†å‰²çš„å‡†ç¡®åº¦æ¥è¿‘æ‰‹åŠ¨åˆ†å‰²ã€‚ç„¶è€Œï¼Œæœ€å‰æ²¿çš„æ¨¡å‹ï¼Œå¦‚åŸºäºTransformerçš„æ¶æ„ï¼Œä¾èµ–äºå¤§è§„æ¨¡æ ‡æ³¨çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”é€šå¸¸å…·æœ‰ç¼–ç å™¨ã€è§£ç å™¨å’Œè·³è¿‡è¿æ¥ä¸­çš„å¯†é›†è¿ç»­å±‚ï¼Œå¯¼è‡´å‚æ•°æ•°é‡åºå¤§ã€‚å¦å¤–ï¼Œä¸ºäº†è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå®ƒä»¬é€šå¸¸éœ€è¦åœ¨æ›´å¤§çš„æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤éœ€è¦è¾ƒå¤§çš„å†…å­˜å¹¶å¢åŠ äº†èµ„æºå¼€é”€ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è½»é‡åŒ–ä½†é«˜æ•ˆçš„æ¨¡å‹ï¼Œåä¸ºLiteNeXtï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œè¯¥æ¨¡å‹åŸºäºå·ç§¯å’Œæ··åˆæ¨¡å—ï¼Œå¹¶ä½¿ç”¨ç®€åŒ–çš„è§£ç å™¨ã€‚è¯¥æ¨¡å‹ä»é›¶å¼€å§‹è®­ç»ƒï¼Œå‚æ•°è¾ƒå°‘ï¼ˆ0.71Mï¼‰ï¼Œå¹¶ä¸”æ¯ç§’å¯è¿›è¡Œ0.42Gigaæµ®ç‚¹è¿ç®—ã€‚ä¸ºäº†å¤„ç†åŒ»å­¦å›¾åƒåŒºåŸŸä¸­è¾¹ç•Œæ¨¡ç³Šä»¥åŠå¯¹è±¡é®æŒ¡æˆ–æ‚ä¹±çš„æƒ…å†µï¼Œæˆ‘ä»¬æå‡ºäº†è¾¹ç¼˜æƒé‡æŸå¤±ï¼ˆMarginal Weight Lossï¼‰ï¼Œå¯ä»¥å¸®åŠ©æœ‰æ•ˆåœ°ç¡®å®šå¯¹è±¡ä¸èƒŒæ™¯ä¹‹é—´çš„è¾¹ç¼˜è¾¹ç•Œã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†è‡ªåµŒå…¥è¡¨ç¤ºå¹¶è¡ŒæŠ€æœ¯ï¼ˆSelf-embedding Representation Parallelï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œåˆ©ç”¨ç½‘ç»œæ¶æ„æœ¬èº«è¿›è¡Œè‡ªå­¦ä¹ å¢å¼ºï¼Œæé«˜ç‰¹å¾æå–çš„ç¨³å¥æ€§è€Œæ— éœ€å¤–éƒ¨æ•°æ®ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–æœ€å…ˆè¿›çš„CNNå’ŒTransformeræ¶æ„ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Data Science Bowlsã€GlaSã€ISIC2018ã€PH2ã€Sunnybrookå’Œè‚ºéƒ¨Xå°„çº¿æ•°æ®ä¸Šå‡æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å·²å‘å¸ƒåœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/tranngocduvnvp/LiteNeXt%E3%80%82">https://github.com/tranngocduvnvp/LiteNeXtã€‚</a></p>
</blockquote>
<p><strong>è§£é‡Š</strong>ï¼š</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15779v2">PDF</a> This manuscript has been accepted by Biomedical Signal Processing and   Control</p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‡ºç°æ¨åŠ¨äº†å›¾åƒåˆ†å‰²ä»»åŠ¡çš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»å­¦å›¾åƒé¢†åŸŸã€‚ä¸€é¡¹æ–°ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§ä½†é«˜æ•ˆçš„æ¨¡å‹LiteNeXtï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ã€‚è¯¥æ¨¡å‹åŸºäºå·ç§¯å’Œæ··åˆæ¨¡å—ï¼Œå…·æœ‰ç®€åŒ–çš„è§£ç å™¨ï¼Œå¯æœ‰æ•ˆå¤„ç†åŒ»å­¦å›¾åƒåŒºåŸŸä¸­è¾¹ç•Œæ¨¡ç³Šã€é®æŒ¡æˆ–æ‚ä¹±çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†è¾¹é™…æƒé‡æŸå¤±å’Œè‡ªæˆ‘åµŒå…¥è¡¨ç¤ºå¹¶è¡Œç­‰åˆ›æ–°ç­–ç•¥ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶æ€§èƒ½ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æŠ€æœ¯æ¨åŠ¨äº†åŒ»å­¦å›¾åƒåˆ†å‰²çš„è¿›å±•ï¼Œè®¸å¤šç¥ç»ç½‘ç»œæ¨¡å‹æé«˜äº†è‡ªåŠ¨åŒ–åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚</li>
<li>æœ€æ–°æ¨¡å‹å¦‚åŸºäºTransformerçš„æ¶æ„éœ€è¦å¤§è§„æ¨¡æ³¨é‡Šè®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”å‚æ•°è¾ƒå¤šã€‚</li>
<li>LiteNeXtæ¨¡å‹æ˜¯ä¸€ä¸ªè½»é‡çº§ä½†é«˜æ•ˆçš„åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ï¼ŒåŸºäºå·ç§¯å’Œæ··åˆæ¨¡å—ï¼Œå…·æœ‰ç®€åŒ–çš„è§£ç å™¨ã€‚</li>
<li>LiteNeXtæ¨¡å‹å¯å¤„ç†åŒ»å­¦å›¾åƒä¸­çš„è¾¹ç•Œæ¨¡ç³Šã€é®æŒ¡æˆ–æ‚ä¹±é—®é¢˜ï¼Œé€šè¿‡è¾¹é™…æƒé‡æŸå¤±æœ‰æ•ˆç¡®å®šç‰©ä½“ä¸èƒŒæ™¯ä¹‹é—´çš„è¾¹ç•Œã€‚</li>
<li>è‡ªæˆ‘åµŒå…¥è¡¨ç¤ºå¹¶è¡Œæ˜¯ä¸€ç§åˆ©ç”¨ç½‘ç»œæ¶æ„è¿›è¡Œè‡ªæˆ‘å­¦ä¹ å¢å¼ºçš„åˆ›æ–°æ•°æ®å¢å¼ºç­–ç•¥ï¼Œæé«˜äº†ç‰¹å¾æå–çš„ç¨³å¥æ€§ã€‚</li>
<li>åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLiteNeXtæ¨¡å‹ä¸å…¶ä»–å…ˆè¿›çš„CNNå’ŒTransformeræ¶æ„ç›¸æ¯”å…·æœ‰å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.15779">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2fdd76dfe1422046c5e96eb83a2d3a8e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce4446c79c60821ebb8662595e67763f.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DeepThalamus-A-novel-deep-learning-method-for-automatic-segmentation-of-brain-thalamic-nuclei-from-multimodal-ultra-high-resolution-MRI"><a href="#DeepThalamus-A-novel-deep-learning-method-for-automatic-segmentation-of-brain-thalamic-nuclei-from-multimodal-ultra-high-resolution-MRI" class="headerlink" title="DeepThalamus: A novel deep learning method for automatic segmentation of   brain thalamic nuclei from multimodal ultra-high resolution MRI"></a>DeepThalamus: A novel deep learning method for automatic segmentation of   brain thalamic nuclei from multimodal ultra-high resolution MRI</h2><p><strong>Authors:Marina Ruiz-Perez, Sergio Morell-Ortega, Marien Gadea, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Mariam de la Iglesia-Vaya, Thomas Tourdias, Pierrick CoupÃ©, JosÃ© V. ManjÃ³n</strong></p>
<p>The implication of the thalamus in multiple neurological pathologies makes it a structure of interest for volumetric analysis. In the present work, we have designed and implemented a multimodal volumetric deep neural network for the segmentation of thalamic nuclei at ultra-high resolution (0.125 mm3). Current tools either operate at standard resolution (1 mm3) or use monomodal data. To achieve the proposed objective, first, a database of semiautomatically segmented thalamic nuclei was created using ultra-high resolution T1, T2 and White Matter nulled (WMn) images. Then, a novel Deep learning based strategy was designed to obtain the automatic segmentations and trained to improve its robustness and accuaracy using a semisupervised approach. The proposed method was compared with a related state-of-the-art method showing competitive results both in terms of segmentation quality and efficiency. To make the proposed method fully available to the scientific community, a full pipeline able to work with monomodal standard resolution T1 images is also proposed. </p>
<blockquote>
<p>ä¸˜è„‘åœ¨å¤šç§ç¥ç»ç—…ç†ä¸­çš„å½±å“ä½¿å…¶æˆä¸ºä½“ç§¯åˆ†ææ„Ÿå…´è¶£çš„ç»“æ„ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ç§å¤šæ¨¡æ€ä½“ç§¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç”¨äºè¶…é«˜åˆ†è¾¨ç‡ï¼ˆ0.125 mm3ï¼‰ä¸‹çš„ä¸˜è„‘æ ¸åˆ†å‰²ã€‚å½“å‰å·¥å…·è¦ä¹ˆåœ¨æ ‡å‡†åˆ†è¾¨ç‡ï¼ˆ1 mm3ï¼‰ä¸‹è¿è¡Œï¼Œè¦ä¹ˆä½¿ç”¨å•æ¨¡æ€æ•°æ®ã€‚ä¸ºäº†å®ç°æ—¢å®šç›®æ ‡ï¼Œé¦–å…ˆä½¿ç”¨è¶…é«˜åˆ†è¾¨ç‡çš„T1ã€T2å’ŒWhite Matter nulledï¼ˆWMnï¼‰å›¾åƒåˆ›å»ºäº†åŠè‡ªåŠ¨åˆ†å‰²çš„ä¸˜è„‘æ ¸æ•°æ®åº“ã€‚ç„¶åï¼Œè®¾è®¡äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–°ç­–ç•¥æ¥è·å¾—è‡ªåŠ¨åˆ†å‰²ï¼Œå¹¶ä½¿ç”¨åŠç›‘ç£æ–¹æ³•è¿›è¡Œè®­ç»ƒä»¥æé«˜å…¶ç¨³å¥æ€§å’Œå‡†ç¡®æ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ä¸€ç§ç›¸å…³çš„é«˜çº§æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œåœ¨åˆ†å‰²è´¨é‡å’Œæ•ˆç‡æ–¹é¢éƒ½æ˜¾ç¤ºå‡ºå…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚ä¸ºäº†ä½¿æ‰€æå‡ºçš„æ–¹æ³•å®Œå…¨å¯ä¾›ç§‘å­¦ç•Œä½¿ç”¨ï¼Œè¿˜æå‡ºäº†ä¸€ç§èƒ½å¤Ÿå¤„ç†å•æ¨¡æ€æ ‡å‡†åˆ†è¾¨ç‡T1å›¾åƒçš„å…¨æµç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.07751v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶è®¾è®¡å¹¶å®æ–½äº†ä¸€ç§å¤šæ¨¡æ€ä½“ç§¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç”¨äºè¶…é«˜åˆ†è¾¨ç‡ï¼ˆ0.125 mmÂ³ï¼‰ä¸˜è„‘æ ¸åˆ†å‰²ã€‚å½“å‰å·¥å…·æ“ä½œäºæ ‡å‡†åˆ†è¾¨ç‡æˆ–ä½¿ç”¨å•æ¨¡æ€æ•°æ®ã€‚æœ¬ç ”ç©¶åˆ›å»ºäº†ä¸€ä¸ªåŠè‡ªåŠ¨åˆ†å‰²ä¸˜è„‘æ ¸æ•°æ®åº“ï¼Œä½¿ç”¨è¶…é«˜åˆ†è¾¨ç‡T1ã€T2å’Œç™½è‰²ç‰©è´¨ç©ºåŒ–ï¼ˆWMnï¼‰å›¾åƒï¼Œç„¶åè®¾è®¡äº†ä¸€ç§æ–°å‹çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åˆ†å‰²ç­–ç•¥å¹¶è¿›è¡Œäº†è®­ç»ƒã€‚æœ¬æ–¹æ³•ä¸ç›¸å…³é¢†åŸŸçš„å‰æ²¿æ–¹æ³•ç›¸æ¯”åœ¨åˆ†å‰²è´¨é‡å’Œæ•ˆç‡æ–¹é¢å±•ç°äº†ç«äº‰åŠ›ï¼Œå¹¶æå‡ºäº†é€‚ç”¨äºå•æ¨¡æ€æ ‡å‡†åˆ†è¾¨ç‡T1å›¾åƒçš„å®Œæ•´æµç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶æ¢è®¨äº†ä¸˜è„‘åœ¨å¤šç§ç¥ç»ç—…ç†å­¦ä¸­çš„ä½œç”¨ï¼Œå¹¶å¯¹å…¶è¿›è¡Œä½“ç§¯åˆ†æã€‚</li>
<li>è®¾è®¡å¹¶å®æ–½äº†ä¸€ç§å¤šæ¨¡æ€ä½“ç§¯æ·±åº¦ç¥ç»ç½‘ç»œç”¨äºè¶…é«˜åˆ†è¾¨ç‡ä¸˜è„‘æ ¸åˆ†å‰²ã€‚</li>
<li>å½“å‰å·¥å…·å­˜åœ¨æ“ä½œäºæ ‡å‡†åˆ†è¾¨ç‡æˆ–ä½¿ç”¨å•æ¨¡æ€æ•°æ®çš„å±€é™ã€‚</li>
<li>é€šè¿‡åˆ›å»ºåŠè‡ªåŠ¨åˆ†å‰²ä¸˜è„‘æ ¸æ•°æ®åº“å¹¶ä½¿ç”¨è¶…é«˜åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œè®­ç»ƒï¼Œæé«˜äº†æ–¹æ³•çš„ç¨³å¥æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>æœ¬æ–¹æ³•ä¸ç›¸å…³é¢†åŸŸçš„å‰æ²¿æ–¹æ³•ç›¸æ¯”åœ¨åˆ†å‰²è´¨é‡å’Œæ•ˆç‡æ–¹é¢å±•ç°äº†ç«äº‰åŠ›ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§å®Œæ•´çš„æµç¨‹ï¼Œèƒ½å¤Ÿå¤„ç†å•æ¨¡æ€æ ‡å‡†åˆ†è¾¨ç‡T1å›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.07751">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b389f5081328cb0935b2454ca680d1d.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-16/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6ab0166324c140954021b1012ef6c3ae.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  VideoMind A Chain-of-LoRA Agent for Long Video Reasoning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-16/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4d56c02d4d522dde64ae67f260834dc1.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-16  StereoCrafter-Zero Zero-Shot Stereo Video Generation with Noisy Restart
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23827k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
