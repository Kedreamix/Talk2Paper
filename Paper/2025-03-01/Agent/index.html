<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-01  Multi-Agent Verification Scaling Test-Time Compute with Multiple   Verifiers">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-84d4f38d510f1dbd809b3d5331d556ad.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    78 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-01-æ›´æ–°"><a href="#2025-03-01-æ›´æ–°" class="headerlink" title="2025-03-01 æ›´æ–°"></a>2025-03-01 æ›´æ–°</h1><h2 id="Multi-Agent-Verification-Scaling-Test-Time-Compute-with-Multiple-Verifiers"><a href="#Multi-Agent-Verification-Scaling-Test-Time-Compute-with-Multiple-Verifiers" class="headerlink" title="Multi-Agent Verification: Scaling Test-Time Compute with Multiple   Verifiers"></a>Multi-Agent Verification: Scaling Test-Time Compute with Multiple   Verifiers</h2><p><strong>Authors:Shalev Lifshitz, Sheila A. McIlraith, Yilun Du</strong></p>
<p>By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time. </p>
<blockquote>
<p>é€šè¿‡æµ‹è¯•æ—¶åˆ©ç”¨æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥åœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹è¿›è¡Œæ”¹è¿›ã€‚ä¸€ç§å¸¸è§ç­–ç•¥æ˜¯ä½¿ç”¨éªŒè¯å™¨æ¥è¯„ä¼°å€™é€‰è¾“å‡ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸ºæµ‹è¯•æ—¶çš„è®¡ç®—æå‡ºäº†ä¸€ç§æ–°å‹æ‰©å±•ç»´åº¦ï¼šæ‰©å±•éªŒè¯å™¨çš„æ•°é‡ã€‚æˆ‘ä»¬å¼•å…¥äº†å¤šä»£ç†éªŒè¯ï¼ˆMAVï¼‰ä½œä¸ºæµ‹è¯•æ—¶è®¡ç®—èŒƒå¼ï¼Œå®ƒå°†å¤šä¸ªéªŒè¯å™¨ç»“åˆèµ·æ¥ä»¥æé«˜æ€§èƒ½ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨æ–¹é¢éªŒè¯å™¨ï¼ˆAVï¼‰ä½œä¸ºMAVä¸­éªŒè¯å™¨çš„ä¸€ç§å¯èƒ½é€‰æ‹©ï¼Œæ–¹é¢éªŒè¯å™¨æ˜¯å³æ’å³ç”¨çš„LLMï¼Œé€šè¿‡æç¤ºæ¥éªŒè¯è¾“å‡ºçš„ä¸åŒæ–¹é¢ã€‚æ–¹é¢éªŒè¯å™¨æ˜¯MAVçš„ä¾¿æ·æ„å»ºå—ï¼Œå¯ä»¥è½»æ˜“ç»„åˆè€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»‹ç»äº†BoN-MAVï¼Œä¸€ç§ç®€å•çš„å¤šä»£ç†éªŒè¯ç®—æ³•ï¼Œå®ƒå°†æœ€ä½³né‡‡æ ·ä¸å¤šä¸ªéªŒè¯å™¨ç›¸ç»“åˆã€‚BoN-MAVè¡¨ç°å‡ºæ¯”è‡ªæˆ‘ä¸€è‡´æ€§å¥–åŠ±æ¨¡å‹éªŒè¯æ›´å¼ºçš„æ‰©å±•æ¨¡å¼ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä»å¼±åˆ°å¼ºçš„æ³›åŒ–ï¼Œå³ç»„åˆå¼±éªŒè¯å™¨å¯ä»¥æ”¹å–„æ›´å¼ºå¤§çš„LLMï¼Œä»¥åŠè‡ªæˆ‘æ”¹è¿›ï¼Œå³ä½¿ç”¨åŒä¸€åŸºç¡€æ¨¡å‹æ¥ç”Ÿæˆå’ŒéªŒè¯è¾“å‡ºã€‚æˆ‘ä»¬çš„ç»“æœå°†æ‰©å±•éªŒè¯å™¨æ•°é‡ç¡®ç«‹ä¸ºæé«˜è¯­è¨€æ¨¡å‹æµ‹è¯•æ—¶æ€§èƒ½çš„æœ‰å‰é€”çš„æ–°ç»´åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20379v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æµ‹è¯•æ—¶å¯ä»¥åˆ©ç”¨æ›´å¤šçš„è®¡ç®—èµ„æºæ¥æé«˜æ€§èƒ½ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æµ‹è¯•æ—¶è®¡ç®—ç»´åº¦â€”â€”å¢åŠ éªŒè¯å™¨çš„æ•°é‡ã€‚æˆ‘ä»¬æå‡ºäº†å¤šä»£ç†éªŒè¯ï¼ˆMAVï¼‰ä½œä¸ºæµ‹è¯•æ—¶è®¡ç®—èŒƒå¼ï¼Œè¯¥èŒƒå¼ç»“åˆäº†å¤šä¸ªéªŒè¯å™¨ä»¥æé«˜æ€§èƒ½ã€‚ä»‹ç»äº†ä¸€ç§å¯ç”¨äºMAVçš„éªŒè¯å™¨é€‰æ‹©â€”â€”æ–¹é¢éªŒè¯å™¨ï¼ˆAVï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†BoN-MAVç®—æ³•ï¼Œè¯¥ç®—æ³•ç»“åˆäº†å¤šä¸ªéªŒè¯å™¨çš„æœ€ä½³né‡‡æ ·æ–¹æ³•ã€‚BoN-MAVè¡¨ç°å‡ºæ¯”è‡ªæˆ‘ä¸€è‡´æ€§å¥–åŠ±æ¨¡å‹éªŒè¯æ›´å¼ºçš„æ‰©å±•æ¨¡å¼ï¼Œå¹¶å±•ç¤ºäº†ä»å¼±åˆ°å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œè‡ªæˆ‘æ”¹è¿›èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¢åŠ éªŒè¯å™¨çš„æ•°é‡æ˜¯æé«˜è¯­è¨€æ¨¡å‹æµ‹è¯•æ€§èƒ½çš„ä¸€ä¸ªæœ‰å‰é€”çš„æ–°ç»´åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥åœ¨æµ‹è¯•é˜¶æ®µæé«˜æ€§èƒ½ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æµ‹è¯•æ—¶è®¡ç®—ç»´åº¦ï¼šå¢åŠ éªŒè¯å™¨çš„æ•°é‡ã€‚</li>
<li>å¼•å…¥äº†å¤šä»£ç†éªŒè¯ï¼ˆMAVï¼‰ä½œä¸ºæµ‹è¯•æ—¶è®¡ç®—èŒƒå¼ï¼Œç»“åˆäº†å¤šä¸ªéªŒè¯å™¨ä»¥æé«˜æ€§èƒ½ã€‚</li>
<li>æ–¹é¢éªŒè¯å™¨ï¼ˆAVï¼‰å¯ä»¥ä½œä¸ºMAVç³»ç»Ÿä¸­çš„ä¸€ç§éªŒè¯å™¨é€‰æ‹©ã€‚</li>
<li>BoN-MAVç®—æ³•ç»“åˆäº†å¤šä¸ªéªŒè¯å™¨çš„æœ€ä½³né‡‡æ ·æ–¹æ³•ï¼Œè¡¨ç°å‡ºè¾ƒå¼ºçš„æ‰©å±•æ¨¡å¼ã€‚</li>
<li>BoN-MAVå®ç°äº†å¼±åˆ°å¼ºçš„æ³›åŒ–å’Œè‡ªæˆ‘æ”¹è¿›èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b2b76a62b0fde8b559d0309c285dac75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-201dbf6a0def84242a23493acd57d1a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d7fad77f7243459384cbd85863a2ab4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1336bd377a42deb455d8003898741945.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-693e8166ef1b67b991cfeda3ced6181f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="M-3Builder-A-Multi-Agent-System-for-Automated-Machine-Learning-in-Medical-Imaging"><a href="#M-3Builder-A-Multi-Agent-System-for-Automated-Machine-Learning-in-Medical-Imaging" class="headerlink" title="M^3Builder: A Multi-Agent System for Automated Machine Learning in   Medical Imaging"></a>M^3Builder: A Multi-Agent System for Automated Machine Learning in   Medical Imaging</h2><p><strong>Authors:Jinghao Feng, Qiaoyu Zheng, Chaoyi Wu, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie</strong></p>
<p>Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks. However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models. In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging. At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training. These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution. (ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data. (iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging. </p>
<blockquote>
<p>åŒ»å­¦äººå·¥æ™ºèƒ½ç³»ç»Ÿå› å…¶è‡ªä¸»æ‰§è¡Œå¤æ‚ä»»åŠ¡çš„èƒ½åŠ›è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹å‡†å¤‡è‰¯å¥½çš„å·¥å…·çš„ä¾èµ–é™åˆ¶äº†å®ƒä»¬åœ¨åŒ»å­¦é¢†åŸŸçš„åº”ç”¨ï¼ŒåŒ»å­¦é¢†åŸŸéœ€è¦è®­ç»ƒä¸“é—¨çš„æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åšå‡ºäº†ä¸‰ä¸ªè´¡çŒ®ï¼šï¼ˆä¸€ï¼‰æˆ‘ä»¬æå‡ºäº†M3Builderï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–åŒ»å­¦å½±åƒä¸­çš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ã€‚M3Builderçš„æ ¸å¿ƒæ˜¯å››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ï¼Œå®ƒä»¬ååŒè§£å†³å¤æ‚çš„åŒ»å­¦MLå·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†å’Œç¯å¢ƒé…ç½®ï¼Œä»¥åŠè‡ªæˆ‘åŒ…å«çš„è‡ªåŠ¨è°ƒè¯•å’Œæ¨¡å‹è®­ç»ƒã€‚è¿™äº›æ™ºèƒ½ä½“åœ¨åŒ»å­¦å½±åƒMLå·¥ä½œç©ºé—´å†…è¿è¡Œï¼Œè¿™æ˜¯ä¸€ä¸ªç»“æ„åŒ–ç¯å¢ƒï¼Œæ—¨åœ¨ä¸ºæ™ºèƒ½ä½“æä¾›æ•°æ®é›†ã€è®­ç»ƒä»£ç å’Œäº¤äº’å·¥å…·çš„æ–‡æœ¬æè¿°ï¼Œä»è€Œå®ç°æ— ç¼é€šä¿¡å’Œä»»åŠ¡æ‰§è¡Œã€‚ï¼ˆäºŒï¼‰ä¸ºäº†è¯„ä¼°åŒ»å­¦æˆåƒè‡ªåŠ¨åŒ–çš„MLè¿›åº¦ï¼Œæˆ‘ä»¬æå‡ºäº†M3Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«äº”ä¸ªè§£å‰–éƒ¨ä½å’Œä¸‰ç§æˆåƒæ¨¡å¼çš„14ä¸ªè®­ç»ƒæ•°æ®é›†ä¸Šçš„å››ä¸ªé€šç”¨ä»»åŠ¡ï¼Œæ¶µç›–äºŒç»´å’Œä¸‰ç»´æ•°æ®ã€‚ï¼ˆä¸‰ï¼‰æˆ‘ä»¬åœ¨ç³»ç»Ÿä¸­ä½¿ç”¨äº†ä¸ƒä¸ªæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæ™ºèƒ½ä½“çš„æ ¸å¿ƒï¼Œä¾‹å¦‚Claudeç³»åˆ—ã€GPT-4oå’ŒDeepSeek-V3ã€‚ä¸ç°æœ‰çš„MLæ™ºèƒ½ä½“è®¾è®¡ç›¸æ¯”ï¼ŒM3Builderåœ¨å®ŒæˆåŒ»å­¦å½±åƒä¸­çš„MLä»»åŠ¡æ—¶è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä½¿ç”¨Claude-3.7-Sonnetä½œä¸ºæ™ºèƒ½ä½“æ ¸å¿ƒæ—¶ï¼ŒæˆåŠŸç‡ä¸º94.29%ï¼Œæ˜¾ç¤ºå‡ºåœ¨åŒ»å­¦å½±åƒä¸­å®Œå…¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ çš„å·¨å¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20301v1">PDF</a> 38 pages, 7 figures</p>
<p><strong>æ‘˜è¦</strong><br>    M3Builderæ˜¯ä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“ä¸ºè‡ªåŠ¨åŒ–åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ è€Œè®¾è®¡ã€‚é€šè¿‡å››ä¸ªä¸“é—¨æ™ºèƒ½ä½“çš„åä½œï¼Œå®ç°åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ çš„å¤æ‚å¤šæ­¥éª¤æµç¨‹è‡ªåŠ¨åŒ–ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€ç¯å¢ƒé…ç½®ã€è‡ªæˆ‘è°ƒè¯•å’Œæ¨¡å‹è®­ç»ƒç­‰ã€‚æå‡ºM3BenchåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°è‡ªåŠ¨åŒ–åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ è¿›å±•ã€‚å®éªŒæ˜¾ç¤ºï¼ŒM3Builderåœ¨åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½¿ç”¨Claude-3.7-Sonnetä½œä¸ºæ™ºèƒ½æ ¸å¿ƒï¼ŒæˆåŠŸç‡ä¸º94.29%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>M3Builderæ˜¯ä¸€ä¸ªæ–°å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“ä¸ºè‡ªåŠ¨åŒ–åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ è€Œè®¾è®¡ã€‚</li>
<li>M3Builderé€šè¿‡å››ä¸ªä¸“é—¨æ™ºèƒ½ä½“è§£å†³åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ çš„å¤æ‚æµç¨‹ã€‚</li>
<li>M3Builderæä¾›äº†ä¸€ä¸ªåŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ çš„å·¥ä½œç©ºé—´ï¼Œä¿ƒè¿›æ™ºèƒ½ä½“é—´çš„æ— ç¼æ²Ÿé€šå’Œä»»åŠ¡æ‰§è¡Œã€‚</li>
<li>M3BenchåŸºå‡†æµ‹è¯•ç”¨äºè¯„ä¼°è‡ªåŠ¨åŒ–åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ çš„è¿›å±•ã€‚</li>
<li>å®éªŒè¡¨æ˜M3Builderåœ¨åŒ»å­¦å½±åƒæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
<li>ä½¿ç”¨Claude-3.7-Sonnetä½œä¸ºæ™ºèƒ½æ ¸å¿ƒçš„M3BuilderæˆåŠŸç‡ä¸º94.29%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84d4f38d510f1dbd809b3d5331d556ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d74b3f214371bf5356a15a34d72428ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edbf97479d5a11c6c804e54f4702b477.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MARVEL-Multi-Agent-Reinforcement-Learning-for-constrained-field-of-View-multi-robot-Exploration-in-Large-scale-environments"><a href="#MARVEL-Multi-Agent-Reinforcement-Learning-for-constrained-field-of-View-multi-robot-Exploration-in-Large-scale-environments" class="headerlink" title="MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View   multi-robot Exploration in Large-scale environments"></a>MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View   multi-robot Exploration in Large-scale environments</h2><p><strong>Authors:Jimmy Chiun, Shizhe Zhang, Yizhuo Wang, Yuhong Cao, Guillaume Sartoretti</strong></p>
<p>In multi-robot exploration, a team of mobile robot is tasked with efficiently mapping an unknown environments. While most exploration planners assume omnidirectional sensors like LiDAR, this is impractical for small robots such as drones, where lightweight, directional sensors like cameras may be the only option due to payload constraints. These sensors have a constrained field-of-view (FoV), which adds complexity to the exploration problem, requiring not only optimal robot positioning but also sensor orientation during movement. In this work, we propose MARVEL, a neural framework that leverages graph attention networks, together with novel frontiers and orientation features fusion technique, to develop a collaborative, decentralized policy using multi-agent reinforcement learning (MARL) for robots with constrained FoV. To handle the large action space of viewpoints planning, we further introduce a novel information-driven action pruning strategy. MARVEL improves multi-robot coordination and decision-making in challenging large-scale indoor environments, while adapting to various team sizes and sensor configurations (i.e., FoV and sensor range) without additional training. Our extensive evaluation shows that MARVELâ€™s learned policies exhibit effective coordinated behaviors, outperforming state-of-the-art exploration planners across multiple metrics. We experimentally demonstrate MARVELâ€™s generalizability in large-scale environments, of up to 90m by 90m, and validate its practical applicability through successful deployment on a team of real drone hardware. </p>
<blockquote>
<p>åœ¨å¤šæœºå™¨äººæ¢æµ‹è¿‡ç¨‹ä¸­ï¼Œä¸€ç»„ç§»åŠ¨æœºå™¨äººè¢«èµ‹äºˆé«˜æ•ˆåœ°å›¾æœªçŸ¥ç¯å¢ƒçš„ä»»åŠ¡ã€‚è™½ç„¶å¤§å¤šæ•°æ¢æµ‹è§„åˆ’å™¨éƒ½å‡è®¾ä½¿ç”¨åƒæ¿€å…‰é›·è¾¾è¿™æ ·çš„å…¨æ–¹ä½ä¼ æ„Ÿå™¨ï¼Œä½†å¯¹äºæ— äººæœºè¿™æ ·çš„å°å‹æœºå™¨äººæ¥è¯´ï¼Œç”±äºæœ‰æ•ˆè½½è·é™åˆ¶ï¼Œä½¿ç”¨è½»é‡çº§ã€å®šå‘çš„ä¼ æ„Ÿå™¨ï¼ˆå¦‚æ‘„åƒæœºï¼‰å¯èƒ½æ˜¯å”¯ä¸€çš„é€‰æ‹©ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸å¯è¡Œçš„ã€‚è¿™äº›ä¼ æ„Ÿå™¨çš„è§†é‡ï¼ˆFoVï¼‰å—é™ï¼Œå¢åŠ äº†æ¢æµ‹é—®é¢˜çš„å¤æ‚æ€§ï¼Œä¸ä»…è¦æ±‚æœºå™¨äººä½ç½®æœ€ä¼˜ï¼Œè€Œä¸”åœ¨ç§»åŠ¨è¿‡ç¨‹ä¸­è¿˜éœ€è¦ä¼ æ„Ÿå™¨æ–¹å‘ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MARVELï¼Œä¸€ä¸ªåˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œç»“åˆæ–°çš„è¾¹ç•Œå’Œå®šå‘ç‰¹å¾èåˆæŠ€æœ¯çš„ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œé‡‡ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸ºè§†é‡å—é™çš„æœºå™¨äººå¼€å‘åä½œã€åˆ†æ•£åŒ–çš„ç­–ç•¥ã€‚ä¸ºäº†å¤„ç†è§†ç‚¹è§„åˆ’ä¸­çš„å¤§åŠ¨ä½œç©ºé—´ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§æ–°çš„ä¿¡æ¯é©±åŠ¨åŠ¨ä½œä¿®å‰ªç­–ç•¥ã€‚MARVELæ”¹è¿›äº†å¤šæœºå™¨äººåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤§è§„æ¨¡å®¤å†…ç¯å¢ƒä¸­çš„åè°ƒå’Œå†³ç­–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§å›¢é˜Ÿè§„æ¨¡å’Œä¼ æ„Ÿå™¨é…ç½®ï¼ˆå³è§†é‡å’Œä¼ æ„Ÿå™¨èŒƒå›´ï¼‰è€Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚æˆ‘ä»¬çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒMARVELæ‰€å­¦ä¹ çš„ç­–ç•¥è¡¨ç°å‡ºæœ‰æ•ˆçš„åè°ƒè¡Œä¸ºï¼Œåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¿‡äº†æœ€æ–°çš„æ¢ç´¢è§„åˆ’å™¨ã€‚æˆ‘ä»¬åœ¨å®éªŒä¸­å±•ç¤ºäº†MARVELåœ¨é«˜è¾¾90ç±³ä¹˜90ç±³çš„å¤§è§„æ¨¡ç¯å¢ƒä¸­çš„é€šç”¨æ€§ï¼Œå¹¶é€šè¿‡æˆåŠŸéƒ¨ç½²åœ¨å®é™…æ— äººæœºç¡¬ä»¶ä¸ŠéªŒè¯äº†å…¶å®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20217v1">PDF</a> \c{opyright} 20XX IEEE. Personal use of this material is permitted.   Permission from IEEE must be obtained for all other uses, in any current or   future media, including reprinting&#x2F;republishing this material for advertising   or promotional purposes, creating new collective works, for resale or   redistribution to servers or lists, or reuse of any copyrighted component of   this work in other works</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ä¸ªåä¸ºMARVELçš„ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºè§£å†³å¤šæœºå™¨äººæ¢ç´¢ä¸­å› è§†é‡å—é™å¯¼è‡´çš„å¤æ‚é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆå›¾æ³¨æ„åŠ›ç½‘ç»œã€å‰æ²¿å’Œæ–¹ä½ç‰¹å¾èåˆæŠ€æœ¯ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å‘å±•åä½œå¼åˆ†æ•£æ”¿ç­–ï¼Œé€‚ç”¨äºè§†é‡å—é™çš„æœºå™¨äººã€‚ä¸ºè§£å†³è§†è§’è§„åˆ’çš„å¤§åŠ¨ä½œç©ºé—´é—®é¢˜ï¼Œå¼•å…¥ä¿¡æ¯é©±åŠ¨çš„åŠ¨ä½œä¿®å‰ªç­–ç•¥ã€‚MARVELæé«˜äº†æœºå™¨äººåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤§å‹å®¤å†…ç¯å¢ƒä¸­çš„åè°ƒæ€§å’Œå†³ç­–èƒ½åŠ›ï¼Œå¹¶èƒ½é€‚åº”å„ç§å›¢é˜Ÿè§„æ¨¡å’Œä¼ æ„Ÿå™¨é…ç½®ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒMARVELçš„å­¦ä¹ ç­–ç•¥è¡¨ç°å‡ºæœ‰æ•ˆçš„åè°ƒè¡Œä¸ºï¼Œåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ¢ç´¢è§„åˆ’å™¨ã€‚å¹¶åœ¨å¤§å‹ç¯å¢ƒä¸­è¿›è¡Œäº†å®éªŒéªŒè¯å…¶é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MARVELæ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºè§£å†³å¤šæœºå™¨äººæ¢ç´¢ä¸­çš„å¤æ‚é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶é’ˆå¯¹è§†é‡å—é™çš„æœºå™¨äººè®¾è®¡ï¼Œåˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå’Œå¼ºåŒ–å­¦ä¹ è¿›è¡Œå†³ç­–ã€‚</li>
<li>MARVELå¼•å…¥äº†å‰æ²¿å’Œæ–¹ä½ç‰¹å¾èåˆæŠ€æœ¯ï¼Œä»¥æé«˜æœºå™¨äººçš„æ¢ç´¢æ•ˆç‡ã€‚</li>
<li>é€šè¿‡ä¿¡æ¯é©±åŠ¨çš„åŠ¨ä½œä¿®å‰ªç­–ç•¥è§£å†³å¤§åŠ¨ä½œç©ºé—´é—®é¢˜ã€‚</li>
<li>MARVELæé«˜äº†æœºå™¨äººåœ¨å¤§å‹å®¤å†…ç¯å¢ƒä¸­çš„åè°ƒæ€§å’Œå†³ç­–èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„å›¢é˜Ÿè§„æ¨¡å’Œä¼ æ„Ÿå™¨é…ç½®ï¼Œä¸”æ— éœ€é¢å¤–è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20217">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-16ee3897eebab18d1eca6b29cfa61130.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15bfd113117281487ded698a4d01a44d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce053a5c0c0d2065a4011b3b0f3b7a67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd8e072334a1bbfeb80f79285f8a8e81.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-29e9257f21e4350471c49a94ce001665.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a49335a08cf8aa72058c4ba9005eda3a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Collab-Overcooked-Benchmarking-and-Evaluating-Large-Language-Models-as-Collaborative-Agents"><a href="#Collab-Overcooked-Benchmarking-and-Evaluating-Large-Language-Models-as-Collaborative-Agents" class="headerlink" title="Collab-Overcooked: Benchmarking and Evaluating Large Language Models as   Collaborative Agents"></a>Collab-Overcooked: Benchmarking and Evaluating Large Language Models as   Collaborative Agents</h2><p><strong>Authors:Haochen Sun, Shuwen Zhang, Lei Ren, Hao Xu, Hao Fu, Caixia Yuan, Xiaojie Wang</strong></p>
<p>Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at <a target="_blank" rel="noopener" href="https://github.com/YusaeMeow/Collab-Overcooked">https://github.com/YusaeMeow/Collab-Overcooked</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç³»ç»Ÿåœ¨ä¼ ç»ŸNLPä»»åŠ¡ä¹‹å¤–çš„ç°å®ä¸–ç•Œåº”ç”¨ä¸­å–å¾—äº†å·¨å¤§è¿›æ­¥ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”±LLMé©±åŠ¨çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆLLM-MASï¼‰åŸºå‡†æµ‹è¯•ï¼Œåä¸ºCollab-Overcookedï¼Œå®ƒæ˜¯åœ¨æµè¡Œçš„Overcooked-AIæ¸¸æˆä¸Šæ„å»ºï¼Œæ‹¥æœ‰æ›´å¤šé€‚ç”¨äºäº¤äº’å¼ç¯å¢ƒä¸­çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚Collab-Overcookedä»ä¸¤ä¸ªæ–°é¢–çš„è§’åº¦æ‰©å±•äº†ç°æœ‰çš„åŸºå‡†æµ‹è¯•ã€‚é¦–å…ˆï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæ”¯æŒå¤šæ ·ä»»åŠ¡å’Œç›®æ ‡çš„å¤šä»£ç†æ¡†æ¶ï¼Œå¹¶é€šè¿‡è‡ªç„¶è¯­è¨€äº¤æµé¼“åŠ±åä½œã€‚å…¶æ¬¡ï¼Œå®ƒå¼•å…¥äº†ä¸€ç³»åˆ—é¢å‘è¿‡ç¨‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ¥è¯„ä¼°ä¸åŒLLMä»£ç†çš„ç²¾å¦™åä½œèƒ½åŠ›ï¼Œè¿™æ˜¯ä»¥å‰å·¥ä½œä¸­ç»å¸¸è¢«å¿½è§†çš„ä¸€ä¸ªç»´åº¦ã€‚æˆ‘ä»¬å¯¹10ä¸ªæµè¡Œçš„LLMè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMåœ¨ç›®æ ‡è§£é‡Šæ–¹é¢è¡¨ç°å‡ºå¾ˆå¼ºèƒ½åŠ›ï¼Œä½†åœ¨ä¸»åŠ¨åä½œå’ŒæŒç»­é€‚åº”æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¿™å¯¹äºæœ‰æ•ˆåœ°å®Œæˆå¤æ‚ä»»åŠ¡è‡³å…³é‡è¦ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çªå‡ºäº†LLM-MASçš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªç»Ÿä¸€å’Œå¼€æºçš„åŸºå‡†æµ‹è¯•æ¥æ”¹è¿›å’Œè¯„ä¼°LLM-MASã€‚ç¯å¢ƒã€30ä¸ªå¼€æ”¾ä»»åŠ¡å’Œä¸€ä¸ªé›†æˆè¯„ä¼°åŒ…ç°åœ¨å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/YusaeMeow/Collab-Overcooked%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/YusaeMeow/Collab-Overcookedå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20073v1">PDF</a> 25 pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œåº”ç”¨å’Œä¼ ç»ŸNLPä»»åŠ¡ä¹‹å¤–å–å¾—äº†å·¨å¤§è¿›æ­¥ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„LLMé©±åŠ¨çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆLLM-MASï¼‰åŸºå‡†æµ‹è¯•â€”â€”Collab-Overcookedï¼Œå®ƒæ˜¯åœ¨æµè¡Œçš„Overcooked-AIæ¸¸æˆä¸Šæ„å»ºçš„ï¼Œå…·æœ‰æ›´é€‚ç”¨å’Œæ›´å…·æŒ‘æˆ˜æ€§çš„äº¤äº’å¼ç¯å¢ƒä¸­çš„ä»»åŠ¡ã€‚Collab-Overcookedä»ä¸¤ä¸ªæ–°é¢–çš„è§’åº¦æ‰©å±•äº†ç°æœ‰çš„åŸºå‡†æµ‹è¯•ã€‚é¦–å…ˆï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæ”¯æŒå¤šæ ·ä»»åŠ¡å’Œç›®æ ‡çš„å¤šä»£ç†æ¡†æ¶ï¼Œå¹¶é€šè¿‡è‡ªç„¶è¯­è¨€äº¤æµé¼“åŠ±åä½œã€‚å…¶æ¬¡ï¼Œå®ƒå¼•å…¥äº†ä¸€ç³»åˆ—é¢å‘è¿‡ç¨‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°ä¸åŒLLMä»£ç†çš„ç²¾ç»†åä½œèƒ½åŠ›ï¼Œè¿™æ˜¯ä»¥å‰å·¥ä½œä¸­ç»å¸¸è¢«å¿½è§†çš„ä¸€ä¸ªç»´åº¦ã€‚æˆ‘ä»¬å¯¹10ä¸ªæµè¡Œçš„LLMè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMåœ¨ç›®æ ‡è§£è¯»æ–¹é¢è¡¨ç°å‡ºå¾ˆå¼ºèƒ½åŠ›ï¼Œä½†åœ¨ä¸»åŠ¨åä½œå’ŒæŒç»­é€‚åº”æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¿™å¯¹äºæœ‰æ•ˆå®Œæˆå¤æ‚ä»»åŠ¡è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¼ºè°ƒäº†LLM-MASçš„ä¼˜ç‚¹å’Œç¼ºç‚¹ï¼Œå¹¶ä¸ºåœ¨ç»Ÿä¸€å’Œå¼€æºåŸºå‡†ä¸Šæ”¹è¿›å’Œè¯„ä¼°LLM-MASæä¾›äº†è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„è¿›æ­¥æ˜¾è‘—ï¼Œå·²åº”ç”¨äºè¶…å‡ºä¼ ç»ŸNLPä»»åŠ¡çš„å¤šä»£ç†ç³»ç»Ÿã€‚</li>
<li>æ–°åŸºå‡†æµ‹è¯•Collab-OvercookedåŸºäºOvercooked-AIæ¸¸æˆæ„å»ºï¼Œé€‚ç”¨äºè¯„ä¼°å¤šä»£ç†ç³»ç»Ÿçš„æ€§èƒ½ã€‚</li>
<li>Collab-Overcookedæä¾›å¤šä»£ç†æ¡†æ¶ï¼Œæ”¯æŒå¤šæ ·ä»»åŠ¡å’Œç›®æ ‡çš„å¤„ç†ï¼Œå¹¶é¼“åŠ±é€šè¿‡è‡ªç„¶è¯­è¨€äº¤æµè¿›è¡Œåä½œã€‚</li>
<li>åŸºå‡†æµ‹è¯•å¼•å…¥äº†é¢å‘è¿‡ç¨‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°LLMä»£ç†çš„ç²¾ç»†åä½œèƒ½åŠ›ï¼Œè¿™æ˜¯ä»¥å‰è¢«å¿½è§†çš„é‡è¦æ–¹é¢ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºLLMåœ¨ç›®æ ‡è§£è¯»æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨ä¸»åŠ¨åä½œå’ŒæŒç»­é€‚åº”æ–¹é¢å­˜åœ¨å·®å¼‚ã€‚</li>
<li>å…¬å…±å¯ç”¨çš„ç¯å¢ƒå’Œä»»åŠ¡ä»¥åŠé›†æˆè¯„ä¼°åŒ…æœ‰åŠ©äºæ”¹è¿›å’Œè¯„ä¼°LLM-MASã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20073">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-621542d11f6c10b7e70154cbd5afbe0e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c8904c59f34ea4edeff782912cc87b66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9406eddc9f5cc58a79eeb183da96e31d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e914e7a11d3dd7f9c1af3286444408e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-79359379e6b30c152d23bf6152ac74d3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Generative-Model-Enhanced-Multi-Agent-Reinforcement-Learning-Method-for-Electric-Vehicle-Charging-Navigation"><a href="#A-Generative-Model-Enhanced-Multi-Agent-Reinforcement-Learning-Method-for-Electric-Vehicle-Charging-Navigation" class="headerlink" title="A Generative Model Enhanced Multi-Agent Reinforcement Learning Method   for Electric Vehicle Charging Navigation"></a>A Generative Model Enhanced Multi-Agent Reinforcement Learning Method   for Electric Vehicle Charging Navigation</h2><p><strong>Authors:Tianyang Qi, Shibo Chen, Jun Zhang</strong></p>
<p>With the widespread adoption of electric vehicles (EVs), navigating for EV drivers to select a cost-effective charging station has become an important yet challenging issue due to dynamic traffic conditions, fluctuating electricity prices, and potential competition from other EVs. The state-of-the-art deep reinforcement learning (DRL) algorithms for solving this task still require global information about all EVs at the execution stage, which not only increases communication costs but also raises privacy issues among EV drivers. To overcome these drawbacks, we introduce a novel generative model-enhanced multi-agent DRL algorithm that utilizes only the EVâ€™s local information while achieving performance comparable to these state-of-the-art algorithms. Specifically, the policy network is implemented on the EV side, and a Conditional Variational Autoencoder-Long Short Term Memory (CVAE-LSTM)-based recommendation model is developed to provide recommendation information. Furthermore, a novel future charging competition encoder is designed to effectively compress global information, enhancing training performance. The multi-gradient descent algorithm (MGDA) is also utilized to adaptively balance the weight between the two parts of the training objective, resulting in a more stable training process. Simulations are conducted based on a practical area in Xi&#39;an, China. Experimental results show that our proposed algorithm, which relies on local information, outperforms existing local information-based methods and achieves less than 8% performance loss compared to global information-based methods. </p>
<blockquote>
<p>éšç€ç”µåŠ¨æ±½è½¦ï¼ˆEVï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œå¯¹äºç”µåŠ¨æ±½è½¦é©¾é©¶å‘˜æ¥è¯´ï¼Œé€‰æ‹©æ€§ä»·æ¯”é«˜çš„å……ç”µç«™å¯¼èˆªæˆä¸ºä¸€ä¸ªé‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºåŠ¨æ€çš„äº¤é€šçŠ¶å†µã€æ³¢åŠ¨çš„ç”µä»·ä»¥åŠæ¥è‡ªå…¶ä»–ç”µåŠ¨æ±½è½¦çš„æ½œåœ¨ç«äº‰ã€‚æœ€å…ˆè¿›çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç®—æ³•åœ¨è§£å†³æ­¤ä»»åŠ¡æ—¶ä»éœ€è¦åœ¨æ‰§è¡Œé˜¶æ®µè·å–æ‰€æœ‰ç”µåŠ¨æ±½è½¦çš„å…¨å±€ä¿¡æ¯ï¼Œè¿™ä¸ä»…å¢åŠ äº†é€šä¿¡æˆæœ¬ï¼Œè€Œä¸”å¼•å‘äº†ç”µåŠ¨æ±½è½¦é©¾é©¶å‘˜ä¹‹é—´çš„éšç§é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™äº›ç¼ºç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹ç”Ÿæˆæ¨¡å‹å¢å¼ºçš„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•ä»…åˆ©ç”¨ç”µåŠ¨æ±½è½¦çš„æœ¬åœ°ä¿¡æ¯ï¼ŒåŒæ—¶å®ç°äº†ä¸è¿™äº›æœ€å…ˆè¿›çš„ç®—æ³•ç›¸å½“çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œç­–ç•¥ç½‘ç»œåœ¨ç”µåŠ¨æ±½è½¦ç«¯å®ç°ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåŸºäºæ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨-é•¿çŸ­æ—¶è®°å¿†ï¼ˆCVAE-LSTMï¼‰çš„æ¨èæ¨¡å‹ï¼Œä»¥æä¾›æ¨èä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€ç§æ–°å‹çš„æœªæ¥å……ç”µç«äº‰ç¼–ç å™¨ï¼Œæœ‰æ•ˆåœ°å‹ç¼©å…¨å±€ä¿¡æ¯ï¼Œæé«˜è®­ç»ƒæ€§èƒ½ã€‚è¿˜åˆ©ç”¨å¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰è‡ªé€‚åº”åœ°å¹³è¡¡è®­ç»ƒç›®æ ‡ä¸­ä¸¤éƒ¨åˆ†çš„æƒé‡ï¼Œä»è€Œå®ç°æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹ã€‚æ¨¡æ‹Ÿå®éªŒåŸºäºä¸­å›½è¥¿å®‰çš„å®é™…åŒºåŸŸè¿›è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ä¾èµ–æœ¬åœ°ä¿¡æ¯çš„ç®—æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„åŸºäºæœ¬åœ°ä¿¡æ¯çš„æ–¹æ³•ï¼Œä¸åŸºäºå…¨å±€ä¿¡æ¯çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½æŸå¤±ä½äº8%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20068v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>éšç€ç”µåŠ¨æ±½è½¦ï¼ˆEVï¼‰çš„å¹¿æ³›åº”ç”¨ï¼ŒEVå¸æœºé€‰æ‹©ç»æµé«˜æ•ˆçš„å……ç”µç«™å˜å¾—è‡³å…³é‡è¦ï¼Œä½†åŒæ—¶ä¹Ÿé¢ä¸´åŠ¨æ€äº¤é€šæ¡ä»¶ã€ç”µä»·æ³¢åŠ¨å’Œå…¶ä»–EVçš„ç«äº‰ç­‰æŒ‘æˆ˜ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œç°æœ‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç®—æ³•åœ¨æ‰§è¡Œé˜¶æ®µéœ€è¦å…³äºæ‰€æœ‰EVçš„å…¨å±€ä¿¡æ¯ï¼Œè¿™ä¸ä»…å¢åŠ äº†é€šä¿¡æˆæœ¬ï¼Œè¿˜å¼•å‘äº†EVå¸æœºä¹‹é—´çš„éšç§é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™äº›ç¼ºç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹ç”Ÿæˆæ¨¡å‹å¢å¼ºçš„å¤šæ™ºèƒ½ä½“DRLç®—æ³•ï¼Œè¯¥ç®—æ³•ä»…åˆ©ç”¨EVçš„æœ¬åœ°ä¿¡æ¯ï¼ŒåŒæ—¶å®ç°äº†ä¸è¿™äº›æœ€å…ˆè¿›çš„ç®—æ³•ç›¸å½“çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œç­–ç•¥ç½‘ç»œåœ¨EVç«¯å®ç°ï¼Œå¹¶å¼€å‘äº†ä¸€ç§åŸºäºæ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨-é•¿çŸ­æœŸè®°å¿†ï¼ˆCVAE-LSTMï¼‰çš„æ¨èæ¨¡å‹ï¼Œä»¥æä¾›æ¨èä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€ç§æ–°å‹çš„æœªæ¥å……ç”µç«äº‰ç¼–ç å™¨ï¼Œæœ‰æ•ˆåœ°å‹ç¼©å…¨å±€ä¿¡æ¯ï¼Œæé«˜è®­ç»ƒæ€§èƒ½ã€‚è¿˜åˆ©ç”¨å¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰è‡ªé€‚åº”åœ°å¹³è¡¡è®­ç»ƒç›®æ ‡ä¸­ä¸¤éƒ¨åˆ†ä¹‹é—´çš„æƒé‡ï¼Œä½¿è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šã€‚åœ¨ä¸­å›½è¥¿å®‰çš„å®é™…åŒºåŸŸè¿›è¡Œäº†æ¨¡æ‹Ÿå®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æ‰€æå‡ºçš„ä¾èµ–æœ¬åœ°ä¿¡æ¯çš„ç®—æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„åŸºäºæœ¬åœ°ä¿¡æ¯çš„æ–¹æ³•ï¼Œä¸åŸºäºå…¨å±€ä¿¡æ¯çš„æ–¹æ³•ç›¸æ¯”æ€§èƒ½æŸå¤±ä¸åˆ°8%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¹¿æ³›é‡‡ç”¨ç”µåŠ¨æ±½è½¦ï¼ˆEVï¼‰å¯¼è‡´é€‰æ‹©æˆæœ¬æ•ˆç›Šé«˜çš„å……ç”µç«™å˜å¾—é‡è¦ä¸”å…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°æœ‰æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç®—æ³•éœ€è¦æ‰€æœ‰EVçš„å…¨å±€ä¿¡æ¯ï¼Œå¢åŠ äº†é€šä¿¡æˆæœ¬å’Œéšç§é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹ç”Ÿæˆæ¨¡å‹å¢å¼ºçš„å¤šæ™ºèƒ½ä½“DRLç®—æ³•ï¼Œä»…åˆ©ç”¨EVçš„æœ¬åœ°ä¿¡æ¯ã€‚</li>
<li>ç­–ç•¥ç½‘ç»œåœ¨EVç«¯å®ç°ï¼Œé‡‡ç”¨CVAE-LSTMæ¨èæ¨¡å‹æä¾›æ¨èä¿¡æ¯ã€‚</li>
<li>è®¾è®¡äº†æœªæ¥å……ç”µç«äº‰ç¼–ç å™¨ä»¥å‹ç¼©å…¨å±€ä¿¡æ¯å¹¶æé«˜è®­ç»ƒæ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨å¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰è‡ªé€‚åº”å¹³è¡¡è®­ç»ƒç›®æ ‡ä¸­çš„ä¸åŒéƒ¨åˆ†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20068">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61696841d49ea69a977ba5eabbc4f516.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8283eb161f43866b82bc8a6f361fe69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed3f2dde387774d6acf1bfd697faa09d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a43868f78e48903b6c16153fe506b12f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c7a659e3d9f187fe031aa8963019507.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a07fcc4720143ec8140ace542ccb47f4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Picking-the-Cream-of-the-Crop-Visual-Centric-Data-Selection-with-Collaborative-Agents"><a href="#Picking-the-Cream-of-the-Crop-Visual-Centric-Data-Selection-with-Collaborative-Agents" class="headerlink" title="Picking the Cream of the Crop: Visual-Centric Data Selection with   Collaborative Agents"></a>Picking the Cream of the Crop: Visual-Centric Data Selection with   Collaborative Agents</h2><p><strong>Authors:Zhenyu Liu, Yunxin Li, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang</strong></p>
<p>To improve Multimodal Large Language Modelsâ€™ (MLLMs) ability to process images and complex instructions, researchers predominantly curate large-scale visual instruction tuning datasets, which are either sourced from existing vision tasks or synthetically generated using LLMs and image descriptions. However, they often suffer from critical flaws, including misaligned instruction-image pairs and low-quality images. Such issues hinder training efficiency and limit performance improvements, as models waste resources on noisy or irrelevant data with minimal benefit to overall capability. To address this issue, we propose a \textbf{Vi}sual-Centric \textbf{S}election approach via \textbf{A}gents Collaboration (ViSA), which centers on image quality assessment and image-instruction relevance evaluation. Specifically, our approach consists of 1) an image information quantification method via visual agents collaboration to select images with rich visual information, and 2) a visual-centric instruction quality assessment method to select high-quality instruction data related to high-quality images. Finally, we reorganize 80K instruction data from large open-source datasets. Extensive experiments demonstrate that ViSA outperforms or is comparable to current state-of-the-art models on seven benchmarks, using only 2.5% of the original data, highlighting the efficiency of our data selection approach. Moreover, we conduct ablation studies to validate the effectiveness of each component of our method. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/ViSA">https://github.com/HITsz-TMG/ViSA</a>. </p>
<blockquote>
<p>ä¸ºæé«˜å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¤„ç†å›¾åƒå’Œå¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œç ”ç©¶è€…ä¸»è¦åˆ›å»ºå¤§è§„æ¨¡è§†è§‰æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œè¿™äº›æ•°æ®é›†æ¥æºäºç°æœ‰çš„è§†è§‰ä»»åŠ¡æˆ–ä½¿ç”¨LLMså’Œå›¾åƒæè¿°äººå·¥åˆæˆã€‚ç„¶è€Œï¼Œå®ƒä»¬ç»å¸¸å­˜åœ¨å…³é”®ç¼ºé™·ï¼ŒåŒ…æ‹¬æŒ‡ä»¤ä¸å›¾åƒä¸åŒ¹é…å’Œä½è´¨é‡å›¾åƒã€‚è¿™äº›é—®é¢˜é˜»ç¢äº†è®­ç»ƒæ•ˆç‡ï¼Œé™åˆ¶äº†æ€§èƒ½æå‡ï¼Œå› ä¸ºæ¨¡å‹ä¼šåœ¨å˜ˆæ‚æˆ–æ— å…³çš„æ•°æ®ä¸Šæµªè´¹èµ„æºï¼Œå¯¹æ•´ä½“èƒ½åŠ›ç›Šå¤„ç”šå¾®ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„é€šè¿‡ä»£ç†åä½œçš„è§†è§‰ä¸­å¿ƒé€‰æ‹©æ–¹æ³•ï¼ˆViSAï¼‰ï¼Œè¯¥æ–¹æ³•ä¾§é‡äºå›¾åƒè´¨é‡è¯„ä¼°å’Œå›¾åƒæŒ‡ä»¤ç›¸å…³æ€§è¯„ä¼°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ï¼š1ï¼‰ä¸€ç§é€šè¿‡è§†è§‰ä»£ç†åä½œçš„å›¾åƒä¿¡æ¯é‡åŒ–æ–¹æ³•ï¼Œç”¨äºé€‰æ‹©è§†è§‰ä¿¡æ¯ä¸°å¯Œçš„å›¾åƒï¼›ä»¥åŠ2ï¼‰ä¸€ç§ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„æŒ‡ä»¤è´¨é‡è¯„ä¼°æ–¹æ³•ï¼Œç”¨äºé€‰æ‹©ä¸é«˜è´¨é‡å›¾åƒç›¸å…³çš„ä¼˜è´¨æŒ‡ä»¤æ•°æ®ã€‚æœ€åï¼Œæˆ‘ä»¬ä»å¤§å‹å¼€æºæ•°æ®é›†ä¸­é‡æ–°æ•´ç†äº†8ä¸‡æ¡æŒ‡ä»¤æ•°æ®ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒViSAåœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºæˆ–ç›¸å½“äºå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œä»…ä½¿ç”¨åŸå§‹æ•°æ®çš„2.5%ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬æ•°æ®é€‰æ‹©æ–¹æ³•çš„é«˜æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å‰¥ç¦»ç ”ç©¶ä»¥éªŒè¯æˆ‘ä»¬æ–¹æ³•çš„æ¯ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/ViSA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HITsz-TMG/ViSAæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19917v1">PDF</a> 15 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§è§†è§‰ä¸ºä¸­å¿ƒçš„é€‰æ‹©æ–¹æ³•â€”â€”ViSAï¼Œé€šè¿‡è§†è§‰ä»£ç†åä½œè¿›è¡Œå›¾åƒä¿¡æ¯é‡åŒ–ï¼Œé€‰æ‹©å…·æœ‰ä¸°å¯Œè§†è§‰ä¿¡æ¯çš„å›¾åƒï¼Œå¹¶é€šè¿‡è§†è§‰ä¸ºä¸­å¿ƒçš„æ•™å­¦æŒ‡ä»¤è´¨é‡è¯„ä¼°æ–¹æ³•é€‰æ‹©ä¸é«˜è´¨å›¾åƒç›¸å…³çš„ä¼˜è´¨æ•™å­¦æ•°æ®ã€‚é€šè¿‡å¤§è§„æ¨¡å®éªŒéªŒè¯ï¼ŒViSAæ–¹æ³•åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å›¾åƒå¤„ç†å’Œå¤æ‚æŒ‡ä»¤å¤„ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸”ä»…ä½¿ç”¨åŸå§‹æ•°æ®çš„2.5%ï¼Œå±•ç°äº†é«˜æ•ˆçš„æ•°æ®é€‰æ‹©èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå…¬å¼€äº†ä»£ç å®ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶è€…ä¸»è¦é€šè¿‡æ„å»ºå¤§è§„æ¨¡è§†è§‰æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ¥æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†å›¾åƒå’Œå¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ•°æ®é›†å­˜åœ¨è¯¸å¤šé—®é¢˜ï¼Œå¦‚æŒ‡ä»¤ä¸å›¾åƒä¸åŒ¹é…ã€å›¾åƒè´¨é‡ä½ä¸‹ç­‰ï¼Œå½±å“æ¨¡å‹è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
<li>æå‡ºViSAæ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒä¿¡æ¯é‡åŒ–åŠè§†è§‰ä¸ºä¸­å¿ƒçš„æ•™å­¦æŒ‡ä»¤è´¨é‡è¯„ä¼°ã€‚</li>
<li>ViSAæ–¹æ³•é€šè¿‡é€‰æ‹©ä¸°å¯Œè§†è§‰ä¿¡æ¯çš„å›¾åƒå’Œé«˜è´¨æ•™å­¦æ•°æ®ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>å®éªŒè¯æ˜ViSAæ–¹æ³•åœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸”ä½¿ç”¨æ•°æ®ä»…ä¸ºåŸæ•°æ®çš„2.5%ã€‚</li>
<li>å…¬å¼€ä»£ç å®ç°ï¼Œä¾¿äºä»–äººä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19917">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0d286ed633556cfc60487a3cd056756d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-73b50fa3e3cb47afe140847ebcf87d36.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9455b97a19ca6841de3abd56d68ae172.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c53a62069c782517f743efa6d7f6e3ec.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Optimus-2-Multimodal-Minecraft-Agent-with-Goal-Observation-Action-Conditioned-Policy"><a href="#Optimus-2-Multimodal-Minecraft-Agent-with-Goal-Observation-Action-Conditioned-Policy" class="headerlink" title="Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action   Conditioned Policy"></a>Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action   Conditioned Policy</h2><p><strong>Authors:Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie</strong></p>
<p>Building an agent that can mimic human behavior patterns to accomplish various open-world tasks is a long-term goal. To enable agents to effectively learn behavioral patterns across diverse tasks, a key challenge lies in modeling the intricate relationships among observations, actions, and language. To this end, we propose Optimus-2, a novel Minecraft agent that incorporates a Multimodal Large Language Model (MLLM) for high-level planning, alongside a Goal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP contains (1) an Action-guided Behavior Encoder that models causal relationships between observations and actions at each timestep, then dynamically interacts with the historical observation-action sequence, consolidating it into fixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with open-ended language instructions to predict actions auto-regressively. Moreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)} dataset, which contains 25,000 videos across 8 atomic tasks, providing about 30M goal-observation-action pairs. The automated construction method, along with the MGOA dataset, can contribute to the communityâ€™s efforts to train Minecraft agents. Extensive experimental results demonstrate that Optimus-2 exhibits superior performance across atomic tasks, long-horizon tasks, and open-ended instruction tasks in Minecraft. </p>
<blockquote>
<p>æ„å»ºèƒ½å¤Ÿæ¨¡ä»¿äººç±»è¡Œä¸ºæ¨¡å¼ä»¥å®Œæˆå„ç§å¼€æ”¾ä¸–ç•Œä»»åŠ¡çš„æ™ºèƒ½ä½“æ˜¯ä¸€é¡¹é•¿æœŸç›®æ ‡ã€‚ä¸ºäº†ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å„ç§ä»»åŠ¡ä¸­æœ‰æ•ˆåœ°å­¦ä¹ è¡Œä¸ºæ¨¡å¼ï¼Œå…³é”®æŒ‘æˆ˜åœ¨äºå¯¹è§‚å¯Ÿã€è¡ŒåŠ¨å’Œè¯­è¨€ä¹‹é—´å¤æ‚å…³ç³»çš„å»ºæ¨¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Optimus-2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹Minecraftæ™ºèƒ½ä½“ï¼Œå®ƒç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¿›è¡Œé«˜çº§è§„åˆ’ï¼Œä»¥åŠä»¥ç›®æ ‡-è§‚å¯Ÿ-è¡ŒåŠ¨æ¡ä»¶ç­–ç•¥ï¼ˆGOAPï¼‰è¿›è¡Œä½çº§æ§åˆ¶ã€‚GOAPåŒ…å«ï¼ˆ1ï¼‰è¡ŒåŠ¨å¯¼å‘è¡Œä¸ºç¼–ç å™¨ï¼Œè¯¥ç¼–ç å™¨ä¼šå»ºæ¨¡è§‚å¯Ÿä¸è¡ŒåŠ¨ä¹‹é—´çš„å› æœå…³ç³»ï¼Œå¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸­ä¸å†å²è§‚å¯Ÿ-è¡ŒåŠ¨åºåˆ—åŠ¨æ€äº’åŠ¨ï¼Œå°†å…¶æ•´åˆä¸ºå›ºå®šé•¿åº¦çš„è¡Œä¸ºä»¤ç‰Œï¼›ï¼ˆ2ï¼‰MLLMåˆ™å°†è¿™äº›è¡Œä¸ºä»¤ç‰Œä¸å¼€æ”¾çš„è¯­è¨€æŒ‡ä»¤å¯¹é½ï¼Œä»¥è¿›è¡Œè‡ªå›å½’è¡ŒåŠ¨é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†é«˜è´¨é‡çš„Minecraftç›®æ ‡-è§‚å¯Ÿ-è¡ŒåŠ¨ï¼ˆMGOAï¼‰æ•°æ®é›†ï¼ŒåŒ…å«8ä¸ªåŸå­ä»»åŠ¡çš„2.5ä¸‡æ®µè§†é¢‘ï¼Œæä¾›çº¦3000ä¸‡çš„ç›®æ ‡-è§‚å¯Ÿ-è¡ŒåŠ¨å¯¹ã€‚è‡ªåŠ¨åŒ–æ„å»ºæ–¹æ³•å’ŒMGOAæ•°æ®é›†èƒ½ä¸ºç¤¾åŒºè®­ç»ƒMinecraftæ™ºèƒ½ä½“çš„åŠªåŠ›åšå‡ºè´¡çŒ®ã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒOptimus-2åœ¨åŸå­ä»»åŠ¡ã€é•¿æœŸä»»åŠ¡å’Œå¼€æ”¾æŒ‡ä»¤ä»»åŠ¡ä¸­ï¼Œåœ¨Minecraftä¸­çš„è¡¨ç°å‡è¶…ç¾¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19902v1">PDF</a> Accept to CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹Minecraftæ™ºèƒ½ä½“Optimus-2çš„æ„å»ºè¿‡ç¨‹ã€‚Optimus-2ç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¿›è¡Œé«˜çº§è§„åˆ’ï¼Œå¹¶é‡‡ç”¨ç›®æ ‡-è§‚å¯Ÿ-åŠ¨ä½œæ¡ä»¶ç­–ç•¥ï¼ˆGOAPï¼‰è¿›è¡Œä½çº§æ§åˆ¶ã€‚å…¶æ ¸å¿ƒç‰¹ç‚¹æ˜¯è¡ŒåŠ¨å¯¼å‘è¡Œä¸ºç¼–ç å™¨ï¼Œå®ƒèƒ½å»ºæ¨¡è§‚å¯Ÿä¸è¡ŒåŠ¨ä¹‹é—´çš„å› æœå…³ç³»ï¼Œå¹¶åŠ¨æ€åœ°å°†å…¶æ•´åˆä¸ºå›ºå®šé•¿åº¦çš„è¡Œä¸ºæ ‡è®°ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†é«˜è´¨é‡çš„Minecraftç›®æ ‡è§‚å¯ŸåŠ¨ä½œï¼ˆMGOAï¼‰æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§åŸå­ä»»åŠ¡çš„å¤§é‡æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOptimus-2åœ¨Minecraftä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§æ–°çš„Minecraftæ™ºèƒ½ä½“Optimus-2çš„æ„å»ºã€‚</li>
<li>Optimus-2ç»“åˆäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ç”¨äºé«˜çº§è§„åˆ’ã€‚</li>
<li>é‡‡ç”¨ç›®æ ‡-è§‚å¯Ÿ-åŠ¨ä½œæ¡ä»¶ç­–ç•¥ï¼ˆGOAPï¼‰è¿›è¡Œä½çº§æ§åˆ¶ã€‚</li>
<li>æ ¸å¿ƒç‰¹ç‚¹æ˜¯è¡ŒåŠ¨å¯¼å‘è¡Œä¸ºç¼–ç å™¨ï¼Œå¯ä»¥å»ºæ¨¡è§‚å¯Ÿä¸è¡ŒåŠ¨ä¹‹é—´çš„å› æœå…³ç³»ã€‚</li>
<li>å¼•å…¥äº†é«˜è´¨é‡çš„Minecraftç›®æ ‡è§‚å¯ŸåŠ¨ä½œï¼ˆMGOAï¼‰æ•°æ®é›†ã€‚</li>
<li>Optimus-2èƒ½å¤„ç†å¤šç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬åŸå­ä»»åŠ¡ã€é•¿æœŸä»»åŠ¡å’Œå¼€æ”¾å¼æŒ‡ä»¤ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19902">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-104d203adb08ea881a692ede7a963b19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08e81f89fe3075cc1bbcfd63d09e4444.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ec94263bdaa797765b1a36e9c350cb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbf6d4920c5eb4b0cf4b851b667fb257.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de0358e15c3de6457bf94f975d3668c2.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Exponential-Topology-enabled-Scalable-Communication-in-Multi-agent-Reinforcement-Learning"><a href="#Exponential-Topology-enabled-Scalable-Communication-in-Multi-agent-Reinforcement-Learning" class="headerlink" title="Exponential Topology-enabled Scalable Communication in Multi-agent   Reinforcement Learning"></a>Exponential Topology-enabled Scalable Communication in Multi-agent   Reinforcement Learning</h2><p><strong>Authors:Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang</strong></p>
<p>In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links-a task that becomes increasingly complex as the number of agents grows-we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/LXXXXR/ExpoComm">https://github.com/LXXXXR/ExpoComm</a>. </p>
<blockquote>
<p>åœ¨åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œè®¾è®¡è‰¯å¥½çš„é€šä¿¡åè®®å¯ä»¥æœ‰æ•ˆåœ°ä¿ƒè¿›æ™ºèƒ½ä½“ä¹‹é—´çš„å…±è¯†ï¼Œä»è€Œæé«˜ä»»åŠ¡æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­å¸¸è§çš„å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œç”±äºä¸å°è§„æ¨¡è®¾ç½®ç›¸æ¯”å±€éƒ¨å¯è§‚å¯Ÿæ€§çš„æŒ‘æˆ˜åŠ å‰§ï¼Œæœ‰æ•ˆçš„é€šä¿¡å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åŠªåŠ›ä¸ºMARLå¼€å‘å¯æ‰©å±•çš„é€šä¿¡åè®®ã€‚ä¸åŒäºä»¥å‰çš„æ–¹æ³•ï¼Œä¾§é‡äºé€‰æ‹©æœ€ä¼˜çš„é…å¯¹é€šä¿¡é“¾æ¥â€”â€”éšç€æ™ºèƒ½ä½“æ•°é‡çš„å¢é•¿ï¼Œè¿™é¡¹ä»»åŠ¡å˜å¾—è¶Šæ¥è¶Šå¤æ‚â€”â€”æˆ‘ä»¬å¯¹é€šä¿¡æ‹“æ‰‘è®¾è®¡é‡‡ç”¨å…¨å±€è§†è§’ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨æŒ‡æ•°æ‹“æ‰‘ï¼Œé€šè¿‡åˆ©ç”¨å…¶å°ç›´å¾„å’Œå°è§„æ¨¡å±æ€§ï¼Œå®ç°åœ¨æ™ºèƒ½ä½“ä¹‹é—´çš„å¿«é€Ÿä¿¡æ¯ä¼ æ’­ã€‚è¿™ç§æ–¹æ³•å¯¼è‡´äº†ä¸€ä¸ªå¯æ‰©å±•çš„é€šä¿¡åè®®ï¼Œç§°ä¸ºExpoCommã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨æŒ‡æ•°å›¾ä½œä¸ºé€šä¿¡æ‹“æ‰‘çš„æ½œåŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºå†…å­˜çš„æ¶ˆæ¯å¤„ç†å™¨å’Œè¾…åŠ©ä»»åŠ¡æ¥ç¡®ä¿æ¶ˆæ¯åæ˜ å…¨å±€ä¿¡æ¯å¹¶æœ‰ç›Šäºå†³ç­–ã€‚åœ¨åŒ…æ‹¬MAgentå’ŒåŸºç¡€è®¾æ–½ç®¡ç†è§„åˆ’ç­‰å¤§å‹åˆä½œåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰é€šä¿¡ç­–ç•¥ç›¸æ¯”ï¼ŒExpoCommå…·æœ‰å“è¶Šçš„æ€§èƒ½å’Œç¨³å¥çš„é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›ã€‚ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/LXXXXR/ExpoComm">https://github.com/LXXXXR/ExpoComm</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19717v1">PDF</a> Accepted by the Thirteenth International Conference on Learning   Representations (ICLR 2025)</p>
<p><strong>Summary</strong></p>
<p>åœ¨åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œè®¾è®¡è‰¯å¥½çš„é€šä¿¡åè®®èƒ½æœ‰æ•ˆä¿ƒè¿›æ™ºèƒ½ä½“é—´çš„å…±è¯†ï¼Œä»è€Œæå‡ä»»åŠ¡æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨å¸¸è§çš„å¤§å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œç”±äºéƒ¨åˆ†è§‚å¯Ÿæ€§çš„æŒ‘æˆ˜åŠ å‰§ï¼Œæœ‰æ•ˆçš„é€šä¿¡æ‰®æ¼”ç€æ›´ä¸ºå…³é”®çš„è§’è‰²ã€‚æœ¬ç ”ç©¶è‡´åŠ›äºå¼€å‘ä¸€ç§é€‚ç”¨äºMARLçš„å¯æ‰©å±•é€šä¿¡åè®®ã€‚ä¸åŒäºä»¥å¾€å…³æ³¨é€‰æ‹©æœ€ä¼˜é…å¯¹é€šä¿¡é“¾æ¥çš„æ–¹æ³•ï¼ˆéšç€æ™ºèƒ½ä½“æ•°é‡çš„å¢é•¿ï¼Œè¯¥ä»»åŠ¡å˜å¾—æ—¥ç›Šå¤æ‚ï¼‰ï¼Œæˆ‘ä»¬é‡‡ç”¨å…¨å±€è§†è§’è®¾è®¡é€šä¿¡æ‹“æ‰‘ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬æè®®åˆ©ç”¨æŒ‡æ•°æ‹“æ‰‘ï¼Œé€šè¿‡å…¶å°ç›´å¾„å’Œå°å°ºå¯¸å±æ€§å®ç°æ™ºèƒ½ä½“é—´çš„å¿«é€Ÿä¿¡æ¯ä¼ æ’­ã€‚è¿™ç§æ–¹æ³•ä¿ƒæˆäº†ä¸€ç§å¯æ‰©å±•çš„é€šä¿¡åè®®â€”â€”ExpoCommã€‚ä¸ºå……åˆ†å‘æŒ¥æŒ‡æ•°å›¾ä½œä¸ºé€šä¿¡æ‹“æ‰‘çš„æ½œåŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºå†…å­˜çš„æ¶ˆæ¯å¤„ç†å™¨å’Œè¾…åŠ©ä»»åŠ¡æ¥éªŒè¯ä¿¡æ¯ï¼Œç¡®ä¿ä¿¡æ¯åæ˜ å…¨å±€ä¿¡æ¯å¹¶æœ‰ç›Šäºå†³ç­–ã€‚åœ¨å¤§å‹åˆä½œåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒï¼ŒåŒ…æ‹¬MAgentå’ŒåŸºç¡€è®¾æ–½ç®¡ç†è§„åˆ’ï¼Œè¯æ˜äº†ExpoCommç›¸è¾ƒäºç°æœ‰é€šä¿¡ç­–ç•¥çš„ä¼˜åŠ¿ï¼Œå…¶å…·å¤‡å“è¶Šçš„æ€§èƒ½å’Œç¨³å¥çš„é›¶å°„å‡»è½¬ç§»æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œé€šä¿¡åè®®è®¾è®¡å¯¹äºä¿ƒè¿›æ™ºèƒ½ä½“é—´å…±è¯†è‡³å…³é‡è¦ã€‚</li>
<li>åœ¨å¤§å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œæœ‰æ•ˆé€šä¿¡å¯¹äºå…‹æœéƒ¨åˆ†è§‚å¯Ÿæ€§çš„æŒ‘æˆ˜è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ç§æ–°çš„å¯æ‰©å±•é€šä¿¡åè®®ExpoCommï¼Œé‡‡ç”¨å…¨å±€è§†è§’è®¾è®¡é€šä¿¡æ‹“æ‰‘ã€‚</li>
<li>ExpoCommåˆ©ç”¨æŒ‡æ•°æ‹“æ‰‘å®ç°æ™ºèƒ½ä½“é—´çš„å¿«é€Ÿä¿¡æ¯ä¼ æ’­ã€‚</li>
<li>ä¸ºå……åˆ†å‘æŒ¥æŒ‡æ•°å›¾ä½œä¸ºé€šä¿¡æ‹“æ‰‘çš„æ½œåŠ›ï¼Œç»“åˆäº†åŸºäºå†…å­˜çš„æ¶ˆæ¯å¤„ç†å™¨å’Œè¾…åŠ©ä»»åŠ¡ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼ŒExpoCommè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œç¨³å¥çš„é›¶å°„å‡»è½¬ç§»æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19717">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-179bb9a5a2941b8393b8398801eafabd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8bee7dcb0c527082e64363127783b43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86ff4b8a81717da73f5e05d6a58b2803.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91e2e3d1c0aae3eceee998e4e6f0f8a9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making"><a href="#Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making" class="headerlink" title="Program Synthesis Dialog Agents for Interactive Decision-Making"></a>Program Synthesis Dialog Agents for Interactive Decision-Making</h2><p><strong>Authors:Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu</strong></p>
<p>Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œä¸­çš„è®¸å¤šèµ„æ ¼é—®é¢˜ï¼Œä»åŒ»å­¦è¯Šæ–­åˆ°ç¨åŠ¡è§„åˆ’ï¼Œéƒ½å¯ä»¥æ˜ å°„åˆ°ä»¥è‡ªç„¶è¯­è¨€è¡¨è¾¾å‡ºçš„å†³ç­–é—®é¢˜ï¼Œå…¶ä¸­æ¨¡å‹å¿…é¡»åŸºäºç”¨æˆ·ç‰¹å¾è¿›è¡ŒäºŒå…ƒé€‰æ‹©ã€‚å¤§è§„æ¨¡é¢†åŸŸï¼ˆå¦‚æ³•å¾‹ä»£ç æˆ–ç»å¸¸æ›´æ–°çš„èµ„åŠ©æœºä¼šï¼‰ä½¿å¾—äººå·¥æ ‡æ³¨ï¼ˆä¾‹å¦‚ç½‘é¡µè¡¨å•æˆ–å†³ç­–æ ‘ï¼‰å˜å¾—ä¸åˆ‡å®é™…ï¼Œè¿™çªæ˜¾äº†éœ€è¦èƒ½å¤Ÿè‡ªåŠ¨ååŠ©å†³ç­–çš„æ™ºèƒ½ä½“çš„å¿…è¦æ€§ã€‚ç”±äºç›¸å…³ä¿¡æ¯é€šå¸¸åªä¸ºç”¨æˆ·æ‰€çŸ¥ï¼Œå› æ­¤è¿™äº›æ™ºèƒ½ä½“æå‡ºæ­£ç¡®çš„é—®é¢˜è‡³å…³é‡è¦ã€‚æ™ºèƒ½ä½“åœ¨å†³å®šä½•æ—¶ç»“æŸå¯¹è¯æ—¶é¢ä¸´ç€å‡†ç¡®æ€§ä¸æ‰€æé—®é¢˜æ•°é‡ä¹‹é—´çš„æƒè¡¡ï¼Œè¿™æ˜¯ç”¨æˆ·ä½“éªŒå’Œæˆæœ¬çš„å…³é”®æŒ‡æ ‡ã€‚ä¸ºäº†è¯„ä¼°è¿™ä¸€ä»»åŠ¡ï¼Œæˆ‘ä»¬æå‡ºäº†BeNYfitsï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºé€šè¿‡äº¤äº’å¼å†³ç­–æ¥ç¡®å®šç”¨æˆ·å¯¹äºå¤šä¸ªé‡å çš„ç¤¾ä¼šç¦åˆ©æœºä¼šçš„èµ„æ ¼ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå½“å‰çš„è¯­è¨€æ¨¡å‹ç»å¸¸äº§ç”Ÿå¹»è§‰ï¼ŒGPT-4oåœ¨ReActé£æ ¼çš„æ€ç»´é“¾ä¸­çš„F1å¾—åˆ†ä»…ä¸º35.7ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ProADAè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡åˆ©ç”¨ç¨‹åºåˆæˆæ¥ååŠ©å†³ç­–ï¼Œé€šè¿‡å°†å¯¹è¯è§„åˆ’æ˜ å°„åˆ°ä»£ç ç”Ÿæˆé—®é¢˜å¹¶ä½¿ç”¨ç»“æ„åŒ–æ•°æ®ä¸­çš„ç©ºç™½æ¥ç¡®å®šæœ€ä½³ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚æˆ‘ä»¬çš„æ™ºèƒ½ä½“ProADAå°†F1åˆ†æ•°æé«˜åˆ°55.6ï¼ŒåŒæ—¶å‡ ä¹ä¿æŒäº†ç›¸åŒçš„å¯¹è¯è½®æ¬¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19610v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç°å®ä¸–ç•Œä¸­ä»åŒ»ç–—è¯Šæ–­åˆ°ç¨åŠ¡è§„åˆ’ç­‰å¤šå…ƒåŒ–çš„èµ„æ ¼è®¤å®šé—®é¢˜ï¼Œå¯è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€è¡¨è¾¾çš„å†³ç­–é—®é¢˜ã€‚ç”±äºå¤§è§„æ¨¡é¢†åŸŸå¦‚æ³•å¾‹æ¡æ–‡æˆ–é¢‘ç¹æ›´æ–°çš„èµ„åŠ©æœºä¼šä½¿å¾—äººå·¥æ ‡æ³¨ä¸å®é™…ï¼Œå› æ­¤éœ€è¦èƒ½å¤Ÿè‡ªåŠ¨ååŠ©å†³ç­–çš„æ™ºèƒ½ä»£ç†ã€‚è¿™äº›æ™ºèƒ½ä»£ç†éœ€èƒ½å¤Ÿå‘ç”¨æˆ·æé—®ä»¥è·å–å…³é”®ä¿¡æ¯ï¼Œå¹¶åœ¨å†³å®šä½•æ—¶ç»“æŸå¯¹è¯æ—¶é¢ä¸´å‡†ç¡®æ€§æé—®æ•°é‡ä¹‹é—´çš„æƒè¡¡ã€‚ä¸ºè¯„ä¼°æ­¤ä»»åŠ¡ï¼Œæ–‡ç« æå‡ºäº†BeNYfitsæ–°åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡äº’åŠ¨å†³ç­–æ¥åˆ¤å®šç”¨æˆ·æ˜¯å¦é€‚åˆå¤šé‡é‡å çš„ç¤¾ä¼šç¦åˆ©æœºä¼šã€‚å®éªŒæ˜¾ç¤ºï¼Œå½“å‰çš„è¯­è¨€æ¨¡å‹å¸¸æœ‰è¯¯åˆ¤ç°è±¡ï¼ŒGPT-4oåœ¨ReActå¼æ€ç»´é“¾ä¸­çš„F1å¾—åˆ†ä»…35.7ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ProADAæ–°æ–¹æ³•ï¼Œé€šè¿‡ç¨‹åºåˆæˆååŠ©å†³ç­–ï¼Œå°†å¯¹è¯è§„åˆ’æ˜ å°„ä¸ºä»£ç ç”Ÿæˆé—®é¢˜å¹¶åˆ©ç”¨ç»“æ„åŒ–æ•°æ®ä¸­çš„ç©ºç™½æ¥ç¡®å®šæœ€ä½³ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚ProADAä»£ç†èƒ½å°†F1å¾—åˆ†æå‡è‡³55.6%ï¼ŒåŒæ—¶ä¿æŒç›¸è¿‘çš„å¯¹è¯è½®æ¬¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°å®ä¸–ç•Œçš„èµ„æ ¼è®¤å®šé—®é¢˜å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€å†³ç­–é—®é¢˜è¡¨è¾¾ã€‚</li>
<li>åœ¨å¤§è§„æ¨¡é¢†åŸŸæˆ–é¢‘ç¹æ›´æ–°çš„èµ„åŠ©æœºä¼šä¸­ï¼Œäººå·¥æ ‡æ³¨å˜å¾—ä¸å®é™…ï¼Œéœ€è¦è‡ªåŠ¨å†³ç­–çš„æ™ºèƒ½ä»£ç†ã€‚</li>
<li>æ™ºèƒ½ä»£ç†å¿…é¡»èƒ½å¤Ÿå‘ç”¨æˆ·æé—®ä»¥è·å–å…³é”®ä¿¡æ¯ã€‚</li>
<li>åœ¨å†³å®šä½•æ—¶ç»“æŸå¯¹è¯æ—¶ï¼Œæ™ºèƒ½ä»£ç†éœ€è¦åœ¨å‡†ç¡®æ€§å’Œæé—®æ•°é‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚</li>
<li>æå‡ºæ–°çš„åŸºå‡†æµ‹è¯•BeNYfitsç”¨äºè¯„ä¼°äº’åŠ¨å†³ç­–æ•ˆæœã€‚</li>
<li>å½“å‰è¯­è¨€æ¨¡å‹å­˜åœ¨è¯¯åˆ¤ç°è±¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚æƒ…å¢ƒä¸­éš¾ä»¥å‡†ç¡®åˆ¤æ–­ç”¨æˆ·èµ„æ ¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19610">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-95382c5be480b889e06f8c14bfe3c553.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf87156faef4bc9dcbd5cb2d1835d2fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4eb9334447d0c0b1576d559cc92b7f95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ed56c47c419526af1367dfa13a6f158.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e1f0e1f536bfcba4f3d7d93b1016911.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Winning-Big-with-Small-Models-Knowledge-Distillation-vs-Self-Training-for-Reducing-Hallucination-in-QA-Agents"><a href="#Winning-Big-with-Small-Models-Knowledge-Distillation-vs-Self-Training-for-Reducing-Hallucination-in-QA-Agents" class="headerlink" title="Winning Big with Small Models: Knowledge Distillation vs. Self-Training   for Reducing Hallucination in QA Agents"></a>Winning Big with Small Models: Knowledge Distillation vs. Self-Training   for Reducing Hallucination in QA Agents</h2><p><strong>Authors:Ashley Lewis, Michael White, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Ye Wang</strong></p>
<p>The deployment of Large Language Models (LLMs) in customer support is constrained by hallucination-generating false information-and the high cost of proprietary models. To address these challenges, we propose a retrieval-augmented question-answering (QA) pipeline and explore how to balance human input and automation. Using a dataset of questions about a Samsung Smart TV user manual, we demonstrate that synthetic data generated by LLMs outperforms crowdsourced data in reducing hallucination in finetuned models. We also compare self-training (fine-tuning models on their own outputs) and knowledge distillation (fine-tuning on stronger modelsâ€™ outputs, e.g., GPT-4o), and find that self-training achieves comparable hallucination reduction. We conjecture that this surprising finding can be attributed to increased exposure bias issues in the knowledge distillation case and support this conjecture with post hoc analysis. We also improve robustness to unanswerable questions and retrieval failures with contextualized â€œI donâ€™t knowâ€ responses. These findings show that scalable, cost-efficient QA systems can be built using synthetic data and self-training with open-source models, reducing reliance on proprietary tools or costly human annotations. </p>
<blockquote>
<p>åœ¨å®¢æˆ·æ”¯æŒä¸­éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å—åˆ°ç”Ÿæˆè™šå‡ä¿¡æ¯çš„å¹»è§‰å’Œé«˜æ˜‚çš„ä¸“æœ‰æ¨¡å‹æˆæœ¬é™åˆ¶ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºé—®ç­”ï¼ˆQAï¼‰ç®¡é“ï¼Œå¹¶æ¢ç´¢å¦‚ä½•å¹³è¡¡äººå·¥è¾“å…¥å’Œè‡ªåŠ¨åŒ–ã€‚æˆ‘ä»¬ä½¿ç”¨æœ‰å…³ä¸‰æ˜Ÿæ™ºèƒ½ç”µè§†ç”¨æˆ·æ‰‹å†Œçš„é—®é¢˜æ•°æ®é›†ï¼Œå±•ç¤ºLLMç”Ÿæˆçš„åˆæˆæ•°æ®åœ¨å‡å°‘å¾®è°ƒæ¨¡å‹ä¸­çš„å¹»è§‰æ–¹é¢ä¼˜äºä¼—åŒ…æ•°æ®ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†è‡ªè®­ç»ƒï¼ˆåœ¨æ¨¡å‹è‡ªèº«è¾“å‡ºä¸Šå¾®è°ƒï¼‰å’ŒçŸ¥è¯†è’¸é¦ï¼ˆåœ¨æ›´å¼ºå¤§æ¨¡å‹çš„è¾“å‡ºä¸Šè¿›è¡Œå¾®è°ƒï¼Œä¾‹å¦‚GPT-4oï¼‰ï¼Œå‘ç°è‡ªè®­ç»ƒå¯å®ç°ç›¸å½“çš„å¹»è§‰å‡å°‘æ•ˆæœã€‚æˆ‘ä»¬æ¨æµ‹è¿™ä¸€ä»¤äººæƒŠè®¶çš„å‘ç°å¯å½’å› äºçŸ¥è¯†è’¸é¦æƒ…å†µä¸‹çš„å¢åŠ æ›å…‰åè§é—®é¢˜ï¼Œå¹¶é€šè¿‡äº‹ååˆ†ææ”¯æŒè¿™ä¸€æ¨æµ‹ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸Šä¸‹æ–‡ä¸­çš„â€œæˆ‘ä¸çŸ¥é“â€çš„å›åº”ï¼Œæé«˜äº†å¯¹æ— æ³•å›ç­”çš„é—®é¢˜å’Œæ£€ç´¢å¤±è´¥çš„ç¨³å¥æ€§ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå¯ä»¥ä½¿ç”¨åˆæˆæ•°æ®å’Œè‡ªè®­ç»ƒä»¥åŠå¼€æºæ¨¡å‹æ„å»ºå¯æ‰©å±•ä¸”æˆæœ¬æ•ˆç›Šé«˜çš„QAç³»ç»Ÿï¼Œå‡å°‘äº†å¯¹ä¸“æœ‰å·¥å…·æˆ–æ˜‚è´µçš„äººåŠ›æ ‡æ³¨çš„ä¾èµ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19545v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®¢æœæ”¯æŒä¸­çš„åº”ç”¨å—åˆ°ç”Ÿæˆè™šå‡ä¿¡æ¯å’Œä¸“æœ‰æ¨¡å‹æˆæœ¬é«˜æ˜‚çš„é™åˆ¶ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ£€ç´¢å¢å¼ºé—®ç­”ï¼ˆQAï¼‰ç®¡é“ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•å¹³è¡¡äººå·¥è¾“å…¥å’Œè‡ªåŠ¨åŒ–ã€‚ä½¿ç”¨å…³äºä¸‰æ˜Ÿæ™ºèƒ½ç”µè§†ç”¨æˆ·æ‰‹å†Œçš„é—®é¢˜æ•°æ®é›†ï¼Œæˆ‘ä»¬è¯æ˜ç”±LLMç”Ÿæˆçš„äººå·¥æ•°æ®åœ¨å¾®è°ƒæ¨¡å‹ä¸­å‡å°‘äº†å¹»è§‰ç”Ÿæˆï¼Œä¼˜äºä¼—åŒ…æ•°æ®ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†è‡ªè®­ç»ƒï¼ˆåœ¨è‡ªèº«è¾“å‡ºä¸Šå¾®è°ƒæ¨¡å‹ï¼‰å’ŒçŸ¥è¯†è’¸é¦ï¼ˆåœ¨æ›´å¼ºå¤§æ¨¡å‹çš„è¾“å‡ºä¸Šå¾®è°ƒï¼Œä¾‹å¦‚GPT-4oï¼‰ï¼Œå‘ç°è‡ªè®­ç»ƒå¯å®ç°ç›¸å½“çš„å¹»è§‰å‡å°‘æ•ˆæœã€‚æˆ‘ä»¬æ¨æµ‹è¿™ä¸€ä»¤äººæƒŠè®¶çš„å‘ç°å¯å½’å› äºçŸ¥è¯†è’¸é¦æƒ…å†µä¸‹çš„æ›å…‰åè§å¢åŠ é—®é¢˜ï¼Œå¹¶é€šè¿‡äº‹ååˆ†ææ”¯æŒè¿™ä¸€æ¨æµ‹ã€‚æˆ‘ä»¬è¿˜é€šè¿‡æä¾›ä¸Šä¸‹æ–‡â€œæˆ‘ä¸çŸ¥é“â€çš„å›åº”ï¼Œæé«˜äº†å¯¹æ— æ³•å›ç­”çš„é—®é¢˜å’Œæ£€ç´¢å¤±è´¥çš„ç¨³å¥æ€§ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå¯ä½¿ç”¨äººå·¥æ•°æ®å’Œè‡ªè®­ç»ƒæ„å»ºå¯æ‰©å±•ã€æˆæœ¬æ•ˆç›Šé«˜çš„é—®ç­”ç³»ç»Ÿï¼Œå‡å°‘ä¾èµ–ä¸“æœ‰å·¥å…·æˆ–æ˜‚è´µçš„çœŸäººæ³¨é‡Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®¢æœæ”¯æŒä¸­é¢ä¸´ç”Ÿæˆè™šå‡ä¿¡æ¯å’Œä¸“æœ‰æ¨¡å‹æˆæœ¬é«˜æ˜‚çš„æŒ‘æˆ˜ã€‚</li>
<li>æ£€ç´¢å¢å¼ºé—®ç­”ï¼ˆQAï¼‰ç®¡é“æœ‰åŠ©äºåº”å¯¹ä»¥ä¸ŠæŒ‘æˆ˜ã€‚</li>
<li>ä½¿ç”¨å…³äºä¸‰æ˜Ÿæ™ºèƒ½ç”µè§†ç”¨æˆ·æ‰‹å†Œçš„é—®é¢˜æ•°æ®é›†ï¼ŒLLMç”Ÿæˆçš„äººå·¥æ•°æ®åœ¨å‡å°‘å¹»è§‰æ–¹é¢ä¼˜äºä¼—åŒ…æ•°æ®ã€‚</li>
<li>è‡ªè®­ç»ƒä¸çŸ¥è¯†è’¸é¦åœ¨å‡å°‘å¹»è§‰æ–¹é¢æ•ˆæœç›¸å½“ï¼Œä½†è‡ªè®­ç»ƒå¯èƒ½å—åˆ°æ›å…‰åè§å¢åŠ çš„å½±å“ã€‚</li>
<li>é€šè¿‡æä¾›â€œæˆ‘ä¸çŸ¥é“â€çš„å›åº”ï¼Œæé«˜äº†å¯¹æ— æ³•å›ç­”çš„é—®é¢˜å’Œæ£€ç´¢å¤±è´¥çš„ç¨³å¥æ€§ã€‚</li>
<li>å¯ä½¿ç”¨äººå·¥æ•°æ®å’Œè‡ªè®­ç»ƒæ„å»ºæˆæœ¬æ•ˆç›Šé«˜çš„é—®ç­”ç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19545">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1bc58304590c494647557492eaf5ab1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7485f4662429ab351a74f4205c745981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-334ec3cf2241de04010a2ec4bbf77570.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b576ff80854a0080a7cbf9aa68331876.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-327fe190f00d81d3c80a0ced241a8fca.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Building-reliable-sim-driving-agents-by-scaling-self-play"><a href="#Building-reliable-sim-driving-agents-by-scaling-self-play" class="headerlink" title="Building reliable sim driving agents by scaling self-play"></a>Building reliable sim driving agents by scaling self-play</h2><p><strong>Authors:Daphne Cornelisse, Aarav Pandya, Kevin Joseph, Joseph SuÃ¡rez, Eugene Vinitsky</strong></p>
<p>Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing system limits, but all applications share one key requirement: reliability. To enable systematic experimentation, a simulation agent must behave as intended. It should minimize actions that may lead to undesired outcomes, such as collisions, which can distort the signal-to-noise ratio in analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents nearly solve the full training set within a day. They generalize effectively to unseen test scenes, achieving a 99.8% goal completion rate with less than 0.8% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in those cases. We open-source the pre-trained agents and integrate them with a batched multi-agent simulator. Demonstrations of agent behaviors can be found at <a target="_blank" rel="noopener" href="https://sites.google.com/view/reliable-sim-agents">https://sites.google.com/view/reliable-sim-agents</a>. </p>
<blockquote>
<p>æ¨¡æ‹Ÿä»£ç†å¯¹äºè®¾è®¡å’Œæµ‹è¯•ä¸äººç±»äº¤äº’çš„ç³»ç»Ÿï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼‰è‡³å…³é‡è¦ã€‚è¿™äº›ä»£ç†å…·æœ‰å¤šç§ç”¨é€”ï¼Œä»è¯„ä¼°è‡ªåŠ¨é©¾é©¶æ€§èƒ½åˆ°å‹åŠ›æµ‹è¯•ç³»ç»Ÿé™åˆ¶ï¼Œä½†æ‰€æœ‰åº”ç”¨ç¨‹åºéƒ½å…±äº«ä¸€ä¸ªå…³é”®è¦æ±‚ï¼šå¯é æ€§ã€‚ä¸ºäº†å®ç°ç³»ç»Ÿçš„å®éªŒï¼Œæ¨¡æ‹Ÿä»£ç†å¿…é¡»æŒ‰é¢„æœŸè¡Œä¸ºè¡Œäº‹ã€‚å®ƒåº”å°½é‡å‡å°‘å¯èƒ½å¯¼è‡´ä¸è‰¯åæœçš„è¡ŒåŠ¨ï¼Œä¾‹å¦‚ç¢°æ’ï¼Œè¿™å¯èƒ½ä¼šåœ¨åˆ†æä¸­æ‰­æ›²ä¿¡å·ä¸å™ªå£°æ¯”ç‡ã€‚ä½œä¸ºæ„å»ºå¯é çš„æ¨¡æ‹Ÿä»£ç†çš„åŸºç¡€ï¼Œæˆ‘ä»¬å»ºè®®åœ¨Waymo Open Motionæ•°æ®é›†ä¸Šï¼Œå¯¹äººç±»æ„ŸçŸ¥å’Œæ§åˆ¶èƒ½åŠ›çš„åŠç°å®é™åˆ¶ä¸‹è¿›è¡Œæˆåƒä¸Šä¸‡çš„åœºæ™¯çš„è‡ªæˆ‘åšå¼ˆæ‰©å±•ã€‚ä½¿ç”¨å•ä¸ªGPUä»å¤´å¼€å§‹è®­ç»ƒï¼Œæˆ‘ä»¬çš„ä»£ç†åœ¨ä¸€å¤©å†…å‡ ä¹è§£å†³äº†æ•´ä¸ªè®­ç»ƒé›†ã€‚ä»–ä»¬æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æœªè§è¿‡çš„æµ‹è¯•åœºæ™¯ï¼Œåœ¨10000ä¸ªä¿ç•™åœºæ™¯ä¸­å®ç°äº†99.8ï¼…çš„ç›®æ ‡å®Œæˆç‡ï¼Œç¢°æ’å’Œé“è·¯å¤–äº‹ä»¶å°‘äº0.8ï¼…ã€‚é™¤äº†åˆ†å¸ƒå†…æ³›åŒ–ä¹‹å¤–ï¼Œæˆ‘ä»¬çš„ä»£ç†å¯¹åˆ†å¸ƒå¤–åœºæ™¯æ˜¾ç¤ºå‡ºéƒ¨åˆ†ç¨³å¥æ€§ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…è¿›è¡Œå¾®è°ƒï¼Œä»¥åœ¨è¿™äº›æƒ…å†µä¸‹å®ç°æ¥è¿‘å®Œç¾çš„æ€§èƒ½ã€‚æˆ‘ä»¬å…¬å¼€äº†é¢„è®­ç»ƒçš„ä»£ç†ï¼Œå¹¶å°†å…¶ä¸æ‰¹å¤„ç†çš„å¤šä»£ç†æ¨¡æ‹Ÿå™¨é›†æˆã€‚æœ‰å…³ä»£ç†è¡Œä¸ºçš„æ¼”ç¤ºï¼Œè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://sites.google.com/view/reliable-sim-agents%E3%80%82">https://sites.google.com/view/reliable-sim-agentsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14706v2">PDF</a> v2</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ¨¡æ‹Ÿä»£ç†å¯¹äºè®¾è®¡å’Œæµ‹è¯•ä¸äººç±»äº¤äº’çš„ç³»ç»Ÿï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼‰çš„é‡è¦æ€§ã€‚æ¨¡æ‹Ÿä»£ç†å¯ä»¥é€šè¿‡åœ¨å„ç§åœºæ™¯ä¸‹æ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼Œä¸ºç³»ç»Ÿè®¾è®¡å’Œæµ‹è¯•æä¾›å¯é çš„å®éªŒåŸºç¡€ã€‚æ–‡ç« æå‡ºä¸€ç§åŸºäºWaymo Open Motionæ•°æ®é›†çš„å¤§è§„æ¨¡è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒæ–¹æ¡ˆï¼Œè®­ç»ƒå¾—åˆ°çš„ä»£ç†åœ¨æœªè§åœºæ™¯ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå¹¶å®Œæˆç›®æ ‡çš„å®Œæˆç‡é«˜è¾¾99.8%ï¼ŒåŒæ—¶ç¢°æ’å’Œç¦»è·¯äº‹æ•…ç‡ä½äº0.8%ã€‚è¿™äº›ä»£ç†è¢«å¼€æºï¼Œå¹¶é›†æˆåˆ°ä¸€ä¸ªæ‰¹å¤„ç†å¤šä»£ç†æ¨¡æ‹Ÿå™¨ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨¡æ‹Ÿä»£ç†åœ¨è®¾è®¡å’Œæµ‹è¯•ä¸äººç±»äº¤äº’çš„ç³»ç»Ÿï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼‰ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>æ¨¡æ‹Ÿä»£ç†çš„å…³é”®è¦æ±‚æ˜¯å¯é æ€§ï¼Œéœ€è¦æœ€å°åŒ–å¯èƒ½å¯¼è‡´æ„å¤–ç»“æœçš„è¡ŒåŠ¨ã€‚</li>
<li>æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºWaymo Open Motionæ•°æ®é›†çš„å¤§è§„æ¨¡è‡ªæˆ‘å¯¹å¼ˆè®­ç»ƒæ–¹æ¡ˆï¼Œç”¨äºåˆ›å»ºå¯é çš„æ¨¡æ‹Ÿä»£ç†ã€‚</li>
<li>è®­ç»ƒå¾—åˆ°çš„ä»£ç†åœ¨æœªè§åœºæ™¯ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå¹¶å®Œæˆç›®æ ‡çš„å®Œæˆç‡é«˜è¾¾99.8%ã€‚</li>
<li>è¿™äº›ä»£ç†å…·æœ‰éƒ¨åˆ†å¯¹ç¦»ç¾¤åœºæ™¯çš„é²æ£’æ€§ï¼Œå¹¶ä¸”å¯ä»¥è¿…é€Ÿå¾®è°ƒä»¥è¾¾åˆ°è¿‘ä¹å®Œç¾çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç†è¢«å¼€æºå¹¶é›†æˆåˆ°ä¸€ä¸ªæ‰¹å¤„ç†å¤šä»£ç†æ¨¡æ‹Ÿå™¨ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œæ›´å¹¿æ³›çš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14706">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1ea619817dc890d50082e16353cd5a24.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d06a85ed528dc980d752eeba20270ee9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-461112367f793bfccc35a1ff115976da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92baa235796ae054060671b6554375c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eee3962d7cc21b57a24ff1627adfd32b.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SDPO-Segment-Level-Direct-Preference-Optimization-for-Social-Agents"><a href="#SDPO-Segment-Level-Direct-Preference-Optimization-for-Social-Agents" class="headerlink" title="SDPO: Segment-Level Direct Preference Optimization for Social Agents"></a>SDPO: Segment-Level Direct Preference Optimization for Social Agents</h2><p><strong>Authors:Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang</strong></p>
<p>Social agents powered by large language models (LLMs) can simulate human social behaviors but fall short in handling complex social dialogues. Direct Preference Optimization (DPO) has proven effective in aligning LLM behavior with human preferences across various agent tasks. However, standard DPO focuses solely on individual turns, which limits its effectiveness in multi-turn social interactions. Several DPO-based multi-turn alignment methods with session-level data have shown potential in addressing this problem.While these methods consider multiple turns across entire sessions, they are often overly coarse-grained, introducing training noise, and lack robust theoretical support. To resolve these limitations, we propose Segment-Level Direct Preference Optimization (SDPO), which dynamically select key segments within interactions to optimize multi-turn agent behavior. SDPO minimizes training noise and is grounded in a rigorous theoretical framework. Evaluations on the SOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform both existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring SDPOâ€™s potential to advance the social intelligence of LLM-based agents. We release our code and data at <a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO</a>. </p>
<blockquote>
<p>ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ç¤¾ä¼šä»£ç†èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„ç¤¾ä¼šè¡Œä¸ºï¼Œä½†åœ¨å¤„ç†å¤æ‚çš„ç¤¾äº¤å¯¹è¯æ—¶æ˜¾å¾—ä¸è¶³ã€‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰åœ¨å°†LLMè¡Œä¸ºä¸å„ç§ä»£ç†ä»»åŠ¡ä¸­çš„äººç±»åå¥½å¯¹é½æ–¹é¢å·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ã€‚ç„¶è€Œï¼Œæ ‡å‡†DPOä»…ä¸“æ³¨äºä¸ªåˆ«å›åˆï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å¤šå›åˆç¤¾ä¼šäº’åŠ¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸€äº›åŸºäºDPOçš„å¤šå›åˆå¯¹é½æ–¹æ³•ä½¿ç”¨ä¼šè¯çº§æ•°æ®ï¼Œå·²ç»æ˜¾ç¤ºå‡ºè§£å†³è¿™ä¸ªé—®é¢˜çš„æ½œåŠ›ã€‚è™½ç„¶è¿™äº›æ–¹æ³•ä¼šè€ƒè™‘æ•´ä¸ªä¼šè¯ä¸­çš„å¤šä¸ªå›åˆï¼Œä½†å®ƒä»¬é€šå¸¸è¿‡äºç²—ç³™ï¼Œå¼•å…¥è®­ç»ƒå™ªå£°ï¼Œå¹¶ä¸”ç¼ºä¹åšå®çš„ç†è®ºæ”¯æŒã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ†æ®µçº§ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆSDPOï¼‰ï¼Œå®ƒåŠ¨æ€é€‰æ‹©äº’åŠ¨ä¸­çš„å…³é”®æ®µè½æ¥ä¼˜åŒ–å¤šå›åˆä»£ç†è¡Œä¸ºã€‚SDPOæœ€å°åŒ–è®­ç»ƒå™ªå£°ï¼Œå¹¶åŸºäºä¸¥æ ¼çš„ç†è®ºæ¡†æ¶ã€‚åœ¨SOTOPIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œç»è¿‡SDPOè°ƒæ•´çš„ä»£ç†å§‹ç»ˆä¼˜äºç°æœ‰çš„åŸºäºDPOçš„æ–¹æ³•ä»¥åŠä¸“æœ‰LLMï¼Œå¦‚GPT-4oï¼Œè¿™çªå‡ºäº†SDPOåœ¨æé«˜åŸºäºLLMçš„ä»£ç†çš„ç¤¾ä¼šæ™ºèƒ½æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO</a>ä¸Šå‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01821v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç¤¾ä¼šä»£ç†èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»ç¤¾äº¤è¡Œä¸ºï¼Œä½†åœ¨å¤„ç†å¤æ‚ç¤¾ä¼šå¯¹è¯æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰åœ¨å°†LLMè¡Œä¸ºä¸å„ç§ä»£ç†ä»»åŠ¡ä¸­çš„äººç±»åå¥½å¯¹é½æ–¹é¢è¡¨ç°å‡ºæˆæ•ˆã€‚ç„¶è€Œï¼Œæ ‡å‡†DPOåªå…³æ³¨ä¸ªåˆ«å›åˆï¼Œè¿™åœ¨å¤šå›åˆç¤¾ä¼šäº’åŠ¨ä¸­çš„æ•ˆæœæœ‰é™ã€‚åŸºäºDPOçš„å¤šå›åˆå¯¹é½æ–¹æ³•è™½ç„¶è€ƒè™‘äº†æ•´ä¸ªä¼šè¯ä¸­çš„å¤šä¸ªå›åˆï¼Œä½†å®ƒä»¬é€šå¸¸è¿‡äºç²—ç³™ï¼Œå¼•å…¥è®­ç»ƒå™ªéŸ³ï¼Œå¹¶ä¸”ç¼ºä¹åšå®çš„ç†è®ºæ”¯æŒã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ†æ®µçº§ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆSDPOï¼‰ï¼Œå®ƒåŠ¨æ€é€‰æ‹©äº’åŠ¨ä¸­çš„å…³é”®æ®µè½è¿›è¡Œä¼˜åŒ–ã€‚SDPOå‡å°‘äº†è®­ç»ƒå™ªéŸ³ï¼Œå¹¶å»ºç«‹åœ¨ä¸¥æ ¼çš„ç†è®ºæ¡†æ¶ä¸Šã€‚åœ¨SOTOPIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œç»è¿‡SDPOè°ƒæ•´çš„ä»£ç†æŒç»­ä¼˜äºç°æœ‰çš„åŸºäºDPOçš„æ–¹æ³•å’Œä¸“æœ‰LLMï¼Œå¦‚GPT-4oï¼Œçªæ˜¾äº†SDPOåœ¨æå‡åŸºäºLLMçš„ä»£ç†çš„ç¤¾ä¼šæ™ºèƒ½æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥æ¨¡æ‹Ÿäººç±»ç¤¾äº¤è¡Œä¸ºï¼Œä½†åœ¨å¤„ç†å¤æ‚ç¤¾ä¼šå¯¹è¯æ—¶è¡¨ç°ä¸è¶³ã€‚</li>
<li>ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰åœ¨LLMä¸äººç±»åå¥½å¯¹é½æ–¹é¢æœ‰æ•ˆï¼Œä½†æ ‡å‡†DPOåœ¨å¤šå›åˆç¤¾ä¼šäº’åŠ¨ä¸­çš„æ•ˆæœæœ‰é™ã€‚</li>
<li>åŸºäºDPOçš„å¤šå›åˆå¯¹é½æ–¹æ³•è™½ç„¶è€ƒè™‘äº†æ•´ä¸ªä¼šè¯ä¸­çš„å¤šä¸ªå›åˆï¼Œä½†å­˜åœ¨è®­ç»ƒå™ªéŸ³å’Œç¼ºä¹ç†è®ºæ”¯æŒçš„é—®é¢˜ã€‚</li>
<li>åˆ†æ®µçº§ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆSDPOï¼‰åŠ¨æ€é€‰æ‹©å…³é”®æ®µè½è¿›è¡Œä¼˜åŒ–ï¼Œå‡å°‘è®­ç»ƒå™ªéŸ³ï¼Œå»ºç«‹åœ¨ä¸¥æ ¼çš„ç†è®ºæ¡†æ¶ä¸Šã€‚</li>
<li>SDPOåœ¨SOTOPIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•å’Œä¸“æœ‰LLMï¼Œçªæ˜¾å…¶åœ¨æå‡LLMä»£ç†çš„ç¤¾ä¼šæ™ºèƒ½æ–¹é¢çš„æ½œåŠ›ã€‚</li>
<li>ä»£ç å’Œæ•°æ®å·²å…¬å¼€å¯ç”¨ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01821">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c9ec459a168935328659df3da927e4ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8066f15c42dcf10f55ad4a3983716b19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a2d6cd91b462b9104cc3e4006d58412.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-009b88b86f736885987d934f5ab4129b.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR"><a href="#CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR" class="headerlink" title="CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR"></a>CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR</h2><p><strong>Authors:Kadir Burak Buldu, SÃ¼leyman Ã–zdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie SchÃ¶nborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir</strong></p>
<p>Recent developments in computer graphics, machine learning, and sensor technologies enable numerous opportunities for extended reality (XR) setups for everyday life, from skills training to entertainment. With large corporations offering affordable consumer-grade head-mounted displays (HMDs), XR will likely become pervasive, and HMDs will develop as personal devices like smartphones and tablets. However, having intelligent spaces and naturalistic interactions in XR is as important as technological advances so that users grow their engagement in virtual and augmented spaces. To this end, large language model (LLM)â€“powered non-player characters (NPCs) with speech-to-text (STT) and text-to-speech (TTS) models bring significant advantages over conventional or pre-scripted NPCs for facilitating more natural conversational user interfaces (CUIs) in XR. This paper provides the community with an open-source, customizable, extendable, and privacy-aware Unity package, CUIfy, that facilitates speech-based NPC-user interaction with widely used LLMs, STT, and TTS models. Our package also supports multiple LLM-powered NPCs per environment and minimizes latency between different computational models through streaming to achieve usable interactions between users and NPCs. We publish our source code in the following repository: <a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify">https://gitlab.lrz.de/hctl/cuify</a> </p>
<blockquote>
<p>è¿‘æœŸè®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ å’Œä¼ æ„Ÿå™¨æŠ€æœ¯çš„è¿›å±•ä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„è¿ç”¨æä¾›äº†æ— æ•°æœºä¼šï¼Œæ— è®ºæ˜¯æŠ€èƒ½åŸ¹è®­è¿˜æ˜¯å¨±ä¹ã€‚éšç€å¤§å‹ä¼ä¸šæä¾›ç»æµå®æƒ çš„æ¶ˆè´¹çº§å¤´æˆ´æ˜¾ç¤ºå™¨ï¼ˆHMDsï¼‰ï¼ŒXRå¯èƒ½ä¼šå˜å¾—æ™®åŠï¼ŒHMDså°†åƒæ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ç”µè„‘ä¸€æ ·æˆä¸ºä¸ªäººè®¾å¤‡ã€‚ç„¶è€Œï¼Œæ‹¥æœ‰æ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶çš„äººæœºäº¤äº’ä¸ç§‘æŠ€è¿›æ­¥åŒæ ·é‡è¦ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿå¢åŠ å¯¹è™šæ‹Ÿå’Œå¢å¼ºç©ºé—´çš„å‚ä¸åº¦ã€‚ä¸ºæ­¤ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„éç©å®¶è§’è‰²ï¼ˆNPCsï¼‰ä½¿ç”¨è¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰å’Œæ–‡æœ¬è¯­éŸ³è½¬æ¢ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„æˆ–é¢„è®¾çš„NPCsï¼Œä¸ºXRä¸­æ›´è‡ªç„¶çš„å¯¹è¯ç”¨æˆ·ç•Œé¢ï¼ˆCUIsï¼‰å¸¦æ¥äº†æ˜¾è‘—ä¼˜åŠ¿ã€‚æœ¬æ–‡ä¸ºç¤¾åŒºæä¾›äº†ä¸€ä¸ªå¼€æºã€å¯å®šåˆ¶ã€å¯æ‰©å±•ä¸”æ³¨é‡éšç§çš„Unityè½¯ä»¶åŒ…CUIfyï¼Œå®ƒä¿ƒè¿›äº†åŸºäºè¯­éŸ³çš„NPCä¸ç”¨æˆ·ä¹‹é—´çš„äº¤äº’ï¼Œå¹¿æ³›ä½¿ç”¨äº†LLMã€STTå’ŒTTSæ¨¡å‹ã€‚æˆ‘ä»¬çš„è½¯ä»¶åŒ…è¿˜æ”¯æŒæ¯ä¸ªç¯å¢ƒå¤šä¸ªLLMé©±åŠ¨çš„NPCsï¼Œå¹¶é€šè¿‡æµå¼ä¼ è¾“å‡å°‘ä¸åŒè®¡ç®—æ¨¡å‹ä¹‹é—´çš„å»¶è¿Ÿï¼Œä»¥å®ç°ç”¨æˆ·å’ŒNPCsä¹‹é—´å¯ç”¨çš„äº¤äº’ã€‚æˆ‘ä»¬åœ¨ä»¥ä¸‹å­˜å‚¨åº“ä¸­å‘å¸ƒæˆ‘ä»¬çš„æºä»£ç ï¼š<a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify%E2%80%8D%E3%80%82">https://gitlab.lrz.de/hctl/cuify</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04671v2">PDF</a> 7th IEEE International Conference on Artificial Intelligence &amp;   eXtended and Virtual Reality (IEEE AIxVR 2025)</p>
<p><strong>Summary</strong><br>     è¿‘æœŸè®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ å’Œä¼ æ„Ÿå™¨æŠ€æœ¯çš„å‘å±•ä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„è¿ç”¨æä¾›äº†æ— æ•°æœºä¼šï¼Œå¦‚æŠ€èƒ½åŸ¹è®­å’Œå¨±ä¹ç­‰ã€‚éšç€å¤§å‹ä¼ä¸šæä¾›ç»æµå®æƒ çš„æ¶ˆè´¹çº§å¤´æˆ´æ˜¾ç¤ºå™¨ï¼ˆHMDï¼‰ï¼ŒXRæœ‰æœ›æˆä¸ºæ™®åŠæŠ€æœ¯ï¼ŒHMDå°†åƒæ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ç”µè„‘ä¸€æ ·æˆä¸ºä¸ªäººè®¾å¤‡ã€‚ä¸ºäº†æå‡ç”¨æˆ·åœ¨è™šæ‹Ÿå’Œå¢å¼ºç©ºé—´ä¸­çš„å‚ä¸åº¦ï¼Œæ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶äº¤äº’æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚ä¸ºæ­¤ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„éç©å®¶è§’è‰²ï¼ˆNPCsï¼‰ç»“åˆè¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰å’Œæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæˆ–é¢„è®¾çš„NPCsï¼Œèƒ½ä¸ºXRåˆ›é€ æ›´è‡ªç„¶çš„å¯¹è¯å¼ç”¨æˆ·ç•Œé¢ï¼ˆCUIsï¼‰ã€‚æœ¬æ–‡å‘ç¤¾åŒºæä¾›ä¸€ä¸ªå¼€æºã€å¯å®šåˆ¶ã€å¯æ‰©å±•ä¸”æ³¨é‡éšç§çš„UnityåŒ…â€”â€”CUIfyï¼Œå®ƒä¿ƒè¿›äº†åŸºäºè¯­éŸ³çš„NPCä¸ç”¨æˆ·ä¹‹é—´çš„äº¤äº’ï¼Œæ”¯æŒå¹¿æ³›ä½¿ç”¨çš„LLMsã€STTå’ŒTTSæ¨¡å‹ã€‚æˆ‘ä»¬çš„è½¯ä»¶åŒ…è¿˜æ”¯æŒæ¯ä¸ªç¯å¢ƒå¤šä¸ªLLMé©±åŠ¨çš„NPCsï¼Œå¹¶é€šè¿‡æµæŠ€æœ¯æœ€å°åŒ–ä¸åŒè®¡ç®—æ¨¡å‹ä¹‹é—´çš„å»¶è¿Ÿï¼Œä»¥å®ç°ç”¨æˆ·å’ŒNPCä¹‹é—´çš„å¯ç”¨äº¤äº’ã€‚æˆ‘ä»¬çš„æºä»£ç å‘å¸ƒåœ¨ä»¥ä¸‹ä»“åº“ä¸­ï¼š<a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify">https://gitlab.lrz.de/hctl/cuify</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XRæŠ€æœ¯å°†æ—¥ç›Šæ™®åŠï¼Œæ¨åŠ¨å¤šä¸ªé¢†åŸŸçš„å‘å±•ã€‚éšç€æŠ€æœ¯çš„è¿›æ­¥å’Œæ¶ˆè´¹è€…è®¾å¤‡çš„é™ä½æˆæœ¬ï¼ŒXRå°†åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚</li>
<li>æ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶äº¤äº’å¯¹äºæé«˜ç”¨æˆ·åœ¨è™šæ‹Ÿå’Œå¢å¼ºç©ºé—´çš„å‚ä¸åº¦è‡³å…³é‡è¦ã€‚è¿™éœ€è¦é‡‡ç”¨å…ˆè¿›çš„è¯­è¨€æ¨¡å‹å’Œè¯­éŸ³è¯†åˆ«æŠ€æœ¯æ¥æ¨åŠ¨äººæœºäº¤äº’çš„è¿›æ­¥ã€‚</li>
<li>LLMé©±åŠ¨çš„NPCsç»“åˆSTTå’ŒTTSæ¨¡å‹èƒ½åˆ›é€ æ›´è‡ªç„¶çš„å¯¹è¯å¼ç”¨æˆ·ç•Œé¢ï¼ˆCUIsï¼‰ã€‚è¿™å°†ä¿ƒè¿›NPCè§’è‰²çš„åŠŸèƒ½æ‰©å±•å¹¶å¢åŠ å…¶å¯ä¿¡åº¦ä¸äº’åŠ¨æ„Ÿã€‚</li>
<li>CUIfyå·¥å…·åŒ…ä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·é›†ï¼Œæ”¯æŒè¯­éŸ³äº¤äº’ã€å¤šNPCç®¡ç†å’Œè®¡ç®—æ¨¡å‹é—´çš„å»¶è¿Ÿæœ€å°åŒ–ã€‚è¿™å°†ç®€åŒ–NPCå’Œç”¨æˆ·ä¹‹é—´çš„äº¤äº’æµç¨‹å¹¶æå‡å…¶æ•ˆç‡ã€‚</li>
<li>CUIfyåŒ…å¼ºè°ƒéšç§ä¿æŠ¤ï¼Œç¡®ä¿ç”¨æˆ·æ•°æ®çš„å®‰å…¨æ€§å’Œéšç§æƒç›Šå¾—åˆ°å°Šé‡ã€‚è¿™å¯¹äºç¡®ä¿ç”¨æˆ·åœ¨ä½¿ç”¨XRæŠ€æœ¯æ—¶çš„ä¿¡æ¯å®‰å…¨è‡³å…³é‡è¦ã€‚</li>
<li>æä¾›çš„UnityåŒ…ä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªå¼€æ”¾æºä»£ç çš„å¹³å°ï¼Œå¯è‡ªç”±å®šåˆ¶å¹¶æ‰©å±•å…¶åŠŸèƒ½ã€‚è¿™å°†æœ‰åŠ©äºç¤¾åŒºæ¨åŠ¨XRæŠ€æœ¯çš„åˆ›æ–°å’Œå‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04671">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec01f6d807daf99cea58aa7d4906756e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90d7d8da6b3bb3b9a79de2dd574a8070.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-273f6ac1d026cc6465dee7b4dc46e0d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7298009103c19166d86615b5e16a162.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AgentSquare-Automatic-LLM-Agent-Search-in-Modular-Design-Space"><a href="#AgentSquare-Automatic-LLM-Agent-Search-in-Modular-Design-Space" class="headerlink" title="AgentSquare: Automatic LLM Agent Search in Modular Design Space"></a>AgentSquare: Automatic LLM Agent Search in Modular Design Space</h2><p><strong>Authors:Yu Shang, Yu Li, Keyu Zhao, Likai Ma, Jiahe Liu, Fengli Xu, Yong Li</strong></p>
<p>Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidating the collective efforts of research community. Code repo is available at <a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/AgentSquare">https://github.com/tsinghua-fib-lab/AgentSquare</a>. </p>
<blockquote>
<p>è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å¯¼è‡´èƒ½å¤Ÿå¤„ç†å„ç§å¤æ‚ä»»åŠ¡çš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿè¿…é€Ÿå¢é•¿ã€‚ç„¶è€Œï¼Œå½“å‰çš„ç ”ç©¶ä¸»è¦ä¾èµ–äºæ‰‹åŠ¨ã€é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„è®¾è®¡ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¯¹æ–°ä»»åŠ¡çš„é€‚åº”æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç ”ç©¶é—®é¢˜ï¼šæ¨¡å—åŒ–LLMä»£ç†æœç´¢ï¼ˆMoLASï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¨¡å—åŒ–è®¾è®¡ç©ºé—´ï¼Œå®ƒå°†ç°æœ‰çš„LLMä»£ç†è®¾è®¡æŠ½è±¡ä¸ºå››ä¸ªå…·æœ‰ç»Ÿä¸€IOæ¥å£çš„åŸºæœ¬æ¨¡å—ï¼šè§„åˆ’ã€æ¨ç†ã€å·¥å…·ä½¿ç”¨å’Œè®°å¿†ã€‚åŸºäºè¿™ä¸ªè®¾è®¡ç©ºé—´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„LLMä»£ç†æœç´¢æ¡†æ¶ï¼Œåä¸ºAgentSquareã€‚å®ƒå¼•å…¥äº†ä¸¤ä¸ªæ ¸å¿ƒæœºåˆ¶ï¼Œå³æ¨¡å—è¿›åŒ–å’Œé‡ç»„ï¼Œä»¥æœ‰æ•ˆåœ°æœç´¢ä¼˜åŒ–LLMä»£ç†ã€‚ä¸ºäº†è¿›ä¸€æ­¥åŠ é€Ÿè¿™ä¸€è¿‡ç¨‹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ€§èƒ½é¢„æµ‹å™¨ï¼Œå®ƒä½¿ç”¨ä¸Šä¸‹æ–‡æ›¿ä»£æ¨¡å‹æ¥è·³è¿‡æ²¡æœ‰å‰é€”çš„ä»£ç†è®¾è®¡ã€‚åœ¨æ¶µç›–ç½‘é¡µã€å®ä½“ã€å·¥å…·ä½¿ç”¨å’Œæ¸¸æˆåº”ç”¨ç¨‹åºç­‰å¤šä¸ªåœºæ™¯çš„å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAgentSquareæ˜¾è‘—ä¼˜äºæ‰‹å·¥åˆ¶ä½œçš„ä»£ç†ï¼Œä¸å·²çŸ¥çš„æœ€ä½³äººç±»è®¾è®¡ç›¸æ¯”ï¼Œå¹³å‡æ€§èƒ½æå‡17.2%ã€‚æ­¤å¤–ï¼ŒAgentSquareå¯ä»¥ç”Ÿæˆå¯è§£é‡Šçš„è®¾è®¡è§è§£ï¼Œä½¿äººä»¬å¯¹ä»£ç†æ¶æ„åŠå…¶å¯¹ä»»åŠ¡æ€§èƒ½çš„å½±å“æœ‰æ›´æ·±å…¥çš„ç†è§£ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæ¨¡å—åŒ–è®¾è®¡ç©ºé—´å’ŒAgentSquareæœç´¢æ¡†æ¶ä¸ºå……åˆ†åˆ©ç”¨ç°æœ‰æˆåŠŸè®¾è®¡çš„æ½œåŠ›ä»¥åŠæ•´åˆç ”ç©¶ç¤¾åŒºçš„é›†ä½“åŠªåŠ›æä¾›äº†ä¸€ä¸ªå¹³å°ã€‚ä»£ç ä»“åº“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/AgentSquare%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/tsinghua-fib-lab/AgentSquareæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.06153v3">PDF</a> 25 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ï¼Œå¹¶æŒ‡å‡ºå½“å‰ç ”ç©¶ä¸»è¦ä¾èµ–äºæ‰‹åŠ¨ä»»åŠ¡ç‰¹å®šçš„è®¾è®¡ï¼Œé™åˆ¶äº†å…¶é€‚åº”æ–°ä»»åŠ¡çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ç ”ç©¶é—®é¢˜ï¼šæ¨¡å—åŒ–LLMä»£ç†æœç´¢ï¼ˆMoLASï¼‰ï¼Œå¹¶åŸºäºæ­¤è®¾è®¡ç©ºé—´æå‡ºäº†ä¸€ç§åä¸ºAgentSquareçš„LLMä»£ç†æœç´¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡å—è¿›åŒ–å’Œé‡ç»„ç­‰æ ¸å¿ƒæœºåˆ¶ï¼Œèƒ½å¤Ÿé«˜æ•ˆæœç´¢ä¼˜åŒ–LLMä»£ç†ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€ä¸ªæ€§èƒ½é¢„æµ‹å™¨ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡æ›¿ä»£æ¨¡å‹æ¥è·³è¿‡æ— å¸Œæœ›çš„ä»£ç†è®¾è®¡ã€‚å®éªŒè¡¨æ˜ï¼ŒAgentSquareåœ¨å¤šç§åº”ç”¨åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºæ‰‹å·¥è®¾è®¡çš„ä»£ç†ï¼Œå¹³å‡æ€§èƒ½æå‡17.2%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•æ¨åŠ¨äº†agenticç³»ç»Ÿçš„å¿«é€Ÿå‘å±•ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§å¤æ‚ä»»åŠ¡ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦ä¾èµ–æ‰‹åŠ¨ä»»åŠ¡ç‰¹å®šçš„è®¾è®¡ï¼Œé™åˆ¶äº†å…¶é€‚åº”æ–°ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†æ¨¡å—åŒ–LLMä»£ç†æœç´¢ï¼ˆMoLASï¼‰çš„æ–°ç ”ç©¶é—®é¢˜ã€‚</li>
<li>ä»‹ç»äº†åŸºäºæ¨¡å—åŒ–è®¾è®¡çš„AgentSquareæœç´¢æ¡†æ¶ï¼ŒåŒ…æ‹¬æ¨¡å—è¿›åŒ–ã€é‡ç»„ç­‰æ ¸å¿ƒæœºåˆ¶ã€‚</li>
<li>è®¾è®¡äº†æ€§èƒ½é¢„æµ‹å™¨ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡æ›¿ä»£æ¨¡å‹è·³è¿‡æ— å¸Œæœ›çš„ä»£ç†è®¾è®¡ã€‚</li>
<li>AgentSquareåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæ‰‹å·¥è®¾è®¡çš„ä»£ç†ï¼Œå¹³å‡æ€§èƒ½æå‡17.2%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.06153">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cd3dc801521612b7b0a3eeceb1a5d79d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd02d898e71e3ad9dbfe0e817e071dab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5092420f03b646f0d980ab05f009b97e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73ce517dcfb43fde86abee372cb4d185.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="InsightBench-Evaluating-Business-Analytics-Agents-Through-Multi-Step-Insight-Generation"><a href="#InsightBench-Evaluating-Business-Analytics-Agents-Through-Multi-Step-Insight-Generation" class="headerlink" title="InsightBench: Evaluating Business Analytics Agents Through Multi-Step   Insight Generation"></a>InsightBench: Evaluating Business Analytics Agents Through Multi-Step   Insight Generation</h2><p><strong>Authors:Gaurav Sahu, Abhay Puri, Juan Rodriguez, Amirhossein Abaskohi, Mohammad Chegini, Alexandre Drouin, Perouz Taslakian, Valentina Zantedeschi, Alexandre Lacoste, David Vazquez, Nicolas Chapados, Christopher Pal, Sai Rajeswar Mudumba, Issam Hadj Laradji</strong></p>
<p>Data analytics is essential for extracting valuable insights from data that can assist organizations in making effective decisions. We introduce InsightBench, a benchmark dataset with three key features. First, it consists of 100 datasets representing diverse business use cases such as finance and incident management, each accompanied by a carefully curated set of insights planted in the datasets. Second, unlike existing benchmarks focusing on answering single queries, InsightBench evaluates agents based on their ability to perform end-to-end data analytics, including formulating questions, interpreting answers, and generating a summary of insights and actionable steps. Third, we conducted comprehensive quality assurance to ensure that each dataset in the benchmark had clear goals and included relevant and meaningful questions and analysis. Furthermore, we implement a two-way evaluation mechanism using LLaMA-3 as an effective, open-source evaluator to assess agentsâ€™ ability to extract insights. We also propose AgentPoirot, our baseline data analysis agent capable of performing end-to-end data analytics. Our evaluation on InsightBench shows that AgentPoirot outperforms existing approaches (such as Pandas Agent) that focus on resolving single queries. We also compare the performance of open- and closed-source LLMs and various evaluation strategies. Overall, this benchmark serves as a testbed to motivate further development in comprehensive automated data analytics and can be accessed here: <a target="_blank" rel="noopener" href="https://github.com/ServiceNow/insight-bench">https://github.com/ServiceNow/insight-bench</a>. </p>
<blockquote>
<p>æ•°æ®åˆ†æå¯¹äºä»æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„è§è§£ä»¥ååŠ©ç»„ç»‡åšå‡ºæœ‰æ•ˆå†³ç­–è‡³å…³é‡è¦ã€‚æˆ‘ä»¬ä»‹ç»äº†InsightBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰ä¸‰ä¸ªå…³é”®ç‰¹å¾çš„æ ‡å‡†æ•°æ®é›†ã€‚é¦–å…ˆï¼Œå®ƒåŒ…å«äº†100ä¸ªä»£è¡¨å„ç§å•†ä¸šç”¨ä¾‹çš„æ•°æ®é›†ï¼Œå¦‚é‡‘èå’Œäº‹ä»¶ç®¡ç†ï¼Œæ¯ä¸ªæ•°æ®é›†éƒ½é…æœ‰ä¸€ç»„ç²¾å¿ƒç­–åˆ’çš„è§è§£ã€‚å…¶æ¬¡ï¼Œä¸ç°æœ‰ä¸»è¦å›ç­”å•ä¸€æŸ¥è¯¢çš„æµ‹è¯•ä¸åŒï¼ŒInsightBenchåŸºäºä»£ç†æ‰§è¡Œç«¯åˆ°ç«¯æ•°æ®åˆ†æçš„èƒ½åŠ›è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬æå‡ºé—®é¢˜ã€è§£é‡Šç­”æ¡ˆå’Œç”Ÿæˆè§è§£å’Œå¯æ“ä½œçš„æ­¥éª¤æ‘˜è¦ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å…¨é¢çš„è´¨é‡ä¿è¯ï¼Œä»¥ç¡®ä¿æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ•°æ®é›†éƒ½æœ‰æ˜ç¡®çš„ç›®æ ‡ï¼ŒåŒ…æ‹¬ç›¸å…³å’Œæœ‰æ„ä¹‰çš„é—®é¢˜å’Œåˆ†æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨LLaMA-3ä½œä¸ºæœ‰æ•ˆçš„å¼€æºè¯„ä¼°å™¨ï¼Œå®æ–½åŒå‘è¯„ä¼°æœºåˆ¶ï¼Œä»¥è¯„ä¼°ä»£ç†æå–è§è§£çš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åŸºçº¿æ•°æ®åˆ†æä»£ç†AgentPoirotï¼Œèƒ½å¤Ÿæ‰§è¡Œç«¯åˆ°ç«¯æ•°æ®åˆ†æã€‚æˆ‘ä»¬åœ¨InsightBenchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒAgentPoirotä¼˜äºç°æœ‰æ–¹æ³•ï¼ˆå¦‚Pandas Agentï¼‰ï¼Œè¿™äº›æ–¹æ³•ä¸“æ³¨äºè§£å†³å•ä¸€æŸ¥è¯¢ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†å¼€æºå’Œé—­æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ä»¥åŠå„ç§è¯„ä¼°ç­–ç•¥ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªåŸºå‡†æµ‹è¯•ä¸ºå…¨é¢è‡ªåŠ¨åŒ–æ•°æ®åˆ†æçš„è¿›ä¸€æ­¥å‘å±•æä¾›äº†åŠ¨åŠ›ï¼Œå¹¶å¯ä»¥åœ¨æ­¤å¤„è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/ServiceNow/insight-bench">https://github.com/ServiceNow/insight-bench</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.06423v4">PDF</a> Accepted to ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†InsightBenchæ•°æ®é›†çš„é‡è¦æ€§ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ä¸ªå…³é”®ç‰¹å¾ï¼šåŒ…å«å¤šç§ä¸šåŠ¡ç”¨ä¾‹çš„æ•°æ®é›†ï¼Œæ³¨é‡ç«¯åˆ°ç«¯æ•°æ®åˆ†æèƒ½åŠ›çš„è¯„ä¼°ï¼Œä»¥åŠå®æ–½å…¨é¢çš„è´¨é‡ä¿è¯ã€‚åŒæ—¶ä»‹ç»äº†åŸºäºè¯¥æ•°æ®é›†çš„åŸºå‡†æ•°æ®åˆ†æä»£ç†AgentPoirotã€‚æ­¤æ•°æ®é›†æ—¨åœ¨ä½œä¸ºç»¼åˆè‡ªåŠ¨åŒ–æ•°æ®åˆ†æçš„è¯•éªŒåœºï¼Œæ¿€åŠ±è¿›ä¸€æ­¥çš„å‘å±•ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·è®¿é—®ä¸Šè¿°GitHubé“¾æ¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>InsightBenchæ˜¯ä¸€ä¸ªåŒ…å«å¤šç§ä¸šåŠ¡ç”¨ä¾‹çš„æ•°æ®é›†ï¼Œæ—¨åœ¨å¸®åŠ©ç»„ç»‡åšå‡ºæœ‰æ•ˆå†³ç­–ã€‚æ¯ä¸ªæ•°æ®é›†éƒ½åŒ…å«ç²¾å¿ƒç­–åˆ’çš„è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.06423">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-925c6c09abccb1d3aa195232115e4f8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60fc60bb54905f41c18d537313684af6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ed18328eddc0a0aff563cc0a60731c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a6b5c054390f230630d305020836c786.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Sports-Traj-A-Unified-Trajectory-Generation-Model-for-Multi-Agent-Movement-in-Sports"><a href="#Sports-Traj-A-Unified-Trajectory-Generation-Model-for-Multi-Agent-Movement-in-Sports" class="headerlink" title="Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent   Movement in Sports"></a>Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent   Movement in Sports</h2><p><strong>Authors:Yi Xu, Yun Fu</strong></p>
<p>Understanding multi-agent movement is critical across various fields. The conventional approaches typically focus on separate tasks such as trajectory prediction, imputation, or spatial-temporal recovery. Considering the unique formulation and constraint of each task, most existing methods are tailored for only one, limiting the ability to handle multiple tasks simultaneously, which is a common requirement in real-world scenarios. Another limitation is that widely used public datasets mainly focus on pedestrian movements with casual, loosely connected patterns, where interactions between individuals are not always present, especially at a long distance, making them less representative of more structured environments. To overcome these limitations, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios in the domain of sports games. Specifically, we introduce a Ghost Spatial Masking (GSM) module, embedded within a Transformer encoder, for spatial feature extraction. We further extend recent State Space Models (SSMs), known as the Mamba model, into a Bidirectional Temporal Mamba (BTM) to better capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to thoroughly scan trajectories while preserving temporal missing relationships. Furthermore, we curate and benchmark three practical sports datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. We hope that our work can advance the understanding of human movement in real-world applications, particularly in sports. Our datasets, code, and model weights are available here <a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch">https://github.com/colorfulfuture/UniTraj-pytorch</a>. </p>
<blockquote>
<p>ç†è§£å¤šæ™ºèƒ½ä½“è¿åŠ¨å¯¹äºå„ä¸ªé¢†åŸŸéƒ½è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„æ–¹æ³•é€šå¸¸ä¾§é‡äºå•ç‹¬çš„ä»»åŠ¡ï¼Œå¦‚è½¨è¿¹é¢„æµ‹ã€å¡«è¡¥æˆ–æ—¶ç©ºæ¢å¤ã€‚è€ƒè™‘åˆ°æ¯ä¸ªä»»åŠ¡çš„ç‹¬ç‰¹å…¬å¼å’Œçº¦æŸï¼Œç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•éƒ½æ˜¯é’ˆå¯¹å…¶ä¸­ä¸€ä¸ªä»»åŠ¡å®šåˆ¶çš„ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡çš„èƒ½åŠ›ï¼Œè€Œåœ¨ç°å®åœºæ™¯ä¸­è¿™æ˜¯å¸¸è§çš„è¦æ±‚ã€‚å¦ä¸€ä¸ªå±€é™æ€§æ˜¯å¹¿æ³›ä½¿ç”¨çš„å…¬å…±æ•°æ®é›†ä¸»è¦å…³æ³¨è¡Œäººè¿åŠ¨çš„å¶ç„¶æ€§å’Œæ¾æ•£è¿æ¥çš„æ¨¡å¼ï¼Œå…¶ä¸­ä¸ªä½“ä¹‹é—´çš„äº’åŠ¨å¹¶éæ€»æ˜¯å­˜åœ¨ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿œè·ç¦»æƒ…å†µä¸‹ï¼Œè¿™ä½¿å¾—å®ƒä»¬æ— æ³•å……åˆ†ä»£è¡¨æ›´å¤æ‚çš„ç¯å¢ƒç»“æ„ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è½¨è¿¹ç”Ÿæˆæ¨¡å‹UniTrajï¼Œå®ƒå¯ä»¥å¤„ç†ä»»æ„è½¨è¿¹ä½œä¸ºé®ç½©è¾“å…¥ï¼Œé€‚åº”äºä½“è‚²æ¸¸æˆé¢†åŸŸçš„ä¸åŒåœºæ™¯ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨Transformerç¼–ç å™¨å†…éƒ¨å¼•å…¥äº†ä¸€ä¸ªGhost Spatial Maskingï¼ˆGSMï¼‰æ¨¡å—è¿›è¡Œç©ºé—´ç‰¹å¾æå–ã€‚æˆ‘ä»¬å°†æœ€è¿‘çš„State Space Modelsï¼ˆSSMsï¼‰å³Mambaæ¨¡å‹è¿›ä¸€æ­¥æ‰©å±•ä¸ºåŒå‘æ—¶åºMambaï¼ˆBTMï¼‰ï¼Œä»¥æ›´å¥½åœ°æ•æ‰æ—¶é—´ä¾èµ–æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬èå…¥äº†åŒå‘æ—¶åºç¼©æ”¾ï¼ˆBTSï¼‰æ¨¡å—ï¼Œå…¨é¢æ‰«æè½¨è¿¹çš„åŒæ—¶ä¿ç•™æ—¶é—´ç¼ºå¤±å…³ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ•´ç†å¹¶è¯„ä¼°äº†ä¸‰ä¸ªå®ç”¨çš„ä½“è‚²æ•°æ®é›†ï¼Œå³Basketball-Uã€Football-Uå’ŒSoccer-Uæ•°æ®é›†è¿›è¡Œè¯„ä¼°ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ¨¡å‹çš„å“è¶Šæ€§èƒ½ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶èƒ½å¤Ÿæ¨åŠ¨å¯¹äººç±»è¿åŠ¨åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„ç†è§£ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½“è‚²é¢†åŸŸã€‚æˆ‘ä»¬çš„æ•°æ®é›†ã€ä»£ç å’Œæ¨¡å‹æƒé‡å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/colorfulfuture/UniTraj-pytorchä¸Šè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17680v2">PDF</a> Accepted by ICLR 2025. Datasets, code, and model weights are   available at: <a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch">https://github.com/colorfulfuture/UniTraj-pytorch</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»Ÿä¸€è½¨è¿¹ç”Ÿæˆæ¨¡å‹UniTrajï¼Œç”¨äºå¤„ç†ä»»æ„è½¨è¿¹ä½œä¸ºæ©ç è¾“å…¥ï¼Œå¹¶é€‚åº”ä½“è‚²é¢†åŸŸä¸­çš„ä¸åŒåœºæ™¯ã€‚æ¨¡å‹åŒ…å«Ghost Spatial Maskingæ¨¡å—ä»¥æå–ç©ºé—´ç‰¹å¾ï¼Œå¹¶æ‰©å±•äº†åŒå‘æ—¶é—´Mambaæ¨¡å‹ä»¥åŠåŒå‘æ—¶é—´ç¼©æ”¾æ¨¡å—ä»¥å…¨é¢æ‰«æè½¨è¿¹å¹¶ä¿ç•™æ—¶é—´ç¼ºå¤±å…³ç³»ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ä¹Ÿä»‹ç»äº†ä¸‰ä¸ªå®ç”¨ä½“è‚²æ•°æ®é›†Basketball-Uã€Football-Uå’ŒSoccer-Uï¼Œç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¯æ˜è¯¥æ¨¡å‹æ€§èƒ½å“è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šé¢†åŸŸä¸‹çš„å¤šæ™ºèƒ½ä½“è¿åŠ¨ç†è§£è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å…³æ³¨å•ç‹¬ä»»åŠ¡ï¼Œå¦‚è½¨è¿¹é¢„æµ‹ã€å¡«è¡¥æˆ–æ—¶ç©ºæ¢å¤ï¼Œéš¾ä»¥åº”å¯¹ç°å®ä¸–ç•Œä¸­çš„å¤šä»»åŠ¡éœ€æ±‚ã€‚</li>
<li>å…¬å…±æ•°æ®é›†ä¸»è¦å…³æ³¨è¡Œäººè¿åŠ¨ï¼Œå¿½è§†ä¸ªä½“é—´äº¤äº’ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿œè·ç¦»ç¯å¢ƒä¸‹ã€‚</li>
<li>æå‡ºç»Ÿä¸€è½¨è¿¹ç”Ÿæˆæ¨¡å‹UniTrajï¼Œé€‚åº”å¤šç§åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯ä½“è‚²é¢†åŸŸã€‚</li>
<li>UniTrajåŒ…å«Ghost Spatial Maskingæ¨¡å—ä»¥æå–ç©ºé—´ç‰¹å¾ï¼Œå¹¶ç»“åˆåŒå‘æ—¶é—´Mambaæ¨¡å‹å’ŒåŒå‘æ—¶é—´ç¼©æ”¾æ¨¡å—æ¥å¤„ç†è½¨è¿¹ã€‚</li>
<li>ä»‹ç»äº†ä¸‰ä¸ªä½“è‚²æ•°æ®é›†Basketball-Uã€Football-Uå’ŒSoccer-Uç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17680">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4deb700fccc96a507464211a8e2801b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79a7bcf6390c939bfeb0203d961339d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-226d753e9a88dcf9de0ae24810eff87c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72fa3c9e2ed27dce96d87e6355ca2859.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="How-Far-Are-We-on-the-Decision-Making-of-LLMs-Evaluating-LLMsâ€™-Gaming-Ability-in-Multi-Agent-Environments"><a href="#How-Far-Are-We-on-the-Decision-Making-of-LLMs-Evaluating-LLMsâ€™-Gaming-Ability-in-Multi-Agent-Environments" class="headerlink" title="How Far Are We on the Decision-Making of LLMs? Evaluating LLMsâ€™ Gaming   Ability in Multi-Agent Environments"></a>How Far Are We on the Decision-Making of LLMs? Evaluating LLMsâ€™ Gaming   Ability in Multi-Agent Environments</h2><p><strong>Authors:Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R. Lyu</strong></p>
<p>Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMsâ€™ decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\gamma$)-Bench, a new framework for evaluating LLMsâ€™ Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMsâ€™ performance. $\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at <a target="_blank" rel="noopener" href="https://github.com/CUHK-ARISE/GAMABench">https://github.com/CUHK-ARISE/GAMABench</a>. </p>
<blockquote>
<p>å†³ç­–æ˜¯ä¸€ä¸ªéœ€è¦å¤šç§èƒ½åŠ›çš„å¤æ‚è¿‡ç¨‹ï¼Œå› æ­¤å®ƒæ˜¯è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»ä½³æ¡†æ¶ã€‚ç ”ç©¶äººå‘˜å·²ç»é€šè¿‡åšå¼ˆè®ºçš„è§’åº¦ç ”ç©¶äº†LLMçš„å†³ç­–åˆ¶å®šã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨ä¸¤äººåœºæ™¯ä¸­ï¼Œå³LLMä¸å…¶ä»–LLMä¹‹é—´çš„ç«äº‰ã€‚æ­¤å¤–ï¼Œå…ˆå‰çš„åŸºå‡†æµ‹è¯•ç”±äºå…¶é™æ€è®¾è®¡è€Œé­å—æµ‹è¯•é›†æ³„éœ²çš„é—®é¢˜ã€‚æˆ‘ä»¬å¼•å…¥äº†GAMA($\gamma$)-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„æ¸¸æˆèƒ½åŠ›ã€‚å®ƒåŒ…æ‹¬å…«ä¸ªç»å…¸çš„æ¸¸æˆç†è®ºåœºæ™¯å’Œä¸€ä¸ªåŠ¨æ€è¯„åˆ†æ–¹æ¡ˆï¼Œä¸“é—¨ç”¨äºå®šé‡è¯„ä¼°LLMçš„æ€§èƒ½ã€‚$\gamma$-Benchå…è®¸çµæ´»çš„æ¸¸æˆè®¾ç½®ï¼Œå¹¶é€‚åº”ä¸åŒçš„æ¸¸æˆå‚æ•°æ¥è°ƒæ•´è¯„åˆ†ç³»ç»Ÿï¼Œä»è€Œå…¨é¢è¯„ä¼°LLMçš„ç¨³å¥æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œæ”¹è¿›ç­–ç•¥ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒGPT-3.5è¡¨ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§ï¼Œä½†æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œå¯ä»¥é€šè¿‡é“¾å¼æ€ç»´ç­‰æ–¹æ³•è¿›è¡Œå¢å¼ºã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æ¥è‡ªå…­ä¸ªæ¨¡å‹å®¶æ—çš„13ä¸ªLLMï¼ŒåŒ…æ‹¬GPT-3.5ã€GPT-4ã€åŒå­åº§ã€LLaMA-3.1ã€Mixtralå’ŒQwen-2ã€‚å…¶ä¸­ï¼ŒåŒå­åº§-1.5-Proè¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†ä¸º100ä¸­çš„69.8åˆ†ï¼Œå…¶æ¬¡æ˜¯LLaMA-3.1-70Bï¼ˆ65.9åˆ†ï¼‰å’ŒMixtral-8x22Bï¼ˆ62.4åˆ†ï¼‰ã€‚æˆ‘ä»¬çš„ä»£ç å’Œå®éªŒç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/CUHK-ARISE/GAMABench%E5%85%AC%E5%BC%80%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/CUHK-ARISE/GAMABenchå…¬å¼€è·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.11807v6">PDF</a> Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;   Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,   Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,   Qwen-2-72B</p>
<p><strong>Summary</strong><br>å†³ç­–åˆ¶å®šæ˜¯ä¸€ä¸ªéœ€è¦å¤šå…ƒèƒ½åŠ›çš„å¤æ‚è¿‡ç¨‹ï¼Œæ˜¯è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç†æƒ³æ¡†æ¶ã€‚ç ”ç©¶è€…é€šè¿‡åšå¼ˆè®ºçš„è§’åº¦ç ”ç©¶LLMsçš„å†³ç­–åˆ¶å®šè¿‡ç¨‹ï¼Œä½†ç°æœ‰çš„è¯„ä¼°ä¸»è¦èšç„¦äºä¸¤ç©å®¶æƒ…å¢ƒï¼Œè®¾è®¡é™æ€è¯„ä¼°æ–¹å¼å®¹æ˜“äº§ç”Ÿæµ‹è¯•é›†æ³„æ¼é—®é¢˜ã€‚æœ¬æ–‡æå‡ºGAMA($\gamma$)-Benchæ–°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMsåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„æ¸¸æˆèƒ½åŠ›ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å…«ä¸ªç»å…¸åšå¼ˆè®ºåœºæ™¯å’ŒåŠ¨æ€è¯„åˆ†æœºåˆ¶ï¼Œèƒ½å®šé‡è¯„ä¼°LLMsè¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºGPT-3.5è¡¨ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§ä½†æœ‰é™çš„å¯æ³›åŒ–æ€§ï¼Œå¯é€šè¿‡é“¾å¼æ€ç»´ç­‰æ–¹æ³•æ”¹è¿›ã€‚æœ¬æ–‡è¿˜è¯„ä¼°äº†å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬GPTç³»åˆ—ã€Geminiã€LLaMAå’ŒMixtralç­‰ã€‚ä»£ç å’Œå®éªŒç»“æœå·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å†³ç­–åˆ¶å®šèƒ½åŠ›å¯é€šè¿‡æ¸¸æˆç†è®ºè¿›è¡Œè¯„ä¼°ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ¡†æ¶ä¸»è¦å…³æ³¨ä¸¤ç©å®¶æƒ…å¢ƒï¼Œå­˜åœ¨æµ‹è¯•é›†æ³„æ¼é—®é¢˜ã€‚</li>
<li>GAMA($\gamma$)-Benchæ¡†æ¶ç”¨äºè¯„ä¼°LLMsåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„æ¸¸æˆèƒ½åŠ›ï¼ŒåŒ…å«å…«ä¸ªç»å…¸åšå¼ˆè®ºåœºæ™¯å’ŒåŠ¨æ€è¯„åˆ†æœºåˆ¶ã€‚</li>
<li>GPT-3.5åœ¨è¯„ä¼°ä¸­æ˜¾ç¤ºå‡ºå¼ºå¤§çš„ç¨³å¥æ€§ï¼Œä½†æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚</li>
<li>ä½¿ç”¨é“¾å¼æ€ç»´ç­‰æ–¹æ³•å¯æ”¹è¿›LLMsçš„è¡¨ç°ã€‚</li>
<li>åœ¨è¯„ä¼°ä¸­ï¼ŒGemini-1.5-Proè¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯LLaMA-3.1å’ŒMixtralã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.11807">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-64507863ea9ddb3035349baae441888e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8efba2ecd89df792cbb3223412e25fd3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3747aa23e21f63b5f58d1f6fc8f8982.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Optimal-number-of-agents-in-a-collective-search-and-when-to-launch-them"><a href="#Optimal-number-of-agents-in-a-collective-search-and-when-to-launch-them" class="headerlink" title="Optimal number of agents in a collective search, and when to launch them"></a>Optimal number of agents in a collective search, and when to launch them</h2><p><strong>Authors:Hugues Meyer, Heiko Rieger</strong></p>
<p>Search processes often involve multiple agents that collectively search a randomly located target. While increasing the number of agents usually decreases the time at which the first agent finds the target, it also requires resources to create and sustain more agents. In this manuscript, we raise the question of the optimal timing for launching multiple agents in a search in order to reach the best compromise between minimizing the overall search time and minimizing the costs associated with launching and sustaining agents. After introducing a general formalism for independent agents in which we allow them to be launched at arbitrary times, we investigate by means of analytical calculations and numerical optimization the optimal launch strategies to optimize the quantiles of the search cost and its mean. Finally, we compare our results with the case of stochastic resetting and study the conditions under which it is preferable to launch new searchers rather than resetting the first one to its initial position. </p>
<blockquote>
<p>åœ¨æœç´¢è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šæ¶‰åŠå¤šä¸ªæœç´¢ä¸»ä½“å…±åŒå¯»æ‰¾éšæœºä½ç½®çš„ç›®æ ‡ã€‚è™½ç„¶å¢åŠ æœç´¢ä¸»ä½“çš„æ•°é‡é€šå¸¸ä¼šå‡å°‘é¦–ä¸ªæœç´¢ä¸»ä½“æ‰¾åˆ°ç›®æ ‡çš„æ—¶é—´ï¼Œä½†åŒæ—¶ä¹Ÿéœ€è¦èµ„æºæ¥åˆ›å»ºå’Œç»´æŒæ›´å¤šçš„æœç´¢ä¸»ä½“ã€‚åœ¨æœ¬æ‰‹ç¨¿ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å…³äºä½•æ—¶å¯åŠ¨å¤šä¸ªæœç´¢ä¸»ä½“ä»¥è¾¾åˆ°æœ€ä½³å¹³è¡¡çš„é—®é¢˜ï¼Œæ—¨åœ¨å°½é‡å‡å°‘æ€»ä½“æœç´¢æ—¶é—´å¹¶é™ä½å¯åŠ¨å’Œç»´æŒæœç´¢ä¸»ä½“çš„æˆæœ¬ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…è®¸å®ƒä»¬åœ¨ä»»æ„æ—¶é—´å¯åŠ¨çš„ç‹¬ç«‹ä¸»ä½“çš„é€šç”¨å½¢å¼åŒ–è¡¨ç¤ºæ–¹æ³•ï¼Œç„¶åé€šè¿‡è§£æè®¡ç®—å’Œæ•°å€¼ä¼˜åŒ–æ¥ç ”ç©¶æœ€ä½³å¯åŠ¨ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–æœç´¢æˆæœ¬çš„åˆ†ä½æ•°å’Œå¹³å‡å€¼ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„ç»“æœä¸éšæœºé‡ç½®çš„æƒ…å†µè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶ç ”ç©¶åœ¨ä½•ç§æƒ…å†µä¸‹å¯åŠ¨æ–°çš„æœç´¢è€…ä¼˜äºå°†ç¬¬ä¸€ä¸ªæœç´¢è€…é‡ç½®åˆ°å…¶åˆå§‹ä½ç½®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.05851v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å¤šä»£ç†æœç´¢è¿‡ç¨‹ä¸­çš„æœ€ä¼˜å¯åŠ¨æ—¶é—´é—®é¢˜ï¼Œæ—¨åœ¨å¯»æ‰¾æœ€å°åŒ–æ€»ä½“æœç´¢æ—¶é—´ä¸é™ä½å¯åŠ¨å’Œç»´æŒä»£ç†çš„æˆæœ¬ä¹‹é—´çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚æ–‡ç« å¼•å…¥äº†ç‹¬ç«‹ä»£ç†çš„ä¸€èˆ¬å½¢å¼ï¼Œåˆ†æäº†é€šè¿‡è§£æè®¡ç®—å’Œæ•°å€¼ä¼˜åŒ–å¾—å‡ºçš„æœ€ä¼˜å¯åŠ¨ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–æœç´¢æˆæœ¬çš„åˆ†ä½æ•°å’Œå‡å€¼ã€‚æ­¤å¤–ï¼Œè¿˜å°†ç»“æœä¸éšæœºé‡ç½®çš„æƒ…å†µè¿›è¡Œäº†æ¯”è¾ƒï¼Œç ”ç©¶äº†åœ¨ä½•ç§æ¡ä»¶ä¸‹å¯åŠ¨æ–°æœç´¢å™¨æ¯”å°†ç¬¬ä¸€ä¸ªæœç´¢å™¨é‡ç½®åˆ°åˆå§‹ä½ç½®æ›´ä¸ºå¯å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥ç‹¬ç«‹ä»£ç†çš„ä¸€èˆ¬å½¢å¼ï¼Œå…è®¸å®ƒä»¬åœ¨ä»»æ„æ—¶é—´å¯åŠ¨ã€‚</li>
<li>æ¢è®¨äº†å¤šä»£ç†æœç´¢ä¸­çš„æœ€ä¼˜å¯åŠ¨æ—¶é—´é—®é¢˜ã€‚</li>
<li>é€šè¿‡è§£æè®¡ç®—å’Œæ•°å€¼ä¼˜åŒ–ï¼Œç ”ç©¶äº†æœ€ä¼˜å¯åŠ¨ç­–ç•¥ä»¥ä¼˜åŒ–æœç´¢æˆæœ¬ã€‚</li>
<li>å¯¹æ¯”äº†éšæœºé‡ç½®ä¸å¯åŠ¨æ–°æœç´¢å™¨çš„æ•ˆæœã€‚</li>
<li>æ­ç¤ºäº†å¯»æ‰¾æœ€å°åŒ–æ€»ä½“æœç´¢æ—¶é—´ä¸é™ä½å¯åŠ¨å’Œç»´æŒä»£ç†çš„æˆæœ¬ä¹‹é—´çš„æœ€ä½³å¹³è¡¡ç‚¹çš„é‡è¦æ€§ã€‚</li>
<li>åˆ†æäº†å¤šä»£ç†æœç´¢åœ¨ç¼©çŸ­æœç´¢æ—¶é—´æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä»¥åŠèµ„æºåˆ†é…çš„ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.05851">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8c30a5ea7c54569bb4aec12f0207ad5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95b3db2316b70691ae597cfd67cc0a9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09840ae369ec07cab02e55b159bf3ed3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-593c21be0b41d2de9448ef561decc258.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-51fffe4934492fbe293e82110d97630c.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-01  Self-Training Elicits Concise Reasoning in Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6f1411ab09e736020130cdd8d94a5c7e.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-01  R2-T2 Re-Routing in Test-Time for Multimodal Mixture-of-Experts
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18723.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
