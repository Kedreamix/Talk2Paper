<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-03-01  Multi-Agent Verification Scaling Test-Time Compute with Multiple   Verifiers">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-84d4f38d510f1dbd809b3d5331d556ad.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    18.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    78 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-01-更新"><a href="#2025-03-01-更新" class="headerlink" title="2025-03-01 更新"></a>2025-03-01 更新</h1><h2 id="Multi-Agent-Verification-Scaling-Test-Time-Compute-with-Multiple-Verifiers"><a href="#Multi-Agent-Verification-Scaling-Test-Time-Compute-with-Multiple-Verifiers" class="headerlink" title="Multi-Agent Verification: Scaling Test-Time Compute with Multiple   Verifiers"></a>Multi-Agent Verification: Scaling Test-Time Compute with Multiple   Verifiers</h2><p><strong>Authors:Shalev Lifshitz, Sheila A. McIlraith, Yilun Du</strong></p>
<p>By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time. </p>
<blockquote>
<p>通过测试时利用更多的计算资源，大型语言模型（LLM）可以在无需额外训练的情况下进行改进。一种常见策略是使用验证器来评估候选输出。在这项工作中，我们为测试时的计算提出了一种新型扩展维度：扩展验证器的数量。我们引入了多代理验证（MAV）作为测试时计算范式，它将多个验证器结合起来以提高性能。我们建议使用方面验证器（AV）作为MAV中验证器的一种可能选择，方面验证器是即插即用的LLM，通过提示来验证输出的不同方面。方面验证器是MAV的便捷构建块，可以轻易组合而无需额外训练。此外，我们介绍了BoN-MAV，一种简单的多代理验证算法，它将最佳n采样与多个验证器相结合。BoN-MAV表现出比自我一致性奖励模型验证更强的扩展模式。我们展示了从弱到强的泛化，即组合弱验证器可以改善更强大的LLM，以及自我改进，即使用同一基础模型来生成和验证输出。我们的结果将扩展验证器数量确立为提高语言模型测试时性能的有前途的新维度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20379v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在测试时可以利用更多的计算资源来提高性能，而无需额外的训练。本文提出了一种新的测试时计算维度——增加验证器的数量。我们提出了多代理验证（MAV）作为测试时计算范式，该范式结合了多个验证器以提高性能。介绍了一种可用于MAV的验证器选择——方面验证器（AV）。最后，我们提出了BoN-MAV算法，该算法结合了多个验证器的最佳n采样方法。BoN-MAV表现出比自我一致性奖励模型验证更强的扩展模式，并展示了从弱到强的泛化能力和自我改进能力。研究结果表明，增加验证器的数量是提高语言模型测试性能的一个有前途的新维度。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>利用更多的计算资源，大型语言模型（LLM）可以在测试阶段提高性能，无需额外训练。</li>
<li>提出了一种新的测试时计算维度：增加验证器的数量。</li>
<li>引入了多代理验证（MAV）作为测试时计算范式，结合了多个验证器以提高性能。</li>
<li>方面验证器（AV）可以作为MAV系统中的一种验证器选择。</li>
<li>BoN-MAV算法结合了多个验证器的最佳n采样方法，表现出较强的扩展模式。</li>
<li>BoN-MAV实现了弱到强的泛化和自我改进能力。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20379">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b2b76a62b0fde8b559d0309c285dac75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-201dbf6a0def84242a23493acd57d1a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d7fad77f7243459384cbd85863a2ab4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1336bd377a42deb455d8003898741945.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-693e8166ef1b67b991cfeda3ced6181f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="M-3Builder-A-Multi-Agent-System-for-Automated-Machine-Learning-in-Medical-Imaging"><a href="#M-3Builder-A-Multi-Agent-System-for-Automated-Machine-Learning-in-Medical-Imaging" class="headerlink" title="M^3Builder: A Multi-Agent System for Automated Machine Learning in   Medical Imaging"></a>M^3Builder: A Multi-Agent System for Automated Machine Learning in   Medical Imaging</h2><p><strong>Authors:Jinghao Feng, Qiaoyu Zheng, Chaoyi Wu, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie</strong></p>
<p>Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks. However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models. In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging. At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training. These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution. (ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data. (iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging. </p>
<blockquote>
<p>医学人工智能系统因其自主执行复杂任务的能力而受到广泛关注。然而，它们对准备良好的工具的依赖限制了它们在医学领域的应用，医学领域需要训练专门的模型。在本文中，我们做出了三个贡献：（一）我们提出了M3Builder，这是一个新型多智能体系统，旨在自动化医学影像中的机器学习（ML）。M3Builder的核心是四个专业智能体，它们协同解决复杂的医学ML工作流程，包括自动化数据处理和环境配置，以及自我包含的自动调试和模型训练。这些智能体在医学影像ML工作空间内运行，这是一个结构化环境，旨在为智能体提供数据集、训练代码和交互工具的文本描述，从而实现无缝通信和任务执行。（二）为了评估医学成像自动化的ML进度，我们提出了M3Bench，这是一个基准测试，包含五个解剖部位和三种成像模式的14个训练数据集上的四个通用任务，涵盖二维和三维数据。（三）我们在系统中使用了七个最先进的大型语言模型作为智能体的核心，例如Claude系列、GPT-4o和DeepSeek-V3。与现有的ML智能体设计相比，M3Builder在完成医学影像中的ML任务时表现出卓越的性能。使用Claude-3.7-Sonnet作为智能体核心时，成功率为94.29%，显示出在医学影像中完全自动化机器学习的巨大潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20301v1">PDF</a> 38 pages, 7 figures</p>
<p><strong>摘要</strong><br>    M3Builder是一种新型多智能体系统，专为自动化医学影像机器学习而设计。通过四个专门智能体的协作，实现医学影像机器学习的复杂多步骤流程自动化，包括数据处理、环境配置、自我调试和模型训练等。提出M3Bench基准测试，用于评估自动化医学影像机器学习进展。实验显示，M3Builder在医学影像机器学习任务上表现出卓越性能，使用Claude-3.7-Sonnet作为智能核心，成功率为94.29%。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>M3Builder是一个新型多智能体系统，专为自动化医学影像机器学习而设计。</li>
<li>M3Builder通过四个专门智能体解决医学影像机器学习的复杂流程。</li>
<li>M3Builder提供了一个医学影像机器学习的工作空间，促进智能体间的无缝沟通和任务执行。</li>
<li>M3Bench基准测试用于评估自动化医学影像机器学习的进展。</li>
<li>实验表明M3Builder在医学影像机器学习任务上表现优越。</li>
<li>使用Claude-3.7-Sonnet作为智能核心的M3Builder成功率为94.29%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20301">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-84d4f38d510f1dbd809b3d5331d556ad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d74b3f214371bf5356a15a34d72428ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edbf97479d5a11c6c804e54f4702b477.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MARVEL-Multi-Agent-Reinforcement-Learning-for-constrained-field-of-View-multi-robot-Exploration-in-Large-scale-environments"><a href="#MARVEL-Multi-Agent-Reinforcement-Learning-for-constrained-field-of-View-multi-robot-Exploration-in-Large-scale-environments" class="headerlink" title="MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View   multi-robot Exploration in Large-scale environments"></a>MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View   multi-robot Exploration in Large-scale environments</h2><p><strong>Authors:Jimmy Chiun, Shizhe Zhang, Yizhuo Wang, Yuhong Cao, Guillaume Sartoretti</strong></p>
<p>In multi-robot exploration, a team of mobile robot is tasked with efficiently mapping an unknown environments. While most exploration planners assume omnidirectional sensors like LiDAR, this is impractical for small robots such as drones, where lightweight, directional sensors like cameras may be the only option due to payload constraints. These sensors have a constrained field-of-view (FoV), which adds complexity to the exploration problem, requiring not only optimal robot positioning but also sensor orientation during movement. In this work, we propose MARVEL, a neural framework that leverages graph attention networks, together with novel frontiers and orientation features fusion technique, to develop a collaborative, decentralized policy using multi-agent reinforcement learning (MARL) for robots with constrained FoV. To handle the large action space of viewpoints planning, we further introduce a novel information-driven action pruning strategy. MARVEL improves multi-robot coordination and decision-making in challenging large-scale indoor environments, while adapting to various team sizes and sensor configurations (i.e., FoV and sensor range) without additional training. Our extensive evaluation shows that MARVEL’s learned policies exhibit effective coordinated behaviors, outperforming state-of-the-art exploration planners across multiple metrics. We experimentally demonstrate MARVEL’s generalizability in large-scale environments, of up to 90m by 90m, and validate its practical applicability through successful deployment on a team of real drone hardware. </p>
<blockquote>
<p>在多机器人探测过程中，一组移动机器人被赋予高效地图未知环境的任务。虽然大多数探测规划器都假设使用像激光雷达这样的全方位传感器，但对于无人机这样的小型机器人来说，由于有效载荷限制，使用轻量级、定向的传感器（如摄像机）可能是唯一的选择，这实际上是不可行的。这些传感器的视野（FoV）受限，增加了探测问题的复杂性，不仅要求机器人位置最优，而且在移动过程中还需要传感器方向。在本研究中，我们提出了MARVEL，一个利用图注意力网络结合新的边界和定向特征融合技术的神经网络框架，采用多智能体强化学习（MARL）为视野受限的机器人开发协作、分散化的策略。为了处理视点规划中的大动作空间，我们进一步引入了一种新的信息驱动动作修剪策略。MARVEL改进了多机器人在具有挑战性的大规模室内环境中的协调和决策能力，能够适应各种团队规模和传感器配置（即视野和传感器范围）而无需额外的训练。我们的广泛评估表明，MARVEL所学习的策略表现出有效的协调行为，在多个指标上超过了最新的探索规划器。我们在实验中展示了MARVEL在高达90米乘90米的大规模环境中的通用性，并通过成功部署在实际无人机硬件上验证了其实用性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20217v1">PDF</a> \c{opyright} 20XX IEEE. Personal use of this material is permitted.   Permission from IEEE must be obtained for all other uses, in any current or   future media, including reprinting&#x2F;republishing this material for advertising   or promotional purposes, creating new collective works, for resale or   redistribution to servers or lists, or reuse of any copyrighted component of   this work in other works</p>
<p><strong>Summary</strong></p>
<p>本文提出一个名为MARVEL的神经网络框架，用于解决多机器人探索中因视野受限导致的复杂问题。该框架结合图注意力网络、前沿和方位特征融合技术，通过多智能体强化学习（MARL）发展协作式分散政策，适用于视野受限的机器人。为解决视角规划的大动作空间问题，引入信息驱动的动作修剪策略。MARVEL提高了机器人在具有挑战性的大型室内环境中的协调性和决策能力，并能适应各种团队规模和传感器配置，无需额外训练。评估结果表明，MARVEL的学习策略表现出有效的协调行为，在多个指标上优于当前最先进的探索规划器。并在大型环境中进行了实验验证其通用性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MARVEL是一个神经网络框架，用于解决多机器人探索中的复杂问题。</li>
<li>该框架针对视野受限的机器人设计，利用图注意力网络和强化学习进行决策。</li>
<li>MARVEL引入了前沿和方位特征融合技术，以提高机器人的探索效率。</li>
<li>通过信息驱动的动作修剪策略解决大动作空间问题。</li>
<li>MARVEL提高了机器人在大型室内环境中的协调性和决策能力。</li>
<li>该框架能够适应不同的团队规模和传感器配置，且无需额外训练。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20217">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-16ee3897eebab18d1eca6b29cfa61130.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15bfd113117281487ded698a4d01a44d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce053a5c0c0d2065a4011b3b0f3b7a67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd8e072334a1bbfeb80f79285f8a8e81.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-29e9257f21e4350471c49a94ce001665.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a49335a08cf8aa72058c4ba9005eda3a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Collab-Overcooked-Benchmarking-and-Evaluating-Large-Language-Models-as-Collaborative-Agents"><a href="#Collab-Overcooked-Benchmarking-and-Evaluating-Large-Language-Models-as-Collaborative-Agents" class="headerlink" title="Collab-Overcooked: Benchmarking and Evaluating Large Language Models as   Collaborative Agents"></a>Collab-Overcooked: Benchmarking and Evaluating Large Language Models as   Collaborative Agents</h2><p><strong>Authors:Haochen Sun, Shuwen Zhang, Lei Ren, Hao Xu, Hao Fu, Caixia Yuan, Xiaojie Wang</strong></p>
<p>Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at <a target="_blank" rel="noopener" href="https://github.com/YusaeMeow/Collab-Overcooked">https://github.com/YusaeMeow/Collab-Overcooked</a>. </p>
<blockquote>
<p>基于大型语言模型（LLM）的代理系统在传统NLP任务之外的现实世界应用中取得了巨大进步。本文提出了一个新的由LLM驱动的多代理系统（LLM-MAS）基准测试，名为Collab-Overcooked，它是在流行的Overcooked-AI游戏上构建，拥有更多适用于交互式环境中的挑战性任务。Collab-Overcooked从两个新颖的角度扩展了现有的基准测试。首先，它提供了一个支持多样任务和目标的多代理框架，并通过自然语言交流鼓励协作。其次，它引入了一系列面向过程的评估指标，来评估不同LLM代理的精妙协作能力，这是以前工作中经常被忽视的一个维度。我们对10个流行的LLM进行了广泛实验，结果表明，虽然LLM在目标解释方面表现出很强能力，但在主动协作和持续适应方面存在显著差异，这对于有效地完成复杂任务至关重要。值得注意的是，我们突出了LLM-MAS的优势和劣势，并提供了一个统一和开源的基准测试来改进和评估LLM-MAS。环境、30个开放任务和一个集成评估包现在可通过<a target="_blank" rel="noopener" href="https://github.com/YusaeMeow/Collab-Overcooked%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/YusaeMeow/Collab-Overcooked公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20073v1">PDF</a> 25 pages, 14 figures</p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）的代理系统在现实世界应用和传统NLP任务之外取得了巨大进步。本文提出了一个新的LLM驱动的多代理系统（LLM-MAS）基准测试——Collab-Overcooked，它是在流行的Overcooked-AI游戏上构建的，具有更适用和更具挑战性的交互式环境中的任务。Collab-Overcooked从两个新颖的角度扩展了现有的基准测试。首先，它提供了一个支持多样任务和目标的多代理框架，并通过自然语言交流鼓励协作。其次，它引入了一系列面向过程的评估指标，以评估不同LLM代理的精细协作能力，这是以前工作中经常被忽视的一个维度。我们对10个流行的LLM进行了广泛实验，结果表明，虽然LLM在目标解读方面表现出很强能力，但在主动协作和持续适应方面存在显著差异，这对于有效完成复杂任务至关重要。我们强调了LLM-MAS的优点和缺点，并为在统一和开源基准上改进和评估LLM-MAS提供了见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在现实世界应用中的进步显著，已应用于超出传统NLP任务的多代理系统。</li>
<li>新基准测试Collab-Overcooked基于Overcooked-AI游戏构建，适用于评估多代理系统的性能。</li>
<li>Collab-Overcooked提供多代理框架，支持多样任务和目标的处理，并鼓励通过自然语言交流进行协作。</li>
<li>基准测试引入了面向过程的评估指标，以评估LLM代理的精细协作能力，这是以前被忽视的重要方面。</li>
<li>实验显示LLM在目标解读方面表现出强大的能力，但在主动协作和持续适应方面存在差异。</li>
<li>公共可用的环境和任务以及集成评估包有助于改进和评估LLM-MAS。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20073">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-621542d11f6c10b7e70154cbd5afbe0e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c8904c59f34ea4edeff782912cc87b66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9406eddc9f5cc58a79eeb183da96e31d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e914e7a11d3dd7f9c1af3286444408e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-79359379e6b30c152d23bf6152ac74d3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Generative-Model-Enhanced-Multi-Agent-Reinforcement-Learning-Method-for-Electric-Vehicle-Charging-Navigation"><a href="#A-Generative-Model-Enhanced-Multi-Agent-Reinforcement-Learning-Method-for-Electric-Vehicle-Charging-Navigation" class="headerlink" title="A Generative Model Enhanced Multi-Agent Reinforcement Learning Method   for Electric Vehicle Charging Navigation"></a>A Generative Model Enhanced Multi-Agent Reinforcement Learning Method   for Electric Vehicle Charging Navigation</h2><p><strong>Authors:Tianyang Qi, Shibo Chen, Jun Zhang</strong></p>
<p>With the widespread adoption of electric vehicles (EVs), navigating for EV drivers to select a cost-effective charging station has become an important yet challenging issue due to dynamic traffic conditions, fluctuating electricity prices, and potential competition from other EVs. The state-of-the-art deep reinforcement learning (DRL) algorithms for solving this task still require global information about all EVs at the execution stage, which not only increases communication costs but also raises privacy issues among EV drivers. To overcome these drawbacks, we introduce a novel generative model-enhanced multi-agent DRL algorithm that utilizes only the EV’s local information while achieving performance comparable to these state-of-the-art algorithms. Specifically, the policy network is implemented on the EV side, and a Conditional Variational Autoencoder-Long Short Term Memory (CVAE-LSTM)-based recommendation model is developed to provide recommendation information. Furthermore, a novel future charging competition encoder is designed to effectively compress global information, enhancing training performance. The multi-gradient descent algorithm (MGDA) is also utilized to adaptively balance the weight between the two parts of the training objective, resulting in a more stable training process. Simulations are conducted based on a practical area in Xi&#39;an, China. Experimental results show that our proposed algorithm, which relies on local information, outperforms existing local information-based methods and achieves less than 8% performance loss compared to global information-based methods. </p>
<blockquote>
<p>随着电动汽车（EV）的广泛应用，对于电动汽车驾驶员来说，选择性价比高的充电站导航成为一个重要且具有挑战性的问题，这主要是由于动态的交通状况、波动的电价以及来自其他电动汽车的潜在竞争。最先进的深度强化学习（DRL）算法在解决此任务时仍需要在执行阶段获取所有电动汽车的全局信息，这不仅增加了通信成本，而且引发了电动汽车驾驶员之间的隐私问题。为了克服这些缺点，我们引入了一种新型生成模型增强的多智能体深度强化学习算法，该算法仅利用电动汽车的本地信息，同时实现了与这些最先进的算法相当的性能。具体来说，策略网络在电动汽车端实现，并开发了一个基于条件变分自动编码器-长短时记忆（CVAE-LSTM）的推荐模型，以提供推荐信息。此外，设计了一种新型的未来充电竞争编码器，有效地压缩全局信息，提高训练性能。还利用多梯度下降算法（MGDA）自适应地平衡训练目标中两部分的权重，从而实现更稳定的训练过程。模拟实验基于中国西安的实际区域进行。实验结果表明，我们提出的依赖本地信息的算法在性能上优于现有的基于本地信息的方法，与基于全局信息的方法相比，性能损失低于8%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20068v1">PDF</a> </p>
<p><strong>总结</strong></p>
<p>随着电动汽车（EV）的广泛应用，EV司机选择经济高效的充电站变得至关重要，但同时也面临动态交通条件、电价波动和其他EV的竞争等挑战。针对此问题，现有的深度强化学习（DRL）算法在执行阶段需要关于所有EV的全局信息，这不仅增加了通信成本，还引发了EV司机之间的隐私问题。为了克服这些缺点，我们提出了一种新型生成模型增强的多智能体DRL算法，该算法仅利用EV的本地信息，同时实现了与这些最先进的算法相当的性能。具体来说，策略网络在EV端实现，并开发了一种基于条件变分自动编码器-长短期记忆（CVAE-LSTM）的推荐模型，以提供推荐信息。此外，设计了一种新型的未来充电竞争编码器，有效地压缩全局信息，提高训练性能。还利用多梯度下降算法（MGDA）自适应地平衡训练目标中两部分之间的权重，使训练过程更加稳定。在中国西安的实际区域进行了模拟实验。实验结果表明，我们所提出的依赖本地信息的算法在性能上优于现有的基于本地信息的方法，与基于全局信息的方法相比性能损失不到8%。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>广泛采用电动汽车（EV）导致选择成本效益高的充电站变得重要且具挑战性。</li>
<li>现有深度强化学习（DRL）算法需要所有EV的全局信息，增加了通信成本和隐私问题。</li>
<li>提出了一种新型生成模型增强的多智能体DRL算法，仅利用EV的本地信息。</li>
<li>策略网络在EV端实现，采用CVAE-LSTM推荐模型提供推荐信息。</li>
<li>设计了未来充电竞争编码器以压缩全局信息并提高训练性能。</li>
<li>使用多梯度下降算法（MGDA）自适应平衡训练目标中的不同部分。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20068">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-61696841d49ea69a977ba5eabbc4f516.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8283eb161f43866b82bc8a6f361fe69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed3f2dde387774d6acf1bfd697faa09d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a43868f78e48903b6c16153fe506b12f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c7a659e3d9f187fe031aa8963019507.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a07fcc4720143ec8140ace542ccb47f4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Picking-the-Cream-of-the-Crop-Visual-Centric-Data-Selection-with-Collaborative-Agents"><a href="#Picking-the-Cream-of-the-Crop-Visual-Centric-Data-Selection-with-Collaborative-Agents" class="headerlink" title="Picking the Cream of the Crop: Visual-Centric Data Selection with   Collaborative Agents"></a>Picking the Cream of the Crop: Visual-Centric Data Selection with   Collaborative Agents</h2><p><strong>Authors:Zhenyu Liu, Yunxin Li, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang</strong></p>
<p>To improve Multimodal Large Language Models’ (MLLMs) ability to process images and complex instructions, researchers predominantly curate large-scale visual instruction tuning datasets, which are either sourced from existing vision tasks or synthetically generated using LLMs and image descriptions. However, they often suffer from critical flaws, including misaligned instruction-image pairs and low-quality images. Such issues hinder training efficiency and limit performance improvements, as models waste resources on noisy or irrelevant data with minimal benefit to overall capability. To address this issue, we propose a \textbf{Vi}sual-Centric \textbf{S}election approach via \textbf{A}gents Collaboration (ViSA), which centers on image quality assessment and image-instruction relevance evaluation. Specifically, our approach consists of 1) an image information quantification method via visual agents collaboration to select images with rich visual information, and 2) a visual-centric instruction quality assessment method to select high-quality instruction data related to high-quality images. Finally, we reorganize 80K instruction data from large open-source datasets. Extensive experiments demonstrate that ViSA outperforms or is comparable to current state-of-the-art models on seven benchmarks, using only 2.5% of the original data, highlighting the efficiency of our data selection approach. Moreover, we conduct ablation studies to validate the effectiveness of each component of our method. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/ViSA">https://github.com/HITsz-TMG/ViSA</a>. </p>
<blockquote>
<p>为提高多模态大型语言模型（MLLMs）处理图像和复杂指令的能力，研究者主要创建大规模视觉指令微调数据集，这些数据集来源于现有的视觉任务或使用LLMs和图像描述人工合成。然而，它们经常存在关键缺陷，包括指令与图像不匹配和低质量图像。这些问题阻碍了训练效率，限制了性能提升，因为模型会在嘈杂或无关的数据上浪费资源，对整体能力益处甚微。为解决此问题，我们提出了一种以视觉为中心的通过代理协作的视觉中心选择方法（ViSA），该方法侧重于图像质量评估和图像指令相关性评估。具体来说，我们的方法包括：1）一种通过视觉代理协作的图像信息量化方法，用于选择视觉信息丰富的图像；以及2）一种以视觉为中心的指令质量评估方法，用于选择与高质量图像相关的优质指令数据。最后，我们从大型开源数据集中重新整理了8万条指令数据。大量实验表明，ViSA在七个基准测试上的表现优于或相当于当前最先进的模型，仅使用原始数据的2.5%，凸显了我们数据选择方法的高效性。此外，我们进行了剥离研究以验证我们方法的每个组件的有效性。代码可在<a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/ViSA%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HITsz-TMG/ViSA找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19917v1">PDF</a> 15 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>本文提出一种视觉为中心的选择方法——ViSA，通过视觉代理协作进行图像信息量化，选择具有丰富视觉信息的图像，并通过视觉为中心的教学指令质量评估方法选择与高质图像相关的优质教学数据。通过大规模实验验证，ViSA方法在多模态大型语言模型的图像处理和复杂指令处理方面表现优异，且仅使用原始数据的2.5%，展现了高效的数据选择能力。同时，公开了代码实现。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>研究者主要通过构建大规模视觉指令微调数据集来提升多模态大型语言模型处理图像和复杂指令的能力。</li>
<li>现有数据集存在诸多问题，如指令与图像不匹配、图像质量低下等，影响模型训练效率和性能。</li>
<li>提出ViSA方法，包括图像信息量化及视觉为中心的教学指令质量评估。</li>
<li>ViSA方法通过选择丰富视觉信息的图像和高质教学数据，显著提升模型性能。</li>
<li>实验证明ViSA方法在七个基准测试上表现优异，且使用数据仅为原数据的2.5%。</li>
<li>公开代码实现，便于他人使用和改进。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19917">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-0d286ed633556cfc60487a3cd056756d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-73b50fa3e3cb47afe140847ebcf87d36.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9455b97a19ca6841de3abd56d68ae172.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c53a62069c782517f743efa6d7f6e3ec.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Optimus-2-Multimodal-Minecraft-Agent-with-Goal-Observation-Action-Conditioned-Policy"><a href="#Optimus-2-Multimodal-Minecraft-Agent-with-Goal-Observation-Action-Conditioned-Policy" class="headerlink" title="Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action   Conditioned Policy"></a>Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action   Conditioned Policy</h2><p><strong>Authors:Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie</strong></p>
<p>Building an agent that can mimic human behavior patterns to accomplish various open-world tasks is a long-term goal. To enable agents to effectively learn behavioral patterns across diverse tasks, a key challenge lies in modeling the intricate relationships among observations, actions, and language. To this end, we propose Optimus-2, a novel Minecraft agent that incorporates a Multimodal Large Language Model (MLLM) for high-level planning, alongside a Goal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP contains (1) an Action-guided Behavior Encoder that models causal relationships between observations and actions at each timestep, then dynamically interacts with the historical observation-action sequence, consolidating it into fixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with open-ended language instructions to predict actions auto-regressively. Moreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)} dataset, which contains 25,000 videos across 8 atomic tasks, providing about 30M goal-observation-action pairs. The automated construction method, along with the MGOA dataset, can contribute to the community’s efforts to train Minecraft agents. Extensive experimental results demonstrate that Optimus-2 exhibits superior performance across atomic tasks, long-horizon tasks, and open-ended instruction tasks in Minecraft. </p>
<blockquote>
<p>构建能够模仿人类行为模式以完成各种开放世界任务的智能体是一项长期目标。为了使智能体能够在各种任务中有效地学习行为模式，关键挑战在于对观察、行动和语言之间复杂关系的建模。为此，我们提出了Optimus-2，这是一个新型Minecraft智能体，它结合了多模态大型语言模型（MLLM）进行高级规划，以及以目标-观察-行动条件策略（GOAP）进行低级控制。GOAP包含（1）行动导向行为编码器，该编码器会建模观察与行动之间的因果关系，并在每个时间步长中与历史观察-行动序列动态互动，将其整合为固定长度的行为令牌；（2）MLLM则将这些行为令牌与开放的语言指令对齐，以进行自回归行动预测。此外，我们还推出了高质量的Minecraft目标-观察-行动（MGOA）数据集，包含8个原子任务的2.5万段视频，提供约3000万的目标-观察-行动对。自动化构建方法和MGOA数据集能为社区训练Minecraft智能体的努力做出贡献。大量的实验结果表明，Optimus-2在原子任务、长期任务和开放指令任务中，在Minecraft中的表现均超群。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19902v1">PDF</a> Accept to CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种新型Minecraft智能体Optimus-2的构建过程。Optimus-2结合了多模态大型语言模型（MLLM）进行高级规划，并采用目标-观察-动作条件策略（GOAP）进行低级控制。其核心特点是行动导向行为编码器，它能建模观察与行动之间的因果关系，并动态地将其整合为固定长度的行为标记。此外，引入了高质量的Minecraft目标观察动作（MGOA）数据集，包含多种原子任务的大量数据。实验结果表明，Optimus-2在Minecraft中表现出卓越的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>介绍了一种新的Minecraft智能体Optimus-2的构建。</li>
<li>Optimus-2结合了多模态大型语言模型（MLLM）用于高级规划。</li>
<li>采用目标-观察-动作条件策略（GOAP）进行低级控制。</li>
<li>核心特点是行动导向行为编码器，可以建模观察与行动之间的因果关系。</li>
<li>引入了高质量的Minecraft目标观察动作（MGOA）数据集。</li>
<li>Optimus-2能处理多种任务，包括原子任务、长期任务和开放式指令任务。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19902">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-104d203adb08ea881a692ede7a963b19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08e81f89fe3075cc1bbcfd63d09e4444.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ec94263bdaa797765b1a36e9c350cb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbf6d4920c5eb4b0cf4b851b667fb257.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de0358e15c3de6457bf94f975d3668c2.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Exponential-Topology-enabled-Scalable-Communication-in-Multi-agent-Reinforcement-Learning"><a href="#Exponential-Topology-enabled-Scalable-Communication-in-Multi-agent-Reinforcement-Learning" class="headerlink" title="Exponential Topology-enabled Scalable Communication in Multi-agent   Reinforcement Learning"></a>Exponential Topology-enabled Scalable Communication in Multi-agent   Reinforcement Learning</h2><p><strong>Authors:Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang</strong></p>
<p>In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links-a task that becomes increasingly complex as the number of agents grows-we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/LXXXXR/ExpoComm">https://github.com/LXXXXR/ExpoComm</a>. </p>
<blockquote>
<p>在合作多智能体强化学习（MARL）中，设计良好的通信协议可以有效地促进智能体之间的共识，从而提高任务性能。此外，在现实世界应用中常见的大规模多智能体系统中，由于与小规模设置相比局部可观察性的挑战加剧，有效的通信发挥着至关重要的作用。在这项工作中，我们努力为MARL开发可扩展的通信协议。不同于以前的方法，侧重于选择最优的配对通信链接——随着智能体数量的增长，这项任务变得越来越复杂——我们对通信拓扑设计采用全局视角。具体来说，我们提出利用指数拓扑，通过利用其小直径和小规模属性，实现在智能体之间的快速信息传播。这种方法导致了一个可扩展的通信协议，称为ExpoComm。为了充分利用指数图作为通信拓扑的潜力，我们采用基于内存的消息处理器和辅助任务来确保消息反映全局信息并有益于决策。在包括MAgent和基础设施管理规划等大型合作基准测试上的广泛实验表明，与现有通信策略相比，ExpoComm具有卓越的性能和稳健的零样本迁移能力。代码公开在<a target="_blank" rel="noopener" href="https://github.com/LXXXXR/ExpoComm">https://github.com/LXXXXR/ExpoComm</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19717v1">PDF</a> Accepted by the Thirteenth International Conference on Learning   Representations (ICLR 2025)</p>
<p><strong>Summary</strong></p>
<p>在合作多智能体强化学习（MARL）中，设计良好的通信协议能有效促进智能体间的共识，从而提升任务性能。特别是在常见的大型多智能体系统中，由于部分观察性的挑战加剧，有效的通信扮演着更为关键的角色。本研究致力于开发一种适用于MARL的可扩展通信协议。不同于以往关注选择最优配对通信链接的方法（随着智能体数量的增长，该任务变得日益复杂），我们采用全局视角设计通信拓扑。具体地，我们提议利用指数拓扑，通过其小直径和小尺寸属性实现智能体间的快速信息传播。这种方法促成了一种可扩展的通信协议——ExpoComm。为充分发挥指数图作为通信拓扑的潜力，我们采用基于内存的消息处理器和辅助任务来验证信息，确保信息反映全局信息并有益于决策。在大型合作基准测试上的广泛实验，包括MAgent和基础设施管理规划，证明了ExpoComm相较于现有通信策略的优势，其具备卓越的性能和稳健的零射击转移性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>合作多智能体强化学习（MARL）中，通信协议设计对于促进智能体间共识至关重要。</li>
<li>在大型多智能体系统中，有效通信对于克服部分观察性的挑战至关重要。</li>
<li>研究人员提出了一种新的可扩展通信协议ExpoComm，采用全局视角设计通信拓扑。</li>
<li>ExpoComm利用指数拓扑实现智能体间的快速信息传播。</li>
<li>为充分发挥指数图作为通信拓扑的潜力，结合了基于内存的消息处理器和辅助任务。</li>
<li>在多个基准测试上，ExpoComm表现出卓越的性能和稳健的零射击转移性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19717">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-179bb9a5a2941b8393b8398801eafabd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8bee7dcb0c527082e64363127783b43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86ff4b8a81717da73f5e05d6a58b2803.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91e2e3d1c0aae3eceee998e4e6f0f8a9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making"><a href="#Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making" class="headerlink" title="Program Synthesis Dialog Agents for Interactive Decision-Making"></a>Program Synthesis Dialog Agents for Interactive Decision-Making</h2><p><strong>Authors:Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu</strong></p>
<p>Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns. </p>
<blockquote>
<p>现实世界中的许多资格问题，从医学诊断到税务规划，都可以映射到以自然语言表达出的决策问题，其中模型必须基于用户特征进行二元选择。大规模领域（如法律代码或经常更新的资助机会）使得人工标注（例如网页表单或决策树）变得不切实际，这突显了需要能够自动协助决策的智能体的必要性。由于相关信息通常只为用户所知，因此这些智能体提出正确的问题至关重要。智能体在决定何时结束对话时面临着准确性与所提问题数量之间的权衡，这是用户体验和成本的关键指标。为了评估这一任务，我们提出了BeNYfits，这是一个新的基准测试，用于通过交互式决策来确定用户对于多个重叠的社会福利机会的资格。我们的实验表明，当前的语言模型经常产生幻觉，GPT-4o在ReAct风格的思维链中的F1得分仅为35.7。为了解决这个问题，我们引入了ProADA这一新方法，它通过利用程序合成来协助决策，通过将对话规划映射到代码生成问题并使用结构化数据中的空白来确定最佳下一步行动。我们的智能体ProADA将F1分数提高到55.6，同时几乎保持了相同的对话轮次。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19610v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了现实世界中从医疗诊断到税务规划等多元化的资格认定问题，可转化为自然语言表达的决策问题。由于大规模领域如法律条文或频繁更新的资助机会使得人工标注不实际，因此需要能够自动协助决策的智能代理。这些智能代理需能够向用户提问以获取关键信息，并在决定何时结束对话时面临准确性提问数量之间的权衡。为评估此任务，文章提出了BeNYfits新基准测试，通过互动决策来判定用户是否适合多重重叠的社会福利机会。实验显示，当前的语言模型常有误判现象，GPT-4o在ReAct式思维链中的F1得分仅35.7。为解决此问题，文章提出了ProADA新方法，通过程序合成协助决策，将对话规划映射为代码生成问题并利用结构化数据中的空白来确定最佳下一步行动。ProADA代理能将F1得分提升至55.6%，同时保持相近的对话轮次。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现实世界的资格认定问题可以通过自然语言决策问题表达。</li>
<li>在大规模领域或频繁更新的资助机会中，人工标注变得不实际，需要自动决策的智能代理。</li>
<li>智能代理必须能够向用户提问以获取关键信息。</li>
<li>在决定何时结束对话时，智能代理需要在准确性和提问数量之间取得平衡。</li>
<li>提出新的基准测试BeNYfits用于评估互动决策效果。</li>
<li>当前语言模型存在误判现象，特别是在复杂情境中难以准确判断用户资格。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19610">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-95382c5be480b889e06f8c14bfe3c553.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf87156faef4bc9dcbd5cb2d1835d2fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4eb9334447d0c0b1576d559cc92b7f95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ed56c47c419526af1367dfa13a6f158.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e1f0e1f536bfcba4f3d7d93b1016911.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Winning-Big-with-Small-Models-Knowledge-Distillation-vs-Self-Training-for-Reducing-Hallucination-in-QA-Agents"><a href="#Winning-Big-with-Small-Models-Knowledge-Distillation-vs-Self-Training-for-Reducing-Hallucination-in-QA-Agents" class="headerlink" title="Winning Big with Small Models: Knowledge Distillation vs. Self-Training   for Reducing Hallucination in QA Agents"></a>Winning Big with Small Models: Knowledge Distillation vs. Self-Training   for Reducing Hallucination in QA Agents</h2><p><strong>Authors:Ashley Lewis, Michael White, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Ye Wang</strong></p>
<p>The deployment of Large Language Models (LLMs) in customer support is constrained by hallucination-generating false information-and the high cost of proprietary models. To address these challenges, we propose a retrieval-augmented question-answering (QA) pipeline and explore how to balance human input and automation. Using a dataset of questions about a Samsung Smart TV user manual, we demonstrate that synthetic data generated by LLMs outperforms crowdsourced data in reducing hallucination in finetuned models. We also compare self-training (fine-tuning models on their own outputs) and knowledge distillation (fine-tuning on stronger models’ outputs, e.g., GPT-4o), and find that self-training achieves comparable hallucination reduction. We conjecture that this surprising finding can be attributed to increased exposure bias issues in the knowledge distillation case and support this conjecture with post hoc analysis. We also improve robustness to unanswerable questions and retrieval failures with contextualized “I don’t know” responses. These findings show that scalable, cost-efficient QA systems can be built using synthetic data and self-training with open-source models, reducing reliance on proprietary tools or costly human annotations. </p>
<blockquote>
<p>在客户支持中部署大型语言模型（LLM）受到生成虚假信息的幻觉和高昂的专有模型成本限制。为了应对这些挑战，我们提出了一种检索增强问答（QA）管道，并探索如何平衡人工输入和自动化。我们使用有关三星智能电视用户手册的问题数据集，展示LLM生成的合成数据在减少微调模型中的幻觉方面优于众包数据。我们还比较了自训练（在模型自身输出上微调）和知识蒸馏（在更强大模型的输出上进行微调，例如GPT-4o），发现自训练可实现相当的幻觉减少效果。我们推测这一令人惊讶的发现可归因于知识蒸馏情况下的增加曝光偏见问题，并通过事后分析支持这一推测。我们还通过上下文中的“我不知道”的回应，提高了对无法回答的问题和检索失败的稳健性。这些发现表明，可以使用合成数据和自训练以及开源模型构建可扩展且成本效益高的QA系统，减少了对专有工具或昂贵的人力标注的依赖。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19545v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在客服支持中的应用受到生成虚假信息和专有模型成本高昂的限制。为解决这些挑战，我们提出了检索增强问答（QA）管道，并探讨了如何平衡人工输入和自动化。使用关于三星智能电视用户手册的问题数据集，我们证明由LLM生成的人工数据在微调模型中减少了幻觉生成，优于众包数据。我们还比较了自训练（在自身输出上微调模型）和知识蒸馏（在更强大模型的输出上微调，例如GPT-4o），发现自训练可实现相当的幻觉减少效果。我们推测这一令人惊讶的发现可归因于知识蒸馏情况下的曝光偏见增加问题，并通过事后分析支持这一推测。我们还通过提供上下文“我不知道”的回应，提高了对无法回答的问题和检索失败的稳健性。这些发现表明，可使用人工数据和自训练构建可扩展、成本效益高的问答系统，减少依赖专有工具或昂贵的真人注释。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在客服支持中面临生成虚假信息和专有模型成本高昂的挑战。</li>
<li>检索增强问答（QA）管道有助于应对以上挑战。</li>
<li>使用关于三星智能电视用户手册的问题数据集，LLM生成的人工数据在减少幻觉方面优于众包数据。</li>
<li>自训练与知识蒸馏在减少幻觉方面效果相当，但自训练可能受到曝光偏见增加的影响。</li>
<li>通过提供“我不知道”的回应，提高了对无法回答的问题和检索失败的稳健性。</li>
<li>可使用人工数据和自训练构建成本效益高的问答系统。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19545">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1bc58304590c494647557492eaf5ab1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7485f4662429ab351a74f4205c745981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-334ec3cf2241de04010a2ec4bbf77570.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b576ff80854a0080a7cbf9aa68331876.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-327fe190f00d81d3c80a0ced241a8fca.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Building-reliable-sim-driving-agents-by-scaling-self-play"><a href="#Building-reliable-sim-driving-agents-by-scaling-self-play" class="headerlink" title="Building reliable sim driving agents by scaling self-play"></a>Building reliable sim driving agents by scaling self-play</h2><p><strong>Authors:Daphne Cornelisse, Aarav Pandya, Kevin Joseph, Joseph Suárez, Eugene Vinitsky</strong></p>
<p>Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing system limits, but all applications share one key requirement: reliability. To enable systematic experimentation, a simulation agent must behave as intended. It should minimize actions that may lead to undesired outcomes, such as collisions, which can distort the signal-to-noise ratio in analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents nearly solve the full training set within a day. They generalize effectively to unseen test scenes, achieving a 99.8% goal completion rate with less than 0.8% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in those cases. We open-source the pre-trained agents and integrate them with a batched multi-agent simulator. Demonstrations of agent behaviors can be found at <a target="_blank" rel="noopener" href="https://sites.google.com/view/reliable-sim-agents">https://sites.google.com/view/reliable-sim-agents</a>. </p>
<blockquote>
<p>模拟代理对于设计和测试与人类交互的系统（如自动驾驶汽车）至关重要。这些代理具有多种用途，从评估自动驾驶性能到压力测试系统限制，但所有应用程序都共享一个关键要求：可靠性。为了实现系统的实验，模拟代理必须按预期行为行事。它应尽量减少可能导致不良后果的行动，例如碰撞，这可能会在分析中扭曲信号与噪声比率。作为构建可靠的模拟代理的基础，我们建议在Waymo Open Motion数据集上，对人类感知和控制能力的半现实限制下进行成千上万的场景的自我博弈扩展。使用单个GPU从头开始训练，我们的代理在一天内几乎解决了整个训练集。他们有效地推广到未见过的测试场景，在10000个保留场景中实现了99.8％的目标完成率，碰撞和道路外事件少于0.8％。除了分布内泛化之外，我们的代理对分布外场景显示出部分稳健性，并且可以在几分钟内进行微调，以在这些情况下实现接近完美的性能。我们公开了预训练的代理，并将其与批处理的多代理模拟器集成。有关代理行为的演示，请访问：<a target="_blank" rel="noopener" href="https://sites.google.com/view/reliable-sim-agents%E3%80%82">https://sites.google.com/view/reliable-sim-agents。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14706v2">PDF</a> v2</p>
<p><strong>Summary</strong></p>
<p>本文介绍了模拟代理对于设计和测试与人类交互的系统（如自动驾驶汽车）的重要性。模拟代理可以通过在各种场景下模拟人类行为，为系统设计和测试提供可靠的实验基础。文章提出一种基于Waymo Open Motion数据集的大规模自我对弈训练方案，训练得到的代理在未见场景上表现良好，并完成目标的完成率高达99.8%，同时碰撞和离路事故率低于0.8%。这些代理被开源，并集成到一个批处理多代理模拟器中。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>模拟代理在设计和测试与人类交互的系统（如自动驾驶汽车）中扮演重要角色。</li>
<li>模拟代理的关键要求是可靠性，需要最小化可能导致意外结果的行动。</li>
<li>文章提出了一种基于Waymo Open Motion数据集的大规模自我对弈训练方案，用于创建可靠的模拟代理。</li>
<li>训练得到的代理在未见场景上表现良好，并完成目标的完成率高达99.8%。</li>
<li>这些代理具有部分对离群场景的鲁棒性，并且可以迅速微调以达到近乎完美的性能。</li>
<li>代理被开源并集成到一个批处理多代理模拟器中，以便进行更广泛的应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14706">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1ea619817dc890d50082e16353cd5a24.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d06a85ed528dc980d752eeba20270ee9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-461112367f793bfccc35a1ff115976da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92baa235796ae054060671b6554375c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eee3962d7cc21b57a24ff1627adfd32b.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="SDPO-Segment-Level-Direct-Preference-Optimization-for-Social-Agents"><a href="#SDPO-Segment-Level-Direct-Preference-Optimization-for-Social-Agents" class="headerlink" title="SDPO: Segment-Level Direct Preference Optimization for Social Agents"></a>SDPO: Segment-Level Direct Preference Optimization for Social Agents</h2><p><strong>Authors:Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang</strong></p>
<p>Social agents powered by large language models (LLMs) can simulate human social behaviors but fall short in handling complex social dialogues. Direct Preference Optimization (DPO) has proven effective in aligning LLM behavior with human preferences across various agent tasks. However, standard DPO focuses solely on individual turns, which limits its effectiveness in multi-turn social interactions. Several DPO-based multi-turn alignment methods with session-level data have shown potential in addressing this problem.While these methods consider multiple turns across entire sessions, they are often overly coarse-grained, introducing training noise, and lack robust theoretical support. To resolve these limitations, we propose Segment-Level Direct Preference Optimization (SDPO), which dynamically select key segments within interactions to optimize multi-turn agent behavior. SDPO minimizes training noise and is grounded in a rigorous theoretical framework. Evaluations on the SOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform both existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring SDPO’s potential to advance the social intelligence of LLM-based agents. We release our code and data at <a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO</a>. </p>
<blockquote>
<p>由大型语言模型（LLM）驱动的社会代理能够模拟人类的社会行为，但在处理复杂的社交对话时显得不足。直接偏好优化（DPO）在将LLM行为与各种代理任务中的人类偏好对齐方面已被证明是有效的。然而，标准DPO仅专注于个别回合，这限制了其在多回合社会互动中的有效性。一些基于DPO的多回合对齐方法使用会话级数据，已经显示出解决这个问题的潜力。虽然这些方法会考虑整个会话中的多个回合，但它们通常过于粗糙，引入训练噪声，并且缺乏坚实的理论支持。为了解决这些局限性，我们提出了分段级直接偏好优化（SDPO），它动态选择互动中的关键段落来优化多回合代理行为。SDPO最小化训练噪声，并基于严格的理论框架。在SOTOPIA基准测试上的评估表明，经过SDPO调整的代理始终优于现有的基于DPO的方法以及专有LLM，如GPT-4o，这突出了SDPO在提高基于LLM的代理的社会智能方面的潜力。我们在<a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO</a>上发布了我们的代码和数据。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01821v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型驱动的社会代理能够模拟人类社交行为，但在处理复杂社会对话方面存在不足。直接偏好优化（DPO）在将LLM行为与各种代理任务中的人类偏好对齐方面表现出成效。然而，标准DPO只关注个别回合，这在多回合社会互动中的效果有限。基于DPO的多回合对齐方法虽然考虑了整个会话中的多个回合，但它们通常过于粗糙，引入训练噪音，并且缺乏坚实的理论支持。为解决这些问题，我们提出了分段级直接偏好优化（SDPO），它动态选择互动中的关键段落进行优化。SDPO减少了训练噪音，并建立在严格的理论框架上。在SOTOPIA基准测试上的评估表明，经过SDPO调整的代理持续优于现有的基于DPO的方法和专有LLM，如GPT-4o，突显了SDPO在提升基于LLM的代理的社会智能方面的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）可以模拟人类社交行为，但在处理复杂社会对话时表现不足。</li>
<li>直接偏好优化（DPO）在LLM与人类偏好对齐方面有效，但标准DPO在多回合社会互动中的效果有限。</li>
<li>基于DPO的多回合对齐方法虽然考虑了整个会话中的多个回合，但存在训练噪音和缺乏理论支持的问题。</li>
<li>分段级直接偏好优化（SDPO）动态选择关键段落进行优化，减少训练噪音，建立在严格的理论框架上。</li>
<li>SDPO在SOTOPIA基准测试上的表现优于现有方法和专有LLM，突显其在提升LLM代理的社会智能方面的潜力。</li>
<li>代码和数据已公开可用，以便进一步研究和应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01821">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c9ec459a168935328659df3da927e4ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8066f15c42dcf10f55ad4a3983716b19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a2d6cd91b462b9104cc3e4006d58412.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-009b88b86f736885987d934f5ab4129b.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR"><a href="#CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR" class="headerlink" title="CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR"></a>CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR</h2><p><strong>Authors:Kadir Burak Buldu, Süleyman Özdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie Schönborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir</strong></p>
<p>Recent developments in computer graphics, machine learning, and sensor technologies enable numerous opportunities for extended reality (XR) setups for everyday life, from skills training to entertainment. With large corporations offering affordable consumer-grade head-mounted displays (HMDs), XR will likely become pervasive, and HMDs will develop as personal devices like smartphones and tablets. However, having intelligent spaces and naturalistic interactions in XR is as important as technological advances so that users grow their engagement in virtual and augmented spaces. To this end, large language model (LLM)–powered non-player characters (NPCs) with speech-to-text (STT) and text-to-speech (TTS) models bring significant advantages over conventional or pre-scripted NPCs for facilitating more natural conversational user interfaces (CUIs) in XR. This paper provides the community with an open-source, customizable, extendable, and privacy-aware Unity package, CUIfy, that facilitates speech-based NPC-user interaction with widely used LLMs, STT, and TTS models. Our package also supports multiple LLM-powered NPCs per environment and minimizes latency between different computational models through streaming to achieve usable interactions between users and NPCs. We publish our source code in the following repository: <a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify">https://gitlab.lrz.de/hctl/cuify</a> </p>
<blockquote>
<p>近期计算机图形学、机器学习和传感器技术的进展为扩展现实（XR）在日常生活中的运用提供了无数机会，无论是技能培训还是娱乐。随着大型企业提供经济实惠的消费级头戴显示器（HMDs），XR可能会变得普及，HMDs将像智能手机和平板电脑一样成为个人设备。然而，拥有智能空间和自然的人机交互与科技进步同样重要，使用户能够增加对虚拟和增强空间的参与度。为此，大型语言模型（LLM）驱动的非玩家角色（NPCs）使用语音识别（STT）和文本语音转换（TTS）模型，相较于传统的或预设的NPCs，为XR中更自然的对话用户界面（CUIs）带来了显著优势。本文为社区提供了一个开源、可定制、可扩展且注重隐私的Unity软件包CUIfy，它促进了基于语音的NPC与用户之间的交互，广泛使用了LLM、STT和TTS模型。我们的软件包还支持每个环境多个LLM驱动的NPCs，并通过流式传输减少不同计算模型之间的延迟，以实现用户和NPCs之间可用的交互。我们在以下存储库中发布我们的源代码：<a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify%E2%80%8D%E3%80%82">https://gitlab.lrz.de/hctl/cuify</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04671v2">PDF</a> 7th IEEE International Conference on Artificial Intelligence &amp;   eXtended and Virtual Reality (IEEE AIxVR 2025)</p>
<p><strong>Summary</strong><br>     近期计算机图形学、机器学习和传感器技术的发展为扩展现实（XR）在日常生活中的运用提供了无数机会，如技能培训和娱乐等。随着大型企业提供经济实惠的消费级头戴显示器（HMD），XR有望成为普及技术，HMD将像智能手机和平板电脑一样成为个人设备。为了提升用户在虚拟和增强空间中的参与度，智能空间和自然交互显得尤为重要。为此，利用大型语言模型（LLM）驱动的非玩家角色（NPCs）结合语音识别（STT）和文本转语音（TTS）模型，相较于传统或预设的NPCs，能为XR创造更自然的对话式用户界面（CUIs）。本文向社区提供一个开源、可定制、可扩展且注重隐私的Unity包——CUIfy，它促进了基于语音的NPC与用户之间的交互，支持广泛使用的LLMs、STT和TTS模型。我们的软件包还支持每个环境多个LLM驱动的NPCs，并通过流技术最小化不同计算模型之间的延迟，以实现用户和NPC之间的可用交互。我们的源代码发布在以下仓库中：<a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify">https://gitlab.lrz.de/hctl/cuify</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XR技术将日益普及，推动多个领域的发展。随着技术的进步和消费者设备的降低成本，XR将在日常生活中发挥重要作用。</li>
<li>智能空间和自然交互对于提高用户在虚拟和增强空间的参与度至关重要。这需要采用先进的语言模型和语音识别技术来推动人机交互的进步。</li>
<li>LLM驱动的NPCs结合STT和TTS模型能创造更自然的对话式用户界面（CUIs）。这将促进NPC角色的功能扩展并增加其可信度与互动感。</li>
<li>CUIfy工具包为开发者提供了一个强大的工具集，支持语音交互、多NPC管理和计算模型间的延迟最小化。这将简化NPC和用户之间的交互流程并提升其效率。</li>
<li>CUIfy包强调隐私保护，确保用户数据的安全性和隐私权益得到尊重。这对于确保用户在使用XR技术时的信息安全至关重要。</li>
<li>提供的Unity包为开发者提供了一个开放源代码的平台，可自由定制并扩展其功能。这将有助于社区推动XR技术的创新和发展。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04671">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ec01f6d807daf99cea58aa7d4906756e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90d7d8da6b3bb3b9a79de2dd574a8070.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-273f6ac1d026cc6465dee7b4dc46e0d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7298009103c19166d86615b5e16a162.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AgentSquare-Automatic-LLM-Agent-Search-in-Modular-Design-Space"><a href="#AgentSquare-Automatic-LLM-Agent-Search-in-Modular-Design-Space" class="headerlink" title="AgentSquare: Automatic LLM Agent Search in Modular Design Space"></a>AgentSquare: Automatic LLM Agent Search in Modular Design Space</h2><p><strong>Authors:Yu Shang, Yu Li, Keyu Zhao, Likai Ma, Jiahe Liu, Fengli Xu, Yong Li</strong></p>
<p>Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidating the collective efforts of research community. Code repo is available at <a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/AgentSquare">https://github.com/tsinghua-fib-lab/AgentSquare</a>. </p>
<blockquote>
<p>近期大型语言模型（LLM）的进步导致能够处理各种复杂任务的智能代理系统迅速增长。然而，当前的研究主要依赖于手动、针对特定任务的设计，这限制了它们对新任务的适应性。在本文中，我们引入了一个新的研究问题：模块化LLM代理搜索（MoLAS）。我们提出了一个模块化设计空间，它将现有的LLM代理设计抽象为四个具有统一IO接口的基本模块：规划、推理、工具使用和记忆。基于这个设计空间，我们提出了一种新的LLM代理搜索框架，名为AgentSquare。它引入了两个核心机制，即模块进化和重组，以有效地搜索优化LLM代理。为了进一步加速这一过程，我们设计了一个性能预测器，它使用上下文替代模型来跳过没有前途的代理设计。在涵盖网页、实体、工具使用和游戏应用程序等多个场景的六个基准测试上的大量实验表明，AgentSquare显著优于手工制作的代理，与已知的最佳人类设计相比，平均性能提升17.2%。此外，AgentSquare可以生成可解释的设计见解，使人们对代理架构及其对任务性能的影响有更深入的理解。我们相信，模块化设计空间和AgentSquare搜索框架为充分利用现有成功设计的潜力以及整合研究社区的集体努力提供了一个平台。代码仓库可在<a target="_blank" rel="noopener" href="https://github.com/tsinghua-fib-lab/AgentSquare%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/tsinghua-fib-lab/AgentSquare找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.06153v3">PDF</a> 25 pages</p>
<p><strong>Summary</strong></p>
<p>本文介绍了大型语言模型（LLM）的最新进展，并指出当前研究主要依赖于手动任务特定的设计，限制了其适应新任务的能力。为此，本文提出了一个新的研究问题：模块化LLM代理搜索（MoLAS），并基于此设计空间提出了一种名为AgentSquare的LLM代理搜索框架。该框架通过模块进化和重组等核心机制，能够高效搜索优化LLM代理。此外，还设计了一个性能预测器，使用上下文替代模型来跳过无希望的代理设计。实验表明，AgentSquare在多种应用场景下显著优于手工设计的代理，平均性能提升17.2%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）的进展推动了agentic系统的快速发展，能够处理各种复杂任务。</li>
<li>当前研究主要依赖手动任务特定的设计，限制了其适应新任务的能力。</li>
<li>提出了模块化LLM代理搜索（MoLAS）的新研究问题。</li>
<li>介绍了基于模块化设计的AgentSquare搜索框架，包括模块进化、重组等核心机制。</li>
<li>设计了性能预测器，使用上下文替代模型跳过无希望的代理设计。</li>
<li>AgentSquare在多个基准测试中显著优于手工设计的代理，平均性能提升17.2%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.06153">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-cd3dc801521612b7b0a3eeceb1a5d79d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd02d898e71e3ad9dbfe0e817e071dab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5092420f03b646f0d980ab05f009b97e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73ce517dcfb43fde86abee372cb4d185.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="InsightBench-Evaluating-Business-Analytics-Agents-Through-Multi-Step-Insight-Generation"><a href="#InsightBench-Evaluating-Business-Analytics-Agents-Through-Multi-Step-Insight-Generation" class="headerlink" title="InsightBench: Evaluating Business Analytics Agents Through Multi-Step   Insight Generation"></a>InsightBench: Evaluating Business Analytics Agents Through Multi-Step   Insight Generation</h2><p><strong>Authors:Gaurav Sahu, Abhay Puri, Juan Rodriguez, Amirhossein Abaskohi, Mohammad Chegini, Alexandre Drouin, Perouz Taslakian, Valentina Zantedeschi, Alexandre Lacoste, David Vazquez, Nicolas Chapados, Christopher Pal, Sai Rajeswar Mudumba, Issam Hadj Laradji</strong></p>
<p>Data analytics is essential for extracting valuable insights from data that can assist organizations in making effective decisions. We introduce InsightBench, a benchmark dataset with three key features. First, it consists of 100 datasets representing diverse business use cases such as finance and incident management, each accompanied by a carefully curated set of insights planted in the datasets. Second, unlike existing benchmarks focusing on answering single queries, InsightBench evaluates agents based on their ability to perform end-to-end data analytics, including formulating questions, interpreting answers, and generating a summary of insights and actionable steps. Third, we conducted comprehensive quality assurance to ensure that each dataset in the benchmark had clear goals and included relevant and meaningful questions and analysis. Furthermore, we implement a two-way evaluation mechanism using LLaMA-3 as an effective, open-source evaluator to assess agents’ ability to extract insights. We also propose AgentPoirot, our baseline data analysis agent capable of performing end-to-end data analytics. Our evaluation on InsightBench shows that AgentPoirot outperforms existing approaches (such as Pandas Agent) that focus on resolving single queries. We also compare the performance of open- and closed-source LLMs and various evaluation strategies. Overall, this benchmark serves as a testbed to motivate further development in comprehensive automated data analytics and can be accessed here: <a target="_blank" rel="noopener" href="https://github.com/ServiceNow/insight-bench">https://github.com/ServiceNow/insight-bench</a>. </p>
<blockquote>
<p>数据分析对于从数据中提取有价值的见解以协助组织做出有效决策至关重要。我们介绍了InsightBench，这是一个具有三个关键特征的标准数据集。首先，它包含了100个代表各种商业用例的数据集，如金融和事件管理，每个数据集都配有一组精心策划的见解。其次，与现有主要回答单一查询的测试不同，InsightBench基于代理执行端到端数据分析的能力进行评估，包括提出问题、解释答案和生成见解和可操作的步骤摘要。第三，我们进行了全面的质量保证，以确保数据集中的每个数据集都有明确的目标，包括相关和有意义的问题和分析。此外，我们使用LLaMA-3作为有效的开源评估器，实施双向评估机制，以评估代理提取见解的能力。我们还提出了基线数据分析代理AgentPoirot，能够执行端到端数据分析。我们在InsightBench上的评估显示，AgentPoirot优于现有方法（如Pandas Agent），这些方法专注于解决单一查询。我们还比较了开源和闭源大型语言模型（LLMs）的性能以及各种评估策略。总的来说，这个基准测试为全面自动化数据分析的进一步发展提供了动力，并可以在此处访问：<a target="_blank" rel="noopener" href="https://github.com/ServiceNow/insight-bench">https://github.com/ServiceNow/insight-bench</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.06423v4">PDF</a> Accepted to ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了InsightBench数据集的重要性，该数据集包含三个关键特征：包含多种业务用例的数据集，注重端到端数据分析能力的评估，以及实施全面的质量保证。同时介绍了基于该数据集的基准数据分析代理AgentPoirot。此数据集旨在作为综合自动化数据分析的试验场，激励进一步的发展。有关详细信息，请访问上述GitHub链接。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>InsightBench是一个包含多种业务用例的数据集，旨在帮助组织做出有效决策。每个数据集都包含精心策划的见解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.06423">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-925c6c09abccb1d3aa195232115e4f8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60fc60bb54905f41c18d537313684af6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9ed18328eddc0a0aff563cc0a60731c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a6b5c054390f230630d305020836c786.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Sports-Traj-A-Unified-Trajectory-Generation-Model-for-Multi-Agent-Movement-in-Sports"><a href="#Sports-Traj-A-Unified-Trajectory-Generation-Model-for-Multi-Agent-Movement-in-Sports" class="headerlink" title="Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent   Movement in Sports"></a>Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent   Movement in Sports</h2><p><strong>Authors:Yi Xu, Yun Fu</strong></p>
<p>Understanding multi-agent movement is critical across various fields. The conventional approaches typically focus on separate tasks such as trajectory prediction, imputation, or spatial-temporal recovery. Considering the unique formulation and constraint of each task, most existing methods are tailored for only one, limiting the ability to handle multiple tasks simultaneously, which is a common requirement in real-world scenarios. Another limitation is that widely used public datasets mainly focus on pedestrian movements with casual, loosely connected patterns, where interactions between individuals are not always present, especially at a long distance, making them less representative of more structured environments. To overcome these limitations, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios in the domain of sports games. Specifically, we introduce a Ghost Spatial Masking (GSM) module, embedded within a Transformer encoder, for spatial feature extraction. We further extend recent State Space Models (SSMs), known as the Mamba model, into a Bidirectional Temporal Mamba (BTM) to better capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to thoroughly scan trajectories while preserving temporal missing relationships. Furthermore, we curate and benchmark three practical sports datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. We hope that our work can advance the understanding of human movement in real-world applications, particularly in sports. Our datasets, code, and model weights are available here <a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch">https://github.com/colorfulfuture/UniTraj-pytorch</a>. </p>
<blockquote>
<p>理解多智能体运动对于各个领域都至关重要。传统的方法通常侧重于单独的任务，如轨迹预测、填补或时空恢复。考虑到每个任务的独特公式和约束，现有的大多数方法都是针对其中一个任务定制的，这限制了它们同时处理多个任务的能力，而在现实场景中这是常见的要求。另一个局限性是广泛使用的公共数据集主要关注行人运动的偶然性和松散连接的模式，其中个体之间的互动并非总是存在，特别是在远距离情况下，这使得它们无法充分代表更复杂的环境结构。为了克服这些局限性，我们提出了一种统一的轨迹生成模型UniTraj，它可以处理任意轨迹作为遮罩输入，适应于体育游戏领域的不同场景。具体来说，我们在Transformer编码器内部引入了一个Ghost Spatial Masking（GSM）模块进行空间特征提取。我们将最近的State Space Models（SSMs）即Mamba模型进一步扩展为双向时序Mamba（BTM），以更好地捕捉时间依赖性。此外，我们融入了双向时序缩放（BTS）模块，全面扫描轨迹的同时保留时间缺失关系。此外，我们还整理并评估了三个实用的体育数据集，即Basketball-U、Football-U和Soccer-U数据集进行评估。大量实验证明了我们模型的卓越性能。我们希望我们的研究能够推动对人类运动在现实世界应用中的理解，特别是在体育领域。我们的数据集、代码和模型权重可在<a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/colorfulfuture/UniTraj-pytorch上获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17680v2">PDF</a> Accepted by ICLR 2025. Datasets, code, and model weights are   available at: <a target="_blank" rel="noopener" href="https://github.com/colorfulfuture/UniTraj-pytorch">https://github.com/colorfulfuture/UniTraj-pytorch</a></p>
<p><strong>Summary</strong></p>
<p>本文提出一种统一轨迹生成模型UniTraj，用于处理任意轨迹作为掩码输入，并适应体育领域中的不同场景。模型包含Ghost Spatial Masking模块以提取空间特征，并扩展了双向时间Mamba模型以及双向时间缩放模块以全面扫描轨迹并保留时间缺失关系。此外，本文也介绍了三个实用体育数据集Basketball-U、Football-U和Soccer-U，用于评估模型性能。实验证明该模型性能卓越。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多领域下的多智能体运动理解至关重要。</li>
<li>传统方法通常关注单独任务，如轨迹预测、填补或时空恢复，难以应对现实世界中的多任务需求。</li>
<li>公共数据集主要关注行人运动，忽视个体间交互，特别是在远距离环境下。</li>
<li>提出统一轨迹生成模型UniTraj，适应多种场景，特别是体育领域。</li>
<li>UniTraj包含Ghost Spatial Masking模块以提取空间特征，并结合双向时间Mamba模型和双向时间缩放模块来处理轨迹。</li>
<li>介绍了三个体育数据集Basketball-U、Football-U和Soccer-U用于评估模型性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17680">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4deb700fccc96a507464211a8e2801b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79a7bcf6390c939bfeb0203d961339d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-226d753e9a88dcf9de0ae24810eff87c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72fa3c9e2ed27dce96d87e6355ca2859.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="How-Far-Are-We-on-the-Decision-Making-of-LLMs-Evaluating-LLMs’-Gaming-Ability-in-Multi-Agent-Environments"><a href="#How-Far-Are-We-on-the-Decision-Making-of-LLMs-Evaluating-LLMs’-Gaming-Ability-in-Multi-Agent-Environments" class="headerlink" title="How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming   Ability in Multi-Agent Environments"></a>How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming   Ability in Multi-Agent Environments</h2><p><strong>Authors:Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R. Lyu</strong></p>
<p>Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMs’ decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\gamma$)-Bench, a new framework for evaluating LLMs’ Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMs’ performance. $\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at <a target="_blank" rel="noopener" href="https://github.com/CUHK-ARISE/GAMABench">https://github.com/CUHK-ARISE/GAMABench</a>. </p>
<blockquote>
<p>决策是一个需要多种能力的复杂过程，因此它是评估大型语言模型（LLM）的绝佳框架。研究人员已经通过博弈论的角度研究了LLM的决策制定。然而，现有的评估主要集中在两人场景中，即LLM与其他LLM之间的竞争。此外，先前的基准测试由于其静态设计而遭受测试集泄露的问题。我们引入了GAMA($\gamma$)-Bench，这是一个新的框架，用于评估LLM在多智能体环境中的游戏能力。它包括八个经典的游戏理论场景和一个动态评分方案，专门用于定量评估LLM的性能。$\gamma$-Bench允许灵活的游戏设置，并适应不同的游戏参数来调整评分系统，从而全面评估LLM的稳健性、泛化能力和改进策略。我们的结果表明，GPT-3.5表现出强大的稳健性，但泛化能力有限，可以通过链式思维等方法进行增强。我们还评估了来自六个模型家族的13个LLM，包括GPT-3.5、GPT-4、双子座、LLaMA-3.1、Mixtral和Qwen-2。其中，双子座-1.5-Pro表现最佳，得分为100中的69.8分，其次是LLaMA-3.1-70B（65.9分）和Mixtral-8x22B（62.4分）。我们的代码和实验结果可在<a target="_blank" rel="noopener" href="https://github.com/CUHK-ARISE/GAMABench%E5%85%AC%E5%BC%80%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/CUHK-ARISE/GAMABench公开获得。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.11807v6">PDF</a> Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;   Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,   Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,   Qwen-2-72B</p>
<p><strong>Summary</strong><br>决策制定是一个需要多元能力的复杂过程，是评估大型语言模型（LLMs）的理想框架。研究者通过博弈论的角度研究LLMs的决策制定过程，但现有的评估主要聚焦于两玩家情境，设计静态评估方式容易产生测试集泄漏问题。本文提出GAMA($\gamma$)-Bench新框架，用于评估LLMs在多智能体环境中的游戏能力。该框架包括八个经典博弈论场景和动态评分机制，能定量评估LLMs表现。结果显示GPT-3.5表现出强大的稳健性但有限的可泛化性，可通过链式思维等方法改进。本文还评估了多个大型语言模型，包括GPT系列、Gemini、LLaMA和Mixtral等。代码和实验结果已公开。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLMs）的决策制定能力可通过游戏理论进行评估。</li>
<li>现有评估框架主要关注两玩家情境，存在测试集泄漏问题。</li>
<li>GAMA($\gamma$)-Bench框架用于评估LLMs在多智能体环境中的游戏能力，包含八个经典博弈论场景和动态评分机制。</li>
<li>GPT-3.5在评估中显示出强大的稳健性，但泛化能力有限。</li>
<li>使用链式思维等方法可改进LLMs的表现。</li>
<li>在评估中，Gemini-1.5-Pro表现最佳，其次是LLaMA-3.1和Mixtral。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.11807">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-64507863ea9ddb3035349baae441888e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8efba2ecd89df792cbb3223412e25fd3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3747aa23e21f63b5f58d1f6fc8f8982.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Optimal-number-of-agents-in-a-collective-search-and-when-to-launch-them"><a href="#Optimal-number-of-agents-in-a-collective-search-and-when-to-launch-them" class="headerlink" title="Optimal number of agents in a collective search, and when to launch them"></a>Optimal number of agents in a collective search, and when to launch them</h2><p><strong>Authors:Hugues Meyer, Heiko Rieger</strong></p>
<p>Search processes often involve multiple agents that collectively search a randomly located target. While increasing the number of agents usually decreases the time at which the first agent finds the target, it also requires resources to create and sustain more agents. In this manuscript, we raise the question of the optimal timing for launching multiple agents in a search in order to reach the best compromise between minimizing the overall search time and minimizing the costs associated with launching and sustaining agents. After introducing a general formalism for independent agents in which we allow them to be launched at arbitrary times, we investigate by means of analytical calculations and numerical optimization the optimal launch strategies to optimize the quantiles of the search cost and its mean. Finally, we compare our results with the case of stochastic resetting and study the conditions under which it is preferable to launch new searchers rather than resetting the first one to its initial position. </p>
<blockquote>
<p>在搜索过程中，通常会涉及多个搜索主体共同寻找随机位置的目标。虽然增加搜索主体的数量通常会减少首个搜索主体找到目标的时间，但同时也需要资源来创建和维持更多的搜索主体。在本手稿中，我们提出了关于何时启动多个搜索主体以达到最佳平衡的问题，旨在尽量减少总体搜索时间并降低启动和维持搜索主体的成本。我们引入了一种允许它们在任意时间启动的独立主体的通用形式化表示方法，然后通过解析计算和数值优化来研究最佳启动策略，以优化搜索成本的分位数和平均值。最后，我们将我们的结果与随机重置的情况进行比较，并研究在何种情况下启动新的搜索者优于将第一个搜索者重置到其初始位置。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.05851v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了多代理搜索过程中的最优启动时间问题，旨在寻找最小化总体搜索时间与降低启动和维持代理的成本之间的最佳平衡点。文章引入了独立代理的一般形式，分析了通过解析计算和数值优化得出的最优启动策略，以优化搜索成本的分位数和均值。此外，还将结果与随机重置的情况进行了比较，研究了在何种条件下启动新搜索器比将第一个搜索器重置到初始位置更为可取。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>引入独立代理的一般形式，允许它们在任意时间启动。</li>
<li>探讨了多代理搜索中的最优启动时间问题。</li>
<li>通过解析计算和数值优化，研究了最优启动策略以优化搜索成本。</li>
<li>对比了随机重置与启动新搜索器的效果。</li>
<li>揭示了寻找最小化总体搜索时间与降低启动和维持代理的成本之间的最佳平衡点的重要性。</li>
<li>分析了多代理搜索在缩短搜索时间方面的优势，以及资源分配的策略。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.05851">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-8c30a5ea7c54569bb4aec12f0207ad5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95b3db2316b70691ae597cfd67cc0a9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09840ae369ec07cab02e55b159bf3ed3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-593c21be0b41d2de9448ef561decc258.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-51fffe4934492fbe293e82110d97630c.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-01  Self-Training Elicits Concise Reasoning in Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6f1411ab09e736020130cdd8d94a5c7e.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-01  R2-T2 Re-Routing in Test-Time for Multimodal Mixture-of-Experts
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">18723.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
