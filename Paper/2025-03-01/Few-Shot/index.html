<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-01  Self-Training Elicits Concise Reasoning in Large Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-51fffe4934492fbe293e82110d97630c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-01-更新"><a href="#2025-03-01-更新" class="headerlink" title="2025-03-01 更新"></a>2025-03-01 更新</h1><h2 id="Self-Training-Elicits-Concise-Reasoning-in-Large-Language-Models"><a href="#Self-Training-Elicits-Concise-Reasoning-in-Large-Language-Models" class="headerlink" title="Self-Training Elicits Concise Reasoning in Large Language Models"></a>Self-Training Elicits Concise Reasoning in Large Language Models</h2><p><strong>Authors:Tergel Munkhbat, Namgyu Ho, Seohyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun</strong></p>
<p>Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens, incurring extraneous inference costs. Upon examination of the output distribution of current LLMs, we find evidence on their latent ability to reason more concisely, relative to their default behavior. To elicit this capability, we propose simple fine-tuning methods which leverage self-generated concise reasoning paths obtained by best-of-N sampling and few-shot conditioning, in task-specific settings. Our combined method achieves a 30% reduction in output tokens on average, across five model families on GSM8K and MATH, while maintaining average accuracy. By exploiting the fundamental stochasticity and in-context learning capabilities of LLMs, our self-training approach robustly elicits concise reasoning on a wide range of models, including those with extensive post-training. Code is available at <a target="_blank" rel="noopener" href="https://github.com/TergelMunkhbat/concise-reasoning">https://github.com/TergelMunkhbat/concise-reasoning</a> </p>
<blockquote>
<p>思维链（CoT）推理使大型语言模型（LLM）能够通过中间标记利用额外的计算来解决复杂的任务。然而，我们认为典型的推理轨迹包含许多冗余的标记，产生了额外的推理成本。在检查当前LLM的输出分布时，我们发现它们相对于默认行为具有更简洁推理的潜在能力。为了激发这一能力，我们提出了简单的微调方法，这些方法利用通过最佳N采样和少样本条件在特定任务环境中生成的自我简洁推理路径。我们的组合方法在GSM8K和MATH上平均输出令牌减少了30%，同时保持了平均精度。通过利用LLM的基本随机性和上下文学习能力，我们的自训练方法在各种模型上都能激发简洁的推理能力，包括那些经过大量后期训练的模型。代码可用<a target="_blank" rel="noopener" href="https://github.com/TergelMunkhbat/concise-reasoning">https://github.com/TergelMunkhbat/concise-reasoning</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20122v1">PDF</a> 23 pages, 10 figures, 18 tables</p>
<p><strong>Summary</strong></p>
<p>基于Chain-of-thought（CoT）推理的大型语言模型（LLM）能够通过中间标记进行复杂任务的额外计算。然而，我们观察到常见的推理路径包含许多冗余标记，导致额外的推理成本。通过对当前LLM的输出分布的研究，我们发现它们相对于默认行为有潜在的更简洁推理的能力。为了激发这一能力，我们提出了简单的微调方法，利用最佳N采样和少样本条件在特定任务环境中生成自我生成的简洁推理路径。我们的综合方法在五大家族模型上平均减少了约30%的输出标记数，在GSM8K和MATH上的平均准确率得到保持。我们的自训练方法通过利用LLM的基本随机性和上下文学习能力，稳健地激发在各种模型上的简洁推理能力，包括经过广泛训练后的模型。相关代码已发布在GitHub上。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Chain-of-thought (CoT) 允许大型语言模型（LLM）通过中间标记进行额外计算来解决复杂任务。</li>
<li>通常的推理路径中存在冗余标记，增加了推理成本。</li>
<li>当前LLM具有潜在的更简洁推理能力。</li>
<li>通过最佳N采样和少样本条件的方法，可以激发LLM的简洁推理能力。</li>
<li>综合方法减少了输出标记数量，同时维持了平均准确率。</li>
<li>自训练方法能够稳健地激发各种模型（包括经过广泛训练后的模型）的简洁推理能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20122">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5943b83f8dad3d0a0ff639822708c907.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf4df0a272bce5a46a6179100a08a64a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f4f49fd89aedf26a88de006267ac2a9b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-52a205504d20d5833915ab13c9833aa7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a0742ff26a61b535f9435f3053d2465.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5718763a438227758f20955cf1036cf1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SeisMoLLM-Advancing-Seismic-Monitoring-via-Cross-modal-Transfer-with-Pre-trained-Large-Language-Model"><a href="#SeisMoLLM-Advancing-Seismic-Monitoring-via-Cross-modal-Transfer-with-Pre-trained-Large-Language-Model" class="headerlink" title="SeisMoLLM: Advancing Seismic Monitoring via Cross-modal Transfer with   Pre-trained Large Language Model"></a>SeisMoLLM: Advancing Seismic Monitoring via Cross-modal Transfer with   Pre-trained Large Language Model</h2><p><strong>Authors:Xinghao Wang, Feng Liu, Rui Su, Zhihui Wang, Lei Bai, Wanli Ouyang</strong></p>
<p>Recent advances in deep learning have revolutionized seismic monitoring, yet developing a foundation model that performs well across multiple complex tasks remains challenging, particularly when dealing with degraded signals or data scarcity. This work presents SeisMoLLM, the first foundation model that utilizes cross-modal transfer for seismic monitoring, to unleash the power of large-scale pre-training from a large language model without requiring direct pre-training on seismic datasets. Through elaborate waveform tokenization and fine-tuning of pre-trained GPT-2 model, SeisMoLLM achieves state-of-the-art performance on the DiTing and STEAD datasets across five critical tasks: back-azimuth estimation, epicentral distance estimation, magnitude estimation, phase picking, and first-motion polarity classification. It attains 36 best results out of 43 task metrics and 12 top scores out of 16 few-shot generalization metrics, with many relative improvements ranging from 10% to 50%. In addition to its superior performance, SeisMoLLM maintains efficiency comparable to or even better than lightweight models in both training and inference. These findings establish SeisMoLLM as a promising foundation model for practical seismic monitoring and highlight cross-modal transfer as an exciting new direction for earthquake studies, showcasing the potential of advanced deep learning techniques to propel seismology research forward. </p>
<blockquote>
<p>最近深度学习的发展已经彻底改变了地震监测领域，然而，开发一个能在多个复杂任务中表现良好的基础模型仍然是一个挑战，尤其是在处理退化信号或数据稀缺的情况下。本文提出了SeisMoLLM，这是第一个利用跨模态迁移进行地震监测的基础模型，它释放了大规模预训练语言模型的力量，而无需在地震数据集上进行直接的预训练。通过精细的波形令牌化（波形令牌化指的是对地震信号数据进行标记和编码）和对预训练GPT-2模型的微调，SeisMoLLM在五个关键任务上实现了最先进的性能：背方位角估计、震中距离估计、震级估计、相位拾取和首动极性分类。它在五个关键任务的性能评价中获得了最佳的三个指标（如本文中所说：“最好的 3 个任务指标的评定”），并且在此之外的另外十多项性能评价指标上也有显著的提升（相对改善范围从 10% 到 50%）。除了卓越的性能外，SeisMoLLM在训练和推理过程中保持了与轻量级模型相当的效率甚至更高。这些发现确立了SeisMoLLM作为实际地震监测中非常有前途的基础模型，并突出了跨模态迁移作为地震研究中的一项令人兴奋的新方向，展示了先进的深度学习技术在推动地震学研究前进方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19960v1">PDF</a> 13 pages, 6 figures. Code is available at   <a target="_blank" rel="noopener" href="https://github.com/StarMoonWang/SeisMoLLM">https://github.com/StarMoonWang/SeisMoLLM</a></p>
<p><strong>Summary</strong>：最新深度学习技术为地震监测带来了革命性变革，但构建一个跨多个复杂任务表现良好的基础模型仍然是一个挑战。本研究提出了SeisMoLLM，这是一个利用跨模态迁移用于地震监测的基础模型。它通过精细的波形令牌化和预训练GPT-2模型的微调，实现了在DiTing和STEAD数据集上五个关键任务的最新性能。SeisMoLLM不仅在性能上表现出卓越，还在训练和推理过程中保持了与轻量级模型相当的效率，甚至更好。这为地震监测的实际应用提供了有前途的基础模型，并突显了跨模态迁移在地震研究中的新方向。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>SeisMoLLM是首个利用跨模态迁移技术为地震监测设计的基础模型。</li>
<li>SeisMoLLM通过微调预训练的GPT-2模型，实现了在多个地震监测任务上的最新性能。</li>
<li>在DiTing和STEAD数据集上的实验表明，SeisMoLLM在五个关键任务中取得了36项最佳结果中的23项最佳成绩。</li>
<li>SeisMoLLM在少数样本推广能力方面也表现出色，在多项指标上实现了相对改善，范围在10%到50%之间。</li>
<li>与轻量级模型相比，SeisMoLLM在训练和推理过程中保持了相当的或更好的效率。</li>
<li>研究结果证明了跨模态迁移在地震研究中的潜力，为地震学研究的进一步发展提供了新的方向。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19960">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-83b0b48ca5afae6baaa4443ac5a21fa4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb02acf1f8e502ca50581b4cec166853.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7163592ea872011da8f6d7bd2e155200.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f2ef7af1225085fbacc8e1897835779.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e81c4ee3be876355cc579624764103b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0bba37d764d53fd0dc025101294caf65.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Twofold-Debiasing-Enhances-Fine-Grained-Learning-with-Coarse-Labels"><a href="#Twofold-Debiasing-Enhances-Fine-Grained-Learning-with-Coarse-Labels" class="headerlink" title="Twofold Debiasing Enhances Fine-Grained Learning with Coarse Labels"></a>Twofold Debiasing Enhances Fine-Grained Learning with Coarse Labels</h2><p><strong>Authors:Xin-yang Zhao, Jian Jin, Yang-yang Li, Yazhou Yao</strong></p>
<p>The Coarse-to-Fine Few-Shot (C2FS) task is designed to train models using only coarse labels, then leverages a limited number of subclass samples to achieve fine-grained recognition capabilities. This task presents two main challenges: coarse-grained supervised pre-training suppresses the extraction of critical fine-grained features for subcategory discrimination, and models suffer from overfitting due to biased distributions caused by limited fine-grained samples. In this paper, we propose the Twofold Debiasing (TFB) method, which addresses these challenges through detailed feature enhancement and distribution calibration. Specifically, we introduce a multi-layer feature fusion reconstruction module and an intermediate layer feature alignment module to combat the model’s tendency to focus on simple predictive features directly related to coarse-grained supervision, while neglecting complex fine-grained level details. Furthermore, we mitigate the biased distributions learned by the fine-grained classifier using readily available coarse-grained sample embeddings enriched with fine-grained information. Extensive experiments conducted on five benchmark datasets demonstrate the efficacy of our approach, achieving state-of-the-art results that surpass competitive methods. </p>
<blockquote>
<p>粗到细少数样本（C2FS）任务旨在使用仅粗标签来训练模型，然后利用有限的子类别样本实现精细的识别能力。此任务面临两个主要挑战：粗粒度监督预训练抑制了关键精细特征的提取，这不利于子类别鉴别；由于有限的精细样本导致的偏见分布，模型容易发生过度拟合。在本文中，我们提出了两阶段去偏（TFB）方法，通过详细的特征增强和分布校准来解决这些挑战。具体来说，我们引入了一种多层特征融合重建模块和中间层特征对齐模块，以解决模型倾向于关注与粗粒度监督直接相关的简单预测特征，而忽视复杂的精细级别细节的问题。此外，我们通过使用丰富的精细信息对可用的粗粒度样本嵌入来减轻精细分类器所学习的偏见分布。在五个基准数据集上进行的广泛实验证明了我们的方法的有效性，实现了超越竞争方法的最先进结果。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19816v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了Coarse-to-Fine Few-Shot任务中面临的挑战，并提出了Twofold Debiasing方法来解决这些问题。该方法通过详细的特征增强和分布校准，提高了模型的性能。实验结果表明，该方法在五个基准数据集上均取得了超过先进方法的效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Coarse-to-Fine Few-Shot任务旨在使用粗标签进行模型预训练，然后利用有限的子类样本实现精细粒度识别能力。</li>
<li>该任务面临两个主要挑战：粗粒度监督预训练抑制了关键精细粒度特征的提取，以及由于有限的精细粒度样本导致的模型过拟合问题。</li>
<li>Twofold Debiasing方法通过详细的特征增强和分布校准来解决这些挑战。</li>
<li>引入多层特征融合重建模块和中间层特征对齐模块，以解决模型过于关注与粗粒度监督直接相关的简单预测特征而忽视复杂精细粒度级别细节的问题。</li>
<li>通过使用丰富的粗粒度样本嵌入来减轻精细分类器学到的偏见分布。</li>
<li>在五个基准数据集上进行的广泛实验证明了Twifold Debiasing方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19816">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-30adc30a5095a5d36b2ed4e455360842.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d89076cb5fd4a6751010495d2919828.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54b84797c8a66fe567628a981750b7b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3c3b503ad203fc16ae26b6c39f26920d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2480f7ecc18b7a5645b49befcca73710.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b3b6460802e2b03ae6faed5cf09d9f9d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="InPK-Infusing-Prior-Knowledge-into-Prompt-for-Vision-Language-Models"><a href="#InPK-Infusing-Prior-Knowledge-into-Prompt-for-Vision-Language-Models" class="headerlink" title="InPK: Infusing Prior Knowledge into Prompt for Vision-Language Models"></a>InPK: Infusing Prior Knowledge into Prompt for Vision-Language Models</h2><p><strong>Authors:Shuchang Zhou</strong></p>
<p>Prompt tuning has become a popular strategy for adapting Vision-Language Models (VLMs) to zero&#x2F;few-shot visual recognition tasks. Some prompting techniques introduce prior knowledge due to its richness, but when learnable tokens are randomly initialized and disconnected from prior knowledge, they tend to overfit on seen classes and struggle with domain shifts for unseen ones. To address this issue, we propose the InPK model, which infuses class-specific prior knowledge into the learnable tokens during initialization, thus enabling the model to explicitly focus on class-relevant information. Furthermore, to mitigate the weakening of class information by multi-layer encoders, we continuously reinforce the interaction between learnable tokens and prior knowledge across multiple feature levels. This progressive interaction allows the learnable tokens to better capture the fine-grained differences and universal visual concepts within prior knowledge, enabling the model to extract more discriminative and generalized text features. Even for unseen classes, the learned interaction allows the model to capture their common representations and infer their appropriate positions within the existing semantic structure. Moreover, we introduce a learnable text-to-vision projection layer to accommodate the text adjustments, ensuring better alignment of visual-text semantics. Extensive experiments on 11 recognition datasets show that InPK significantly outperforms state-of-the-art methods in multiple zero&#x2F;few-shot image classification tasks. </p>
<blockquote>
<p>提示调整已成为适应视觉语言模型（VLM）到零&#x2F;少样本视觉识别任务的流行策略。一些提示技术由于其丰富性而引入了先验知识，但是，当可学习令牌随机初始化并与先验知识断开连接时，它们倾向于过度拟合已见类别，并且在面对未见类别时遇到域偏移问题。为了解决这一问题，我们提出了InPK模型，该模型在初始化期间将特定类别的先验知识注入可学习令牌中，从而使模型能够显式关注与类别相关的信息。此外，为了减轻多层编码器对类信息的削弱，我们在多个特征级别上不断加强对可学习令牌和先验知识之间的交互。这种渐进的交互允许可学习令牌更好地捕捉先验知识中的细微差别和通用视觉概念，使模型能够提取更具辨别力和泛化的文本特征。即使对于未见过的类别，学到的交互也允许模型捕捉它们的共同表示，并在现有的语义结构中推断它们的位置。此外，我们引入了一个可学习的文本到视觉投影层以适应文本调整，确保视觉文本语义的更好对齐。在11个识别数据集上的大量实验表明，InPK在多个零&#x2F;少样本图像分类任务中显著优于最新方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19777v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了如何通过InPK模型在视觉语言模型（VLMs）中融入类别特定先验知识，以解决零&#x2F;少样本视觉识别任务中的过拟合和领域偏移问题。通过初始化学习标记并融入先验知识，模型能更明确地关注类别相关信息。同时，为了减轻多层编码器对类别信息的削弱，模型在不同特征级别之间持续强化学习标记和先验知识之间的交互。这种渐进的交互使学习标记能够更好地捕捉先验知识中的细微差别和通用视觉概念，从而提取更具鉴别力和泛化的文本特征。对于未见类别，学习到的交互允许模型捕捉其共同表示并推断其在现有语义结构中的适当位置。此外，引入了可学习的文本到视觉投影层以适应文本调整，确保视觉文本语义的更好对齐。在多个零&#x2F;少样本图像分类任务中，InPK模型显著优于现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>InPK模型通过融入类别特定先验知识来解决零&#x2F;少样本视觉识别任务中的过拟合和领域偏移问题。</li>
<li>初始化学习标记并融入先验知识，使模型能更关注类别相关信息。</li>
<li>通过在不同特征级别之间强化学习标记和先验知识的交互，模型能更有效地提取文本特征。</li>
<li>学习到的交互允许模型捕捉未见类别的共同表示，并推断其在现有语义结构中的位置。</li>
<li>引入可学习的文本到视觉投影层以确保视觉文本语义的更好对齐。</li>
<li>InPK模型在多个零&#x2F;少样本图像分类任务中显著优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19777">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-578391726f8b070b5e2602190841c197.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1309c0ace0f6e2bd318572413dd499a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7085e03874b2f0eb26220af77b090ca8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-81876db154291afce807b61a6183033a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Few-Shot-Multilingual-Open-Domain-QA-from-5-Examples"><a href="#Few-Shot-Multilingual-Open-Domain-QA-from-5-Examples" class="headerlink" title="Few-Shot Multilingual Open-Domain QA from 5 Examples"></a>Few-Shot Multilingual Open-Domain QA from 5 Examples</h2><p><strong>Authors:Fan Jiang, Tom Drummond, Trevor Cohn</strong></p>
<p>Recent approaches to multilingual open-domain question answering (MLODQA) have achieved promising results given abundant language-specific training data. However, the considerable annotation cost limits the application of these methods for underrepresented languages. We introduce a \emph{few-shot learning} approach to synthesise large-scale multilingual data from large language models (LLMs). Our method begins with large-scale self-supervised pre-training using WikiData, followed by training on high-quality synthetic multilingual data generated by prompting LLMs with few-shot supervision. The final model, \textsc{FsModQA}, significantly outperforms existing few-shot and supervised baselines in MLODQA and cross-lingual and monolingual retrieval. We further show our method can be extended for effective zero-shot adaptation to new languages through a \emph{cross-lingual prompting} strategy with only English-supervised data, making it a general and applicable solution for MLODQA tasks without costly large-scale annotation. </p>
<blockquote>
<p>近期多语言开放领域问答（MLODQA）的方法在大量特定语言训练数据的支持下取得了有前景的结果。然而，巨大的标注成本限制了这些方法在代表性不足的语言中的应用。我们引入了一种“小样本学习”方法，用于从大型语言模型（LLM）中合成大规模的多语言数据。我们的方法首先使用WikiData进行大规模自监督预训练，然后通过在少量监督下提示LLM来生成高质量的多语言合成数据，进行训练。最终模型FsModQA在MLODQA以及跨语言和单语言检索方面显著优于现有的小样本和受监督的基线模型。我们进一步展示，通过仅使用英语监督数据的跨语言提示策略，我们的方法可以扩展到对新语言的有效零样本适应，使其成为无需昂贵的大规模标注的MLODQA任务的一般且适用的解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19722v1">PDF</a> Accepted by TACL; pre-MIT Press publication version</p>
<p><strong>Summary</strong><br>多语种开放域问答（MLODQA）的新方法使用大量的特定语言训练数据取得了很好的结果。但巨大的标注成本限制了这些方法在代表性不足的语言中的应用。本研究引入了基于少样本学习的策略，通过大型语言模型合成大规模多语言数据。首先通过WikiData进行大规模自监督预训练，然后通过少数样本监督生成高质量的多语言合成数据进行训练。最终模型FsModQA在MLODQA任务以及跨语言和单语言检索方面都显著超过了现有的少样本和监督基线方法。此外，该研究还展示了模型可以通过跨语言提示策略扩展到对新语言的有效零样本适应，只需英语监督数据，使其成为无需大规模标注的通用解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多语种开放域问答（MLODQA）的新方法需要大量语言特定的训练数据。</li>
<li>由于标注成本高昂，这些方法在代表性不足的语言中的应用受限。</li>
<li>研究引入基于少样本学习的策略，利用大型语言模型合成大规模多语言数据。</li>
<li>研究先进行大规模自监督预训练，再基于少数样本生成的高质量多语言合成数据进行训练。</li>
<li>最终模型FsModQA在MLODQA任务上表现优异，显著超过现有方法。</li>
<li>模型可以通过跨语言提示策略进行零样本适应，适应新语言。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19722">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-ac8781b6ceaede32665e74597aac1905.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-059654bec2fe5a7e364b668c755fa821.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-739433b5a5661149ce0728cb849e5269.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e10d100907eceb0616b8b37eec452c7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-201d5cad16244794cded5491aae46cc9.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Meta-Task-A-Method-Agnostic-Framework-for-Learning-to-Regularize-in-Few-Shot-Learning"><a href="#Meta-Task-A-Method-Agnostic-Framework-for-Learning-to-Regularize-in-Few-Shot-Learning" class="headerlink" title="Meta-Task: A Method-Agnostic Framework for Learning to Regularize in   Few-Shot Learning"></a>Meta-Task: A Method-Agnostic Framework for Learning to Regularize in   Few-Shot Learning</h2><p><strong>Authors:Mohammad Rostami, Atik Faysal, Huaxia Wang, Avimanyu Sahoo</strong></p>
<p>Overfitting is a significant challenge in Few-Shot Learning (FSL), where models trained on small, variable datasets tend to memorize rather than generalize to unseen tasks. Regularization is crucial in FSL to prevent overfitting and enhance generalization performance. To address this issue, we introduce Meta-Task, a novel, method-agnostic framework that leverages both labeled and unlabeled data to enhance generalization through auxiliary tasks for regularization. Specifically, Meta-Task introduces a Task-Decoder, which is a simple example of the broader framework that refines hidden representations by reconstructing input images from embeddings, effectively mitigating overfitting.   Our framework’s method-agnostic design ensures its broad applicability across various FSL settings. We validate Meta-Task’s effectiveness on standard benchmarks, including Mini-ImageNet, Tiered-ImageNet, and FC100, where it consistently improves existing state-of-the-art meta-learning techniques, demonstrating superior performance, faster convergence, reduced generalization error, and lower variance-all without extensive hyperparameter tuning. These results underline Meta-Task’s practical applicability and efficiency in real-world, resource-constrained scenarios. </p>
<blockquote>
<p>过拟合是Few-Shot学习（FSL）中的一个重大挑战。在FSL中，训练于小型可变数据集的模型往往倾向于记忆而非泛化到未见过的任务。正则化在FSL中至关重要，可以防止过拟合并增强泛化性能。为了解决这个问题，我们引入了Meta-Task，这是一个新的方法通用的框架，它利用有标签和无标签的数据，通过辅助任务进行正则化，以增强泛化能力。具体来说，Meta-Task引入了Task-Decoder，这是更广泛框架的一个简单示例，它通过从嵌入重构输入图像来优化隐藏表示，有效地减轻了过拟合并。我们框架的方法通用设计确保其在各种FSL设置中的广泛应用。我们在包括Mini-ImageNet、Tiered-ImageNet和FC100等标准基准测试上对Meta-Task的有效性进行了验证，它在现有的最先进的元学习技术上进行了一致的改进，表现出了优越的性能、更快的收敛速度、减少的泛化误差和较低方差，且无需进行大量的超参数调整。这些结果突出了Meta-Task在现实资源受限场景中的实际适用性和效率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18599v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>模型在小样本学习（FSL）中面临过拟合的挑战，其中模型在小型可变数据集上训练时容易记忆而非泛化到未见过的任务。正则化在FSL中至关重要，可防止过拟合并增强泛化性能。为解决这个问题，我们引入了Meta-Task这一新颖的方法论无关框架，该框架利用有标签和无标签数据，通过辅助任务进行正则化以增强泛化能力。具体来说，Meta-Task引入了任务解码器（Task-Decoder），它是更广泛框架的一个简单示例，通过从嵌入重构输入图像来优化隐藏表示，有效地减轻过拟合。我们的框架方法论无关的设计确保了其在各种FSL设置中的广泛应用。我们在包括Mini-ImageNet、Tiered-ImageNet和FC100等标准基准测试上对Meta-Task的有效性进行了验证，它在现有最先进的元学习技术上进行了改进，展示了卓越的性能、更快的收敛速度、降低的泛化误差和较低方差，且无需广泛调整超参数。这些结果突显了Meta-Task在现实世界的资源受限场景中的实际应用性和效率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>小样本学习（FSL）面临过拟合的挑战。</li>
<li>正则化在FSL中至关重要，可防止过拟合并增强模型泛化性能。</li>
<li>引入Meta-Task框架，利用有标签和无标签数据，通过辅助任务进行正则化。</li>
<li>Meta-Task包含任务解码器（Task-Decoder），通过重构输入图像来优化隐藏表示。</li>
<li>Meta-Task框架方法论无关，适用于各种FSL设置。</li>
<li>Meta-Task在标准基准测试上表现优越，包括Mini-ImageNet、Tiered-ImageNet和FC100。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.18599">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-fe7589e13dbb0501c30e2c433ef28294.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af19f30d08f653a231d8299ec8e76926.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51fffe4934492fbe293e82110d97630c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-01/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-7f7fc29b12bc5a21314e1b2bf530294d.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-03-01  ProxyTransformation Preshaping Point Cloud Manifold With Proxy   Attention For 3D Visual Grounding
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-01/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-84d4f38d510f1dbd809b3d5331d556ad.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-03-01  Multi-Agent Verification Scaling Test-Time Compute with Multiple   Verifiers
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19017.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
