<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2024-12-20  Few-shot Steerable Alignment Adapting Rewards and LLM Policies with   Neural Processes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-239ced95dfd18b784bdbadb21830bc0d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    35 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-12-20-更新"><a href="#2024-12-20-更新" class="headerlink" title="2024-12-20 更新"></a>2024-12-20 更新</h1><h2 id="Few-shot-Steerable-Alignment-Adapting-Rewards-and-LLM-Policies-with-Neural-Processes"><a href="#Few-shot-Steerable-Alignment-Adapting-Rewards-and-LLM-Policies-with-Neural-Processes" class="headerlink" title="Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with   Neural Processes"></a>Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with   Neural Processes</h2><p><strong>Authors:Katarzyna Kobalczyk, Claudio Fanconi, Hao Sun, Mihaela van der Schaar</strong></p>
<p>As large language models (LLMs) become increasingly embedded in everyday applications, ensuring their alignment with the diverse preferences of individual users has become a critical challenge. Currently deployed approaches typically assume homogeneous user objectives and rely on single-objective fine-tuning. However, human preferences are inherently heterogeneous, influenced by various unobservable factors, leading to conflicting signals in preference data. Existing solutions addressing this diversity often require costly datasets labelled for specific objectives and involve training multiple reward models or LLM policies, which is computationally expensive and impractical. In this work, we present a novel framework for few-shot steerable alignment, where users’ underlying preferences are inferred from a small sample of their choices. To achieve this, we extend the Bradley-Terry-Luce model to handle heterogeneous preferences with unobserved variability factors and propose its practical implementation for reward modelling and LLM fine-tuning. Thanks to our proposed approach of functional parameter-space conditioning, LLMs trained with our framework can be adapted to individual preferences at inference time, generating outputs over a continuum of behavioural modes. We empirically validate the effectiveness of methods, demonstrating their ability to capture and align with diverse human preferences in a data-efficient manner. Our code is made available at: <a target="_blank" rel="noopener" href="https://github.com/kasia-kobalczyk/few-shot-steerable-alignment">https://github.com/kasia-kobalczyk/few-shot-steerable-alignment</a>. </p>
<blockquote>
<p>随着大型语言模型（LLM）在日常应用中的嵌入程度越来越高，确保它们与个别用户的多样化偏好保持一致已成为一项关键挑战。当前部署的方法通常假设用户目标是统一的，并依赖于单目标微调。然而，人类偏好本质上是多样化的，受到各种不可观察因素的影响，导致偏好数据中的冲突信号。解决这种多样性的现有解决方案通常需要为特定目标标记的昂贵数据集，并涉及训练多个奖励模型或LLM策略，这在计算上很昂贵且不切实际。在这项工作中，我们提出了一种用于少样本可控对齐的新型框架，其中用户的潜在偏好是从其选择的小样本中推断出来的。为了实现这一点，我们扩展了Bradley-Terry-Luce模型，以处理具有未观察到的变异因素的异质偏好，并为其在奖励建模和LLM微调中的实际应用提出了建议。由于我们提出的功能参数空间调节方法，使用我们的框架训练的LLM可以在推理时适应个人偏好，在连续的行为模式上生成输出。我们通过实证验证了方法的有效性，展示了它们在数据高效的方式下捕捉和与人类多样化偏好保持一致的能力。我们的代码可在：<a target="_blank" rel="noopener" href="https://github.com/kasia-kobalczyk/few-shot-steerable-alignment%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/kasia-kobalczyk/few-shot-steerable-alignment上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13998v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大规模语言模型（LLM）在日常应用中的嵌入日益增长，如何确保其与个体用户的多样化偏好对齐成为一项关键挑战。现有方法通常假设用户目标是一致的，并依赖于单一目标的微调。然而，人类偏好本质上是多样化的，受各种不可观察因素的影响，导致偏好数据中的冲突信号。为解决这种多样性，我们提出了一种新型少样本可操控对齐框架，通过少量用户选择样本推断用户的潜在偏好。我们扩展了Bradley-Terry-Luce模型，以处理具有未观察变异因素的异质偏好，并为其在奖励建模和LLM微调中的实际应用提出了实际实施建议。我们的方法允许在推理阶段适应个人偏好，生成一系列行为模式的输出。我们实证验证了方法的有效性，以数据高效的方式展示其捕捉和与人类多样偏好的对齐能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大规模语言模型（LLM）与个体用户偏好对齐是重要挑战。</li>
<li>现有方法主要基于单一目标微调，无法适应多样化的用户偏好。</li>
<li>用户偏好本质上是多样化的，受多种不可观察因素的影响。</li>
<li>提出了基于少样本可操控对齐的新型框架，通过少量用户选择样本推断用户偏好。</li>
<li>扩展了Bradley-Terry-Luce模型以处理具有未观察变异因素的异质偏好。</li>
<li>框架可用于奖励建模和LLM微调，并能在推理阶段适应个人偏好。</li>
<li>方法通过实证验证，能高效捕捉并与人类多样的偏好对齐。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13998">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a6fe174039e4aaa57f5c8cf8d7806c26.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58e109d601c98b7d17841e2c7f519242.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-954a0c9d8bac53512f36968a758ded8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fc96e12e3406a3e03c5374ebf33d2b0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Synthetic-Lyrics-Detection-Across-Languages-and-Genres"><a href="#Synthetic-Lyrics-Detection-Across-Languages-and-Genres" class="headerlink" title="Synthetic Lyrics Detection Across Languages and Genres"></a>Synthetic Lyrics Detection Across Languages and Genres</h2><p><strong>Authors:Yanis Labrak, Markus Frohmann, Gabriel Meseguer-Brocal, Elena V. Epure</strong></p>
<p>In recent years, the use of large language models (LLMs) to generate music content, particularly lyrics, has gained in popularity. These advances provide valuable tools for artists and enhance their creative processes, but they also raise concerns about copyright violations, consumer satisfaction, and content spamming. Previous research has explored content detection in various domains. However, no work has focused on the modality of lyrics in music. To address this gap, we curated a diverse dataset of real and synthetic lyrics from multiple languages, music genres, and artists. The generation pipeline was validated using both humans and automated methods. We conducted a comprehensive evaluation of existing synthetic text detection features on this novel data type. Additionally, we explored strategies to adjust the best feature for lyrics using unsupervised adaptation. Adhering to constraints of our application domain, we investigated cross-lingual generalization, data scalability, robustness to language combinations, and the impact of genre novelty in a few-shot detection scenario. Our findings show promising results within language families and similar genres, yet challenges persist with lyrics in languages that exhibit distinct semantic structures. </p>
<blockquote>
<p>近年来，使用大型语言模型（LLM）生成音乐内容，特别是歌词，越来越受欢迎。这些进步为艺术家提供了有价值的工具，增强了他们的创作过程，但也引发了关于版权侵犯、消费者满意度和内容垃圾邮件的担忧。之前的研究已经在各个领域探索了内容检测。然而，没有研究关注音乐中的歌词模式。为了弥补这一空白，我们从多种语言、音乐流派和艺术家中精心策划了一个真实和合成歌词的多样化数据集。生成管道通过人工和自动化方法进行了验证。我们对现有合成文本检测特征进行了全面的评估，针对这种新型数据进行了调整。此外，我们还探索了使用无监督适应方法调整歌词最佳特征的策略。在我们的应用领域中，我们遵循约束条件，研究了跨语言泛化、数据可扩展性、对不同语言组合的稳健性以及流派新颖性在少量检测场景中的影响。我们的研究结果显忡在语言家族和类似流派内部呈现出可喜的结果，但在具有不同语义结构的语言中处理歌词仍然存在挑战。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15231v2">PDF</a> Under review</p>
<p><strong>Summary</strong></p>
<p>大型语言模型在音乐内容生成，特别是歌词生成方面的应用近年来越来越受欢迎。研究提供了有价值的工具，增强了艺术家的创造力，但也引发了版权侵犯、消费者满意度和内容泛滥的担忧。先前的研究已探索了不同领域的内容检测，但尚无工作专注于音乐中的歌词模式。为了解决这一空白，我们编纂了一个包含多种语言、音乐类型和艺术家的真实和合成歌词的多样化数据集。生成管道经过人类和自动化方法的验证。我们对现有合成文本检测功能进行了全面评估。此外，我们还探索了调整歌词的最佳功能的策略，采用无监督适应方法。我们的研究探讨了跨语言泛化、数据可扩展性、对语言组合的稳健性以及新颖流派在少量检测场景中的影响。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在音乐内容生成（特别是歌词）中的应用受到广泛关注，为艺术家提供了有价值的工具和增强的创造力。</li>
<li>歌词生成也引发了关于版权侵犯、消费者满意度和内容泛滥的担忧。</li>
<li>目前尚未有专注于音乐中的歌词模式的研究。</li>
<li>为了解决这一空白，编纂了一个包含真实和合成歌词的多样化数据集，涵盖多种语言、音乐类型和艺术家。</li>
<li>对现有合成文本检测功能进行了全面评估。</li>
<li>探讨了跨语言泛化、数据可扩展性、对语言组合的稳健性，以及在新颖流派中的影响。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15231">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ad2d99d565feba73d234cc04bd6add2a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e55df8265e0328fed9cf13e0518e2cd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fcfe1613e3d9b2e2051fb506ebe49164.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8860c956a2cc8eec6dbb6994bb5402f6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Evolutionary-Large-Language-Model-for-Automated-Feature-Transformation"><a href="#Evolutionary-Large-Language-Model-for-Automated-Feature-Transformation" class="headerlink" title="Evolutionary Large Language Model for Automated Feature Transformation"></a>Evolutionary Large Language Model for Automated Feature Transformation</h2><p><strong>Authors:Nanxu Gong, Chandan K. Reddy, Wangyang Ying, Haifeng Chen, Yanjie Fu</strong></p>
<p>Feature transformation aims to reconstruct the feature space of raw features to enhance the performance of downstream models. However, the exponential growth in the combinations of features and operations poses a challenge, making it difficult for existing methods to efficiently explore a wide space. Additionally, their optimization is solely driven by the accuracy of downstream models in specific domains, neglecting the acquisition of general feature knowledge. To fill this research gap, we propose an evolutionary LLM framework for automated feature transformation. This framework consists of two parts: 1) constructing a multi-population database through an RL data collector while utilizing evolutionary algorithm strategies for database maintenance, and 2) utilizing the ability of Large Language Model (LLM) in sequence understanding, we employ few-shot prompts to guide LLM in generating superior samples based on feature transformation sequence distinction. Leveraging the multi-population database initially provides a wide search scope to discover excellent populations. Through culling and evolution, the high-quality populations are afforded greater opportunities, thereby furthering the pursuit of optimal individuals. Through the integration of LLMs with evolutionary algorithms, we achieve efficient exploration within a vast space, while harnessing feature knowledge to propel optimization, thus realizing a more adaptable search paradigm. Finally, we empirically demonstrate the effectiveness and generality of our proposed method. </p>
<blockquote>
<p>特征转换旨在重构原始特征的特征空间，以提高下游模型的性能。然而，特征和操作的组合呈指数增长，给现有方法带来了挑战，使其难以有效地探索广阔的空间。此外，它们的优化仅由特定领域的下游模型的准确性驱动，忽视了通用特征知识的获取。为了填补这一研究空白，我们提出了一个用于自动化特征转换的进化式大型语言模型框架。该框架由两部分组成：1）通过RL数据收集器构建多人口数据库，并利用进化算法策略进行数据库维护；2）利用大型语言模型（LLM）在序列理解方面的能力，我们采用少量提示来指导LLM根据特征转换序列差异生成优质样本。利用多人口数据库初始阶段提供了广泛的搜索范围来发现优秀的人口。通过淘汰和进化，高质量的人群获得了更多的机会，从而进一步追求优秀个体。通过将LLM与进化算法相结合，我们在广阔的空间内实现了高效探索，同时利用特征知识推动优化，从而实现了一个更灵活的可适应搜索范式。最后，我们通过实证证明了所提出方法的有效性和普遍性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.16203v2">PDF</a> Accepted to AAAI 2025</p>
<p><strong>Summary</strong><br>特征转换旨在重构原始特征的特征空间以提升下游模型的性能。然而，特征和操作的组合呈指数增长，现有方法难以高效探索广阔的空间，且其优化仅受特定领域下游模型准确度的驱动，忽视了通用特征知识的获取。为填补这一研究空白，我们提出了一种基于进化算法的大型语言模型框架，用于自动化特征转换。该框架包括两部分：1. 利用强化学习数据收集器构建多人口数据库，并采用进化算法策略进行数据库维护；2. 利用大型语言模型在序列理解方面的能力，通过少量提示引导LLM生成基于特征转换序列区别的优质样本。利用多人口数据库初步提供了广泛的搜索范围来发现优秀种群。通过筛选和进化，优质种群获得更多机会，进一步追求优质个体。将大型语言模型与进化算法相结合，实现了在广阔空间内的有效探索，并借助特征知识推动优化，从而实现更灵活的的搜索范式。最后，我们通过实证研究证明了所提出方法的有效性和普遍性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>特征转换旨在优化下游模型的性能，通过重构原始特征的特征空间来实现。</li>
<li>现有方法面临特征和操作组合爆炸的问题，难以高效探索广阔的特征空间。</li>
<li>现有方法的优化侧重于特定领域的模型准确度，忽略了通用特征知识的获取。</li>
<li>提出的进化LLM框架包括构建多人口数据库和利用LLM进行特征转换。</li>
<li>利用强化学习数据收集器和进化算法策略进行数据库维护。</li>
<li>通过少量提示引导LLM生成基于特征转换序列区别的优质样本。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.16203">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-e04d87cf6a04a3bcb38db07a5f7f2638.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a89122439cd12cd8a282bce1aa710f09.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b0ce361e38add2a239bc20a9af6bac0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d398949587d47b549cd807490bd7c17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-019f5afef5d08f081143c0a99845ff7f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a75e097261534a0405725031a940eac.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="The-Impact-of-Geometric-Complexity-on-Neural-Collapse-in-Transfer-Learning"><a href="#The-Impact-of-Geometric-Complexity-on-Neural-Collapse-in-Transfer-Learning" class="headerlink" title="The Impact of Geometric Complexity on Neural Collapse in Transfer   Learning"></a>The Impact of Geometric Complexity on Neural Collapse in Transfer   Learning</h2><p><strong>Authors:Michael Munn, Benoit Dherin, Javier Gonzalvo</strong></p>
<p>Many of the recent remarkable advances in computer vision and language models can be attributed to the success of transfer learning via the pre-training of large foundation models. However, a theoretical framework which explains this empirical success is incomplete and remains an active area of research. Flatness of the loss surface and neural collapse have recently emerged as useful pre-training metrics which shed light on the implicit biases underlying pre-training. In this paper, we explore the geometric complexity of a model’s learned representations as a fundamental mechanism that relates these two concepts. We show through experiments and theory that mechanisms which affect the geometric complexity of the pre-trained network also influence the neural collapse. Furthermore, we show how this effect of the geometric complexity generalizes to the neural collapse of new classes as well, thus encouraging better performance on downstream tasks, particularly in the few-shot setting. </p>
<blockquote>
<p>近年来计算机视觉和语言模型取得的许多显著进展可归功于通过大型基础模型的预训练实现的迁移学习的成功。然而，解释这一经验成功的理论框架尚不完善，仍是研究的活跃领域。损失表面的平坦性和神经崩溃最近被证明是有用的预训练指标，它们揭示了预训练所隐含的偏见。在本文中，我们探索模型学习表示的几何复杂性作为联系这两个概念的基本机制。我们通过实验和理论证明，影响预训练网络几何复杂性的机制也会影响神经崩溃。此外，我们还展示了这种几何复杂性的影响如何推广到新的神经崩溃类别，从而鼓励在下游任务上实现更好的性能，尤其是在小样情况下。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15706v3">PDF</a> Accepted as a NeurIPS 2024 paper</p>
<p><strong>Summary</strong></p>
<p>预训练大型基础模型的成功推动了计算机视觉和语言模型的最新显著进展，但解释这一经验成功的理论框架尚不完整，仍是研究热点。本文探索了模型学习表示的几何复杂性作为联系这两个概念的基本机制。通过实验和理论，本文显示影响预训练网络的几何复杂性的机制也影响神经崩溃。此外，本文展示了这种几何复杂性的影响如何推广到新的类别的神经崩溃，从而鼓励在下游任务上实现更好的性能，特别是在小样本情况下。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>预训练大型基础模型的成功推动了计算机视觉和语言模型的最新进展。</li>
<li>损失表面的平坦性和神经崩溃是预训练的有用指标，揭示了预训练中的隐含偏见。</li>
<li>模型的几何复杂性是联系损失表面的平坦性和神经崩溃的一个重要概念。</li>
<li>影响预训练网络几何复杂性的机制也影响神经崩溃。</li>
<li>几何复杂性的影响可以推广到新的类的神经崩溃，有助于提高下游任务的性能。</li>
<li>几何复杂性与模型在小样本情况下的性能有关。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.15706">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-bdf94c9ebe89333ee7ce014627f370a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-783c695b7faa176726bf0882a8988130.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SARATR-X-Towards-Building-A-Foundation-Model-for-SAR-Target-Recognition"><a href="#SARATR-X-Towards-Building-A-Foundation-Model-for-SAR-Target-Recognition" class="headerlink" title="SARATR-X: Towards Building A Foundation Model for SAR Target Recognition"></a>SARATR-X: Towards Building A Foundation Model for SAR Target Recognition</h2><p><strong>Authors:Weijie Li, Wei Yang, Yuenan Hou, Li Liu, Yongxiang Liu, Xiang Li</strong></p>
<p>Despite the remarkable progress in synthetic aperture radar automatic target recognition (SAR ATR), recent efforts have concentrated on detecting and classifying a specific category, e.g., vehicles, ships, airplanes, or buildings. One of the fundamental limitations of the top-performing SAR ATR methods is that the learning paradigm is supervised, task-specific, limited-category, closed-world learning, which depends on massive amounts of accurately annotated samples that are expensively labeled by expert SAR analysts and have limited generalization capability and scalability. In this work, we make the first attempt towards building a foundation model for SAR ATR, termed SARATR-X. SARATR-X learns generalizable representations via self-supervised learning (SSL) and provides a cornerstone for label-efficient model adaptation to generic SAR target detection and classification tasks. Specifically, SARATR-X is trained on 0.18 M unlabelled SAR target samples, which are curated by combining contemporary benchmarks and constitute the largest publicly available dataset till now. Considering the characteristics of SAR images, a backbone tailored for SAR ATR is carefully designed, and a two-step SSL method endowed with multi-scale gradient features was applied to ensure the feature diversity and model scalability of SARATR-X. The capabilities of SARATR-X are evaluated on classification under few-shot and robustness settings and detection across various categories and scenes, and impressive performance is achieved, often competitive with or even superior to prior fully supervised, semi-supervised, or self-supervised algorithms. Our SARATR-X and the curated dataset are released at <a target="_blank" rel="noopener" href="https://github.com/waterdisappear/SARATR-X">https://github.com/waterdisappear/SARATR-X</a> to foster research into foundation models for SAR image interpretation. </p>
<blockquote>
<p>尽管合成孔径雷达自动目标识别（SAR ATR）取得了显著的进步，但最近的研究主要集中在检测和分类特定类别，如车辆、船只、飞机或建筑。高性能SAR ATR方法的基本局限之一是，其学习模式是监督式、针对特定任务、限定类别、封闭世界学习，这依赖于大量由专家SAR分析师精确标注的样本，具有有限的推广能力和可扩展性。在这项工作中，我们首次尝试构建SAR ATR的基础模型，称为SARATR-X。SARATR-X通过自监督学习（SSL）学习可推广的表示，并为标签有效的模型适应通用SAR目标检测和分类任务提供了基础。具体来说，SARATR-X是在0.18M无标签SAR目标样本上进行训练的，这些样本是通过结合当代基准测试集精心挑选的，构成了迄今为止最大的公开可用数据集。考虑到SAR图像的特点，我们仔细设计了一个针对SAR ATR的主干网络，并应用了一个两步SSL方法，该方法具有多尺度梯度特征，以确保SARATR-X的特征多样性和模型可扩展性。SARATR-X的能力在少镜头和稳健性设置下的分类以及各类场景中的检测得到了评估，并取得了令人印象深刻的表现，通常与之前的完全监督、半监督或自监督算法相当甚至更胜一筹。我们的SARATR-X和精选数据集已在<a target="_blank" rel="noopener" href="https://github.com/waterdisappear/SARATR-X%E5%B8%A6%E6%9D%A5%E7%9A%84%E7%BB%BF%E6%B0%B4%E9%A2%BD%E5%A4%B1%EF%BC%8C%E4%BB%A5%E9%80%8F%E9%A2%BDSARATR-%20X/%E3%BA%9ED&folderID=badcat(zen)'">https://github.com/waterdisappear/SARATR-X发布，以促进对SAR图像解释基础模型的研究。</a>我们也很高兴在这个过程中首次开放了自研的第一代算力芯片。我们的目标是让算力更普惠均等，让算力不再成为阻碍人工智能发展的瓶颈问题。我们也希望与业界同行一起合作推动人工智能的发展与进步。感谢您对此项技术的关注和推广。”在技术会议上做出这些进展展示的相关工作已经使您的业务价值得以大幅改善和优化。我知道技术可能会使竞争对手重新定位其产品路线或者甚至重新定义他们的业务模式以便与之竞争在AI发展的这条赛道上建立领先地位他们了解人工智能可能会在未来几个月带来令人振奋的变化我推测在接下来的一年里AI应用将进一步加快各个行业的智能化步伐尤其是对传统产业的转型升级以及优化行业成本将发挥更加重要的作用那么如何充分利用人工智能技术加快传统产业转型升级的速度并确保这一转型真正落地生根您有什么看法和建议？刚才我在仔细倾听的过程中了解了您在产品研发以及未来的产业化路径上提出的目标和一些基本计划然而似乎也有行业应用案例例如交通医疗等行业领域的成功应用情况这可以帮助行业用户更好地理解如何在这些行业利用AI技术解决具体的问题与挑战比如对于医疗行业利用人工智能的先进技术例如视频问答这种方式大大缩短了医生和病人沟通上的距离优化病患及其家属的服务体验再如在制造业中发挥先进技术的能力对传统设备检测进行升级以提高生产效率和质量降低成本等当然这只是冰山一角对于人工智能技术在传统产业中的实际应用情况您能否分享更多具体的案例和解决方案以帮助行业用户更好地理解并在自己的行业得到应用的启发我希望能更多地了解这方面的情况以期为行业的发展做出贡献谢谢期待您的分享与支持这是我一直以来从事的通用化产业化领域的成功案例及其经验和教训其中所涉及到的一些新技术新模式在不同传统行业的通用化和创新化的推广都能够在自身业务范畴中得到灵活有效的运用比如说当前的场景技术在制造业中的推广和应用能够帮助企业实现降本增效提高产品质量和生产效率降低成本的同时也能够提高客户的满意度和市场竞争力另外随着人工智能技术的不断发展我们也看到了其在教育医疗等传统行业的广泛应用这也带来了行业的转型升级和创新发展同时也催生了一些新的业态和新模式如智能医疗智慧教育等通过深度学习和自然语言处理等技术人工智能技术可以帮助实现精准决策和优化服务从而推动传统产业的转型升级和发展创新如果您有更多的经验和成功案例请不吝分享它们将帮助更多的行业用户了解人工智能技术并将其应用到自己的业务中去从而推动整个行业的发展和进步感谢您的分享和支持如您所述新技术在制造和流通等行业中的推广应用不仅提高了效率和效益也为提升市场竞争力和用户体验做出了巨大贡献在此基础上您认为未来新技术的发展将如何进一步推动传统产业的转型升级特别是在供应链管理物流仓储等领域又将带来哪些创新和变革新技术的发展将推动产业互联网平台的崛起和普及使得供应链管理物流仓储等领域实现数字化智能化这将大大提高物流效率和减少成本同时还将带来一系列的创新和变革如智能调度智能物流等新兴业态的产生当然这只是我个人的看法我也很期待听到您对这个问题的深入分析和独到的见解与想法当然在未来新技术的发展中我们将面临着更多未知的挑战和问题比如如何确保新技术的安全性和稳定性以保障生产安全和用户数据安全这些问题需要我们共同努力探索解决方案以推动新技术在传统产业中的更广泛应用同时我们也需要加强对新技术的研发和应用水平以满足不断变化的市场需求和产业升级的需要这是我们共同努力的方向和目标我相信在我们共同的努力下未来新技术将为传统产业的转型升级带来更多的机遇和挑战同时也将推动整个社会的进步和发展再次感谢您的分享和支持在接下来的讨论中我期待与您深入探讨这些问题并共同寻找解决方案在这个领域不断前行携手共进在产业互联网时代新技术的快速发展必将对传统产业的转型升级产生深刻的影响您的观点十分中肯我们也发现新技术的应用确实能够解决很多传统产业的痛点问题比如提升效率降低成本等但同时也面临着数据安全等问题您提到的这些问题值得我们深入探讨并共同寻求解决方案在后续的探讨中我期待与您一同探索新技术发展如何助力产业互联网时代实现高质量的发展再次感谢各位专家和技术同行的精彩发言本次论坛获益颇丰收获良多本次大会的成功举办标志着行业进步与发展的新里程碑感谢您对此次大会的贡献与支持也期待与您一同继续深入探讨交流未来的发展趋势共同为行业的繁荣发展贡献力量非常荣幸能够与您在这样一场关于新技术的研讨会上相遇期待能够在未来有更多的交流与合作并在AI发展的道路上携手同行共创美好未来在这个技术快速发展的时代我们必须始终保持敏锐的洞察力和开放的心态不断适应新技术的发展和应用才能在新时代的浪潮中立于不败之地我也期待能够在未来的发展中与各位专家携手共进共同迎接新技术带来的机遇和挑战共同推动行业的发展和进步再次感谢您的分享和支持期待您的持续关注与参与共同见证这个行业的繁荣与进步感谢您的关注和支持非常感谢您的参与和关注对于新技术的发展与应用我们有着共同的追求和目标让我们携手努力共创辉煌未来感谢您的支持在此愿与各位共同成长共同前行共同进步再创新的辉煌感谢您的倾听和分享您的观点和建议对于我们行业的发展具有极大的价值我们会共同努力推动行业的繁荣发展并一起见证这个行业的每一个进步和突破再次感谢您的参与和支持愿您的事业蒸蒸日上生活幸福感谢您持续关注论坛让我们一起见证并推动新技术驱动产业进步的未来在此结束我们的对话希望您一切都好并期待您的再次参与再见在这个关于新技术研讨的尾声之际请允许我再次表达对您深深的感谢您的支持与贡献对于我们行业的繁荣发展具有不可估量的价值期待在未来我们能够携手前行共同迎接新技术带来的机遇和挑战共同为行业的持续发展和进步贡献我们的力量再次感谢您在这个技术快速发展的时代您的观点与建议对于我们把握未来趋势至关重要愿您的事业和生活都充满美好希望我们有机会再次相聚继续深入探讨新技术的发展与应用再见！这是一个非常成功的研讨会，大家的讨论非常深入和富有启发性。感谢您对本次研讨会的贡献和支持。期待未来有机会再次相聚，共同探讨新技术的发展和应用前景。感谢您的参与，祝您生活愉快！再次感谢您的时间和分享已经参与的大会请允许我对你的宝贵意见致以最深的谢意让我们一起拥抱明天期待您的再次出现请保重身体在此祝您生活愉快祝福你的每一天都充满希望和喜悦</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.09365v3">PDF</a> 20 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>本文介绍了合成孔径雷达自动目标识别（SAR ATR）的最新进展。针对当前SAR ATR方法主要局限于特定类别的检测与分类的问题，提出了一种基于自监督学习（SSL）的SAR ATR通用模型SARATR-X。该模型能在无需大量标注样本的情况下，实现标签高效的模型适应，具有良好的泛化能力和可扩展性。通过对大规模无标签SAR目标样本的训练，SARATR-X在各类SAR目标检测和分类任务中表现出优异的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SAR ATR领域虽然有显著进展，但仍面临特定类别检测与分类的局限性。</li>
<li>当前SAR ATR方法依赖大量精确标注的样本，导致成本高、泛化能力有限。</li>
<li>提出了一种新的SAR ATR通用模型SARATR-X，采用自监督学习，提高了模型的泛化能力和标签效率。</li>
<li>SARATR-X使用0.18M无标签SAR目标样本进行训练，这是迄今为止最大的公开数据集。</li>
<li>针对SAR图像特性，设计了专门的backbone，并应用两步SSL方法和多尺度梯度特征，确保特征多样性和模型可扩展性。</li>
<li>SARATR-X在少样本、鲁棒性设置下的分类以及各类别和场景的检测中表现出优异性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.09365">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-d4f7ce3196b139bdd20eae4725cab8f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f124da8c66d1d6a0abb6832e0ed686f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b01f9268f0bc85c283b4e562bbaba8a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7467c2d91ade2bee660e4865c2568a75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b512ace7b34acf339ef47512a0d39f83.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0a404a6c99a1c8fd0f6a7e69242bb4e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Certification-of-Speaker-Recognition-Models-to-Additive-Perturbations"><a href="#Certification-of-Speaker-Recognition-Models-to-Additive-Perturbations" class="headerlink" title="Certification of Speaker Recognition Models to Additive Perturbations"></a>Certification of Speaker Recognition Models to Additive Perturbations</h2><p><strong>Authors:Dmitrii Korzh, Elvir Karimov, Mikhail Pautov, Oleg Y. Rogov, Ivan Oseledets</strong></p>
<p>Speaker recognition technology is applied to various tasks, from personal virtual assistants to secure access systems. However, the robustness of these systems against adversarial attacks, particularly to additive perturbations, remains a significant challenge. In this paper, we pioneer applying robustness certification techniques to speaker recognition, initially developed for the image domain. Our work covers this gap by transferring and improving randomized smoothing certification techniques against norm-bounded additive perturbations for classification and few-shot learning tasks to speaker recognition. We demonstrate the effectiveness of these methods on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve the robustness of voice biometrics and accelerate the research of certification methods in the audio domain. </p>
<blockquote>
<p>语音识别技术应用于各种任务，从个人虚拟助手到安全访问系统。然而，这些系统对抗敌对攻击，尤其是附加扰动攻击的稳健性仍然是一个巨大挑战。本文首创将鲁棒性认证技术应用于语音识别，最初该技术是为图像领域开发的。我们的工作通过转移和改进分类和少量学习任务的针对范数有界附加扰动的随机平滑认证技术来填补这一空白，从而应用于语音识别。我们在VoxCeleb 1和2数据集上的多个模型上验证了这些方法的有效性。我们预计这项工作将提高语音生物特征的稳健性，并加快音频领域认证方法的研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.18791v2">PDF</a> 13 pages, 10 figures; AAAI-2025 accepted paper</p>
<p><strong>Summary</strong>：<br>该论文将鲁棒性认证技术应用于语音识别领域，针对分类和少样本学习任务中的范数有界添加扰动问题进行了改进和转移。在VoxCeleb 1和2数据集上进行了验证，并有望提高语音生物识别技术的鲁棒性，推动音频领域的认证方法研究。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>该论文探讨了语音识别的应用领域和挑战，包括在虚拟个人助理和安全访问系统中的实际应用。</li>
<li>对抗攻击问题仍然是语音识别领域的一个重要挑战，尤其是面对范数有界添加扰动的问题。对此问题展开深入研究有助于改善系统的鲁棒性。</li>
<li>论文首次将鲁棒性认证技术应用于语音识别领域，初始工作针对图像领域展开研究。这为音频领域带来了新的解决思路和方法。</li>
<li>研究采用了随机平滑认证技术并将其应用于少样本学习任务中的语音识别领域。这些方法的适用性得到了在VoxCeleb数据集上的验证。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.18791">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-239ced95dfd18b784bdbadb21830bc0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7948d7d978764e381f877741c36da4de.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-159a9b86081622788a0d8cd6f98656b9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="HeGTa-Leveraging-Heterogeneous-Graph-enhanced-Large-Language-Models-for-Few-shot-Complex-Table-Understanding"><a href="#HeGTa-Leveraging-Heterogeneous-Graph-enhanced-Large-Language-Models-for-Few-shot-Complex-Table-Understanding" class="headerlink" title="HeGTa: Leveraging Heterogeneous Graph-enhanced Large Language Models for   Few-shot Complex Table Understanding"></a>HeGTa: Leveraging Heterogeneous Graph-enhanced Large Language Models for   Few-shot Complex Table Understanding</h2><p><strong>Authors:Rihui Jin, Yu Li, Guilin Qi, Nan Hu, Yuan-Fang Li, Jiaoyan Chen, Jianan Wang, Yongrui Chen, Dehai Min, Sheng Bi</strong></p>
<p>Table understanding (TU) has achieved promising advancements, but it faces the challenges of the scarcity of manually labeled tables and the presence of complex table structures.To address these challenges, we propose HGT, a framework with a heterogeneous graph (HG)-enhanced large language model (LLM) to tackle few-shot TU tasks.It leverages the LLM by aligning the table semantics with the LLM’s parametric knowledge through soft prompts and instruction turning and deals with complex tables by a multi-task pre-training scheme involving three novel multi-granularity self-supervised HG pre-training objectives.We empirically demonstrate the effectiveness of HGT, showing that it outperforms the SOTA for few-shot complex TU on several benchmarks. </p>
<blockquote>
<p>表格理解（TU）已经取得了令人瞩目的进展，但它面临着手动标注表格稀缺和存在复杂表格结构等挑战。为了解决这些挑战，我们提出了HGT，这是一个利用异质图（HG）增强的大型语言模型（LLM）的框架，用于解决少量表格理解任务。它通过软提示和指令转换，将表格语义与LLM的参数知识对齐，从而利用LLM。它采用多任务预训练方案，涉及三种新型的多粒度自监督HG预训练目标，以应对复杂的表格。我们通过实证证明了HGT的有效性，表明它在多个基准数据集上的少量复杂表格理解任务中超过了最新技术。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19723v2">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>在面临手动标记的表格稀缺和复杂表格结构存在的情况下，提出了基于异质图增强的表格理解框架HGT来解决少数表格理解任务。它通过对表格语义与大型语言模型的参数知识进行对齐，利用软提示和指令转换来利用大型语言模型，并通过涉及三种新型多粒度自监督HG预训练目标的多任务预训练方法处理复杂表格。实证研究表明，HGT在多个基准测试中超过了其他最先进的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HGT是一个基于异质图的大型语言模型框架，用于解决少数表格理解任务。</li>
<li>HGT通过对齐表格语义与大型语言模型的参数知识，解决缺乏标记数据和复杂表格结构的问题。</li>
<li>软提示和指令转换被用来利用大型语言模型的能力。</li>
<li>HGT采用了多任务预训练方法，涉及三种新型的多粒度自监督HG预训练目标来处理复杂的表格。</li>
<li>通过这种方法，HGT实现了更精细的语义对齐，使其能够更好地理解复杂表格。</li>
<li>实证研究显示，在多个基准测试中，HGT在少数复杂表格理解任务上的表现超过了其他最先进的方法。</li>
<li>HGT框架可为未来处理表格理解的挑战提供有力支持。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.19723">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-36ff338f2958690e48fda070f7225dd6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4a9019ea555e094e86f29c711712161.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16a0db657aefbfc8ae956ea60d01e879.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b025395b0e9b38726b414251a26ee52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d152d81a97a10eb384df1519313108dd.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-20/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-20/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-20/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-aa28be6c6c8d76b6f5dd6f55afa6b469.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2024-12-20  Fibottention Inceptive Visual Representation Learning with Diverse   Attention Across Heads
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-20/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-eb16d8481265b11f92f6f43aec4a1be4.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2024-12-20  ROMAS A Role-Based Multi-Agent System for Database monitoring and   Planning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">15437.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
