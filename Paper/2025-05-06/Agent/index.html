<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-05-06  Exploring Equity of Climate Policies using Multi-Agent Multi-Objective   Reinforcement Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-25d23e516ee65375e4cc85089bd98480.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    10.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    41 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-06-更新"><a href="#2025-05-06-更新" class="headerlink" title="2025-05-06 更新"></a>2025-05-06 更新</h1><h2 id="Exploring-Equity-of-Climate-Policies-using-Multi-Agent-Multi-Objective-Reinforcement-Learning"><a href="#Exploring-Equity-of-Climate-Policies-using-Multi-Agent-Multi-Objective-Reinforcement-Learning" class="headerlink" title="Exploring Equity of Climate Policies using Multi-Agent Multi-Objective   Reinforcement Learning"></a>Exploring Equity of Climate Policies using Multi-Agent Multi-Objective   Reinforcement Learning</h2><p><strong>Authors:Palok Biswas, Zuzanna Osika, Isidoro Tamassia, Adit Whorra, Jazmin Zatarain-Salazar, Jan Kwakkel, Frans A. Oliehoek, Pradeep K. Murukannaiah</strong></p>
<p>Addressing climate change requires coordinated policy efforts of nations worldwide. These efforts are informed by scientific reports, which rely in part on Integrated Assessment Models (IAMs), prominent tools used to assess the economic impacts of climate policies. However, traditional IAMs optimize policies based on a single objective, limiting their ability to capture the trade-offs among economic growth, temperature goals, and climate justice. As a result, policy recommendations have been criticized for perpetuating inequalities, fueling disagreements during policy negotiations. We introduce Justice, the first framework integrating IAM with Multi-Objective Multi-Agent Reinforcement Learning (MOMARL). By incorporating multiple objectives, Justice generates policy recommendations that shed light on equity while balancing climate and economic goals. Further, using multiple agents can provide a realistic representation of the interactions among the diverse policy actors. We identify equitable Pareto-optimal policies using our framework, which facilitates deliberative decision-making by presenting policymakers with the inherent trade-offs in climate and economic policy. </p>
<blockquote>
<p>应对气候变化需要全球各国政策的协调努力。这些努力以科学报告为依据，科学报告部分依赖于综合评估模型（IAMs），这是评估气候政策经济影响的重要工具。然而，传统的IAMs基于单一目标优化政策，这限制了其捕捉经济增长、温度目标和气候正义之间权衡的能力。因此，政策建议因加剧不平等、在政策谈判中引发分歧而受到批评。我们引入了Justice，它是第一个将IAM与多目标多智能体强化学习（MOMARL）相结合的理论框架。通过融入多重目标，Justice在平衡气候和经济目标的同时，提出了关注公平的政策建议。此外，利用多个智能体可以提供对多样化政策行动者之间互动的逼真描述。我们使用此框架确定了公平的帕累托最优政策，通过向政策制定者展示气候和经济政策中的固有权衡来促进审慎决策。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01115v1">PDF</a> Accepted to IJCAI 2025, AI and Social Good Track</p>
<p><strong>Summary</strong></p>
<p>本文强调了应对气候变化需要全球各国协同政策努力，而科学报告和集成评估模型（IAM）是制定这些政策的重要参考。然而，传统的IAM以单一目标进行优化，难以兼顾经济增长、温度目标和气候公平之间的权衡，因此政策推荐受到批评，加剧了不平等和政策谈判中的分歧。为此，我们引入了结合IAM和多目标多智能体强化学习（MOMARL）的正义框架。该框架通过融入多个目标，在平衡气候和经济目标的同时，为政策制定者提供公平的政策建议。此外，使用多个智能体可以真实反映不同政策制定者之间的互动。我们的框架能够识别公平的帕累托最优政策，帮助政策制定者在气候和经济政策之间进行权衡决策。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>应对气候变化需要全球协同政策努力，科学报告和集成评估模型（IAM）是重要参考。</li>
<li>传统IAM以单一目标优化，难以兼顾经济、温度目标和气候公平。</li>
<li>政策推荐因未能充分考虑公平而受批评，加剧不平等和政策分歧。</li>
<li>引入结合IAM和多目标多智能体强化学习（MOMARL）的“正义”框架。</li>
<li>“正义”框架能生成兼顾气候和经济目标的公平政策建议。</li>
<li>使用多个智能体能真实反映不同政策制定者间的互动。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01115">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-443e262c4d481a876510201a00a524f5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebe94124d77c6887c7cbaad29764bbb9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19722ca05d31a4f6800a94027f6fee70.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25d23e516ee65375e4cc85089bd98480.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84b48439805b02e65c82c82e8c070765.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-619a4949900c65f7abf4313100ab56b7.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WirelessAgent-Large-Language-Model-Agents-for-Intelligent-Wireless-Networks"><a href="#WirelessAgent-Large-Language-Model-Agents-for-Intelligent-Wireless-Networks" class="headerlink" title="WirelessAgent: Large Language Model Agents for Intelligent Wireless   Networks"></a>WirelessAgent: Large Language Model Agents for Intelligent Wireless   Networks</h2><p><strong>Authors:Jingwen Tong, Wei Guo, Jiawei Shao, Qiong Wu, Zijian Li, Zehong Lin, Jun Zhang</strong></p>
<p>The rapid evolution of wireless networks presents unprecedented challenges in managing complex and dynamic systems. Existing methods are increasingly facing fundamental limitations in addressing these challenges. In this paper, we introduce WirelessAgent, a novel framework that harnesses large language models (LLMs) to create autonomous AI agents for diverse wireless network tasks. This framework integrates four core modules that mirror human cognitive processes: perception, memory, planning, and action. To implement it, we provide a basic usage based on agentic workflows and the LangGraph architecture. We demonstrate the effectiveness of WirelessAgent through a comprehensive case study on network slicing. The numerical results show that WirelessAgent achieves $44.4%$ higher bandwidth utilization than the \emph{Prompt-based} method, while performing only $4.3%$ below the \emph{Rule-based optimality}. Notably, WirelessAgent delivers near-optimal network throughput across diverse network scenarios. These underscore the framework’s potential for intelligent and autonomous resource management in future wireless networks. The code is available at \url{<a target="_blank" rel="noopener" href="https://github.com/jwentong/WirelessAgent_R1%7D">https://github.com/jwentong/WirelessAgent_R1}</a>. </p>
<blockquote>
<p>无线网络的快速发展给管理复杂动态系统带来了前所未有的挑战。现有方法在应对这些挑战时面临着越来越多的根本性局限。在本文中，我们介绍了WirelessAgent，这是一个新型框架，它利用大型语言模型（LLMs）来创建用于多种无线网络任务的自主AI代理。该框架集成了四个核心模块，这些模块反映了人类的认知过程：感知、记忆、规划和行动。为了实现它，我们提供了基于代理工作流程和LangGraph架构的基本用法。我们通过关于网络切片的综合案例研究证明了WirelessAgent的有效性。数值结果表明，WirelessAgent的带宽利用率比“基于提示”的方法高出44.4%，同时仅比“基于规则的最优值”低4.3%。值得注意的是，WirelessAgent在不同网络场景中实现了接近最优的网络吞吐量。这些成果凸显了未来无线网络中智能自主资源管理中该框架的潜力。代码可在<a target="_blank" rel="noopener" href="https://github.com/jwentong/WirelessAgent_R1%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jwentong/WirelessAgent_R1找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01074v1">PDF</a> This manuscript is an extended version of a previous magazine version   and is now submitted to a journal for possible publication. arXiv admin note:   text overlap with arXiv:2409.07964</p>
<p><strong>Summary</strong><br>无线网络的快速发展给管理复杂动态系统带来了前所未有的挑战。现有方法在处理这些挑战时面临着越来越大的局限性。本文介绍了WirelessAgent，一种利用大型语言模型（LLMs）创建用于多种无线网络任务的自主AI代理的新型框架。该框架集成了四个反映人类认知过程的核心模块：感知、记忆、规划和行动。通过基于代理的工作流程和LangGraph架构的基本使用，我们实现了它。通过对网络切片进行综合性案例研究，展示了WirelessAgent的有效性。数值结果表明，WirelessAgent的带宽利用率比基于提示的方法高出44.4%，同时仅比基于规则的最优方案低4.3%。WirelessAgent在不同网络场景下都能实现接近最优的网络吞吐量，凸显了其在未来无线网络中智能自主资源管理的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>无线网络面临管理复杂动态系统的挑战。</li>
<li>WirelessAgent框架利用大型语言模型创建自主AI代理应对这些挑战。</li>
<li>WirelessAgent包含四个核心模块：感知、记忆、规划和行动，这些模块反映了人类认知过程。</li>
<li>通过代理的工作流程和LangGraph架构实现了WirelessAgent。</li>
<li>网络切片的案例研究表明，WirelessAgent在带宽利用率方面表现出卓越的性能。</li>
<li>WirelessAgent的性能接近最优，凸显了其在未来无线网络中的潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01074">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9a5bb10dfd2889c47c46c63ad7090ef8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-351772617211cb012b3403b4ed7c673e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ca2b9bdafa0f50616fabbcf40ac34c54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5228fc1496e873ed8f07cb5defcaff91.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="VTS-LLM-Domain-Adaptive-LLM-Agent-for-Enhancing-Awareness-in-Vessel-Traffic-Services-through-Natural-Language"><a href="#VTS-LLM-Domain-Adaptive-LLM-Agent-for-Enhancing-Awareness-in-Vessel-Traffic-Services-through-Natural-Language" class="headerlink" title="VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel   Traffic Services through Natural Language"></a>VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel   Traffic Services through Natural Language</h2><p><strong>Authors:Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu</strong></p>
<p>Vessel Traffic Services (VTS) are essential for maritime safety and regulatory compliance through real-time traffic management. However, with increasing traffic complexity and the prevalence of heterogeneous, multimodal data, existing VTS systems face limitations in spatiotemporal reasoning and intuitive human interaction. In this work, we propose VTS-LLM Agent, the first domain-adaptive large LLM agent tailored for interactive decision support in VTS operations. We formalize risk-prone vessel identification as a knowledge-augmented Text-to-SQL task, combining structured vessel databases with external maritime knowledge. To support this, we construct a curated benchmark dataset consisting of a custom schema, domain-specific corpus, and a query-SQL test set in multiple linguistic styles. Our framework incorporates NER-based relational reasoning, agent-based domain knowledge injection, semantic algebra intermediate representation, and query rethink mechanisms to enhance domain grounding and context-aware understanding. Experimental results show that VTS-LLM outperforms both general-purpose and SQL-focused baselines under command-style, operational-style, and formal natural language queries, respectively. Moreover, our analysis provides the first empirical evidence that linguistic style variation introduces systematic performance challenges in Text-to-SQL modeling. This work lays the foundation for natural language interfaces in vessel traffic services and opens new opportunities for proactive, LLM-driven maritime real-time traffic management. </p>
<blockquote>
<p>船舶交通服务（VTS）对于通过实时交通管理实现海上安全和法规合规至关重要。然而，随着交通复杂性的增加和异构多模态数据的普及，现有VTS系统在时空推理和直观人机交互方面面临局限性。在这项工作中，我们提出了VTS-LLM Agent，这是第一个针对VTS操作中的交互式决策支持量身定制的域自适应大型LLM代理。我们将易出风险的船舶识别形式化为知识增强的文本到SQL任务，结合结构化船舶数据库和外部海事知识。为此，我们构建了一个精心制作的基准数据集，包括自定义模式、领域特定语料库和多种语言风格的查询SQL测试集。我们的框架结合了基于NER的关系推理、基于代理的领域知识注入、语义代数中间表示和查询反思机制，以增强领域定位和上下文感知理解。实验结果表明，VTS-LLM在命令风格、操作风格和正式自然语言查询方面均优于通用型和SQL专注的基线。此外，我们的分析首次提供了实证证据表明，语言风格的变化给文本到SQL建模带来了系统性的性能挑战。这项工作奠定了自然语言接口在船舶交通服务中的基础，并为基于LLM的主动海事实时交通管理提供了新的机会。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00989v1">PDF</a> 8 pages, 5 figures, 7 tablels, submitted to ITSC2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了VTS-LLM Agent在船舶交通服务中的重要性及其优势。该智能代理通过结合结构化船舶数据库和外部海事知识，采用文本到SQL的任务模式进行风险船舶识别。VTS-LLM Agent构建了专门的数据集，并引入了多种技术来提升其在特定领域的理解和上下文感知能力。实验结果显示，VTS-LLM Agent在命令风格、操作风格和正式自然语言查询方面的性能优于基准测试。同时，文章首次实证表明，语言风格变化对文本到SQL建模的系统性能带来挑战。此研究为船舶交通服务的自然语言接口奠定了基石，并为实时交通管理提供了新的机会。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VTS在海上安全和法规遵守方面至关重要，但现有系统面临时空推理和直观人机交互的局限性。</li>
<li>VTS-LLM Agent是首个针对VTS操作的交互式决策支持的大型语言模型代理。</li>
<li>风险船舶识别被形式化为知识增强的文本到SQL任务，结合了结构化船舶数据库和外部海事知识。</li>
<li>VTS-LLM Agent构建了一个专门的数据集，包括自定义模式、特定领域的语料库和多种语言风格的查询SQL测试集。</li>
<li>该框架采用NER关系推理、基于代理的领域知识注入、语义代数中间表示和查询重新思考机制等技术，提升领域定位和上下文感知理解。</li>
<li>实验结果表明，VTS-LLM Agent在多种查询风格下的性能优于基准测试。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00989">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-59d93531340f3a1dfe83c006d9c52d78.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a36cba1965e27487f77e25145204b304.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6964608088bab6f0e3d27804688dfb03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef613ba107e894129a8787258504f079.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-243f226340aa20b340d7807299bbe65d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94f8cca22b2bfbb69593098c09b6cdb3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9069601517bb7222d0649c9771f65925.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2cab05ddc4eea493058a7bfcd2a9e5a8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multi-agents-based-User-Values-Mining-for-Recommendation"><a href="#Multi-agents-based-User-Values-Mining-for-Recommendation" class="headerlink" title="Multi-agents based User Values Mining for Recommendation"></a>Multi-agents based User Values Mining for Recommendation</h2><p><strong>Authors:Lijian Chen, Wei Yuan, Tong Chen, Xiangyu Zhao, Nguyen Quoc Viet Hung, Hongzhi Yin</strong></p>
<p>Recommender systems have rapidly evolved and become integral to many online services. However, existing systems sometimes produce unstable and unsatisfactory recommendations that fail to align with users’ fundamental and long-term preferences. This is because they primarily focus on extracting shallow and short-term interests from user behavior data, which is inherently dynamic and challenging to model. Unlike these transient interests, user values are more stable and play a crucial role in shaping user behaviors, such as purchasing items and consuming content. Incorporating user values into recommender systems can help stabilize recommendation performance and ensure results better reflect users’ latent preferences. However, acquiring user values is typically difficult and costly. To address this challenge, we leverage the strong language understanding, zero-shot inference, and generalization capabilities of Large Language Models (LLMs) to extract user values from users’ historical interactions. Unfortunately, direct extraction using LLMs presents several challenges such as length constraints and hallucination. To overcome these issues, we propose ZOOM, a zero-shot multi-LLM collaborative framework for effective and accurate user value extraction. In ZOOM, we apply text summarization techniques to condense item content while preserving essential meaning. To mitigate hallucinations, ZOOM introduces two specialized agent roles: evaluators and supervisors, to collaboratively generate accurate user values. Extensive experiments on two widely used recommendation datasets with two state-of-the-art recommendation models demonstrate the effectiveness and generalization of our framework in automatic user value mining and recommendation performance improvement. </p>
<blockquote>
<p>推荐系统已经迅速演变并成为许多在线服务的重要组成部分。然而，现有系统有时会产生不稳定和不满意的推荐结果，无法与用户的基本和长期偏好相吻合。这是因为它们主要关注从用户行为数据中提取浅层和短期的兴趣，而用户行为数据本质上是动态的，难以进行建模。不同于这些短暂的兴趣，用户价值更加稳定，在塑造用户行为（如购买物品和消耗内容）方面起着至关重要的作用。将用户价值纳入推荐系统可以帮助稳定推荐性能，并确保结果更好地反映用户的潜在偏好。然而，获取用户价值通常很困难且成本高昂。为了应对这一挑战，我们利用大型语言模型（LLM）的强大语言理解、零启动推理和泛化能力，从用户的历史交互中提取用户价值。然而，直接使用LLM进行提取面临长度限制和幻觉等挑战。为了克服这些问题，我们提出了ZOOM（零启动多LLM协作框架），旨在实现有效和精确的用户价值提取。在ZOOM中，我们应用文本摘要技术来浓缩项目内容，同时保留关键意义。为了减轻幻觉问题，ZOOM引入了两种专门的代理角色：评估者和监督者，以协作生成准确的用户价值。在两个广泛使用的推荐数据集上进行的大量实验表明，与两种先进的推荐模型相比，我们的框架在自动用户价值挖掘和推荐性能提升方面都具有有效性和泛化性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00981v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>推荐系统已迅速演进并已成为许多在线服务的重要组成部分。然而，现有系统产生的推荐结果有时不稳定且不满意，无法与用户的基本和长期偏好对齐。这是因为它们主要关注从用户行为数据中提取短暂和浅层的兴趣，这本质上是动态的且难以建模。通过结合用户价值可以稳定推荐性能并确保结果更好地反映用户的潜在偏好。为从用户历史交互中提取用户价值，我们利用大型语言模型的强大语言理解能力、零样本推断能力和泛化能力来解决这一挑战。我们提出一种名为ZOOM的零样本多语言模型协作框架，用于有效和准确地提取用户价值。实验证明，该框架在自动用户价值挖掘和推荐性能提升方面的有效性和泛化性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>推荐系统已变得至关重要，但仍存在不稳定和无法满足用户长期偏好等问题。</li>
<li>现有系统主要关注用户行为的短暂和浅层兴趣，这导致推荐结果的不稳定。</li>
<li>用户价值是更稳定并影响用户行为的关键因素，如购买物品和消耗内容。</li>
<li>将用户价值纳入推荐系统可以提高推荐性能的稳定性并反映用户的潜在偏好。</li>
<li>提取用户价值具有挑战性，成本高昂。利用大型语言模型的强大能力来解决这一挑战。</li>
<li>提出名为ZOOM的零样本多语言模型协作框架，用于有效和准确地提取用户价值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00981">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e209c4553c8db51a0ab8814e6f35fb5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78bedef6d2f438841db476f908505440.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Autonomous-Embodied-Agents-When-Robotics-Meets-Deep-Learning-Reasoning"><a href="#Autonomous-Embodied-Agents-When-Robotics-Meets-Deep-Learning-Reasoning" class="headerlink" title="Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning"></a>Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning</h2><p><strong>Authors:Roberto Bigazzi</strong></p>
<p>The increase in available computing power and the Deep Learning revolution have allowed the exploration of new topics and frontiers in Artificial Intelligence research. A new field called Embodied Artificial Intelligence, which places at the intersection of Computer Vision, Robotics, and Decision Making, has been gaining importance during the last few years, as it aims to foster the development of smart autonomous robots and their deployment in society. The recent availability of large collections of 3D models for photorealistic robotic simulation has allowed faster and safe training of learning-based agents for millions of frames and a careful evaluation of their behavior before deploying the models on real robotic platforms. These intelligent agents are intended to perform a certain task in a possibly unknown environment. To this end, during the training in simulation, the agents learn to perform continuous interactions with the surroundings, such as gathering information from the environment, encoding and extracting useful cues for the task, and performing actions towards the final goal; where every action of the agent influences the interactions. This dissertation follows the complete creation process of embodied agents for indoor environments, from their concept to their implementation and deployment. We aim to contribute to research in Embodied AI and autonomous agents, in order to foster future work in this field. We present a detailed analysis of the procedure behind implementing an intelligent embodied agent, comprehending a thorough description of the current state-of-the-art in literature, technical explanations of the proposed methods, and accurate experimental studies on relevant robotic tasks. </p>
<blockquote>
<p>随着可用计算能力的增加和深度学习的革命，人工智能研究中的新主题和前沿领域得到了探索。一个名为“实体人工智能”的新领域，它位于计算机视觉、机器人技术和决策制定的交界处，在过去的几年里变得越来越重要，因为它旨在促进智能自主机器人的发展及其在社会的部署。最近，大量用于真实感机器人模拟的3D模型的可用性允许了基于学习的代理人的快速和安全训练，以及数百万帧的行为的仔细评估，然后才将模型部署在实际的机器人平台上。这些智能代理旨在在一个可能未知的环境中执行特定任务。为此，代理在模拟训练期间学习不断与周围环境进行交互，如从环境中收集信息、编码和提取任务的有用线索，以及朝着最终目标采取行动；代理的每个行动都会影响其交互。本论文将跟踪实体代理在室内环境中的完整创建过程，从概念到实施和部署。我们旨在为实体人工智能和自主代理的研究做出贡献，以促进这一领域的未来工作。我们详细介绍了实现智能实体代理的过程分析，包括对文献中最新技术的全面描述、所提出方法的技术解释以及关于相关机器人任务的准确实验研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00935v1">PDF</a> Ph.D. Dissertation</p>
<p><strong>Summary</strong><br>     深度学习革命和计算能力的提升推动了人工智能新领域——嵌入式人工智能的发展，该领域旨在培养智能自主机器人并将其部署于社会。利用大规模三维模型进行逼真机器人模拟，可在模拟环境中快速安全地训练学习主体，并评估其行为，再部署到真实机器人平台。这些智能主体旨在能在未知环境中完成任务，通过连续互动，收集信息、编码提取任务线索并行动以达到最终目标。本文详细阐述了嵌入式主体的创建过程，从概念到实施和部署，并对当前文献的先进技术、方法的技术解释以及相关的机器人任务准确实验进行了研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习革命和计算能力的增加推动了嵌入式人工智能领域的发展。</li>
<li>嵌入式人工智能是计算机视觉、机器人技术和决策制定的交叉点。</li>
<li>嵌入式人工智能的目标是培育智能自主机器人并将其部署于社会。</li>
<li>利用大规模三维模型进行机器人模拟可以加快安全训练学习主体的速度。</li>
<li>智能主体能在未知环境中完成任务，通过与环境的连续互动进行学习。</li>
<li>本文详细阐述了嵌入式主体的创建过程，从概念到实施和部署。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00935">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5fa2edf6dfed9e3fdba0a471e223de16.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Virtual-Force-Based-Routing-of-Modular-Agents-on-a-Graph"><a href="#Virtual-Force-Based-Routing-of-Modular-Agents-on-a-Graph" class="headerlink" title="Virtual Force-Based Routing of Modular Agents on a Graph"></a>Virtual Force-Based Routing of Modular Agents on a Graph</h2><p><strong>Authors:Adam Casselman, Manav Vora, Melkior Ornik</strong></p>
<p>Modular vehicles have become an area of academic interest in the field of multi-agent systems. Modularity allows vehicles to connect and disconnect with each other mid-transit which provides a balance between efficiency and flexibility when solving complex and large scale tasks in urban or aerial transportation. This paper details a generalized scheme to route multiple modular agents on a graph to a predetermined set of target nodes. The objective is to visit all target nodes while incurring minimum resource expenditure. Agents that are joined together will incur the equivalent cost of a single agent, which is motivated by the logistical benefits of traffic reduction and increased fuel efficiency. To solve this problem, we introduce a heuristic algorithm that seeks to balance the optimality of the path that an agent takes and the cost benefit of joining agents. Our approach models the agents and targets as point charges, where the agents take the path of highest attractive force from its target node and neighboring agents. We validate our approach by simulating multiple modular agents along real-world transportation routes in the road network of Champaign-Urbana, Illinois, USA. For two vehicles, it performed equally compared to an existing modular-agent routing algorithm. Three agents were then routed using our method and the performance was benchmarked against non-modular agents using a simple shortest path policy where it performs better than the non-modular implementation 81 percent of the time. Moreover, we show that the proposed algorithm operates faster than existing routing methods for modular agents. </p>
<blockquote>
<p>模块化车辆已成为多智能体系统领域的一个学术兴趣点。模块化允许车辆在运输过程中相互连接和断开，从而在解决城市或空中运输的复杂大规模任务时实现效率和灵活性的平衡。本文详细介绍了一种在图上对多个模块化智能体进行路由的通用方案，以达到预先设定的目标节点集。目标是访问所有目标节点，同时产生最小的资源消耗。组合在一起的智能体将产生相当于单个智能体的成本，这源于减少交通和增加燃料效率的后勤效益。为了解决这一问题，我们引入了一种启发式算法，旨在平衡智能体所走路径的优越性和组合智能体的成本优势。我们的方法将智能体和目标建模为点电荷，智能体从其目标节点和相邻智能体那里选择具有最大吸引力的路径。我们通过模拟伊利诺伊州香槟-厄巴纳道路网上现实世界中的多个模块化智能体来验证我们的方法。对于两辆车来说，其性能与现有的模块化智能体路由算法相当。然后，我们使用我们的方法对三个智能体进行路由，并与非模块化智能体在简单最短路径策略下的性能进行基准测试，在81%的时间内，其性能优于非模块化实现。此外，我们还表明，所提出算法的运行速度比现有模块化智能体路由方法更快。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00928v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>模块化车辆在多智能体系统领域引起了学术界的关注。本文提出了一种多模块化智能体在图结构上的路由方案，目标是访问所有目标节点的同时最小化资源消耗。智能体间的连接可以带来交通减少和燃油效率提升的好处。本文引入了一种启发式算法，旨在平衡智能体路径的最优性和连接智能体的成本优势。通过模拟真实世界交通路线上的多个模块化智能体，验证了该方法的性能表现优于现有方法。模拟实验证明该算法效率高，优于非模块化实现方案的81%。同时，该算法的运行速度也比现有的模块化智能体路由方法更快。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>模块化车辆已成为多智能体系统领域的学术焦点。</li>
<li>模块车辆通过连接和断开实现效率和灵活性的平衡，解决大规模任务问题。</li>
<li>本文提出了多模块化智能体在图结构上的路由方案，目标是访问所有目标节点同时最小化资源消耗。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00928">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-20ba2d846a2f72981ba03a7052dc1f89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76870182f1e0d4b470aaa5c24bb31e5a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe1d074ed48a17817dac3f042f0cf2fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c11c25f9a12081ebbe59e055cc19349.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8ad9ddd1855cbac55d4b61354858b10.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a43602a741d171c5c70d4c69886a78d9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Thoughts-without-Thinking-Reconsidering-the-Explanatory-Value-of-Chain-of-Thought-Reasoning-in-LLMs-through-Agentic-Pipelines"><a href="#Thoughts-without-Thinking-Reconsidering-the-Explanatory-Value-of-Chain-of-Thought-Reasoning-in-LLMs-through-Agentic-Pipelines" class="headerlink" title="Thoughts without Thinking: Reconsidering the Explanatory Value of   Chain-of-Thought Reasoning in LLMs through Agentic Pipelines"></a>Thoughts without Thinking: Reconsidering the Explanatory Value of   Chain-of-Thought Reasoning in LLMs through Agentic Pipelines</h2><p><strong>Authors:Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman</strong></p>
<p>Agentic pipelines present novel challenges and opportunities for human-centered explainability. The HCXAI community is still grappling with how best to make the inner workings of LLMs transparent in actionable ways. Agentic pipelines consist of multiple LLMs working in cooperation with minimal human control. In this research paper, we present early findings from an agentic pipeline implementation of a perceptive task guidance system. Through quantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT) reasoning, a common vehicle for explainability in LLMs, operates within agentic pipelines. We demonstrate that CoT reasoning alone does not lead to better outputs, nor does it offer explainability, as it tends to produce explanations without explainability, in that they do not improve the ability of end users to better understand systems or achieve their goals. </p>
<blockquote>
<p>智能管道为人为中心的解释性带来了新的挑战和机会。HCXAI社区仍在努力探索如何以可操作的方式使大型语言模型（LLM）的内部工作透明化。智能管道由多个大型语言模型组成，它们以最小的人为控制进行协同工作。在这篇研究论文中，我们展示了一个感知任务指导系统的智能管道实施的初步发现。通过定量和定性分析，我们分析了思维链（CoT）推理在智能管道中的运行方式，这是大型语言模型中解释性的常见方式。我们证明，单独的CoT推理并不能产生更好的输出，也不能提供解释性，因为它往往会产生没有解释性的解释，即它们并不能提高最终用户理解系统或实现目标的能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00875v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>在代理管道中，存在新的挑战和机遇，需要以人为中心的解释性。HCXAI社区仍在努力探索如何以可操作的方式使大型语言模型的内部工作机制透明化。代理管道由多个大型语言模型组成，这些模型相互配合并受到最低限度的人为控制。本研究论文提出了一个感知任务指导系统的代理管道实现的初步发现。通过定量和定性分析，我们研究了链式思维（CoT）推理在代理管道中的运作方式。我们证明，CoT推理本身并不能带来更好的输出或提供解释性，因为它倾向于产生无解释性的解释，即它们并不能提高最终用户理解系统或实现目标的能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agentic管道带来新挑战和机会，需要以人为中心的解释性。</li>
<li>HCXAI社区正在努力探索如何使大型语言模型的内部工作更加透明。</li>
<li>Agentic管道由多个大型语言模型组成，这些模型相互配合并受到人为控制的限制。</li>
<li>研究展示了感知任务指导系统的代理管道实施的初步发现。</li>
<li>通过定量和定性分析，发现链式思维（CoT）推理在代理管道中的运作方式。</li>
<li>CoT推理并不一定能带来更好的输出或提供有效的解释。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00875">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-46fef90c14628eb317dacb577a420bf1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c1730e336f19e5806a6569f4f2809a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8e7119b8f77b9eb74e50c107558b824.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-793e282e3935908c94c49cd8633699d4.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-Large-Language-Model-based-Human-Agent-Systems"><a href="#A-Survey-on-Large-Language-Model-based-Human-Agent-Systems" class="headerlink" title="A Survey on Large Language Model based Human-Agent Systems"></a>A Survey on Large Language Model based Human-Agent Systems</h2><p><strong>Authors:Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu</strong></p>
<p>Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents. However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications. To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety. This paper provides the first comprehensive and structured survey of LLM-HAS. It clarifies fundamental concepts, systematically presents core components shaping these systems, including environment &amp; profiling, human feedback, interaction types, orchestration and communication, explores emerging applications, and discusses unique challenges and opportunities. By consolidating current knowledge and offering a structured overview, we aim to foster further research and innovation in this rapidly evolving interdisciplinary field. Paper lists and resources are available at <a target="_blank" rel="noopener" href="https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers">https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers</a>. </p>
<blockquote>
<p>最近大型语言模型（LLM）的进展引发了人们对构建完全自主代理人的日益浓厚的兴趣。然而，基于LLM的完全自主代理人仍然面临诸多挑战，包括由于幻觉导致的可靠性有限、处理复杂任务的困难以及实质性的安全和道德风险，这些都限制了它们在现实世界应用中的可行性和可信度。为了克服这些局限性，基于LLM的人机系统（LLM-HAS）将人类提供的信息、反馈或控制融入代理系统，以提高系统性能、可靠性和安全性。本文对LLM-HAS进行了首次全面和系统的调查。它阐明了基本概念，系统地介绍了构成这些系统的核心组件，包括环境&amp;配置、人类反馈、交互类型、编排和通信，探索了新兴应用，并讨论了独特的挑战和机遇。通过整合当前知识并提供结构化概述，我们的目标是促进这一快速发展的跨学科领域的进一步研究和创新。论文列表和资源可通过<a target="_blank" rel="noopener" href="https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00753v1">PDF</a> Paper lists and resources are available at   \url{<a target="_blank" rel="noopener" href="https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers%7D">https://github.com/HenryPengZou/Awesome-LLM-Based-Human-Agent-System-Papers}</a></p>
<p><strong>Summary</strong><br>大型语言模型（LLM）为基础的全自主代理技术日益受到关注，但仍面临可靠性、处理复杂任务能力、安全和伦理风险等方面的挑战。为解决这些问题，结合人类信息和控制的LLM人类代理系统（LLM-HAS）被提出，旨在提高系统性能、可靠性和安全性。本文首次全面系统地介绍了LLM-HAS，包括其核心组件、新兴应用、独特挑战和机遇。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLM为基础的全自主代理技术虽受关注，但仍存在可靠性、任务处理、安全和伦理风险方面的挑战。</li>
<li>LLM-HAS通过结合人类信息和控制，旨在提高系统性能、可靠性和安全性。</li>
<li>本文提供了LLM-HAS的首个全面系统的介绍，包括其核心组件、新兴应用和独特挑战。</li>
<li>LLM-HAS的核心组件包括环境&amp;分析、人类反馈、交互类型、协同和沟通。</li>
<li>LLM-HAS面临独特的挑战和机遇，需要进一步的研究和创新。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00753">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e6ed737294a456431a754e61c4a5e2e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df197334e6903ef718680974f240e3db.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7dc1304f8b1c564c69ae0df8f29cb54b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7559dc20bfe28f56e14eaa36bb1236a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Empowering-Agentic-Video-Analytics-Systems-with-Video-Language-Models"><a href="#Empowering-Agentic-Video-Analytics-Systems-with-Video-Language-Models" class="headerlink" title="Empowering Agentic Video Analytics Systems with Video Language Models"></a>Empowering Agentic Video Analytics Systems with Video Language Models</h2><p><strong>Authors:Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu</strong></p>
<p>AI-driven video analytics has become increasingly pivotal across diverse domains. However, existing systems are often constrained to specific, predefined tasks, limiting their adaptability in open-ended analytical scenarios. The recent emergence of Video-Language Models (VLMs) as transformative technologies offers significant potential for enabling open-ended video understanding, reasoning, and analytics. Nevertheless, their limited context windows present challenges when processing ultra-long video content, which is prevalent in real-world applications. To address this, we introduce AVAS, a VLM-powered system designed for open-ended, advanced video analytics. AVAS incorporates two key innovations: (1) the near real-time construction of Event Knowledge Graphs (EKGs) for efficient indexing of long or continuous video streams, and (2) an agentic retrieval-generation mechanism that leverages EKGs to handle complex and diverse queries. Comprehensive evaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that AVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy, respectively, significantly surpassing existing VLM and video Retrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video analytics in ultra-long and open-world video scenarios, we introduce a new benchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hours in duration, along with 120 manually annotated, diverse, and complex question-answer pairs. On AVAS-100, AVAS achieves top-tier performance with an accuracy of 75.8%. </p>
<blockquote>
<p>人工智能驱动的视频分析在不同领域变得越来越重要。然而，现有系统通常局限于特定的预定义任务，限制了它们在开放式分析场景中的适应性。最近出现的视频语言模型（VLM）作为变革性技术，为开放式视频理解、推理和分析提供了巨大潜力。然而，它们有限的上下文窗口在处理超长视频内容时面临挑战，而超长视频内容在现实世界应用中普遍存在。为了解决这一问题，我们引入了AVAS，这是一个由VLM驱动的系统，旨在进行开放式高级视频分析。AVAS有两个关键的创新点：（1）近乎实时构建事件知识图谱（EKGs），以实现对长视频流或连续视频流的有效索引；（2）一种利用EKGs处理复杂和多样化查询的代理检索生成机制。在公共基准测试LVBench和VideoMME-Long上的综合评估表明，AVAS达到了最先进的性能，分别实现了62.3%和64.1%的准确率，显著超越了现有的VLM和视频检索增强生成（RAG）系统。此外，为了评估超长和开放式视频场景中的视频分析，我们引入了新的基准测试AVAS-100。该基准测试包含8个视频，每个视频持续时间超过10小时，以及120个手动注释的多样化、复杂的问答对。在AVAS-100上，AVAS以75.8%的准确率达到了顶尖性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00254v2">PDF</a> 15 pages, AVAS</p>
<p><strong>摘要</strong><br>AI驱动的视频分析技术在各领域中的作用愈发关键，但现有系统主要局限于特定预定义任务，限制了其在开放分析场景中的适应性。视频语言模型（VLM）技术的出现为开放视频理解、推理和分析提供了巨大潜力。然而，处理超长视频内容时，其有限的上下文窗口带来挑战。为解决此问题，我们推出AVAS系统，旨在进行开放的高级视频分析。AVAS两大创新点包括：（1）构建事件知识图谱（EKG），实现长视频流的实时高效索引；（2）利用EKG的代理检索生成机制，处理复杂多样的查询。在公开基准测试LVBench和视频MME-Long上的评估显示，AVAS达到领先水平，准确率分别为62.3%和64.1%，显著超越现有VLM和视频检索增强生成（RAG）系统。此外，为评估超长和开放世界视频场景下的视频分析，我们推出新基准测试AVAS-100。该测试包含8个时长超过10小时的视频，以及120组手动标注的复杂多样化问答。在AVAS-100测试中，AVAS以75.8%的准确率取得顶尖表现。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>AI驱动的视频分析技术在不同领域中的重要性不断提升。</li>
<li>现有视频分析系统主要局限于预定义任务，缺乏在开放场景中的适应性。</li>
<li>视频语言模型（VLM）技术为视频理解、推理和分析提供了巨大潜力。</li>
<li>处理超长视频内容时，VLM技术面临上下文窗口有限的挑战。</li>
<li>AVAS系统通过构建事件知识图谱（EKG）和代理检索生成机制实现高级视频分析。</li>
<li>AVAS在公开基准测试上表现出色，准确率超过现有系统。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00254">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fa7839ee5004eca4e92d4d5a1a3df31c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d4f47b2e86188b22599e6269aa2a577.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-68d64cc2261fb26d0df8657125d407ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a03918f5cd0e2bf37a1e0a7e7ab9155.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Agentic-Feedback-Loop-Modeling-Improves-Recommendation-and-User-Simulation"><a href="#Agentic-Feedback-Loop-Modeling-Improves-Recommendation-and-User-Simulation" class="headerlink" title="Agentic Feedback Loop Modeling Improves Recommendation and User   Simulation"></a>Agentic Feedback Loop Modeling Improves Recommendation and User   Simulation</h2><p><strong>Authors:Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli Feng, Xiangnan He</strong></p>
<p>Large language model-based agents are increasingly applied in the recommendation field due to their extensive knowledge and strong planning capabilities. While prior research has primarily focused on enhancing either the recommendation agent or the user agent individually, the collaborative interaction between the two has often been overlooked. Towards this research gap, we propose a novel framework that emphasizes the feedback loop process to facilitate the collaboration between the recommendation agent and the user agent. Specifically, the recommendation agent refines its understanding of user preferences by analyzing the feedback from the user agent on the item recommendation. Conversely, the user agent further identifies potential user interests based on the items and recommendation reasons provided by the recommendation agent. This iterative process enhances the ability of both agents to infer user behaviors, enabling more effective item recommendations and more accurate user simulations. Extensive experiments on three datasets demonstrate the effectiveness of the agentic feedback loop: the agentic feedback loop yields an average improvement of 11.52% over the single recommendation agent and 21.12% over the single user agent. Furthermore, the results show that the agentic feedback loop does not exacerbate popularity or position bias, which are typically amplified by the real-world feedback loop, highlighting its robustness. The source code is available at <a target="_blank" rel="noopener" href="https://github.com/Lanyu0303/AFL">https://github.com/Lanyu0303/AFL</a>. </p>
<blockquote>
<p>基于大型语言模型的代理由于其广泛的知识和强大的规划能力，在推荐领域的应用越来越广泛。虽然先前的研究主要集中于单独提高推荐代理或用户代理的性能，但两者之间的协作交互经常被忽视。针对这一研究空白，我们提出了一种新的框架，该框架强调反馈循环过程，以促进推荐代理和用户代理之间的协作。具体来说，推荐代理通过分析用户代理对项目推荐的反馈来完善对用户偏好的理解。相反，用户代理则基于推荐代理提供的项目和推荐理由来进一步识别潜在的用户兴趣。这种迭代过程提高了两个代理推断用户行为的能力，使项目推荐更加有效，用户模拟更加准确。在三个数据集上的大量实验证明了代理反馈循环的有效性：与单个推荐代理相比，代理反馈循环的平均改进率为11.52%；与单个用户代理相比，改进率为21.12%。此外，结果表明，代理反馈循环并不会加剧通常由真实反馈循环放大的流行度或位置偏见，这凸显了其稳健性。源代码可在<a target="_blank" rel="noopener" href="https://github.com/Lanyu0303/AFL">https://github.com/Lanyu0303/AFL</a>获得。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.20027v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型的智能推荐系统在推荐领域的应用日益广泛，其丰富的知识和强大的规划能力备受关注。本文提出一种新型框架，强调反馈循环过程，促进推荐和用户代理之间的协作。推荐代理通过分析用户代理对物品推荐的反馈来优化对用户偏好的理解，而用户代理则根据推荐代理提供的物品和推荐理由进一步识别潜在的用户兴趣。这种迭代过程提高了两个代理推断用户行为的能力，实现了更有效的物品推荐和更精确的用户模拟。实验表明，该反馈循环相较于单推荐代理和用户代理分别提高了平均11.52%和21.12%，并且不会加剧现实反馈循环中常见的热门或位置偏见问题，展现出良好的稳健性。源码已公开于链接<a target="_blank" rel="noopener" href="https://github.com/Lanyu0303/AFL%E3%80%82">https://github.com/Lanyu0303/AFL。</a> </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型代理在推荐领域的广泛应用及其丰富的知识和规划能力的重要性。</li>
<li>提出的新型框架强调反馈循环过程，促进推荐和用户代理之间的协作。</li>
<li>推荐代理通过解析用户代理的反馈来优化用户偏好理解。</li>
<li>用户代理能根据推荐代理提供的物品和推荐理由识别潜在用户兴趣。</li>
<li>迭代过程提高了两个代理推断用户行为的能力，实现了更有效的物品推荐和更精确的用户模拟。</li>
<li>实验结果显示，该反馈循环显著提高了推荐效果，并表现出良好的稳健性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.20027">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-850c864fd64d9c7a193a98dde5c16007.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5234b6977eff738e358d8c414b6667c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b04f15f3b0dd58e2645652d2ff402440.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8991a68cdb31456f9deb70759deb8258.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-652b0b56e7676929af695cd415cb829b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cd9a97f05d6cae5e4a65e2177869c897.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-06/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-06/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-06/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-36ca3bb6a30754a93681d0280c553134.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-05-06  CDFormer Cross-Domain Few-Shot Object Detection Transformer Against   Feature Confusion
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-06/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4a2373489183353348b449a9c9c8ec76.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-05-06  FlowDubber Movie Dubbing with LLM-based Semantic-aware Learning and   Flow Matching based Voice Enhancing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">26024.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
