<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-06  FlowDubber Movie Dubbing with LLM-based Semantic-aware Learning and   Flow Matching based Voice Enhancing">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4a2373489183353348b449a9c9c8ec76.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    30 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-06-æ›´æ–°"><a href="#2025-05-06-æ›´æ–°" class="headerlink" title="2025-05-06 æ›´æ–°"></a>2025-05-06 æ›´æ–°</h1><h2 id="FlowDubber-Movie-Dubbing-with-LLM-based-Semantic-aware-Learning-and-Flow-Matching-based-Voice-Enhancing"><a href="#FlowDubber-Movie-Dubbing-with-LLM-based-Semantic-aware-Learning-and-Flow-Matching-based-Voice-Enhancing" class="headerlink" title="FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and   Flow Matching based Voice Enhancing"></a>FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and   Flow Matching based Voice Enhancing</h2><p><strong>Authors:Gaoxiang Cong, Liang Li, Jiadong Pan, Zhedong Zhang, Amin Beheshti, Anton van den Hengel, Yuankai Qi, Qingming Huang</strong></p>
<p>Movie Dubbing aims to convert scripts into speeches that align with the given movie clip in both temporal and emotional aspects while preserving the vocal timbre of a given brief reference audio. Existing methods focus primarily on reducing the word error rate while ignoring the importance of lip-sync and acoustic quality. To address these issues, we propose a large language model (LLM) based flow matching architecture for dubbing, named FlowDubber, which achieves high-quality audio-visual sync and pronunciation by incorporating a large speech language model and dual contrastive aligning while achieving better acoustic quality via the proposed voice-enhanced flow matching than previous works. First, we introduce Qwen2.5 as the backbone of LLM to learn the in-context sequence from movie scripts and reference audio. Then, the proposed semantic-aware learning focuses on capturing LLM semantic knowledge at the phoneme level. Next, dual contrastive aligning (DCA) boosts mutual alignment with lip movement, reducing ambiguities where similar phonemes might be confused. Finally, the proposed Flow-based Voice Enhancing (FVE) improves acoustic quality in two aspects, which introduces an LLM-based acoustics flow matching guidance to strengthen clarity and uses affine style prior to enhance identity when recovering noise into mel-spectrograms via gradient vector field prediction. Extensive experiments demonstrate that our method outperforms several state-of-the-art methods on two primary benchmarks. The demos are available at {\href{<a target="_blank" rel="noopener" href="https://galaxycong.github.io/LLM-Flow-Dubber/%7D%7B/textcolor%7Bred%7D%7Bhttps://galaxycong.github.io/LLM-Flow-Dubber/%7D%7D%7D">https://galaxycong.github.io/LLM-Flow-Dubber/}{\textcolor{red}{https://galaxycong.github.io/LLM-Flow-Dubber/}}}</a>. </p>
<blockquote>
<p>ç”µå½±é…éŸ³æ—¨åœ¨å°†å‰§æœ¬è½¬æ¢ä¸ºä¸ç»™å®šç”µå½±ç‰‡æ®µåœ¨æ—¶é—´å’Œæƒ…æ„Ÿæ–¹é¢å¯¹é½çš„è¯­éŸ³ï¼ŒåŒæ—¶ä¿ç•™ç»™å®šç®€çŸ­å‚è€ƒéŸ³é¢‘çš„éŸ³è‰²ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¸“æ³¨äºé™ä½è¯é”™è¯¯ç‡ï¼Œè€Œå¿½è§†å”‡å½¢åŒæ­¥å’ŒéŸ³è´¨çš„é‡è¦æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é…éŸ³æµç¨‹åŒ¹é…æ¶æ„ï¼Œåä¸ºFlowDubberã€‚å®ƒé€šè¿‡ç»“åˆå¤§å‹è¯­éŸ³è¯­è¨€æ¨¡å‹å’ŒåŒå¯¹æ¯”å¯¹é½ï¼Œå®ç°äº†é«˜è´¨é‡çš„å£°éŸ³è§†è§‰åŒæ­¥å’Œå‘éŸ³ï¼Œå¹¶é€šè¿‡æå‡ºçš„å£°éŸ³å¢å¼ºæµç¨‹åŒ¹é…ï¼Œå®ç°äº†æ¯”ä»¥å‰å·¥ä½œæ›´å¥½çš„éŸ³è´¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥Qwen2.5ä½œä¸ºLLMçš„éª¨å¹²ï¼Œä»ç”µå½±å‰§æœ¬å’Œå‚è€ƒéŸ³é¢‘ä¸­å­¦ä¹ ä¸Šä¸‹æ–‡åºåˆ—ã€‚ç„¶åï¼Œæå‡ºçš„è¯­ä¹‰æ„ŸçŸ¥å­¦ä¹ ä¾§é‡äºåœ¨éŸ³ç´ çº§åˆ«æ•è·LLMè¯­ä¹‰çŸ¥è¯†ã€‚æ¥ä¸‹æ¥ï¼ŒåŒå¯¹æ¯”å¯¹é½ï¼ˆDCAï¼‰å¢å¼ºäº†ä¸å˜´å”‡è¿åŠ¨çš„ç›¸äº’å¯¹é½ï¼Œå‡å°‘äº†ç›¸ä¼¼éŸ³ç´ å¯èƒ½äº§ç”Ÿçš„æ··æ·†ã€‚æœ€åï¼Œæå‡ºçš„åŸºäºæµçš„è¯­éŸ³å¢å¼ºï¼ˆFVEï¼‰ä»ä¸¤ä¸ªæ–¹é¢æé«˜äº†éŸ³è´¨ï¼šå®ƒå¼•å…¥äº†ä¸€ç§åŸºäºLLMçš„å£°å­¦æµç¨‹åŒ¹é…æŒ‡å¯¼ï¼Œä»¥å¢å¼ºæ¸…æ™°åº¦ï¼Œå¹¶ä½¿ç”¨ä»¿å°„é£æ ¼å…ˆéªŒæ¥å¢å¼ºèº«ä»½ï¼Œé€šè¿‡æ¢¯åº¦çŸ¢é‡åœºé¢„æµ‹æ¢å¤å™ªå£°æ—¶çš„æ¢…å°”é¢‘è°±å›¾ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸¤ä¸ªä¸»è¦åŸºå‡†ä¸Šä¼˜äºå‡ ç§æœ€æ–°æ–¹æ³•ã€‚ç›¸å…³æ¼”ç¤ºå¯é€šè¿‡é“¾æ¥{\href{<a target="_blank" rel="noopener" href="https://galaxycong.github.io/LLM-Flow-Dubber/%7D%7B/textcolor%7Bred%7D%7Bhttps://galaxycong.github.io/LLM-Flow-Dubber/%7D%7D%7D%E6%9F%A5%E7%9C%8B%E3%80%82">https://galaxycong.github.io/LLM-Flow-Dubber/}{\textcolor{red}{https://galaxycong.github.io/LLM-Flow-Dubber/}}}æŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.01263v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç”µå½±é…éŸ³æ—¨åœ¨å°†å‰§æœ¬è½¬æ¢ä¸ºä¸ç»™å®šç”µå½±ç‰‡æ®µåœ¨æ—¶é—´å’Œæƒ…æ„Ÿæ–¹é¢å¯¹é½çš„æ¼”è®²ï¼ŒåŒæ—¶ä¿ç•™ç®€çŸ­å‚è€ƒéŸ³é¢‘çš„éŸ³è‰²ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨é™ä½è¯é”™è¯¯ç‡ï¼Œè€Œå¿½è§†å”‡åŒæ­¥å’ŒéŸ³è´¨çš„é‡è¦æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æµç¨‹åŒ¹é…æ¶æ„è¿›è¡Œé…éŸ³ï¼Œåä¸ºFlowDubberï¼Œé€šè¿‡ç»“åˆå¤§å‹è¯­éŸ³è¯­è¨€æ¨¡å‹å’ŒåŒå¯¹æ¯”å¯¹é½ï¼Œå®ç°äº†é«˜è´¨é‡çš„å£°éŸ³åŒæ­¥å’Œå‘éŸ³ï¼ŒåŒæ—¶æå‡ºçš„å£°éŸ³å¢å¼ºæµç¨‹åŒ¹é…è·å¾—äº†æ›´å¥½çš„éŸ³è´¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å¼•å…¥Qwen2.5ä½œä¸ºLLMçš„åç«¯ï¼Œå­¦ä¹ ç”µå½±å‰§æœ¬å’Œå‚è€ƒéŸ³é¢‘çš„ä¸Šä¸‹æ–‡åºåˆ—ï¼Œå¹¶å…³æ³¨æ•æ‰LLMè¯­ä¹‰çŸ¥è¯†åœ¨éŸ³ç´ å±‚é¢ã€‚æ­¤å¤–ï¼ŒåŒå¯¹æ¯”å¯¹é½æé«˜äº†ä¸å”‡éƒ¨åŠ¨ä½œçš„ç›¸äº’å¯¹é½ï¼Œå‡å°‘äº†ç›¸ä¼¼éŸ³ç´ å¯èƒ½äº§ç”Ÿçš„æ··æ·†ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºçš„åŸºäºæµçš„è¯­éŸ³å¢å¼ºï¼ˆFVEï¼‰ä»ä¸¤ä¸ªæ–¹é¢æé«˜äº†éŸ³è´¨ï¼šå¼•å…¥LLMçš„å£°å­¦æµç¨‹åŒ¹é…æŒ‡å¯¼ä»¥å¢å¼ºæ¸…æ™°åº¦ï¼Œå¹¶ä½¿ç”¨ä»¿å°„é£æ ¼å…ˆéªŒåœ¨é€šè¿‡æ¢¯åº¦å‘é‡åœºé¢„æµ‹æ¢å¤å™ªå£°æ—¶å¢å¼ºèº«ä»½ç‰¹å¾ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸¤ä¸ªä¸»è¦åŸºå‡†æµ‹è¯•ä¸Šä¼˜äºå‡ ç§æœ€æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”µå½±é…éŸ³éœ€åŒæ­¥è¯­éŸ³å’Œå½±åƒï¼Œå…¼é¡¾æ—¶é—´å’Œæƒ…æ„Ÿæ–¹é¢ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è¯é”™è¯¯ç‡ï¼Œä½†å¿½è§†å”‡åŒæ­¥å’ŒéŸ³è´¨ã€‚</li>
<li>FlowDubberæ¶æ„ç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œæµç¨‹åŒ¹é…å®ç°é«˜è´¨é‡éŸ³é¢‘-è§†è§‰åŒæ­¥å’Œå‘éŸ³ã€‚</li>
<li>Qwen2.5ä½œä¸ºLLMåç«¯ï¼Œå­¦ä¹ ç”µå½±å‰§æœ¬å’Œå‚è€ƒéŸ³é¢‘çš„ä¸Šä¸‹æ–‡åºåˆ—ã€‚</li>
<li>è¯­ä¹‰æ„ŸçŸ¥å­¦ä¹ æ•æ‰LLMåœ¨éŸ³ç´ å±‚é¢çš„è¯­ä¹‰çŸ¥è¯†ã€‚</li>
<li>åŒå¯¹æ¯”å¯¹é½ï¼ˆDCAï¼‰æé«˜å”‡éƒ¨åŠ¨ä½œç›¸äº’å¯¹é½ï¼Œå‡å°‘éŸ³ç´ æ··æ·†ã€‚</li>
<li>åŸºäºæµçš„è¯­éŸ³å¢å¼ºï¼ˆFVEï¼‰æé«˜éŸ³è´¨ï¼Œé€šè¿‡å¼•å…¥LLMçš„å£°å­¦æµç¨‹åŒ¹é…æŒ‡å¯¼å’Œä»¿å°„é£æ ¼å…ˆéªŒå¢å¼ºæ¸…æ™°åº¦å’Œèº«ä»½ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.01263">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0d9d85101c98baa91b864183d7ffbc0f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8ab1d6e5fd7620761b6362fdd212bd4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2c88dbbf9cf0ff33c9247402b1270ed.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Compact-Recurrent-Transformer-with-Persistent-Memory"><a href="#Compact-Recurrent-Transformer-with-Persistent-Memory" class="headerlink" title="Compact Recurrent Transformer with Persistent Memory"></a>Compact Recurrent Transformer with Persistent Memory</h2><p><strong>Authors:Edison Mucllari, Zachary Daniels, David Zhang, Qiang Ye</strong></p>
<p>The Transformer architecture has shown significant success in many language processing and visual tasks. However, the method faces challenges in efficiently scaling to long sequences because the self-attention computation is quadratic with respect to the input length. To overcome this limitation, several approaches scale to longer sequences by breaking long sequences into a series of segments, restricting self-attention to local dependencies between tokens within each segment and using a memory mechanism to manage information flow between segments. However, these approached generally introduce additional compute overhead that restricts them from being used for applications where limited compute memory and power are of great concern (such as edge computing). We propose a novel and efficient Compact Recurrent Transformer (CRT), which combines shallow Transformer models that process short local segments with recurrent neural networks to compress and manage a single persistent memory vector that summarizes long-range global information between segments. We evaluate CRT on WordPTB and WikiText-103 for next-token-prediction tasks, as well as on the Toyota Smarthome video dataset for classification. CRT achieves comparable or superior prediction results to full-length Transformers in the language datasets while using significantly shorter segments (half or quarter size) and substantially reduced FLOPs. Our approach also demonstrates state-of-the-art performance on the Toyota Smarthome video dataset. </p>
<blockquote>
<p>Transformeræ¶æ„åœ¨è®¸å¤šè¯­è¨€å¤„ç†å’Œè§†è§‰ä»»åŠ¡ä¸­éƒ½å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œè¯¥æ–¹æ³•åœ¨æ‰©å±•åˆ°é•¿åºåˆ—æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºè‡ªæ³¨æ„åŠ›è®¡ç®—ä¸è¾“å…¥é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å…³ç³»ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œä¸€äº›æ–¹æ³•é€šè¿‡å°†é•¿åºåˆ—åˆ†è§£æˆä¸€ç³»åˆ—ç‰‡æ®µæ¥é€‚åº”æ›´é•¿çš„åºåˆ—ï¼Œé™åˆ¶è‡ªæ³¨æ„åŠ›åœ¨æ¯ä¸ªç‰‡æ®µå†…æ ‡è®°ä¹‹é—´çš„å±€éƒ¨ä¾èµ–å…³ç³»ï¼Œå¹¶ä½¿ç”¨è®°å¿†æœºåˆ¶æ¥ç®¡ç†ç‰‡æ®µä¹‹é—´çš„ä¿¡æ¯æµã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å¼•å…¥äº†é¢å¤–çš„è®¡ç®—å¼€é”€ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨è®¡ç®—å†…å­˜å’ŒåŠŸç‡å—é™çš„åº”ç”¨é¢†åŸŸï¼ˆå¦‚è¾¹ç¼˜è®¡ç®—ï¼‰çš„ä½¿ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹é«˜æ•ˆçš„Compact Recurrent Transformerï¼ˆCRTï¼‰ï¼Œå®ƒå°†æµ…å±‚Transformeræ¨¡å‹ä¸é€’å½’ç¥ç»ç½‘ç»œç›¸ç»“åˆï¼Œå¤„ç†å’Œå‹ç¼©ä¸€ä¸ªæŒä¹…è®°å¿†å‘é‡ï¼Œè¯¥å‘é‡æ€»ç»“äº†ç‰‡æ®µä¹‹é—´çš„é•¿è·ç¦»å…¨å±€ä¿¡æ¯ã€‚æˆ‘ä»¬åœ¨WordPTBå’ŒWikiText-103æ•°æ®é›†ä¸Šè¯„ä¼°CRTçš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ä»»åŠ¡æ€§èƒ½ï¼Œä»¥åŠåœ¨ä¸°ç”°æ™ºèƒ½å®¶å±…è§†é¢‘æ•°æ®é›†ä¸Šè¿›è¡Œåˆ†ç±»ä»»åŠ¡è¯„ä¼°ã€‚CRTåœ¨è¯­è¨€æ•°æ®é›†ä¸­å®ç°äº†ä¸å…¨é•¿Transformerç›¸å½“çš„é¢„æµ‹ç»“æœï¼ŒåŒæ—¶ä½¿ç”¨äº†è¾ƒçŸ­çš„ç‰‡æ®µï¼ˆä¸€åŠæˆ–å››åˆ†ä¹‹ä¸€å¤§å°ï¼‰ï¼Œå¹¶å¤§å¹…å‡å°‘äº†FLOPsã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸°ç”°æ™ºèƒ½å®¶å±…è§†é¢‘æ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°å‡ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00929v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹é«˜æ•ˆç´§å‡‘å¾ªç¯Transformerï¼ˆCRTï¼‰æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰Transformeråœ¨å¤„ç†é•¿åºåˆ—æ—¶çš„å±€é™æ€§ã€‚CRTç»“åˆæµ…å±‚Transformeræ¨¡å‹å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼Œå¯¹é•¿åºåˆ—è¿›è¡Œåˆ†æ®µå¤„ç†ï¼ŒåŒæ—¶å‹ç¼©å’Œç®¡ç†ä¸€ä¸ªæŒä¹…å†…å­˜å‘é‡ï¼Œä»¥æ±‡æ€»åˆ†æ®µé—´çš„é•¿è·ç¦»å…¨å±€ä¿¡æ¯ã€‚åœ¨WordPTBå’ŒWikiText-103çš„ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹ä»»åŠ¡ä»¥åŠToyota Smarthomeè§†é¢‘æ•°æ®é›†ä¸Šçš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒCRTå®ç°äº†ä¸å…¨é•¿Transformerç›¸å½“æˆ–æ›´ä¼˜çš„é¢„æµ‹ç»“æœï¼ŒåŒæ—¶ä½¿ç”¨äº†æ›´çŸ­çš„åºåˆ—åˆ†æ®µå¹¶å¤§å¹…å‡å°‘äº†è®¡ç®—é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformeræ¶æ„åœ¨å¤„ç†é•¿åºåˆ—æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œè‡ªæ³¨æ„åŠ›è®¡ç®—æ˜¯è¾“å…¥é•¿åº¦çš„äºŒæ¬¡æ–¹ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šè¿‡åˆ†æ®µå¤„ç†é•¿åºåˆ—æ¥å…‹æœè¿™ä¸€é™åˆ¶ï¼Œä½†å¼•å…¥äº†é¢å¤–çš„è®¡ç®—å¼€é”€ï¼Œä¸é€‚ç”¨äºè®¡ç®—å†…å­˜å’ŒåŠŸç‡æœ‰é™çš„åœºæ™¯ã€‚</li>
<li>CRTæ¨¡å‹ç»“åˆäº†æµ…å±‚Transformeræ¨¡å‹å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼Œå¤„ç†çŸ­å±€éƒ¨åˆ†æ®µï¼ŒåŒæ—¶å‹ç¼©å’Œç®¡ç†ä¸€ä¸ªæŒä¹…å†…å­˜å‘é‡æ¥æ±‡æ€»åˆ†æ®µé—´çš„å…¨å±€ä¿¡æ¯ã€‚</li>
<li>CRTåœ¨WordPTBå’ŒWikiText-103çš„ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜ç§€ã€‚</li>
<li>CRTåœ¨Toyota Smarthomeè§†é¢‘æ•°æ®é›†ä¸Šçš„åˆ†ç±»ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>CRTä½¿ç”¨æ›´çŸ­çš„åºåˆ—åˆ†æ®µå¹¶å¤§å¹…å‡å°‘äº†è®¡ç®—é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00929">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9423cf01115215a13deeb577749c3a36.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-132c7336327ca75deb8f1b760d764d37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95ce734fe888ef9906e6ce27191e1d57.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cbbedc94ce0c32b37b757642bb70e5cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5517d639ae50411b5efbff0f314caaf.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="How-Transformers-Learn-Regular-Language-Recognition-A-Theoretical-Study-on-Training-Dynamics-and-Implicit-Bias"><a href="#How-Transformers-Learn-Regular-Language-Recognition-A-Theoretical-Study-on-Training-Dynamics-and-Implicit-Bias" class="headerlink" title="How Transformers Learn Regular Language Recognition: A Theoretical Study   on Training Dynamics and Implicit Bias"></a>How Transformers Learn Regular Language Recognition: A Theoretical Study   on Training Dynamics and Implicit Bias</h2><p><strong>Authors:Ruiquan Huang, Yingbin Liang, Jing Yang</strong></p>
<p>Language recognition tasks are fundamental in natural language processing (NLP) and have been widely used to benchmark the performance of large language models (LLMs). These tasks also play a crucial role in explaining the working mechanisms of transformers. In this work, we focus on two representative tasks in the category of regular language recognition, known as <code>even pairs&#39; and </code>parity checkâ€™, the aim of which is to determine whether the occurrences of certain subsequences in a given sequence are even. Our goal is to explore how a one-layer transformer, consisting of an attention layer followed by a linear layer, learns to solve these tasks by theoretically analyzing its training dynamics under gradient descent. While even pairs can be solved directly by a one-layer transformer, parity check need to be solved by integrating Chain-of-Thought (CoT), either into the inference stage of a transformer well-trained for the even pairs task, or into the training of a one-layer transformer. For both problems, our analysis shows that the joint training of attention and linear layers exhibits two distinct phases. In the first phase, the attention layer grows rapidly, mapping data sequences into separable vectors. In the second phase, the attention layer becomes stable, while the linear layer grows logarithmically and approaches in direction to a max-margin hyperplane that correctly separates the attention layer outputs into positive and negative samples, and the loss decreases at a rate of $O(1&#x2F;t)$. Our experiments validate those theoretical results. </p>
<blockquote>
<p>è¯­è¨€è¯†åˆ«ä»»åŠ¡åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­æ˜¯æœ€åŸºæœ¬çš„ä»»åŠ¡ä¹‹ä¸€ï¼Œå¹¶ä¸”å·²è¢«å¹¿æ³›åº”ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½ã€‚è¿™äº›ä»»åŠ¡åœ¨è§£é‡Šå˜å‹å™¨çš„å·¥ä½œåŸç†æ–¹é¢ä¹Ÿèµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºå¸¸è§„è¯­è¨€è¯†åˆ«ç±»åˆ«ä¸­çš„ä¸¤ä¸ªä»£è¡¨æ€§ä»»åŠ¡ï¼Œå³â€œå¶æ•°å¯¹â€å’Œâ€œå¥‡å¶æ ¡éªŒâ€ï¼Œè¿™ä¸¤ä¸ªä»»åŠ¡çš„ç›®æ ‡æ˜¯ç¡®å®šåœ¨ç»™å®šçš„åºåˆ—ä¸­æŸäº›å­åºåˆ—çš„å‡ºç°æ˜¯å¦ä¸ºå¶æ•°ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¢ç´¢ç”±æ³¨æ„åŠ›å±‚å’Œçº¿æ€§å±‚ç»„æˆçš„ä¸€å±‚å˜å‹å™¨å¦‚ä½•å­¦ä¹ è§£å†³è¿™äº›ä»»åŠ¡ï¼Œé€šè¿‡ç†è®ºåˆ†æå…¶åœ¨æ¢¯åº¦ä¸‹é™ä¸‹çš„è®­ç»ƒåŠ¨æ€ã€‚è™½ç„¶â€œå¶æ•°å¯¹â€å¯ä»¥ç›´æ¥ç”±ä¸€å±‚å˜å‹å™¨è§£å†³ï¼Œâ€œå¥‡å¶æ ¡éªŒâ€éœ€è¦é€šè¿‡å°†æ€ç»´é“¾ï¼ˆCoTï¼‰é›†æˆåˆ°ä¸ºâ€œå¶æ•°å¯¹â€ä»»åŠ¡è®­ç»ƒè‰¯å¥½çš„å˜å‹å™¨çš„æ¨ç†é˜¶æ®µæˆ–ä¸€å±‚å˜å‹å™¨çš„è®­ç»ƒä¸­æ¥è§£å†³ã€‚å¯¹äºè¿™ä¸¤ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ³¨æ„åŠ›å±‚å’Œçº¿æ€§å±‚çš„è”åˆè®­ç»ƒè¡¨ç°å‡ºä¸¤ä¸ªæ˜æ˜¾çš„é˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæ³¨æ„åŠ›å±‚è¿…é€Ÿå¢é•¿ï¼Œå°†æ•°æ®åºåˆ—æ˜ å°„ä¸ºå¯åˆ†ç«‹çš„å‘é‡ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ³¨æ„åŠ›å±‚å˜å¾—ç¨³å®šï¼Œè€Œçº¿æ€§å±‚çš„å¢é•¿å‘ˆå¯¹æ•°è¶‹åŠ¿ï¼Œå¹¶æœå‘ä¸€ä¸ªæœ€å¤§é—´éš”è¶…å¹³é¢å‘å±•ï¼Œè¯¥è¶…å¹³é¢èƒ½æ­£ç¡®åœ°å°†æ³¨æ„åŠ›å±‚çš„è¾“å‡ºåˆ†ä¸ºæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼ŒæŸå¤±ä»¥O(1&#x2F;t)çš„é€Ÿåº¦å‡å°‘ã€‚æˆ‘ä»¬çš„å®éªŒéªŒè¯äº†è¿™äº›ç†è®ºç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00926v1">PDF</a> accepted by ICML 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡ç ”ç©¶äº†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è¯­è¨€è¯†åˆ«ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹â€œeven pairsâ€å’Œâ€œparity checkâ€ä¸¤ä¸ªä»£è¡¨æ€§ä»»åŠ¡ã€‚æ–‡ç« ç€é‡æ¢è®¨äº†å•å±‚å˜å‹å™¨æ¨¡å‹å¦‚ä½•å­¦ä¹ è§£å†³è¿™äº›ä»»åŠ¡ï¼Œé€šè¿‡ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸¤ä¸ªæ˜æ˜¾é˜¶æ®µä»¥åŠå¦‚ä½•åˆ©ç”¨Chain-of-Thoughtï¼ˆCoTï¼‰è§£å†³å¥‡å¶æ ¡éªŒé—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€è¯†åˆ«ä»»åŠ¡æ˜¯è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„é‡è¦åŸºå‡†ï¼Œä¹Ÿæœ‰åŠ©äºè§£é‡Šå˜å‹å™¨çš„å·¥ä½œåŸç†ã€‚</li>
<li>â€œeven pairsâ€å’Œâ€œparity checkâ€æ˜¯è¯­è¨€è¯†åˆ«ä¸­çš„ä»£è¡¨æ€§ä»»åŠ¡ï¼Œæ—¨åœ¨ç¡®å®šç»™å®šåºåˆ—ä¸­æŸäº›å­åºåˆ—çš„å‡ºç°æ˜¯å¦ä¸ºå¶æ•°ã€‚</li>
<li>å•å±‚å˜å‹å™¨æ¨¡å‹å¯ä»¥ç›´æ¥è§£å†³â€œeven pairsâ€é—®é¢˜ï¼Œä½†è§£å†³â€œparity checkâ€é—®é¢˜éœ€è¦é›†æˆChain-of-Thoughtï¼ˆCoTï¼‰ã€‚</li>
<li>å•å±‚å˜å‹å™¨æ¨¡å‹åœ¨è§£å†³è¿™äº›é—®é¢˜çš„è¿‡ç¨‹ä¸­å±•ç°å‡ºä¸¤ä¸ªæ˜æ˜¾çš„è®­ç»ƒé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯æ³¨æ„åŠ›å±‚çš„å¿«é€Ÿå¢é•¿ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯æ³¨æ„åŠ›å±‚çš„ç¨³å®šä»¥åŠçº¿æ€§å±‚çš„å¯¹æ•°å¢é•¿ã€‚</li>
<li>çº¿æ€§å±‚æœ€ç»ˆä¼šæœå‘ä¸€ä¸ªæœ€å¤§é—´éš”è¶…å¹³é¢å‘å±•ï¼Œæ­£ç¡®åœ°å°†æ³¨æ„åŠ›å±‚çš„è¾“å‡ºåˆ†ä¸ºæ­£è´Ÿæ ·æœ¬ã€‚</li>
<li>æŸå¤±å‡½æ•°éšæ—¶é—´å‘ˆO(1&#x2F;t)é€Ÿç‡ä¸‹é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00926">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-517ddb8dd2f4df09ff9f84556bc1c1d4.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-Causal-World-Model-Underlying-Next-Token-Prediction-Exploring-GPT-in-a-Controlled-Environment"><a href="#A-Causal-World-Model-Underlying-Next-Token-Prediction-Exploring-GPT-in-a-Controlled-Environment" class="headerlink" title="A Causal World Model Underlying Next Token Prediction: Exploring GPT in   a Controlled Environment"></a>A Causal World Model Underlying Next Token Prediction: Exploring GPT in   a Controlled Environment</h2><p><strong>Authors:Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Estelle Aflalo, Vasudev Lal</strong></p>
<p>Do generative pre-trained transformer (GPT) models, trained only to predict the next token, implicitly learn a world model from which a sequence is generated one token at a time? We address this question by deriving a causal interpretation of the attention mechanism in GPT, and suggesting a causal world model that arises from this interpretation. Furthermore, we propose that GPT models, at inference time, can be utilized for zero-shot causal structure learning for input sequences and present a confidence score. Empirical evaluation is conducted in a controlled environment using the setup and rules of the Othello and Chess strategy games. A GPT, pre-trained on real-world games played with the intention of winning, is tested on out-of-distribution synthetic data consisting of sequences of random legal moves. We find that the GPT model is likely to generate legal next moves for out-of-distribution sequences for which a causal structure is encoded in the attention mechanism with high confidence. In cases for which the GPT model generates illegal moves it also fails to capture any causal structure. </p>
<blockquote>
<p>ä½¿ç”¨ä»…ç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªä»£å¸çš„ç”Ÿæˆå¼é¢„è®­ç»ƒè½¬æ¢å™¨ï¼ˆGPTï¼‰æ¨¡å‹ï¼Œæ˜¯å¦ä¼šéšå¼åœ°å­¦ä¹ ä¸€ä¸ªä¸–ç•Œæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿé€ä¸ªä»£å¸åœ°ç”Ÿæˆä¸€ä¸ªåºåˆ—ï¼Ÿæˆ‘ä»¬é€šè¿‡æ¨å¯¼GPTä¸­æ³¨æ„åŠ›æœºåˆ¶çš„å› æœè§£é‡Šï¼Œä»¥åŠç”±æ­¤äº§ç”Ÿçš„å› æœä¸–ç•Œæ¨¡å‹æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºï¼Œåœ¨æ¨ç†é˜¶æ®µï¼ŒGPTæ¨¡å‹å¯ç”¨äºè¾“å…¥åºåˆ—çš„é›¶æ ·æœ¬å› æœç»“æ„å­¦ä¹ ï¼Œå¹¶å‘ˆç°ç½®ä¿¡åº¦å¾—åˆ†ã€‚åœ¨Othelloå’Œè±¡æ£‹ç­–ç•¥æ¸¸æˆçš„è®¾ç½®å’Œè§„åˆ™æ§åˆ¶çš„ç¯å¢ƒä¸‹è¿›è¡Œå®è¯ç ”ç©¶ã€‚GPTåœ¨ç°å®ä¸–ç•Œæ¸¸æˆä¸­è¿›è¡Œé¢„è®­ç»ƒï¼Œæ—¨åœ¨èµ¢å¾—æ¯”èµ›ï¼Œç„¶åæµ‹è¯•å…¶åœ¨ç”±éšæœºåˆæ³•åŠ¨ä½œåºåˆ—ç»„æˆçš„ç¦»ç¾¤åˆæˆæ•°æ®ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬å‘ç°ï¼ŒGPTæ¨¡å‹å¾ˆå¯èƒ½ä¸ºç¦»ç¾¤åºåˆ—ç”Ÿæˆåˆæ³•çš„ä¸‹ä¸€ä¸ªåŠ¨ä½œï¼Œåœ¨è¿™äº›åŠ¨ä½œä¸­ï¼Œæ³¨æ„åŠ›æœºåˆ¶ç¼–ç äº†å› æœå…³ç³»ç»“æ„å¹¶è¡¨ç°å‡ºé«˜ç½®ä¿¡åº¦ã€‚åœ¨GPTæ¨¡å‹ç”Ÿæˆéæ³•åŠ¨ä½œçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿæ— æ³•æ•æ‰åˆ°ä»»ä½•å› æœå…³ç³»ç»“æ„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07446v3">PDF</a> International Conference on Machine Learning (ICML), 2025</p>
<p><strong>Summary</strong>ï¼šGPTæ¨¡å‹é€šè¿‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ç¬¦è¿›è¡Œè®­ç»ƒï¼Œæ˜¯å¦ä¼šä»ä¸–ç•Œæ¨¡å‹ä¸­ç”Ÿæˆåºåˆ—çš„æ¯ä¸€ä¸ªè¯ç¬¦ï¼Ÿæœ¬æ–‡ç»™å‡ºäº†ä¸€ä¸ªå¯¹GPTä¸­æ³¨æ„åŠ›æœºåˆ¶çš„å› æœè§£é‡Šï¼Œå¹¶æå‡ºä¸€ä¸ªç”±æ­¤äº§ç”Ÿçš„å› æœä¸–ç•Œæ¨¡å‹ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æå‡ºGPTæ¨¡å‹åœ¨æ¨ç†æ—¶é—´å¯ç”¨äºé›¶æ­¥å› æœç»“æ„å­¦ä¹ è¾“å…¥åºåˆ—å¹¶å‘ˆç°ç½®ä¿¡åº¦è¯„åˆ†ã€‚å®éªŒé€šè¿‡æ£‹ç±»æ¸¸æˆè¿›è¡Œå®è¯è¯„ä¼°ï¼Œç»“æœè¡¨æ˜GPTæ¨¡å‹èƒ½å¤Ÿé’ˆå¯¹æœ‰æ³¨æ„åŠ›æœºåˆ¶ç¼–ç å› æœç»“æ„çš„éåˆ†å¸ƒåºåˆ—ç”Ÿæˆåˆæ³•ä¸‹ä¸€æ­¥ï¼Œè€Œå¯¹ç”Ÿæˆéæ³•è¡Œä¸ºçš„åºåˆ—åˆ™æ— æ³•æ•æ‰åˆ°å› æœç»“æ„ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>GPTæ¨¡å‹æ˜¯å¦é€šè¿‡å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ç¬¦æ¥éšå«åœ°äº†è§£ä¸–ç•Œæ¨¡å‹ã€‚</li>
<li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶çš„å› æœè§£é‡Šï¼Œæå‡ºäº†ä¸€ä¸ªå› æœä¸–ç•Œæ¨¡å‹ã€‚</li>
<li>GPTæ¨¡å‹åœ¨æ¨ç†æ—¶é—´å¯ä»¥ç”¨äºé›¶æ­¥å› æœç»“æ„å­¦ä¹ è¾“å…¥åºåˆ—ã€‚</li>
<li>GPTæ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„å› æœç»“æ„å¯¹è¾“å‡ºåºåˆ—çš„åˆæ³•æ€§è¿›è¡Œè‡ªä¿¡åº¦è¯„ä¼°ã€‚</li>
<li>åœ¨æ£‹ç±»æ¸¸æˆçš„å®è¯è¯„ä¼°ä¸­ï¼ŒGPTæ¨¡å‹èƒ½é’ˆå¯¹æœ‰ç¼–ç å› æœç»“æ„çš„éåˆ†å¸ƒåºåˆ—ç”Ÿæˆåˆæ³•ä¸‹ä¸€æ­¥ã€‚</li>
<li>GPTæ¨¡å‹å¯¹ç”Ÿæˆéæ³•è¡Œä¸ºçš„åºåˆ—æ— æ³•æ•æ‰åˆ°å› æœç»“æ„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07446">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e96c365848126e19bc3d0de1dcdd990a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf1ced7876f0b6af52bd1a5ef3380de1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48a4a53684aa715f79709cb77933ce27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebb556c9bc12f4b3947eff8a94f9a624.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="An-Efficient-Matrix-Multiplication-Algorithm-for-Accelerating-Inference-in-Binary-and-Ternary-Neural-Networks"><a href="#An-Efficient-Matrix-Multiplication-Algorithm-for-Accelerating-Inference-in-Binary-and-Ternary-Neural-Networks" class="headerlink" title="An Efficient Matrix Multiplication Algorithm for Accelerating Inference   in Binary and Ternary Neural Networks"></a>An Efficient Matrix Multiplication Algorithm for Accelerating Inference   in Binary and Ternary Neural Networks</h2><p><strong>Authors:Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh</strong></p>
<p>Despite their tremendous success and versatility, Deep Neural Networks (DNNs) such as Large Language Models (LLMs) suffer from inference inefficiency and rely on advanced computational infrastructure. To address these challenges and make these models more accessible and cost-effective, in this paper, we propose algorithms to improve the inference time and memory efficiency of DNNs with binary and ternary weight matrices. Particularly focusing on matrix multiplication as the bottleneck operation of inference, we observe that, once trained, the weight matrices of a model no longer change. This allows us to preprocess these matrices and create indices that help reduce the storage requirements by a logarithmic factor while enabling our efficient inference algorithms. Specifically, for a $n\times n$ weight matrix, our efficient algorithm guarantees a time complexity of $O(\frac{n^2}{\log n})$, a logarithmic factor improvement over the standard vector-matrix multiplication. Besides theoretical analysis, we conduct extensive experiments to evaluate the practical efficiency of our algorithms. Our results confirm the superiority of our approach both with respect to time and memory, as we observed a reduction in the multiplication time up to 29x and memory usage up to 6x. When applied to LLMs, our experiments show up to a 5.24x speedup in the inference time. </p>
<blockquote>
<p>å°½ç®¡æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰å¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å–å¾—äº†å·¨å¤§çš„æˆåŠŸå¹¶å…·æœ‰æå¤§çš„çµæ´»æ€§ï¼Œä½†å®ƒä»¬å´é¢ä¸´ç€æ¨ç†æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œå¹¶ä¾èµ–äºå…ˆè¿›çš„è®¡ç®—åŸºç¡€è®¾æ–½ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œä½¿è¿™äº›æ¨¡å‹æ›´åŠ æ˜“äºè®¿é—®å¹¶å…·æœ‰æˆæœ¬æ•ˆç›Šï¼Œæœ¬æ–‡æå‡ºäº†æ”¹è¿›DNNæ¨ç†æ—¶é—´å’Œå†…å­˜æ•ˆç‡çš„ç®—æ³•ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹äºŒå…ƒå’Œä¸‰å…ƒæƒé‡çŸ©é˜µã€‚æˆ‘ä»¬é‡ç‚¹å…³æ³¨çŸ©é˜µä¹˜æ³•ä½œä¸ºæ¨ç†è¿‡ç¨‹ä¸­çš„ç“¶é¢ˆæ“ä½œï¼Œè§‚å¯Ÿåˆ°ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹çš„æƒé‡çŸ©é˜µå°±ä¸å†æ”¹å˜ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹è¿™äº›çŸ©é˜µè¿›è¡Œé¢„å¤„ç†å¹¶åˆ›å»ºç´¢å¼•ï¼Œæœ‰åŠ©äºä»¥å¯¹æ•°å› å­å‡å°‘å­˜å‚¨è¦æ±‚ï¼ŒåŒæ—¶å®ç°é«˜æ•ˆçš„æ¨ç†ç®—æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äº$n\times n$çš„æƒé‡çŸ©é˜µï¼Œæˆ‘ä»¬çš„é«˜æ•ˆç®—æ³•ä¿è¯äº†æ—¶é—´å¤æ‚åº¦ä¸º$O(\frac{n^2}{\log n})$ï¼Œç›¸å¯¹äºæ ‡å‡†å‘é‡-çŸ©é˜µä¹˜æ³•æœ‰ä¸€ä¸ªå¯¹æ•°å› å­çš„æ”¹è¿›ã€‚é™¤äº†ç†è®ºåˆ†æå¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒæ¥è¯„ä¼°ç®—æ³•çš„å®é™…æ•ˆç‡ã€‚ç»“æœè¯å®äº†æˆ‘ä»¬æ–¹æ³•åœ¨æ—¶é—´å’Œå†…å­˜æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä¹˜æ³•æ—¶é—´å‡å°‘äº†é«˜è¾¾29å€ï¼Œå†…å­˜ä½¿ç”¨ç‡å‡å°‘äº†é«˜è¾¾6å€ã€‚å½“åº”ç”¨äºLLMæ—¶ï¼Œæˆ‘ä»¬çš„å®éªŒæ˜¾ç¤ºæ¨ç†æ—¶é—´æœ€å¤šå¯åŠ å¿«5.24å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.06360v3">PDF</a> Accepted at ICML 2025</p>
<p><strong>Summary</strong><br>     è¯¥è®ºæ–‡é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰å¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨é—®é¢˜ï¼Œæå‡ºäº†æ”¹è¿›ç®—æ³•ã€‚é€šè¿‡å¼•å…¥äºŒè¿›åˆ¶å’Œä¸‰å…ƒæƒé‡çŸ©é˜µï¼Œä¼˜åŒ–çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œé™ä½å­˜å‚¨éœ€æ±‚å¹¶æé«˜æ¨ç†æ•ˆç‡ã€‚ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯å‡è¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ—¶é—´å’Œå†…å­˜ä¸Šå‡è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œåº”ç”¨äºLLMsæ—¶æ¨ç†é€Ÿåº¦æœ€å¿«å¯æé«˜5.24å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡å…³æ³¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰å¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†æ•ˆç‡å’Œå†…å­˜æ•ˆç‡é—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä½¿ç”¨äºŒè¿›åˆ¶å’Œä¸‰å…ƒæƒé‡çŸ©é˜µçš„ç®—æ³•ï¼Œä»¥ä¼˜åŒ–çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œä»è€Œæé«˜æ¨ç†æ•ˆç‡ã€‚</li>
<li>è®ºæ–‡è§‚å¯Ÿåˆ°è®­ç»ƒåçš„æƒé‡çŸ©é˜µä¸å†æ”¹å˜ï¼Œå› æ­¤å¯ä»¥å¯¹å…¶è¿›è¡Œé¢„å¤„ç†å¹¶å»ºç«‹ç´¢å¼•ï¼Œä»¥é™ä½å­˜å‚¨è¦æ±‚ã€‚</li>
<li>å¯¹äº$n\times n$çš„æƒé‡çŸ©é˜µï¼Œè®ºæ–‡æå‡ºçš„ç®—æ³•ä¿è¯æ—¶é—´å¤æ‚åº¦ä¸º$O(\frac{n^2}{\log n})$ï¼Œè¾ƒæ ‡å‡†å‘é‡çŸ©é˜µä¹˜æ³•æœ‰å¯¹æ•°çº§çš„æ”¹è¿›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨æ—¶é—´å’Œå†…å­˜ä¸Šå‡è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œä¹˜æ³•æ—¶é—´æœ€å¤šå¯å‡å°‘29å€ï¼Œå†…å­˜ä½¿ç”¨æœ€å¤šå¯å‡å°‘6å€ã€‚</li>
<li>å½“åº”ç”¨äºLLMsæ—¶ï¼Œè¯¥ç®—æ³•å¯æé«˜æ¨ç†é€Ÿåº¦ï¼Œæœ€å¿«å¯æé«˜5.24å€ã€‚</li>
<li>è¯¥è®ºæ–‡ä¸ºDNNsçš„æ¨ç†æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨é—®é¢˜æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.06360">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-811d28f73e425385b29907e55fb19475.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbdcd9d37d3fc68b9a55226b685883ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-384771d99e44b1401f24564cbf9aa8ca.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a794957afd8d16519334858b03cbcf43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-327c2db1dcc42a3130e17c64235af032.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MoDeGPT-Modular-Decomposition-for-Large-Language-Model-Compression"><a href="#MoDeGPT-Modular-Decomposition-for-Large-Language-Model-Compression" class="headerlink" title="MoDeGPT: Modular Decomposition for Large Language Model Compression"></a>MoDeGPT: Modular Decomposition for Large Language Model Compression</h2><p><strong>Authors:Chi-Heng Lin, Shangqian Gao, James Seale Smith, Abhishek Patel, Shikhar Tuli, Yilin Shen, Hongxia Jin, Yen-Chang Hsu</strong></p>
<p>Large Language Models (LLMs) have reshaped the landscape of artificial intelligence by demonstrating exceptional performance across various tasks. However, substantial computational requirements make their deployment challenging on devices with limited resources. Recently, compression methods using low-rank matrix techniques have shown promise, yet these often lead to degraded accuracy or introduce significant overhead in parameters and inference latency. This paper introduces \textbf{Mo}dular \textbf{De}composition (MoDeGPT), a novel structured compression framework that does not need recovery fine-tuning while resolving the above drawbacks. MoDeGPT partitions the Transformer block into modules comprised of matrix pairs and reduces the hidden dimensions via reconstructing the module-level outputs. MoDeGPT is developed based on a theoretical framework that utilizes three well-established matrix decomposition algorithms â€“ Nystr&quot;om approximation, CR decomposition, and SVD â€“ and applies them to our redefined transformer modules. Our comprehensive experiments show MoDeGPT, without backward propagation, matches or surpasses previous structured compression methods that rely on gradient information, and saves 98% of compute costs on compressing a 13B model. On \textsc{Llama}-2&#x2F;3 and OPT models, MoDeGPT maintains 90-95% zero-shot performance with 25-30% compression rates. Moreover, the compression can be done on a single GPU within a few hours and increases the inference throughput by up to 46%. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„é¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä»è€Œæ”¹å˜äº†äººå·¥æ™ºèƒ½é¢†åŸŸçš„æ ¼å±€ã€‚ç„¶è€Œï¼Œç”±äºå…¶å·¨å¤§çš„è®¡ç®—éœ€æ±‚ï¼Œåœ¨èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²è¿™äº›æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ€è¿‘ï¼Œä½¿ç”¨ä½ç§©çŸ©é˜µæŠ€æœ¯çš„å‹ç¼©æ–¹æ³•æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€ä¼šå¯¼è‡´ç²¾åº¦ä¸‹é™æˆ–åœ¨å‚æ•°å’Œæ¨ç†å»¶è¿Ÿæ–¹é¢å¼•å…¥æ˜¾è‘—å¼€é”€ã€‚æœ¬æ–‡ä»‹ç»äº†<strong>MoDeGPT</strong>ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç»“æ„åŒ–å‹ç¼©æ¡†æ¶ï¼Œæ— éœ€æ¢å¤å¾®è°ƒå³å¯è§£å†³ä¸Šè¿°ç¼ºç‚¹ã€‚MoDeGPTå°†Transformerå—åˆ†åŒºæˆç”±çŸ©é˜µå¯¹ç»„æˆçš„æ¨¡å—ï¼Œå¹¶é€šè¿‡é‡å»ºæ¨¡å—çº§è¾“å‡ºé™ä½éšè—ç»´åº¦ã€‚MoDeGPTæ˜¯åŸºäºä¸€ä¸ªç†è®ºæ¡†æ¶å¼€å‘çš„ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä¸‰ç§æˆç†Ÿçš„çŸ©é˜µåˆ†è§£ç®—æ³•â€”â€”NystrÃ¶mè¿‘ä¼¼ã€CRåˆ†è§£å’ŒSVDâ€”â€”å¹¶å°†å®ƒä»¬åº”ç”¨äºæˆ‘ä»¬é‡æ–°å®šä¹‰çš„å˜å‹å™¨æ¨¡å—ã€‚æˆ‘ä»¬çš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒMoDeGPTæ— éœ€åå‘ä¼ æ’­å³å¯åŒ¹é…æˆ–è¶…è¶Šä¾èµ–æ¢¯åº¦ä¿¡æ¯çš„å…ˆå‰ç»“æ„åŒ–å‹ç¼©æ–¹æ³•ï¼Œå¹¶åœ¨å‹ç¼©13Bæ¨¡å‹æ—¶èŠ‚çœäº†98%çš„è®¡ç®—æˆæœ¬ã€‚åœ¨\textsc{Llama}-2&#x2F;3å’ŒOPTæ¨¡å‹ä¸Šï¼ŒMoDeGPTåœ¨25-30%çš„å‹ç¼©ç‡ä¸‹ä¿æŒäº†90-95%çš„é›¶æ ·æœ¬æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå‹ç¼©å¯ä»¥åœ¨å•ä¸ªGPUä¸Šäºå‡ å°æ—¶å†…å®Œæˆï¼Œå¹¶ä¸”æœ€å¤šå¯æé«˜æ¨ç†ååé‡è¾¾46%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09632v5">PDF</a> ICLR 2025 Oral</p>
<p><strong>Summary</strong></p>
<p>LLMçš„æ€§èƒ½ä»¤äººç©ç›®ï¼Œä½†å…¶å·¨å¤§çš„è®¡ç®—éœ€æ±‚åœ¨èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚æœ€è¿‘ï¼Œä½ç§©çŸ©é˜µæŠ€æœ¯çš„å‹ç¼©æ–¹æ³•å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å¯èƒ½å¯¼è‡´ç²¾åº¦ä¸‹é™æˆ–å¢åŠ å‚æ•°å’Œæ¨ç†å»¶è¿Ÿã€‚æœ¬æ–‡æå‡ºMoDeGPTï¼Œä¸€ç§æ–°å‹ç»“æ„åŒ–å‹ç¼©æ¡†æ¶ï¼Œæ— éœ€æ¢å¤å¾®è°ƒå³å¯è§£å†³ä¸Šè¿°é—®é¢˜ã€‚MoDeGPTå°†Transformerå—åˆ†åŒºä¸ºæ¨¡å—ï¼Œåˆ©ç”¨ä¸‰ç§çŸ©é˜µåˆ†è§£ç®—æ³•ï¼Œå®ç°æ¨¡å—çº§åˆ«çš„è¾“å‡ºé‡å»ºå’Œéšè—ç»´åº¦çš„å‡å°‘ã€‚å®éªŒæ˜¾ç¤ºï¼ŒMoDeGPTåœ¨ä¸è¿›è¡Œåå‘ä¼ æ’­çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šä¾èµ–æ¢¯åº¦ä¿¡æ¯çš„ä¼ ç»Ÿå‹ç¼©æ–¹æ³•ï¼Œåœ¨å‹ç¼©13Bæ¨¡å‹æ—¶èŠ‚çœ98%çš„è®¡ç®—æˆæœ¬ã€‚å¯¹äºLlama-2&#x2F;3å’ŒOPTæ¨¡å‹ï¼ŒMoDeGPTåœ¨ä¿æŒ90-95%é›¶æ ·æœ¬æ€§èƒ½çš„åŒæ—¶å®ç°25-30%çš„å‹ç¼©ç‡ï¼Œä¸”å‹ç¼©è¿‡ç¨‹å¯åœ¨å•ä¸ªGPUä¸Šå‡ å°æ—¶å†…å®Œæˆï¼Œæé«˜æ¨ç†é€Ÿåº¦è¾¾46%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMå±•ç°äº†å¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ä½ç§©çŸ©é˜µæŠ€æœ¯çš„å‹ç¼©æ–¹æ³•è™½ç„¶æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å¯èƒ½å¸¦æ¥ç²¾åº¦æŸå¤±å’Œé¢å¤–çš„å‚æ•°ä¸æ¨ç†å»¶è¿Ÿã€‚</li>
<li>MoDeGPTæ˜¯ä¸€ç§æ–°å‹ç»“æ„åŒ–å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åˆ†è§£è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæ— éœ€æ¢å¤å¾®è°ƒã€‚</li>
<li>MoDeGPTå°†Transformerå—åˆ’åˆ†ä¸ºæ¨¡å—å¹¶è¿ç”¨ä¸‰ç§çŸ©é˜µåˆ†è§£ç®—æ³•ï¼Œå®ç°æ¨¡å—çº§åˆ«çš„è¾“å‡ºé‡å»ºå’Œéšè—ç»´åº¦å‡å°‘ã€‚</li>
<li>MoDeGPTåœ¨ä¸è¿›è¡Œåå‘ä¼ æ’­çš„æƒ…å†µä¸‹è¶…è¶Šä¼ ç»Ÿå‹ç¼©æ–¹æ³•ï¼Œå¤§å¹…èŠ‚çœè®¡ç®—æˆæœ¬ã€‚</li>
<li>MoDeGPTåœ¨ä¿æŒé«˜é›¶æ ·æœ¬æ€§èƒ½çš„åŒæ—¶å®ç°è¾ƒé«˜çš„å‹ç¼©ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.09632">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4a2373489183353348b449a9c9c8ec76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d50e437ae673d47685274776476fddb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55c92b06a4cb98ffdc24234a3cca84f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d0b1c16480672f2c2df81b1fa8c0c7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e249b33845c4ee31b5f86e1de125f5b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="FlexLLM-A-System-for-Co-Serving-Large-Language-Model-Inference-and-Parameter-Efficient-Finetuning"><a href="#FlexLLM-A-System-for-Co-Serving-Large-Language-Model-Inference-and-Parameter-Efficient-Finetuning" class="headerlink" title="FlexLLM: A System for Co-Serving Large Language Model Inference and   Parameter-Efficient Finetuning"></a>FlexLLM: A System for Co-Serving Large Language Model Inference and   Parameter-Efficient Finetuning</h2><p><strong>Authors:Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia</strong></p>
<p>Finetuning large language models (LLMs) is essential for task adaptation, yet serving stacks today isolate inference and finetuning on separate GPU clusters â€“ wasting resources and under-utilizing hardware. We introduce FlexLLM, the first system to co-serve LLM inference and PEFT-based finetuning on shared GPUs by fusing computation at the token level. The static compilation optimizations in FlexLLM â€“ dependent parallelization and graph pruning significantly shrink activation memory, leading to end-to-end GPU memory savings by up to 80%. At runtime, a novel token-level finetuning mechanism paired with a hybrid token scheduler dynamically interleaves inference and training tokens within each co-serving iteration, meeting strict latency SLOs while maximizing utilization. In end-to-end benchmarks on LLaMA-3.1-8B, Qwen-2.5-14B, and Qwen-2.5-32B, FlexLLM sustains the inference SLO requirements up to 20 req&#x2F;s, and improves finetuning throughput by 1.9-4.8x under heavy inference workloads and 2.5-6.8x under light loads, preserving over 76% of peak finetuning progress even at peak demand. The source code of FlexLLM is publicly available at <a target="_blank" rel="noopener" href="https://github.com/flexflow/FlexFlow/">https://github.com/flexflow/FlexFlow/</a>. </p>
<blockquote>
<p>å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äºä»»åŠ¡é€‚åº”è‡³å…³é‡è¦ï¼Œç„¶è€Œï¼Œå½“å‰çš„æœåŠ¡å™¨å †æ ˆå°†æ¨ç†å’Œå¾®è°ƒéš”ç¦»åœ¨ä¸åŒçš„GPUé›†ç¾¤ä¸Šï¼Œè¿™æµªè´¹äº†èµ„æºå¹¶æœªèƒ½å……åˆ†åˆ©ç”¨ç¡¬ä»¶ã€‚æˆ‘ä»¬æ¨å‡ºäº†FlexLLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿåœ¨å…±äº«GPUä¸Šå…±åŒæä¾›LLMæ¨ç†å’ŒåŸºäºPEFTçš„å¾®è°ƒçš„ç³»ç»Ÿï¼Œé€šè¿‡ä»¤ç‰Œçº§åˆ«çš„èåˆè®¡ç®—æ¥å®ç°ã€‚FlexLLMä¸­çš„é™æ€ç¼–è¯‘ä¼˜åŒ–â€”â€”ä¾èµ–å¹¶è¡ŒåŒ–å’Œå›¾ä¿®å‰ªï¼Œæå¤§åœ°å‡å°‘äº†æ¿€æ´»å†…å­˜ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯GPUå†…å­˜èŠ‚çœé«˜è¾¾80%ã€‚è¿è¡Œæ—¶ï¼Œä¸€ç§æ–°å‹ä»¤ç‰Œçº§å¾®è°ƒæœºåˆ¶ä¸æ··åˆä»¤ç‰Œè°ƒåº¦ç¨‹åºç›¸ç»“åˆï¼Œåœ¨æ¯ä¸ªå…±åŒæœåŠ¡è¿­ä»£ä¸­åŠ¨æ€äº¤é”™æ¨ç†å’Œè®­ç»ƒä»¤ç‰Œï¼Œæ»¡è¶³ä¸¥æ ¼çš„å»¶è¿ŸSLOè¦æ±‚ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°æé«˜åˆ©ç”¨ç‡ã€‚åœ¨LLaMA-3.1-8Bã€Qwen-2.5-14Bå’ŒQwen-2.5-32Bçš„ç«¯åˆ°ç«¯åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFlexLLMç»´æŒäº†é«˜è¾¾20 req&#x2F;sçš„æ¨ç†SLOè¦æ±‚ï¼Œå¹¶åœ¨é‡æ¨ç†å·¥ä½œè´Ÿè½½ä¸‹æé«˜å¾®è°ƒååé‡1.9-4.8å€ï¼Œåœ¨è½»è´Ÿè½½ä¸‹æé«˜2.5-6.8å€ã€‚å³ä½¿åœ¨é«˜å³°éœ€æ±‚æ—¶ï¼Œä¹Ÿèƒ½ä¿æŒè¶…è¿‡76%çš„å³°å€¼å¾®è°ƒè¿›åº¦ã€‚FlexLLMçš„æºä»£ç å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/flexflow/FlexFlow/%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/flexflow/FlexFlow/ä¸Šå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18789v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¾®è°ƒå¯¹äºä»»åŠ¡é€‚åº”è‡³å…³é‡è¦ï¼Œä½†ç›®å‰çš„æœåŠ¡å †æ ˆå°†æ¨ç†å’Œå¾®è°ƒéš”ç¦»åœ¨å•ç‹¬çš„GPUé›†ç¾¤ä¸Šï¼Œæµªè´¹èµ„æºä¸”æœªèƒ½å……åˆ†åˆ©ç”¨ç¡¬ä»¶ã€‚FlexLLMç³»ç»Ÿé¦–æ¬¡å®ç°äº†åœ¨å…±äº«GPUä¸ŠåŒæ—¶æä¾›LLMæ¨ç†å’ŒåŸºäºPEFTçš„å¾®è°ƒæœåŠ¡ï¼Œé€šè¿‡ä»¤ç‰Œçº§åˆ«çš„èåˆè®¡ç®—ã€‚FlexLLMçš„é™æ€ç¼–è¯‘ä¼˜åŒ–ï¼Œå¦‚ä¾èµ–å¹¶è¡ŒåŒ–å’Œå›¾å‰ªæï¼Œæ˜¾è‘—å‡å°‘äº†æ¿€æ´»å†…å­˜ï¼Œå®ç°äº†ç«¯åˆ°ç«¯GPUå†…å­˜èŠ‚çœé«˜è¾¾80%ã€‚è¿è¡Œæ—¶ï¼Œä¸€ç§æ–°çš„ä»¤ç‰Œçº§å¾®è°ƒæœºåˆ¶ä¸æ··åˆä»¤ç‰Œè°ƒåº¦å™¨ç›¸ç»“åˆï¼Œåœ¨æ¯ä¸ªååŒæœåŠ¡è¿­ä»£ä¸­åŠ¨æ€äº¤æ›¿æ¨ç†å’Œè®­ç»ƒä»¤ç‰Œï¼Œæ»¡è¶³ä¸¥æ ¼çš„å»¶è¿ŸSLOè¦æ±‚ï¼ŒåŒæ—¶æœ€å¤§åŒ–åˆ©ç”¨ç‡ã€‚åœ¨LLaMA-3.1-8Bã€Qwen-2.5-14Bå’ŒQwen-2.5-32Bçš„ç«¯åˆ°ç«¯åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFlexLLMç»´æŒäº†æ¨ç†SLOè¦æ±‚ï¼Œå¹¶åœ¨é‡è´Ÿè½½å’Œè½»è´Ÿè½½ä¸‹åˆ†åˆ«æé«˜äº†å¾®è°ƒååé‡çš„1.9-4.8å€å’Œ2.5-6.8å€ï¼Œå³ä½¿åœ¨é«˜å³°éœ€æ±‚æ—¶ä¹Ÿèƒ½ä¿æŒè¶…è¿‡76%çš„å³°å€¼å¾®è°ƒè¿›åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FlexLLMç³»ç»Ÿå…è®¸åœ¨å…±äº«GPUä¸ŠåŒæ—¶è¿›è¡ŒLLMæ¨ç†å’Œå¾®è°ƒï¼Œæé«˜äº†èµ„æºåˆ©ç”¨ç‡ã€‚</li>
<li>é€šè¿‡ä»¤ç‰Œçº§åˆ«çš„èåˆè®¡ç®—ï¼ŒFlexLLMä¼˜åŒ–äº†è®¡ç®—è¿‡ç¨‹ã€‚</li>
<li>é™æ€ç¼–è¯‘ä¼˜åŒ–ï¼ˆå¦‚ä¾èµ–å¹¶è¡ŒåŒ–å’Œå›¾å‰ªæï¼‰æ˜¾è‘—å‡å°‘äº†æ¿€æ´»å†…å­˜ä½¿ç”¨ã€‚</li>
<li>FlexLLMå®ç°äº†é«˜è¾¾80%çš„ç«¯åˆ°ç«¯GPUå†…å­˜èŠ‚çœã€‚</li>
<li>æ–°çš„ä»¤ç‰Œçº§å¾®è°ƒæœºåˆ¶å’Œæ··åˆä»¤ç‰Œè°ƒåº¦å™¨åŠ¨æ€äº¤æ›¿æ¨ç†å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œæ»¡è¶³å»¶è¿Ÿè¦æ±‚å¹¶æœ€å¤§åŒ–åˆ©ç”¨ç‡ã€‚</li>
<li>åœ¨å¤šç§LLMåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFlexLLMç»´æŒäº†æ¨ç†æ€§èƒ½å¹¶æ˜¾è‘—æé«˜äº†å¾®è°ƒååé‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.18789">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2e79adf5e58663f68d2245b4751a5da0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e23aa79c288f629fe6a7ecd11a9cdae0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-259af12382c51f7b94b710ec9d5132fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0165d11d76bc3d51eded5e7cae07f098.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-06/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-06/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-06/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-25d23e516ee65375e4cc85089bd98480.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-06  Exploring Equity of Climate Policies using Multi-Agent Multi-Objective   Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-06/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-8707e3770fca67020b56ee958d37a14a.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-06  TRAVELER A Benchmark for Evaluating Temporal Reasoning across Vague,   Implicit and Explicit References
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26254.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
