<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-26  PartGen Part-level 3D Generation and Reconstruction with Multi-View   Diffusion Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-1ead218b7a67780339b0cc9755cc860e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    38 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-26-æ›´æ–°"><a href="#2024-12-26-æ›´æ–°" class="headerlink" title="2024-12-26 æ›´æ–°"></a>2024-12-26 æ›´æ–°</h1><h2 id="PartGen-Part-level-3D-Generation-and-Reconstruction-with-Multi-View-Diffusion-Models"><a href="#PartGen-Part-level-3D-Generation-and-Reconstruction-with-Multi-View-Diffusion-Models" class="headerlink" title="PartGen: Part-level 3D Generation and Reconstruction with Multi-View   Diffusion Models"></a>PartGen: Part-level 3D Generation and Reconstruction with Multi-View   Diffusion Models</h2><p><strong>Authors:Minghao Chen, Roman Shapovalov, Iro Laina, Tom Monnier, Jianyuan Wang, David Novotny, Andrea Vedaldi</strong></p>
<p>Text- or image-to-3D generators and 3D scanners can now produce 3D assets with high-quality shapes and textures. These assets typically consist of a single, fused representation, like an implicit neural field, a Gaussian mixture, or a mesh, without any useful structure. However, most applications and creative workflows require assets to be made of several meaningful parts that can be manipulated independently. To address this gap, we introduce PartGen, a novel approach that generates 3D objects composed of meaningful parts starting from text, an image, or an unstructured 3D object. First, given multiple views of a 3D object, generated or rendered, a multi-view diffusion model extracts a set of plausible and view-consistent part segmentations, dividing the object into parts. Then, a second multi-view diffusion model takes each part separately, fills in the occlusions, and uses those completed views for 3D reconstruction by feeding them to a 3D reconstruction network. This completion process considers the context of the entire object to ensure that the parts integrate cohesively. The generative completion model can make up for the information missing due to occlusions; in extreme cases, it can hallucinate entirely invisible parts based on the input 3D asset. We evaluate our method on generated and real 3D assets and show that it outperforms segmentation and part-extraction baselines by a large margin. We also showcase downstream applications such as 3D part editing. </p>
<blockquote>
<p>æ–‡æœ¬æˆ–å›¾åƒåˆ°3Dç”Ÿæˆå™¨å’Œ3Dæ‰«æä»ªç°åœ¨å¯ä»¥ç”Ÿæˆå…·æœ‰é«˜è´¨é‡å½¢çŠ¶å’Œçº¹ç†çš„3Dèµ„äº§ã€‚è¿™äº›èµ„äº§é€šå¸¸ç”±å•ä¸€èåˆè¡¨ç¤ºç»„æˆï¼Œå¦‚éšå¼ç¥ç»ç½‘ç»œã€é«˜æ–¯æ··åˆæˆ–ç½‘æ ¼ï¼Œè€Œæ²¡æœ‰æœ‰ç”¨çš„ç»“æ„ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°åº”ç”¨ç¨‹åºå’Œåˆ›æ„å·¥ä½œæµç¨‹è¦æ±‚èµ„äº§ç”±å¯ä»¥ç‹¬ç«‹æ“ä½œçš„å¤šä¸ªæœ‰æ„ä¹‰çš„éƒ¨åˆ†ç»„æˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†PartGenï¼Œè¿™æ˜¯ä¸€ç§ä»æ–‡æœ¬ã€å›¾åƒæˆ–æ— åºçš„3Då¯¹è±¡å¼€å§‹ç”Ÿæˆç”±æœ‰æ„ä¹‰çš„éƒ¨ä»¶ç»„æˆçš„3Då¯¹è±¡çš„æ–°æ–¹æ³•ã€‚é¦–å…ˆï¼Œç»™å®šä¸€ä¸ª3Då¯¹è±¡çš„å¤šä¸ªè§†å›¾ï¼Œæ— è®ºæ˜¯ç”Ÿæˆçš„è¿˜æ˜¯æ¸²æŸ“çš„ï¼Œå¤šè§†å›¾æ‰©æ•£æ¨¡å‹ä¼šæå–ä¸€ç»„åˆç†ä¸”è§†å›¾ä¸€è‡´çš„éƒ¨åˆ†åˆ†å‰²ï¼Œå°†å¯¹è±¡åˆ†å‰²æˆå„ä¸ªéƒ¨åˆ†ã€‚ç„¶åï¼Œç¬¬äºŒä¸ªå¤šè§†å›¾æ‰©æ•£æ¨¡å‹å•ç‹¬å¤„ç†æ¯ä¸ªéƒ¨åˆ†ï¼Œå¡«å……é®æŒ¡ç‰©ï¼Œå¹¶ä½¿ç”¨è¿™äº›å®Œæˆçš„è§†å›¾è¿›è¡Œ3Dé‡å»ºï¼Œæ–¹æ³•æ˜¯å°†å…¶è¾“å…¥åˆ°3Dé‡å»ºç½‘ç»œä¸­ã€‚æ­¤å®Œæˆè¿‡ç¨‹ä¼šè€ƒè™‘æ•´ä¸ªå¯¹è±¡çš„ä¸Šä¸‹æ–‡ï¼Œä»¥ç¡®ä¿å„éƒ¨åˆ†èƒ½å¤Ÿç´§å¯†é›†æˆã€‚ç”Ÿæˆå®Œæˆæ¨¡å‹å¯ä»¥å¼¥è¡¥å› é®æŒ¡è€Œç¼ºå¤±çš„ä¿¡æ¯ï¼›åœ¨æç«¯æƒ…å†µä¸‹ï¼Œå®ƒå¯ä»¥æ ¹æ®è¾“å…¥çš„3Dèµ„äº§å®Œå…¨è™šæ„å‡ºä¸å¯è§çš„éƒ¨åˆ†ã€‚æˆ‘ä»¬åœ¨ç”Ÿæˆçš„å’ŒçœŸå®çš„3Dèµ„äº§ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶æ˜¾ç¤ºå‡ºå®ƒå¤§å¤§ä¼˜äºåˆ†å‰²å’Œéƒ¨åˆ†æå–çš„åŸºçº¿ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸‹æ¸¸åº”ç”¨ï¼Œå¦‚3Dé›¶ä»¶ç¼–è¾‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18608v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://silent-chen.github.io/PartGen/">https://silent-chen.github.io/PartGen/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºPartGençš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»æ–‡æœ¬ã€å›¾åƒæˆ–æ— åºçš„3Då¯¹è±¡å¼€å§‹ï¼Œç”Ÿæˆç”±æœ‰æ„ä¹‰çš„éƒ¨ä»¶ç»„æˆçš„3Dç‰©ä½“ã€‚PartGené€šè¿‡å¤šè§†è§’æ‰©æ•£æ¨¡å‹æå–å‡ºå¯èƒ½çš„ã€è§†è§’ä¸€è‡´çš„éƒ¨ä»¶åˆ†å‰²ï¼Œç„¶åå¯¹æ¯ä¸€ä¸ªéƒ¨ä»¶è¿›è¡Œå¡«å……å’Œå®Œå–„ï¼Œæœ€åé€šè¿‡3Dé‡å»ºç½‘ç»œè¿›è¡Œä¸‰ç»´é‡å»ºã€‚æ­¤æ–¹æ³•èƒ½å¤Ÿå¼¥è¡¥å› é®æŒ¡è€Œç¼ºå¤±çš„ä¿¡æ¯ï¼Œç”šè‡³åœ¨æç«¯æƒ…å†µä¸‹ï¼Œå¯ä»¥åŸºäºè¾“å…¥çš„3Dèµ„äº§å‡­ç©ºç”Ÿæˆå®Œå…¨ä¸å¯è§çš„éƒ¨ä»¶ã€‚PartGenåœ¨ç”Ÿæˆå’ŒçœŸå®çš„3Dèµ„äº§ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„åˆ†å‰²å’Œéƒ¨ä»¶æå–æ–¹æ³•ï¼Œå¹¶åœ¨3Déƒ¨ä»¶ç¼–è¾‘ç­‰ä¸‹æ¸¸åº”ç”¨å±•ç¤ºäº†å…¶æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PartGenèƒ½å¤Ÿç”Ÿæˆç”±æœ‰æ„ä¹‰éƒ¨ä»¶ç»„æˆçš„3Dèµ„äº§ï¼Œä»æ–‡æœ¬ã€å›¾åƒæˆ–æ— åºçš„3Då¯¹è±¡å¼€å§‹ã€‚</li>
<li>PartGenä½¿ç”¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹æå–3Dç‰©ä½“çš„éƒ¨ä»¶åˆ†å‰²ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿå¡«å……å’Œå®Œå–„éƒ¨ä»¶ï¼Œå¹¶è€ƒè™‘æ•´ä¸ªç‰©ä½“çš„ä¸Šä¸‹æ–‡æ¥ç¡®ä¿éƒ¨ä»¶çš„æ•´åˆã€‚</li>
<li>PartGenèƒ½å¤Ÿå¼¥è¡¥å› é®æŒ¡è€Œç¼ºå¤±çš„ä¿¡æ¯ï¼Œç”šè‡³ç”Ÿæˆå®Œå…¨ä¸å¯è§çš„éƒ¨ä»¶ã€‚</li>
<li>PartGenåœ¨ç”Ÿæˆå’ŒçœŸå®çš„3Dèµ„äº§ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚</li>
<li>PartGenå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¦‚3Déƒ¨ä»¶ç¼–è¾‘ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</li>
<li>PartGenä¸ºåˆ›å»ºå’Œæ“ä½œå¤æ‚çš„3Dåœºæ™¯æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„å·¥å…·ï¼Œæœ‰åŠ©äºæ¨åŠ¨3Dç”Ÿæˆå’Œç¼–è¾‘æŠ€æœ¯çš„å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18608">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8a6eb0c9674fc20fcc197c698773b0c6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a4484bed5c2f49df6684085dd8cb8c1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7a04b43ae9c468b0c9a10571b740f65a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ec6164f2b484e5b17e41a37dff6fa50.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Resolution-Robust-3D-MRI-Reconstruction-with-2D-Diffusion-Priors-Diverse-Resolution-Training-Outperforms-Interpolation"><a href="#Resolution-Robust-3D-MRI-Reconstruction-with-2D-Diffusion-Priors-Diverse-Resolution-Training-Outperforms-Interpolation" class="headerlink" title="Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors:   Diverse-Resolution Training Outperforms Interpolation"></a>Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors:   Diverse-Resolution Training Outperforms Interpolation</h2><p><strong>Authors:Anselm Krainovic, Stefan Ruschke, Reinhard Heckel</strong></p>
<p>Deep learning-based 3D imaging, in particular magnetic resonance imaging (MRI), is challenging because of limited availability of 3D training data. Therefore, 2D diffusion models trained on 2D slices are starting to be leveraged for 3D MRI reconstruction. However, as we show in this paper, existing methods pertain to a fixed voxel size, and performance degrades when the voxel size is varied, as it is often the case in clinical practice. In this paper, we propose and study several approaches for resolution-robust 3D MRI reconstruction with 2D diffusion priors. As a result of this investigation, we obtain a simple resolution-robust variational 3D reconstruction approach based on diffusion-guided regularization of randomly sampled 2D slices. This method provides competitive reconstruction quality compared to posterior sampling baselines. Towards resolving the sensitivity to resolution-shifts, we investigate state-of-the-art model-based approaches including Gaussian splatting, neural representations, and infinite-dimensional diffusion models, as well as a simple data-centric approach of training the diffusion model on several resolutions. Our experiments demonstrate that the model-based approaches fail to close the performance gap in 3D MRI. In contrast, the data-centric approach of training the diffusion model on various resolutions effectively provides a resolution-robust method without compromising accuracy. </p>
<blockquote>
<p>åŸºäºæ·±åº¦å­¦ä¹ çš„3Dæˆåƒï¼Œç‰¹åˆ«æ˜¯ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ï¼Œç”±äº3Dè®­ç»ƒæ•°æ®çš„æœ‰é™å¯ç”¨æ€§è€Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œå¼€å§‹åˆ©ç”¨åœ¨2Dåˆ‡ç‰‡ä¸Šè®­ç»ƒçš„2Dæ‰©æ•£æ¨¡å‹è¿›è¡Œ3D MRIé‡å»ºã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­å±•ç¤ºï¼Œç°æœ‰æ–¹æ³•æ¶‰åŠå›ºå®šçš„ä½“ç´ å¤§å°ï¼Œå½“ä½“ç´ å¤§å°å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼Œè¿™åœ¨ä¸´åºŠå®è·µä¸­æ˜¯å¸¸è§çš„æƒ…å†µã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹å…·æœ‰2Dæ‰©æ•£å…ˆéªŒçš„åˆ†è¾¨ç‡ç¨³å¥çš„3D MRIé‡å»ºæå‡ºäº†å‡ ç§æ–¹æ³•å¹¶è¿›è¡Œäº†ç ”ç©¶ã€‚é€šè¿‡è¿™é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬è·å¾—äº†ä¸€ç§åŸºäºéšæœºé‡‡æ ·2Dåˆ‡ç‰‡çš„æ‰©æ•£å¼•å¯¼æ­£åˆ™åŒ–çš„ç®€å•åˆ†è¾¨ç‡ç¨³å¥å˜åˆ†3Dé‡å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸åé‡‡æ ·åŸºçº¿ç›¸æ¯”ï¼Œæä¾›äº†å…·æœ‰ç«äº‰åŠ›çš„é‡å»ºè´¨é‡ã€‚ä¸ºäº†è§£å†³å¯¹åˆ†è¾¨ç‡å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œæˆ‘ä»¬è°ƒæŸ¥äº†åŸºäºæ¨¡å‹çš„æœ€æ–°æ–¹æ³•ï¼ŒåŒ…æ‹¬é«˜æ–¯å–·å°„ã€ç¥ç»è¡¨ç¤ºå’Œæ— é™ç»´æ‰©æ•£æ¨¡å‹ï¼Œä»¥åŠä¸€ç§åœ¨å¤šç§åˆ†è¾¨ç‡ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç®€å•ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•æœªèƒ½ç¼©å°åœ¨3D MRIä¸­çš„æ€§èƒ½å·®è·ã€‚ç›¸åï¼Œä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„åœ¨å¤šç§åˆ†è¾¨ç‡ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•æœ‰æ•ˆåœ°æä¾›äº†ä¸€ç§åˆ†è¾¨ç‡ç¨³å¥çš„æ–¹æ³•ï¼Œè€Œä¸ä¼šç‰ºç‰²å‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18584v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸‰ç»´æˆåƒæŠ€æœ¯ï¼ˆå°¤å…¶æ˜¯ç£å…±æŒ¯æˆåƒï¼‰æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚å› ä¸‰ç»´è®­ç»ƒæ•°æ®çš„å±€é™æ€§ï¼Œå¼€å§‹åˆ©ç”¨äºŒç»´æ‰©æ•£æ¨¡å‹è¿›è¡Œä¸‰ç»´MRIé‡å»ºã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å—é™äºå›ºå®šçš„ä½“ç´ å¤§å°ï¼Œåœ¨ä¸´åºŠå®è·µä¸­ä½“ç´ å¤§å°å˜åŒ–æ—¶æ€§èƒ½ä¼šä¸‹é™ã€‚æœ¬æ–‡æå‡ºå¹¶ç ”ç©¶äº†å‡ ç§å…·æœ‰äºŒç»´æ‰©æ•£å…ˆéªŒçš„åˆ†è¾¨ç‡é²æ£’ä¸‰ç»´MRIé‡å»ºæ–¹æ³•ã€‚ç»è¿‡è°ƒæŸ¥ï¼Œå¾—å‡ºä¸€ç§åŸºäºæ‰©æ•£å¼•å¯¼æ­£åˆ™åŒ–çš„ç®€å•åˆ†è¾¨ç‡é²æ£’ä¸‰ç»´é‡å»ºæ–¹æ³•ï¼Œå¯¹éšæœºé‡‡æ ·çš„äºŒç»´åˆ‡ç‰‡è¿›è¡Œå¤„ç†ã€‚ä¸åé‡‡æ ·åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å…·æœ‰ç«äº‰åŠ›çš„é‡å»ºè´¨é‡ã€‚ä¸ºè§£å†³å¯¹åˆ†è¾¨ç‡å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œæœ¬æ–‡ç ”ç©¶äº†åŸºäºæ¨¡å‹çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬é«˜æ–¯æº…å°„ã€ç¥ç»è¡¨å¾å’Œæ— é™ç»´æ‰©æ•£æ¨¡å‹ç­‰ï¼Œä»¥åŠä¸€ç§ç®€å•çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œå³åœ¨å¤šç§åˆ†è¾¨ç‡ä¸Šè¿›è¡Œè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•åœ¨3D MRIä¸­æœªèƒ½å¼¥è¡¥æ€§èƒ½å·®è·ã€‚ç›¸åï¼Œä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•åœ¨å„ç§åˆ†è¾¨ç‡ä¸Šæä¾›æœ‰æ•ˆçš„åˆ†è¾¨ç‡é²æ£’æ–¹æ³•ï¼Œä¸”ä¸æŸå¤±å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨ä¸‰ç»´æˆåƒï¼ˆå°¤å…¶æ˜¯MRIï¼‰ä¸­çš„åº”ç”¨é¢ä¸´ç¼ºä¹è¶³å¤Ÿçš„ä¸‰ç»´è®­ç»ƒæ•°æ®çš„æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰çš„æ–¹æ³•å—é™äºå›ºå®šçš„ä½“ç´ å¤§å°ï¼Œä½¿å¾—åœ¨ä¸´åºŠå®è·µä¸­ä½“ç´ å¤§å°å˜åŒ–æ—¶æ€§èƒ½ä¸‹é™ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£å¼•å¯¼æ­£åˆ™åŒ–çš„åˆ†è¾¨ç‡é²æ£’çš„ä¸‰ç»´MRIé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¤„ç†éšæœºé‡‡æ ·çš„äºŒç»´åˆ‡ç‰‡ã€‚</li>
<li>ä¸åé‡‡æ ·åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å…·æœ‰ç«äº‰åŠ›çš„é‡å»ºè´¨é‡ã€‚</li>
<li>å°è¯•å¤šç§æ¨¡å‹æ–¹æ³•ä»¥è§£å†³åˆ†è¾¨ç‡å˜åŒ–çš„é—®é¢˜ï¼ŒåŒ…æ‹¬é«˜æ–¯æº…å°„ã€ç¥ç»è¡¨å¾å’Œæ— é™ç»´æ‰©æ•£æ¨¡å‹ç­‰ï¼Œä½†æ•ˆæœå¹¶ä¸ç†æƒ³ã€‚</li>
<li>ä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•åœ¨å„ç§åˆ†è¾¨ç‡ä¸Šè¡¨ç°æœ‰æ•ˆï¼Œæä¾›åˆ†è¾¨ç‡é²æ£’æ€§ä¸”ä¸æŸå¤±å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4ab37b91bb3c25653117a3e6afd05dc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4277b872cd8a48906ad1edb80745a469.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3947428a182ab03c5f554d225b6327e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="3DEnhancer-Consistent-Multi-View-Diffusion-for-3D-Enhancement"><a href="#3DEnhancer-Consistent-Multi-View-Diffusion-for-3D-Enhancement" class="headerlink" title="3DEnhancer: Consistent Multi-View Diffusion for 3D Enhancement"></a>3DEnhancer: Consistent Multi-View Diffusion for 3D Enhancement</h2><p><strong>Authors:Yihang Luo, Shangchen Zhou, Yushi Lan, Xingang Pan, Chen Change Loy</strong></p>
<p>Despite advances in neural rendering, due to the scarcity of high-quality 3D datasets and the inherent limitations of multi-view diffusion models, view synthesis and 3D model generation are restricted to low resolutions with suboptimal multi-view consistency. In this study, we present a novel 3D enhancement pipeline, dubbed 3DEnhancer, which employs a multi-view latent diffusion model to enhance coarse 3D inputs while preserving multi-view consistency. Our method includes a pose-aware encoder and a diffusion-based denoiser to refine low-quality multi-view images, along with data augmentation and a multi-view attention module with epipolar aggregation to maintain consistent, high-quality 3D outputs across views. Unlike existing video-based approaches, our model supports seamless multi-view enhancement with improved coherence across diverse viewing angles. Extensive evaluations show that 3DEnhancer significantly outperforms existing methods, boosting both multi-view enhancement and per-instance 3D optimization tasks. </p>
<blockquote>
<p>å°½ç®¡ç¥ç»ç½‘ç»œæ¸²æŸ“æœ‰æ‰€è¿›å±•ï¼Œä½†ç”±äºé«˜è´¨é‡3Dæ•°æ®é›†ç¨€ç¼ºä»¥åŠå¤šè§†è§’æ‰©æ•£æ¨¡å‹æœ¬èº«çš„å±€é™æ€§ï¼Œè§†å›¾åˆæˆå’Œ3Dæ¨¡å‹ç”Ÿæˆä»ç„¶å—é™äºä½åˆ†è¾¨ç‡ï¼Œå¹¶ä¸”å¤šè§†è§’ä¸€è‡´æ€§ä¸ä½³ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹3Då¢å¼ºæµç¨‹ï¼Œåä¸ºâ€œ3DEnhancerâ€ï¼Œå®ƒé‡‡ç”¨å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒå¤šè§†è§’ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¢å¼ºç²—ç³™çš„3Dè¾“å…¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸€ä¸ªå§¿æ€æ„ŸçŸ¥ç¼–ç å™¨å’Œä¸€ä¸ªåŸºäºæ‰©æ•£çš„å»å™ªå™¨ï¼Œç”¨äºç»†åŒ–ä½è´¨é‡çš„å¤šè§†è§’å›¾åƒï¼Œè¿˜åŒ…æ‹¬æ•°æ®å¢å¼ºå’Œå¸¦æœ‰æçº¿èšåˆçš„å¤šè§†è§’æ³¨æ„åŠ›æ¨¡å—ï¼Œä»¥åœ¨å¤šç§è§†è§’ä¹‹é—´ä¿æŒä¸€è‡´ã€é«˜è´¨é‡è¾“å‡ºã€‚ä¸ç°æœ‰çš„è§†é¢‘æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ”¯æŒæ— ç¼çš„å¤šè§†è§’å¢å¼ºï¼Œå¹¶ä¸”åœ¨ä¸åŒçš„è§‚çœ‹è§’åº¦ä¸Šéƒ½å…·å¤‡æ›´å¼ºçš„è¿è´¯æ€§ã€‚å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œ3DEnhanceråœ¨å¤šè§†è§’å¢å¼ºå’Œæ¯ä¸ªå®ä¾‹çš„3Dä¼˜åŒ–ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18565v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://yihangluo.com/projects/3DEnhancer">https://yihangluo.com/projects/3DEnhancer</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º3DEnhancerçš„æ–°å‹3Då¢å¼ºç®¡é“ï¼Œé‡‡ç”¨å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¯¹ç²—ç³™çš„3Dè¾“å…¥è¿›è¡Œå¢å¼ºï¼ŒåŒæ—¶ä¿æŒå¤šè§†è§’çš„ä¸€è‡´æ€§ã€‚é€šè¿‡å§¿æ€æ„ŸçŸ¥ç¼–ç å™¨ã€åŸºäºæ‰©æ•£çš„å»å™ªå™¨ã€æ•°æ®å¢å¼ºå’Œå¤šè§†è§’æ³¨æ„åŠ›æ¨¡å—ç­‰å¤šç§æŠ€æœ¯ï¼Œå®ç°äº†ä½è´¨é‡å¤šè§†è§’å›¾åƒçš„ç²¾ç»†å¤„ç†ï¼Œå¹¶ç»´æŒäº†è·¨è§†è§’çš„é«˜å“è´¨3Dè¾“å‡ºä¸€è‡´æ€§ã€‚ä¸ç°æœ‰è§†é¢‘æ–¹æ³•ä¸åŒï¼Œè¯¥æ¨¡å‹æ”¯æŒæ— ç¼å¤šè§†è§’å¢å¼ºï¼Œåœ¨ä¸åŒè§‚çœ‹è§’åº¦é—´å…·æœ‰æ›´å¥½çš„è¿è´¯æ€§ã€‚è¯„ä¼°è¡¨æ˜ï¼Œ3DEnhanceræ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶æå‡äº†å¤šè§†è§’å¢å¼ºå’Œæ¯ä¸ªå®ä¾‹çš„3Dä¼˜åŒ–ä»»åŠ¡çš„æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†æ–°å‹çš„3Då¢å¼ºç®¡é“â€”â€”3DEnhancerã€‚</li>
<li>é‡‡ç”¨å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œä½è´¨é‡3Dè¾“å…¥çš„å¢å¼ºã€‚</li>
<li>é€šè¿‡å§¿æ€æ„ŸçŸ¥ç¼–ç å™¨å’ŒåŸºäºæ‰©æ•£çš„å»å™ªå™¨å¯¹ä½è´¨é‡çš„å¤šè§†è§’å›¾åƒè¿›è¡Œç²¾ç»†å¤„ç†ã€‚</li>
<li>åˆ©ç”¨æ•°æ®å¢å¼ºå’Œå¤šè§†è§’æ³¨æ„åŠ›æ¨¡å—ç»´æŒè·¨è§†è§’çš„é«˜å“è´¨è¾“å‡ºä¸€è‡´æ€§ã€‚</li>
<li>ä¸ç°æœ‰è§†é¢‘æ–¹æ³•ä¸åŒï¼Œæ”¯æŒæ— ç¼å¤šè§†è§’å¢å¼ºï¼Œæé«˜ä¸åŒè§‚çœ‹è§’åº¦é—´çš„è¿è´¯æ€§ã€‚</li>
<li>è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œ3DEnhanceråœ¨å¤šé¡¹ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18565">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f0a83df7bf7fc59916b692efdd3d7500.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8195456775649f2779d2720d6702a36b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-887734334fd2d73c4119c506bc2c07c5.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Fashionability-Enhancing-Outfit-Image-Editing-with-Conditional-Diffusion-Models"><a href="#Fashionability-Enhancing-Outfit-Image-Editing-with-Conditional-Diffusion-Models" class="headerlink" title="Fashionability-Enhancing Outfit Image Editing with Conditional Diffusion   Models"></a>Fashionability-Enhancing Outfit Image Editing with Conditional Diffusion   Models</h2><p><strong>Authors:Qice Qin, Yuki Hirakawa, Ryotaro Shimizu, Takuya Furusawa, Edgar Simo-Serra</strong></p>
<p>Image generation in the fashion domain has predominantly focused on preserving body characteristics or following input prompts, but little attention has been paid to improving the inherent fashionability of the output images. This paper presents a novel diffusion model-based approach that generates fashion images with improved fashionability while maintaining control over key attributes. Key components of our method include: 1) fashionability enhancement, which ensures that the generated images are more fashionable than the input; 2) preservation of body characteristics, encouraging the generated images to maintain the original shape and proportions of the input; and 3) automatic fashion optimization, which does not rely on manual input or external prompts. We also employ two methods to collect training data for guidance while generating and evaluating the images. In particular, we rate outfit images using fashionability scores annotated by multiple fashion experts through OpenSkill-based and five critical aspect-based pairwise comparisons. These methods provide complementary perspectives for assessing and improving the fashionability of the generated images. The experimental results show that our approach outperforms the baseline Fashion++ in generating images with superior fashionability, demonstrating its effectiveness in producing more stylish and appealing fashion images. </p>
<blockquote>
<p>æ—¶å°šé¢†åŸŸçš„å›¾åƒç”Ÿæˆä¸»è¦èšç„¦äºä¿ç•™äººä½“ç‰¹å¾æˆ–éµå¾ªè¾“å…¥æç¤ºï¼Œä½†å¯¹æé«˜è¾“å‡ºå›¾åƒçš„å†…åœ¨æ—¶å°šæ€§å…³æ³¨è¾ƒå°‘ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œåœ¨ä¿æŒå…³é”®å±æ€§æ§åˆ¶çš„åŒæ—¶ï¼Œç”Ÿæˆå…·æœ‰æ”¹è¿›æ—¶å°šæ€§çš„æ—¶å°šå›¾åƒã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š1ï¼‰æ—¶å°šæ€§å¢å¼ºï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾åƒæ¯”è¾“å…¥å›¾åƒæ›´æ—¶å°šï¼›2ï¼‰ä¿ç•™äººä½“ç‰¹å¾ï¼Œé¼“åŠ±ç”Ÿæˆçš„å›¾åƒä¿æŒè¾“å…¥çš„åŸå§‹å½¢çŠ¶å’Œæ¯”ä¾‹ï¼›3ï¼‰è‡ªåŠ¨æ—¶å°šä¼˜åŒ–ï¼Œä¸ä¾èµ–æ‰‹åŠ¨è¾“å…¥æˆ–å¤–éƒ¨æç¤ºã€‚æˆ‘ä»¬è¿˜é‡‡ç”¨ä¸¤ç§æ–¹æ³•æ”¶é›†è®­ç»ƒæ•°æ®ï¼Œç”¨äºåœ¨ç”Ÿæˆå’Œè¯„ä¼°å›¾åƒæ—¶è¿›è¡ŒæŒ‡å¯¼ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡åŸºäºOpenSkillå’Œäº”ä¸ªå…³é”®æ–¹é¢çš„æˆå¯¹æ¯”è¾ƒï¼Œç”±å¤šåæ—¶å°šä¸“å®¶å¯¹æœè£…å›¾åƒè¿›è¡Œæ—¶å°šåº¦è¯„åˆ†æ³¨é‡Šã€‚è¿™äº›æ–¹æ³•ä¸ºè¯„ä¼°å’Œæé«˜ç”Ÿæˆå›¾åƒçš„æ—¶å°šæ€§æä¾›äº†äº’è¡¥çš„è§†è§’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¼˜è¶Šæ—¶å°šæ€§çš„å›¾åƒæ–¹é¢ä¼˜äºåŸºçº¿Fashion++ï¼Œè¯æ˜å…¶åœ¨ç”Ÿæˆæ›´æ—¶å°šå’Œå¸å¼•äººçš„æ—¶å°šå›¾åƒæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18421v1">PDF</a> 11 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆæ—¶å°šå›¾åƒã€‚è¯¥æ–¹æ³•å¯æ”¹å–„ç”Ÿæˆå›¾åƒçš„æ—¶å°šæ€§ï¼ŒåŒæ—¶ä¿æŒå¯¹å…³é”®å±æ€§çš„æ§åˆ¶ã€‚è¯¥ç ”ç©¶é‡‡ç”¨å¤šç§æ–¹æ³•æ”¶é›†è®­ç»ƒæ•°æ®ï¼Œå¹¶åˆ©ç”¨æ—¶å°šä¸“å®¶æ ‡æ³¨çš„æ—¶å°šè¯„åˆ†æ¥è¯„ä¼°å’Œæ”¹è¿›ç”Ÿæˆå›¾åƒçš„æ—¶å°šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰æ›´é«˜æ—¶å°šæ€§çš„å›¾åƒæ–¹é¢ä¼˜äºåŸºçº¿Fashion++ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¶å°šé¢†åŸŸçš„å›¾åƒç”Ÿæˆä¸»è¦å…³æ³¨ä¿ç•™èº«ä½“ç‰¹å¾æˆ–éµå¾ªè¾“å…¥æç¤ºï¼Œä½†å¾ˆå°‘æœ‰äººå…³æ³¨æé«˜è¾“å‡ºå›¾åƒçš„å†…åœ¨æ—¶å°šæ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ”¹è¿›æ—¶å°šæ€§çš„æ—¶å°šå›¾åƒï¼ŒåŒæ—¶ä¿æŒå¯¹å…³é”®å±æ€§çš„æ§åˆ¶ã€‚</li>
<li>æ–¹æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼šæé«˜æ—¶å°šæ€§ã€ä¿ç•™èº«ä½“ç‰¹å¾ä»¥åŠè‡ªåŠ¨æ—¶å°šä¼˜åŒ–ã€‚</li>
<li>é‡‡ç”¨ä¸¤ç§æ–¹æ³•æ¥æ”¶é›†è®­ç»ƒæ•°æ®ï¼Œç”¨äºåœ¨ç”Ÿæˆå’Œè¯„ä¼°å›¾åƒæ—¶æä¾›æŒ‡å¯¼ã€‚</li>
<li>é€šè¿‡åŸºäºæ—¶å°šçš„è¯„åˆ†å’Œäº”ä¸ªå…³é”®æ–¹é¢çš„æˆå¯¹æ¯”è¾ƒï¼Œç”±å¤šä½æ—¶å°šä¸“å®¶å¯¹æœè£…å›¾åƒè¿›è¡Œè¯„ä¼°ã€‚</li>
<li>è¿™äº›æ–¹æ³•æä¾›äº†è¯„ä¼°å’Œæ”¹è¿›ç”Ÿæˆå›¾åƒæ—¶å°šæ€§çš„äº’è¡¥è§†è§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18421">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-322d04d054ae05a912e6574227b6116b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3368c2bdc1a1b7b9e7efb2546ef2b46.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-410ef73b77e04c6991bdb5fcb6d53f38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95f8aa51dbcce4b118c6d338a7ea18e4.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Expand-VSR-Benchmark-for-VLLM-to-Expertize-in-Spatial-Rules"><a href="#Expand-VSR-Benchmark-for-VLLM-to-Expertize-in-Spatial-Rules" class="headerlink" title="Expand VSR Benchmark for VLLM to Expertize in Spatial Rules"></a>Expand VSR Benchmark for VLLM to Expertize in Spatial Rules</h2><p><strong>Authors:Peijin Xie, Lin Sun, Bingquan Liu, Dexin Wang, Xiangzheng Zhang, Chengjie Sun, Jiajia Zhang</strong></p>
<p>Distinguishing spatial relations is a basic part of human cognition which requires fine-grained perception on cross-instance. Although benchmarks like MME, MMBench and SEED comprehensively have evaluated various capabilities which already include visual spatial reasoning(VSR). There is still a lack of sufficient quantity and quality evaluation and optimization datasets for Vision Large Language Models(VLLMs) specifically targeting visual positional reasoning. To handle this, we first diagnosed current VLLMs with the VSR dataset and proposed a unified test set. We found current VLLMs to exhibit a contradiction of over-sensitivity to language instructions and under-sensitivity to visual positional information. By expanding the original benchmark from two aspects of tunning data and model structure, we mitigated this phenomenon. To our knowledge, we expanded spatially positioned image data controllably using diffusion models for the first time and integrated original visual encoding(CLIP) with other 3 powerful visual encoders(SigLIP, SAM and DINO). After conducting combination experiments on scaling data and models, we obtained a VLLM VSR Expert(VSRE) that not only generalizes better to different instructions but also accurately distinguishes differences in visual positional information. VSRE achieved over a 27% increase in accuracy on the VSR test set. It becomes a performant VLLM on the position reasoning of both the VSR dataset and relevant subsets of other evaluation benchmarks. We open-sourced the expanded model with data and Appendix at \url{<a target="_blank" rel="noopener" href="https://github.com/peijin360/vsre%7D">https://github.com/peijin360/vsre}</a> and hope it will accelerate advancements in VLLM on VSR learning. </p>
<blockquote>
<p>åŒºåˆ†ç©ºé—´å…³ç³»æ˜¯äººç±»è®¤çŸ¥çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œè¿™éœ€è¦è·¨å®ä¾‹çš„ç²¾ç»†æ„ŸçŸ¥ã€‚è™½ç„¶MMEã€MMBenchå’ŒSEEDç­‰åŸºå‡†æµ‹è¯•å·²ç»å…¨é¢è¯„ä¼°äº†å„ç§èƒ½åŠ›ï¼Œå…¶ä¸­åŒ…æ‹¬è§†è§‰ç©ºé—´æ¨ç†ï¼ˆVSRï¼‰ã€‚ç„¶è€Œï¼Œé’ˆå¯¹è§†è§‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰ä¸“é—¨ç”¨äºè§†è§‰ä½ç½®æ¨ç†çš„å……è¶³æ•°é‡å’Œè´¨é‡è¯„ä»·å’Œä¼˜åŒ–çš„æ•°æ®é›†ä»ç„¶ç¼ºä¹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨VSRæ•°æ®é›†å¯¹å½“å‰çš„VLLMsè¿›è¡Œäº†è¯Šæ–­ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æµ‹è¯•é›†ã€‚æˆ‘ä»¬å‘ç°å½“å‰çš„VLLMsè¡¨ç°å‡ºå¯¹è¯­è¨€æŒ‡ä»¤è¿‡äºæ•æ„Ÿå’Œå¯¹è§†è§‰ä½ç½®ä¿¡æ¯ä¸å¤Ÿæ•æ„Ÿçš„çŸ›ç›¾ã€‚æˆ‘ä»¬é€šè¿‡ä»è°ƒæ•´æ•°æ®å’Œæ¨¡å‹ç»“æ„ä¸¤ä¸ªæ–¹é¢æ‰©å±•åŸºå‡†æµ‹è¯•ï¼Œç¼“è§£äº†è¿™ä¸€ç°è±¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬é¦–æ¬¡ä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯æ§åœ°æ‰©å±•äº†ç©ºé—´å®šä½å›¾åƒæ•°æ®ï¼Œå¹¶å°†åŸå§‹çš„è§†è§‰ç¼–ç ï¼ˆCLIPï¼‰ä¸å…¶ä»–ä¸‰ç§å¼ºå¤§çš„è§†è§‰ç¼–ç å™¨ï¼ˆSigLIPã€SAMå’ŒDINOï¼‰è¿›è¡Œäº†é›†æˆã€‚åœ¨æ‰©å¤§æ•°æ®å’Œæ¨¡å‹è§„æ¨¡çš„ç»„åˆå®éªŒåï¼Œæˆ‘ä»¬è·å¾—äº†ä¸€ä¸ªVLLM VSRä¸“å®¶ï¼ˆVSREï¼‰ï¼Œå®ƒä¸ä»…èƒ½æ›´å¥½åœ°é€‚åº”ä¸åŒçš„æŒ‡ä»¤ï¼Œè¿˜èƒ½å‡†ç¡®åŒºåˆ†è§†è§‰ä½ç½®ä¿¡æ¯çš„å·®å¼‚ã€‚VSREåœ¨VSRæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡æé«˜äº†27%ä»¥ä¸Šã€‚å®ƒæˆä¸ºåœ¨VSRæ•°æ®é›†å’Œå…¶ä»–ç›¸å…³å­é›†çš„å®šä½æ¨ç†æ–¹é¢çš„æ€§èƒ½è‰¯å¥½çš„VLLMã€‚æˆ‘ä»¬å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/peijin360/vsre%E5%BC%80%E6%BA%90%E6%89%A9%E5%B1%95%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%99%84%E5%BD%95%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%B8%8C%E6%9C%9B%E5%AE%83%E8%83%BD%E5%8A%A0%E9%80%9FVLLM%E5%9C%A8VSR%E5%AD%A6%E4%B9%A0%E6%96%B9%E9%9D%A2%E7%9A%84%E8%BF%9B%E5%B1%95%E3%80%82">https://github.com/peijin360/vsreå¼€æºæ‰©å±•çš„æ¨¡å‹å’Œé™„å½•æ•°æ®ï¼Œå¸Œæœ›å®ƒèƒ½åŠ é€ŸVLLMåœ¨VSRå­¦ä¹ æ–¹é¢çš„è¿›å±•ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18224v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯¥æ–‡ç ”ç©¶äº†äººç±»è®¤çŸ¥ä¸­çš„ç©ºé—´å…³ç³»åŒºåˆ†èƒ½åŠ›ï¼Œå¹¶æŒ‡å‡ºå½“å‰é’ˆå¯¹è§†è§‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰åœ¨è§†è§‰ä½ç½®æ¨ç†æ–¹é¢çš„æ•°æ®é›†ç¼ºä¹è¶³å¤Ÿçš„æ•°é‡å’Œè´¨é‡ã€‚æ–‡ç« é€šè¿‡è¯Šæ–­å½“å‰VLLMsä¸VSRæ•°æ®é›†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æµ‹è¯•é›†ï¼Œå¹¶å‘ç°å½“å‰æ¨¡å‹å¯¹è¯­è¨€æŒ‡ä»¤è¿‡äºæ•æ„Ÿè€Œå¯¹è§†è§‰ä½ç½®ä¿¡æ¯ä¸å¤Ÿæ•æ„Ÿçš„é—®é¢˜ã€‚é€šè¿‡ä»æ•°æ®å’Œæ¨¡å‹ç»“æ„ä¸¤æ–¹é¢è¿›è¡Œæ‰©å±•ï¼Œç¼“è§£äº†è¿™ä¸€é—®é¢˜ã€‚æ­¤å¤–ï¼Œæ–‡ç« é¦–æ¬¡ä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯æ§åœ°æ‰©å±•äº†ç©ºé—´å®šä½å›¾åƒæ•°æ®ï¼Œå¹¶å°†åŸå§‹è§†è§‰ç¼–ç CLIPä¸å…¶ä»–ä¸‰ç§å¼ºå¤§çš„è§†è§‰ç¼–ç å™¨SigLIPã€SAMå’ŒDINOç›¸ç»“åˆã€‚é€šè¿‡æ•°æ®å’Œæ¨¡å‹çš„è§„æ¨¡æ‰©å±•ç»„åˆå®éªŒï¼Œè·å¾—äº†VLLM VSR Expertï¼ˆVSREï¼‰ï¼Œè¯¥æ¨¡å‹ä¸ä»…å¯¹ä¸åŒæŒ‡ä»¤çš„æ³›åŒ–èƒ½åŠ›æ›´å¼ºï¼Œè€Œä¸”èƒ½å‡†ç¡®åŒºåˆ†è§†è§‰ä½ç½®ä¿¡æ¯çš„å·®å¼‚ã€‚VSREåœ¨VSRæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡æé«˜äº†è¶…è¿‡27%ï¼Œæˆä¸ºåœ¨VSRæ•°æ®é›†å’Œå…¶ä»–ç›¸å…³å­é›†çš„ä½ç½®æ¨ç†æ–¹é¢çš„ä¼˜ç§€VLLMã€‚ç ”ç©¶å›¢é˜Ÿå·²å…¬å¼€æ‰©å±•çš„æ¨¡å‹å’Œé™„å½•æ•°æ®ï¼Œä»¥åŠ é€ŸVLLMåœ¨VSRå­¦ä¹ æ–¹é¢çš„è¿›å±•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å½“å‰é’ˆå¯¹è§†è§‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰åœ¨è§†è§‰ä½ç½®æ¨ç†æ–¹é¢çš„æ•°æ®é›†ç¼ºä¹è¶³å¤Ÿçš„æ•°é‡å’Œè´¨é‡è¯„ä»·å’Œä¼˜åŒ–ã€‚</li>
<li>å¯¹å½“å‰VLLMsè¿›è¡Œè¯Šæ–­ï¼Œå‘ç°å®ƒä»¬å¯¹è¯­è¨€æŒ‡ä»¤è¿‡äºæ•æ„Ÿï¼Œå¯¹è§†è§‰ä½ç½®ä¿¡æ¯ä¸å¤Ÿæ•æ„Ÿã€‚</li>
<li>é€šè¿‡æ‰©å±•æ•°æ®å’Œæ¨¡å‹ç»“æ„ï¼Œæå‡ºäº†ä¸€ç§ç¼“è§£ä¸Šè¿°ç°è±¡çš„æ–¹æ³•ã€‚</li>
<li>é¦–æ¬¡ä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯æ§åœ°æ‰©å±•ç©ºé—´å®šä½å›¾åƒæ•°æ®ï¼Œå¹¶å°†CLIPä¸å…¶ä»–ä¸‰ç§è§†è§‰ç¼–ç å™¨ç»“åˆã€‚</li>
<li>é€šè¿‡ç»„åˆå®éªŒï¼Œè·å¾—äº†åä¸ºVSREçš„VLLM VSR Expertï¼Œè¯¥æ¨¡å‹åœ¨VSRæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚</li>
<li>VSREæ¨¡å‹å·²åœ¨ä¸åŒæŒ‡ä»¤ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶èƒ½å‡†ç¡®åŒºåˆ†è§†è§‰ä½ç½®ä¿¡æ¯çš„å·®å¼‚ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿå·²å…¬å¼€æ¨¡å‹å’Œé™„å½•æ•°æ®ï¼Œä»¥åŠ é€ŸVLLMåœ¨VSRå­¦ä¹ æ–¹é¢çš„è¿›å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18224">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-757e45d22fad6bd5f6fd81e80d8f7ad7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5801014f6d501ca685538bf1d78406ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e79c67494a9a98161c00b97dbee34503.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3068dc504705f14123a918249b80a559.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4d3300295e228f4a87990454572932db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-535ccb900dbf7efa279a64a90db2a57e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Dense-Face-Personalized-Face-Generation-Model-via-Dense-Annotation-Prediction"><a href="#Dense-Face-Personalized-Face-Generation-Model-via-Dense-Annotation-Prediction" class="headerlink" title="Dense-Face: Personalized Face Generation Model via Dense Annotation   Prediction"></a>Dense-Face: Personalized Face Generation Model via Dense Annotation   Prediction</h2><p><strong>Authors:Xiao Guo, Manh Tran, Jiaxin Cheng, Xiaoming Liu</strong></p>
<p>The text-to-image (T2I) personalization diffusion model can generate images of the novel concept based on the user input text caption. However, existing T2I personalized methods either require test-time fine-tuning or fail to generate images that align well with the given text caption. In this work, we propose a new T2I personalization diffusion model, Dense-Face, which can generate face images with a consistent identity as the given reference subject and align well with the text caption. Specifically, we introduce a pose-controllable adapter for the high-fidelity image generation while maintaining the text-based editing ability of the pre-trained stable diffusion (SD). Additionally, we use internal features of the SD UNet to predict dense face annotations, enabling the proposed method to gain domain knowledge in face generation. Empirically, our method achieves state-of-the-art or competitive generation performance in image-text alignment, identity preservation, and pose control. </p>
<blockquote>
<p>æ–‡æœ¬è½¬å›¾åƒï¼ˆT2Iï¼‰ä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹å¯ä»¥æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æè¿°ç”Ÿæˆæ–°å‹æ¦‚å¿µçš„å›¾åƒã€‚ç„¶è€Œï¼Œç°æœ‰çš„T2Iä¸ªæ€§åŒ–æ–¹æ³•è¦ä¹ˆéœ€è¦æµ‹è¯•æ—¶çš„å¾®è°ƒï¼Œè¦ä¹ˆæ— æ³•ç”Ÿæˆä¸ç»™å®šæ–‡æœ¬æè¿°ç›¸ç¬¦çš„å›¾åƒã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„T2Iä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹â€”â€”Dense-Faceï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸ç»™å®šå‚è€ƒä¸»ä½“èº«ä»½ä¸€è‡´çš„é¢éƒ¨å›¾åƒï¼Œå¹¶ä¸æ–‡æœ¬æè¿°è‰¯å¥½å¯¹é½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨ä¿æŒé¢„è®­ç»ƒç¨³å®šæ‰©æ•£ï¼ˆSDï¼‰çš„æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›çš„åŒæ—¶ï¼Œå¼•å…¥äº†ä¸€ä¸ªå§¿æ€å¯æ§çš„é€‚é…å™¨ï¼Œç”¨äºé«˜ä¿çœŸå›¾åƒç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨SD UNetçš„å†…éƒ¨ç‰¹å¾æ¥é¢„æµ‹å¯†é›†é¢éƒ¨æ³¨é‡Šï¼Œä½¿æ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿè·å–é¢éƒ¨ç”Ÿæˆçš„é¢†åŸŸçŸ¥è¯†ã€‚ä»ç»éªŒä¸Šçœ‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒæ–‡æœ¬å¯¹é½ã€èº«ä»½ä¿ç•™å’Œå§¿æ€æ§åˆ¶æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆ–å…·æœ‰ç«äº‰åŠ›çš„ç”Ÿæˆæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.18149v1">PDF</a> 15 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹æ–‡æœ¬è½¬å›¾åƒä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹â€”â€”Dense-Faceã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æè¿°ç”Ÿæˆæ–°é¢–æ¦‚å¿µçš„å›¾åƒï¼Œå¹¶ä¸”èƒ½ç”Ÿæˆä¸ç»™å®šå‚è€ƒä¸»ä½“èº«ä»½ä¸€è‡´çš„äººè„¸å›¾åƒï¼ŒåŒæ—¶ä¸æ–‡æœ¬æè¿°é«˜åº¦å¯¹é½ã€‚æ¨¡å‹å¼•å…¥äº†å§¿æ€å¯æ§é€‚é…å™¨ï¼Œä»¥åœ¨ä¿æŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°é«˜ä¿çœŸå›¾åƒç”Ÿæˆã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨é¢„è®­ç»ƒç¨³å®šæ‰©æ•£çš„å†…éƒ¨ç‰¹å¾æ¥é¢„æµ‹å¯†é›†äººè„¸æ³¨é‡Šï¼Œä½¿è¯¥æ–¹æ³•è·å¾—äººè„¸ç”Ÿæˆé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒæ–‡æœ¬å¯¹é½ã€èº«ä»½ä¿ç•™å’Œå§¿æ€æ§åˆ¶æ–¹é¢è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³æˆ–å…·æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Dense-Faceæ¨¡å‹èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æè¿°ç”Ÿæˆæ–°é¢–æ¦‚å¿µçš„å›¾åƒã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸ç»™å®šå‚è€ƒä¸»ä½“èº«ä»½ä¸€è‡´çš„äººè„¸å›¾åƒã€‚</li>
<li>Dense-Faceæ¨¡å‹å¼•å…¥äº†å§¿æ€å¯æ§é€‚é…å™¨ä»¥å®ç°é«˜ä¿çœŸå›¾åƒç”Ÿæˆã€‚</li>
<li>æ¨¡å‹ç»“åˆäº†é¢„è®­ç»ƒç¨³å®šæ‰©æ•£çš„å†…éƒ¨ç‰¹å¾è¿›è¡Œå¯†é›†äººè„¸æ³¨é‡Šé¢„æµ‹ã€‚</li>
<li>Dense-Faceæ¨¡å‹åœ¨å›¾åƒæ–‡æœ¬å¯¹é½æ–¹é¢è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³æˆ–å…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨èº«ä»½ä¿ç•™å’Œå§¿æ€æ§åˆ¶æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.18149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-45d73ef7bd4a55034e21586e69cc6368.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-151c9344f59c7460eeecd09816897c86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebc316c36204be8b4735e512921a66e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fcd302267d86d19a36bc5ae8bb0bec2.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Label-Efficient-Data-Augmentation-with-Video-Diffusion-Models-for-Guidewire-Segmentation-in-Cardiac-Fluoroscopy"><a href="#Label-Efficient-Data-Augmentation-with-Video-Diffusion-Models-for-Guidewire-Segmentation-in-Cardiac-Fluoroscopy" class="headerlink" title="Label-Efficient Data Augmentation with Video Diffusion Models for   Guidewire Segmentation in Cardiac Fluoroscopy"></a>Label-Efficient Data Augmentation with Video Diffusion Models for   Guidewire Segmentation in Cardiac Fluoroscopy</h2><p><strong>Authors:Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun</strong></p>
<p>The accurate segmentation of guidewires in interventional cardiac fluoroscopy videos is crucial for computer-aided navigation tasks. Although deep learning methods have demonstrated high accuracy and robustness in wire segmentation, they require substantial annotated datasets for generalizability, underscoring the need for extensive labeled data to enhance model performance. To address this challenge, we propose the Segmentation-guided Frame-consistency Video Diffusion Model (SF-VD) to generate large collections of labeled fluoroscopy videos, augmenting the training data for wire segmentation networks. SF-VD leverages videos with limited annotations by independently modeling scene distribution and motion distribution. It first samples the scene distribution by generating 2D fluoroscopy images with wires positioned according to a specified input mask, and then samples the motion distribution by progressively generating subsequent frames, ensuring frame-to-frame coherence through a frame-consistency strategy. A segmentation-guided mechanism further refines the process by adjusting wire contrast, ensuring a diverse range of visibility in the synthesized image. Evaluation on a fluoroscopy dataset confirms the superior quality of the generated videos and shows significant improvements in guidewire segmentation. </p>
<blockquote>
<p>åœ¨å¿ƒè„ä»‹å…¥æ‰‹æœ¯çš„è§è§†è§†é¢‘ä¸­å¯¹å¯¼çº¿çš„ç²¾ç¡®åˆ†å‰²å¯¹äºè®¡ç®—æœºè¾…åŠ©å¯¼èˆªä»»åŠ¡è‡³å…³é‡è¦ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ çš„æ–¹æ³•å·²ç»åœ¨å¯¼çº¿åˆ†å‰²ä¸­æ˜¾ç¤ºå‡ºè¾ƒé«˜çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼Œä½†å®ƒä»¬éœ€è¦å¤§è§„æ¨¡çš„æ ‡æ³¨æ•°æ®é›†æ¥å®ç°æ³›åŒ–ï¼Œè¿™çªæ˜¾äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„éœ€è¦ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å‰²å¼•å¯¼çš„å¸§ä¸€è‡´æ€§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆSF-VDï¼‰ï¼Œç”¨äºç”Ÿæˆå¤§é‡æ ‡æ³¨çš„è§è§†è§†é¢‘ï¼Œå¢å¼ºå¯¼çº¿åˆ†å‰²ç½‘ç»œçš„è®­ç»ƒæ•°æ®ã€‚SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒæ¥åˆ©ç”¨æ ‡æ³¨ä¸è¶³çš„è§†é¢‘ã€‚å®ƒé¦–å…ˆé€šè¿‡æ ¹æ®æŒ‡å®šçš„è¾“å…¥æ©è†œç”Ÿæˆå¸¦æœ‰å¯¼çº¿çš„äºŒç»´è§è§†å›¾åƒæ¥é‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œç„¶åé€šè¿‡é€æ­¥ç”Ÿæˆåç»­å¸§æ¥é‡‡æ ·è¿åŠ¨åˆ†å¸ƒï¼Œå¹¶é€šè¿‡å¸§ä¸€è‡´æ€§ç­–ç•¥ç¡®ä¿å¸§ä¸å¸§ä¹‹é—´çš„è¿è´¯æ€§ã€‚åˆ†å‰²å¼•å¯¼æœºåˆ¶è¿›ä¸€æ­¥è°ƒæ•´äº†å¯¼çº¿çš„å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§èŒƒå›´å¤šæ ·åŒ–ã€‚åœ¨è§è§†æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯å®äº†æ‰€ç”Ÿæˆè§†é¢‘çš„é«˜è´¨é‡ï¼Œå¹¶æ˜¾ç¤ºå‡ºåœ¨å¯¼çº¿åˆ†å‰²æ–¹é¢çš„æ˜¾è‘—æ”¹å–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16050v2">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¿ƒè„ä»‹å…¥æ‰‹æœ¯è§å…‰é€è§†è§†é¢‘ä¸­å‡†ç¡®åˆ†å‰²å¯¼ä¸å¯¹äºè®¡ç®—æœºè¾…åŠ©å¯¼èˆªä»»åŠ¡è‡³å…³é‡è¦ã€‚ä¸ºè§£å†³æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¯¼ä¸åˆ†å‰²ä¸­å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å‰²å¼•å¯¼çš„å¸§ä¸€è‡´æ€§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆSF-VDï¼‰ã€‚è¯¥æ¨¡å‹èƒ½ç”Ÿæˆå¤§é‡æ ‡æ³¨çš„è§å…‰é€è§†è§†é¢‘ï¼Œå¢å¼ºå¯¼ä¸åˆ†å‰²ç½‘ç»œçš„è®­ç»ƒæ•°æ®ã€‚SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒï¼Œåˆ©ç”¨æœ‰é™æ ‡æ³¨çš„è§†é¢‘æ ·æœ¬è¿›è¡Œè®­ç»ƒã€‚å®ƒé¦–å…ˆæ ¹æ®æŒ‡å®šçš„è¾“å…¥æ©è†œç”ŸæˆäºŒç»´è§å…‰é€è§†å›¾åƒæ¥é‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œç„¶åé€šè¿‡é€æ­¥ç”Ÿæˆåç»­å¸§æ¥é‡‡æ ·è¿åŠ¨åˆ†å¸ƒï¼Œç¡®ä¿å¸§é—´ä¸€è‡´æ€§ã€‚åˆ†å‰²å¼•å¯¼æœºåˆ¶è¿›ä¸€æ­¥è°ƒæ•´å¯¼ä¸å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§å¤šæ ·æ€§ã€‚åœ¨è§å…‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜ï¼Œç”Ÿæˆè§†é¢‘çš„è´¨é‡ä¸Šä¹˜ï¼Œå¯¼ä¸åˆ†å‰²çš„æ”¹è¿›æ˜¾è‘—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¼ä¸åœ¨å¿ƒè„ä»‹å…¥æ‰‹æœ¯è§å…‰é€è§†è§†é¢‘ä¸­çš„å‡†ç¡®åˆ†å‰²å¯¹è®¡ç®—æœºè¾…åŠ©å¯¼èˆªè‡³å…³é‡è¦ã€‚</li>
<li>æ·±åº¦å­¦ä¹ åœ¨å¯¼ä¸åˆ†å‰²ä¸­è™½è¡¨ç°å‡ºé«˜å‡†ç¡®æ€§ä¸ç¨³å¥æ€§ï¼Œä½†éœ€å¤§é‡æ ‡æ³¨æ•°æ®æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æå‡ºSF-VDæ¨¡å‹ä»¥ç”Ÿæˆå¤§é‡æ ‡æ³¨çš„è§å…‰é€è§†è§†é¢‘ï¼Œå¢å¼ºå¯¼ä¸åˆ†å‰²ç½‘ç»œçš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒæ¥å¤„ç†æœ‰é™æ ‡æ³¨è§†é¢‘æ ·æœ¬ã€‚</li>
<li>æ¨¡å‹é€šè¿‡ç”ŸæˆäºŒç»´è§å…‰é€è§†å›¾åƒé‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œå¹¶é€æ­¥ç”Ÿæˆåç»­å¸§æ¥é‡‡æ ·è¿åŠ¨åˆ†å¸ƒã€‚</li>
<li>åˆ†å‰²å¼•å¯¼æœºåˆ¶è°ƒæ•´å¯¼ä¸å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§å¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16050">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9b893f5d2e52178f2901ce6712e4992d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9a2f0b88c0190b7511a9244cdd8f011.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6dfead2b062aa6a8f15edfc59eb3429.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d47112dbe22818737ff4b9362916e1d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Adversarial-Score-identity-Distillation-Rapidly-Surpassing-the-Teacher-in-One-Step"><a href="#Adversarial-Score-identity-Distillation-Rapidly-Surpassing-the-Teacher-in-One-Step" class="headerlink" title="Adversarial Score identity Distillation: Rapidly Surpassing the Teacher   in One Step"></a>Adversarial Score identity Distillation: Rapidly Surpassing the Teacher   in One Step</h2><p><strong>Authors:Mingyuan Zhou, Huangjie Zheng, Yi Gu, Zhendong Wang, Hai Huang</strong></p>
<p>Score identity Distillation (SiD) is a data-free method that has achieved SOTA performance in image generation by leveraging only a pretrained diffusion model, without requiring any training data. However, its ultimate performance is constrained by how accurate the pretrained model captures the true data scores at different stages of the diffusion process. In this paper, we introduce SiDA (SiD with Adversarial Loss), which not only enhances generation quality but also improves distillation efficiency by incorporating real images and adversarial loss. SiDA utilizes the encoder from the generatorâ€™s score network as a discriminator, allowing it to distinguish between real images and those generated by SiD. The adversarial loss is batch-normalized within each GPU and then combined with the original SiD loss. This integration effectively incorporates the average â€œfakenessâ€ per GPU batch into the pixel-based SiD loss, enabling SiDA to distill a single-step generator. SiDA converges significantly faster than its predecessor when distilled from scratch, and swiftly improves upon the original modelâ€™s performance during fine-tuning from a pre-distilled SiD generator. This one-step adversarial distillation method establishes new benchmarks in generation performance when distilling EDM diffusion models, achieving FID scores of 1.110 on ImageNet 64x64. When distilling EDM2 models trained on ImageNet 512x512, our SiDA method surpasses even the largest teacher model, EDM2-XXL, which achieved an FID of 1.81 using classifier-free guidance (CFG) and 63 generation steps. In contrast, SiDA achieves FID scores of 2.156 for size XS, 1.669 for S, 1.488 for M, 1.413 for L, 1.379 for XL, and 1.366 for XXL, all without CFG and in a single generation step. These results highlight substantial improvements across all model sizes. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/mingyuanzhou/SiD/tree/sida">https://github.com/mingyuanzhou/SiD/tree/sida</a>. </p>
<blockquote>
<p>Score identity Distillationï¼ˆSiDï¼‰æ˜¯ä¸€ç§æ— éœ€æ•°æ®çš„æ–¹æ³•ï¼Œä»…åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œåœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¾¾åˆ°äº† state-of-the-artï¼ˆSOTAï¼‰çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…¶æœ€ç»ˆæ€§èƒ½å—é™äºé¢„è®­ç»ƒæ¨¡å‹åœ¨æ‰©æ•£è¿‡ç¨‹çš„ä¸åŒé˜¶æ®µæ•æ‰çœŸå®æ•°æ®å‡†ç¡®åº¦çš„ç¨‹åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¸¦æœ‰å¯¹æŠ—æ€§æŸå¤±ï¼ˆAdversarial Lossï¼‰çš„SiDï¼ˆSiDAï¼‰ã€‚SiDAä¸ä»…æé«˜äº†ç”Ÿæˆè´¨é‡ï¼Œè€Œä¸”é€šè¿‡ç»“åˆçœŸå®å›¾åƒå’Œå¯¹æŠ—æ€§æŸå¤±æé«˜äº†è’¸é¦æ•ˆç‡ã€‚SiDAä½¿ç”¨ç”Ÿæˆå™¨è¯„åˆ†ç½‘ç»œä¸­çš„ç¼–ç å™¨ä½œä¸ºé‰´åˆ«å™¨ï¼Œèƒ½å¤ŸåŒºåˆ†çœŸå®å›¾åƒå’ŒSiDç”Ÿæˆçš„å›¾åƒã€‚å¯¹æŠ—æ€§æŸå¤±åœ¨æ¯ä¸ªGPUå†…è¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–ï¼Œç„¶åä¸åŸå§‹SiDæŸå¤±ç›¸ç»“åˆã€‚è¿™ç§ç»“åˆæœ‰æ•ˆåœ°å°†æ¯ä¸ªGPUæ‰¹æ¬¡çš„å¹³å‡â€œè™šå‡æ€§â€çº³å…¥åŸºäºåƒç´ çš„SiDæŸå¤±ï¼Œä½¿SiDAèƒ½å¤Ÿè’¸é¦å•æ­¥ç”Ÿæˆå™¨ã€‚å½“ä»é›¶å¼€å§‹è’¸é¦æ—¶ï¼ŒSiDAæ¯”å…¶å‰èº«æ”¶æ•›å¾—æ›´å¿«ï¼Œå¹¶ä¸”åœ¨é¢„è’¸é¦çš„SiDç”Ÿæˆå™¨ä¸Šè¿›è¡Œå¾®è°ƒæ—¶ï¼Œèƒ½è¿…é€Ÿæé«˜åŸå§‹æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™ç§ä¸€æ­¥å¯¹æŠ—æ€§è’¸é¦æ–¹æ³•åœ¨ä¸ºEDMæ‰©æ•£æ¨¡å‹è¿›è¡Œè’¸é¦æ—¶ï¼Œåœ¨ImageNet 64x64ä¸Šå®ç°äº†FIDåˆ†æ•°ä¸º1.110çš„æ–°åŸºå‡†ã€‚å½“å¯¹ImageNet 512x512è®­ç»ƒçš„EDM2æ¨¡å‹è¿›è¡Œè’¸é¦æ—¶ï¼Œæˆ‘ä»¬çš„SiDAæ–¹æ³•ç”šè‡³è¶…è¶Šäº†æœ€å¤§çš„æ•™å¸ˆæ¨¡å‹EDM2-XXLï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰å’Œ63ä¸ªç”Ÿæˆæ­¥éª¤å®ç°äº†FIDåˆ†æ•°ä¸º1.81ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒSiDAå®ç°äº†FIDåˆ†æ•°ä¸º2.156ï¼ˆXSå¤§å°ï¼‰ã€1.669ï¼ˆSå¤§å°ï¼‰ã€1.488ï¼ˆMå¤§å°ï¼‰ã€1.413ï¼ˆLå¤§å°ï¼‰ã€1.379ï¼ˆXLå¤§å°ï¼‰å’Œ1.366ï¼ˆXXLå¤§å°ï¼‰ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ²¡æœ‰ä½¿ç”¨CFGä¸”ä»…åœ¨ä¸€ä¸ªç”Ÿæˆæ­¥éª¤ä¸­å®Œæˆã€‚è¿™äº›ç»“æœçªæ˜¾äº†æ‰€æœ‰æ¨¡å‹å°ºå¯¸çš„æ˜¾è‘—æ”¹è¿›ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº <a target="_blank" rel="noopener" href="https://github.com/mingyuanzhou/SiD/tree/sida%E3%80%82">https://github.com/mingyuanzhou/SiD/tree/sidaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.14919v4">PDF</a> 10 pages (main text), 34 figures, and 10 tables</p>
<p><strong>æ‘˜è¦</strong></p>
<p>SiDAï¼ˆå¸¦æœ‰å¯¹æŠ—æŸå¤±çš„åˆ†æ•°èº«ä»½è’¸é¦æ³•ï¼‰æ˜¯ä¸€ç§ç»“åˆçœŸå®å›¾åƒä¸å¯¹æŠ—æŸå¤±çš„æŠ€æœ¯ï¼Œæé«˜äº†å›¾åƒç”Ÿæˆçš„å“è´¨ä¸è’¸é¦æ•ˆç‡ã€‚å®ƒé€šè¿‡å¼•å…¥å¯¹æŠ—æŸå¤±å¹¶èå…¥åŸæœ‰SiDï¼ˆåˆ†æ•°èº«ä»½è’¸é¦æ³•ï¼‰æŸå¤±ï¼Œæœ‰æ•ˆç»“åˆå¹³å‡â€œå‡åº¦â€ä¸åƒç´ çº§SiDæŸå¤±ï¼Œå®ç°äº†å•æ­¥ç”Ÿæˆå™¨çš„è’¸é¦ã€‚SiDAç›¸è¾ƒäºå‰ä»£æŠ€æœ¯ï¼Œä»ç©ºç™½çŠ¶æ€å¼€å§‹è’¸é¦æ—¶æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”åœ¨é¢„è’¸é¦SiDç”Ÿæˆå™¨ä¸Šè¿›è¡Œå¾®è°ƒæ—¶è¿…é€Ÿæå‡æ€§èƒ½ã€‚è¿™ä¸€å•æ­¥å¯¹æŠ—è’¸é¦æ–¹æ³•æ‰“ç ´äº†è’¸é¦æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½è®°å½•ï¼Œå¦‚åœ¨ImageNet 64x64ä¸Šå®ç°FIDå¾—åˆ†1.110ã€‚åœ¨è’¸é¦è®­ç»ƒäºImageNet 512x512çš„EDM2æ¨¡å‹æ—¶ï¼ŒSiDAæ–¹æ³•ç”šè‡³è¶…è¶Šäº†ä½¿ç”¨æ— åˆ†ç±»æŒ‡å¯¼ï¼ˆCFGï¼‰å’Œ63æ­¥ç”Ÿæˆçš„æœ€å¤§çš„æ•™å¸ˆæ¨¡å‹EDM2-XXLï¼ˆFID 1.81ï¼‰ã€‚ç›¸åï¼ŒSiDAåœ¨æ‰€æœ‰æ¨¡å‹å°ºå¯¸ä¸Šéƒ½å®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œæ— éœ€CFGå³å¯åœ¨å•ä¸€ç”Ÿæˆæ­¥éª¤ä¸­è¾¾åˆ°FIDå¾—åˆ†ï¼šXSä¸º2.156ã€Sä¸º1.669ã€Mä¸º1.488ã€Lä¸º1.413ã€XLä¸º1.379ä»¥åŠXXLä¸º1.366ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>SiDAæ˜¯é¦–ä¸ªç»“åˆçœŸå®å›¾åƒå’Œå¯¹æŠ—æŸå¤±ä»¥æé«˜å›¾åƒç”Ÿæˆè´¨é‡å’Œè’¸é¦æ•ˆç‡çš„æ–¹æ³•ã€‚</li>
<li>SiDAåˆ©ç”¨ç”Ÿæˆå™¨åˆ†æ•°ç½‘ç»œä¸­çš„ç¼–ç å™¨ä½œä¸ºåˆ¤åˆ«å™¨ï¼Œèƒ½å¤ŸåŒºåˆ†çœŸå®å›¾åƒå’Œç”±SiDç”Ÿæˆçš„å›¾åƒã€‚</li>
<li>å¯¹æŠ—æŸå¤±ä¸SiDæŸå¤±çš„èåˆï¼Œæœ‰æ•ˆèå…¥äº†GPUæ‰¹å¤„ç†ä¸­çš„å¹³å‡â€œå‡åº¦â€ï¼Œå®ç°äº†å•æ­¥ç”Ÿæˆå™¨çš„è’¸é¦ã€‚</li>
<li>SiDAåœ¨å¤šç§æ¨¡å‹å°ºå¯¸ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ— éœ€å¤æ‚çš„åˆ†ç±»æŒ‡å¯¼ï¼ˆCFGï¼‰å’Œå¤šä¸ªç”Ÿæˆæ­¥éª¤ã€‚</li>
<li>SiDAåœ¨ImageNet 64x64ä¸Šè¾¾åˆ°äº†FIDå¾—åˆ†1.110çš„æ–°æ€§èƒ½åŸºå‡†ã€‚</li>
<li>å¯¹äºæ›´å¤§å°ºå¯¸çš„ImageNet 512x512æ¨¡å‹ï¼ŒSiDAè¶…è¶Šäº†æœ€å…ˆè¿›æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>SiDAæ–¹æ³•å·²ç»å¼€æºï¼Œå¹¶ä¸”å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æé«˜å›¾åƒç”Ÿæˆè´¨é‡å’Œæ•ˆç‡æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.14919">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b44a083cfb44565b8cfda8cf62fd545.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-18b516f3bbead8b8d06a21305cf6298e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="EraseDraw-Learning-to-Draw-Step-by-Step-via-Erasing-Objects-from-Images"><a href="#EraseDraw-Learning-to-Draw-Step-by-Step-via-Erasing-Objects-from-Images" class="headerlink" title="EraseDraw: Learning to Draw Step-by-Step via Erasing Objects from Images"></a>EraseDraw: Learning to Draw Step-by-Step via Erasing Objects from Images</h2><p><strong>Authors:Alper Canberk, Maksym Bondarenko, Ege Ozguroglu, Ruoshi Liu, Carl Vondrick</strong></p>
<p>Creative processes such as painting often involve creating different components of an image one by one. Can we build a computational model to perform this task? Prior works often fail by making global changes to the image, inserting objects in unrealistic spatial locations, and generating inaccurate lighting details. We observe that while state-of-the-art models perform poorly on object insertion, they can remove objects and erase the background in natural images very well. Inverting the direction of object removal, we obtain high-quality data for learning to insert objects that are spatially, physically, and optically consistent with the surroundings. With this scalable automatic data generation pipeline, we can create a dataset for learning object insertion, which is used to train our proposed text conditioned diffusion model. Qualitative and quantitative experiments have shown that our model achieves state-of-the-art results in object insertion, particularly for in-the-wild images. We show compelling results on diverse insertion prompts and images across various domains.In addition, we automate iterative insertion by combining our insertion model with beam search guided by CLIP. </p>
<blockquote>
<p>ç»˜ç”»ç­‰åˆ›é€ æ€§è¿‡ç¨‹é€šå¸¸æ¶‰åŠé€ä¸ªåˆ›å»ºå›¾åƒçš„ä¸åŒç»„æˆéƒ¨åˆ†ã€‚æˆ‘ä»¬å¯ä»¥å»ºç«‹ä¸€ä¸ªè®¡ç®—æ¨¡å‹æ¥å®Œæˆè¿™é¡¹ä»»åŠ¡å—ï¼Ÿå…ˆå‰çš„å·¥ä½œå¾€å¾€é€šè¿‡åœ¨å›¾åƒä¸Šè¿›è¡Œå…¨å±€æ›´æ”¹ã€åœ¨ä¸ç°å®çš„ç©ºé—´ä½ç½®æ’å…¥å¯¹è±¡ä»¥åŠç”Ÿæˆä¸å‡†ç¡®çš„å…‰ç…§ç»†èŠ‚è€Œå¤±è´¥ã€‚æˆ‘ä»¬å‘ç°ï¼Œè™½ç„¶æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨å¯¹è±¡æ’å…¥æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œä½†å®ƒä»¬å¯ä»¥å¾ˆå¥½åœ°ä»è‡ªç„¶å›¾åƒä¸­ç§»é™¤å¯¹è±¡å’ŒèƒŒæ™¯ã€‚é€šè¿‡åè½¬å¯¹è±¡ç§»é™¤çš„æ–¹å‘ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—é«˜è´¨é‡çš„æ•°æ®æ¥å­¦ä¹ æ’å…¥ä¸å‘¨å›´ç¯å¢ƒåœ¨ç©ºé—´ã€ç‰©ç†å’Œå…‰å­¦ä¸Šä¸€è‡´çš„ç‰©ä½“ã€‚é€šè¿‡è¿™ç§å¯æ‰©å±•çš„è‡ªåŠ¨æ•°æ®ç”Ÿæˆç®¡é“ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç”¨äºå­¦ä¹ å¯¹è±¡æ’å…¥çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”¨äºè®­ç»ƒæˆ‘ä»¬æå‡ºçš„æ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€‚å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¯¹è±¡æ’å…¥æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡å¤–å›¾åƒæ–¹é¢ã€‚æˆ‘ä»¬åœ¨å„ç§æ’å…¥æç¤ºå’Œè·¨åŸŸå›¾åƒä¸Šå±•ç¤ºäº†ä»¤äººä¿¡æœçš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ’å…¥æ¨¡å‹ä¸CLIPå¼•å¯¼çš„æŸæœç´¢ç›¸ç»“åˆï¼Œå®ç°äº†è‡ªåŠ¨è¿­ä»£æ’å…¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.00522v2">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ›ä½œè¿‡ç¨‹å¦‚ç»˜ç”»éœ€é€ä¸ªæ„å»ºå›¾åƒçš„ä¸åŒç»„æˆéƒ¨åˆ†ã€‚èƒ½å¦å»ºç«‹è®¡ç®—æ¨¡å‹å®Œæˆæ­¤ä»»åŠ¡ï¼Ÿå…ˆå‰çš„å·¥ä½œå¸¸å› å…¨å±€æ›´æ”¹å›¾åƒã€æ’å…¥ä¸ç°å®çš„ç‰©ä½“ä½ç½®åŠç”Ÿæˆä¸å‡†ç¡®çš„å…‰ç…§ç»†èŠ‚è€Œå¤±è´¥ã€‚æˆ‘ä»¬å‘ç°è™½ç„¶æœ€æ–°æ¨¡å‹åœ¨ç‰©ä½“æ’å…¥æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œä½†åœ¨è‡ªç„¶å›¾åƒçš„èƒŒæ™¯å»é™¤æ–¹é¢éå¸¸å‡ºè‰²ã€‚é€šè¿‡åè½¬ç‰©ä½“ç§»é™¤çš„æ–¹å‘ï¼Œæˆ‘ä»¬è·å¾—äº†é«˜è´¨é‡æ•°æ®ï¼Œå­¦ä¹ æ’å…¥ä¸å‘¨å›´ç¯å¢ƒåœ¨ç©ºé—´ã€ç‰©ç†å’Œå…‰å­¦ä¸Šä¸€è‡´çš„ç‰©ä½“ã€‚åˆ©ç”¨è¿™ä¸€å¯æ‰©å±•çš„è‡ªåŠ¨æ•°æ®ç”Ÿæˆç®¡é“ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ç”¨äºè®­ç»ƒæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„æ•°æ®é›†ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ç‰©ä½“æ’å…¥æ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡å¤–å›¾åƒæ–¹é¢ã€‚æˆ‘ä»¬å±•ç¤ºäº†å„ç§æ’å…¥æç¤ºå’Œè·¨åŸŸå›¾åƒçš„ä»¤äººä¿¡æœçš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ’å…¥æ¨¡å‹ä¸CLIPå¼•å¯¼çš„æŸæœç´¢ç›¸ç»“åˆï¼Œå®ç°äº†è‡ªåŠ¨è¿­ä»£æ’å…¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—æ¨¡å‹å¯æ¨¡æ‹Ÿåˆ›ä½œè¿‡ç¨‹å¦‚ç»˜ç”»ä¸­çš„ç‰©ä½“é€ä¸ªæ„å»ºã€‚</li>
<li>å…ˆå‰æ¨¡å‹åœ¨æ’å…¥ç‰©ä½“æ—¶è¡¨ç°æ¬ ä½³ï¼Œå­˜åœ¨ç©ºé—´ä½ç½®ä¸çœŸå®ã€å…‰ç…§ç»†èŠ‚ä¸å‡†ç¡®ç­‰é—®é¢˜ã€‚</li>
<li>æœ€æ–°æ¨¡å‹åœ¨å»é™¤èƒŒæ™¯æ–¹é¢è¡¨ç°ä¼˜ç§€ï¼Œé€šè¿‡åè½¬è¿™ä¸€æ–¹å‘è·å¾—é«˜è´¨é‡æ•°æ®ç”¨äºå­¦ä¹ ç‰©ä½“æ’å…¥ã€‚</li>
<li>å»ºç«‹äº†è‡ªåŠ¨æ•°æ®ç”Ÿæˆç®¡é“ä»¥è®­ç»ƒæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹åœ¨ç‰©ä½“æ’å…¥æ–¹é¢è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é‡å¤–å›¾åƒæ—¶æ•ˆæœæ˜¾è‘—ã€‚</li>
<li>æ¨¡å‹å¯å¤„ç†å¤šç§æ’å…¥æç¤ºå’Œè·¨åŸŸå›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.00522">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1ead218b7a67780339b0cc9755cc860e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57f3f41ffec48a1b0fdf51b016d3088b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89eb5e8f8981feaa95bb5d1a89261fbf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba7f1d3af760a7d255ca253ba19981c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab4599751b95b360e59b67b15ec7e5f3.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-26/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-26/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-26/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3ee184809f97812831c45a8673743f23.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-26  Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors   Diverse-Resolution Training Outperforms Interpolation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-26/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-718132e6f5bbf9d8ece72adb831f3ee7.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-26  Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs   Algorithms
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">16042k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
