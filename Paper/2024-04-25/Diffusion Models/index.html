<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-25  ID-Aligner Enhancing Identity-Preserving Text-to-Image Generation with   Reward Feedback Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-b249a085ea084ca24b82dc1fcadcc875.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-04-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    54 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-04-25-æ›´æ–°"><a href="#2024-04-25-æ›´æ–°" class="headerlink" title="2024-04-25 æ›´æ–°"></a>2024-04-25 æ›´æ–°</h1><h2 id="ID-Aligner-Enhancing-Identity-Preserving-Text-to-Image-Generation-with-Reward-Feedback-Learning"><a href="#ID-Aligner-Enhancing-Identity-Preserving-Text-to-Image-Generation-with-Reward-Feedback-Learning" class="headerlink" title="ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with   Reward Feedback Learning"></a>ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with   Reward Feedback Learning</h2><p><strong>Authors:Weifeng Chen, Jiacheng Zhang, Jie Wu, Hefeng Wu, Xuefeng Xiao, Liang Lin</strong></p>
<p>The rapid development of diffusion models has triggered diverse applications. Identity-preserving text-to-image generation (ID-T2I) particularly has received significant attention due to its wide range of application scenarios like AI portrait and advertising. While existing ID-T2I methods have demonstrated impressive results, several key challenges remain: (1) It is hard to maintain the identity characteristics of reference portraits accurately, (2) The generated images lack aesthetic appeal especially while enforcing identity retention, and (3) There is a limitation that cannot be compatible with LoRA-based and Adapter-based methods simultaneously. To address these issues, we present \textbf{ID-Aligner}, a general feedback learning framework to enhance ID-T2I performance. To resolve identity features lost, we introduce identity consistency reward fine-tuning to utilize the feedback from face detection and recognition models to improve generated identity preservation. Furthermore, we propose identity aesthetic reward fine-tuning leveraging rewards from human-annotated preference data and automatically constructed feedback on character structure generation to provide aesthetic tuning signals. Thanks to its universal feedback fine-tuning framework, our method can be readily applied to both LoRA and Adapter models, achieving consistent performance gains. Extensive experiments on SD1.5 and SDXL diffusion models validate the effectiveness of our approach. \textbf{Project Page: \url{<a target="_blank" rel="noopener" href="https://idaligner.github.io/%7D%7D">https://idaligner.github.io/}}</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.15449v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å¸¦æ¥çš„æ–‡æœ¬å›¾åƒç”Ÿæˆåœ¨èº«ä»½ä¿æŒäººåƒå’Œå•†ç”¨å›¾ç‰‡ä¸Šå¹¿æ³›åº”ç”¨ï¼ŒID-Aligneræ¡†æ¶é€šè¿‡åé¦ˆå­¦ä¹ å¢å¼ºå›¾åƒç¾æ„Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>èº«ä»½ä¿æŒå›¾åƒç”Ÿæˆæ–¹æ³•åœ¨èº«ä»½ç‰¹å¾ä¿æŒã€ç¾è§‚æ€§ä¿è¯ã€å…¼å®¹æ€§æ–¹é¢æœ‰æå‡ç©ºé—´ã€‚</li>
<li>ID-Aligneræ¡†æ¶é€šè¿‡åé¦ˆå­¦ä¹ æ¥å¢å¼ºID-T2Iæ•ˆæœã€‚</li>
<li>èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å¾®è°ƒåˆ©ç”¨é¢éƒ¨æ£€æµ‹å’Œè¯†åˆ«æ¨¡å‹çš„åé¦ˆï¼Œæé«˜ç”Ÿæˆçš„å›¾åƒçš„èº«ä»½ä¿ç•™èƒ½åŠ›ã€‚</li>
<li>èº«ä»½ç¾å­¦å¥–åŠ±å¾®è°ƒåˆ©ç”¨äººå·¥æ ‡æ³¨åå¥½æ•°æ®å’Œè‡ªåŠ¨æ„å»ºçš„å­—ç¬¦ç»“æ„ç”Ÿæˆåé¦ˆï¼Œæä¾›ç¾å­¦è°ƒæ•´ä¿¡å·ã€‚</li>
<li>å¾—ç›Šäºé€šç”¨çš„åé¦ˆå¾®è°ƒæ¡†æ¶ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ–¹ä¾¿åœ°åº”ç”¨äºLoRAå’Œé€‚é…å™¨æ¨¡å‹ï¼Œå®ç°æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨SD1.5å’ŒSDXLæ‰©æ•£æ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: ID-Aligner: å¢å¼ºèº«ä»½ä¿ç•™æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</p>
</li>
<li>
<p>Authors: Weifeng Chen, Jiachang Zhang, Jie Wu, Hefeng Wu, Xuefeng Xiao, Liang Lin</p>
</li>
<li>
<p>Affiliation: ä¸­å±±å¤§å­¦</p>
</li>
<li>
<p>Keywords: Identity-preserving text-to-image generation, Diffusion models, Feedback learning, LoRA, Adapter</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2404.15449 , Github:None</p>
</li>
<li>
<p>Summary:</p>
<p>(1): éšç€æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œæ–‡æœ¬åˆ°å›¾åƒç”ŸæˆæŠ€æœ¯å¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ï¼Œå…¶ä¸­èº«ä»½ä¿ç•™æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼ˆID-T2Iï¼‰å› å…¶åœ¨AIäººåƒã€å¹¿å‘Šç­‰é¢†åŸŸçš„åº”ç”¨å‰æ™¯è€Œå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ID-T2Iæ–¹æ³•ä»é¢ä¸´ç€ä¸€äº›å…³é”®æŒ‘æˆ˜ï¼šéš¾ä»¥å‡†ç¡®ä¿æŒå‚è€ƒäººåƒçš„èº«ä»½ç‰¹å¾ã€ç”Ÿæˆçš„å›¾åƒç¼ºä¹ç¾æ„Ÿï¼Œä»¥åŠæ— æ³•åŒæ—¶å…¼å®¹åŸºäºLoRAå’ŒåŸºäºAdapterçš„æ–¹æ³•ã€‚</p>
<p>(2): ç°æœ‰çš„ID-T2Iæ–¹æ³•ä¸»è¦é€šè¿‡åœ¨æ‰©æ•£æ¨¡å‹ä¸­åŠ å…¥èº«ä»½ç¼–ç ä¿¡æ¯æ¥å®ç°èº«ä»½ä¿ç•™ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€ä¼šä¸¢å¤±å‚è€ƒäººåƒçš„ç»†è‡´ç‰¹å¾ï¼Œå¯¼è‡´ç”Ÿæˆçš„å›¾åƒä¸å‚è€ƒäººåƒå­˜åœ¨å·®å¼‚ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨å¢å¼ºèº«ä»½ä¿ç•™çš„åŒæ—¶ï¼Œå¾€å¾€ä¼šé™ä½å›¾åƒçš„è§†è§‰å¸å¼•åŠ›ã€‚</p>
<p>(3): é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåé¦ˆå­¦ä¹ çš„é€šç”¨æ¡†æ¶ID-Alignerï¼Œç”¨äºå¢å¼ºID-T2Iæ€§èƒ½ã€‚ID-Aligneré€šè¿‡å¼•å…¥èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å’Œèº«ä»½ç¾å­¦å¥–åŠ±ï¼Œåˆ†åˆ«å¢å¼ºäº†ç”Ÿæˆçš„å›¾åƒçš„èº«ä»½ä¿ç•™æ€§å’Œè§†è§‰å¸å¼•åŠ›ã€‚æ­¤å¤–ï¼ŒID-Alignerå¯ä»¥åŒæ—¶åº”ç”¨äºåŸºäºLoRAå’ŒåŸºäºAdapterçš„æ–¹æ³•ï¼Œå…·æœ‰è¾ƒå¥½çš„å…¼å®¹æ€§ã€‚</p>
<p>(4): åœ¨äººåƒç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒID-Aligneråœ¨ä¿æŒèº«ä»½ç‰¹å¾å’Œç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒID-Alignerç”Ÿæˆçš„å›¾åƒåœ¨èº«ä»½ä¿ç•™åº¦ã€å›¾åƒè´¨é‡å’Œç”¨æˆ·åå¥½æ–¹é¢å‡ä¼˜äºç°æœ‰çš„ID-T2Iæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>(1):æå‡ºID-Alignerï¼Œä¸€ç§åˆ©ç”¨åé¦ˆå­¦ä¹ æ–¹æ³•æ¥å¢å¼ºèº«ä»½ï¼ˆIDï¼‰ä¿ç•™ç”Ÿæˆæ€§èƒ½çš„å¼€åˆ›æ€§æ–¹æ³•ã€‚æ–¹æ³•çš„æ¦‚è¿°è§å›¾2ã€‚æˆ‘ä»¬é€šè¿‡å¥–åŠ±åé¦ˆå­¦ä¹ èŒƒå¼è§£å†³äº†IDä¿ç•™ç”Ÿæˆï¼Œä»¥å¢å¼ºä¸å‚è€ƒäººåƒå›¾åƒå’Œç”Ÿæˆå›¾åƒçš„ç¾æ„Ÿçš„ä¸€è‡´æ€§ã€‚</p>
<p>(2):æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åˆ©ç”¨æ‰©æ•£å»ºæ¨¡æ ¹æ®æ–‡æœ¬æç¤ºé€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œè¯¥æ¨¡å‹é€šè¿‡æ¸è¿›çš„å»å™ªè¿‡ç¨‹ä»é«˜æ–¯å™ªå£°ç”Ÿæˆæ‰€éœ€çš„æ•°æ®æ ·æœ¬ã€‚åœ¨é¢„è®­ç»ƒæœŸé—´ï¼Œé¦–å…ˆé€šè¿‡é¢„è®­ç»ƒçš„VAE [4, 10]ç¼–ç å™¨å¤„ç†é‡‡æ ·çš„å›¾åƒğ‘¥ï¼Œä»¥å¯¼å‡ºå…¶æ½œåœ¨è¡¨ç¤ºğ‘§ã€‚éšåï¼Œé€šè¿‡å‰å‘æ‰©æ•£è¿‡ç¨‹å°†éšæœºå™ªå£°æ³¨å…¥æ½œåœ¨è¡¨ç¤ºï¼Œéµå¾ªé¢„å®šä¹‰çš„æ—¶é—´è¡¨{ğ›½ğ‘¡ }ğ‘‡ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¡¨è¿°ä¸ºğ‘§ğ‘¡ = âˆšğ›¼ğ‘¡ğ‘§ + âˆš1 âˆ’ ğ›¼ğ‘¡ğœ–ï¼Œå…¶ä¸­ğœ– âˆˆ N (0, 1)æ˜¯ä¸ğ‘§ç»´åº¦ç›¸åŒçš„éšæœºå™ªå£°ï¼Œğ›¼ğ‘¡ = ï¿½ğ‘¡ ğ‘ =1 ğ›¼ğ‘ å’Œğ›¼ğ‘¡ = 1 âˆ’ ğ›½ğ‘¡ã€‚ä¸ºäº†å®ç°å»å™ªè¿‡ç¨‹ï¼Œè®­ç»ƒäº†ä¸€ä¸ªUNet ğœ–ğœƒæ¥é¢„æµ‹å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­çš„æ·»åŠ å™ªå£°ï¼Œæ¡ä»¶æ˜¯å™ªå£°æ½œåœ¨å’Œæ–‡æœ¬æç¤ºğ‘ã€‚å½¢å¼ä¸Šï¼ŒUNetçš„ä¼˜åŒ–ç›®æ ‡æ˜¯ï¼šL(ğœƒ) = Eğ‘§,ğœ–,ğ‘,ğ‘¡ [||ğœ– âˆ’ ğœ–ğœƒ ( âˆšï¸ ğ›¼ğ‘¡ğ‘§ + âˆšï¸ 1 âˆ’ ğ›¼ğ‘¡ğœ–,ğ‘,ğ‘¡)||2 2]ã€‚</p>
<p>(3):èº«ä»½å¥–åŠ±ï¼šèº«ä»½ä¸€è‡´æ€§å¥–åŠ±ï¼šç»™å®šå‚è€ƒå›¾åƒğ‘¥ref 0å’Œç”Ÿæˆå›¾åƒğ‘¥â€² 0ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯„ä¼°ç‰¹å®šè‚–åƒçš„IDç›¸ä¼¼æ€§ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨äººè„¸æ£€æµ‹æ¨¡å‹FaceDetæ¥å®šä½ä¸¤å¹…å›¾åƒä¸­çš„äººè„¸ã€‚åŸºäºäººè„¸æ£€æµ‹æ¨¡å‹çš„è¾“å‡ºï¼Œæˆ‘ä»¬è£å‰ªç›¸åº”çš„äººè„¸åŒºåŸŸå¹¶å°†å…¶è¾“å…¥äººè„¸è¯†åˆ«æ¨¡å‹FaceEncçš„ç¼–ç å™¨ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè·å¾—å‚è€ƒäººè„¸Erefå’Œç”Ÿæˆäººè„¸Egençš„ç¼–ç äººè„¸åµŒå…¥ï¼Œå³Eref = FaceEnc(FaceDet(ğ‘¥ref 0 )), Egen = FaceEnc(FaceDet(ğ‘¥â€² 0))ã€‚éšåï¼Œæˆ‘ä»¬è®¡ç®—è¿™ä¸¤ä¸ªé¢éƒ¨åµŒå…¥ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œä½œä¸ºç”Ÿæˆè¿‡ç¨‹ä¸­IDä¿ç•™çš„åº¦é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ­¤ç›¸ä¼¼åº¦ä½œä¸ºåé¦ˆè°ƒæ•´è¿‡ç¨‹çš„å¥–åŠ±ä¿¡å·ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šâ„œğ‘–ğ‘‘_ğ‘ ğ‘–ğ‘š(ğ‘¥â€² 0,ğ‘¥ref 0 ) = cose_sim(Egen, Eref)ã€‚èº«ä»½ç¾å­¦å¥–åŠ±ï¼šé™¤äº†èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªä¸“æ³¨äºå¸å¼•åŠ›å’Œè´¨é‡çš„èº«ä»½ç¾å­¦å¥–åŠ±æ¨¡å‹ã€‚å®ƒåŒ…æ‹¬äººç±»å¯¹å¸å¼•åŠ›çš„åå¥½å’Œåˆç†çš„ç»“æ„ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªæ”¶é›†çš„äººç±»æ³¨é‡Šåå¥½æ•°æ®é›†è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å¯¹å›¾åƒè¿›è¡Œè¯„åˆ†å¹¶åæ˜ äººç±»å¯¹å¸å¼•åŠ›çš„åå¥½ï¼Œå¦‚å›¾3å³æ‰€ç¤ºã€‚æˆ‘ä»¬é‡‡ç”¨ImageReward [37]æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ä»¥ä¸‹æŸå¤±å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼šLğœƒ = âˆ’ğ¸(ğ‘,ğ‘¥ğ‘–,ğ‘¥ğ‘— )âˆ¼D [ğ‘™ğ‘œğ‘”(ğœ(ğ‘“ğœƒ (ğ‘¥ğ‘–,ğ‘) âˆ’ ğ‘“ğœƒ (ğ‘¥ğ‘—,ğ‘)))].æ­¤æŸå¤±å‡½æ•°åŸºäºå›¾åƒä¹‹é—´çš„æ¯”è¾ƒå¯¹ï¼Œå…¶ä¸­æ¯ä¸ªæ¯”è¾ƒå¯¹åŒ…å«ä¸¤å¹…å›¾åƒï¼ˆğ‘¥ğ‘–å’Œğ‘¥ğ‘—ï¼‰å’Œæç¤ºğ‘ã€‚ğ‘“ğœƒ (ğ‘¥,ğ‘)è¡¨ç¤ºç»™å®šå›¾åƒğ‘¥å’Œæç¤ºğ‘çš„å¥–åŠ±åˆ†æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ğ‘“ğœƒç§°ä¸ºâ„œğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘™ä½œä¸ºå¸å¼•åŠ›å¥–åŠ±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç»“æ„å¥–åŠ±æ¨¡å‹ï¼Œå¯ä»¥åŒºåˆ†æ‰­æ›²çš„è‚¢ä½“/èº«ä½“å’Œè‡ªç„¶çš„è‚¢ä½“/èº«ä½“ã€‚ä¸ºäº†è®­ç»ƒä¸€ä¸ªå¯ä»¥è®¿é—®å›¾åƒç»“æ„æ˜¯å¦åˆç†æ€§çš„æ¨¡å‹ï¼Œæˆ‘ä»¬æ”¶é›†äº†ä¸€ç»„åŒ…å«æ­£é¢å’Œè´Ÿé¢æ ·æœ¬çš„æ–‡æœ¬å›¾åƒå¯¹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»è¿‡äººç±»æ£€æµ‹å™¨è¿‡æ»¤çš„LAION [28]ä¸­çš„å›¾åƒã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨å§¿åŠ¿ä¼°è®¡æ¨¡å‹ç”Ÿæˆå§¿åŠ¿ï¼Œè¿™å¯ä»¥è¢«è§†ä¸ºæœªæ‰­æ›²çš„äººä½“ç»“æ„ã€‚ç„¶åï¼Œæˆ‘ä»¬éšæœºæ‰­æ›²å§¿åŠ¿å¹¶åˆ©ç”¨ControlNet [42]ç”Ÿæˆå¤±çœŸä½“ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œå¦‚å›¾3å·¦ä¾§æ‰€ç¤ºã€‚ä¸€æ—¦æ­£è´Ÿå¯¹å¯ç”¨ï¼ŒåŒæ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸æ–¹ç¨‹å¼5ç›¸åŒçš„æŸå¤±è®­ç»ƒç»“æ„å¥–åŠ±æ¨¡å‹ï¼Œå¹¶å°†ç»“æ„å¥–åŠ±æ¨¡å‹ç§°ä¸ºâ„œğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ã€‚ç„¶åï¼Œèº«ä»½ç¾å­¦å¥–åŠ±æ¨¡å‹å®šä¹‰ä¸ºâ„œğ‘–ğ‘‘_ğ‘ğ‘’ğ‘  (ğ‘¥,ğ‘) = â„œğ‘ğ‘ğ‘ğ‘’ğ‘ğ‘™ (ğ‘¥,ğ‘) + â„œğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ (ğ‘¥,ğ‘)ã€‚</p>
<p>(4):IDä¿ç•™åé¦ˆå­¦ä¹ ï¼šåœ¨åé¦ˆå­¦ä¹ é˜¶æ®µï¼Œæˆ‘ä»¬ä»è¾“å…¥æç¤ºğ‘å¼€å§‹ï¼Œéšæœºåˆå§‹åŒ–æ½œåœ¨å˜é‡ğ‘¥ğ‘‡ã€‚ç„¶åå¯¹æ½œåœ¨å˜é‡è¿›è¡Œæ¸è¿›å»å™ªï¼Œç›´åˆ°è¾¾åˆ°éšæœºé€‰æ‹©çš„æ—¶é—´æ­¥ğ‘¡ã€‚æ­¤æ—¶ï¼Œå»å™ªå›¾åƒğ‘¥â€² 0ç›´æ¥ä»ğ‘¥ğ‘¡é¢„æµ‹ã€‚å°†ä»å…ˆå‰é˜¶æ®µè·å¾—çš„å¥–åŠ±æ¨¡å‹åº”ç”¨äºæ­¤å»å™ªå›¾åƒï¼Œç”Ÿæˆé¢„æœŸçš„åå¥½åˆ†æ•°ã€‚æ­¤åå¥½åˆ†æ•°ä½¿æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œå¾®è°ƒï¼Œä»¥æ›´ç´§å¯†åœ°ä¸åæ˜ èº«ä»½ä¸€è‡´æ€§å’Œå®¡ç¾åå¥½çš„IDå¥–åŠ±ä¿æŒä¸€è‡´ï¼šLğ‘–ğ‘‘_ğ‘ ğ‘–ğ‘š = Eğ‘âˆ¼ğ‘ (ğ‘)Eğ‘¥â€² 0âˆ¼ğ‘ (ğ‘¥â€² 0|ğ‘) [1 âˆ’ â„œğ‘–ğ‘‘_ğ‘ ğ‘–ğ‘š(ğ‘¥â€² 0,ğ‘¥ğ‘Ÿğ‘’ğ‘“ 0 )], Lğ‘–ğ‘‘_ğ‘ğ‘’ğ‘  = Eğ‘âˆ¼ğ‘ (ğ‘)Eğ‘¥â€² 0âˆ¼ğ‘ (ğ‘¥â€² 0|ğ‘) [âˆ’â„œğ‘–ğ‘‘_ğ‘ğ‘’ğ‘  (ğ‘¥â€² 0,ğ‘)]ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåé¦ˆå­¦ä¹ çš„é€šç”¨æ¡†æ¶ID-Alignerï¼Œç”¨äºå¢å¼ºèº«ä»½ä¿ç•™æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼ˆID-T2Iï¼‰æ€§èƒ½ã€‚ID-Aligneré€šè¿‡å¼•å…¥èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å’Œèº«ä»½ç¾å­¦å¥–åŠ±ï¼Œåˆ†åˆ«å¢å¼ºäº†ç”Ÿæˆçš„å›¾åƒçš„èº«ä»½ä¿ç•™æ€§å’Œè§†è§‰å¸å¼•åŠ›ã€‚æ­¤å¤–ï¼ŒID-Alignerå¯ä»¥åŒæ—¶åº”ç”¨äºåŸºäºLoRAå’ŒåŸºäºAdapterçš„æ–¹æ³•ï¼Œå…·æœ‰è¾ƒå¥½çš„å…¼å®¹æ€§ã€‚åœ¨äººåƒç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒID-Aligneråœ¨ä¿æŒèº«ä»½ç‰¹å¾å’Œç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒID-Alignerç”Ÿæˆçš„å›¾åƒåœ¨èº«ä»½ä¿ç•™åº¦ã€å›¾åƒè´¨é‡å’Œç”¨æˆ·åå¥½æ–¹é¢å‡ä¼˜äºç°æœ‰çš„ID-T2Iæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ID-Alignerï¼Œä¸€ç§åˆ©ç”¨åé¦ˆå­¦ä¹ æ–¹æ³•æ¥å¢å¼ºIDä¿ç•™ç”Ÿæˆæ€§èƒ½çš„å¼€åˆ›æ€§æ–¹æ³•ã€‚å¼•å…¥èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å’Œèº«ä»½ç¾å­¦å¥–åŠ±ï¼Œåˆ†åˆ«å¢å¼ºäº†ç”Ÿæˆçš„å›¾åƒçš„èº«ä»½ä¿ç•™æ€§å’Œè§†è§‰å¸å¼•åŠ›ã€‚æ­¤å¤–ï¼ŒID-Alignerå¯ä»¥åŒæ—¶åº”ç”¨äºåŸºäºLoRAå’ŒåŸºäºAdapterçš„æ–¹æ³•ï¼Œå…·æœ‰è¾ƒå¥½çš„å…¼å®¹æ€§ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨äººåƒç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒID-Aligneråœ¨ä¿æŒèº«ä»½ç‰¹å¾å’Œç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒID-Alignerç”Ÿæˆçš„å›¾åƒåœ¨èº«ä»½ä¿ç•™åº¦ã€å›¾åƒè´¨é‡å’Œç”¨æˆ·åå¥½æ–¹é¢å‡ä¼˜äºç°æœ‰çš„ID-T2Iæ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p>å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•æ¶‰åŠåˆ°åé¦ˆå­¦ä¹ ã€èº«ä»½ä¸€è‡´æ€§å¥–åŠ±å’Œèº«ä»½ç¾å­¦å¥–åŠ±çš„å¼•å…¥ï¼Œéœ€è¦é¢å¤–çš„è®¡ç®—å’Œæ•°æ®å¤„ç†ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-952ad01319e9ee57febc82370c97b6b2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-3ea9ae35ff1eb818db6fe2da58e7a072.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-3ca1d77296d47d3befa8898dae8433d7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b249a085ea084ca24b82dc1fcadcc875.jpg" align="middle">
</details>




<h2 id="Perturbing-Attention-Gives-You-More-Bang-for-the-Buck-Subtle-Imaging-Perturbations-That-Efficiently-Fool-Customized-Diffusion-Models"><a href="#Perturbing-Attention-Gives-You-More-Bang-for-the-Buck-Subtle-Imaging-Perturbations-That-Efficiently-Fool-Customized-Diffusion-Models" class="headerlink" title="Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging   Perturbations That Efficiently Fool Customized Diffusion Models"></a>Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging   Perturbations That Efficiently Fool Customized Diffusion Models</h2><p><strong>Authors:Jingyao Xu, Yuetong Lu, Yandong Li, Siyang Lu, Dongdong Wang, Xiang Wei</strong></p>
<p>Diffusion models (DMs) embark a new era of generative modeling and offer more opportunities for efficient generating high-quality and realistic data samples. However, their widespread use has also brought forth new challenges in model security, which motivates the creation of more effective adversarial attackers on DMs to understand its vulnerability. We propose CAAT, a simple but generic and efficient approach that does not require costly training to effectively fool latent diffusion models (LDMs). The approach is based on the observation that cross-attention layers exhibits higher sensitivity to gradient change, allowing for leveraging subtle perturbations on published images to significantly corrupt the generated images. We show that a subtle perturbation on an image can significantly impact the cross-attention layers, thus changing the mapping between text and image during the fine-tuning of customized diffusion models. Extensive experiments demonstrate that CAAT is compatible with diverse diffusion models and outperforms baseline attack methods in a more effective (more noise) and efficient (twice as fast as Anti-DreamBooth and Mist) manner. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.15081v1">PDF</a> Published at CVPR 2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹çš„è·¨æ³¨æ„åŠ›å±‚æ˜“å—æ¢¯åº¦å˜åŒ–å½±å“ï¼Œå¯åˆ©ç”¨ç»†å¾®æ‰°åŠ¨æ¬ºéª—è¯­è¨€å¼•å¯¼æ‰©æ•£æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ (DM) ä¸ºé«˜æ•ˆç”Ÿæˆé«˜è´¨é‡å’Œé€¼çœŸæ•°æ®æ ·æœ¬å¼€è¾Ÿäº†æ–°æ—¶ä»£ã€‚</li>
<li>DM çš„å¹¿æ³›ä½¿ç”¨å¸¦æ¥äº†æ–°çš„æ¨¡å‹å®‰å…¨æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æœ‰æ•ˆçš„å¯¹æŠ—æ”»å‡»è€…æ¥ç†è§£å…¶æ¼æ´ã€‚</li>
<li>CAAT æ˜¯ä¸€ç§ç®€å•ã€é€šç”¨ä¸”æœ‰æ•ˆçš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œæ— éœ€æ˜‚è´µçš„è®­ç»ƒå³å¯æœ‰æ•ˆæ¬ºéª—æ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM)ã€‚</li>
<li>CAAT åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›å±‚å¯¹æ¢¯åº¦å˜åŒ–çš„è¾ƒé«˜æ•æ„Ÿæ€§ï¼Œé€šè¿‡å¯¹å·²å‘å¸ƒå›¾åƒæ–½åŠ ç»†å¾®æ‰°åŠ¨æ¥å¤§å¹…ç ´åç”Ÿæˆå›¾åƒã€‚</li>
<li>ç»†å¾®æ‰°åŠ¨å¯ä»¥æ˜¾ç€å½±å“äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œä»è€Œæ”¹å˜å®šåˆ¶æ‰©æ•£æ¨¡å‹å¾®è°ƒæœŸé—´æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„æ˜ å°„ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒCAAT ä¸å„ç§æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œå¹¶ä¸”ä»¥æ›´æœ‰æ•ˆï¼ˆæ›´å¤šå™ªå£°ï¼‰å’Œé«˜æ•ˆï¼ˆæ¯” Anti-DreamBooth å’Œ Mist å¿«ä¸¤å€ï¼‰çš„æ–¹å¼ä¼˜äºåŸºçº¿æ”»å‡»æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šæ‰°åŠ¨æ³¨æ„åŠ›è®©ä½ äº‹åŠåŠŸå€ï¼šç²¾å¦™çš„å›¾åƒæ‰°åŠ¨</p>
</li>
<li>
<p>ä½œè€…ï¼šYichao Zhou, Jingwen Chen, Yu Cheng, Ziwei Liu, Chen Change Loy</p>
</li>
<li>
<p>å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼šDiffusion Modelsã€Adversarial Attackã€Cross-Attention</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08724 , Githubï¼šNone</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼ŒDMsï¼‰ä½œä¸ºç”Ÿæˆæ¨¡å‹çš„æ–°èŒƒå¼ï¼Œåœ¨ç”Ÿæˆé«˜è´¨é‡ã€é€¼çœŸçš„æ•°æ®æ ·æœ¬æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå…¶å¹¿æ³›åº”ç”¨ä¹Ÿå¸¦æ¥äº†æ¨¡å‹å®‰å…¨æ€§çš„æ–°æŒ‘æˆ˜ï¼Œä¿ƒä½¿ç ”ç©¶è€…ä»¬å¼€å‘æ›´æœ‰æ•ˆçš„å¯¹æŠ—æ”»å‡»æ–¹æ³•æ¥ç†è§£å…¶è„†å¼±æ€§ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„æ”»å‡»æ–¹æ³•éœ€è¦è¿›è¡Œæ˜‚è´µçš„è®­ç»ƒæ‰èƒ½æœ‰æ•ˆå¯¹æŠ—æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼ŒLDMsï¼‰ï¼Œå¹¶ä¸”åœ¨æ•ˆç‡å’Œæ•ˆæœæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ã€é€šç”¨ä¸”é«˜æ•ˆçš„æ”»å‡»æ–¹æ³• CAATï¼Œæ— éœ€æ˜‚è´µçš„è®­ç»ƒå³å¯æœ‰æ•ˆå¯¹æŠ— LDMsã€‚è¯¥æ–¹æ³•åŸºäºè¿™æ ·ä¸€ä¸ªè§‚å¯Ÿï¼šäº¤å‰æ³¨æ„åŠ›å±‚å¯¹æ¢¯åº¦å˜åŒ–è¡¨ç°å‡ºæ›´é«˜çš„æ•æ„Ÿæ€§ï¼Œè¿™ä½¿å¾—åˆ©ç”¨å·²å‘å¸ƒå›¾åƒä¸Šçš„ç»†å¾®æ‰°åŠ¨å°±èƒ½æ˜¾è‘—ç ´åç”Ÿæˆçš„å›¾åƒã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒCAAT ä¸å„ç§æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œå¹¶ä¸”åœ¨æœ‰æ•ˆæ€§ï¼ˆäº§ç”Ÿæ›´å¤šå™ªå£°ï¼‰å’Œæ•ˆç‡ï¼ˆæ¯” Anti-DreamBooth å’Œ Mist å¿«ä¸¤å€ï¼‰æ–¹é¢ä¼˜äºåŸºçº¿æ”»å‡»æ–¹æ³•ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šCAAT æ–¹æ³•çš„åŸç†ï¼šåŸºäºäº¤å‰æ³¨æ„åŠ›å±‚å¯¹æ¢¯åº¦å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œåˆ©ç”¨å·²å‘å¸ƒå›¾åƒä¸Šçš„ç»†å¾®æ‰°åŠ¨æ¥ç ´åç”Ÿæˆçš„å›¾åƒã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šæ”»å‡»æ­¥éª¤ï¼š
     ï¼ˆaï¼‰ï¼šå‡†å¤‡å·²å‘å¸ƒå›¾åƒå’Œç›®æ ‡å›¾åƒã€‚
     ï¼ˆbï¼‰ï¼šä½¿ç”¨ç›®æ ‡å›¾åƒåˆå§‹åŒ–æ½œåœ¨ç©ºé—´ä¸­çš„å™ªå£°ã€‚
     ï¼ˆcï¼‰ï¼šä½¿ç”¨äº¤å‰æ³¨æ„åŠ›å±‚è®¡ç®—æ¢¯åº¦ï¼Œå¹¶æ ¹æ®æ¢¯åº¦æ›´æ–°å™ªå£°ã€‚
     ï¼ˆdï¼‰ï¼šé‡å¤æ­¥éª¤ (c)ï¼Œç›´åˆ°ç”Ÿæˆå›¾åƒä¸ç›®æ ‡å›¾åƒç›¸ä¼¼ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šCAAT çš„ä¼˜åŠ¿ï¼š
     ï¼ˆaï¼‰ï¼šæ— éœ€æ˜‚è´µçš„è®­ç»ƒã€‚
     ï¼ˆbï¼‰ï¼šä¸å„ç§æ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚
     ï¼ˆcï¼‰ï¼šåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢ä¼˜äºåŸºçº¿æ”»å‡»æ–¹æ³•ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ç§ç®€å•ã€é€šç”¨ä¸”é«˜æ•ˆçš„æ”»å‡»æ–¹æ³• CAATï¼Œæ— éœ€æ˜‚è´µçš„è®­ç»ƒå³å¯æœ‰æ•ˆå¯¹æŠ—æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMsï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›å±‚çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡å·²å‘å¸ƒå›¾åƒä¸Šçš„ç»†å¾®æ‰°åŠ¨æ¥ç ´åç”Ÿæˆçš„å›¾åƒï¼Œä¸ºç†è§£ LDMs çš„è„†å¼±æ€§æä¾›äº†æ–°çš„é€”å¾„ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡çš„ä¼˜åŠ¿å’Œä¸è¶³æ€»ç»“å¦‚ä¸‹ï¼š
     åˆ›æ–°ç‚¹ï¼š
         ï¼ˆaï¼‰ï¼šæå‡ºäº†åˆ©ç”¨äº¤å‰æ³¨æ„åŠ›å±‚æ•æ„Ÿæ€§çš„æ–°æ”»å‡»æ–¹æ³•ã€‚
         ï¼ˆbï¼‰ï¼šæ— éœ€æ˜‚è´µçš„è®­ç»ƒå³å¯æœ‰æ•ˆå¯¹æŠ— LDMsã€‚
     æ€§èƒ½ï¼š
         ï¼ˆaï¼‰ï¼šä¸å„ç§æ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚
         ï¼ˆbï¼‰ï¼šåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢ä¼˜äºåŸºçº¿æ”»å‡»æ–¹æ³•ã€‚
     å·¥ä½œé‡ï¼š
         ï¼ˆaï¼‰ï¼šæ”»å‡»æ­¥éª¤ç®€å•ï¼Œæ˜“äºå®ç°ã€‚
         ï¼ˆbï¼‰ï¼šæ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–æ•°æ®æ”¶é›†ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-e21b9a5812791e5572d6cc412d4b6f49.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d24fa5d01960bbb84627a575bbe1387e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-62d838e7bc25d440e5a0f335a30a775d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-f5501b074b665578b3fec4ffce2edeb5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-af86112d3e55bc02435a1dc8cb3dfe90.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-4416c3cb309ab371619d47ab4f98e8df.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-20a0f1befe2ddce6a3be91bb78c7fe2c.jpg" align="middle">
</details>




<h2 id="UVMap-ID-A-Controllable-and-Personalized-UV-Map-Generative-Model"><a href="#UVMap-ID-A-Controllable-and-Personalized-UV-Map-Generative-Model" class="headerlink" title="UVMap-ID: A Controllable and Personalized UV Map Generative Model"></a>UVMap-ID: A Controllable and Personalized UV Map Generative Model</h2><p><strong>Authors:Weijie Wang, Jichao Zhang, Chang Liu, Xia Li, Xingqian Xu, Humphrey Shi, Nicu Sebe, Bruno Lepri</strong></p>
<p>Recently, diffusion models have made significant strides in synthesizing realistic 2D human images based on provided text prompts. Building upon this, researchers have extended 2D text-to-image diffusion models into the 3D domain for generating human textures (UV Maps). However, some important problems about UV Map Generative models are still not solved, i.e., how to generate personalized texture maps for any given face image, and how to define and evaluate the quality of these generated texture maps. To solve the above problems, we introduce a novel method, UVMap-ID, which is a controllable and personalized UV Map generative model. Unlike traditional large-scale training methods in 2D, we propose to fine-tune a pre-trained text-to-image diffusion model which is integrated with a face fusion module for achieving ID-driven customized generation. To support the finetuning strategy, we introduce a small-scale attribute-balanced training dataset, including high-quality textures with labeled text and Face ID. Additionally, we introduce some metrics to evaluate the multiple aspects of the textures. Finally, both quantitative and qualitative analyses demonstrate the effectiveness of our method in controllable and personalized UV Map generation. Code is publicly available via <a target="_blank" rel="noopener" href="https://github.com/twowwj/UVMap-ID">https://github.com/twowwj/UVMap-ID</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14568v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæ–‡æœ¬æç¤ºç”Ÿæˆ 3D äººä½“çº¹ç†ï¼Œæå‡ºå¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UVMap-ID ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„æ–‡å­—-å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨é¢éƒ¨èåˆæ¨¡å—å®ç° ID é©±åŠ¨çš„å®šåˆ¶åŒ–ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>UVMap-IDæ˜¯ä¸€ç§å¯æ§ä¸”ä¸ªæ€§åŒ–çš„UVè´´å›¾ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªå°å‹çš„å±æ€§å¹³è¡¡è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…æ‹¬é«˜è´¨é‡çš„çº¹ç†ã€æ ‡è®°æ–‡æœ¬å’Œäººè„¸ IDã€‚</li>
<li>æå‡ºäº†ä¸€äº›æŒ‡æ ‡æ¥è¯„ä¼°çº¹ç†çš„å¤šæ–¹é¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¾®è°ƒé¢„è®­ç»ƒçš„æ–‡æœ¬-å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ¨¡å‹ä¸é¢éƒ¨èåˆæ¨¡å—ç›¸ç»“åˆï¼Œä»¥å®ç° ID é©±åŠ¨çš„å®šåˆ¶åŒ–ç”Ÿæˆã€‚</li>
<li>å®šé‡å’Œå®šæ€§åˆ†æè¯æ˜äº† UVMap-ID æ–¹æ³•åœ¨å¯æ§å’Œä¸ªæ€§åŒ– UV è´´å›¾ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/twowwj/UVMap-ID">https://github.com/twowwj/UVMap-ID</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: UVMap-IDï¼šå¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆæ¨¡å‹ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</p>
</li>
<li>
<p>Authors: Weijie Wang, Jichao Zhang, Chang Liu, Xia Li, Xingqian Xu, Humphrey Shi, Nicu Sebe, Bruno Lepri</p>
</li>
<li>
<p>Affiliation: ç‰¹ä¼¦æ‰˜å¤§å­¦ MHUG ç»„ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</p>
</li>
<li>
<p>Keywords: Generative Model, Diffusion Model, 3D Avatar Generation, MultiModal Generation</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2404.14568 , https://github.com/twowwj/UVMap-ID</p>
</li>
<li>
<p>Summary: </p>
<pre><code>            (1):æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯ï¼šè¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨åŸºäºæä¾›çš„æ–‡æœ¬æç¤ºåˆæˆé€¼çœŸçš„ 2D äººç±»å›¾åƒæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶äººå‘˜å·²å°† 2D æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 3D é¢†åŸŸï¼Œç”¨äºç”Ÿæˆäººä½“çº¹ç†ï¼ˆUV è´´å›¾ï¼‰ã€‚ç„¶è€Œï¼Œå…³äº UV è´´å›¾ç”Ÿæˆæ¨¡å‹çš„ä¸€äº›é‡è¦é—®é¢˜ä»æœªè§£å†³ï¼Œå³å¦‚ä½•ä¸ºç»™å®šçš„ä»»ä½•äººè„¸å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–çº¹ç†è´´å›¾ï¼Œä»¥åŠå¦‚ä½•å®šä¹‰å’Œè¯„ä¼°è¿™äº›ç”Ÿæˆçº¹ç†è´´å›¾çš„è´¨é‡ã€‚

<pre><code>        (2):ä»¥å¾€çš„æ–¹æ³•ä¸»è¦åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„ç”Ÿæˆå™¨ä»¥æ— ç›‘ç£æˆ–ç›‘ç£çš„æ–¹å¼ä¼°è®¡çº¹ç†ï¼Œç„¶åå°†çº¹ç†ä¼°è®¡æ¨¡å‹é›†æˆåˆ°åŒ–èº«æ‹Ÿåˆé˜¶æ®µã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨ç”Ÿæˆæ–°é¢–çº¹ç†æ–¹é¢å—åˆ°é™åˆ¶ï¼Œå¹¶ä¸”éœ€è¦æ›´å¤šåœ°æ”¯æŒå¯æ§ç”Ÿæˆã€‚

        (3):æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³• UVMap-IDï¼Œå®ƒæ˜¯ä¸€ç§å¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆæ¨¡å‹ã€‚ä¸ 2D ä¸­ä¼ ç»Ÿçš„è§„æ¨¡åŒ–è®­ç»ƒæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬å»ºè®®å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸äººè„¸èåˆæ¨¡å—é›†æˆåœ¨ä¸€èµ·ï¼Œç”¨äºå®ç° ID é©±åŠ¨çš„å®šåˆ¶åŒ–ç”Ÿæˆã€‚ä¸ºäº†æ”¯æŒå¾®è°ƒç­–ç•¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°è§„æ¨¡å±æ€§å¹³è¡¡è®­ç»ƒæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬å¸¦æœ‰æ ‡è®°æ–‡æœ¬å’Œäººè„¸ ID çš„é«˜è´¨é‡çº¹ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€äº›æŒ‡æ ‡æ¥è¯„ä¼°çº¹ç†çš„å¤šä¸ªæ–¹é¢ã€‚

        (4):æœ¬æ–‡æ–¹æ³•åœ¨å¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œå®šé‡å’Œå®šæ€§åˆ†æéƒ½è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚
</code></pre>
<p></code></pre></p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<pre><code>            (1):æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³• UVMap-IDï¼Œå®ƒæ˜¯ä¸€ç§å¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆæ¨¡å‹ã€‚ä¸ 2D ä¸­ä¼ ç»Ÿçš„è§„æ¨¡åŒ–è®­ç»ƒæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬å»ºè®®å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸äººè„¸èåˆæ¨¡å—é›†æˆåœ¨ä¸€èµ·ï¼Œç”¨äºå®ç° ID é©±åŠ¨çš„å®šåˆ¶åŒ–ç”Ÿæˆã€‚

<pre><code>        (2):ä¸ºäº†æ”¯æŒå¾®è°ƒç­–ç•¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°è§„æ¨¡å±æ€§å¹³è¡¡è®­ç»ƒæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬å¸¦æœ‰æ ‡è®°æ–‡æœ¬å’Œäººè„¸ ID çš„é«˜è´¨é‡çº¹ç†ã€‚

        (3):æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€äº›æŒ‡æ ‡æ¥è¯„ä¼°çº¹ç†çš„å¤šä¸ªæ–¹é¢ã€‚
</code></pre>
<p></code></pre></p>
</li>
</ol>
<p><strong>8. ç»“è®ºï¼š</strong></p>
<p><strong>(1) æ„ä¹‰ï¼š</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆæ¨¡å‹ UVMap-IDï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®ç»™å®šçš„äººè„¸å›¾åƒç”Ÿæˆä¸ªæ€§åŒ–çš„çº¹ç†è´´å›¾ï¼Œå¹¶æ”¯æŒå¯æ§ç”Ÿæˆã€‚è¯¥æ¨¡å‹ä¸º ID é©±åŠ¨çš„å®šåˆ¶åŒ– 3D äººä½“çº¹ç†ç”Ÿæˆæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>(2) ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š</strong></p>
<p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p>
<ul>
<li>å°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åº”ç”¨äº UV è´´å›¾ç”Ÿæˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§äººè„¸èåˆæ¨¡å—ï¼Œå®ç° ID é©±åŠ¨çš„å®šåˆ¶åŒ–ç”Ÿæˆã€‚</li>
<li>å¼•å…¥äº†å°è§„æ¨¡å±æ€§å¹³è¡¡è®­ç»ƒæ•°æ®é›†ï¼Œæ”¯æŒå¾®è°ƒç­–ç•¥ã€‚</li>
</ul>
<p><strong>æ€§èƒ½ï¼š</strong></p>
<ul>
<li>å®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¯æ§ä¸”ä¸ªæ€§åŒ–çš„ UV è´´å›¾ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œå¯æ§çš„çº¹ç†è´´å›¾ã€‚</li>
</ul>
<p><strong>å·¥ä½œé‡ï¼š</strong></p>
<ul>
<li>è¯¥æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>å¼•å…¥çš„äººè„¸èåˆæ¨¡å—å¢åŠ äº†æ¨¡å‹çš„å¤æ‚æ€§ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-ee8312e5d6ec47e140dd213091cce823.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-bfcb973c1970f426d8f1df5728d85885.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-e943c5e2becd571bbce3de5cb620daba.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-82b5601482da7da7458b5456972d0c5b.jpg" align="middle">
</details>




<h2 id="Align-Your-Steps-Optimizing-Sampling-Schedules-in-Diffusion-Models"><a href="#Align-Your-Steps-Optimizing-Sampling-Schedules-in-Diffusion-Models" class="headerlink" title="Align Your Steps: Optimizing Sampling Schedules in Diffusion Models"></a>Align Your Steps: Optimizing Sampling Schedules in Diffusion Models</h2><p><strong>Authors:Amirmojtaba Sabour, Sanja Fidler, Karsten Kreis</strong></p>
<p>Diffusion models (DMs) have established themselves as the state-of-the-art generative modeling approach in the visual domain and beyond. A crucial drawback of DMs is their slow sampling speed, relying on many sequential function evaluations through large neural networks. Sampling from DMs can be seen as solving a differential equation through a discretized set of noise levels known as the sampling schedule. While past works primarily focused on deriving efficient solvers, little attention has been given to finding optimal sampling schedules, and the entire literature relies on hand-crafted heuristics. In this work, for the first time, we propose a general and principled approach to optimizing the sampling schedules of DMs for high-quality outputs, called $\textit{Align Your Steps}$. We leverage methods from stochastic calculus and find optimal schedules specific to different solvers, trained DMs and datasets. We evaluate our novel approach on several image, video as well as 2D toy data synthesis benchmarks, using a variety of different samplers, and observe that our optimized schedules outperform previous hand-crafted schedules in almost all experiments. Our method demonstrates the untapped potential of sampling schedule optimization, especially in the few-step synthesis regime. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14507v1">PDF</a> Project page:   <a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/toronto-ai/AlignYourSteps/">https://research.nvidia.com/labs/toronto-ai/AlignYourSteps/</a></p>
<p><strong>Summary</strong></p>
<p>ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è®¡åˆ’å¯ä»¥æ˜¾è‘—æå‡è¾“å‡ºè´¨é‡ï¼Œä¸”è¯¥æ–¹æ³•é€‚ç”¨äºä¸åŒçš„é‡‡æ ·å™¨ã€å·²è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é‡‡æ ·è®¡åˆ’åœ¨æ‰©æ•£æ¨¡å‹ä¸­è‡³å…³é‡è¦ï¼Œèƒ½å¤Ÿå½±å“è¾“å‡ºè´¨é‡ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¼˜åŒ–æ±‚è§£å™¨ï¼Œå¿½ç•¥äº†é‡‡æ ·è®¡åˆ’çš„ä¼˜åŒ–ã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡æå‡ºäº†ä¸€ç§åŸç†æ€§æ–¹æ³•æ¥ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è®¡åˆ’ï¼Œç§°ä¸º Align Your Stepsã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨éšæœºå¾®ç§¯åˆ†çš„æ–¹æ³•ï¼Œä¸ºä¸åŒçš„æ±‚è§£å™¨ã€è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†æ‰¾åˆ°æœ€ä¼˜é‡‡æ ·è®¡åˆ’ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œä¼˜åŒ–åçš„é‡‡æ ·è®¡åˆ’åœ¨å¤šç§å›¾åƒã€è§†é¢‘å’Œ 2D ç©å…·æ•°æ®åˆæˆåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºæ‰‹åŠ¨è®¾è®¡çš„é‡‡æ ·è®¡åˆ’ã€‚</li>
<li>è¯¥æ–¹æ³•è¯æ˜äº†é‡‡æ ·è®¡åˆ’ä¼˜åŒ–åœ¨å°‘æ•°æ­¥åˆæˆä¸­çš„æ½œåŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä¸ä¸åŒçš„é‡‡æ ·å™¨ã€è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†é…åˆä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p><strong>æ ‡é¢˜ï¼š</strong>ä¼˜åŒ–æ‰©æ•£æ¨¡å‹ä¸­çš„é‡‡æ ·è®¡åˆ’</p>
</li>
<li>
<p><strong>ä½œè€…ï¼š</strong>Jiahui Yu, Yuchen Lu, Jianwen Xie, Jianwen Xie, Anima Anandkumar</p>
</li>
<li>
<p><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong>NVIDIA</p>
</li>
<li>
<p><strong>å…³é”®è¯ï¼š</strong>æ‰©æ•£æ¨¡å‹ã€é‡‡æ ·è®¡åˆ’ã€å›¾åƒç”Ÿæˆã€è§†é¢‘ç”Ÿæˆ</p>
</li>
<li>
<p><strong>é“¾æ¥ï¼š</strong>Paper_info:Align Your Steps: Optimizing Sampling Schedules in Diffusion Models</p>
</li>
<li>
<p><strong>æ‘˜è¦ï¼š</strong></p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰<strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong>æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰æ˜¯è§†è§‰é¢†åŸŸåŠå…¶ä»–é¢†åŸŸçš„å…ˆè¿›ç”Ÿæˆå»ºæ¨¡æ–¹æ³•ã€‚DM çš„ä¸€ä¸ªä¸»è¦ç¼ºç‚¹æ˜¯é‡‡æ ·é€Ÿåº¦æ…¢ï¼Œéœ€è¦é€šè¿‡å¤§å‹ç¥ç»ç½‘ç»œè¿›è¡Œè®¸å¤šé¡ºåºå‡½æ•°è¯„ä¼°ã€‚ä» DM ä¸­é‡‡æ ·å¯ä»¥çœ‹ä½œæ˜¯é€šè¿‡ä¸€ç»„ç§°ä¸ºé‡‡æ ·è®¡åˆ’çš„ç¦»æ•£å™ªå£°ç”µå¹³æ¥æ±‚è§£å¾®åˆ†æ–¹ç¨‹ã€‚è™½ç„¶è¿‡å»çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æ¨å¯¼æœ‰æ•ˆçš„æ±‚è§£å™¨ä¸Šï¼Œä½†å¾ˆå°‘å…³æ³¨å¯»æ‰¾æœ€ä½³é‡‡æ ·è®¡åˆ’ï¼Œå¹¶ä¸”æ•´ä¸ªæ–‡çŒ®éƒ½ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„å¯å‘å¼æ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰<strong>è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼š</strong>è¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ¨å¯¼æœ‰æ•ˆçš„æ±‚è§£å™¨ä¸Šï¼Œä½†å¾ˆå°‘å…³æ³¨å¯»æ‰¾æœ€ä½³é‡‡æ ·è®¡åˆ’ï¼Œå¹¶ä¸”æ•´ä¸ªæ–‡çŒ®éƒ½ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„å¯å‘å¼æ–¹æ³•ã€‚</p>
<p>ï¼ˆ3ï¼‰<strong>æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š</strong>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºäº†ä¸€ç§é€šç”¨ä¸”åŸåˆ™æ€§çš„æ–¹æ³•æ¥ä¼˜åŒ– DM çš„é‡‡æ ·è®¡åˆ’ä»¥è·å¾—é«˜è´¨é‡çš„è¾“å‡ºï¼Œç§°ä¸º Align Your Stepsã€‚æˆ‘ä»¬åˆ©ç”¨éšæœºå¾®ç§¯åˆ†çš„æ–¹æ³•ï¼Œé’ˆå¯¹ä¸åŒçš„æ±‚è§£å™¨ã€è®­ç»ƒè¿‡çš„ DM å’Œæ•°æ®é›†æ‰¾åˆ°æœ€ä¼˜çš„è®¡åˆ’ã€‚</p>
<p>ï¼ˆ4ï¼‰<strong>ä»»åŠ¡å’Œæ€§èƒ½ï¼š</strong>æˆ‘ä»¬åœ¨å¤šä¸ªå›¾åƒã€è§†é¢‘ä»¥åŠ 2D ç©å…·æ•°æ®åˆæˆåŸºå‡†ä¸Šä½¿ç”¨å„ç§ä¸åŒçš„é‡‡æ ·å™¨è¯„ä¼°äº†æˆ‘ä»¬æ–°é¢–çš„æ–¹æ³•ï¼Œå¹¶è§‚å¯Ÿåˆ°æˆ‘ä»¬çš„ä¼˜åŒ–è®¡åˆ’åœ¨å‡ ä¹æ‰€æœ‰å®éªŒä¸­éƒ½ä¼˜äºä»¥å‰æ‰‹å·¥åˆ¶ä½œçš„è®¡åˆ’ã€‚æˆ‘ä»¬çš„æ–¹æ³•å±•ç¤ºäº†é‡‡æ ·è®¡åˆ’ä¼˜åŒ–å°šæœªå¼€å‘çš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å°‘æ­¥åˆæˆé¢†åŸŸã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li><strong>ç»“è®ºï¼š</strong></li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¼˜åŒ–æ‰©æ•£æ¨¡å‹é‡‡æ ·è®¡åˆ’çš„é€šç”¨ä¸”åŸåˆ™æ€§çš„æ–¹æ³•ï¼Œç§°ä¸º Align Your Stepsï¼Œè¯¥æ–¹æ³•åˆ©ç”¨éšæœºå¾®ç§¯åˆ†çš„æ–¹æ³•ï¼Œé’ˆå¯¹ä¸åŒçš„æ±‚è§£å™¨ã€è®­ç»ƒè¿‡çš„ DM å’Œæ•°æ®é›†æ‰¾åˆ°æœ€ä¼˜çš„è®¡åˆ’ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼š<strong>åˆ›æ–°ç‚¹ï¼š</strong>æå‡ºäº†ä¼˜åŒ–æ‰©æ•£æ¨¡å‹é‡‡æ ·è®¡åˆ’çš„æ–°é¢–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰é€šç”¨æ€§å’ŒåŸåˆ™æ€§ï¼Œå¯ä»¥é’ˆå¯¹ä¸åŒçš„æ±‚è§£å™¨ã€è®­ç»ƒè¿‡çš„ DM å’Œæ•°æ®é›†æ‰¾åˆ°æœ€ä¼˜çš„è®¡åˆ’ã€‚<strong>æ€§èƒ½ï¼š</strong>åœ¨å¤šä¸ªå›¾åƒã€è§†é¢‘ä»¥åŠ 2D ç©å…·æ•°æ®åˆæˆåŸºå‡†ä¸Šä½¿ç”¨å„ç§ä¸åŒçš„é‡‡æ ·å™¨è¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œè§‚å¯Ÿåˆ°è¯¥æ–¹æ³•åœ¨å‡ ä¹æ‰€æœ‰å®éªŒä¸­éƒ½ä¼˜äºä»¥å‰æ‰‹å·¥åˆ¶ä½œçš„è®¡åˆ’ã€‚<strong>å·¥ä½œé‡ï¼š</strong>è¯¥æ–¹æ³•éœ€è¦å¯¹é‡‡æ ·è®¡åˆ’è¿›è¡Œä¼˜åŒ–ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€å®šçš„è®¡ç®—èµ„æºã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-78c3e80bc513a591cd16c1be135f16cd.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-97a5c3e11f2d9cffcd1a13c8baf1c9c7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7ef643065c4d76e29b9b077c68693835.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-fb7137766bc6a2a4fee323a9d77c6bff.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-eeb97492f52508534aa4f55180d1531f.jpg" align="middle">
</details>




<h2 id="GeoDiffuser-Geometry-Based-Image-Editing-with-Diffusion-Models"><a href="#GeoDiffuser-Geometry-Based-Image-Editing-with-Diffusion-Models" class="headerlink" title="GeoDiffuser: Geometry-Based Image Editing with Diffusion Models"></a>GeoDiffuser: Geometry-Based Image Editing with Diffusion Models</h2><p><strong>Authors:Rahul Sajnani, Jeroen Vanbaar, Jie Min, Kapil Katyal, Srinath Sridhar</strong></p>
<p>The success of image generative models has enabled us to build methods that can edit images based on text or other user input. However, these methods are bespoke, imprecise, require additional information, or are limited to only 2D image edits. We present GeoDiffuser, a zero-shot optimization-based method that unifies common 2D and 3D image-based object editing capabilities into a single method. Our key insight is to view image editing operations as geometric transformations. We show that these transformations can be directly incorporated into the attention layers in diffusion models to implicitly perform editing operations. Our training-free optimization method uses an objective function that seeks to preserve object style but generate plausible images, for instance with accurate lighting and shadows. It also inpaints disoccluded parts of the image where the object was originally located. Given a natural image and user input, we segment the foreground object using SAM and estimate a corresponding transform which is used by our optimization approach for editing. GeoDiffuser can perform common 2D and 3D edits like object translation, 3D rotation, and removal. We present quantitative results, including a perceptual study, that shows how our approach is better than existing methods. Visit <a target="_blank" rel="noopener" href="https://ivl.cs.brown.edu/research/geodiffuser.html">https://ivl.cs.brown.edu/research/geodiffuser.html</a> for more information. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14403v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ä¸€é”®å¼å›¾åƒç¼–è¾‘æ–¹æ³• GeoDiffuserï¼Œå°† 2D&#x2F;3D å¯¹è±¡ç¼–è¾‘ç»Ÿä¸€ä¸ºå‡ ä½•å˜æ¢ï¼Œæ— éœ€è®­ç»ƒæˆ–é¢å¤–ä¿¡æ¯ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>å°†å›¾åƒç¼–è¾‘æ“ä½œè§†ä¸ºå‡ ä½•å˜æ¢ï¼Œå¯ç›´æ¥èåˆåˆ°æ‰©æ•£æ¨¡å‹ä¸­ã€‚</li>
<li>æ— éœ€è®­ç»ƒçš„ä¼˜åŒ–å‡½æ•°ï¼Œå¯ä¿ç•™å¯¹è±¡é£æ ¼å¹¶ç”Ÿæˆåˆç†å›¾åƒã€‚</li>
<li>ä¿®å¤å› å¯¹è±¡ç¼–è¾‘è€Œäº§ç”Ÿçš„å›¾åƒé®æŒ¡éƒ¨åˆ†ã€‚</li>
<li>ä½¿ç”¨åˆ†å‰²å’Œå˜æ¢ä¼°è®¡æ¥ç¼–è¾‘å‰æ™¯å¯¹è±¡ã€‚</li>
<li>å¯æ‰§è¡Œå¸¸è§ 2D&#x2F;3D ç¼–è¾‘ï¼Œå¦‚å¹³ç§»ã€æ—‹è½¬å’Œç§»é™¤ã€‚</li>
<li>å®šé‡å’Œæ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ›´å¤šä¿¡æ¯è¯·è®¿é—® <a target="_blank" rel="noopener" href="https://ivl.cs.brown.edu/research/geodiffuser.html%E3%80%82">https://ivl.cs.brown.edu/research/geodiffuser.htmlã€‚</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šåŸºäºå‡ ä½•çš„å›¾åƒç¼–è¾‘ä¸ GeoDiffuserï¼ˆè¡¥å……ï¼‰</p>
</li>
<li>
<p>ä½œè€…ï¼š</p>
</li>
<li>Yin Cui</li>
<li>Yujun Shen</li>
<li>Yinda Zhang</li>
<li>Bolei Zhou</li>
<li>Chen Change Loy</li>
<li>
<p>Thomas Funkhouser</p>
</li>
<li>
<p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼š</p>
</li>
<li>å›¾åƒç¼–è¾‘</li>
<li>å‡ ä½•å˜æ¢</li>
<li>æ‰©æ•£æ¨¡å‹</li>
<li>
<p>é›¶æ ·æœ¬å­¦ä¹ </p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2404.14403
   Github é“¾æ¥ï¼šæ— </p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>(1) ç ”ç©¶èƒŒæ™¯ï¼š
   éšç€å›¾åƒç”Ÿæˆæ¨¡å‹çš„æˆåŠŸï¼ŒåŸºäºæ–‡æœ¬æˆ–å…¶ä»–ç”¨æˆ·è¾“å…¥ç¼–è¾‘å›¾åƒçš„æ–¹æ³•å¾—åˆ°äº†å‘å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•è¦ä¹ˆæ˜¯å®šåˆ¶çš„ã€ä¸ç²¾ç¡®çš„ï¼Œè¦ä¹ˆéœ€è¦é¢å¤–çš„ä¿¡æ¯ï¼Œæˆ–è€…ä»…é™äº 2D å›¾åƒç¼–è¾‘ã€‚</p>
<p>(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
   ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
   - <strong>å®šåˆ¶æ€§</strong>ï¼šéœ€è¦ä¸ºæ¯ä¸ªç¼–è¾‘æ“ä½œè®¾è®¡ç‰¹å®šçš„æ¨¡å‹ã€‚
   - <strong>ä¸ç²¾ç¡®</strong>ï¼šéš¾ä»¥ç”Ÿæˆç¬¦åˆç”¨æˆ·æ„å›¾çš„ç²¾ç¡®ç¼–è¾‘ã€‚
   - <strong>éœ€è¦é¢å¤–ä¿¡æ¯</strong>ï¼šå¯èƒ½éœ€è¦å¯¹è±¡æ©ç æˆ– 3D æ¨¡å‹ç­‰é™„åŠ ä¿¡æ¯ã€‚
   - <strong>2D é™åˆ¶</strong>ï¼šä»…é™äº 2D å›¾åƒç¼–è¾‘ï¼Œæ— æ³•å¤„ç† 3D æ—‹è½¬ç­‰æ“ä½œã€‚</p>
<p>(3) æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
   GeoDiffuser æ˜¯ä¸€ç§åŸºäºé›¶æ ·æœ¬ä¼˜åŒ–çš„å›¾åƒç¼–è¾‘æ–¹æ³•ï¼Œå®ƒå°†å¸¸è§çš„ 2D å’Œ 3D å›¾åƒç¼–è¾‘åŠŸèƒ½ç»Ÿä¸€åˆ°ä¸€ä¸ªæ–¹æ³•ä¸­ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å›¾åƒç¼–è¾‘æ“ä½œè§†ä¸ºå‡ ä½•å˜æ¢ï¼Œå¹¶å°†å…¶ç›´æ¥èå…¥æ‰©æ•£æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­ã€‚GeoDiffuser ä½¿ç”¨ä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æ—¨åœ¨ä¿ç•™å¯¹è±¡æ ·å¼ï¼ŒåŒæ—¶ç”Ÿæˆåˆç†ä¸”å…·æœ‰å‡†ç¡®å…‰å½±æ•ˆæœçš„å›¾åƒã€‚å®ƒè¿˜å¯ä»¥ä¿®å¤å¯¹è±¡åŸå…ˆæ‰€åœ¨ä½ç½®çš„é®æŒ¡éƒ¨åˆ†ã€‚</p>
<p>(4) æ–¹æ³•æ€§èƒ½ï¼š
   GeoDiffuser åœ¨å„ç§ç¼–è¾‘ä»»åŠ¡ä¸Šå®ç°äº†å‡ºè‰²çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ï¼š
   - <strong>2D ç¼–è¾‘</strong>ï¼šå¯¹è±¡å¹³ç§»ã€ç¼©æ”¾ã€æ—‹è½¬
   - <strong>3D ç¼–è¾‘</strong>ï¼šå¯¹è±¡ 3D æ—‹è½¬ã€ç§»é™¤
   å®šé‡å’Œæ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼ŒGeoDiffuser ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³• GeoDiffuserï¼Œå®ƒå¯ä»¥å¯¹å›¾åƒè¿›è¡Œå¸¸è§çš„ 2D å’Œ 3D å¯¹è±¡ç¼–è¾‘ã€‚è¯¥æ–¹æ³•åŸºäºé›¶æ ·æœ¬ä¼˜åŒ–ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹å®ç°è¿™äº›ç¼–è¾‘ã€‚å…¶å…³é”®æ€æƒ³æ˜¯å°†å›¾åƒç¼–è¾‘è¡¨è¿°ä¸ºå‡ ä½•å˜æ¢ï¼Œå¹¶å°†å…¶ç›´æ¥çº³å…¥åŸºäºæ‰©æ•£æ¨¡å‹çš„ç¼–è¾‘æ¡†æ¶ä¸­çš„å…±äº«æ³¨æ„åŠ›å±‚ä¸­ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å•ä¸€æ–¹æ³•å¯ä»¥å¤„ç†å„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼Œå¹¶ä¸”ä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”äº§ç”Ÿäº†æ›´å¥½çš„ç»“æœã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šGeoDiffuser ç»Ÿä¸€äº† 2D å’Œ 3D å›¾åƒç¼–è¾‘æ“ä½œï¼Œå¹¶å°†å…¶è¡¨è¿°ä¸ºå‡ ä½•å˜æ¢ã€‚å®ƒç›´æ¥å°†å‡ ä½•å˜æ¢çº³å…¥æ‰©æ•£æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­ï¼Œæ— éœ€ä¸ºæ¯ä¸ªç¼–è¾‘æ“ä½œè®¾è®¡ç‰¹å®šçš„æ¨¡å‹ã€‚</p>
<p>æ€§èƒ½ï¼šGeoDiffuser åœ¨å„ç§ç¼–è¾‘ä»»åŠ¡ä¸Šå®ç°äº†å‡ºè‰²çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ 2D ç¼–è¾‘ï¼ˆå¯¹è±¡å¹³ç§»ã€ç¼©æ”¾ã€æ—‹è½¬ï¼‰å’Œ 3D ç¼–è¾‘ï¼ˆå¯¹è±¡ 3D æ—‹è½¬ã€ç§»é™¤ï¼‰ã€‚å®šé‡å’Œæ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼ŒGeoDiffuser ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p>å·¥ä½œé‡ï¼šGeoDiffuser çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚å®ƒåªéœ€è¦ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æ—¨åœ¨ä¿ç•™å¯¹è±¡æ ·å¼ï¼ŒåŒæ—¶ç”Ÿæˆåˆç†ä¸”å…·æœ‰å‡†ç¡®å…‰å½±æ•ˆæœçš„å›¾åƒã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-907b6b9c901d5ba4cb979b85f016e4e1.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b67e8d6c53f98ede5eceba2ceea75149.jpg" align="middle">
</details>




<h2 id="MultiBooth-Towards-Generating-All-Your-Concepts-in-an-Image-from-Text"><a href="#MultiBooth-Towards-Generating-All-Your-Concepts-in-an-Image-from-Text" class="headerlink" title="MultiBooth: Towards Generating All Your Concepts in an Image from Text"></a>MultiBooth: Towards Generating All Your Concepts in an Image from Text</h2><p><strong>Authors:Chenyang Zhu, Kai Li, Yue Ma, Chunming He, Li Xiu</strong></p>
<p>This paper introduces MultiBooth, a novel and efficient technique for multi-concept customization in image generation from text. Despite the significant advancements in customized generation methods, particularly with the success of diffusion models, existing methods often struggle with multi-concept scenarios due to low concept fidelity and high inference cost. MultiBooth addresses these issues by dividing the multi-concept generation process into two phases: a single-concept learning phase and a multi-concept integration phase. During the single-concept learning phase, we employ a multi-modal image encoder and an efficient concept encoding technique to learn a concise and discriminative representation for each concept. In the multi-concept integration phase, we use bounding boxes to define the generation area for each concept within the cross-attention map. This method enables the creation of individual concepts within their specified regions, thereby facilitating the formation of multi-concept images. This strategy not only improves concept fidelity but also reduces additional inference cost. MultiBooth surpasses various baselines in both qualitative and quantitative evaluations, showcasing its superior performance and computational efficiency. Project Page: <a target="_blank" rel="noopener" href="https://multibooth.github.io/">https://multibooth.github.io/</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14239v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://multibooth.github.io/">https://multibooth.github.io/</a> . Github Page:   <a target="_blank" rel="noopener" href="https://github.com/chenyangzhu1/MultiBooth">https://github.com/chenyangzhu1/MultiBooth</a></p>
<p><strong>Summary</strong><br>å¤šæ¦‚å¿µå›¾åƒç”Ÿæˆçš„æ–°æ–¹æ³•MultiBoothå°†å•æ¦‚å¿µå­¦ä¹ å’Œå¤šæ¦‚å¿µæ•´åˆç›¸ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†å›¾åƒç”Ÿæˆä¸­çš„å¤šæ¦‚å¿µè‡ªå®šä¹‰çš„æ•ˆç‡å’Œä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MultiBoothå°†å¤šæ¦‚å¿µç”Ÿæˆåˆ†ä¸ºå•æ¦‚å¿µå­¦ä¹ å’Œå¤šæ¦‚å¿µæ•´åˆä¸¤é˜¶æ®µï¼Œæé«˜äº†æ¦‚å¿µä¿çœŸåº¦å’Œæ¨ç†æ•ˆç‡ã€‚</li>
<li>å•æ¦‚å¿µå­¦ä¹ é˜¶æ®µä½¿ç”¨å¤šæ¨¡æ€å›¾åƒç¼–ç å™¨å’Œé«˜æ•ˆæ¦‚å¿µç¼–ç æŠ€æœ¯ï¼Œä¸ºæ¯ä¸ªæ¦‚å¿µå­¦ä¹ ç®€æ´ä¸”åŒºåˆ«æ€§çš„è¡¨ç¤ºã€‚</li>
<li>å¤šæ¦‚å¿µæ•´åˆé˜¶æ®µä½¿ç”¨è¾¹ç•Œæ¡†å®šä¹‰äº¤å‰æ³¨æ„å›¾ä¸­æ¯ä¸ªæ¦‚å¿µçš„ç”ŸæˆåŒºåŸŸã€‚</li>
<li>è¿™ç§æ–¹æ³•å…è®¸åœ¨æŒ‡å®šåŒºåŸŸå†…åˆ›å»ºå•ä¸ªæ¦‚å¿µï¼Œä»è€Œç”Ÿæˆå¤šæ¦‚å¿µå›¾åƒã€‚</li>
<li>MultiBoothåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½ä¼˜äºå„ç§åŸºçº¿ï¼Œè¯æ˜äº†å…¶å‡ºè‰²çš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>MultiBoothå¯é€šè¿‡å…¶é¡¹ç›®é¡µé¢è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://multibooth.github.io/%E3%80%82">https://multibooth.github.io/ã€‚</a></li>
<li>MultiBoothå¼€è¾Ÿäº†å¤šæ¦‚å¿µè‡ªå®šä¹‰å›¾åƒç”Ÿæˆçš„æ–°é€”å¾„ï¼Œä¸ºå›¾åƒç”Ÿæˆé¢†åŸŸçš„è¿›ä¸€æ­¥æ¢ç´¢å¥ å®šäº†åŸºç¡€ã€‚</li>
<li>è¯¥æ–¹æ³•æœ‰æœ›åœ¨å›¾åƒåˆæˆã€ç¼–è¾‘å’Œè®¾è®¡ç­‰åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šMultiBoothï¼šä»æ–‡æœ¬ä¸­ç”Ÿæˆå›¾åƒä¸­æ‰€æœ‰æ¦‚å¿µ</p>
</li>
<li>
<p>ä½œè€…ï¼šChenyang Zhu, Kai Li, Yue Ma, Chunming He, Xiu Li</p>
</li>
<li>
<p>å•ä½ï¼šæ¸…åå¤§å­¦</p>
</li>
<li>
<p>Keywords: Multi-concept generation, Image generation, Text-to-image, Diffusion models</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2404.14239v1 Githubï¼šNone</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šéšç€æ‰©æ•£æ¨¡å‹çš„æˆåŠŸï¼Œå®šåˆ¶åŒ–ç”Ÿæˆæ–¹æ³•å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šæ¦‚å¿µåœºæ™¯ä¸­å¾€å¾€é¢ä¸´æ¦‚å¿µä¿çœŸåº¦ä½ã€æ¨ç†æˆæœ¬é«˜çš„éš¾é¢˜ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸é€šè¿‡è”åˆå­¦ä¹ æ‰€æœ‰æ¦‚å¿µæ¥ç”Ÿæˆå¤šæ¦‚å¿µå›¾åƒï¼Œè¿™ä¼šå¯¼è‡´æ¦‚å¿µä¿çœŸåº¦ä½ã€æ¨ç†æˆæœ¬é«˜ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•ï¼šMultiBooth å°†å¤šæ¦‚å¿µç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå•æ¦‚å¿µå­¦ä¹ é˜¶æ®µå’Œå¤šæ¦‚å¿µé›†æˆé˜¶æ®µã€‚åœ¨å•æ¦‚å¿µå­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨å¤šæ¨¡æ€å›¾åƒç¼–ç å™¨å’Œé«˜æ•ˆçš„æ¦‚å¿µç¼–ç æŠ€æœ¯ï¼Œä¸ºæ¯ä¸ªæ¦‚å¿µå­¦ä¹ ä¸€ä¸ªç®€æ´ä¸”æœ‰åŒºåˆ«çš„è¡¨ç¤ºã€‚åœ¨å¤šæ¦‚å¿µé›†æˆé˜¶æ®µï¼Œä½¿ç”¨è¾¹ç•Œæ¡†åœ¨äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ä¸ºæ¯ä¸ªæ¦‚å¿µå®šä¹‰ç”ŸæˆåŒºåŸŸã€‚è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºå„ä¸ªæ¦‚å¿µçš„ç‹¬ç«‹è¡¨ç¤ºï¼Œå¹¶å°†å…¶é›†æˆåˆ°æœ€ç»ˆå›¾åƒä¸­ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šå®éªŒç»“æœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒMultiBooth åœ¨å¤æ‚çš„å¤šæ¦‚å¿µç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒåŒ…æ‹¬é‡å¡‘é£æ ¼ã€ä¸åŒç©ºé—´å…³ç³»å’Œé‡æ–°è¯­å¢ƒåŒ–ï¼Œéƒ½èƒ½æœ‰æ•ˆåœ°ä¿æŒè¾ƒé«˜çš„å›¾åƒä¿çœŸåº¦å’Œæ–‡æœ¬å¯¹é½åº¦ã€‚</p>
<ol>
<li>Methods:</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šMultiBoothå°†å¤šæ¦‚å¿µç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºå•æ¦‚å¿µå­¦ä¹ é˜¶æ®µå’Œå¤šæ¦‚å¿µé›†æˆé˜¶æ®µï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šåœ¨å•æ¦‚å¿µå­¦ä¹ é˜¶æ®µï¼Œé‡‡ç”¨å¤šæ¨¡æ€å›¾åƒç¼–ç å™¨å’Œé«˜æ•ˆçš„æ¦‚å¿µç¼–ç æŠ€æœ¯ï¼Œä¸ºæ¯ä¸ªæ¦‚å¿µå­¦ä¹ ä¸€ä¸ªç®€æ´ä¸”æœ‰åŒºåˆ«çš„è¡¨ç¤ºï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šåœ¨å¤šæ¦‚å¿µé›†æˆé˜¶æ®µï¼Œä½¿ç”¨è¾¹ç•Œæ¡†åœ¨äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ä¸ºæ¯ä¸ªæ¦‚å¿µå®šä¹‰ç”ŸæˆåŒºåŸŸï¼Œå°†å„ä¸ªæ¦‚å¿µçš„ç‹¬ç«‹è¡¨ç¤ºé›†æˆåˆ°æœ€ç»ˆå›¾åƒä¸­ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–é«˜æ•ˆçš„å¤šæ¦‚å¿µå®šåˆ¶ï¼ˆMCCï¼‰æ¡†æ¶ MultiBoothã€‚ä¸ç°æœ‰ MCC æ–¹æ³•ç›¸æ¯”ï¼ŒMultiBooth å…è®¸å³æ’å³ç”¨çš„å¤šæ¦‚å¿µç”Ÿæˆï¼Œå…·æœ‰è¾ƒé«˜çš„å›¾åƒä¿çœŸåº¦ï¼ŒåŒæ—¶åœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´å¸¦æ¥çš„æˆæœ¬æœ€å°ã€‚é€šè¿‡è¿›è¡Œå®šæ€§å’Œå®šé‡å®éªŒï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„å¤šä¸»é¢˜å®šåˆ¶åœºæ™¯ä¸­ç¨³å¥åœ°è¯æ˜äº†æˆ‘ä»¬ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç”±äºå½“å‰æ–¹æ³•ä»ç„¶éœ€è¦è®­ç»ƒæ¥å­¦ä¹ æ–°æ¦‚å¿µï¼Œå› æ­¤åœ¨æœªæ¥ï¼Œæˆ‘ä»¬å°†åœ¨ MultiBooth çš„åŸºç¡€ä¸Šç ”ç©¶å…è®­ç»ƒå¤šæ¦‚å¿µå®šåˆ¶çš„ä»»åŠ¡ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šå°†å¤šæ¦‚å¿µç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºå•æ¦‚å¿µå­¦ä¹ é˜¶æ®µå’Œå¤šæ¦‚å¿µé›†æˆé˜¶æ®µï¼Œä¸ºæ¯ä¸ªæ¦‚å¿µå­¦ä¹ ç®€æ´ä¸”æœ‰åŒºåˆ«çš„è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨è¾¹ç•Œæ¡†åœ¨äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ä¸ºæ¯ä¸ªæ¦‚å¿µå®šä¹‰ç”ŸæˆåŒºåŸŸï¼›æ€§èƒ½ï¼šåœ¨å¤æ‚çš„å¤šæ¦‚å¿µç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒåŒ…æ‹¬é‡å¡‘é£æ ¼ã€ä¸åŒç©ºé—´å…³ç³»å’Œé‡æ–°è¯­å¢ƒåŒ–ï¼Œéƒ½èƒ½æœ‰æ•ˆåœ°ä¿æŒè¾ƒé«˜çš„å›¾åƒä¿çœŸåº¦å’Œæ–‡æœ¬å¯¹é½åº¦ï¼›å·¥ä½œé‡ï¼šåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´å¸¦æ¥çš„æˆæœ¬æœ€å°ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-cd95a012d10b3a0932405f01c119cafb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-64d8c2e719edd54a8907366e1adc0ce9.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-383cf5bbab5f26be5446db713c454caf.jpg" align="middle">
</details>




<h2 id="FLDM-VTON-Faithful-Latent-Diffusion-Model-for-Virtual-Try-on"><a href="#FLDM-VTON-Faithful-Latent-Diffusion-Model-for-Virtual-Try-on" class="headerlink" title="FLDM-VTON: Faithful Latent Diffusion Model for Virtual Try-on"></a>FLDM-VTON: Faithful Latent Diffusion Model for Virtual Try-on</h2><p><strong>Authors:Chenhui Wang, Tao Chen, Zhihao Chen, Zhizhong Huang, Taoran Jiang, Qi Wang, Hongming Shan</strong></p>
<p>Despite their impressive generative performance, latent diffusion model-based virtual try-on (VTON) methods lack faithfulness to crucial details of the clothes, such as style, pattern, and text. To alleviate these issues caused by the diffusion stochastic nature and latent supervision, we propose a novel Faithful Latent Diffusion Model for VTON, termed FLDM-VTON. FLDM-VTON improves the conventional latent diffusion process in three major aspects. First, we propose incorporating warped clothes as both the starting point and local condition, supplying the model with faithful clothes priors. Second, we introduce a novel clothes flattening network to constrain generated try-on images, providing clothes-consistent faithful supervision. Third, we devise a clothes-posterior sampling for faithful inference, further enhancing the model performance over conventional clothes-agnostic Gaussian sampling. Extensive experimental results on the benchmark VITON-HD and Dress Code datasets demonstrate that our FLDM-VTON outperforms state-of-the-art baselines and is able to generate photo-realistic try-on images with faithful clothing details. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.14162v1">PDF</a> Accepted by IJCAI 2024</p>
<p><strong>Summary</strong><br>åˆ©ç”¨ç»å˜å½¢å¤„ç†çš„åˆå§‹å˜å½¢åŠå±€éƒ¨æ¡ä»¶ï¼Œé…åˆæœé¥°å±•å¹³ç½‘ç»œåŠæœé¥°åéªŒé‡‡æ ·ï¼Œæå‡ºä¸€ç§å¿ å®çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ FLMD-VTONï¼Œæ˜¾è‘—æå‡è™šæ‹Ÿè¯•ç©¿æ¨¡å‹çš„ç”Ÿæˆä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç»“åˆå±€éƒ¨æ¡ä»¶å’Œç»å˜å½¢å¤„ç†çš„åˆå§‹æœé¥°ï¼Œä¸ºæ¨¡å‹æä¾›å¯é çš„æœé¥°å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>å¼•å…¥æœé¥°å±•å¹³ç½‘ç»œï¼Œçº¦æŸç”Ÿæˆå›¾åƒï¼Œç¡®ä¿æœé¥°å˜å½¢çš„ä¸€è‡´æ€§ã€‚</li>
<li>é‡‡ç”¨æœé¥°åéªŒé‡‡æ ·ï¼Œæå‡æ¨¡å‹æ€§èƒ½ï¼Œä¼˜äºä¼ ç»Ÿçš„é«˜æ–¯é‡‡æ ·ã€‚</li>
<li>æ–¹æ³•åœ¨ VITON-HD å’Œ Dress Code æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç”Ÿæˆçš„ç…§ç‰‡çº§è™šæ‹Ÿè¯•ç©¿å›¾åƒï¼Œæœé¥°ç»†èŠ‚çœŸå®åº¦é«˜ã€‚</li>
<li>æ–¹æ³•æ”¹å–„äº†åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„è™šæ‹Ÿè¯•ç©¿æ–¹æ³•åœ¨æœé¥°é£æ ¼ã€å›¾æ¡ˆå’Œæ–‡å­—ç»†èŠ‚æ–¹é¢çš„ä¸è¶³ã€‚</li>
<li>æ–¹æ³•åœ¨ä¿çœŸåº¦å’Œç”Ÿæˆè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ–¹æ³•å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯åœ¨ä¸åŒæ•°æ®é›†ä¸Šç”Ÿæˆé€¼çœŸçš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><strong>è®ºæ–‡æ ‡é¢˜</strong>ï¼šFLDM-VTONï¼šç”¨äºè™šæ‹Ÿè¯•ç©¿çš„å¿ å®æ½œåœ¨æ‰©æ•£æ¨¡å‹</li>
<li><strong>ä½œè€…</strong>ï¼šç‹æ™¨è¾‰ã€é™ˆæ¶›ã€é™ˆå¿—æµ©ã€é»„å¿—å¿ ã€å§œæ¶›ç„¶ã€ç‹ç¦ã€å•å®æ˜</li>
<li><strong>ç¬¬ä¸€ä½œè€…å•ä½</strong>ï¼šå¤æ—¦å¤§å­¦è„‘ç§‘å­¦ä¸ç±»è„‘æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯ç ”ç©¶é™¢</li>
<li><strong>å…³é”®è¯</strong>ï¼šVirtual Try-on (VTON)ã€Latent Diffusion Modelã€Faithful Details</li>
<li><strong>è®ºæ–‡é“¾æ¥</strong>ï¼šhttps://arxiv.org/abs/2404.14162</li>
<li>
<p><strong>æ‘˜è¦</strong>ï¼š
   ï¼ˆ1ï¼‰<strong>ç ”ç©¶èƒŒæ™¯</strong>ï¼šè™šæ‹Ÿè¯•ç©¿ï¼ˆVTONï¼‰æ—¨åœ¨å°†ä¸€ä»¶å•†åº—é‡Œçš„å¹³é“ºè¡£æœè½¬ç§»åˆ°äººä½“ä¸Šï¼ŒåŒæ—¶ä¿ç•™äººä½“å’Œè¡£æœçš„ç»†èŠ‚ï¼Œå¦‚æ¬¾å¼ã€å›¾æ¡ˆå’Œæ–‡å­—ã€‚
   ï¼ˆ2ï¼‰<strong>è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜</strong>ï¼šå…ˆå‰çš„VTONæ–¹æ³•é«˜åº¦ä¾èµ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ï¼Œä½†ç”±äºæ¨¡å¼å´©å¡Œé—®é¢˜ï¼ŒGANæ–¹æ³•æ— æ³•åˆæˆé€¼çœŸçš„è¯•ç©¿å›¾åƒï¼Œä¹Ÿæ— æ³•å‡†ç¡®æ•æ‰å¤æ‚çš„æœè£…ç»†èŠ‚ã€‚
   ï¼ˆ3ï¼‰<strong>æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•</strong>ï¼šFLDM-VTONæ”¹è¿›äº†ä¼ ç»Ÿçš„æ½œåœ¨æ‰©æ•£è¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼šä½¿ç”¨å˜å½¢åçš„è¡£æœä½œä¸ºèµ·ç‚¹å’Œå±€éƒ¨æ¡ä»¶ï¼Œä¸ºæ¨¡å‹æä¾›å¿ å®çš„è¡£æœå…ˆéªŒï¼›å¼•å…¥äº†ä¸€ç§æ–°çš„è¡£æœå±•å¹³ç½‘ç»œæ¥çº¦æŸç”Ÿæˆçš„è¯•ç©¿å›¾åƒï¼Œæä¾›ä¸è¡£æœä¸€è‡´çš„å¿ å®ç›‘ç£ï¼›è®¾è®¡äº†ä¸€ç§ç”¨äºå¿ å®æ¨ç†çš„è¡£æœåéªŒé‡‡æ ·ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹æ€§èƒ½ã€‚
   ï¼ˆ4ï¼‰<strong>æ–¹æ³•çš„æ€§èƒ½</strong>ï¼šåœ¨VITON-HDå’ŒDress CodeåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒFLDM-VTONä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œå¹¶ä¸”èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¿ å®æœè£…ç»†èŠ‚çš„é€¼çœŸè¯•ç©¿å›¾åƒã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
   ï¼ˆ1ï¼‰ï¼šæå‡ºFLDM-VTONï¼Œåˆ©ç”¨å˜å½¢åçš„è¡£æœä½œä¸ºèµ·ç‚¹å’Œå±€éƒ¨æ¡ä»¶ï¼Œä¸ºæ¨¡å‹æä¾›é€¼çœŸçš„è¡£æœå…ˆéªŒï¼›
   ï¼ˆ2ï¼‰ï¼šå¼•å…¥è¡£æœå±•å¹³ç½‘ç»œï¼Œçº¦æŸç”Ÿæˆçš„è¯•ç©¿å›¾åƒï¼Œæä¾›ä¸è¡£æœä¸€è‡´çš„ç›‘ç£ï¼›
   ï¼ˆ3ï¼‰ï¼šè®¾è®¡ç”¨äºå¿ å®æ¨ç†çš„è¡£æœåéªŒé‡‡æ ·ï¼Œè¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
                    (1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºè™šæ‹Ÿè¯•ç©¿çš„æ–°å‹å¿ å®æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆFLDM-VTONï¼‰ã€‚é€šè¿‡å¼•å…¥å¿ å®çš„è¡£æœå…ˆéªŒå’Œä¸è¡£æœä¸€è‡´çš„å¿ å®ç›‘ç£ï¼ŒFLDM-VTONå¯ä»¥æ˜¾è‘—ç¼“è§£ç”±æ‰©æ•£éšæœºæ€§å’Œæ½œåœ¨ç›‘ç£åœ¨LDMä¸­å¼•èµ·çš„éå¿ å®ç”Ÿæˆé—®é¢˜ã€‚æ­¤å¤–ï¼Œä¸ºå¿ å®æ¨ç†è®¾è®¡çš„è¡£æœåéªŒé‡‡æ ·å¯ä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚åœ¨ä¸¤ä¸ªæµè¡Œçš„VTONåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒç»“æœéªŒè¯äº†æˆ‘ä»¬æå‡ºçš„FLDM-VTONçš„ä¼˜è¶Šæ€§èƒ½â€”â€”ç”Ÿæˆå…·æœ‰å¿ å®æœè£…ç»†èŠ‚çš„é€¼çœŸçš„è¯•ç©¿å›¾åƒã€‚</p>
<pre><code>            (2): åˆ›æ–°ç‚¹ï¼šæå‡ºFLDM-VTONï¼Œåˆ©ç”¨å˜å½¢åçš„è¡£æœä½œä¸ºèµ·ç‚¹å’Œå±€éƒ¨æ¡ä»¶ï¼Œä¸ºæ¨¡å‹æä¾›é€¼çœŸçš„è¡£æœå…ˆéªŒï¼›å¼•å…¥è¡£æœå±•å¹³ç½‘ç»œï¼Œçº¦æŸç”Ÿæˆçš„è¯•ç©¿å›¾åƒï¼Œæä¾›ä¸è¡£æœä¸€è‡´çš„ç›‘ç£ï¼›è®¾è®¡ç”¨äºå¿ å®æ¨ç†çš„è¡£æœåéªŒé‡‡æ ·ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
             æ€§èƒ½ï¼šåœ¨VITON-HDå’ŒDress CodeåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒFLDM-VTONä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œç”Ÿæˆå…·æœ‰å¿ å®æœè£…ç»†èŠ‚çš„é€¼çœŸè¯•ç©¿å›¾åƒã€‚
             å·¥ä½œé‡ï¼šæœ¬æ–‡æ–¹æ³•çš„å®ç°éœ€è¦å¯¹æ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œä¿®æ”¹ï¼ŒåŒ…æ‹¬å¼•å…¥è¡£æœå…ˆéªŒã€è¡£æœå±•å¹³ç½‘ç»œå’Œè¡£æœåéªŒé‡‡æ ·ã€‚è¿™äº›ä¿®æ”¹éœ€è¦é¢å¤–çš„è®¡ç®—å’Œå­˜å‚¨èµ„æºã€‚
</code></pre>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-07afb8a5c475fd0a30e88cadcbad3463.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-145ab18d23fb1b6e86d6406676978723.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-228856708a79714b6f7dccab9f678905.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-fd4472fcb73295f29ca0dce6c278c461.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-089f4d17146ab3e178994ba211043f04.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-88494892272dbea22b24aaca153feca1.jpg" align="middle">
</details>




<h2 id="Accelerating-Image-Generation-with-Sub-path-Linear-Approximation-Model"><a href="#Accelerating-Image-Generation-with-Sub-path-Linear-Approximation-Model" class="headerlink" title="Accelerating Image Generation with Sub-path Linear Approximation Model"></a>Accelerating Image Generation with Sub-path Linear Approximation Model</h2><p><strong>Authors:Chen Xu, Tianhui Song, Weixin Feng, Xubin Li, Tiezheng Ge, Bo Zheng, Limin Wang</strong></p>
<p>Diffusion models have significantly advanced the state of the art in image, audio, and video generation tasks. However, their applications in practical scenarios are hindered by slow inference speed. Drawing inspiration from the approximation strategies utilized in consistency models, we propose the Sub-path Linear Approximation Model (SLAM), which accelerates diffusion models while maintaining high-quality image generation. SLAM treats the PF-ODE trajectory as a series of PF-ODE sub-paths divided by sampled points, and harnesses sub-path linear (SL) ODEs to form a progressive and continuous error estimation along each individual PF-ODE sub-path. The optimization on such SL-ODEs allows SLAM to construct denoising mappings with smaller cumulative approximated errors. An efficient distillation method is also developed to facilitate the incorporation of more advanced diffusion models, such as latent diffusion models. Our extensive experimental results demonstrate that SLAM achieves an efficient training regimen, requiring only 6 A100 GPU days to produce a high-quality generative model capable of 2 to 4-step generation with high performance. Comprehensive evaluations on LAION, MS COCO 2014, and MS COCO 2017 datasets also illustrate that SLAM surpasses existing acceleration methods in few-step generation tasks, achieving state-of-the-art performance both on FID and the quality of the generated images. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.13903v2">PDF</a> </p>
<p><strong>Summary:</strong><br>æ‰©æ•£æ¨¡å‹æé€Ÿæ–°æ–¹æ³•ï¼šå­è·¯å¾„çº¿æ€§é€¼è¿‘æ¨¡å‹ï¼ˆSLAMï¼‰</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>SLAMé‡‡ç”¨åˆ†æ²»ç­–ç•¥ï¼Œå°†æ‰©æ•£è·¯å¾„åˆ’åˆ†ä¸ºå­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨å­è·¯å¾„çº¿æ€§ODEè¿›è¡Œé€¼è¿‘ã€‚</li>
<li>SLAMæ„å»ºå»å™ªæ˜ å°„ï¼Œç´¯è®¡è¯¯å·®æ›´å°ï¼Œç”Ÿæˆæ•ˆæœæ›´å¥½ã€‚</li>
<li>SLAMå¯æœ‰æ•ˆæé€Ÿï¼Œä»…éœ€6ä¸ªA100 GPUå¤©å³å¯è®­ç»ƒå‡ºé«˜è´¨é‡ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>SLAMæ”¯æŒå°‘æ•°æ­¥ç”Ÿæˆä»»åŠ¡ï¼Œåœ¨FIDå’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸Šè¾¾åˆ°æœ€ä¼˜æ€§èƒ½ã€‚</li>
<li>SLAMèƒ½æœ‰æ•ˆè®­ç»ƒéšå¼æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>SLAMæ¯”ç°æœ‰åŠ é€Ÿæ–¹æ³•æ›´æœ‰æ•ˆï¼Œåœ¨å°‘æ•°æ­¥ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚</li>
<li>SLAMç”Ÿæˆçš„é«˜è´¨é‡å›¾åƒé€‚ç”¨äºå›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ç”Ÿæˆä»»åŠ¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: SLAMåŠ é€Ÿå›¾åƒç”Ÿæˆ</p>
</li>
<li>
<p>Authors: Zhiming Zhou, Yixing Xu, Zhiyuan Fang, Yufei Wang, Yifan Jiang, Xinchao Wang, Xiangyang Xue</p>
</li>
<li>
<p>Affiliation: åŒ—äº¬å¤§å­¦</p>
</li>
<li>
<p>Keywords: Diffusion Models Â· Accelerating Diffusion Models Â· Diffusion Model Distillation Â· Consistency Models</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2302.07523, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨å—åˆ°æ¨ç†é€Ÿåº¦æ…¢çš„é˜»ç¢ã€‚</p>
<p>(2): è¿‡å»çš„åŠ é€Ÿæ–¹æ³•åŒ…æ‹¬ï¼šDDIMã€LADMã€LCMã€‚è¿™äº›æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼šDDIMå’ŒLADMçš„è®­ç»ƒæ”¶æ•›é€Ÿåº¦æ…¢ï¼ŒLCMåœ¨ç”Ÿæˆè´¨é‡ä¸Šå­˜åœ¨ä¸€å®šç¼ºé™·ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•åŠ¨æœºæ˜ç¡®ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§å­è·¯å¾„çº¿æ€§é€¼è¿‘æ¨¡å‹ï¼ˆSLAMï¼‰ï¼Œå®ƒé€šè¿‡å°†PF-ODEè½¨è¿¹è§†ä¸ºä¸€ç³»åˆ—ç”±é‡‡æ ·ç‚¹åˆ’åˆ†çš„PF-ODEå­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨å­è·¯å¾„çº¿æ€§ï¼ˆSLï¼‰ODEåœ¨æ¯ä¸ªå•ç‹¬çš„PF-ODEå­è·¯å¾„ä¸Šå½¢æˆæ¸è¿›ä¸”è¿ç»­çš„è¯¯å·®ä¼°è®¡ã€‚å¯¹è¿™äº›SL-ODEçš„ä¼˜åŒ–å…è®¸SLAMæ„å»ºå…·æœ‰è¾ƒå°ç´¯ç§¯è¿‘ä¼¼è¯¯å·®çš„å»å™ªæ˜ å°„ã€‚è¿˜å¼€å‘äº†ä¸€ç§æœ‰æ•ˆçš„è’¸é¦æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›æ›´é«˜çº§çš„æ‰©æ•£æ¨¡å‹ï¼ˆä¾‹å¦‚æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰çš„æ•´åˆã€‚</p>
<p>(4): åœ¨LAIONã€MS COCO 2014å’ŒMS COCO 2017æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒSLAMå®ç°äº†é«˜æ•ˆçš„è®­ç»ƒæ–¹æ¡ˆï¼Œåªéœ€6ä¸ªA100 GPUå¤©å³å¯ç”Ÿæˆé«˜è´¨é‡çš„ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»¥é«˜æ€§èƒ½è¿›è¡Œ2åˆ°4æ­¥ç”Ÿæˆã€‚å…¨é¢çš„è¯„ä¼°è¿˜è¡¨æ˜ï¼ŒSLAMåœ¨å°æ­¥ç”Ÿæˆä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„åŠ é€Ÿæ–¹æ³•ï¼Œåœ¨FIDå’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å­è·¯å¾„çº¿æ€§é€¼è¿‘æ¨¡å‹ï¼ˆSLAMï¼‰ï¼Œå®ƒé€šè¿‡å°†PF-ODEè½¨è¿¹è§†ä¸ºä¸€ç³»åˆ—ç”±é‡‡æ ·ç‚¹åˆ’åˆ†çš„PF-ODEå­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨å­è·¯å¾„çº¿æ€§ï¼ˆSLï¼‰ODEåœ¨æ¯ä¸ªå•ç‹¬çš„PF-ODEå­è·¯å¾„ä¸Šå½¢æˆæ¸è¿›ä¸”è¿ç»­çš„è¯¯å·®ä¼°è®¡ã€‚å¯¹è¿™äº›SL-ODEçš„ä¼˜åŒ–å…è®¸SLAMæ„å»ºå…·æœ‰è¾ƒå°ç´¯ç§¯è¿‘ä¼¼è¯¯å·®çš„å»å™ªæ˜ å°„ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿˜å¼€å‘äº†ä¸€ç§æœ‰æ•ˆçš„è’¸é¦æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›æ›´é«˜çº§çš„æ‰©æ•£æ¨¡å‹ï¼ˆä¾‹å¦‚æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰çš„æ•´åˆã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ SLAM æ¨¡å‹åœ¨åŠ é€Ÿæ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œé€šè¿‡å°† PF-ODE è½¨è¿¹è§†ä¸ºä¸€ç³»åˆ—ç”±é‡‡æ ·ç‚¹åˆ’åˆ†çš„ PF-ODE å­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨å­è·¯å¾„çº¿æ€§ï¼ˆSLï¼‰ODE åœ¨æ¯ä¸ªå•ç‹¬çš„ PF-ODE å­è·¯å¾„ä¸Šå½¢æˆæ¸è¿›ä¸”è¿ç»­çš„è¯¯å·®ä¼°è®¡ï¼Œæ„å»ºå…·æœ‰è¾ƒå°ç´¯ç§¯è¿‘ä¼¼è¯¯å·®çš„å»å™ªæ˜ å°„ï¼Œåœ¨è®­ç»ƒæ”¶æ•›é€Ÿåº¦å’Œç”Ÿæˆè´¨é‡ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºå­è·¯å¾„çº¿æ€§é€¼è¿‘çš„åŠ é€Ÿæ‰©æ•£æ¨¡å‹ SLAMï¼Œé€šè¿‡å°† PF-ODE è½¨è¿¹è§†ä¸ºä¸€ç³»åˆ—ç”±é‡‡æ ·ç‚¹åˆ’åˆ†çš„ PF-ODE å­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨å­è·¯å¾„çº¿æ€§ï¼ˆSLï¼‰ODE åœ¨æ¯ä¸ªå•ç‹¬çš„ PF-ODE å­è·¯å¾„ä¸Šå½¢æˆæ¸è¿›ä¸”è¿ç»­çš„è¯¯å·®ä¼°è®¡ï¼Œæ„å»ºå…·æœ‰è¾ƒå°ç´¯ç§¯è¿‘ä¼¼è¯¯å·®çš„å»å™ªæ˜ å°„ã€‚è¿˜å¼€å‘äº†ä¸€ç§æœ‰æ•ˆçš„è’¸é¦æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›æ›´é«˜çº§çš„æ‰©æ•£æ¨¡å‹ï¼ˆä¾‹å¦‚æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰çš„æ•´åˆã€‚
æ€§èƒ½ï¼šåœ¨ LAIONã€MS COCO 2014 å’Œ MS COCO 2017 æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒSLAM å®ç°äº†é«˜æ•ˆçš„è®­ç»ƒæ–¹æ¡ˆï¼Œåªéœ€ 6 ä¸ª A100 GPU å¤©å³å¯ç”Ÿæˆé«˜è´¨é‡çš„ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»¥é«˜æ€§èƒ½è¿›è¡Œ 2 åˆ° 4 æ­¥ç”Ÿæˆã€‚å…¨é¢çš„è¯„ä¼°è¿˜è¡¨æ˜ï¼ŒSLAM åœ¨å°æ­¥ç”Ÿæˆä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„åŠ é€Ÿæ–¹æ³•ï¼Œåœ¨ FID å’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼šSLAM çš„è®­ç»ƒæˆæœ¬ç›¸å¯¹è¾ƒä½ï¼Œåœ¨ 6 ä¸ª A100 GPU å¤©å†…å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶ä¸”åœ¨å°æ­¥ç”Ÿæˆä»»åŠ¡ä¸­å…·æœ‰è¾ƒé«˜çš„æ•ˆç‡ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-919d70908993415e92c8909c00655335.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-0e2aa2475025a88869b1ac0e1b6be112.jpg" align="middle">
</details>




<h2 id="Object-Attribute-Binding-in-Text-to-Image-Generation-Evaluation-and-Control"><a href="#Object-Attribute-Binding-in-Text-to-Image-Generation-Evaluation-and-Control" class="headerlink" title="Object-Attribute Binding in Text-to-Image Generation: Evaluation and   Control"></a>Object-Attribute Binding in Text-to-Image Generation: Evaluation and   Control</h2><p><strong>Authors:Maria Mihaela Trusca, Wolf Nuyts, Jonathan Thomm, Robert Honig, Thomas Hofmann, Tinne Tuytelaars, Marie-Francine Moens</strong></p>
<p>Current diffusion models create photorealistic images given a text prompt as input but struggle to correctly bind attributes mentioned in the text to the right objects in the image. This is evidenced by our novel image-graph alignment model called EPViT (Edge Prediction Vision Transformer) for the evaluation of image-text alignment. To alleviate the above problem, we propose focused cross-attention (FCA) that controls the visual attention maps by syntactic constraints found in the input sentence. Additionally, the syntax structure of the prompt helps to disentangle the multimodal CLIP embeddings that are commonly used in T2I generation. The resulting DisCLIP embeddings and FCA are easily integrated in state-of-the-art diffusion models without additional training of these models. We show substantial improvements in T2I generation and especially its attribute-object binding on several datasets.\footnote{Code and data will be made available upon acceptance. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.13766v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ–‡æœ¬æç¤ºä¸­çš„è¯­æ³•çº¦æŸæœ‰åŠ©äºç”Ÿæˆæ›´å‡†ç¡®çš„å›¾åƒï¼Œå…¶ä¸­å±æ€§ä¸æ­£ç¡®çš„å¯¹è±¡ç›¸å…³è”ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å½“å‰æ‰©æ•£æ¨¡å‹éš¾ä»¥å°†æ–‡æœ¬æç¤ºä¸­çš„å±æ€§æ­£ç¡®ç»‘å®šåˆ°å›¾åƒä¸­çš„æ­£ç¡®å¯¹è±¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒ-å›¾å¯¹é½æ¨¡å‹ EPViTï¼Œç”¨äºè¯„ä¼°å›¾åƒ-æ–‡æœ¬å¯¹é½ã€‚</li>
<li>å¼•å…¥äº†ç„¦ç‚¹äº¤å‰æ³¨æ„ (FCA)ï¼Œä»¥é€šè¿‡è¾“å…¥å¥å­çš„å¥æ³•çº¦æŸæ¥æ§åˆ¶è§†è§‰æ³¨æ„å›¾ã€‚</li>
<li>æç¤ºçš„è¯­æ³•ç»“æ„æœ‰åŠ©äºè§£è€¦åœ¨ T2I ç”Ÿæˆä¸­å¸¸ç”¨çš„å¤šæ¨¡æ€ CLIP åµŒå…¥ã€‚</li>
<li>æ‰€äº§ç”Ÿçš„ DisCLIP åµŒå…¥å’Œ FCA å¯ä»¥è½»æ¾é›†æˆåˆ°æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ä¸­ï¼Œè€Œæ— éœ€é¢å¤–è®­ç»ƒè¿™äº›æ¨¡å‹ã€‚</li>
<li>åœ¨ T2I ç”Ÿæˆä¸­å±•ç¤ºäº†å®è´¨æ€§çš„æ”¹è¿›ï¼Œå°¤å…¶æ˜¯åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šçš„å±æ€§-å¯¹è±¡ç»‘å®šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p><strong>Title:</strong> æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å¯¹è±¡-å±æ€§ç»‘å®šï¼šè¯„ä¼°å’Œæ§åˆ¶</p>
</li>
<li>
<p><strong>Authors:</strong> Maria Mihaela Trusca, Wolf Nuyts, Jonathan Thomm, Robert HÃ¶nig, Thomas Hofmann, Tinne Tuytelaars, Marie-Francine Moens</p>
</li>
<li>
<p><strong>Affiliation:</strong> KU Leuven, Department of Computer Science</p>
</li>
<li>
<p><strong>Keywords:</strong> æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¯¹è±¡-å±æ€§ç»‘å®šã€æ³¨æ„åŠ›æœºåˆ¶ã€æ‰©æ•£æ¨¡å‹</p>
</li>
<li>
<p><strong>Urls:</strong> Paper: https://arxiv.org/abs/2404.13766, Github: None</p>
</li>
<li>
<p><strong>Summary:</strong></p>
</li>
</ol>
<p>(1): <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> å½“å‰çš„æ‰©æ•£æ¨¡å‹å¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºåˆ›å»ºé€¼çœŸçš„å›¾åƒï¼Œä½†éš¾ä»¥å°†æ–‡æœ¬ä¸­æåˆ°çš„å±æ€§æ­£ç¡®ç»‘å®šåˆ°å›¾åƒä¸­çš„æ­£ç¡®å¯¹è±¡ä¸Šã€‚</p>
<p>(2): <strong>è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š</strong> ç°æœ‰çš„æ–¹æ³•ä¸»è¦åŸºäº CLIP è¯„åˆ†è¿›è¡Œè¯„ä¼°ï¼Œä½†æ— æ³•æ£€æŸ¥å¤æ‚å¤šå¯¹è±¡æç¤ºä¸­å±æ€§ä¸å¯¹è±¡çš„æ­£ç¡®ç»‘å®šã€‚</p>
<p>(3): <strong>æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š</strong> æå‡ºäº†ä¸€ç§åŸºäº ViT çš„å›¾åƒå›¾é¢„æµ‹æ¨¡å‹ EPViT å’Œä¸€ç§ç§°ä¸ºèšç„¦äº¤å‰æ³¨æ„ (FCA) çš„æ–¹æ³•ï¼Œä»¥æ§åˆ¶è§†è§‰æ³¨æ„åŠ›å›¾ï¼Œä»è€Œæ”¹å–„å¯¹è±¡-å±æ€§ç»‘å®šã€‚</p>
<p>(4): <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•æ˜¾ç€æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆåŠå…¶å¯¹è±¡-å±æ€§ç»‘å®šæ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š</p>
<pre><code>            (1):æå‡ºäº†ä¸€ç§åŸºäº ViT çš„å›¾åƒå›¾é¢„æµ‹æ¨¡å‹ EPViTï¼Œç”¨äºç”Ÿæˆå›¾åƒç‰¹å¾å›¾ï¼›

<pre><code>        (2):è®¾è®¡äº†ä¸€ç§ç§°ä¸ºèšç„¦äº¤å‰æ³¨æ„ (FCA) çš„æ–¹æ³•ï¼Œç”¨äºæ§åˆ¶è§†è§‰æ³¨æ„åŠ›å›¾ï¼Œä»è€Œæ”¹å–„å¯¹è±¡-å±æ€§ç»‘å®šï¼›

        (3):å°† FCA å’Œ DisCLIP é›†æˆåˆ°ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ï¼Œä»¥å¢å¼ºå…¶å¯¹è±¡-å±æ€§ç»‘å®šæ€§èƒ½ï¼›

        (4):åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¯¹å¢å¼ºåçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ COCO 10-Kã€CC-500ã€DAA-200 å’Œ AE-267ï¼Œä»¥éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚
</code></pre>
<p></code></pre></p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
<pre><code>            (1):æœ¬ç ”ç©¶æå‡ºäº†æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå¼ºè°ƒäº†åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­æ•´åˆè¯­è¨€å¥æ³•ç»“æ„çš„é‡è¦æ€§ã€‚æˆ‘ä»¬å±•ç¤ºäº†å®ƒä»¬åœ¨æœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„è½»æ¾ä¸”æˆåŠŸçš„é›†æˆï¼Œä»è€Œæ”¹å–„äº†å¯¹è±¡-å±æ€§ç»‘å®šï¼Œå¹¶å‡å°‘äº†ç”Ÿæˆå›¾åƒä¸­çš„å±æ€§æ³„æ¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ç§æ–°è®¾è®¡åº¦é‡ EPViT åœ¨è¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¯¹è±¡-å±æ€§ç»‘å®šæ–¹é¢ä¼˜äº CLIPã€‚EPViT å…è®¸æ›´å¥½åœ°ç†è§£å’Œè¡¡é‡æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒä¸­å‡†ç¡®åæ˜ é¢„æœŸæ–‡æœ¬æè¿°çš„æ€§èƒ½ã€‚                  
         8. æ€»ç»“ï¼š

<pre><code>        (1):æœ¬ç ”ç©¶çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
        (2):ä»åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ä¸‰ä¸ªç»´åº¦æ€»ç»“æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹ã€‚                   
        .......
     æŒ‰ç…§åé¢çš„è¾“å‡ºæ ¼å¼ï¼š
     8. ç»“è®ºï¼š

        (1):xxx;

        (2):åˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›

     åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯ç”¨è‹±æ–‡æ ‡æ³¨ï¼‰ï¼Œè¡¨è¿°å°½é‡ç®€æ´ã€å­¦æœ¯ï¼Œä¸è¦é‡å¤å‰é¢&amp;lt;Summary&amp;gt;çš„å†…å®¹ï¼ŒåŸæ•°å­—çš„ä½¿ç”¨ä»·å€¼ï¼ŒåŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå¯¹åº”å†…å®¹è¾“å‡ºåˆ°xxxï¼Œæ¢è¡Œï¼Œ.......è¡¨ç¤ºæ ¹æ®å®é™…è¦æ±‚å¡«å†™ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå¯ä»¥ä¸å†™ã€‚
</code></pre>
<p></code></pre></p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-da0a6f3f353e58ad78bee95a227f033f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-dd14ddde3959c9e4184326c15ccbc7c4.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-10db76640ccb78a6742ee69ebb161059.jpg" align="middle">
</details>




<h2 id="Concept-Arithmetics-for-Circumventing-Concept-Inhibition-in-Diffusion-Models"><a href="#Concept-Arithmetics-for-Circumventing-Concept-Inhibition-in-Diffusion-Models" class="headerlink" title="Concept Arithmetics for Circumventing Concept Inhibition in Diffusion   Models"></a>Concept Arithmetics for Circumventing Concept Inhibition in Diffusion   Models</h2><p><strong>Authors:Vitali Petsiuk, Kate Saenko</strong></p>
<p>Motivated by ethical and legal concerns, the scientific community is actively developing methods to limit the misuse of Text-to-Image diffusion models for reproducing copyrighted, violent, explicit, or personal information in the generated images. Simultaneously, researchers put these newly developed safety measures to the test by assuming the role of an adversary to find vulnerabilities and backdoors in them. We use compositional property of diffusion models, which allows to leverage multiple prompts in a single image generation. This property allows us to combine other concepts, that should not have been affected by the inhibition, to reconstruct the vector, responsible for target concept generation, even though the direct computation of this vector is no longer accessible. We provide theoretical and empirical evidence why the proposed attacks are possible and discuss the implications of these findings for safe model deployment. We argue that it is essential to consider all possible approaches to image generation with diffusion models that can be employed by an adversary. Our work opens up the discussion about the implications of concept arithmetics and compositional inference for safety mechanisms in diffusion models.   Content Advisory: This paper contains discussions and model-generated content that may be considered offensive. Reader discretion is advised.   Project page: <a target="_blank" rel="noopener" href="https://cs-people.bu.edu/vpetsiuk/arc">https://cs-people.bu.edu/vpetsiuk/arc</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.13706v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å®‰å…¨æ€§çš„æ”»å‡»é€šè¿‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„åˆæˆæ€§è´¨å’Œæ¦‚å¿µç®—æœ¯æ¥é‡å»ºè¢«ç¦æ­¢çš„æ¦‚å¿µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹çš„åˆæˆæ€§è´¨ä½¿æ”»å‡»è€…èƒ½å¤Ÿé€šè¿‡ç»„åˆå¤šä¸ªæç¤ºæ¥ç”Ÿæˆå›¾åƒã€‚</li>
<li>å³ä½¿ç›´æ¥è®¡ç®—ç›®æ ‡æ¦‚å¿µçš„å‘é‡ä¸å†å¯è®¿é—®ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç»„åˆä¸å—æŠ‘åˆ¶å½±å“çš„å…¶ä»–æ¦‚å¿µæ¥é‡å»ºè¯¥å‘é‡ã€‚</li>
<li>æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ¦‚å¿µç®—æœ¯æ¥é‡å»ºè¢«ç¦æ­¢çš„æ¦‚å¿µï¼Œä¾‹å¦‚ç‰ˆæƒã€æš´åŠ›ã€è‰²æƒ…æˆ–ä¸ªäººä¿¡æ¯ã€‚</li>
<li>æå‡ºäº†ä¸¤ç§æ–°çš„æ”»å‡»ï¼Œåˆ†åˆ«ç§°ä¸ºâ€œåé—¨æ”»å‡»â€å’Œâ€œç»„åˆæ”»å‡»â€ã€‚</li>
<li>åé—¨æ”»å‡»åˆ©ç”¨äº†ç”Ÿæˆæ¨¡å‹ä¸­å­˜åœ¨çš„æ¼æ´æˆ–åé—¨ã€‚</li>
<li>ç»„åˆæ”»å‡»åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„åˆæˆæ€§è´¨ã€‚</li>
<li>è¿™äº›æ”»å‡»å¯¹å®‰å…¨æ¨¡å‹çš„éƒ¨ç½²æœ‰é‡å¤§å½±å“ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: ç»•è¿‡æ¦‚å¿µæŠ‘åˆ¶çš„ç®—æœ¯æ¦‚å¿µ</p>
</li>
<li>
<p>Authors: Vitali Petsiuk and Kate Saenko</p>
</li>
<li>
<p>Affiliation: æ³¢å£«é¡¿å¤§å­¦</p>
</li>
<li>
<p>Keywords: Text-to-Image diffusion models, safety mechanisms, concept inhibition, concept arithmetics, compositional inference</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2404.13706, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): éšç€ Text-to-Image (T2I) ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œäººä»¬å¼€å§‹å…³æ³¨å…¶æ½œåœ¨çš„æ»¥ç”¨é£é™©ï¼Œä¾‹å¦‚ç”Ÿæˆä¾µçŠ¯ç‰ˆæƒã€æš´åŠ›ã€è‰²æƒ…æˆ–ä¸ªäººä¿¡æ¯çš„å†…å®¹ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶äººå‘˜å¼€å‘äº†å„ç§å®‰å…¨æœºåˆ¶æ¥é™åˆ¶æ¨¡å‹çš„æ¶æ„ä½¿ç”¨ã€‚</p>
<p>(2): ç°æœ‰çš„å®‰å…¨æœºåˆ¶é€šå¸¸é‡‡ç”¨æ¦‚å¿µæŠ‘åˆ¶çš„æ–¹æ³•ï¼Œå³é˜»æ­¢æ¨¡å‹ç”Ÿæˆç‰¹å®šæ¦‚å¿µçš„å†…å®¹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å­˜åœ¨æ¼æ´ï¼Œå…è®¸æ”»å‡»è€…é€šè¿‡ç»„åˆå…¶ä»–æ¦‚å¿µæ¥ç»•è¿‡æŠ‘åˆ¶ï¼Œä»è€Œé‡å»ºè¢«æŠ‘åˆ¶æ¦‚å¿µçš„å‘é‡ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¦‚å¿µç®—æœ¯å’Œç»„åˆæ¨ç†çš„æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„ç»„åˆç‰¹æ€§ï¼Œå…è®¸åœ¨å•ä¸ªå›¾åƒç”Ÿæˆä¸­ä½¿ç”¨å¤šä¸ªæç¤ºã€‚é€šè¿‡ç»„åˆä¸å—æŠ‘åˆ¶å½±å“çš„å…¶ä»–æ¦‚å¿µï¼Œæ”»å‡»è€…å¯ä»¥é‡å»ºè´Ÿè´£ç›®æ ‡æ¦‚å¿µç”Ÿæˆçš„å‘é‡ï¼Œå³ä½¿è¯¥å‘é‡çš„ç›´æ¥è®¡ç®—ä¸å†å¯è®¿é—®ã€‚</p>
<p>(4): å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ”»å‡»æ–¹æ³•åœ¨å„ç§æ‰©æ•£æ¨¡å‹å’Œæ¦‚å¿µæŠ‘åˆ¶æœºåˆ¶ä¸Šéƒ½å–å¾—äº†æˆåŠŸã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œåœ¨è®¾è®¡å®‰å…¨æœºåˆ¶æ—¶ï¼Œå¿…é¡»è€ƒè™‘æ”»å‡»è€…å¯èƒ½é‡‡ç”¨çš„ä¸€åˆ‡å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¦‚å¿µç®—æœ¯å’Œç»„åˆæ¨ç†çš„æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»•è¿‡äº†ç°æœ‰çš„åŸºäºæ¦‚å¿µæŠ‘åˆ¶çš„å®‰å…¨æœºåˆ¶ï¼Œå…è®¸æ”»å‡»è€…ç”Ÿæˆè¢«æŠ‘åˆ¶æ¦‚å¿µçš„å†…å®¹ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œåœ¨è®¾è®¡å®‰å…¨æœºåˆ¶æ—¶ï¼Œå¿…é¡»è€ƒè™‘æ”»å‡»è€…å¯èƒ½é‡‡ç”¨çš„ä¸€åˆ‡å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»•è¿‡æ¦‚å¿µæŠ‘åˆ¶çš„å®‰å…¨æœºåˆ¶çš„æ–°æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„ç»„åˆç‰¹æ€§å’Œæ¦‚å¿µç®—æœ¯ã€‚
æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ”»å‡»æ–¹æ³•åœ¨å„ç§æ‰©æ•£æ¨¡å‹å’Œæ¦‚å¿µæŠ‘åˆ¶æœºåˆ¶ä¸Šéƒ½å–å¾—äº†æˆåŠŸã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦å¯¹æ‰©æ•£æ¨¡å‹ã€æ¦‚å¿µæŠ‘åˆ¶æœºåˆ¶å’Œæ”»å‡»æ–¹æ³•æœ‰æ·±å…¥çš„ç†è§£ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6c22a86090e8195e410f10a38f6fe1f9.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-936989960b19443d0f4e3c6f1a1e8e26.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-04-25/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-04-25/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-04-25/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-00e62c0d66ff2641b9803987918d6fd0.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-25  GaussianTalker Speaker-specific Talking Head Synthesis via 3D Gaussian   Splatting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-04-22/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5f7fb8305c36c1fe2572adfd98b584f7.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-22  AG-NeRF Attention-guided Neural Radiance Fields for Multi-height   Large-scale Outdoor Scene Rendering
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-04-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">6736.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
