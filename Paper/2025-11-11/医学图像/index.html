<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-11  Intensive X-ray/UVOIR continuum reverberation mapping of the Seyfert AGN   MCG+08-11-11">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-c4de5018b60c7ef69ef19be072062b3c')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    70 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-11-æ›´æ–°"><a href="#2025-11-11-æ›´æ–°" class="headerlink" title="2025-11-11 æ›´æ–°"></a>2025-11-11 æ›´æ–°</h1><h2 id="Intensive-X-ray-UVOIR-continuum-reverberation-mapping-of-the-Seyfert-AGN-MCG-08-11-11"><a href="#Intensive-X-ray-UVOIR-continuum-reverberation-mapping-of-the-Seyfert-AGN-MCG-08-11-11" class="headerlink" title="Intensive X-ray&#x2F;UVOIR continuum reverberation mapping of the Seyfert AGN   MCG+08-11-11"></a>Intensive X-ray&#x2F;UVOIR continuum reverberation mapping of the Seyfert AGN   MCG+08-11-11</h2><p><strong>Authors:D. Kynoch, I. M. McHardy, E. M. Cackett, J. Gelbord, J. V. HernÃ¡ndez Santisteban, K. Horne, J. A. Miller, H. Netzer, C. Done, R. Edelson, M. M. Fausnaugh, M. R. Goad, B. M. Peterson, F. M. Vincentelli</strong></p>
<p>We present results from intensive (x3 daily), three-month-long X-ray, UV and optical monitoring of the bright Seyfert active galactic nucleus (AGN) MCG+08-11-11 with Swift, supported by optical-infrared ground-based monitoring. The 12 resultant, well-sampled, lightcurves are highly correlated; in particular, the X-ray to UV correlation r_max &#x3D; 0.85 is, as far as we know, the highest yet recorded in a Seyfert galaxy. The lags increase with wavelength, as expected from reprocessing of central high-energy emission by surrounding material. Our lag spectrum is much shallower than that obtained from an optical monitoring campaign conducted a year earlier when MCG+08-11-11 was approximately 4 times brighter. After filtering out long-term trends in the earlier optical lightcurves we recover shorter lags consistent with our own - demonstrating concurrent reverberation signals from different spatial scales and the luminosity dependence of the measured lags. We use our lag spectrum to test several physical models, finding that disc reprocessing models cannot account for the observed â€˜excessâ€™ lags in the u and r-i-bands that are highly indicative of the Balmer and Paschen continua produced by reprocessing in the broad line region (BLR) gas. The structure seen in both the variable (rms) and lag spectra, and the large time delay between X-ray and UV variations (approximately 2 days) all suggest that the BLR is the dominant reprocessor. The hard X-ray spectrum (Gamma approximately 1.7) and faint, red, UV-optical spectrum both indicate that the Eddington accretion ratio is low: approximately 0.03. The bolometric luminosity then requires that the black hole mass is substantially greater than current reverberation mapping derived estimates. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹æ˜äº®çš„å¡å¼—ç‰¹æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆAGNï¼‰MCG+08-11-11è¿›è¡Œäº†å¯†é›†ï¼ˆæ¯æ—¥ä¸‰æ¬¡ï¼‰ã€ä¸ºæœŸä¸‰ä¸ªæœˆçš„Xå°„çº¿ã€ç´«å¤–çº¿å’Œå…‰å­¦ç›‘æµ‹ï¼Œå¹¶åˆ©ç”¨Swiftå’Œåœ°é¢å…‰å­¦-çº¢å¤–ç›‘æµ‹æ•°æ®æ”¯æŒã€‚æ‰€å¾—çš„12æ¡é‡‡æ ·è‰¯å¥½çš„å…‰å˜æ›²çº¿é«˜åº¦ç›¸å…³ã€‚ç‰¹åˆ«æ˜¯Xå°„çº¿å’Œç´«å¤–çº¿çš„æœ€å¤§ç›¸å…³ç³»æ•°r_max&#x3D;0.85ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯åœ¨å¡å¼—ç‰¹æ˜Ÿç³»ä¸­è®°å½•çš„æœ€é«˜å€¼ã€‚å»¶è¿Ÿæ—¶é—´éšæ³¢é•¿å¢åŠ è€Œå¢åŠ ï¼Œè¿™ç¬¦åˆå‘¨å›´ç‰©è´¨å¯¹ä¸­å¤®é«˜èƒ½å‘å°„çš„å†å¤„ç†é¢„æœŸã€‚æˆ‘ä»¬çš„å»¶è¿Ÿè°±æ¯”ä¸€å¹´å‰è¿›è¡Œçš„å…‰å­¦ç›‘æµ‹æ´»åŠ¨å¾—åˆ°çš„å»¶è¿Ÿè°±è¦å¹³ç¼“å¾—å¤šï¼Œå½“æ—¶MCG+08-11-11äº®åº¦å¤§çº¦æ˜¯ç°åœ¨çš„å››å€ã€‚åœ¨è¿‡æ»¤æ‰æ—©æœŸå…‰å­¦å…‰å˜æ›²çº¿çš„é•¿æœŸè¶‹åŠ¿åï¼Œæˆ‘ä»¬æ¢å¤äº†è¾ƒçŸ­çš„å»¶è¿Ÿæ—¶é—´ï¼Œè¿™ä¸æˆ‘ä»¬è‡ªå·±çš„è§‚æµ‹ç»“æœä¸€è‡´ï¼Œè¯æ˜äº†ä¸åŒç©ºé—´å°ºåº¦ä¸Šçš„åŒæ—¶å›æ³¢ä¿¡å·ä»¥åŠæµ‹é‡åˆ°çš„å»¶è¿Ÿä¸å…‰åº¦ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚æˆ‘ä»¬ä½¿ç”¨å»¶è¿Ÿè°±æµ‹è¯•äº†å‡ ç§ç‰©ç†æ¨¡å‹ï¼Œå‘ç°åœ†ç›˜å†å¤„ç†æ¨¡å‹æ— æ³•è§£é‡Šuæ³¢æ®µå’Œr-iæ³¢æ®µè§‚å¯Ÿåˆ°çš„â€œè¿‡å‰©â€å»¶è¿Ÿï¼Œè¿™äº›å»¶è¿Ÿæ˜æ˜¾è¡¨æ˜å·´å°”æœ«è¿ç»­ä½“å’Œå¸•ç”³è¿ç»­ä½“æ˜¯åœ¨å®½çº¿åŒºï¼ˆBLRï¼‰æ°”ä½“å†å¤„ç†äº§ç”Ÿçš„ã€‚åœ¨å¯å˜ï¼ˆrmsï¼‰å…‰è°±å’Œå»¶è¿Ÿå…‰è°±ä¸­çœ‹åˆ°çš„ç»“æ„ä»¥åŠXå°„çº¿å’Œç´«å¤–çº¿å˜åŒ–ä¹‹é—´è¾ƒé•¿çš„æ—¶é—´å»¶è¿Ÿï¼ˆçº¦ä¸¤å¤©ï¼‰éƒ½è¡¨æ˜å®½çº¿åŒºæ˜¯ä¸»è¦çš„å†å¤„ç†å™¨ã€‚ç¡¬Xå°„çº¿å…‰è°±ï¼ˆGammaçº¦ä¸º1.7ï¼‰å’Œå¾®å¼±ã€çº¢è‰²ã€ç´«å¤–å…‰å­¦å…‰è°±å‡è¡¨æ˜çˆ±ä¸é¡¿å¢è´¨ç‡è¾ƒä½ï¼šçº¦ä¸º0.03ã€‚æ€»å…‰åº¦è¦æ±‚é»‘æ´è´¨é‡è¿œå¤§äºå½“å‰ç”±å›æ³¢æ˜ å°„å¾—å‡ºçš„ä¼°è®¡å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.05342v1">PDF</a> 24 pages, 13 figures (including appendices). Revised following   refereeâ€™s report</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¯¹äº®å¡å¼—ç‰¹æ´»åŠ¨æ˜Ÿç³»æ ¸ï¼ˆMCG+08-11-11ï¼‰è¿›è¡Œä¸ºæœŸä¸‰ä¸ªæœˆçš„å¯†é›†ï¼ˆæ¯æ—¥ä¸‰æ¬¡ï¼‰Xå°„çº¿ã€ç´«å¤–çº¿å’Œå…‰å­¦ç›‘æµ‹çš„ç»“æœã€‚ç ”ç©¶å‘ç°Xå°„çº¿è‡³ç´«å¤–çº¿çš„å¼ºç›¸å…³æ€§ï¼Œä¸”æ—¶å»¶éšæ³¢é•¿å¢åŠ è€Œå¢åŠ ã€‚ä¸å‰ä¸€å¹´çš„å…‰å­¦ç›‘æµ‹ç»“æœç›¸æ¯”ï¼Œæœ¬ç ”ç©¶çš„æ»åå…‰è°±æ›´ä¸ºå¹³ç¼“ã€‚ç ”ç©¶è¿˜æµ‹è¯•äº†å¤šç§ç‰©ç†æ¨¡å‹ï¼Œå‘ç°ç›˜å†å¤„ç†æ¨¡å‹æ— æ³•è§£é‡Šè§‚å¯Ÿåˆ°çš„â€œè¿‡å‰©â€æ»åç°è±¡ï¼Œæç¤ºå·´å°”é»˜å’Œå¸•ç”³è¿ç»­ä½“æ˜¯åœ¨å®½çº¿åŒºï¼ˆBLRï¼‰æ°”ä½“ä¸­äº§ç”Ÿçš„ã€‚å¤§çš„æ—¶é—´å»¶è¿Ÿå’Œç»“æ„ç‰¹å¾å‡è¡¨æ˜å®½çº¿åŒºæ˜¯ä¸»è¦çš„å…‰å­¦ååº”å™¨ã€‚ç¡¬Xå°„çº¿å…‰è°±å’Œæš—æ·¡çš„çº¢å¤–-å…‰å­¦å…‰è°±å‡è¡¨æ˜çˆ±ä¸é¡¿ç§¯ç‡è¾ƒä½ï¼Œè¦æ±‚é»‘æ´è´¨é‡è¿œå¤§äºå½“å‰é€šè¿‡å›æ³¢æ˜ å°„å¾—å‡ºçš„ä¼°è®¡å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿›è¡Œäº†é•¿è¾¾ä¸‰ä¸ªæœˆçš„å¯†é›†Xå°„çº¿ã€ç´«å¤–çº¿å’Œå…‰å­¦ç›‘æµ‹ï¼Œé’ˆå¯¹äº®å¡å¼—ç‰¹æ´»åŠ¨æ˜Ÿç³»æ ¸MCG+08-11-11ã€‚</li>
<li>å‘ç°Xå°„çº¿è‡³ç´«å¤–çº¿ä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸å…³æ€§ï¼Œæœ€å¤§ç›¸å…³ç³»æ•°r_max &#x3D; 0.85ã€‚</li>
<li>æ—¶å»¶éšæ³¢é•¿å¢åŠ è€Œå¢åŠ ï¼Œç¬¦åˆä¸­å¿ƒé«˜èƒ½è¾å°„è¢«å‘¨å›´ç‰©è´¨å†å¤„ç†çš„é¢„æœŸã€‚</li>
<li>ä¸å‰ä¸€å¹´çš„å…‰å­¦ç›‘æµ‹ç»“æœç›¸æ¯”ï¼Œæœ¬ç ”ç©¶ä¸­çš„æ»åå…‰è°±æ›´å¹³ç¼“ã€‚</li>
<li>ç›˜å†å¤„ç†æ¨¡å‹æ— æ³•è§£é‡Šè§‚å¯Ÿåˆ°çš„æŸäº›æ»åç°è±¡ï¼Œæš—ç¤ºå®½çº¿åŒºï¼ˆBLRï¼‰æ°”ä½“äº§ç”Ÿå·´å°”é»˜å’Œå¸•ç”³è¿ç»­ä½“ã€‚</li>
<li>å®½çº¿åŒºå¯èƒ½æ˜¯ä¸»è¦çš„å…‰å­¦ååº”å™¨ï¼Œè¿™ä¸€ç»“è®ºåŸºäºå¤§çš„æ—¶é—´å»¶è¿Ÿã€å˜é‡å…‰è°±å’Œç‰¹å®šçš„æ—¶é—´ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.05342">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b5e3c9cc2414b9dd2848589825ffe7f1" align="middle">
<img src="https://picx.zhimg.com/v2-1026e01203982ce7ea722f92d6dbdd14" align="middle">
<img src="https://picx.zhimg.com/v2-82f4106597bbe509a3d856c8b59adda2" align="middle">
<img src="https://picx.zhimg.com/v2-2446e87e03e7ac38beb9936ca4e5ee97" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Walk-the-Lines-2-Contour-Tracking-for-Detailed-Segmentation"><a href="#Walk-the-Lines-2-Contour-Tracking-for-Detailed-Segmentation" class="headerlink" title="Walk the Lines 2: Contour Tracking for Detailed Segmentation"></a>Walk the Lines 2: Contour Tracking for Detailed Segmentation</h2><p><strong>Authors:AndrÃ© Peter Kelm, Max Braeschke, Emre GÃ¼lsoylu, Simone Frintrop</strong></p>
<p>This paper presents Walk the Lines 2 (WtL2), a unique contour tracking algorithm specifically adapted for detailed segmentation of infrared (IR) ships and various objects in RGB.1 This extends the original Walk the Lines (WtL) [12], which focused solely on detailed ship segmentation in color. These innovative WtLs can replace the standard non-maximum suppression (NMS) by using contour tracking to refine the object contour until a 1-pixel-wide closed shape can be binarized, forming a segmentable area in foreground-background scenarios. WtL2 broadens the application range of WtL beyond its original scope, adapting to IR and expanding to diverse objects within the RGB context. To achieve IR segmentation, we adapt its input, the object contour detector, to IR ships. In addition, the algorithm is enhanced to process a wide range of RGB objects, outperforming the latest generation of contour-based methods when achieving a closed object contour, offering high peak Intersection over Union (IoU) with impressive details. This positions WtL2 as a compelling method for specialized applications that require detailed segmentation or high-quality samples, potentially accelerating progress in several niche areas of image segmentation. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†Walk the Lines 2ï¼ˆWtL2ï¼‰è¿™ä¸€ç‹¬ç‰¹çš„è½®å»“è·Ÿè¸ªç®—æ³•ï¼Œè¯¥ç®—æ³•ç‰¹åˆ«é€‚ç”¨äºçº¢å¤–ï¼ˆIRï¼‰èˆ¹èˆ¶å’ŒRGBä¸­å„ç§å¯¹è±¡çš„è¯¦ç»†åˆ†å‰²1ã€‚è¿™æ˜¯å¯¹åŸå§‹Walk the Linesï¼ˆWtLï¼‰çš„æ‰©å±•ï¼ŒWtLä¸“æ³¨äºå½©è‰²å›¾åƒçš„è¯¦ç»†èˆ¹èˆ¶åˆ†å‰²ã€‚è¿™äº›åˆ›æ–°çš„WtLèƒ½å¤Ÿé€šè¿‡è½®å»“è·Ÿè¸ªæ¥å®Œå–„å¯¹è±¡è½®å»“ï¼Œç›´è‡³è¾¾åˆ°1åƒç´ å®½çš„é—­åˆå½¢çŠ¶å¯è¿›è¡ŒäºŒå€¼åŒ–ï¼Œä»è€Œåœ¨å‰æ™¯-èƒŒæ™¯åœºæ™¯ä¸­å½¢æˆå¯åˆ†å‰²åŒºåŸŸï¼Œä»è€Œå–ä»£æ ‡å‡†çš„éæœ€å¤§æŠ‘åˆ¶ï¼ˆNMSï¼‰ã€‚WtL2æ‹“å®½äº†WtLçš„åº”ç”¨èŒƒå›´ï¼Œé€‚åº”çº¢å¤–é¢†åŸŸå¹¶æ‰©å±•åˆ°RGBå†…éƒ¨çš„å¤šç§å¯¹è±¡ã€‚ä¸ºäº†å®ç°çº¢å¤–åˆ†å‰²ï¼Œæˆ‘ä»¬è°ƒæ•´äº†è¾“å…¥çš„å¯¹è±¡è½®å»“æ£€æµ‹å™¨ä»¥é€‚åº”çº¢å¤–èˆ¹èˆ¶ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•ç»è¿‡æ”¹è¿›èƒ½å¤Ÿå¤„ç†å¤šç§RGBå¯¹è±¡ï¼Œåœ¨è¾¾åˆ°é—­åˆå¯¹è±¡è½®å»“æ—¶ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€æ–°çš„è½®å»“æ–¹æ³•ï¼Œå…·æœ‰é«˜çš„å³°å€¼äº¤å¹¶æ¯”ï¼ˆIoUï¼‰ä¸”ç»†èŠ‚ä»¤äººå°è±¡æ·±åˆ»ã€‚è¿™ä½¿å¾—WtL2æˆä¸ºä¸“ä¸šåº”ç”¨çš„ç†æƒ³æ–¹æ³•ï¼Œé€‚ç”¨äºéœ€è¦è¯¦ç»†åˆ†å‰²æˆ–é«˜è´¨é‡æ ·æœ¬çš„åº”ç”¨é¢†åŸŸï¼Œæœ‰æœ›åŠ é€Ÿå›¾åƒåˆ†å‰²é¢†åŸŸçš„å¤šä¸ªå°ä¼—é¢†åŸŸçš„è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.05210v1">PDF</a> 11 pages, 6 figures. Accepted at CAIP 2025: 21st International   Conference on Computer Analysis of Images and Patterns, Las Palmas de Gran   Canaria, Spain, September 22-25, 2025. To appear in: Proceedings Part I,   Lecture Notes in Computer Science (LNCS), Springer Nature Switzerland</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Walk the Lines 2ï¼ˆWtL2ï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•æ˜¯ä¸€ç§ç‹¬ç‰¹çš„è½®å»“è·Ÿè¸ªç®—æ³•ï¼Œé€‚ç”¨äºçº¢å¤–ï¼ˆIRï¼‰èˆ¹èˆ¶å’ŒRGBä¸­å„ç§å¯¹è±¡çš„è¯¦ç»†åˆ†å‰²ã€‚WtL2æ‰©å±•äº†åŸå§‹çš„Walk the Linesï¼ˆWtLï¼‰ï¼Œä¸ä»…èƒ½å¯¹å½©è‰²èˆ¹èˆ¶è¿›è¡Œè¯¦ç»†åˆ†å‰²ï¼Œè¿˜èƒ½é€‚åº”çº¢å¤–åˆ†å‰²å’ŒRGBä¸­çš„å¤šç§å¯¹è±¡ã€‚WtL2é€šè¿‡è½®å»“è·Ÿè¸ªç»†åŒ–å¯¹è±¡è½®å»“ï¼Œç›´è‡³è¾¾åˆ°1åƒç´ å®½åº¦çš„é—­åˆå½¢çŠ¶ï¼Œå¯åœ¨å‰æ™¯èƒŒæ™¯åœºæ™¯ä¸­å½¢æˆå¯äºŒå€¼åŒ–çš„åˆ†æ®µåŒºåŸŸã€‚è¯¥ç®—æ³•åœ¨è¾¾åˆ°é—­åˆå¯¹è±¡è½®å»“æ–¹é¢ä¼˜äºæœ€æ–°çš„è½®å»“æ–¹æ³•ï¼Œå…·æœ‰é«˜çš„å³°å€¼äº¤é›†æ¯”å¹¶å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„ç»†èŠ‚ã€‚è¿™ä½¿å¾—WtL2æˆä¸ºéœ€è¦è¯¦ç»†åˆ†å‰²æˆ–é«˜è´¨é‡æ ·æœ¬çš„ä¸“ç”¨åº”ç”¨ç¨‹åºçš„æœ‰å¸å¼•åŠ›çš„æ–¹æ³•ï¼Œæœ‰æœ›åŠ é€Ÿå›¾åƒåˆ†å‰²é¢†åŸŸçš„å¤šä¸ªç»†åˆ†é¢†åŸŸçš„è¿›å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>WtL2æ˜¯ä¸€ç§åŸºäºè½®å»“è·Ÿè¸ªçš„ç®—æ³•ï¼Œç”¨äºè¯¦ç»†åˆ†å‰²çº¢å¤–èˆ¹èˆ¶å’ŒRGBä¸­çš„å¤šç§å¯¹è±¡ã€‚</li>
<li>WtL2æ‰©å±•äº†åŸå§‹çš„WtLç®—æ³•ï¼Œé€‚åº”äº†çº¢å¤–åˆ†å‰²ï¼Œå¹¶æ‰©å±•åˆ°RGBä¸­çš„å¤šç§å¯¹è±¡ã€‚</li>
<li>WtL2é€šè¿‡è½®å»“è·Ÿè¸ªç»†åŒ–å¯¹è±¡è½®å»“ï¼Œè¾¾åˆ°1åƒç´ å®½åº¦çš„é—­åˆå½¢çŠ¶ï¼Œå½¢æˆå¯äºŒå€¼åŒ–çš„åˆ†æ®µåŒºåŸŸã€‚</li>
<li>WtL2åœ¨è¾¾åˆ°é—­åˆå¯¹è±¡è½®å»“æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰é«˜å³°å€¼äº¤é›†æ¯”å’Œä»¤äººå°è±¡æ·±åˆ»çš„ç»†èŠ‚ã€‚</li>
<li>WtL2é€‚ç”¨äºéœ€è¦è¯¦ç»†åˆ†å‰²æˆ–é«˜è´¨é‡æ ·æœ¬çš„ä¸“ç”¨åº”ç”¨ç¨‹åºã€‚</li>
<li>WtL2å¯èƒ½æˆä¸ºåŠ é€Ÿå›¾åƒåˆ†å‰²é¢†åŸŸå¤šä¸ªç»†åˆ†é¢†åŸŸè¿›å±•çš„å…³é”®æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.05210">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f7e39d2d7a7cd826926105aaa750706" align="middle">
<img src="https://picx.zhimg.com/v2-325da1ebc312b1a6089acb704dfaf226" align="middle">
<img src="https://picx.zhimg.com/v2-b211d68e5e67d85397e58970d1a72e67" align="middle">
<img src="https://picx.zhimg.com/v2-5cfa270867627650a44d67da76b9062c" align="middle">
<img src="https://picx.zhimg.com/v2-c4de5018b60c7ef69ef19be072062b3c" align="middle">
<img src="https://picx.zhimg.com/v2-afb971b212b5882d5ff49488ca2bd1cf" align="middle">
<img src="https://picx.zhimg.com/v2-6f61026c5561ea02fd2978e26296f88d" align="middle">
<img src="https://picx.zhimg.com/v2-afdd2d1c77756d98a1088c96e5ca1b0d" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Multimodal-Deep-Learning-for-Prediction-of-Progression-Free-Survival-in-Patients-with-Neuroendocrine-Tumors-Undergoing-177Lu-based-Peptide-Receptor-Radionuclide-Therapy"><a href="#Multimodal-Deep-Learning-for-Prediction-of-Progression-Free-Survival-in-Patients-with-Neuroendocrine-Tumors-Undergoing-177Lu-based-Peptide-Receptor-Radionuclide-Therapy" class="headerlink" title="Multimodal Deep Learning for Prediction of Progression-Free Survival in   Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor   Radionuclide Therapy"></a>Multimodal Deep Learning for Prediction of Progression-Free Survival in   Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor   Radionuclide Therapy</h2><p><strong>Authors:Simon Baur, Tristan Ruhwedel, Ekin BÃ¶ke, Zuzanna Kobus, Gergana Lishkova, Christoph Wetz, Holger Amthauer, Christoph Roderburg, Frank Tacke, Julian M. Rogasch, Wojciech Samek, Henning Jann, Jackie Ma, Johannes Eschrich</strong></p>
<p>Peptide receptor radionuclide therapy (PRRT) is an established treatment for metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs only in a subset of patients. Predicting progression-free survival (PFS) could support individualized treatment planning. This study evaluates laboratory, imaging, and multimodal deep learning models for PFS prediction in PRRT-treated patients. In this retrospective, single-center study 116 patients with metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical characteristics, laboratory values, and pretherapeutic somatostatin receptor positron emission tomography&#x2F;computed tomographies (SR-PET&#x2F;CT) were collected. Seven models were trained to classify low- vs. high-PFS groups, including unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches. Explainability was evaluated by feature importance analysis and gradient maps. Forty-two patients (36%) had short PFS (&lt; 1 year), 74 patients long PFS (&gt;1 year). Groups were similar in most characteristics, except for higher baseline chromogranin A (p &#x3D; 0.003), elevated gamma-GT (p &#x3D; 0.002), and fewer PRRT cycles (p &lt; 0.001) in short-PFS patients. The Random Forest model trained only on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal three-dimensional convolutional neural networks using SR-PET or CT performed worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch - achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01). Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers outperformed unimodal approaches for PFS prediction after PRRT. Upon external validation, such models may support risk-adapted follow-up strategies. </p>
<blockquote>
<p>è‚½å—ä½“æ”¾å°„æ€§æ ¸ç´ æ²»ç–—ï¼ˆPRRTï¼‰æ˜¯æ²»ç–—è½¬ç§»æ€§ç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤ï¼ˆNETsï¼‰çš„ä¸€ç§æ—¢å®šæ–¹æ³•ï¼Œä½†é•¿æœŸç–¾ç—…æ§åˆ¶ä»…å‘ç”Ÿåœ¨éƒ¨åˆ†æ‚£è€…ä¸­ã€‚é¢„æµ‹æ— è¿›å±•ç”Ÿå­˜æœŸï¼ˆPFSï¼‰æœ‰åŠ©äºåˆ¶å®šä¸ªä½“åŒ–æ²»ç–—æ–¹æ¡ˆã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†å®éªŒå®¤ã€æˆåƒå’Œå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨PRRTæ²»ç–—æ‚£è€…ä¸­çš„PFSé¢„æµ‹æ•ˆæœã€‚è¿™é¡¹å›é¡¾æ€§å•ä¸­å¿ƒç ”ç©¶çº³å…¥äº†116ä¾‹æ¥å—177Lu-DOTATOCæ²»ç–—çš„è½¬ç§»æ€§NETsæ‚£è€…ã€‚æ”¶é›†äº†ä¸´åºŠç‰¹å¾ã€å®éªŒå®¤å€¼å’Œé¢„æ²»ç–—å‰çš„ç”Ÿé•¿æŠ‘ç´ å—ä½“æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ&#x2F;è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆSR-PET&#x2F;CTï¼‰æ•°æ®ã€‚è®­ç»ƒäº†7ç§æ¨¡å‹æ¥åŒºåˆ†ä½PFSç»„å’Œé«˜PFSç»„ï¼ŒåŒ…æ‹¬å•æ¨¡æ€ï¼ˆå®éªŒå®¤ã€SR-PETæˆ–CTï¼‰å’Œå¤šæ¨¡æ€èåˆæ–¹æ³•ã€‚é€šè¿‡ç‰¹å¾é‡è¦æ€§åˆ†æå’Œæ¢¯åº¦å›¾å¯¹è§£é‡Šæ€§è¿›è¡Œäº†è¯„ä¼°ã€‚42åæ‚£è€…ï¼ˆ36%ï¼‰PFSè¾ƒçŸ­ï¼ˆ&lt;1å¹´ï¼‰ï¼Œ74åæ‚£è€…PFSè¾ƒé•¿ï¼ˆ&gt;1å¹´ï¼‰ã€‚é™¤åŸºçº¿è¡€æµ†é“¬ç²’ç´ Aå‡é«˜ï¼ˆp&#x3D;0.003ï¼‰ã€Î³-GTå‡é«˜ï¼ˆp&#x3D;0.002ï¼‰å’ŒPRRTå‘¨æœŸè¾ƒå°‘ï¼ˆp&lt;0.001ï¼‰å¤–ï¼Œä¸¤ç»„æ‚£è€…çš„å¤šæ•°ç‰¹å¾ç›¸ä¼¼ã€‚ä»…ä½¿ç”¨å®éªŒå®¤ç”Ÿç‰©æ ‡å¿—ç‰©è®­ç»ƒçš„éšæœºæ£®æ—æ¨¡å‹è¾¾åˆ°AUROC 0.59 Â± 0.02ã€‚ä½¿ç”¨SR-PETæˆ–CTçš„å•æ¨¡æ€ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œè¡¨ç°è¾ƒå·®ï¼ˆAUROCåˆ†åˆ«ä¸º0.42 Â± 0.03å’Œ0.54 Â± 0.01ï¼‰ã€‚ä¸€ç§ç»“åˆå®éªŒå®¤å€¼ã€SR-PETå’ŒCTçš„å¤šæ¨¡æ€èåˆæ¨¡å‹ï¼Œè¾…ä»¥é¢„è®­ç»ƒCTåˆ†æ”¯ï¼Œå–å¾—äº†æœ€ä½³ç»“æœï¼ˆAUROC 0.72 Â± 0.01ï¼ŒAUPRC 0.80 Â± 0.01ï¼‰ã€‚å¯¹äºPRRTåçš„PFSé¢„æµ‹ï¼Œç»“åˆSR-PETã€CTå’Œå®éªŒå®¤ç”Ÿç‰©æ ‡å¿—ç‰©çš„å¤šæ¨¡æ€æ·±åº¦å­¦ä¹ ä¼˜äºå•æ¨¡æ€æ–¹æ³•ã€‚ç»è¿‡å¤–éƒ¨éªŒè¯ï¼Œæ­¤ç±»æ¨¡å‹å¯æ”¯æŒé£é™©é€‚åº”çš„éšè®¿ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.05169v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬ç ”ç©¶è¯„ä¼°äº†è‚½å—ä½“æ”¾å°„æ€§æ ¸ç´ ç–—æ³•ï¼ˆPRRTï¼‰æ²»ç–—è½¬ç§»æ€§ç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤ï¼ˆNETsï¼‰åï¼Œé€šè¿‡å®éªŒå®¤æ£€æµ‹ã€å½±åƒæŠ€æœ¯ä»¥åŠå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ æ¨¡å‹é¢„æµ‹æ— è¿›å±•ç”Ÿå­˜æœŸï¼ˆPFSï¼‰çš„æ–¹æ³•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¤šæ¨¡æ€èåˆæ¨¡å‹ç»“åˆå®éªŒå®¤æ£€æµ‹ã€SR-PETå’ŒCTæ•°æ®èƒ½å¤Ÿè¾¾åˆ°æœ€ä½³é¢„æµ‹æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶èƒŒæ™¯ï¼šè™½ç„¶PRRTæ˜¯æ²»ç–—è½¬ç§»æ€§NETsçš„æ—¢å®šæ–¹æ³•ï¼Œä½†é•¿æœŸç–¾ç—…æ§åˆ¶ä»…å‘ç”Ÿåœ¨éƒ¨åˆ†æ‚£è€…ä¸­ã€‚é¢„æµ‹PFSæœ‰åŠ©äºæ”¯æŒä¸ªä½“åŒ–æ²»ç–—è®¡åˆ’ã€‚</li>
<li>ç ”ç©¶æ–¹æ³•ï¼šæœ¬ç ”ç©¶é‡‡ç”¨å›é¡¾æ€§ã€å•ä¸­å¿ƒç ”ç©¶ï¼Œçº³å…¥116ä¾‹æ¥å—177Lu-DOTATOCæ²»ç–—çš„è½¬ç§»æ€§NETsæ‚£è€…ï¼Œæ”¶é›†ä¸´åºŠç‰¹å¾ã€å®éªŒå®¤å€¼ä»¥åŠæ²»ç–—å‰ä½“ç´ å—ä½“æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æ&#x2F;è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆSR-PET&#x2F;CTï¼‰æ•°æ®ã€‚</li>
<li>é¢„æµ‹æ¨¡å‹ï¼šè®­ç»ƒäº†åŒ…æ‹¬å•æ¨¡æ€ï¼ˆå®éªŒå®¤ã€SR-PETæˆ–CTï¼‰å’Œå¤šæ¨¡æ€èåˆæ–¹æ³•ç­‰åœ¨å†…çš„7ä¸ªæ¨¡å‹æ¥åˆ†ç±»ä½PFSä¸é«˜PFSç»„ã€‚</li>
<li>ç»“æœåˆ†æï¼šå®éªŒå®¤ç”Ÿç‰©æ ‡å¿—ç‰©éšæœºæ£®æ—æ¨¡å‹è¾¾åˆ°AUROC 0.59Â±0.02ã€‚SR-PETæˆ–CTçš„å•æ¨¡æ€ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œè¡¨ç°è¾ƒå·®ã€‚å¤šæ¨¡æ€èåˆæ¨¡å‹ç»“åˆå®éªŒå®¤å€¼ã€SR-PETå’ŒCTæ•°æ®ï¼Œå¹¶è¾…ä»¥é¢„è®­ç»ƒCTåˆ†æ”¯ï¼Œå–å¾—æœ€ä½³ç»“æœï¼ŒAUROCä¸º0.72Â±0.01ï¼ŒAUPRCä¸º0.80Â±0.01ã€‚</li>
<li>é‡è¦æ€§åˆ†æï¼šå¤šæ¨¡æ€æ·±åº¦å­¦ä¹ ç»“åˆSR-PETã€CTå’Œå®éªŒå®¤ç”Ÿç‰©æ ‡å¿—ç‰©åœ¨é¢„æµ‹PRRTåçš„PFSæ–¹é¢ä¼˜äºå•æ¨¡æ€æ–¹æ³•ã€‚æœªæ¥ç»è¿‡å¤–éƒ¨éªŒè¯åï¼Œæ­¤ç±»æ¨¡å‹å¯æ”¯æŒé£é™©é€‚åº”çš„éšè®¿ç­–ç•¥ã€‚</li>
<li>ç ”ç©¶äº®ç‚¹ï¼šå¤šæ¨¡æ€èåˆæ–¹æ³•è¡¨ç°å‡ºæœ€ä½³é¢„æµ‹æ€§èƒ½ï¼Œæ•´åˆäº†ä¸åŒæ•°æ®æ¨¡æ€çš„ä¼˜åŠ¿ï¼Œæœ‰åŠ©äºæé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.05169">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-99c7d3f7ab5f5dd704a946bb5fd6ac01" align="middle">
<img src="https://picx.zhimg.com/v2-1648495cd2ab8350c854071cf61cb2aa" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Medical-Referring-Image-Segmentation-via-Next-Token-Mask-Prediction"><a href="#Medical-Referring-Image-Segmentation-via-Next-Token-Mask-Prediction" class="headerlink" title="Medical Referring Image Segmentation via Next-Token Mask Prediction"></a>Medical Referring Image Segmentation via Next-Token Mask Prediction</h2><p><strong>Authors:Xinyu Chen, Yiran Wang, Gaoyang Pang, Jiafu Hao, Chentao Yue, Luping Zhou, Yonghui Li</strong></p>
<p>Medical Referring Image Segmentation (MRIS) involves segmenting target regions in medical images based on natural language descriptions. While achieving promising results, recent approaches usually involve complex design of multimodal fusion or multi-stage decoders. In this work, we propose NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive next-token prediction task over a unified multimodal sequence of tokenized image, text, and mask representations. This formulation streamlines model design by eliminating the need for modality-specific fusion and external segmentation models, supports a unified architecture for end-to-end training. It also enables the use of pretrained tokenizers from emerging large-scale multimodal models, enhancing generalization and adaptability. More importantly, to address challenges under this formulation-such as exposure bias, long-tail token distributions, and fine-grained lesion edges-we propose three novel strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance boundary sensitivity and mitigate long-tail distribution effects, and (3) a memory-based Hard Error Token (HET) optimization strategy that emphasizes difficult tokens during training. Extensive experiments on the QaTa-COV19 and MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art performance, offering a streamlined and effective alternative to traditional MRIS pipelines. </p>
<blockquote>
<p>åŒ»å­¦å‚è€ƒå›¾åƒåˆ†å‰²ï¼ˆMRISï¼‰æ¶‰åŠæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°å¯¹åŒ»å­¦å›¾åƒä¸­çš„ç›®æ ‡åŒºåŸŸè¿›è¡Œåˆ†å‰²ã€‚è™½ç„¶è¿‘æœŸçš„æ–¹æ³•å–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å®ƒä»¬é€šå¸¸æ¶‰åŠå¤æ‚çš„å¤šæ¨¡æ€èåˆè®¾è®¡æˆ–å¤šé˜¶æ®µè§£ç å™¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†NTP-MRISegï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œå®ƒå°†MRISé‡æ–°è¡¨è¿°ä¸ºä¸€ä¸ªåœ¨ä»¤ç‰ŒåŒ–å›¾åƒã€æ–‡æœ¬å’Œæ©ç è¡¨ç¤ºçš„ç»Ÿä¸€å¤šæ¨¡æ€åºåˆ—ä¸Šçš„è‡ªå›å½’ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹ä»»åŠ¡ã€‚è¿™ç§è¡¨è¿°ç®€åŒ–äº†æ¨¡å‹è®¾è®¡ï¼Œæ¶ˆé™¤äº†å¯¹ç‰¹å®šæ¨¡æ€èåˆå’Œå¤–éƒ¨åˆ†å‰²æ¨¡å‹çš„éœ€æ±‚ï¼Œæ”¯æŒç«¯åˆ°ç«¯çš„ç»Ÿä¸€æ¶æ„è¿›è¡Œè®­ç»ƒã€‚å®ƒè¿˜å…è®¸ä½¿ç”¨æ¥è‡ªæ–°å…´å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹çš„é¢„è®­ç»ƒä»¤ç‰Œå™¨ï¼Œå¢å¼ºäº†é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ä¸‹çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚æš´éœ²åå·®ã€é•¿å°¾ä»¤ç‰Œåˆ†å¸ƒå’Œç²¾ç»†ç—…å˜è¾¹ç¼˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ–°çš„ç­–ç•¥ï¼šï¼ˆ1ï¼‰ä¸€ç§Next-kä»¤ç‰Œé¢„æµ‹ï¼ˆNkTPï¼‰æ–¹æ¡ˆï¼Œä»¥å‡å°‘ç´¯ç§¯é¢„æµ‹é”™è¯¯ï¼Œï¼ˆ2ï¼‰ä»¤ç‰Œçº§å¯¹æ¯”å­¦ä¹ ï¼ˆTCLï¼‰ä»¥å¢å¼ºè¾¹ç•Œæ•æ„Ÿæ€§å’Œå‡è½»é•¿å°¾åˆ†å¸ƒçš„å½±å“ï¼Œï¼ˆ3ï¼‰ä¸€ç§åŸºäºå†…å­˜çš„ç¡¬é”™è¯¯ä»¤ç‰Œï¼ˆHETï¼‰ä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼ºè°ƒå›°éš¾ä»¤ç‰Œã€‚åœ¨QaTa-COV19å’ŒMosMedData+æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒNTP-MRISegè¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸ºä¼ ç»Ÿçš„MRISç®¡é“æä¾›äº†ç®€åŒ–è€Œæœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.05044v1">PDF</a> This work has been submitted to the IEEE Transactions on Medical   Imaging for possible publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•â€”â€”NTP-MRISegæ¡†æ¶ï¼Œå®ƒå°†åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªç»Ÿä¸€çš„åºåˆ—é¢„æµ‹ä»»åŠ¡ï¼Œé€šè¿‡ç»Ÿä¸€çš„ç«¯åˆ°ç«¯è®­ç»ƒæ¶æ„å®ç°å›¾åƒã€æ–‡æœ¬å’Œæ©ç çš„å¤šæ¨¡æ€èåˆã€‚æ¡†æ¶åŒ…æ‹¬å¤šç§æ–°ç­–ç•¥ä»¥ä¼˜åŒ–é¢„æµ‹ç»“æœï¼Œå¦‚å‡å°‘ç´¯ç§¯é¢„æµ‹è¯¯å·®çš„ä¸‹ä¸€ä¸ªKä¸ªä»¤ç‰Œé¢„æµ‹æ–¹æ¡ˆï¼Œå¢å¼ºè¾¹ç•Œæ•æ„Ÿæ€§å’Œç¼“è§£é•¿å°¾åˆ†å¸ƒæ•ˆåº”çš„ä»¤ç‰Œçº§å¯¹æ¯”å­¦ä¹ ï¼Œä»¥åŠåŸºäºå†…å­˜çš„é”™è¯¯ä»¤ç‰Œä¼˜åŒ–ç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼ŒNTP-MRISegåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—äº†æœ€æ–°æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NTP-MRISegå°†åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡è½¬åŒ–ä¸ºåºåˆ—é¢„æµ‹ä»»åŠ¡ï¼Œç®€åŒ–äº†æ¨¡å‹è®¾è®¡ã€‚</li>
<li>åˆ©ç”¨ç»Ÿä¸€çš„å¤šæ¨¡æ€åºåˆ—ä»¤ç‰ŒåŒ–æŠ€æœ¯å®ç°äº†ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¶æ„ã€‚</li>
<li>æ¡†æ¶å¯ä»¥åˆ©ç”¨é¢„è®­ç»ƒçš„ä»¤ç‰ŒåŒ–å™¨æé«˜æ³›åŒ–å’Œé€‚åº”æ€§ã€‚</li>
<li>æå‡ºä¸‰ç§æ–°ç­–ç•¥ï¼šä¸‹ä¸€ä¸ªKä¸ªä»¤ç‰Œé¢„æµ‹æ–¹æ¡ˆå‡å°‘é¢„æµ‹è¯¯å·®ï¼Œä»¤ç‰Œçº§å¯¹æ¯”å­¦ä¹ å¢å¼ºè¾¹ç•Œæ•æ„Ÿæ€§å’Œç¼“è§£é•¿å°¾åˆ†å¸ƒæ•ˆåº”ï¼ŒåŸºäºå†…å­˜çš„é”™è¯¯ä»¤ç‰Œä¼˜åŒ–ç­–ç•¥å¼ºåŒ–è®­ç»ƒè¿‡ç¨‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.05044">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f99515a611ca8f46557b065be6c660f1" align="middle">
<img src="https://picx.zhimg.com/v2-b2e110f0dcbc5168069a9c367fb7d6ff" align="middle">
<img src="https://picx.zhimg.com/v2-8540d900d408488d5020581635f5d7df" align="middle">
<img src="https://picx.zhimg.com/v2-2391e92ed39d1f7ce5a1e7d8d3edd1e3" align="middle">
<img src="https://picx.zhimg.com/v2-a32d00674a8f83d6629fbe8b1780cb0c" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Pattern-Aware-Diffusion-Synthesis-of-fMRI-dMRI-with-Tissue-and-Microstructural-Refinement"><a href="#Pattern-Aware-Diffusion-Synthesis-of-fMRI-dMRI-with-Tissue-and-Microstructural-Refinement" class="headerlink" title="Pattern-Aware Diffusion Synthesis of fMRI&#x2F;dMRI with Tissue and   Microstructural Refinement"></a>Pattern-Aware Diffusion Synthesis of fMRI&#x2F;dMRI with Tissue and   Microstructural Refinement</h2><p><strong>Authors:Xiongri Shen, Jiaqi Wang, Yi Zhong, Zhenxi Song, Leilei Zhao, Yichen Wei, Lingyan Liang, Shuqiang Wang, Baiying Lei, Demao Deng, Zhiguo Zhang</strong></p>
<p>Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and diffusion MRI (dMRI), is essential for studying neurodegenerative diseases. However, missing modalities pose a major barrier to their clinical use. Although GAN- and diffusion model-based approaches have shown some promise in modality completion, they remain limited in fMRI-dMRI synthesis due to (1) significant BOLD vs. diffusion-weighted signal differences between fMRI and dMRI in time&#x2F;gradient axis, and (2) inadequate integration of disease-related neuroanatomical patterns during generation. To address these challenges, we propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D diffusion framework for cross-modality learning, and (2) a tissue refinement network integrated with a efficient microstructure refinement to maintain structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house datasets, our method achieves state-of-the-art results, with PSNR&#x2F;SSIM scores of 29.83 dB&#x2F;90.84% for fMRI synthesis (+1.54 dB&#x2F;+4.12% over baselines) and 30.00 dB&#x2F;77.55% for dMRI synthesis (+1.02 dB&#x2F;+2.2%). In clinical validation, the synthesized data show strong diagnostic performance, achieving 67.92%&#x2F;66.02%&#x2F;64.15% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic experiments. Code is available in \href{<a target="_blank" rel="noopener" href="https://github.com/SXR3015/PDS%7D%7BPDS">https://github.com/SXR3015/PDS}{PDS</a> GitHub Repository} </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ï¼Œç‰¹åˆ«æ˜¯åŠŸèƒ½ç£å…±æŒ¯æˆåƒï¼ˆfMRIï¼‰å’Œæ‰©æ•£ç£å…±æŒ¯æˆåƒï¼ˆdMRIï¼‰ï¼Œåœ¨ç ”ç©¶ç¥ç»é€€è¡Œæ€§ç–¾ç—…ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚ç„¶è€Œï¼Œç¼ºä¹æ¨¡æ€æ˜¯å…¶åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„ä¸€å¤§éšœç¢ã€‚è™½ç„¶åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•åœ¨æ¨¡æ€è¡¥å…¨æ–¹é¢æ˜¾ç¤ºå‡ºäº†ä¸€äº›å‰æ™¯ï¼Œä½†ç”±äºï¼ˆ1ï¼‰fMRIå’ŒdMRIåœ¨æ—¶é—´&#x2F;æ¢¯åº¦è½´ä¸Šçš„BOLDä¸æ‰©æ•£åŠ æƒä¿¡å·å·®å¼‚æ˜¾è‘—ï¼Œï¼ˆ2ï¼‰åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç–¾ç—…ç›¸å…³ç¥ç»è§£å‰–æ¨¡å¼çš„æ•´åˆä¸è¶³ï¼Œå®ƒä»¬åœ¨fMRI-dMRIåˆæˆæ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†PDSæ–¹æ³•ï¼Œå¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰ä¸€ç§æ¨¡å¼æ„ŸçŸ¥åŒæ¨¡æ€3Dæ‰©æ•£æ¡†æ¶ï¼Œç”¨äºè·¨æ¨¡æ€å­¦ä¹ ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªä¸é«˜æ•ˆå¾®è§‚ç»“æ„ç»†åŒ–ç›¸ç»“åˆçš„ç»„ç»‡ç»†åŒ–ç½‘ç»œï¼Œä»¥ä¿æŒç»“æ„ä¿çœŸåº¦å’Œç»†èŠ‚ã€‚åœ¨OASIS-3ã€ADNIå’Œå†…éƒ¨æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„ç»“æœï¼ŒfMRIåˆæˆçš„PSNR&#x2F;SSIMåˆ†æ•°ä¸º29.83 dB&#x2F;90.84%ï¼ˆæ¯”åŸºçº¿é«˜å‡º1.54 dB&#x2F; + 4.12ï¼…ï¼‰ï¼ŒdMRIåˆæˆçš„PSNR&#x2F;SSIMåˆ†æ•°ä¸º30.00 dB&#x2F;77.55ï¼… ï¼ˆæ¯”åŸºçº¿é«˜å‡º1.02 dB&#x2F;+ 2.2ï¼…ï¼‰ã€‚åœ¨ä¸´åºŠéªŒè¯ä¸­ï¼Œåˆæˆæ•°æ®æ˜¾ç¤ºäº†å¼ºå¤§çš„è¯Šæ–­æ€§èƒ½ï¼Œåœ¨æ··åˆçœŸå®-åˆæˆå®éªŒä¸­å®ç°äº†å¯¹NCä¸MCIä¸ADè¯Šæ–­çš„67.92ï¼…&#x2F; 66.02ï¼…&#x2F; 64.15ï¼…çš„å‡†ç¡®ç‡ã€‚ä»£ç å¯åœ¨PDS GitHub Repositoryï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/SXR3015/PDS%EF%BC%89%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/SXR3015/PDSï¼‰ä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.04963v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ–‡æœ¬ä¸­æåˆ°åˆ©ç”¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­çš„åŠŸèƒ½MRIï¼ˆfMRIï¼‰å’Œæ‰©æ•£MRIï¼ˆdMRIï¼‰æ¥ç ”ç©¶ç¥ç»é€€è¡Œæ€§ç–¾ç—…çš„é‡è¦æ€§ï¼Œä½†ç¼ºå¤±çš„æ¨¡å¼æ˜¯ä¸´åºŠåº”ç”¨çš„ä¸»è¦éšœç¢ã€‚è™½ç„¶åŸºäºGANå’Œæ‰©æ•£æ¨¡å‹çš„æ¨¡æ€å®Œæˆæ³•æ˜¾ç¤ºå‡ºäº†ä¸€äº›æ½œåŠ›ï¼Œä½†ç”±äºfMRIå’ŒdMRIåœ¨æ—¶é—´&#x2F;æ¢¯åº¦è½´ä¸Šçš„BOLDä¸æ‰©æ•£åŠ æƒä¿¡å·å·®å¼‚æ˜¾è‘—ï¼Œä»¥åŠåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç–¾ç—…ç›¸å…³ç¥ç»è§£å‰–å­¦æ¨¡å¼çš„æ•´åˆä¸è¶³ï¼Œå®ƒä»¬åœ¨fMRI-dMRIåˆæˆä¸­ä»å—åˆ°é™åˆ¶ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†PDSæ–¹æ³•ï¼Œå¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯æ¨¡å¼æ„ŸçŸ¥åŒæ¨¡æ€3Dæ‰©æ•£æ¡†æ¶ï¼Œç”¨äºè·¨æ¨¡æ€å­¦ä¹ ï¼›äºŒæ˜¯ç»“åˆé«˜æ•ˆå¾®è§‚ç»“æ„ç²¾åŒ–çš„ç»„ç»‡ç»†åŒ–ç½‘ç»œï¼Œä»¥ä¿æŒç»“æ„ä¿çœŸåº¦å’Œç»†èŠ‚ã€‚åœ¨OASIS-3ã€ADNIå’Œå†…éƒ¨æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ŒfMRIåˆæˆçš„PSNR&#x2F;SSIMåˆ†æ•°ä¸º29.83 dB&#x2F;90.84%ï¼ˆæ¯”åŸºçº¿é«˜å‡º1.54 dB&#x2F;4.12%ï¼‰ï¼ŒdMRIåˆæˆçš„PSNR&#x2F;SSIMåˆ†æ•°ä¸º30.00 dB&#x2F;77.55%ï¼ˆæ¯”åŸºçº¿é«˜å‡º1.02 dB&#x2F;2.2%ï¼‰ã€‚åœ¨ä¸´åºŠéªŒè¯ä¸­ï¼Œåˆæˆæ•°æ®è¡¨ç°å‡ºå¼ºå¤§çš„è¯Šæ–­æ€§èƒ½ï¼Œåœ¨æ··åˆçœŸå®-åˆæˆå®éªŒä¸­ï¼Œå¯¹NCä¸MCIåŠADçš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°67.92%&#x2F;66.02%&#x2F;64.15%ã€‚ç›¸å…³ä»£ç å¯åœ¨PDS GitHub Repositoryæ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸­çš„åŠŸèƒ½MRIï¼ˆfMRIï¼‰å’Œæ‰©æ•£MRIï¼ˆdMRIï¼‰åœ¨ç ”ç©¶ç¥ç»é€€è¡Œæ€§ç–¾ç—…ä¸­å…·æœ‰é‡è¦ä½œç”¨ã€‚</li>
<li>ç¼ºå¤±çš„æ¨¡å¼æ˜¯MRIåœ¨ä¸´åºŠåº”ç”¨ä¸­çš„ä¸»è¦éšœç¢ä¹‹ä¸€ã€‚</li>
<li>åŸºäºGANå’Œæ‰©æ•£æ¨¡å‹çš„æ¨¡æ€å®Œæˆæ³•åœ¨fMRI-dMRIåˆæˆä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ä¿¡å·å·®å¼‚å’Œç–¾ç—…ç›¸å…³ç¥ç»è§£å‰–å­¦æ¨¡å¼çš„æ•´åˆé—®é¢˜ã€‚</li>
<li>PDSæ–¹æ³•é€šè¿‡å¼•å…¥æ¨¡å¼æ„ŸçŸ¥åŒæ¨¡æ€3Dæ‰©æ•£æ¡†æ¶å’Œç»“åˆå¾®è§‚ç»“æ„ç²¾åŒ–çš„ç»„ç»‡ç»†åŒ–ç½‘ç»œï¼Œè§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>PDSæ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶åœ¨ä¸´åºŠéªŒè¯ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„è¯Šæ–­æ€§èƒ½ã€‚</li>
<li>PDSæ–¹æ³•çš„fMRIå’ŒdMRIåˆæˆç»“æœå…·æœ‰è¾ƒé«˜çš„PSNRå’ŒSSIMåˆ†æ•°ï¼Œè¡¨æ˜å…¶è‰¯å¥½çš„å›¾åƒè´¨é‡å’Œç»“æ„ç›¸ä¼¼æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.04963">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1d7e361bff50c884ca7a17bc013815bf" align="middle">
<img src="https://picx.zhimg.com/v2-0c319873c0d344d6a4d873a13e494533" align="middle">
<img src="https://picx.zhimg.com/v2-f13443724e3a713f508025d735be8157" align="middle">
<img src="https://picx.zhimg.com/v2-f3c20235b3f0c8293e46246d51300f28" align="middle">
<img src="https://picx.zhimg.com/v2-ace157c890fa8f94c50aa042eab1386a" align="middle">
<img src="https://picx.zhimg.com/v2-1799fa2f248ab539083b3e1551f3b8ad" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="An-Active-Learning-Pipeline-for-Biomedical-Image-Instance-Segmentation-with-Minimal-Human-Intervention"><a href="#An-Active-Learning-Pipeline-for-Biomedical-Image-Instance-Segmentation-with-Minimal-Human-Intervention" class="headerlink" title="An Active Learning Pipeline for Biomedical Image Instance Segmentation   with Minimal Human Intervention"></a>An Active Learning Pipeline for Biomedical Image Instance Segmentation   with Minimal Human Intervention</h2><p><strong>Authors:Shuo Zhao, Yu Zhou, Jianxu Chen</strong></p>
<p>Biomedical image segmentation is critical for precise structure delineation and downstream analysis. Traditional methods often struggle with noisy data, while deep learning models such as U-Net have set new benchmarks in segmentation performance. nnU-Net further automates model configuration, making it adaptable across datasets without extensive tuning. However, it requires a substantial amount of annotated data for cross-validation, posing a challenge when only raw images but no labels are available. Large foundation models offer zero-shot generalizability, but may underperform on specific datasets with unique characteristics, limiting their direct use for analysis. This work addresses these bottlenecks by proposing a data-centric AI workflow that leverages active learning and pseudo-labeling to combine the strengths of traditional neural networks and large foundation models while minimizing human intervention. The pipeline starts by generating pseudo-labels from a foundation model, which are then used for nnU-Netâ€™s self-configuration. Subsequently, a representative core-set is selected for minimal manual annotation, enabling effective fine-tuning of the nnU-Net model. This approach significantly reduces the need for manual annotations while maintaining competitive performance, providing an accessible solution for biomedical researchers to apply state-of-the-art AI techniques in their segmentation tasks. The code is available at <a target="_blank" rel="noopener" href="https://github.com/MMV-Lab/AL_BioMed_img_seg">https://github.com/MMV-Lab/AL_BioMed_img_seg</a>. </p>
<blockquote>
<p>ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹äºç²¾ç¡®ç»“æ„ç•Œå®šå’Œä¸‹æ¸¸åˆ†æè‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†å™ªå£°æ•°æ®æ—¶ç»å¸¸é‡åˆ°å›°éš¾ï¼Œè€ŒU-Netç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨åˆ†å‰²æ€§èƒ½ä¸Šè®¾å®šäº†æ–°çš„åŸºå‡†ã€‚nnU-Netè¿›ä¸€æ­¥è‡ªåŠ¨åŒ–äº†æ¨¡å‹é…ç½®ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”å„ç§æ•°æ®é›†è€Œæ— éœ€å¤§é‡è°ƒæ•´ã€‚ç„¶è€Œï¼Œå®ƒéœ€è¦è¿›è¡Œå¤§é‡çš„äº¤å‰éªŒè¯æ ‡æ³¨æ•°æ®ï¼Œå½“åªæœ‰åŸå§‹å›¾åƒè€Œæ²¡æœ‰æ ‡ç­¾æ—¶ï¼Œè¿™å°±æ„æˆäº†æŒ‘æˆ˜ã€‚å¤§å‹åŸºç¡€æ¨¡å‹æä¾›é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨å…·æœ‰ç‹¬ç‰¹ç‰¹æ€§çš„ç‰¹å®šæ•°æ®é›†ä¸Šå¯èƒ½ä¼šè¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶ç›´æ¥ç”¨äºåˆ†æã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æå‡ºä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„AIå·¥ä½œæµç¨‹æ¥è§£å†³è¿™äº›ç“¶é¢ˆï¼Œè¯¥æµç¨‹ç»“åˆä¼ ç»Ÿç¥ç»ç½‘ç»œå’Œå¤§å‹åŸºç¡€æ¨¡å‹çš„ä¼˜ç‚¹ï¼ŒåŒæ—¶æœ€å°åŒ–äººå·¥å¹²é¢„ï¼Œåˆ©ç”¨ä¸»åŠ¨å­¦ä¹ å’Œä¼ªæ ‡ç­¾æ ‡æ³¨ã€‚è¯¥æµç¨‹é¦–å…ˆä½¿ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç„¶åç”¨äºnnU-Netçš„è‡ªæˆ‘é…ç½®ã€‚éšåé€‰æ‹©æœ‰ä»£è¡¨æ€§çš„æ ¸å¿ƒé›†è¿›è¡Œæœ€å°æ‰‹åŠ¨æ³¨é‡Šï¼Œå®ç°å¯¹nnU-Netæ¨¡å‹çš„æœ‰æ•ˆå¾®è°ƒã€‚è¿™ç§æ–¹æ³•åœ¨å‡å°‘å¯¹æ‰‹åŠ¨æ³¨é‡Šéœ€æ±‚çš„åŒæ—¶ä¿æŒäº†ç«äº‰åŠ›ï¼Œä¸ºç”Ÿç‰©åŒ»å­¦ç ”ç©¶äººå‘˜åœ¨å…¶åˆ†å‰²ä»»åŠ¡ä¸­åº”ç”¨æœ€å…ˆè¿›çš„AIæŠ€æœ¯æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/MMV-Lab/AL_BioMed_img_seg">https://github.com/MMV-Lab/AL_BioMed_img_seg</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.04811v1">PDF</a> 6 pages, 4 figures, presented at Bildverarbeitung f&quot;ur die Medizin   (BVM) 2025, Wiesbaden, Germany</p>
<p><strong>Summary</strong><br>     ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹äºç²¾ç¡®ç»“æ„è½®å»“æç»˜å’Œä¸‹æ¸¸åˆ†æè‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•å¸¸å¸¸éš¾ä»¥å¤„ç†å™ªå£°æ•°æ®ï¼Œè€Œæ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚U-Netä¸ºåˆ†å‰²æ€§èƒ½è®¾å®šäº†æ–°çš„åŸºå‡†ã€‚nnU-Netè¿›ä¸€æ­¥è‡ªåŠ¨åŒ–æ¨¡å‹é…ç½®ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒæ•°æ®é›†è€Œæ— éœ€å¹¿æ³›è°ƒæ•´ã€‚ç„¶è€Œï¼Œå®ƒéœ€è¦åœ¨å¤§é‡æ ‡æ³¨æ•°æ®ä¸Šè¿›è¡Œäº¤å‰éªŒè¯ï¼Œè¿™å¯¹ä»…æä¾›åŸå§‹å›¾åƒè€Œæ— æ ‡ç­¾çš„æƒ…å†µæå‡ºäº†æŒ‘æˆ˜ã€‚å¤§å‹åŸºç¡€æ¨¡å‹æä¾›é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨å…·æœ‰ç‹¬ç‰¹ç‰¹æ€§çš„ç‰¹å®šæ•°æ®é›†ä¸Šå¯èƒ½è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡è§£å†³è¿™äº›ç“¶é¢ˆï¼Œé€šè¿‡åˆ©ç”¨ä¸»åŠ¨å­¦ä¹ å’Œä¼ªæ ‡ç­¾çš„æ•°æ®ä¸­å¿ƒAIå·¥ä½œæµç¨‹ç»“åˆä¼ ç»Ÿç¥ç»ç½‘ç»œå’Œå¤§å‹åŸºç¡€æ¨¡å‹çš„ä¼˜ç‚¹ï¼ŒåŒæ—¶æœ€å°åŒ–äººå·¥å¹²é¢„ã€‚ä»åŸºç¡€æ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç”¨äºnnU-Netçš„è‡ªæˆ‘é…ç½®ã€‚éšåé€‰æ‹©ä»£è¡¨æ€§æ ¸å¿ƒé›†è¿›è¡Œæœ€å°æ‰‹åŠ¨æ³¨é‡Šï¼Œå®ç°å¯¹nnU-Netæ¨¡å‹çš„æœ‰æ•ˆå¾®è°ƒã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—å‡å°‘äº†å¯¹æ‰‹åŠ¨æ³¨é‡Šçš„éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›æ€§èƒ½ï¼Œä¸ºç”Ÿç‰©åŒ»å­¦ç ”ç©¶äººå‘˜åœ¨å…¶åˆ†å‰²ä»»åŠ¡ä¸­åº”ç”¨æœ€æ–°AIæŠ€æœ¯æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²å¯¹äºåç»­åˆ†æè‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†å™ªå£°æ•°æ®æ—¶è¡¨ç°ä¸ä½³ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚U-Netåœ¨å›¾åƒåˆ†å‰²ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œè€ŒnnU-Netèƒ½è‡ªåŠ¨åŒ–æ¨¡å‹é…ç½®ä»¥é€‚åº”ä¸åŒæ•°æ®é›†ã€‚</li>
<li>nnU-Netéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯ï¼Œè¿™åœ¨ç¼ºä¹æ ‡ç­¾çš„æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>å¤§å‹åŸºç¡€æ¨¡å‹è™½å…·æœ‰é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šå¯èƒ½è¡¨ç°ä¸è¶³ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ•°æ®ä¸­å¿ƒçš„AIå·¥ä½œæµç¨‹ï¼Œç»“åˆäº†ä¼ ç»Ÿç¥ç»ç½‘ç»œå’Œå¤§å‹åŸºç¡€æ¨¡å‹çš„ä¼˜ç‚¹ï¼ŒåŒæ—¶å‡å°‘äº†äººå·¥å¹²é¢„ã€‚</li>
<li>è¯¥æµç¨‹åˆ©ç”¨ä¼ªæ ‡ç­¾å’Œä¸»åŠ¨å­¦ä¹ ï¼Œé€šè¿‡é€‰æ‹©ä»£è¡¨æ€§æ ¸å¿ƒé›†è¿›è¡Œæœ€å°æ‰‹åŠ¨æ³¨é‡Šæ¥ä¼˜åŒ–nnU-Netæ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.04811">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2d4bba85e3a6023818f3103a1ae0a410" align="middle">
<img src="https://picx.zhimg.com/v2-f52a8ffe1d83c0e9eafae88ca232ecf3" align="middle">
<img src="https://picx.zhimg.com/v2-4a4ab5899736ff3d4ff6b62e63fb407f" align="middle">
<img src="https://picx.zhimg.com/v2-def14fecae04f84a2d98097dda0c71fb" align="middle">
<img src="https://picx.zhimg.com/v2-d42712e6572a95a376973d480d508a6d" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Data-Efficiency-and-Transfer-Robustness-in-Biomedical-Image-Segmentation-A-Study-of-Redundancy-and-Forgetting-with-Cellpose"><a href="#Data-Efficiency-and-Transfer-Robustness-in-Biomedical-Image-Segmentation-A-Study-of-Redundancy-and-Forgetting-with-Cellpose" class="headerlink" title="Data Efficiency and Transfer Robustness in Biomedical Image   Segmentation: A Study of Redundancy and Forgetting with Cellpose"></a>Data Efficiency and Transfer Robustness in Biomedical Image   Segmentation: A Study of Redundancy and Forgetting with Cellpose</h2><p><strong>Authors:Shuo Zhao, Jianxu Chen</strong></p>
<p>Generalist biomedical image segmentation models such as Cellpose are increasingly applied across diverse imaging modalities and cell types. However, two critical challenges remain underexplored: (1) the extent of training data redundancy and (2) the impact of cross domain transfer on model retention. In this study, we conduct a systematic empirical analysis of these challenges using Cellpose as a case study. First, to assess data redundancy, we propose a simple dataset quantization (DQ) strategy for constructing compact yet diverse training subsets. Experiments on the Cyto dataset show that image segmentation performance saturates with only 10% of the data, revealing substantial redundancy and potential for training with minimal annotations. Latent space analysis using MAE embeddings and t-SNE confirms that DQ selected patches capture greater feature diversity than random sampling. Second, to examine catastrophic forgetting, we perform cross domain finetuning experiments and observe significant degradation in source domain performance, particularly when adapting from generalist to specialist domains. We demonstrate that selective DQ based replay reintroducing just 5-10% of the source data effectively restores source performance, while full replay can hinder target adaptation. Additionally, we find that training domain sequencing improves generalization and reduces forgetting in multi stage transfer. Our findings highlight the importance of data centric design in biomedical image segmentation and suggest that efficient training requires not only compact subsets but also retention aware learning strategies and informed domain ordering. The code is available at <a target="_blank" rel="noopener" href="https://github.com/MMV-Lab/biomedseg-efficiency">https://github.com/MMV-Lab/biomedseg-efficiency</a>. </p>
<blockquote>
<p>é€šç”¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ï¼ˆå¦‚Cellposeï¼‰åœ¨å¤šç§æˆåƒæ¨¡å¼å’Œç»†èƒç±»å‹ä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ã€‚ç„¶è€Œï¼Œè¿˜æœ‰ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ï¼šï¼ˆ1ï¼‰è®­ç»ƒæ•°æ®å†—ä½™çš„ç¨‹åº¦ä»¥åŠï¼ˆ2ï¼‰è·¨åŸŸè½¬ç§»å¯¹æ¨¡å‹ä¿ç•™çš„å½±å“ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä»¥Cellposeä¸ºæ¡ˆä¾‹ï¼Œå¯¹è¿™äº›æŒ‘æˆ˜è¿›è¡Œäº†ç³»ç»Ÿçš„å®è¯åˆ†æã€‚é¦–å…ˆï¼Œä¸ºäº†è¯„ä¼°æ•°æ®å†—ä½™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„æ•°æ®é›†é‡åŒ–ï¼ˆDQï¼‰ç­–ç•¥ï¼Œç”¨äºæ„å»ºç´§å‡‘ä¸”å¤šæ ·åŒ–çš„è®­ç»ƒå­é›†ã€‚åœ¨Cytoæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨10%çš„æ•°æ®ï¼Œå›¾åƒåˆ†å‰²æ€§èƒ½å°±è¾¾åˆ°é¥±å’Œï¼Œè¿™æ­ç¤ºäº†å¤§é‡çš„æ•°æ®å†—ä½™å’Œå°‘é‡æ³¨é‡Šè¿›è¡Œè®­ç»ƒçš„å¯èƒ½æ€§ã€‚ä½¿ç”¨MAEåµŒå…¥å’Œt-SNEè¿›è¡Œçš„æ½œåœ¨ç©ºé—´åˆ†æè¯å®ï¼ŒDQé€‰æ‹©çš„è¡¥ä¸æ¯”éšæœºæŠ½æ ·æ›´èƒ½æ•æ‰ç‰¹å¾å¤šæ ·æ€§ã€‚å…¶æ¬¡ï¼Œä¸ºäº†ç ”ç©¶ç¾éš¾æ€§é—å¿˜ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è·¨åŸŸå¾®è°ƒå®éªŒï¼Œå¹¶è§‚å¯Ÿåˆ°æºåŸŸæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»é€šç”¨é¢†åŸŸè½¬å‘ä¸“ä¸šé¢†åŸŸæ—¶ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒåŸºäºé€‰æ‹©æ€§DQé‡æ’­ä»…é‡æ–°å¼•å…¥5-10%çš„æºæ•°æ®å³å¯æœ‰æ•ˆæ¢å¤æºæ€§èƒ½ï¼Œè€Œå…¨é¢é‡æ’­å¯èƒ½ä¼šé˜»ç¢ç›®æ ‡é€‚åº”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°è®­ç»ƒåŸŸæ’åºæ”¹è¿›äº†æ³›åŒ–å¹¶åœ¨å¤šé˜¶æ®µè½¬ç§»ä¸­å‡å°‘äº†é—å¿˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ•°æ®ä¸ºä¸­å¿ƒçš„è®¾è®¡åœ¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„é‡è¦æ€§ï¼Œå¹¶è¡¨æ˜é«˜æ•ˆè®­ç»ƒä¸ä»…éœ€è¦ç´§å‡‘çš„å­é›†ï¼Œè¿˜éœ€è¦ä¿ç•™æ„ŸçŸ¥çš„å­¦ä¹ ç­–ç•¥å’ŒçŸ¥æƒ…çš„åŸŸæ’åºã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MMV-Lab/biomedseg-efficiency%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MMV-Lab/biomedseg-efficiencyä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.04803v1">PDF</a> Accepted to IEEE BIBM 2025 Workshop; 6 pages; 4 figures; 5 tables;   IEEEtran class. Code: <a target="_blank" rel="noopener" href="https://github.com/MMV-Lab/biomedseg-efficiency">https://github.com/MMV-Lab/biomedseg-efficiency</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶é’ˆå¯¹ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ï¼ˆå¦‚Cellposeï¼‰åœ¨å¤šæ ·æˆåƒæ¨¡æ€å’Œç»†èƒç±»å‹ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç³»ç»Ÿæ€§åœ°æ¢è®¨äº†ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šè®­ç»ƒæ•°æ®å†—ä½™å’Œè·¨åŸŸè¿ç§»å¯¹æ¨¡å‹ä¿ç•™çš„å½±å“ã€‚ç ”ç©¶é€šè¿‡æ•°æ®é›†é‡åŒ–ç­–ç•¥è¯„ä¼°æ•°æ®å†—ä½™ï¼Œå‘ç°ä»…ä½¿ç”¨10%çš„æ•°æ®å³å¯è¾¾åˆ°å›¾åƒåˆ†å‰²æ€§èƒ½é¥±å’Œï¼Œè¡¨æ˜å­˜åœ¨å¤§é‡å†—ä½™ï¼Œå¯è¿›è¡Œæœ€å°æ ‡æ³¨è®­ç»ƒã€‚åŒæ—¶ï¼Œç ”ç©¶é€šè¿‡æ½œåœ¨ç©ºé—´åˆ†æç¡®è®¤é‡åŒ–é€‰å–çš„è¡¥ä¸èƒ½å¤Ÿæ•æ‰æ›´å¤šçš„ç‰¹å¾å¤šæ ·æ€§ã€‚åœ¨è€ƒå¯Ÿç¾éš¾é—å¿˜æ–¹é¢ï¼Œç ”ç©¶è¿›è¡Œäº†è·¨åŸŸå¾®è°ƒå®éªŒï¼Œè§‚å¯Ÿåˆ°æºåŸŸæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»é€šç”¨é¢†åŸŸåˆ°ä¸“ä¸šé¢†åŸŸè½¬å˜æ—¶ã€‚é€šè¿‡é€‰æ‹©æ€§å›æ”¾å’Œè®­ç»ƒåŸŸæ’åºç­–ç•¥ï¼Œç ”ç©¶æœ‰æ•ˆåœ°æ¢å¤äº†æºåŸŸæ€§èƒ½å¹¶æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†æ•°æ®ä¸ºä¸­å¿ƒçš„ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²è®¾è®¡çš„é‡è¦æ€§ï¼Œå»ºè®®é«˜æ•ˆè®­ç»ƒéœ€è¦ç²¾ç®€å­é›†ã€ä¿ç•™æ„ŸçŸ¥å­¦ä¹ ç­–ç•¥å’Œæ˜æ™ºçš„åŸŸæ’åºã€‚ç›¸å…³ä»£ç å·²å…¬å¼€åˆ†äº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Cellposeç­‰é€šç”¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹é¢ä¸´è®­ç»ƒæ•°æ®å†—ä½™å’Œè·¨åŸŸè¿ç§»æŒ‘æˆ˜ã€‚</li>
<li>æ•°æ®é›†é‡åŒ–ç­–ç•¥ç”¨äºè¯„ä¼°æ•°æ®å†—ä½™ï¼Œæ˜¾ç¤ºä»…ä½¿ç”¨å°‘é‡æ•°æ®å³å¯è¾¾åˆ°æ€§èƒ½é¥±å’Œã€‚</li>
<li>é€šè¿‡æ½œåœ¨ç©ºé—´åˆ†æç¡®è®¤é‡åŒ–é€‰å–çš„æ•°æ®ç‰‡æ®µå…·æœ‰æ›´å¤§çš„ç‰¹å¾å¤šæ ·æ€§ã€‚</li>
<li>è·¨åŸŸå¾®è°ƒå®éªŒä¸­è§‚å¯Ÿåˆ°æºåŸŸæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚</li>
<li>é€‰æ‹©æ€§å›æ”¾ç­–ç•¥å¯æœ‰æ•ˆåœ°æ¢å¤æºåŸŸæ€§èƒ½å¹¶å‡å°‘ç›®æ ‡åŸŸé€‚åº”éšœç¢ã€‚</li>
<li>è®­ç»ƒåŸŸæ’åºç­–ç•¥æœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œå‡å°‘é—å¿˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.04803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2a22506cedf3356a188ae90eab435dfb" align="middle">
<img src="https://picx.zhimg.com/v2-387ee04f3a09f17a0326ba441abc0351" align="middle">
<img src="https://picx.zhimg.com/v2-845c4cf727e0de4b0c5ca1b85f4718b7" align="middle">
<img src="https://picx.zhimg.com/v2-a9b2ab56ad8af3a13ff079b30e38cb21" align="middle">
<img src="https://picx.zhimg.com/v2-e253d1c2b93cb11e34f90ba51479c6da" align="middle">
<img src="https://picx.zhimg.com/v2-5fad8525f6a14bee5aca5677d7fe0b09" align="middle">
<img src="https://picx.zhimg.com/v2-3c3d98c39f8b74aad31c33ec72e667cb" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="The-nexus-between-negative-charge-transfer-and-reduced-on-site-Coulomb-energy-in-correlated-topological-metals"><a href="#The-nexus-between-negative-charge-transfer-and-reduced-on-site-Coulomb-energy-in-correlated-topological-metals" class="headerlink" title="The nexus between negative charge-transfer and reduced on-site Coulomb   energy in correlated topological metals"></a>The nexus between negative charge-transfer and reduced on-site Coulomb   energy in correlated topological metals</h2><p><strong>Authors:A. R. Shelke, C. -W. Chuang, S. Hamamoto, M. Oura, M. Yoshimura, N. Hiraoka, C. -N. Kuo, C. -S. Lue, A. Fujimori, A. Chainani</strong></p>
<p>The layered $3d$ transition metal dichalcogenides (TMDs) CoTe$<em>2$ and NiTe$<em>2$ are topological Dirac Type-II metals. Their $d$-bands do not exhibit the expected correlation-induced band narrowing seen in CoO and NiO. We address this conundrum by quantifying the on-site Coulomb energy $U</em>{dd}$ via single-particle partial density of states and the two-hole correlation satellite using valence band resonant photoemission spectroscopy (PES), and obtain $U</em>{dd}$ &#x3D; 3.0 eV&#x2F;3.7 eV for CoTe$_2$&#x2F;NiTe$<em>2$. Charge-transfer (CT) cluster model simulations of the measured core-level PES and x-ray absorption spectra of CoTe$<em>2$ and CoO validate their contrasting electronic parameters:$U</em>{dd}$ and CT energy $\Delta$ are (3.0 eV, -2.0 eV) for CoTe$<em>2$, and (5.0 eV, 4.0 eV) for CoO, respectively. The $d$-$p$ hybridization strength $T</em>{eg}$ for CoTe$<em>2$$&lt;$CoO, and indicates that the reduced $U_{dd}$ in CoTe$_2$ is not due to $T_{eg}$. The increase in $d^n$-count$\sim$1 by CT from ligand to Co site in CoTe$_2$ is due to a negative-$\Delta$ and reduced $U_{dd}$. Yet, only because $U_{dd}$$&gt;$$\big|\Delta\big|$, CoTe$</em>{2}$ becomes a topological metal with $p$$\rightarrow$${p}$ type lowest energy excitations. Similarly, we obtain a negative-$\Delta$ and reduced $U</em>{dd}$ in NiTe$<em>2$ compared to NiO. The study reveals the nexus between negative-$\Delta$ and reduced $U</em>{dd}$ required for setting up the electronic structure framework for achieving topological behavior via band inversion in correlated metals. </p>
<blockquote>
<p>å±‚çŠ¶ä¸‰ç»´è¿‡æ¸¡é‡‘å±äºŒå¤åŒ–ç‰©ï¼ˆTMDsï¼‰CoTe2å’ŒNiTe2æ˜¯æ‹“æ‰‘ç‹„æ‹‰å…‹äºŒç±»é‡‘å±ã€‚å®ƒä»¬çš„dè½¨é“å¸¦å¹¶æœªè¡¨ç°å‡ºåœ¨CoOå’ŒNiOä¸­é¢„æœŸçš„ç”±å…³è”å¼•èµ·çš„å¸¦éš™å˜çª„ç°è±¡ã€‚æˆ‘ä»¬é€šè¿‡é‡åŒ–åº“ä»‘èƒ½é‡Uddæ¥ç ”ç©¶è¿™ä¸€éš¾é¢˜ï¼Œé‡‡ç”¨å•ç²’å­éƒ¨åˆ†æ€å¯†åº¦å’Œé€šè¿‡ä»·å¸¦å…±æŒ¯å…‰ç”µå­å…‰è°±æ³•ï¼ˆPESï¼‰å¾—åˆ°ä¸¤ç©ºç©´å…³è”å«æ˜Ÿï¼Œå¯¹äºCoTe2å’ŒNiTe2ï¼Œæˆ‘ä»¬å¾—åˆ°Udd&#x3D; 3.0 eV&#x2F;3.7 eVã€‚å¯¹CoTe2å’ŒCoOçš„æµ‹é‡æ ¸å¿ƒèƒ½çº§PESå’ŒXå°„çº¿å¸æ”¶å…‰è°±çš„ç”µè·è½¬ç§»ï¼ˆCTï¼‰é›†ç¾¤æ¨¡å‹æ¨¡æ‹ŸéªŒè¯äº†å…¶å¯¹æ¯”ç”µå­å‚æ•°ï¼šå¯¹äºCoTe2ï¼ŒUddå’Œç”µè·è½¬ç§»èƒ½é‡Î”åˆ†åˆ«ä¸ºï¼ˆ3.0 eVï¼Œ-2.0 eVï¼‰ï¼Œè€Œå¯¹äºCoOåˆ†åˆ«ä¸ºï¼ˆ5.0 eVï¼Œ4.0 eVï¼‰ã€‚CoTe2çš„d-pæ‚åŒ–å¼ºåº¦Tegå°äºCoOï¼Œè¡¨æ˜CoTe2ä¸­Uddçš„å‡å°‘å¹¶éç”±äºTegã€‚CoTe2ä¸­ä»é…ä½“åˆ°Coä½ç‚¹çš„ç”µè·è½¬ç§»å¯¼è‡´dnè®¡æ•°å¢åŠ çº¦1ï¼Œè¿™æ˜¯ç”±äºè´ŸÎ”å’Œå‡å°‘çš„Uddã€‚ç„¶è€Œï¼Œåªæœ‰Udd&gt; |Î”|æ—¶ï¼ŒCoTe2æ‰èƒ½æˆä¸ºå…·æœ‰pâ†’på‹æœ€ä½èƒ½é‡æ¿€å‘çš„æ‹“æ‰‘é‡‘å±ã€‚ç±»ä¼¼åœ°ï¼Œä¸NiOç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨NiTe2ä¸­ä¹Ÿè·å¾—äº†è´ŸÎ”å’Œå‡å°‘çš„Uddã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†è´ŸÎ”å’Œå‡å°‘çš„Uddä¹‹é—´çš„è”ç³»ï¼Œè¿™å¯¹äºé€šè¿‡ç›¸å…³é‡‘å±ä¸­çš„èƒ½å¸¦åè½¬å®ç°æ‹“æ‰‘è¡Œä¸ºçš„ç”µå­ç»“æ„æ¡†æ¶è‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.03299v2">PDF</a> 8 pages + 5 figures(main) and 10 pages + 9 figures (SM) (submitted to   PRB)(corrected reference nos.)</p>
<p><strong>Summary</strong><br>    é’´å’Œé•çš„ä¸‰å…ƒäºŒç»´è¿‡æ¸¡é‡‘å±äºŒç¡«åŒ–ç‰©ï¼ˆTMDsï¼‰CoTe2å’ŒNiTe2æ˜¯æ‹“æ‰‘ç‹„æ‹‰å…‹Type-IIé‡‘å±ã€‚ç ”ç©¶é€šè¿‡æµ‹é‡å•ç²’å­éƒ¨åˆ†æ€å¯†åº¦å’Œä¸¤å­”å…³è”å…‰è°±çš„åº“ä»‘èƒ½é‡Udï¼Œè§£å†³äº†å®ƒä»¬åœ¨då¸¦ä¸Šæœªå‡ºç°é¢„æœŸçš„ç›¸å…³æ€§å¼•èµ·çš„å¸¦çª„åŒ–é—®é¢˜ã€‚å¯¹CoTe2å’ŒNiTe2çš„Udåˆ†åˆ«ä¸º3.0 eVå’Œ3.7 eVã€‚å¯¹CoTe2å’ŒCoOçš„æ ¸å¿ƒèƒ½çº§å…‰ç”µå­å‘å°„å…‰è°±å’ŒXå°„çº¿å¸æ”¶å…‰è°±çš„ç”µè·è½¬ç§»é›†ç¾¤æ¨¡å‹æ¨¡æ‹ŸéªŒè¯äº†å…¶ä¸åŒçš„ç”µå­å‚æ•°ï¼šCoTe2çš„Udå’Œç”µè·è½¬ç§»èƒ½é‡Î”åˆ†åˆ«ä¸º3.0 eVå’Œ-2.0 eVï¼Œè€ŒCoOçš„åˆ†åˆ«ä¸º5.0 eVå’Œ4.0 eVã€‚ç ”ç©¶æ­ç¤ºäº†è´ŸÎ”å’Œé™ä½çš„Udå¯¹äºé€šè¿‡å¸¦åè½¬åœ¨ç›¸å…³é‡‘å±ä¸­å®ç°æ‹“æ‰‘è¡Œä¸ºçš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CoTe2å’ŒNiTe2æ˜¯æ‹“æ‰‘ç‹„æ‹‰å…‹Type-IIé‡‘å±ã€‚</li>
<li>é€šè¿‡æµ‹é‡å•ç²’å­éƒ¨åˆ†æ€å¯†åº¦å’Œä¸¤å­”å…³è”å…‰è°±è§£å†³äº†då¸¦ä¸Šæœªå‡ºç°çš„å¸¦çª„åŒ–é—®é¢˜ã€‚</li>
<li>CoTe2å’ŒNiTe2çš„åº“ä»‘èƒ½é‡Udåˆ†åˆ«ä¸º3.0 eVå’Œ3.7 eVã€‚</li>
<li>ç›¸è¾ƒäºCoOï¼ŒCoTe2çš„d-pæ‚åŒ–å¼ºåº¦Tegè¾ƒä½ã€‚</li>
<li>è´Ÿçš„ç”µè·è½¬ç§»èƒ½é‡Î”å’Œè¾ƒä½çš„Udå­˜åœ¨äºCoTe2å’ŒNiTe2ä¸­ï¼Œç›¸è¾ƒäºå…¶å¯¹åº”çš„æ°§åŒ–ç‰©ï¼ˆå¦‚CoOå’ŒNiOï¼‰ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜è´ŸÎ”å’Œé™ä½çš„Udå¯¹äºåœ¨ç›¸å…³é‡‘å±ä¸­å®ç°æ‹“æ‰‘è¡Œä¸ºè‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.03299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cdfeb79e8d87237e192cf03bde67b97e" align="middle">
<img src="https://picx.zhimg.com/v2-705775a9fde703855acebb460a412a76" align="middle">
<img src="https://picx.zhimg.com/v2-4228be3ee0398f1f5738ceb43b6ee3b6" align="middle">
<img src="https://picx.zhimg.com/v2-1b1859b04f413f06f9552afa90024179" align="middle">
<img src="https://picx.zhimg.com/v2-f4fd181fe6d20d7864c326a049563444" align="middle">
<img src="https://picx.zhimg.com/v2-3ca4968991bf0e0468fafc8f5e628ed1" align="middle">
<img src="https://picx.zhimg.com/v2-178922d3d63a936d99b568e4d346d092" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Beyond-Spin-Coating-Homogeneous-All-Inorganic-Perovskite-Films-via-High-Pressure-Recrystallization"><a href="#Beyond-Spin-Coating-Homogeneous-All-Inorganic-Perovskite-Films-via-High-Pressure-Recrystallization" class="headerlink" title="Beyond Spin Coating: Homogeneous All-Inorganic Perovskite Films via   High-Pressure Recrystallization"></a>Beyond Spin Coating: Homogeneous All-Inorganic Perovskite Films via   High-Pressure Recrystallization</h2><p><strong>Authors:Asma Miled, Trong Tam Nguyen, JosÃ© Penuelas, Aziz Benamrouche, CÃ©line Chevalier, Thi Kim Anh Hoang, GaÃ«lle TrippÃ©-Allard, Elsa Cassette, Brice Devif, Emmanuel Drouard, Emmanuelle Deleporte, Hong Hanh Mai, Abdelaziz Bouazizi, Christian Seassal, Hai Son Nguyen</strong></p>
<p>Metal halide perovskites are promising materials for optoelectronic applications owing to their outstanding optical and electronic properties. Among them, all-inorganic perovskites such as CsPbBr$_3$ offer superior thermal and chemical stability. However, obtaining high-quality CsPbBr$_3$ thin films via solution processing remains challenging due to the precursorâ€™s low solubility, and current additive or solvent engineering strategies are often complex and poorly reproducible. High-pressure recrystallization has recently emerged as a promising route to improve film quality, yet its impact on film properties remains insufficiently explored. Here, we systematically investigate the morphological, structural, and optical properties of CsPbBr$_3$ thin films prepared by high-pressure recrystallization, in comparison with standard non-recrystallized films. Optimized recrystallization at 300 bar produces smooth, pinhole-free, single-phase 3D perovskite layers with sub-nanometer roughness, while the film thickness is precisely tunable via precursor concentration. The process enhances both grain and crystallite sizes, leading to amplified spontaneous emission with a reduced excitation threshold and improved photostability. Temperature-dependent X-ray diffraction further reveals the orthorhombicâ€“tetragonalâ€“cubic phase transition, consistent with single-crystal behavior. This study provides fundamental insights into pressure-driven recrystallization and establishes a reproducible, scalable approach for fabricating high-quality CsPbBr$_3$ films for optoelectronic devices. </p>
<blockquote>
<p>é‡‘å±å¤åŒ–ç‰©é’™é’›çŸ¿å› å…¶å“è¶Šçš„å…‰å­¦å’Œç”µå­ç‰¹æ€§è€Œæˆä¸ºå…‰ç”µå­åº”ç”¨ä¸­çš„æœ‰å‰é€”çš„ææ–™ã€‚å…¶ä¸­ï¼Œå¦‚CsPbBr3ä¹‹ç±»çš„å…¨æ— æœºé’™é’›çŸ¿å…·æœ‰å‡ºè‰²çš„çƒ­å’ŒåŒ–å­¦ç¨³å®šæ€§ã€‚ç„¶è€Œï¼Œé€šè¿‡æº¶æ¶²å¤„ç†è·å¾—é«˜è´¨é‡çš„CsPbBr3è–„è†œä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå‰é©±ä½“çš„æº¶è§£åº¦ä½ï¼Œå¹¶ä¸”å½“å‰çš„æ·»åŠ å‰‚æˆ–æº¶å‰‚å·¥ç¨‹ç­–ç•¥é€šå¸¸å¤æ‚ä¸”é‡ç°æ€§å·®ã€‚é«˜å‹å†ç»“æ™¶æœ€è¿‘è¢«è¯æ˜æ˜¯æé«˜è–„è†œè´¨é‡çš„æœ‰å‰é€”çš„é€”å¾„ï¼Œç„¶è€Œå®ƒå¯¹è–„è†œæ€§èƒ½çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ç ”ç©¶äº†é€šè¿‡é«˜å‹å†ç»“æ™¶åˆ¶å¤‡çš„CsPbBr3è–„è†œä¸æ ‡å‡†éå†ç»“æ™¶è–„è†œçš„å½¢æ€å­¦ã€ç»“æ„å’Œå…‰å­¦æ€§èƒ½ã€‚åœ¨300å·´ä¸‹ä¼˜åŒ–çš„å†ç»“æ™¶å¯äº§ç”Ÿå…‰æ»‘ã€æ— é’ˆå­”ã€å•ç›¸çš„3Dé’™é’›çŸ¿å±‚ï¼Œç²—ç³™åº¦åœ¨äºšçº³ç±³èŒƒå›´å†…ï¼ŒåŒæ—¶å¯é€šè¿‡å‰é©±ä½“æµ“åº¦ç²¾ç¡®è°ƒèŠ‚è–„è†œåšåº¦ã€‚è¿™ä¸€è¿‡ç¨‹å¢åŠ äº†æ™¶ç²’å’Œå¾®æ™¶çš„å°ºå¯¸ï¼Œä»è€Œæ”¾å¤§äº†è‡ªå‘å‘å°„ï¼Œé™ä½äº†æ¿€å‘é˜ˆå€¼å¹¶æé«˜äº†å…‰ç¨³å®šæ€§ã€‚æ¸©åº¦ä¾èµ–çš„Xå°„çº¿è¡å°„è¿›ä¸€æ­¥æ­ç¤ºäº†æ­£äº¤-å››é‡-ç«‹æ–¹ç›¸å˜ï¼Œè¿™ä¸å•æ™¶è¡Œä¸ºç›¸ä¸€è‡´ã€‚æœ¬ç ”ç©¶ä¸ºå‹åŠ›é©±åŠ¨å†ç»“æ™¶æä¾›äº†åŸºæœ¬è§è§£ï¼Œå¹¶å»ºç«‹äº†ä¸€ç§å¯é‡å¤ã€å¯æ‰©å±•çš„æ–¹æ³•æ¥åˆ¶é€ ç”¨äºå…‰ç”µå­å™¨ä»¶çš„é«˜è´¨é‡CsPbBr3è–„è†œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.02177v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é‡‘å±å¤åŒ–ç‰©é’™é’›çŸ¿å› å…¶å“è¶Šçš„å…‰å­¦å’Œç”µå­ç‰¹æ€§è€Œæˆä¸ºå…‰ç”µå­åº”ç”¨çš„æœ‰å‰é€”çš„ææ–™ã€‚ç„¶è€Œï¼Œé€šè¿‡æº¶æ¶²å¤„ç†è·å¾—é«˜è´¨é‡çš„CsPbBr_3è–„è†œä»å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå‰é©±ä½“çš„æº¶è§£åº¦ä½ï¼Œå½“å‰çš„æ·»åŠ å‰‚æˆ–æº¶å‰‚å·¥ç¨‹ç­–ç•¥å¾€å¾€å¤æ‚ä¸”é‡ç°æ€§å·®ã€‚é«˜å‹å†ç»“æ™¶æœ€è¿‘è¢«è¯æ˜æ˜¯æé«˜è–„è†œè´¨é‡çš„æœ‰å‰é€”çš„é€”å¾„ï¼Œä½†å…¶å¯¹è–„è†œæ€§è´¨çš„å½±å“ä»æ¢ç´¢ä¸è¶³ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†é€šè¿‡é«˜å‹å†ç»“æ™¶åˆ¶å¤‡çš„CsPbBr_3è–„è†œçš„å½¢æ€å­¦ã€ç»“æ„å’Œå…‰å­¦æ€§è´¨ï¼Œå¹¶ä¸æ ‡å‡†çš„éå†ç»“æ™¶è–„è†œè¿›è¡Œäº†æ¯”è¾ƒã€‚åœ¨300å·´ä¸‹ä¼˜åŒ–çš„å†ç»“æ™¶äº§ç”Ÿäº†å…‰æ»‘ã€æ— é’ˆå­”ã€å•ç›¸çš„3Dé’™é’›çŸ¿å±‚ï¼Œç²—ç³™åº¦åœ¨äºšçº³ç±³èŒƒå›´å†…ï¼ŒåŒæ—¶å¯é€šè¿‡å‰é©±ä½“æµ“åº¦ç²¾ç¡®è°ƒèŠ‚è–„è†œåšåº¦ã€‚è¿™ä¸€è¿‡ç¨‹æé«˜äº†æ™¶ç²’å’Œå¾®æ™¶çš„å°ºå¯¸ï¼Œå¯¼è‡´è‡ªå‘å‘å°„å¢å¼ºï¼Œæ¿€å‘é˜ˆå€¼é™ä½ï¼Œå…‰ç¨³å®šæ€§æé«˜ã€‚æ¸©åº¦ä¾èµ–çš„Xå°„çº¿è¡å°„è¿›ä¸€æ­¥æ­ç¤ºäº†æ­£äº¤-å››é‡-ç«‹æ–¹ç›¸å˜ï¼Œä¸å•æ™¶è¡Œä¸ºä¸€è‡´ã€‚æœ¬ç ”ç©¶ä¸ºå‹åŠ›é©±åŠ¨å†ç»“æ™¶æä¾›äº†åŸºç¡€è§è§£ï¼Œå¹¶å»ºç«‹äº†ä¸€ç§å¯é‡å¤ã€å¯æ‰©å±•çš„æ–¹æ³•æ¥åˆ¶é€ ç”¨äºå…‰ç”µå­å™¨ä»¶çš„é«˜è´¨é‡CsPbBr_3è–„è†œã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>é‡‘å±å¤åŒ–ç‰©é’™é’›çŸ¿ï¼Œå¦‚CsPbBr_3ï¼Œåœ¨å…‰ç”µå­åº”ç”¨ä¸­å…·æœ‰å‰æ™¯ã€‚</li>
<li>é«˜å‹å†ç»“æ™¶æ˜¯æé«˜CsPbBr_3è–„è†œè´¨é‡çš„æœ‰å‰é€”çš„æ–¹æ³•ã€‚</li>
<li>ä¼˜åŒ–åçš„é«˜å‹å†ç»“æ™¶ï¼ˆ300 barï¼‰äº§ç”Ÿäº†å…‰æ»‘ã€æ— é’ˆå­”ã€å•ç›¸çš„é’™é’›çŸ¿å±‚ã€‚</li>
<li>è–„è†œåšåº¦å¯é€šè¿‡å‰é©±ä½“æµ“åº¦ç²¾ç¡®è°ƒèŠ‚ã€‚</li>
<li>é«˜å‹å†ç»“æ™¶æé«˜äº†æ™¶ç²’å’Œå¾®æ™¶å°ºå¯¸ï¼Œå¢å¼ºäº†è‡ªå‘å‘å°„å¹¶é™ä½äº†æ¿€å‘é˜ˆå€¼ã€‚</li>
<li>æ¸©åº¦ä¾èµ–çš„Xå°„çº¿è¡å°„æ­ç¤ºäº†CsPbBr_3çš„ç›¸å˜è¡Œä¸ºï¼Œä¸å•æ™¶æ€§è´¨ä¸€è‡´ã€‚</li>
<li>ç ”ç©¶ä¸ºåˆ¶é€ é«˜è´¨é‡CsPbBr_3è–„è†œæä¾›äº†å¯é‡å¤å’Œå¯æ‰©å±•çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.02177">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eb75bf3128e16bd4e8c1b2ff6fb008fe" align="middle">
<img src="https://picx.zhimg.com/v2-ccef4c01a1fe3d652d9bbcdd5efa6013" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Med-Banana-50K-A-Cross-modality-Large-Scale-Dataset-for-Text-guided-Medical-Image-Editing"><a href="#Med-Banana-50K-A-Cross-modality-Large-Scale-Dataset-for-Text-guided-Medical-Image-Editing" class="headerlink" title="Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided   Medical Image Editing"></a>Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided   Medical Image Editing</h2><p><strong>Authors:Zhihui Chen, Mengling Feng</strong></p>
<p>Medical image editing has emerged as a pivotal technology with broad applications in data augmentation, model interpretability, medical education, and treatment simulation. However, the lack of large-scale, high-quality, and openly accessible datasets tailored for medical contexts with strict anatomical and clinical constraints has significantly hindered progress in this domain. To bridge this gap, we introduce Med-Banana-50K, a comprehensive dataset of over 50k medically curated image edits spanning chest X-ray, brain MRI, and fundus photography across 23 diseases. Each sample supports bidirectional lesion editing (addition and removal) and is constructed using Gemini-2.5-Flash-Image based on real clinical images. A key differentiator of our dataset is the medically grounded quality control protocol: we employ an LLM-as-Judge evaluation framework with criteria such as instruction compliance, structural plausibility, image realism, and fidelity preservation, alongside iterative refinement over up to five rounds. Additionally, Med-Banana-50K includes around 37,000 failed editing attempts with full evaluation logs to support preference learning and alignment research. By offering a large-scale, medically rigorous, and fully documented resource, Med-Banana-50K establishes a critical foundation for developing and evaluating reliable medical image editing systems. Our dataset and code are publicly available. [<a target="_blank" rel="noopener" href="https://github.com/richardChenzhihui/med-banana-50k]">https://github.com/richardChenzhihui/med-banana-50k]</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒç¼–è¾‘å·²æˆä¸ºä¸€é¡¹å…·æœ‰å¹¿æ³›åº”ç”¨çš„å…³é”®æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ•°æ®å¢å¼ºã€æ¨¡å‹è§£é‡Šæ€§ã€åŒ»å­¦æ•™è‚²å’Œæ²»ç–—æ¨¡æ‹Ÿç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹é’ˆå¯¹åŒ»å­¦æƒ…å¢ƒçš„ã€ç¬¦åˆä¸¥æ ¼è§£å‰–å­¦å’Œä¸´åºŠçº¦æŸçš„å¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å…¬å¼€å¯è®¿é—®çš„æ•°æ®é›†ï¼Œè¯¥é¢†åŸŸçš„è¿›å±•å—åˆ°äº†æ˜¾è‘—é˜»ç¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Med-Banana-50Kæ•°æ®é›†ï¼Œå®ƒåŒ…å«è¶…è¿‡5ä¸‡ä»½ç»è¿‡åŒ»å­¦å¤„ç†çš„å›¾åƒç¼–è¾‘ï¼Œæ¶µç›–èƒ¸éƒ¨Xå…‰ç‰‡ã€è„‘éƒ¨MRIå’Œçœ¼åº•æ‘„å½±ï¼Œè·¨è¶Š23ç§ç–¾ç—…ã€‚æ¯ä¸ªæ ·æœ¬éƒ½æ”¯æŒåŒå‘ç—…å˜ç¼–è¾‘ï¼ˆå¢åŠ å’Œåˆ é™¤ï¼‰ï¼Œå¹¶ä½¿ç”¨åŸºäºçœŸå®ä¸´åºŠå›¾åƒçš„Gemini-2.5-Flash-Imageæ„å»ºã€‚æˆ‘ä»¬æ•°æ®é›†çš„ä¸€ä¸ªå…³é”®åŒºåˆ«åœ¨äºåŒ»å­¦åŸºç¡€çš„è´¨é‡æ§åˆ¶åè®®ï¼šæˆ‘ä»¬é‡‡ç”¨LLM-as-Judgeè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬æŒ‡ä»¤åˆè§„æ€§ã€ç»“æ„åˆç†æ€§ã€å›¾åƒçœŸå®æ€§å’Œä¿çœŸåº¦ä¿æŒç­‰æ ‡å‡†ï¼Œå¹¶è¿›è¡Œæœ€å¤šäº”è½®çš„è¿­ä»£æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒMed-Banana-50Kè¿˜åŒ…æ‹¬çº¦3.7ä¸‡æ¬¡å¤±è´¥çš„ç¼–è¾‘å°è¯•åŠå®Œæ•´çš„è¯„ä¼°æ—¥å¿—ï¼Œä»¥æ”¯æŒåå¥½å­¦ä¹ å’Œå¯¹é½ç ”ç©¶ã€‚é€šè¿‡æä¾›å¤§è§„æ¨¡ã€åŒ»å­¦ä¸¥è°¨å’Œå®Œæ•´çš„èµ„æºï¼ŒMed-Banana-50Kä¸ºå¼€å‘å¯é çš„åŒ»å­¦å›¾åƒç¼–è¾‘ç³»ç»Ÿå¥ å®šäº†å…³é”®åŸºç¡€ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å¯ç”¨ã€‚[<a target="_blank" rel="noopener" href="https://github.com/richardChenzhihui/med-banana-50k]%E3%80%82">https://github.com/richardChenzhihui/med-banana-50k]ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.00801v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»ç–—å›¾åƒç¼–è¾‘æŠ€æœ¯åœ¨æ•°æ®å¢å¼ºã€æ¨¡å‹è§£é‡Šæ€§ã€åŒ»å­¦æ•™è‚²å’Œæ²»ç–—æ¨¡æ‹Ÿç­‰æ–¹é¢æœ‰ç€å¹¿æ³›åº”ç”¨ï¼Œä½†ç¼ºä¹é’ˆå¯¹åŒ»å­¦è¯­å¢ƒçš„å¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å…¬å¼€å¯è®¿é—®çš„æ•°æ®é›†é™åˆ¶äº†è¯¥é¢†åŸŸçš„è¿›å±•ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºMed-Banana-50Kæ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡5ä¸‡ä»½åŒ»å­¦å®¡æ ¸è¿‡çš„å›¾åƒç¼–è¾‘æ ·æœ¬ï¼Œæ¶µç›–èƒ¸éƒ¨Xå…‰ã€è„‘éƒ¨MRIå’Œçœ¼åº•æ‘„å½±ç­‰23ç§ç–¾ç—…ã€‚æ¯ä¸ªæ ·æœ¬æ”¯æŒåŒå‘ç—…å˜ç¼–è¾‘ï¼ˆå¢åŠ å’Œç§»é™¤ï¼‰ï¼ŒåŸºäºçœŸå®ä¸´åºŠå›¾åƒä½¿ç”¨Gemini-2.5-Flash-Imageæ„å»ºã€‚æˆ‘ä»¬çš„æ•°æ®é›†é‡‡ç”¨åŒ»å­¦åŸºç¡€è´¨é‡æ§åˆ¶åè®®ï¼Œé‡‡ç”¨LLM-as-Judgeè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬æŒ‡ä»¤åˆè§„æ€§ã€ç»“æ„åˆç†æ€§ã€å›¾åƒçœŸå®æ€§å’Œä¿çœŸåº¦ä¿ç•™ç­‰æ ‡å‡†ï¼Œå¹¶è¿›è¡Œè‡³å¤šäº”è½®çš„è¿­ä»£æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒMed-Banana-50Kè¿˜åŒ…æ‹¬çº¦3.7ä¸‡æ¬¡ç¼–è¾‘å¤±è´¥çš„å°è¯•ï¼Œå¹¶é™„æœ‰å®Œæ•´çš„è¯„ä¼°æ—¥å¿—ï¼Œä»¥æ”¯æŒåå¥½å­¦ä¹ å’Œå¯¹é½ç ”ç©¶ã€‚é€šè¿‡æä¾›å¤§è§„æ¨¡ã€åŒ»å­¦ä¸¥è°¨å’Œå®Œæ•´è®°å½•çš„èµ„æºï¼ŒMed-Banana-50Kä¸ºå¼€å‘è¯„ä¼°å¯é çš„åŒ»ç–—å›¾åƒç¼–è¾‘ç³»ç»Ÿæä¾›äº†é‡è¦åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—å›¾åƒç¼–è¾‘æŠ€æœ¯å¹¿æ³›åº”ç”¨äºæ•°æ®å¢å¼ºã€æ¨¡å‹è§£é‡Šæ€§ç­‰é¢†åŸŸã€‚</li>
<li>ç¼ºä¹é’ˆå¯¹åŒ»å­¦è¯­å¢ƒçš„å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†é™åˆ¶äº†åŒ»ç–—å›¾åƒç¼–è¾‘æŠ€æœ¯çš„å‘å±•ã€‚</li>
<li>Med-Banana-50Kæ˜¯ä¸€ä¸ªæ¶µç›–å¤šç§åŒ»ç–—å›¾åƒçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ”¯æŒç—…å˜çš„åŒå‘ç¼–è¾‘ã€‚</li>
<li>Med-Banana-50KåŸºäºçœŸå®ä¸´åºŠå›¾åƒæ„å»ºï¼Œå¹¶ä½¿ç”¨åŒ»å­¦åŸºç¡€è´¨é‡æ§åˆ¶åè®®ã€‚</li>
<li>Med-Banana-50Ké‡‡ç”¨LLM-as-Judgeè¯„ä¼°æ¡†æ¶è¿›è¡Œè´¨é‡è¯„ä¼°ï¼ŒåŒ…æ‹¬å¤šä¸ªè¯„ä¼°æ ‡å‡†ã€‚</li>
<li>æ•°æ®é›†åŒ…å«ç¼–è¾‘å¤±è´¥çš„å°è¯•å’Œè¯„ä¼°æ—¥å¿—ï¼Œä»¥æ”¯æŒåå¥½å­¦ä¹ å’Œå¯¹é½ç ”ç©¶ã€‚</li>
<li>Med-Banana-50Kä¸ºå¼€å‘è¯„ä¼°å¯é çš„åŒ»ç–—å›¾åƒç¼–è¾‘ç³»ç»Ÿæä¾›äº†é‡è¦åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.00801">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b22bea946876a9ff6f129c57a4e62b2d" align="middle">
<img src="https://picx.zhimg.com/v2-aba82df67b50d13e66b3cc5a06c0e816" align="middle">
<img src="https://picx.zhimg.com/v2-1fd183790e3414718e82ac83a0f9c4a5" align="middle">
<img src="https://picx.zhimg.com/v2-39aafbb7d0a38a259240fc6806efd230" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Wind-AE-A-Fast-Open-source-1D-Photoevaporation-Code-with-Metal-and-Multi-frequency-X-ray-Capabilities"><a href="#Wind-AE-A-Fast-Open-source-1D-Photoevaporation-Code-with-Metal-and-Multi-frequency-X-ray-Capabilities" class="headerlink" title="Wind-AE: A Fast, Open-source 1D Photoevaporation Code with Metal and   Multi-frequency X-ray Capabilities"></a>Wind-AE: A Fast, Open-source 1D Photoevaporation Code with Metal and   Multi-frequency X-ray Capabilities</h2><p><strong>Authors:Madelyn Broome, Ruth Murray-Clay, John McCann, James E Owen</strong></p>
<p>Throughout their lives, short period exoplanets (&lt;100 days) experience X-ray and extreme-UV (XUV) stellar irradiation that can heat and photoionize planetsâ€™ upper atmospheres, driving transonic outflows. This photoevaporative mass loss plays a role in both evolution and observed demographics; however, mass loss rates are not currently directly observable and can only be inferred from models. To that end, we present an open-source fast 1D, XUV multi-frequency, multispecies, steady-state, hydrodynamic Parker Wind photoevaporation relaxation model based on Murray-Clay et al. (2009,arXiv:0811.0006). The model can move smoothly between high and low flux regimes and accepts custom multi-frequency stellar spectra. While the inclusion of high-energy X-rays increases mass loss rates ($\dot{M}$), metals decrease $\dot{M}$, and the net result for a typical hot Jupiter is a similar $\dot{M}$, but a hotter, faster, and more gradually ionized wind. We find that mulitfrequency photons (e.g., 13.6-2000eV) are absorbed over a broader range of heights in the atmosphere resulting in a wind-launch radius, $R_{XUV}$, that is of order 10 nanobars for all but the highest surface gravity planets. Grids of H&#x2F;He solar metallicity atmospheres reveal that, for typical hot Jupiters like HD 209458b, $R_{XUV}$~1.1-1.8$R_P$ for low-fluxes, meaning that the energy-limited mass loss rate, $\dot{M}<em>{Elim}(R)$, computed at $R&#x3D;R_P$ is a good approximation. However, for planets with low escape velocities, like many sub-Neptunes and super-Earths, $R_{XUV}$ can be &gt;&gt;$R_P$, making it necessary to use $\dot{M}</em>{Elim}(R&#x3D;R_{XUV})$ to avoid significantly underestimating mass loss rates. For both high escape velocities and large incident fluxes, radiative cooling is significant and energy-limited mass loss overestimates $\dot{M}$. </p>
<blockquote>
<p>åœ¨å®ƒä»¬çš„ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œå‘¨æœŸçŸ­äº100å¤©çš„å¤–è¡Œæ˜Ÿä¼šç»å†Xå°„çº¿å’Œæç«¯ç´«å¤–ï¼ˆXUVï¼‰æ’æ˜Ÿè¾å°„ï¼Œè¿™äº›è¾å°„å¯ä»¥åŠ çƒ­å’Œç”µç¦»è¡Œæ˜Ÿçš„ä¸Šå±‚å¤§æ°”ï¼Œä»è€Œäº§ç”Ÿè·¨éŸ³é€Ÿæµå‡ºã€‚è¿™ç§å…‰è’¸å‘è´¨é‡æŸå¤±åœ¨è¡Œæ˜Ÿçš„æ¼”å˜å’Œè§‚æµ‹äººå£ç»Ÿè®¡ä¸­éƒ½å‘æŒ¥ä½œç”¨ï¼›ç„¶è€Œï¼Œç›®å‰æ— æ³•ç›´æ¥è§‚æµ‹åˆ°è´¨é‡æŸå¤±ç‡ï¼Œåªèƒ½æ ¹æ®æ¨¡å‹è¿›è¡Œæ¨æ–­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åŸºäºMurray-Clayç­‰äººï¼ˆ2009ï¼ŒarXiv:0811.0006ï¼‰çš„ç ”ç©¶ï¼Œæå‡ºäº†ä¸€ä¸ªå¼€æºçš„å¿«é€Ÿä¸€ç»´XUVå¤šé¢‘ã€å¤šç»„åˆ†ç¨³æ€æµä½“åŠ¨åŠ›å¸•å…‹é£ï¼ˆParker Windï¼‰å…‰è’¸å‘æ¾å¼›æ¨¡å‹ã€‚è¯¥æ¨¡å‹å¯ä»¥åœ¨é«˜ã€ä½æµé‡çŠ¶æ€ä¹‹é—´å¹³ç¨³è¿‡æ¸¡ï¼Œå¹¶æ¥å—è‡ªå®šä¹‰çš„å¤šé¢‘æ’æ˜Ÿå…‰è°±ã€‚åœ¨åŒ…å«é«˜èƒ½çš„Xå°„çº¿ä¼šå¢åŠ è´¨é‡æŸå¤±ç‡ï¼ˆMï¼‰ï¼Œè€Œé‡‘å±ä¼šé™ä½Mçš„æƒ…å†µä¸‹ï¼Œå¯¹äºå…¸å‹çš„çƒ­æœ¨æ˜Ÿæ¥è¯´ï¼Œå‡€ç»“æœå…·æœ‰ç›¸ä¼¼çš„Må€¼ï¼Œä½†é£æ›´åŠ çƒ­ã€æ›´å¿«ã€ç”µç¦»è¿‡ç¨‹æ›´ä¸ºæ¸è¿›ã€‚æˆ‘ä»¬å‘ç°å¤šé¢‘å…‰å­ï¼ˆä¾‹å¦‚ï¼Œåœ¨13.6-2000ç”µå­ä¼ç‰¹ä¹‹é—´ï¼‰åœ¨å¤§æ°”å±‚ä¸­æ›´é«˜çš„é«˜åº¦èŒƒå›´å†…è¢«å¸æ”¶ï¼Œå¯¼è‡´é£å‘å°„åŠå¾„Rxuvåœ¨æ‰€æœ‰è¡Œæ˜Ÿä¸­é™¤è¡¨é¢é‡åŠ›æœ€é«˜çš„è¡Œæ˜Ÿå¤–çº¦ä¸º10çº³ç±³å·´ã€‚ç”±H&#x2F;Heå¤ªé˜³é‡‘å±ç»„æˆçš„å¤§æ°”ç½‘æ ¼æ­ç¤ºï¼Œå¯¹äºåƒHD 209458bè¿™æ ·çš„å…¸å‹çƒ­æœ¨æ˜Ÿæ¥è¯´ï¼ŒRxuvä¸ºRpçš„1.1-1.8å€åœ¨ä½æµé‡ä¸‹æ„å‘³ç€èƒ½é‡é™åˆ¶çš„è´¨é‡æŸå¤±ç‡åœ¨Rpå¤„è®¡ç®—æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è¿‘ä¼¼å€¼ã€‚ç„¶è€Œï¼Œå¯¹äºå…·æœ‰ä½é€ƒé€¸é€Ÿåº¦çš„è¡Œå¦‚è®¸å¤šæ¬¡æµ·ç‹æ˜Ÿå’Œè¶…çº§åœ°çƒæ¥è¯´ï¼ŒRxuvå¯èƒ½è¿œå¤§äºRpï¼Œå› æ­¤å¿…é¡»ä½¿ç”¨ä»¥R&#x3D;Rxuvå¤„çš„èƒ½é‡é™åˆ¶è´¨é‡æŸå¤±ç‡æ¥é¿å…ä½ä¼°è´¨é‡æŸå¤±ç‡ã€‚å¯¹äºé«˜é€ƒé€¸é€Ÿåº¦å’Œå¤§çš„å…¥å°„æµé‡çš„æƒ…å†µï¼Œè¾å°„å†·å´æ˜¯æ˜¾è‘—çš„å¹¶ä¸”èƒ½é‡é™åˆ¶çš„è´¨é‡æŸå¤±ä¼šé«˜ä¼°Må€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.23857v2">PDF</a> 40 pages, 23 figures, Accepted</p>
<p><strong>Summary</strong><br>    è¯¥æ–‡æœ¬ä»‹ç»äº†çŸ­å‘¨æœŸå¤–è¡Œæ˜Ÿï¼ˆå¯¿å‘½å°äº100å¤©ï¼‰åœ¨Xå°„çº¿å’Œæç«¯ç´«å¤–ï¼ˆXUVï¼‰æ’æ˜Ÿè¾å°„ä¸‹çš„çŠ¶å†µï¼Œè¿™ç§è¾å°„ä¼šåŠ çƒ­å’Œç”µç¦»è¡Œæ˜Ÿä¸Šå±‚å¤§æ°”ï¼Œä»è€Œäº§ç”Ÿè·¨éŸ³é€Ÿæµå‡ºã€‚é€šè¿‡å‘ˆç°åŸºäºMurray-Clayç­‰äººï¼ˆ2009ï¼‰çš„å¼€æºå¿«é€Ÿä¸€ç»´ã€XUVå¤šé¢‘ã€å¤šç»„åˆ†ç¨³æ€æµä½“åŠ¨åŠ›Parkeré£çš„å…‰è’¸å‘æ¾å¼›æ¨¡å‹ï¼Œæ–‡ä¸­æ¢è®¨äº†è¡Œæ˜Ÿè´¨é‡æŸå¤±çš„å½±å“ã€‚æ¨¡å‹èƒ½å¤Ÿçµæ´»é€‚åº”é«˜ã€ä½æµé‡çŠ¶æ€ï¼Œå¹¶æ¥å—è‡ªå®šä¹‰çš„å¤šé¢‘æ’æ˜Ÿå…‰è°±ã€‚åŒæ—¶å‘ç°ï¼Œé‡‘å±å’Œèƒ½é‡çš„ç›¸äº’ä½œç”¨ä¼šå¯¼è‡´è´¨é‡æŸå¤±ç‡ï¼ˆMdotï¼‰çš„å‡€ç»“æœä¿æŒç¨³å®šï¼Œä½†å¯¹è¡Œæ˜Ÿé£çš„æ€§è´¨æœ‰æ˜¾è‘—å½±å“ï¼Œä½¿è¡Œæ˜Ÿçš„é£æ›´çƒ­ã€æ›´å¿«å¹¶ä¸”ç”µç¦»ç¨‹åº¦æ›´åŠ ç¼“æ…¢ã€‚å¼ºè°ƒåœ¨ä¸åŒæƒ…å½¢ä¸‹è¿›è¡Œç²¾ç¡®ä¼°ç®—æ—¶é€‰å–é€‚å®œçš„åŠå¾„çš„é‡è¦æ€§ã€‚å¯¹äºé€ƒé€¸é€Ÿåº¦è¾ƒé«˜çš„è¡Œæ˜Ÿå’Œè¾ƒå¤§çš„å…¥å°„æµé‡ï¼Œèƒ½é‡é™åˆ¶çš„è´¨é‡æŸå¤±å­˜åœ¨é«˜ä¼°çš„å¯èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŸ­å‘¨æœŸå¤–è¡Œæ˜Ÿå—åˆ°å¼ºçƒˆçš„Xå°„çº¿å’Œæç«¯ç´«å¤–è¾å°„å½±å“ï¼Œå¯¼è‡´å¤§æ°”å±‚çš„çƒ­åŒ–å’Œå…‰è‡´ç”µç¦»ã€‚è¿™ç§å½±å“æˆä¸ºå½±å“è¡Œæ˜Ÿæ¼”å˜å’Œè§‚æµ‹åˆ°çš„ç‰¹ç‚¹çš„é‡è¦å› ç´ ä¹‹ä¸€ã€‚ä¸ºäº†é¢„æµ‹è´¨é‡æŸå¤±è¿‡ç¨‹éœ€è¦ä½¿ç”¨å»ºæ¨¡æŠ€æœ¯ã€‚æ–‡ä¸­ä»‹ç»äº†ä¸€ä¸ªåŸºäºParkeré£çš„å…‰è’¸å‘æ¾å¼›æ¨¡å‹ã€‚è¯¥æ¨¡å‹è€ƒè™‘äº†å¤šç§é¢‘ç‡çš„æ’æ˜Ÿå…‰è°±ï¼Œå¹¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„æµé‡ç¯å¢ƒã€‚æ–‡ä¸­ç‰¹åˆ«æåˆ°äº†é«˜èƒ½é‡Xå°„çº¿çš„åŠ å…¥ä¼šå¢åŠ è´¨é‡æŸå¤±ç‡ï¼ˆMdotï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.23857">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-16c19a5bcf088a0e5c927f49e8e0d7ad" align="middle">
<img src="https://picx.zhimg.com/v2-d9700a78c064eae187c6cfab32b3e193" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Self-supervised-Deep-Unrolled-Model-with-Implicit-Neural-Representation-Regularization-for-Accelerating-MRI-Reconstruction"><a href="#Self-supervised-Deep-Unrolled-Model-with-Implicit-Neural-Representation-Regularization-for-Accelerating-MRI-Reconstruction" class="headerlink" title="Self-supervised Deep Unrolled Model with Implicit Neural Representation   Regularization for Accelerating MRI Reconstruction"></a>Self-supervised Deep Unrolled Model with Implicit Neural Representation   Regularization for Accelerating MRI Reconstruction</h2><p><strong>Authors:Jingran Xu, Yuanyuan Liu, Yuanbiao Yang, Zhuo-Xu Cui, Jing Cheng, Qingyong Zhu, Nannan Zhang, Yihang Zhou, Dong Liang, Yanjie Zhu</strong></p>
<p>Magnetic resonance imaging (MRI) is a vital clinical diagnostic tool, yet its application is limited by prolonged scan times. Accelerating MRI reconstruction addresses this issue by reconstructing high-fidelity MR images from undersampled k-space measurements. In recent years, deep learning-based methods have demonstrated remarkable progress. However, most methods rely on supervised learning, which requires large amounts of fully-sampled training data that are difficult to obtain. This paper proposes a novel zero-shot self-supervised reconstruction method named UnrollINR, which enables scan-specific MRI reconstruction without external training data. UnrollINR adopts a physics-guided unrolled reconstruction architecture and introduces implicit neural representation (INR) as a regularization prior to effectively constrain the solution space. This method overcomes the local bias limitation of CNNs in traditional deep unrolled methods and avoids the instability associated with relying solely on INRâ€™s implicit regularization in highly ill-posed scenarios. Consequently, UnrollINR significantly improves MRI reconstruction performance under high acceleration rates. Experimental results show that even at a high acceleration rate of 10, UnrollINR achieves superior reconstruction performance compared to supervised and self-supervised learning methods, validating its effectiveness and superiority. </p>
<blockquote>
<p>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯ä¸€ç§é‡è¦çš„ä¸´åºŠè¯Šæ–­å·¥å…·ï¼Œä½†å…¶æ‰«ææ—¶é—´è¿‡é•¿é™åˆ¶äº†å…¶åº”ç”¨ã€‚åŠ é€ŸMRIé‡å»ºé€šè¿‡ä»æ¬ é‡‡æ ·çš„kç©ºé—´æµ‹é‡å€¼é‡å»ºé«˜ä¿çœŸMRå›¾åƒæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•ä¾èµ–äºç›‘ç£å­¦ä¹ ï¼Œè¿™éœ€è¦å¤§é‡å®Œå…¨é‡‡æ ·çš„è®­ç»ƒæ•°æ®ï¼Œè¿™äº›æ•°æ®å¾ˆéš¾è·å¾—ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è‡ªç›‘ç£é‡å»ºæ–¹æ³•ï¼Œåä¸ºUnrollINRï¼Œå®ƒå¯ä»¥åœ¨æ²¡æœ‰å¤–éƒ¨è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°ç‰¹å®šçš„MRIé‡å»ºã€‚UnrollINRé‡‡ç”¨ç‰©ç†å¼•å¯¼çš„åå·ç§¯é‡å»ºæ¶æ„ï¼Œå¹¶å¼•å…¥éšå¼ç¥ç»è¡¨ç¤ºï¼ˆINRï¼‰ä½œä¸ºæ­£åˆ™åŒ–å…ˆéªŒï¼Œæœ‰æ•ˆåœ°çº¦æŸè§£ç©ºé—´ã€‚è¯¥æ–¹æ³•å…‹æœäº†ä¼ ç»Ÿæ·±åº¦åå·ç§¯æ–¹æ³•ä¸­CNNçš„å±€éƒ¨åè§é™åˆ¶ï¼Œé¿å…äº†åœ¨é«˜åº¦ä¸é€‚å®šåœºæ™¯ä¸­ä»…ä¾èµ–INRéšå¼æ­£åˆ™åŒ–çš„ä¸ç¨³å®šæ€§ã€‚å› æ­¤ï¼ŒUnrollINRåœ¨é«˜é€Ÿæ‰«æä¸‹æ˜¾è‘—æé«˜äº†MRIé‡å»ºæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨é«˜è¾¾10å€çš„åŠ é€Ÿç‡ä¸‹ï¼ŒUnrollINRçš„é‡å»ºæ€§èƒ½ä¹Ÿä¼˜äºç›‘ç£å’Œè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06611v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºUnrollINRçš„é›¶æ ·æœ¬è‡ªç›‘ç£é‡å»ºæ–¹æ³•ï¼Œè§£å†³äº†æ ¸ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ‰«ææ—¶é—´é•¿çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç‰©ç†å¼•å¯¼çš„åå·ç§¯é‡å»ºæ¶æ„ï¼Œå¼•å…¥éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºï¼ˆINRï¼‰ä½œä¸ºæ­£åˆ™åŒ–å…ˆéªŒï¼Œæœ‰æ•ˆçº¦æŸè§£ç©ºé—´ã€‚ä¸ä¼ ç»Ÿæ·±åº¦åå·ç§¯æ–¹æ³•ä¸­çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å±€éƒ¨åè§é™åˆ¶ç›¸æ¯”ï¼ŒUnrollINRé¿å…äº†é«˜åº¦ä¸é€‚å®šåœºæ™¯ä¸­ä»…ä¾èµ–INRéšå¼æ­£åˆ™åŒ–çš„ä¸ç¨³å®šæ€§ã€‚å› æ­¤ï¼ŒUnrollINRåœ¨é«˜åŠ é€Ÿç‡ä¸‹æ˜¾è‘—æé«˜äº†MRIé‡å»ºæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨é«˜è¾¾10çš„åŠ é€Ÿç‡ä¸‹ï¼ŒUnrollINRçš„é‡å»ºæ€§èƒ½ä¹Ÿä¼˜äºç›‘ç£å­¦ä¹ å’Œè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>UnrollINRæ˜¯ä¸€ç§é›¶æ ·æœ¬è‡ªç›‘ç£MRIé‡å»ºæ–¹æ³•ï¼Œæ— éœ€å¤–éƒ¨è®­ç»ƒæ•°æ®ã€‚</li>
<li>é‡‡ç”¨ç‰©ç†å¼•å¯¼çš„åå·ç§¯é‡å»ºæ¶æ„ã€‚</li>
<li>å¼•å…¥éšå¼ç¥ç»ç½‘ç»œè¡¨ç¤ºï¼ˆINRï¼‰ä½œä¸ºæ­£åˆ™åŒ–å…ˆéªŒï¼Œæœ‰æ•ˆçº¦æŸè§£ç©ºé—´ã€‚</li>
<li>å…‹æœäº†ä¼ ç»Ÿæ·±åº¦åå·ç§¯æ–¹æ³•ä¸­CNNçš„å±€éƒ¨åè§é™åˆ¶ã€‚</li>
<li>é¿å…åœ¨é«˜åº¦ä¸é€‚å®šåœºæ™¯ä¸­ä»…ä¾èµ–INRéšå¼æ­£åˆ™åŒ–çš„ä¸ç¨³å®šæ€§ã€‚</li>
<li>åœ¨é«˜åŠ é€Ÿç‡ä¸‹ï¼ŒUnrollINRæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„MRIé‡å»ºæ€§èƒ½æ”¹è¿›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒUnrollINRçš„é‡å»ºæ€§èƒ½ä¼˜äºç›‘ç£å­¦ä¹ å’Œè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f53b590b21edc6417b8fa626195bf949" align="middle">
<img src="https://picx.zhimg.com/v2-3e370b48c2ff97eea7fa21300d7cbb57" align="middle">
<img src="https://picx.zhimg.com/v2-7569a9653e052124e77c87136186ff86" align="middle">
<img src="https://picx.zhimg.com/v2-1943614add6b131af7bb8cc31083fe68" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Dual-Teacher-Student-Learning-for-Semi-supervised-Medical-Image-Segmentation"><a href="#Dual-Teacher-Student-Learning-for-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="Dual Teacher-Student Learning for Semi-supervised Medical Image   Segmentation"></a>Dual Teacher-Student Learning for Semi-supervised Medical Image   Segmentation</h2><p><strong>Authors:Pengchen Zhang, Alan J. X. Guo, Sipin Luo, Zhe Han, Lin Guo</strong></p>
<p>Semi-supervised learning reduces the costly manual annotation burden in medical image segmentation. A popular approach is the mean teacher (MT) strategy, which applies consistency regularization using a temporally averaged teacher model. In this work, the MT strategy is reinterpreted as a form of self-paced learning in the context of supervised learning, where agreement between the teacherâ€™s predictions and the ground truth implicitly guides the model from easy to hard. Extending this insight to semi-supervised learning, we propose dual teacher-student learning (DTSL). It regulates the learning pace on unlabeled data using two signals: a temporally averaged signal from an in-group teacher and a cross-architectural signal from a student in a second, distinct model group. Specifically, a novel consensus label generator (CLG) creates the pseudo-labels from the agreement between these two signals, establishing an effective learning curriculum. Extensive experiments on four benchmark datasets demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches. Remarkably, on three of the four datasets, our semi-supervised method with limited labeled data surpasses its fully supervised counterparts, validating the effectiveness of our self-paced learning design. </p>
<blockquote>
<p>åŠç›‘ç£å­¦ä¹ é™ä½äº†åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æ˜‚è´µçš„æ‰‹åŠ¨æ ‡æ³¨è´Ÿæ‹…ã€‚ä¸€ç§æµè¡Œçš„æ–¹æ³•æ˜¯å‡å€¼æ•™å¸ˆï¼ˆMTï¼‰ç­–ç•¥ï¼Œå®ƒä½¿ç”¨éšæ—¶é—´å¹³å‡çš„æ•™å¸ˆæ¨¡å‹åº”ç”¨ä¸€è‡´æ€§æ­£åˆ™åŒ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†MTç­–ç•¥é‡æ–°è§£é‡Šä¸ºç›‘ç£å­¦ä¹ èƒŒæ™¯ä¸‹çš„è‡ªæˆ‘èŠ‚å¥å­¦ä¹ å½¢å¼ï¼Œæ•™å¸ˆé¢„æµ‹å’Œåœ°é¢çœŸå®ä¹‹é—´çš„åè®®éšå¼åœ°å¼•å¯¼æ¨¡å‹ä»æ˜“åˆ°éš¾ã€‚å°†è¿™ç§è§è§£æ‰©å±•åˆ°åŠç›‘ç£å­¦ä¹ ï¼Œæˆ‘ä»¬æå‡ºäº†åŒæ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ ï¼ˆDTSLï¼‰ã€‚å®ƒä½¿ç”¨ä¸¤ä¸ªä¿¡å·è°ƒèŠ‚æœªæ ‡è®°æ•°æ®ä¸Šçš„å­¦ä¹ è¿›åº¦ï¼šä¸€ä¸ªæ¥è‡ªç»„å†…æ•™å¸ˆçš„éšæ—¶é—´å¹³å‡çš„ä¿¡å·ï¼Œå¦ä¸€ä¸ªæ¥è‡ªç¬¬äºŒä¸ªä¸åŒæ¨¡å‹ç»„ä¸­çš„å­¦ç”Ÿçš„è·¨æ¶æ„ä¿¡å·ã€‚å…·ä½“æ¥è¯´ï¼Œä¸€ç§æ–°å‹å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨ï¼ˆCLGï¼‰é€šè¿‡è¿™ä¸¤ä¸ªä¿¡å·ä¹‹é—´çš„åè®®åˆ›å»ºä¼ªæ ‡ç­¾ï¼Œå»ºç«‹æœ‰æ•ˆçš„å­¦ä¹ è¯¾ç¨‹ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å§‹ç»ˆä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨å››ä¸ªæ•°æ®é›†ä¸­çš„ä¸‰ä¸ªä¸Šï¼Œæˆ‘ä»¬çš„åŠç›‘ç£æ–¹æ³•ä½¿ç”¨æœ‰é™çš„æ ‡è®°æ•°æ®è¶…è¶Šäº†å…¶å®Œå…¨ç›‘ç£çš„åŒç±»æ–¹æ³•ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„è‡ªæˆ‘èŠ‚å¥å­¦ä¹ è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11018v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŠç›‘ç£å­¦ä¹ é™ä½äº†åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æ˜‚è´µçš„æ‰‹åŠ¨æ ‡æ³¨è´Ÿæ‹…ã€‚æœ¬ç ”ç©¶å°†å¹³å‡æ•™å¸ˆï¼ˆMTï¼‰ç­–ç•¥è§£è¯»ä¸ºä¸€ç§ç›‘ç£å­¦ä¹ ä¸­çš„è‡ªæˆ‘èŠ‚å¥å­¦ä¹ ï¼Œå…¶ä¸­æ•™å¸ˆé¢„æµ‹ä¸çœŸå®å€¼ä¹‹é—´çš„åè®®éšå«åœ°å¼•å¯¼æ¨¡å‹ä»æ˜“åˆ°éš¾å­¦ä¹ ã€‚å°†æ­¤è§è§£æ‰©å±•åˆ°åŠç›‘ç£å­¦ä¹ ï¼Œæˆ‘ä»¬æå‡ºäº†åŒæ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ ï¼ˆDTSLï¼‰æ–¹æ³•ã€‚å®ƒåœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šä½¿ç”¨ä¸¤ä¸ªä¿¡å·è°ƒèŠ‚å­¦ä¹ è¿›åº¦ï¼šæ¥è‡ªç»„å†…æ•™å¸ˆçš„æ—¶é—´å¹³å‡ä¿¡å·å’Œæ¥è‡ªç¬¬äºŒä¸ªä¸åŒæ¨¡å‹ç»„çš„å­¦ç”Ÿäº¤å‰æ¶æ„ä¿¡å·ã€‚ç‰¹åˆ«æ˜¯ï¼Œä¸€ç§æ–°çš„å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨ï¼ˆCLGï¼‰é€šè¿‡è¿™ä¸¤ä¸ªä¿¡å·ä¹‹é—´çš„åè®®åˆ›å»ºä¼ªæ ‡ç­¾ï¼Œå»ºç«‹äº†æœ‰æ•ˆçš„å­¦ä¹ è¯¾ç¨‹ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å§‹ç»ˆä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡å…¶å®Œå…¨ç›‘ç£æ–¹æ³•çš„è¡¨ç°ã€‚éªŒè¯äº†è‡ªæˆ‘èŠ‚å¥å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚ </p>
<p><strong>Key Takeaways</strong> </p>
<ul>
<li>åŠç›‘ç£å­¦ä¹ å‡å°‘äº†åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„æ‰‹åŠ¨æ ‡æ³¨æˆæœ¬ã€‚ </li>
<li>å¹³å‡æ•™å¸ˆç­–ç•¥è¢«é‡æ–°è§£é‡Šä¸ºè‡ªæˆ‘èŠ‚å¥å­¦ä¹ çš„ä¸€ç§å½¢å¼ï¼Œå…¶ä¸­æ•™å¸ˆé¢„æµ‹ä¸çœŸå®å€¼ä¹‹é—´çš„åè®®æŒ‡å¯¼æ¨¡å‹å­¦ä¹ è¿›åº¦ã€‚ </li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŒæ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ æ–¹æ³•ï¼Œåˆ©ç”¨ä¸¤ä¸ªä¿¡å·åœ¨è‡ªæˆ‘èŠ‚å¥å­¦ä¹ ä¸­è°ƒèŠ‚æ— æ ‡ç­¾æ•°æ®çš„å­¦ä¹ è¿›åº¦ã€‚ </li>
<li>å…±è¯†æ ‡ç­¾ç”Ÿæˆå™¨é€šè¿‡ä¸¤ä¸ªä¿¡å·ä¹‹é—´çš„åè®®åˆ›å»ºä¼ªæ ‡ç­¾ï¼Œä»¥æ›´æœ‰æ•ˆåœ°è¿›è¡Œå­¦ä¹ ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11018">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2b46e9ffc8658a6955900dc408efb343" align="middle">
<img src="https://picx.zhimg.com/v2-5bc440c118e681f4c381c6df0a160892" align="middle">
<img src="https://picx.zhimg.com/v2-631ebd2fc793d877de58add7d93158bc" align="middle">
<img src="https://picx.zhimg.com/v2-33c7af667037f48c92c643d1e50119f2" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Consistency-Trajectory-Matching-for-One-Step-Generative-Super-Resolution"><a href="#Consistency-Trajectory-Matching-for-One-Step-Generative-Super-Resolution" class="headerlink" title="Consistency Trajectory Matching for One-Step Generative Super-Resolution"></a>Consistency Trajectory Matching for One-Step Generative Super-Resolution</h2><p><strong>Authors:Weiyi You, Mingyang Zhang, Leheng Zhang, Xingyu Zhou, Kexuan Shi, Shuhang Gu</strong></p>
<p>Current diffusion-based super-resolution (SR) approaches achieve commendable performance at the cost of high inference overhead. Therefore, distillation techniques are utilized to accelerate the multi-step teacher model into one-step student model. Nevertheless, these methods significantly raise training costs and constrain the performance of the student model by the teacher model. To overcome these tough challenges, we propose Consistency Trajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy that is able to generate photo-realistic SR results in one step. Concretely, we first formulate a Probability Flow Ordinary Differential Equation (PF-ODE) trajectory to establish a deterministic mapping from low-resolution (LR) images with noise to high-resolution (HR) images. Then we apply the Consistency Training (CT) strategy to directly learn the mapping in one step, eliminating the necessity of pre-trained diffusion model. To further enhance the performance and better leverage the ground-truth during the training process, we aim to align the distribution of SR results more closely with that of the natural images. To this end, we propose to minimize the discrepancy between their respective PF-ODE trajectories from the LR image distribution by our meticulously designed Distribution Trajectory Matching (DTM) loss, resulting in improved realism of our recovered HR images. Comprehensive experimental results demonstrate that the proposed methods can attain comparable or even superior capabilities on both synthetic and real datasets while maintaining minimal inference latency. </p>
<blockquote>
<p>å½“å‰åŸºäºæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æ–¹æ³•åœ¨é«˜æ¨ç†å¼€é”€çš„ä»£ä»·ä¸‹å®ç°äº†ä»¤äººé’¦ä½©çš„æ€§èƒ½ã€‚å› æ­¤ï¼Œé‡‡ç”¨è’¸é¦æŠ€æœ¯å°†å¤šæ­¥æ•™å¸ˆæ¨¡å‹åŠ é€Ÿä¸ºä¸€æ­¥å­¦ç”Ÿæ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ˜¾è‘—å¢åŠ äº†è®­ç»ƒæˆæœ¬ï¼Œå¹¶ä¸”å­¦ç”Ÿæ¨¡å‹çš„è¡¨ç°å—åˆ°æ•™å¸ˆæ¨¡å‹çš„åˆ¶çº¦ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ— è’¸é¦ç­–ç•¥çš„ä¸€è‡´è½¨è¿¹åŒ¹é…è¶…åˆ†è¾¨ç‡é‡å»ºï¼ˆCTMSRï¼‰ï¼Œèƒ½å¤Ÿä¸€æ­¥ç”Ÿæˆé€¼çœŸçš„SRç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¶å®šæ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆPF-ODEï¼‰è½¨è¿¹ï¼Œä»å¸¦æœ‰å™ªå£°çš„ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒå»ºç«‹ç¡®å®šæ€§æ˜ å°„åˆ°é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬åº”ç”¨ä¸€è‡´æ€§è®­ç»ƒï¼ˆCTï¼‰ç­–ç•¥ç›´æ¥ä¸€æ­¥å­¦ä¹ æ˜ å°„ï¼Œæ¶ˆé™¤äº†é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å¿…è¦æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ€§èƒ½å¹¶æ›´å¥½åœ°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åˆ©ç”¨çœŸå®æ ‡ç­¾ï¼Œæˆ‘ä»¬æ—¨åœ¨ä½¿SRç»“æœåˆ†å¸ƒä¸è‡ªç„¶å›¾åƒåˆ†å¸ƒæ›´ç´§å¯†å¯¹é½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆ†å¸ƒè½¨è¿¹åŒ¹é…ï¼ˆDTMï¼‰æŸå¤±æ¥æœ€å°åŒ–LRå›¾åƒåˆ†å¸ƒå„è‡ªçš„PF-ODEè½¨è¿¹ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæé«˜æ¢å¤çš„é«˜åˆ†è¾¨ç‡å›¾åƒçš„çœŸå®æ„Ÿã€‚ç»¼åˆå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå¯ä»¥è¾¾åˆ°ç›¸å½“ç”šè‡³æ›´ä¼˜çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæœ€ä½æ¨ç†å»¶è¿Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20349v5">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€è’¸é¦çš„ç­–ç•¥â€”â€”ä¸€è‡´æ€§è½¨è¿¹åŒ¹é…è¶…åˆ†è¾¨ç‡ï¼ˆCTMSRï¼‰ï¼Œèƒ½å¤Ÿåœ¨ä¸€æ­¥å†…ç”Ÿæˆé€¼çœŸçš„è¶…åˆ†è¾¨ç‡ç»“æœã€‚è¯¥æ–¹æ³•é€šè¿‡å»ºç«‹æ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆPF-ODEï¼‰è½¨è¿¹æ¥æ˜ å°„ä»å¸¦å™ªå£°çš„ä½åˆ†è¾¨ç‡å›¾åƒåˆ°é«˜åˆ†è¾¨ç‡å›¾åƒçš„å…³ç³»ï¼Œå¹¶åº”ç”¨ä¸€è‡´æ€§è®­ç»ƒç­–ç•¥ç›´æ¥å­¦ä¹ è¿™ç§æ˜ å°„ã€‚åŒæ—¶ï¼Œä¸ºäº†è¿›ä¸€æ­¥æé«˜æ€§èƒ½å¹¶æ›´å¥½åœ°åˆ©ç”¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„çœŸå®æ ‡ç­¾ï¼Œè¯¥æ–¹æ³•è¿˜é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„åˆ†å¸ƒè½¨è¿¹åŒ¹é…ï¼ˆDTMï¼‰æŸå¤±æ¥å‡å°‘è¶…åˆ†è¾¨ç‡ç»“æœåˆ†å¸ƒä¸è‡ªç„¶å›¾åƒåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæé«˜æ¢å¤çš„é«˜åˆ†è¾¨ç‡å›¾åƒçš„çœŸå®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„æ€§èƒ½å¯è¾¾åˆ°æˆ–è¶…è¿‡ç°æœ‰æŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒæä½çš„æ¨ç†å»¶è¿Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰æ‰©æ•£è¶…åˆ†è¾¨ç‡æ–¹æ³•è™½ç„¶æ€§èƒ½è‰¯å¥½ï¼Œä½†æ¨ç†å¼€é”€è¾ƒå¤§ï¼Œéœ€è¦é€šè¿‡è’¸é¦æŠ€æœ¯åŠ é€Ÿã€‚</li>
<li>æå‡ºçš„CTMSRç­–ç•¥æ— éœ€è’¸é¦ï¼Œèƒ½å¤Ÿä¸€æ­¥ç”Ÿæˆè¶…åˆ†è¾¨ç‡ç»“æœï¼Œé™ä½è®­ç»ƒæˆæœ¬ã€‚</li>
<li>CTMSRé€šè¿‡å»ºç«‹PF-ODEè½¨è¿¹æ¥æ˜ å°„ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒçš„å…³ç³»ã€‚</li>
<li>ä¸€è‡´æ€§è®­ç»ƒç­–ç•¥ç”¨äºç›´æ¥å­¦ä¹ è¿™ç§æ˜ å°„ï¼Œæ— éœ€é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>ä¸ºäº†æé«˜æ€§èƒ½ï¼Œé€šè¿‡DTMæŸå¤±å‡å°‘è¶…åˆ†è¾¨ç‡ç»“æœåˆ†å¸ƒä¸è‡ªç„¶å›¾åƒåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜CTMSRåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ¨ç†å»¶è¿Ÿä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20349">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-baa6c5e79fcb8e769fbba49b31bb5c5f" align="middle">
<img src="https://picx.zhimg.com/v2-e39792268f397a3c3f9db7b355aa238a" align="middle">
<img src="https://picx.zhimg.com/v2-dd03c7bf4c9d866d2137b9def7bc7b38" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="FreeSeg-Diff-Training-Free-Open-Vocabulary-Segmentation-with-Diffusion-Models"><a href="#FreeSeg-Diff-Training-Free-Open-Vocabulary-Segmentation-with-Diffusion-Models" class="headerlink" title="FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion   Models"></a>FreeSeg-Diff: Training-Free Open-Vocabulary Segmentation with Diffusion   Models</h2><p><strong>Authors:Barbara Toniella Corradini, Mustafa Shukor, Paul Couairon, Guillaume Couairon, Franco Scarselli, Matthieu Cord</strong></p>
<p>Foundation models have exhibited unprecedented capabilities in tackling many domains and tasks. Models such as CLIP are currently widely used to bridge cross-modal representations, and text-to-image diffusion models are arguably the leading models in terms of realistic image generation. Image generative models are trained on massive datasets that provide them with powerful internal spatial representations. In this work, we explore the potential benefits of such representations, beyond image generation, in particular, for dense visual prediction tasks. We focus on the task of image segmentation, which is traditionally solved by training models on closed-vocabulary datasets, with pixel-level annotations. To avoid the annotation cost or training large diffusion models, we constraint our setup to be zero-shot and training-free. In a nutshell, our pipeline leverages different and relatively small-sized, open-source foundation models for zero-shot open-vocabulary segmentation. The pipeline is as follows: the image is passed to both a captioner model (i.e. BLIP) and a diffusion model (i.e., Stable Diffusion Model) to generate a text description and visual representation, respectively. The features are clustered and binarized to obtain class agnostic masks for each object. These masks are then mapped to a textual class, using the CLIP model to support open-vocabulary. Finally, we add a refinement step that allows to obtain a more precise segmentation mask. Our approach (dubbed FreeSeg-Diff), which does not rely on any training, outperforms many training-based approaches on both Pascal VOC and COCO datasets. In addition, we show very competitive results compared to the recent weakly-supervised segmentation approaches. We provide comprehensive experiments showing the superiority of diffusion model features compared to other pretrained models. Project page: <a target="_blank" rel="noopener" href="https://bcorrad.github.io/freesegdiff/">https://bcorrad.github.io/freesegdiff/</a> </p>
<blockquote>
<p>æ¨¡å‹ï¼Œå¦‚CLIPï¼Œå½“å‰å¹¿æ³›ç”¨äºè·¨æ¨¡æ€è¡¨ç¤ºçš„æ¡¥æ¢ï¼Œæ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹æ— ç–‘æ˜¯ç°å®å›¾åƒç”Ÿæˆé¢†åŸŸçš„é¢†å…ˆæ¨¡å‹ã€‚å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¸ºå®ƒä»¬æä¾›å¼ºå¤§çš„å†…éƒ¨ç©ºé—´è¡¨ç¤ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†è¿™ç§è¡¨ç¤ºåœ¨å›¾åƒç”Ÿæˆä¹‹å¤–çš„æ½œåœ¨ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¯†é›†è§†è§‰é¢„æµ‹ä»»åŠ¡ã€‚æˆ‘ä»¬ä¸“æ³¨äºå›¾åƒåˆ†å‰²ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡ä¼ ç»Ÿä¸Šæ˜¯é€šè¿‡åœ¨å°é—­è¯æ±‡æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹å¹¶é…å¤‡åƒç´ çº§æ³¨é‡Šæ¥è§£å†³çš„ã€‚ä¸ºäº†é¿å…æ³¨é‡Šæˆæœ¬æˆ–è®­ç»ƒå¤§å‹æ‰©æ•£æ¨¡å‹ï¼Œæˆ‘ä»¬å°†è®¾ç½®çº¦æŸä¸ºé›¶å¯åŠ¨ä¸”æ— éœ€è®­ç»ƒã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬çš„ç®¡é“åˆ©ç”¨ä¸åŒä¸”ç›¸å¯¹è¾ƒå°çš„å¼€æºåŸºç¡€æ¨¡å‹è¿›è¡Œé›¶å¯åŠ¨å¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚ç®¡é“å¦‚ä¸‹ï¼šå›¾åƒè¢«ä¼ é€’ç»™æè¿°æ¨¡å‹ï¼ˆä¾‹å¦‚BLIPï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆä¾‹å¦‚Stable Diffusion Modelï¼‰ï¼Œä»¥åˆ†åˆ«ç”Ÿæˆæ–‡æœ¬æè¿°å’Œè§†è§‰è¡¨ç¤ºã€‚è¿™äº›ç‰¹å¾è¢«èšç±»å’ŒäºŒå€¼åŒ–ä»¥è·å–æ¯ä¸ªå¯¹è±¡çš„ç±»ä¸å¯çŸ¥æ©æ¨¡ã€‚ç„¶åï¼Œè¿™äº›æ©æ¨¡è¢«æ˜ å°„åˆ°æ–‡æœ¬ç±»åˆ«ï¼Œä½¿ç”¨CLIPæ¨¡å‹æ”¯æŒå¼€æ”¾è¯æ±‡ã€‚æœ€åï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªç»†åŒ–æ­¥éª¤ï¼Œå…è®¸è·å¾—æ›´ç²¾ç¡®çš„åˆ†å‰²æ©æ¨¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼ˆç§°ä¸ºFreeSeg-Diffï¼‰ä¸ä¾èµ–ä»»ä½•è®­ç»ƒï¼Œåœ¨Pascal VOCå’ŒCOCOæ•°æ®é›†ä¸Šä¼˜äºè®¸å¤šåŸºäºè®­ç»ƒçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä¸æœ€è¿‘çš„å¼±ç›‘ç£åˆ†å‰²æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†æå…·ç«äº‰åŠ›çš„ç»“æœã€‚æˆ‘ä»¬æä¾›äº†å…¨é¢çš„å®éªŒï¼Œæ˜¾ç¤ºæ‰©æ•£æ¨¡å‹ç‰¹å¾ç›¸è¾ƒäºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://bcorrad.github.io/freesegdiff/">https://bcorrad.github.io/freesegdiff/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.20105v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢ç´¢äº†å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚CLIPå’Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼‰åœ¨å¯†é›†è§†è§‰é¢„æµ‹ä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œé‡ç‚¹å…³æ³¨å›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºé›¶æ ·æœ¬å’Œå…è®­ç»ƒç­–ç•¥çš„è‡ªç”±åˆ†å‰²æ–¹æ³•ï¼ˆFreeSeg-Diffï¼‰ï¼Œåˆ©ç”¨å¼€æºåŸºç¡€æ¨¡å‹è¿›è¡Œå¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”Ÿæˆæ–‡æœ¬æè¿°å’Œè§†è§‰è¡¨ç¤ºï¼Œç»“åˆCLIPæ¨¡å‹è¿›è¡Œå¼€æ”¾è¯æ±‡åˆ†ç±»æ˜ å°„ï¼Œè·å¾—ç²¾ç¡®åˆ†å‰²æ©è†œã€‚åœ¨Pascal VOCå’ŒCOCOæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºè®¸å¤šåŸºäºè®­ç»ƒçš„æ–¹æ³•ï¼Œä¸æœ€æ–°çš„å¼±ç›‘ç£åˆ†å‰²æ–¹æ³•ç›¸æ¯”ä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶ä¹Ÿè¿›è¡Œäº†å¯¹æ¯”å®éªŒï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹ç‰¹å¾ç›¸è¾ƒäºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºç¡€æ¨¡å‹å¦‚CLIPåœ¨è·¨æ¨¡æ€è¡¨ç¤ºä¸­å…·æœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>å›¾åƒç”Ÿæˆæ¨¡å‹èƒ½æä¾›å¼ºå¤§çš„å†…éƒ¨ç©ºé—´è¡¨ç¤ºï¼Œè¿™åœ¨å¯†é›†è§†è§‰é¢„æµ‹ä»»åŠ¡ä¸­å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ã€‚</li>
<li>ç ”ç©¶èšç„¦äºé›¶æ ·æœ¬å’Œå…è®­ç»ƒçš„å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼Œåˆ©ç”¨å¼€æºåŸºç¡€æ¨¡å‹å®ç°å¼€æ”¾è¯æ±‡åˆ†å‰²ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†æ–‡æœ¬æè¿°å’Œè§†è§‰è¡¨ç¤ºç”Ÿæˆï¼Œé€šè¿‡CLIPæ¨¡å‹è¿›è¡Œå¼€æ”¾è¯æ±‡åˆ†ç±»æ˜ å°„ã€‚</li>
<li>FreeSeg-Diffæ–¹æ³•åœ¨Pascal VOCå’ŒCOCOæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œç›¸è¾ƒäºè®­ç»ƒæ–¹æ³•å’Œå¼±ç›‘ç£æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ç‰¹å¾ç›¸è¾ƒäºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹å…·æœ‰ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.20105">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee8bd6130226bd4fbd71ecad2d457e8c" align="middle">
<img src="https://picx.zhimg.com/v2-ac8f409f1af84d88ca424ac6a0fdf3bb" align="middle">
<img src="https://picx.zhimg.com/v2-1c5d57e25a579a588b8b5b4d32537b1d" align="middle">
<img src="https://picx.zhimg.com/v2-910198eabf6d0d64d953a0a2e482c241" align="middle">
<img src="https://picx.zhimg.com/v2-53508689d6052c827bb591334f656b54" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-11/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-11/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-602a6d16fb84fdd5ea5fe19865ab5950" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-11  Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-11/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5c76f0fda9369b0d52b7707d03ac2403" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-11  A benchmark multimodal oro-dental dataset for large vision-language   models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32306k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
