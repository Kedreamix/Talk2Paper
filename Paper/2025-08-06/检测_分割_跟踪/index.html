<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  Enhancing Object Discovery for Unsupervised Instance Segmentation and   Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6c014146585de1fbe87fd8be9413e80e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-06-æ›´æ–°"><a href="#2025-08-06-æ›´æ–°" class="headerlink" title="2025-08-06 æ›´æ–°"></a>2025-08-06 æ›´æ–°</h1><h2 id="Enhancing-Object-Discovery-for-Unsupervised-Instance-Segmentation-and-Object-Detection"><a href="#Enhancing-Object-Discovery-for-Unsupervised-Instance-Segmentation-and-Object-Detection" class="headerlink" title="Enhancing Object Discovery for Unsupervised Instance Segmentation and   Object Detection"></a>Enhancing Object Discovery for Unsupervised Instance Segmentation and   Object Detection</h2><p><strong>Authors:Xingyu Feng, Hebei Gao, Hong Li</strong></p>
<p>We propose Cut-Once-and-LEaRn (COLER), a simple approach for unsupervised instance segmentation and object detection. COLER first uses our developed CutOnce to generate coarse pseudo labels, then enables the detector to learn from these masks. CutOnce applies Normalized Cut only once and does not rely on any clustering methods, but it can generate multiple object masks in an image. We have designed several novel yet simple modules that not only allow CutOnce to fully leverage the object discovery capabilities of self-supervised models, but also free it from reliance on mask post-processing. During training, COLER achieves strong performance without requiring specially designed loss functions for pseudo labels, and its performance is further improved through self-training. COLER is a zero-shot unsupervised model that outperforms previous state-of-the-art methods on multiple benchmarks.We believe our method can help advance the field of unsupervised object localization. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†Cut-Once-and-LEaRnï¼ˆCOLERï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ— ç›‘ç£å®ä¾‹åˆ†å‰²å’Œå¯¹è±¡æ£€æµ‹çš„ç®€å•æ–¹æ³•ã€‚COLERé¦–å…ˆä½¿ç”¨æˆ‘ä»¬å¼€å‘çš„CutOnceç”Ÿæˆç²—ç•¥çš„ä¼ªæ ‡ç­¾ï¼Œç„¶åè®©æ£€æµ‹å™¨ä»è¿™äº›æ©è†œä¸­å­¦ä¹ ã€‚CutOnceåªåº”ç”¨ä¸€æ¬¡å½’ä¸€åŒ–åˆ‡å‰²ï¼Œä¸ä¾èµ–ä»»ä½•èšç±»æ–¹æ³•ï¼Œä½†å¯ä»¥åœ¨å›¾åƒä¸­ç”Ÿæˆå¤šä¸ªå¯¹è±¡æ©è†œã€‚æˆ‘ä»¬è®¾è®¡äº†å‡ ç§æ–°é¢–è€Œç®€å•çš„æ¨¡å—ï¼Œè¿™äº›æ¨¡å—ä¸ä»…å…è®¸CutOnceå……åˆ†åˆ©ç”¨è‡ªç›‘ç£æ¨¡å‹çš„å¯¹è±¡å‘ç°èƒ½åŠ›ï¼Œè€Œä¸”è¿˜ä½¿å…¶æ‘†è„±å¯¹æ©è†œåå¤„ç†çš„ä¾èµ–ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒCOLERåœ¨ä¸é’ˆå¯¹ä¼ªæ ‡ç­¾è®¾è®¡ç‰¹æ®ŠæŸå¤±å‡½æ•°çš„æƒ…å†µä¸‹å®ç°äº†å¼ºå¤§çš„æ€§èƒ½ï¼Œå¹¶ä¸”å…¶æ€§èƒ½é€šè¿‡è‡ªè®­ç»ƒå¾—åˆ°äº†è¿›ä¸€æ­¥æé«˜ã€‚COLERæ˜¯ä¸€ç§é›¶æ ·æœ¬æ— ç›‘ç£æ¨¡å‹ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¶…è¿‡äº†ä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å¸®åŠ©æ¨åŠ¨æ— ç›‘ç£å¯¹è±¡å®šä½é¢†åŸŸçš„å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02386v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æå‡ºäº†Cut-Once-and-LEaRnï¼ˆCOLERï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ— ç›‘ç£å®ä¾‹åˆ†å‰²å’Œå¯¹è±¡æ£€æµ‹çš„ç®€å•æ–¹æ³•ã€‚COLERé¦–å…ˆä½¿ç”¨å¼€å‘çš„CutOnceç”Ÿæˆç²—ç•¥ä¼ªæ ‡ç­¾ï¼Œç„¶åä½¿æ£€æµ‹å™¨ä»è¿™äº›æ ‡ç­¾ä¸­å­¦ä¹ ã€‚CutOnceåªåº”ç”¨ä¸€æ¬¡æ ‡å‡†åŒ–åˆ‡å‰²ï¼Œæ— éœ€ä¾èµ–ä»»ä½•èšç±»æ–¹æ³•ï¼Œä½†å¯ä»¥ç”Ÿæˆå›¾åƒä¸­çš„å¤šä¸ªå¯¹è±¡æ©æ¨¡ã€‚é€šè¿‡å‡ ä¸ªæ–°çš„ç®€å•æ¨¡å—ï¼ŒCutOnceä¸ä»…èƒ½å¤Ÿå……åˆ†åˆ©ç”¨è‡ªç›‘ç£æ¨¡å‹çš„å¯¹è±¡å‘ç°èƒ½åŠ›ï¼Œè€Œä¸”æ‘†è„±äº†ä¼ªæ ‡ç­¾çš„ä¾èµ–ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒCOLERæ— éœ€é’ˆå¯¹ä¼ªæ ‡ç­¾è®¾è®¡ç‰¹æ®Šè®¾è®¡çš„æŸå¤±å‡½æ•°ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡è‡ªè®­ç»ƒè¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚COLERæ˜¯ä¸€ä¸ªé›¶æ ·æœ¬æ— ç›‘ç£æ¨¡å‹ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¿‡äº†æœ€æ–°çš„æŠ€æœ¯æ–¹æ³•ã€‚æœ¬æ–‡è®¤ä¸ºè¯¥æ–¹æ³•æœ‰åŠ©äºæ¨åŠ¨æ— ç›‘ç£å¯¹è±¡å®šä½é¢†åŸŸçš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>COLERæ˜¯ä¸€ç§ç”¨äºæ— ç›‘ç£å®ä¾‹åˆ†å‰²å’Œå¯¹è±¡æ£€æµ‹çš„ç®€å•æ–¹æ³•ã€‚</li>
<li>CutOnceç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œç”¨äºè®­ç»ƒæ£€æµ‹å™¨ã€‚</li>
<li>CutOnceé€šè¿‡åº”ç”¨ä¸€æ¬¡æ ‡å‡†åŒ–åˆ‡å‰²ç”Ÿæˆå¤šä¸ªå¯¹è±¡æ©æ¨¡ï¼Œæ— éœ€èšç±»æ–¹æ³•ã€‚</li>
<li>é€šè¿‡æ–°æ¨¡å—çš„åº”ç”¨ï¼ŒCutOnceèƒ½å……åˆ†åˆ©ç”¨è‡ªç›‘ç£æ¨¡å‹çš„å¯¹è±¡å‘ç°èƒ½åŠ›ï¼Œå¹¶æ‘†è„±å¯¹ä¼ªæ ‡ç­¾çš„ä¾èµ–ã€‚</li>
<li>COLERåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ— éœ€ç‰¹æ®Šè®¾è®¡çš„æŸå¤±å‡½æ•°ï¼Œå¯é€šè¿‡è‡ªè®­ç»ƒè¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚</li>
<li>COLERæ˜¯ä¸€ä¸ªé›¶æ ·æœ¬æ— ç›‘ç£æ¨¡å‹ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02386">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3f06bef4c49a0bb56d1d39decac8a97e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ed7b22051b465bab036c28466ea6c3c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f5f4fb6faeef55a77621f9a09d5d31ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69fa25226b76408575b66135099502ff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-635e11c3ae63ecfcbba54b6ff802a3e8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Semi-Supervised-Semantic-Segmentation-via-Derivative-Label-Propagation"><a href="#Semi-Supervised-Semantic-Segmentation-via-Derivative-Label-Propagation" class="headerlink" title="Semi-Supervised Semantic Segmentation via Derivative Label Propagation"></a>Semi-Supervised Semantic Segmentation via Derivative Label Propagation</h2><p><strong>Authors:Yuanbin Fu, Xiaojie Guo</strong></p>
<p>Semi-supervised semantic segmentation, which leverages a limited set of labeled images, helps to relieve the heavy annotation burden. While pseudo-labeling strategies yield promising results, there is still room for enhancing the reliability of pseudo-labels. Hence, we develop a semi-supervised framework, namely DerProp, equipped with a novel derivative label propagation to rectify imperfect pseudo-labels. Our label propagation method imposes discrete derivative operations on pixel-wise feature vectors as additional regularization, thereby generating strictly regularized similarity metrics. Doing so effectively alleviates the ill-posed problem that identical similarities correspond to different features, through constraining the solution space. Extensive experiments are conducted to verify the rationality of our design, and demonstrate our superiority over other methods. Codes are available at <a target="_blank" rel="noopener" href="https://github.com/ForawardStar/DerProp/">https://github.com/ForawardStar/DerProp/</a>. </p>
<blockquote>
<p>åŠç›‘ç£è¯­ä¹‰åˆ†å‰²åˆ©ç”¨æœ‰é™çš„æ ‡è®°å›¾åƒï¼Œæœ‰åŠ©äºå‡è½»ç¹é‡çš„æ ‡æ³¨è´Ÿæ‹…ã€‚è™½ç„¶ä¼ªæ ‡ç­¾ç­–ç•¥å–å¾—äº†ä»¤äººé¼“èˆçš„ç»“æœï¼Œä½†æé«˜ä¼ªæ ‡ç­¾çš„å¯é æ€§ä»æœ‰ç©ºé—´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåä¸ºDerPropçš„åŠç›‘ç£æ¡†æ¶ï¼Œé…å¤‡äº†ä¸€ç§æ–°å‹è¡ç”Ÿæ ‡ç­¾ä¼ æ’­æ–¹æ³•ï¼Œä»¥ä¿®æ­£ä¸å®Œç¾çš„ä¼ªæ ‡ç­¾ã€‚æˆ‘ä»¬çš„æ ‡ç­¾ä¼ æ’­æ–¹æ³•å°†ç¦»æ•£å¯¼æ•°è¿ç®—æ–½åŠ äºåƒç´ çº§ç‰¹å¾å‘é‡ä½œä¸ºé¢å¤–çš„æ­£åˆ™åŒ–ï¼Œä»è€Œäº§ç”Ÿä¸¥æ ¼æ­£åˆ™åŒ–çš„ç›¸ä¼¼åº¦åº¦é‡ã€‚è¿™æ ·åšå¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£ä¸é€‚å®šé—®é¢˜ï¼Œå³ç›¸åŒçš„ç›¸ä¼¼åº¦å¯¹åº”äºä¸åŒçš„ç‰¹å¾ï¼Œé€šè¿‡çº¦æŸè§£ç©ºé—´æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒæ¥éªŒè¯è®¾è®¡çš„åˆç†æ€§ï¼Œå¹¶è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/ForawardStar/DerProp/%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ForawardStar/DerProp/è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02254v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæœ‰é™æ ‡è®°å›¾åƒé›†çš„æ–°å‹åŠç›‘ç£è¯­ä¹‰åˆ†å‰²æ¡†æ¶DerPropã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°å‹æ ‡ç­¾ä¼ æ’­ç­–ç•¥æ¥çº æ­£ä¸å®Œç¾çš„ä¼ªæ ‡ç­¾ï¼Œå¯¹åƒç´ çº§ç‰¹å¾å‘é‡è¿›è¡Œç¦»æ•£å¯¼æ•°æ“ä½œï¼Œç”Ÿæˆä¸¥æ ¼çš„è§„åˆ™åŒ–ç›¸ä¼¼æ€§åº¦é‡ï¼Œæœ‰æ•ˆè§£å†³ç›¸ä¼¼ç‰¹å¾å¯¹åº”çš„ä¼ªæ ‡ç­¾é”™è¯¯é—®é¢˜ï¼Œå¹¶åœ¨å®éªŒä¸Šè¯æ˜äº†å…¶è®¾è®¡çš„åˆç†æ€§å’Œè¶…è¶Šå…¶ä»–æ–¹æ³•çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºæœ‰é™æ ‡è®°å›¾åƒé›†çš„æ–°å‹åŠç›‘ç£è¯­ä¹‰åˆ†å‰²æ¡†æ¶DerPropã€‚</li>
<li>é‡‡ç”¨æ–°å‹æ ‡ç­¾ä¼ æ’­ç­–ç•¥æ¥çº æ­£ä¼ªæ ‡ç­¾ã€‚</li>
<li>å¯¹åƒç´ çº§ç‰¹å¾å‘é‡è¿›è¡Œç¦»æ•£å¯¼æ•°æ“ä½œï¼Œç”Ÿæˆè§„åˆ™åŒ–çš„ç›¸ä¼¼æ€§åº¦é‡ã€‚</li>
<li>è§£å†³ç›¸ä¼¼ç‰¹å¾å¯¹åº”çš„ä¼ªæ ‡ç­¾é”™è¯¯é—®é¢˜ã€‚</li>
<li>å®éªŒéªŒè¯äº†è®¾è®¡çš„åˆç†æ€§ä»¥åŠDerPropç›¸å¯¹äºå…¶ä»–æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>ä»£ç å·²ç»å¼€æºå¹¶å¯åœ¨ç½‘ä¸Šè·å–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02254">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-362fdbe9b3c7230d282b64bd9f25978e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51d4e090bec061e8e10e97d9fc9ee490.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c03b5a34caabc95e7c189eee6d5c4482.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f089ad40274a2410ca39dda72eabe5f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Unified-Category-Level-Object-Detection-and-Pose-Estimation-from-RGB-Images-using-3D-Prototypes"><a href="#Unified-Category-Level-Object-Detection-and-Pose-Estimation-from-RGB-Images-using-3D-Prototypes" class="headerlink" title="Unified Category-Level Object Detection and Pose Estimation from RGB   Images using 3D Prototypes"></a>Unified Category-Level Object Detection and Pose Estimation from RGB   Images using 3D Prototypes</h2><p><strong>Authors:Tom Fischer, Xiaojie Zhang, Eddy Ilg</strong></p>
<p>Recognizing objects in images is a fundamental problem in computer vision. Although detecting objects in 2D images is common, many applications require determining their pose in 3D space. Traditional category-level methods rely on RGB-D inputs, which may not always be available, or employ two-stage approaches that use separate models and representations for detection and pose estimation. For the first time, we introduce a unified model that integrates detection and pose estimation into a single framework for RGB images by leveraging neural mesh models with learned features and multi-model RANSAC. Our approach achieves state-of-the-art results for RGB category-level pose estimation on REAL275, improving on the current state-of-the-art by 22.9% averaged across all scale-agnostic metrics. Finally, we demonstrate that our unified method exhibits greater robustness compared to single-stage baselines. Our code and models are available at <a target="_blank" rel="noopener" href="https://github.com/Fischer-Tom/unified-detection-and-pose-estimation">https://github.com/Fischer-Tom/unified-detection-and-pose-estimation</a>. </p>
<blockquote>
<p>è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚è™½ç„¶æ£€æµ‹äºŒç»´å›¾åƒä¸­çš„ç‰©ä½“å¾ˆå¸¸è§ï¼Œä½†è®¸å¤šåº”ç”¨éœ€è¦ç¡®å®šå…¶åœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„å§¿æ€ã€‚ä¼ ç»Ÿçš„ç±»åˆ«çº§åˆ«çš„æ–¹æ³•ä¾èµ–äºRGB-Dè¾“å…¥ï¼Œè¿™å¯èƒ½å¹¶ä¸æ€»æ˜¯å¯ç”¨ï¼Œæˆ–è€…é‡‡ç”¨ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œä½¿ç”¨ç‹¬ç«‹çš„æ¨¡å‹å’Œè¡¨ç¤ºä¸ºæ£€æµ‹å’Œå§¿æ€ä¼°è®¡å»ºæ¨¡ã€‚é¦–æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç»Ÿä¸€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨ç¥ç»ç½‘æ ¼æ¨¡å‹å­¦ä¹ çš„ç‰¹å¾å’ŒåŸºäºå¤šæ¨¡å‹çš„RANSACå°†æ£€æµ‹å’Œå§¿æ€ä¼°è®¡é›†æˆåˆ°ä¸€ä¸ªå•ä¸€çš„RGBå›¾åƒæ¡†æ¶ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨REAL275çš„RGBç±»åˆ«çº§åˆ«çš„å§¿æ€ä¼°è®¡ä¸Šå–å¾—äº†æœ€æ–°çš„ç»“æœï¼Œåœ¨æ‰€æœ‰å°ºåº¦æ— å…³æŒ‡æ ‡ä¸Šçš„å¹³å‡è¡¨ç°è¾ƒå½“å‰æœ€ä½³æ°´å¹³æé«˜äº†22.9%ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ç»Ÿä¸€æ–¹æ³•æ¯”å•é˜¶æ®µåŸºçº¿å±•ç°å‡ºæ›´å¤§çš„ç¨³å¥æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹åœ¨<a target="_blank" rel="noopener" href="https://github.com/Fischer-Tom/unified-detection-and-pose-estimation%E4%B8%8A%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/Fischer-Tom/unified-detection-and-pose-estimationä¸Šå¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02157v1">PDF</a> Published at ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„ç»Ÿä¸€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹å’Œå­¦ä¹ çš„ç‰¹å¾ä»¥åŠå¤šæ¨¡æ€RANSACï¼Œå°†ç‰©ä½“æ£€æµ‹ä¸å§¿æ€ä¼°è®¡æ•´åˆåˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œä»…ä½¿ç”¨RGBå›¾åƒå³å¯å®ç°ã€‚è¯¥æ–¹æ³•åœ¨RGBç±»åˆ«çº§åˆ«çš„å§¿æ€ä¼°è®¡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆæœï¼Œå¹¶è¡¨ç°å‡ºè¾ƒé«˜çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡è§£å†³äº†è®¡ç®—æœºè§†è§‰ä¸­çš„ç‰©ä½“è¯†åˆ«é—®é¢˜ï¼Œå¹¶é‡ç‚¹å…³æ³¨åœ¨å›¾åƒä¸­çš„ç‰©ä½“æ£€æµ‹åŠå…¶åœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„å§¿æ€ç¡®å®šã€‚</li>
<li>ä¼ ç»Ÿçš„æ–¹æ³•é€šå¸¸ä¾èµ–äºRGB-Dè¾“å…¥æˆ–ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œéœ€è¦ä½¿ç”¨ç‹¬ç«‹çš„æ¨¡å‹å’Œè¡¨ç¤ºè¿›è¡Œæ£€æµ‹å’Œå§¿æ€ä¼°è®¡ã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡å¼•å…¥äº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†æ£€æµ‹å’Œå§¿æ€ä¼°è®¡æ•´åˆåˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ï¼Œä»…ä½¿ç”¨RGBå›¾åƒã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹å’Œå­¦ä¹ çš„ç‰¹å¾ï¼Œä»¥åŠå¤šæ¨¡æ€RANSACæ¥å®ç°ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨RGBç±»åˆ«çº§åˆ«çš„å§¿æ€ä¼°è®¡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆæœï¼Œå¹³å‡æ”¹è¿›äº†å½“å‰æœ€å…ˆè¿›æŠ€æœ¯çš„22.9%ã€‚</li>
<li>ä¸å•é˜¶æ®µåŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ›´é«˜çš„ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02157">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da2bfd6067af96f3329bb82cc0e384d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2e63c652391abe5a02ce1f5f361e11f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-caca239ff317f5769b8d2bb9db054288.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f07e49deb17a67d0b0b375ab1f6cac13.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Beyond-RGB-and-Events-Enhancing-Object-Detection-under-Adverse-Lighting-with-Monocular-Normal-Maps"><a href="#Beyond-RGB-and-Events-Enhancing-Object-Detection-under-Adverse-Lighting-with-Monocular-Normal-Maps" class="headerlink" title="Beyond RGB and Events: Enhancing Object Detection under Adverse Lighting   with Monocular Normal Maps"></a>Beyond RGB and Events: Enhancing Object Detection under Adverse Lighting   with Monocular Normal Maps</h2><p><strong>Authors:Mingjie Liu, Hanqing Liu, Chuang Zhu</strong></p>
<p>Accurate object detection under adverse lighting conditions is critical for real-world applications such as autonomous driving. Although neuromorphic event cameras have been introduced to handle these scenarios, adverse lighting often induces distracting reflections from tunnel walls or road surfaces, which frequently lead to false obstacle detections. However, neither RGB nor event data alone is robust enough to address these complexities, and mitigating these issues without additional sensors remains underexplored. To overcome these challenges, we propose leveraging normal maps, directly predicted from monocular RGB images, as robust geometric cues to suppress false positives and enhance detection accuracy. We introduce NRE-Net, a novel multi-modal detection framework that effectively fuses three complementary modalities: monocularly predicted surface normal maps, RGB images, and event streams. To optimize the fusion process, our framework incorporates two key modules: the Adaptive Dual-stream Fusion Module (ADFM), which integrates RGB and normal map features, and the Event-modality Aware Fusion Module (EAFM), which adapts to the high dynamic range characteristics of event data. Extensive evaluations on the DSEC-Det-sub and PKU-DAVIS-SOD datasets demonstrate that NRE-Net significantly outperforms state-of-the-art methods. Our approach achieves mAP50 improvements of 7.9% and 6.1% over frame-based approaches (e.g., YOLOX), while surpassing the fusion-based SFNet by 2.7% on the DSEC-Det-sub dataset and SODFormer by 7.1% on the PKU-DAVIS-SOD dataset. </p>
<blockquote>
<p>åœ¨æ¶åŠ£ç…§æ˜æ¡ä»¶ä¸‹å‡†ç¡®çš„ç›®æ ‡æ£€æµ‹å¯¹äºè‡ªåŠ¨é©¾é©¶ç­‰å®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚å°½ç®¡ç¥ç»å½¢æ€äº‹ä»¶ç›¸æœºå·²ç»è¢«å¼•å…¥æ¥å¤„ç†è¿™äº›åœºæ™¯ï¼Œä½†æ¶åŠ£çš„ç…§æ˜æ¡ä»¶å¾€å¾€ä¼šå¼•èµ·éš§é“å¢™å£æˆ–è·¯é¢è¡¨é¢çš„åå°„å¹²æ‰°ï¼Œè¿™ç»å¸¸å¯¼è‡´é”™è¯¯çš„éšœç¢ç‰©æ£€æµ‹ã€‚ç„¶è€Œï¼Œæ— è®ºæ˜¯RGBè¿˜æ˜¯å•ç‹¬çš„äº‹ä»¶æ•°æ®ï¼Œéƒ½æ— æ³•è¶³å¤Ÿç¨³å¥åœ°åº”å¯¹è¿™äº›å¤æ‚æ€§ï¼Œè€Œä¸”ä¸ä¾èµ–é¢å¤–çš„ä¼ æ„Ÿå™¨æ¥ç¼“è§£è¿™äº›é—®é¢˜ä»ç„¶ç¼ºä¹è¶³å¤Ÿçš„æ¢ç´¢ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨ä»å•ç›®RGBå›¾åƒç›´æ¥é¢„æµ‹å¾—åˆ°çš„æ³•çº¿å›¾ä½œä¸ºç¨³å¥çš„å‡ ä½•çº¿ç´¢æ¥æŠ‘åˆ¶è¯¯æŠ¥å¹¶å¢å¼ºæ£€æµ‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†NRE-Netï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€æ£€æµ‹æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆä¸‰ç§äº’è¡¥æ¨¡æ€ï¼šä»å•ç›®ä¸­é¢„æµ‹çš„æ³•çº¿å›¾ã€RGBå›¾åƒå’Œäº‹ä»¶æµã€‚ä¸ºäº†ä¼˜åŒ–èåˆè¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„æ¡†æ¶é‡‡ç”¨äº†ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šè‡ªé€‚åº”åŒæµèåˆæ¨¡å—ï¼ˆADFMï¼‰ï¼Œå®ƒèåˆäº†RGBå’Œæ³•å›¾ç‰¹å¾ï¼›äº‹ä»¶æ¨¡æ€æ„ŸçŸ¥èåˆæ¨¡å—ï¼ˆEAFMï¼‰ï¼Œå®ƒé€‚åº”äº†äº‹ä»¶æ•°æ®çš„é«˜åŠ¨æ€èŒƒå›´ç‰¹æ€§ã€‚åœ¨DSEC-Det-subå’ŒPKU-DAVIS-SODæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒNRE-Netæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸºäºå¸§çš„æ–¹æ³•ï¼ˆä¾‹å¦‚YOLOXï¼‰çš„åŸºç¡€ä¸Šæé«˜äº†mAP50çš„å‡†ç¡®åº¦ï¼Œè¾¾åˆ°7.9%å’Œ6.1%ï¼Œè€Œåœ¨åŸºäºèåˆçš„æ–¹æ³•ä¸­ï¼Œç›¸è¾ƒäºSFNetåœ¨DSEC-Det-subæ•°æ®é›†ä¸Šæé«˜äº†2.7%ï¼Œç›¸è¾ƒäºSODFormeråœ¨PKU-DAVIS-SODæ•°æ®é›†ä¸Šæé«˜äº†7.1%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02127v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åœ¨æ¶åŠ£ç…§æ˜æ¡ä»¶ä¸‹å‡†ç¡®çš„ç›®æ ‡æ£€æµ‹å¯¹äºè‡ªåŠ¨é©¾é©¶ç­‰å®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚å°½ç®¡ç¥ç»å½¢æ€äº‹ä»¶ç›¸æœºå·²è¢«å¼•å…¥å¤„ç†è¿™äº›æƒ…å†µï¼Œä½†æ¶åŠ£çš„ç…§æ˜æ¡ä»¶ç»å¸¸åœ¨éš§é“å¢™å£æˆ–è·¯é¢è¡¨é¢å¼•èµ·å¹²æ‰°åå°„ï¼Œè¿™ç»å¸¸å¯¼è‡´é”™è¯¯çš„éšœç¢æ£€æµ‹ã€‚ç„¶è€Œï¼Œæ— è®ºæ˜¯RGBè¿˜æ˜¯äº‹ä»¶æ•°æ®æœ¬èº«éƒ½ä¸è¶³ä»¥åº”å¯¹è¿™äº›å¤æ‚æ€§ï¼Œè€Œä¸”ä¸ä¾èµ–é¢å¤–ä¼ æ„Ÿå™¨æ¥å‡è½»è¿™äº›é—®é¢˜ä»ç„¶æ˜¯ä¸€ä¸ªå°šæœªå……åˆ†ç ”ç©¶çš„é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†åˆ©ç”¨ä»å•ç›®RGBå›¾åƒç›´æ¥é¢„æµ‹å¾—åˆ°çš„æ³•çº¿å›¾ä½œä¸ºå¯é çš„å‡ ä½•çº¿ç´¢æ¥æŠ‘åˆ¶è¯¯æŠ¥å¹¶æé«˜æ£€æµ‹å‡†ç¡®æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†NRE-Netï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€æ£€æµ‹æ¡†æ¶ï¼Œå®ƒæœ‰æ•ˆåœ°èåˆäº†ä¸‰ç§äº’è¡¥æ¨¡æ€ï¼šä»å•ç›®å›¾åƒé¢„æµ‹å¾—åˆ°çš„è¡¨é¢æ³•çº¿å›¾ã€RGBå›¾åƒå’Œäº‹ä»¶æµã€‚ä¸ºäº†ä¼˜åŒ–èåˆè¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„æ¡†æ¶é‡‡ç”¨äº†ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šè‡ªé€‚åº”åŒæµèåˆæ¨¡å—ï¼ˆADFMï¼‰ï¼Œå®ƒèåˆäº†RGBå’Œæ³•çº¿å›¾ç‰¹å¾ï¼›äº‹ä»¶æ¨¡æ€æ„ŸçŸ¥èåˆæ¨¡å—ï¼ˆEAFMï¼‰ï¼Œå®ƒé€‚åº”äº†äº‹ä»¶æ•°æ®çš„é«˜åŠ¨æ€èŒƒå›´ç‰¹æ€§ã€‚åœ¨DSEC-Det-subå’ŒPKU-DAVIS-SODæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒNRE-Netæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨DSEC-Det-subæ•°æ®é›†ä¸Šè¾ƒåŸºäºå¸§çš„æ–¹æ³•ï¼ˆä¾‹å¦‚YOLOXï¼‰æé«˜äº†mAP50å¾—åˆ†7.9ï¼…å’Œ6.1ï¼…ï¼Œå¹¶åœ¨PKU-DAVIS-SODæ•°æ®é›†ä¸Šè¾ƒèåˆæ–¹æ³•çš„SODFormeré«˜å‡º7.1ï¼…ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>åœ¨æ¶åŠ£ç…§æ˜æ¡ä»¶ä¸‹ï¼Œç›®æ ‡æ£€æµ‹é¢ä¸´å¹²æ‰°åå°„é—®é¢˜ï¼Œå¯¼è‡´è¯¯æŠ¥ã€‚</li>
<li>ä»…ä¾èµ–RGBæˆ–äº‹ä»¶æ•°æ®ä¸è¶³ä»¥è§£å†³è¿™äº›å¤æ‚æ€§ã€‚</li>
<li>æå‡ºåˆ©ç”¨ä»å•ç›®RGBå›¾åƒç›´æ¥é¢„æµ‹å¾—åˆ°çš„æ³•çº¿å›¾ä½œä¸ºå‡ ä½•çº¿ç´¢æ¥æé«˜æ£€æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>ä»‹ç»NRE-Netå¤šæ¨¡æ€æ£€æµ‹æ¡†æ¶ï¼Œèåˆäº†RGBå›¾åƒã€äº‹ä»¶æµå’Œæ³•çº¿å›¾ä¸‰ç§æ¨¡æ€ã€‚</li>
<li>æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šADFMå’ŒEAFMï¼Œåˆ†åˆ«ç”¨äºç‰¹å¾èåˆå’Œé€‚åº”äº‹ä»¶æ•°æ®çš„é«˜åŠ¨æ€èŒƒå›´ç‰¹æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02127">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5c18e59acb0c65b2b42f0ace7e34efd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00cd4bee9f04fcd035d3e3f0f180aae3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f4f172d00655c3ce761b85432f912f7e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c014146585de1fbe87fd8be9413e80e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Self-Supervised-YOLO-Leveraging-Contrastive-Learning-for-Label-Efficient-Object-Detection"><a href="#Self-Supervised-YOLO-Leveraging-Contrastive-Learning-for-Label-Efficient-Object-Detection" class="headerlink" title="Self-Supervised YOLO: Leveraging Contrastive Learning for   Label-Efficient Object Detection"></a>Self-Supervised YOLO: Leveraging Contrastive Learning for   Label-Efficient Object Detection</h2><p><strong>Authors:Manikanta Kotthapalli, Reshma Bhatia, Nainsi Jain</strong></p>
<p>One-stage object detectors such as the YOLO family achieve state-of-the-art performance in real-time vision applications but remain heavily reliant on large-scale labeled datasets for training. In this work, we present a systematic study of contrastive self-supervised learning (SSL) as a means to reduce this dependency by pretraining YOLOv5 and YOLOv8 backbones on unlabeled images using the SimCLR framework. Our approach introduces a simple yet effective pipeline that adapts YOLOâ€™s convolutional backbones as encoders, employs global pooling and projection heads, and optimizes a contrastive loss using augmentations of the COCO unlabeled dataset (120k images). The pretrained backbones are then fine-tuned on a cyclist detection task with limited labeled data. Experimental results show that SSL pretraining leads to consistently higher mAP, faster convergence, and improved precision-recall performance, especially in low-label regimes. For example, our SimCLR-pretrained YOLOv8 achieves a mAP@50:95 of 0.7663, outperforming its supervised counterpart despite using no annotations during pretraining. These findings establish a strong baseline for applying contrastive SSL to one-stage detectors and highlight the potential of unlabeled data as a scalable resource for label-efficient object detection. </p>
<blockquote>
<p>å•é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨ï¼Œå¦‚YOLOç³»åˆ—ï¼Œåœ¨å®æ—¶è§†è§‰åº”ç”¨ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä½†ä»ä¸¥é‡ä¾èµ–äºå¤§è§„æ¨¡æ ‡æ³¨æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹å¯¹æ¯”è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œä»¥å‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨SimCLRæ¡†æ¶ï¼Œå¯¹YOLOv5å’ŒYOLOv8çš„ä¸»å¹²ç½‘ç»œè¿›è¡Œé¢„è®­ç»ƒï¼Œåˆ©ç”¨æ— æ ‡ç­¾å›¾åƒæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„æµç¨‹ï¼Œå°†YOLOçš„å·ç§¯ä¸»å¹²ç½‘ç»œä½œä¸ºç¼–ç å™¨ï¼Œé‡‡ç”¨å…¨å±€æ± åŒ–å’ŒæŠ•å½±å¤´ï¼Œå¹¶ä½¿ç”¨COCOæ— æ ‡ç­¾æ•°æ®é›†ï¼ˆ12ä¸‡å¼ å›¾åƒï¼‰çš„å¢å¼ºç‰ˆæ¥ä¼˜åŒ–å¯¹æ¯”æŸå¤±ã€‚ç„¶åï¼Œåœ¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ä¸Šï¼Œå¯¹é¢„è®­ç»ƒçš„ä¸»å¹²ç½‘ç»œè¿›è¡Œå¾®è°ƒï¼Œä»¥æ‰§è¡Œéª‘è¡Œè€…æ£€æµ‹ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSLé¢„è®­ç»ƒèƒ½æŒç»­æé«˜mAPã€åŠ å¿«æ”¶æ•›é€Ÿåº¦å¹¶æ”¹å–„ç²¾åº¦-å¬å›ç‡æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ ‡æ³¨æ•°æ®è¾ƒå°‘çš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬é‡‡ç”¨SimCLRé¢„è®­ç»ƒçš„YOLOv8åœ¨mAP@50:95ä¸Šè¾¾åˆ°äº†0.7663ï¼Œå°½ç®¡åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­æ²¡æœ‰ä½¿ç”¨ä»»ä½•æ³¨é‡Šï¼Œä»ä¼˜äºå…¶æœ‰ç›‘ç£çš„åŒç±»æ¨¡å‹ã€‚è¿™äº›å‘ç°ä¸ºå°†å¯¹æ¯”SSLåº”ç”¨äºå•é˜¶æ®µæ£€æµ‹å™¨å»ºç«‹äº†å¼ºå¤§çš„åŸºçº¿ï¼Œå¹¶çªå‡ºäº†æ— æ ‡ç­¾æ•°æ®ä½œä¸ºæ ‡ç­¾é«˜æ•ˆç›®æ ‡æ£€æµ‹çš„å¯æ‰©å±•èµ„æºçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01966v1">PDF</a> 11 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºYOLOç³»åˆ—çš„ä¸€é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨åœ¨å®æ—¶è§†è§‰åº”ç”¨ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸¥é‡ä¾èµ–äºå¤§è§„æ¨¡æ ‡ç­¾æ•°æ®é›†ã€‚æœ¬æ–‡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†å¯¹æ¯”å‹è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æŠ€æœ¯ï¼Œä»¥å‡å°å¯¹è¿™ç§ä¾èµ–ç¨‹åº¦ã€‚é€šè¿‡åœ¨æœªæ ‡è®°çš„å›¾åƒä¸Šé‡‡ç”¨SimCLRæ¡†æ¶é¢„è®­ç»ƒYOLOv5å’ŒYOLOv8çš„backboneéƒ¨åˆ†ï¼Œç ”ç©¶å¼•å…¥äº†ç®€å•æœ‰æ•ˆçš„ç®¡é“çº¿ã€‚æ­¤æ–¹æ³•å¯¹YOLOçš„å·ç§¯ä¸»å¹²è¿›è¡Œé€‚åº”æ€§è°ƒæ•´ï¼Œå°†å…¶ä½œä¸ºç¼–ç å™¨ï¼Œå¹¶åˆ©ç”¨å…¨å±€æ± åŒ–å’ŒæŠ•å½±å¤´æ¥ä¼˜åŒ–å¯¹æ¯”æŸå¤±ï¼Œå¹¶åˆ©ç”¨COCOæ— æ ‡ç­¾æ•°æ®é›†çš„æ‰©å……è¿›è¡Œä¼˜åŒ–è®­ç»ƒã€‚ä¹‹åä½¿ç”¨æœ‰é™çš„æ ‡è®°æ•°æ®å¯¹é¢„è®­ç»ƒçš„backboneè¿›è¡Œå¾®è°ƒï¼Œç”¨äºéª‘è¡Œè€…æ£€æµ‹ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSSLé¢„è®­ç»ƒæŒç»­æé«˜äº†mAPå€¼ã€åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æ”¹å–„äº†ç²¾åº¦å¬å›æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ ‡ç­¾ç¨€ç¼ºçš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨SimCLRé¢„è®­ç»ƒçš„YOLOv8åœ¨mAP@50:95æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†0.7663ï¼Œå°½ç®¡åœ¨é¢„è®­ç»ƒé˜¶æ®µæœªä½¿ç”¨ä»»ä½•æ³¨é‡Šï¼Œä½†è¶…è¶Šäº†å…¶æœ‰ç›‘ç£è®­ç»ƒä¸‹çš„æ€§èƒ½æ°´å¹³ã€‚è¿™ä¸€å‘ç°å¯¹äºå°†å¯¹æ¯”å‹SSLåº”ç”¨åœ¨ä¸€é˜¶æ®µæ£€æµ‹å™¨ä¸Šå…·æœ‰é‡è¦çš„é‡Œç¨‹ç¢‘æ„ä¹‰ï¼Œå¹¶çªå‡ºäº†æœªæ ‡è®°æ•°æ®ä½œä¸ºæ ‡ç­¾é«˜æ•ˆç›®æ ‡æ£€æµ‹çš„æ½œåœ¨å¯æ‰©å±•èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸€é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨å¦‚YOLOç³»åˆ—åœ¨å®æ—¶è§†è§‰åº”ç”¨ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†å¯¹å¤§è§„æ¨¡æ ‡ç­¾æ•°æ®é›†ä¾èµ–æ€§å¼ºã€‚</li>
<li>å¯¹æ¯”å‹è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰ç”¨äºå‡å°‘è¿™ç§ä¾èµ–ã€‚</li>
<li>é‡‡ç”¨SimCLRæ¡†æ¶è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿ç”¨æœªæ ‡è®°å›¾åƒå¯¹YOLOv5å’ŒYOLOv8çš„backboneè¿›è¡Œè®­ç»ƒã€‚</li>
<li>é¢„è®­ç»ƒæ¨¡å‹åœ¨éª‘è¡Œè€…æ£€æµ‹ä»»åŠ¡ä¸Šé€šè¿‡æœ‰é™çš„æ ‡è®°æ•°æ®è¿›è¡Œå¾®è°ƒã€‚</li>
<li>SSLé¢„è®­ç»ƒæé«˜äº†mAPå€¼ã€åŠ å¿«äº†æ”¶æ•›é€Ÿåº¦å¹¶æ”¹å–„äº†ç²¾åº¦å¬å›æ€§èƒ½ã€‚</li>
<li>åœ¨ä½æ ‡ç­¾æ•°æ®æƒ…å†µä¸‹ï¼ŒSSLé¢„è®­ç»ƒå°¤ä¸ºé‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01966">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8eb0be628f43ece6eae4efb8b100f75d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bf3cf53c8fba3233712024eac7a93bc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73bf5ced1bae2b59aeefb91d948fd39f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Referring-Remote-Sensing-Image-Segmentation-with-Cross-view-Semantics-Interaction-Network"><a href="#Referring-Remote-Sensing-Image-Segmentation-with-Cross-view-Semantics-Interaction-Network" class="headerlink" title="Referring Remote Sensing Image Segmentation with Cross-view Semantics   Interaction Network"></a>Referring Remote Sensing Image Segmentation with Cross-view Semantics   Interaction Network</h2><p><strong>Authors:Jiaxing Yang, Lihe Zhang, Huchuan Lu</strong></p>
<p>Recently, Referring Remote Sensing Image Segmentation (RRSIS) has aroused wide attention. To handle drastic scale variation of remote targets, existing methods only use the full image as input and nest the saliency-preferring techniques of cross-scale information interaction into traditional single-view structure. Although effective for visually salient targets, they still struggle in handling tiny, ambiguous ones in lots of real scenarios. In this work, we instead propose a paralleled yet unified segmentation framework Cross-view Semantics Interaction Network (CSINet) to solve the limitations. Motivated by human behavior in observing targets of interest, the network orchestrates visual cues from remote and close distances to conduct synergistic prediction. In its every encoding stage, a Cross-View Window-attention module (CVWin) is utilized to supplement global and local semantics into close-view and remote-view branch features, finally promoting the unified representation of feature in every encoding stage. In addition, we develop a Collaboratively Dilated Attention enhanced Decoder (CDAD) to mine the orientation property of target and meanwhile integrate cross-view multiscale features. The proposed network seamlessly enhances the exploitation of global and local semantics, achieving significant improvements over others while maintaining satisfactory speed. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œé¥æ„Ÿå›¾åƒåˆ†å‰²ï¼ˆRRSISï¼‰å·²å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚åœ¨å¤„ç†é¥æ„Ÿç›®æ ‡çš„å°ºåº¦å‰§å˜æ—¶ï¼Œç°æœ‰æ–¹æ³•ä»…ä½¿ç”¨å…¨å›¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†è·¨å°ºåº¦ä¿¡æ¯äº¤äº’çš„æ˜¾è‘—æ€§ä¼˜å…ˆæŠ€æœ¯åµŒå…¥åˆ°ä¼ ç»Ÿçš„å•è§†å›¾ç»“æ„ä¸­ã€‚å°½ç®¡å¯¹äºè§†è§‰ä¸Šæ˜¾è‘—çš„ç›®æ ‡è¿™äº›æ–¹æ³•å¾ˆæœ‰æ•ˆï¼Œä½†åœ¨å¤„ç†ç°å®ä¸­å¤§é‡çš„å°å‹ã€æ¨¡ç³Šçš„ç›®æ ‡æ—¶ï¼Œå®ƒä»¬ä»ç„¶å­˜åœ¨é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¹¶è¡Œä½†ç»Ÿä¸€çš„åˆ†å‰²æ¡†æ¶â€”â€”è·¨è§†å›¾è¯­ä¹‰äº¤äº’ç½‘ç»œï¼ˆCSINetï¼‰ï¼Œä»¥è§£å†³è¿™äº›é™åˆ¶ã€‚å—äººç±»è§‚å¯Ÿæ„Ÿå…´è¶£ç›®æ ‡çš„è¡Œä¸ºçš„å¯å‘ï¼Œè¯¥ç½‘ç»œåè°ƒæ¥è‡ªè¿œè¿‘è·ç¦»çš„è§†è§‰çº¿ç´¢æ¥è¿›è¡ŒååŒé¢„æµ‹ã€‚åœ¨å…¶æ¯ä¸ªç¼–ç é˜¶æ®µï¼Œä½¿ç”¨è·¨è§†å›¾çª—å£æ³¨æ„åŠ›æ¨¡å—ï¼ˆCVWinï¼‰å°†å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰è¡¥å……åˆ°è¿‘è§†å›¾å’Œè¿œè§†å›¾åˆ†æ”¯ç‰¹å¾ä¸­ï¼Œæœ€ç»ˆä¿ƒè¿›æ¯ä¸ªç¼–ç é˜¶æ®µç‰¹å¾çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ååŒæ‰©å¼ æ³¨æ„åŠ›å¢å¼ºè§£ç å™¨ï¼ˆCDADï¼‰ï¼Œä»¥æŒ–æ˜ç›®æ ‡çš„æ–¹å‘å±æ€§ï¼ŒåŒæ—¶é›†æˆè·¨è§†å›¾çš„å¤šå°ºåº¦ç‰¹å¾ã€‚æ‰€æå‡ºçš„ç½‘ç»œæ— ç¼åœ°å¢å¼ºäº†å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰çš„åˆ©ç”¨ï¼Œåœ¨ä¿æŒä»¤äººæ»¡æ„çš„è¿è¡Œé€Ÿåº¦çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹ä»–äººæˆæœçš„æ˜¾è‘—æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01331v1">PDF</a> </p>
<p><strong>Summary</strong><br>è¿œç¨‹é¥æ„Ÿå›¾åƒåˆ†å‰²ï¼ˆRRSISï¼‰é¢†åŸŸä¸­çš„ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å°ºåº¦å˜åŒ–å‰§çƒˆçš„é¥æ„Ÿç›®æ ‡æ—¶å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¹¶è¡Œç»Ÿä¸€çš„åˆ†å‰²æ¡†æ¶â€”â€”è·¨è§†å›¾è¯­ä¹‰äº¤äº’ç½‘ç»œï¼ˆCSINetï¼‰ã€‚è¯¥ç½‘ç»œæ¨¡ä»¿äººç±»è§‚å¯Ÿç›®æ ‡çš„è¡Œä¸ºï¼Œåè°ƒè¿œç¨‹å’Œè¿‘è·ç¦»çš„è§†è§‰çº¿ç´¢è¿›è¡ŒååŒé¢„æµ‹ã€‚åœ¨æ¯ä¸ªç¼–ç é˜¶æ®µï¼Œä½¿ç”¨è·¨è§†å›¾çª—å£æ³¨æ„åŠ›æ¨¡å—ï¼ˆCVWinï¼‰å°†å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰ä¿¡æ¯è¡¥å……åˆ°è¿‘è·ç¦»å’Œè¿œè·ç¦»åˆ†æ”¯ç‰¹å¾ä¸­ï¼Œä¿ƒè¿›äº†æ¯ä¸ªç¼–ç é˜¶æ®µç‰¹å¾çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè¿˜å¼€å‘äº†ä¸€ç§ååŒæ‰©å¼ æ³¨æ„åŠ›å¢å¼ºè§£ç å™¨ï¼ˆCDADï¼‰ï¼Œä»¥æŒ–æ˜ç›®æ ‡çš„å®šå‘å±æ€§å¹¶åŒæ—¶æ•´åˆè·¨è§†å›¾çš„å¤šå°ºåº¦ç‰¹å¾ã€‚æ‰€æå‡ºçš„ç½‘ç»œæ— ç¼åœ°æé«˜äº†å…¨å±€å’Œå±€éƒ¨è¯­ä¹‰çš„åˆ©ç”¨ï¼Œåœ¨ä¿æŒä»¤äººæ»¡æ„çš„é€Ÿåº¦çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹å…¶ä»–äººæ˜¾è‘—çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RRSISé¢†åŸŸä¸­ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å°ºåº¦å˜åŒ–å‰§çƒˆçš„é¥æ„Ÿç›®æ ‡æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¹¶è¡Œç»Ÿä¸€çš„åˆ†å‰²æ¡†æ¶CSINetæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>CSINetæ¨¡ä»¿äººç±»è§‚å¯Ÿç›®æ ‡çš„è¡Œä¸ºï¼Œèåˆè¿œç¨‹å’Œè¿‘è·ç¦»çš„è§†è§‰çº¿ç´¢è¿›è¡ŒååŒé¢„æµ‹ã€‚</li>
<li>è·¨è§†å›¾çª—å£æ³¨æ„åŠ›æ¨¡å—ï¼ˆCVWinï¼‰åœ¨æ¯ä¸ªç¼–ç é˜¶æ®µèåˆå…¨å±€å’Œå±€éƒ¨è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§ååŒæ‰©å¼ æ³¨æ„åŠ›å¢å¼ºè§£ç å™¨ï¼ˆCDADï¼‰ä»¥æŒ–æ˜ç›®æ ‡çš„å®šå‘å±æ€§å¹¶æ•´åˆå¤šå°ºåº¦ç‰¹å¾ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01331">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31ddd378e0580946a1c7f0a8ae5a482b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54c2f43bc467354492179196034ec705.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e8866187f47e0807a8496d1ce1241242.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ODOV-Towards-Open-Domain-Open-Vocabulary-Object-Detection"><a href="#ODOV-Towards-Open-Domain-Open-Vocabulary-Object-Detection" class="headerlink" title="ODOV: Towards Open-Domain Open-Vocabulary Object Detection"></a>ODOV: Towards Open-Domain Open-Vocabulary Object Detection</h2><p><strong>Authors:Yupeng Zhang, Ruize Han, Fangnan Zhou, Song Wang, Wei Feng, Liang Wan</strong></p>
<p>In this work, we handle a new problem of Open-Domain Open-Vocabulary (ODOV) object detection, which considers the detection modelâ€™s adaptability to the real world including both domain and category shifts. For this problem, we first construct a new benchmark OD-LVIS, which includes 46,949 images, covers 18 complex real-world domains and 1,203 categories, and provides a comprehensive dataset for evaluating real-world object detection. Besides, we develop a novel baseline method for ODOV detection.The proposed method first leverages large language models to generate the domain-agnostic text prompts for category embedding. It further learns the domain embedding from the given image, which, during testing, can be integrated into the category embedding to form the customized domain-specific category embedding for each test image. We provide sufficient benchmark evaluations for the proposed ODOV detection task and report the results, which verify the rationale of ODOV detection, the usefulness of our benchmark, and the superiority of the proposed method. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†ä¸€ä¸ªå…¨æ–°çš„å¼€æ”¾åŸŸå¼€æ”¾è¯æ±‡è¡¨ï¼ˆODOVï¼‰ç›®æ ‡æ£€æµ‹é—®é¢˜ã€‚è¿™ä¸ªé—®é¢˜è€ƒè™‘äº†æ£€æµ‹æ¨¡å‹å¯¹ç°å®ä¸–ç•Œé€‚åº”æ€§çš„é—®é¢˜ï¼ŒåŒ…æ‹¬é¢†åŸŸå’Œç±»åˆ«è¿ç§»ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•OD-LVISï¼Œå…¶ä¸­åŒ…æ‹¬46949å¼ å›¾åƒï¼Œæ¶µç›–18ä¸ªå¤æ‚çš„ç°å®ä¸–ç•Œé¢†åŸŸå’Œ1203ä¸ªç±»åˆ«ï¼Œä¸ºè¯„ä¼°ç°å®ä¸–ç•Œç›®æ ‡æ£€æµ‹æä¾›äº†ç»¼åˆæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä¸ºODOVæ£€æµ‹å¼€å‘äº†ä¸€ç§æ–°çš„åŸºçº¿æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸é¢†åŸŸæ— å…³çš„æ–‡å­—æç¤ºæ¥è¿›è¡Œç±»åˆ«åµŒå…¥ã€‚å®ƒè¿›ä¸€æ­¥ä»ç»™å®šçš„å›¾åƒä¸­å­¦ä¹ é¢†åŸŸåµŒå…¥ï¼Œåœ¨æµ‹è¯•æœŸé—´ï¼Œå¯ä»¥å°†å…¶é›†æˆåˆ°ç±»åˆ«åµŒå…¥ä¸­ï¼Œä»¥å½¢æˆé’ˆå¯¹æ¯ä¸ªæµ‹è¯•å›¾åƒçš„è‡ªå®šä¹‰é¢†åŸŸç‰¹å®šç±»åˆ«åµŒå…¥ã€‚æˆ‘ä»¬å¯¹æå‡ºçš„ODOVæ£€æµ‹ä»»åŠ¡è¿›è¡Œäº†å……åˆ†çš„åŸºå‡†è¯„ä¼°å¹¶æŠ¥å‘Šäº†ç»“æœï¼ŒéªŒè¯äº†ODOVæ£€æµ‹çš„åŸç†ã€æˆ‘ä»¬åŸºå‡†æµ‹è¯•çš„å®ç”¨æ€§å’Œæ‰€æå‡ºæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01253v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç« æ¢è®¨äº†å¼€æ”¾åŸŸå¼€æ”¾è¯æ±‡ï¼ˆODOVï¼‰ç‰©ä½“æ£€æµ‹çš„æ–°é—®é¢˜ï¼Œå…³æ³¨æ£€æµ‹æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­çš„é€‚åº”æ€§ï¼ŒåŒ…æ‹¬é¢†åŸŸå’Œç±»åˆ«è¿ç§»ã€‚ä¸ºæ­¤ï¼Œæ„å»ºäº†æ–°çš„åŸºå‡†æ•°æ®é›†OD-LVISï¼ŒåŒ…å«46,949å¼ å›¾åƒã€æ¶µç›–18ä¸ªå¤æ‚ç°å®ä¸–ç•Œé¢†åŸŸå’Œ1,203ä¸ªç±»åˆ«ï¼Œä¸ºè¯„ä¼°ç°å®ä¸–ç•Œç‰©ä½“æ£€æµ‹æä¾›äº†ç»¼åˆæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œå¼€å‘äº†ä¸€ç§é’ˆå¯¹ODOVæ£€æµ‹çš„åŸºçº¿æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸é¢†åŸŸæ— å…³çš„æ–‡å­—æç¤ºæ¥è¿›è¡Œç±»åˆ«åµŒå…¥ï¼Œå¹¶ä»ç»™å®šå›¾åƒä¸­å­¦ä¹ é¢†åŸŸåµŒå…¥ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œå¯ä»¥å°†é¢†åŸŸåµŒå…¥é›†æˆåˆ°ç±»åˆ«åµŒå…¥ä¸­ï¼Œå½¢æˆé’ˆå¯¹æ¯ä¸ªæµ‹è¯•å›¾åƒçš„è‡ªå®šä¹‰é¢†åŸŸç‰¹å®šç±»åˆ«åµŒå…¥ã€‚æ–‡ç« æä¾›äº†å¯¹æå‡ºçš„ODOVæ£€æµ‹ä»»åŠ¡çš„å……è¶³åŸºå‡†è¯„ä¼°ï¼Œå¹¶æŠ¥å‘Šäº†ç»“æœï¼ŒéªŒè¯äº†ODOVæ£€æµ‹çš„åŸç†ã€åŸºå‡†æ•°æ®é›†çš„æœ‰ç”¨æ€§ä»¥åŠæ‰€æå‡ºæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« è§£å†³äº†å¼€æ”¾åŸŸå¼€æ”¾è¯æ±‡ï¼ˆODOVï¼‰ç‰©ä½“æ£€æµ‹çš„æ–°é—®é¢˜ï¼Œå…³æ³¨æ¨¡å‹åœ¨ç°å®ä¸–ç•Œçš„é€‚åº”æ€§ã€‚</li>
<li>æ„å»ºäº†æ–°çš„åŸºå‡†æ•°æ®é›†OD-LVISï¼ŒåŒ…å«å¤šç§é¢†åŸŸçš„å›¾åƒå’Œä¸°å¯Œçš„ç±»åˆ«ï¼Œä¸ºè¯„ä¼°ç°å®ä¸–ç•Œç‰©ä½“æ£€æµ‹æä¾›äº†ç»¼åˆæ•°æ®é›†ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é’ˆå¯¹ODOVæ£€æµ‹çš„åŸºçº¿æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡å­—æç¤ºè¿›è¡Œç±»åˆ«åµŒå…¥ã€‚</li>
<li>æ–¹æ³•é€šè¿‡ç»“åˆé¢†åŸŸåµŒå…¥å’Œç±»åˆ«åµŒå…¥ï¼Œå½¢æˆé’ˆå¯¹æ¯ä¸ªæµ‹è¯•å›¾åƒçš„è‡ªå®šä¹‰é¢†åŸŸç‰¹å®šç±»åˆ«åµŒå…¥ã€‚</li>
<li>æ–‡ç« è¿›è¡Œäº†å……åˆ†çš„å®éªŒè¯„ä¼°ï¼ŒéªŒè¯äº†ODOVæ£€æµ‹ä»»åŠ¡çš„é‡è¦æ€§ã€åŸºå‡†æ•°æ®é›†çš„æœ‰ç”¨æ€§ä»¥åŠæ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºå¤„ç†ç°å®ä¸–ç•Œä¸­å¤æ‚é¢†åŸŸçš„ç‰©ä½“æ£€æµ‹é—®é¢˜å…·æœ‰æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01253">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f2987aa6026c28caa7c668789434b826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cac428d7fec5530177de3ced2567252f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-35088e73a5b0138b81cf3b6cc9c2588b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de9f0a60722392bc732dbfd2edacaeec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0287a626534b7741ae7f8e334b9e5ed.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Taming-SAM-for-Underwater-Instance-Segmentation-and-Beyond"><a href="#Taming-SAM-for-Underwater-Instance-Segmentation-and-Beyond" class="headerlink" title="Taming SAM for Underwater Instance Segmentation and Beyond"></a>Taming SAM for Underwater Instance Segmentation and Beyond</h2><p><strong>Authors:Hua Li, Shijie Lian, Zhiyuan Li, Runmin Cong, Chongyi Li</strong></p>
<p>With recent breakthroughs in large-scale modeling, the Segment Anything Model (SAM) has demonstrated significant potential in a variety of visual applications. However, due to the lack of underwater domain expertise, SAM and its variants face performance limitations in end-to-end underwater instance segmentation tasks, while their higher computational requirements further hinder their application in underwater scenarios. To address this challenge, we propose a large-scale underwater instance segmentation dataset, UIIS10K, which includes 10,048 images with pixel-level annotations for 10 categories. Then, we introduce UWSAM, an efficient model designed for automatic and accurate segmentation of underwater instances. UWSAM efficiently distills knowledge from the SAM ViT-Huge image encoder into the smaller ViT-Small image encoder via the Mask GAT-based Underwater Knowledge Distillation (MG-UKD) method for effective visual representation learning. Furthermore, we design an End-to-end Underwater Prompt Generator (EUPG) for UWSAM, which automatically generates underwater prompts instead of explicitly providing foreground points or boxes as prompts, thus enabling the network to locate underwater instances accurately for efficient segmentation. Comprehensive experimental results show that our model is effective, achieving significant performance improvements over state-of-the-art methods on multiple underwater instance datasets. Datasets and codes are available at <a target="_blank" rel="noopener" href="https://github.com/LiamLian0727/UIIS10K">https://github.com/LiamLian0727/UIIS10K</a>. </p>
<blockquote>
<p>éšç€å¤§è§„æ¨¡å»ºæ¨¡çš„æœ€æ–°çªç ´ï¼ŒSegment Anything Modelï¼ˆSAMï¼‰åœ¨å„ç§è§†è§‰åº”ç”¨ä¸­è¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ°´ä¸‹é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼ŒSAMåŠå…¶å˜ä½“åœ¨ç«¯åˆ°ç«¯çš„æ°´ä¸‹å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸­é¢ä¸´æ€§èƒ½å±€é™ï¼Œè€Œå®ƒä»¬è¾ƒé«˜çš„è®¡ç®—è¦æ±‚è¿›ä¸€æ­¥é˜»ç¢äº†åœ¨æ°´ä¸‹åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤§è§„æ¨¡æ°´ä¸‹å®ä¾‹åˆ†å‰²æ•°æ®é›†UIIS10Kï¼Œå…¶ä¸­åŒ…æ‹¬10,048å¼ å…·æœ‰åƒç´ çº§æ³¨é‡Šçš„10ç±»å›¾åƒã€‚æ¥ç€ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸“ä¸ºè‡ªåŠ¨å’Œç²¾ç¡®æ°´ä¸‹å®ä¾‹åˆ†å‰²è€Œè®¾è®¡çš„é«˜æ•ˆæ¨¡å‹UWSAMã€‚UWSAMé€šè¿‡åŸºäºMask GATçš„æ°´ä¸‹çŸ¥è¯†è’¸é¦ï¼ˆMG-UKDï¼‰æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä»SAMçš„ViT-Hugeå›¾åƒç¼–ç å™¨æç‚¼çŸ¥è¯†ï¼Œå¹¶åº”ç”¨åˆ°è¾ƒå°çš„ViT-Smallå›¾åƒç¼–ç å™¨ä¸Šï¼Œä»¥å®ç°æœ‰æ•ˆçš„è§†è§‰è¡¨ç¤ºå­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸ºUWSAMè®¾è®¡äº†ç«¯åˆ°ç«¯çš„æ°´ä¸‹æç¤ºç”Ÿæˆå™¨ï¼ˆEUPGï¼‰ï¼Œå®ƒä¼šè‡ªåŠ¨ç”Ÿæˆæ°´ä¸‹æç¤ºï¼Œè€Œä¸æ˜¯æ˜¾å¼æä¾›å‰æ™¯ç‚¹æˆ–æ¡†ä½œä¸ºæç¤ºï¼Œä»è€Œä½¿ç½‘ç»œèƒ½å¤Ÿå‡†ç¡®å®šä½æ°´ä¸‹å®ä¾‹ï¼Œå®ç°é«˜æ•ˆåˆ†å‰²ã€‚ç»¼åˆå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ï¼Œåœ¨å¤šä¸ªæ°´ä¸‹å®ä¾‹æ•°æ®é›†ä¸Šå®ç°äº†å¯¹æœ€å…ˆè¿›æ–¹æ³•çš„é‡è¦æ€§èƒ½æ”¹è¿›ã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/LiamLian0">https://github.com/LiamLian0</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15581v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>éšç€å¤§è§„æ¨¡å»ºæ¨¡æŠ€æœ¯çš„çªç ´ï¼ŒSegment Anything Modelï¼ˆSAMï¼‰åœ¨å¤šç§è§†è§‰åº”ç”¨ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ°´ä¸‹é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼ŒSAMåŠå…¶å˜ä½“åœ¨ç«¯åˆ°ç«¯çš„æ°´ä¸‹å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸­çš„æ€§èƒ½å—åˆ°é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†å¤§è§„æ¨¡æ°´ä¸‹å®ä¾‹åˆ†å‰²æ•°æ®é›†UIIS10Kï¼ŒåŒ…å«10,048å¼ å¸¦æœ‰åƒç´ çº§æ³¨é‡Šçš„10ç±»å›¾åƒã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†é¢å‘æ°´ä¸‹å®ä¾‹è‡ªåŠ¨å‡†ç¡®åˆ†å‰²çš„UWSAMæ¨¡å‹ã€‚å®ƒé€šè¿‡Mask GATåŸºç¡€æ°´ä¸‹çŸ¥è¯†è’¸é¦ï¼ˆMG-UKDï¼‰æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä»SAMçš„ViT-Hugeå›¾åƒç¼–ç å™¨ä¸­æç‚¼çŸ¥è¯†ï¼Œç”¨äºå°å‹ViT-Smallå›¾åƒç¼–ç å™¨çš„æœ‰æ•ˆè§†è§‰è¡¨ç¤ºå­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸ºUWSAMè®¾è®¡äº†ç«¯åˆ°ç«¯æ°´ä¸‹æç¤ºç”Ÿæˆå™¨ï¼ˆEUPGï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆæ°´ä¸‹æç¤ºï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿå‡†ç¡®å®šä½æ°´ä¸‹å®ä¾‹ï¼Œå®ç°é«˜æ•ˆåˆ†å‰²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤šä¸ªæ°´ä¸‹å®ä¾‹æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Segment Anything Modelï¼ˆSAMï¼‰åœ¨è§†è§‰åº”ç”¨ä¸­æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†åœ¨æ°´ä¸‹å®ä¾‹åˆ†å‰²æ–¹é¢å­˜åœ¨æ€§èƒ½é™åˆ¶ã€‚</li>
<li>ç¼ºä¹æ°´ä¸‹é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†æ˜¯SAMåŠå…¶å˜ä½“åœ¨æ°´ä¸‹åº”ç”¨ä¸­çš„ä¸€å¤§æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†å¤§è§„æ¨¡æ°´ä¸‹å®ä¾‹åˆ†å‰²æ•°æ®é›†UIIS10Kï¼ŒåŒ…å«10,048å¼ å¸¦æœ‰åƒç´ çº§æ³¨é‡Šçš„å›¾åƒã€‚</li>
<li>å¼•å…¥äº†é¢å‘æ°´ä¸‹å®ä¾‹åˆ†å‰²çš„UWSAMæ¨¡å‹ï¼Œå…·æœ‰é«˜æ•ˆçš„çŸ¥è¯†æç‚¼å’Œè§†è§‰è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ã€‚</li>
<li>UWSAMé€šè¿‡Mask GATåŸºç¡€æ°´ä¸‹çŸ¥è¯†è’¸é¦ï¼ˆMG-UKDï¼‰æ–¹æ³•æå‡æ€§èƒ½ã€‚</li>
<li>ä»‹ç»äº†ç«¯åˆ°ç«¯æ°´ä¸‹æç¤ºç”Ÿæˆå™¨ï¼ˆEUPGï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆæ°´ä¸‹æç¤ºï¼Œæé«˜ç½‘ç»œå®šä½æ°´ä¸‹å®ä¾‹çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6ecb05a47af4b85db1bb146fb2f8a00a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cefa54b5cff8ecd0b6e01a97f424d5df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-523ebe3b707ca0a28da3138c83e7ba28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01897eabea2660f7b94d2515def72534.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a8503ef79ba6f37bebdd25898b8e026.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-06/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-06/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-06/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8560fdbacc0a01f8ec2b9d23c9246927.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  DiffusionFF Face Forgery Detection via Diffusion-based Artifact   Localization
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-06/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-fb4281b718235c06a29087ee9685816d.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  Glioblastoma Overall Survival Prediction With Vision Transformers
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
