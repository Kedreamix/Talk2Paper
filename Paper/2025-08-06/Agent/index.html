<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  Hierarchical Learning-Based Control for Multi-Agent Shepherding of   Stochastic Autonomous Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9667208415f3a6b2b2fd2f0880e5b1ab.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    66 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-06-æ›´æ–°"><a href="#2025-08-06-æ›´æ–°" class="headerlink" title="2025-08-06 æ›´æ–°"></a>2025-08-06 æ›´æ–°</h1><h2 id="Hierarchical-Learning-Based-Control-for-Multi-Agent-Shepherding-of-Stochastic-Autonomous-Agents"><a href="#Hierarchical-Learning-Based-Control-for-Multi-Agent-Shepherding-of-Stochastic-Autonomous-Agents" class="headerlink" title="Hierarchical Learning-Based Control for Multi-Agent Shepherding of   Stochastic Autonomous Agents"></a>Hierarchical Learning-Based Control for Multi-Agent Shepherding of   Stochastic Autonomous Agents</h2><p><strong>Authors:Italo Napolitano, Stefano Covone, Andrea Lama, Francesco De Lellis, Mario di Bernardo</strong></p>
<p>Multi-agent shepherding represents a challenging distributed control problem where herder agents must coordinate to guide independently moving targets to desired spatial configurations. Most existing control strategies assume cohesive target behavior, which frequently fails in practical applications where targets exhibit stochastic autonomous behavior. This paper presents a hierarchical learning-based control architecture that decomposes the shepherding problem into a high-level decision-making module and a low-level motion control component. The proposed distributed control system synthesizes effective control policies directly from closed-loop experience without requiring explicit inter-agent communication or prior knowledge of target dynamics. The decentralized architecture achieves cooperative control behavior through emergent coordination without centralized supervision. Experimental validation demonstrates superior closed-loop performance compared to state-of-the-art heuristic control methods, achieving 100% success rates with improved settling times and control efficiency. The control architecture scales beyond its design conditions, adapts to time-varying goal regions, and demonstrates practical implementation feasibility through real-time experiments on the Robotarium platform. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“æ”¾ç‰§ä»£è¡¨äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åˆ†å¸ƒå¼æ§åˆ¶é—®é¢˜ï¼Œå…¶ä¸­ç‰§ç¾Šäººæ™ºèƒ½ä½“å¿…é¡»åè°ƒè¡ŒåŠ¨ï¼Œä»¥å¼•å¯¼ç‹¬ç«‹ç§»åŠ¨çš„ç›®æ ‡è¾¾åˆ°æœŸæœ›çš„ç©ºé—´é…ç½®ã€‚å¤§å¤šæ•°ç°æœ‰çš„æ§åˆ¶ç­–ç•¥éƒ½å‡è®¾ç›®æ ‡è¡Œä¸ºæ˜¯åè°ƒä¸€è‡´çš„ï¼Œè¿™åœ¨ç›®æ ‡è¡¨ç°å‡ºéšæœºè‡ªä¸»è¡Œä¸ºçš„åº”ç”¨åœºæ™¯ä¸­å¾€å¾€ä¼šå¤±è´¥ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå±‚æ¬¡å­¦ä¹ çš„æ§åˆ¶æ¶æ„ï¼Œå®ƒå°†æ”¾ç‰§é—®é¢˜åˆ†è§£ä¸ºé«˜å±‚å†³ç­–æ¨¡å—å’Œåº•å±‚è¿åŠ¨æ§åˆ¶ç»„ä»¶ã€‚æ‰€æå‡ºçš„åˆ†å¸ƒå¼æ§åˆ¶ç³»ç»Ÿç›´æ¥ä»é—­ç¯ç»éªŒä¸­ç»¼åˆæœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥ï¼Œæ— éœ€æ˜ç¡®çš„æ™ºèƒ½ä½“é—´é€šä¿¡æˆ–å¯¹ç›®æ ‡åŠ¨åŠ›å­¦çš„å…ˆéªŒçŸ¥è¯†ã€‚å»ä¸­å¿ƒåŒ–çš„æ¶æ„é€šè¿‡æ¶Œç°åè°ƒå®ç°äº†æ— é›†ä¸­ç›‘ç®¡çš„åˆä½œæ§åˆ¶è¡Œä¸ºã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„å¯å‘å¼æ§åˆ¶æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¶æ„å…·æœ‰ä¼˜è¶Šçš„é—­ç¯æ€§èƒ½ï¼Œå®ç°äº†100%çš„æˆåŠŸç‡ï¼Œç¼©çŸ­äº†ç¨³å®šæ—¶é—´å’Œæé«˜äº†æ§åˆ¶æ•ˆç‡ã€‚è¯¥æ§åˆ¶æ¶æ„åœ¨è®¾è®¡æ¡ä»¶ä¹‹å¤–è¿›è¡Œäº†æ‰©å±•ï¼Œé€‚åº”äº†æ—¶å˜ç›®æ ‡åŒºåŸŸï¼Œå¹¶é€šè¿‡Robotariumå¹³å°ä¸Šçš„å®æ—¶å®éªŒè¯æ˜äº†å…¶å®æ–½çš„å¯è¡Œæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02632v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºåˆ†å±‚å­¦ä¹ æ§åˆ¶æ¶æ„çš„å¤šæ™ºèƒ½ä½“ç‰§ç¾Šé—®é¢˜è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¶æ„åˆ†ä¸ºé«˜å±‚å†³ç­–æ¨¡å—å’Œä½å±‚è¿åŠ¨æ§åˆ¶ç»„ä»¶ï¼Œå¯ä»é—­ç¯ç»éªŒä¸­ç›´æ¥åˆæˆæœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥ï¼Œæ— éœ€æ˜ç¡®çš„æ™ºèƒ½ä½“é—´é€šä¿¡æˆ–å¯¹ç›®æ ‡åŠ¨åŠ›å­¦çš„å…ˆéªŒçŸ¥è¯†ã€‚è¯¥åˆ†æ•£å¼æ¶æ„é€šè¿‡çªå‘åè°ƒå®ç°æ§åˆ¶è¡Œä¸ºï¼Œæ— éœ€ä¸­å¤®ç›‘ç£ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„å¯å‘å¼æ§åˆ¶æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¶æ„å…·æœ‰ä¼˜å¼‚çš„é—­ç¯æ€§èƒ½ï¼Œå®ç°äº†æ›´é«˜çš„æˆåŠŸç‡ã€æ›´å¿«çš„ç»“ç®—æ—¶é—´å’Œæ›´é«˜çš„æ§åˆ¶æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ§åˆ¶æ¶æ„èƒ½å¤Ÿé€‚åº”æ—¶é—´å˜åŒ–çš„ç›®æ ‡åŒºåŸŸï¼Œåœ¨Robotariumå¹³å°ä¸Šè¿›è¡Œå®æ—¶å®éªŒï¼Œè¯æ˜äº†å…¶å®æ–½çš„å¯è¡Œæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç‰§ç¾Šé—®é¢˜æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æ§åˆ¶æŒ‘æˆ˜ï¼Œéœ€è¦æ™ºèƒ½ä½“åè°ƒå¼•å¯¼ç‹¬ç«‹ç§»åŠ¨çš„ç›®æ ‡è¾¾åˆ°æœŸæœ›çš„ç©ºé—´é…ç½®ã€‚</li>
<li>ç°æœ‰æ§åˆ¶ç­–ç•¥å¤§å¤šå‡è®¾ç›®æ ‡è¡Œä¸ºå…·æœ‰å‡èšåŠ›ï¼Œä½†åœ¨ç›®æ ‡è¡¨ç°å‡ºéšæœºè‡ªä¸»è¡Œä¸ºæ—¶ï¼Œè¿™äº›ç­–ç•¥å¸¸å¸¸ä¼šå¤±æ•ˆã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚å­¦ä¹ æ§åˆ¶æ¶æ„çš„è§£å†³æ–¹æ¡ˆï¼Œè¯¥æ¶æ„åˆ†ä¸ºé«˜å±‚å†³ç­–å’Œä½å±‚è¿åŠ¨æ§åˆ¶ã€‚</li>
<li>è¯¥æ¶æ„èƒ½ä»é—­ç¯ç»éªŒä¸­åˆæˆæœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥ï¼Œæ— éœ€æ™ºèƒ½ä½“é—´çš„æ˜ç¡®é€šä¿¡æˆ–å¯¹ç›®æ ‡åŠ¨åŠ›å­¦çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>åˆ†æ•£å¼æ¶æ„é€šè¿‡çªå‘åè°ƒå®ç°æ§åˆ¶è¡Œä¸ºï¼Œæ— éœ€ä¸­å¤®ç›‘ç£ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯å…¶æ€§èƒ½ä¼˜äºå¯å‘å¼æ§åˆ¶æ–¹æ³•ã€‚</li>
<li>æ§åˆ¶æ¶æ„å…·æœ‰è‰¯å¥½çš„é€‚åº”æ€§ï¼Œèƒ½å¤Ÿåº”å¯¹æ—¶é—´å˜åŒ–çš„ç›®æ ‡åŒºåŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02632">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e1bdc47b251e171961f4dd435421e70f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e23b7d44c0a91d73c4912a121ab67963.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f9afd92a4e0839470a2b3b870b2ea6e2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7cc1721c64e082b5f39d3a6730a631d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94ae7f573bfeeff5d3545dd72d07b48b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a9e20c8acdc6d09eb969fa5a0100a2a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="HyCodePolicy-Hybrid-Language-Controllers-for-Multimodal-Monitoring-and-Decision-in-Embodied-Agents"><a href="#HyCodePolicy-Hybrid-Language-Controllers-for-Multimodal-Monitoring-and-Decision-in-Embodied-Agents" class="headerlink" title="HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and   Decision in Embodied Agents"></a>HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and   Decision in Embodied Agents</h2><p><strong>Authors:Yibin Liu, Zhixuan Liang, Zanxin Chen, Tianxing Chen, Mengkang Hu, Wanxi Dong, Congsheng Xu, Zhaoming Han, Yusen Qin, Yao Mu</strong></p>
<p>Recent advances in multimodal large language models (MLLMs) have enabled richer perceptual grounding for code policy generation in embodied agents. However, most existing systems lack effective mechanisms to adaptively monitor policy execution and repair codes during task completion. In this work, we introduce HyCodePolicy, a hybrid language-based control framework that systematically integrates code synthesis, geometric grounding, perceptual monitoring, and iterative repair into a closed-loop programming cycle for embodied agents. Technically, given a natural language instruction, our system first decomposes it into subgoals and generates an initial executable program grounded in object-centric geometric primitives. The program is then executed in simulation, while a vision-language model (VLM) observes selected checkpoints to detect and localize execution failures and infer failure reasons. By fusing structured execution traces capturing program-level events with VLM-based perceptual feedback, HyCodePolicy infers failure causes and repairs programs. This hybrid dual feedback mechanism enables self-correcting program synthesis with minimal human supervision. Our results demonstrate that HyCodePolicy significantly improves the robustness and sample efficiency of robot manipulation policies, offering a scalable strategy for integrating multimodal reasoning into autonomous decision-making pipelines. </p>
<blockquote>
<p>æœ€è¿‘çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„è¿›æ­¥ä¸ºå®ä½“ä»£ç†ä¸­çš„ä»£ç ç­–ç•¥ç”Ÿæˆæä¾›äº†æ›´ä¸°å¯Œçš„æ„ŸçŸ¥åŸºç¡€ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿç¼ºä¹æœ‰æ•ˆçš„æœºåˆ¶æ¥åœ¨ä»»åŠ¡å®Œæˆè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°ç›‘è§†ç­–ç•¥æ‰§è¡Œå’Œä¿®å¤ä»£ç ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†HyCodePolicyï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ··åˆè¯­è¨€çš„æ§åˆ¶æ¡†æ¶ï¼Œå®ƒç³»ç»Ÿåœ°é›†æˆäº†ä»£ç åˆæˆã€å‡ ä½•åŸºç¡€ã€æ„ŸçŸ¥ç›‘æ§å’Œè¿­ä»£ä¿®å¤ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ç¼–ç¨‹å‘¨æœŸï¼Œç”¨äºå®ä½“ä»£ç†ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œç»™å®šè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿé¦–å…ˆå°†å…¶åˆ†è§£ä¸ºå­ç›®æ ‡å¹¶ç”ŸæˆåŸºäºå¯¹è±¡ä¸ºä¸­å¿ƒçš„å‡ ä½•åŸå§‹æ•°æ®çš„åˆå§‹å¯æ‰§è¡Œç¨‹åºã€‚ç„¶åï¼Œè¯¥ç¨‹åºåœ¨ä»¿çœŸä¸­æ‰§è¡Œï¼ŒåŒæ—¶è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è§‚å¯Ÿé€‰å®šçš„æ£€æŸ¥ç‚¹ä»¥æ£€æµ‹å’Œå®šä½æ‰§è¡Œæ•…éšœå¹¶æ¨æ–­æ•…éšœåŸå› ã€‚é€šè¿‡å°†æ•è·ç¨‹åºçº§äº‹ä»¶çš„ç»“æ„åŒ–æ‰§è¡Œè½¨è¿¹ä¸åŸºäºVLMçš„æ„ŸçŸ¥åé¦ˆç›¸ç»“åˆï¼ŒHyCodePolicyå¯ä»¥æ¨æ–­å‡ºå¤±è´¥åŸå› å¹¶ä¿®å¤ç¨‹åºã€‚è¿™ç§æ··åˆåŒé‡åé¦ˆæœºåˆ¶å®ç°äº†è‡ªæˆ‘ä¿®æ­£çš„ç¨‹åºåˆæˆï¼Œåªéœ€æœ€å°‘çš„äººå·¥ç›‘ç£ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒHyCodePolicyæ˜¾è‘—æé«˜äº†æœºå™¨äººæ“ä½œç­–ç•¥çš„ç¨³å¥æ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œä¸ºå°†å¤šæ¨¡æ€æ¨ç†é›†æˆåˆ°è‡ªä¸»å†³ç­–ç®¡é“ä¸­æä¾›äº†å¯ä¼¸ç¼©çš„ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02629v1">PDF</a> Accepted to ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic   Intelligence</p>
<p><strong>Summary</strong></p>
<p>éšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿‘æœŸå‘å±•ï¼Œä¸ºå®ä½“ä»£ç†ä¸­çš„ä»£ç ç­–ç•¥ç”Ÿæˆæä¾›äº†æ›´ä¸°å¯Œçš„æ„ŸçŸ¥åŸºç¡€ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿç¼ºä¹åœ¨ä»»åŠ¡å®Œæˆè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°ç›‘æ§ç­–ç•¥æ‰§è¡Œå’Œä¿®å¤ä»£ç çš„æœ‰æ•ˆæœºåˆ¶ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†HyCodePolicyï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè¯­è¨€çš„æ§åˆ¶æ¡†æ¶ï¼Œç³»ç»Ÿåœ°é›†æˆäº†ä»£ç åˆæˆã€å‡ ä½•åŸºç¡€ã€æ„ŸçŸ¥ç›‘æ§å’Œè¿­ä»£ä¿®å¤ï¼Œä¸ºå®ä½“ä»£ç†æä¾›äº†ä¸€ä¸ªé—­ç¯ç¼–ç¨‹å‘¨æœŸã€‚ç»™å®šè‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿé¦–å…ˆå°†å…¶åˆ†è§£ä¸ºå­ç›®æ ‡å¹¶ç”ŸæˆåŸºäºå¯¹è±¡ä¸ºä¸­å¿ƒçš„å‡ ä½•åŸå§‹æ•°æ®çš„åˆå§‹å¯æ‰§è¡Œç¨‹åºã€‚è¯¥ç¨‹åºåœ¨æ¨¡æ‹Ÿä¸­æ‰§è¡Œï¼ŒåŒæ—¶è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¼šè§‚å¯Ÿé€‰å®šæ£€æŸ¥ç‚¹ä»¥æ£€æµ‹å’Œå®šä½æ‰§è¡Œæ•…éšœå¹¶æ¨æ–­æ•…éšœåŸå› ã€‚é€šè¿‡èåˆæ•æ‰ç¨‹åºçº§äº‹ä»¶çš„ç»“æ„åŒ–æ‰§è¡Œè½¨è¿¹ä¸åŸºäºVLMçš„æ„ŸçŸ¥åé¦ˆï¼ŒHyCodePolicyèƒ½å¤Ÿæ¨æ–­æ•…éšœåŸå› å¹¶ä¿®å¤ç¨‹åºã€‚è¿™ç§æ··åˆåŒé‡åé¦ˆæœºåˆ¶å®ç°äº†è‡ªæˆ‘ä¿®æ­£çš„ç¨‹åºåˆæˆï¼Œå‡ ä¹æ— éœ€äººå·¥ç›‘ç£ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒHyCodePolicyæ˜¾è‘—æé«˜äº†æœºå™¨äººæ“ä½œç­–ç•¥çš„ç¨³å¥æ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œä¸ºè‡ªä¸»å†³ç­–ç®¡é“ä¸­å¤šæ¨¡å¼æ¨ç†çš„é›†æˆæä¾›äº†å¯æ‰©å±•çš„ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸ºå®ä½“ä»£ç†ä¸­çš„ä»£ç ç­–ç•¥ç”Ÿæˆæä¾›äº†ä¸°å¯Œçš„æ„ŸçŸ¥åŸºç¡€ã€‚</li>
<li>å½“å‰ç³»ç»Ÿç¼ºä¹åœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­è‡ªé€‚åº”ç›‘æ§å’Œè°ƒæ•´ä»£ç çš„èƒ½åŠ›ã€‚</li>
<li>HyCodePolicyæ˜¯ä¸€ä¸ªåŸºäºè¯­è¨€çš„æ§åˆ¶æ¡†æ¶ï¼Œé›†æˆäº†ä»£ç åˆæˆã€å‡ ä½•åŸºç¡€ã€æ„ŸçŸ¥ç›‘æ§å’Œè¿­ä»£ä¿®å¤ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡åˆ†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆåˆå§‹å¯æ‰§è¡Œç¨‹åºï¼Œè¯¥ç¨‹åºåŸºäºå¯¹è±¡ä¸­å¿ƒçš„å‡ ä½•åŸå§‹æ•°æ®ã€‚</li>
<li>ç¨‹åºåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œï¼ŒæœŸé—´ç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è§‚å¯Ÿå¹¶æ£€æµ‹æ‰§è¡Œæ•…éšœã€‚</li>
<li>é€šè¿‡ç»“åˆç»“æ„åŒ–æ‰§è¡Œè½¨è¿¹å’ŒåŸºäºVLMçš„æ„ŸçŸ¥åé¦ˆï¼ŒHyCodePolicyèƒ½æ¨æ–­æ•…éšœåŸå› å¹¶è¿›è¡Œç¨‹åºä¿®å¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02629">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f1b1063d79cac75e2b5970f38e7c1b8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e00bea4a7fb9f8f4ccfb2822d131f8ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-071ec1194a132ef9a07dfbf35bf0f5f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b03b45c362657aa8047b34093867ff8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45c0ca75878461436ff4182c63ab2bee.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HealthFlow-A-Self-Evolving-AI-Agent-with-Meta-Planning-for-Autonomous-Healthcare-Research"><a href="#HealthFlow-A-Self-Evolving-AI-Agent-with-Meta-Planning-for-Autonomous-Healthcare-Research" class="headerlink" title="HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous   Healthcare Research"></a>HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous   Healthcare Research</h2><p><strong>Authors:Yinghao Zhu, Yifan Qi, Zixiang Wang, Lei Gu, Dehao Sui, Haoran Hu, Xichen Zhang, Ziyi He, Liantao Ma, Lequan Yu</strong></p>
<p>The efficacy of AI agents in healthcare research is hindered by their reliance on static, predefined strategies. This creates a critical limitation: agents can become better tool-users but cannot learn to become better strategic planners, a crucial skill for complex domains like healthcare. We introduce HealthFlow, a self-evolving AI agent that overcomes this limitation through a novel meta-level evolution mechanism. HealthFlow autonomously refines its own high-level problem-solving policies by distilling procedural successes and failures into a durable, strategic knowledge base. To anchor our research and facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark featuring complex, realistic health data analysis tasks derived from peer-reviewed clinical research. Our comprehensive experiments demonstrate that HealthFlowâ€™s self-evolving approach significantly outperforms state-of-the-art agent frameworks. This work marks a necessary shift from building better tool-users to designing smarter, self-evolving task-managers, paving the way for more autonomous and effective AI for scientific discovery. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ä»£ç†åœ¨åŒ»ç–—é¢†åŸŸç ”ç©¶çš„æ•ˆç”¨å—åˆ°å…¶ä¾èµ–é™æ€ã€é¢„è®¾ç­–ç•¥çš„é˜»ç¢ã€‚è¿™äº§ç”Ÿäº†ä¸€ä¸ªå…³é”®çš„å±€é™æ€§ï¼šä»£ç†å¯ä»¥å˜å¾—æ›´å¥½çš„å·¥å…·ä½¿ç”¨è€…ï¼Œä½†ä¸èƒ½å­¦ä¼šæˆä¸ºæ›´å¥½çš„ç­–ç•¥è§„åˆ’è€…ï¼Œè¿™å¯¹äºåŒ»ç–—ç­‰å¤æ‚é¢†åŸŸæ˜¯ä¸€é¡¹è‡³å…³é‡è¦çš„æŠ€èƒ½ã€‚æˆ‘ä»¬å¼•å…¥äº†HealthFlowï¼Œè¿™æ˜¯ä¸€ç§è‡ªæˆ‘è¿›åŒ–çš„AIä»£ç†ï¼Œå®ƒé€šè¿‡ä¸€ç§æ–°çš„å…ƒçº§è¿›åŒ–æœºåˆ¶å…‹æœäº†è¿™ä¸€å±€é™æ€§ã€‚HealthFlowè‡ªä¸»åœ°æç‚¼å…¶è‡ªå·±çš„é«˜çº§é—®é¢˜è§£å†³ç­–ç•¥ï¼Œå°†ç¨‹åºçš„æˆåŠŸå’Œå¤±è´¥è½¬åŒ–ä¸ºæŒä¹…ã€æˆ˜ç•¥æ€§çš„çŸ¥è¯†åº“ã€‚ä¸ºäº†å·©å›ºæˆ‘ä»¬çš„ç ”ç©¶å¹¶ä¿ƒè¿›å¯é‡å¤è¯„ä¼°ï¼Œæˆ‘ä»¬æ¨å‡ºäº†EHRFlowBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œå®ƒåŒ…å«ä»åŒè¡Œè¯„å®¡çš„ä¸´åºŠç ”ç©¶ä¸­å¾—å‡ºçš„å¤æ‚ä¸”çœŸå®å¥åº·æ•°æ®åˆ†æä»»åŠ¡ã€‚æˆ‘ä»¬çš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒHealthFlowçš„è‡ªæˆ‘è¿›åŒ–æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€æ–°çš„ä»£ç†æ¡†æ¶ã€‚è¿™é¡¹å·¥ä½œæ ‡å¿—ç€ä»æ„å»ºæ›´å¥½çš„å·¥å…·ä½¿ç”¨è€…åˆ°è®¾è®¡æ›´æ™ºèƒ½ã€è‡ªæˆ‘è¿›åŒ–çš„ä»»åŠ¡ç®¡ç†å™¨çš„å¿…è¦è½¬å˜ï¼Œä¸ºæ›´è‡ªä¸»ã€æœ‰æ•ˆçš„AIç§‘å­¦å‘ç°é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02621v1">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/yhzhu99/HealthFlow">https://github.com/yhzhu99/HealthFlow</a></p>
<p><strong>Summary</strong></p>
<p>AIä»£ç†åœ¨åŒ»ç–—å¥åº·ç ”ç©¶ä¸­çš„æ•ˆèƒ½å—é™äºå…¶ä¾èµ–é™æ€ã€é¢„è®¾ç­–ç•¥çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æ¨å‡ºHealthFlowï¼Œä¸€ç§è‡ªæˆ‘è¿›åŒ–çš„AIä»£ç†ï¼Œé€šè¿‡æ–°å‹å…ƒçº§è¿›åŒ–æœºåˆ¶çªç ´æ­¤é™åˆ¶ã€‚HealthFlowå¯è‡ªä¸»ä¼˜åŒ–å…¶é«˜çº§é—®é¢˜è§£å†³ç­–ç•¥ï¼Œå°†ç¨‹åºæˆåŠŸä¸å¤±è´¥ç»éªŒæç‚¼æˆæŒä¹…ã€æˆ˜ç•¥æ€§çš„çŸ¥è¯†åº“ã€‚ä¸ºæ”¯æŒç ”ç©¶å¹¶ä¿ƒè¿›å¯é‡å¤è¯„ä¼°ï¼Œæˆ‘ä»¬æ¨å‡ºEHRFlowBenchï¼Œä»¥å¤æ‚ã€ç°å®åŒ–çš„å¥åº·æ•°æ®åˆ†æä»»åŠ¡ä¸ºç‰¹ç‚¹çš„æ–°åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›ä»»åŠ¡æºè‡ªç»è¿‡åŒè¡Œè¯„å®¡çš„ä¸´åºŠç ”ç©¶ã€‚æˆ‘ä»¬çš„ç»¼åˆå®éªŒæ˜¾ç¤ºï¼ŒHealthFlowçš„è‡ªæˆ‘è¿›åŒ–æ–¹æ³•æ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„ä»£ç†æ¡†æ¶ã€‚è¿™é¡¹å·¥ä½œæ ‡å¿—ç€ä»æ„å»ºæ›´å¥½çš„å·¥å…·ç”¨æˆ·è½¬å‘è®¾è®¡æ›´æ™ºèƒ½çš„è‡ªæˆ‘è¿›åŒ–ä»»åŠ¡ç®¡ç†å™¨ï¼Œä¸ºæ›´è‡ªä¸»å’Œæœ‰æ•ˆçš„AIç§‘å­¦å‘ç°é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIä»£ç†åœ¨åŒ»ç–—å¥åº·ç ”ç©¶ä¸­çš„æ•ˆèƒ½å—é™ã€‚</li>
<li>ç°æœ‰AIä»£ç†ä¸»è¦ä½œä¸ºå·¥å…·ç”¨æˆ·ï¼Œç¼ºä¹æˆ˜ç•¥è§„åˆ’èƒ½åŠ›ã€‚</li>
<li>HealthFlowé€šè¿‡è‡ªæˆ‘è¿›åŒ–æœºåˆ¶çªç ´æ­¤é™åˆ¶ï¼Œå¯è‡ªä¸»ä¼˜åŒ–é«˜çº§é—®é¢˜è§£å†³ç­–ç•¥ã€‚</li>
<li>HealthFlowå°†ç»éªŒæç‚¼æˆæŒä¹…ã€æˆ˜ç•¥æ€§çš„çŸ¥è¯†åº“ã€‚</li>
<li>æ¨å‡ºEHRFlowBenchä½œä¸ºæ–°å‹åŸºå‡†æµ‹è¯•ï¼Œä»¥æ”¯æŒç ”ç©¶å’Œä¿ƒè¿›è¯„ä¼°çš„å¯é‡å¤æ€§ã€‚</li>
<li>ç»¼åˆå®éªŒæ˜¾ç¤ºHealthFlowæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„ä»£ç†æ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02621">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6583329b7d83f21eaa2c818413e17718.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50065c8704aab9311ac2e750f13e2bad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-47f1a7ae4a529cb58f8300807f1536e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0899982d81a337c9cae6476ecf5eedd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5285ac4c2f2cec3122944a66f69b276f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60fefc2a8d9f17c4a0dda6a3e7915c90.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Emergence-of-Fair-Leaders-via-Mediators-in-Multi-Agent-Reinforcement-Learning"><a href="#Emergence-of-Fair-Leaders-via-Mediators-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Emergence of Fair Leaders via Mediators in Multi-Agent Reinforcement   Learning"></a>Emergence of Fair Leaders via Mediators in Multi-Agent Reinforcement   Learning</h2><p><strong>Authors:Akshay Dodwadmath, Setareh Maghsudi</strong></p>
<p>Stackelberg games and their resulting equilibria have received increasing attention in the multi-agent reinforcement learning literature. Each stage of a traditional Stackelberg game involves a leader(s) acting first, followed by the followers. In situations where the roles of leader(s) and followers can be interchanged, the designated role can have considerable advantages, for example, in first-mover advantage settings. Then the question arises: Who should be the leader and when? A bias in the leader selection process can lead to unfair outcomes. This problem is aggravated if the agents are self-interested and care only about their goals and rewards. We formally define this leader selection problem and show its relation to fairness in agentsâ€™ returns. Furthermore, we propose a multi-agent reinforcement learning framework that maximizes fairness by integrating mediators. Mediators have previously been used in the simultaneous action setting with varying levels of control, such as directly performing agentsâ€™ actions or just recommending them. Our framework integrates mediators in the Stackelberg setting with minimal control (leader selection). We show that the presence of mediators leads to self-interested agents taking fair actions, resulting in higher overall fairness in agentsâ€™ returns. </p>
<blockquote>
<p>æ–¯å¡”å…‹å°”ä¼¯æ ¼ï¼ˆStackelbergï¼‰åšå¼ˆåŠå…¶äº§ç”Ÿçš„å‡è¡¡çŠ¶æ€åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–‡çŒ®ä¸­å—åˆ°äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ä¼ ç»Ÿçš„æ–¯å¡”å…‹å°”ä¼¯æ ¼åšå¼ˆçš„æ¯ä¸ªé˜¶æ®µéƒ½æ¶‰åŠä¸€ä¸ªæˆ–å¤šä¸ªé¢†å¯¼è€…ç‡å…ˆè¡ŒåŠ¨ï¼Œéšåæ˜¯è¿½éšè€…ã€‚åœ¨é¢†å¯¼è€…å’Œè¿½éšè€…çš„è§’è‰²å¯ä»¥äº’æ¢çš„æƒ…å†µä¸‹ï¼ŒæŒ‡å®šçš„è§’è‰²å¯ä»¥å¸¦æ¥å·¨å¤§çš„ä¼˜åŠ¿ï¼Œä¾‹å¦‚åœ¨å…ˆè¡Œä¼˜åŠ¿ç¯å¢ƒä¸­ã€‚ç„¶åä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼šè°åº”è¯¥æ˜¯é¢†å¯¼è€…ï¼Œåˆåº”è¯¥åœ¨ä½•æ—¶ï¼Ÿé¢†å¯¼è€…é€‰æ‹©è¿‡ç¨‹ä¸­çš„åè§å¯èƒ½å¯¼è‡´ä¸å…¬å¹³çš„ç»“æœã€‚å¦‚æœæ™ºèƒ½ä½“æ˜¯è‡ªç§çš„ï¼Œåªå…³å¿ƒä»–ä»¬çš„ç›®æ ‡å’Œå›æŠ¥ï¼Œé‚£ä¹ˆè¿™ä¸ªé—®é¢˜å°±ä¼šåŠ å‰§ã€‚æˆ‘ä»¬æ­£å¼å®šä¹‰äº†è¿™ä¸ªé—®é¢˜å¹¶å±•ç¤ºäº†å®ƒä¸æ™ºèƒ½ä½“å›æŠ¥å…¬å¹³æ€§çš„å…³ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸­ä»‹æ¥æœ€å¤§åŒ–å…¬å¹³æ€§ã€‚ä¸­ä»‹ä»¥å‰å·²è¢«ç”¨äºå…·æœ‰ä¸åŒæ§åˆ¶çº§åˆ«çš„åŒæ—¶è¡ŒåŠ¨è®¾ç½®ï¼Œä¾‹å¦‚ç›´æ¥æ‰§è¡Œæ™ºèƒ½ä½“çš„è¡ŒåŠ¨æˆ–ä»…ä»…æ˜¯æå‡ºå»ºè®®ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨æ–¯å¡”å…‹å°”ä¼¯æ ¼èƒŒæ™¯ä¸‹æ•´åˆä¸­ä»‹ï¼Œæ§åˆ¶åŠ›åº¦æœ€å°ï¼ˆé¢†å¯¼å±‚é€‰æ‹©ï¼‰ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œä¸­ä»‹çš„å­˜åœ¨å¯¼è‡´è‡ªç§çš„æ™ºèƒ½ä½“é‡‡å–å…¬å¹³çš„è¡ŒåŠ¨ï¼Œä»è€Œæé«˜äº†æ™ºèƒ½ä½“å›æŠ¥çš„æ•´ä½“å…¬å¹³æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02421v1">PDF</a> Accepted to ECAI 2025</p>
<p><strong>Summary</strong><br>åœ¨å¤šé‡ä»£ç†å¼ºåŒ–å­¦ä¹ æ–‡çŒ®ä¸­ï¼Œæ–¯å¡”å…‹å°”ä¼¯æ ¼åšå¼ˆåŠå…¶äº§ç”Ÿçš„å‡è¡¡çŠ¶æ€è¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚ä¼ ç»Ÿçš„æ–¯å¡”å…‹å°”ä¼¯æ ¼åšå¼ˆæ¯ä¸ªé˜¶æ®µéƒ½æœ‰é¢†å¯¼è€…å…ˆè¡Œï¼Œéšåæ˜¯è¿½éšè€…ã€‚åœ¨é¢†å¯¼è€…å’Œè¿½éšè€…è§’è‰²å¯ä»¥äº’æ¢çš„æƒ…å†µä¸‹ï¼ŒæŒ‡å®šè§’è‰²å¯ä»¥å¸¦æ¥å·¨å¤§çš„ä¼˜åŠ¿ï¼Œä¾‹å¦‚åœ¨å…ˆè¡Œä¼˜åŠ¿è®¾ç½®ä¸­ã€‚å› æ­¤äº§ç”Ÿäº†ä¸€ä¸ªé—®é¢˜ï¼šè°åº”è¯¥æˆä¸ºé¢†å¯¼è€…ï¼Œä½•æ—¶æˆä¸ºé¢†å¯¼è€…ï¼Ÿé¢†å¯¼é€‰æ‹©è¿‡ç¨‹ä¸­çš„åè§å¯èƒ½å¯¼è‡´ä¸å…¬å¹³çš„ç»“æœã€‚å¦‚æœä»£ç†äººæ˜¯è‡ªç§çš„ï¼Œåªå…³å¿ƒä»–ä»¬çš„ç›®æ ‡å’Œå›æŠ¥ï¼Œè¿™ä¸ªé—®é¢˜ä¼šæ›´åŠ ä¸¥é‡ã€‚æˆ‘ä»¬æ­£å¼å®šä¹‰äº†è¿™ä¸ªé¢†å¯¼é€‰æ‹©é—®é¢˜ï¼Œå¹¶å±•ç¤ºäº†å®ƒä¸ä»£ç†å›æŠ¥å…¬å¹³æ€§çš„å…³ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥è°ƒè§£è€…æ¥æœ€å¤§åŒ–å…¬å¹³æ€§ã€‚è°ƒè§£è€…ä»¥å‰å·²è¢«ç”¨äºåŒæ—¶è¡ŒåŠ¨çš„ç¯å¢ƒä¸­ï¼Œå…·æœ‰ä¸åŒç¨‹åº¦çš„æ§åˆ¶åŠ›ï¼Œå¦‚ç›´æ¥æ‰§è¡Œä»£ç†çš„è¡ŒåŠ¨æˆ–ä»…æä¾›å»ºè®®ã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†è°ƒè§£è€…çº³å…¥æ–¯å¡”å…‹å°”ä¼¯æ ¼è®¾ç½®ä¸­ï¼Œå…·æœ‰æœ€å°çš„æ§åˆ¶åŠ›ï¼ˆé¢†å¯¼é€‰æ‹©ï¼‰ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè°ƒè§£è€…çš„å­˜åœ¨å¯¼è‡´è‡ªç§çš„ä»£ç†äººé‡‡å–å…¬å¹³è¡ŒåŠ¨ï¼Œä»è€Œæé«˜ä»£ç†å›æŠ¥çš„æ•´ä½“å…¬å¹³æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–¯å¡”å…‹å°”ä¼¯æ ¼åšå¼ˆåœ¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ä¸­å—åˆ°å…³æ³¨ã€‚</li>
<li>é¢†å¯¼è€…å’Œè¿½éšè€…è§’è‰²çš„äº’æ¢åœ¨åšå¼ˆä¸­å…·æœ‰ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å…ˆè¡Œä¼˜åŠ¿åœºæ™¯ä¸­ã€‚</li>
<li>é¢†å¯¼é€‰æ‹©è¿‡ç¨‹ä¸­çš„åè§å¯èƒ½å¯¼è‡´ä¸å…¬å¹³ç»“æœã€‚</li>
<li>ä»£ç†çš„è‡ªç§æ€§ä¼šåŠ å‰§è¿™ä¸€é—®é¢˜ã€‚</li>
<li>æå‡ºäº†é¢†å¯¼é€‰æ‹©é—®é¢˜çš„æ­£å¼å®šä¹‰ï¼Œå¹¶ä¸ä»£ç†å›æŠ¥çš„å…¬å¹³æ€§ç›¸è”ç³»ã€‚</li>
<li>å¼•å…¥è°ƒè§£è€…çš„å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ¡†æ¶å¯ä»¥æœ€å¤§åŒ–å…¬å¹³æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02421">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-628bc9a17eb86cf3afa8405888a44afb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6574dc55891d02c02e2eb8d917003421.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db5dfeb1a47e3a51c9b5f05f5d47cb1b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c3b8b34f5ff29d94777f24bb7c22528e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a31227162febfed18b1f178796d7036.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CellForge-Agentic-Design-of-Virtual-Cell-Models"><a href="#CellForge-Agentic-Design-of-Virtual-Cell-Models" class="headerlink" title="CellForge: Agentic Design of Virtual Cell Models"></a>CellForge: Agentic Design of Virtual Cell Models</h2><p><strong>Authors:Xiangru Tang, Zhuoyun Yu, Jiapeng Chen, Yan Cui, Daniel Shao, Weixu Wang, Fang Wu, Yuchen Zhuang, Wenqi Shi, Zhi Huang, Arman Cohan, Xihong Lin, Fabian Theis, Smita Krishnaswamy, Mark Gerstein</strong></p>
<p>Virtual cell modeling represents an emerging frontier at the intersection of artificial intelligence and biology, aiming to predict quantities such as responses to diverse perturbations quantitatively. However, autonomously building computational models for virtual cells is challenging due to the complexity of biological systems, the heterogeneity of data modalities, and the need for domain-specific expertise across multiple disciplines. Here, we introduce CellForge, an agentic system that leverages a multi-agent framework that transforms presented biological datasets and research objectives directly into optimized computational models for virtual cells. More specifically, given only raw single-cell multi-omics data and task descriptions as input, CellForge outputs both an optimized model architecture and executable code for training virtual cell models and inference. The framework integrates three core modules: Task Analysis for presented dataset characterization and relevant literature retrieval, Method Design, where specialized agents collaboratively develop optimized modeling strategies, and Experiment Execution for automated generation of code. The agents in the Design module are separated into experts with differing perspectives and a central moderator, and have to collaboratively exchange solutions until they achieve a reasonable consensus. We demonstrate CellForgeâ€™s capabilities in single-cell perturbation prediction, using six diverse datasets that encompass gene knockouts, drug treatments, and cytokine stimulations across multiple modalities. CellForge consistently outperforms task-specific state-of-the-art methods. Overall, CellForge demonstrates how iterative interaction between LLM agents with differing perspectives provides better solutions than directly addressing a modeling challenge. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/gersteinlab/CellForge">https://github.com/gersteinlab/CellForge</a>. </p>
<blockquote>
<p>è™šæ‹Ÿç»†èƒå»ºæ¨¡æ˜¯äººå·¥æ™ºèƒ½å’Œç”Ÿç‰©å­¦äº¤å‰é¢†åŸŸçš„æ–°å…´å‰æ²¿ï¼Œæ—¨åœ¨å®šé‡é¢„æµ‹å¯¹ä¸åŒæ‰°åŠ¨çš„ååº”ç­‰æ•°é‡ã€‚ç„¶è€Œï¼Œç”±äºç”Ÿç‰©ç³»ç»Ÿçš„å¤æ‚æ€§ã€æ•°æ®æ¨¡æ€çš„å¼‚è´¨æ€§å’Œå¤šå­¦ç§‘é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„éœ€æ±‚ï¼Œè‡ªä¸»æ„å»ºè™šæ‹Ÿç»†èƒè®¡ç®—æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†CellForgeï¼Œä¸€ä¸ªæ™ºèƒ½ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶ç›´æ¥å°†å‘ˆç°çš„ç”Ÿç‰©å­¦æ•°æ®é›†å’Œç ”ç©¶ç›®æ ‡è½¬åŒ–ä¸ºä¼˜åŒ–çš„è®¡ç®—æ¨¡å‹ï¼Œç”¨äºè™šæ‹Ÿç»†èƒã€‚æ›´å…·ä½“åœ°è¯´ï¼ŒCellForgeä»…æ¥å—åŸå§‹çš„å•ç»†èƒå¤šç»„å­¦æ•°æ®å’Œä»»åŠ¡æè¿°ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºçš„æ˜¯ä¼˜åŒ–åçš„æ¨¡å‹æ¶æ„å’Œå¯ç”¨äºè®­ç»ƒè™šæ‹Ÿç»†èƒæ¨¡å‹å’Œè¿›è¡Œæ¨æ–­çš„å¯æ‰§è¡Œä»£ç ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šä»»åŠ¡åˆ†æï¼Œç”¨äºå‘ˆç°æ•°æ®é›†è¡¨å¾å’Œç›¸å…³æ–‡çŒ®æ£€ç´¢ï¼›æ–¹æ³•è®¾è®¡ï¼Œå…¶ä¸­ä¸“ä¸šæ™ºèƒ½ä½“ååŒå¼€å‘ä¼˜åŒ–å»ºæ¨¡ç­–ç•¥ï¼›å®éªŒæ‰§è¡Œï¼Œç”¨äºè‡ªåŠ¨ç”Ÿæˆä»£ç ã€‚è®¾è®¡æ¨¡å—ä¸­çš„æ™ºèƒ½ä½“åˆ†ä¸ºä¸åŒè§’åº¦çš„ä¸“å®¶å’Œä¸€ä¸ªä¸­å¤®åè°ƒè€…ï¼Œä»–ä»¬å¿…é¡»ååŒäº¤æµè§£å†³æ–¹æ¡ˆï¼Œç›´åˆ°è¾¾æˆåˆç†å…±è¯†ã€‚æˆ‘ä»¬åˆ©ç”¨æ¶µç›–åŸºå› æ•²é™¤ã€è¯ç‰©æ²»ç–—å’Œç»†èƒå› å­åˆºæ¿€çš„å…­ä¸ªä¸åŒæ•°æ®é›†ï¼Œå±•ç¤ºäº†CellForgeåœ¨å•ç»†èƒæ‰°åŠ¨é¢„æµ‹æ–¹é¢çš„èƒ½åŠ›ã€‚CellForgeçš„æ€§èƒ½å§‹ç»ˆä¼˜äºç‰¹å®šä»»åŠ¡çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æ€»çš„æ¥è¯´ï¼ŒCellForgeå±•ç¤ºäº†ä¸åŒè§’åº¦çš„LLMæ™ºèƒ½ä½“ä¹‹é—´çš„è¿­ä»£äº¤äº’å¦‚ä½•æä¾›æ¯”ç›´æ¥è§£å†³å»ºæ¨¡æŒ‘æˆ˜æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/gersteinlab/CellForge%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/gersteinlab/CellForgeå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02276v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è™šæ‹Ÿç»†èƒå»ºæ¨¡æ˜¯äººå·¥æ™ºèƒ½ä¸ç”Ÿç‰©å­¦äº¤å‰é¢†åŸŸçš„æ–°å…´å‰æ²¿ï¼Œæ—¨åœ¨å®šé‡é¢„æµ‹å¯¹å¤šç§æ‰°åŠ¨çš„å“åº”ã€‚ç„¶è€Œï¼Œè‡ªä¸»æ„å»ºè™šæ‹Ÿç»†èƒçš„è®¡ç®—æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç”Ÿç‰©ç³»ç»Ÿçš„å¤æ‚æ€§ã€æ•°æ®æ¨¡æ€çš„å¼‚è´¨æ€§å’Œå¤šå­¦ç§‘é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„éœ€æ±‚ã€‚è¿™é‡Œä»‹ç»CellForgeï¼Œä¸€ä¸ªåˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¡†æ¶çš„agenticç³»ç»Ÿï¼Œå¯ç›´æ¥å°†å‘ˆç°çš„ç”Ÿç‰©å­¦æ•°æ®é›†å’Œç ”ç©¶ç›®æ ‡è½¬åŒ–ä¸ºä¼˜åŒ–çš„è®¡ç®—æ¨¡å‹ã€‚CellForgeæ¥å—åŸå§‹å•ç»†èƒå¤šç»„å­¦æ•°æ®å’Œä»»åŠ¡æè¿°ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¼˜åŒ–åçš„æ¨¡å‹æ¶æ„å’Œå¯æ‰§è¡Œä»£ç ï¼Œç”¨äºè®­ç»ƒå’Œæ¨æ–­è™šæ‹Ÿç»†èƒæ¨¡å‹ã€‚é€šè¿‡ä»»åŠ¡åˆ†æã€æ–¹æ³•è®¾è®¡å’Œå®éªŒæ‰§è¡Œä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œå®ç°äº†è‡ªåŠ¨åŒ–ç”Ÿæˆä»£ç ã€‚åœ¨å•ç»†èƒæ‰°åŠ¨é¢„æµ‹ä¸­ï¼ŒCellForgeä½¿ç”¨å…­ä¸ªåŒ…å«åŸºå› æ•²é™¤ã€è¯ç‰©æ²»ç–—å’Œç»†èƒå› å­åˆºæ¿€çš„å¤šæ¨¡æ€æ•°æ®é›†è¿›è¡Œæ¼”ç¤ºï¼Œå¹¶å§‹ç»ˆä¼˜äºç‰¹å®šä»»åŠ¡çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æ€»ä½“è€Œè¨€ï¼ŒCellForgeå±•ç¤ºäº†åœ¨ä¸åŒè§†è§’çš„å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ä¹‹é—´çš„è¿­ä»£äº¤äº’å¦‚ä½•æä¾›æ¯”ç›´æ¥è§£å†³å»ºæ¨¡æŒ‘æˆ˜æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è™šæ‹Ÿç»†èƒå»ºæ¨¡æ˜¯äººå·¥æ™ºèƒ½ä¸ç”Ÿç‰©å­¦ç»“åˆçš„æ–°å…´é¢†åŸŸï¼Œæ—¨åœ¨é¢„æµ‹ç”Ÿç‰©ç³»ç»Ÿå¯¹æ‰°åŠ¨çš„å“åº”ã€‚</li>
<li>CellForgeæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œèƒ½å°†ç”Ÿç‰©æ•°æ®é›†å’Œç ”ç©¶ç›®æ ‡è½¬åŒ–ä¸ºè™šæ‹Ÿç»†èƒæ¨¡å‹ã€‚</li>
<li>CellForgeæ¥å—åŸå§‹å•ç»†èƒå¤šç»„å­¦æ•°æ®å’Œä»»åŠ¡æè¿°ä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¼˜åŒ–åçš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒä»£ç ã€‚</li>
<li>CellForgeåŒ…æ‹¬ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šä»»åŠ¡åˆ†æã€æ–¹æ³•è®¾è®¡å’Œå®éªŒæ‰§è¡Œã€‚</li>
<li>åœ¨å•ç»†èƒæ‰°åŠ¨é¢„æµ‹ä¸­ï¼ŒCellForgeè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>CellForgeé€šè¿‡æ™ºèƒ½ä½“é—´çš„è¿­ä»£äº¤äº’ï¼Œå®ç°äº†æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>CellForgeçš„ä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02276">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cdf8a8a3e0512e40aa4e7b561da76174.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9b8d9c9aec41c575dde3b7e66cf1d18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19a7a03f2c36b1258440486dcd43b77c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8400162dd794e1f4c8c1437d1f3e4a2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9667208415f3a6b2b2fd2f0880e5b1ab.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Patho-AgenticRAG-Towards-Multimodal-Agentic-Retrieval-Augmented-Generation-for-Pathology-VLMs-via-Reinforcement-Learning"><a href="#Patho-AgenticRAG-Towards-Multimodal-Agentic-Retrieval-Augmented-Generation-for-Pathology-VLMs-via-Reinforcement-Learning" class="headerlink" title="Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented   Generation for Pathology VLMs via Reinforcement Learning"></a>Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented   Generation for Pathology VLMs via Reinforcement Learning</h2><p><strong>Authors:Wenchuan Zhang, Jingru Guo, Hengzhe Zhang, Penghao Zhang, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi, Hong Bu</strong></p>
<p>Although Vision Language Models (VLMs) have shown strong generalization in medical imaging, pathology presents unique challenges due to ultra-high resolution, complex tissue structures, and nuanced clinical semantics. These factors make pathology VLMs prone to hallucinations, i.e., generating outputs inconsistent with visual evidence, which undermines clinical trust. Existing RAG approaches in this domain largely depend on text-based knowledge bases, limiting their ability to leverage diagnostic visual cues. To address this, we propose Patho-AgenticRAG, a multimodal RAG framework with a database built on page-level embeddings from authoritative pathology textbooks. Unlike traditional text-only retrieval systems, it supports joint text-image search, enabling direct retrieval of textbook pages that contain both the queried text and relevant visual cues, thus avoiding the loss of critical image-based information. Patho-AgenticRAG also supports reasoning, task decomposition, and multi-turn search interactions, improving accuracy in complex diagnostic scenarios. Experiments show that Patho-AgenticRAG significantly outperforms existing multimodal models in complex pathology tasks like multiple-choice diagnosis and visual question answering. Our project is available at the Patho-AgenticRAG repository: <a target="_blank" rel="noopener" href="https://github.com/Wenchuan-Zhang/Patho-AgenticRAG">https://github.com/Wenchuan-Zhang/Patho-AgenticRAG</a>. </p>
<blockquote>
<p>å°½ç®¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨åŒ»å­¦æˆåƒä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†ç”±äºè¶…é«˜åˆ†è¾¨ç‡ã€å¤æ‚çš„ç»„ç»‡ç»“æ„å’Œå¾®å¦™çš„ä¸´åºŠè¯­ä¹‰ï¼Œç—…ç†å­¦è¿˜æ˜¯é¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚è¿™äº›å› ç´ ä½¿å¾—ç—…ç†å­¦VLMså®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆä¸è§†è§‰è¯æ®ä¸ä¸€è‡´çš„è¾“å‡ºï¼Œè¿™æŸå®³äº†ä¸´åºŠä¿¡ä»»ã€‚ç›®å‰è¯¥é¢†åŸŸçš„RAGæ–¹æ³•å¤§å¤šä¾èµ–äºåŸºäºæ–‡æœ¬çš„çŸ¥è¯†åº“ï¼Œé™åˆ¶äº†å®ƒä»¬åˆ©ç”¨è¯Šæ–­è§†è§‰çº¿ç´¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Patho-AgenticRAGï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€RAGæ¡†æ¶ï¼Œå…¶æ•°æ®åº“å»ºç«‹åœ¨æƒå¨ç—…ç†å­¦æ•™ç§‘ä¹¦é¡µé¢çº§åˆ«çš„åµŒå…¥ä¹‹ä¸Šã€‚ä¸ä¼ ç»Ÿçš„ä»…æ–‡æœ¬æ£€ç´¢ç³»ç»Ÿä¸åŒï¼Œå®ƒæ”¯æŒè”åˆæ–‡æœ¬å›¾åƒæœç´¢ï¼Œèƒ½å¤Ÿç›´æ¥æ£€ç´¢åŒ…å«æŸ¥è¯¢æ–‡æœ¬å’Œç›¸å…³è§†è§‰çº¿ç´¢çš„æ•™ç§‘ä¹¦é¡µé¢ï¼Œä»è€Œé¿å…äº†åŸºäºå…³é”®å›¾åƒä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ã€‚Patho-AgenticRAGè¿˜æ”¯æŒæ¨ç†ã€ä»»åŠ¡åˆ†è§£å’Œå¤šè½®æœç´¢äº¤äº’ï¼Œæé«˜äº†å¤æ‚è¯Šæ–­åœºæ™¯ä¸­çš„å‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒPatho-AgenticRAGåœ¨å¤šé¡¹é€‰æ‹©é¢˜è¯Šæ–­å’Œè§†è§‰é—®ç­”ç­‰å¤æ‚ç—…ç†å­¦ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¤šæ¨¡æ€æ¨¡å‹ã€‚æˆ‘ä»¬çš„é¡¹ç›®å¯åœ¨Patho-AgenticRAGä»“åº“ä¸­æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/Wenchuan-Zhang/Patho-AgenticRAG%E3%80%82">https://github.com/Wenchuan-Zhang/Patho-AgenticRAGã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02258v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç—…ç†è§†è¯­è¨€æ¨¡å‹é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è¶…é«˜åˆ†è¾¨ç‡ã€å¤æ‚ç»„ç»‡ç»“æ„å’Œç»†å¾®ä¸´åºŠè¯­ä¹‰ã€‚Patho-AgenticRAGæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€RAGæ¡†æ¶ï¼Œæ”¯æŒè”åˆæ–‡æœ¬å›¾åƒæœç´¢ï¼Œé¿å…ä¸¢å¤±å…³é”®å›¾åƒä¿¡æ¯ï¼Œæé«˜å¤æ‚è¯Šæ–­åœºæ™¯çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç—…ç†è§†è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨åŒ»å­¦æˆåƒä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨ç—…ç†å­¦é¢†åŸŸé¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ã€‚</li>
<li>ç—…ç†å­¦çš„é«˜åˆ†è¾¨ç‡ã€å¤æ‚ç»„ç»‡ç»“æ„å’Œç»†å¾®ä¸´åºŠè¯­ä¹‰ä½¿æ¨¡å‹æ˜“äº§ç”Ÿå¹»è§‰è¾“å‡ºã€‚</li>
<li>ç°æœ‰RAGæ–¹æ³•ä¸»è¦ä¾èµ–æ–‡æœ¬çŸ¥è¯†åº“ï¼Œéš¾ä»¥åˆ©ç”¨è¯Šæ–­è§†è§‰çº¿ç´¢ã€‚</li>
<li>Patho-AgenticRAGæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€RAGæ¡†æ¶ï¼Œæ”¯æŒè”åˆæ–‡æœ¬å›¾åƒæœç´¢ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±ã€‚</li>
<li>Patho-AgenticRAGèƒ½è¿›è¡Œæ¨ç†ã€ä»»åŠ¡åˆ†è§£å’Œå¤šè½®æœç´¢äº¤äº’ï¼Œæé«˜å¤æ‚è¯Šæ–­åœºæ™¯çš„å‡†ç¡®æ€§ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒPatho-AgenticRAGåœ¨å¤æ‚ç—…ç†å­¦ä»»åŠ¡ï¼ˆå¦‚å¤šé€‰è¯Šæ–­å’Œè§†è§‰é—®ç­”ï¼‰ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¤šæ¨¡æ€æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-383714874adb8c283a72898d8cf40c20.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0b7d3a6bc7da7e065fed1cada15982e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9eb62662ced5d199cf4632bae1ece74a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-014b4ea2844b0d4895915050978ca620.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d38304ea1fed64524c9f9465a9e2a1e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f8b8677788ced309e6357cc3f2a8729.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SE-Agent-Self-Evolution-Trajectory-Optimization-in-Multi-Step-Reasoning-with-LLM-Based-Agents"><a href="#SE-Agent-Self-Evolution-Trajectory-Optimization-in-Multi-Step-Reasoning-with-LLM-Based-Agents" class="headerlink" title="SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning   with LLM-Based Agents"></a>SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning   with LLM-Based Agents</h2><p><strong>Authors:Jiaye Lin, Yifu Guo, Yuzhen Han, Sen Hu, Ziyi Ni, Licheng Wang, Mingguang Chen, Daxin Jiang, Binxing Jiao, Chen Hu, Huacan Wang</strong></p>
<p>Large Language Model (LLM)-based agents have recently shown impressive capabilities in complex reasoning and tool use via multi-step interactions with their environments. While these agents have the potential to tackle complicated tasks, their problem-solving process, i.e., agentsâ€™ interaction trajectory leading to task completion, remains underexploited. These trajectories contain rich feedback that can navigate agents toward the right directions for solving problems correctly. Although prevailing approaches, such as Monte Carlo Tree Search (MCTS), can effectively balance exploration and exploitation, they ignore the interdependence among various trajectories and lack the diversity of search spaces, which leads to redundant reasoning and suboptimal outcomes. To address these challenges, we propose SE-Agent, a Self-Evolution framework that enables Agents to optimize their reasoning processes iteratively. Our approach revisits and enhances former pilot trajectories through three key operations: revision, recombination, and refinement. This evolutionary mechanism enables two critical advantages: (1) it expands the search space beyond local optima by intelligently exploring diverse solution paths guided by previous trajectories, and (2) it leverages cross-trajectory inspiration to efficiently enhance performance while mitigating the impact of suboptimal reasoning paths. Through these mechanisms, SE-Agent achieves continuous self-evolution that incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench Verified to resolve real-world GitHub issues. Experimental results across five strong LLMs show that integrating SE-Agent delivers up to 55% relative improvement, achieving state-of-the-art performance among all open-source agents on SWE-bench Verified. Our code and demonstration materials are publicly available at <a target="_blank" rel="noopener" href="https://github.com/wanghuacan/SE-Agent">https://github.com/wanghuacan/SE-Agent</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æœ€è¿‘è¡¨ç°å‡ºé€šè¿‡å¤šæ­¥éª¤ä¸ç¯å¢ƒäº’åŠ¨è¿›è¡Œå¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨çš„æƒŠäººèƒ½åŠ›ã€‚è™½ç„¶è¿™äº›ä»£ç†æœ‰æ½œåŠ›å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œä½†ä»–ä»¬çš„è§£å†³é—®é¢˜è¿‡ç¨‹ï¼Œå³ä»£ç†å®Œæˆä»»åŠ¡çš„äº’åŠ¨è½¨è¿¹ï¼Œä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚è¿™äº›è½¨è¿¹åŒ…å«ä¸°å¯Œçš„åé¦ˆï¼Œå¯ä»¥å¼•å¯¼ä»£ç†æœç€æ­£ç¡®æ–¹å‘è§£å†³é—®é¢˜ã€‚è™½ç„¶ç°æœ‰çš„æ–¹æ³•ï¼Œå¦‚è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†ä¸åŒè½¨è¿¹ä¹‹é—´çš„ç›¸äº’ä¾èµ–æ€§ï¼Œå¹¶ä¸”ç¼ºä¹æœç´¢ç©ºé—´çš„å¤šæ ·æ€§ï¼Œè¿™å¯¼è‡´å†—ä½™æ¨ç†å’Œæ¬¡ä¼˜ç»“æœã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SE-Agentï¼Œè¿™æ˜¯ä¸€ç§è‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–ä»–ä»¬çš„æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¸‰ä¸ªå…³é”®æ“ä½œæ¥é‡æ–°å®¡è§†å’Œæ”¹è¿›å…ˆå‰çš„è½¨è¿¹ï¼šä¿®è®¢ã€é‡ç»„å’Œç»†åŒ–ã€‚è¿™ç§è¿›åŒ–æœºåˆ¶å¸¦æ¥äº†ä¸¤ä¸ªå…³é”®ä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰å®ƒé€šè¿‡æ™ºèƒ½åœ°æ¢ç´¢ä»¥å‰è½¨è¿¹å¼•å¯¼çš„å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè·¯å¾„ï¼Œæ‰©å¤§äº†æœç´¢ç©ºé—´ï¼Œè¶…è¶Šäº†å±€éƒ¨æœ€ä¼˜ï¼›ï¼ˆ2ï¼‰å®ƒåˆ©ç”¨è·¨è½¨è¿¹çš„çµæ„Ÿæ¥æœ‰æ•ˆåœ°æé«˜æ€§èƒ½ï¼ŒåŒæ—¶å‡è½»æ¬¡ä¼˜æ¨ç†è·¯å¾„çš„å½±å“ã€‚é€šè¿‡è¿™äº›æœºåˆ¶ï¼ŒSE-Agentå®ç°äº†æŒç»­çš„è‡ªæˆ‘è¿›åŒ–ï¼Œé€æ­¥æé«˜äº†æ¨ç†è´¨é‡ã€‚æˆ‘ä»¬åœ¨SWE-bench Verifiedä¸Šè¯„ä¼°äº†SE-Agentï¼Œä»¥è§£å†³ç°å®ä¸–ç•Œä¸­çš„GitHubé—®é¢˜ã€‚åœ¨äº”ä¸ªå¼ºå¤§çš„LLMä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆSE-Agentå¸¦æ¥äº†é«˜è¾¾55%çš„ç›¸å¯¹æ”¹è¿›ï¼Œåœ¨SWE-bench Verifiedä¸Šçš„æ€§èƒ½è¾¾åˆ°äº†å¼€æºä»£ç†ä¸­çš„æœ€ä½³æ°´å¹³ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¼”ç¤ºææ–™å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/wanghuacan/SE-Agent%E5%85%AC%E5%BC%80%E9%83%BD%E5%8F%96%E3%80%82">https://github.com/wanghuacan/SE-Agentå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02085v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨æ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œé€šè¿‡å¤šæ­¥éª¤ä¸ç¯å¢ƒçš„äº¤äº’æ¥å®Œæˆä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›ä»£ç†çš„é—®é¢˜è§£å†³è¿‡ç¨‹ï¼Œå³ä»£ç†å®Œæˆä»»åŠ¡çš„äº¤äº’è½¨è¿¹ï¼Œå°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚è¿™äº›è½¨è¿¹åŒ…å«ä¸°å¯Œçš„åé¦ˆï¼Œå¯ä»¥å¼•å¯¼ä»£ç†æ­£ç¡®è§£å†³é—®é¢˜ã€‚è™½ç„¶ç°æœ‰çš„æ–¹æ³•å¦‚è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å¯ä»¥æœ‰æ•ˆåœ°å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†ä¸åŒè½¨è¿¹ä¹‹é—´çš„ä¾èµ–æ€§å¹¶ç¼ºä¹æœç´¢ç©ºé—´çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´å†—ä½™æ¨ç†å’Œæ¬¡ä¼˜ç»“æœã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SE-Agentï¼Œä¸€ä¸ªè‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–å…¶æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡ä¿®è®¢ã€é‡ç»„å’Œç»†åŒ–ç­‰å…³é”®æ“ä½œï¼Œè¯¥æœºåˆ¶æ‰©å¤§äº†æœç´¢ç©ºé—´å¹¶æé«˜äº†æ€§èƒ½ã€‚åœ¨SWE-bench Verifiedä¸Šè¯„ä¼°SE-Agentè§£å†³GitHubå®é™…é—®é¢˜çš„èƒ½åŠ›æ—¶ï¼Œç›¸è¾ƒäºäº”ä¸ªä¸»æµLLMï¼Œå…¶å®ç°äº†é«˜è¾¾55%çš„ç›¸å¯¹æ”¹è¿›ç‡å¹¶è¾¾åˆ°å…ˆè¿›æ€§èƒ½æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based agents demonstrate impressive capabilities in complex reasoning and tool use via multi-step interactions with environments.</li>
<li>Agentsâ€™ problem-solving trajectories contain rich feedback that can guide them to solve problems correctly.</li>
<li>Existing methods like MCTS ignore the interdependence among trajectories and lack search space diversity, leading to redundant reasoning and suboptimal outcomes.</li>
<li>SE-Agent framework enables iterative optimization of reasoning processes for agents through three key operations: revision, recombination, and refinement.</li>
<li>SE-Agent expands search space beyond local optima and leverages cross-trajectory inspiration to enhance performance.</li>
<li>SE-Agent achieves continuous self-evolution, incrementally improving reasoning quality.</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02085">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0b7f2fbb98b7e8c38dc87889e0d9ce0c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4bea939b287932cfc986fed5e11ab9cc.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Agent-Based-Feature-Generation-from-Clinical-Notes-for-Outcome-Prediction"><a href="#Agent-Based-Feature-Generation-from-Clinical-Notes-for-Outcome-Prediction" class="headerlink" title="Agent-Based Feature Generation from Clinical Notes for Outcome   Prediction"></a>Agent-Based Feature Generation from Clinical Notes for Outcome   Prediction</h2><p><strong>Authors:Jiayi Wang, Jacqueline Jil Vallon, Neil Panjwani, Xi Ling, Sushmita Vij, Sandy Srinivas, John Leppert, Mark K. Buyyounouski, Mohsen Bayati</strong></p>
<p>Electronic health records (EHRs) contain rich unstructured clinical notes that could enhance predictive modeling, yet extracting meaningful features from these notes remains challenging. Current approaches range from labor-intensive manual clinician feature generation (CFG) to fully automated representational feature generation (RFG) that lack interpretability and clinical relevance. Here we introduce SNOW (Scalable Note-to-Outcome Workflow), a modular multi-agent system powered by large language models (LLMs) that autonomously generates structured clinical features from unstructured notes without human intervention. We evaluated SNOW against manual CFG, clinician-guided LLM approaches, and RFG methods for predicting 5-year prostate cancer recurrence in 147 patients from Stanford Healthcare. While manual CFG achieved the highest performance (AUC-ROC: 0.771), SNOW matched this performance (0.761) without requiring any clinical expertise, significantly outperforming both baseline features alone (0.691) and all RFG approaches. The clinician-guided LLM method also performed well (0.732) but still required expert input. SNOWâ€™s specialized agents handle feature discovery, extraction, validation, post-processing, and aggregation, creating interpretable features that capture complex clinical information typically accessible only through manual review. Our findings demonstrate that autonomous LLM systems can replicate expert-level feature engineering at scale, potentially transforming how clinical ML models leverage unstructured EHR data while maintaining the interpretability essential for clinical deployment. </p>
<blockquote>
<p>ç”µå­å¥åº·è®°å½•ï¼ˆEHRsï¼‰åŒ…å«ä¸°å¯Œçš„éç»“æ„åŒ–ä¸´åºŠç¬”è®°ï¼Œè¿™äº›ç¬”è®°å¯ä»¥å¢å¼ºé¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œç„¶è€Œä»è¿™äº›ç¬”è®°ä¸­æå–æœ‰æ„ä¹‰çš„ç‰¹å¾ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•èŒƒå›´ä»åŠ³åŠ¨å¯†é›†å‹çš„æ‰‹åŠ¨ä¸´åºŠåŒ»ç”Ÿç‰¹å¾ç”Ÿæˆï¼ˆCFGï¼‰åˆ°ç¼ºä¹å¯è§£é‡Šæ€§å’Œä¸´åºŠç›¸å…³æ€§çš„å®Œå…¨è‡ªåŠ¨åŒ–çš„ä»£è¡¨æ€§ç‰¹å¾ç”Ÿæˆï¼ˆRFGï¼‰ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†SNOWï¼ˆå¯æ‰©å±•çš„ç¬”è®°åˆ°ç»“æœå·¥ä½œæµç¨‹ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ¨¡å—åŒ–å¤šä»£ç†ç³»ç»Ÿï¼Œèƒ½å¤Ÿæ— éœ€äººå·¥å¹²é¢„ï¼Œä»éç»“æ„åŒ–ç¬”è®°ä¸­è‡ªä¸»ç”Ÿæˆç»“æ„åŒ–ä¸´åºŠç‰¹å¾ã€‚æˆ‘ä»¬åœ¨æ–¯å¦ç¦åŒ»ç–—å¥åº·çš„147åæ‚£è€…ä¸­ï¼Œç”¨SNOWä¸æ‰‹åŠ¨CFGã€ä¸´åºŠåŒ»ç”ŸæŒ‡å¯¼çš„LLMæ–¹æ³•å’ŒRFGæ–¹æ³•é¢„æµ‹å‰åˆ—è…ºç™Œ5å¹´å¤å‘ç‡è¿›è¡Œæ¯”è¾ƒè¯„ä¼°ã€‚è™½ç„¶æ‰‹åŠ¨CFGè¡¨ç°æœ€ä½³ï¼ˆAUC-ROCï¼š0.771ï¼‰ï¼Œä½†SNOWä¸ä¹‹ç›¸åŒ¹é…ï¼ˆ0.761ï¼‰ï¼Œæ— éœ€ä»»ä½•ä¸´åºŠç»éªŒï¼Œæ˜¾è‘—ä¼˜äºåŸºæœ¬ç‰¹å¾ï¼ˆ0.691ï¼‰å’Œæ‰€æœ‰RFGæ–¹æ³•ã€‚ä¸´åºŠåŒ»ç”ŸæŒ‡å¯¼çš„LLMæ–¹æ³•è¡¨ç°è‰¯å¥½ï¼ˆ0.732ï¼‰ï¼Œä½†ä»éœ€ä¸“å®¶è¾“å…¥ã€‚SNOWçš„ä¸“ç”¨ä»£ç†å¤„ç†ç‰¹å¾å‘ç°ã€æå–ã€éªŒè¯ã€åå¤„ç†å’Œèšåˆï¼Œåˆ›å»ºå¯è§£é‡Šçš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾èƒ½å¤Ÿæ•è·é€šå¸¸åªèƒ½é€šè¿‡æ‰‹åŠ¨å®¡æŸ¥æ‰èƒ½è·å¾—çš„å¤æ‚ä¸´åºŠä¿¡æ¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè‡ªä¸»åŒ–çš„LLMç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡ä¸Šå¤åˆ¶ä¸“å®¶çº§çš„ç‰¹å¾å·¥ç¨‹ï¼Œæœ‰å¯èƒ½æ”¹å˜ä¸´åºŠæœºå™¨å­¦ä¹ æ¨¡å‹å¦‚ä½•åˆ©ç”¨éç»“æ„åŒ–EHRæ•°æ®çš„æ–¹å¼ï¼ŒåŒæ—¶ä¿æŒå¯¹äºä¸´åºŠéƒ¨ç½²è‡³å…³é‡è¦çš„å¯è§£é‡Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01956v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åä¸ºSNOWçš„æ¨¡å—åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»éç»“æ„åŒ–ç—…å†è®°å½•ä¸­æå–ç»“æ„åŒ–ä¸´åºŠç‰¹å¾ï¼Œç”¨äºé¢„æµ‹å‰åˆ—è…ºç™Œå¤å‘çš„é£é™©ã€‚åœ¨æ–¯å¦ç¦åŒ»ç–—æœºæ„çš„æµ‹è¯•ä¸­ï¼Œå°½ç®¡æ‰‹åŠ¨CFGè¡¨ç°æœ€ä½³ï¼ˆAUC-ROCï¼š0.771ï¼‰ï¼Œä½†SNOWç³»ç»Ÿæ— éœ€ä¸´åºŠä¸“å®¶å‚ä¸å³å®ç°äº†ä¸ä¹‹ç›¸å½“çš„æ€§èƒ½ï¼ˆAUC-ROCï¼š0.761ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºåŸºæœ¬ç‰¹å¾ï¼ˆAUC-ROCï¼š0.691ï¼‰å’Œå…¨è‡ªåŠ¨RFGæ–¹æ³•ã€‚SNOWç³»ç»Ÿç”±å¤šä¸ªæ™ºèƒ½ä½“ç»„æˆï¼Œè´Ÿè´£ç‰¹å¾å‘ç°ã€æå–ã€éªŒè¯ã€åå¤„ç†å’Œèšåˆï¼Œå¯ç”Ÿæˆæ˜“äºç†è§£çš„ç‰¹å¾ï¼Œæ•æ‰å¤æ‚ä¸´åºŠä¿¡æ¯ï¼Œè¿™é€šå¸¸æ˜¯åªèƒ½é€šè¿‡äººå·¥å®¡æŸ¥æ‰èƒ½è·å–çš„ã€‚è¿™äº›å‘ç°è¯æ˜ï¼Œè‡ªä¸»çš„å¤§å‹è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨å¤§è§„æ¨¡ç‰¹å¾å·¥ç¨‹ä¸Šå¯æ¨¡æ‹Ÿä¸“å®¶çº§çš„è¡¨ç°ï¼Œå¯èƒ½ä¸ºä¸´åºŠéƒ¨ç½²ä¸­çš„æœºå™¨å­¦ä¹ æ¨¡å‹æä¾›æ›´é«˜æ•ˆçš„éç»“æ„åŒ–ç—…å†æ•°æ®åˆ©ç”¨æ–¹å¼å¹¶ä¿æŒå¿…è¦çš„å¯è§£é‡Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SNOWç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»éç»“æ„åŒ–ç—…å†è®°å½•ä¸­æå–ç»“æ„åŒ–ä¸´åºŠç‰¹å¾ã€‚</li>
<li>SNOWç³»ç»Ÿçš„æ€§èƒ½ä¸æ‰‹åŠ¨CFGç›¸å½“ï¼Œä½†æ— éœ€ä¸´åºŠä¸“å®¶å‚ä¸ã€‚</li>
<li>SNOWç³»ç»Ÿé€šè¿‡å¤šä¸ªæ™ºèƒ½ä½“è¿›è¡Œç‰¹å¾å‘ç°ã€æå–ã€éªŒè¯ã€åå¤„ç†å’Œèšåˆã€‚</li>
<li>SNOWç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæ˜“äºç†è§£çš„ç‰¹å¾ï¼Œæ•æ‰å¤æ‚ä¸´åºŠä¿¡æ¯ã€‚</li>
<li>è‡ªä¸»çš„å¤§å‹è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨ç‰¹å¾å·¥ç¨‹ä¸Šå¯æ¨¡æ‹Ÿä¸“å®¶çº§çš„è¡¨ç°ã€‚</li>
<li>SNOWç³»ç»Ÿçš„åº”ç”¨å¯æå‡ä¸´åºŠæœºå™¨å­¦ä¹ æ¨¡å‹å¯¹éç»“æ„åŒ–ç—…å†æ•°æ®çš„åˆ©ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01956">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-804da4e86d3cf863013c2e5eae9ed990.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-395e1a0b1dff23b9c2e6ee51bf9b4fed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-21be5355ff492c9450aeeb1a399a1029.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="StreamAgent-Towards-Anticipatory-Agents-for-Streaming-Video-Understanding"><a href="#StreamAgent-Towards-Anticipatory-Agents-for-Streaming-Video-Understanding" class="headerlink" title="StreamAgent: Towards Anticipatory Agents for Streaming Video   Understanding"></a>StreamAgent: Towards Anticipatory Agents for Streaming Video   Understanding</h2><p><strong>Authors:Haolin Yang, Feilong Tang, Linxiao Zhao, Xiang An, Ming Hu, Huifa Li, Xinlin Zhuang, Boqian Wang, Yifan Lu, Xiaofeng Zhang, Abdalla Swikir, Junjun He, Zongyuan Ge, Imran Razzak</strong></p>
<p>Real-time streaming video understanding in domains such as autonomous driving and intelligent surveillance poses challenges beyond conventional offline video processing, requiring continuous perception, proactive decision making, and responsive interaction based on dynamically evolving visual content. However, existing methods rely on alternating perception-reaction or asynchronous triggers, lacking task-driven planning and future anticipation, which limits their real-time responsiveness and proactive decision making in evolving video streams. To this end, we propose a StreamAgent that anticipates the temporal intervals and spatial regions expected to contain future task-relevant information to enable proactive and goal-driven responses. Specifically, we integrate question semantics and historical observations through prompting the anticipatory agent to anticipate the temporal progression of key events, align current observations with the expected future evidence, and subsequently adjust the perception action (e.g., attending to task-relevant regions or continuously tracking in subsequent frames). To enable efficient inference, we design a streaming KV-cache memory mechanism that constructs a hierarchical memory structure for selective recall of relevant tokens, enabling efficient semantic retrieval while reducing the overhead of storing all tokens in the traditional KV-cache. Extensive experiments on streaming and long video understanding tasks demonstrate that our method outperforms existing methods in response accuracy and real-time efficiency, highlighting its practical value for real-world streaming scenarios. </p>
<blockquote>
<p>åœ¨è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸï¼Œå®æ—¶æµåª’ä½“è§†é¢‘ç†è§£é¢ä¸´ç€è¶…è¶Šä¼ ç»Ÿç¦»çº¿è§†é¢‘å¤„ç†çš„æŒ‘æˆ˜ã€‚è¿™éœ€è¦æˆ‘ä»¬è¿›è¡Œè¿ç»­æ„ŸçŸ¥ã€ä¸»åŠ¨å†³ç­–ï¼Œä»¥åŠåŸºäºåŠ¨æ€æ¼”åŒ–è§†è§‰å†…å®¹çš„å“åº”äº¤äº’ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºäº¤æ›¿æ„ŸçŸ¥ååº”æˆ–å¼‚æ­¥è§¦å‘ï¼Œç¼ºä¹ä»»åŠ¡é©±åŠ¨çš„è§„åˆ’å’Œæœªæ¥é¢„æœŸï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®æ—¶æµåª’ä½“ä¸­çš„å®æ—¶å“åº”èƒ½åŠ›å’Œä¸»åŠ¨å†³ç­–åˆ¶å®šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†StreamAgentï¼Œèƒ½å¤Ÿé¢„æµ‹æœªæ¥åŒ…å«ä»»åŠ¡ç›¸å…³ä¿¡æ¯çš„æ—¶é—´é—´éš”å’Œç©ºé—´åŒºåŸŸï¼Œä»¥å®ç°ä»¥ç›®æ ‡å’Œä¸»åŠ¨çš„ååº”ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡æç¤ºé¢„æµ‹ä»£ç†æ•´åˆé—®é¢˜è¯­ä¹‰å’Œå†å²è§‚å¯Ÿï¼Œä»¥é¢„æµ‹å…³é”®äº‹ä»¶çš„æ—¶é—´è¿›å±•ï¼Œå°†å½“å‰è§‚å¯Ÿä¸é¢„æœŸçš„æœªæ¥è¯æ®å¯¹é½ï¼Œéšåè°ƒæ•´æ„ŸçŸ¥è¡Œä¸ºï¼ˆä¾‹å¦‚ï¼Œå…³æ³¨ä»»åŠ¡ç›¸å…³åŒºåŸŸæˆ–åœ¨åç»­å¸§ä¸­æŒç»­è·Ÿè¸ªï¼‰ã€‚ä¸ºäº†å®ç°é«˜æ•ˆæ¨ç†ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æµå¼KVç¼“å­˜æœºåˆ¶ï¼Œæ„å»ºäº†ä¸€ç§åˆ†å±‚å†…å­˜ç»“æ„ï¼Œç”¨äºé€‰æ‹©æ€§å›å¿†ç›¸å…³ä»¤ç‰Œï¼Œå®ç°åœ¨ä¸å­˜å‚¨æ‰€æœ‰ä»¤ç‰Œçš„ä¼ ç»ŸKVç¼“å­˜çš„åŒæ—¶è¿›è¡Œé«˜æ•ˆè¯­ä¹‰æ£€ç´¢ã€‚åœ¨æµåª’ä½“å’Œé•¿è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å“åº”å‡†ç¡®æ€§å’Œå®æ—¶æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå‡¸æ˜¾äº†å…¶åœ¨çœŸå®ä¸–ç•Œæµåª’ä½“åœºæ™¯ä¸­çš„å®ç”¨ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01875v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å®æ—¶æµåª’ä½“è§†é¢‘ç†è§£åœ¨è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸé¢ä¸´ä¼ ç»Ÿç¦»çº¿è§†é¢‘å¤„ç†æ— æ³•åº”å¯¹çš„æŒ‘æˆ˜ï¼Œéœ€è¦æŒç»­æ„ŸçŸ¥ã€ä¸»åŠ¨å†³ç­–å’ŒåŸºäºåŠ¨æ€æ¼”åŒ–è§†è§‰å†…å®¹çš„å“åº”äº¤äº’ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºäº¤æ›¿æ„ŸçŸ¥ååº”æˆ–å¼‚æ­¥è§¦å‘ï¼Œç¼ºä¹ä»»åŠ¡é©±åŠ¨çš„è§„åˆ’å’Œæœªæ¥é¢„æœŸï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®æ—¶æµåª’ä½“ä¸­çš„å“åº”èƒ½åŠ›å’Œä¸»åŠ¨å†³ç­–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†StreamAgentï¼Œå¯é¢„æµ‹æœªæ¥ä»»åŠ¡ç›¸å…³ä¿¡æ¯çš„é¢„æœŸæ—¶é—´é—´éš”å’Œç©ºé—´åŒºåŸŸï¼Œä»¥å®ç°ç›®æ ‡é©±åŠ¨çš„å“åº”ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡æ•´åˆé—®é¢˜è¯­ä¹‰å’Œå†å²è§‚å¯Ÿï¼Œä¿ƒä½¿é¢„æµ‹ä»£ç†é¢„æµ‹å…³é”®äº‹ä»¶çš„æ—¶é—´è¿›å±•ï¼Œå°†å½“å‰è§‚å¯Ÿä¸é¢„æœŸçš„æœªæ¥è¯æ®å¯¹é½ï¼Œå¹¶æ®æ­¤è°ƒæ•´æ„ŸçŸ¥è¡ŒåŠ¨ï¼ˆä¾‹å¦‚ï¼Œå…³æ³¨ä»»åŠ¡ç›¸å…³åŒºåŸŸæˆ–åœ¨åç»­å¸§ä¸­è¿›è¡ŒæŒç»­è·Ÿè¸ªï¼‰ã€‚ä¸ºæå‡æ¨ç†æ•ˆç‡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æµå¼KVç¼“å­˜æœºåˆ¶ï¼Œæ„å»ºåˆ†å±‚å†…å­˜ç»“æ„ä»¥å®ç°é€‰æ‹©æ€§å¬å›ç›¸å…³ä»¤ç‰Œï¼Œä»è€Œåœ¨å‡å°‘å­˜å‚¨æ‰€æœ‰ä»¤ç‰Œçš„ä¼ ç»ŸKVç¼“å­˜å¼€é”€çš„åŒæ—¶ï¼Œå®ç°é«˜æ•ˆè¯­ä¹‰æ£€ç´¢ã€‚åœ¨æµåª’ä½“å’Œé•¿è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å“åº”å‡†ç¡®æ€§å’Œå®æ—¶æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œçªæ˜¾å…¶åœ¨çœŸå®ä¸–ç•Œæµåª’ä½“åœºæ™¯ä¸­çš„å®ç”¨ä»·å€¼ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å®æ—¶æµåª’ä½“è§†é¢‘ç†è§£é¢ä¸´è¶…è¶Šä¼ ç»Ÿç¦»çº¿è§†é¢‘å¤„ç†çš„æŒ‘æˆ˜ï¼Œéœ€è¦æŒç»­æ„ŸçŸ¥ã€ä¸»åŠ¨å†³ç­–å’Œå“åº”äº¤äº’ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ç¼ºä¹ä»»åŠ¡é©±åŠ¨çš„è§„åˆ’å’Œæœªæ¥é¢„æœŸï¼Œé™åˆ¶äº†å®æ—¶å“åº”èƒ½åŠ›å’Œä¸»åŠ¨å†³ç­–ã€‚</li>
<li>æå‡ºçš„StreamAgentèƒ½å¤Ÿé¢„æµ‹æœªæ¥ä»»åŠ¡ç›¸å…³ä¿¡æ¯çš„é¢„æœŸæ—¶é—´é—´éš”å’Œç©ºé—´åŒºåŸŸã€‚</li>
<li>é€šè¿‡æ•´åˆé—®é¢˜è¯­ä¹‰å’Œå†å²è§‚å¯Ÿï¼ŒStreamAgentå¯ä»¥ä¿ƒä½¿é¢„æµ‹ä»£ç†é¢„æµ‹å…³é”®äº‹ä»¶çš„æ—¶é—´è¿›å±•ã€‚</li>
<li>StreamAgentèƒ½å¤Ÿè°ƒæ•´æ„ŸçŸ¥è¡ŒåŠ¨ï¼Œä¾‹å¦‚å…³æ³¨ä»»åŠ¡ç›¸å…³åŒºåŸŸæˆ–åœ¨åç»­å¸§ä¸­è¿›è¡ŒæŒç»­è·Ÿè¸ªã€‚</li>
<li>è®¾è®¡äº†æµå¼KVç¼“å­˜æœºåˆ¶ï¼Œå®ç°é«˜æ•ˆè¯­ä¹‰æ£€ç´¢å’Œå‡å°‘å­˜å‚¨å¼€é”€ã€‚</li>
<li>åœ¨æµåª’ä½“å’Œé•¿è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒStreamAgentåœ¨å“åº”å‡†ç¡®æ€§å’Œå®æ—¶æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01875">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f0a322e89a14c8913098a83056c4f167.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-da8f345e4cb79d9109a343dcaf1df819.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1d428b2932a8049520c7e9dae36ca77.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-336bd406f4175d31309dc8ecb170e644.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-990e8dddf959acfac63f7f3bf6a5df58.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Web-CogReasoner-Towards-Knowledge-Induced-Cognitive-Reasoning-for-Web-Agents"><a href="#Web-CogReasoner-Towards-Knowledge-Induced-Cognitive-Reasoning-for-Web-Agents" class="headerlink" title="Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web   Agents"></a>Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web   Agents</h2><p><strong>Authors:Yuhan Guo, Cong Guo, Aiwen Sun, Hongliang He, Xinyu Yang, Yue Lu, Yingji Zhang, Xuntao Guo, Dong Zhang, Jianzhuang Liu, Jiang Duan, Yijia Xiao, Liangjian Wen, Hai-Ming Xu, Yong Dai</strong></p>
<p>Multimodal large-scale models have significantly advanced the development of web agents, enabling perception and interaction with digital environments akin to human cognition. In this paper, we argue that web agents must first acquire sufficient knowledge to effectively engage in cognitive reasoning. Therefore, we decompose a web agentâ€™s capabilities into two essential stages: knowledge content learning and cognitive processes. To formalize this, we propose Web-CogKnowledge Framework, categorizing knowledge as Factual, Conceptual, and Procedural. In this framework, knowledge content learning corresponds to the agentâ€™s processes of Memorizing and Understanding, which rely on the first two knowledge types, representing the â€œwhatâ€ of learning. Conversely, cognitive processes correspond to Exploring, grounded in Procedural knowledge, defining the â€œhowâ€ of reasoning and action. To facilitate knowledge acquisition, we construct the Web-CogDataset, a structured resource curated from 14 real-world websites, designed to systematically instill core knowledge necessary for web agent. This dataset serves as the agentâ€™s conceptual grounding-the â€œnounsâ€ upon which comprehension is built-as well as the basis for learning how to reason and act. Building on this foundation, we operationalize these processes through a novel knowledge-driven Chain-of-Thought (CoT) reasoning framework, developing and training our proposed agent, the Web-CogReasoner. Extensive experimentation reveals its significant superiority over existing models, especially in generalizing to unseen tasks where structured knowledge is decisive. To enable rigorous evaluation, we introduce the Web-CogBench, a comprehensive evaluation suite designed to assess and compare agent performance across the delineated knowledge domains and cognitive capabilities. Our code and data is open sourced at <a target="_blank" rel="noopener" href="https://github.com/Gnonymous/Web-CogReasoner">https://github.com/Gnonymous/Web-CogReasoner</a> </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§è§„æ¨¡æ¨¡å‹å·²ç»æ˜¾è‘—æ¨åŠ¨äº†ç½‘ç»œä»£ç†çš„å‘å±•ï¼Œä½¿å…¶èƒ½å¤Ÿæ„ŸçŸ¥å’Œä¸æ•°å­—ç¯å¢ƒè¿›è¡Œç±»ä¼¼äºäººç±»è®¤çŸ¥çš„äº¤äº’ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºç½‘ç»œä»£ç†å¿…é¡»é¦–å…ˆè·å¾—è¶³å¤Ÿçš„çŸ¥è¯†ä»¥æœ‰æ•ˆåœ°å‚ä¸è®¤çŸ¥æ¨ç†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ç½‘ç»œä»£ç†çš„èƒ½åŠ›åˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šçŸ¥è¯†å†…å®¹å­¦ä¹ å’Œè®¤çŸ¥è¿‡ç¨‹ã€‚ä¸ºäº†æ­£å¼æå‡ºè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†Web-CogKnowledgeæ¡†æ¶ï¼Œå°†çŸ¥è¯†åˆ†ç±»ä¸ºäº‹å®ã€æ¦‚å¿µå’Œç¨‹åºä¸‰ç±»ã€‚åœ¨æ­¤æ¡†æ¶ä¸­ï¼ŒçŸ¥è¯†å†…å®¹å­¦ä¹ å¯¹åº”äºä»£ç†çš„è®°å¿†å’Œç†è§£è¿‡ç¨‹ï¼Œè¿™ä¾èµ–äºå‰ä¸¤ç§çŸ¥è¯†ç±»å‹ï¼Œä»£è¡¨å­¦ä¹ çš„â€œå†…å®¹æ˜¯ä»€ä¹ˆâ€ã€‚ç›¸åï¼Œè®¤çŸ¥è¿‡ç¨‹å¯¹åº”äºåŸºäºç¨‹åºçŸ¥è¯†çš„æ¢ç´¢ï¼Œå®šä¹‰äº†æ¨ç†å’Œè¡ŒåŠ¨æ–¹å¼çš„â€œå¦‚ä½•â€ã€‚ä¸ºäº†ä¿ƒè¿›çŸ¥è¯†è·å–ï¼Œæˆ‘ä»¬æ„å»ºäº†Web-Cogæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªä»14ä¸ªçœŸå®ç½‘ç«™ç²¾å¿ƒç­–åˆ’çš„ç»“æ„åŒ–èµ„æºï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°çŒè¾“ç½‘ç»œä»£ç†æ‰€éœ€çš„æ ¸å¿ƒçŸ¥è¯†ã€‚è¯¥æ•°æ®é›†ä½œä¸ºä»£ç†çš„æ¦‚å¿µåŸºç¡€â€”â€”æ„å»ºç†è§£çš„â€œåè¯â€ï¼Œä»¥åŠå­¦ä¹ å¦‚ä½•æ¨ç†å’Œè¡ŒåŠ¨çš„åŸºç¡€ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡æ–°çš„çŸ¥è¯†é©±åŠ¨çš„æ€è€ƒé“¾ï¼ˆCoTï¼‰æ¨ç†æ¡†æ¶æ¥å®æ–½è¿™äº›è¿‡ç¨‹ï¼Œå¼€å‘å’Œè®­ç»ƒæˆ‘ä»¬æå‡ºçš„ä»£ç†â€”â€”Web-CogReasonerã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†æœªè§è¿‡çš„ä»»åŠ¡æ—¶ï¼Œç»“æ„åŒ–çŸ¥è¯†æ˜¯èµ·å†³å®šæ€§çš„ã€‚ä¸ºäº†è¿›è¡Œä¸¥æ ¼çš„è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†Web-CogBenchï¼Œè¿™æ˜¯ä¸€å¥—å…¨é¢çš„è¯„ä¼°å·¥å…·ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæ¯”è¾ƒä»£ç†åœ¨ä¸åŒåˆ’åˆ†çš„çŸ¥è¯†é¢†åŸŸå’Œè®¤çŸ¥èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®åœ¨<a target="_blank" rel="noopener" href="https://github.com/Gnonymous/Web-CogReasoner%E5%BC%80%E6%BA%90%E3%80%82">https://github.com/Gnonymous/Web-CogReasonerå¼€æºã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01858v1">PDF</a> Our code and data is open sourced at   <a target="_blank" rel="noopener" href="https://github.com/Gnonymous/Web-CogReasoner">https://github.com/Gnonymous/Web-CogReasoner</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä¸»å¼ Webä»£ç†éœ€å…ˆè·å–å……è¶³çŸ¥è¯†å†å‚ä¸è®¤çŸ¥æ¨ç†ï¼Œæå‡ºWeb-CogKnowledge Frameworkï¼Œå°†çŸ¥è¯†åˆ†ä¸ºäº‹å®ã€æ¦‚å¿µä¸ç¨‹åºä¸‰ç±»ã€‚ä¸ºä¿ƒä½¿çŸ¥è¯†è·å–ï¼Œæ„å»ºWeb-CogDatasetï¼Œé€šè¿‡ç»“æ„åŒ–èµ„æºæ•™æˆæ ¸å¿ƒçŸ¥è¯†ã€‚åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºChain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ¡†æ¶å¹¶è®­ç»ƒWeb-CogReasonerä»£ç†ã€‚å®éªŒè¯æ˜å…¶åœ¨æœªè§ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚åŒæ—¶æ¨å‡ºWeb-CogBenchè¯„ä¼°å¥—ä»¶æ¥è¯„ä¼°ä»£ç†æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Webä»£ç†åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆéœ€è¦è·å–å……è¶³çš„çŸ¥è¯†æ¥è¿›è¡Œæœ‰æ•ˆçš„è®¤çŸ¥æ¨ç†ã€‚</li>
<li>æå‡ºWeb-CogKnowledge Frameworkæ¡†æ¶ï¼Œå°†çŸ¥è¯†åˆ†ä¸ºäº‹å®ã€æ¦‚å¿µå’Œç¨‹åºä¸‰ç±»ã€‚</li>
<li>æ„å»ºWeb-CogDatasetæ•°æ®é›†ï¼Œä»çœŸå®ä¸–ç•Œçš„ç½‘ç«™ä¸­æŒ‘é€‰ç»“æ„åŒ–èµ„æºï¼Œä¸ºä»£ç†æä¾›æ ¸å¿ƒçŸ¥è¯†çš„è®­ç»ƒåŸºç¡€ã€‚</li>
<li>å¼•å…¥Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½åœ¨è·å–çš„çŸ¥è¯†åŸºç¡€ä¸Šè¿›è¡Œæ¨ç†æ“ä½œã€‚</li>
<li>è®­ç»ƒå‡ºWeb-CogReasonerä»£ç†ï¼Œå¹¶åœ¨ä¸€ç³»åˆ—å®éªŒä¸­è¯æ˜äº†å…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
<li>æ¨å‡ºWeb-CogBenchè¯„ä¼°å¥—ä»¶ï¼Œç”¨äºè¯„ä¼°ä»£ç†åœ¨ä¸åŒçŸ¥è¯†é¢†åŸŸå’Œè®¤çŸ¥èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01858">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f2482ff355f92c6997ee058a612d80d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef234964cf0f399bfb6ac0b23200ee88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-448ad4e4b5a7abfcea94db0e958d502b.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AGENTICT-2-S-Robust-Text-to-SPARQL-via-Agentic-Collaborative-Reasoning-over-Heterogeneous-Knowledge-Graphs-for-the-Circular-Economy"><a href="#AGENTICT-2-S-Robust-Text-to-SPARQL-via-Agentic-Collaborative-Reasoning-over-Heterogeneous-Knowledge-Graphs-for-the-Circular-Economy" class="headerlink" title="AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning   over Heterogeneous Knowledge Graphs for the Circular Economy"></a>AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning   over Heterogeneous Knowledge Graphs for the Circular Economy</h2><p><strong>Authors:Yang Zhao, Chengxiao Dai, Wei Zhuo, Tan Chuan Fu, Yue Xiu, Dusit Niyato, Jonathan Z. Low, Eugene Ho Hong Zhuang, Daren Zong Loong Tan</strong></p>
<p>Question answering over heterogeneous knowledge graphs (KGQA) involves reasoning across diverse schemas, incomplete alignments, and distributed data sources. Existing text-to-SPARQL approaches rely on large-scale domain-specific fine-tuning or operate within single-graph settings, limiting their generalizability in low-resource domains and their ability to handle queries spanning multiple graphs. These challenges are particularly relevant in domains such as the circular economy, where information about classifications, processes, and emissions is distributed across independently curated knowledge graphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes KGQA into subtasks managed by specialized agents responsible for retrieval, query generation, and verification. A scheduler assigns subgoals to different graphs using weak-to-strong alignment strategies. A two-stage verifier detects structurally invalid and semantically underspecified queries through symbolic validation and counterfactual consistency checks. Experiments on real-world circular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy by 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing the average prompt length by 46.4%. These results demonstrate the benefits of agent-based schema-aware reasoning for scalable KGQA and support decision-making in sustainability domains through robust cross-graph reasoning. </p>
<blockquote>
<p>é—®ç­”ç³»ç»Ÿåœ¨å¼‚è´¨çŸ¥è¯†å›¾è°±ï¼ˆKGQAï¼‰ä¸­çš„åº”ç”¨æ¶‰åŠè·¨ä¸åŒæ¨¡å¼ã€ä¸å®Œæ•´å¯¹é½å’Œåˆ†å¸ƒå¼æ•°æ®æºçš„æ¨ç†ã€‚ç°æœ‰çš„æ–‡æœ¬åˆ°SPARQLçš„æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡çš„ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒï¼Œæˆ–è€…åœ¨å•ä¸ªå›¾ç¯å¢ƒä¸­è¿è¡Œï¼Œè¿™åœ¨ä½èµ„æºé¢†åŸŸä¸­é™åˆ¶äº†å…¶é€šç”¨æ€§ï¼Œä¹Ÿé™åˆ¶äº†å®ƒä»¬å¤„ç†è·¨å¤šä¸ªå›¾çš„æŸ¥è¯¢çš„èƒ½åŠ›ã€‚è¿™äº›æŒ‘æˆ˜åœ¨å¾ªç¯ç»æµç­‰é¢†åŸŸå°¤ä¸ºçªå‡ºï¼Œå¾ªç¯ç»æµä¸­çš„åˆ†ç±»ã€è¿‡ç¨‹å’Œæ’æ”¾ä¿¡æ¯åˆ†å¸ƒåœ¨ç‹¬ç«‹ç»´æŠ¤çš„çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸­ã€‚æˆ‘ä»¬æå‡ºäº†AgenticT$^2$Sï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå®ƒå°†KGQAåˆ†è§£æˆç”±ä¸“é—¨ä»£ç†è´Ÿè´£æ£€ç´¢ã€æŸ¥è¯¢ç”Ÿæˆå’ŒéªŒè¯çš„å­ä»»åŠ¡ã€‚è°ƒåº¦å™¨ä½¿ç”¨å¼±åˆ°å¼ºçš„å¯¹é½ç­–ç•¥å°†å­ç›®æ ‡åˆ†é…ç»™ä¸åŒçš„å›¾å½¢ã€‚ä¸¤é˜¶æ®µéªŒè¯å™¨é€šè¿‡ç¬¦å·éªŒè¯å’Œåå‘äº‹å®ä¸€è‡´æ€§æ£€æŸ¥æ¥æ£€æµ‹ç»“æ„æ— æ•ˆå’Œè¯­ä¹‰æœªæŒ‡å®šçš„æŸ¥è¯¢ã€‚åœ¨ç°å®ä¸–ç•Œå¾ªç¯ç»æµçŸ¥è¯†å›¾è°±ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸æœ€ä½³åŸºçº¿ç›¸æ¯”ï¼ŒAgenticT$^2$Sçš„æ‰§è¡Œç²¾åº¦æé«˜äº†17.3%ï¼Œä¸‰é‡F$_1$æé«˜äº†25.4%ï¼ŒåŒæ—¶å¹³å‡æç¤ºé•¿åº¦å‡å°‘äº†46.4%ã€‚è¿™äº›ç»“æœè¯æ˜äº†åŸºäºä»£ç†çš„æ¨¡å¼æ„ŸçŸ¥æ¨ç†åœ¨å¯æ‰©å±•çš„KGQAä¸­çš„å¥½å¤„ï¼Œå¹¶é€šè¿‡å¯é çš„è·¨å›¾æ¨ç†æ”¯æŒå¯æŒç»­æ€§é¢†åŸŸçš„å†³ç­–åˆ¶å®šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01815v1">PDF</a> </p>
<p><strong>Summary</strong><br>çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰é¢ä¸´è·¨ä¸åŒæ¨¡å¼ã€ä¸å®Œå…¨å¯¹é½å’Œåˆ†å¸ƒå¼æ•°æ®æºçš„æ¨ç†æŒ‘æˆ˜ã€‚ç°æœ‰æ–‡æœ¬åˆ°SPARQLçš„è½¬æ¢æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒæˆ–åœ¨å•ä¸€å›¾è°±ç¯å¢ƒä¸­è¿è¡Œï¼Œè¿™é™åˆ¶äº†å…¶åœ¨ä½èµ„æºé¢†åŸŸä¸­çš„é€šç”¨æ€§ä»¥åŠå¤„ç†è·¨å¤šå›¾è°±æŸ¥è¯¢çš„èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯åœ¨å¾ªç¯ç»æµç­‰é¢†åŸŸï¼Œä¿¡æ¯åˆ†æ•£åœ¨ç‹¬ç«‹ç¼–åˆ¶çš„çŸ¥è¯†å›¾è°±ä¸­ã€‚æˆ‘ä»¬æå‡ºäº†AgenticT$^2$Sï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå°†KGQAåˆ†è§£æˆç”±ä¸“é—¨ä»£ç†è´Ÿè´£æ£€ç´¢ã€æŸ¥è¯¢ç”Ÿæˆå’ŒéªŒè¯çš„å­ä»»åŠ¡ã€‚è°ƒåº¦å™¨ä½¿ç”¨å¼±åˆ°å¼ºçš„å¯¹é½ç­–ç•¥å°†å­ç›®æ ‡åˆ†é…ç»™ä¸åŒçš„å›¾è°±ã€‚ä¸¤é˜¶æ®µéªŒè¯å™¨é€šè¿‡ç¬¦å·éªŒè¯å’Œåäº‹å®ä¸€è‡´æ€§æ£€æŸ¥æ£€æµ‹ç»“æ„å’Œè¯­ä¹‰ä¸ŠæœªæŒ‡å®šçš„æŸ¥è¯¢ã€‚åœ¨çœŸå®å¾ªç¯ç»æµçŸ¥è¯†å›¾è°±ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAgenticT$^2$Sç›¸è¾ƒäºæœ€ä½³åŸºçº¿ï¼Œæ‰§è¡Œç²¾åº¦æé«˜17.3%ï¼Œä¸‰å…ƒç»„çº§åˆ«F$_1$æé«˜25.4%ï¼Œå¹³å‡æç¤ºé•¿åº¦å‡å°‘46.4%ã€‚è¿™è¡¨æ˜åŸºäºä»£ç†çš„æ¨¡å¼æ„ŸçŸ¥æ¨ç†å¯¹äºå¯æ‰©å±•çš„KGQAå’Œå¯æŒç»­æ€§é¢†åŸŸçš„å†³ç­–æ”¯æŒå…·æœ‰ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KGQAé¢ä¸´è·¨ä¸åŒçŸ¥è¯†å›¾è°±çš„æ¨ç†æŒ‘æˆ˜ï¼Œéœ€å¤„ç†å¤šæ ·æ¨¡å¼ã€ä¸å®Œå…¨å¯¹é½å’Œåˆ†å¸ƒå¼æ•°æ®æºã€‚</li>
<li>ç°æœ‰æ–‡æœ¬åˆ°SPARQLçš„è½¬æ¢æ–¹æ³•ç¼ºä¹é€šç”¨æ€§ï¼Œéš¾ä»¥å¤„ç†è·¨å¤šå›¾è°±æŸ¥è¯¢ã€‚</li>
<li>AgenticT$^2$Sæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œé€šè¿‡ä¸“é—¨ä»£ç†å¤„ç†KGQAçš„ä¸åŒå­ä»»åŠ¡ï¼Œå¦‚æ£€ç´¢ã€æŸ¥è¯¢ç”Ÿæˆå’ŒéªŒè¯ã€‚</li>
<li>è°ƒåº¦å™¨æ ¹æ®å¼±åˆ°å¼ºçš„å¯¹é½ç­–ç•¥åˆ†é…å­ç›®æ ‡åˆ°ä¸åŒå›¾è°±ã€‚</li>
<li>ä¸¤é˜¶æ®µéªŒè¯å™¨æ£€æµ‹ç»“æ„å’Œè¯­ä¹‰ä¸ŠæœªæŒ‡å®šçš„æŸ¥è¯¢ã€‚</li>
<li>åœ¨çœŸå®å¾ªç¯ç»æµçŸ¥è¯†å›¾è°±ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAgenticT$^2$Sè¾ƒç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-111e9a1826250d0fd9e91ab96e587750.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e5ab24816efd01d6f89af3b74c4ffcf9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3cffb252e83ecd909099ce46edca8a8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3477f14a12cf50f32f6d714eccff55a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ce4780a1ad0b8421fad304f1bf3141c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9197d2868e37de21e55e3c519037ab06.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b122537bc2123cf8cea965ba0dfcf09.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Collaborative-Medical-Triage-under-Uncertainty-A-Multi-Agent-Dynamic-Matching-Approach"><a href="#Collaborative-Medical-Triage-under-Uncertainty-A-Multi-Agent-Dynamic-Matching-Approach" class="headerlink" title="Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic   Matching Approach"></a>Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic   Matching Approach</h2><p><strong>Authors:Hongyan Cheng, Chengzhang Yu, Yanshu Shi, Chiyue Wang, Cong Liu, Zhanpeng Jin</strong></p>
<p>The post-pandemic surge in healthcare demand, coupled with critical nursing shortages, has placed unprecedented pressure on medical triage systems, necessitating innovative AI-driven solutions. We present a multi-agent interactive intelligent system for medical triage that addresses three fundamental challenges in current AI-based triage systems: inadequate medical specialization leading to misclassification, heterogeneous department structures across healthcare institutions, and inefficient detail-oriented questioning that impedes rapid triage decisions. Our system employs three specialized agentsâ€“RecipientAgent, InquirerAgent, and DepartmentAgentâ€“that collaborate through Inquiry Guidance mechanism and Classification Guidance Mechanism to transform unstructured patient symptoms into accurate department recommendations. To ensure robust evaluation, we constructed a comprehensive Chinese medical triage dataset from â€œAi Ai Yi Medical Networkâ€, comprising 3,360 real-world cases spanning 9 primary departments and 62 secondary departments. Experimental results demonstrate that our multi-agent system achieves 89.6% accuracy in primary department classification and 74.3% accuracy in secondary department classification after four rounds of patient interaction. The systemâ€™s dynamic matching based guidance mechanisms enable efficient adaptation to diverse hospital configurations while maintaining high triage accuracy. We successfully developed this multi-agent triage system that not only adapts to organizational heterogeneity across healthcare institutions but also ensures clinically sound decision-making. </p>
<blockquote>
<p>åç–«æƒ…æ—¶ä»£åŒ»ç–—éœ€æ±‚çš„æ¿€å¢ï¼ŒåŠ ä¸ŠæŠ¤ç†äººå‘˜çš„ä¸¥é‡çŸ­ç¼ºï¼Œç»™åŒ»ç–—åˆ†æµç³»ç»Ÿå¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„å‹åŠ›ï¼Œæ€¥éœ€åˆ›æ–°çš„AIé©±åŠ¨è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºåŒ»ç–—åˆ†æµçš„å¤šæ™ºèƒ½ä½“äº¤äº’å¼ç³»ç»Ÿï¼Œè§£å†³äº†å½“å‰åŸºäºAIçš„åˆ†æµç³»ç»Ÿä¸­çš„ä¸‰ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼šåŒ»ç–—ä¸“ä¸šåŒ–ä¸è¶³å¯¼è‡´è¯¯åˆ†ç±»ã€åŒ»ç–—æœºæ„ä¹‹é—´éƒ¨é—¨ç»“æ„å¼‚è´¨ã€ä»¥åŠæ•ˆç‡ä½ä¸‹ã€ç»†èŠ‚å¯¼å‘çš„æé—®é˜»ç¢å¿«é€Ÿåˆ†æµå†³ç­–ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé‡‡ç”¨ä¸‰ä¸ªä¸“ç”¨æ™ºèƒ½ä½“â€”â€”RecipientAgentã€InquirerAgentå’ŒDepartmentAgentï¼Œå®ƒä»¬é€šè¿‡æŸ¥è¯¢æŒ‡å¯¼æœºåˆ¶å’Œåˆ†ç±»æŒ‡å¯¼æœºåˆ¶è¿›è¡Œåä½œï¼Œå°†éç»“æ„åŒ–çš„æ‚£è€…ç—‡çŠ¶è½¬åŒ–ä¸ºå‡†ç¡®çš„éƒ¨é—¨æ¨èã€‚ä¸ºç¡®ä¿ç¨³å¥è¯„ä¼°ï¼Œæˆ‘ä»¬ä»â€œçˆ±çˆ±åŒ»ç–—ç½‘â€æ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŒ»ç–—åˆ†æµæ•°æ®é›†ï¼ŒåŒ…å«3360ä¸ªçœŸå®æ¡ˆä¾‹ï¼Œæ¶µç›–9ä¸ªä¸»è¦éƒ¨é—¨å’Œ62ä¸ªæ¬¡è¦éƒ¨é—¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å››è½®æ‚£è€…äº’åŠ¨åï¼Œåœ¨ä¸»è¦éƒ¨é—¨åˆ†ç±»æ–¹é¢è¾¾åˆ°äº†89.6%çš„å‡†ç¡®ç‡ï¼Œåœ¨æ¬¡è¦éƒ¨é—¨åˆ†ç±»æ–¹é¢è¾¾åˆ°äº†74.3%çš„å‡†ç¡®ç‡ã€‚è¯¥ç³»ç»Ÿçš„åŠ¨æ€åŒ¹é…æŒ‡å¯¼æœºåˆ¶èƒ½å¤Ÿé«˜æ•ˆåœ°é€‚åº”ä¸åŒçš„åŒ»é™¢é…ç½®ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„åˆ†æµå‡†ç¡®ç‡ã€‚æˆ‘ä»¬æˆåŠŸå¼€å‘äº†è¿™ä¸ªå¤šæ™ºèƒ½ä½“åˆ†æµç³»ç»Ÿï¼Œå®ƒä¸ä»…é€‚åº”äºåŒ»ç–—æœºæ„ä¹‹é—´çš„ç»„ç»‡å¼‚è´¨æ€§ï¼Œè€Œä¸”ç¡®ä¿ä¸´åºŠå†³ç­–çš„ç§‘å­¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.22504v2">PDF</a> 10 pages, 8 figures, 2 table</p>
<p><strong>æ€»ç»“</strong><br>    ç–«æƒ…ååŒ»ç–—ä¿å¥éœ€æ±‚çš„æ¿€å¢ä¸æŠ¤ç†äººå‘˜çš„çŸ­ç¼ºç»™åŒ»ç–—åˆ†æµç³»ç»Ÿå¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„å‹åŠ›ï¼Œè¿«åˆ‡éœ€è¦åˆ›æ–°çš„äººå·¥æ™ºèƒ½é©±åŠ¨è§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹å½“å‰AIåˆ†æµç³»ç»Ÿä¸­çš„ä¸‰ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼Œå³åŒ»ç–—ä¸“ä¸šåŒ–ä¸è¶³å¯¼è‡´çš„è¯¯åˆ†ç±»ã€åŒ»ç–—æœºæ„ä¹‹é—´éƒ¨é—¨ç»“æ„å·®å¼‚å¤§å’Œä¸è¯¦å°½çš„ç»†èŠ‚é—®é¢˜å¯¼è‡´çš„åˆ†æµå†³ç­–æ•ˆç‡ä½ä¸‹ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“äº’åŠ¨æ™ºèƒ½ç³»ç»Ÿè¿›è¡ŒåŒ»ç–—åˆ†æµã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ä¸‰ä¸ªä¸“é—¨ä»£ç†ï¼šRecipientAgentã€InquirerAgentå’ŒDepartmentAgentï¼Œé€šè¿‡è¯¢é—®æŒ‡å¯¼å’Œåˆ†ç±»æŒ‡å¯¼æœºåˆ¶ååŒå·¥ä½œï¼Œå°†æ‚£è€…çš„ä¸ç»“æ„åŒ–ç—‡çŠ¶è½¬åŒ–ä¸ºå‡†ç¡®çš„ç§‘å®¤æ¨èã€‚ä¸ºäº†ç¡®ä¿æœ‰æ•ˆçš„è¯„ä¼°ï¼Œæˆ‘ä»¬ä»â€œçˆ±çˆ±åŒ»åŒ»ç–—ç½‘ç»œâ€æ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŒ»ç–—åˆ†æµæ•°æ®é›†ï¼ŒåŒ…å«æ¶µç›–9ä¸ªä¸»è¦ç§‘å®¤å’Œ62ä¸ªäºŒçº§ç§‘å®¤çš„3360ä¸ªçœŸå®ç—…ä¾‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å››è½®çš„æ‚£è€…äº’åŠ¨åï¼Œè¯¥å¤šæ™ºèƒ½ç³»ç»Ÿä¸»è¦ç§‘å®¤åˆ†ç±»å‡†ç¡®åº¦è¾¾åˆ°äº†89.6%ï¼ŒäºŒçº§ç§‘å®¤åˆ†ç±»å‡†ç¡®åº¦è¾¾åˆ°äº†74.3%ã€‚è¯¥ç³»ç»Ÿçš„åŠ¨æ€åŒ¹é…æŒ‡å¯¼æœºåˆ¶èƒ½å¤Ÿå®ç°é«˜æ•ˆçš„åŒ»é™¢é…ç½®é€‚åº”ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„åˆ†æµå‡†ç¡®æ€§ã€‚æˆ‘ä»¬æˆåŠŸå¼€å‘äº†è¿™ä¸ªå¤šæ™ºèƒ½åˆ†æµç³»ç»Ÿï¼Œä¸ä»…é€‚åº”äºåŒ»ç–—æœºæ„é—´çš„ç»„ç»‡å¼‚è´¨æ€§ï¼Œè€Œä¸”ç¡®ä¿ä¸´åºŠå†³ç­–çš„ç§‘å­¦æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç–«æƒ…åçš„åŒ»ç–—ä¿å¥éœ€æ±‚æ¿€å¢å’ŒæŠ¤ç†çŸ­ç¼ºç»™åŒ»ç–—åˆ†æµç³»ç»Ÿå¸¦æ¥äº†å‹åŠ›ï¼Œéœ€è¦AIè§£å†³æ–¹æ¡ˆã€‚</li>
<li>å½“å‰AIåŒ»ç–—åˆ†æµç³»ç»Ÿé¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼šåŒ»ç–—ä¸“ä¸šåŒ–ä¸è¶³ã€åŒ»ç–—æœºæ„éƒ¨é—¨ç»“æ„å·®å¼‚å¤§å’Œæ•ˆç‡é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“äº’åŠ¨æ™ºèƒ½ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä¸‰ä¸ªä¸“é—¨ä»£ç†ï¼šRecipientAgentã€InquirerAgentå’ŒDepartmentAgentã€‚</li>
<li>é€šè¿‡è¯¢é—®æŒ‡å¯¼å’Œåˆ†ç±»æŒ‡å¯¼æœºåˆ¶ï¼Œæ™ºèƒ½ç³»ç»Ÿå¯å°†æ‚£è€…çš„ä¸ç»“æ„åŒ–ç—‡çŠ¶è½¬åŒ–ä¸ºå‡†ç¡®çš„ç§‘å®¤æ¨èã€‚</li>
<li>åœ¨åŒ…å«çœŸå®ç—…ä¾‹çš„ä¸­æ–‡åŒ»ç–—åˆ†æµæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯¥ç³»ç»Ÿè¡¨ç°è‰¯å¥½ï¼Œä¸»è¦ç§‘å®¤åˆ†ç±»å‡†ç¡®åº¦é«˜ã€‚</li>
<li>ç³»ç»Ÿçš„åŠ¨æ€åŒ¹é…æŒ‡å¯¼æœºåˆ¶èƒ½é€‚åº”ä¸åŒçš„åŒ»é™¢é…ç½®ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„åˆ†æµå‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.22504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a3da58f9ad030263fb73e6ed308e5016.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20286432eadcdf5f23df851e01a78324.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-434b2667cfd235646a507b91ee78998e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb477c1378d6dff9bedc66ce3cca704f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cbd808d8692665741ce01194e3a0cdd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b4d89f1ed8b412ec02431ee17b248c0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="GEM-Gaussian-Embedding-Modeling-for-Out-of-Distribution-Detection-in-GUI-Agents"><a href="#GEM-Gaussian-Embedding-Modeling-for-Out-of-Distribution-Detection-in-GUI-Agents" class="headerlink" title="GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in   GUI Agents"></a>GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in   GUI Agents</h2><p><strong>Authors:Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang</strong></p>
<p>Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70% over the best-performing baseline while only increasing training time by 4.9% and testing time by 6.5%. We also experimentally demonstrate that GEM can improve the step-wise success rate by 9.40% by requesting assistance from the cloud model when encountering OOD samples. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at <a target="_blank" rel="noopener" href="https://github.com/Wuzheng02/GEM-OODforGUIagents">https://github.com/Wuzheng02/GEM-OODforGUIagents</a>. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ä½œä¸ºäººæœºäº¤äº’çš„ä¸€ç§å¼•äººå…¥èƒœçš„æ¨¡å¼æœ€è¿‘å·²ç»å‡ºç°ï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨æ‰§è¡Œç”¨æˆ·æŒ‡ä»¤æ¥æ“ä½œæ™ºèƒ½ç»ˆç«¯è®¾å¤‡ã€‚ç„¶è€Œï¼Œå½“é‡åˆ°è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰çš„æŒ‡ä»¤ï¼Œè¿™äº›æŒ‡ä»¤å¯èƒ½è¿åç¯å¢ƒçº¦æŸæˆ–è¶…å‡ºä»£ç†çš„å½“å‰èƒ½åŠ›æ—¶ï¼ŒGUIä»£ç†å¯èƒ½ä¼šå‘ç”Ÿä»»åŠ¡æ•…éšœï¼Œç”šè‡³å¯èƒ½æ„æˆå®‰å…¨å¨èƒã€‚å› æ­¤ï¼Œæœ‰æ•ˆçš„GUIä»£ç†çš„OODæ£€æµ‹è‡³å…³é‡è¦ã€‚ç”±äºåµŒå…¥ç©ºé—´çš„å¤æ‚æ€§å’ŒGUIç¯å¢ƒçš„ä¸æ–­å˜åŒ–ï¼Œä¼ ç»Ÿçš„OODæ£€æµ‹æ–¹æ³•åœ¨è¿™ä¸ªé¢†åŸŸè¡¨ç°ä¸ä½³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‘ç°GUIä»£ç†çš„å†…ç½®åˆ†å¸ƒè¾“å…¥è¯­ä¹‰ç©ºé—´åœ¨è·ç¦»è´¨å¿ƒæ–¹é¢è¡¨ç°å‡ºèšç±»æ¨¡å¼ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹æ‹Ÿåˆçš„GEMæ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯¹ä»GUIä»£ç†æå–çš„è¾“å…¥åµŒå…¥è·ç¦»è¿›è¡Œå»ºæ¨¡ï¼Œåæ˜ äº†å…¶èƒ½åŠ›è¾¹ç•Œã€‚åœ¨æ¶µç›–æ™ºèƒ½æ‰‹æœºã€è®¡ç®—æœºå’Œç½‘é¡µæµè§ˆå™¨çš„å…«ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ä¸Šå¹³å‡æé«˜äº†23.70%çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶ä»…å°†è®­ç»ƒæ—¶é—´å¢åŠ 4.9%ï¼Œæµ‹è¯•æ—¶é—´å¢åŠ 6.5%ã€‚æˆ‘ä»¬è¿˜é€šè¿‡å®éªŒè¯æ˜ï¼Œå½“é‡åˆ°OODæ ·æœ¬æ—¶ï¼Œé€šè¿‡è¯·æ±‚äº‘æ¨¡å‹ååŠ©ï¼ŒGEMå¯ä»¥æé«˜æ­¥éª¤æˆåŠŸç‡9.4%ã€‚åˆ†æå¹¶é€šè¿‡åœ¨ä¹ä¸ªä¸åŒä¸»å¹²ç½‘ç»œä¸Šè¿›è¡Œçš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚ç›¸å…³ä»£ç å¯é€šè¿‡é“¾æ¥<a target="_blank" rel="noopener" href="https://github.com/Wuzheng02/GEM-OODforGUIagents%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/Wuzheng02/GEM-OODforGUIagentsè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12842v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†åœ¨é¢ä¸´è¶…å‡ºå…¶èƒ½åŠ›èŒƒå›´æˆ–è¿åç¯å¢ƒçº¦æŸçš„æœªçŸ¥æŒ‡ä»¤æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„æ–¹æ³•ï¼ˆGEMï¼‰è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆè¯†åˆ«å‡ºGUIä»£ç†åœ¨æ™ºèƒ½æ‰‹æœºã€è®¡ç®—æœºå’Œç½‘é¡µæµè§ˆå™¨ç­‰ä¸åŒå¹³å°ä¸Šçš„å¼‚å¸¸è¾“å…¥ï¼Œç›¸è¾ƒäºç°æœ‰æœ€ä½³åŸºçº¿æ¨¡å‹ï¼Œå…¶å‡†ç¡®ç‡å¹³å‡æé«˜23.70%ï¼ŒåŒæ—¶ä»…å¢åŠ è®­ç»ƒæ—¶é—´4.9%å’Œæµ‹è¯•æ—¶é—´6.5%ã€‚å½“é‡åˆ°è¶…å‡ºä»£ç†èƒ½åŠ›çš„æ ·æœ¬æ—¶ï¼Œé€šè¿‡è¯·æ±‚äº‘æ¨¡å‹ååŠ©ï¼Œå¯è¿›ä¸€æ­¥æé«˜æ­¥éª¤æˆåŠŸç‡9.40%ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œç›¸å…³ä»£ç å·²å…¬å¼€äºGitHubã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GUIä»£ç†åœ¨é¢ä¸´è¶…å‡ºå…¶èƒ½åŠ›èŒƒå›´æˆ–è¿åç¯å¢ƒçº¦æŸçš„æœªçŸ¥æŒ‡ä»¤æ—¶å¯èƒ½å‡ºç°é—®é¢˜ã€‚</li>
<li>ä¼ ç»ŸOODæ£€æµ‹æ–¹æ³•åœ¨GUIç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºç¯å¢ƒå¤æ‚å’Œå˜åŒ–æ€§å¤§ã€‚</li>
<li>æœ¬æ–‡è§‚å¯Ÿåˆ°GUIä»£ç†çš„è¾“å…¥è¯­ä¹‰ç©ºé—´å…·æœ‰ç‰¹å®šçš„èšç±»æ¨¡å¼ï¼ŒåŸºäºæ­¤æå‡ºäº†åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„GEMæ–¹æ³•ã€‚</li>
<li>GEMæ–¹æ³•åœ¨ä¸åŒå¹³å°ä¸Šå®ç°äº†è¾ƒé«˜çš„å‡†ç¡®ç‡æå‡ï¼Œä¸”å¯¹è®­ç»ƒå’Œæµ‹è¯•æ—¶é—´çš„å½±å“è¾ƒå°ã€‚</li>
<li>å½“é‡åˆ°æœªçŸ¥æ ·æœ¬æ—¶ï¼Œé€šè¿‡è¯·æ±‚äº‘æ¨¡å‹ååŠ©ï¼Œå¯è¿›ä¸€æ­¥æé«˜ä»£ç†çš„æ€§èƒ½ã€‚</li>
<li>å®éªŒè¯æ˜GEMæ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶é€‚ç”¨äºå¤šç§ä¸åŒçš„æ¨¡å‹æ¶æ„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12842">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d23f1f13aa38d5cc6a37242728bd2846.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed0b213bd5f2f06b369a58934137a559.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93286aca50f6d7492bccd07f3cbdf121.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d11ed813242b14fec95f65eda28f1a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9476b1ac5c9690bc7535feebb29fb81f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7712fd477bee525baff1c5a7cfcb16fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8f1323ab0da352e826c7ac45bab91788.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Interpreting-Multi-band-Galaxy-Observations-with-Large-Language-Model-Based-Agents"><a href="#Interpreting-Multi-band-Galaxy-Observations-with-Large-Language-Model-Based-Agents" class="headerlink" title="Interpreting Multi-band Galaxy Observations with Large Language   Model-Based Agents"></a>Interpreting Multi-band Galaxy Observations with Large Language   Model-Based Agents</h2><p><strong>Authors:Zechang Sun, Yuan-Sen Ting, Yaobo Liang, Nan Duan, Song Huang, Zheng Cai</strong></p>
<p>Astronomical research traditionally relies on extensive domain knowledge to interpret observations and narrow down hypotheses. We demonstrate that this process can be emulated using large language model-based agents to accelerate research workflows. We propose mephisto, a multi-agent collaboration framework that mimics human reasoning to interpret multi-band galaxy observations. mephisto interacts with the CIGALE codebase, which includes spectral energy distribution (SED) models to explain observations. In this open-world setting, mephisto learns from its self-play experience, performs tree search, and accumulates knowledge in a dynamically updated base. As a proof of concept, we apply mephisto to the latest data from the James Webb Space Telescope. mephisto attains near-human proficiency in reasoning about galaxiesâ€™ physical scenarios, even when dealing with a recently discovered population of â€œLittle Red Dotâ€ galaxies. This represents the first demonstration of agentic research in astronomy, advancing towards end-to-end research via LLM agents and potentially expediting astronomical discoveries. </p>
<blockquote>
<p>ä¼ ç»Ÿçš„å¤©æ–‡ç ”ç©¶ä¾èµ–äºå¹¿æ³›çš„é¢†åŸŸçŸ¥è¯†æ¥è§£é‡Šè§‚æµ‹ç»“æœå¹¶ç¼©å°å‡è®¾èŒƒå›´ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯ä»¥ä½¿ç”¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†æ¥åŠ é€Ÿç ”ç©¶å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬æå‡ºäº†æ¨¡ä»¿äººç±»æ¨ç†æ¥è§£é‡Šå¤šæ³¢æ®µæ˜Ÿç³»è§‚æµ‹æ•°æ®çš„æ™ºèƒ½ä½“åˆä½œæ¡†æ¶â€œå¢¨è²æ–¯æ‰˜â€ã€‚å¢¨è²æ–¯æ‰˜ä¸CIGALEä»£ç åº“è¿›è¡Œäº¤äº’ï¼Œè¯¥ä»£ç åº“åŒ…å«å…‰è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDï¼‰æ¨¡å‹æ¥è§£é‡Šè§‚æµ‹ç»“æœã€‚åœ¨è¿™ä¸ªå¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­ï¼Œå¢¨è²æ–¯æ‰˜é€šè¿‡è‡ªæˆ‘ç©è€ç»éªŒå­¦ä¹ ï¼Œè¿›è¡Œæ ‘æœç´¢ï¼Œå¹¶åœ¨åŠ¨æ€æ›´æ–°çš„åŸºç¡€ä¸Šç§¯ç´¯çŸ¥è¯†ã€‚ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œæˆ‘ä»¬å°†å¢¨è²æ–¯æ‰˜åº”ç”¨äºè©¹å§†æ–¯éŸ¦ä¼¯å¤ªç©ºæœ›è¿œé•œçš„æœ€æ–°æ•°æ®ã€‚å¢¨è²æ–¯æ‰˜åœ¨å¤„ç†æœ€è¿‘å‘ç°çš„â€œå°çº¢ç‚¹â€æ˜Ÿç³»ç¾¤ä½“æ—¶ï¼Œåœ¨ç†è§£æ˜Ÿç³»ç‰©ç†åœºæ™¯æ–¹é¢è¾¾åˆ°äº†è¿‘ä¹äººç±»çš„ç†Ÿç»ƒç¨‹åº¦ã€‚è¿™æ ‡å¿—ç€å¤©æ–‡é¢†åŸŸæ™ºèƒ½ç ”ç©¶çš„é¦–æ¬¡å±•ç¤ºï¼Œæœç€é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†è¿›è¡Œç«¯åˆ°ç«¯ç ”ç©¶çš„æ–¹å‘è¿ˆè¿›ï¼Œå¹¶æœ‰å¯èƒ½åŠ é€Ÿå¤©æ–‡å­¦å‘ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.14807v2">PDF</a> Accepted at the NIPS ML4PS Workshop 2024. The journal version is in   preparation. Code and data will be fully made public following the journal   publication. We welcome any comments and feedback</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ¨ç†ï¼ŒåŠ å¿«å¤©æ–‡ç ”ç©¶æµç¨‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºmephistoçš„å¤šä»£ç†åä½œæ¡†æ¶ï¼Œç”¨äºè§£é‡Šå¤šæ³¢æ®µæ˜Ÿç³»è§‚æµ‹ç»“æœã€‚é€šè¿‡ä¸åŒ…æ‹¬å…‰è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDï¼‰æ¨¡å‹åœ¨å†…çš„CIGALEä»£ç åº“äº’åŠ¨ï¼Œmephistoå¯ä»¥åœ¨å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œè‡ªæˆ‘æ¸¸æˆç»éªŒå­¦ä¹ ï¼Œè¿›è¡Œæ ‘çŠ¶æœç´¢å¹¶åœ¨åŠ¨æ€æ›´æ–°çš„çŸ¥è¯†åº“ä¸­ç§¯ç´¯çŸ¥è¯†ã€‚åœ¨è©¹å§†æ–¯Â·éŸ¦ä¼¯å¤ªç©ºæœ›è¿œé•œçš„æœ€æ–°æ•°æ®åº”ç”¨ä¸­ï¼Œmephistoåœ¨å…³äºæ˜Ÿç³»ç‰©ç†åœºæ™¯çš„æ¨ç†ä¸­è¾¾åˆ°äº†æ¥è¿‘äººç±»çš„ç†Ÿç»ƒç¨‹åº¦ï¼Œå³ä½¿åœ¨å¤„ç†æœ€æ–°å‘ç°çš„â€œå°çº¢ç‚¹â€æ˜Ÿç³»ç¾¤ä½“æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™æ ‡å¿—ç€ä»£ç†ç ”ç©¶çš„é¦–æ¬¡åœ¨å¤©æ–‡å­¦é¢†åŸŸçš„å±•ç¤ºï¼Œæœç€é€šè¿‡LLMä»£ç†è¿›è¡Œç«¯åˆ°ç«¯ç ”ç©¶çš„æ–¹å‘è¿ˆè¿›ï¼Œå¹¶å¯èƒ½åŠ é€Ÿå¤©æ–‡å­¦å‘ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†èƒ½æ¨¡æ‹Ÿäººç±»æ¨ç†ä»¥åŠ å¿«å¤©æ–‡å­¦ç ”ç©¶ã€‚</li>
<li>æå‡ºåä¸ºmephistoçš„å¤šä»£ç†åä½œæ¡†æ¶ï¼Œç”¨ä»¥è§£é‡Šå¤šæ³¢æ®µæ˜Ÿç³»è§‚æµ‹ã€‚</li>
<li>mephistoä¸CIGALEä»£ç åº“ä¸­çš„SEDæ¨¡å‹äº’åŠ¨ã€‚</li>
<li>mephistoåœ¨å¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œè‡ªæˆ‘æ¸¸æˆç»éªŒå­¦ä¹ ã€æ ‘çŠ¶æœç´¢å’ŒçŸ¥è¯†ç§¯ç´¯ã€‚</li>
<li>åœ¨è©¹å§†æ–¯Â·éŸ¦ä¼¯å¤ªç©ºæœ›è¿œé•œæ•°æ®ä¸­ï¼Œmephistoå±•ç°å‡ºæ¥è¿‘äººç±»çš„æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è§£é‡Šæ˜Ÿç³»ç‰©ç†åœºæ™¯æ–¹é¢ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡å±•ç¤ºåœ¨å¤©æ–‡å­¦é¢†åŸŸä½¿ç”¨ä»£ç†è¿›è¡Œç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.14807">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6425f9e89d79cb0f7af7c2868d3a0448.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-faaa9449101f0aa4b09028fe216e8c56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-869b32fe6a7ff5202c1da3366a1f7b9e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-13cb0cc4d0ced69b5bb07a8d318a2f48.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="ME-IGM-Individual-Global-Max-in-Maximum-Entropy-Multi-Agent-Reinforcement-Learning"><a href="#ME-IGM-Individual-Global-Max-in-Maximum-Entropy-Multi-Agent-Reinforcement-Learning" class="headerlink" title="ME-IGM: Individual-Global-Max in Maximum Entropy Multi-Agent   Reinforcement Learning"></a>ME-IGM: Individual-Global-Max in Maximum Entropy Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Wen-Tse Chen, Yuxuan Li, Shiyu Huang, Jiayu Chen, Jeff Schneider</strong></p>
<p>Multi-agent credit assignment is a fundamental challenge for cooperative multi-agent reinforcement learning (MARL), where a team of agents learn from shared reward signals. The Individual-Global-Max (IGM) condition is a widely used principle for multi-agent credit assignment, requiring that the joint action determined by individual Q-functions maximizes the global Q-value. Meanwhile, the principle of maximum entropy has been leveraged to enhance exploration in MARL. However, we identify a critical limitation in existing maximum entropy MARL methods: a misalignment arises between local policies and the joint policy that maximizes the global Q-value, leading to violations of the IGM condition. To address this misalignment, we propose an order-preserving transformation. Building on it, we introduce ME-IGM, a novel maximum entropy MARL algorithm compatible with any credit assignment mechanism that satisfies the IGM condition while enjoying the benefits of maximum entropy exploration. We empirically evaluate two variants of ME-IGM: ME-QMIX and ME-QPLEX, in non-monotonic matrix games, and demonstrate their state-of-the-art performance across 17 scenarios in SMAC-v2 and Overcooked. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“ä¿¡ç”¨åˆ†é…æ˜¯åˆä½œå‹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼Œå…¶ä¸­ä¸€ç»„æ™ºèƒ½ä½“ä»å…±äº«å¥–åŠ±ä¿¡å·ä¸­å­¦ä¹ ã€‚ä¸ªä½“-å…¨å±€-æœ€å¤§åŒ–ï¼ˆIGMï¼‰æ¡ä»¶æ˜¯ç”¨äºå¤šæ™ºèƒ½ä½“ä¿¡ç”¨åˆ†é…çš„ä¸€ä¸ªå¹¿æ³›åº”ç”¨çš„åŸåˆ™ï¼Œè¦æ±‚ç”±ä¸ªä½“Qå‡½æ•°å†³å®šçš„è”åˆè¡ŒåŠ¨æœ€å¤§åŒ–å…¨å±€Qå€¼ã€‚åŒæ—¶ï¼Œæœ€å¤§ç†µåŸåˆ™å·²è¢«ç”¨äºå¢å¼ºMARLä¸­çš„æ¢ç´¢ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°äº†ç°æœ‰æœ€å¤§ç†µMARLæ–¹æ³•çš„ä¸€ä¸ªå…³é”®å±€é™ï¼šå±€éƒ¨æ”¿ç­–å’Œæœ€å¤§åŒ–å…¨å±€Qå€¼çš„è”åˆæ”¿ç­–ä¹‹é—´å‡ºç°ä¸åŒ¹é…ï¼Œå¯¼è‡´IGMæ¡ä»¶çš„è¿åã€‚ä¸ºäº†è§£å†³è¿™ç§ä¸åŒ¹é…ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¿åºå˜æ¢ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†ME-IGMï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æœ€å¤§ç†µMARLç®—æ³•ï¼Œä¸ä»»ä½•æ»¡è¶³IGMæ¡ä»¶çš„ä¿¡ç”¨åˆ†é…æœºåˆ¶å…¼å®¹ï¼ŒåŒæ—¶äº«å—æœ€å¤§ç†µæ¢ç´¢çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬é€šè¿‡éå•è°ƒçŸ©é˜µæ¸¸æˆå¯¹ME-IGMçš„ä¸¤ä¸ªå˜ä½“ME-QMIXå’ŒME-QPLEXè¿›è¡Œäº†å®è¯è¯„ä¼°ï¼Œåœ¨SMAC-v2å’ŒOvercookedçš„17ä¸ªåœºæ™¯ä¸­å±•ç¤ºäº†å®ƒä»¬çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13930v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¿¡ç”¨åˆ†é…é—®é¢˜ï¼Œå¹¶æŒ‡å‡ºäº†ç°æœ‰æœ€å¤§ç†µå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸­çš„å…³é”®å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ME-IGMç®—æ³•ï¼Œè¯¥ç®—æ³•å…¼å®¹ä»»ä½•æ»¡è¶³IGMæ¡ä»¶çš„ä¿¡ç”¨åˆ†é…æœºåˆ¶ï¼Œå¹¶äº«å—æœ€å¤§ç†µæ¢ç´¢çš„ä¼˜åŠ¿ã€‚ç»è¿‡åœ¨éå•è°ƒçŸ©é˜µæ¸¸æˆä¸­çš„å®è¯ç ”ç©¶ï¼ŒME-IGMçš„ä¸¤ä¸ªå˜ä½“ME-QMIXå’ŒME-QPLEXåœ¨SMAC-v2å’ŒOvercookedçš„17ä¸ªåœºæ™¯ä¸­å±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€æ˜¯ä¿¡ç”¨åˆ†é…é—®é¢˜ï¼Œå°¤å…¶åœ¨å…±äº«å¥–åŠ±ä¿¡å·çš„æƒ…å¢ƒä¸­å°¤ä¸ºé‡è¦ã€‚</li>
<li>ä¸ªä½“å…¨å±€æœ€å¤§ï¼ˆIGMï¼‰æ¡ä»¶å¹¿æ³›åº”ç”¨äºå¤šæ™ºèƒ½ä½“ä¿¡ç”¨åˆ†é…åŸåˆ™ä¸­ï¼Œå®ƒè¦æ±‚ç”±ä¸ªä½“Qå‡½æ•°å†³å®šçš„è”åˆè¡ŒåŠ¨æœ€å¤§åŒ–å…¨å±€Qå€¼ã€‚</li>
<li>æœ€å¤§ç†µåŸåˆ™å·²ç”¨äºå¢å¼ºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢èƒ½åŠ›ã€‚</li>
<li>ç„¶è€Œï¼Œç°æœ‰çš„æœ€å¤§ç†µå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•å­˜åœ¨ä¸€ä¸ªå…³é”®å±€é™ï¼šå±€éƒ¨æ”¿ç­–ä¸æœ€å¤§åŒ–å…¨å±€Qå€¼çš„è”åˆæ”¿ç­–ä¹‹é—´çš„ä¸åŒ¹é…å¯¼è‡´IGMæ¡ä»¶çš„è¿åã€‚</li>
<li>ä¸ºäº†è§£å†³è¿™ä¸€ä¸åŒ¹é…é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é¡ºåºä¿ç•™è½¬æ¢æ–¹æ³•ã€‚</li>
<li>åŸºäºæ­¤è½¬æ¢æ–¹æ³•ï¼Œå¼•å…¥äº†ME-IGMç®—æ³•ï¼Œè¯¥ç®—æ³•ä¸ä»»ä½•æ»¡è¶³IGMæ¡ä»¶çš„ä¿¡ç”¨åˆ†é…æœºåˆ¶å…¼å®¹ï¼Œå¹¶äº«å—æœ€å¤§ç†µæ¢ç´¢çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.13930">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-778bdeb0341b2c5b4a7a3f1ff8382cf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffba41638f2e8cb75c213513307453f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c49894d235ec3065295651d15529bf36.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f97ec04e7a2e286f1a17a4604cb25b05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62c1ac08f122a5d693e2ceda80543bc5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-478183fd9210f6cb966afc43f0e42a53.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-06/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-06/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-06/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-098648614c4853e987444c1488b0fb78.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  MicroMix Efficient Mixed-Precision Quantization with Microscaling   Formats for Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-06/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-35e7d6f740610ead318746206df0c675.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-06  Raw Data Matters Enhancing Prompt Tuning by Internal Augmentation on   Vision-Language Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26548.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
