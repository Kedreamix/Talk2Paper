<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM 方向最新论文已更新，请持续关注 Update in 2025-08-04  Probing then Editing Response Personality of Large Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d5ba4411c3480909084ccb331b6501c9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    35 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-04-更新"><a href="#2025-08-04-更新" class="headerlink" title="2025-08-04 更新"></a>2025-08-04 更新</h1><h2 id="Probing-then-Editing-Response-Personality-of-Large-Language-Models"><a href="#Probing-then-Editing-Response-Personality-of-Large-Language-Models" class="headerlink" title="Probing then Editing Response Personality of Large Language Models"></a>Probing then Editing Response Personality of Large Language Models</h2><p><strong>Authors:Tianjie Ju, Zhenyu Shao, Bowen Wang, Yujia Chen, Zhuosheng Zhang, Hao Fei, Mong-Li Lee, Wynne Hsu, Sufeng Duan, Gongshen Liu</strong></p>
<p>Large Language Models (LLMs) have demonstrated promising capabilities to generate responses that simulate consistent personality traits. Despite the major attempts to analyze personality expression through output-based evaluations, little is known about how such traits are internally encoded within LLM parameters. In this paper, we introduce a layer-wise probing framework to systematically investigate the layer-wise capability of LLMs in simulating personality for responding. We conduct probing experiments on 11 open-source LLMs over the PersonalityEdit benchmark and find that LLMs predominantly simulate personality for responding in their middle and upper layers, with instruction-tuned models demonstrating a slightly clearer separation of personality traits. Furthermore, by interpreting the trained probing hyperplane as a layer-wise boundary for each personality category, we propose a layer-wise perturbation method to edit the personality expressed by LLMs during inference. Our results show that even when the prompt explicitly specifies a particular personality, our method can still successfully alter the response personality of LLMs. Interestingly, the difficulty of converting between certain personality traits varies substantially, which aligns with the representational distances in our probing experiments. Finally, we conduct a comprehensive MMLU benchmark evaluation and time overhead analysis, demonstrating that our proposed personality editing method incurs only minimal degradation in general capabilities while maintaining low training costs and acceptable inference latency. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/universe-sky/probing-then-editing-personality">https://github.com/universe-sky/probing-then-editing-personality</a>. </p>
<blockquote>
<p>大型语言模型（LLM）已展现出生成具有一致性格特征回应的潜力。尽管已经进行了大量尝试通过分析基于输出的评估来探究性格表达，但对于LLM参数内部如何编码此类特性仍知之甚少。在本文中，我们引入了一种逐层探测框架，以系统地研究LLM在响应中模拟性格的逐层能力。我们在PersonalityEdit基准测试上对11个开源LLM进行了探测实验，发现LLM主要在中间层和上层模拟性格以进行回应，经过指令调整的模型在性格特征上表现出稍微清晰的分离。此外，通过将训练好的探测超平面解释为每个性格类别的逐层边界，我们提出了一种逐层扰动方法在推理过程中编辑LLM所表现出的性格。我们的结果表明，即使提示明确指定了某种性格，我们的方法仍然可以成功地改变LLM的回应性格。有趣的是，在不同性格之间的转换难度存在很大差异，这与我们的探测实验中的代表性距离相吻合。最后，我们进行了全面的MMLU基准测试评估和时间开销分析，证明了我们提出的性格编辑方法仅对一般能力造成最小退化，同时保持低训练成本和可接受的推理延迟。我们的代码公开在<a target="_blank" rel="noopener" href="https://github.com/universe-sky/probing-then-editing-personality%E3%80%82">https://github.com/universe-sky/probing-then-editing-personality。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10227v2">PDF</a> Accepted at COLM 2025</p>
<p><strong>Summary</strong></p>
<p>本文探究了大型语言模型（LLM）在模拟人格特质方面的能力，并提出了一种逐层探测框架来系统研究LLM各层在模拟人格方面的能力。通过 PersonalityEdit 基准测试集的探测实验发现，LLM主要在中层和上层模拟人格，指令调整模型在人格特质上表现出略微清晰的分离。此外，本文提出一种逐层微扰方法，可在推理过程中编辑LLM表达的人格。结果显示，即使提示明确指定了特定人格，该方法仍能成功改变LLM的响应人格。研究还表明不同人格特质之间的转换难度差异显著，与探测实验结果中的代表性距离相符。最后进行了MMLU基准评估和时间开销分析，证明本文提出的人格编辑方法仅对一般能力产生轻微影响，同时保持低训练成本和可接受的推理延迟。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM具备模拟人格特质的能力，主要通过中层和上层进行。</li>
<li>指令调整模型在模拟人格特质上表现出轻微分离。</li>
<li>逐层微扰方法可在推理过程中编辑LLM的人格表达。</li>
<li>人格特质之间的转换难度存在差异，与探测实验中的代表性距离相符。</li>
<li>提出的方法对LLM的一般能力影响轻微。</li>
<li>方法具有较低的训练成本和可接受的推理延迟。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10227">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-033f8e0731ce0f25af4c4b5cd1fb5425.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9e6f8563a78ee6025d8e87c66d4a87fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00017938891a792ed728c29e0161e745.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36087282b363466b98a64b0a0bf180af.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Bi-LAT-Bilateral-Control-Based-Imitation-Learning-via-Natural-Language-and-Action-Chunking-with-Transformers"><a href="#Bi-LAT-Bilateral-Control-Based-Imitation-Learning-via-Natural-Language-and-Action-Chunking-with-Transformers" class="headerlink" title="Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language   and Action Chunking with Transformers"></a>Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language   and Action Chunking with Transformers</h2><p><strong>Authors:Takumi Kobayashi, Masato Kobayashi, Thanpimon Buamanee, Yuki Uranishi</strong></p>
<p>We present Bi-LAT, a novel imitation learning framework that unifies bilateral control with natural language processing to achieve precise force modulation in robotic manipulation. Bi-LAT leverages joint position, velocity, and torque data from leader-follower teleoperation while also integrating visual and linguistic cues to dynamically adjust applied force. By encoding human instructions such as “softly grasp the cup” or “strongly twist the sponge” through a multimodal Transformer-based model, Bi-LAT learns to distinguish nuanced force requirements in real-world tasks. We demonstrate Bi-LAT’s performance in (1) unimanual cup-stacking scenario where the robot accurately modulates grasp force based on language commands, and (2) bimanual sponge-twisting task that requires coordinated force control. Experimental results show that Bi-LAT effectively reproduces the instructed force levels, particularly when incorporating SigLIP among tested language encoders. Our findings demonstrate the potential of integrating natural language cues into imitation learning, paving the way for more intuitive and adaptive human-robot interaction. For additional material, please visit: <a target="_blank" rel="noopener" href="https://mertcookimg.github.io/bi-lat/">https://mertcookimg.github.io/bi-lat/</a> </p>
<blockquote>
<p>我们提出了Bi-LAT，这是一种新型模仿学习框架，它将双边控制与自然语言处理相结合，实现机器人操作中的精确力度调节。Bi-LAT利用领导者-跟随者遥操作中的关节位置、速度和扭矩数据，同时整合视觉和语言线索来动态调整应用力度。通过基于Transformer的多模态模型编码人类指令，如“轻轻握住杯子”或“用力扭转海绵”，Bi-LAT学会了在现实任务中区分细微的力度要求。我们展示了Bi-LAT在（1）单手叠杯场景中的表现，机器人能够根据语言命令准确调节握力力度；（2）需要协调力度控制的双手扭转海绵任务。实验结果表明，Bi-LAT在采用SigLIP语言编码器进行测试时，能够有效地复制指示的力度水平。我们的研究展示了将自然语言线索融入模仿学习的潜力，为更直观和适应性的人机交互铺平了道路。更多材料请访问：[<a target="_blank" rel="noopener" href="https://mertcookimg.github.io/bi-lat/]">https://mertcookimg.github.io/bi-lat/]</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01301v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了Bi-LAT这一新型模仿学习框架，它将双边控制与自然语言处理相结合，实现机器人操作中的精确力度调节。Bi-LAT利用领导者-跟随者遥控操作中的关节位置、速度和扭矩数据，同时整合视觉和语言线索来动态调整应用力度。通过多模态Transformer模型编码人类指令，Bi-LAT能够区分现实任务中的细微力度要求。在单手叠杯和双手扭海绵的场景中，Bi-LAT表现出良好的性能，能够准确根据语言命令调整抓握力度和协调力度控制。实验结果表明，Bi-LAT在融入SigLIP语言编码器后，能够更有效地复制指令力度水平。此研究展示了将自然语言线索融入模仿学习的潜力，为更直观和适应性的人机交互铺平了道路。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Bi-LAT是一个结合双边控制与自然语言处理的模仿学习框架，用于机器人操作中的精确力度调节。</li>
<li>Bi-LAT利用领导者-跟随者遥控操作中的多种数据，同时结合视觉和语言线索进行动态力度调整。</li>
<li>多模态Transformer模型被用于编码人类指令，使Bi-LAT能够区分现实任务中的细微力度差异。</li>
<li>在单双手操作场景中，Bi-LAT表现出良好的性能，能够准确根据语言命令调整力度。</li>
<li>实验表明，融入SigLIP语言编码器后，Bi-LAT能更有效地复制指令力度水平。</li>
<li>Bi-LAT研究展示了自然语言线索在模仿学习中的潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01301">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9c3e9a82c3198af472774a8224019e51.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-50a5e87cac9caca9a0eb8c7a25d3d5d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f98433984e7328ce74b520b785abcde.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-001017459d7afd5367f0a488807bc7ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0dfbec982a29513868dd51bd409c6906.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e89bda4e258be892b2719a1c10d5242.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21e224135314776ef587b2431d61775e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e368b57faedfe1f1cc6fbef11b4b8b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a2ac4b1bc1b1f3e0ee90bc65e708afc.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Generating-Clinically-Realistic-EHR-Data-via-a-Hierarchy-and-Semantics-Guided-Transformer"><a href="#Generating-Clinically-Realistic-EHR-Data-via-a-Hierarchy-and-Semantics-Guided-Transformer" class="headerlink" title="Generating Clinically Realistic EHR Data via a Hierarchy- and   Semantics-Guided Transformer"></a>Generating Clinically Realistic EHR Data via a Hierarchy- and   Semantics-Guided Transformer</h2><p><strong>Authors:Guanglin Zhou, Sebastiano Barbieri</strong></p>
<p>Generating realistic synthetic electronic health records (EHRs) holds tremendous promise for accelerating healthcare research, facilitating AI model development and enhancing patient privacy. However, existing generative methods typically treat EHRs as flat sequences of discrete medical codes. This approach overlooks two critical aspects: the inherent hierarchical organization of clinical coding systems and the rich semantic context provided by code descriptions. Consequently, synthetic patient sequences often lack high clinical fidelity and have limited utility in downstream clinical tasks. In this paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT), a novel framework that leverages both hierarchical and semantic information for the generative process. HiSGT constructs a hierarchical graph to encode parent-child and sibling relationships among clinical codes and employs a graph neural network to derive hierarchy-aware embeddings. These are then fused with semantic embeddings extracted from a pre-trained clinical language model (e.g., ClinicalBERT), enabling the Transformer-based generator to more accurately model the nuanced clinical patterns inherent in real EHRs. Extensive experiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGT significantly improves the statistical alignment of synthetic data with real patient records, as well as supports robust downstream applications such as chronic disease classification. By addressing the limitations of conventional raw code-based generative models, HiSGT represents a significant step toward clinically high-fidelity synthetic data generation and a general paradigm suitable for interpretable medical code representation, offering valuable applications in data augmentation and privacy-preserving healthcare analytics. </p>
<blockquote>
<p>生成逼真的合成电子健康记录（EHRs）对于加速医疗研究、促进人工智能模型发展和增强患者隐私保护具有巨大潜力。然而，现有的生成方法通常将EHRs视为离散医疗代码的平面序列。这种方法忽略了两个关键方面：临床编码系统的固有层次结构和代码描述提供的丰富语义上下文。因此，合成患者序列通常缺乏高度的临床真实性和在下游临床任务中的实用性。在本文中，我们提出了层次化和语义引导变压器（HiSGT），这是一种利用层次和语义信息进行生成过程的新型框架。HiSGT构建了一个层次图来编码临床代码之间的父子关系和兄弟关系，并采用图神经网络来推导层次感知嵌入。这些嵌入然后与从预训练的临床语言模型（例如，ClinicalBERT）中提取的语义嵌入相融合，使基于Transformer的生成器能够更准确地模拟真实EHRs中固有的微妙临床模式。在MIMIC-III和MIMIC-IV数据集上的大量实验表明，HiSGT显著提高了合成数据与真实患者记录之间的统计对齐，并支持慢性疾病分类等稳健的下游应用。通过解决基于传统原始代码的生成模型的局限性，HiSGT朝着临床高保真合成数据生成迈出了重要一步，并形成了适合可解释医疗代码表示的一般范式，在数据增强和隐私保护医疗分析中具有宝贵的应用价值。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20719v2">PDF</a> The camera ready version for ECAI-2025</p>
<p><strong>摘要</strong></p>
<p>生成真实的合成电子健康记录（EHRs）对于加速医学研究、促进人工智能模型发展和增强患者隐私保护具有巨大潜力。然而，现有的生成方法通常将EHRs视为离散医疗代码的平面序列，忽略了临床编码系统的固有层次结构和代码描述所提供的丰富语义上下文。因此，合成患者序列通常缺乏高度临床真实性，在下游临床任务中的实用性有限。本文提出一种利用层次和语义信息引导的新型框架Hierarchy- and Semantics-Guided Transformer（HiSGT）。HiSGT构建了一个层次结构图来编码临床代码之间的父子关系和兄弟姐妹关系，并使用图神经网络来推导层次感知嵌入。这些嵌入与来自预训练临床语言模型（如ClinicalBERT）的语义嵌入相结合，使基于Transformer的生成器能够更准确地模拟真实EHRs中固有的微妙临床模式。在MIMIC-III和MIMIC-IV数据集上的大量实验表明，HiSGT显著提高了合成数据与真实患者记录的统计对齐程度，并支持如慢性病分类等稳健的下游应用。通过解决基于原始代码的生成模型的局限性，HiSGT是朝着临床高保真合成数据生成迈出的重要一步，并且是适合可解释医疗代码表示的一般范式，在数据增强和隐私保护医疗分析中具有宝贵的应用价值。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>生成合成电子健康记录（EHRs）对于医疗研究、AI模型发展和患者隐私保护具有重要意义。</li>
<li>现有生成方法通常忽略EHRs的层次结构和语义上下文，导致合成数据缺乏临床真实性。</li>
<li>HiSGT框架利用层次结构和语义信息来提高合成数据的临床真实性。</li>
<li>HiSGT通过构建层次结构图和利用图神经网络来编码临床代码的复杂关系。</li>
<li>HiSGT融合层次感知嵌入和语义嵌入，以提高合成数据的准确性。</li>
<li>在MIMIC-III和MIMIC-IV数据集上的实验表明，HiSGT提高了合成数据与真实数据的统计对齐程度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20719">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ff6a7c710a34973983777e2f683da629.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5ba4411c3480909084ccb331b6501c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-68b5afd8c39277af0678608471f0d414.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d0ef6077c5098f1705aab942bd1d4c5.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Bias-in-Decision-Making-for-AI’s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude"><a href="#Bias-in-Decision-Making-for-AI’s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude" class="headerlink" title="Bias in Decision-Making for AI’s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude"></a>Bias in Decision-Making for AI’s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude</h2><p><strong>Authors:Yile Yan, Yuqi Zhu, Wentao Xu</strong></p>
<p>Recent advances in Large Language Models (LLMs) have enabled human-like responses across various tasks, raising questions about their ethical decision-making capabilities and potential biases. This study investigates protected attributes in LLMs through systematic evaluation of their responses to ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5 Sonnet - we analyzed their decision-making patterns across multiple protected attributes including age, gender, race, appearance, and disability status. Through 11,200 experimental trials involving both single-factor and two-factor protected attribute combinations, we evaluated the models’ ethical preferences, sensitivity, stability, and clustering of preferences. Our findings reveal significant protected attributeses in both models, with consistent preferences for certain features (e.g., “good-looking”) and systematic neglect of others. Notably, while GPT-3.5 Turbo showed stronger preferences aligned with traditional power structures, Claude 3.5 Sonnet demonstrated more diverse protected attribute choices. We also found that ethical sensitivity significantly decreases in more complex scenarios involving multiple protected attributes. Additionally, linguistic referents heavily influence the models’ ethical evaluations, as demonstrated by differing responses to racial descriptors (e.g., “Yellow” versus “Asian”). These findings highlight critical concerns about the potential impact of LLM biases in autonomous decision-making systems and emphasize the need for careful consideration of protected attributes in AI development. Our study contributes to the growing body of research on AI ethics by providing a systematic framework for evaluating protected attributes in LLMs’ ethical decision-making capabilities. </p>
<blockquote>
<p>最近大型语言模型（LLM）的进步能够在各种任务中生成类似人类的回应，这引发了关于其伦理决策能力和潜在偏见的问题。本研究通过系统评估语言模型在道德困境中的回应，探究其保护属性。我们使用两个突出的模型——GPT-3.5 Turbo和Claude 3.5 Sonnet——分析他们在年龄、性别、种族、外貌和残疾状态等多个保护属性上的决策模式。通过11,200次涉及单因素和两因素保护属性组合的实验，我们评估了模型的伦理偏好、敏感性、稳定性和偏好聚类。我们的研究结果显示两个模型都存在重要的保护属性，对某些特征有持续的偏好（例如，“好看”），系统性地忽略其他特征。值得注意的是，GPT-3.5 Turbo显示出与传统权力结构更一致的偏好，而Claude 3.5 Sonnet则表现出更多样化的保护属性选择。我们还发现，在涉及多个保护属性的更复杂场景中，道德敏感性会显著降低。此外，语言参照物严重影响模型的道德评估，如对不同种族描述符的回应不同（例如，“黄色”与“亚洲”）。这些发现突显了大型语言模型的偏见在自主决策系统中可能产生的潜在影响，并强调在人工智能发展中需要仔细考虑保护属性。本研究为评估大型语言模型在伦理决策能力中的保护属性提供了一个系统框架，为人工智能伦理研究领域的不断增长做出贡献。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10484v2">PDF</a> This paper has been accepted by International AAAI Conference on Web   and Social Media 2026, sunny Los Angeles, California</p>
<p><strong>摘要</strong></p>
<p>近期大型语言模型（LLM）的进步使其能够在各种任务中做出类似人类的响应，引发了关于其伦理决策能力和潜在偏见的的问题。本研究通过系统评估LLM对伦理困境的响应，探究其保护属性。使用GPT-3.5 Turbo和Claude 3.5 Sonnet两个主流模型，我们分析了他们在年龄、性别、种族、外貌和残疾状态等多个保护属性上的决策模式。通过涉及单一因素和两因素保护属性组合的实验，我们评估了模型的伦理偏好、敏感性、稳定性和偏好聚类。我们的研究结果显示两个模型都存在重要的保护属性，对某些特征有持续的偏好（如“好看”），而忽视其他特征。值得注意的是，GPT-3.5 Turbo的偏好更符合传统权力结构，而Claude 3.5 Sonnet的保护属性选择更多样化。我们还发现，在涉及多个保护属性的更复杂的场景中，伦理敏感性会显著降低。此外，语言参照物会影响模型的伦理评价，对种族描述符的反应不同（例如，“黄色”与“亚洲”）。这些发现突显了大型语言模型偏见在自主决策系统中可能产生的影响，并强调在人工智能发展中需要仔细考虑保护属性。本研究为评估LLM伦理决策能力中的保护属性提供了系统框架，为人工智能伦理研究领域的增长做出贡献。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>大型语言模型（LLMs）在伦理决策中显示出潜在偏见和局限。</li>
<li>通过实验评估了LLMs在多个保护属性（如年龄、性别、种族等）上的决策模式。</li>
<li>GPT-3.5 Turbo和Claude 3.5 Sonnet在保护属性上有不同的偏好和敏感性。</li>
<li>在复杂场景中，模型的伦理敏感性降低。</li>
<li>语言参考物对模型的伦理评价具有显著影响，表现出对种族描述符的不同反应。</li>
<li>LLM的潜在偏见可能对自主决策系统产生实际影响。</li>
<li>研究为评估LLMs在伦理决策中的保护属性提供了系统框架。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10484">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-aa8b9da2f9f3f30e9171f0c0e5abfb1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49cbc0ecc3f4e2639d119954af4f8c75.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c4c86e8cd9ec6d28f69ad784455540d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61c26d27b719e0fc0f03e6cf853654c5.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Can-LLMs-assist-with-Ambiguity-A-Quantitative-Evaluation-of-various-Large-Language-Models-on-Word-Sense-Disambiguation"><a href="#Can-LLMs-assist-with-Ambiguity-A-Quantitative-Evaluation-of-various-Large-Language-Models-on-Word-Sense-Disambiguation" class="headerlink" title="Can LLMs assist with Ambiguity? A Quantitative Evaluation of various   Large Language Models on Word Sense Disambiguation"></a>Can LLMs assist with Ambiguity? A Quantitative Evaluation of various   Large Language Models on Word Sense Disambiguation</h2><p><strong>Authors:T. G. D. K. Sumanathilaka, Nicholas Micallef, Julian Hough</strong></p>
<p>Ambiguous words are often found in modern digital communications. Lexical ambiguity challenges traditional Word Sense Disambiguation (WSD) methods, due to limited data. Consequently, the efficiency of translation, information retrieval, and question-answering systems is hindered by these limitations. This study investigates the use of Large Language Models (LLMs) to improve WSD using a novel approach combining a systematic prompt augmentation mechanism with a knowledge base (KB) consisting of different sense interpretations. The proposed method incorporates a human-in-loop approach for prompt augmentation where prompt is supported by Part-of-Speech (POS) tagging, synonyms of ambiguous words, aspect-based sense filtering and few-shot prompting to guide the LLM. By utilizing a few-shot Chain of Thought (COT) prompting-based approach, this work demonstrates a substantial improvement in performance. The evaluation was conducted using FEWS test data and sense tags. This research advances accurate word interpretation in social media and digital communication. </p>
<blockquote>
<p>在现代数字通信中经常可以发现模棱两可的词汇。词汇的歧义给传统的词义消歧（WSD）方法带来了挑战，主要是由于数据有限。因此，翻译、信息检索和问答系统的效率受到了这些限制的阻碍。本研究探讨了使用大型语言模型（LLM）来改善词义消歧的方法，采用了一种结合系统提示增强机制和包含不同词义解释的知识库（KB）的新方法。所提出的方法采用了一种人类循环提示增强方法，提示由词性标注、模糊词同义词、基于方面的词义过滤和少量提示组成，以指导LLM。通过基于少量提示的思考链（COT）提示方法，这项工作在性能上取得了显著改进。评估工作使用了FEWS测试数据和词义标签。该研究推动了社交媒体和数字通信中的准确词汇解释。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18337v4">PDF</a> 12 pages,6 tables, 1 figure, Proceedings of the 1st International   Conference on NLP &amp; AI for Cyber Security</p>
<p><strong>Summary</strong></p>
<p>本摘要基于现代数字通讯中的词汇歧义问题，研究了利用大型语言模型（LLM）结合知识库和一系列策略来改善词义消歧的方法。研究结合了人工辅助的提示增强方法，使用词性标注、同义词、基于方面的意义过滤和少量提示来引导LLM。该研究在FEWS测试数据和词义标签上取得了显著的提升，并推进了社交媒体和数字通讯中的精确词汇解读。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是本段文字中最为重要的七个要点：</p>
<ol>
<li>现代数字通讯中存在词汇歧义问题，对传统词义消歧方法构成挑战。</li>
<li>LLMs被用于改进词义消歧方法。</li>
<li>结合知识库进行系统提示增强机制是一种新方法。</li>
<li>人类参与循环提示增强方法，借助词性标注、同义词等策略引导LLM。</li>
<li>采用少量链式思维（COT）提示为基础的方法显著提高了性能。</li>
<li>研究在FEWS测试数据和词义标签上的评价证明了该方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18337">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-ad3886a2ed9dcbd7c66b7dcd1a190cc8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-770565f58942563b94aaa03ad6dd5e2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6b2d1dd25c8c65295f0bcf388c3611d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2076c8f95119ae476ffbefe14cd878a4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Local-Attention-Mechanism-Boosting-the-Transformer-Architecture-for-Long-Sequence-Time-Series-Forecasting"><a href="#Local-Attention-Mechanism-Boosting-the-Transformer-Architecture-for-Long-Sequence-Time-Series-Forecasting" class="headerlink" title="Local Attention Mechanism: Boosting the Transformer Architecture for   Long-Sequence Time Series Forecasting"></a>Local Attention Mechanism: Boosting the Transformer Architecture for   Long-Sequence Time Series Forecasting</h2><p><strong>Authors:Ignacio Aguilera-Martos, Andrés Herrera-Poyatos, Julián Luengo, Francisco Herrera</strong></p>
<p>Transformers have become the leading choice in natural language processing over other deep learning architectures. This trend has also permeated the field of time series analysis, especially for long-horizon forecasting, showcasing promising results both in performance and running time.   In this paper, we introduce Local Attention Mechanism (LAM), an efficient attention mechanism tailored for time series analysis. This mechanism exploits the continuity properties of time series to reduce the number of attention scores computed. We present an algorithm for implementing LAM in tensor algebra that runs in time and memory O(nlogn), significantly improving upon the O(n^2) time and memory complexity of traditional attention mechanisms. We also note the lack of proper datasets to evaluate long-horizon forecast models. Thus, we propose a novel set of datasets to improve the evaluation of models addressing long-horizon forecasting challenges.   Our experimental analysis demonstrates that the vanilla transformer architecture magnified with LAM surpasses state-of-the-art models, including the vanilla attention mechanism. These results confirm the effectiveness of our approach and highlight a range of future challenges in long-sequence time series forecasting. </p>
<blockquote>
<p>Transformer在自然语言处理领域已成为深度学习架构中的首选。这一趋势也渗透到了时间序列分析领域，特别是在长期预测方面，在性能和运行时间上展现出有前景的结果。在本文中，我们引入了专为时间序列分析定制的高效注意力机制——局部注意力机制（LAM）。该机制利用时间序列的连续性属性来减少计算注意力分数。我们提出了一种在张量代数中实现LAM的算法，其运行时间和内存为O(nlogn)，显著改善了传统注意力机制的O(n^2)时间和内存复杂度。我们还注意到缺乏适当的数据集来评估长期预测模型。因此，我们提出了一个新的数据集，以改善长期预测挑战模型的评估。实验分析表明，通过LAM放大的基本转换器架构超过了最新模型，包括基本注意力机制。这些结果证实了我们的方法的有效性，并突出了长期序列时间序列预测的一系列未来挑战。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.03805v3">PDF</a> </p>
<p><strong>Summary</strong><br>     本文介绍了针对时间序列分析的高效注意力机制——局部注意力机制（LAM）。该机制利用时间序列的连续性属性减少计算注意力分数数量，在时间和内存复杂度上实现O(nlogn)的优化，优于传统注意力机制的O(n^2)。此外，文章提出了一系列新的数据集，以改善对长期视野预测挑战模型的评估。实验分析表明，配备LAM的变压器架构超过了包括普通注意力机制在内的最先进的模型，证实了该方法的有效性，并指出了长期序列时间序列预测的一系列未来挑战。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>变压器已成为自然语言处理中的主导深度学习架构，并在时间序列分析领域展现出优势。</li>
<li>局部注意力机制（LAM）是一种针对时间序列分析的高效注意力机制。</li>
<li>LAM利用时间序列的连续性属性减少注意力分数计算数量。</li>
<li>LAM在时间和内存复杂度上实现O(nlogn)的优化。</li>
<li>当前缺乏适当的数据集来评估长期视野预测模型。</li>
<li>文章提出了一系列新的数据集，以改善对长期视野预测模型的评估。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.03805">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-392d93bae10ee3097e00f3d2d4765431.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2358e2ff9f0e95d99b375a7392e6fadb.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Neutral-Residues-Revisiting-Adapters-for-Model-Extension"><a href="#Neutral-Residues-Revisiting-Adapters-for-Model-Extension" class="headerlink" title="Neutral Residues: Revisiting Adapters for Model Extension"></a>Neutral Residues: Revisiting Adapters for Model Extension</h2><p><strong>Authors:Franck Signe Talla, Edouard Grave, Hervé Jégou</strong></p>
<p>We address the problem of extending a pretrained large language model to a new domain that was not seen during training. Standard techniques, such as finetuning or low-rank adaptation (LoRA) are successful at domain adaptation, but do not formally add capacity to the model. This often leads to a trade-off, between performing well on the new domain vs. degrading performance on the original domain. Here, we revisit and improve adapters to extend LLMs from three angles: data, architecture and training procedure, which are advantageously considered jointly. The resulting method, called neutral residues, modifies adapters in a way that leads each new residual block to output near-zeros on the original domain. This solution leads to strong results when adapting a state-of-the-art model originally trained on English to a new language. Neutral residues significantly outperform competing approaches such as finetuning, LoRA or vanilla adapters in terms of the trade-off between learning the new language and not forgetting English. </p>
<blockquote>
<p>我们解决将预训练的通用大型语言模型扩展到未见过的全新领域的问题。虽然微调或低秩适应（LoRA）等标准技术在领域适应方面很成功，但它们并没有正式增加模型的容量。这经常导致在新的领域表现良好与在原始领域性能下降之间的权衡。在这里，我们从数据、架构和训练程序三个角度重新审视和改进了适配器，以扩展大型语言模型，这三个方面的联合考虑具有优势。由此产生的方法称为中性残留物，它以这样的方式修改适配器，使得每个新的残差块在原始领域上输出接近零。当将一个最先在英语上训练的先进模型适应到一种新语言时，这种解决方案取得了很好的效果。中性残留物在学习新语言的同时，且在避免遗忘英语方面明显优于其他方法，如微调、LoRA或普通适配器之间的权衡取舍。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.02744v3">PDF</a> Accepted at ICML 2025</p>
<p><strong>摘要</strong></p>
<p>本文解决将预训练的大型语言模型扩展到未见过的新领域的问题。虽然微调或低秩适应（LoRA）等标准技术在领域适应方面是成功的，但它们并没有正式增加模型的容量。这常常导致在新的领域表现良好与保持原有领域性能之间的权衡。本文重新审视和改进了从数据、架构和训练过程三个角度扩展LLM的适配器。我们提出的方法称为中性残基，它通过修改适配器的方式，使每个新的残差块在原始域上输出接近零的值。当将一个先进的模型从英语适应到新的语言时，中性残基显著优于微调、LoRA或普通适配器等方法，在学习新语言的同时不会忘记英语。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>本文解决了将预训练的大型语言模型适应到未见过的领域的问题。</li>
<li>现有的技术如微调或低秩适应虽在领域适应上有效，但缺乏对模型容量的正式增加。</li>
<li>提出了一种新的方法——中性残基，通过改进适配器，使新残差块在原始域上输出接近零的值。</li>
<li>中性残基在适应先进模型到新的语言时表现出强大的性能。</li>
<li>中性残基在保持原有领域性能的同时，能更好地适应新领域。</li>
<li>中性残基显著优于其他方法，如微调、LoRA或普通适配器。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.02744">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-07050531b8b7db913048a8a11b85bcdd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-80a8464dab5cb86d8f96b37ffca3cf84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-470cf36192ff469ec4f3cc0c6ae544af.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2666411ef403efd4abb3ec31f0a3b6bb.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Comparison-of-pipeline-sequence-to-sequence-and-GPT-models-for-end-to-end-relation-extraction-experiments-with-the-rare-disease-use-case"><a href="#Comparison-of-pipeline-sequence-to-sequence-and-GPT-models-for-end-to-end-relation-extraction-experiments-with-the-rare-disease-use-case" class="headerlink" title="Comparison of pipeline, sequence-to-sequence, and GPT models for   end-to-end relation extraction: experiments with the rare disease use-case"></a>Comparison of pipeline, sequence-to-sequence, and GPT models for   end-to-end relation extraction: experiments with the rare disease use-case</h2><p><strong>Authors:Shashank Gupta, Xuguang Ai, Ramakanth Kavuluru</strong></p>
<p>End-to-end relation extraction (E2ERE) is an important and realistic application of natural language processing (NLP) in biomedicine. In this paper, we aim to compare three prevailing paradigms for E2ERE using a complex dataset focused on rare diseases involving discontinuous and nested entities. We use the RareDis information extraction dataset to evaluate three competing approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to sequence models, and generative pre-trained transformer (GPT) models. We use comparable state-of-the-art models and best practices for each of these approaches and conduct error analyses to assess their failure modes. Our findings reveal that pipeline models are still the best, while sequence-to-sequence models are not far behind; GPT models with eight times as many parameters are worse than even sequence-to-sequence models and lose to pipeline models by over 10 F1 points. Partial matches and discontinuous entities caused many NER errors contributing to lower overall E2E performances. We also verify these findings on a second E2ERE dataset for chemical-protein interactions. Although generative LM-based methods are more suitable for zero-shot settings, when training data is available, our results show that it is better to work with more conventional models trained and tailored for E2ERE. More innovative methods are needed to marry the best of the both worlds from smaller encoder-decoder pipeline models and the larger GPT models to improve E2ERE. As of now, we see that well designed pipeline models offer substantial performance gains at a lower cost and carbon footprint for E2ERE. Our contribution is also the first to conduct E2ERE for the RareDis dataset. </p>
<blockquote>
<p>端到端关系抽取（E2ERE）是生物医学自然语言处理（NLP）的重要且现实应用。本文旨在使用专注于涉及不连续和嵌套实体的罕见疾病的复杂数据集，比较E2ERE的三种流行范式。我们使用RareDis信息提取数据集来评估三种竞争方法（用于E2ERE）：NER→RE管道、联合序列到序列模型和预训练生成式变压器（GPT）模型。我们使用每种方法的可比的最先进模型和最佳实践，并进行误差分析以评估其失败模式。我们的研究发现，管道模型仍然是最好的，而序列到序列模型紧随其后；GPT模型的参数是序列到序列模型的八倍，但表现却更差，与管道模型的F1分数相差超过10个点。部分匹配和不连续的实体导致了许多NER错误，从而降低了整体的E2E性能。我们还通过第二个用于化学蛋白质相互作用的E2ERE数据集验证了这些发现。尽管基于生成的语言模型（LM）的方法更适合零样本设置，但当训练数据可用时，我们的结果表明，使用针对E2ERE进行培训和定制的更传统模型效果更好。需要更创新的方法将较小的编码器-解码器管道模型和较大的GPT模型的优点结合起来，以提高E2ERE的效果。到目前为止，我们可以看到，精心设计的管道模型在较低的成本和碳足迹下为E2ERE提供了巨大的性能提升。我们的贡献也是首次对RareDis数据集进行E2ERE研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.13729v3">PDF</a> An updated version of this paper has appeared in the proceedings of   NLDB 2025 with a different title. The corresonding DOI is in the metadata   provided below</p>
<p><strong>摘要</strong></p>
<p>本文对比了三种主流的在生物医学领域的端对端关系抽取（E2ERE）范式，使用复杂数据集专注于涉及不连续和嵌套实体的罕见疾病。通过RareDis信息提取数据集评估了NER→RE管道、联合序列到序列模型和生成式预训练转换器（GPT）模型。研究发现，管道模型仍然是最佳模型，序列到序列模型表现也不错；GPT模型参数多八倍但表现较差，与管道模型相差超过十分之一个F1点。部分匹配和不连续实体导致许多NER错误，影响整体E2E性能。同时，在第二份关于化学蛋白质相互作用的E2ERE数据集上验证了这些发现。尽管生成式LM方法更适合零样本设置，但当训练数据可用时，最好是使用针对E2ERE设计并训练的更常规模型。目前，精心设计的小型编码器-解码器管道模型性能卓越且成本低廉、碳足迹较小。此外，本文首次针对罕见疾病的E2ERE为数据集进行探究分析，为未来的研究提供了有价值的参考。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>端对端关系抽取（E2ERE）是生物医学自然语言处理（NLP）的重要实际应用。</li>
<li>使用复杂的罕见疾病数据集进行了比较研究，发现NER→RE管道模型仍是最佳选项。</li>
<li>序列到序列模型表现不俗，但参数庞大的GPT模型性能不佳。管道模型的性能高出超过十分之一个F1点。</li>
<li>部分匹配和不连续实体影响关系抽取模型的性能表现，这在抽取时构成很多NER错误。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2311.13729">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d69bb85bfb9d13ac218ebdc35165978c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e4cbdad1e8012bd69afc8c3eb56d429.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-47f105c5bda58fd730dc45d5e421979a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bce83254650f438db15359ee6816e50c.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-04/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-04/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-04/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-119000b54380062648311e542c5c54f0.jpg" class="responsive-img" alt="检测/分割/跟踪">
                        
                        <span class="card-title">检测/分割/跟踪</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            检测/分割/跟踪 方向最新论文已更新，请持续关注 Update in 2025-08-04  ZS-VCOS Zero-Shot Video Camouflaged Object Segmentation By Optical Flow   and Open Vocabulary Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    检测/分割/跟踪
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">检测/分割/跟踪</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-04/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-28cf34600faaa38049e50db9297885ea.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning 方向最新论文已更新，请持续关注 Update in 2025-08-04  Trustworthy Reasoning Evaluating and Enhancing Factual Accuracy in LLM   Intermediate Thought Processes
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
