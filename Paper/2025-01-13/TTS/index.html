<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS 方向最新论文已更新，请持续关注 Update in 2025-01-14  Low-Resource Text-to-Speech Synthesis Using Noise-Augmented Training of   ForwardTacotron">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-a5dd8467341555d03e377166d4f53cfd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-01-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    26 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-14-更新"><a href="#2025-01-14-更新" class="headerlink" title="2025-01-14 更新"></a>2025-01-14 更新</h1><h2 id="Low-Resource-Text-to-Speech-Synthesis-Using-Noise-Augmented-Training-of-ForwardTacotron"><a href="#Low-Resource-Text-to-Speech-Synthesis-Using-Noise-Augmented-Training-of-ForwardTacotron" class="headerlink" title="Low-Resource Text-to-Speech Synthesis Using Noise-Augmented Training of   ForwardTacotron"></a>Low-Resource Text-to-Speech Synthesis Using Noise-Augmented Training of   ForwardTacotron</h2><p><strong>Authors:Kishor Kayyar Lakshminarayana, Frank Zalkow, Christian Dittmar, Nicola Pia, Emanuel A. P. Habets</strong></p>
<p>In recent years, several text-to-speech systems have been proposed to synthesize natural speech in zero-shot, few-shot, and low-resource scenarios. However, these methods typically require training with data from many different speakers. The speech quality across the speaker set typically is diverse and imposes an upper limit on the quality achievable for the low-resource speaker. In the current work, we achieve high-quality speech synthesis using as little as five minutes of speech from the desired speaker by augmenting the low-resource speaker data with noise and employing multiple sampling techniques during training. Our method requires only four high-quality, high-resource speakers, which are easy to obtain and use in practice. Our low-complexity method achieves improved speaker similarity compared to the state-of-the-art zero-shot method HierSpeech++ and the recent low-resource method AdapterMix while maintaining comparable naturalness. Our proposed approach can also reduce the data requirements for speech synthesis for new speakers and languages. </p>
<blockquote>
<p>近年来，已经提出了多种文本到语音系统，用于在零样本、小样例和低资源场景中合成自然语音。然而，这些方法通常需要与许多不同说话人的数据进行训练。不同说话人的语音质量各不相同，并对低资源说话人可达到的质量设置了上限。在当前工作中，我们通过使用目标说话人的五分钟语音进行扩充和低资源说话人数据的噪声处理，以及采用多重采样技术进行训练，实现了高质量的语音合成。我们的方法只需要四个高质量、高资源的说话人，这在实践中很容易获得和使用。我们的低复杂度方法在提高说话人相似度方面优于最新的零样本方法HierSpeech++和最近的低资源方法AdapterMix，同时保持了相当的自然度。我们提出的方法还可以减少新说话人和新语言进行语音合成所需的数据要求。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05976v1">PDF</a> Accepted for publication at the 2025 IEEE International Conference on   Acoustics, Speech, and Signal Processing (ICASSP 2025) to be held at   Hyderabad, India</p>
<p><strong>Summary</strong><br>新一代文本转语音系统通过增强低资源说话者数据并引入多种采样技术，实现了高质量语音合成，仅需五分钟说话者语音数据即可实现高质量合成。此方法仅需四个高质量、高资源说话者，易于在实际中获得和使用。相较于当前最前沿的零样本方法（如 HierSpeech++）和低资源方法（如 AdapterMix），此方法在提高说话者相似性的同时保持了自然度。此外，该方法还降低了新说话者和新语言对语音合成所需的数据要求。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种新颖的文本转语音系统，用于在零样本、少样本和低资源场景下合成自然语音。</li>
<li>该方法通过使用少量的说话者语音数据（仅需五分钟）实现了高质量语音合成。</li>
<li>通过增强低资源说话者数据和引入多种采样技术，提高了语音合成的质量。</li>
<li>该方法仅需四个高质量、高资源的说话者，易于获取并应用于实际场景中。</li>
<li>与当前最前沿的零样本和低资源方法相比，该方法在维持自然度的同时，提高了说话者相似性。</li>
<li>该方法降低了新说话者和新语言对语音合成所需的数据要求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05976">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8627bb3acb34ae21e0051676b4a63d76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5cdc86350e7df716c4eef9db8fb102d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b276c7df10d0c0ff301145f43106594.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5dea2c4271cb0ac387f48852700a8b93.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MARS6-A-Small-and-Robust-Hierarchical-Codec-Text-to-Speech-Model"><a href="#MARS6-A-Small-and-Robust-Hierarchical-Codec-Text-to-Speech-Model" class="headerlink" title="MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model"></a>MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model</h2><p><strong>Authors:Matthew Baas, Pieter Scholtz, Arnav Mehta, Elliott Dyson, Akshat Prakash, Herman Kamper</strong></p>
<p>Codec-based text-to-speech (TTS) models have shown impressive quality with zero-shot voice cloning abilities. However, they often struggle with more expressive references or complex text inputs. We present MARS6, a robust encoder-decoder transformer for rapid, expressive TTS. MARS6 is built on recent improvements in spoken language modelling. Utilizing a hierarchical setup for its decoder, new speech tokens are processed at a rate of only 12 Hz, enabling efficient modelling of long-form text while retaining reconstruction quality. We combine several recent training and inference techniques to reduce repetitive generation and improve output stability and quality. This enables the 70M-parameter MARS6 to achieve similar performance to models many times larger. We show this in objective and subjective evaluations, comparing TTS output quality and reference speaker cloning ability. Project page: <a target="_blank" rel="noopener" href="https://camb-ai.github.io/mars6-turbo/">https://camb-ai.github.io/mars6-turbo/</a> </p>
<blockquote>
<p>基于编码器的文本到语音（TTS）模型已经表现出了令人印象深刻的零射击声克隆能力。然而，它们在处理更具表现力的参考或复杂的文本输入时经常遇到困难。我们推出了MARS6，这是一个强大的编码器-解码器转换器，用于快速、富有表现力的TTS。MARS6是建立在口语建模的最新改进基础上的。其解码器采用分层设置，新的语音标记符的处理速度仅为12Hz，能够在保留重建质量的同时，对长文本进行有效建模。我们结合了最近的训练和推理技术，以减少重复生成，提高输出稳定性和质量。这使得7000万的MARS6参数能够实现与许多更大模型的相似性能。我们在客观和主观评估中都展示了这一点，比较了TTS输出质量和参考说话人的克隆能力。项目页面：<a target="_blank" rel="noopener" href="https://camb-ai.github.io/mars6-turbo/">https://camb-ai.github.io/mars6-turbo/</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05787v1">PDF</a> 5 pages, 2 figures, 1 table. Accepted at ICASSP 2025</p>
<p><strong>摘要</strong></p>
<p>基于编码器的文本到语音（TTS）模型具有令人印象深刻的零声母克隆能力，但对于更生动的参考或复杂的文本输入往往表现挣扎。我们推出MARS6，一个稳健的编码器-解码器转换器，用于快速、生动的TTS。MARS6建立在最新的口语建模改进之上。其解码器采用分层设置，新的语音令牌处理速率仅为12Hz，可在保留重建质量的同时，对长文本进行有效建模。我们结合了最新的训练和推理技术，以减少重复生成，提高输出稳定性和质量。这使得7000万参数的MARS6能够达到比许多更大模型的相似性能。我们在客观和主观评估中展示了这一点，比较了TTS输出质量和参考说话人的克隆能力。</p>
<p><strong>要点</strong></p>
<ol>
<li>MARS6是一个用于快速、生动TTS的稳健编码器-解码器转换器。</li>
<li>MARS6建立在最新的口语建模改进之上，具有出色的文本到语音转换能力。</li>
<li>采用分层解码器设置，处理新语音令牌的速度快，仅为12Hz。</li>
<li>MARS6可以有效地对长文本进行建模，同时保留重建质量。</li>
<li>通过结合最新的训练和推理技术，MARS6减少了重复生成，提高了输出稳定性和质量。</li>
<li>MARS6的参数为70M，性能与许多更大的模型相当。</li>
<li>在客观和主观评估中，MARS6在TTS输出质量和参考说话人克隆能力方面表现出色。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05787">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3a4655509aa9dc7105c11b939898b023.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e622c11d9344550769b5e33af8668d6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7fbe2800140a24b85a9d3c14c6dc6021.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="JELLY-Joint-Emotion-Recognition-and-Context-Reasoning-with-LLMs-for-Conversational-Speech-Synthesis"><a href="#JELLY-Joint-Emotion-Recognition-and-Context-Reasoning-with-LLMs-for-Conversational-Speech-Synthesis" class="headerlink" title="JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for   Conversational Speech Synthesis"></a>JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for   Conversational Speech Synthesis</h2><p><strong>Authors:Jun-Hyeok Cha, Seung-Bin Kim, Hyung-Seok Oh, Seong-Whan Lee</strong></p>
<p>Recently, there has been a growing demand for conversational speech synthesis (CSS) that generates more natural speech by considering the conversational context. To address this, we introduce JELLY, a novel CSS framework that integrates emotion recognition and context reasoning for generating appropriate speech in conversation by fine-tuning a large language model (LLM) with multiple partial LoRA modules. We propose an Emotion-aware Q-former encoder, which enables the LLM to perceive emotions in speech. The encoder is trained to align speech emotions with text, utilizing datasets of emotional speech. The entire model is then fine-tuned with conversational speech data to infer emotional context for generating emotionally appropriate speech in conversation. Our experimental results demonstrate that JELLY excels in emotional context modeling, synthesizing speech that naturally aligns with conversation, while mitigating the scarcity of emotional conversational speech datasets. </p>
<blockquote>
<p>最近，对话式语音合成（CSS）的需求不断增长，它能够通过考虑对话上下文来生成更自然的语音。为了解决这一问题，我们引入了JELLY，这是一个新型的CSS框架，通过微调大型语言模型（LLM）并集成多个局部LoRA模块，来生成对话中适当的语音。我们提出了一种情感感知的Q-former编码器，使LLM能够感知语音中的情感。该编码器经过训练，能够将语音情感与文本对齐，利用情感语音数据集。然后对整个模型进行对话语音数据的微调，以推断情感上下文，从而在对话中生成情感上适当的语音。我们的实验结果表明，JELLY在情感上下文建模方面表现出色，能够合成与对话自然对齐的语音，同时缓解了情感对话语音数据集稀缺的问题。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04904v1">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>近期对话式语音合成（CSS）需求增长，需生成更自然的语音并考虑对话上下文。为此，我们引入了JELLY这一新型CSS框架，它集成了情感识别和上下文推理，通过微调大型语言模型（LLM）和多个部分LoRA模块来生成适当的对话语音。我们提出了情感感知Q-former编码器，使LLM能够感知语音中的情感。编码器经过训练，能够将语音情感与文本对齐，利用情感语音数据集。整个模型进一步用对话语音数据进行微调，以推断情感上下文，生成与对话自然对齐的语音。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>JELLY是一个新型对话式语音合成（CSS）框架，旨在生成更自然的语音。</li>
<li>它通过集成情感识别和上下文推理来适应对话上下文。</li>
<li>JELLY使用大型语言模型（LLM）并微调多个部分LoRA模块来实现这一目标。</li>
<li>提出了一种情感感知Q-former编码器，使LLM能够感知语音中的情感。</li>
<li>编码器利用情感语音数据集进行训练，实现语音情感与文本的对齐。</li>
<li>整个模型通过对话语音数据进一步微调，以推断情感上下文。</li>
<li>实验结果表明，JELLY在情感上下文建模方面表现出色，能够合成与对话自然对齐的语音，并缓解了情感对话语音数据集稀缺的问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04904">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a5dd8467341555d03e377166d4f53cfd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-505768a7af8b9a4f17eba5b2df8da603.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f0a7b437f5523ad6388d50483a3e85f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-314c4671b2d44201482c293b8593039e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OpenOmni-Large-Language-Models-Pivot-Zero-shot-Omnimodal-Alignment-across-Language-with-Real-time-Self-Aware-Emotional-Speech-Synthesis"><a href="#OpenOmni-Large-Language-Models-Pivot-Zero-shot-Omnimodal-Alignment-across-Language-with-Real-time-Self-Aware-Emotional-Speech-Synthesis" class="headerlink" title="OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment   across Language with Real-time Self-Aware Emotional Speech Synthesis"></a>OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment   across Language with Real-time Self-Aware Emotional Speech Synthesis</h2><p><strong>Authors:Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen, Jiaming Li, Lei Zhang, Yangyi Chen, Hamid Alinejad-Rokny, Fei Huang</strong></p>
<p>Recent advancements in omnimodal learning have been achieved in understanding and generation across images, text, and speech, though mainly within proprietary models. Limited omnimodal datasets and the inherent challenges associated with real-time emotional speech generation have hindered open-source progress. To address these issues, we propose openomni, a two-stage training method combining omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model. In the alignment phase, a pre-trained speech model is further trained on text-image tasks to generalize from vision to speech in a (near) zero-shot manner, outperforming models trained on tri-modal datasets. In the speech generation phase, a lightweight decoder facilitates real-time emotional speech through training on speech tasks and preference learning. Experiments demonstrate that openomni consistently improves across omnimodal, vision-language, and speech-language evaluations, enabling natural, emotion-rich dialogues and real-time emotional speech generation. </p>
<blockquote>
<p>近期多模态学习在图像、文本和语音的理解和生成方面取得了进展，但主要局限于专有模型内部。有限的多模态数据集和实时情感语音生成所固有的挑战阻碍了开源进度。为了解决这些问题，我们提出了openomni，这是一种结合多模态对齐和语音生成的两阶段训练方法，以开发先进的多模态大型语言模型。在对齐阶段，预训练的语音模型进一步在文本图像任务上进行训练，以（接近）零样本的方式从视觉到语音进行推广，超越了那些在三元模态数据集上训练的模型。在语音生成阶段，一个轻量级的解码器通过语音任务和偏好学习进行训练，促进实时情感语音的产生。实验表明，openomni在多模态、视觉语言和语音语言评估中持续改进，可实现自然、情感丰富的对话和实时情感语音生成。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04561v2">PDF</a> </p>
<p><strong>Summary</strong><br>    开放omnimodal大型语言模型的研究取得进展，提出名为openomni的两阶段训练方法，通过omnimodal对齐和语音生成，实现跨图像、文本和语音的理解与生成。对齐阶段预训练语音模型在文本图像任务上进行进一步训练，以在零样本或接近零样本情况下从视觉到语音进行推广，表现出优于在三模态数据集上训练模型的效果。在语音生成阶段，使用轻量级解码器通过语音任务和偏好学习进行训练，实现实时情感语音生成。实验证明openomni在omnimodal、视觉语言和语音语言评估中表现优异，可实现自然、情感丰富的对话和实时情感语音生成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>openomni是一种创新的双阶段训练方法，专注于Omnimodal大型语言模型的训练。</li>
<li>对齐阶段是预训练语音模型在文本图像任务上的进一步训练，实现视觉到语音的推广。</li>
<li>openomni能够在零样本或接近零样本情况下表现优异，优于在三模态数据集上训练的模型。</li>
<li>语音生成阶段使用轻量级解码器进行实时情感语音生成。</li>
<li>openomni支持实时情感语音生成和自然、情感丰富的对话。</li>
<li>实验证明openomni在多个评估中表现优异，包括omnimodal、视觉语言和语音语言评估。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04561">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0324a32d60d3153e3b5176d6bde9ea35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5c2084f80afa2ea596383ba629e585b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-305abf61800caf355fc1caae410cc70e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d31f7a3bcd73d4ef46049763ff3ce337.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MacST-Multi-Accent-Speech-Synthesis-via-Text-Transliteration-for-Accent-Conversion"><a href="#MacST-Multi-Accent-Speech-Synthesis-via-Text-Transliteration-for-Accent-Conversion" class="headerlink" title="MacST: Multi-Accent Speech Synthesis via Text Transliteration for Accent   Conversion"></a>MacST: Multi-Accent Speech Synthesis via Text Transliteration for Accent   Conversion</h2><p><strong>Authors:Sho Inoue, Shuai Wang, Wanxing Wang, Pengcheng Zhu, Mengxiao Bi, Haizhou Li</strong></p>
<p>In accented voice conversion or accent conversion, we seek to convert the accent in speech from one another while preserving speaker identity and semantic content. In this study, we formulate a novel method for creating multi-accented speech samples, thus pairs of accented speech samples by the same speaker, through text transliteration for training accent conversion systems. We begin by generating transliterated text with Large Language Models (LLMs), which is then fed into multilingual TTS models to synthesize accented English speech. As a reference system, we built a sequence-to-sequence model on the synthetic parallel corpus for accent conversion. We validated the proposed method for both native and non-native English speakers. Subjective and objective evaluations further validate our dataset’s effectiveness in accent conversion studies. </p>
<blockquote>
<p>在口音转换或口音转换中，我们旨在将语音中的口音进行转换，同时保留说话者的身份和语义内容。在这项研究中，我们提出了一种创建多口音语音样本的新方法，因此通过文本音译来训练口音转换系统，从而形成同一说话人的带口音语音样本对。我们首先使用大型语言模型（LLM）生成音译文本，然后将其输入多语种语音合成（TTS）模型以合成带口音的英语语音。作为参考系统，我们在合成平行语料库上建立了序列到序列的模型进行口音转换。我们对英语母语和非母语人士都验证了所提出的方法。主观和客观评估进一步验证了我们的数据集在口音转换研究中的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09352v2">PDF</a> This is accepted to IEEE ICASSP 2025; Project page with Speech Demo:   <a target="_blank" rel="noopener" href="https://github.com/shinshoji01/MacST-project-page">https://github.com/shinshoji01/MacST-project-page</a></p>
<p><strong>总结</strong></p>
<p>在带有口音的语音转换或口音转换中，我们致力于将语音中的口音进行转换，同时保持说话人的身份和语义内容不变。本研究提出了一种新颖的方法，通过文本转译生成带有多种口音的语音样本对，用于训练口音转换系统。我们利用大型语言模型生成转译文本，然后将其输入多语种文本转语音模型，合成带有口音的英语语音。作为参考系统，我们在合成平行语料库上建立了序列到序列的模型进行口音转换。我们对英语母语和非母语人士都验证了所提出的方法。主观和客观评估进一步验证了我们的数据集在口音转换研究中的有效性。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>研究旨在实现口音转换，同时保持说话人的身份和语义内容不变。</li>
<li>提出了一种基于文本转译生成带有多种口音的语音样本对的新方法。</li>
<li>利用大型语言模型生成转译文本，并输入多语种文本转语音模型进行语音合成。</li>
<li>建立了序列到序列的模型作为参考系统，用于口音转换研究。</li>
<li>方法适用于英语母语和非母语人士。</li>
<li>主观和客观评估验证了数据集在口音转换研究中的有效性。</li>
<li>此方法为未来口音转换系统的训练和发展提供了新的思路和方向。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09352">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bda998ee7c6539ce6d05781d2e0e4d1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-081b421c361ba539819a9c6ba2a70296.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-255fe0b982a65b5a7f38cd3d865e82da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fbf0627b83804e6fad6f45ab6436e4d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78b865ce5c3ba31b1c0a8168716a2d00.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="AccentBox-Towards-High-Fidelity-Zero-Shot-Accent-Generation"><a href="#AccentBox-Towards-High-Fidelity-Zero-Shot-Accent-Generation" class="headerlink" title="AccentBox: Towards High-Fidelity Zero-Shot Accent Generation"></a>AccentBox: Towards High-Fidelity Zero-Shot Accent Generation</h2><p><strong>Authors:Jinzuomu Zhong, Korin Richmond, Zhiba Su, Siqi Sun</strong></p>
<p>While recent Zero-Shot Text-to-Speech (ZS-TTS) models have achieved high naturalness and speaker similarity, they fall short in accent fidelity and control. To address this issue, we propose zero-shot accent generation that unifies Foreign Accent Conversion (FAC), accented TTS, and ZS-TTS, with a novel two-stage pipeline. In the first stage, we achieve state-of-the-art (SOTA) on Accent Identification (AID) with 0.56 f1 score on unseen speakers. In the second stage, we condition a ZS-TTS system on the pretrained speaker-agnostic accent embeddings extracted by the AID model. The proposed system achieves higher accent fidelity on inherent&#x2F;cross accent generation, and enables unseen accent generation. </p>
<blockquote>
<p>尽管最近的零样本文本到语音（ZS-TTS）模型在自然性和说话人相似性方面取得了很高的成就，但在口音的保真度和控制方面还存在不足。为了解决这一问题，我们提出了零样本口音生成，将外语口音转换（FAC）、带口音的TTS和ZS-TTS统一起来，采用新型的两阶段流程。在第一阶段，我们在未见过的说话人上实现了最先进的口音识别（AID），F1分数为0.56。在第二阶段，我们以由AID模型提取的预训练说话人无关口音嵌入为条件，对ZS-TTS系统进行调节。所提系统在固有&#x2F;交叉口音生成方面实现了更高的口音保真度，并实现了未见口音的生成。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09098v2">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>近期虽然零样本文本转语音（ZS-TTS）模型在自然度和说话人相似性方面取得了很高的成就，但在口音的保真和控制方面仍存在不足。为解决这一问题，我们提出了零样本口音生成方法，统一了外籍口音转换（FAC）、带口音的TTS和ZS-TTS，采用新型两阶段流程。第一阶段，我们在未见过的说话人上实现了最先进的口音识别（AID）0.56 f1分数。第二阶段，我们以由AID模型提取的预训练说话人无关口音嵌入为条件，对ZS-TTS系统进行调节。所提出系统在生成内在&#x2F;交叉口音方面实现了更高的口音保真度，并能生成未见过的口音。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>零样本文本转语音（ZS-TTS）模型在口音的保真和控制方面存在挑战。</li>
<li>提出一种零样本口音生成方法，整合外籍口音转换（FAC）、带口音的TTS和ZS-TTS。</li>
<li>采用两阶段流程实现：第一阶段实现先进的口音识别（AID）。</li>
<li>第二阶段以由AID模型提取的预训练说话人无关口音嵌入为条件，调节ZS-TTS系统。</li>
<li>所提出系统在生成内在和交叉口音方面表现优异。</li>
<li>系统能够实现未见过的口音生成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09098">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-cb6876b1af86887d27bea8ba41f66cb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8047016a676ff64896d3500d6a88cb5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce8bde694034e76c2d87b8ffc93f1d1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88987e1f89e9d814e60f6980b03bb4a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be5108ea843559008ce1ebac4b83e0d3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-058672032f9057e6673dc755261b94b6.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Spatz-Clustering-Compact-RISC-V-Based-Vector-Units-to-Maximize-Computing-Efficiency"><a href="#Spatz-Clustering-Compact-RISC-V-Based-Vector-Units-to-Maximize-Computing-Efficiency" class="headerlink" title="Spatz: Clustering Compact RISC-V-Based Vector Units to Maximize   Computing Efficiency"></a>Spatz: Clustering Compact RISC-V-Based Vector Units to Maximize   Computing Efficiency</h2><p><strong>Authors:Matteo Perotti, Samuel Riedel, Matheus Cavalcante, Luca Benini</strong></p>
<p>The ever-increasing computational and storage requirements of modern applications and the slowdown of technology scaling pose major challenges to designing and implementing efficient computer architectures. To mitigate the bottlenecks of typical processor-based architectures on both the instruction and data sides of the memory, we present Spatz, a compact 64-bit floating-point-capable vector processor based on RISC-V’s Vector Extension Zve64d. Using Spatz as the main Processing Element (PE), we design an open-source dual-core vector processor architecture based on a modular and scalable cluster sharing a Scratchpad Memory (SCM). Unlike typical vector processors, whose Vector Register Files (VRFs) are hundreds of KiB large, we prove that Spatz can achieve peak energy efficiency with a latch-based VRF of only 2 KiB. An implementation of the Spatz-based cluster in GlobalFoundries’ 12LPP process with eight double-precision Floating Point Units (FPUs) achieves an FPU utilization just 3.4% lower than the ideal upper bound on a double-precision, floating-point matrix multiplication. The cluster reaches 7.7 FMA&#x2F;cycle, corresponding to 15.7 DP-GFLOPS and 95.7 DP-GFLOPS&#x2F;W at 1 GHz and nominal operating conditions (TT, 0.80V, 25C), with more than 55% of the power spent on the FPUs. Furthermore, the optimally-balanced Spatz-based cluster reaches a 95.0% FPU utilization (7.6 FMA&#x2F;cycle), 15.2 DP-GFLOPS, and 99.3 DP-GFLOPS&#x2F;W (61% of the power spent in the FPU) on a 2D workload with a 7x7 kernel, resulting in an outstanding area&#x2F;energy efficiency of 171 DP-GFLOPS&#x2F;W&#x2F;mm2. At equi-area, the computing cluster built upon compact vector processors reaches a 30% higher energy efficiency than a cluster with the same FPU count built upon scalar cores specialized for stream-based floating-point computation. </p>
<blockquote>
<p>随着现代应用程序计算与存储需求的日益增长以及技术规模缩减带来的放缓，设计并实现高效的计算机架构面临巨大挑战。为了缓解基于典型处理器的架构在内存指令和数据方面的瓶颈，我们推出了Spatz，这是一款基于RISC-V的向量扩展Zve64d的紧凑型64位浮点向量处理器。以Spatz为主要处理单元（PE），我们设计了一种基于模块化且可伸缩集群的开源双核向量处理器架构，该架构共享一个Scratchpad Memory（SCM）。不同于通常的向量处理器，其向量寄存器文件（VRF）通常有几百千字节大，我们证明Spatz仅使用基于锁定的VRF即可实现峰值能效，其大小仅为2KiB。使用GlobalFoundries的12LPP工艺实现的Spatz集群包含八个双精度浮点单元（FPU），其FPU利用率比双精度浮点矩阵乘法理想的上限仅低3.4%。该集群达到每秒执行浮点矩阵乘法运算7.7次（相当于在每秒条件下运行速度为每秒亿级双精度浮点数（GFLOPS）），消耗功率下可得到每瓦百万次双精度浮点数操作（DP-GFLOPS&#x2F;W）为95.7的指标值，其中超过55%的功率消耗在FPU上。此外，最优平衡的Spatz集群在处理二维工作负载（具有7x7内核）时，其FPU利用率达到95%（每秒执行浮点矩阵乘法运算7.6次），具有出色的每瓦性能值高达每秒千万次双精度浮点操作数（DP-GFLOPS&#x2F;W）以及极高的能效性能密度值高达每平方毫米每秒亿级双精度浮点数操作数（DP-GFLOPS&#x2F;W&#x2F;mm²）高达数百单位或接近更大的能力在相同面积下，基于紧凑向量处理器的计算集群比基于专门用于流式浮点计算的标量处理器的集群能效高出约百分之三十。这将为未来的计算机架构设计提供新的视角和解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.10137v2">PDF</a> To be published in “IEEE Transactions on Computer-Aided Design of   Integrated Circuits and Systems”</p>
<p><strong>Summary</strong><br>     现代应用对计算和存储需求的不断增长以及技术缩微速度的放缓，给设计高效计算机架构带来了巨大的挑战。为此，研究团队提出了Spatz矢量处理器，它是基于RISC-V的Vector Extension Zve64d的64位浮点矢量处理器。Spatz作为主要的处理单元（PE），设计了一种基于模块化、可扩展集群的开源双核矢量处理器架构，通过共享一个Scratchpad内存（SCM）来突破指令和数据在内存方面的瓶颈。相较于传统的大型向量寄存器文件（VRF），Spatz以其仅2KiB的基于门控的VRF证明了其峰值能效的实现能力。在全球科技联盟成立流程中使用Spatz为基础集群的实施中实现了FPU应用的效率峰值利用率差距仅在理想上限值之下，提升了双精度浮点矩阵乘法的效能。其高效性能体现在多个方面，包括高运算速度、低功耗以及优秀的能效表现等。相较于传统的标量核心计算集群，Spatz所构建的矢量处理器集群在能效上更胜一筹。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Spatz是基于RISC-V Vector Extension的新型矢量处理器，旨在应对现代应用对计算和存储的挑战。</li>
<li>Spatz采用的双核架构以Scratchpad Memory为核心进行数据处理。它通过内存共享方式突破了处理器在执行指令和数据处理方面的瓶颈。相较于传统的大型向量处理器拥有较小体积的向量寄存器文件(VRF)，能效性能却同样出色。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.10137">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7f26b4ba3e96727db4182893b804602b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-721b8a47632e29df0bbf0aaf98eb3ec3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2896230edad63d524a08afebe3d4f326.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-eb2178b2d9c08e67795eabe88ed3e863.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ed261bd6a4a8a1805f8ef2bc2525be4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fde10804e2e978fe20f8baca9609c9f6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-13/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-13/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-14/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1498048b4d84cb56a8c04fe13cf4817d.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-01-14  Beyond Flat Text Dual Self-inherited Guidance for Visual Text   Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-13/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-fbe9ac1ef0f46cbfd28ac30122713098.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-01-14  The ultraviolet luminosity function of star-forming galaxies between   redshifts of 0.4 and 0.6
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">9017.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
