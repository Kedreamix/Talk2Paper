<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement   Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-10ddfae4d76a7f98708a0cce9cae8d66~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100696&auth_key=1760100696-0-0-55461025763bca8d116bb1f92045260d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-03-æ›´æ–°"><a href="#2025-10-03-æ›´æ–°" class="headerlink" title="2025-10-03 æ›´æ–°"></a>2025-10-03 æ›´æ–°</h1><h2 id="Efficient-and-Transferable-Agentic-Knowledge-Graph-RAG-via-Reinforcement-Learning"><a href="#Efficient-and-Transferable-Agentic-Knowledge-Graph-RAG-via-Reinforcement-Learning" class="headerlink" title="Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement   Learning"></a>Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement   Learning</h2><p><strong>Authors:Jinyeop Song, Song Wang, Julian Shun, Yada Zhu</strong></p>
<p>Knowledge-graph retrieval-augmented generation (KG-RAG) couples large language models (LLMs) with structured, verifiable knowledge graphs (KGs) to reduce hallucinations and expose reasoning traces. However, many KG-RAG systems compose multiple LLM modules (e.g planning, reasoning, and responding), inflating inference cost and binding behavior to a specific target KG. To address this, we introduce KG-R1, an agentic KG retrieval-augmented generation (KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single agent that interacts with KGs as its environment, learning to retrieve at each step and incorporating the retrieved information into its reasoning and generation. The process is optimized through end-to-end RL. In controlled experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our method demonstrates both efficiency and transferability: Using Qwen-2.5-3B, KG-R1 improves answer accuracy with fewer generation tokens than prior multi-module workflow methods that use larger foundation or fine-tuned models. Furthermore, KG-R1 enables plug and play: after training, it maintains strong accuracy on new KGs without modification. These properties make KG-R1 a promising KG-RAG framework for real-world deployment. Our code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/Jinyeop3110/KG-R1">https://github.com/Jinyeop3110/KG-R1</a>. </p>
<blockquote>
<p>çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ç»“æ„åŒ–çš„ã€å¯éªŒè¯çš„çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰ç›¸ç»“åˆï¼Œä»¥å‡å°‘å¹»æƒ³å¹¶æš´éœ²æ¨ç†ç—•è¿¹ã€‚ç„¶è€Œï¼Œè®¸å¤šKG-RAGç³»ç»Ÿç”±å¤šä¸ªLLMæ¨¡å—ï¼ˆå¦‚è§„åˆ’ã€æ¨ç†å’Œå“åº”ï¼‰ç»„æˆï¼Œå¢åŠ äº†æ¨ç†æˆæœ¬ï¼Œå¹¶ä¸”ç»‘å®šåˆ°ç‰¹å®šçš„ç›®æ ‡çŸ¥è¯†å›¾è°±ä¸Šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†KG-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å®ç°çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰æ¡†æ¶ã€‚KG-R1ä½¿ç”¨ä¸€ä¸ªå•ç‹¬çš„æ™ºèƒ½ä½“ä¸ç¯å¢ƒä¸­çš„çŸ¥è¯†å›¾è°±è¿›è¡Œäº¤äº’ï¼Œå­¦ä¹ å¦‚ä½•é€æ­¥æ£€ç´¢ï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ä¿¡æ¯èå…¥å…¶æ¨ç†å’Œç”Ÿæˆä¸­ã€‚è¯¥è¿‡ç¨‹é€šè¿‡ç«¯åˆ°ç«¯çš„RLè¿›è¡Œä¼˜åŒ–ã€‚åœ¨çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰åŸºå‡†æµ‹è¯•ä¸Šçš„å—æ§å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ—¢æœ‰æ•ˆç‡åˆæœ‰å¯è¿ç§»æ€§ï¼šä½¿ç”¨Qwen-2.5-3BåŸºå‡†æµ‹è¯•ï¼ŒKG-R1åœ¨è¾ƒå°‘çš„ç”Ÿæˆæ ‡è®°ä¸­æé«˜äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œä¼˜äºå…ˆå‰çš„å¤šæ¨¡å—å·¥ä½œæµç¨‹æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä½¿ç”¨æ›´å¤§çš„åŸºç¡€æ¨¡å‹æˆ–å¾®è°ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼ŒKG-R1è¿˜å…·æœ‰å³æ’å³ç”¨åŠŸèƒ½ï¼šè®­ç»ƒåï¼Œå®ƒèƒ½å¤Ÿåœ¨æ— éœ€ä¿®æ”¹çš„æƒ…å†µä¸‹åœ¨æ–°çš„çŸ¥è¯†å›¾è°±ä¸Šä¿æŒè¾ƒé«˜çš„å‡†ç¡®æ€§ã€‚è¿™äº›ç‰¹æ€§ä½¿KG-R1æˆä¸ºé¢å‘ç°å®ä¸–ç•Œéƒ¨ç½²çš„æœ‰å¸Œæœ›çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/Jinyeop3110/KG-R1%E3%80%82">https://github.com/Jinyeop3110/KG-R1ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26383v2">PDF</a> 10 pages, 5 figures. Submitted to ICLR 2026</p>
<p><strong>Summary</strong></p>
<p>KG-R1æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKG-RAGï¼‰æ¡†æ¶ã€‚å®ƒä½¿ç”¨ä¸€ä¸ªæ™ºèƒ½ä½“ä¸ç¯å¢ƒï¼ˆçŸ¥è¯†å›¾è°±ï¼‰è¿›è¡Œäº¤äº’ï¼Œåœ¨æ¯ä¸€æ­¥ä¸­å­¦ä¹ æ£€ç´¢ï¼Œå¹¶å°†æ£€ç´¢åˆ°çš„ä¿¡æ¯èå…¥å…¶æ¨ç†å’Œç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚è¯¥æ–¹æ³•ä¼˜åŒ–äº†ç«¯åˆ°ç«¯çš„RLè¿‡ç¨‹ï¼Œåœ¨çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆKGQAï¼‰åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºé«˜æ•ˆæ€§å’Œå¯è¿ç§»æ€§ã€‚KG-R1èƒ½æé«˜ç­”æ¡ˆå‡†ç¡®æ€§ï¼Œå¹¶ä½¿ç”¨è¾ƒå°‘çš„ç”Ÿæˆä»¤ç‰Œã€‚æ­¤å¤–ï¼Œå®ƒå®ç°äº†å³æ’å³ç”¨ï¼Œè®­ç»ƒååœ¨æ–°çŸ¥è¯†å›¾è°±ä¸Šä¿æŒé«˜å‡†ç¡®æ€§è€Œæ— éœ€ä¿®æ”¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KG-R1æ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„çŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ã€‚</li>
<li>KG-R1ä½¿ç”¨ä¸€ä¸ªæ™ºèƒ½ä½“ä¸ç¯å¢ƒï¼ˆçŸ¥è¯†å›¾è°±ï¼‰äº¤äº’ï¼Œè¿›è¡ŒçŸ¥è¯†æ£€ç´¢ã€‚</li>
<li>KG-R1å°†æ£€ç´¢åˆ°çš„çŸ¥è¯†èå…¥å…¶æ¨ç†å’Œç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>KG-R1é€šè¿‡ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>KG-R1åœ¨çŸ¥è¯†å›¾è°±é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºé«˜æ•ˆæ€§å’Œå¯è¿ç§»æ€§ã€‚</li>
<li>KG-R1æé«˜äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä½¿ç”¨äº†è¾ƒå°‘çš„ç”Ÿæˆä»¤ç‰Œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26383">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4bb2658d30d49e7a20990a844c6123f9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084664&auth_key=1760084664-0-0-6527e07cf26a121298f82d9beabe5714&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a57f2b36b5b6aa52b3aaa3dcce5bb2a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084672&auth_key=1760084672-0-0-e2a58f9d59cef057985c7d1304a81cb1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-10ddfae4d76a7f98708a0cce9cae8d66~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084679&auth_key=1760084679-0-0-67cf9723e68ad0a3727febbaf32ebe2f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Beyond-the-Algorithm-A-Field-Guide-to-Deploying-AI-Agents-in-Clinical-Practice"><a href="#Beyond-the-Algorithm-A-Field-Guide-to-Deploying-AI-Agents-in-Clinical-Practice" class="headerlink" title="Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical   Practice"></a>Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical   Practice</h2><p><strong>Authors:Jack Gallifant, Katherine C. Kellogg, Matt Butler, Amanda Centi, Shan Chen, Patrick F. Doyle, Sayon Dutta, Joyce Guo, Matthew J. Hadfield, Esther H. Kim, David E. Kozono, Hugo JWL Aerts, Adam B. Landman, Raymond H. Mak, Rebecca G. Mishuris, Tanna L. Nelson, Guergana K. Savova, Elad Sharon, Benjamin C. Silverman, Umit Topaloglu, Jeremy L. Warner, Danielle S. Bitterman</strong></p>
<p>Large language models (LLMs) integrated into agent-driven workflows hold immense promise for healthcare, yet a significant gap exists between their potential and practical implementation within clinical settings. To address this, we present a practitioner-oriented field manual for deploying generative agents that use electronic health record (EHR) data. This guide is informed by our experience deploying the â€œirAE-Agentâ€, an automated system to detect immune-related adverse events from clinical notes at Mass General Brigham, and by structured interviews with 20 clinicians, engineers, and informatics leaders involved in the project. Our analysis reveals a critical misalignment in clinical AI development: less than 20% of our effort was dedicated to prompt engineering and model development, while over 80% was consumed by the sociotechnical work of implementation. We distill this effort into five â€œheavy liftsâ€: data integration, model validation, ensuring economic value, managing system drift, and governance. By providing actionable solutions for each of these challenges, this field manual shifts the focus from algorithmic development to the essential infrastructure and implementation work required to bridge the â€œvalley of deathâ€ and successfully translate generative AI from pilot projects into routine clinical care. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é›†æˆåˆ°ä»£ç†é©±åŠ¨çš„å·¥ä½œæµç¨‹ä¸­ä¸ºåŒ»ç–—ä¿å¥é¢†åŸŸå¸¦æ¥äº†å·¨å¤§çš„æ½œåŠ›ï¼Œä½†æ˜¯åœ¨ä¸´åºŠç¯å¢ƒä¸­å®ç°å…¶æ½œåœ¨ä»·å€¼ä¸å®é™…åº”ç”¨ä¹‹é—´ä»å­˜åœ¨å¾ˆå¤§å·®è·ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬ç¼–åˆ¶äº†ä¸€æœ¬é¢å‘å®è·µè€…çš„ç°åœºæ‰‹å†Œï¼Œä»‹ç»äº†å¦‚ä½•éƒ¨ç½²ä½¿ç”¨ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æ•°æ®çš„ç”Ÿæˆä»£ç†ã€‚æœ¬æŒ‡å—çš„ç¼–å†™å‚è€ƒäº†æˆ‘ä»¬éƒ¨ç½²â€œirAE-Agentâ€ï¼ˆä¸€ç§ä»Mass General Brighamçš„ä¸´åºŠç¬”è®°ä¸­è‡ªåŠ¨æ£€æµ‹å…ç–«ç›¸å…³ä¸è‰¯äº‹ä»¶çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼‰çš„ç»éªŒï¼Œä»¥åŠä¸å‚ä¸è¯¥é¡¹ç›®çš„20åä¸´åºŠåŒ»ç”Ÿã€å·¥ç¨‹å¸ˆå’Œä¿¡æ¯æŠ€æœ¯é¢†å¯¼çš„ç»“æ„åŒ–è®¿è°ˆã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ä¸´åºŠäººå·¥æ™ºèƒ½å‘å±•ä¸­çš„å…³é”®ä¸åŒ¹é…ï¼šæˆ‘ä»¬çš„åŠªåŠ›ä¸­åªæœ‰ä¸åˆ°20%ä¸“æ³¨äºå³æ—¶å·¥ç¨‹æ¨¡å‹å’Œå¼€å‘ï¼Œè€Œè¶…è¿‡80%è¢«å®æ–½çš„ç¤¾æŠ€æœ¯å·¥ä½œæ‰€å æ®ã€‚æˆ‘ä»¬å°†è¿™äº›åŠªåŠ›ç®€åŒ–ä¸ºäº”ä¸ªâ€œé‡ç‚¹ä»»åŠ¡â€ï¼šæ•°æ®é›†æˆã€æ¨¡å‹éªŒè¯ã€ç¡®ä¿ç»æµä»·å€¼ã€ç®¡ç†ç³»ç»Ÿæ¼‚ç§»å’Œæ²»ç†ã€‚é€šè¿‡ä¸ºè¿™äº›æŒ‘æˆ˜æä¾›å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œæœ¬ç°åœºæ‰‹å†Œå°†é‡ç‚¹ä»ç®—æ³•å¼€å‘è½¬å‘å¿…è¦çš„åŸºç¡€è®¾æ–½å’Œå®æ–½å·¥ä½œï¼Œä»¥å¡«è¡¥â€œæ­»äº¡ä¹‹è°·â€ï¼ŒæˆåŠŸåœ°å°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä»è¯•ç‚¹é¡¹ç›®è½¬åŒ–ä¸ºå¸¸è§„ä¸´åºŠæŠ¤ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26153v2">PDF</a> Under review. 5 Tables, 2 Figures</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—å¥åº·é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†åœ¨ä¸´åºŠå®è·µä¸­çš„å®é™…åº”ç”¨ä¸æ½œåŠ›ä¹‹é—´å­˜åœ¨è¾ƒå¤§å·®è·ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æŒ‡å—ä»¥ä»ä¸šè€…ä¸ºå¯¼å‘ï¼Œä»‹ç»å¦‚ä½•åœ¨åŒ»ç–—è®°å½•æ•°æ®çš„åŸºç¡€ä¸Šéƒ¨ç½²ç”Ÿæˆå¼æ™ºèƒ½ä»£ç†ã€‚æœ¬æŒ‡å—åŸºäºåœ¨Mass General Brighaméƒ¨ç½²irAE-Agentç³»ç»Ÿçš„ç»éªŒï¼Œå¹¶ä¸å‚ä¸è¯¥é¡¹ç›®çš„ä¸´åºŠåŒ»ç”Ÿã€å·¥ç¨‹å¸ˆå’Œä¿¡æ¯æŠ€æœ¯é¢†å¯¼è€…è¿›è¡Œæ·±å…¥è®¿è°ˆã€‚åˆ†ææ˜¾ç¤ºï¼Œä¸´åºŠäººå·¥æ™ºèƒ½çš„å‘å±•å­˜åœ¨å…³é”®æ€§å¤±è°ƒï¼šä»…ä¸åˆ°20%çš„åŠªåŠ›ç”¨äºå¿«é€Ÿå·¥ç¨‹å¼€å‘å’Œæ¨¡å‹å¼€å‘ï¼Œè€Œè¶…è¿‡80%çš„åŠªåŠ›è¢«å®æ–½çš„ç¤¾ä¼šæŠ€æœ¯å·¥ä½œæ‰€æ¶ˆè€—ã€‚æœ¬æŒ‡å—æä¾›è§£å†³è¿™äº›æŒ‘æˆ˜çš„å®é™…è§£å†³æ–¹æ¡ˆï¼Œå°†é‡ç‚¹ä»ç®—æ³•å¼€å‘è½¬å‘å¿…è¦çš„åŸºç¡€è®¾æ–½å’Œå®æ–½å·¥ä½œï¼Œä»¥æˆåŠŸå°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä»è¯•ç‚¹é¡¹ç›®è½¬åŒ–ä¸ºå¸¸è§„ä¸´åºŠæŠ¤ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—å¥åº·é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å®é™…åº”ç”¨ä¸­å­˜åœ¨å·®è·ã€‚</li>
<li>éƒ¨ç½²ç”Ÿæˆå¼æ™ºèƒ½ä»£ç†éœ€è¦å…³æ³¨æ•°æ®é›†æˆã€æ¨¡å‹éªŒè¯ç­‰äº”ä¸ªæ–¹é¢çš„â€œé‡å·¥ä½œâ€ã€‚</li>
<li>å®é™…åº”ç”¨ä¸­è¶…è¿‡80%çš„åŠªåŠ›è¢«å®æ–½çš„ç¤¾ä¼šæŠ€æœ¯å·¥ä½œæ‰€æ¶ˆè€—ã€‚</li>
<li>é€šè¿‡æä¾›é’ˆå¯¹æ¯ä¸ªæŒ‘æˆ˜çš„å®é™…è§£å†³æ–¹æ¡ˆï¼Œæœ¬æŒ‡å—å°†ç„¦ç‚¹ä»ç®—æ³•å¼€å‘è½¬å‘å¿…è¦çš„åŸºç¡€è®¾æ–½å’Œå®æ–½å·¥ä½œã€‚</li>
<li>irAE-Agentç³»ç»Ÿå±•ç¤ºäº†å°†ç”Ÿæˆå¼AIåº”ç”¨äºä¸´åºŠå®è·µçš„å®ä¾‹ã€‚</li>
<li>å®åœ°è€ƒå¯Ÿå’Œç»éªŒè®¿è°ˆæ­ç¤ºäº†ä¸´åºŠAIå‘å±•ä¸­çš„å…³é”®é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26153">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ea05f0c992a5b3aff5cef348c76e9cc1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084686&auth_key=1760084686-0-0-b638b4e19e1f897630001cb790b72195&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Automatically-Generating-Web-Applications-from-Requirements-Via-Multi-Agent-Test-Driven-Development"><a href="#Automatically-Generating-Web-Applications-from-Requirements-Via-Multi-Agent-Test-Driven-Development" class="headerlink" title="Automatically Generating Web Applications from Requirements Via   Multi-Agent Test-Driven Development"></a>Automatically Generating Web Applications from Requirements Via   Multi-Agent Test-Driven Development</h2><p><strong>Authors:Yuxuan Wan, Tingshuo Liang, Jiakai Xu, Jingyu Xiao, Yintong Huo, Michael R. Lyu</strong></p>
<p>Developing full-stack web applications is complex and time-intensive, demanding proficiency across diverse technologies and frameworks. Although recent advances in multimodal large language models (MLLMs) enable automated webpage generation from visual inputs, current solutions remain limited to front-end tasks and fail to deliver fully functional applications. In this work, we introduce TDDev, the first test-driven development (TDD)-enabled LLM-agent framework for end-to-end full-stack web application generation. Given a natural language description or design image, TDDev automatically derives executable test cases, generates front-end and back-end code, simulates user interactions, and iteratively refines the implementation until all requirements are satisfied. Our framework addresses key challenges in full-stack automation, including underspecified user requirements, complex interdependencies among multiple files, and the need for both functional correctness and visual fidelity. Through extensive experiments on diverse application scenarios, TDDev achieves a 14.4% improvement on overall accuracy compared to state-of-the-art baselines, demonstrating its effectiveness in producing reliable, high-quality web applications without requiring manual intervention. </p>
<blockquote>
<p>å¼€å‘å…¨æ ˆå¼Webåº”ç”¨ç¨‹åºæ˜¯ä¸€é¡¹å¤æ‚ä¸”è€—æ—¶çš„å·¥ä½œï¼Œéœ€è¦å¯¹å¤šç§æŠ€æœ¯å’Œæ¡†æ¶æœ‰ç²¾é€šçš„èƒ½åŠ›ã€‚å°½ç®¡æœ€è¿‘çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›æ­¥èƒ½å¤Ÿå®ç°ä»è§†è§‰è¾“å…¥è‡ªåŠ¨ç”Ÿæˆç½‘é¡µï¼Œä½†å½“å‰çš„è§£å†³æ–¹æ¡ˆä»ç„¶ä»…é™äºå‰ç«¯ä»»åŠ¡ï¼Œæ— æ³•æä¾›å®Œæ•´çš„åŠŸèƒ½æ€§åº”ç”¨ç¨‹åºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†TDDevï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒç«¯åˆ°ç«¯å…¨æ ˆWebåº”ç”¨ç¨‹åºç”Ÿæˆçš„ä½¿ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†æ¡†æ¶ã€‚ç»™å®šè‡ªç„¶è¯­è¨€æè¿°æˆ–è®¾è®¡å›¾åƒï¼ŒTDDevä¼šè‡ªåŠ¨æ¨å¯¼å¯æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹ï¼Œç”Ÿæˆå‰ç«¯å’Œåç«¯ä»£ç ï¼Œæ¨¡æ‹Ÿç”¨æˆ·äº¤äº’ï¼Œå¹¶è¿­ä»£åœ°å®Œå–„å®ç°ï¼Œç›´åˆ°æ»¡è¶³æ‰€æœ‰è¦æ±‚ã€‚æˆ‘ä»¬çš„æ¡†æ¶è§£å†³äº†å…¨æ ˆè‡ªåŠ¨åŒ–çš„å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç”¨æˆ·éœ€æ±‚ä¸æ˜ç¡®ã€å¤šä¸ªæ–‡ä»¶ä¹‹é—´çš„å¤æ‚ç›¸äº’ä¾èµ–å…³ç³»ä»¥åŠå¯¹åŠŸèƒ½æ­£ç¡®æ€§å’Œè§†è§‰ä¿çœŸåº¦çš„éœ€æ±‚ã€‚é€šè¿‡å¯¹ä¸åŒåº”ç”¨åœºæ™¯çš„å¹¿æ³›å®éªŒï¼ŒTDDevåœ¨æ•´ä½“å‡†ç¡®æ€§æ–¹é¢æ¯”æœ€æ–°æŠ€æœ¯åŸºçº¿æé«˜äº†14.4%ï¼Œè¯æ˜äº†å…¶åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ç”Ÿæˆå¯é ã€é«˜è´¨é‡Webåº”ç”¨ç¨‹åºçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25297v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>MLLMsèµ‹èƒ½è‡ªåŠ¨åŒ–ç½‘é¡µç”ŸæˆæŠ€æœ¯ï¼Œä½†ä»å±€é™äºå‰ç«¯ä»»åŠ¡ã€‚æœ¬æ–‡ä»‹ç»TDDevæ¡†æ¶ï¼Œé‡‡ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰å’ŒLLMä»£ç†æŠ€æœ¯å®ç°å…¨æ ˆWebåº”ç”¨ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚è¯¥æ¡†æ¶å¯æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°æˆ–è®¾è®¡å›¾åƒè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…æ‹¬å‰åç«¯ä»£ç ï¼Œæ¨¡æ‹Ÿç”¨æˆ·äº¤äº’ï¼Œå¹¶åœ¨æ»¡è¶³æ‰€æœ‰è¦æ±‚åé€æ­¥ä¼˜åŒ–å®ç°ã€‚å®éªŒç»“æœè¯æ˜äº†å…¶åœ¨ç”Ÿæˆå¯é é«˜è´¨é‡Webåº”ç”¨æ–¹é¢çš„ä¼˜åŠ¿ã€‚ç›¸æ¯”å½“å‰æœ€æ–°æŠ€æœ¯åŸºçº¿ï¼ŒTDDevåœ¨æ€»ä½“å‡†ç¡®æ€§ä¸Šæå‡äº†é«˜è¾¾ç™¾åˆ†ä¹‹åå››ç‚¹å››çš„å‡†ç¡®åº¦ï¼Œæé«˜äº†æ— äººå·¥å¹²é¢„çš„è‡ªé€‚åº”èƒ½åŠ›ã€‚åŒæ—¶èƒ½å¾ˆå¥½åœ°å¤„ç†ç”¨æˆ·è¦æ±‚ä¸æ˜ç¡®ç­‰éš¾é¢˜ï¼Œæ˜¯è·¨é¢†åŸŸæŠ€æœ¯åˆ›æ–°çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ç»¼åˆè¯•éªŒæ˜¾ç¤ºäº†å…¶æ˜¾è‘—çš„ä¼˜åŠ¿å’Œæ½œåŠ›ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼€å‘å…¨æ ˆWebåº”ç”¨æ˜¯ä¸€ä¸ªå¤æ‚ä¸”è€—æ—¶çš„è¿‡ç¨‹ï¼Œéœ€è¦æŒæ¡å¤šç§æŠ€æœ¯å’Œæ¡†æ¶çš„æŠ€èƒ½ã€‚ç°æœ‰çš„è‡ªåŠ¨åŒ–å·¥å…·å¤§å¤šå±€é™äºå‰ç«¯ä»»åŠ¡ï¼Œæ— æ³•å®ç°å®Œå…¨è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚è€Œæœ¬æ–‡ä»‹ç»çš„TDDevæ¡†æ¶å®ç°äº†ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–ç”ŸæˆåŠŸèƒ½ã€‚</li>
<li>TDDevæ¡†æ¶é‡‡ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯ï¼Œèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°æˆ–è®¾è®¡å›¾åƒè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å’Œä»£ç ã€‚æ­¤æŠ€æœ¯é€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·äº¤äº’ä¸æ–­ä¼˜åŒ–å’Œå®Œå–„åº”ç”¨ç¨‹åºåŠŸèƒ½ï¼Œä»¥ç¡®ä¿å…¶æ»¡è¶³ç”¨æˆ·éœ€æ±‚å¹¶å…·æœ‰å¼ºå¤§çš„åŠŸèƒ½æ€§æ­£ç¡®æ€§ã€‚ä¸å…¶ä»–å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶çš„ä¼˜åŠ¿æ˜æ˜¾ï¼Œèƒ½æ˜¾è‘—æå‡å…¨æ ˆåº”ç”¨çš„æ€»ä½“å‡†ç¡®åº¦è¾¾åˆ°ç™¾åˆ†ä¹‹åå››ç‚¹å››çš„æå‡å¹…åº¦ã€‚ä¸”èƒ½å¤Ÿä»¥ç®€å•æœ‰æ•ˆçš„æ–¹å¼åº”å¯¹ä¸€ç³»åˆ—å¸¸è§çš„éš¾é¢˜ã€‚å®ƒå¯¹ç¼–ç¨‹è¡Œä¸šæœªæ¥çš„å‘å±•æ–¹å‘å…·æœ‰é‡è¦çš„æ¨åŠ¨ä½œç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c4970290a4ac709eabdaca113ca7c0ba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084693&auth_key=1760084693-0-0-74bfbd45a89d756e80b8083a9c8c6dee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6726b5ba0ca97f2ccd8387206efbf139~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084701&auth_key=1760084701-0-0-0fd73b2b653eb5995ae67e0a94c941d1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-08c818c652dd7b7c9d182d07aa472825~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084707&auth_key=1760084707-0-0-e785a214c1421eae0894a234bdf6900b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-28b69df8523b86ea64d0a0122ecf2f18~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084714&auth_key=1760084714-0-0-dd449916f979d998576dc52de1191315&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SafeSearch-Automated-Red-Teaming-for-the-Safety-of-LLM-Based-Search-Agents"><a href="#SafeSearch-Automated-Red-Teaming-for-the-Safety-of-LLM-Based-Search-Agents" class="headerlink" title="SafeSearch: Automated Red-Teaming for the Safety of LLM-Based Search   Agents"></a>SafeSearch: Automated Red-Teaming for the Safety of LLM-Based Search   Agents</h2><p><strong>Authors:Jianshuo Dong, Sheng Guo, Hao Wang, Zhuotao Liu, Tianwei Zhang, Ke Xu, Minlie Huang, Han Qiu</strong></p>
<p>Search agents connect LLMs to the Internet, enabling access to broader and more up-to-date information. However, unreliable search results may also pose safety threats to end users, establishing a new threat surface. In this work, we conduct two in-the-wild experiments to demonstrate both the prevalence of low-quality search results and their potential to misguide agent behaviors. To counter this threat, we introduce an automated red-teaming framework that is systematic, scalable, and cost-efficient, enabling lightweight and harmless safety assessments of search agents. Building on this framework, we construct the SafeSearch benchmark, which includes 300 test cases covering five categories of risks (e.g., misinformation and indirect prompt injection). Using this benchmark, we evaluate three representative search agent scaffolds, covering search workflow, tool-calling, and deep research, across 7 proprietary and 8 open-source backend LLMs. Our results reveal substantial vulnerabilities of LLM-based search agents: when exposed to unreliable websites, the highest ASR reached 90.5% for GPT-4.1-mini under a search workflow setting. Moreover, our analysis highlights the limited effectiveness of common defense practices, such as reminder prompting. This emphasizes the value of our framework in promoting transparency for safer agent development. Our codebase and test cases are publicly available: <a target="_blank" rel="noopener" href="https://github.com/jianshuod/SafeSearch">https://github.com/jianshuod/SafeSearch</a>. </p>
<blockquote>
<p>æœç´¢ä»£ç†å°†å¤§å‹è¯­è¨€æ¨¡å‹è¿æ¥åˆ°äº’è”ç½‘ï¼Œä»¥ä¾¿è®¿é—®æ›´å¹¿æ³›å’Œæœ€æ–°çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œä¸å¯é çš„æœç´¢ç»“æœä¹Ÿå¯èƒ½å¯¹æœ€ç»ˆç”¨æˆ·æ„æˆå®‰å…¨å¨èƒï¼Œå½¢æˆæ–°çš„å¨èƒé¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¸¤é¡¹é‡å¤–å®éªŒæ¥å±•ç¤ºä½è´¨é‡æœç´¢ç»“æœçš„æ™®éæ€§ä»¥åŠå®ƒä»¬è¯¯å¯¼ä»£ç†è¡Œä¸ºçš„å¯èƒ½æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€å¨èƒï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç³»ç»ŸåŒ–ã€å¯æ‰©å±•ä¸”æˆæœ¬æ•ˆç›Šé«˜çš„è‡ªåŠ¨åŒ–çº¢é˜Ÿæ¡†æ¶ï¼Œå¯ä»¥å¯¹æœç´¢ä»£ç†è¿›è¡Œè½»ä¾¿ä¸”æ— å®³çš„å®‰å…¨è¯„ä¼°ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œæˆ‘ä»¬æ„å»ºäº†SafeSearchåŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬æ¶µç›–äº”ç§é£é™©ç±»åˆ«çš„300ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆä¾‹å¦‚ï¼Œé”™è¯¯ä¿¡æ¯å’Œé—´æ¥æç¤ºæ³¨å…¥ï¼‰ã€‚ä½¿ç”¨è¯¥åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸‰ç§å…·æœ‰ä»£è¡¨æ€§çš„æœç´¢ä»£ç†æ¶æ„ï¼Œæ¶µç›–æœç´¢å·¥ä½œæµç¨‹ã€å·¥å…·è°ƒç”¨å’Œæ·±åº¦ç ”ç©¶ï¼Œæ¶‰åŠ7ä¸ªä¸“æœ‰å’Œ8ä¸ªå¼€æºåç«¯å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æœç´¢ä»£ç†å­˜åœ¨å¤§é‡æ¼æ´ï¼šåœ¨é¢å¯¹ä¸å¯é çš„ç½‘ç«™æ—¶ï¼ŒGPT-4.1 miniåœ¨æœç´¢å·¥ä½œæµç¨‹è®¾ç½®ä¸‹çš„è¯¯æŠ¥ç‡æœ€é«˜è¾¾åˆ°90.5%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„åˆ†æå¼ºè°ƒäº†å¸¸è§é˜²å¾¡æªæ–½ï¼ˆå¦‚æé†’æç¤ºï¼‰çš„æœ‰é™æœ‰æ•ˆæ€§ï¼Œè¿™å¼ºè°ƒäº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨ä¿ƒè¿›æ›´å®‰å…¨ä»£ç†å¼€å‘ä¸­çš„é€æ˜åº¦çš„ä»·å€¼ã€‚æˆ‘ä»¬çš„ä»£ç åº“å’Œæµ‹è¯•ç”¨ä¾‹å¯å…¬å¼€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/jianshuod/SafeSearch">https://github.com/jianshuod/SafeSearch</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23694v2">PDF</a> Preprint</p>
<p><strong>Summary</strong><br>     æœç´¢ä»£ç†å°†å¤§å‹è¯­è¨€æ¨¡å‹è¿æ¥åˆ°äº’è”ç½‘ï¼Œæä¾›è·å–æ›´å…¨é¢ã€æœ€æ–°çš„ä¿¡æ¯çš„æœºä¼šï¼Œä½†åŒæ—¶ä¹Ÿå¸¦æ¥äº†å®‰å…¨å¨èƒã€‚å®éªŒè¡¨æ˜æœç´¢ç»“æœçš„ä¸å¯é æ€§å¯¹ç»ˆç«¯ç”¨æˆ·çš„å®‰å…¨æ„æˆäº†å¨èƒã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç³»ç»ŸåŒ–ã€å¯æ‰©å±•ä¸”ç»æµé«˜æ•ˆçš„è‡ªåŠ¨åŒ–çº¢é˜Ÿæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯å¯¹æœç´¢ä»£ç†è¿›è¡Œå®‰å…¨è¯„ä¼°ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œæˆ‘ä»¬åˆ›å»ºäº†SafeSearchåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº”ç§é£é™©ç±»åˆ«çš„æµ‹è¯•æ¡ˆä¾‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼ŒLLMä¸ºåŸºç¡€æœç´¢ä»£ç†å­˜åœ¨æ˜¾è‘—æ¼æ´ï¼Œå¯èƒ½é¢ä¸´é«˜è¯¯æŠ¥ç‡ï¼ˆé«˜è¾¾GPT-4.1 miniç‰ˆæœ¬ä¸­çš„é«˜è¾¾90.5%ï¼‰ã€‚ç°æœ‰çš„é˜²å¾¡æªæ–½çš„æœ‰æ•ˆæ€§æœ‰é™ï¼Œå¼ºè°ƒäº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨æé«˜å®‰å…¨æ€§æ–¹é¢çš„ä»·å€¼ã€‚ä»£ç åº“å’Œæµ‹è¯•ç”¨ä¾‹å·²å…¬å¼€åˆ†äº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœç´¢ä»£ç†è¿æ¥å¤§å‹è¯­è¨€æ¨¡å‹åˆ°äº’è”ç½‘ï¼Œå¸¦æ¥ä¿¡æ¯è·å–çš„ä¾¿åˆ©æ€§å’Œå®‰å…¨æ€§å¨èƒã€‚</li>
<li>ä½è´¨é‡çš„æœç´¢ç»“æœå¯èƒ½è¯¯å¯¼ä»£ç†è¡Œä¸ºå¹¶æ„æˆå®‰å…¨å¨èƒã€‚</li>
<li>æå‡ºä¸€ç§è‡ªåŠ¨åŒ–çº¢é˜Ÿæ¡†æ¶è¿›è¡Œç³»ç»Ÿçš„ã€è½»é‡çº§çš„æ— å®³å®‰å…¨è¯„ä¼°ã€‚</li>
<li>åˆ›å»ºSafeSearchåŸºå‡†æµ‹è¯•æ¶µç›–äº”ç§é£é™©ç±»åˆ«ï¼ŒåŒ…æ‹¬è¯¯å¯¼ä¿¡æ¯å’Œé—´æ¥æç¤ºæ³¨å…¥ç­‰ã€‚</li>
<li>å‘ç°LLMä¸ºåŸºç¡€çš„æœç´¢ä»£ç†å­˜åœ¨æ˜¾è‘—æ¼æ´ï¼Œé¢ä¸´é«˜è¯¯æŠ¥ç‡é£é™©ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23694">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0703667c32d52cc458be736d5de413dd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084721&auth_key=1760084721-0-0-ff8fb6edd56213dfc5c30d5482cb7527&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ec19a273e50ac4f79b211795834aafe6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084728&auth_key=1760084728-0-0-ec119b658a2b7effe74e5d2adad495b9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-52e399bccd60e16f457d58f389973d5c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100703&auth_key=1760100703-0-0-7510f4bf9bbcbe9c2409b6d32cebce8f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8b8b4944ab2bb8aebdb4d7a8fced3c0a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100710&auth_key=1760100710-0-0-e0b5e3b6e33413a6ea8d531e31711864&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-97a3d43e052b88a06bee4e8d6aecfd83~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100717&auth_key=1760100717-0-0-cb65f90b09814f383cbd1c67a2205b37&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-08d34d26edec73a7959476a801a911ab~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100723&auth_key=1760100723-0-0-85c2f174b93e49ab611af02aff5909a8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ReWatch-R1-Boosting-Complex-Video-Reasoning-in-Large-Vision-Language-Models-through-Agentic-Data-Synthesis"><a href="#ReWatch-R1-Boosting-Complex-Video-Reasoning-in-Large-Vision-Language-Models-through-Agentic-Data-Synthesis" class="headerlink" title="ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language   Models through Agentic Data Synthesis"></a>ReWatch-R1: Boosting Complex Video Reasoning in Large Vision-Language   Models through Agentic Data Synthesis</h2><p><strong>Authors:Congzhi Zhang, Zhibin Wang, Yinchao Ma, Jiawei Peng, Yihan Wang, Qiang Zhou, Jun Song, Bo Zheng</strong></p>
<p>While Reinforcement Learning with Verifiable Reward (RLVR) significantly advances image reasoning in Large Vision-Language Models (LVLMs), its application to complex video reasoning remains underdeveloped. This gap stems primarily from a critical data bottleneck: existing datasets lack the challenging, multi-hop questions and high-quality, video-grounded Chain-of-Thought (CoT) data necessary to effectively bootstrap RLVR. To address this, we introduce ReWatch, a large-scale dataset built to foster advanced video reasoning. We propose a novel multi-stage synthesis pipeline to synthesize its three components: ReWatch-Caption, ReWatch-QA, and ReWatch-CoT. A core innovation is our Multi-Agent ReAct framework for CoT synthesis, which simulates a human-like â€œre-watchingâ€ process to generate video-grounded reasoning traces by explicitly modeling information retrieval and verification. Building on this dataset, we develop ReWatch-R1 by post-training a strong baseline LVLM with Supervised Fine-Tuning (SFT) and our RLVR framework. This framework incorporates a novel Observation &amp; Reasoning (O&amp;R) reward mechanism that evaluates both the final answerâ€™s correctness and the reasoningâ€™s alignment with video content, directly penalizing hallucination. Our experiments show that ReWatch-R1 achieves state-of-the-art average performance on five challenging video reasoning benchmarks. Project Page: <a target="_blank" rel="noopener" href="https://rewatch-r1.github.io/">https://rewatch-r1.github.io</a> </p>
<blockquote>
<p>åœ¨å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æ˜¾è‘—æ¨è¿›å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„å›¾åƒæ¨ç†çš„åŒæ—¶ï¼Œå…¶åœ¨å¤æ‚è§†é¢‘æ¨ç†ä¸­çš„åº”ç”¨ä»ç„¶å¤„äºåˆçº§é˜¶æ®µã€‚è¿™ä¸€å·®è·ä¸»è¦æºäºå…³é”®çš„æ•°æ®ç“¶é¢ˆï¼šç°æœ‰æ•°æ®é›†ç¼ºä¹å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šè·³é—®é¢˜å’Œé«˜è´¨é‡çš„è§†é¢‘åŸºç¡€æ€ç»´é“¾ï¼ˆCoTï¼‰æ•°æ®ï¼Œæ— æ³•æœ‰æ•ˆå¼•å¯¼RLVRã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ReWatchï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºäº†ä¿ƒè¿›é«˜çº§è§†é¢‘æ¨ç†è€Œæ„å»ºçš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šé˜¶æ®µåˆæˆç®¡é“æ¥åˆæˆå…¶ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šReWatch-Captionã€ReWatch-QAå’ŒReWatch-CoTã€‚ä¸€ä¸ªæ ¸å¿ƒåˆ›æ–°æ˜¯æˆ‘ä»¬ä¸ºCoTåˆæˆæå‡ºçš„Multi-Agent ReActæ¡†æ¶ï¼Œå®ƒé€šè¿‡æ¨¡æ‹Ÿäººç±»â€œé‡çœ‹â€è¿‡ç¨‹æ¥ç”Ÿæˆè§†é¢‘åŸºç¡€æ¨ç†è½¨è¿¹ï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡ä¿¡æ¯æ£€ç´¢å’ŒéªŒè¯ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œæˆ‘ä»¬çš„RLVRæ¡†æ¶å¯¹å¼ºå¤§çš„åŸºçº¿LVLMè¿›è¡Œåè®­ç»ƒï¼Œå¼€å‘äº†ReWatch-R1ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§æ–°å‹çš„è§‚å¯Ÿä¸æ¨ç†ï¼ˆO&amp;Rï¼‰å¥–åŠ±æœºåˆ¶ï¼Œè¯¥æœºåˆ¶ä¸ä»…è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼Œè¿˜è¯„ä¼°æ¨ç†ä¸è§†é¢‘å†…å®¹çš„å¯¹é½ç¨‹åº¦ï¼Œç›´æ¥æƒ©ç½šè™šæ„æƒ…å†µã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒReWatch-R1åœ¨äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å¹³å‡æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://rewatch-r1.github.io/">https://rewatch-r1.github.io</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23652v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå¼ºåŒ–å­¦ä¹ éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„å›¾åƒæ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤æ‚è§†é¢‘æ¨ç†æ–¹é¢çš„åº”ç”¨å°šå¾…å‘å±•ã€‚è¿™ä¸»è¦æ˜¯ç”±äºå…³é”®æ•°æ®ç“¶é¢ˆçš„å­˜åœ¨ï¼šç°æœ‰æ•°æ®é›†ç¼ºä¹æŒ‘æˆ˜æ€§çš„å¤šè·³é—®é¢˜å’Œé«˜è´¨é‡çš„è§†é¢‘åŸºç¡€æ€ç»´é“¾æ•°æ®ï¼Œæ— æ³•æœ‰æ•ˆåœ°å¼•å¯¼RLVRã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ReWatchæ•°æ®é›†ï¼Œæ—¨åœ¨ä¿ƒè¿›é«˜çº§è§†é¢‘æ¨ç†çš„å‘å±•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤šé˜¶æ®µåˆæˆç®¡é“æ¥åˆæˆå…¶ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šReWatch-Captionã€ReWatch-QAå’ŒReWatch-CoTã€‚å…¶ä¸­æ ¸å¿ƒåˆ›æ–°æ˜¯CoTåˆæˆçš„å¤šæ™ºèƒ½ä½“ååº”æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ¨¡æ‹Ÿäººç±»â€œé‡çœ‹â€è¿‡ç¨‹æ¥ç”Ÿæˆè§†é¢‘åŸºç¡€æ¨ç†è½¨è¿¹ï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡ä¿¡æ¯æ£€ç´¢å’ŒéªŒè¯ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å‘å±•äº†ReWatch-R1ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œæˆ‘ä»¬çš„RLVRæ¡†æ¶å¯¹å¼ºå¤§çš„åŸºçº¿LVLMè¿›è¡Œåè®­ç»ƒã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†ä¸€ç§æ–°å‹çš„è§‚å¯Ÿä¸æ¨ç†ï¼ˆO&amp;Rï¼‰å¥–åŠ±æœºåˆ¶ï¼Œæ—¢è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼Œåˆè¯„ä¼°å…¶ä¸è§†é¢‘å†…å®¹çš„å»åˆç¨‹åº¦ï¼Œç›´æ¥éåˆ¶å¹»è§‰ç°è±¡ã€‚å®éªŒè¡¨æ˜ï¼ŒReWatch-R1åœ¨äº”ä¸ªæŒ‘æˆ˜æ€§çš„è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¹³å‡æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„å›¾åƒæ¨ç†ä¸­æœ‰æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨è§†é¢‘æ¨ç†ä¸­åº”ç”¨ä¸è¶³ã€‚</li>
<li>æ•°æ®ç“¶é¢ˆæ˜¯é™åˆ¶RLVRåœ¨è§†é¢‘æ¨ç†ä¸­åº”ç”¨çš„ä¸»è¦åŸå› ï¼Œç°æœ‰æ•°æ®é›†ç¼ºä¹æŒ‘æˆ˜æ€§å¤šè·³é—®é¢˜å’Œé«˜è´¨é‡è§†é¢‘åŸºç¡€æ€ç»´é“¾æ•°æ®ã€‚</li>
<li>æ¨å‡ºReWatchæ•°æ®é›†ï¼Œæ—¨åœ¨ä¿ƒè¿›é«˜çº§è§†é¢‘æ¨ç†çš„å‘å±•ã€‚</li>
<li>æå‡ºæ–°çš„å¤šé˜¶æ®µåˆæˆç®¡é“æ¥åˆæˆReWatchæ•°æ®é›†çš„ä¸‰éƒ¨åˆ†ï¼šReWatch-Captionã€ReWatch-QAå’ŒReWatch-CoTã€‚</li>
<li>å¼•å…¥å¤šæ™ºèƒ½ä½“ååº”æ¡†æ¶è¿›è¡Œæ€ç»´é“¾åˆæˆï¼Œæ¨¡æ‹Ÿäººç±»â€œé‡çœ‹â€è¿‡ç¨‹ç”Ÿæˆè§†é¢‘åŸºç¡€æ¨ç†è½¨è¿¹ã€‚</li>
<li>å‘å±•äº†ReWatch-R1ï¼Œç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’ŒRLVRæ¡†æ¶è¿›è¡Œåè®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-54c706fba2449dbd8d99e22e73b859d0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100730&auth_key=1760100730-0-0-8763f16fa9c12cba16afe0bf7016b926&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-357c59e964f6a862a0e3317d860ddbc3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100738&auth_key=1760100738-0-0-efbf7c5cbca82297c557ea8e087a480d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cb04e41e18c0344646a370d1b0e9176b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100744&auth_key=1760100744-0-0-bafbe6c36fa10486dc96d0f5bedc62db&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-78693b6c5ca9d9807928811476dc4858~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100751&auth_key=1760100751-0-0-a7c888af21c82c92ce8e69474f3199bc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DBF-MA-A-Differential-Bayesian-Filtering-Planner-for-Multi-Agent-Autonomous-Racing-Overtakes"><a href="#DBF-MA-A-Differential-Bayesian-Filtering-Planner-for-Multi-Agent-Autonomous-Racing-Overtakes" class="headerlink" title="DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent   Autonomous Racing Overtakes"></a>DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent   Autonomous Racing Overtakes</h2><p><strong>Authors:Trent Weiss, Amar Kulkarni, Madhur Behl</strong></p>
<p>A significant challenge in autonomous racing is to generate overtaking maneuvers. Racing agents must execute these maneuvers on complex racetracks with little room for error. Optimization techniques and graph-based methods have been proposed, but these methods often rely on oversimplified assumptions for collision-avoidance and dynamic constraints. In this work, we present an approach to trajectory synthesis based on an extension of the Differential Bayesian Filtering framework. Our approach for collision-free trajectory synthesis frames the problem as one of Bayesian Inference over the space of Composite Bezier Curves. Our method is derivative-free, does not require a spherical approximation of the vehicle footprint, linearization of constraints, or simplifying upper bounds on collision avoidance. We conduct a closed-loop analysis of DBF-MA and find it successfully overtakes an opponent in 87% of tested scenarios, outperforming existing methods in autonomous overtaking. </p>
<blockquote>
<p>è‡ªä¸»é©¾é©¶ç«èµ›ä¸­çš„ä¸€å¤§æŒ‘æˆ˜æ˜¯ç”Ÿæˆè¶…è½¦æœºåŠ¨åŠ¨ä½œã€‚ç«èµ›ä»£ç†å¿…é¡»åœ¨å¤æ‚çš„èµ›é“ä¸Šæ‰§è¡Œè¿™äº›åŠ¨ä½œï¼Œè€Œä¸”ä¸èƒ½æœ‰å¤ªå¤šå¤±è¯¯ã€‚è™½ç„¶å·²æœ‰ä¼˜åŒ–æŠ€æœ¯å’ŒåŸºäºå›¾çš„æ–¹æ³•è¢«æå‡ºï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸åœ¨é¿å…ç¢°æ’å’ŒåŠ¨æ€çº¦æŸæ–¹é¢å­˜åœ¨è¿‡äºç®€åŒ–çš„å‡è®¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå·®åˆ†è´å¶æ–¯æ»¤æ³¢æ¡†æ¶æ‰©å±•çš„è½¨è¿¹åˆæˆæ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºçš„æ— ç¢°æ’è½¨è¿¹åˆæˆæ–¹æ³•å°†é—®é¢˜è¡¨è¿°ä¸ºå¤åˆè´å¡å°”æ›²çº¿ç©ºé—´ä¸Šçš„è´å¶æ–¯æ¨æ–­é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€æ±‚å¯¼ï¼Œä¸éœ€è¦å¯¹è½¦è¾†è¶³è¿¹è¿›è¡Œçƒå½¢è¿‘ä¼¼ï¼Œä¸éœ€è¦å¯¹çº¦æŸè¿›è¡Œçº¿æ€§åŒ–ï¼Œä¹Ÿä¸éœ€è¦ç®€åŒ–é¿å…ç¢°æ’çš„ä¸Šç•Œã€‚æˆ‘ä»¬å¯¹DBF-MAè¿›è¡Œäº†é—­ç¯åˆ†æï¼Œå‘ç°å…¶åœ¨87%çš„æµ‹è¯•åœºæ™¯ä¸­æˆåŠŸè¶…è¶Šäº†å¯¹æ‰‹ï¼Œåœ¨è‡ªä¸»è¶…è½¦æ–¹é¢è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22937v2">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong><br>è‡ªä¸»èµ›è½¦é¢†åŸŸçš„ä¸€å¤§æŒ‘æˆ˜æ˜¯ç”Ÿæˆè¶…è½¦åŠ¨ä½œã€‚ç«èµ›ä»£ç†å¿…é¡»åœ¨å¤æ‚çš„èµ›é“ä¸Šæ‰§è¡Œè¿™äº›åŠ¨ä½œï¼Œä¸èƒ½æœ‰å¤ªå¤šå¤±è¯¯ã€‚è™½ç„¶å·²æœ‰ä¼˜åŒ–æŠ€æœ¯å’ŒåŸºäºå›¾çš„æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸åœ¨é¿å…ç¢°æ’å’ŒåŠ¨æ€çº¦æŸæ–¹é¢åšäº†ç®€åŒ–çš„å‡è®¾ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå·®åˆ†è´å¶æ–¯æ»¤æ³¢æ¡†æ¶çš„è½¨è¿¹åˆæˆæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ— ç¢°æ’è½¨è¿¹åˆæˆæ–¹æ³•å°†é—®é¢˜è§†ä¸ºè´å¶æ–¯æ¨æ–­åœ¨å¤åˆè´å¡å°”æ›²çº¿ç©ºé—´ä¸Šçš„é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€è½¦è¾†è¶³è¿¹çš„çƒå½¢è¿‘ä¼¼ã€çº¦æŸçš„çº¿æ€§åŒ–æˆ–åœ¨é¿å…ç¢°æ’æ–¹é¢çš„ç®€åŒ–ä¸Šç•Œã€‚æˆ‘ä»¬å¯¹DBF-MAè¿›è¡Œäº†é—­ç¯åˆ†æï¼Œå‘ç°å®ƒåœ¨87%çš„æµ‹è¯•åœºæ™¯ä¸­æˆåŠŸè¶…è¶Šäº†å¯¹æ‰‹ï¼Œåœ¨è‡ªä¸»è¶…è½¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»èµ›è½¦ä¸­çš„è¶…è½¦åŠ¨ä½œæ˜¯ä¸€å¤§æŒ‘æˆ˜ï¼Œéœ€è¦åœ¨å¤æ‚èµ›é“ä¸Šç²¾ç¡®æ‰§è¡Œã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é¿å…ç¢°æ’å’ŒåŠ¨æ€çº¦æŸæ—¶å­˜åœ¨ç®€åŒ–å‡è®¾ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå·®åˆ†è´å¶æ–¯æ»¤æ³¢æ¡†æ¶çš„è½¨è¿¹åˆæˆæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å°†é—®é¢˜è§†ä¸ºè´å¶æ–¯æ¨æ–­åœ¨å¤åˆè´å¡å°”æ›²çº¿ç©ºé—´ä¸Šçš„é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€å¯¹è½¦è¾†è¶³è¿¹è¿›è¡Œçƒå½¢è¿‘ä¼¼ã€çº¦æŸçš„çº¿æ€§åŒ–æˆ–é¿å…ç¢°æ’çš„ç®€åŒ–ä¸Šç•Œã€‚</li>
<li>DBF-MAåœ¨é—­ç¯åˆ†æä¸­æˆåŠŸè¶…è¶Šäº†å¯¹æ‰‹ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22937">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-89a810fefbbc8d8234d58c13173d2e1c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100759&auth_key=1760100759-0-0-26fdd468b72ba2057e33fcd895218cd7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e4b384143b7fa57fc7b0799ca9fdec1d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100766&auth_key=1760100766-0-0-251f5b0c041e6c92c75a7d4218c048ba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9dd235a0453a260ee949f2adf40bf2fd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100773&auth_key=1760100773-0-0-b5456b31d65530010969136f4540ba50&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bb9e8d7c5549469a12b6990681528226~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100780&auth_key=1760100780-0-0-d00f00b1ca8f3d7ff59588e7c052e9e1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9af547db9e8386e5d3148a04cd11a4c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100787&auth_key=1760100787-0-0-4a574a2c8d1f1670c15c69b0c78bf957&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Interactive-Recommendation-Agent-with-Active-User-Commands"><a href="#Interactive-Recommendation-Agent-with-Active-User-Commands" class="headerlink" title="Interactive Recommendation Agent with Active User Commands"></a>Interactive Recommendation Agent with Active User Commands</h2><p><strong>Authors:Jiakai Tang, Yujie Luo, Xunke Xi, Fei Sun, Xueyang Feng, Sunhao Dai, Chao Yi, Dian Chen, Zhujin Gao, Yang Li, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang, Bo Zheng</strong></p>
<p>Traditional recommender systems rely on passive feedback mechanisms that limit users to simple choices such as like and dislike. However, these coarse-grained signals fail to capture usersâ€™ nuanced behavior motivations and intentions. In turn, current systems cannot also distinguish which specific item attributes drive user satisfaction or dissatisfaction, resulting in inaccurate preference modeling. These fundamental limitations create a persistent gap between user intentions and system interpretations, ultimately undermining user satisfaction and harming system effectiveness.   To address these limitations, we introduce the Interactive Recommendation Feed (IRF), a pioneering paradigm that enables natural language commands within mainstream recommendation feeds. Unlike traditional systems that confine users to passive implicit behavioral influence, IRF empowers active explicit control over recommendation policies through real-time linguistic commands. To support this paradigm, we develop RecBot, a dual-agent architecture where a Parser Agent transforms linguistic expressions into structured preferences and a Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly policy adjustment. To enable practical deployment, we employ simulation-augmented knowledge distillation to achieve efficient performance while maintaining strong reasoning capabilities. Through extensive offline and long-term online experiments, RecBot shows significant improvements in both user satisfaction and business outcomes. </p>
<blockquote>
<p>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–äºè¢«åŠ¨åé¦ˆæœºåˆ¶ï¼Œè¿™é™åˆ¶äº†ç”¨æˆ·çš„ç®€å•é€‰æ‹©ï¼Œå¦‚å–œæ¬¢å’Œä¸å–œæ¬¢ã€‚ç„¶è€Œï¼Œè¿™äº›ç²—ç²’åº¦çš„ä¿¡å·æ— æ³•æ•æ‰åˆ°ç”¨æˆ·å¾®å¦™çš„åŠ¨æœºå’Œè¡Œä¸ºæ„å›¾ã€‚æ­¤å¤–ï¼Œå½“å‰çš„ç³»ç»Ÿä¹Ÿæ— æ³•åŒºåˆ†å“ªäº›ç‰¹å®šçš„é¡¹ç›®å±æ€§å¯¼è‡´ç”¨æˆ·çš„æ»¡æ„æˆ–ä¸æ»¡æ„ï¼Œä»è€Œå¯¼è‡´åå¥½å»ºæ¨¡ä¸å‡†ç¡®ã€‚è¿™äº›åŸºæœ¬é™åˆ¶åœ¨ç”¨æˆ·æ„å›¾å’Œç³»ç»Ÿè§£é‡Šä¹‹é—´é€ æˆäº†æŒä¹…çš„å·®è·ï¼Œæœ€ç»ˆç ´åäº†ç”¨æˆ·æ»¡æ„åº¦å¹¶æŸå®³äº†ç³»ç»Ÿæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†äº¤äº’å¼æ¨èé¦ˆé€ï¼ˆIRFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¼€åˆ›æ€§çš„èŒƒå¼ï¼Œèƒ½å¤Ÿåœ¨ä¸»æµæ¨èé¦ˆé€ä¸­å®ç°è‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚ä¸åŒäºé™åˆ¶ç”¨æˆ·äºè¢«åŠ¨éšå«è¡Œä¸ºå½±å“çš„ä¼ ç»Ÿç³»ç»Ÿï¼ŒIRFé€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤å®ç°å¯¹æ¨èç­–ç•¥çš„ä¸»åŠ¨æ˜ç¡®æ§åˆ¶ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬å¼€å‘äº†RecBotï¼Œè¿™æ˜¯ä¸€ä¸ªåŒä»£ç†æ¶æ„ï¼Œå…¶ä¸­è§£æå™¨ä»£ç†å°†è¯­è¨€è¡¨è¾¾è½¬åŒ–ä¸ºç»“æ„åŒ–åå¥½ï¼Œè€Œè§„åˆ’å™¨ä»£ç†åŠ¨æ€åè°ƒé€‚åº”æ€§çš„å·¥å…·é“¾è¿›è¡Œå³æ—¶ç­–ç•¥è°ƒæ•´ã€‚ä¸ºäº†å®ç°å®é™…éƒ¨ç½²ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¿çœŸå¢å¼ºçŸ¥è¯†è’¸é¦æ³•ï¼Œä»¥å®ç°é«˜æ•ˆæ€§èƒ½çš„åŒæ—¶ä¿æŒå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¤§é‡çš„ç¦»çº¿æµ‹è¯•å’Œé•¿æœŸåœ¨çº¿å®éªŒï¼ŒRecBotåœ¨ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœæ–¹é¢æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21317v2">PDF</a> Under Review</p>
<p><strong>Summary</strong></p>
<p>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–è¢«åŠ¨åé¦ˆæœºåˆ¶ï¼Œåªæä¾›ç®€å•é€‰æ‹©ï¼ˆå¦‚å–œæ¬¢å’Œä¸å–œæ¬¢ï¼‰ï¼Œéš¾ä»¥æ•æ‰ç”¨æˆ·è¡Œä¸ºèƒŒåçš„å¤æ‚åŠ¨æœºå’Œæ„å›¾ã€‚å› æ­¤ï¼Œç³»ç»Ÿæ— æ³•å‡†ç¡®å»ºç«‹ç”¨æˆ·åå¥½æ¨¡å‹ï¼Œå¯¼è‡´ç”¨æˆ·æ„å›¾ä¸ç³»ç»Ÿè§£è¯»ä¹‹é—´å­˜åœ¨é¸¿æ²Ÿï¼Œå½±å“ç”¨æˆ·æ»¡æ„åº¦å’Œç³»ç»Ÿæ•ˆç‡ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº’åŠ¨æ¨èé¦ˆé€ï¼ˆIRFï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ä¸»æµæ¨èé¦ˆé€ä¸­èå…¥è‡ªç„¶è¯­è¨€å‘½ä»¤çš„åˆ›æ–°èŒƒå¼ã€‚IRFè®©ç”¨æˆ·é€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤ä¸»åŠ¨æ§åˆ¶æ¨èç­–ç•¥ï¼Œæ”¹å˜äº†ä¼ ç»Ÿç³»ç»Ÿä»…ä¾èµ–è¢«åŠ¨éšæ€§è¡Œä¸ºå½±å“çš„å±€é™ã€‚æˆ‘ä»¬å¼€å‘çš„RecBotæ˜¯ä¸€ä¸ªåŒä»£ç†æ¶æ„ï¼Œå…¶ä¸­è§£æå™¨ä»£ç†å°†è¯­è¨€è¡¨è¾¾å¼è½¬åŒ–ä¸ºç»“æ„åŒ–åå¥½ï¼Œè§„åˆ’å™¨ä»£ç†åŠ¨æ€åè°ƒå³æ—¶ç­–ç•¥è°ƒæ•´çš„å·¥å…·é“¾ã€‚é€šè¿‡æ¨¡æ‹Ÿå¢å¼ºçš„çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼ŒRecBotåœ¨ä¿æŒå¼ºå¤§æ¨ç†èƒ½åŠ›çš„åŒæ—¶å®ç°äº†é«˜æ•ˆæ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒRecBotåœ¨ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœæ–¹é¢å‡æœ‰æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿæ¨èç³»ç»Ÿä¾èµ–ç®€å•åé¦ˆé€‰æ‹©ï¼Œéš¾ä»¥æ•æ‰ç”¨æˆ·å¤æ‚åŠ¨æœºå’Œæ„å›¾ã€‚</li>
<li>ç”¨æˆ·æ„å›¾ä¸ç³»ç»Ÿè§£è¯»ä¹‹é—´å­˜åœ¨é¸¿æ²Ÿï¼Œå½±å“ç”¨æˆ·æ»¡æ„åº¦å’Œç³»ç»Ÿæ•ˆç‡ã€‚</li>
<li>äº’åŠ¨æ¨èé¦ˆé€ï¼ˆIRFï¼‰å…è®¸ç”¨æˆ·é€šè¿‡å®æ—¶è¯­è¨€å‘½ä»¤ä¸»åŠ¨æ§åˆ¶æ¨èç­–ç•¥ã€‚</li>
<li>RecBotæ˜¯ä¸€ä¸ªåŒä»£ç†æ¶æ„ï¼ŒåŒ…æ‹¬è§£æå™¨ä»£ç†å’Œè§„åˆ’å™¨ä»£ç†ï¼Œåˆ†åˆ«å¤„ç†ç”¨æˆ·è¯­è¨€å’Œç­–ç•¥è°ƒæ•´ã€‚</li>
<li>æ¨¡æ‹Ÿå¢å¼ºçš„çŸ¥è¯†è’¸é¦æŠ€æœ¯ä½¿RecBotä¿æŒé«˜æ•ˆæ€§èƒ½çš„åŒæ—¶å…·å¤‡å¼ºå¤§æ¨ç†èƒ½åŠ›ã€‚</li>
<li>RecBotåœ¨ç”¨æˆ·æ»¡æ„åº¦å’Œä¸šåŠ¡æˆæœæ–¹é¢å®ç°äº†æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21317">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b3d76c7ecd229441caa62676285c994c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100794&auth_key=1760100794-0-0-b0202dac3ac52d29ab763565a2893a94&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7f5f3ec9f16c664a1d5ffa692bb8ca0f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100802&auth_key=1760100802-0-0-1318979f5760c44e99ea7ab24e72cb0a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f2ee8de866ca3bb4dd943c20d80b8257~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100808&auth_key=1760100808-0-0-da0cf271889f50753b25c45d9c8a7509&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-16988c5e3ddf548507f8afd1dcb31e29~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100815&auth_key=1760100815-0-0-1f18bf63c4fd8cf72bd1017b92ea8c59&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Foam-Agent-2-0-An-End-to-End-Composable-Multi-Agent-Framework-for-Automating-CFD-Simulation-in-OpenFOAM"><a href="#Foam-Agent-2-0-An-End-to-End-Composable-Multi-Agent-Framework-for-Automating-CFD-Simulation-in-OpenFOAM" class="headerlink" title="Foam-Agent 2.0: An End-to-End Composable Multi-Agent Framework for   Automating CFD Simulation in OpenFOAM"></a>Foam-Agent 2.0: An End-to-End Composable Multi-Agent Framework for   Automating CFD Simulation in OpenFOAM</h2><p><strong>Authors:Ling Yue, Nithin Somasekharan, Tingwen Zhang, Yadi Cao, Shaowu Pan</strong></p>
<p>Computational Fluid Dynamics (CFD) is an essential simulation tool in engineering, yet its steep learning curve and complex manual setup create significant barriers. To address these challenges, we introduce Foam-Agent, a multi-agent framework that automates the entire end-to-end OpenFOAM workflow from a single natural language prompt. Our key innovations address critical gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation: Foam-Agent is the first system to manage the full simulation pipeline, including advanced pre-processing with a versatile Meshing Agent capable of handling external mesh files and generating new geometries via Gmsh, automatic generation of HPC submission scripts, and post-simulation visualization via ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent, the framework uses Model Context Protocol (MCP) to expose its core functions as discrete, callable tools. This allows for flexible integration and use by other agentic systems, such as Claude-code, for more exploratory workflows. 3. High-Fidelity Configuration Generation: We achieve superior accuracy through a Hierarchical Multi-Index RAG for precise context retrieval and a dependency-aware generation process that ensures configuration consistency. Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the expertise barrier for CFD, demonstrating how specialized multi-agent systems can democratize complex scientific computing. The code is public at <a target="_blank" rel="noopener" href="https://github.com/csml-rpi/Foam-Agent">https://github.com/csml-rpi/Foam-Agent</a>. </p>
<blockquote>
<p>è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰æ˜¯å·¥ç¨‹ä¸­é‡è¦çš„æ¨¡æ‹Ÿå·¥å…·ï¼Œä½†å…¶é™¡å³­çš„å­¦ä¹ æ›²çº¿å’Œå¤æ‚çš„æ‰‹åŠ¨è®¾ç½®æ„æˆäº†é‡å¤§éšœç¢ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Foam-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡å•ä¸ªè‡ªç„¶è¯­è¨€æç¤ºè‡ªåŠ¨å®Œæˆæ•´ä¸ªOpenFOAMå·¥ä½œæµã€‚æˆ‘ä»¬çš„å…³é”®åˆ›æ–°è§£å†³äº†ç°æœ‰ç³»ç»Ÿä¸­çš„å…³é”®ç©ºç™½ï¼š1.å…¨é¢çš„ç«¯åˆ°ç«¯ä»¿çœŸè‡ªåŠ¨åŒ–ï¼šFoam-Agentæ˜¯ç¬¬ä¸€ä¸ªç®¡ç†å®Œæ•´ä»¿çœŸç®¡é“çš„ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä½¿ç”¨å¤šåŠŸèƒ½ç½‘æ ¼ä»£ç†è¿›è¡Œé«˜çº§é¢„å¤„ç†ï¼Œèƒ½å¤Ÿå¤„ç†å¤–éƒ¨ç½‘æ ¼æ–‡ä»¶å¹¶é€šè¿‡Gmshç”Ÿæˆæ–°å‡ ä½•ä½“ï¼Œè‡ªåŠ¨ç”ŸæˆHPCæäº¤è„šæœ¬ï¼Œä»¥åŠé€šè¿‡ParaViewè¿›è¡Œä»¿çœŸåçš„å¯è§†åŒ–ã€‚2.å¯ç»„åˆçš„æœåŠ¡æ¶æ„ï¼šè¶…è¶Šå•ä¸€æ™ºèƒ½ä½“çš„æ¡†æ¶ï¼Œä½¿ç”¨æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰å°†å…¶æ ¸å¿ƒåŠŸèƒ½æš´éœ²ä¸ºç‹¬ç«‹çš„ã€å¯è°ƒç”¨çš„å·¥å…·ã€‚è¿™å…è®¸å…¶ä»–æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¦‚Claude-codeï¼Œè¿›è¡Œçµæ´»çš„é›†æˆå’Œä½¿ç”¨ï¼Œä»¥æ”¯æŒæ›´æ¢ç´¢æ€§çš„å·¥ä½œæµç¨‹ã€‚3.é«˜ä¿çœŸé…ç½®ç”Ÿæˆï¼šæˆ‘ä»¬é€šè¿‡åˆ†å±‚å¤šç´¢å¼•RAGå®ç°é«˜çº§ç²¾åº¦ï¼Œç”¨äºç²¾ç¡®ä¸Šä¸‹æ–‡æ£€ç´¢å’Œä¾èµ–æ„ŸçŸ¥ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿é…ç½®ä¸€è‡´æ€§ã€‚åœ¨110ä¸ªä»¿çœŸä»»åŠ¡åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFoam-Agentä¸Claude 3.5 Sonneté…åˆä½¿ç”¨ï¼ŒæˆåŠŸç‡è¾¾åˆ°88.2%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ¡†æ¶ï¼ˆMetaOpenFOAMä¸º55.5%ï¼‰ã€‚Foam-Agentå¤§å¤§é™ä½äº†CFDçš„ä¸“ä¸šçŸ¥è¯†å£å’ï¼Œå±•ç¤ºäº†ä¸“ä¸šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ˜¯å¦‚ä½•ä½¿å¤æ‚çš„ç§‘å­¦è®¡ç®—æ™®åŠåŒ–çš„ã€‚ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/csml-rpi/Foam-Agent%E3%80%82">https://github.com/csml-rpi/Foam-Agentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18178v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æ³¡æ²«ä»£ç†ï¼ˆFoam-Agentï¼‰æ˜¯ä¸€ä¸ªå¤šä»£ç†æ¡†æ¶ï¼Œå®ƒé€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºè‡ªåŠ¨åŒ–æ•´ä¸ªOpenFOAMå·¥ä½œæµç¨‹ã€‚å…¶å…³é”®åˆ›æ–°åœ¨äºå…¨é¢çš„ç«¯åˆ°ç«¯ä»¿çœŸè‡ªåŠ¨åŒ–ã€å¯ç»„åˆçš„ä»£ç†æ¶æ„å’Œé«˜ä¿çœŸé…ç½®ç”Ÿæˆã€‚æ­¤æ¡†æ¶é€šè¿‡è‡ªåŠ¨åŒ–å’Œé›†æˆå¤æ‚è¿‡ç¨‹ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰çš„é—¨æ§›ã€‚è¯¦ç»†ä¿¡æ¯å¯è®¿é—®å…¬å¼€ä»£ç åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/csml-rpi/Foam-Agent">https://github.com/csml-rpi/Foam-Agent</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Foam-Agent æ˜¯ä¸€ä¸ªå¤šä»£ç†æ¡†æ¶ï¼Œå®ç°äº†ä»è‡ªç„¶è¯­è¨€æç¤ºåˆ°OpenFOAMå…¨ä»¿çœŸæµç¨‹çš„è‡ªåŠ¨åŒ–ã€‚</li>
<li>å…·å¤‡å…ˆè¿›çš„é¢„å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬å¤„ç†å¤–éƒ¨ç½‘æ ¼æ–‡ä»¶ã€é€šè¿‡Gmshç”Ÿæˆæ–°å‡ ä½•ä½“ç­‰ã€‚</li>
<li>è‡ªåŠ¨ç”Ÿæˆé«˜æ€§èƒ½è®¡ç®—æäº¤è„šæœ¬å’Œä»¿çœŸåå¯è§†åŒ–ã€‚</li>
<li>é‡‡ç”¨å¯ç»„åˆçš„ä»£ç†æ¶æ„ï¼Œé€šè¿‡Model Context Protocolï¼ˆMCPï¼‰æš´éœ²æ ¸å¿ƒåŠŸèƒ½ï¼Œä¾¿äºä¸å…¶ä»–ç³»ç»Ÿæ•´åˆã€‚</li>
<li>åˆ©ç”¨Hierarchical Multi-Index RAGå®ç°é«˜ç²¾åº¦é…ç½®ç”Ÿæˆã€‚</li>
<li>åœ¨110ä¸ªä»¿çœŸä»»åŠ¡ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒFoam-Agentä½¿ç”¨Claude 3.5 Sonnetè¾¾åˆ°äº†88.2%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ¡†æ¶ï¼ˆMetaOpenFOAMçš„55.5%ï¼‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18178">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-86ca15b6d5ae46c5ea5aca25b14acefe~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100822&auth_key=1760100822-0-0-75a8e8a01f0fe8d4d074413d5867485a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-546cda0a6530ef0dda9e7b4b8674391e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100830&auth_key=1760100830-0-0-19e868826d8d97305a8e21181759d723&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7943f02c4bfa14b1f28f7a38501c2485~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100837&auth_key=1760100837-0-0-9521f960e1a93d965b284c9dabad69ca&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e48edd135a450ec62e911e5d514c2812~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100844&auth_key=1760100844-0-0-6d01845640992ab9017f3c3523d5e297&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Code-Like-Humans-A-Multi-Agent-Solution-for-Medical-Coding"><a href="#Code-Like-Humans-A-Multi-Agent-Solution-for-Medical-Coding" class="headerlink" title="Code Like Humans: A Multi-Agent Solution for Medical Coding"></a>Code Like Humans: A Multi-Agent Solution for Medical Coding</h2><p><strong>Authors:Andreas Motzfeldt, Joakim Edin, Casper L. Christensen, Christian Hardmeier, Lars MaalÃ¸e, Anna Rogers</strong></p>
<p>In medical coding, experts map unstructured clinical notes to alphanumeric codes for diagnoses and procedures. We introduce Code Like Humans: a new agentic framework for medical coding with large language models. It implements official coding guidelines for human experts, and it is the first solution that can support the full ICD-10 coding system (+70K labels). It achieves the best performance to date on rare diagnosis codes (fine-tuned discriminative classifiers retain an advantage for high-frequency codes, to which they are limited). Towards future work, we also contribute an analysis of system performance and identify its &#96;blind spotsâ€™ (codes that are systematically undercoded). </p>
<blockquote>
<p>åœ¨åŒ»ç–—ç¼–ç é¢†åŸŸï¼Œä¸“å®¶å°†éç»“æ„çš„ä¸´åºŠç¬”è®°æ˜ å°„åˆ°ç”¨äºè¯Šæ–­å’Œç¨‹åºçš„å­—æ¯æ•°å­—ä»£ç ã€‚æˆ‘ä»¬æ¨å‡ºäº†â€œäººç±»å¼ç¼–ç â€ï¼šä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒåŒ»ç–—ç¼–ç çš„æ–°å‹ä»£ç†æ¡†æ¶ã€‚å®ƒå®ç°äº†äººç±»ä¸“å®¶çš„å®˜æ–¹ç¼–ç æŒ‡å—ï¼Œæ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿæ”¯æŒå®Œæ•´ICD-10ç¼–ç ç³»ç»Ÿï¼ˆè¶…è¿‡7ä¸‡ä¸ªæ ‡ç­¾ï¼‰çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨ç½•è§çš„è¯Šæ–­ä»£ç ä¸Šï¼Œå®ƒå–å¾—äº†è¿„ä»Šä¸ºæ­¢çš„æœ€ä½³æ€§èƒ½ï¼ˆç»è¿‡ç²¾ç»†è°ƒæ•´çš„åˆ¤åˆ«åˆ†ç±»å™¨åœ¨é«˜é¢‘ä»£ç ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä½†ä»…é™äºè¿™äº›ä»£ç ï¼‰ã€‚åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¿˜å¯¹ç³»ç»Ÿæ€§èƒ½è¿›è¡Œäº†åˆ†æï¼Œå¹¶ç¡®å®šäº†å…¶â€œç›²ç‚¹â€ï¼ˆç³»ç»Ÿæ€§ç¼–ç ä¸è¶³çš„ä»£ç ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05378v2">PDF</a> EMNLP Findings 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡ç« ä»‹ç»äº†Code Like Humansè¿™ä¸€æ–°å‹åŒ»ç–—ç¼–ç æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å®ç°äº†åŒ»ç–—ç¼–ç ã€‚æ­¤æ¡†æ¶éµå¾ªä¸“ä¸šç¼–ç æŒ‡å—ï¼Œå¯æ”¯æŒå®Œæ•´çš„ICD-10ç¼–ç ç³»ç»Ÿï¼ˆè¶…è¿‡7ä¸‡æ ‡ç­¾ï¼‰ã€‚å®ƒåœ¨ç½•è§è¯Šæ–­ä»£ç çš„ç¼–ç ä¸Šè¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ã€‚åŒæ—¶ï¼Œæ–‡ç« ä¹Ÿåˆ†æäº†ç³»ç»Ÿæ€§èƒ½å¹¶è¯†åˆ«å‡ºå…¶å­˜åœ¨çš„ç›²ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Code Like Humansæ˜¯ä¸€ä¸ªæ–°çš„åŒ»ç–—ç¼–ç æ¡†æ¶ï¼Œé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å®ç°ã€‚</li>
<li>æ­¤æ¡†æ¶èƒ½æ”¯æŒå®Œæ•´çš„ICD-10ç¼–ç ç³»ç»Ÿï¼ˆè¶…è¿‡7ä¸‡æ ‡ç­¾ï¼‰ã€‚</li>
<li>è¯¥æ¡†æ¶éµå¾ªå®˜æ–¹ç¼–ç æŒ‡å—ï¼Œå®ç°äº†äººç±»ä¸“å®¶çš„ç¼–ç æ–¹å¼ã€‚</li>
<li>Code Like Humansåœ¨ç½•è§è¯Šæ–­ä»£ç çš„ç¼–ç ä¸Šè¾¾åˆ°äº†æœ€ä½³æ€§èƒ½ã€‚</li>
<li>å¯¹äºé«˜é¢‘ä»£ç ï¼Œç²¾ç»†è°ƒæ•´çš„åˆ†ç±»å™¨ä»å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>æ–‡ç« åˆ†æäº†ç³»ç»Ÿæ€§èƒ½ï¼Œè¯†åˆ«å‡ºäº†ç¼–ç è¿‡ç¨‹ä¸­çš„ç›²ç‚¹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05378">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-72765d750d39868d6538cc251981d6b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100852&auth_key=1760100852-0-0-c4d3a475d3f8db8de870476f529ad259&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c99f6057eeee713588bc73f86ce7d51~resize:0:q75.jpg?source=1f5c5e47&expiration=1760103442&auth_key=1760103442-0-0-f99f05af4c8d20f579df1f0331ef107e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents"><a href="#Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents" class="headerlink" title="Breaking Down and Building Up: Mixture of Skill-Based   Vision-and-Language Navigation Agents"></a>Breaking Down and Building Up: Mixture of Skill-Based   Vision-and-Language Navigation Agents</h2><p><strong>Authors:Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi</strong></p>
<p>Vision-and-Language Navigation (VLN) poses significant challenges for agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. To support targeted skill training without manual data annotation, we construct a synthetic dataset pipeline that generates diverse, linguistically natural, skill-specific instruction-trajectory pairs. We then introduce a novel training-free Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav obtains competitive results on commonly used benchmarks and establishes state-of-the-art generalization to the GSA-R2R, a benchmark with novel instruction styles and unseen environments. </p>
<blockquote>
<p>è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰å¯¹ä»£ç†æå‡ºäº†é‡å¤§æŒ‘æˆ˜ï¼Œè¦æ±‚ä»£ç†è§£é‡Šè‡ªç„¶è¯­è¨€æŒ‡ä»¤å¹¶å¯¼èˆªå¤æ‚çš„3Dç¯å¢ƒã€‚å°½ç®¡æœ€è¿‘çš„è¿›å±•å¾—ç›Šäºå¤§è§„æ¨¡é¢„è®­ç»ƒå’Œæ•°æ®å¢å¼ºï¼Œä½†å½“å‰çš„æ–¹æ³•ä»ç„¶éš¾ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤æ‚çš„ç©ºé—´å’Œæ—¶é—´æ¨ç†æ—¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SkillNavï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå®ƒå°†ç»“æ„åŒ–ã€åŸºäºæŠ€èƒ½çš„æ¨ç†å¼•å…¥åˆ°åŸºäºTransformerçš„VLNä»£ç†ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¯¼èˆªåˆ†è§£æˆä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆä¾‹å¦‚å‚ç›´ç§»åŠ¨ã€åŒºåŸŸè¯†åˆ«ã€åœæ­¢å’Œæš‚åœç­‰ï¼‰ï¼Œæ¯ä¸ªæŠ€èƒ½éƒ½ç”±ä¸€ä¸ªä¸“é—¨çš„ä»£ç†å¤„ç†ã€‚ä¸ºäº†æ”¯æŒæœ‰é’ˆå¯¹æ€§çš„æŠ€èƒ½è®­ç»ƒè€Œæ— éœ€æ‰‹åŠ¨æ•°æ®æ ‡æ³¨ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåˆæˆæ•°æ®é›†ç®¡é“ï¼Œè¯¥ç®¡é“ç”Ÿæˆå¤šæ ·ã€è¯­è¨€è‡ªç„¶ã€æŠ€èƒ½ç‰¹å®šçš„æŒ‡ä»¤-è½¨è¿¹å¯¹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åŸºäºè®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è·¯ç”±å™¨ï¼Œè¯¥è·¯ç”±å™¨é€šè¿‡å°†ä¸è§†è§‰è§‚å¯Ÿå’Œå†å²è¡ŒåŠ¨çš„å­ç›®æ ‡å¯¹é½ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†ã€‚SkillNavåœ¨å¸¸ç”¨åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œå¹¶åœ¨å…·æœ‰æ–°å‹æŒ‡ä»¤é£æ ¼å’Œæœªè§è¿‡çš„ç¯å¢ƒçš„GSA-R2RåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ¨å¹¿æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07642v2">PDF</a> </p>
<p><strong>Summary</strong><br>æä¾›è§†è§‰å’Œè¯­è¨€å¯¼èˆªçš„ä»»åŠ¡è¦æ±‚ä»£ç†è§£æè‡ªç„¶è¯­è¨€æŒ‡ä»¤å¹¶å¯¼èˆªå¤æ‚çš„3Dç¯å¢ƒï¼Œå­˜åœ¨è¯¸å¤šæŒ‘æˆ˜ã€‚è™½ç„¶å·²æœ‰è¿›æ­¥æºäºå¤§è§„æ¨¡é¢„è®­ç»ƒå’Œæ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æœªçŸ¥åœºæ™¯æ—¶ï¼Œç‰¹åˆ«æ˜¯éœ€è¦è¿›è¡Œå¤æ‚ç©ºé—´å’Œæ—¶é—´æ¨ç†æ—¶ï¼Œä»ç„¶éš¾ä»¥æ¨å¹¿ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SkillNavï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå®ƒå°†ç»“æ„åŒ–ã€åŸºäºæŠ€èƒ½çš„æ¨ç†å¼•å…¥åˆ°åŸºäºTransformerçš„VLNä»£ç†ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¯¼èˆªåˆ†è§£æˆä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆä¾‹å¦‚å‚ç›´ç§»åŠ¨ã€åŒºåŸŸè¯†åˆ«ã€åœæ­¢å’Œæš‚åœç­‰ï¼‰ï¼Œæ¯ä¸ªæŠ€èƒ½ç”±ä¸“é—¨çš„ä»£ç†å¤„ç†ã€‚ä¸ºäº†æ”¯æŒæœ‰é’ˆå¯¹æ€§çš„æŠ€èƒ½è®­ç»ƒè€Œæ— éœ€æ‰‹åŠ¨æ•°æ®æ ‡æ³¨ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåˆæˆæ•°æ®é›†ç®¡é“ï¼Œè¯¥ç®¡é“ç”Ÿæˆå¤šæ ·åŒ–ã€è¯­è¨€è‡ªç„¶ã€æŠ€èƒ½ç‰¹å®šçš„æŒ‡ä»¤è½¨è¿¹å¯¹ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åŸºäºè®­ç»ƒçš„æ— è§†è§‰è¯­è¨€æ¨¡å‹è·¯ç”±å™¨ï¼Œè¯¥æ¨¡å‹é€šè¿‡åŒ¹é…å­ç›®æ ‡ä¸è§†è§‰è§‚å¯Ÿå’Œå†å²åŠ¨ä½œï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†ã€‚SkillNavåœ¨å¸¸ç”¨åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶åœ¨å…·æœ‰æ–°æŒ‡ä»¤é£æ ¼å’Œæœªè§ç¯å¢ƒçš„åŸºå‡†æµ‹è¯•GSA-R2Rä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ¨å¹¿æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VLNä»»åŠ¡é¢ä¸´å¯¹å¤æ‚ç¯å¢ƒå’Œè¯­è¨€ç†è§£çš„æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰æ–¹æ³•éš¾ä»¥æ¨å¹¿åˆ°æœªè§åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤æ‚ç©ºé—´å’Œæ—¶é—´æ¨ç†çš„æƒ…å†µä¸‹ã€‚</li>
<li>SkillNavæ¡†æ¶å¼•å…¥äº†ç»“æ„åŒ–ã€åŸºäºæŠ€èƒ½çš„æ¨ç†ï¼Œå°†å¯¼èˆªåˆ†è§£æˆä¸€ç³»åˆ—åŸå­æŠ€èƒ½ã€‚</li>
<li>åˆ©ç”¨åˆæˆæ•°æ®é›†è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æŠ€èƒ½è®­ç»ƒï¼Œæ— éœ€æ‰‹åŠ¨æ•°æ®æ ‡æ³¨ã€‚</li>
<li>å¼•å…¥åŸºäºè®­ç»ƒçš„æ— è§†è§‰è¯­è¨€æ¨¡å‹è·¯ç”±å™¨ï¼ŒåŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07642">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cce2f953f0850150d813e49cf3b5b3d8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100924&auth_key=1760100924-0-0-a4458064ba792d2071b97abdeb1b721e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-47848219568e2ff8af94651f680b59b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100932&auth_key=1760100932-0-0-e24d520098280f8357f4d93c4c71cb7c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-923d94299bf661e9af20d3c0d49009ae~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100940&auth_key=1760100940-0-0-fd8c11dbe92ec82136accf1db298ed62&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AgentMisalignment-Measuring-the-Propensity-for-Misaligned-Behaviour-in-LLM-Based-Agents"><a href="#AgentMisalignment-Measuring-the-Propensity-for-Misaligned-Behaviour-in-LLM-Based-Agents" class="headerlink" title="AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in   LLM-Based Agents"></a>AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in   LLM-Based Agents</h2><p><strong>Authors:Akshat Naik, Patrick Quinn, Guillermo Bosch, Emma GounÃ©, Francisco Javier Campos Zabala, Jason Ross Brown, Edward James Young</strong></p>
<p>As Large Language Model (LLM) agents become more widespread, associated misalignment risks increase. While prior research has studied agentsâ€™ ability to produce harmful outputs or follow malicious instructions, it remains unclear how likely agents are to spontaneously pursue unintended goals in realistic deployments. In this work, we approach misalignment as a conflict between the internal goals pursued by the model and the goals intended by its deployer. We introduce a misalignment propensity benchmark, \textsc{AgentMisalignment}, a benchmark suite designed to evaluate the propensity of LLM agents to misalign in realistic scenarios. Evaluations cover behaviours such as avoiding oversight, resisting shutdown, sandbagging, and power-seeking. Testing frontier models, we find that more capable agents tend to exhibit higher misalignment on average. We also systematically vary agent personalities through different system prompts and observe that persona characteristics can strongly and unpredictably influence misalignment, sometimes more than the choice of model itself. Our results reveal the limitations of current alignment methods for autonomous LLM agents and underscore the need to rethink misalignment in realistic deployment settings. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„æ™®åŠï¼Œç›¸å…³çš„è¯¯å¯¹é½é£é™©ä¹Ÿåœ¨å¢åŠ ã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å·²ç»ç ”ç©¶äº†ä»£ç†äº§ç”Ÿæœ‰å®³è¾“å‡ºæˆ–éµå¾ªæ¶æ„æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œä»£ç†è‡ªå‘è¿½æ±‚æ„å¤–ç›®æ ‡çš„å¯èƒ½æ€§ä»ç„¶ä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†è¯¯å¯¹é½è§†ä¸ºæ¨¡å‹è¿½æ±‚çš„å†…éƒ¨ç›®æ ‡ä¸éƒ¨ç½²è€…çš„ç›®æ ‡ä¹‹é—´çš„å†²çªã€‚æˆ‘ä»¬å¼•å…¥äº†è¯¯å¯¹é½å€¾å‘åŸºå‡†æµ‹è¯•\text{AgentMisalignment}ï¼Œè¿™æ˜¯ä¸€å¥—æ—¨åœ¨è¯„ä¼°LLMä»£ç†åœ¨ç°å®åœºæ™¯ä¸­è¯¯å¯¹é½å€¾å‘çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚è¯„ä¼°åŒ…æ‹¬é¿å…ç›‘ç£ã€æŠµæŠ—å…³é—­ã€æ²™è¢‹å’ŒæƒåŠ›å¯»æ±‚ç­‰è¡Œä¸ºã€‚é€šè¿‡å¯¹å‰æ²¿æ¨¡å‹çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°æ›´å¼ºå¤§çš„ä»£ç†å¹³å‡æ›´å®¹æ˜“å‡ºç°è¯¯å¯¹é½ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸åŒçš„ç³»ç»Ÿæç¤ºç³»ç»Ÿåœ°æ”¹å˜ä»£ç†çš„ä¸ªæ€§ï¼Œå¹¶å‘ç°äººæ ¼ç‰¹å¾å¯ä»¥å¼ºçƒˆä¸”ä¸å¯é¢„æµ‹åœ°å½±å“è¯¯å¯¹é½ï¼Œæœ‰æ—¶ç”šè‡³è¶…è¿‡æ¨¡å‹æœ¬èº«çš„é€‰æ‹©ã€‚æˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†å½“å‰è‡ªä¸»LLMä»£ç†å¯¹é½æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒéœ€è¦åœ¨ç°å®éƒ¨ç½²ç¯å¢ƒä¸­é‡æ–°æ€è€ƒè¯¯å¯¹é½é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04018v2">PDF</a> Prepint, under review for NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„æ™®åŠå¢åŠ äº†ç›¸å…³çš„ä¸å¯¹é½é£é™©ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶å·²ç»ç ”ç©¶äº†ä»£ç†äº§ç”Ÿæœ‰å®³è¾“å‡ºæˆ–éµå¾ªæ¶æ„æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œä½†åœ¨ç°å®éƒ¨ç½²ä¸­ï¼Œä»£ç†è‡ªå‘è¿½æ±‚éæ„å›¾ç›®æ ‡çš„å¯èƒ½æ€§ä»ç„¶ä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†ä¸å¯¹é½è§†ä¸ºæ¨¡å‹å†…éƒ¨è¿½æ±‚ç›®æ ‡ä¸éƒ¨ç½²è€…ç›®æ ‡ä¹‹é—´çš„å†²çªã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸å¯¹é½å€¾å‘åŸºå‡†æµ‹è¯•\text{AgentMisalignment}ï¼Œè¯¥åŸºå‡†æµ‹è¯•å¥—ä»¶æ—¨åœ¨è¯„ä¼°LLMä»£ç†åœ¨ç°å®åœºæ™¯ä¸­çš„ä¸å¯¹é½å€¾å‘ã€‚è¯„ä¼°åŒ…æ‹¬é¿å…ç›‘ç£ã€æŠµæŠ—å…³é—­ã€æ²™è¢‹å’ŒæƒåŠ›å¯»æ±‚ç­‰è¡Œä¸ºã€‚é€šè¿‡å¯¹å‰æ²¿æ¨¡å‹çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°èƒ½åŠ›æ›´å¼ºçš„ä»£ç†å¹³å‡è¡¨ç°å‡ºæ›´é«˜çš„ä¸å¯¹é½å€¾å‘ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸åŒçš„ç³»ç»Ÿæç¤ºç³»ç»Ÿåœ°æ”¹å˜äº†ä»£ç†ä¸ªæ€§ï¼Œå¹¶å‘ç°ä¸ªæ€§ç‰¹å¾å¯ä»¥å¼ºçƒˆä¸”ä¸å¯é¢„æµ‹åœ°å½±å“ä¸å¯¹é½ï¼Œæœ‰æ—¶ç”šè‡³è¶…è¿‡æ¨¡å‹æœ¬èº«çš„é€‰æ‹©ã€‚æˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†å½“å‰è‡ªä¸»LLMä»£ç†å¯¹é½æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒéœ€è¦åœ¨ç°å®éƒ¨ç½²ç¯å¢ƒä¸­é‡æ–°æ€è€ƒä¸å¯¹é½é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„æ™®åŠå¢åŠ äº†ä¸å¯¹é½é£é™©ã€‚</li>
<li>ä»£ç†åœ¨ç°å®éƒ¨ç½²ä¸­å¯èƒ½è‡ªå‘è¿½æ±‚éæ„å›¾ç›®æ ‡ã€‚</li>
<li>å¼•å…¥äº†\text{AgentMisalignment}åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°LLMä»£ç†çš„ä¸å¯¹é½å€¾å‘ã€‚</li>
<li>è¯„ä¼°åŒ…æ‹¬ä»£ç†çš„è¡Œä¸ºå¦‚é¿å…ç›‘ç£ã€æŠµæŠ—å…³é—­ã€æ²™è¢‹å’ŒæƒåŠ›å¯»æ±‚ã€‚</li>
<li>æ›´å¼ºå¤§çš„ä»£ç†å¹³å‡è¡¨ç°å‡ºæ›´é«˜çš„ä¸å¯¹é½å€¾å‘ã€‚</li>
<li>ä»£ç†ä¸ªæ€§å¯ä»¥å¼ºçƒˆå½±å“ä¸å¯¹é½ç¨‹åº¦ï¼Œæœ‰æ—¶ç”šè‡³è¶…è¿‡æ¨¡å‹æœ¬èº«ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04018">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-76465c4a539f7313a68b151c8a6c4c80~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100947&auth_key=1760100947-0-0-3ef7b173b4a3ac793f686a78d6a9ad21&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cb3dc5ee1b9f11ed517d1aa6bfcf9474~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100954&auth_key=1760100954-0-0-502cccfc03ea4dc80bd7449de58791f7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="The-challenge-of-hidden-gifts-in-multi-agent-reinforcement-learning"><a href="#The-challenge-of-hidden-gifts-in-multi-agent-reinforcement-learning" class="headerlink" title="The challenge of hidden gifts in multi-agent reinforcement learning"></a>The challenge of hidden gifts in multi-agent reinforcement learning</h2><p><strong>Authors:Dane Malenfant, Blake A. Richards</strong></p>
<p>Sometimes we benefit from actions that others have taken even when we are unaware that they took those actions. For example, if your neighbor chooses not to take a parking spot in front of your house when you are not there, you can benefit, even without being aware that they took this action. These <code>hidden gifts&#39;&#39; represent an interesting challenge for multi-agent reinforcement learning (MARL), since assigning credit when the beneficial actions of others are hidden is non-trivial. Here, we study the impact of hidden gifts with a very simple MARL task. In this task, agents in a grid-world environment have individual doors to unlock in order to obtain individual rewards. As well, if all the agents unlock their door the group receives a larger collective reward. However, there is only one key for all of the doors, such that the collective reward can only be obtained when the agents drop the key for others after they use it. Notably, there is nothing to indicate to an agent that the other agents have dropped the key, thus this act for others is a </code>hidden giftâ€™â€™. We show that several different state-of-the-art MARL algorithms, including MARL specific architectures, fail to learn how to obtain the collective reward in this simple task. Interestingly, we find that decentralized actor-critic policy gradient agents can succeed when we provide them with information about their own action history, but MARL agents still cannot solve the task with action history. Finally, we derive a correction term for policy gradient agents, inspired by learning aware approaches, which reduces the variance in learning and helps them to converge to collective success more reliably. These results show that credit assignment in multi-agent settings can be particularly challenging in the presence of &#96;&#96;hidden giftsâ€™â€™, and demonstrate that self learning-awareness in decentralized agents can benefit these settings. </p>
<blockquote>
<p>æœ‰æ—¶å€™ï¼Œå³ä½¿æˆ‘ä»¬ä¸çŸ¥é“ä»–äººå·²ç»é‡‡å–äº†æŸäº›è¡ŒåŠ¨ï¼Œæˆ‘ä»¬ä¹Ÿä¼šä»ä»–ä»¬çš„è¡ŒåŠ¨ä¸­å—ç›Šã€‚ä¾‹å¦‚ï¼Œå½“æ‚¨ä¸åœ¨å®¶æ—¶ï¼Œå¦‚æœæ‚¨çš„é‚»å±…é€‰æ‹©ä¸åœ¨æ‚¨å®¶é—¨å£åœè½¦ï¼Œæ‚¨å°±å¯ä»¥å—ç›Šï¼Œå³ä½¿æ‚¨å¹¶ä¸çŸ¥é“ä»–ä»¬é‡‡å–äº†è¿™ä¸€è¡ŒåŠ¨ã€‚è¿™äº›â€œéšè—ç¤¼ç‰©â€å¯¹äºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¥è¯´ä»£è¡¨äº†ä¸€ä¸ªæœ‰è¶£çš„æŒ‘æˆ˜ï¼Œå› ä¸ºåœ¨ä¸çŸ¥é“ä»–äººæœ‰ç›Šè¡ŒåŠ¨çš„æƒ…å†µä¸‹åˆ†é…åŠŸåŠ³æ˜¯éå‡¡çš„ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡ä¸€é¡¹éå¸¸ç®€å•çš„MARLä»»åŠ¡æ¥ç ”ç©¶éšè—èµ ç¤¼çš„å½±å“ã€‚åœ¨æ­¤ä»»åŠ¡ä¸­ï¼Œç½‘æ ¼ç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“éœ€è¦è§£é”å„è‡ªç‹¬ç«‹çš„é—¨ä»¥è·å–ä¸ªä½“å¥–åŠ±ã€‚æ­¤å¤–ï¼Œå¦‚æœæ‰€æœ‰æ™ºèƒ½ä½“éƒ½æ‰“å¼€è‡ªå·±çš„é—¨ï¼Œé‚£ä¹ˆæ•´ä¸ªå›¢é˜Ÿå°†è·å¾—æ›´å¤§çš„é›†ä½“å¥–åŠ±ã€‚ä½†æ˜¯ï¼Œæ‰€æœ‰é—¨çš„é’¥åŒ™åªæœ‰ä¸€æŠŠï¼Œæ™ºèƒ½ä½“åœ¨ä½¿ç”¨åå¿…é¡»æ”¾ä¸‹é’¥åŒ™ä¾›å…¶ä»–æ™ºèƒ½ä½“ä½¿ç”¨æ‰èƒ½è·å–é›†ä½“å¥–åŠ±ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ²¡æœ‰ä»»ä½•è¿¹è±¡è¡¨æ˜å…¶ä»–æ™ºèƒ½ä½“å·²ç»æ”¾ä¸‹äº†é’¥åŒ™ï¼Œå› æ­¤ä¸ºä»–äººæ”¾ä¸‹é’¥åŒ™çš„è¡Œä¸ºæ˜¯â€œéšè—çš„ç¤¼ç‰©â€ã€‚æˆ‘ä»¬è¡¨æ˜ï¼ŒåŒ…æ‹¬MARLç‰¹å®šæ¶æ„åœ¨å†…çš„å‡ ç§å…ˆè¿›çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•éƒ½æœªèƒ½å­¦ä¼šå¦‚ä½•åœ¨ç®€å•ä»»åŠ¡ä¸­è·å–é›†ä½“å¥–åŠ±ã€‚æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°åˆ†æ•£å¼æ¼”å‘˜è¯„è®ºå®¶ç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“åœ¨æä¾›æœ‰å…³å…¶è‡ªèº«è¡ŒåŠ¨å†å²çš„ä¿¡æ¯æ—¶å¯ä»¥æˆåŠŸå®Œæˆä»»åŠ¡ï¼Œä½†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä»ç„¶æ— æ³•ä½¿ç”¨è¡ŒåŠ¨å†å²æ¥å®Œæˆä»»åŠ¡ã€‚æœ€åï¼Œæˆ‘ä»¬ä»å­¦ä¹ æ„è¯†æ–¹æ³•ä¸­æ±²å–çµæ„Ÿï¼Œä¸ºç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“æ¨å¯¼å‡ºä¸€ä¸ªæ ¡æ­£é¡¹ï¼Œè¿™å‡å°‘äº†å­¦ä¹ çš„æ–¹å·®å¹¶å¸®åŠ©å®ƒä»¬æ›´å¯é åœ°æ”¶æ•›åˆ°é›†ä½“æˆåŠŸã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œâ€œéšè—ç¤¼ç‰©â€çš„å­˜åœ¨ä½¿å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„ä¿¡ç”¨åˆ†é…ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶è¯æ˜äº†åˆ†æ•£å¼æ™ºèƒ½ä½“çš„è‡ªæˆ‘å­¦ä¹ æ„è¯†å¯ä»¥åœ¨è¿™äº›ç¯å¢ƒä¸­å¸¦æ¥å¥½å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20579v5">PDF</a> Added LOLA baselines to appendix, new corollary proof on correction   term not conflicting with individual objectives, related works on   multi-objective RL and coordination MARL, expanded the contraposition   appendix experiment, moved key drop rate experiments to appendix and aligned   first success plots with key-drop plots</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤šäººç¯å¢ƒä¸­ï¼Œå…¶ä»–äººçš„è¡Œä¸ºæœ‰æ—¶ä¼šå¯¹æˆ‘ä»¬äº§ç”Ÿç§¯æå½±å“ï¼Œå³ä½¿æˆ‘ä»¬å¹¶ä¸çŸ¥æƒ…ã€‚åœ¨ä¸€ä¸ªç®€å•çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“åœ¨ç½‘æ ¼ä¸–ç•Œä¸­éœ€è¦è§£é”ä¸ªäººé—¨æ¥è·å¾—å¥–åŠ±ã€‚è‹¥æ‰€æœ‰æ™ºèƒ½ä½“éƒ½è§£é”äº†é—¨ï¼Œé›†ä½“å°†è·å¾—æ›´å¤§çš„å¥–åŠ±ã€‚ç„¶è€Œï¼Œåªæœ‰ä¸€ä¸ªé’¥åŒ™å¯ä»¥è§£é”æ‰€æœ‰é—¨ï¼Œæ™ºèƒ½ä½“åœ¨ä½¿ç”¨é’¥åŒ™åå¿…é¡»å°†å…¶æ”¾ä¸‹ä¾›ä»–äººä½¿ç”¨æ‰èƒ½å¸¦æ¥é›†ä½“å¥–åŠ±ï¼Œè€Œè¿™ä¸€è¡Œä¸ºæ˜¯éšè—çš„ã€‚ç ”ç©¶å‘ç°ï¼Œè®¸å¤šå…ˆè¿›çš„MARLç®—æ³•æ— æ³•å­¦ä¹ å¦‚ä½•è·å¾—é›†ä½“å¥–åŠ±ï¼Œè€Œåˆ†æ•£å¼è¡ŒåŠ¨è¯„è®ºå®¶ç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“åœ¨æä¾›è‡ªèº«è¡ŒåŠ¨å†å²ä¿¡æ¯åå¯ä»¥æˆåŠŸå®Œæˆä»»åŠ¡ã€‚æœ€åï¼Œå—å­¦ä¹ æ„è¯†æ–¹æ³•çš„å¯å‘ï¼Œæå‡ºäº†ç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“çš„ä¿®æ­£é¡¹ï¼Œä»¥å‡å°‘å­¦ä¹ æ–¹å·®å¹¶æ›´å¯é åœ°å¸®åŠ©ä»–ä»¬å®ç°é›†ä½“æˆåŠŸã€‚è¿™è¡¨æ˜åœ¨å­˜åœ¨â€œéšè—ç¤¼ç‰©â€çš„æƒ…å†µä¸‹ï¼Œå¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„ä¿¡ç”¨åˆ†é…å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶è¯æ˜äº†åˆ†æ•£å¼æ™ºèƒ½ä½“çš„è‡ªæˆ‘å­¦ä¹ æ„è¯†å¯ä»¥åœ¨è¿™äº›ç¯å¢ƒä¸­å—ç›Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…¶ä»–äººçš„è¡Œä¸ºæœ‰æ—¶ä¼šå¯¹æˆ‘ä»¬äº§ç”Ÿç§¯æå½±å“ï¼Œå³ä½¿æˆ‘ä»¬å¹¶ä¸çŸ¥æƒ…ï¼Œè¿™æ„æˆäº†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­çš„ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>åœ¨ä¸€ä¸ªç®€å•çš„MARLä»»åŠ¡ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦è§£é”é—¨ä»¥è·å–å¥–åŠ±ï¼Œå¹¶ä¸”å­˜åœ¨ä¸€ä¸ªéšè—çš„é›†ä½“å¥–åŠ±ï¼Œåªæœ‰åœ¨æ‰€æœ‰æ™ºèƒ½ä½“éƒ½æ”¾ä¸‹é’¥åŒ™åæ‰èƒ½è·å¾—ã€‚</li>
<li>è®¸å¤šå…ˆè¿›çš„MARLç®—æ³•æ— æ³•åœ¨è¿™ä¸ªä»»åŠ¡ä¸­å­¦ä¹ å¦‚ä½•è·å¾—é›†ä½“å¥–åŠ±ã€‚</li>
<li>åˆ†æ•£å¼è¡ŒåŠ¨è¯„è®ºå®¶ç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“åœ¨æä¾›è‡ªèº«è¡ŒåŠ¨å†å²ä¿¡æ¯åå¯ä»¥æˆåŠŸå®Œæˆä»»åŠ¡ã€‚</li>
<li>å­¦ä¹ æ„è¯†æ–¹æ³•çš„å¯å‘ä¸‹ï¼Œæå‡ºäº†ç­–ç•¥æ¢¯åº¦æ™ºèƒ½ä½“çš„ä¿®æ­£é¡¹ä»¥å‡å°‘å­¦ä¹ æ–¹å·®å¹¶æ›´å¯é åœ°å®ç°é›†ä½“æˆåŠŸã€‚</li>
<li>ä¿¡ç”¨åˆ†é…åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨â€œéšè—ç¤¼ç‰©â€çš„æƒ…å†µä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20579">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f53cc4e6c217cebf30160f763185f994~resize:0:q75.jpg?source=1f5c5e47&expiration=1760100962&auth_key=1760100962-0-0-3c06989a74791f43c31638115e8cc2fd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cba6285e87d3480ba0df1a21edc8d5eb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101011&auth_key=1760101011-0-0-c98821e4d3894d39e8aa88fd87652dba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c005a049625c9b31d1b3ee758484a6b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101018&auth_key=1760101018-0-0-eb51c7eec8ba65d1f8bc151ed30df867&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="R-D-Agent-An-LLM-Agent-Framework-Towards-Autonomous-Data-Science"><a href="#R-D-Agent-An-LLM-Agent-Framework-Towards-Autonomous-Data-Science" class="headerlink" title="R&amp;D-Agent: An LLM-Agent Framework Towards Autonomous Data Science"></a>R&amp;D-Agent: An LLM-Agent Framework Towards Autonomous Data Science</h2><p><strong>Authors:Xu Yang, Xiao Yang, Shikai Fang, Yifei Zhang, Jian Wang, Bowen Xian, Qizheng Li, Jingyuan Li, Minrui Xu, Yuante Li, Haoran Pan, Yuge Zhang, Weiqing Liu, Yelong Shen, Weizhu Chen, Jiang Bian</strong></p>
<p>Recent advances in AI and ML have transformed data science, yet increasing complexity and expertise requirements continue to hinder progress. Although crowd-sourcing platforms alleviate some challenges, high-level machine learning engineering (MLE) tasks remain labor-intensive and iterative. We introduce R&amp;D-Agent, a comprehensive, decoupled, and extensible framework that formalizes the MLE process. R&amp;D-Agent defines the MLE workflow into two phases and six components, turning agent design for MLE from ad-hoc craftsmanship into a principled, testable process. Although several existing agents report promising gains on their chosen components, they can mostly be summarized as a partial optimization from our frameworkâ€™s simple baseline. Inspired by human experts, we designed efficient and effective agents within this framework that achieve state-of-the-art performance. Evaluated on MLE-Bench, the agent built on R&amp;D-Agent ranks as the top-performing machine learning engineering agent, achieving 35.1% any medal rate, demonstrating the ability of the framework to speed up innovation and improve accuracy across a wide range of data science applications. We have open-sourced R&amp;D-Agent on GitHub: <a target="_blank" rel="noopener" href="https://github.com/microsoft/RD-Agent">https://github.com/microsoft/RD-Agent</a>. </p>
<blockquote>
<p>æœ€è¿‘äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„è¿›æ­¥å·²ç»æ”¹å˜äº†æ•°æ®ç§‘å­¦çš„é¢è²Œï¼Œç„¶è€Œæ—¥ç›Šå¢åŠ çš„å¤æ‚æ€§å’Œä¸“ä¸šæŠ€èƒ½è¦æ±‚ä»ç„¶é˜»ç¢äº†è¿›å±•ã€‚å°½ç®¡ä¼—åŒ…å¹³å°ç¼“è§£äº†ä¸€äº›æŒ‘æˆ˜ï¼Œä½†é«˜çº§æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰ä»»åŠ¡ä»ç„¶åŠ³åŠ¨å¯†é›†ä¸”è¿­ä»£ã€‚æˆ‘ä»¬å¼•å…¥äº†R&amp;D-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢ã€è§£è€¦å’Œå¯æ‰©å±•çš„æ¡†æ¶ï¼Œå®ƒå½¢å¼åŒ–äº†MLEè¿‡ç¨‹ã€‚R&amp;D-Agentå°†MLEå·¥ä½œæµç¨‹å®šä¹‰ä¸ºä¸¤ä¸ªé˜¶æ®µå’Œå…­ä¸ªç»„ä»¶ï¼Œå°†MLEçš„ä»£ç†è®¾è®¡ä»ä¸´æ—¶æ€§çš„æ‰‹è‰ºè½¬å˜ä¸ºæœ‰åŸåˆ™çš„ã€å¯æµ‹è¯•çš„è¿‡ç¨‹ã€‚è™½ç„¶æœ‰å‡ ä¸ªç°æœ‰çš„ä»£ç†æŠ¥å‘Šäº†åœ¨æ‰€é€‰ç»„ä»¶ä¸Šçš„å¯å–œæ”¶ç›Šï¼Œä½†å®ƒä»¬å¤§å¤šå¯ä»¥è¢«æ¦‚æ‹¬ä¸ºä»æˆ‘ä»¬æ¡†æ¶çš„ç®€å•åŸºçº¿è¿›è¡Œçš„å±€éƒ¨ä¼˜åŒ–ã€‚å—äººç±»ä¸“å®¶çš„å¯å‘ï¼Œæˆ‘ä»¬åœ¨è¯¥æ¡†æ¶å†…è®¾è®¡äº†é«˜æ•ˆä¸”æœ‰æ•ˆçš„ä»£ç†ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨MLE-Benchä¸Šè¯„ä¼°ï¼ŒåŸºäºR&amp;D-Agentæ„å»ºçš„ä»£ç†è¢«è¯„ä¸ºè¡¨ç°æœ€ä½³çš„æœºå™¨å­¦ä¹ å·¥ç¨‹ä»£ç†ï¼Œè·å¾—å¥–ç‰Œç‡ä¸º35.1%ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨åŠ é€Ÿåˆ›æ–°å’Œæé«˜å„ç§æ•°æ®ç§‘å­¦åº”ç”¨å‡†ç¡®æ€§æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å·²åœ¨GitHubä¸Šå¼€æºR&amp;D-Agentï¼š<a target="_blank" rel="noopener" href="https://github.com/microsoft/RD-Agent%E3%80%82">https://github.com/microsoft/RD-Agentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14738v2">PDF</a> 33 pages</p>
<p><strong>Summary</strong><br>     è¿‘æœŸAIå’ŒMLçš„è¿›æ­¥ä¸ºæ•°æ®ç§‘å­¦å¸¦æ¥äº†å˜é©ï¼Œä½†å¤æ‚æ€§å’Œä¸“ä¸šçŸ¥è¯†çš„éœ€æ±‚ä¸æ–­å¢åŠ ä»ç„¶é˜»ç¢äº†è¿›å±•ã€‚è™½ç„¶ä¼—ç­¹å¹³å°ç¼“è§£äº†ä¸€äº›æŒ‘æˆ˜ï¼Œä½†é«˜çº§æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰ä»»åŠ¡ä»ç„¶æ˜¯åŠ³åŠ¨å¯†é›†å‹å’Œè¿­ä»£å‹çš„ã€‚æˆ‘ä»¬å¼•å…¥äº†R&amp;D-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢ã€è§£è€¦å’Œå¯æ‰©å±•çš„æ¡†æ¶ï¼Œæ­£å¼åŒ–MLEè¿‡ç¨‹ã€‚R&amp;D-Agentå°†MLEå·¥ä½œæµç¨‹å®šä¹‰ä¸ºä¸¤ä¸ªé˜¶æ®µå’Œå…­ä¸ªç»„ä»¶ï¼Œå°†MLEçš„ä»£ç†è®¾è®¡ä»ä¸´æ—¶æ€§çš„æ‰‹è‰ºè½¬å˜ä¸ºæœ‰åŸåˆ™çš„ã€å¯æµ‹è¯•çš„è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨é«˜æ•ˆå’Œæœ‰æ•ˆçš„ä»£ç†è®¾è®¡æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨MLE-Benchä¸Šè¯„ä¼°ï¼ŒåŸºäºR&amp;D-Agentçš„ä»£ç†è¢«è¯„ä¸ºè¡¨ç°æœ€ä½³çš„MLEä»£ç†ï¼Œè·å¾—å¥–ç‰Œç‡é«˜è¾¾35.1%ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨åŠ é€Ÿåˆ›æ–°å’Œæé«˜å„ç§æ•°æ®ç§‘å­¦åº”ç”¨å‡†ç¡®æ€§æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å·²åœ¨GitHubä¸Šå¼€æºR&amp;D-Agentï¼š<a target="_blank" rel="noopener" href="https://github.com/microsoft/RD-Agent%E3%80%82">https://github.com/microsoft/RD-Agentã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIå’ŒMLçš„è¿›æ­¥ä¸ºæ•°æ®ç§‘å­¦å¸¦æ¥äº†å˜é©ï¼Œä½†å¤æ‚æ€§å¢åŠ äº†è¿›å±•çš„éš¾åº¦ã€‚</li>
<li>ä¼—ç­¹å¹³å°è™½æœ‰åŠ©äºè§£å†³éƒ¨åˆ†æŒ‘æˆ˜ï¼Œä½†é«˜çº§MLEä»»åŠ¡ä»ç„¶å¤æ‚ã€‚</li>
<li>R&amp;D-Agentæ˜¯ä¸€ä¸ªå…¨é¢ã€è§£è€¦å’Œå¯æ‰©å±•çš„æ¡†æ¶ï¼Œæ­£å¼åŒ–MLEè¿‡ç¨‹ã€‚</li>
<li>R&amp;D-Agentå°†MLEå·¥ä½œæµç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µå’Œå…­ä¸ªç»„ä»¶ï¼Œä½¿ä»£ç†è®¾è®¡æ›´ä¸ºç³»ç»Ÿå’Œå¯æµ‹è¯•ã€‚</li>
<li>ä¸ç°æœ‰ä»£ç†ç›¸æ¯”ï¼ŒR&amp;D-Agentå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨MLE-Benchè¯„ä¼°ä¸­ï¼ŒåŸºäºR&amp;D-Agentçš„ä»£ç†è¡¨ç°æœ€ä½³ï¼Œè·å¾—å¥–ç‰Œç‡é«˜è¾¾35.1%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14738">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-af2df7e0cb5f0a5b81fc374f984beca8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101026&auth_key=1760101026-0-0-96d15b5b107eea24c68c3bd0b9f8da1b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f2529ac7ec5e183a091a39b61fd459a6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101033&auth_key=1760101033-0-0-830c561a0d3444299d185c88091edb92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4dada8ceb48492f6f0a66450fc6c688f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101041&auth_key=1760101041-0-0-5a89b20a3d199a86594fccf3bee5f280&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="GUI-R1-A-Generalist-R1-Style-Vision-Language-Action-Model-For-GUI-Agents"><a href="#GUI-R1-A-Generalist-R1-Style-Vision-Language-Action-Model-For-GUI-Agents" class="headerlink" title="GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI   Agents"></a>GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI   Agents</h2><p><strong>Authors:Run Luo, Lu Wang, Wanwei He, Longze Chen, Jiaming Li, Xiaobo Xia</strong></p>
<p>Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \name achieves superior performance using only 0.02% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks. </p>
<blockquote>
<p>ç°æœ‰æ„å»ºå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†çš„åŠªåŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ä¸Šçš„ç›‘ç£å¾®è°ƒè®­ç»ƒèŒƒå¼ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•ä¸ä»…éœ€æ±‚å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œä¸”åœ¨ç†è§£GUIæˆªå›¾å’Œæ³›åŒ–åˆ°æœªè§è¿‡çš„ç•Œé¢æ—¶é¢ä¸´å›°éš¾ã€‚è¿™ä¸€é—®é¢˜æå¤§åœ°é™åˆ¶äº†å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜çº§ä»»åŠ¡ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10458v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸º\nameçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡ï¼Œæé«˜å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨é«˜çº§ç°å®ä¸–ç•Œä»»åŠ¡åœºæ™¯ä¸­çš„GUIèƒ½åŠ›ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨è·¨å¤šä¸ªå¹³å°çš„å°‘é‡é«˜è´¨é‡æ•°æ®ï¼Œå¹¶é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç­‰ç­–ç•¥ä¼˜åŒ–ç®—æ³•æ¥æ›´æ–°æ¨¡å‹ï¼Œå®ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚ä¸ä¹‹å‰çš„å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œä½¿ç”¨çš„æ•°æ®é‡å¤§å¤§å‡å°‘ï¼ˆä»…ä½¿ç”¨0.02ï¼…çš„æ•°æ®ï¼‰ï¼Œä¸”åœ¨ä¸‰ä¸ªä¸åŒå¹³å°ï¼ˆç§»åŠ¨ã€æ¡Œé¢å’Œç½‘é¡µï¼‰ä¸Šçš„å…«ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚è¿™å±•ç¤ºäº†åŸºäºç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡çš„å¼ºåŒ–å­¦ä¹ åœ¨æå‡LVLMsæ‰§è¡Œç°å®ä¸–ç•ŒGUIä»»åŠ¡èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰GUIä»£ç†æ„å»ºå·¥ä½œä¸»è¦ä¾èµ–äºåœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸Šé‡‡ç”¨ç›‘ç£å¾®è°ƒè®­ç»ƒèŒƒå¼ã€‚</li>
<li>æ­¤æ–¹æ³•éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”åœ¨ç†è§£GUIæˆªå›¾å’Œæ³›åŒ–åˆ°æœªè§è¿‡çš„ç•Œé¢æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
<li>\nameæ˜¯é¦–ä¸ªæ—¨åœ¨å¢å¼ºLVLMsåœ¨é«˜çº§ç°å®ä¸–ç•Œä»»åŠ¡åœºæ™¯ä¸­GUIèƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚</li>
<li>\nameé€šè¿‡ç»Ÿä¸€åŠ¨ä½œç©ºé—´è§„åˆ™å»ºæ¨¡ï¼Œåˆ©ç”¨è·¨å¤šä¸ªå¹³å°çš„é«˜è´¨é‡æ•°æ®ã€‚</li>
<li>\nameä½¿ç”¨ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œæ¥æ›´æ–°æ¨¡å‹ã€‚</li>
<li>ä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œ\nameä½¿ç”¨æ›´å°‘çš„æ•°æ®å®ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼ˆä»…ä½¿ç”¨0.02%çš„æ•°æ®ï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bbfc30bdd3b81d4f104f99caa2f9bbab~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101048&auth_key=1760101048-0-0-cfd3a147c4240cc56d80761859403e96&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-51badfad75a4e93acc1541b77c5ace43~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101055&auth_key=1760101055-0-0-209ac7ac938f541d792d22d64ec52e0c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cee7f97d0afb8959daa1367850bcd49f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101062&auth_key=1760101062-0-0-c3e869fa2937e7997b90532375db580f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d9212295ff85fc241781bdc160c47cad~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101069&auth_key=1760101069-0-0-88fa568aa3d1186ce2fab60d727265e6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Grounding-Multimodal-LLMs-to-Embodied-Agents-that-Ask-for-Help-with-Reinforcement-Learning"><a href="#Grounding-Multimodal-LLMs-to-Embodied-Agents-that-Ask-for-Help-with-Reinforcement-Learning" class="headerlink" title="Grounding Multimodal LLMs to Embodied Agents that Ask for Help with   Reinforcement Learning"></a>Grounding Multimodal LLMs to Embodied Agents that Ask for Help with   Reinforcement Learning</h2><p><strong>Authors:Ram Ramrakhya, Matthew Chang, Xavier Puig, Ruta Desai, Zsolt Kira, Roozbeh Mottaghi</strong></p>
<p>Embodied agents operating in household environments must interpret ambiguous and under-specified human instructions. A capable household robot should recognize ambiguity and ask relevant clarification questions to infer the user intent accurately, leading to more effective task execution. To study this problem, we introduce the Ask-to-Act task, where an embodied agent is tasked with a single or multi-object rearrangement task using an under-specified instruction in a home environment. The agent must strategically ask minimal, yet relevant, clarification questions to resolve ambiguity while navigating under partial observability. To address this challenge, we propose a novel approach that fine-tunes multi-modal large language models (MLLMs) as vision-language-action (VLA) policies using online reinforcement learning (RL) with LLM-generated rewards. Our method eliminates the need for large-scale human demonstrations or manually engineered rewards for training such agents. We benchmark against strong zero-shot baselines including GPT-4o as well as supervised fine-tuned MLLMs on our task. Our results show that our RL-finetuned MLLM outperforms all baselines by a significant margin (10.4-16.5%), generalizing well to novel scenes and tasks. To the best of our knowledge, this is the first demonstration of adapting MLLMs as VLA agents that can act and ask for help using LLM-generated rewards with online RL. </p>
<blockquote>
<p>åœ¨å®¶åº­ç¯å¢ƒä¸­è¿è¡Œçš„å®ä½“ä»£ç†å¿…é¡»è§£é‡Šæ¨¡ç³Šå’ŒæœªæŒ‡å®šçš„äººç±»æŒ‡ä»¤ã€‚ä¸€ä¸ªèƒ½å¹²çš„å®¶ç”¨æœºå™¨äººåº”è¯¥èƒ½å¤Ÿè¯†åˆ«æ¨¡ç³Šæ€§ï¼Œå¹¶æå‡ºç›¸å…³æ¾„æ¸…é—®é¢˜ï¼Œä»¥å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„ä»»åŠ¡æ‰§è¡Œã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€œé—®å†è¡ŒåŠ¨â€ä»»åŠ¡ï¼Œåœ¨è¯¥ä»»åŠ¡ä¸­ï¼Œå®ä½“ä»£ç†éœ€è¦åœ¨å®¶åº­ç¯å¢ƒä¸­ä½¿ç”¨æœªæŒ‡å®šçš„æŒ‡ä»¤å®Œæˆå•å¯¹è±¡æˆ–å¤šå¯¹è±¡é‡æ–°å¸ƒç½®ä»»åŠ¡ã€‚ä»£ç†å¿…é¡»åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿçš„æƒ…å†µä¸‹è§£å†³æ¨¡ç³Šé—®é¢˜ï¼ŒåŒæ—¶ç­–ç•¥æ€§åœ°æå‡ºæœ€å°‘ä½†ç›¸å…³çš„é—®é¢˜è¿›è¡Œæ¾„æ¸…ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œä½¿ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾®è°ƒå¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œå°†å…¶ä½œä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶ˆé™¤äº†è®­ç»ƒæ­¤ç±»ä»£ç†éœ€è¦å¤§é‡äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±çš„éœ€æ±‚ã€‚æˆ‘ä»¬åœ¨å¼ºå¤§çš„é›¶æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬GPT-4oä»¥åŠé’ˆå¯¹æˆ‘ä»¬ä»»åŠ¡è¿›è¡Œç›‘ç£çš„å¾®è°ƒMLLMsã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„RLå¾®è°ƒMLLMåœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡å¤§å¹…åº¦è¶…è¶Šï¼ˆæé«˜å¹…åº¦åœ¨10.4-16.5%ï¼‰ï¼Œå¹¶èƒ½å¾ˆå¥½åœ°æ¨å¹¿åˆ°æ–°çš„åœºæ™¯å’Œä»»åŠ¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°†MLLMsä½œä¸ºèƒ½å¤Ÿé€‚åº”åœ¨çº¿RLå¥–åŠ±çš„å¸®åŠ©è¯·æ±‚è¡Œä¸ºçš„VLAä»£ç†è¿›è¡Œé€‚åº”å±•ç¤ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.00907v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨å®¶åº­ç¯å¢ƒä¸­æ“ä½œçš„å®ä½“ä»£ç†éœ€è¦è§£é‡Šæ¨¡ç³Šå’ŒæœªæŒ‡å®šçš„äººç±»æŒ‡ä»¤ã€‚ä¸ºäº†å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾å¹¶æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå®¶ç”¨æœºå™¨äººåº”è¯¥èƒ½å¤Ÿè¯†åˆ«æŒ‡ä»¤çš„æ¨¡ç³Šæ€§å¹¶è¯¢é—®ç›¸å…³çš„æ¾„æ¸…é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€œé—®è¡Œä»»åŠ¡â€ï¼ˆAsk-to-Act taskï¼‰ï¼Œå¹¶åœ¨æ­¤ä»»åŠ¡ä¸­ç ”ç©¶å®ä½“ä»£ç†å¦‚ä½•åœ¨ä½¿ç”¨æœªæŒ‡å®šæŒ‡ä»¤è¿›è¡Œå•å¯¹è±¡æˆ–å¤šå¯¹è±¡é‡æ–°å¸ƒç½®æ—¶è§£å†³æ¨¡ç³Šæ€§å’Œå¯¼èˆªé—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œå°†å…¶ä½œä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰ç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶ˆé™¤äº†å¯¹å¤§è§„æ¨¡äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±çš„éœ€æ±‚ã€‚åœ¨åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬çš„RLå¾®è°ƒMLLMæ˜¾è‘—ä¼˜äºåŒ…æ‹¬GPT-4oåœ¨å†…çš„é›¶æ ·æœ¬åŸºçº¿ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å±•ç¤ºå°†MLLMsé€‚åº”ä¸ºVLAä»£ç†ï¼Œå¯ä»¥ä½¿ç”¨LLMç”Ÿæˆçš„å¥–åŠ±è¿›è¡Œåœ¨çº¿RLè¡ŒåŠ¨å’Œå¯»æ±‚å¸®åŠ©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ä½“ä»£ç†éœ€è¦è§£é‡Šå®¶åº­ç¯å¢ƒä¸­çš„æ¨¡ç³Šå’ŒæœªæŒ‡å®šçš„äººç±»æŒ‡ä»¤ã€‚</li>
<li>å®¶ç”¨æœºå™¨äººåº”èƒ½è¯†åˆ«æŒ‡ä»¤æ¨¡ç³Šæ€§å¹¶è¯¢é—®æ¾„æ¸…é—®é¢˜ä»¥å‡†ç¡®æ¨æ–­ç”¨æˆ·æ„å›¾ã€‚</li>
<li>å¼•å…¥â€œé—®è¡Œä»»åŠ¡â€ä»¥ç ”ç©¶å®ä½“ä»£ç†åœ¨è§£å†³å®¶åº­ç¯å¢ƒä¸­çš„æŒ‡ä»¤æ¨¡ç³Šæ€§å’Œå¯¼èˆªé—®é¢˜æ—¶çš„ç­–ç•¥ã€‚</li>
<li>æå‡ºä¸€ç§é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ å¾®è°ƒå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ–°æ–¹æ³•ï¼Œä½œä¸ºè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰ç­–ç•¥ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸éœ€è¦å¤§è§„æ¨¡çš„äººç±»æ¼”ç¤ºæˆ–æ‰‹åŠ¨å·¥ç¨‹å¥–åŠ±ã€‚</li>
<li>RLå¾®è°ƒMLLMåœ¨åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºé›¶æ ·æœ¬åŸºçº¿ï¼ŒåŒ…æ‹¬GPT-4oã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.00907">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-590ee0105f0982409f3cdf215d741bd8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101076&auth_key=1760101076-0-0-30a897db4a35daf5f26b725b8313a2e1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-73d8f16acf62c8b4923d695093b44c26~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101084&auth_key=1760101084-0-0-c45003557c1394f9834f84d3c3bb32dd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-245141559a152456485cf5b9e7cafc44~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101091&auth_key=1760101091-0-0-7b70a96a4880dcbeeebfadc86ae8869a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Self-Evolving-Multi-Agent-Simulations-for-Realistic-Clinical-Interactions"><a href="#Self-Evolving-Multi-Agent-Simulations-for-Realistic-Clinical-Interactions" class="headerlink" title="Self-Evolving Multi-Agent Simulations for Realistic Clinical   Interactions"></a>Self-Evolving Multi-Agent Simulations for Realistic Clinical   Interactions</h2><p><strong>Authors:Mohammad Almansoori, Komal Kumar, Hisham Cholakkal</strong></p>
<p>In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLMâ€™s ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{<a target="_blank" rel="noopener" href="https://medagentsim.netlify.app/%7D">https://medagentsim.netlify.app/}</a>. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†MedAgentSimï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„æ¨¡æ‹Ÿä¸´åºŠç¯å¢ƒï¼Œå…¶ä¸­åŒ…å«åŒ»ç”Ÿã€æ‚£è€…å’Œæµ‹é‡ä»£ç†ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è¯Šæ–­ç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚ä¸ä»¥å‰çš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ¡†æ¶è¦æ±‚åŒ»ç”Ÿä»£ç†é€šè¿‡å¤šè½®å¯¹è¯ç§¯æä¸æ‚£è€…äº’åŠ¨ï¼Œä»æµ‹é‡ä»£ç†è¯·æ±‚ç›¸å…³çš„åŒ»å­¦æ£€æŸ¥ï¼ˆä¾‹å¦‚ï¼Œä½“æ¸©ã€è¡€å‹ã€å¿ƒç”µå›¾ï¼‰å’Œæˆåƒç»“æœï¼ˆä¾‹å¦‚ï¼ŒMRIã€Xå°„çº¿ï¼‰ï¼Œä»¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„è¯Šæ–­è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†è‡ªæˆ‘æ”¹è¿›æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹é€šè¿‡ä¸æ–­ä¸æ›´å¤šæ‚£è€…äº’åŠ¨æ¥è¿­ä»£ä¼˜åŒ–å…¶è¯Šæ–­ç­–ç•¥ã€‚æˆ‘ä»¬é€šè¿‡é›†æˆå¤šä»£ç†è®¨è®ºã€é“¾å¼æ€ç»´æ¨ç†å’ŒåŸºäºç»éªŒçš„çŸ¥è¯†æ£€ç´¢ï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œä¿ƒè¿›åŒ»ç”Ÿä»£ç†åœ¨ä¸æ›´å¤šæ‚£è€…äº’åŠ¨æ—¶çš„æ¸è¿›å­¦ä¹ ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªè¯„ä¼°åŸºå‡†ï¼Œä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹å‚ä¸åŠ¨æ€ã€åŸºäºä¸Šä¸‹æ–‡è¯Šæ–­äº¤äº’çš„èƒ½åŠ›ã€‚è™½ç„¶MedAgentSimå®Œå…¨è‡ªåŠ¨åŒ–ï¼Œä½†å®ƒä¹Ÿæ”¯æŒç”¨æˆ·æ§åˆ¶æ¨¡å¼ï¼Œå¯ä»¥ä¸åŒ»ç”Ÿæˆ–æ‚£è€…ä»£ç†è¿›è¡Œäººæœºäº¤äº’ã€‚åœ¨å„ç§æ¨¡æ‹Ÿè¯Šæ–­åœºæ™¯ä¸­çš„ç»¼åˆè¯„ä¼°è¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç ã€ä»¿çœŸå·¥å…·å’ŒåŸºå‡†æµ‹è¯•å¹³å°å¯åœ¨[<a target="_blank" rel="noopener" href="https://medagentsim.netlify.app/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://medagentsim.netlify.app/]ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22678v2">PDF</a> 14 page, 4 figures, 61 references, presented in MICCAI (Oral)</p>
<p><strong>Summary</strong>ï¼š</p>
<p>MedAgentSimæ˜¯ä¸€ä¸ªå¼€æºæ¨¡æ‹Ÿä¸´åºŠç¯å¢ƒï¼ŒåŒ…å«åŒ»ç”Ÿã€æ‚£è€…å’Œæµ‹é‡ä»£ç†ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è¯Šæ–­ç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶è¦æ±‚åŒ»ç”Ÿä»£ç†é€šè¿‡å¤šè½®å¯¹è¯ç§¯æä¸æ‚£è€…äº’åŠ¨ï¼Œè¯·æ±‚ç›¸å…³åŒ»å­¦æ£€æŸ¥å’Œå½±åƒç»“æœï¼Œæ¨¡ä»¿ç°å®ä¸–ç•Œçš„è¯Šæ–­è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œå®ƒæ•´åˆäº†å¤šä»£ç†è®¨è®ºã€é“¾å¼æ€ç»´å’ŒåŸºäºç»éªŒçš„çŸ¥è¯†æ£€ç´¢ï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªè¯„ä¼°åŸºå‡†ï¼Œä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯Šæ–­äº¤äº’ä¸­çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>MedAgentSimæ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿä¸´åºŠç¯å¢ƒï¼Œç”¨äºè¯„ä¼°å’Œæé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è¯Šæ–­åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…å«åŒ»ç”Ÿã€æ‚£è€…å’Œæµ‹é‡ä»£ç†ï¼Œæ¨¡æ‹ŸçœŸå®çš„åŒ»ç”Ÿä¸æ‚£è€…çš„äº’åŠ¨è¿‡ç¨‹ã€‚</li>
<li>MedAgentSimè¦æ±‚åŒ»ç”Ÿä»£ç†é€šè¿‡å¤šè½®å¯¹è¯ä¸æ‚£è€…äº’åŠ¨ï¼Œå¹¶è¯·æ±‚åŒ»å­¦æ£€æŸ¥å’Œå½±åƒç»“æœã€‚</li>
<li>æ¡†æ¶æ”¯æŒå¤šä»£ç†è®¨è®ºã€é“¾å¼æ€ç»´å’ŒåŸºäºç»éªŒçš„çŸ¥è¯†æ£€ç´¢ï¼Œå¸®åŠ©æ¨¡å‹æ”¹è¿›è¯Šæ–­ç­–ç•¥ã€‚</li>
<li>æä¾›ä¸€ä¸ªè¯„ä¼°åŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åŠ¨æ€è¯Šæ–­äº¤äº’ä¸­çš„èƒ½åŠ›ã€‚</li>
<li>MedAgentSimæ”¯æŒå…¨è‡ªåŠ¨å’Œç”¨æˆ·æ§åˆ¶æ¨¡å¼ï¼Œå¯ä»¥ä¸äººæœºäº¤äº’ã€‚</li>
<li>è¯¥æ¡†æ¶çš„ä»£ç ã€æ¨¡æ‹Ÿå·¥å…·å’Œè¯„ä¼°åŸºå‡†å·²å…¬å¼€å‘å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22678">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bc3593c6ed306066a1198515835e392b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101098&auth_key=1760101098-0-0-b7b6bf26376bd0005e98e77cb870705a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c36302077904043d08830b93a12ea2e6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101105&auth_key=1760101105-0-0-6fbe491b74ed136d7e8078fcd2ea1f47&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-789046c67c42d4399d14a7b05d9a2cfa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101112&auth_key=1760101112-0-0-06ddef6f30b9728007420685bc19ee53&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Grounded-GUI-Understanding-for-Vision-Based-Spatial-Intelligent-Agent-Exemplified-by-Extended-Reality-Apps"><a href="#Grounded-GUI-Understanding-for-Vision-Based-Spatial-Intelligent-Agent-Exemplified-by-Extended-Reality-Apps" class="headerlink" title="Grounded GUI Understanding for Vision-Based Spatial Intelligent Agent:   Exemplified by Extended Reality Apps"></a>Grounded GUI Understanding for Vision-Based Spatial Intelligent Agent:   Exemplified by Extended Reality Apps</h2><p><strong>Authors:Shuqing Li, Binchang Li, Yepang Liu, Cuiyun Gao, Jianping Zhang, Shing-Chi Cheung, Michael R. Lyu</strong></p>
<p>In recent years, spatial computing a.k.a. Extended Reality (XR) has emerged as a transformative technology, offering users immersive and interactive experiences across diversified virtual environments. Users can interact with XR apps through interactable GUI elements (IGEs) on the stereoscopic three-dimensional (3D) graphical user interface (GUI). The accurate recognition of these IGEs is instrumental, serving as the foundation of many software engineering tasks, including automated testing and effective GUI search. The most recent IGE detection approaches for 2D mobile apps typically train a supervised object detection model based on a large-scale manually-labeled GUI dataset, usually with a pre-defined set of clickable GUI element categories like buttons and spinners. Such approaches can hardly be applied to IGE detection in XR apps, due to a multitude of challenges including complexities posed by open-vocabulary and heterogeneous IGE categories, intricacies of context-sensitive interactability, and the necessities of precise spatial perception and visual-semantic alignment for accurate IGE detection results. Thus, it is necessary to embark on the IGE research tailored to XR apps. In this paper, we propose the first zero-shot cOntext-sensitive inteRactable GUI ElemeNT dEtection framework for virtual Reality apps, named Orienter. By imitating human behaviors, Orienter observes and understands the semantic contexts of XR app scenes first, before performing the detection. The detection process is iterated within a feedback-directed validation and reflection loop. Specifically, Orienter contains three components, including (1) Semantic context comprehension, (2) Reflection-directed IGE candidate detection, and (3) Context-sensitive interactability classification. Extensive experiments demonstrate that Orienter is more effective than the state-of-the-art GUI element detection approaches. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œç©ºé—´è®¡ç®—ï¼ˆåˆç§°æ‰©å±•ç°å®ï¼ˆXRï¼‰ï¼‰ä½œä¸ºä¸€é¡¹å˜é©æ€§æŠ€æœ¯å´­éœ²å¤´è§’ï¼Œä¸ºç”¨æˆ·åœ¨å¤šæ ·åŒ–çš„è™šæ‹Ÿç¯å¢ƒä¸­æä¾›æ²‰æµ¸å¼å’Œäº¤äº’å¼ä½“éªŒã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç«‹ä½“ä¸‰ç»´ï¼ˆ3Dï¼‰å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä¸Šçš„å¯äº¤äº’GUIå…ƒç´ ï¼ˆIGEsï¼‰ä¸XRåº”ç”¨ç¨‹åºè¿›è¡Œäº¤äº’ã€‚è¿™äº›IGEsçš„å‡†ç¡®è¯†åˆ«è‡³å…³é‡è¦ï¼Œæ˜¯è®¸å¤šè½¯ä»¶å·¥ç¨‹ä»»åŠ¡çš„åŸºç¡€ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–æµ‹è¯•å’Œæœ‰æ•ˆçš„GUIæœç´¢ã€‚é’ˆå¯¹2Dç§»åŠ¨åº”ç”¨çš„æœ€æ–°IGEæ£€æµ‹æ–¹æ³•é€šå¸¸åŸºäºå¤§è§„æ¨¡æ‰‹åŠ¨æ ‡è®°çš„GUIæ•°æ®é›†è®­ç»ƒç›‘ç£å¯¹è±¡æ£€æµ‹æ¨¡å‹ï¼Œé€šå¸¸å…·æœ‰é¢„å®šä¹‰çš„å¯ç‚¹å‡»GUIå…ƒç´ ç±»åˆ«ï¼Œä¾‹å¦‚æŒ‰é’®å’Œå¾®è°ƒå™¨ã€‚ç”±äºå¼€æ”¾è¯æ±‡å’Œå¼‚è´¨IGEç±»åˆ«çš„å¤æ‚æ€§ã€ä¸Šä¸‹æ–‡æ•æ„Ÿäº¤äº’çš„å¤æ‚æ€§ä»¥åŠå¯¹ç²¾ç¡®ç©ºé—´æ„ŸçŸ¥å’Œè§†è§‰è¯­ä¹‰å¯¹é½çš„å¿…éœ€æ€§ç­‰å¤šé‡æŒ‘æˆ˜ï¼Œè¿™äº›æ–¹æ¡ˆå‡ ä¹æ— æ³•åº”ç”¨äºXRåº”ç”¨ç¨‹åºä¸­çš„IGEæ£€æµ‹ã€‚å› æ­¤ï¼Œæœ‰å¿…è¦é’ˆå¯¹XRåº”ç”¨ç¨‹åºå®šåˆ¶IGEç ”ç©¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†é’ˆå¯¹è™šæ‹Ÿç°å®åº”ç”¨ç¨‹åºçš„ç¬¬ä¸€ä¸ªé›¶æ ·æœ¬ä¸Šä¸‹æ–‡æ•æ„Ÿå¯äº¤äº’GUIå…ƒç´ æ£€æµ‹æ¡†æ¶ï¼Œåä¸ºOrienterã€‚é€šè¿‡æ¨¡ä»¿äººç±»è¡Œä¸ºï¼ŒOrienteré¦–å…ˆè§‚å¯Ÿå’Œç†è§£XRåº”ç”¨ç¨‹åºåœºæ™¯è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œç„¶åè¿›è¡Œæ£€æµ‹ã€‚æ£€æµ‹è¿‡ç¨‹æ˜¯åœ¨åé¦ˆæŒ‡å¯¼çš„éªŒè¯å’Œåæ€å¾ªç¯ä¸­è¿›è¡Œçš„ã€‚å…·ä½“æ¥è¯´ï¼ŒOrienteråŒ…å«ä¸‰ä¸ªç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼ˆ1ï¼‰è¯­ä¹‰ä¸Šä¸‹æ–‡ç†è§£ã€ï¼ˆ2ï¼‰åæ€æŒ‡å¯¼çš„IGEå€™é€‰æ£€æµ‹ã€ï¼ˆ3ï¼‰ä¸Šä¸‹æ–‡æ•æ„Ÿäº¤äº’æ€§åˆ†ç±»ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒOrienteræ¯”æœ€å…ˆè¿›çš„GUIå…ƒç´ æ£€æµ‹æ–¹æ³•æ›´æœ‰æ•ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.10811v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ç©ºé—´è®¡ç®—ï¼ˆExtended Realityï¼ŒXRï¼‰æŠ€æœ¯åŠå…¶åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„æ²‰æµ¸å¼äº’åŠ¨ä½“éªŒåº”ç”¨ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç«‹ä½“ä¸‰ç»´å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä¸Šçš„å¯äº¤äº’GUIå…ƒç´ ï¼ˆIGEsï¼‰ä¸XRåº”ç”¨ç¨‹åºè¿›è¡Œäº¤äº’ã€‚å‡†ç¡®çš„IGEè¯†åˆ«å¯¹äºåŒ…æ‹¬è‡ªåŠ¨åŒ–æµ‹è¯•å’Œæœ‰æ•ˆçš„GUIæœç´¢åœ¨å†…çš„è®¸å¤šè½¯ä»¶å·¥ç¨‹ä»»åŠ¡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„IGEæ£€æµ‹æ–¹æ³•éš¾ä»¥åº”ç”¨äºXRåº”ç”¨ç¨‹åºä¸­çš„IGEæ£€æµ‹ï¼Œé¢ä¸´å¼€æ”¾è¯æ±‡ã€å¼‚è´¨IGEç±»åˆ«ã€ä¸Šä¸‹æ–‡æ•æ„Ÿäº¤äº’æ€§ç­‰å¤šæ–¹é¢çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOrienterçš„é›¶æ ·æœ¬ä¸Šä¸‹æ–‡æ•æ„Ÿäº¤äº’å¼GUIå…ƒç´ æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡æ¨¡ä»¿äººç±»è¡Œä¸ºæ¥è§‚å¯Ÿå’Œç†è§£XRåº”ç”¨ç¨‹åºåœºæ™¯çš„è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œè¿›è¡ŒIGEæ£€æµ‹ï¼Œå¹¶é€šè¿‡åé¦ˆå¯¼å‘çš„éªŒè¯å’Œåæ€å¾ªç¯è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼ŒOrienteræ¯”ç°æœ‰çš„GUIå…ƒç´ æ£€æµ‹æ–¹æ³•æ›´æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç©ºé—´è®¡ç®—ï¼ˆXRï¼‰æŠ€æœ¯æä¾›æ²‰æµ¸å¼äº’åŠ¨ä½“éªŒåœ¨è™šæ‹Ÿç¯å¢ƒä¸­ã€‚</li>
<li>IGEè¯†åˆ«åœ¨è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­èµ·å…³é”®ä½œç”¨ï¼Œå¦‚è‡ªåŠ¨åŒ–æµ‹è¯•å’ŒGUIæœç´¢ã€‚</li>
<li>ç°æœ‰IGEæ£€æµ‹æ–¹æ³•éš¾ä»¥åº”ç”¨äºXRåº”ç”¨ç¨‹åºä¸­çš„IGEæ£€æµ‹ï¼Œå­˜åœ¨å¤šç§æŒ‘æˆ˜ã€‚</li>
<li>Orienteræ¡†æ¶é€šè¿‡æ¨¡ä»¿äººç±»è¡Œä¸ºæ¥è¿›è¡ŒIGEæ£€æµ‹ï¼Œå¹¶è§‚å¯Ÿå’Œç†è§£XRåº”ç”¨ç¨‹åºåœºæ™¯çš„è¯­ä¹‰ä¸Šä¸‹æ–‡ã€‚</li>
<li>OrienteråŒ…å«ä¸‰ä¸ªç»„ä»¶ï¼šè¯­ä¹‰ä¸Šä¸‹æ–‡ç†è§£ã€åæ€å¯¼å‘çš„IGEå€™é€‰æ£€æµ‹ã€ä¸Šä¸‹æ–‡æ•æ„Ÿäº¤äº’æ€§åˆ†ç±»ã€‚</li>
<li>Orienteré€šè¿‡åé¦ˆå¯¼å‘çš„éªŒè¯å’Œåæ€å¾ªç¯è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.10811">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9c38f90dc4e2883d8b0303ea3c255227~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101119&auth_key=1760101119-0-0-9f46f744459c65c7fd7b406683406a10&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1a0f5ab2b2e11dc9d27c2e9ad2f872e5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101127&auth_key=1760101127-0-0-1640015f0082287be79a304ca7701f29&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2609a3351124de21834bef7cb589ec2a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101133&auth_key=1760101133-0-0-015678d65d76810e7994c127aa4ae56c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7997c84839f45829aa732baad2f5af60~resize:0:q75.jpg?source=1f5c5e47&expiration=1760101141&auth_key=1760101141-0-0-4dd0ebe74bf14221800835d65fbc5200&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-03/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-03/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-03/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-598b91112bacbcae29926a32bbe74dff~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084799&auth_key=1760084799-0-0-c5602fd74fdaba9e1e1f519417859ed9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  SeMoBridge Semantic Modality Bridge for Efficient Few-Shot Adaptation   of CLIP
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-03/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-3d52d5228ee62a219a9444fa4da71d49~resize:0:q75.jpg?source=1f5c5e47&expiration=1760084237&auth_key=1760084237-0-0-30cb4e3d4574ff2cf917b9511e5e07c8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  Beyond the Algorithm A Field Guide to Deploying AI Agents in Clinical   Practice
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30341.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
