<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  DC-Gen Post-Training Diffusion Acceleration with Deeply Compressed   Latent Space">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6ea24de25c382ba42b67043adb35d3b4')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    34 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-03-æ›´æ–°"><a href="#2025-10-03-æ›´æ–°" class="headerlink" title="2025-10-03 æ›´æ–°"></a>2025-10-03 æ›´æ–°</h1><h2 id="DC-Gen-Post-Training-Diffusion-Acceleration-with-Deeply-Compressed-Latent-Space"><a href="#DC-Gen-Post-Training-Diffusion-Acceleration-with-Deeply-Compressed-Latent-Space" class="headerlink" title="DC-Gen: Post-Training Diffusion Acceleration with Deeply Compressed   Latent Space"></a>DC-Gen: Post-Training Diffusion Acceleration with Deeply Compressed   Latent Space</h2><p><strong>Authors:Wenkun He, Yuchao Gu, Junyu Chen, Dongyun Zou, Yujun Lin, Zhekai Zhang, Haocheng Xi, Muyang Li, Ligeng Zhu, Jincheng Yu, Junsong Chen, Enze Xie, Song Han, Han Cai</strong></p>
<p>Existing text-to-image diffusion models excel at generating high-quality images, but face significant efficiency challenges when scaled to high resolutions, like 4K image generation. While previous research accelerates diffusion models in various aspects, it seldom handles the inherent redundancy within the latent space. To bridge this gap, this paper introduces DC-Gen, a general framework that accelerates text-to-image diffusion models by leveraging a deeply compressed latent space. Rather than a costly training-from-scratch approach, DC-Gen uses an efficient post-training pipeline to preserve the quality of the base model. A key challenge in this paradigm is the representation gap between the base modelâ€™s latent space and a deeply compressed latent space, which can lead to instability during direct fine-tuning. To overcome this, DC-Gen first bridges the representation gap with a lightweight embedding alignment training. Once the latent embeddings are aligned, only a small amount of LoRA fine-tuning is needed to unlock the base modelâ€™s inherent generation quality. We verify DC-Genâ€™s effectiveness on SANA and FLUX.1-Krea. The resulting DC-Gen-SANA and DC-Gen-FLUX models achieve quality comparable to their base models but with a significant speedup. Specifically, DC-Gen-FLUX reduces the latency of 4K image generation by 53x on the NVIDIA H100 GPU. When combined with NVFP4 SVDQuant, DC-Gen-FLUX generates a 4K image in just 3.5 seconds on a single NVIDIA 5090 GPU, achieving a total latency reduction of 138x compared to the base FLUX.1-Krea model. Code: <a target="_blank" rel="noopener" href="https://github.com/dc-ai-projects/DC-Gen">https://github.com/dc-ai-projects/DC-Gen</a>. </p>
<blockquote>
<p>ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æ‰©å±•åˆ°é«˜åˆ†è¾¨ç‡ï¼ˆå¦‚4Kå›¾åƒç”Ÿæˆï¼‰æ—¶é¢ä¸´é‡å¤§çš„æ•ˆç‡æŒ‘æˆ˜ã€‚å°½ç®¡ä¹‹å‰çš„ç ”ç©¶ä»å„ä¸ªæ–¹é¢åŠ é€Ÿäº†æ‰©æ•£æ¨¡å‹ï¼Œä½†å¾ˆå°‘å¤„ç†æ½œåœ¨ç©ºé—´ä¸­çš„å›ºæœ‰å†—ä½™ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡ä»‹ç»äº†DC-Genï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡åˆ©ç”¨æ·±åº¦å‹ç¼©æ½œåœ¨ç©ºé—´æ¥åŠ é€Ÿæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é€šç”¨æ¡†æ¶ã€‚DC-Genå¹¶éé‡‡ç”¨æ˜‚è´µçš„ä»å¤´å¼€å§‹è®­ç»ƒçš„æ–¹æ³•ï¼Œè€Œæ˜¯é‡‡ç”¨é«˜æ•ˆçš„åè®­ç»ƒç®¡é“æ¥ä¿ç•™åŸºç¡€æ¨¡å‹çš„è´¨é‡ã€‚è¿™ä¸€èŒƒå¼ä¸­çš„å…³é”®æŒ‘æˆ˜æ˜¯åŸºç¡€æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸æ·±åº¦å‹ç¼©çš„æ½œåœ¨ç©ºé—´ä¹‹é—´çš„è¡¨ç¤ºå·®è·ï¼Œè¿™å¯èƒ½å¯¼è‡´ç›´æ¥å¾®è°ƒæ—¶çš„ä¸ç¨³å®šæ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼ŒDC-Gené¦–å…ˆé€šè¿‡è½»é‡çº§çš„åµŒå…¥å¯¹é½è®­ç»ƒæ¥å¼¥åˆè¡¨ç¤ºå·®è·ã€‚ä¸€æ—¦æ½œåœ¨åµŒå…¥å¯¹é½ï¼Œåªéœ€å°‘é‡çš„LoRAå¾®è°ƒå³å¯é‡Šæ”¾åŸºç¡€æ¨¡å‹çš„å›ºæœ‰ç”Ÿæˆè´¨é‡ã€‚æˆ‘ä»¬åœ¨SANAå’ŒFLUX.1-Kreaä¸ŠéªŒè¯äº†DC-Gençš„æœ‰æ•ˆæ€§ã€‚DC-Gen-SANAå’ŒDC-Gen-FLUXæ¨¡å‹åœ¨è´¨é‡ä¸Šä¸åŸºç¡€æ¨¡å‹ç›¸å½“ï¼Œä½†é€Ÿåº¦æ˜¾è‘—æé«˜ã€‚å…·ä½“æ¥è¯´ï¼ŒDC-Gen-FLUXåœ¨NVIDIA H100 GPUä¸Šå°†4Kå›¾åƒçš„ç”Ÿæˆå»¶è¿Ÿå‡å°‘äº†53å€ã€‚å½“ä¸NVFP4 SVDQuantç»“åˆæ—¶ï¼ŒDC-Gen-FLUXåœ¨å•ä¸ªNVIDIA 5090 GPUä¸Šä»…ç”¨3.5ç§’å³å¯ç”Ÿæˆ4Kå›¾åƒï¼Œä¸åŸºç¡€FLUX.1-Kreaæ¨¡å‹ç›¸æ¯”ï¼Œæ€»å»¶è¿Ÿå‡å°‘äº†138å€ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/dc-ai-projects/DC-Gen%E3%80%82">https://github.com/dc-ai-projects/DC-Genã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25180v2">PDF</a> Tech Report. The first three authors contributed equally to this work</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†DC-Genæ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨æ·±åº¦å‹ç¼©çš„æ½œåœ¨ç©ºé—´æ¥åŠ é€Ÿæ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹ã€‚DC-Gené‡‡ç”¨é«˜æ•ˆçš„è®­ç»ƒåæµç¨‹ï¼Œè€Œéä»å¤´å¼€å§‹è®­ç»ƒçš„æ–¹æ³•ï¼Œä¿ç•™äº†åŸºç¡€æ¨¡å‹çš„è´¨é‡ã€‚è§£å†³äº†åŸºç¡€æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸æ·±åº¦å‹ç¼©çš„æ½œåœ¨ç©ºé—´ä¹‹é—´çš„è¡¨ç¤ºé¸¿æ²Ÿé—®é¢˜ï¼Œé‡‡ç”¨è½»é‡çº§åµŒå…¥å¯¹é½è®­ç»ƒè¿›è¡Œå¼¥è¡¥ï¼Œç„¶åé€šè¿‡å°‘é‡çš„LoRAå¾®è°ƒæ¥è§£é”åŸºç¡€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚åœ¨SANAå’ŒFLUX.1-Kreaä¸ŠéªŒè¯äº†DC-Gençš„æœ‰æ•ˆæ€§ï¼Œç”Ÿæˆçš„æ¨¡å‹åœ¨è´¨é‡ä¸Šå¯ä¸åŸºç¡€æ¨¡å‹ç›¸å½“ï¼Œä½†é€Ÿåº¦æ›´å¿«ã€‚ç‰¹åˆ«æ˜¯DC-Gen-FLUXåœ¨NVIDIA H100 GPUä¸Šå°†4Kå›¾åƒç”Ÿæˆçš„å»¶è¿Ÿå‡å°‘äº†53å€ã€‚ç»“åˆNVFP4 SVDQuantï¼ŒDC-Gen-FLUXåœ¨å•ä¸ªNVIDIA 5090 GPUä¸Šç”Ÿæˆ4Kå›¾åƒåªéœ€3.5ç§’ï¼Œä¸åŸºç¡€FLUX.1-Kreaæ¨¡å‹ç›¸æ¯”ï¼Œæ€»å»¶è¿Ÿé™ä½äº†138å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DC-Genæ˜¯ä¸€ä¸ªç”¨äºåŠ é€Ÿæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ·±åº¦å‹ç¼©æ½œåœ¨ç©ºé—´æ¥æé«˜æ•ˆç‡ã€‚</li>
<li>DC-Gené‡‡ç”¨è®­ç»ƒåæµç¨‹ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒï¼Œä»¥ä¿ç•™åŸºç¡€æ¨¡å‹çš„è´¨é‡ã€‚</li>
<li>è§£å†³äº†åŸºç¡€æ¨¡å‹ä¸æ·±åº¦å‹ç¼©æ½œåœ¨ç©ºé—´ä¹‹é—´çš„è¡¨ç¤ºé¸¿æ²Ÿé—®é¢˜ã€‚</li>
<li>é‡‡ç”¨è½»é‡çº§åµŒå…¥å¯¹é½è®­ç»ƒæ¥å¼¥è¡¥è¡¨ç¤ºé¸¿æ²Ÿã€‚</li>
<li>ä»…éœ€å°‘é‡LoRAå¾®è°ƒå³å¯è§£é”åŸºç¡€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚</li>
<li>DC-Genåœ¨SANAå’ŒFLUX.1-Kreaæ¨¡å‹ä¸Šçš„å®æ–½æ•ˆæœæ˜¾è‘—ï¼Œç”Ÿæˆå›¾åƒè´¨é‡ç›¸å½“ï¼Œä½†é€Ÿåº¦æ›´å¿«ã€‚</li>
<li>DC-Genä¸FLUXæ¨¡å‹çš„ç»“åˆåœ¨4Kå›¾åƒç”Ÿæˆæ–¹é¢å®ç°äº†æ˜¾è‘—çš„å»¶è¿Ÿé™ä½ï¼Œä¸ºå®é™…åº”ç”¨å¸¦æ¥äº†æ›´é«˜çš„æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25180">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-97b25c626d196d0397844abc9035966c" align="middle">
<img src="https://picx.zhimg.com/v2-870b43fb9340f52265b87cac03b4c273" align="middle">
<img src="https://picx.zhimg.com/v2-7df64a210de14f379b0b045d22d2b66f" align="middle">
<img src="https://picx.zhimg.com/v2-71801132766dbdd6b82b721f01129728" align="middle">
<img src="https://picx.zhimg.com/v2-ef108f1fc8f84c9a615d90e0ace25cd5" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Imagining-Alternatives-Towards-High-Resolution-3D-Counterfactual-Medical-Image-Generation-via-Language-Guidance"><a href="#Imagining-Alternatives-Towards-High-Resolution-3D-Counterfactual-Medical-Image-Generation-via-Language-Guidance" class="headerlink" title="Imagining Alternatives: Towards High-Resolution 3D Counterfactual   Medical Image Generation via Language Guidance"></a>Imagining Alternatives: Towards High-Resolution 3D Counterfactual   Medical Image Generation via Language Guidance</h2><p><strong>Authors:Mohamed Mohamed, Brennan Nichyporuk, Douglas L. Arnold, Tal Arbel</strong></p>
<p>Vision-language models have demonstrated impressive capabilities in generating 2D images under various conditions; however, the success of these models is largely enabled by extensive, readily available pretrained foundation models. Critically, comparable pretrained models do not exist for 3D, significantly limiting progress. As a result, the potential of vision-language models to produce high-resolution 3D counterfactual medical images conditioned solely on natural language remains unexplored. Addressing this gap would enable powerful clinical and research applications, such as personalized counterfactual explanations, simulation of disease progression, and enhanced medical training by visualizing hypothetical conditions in realistic detail. Our work takes a step toward this challenge by introducing a framework capable of generating high-resolution 3D counterfactual medical images of synthesized patients guided by free-form language prompts. We adapt state-of-the-art 3D diffusion models with enhancements from Simple Diffusion and incorporate augmented conditioning to improve text alignment and image quality. To our knowledge, this is the first demonstration of a language-guided native-3D diffusion model applied to neurological imaging, where faithful three-dimensional modeling is essential. On two neurological MRI datasets, our framework simulates varying counterfactual lesion loads in Multiple Sclerosis and cognitive states in Alzheimerâ€™s disease, generating high-quality images while preserving subject fidelity. Our results lay the groundwork for prompt-driven disease progression analysis in 3D medical imaging. Project link - <a target="_blank" rel="noopener" href="https://lesupermomo.github.io/imagining-alternatives/">https://lesupermomo.github.io/imagining-alternatives/</a>. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å„ç§æ¡ä»¶ä¸‹ç”Ÿæˆ2Då›¾åƒçš„èƒ½åŠ›ä»¤äººå°è±¡æ·±åˆ»ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„æˆåŠŸåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—ç›Šäºå¹¿æ³›ä¸”æ˜“äºè·å–çš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ã€‚å…³é”®çš„æ˜¯ï¼Œå¯¹äº3Dé¢†åŸŸï¼Œå¹¶æ²¡æœ‰ä¸ä¹‹ç›¸å½“çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™ä¸¥é‡é™åˆ¶äº†è¿›å±•ã€‚å› æ­¤ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä»…æ ¹æ®è‡ªç„¶è¯­è¨€ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„3Dåäº‹å®åŒ»å­¦å½±åƒæ–¹é¢çš„æ½œåŠ›å°šæœªè¢«æ¢ç´¢ã€‚å¡«è¡¥è¿™ä¸€ç©ºç™½å°†èƒ½æ¨åŠ¨ä¸´åºŠå’Œç ”ç©¶åº”ç”¨çš„å‘å±•ï¼Œå¦‚ä¸ªæ€§åŒ–çš„åäº‹å®è§£é‡Šã€ç–¾ç—…è¿›å±•æ¨¡æ‹Ÿä»¥åŠé€šè¿‡è¯¦ç»†å±•ç¤ºå‡è®¾æ¡ä»¶æ¥å¢å¼ºåŒ»å­¦åŸ¹è®­ã€‚æˆ‘ä»¬çš„å·¥ä½œæœç€è¿™ä¸€æŒ‘æˆ˜è¿ˆå‡ºäº†ä¸€æ­¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€šè¿‡è‡ªç”±å½¢å¼çš„è¯­è¨€æç¤ºæ¥ç”Ÿæˆç”±åˆæˆæ‚£è€…çš„é«˜åˆ†è¾¨ç‡3Dåäº‹å®åŒ»å­¦å½±åƒã€‚æˆ‘ä»¬æ”¹è¿›äº†æœ€å…ˆè¿›çš„3Dæ‰©æ•£æ¨¡å‹å¹¶èå…¥äº†ç®€å•æ‰©æ•£ï¼ŒåŒæ—¶å¢åŠ äº†é™„åŠ æ¡ä»¶æ¥æé«˜æ–‡æœ¬å¯¹é½å’Œå›¾åƒè´¨é‡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°†è¯­è¨€å¼•å¯¼çš„åŸç”Ÿ3Dæ‰©æ•£æ¨¡å‹åº”ç”¨äºç¥ç»æˆåƒï¼Œå¿ å®çš„ä¸‰ç»´å»ºæ¨¡åœ¨è¿™é‡Œè‡³å…³é‡è¦ã€‚åœ¨ä¸¤ä¸ªç¥ç»MRIæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ¨¡æ‹Ÿäº†å¤šå‘æ€§ç¡¬åŒ–ç—‡çš„å¤šç§åäº‹å®ç—…ç¶è´Ÿè·ä»¥åŠé˜¿å°”èŒ¨æµ·é»˜ç—…çš„è®¤çŸ¥çŠ¶æ€ï¼Œç”Ÿæˆäº†é«˜è´¨é‡å›¾åƒï¼ŒåŒæ—¶ä¿æŒäº†ä¸»ä½“å¿ å®åº¦ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸º3DåŒ»å­¦å½±åƒä¸­çš„æç¤ºé©±åŠ¨ç–¾ç—…è¿›å±•åˆ†æå¥ å®šäº†åŸºç¡€ã€‚é¡¹ç›®é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://lesupermomo.github.io/imagining-alternatives/">https://lesupermomo.github.io/imagining-alternatives/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05978v2">PDF</a> Accepted to the 2025 MICCAI ELAMI Workshop</p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä¸»è¦ä»‹ç»äº†åœ¨ç”Ÿæˆé«˜è´¨é‡ä¸‰ç»´å›¾åƒæ–¹é¢çš„æŠ€æœ¯æŒ‘æˆ˜ä¸ç°çŠ¶ã€‚ç›®å‰å¤§å¤šæ•°æˆåŠŸçš„è§†è§‰è¯­è¨€æ¨¡å‹éƒ½ä¾èµ–äºå·²ç»å­˜åœ¨çš„é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œä½†è¿™æ ·çš„æ¨¡å‹åœ¨ä¸‰ç»´å›¾åƒç”Ÿæˆé¢†åŸŸä»å±ç¨€ç¼ºã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªèƒ½å¤ŸåŸºäºè‡ªç„¶è¯­è¨€æç¤ºç”Ÿæˆé«˜è´¨é‡ä¸‰ç»´åŒ»ç–—å›¾åƒçš„ç³»ç»Ÿæ¡†æ¶ï¼Œè¿™å¯ä»¥åº”ç”¨åœ¨åŒ»ç–—çš„ä¸´åºŠå’Œç ”ç©¶ä¸Šï¼Œæ¯”å¦‚ç”Ÿæˆä¸ªæ€§åŒ–åå‘è§£é‡Šã€æ¨¡æ‹Ÿç–¾ç—…è¿›å±•ç­‰ã€‚è¿™ä¸ºåç»­çš„è¿›ä¸€æ­¥ç ”ç©¶ï¼Œå¦‚åŸºäºæç¤ºçš„ç–¾ç—…è¿›å±•åˆ†æå¥ å®šäº†åŸºç¡€ã€‚è¯¥é¡¹ç›®å·²åœ¨ä¸¤ä¸ªç¥ç»MRIæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å½“å‰è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡ä¸‰ç»´å›¾åƒæ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼ŒåŸå› åœ¨äºç¼ºä¹ç›¸åº”çš„é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ã€‚</li>
<li>æœ¬æ–‡ä»‹ç»çš„ç³»ç»Ÿæ¡†æ¶é¦–æ¬¡å±•ç¤ºäº†è¯­è¨€å¼•å¯¼çš„åŸç”Ÿä¸‰ç»´æ‰©æ•£æ¨¡å‹åœ¨ç¥ç»æˆåƒä¸­çš„åº”ç”¨ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤ŸåŸºäºè‡ªç„¶è¯­è¨€æç¤ºç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´åŒ»ç–—å›¾åƒï¼Œå¹¶åº”ç”¨äºä¸ªæ€§åŒ–åå‘è§£é‡Šã€æ¨¡æ‹Ÿç–¾ç—…è¿›å±•ç­‰åŒ»ç–—ä¸´åºŠå’Œç ”ç©¶é¢†åŸŸã€‚</li>
<li>è¯¥ç³»ç»Ÿåœ¨ä¸¤ä¸ªç¥ç»MRIæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿå¤šå‘æ€§ç¡¬åŒ–ç—‡çš„ç—…å˜è´Ÿè·å’Œé˜¿å°”èŒ¨æµ·é»˜ç—…ä¸­çš„è®¤çŸ¥çŠ¶æ€å˜åŒ–ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05978">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fceeacd1f70cf381ac75b13d63e93c2c" align="middle">
<img src="https://picx.zhimg.com/v2-84788cd2c6aaec08fb6b9eec83a92e8e" align="middle">
<img src="https://picx.zhimg.com/v2-6ea24de25c382ba42b67043adb35d3b4" align="middle">
<img src="https://picx.zhimg.com/v2-897e1f7c4fd0dbd99a0e12217777eed8" align="middle">
<img src="https://picx.zhimg.com/v2-fe4a36818c6a34cca0fd5b3099d757ce" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Text-to-CT-Generation-via-3D-Latent-Diffusion-Model-with-Contrastive-Vision-Language-Pretraining"><a href="#Text-to-CT-Generation-via-3D-Latent-Diffusion-Model-with-Contrastive-Vision-Language-Pretraining" class="headerlink" title="Text-to-CT Generation via 3D Latent Diffusion Model with Contrastive   Vision-Language Pretraining"></a>Text-to-CT Generation via 3D Latent Diffusion Model with Contrastive   Vision-Language Pretraining</h2><p><strong>Authors:Daniele Molino, Camillo Maria Caruso, Filippo Ruffini, Paolo Soda, Valerio Guarrasi</strong></p>
<p>Objective: While recent advances in text-conditioned generative models have enabled the synthesis of realistic medical images, progress has been largely confined to 2D modalities such as chest X-rays. Extending text-to-image generation to volumetric CT remains a significant challenge, due to its high dimensionality, anatomical complexity, and the absence of robust frameworks that align vision-language data in 3D medical imaging. Methods: We introduce a novel architecture for Text-to-CT generation that combines a latent diffusion model with a 3D contrastive vision-language pretraining scheme. Our approach leverages a dual-encoder CLIP-style model trained on paired CT volumes and radiology reports to establish a shared embedding space, which serves as the conditioning input for generation. CT volumes are compressed into a low-dimensional latent space via a pretrained volumetric VAE, enabling efficient 3D denoising diffusion without requiring external super-resolution stages. Results: We evaluate our method on the CT-RATE dataset and conduct a comprehensive assessment of image fidelity, clinical relevance, and semantic alignment. Our model achieves competitive performance across all tasks, significantly outperforming prior baselines for text-to-CT generation. Moreover, we demonstrate that CT scans synthesized by our framework can effectively augment real data, improving downstream diagnostic performance. Conclusion: Our results show that modality-specific vision-language alignment is a key component for high-quality 3D medical image generation. By integrating contrastive pretraining and volumetric diffusion, our method offers a scalable and controllable solution for synthesizing clinically meaningful CT volumes from text, paving the way for new applications in data augmentation, medical education, and automated clinical simulation. Code at <a target="_blank" rel="noopener" href="https://github.com/cosbidev/Text2CT">https://github.com/cosbidev/Text2CT</a>. </p>
<blockquote>
<p>ç›®æ ‡ï¼šå°½ç®¡è¿‘æœŸæ–‡æœ¬æ¡ä»¶ç”Ÿæˆæ¨¡å‹å–å¾—äº†è¿›å±•ï¼Œå·²ç»èƒ½å¤Ÿåˆæˆé€¼çœŸçš„åŒ»å­¦å›¾åƒï¼Œä½†è¿›å±•ä¸»è¦å±€é™äºå¦‚èƒ¸éƒ¨Xå…‰ç­‰2Dæ¨¡å¼ã€‚å°†æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆæ‰©å±•åˆ°ä½“ç§¯CTä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºå…¶é«˜ç»´åº¦ã€è§£å‰–ç»“æ„å¤æ‚ï¼Œä»¥åŠç¼ºä¹èƒ½å¤Ÿåœ¨3DåŒ»å­¦æˆåƒä¸­å¯¹è§†è§‰è¯­è¨€æ•°æ®è¿›è¡Œå¯¹é½çš„ç¨³å¥æ¡†æ¶ã€‚æ–¹æ³•ï¼šæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”¨äºæ–‡æœ¬åˆ°CTç”Ÿæˆçš„æ–°å‹æ¶æ„ï¼Œå®ƒç»“åˆäº†æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¸3Då¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ–¹æ¡ˆã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨åœ¨é…å¯¹CTä½“ç§¯å’Œæ”¾å°„å­¦æŠ¥å‘Šä¸Šè®­ç»ƒçš„åŒé‡ç¼–ç å™¨CLIPé£æ ¼æ¨¡å‹ï¼Œå»ºç«‹å…±äº«åµŒå…¥ç©ºé—´ï¼Œä½œä¸ºç”Ÿæˆçš„æ¡ä»¶è¾“å…¥ã€‚CTä½“ç§¯é€šè¿‡é¢„è®­ç»ƒçš„ä½“ç§¯VAEå‹ç¼©æˆä½ç»´æ½œåœ¨ç©ºé—´ï¼Œå®ç°é«˜æ•ˆçš„3Då»å™ªæ‰©æ•£ï¼Œè€Œæ— éœ€å¤–éƒ¨è¶…åˆ†è¾¨ç‡é˜¶æ®µã€‚ç»“æœï¼šæˆ‘ä»¬åœ¨CT-RATEæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶å…¨é¢è¯„ä¼°äº†å›¾åƒä¿çœŸåº¦ã€ä¸´åºŠç›¸å…³æ€§å’Œè¯­ä¹‰å¯¹é½ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œåœ¨æ–‡æœ¬åˆ°CTç”Ÿæˆæ–¹é¢æ˜¾è‘—è¶…è¶Šäº†å…ˆå‰çš„åŸºçº¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬æ¡†æ¶åˆæˆçš„CTæ‰«æå¯ä»¥æœ‰æ•ˆåœ°å¢å¼ºçœŸå®æ•°æ®ï¼Œæé«˜ä¸‹æ¸¸è¯Šæ–­æ€§èƒ½ã€‚ç»“è®ºï¼šæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ¨¡æ€ç‰¹å®šçš„è§†è§‰è¯­è¨€å¯¹é½æ˜¯é«˜è´¨é‡3DåŒ»å­¦å›¾åƒç”Ÿæˆçš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚é€šè¿‡ç»“åˆå¯¹æ¯”é¢„è®­ç»ƒå’Œä½“ç§¯æ‰©æ•£ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸€ç§å¯æ‰©å±•å’Œå¯æ§çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬åˆæˆå…·æœ‰ä¸´åºŠæ„ä¹‰çš„CTä½“ç§¯ï¼Œä¸ºæ•°æ®å¢å¼ºã€åŒ»å­¦æ•™è‚²å’Œè‡ªåŠ¨åŒ–ä¸´åºŠæ¨¡æ‹Ÿç­‰é¢†åŸŸå¼€è¾Ÿäº†æ–°åº”ç”¨é€”å¾„ã€‚ç›¸å…³ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/cosbidev/Text2CT%E6%89%BE%E5%88%B0%E3%80%82]">https://github.com/cosbidev/Text2CTæ‰¾åˆ°ã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00633v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å°†æ–‡æœ¬è½¬åŒ–ä¸ºCTå›¾åƒçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹å’Œä¸‰ç»´å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ–¹æ¡ˆï¼Œå®ç°äº†æ–‡æœ¬åˆ°CTå›¾åƒçš„é«˜æ•ˆç”Ÿæˆã€‚è¯¥æ–¹æ³•ä½¿ç”¨åŒç¼–ç å™¨CLIPé£æ ¼çš„æ¨¡å‹ï¼Œåœ¨é…å¯¹CTä½“ç§¯å’Œæ”¾å°„å­¦æŠ¥å‘Šä¸Šè®­ç»ƒï¼Œå»ºç«‹å…±äº«åµŒå…¥ç©ºé—´ä½œä¸ºç”Ÿæˆçš„æ¡ä»¶è¾“å…¥ã€‚å°†CTä½“ç§¯å‹ç¼©åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„ä½“ç§¯VAEå®ç°é«˜æ•ˆçš„ä¸‰ç»´å»å™ªæ‰©æ•£ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒä¿çœŸåº¦ã€ä¸´åºŠç›¸å…³æ€§å’Œè¯­ä¹‰å¯¹é½æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—ä¼˜äºå…ˆå‰çš„åŸºçº¿æ–‡æœ¬åˆ°CTç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆæˆCTæ‰«ææ•°æ®å¯¹çœŸå®æ•°æ®è¿›è¡Œå¢å¼ºï¼Œå¯æé«˜ä¸‹æ¸¸è¯Šæ–­æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§æ–°çš„æ–‡æœ¬è½¬CTå›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿåˆæˆé€¼çœŸçš„ä¸‰ç»´åŒ»å­¦å›¾åƒã€‚</li>
<li>é‡‡ç”¨äº†æ½œåœ¨æ‰©æ•£æ¨¡å‹å’Œä¸‰ç»´å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼Œæé«˜äº†ç”Ÿæˆæ¨¡å‹çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨åŒç¼–ç å™¨CLIPé£æ ¼çš„æ¨¡å‹ï¼Œå»ºç«‹å…±äº«åµŒå…¥ç©ºé—´ä½œä¸ºç”Ÿæˆæ¡ä»¶ï¼Œå¢å¼ºäº†å›¾åƒä¸æ–‡æœ¬çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>é€šè¿‡å°†CTä½“ç§¯å‹ç¼©åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†é«˜æ•ˆçš„ä¸‰ç»´å»å™ªæ‰©æ•£ï¼Œæ— éœ€å¤–éƒ¨è¶…åˆ†è¾¨ç‡é˜¶æ®µã€‚</li>
<li>è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒä¿çœŸåº¦ã€ä¸´åºŠç›¸å…³æ€§å’Œè¯­ä¹‰å¯¹é½æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>åˆæˆCTæ‰«ææ•°æ®å¯æœ‰æ•ˆå¢å¼ºçœŸå®æ•°æ®ï¼Œæé«˜ä¸‹æ¸¸è¯Šæ–­æ€§èƒ½ã€‚</li>
<li>æ¨¡æ€ç‰¹å®šçš„è§†è§‰è¯­è¨€å¯¹é½æ˜¯é«˜è´¨é‡ä¸‰ç»´åŒ»å­¦å›¾åƒç”Ÿæˆçš„å…³é”®ç»„ä»¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00633">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-36354841c477278b4968e2dbea634e97" align="middle">
<img src="https://picx.zhimg.com/v2-163155acdc8174e7ec9574d1e238064d" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="STORK-Faster-Diffusion-And-Flow-Matching-Sampling-By-Resolving-Both-Stiffness-And-Structure-Dependence"><a href="#STORK-Faster-Diffusion-And-Flow-Matching-Sampling-By-Resolving-Both-Stiffness-And-Structure-Dependence" class="headerlink" title="STORK: Faster Diffusion And Flow Matching Sampling By Resolving Both   Stiffness And Structure-Dependence"></a>STORK: Faster Diffusion And Flow Matching Sampling By Resolving Both   Stiffness And Structure-Dependence</h2><p><strong>Authors:Zheng Tan, Weizhen Wang, Andrea L. Bertozzi, Ernest K. Ryu</strong></p>
<p>Diffusion models (DMs) and flow-matching models have demonstrated remarkable performance in image and video generation. However, such models require a significant number of function evaluations (NFEs) during sampling, leading to costly inference. Consequently, quality-preserving fast sampling methods that require fewer NFEs have been an active area of research. However, prior training-free sampling methods fail to simultaneously address two key challenges: the stiffness of the ODE (i.e., the non-straightness of the velocity field) and dependence on the semi-linear structure of the DM ODE (which limits their direct applicability to flow-matching models). In this work, we introduce the Stabilized Taylor Orthogonal Rungeâ€“Kutta (STORK) method, addressing both design concerns. We demonstrate that STORK consistently improves the quality of diffusion and flow-matching sampling for image and video generation. Code is available at <a target="_blank" rel="noopener" href="https://github.com/ZT220501/STORK">https://github.com/ZT220501/STORK</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰å’Œæµé‡åŒ¹é…æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­éœ€è¦å¤§é‡çš„å‡½æ•°è¯„ä¼°ï¼ˆNFEsï¼‰ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜æ˜‚ã€‚å› æ­¤ï¼Œéœ€è¦è¾ƒå°‘NFEsçš„ä¿è´¨ä¿é€Ÿé‡‡æ ·æ–¹æ³•å·²æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ— è®­ç»ƒé‡‡æ ·æ–¹æ³•æœªèƒ½åŒæ—¶è§£å†³ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šå¸¸å¾®åˆ†æ–¹ç¨‹çš„åˆšåº¦ï¼ˆå³é€Ÿåº¦åœºçš„éç›´çº¿æ€§ï¼‰å’Œå¯¹DMå¸¸å¾®åˆ†æ–¹ç¨‹çš„åŠçº¿æ€§ç»“æ„çš„ä¾èµ–ï¼ˆè¿™é™åˆ¶äº†å®ƒä»¬ç›´æ¥åº”ç”¨äºæµé‡åŒ¹é…æ¨¡å‹ï¼‰ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç¨³å®šçš„æ³°å‹’æ­£äº¤é¾™æ ¼-åº“å¡”ï¼ˆSTORKï¼‰æ–¹æ³•ï¼Œè§£å†³äº†è¿™ä¸¤ä¸ªè®¾è®¡é—®é¢˜ã€‚æˆ‘ä»¬è¯æ˜STORKæ–¹æ³•èƒ½æŒç»­æé«˜å›¾åƒå’Œè§†é¢‘ç”Ÿæˆçš„æ‰©æ•£å’Œæµé‡åŒ¹é…é‡‡æ ·çš„è´¨é‡ã€‚ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/ZT220501/STORK">https://github.com/ZT220501/STORK</a> è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24210v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Diffusion modelsï¼ˆDMsï¼‰åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸­çš„å‡ºè‰²è¡¨ç°ï¼Œä½†é‡‡æ ·è¿‡ç¨‹ä¸­éœ€è¦å¤§é‡åŠŸèƒ½è¯„ä¼°ï¼ˆNFEsï¼‰ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜æ˜‚ã€‚ä¸ºå‡å°‘NFEsï¼Œç ”ç©¶è€…ä»¬è‡´åŠ›äºå¼€å‘ä¿æŒè´¨é‡çš„åŒæ—¶æ›´å¿«çš„é‡‡æ ·æ–¹æ³•ã€‚ç„¶è€Œï¼Œå…ˆå‰æ— è®­ç»ƒé‡‡æ ·æ–¹æ³•æœªèƒ½åŒæ—¶è§£å†³ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼šå¸¸å¾®åˆ†æ–¹ç¨‹çš„åˆšåº¦ï¼ˆå³é€Ÿåº¦åœºçš„ä¸ç›´çº¿æ€§ï¼‰å’Œå¯¹DM ODEåŠçº¿æ€§ç»“æ„çš„ä¾èµ–ï¼ˆé™åˆ¶äº†å®ƒä»¬å¯¹æµåŠ¨åŒ¹é…æ¨¡å‹çš„ç›´æ¥åº”ç”¨ï¼‰ã€‚æœ¬ç ”ç©¶å¼•å…¥ç¨³å®šåŒ–çš„æ³°å‹’æ­£äº¤é¾™æ ¼åº“å¡”ï¼ˆSTORKï¼‰æ–¹æ³•ï¼Œè§£å†³äº†è¿™ä¸¤ä¸ªè®¾è®¡éš¾é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒSTORKåœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆçš„æ‰©æ•£å’ŒæµåŠ¨åŒ¹é…é‡‡æ ·ä¸­æŒç»­æé«˜äº†è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Diffusion models (DMs) å’ŒæµåŠ¨åŒ¹é…æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>é‡‡æ ·è¿‡ç¨‹ä¸­éœ€è¦å¤§é‡åŠŸèƒ½è¯„ä¼°ï¼ˆNFEsï¼‰ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>æ­¤å‰æ— è®­ç»ƒé‡‡æ ·æ–¹æ³•æ— æ³•åŒæ—¶è§£å†³ODEçš„åˆšåº¦é—®é¢˜å’ŒåŠçº¿æ€§ç»“æ„ä¾èµ–é—®é¢˜ã€‚</li>
<li>å¼•å…¥çš„STORKæ–¹æ³•è§£å†³äº†è¿™ä¸¤ä¸ªè®¾è®¡éš¾é¢˜ã€‚</li>
<li>STORKæ–¹æ³•æé«˜äº†å›¾åƒå’Œè§†é¢‘ç”Ÿæˆçš„æ‰©æ•£å’ŒæµåŠ¨åŒ¹é…é‡‡æ ·çš„è´¨é‡ã€‚</li>
<li>STORKæ–¹æ³•çš„ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24210">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fca0e44570766cf683bf42d6aa8562d4" align="middle">
<img src="https://picx.zhimg.com/v2-82baf2376c26c905709c794901074d68" align="middle">
<img src="https://picx.zhimg.com/v2-5f30f5184c428b5648c67b05b1376dc8" align="middle">
<img src="https://picx.zhimg.com/v2-a135d2e392885adbacf23f3e35661c7b" align="middle">
<img src="https://picx.zhimg.com/v2-611944c35b57f3e65f723f23bae413e0" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="H3AE-High-Compression-High-Speed-and-High-Quality-AutoEncoder-for-Video-Diffusion-Models"><a href="#H3AE-High-Compression-High-Speed-and-High-Quality-AutoEncoder-for-Video-Diffusion-Models" class="headerlink" title="H3AE: High Compression, High Speed, and High Quality AutoEncoder for   Video Diffusion Models"></a>H3AE: High Compression, High Speed, and High Quality AutoEncoder for   Video Diffusion Models</h2><p><strong>Authors:Yushu Wu, Yanyu Li, Ivan Skorokhodov, Anil Kag, Willi Menapace, Sharath Girish, Aliaksandr Siarohin, Yanzhi Wang, Sergey Tulyakov</strong></p>
<p>Autoencoder (AE) is the key to the success of latent diffusion models for image and video generation, reducing the denoising resolution and improving efficiency. However, the power of AE has long been underexplored in terms of network design, compression ratio, and training strategy. In this work, we systematically examine the architecture design choices and optimize the computation distribution to obtain a series of efficient and high-compression video AEs that can decode in real time even on mobile devices. We also propose an omni-training objective to unify the design of plain Autoencoder and image-conditioned I2V VAE, achieving multifunctionality in a single VAE network but with enhanced quality. In addition, we propose a novel latent consistency loss that provides stable improvements in reconstruction quality. Latent consistency loss outperforms prior auxiliary losses including LPIPS, GAN and DWT in terms of both quality improvements and simplicity. H3AE achieves ultra-high compression ratios and real-time decoding speed on GPU and mobile, and outperforms prior arts in terms of reconstruction metrics by a large margin. We finally validate our AE by training a DiT on its latent space and demonstrate fast, high-quality text-to-video generation capability. </p>
<blockquote>
<p>è‡ªç¼–ç å™¨ï¼ˆAEï¼‰æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ–¹é¢å–å¾—æˆåŠŸçš„å…³é”®ï¼Œå®ƒå¯ä»¥é™ä½é™å™ªåˆ†è¾¨ç‡å¹¶æé«˜æ•ˆç‡ã€‚ç„¶è€Œï¼Œå…³äºè‡ªç¼–ç å™¨çš„ç½‘ç»œè®¾è®¡ã€å‹ç¼©æ¯”å’Œè®­ç»ƒç­–ç•¥ç­‰æ–¹é¢çš„æ½œåŠ›é•¿æœŸä»¥æ¥ä¸€ç›´æœªè¢«å……åˆ†æ¢ç´¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ç ”ç©¶äº†æ¶æ„è®¾è®¡é€‰æ‹©ï¼Œä¼˜åŒ–äº†è®¡ç®—åˆ†é…ï¼Œè·å¾—äº†ä¸€ç³»åˆ—é«˜æ•ˆçš„é«˜å‹ç¼©è§†é¢‘è‡ªç¼–ç å™¨ï¼Œå³ä½¿åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä¹Ÿèƒ½å®æ—¶è§£ç ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªå…¨é¢çš„è®­ç»ƒç›®æ ‡ï¼Œä»¥ç»Ÿä¸€æ™®é€šè‡ªç¼–ç å™¨å’Œå›¾åƒæ¡ä»¶I2V VAEçš„è®¾è®¡ï¼Œåœ¨ä¸€ä¸ªå•ä¸€çš„VAEç½‘ç»œä¸­å®ç°å¤šåŠŸèƒ½æ€§ï¼ŒåŒæ—¶æé«˜äº†è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ½œåœ¨ä¸€è‡´æ€§æŸå¤±ï¼Œåœ¨é‡å»ºè´¨é‡æ–¹é¢æä¾›äº†ç¨³å®šçš„æ”¹è¿›ã€‚æ½œåœ¨ä¸€è‡´æ€§æŸå¤±åœ¨è´¨é‡å’Œç®€æ´æ€§æ–¹é¢ä¼˜äºå…ˆå‰çš„è¾…åŠ©æŸå¤±ï¼ŒåŒ…æ‹¬LPIPSã€GANå’ŒDWTã€‚H3AEåœ¨GPUå’Œç§»åŠ¨è®¾å¤‡ä¸Šå®ç°äº†è¶…é«˜å‹ç¼©æ¯”å’Œå®æ—¶è§£ç é€Ÿåº¦ï¼Œåœ¨é‡å»ºæŒ‡æ ‡ä¸Šå¤§å¤§ä¼˜äºå…ˆå‰æŠ€æœ¯ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡åœ¨å…¶æ½œåœ¨ç©ºé—´ä¸Šè®­ç»ƒDiTæ¥éªŒè¯æˆ‘ä»¬çš„è‡ªç¼–ç å™¨ï¼Œå¹¶å±•ç¤ºäº†å¿«é€Ÿã€é«˜è´¨é‡çš„æ–‡å­—åˆ°è§†é¢‘ç”Ÿæˆèƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10567v2">PDF</a> 17 pages, 6 figures, 9 tables</p>
<p><strong>Summary</strong></p>
<p>è‡ªåŠ¨ç¼–ç å™¨ï¼ˆAEï¼‰æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒå’Œè§†é¢‘ç”Ÿæˆä¸­æˆåŠŸçš„å…³é”®ï¼Œèƒ½å¤Ÿé™ä½å»å™ªåˆ†è¾¨ç‡å¹¶æé«˜æ•ˆç‡ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†æ¶æ„è®¾è®¡çš„é€‰æ‹©ï¼Œä¼˜åŒ–äº†è®¡ç®—åˆ†å¸ƒï¼Œè·å¾—äº†ä¸€ç³»åˆ—é«˜æ•ˆã€é«˜å‹ç¼©çš„è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œå³ä½¿åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä¹Ÿèƒ½å®æ—¶è§£ç ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§å…¨é¢çš„è®­ç»ƒç›®æ ‡ï¼Œå®ç°äº†æ™®é€šè‡ªåŠ¨ç¼–ç å™¨å’Œå›¾åƒæ¡ä»¶I2V VAEçš„ç»Ÿä¸€è®¾è®¡ï¼Œåœ¨å•ä¸ªVAEç½‘ç»œä¸­å®ç°å¤šåŠŸèƒ½å¹¶å¢å¼ºäº†è´¨é‡ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ½œåœ¨ä¸€è‡´æ€§æŸå¤±ï¼Œåœ¨é‡å»ºè´¨é‡æ–¹é¢æä¾›äº†ç¨³å®šçš„æ”¹è¿›ã€‚æ½œåœ¨ä¸€è‡´æ€§æŸå¤±åœ¨è´¨é‡å’Œç®€æ´æ€§æ–¹é¢ä¼˜äºå…ˆå‰çš„è¾…åŠ©æŸå¤±ï¼ŒåŒ…æ‹¬LPIPSã€GANå’ŒDWTã€‚H3AEåœ¨GPUå’Œç§»åŠ¨è®¾å¤‡ä¸Šå®ç°äº†è¶…é«˜å‹ç¼©æ¯”å’Œå®æ—¶è§£ç é€Ÿåº¦ï¼Œåœ¨é‡å»ºæŒ‡æ ‡ä¸Šå¤§å¹…ä¼˜äºå…ˆå‰æŠ€æœ¯ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡åœ¨å…¶æ½œåœ¨ç©ºé—´ä¸Šè®­ç»ƒDiTæ¥éªŒè¯æˆ‘ä»¬çš„AEï¼Œå¹¶å±•ç¤ºäº†å¿«é€Ÿã€é«˜è´¨é‡çš„æ–‡å­—åˆ°è§†é¢‘ç”Ÿæˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨ç¼–ç å™¨ï¼ˆAEï¼‰æ˜¯æ½œåœ¨æ‰©æ•£æ¨¡å‹æˆåŠŸçš„å…³é”®ï¼Œèƒ½é™ä½å»å™ªåˆ†è¾¨ç‡å¹¶æé«˜å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ•ˆç‡ã€‚</li>
<li>ç ”ç©¶ä¼˜åŒ–äº†è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨çš„æ¶æ„è®¾è®¡ï¼Œå®ç°é«˜æ•ˆã€é«˜å‹ç¼©çš„è§†é¢‘å¤„ç†ï¼Œæ”¯æŒå®æ—¶è§£ç ï¼ŒåŒ…æ‹¬åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šã€‚</li>
<li>æå‡ºå…¨é¢çš„è®­ç»ƒç›®æ ‡ï¼Œç»Ÿä¸€æ™®é€šè‡ªåŠ¨ç¼–ç å™¨å’Œå›¾åƒæ¡ä»¶I2V VAEçš„è®¾è®¡ï¼Œå¢å¼ºç½‘ç»œå¤šåŠŸèƒ½æ€§å’Œè´¨é‡ã€‚</li>
<li>å¼•å…¥æ–°å‹æ½œåœ¨ä¸€è‡´æ€§æŸå¤±ï¼Œæœ‰æ•ˆæé«˜é‡å»ºè´¨é‡ï¼Œä¼˜äºå…¶ä»–è¾…åŠ©æŸå¤±æ–¹æ³•ã€‚</li>
<li>H3AEåœ¨GPUå’Œç§»åŠ¨è®¾å¤‡ä¸Šå®ç°è¶…é«˜å‹ç¼©æ¯”å’Œå¿«é€Ÿè§£ç ï¼Œå¹¶åœ¨é‡å»ºæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>å®éªŒéªŒè¯äº†AEçš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆèƒ½åŠ›ï¼Œè¡¨ç°å‡ºé«˜è´¨é‡å’Œå¿«é€Ÿç”Ÿæˆçš„ç‰¹ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10567">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b7341ab9fab8faed96e3b78d048d1147" align="middle">
<img src="https://picx.zhimg.com/v2-1765bc676dd0302c524601fc33903dfb" align="middle">
<img src="https://picx.zhimg.com/v2-86b605fa7c574a0db31d0464b3e3610e" align="middle">
<img src="https://picx.zhimg.com/v2-cba9f36a5c9dc7b11ef17d4a488f550b" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BlobCtrl-Taming-Controllable-Blob-for-Element-level-Image-Editing"><a href="#BlobCtrl-Taming-Controllable-Blob-for-Element-level-Image-Editing" class="headerlink" title="BlobCtrl: Taming Controllable Blob for Element-level Image Editing"></a>BlobCtrl: Taming Controllable Blob for Element-level Image Editing</h2><p><strong>Authors:Yaowei Li, Lingen Li, Zhaoyang Zhang, Xiaoyu Li, Guangzhi Wang, Hongxiang Li, Xiaodong Cun, Ying Shan, Yuexian Zou</strong></p>
<p>As user expectations for image editing continue to rise, the demand for flexible, fine-grained manipulation of specific visual elements presents a challenge for current diffusion-based methods. In this work, we present BlobCtrl, a framework for element-level image editing based on a probabilistic blob-based representation. Treating blobs as visual primitives, BlobCtrl disentangles layout from appearance, affording fine-grained, controllable object-level manipulation. Our key contributions are twofold: (1) an in-context dual-branch diffusion model that separates foreground and background processing, incorporating blob representations to explicitly decouple layout and appearance, and (2) a self-supervised disentangle-then-reconstruct training paradigm with an identity-preserving loss function, along with tailored strategies to efficiently leverage blob-image pairs. To foster further research, we introduce BlobData for large-scale training and BlobBench, a benchmark for systematic evaluation. Experimental results demonstrate that BlobCtrl achieves state-of-the-art performance in a variety of element-level editing tasks, such as object addition, removal, scaling, and replacement, while maintaining computational efficiency. Project Webpage: <a target="_blank" rel="noopener" href="https://liyaowei-stu.github.io/project/BlobCtrl/">https://liyaowei-stu.github.io/project/BlobCtrl/</a> </p>
<blockquote>
<p>éšç€ç”¨æˆ·å¯¹å›¾åƒç¼–è¾‘çš„æœŸæœ›ä¸æ–­æé«˜ï¼Œå¯¹ç‰¹å®šè§†è§‰å…ƒç´ è¿›è¡Œçµæ´»ã€ç²¾ç»†æ“æ§çš„éœ€æ±‚ä¸ºå½“å‰åŸºäºæ‰©æ•£çš„æ–¹æ³•å¸¦æ¥äº†æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†BlobCtrlï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ¦‚ç‡æ€§blobè¡¨ç¤ºçš„å…ƒç´ çº§å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚å°†blobè§†ä¸ºè§†è§‰åŸºæœ¬å…ƒç´ ï¼ŒBlobCtrlå°†å¸ƒå±€å’Œå¤–è§‚åˆ†å¼€å¤„ç†ï¼Œå®ç°äº†ç²¾ç»†å¯æ§çš„å¯¹è±¡çº§æ“ä½œã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æœ‰ä¸¤ç‚¹ï¼šï¼ˆ1ï¼‰ä¸Šä¸‹æ–‡ä¸­çš„åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†å‰æ™¯å’ŒèƒŒæ™¯å¤„ç†åˆ†å¼€ï¼Œé€šè¿‡èå…¥blobè¡¨ç¤ºæ¥æ˜¾å¼åœ°è§£è€¦å¸ƒå±€å’Œå¤–è§‚ï¼›ï¼ˆ2ï¼‰é‡‡ç”¨è‡ªç›‘ç£çš„è§£è€¦é‡å»ºè®­ç»ƒèŒƒå¼ï¼Œå¹¶é…æœ‰èº«ä»½ä¿æŒæŸå¤±å‡½æ•°ï¼Œä»¥åŠé’ˆå¯¹blobå›¾åƒå¯¹è¿›è¡Œæœ‰æ•ˆåˆ©ç”¨çš„å®šåˆ¶ç­–ç•¥ã€‚ä¸ºäº†ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç”¨äºå¤§è§„æ¨¡è®­ç»ƒçš„BlobDataå’Œç”¨äºç³»ç»Ÿè¯„ä¼°çš„BlobBenchåŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBlobCtrlåœ¨å„ç§å…ƒç´ çº§ç¼–è¾‘ä»»åŠ¡ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¦‚å¯¹è±¡æ·»åŠ ã€åˆ é™¤ã€ç¼©æ”¾å’Œæ›¿æ¢ï¼ŒåŒæ—¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚é¡¹ç›®ç½‘é¡µï¼š<a target="_blank" rel="noopener" href="https://liyaowei-stu.github.io/project/BlobCtrl/">https://liyaowei-stu.github.io/project/BlobCtrl/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13434v2">PDF</a> Project Webpage: <a target="_blank" rel="noopener" href="https://liyaowei-stu.github.io/project/BlobCtrl/">https://liyaowei-stu.github.io/project/BlobCtrl/</a>   This version presents a major update with rephrased writing. Accepted to   SIGGRAPH Asia 2025</p>
<p><strong>Summary</strong><br>     éšç€ç”¨æˆ·å¯¹å›¾åƒç¼–è¾‘çš„æœŸæœ›ä¸æ–­æé«˜ï¼Œå¯¹ç‰¹å®šè§†è§‰å…ƒç´ è¿›è¡Œçµæ´»ã€ç²¾ç»†çš„æ“æ§å¯¹å½“å‰çš„æ‰©æ•£æ–¹æ³•æå‡ºäº†æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†BlobCtrlæ¡†æ¶ï¼ŒåŸºäºæ¦‚ç‡æ€§æ–‘å—è¡¨ç¤ºè¿›è¡Œå…ƒç´ çº§å›¾åƒç¼–è¾‘ã€‚BlobCtrlå°†æ–‘å—è§†ä¸ºè§†è§‰åŸºæœ¬å…ƒç´ ï¼Œä½¿å¸ƒå±€å’Œå¤–è§‚åˆ†ç¦»ï¼Œä»è€Œå®ç°ç²¾ç»†ã€å¯æ§çš„å¯¹è±¡çº§æ“ä½œã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šä¸€ã€ä¸Šä¸‹æ–‡åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹ï¼Œå°†å‰æ™¯å’ŒèƒŒæ™¯å¤„ç†åˆ†ç¦»ï¼Œç»“åˆæ–‘å—è¡¨ç¤ºæ˜¾å¼åœ°è§£è€¦å¸ƒå±€å’Œå¤–è§‚ï¼›äºŒã€è‡ªæˆ‘ç›‘ç£çš„è§£è€¦é‡å»ºè®­ç»ƒæ¨¡å¼ï¼Œå…·æœ‰èº«ä»½ä¿ç•™çš„æŸå¤±å‡½æ•°ï¼Œä»¥åŠæœ‰æ•ˆåˆ©ç”¨æ–‘å—å›¾åƒå¯¹çš„ç­–ç•¥ã€‚ä¸ºæ”¯æŒè¿›ä¸€æ­¥ç ”ç©¶ï¼Œå¼•å…¥äº†BlobDataç”¨äºå¤§è§„æ¨¡è®­ç»ƒå’ŒBlobBenchç³»ç»Ÿè¯„ä¼°åŸºå‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBlobCtrlåœ¨å…ƒç´ çº§ç¼–è¾‘ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¦‚å¯¹è±¡æ·»åŠ ã€åˆ é™¤ã€ç¼©æ”¾å’Œæ›¿æ¢ï¼ŒåŒæ—¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”¨æˆ·å¯¹å›¾åƒç¼–è¾‘çš„æœŸæœ›ä¸æ–­æé«˜ï¼Œå¯¹ç‰¹å®šè§†è§‰å…ƒç´ çš„ç²¾ç»†æ“æ§æˆä¸ºæŒ‘æˆ˜ã€‚</li>
<li>BlobCtrlæ¡†æ¶åŸºäºæ¦‚ç‡æ€§æ–‘å—è¡¨ç¤ºè¿›è¡Œå…ƒç´ çº§å›¾åƒç¼–è¾‘ã€‚</li>
<li>BlobCtrlå°†å¸ƒå±€å’Œå¤–è§‚è§£è€¦ï¼Œå®ç°ç²¾ç»†ã€å¯æ§çš„å¯¹è±¡çº§æ“ä½œã€‚</li>
<li>ä¸»è¦è´¡çŒ®åŒ…æ‹¬ä¸Šä¸‹æ–‡åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹å’Œè‡ªæˆ‘ç›‘ç£çš„è§£è€¦é‡å»ºè®­ç»ƒæ¨¡å¼ã€‚</li>
<li>å¼•å…¥äº†BlobDataç”¨äºå¤§è§„æ¨¡è®­ç»ƒå’ŒBlobBenchä½œä¸ºç³»ç»Ÿè¯„ä¼°åŸºå‡†ã€‚</li>
<li>BlobCtrlåœ¨å…ƒç´ çº§ç¼–è¾‘ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13434">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c025340fe7a1a877c8e9a53a7b48c927" align="middle">
<img src="https://picx.zhimg.com/v2-88018e9c912ed6575c1322096fbd831f" align="middle">
<img src="https://picx.zhimg.com/v2-0e0925a9f681a5fc6dafb1f697226b84" align="middle">
<img src="https://picx.zhimg.com/v2-09bc6f38b6767a984174c03afb27963b" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Diffusion-Model-as-a-Noise-Aware-Latent-Reward-Model-for-Step-Level-Preference-Optimization"><a href="#Diffusion-Model-as-a-Noise-Aware-Latent-Reward-Model-for-Step-Level-Preference-Optimization" class="headerlink" title="Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level   Preference Optimization"></a>Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level   Preference Optimization</h2><p><strong>Authors:Tao Zhang, Cheng Da, Kun Ding, Huan Yang, Kun Jin, Yan Li, Tingting Gao, Di Zhang, Shiming Xiang, Chunhong Pan</strong></p>
<p>Preference optimization for diffusion models aims to align them with human preferences for images. Previous methods typically use Vision-Language Models (VLMs) as pixel-level reward models to approximate human preferences. However, when used for step-level preference optimization, these models face challenges in handling noisy images of different timesteps and require complex transformations into pixel space. In this work, we show that pre-trained diffusion models are naturally suited for step-level reward modeling in the noisy latent space, as they are explicitly designed to process latent images at various noise levels. Accordingly, we propose the Latent Reward Model (LRM), which repurposes components of the diffusion model to predict preferences of latent images at arbitrary timesteps. Building on LRM, we introduce Latent Preference Optimization (LPO), a step-level preference optimization method conducted directly in the noisy latent space. Experimental results indicate that LPO significantly improves the modelâ€™s alignment with general, aesthetic, and text-image alignment preferences, while achieving a 2.5-28x training speedup over existing preference optimization methods. Our code and models are available at <a target="_blank" rel="noopener" href="https://github.com/Kwai-Kolors/LPO">https://github.com/Kwai-Kolors/LPO</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹çš„åå¥½ä¼˜åŒ–æ—¨åœ¨ä½¿å›¾åƒä¸äººç±»åå¥½å¯¹é½ã€‚ä¹‹å‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä½œä¸ºåƒç´ çº§å¥–åŠ±æ¨¡å‹æ¥è¿‘ä¼¼äººç±»åå¥½ã€‚ç„¶è€Œï¼Œå½“ç”¨äºæ­¥éª¤çº§åå¥½ä¼˜åŒ–æ—¶ï¼Œè¿™äº›æ¨¡å‹åœ¨å¤„ç†ä¸åŒæ—¶é—´æ­¥çš„å™ªå£°å›¾åƒæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦å°†å¤æ‚çš„è½¬æ¢è¿›è¡Œåˆ°åƒç´ ç©ºé—´ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è‡ªç„¶é€‚ç”¨äºå™ªå£°æ½œåœ¨ç©ºé—´çš„æ­¥éª¤çº§å¥–åŠ±å»ºæ¨¡ï¼Œå› ä¸ºå®ƒä»¬è¢«æ˜ç¡®è®¾è®¡ä¸ºå¤„ç†å„ç§å™ªå£°æ°´å¹³çš„æ½œåœ¨å›¾åƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†æ½œåœ¨å¥–åŠ±æ¨¡å‹ï¼ˆLRMï¼‰ï¼Œè¯¥æ¨¡å‹é‡æ–°åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç»„ä»¶æ¥é¢„æµ‹ä»»æ„æ—¶é—´æ­¥çš„æ½œåœ¨å›¾åƒçš„åå¥½ã€‚åŸºäºLRMï¼Œæˆ‘ä»¬å¼•å…¥äº†æ½œåœ¨åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç›´æ¥åœ¨å™ªå£°æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œçš„æ­¥éª¤çº§åå¥½ä¼˜åŒ–æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLPOæ˜¾è‘—æé«˜äº†æ¨¡å‹ä¸ä¸€èˆ¬åå¥½ã€å®¡ç¾åå¥½å’Œæ–‡æœ¬å›¾åƒå¯¹é½åå¥½çš„å¯¹é½ç¨‹åº¦ï¼ŒåŒæ—¶å®ç°äº†ç›¸å¯¹äºç°æœ‰åå¥½ä¼˜åŒ–æ–¹æ³•çš„2.5-28å€è®­ç»ƒé€Ÿåº¦æå‡ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Kwai-Kolors/LPO%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Kwai-Kolors/LPOæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01051v4">PDF</a> NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„åå¥½ä¼˜åŒ–ï¼Œæ—¨åœ¨ä½¿å›¾åƒä¸äººç±»åå¥½å¯¹é½ã€‚ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä½œä¸ºåƒç´ çº§å¥–åŠ±æ¨¡å‹æ¥æ¨¡æ‹Ÿäººç±»åå¥½ï¼Œä½†åœ¨å¤„ç†ä¸åŒæ—¶é—´æ­¥çš„å™ªå£°å›¾åƒæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¤©ç„¶é€‚åˆå™ªå£°æ½œåœ¨ç©ºé—´çš„æ­¥çº§å¥–åŠ±å»ºæ¨¡ï¼Œå¹¶ä»‹ç»äº†æ½œåœ¨å¥–åŠ±æ¨¡å‹ï¼ˆLRMï¼‰ã€‚åŸºäºLRMï¼Œæœ¬æ–‡æå‡ºäº†æ½œåœ¨åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰ï¼Œç›´æ¥åœ¨å™ªå£°æ½œåœ¨ç©ºé—´è¿›è¡Œæ­¥çº§åå¥½ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLPOåœ¨é€šç”¨ã€ç¾å­¦å’Œæ–‡æœ¬å›¾åƒå¯¹é½åå¥½æ–¹é¢æ˜¾è‘—æé«˜æ¨¡å‹å¯¹é½åº¦ï¼ŒåŒæ—¶å®ç°ç°æœ‰åå¥½ä¼˜åŒ–æ–¹æ³•çš„2.5-28å€è®­ç»ƒé€Ÿåº¦æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹çš„åå¥½ä¼˜åŒ–æ—¨åœ¨ä½¿å›¾åƒä¸äººç±»åå¥½å¯¹é½ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä½œä¸ºåƒç´ çº§å¥–åŠ±æ¨¡å‹ï¼Œå¤„ç†ä¸åŒæ—¶é—´æ­¥çš„å™ªå£°å›¾åƒæ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹é€‚åˆè¿›è¡Œå™ªå£°æ½œåœ¨ç©ºé—´çš„æ­¥çº§å¥–åŠ±å»ºæ¨¡ã€‚</li>
<li>æå‡ºäº†æ½œåœ¨å¥–åŠ±æ¨¡å‹ï¼ˆLRMï¼‰ä»¥é¢„æµ‹ä¸åŒæ—¶é—´æ­¥çš„æ½œåœ¨å›¾åƒçš„åå¥½ã€‚</li>
<li>åŸºäºLRMï¼Œå¼•å…¥äº†æ½œåœ¨åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰ï¼Œç›´æ¥åœ¨å™ªå£°æ½œåœ¨ç©ºé—´è¿›è¡Œæ­¥çº§åå¥½ä¼˜åŒ–ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒLPOåœ¨å¤šç§åå¥½æ–¹é¢æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ï¼ŒåŒæ—¶å®ç°è®­ç»ƒé€Ÿåº¦æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01051">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ff2b67b0457b56d39c1b4368cfd333b" align="middle">
<img src="https://picx.zhimg.com/v2-40245af21d182d5cbb5fd4cac79c8e1c" align="middle">
<img src="https://picx.zhimg.com/v2-3eb1dd74e5a6200b0cc64dc78d185572" align="middle">
<img src="https://picx.zhimg.com/v2-247a0b8c6ce3d0ad2feaa6dfd33a5440" align="middle">
<img src="https://picx.zhimg.com/v2-6ea0fa1ed50d9779b7a5bc2d60223c81" align="middle">
<img src="https://picx.zhimg.com/v2-aae9eafe05331d1c6c6ee6e8a71f7ff3" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Towards-More-Accurate-Diffusion-Model-Acceleration-with-A-Timestep-Tuner"><a href="#Towards-More-Accurate-Diffusion-Model-Acceleration-with-A-Timestep-Tuner" class="headerlink" title="Towards More Accurate Diffusion Model Acceleration with A Timestep Tuner"></a>Towards More Accurate Diffusion Model Acceleration with A Timestep Tuner</h2><p><strong>Authors:Mengfei Xia, Yujun Shen, Changsong Lei, Yu Zhou, Ran Yi, Deli Zhao, Wenping Wang, Yong-Jin Liu</strong></p>
<p>A diffusion model, which is formulated to produce an image using thousands of denoising steps, usually suffers from a slow inference speed. Existing acceleration algorithms simplify the sampling by skipping most steps yet exhibit considerable performance degradation. By viewing the generation of diffusion models as a discretized integral process, we argue that the quality drop is partly caused by applying an inaccurate integral direction to a timestep interval. To rectify this issue, we propose a \textbf{timestep tuner} that helps find a more accurate integral direction for a particular interval at the minimum cost. Specifically, at each denoising step, we replace the original parameterization by conditioning the network on a new timestep, enforcing the sampling distribution towards the real one. Extensive experiments show that our plug-in design can be trained efficiently and boost the inference performance of various state-of-the-art acceleration methods, especially when there are few denoising steps. For example, when using 10 denoising steps on LSUN Bedroom dataset, we improve the FID of DDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate set of timesteps. Code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/THU-LYJ-Lab/time-tuner%7D%7Bhttps://github.com/THU-LYJ-Lab/time-tuner%7D">https://github.com/THU-LYJ-Lab/time-tuner}{https://github.com/THU-LYJ-Lab/time-tuner}</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹é€šè¿‡æ•°åƒæ­¥å»å™ªæ­¥éª¤ç”Ÿæˆå›¾åƒï¼Œé€šå¸¸é¢ä¸´æ¨ç†é€Ÿåº¦è¾ƒæ…¢çš„é—®é¢˜ã€‚ç°æœ‰çš„åŠ é€Ÿç®—æ³•é€šè¿‡è·³è¿‡å¤§éƒ¨åˆ†æ­¥éª¤æ¥ç®€åŒ–é‡‡æ ·ï¼Œä½†ä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè§†ä¸ºç¦»æ•£ç§¯åˆ†è¿‡ç¨‹ï¼Œè®¤ä¸ºè´¨é‡ä¸‹é™éƒ¨åˆ†æ˜¯ç”±äºå¯¹æ—¶é—´æ­¥é•¿åº”ç”¨äº†ä¸å‡†ç¡®çš„æ–¹å‘ç§¯åˆ†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§<strong>æ—¶é—´æ­¥é•¿è°ƒæ•´å™¨</strong>ï¼Œå®ƒå¯ä»¥å¸®åŠ©ä»¥æœ€ä½æˆæœ¬ä¸ºç‰¹å®šé—´éš”æ‰¾åˆ°æ›´ç²¾ç¡®çš„æ–¹å‘ç§¯åˆ†ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»¥æ–°çš„æ—¶é—´æ­¥é•¿å¯¹ç½‘ç»œè¿›è¡Œæ¡ä»¶çº¦æŸï¼Œæ›¿æ¢åŸå§‹å‚æ•°åŒ–ï¼Œå¼ºåˆ¶é‡‡æ ·åˆ†å¸ƒæ¥è¿‘çœŸå®åˆ†å¸ƒã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ’ä»¶è®¾è®¡å¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œè®­ç»ƒï¼Œå¹¶æå‡å„ç§æœ€å…ˆè¿›çš„åŠ é€Ÿæ–¹æ³•çš„æ¨ç†æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å»å™ªæ­¥éª¤è¾ƒå°‘æ—¶ã€‚ä¾‹å¦‚ï¼Œåœ¨LSUNå§å®¤æ•°æ®é›†ä¸Šä½¿ç”¨10ä¸ªå»å™ªæ­¥éª¤æ—¶ï¼Œæˆ‘ä»¬ä»…ä»…é€šè¿‡é‡‡ç”¨æˆ‘ä»¬çš„æ–¹æ³•ä¸ºé€‚å½“çš„æ—¶é—´æ­¥é•¿é›†ï¼Œå°±å¯ä»¥å°†DDIMçš„FIDä»9.65æé«˜åˆ°6.07ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/THU-LYJ-Lab/time-tuner%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/THU-LYJ-Lab/time-tunerè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09469v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„æ—¶åºè°ƒæ•´å™¨ï¼ˆtimestep tunerï¼‰ï¼Œè§£å†³äº†ç°æœ‰åŠ é€Ÿç®—æ³•åœ¨ç®€åŒ–é‡‡æ ·è¿‡ç¨‹ä¸­å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚é€šè¿‡å°†æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºç¦»æ•£ç§¯åˆ†è¿‡ç¨‹ï¼Œè¯¥è°ƒæ•´å™¨èƒ½å¤Ÿåœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­ï¼Œé€šè¿‡æ¡ä»¶ç½‘ç»œå¯¹æ–°çš„æ—¶åºè¿›è¡Œå‚æ•°åŒ–ï¼Œä½¿é‡‡æ ·åˆ†å¸ƒæ›´åŠ æ¥è¿‘çœŸå®åˆ†å¸ƒã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæé«˜äº†åŠ é€Ÿæ–¹æ³•çš„æ¨ç†æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨è¾ƒå°‘å»å™ªæ­¥éª¤çš„æƒ…å†µä¸‹ã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹é€šå¸¸é€šè¿‡æ•°åƒæ­¥å»å™ªç”Ÿæˆå›¾åƒï¼Œå¯¼è‡´æ¨ç†é€Ÿåº¦æ…¢ã€‚</li>
<li>ç°æœ‰åŠ é€Ÿç®—æ³•é€šè¿‡è·³è¿‡å¤§éƒ¨åˆ†æ­¥éª¤æ¥ç®€åŒ–é‡‡æ ·ï¼Œä½†ä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚</li>
<li>æœ¬æ–‡å°†æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºç¦»æ•£ç§¯åˆ†è¿‡ç¨‹ï¼Œå¹¶æå‡ºæ—¶åºè°ƒæ•´å™¨ï¼ˆtimestep tunerï¼‰æ¥è§£å†³æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚</li>
<li>æ—¶åºè°ƒæ•´å™¨é€šè¿‡åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­æ¡ä»¶ç½‘ç»œå¯¹æ–°çš„æ—¶åºè¿›è¡Œå‚æ•°åŒ–ï¼Œä½¿é‡‡æ ·åˆ†å¸ƒæ›´æ¥è¿‘çœŸå®åˆ†å¸ƒã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥é«˜æ•ˆè®­ç»ƒï¼Œå¹¶æå‡å„ç§å…ˆè¿›åŠ é€Ÿæ–¹æ³•çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>åœ¨ä½¿ç”¨è¾ƒå°‘å»å™ªæ­¥éª¤çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•è¡¨ç°å°¤å…¶å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.09469">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da4173ee8029b41c382049813f740d10" align="middle">
<img src="https://picx.zhimg.com/v2-7aa046c42a4634fd097ae66f6645ab69" align="middle">
<img src="https://picx.zhimg.com/v2-0cf208ba214649f11d349e46f094a441" align="middle">
<img src="https://picx.zhimg.com/v2-2df68767f8a018b1065f6818df003a92" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-03/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-03/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-03/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6289565d9edbf498866c5591bf0f7bfa" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  A Multimodal LLM Approach for Visual Question Answering on   Multiparametric 3D Brain MRI
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-03/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-03d17805e456b2d5914d6f9c7f69e779" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-03  SMaRt Improving GANs with Score Matching Regularity
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
