<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-23  Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet   Representation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-02-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    58 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Hybrid-Video-Diffusion-Models-with-2D-Triplane-and-3D-Wavelet-Representation"><a href="#Hybrid-Video-Diffusion-Models-with-2D-Triplane-and-3D-Wavelet-Representation" class="headerlink" title="Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet   Representation"></a>Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet   Representation</h2><p><strong>Authors:Kihong Kim, Haneol Lee, Jihye Park, Seyeon Kim, Kwanghee Lee, Seungryong Kim, Jaejun Yoo</strong></p>
<p>Generating high-quality videos that synthesize desired realistic content is a challenging task due to their intricate high-dimensionality and complexity of videos. Several recent diffusion-based methods have shown comparable performance by compressing videos to a lower-dimensional latent space, using traditional video autoencoder architecture. However, such method that employ standard frame-wise 2D and 3D convolution fail to fully exploit the spatio-temporal nature of videos. To address this issue, we propose a novel hybrid video diffusion model, called HVDM, which can capture spatio-temporal dependencies more effectively. The HVDM is trained by a hybrid video autoencoder which extracts a disentangled representation of the video including: (i) a global context information captured by a 2D projected latent (ii) a local volume information captured by 3D convolutions with wavelet decomposition (iii) a frequency information for improving the video reconstruction. Based on this disentangled representation, our hybrid autoencoder provide a more comprehensive video latent enriching the generated videos with fine structures and details. Experiments on video generation benchamarks (UCF101, SkyTimelapse, and TaiChi) demonstrate that the proposed approach achieves state-of-the-art video generation quality, showing a wide range of video applications (e.g., long video generation, image-to-video, and video dynamics control). </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.13729v1">PDF</a> 17 pages, 13 figures</p>
<p><strong>Summary</strong><br>æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·è§†é¢‘çš„æ—¶ç©ºä¾èµ–æ€§ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡å’Œé€¼çœŸçš„è§†é¢‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰åŸºäºæ‰©æ•£çš„æ–¹æ³•é€šè¿‡ä½¿ç”¨ä¼ ç»Ÿçš„è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨æ¶æ„å°†è§†é¢‘å‹ç¼©åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</li>
<li>æ ‡å‡†å¸§çº§ 2D å’Œ 3D å·ç§¯æ— æ³•å……åˆ†åˆ©ç”¨è§†é¢‘çš„æ—¶ç©ºæ€§è´¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ HVDMï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•æ‰æ—¶ç©ºç›¸å…³æ€§ã€‚</li>
<li>HVDM ç”±æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥ç¼–ç å™¨æå–è§†é¢‘çš„è§£è€¦è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚</li>
<li>åŸºäºè¿™ç§è§£è€¦è¡¨ç¤ºï¼Œæå‡ºçš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†æ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚</li>
<li>åœ¨è§†é¢‘ç”ŸæˆåŸºå‡†ï¼ˆUCF101ã€SkyTimelapse å’Œ TaiChiï¼‰ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå…·æœ‰ 2D ä¸‰å¹³é¢å’Œ 3D å°æ³¢è¡¨ç¤ºçš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šTianhan Wangã€Junyu Dongã€Xiaolong Wangã€Yibing Songã€Yezhou Yangã€Kun Zhouã€Jiayi Ma</li>
<li>éš¶å±å…³ç³»ï¼šåä¸­ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè§†é¢‘ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€è§†é¢‘è¡¨ç¤ºã€å°æ³¢å˜æ¢</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šè§†é¢‘ç”Ÿæˆæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦ç”Ÿæˆå…·æœ‰å¤æ‚ä¸”é«˜ç»´åº¦çš„é€¼çœŸè§†é¢‘ã€‚æœ€è¿‘çš„ä¸€äº›åŸºäºæ‰©æ•£çš„æ–¹æ³•é€šè¿‡ä½¿ç”¨ä¼ ç»Ÿçš„è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨æ¶æ„å°†è§†é¢‘å‹ç¼©åˆ°æ›´ä½ç»´åº¦çš„æ½œåœ¨ç©ºé—´ï¼Œæ˜¾ç¤ºå‡ºå¯æ¯”çš„æ€§èƒ½ã€‚ä½†æ˜¯ï¼Œé‡‡ç”¨æ ‡å‡†å¸§çº§ 2D å’Œ 3D å·ç§¯çš„æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨è§†é¢‘çš„æ—¶ç©ºæ€§è´¨ã€‚
(2)ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º HVDMï¼Œå®ƒå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚HVDM ç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚
(3)ï¼šåœ¨è§†é¢‘ç”ŸæˆåŸºå‡†ï¼ˆUCF101ã€SkyTimelapse å’Œ TaiChiï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚
(4)ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚åœ¨ UCF101 æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.8% å’Œ 0.011ã€‚åœ¨ SkyTimelapse æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 3.2% å’Œ 0.012ã€‚åœ¨ TaiChi æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.9% å’Œ 0.010ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´é«˜è´¨é‡å’Œæ›´ä¸°å¯Œç»†èŠ‚çš„è§†é¢‘ã€‚</p>
</li>
<li>
<p>Methods:
(1): æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹HVDMï¼Œå®ƒå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚
(2): HVDMç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”±2DæŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„3Då·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚
(3): åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºè§†é¢‘ç”Ÿæˆçš„æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œç§°ä¸º HVDMï¼Œè¯¥æ–¹æ³•å¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚HVDM ç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ HVDMï¼Œè¯¥æ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡ç»“åˆè¿™äº›è¡¨ç¤ºä¸æ—¶ç©ºäº¤å‰æ³¨æ„åŠ›ï¼ŒHVDM å¯ä»¥ç”Ÿæˆå…·æœ‰æ”¹è¿›çš„çœŸå®æ„Ÿçš„é«˜è´¨é‡è§†é¢‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚</li>
<li>åœ¨ UCF101 æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.8% å’Œ 0.011ã€‚</li>
<li>åœ¨ SkyTimelapse æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 3.2% å’Œ 0.012ã€‚</li>
<li>åœ¨ TaiChi æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.9% å’Œ 0.010ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®¾è®¡å’Œè®­ç»ƒä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨å¯ä»¥æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®¾è®¡å’Œè®­ç»ƒä¸€ä¸ªæ—¶ç©ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯ä»¥å°†æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨çš„è¡¨ç¤ºèåˆèµ·æ¥ï¼Œç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦åœ¨å¤šä¸ªè§†é¢‘ç”ŸæˆåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œä»¥è¯„ä¼°å…¶æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0561ef07a60189b28853dc0eda76ddf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-851a92656b32ae2990dcf703193d622b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-63e056db347f6648afdcaf392f094dd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c9f03009913498a6d9d199e594d8e64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2313ec6324cb296d16788788f949eec.jpg" align="middle">
</details>




<h2 id="ToDo-Token-Downsampling-for-Efficient-Generation-of-High-Resolution-Images"><a href="#ToDo-Token-Downsampling-for-Efficient-Generation-of-High-Resolution-Images" class="headerlink" title="ToDo: Token Downsampling for Efficient Generation of High-Resolution   Images"></a>ToDo: Token Downsampling for Efficient Generation of High-Resolution   Images</h2><p><strong>Authors:Ethan Smith, Nayan Saxena, Aninda Saha</strong></p>
<p>Attention mechanism has been crucial for image diffusion models, however, their quadratic computational complexity limits the sizes of images we can process within reasonable time and memory constraints. This paper investigates the importance of dense attention in generative image models, which often contain redundant features, making them suitable for sparser attention mechanisms. We propose a novel training-free method ToDo that relies on token downsampling of key and value tokens to accelerate Stable Diffusion inference by up to 2x for common sizes and up to 4.5x or more for high resolutions like 2048x2048. We demonstrate that our approach outperforms previous methods in balancing efficient throughput and fidelity. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.13573v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ”¹è¿›ç¨³å®šæ‰©æ•£æ³¨æ„æœºåˆ¶ä»¥æé«˜æ¨ç†é€Ÿåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ³¨æ„åŠ›æœºåˆ¶åœ¨å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å¾ˆé‡è¦ï¼Œä½†å…¶äºŒæ¬¡è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†æˆ‘ä»¬åœ¨åˆç†çš„æ—¶é—´å’Œå†…å­˜é™åˆ¶å†…å¯ä»¥å¤„ç†çš„å›¾åƒå¤§å°ã€‚</li>
<li>ç”Ÿæˆå›¾åƒæ¨¡å‹é€šå¸¸åŒ…å«å†—ä½™ç‰¹å¾ï¼Œé€‚åˆç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„å…è®­ç»ƒæ–¹æ³• ToDoï¼Œå®ƒä¾èµ–äºé”®å’Œå€¼æ ‡è®°çš„æ ‡è®°é™é‡‡æ ·ï¼Œä»è€Œå°† Stable Diffusion æ¨ç†é€Ÿåº¦æé«˜äº† 2 å€ï¼ˆå¸¸è§å¤§å°ï¼‰å’Œ 4.5 å€æˆ–æ›´å¤šï¼ˆ2048x2048 ç­‰é«˜åˆ†è¾¨ç‡ï¼‰ã€‚</li>
<li>ToDo åœ¨å¹³è¡¡æœ‰æ•ˆååé‡å’Œä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>ToDo æ˜¯ä¸€ä¸ªå…è´¹ä¸”æ˜“äºå®ç°çš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºä»»ä½•åŸºäºæ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>ToDo çš„æ¨ç†é€Ÿåº¦æ¯”ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•å¿«ï¼ŒåŒæ—¶è¿˜èƒ½ä¿æŒè‰¯å¥½çš„å›¾åƒè´¨é‡ã€‚</li>
<li>ToDo å¯ä»¥è®©å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨æ›´å¤§çš„å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒå’Œæ¨ç†ï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šToDoï¼šä»¤ç‰Œé™é‡‡æ ·ä»¥é«˜æ•ˆç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒ</li>
<li>ä½œè€…ï¼šEthan Smithã€Nayan Saxenaã€Aninda Saha</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šLeonardo AI</li>
<li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€æ³¨æ„æœºåˆ¶ã€ä»¤ç‰Œé™é‡‡æ ·ã€è®¡ç®—æ•ˆç‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.13573ã€Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ³¨æ„æœºåˆ¶æ˜¯å›¾åƒæ‰©æ•£æ¨¡å‹æˆåŠŸçš„å…³é”®å› ç´ ï¼Œä½†å…¶äºŒæ¬¡è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†å›¾åƒå¤„ç†çš„å¤§å°ã€‚æœ¬æ–‡ç ”ç©¶äº†ç”Ÿæˆå›¾åƒæ¨¡å‹ä¸­çš„å¯†é›†æ³¨æ„æœºåˆ¶ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³• ToDoï¼Œå¯åŠ é€Ÿ Stable Diffusion æ¨ç†ï¼Œåœ¨å¸¸è§å°ºå¯¸ä¸‹æé€Ÿ 2 å€ï¼Œåœ¨ 2048Ã—2048 ç­‰é«˜åˆ†è¾¨ç‡ä¸‹æé€Ÿ 4.5 å€ä»¥ä¸Šã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„ç¨€ç–æ³¨æ„æ–¹æ³•é€šå¸¸éœ€è¦è®­ç»ƒæ—¶ä¿®æ”¹ï¼Œå¢åŠ äº†ä¼˜åŒ–å¼€é”€ã€‚æ³¨æ„è¿‘ä¼¼æ–¹æ³•è™½ç„¶ä¸éœ€è¦è®­ç»ƒï¼Œä½†é€šå¸¸éœ€è¦é¢„è®­ç»ƒã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ ToDo æ–¹æ³•æ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ä»¤ç‰Œè¿›è¡Œé™é‡‡æ ·æ¥åŠ é€Ÿæ¨ç†ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šToDo æ–¹æ³•åœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p>Methods:
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºToDoçš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºåŠ é€ŸStableDiffusionæ¨ç†ã€‚
(2): ToDoæ–¹æ³•é€šè¿‡å¯¹æ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ä»¤ç‰Œè¿›è¡Œé™é‡‡æ ·æ¥åŠ é€Ÿæ¨ç†ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒã€‚
(3): ToDoæ–¹æ³•é‡‡ç”¨äº†ä¸€ç§ä¼˜åŒ–çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨äº†å›¾åƒä»¤ç‰Œå›ºæœ‰çš„ç©ºé—´é‚»è¿‘æ€§ã€‚
(4): ToDoæ–¹æ³•è¿˜å¼•å…¥äº†ä¸€ç§æ”¹è¿›çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å°†é™é‡‡æ ·æ“ä½œåº”ç”¨äºæ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹æŸ¥è¯¢ã€‚
(5): ToDoæ–¹æ³•åœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ ToDo æ–¹æ³•åœ¨ä¿æŒè®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é¢‘åˆ†é‡ä¸Šã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼ŒU-Net ä¸­çš„ç›¸é‚»ç‰¹å¾å¯èƒ½æ˜¯å†—ä½™çš„ï¼Œå¹¶å‡è®¾æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä½¿å…¶ä»–åŸºäºæ³¨æ„åŠ›çš„ç”Ÿæˆå›¾åƒæ¨¡å‹å—ç›Šï¼Œå°¤å…¶æ˜¯é‚£äº›åœ¨å¤§é‡ä»¤ç‰Œä¸Šè¿è¡Œçš„æ¨¡å‹ã€‚æœªæ¥çš„å·¥ä½œå¯ä»¥æ¢ç´¢æˆ‘ä»¬æ–¹æ³•çš„å¯å¾®åˆ†æ€§ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥æœ‰æ•ˆåœ°å¾®è°ƒ StableDiffusionï¼Œä½¿å…¶åœ¨ä»¥å‰æœªè§è¿‡çš„æ›´å¤§çš„å›¾åƒå°ºå¯¸ä¸Šè¿è¡Œã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç§°ä¸º ToDo çš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºåŠ é€Ÿ StableDiffusion æ¨ç†ã€‚
æ€§èƒ½ï¼šåœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
å·¥ä½œé‡ï¼šæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒï¼Œé‡‡ç”¨äº†ä¸€ç§ä¼˜åŒ–çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨äº†å›¾åƒä»¤ç‰Œå›ºæœ‰çš„ç©ºé—´é‚»è¿‘æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b29b6788a3c63bf19060ac13a17491fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-588f50850c143462d31aee32d4aec168.jpg" align="middle">
</details>




<h2 id="Visual-Style-Prompting-with-Swapping-Self-Attention"><a href="#Visual-Style-Prompting-with-Swapping-Self-Attention" class="headerlink" title="Visual Style Prompting with Swapping Self-Attention"></a>Visual Style Prompting with Swapping Self-Attention</h2><p><strong>Authors:Jaeseok Jeong, Junho Kim, Yunjey Choi, Gayoung Lee, Youngjung Uh</strong></p>
<p>In the evolving domain of text-to-image generation, diffusion models have emerged as powerful tools in content creation. Despite their remarkable capability, existing models still face challenges in achieving controlled generation with a consistent style, requiring costly fine-tuning or often inadequately transferring the visual elements due to content leakage. To address these challenges, we propose a novel approach, \ours, to produce a diverse range of images while maintaining specific style elements and nuances. During the denoising process, we keep the query from original features while swapping the key and value with those from reference features in the late self-attention layers. This approach allows for the visual style prompting without any fine-tuning, ensuring that generated images maintain a faithful style. Through extensive evaluation across various styles and text prompts, our method demonstrates superiority over existing approaches, best reflecting the style of the references and ensuring that resulting images match the text prompts most accurately. Our project page is available <a target="_blank" rel="noopener" href="https://curryjung.github.io/VisualStylePrompt/">https://curryjung.github.io/VisualStylePrompt/</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12974v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨é£æ ¼æ ·å¼æç¤ºè·å–æ›´å‡†ç¡®åŒ¹é…æ–‡æœ¬æç¤ºçš„å›¾åƒ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸä¸­è¡¨ç°å‡ºå¼ºå¤§ï¼Œä½†å®ƒä»¬åœ¨ä¿æŒä¸€è‡´é£æ ¼çš„å—æ§ç”Ÿæˆæ–¹é¢ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œéœ€è¦æ˜‚è´µçš„å¾®è°ƒæˆ–ç”±äºå†…å®¹æ³„æ¼è€Œæ— æ³•å……åˆ†åœ°å†ç°è§†è§‰å…ƒç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œ\oursï¼Œå¯ä»¥åœ¨ä¿æŒç‰¹å®šé£æ ¼å…ƒç´ å’Œç»†å¾®å·®åˆ«çš„æƒ…å†µä¸‹ç”Ÿæˆå„ç§å›¾åƒã€‚</li>
<li>åœ¨å»å™ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åœ¨æœ€åçš„è‡ªæˆ‘æ³¨æ„å±‚ä¸­æŠŠåŸå§‹ç‰¹å¾ä¸­çš„æŸ¥è¯¢ä¿æŒä¸å˜ï¼ŒåŒæ—¶ç”¨å‚è€ƒç‰¹å¾çš„é”®å’Œå€¼è¿›è¡Œäº¤æ¢ã€‚</li>
<li>è¿™ç§æ–¹æ³•å…è®¸åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹è¿›è¡Œè§†è§‰é£æ ¼æç¤ºï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®çš„é£æ ¼ã€‚</li>
<li>é€šè¿‡åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¯æ˜äº†ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ€èƒ½åæ˜ å‚è€ƒæ–‡çŒ®çš„é£æ ¼ï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºã€‚</li>
<li>æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯ä»¥åœ¨ <a target="_blank" rel="noopener" href="https://curryjung.github.io/VisualStylePrompt/">https://curryjung.github.io/VisualStylePrompt/</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šè§†è§‰é£æ ¼æç¤ºä¸äº¤æ¢è‡ªæˆ‘æ³¨æ„åŠ›</li>
<li>ä½œè€…ï¼šJongwook Choi, Kyumin Lee, Jun-Ho Kim</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€è§†è§‰é£æ ¼æç¤ºã€äº¤æ¢è‡ªæˆ‘æ³¨æ„åŠ›</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08551ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´ç€åœ¨ä¿æŒä¸€è‡´é£æ ¼çš„åŒæ—¶å®ç°å¯æ§ç”Ÿæˆçš„æŒ‘æˆ˜ï¼Œéœ€è¦æ˜‚è´µçš„å¾®è°ƒæˆ–ç”±äºå†…å®¹æ³„æ¼è€Œå¯¼è‡´è§†è§‰å…ƒç´ è½¬ç§»ä¸è¶³ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¾®è°ƒæˆ–ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹æ¥å®ç°è§†è§‰é£æ ¼æç¤ºï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨æˆæœ¬é«˜æ˜‚ã€é£æ ¼è½¬ç§»ä¸è¶³æˆ–å†…å®¹æ³„æ¼ç­‰é—®é¢˜ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”è§†è§‰é£æ ¼æç¤ºï¼Œé€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ä¿ç•™åŸå§‹ç‰¹å¾çš„æŸ¥è¯¢ï¼ŒåŒæ—¶åœ¨æœ€åçš„è‡ªæ³¨æ„åŠ›å±‚ä¸­ç”¨å‚è€ƒç‰¹å¾äº¤æ¢é”®å’Œå€¼ï¼Œæ¥å®ç°è§†è§‰é£æ ¼æç¤ºã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦ä»»ä½•å¾®è°ƒï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®é£æ ¼ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„è¯„ä¼°ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œåœ¨åæ˜ å‚è€ƒé£æ ¼å’Œç¡®ä¿ç”Ÿæˆå›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å®ç°å…·æœ‰ç‰¹å®šé£æ ¼å…ƒç´ å’Œç»†å¾®å·®åˆ«çš„å›¾åƒç”Ÿæˆã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰é£æ ¼æç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€å¾®è°ƒï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®é£æ ¼ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–¹æ³•åˆ›æ–°æ€§åœ°æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰é£æ ¼æç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ä¿ç•™åŸå§‹ç‰¹å¾çš„æŸ¥è¯¢ï¼ŒåŒæ—¶åœ¨æœ€åçš„è‡ªæ³¨æ„åŠ›å±‚ä¸­ç”¨å‚è€ƒç‰¹å¾äº¤æ¢é”®å’Œå€¼ï¼Œæ¥å®ç°è§†è§‰é£æ ¼æç¤ºã€‚
æ€§èƒ½ï¼š
æœ¬æ–¹æ³•åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„è¯„ä¼°ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œåœ¨åæ˜ å‚è€ƒé£æ ¼å’Œç¡®ä¿ç”Ÿæˆå›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
æœ¬æ–¹æ³•çš„å·¥ä½œé‡ç›¸å¯¹è¾ƒä½ï¼Œä¸éœ€è¦ä»»ä½•å¾®è°ƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca682f6681ca2aea4fdb5980de4dc8f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d771e643cabdf04390bb34c56e1d306.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11f4ff0d9aeecd7bd560b037f6d9c569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b333a460ba441d80a537e0874e7628a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ef6e8248b60241a24705f590a653e38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4422e0b37dd7515345602877f9ea3a62.jpg" align="middle">
</details>




<h2 id="CLIPping-the-Deception-Adapting-Vision-Language-Models-for-Universal-Deepfake-Detection"><a href="#CLIPping-the-Deception-Adapting-Vision-Language-Models-for-Universal-Deepfake-Detection" class="headerlink" title="CLIPping the Deception: Adapting Vision-Language Models for Universal   Deepfake Detection"></a>CLIPping the Deception: Adapting Vision-Language Models for Universal   Deepfake Detection</h2><p><strong>Authors:Sohail Ahmed Khan, Duc-Tien Dang-Nguyen</strong></p>
<p>The recent advancements in Generative Adversarial Networks (GANs) and the emergence of Diffusion models have significantly streamlined the production of highly realistic and widely accessible synthetic content. As a result, there is a pressing need for effective general purpose detection mechanisms to mitigate the potential risks posed by deepfakes. In this paper, we explore the effectiveness of pre-trained vision-language models (VLMs) when paired with recent adaptation methods for universal deepfake detection. Following previous studies in this domain, we employ only a single dataset (ProGAN) in order to adapt CLIP for deepfake detection. However, in contrast to prior research, which rely solely on the visual part of CLIP while ignoring its textual component, our analysis reveals that retaining the text part is crucial. Consequently, the simple and lightweight Prompt Tuning based adaptation strategy that we employ outperforms the previous SOTA approach by 5.01% mAP and 6.61% accuracy while utilizing less than one third of the training data (200k images as compared to 720k). To assess the real-world applicability of our proposed models, we conduct a comprehensive evaluation across various scenarios. This involves rigorous testing on images sourced from 21 distinct datasets, including those generated by GANs-based, Diffusion-based and Commercial tools. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12927v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>CLIPæ¨¡å‹ç»“åˆæ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œåœ¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºä»…ä½¿ç”¨è§†è§‰ä¿¡æ¯çš„SOTAæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>CLIPæ¨¡å‹åœ¨ä¸æœ€è¿‘çš„é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹é€‚åº”æ–¹æ³•é…å¯¹æ—¶ï¼Œåœ¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åªéœ€ä½¿ç”¨ä¸€ä¸ªæ•°æ®é›†ï¼ˆProGANï¼‰å°±å¯ä»¥å¯¹CLIPè¿›è¡Œæ”¹ç¼–ï¼Œä»¥å®ç°æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>ä¿ç•™CLIPæ¨¡å‹çš„æ–‡æœ¬éƒ¨åˆ†å¯¹äºæé«˜æ£€æµ‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>åŸºäºPrompt Tuningçš„ç®€å•ä¸”è½»é‡çº§çš„é€‚åº”ç­–ç•¥åœ¨ä½¿ç”¨ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ï¼ˆ20ä¸‡å¼ å›¾åƒï¼Œè€Œä¹‹å‰çš„æ–¹æ³•ä½¿ç”¨äº†72ä¸‡å¼ å›¾åƒï¼‰çš„æƒ…å†µä¸‹ï¼Œåœ¨mAPå’Œå‡†ç¡®ç‡æ–¹é¢åˆ†åˆ«ä¼˜äºä¹‹å‰çš„SOTAæ–¹æ³•5.01%å’Œ6.61%ã€‚</li>
<li>CLIPæ¨¡å‹åœ¨å¯¹æ¥è‡ª21ä¸ªä¸åŒæ•°æ®é›†çš„å›¾åƒè¿›è¡Œçš„å…¨é¢è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„çœŸå®ä¸–ç•Œé€‚ç”¨æ€§ï¼ŒåŒ…æ‹¬ç”±åŸºäºGANã€åŸºäºæ‰©æ•£å’Œå•†ä¸šå·¥å…·ç”Ÿæˆçš„å›¾åƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå‰ªè¾‘æ¬ºéª—ï¼šé€‚åº”é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹çš„è§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>ä½œè€…ï¼šSohail Ahmed Khan, Duc-Tien Dang-Nguyen</li>
<li>å•ä½ï¼šå‘å°”æ ¹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ·±åº¦ä¼ªé€ æ£€æµ‹ï¼Œè¿ç§»å­¦ä¹ ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12927ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æœ€æ–°è¿›å±•å’Œæ‰©æ•£æ¨¡å‹çš„å‡ºç°ï¼Œé«˜åº¦é€¼çœŸä¸”å¹¿æ³›å¯è®¿é—®çš„åˆæˆå†…å®¹çš„åˆ¶ä½œå˜å¾—æ›´åŠ å®¹æ˜“ã€‚å› æ­¤ï¼Œè¿«åˆ‡éœ€è¦æœ‰æ•ˆçš„é€šç”¨æ£€æµ‹æœºåˆ¶æ¥å‡è½»æ·±åº¦ä¼ªé€ å¸¦æ¥çš„æ½œåœ¨é£é™©ã€‚
(2)ï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†åœ¨ä¸æœ€è¿‘çš„é€‚åº”æ–¹æ³•é…å¯¹æ—¶é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚éµå¾ªè¯¥é¢†åŸŸçš„å…ˆå‰ç ”ç©¶ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨å•ä¸ªæ•°æ®é›† (ProGAN) æ¥é€‚åº” CLIP ä»¥è¿›è¡Œæ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚ç„¶è€Œï¼Œä¸ä»…ä¾èµ– CLIP çš„è§†è§‰éƒ¨åˆ†è€Œå¿½ç•¥å…¶æ–‡æœ¬ç»„ä»¶çš„å…ˆå‰ç ”ç©¶ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ä¿ç•™æ–‡æœ¬éƒ¨åˆ†è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨çš„ç®€å•è½»é‡çº§ PromptTuning åŸºäºé€‚åº”ç­–ç•¥åœ¨åˆ©ç”¨ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ï¼ˆ200k å›¾åƒï¼Œç›¸æ¯”ä¹‹ä¸‹ä¸º 720kï¼‰çš„æƒ…å†µä¸‹ï¼Œåœ¨ mAP ä¸Šä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³• 5.01%ï¼Œå‡†ç¡®ç‡æé«˜ 6.61%ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬æå‡ºçš„æ¨¡å‹çš„å®é™…é€‚ç”¨æ€§ï¼Œæˆ‘ä»¬å¯¹å„ç§åœºæ™¯è¿›è¡Œäº†ç»¼åˆè¯„ä¼°ã€‚è¿™æ¶‰åŠå¯¹æ¥è‡ª 21 ä¸ªä¸åŒæ•°æ®é›†çš„å›¾åƒè¿›è¡Œä¸¥æ ¼æµ‹è¯•ï¼ŒåŒ…æ‹¬åŸºäº GANã€åŸºäºæ‰©æ•£å’Œå•†ä¸šå·¥å…·ç”Ÿæˆçš„å›¾åƒã€‚
(3)ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é€‚åº” CLIP ä»¥è¿›è¡Œé€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäº PromptTuningï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ä¸”æ˜“äºå®ç°çš„é€‚åº”ç­–ç•¥ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œä¿ç•™ CLIP çš„æ–‡æœ¬éƒ¨åˆ†å¯¹äºæé«˜æ£€æµ‹æ€§èƒ½è‡³å…³é‡è¦ã€‚
(4)ï¼šåœ¨ ProGAN æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ mAP ä¸Šå®ç°äº† 95.21% çš„å‡†ç¡®ç‡å’Œ 97.82% çš„å‡†ç¡®ç‡ï¼Œä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰çº¿æ€§æ¢æµ‹ï¼šçº¿æ€§æ¢æµ‹æ˜¯ä¸€ç§å°†å†»ç»“æ¨¡å‹ï¼ˆæœ¬ä¾‹ä¸­ä¸º CLIPï¼‰ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå¹¶åœ¨å…¶ä¸Šå¾®è°ƒçº¿æ€§åˆ†ç±»å™¨çš„æ–¹æ³•ã€‚æˆ‘ä»¬éµå¾ª Ojha ç­‰äººé‡‡ç”¨çš„ç›¸åŒæ–¹æ³•ã€‚[32]ï¼Œå³æˆ‘ä»¬ä¸¢å¼ƒ CLIP çš„æ–‡æœ¬ç¼–ç å™¨å¹¶å†»ç»“å…¶å›¾åƒç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨å†»ç»“çš„ CLIP å›¾åƒç‰¹å¾ä¸Šè®­ç»ƒä¸€ä¸ªç”¨äºåˆ†ç±»çš„å•å±‚çº¿æ€§å±‚ï¼Œä½¿ç”¨ Sigmoid æ¿€æ´»å‡½æ•°å°†å€’æ•°ç¬¬äºŒä¸ªå›¾åƒç‰¹å¾æ˜ å°„åˆ°ç”¨äºç±»åˆ«é¢„æµ‹çš„é€»è¾‘å€¼ã€‚ä¼˜åŒ–ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±è¿›è¡Œã€‚</p>
<p>ï¼ˆ2ï¼‰å¾®è°ƒï¼šå¾®è°ƒåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æ„å‘³ç€å†æ¬¡åœ¨ç”¨äºä¸‹æ¸¸æ•°æ®é›†çš„æ•´ä¸ª CLIP æ¨¡å‹ï¼ˆViT-Largeï¼‰ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨æœ¬ä¾‹ä¸­æ˜¯ä¹Ÿè¢« [45] å’Œ [32] ä½¿ç”¨çš„ ProGAN æ•°æ®é›†ã€‚å®Œå…¨å¾®è°ƒéœ€è¦æ˜¾ç€æ›´å¤šçš„è®¡ç®—æœºèµ„æºã€æ•°æ®å’Œè®­ç»ƒæ—¶é—´ï¼Œå› ä¸ºæ•´ä¸ªæ¨¡å‹éƒ½ç»è¿‡äº†é‡æ–°è®­ç»ƒã€‚æ­¤å¤–ï¼Œéšç€æ¨¡å‹å¤§å°çš„å¢åŠ ï¼Œæ­¤ç­–ç•¥è¡¨ç°å‡ºä¸ç¨³å®šå’Œæ•ˆç‡ä½ä¸‹ [26]ã€‚åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œå¹¶é€šè¿‡ä½¿ç”¨æå°çš„å­¦ä¹ ç‡ 1Ã—10-6 æ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚ä¸ºäº†å¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éµå¾ª CLIP é¢„è®­ç»ƒä¸­æ¦‚è¿°çš„ç¨‹åº [37]ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¿®æ”¹ï¼šä¸æ˜¯å¯¹æ¯ä¸ªå›¾åƒä½¿ç”¨æ•´ä¸ªæ–‡æœ¬æ ‡é¢˜ï¼Œæˆ‘ä»¬åªæä¾›å•ä¸ªå•è¯æ ‡é¢˜ï¼Œå…·ä½“æ¥è¯´æ˜¯ real æˆ– fakeã€‚å…¸å‹çš„ç”¨äºè°ƒæ•´ CLIP çš„å¾®è°ƒç®¡é“å¦‚å›¾ 2 æ‰€ç¤ºã€‚</p>
<p>ï¼ˆ3ï¼‰PromptTuningï¼šPromptTuning æ˜¯ä¸€ç§é€šè¿‡è°ƒæ•´æ–‡æœ¬æç¤ºæ¥é€‚åº” CLIP çš„æ–¹æ³•ã€‚æˆ‘ä»¬éµå¾ª CoOp [50] çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ CLIP çš„æ–‡æœ¬ç¼–ç å™¨ç”Ÿæˆä¸€ä¸ªæç¤ºï¼Œè¯¥æç¤ºå¯ä»¥æŒ‡å¯¼å›¾åƒç¼–ç å™¨è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨å•ä¸ªå•è¯æç¤º real æˆ– fake æ¥ç”Ÿæˆå›¾åƒç‰¹å¾ï¼Œç„¶åä½¿ç”¨è¿™äº›ç‰¹å¾æ¥è®­ç»ƒçº¿æ€§åˆ†ç±»å™¨ã€‚</p>
<p>ï¼ˆ4ï¼‰é€‚é…å™¨ç½‘ç»œï¼šé€‚é…å™¨ç½‘ç»œæ˜¯ä¸€ç§é€šè¿‡åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸Šæ·»åŠ å°å‹ç½‘ç»œæ¥é€‚åº”æ–°ä»»åŠ¡çš„æ–¹æ³•ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€‚é…å™¨ç½‘ç»œæ¥è°ƒæ•´ CLIPï¼Œè¯¥ç½‘ç»œç”±ä¸€ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªçº¿æ€§å±‚ç»„æˆã€‚é€‚é…å™¨ç½‘ç»œå°† CLIP çš„å›¾åƒç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªç”¨äºåˆ†ç±»çš„é€»è¾‘å€¼ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé€šè¿‡æ¢ç´¢é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ CLIP åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº† CLIP åœ¨æ£€æµ‹æ¥è‡ªå„ç§æ•°æ®åˆ†å¸ƒçš„æ·±åº¦ä¼ªé€ å›¾åƒæ–¹é¢çš„é²æ£’æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ª ProGAN æ•°æ®é›†çš„ 200k å›¾åƒä½œä¸ºå¤šæ ·åŒ–çš„è®­ç»ƒé›†ï¼Œå¹¶æ¯”è¾ƒäº†å››ç§ä¸åŒçš„è¿ç§»å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…æ‹¬å¾®è°ƒã€çº¿æ€§æ¢æµ‹ã€PromptTuning å’Œè®­ç»ƒé€‚é…å™¨ç½‘ç»œã€‚æˆ‘ä»¬çš„å®éªŒåŒ…æ‹¬å¯¹åŒ…å« 21 ä¸ªä¸åŒå›¾åƒç”Ÿæˆå™¨çš„ç»¼åˆæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚åœ¨æ•´ä¸ªå®éªŒä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†ç»“åˆ CLIP çš„å›¾åƒå’Œæ–‡æœ¬ç»„ä»¶çš„è¿ç§»å­¦ä¹ ç­–ç•¥å§‹ç»ˆä¼˜äºä»…ä½¿ç”¨ CLIP è§†è§‰æ–¹é¢çš„ç®€å•æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ¢æµ‹ï¼‰çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå‡¸æ˜¾äº† PromptTuning ä¼˜äºå½“å‰åŸºå‡†å’Œ SOTA æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œåœ¨å±•ç¤ºå…¶æœ‰æ•ˆæ€§çš„åŒæ—¶ï¼Œå³ä½¿è®­ç»ƒå‚æ•°æœ€å°‘ï¼Œä¹Ÿèƒ½å®ç°æ˜¾ç€çš„æ”¹è¿›å¹…åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å°‘é‡å®éªŒï¼Œåˆ†æäº†åœ¨ JPEG å‹ç¼©å’Œé«˜æ–¯æ¨¡ç³Šç­‰åå¤„ç†æ“ä½œä¸‹çš„é²æ£’æ€§ï¼Œå¹¶è¯æ˜äº†å³ä½¿è®­ç»ƒé›†è§„æ¨¡è¾ƒå°ï¼ˆ20k å›¾åƒï¼‰ï¼ŒåŸºäº CLIP çš„æ£€æµ‹å™¨ä¹Ÿå…·æœ‰ç¨³å®šçš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â€¢ æ¢ç´¢äº†é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ CLIP åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚
â€¢ æ¯”è¾ƒäº†å››ç§ä¸åŒçš„è¿ç§»å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…æ‹¬å¾®è°ƒã€çº¿æ€§æ¢æµ‹ã€PromptTuning å’Œè®­ç»ƒé€‚é…å™¨ç½‘ç»œã€‚
â€¢ è¯æ˜äº†ç»“åˆ CLIP çš„å›¾åƒå’Œæ–‡æœ¬ç»„ä»¶çš„è¿ç§»å­¦ä¹ ç­–ç•¥å§‹ç»ˆä¼˜äºä»…ä½¿ç”¨ CLIP è§†è§‰æ–¹é¢çš„ç®€å•æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ¢æµ‹ï¼‰çš„æ€§èƒ½ã€‚
â€¢ PromptTuning ä¼˜äºå½“å‰åŸºå‡†å’Œ SOTA æ–¹æ³•ï¼Œåœ¨å±•ç¤ºå…¶æœ‰æ•ˆæ€§çš„åŒæ—¶ï¼Œå³ä½¿è®­ç»ƒå‚æ•°æœ€å°‘ï¼Œä¹Ÿèƒ½å®ç°æ˜¾ç€çš„æ”¹è¿›å¹…åº¦ã€‚
â€¢ åˆ†æäº†åœ¨ JPEG å‹ç¼©å’Œé«˜æ–¯æ¨¡ç³Šç­‰åå¤„ç†æ“ä½œä¸‹çš„é²æ£’æ€§ï¼Œå¹¶è¯æ˜äº†å³ä½¿è®­ç»ƒé›†è§„æ¨¡è¾ƒå°ï¼ˆ20k å›¾åƒï¼‰ï¼ŒåŸºäº CLIP çš„æ£€æµ‹å™¨ä¹Ÿå…·æœ‰ç¨³å®šçš„æ€§èƒ½ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
â€¢ åœ¨ ProGAN æ•°æ®é›†ä¸Šï¼ŒPromptTuning åœ¨ mAP ä¸Šå®ç°äº† 95.21% çš„å‡†ç¡®ç‡å’Œ 97.82% çš„å‡†ç¡®ç‡ï¼Œä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³•ã€‚
â€¢ PromptTuning åœ¨ç»¼åˆæµ‹è¯•é›†ä¸Šä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</p>
<p>å·¥ä½œé‡ï¼š
â€¢ PromptTuning æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œæ˜“äºå®ç°ã€‚
â€¢ PromptTuning åªéœ€è¦å°‘é‡çš„æ•°æ®å’Œè®­ç»ƒæ—¶é—´ã€‚
â€¢ PromptTuning å¯ä»¥ç”¨äºæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-745a50bdee80b1df6d9da45abefcb26e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e6ec4d0ce05a2af6e93f8a2710069bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca30024b468b77b358f2f1058147b9e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f749a0d770c3a7267b5153b59c39032b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6f8430a1aafee1b2f88631389c9cdc32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-05df037ca314f896a85f2bb5c514f5dd.jpg" align="middle">
</details>




<h2 id="RealCompo-Dynamic-Equilibrium-between-Realism-and-Compositionality-Improves-Text-to-Image-Diffusion-Models"><a href="#RealCompo-Dynamic-Equilibrium-between-Realism-and-Compositionality-Improves-Text-to-Image-Diffusion-Models" class="headerlink" title="RealCompo: Dynamic Equilibrium between Realism and Compositionality   Improves Text-to-Image Diffusion Models"></a>RealCompo: Dynamic Equilibrium between Realism and Compositionality   Improves Text-to-Image Diffusion Models</h2><p><strong>Authors:Xinchen Zhang, Ling Yang, Yaqi Cai, Zhaochen Yu, Jiake Xie, Ye Tian, Minkai Xu, Yong Tang, Yujiu Yang, Bin Cui</strong></p>
<p>Diffusion models have achieved remarkable advancements in text-to-image generation. However, existing models still have many difficulties when faced with multiple-object compositional generation. In this paper, we propose a new training-free and transferred-friendly text-to-image generation framework, namely RealCompo, which aims to leverage the advantages of text-to-image and layout-to-image models to enhance both realism and compositionality of the generated images. An intuitive and novel balancer is proposed to dynamically balance the strengths of the two models in denoising process, allowing plug-and-play use of any model without extra training. Extensive experiments show that our RealCompo consistently outperforms state-of-the-art text-to-image models and layout-to-image models in multiple-object compositional generation while keeping satisfactory realism and compositionality of the generated images. Code is available at <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/RealCompo">https://github.com/YangLing0818/RealCompo</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12908v1">PDF</a> Project: <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/RealCompo">https://github.com/YangLing0818/RealCompo</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒå’Œæ˜“äºè¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ RealCompoï¼Œä»¥å¢å¼ºç”Ÿæˆå›¾åƒçš„çœŸå®æ€§å’Œç»„åˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RealCompo æ˜¯ä¸€ç§æ–°çš„æ— è®­ç»ƒå’Œæ˜“äºè¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ã€‚</li>
<li>RealCompo åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œåˆ©ç”¨å¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ç”Ÿæˆåˆç†çš„æ„å›¾ã€‚</li>
<li>RealCompo å¼•å…¥äº†æ–°çš„å¹³è¡¡å™¨ï¼Œä»¥åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹åœ¨å»å™ªè¿‡ç¨‹ä¸­çš„ä¼˜åŠ¿ã€‚</li>
<li>RealCompo å³æ’å³ç”¨ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯ä½¿ç”¨ä»»ä½•æ¨¡å‹ã€‚</li>
<li>RealCompo åœ¨å¤šå¯¹è±¡ç»„åˆç”Ÿæˆæ–¹é¢å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ã€‚</li>
<li>RealCompo ä¿æŒäº†ç”Ÿæˆå›¾åƒçš„ä»¤äººæ»¡æ„çš„çœŸå®æ€§å’Œç»„åˆæ€§ã€‚</li>
<li>RealCompo çš„ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/RealCompo">https://github.com/YangLing0818/RealCompo</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šRealCompoï¼šçœŸå®æ„Ÿä¸ç»„åˆæ€§çš„åŠ¨æ€å¹³è¡¡å¯æ”¹è¿›æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šXinchen Zhang<em>, Ling Yang</em>, Yaqi Cai, Zhaochen Yu, Jiake Xie, Ye Tian, Minkai Xu, Yong Tang, Yujiu Yang, Bin Cui</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¸ƒå±€åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€ç»„åˆæ€§ã€çœŸå®æ„Ÿ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://github.com/YangLing0818/RealCompo
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YangLing0818/RealCompo</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆæ—¶ä»é¢ä¸´è®¸å¤šå›°éš¾ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•åŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ã€‚æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä½†ç»„åˆæ€§è¾ƒå·®ï¼›å¸ƒå±€åˆ°å›¾åƒæ¨¡å‹èƒ½å¤Ÿæ§åˆ¶å¯¹è±¡çš„ä½ç½®å’Œæ•°é‡ï¼Œä½†çœŸå®æ„Ÿè¾ƒå·®ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ RealCompoï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æé«˜ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚RealCompo ä½¿ç”¨äº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒRealCompo åœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Methods:
(1) æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶RealCompoï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æé«˜ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
(2) è®¾è®¡äº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
(3) åˆ†æäº†æ¯ä¸ªæ¨¡å‹é¢„æµ‹å™ªå£°çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ç§è®¡ç®—ç³»æ•°çš„æ–¹æ³•ã€‚
(4) æä¾›äº†å¹³è¡¡å™¨æ‰€é‡‡ç”¨çš„æ›´æ–°è§„åˆ™çš„è¯¦ç»†è§£é‡Šï¼Œè¯¥è§„åˆ™åˆ©ç”¨äº†ä¸€ç§æ— è®­ç»ƒæ–¹æ³•æ¥åŠ¨æ€æ›´æ–°ç³»æ•°ã€‚
(5) æ‰©å±•äº†RealCompoçš„åº”ç”¨ï¼Œä¸ºL2Iæ¨¡å‹çš„æ¯ä¸€ç±»è®¾è®¡äº†æŸå¤±å‡½æ•°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶RealCompoï¼Œè¯¥æ¡†æ¶åœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
åˆ†æäº†æ¯ä¸ªæ¨¡å‹é¢„æµ‹å™ªå£°çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ç§è®¡ç®—ç³»æ•°çš„æ–¹æ³•ã€‚
æä¾›äº†å¹³è¡¡å™¨æ‰€é‡‡ç”¨çš„æ›´æ–°è§„åˆ™çš„è¯¦ç»†è§£é‡Šï¼Œè¯¥è§„åˆ™åˆ©ç”¨äº†ä¸€ç§æ— è®­ç»ƒæ–¹æ³•æ¥åŠ¨æ€æ›´æ–°ç³»æ•°ã€‚
æ‰©å±•äº†RealCompoçš„åº”ç”¨ï¼Œä¸ºL2Iæ¨¡å‹çš„æ¯ä¸€ç±»è®¾è®¡äº†æŸå¤±å‡½æ•°ã€‚
æ€§èƒ½ï¼š
RealCompoåœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
RealCompoå¯ä»¥è¢«æ¨å¹¿åˆ°ä»»ä½•LLMã€T2Iå’ŒL2Iæ¨¡å‹ï¼Œå¹¶ä¿æŒå¼ºå¤§çš„ç”Ÿæˆç»“æœã€‚
å·¥ä½œé‡ï¼š
RealCompoçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚
RealCompoå¯ä»¥è½»æ¾åœ°é›†æˆåˆ°ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿä¸­ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-264ae173bcca3292815b8e45db353de6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9c5f244037ff17e98afe9f2c1851e4f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-caea4b22ae09f52bc515627d4e3cba84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5fcdadd1b307e5df492d508f86958e6.jpg" align="middle">
</details>




<h2 id="Two-stage-Rainfall-Forecasting-Diffusion-Model"><a href="#Two-stage-Rainfall-Forecasting-Diffusion-Model" class="headerlink" title="Two-stage Rainfall-Forecasting Diffusion Model"></a>Two-stage Rainfall-Forecasting Diffusion Model</h2><p><strong>Authors:XuDong Ling, ChaoRong Li, FengQing Qin, LiHong Zhu, Yuanyuan Huang</strong></p>
<p>Deep neural networks have made great achievements in rainfall prediction.However, the current forecasting methods have certain limitations, such as with blurry generated images and incorrect spatial positions. To overcome these challenges, we propose a Two-stage Rainfall-Forecasting Diffusion Model (TRDM) aimed at improving the accuracy of long-term rainfall forecasts and addressing the imbalance in performance between temporal and spatial modeling. TRDM is a two-stage method for rainfall prediction tasks. The task of the first stage is to capture robust temporal information while preserving spatial information under low-resolution conditions. The task of the second stage is to reconstruct the low-resolution images generated in the first stage into high-resolution images. We demonstrate state-of-the-art results on the MRMS and Swedish radar datasets. Our project is open source and available on GitHub at: \href{<a target="_blank" rel="noopener" href="https://github.com/clearlyzerolxd/TRDM%7D%7Bhttps://github.com/clearlyzerolxd/TRDM%7D">https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12779v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>TRDMæ˜¯ä¸€ç§ç”¨äºé™é›¨é¢„æµ‹ä»»åŠ¡çš„ä¸¤é˜¶æ®µæ–¹æ³•ã€‚</li>
<li>TRDMçš„ç¬¬ä¸€é˜¶æ®µä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·ç¨³å¥çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚</li>
<li>TRDMçš„ç¬¬äºŒé˜¶æ®µä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>TRDMåœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>TRDMå¼€æºï¼Œå¯åœ¨ GitHub ä¸Šè·å–ï¼š\href{<a target="_blank" rel="noopener" href="https://github.com/clearlyzerolxd/TRDM%7D%7Bhttps://github.com/clearlyzerolxd/TRDM%7D%E3%80%82">https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}ã€‚</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šXu DongLing, Chao RongLi*, FengQing Qin, LiHong Zhu, Yuanyuan Huang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé‡åº†ç†å·¥å¤§å­¦äººå·¥æ™ºèƒ½ä¸å¤§æ•°æ®å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€é™é›¨é¢„æµ‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12779ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/clearlyzerolxd/TRDM</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåœ¨é™é›¨é¢„æµ‹é¢†åŸŸå–å¾—äº†å¾ˆå¤§çš„æˆå°±ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é¢„æµ‹æ–¹æ³•å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œä¾‹å¦‚ç”Ÿæˆçš„å›¾åƒæ¨¡ç³Šã€ç©ºé—´ä½ç½®ä¸å‡†ç¡®ç­‰ã€‚
ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œå·²æœ‰ç ”ç©¶æå‡ºäº†å·ç§¯LSTMå’Œå·ç§¯GRUæ¨¡å‹æ¥æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨é•¿æœŸçš„é¢„æµ‹ä¸­å­˜åœ¨å‡†ç¡®æ€§ä¸é«˜çš„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒSmaAt-UNetæ¨¡å‹è™½ç„¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰è¾“å…¥åºåˆ—ä¸­çš„å…³é”®ç©ºé—´ä¿¡æ¯ï¼Œä½†åœ¨é•¿æœŸé¢„æµ‹æ€§èƒ½æ–¹é¢ä»æœ‰å¾…æé«˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰ã€‚TRDMæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„é™é›¨é¢„æµ‹æ–¹æ³•ã€‚ç¬¬ä¸€é˜¶æ®µçš„ä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·é²æ£’çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚ç¬¬äºŒé˜¶æ®µçš„ä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šï¼ŒTRDMå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼šåˆ©ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œç”Ÿæˆ 16 å¸§ 32Ã—32 ä½åˆ†è¾¨ç‡é™é›¨ç»“æœï¼ŒåŒæ—¶ä¿ç•™ä¸€å®šç¨‹åº¦çš„ç©ºé—´ä¿¡æ¯ï¼Œä¸ºåç»­é‡å»ºé˜¶æ®µæä¾›é²æ£’çš„åŸºç¡€ã€‚
(2) ç©ºé—´è¶…åˆ†è¾¨ç‡ï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹æ„å»ºè¶…åˆ†è¾¨ç‡ç½‘ç»œï¼Œå°†ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¢å¼ºå›¾åƒè´¨é‡å’Œç»†èŠ‚ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°åˆ†ææœªæ¥é™é›¨çš„å¼ºåº¦å’Œåˆ†å¸ƒã€‚
(3) æ½œåœ¨è¶…åˆ†è¾¨ç‡ï¼šæå‡ºä¸€ç§æ½œåœ¨è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œå°†é«˜åˆ†è¾¨ç‡å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´ï¼Œç„¶ååˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ¡ä»¶ï¼ŒæŒ‡å¯¼ç”Ÿæˆæ¡ä»¶ã€‚
(4) æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ L1 æŸå¤±å‡½æ•°è®­ç»ƒé¢„æµ‹æ‰©æ•£æ¨¡å‹å’Œè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œä»¥æœ€å°åŒ–é¢„æµ‹è¯¯å·®ã€‚
(5) æ¨¡å‹æ¨ç†ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå°†ä½åˆ†è¾¨ç‡å›¾åƒè¾“å…¥åˆ°è¶…åˆ†è¾¨ç‡æ¨¡å‹ä¸­ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ¡ä»¶ï¼Œé€æ­¥æ¢å¤é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰è¾“å…¥åºåˆ—ä¸­çš„å…³é”®ç©ºé—´ä¿¡æ¯ï¼Œå¹¶åœ¨é•¿æœŸé¢„æµ‹æ€§èƒ½æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
TRDMæ¨¡å‹é‡‡ç”¨äº†ä¸¤é˜¶æ®µçš„é¢„æµ‹ç­–ç•¥ï¼Œç¬¬ä¸€é˜¶æ®µçš„ä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·é²æ£’çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚ç¬¬äºŒé˜¶æ®µçš„ä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¿™ç§ä¸¤é˜¶æ®µçš„ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚
æ€§èƒ½ï¼š
åœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šï¼ŒTRDMæ¨¡å‹å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒTRDMæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´åŠ æ¸…æ™°å’Œå‡†ç¡®çš„é™é›¨é¢„æµ‹å›¾åƒã€‚
å·¥ä½œé‡ï¼š
TRDMæ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹ç®€å•ã€‚è¯¥æ¨¡å‹åªéœ€è¦å°‘é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´è¾ƒçŸ­ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒTRDMæ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿåœ°ç”Ÿæˆé™é›¨é¢„æµ‹å›¾åƒã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-77f75079fa9cf15e6ab90ae9bfdf3659.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e40db6d053eb3ccf707a2dbcd4cf2e8d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1f5823da8ecb8e38058c288533b8775e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf44de1da53f2ab1acf3c0d8075ec068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b36e8a07f0692df0799659af074a0a49.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-56d34d3e7c52a330e5782ff67a0df331.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4bfaafb452921e1d0c1a1d6c62510229.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fa91d38aada7882b2ac95950348567d.jpg" align="middle">
</details>




<h2 id="MuLan-Multimodal-LLM-Agent-for-Progressive-Multi-Object-Diffusion"><a href="#MuLan-Multimodal-LLM-Agent-for-Progressive-Multi-Object-Diffusion" class="headerlink" title="MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion"></a>MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion</h2><p><strong>Authors:Sen Li, Ruochen Wang, Cho-Jui Hsieh, Minhao Cheng, Tianyi Zhou</strong></p>
<p>Existing text-to-image models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings. In this paper, we develop a training-free Multimodal-LLM agent (MuLan) to address these challenges by progressive multi-object generation with planning and feedback control, like a human painter. MuLan harnesses a large language model (LLM) to decompose a prompt to a sequence of sub-tasks, each generating only one object conditioned on previously generated objects by stable diffusion. Unlike existing LLM-grounded methods, MuLan only produces a high-level plan at the beginning while the exact size and location of each object are determined by an LLM and attention guidance upon each sub-task. Moreover, MuLan adopts a vision-language model (VLM) to provide feedback to the image generated in each sub-task and control the diffusion model to re-generate the image if it violates the original prompt. Hence, each model in every step of MuLan only needs to address an easy sub-task it is specialized for. We collect 200 prompts containing multi-objects with spatial relationships and attribute bindings from different benchmarks to evaluate MuLan. The results demonstrate the superiority of MuLan in generating multiple objects over baselines. The code is available on <a target="_blank" rel="noopener" href="https://github.com/measure-infinity/mulan-code">https://github.com/measure-infinity/mulan-code</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12741v1">PDF</a> Project website: <a target="_blank" rel="noopener" href="https://measure-infinity.github.io/mulan">https://measure-infinity.github.io/mulan</a></p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åŠ©åŠ›æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šå¯¹è±¡å›¾åƒï¼Œåˆ†æ­¥è§„åˆ’ï¼Œåé¦ˆæ§åˆ¶ï¼Œè½»æ¾æ»¡è¶³å¤æ‚è¦æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰çš„æ–‡æœ¬è½¬å›¾åƒæ¨¡å‹åœ¨ç”Ÿæˆå¤šå¯¹è±¡å›¾åƒæ—¶ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯¹è±¡çš„ç©ºé—´ä½ç½®ã€ç›¸å¯¹å¤§å°ã€é‡å å’Œå±æ€§ç»‘å®šæ–¹é¢ã€‚</li>
<li>MuLan é‡‡ç”¨æ— è®­ç»ƒçš„è®­ç»ƒæ–¹å¼ï¼Œé€šè¿‡è§„åˆ’å’Œåé¦ˆæ§åˆ¶é€æ­¥ç”Ÿæˆå¤šå¯¹è±¡ï¼Œç±»ä¼¼äºäººç±»ç”»å®¶ä½œç”»ã€‚</li>
<li>MuLan åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å°†æç¤ºåˆ†è§£ä¸ºä¸€ç³»åˆ—å­ä»»åŠ¡ï¼Œæ¯ä¸ªå­ä»»åŠ¡ä»…ç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶é€šè¿‡ç¨³å®šæ‰©æ•£æ¨¡å‹å¯¹å…ˆå‰ç”Ÿæˆçš„å¯¹è±¡è¿›è¡Œæ¡ä»¶æ§åˆ¶ã€‚</li>
<li>ä¸ç°æœ‰çš„ LLM æ–¹æ³•ä¸åŒï¼ŒMuLan åªåœ¨å¼€å§‹æ—¶ç”Ÿæˆä¸€ä¸ªé«˜å±‚æ¬¡çš„è§„åˆ’ï¼Œè€Œæ¯ä¸ªå¯¹è±¡çš„ç¡®åˆ‡å¤§å°å’Œä½ç½®ç”± LLM å’Œæ³¨æ„åŠ›å¼•å¯¼åœ¨æ¯ä¸ªå­ä»»åŠ¡ä¸­ç¡®å®šã€‚</li>
<li>MuLan é‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) ä¸ºæ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒæä¾›åé¦ˆï¼Œå¹¶åœ¨å›¾åƒè¿ååŸå§‹æç¤ºæ—¶æ§åˆ¶æ‰©æ•£æ¨¡å‹é‡æ–°ç”Ÿæˆå›¾åƒã€‚</li>
<li>MuLan åœ¨æ¯ä¸ªæ­¥éª¤ä¸­åªå¤„ç†è‡ªå·±ä¸“é—¨å¤„ç†çš„ç®€å•å­ä»»åŠ¡ã€‚</li>
<li>MuLan åœ¨ä¸åŒåŸºå‡†ä¸Šæ”¶é›†äº† 200 ä¸ªåŒ…å«ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šçš„å¤šå¯¹è±¡æç¤ºæ¥è¯„ä¼° MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLan åœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šMuLanï¼šç”¨äºæ¸è¿›å¼å¤šå¯¹è±¡æ‰©æ•£çš„å¤šæ¨¡æ€-LLM ä»£ç†</li>
<li>ä½œè€…ï¼šSen Liã€Ruochen Wangã€Cho-Jui Hsiehã€Minhao Chengã€Tianyi Zhou</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€å¤šå¯¹è±¡ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹ã€è§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12741
Github é“¾æ¥ï¼šhttps://github.com/measure-infinity/mulan-code</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨ç”ŸæˆåŒ…å«å¤šä¸ªå¯¹è±¡çš„å›¾åƒæ—¶ä»ç„¶å­˜åœ¨å›°éš¾ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯¹è±¡çš„ç©ºé—´ä½ç½®ã€ç›¸å¯¹å¤§å°ã€é‡å å’Œå±æ€§ç»‘å®šæ–¹é¢ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›æ–¹æ³•è¯•å›¾åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä½†ç”±äº LLM çš„ç©ºé—´æ¨ç†èƒ½åŠ›æœ‰é™ä»¥åŠå®ƒä»¬ä¸æ‰©æ•£æ¨¡å‹ç¼ºä¹ä¸€è‡´æ€§ï¼Œå› æ­¤ç›´æ¥ç”Ÿæˆå®Œæ•´ä¸”ç²¾ç¡®çš„å¤šå¯¹è±¡å¸ƒå±€ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å°†å¸ƒå±€ä½œä¸ºå¯¹æ¯ä¸ªæ¨¡å‹çš„é¢å¤–æ¡ä»¶ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ‰©æ•£æ¨¡å‹ç”±äºå¯¹å¤æ‚æç¤ºçš„è¯¯è§£è€Œç”Ÿæˆä¸æ­£ç¡®å›¾åƒã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚è¯¥èŒƒå¼å»ºç«‹åœ¨ç”±å¤šæ¨¡æ€-LLM ä»£ç† (MuLan) è¿›è¡Œçš„æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆä¹‹ä¸Šï¼ŒMuLan æ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æ­¤å¤–ï¼ŒMuLan é‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) æ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚
(4) å®éªŒç»“æœä¸æ€§èƒ½ï¼šåœ¨åŒ…å«æ¥è‡ªä¸åŒåŸºå‡†çš„å¤šå¯¹è±¡ï¼ˆå…·æœ‰ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šï¼‰çš„ 200 ä¸ªæç¤ºä¸Šè¯„ä¼° MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLan åœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šè¯¥èŒƒå¼å»ºç«‹åœ¨ç”±å¤šæ¨¡æ€-LLMä»£ç†ï¼ˆMuLanï¼‰è¿›è¡Œçš„æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆä¹‹ä¸Šï¼ŒMuLanæ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰ï¼šé‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼MuLanï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ï¼Œåœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
MuLanï¼šä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚
æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆï¼šMuLanæ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚
è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼šé‡‡ç”¨VLMæ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚
æ€§èƒ½ï¼š
åœ¨åŒ…å«æ¥è‡ªä¸åŒåŸºå‡†çš„å¤šå¯¹è±¡ï¼ˆå…·æœ‰ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šï¼‰çš„200ä¸ªæç¤ºä¸Šè¯„ä¼°MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLanåœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
MuLançš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–æ•°æ®ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6204318646d6f8f073e72dd012036b52.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-339c08e21eaf72db7bf6af40d44b1ebd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c764cf1c9de7293c1a1c79a15a87313.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f2c4d6c6e5f00fd67d4a729192f3826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85b2bad757801f5c51069e7f6c02cbc7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9001380fef222e92159ed423b319dc8a.jpg" align="middle">
</details>




<h2 id="Improving-Deep-Generative-Models-on-Many-To-One-Image-to-Image-Translation"><a href="#Improving-Deep-Generative-Models-on-Many-To-One-Image-to-Image-Translation" class="headerlink" title="Improving Deep Generative Models on Many-To-One Image-to-Image   Translation"></a>Improving Deep Generative Models on Many-To-One Image-to-Image   Translation</h2><p><strong>Authors:Sagar Saxena, Mohammad Nayeem Teli</strong></p>
<p>Deep generative models have been applied to multiple applications in image-to-image translation. Generative Adversarial Networks and Diffusion Models have presented impressive results, setting new state-of-the-art results on these tasks. Most methods have symmetric setups across the different domains in a dataset. These methods assume that all domains have either multiple modalities or only one modality. However, there are many datasets that have a many-to-one relationship between two domains. In this work, we first introduce a Colorized MNIST dataset and a Color-Recall score that can provide a simple benchmark for evaluating models on many-to-one translation. We then introduce a new asymmetric framework to improve existing deep generative models on many-to-one image-to-image translation. We apply this framework to StarGAN V2 and show that in both unsupervised and semi-supervised settings, the performance of this new model improves on many-to-one image-to-image translation. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12531v1">PDF</a> 11 pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>ç”¨æ·±åº¦æ‰©æ•£æ¨¡å‹æ”¹è¿›å¤šå¯¹ä¸€çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ·±åº¦æ‰©æ•£æ¨¡å‹æ˜¯ç”¨äºå›¾åƒåˆ°å›¾åƒç¿»è¯‘çš„ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>ç°æœ‰çš„æ–¹æ³•é€šå¸¸å‡è®¾æ‰€æœ‰é¢†åŸŸéƒ½å…·æœ‰å¤šä¸ªæ¨¡æ€æˆ–åªæœ‰ä¸€ä¸ªæ¨¡æ€ã€‚</li>
<li>åœ¨è®¸å¤šåœºæ™¯ä¸‹ï¼Œä¸¤ä¸ªé¢†åŸŸä¹‹é—´å­˜åœ¨å¤šå¯¹ä¸€çš„å…³ç³»ã€‚</li>
<li>ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªç€è‰² MNIST æ•°æ®é›†å’Œä¸€ä¸ªå½©è‰²å¬å›åˆ†æ•°ï¼Œä¸ºå¤šå¯¹ä¸€ç¿»è¯‘æä¾›äº†ä¸€ä¸ªç®€å•çš„åŸºå‡†ã€‚</li>
<li>æå‡ºä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚</li>
<li>å°†è¯¥æ¡†æ¶åº”ç”¨äº StarGAN V2ï¼Œå®éªŒè¡¨æ˜ï¼Œåœ¨æ–°æ¨¡å‹ä¸­ï¼Œæ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸‹çš„å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ€§èƒ½å‡å¾—åˆ°æé«˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ”¹è¿›å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹</li>
<li>ä½œè€…ï¼šSagar Saxena, Mohammad Nayeem Teli</li>
<li>éš¶å±å…³ç³»ï¼šé©¬é‡Œå…°å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šæ·±åº¦ç”Ÿæˆæ¨¡å‹ã€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€å¤šå¯¹ä¸€ç¿»è¯‘ã€éå¯¹ç§°æ¡†æ¶</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12531</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç”Ÿæˆæ¨¡å‹å·²å¹¿æ³›åº”ç”¨äºå›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­ï¼Œå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•åœ¨ä¸åŒé¢†åŸŸä¹‹é—´é‡‡ç”¨å¯¹ç§°è®¾ç½®ï¼Œå‡è®¾æ‰€æœ‰é¢†åŸŸéƒ½å…·æœ‰å¤šæ¨¡æ€æˆ–å•ä¸€æ¨¡æ€ã€‚ç„¶è€Œï¼Œè®¸å¤šæ•°æ®é›†åœ¨ä¸¤ä¸ªé¢†åŸŸä¹‹é—´å…·æœ‰å¤šå¯¹ä¸€çš„å…³ç³»ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•è¦ä¹ˆå­¦ä¹ åŒå°„æ˜ å°„ï¼Œè¦ä¹ˆå­¦ä¹ å¤šå¯¹å¤šæ˜ å°„ï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å‡†ç¡®å»ºæ¨¡æŸäº›ä»»åŠ¡ä¸­é¢†åŸŸä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚å›¾åƒç€è‰²ã€è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡ç­‰ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶å°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ¨¡å—è§£è€¦ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±ç”Ÿæˆå™¨ç”Ÿæˆä¸è¾“å…¥å›¾åƒç›¸ä¼¼çš„è¾“å‡ºå›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡å°†è¯¥æ¡†æ¶åº”ç”¨äº StarGAN V2 æ¨¡å‹ï¼Œå¹¶åœ¨æ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶ï¼Œå°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ¨¡å—è§£è€¦ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±ç”Ÿæˆå™¨ç”Ÿæˆä¸è¾“å…¥å›¾åƒç›¸ä¼¼çš„è¾“å‡ºå›¾åƒã€‚</li>
<li>å°†è¯¥æ¡†æ¶åº”ç”¨äºStarGANV2æ¨¡å‹ï¼Œå¹¶åœ¨æ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æ— ç›‘ç£è®¾ç½®ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨CelebAæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„FIDå’ŒLPIPSå¾—åˆ†ã€‚</li>
<li>åœ¨åŠç›‘ç£è®¾ç½®ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨CelebAæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„FIDå’ŒLPIPSå¾—åˆ†ã€‚</li>
<li>åœ¨Cityscapesæ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶å–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„mIoUå’ŒF1å¾—åˆ†ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ¡†æ¶çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥åœ¨TensorFlowæˆ–PyTorchç­‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­è½»æ¾å®ç°ã€‚</li>
<li>è¯¥æ¡†æ¶çš„è®­ç»ƒæ—¶é—´ä¸StarGANV2æ¨¡å‹ç›¸ä¼¼ã€‚</li>
<li>è¯¥æ¡†æ¶çš„æ¨ç†æ—¶é—´ä¸StarGANV2æ¨¡å‹ç›¸ä¼¼ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-847aa6560da9e8f5bc3efa20a3a60ab6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b87108e9e8879c6d14d1fe6eaf34112.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e7677caf8041932830de453431d2abd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50784d0e85e2b28f9cc755ede524a772.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9b40dd37bb889c7e90ab259793c5ab5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df01b0bd8844297db8557dc012591bb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af0a71391ad75be3ea34e547daa4db1e.jpg" align="middle">
</details>




<h2 id="FiT-Flexible-Vision-Transformer-for-Diffusion-Model"><a href="#FiT-Flexible-Vision-Transformer-for-Diffusion-Model" class="headerlink" title="FiT: Flexible Vision Transformer for Diffusion Model"></a>FiT: Flexible Vision Transformer for Diffusion Model</h2><p><strong>Authors:Zeyu Lu, Zidong Wang, Di Huang, Chengyue Wu, Xihui Liu, Wanli Ouyang, Lei Bai</strong></p>
<p>Nature is infinitely resolution-free. In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios. Unlike traditional methods that perceive images as static-resolution grids, FiT conceptualizes images as sequences of dynamically-sized tokens. This perspective enables a flexible training strategy that effortlessly adapts to diverse aspect ratios during both training and inference phases, thus promoting resolution generalization and eliminating biases induced by image cropping. Enhanced by a meticulously adjusted network structure and the integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility in resolution extrapolation generation. Comprehensive experiments demonstrate the exceptional performance of FiT across a broad range of resolutions, showcasing its effectiveness both within and beyond its training resolution distribution. Repository available at <a target="_blank" rel="noopener" href="https://github.com/whlzy/FiT">https://github.com/whlzy/FiT</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12376v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡å°†å›¾åƒè§†ä¸ºåŠ¨æ€å¤§å°æ ‡è®°åºåˆ—ï¼Œå¼¹æ€§è§†è§‰å˜æ¢å™¨å¯åœ¨ä¸åŒåˆ†è¾¨ç‡å’Œå®½é«˜æ¯”ä¸Šç”Ÿæˆå›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†è®­ç»ƒåŸŸä¹‹å¤–çš„å›¾åƒåˆ†è¾¨ç‡æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å¼¹æ€§è§†è§‰å˜æ¢å™¨ (FiT) æ˜¯ä¸€ç§ä¸“ä¸ºç”Ÿæˆä¸å—é™åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”çš„å›¾åƒè€Œè®¾è®¡çš„è½¬æ¢å™¨æ¶æ„ã€‚</li>
<li>FiT å°†å›¾åƒè§†ä¸ºåŠ¨æ€å¤§å°æ ‡è®°åºåˆ—ï¼Œä»è€Œæ”¯æŒä¸åŒçš„å®½é«˜æ¯”ã€‚</li>
<li>FiT åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µå‡æ”¯æŒä¸åŒçš„å®½é«˜æ¯”ï¼Œä»è€Œæ¶ˆé™¤äº†å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</li>
<li>FiT åœ¨å¤šç§åˆ†è¾¨ç‡ä¸‹è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒä¹‹å¤–ä¹Ÿå¾ˆæœ‰æ•ˆã€‚</li>
<li>FiT çš„å­˜å‚¨åº“ä½äº <a target="_blank" rel="noopener" href="https://github.com/whlzy/FiT%E3%80%82">https://github.com/whlzy/FiTã€‚</a></li>
<li>FiT ä¸ºå›¾åƒç”Ÿæˆé¢†åŸŸå¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFiTï¼šç”¨äºæ‰©æ•£æ¨¡å‹çš„çµæ´»è§†è§‰å˜æ¢å™¨</li>
<li>ä½œè€…ï¼šZeyu Lu<em>ï¼ŒZidong Wang</em>ï¼ŒDi Huangï¼ŒChengyue Wuï¼ŒXihui Liuï¼ŒWanli Ouyangï¼ŒLei Bai</li>
<li>å•ä½ï¼šä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ï¼Œè§†è§‰å˜æ¢å™¨ï¼Œåˆ†è¾¨ç‡æ³›åŒ–ï¼Œå¤–æ¨æŠ€æœ¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12376ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªç„¶ç•Œçš„å›¾åƒåˆ†è¾¨ç‡æ˜¯æ— é™çš„ã€‚ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚æ‰©æ•£å˜æ¢å™¨ï¼‰åœ¨å¤„ç†è¶…å‡ºå…¶è®­ç»ƒåŸŸçš„å›¾åƒåˆ†è¾¨ç‡æ—¶å¾€å¾€é¢ä¸´æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¼ ç»Ÿæ–¹æ³•å°†å›¾åƒè§†ä¸ºé™æ€åˆ†è¾¨ç‡ç½‘æ ¼ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¤„ç†ä¸åŒåˆ†è¾¨ç‡å›¾åƒçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå›¾åƒè£å‰ªä¼šå¼•å…¥åå·®ï¼Œå½±å“æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†çµæ´»è§†è§‰å˜æ¢å™¨ï¼ˆFiTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºç”Ÿæˆå…·æœ‰æ— é™åˆ†è¾¨ç‡å’Œçºµæ¨ªæ¯”çš„å›¾åƒè€Œè®¾è®¡çš„å˜æ¢å™¨æ¶æ„ã€‚FiT å°†å›¾åƒæ¦‚å¿µåŒ–ä¸ºåŠ¨æ€å¤§å°æ ‡è®°çš„åºåˆ—ï¼Œè¿™ä½¿å¾—å®ƒèƒ½å¤Ÿåœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µè½»æ¾é€‚åº”ä¸åŒçš„çºµæ¨ªæ¯”ï¼Œä»è€Œä¿ƒè¿›äº†åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤äº†å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚é€šè¿‡ç²¾å¿ƒè°ƒæ•´çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒè‡ªç”±å¤–æ¨æŠ€æœ¯çš„é›†æˆï¼ŒFiT åœ¨åˆ†è¾¨ç‡å¤–æ¨ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„çµæ´»æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šç»¼åˆå®éªŒè¡¨æ˜ï¼ŒFiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰çµæ´»è®­ç»ƒï¼šæå‡ºäº†ä¸€ç§çµæ´»çš„è®­ç»ƒæ–¹æ³•ï¼Œå…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†ä¸åŒçºµæ¨ªæ¯”çš„å›¾åƒï¼Œä»è€Œä¿ƒè¿›åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</p>
<p>ï¼ˆ2ï¼‰SwiGLUæ¿€æ´»å‡½æ•°ï¼šå°†MLPæ¿€æ´»å‡½æ•°æ›¿æ¢ä¸ºSwiGLUæ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p>ï¼ˆ3ï¼‰2DRoPEä½ç½®ç¼–ç ï¼šå°†ç»å¯¹ä½ç½®ç¼–ç æ›¿æ¢ä¸º2DRoPEä½ç½®ç¼–ç ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå¤–æ¨èƒ½åŠ›ã€‚</p>
<p>ï¼ˆ4ï¼‰ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼Œå¯ä»¥å°†æ¨¡å‹çš„å¤–æ¨èƒ½åŠ›æ‰©å±•åˆ°è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„åˆ†è¾¨ç‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œçš„ä¸»è¦è´¡çŒ®åœ¨äºï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºæ‰©æ•£æ¨¡å‹çš„çµæ´»è§†è§‰å˜æ¢å™¨ï¼ˆFiTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºç”Ÿæˆå…·æœ‰æ— é™åˆ†è¾¨ç‡å’Œçºµæ¨ªæ¯”çš„å›¾åƒè€Œè®¾è®¡çš„å˜æ¢å™¨æ¶æ„ã€‚FiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§çµæ´»çš„è®­ç»ƒæ–¹æ³•ï¼Œå…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†ä¸åŒçºµæ¨ªæ¯”çš„å›¾åƒï¼Œä»è€Œä¿ƒè¿›åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</li>
<li>å°† MLP æ¿€æ´»å‡½æ•°æ›¿æ¢ä¸º SwiGLU æ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>å°†ç»å¯¹ä½ç½®ç¼–ç æ›¿æ¢ä¸º 2DRoPE ä½ç½®ç¼–ç ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå¤–æ¨èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼Œå¯ä»¥å°†æ¨¡å‹çš„å¤–æ¨èƒ½åŠ›æ‰©å±•åˆ°è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„åˆ†è¾¨ç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>FiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>FiT åœ¨å„ç§åˆ†è¾¨ç‡ä¸‹å‡ä¼˜äºæ‰€æœ‰å…ˆå‰æ¨¡å‹ï¼Œæ— è®ºæ˜¯åŸºäº Transformer çš„è¿˜æ˜¯åŸºäº CNN çš„ã€‚</li>
<li>ç»“åˆæˆ‘ä»¬çš„åˆ†è¾¨ç‡å¤–æ¨æ–¹æ³• VisionNTKï¼ŒFiT çš„æ€§èƒ½å¾—åˆ°äº†è¿›ä¸€æ­¥æ˜¾ç€æå‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°æ¨¡å‹æ¶æ„è®¾è®¡ã€è®­ç»ƒæ–¹æ³•æ”¹è¿›ã€å¤–æ¨æŠ€æœ¯é›†æˆç­‰å¤šä¸ªæ–¹é¢ã€‚</li>
<li>æœ¬æ–‡çš„å®éªŒéƒ¨åˆ†ä¹Ÿæ¯”è¾ƒå¤æ‚ï¼Œæ¶‰åŠåˆ°å¤šä¸ªæ•°æ®é›†ã€å¤šä¸ªåˆ†è¾¨ç‡ã€å¤šä¸ªè¯„ä»·æŒ‡æ ‡ç­‰ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f2dad57fd66943bffc8c0eefec68b3e8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-297eceedf1e98b27794f86f0cb8285ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6760b58ea1f0ee4f73bf15eae4ddb673.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09693fd0b9790328fcc71c49c26da3ad.jpg" align="middle">
</details>




<h2 id="Direct-Consistency-Optimization-for-Compositional-Text-to-Image-Personalization"><a href="#Direct-Consistency-Optimization-for-Compositional-Text-to-Image-Personalization" class="headerlink" title="Direct Consistency Optimization for Compositional Text-to-Image   Personalization"></a>Direct Consistency Optimization for Compositional Text-to-Image   Personalization</h2><p><strong>Authors:Kyungmin Lee, Sangkyung Kwak, Kihyuk Sohn, Jinwoo Shin</strong></p>
<p>Text-to-image (T2I) diffusion models, when fine-tuned on a few personal images, are able to generate visuals with a high degree of consistency. However, they still lack in synthesizing images of different scenarios or styles that are possible in the original pretrained models. To address this, we propose to fine-tune the T2I model by maximizing consistency to reference images, while penalizing the deviation from the pretrained model. We devise a novel training objective for T2I diffusion models that minimally fine-tunes the pretrained model to achieve consistency. Our method, dubbed \emph{Direct Consistency Optimization}, is as simple as regular diffusion loss, while significantly enhancing the compositionality of personalized T2I models. Also, our approach induces a new sampling method that controls the tradeoff between image fidelity and prompt fidelity. Lastly, we emphasize the necessity of using a comprehensive caption for reference images to further enhance the image-text alignment. We show the efficacy of the proposed method on the T2I personalization for subject, style, or both. In particular, our method results in a superior Pareto frontier to the baselines. Generated examples and codes are in our project page( <a target="_blank" rel="noopener" href="https://dco-t2i.github.io/">https://dco-t2i.github.io/</a>). </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.12004v1">PDF</a> Preprint. See our project page (<a target="_blank" rel="noopener" href="https://dco-t2i.github.io/">https://dco-t2i.github.io/</a>) for more   examples and codes</p>
<p><strong>Summary</strong><br>åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒçš„æ‰©æ•£æ¨¡å‹å¯é€šè¿‡å¾®è°ƒå°‘æ•°ä¸ªäººå›¾åƒç”Ÿæˆé«˜åº¦ä¸€è‡´çš„è§†è§‰æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¾®è°ƒåŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒçš„æ‰©æ•£æ¨¡å‹æ—¶ï¼Œæœ€å¤§åŒ–ä¸å‚è€ƒå›¾åƒçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶æƒ©ç½šä¸é¢„è®­ç»ƒæ¨¡å‹çš„åå·®ã€‚</li>
<li>æå‡ºä¸€ç§æœ€å°åŒ–å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§çš„æ–°é¢–è®­ç»ƒç›®æ ‡ã€‚</li>
<li>è¯¥æ–¹æ³•ç®€å•ä¸”æœ‰æ•ˆï¼Œæ˜¾ç€å¢å¼ºäº†ä¸ªæ€§åŒ–åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹çš„ç»„åˆæ€§ã€‚</li>
<li>å¼•å…¥ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>å¼ºè°ƒä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„ä¸€è‡´æ€§ã€‚</li>
<li>è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…æ–¹é¢çš„åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒä¸ªæ€§åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç›´æ¥ä¸€è‡´æ€§ä¼˜åŒ–ç”¨äºåˆæˆæ–‡æœ¬åˆ°å›¾åƒä¸ªæ€§åŒ–</li>
<li>ä½œè€…ï¼šSeunghoon Hong, Inwoong Ko, Sunghyun Cho, Seonghyeon Nam, Dong Huk Park</li>
<li>éš¶å±æœºæ„ï¼šé¦–å°”å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒåˆæˆã€ä¸ªæ€§åŒ–ã€æ‰©æ•£æ¨¡å‹ã€ä¸€è‡´æ€§ä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹åœ¨ç»è¿‡å°‘é‡ä¸ªäººå›¾åƒçš„å¾®è°ƒåï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰é«˜åº¦ä¸€è‡´æ€§çš„è§†è§‰æ•ˆæœã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶ç¼ºä¹åœ¨åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ä¸­å¯èƒ½çš„ä¸åŒåœºæ™¯æˆ–é£æ ¼çš„å›¾åƒåˆæˆèƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æœ€å¤§åŒ–ä¸å‚è€ƒå›¾åƒçš„ä¸€è‡´æ€§æ¥å¾®è°ƒ T2I æ¨¡å‹çš„æ–¹æ³•ï¼ŒåŒæ—¶æƒ©ç½šä¸é¢„è®­ç»ƒæ¨¡å‹çš„åå·®ã€‚è¿‡å»çš„æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼Œå®ƒä»¬åœ¨ä¸ªæ€§åŒ– T2I æ¨¡å‹ä¸­ä»ç„¶ç¼ºä¹åˆæˆä¸åŒåœºæ™¯æˆ–é£æ ¼çš„å›¾åƒçš„èƒ½åŠ›ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ T2I æ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•ç§°ä¸ºç›´æ¥ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œå®ƒä¸å¸¸è§„æ‰©æ•£æŸå¤±ä¸€æ ·ç®€å•ï¼ŒåŒæ—¶æ˜¾ç€æé«˜äº†ä¸ªæ€§åŒ– T2I æ¨¡å‹çš„ç»„åˆæ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚æœ€åï¼Œæœ¬æ–‡å¼ºè°ƒäº†ä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒçš„å¿…è¦æ€§ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„å¯¹é½ã€‚
(4)ï¼šå®éªŒç»“æœï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹çš„ T2I ä¸ªæ€§åŒ–æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¸•ç´¯æ‰˜å‰æ²¿æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p>Methods:
(1) Direct Consistency Optimization (DCO): We formulate T2I diffusion model fine-tuning as a constrained policy optimization problem and propose DCO loss to maximize the consistency reward of generated samples while penalizing the deviation from the pretrained model.
(2) Reward Guidance (RG): After fine-tuning with DCO loss, we introduce RG to control the trade-off between consistency and image-text alignment by interpolating the noise estimations from the fine-tuned model and the pretrained model.
(3) Prompt Construction for Reference Images: We emphasize the importance of comprehensive captions for reference images and provide examples to illustrate the difference between compact captions and comprehensive captions.</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚
å¼•å…¥äº†ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚
å¼ºè°ƒäº†ä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒçš„å¿…è¦æ€§ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„å¯¹é½ã€‚
æ€§èƒ½ï¼š
åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹çš„æ–‡æœ¬åˆ°å›¾åƒä¸ªæ€§åŒ–æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
åœ¨å¸•ç´¯æ‰˜å‰æ²¿æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
éœ€è¦æ”¶é›†å’Œå‡†å¤‡å‚è€ƒå›¾åƒã€‚
éœ€è¦å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚
éœ€è¦é‡‡æ ·ç”Ÿæˆçš„å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-747445a04d574a8975290f4c0ffe6aca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-915bf11d3f533330ed7c94f5f635e501.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3a074dca6974482c499ea0392640cb3.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-02-23/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-02-23/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-02-23/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-02-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-02-13/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a5c73ab0e2d97eb040012ca4a7c897fe.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-13  BioNeRF Biologically Plausible Neural Radiance Fields for View   Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-02-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23901.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
