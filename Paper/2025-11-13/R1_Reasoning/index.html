<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-13  SpatialThinker Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.07403v1/page_5_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    84 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-13-æ›´æ–°"><a href="#2025-11-13-æ›´æ–°" class="headerlink" title="2025-11-13 æ›´æ–°"></a>2025-11-13 æ›´æ–°</h1><h2 id="SpatialThinker-Reinforcing-3D-Reasoning-in-Multimodal-LLMs-via-Spatial-Rewards"><a href="#SpatialThinker-Reinforcing-3D-Reasoning-in-Multimodal-LLMs-via-Spatial-Rewards" class="headerlink" title="SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards"></a>SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards</h2><p><strong>Authors:Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark</strong></p>
<p>Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.</p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨ç©ºé—´ç†è§£æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚ç°æœ‰çš„ç©ºé—´MLLMsé€šå¸¸ä¾èµ–äºæ˜ç¡®çš„3Dè¾“å…¥æˆ–é’ˆå¯¹ç‰¹å®šæ¶æ„çš„ä¿®æ”¹ï¼Œå¹¶å—åˆ°å¤§è§„æ¨¡æ•°æ®é›†æˆ–ç¨€ç–ç›‘ç£çš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†SpatialThinkerï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒçš„å¯¹3Dæœ‰æ„ŸçŸ¥çš„MLLMï¼Œæ—¨åœ¨å°†ç»“æ„åŒ–ç©ºé—´æ¥åœ°ä¸å¤šæ­¥éª¤æ¨ç†ç›¸ç»“åˆã€‚è¯¥æ¨¡å‹é€šè¿‡æ„å»ºä¸ä»»åŠ¡ç›¸å…³çš„å¯¹è±¡å’Œç©ºé—´å…³ç³»çš„åœºæ™¯å›¾æ¥æ¨¡æ‹Ÿäººç±»çš„ç©ºé—´æ„ŸçŸ¥ï¼Œå¹¶é€šè¿‡å¯†é›†çš„ç©ºé—´å¥–åŠ±è¿›è¡Œæ¨ç†ä»¥å¾—å‡ºç­”æ¡ˆã€‚SpatialThinkerç”±ä¸¤ä¸ªå…³é”®è´¡çŒ®ç»„æˆï¼šï¼ˆ1ï¼‰æ•°æ®åˆæˆç®¡é“ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç©ºé—´VQAæ•°æ®é›†STVQA-7Kï¼›ï¼ˆ2ï¼‰åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼Œé‡‡ç”¨å¤šç›®æ ‡å¯†é›†ç©ºé—´å¥–åŠ±æ¥åŠ å¼ºç©ºé—´æ¥åœ°ã€‚SpatialThinker-7Båœ¨ç©ºé—´å’Œç°å®ä¸–ç•ŒVQAåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºç›‘ç£å¾®è°ƒæ–¹æ³•å’Œç¨€ç–å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œä¸ç¨€ç–å¼ºåŒ–å­¦ä¹ ç›¸æ¯”ï¼Œå®ƒå‡ ä¹å°†åŸºç¡€æ¨¡å‹çš„æ”¶ç›Šæé«˜äº†ä¸€å€ï¼Œå¹¶è¶…è¶Šäº†GPT-4oã€‚è¿™äº›ç»“æœå±•ç¤ºäº†åœ¨ç©ºé—´ç›‘ç£ä¸å¥–åŠ±å¯¹é½çš„æ¨ç†ç›¸ç»“åˆæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æœ‰é™çš„æ•°æ®ä¸­å®ç°ç¨³å¥çš„3Dç©ºé—´ç†è§£ï¼Œæ¨åŠ¨MLLMsæœç€äººç±»æ°´å¹³çš„è§†è§‰æ¨ç†å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.07403v1">PDF</a> Preprint. Accepted at NeurIPS 2025 Workshops on SPACE in Vision, Language, and Embodied AI (SpaVLE), Embodied World Models for Decision Making (EWM), Aligning Reinforcement Learning Experimentalists and Theorists (ARLET), and Scaling Environments for Agents (SEA)</p>
<p><strong>Summary</strong></p>
<p>ç©ºé—´å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨ç©ºé—´ç†è§£æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸ºè§£å†³ç°æœ‰ç©ºé—´MLLMså¯¹æ˜ç¡®3Dè¾“å…¥æˆ–ç‰¹å®šæ¶æ„ä¿®æ”¹çš„ä¾èµ–ï¼Œä»¥åŠå¤§è§„æ¨¡æ•°æ®é›†æˆ–ç¨€ç–ç›‘ç£çš„é™åˆ¶ï¼Œæˆ‘ä»¬æ¨å‡ºäº†SpatialThinkerã€‚è¿™æ˜¯ä¸€æ¬¾ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒè€Œæˆçš„å…·å¤‡3Dæ„ŸçŸ¥èƒ½åŠ›çš„MLLMï¼Œèƒ½å¤Ÿæ•´åˆç»“æ„åŒ–ç©ºé—´æ¥åœ°ä¸å¤šæ­¥æ¨ç†ã€‚å®ƒé€šè¿‡æ„å»ºä»»åŠ¡ç›¸å…³ç‰©ä½“å’Œç©ºç¼˜å…³ç³»çš„åœºæ™¯å›¾æ¥æ¨¡æ‹Ÿäººç±»çš„ç©ºé—´æ„ŸçŸ¥ï¼Œå¹¶é€šè¿‡å¯†é›†çš„ç©ºé—´å¥–åŠ±è¿›è¡Œæ¨ç†å¾—å‡ºç­”æ¡ˆã€‚SpatialThinkerçš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰æ•°æ®åˆæˆç®¡é“ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç©ºé—´VQAæ•°æ®é›†STVQA-7Kï¼›ï¼ˆ2ï¼‰åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼Œé‡‡ç”¨å¤šç›®æ ‡å¯†é›†ç©ºé—´å¥–åŠ±æ¥å¼ºåŒ–ç©ºé—´æ¥åœ°ã€‚åœ¨ç†è§£å’Œç°å®ä¸–ç•Œé—®ç­”åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSpatialThinker-7Bçš„è¡¨ç°ä¼˜äºç›‘ç£å¾®è°ƒæ–¹æ³•å’Œç¨€ç–å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œå…¶å¢ç›Šå‡ ä¹æ˜¯åŸºç¡€æ¨¡å‹çš„ä¸¤å€ï¼Œå¹¶è¶…è¶Šäº†GPT-4oã€‚è¿™äº›ç»“æœå±•ç¤ºäº†åœ¨ç©ºé—´ç›‘ç£ä¸å¥–åŠ±å¯¹é½æ¨ç†çš„ç»“åˆä¸‹ï¼Œå®ç°æœ‰é™æ•°æ®çš„ç¨³å¥3Dç©ºé—´ç†è§£çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ¨åŠ¨MLLMå‘äººç±»æ°´å¹³çš„è§†è§‰æ¨ç†å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨ç©ºé—´ç†è§£æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰ç©ºé—´MLLMså¸¸å¸¸ä¾èµ–æ˜ç¡®çš„3Dè¾“å…¥æˆ–ç‰¹å®šæ¶æ„ä¿®æ”¹ï¼Œå¹¶å—é™äºå¤§è§„æ¨¡æ•°æ®é›†å’Œç¨€ç–ç›‘ç£ã€‚</li>
<li>SpatialThinkeræ˜¯ä¸€æ¬¾ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„å…·å¤‡3Dæ„ŸçŸ¥èƒ½åŠ›çš„MLLMï¼Œèƒ½æ•´åˆç»“æ„åŒ–ç©ºé—´æ¥åœ°ä¸å¤šæ­¥æ¨ç†ã€‚</li>
<li>SpatialThinkeré€šè¿‡æ„å»ºåœºæ™¯å›¾æ¥æ¨¡æ‹Ÿäººç±»çš„ç©ºé—´æ„ŸçŸ¥ï¼ŒåŒ…æ‹¬ä»»åŠ¡ç›¸å…³ç‰©ä½“å’Œç©ºç¼˜å…³ç³»ã€‚</li>
<li>SpatialThinkeré‡‡ç”¨æ•°æ®åˆæˆç®¡é“ç”Ÿæˆé«˜è´¨é‡çš„ç©ºé—´VQAæ•°æ®é›†STVQA-7Kã€‚</li>
<li>åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸å¤šç›®æ ‡å¯†é›†ç©ºé—´å¥–åŠ±è¢«ç”¨äºå¼ºåŒ–ç©ºé—´æ¥åœ°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.07403">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.07403v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.07403v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.07403v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.07403v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SofT-GRPO-Surpassing-Discrete-Token-LLM-Reinforcement-Learning-via-Gumbel-Reparameterized-Soft-Thinking-Policy-Optimization"><a href="#SofT-GRPO-Surpassing-Discrete-Token-LLM-Reinforcement-Learning-via-Gumbel-Reparameterized-Soft-Thinking-Policy-Optimization" class="headerlink" title="SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization"></a>SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization</h2><p><strong>Authors:Zhi Zheng, Wee Sun Lee</strong></p>
<p>The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on <a target="_blank" rel="noopener" href="https://github.com/zz1358m/SofT-GRPO-master">https://github.com/zz1358m/SofT-GRPO-master</a></p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†çš„è½¯æ€è€ƒèŒƒå¼åœ¨æŸäº›åœºæ™¯ä¸­èƒ½ä¼˜äºä¼ ç»Ÿçš„ç¦»æ•£æ ‡è®°é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ï¼Œè¿™å‡¸æ˜¾äº†å®ƒçš„ç ”ç©¶å’Œåº”ç”¨ä»·å€¼ã€‚ç„¶è€Œï¼Œè™½ç„¶é€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ç­‰ç­–ç•¥ä¼˜åŒ–ç®—æ³•å¯ä»¥åŠ å¼ºç¦»æ•£æ ‡è®°çš„CoTæ¨ç†æ¨¡å¼ï¼Œä½†ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥æ‰©å±•è½¯æ€è€ƒæ¨¡å¼ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™ä¸€éš¾ç‚¹æºäºå‘è½¯æ€è€ƒæ ‡è®°ä¸­æ³¨å…¥éšæœºæ€§å¹¶ç›¸åº”æ›´æ–°è½¯æ€è€ƒç­–ç•¥çš„å¤æ‚æ€§ã€‚å› æ­¤ï¼Œä¹‹å‰å°è¯•å°†è½¯æ€è€ƒä¸GRPOç›¸ç»“åˆçš„å°è¯•é€šå¸¸è¡¨ç°ä¸å¦‚å…¶ç¦»æ•£æ ‡è®°GRPOçš„åŒç±»ç®—æ³•ã€‚ä¸ºäº†å……åˆ†å‘æŒ¥è½¯æ€è€ƒçš„ä¼˜åŠ¿ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•SofT-GRPOï¼Œä»¥åœ¨è½¯æ€è€ƒæ¨ç†æ¨¡å¼ä¸‹åŠ å¼ºLLMã€‚SofT-GRPOå‘é€»è¾‘æ¦‚ç‡ä¸­æ³¨å…¥Gumbelå™ªå£°ï¼Œé‡‡ç”¨Gumbel-SoftmaxæŠ€æœ¯é¿å…è½¯æ€è€ƒæ ‡è®°è¶…å‡ºé¢„è®­ç»ƒåµŒå…¥ç©ºé—´ï¼Œå¹¶åˆ©ç”¨ç­–ç•¥æ¢¯åº¦ä¸­çš„é‡å‚æ•°åŒ–æŠ€å·§ã€‚æˆ‘ä»¬åœ¨åŸºç¡€LLMä¸Šè¿›è¡Œäº†å®éªŒï¼Œå‚æ•°èŒƒå›´ä»1.5Båˆ°7Bï¼Œç»“æœè¡¨æ˜SofT-GRPOä½¿è½¯æ€è€ƒLLMåœ¨Pass@1ï¼ˆå¹³å‡å‡†ç¡®ç‡æé«˜0.13%ï¼‰ä¸Šç•¥å¾®ä¼˜äºç¦»æ•£æ ‡è®°GRPOï¼Œè€Œåœ¨Pass@32ï¼ˆå¹³å‡å‡†ç¡®ç‡æé«˜2.19%ï¼‰ä¸Šæœ‰æ˜¾è‘—çš„æå‡ã€‚ç›¸å…³ä»£ç å’Œæƒé‡å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zz1358m/SofT-GRPO-master%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zz1358m/SofT-GRPO-masteræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.06411v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è½¯æ€è€ƒèŒƒå¼ä¸ä¼ ç»Ÿç¦»æ•£ç¬¦å·é“¾æ€è€ƒï¼ˆCoTï¼‰èŒƒå¼çš„å¯¹æ¯”ã€‚è½¯æ€è€ƒåœ¨æŸäº›åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œä½†ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•SofT-GRPOï¼Œæ—¨åœ¨å¼ºåŒ–è½¯æ€è€ƒæ¨¡å¼ä¸‹çš„LLMã€‚å®éªŒè¡¨æ˜ï¼ŒSofT-GRPOåœ¨Pass@1å’ŒPass@32ä¸Šç•¥æœ‰ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è½¯æ€è€ƒèŒƒå¼åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­å±•ç°å‡ºä¼˜äºä¼ ç»Ÿç¦»æ•£ç¬¦å·é“¾æ€è€ƒï¼ˆCoTï¼‰èŒƒå¼çš„æ½œåŠ›ã€‚</li>
<li>ç¦»æ•£ç¬¦å·CoTæ¨ç†æ¨¡å¼å¯é€šè¿‡ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ç»„ç›¸å…³ç­–ç•¥ä¼˜åŒ–GRPOï¼‰åŠ å¼ºã€‚</li>
<li>è½¯æ€è€ƒä¸å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç»“åˆé¢ä¸´æŒ‘æˆ˜ï¼Œæºäºå‘è½¯æ€è€ƒæ ‡è®°æ³¨å…¥éšæœºæ€§å’Œç›¸åº”æ›´æ–°è½¯æ€è€ƒç­–ç•¥çš„å¤æ‚æ€§ã€‚</li>
<li>å°è¯•ç»“åˆè½¯æ€è€ƒä¸GRPOçš„æ–¹æ³•é€šå¸¸è¡¨ç°ä¸å¦‚ç¦»æ•£ç¬¦å·GRPOã€‚</li>
<li>SofT-GRPOæ˜¯ä¸€ç§æ–°çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œæ—¨åœ¨å¼ºåŒ–è½¯æ€è€ƒæ¨¡å¼ä¸‹çš„LLMã€‚</li>
<li>SofT-GRPOé€šè¿‡æ³¨å…¥Gumbelå™ªå£°åˆ°logitsã€ä½¿ç”¨Gumbel-SoftmaxæŠ€æœ¯é¿å…è½¯æ€è€ƒæ ‡è®°è¶…å‡ºé¢„è®­ç»ƒåµŒå…¥ç©ºé—´å’Œä½¿ç”¨ç­–ç•¥æ¢¯åº¦ä¸­çš„é‡å‚æ•°åŒ–æŠ€å·§æ¥å®ç°å…¶ç›®æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.06411">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.06411v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.06411v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.06411v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2511.06411v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="PRISM-Bench-A-Benchmark-of-Puzzle-Based-Visual-Tasks-with-CoT-Error-Detection"><a href="#PRISM-Bench-A-Benchmark-of-Puzzle-Based-Visual-Tasks-with-CoT-Error-Detection" class="headerlink" title="PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection"></a>PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection</h2><p><strong>Authors:Yusu Qian, Cheng Wan, Chao Jia, Yinfei Yang, Qingyu Zhao, Zhe Gan</strong></p>
<p>Multimodal large language models (MLLMs) have achieved remarkable progress on vision-language tasks, yet their reasoning processes remain sometimes unreliable. We introduce PRISM-Bench, a benchmark of puzzle-based visual challenges designed to evaluate not only whether models can solve problems, but how their reasoning unfolds. Unlike prior evaluations that measure only final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error, models must identify the first incorrect step. This setting enables fine-grained assessment of logical consistency, error detection, and visual reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric, and analogical reasoning, resisting shortcuts based on superficial pattern matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap between fluent generation and faithful reasoning: models that produce plausible CoTs often fail to locate simple logical faults. By disentangling answer generation from reasoning verification, PRISM-Bench offers a sharper lens on multimodal reasoning competence and underscores the need for diagnostic evaluation protocols in the development of trustworthy MLLMs.</p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†å®ƒä»¬çš„æ¨ç†è¿‡ç¨‹æœ‰æ—¶ä»ç„¶ä¸å¯é ã€‚æˆ‘ä»¬å¼•å…¥äº†PRISM-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè°œé¢˜è§†è§‰æŒ‘æˆ˜çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹ä¸ä»…æ˜¯å¦èƒ½è§£å†³é—®é¢˜ï¼Œè¿˜èƒ½è¯„ä¼°å®ƒä»¬çš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ä»¥å¾€ä»…æµ‹é‡æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§çš„è¯„ä¼°ä¸åŒï¼ŒPRISM-Benchå¼•å…¥äº†ä¸€é¡¹è¯Šæ–­ä»»åŠ¡ï¼šç»™å®šä¸€ä¸ªè§†è§‰è°œé¢˜å’Œä¸€ä¸ªé€æ­¥æ€è€ƒè¿‡ç¨‹ï¼ˆCoTï¼‰ï¼Œå…¶ä¸­åŒ…å«æ°å¥½ä¸€ä¸ªé”™è¯¯ï¼Œæ¨¡å‹å¿…é¡»è¯†åˆ«å‡ºç¬¬ä¸€ä¸ªé”™è¯¯çš„æ­¥éª¤ã€‚è¿™ç§è®¾ç½®èƒ½å¤Ÿç²¾ç»†åœ°è¯„ä¼°é€»è¾‘ä¸€è‡´æ€§ã€é”™è¯¯æ£€æµ‹å’Œè§†è§‰æ¨ç†ã€‚PRISM-Benchä¸­çš„è°œé¢˜éœ€è¦è¿›è¡Œå¤šæ­¥éª¤çš„ç¬¦å·ã€å‡ ä½•å’Œç±»æ¯”æ¨ç†ï¼ŒæŠµåˆ¶åŸºäºè¡¨é¢æ¨¡å¼åŒ¹é…çš„æ·å¾„ã€‚å¯¹æœ€æ–°MLLMsçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæµç•…ç”Ÿæˆå’Œå¿ å®æ¨ç†ä¹‹é—´å­˜åœ¨æŒç»­å·®è·ï¼šèƒ½å¤Ÿäº§ç”Ÿåˆç†æ€è€ƒè¿‡ç¨‹çš„æ¨¡å‹å¾€å¾€æ— æ³•æ‰¾å‡ºç®€å•çš„é€»è¾‘é”™è¯¯ã€‚é€šè¿‡å°†ç­”æ¡ˆç”Ÿæˆä¸æ¨ç†éªŒè¯åˆ†å¼€ï¼ŒPRISM-Benchä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›æä¾›äº†æ›´é”åˆ©çš„è§†è§’ï¼Œå¹¶å¼ºè°ƒäº†åœ¨å¼€å‘å¯é MLLMsæ—¶éœ€è¦è¯Šæ–­è¯„ä¼°åè®®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.23594v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>MLLMåœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹æœ‰æ—¶ä¸å¯é ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†PRISM-BenchåŸºå‡†æµ‹è¯•ï¼Œå®ƒåŸºäºè°œé¢˜è®¾è®¡çš„è§†è§‰æŒ‘æˆ˜ä»»åŠ¡ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹ä¸ä»…èƒ½è§£å†³é—®é¢˜ï¼Œè¿˜èƒ½å¦‚ä½•å±•ç°å…¶æ¨ç†è¿‡ç¨‹ã€‚ä¸ä»…æµ‹é‡æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§çš„å…ˆå‰è¯„ä¼°ä¸åŒï¼ŒPRISM-Benchå¼•å…¥äº†ä¸€é¡¹è¯Šæ–­ä»»åŠ¡ï¼šç»™å®šä¸€ä¸ªè§†è§‰è°œé¢˜å’Œä¸€ä¸ªé€æ­¥æ¨ç†è¿‡ç¨‹ï¼ˆCoTï¼‰ï¼Œå…¶ä¸­æ°å¥½æœ‰ä¸€ä¸ªé”™è¯¯æ­¥éª¤ï¼Œæ¨¡å‹å¿…é¡»æ‰¾å‡ºç¬¬ä¸€ä¸ªé”™è¯¯çš„æ­¥éª¤ã€‚è¿™ä¸€è®¾å®šæœ‰åŠ©äºç²¾ç»†è¯„ä¼°é€»è¾‘ä¸€è‡´æ€§ã€é”™è¯¯æ£€æµ‹å’Œè§†è§‰æ¨ç†èƒ½åŠ›ã€‚PRISM-Benchä¸­çš„è°œé¢˜è¦æ±‚å¤šæ­¥éª¤çš„ç¬¦å·ã€å‡ ä½•å’Œç±»æ¯”æ¨ç†ï¼ŒæŠµæŠ—åŸºäºè¡¨é¢æ¨¡å¼çš„æ·å¾„ã€‚å¯¹æœ€æ–°MLLMçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæµç•…ç”Ÿæˆä¸å¿ å®æ¨ç†ä¹‹é—´å­˜åœ¨æŒä¹…å·®è·ï¼šèƒ½å¤Ÿç”Ÿæˆåˆç†CoTçš„æ¨¡å‹å¾€å¾€æ— æ³•æ‰¾åˆ°ç®€å•çš„é€»è¾‘é”™è¯¯ã€‚é€šè¿‡è§£å¼€ç­”æ¡ˆç”Ÿæˆä¸æ¨ç†éªŒè¯çš„å…³è”ï¼ŒPRISM-Benchä¸ºè¯„ä¼°å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›æä¾›äº†æ›´é”åˆ©çš„è§†è§’ï¼Œå¹¶å¼ºè°ƒåœ¨å¼€å‘å¯ä¿¡èµ–çš„MLLMè¿‡ç¨‹ä¸­éœ€è¦è¯Šæ–­è¯„ä¼°åè®®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†æ¨ç†è¿‡ç¨‹æœ‰æ—¶ä¸å¯é ã€‚</li>
<li>PRISM-BenchåŸºå‡†æµ‹è¯•æ—¨åœ¨è¯„ä¼°MLLMä¸ä»…è§£å†³é—®é¢˜ï¼Œè€Œä¸”å¦‚ä½•å±•ç°å…¶æ¨ç†è¿‡ç¨‹ã€‚</li>
<li>PRISM-Benchå¼•å…¥äº†ä¸€é¡¹æ–°çš„è¯Šæ–­ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹è¯†åˆ«åŒ…å«ç²¾ç¡®ä¸€ä¸ªé”™è¯¯çš„é€æ­¥æ¨ç†è¿‡ç¨‹ä¸­çš„ç¬¬ä¸€ä¸ªé”™è¯¯æ­¥éª¤ã€‚</li>
<li>è¿™ä¸€è®¾å®šèƒ½å¤Ÿç²¾ç»†è¯„ä¼°æ¨¡å‹çš„é€»è¾‘ä¸€è‡´æ€§ã€é”™è¯¯æ£€æµ‹å’Œè§†è§‰æ¨ç†èƒ½åŠ›ã€‚</li>
<li>PRISM-Benchä¸­çš„è°œé¢˜éœ€è¦å¤šæ­¥éª¤çš„ç¬¦å·ã€å‡ ä½•å’Œç±»æ¯”æ¨ç†ï¼Œä¸æ˜“é€šè¿‡è¡¨é¢æ¨¡å¼åŒ¹é…æ¥æ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚</li>
<li>è¯„ä¼°æ˜¾ç¤ºï¼Œå½“å‰MLLMåœ¨ç”Ÿæˆæµç•…ç­”æ¡ˆå’Œå¿ å®æ‰§è¡Œæ¨ç†ä¹‹é—´å­˜æœ‰æ˜æ˜¾å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.23594">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.23594v2/page_5_1.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Slow-Fast-Policy-Optimization-Reposition-Before-Update-for-LLM-Reasoning"><a href="#Slow-Fast-Policy-Optimization-Reposition-Before-Update-for-LLM-Reasoning" class="headerlink" title="Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning"></a>Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning</h2><p><strong>Authors:Ziyan Wang, Zheng Wang, Jie Fu, Xingwei Qu, Qi Cheng, Shengpu Tang, Minjia Zhang, Xiaoming Huo</strong></p>
<p>Reinforcement learning (RL) has become central to enhancing reasoning in large language models (LLMs). Yet on-policy algorithms such as Group Relative Policy Optimization (GRPO) often suffer in early training: noisy gradients from low-quality rollouts lead to unstable updates and inefficient exploration. We introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient framework to address these limitations via decomposing each step into three stages: a short fast trajectory of inner steps on the same batch, a reposition mechanism to control off-policy drift, and a final slow correction. This reposition-before-update design preserves the objective and rollout process unchanged, making SFPO plug-compatible with existing policy-gradient pipelines. Extensive experiments demonstrate that SFPO consistently improves stability, reduces rollouts, and accelerates convergence of reasoning RL training. Specifically, it outperforms GRPO by up to 2.80 points in average on math reasoning benchmarks. It also achieves up to 4.93\texttimes{} fewer rollouts and an up to 4.19\texttimes{} reduction in wall-clock time to match GRPOâ€™s best accuracy.</p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å‘æŒ¥ç€æ ¸å¿ƒä½œç”¨ã€‚ç„¶è€Œï¼ŒåŸºäºç­–ç•¥çš„ç®—æ³•ï¼Œå¦‚é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œåœ¨æ—©æœŸè®­ç»ƒä¸­ç»å¸¸é­é‡å›°å¢ƒï¼šæ¥è‡ªä½è´¨é‡rolloutsçš„å™ªå£°æ¢¯åº¦å¯¼è‡´æ›´æ–°ä¸ç¨³å®šå’Œæ•ˆç‡ä¸é«˜çš„æ¢ç´¢ã€‚æˆ‘ä»¬å¼•å…¥äº†æ…¢å¿«ç­–ç•¥ä¼˜åŒ–ï¼ˆSFPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„æ¡†æ¶ï¼Œé€šè¿‡åˆ†è§£æ¯ä¸€æ­¥ä¸ºä¸‰ä¸ªé˜¶æ®µæ¥è§£å†³è¿™äº›é™åˆ¶ï¼šåœ¨åŒä¸€æ‰¹æ¬¡ä¸Šè¿›è¡ŒçŸ­æš‚å¿«é€Ÿçš„å†…æ­¥è½¨è¿¹ã€æ§åˆ¶ç¦»ç­–ç•¥æ¼‚ç§»çš„å®šä½æœºåˆ¶ã€ä»¥åŠæœ€åçš„ç¼“æ…¢æ ¡æ­£ã€‚è¿™ç§æ›´æ–°å‰çš„å®šä½è®¾è®¡ä¿æŒäº†ç›®æ ‡å’Œrolloutè¿‡ç¨‹ä¸å˜ï¼Œä½¿å¾—SFPOä¸ç°æœ‰çš„ç­–ç•¥æ¢¯åº¦ç®¡é“å…¼å®¹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSFPOæŒç»­æé«˜äº†ç¨³å®šæ€§ï¼Œå‡å°‘äº†rolloutsï¼Œå¹¶åŠ é€Ÿäº†æ¨ç†RLè®­ç»ƒçš„æ”¶æ•›ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒåœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æ¯”GRPOé«˜å‡º2.80ä¸ªç‚¹ã€‚å®ƒè¿˜å®ç°äº†æœ€å¤šå‡å°‘4.93å€rolloutså’Œæœ€å¤šå‡å°‘4.19å€åŒ¹é…GRPOæœ€ä½³å‡†ç¡®ç‡çš„æ—¶é’Ÿæ—¶é—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.04072v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚ç„¶è€Œï¼Œæ—©æœŸè®­ç»ƒä¸­å¦‚Group Relative Policy Optimizationï¼ˆGRPOï¼‰ç­‰åŸºäºç­–ç•¥çš„ç®—æ³•å¸¸å¸¸é¢ä¸´æŒ‘æˆ˜ï¼šæ¥è‡ªä½è´¨é‡rolloutsçš„å™ªå£°æ¢¯åº¦å¯¼è‡´æ›´æ–°ä¸ç¨³å®šå’Œæ•ˆç‡ä½ä¸‹çš„æ¢ç´¢è¿‡ç¨‹ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºSlow-Fast Policy Optimizationï¼ˆSFPOï¼‰ï¼Œå®ƒæ˜¯ä¸€ç§é€šè¿‡åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µçš„ç®€å•è€Œæœ‰æ•ˆçš„æ¡†æ¶ï¼šåœ¨åŒä¸€æ‰¹æ¬¡ä¸Šè¿›è¡ŒçŸ­æ—¶é—´çš„å¿«é€Ÿè½¨è¿¹å†…éƒ¨æ­¥éª¤ã€æ§åˆ¶éç­–ç•¥åç§»çš„é‡æ–°å®šä½æœºåˆ¶ï¼Œä»¥åŠæœ€ç»ˆçš„æ…¢é€Ÿä¿®æ­£ã€‚è¿™ç§æ›´æ–°å‰çš„é‡æ–°å®šä½è®¾è®¡ä¿ç•™äº†ç›®æ ‡å€¼å’Œrolloutè¿‡ç¨‹ä¸å˜ï¼Œä½¿å¾—SFPOèƒ½å¤Ÿå…¼å®¹ç°æœ‰çš„ç­–ç•¥æ¢¯åº¦ç®¡é“ã€‚å®éªŒè¯æ˜ï¼ŒSFPOåœ¨ç¨³å®šæ€§ã€å‡å°‘rolloutså’ŒåŠ é€Ÿæ¨ç†è®­ç»ƒæ”¶æ•›æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚ç‰¹åˆ«åœ°ï¼Œå®ƒåœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æ¯”GRPOé«˜å‡ºé«˜è¾¾2.80ä¸ªç‚¹ï¼ŒåŒæ—¶å‡å°‘äº†é«˜è¾¾4.93å€rolloutsï¼Œå¹¶åœ¨åŒ¹é…GRPOçš„æœ€ä½³å‡†ç¡®æ€§æ—¶å‡å°‘äº†é«˜è¾¾4.19å€çš„æ—¶é’Ÿæ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸­èµ·å…³é”®ä½œç”¨ã€‚</li>
<li>åŸºäºç­–ç•¥çš„ç®—æ³•å¦‚GRPOåœ¨æ—©æœŸè®­ç»ƒä¸­é¢ä¸´å™ªå£°æ¢¯åº¦å’Œä¸ç¨³å®šæ›´æ–°é—®é¢˜ã€‚</li>
<li>SFPOæ¡†æ¶é€šè¿‡åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µæ¥è§£å†³è¿™äº›é—®é¢˜ï¼šå¿«é€Ÿè½¨è¿¹ã€é‡æ–°å®šä½æœºåˆ¶å’Œæ…¢é€Ÿä¿®æ­£ã€‚</li>
<li>SFPOä¸ç°æœ‰ç­–ç•¥æ¢¯åº¦ç®¡é“å…¼å®¹ï¼Œä¿æŒç›®æ ‡å€¼å’Œrolloutè¿‡ç¨‹ä¸å˜ã€‚</li>
<li>å®éªŒè¯æ˜SFPOåœ¨ç¨³å®šæ€§ã€å‡å°‘rolloutså’ŒåŠ é€Ÿè®­ç»ƒæ”¶æ•›æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>SFPOåœ¨æ•°å­¦æ¨ç†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºGRPOï¼Œå¹³å‡é«˜å‡º2.8ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.04072">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.04072v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.04072v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.04072v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GRPO-Î»-Credit-Assignment-improves-LLM-Reasoning"><a href="#GRPO-Î»-Credit-Assignment-improves-LLM-Reasoning" class="headerlink" title="GRPO-$Î»$: Credit Assignment improves LLM Reasoning"></a>GRPO-$Î»$: Credit Assignment improves LLM Reasoning</h2><p><strong>Authors:Prasanna Parthasarathi, Mathieu Reymond, Boxing Chen, Yufei Cui, Sarath Chandar</strong></p>
<p>Large language models (LLMs) are increasingly deployed for tasks requiring complex reasoning, prompting significant interest in improving their reasoning abilities through post-training. Especially RL based methods using verifiable reward, like the state-of-the-art GRPO, have shown to tremendously improve reasoning behaviors when applied as post-training methods. However, the lack of an explicit reward or critic model limits GRPOâ€™s ability to assign fine-grained credit across token sequences. In this work, we present GRPO-$Î»$, a novel extension to GRPO that enhances credit assignment in RL finetuning of LLMs for complex reasoning tasks. We approximate learning from $Î»$-return with a reformulation of eligibility traces using token-level log-probabilities applied after each sequence generation, and a novel critic-free approximation of the temporal-difference error. We introduce a few variations for the weighting of the $Î»$-return, and their applications to the eligibility-trace, where all the variations provide significant gains over GRPO. We compare GRPO-$Î»$ against GRPO by training models from 1.5B to 7B parameters on $4$ different math reasoning datasets. The training plots demonstrate 30-40% improved performance during RL training on both LLaMA-3.1 and Qwen-2.5 architectures. Finally, we show that with GRPO-$Î»$, the resulting average performance on AIME24, Math500, OlympiadMath, MinervaMath, and AMC improves over GRPO by over $3$ points and a $4.5$ points improvement on the 7B model.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²äºéœ€è¦å¤æ‚æ¨ç†çš„ä»»åŠ¡ä¸­ï¼Œè¿™å¼•å‘äº†é€šè¿‡åç»­è®­ç»ƒæé«˜å…¶æ¨ç†èƒ½åŠ›çš„æµ“åšå…´è¶£ã€‚ç‰¹åˆ«æ˜¯åŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¦‚æœ€å…ˆè¿›çš„GRPOï¼Œåœ¨ä½œä¸ºåç»­è®­ç»ƒæ–¹æ³•åº”ç”¨æ—¶ï¼Œå·²è¯æ˜èƒ½æå¤§åœ°æ”¹å–„æ¨ç†è¡Œä¸ºã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜ç¡®çš„å¥–åŠ±æˆ–è¯„è®ºå®¶æ¨¡å‹ï¼ŒGRPOåœ¨è·¨ä»¤ç‰Œåºåˆ—åˆ†é…ç²¾ç»†ç²’åº¦ä¿¡ç”¨æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GRPO-$Î»$ï¼Œè¿™æ˜¯GRPOçš„ä¸€ä¸ªæ–°é¢–æ‰©å±•ï¼Œå¯å¢å¼ºåœ¨å¤æ‚æ¨ç†ä»»åŠ¡çš„LLMå¼ºåŒ–å­¦ä¹ å¾®è°ƒä¸­çš„ä¿¡ç”¨åˆ†é…ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä»¤ç‰Œçº§åˆ«æ—¥å¿—æ¦‚ç‡çš„èµ„æ ¼ç—•è¿¹é‡æ–°è¡¨è¿°æ¥å­¦ä¹ $Î»$-å›æŠ¥çš„è¿‘ä¼¼å€¼ï¼Œè¿™æ˜¯åœ¨æ¯æ¬¡åºåˆ—ç”Ÿæˆååº”ç”¨çš„ï¼Œä»¥åŠæ—¶é—´å·®è¯¯å·®çš„æ— è¯„è®ºå®¶è¿‘ä¼¼å€¼ã€‚æˆ‘ä»¬ä»‹ç»äº†å‡ ç§$Î»$-å›æŠ¥çš„åŠ æƒæ–¹æ³•åŠå…¶åœ¨èµ„æ ¼ç—•è¿¹ä¸­çš„åº”ç”¨ï¼Œæ‰€æœ‰å˜ä½“éƒ½æä¾›äº†å¯¹GRPOçš„é‡å¤§æ”¶ç›Šã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸åŒçš„æ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šè®­ç»ƒä»1.5Båˆ°7Bå‚æ•°çš„æ¨¡å‹ï¼Œæ¯”è¾ƒäº†GRPO-$Î»$å’ŒGRPOã€‚è®­ç»ƒå›¾è¡¨æ˜ï¼Œåœ¨LLaMA-3.1å’ŒQwen-2.5æ¶æ„ä¸Šï¼ŒRLè®­ç»ƒæœŸé—´æ€§èƒ½æé«˜äº†30-40%ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä½¿ç”¨GRPO-$Î»$ï¼Œåœ¨AIME24ã€Math500ã€OlympiadMathã€MinervaMathå’ŒAMCä¸Šçš„å¹³å‡æ€§èƒ½ä¼˜äºGRPOè¶…è¿‡3åˆ†ï¼Œ7Bæ¨¡å‹ä¸Šæ”¹è¿›äº†4.5åˆ†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00194v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éœ€è¦å¤æ‚æ¨ç†çš„ä»»åŠ¡éƒ¨ç½²ä¸­è¶Šæ¥è¶Šå¹¿æ³›ï¼Œå¼•å‘äº†é€šè¿‡åå¤©è®­ç»ƒæé«˜å…¶æ¨ç†èƒ½åŠ›çš„å…´è¶£ã€‚ç‰¹åˆ«æ˜¯ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•ï¼Œå¦‚æœ€æ–°çš„GRPOï¼Œå·²è¢«è¯æ˜åœ¨åå¤©è®­ç»ƒæ—¶èƒ½æå¤§åœ°æ”¹å–„æ¨ç†è¡Œä¸ºã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜ç¡®çš„å¥–åŠ±æˆ–è¯„è®ºå®¶æ¨¡å‹ï¼ŒGRPOåœ¨è·¨ä»¤ç‰Œåºåˆ—åˆ†é…ç²¾ç»†ç²’åº¦ä¿¡ç”¨æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†GRPO-$Î»$ï¼Œè¿™æ˜¯GRPOçš„ä¸€ä¸ªæ–°é¢–æ‰©å±•ï¼Œèƒ½å¤Ÿå¢å¼ºLLMsåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„ä¿¡ç”¨åˆ†é…èƒ½åŠ›ã€‚é€šè¿‡åˆ©ç”¨ä»¤ç‰Œçº§å¯¹æ•°æ¦‚ç‡å¯¹èµ„æ ¼è¿¹è¿›è¡Œé‡æ„ï¼Œä»¥åŠé‡‡ç”¨æ— è¯„è®ºå®¶æ¨¡å‹çš„æ—¶åºå·®åˆ†è¯¯å·®è¿‘ä¼¼ï¼Œæˆ‘ä»¬å®ç°äº†ä»$Î»$-å›æŠ¥ä¸­å­¦ä¹ ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†å‡ ç§åŠ æƒ$Î»$-å›æŠ¥çš„æ–¹æ³•ï¼Œä»¥åŠå…¶åœ¨èµ„æ ¼è¿¹ä¸­çš„åº”ç”¨ï¼Œæ‰€æœ‰è¿™äº›å˜ä½“éƒ½æä¾›äº†ç›¸è¾ƒäºGRPOçš„æ˜¾è‘—æ”¶ç›Šã€‚é€šè¿‡åœ¨ä¸åŒæ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šå¯¹è§„æ¨¡ä»1.5Båˆ°7Bçš„æ¨¡å‹è¿›è¡Œè®­ç»ƒæ¯”è¾ƒï¼Œè¯æ˜äº†GRPO-$Î»$çš„æœ‰æ•ˆæ€§ã€‚æœ€ç»ˆç»“æœæ˜¾ç¤ºï¼Œåœ¨AIME24ã€Math500ã€OlympiadMathã€MinervaMathå’ŒAMCç­‰å¤šä¸ªæ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºGRPOï¼Œä½¿ç”¨GRPO-$Î»$å¯æé«˜å¹³å‡æ€§èƒ½è¶…è¿‡3ä¸ªç‚¹ï¼Œå¹¶åœ¨7Bæ¨¡å‹ä¸Šæé«˜4.5ä¸ªç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„éƒ¨ç½²å¼•å‘äº†å¯¹æé«˜æ¨ç†èƒ½åŠ›çš„å…´è¶£ã€‚</li>
<li>åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ–¹æ³•ï¼Œå¦‚GRPOï¼Œå·²åœ¨LLMsçš„åå¤©è®­ç»ƒä¸­æ˜¾ç¤ºå‡ºå¯¹æ”¹å–„æ¨ç†è¡Œä¸ºçš„é‡è¦æ€§ã€‚</li>
<li>GRPOå­˜åœ¨è·¨ä»¤ç‰Œåºåˆ—åˆ†é…ç²¾ç»†ç²’åº¦ä¿¡ç”¨çš„å±€é™æ€§ã€‚</li>
<li>å¼•å…¥GRPO-$Î»$æ‰©å±•æ¥è§£å†³æ­¤é—®é¢˜ï¼Œå®ƒé€šè¿‡é‡æ„èµ„æ ¼è¿¹å¹¶åˆ©ç”¨æ— è¯„è®ºå®¶æ¨¡å‹çš„æ—¶åºå·®åˆ†è¯¯å·®è¿‘ä¼¼æ¥å®ç°ä»$Î»$-å›æŠ¥ä¸­å­¦ä¹ ã€‚</li>
<li>ä»‹ç»äº†åŠ æƒ$Î»$-å›æŠ¥çš„ä¸åŒæ–¹æ³•åŠå…¶åœ¨èµ„æ ¼è¿¹ä¸­çš„åº”ç”¨ã€‚</li>
<li>å¯¹æ¯”å®éªŒè¡¨æ˜ï¼ŒGRPO-$Î»$åœ¨å¤šä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºGRPOã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00194">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.00194v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.00194v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.00194v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2510.00194v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="WirelessMathLM-Teaching-Mathematical-Reasoning-for-LLMs-in-Wireless-Communications-with-Reinforcement-Learning"><a href="#WirelessMathLM-Teaching-Mathematical-Reasoning-for-LLMs-in-Wireless-Communications-with-Reinforcement-Learning" class="headerlink" title="WirelessMathLM: Teaching Mathematical Reasoning for LLMs in Wireless Communications with Reinforcement Learning"></a>WirelessMathLM: Teaching Mathematical Reasoning for LLMs in Wireless Communications with Reinforcement Learning</h2><p><strong>Authors:Xin Li, Mengbing Liu, Yiyang Zhu, Wenhe Zhang, Li Wei, Jiancheng An, Chau Yuen</strong></p>
<p>Large language models (LLMs) excel at general mathematical reasoning but fail catastrophically on specialized technical mathematics. In wireless communications, where problems require precise manipulation of information-theoretic bounds, optimization constraints, and signal processing formulations, even state-of-the-art models struggle to achieve competent performance. We present WirelessMathLM, demonstrating that compact models (0.5B-7B parameters) can match or exceed much larger models through domain-specific reinforcement learning with verifiable rewards. Our key insight is that wireless mathematics problems possess a unique propertyâ€“verifiable correctnessâ€“that enables effective reinforcement learning without human feedback. We construct WirelessMathBench-XL, a comprehensive benchmark of 4,027 problems from 970 papers. Using Group Relative Policy Optimization (GRPO) with binary verification rewards, we train models directly from base checkpoints without supervised warm-start. Our 7B model achieves 39.5% accuracy on WirelessMathBench-XL, approaching GPT-4o (40.4%) while using about 100 times fewer parameters than DeepSeek-R1 (671B, 57.4%). Remarkably, GRPO training nearly doubles performance across all model scales (0.5B +11%, 3B +103%, 7B +81%), with positive transfer to general mathematics benchmarksâ€“our models gain +8.4 points on average across MATH, Minerva-Math, OlympiadBench, AMC, and AIME without any training on these tasks.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸€èˆ¬æ•°å­¦æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä¸“ä¸šæŠ€æœ¯æ•°å­¦ä¸Šå´é­é‡äº†é‡å¤§å¤±è´¥ã€‚åœ¨æ— çº¿é€šä¿¡é¢†åŸŸï¼Œé—®é¢˜éœ€è¦å¯¹ä¿¡æ¯ç†è®ºç•Œé™ã€ä¼˜åŒ–çº¦æŸå’Œä¿¡å·å¤„ç†å…¬å¼è¿›è¡Œç²¾ç¡®æ“ä½œï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ä¹Ÿå¾ˆéš¾å®ç°å‡ºè‰²çš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†WirelessMathLMï¼Œè¯æ˜é€šè¿‡é¢†åŸŸç‰¹å®šçš„å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼Œå°å‹æ¨¡å‹ï¼ˆ0.5B-7Bå‚æ•°ï¼‰å¯ä»¥ä¸æ›´å¤§çš„æ¨¡å‹ç›¸åŒ¹æ•Œç”šè‡³è¶…è¿‡å®ƒä»¬ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œæ— çº¿æ•°å­¦é—®é¢˜å…·æœ‰å¯éªŒè¯æ­£ç¡®æ€§çš„ç‹¬ç‰¹å±æ€§ï¼Œè¿™å¯ä»¥åœ¨æ²¡æœ‰äººç±»åé¦ˆçš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆçš„å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬æ„å»ºäº†WirelessMathBench-XLï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«4027ä¸ªé—®é¢˜çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œæ¥è‡ª970ç¯‡è®ºæ–‡ã€‚æˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰äºŒè¿›åˆ¶éªŒè¯å¥–åŠ±çš„Group Relative Policy Optimizationï¼ˆGRPOï¼‰ç›´æ¥ä»åŸºå‡†ç‚¹è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€ç›‘ç£é¢„çƒ­å¯åŠ¨ã€‚æˆ‘ä»¬çš„7Bæ¨¡å‹åœ¨WirelessMathBench-XLä¸Šè¾¾åˆ°äº†39.5%çš„å‡†ç¡®ç‡ï¼Œæ¥è¿‘GPT-4oï¼ˆ40.4%ï¼‰ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ¯”DeepSeek-R1ï¼ˆ671Bï¼Œ57.4%ï¼‰å°‘äº†çº¦100å€ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGRPOè®­ç»ƒåœ¨æ‰€æœ‰æ¨¡å‹è§„æ¨¡ä¸Šå‡ ä¹å°†æ€§èƒ½æé«˜äº†ä¸€å€ï¼ˆ0.5Bæé«˜11%ï¼Œ3Bæé«˜103%ï¼Œ7Bæé«˜81%ï¼‰ï¼Œå¹¶ä¸”æ­£å‘è½¬ç§»åˆ°ä¸€èˆ¬æ•°å­¦åŸºå‡†æµ‹è¯•â€”â€”æˆ‘ä»¬çš„æ¨¡å‹åœ¨MATHã€Minerva-Mathã€OlympiadBenchã€AMCå’ŒAIMEç­‰ä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†8.4åˆ†ï¼Œè€Œæ— éœ€å¯¹è¿™äº›ä»»åŠ¡è¿›è¡Œä»»ä½•è®­ç»ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23219v1">PDF</a> Project Homepage: <a target="_blank" rel="noopener" href="https://lixin.ai/WirelessMathLM">https://lixin.ai/WirelessMathLM</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸€èˆ¬æ•°å­¦æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä¸“ä¸šæŠ€æœ¯æ•°å­¦é¢†åŸŸå­˜åœ¨æ˜¾è‘—ç¼ºé™·ã€‚åœ¨æ— çº¿é€šä¿¡ç­‰éœ€è¦ç²¾ç¡®æ“ä½œä¿¡æ¯ç†è®ºç•Œé™ã€ä¼˜åŒ–çº¦æŸå’Œä¿¡å·å¤„ç†å…¬å¼çš„é—®é¢˜ä¸­ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ä¹Ÿå¾ˆéš¾å®ç°æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºWirelessMathLMï¼Œé€šè¿‡é¢†åŸŸç‰¹å®šçš„å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼Œè¯æ˜ç´§å‡‘æ¨¡å‹ï¼ˆ0.5B-7Bå‚æ•°ï¼‰å¯ä»¥åŒ¹é…æˆ–è¶…è¿‡æ›´å¤§æ¨¡å‹ã€‚å…³é”®è§è§£æ˜¯ï¼Œæ— çº¿é€šä¿¡æ•°å­¦é—®é¢˜å…·æœ‰å¯éªŒè¯çš„æ­£ç¡®æ€§ï¼Œè¿™èƒ½å¤Ÿåœ¨æ²¡æœ‰äººç±»åé¦ˆçš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆçš„å¼ºåŒ–å­¦ä¹ ã€‚æ„å»ºäº†WirelessMathBench-XLï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«4,027ä¸ªé—®é¢˜çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œæ¥è‡ª970ç¯‡è®ºæ–‡ã€‚ä½¿ç”¨Group Relative Policy Optimizationï¼ˆGRPOï¼‰å’ŒäºŒå…ƒéªŒè¯å¥–åŠ±ï¼Œç›´æ¥ä»åŸºæœ¬æ£€æŸ¥ç‚¹è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ— éœ€ç›‘ç£é¢„çƒ­ã€‚7Bæ¨¡å‹çš„å‡†ç¡®æ€§è¾¾åˆ°39.5%ï¼Œæ¥è¿‘GPT-4oï¼ˆ40.4%ï¼‰ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°å¤§çº¦æ˜¯DeepSeek-R1ï¼ˆ671Bï¼Œ57.4%ï¼‰çš„ååˆ†ä¹‹ä¸€ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGRPOè®­ç»ƒå‡ ä¹ä½¿æ‰€æœ‰æ¨¡å‹è§„æ¨¡çš„æ€§èƒ½ç¿»äº†ä¸€ç•ªï¼ˆ0.5B+11%ï¼Œ3B+103%ï¼Œ7B+81%ï¼‰ï¼Œå¹¶å¯¹ä¸€èˆ¬æ•°å­¦åŸºå‡†æµ‹è¯•äº§ç”Ÿäº†ç§¯æçš„è½¬ç§»æ•ˆæœâ€”â€”æˆ‘ä»¬çš„æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†8.4åˆ†ï¼Œæ— éœ€ä»»ä½•é¢å¤–è®­ç»ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸€èˆ¬æ•°å­¦æ¨ç†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä¸“ä¸šæŠ€æœ¯æ•°å­¦é¢†åŸŸå­˜åœ¨ç¼ºé™·ã€‚</li>
<li>æ— çº¿é€šä¿¡ä¸­çš„æ•°å­¦é—®é¢˜å…·æœ‰å¯éªŒè¯çš„æ­£ç¡®æ€§ï¼Œè¿™æœ‰åŠ©äºå¼ºåŒ–å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>WirelessMathLMé€šè¿‡é¢†åŸŸç‰¹å®šçš„å¼ºåŒ–å­¦ä¹ å’Œå¯éªŒè¯å¥–åŠ±ï¼Œå±•ç¤ºç´§å‡‘æ¨¡å‹å¯ä»¥åŒ¹é…æˆ–è¶…è¿‡å¤§å‹æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ„å»ºäº†WirelessMathBench-XLåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æ¥è‡ª970ç¯‡è®ºæ–‡çš„4,027ä¸ªé—®é¢˜ã€‚</li>
<li>ä½¿ç”¨Group Relative Policy Optimization (GRPO) å’ŒäºŒå…ƒéªŒè¯å¥–åŠ±è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ— éœ€ç›‘ç£é¢„çƒ­ã€‚</li>
<li>7Bæ¨¡å‹çš„å‡†ç¡®æ€§æ¥è¿‘GPT-4oï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°è¿œå°‘äºå…¶ä»–æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23219">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.23219v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.23219v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.23219v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Variational-Reasoning-for-Language-Models"><a href="#Variational-Reasoning-for-Language-Models" class="headerlink" title="Variational Reasoning for Language Models"></a>Variational Reasoning for Language Models</h2><p><strong>Authors:Xiangxin Zhou, Zichen Liu, Haonan Wang, Chao Du, Min Lin, Chongxuan Li, Liang Wang, Tianyu Pang</strong></p>
<p>We introduce a variational reasoning framework for language models that treats thinking traces as latent variables and optimizes them through variational inference. Starting from the evidence lower bound (ELBO), we extend it to a multi-trace objective for tighter bounds and propose a forward-KL formulation that stabilizes the training of the variational posterior. We further show that rejection sampling finetuning and binary-reward RL, including GRPO, can be interpreted as local forward-KL objectives, where an implicit weighting by model accuracy naturally arises from the derivation and reveals a previously unnoticed bias toward easier questions. We empirically validate our method on the Qwen 2.5 and Qwen 3 model families across a wide range of reasoning tasks. Overall, our work provides a principled probabilistic perspective that unifies variational inference with RL-style methods and yields stable objectives for improving the reasoning ability of language models. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/sail-sg/variational-reasoning">https://github.com/sail-sg/variational-reasoning</a>.</p>
<blockquote>
<p>æˆ‘ä»¬ä¸ºè¯­è¨€æ¨¡å‹å¼•å…¥äº†ä¸€ä¸ªå˜åˆ†æ¨ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†æ€è€ƒè½¨è¿¹è§†ä¸ºæ½œåœ¨å˜é‡ï¼Œå¹¶é€šè¿‡å˜åˆ†æ¨ç†å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚æˆ‘ä»¬ä»è¯æ®ä¸‹ç•Œï¼ˆELBOï¼‰å‡ºå‘ï¼Œå°†å…¶æ‰©å±•ä¸ºå¤šè½¨è¿¹ç›®æ ‡ä»¥è·å–æ›´ç´§å¯†ç•Œé™ï¼Œå¹¶æå‡ºå‰å‘KLå…¬å¼ä»¥ç¨³å®šå˜åˆ†åéªŒçš„è®­ç»ƒã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œæ‹’ç»é‡‡æ ·å¾®è°ƒå’ŒäºŒå€¼å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼ˆåŒ…æ‹¬GRPOï¼‰å¯ä»¥è§£é‡Šä¸ºå±€éƒ¨å‰å‘KLç›®æ ‡ï¼Œå…¶ä¸­æ¨¡å‹å‡†ç¡®æ€§çš„éšå¼åŠ æƒè‡ªç„¶äº§ç”Ÿäºæ¨å¯¼ä¸­ï¼Œå¹¶æ­ç¤ºäº†ä¹‹å‰æœªè¢«æ³¨æ„åˆ°çš„å¯¹æ›´ç®€å•é—®é¢˜çš„åå‘ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›çš„æ¨ç†ä»»åŠ¡ä¸Šå¯¹Qwen 2.5å’ŒQwen 3æ¨¡å‹å®¶æ—è¿›è¡Œäº†å®è¯éªŒè¯ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ä¸ªæœ‰åŸåˆ™çš„æ¦‚ç‡è§†è§’ï¼Œå°†å˜åˆ†æ¨ç†ä¸RLé£æ ¼çš„æ–¹æ³•ç»Ÿä¸€èµ·æ¥ï¼Œå¹¶äº§ç”Ÿäº†ç¨³å®šçš„ç›®æ ‡ï¼Œä»¥æé«˜è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/sail-sg/variational-reasoning%E3%80%82">https://github.com/sail-sg/variational-reasoningã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22637v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºè¯­è¨€æ¨¡å‹å˜åˆ†æ¨ç†æ¡†æ¶ï¼Œå°†æ€è€ƒè½¨è¿¹è§†ä¸ºæ½œåœ¨å˜é‡å¹¶é€šè¿‡å˜åˆ†æ¨æ–­è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡æ‰©å±•è¯æ®ä¸‹é™ï¼ˆELBOï¼‰åˆ°å¤šè½¨è¿¹ç›®æ ‡ä»¥è·å–æ›´ç´§å¯†ç•Œé™ï¼Œå¹¶æå‡ºå‰å‘KLå…¬å¼æ¥ç¨³å®šå˜åˆ†åéªŒçš„è®­ç»ƒã€‚åŒæ—¶ï¼Œæœ¬æ–‡æ­ç¤ºäº†æ‹’ç»é‡‡æ ·å¾®è°ƒä¸äºŒå…ƒå¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼ˆåŒ…æ‹¬GRPOï¼‰å¯è§£é‡Šä¸ºå±€éƒ¨å‰å‘KLç›®æ ‡ï¼Œå…¶ä¸­æ¨¡å‹å‡†ç¡®æ€§çš„éšå¼æƒé‡è‡ªç„¶äº§ç”Ÿäºæ¨å¯¼ä¸­ï¼Œå¹¶æ­ç¤ºäº†åå‘æ›´ç®€å•é—®é¢˜çš„å…ˆå‰æœªæ³¨æ„åˆ°çš„åè§ã€‚åœ¨Qwen 2.5å’ŒQwen 3æ¨¡å‹å®¶æ—ä¸Šè¿›è¡Œçš„å®è¯éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¹¿æ³›æ¨ç†ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡æä¾›äº†ä¸€ä¸ªæœ‰åŸåˆ™çš„æ¦‚ç‡è§†è§’ï¼Œå°†å˜åˆ†æ¨æ–­ä¸RLé£æ ¼æ–¹æ³•ç»Ÿä¸€èµ·æ¥ï¼Œå¹¶ä¸ºæé«˜è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æä¾›äº†ç¨³å®šçš„ç›®æ ‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥å˜åˆ†æ¨ç†æ¡†æ¶ï¼Œå°†æ€è€ƒè½¨è¿¹è§†ä¸ºæ½œåœ¨å˜é‡ï¼Œé€šè¿‡å˜åˆ†æ¨æ–­ä¼˜åŒ–ã€‚</li>
<li>æ‰©å±•è¯æ®ä¸‹é™ï¼ˆELBOï¼‰è‡³å¤šè½¨è¿¹ç›®æ ‡ï¼Œä»¥è·å–æ›´ç´§å¯†ç•Œé™ã€‚</li>
<li>æå‡ºå‰å‘KLå…¬å¼ï¼Œç¨³å®šå˜åˆ†åéªŒçš„è®­ç»ƒã€‚</li>
<li>æ­ç¤ºæ‹’ç»é‡‡æ ·å¾®è°ƒä¸äºŒå…ƒå¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼ˆåŒ…æ‹¬GRPOï¼‰å¯è§£é‡Šä¸ºå±€éƒ¨å‰å‘KLç›®æ ‡ã€‚</li>
<li>æ¨¡å‹å‡†ç¡®æ€§çš„éšå¼æƒé‡è‡ªç„¶äº§ç”Ÿäºæ¨å¯¼ä¸­ï¼Œæ­ç¤ºåå‘æ›´ç®€å•é—®é¢˜çš„å…ˆå‰æœªæ³¨æ„åˆ°çš„åè§ã€‚</li>
<li>åœ¨å¤šä¸ªæ¨¡å‹å®¶æ—ä¸Šè¿›è¡Œçš„å®è¯éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¹¿æ³›æ¨ç†ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22637">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.22637v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.22637v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.22637v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Tree-Search-for-LLM-Agent-Reinforcement-Learning"><a href="#Tree-Search-for-LLM-Agent-Reinforcement-Learning" class="headerlink" title="Tree Search for LLM Agent Reinforcement Learning"></a>Tree Search for LLM Agent Reinforcement Learning</h2><p><strong>Authors:Yuxiang Ji, Ziyu Ma, Yong Wang, Guanhua Chen, Xiangxiang Chu, Liaoni Wu</strong></p>
<p>Recent advances in reinforcement learning (RL) have significantly enhanced the agentic capabilities of large language models (LLMs). In long-term and multi-turn agent tasks, existing approaches driven solely by outcome rewards often suffer from the problem of sparse supervision. To address the challenge, we propose Tree-based Group Relative Policy Optimization (Tree-GRPO), a grouped agent RL method based on tree search, where each tree node represents the complete agent interaction step. By sharing common prefixes, the tree search sampling increases the number of rollouts achievable within a fixed budget of tokens or tool calls. Moreover, we find that the tree-structured trajectory naturally allows the construction of step-wise process supervised signals even using only the outcome reward. Based on this, Tree-GRPO estimates the grouped relative advantages both on intra-tree and inter-tree levels. Through theoretical analysis, we demonstrate that the objective of intra-tree level group relative policy optimization is equivalent to that of step-level direct preference learning. Experiments across 11 datasets and 3 types of QA tasks demonstrate the superiority of the proposed tree-based RL over the chain-based RL method.</p>
<blockquote>
<p>è¿‘æœŸå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è¿›å±•æå¤§åœ°å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†èƒ½åŠ›ã€‚åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œä»…ç”±ç»“æœå¥–åŠ±é©±åŠ¨ç°æœ‰æ–¹æ³•å¸¸å¸¸é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ ‘æœç´¢çš„æ ‘çŠ¶ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆTree-GRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ†ç»„ä»£ç†RLæ–¹æ³•ï¼Œå…¶ä¸­æ¯ä¸ªæ ‘èŠ‚ç‚¹ä»£è¡¨å®Œæ•´çš„ä»£ç†äº¤äº’æ­¥éª¤ã€‚é€šè¿‡å…±äº«å…¬å…±å‰ç¼€ï¼Œæ ‘æœç´¢é‡‡æ ·å¢åŠ äº†åœ¨å›ºå®šé¢„ç®—çš„ä»¤ç‰Œæˆ–å·¥å…·è°ƒç”¨ä¸­å¯å®ç°çš„å›æ»šæ¬¡æ•°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ ‘çŠ¶è½¨è¿¹ç»“æ„è‡ªç„¶å…è®¸å³ä½¿ä»…ä½¿ç”¨ç»“æœå¥–åŠ±ä¹Ÿèƒ½æ„å»ºé€æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ã€‚åŸºäºæ­¤ï¼ŒTree-GRPOä¼°è®¡äº†æ ‘å†…å’Œæ ‘é—´çº§åˆ«çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚é€šè¿‡ç†è®ºåˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†æ ‘å†…çº§åˆ«åˆ†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„ç›®æ ‡ä¸æ­¥éª¤çº§åˆ«ç›´æ¥åå¥½å­¦ä¹ çš„ç›®æ ‡æ˜¯ä¸€è‡´çš„ã€‚åœ¨11ä¸ªæ•°æ®é›†å’Œ3ç§é—®ç­”ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸åŸºäºé“¾çš„RLæ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„åŸºäºæ ‘çš„RLå…·æœ‰ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.21240v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æœ€æ–°è¿›å±•æå¤§åœ°æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†èƒ½åŠ›ã€‚åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œä»…ç”±ç»“æœå¥–åŠ±é©±åŠ¨çš„æ–¹æ³•å¸¸å¸¸é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ ‘æœç´¢çš„åˆ†ç»„ä»£ç†RLæ–¹æ³•â€”â€”Tree-GRPOã€‚æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨å®Œæ•´çš„ä»£ç†äº¤äº’æ­¥éª¤ã€‚é€šè¿‡å…±äº«å…¬å…±å‰ç¼€ï¼Œæ ‘æœç´¢é‡‡æ ·åœ¨å›ºå®šçš„ä»¤ç‰Œæˆ–å·¥å…·è°ƒç”¨é¢„ç®—å†…å¢åŠ äº†å¯å®ç°æ»šåŠ¨æ¬¡æ•°ã€‚æ­¤å¤–ï¼Œæ ‘ç»“æ„è½¨è¿¹è‡ªç„¶åœ°å…è®¸ä½¿ç”¨ä»…ç»“æœå¥–åŠ±æ„å»ºé€æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ã€‚åŸºäºæ­¤ï¼ŒTree-GRPOä¼°è®¡äº†æ ‘å†…å’Œæ ‘é—´çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œæ ‘å†…çº§åˆ«çš„ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„ç›®æ ‡ä¸æ­¥éª¤çº§åˆ«çš„ç›´æ¥åå¥½å­¦ä¹ çš„ç›®æ ‡ç­‰æ•ˆã€‚åœ¨11ä¸ªæ•°æ®é›†å’Œ3ç§é—®ç­”ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºæ ‘çš„RLä¼˜äºåŸºäºé“¾çš„RLæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†èƒ½åŠ›æ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>åœ¨é•¿æœŸå’Œå¤šè½®ä»£ç†ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ç›‘ç£ç¨€ç–çš„é—®é¢˜ã€‚</li>
<li>Tree-GRPOæ˜¯ä¸€ç§åŸºäºæ ‘æœç´¢çš„åˆ†ç»„ä»£ç†RLæ–¹æ³•ï¼Œé€šè¿‡å…±äº«å…¬å…±å‰ç¼€å¢åŠ æ»šåŠ¨æ¬¡æ•°å¹¶æé«˜ç›‘ç£æ•ˆç‡ã€‚</li>
<li>æ ‘ç»“æ„è½¨è¿¹å¯æ„å»ºé€æ­¥è¿‡ç¨‹ç›‘ç£ä¿¡å·ï¼Œä»…ä½¿ç”¨ç»“æœå¥–åŠ±ã€‚</li>
<li>Tree-GRPOå¯ä¼°è®¡æ ‘å†…å’Œæ ‘é—´çš„åˆ†ç»„ç›¸å¯¹ä¼˜åŠ¿ã€‚</li>
<li>æ ‘å†…çº§åˆ«çš„ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç›®æ ‡ä¸æ­¥éª¤çº§åˆ«çš„ç›´æ¥åå¥½å­¦ä¹ ç›®æ ‡ç­‰æ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.21240">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.21240v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.21240v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.21240v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.21240v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Emergent-Hierarchical-Reasoning-in-LLMs-through-Reinforcement-Learning"><a href="#Emergent-Hierarchical-Reasoning-in-LLMs-through-Reinforcement-Learning" class="headerlink" title="Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning"></a>Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning</h2><p><strong>Authors:Haozhe Wang, Qixin Xu, Che Liu, Junhong Wu, Fangzhen Lin, Wenhu Chen</strong></p>
<p>Reinforcement Learning (RL) has proven highly effective at enhancing the complex reasoning abilities of Large Language Models (LLMs), yet underlying mechanisms driving this success remain largely opaque. Our analysis reveals that puzzling phenomena like <code>aha moments&quot;, </code>length-scalingâ€™â€™ and entropy dynamics are not disparate occurrences but hallmarks of an emergent reasoning hierarchy, akin to the separation of high-level strategic planning from low-level procedural execution in human cognition. We uncover a compelling two-phase dynamic: initially, a model is constrained by procedural correctness and must improve its low-level skills. The learning bottleneck then decisively shifts, with performance gains being driven by the exploration and mastery of high-level strategic planning. This insight exposes a core inefficiency in prevailing RL algorithms like GRPO, which apply optimization pressure agnostically and dilute the learning signal across all tokens. To address this, we propose Hierarchy-Aware Credit Assignment (HICRA), an algorithm that concentrates optimization efforts on high-impact planning tokens. Our extensive experiments validate that HICRA significantly outperforms strong baselines, and offer deep insights into how reasoning advances through the lens of strategic exploration.</p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç»è¯æ˜å¯ä»¥æœ‰æ•ˆæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œä½†é©±åŠ¨è¿™ä¸€æˆåŠŸçš„æ½œåœ¨æœºåˆ¶ä»ç„¶å¤§å¤šä¸æ˜ç¡®ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºï¼Œåƒâ€œå•Šå“ˆæ—¶åˆ»â€ã€â€œé•¿åº¦ç¼©æ”¾â€å’Œç†µåŠ¨åŠ›å­¦ç­‰ä»¤äººå›°æƒ‘çš„ç°è±¡å¹¶ä¸æ˜¯å­¤ç«‹å‘ç”Ÿçš„ï¼Œè€Œæ˜¯æ–°å…´æ¨ç†å±‚æ¬¡çš„æ ‡å¿—ï¼Œç±»ä¼¼äºäººç±»è®¤çŸ¥ä¸­é«˜çº§æˆ˜ç•¥è§„åˆ’ä¸ä½çº§ç¨‹åºæ‰§è¡Œçš„åˆ†ç¦»ã€‚æˆ‘ä»¬å‘ç°äº†å¼•äººæ³¨ç›®çš„ä¸¤é˜¶æ®µåŠ¨æ€è¿‡ç¨‹ï¼šæœ€åˆï¼Œæ¨¡å‹å—åˆ°ç¨‹åºæ­£ç¡®æ€§çš„çº¦æŸï¼Œå¿…é¡»æé«˜å…¶ä½çº§æŠ€èƒ½ã€‚å­¦ä¹ ç“¶é¢ˆéšåå‘ç”Ÿå†³å®šæ€§è½¬ç§»ï¼Œæ€§èƒ½å¢ç›Šæºäºå¯¹é«˜çº§æˆ˜ç•¥è§„åˆ’çš„æ¢ç´¢å’ŒæŒæ¡ã€‚è¿™ç§æ´å¯ŸåŠ›æ­ç¤ºäº†ç°è¡ŒRLç®—æ³•ï¼ˆå¦‚GRPOï¼‰ä¸­çš„æ ¸å¿ƒä½æ•ˆä¹‹å¤„ï¼Œè¿™äº›ç®—æ³•ç›²ç›®åœ°æ–½åŠ ä¼˜åŒ–å‹åŠ›ï¼Œå¹¶åœ¨æ‰€æœ‰ä»¤ç‰Œä¸Šç¨€é‡Šå­¦ä¹ ä¿¡å·ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Hierarchy-Aware Credit Assignment (HICRA)ç®—æ³•ï¼Œè¯¥ç®—æ³•å°†ä¼˜åŒ–å·¥ä½œé›†ä¸­åœ¨é«˜å½±å“åŠ›çš„è§„åˆ’ä»¤ç‰Œä¸Šã€‚æˆ‘ä»¬çš„å¤§é‡å®éªŒéªŒè¯äº†HICRAæ˜¾è‘—ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œå¹¶æ·±å…¥æ´å¯Ÿäº†é€šè¿‡æˆ˜ç•¥æ¢ç´¢è§†è§’æ¨ç†å¦‚ä½•è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.03646v3">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ•ˆæœï¼Œä½†å…¶èƒŒåçš„æœºåˆ¶ä»å¤§å¤šä¸æ˜ç¡®ã€‚æœ¬æ–‡æ­ç¤ºäº†ä¸€äº›ç°è±¡ï¼Œå¦‚â€œå•Šå“ˆæ—¶åˆ»â€ã€â€œé•¿åº¦ç¼©æ”¾â€å’Œç†µåŠ¨åŠ›å­¦ï¼Œå®ƒä»¬å¹¶éå­¤ç«‹å­˜åœ¨ï¼Œè€Œæ˜¯æ–°å…´æ¨ç†å±‚æ¬¡çš„æ ‡å¿—ï¼Œç±»ä¼¼äºäººç±»è®¤çŸ¥ä¸­é«˜çº§æˆ˜ç•¥è§„åˆ’ä¸ä½çº§ç¨‹åºæ‰§è¡Œçš„åˆ†ç¦»ã€‚ç ”ç©¶å‘ç°ä¸€ä¸ªå¼•äººæ³¨ç›®çš„ä¸¤é˜¶æ®µåŠ¨æ€è¿‡ç¨‹ï¼šåˆæœŸï¼Œæ¨¡å‹å—ç¨‹åºæ­£ç¡®æ€§çº¦æŸï¼Œå¿…é¡»æ”¹è¿›ä½çº§æŠ€èƒ½ã€‚å­¦ä¹ ç“¶é¢ˆéšåå‘ç”Ÿå†³å®šæ€§è½¬å˜ï¼Œæ€§èƒ½æå‡æºäºé«˜çº§æˆ˜ç•¥è§„åˆ’çš„æ¢ç´¢ä¸æŒæ¡ã€‚è¿™æ­ç¤ºäº†å½“å‰RLç®—æ³•ï¼ˆå¦‚GRPOï¼‰çš„æ ¸å¿ƒä½æ•ˆä¹‹å¤„ï¼Œå³ä¼˜åŒ–å‹åŠ›çš„åº”ç”¨å…·æœ‰ç›²ç›®æ€§ï¼Œä¿¡å·åˆ†æ•£åœ¨æ‰€æœ‰æ ‡è®°ä¸Šã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å±‚æ¬¡æ„ŸçŸ¥ä¿¡ç”¨åˆ†é…ï¼ˆHICRAï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•é›†ä¸­ä¼˜åŒ–åŠªåŠ›äºé«˜å½±å“è§„åˆ’æ ‡è®°ä¸Šã€‚å¤§é‡å®éªŒéªŒè¯HICRAæ˜¾è‘—ä¼˜äºå¼ºåŠ²åŸºçº¿ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†æˆ˜ç•¥æ¢ç´¢ä¸‹æ¨ç†èƒ½åŠ›å¦‚ä½•æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚</li>
<li>æ¨¡å‹åœ¨å­¦ä¹ çš„åˆå§‹é˜¶æ®µä¸»è¦å…³æ³¨ä½çº§æŠ€èƒ½çš„æ”¹è¿›ã€‚</li>
<li>å­¦ä¹ è¿‡ç¨‹ä¸­ä¼šå‡ºç°ä»ä½çº§åˆ°é«˜çº§çš„æŠ€èƒ½è½¬å˜ï¼Œè¡¨ç°ä¸ºä¸€ç§â€œå±‚æ¬¡æ€§çš„åŠ¨æ€â€ã€‚</li>
<li>å½“å‰å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨ä¼˜åŒ–ä¸Šå­˜åœ¨æ ¸å¿ƒä½æ•ˆé—®é¢˜ï¼Œä¿¡å·åˆ†æ•£åœ¨æ‰€æœ‰æ ‡è®°ä¸Šã€‚</li>
<li>æå‡ºäº†å±‚æ¬¡æ„ŸçŸ¥ä¿¡ç”¨åˆ†é…ï¼ˆHICRAï¼‰ç®—æ³•ï¼Œä¸“æ³¨äºä¼˜åŒ–é«˜å½±å“è§„åˆ’æ ‡è®°ã€‚</li>
<li>HICRAç®—æ³•åœ¨å®éªŒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰å¼ºåŠ²åŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.03646">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.03646v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.03646v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.03646v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2509.03646v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="ARM-Adaptive-Reasoning-Model"><a href="#ARM-Adaptive-Reasoning-Model" class="headerlink" title="ARM: Adaptive Reasoning Model"></a>ARM: Adaptive Reasoning Model</h2><p><strong>Authors:Siye Wu, Jian Xie, Yikai Zhang, Aili Chen, Kai Zhang, Yu Su, Yanghua Xiao</strong></p>
<p>While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on task difficulty. This often leads to the â€œoverthinkingâ€ problem â€“ excessive and unnecessary reasoning â€“ which, although potentially mitigated by human intervention to control the token budget, still fundamentally contradicts the goal of achieving fully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a reasoning model capable of adaptively selecting appropriate reasoning formats based on the task at hand. These formats include three efficient ones â€“ Direct Answer, Short CoT, and Code â€“ as well as a more elaborate format, Long CoT. To train ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy Optimization (GRPO), which addresses the format collapse issue in traditional GRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by an average of 30%, and up to 70%, while maintaining performance comparable to the model that relies solely on Long CoT. Furthermore, not only does it improve inference efficiency through reduced token generation, but it also brings a 2x speedup in training. In addition to the default Adaptive Mode, ARM supports two additional reasoning modes: 1) Instruction-Guided Mode, which allows users to explicitly specify the reasoning format via special tokens â€“ ideal when the appropriate format is known for a batch of tasks. 2) Consensus-Guided Mode, which aggregates the outputs of the three efficient formats and resorts to Long CoT in case of disagreement, prioritizing performance with higher token usage.</p>
<blockquote>
<p>å°½ç®¡å¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬ç¼ºä¹æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´æ¨ç†ä»¤ç‰Œä½¿ç”¨çš„èƒ½åŠ›ã€‚è¿™å¸¸å¸¸ä¼šå¯¼è‡´â€œè¿‡åº¦æ€è€ƒâ€é—®é¢˜â€”â€”å³è¿‡åº¦ä¸”ä¸å¿…è¦çš„æ¨ç†ã€‚è™½ç„¶å¯ä»¥é€šè¿‡äººå·¥å¹²é¢„æ¥æ§åˆ¶ä»¤ç‰Œé¢„ç®—æ¥æ½œåœ¨åœ°ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä½†è¿™ä»ç„¶ä¸å®ç°å®Œå…¨è‡ªä¸»çš„äººå·¥æ™ºèƒ½çš„ç›®æ ‡ç›¸æ‚–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”æ¨ç†æ¨¡å‹ï¼ˆARMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿæ ¹æ®æ‰‹å¤´ä»»åŠ¡è‡ªé€‚åº”é€‰æ‹©é€‚å½“æ¨ç†æ ¼å¼çš„æ¨ç†æ¨¡å‹ã€‚è¿™äº›æ ¼å¼åŒ…æ‹¬ä¸‰ç§é«˜æ•ˆçš„æ ¼å¼â€”â€”ç›´æ¥å›ç­”ã€ç®€çŸ­CoTå’Œä»£ç ï¼Œä»¥åŠä¸€ç§æ›´è¯¦ç»†çš„æ ¼å¼ï¼Œå³é•¿CoTã€‚ä¸ºäº†è®­ç»ƒARMï¼Œæˆ‘ä»¬å¯¹ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰è¿›è¡Œäº†æ”¹è¿›ï¼Œå¼•å…¥äº†Ada-GRPOï¼Œä»¥è§£å†³ä¼ ç»ŸGRPOä¸­çš„æ ¼å¼å´©æºƒé—®é¢˜ã€‚Ada-GRPOä½¿ARMå®ç°äº†é«˜ä»¤ç‰Œæ•ˆç‡ï¼Œå¹³å‡å‡å°‘ä»¤ç‰Œä½¿ç”¨30%ï¼Œæœ€é«˜å¯è¾¾70%ï¼ŒåŒæ—¶ä¿æŒä¸ä»…ä¾èµ–Long CoTçš„æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®ƒä¸ä»…é€šè¿‡å‡å°‘ä»¤ç‰Œç”Ÿæˆæé«˜äº†æ¨ç†æ•ˆç‡ï¼Œè€Œä¸”è¿˜å°†è®­ç»ƒé€Ÿåº¦æé«˜äº†ä¸¤å€ã€‚é™¤äº†é»˜è®¤çš„è‡ªé€‚åº”æ¨¡å¼å¤–ï¼ŒARMè¿˜æ”¯æŒä¸¤ç§é¢å¤–çš„æ¨ç†æ¨¡å¼ï¼š1ï¼‰æŒ‡ä»¤å¼•å¯¼æ¨¡å¼ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡ç‰¹æ®Šä»¤ç‰Œæ˜ç¡®æŒ‡å®šæ¨ç†æ ¼å¼â€”â€”å½“ä¸€æ‰¹ä»»åŠ¡é€‚åˆçš„æ ¼å¼å·²çŸ¥æ—¶ï¼Œè¿™æ˜¯ç†æƒ³çš„é€‰æ‹©ã€‚2ï¼‰å…±è¯†å¼•å¯¼æ¨¡å¼ï¼Œå®ƒèšåˆä¸‰ç§é«˜æ•ˆæ ¼å¼çš„è¾“å‡ºæ¥è¾¾æˆç»“æœå…±è¯†ï¼Œå¹¶åœ¨å‡ºç°åˆ†æ­§æ—¶é‡‡ç”¨é•¿CoTæ ¼å¼ä¼˜å…ˆä¿è¯æ€§èƒ½è¡¨ç°ã€‚è¿™ç§æ¨¡å¼åœ¨é«˜ä»¤ç‰Œä½¿ç”¨çš„æƒ…å†µä¸‹ä¼˜å…ˆè€ƒè™‘æ€§èƒ½è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20258v2">PDF</a> NeurIPS 2025 (Spotlight)</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æŒ‡å‡ºå¤§å‹æ¨ç†æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬ç¼ºä¹æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´æ¨ç†ç¬¦å·ä½¿ç”¨çš„èƒ½åŠ›ã€‚è¿™å¯¼è‡´äº†â€œè¿‡åº¦æ€è€ƒâ€çš„é—®é¢˜ï¼Œå³è¿‡åº¦å’Œä¸å¿…è¦çš„æ¨ç†ã€‚å°½ç®¡å¯ä»¥é€šè¿‡äººä¸ºå¹²é¢„æ¥æ§åˆ¶ç¬¦å·é¢„ç®—æ¥å‡è½»è¿™ä¸€é—®é¢˜ï¼Œä½†è¿™ä¸å®ç°å®Œå…¨è‡ªä¸»çš„äººå·¥æ™ºèƒ½çš„ç›®æ ‡ç›¸çŸ›ç›¾ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†è‡ªé€‚åº”æ¨ç†æ¨¡å‹ï¼ˆARMï¼‰ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡é€‰æ‹©é€‚å½“çš„æ¨ç†æ ¼å¼ã€‚ARMå¼•å…¥äº†Ada-GRPOè®­ç»ƒæ–¹æ³•ï¼Œè§£å†³äº†ä¼ ç»ŸGRPOä¸­çš„æ ¼å¼å´©æºƒé—®é¢˜ï¼Œä½¿ARMå®ç°äº†é«˜ç¬¦å·æ•ˆç‡ï¼Œå¹³å‡å‡å°‘30%çš„ç¬¦å·ï¼Œæœ€é«˜å¯è¾¾70%ï¼ŒåŒæ—¶ä¿æŒä¸ä»…ä¾èµ–Long CoTçš„æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒARMè¿˜æé«˜äº†æ¨ç†æ•ˆç‡ï¼Œå‡å°‘äº†ç¬¦å·ç”Ÿæˆï¼Œå¹¶å®ç°äº†2å€çš„åŸ¹è®­é€Ÿåº¦ã€‚ARMè¿˜æ”¯æŒä¸¤ç§é¢å¤–çš„æ¨ç†æ¨¡å¼ï¼šæŒ‡ä»¤å¼•å¯¼æ¨¡å¼å’Œå…±è¯†å¼•å¯¼æ¨¡å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹æ¨ç†æ¨¡å‹è™½ç„¶èƒ½å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œä½†ç¼ºä¹æ ¹æ®ä»»åŠ¡éš¾åº¦è°ƒæ•´æ¨ç†çš„èƒ½åŠ›ï¼Œå¯¼è‡´â€œè¿‡åº¦æ€è€ƒâ€é—®é¢˜ã€‚</li>
<li>è‡ªé€‚åº”æ¨ç†æ¨¡å‹ï¼ˆARMï¼‰èƒ½æ ¹æ®ä»»åŠ¡é€‰æ‹©é€‚å½“çš„æ¨ç†æ ¼å¼ï¼ŒåŒ…æ‹¬Direct Answerã€Short CoTã€Codeå’ŒLong CoTç­‰ã€‚</li>
<li>Ada-GRPOè®­ç»ƒæ–¹æ³•è§£å†³äº†æ ¼å¼å´©æºƒé—®é¢˜ï¼Œæé«˜äº†ç¬¦å·æ•ˆç‡ï¼Œå¹³å‡å‡å°‘30%çš„ç¬¦å·ä½¿ç”¨ï¼Œæœ€é«˜å¯è¾¾70%ã€‚</li>
<li>Ada-GRPOè®­ç»ƒæ–¹æ³•ä¿æŒäº†ä¸ä»…ä¾èµ–Long CoTçš„æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚</li>
<li>ARMæé«˜äº†æ¨ç†æ•ˆç‡ï¼Œå‡å°‘äº†ç¬¦å·ç”Ÿæˆï¼Œå¹¶å®ç°äº†2å€çš„åŸ¹è®­é€Ÿåº¦ã€‚</li>
<li>ARMæ”¯æŒæŒ‡ä»¤å¼•å¯¼æ¨¡å¼ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡ç‰¹æ®Šç¬¦å·æ˜ç¡®æŒ‡å®šæ¨ç†æ ¼å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.20258v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.20258v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.20258v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Enhancing-Efficiency-and-Exploration-in-Reinforcement-Learning-for-LLMs"><a href="#Enhancing-Efficiency-and-Exploration-in-Reinforcement-Learning-for-LLMs" class="headerlink" title="Enhancing Efficiency and Exploration in Reinforcement Learning for LLMs"></a>Enhancing Efficiency and Exploration in Reinforcement Learning for LLMs</h2><p><strong>Authors:Mengqi Liao, Xiangyu Xi, Ruinian Chen, Jia Leng, Yangen Hu, Ke Zeng, Shuai Liu, Huaiyu Wan</strong></p>
<p>Reasoning large language models (LLMs) excel in complex tasks, which has drawn significant attention to reinforcement learning (RL) for LLMs. However, existing approaches allocate an equal number of rollouts to all questions during the RL process, which is inefficient. This inefficiency stems from the fact that training on simple questions yields limited gains, whereas more rollouts are needed for challenging questions to sample correct answers. Furthermore, while RL improves response precision, it limits the modelâ€™s exploration ability, potentially resulting in a performance cap below that of the base model prior to RL. To address these issues, we propose a mechanism for dynamically allocating rollout budgets based on the difficulty of the problems, enabling more efficient RL training. Additionally, we introduce an adaptive dynamic temperature adjustment strategy to maintain the entropy at a stable level, thereby encouraging sufficient exploration. This enables LLMs to improve response precision while preserving their exploratory ability to uncover potential correct pathways. The code and data is available on: <a target="_blank" rel="noopener" href="https://github.com/LiaoMengqi/E3-RL4LLMs">https://github.com/LiaoMengqi/E3-RL4LLMs</a></p>
<blockquote>
<p>æ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¿™å¼•èµ·äº†äººä»¬å¯¹å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨LLMsä¸­çš„åº”ç”¨çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­çš„æ‰€æœ‰é—®é¢˜ä¸Šéƒ½åˆ†é…äº†ç­‰é‡çš„è¯•éªŒæ¬¡æ•°ï¼Œè¿™æ˜¯ä½æ•ˆçš„ã€‚è¿™ç§ä½æ•ˆæºäºåœ¨ç®€å•é—®é¢˜ä¸Šè¿›è¡Œè®­ç»ƒæ‰€è·å¾—çš„æ”¶ç›Šæœ‰é™ï¼Œè€ŒæŒ‘æˆ˜æ€§é—®é¢˜éœ€è¦æ›´å¤šçš„è¯•éªŒæ¬¡æ•°æ¥é‡‡æ ·æ­£ç¡®ç­”æ¡ˆçš„äº‹å®ã€‚æ­¤å¤–ï¼Œè™½ç„¶å¼ºåŒ–å­¦ä¹ æé«˜äº†å“åº”ç²¾åº¦ï¼Œä½†å®ƒé™åˆ¶äº†æ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä½äºå¼ºåŒ–å­¦ä¹ å‰çš„åŸºå‡†æ¨¡å‹ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé—®é¢˜éš¾åº¦çš„åŠ¨æ€åˆ†é…è¯•éªŒé¢„ç®—çš„æœºåˆ¶ï¼Œä»¥å®ç°æ›´æœ‰æ•ˆçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”åŠ¨æ€æ¸©åº¦è°ƒæ•´ç­–ç•¥ï¼Œä»¥ä¿æŒç†µçš„ç¨³å®šæ°´å¹³ï¼Œä»è€Œé¼“åŠ±è¶³å¤Ÿçš„æ¢ç´¢ã€‚è¿™ä½¿å¾—LLMsèƒ½å¤Ÿåœ¨æé«˜å“åº”ç²¾åº¦çš„åŒæ—¶ï¼Œä¿æŒå…¶æ¢ç´¢èƒ½åŠ›ï¼Œå‘ç°æ½œåœ¨çš„æ­£ç¡®è·¯å¾„ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/LiaoMengqi/E3-RL4LLMs">https://github.com/LiaoMengqi/E3-RL4LLMs</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18573v2">PDF</a> Accept by EMNLP 2025 main</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åº”ç”¨å·²å¼•èµ·å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨æ‰€æœ‰é—®é¢˜ä¸Šéƒ½åˆ†é…äº†ç­‰é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œè¿™å¯¼è‡´äº†æ•ˆç‡é—®é¢˜ã€‚é’ˆå¯¹ç®€å•é—®é¢˜çš„è®­ç»ƒæ”¶ç›Šæœ‰é™ï¼Œè€Œå¤æ‚é—®é¢˜éœ€è¦æ›´å¤šçš„è®­ç»ƒæ ·æœ¬æ‰èƒ½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€åˆ†é…è®­ç»ƒæ ·æœ¬çš„æœºåˆ¶ï¼Œæ ¹æ®é—®é¢˜çš„éš¾åº¦è¿›è¡Œåˆ†é…ä»¥æé«˜æ•ˆç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†è‡ªé€‚åº”åŠ¨æ€æ¸©åº¦è°ƒæ•´ç­–ç•¥æ¥ä¿æŒæ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºå®ç°LLMå“åº”ç²¾åº¦å’Œæ¨¡å‹æ¢ç´¢èƒ½åŠ›çš„å¹³è¡¡ã€‚æ›´å¤šä¿¡æ¯å¯é€šè¿‡è®¿é—®æˆ‘ä»¬çš„GitHubä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/LiaoMengqi/E3-RL4LLMs">https://github.com/LiaoMengqi/E3-RL4LLMs</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨æ˜¯å…³é”®çš„ç ”ç©¶é¢†åŸŸã€‚</li>
<li>å½“å‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨åˆ†é…è®­ç»ƒæ ·æœ¬æ–¹é¢å­˜åœ¨æ•ˆç‡é—®é¢˜ï¼Œéœ€è¦å¯¹ä¸åŒéš¾åº¦çš„é—®é¢˜è¿›è¡ŒåŠ¨æ€åˆ†é…ã€‚</li>
<li>ç®€å•é—®é¢˜çš„è®­ç»ƒæ”¶ç›Šæœ‰é™ï¼Œè€Œå¤æ‚é—®é¢˜éœ€è¦æ›´å¤šçš„è®­ç»ƒæ ·æœ¬ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŠ¨æ€åˆ†é…è®­ç»ƒæ ·æœ¬çš„æœºåˆ¶æ¥æé«˜å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡ã€‚</li>
<li>å¼•å…¥äº†è‡ªé€‚åº”åŠ¨æ€æ¸©åº¦è°ƒæ•´ç­–ç•¥æ¥ä¿æŒæ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶æœ‰åŠ©äºå¹³è¡¡å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å“åº”ç²¾åº¦å’Œæ¨¡å‹æ¢ç´¢èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18573">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_5_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.18573v2/page_5_2.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Auditing-Meta-Cognitive-Hallucinations-in-Reasoning-Large-Language-Models"><a href="#Auditing-Meta-Cognitive-Hallucinations-in-Reasoning-Large-Language-Models" class="headerlink" title="Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models"></a>Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models</h2><p><strong>Authors:Haolang Lu, Yilian Liu, Jingxin Xu, Guoshun Nan, Yuanlong Yu, Zhican Chen, Kun Wang</strong></p>
<p>The development of Reasoning Large Language Models (RLLMs) has significantly improved multi-step reasoning capabilities, but it has also made hallucination problems more frequent and harder to eliminate. While existing approaches mitigate hallucinations through external knowledge integration, model parameter analysis, or self-verification, they often fail to capture how hallucinations emerge and evolve across the reasoning chain. In this work, we study the causality of hallucinations under constrained knowledge domains by auditing the Chain-of-Thought (CoT) trajectory and assessing the modelâ€™s cognitive confidence in potentially erroneous or biased claims. Our analysis reveals that in long-CoT settings, RLLMs can iteratively reinforce biases and errors through flawed reflective reasoning, eventually leading to hallucinated reasoning paths. Surprisingly, even direct interventions at the origin of hallucinations often fail to reverse their effects, as reasoning chains exhibit â€˜chain disloyaltyâ€™ â€“ a resistance to correction and a tendency to preserve flawed logic. Furthermore, we show that existing hallucination detection methods are less reliable and interpretable than previously assumed in complex reasoning scenarios. Unlike methods such as circuit tracing that require access to model internals, our black-box auditing approach supports interpretable long-chain hallucination attribution, offering better generalizability and practical utility. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/Winnie-Lian/AHa_Meta_Cognitive">https://github.com/Winnie-Lian/AHa_Meta_Cognitive</a></p>
<blockquote>
<p>æ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆRLLMsï¼‰çš„å‘å±•æ˜¾è‘—æé«˜äº†å¤šæ­¥æ¨ç†èƒ½åŠ›ï¼Œä½†åŒæ—¶ä¹Ÿä½¿è™šæ„é—®é¢˜æ›´åŠ é¢‘ç¹ä¸”éš¾ä»¥æ¶ˆé™¤ã€‚è™½ç„¶ç°æœ‰æ–¹æ³•é€šè¿‡å¤–éƒ¨çŸ¥è¯†æ•´åˆã€æ¨¡å‹å‚æ•°åˆ†ææˆ–è‡ªæˆ‘éªŒè¯æ¥ç¼“è§£è™šæ„ç°è±¡ï¼Œä½†å®ƒä»¬å¾€å¾€æ— æ³•æ•æ‰è™šæ„å¦‚ä½•åœ¨æ¨ç†é“¾ä¸­æ¶Œç°å’Œæ¼”å˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å®¡æ ¸æ€ç»´é“¾ï¼ˆCoTï¼‰è½¨è¿¹å¹¶è¯„ä¼°æ¨¡å‹å¯¹æ½œåœ¨é”™è¯¯æˆ–åè§ä¸»å¼ çš„è®¤çŸ¥ä¿¡å¿ƒï¼Œæ¥ç ”ç©¶å—æ§çŸ¥è¯†åŸŸä¸‹è™šæ„çš„å› æœå…³ç³»ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºï¼Œåœ¨é•¿CoTè®¾ç½®ä¸­ï¼ŒRLLMså¯ä»¥é€šè¿‡é”™è¯¯çš„åæ€æ¨ç†æ¥è¿­ä»£å¼ºåŒ–åè§å’Œé”™è¯¯ï¼Œæœ€ç»ˆå¯¼è‡´è™šæ„çš„æ¨ç†è·¯å¾„ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå³ä½¿åœ¨è™šæ„çš„èµ·æºå¤„è¿›è¡Œç›´æ¥å¹²é¢„ä¹Ÿå¾€å¾€æ— æ³•é€†è½¬å…¶å½±å“ï¼Œå› ä¸ºæ¨ç†é“¾è¡¨ç°å‡ºâ€œé“¾ä¸å¿ â€â€“å¯¹ä¿®æ­£çš„æŠµæŠ—åŠ›å’Œä¿ç•™é”™è¯¯é€»è¾‘çš„è¶‹åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œåœ¨å¤æ‚çš„æ¨ç†åœºæ™¯ä¸­ï¼Œç°æœ‰çš„è™šæ„æ£€æµ‹æ–¹æ³•æ¯”ä»¥å¾€è®¤ä¸ºçš„è¦å°‘å¯é å’Œå¯è§£é‡Šæ€§ã€‚ä¸åŒäºéœ€è¦è®¿é—®æ¨¡å‹å†…éƒ¨çš„ç”µè·¯è·Ÿè¸ªç­‰æ–¹æ³•ï¼Œæˆ‘ä»¬çš„é»‘ç›’å®¡è®¡æ–¹æ³•æ”¯æŒå¯è§£é‡Šçš„é•¿é“¾è™šæ„å½’å› ï¼Œæä¾›æ›´å¥½çš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/Winnie-Lian/AHa_Meta_Cognitive%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Winnie-Lian/AHa_Meta_Cognitiveæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13143v2">PDF</a> Accepted by NeurIPS 2025 (37 pages)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†å‘å±•è™½æå‡äº†å¤šæ­¥æ¨ç†èƒ½åŠ›ï¼Œä½†ä¹Ÿå¢åŠ äº†å‡ºç°å¹»è§‰é—®é¢˜çš„é¢‘ç‡å’Œæ¶ˆé™¤éš¾åº¦ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡å¤–éƒ¨çŸ¥è¯†æ•´åˆã€æ¨¡å‹å‚æ•°åˆ†ææˆ–è‡ªæˆ‘éªŒè¯æ¥å‡è½»å¹»è§‰é—®é¢˜ï¼Œä½†éš¾ä»¥æ•æ‰å¹»è§‰åœ¨æ¨ç†é“¾ä¸­çš„äº§ç”Ÿå’Œæ¼”å˜è¿‡ç¨‹ã€‚æœ¬ç ”ç©¶é€šè¿‡å®¡è®¡æ€ç»´é“¾è½¨è¿¹å’Œè¯„ä¼°æ¨¡å‹å¯¹æ½œåœ¨é”™è¯¯æˆ–åè§ä¸»å¼ çš„è®¤çŸ¥ä¿¡å¿ƒï¼Œæ¢è®¨å¹»è§‰çš„å› æœå…³ç³»ã€‚åˆ†ææ˜¾ç¤ºï¼Œåœ¨é•¿ç¯‡æ€ç»´é“¾è®¾ç½®ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å¯é€šè¿‡ç¼ºé™·åæ€æ¨ç†ï¼Œä¸æ–­å¼ºåŒ–çš„åè§å’Œé”™è¯¯ï¼Œæœ€ç»ˆå¯¼è‡´å¹»è§‰æ¨ç†è·¯å¾„ã€‚å³ä½¿å¯¹å¹»è§‰äº§ç”Ÿçš„æºå¤´è¿›è¡Œç›´æ¥å¹²é¢„ï¼Œä¹Ÿå¸¸æ— æ³•æ¶ˆé™¤å…¶å½±å“ï¼Œå› ä¸ºæ€ç»´é“¾å±•ç°å‡ºâ€œé“¾ä¸å¿ â€çš„ç‰¹æ€§ï¼Œå³æŠµæŠ—çº æ­£å¹¶å€¾å‘äºç»´æŒé”™è¯¯é€»è¾‘ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸­ä¸å¦‚å…ˆå‰å‡è®¾çš„é‚£ä¹ˆå¯é å’Œå¯è§£é‡Šã€‚æœ¬ç ”ç©¶é‡‡ç”¨çš„é»‘ç›’å®¡è®¡æ–¹æ³•æ”¯æŒå¯è§£é‡Šçš„é•¿é“¾å¹»è§‰å½’å› ï¼Œæä¾›æ›´å¥½çš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ­¥æ¨ç†èƒ½åŠ›æ˜¾è‘—æé«˜ï¼Œä½†å¹»è§‰é—®é¢˜æ›´é¢‘ç¹ä¸”éš¾ä»¥æ¶ˆé™¤ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰å¹»è§‰åœ¨æ¨ç†é“¾ä¸­çš„äº§ç”Ÿå’Œæ¼”å˜ã€‚</li>
<li>ç ”ç©¶é€šè¿‡å®¡è®¡æ€ç»´é“¾è½¨è¿¹å’Œè¯„ä¼°è®¤çŸ¥ä¿¡å¿ƒæ¥æ¢è®¨å¹»è§‰çš„å› æœå…³ç³»ã€‚</li>
<li>åœ¨é•¿ç¯‡æ€ç»´é“¾è®¾ç½®ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ä¼šé€šè¿‡ç¼ºé™·åæ€æ¨ç†å¼ºåŒ–åè§å’Œé”™è¯¯ã€‚</li>
<li>æ€ç»´é“¾å±•ç°å‡ºâ€œé“¾ä¸å¿ â€ç‰¹æ€§ï¼ŒæŠµæŠ—çº æ­£å¹¶ç»´æŒé”™è¯¯é€»è¾‘ã€‚</li>
<li>ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸­å…¶å¯é æ€§å’Œå¯è§£é‡Šæ€§å—é™ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨çš„é»‘ç›’å®¡è®¡æ–¹æ³•æ”¯æŒå¯è§£é‡Šçš„é•¿é“¾å¹»è§‰å½’å› ï¼Œå…·å¤‡æ›´å¥½çš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13143">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.13143v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.13143v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.13143v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.13143v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="DisCO-Reinforcing-Large-Reasoning-Models-with-Discriminative-Constrained-Optimization"><a href="#DisCO-Reinforcing-Large-Reasoning-Models-with-Discriminative-Constrained-Optimization" class="headerlink" title="DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization"></a>DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization</h2><p><strong>Authors:Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang</strong></p>
<p>The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach, yielding long and stable training dynamics; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7% over GRPO and 6% over DAPO across six benchmark tasks for an 1.5B model.</p>
<blockquote>
<p>DeepSeek-R1çš„è¿‘æœŸæˆåŠŸå’Œå¼€æ”¾æ€§ä½¿äººä»¬å¹¿æ³›å…³æ³¨Group Relative Policy Optimization (GRPO)ä½œä¸ºä¸€ç§ç”¨äºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨äºŒå…ƒå¥–åŠ±è®¾ç½®ä¸‹åˆ†æäº†GRPOçš„ç›®æ ‡ï¼Œå¹¶æ­ç¤ºäº†é—®é¢˜éš¾åº¦åå·®çš„å†…åœ¨å±€é™æ€§ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«æ–¹æ³•ä¹‹é—´çš„è”ç³»ã€‚å—è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºåˆ¤åˆ«å­¦ä¹ åŸç†çš„æ–°å‹åˆ¤åˆ«çº¦æŸä¼˜åŒ–ï¼ˆDisCOï¼‰æ¡†æ¶ï¼Œç”¨äºå¼ºåŒ–LRMsã€‚DisCOä¸GRPOåŠå…¶æœ€è¿‘å˜ä½“ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šï¼ˆ1ï¼‰å®ƒç”¨åˆ¤åˆ«ç›®æ ‡æ›¿ä»£äº†ç›¸å¯¹ç»„ç›®æ ‡ï¼Œè¯¥ç›®æ ‡ç”±è¯„åˆ†å‡½æ•°å®šä¹‰ï¼›ï¼ˆ2ï¼‰å®ƒæ”¾å¼ƒäº†åŸºäºå‰ªè¾‘çš„æ›¿ä»£å“ï¼Œè½¬è€Œä½¿ç”¨éå‰ªè¾‘çš„RLæ›¿ä»£ç›®æ ‡ä½œä¸ºè¯„åˆ†å‡½æ•°ï¼›ï¼ˆ3ï¼‰å®ƒé‡‡ç”¨ç®€å•æœ‰æ•ˆçš„çº¦æŸä¼˜åŒ–æ–¹æ³•æ¥å¼ºåˆ¶æ‰§è¡ŒKLæ•£åº¦çº¦æŸã€‚å› æ­¤ï¼ŒDisCOç›¸å¯¹äºGRPOåŠå…¶å˜ä½“å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼šï¼ˆiï¼‰å®ƒé‡‡ç”¨åˆ¤åˆ«ç›®æ ‡ï¼Œå®Œå…¨æ¶ˆé™¤äº†éš¾åº¦åå·®ï¼›ï¼ˆiiï¼‰å®ƒé€šè¿‡éå‰ªè¾‘è¯„åˆ†å‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ–¹æ³•è§£å†³äº†GRPOåŠå…¶å˜ä½“ä¸­çš„ç†µä¸ç¨³å®šé—®é¢˜ï¼Œäº§ç”Ÿäº†é•¿æœŸç¨³å®šçš„è®­ç»ƒåŠ¨æ€ï¼›ï¼ˆiiiï¼‰å®ƒå…è®¸çº³å…¥å…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤§é‡é—®é¢˜çš„ç”Ÿæˆç­”æ¡ˆä¸­è´Ÿç­”æ¡ˆå¤šäºæ­£ç­”æ¡ˆã€‚æˆ‘ä»¬åœ¨å¢å¼ºSFTå¾®è°ƒæ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢çš„å®éªŒè¡¨æ˜ï¼ŒDisCOæ˜¾è‘—ä¼˜äºGRPOåŠå…¶æ”¹è¿›å˜ä½“ï¼ˆå¦‚DAPOï¼‰ï¼Œåœ¨å…­ä¸ªåŸºå‡†ä»»åŠ¡ä¸­å¯¹1.5Bæ¨¡å‹çš„å¹³å‡å¢ç›Šä¸º7%ï¼Œå¯¹DAPOçš„å¹³å‡å¢ç›Šä¸º6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12366v3">PDF</a> Accepted to NeurIPS 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>DeepSeek-R1çš„æˆåŠŸå’Œå¼€æ”¾æ€§ä½¿Group Relative Policy Optimizationï¼ˆGRPOï¼‰ä½œä¸ºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å—åˆ°å¹¿æ³›å…³æ³¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨äºŒè¿›åˆ¶å¥–åŠ±è®¾ç½®ä¸‹åˆ†æäº†GRPOçš„ç›®æ ‡ï¼Œå¹¶æ­ç¤ºäº†é—®é¢˜çº§åˆ«éš¾åº¦åå·®çš„å›ºæœ‰å±€é™æ€§ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«æ–¹æ³•ä¹‹é—´çš„è”ç³»ã€‚å—è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬ä¸ºå¼ºåŒ–LRMså¼•å…¥äº†æ–°çš„Discriminative Constrained Optimizationï¼ˆDisCOï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºåˆ¤åˆ«å­¦ä¹ çš„åŸåˆ™ã€‚DisCOä¸GRPOåŠå…¶æœ€è¿‘å˜ä½“ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šï¼ˆ1ï¼‰å®ƒç”¨åˆ¤åˆ«ç›®æ ‡æ›¿ä»£äº†ç»„ç›¸å¯¹ç›®æ ‡ï¼Œè¯¥ç›®æ ‡ç”±è¯„åˆ†å‡½æ•°å®šä¹‰ï¼›ï¼ˆ2ï¼‰å®ƒæ”¾å¼ƒäº†åŸºäºå‰ªè¾‘çš„æ›¿ä»£å“ï¼Œè½¬è€Œä½¿ç”¨éå‰ªè¾‘RLæ›¿ä»£å“ç›®æ ‡ä½œä¸ºè¯„åˆ†å‡½æ•°ï¼›ï¼ˆ3ï¼‰å®ƒé‡‡ç”¨ç®€å•æœ‰æ•ˆçš„çº¦æŸä¼˜åŒ–æ–¹æ³•æ¥å¼ºåˆ¶æ‰§è¡ŒKLæ•£åº¦çº¦æŸã€‚å› æ­¤ï¼ŒDisCOç›¸å¯¹äºGRPOåŠå…¶å˜ä½“å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼šï¼ˆiï¼‰é€šè¿‡é‡‡ç”¨åˆ¤åˆ«ç›®æ ‡ï¼Œå®ƒå®Œå…¨æ¶ˆé™¤äº†éš¾åº¦åè§ï¼›ï¼ˆiiï¼‰å®ƒè§£å†³äº†GRPOåŠå…¶å˜ä½“ä¸­çš„ç†µä¸ç¨³å®šé—®é¢˜ï¼Œé€šè¿‡ä½¿ç”¨éå‰ªè¾‘è¯„åˆ†å‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ–¹æ³•ï¼Œäº§ç”Ÿé•¿æœŸç¨³å®šçš„è®­ç»ƒåŠ¨æ€ï¼›ï¼ˆiiiï¼‰å®ƒå…è®¸çº³å…¥å…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯æ¥è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤§é‡é—®é¢˜çš„ç”Ÿæˆç­”æ¡ˆä¸­è´Ÿé¢ç­”æ¡ˆå¤šäºæ­£é¢ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œåœ¨æé«˜SFTå¾®è°ƒæ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢ï¼ŒDisCOæ˜¾è‘—ä¼˜äºGRPOåŠå…¶æ”¹è¿›å˜ä½“å¦‚DAPOï¼Œåœ¨å…­ä¸ªåŸºå‡†ä»»åŠ¡ä¸Šï¼ŒDisCOå¯¹GRPOçš„å¹³å‡å¢ç›Šä¸º7ï¼…ï¼Œå¯¹DAPOçš„å¹³å‡å¢ç›Šä¸º6ï¼…ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>DeepSeek-R1çš„æˆåŠŸå¼•é¢†äº†å¯¹Group Relative Policy Optimizationï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å…³æ³¨ï¼Œè¯¥æ–¹æ³•ç”¨äºå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ã€‚</li>
<li>åœ¨äºŒè¿›åˆ¶å¥–åŠ±è®¾ç½®ä¸‹åˆ†æäº†GRPOï¼Œæ­ç¤ºäº†å…¶é—®é¢˜çº§åˆ«éš¾åº¦åå·®çš„å±€é™æ€§ã€‚</li>
<li>å‘ç°äº†GRPOä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸­çš„åˆ¤åˆ«æ–¹æ³•ä¹‹é—´çš„è”ç³»ã€‚</li>
<li>å¼•å…¥äº†æ–°çš„DisCOæ¡†æ¶ï¼Œé‡‡ç”¨åˆ¤åˆ«å­¦ä¹ ç›®æ ‡ï¼Œæ¶ˆé™¤äº†éš¾åº¦åè§ã€‚</li>
<li>DisCOé€šè¿‡éå‰ªè¾‘è¯„åˆ†å‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ–¹æ³•è§£å†³äº†GRPOä¸­çš„ç†µä¸ç¨³å®šé—®é¢˜ï¼Œå®ç°äº†é•¿æœŸç¨³å®šçš„è®­ç»ƒã€‚</li>
<li>DisCOå…è®¸ç»“åˆå…ˆè¿›çš„åˆ¤åˆ«å­¦ä¹ æŠ€æœ¯å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.12366v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.12366v3/page_3_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Kalman-Filter-Enhanced-GRPO-for-Reinforcement-Learning-Based-Language-Model-Reasoning"><a href="#Kalman-Filter-Enhanced-GRPO-for-Reinforcement-Learning-Based-Language-Model-Reasoning" class="headerlink" title="Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning"></a>Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning</h2><p><strong>Authors:Hu Wang, Congbo Ma, Ian Reid, Mohammad Yaqub</strong></p>
<p>The advantage function is a central concept in RL that helps reduce variance in policy gradient estimates. Recently, for language modeling, Group Relative Policy Optimization (GRPO) was proposed to compute the advantage for each output by subtracting the mean reward, as the baseline, for all outputs in the group. However, it can lead to high variance when the reward advantage is inaccurately predicted. In this work, we propose Kalman Filter Enhanced Group Relative Policy Optimization (KRPO) model, by using lightweight Kalman filtering to dynamically estimate the latent reward baseline and uncertainty. This filtering technique replaces the naive group mean, enabling more adaptive advantage normalization. Our method does not require additional learned parameters over GRPO. This approach offers a simple yet effective way to incorporate multiple outputs of GRPO into advantage estimation, improving policy optimization in settings where highly dynamic reward signals are difficult to model for language models. Through the accuracies and rewards obtained from math question answering and reasoning, we show that using a more adaptive advantage estimation model, KRPO can improve the stability and performance of GRPO. The code is available at <a target="_blank" rel="noopener" href="https://github.com/billhhh/KRPO_LLMs_RL">https://github.com/billhhh/KRPO_LLMs_RL</a>.</p>
<blockquote>
<p>ä¼˜åŠ¿å‡½æ•°æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼Œæœ‰åŠ©äºå‡å°‘ç­–ç•¥æ¢¯åº¦ä¼°è®¡ä¸­çš„æ–¹å·®ã€‚æœ€è¿‘ï¼Œå¯¹äºè¯­è¨€å»ºæ¨¡ï¼Œæå‡ºäº†Group Relative Policy Optimization (GRPO)ï¼Œé€šè¿‡å‡å»æ‰€æœ‰è¾“å‡ºç»„çš„å¹³å‡å¥–åŠ±ä½œä¸ºåŸºå‡†å€¼æ¥è®¡ç®—æ¯ä¸ªè¾“å‡ºçš„ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå½“å¥–åŠ±ä¼˜åŠ¿é¢„æµ‹ä¸å‡†ç¡®æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¾ƒé«˜çš„æ–¹å·®ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¡å°”æ›¼æ»¤æ³¢å¢å¼ºçš„Group Relative Policy Optimizationï¼ˆKRPOï¼‰æ¨¡å‹ï¼Œé€šè¿‡ä½¿ç”¨è½»é‡çº§çš„å¡å°”æ›¼æ»¤æ³¢æ¥åŠ¨æ€ä¼°è®¡æ½œåœ¨å¥–åŠ±åŸºå‡†å€¼å’Œä¸ç¡®å®šæ€§ã€‚è¿™ç§æ»¤æ³¢æŠ€æœ¯æ›¿æ¢äº†ç®€å•çš„ç»„å‡å€¼ï¼Œå®ç°äº†æ›´è‡ªé€‚åº”çš„ä¼˜åŠ¿å½’ä¸€åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦åœ¨GRPOçš„åŸºç¡€ä¸Šå¢åŠ é¢å¤–çš„å­¦ä¹ å‚æ•°ã€‚è¿™ç§æ–¹æ³•ä¸ºå°†GRPOçš„å¤šä¸ªè¾“å‡ºçº³å…¥ä¼˜åŠ¿ä¼°è®¡æä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯­è¨€æ¨¡å‹ä¸­éš¾ä»¥å»ºæ¨¡é«˜åº¦åŠ¨æ€çš„å¥–åŠ±ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œæ”¹å–„äº†ç­–ç•¥ä¼˜åŒ–ã€‚é€šè¿‡æ•°å­¦é—®é¢˜çš„å›ç­”å’Œæ¨ç†æ‰€è·å¾—çš„å‡†ç¡®æ€§å’Œå¥–åŠ±ï¼Œæˆ‘ä»¬è¯æ˜äº†ä½¿ç”¨æ›´è‡ªé€‚åº”çš„ä¼˜åŠ¿ä¼°è®¡æ¨¡å‹KRPOå¯ä»¥æé«˜GRPOçš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/billhhh/KRPO_LLMs_RL%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/billhhh/KRPO_LLMs_RLä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.07527v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¼ºåŒ–å­¦ä¹ ä¸­çš„ä¼˜åŠ¿å‡½æ•°æ¦‚å¿µï¼Œæå‡ºäº†Kalmanæ»¤æ³¢å¢å¼ºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆKRPOï¼‰æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä½¿ç”¨è½»é‡çº§Kalmanæ»¤æ³¢å™¨åŠ¨æ€ä¼°è®¡æ½œåœ¨å¥–åŠ±åŸºå‡†å€¼å’Œä¸ç¡®å®šæ€§ï¼Œæ”¹è¿›äº†è¯­è¨€å»ºæ¨¡ä¸­çš„ç­–ç•¥ä¼˜åŒ–ã€‚é€šè¿‡æ•°å­¦é—®ç­”å’Œæ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§å’Œå¥–åŠ±æ¥è¯æ˜ï¼ŒKRPOèƒ½æé«˜GRPOçš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼˜åŠ¿å‡½æ•°åœ¨ç­–ç•¥æ¢¯åº¦ä¼°è®¡ä¸­ç”¨äºå‡å°‘æ–¹å·®ã€‚</li>
<li>Group Relative Policy Optimization (GRPO)ç”¨äºè®¡ç®—è¯­è¨€æ¨¡å‹çš„è¾“å‡ºä¼˜åŠ¿ã€‚</li>
<li>GRPOåœ¨è®¡ç®—ä¼˜åŠ¿æ—¶é‡‡ç”¨ç»„å‡å€¼ä½œä¸ºåŸºçº¿ï¼Œä½†å¯èƒ½å¯¼è‡´é«˜æ–¹å·®ã€‚</li>
<li>KRPOæ¨¡å‹ä½¿ç”¨Kalmanæ»¤æ³¢å™¨åŠ¨æ€ä¼°è®¡å¥–åŠ±åŸºçº¿å’Œä¸ç¡®å®šæ€§ï¼Œæ”¹è¿›äº†ä¼˜åŠ¿ä¼°è®¡ã€‚</li>
<li>KRPOæ–¹æ³•ä¸éœ€è¦é¢å¤–å­¦ä¹ å‚æ•°ï¼Œç®€åŒ–äº†ä¼˜åŠ¿ä¼°ç®—è¿‡ç¨‹ã€‚</li>
<li>KRPOæé«˜äº†GRPOåœ¨åŠ¨æ€å¥–åŠ±ä¿¡å·éš¾ä»¥å»ºæ¨¡æƒ…å†µä¸‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.07527">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.07527v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.07527v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.07527v3/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2505.07527v3/page_5_1.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="MrGuard-A-Multilingual-Reasoning-Guardrail-for-Universal-LLM-Safety"><a href="#MrGuard-A-Multilingual-Reasoning-Guardrail-for-Universal-LLM-Safety" class="headerlink" title="MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety"></a>MrGuard: A Multilingual Reasoning Guardrail for Universal LLM Safety</h2><p><strong>Authors:Yahan Yang, Soham Dan, Shuo Li, Dan Roth, Insup Lee</strong></p>
<p>Large Language Models (LLMs) are susceptible to adversarial attacks such as jailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability is exacerbated in multilingual settings, where multilingual safety-aligned data is often limited. Thus, developing a guardrail capable of detecting and filtering unsafe content across diverse languages is critical for deploying LLMs in real-world applications. In this work, we introduce a multilingual guardrail with reasoning for prompt classification. Our method consists of: (1) synthetic multilingual data generation incorporating culturally and linguistically nuanced variants, (2) supervised fine-tuning, and (3) a curriculum-based Group Relative Policy Optimization (GRPO) framework that further improves performance. Experimental results demonstrate that our multilingual guardrail, MrGuard, consistently outperforms recent baselines across both in-domain and out-of-domain languages by more than 15%. We also evaluate MrGuardâ€™s robustness to multilingual variations, such as code-switching and low-resource language distractors in the prompt, and demonstrate that it preserves safety judgments under these challenging conditions. The multilingual reasoning capability of our guardrail enables it to generate explanations, which are particularly useful for understanding language-specific risks and ambiguities in multilingual content moderation.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“å—åˆ°å¦‚è¶Šç‹±ç­‰å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼Œä»è€Œå¼•å‘æœ‰å®³æˆ–ä¸å®‰å…¨çš„è¡Œä¸ºã€‚åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­ï¼Œç”±äºå¤šè¯­è¨€å®‰å…¨å¯¹é½æ•°æ®é€šå¸¸æœ‰é™ï¼Œè¿™ä¸€æ¼æ´æ›´åŠ ä¸¥é‡ã€‚å› æ­¤ï¼Œå¼€å‘ä¸€ç§èƒ½å¤Ÿåœ¨å¤šç§è¯­è¨€ä¸­æ£€æµ‹å’Œè¿‡æ»¤ä¸å®‰å…¨å†…å®¹çš„æŠ¤æ ï¼Œå¯¹äºåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­éƒ¨ç½²LLMè‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…·æœ‰æç¤ºåˆ†ç±»æ¨ç†çš„å¤šè¯­è¨€æŠ¤æ ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰åˆæˆå¤šè¯­è¨€æ•°æ®ç”Ÿæˆï¼Œèå…¥æ–‡åŒ–å’Œè¯­è¨€ä¸Šçš„ç»†å¾®å·®åˆ«ï¼Œï¼ˆ2ï¼‰ç›‘ç£å¾®è°ƒï¼Œä»¥åŠï¼ˆ3ï¼‰åŸºäºè¯¾ç¨‹çš„ç›¸å¯¹ç»„ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¡†æ¶ï¼Œè¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¤šè¯­è¨€æŠ¤æ MrGuardåœ¨åŸŸå†…å’ŒåŸŸå¤–è¯­è¨€ä¸Šçš„è¡¨ç°å‡è¶…è¿‡è¿‘æœŸåŸºçº¿15%ä»¥ä¸Šã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†MrGuardåœ¨å¤šè¯­è¨€å˜åŒ–ä¸‹çš„ç¨³å¥æ€§ï¼Œå¦‚æç¤ºä¸­çš„ä»£ç åˆ‡æ¢å’Œä½èµ„æºè¯­è¨€å¹²æ‰°é¡¹ï¼Œå¹¶è¯æ˜å®ƒåœ¨è¿™äº›å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹èƒ½ä¿æŒå®‰å…¨åˆ¤æ–­ã€‚æˆ‘ä»¬çš„æŠ¤æ å…·å¤‡å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿç”Ÿæˆè§£é‡Šï¼Œè¿™å¯¹äºç†è§£å¤šè¯­è¨€å†…å®¹å®¡æ ¸ä¸­çš„è¯­è¨€ç‰¹å®šé£é™©å’Œæ¨¡ç³Šæ€§ç‰¹åˆ«æœ‰ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15241v3">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“å—åˆ°å¦‚â€œè¶Šç‹±â€ä¹‹ç±»çš„å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼Œä»è€Œå¼•å‘æœ‰å®³æˆ–ä¸å®‰å…¨çš„è¡Œä¸ºã€‚åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­ï¼Œè¿™ç§è„†å¼±æ€§å› å¤šè¯­è¨€å®‰å…¨å¯¹é½æ•°æ®çš„ç¼ºä¹è€ŒåŠ å‰§ã€‚å› æ­¤ï¼Œå¼€å‘ä¸€ç§èƒ½å¤Ÿåœ¨å¤šç§è¯­è¨€ä¹‹é—´æ£€æµ‹å’Œè¿‡æ»¤ä¸å®‰å…¨å†…å®¹çš„é˜²æŠ¤æ ï¼Œå¯¹äºåœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²LLMsè‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§é…å¤‡æ¨ç†åŠŸèƒ½çš„è·¨è¯­è¨€é˜²æŠ¤æ ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰åˆæˆå¤šè¯­è¨€æ•°æ®ç”Ÿæˆï¼Œæ¶µç›–æ–‡åŒ–å’Œè¯­è¨€ç»†å¾®å·®åˆ«ï¼Œï¼ˆ2ï¼‰é€šè¿‡ç›‘ç£å¾®è°ƒè¿›è¡Œæ”¹è¿›ï¼Œï¼ˆ3ï¼‰åŸºäºè¯¾ç¨‹çš„ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¡†æ¶è¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¤šè¯­è¨€é˜²æŠ¤æ MrGuardåœ¨åŸŸå†…å’ŒåŸŸå¤–è¯­è¨€ä¸Šçš„è¡¨ç°å‡ä¼˜äºæœ€æ–°åŸºçº¿è¶…è¿‡15%ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†MrGuardåœ¨å¤šè¯­è¨€å˜åŒ–ä¸‹çš„ç¨³å¥æ€§ï¼Œå¦‚ä»£ç åˆ‡æ¢å’Œä½èµ„æºè¯­è¨€å¹²æ‰°æç¤ºï¼Œå¹¶è¯æ˜å®ƒåœ¨è¿™äº›å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ä»èƒ½ç»´æŒå®‰å…¨åˆ¤æ–­ã€‚æˆ‘ä»¬çš„é˜²æŠ¤æ å…·å¤‡å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿç”Ÿæˆè§£é‡Šï¼Œå¯¹äºç†è§£å¤šè¯­è¨€å†…å®¹å®¡æŸ¥ä¸­çš„è¯­è¨€ç‰¹å®šé£é™©å’Œæ­§ä¹‰ç‰¹åˆ«æœ‰ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­ã€‚</li>
<li>å¼€å‘ä¸€ç§å¤šè¯­è¨€é˜²æŠ¤æ å¯¹äºåœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²LLMsè‡³å…³é‡è¦ã€‚</li>
<li>æå‡ºçš„é˜²æŠ¤æ æ–¹æ³•åŒ…æ‹¬åˆæˆå¤šè¯­è¨€æ•°æ®ç”Ÿæˆã€ç›‘ç£å¾®è°ƒä»¥åŠåŸºäºè¯¾ç¨‹çš„ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¡†æ¶ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥é˜²æŠ¤æ åœ¨åŸŸå†…å’ŒåŸŸå¤–è¯­è¨€çš„æ€§èƒ½å‡è¶…è¿‡ç°æœ‰æ–¹æ³•ï¼Œä¸”å…·å¤‡ç¨³å¥æ€§ã€‚</li>
<li>é˜²æŠ¤æ çš„å¤šè¯­è¨€æ¨ç†èƒ½åŠ›èƒ½å¤Ÿç”Ÿæˆè§£é‡Šï¼Œæœ‰åŠ©äºç†è§£å¤šè¯­è¨€å†…å®¹å®¡æŸ¥ä¸­çš„ç‰¹å®šé£é™©å’Œæ­§ä¹‰ã€‚</li>
<li>é˜²æŠ¤æ åœ¨åº”å¯¹å¤šè¯­è¨€å˜åŒ–ï¼Œå¦‚ä»£ç åˆ‡æ¢å’Œä½èµ„æºè¯­è¨€å¹²æ‰°æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15241">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.15241v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.15241v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.15241v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.15241v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="LogicTree-Structured-Proof-Exploration-for-Coherent-and-Rigorous-Logical-Reasoning-with-Large-Language-Models"><a href="#LogicTree-Structured-Proof-Exploration-for-Coherent-and-Rigorous-Logical-Reasoning-with-Large-Language-Models" class="headerlink" title="LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models"></a>LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models</h2><p><strong>Authors:Kang He, Kaushik Roy</strong></p>
<p>Large language models (LLMs) have achieved remarkable multi-step reasoning capabilities across various domains. However, LLMs still face distinct challenges in complex logical reasoning, as (1) proof-finding requires systematic exploration and the maintenance of logical coherence and (2) searching the right combination of premises at each reasoning step is inherently challenging in tasks with large premise space. To address this, we propose LogicTree, an inference-time modular framework employing algorithm-guided search to automate structured proof exploration and ensure logical coherence. Advancing beyond tree-of-thought (ToT), we incorporate caching mechanism into LogicTree to enable effective utilization of historical knowledge, preventing reasoning stagnation and minimizing redundancy. Furthermore, we address the combinatorial complexity of premise search by decomposing it into a linear process. The refined premise selection restricts subsequent inference to at most one derivation per step, enhancing reasoning granularity and enforcing strict step-by-step reasoning. Additionally, we introduce two LLM-free heuristics for premise prioritization, enabling strategic proof search. Experimental results on five datasets demonstrate that LogicTree optimally scales inference-time computation to achieve higher proof accuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6% and 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o outperforms o3-mini by 7.6% on average.</p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²åœ¨å¤šä¸ªé¢†åŸŸå±•ç°å‡ºæ˜¾è‘—çš„å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨å¤æ‚çš„é€»è¾‘æ¨ç†æ–¹é¢ï¼ŒLLMä»é¢ä¸´ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚å› ä¸ºï¼ˆ1ï¼‰è¯æ˜å¯»æ‰¾éœ€è¦ç³»ç»Ÿçš„æ¢ç´¢å’Œç»´æŒé€»è¾‘è¿è´¯æ€§ï¼›ï¼ˆ2ï¼‰åœ¨å…·æœ‰å¤§é‡å‰æç©ºé—´çš„ä»»åŠ¡ä¸­ï¼Œæœç´¢æ¯ä¸€æ­¥æ¨ç†çš„æ­£ç¡®å‰æç»„åˆæœ¬è´¨ä¸Šæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†LogicTreeï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨ç†æ—¶é—´æ¨¡å—åŒ–æ¡†æ¶ï¼Œé‡‡ç”¨ç®—æ³•æŒ‡å¯¼çš„æœç´¢æ¥è‡ªåŠ¨æ¢ç´¢ç»“æ„åŒ–è¯æ˜å¹¶ç¡®ä¿é€»è¾‘è¿è´¯æ€§ã€‚è¶…è¶Šæ€ç»´æ ‘ï¼ˆToTï¼‰ï¼Œæˆ‘ä»¬åœ¨LogicTreeä¸­å¼•å…¥äº†ç¼“å­˜æœºåˆ¶ï¼Œä»¥æœ‰æ•ˆåˆ©ç”¨å†å²çŸ¥è¯†ï¼Œé˜²æ­¢æ¨ç†åœæ»å¹¶å°½é‡å‡å°‘å†—ä½™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†å‰ææœç´¢çš„ç»„åˆå¤æ‚æ€§åˆ†è§£ä¸ºçº¿æ€§è¿‡ç¨‹æ¥è§£å†³ã€‚ç²¾ç»†çš„å‰æé€‰æ‹©å°†åç»­æ¨ç†é™åˆ¶ä¸ºæ¯ä¸€æ­¥æœ€å¤šä¸€ä¸ªæ¨å¯¼ï¼Œæé«˜äº†æ¨ç†çš„ç²’åº¦å¹¶å®æ–½äº†ä¸¥æ ¼çš„é€æ­¥æ¨ç†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§æ— éœ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯å‘å¼æ–¹æ³•æ¥ä¼˜å…ˆå¤„ç†å‰æï¼Œä»¥å®ç°æˆ˜ç•¥æ€§çš„è¯æ˜æœç´¢ã€‚åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒLogicTreeèƒ½å¤Ÿæœ€ä¼˜åœ°æ‰©å±•æ¨ç†æ—¶é—´çš„è®¡ç®—ï¼Œæé«˜è¯æ˜å‡†ç¡®æ€§ï¼Œè¶…è¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰å’ŒToTï¼Œåœ¨GPT-4oä¸Šçš„å¹³å‡å¢ç›Šä¸º23.6%å’Œ12.5%ã€‚æ­¤å¤–ï¼Œåœ¨LogicTreeå†…éƒ¨ï¼ŒGPT-4oçš„å¹³å‡è¡¨ç°ä¼˜äºo3-mini 7.6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.14089v2">PDF</a> EMNLP 2025 Main Conference</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ­¥æ¨ç†é¢†åŸŸå±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚é€»è¾‘æ¨ç†æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†LogicTreeæ¡†æ¶ï¼Œé€šè¿‡ç®—æ³•å¼•å¯¼æœç´¢æ¥è‡ªåŠ¨åŒ–ç»“æ„è¯æ˜æ¢ç´¢å¹¶ç¡®ä¿é€»è¾‘è¿è´¯æ€§ã€‚LogicTreeå¼•å…¥ç¼“å­˜æœºåˆ¶ï¼Œé¿å…æ¨ç†åœæ»å’Œå†—ä½™ï¼Œå¹¶åˆ†è§£å¤æ‚çš„å‰ææœç´¢ä¸ºçº¿æ€§è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLogicTreeåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„è¯æ˜å‡†ç¡®æ€§ï¼Œç›¸å¯¹äºé“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’Œæ€ç»´æ ‘ï¼ˆToTï¼‰å¹³å‡æå‡äº†23.6%å’Œ12.5%ã€‚GPT-4oåœ¨LogicTreeå†…çš„è¡¨ç°ä¼˜äºo3-miniï¼Œå¹³å‡æé«˜äº†7.6%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ­¥æ¨ç†ä¸­è¡¨ç°å“è¶Šï¼Œä½†åœ¨å¤æ‚é€»è¾‘æ¨ç†æ–¹é¢ä»æœ‰æŒ‘æˆ˜ã€‚</li>
<li>LogicTreeæ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–ç»“æ„è¯æ˜æ¢ç´¢çš„æ¨ç†æ—¶é—´æ¨¡å—åŒ–æ¡†æ¶ï¼Œç¡®ä¿é€»è¾‘è¿è´¯æ€§ã€‚</li>
<li>LogicTreeé€šè¿‡å¼•å…¥ç¼“å­˜æœºåˆ¶ï¼Œé¿å…æ¨ç†åœæ»å’Œå†—ä½™ã€‚</li>
<li>LogicTreeå°†å¤æ‚çš„å‰ææœç´¢åˆ†è§£ä¸ºçº¿æ€§è¿‡ç¨‹ï¼Œæé«˜äº†æ¨ç†çš„ç²¾ç»†åº¦ã€‚</li>
<li>LogicTreeæé«˜äº†è¯æ˜å‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºå…¶ä»–æ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
<li>GPT-4oåœ¨LogicTreeæ¡†æ¶å†…çš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.14089">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.14089v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.14089v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.14089v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="GRPO-LEAD-A-Difficulty-Aware-Reinforcement-Learning-Approach-for-Concise-Mathematical-Reasoning-in-Language-Models"><a href="#GRPO-LEAD-A-Difficulty-Aware-Reinforcement-Learning-Approach-for-Concise-Mathematical-Reasoning-in-Language-Models" class="headerlink" title="GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models"></a>GRPO-LEAD: A Difficulty-Aware Reinforcement Learning Approach for Concise Mathematical Reasoning in Language Models</h2><p><strong>Authors:Jixiao Zhang, Chunsheng Zuo</strong></p>
<p>Group Relative Policy Optimization (GRPO), which is widely adopted by R1-like reasoning models, has advanced mathematical reasoning. Nevertheless, GRPO faces challenges in reward sparsity, verbosity, and inadequate focus on problem difficulty. We propose GRPO-LEAD, enhancing GRPO with: (1) length-regularized rewards to encourage conciseness while maintaining accuracy; (2) explicit penalties for incorrect solutions to improve model precision; and (3) difficulty-aware advantage reweighting for robust generalization on challenging problems. Comprehensive evaluations demonstrate that GRPO-LEAD significantly improves reasoning accuracy, conciseness, and efficiency. Our approach achieves state-of-the-art performance for 14B-scale models, underscoring the synergy of our methods with appropriate model scale and high-quality data. Our source code, generated dataset, and models are available at <a target="_blank" rel="noopener" href="https://github.com/aeroplanepaper/GRPO-LEAD">https://github.com/aeroplanepaper/GRPO-LEAD</a>.</p>
<blockquote>
<p>é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰è¢«R1ç±»æ¨ç†æ¨¡å‹å¹¿æ³›åº”ç”¨ï¼Œå…·æœ‰å…ˆè¿›çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒGRPOé¢ä¸´å¥–åŠ±ç¨€ç–ã€å†—ä½™ä»¥åŠç¼ºä¹å¯¹é—®é¢˜éš¾åº¦å…³æ³¨åº¦çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºGRPO-LEADï¼Œé€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢å¢å¼ºGRPOï¼šï¼ˆ1ï¼‰é•¿åº¦æ­£åˆ™åŒ–å¥–åŠ±ï¼Œåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶é¼“åŠ±ç®€æ´æ€§ï¼›ï¼ˆ2ï¼‰å¯¹é”™è¯¯è§£å†³æ–¹æ¡ˆçš„æ˜ç¡®æƒ©ç½šï¼Œä»¥æé«˜æ¨¡å‹ç²¾åº¦ï¼›ï¼ˆ3ï¼‰éš¾åº¦æ„ŸçŸ¥ä¼˜åŠ¿é‡æ–°åŠ æƒï¼Œä»¥å®ç°åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ä¸Šçš„ç¨³å¥æ³›åŒ–ã€‚å…¨é¢è¯„ä¼°è¡¨æ˜ï¼ŒGRPO-LEADåœ¨æ¨ç†å‡†ç¡®æ€§ã€ç®€æ´æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸º14Bè§„æ¨¡æ¨¡å‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•ä¸é€‚å½“æ¨¡å‹è§„æ¨¡å’Œé«˜è´¨é‡æ•°æ®çš„ååŒä½œç”¨ã€‚æˆ‘ä»¬çš„æºä»£ç ã€ç”Ÿæˆæ•°æ®é›†å’Œæ¨¡å‹å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/aeroplanepaper/GRPO-LEAD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/aeroplanepaper/GRPO-LEADè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.09696v2">PDF</a> Accepted to EMNLP 2025 (Main)</p>
<p><strong>Summary</strong></p>
<p>GRPO-LEADæ˜¯æ”¹è¿›çš„Group Relative Policy Optimizationï¼ˆGRPOï¼‰ç­–ç•¥ï¼Œé€‚ç”¨äºR1ç±»ä¼¼çš„æ¨ç†æ¨¡å‹ï¼Œå¯æå‡æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚å®ƒè§£å†³äº†å¥–åŠ±ç¨€ç–ã€å†—é•¿å’Œç¼ºä¹é—®é¢˜éš¾åº¦å…³æ³¨çš„é—®é¢˜ã€‚GRPO-LEADé€šè¿‡ä»¥ä¸‹æ–¹å¼å¢å¼ºGRPOï¼š1ï¼‰é•¿åº¦æ­£åˆ™åŒ–å¥–åŠ±ï¼Œé¼“åŠ±å‡†ç¡®æ€§åŒæ—¶ä¿æŒç®€æ´æ€§ï¼›2ï¼‰å¯¹é”™è¯¯è§£å†³æ–¹æ¡ˆçš„æ˜ç¡®æƒ©ç½šï¼Œæé«˜æ¨¡å‹ç²¾åº¦ï¼›3ï¼‰éš¾åº¦æ„ŸçŸ¥ä¼˜åŠ¿é‡æ–°åŠ æƒï¼Œä»¥åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ä¸Šå®ç°ç¨³å¥æ³›åŒ–ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒGRPO-LEADåœ¨å‡†ç¡®æ€§ã€ç®€æ´æ€§å’Œæ•ˆç‡æ–¹é¢æ˜¾è‘—æ”¹å–„ï¼Œä¸”å¯¹å¤§è§„æ¨¡æ¨¡å‹æ€§èƒ½å…·æœ‰å…ˆè¿›æ€§ã€‚å¼€æºä»£ç å’Œæ¨¡å‹åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/aeroplanepaper/GRPO-LEAD%E3%80%82">https://github.com/aeroplanepaper/GRPO-LEADã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GRPOåœ¨å¹¿æ³›é€‚ç”¨çš„è¿‡ç¨‹ä¸­ï¼Œæœ‰æ½œåœ¨çš„å¥–åŠ±ç¨€ç–å’Œå†—é•¿çš„é—®é¢˜éœ€è¦è§£å†³ã€‚æ–°ç­–ç•¥GRPO-LEADå¢åŠ äº†å¯¹æ–°æŒ‘æˆ˜çš„å¤„ç†æœºåˆ¶æ¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>GRPO-LEADé€šè¿‡å¼•å…¥é•¿åº¦æ­£åˆ™åŒ–å¥–åŠ±æ¥é¼“åŠ±ç®€æ´æ€§å¹¶ä¿æŒå‡†ç¡®æ€§ã€‚è¿™ç§ç­–ç•¥æœ‰åŠ©äºæ¨¡å‹åœ¨è§£ç­”é—®é¢˜æ—¶é¿å…å†—ä½™ä¿¡æ¯ã€‚</li>
<li>ä¸ºäº†æé«˜æ¨¡å‹çš„ç²¾ç¡®åº¦å’Œçº æ­£èƒ½åŠ›ï¼ŒGRPO-LEADåŠ å…¥äº†å¯¹é”™è¯¯è§£å†³æ–¹æ¡ˆçš„æ˜¾æ€§æƒ©ç½šã€‚è¿™å¯¹äºæ”¹è¿›æ¨¡å‹åˆ¤æ–­æ­£ç¡®æ€§ååˆ†å¿…è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.09696">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.09696v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.09696v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2504.09696v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Reason-RFT-Reinforcement-Fine-Tuning-for-Visual-Reasoning-of-Vision-Language-Models"><a href="#Reason-RFT-Reinforcement-Fine-Tuning-for-Visual-Reasoning-of-Vision-Language-Models" class="headerlink" title="Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning of Vision Language Models"></a>Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning of Vision Language Models</h2><p><strong>Authors:Huajie Tan, Yuheng Ji, Xiaoshuai Hao, Xiansheng Chen, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang</strong></p>
<p>Visual reasoning abilities play a crucial role in understanding complex multimodal data, advancing both domain-specific applications and artificial general intelligence (AGI). Existing methods enhance Vision-Language Models (VLMs) through Chain-of-Thought (CoT) supervised fine-tuning using meticulously annotated data. However, this approach may lead to overfitting and cognitive rigidity, limiting the modelâ€™s generalization ability under domain shifts and reducing real-world applicability. To overcome these limitations, we propose Reason-RFT, a two-stage reinforcement fine-tuning framework for visual reasoning. First, Supervised Fine-Tuning (SFT) with curated CoT data activates the reasoning potential of VLMs. This is followed by reinforcement learning based on Group Relative Policy Optimization (GRPO), which generates multiple reasoning-response pairs to enhance adaptability to domain shifts. To evaluate Reason-RFT, we reconstructed a comprehensive dataset covering visual counting, structural perception, and spatial transformation, serving as a benchmark for systematic assessment across three key dimensions. Experimental results highlight three advantages: (1) performance enhancement, with Reason-RFT achieving state-of-the-art results and outperforming both open-source and proprietary models; (2) generalization superiority, maintaining robust performance under domain shifts across various tasks; and (3) data efficiency, excelling in few-shot learning scenarios and surpassing full-dataset SFT baselines. Reason-RFT introduces a novel training paradigm for visual reasoning and marks a significant step forward in multimodal research. Project website: <a target="_blank" rel="noopener" href="https://tanhuajie.github.io/ReasonRFT">https://tanhuajie.github.io/ReasonRFT</a></p>
<blockquote>
<p>è§†è§‰æ¨ç†èƒ½åŠ›åœ¨ç†è§£å¤æ‚çš„å¤šæ¨¡æ€æ•°æ®ã€æ¨åŠ¨ç‰¹å®šé¢†åŸŸåº”ç”¨å’Œé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰å‘å±•æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡ä½¿ç”¨ç²¾å¿ƒæ³¨é‡Šçš„æ•°æ®å¯¹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¿›è¡Œæ€ç»´é“¾ï¼ˆCoTï¼‰ç›‘ç£å¾®è°ƒæ¥å¢å¼ºå…¶æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆå’Œè®¤çŸ¥åƒµåŒ–ï¼Œé™åˆ¶äº†æ¨¡å‹åœ¨é¢†åŸŸå˜åŒ–ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶é™ä½äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„é€‚ç”¨æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Reason-RFTï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè§†è§‰æ¨ç†çš„ä¸¤é˜¶æ®µå¼ºåŒ–å¾®è°ƒæ¡†æ¶ã€‚é¦–å…ˆï¼Œä½¿ç”¨ç²¾é€‰çš„CoTæ•°æ®è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä»¥æ¿€å‘VLMsçš„æ¨ç†æ½œåŠ›ã€‚å…¶æ¬¡æ˜¯åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ ï¼Œç”Ÿæˆå¤šä¸ªæ¨ç†-å“åº”å¯¹ï¼Œä»¥å¢å¼ºå¯¹é¢†åŸŸå˜åŒ–çš„é€‚åº”èƒ½åŠ›ã€‚ä¸ºäº†è¯„ä¼°Reason-RFTï¼Œæˆ‘ä»¬é‡æ–°æ„å»ºäº†ä¸€ä¸ªç»¼åˆæ•°æ®é›†ï¼Œæ¶µç›–äº†è§†è§‰è®¡æ•°ã€ç»“æ„æ„ŸçŸ¥å’Œç©ºé—´è½¬æ¢ï¼Œä½œä¸ºä¸‰ä¸ªå…³é”®ç»´åº¦ç³»ç»Ÿè¯„ä¼°çš„åŸºå‡†ã€‚å®éªŒç»“æœçªå‡ºäº†ä¸‰ä¸ªä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰æ€§èƒ½å¢å¼ºï¼ŒReason-RFTè¾¾åˆ°æœ€æ–°ç»“æœå¹¶ä¼˜äºå¼€æºå’Œä¸“æœ‰æ¨¡å‹ï¼›ï¼ˆ2ï¼‰æ³›åŒ–ä¼˜åŠ¿ï¼Œåœ¨å„ç§ä»»åŠ¡é¢†åŸŸå˜åŒ–ä¸‹ä¿æŒç¨³å¥æ€§èƒ½ï¼›ï¼ˆ3ï¼‰æ•°æ®æ•ˆç‡ï¼Œåœ¨å°‘é‡å­¦ä¹ åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²å¹¶è¶…è¶Šå…¨æ•°æ®é›†SFTåŸºå‡†çº¿ã€‚Reason-RFTä¸ºè§†è§‰æ¨ç†å¼•å…¥äº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œå¹¶åœ¨å¤šæ¨¡æ€ç ”ç©¶ä¸­å–å¾—äº†é‡å¤§è¿›å±•ã€‚é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://tanhuajie.github.io/ReasonRFT">https://tanhuajie.github.io/ReasonRFT</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20752v3">PDF</a> 51 pages, 23 figures, NeurIPSâ€™25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨è§†è§‰æ¨ç†èƒ½åŠ›åœ¨ç†è§£å¤æ‚å¤šæ¨¡æ€æ•°æ®ä¸­çš„ä½œç”¨ï¼Œå¹¶æŒ‡å‡ºä¼ ç»Ÿæ–¹æ³•å¯èƒ½å¯¼è‡´çš„è¿‡æ‹Ÿåˆå’Œè®¤çŸ¥åƒµåŒ–é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§åä¸ºReason-RFTçš„ä¸¤é˜¶æ®µå¼ºåŒ–å¾®è°ƒæ¡†æ¶ï¼Œé€šè¿‡ç›‘ç£ç²¾ç»†è°ƒæœºå’ŒåŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ æ¥å¢å¼ºè§†è§‰æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æé«˜æ€§èƒ½ã€ä»»åŠ¡æ³›åŒ–å’Œæ•°æ®æ•ˆç‡æ–¹é¢å‡æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†è§‰æ¨ç†èƒ½åŠ›å¯¹äºç†è§£å¤æ‚å¤šæ¨¡æ€æ•°æ®å’Œæ¨è¿›ç‰¹å®šé¢†åŸŸåº”ç”¨åŠé€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•å…·æœ‰å…³é”®ä½œç”¨ã€‚</li>
<li>ä¼ ç»Ÿé€šè¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰å¯¹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œç²¾ç»†ç›‘ç£è°ƒæœºçš„æ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆå’Œè®¤çŸ¥åƒµåŒ–ã€‚</li>
<li>Reason-RFTæ¡†æ¶åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µé€šè¿‡ç›‘ç£ç²¾ç»†è°ƒæœºæ¿€æ´»VLMçš„æ¨ç†æ½œåŠ›ï¼›ç¬¬äºŒé˜¶æ®µåˆ©ç”¨åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ æ¥æå‡æ¨¡å‹é€‚åº”ä¸åŒé¢†åŸŸçš„èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨è§†è§‰è®¡æ•°ã€ç»“æ„æ„ŸçŸ¥å’Œç©ºé—´è½¬æ¢ç­‰ä»»åŠ¡ä¸Šæ„å»ºäº†ç»¼åˆæ•°æ®é›†ï¼Œä¸ºç³»ç»Ÿè¯„ä¼°æä¾›äº†åŸºå‡†ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒReason-RFTæ¡†æ¶åœ¨æ€§èƒ½ã€ä»»åŠ¡æ³›åŒ–å’Œæ•°æ®æ•ˆç‡æ–¹é¢è¾ƒä¼ ç»Ÿæ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
<li>Reason-RFTä¸ºè§†è§‰æ¨ç†ç ”ç©¶æä¾›äº†æ–°çš„è®­ç»ƒèŒƒå¼ï¼Œå¹¶åœ¨å¤šæ¨¡æ€ç ”ç©¶ä¸­å–å¾—äº†é‡è¦è¿›å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20752">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.20752v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.20752v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.20752v3/page_3_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Explainable-Sentiment-Analysis-with-DeepSeek-R1-Performance-Efficiency-and-Few-Shot-Learning"><a href="#Explainable-Sentiment-Analysis-with-DeepSeek-R1-Performance-Efficiency-and-Few-Shot-Learning" class="headerlink" title="Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning"></a>Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning</h2><p><strong>Authors:Donghao Huang, Zhaoxia Wang</strong></p>
<p>Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1â€“an open-source reasoning modelâ€“against OpenAIâ€™s GPT-4o and GPT-4o-mini. We test the full 671B model and its distilled variants, systematically documenting few-shot learning curves. Our experiments show DeepSeek-R1 achieves a 91.39% F1 score on 5-class sentiment and 99.31% accuracy on binary tasks with just 5 shots, an eightfold improvement in few-shot efficiency over GPT-4o. Architecture-specific distillation effects emerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant by 6.69 percentage points. While its reasoning process reduces throughput, DeepSeek-R1 offers superior explainability via transparent, step-by-step traces, establishing it as a powerful, interpretable open-source alternative.</p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æ”¹å˜äº†æƒ…æ„Ÿåˆ†æé¢†åŸŸï¼Œä½†åœ¨å‡†ç¡®æ€§ã€æ•ˆç‡å’Œå¯è§£é‡Šæ€§ä¹‹é—´å–å¾—å¹³è¡¡ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å¯¹DeepSeek-R1è¿™ä¸€å¼€æºæ¨ç†æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå°†å…¶ä¸OpenAIçš„GPT-4oå’ŒGPT-4o-miniè¿›è¡Œäº†å¯¹æ¯”ã€‚æˆ‘ä»¬æµ‹è¯•äº†å®Œæ•´çš„671Bæ¨¡å‹åŠå…¶è’¸é¦å˜ä½“ï¼Œç³»ç»Ÿåœ°è®°å½•äº†å°æ ·æœ¬å­¦ä¹ æ›²çº¿ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒDeepSeek-R1åœ¨5ç±»æƒ…æ„Ÿåˆ†æä¸Šè¾¾åˆ°äº†91.39%çš„F1åˆ†æ•°ï¼Œåœ¨äºŒå…ƒä»»åŠ¡ä¸Šè¾¾åˆ°äº†99.31%çš„å‡†ç¡®ç‡ï¼Œåªéœ€5ä¸ªæ ·æœ¬ï¼Œå…¶åœ¨å°æ ·æœ¬æ•ˆç‡ä¸Šæ˜¯GPT-4oçš„8å€ã€‚å‡ºç°äº†ä¸æ¶æ„ç‰¹å®šçš„è’¸é¦æ•ˆåº”ï¼Œå…¶ä¸­åŸºäº32B Qwen2.5çš„æ¨¡å‹ä¼˜äºåŸºäº70B Llamaçš„å˜ä½“ï¼Œé«˜å‡º6.69ä¸ªç™¾åˆ†ç‚¹ã€‚è™½ç„¶å…¶æ¨ç†è¿‡ç¨‹é™ä½äº†ååé‡ï¼Œä½†DeepSeek-R1é€šè¿‡é€æ˜ã€é€æ­¥çš„è¿½è¸ªæä¾›äº†å‡ºè‰²çš„å¯è§£é‡Šæ€§ï¼Œä½¿å…¶æˆä¸ºå¼ºå¤§ã€å¯è§£é‡Šçš„å¼€æºæ›¿ä»£å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11655v4">PDF</a> 10 pages, with 2 figures and 6 tables, accepted for publication in an IEEE Intelligent Systems journal</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æƒ…æ„Ÿåˆ†æé¢†åŸŸå®ç°äº†æ˜¾è‘—å˜é©ï¼Œä½†å¦‚ä½•åœ¨å‡†ç¡®æ€§ã€æ•ˆç‡å’Œå¯è§£é‡Šæ€§ä¹‹é—´å–å¾—å¹³è¡¡ä»æ˜¯å…³é”®æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶å¯¹DeepSeek-R1è¿™ä¸€å¼€æºæ¨ç†æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶ä¸OpenAIçš„GPT-4oå’ŒGPT-4o-miniè¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDeepSeek-R1åœ¨5ç±»æƒ…æ„Ÿåˆ†æä¸Šè¾¾åˆ°91.39%çš„F1åˆ†æ•°ï¼Œåœ¨äºŒå…ƒä»»åŠ¡ä¸Šè¾¾åˆ°99.31%çš„å‡†ç¡®ç‡ï¼Œä»…é€šè¿‡å‡ æ¬¡å­¦ä¹ æ›²çº¿å³å¯å®ç°ã€‚ç›¸è¾ƒäºGPT-4oï¼ŒDeepSeek-R1åœ¨å°‘æ ·æœ¬å­¦ä¹ æ–¹é¢çš„æ•ˆç‡æé«˜äº†å…«å€ã€‚åŒæ—¶ï¼Œæ¶æ„ç‰¹å®šçš„è’¸é¦æ•ˆåº”æ˜¾ç°ï¼Œä¸€ä¸ªåŸºäºQwen2.5çš„32Bæ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¶…è¿‡äº†åŸºäºLlamaçš„70Bæ¨¡å‹ã€‚è™½ç„¶æ¨ç†è¿‡ç¨‹å¯èƒ½å½±å“é€Ÿåº¦ï¼Œä½†DeepSeek-R1å‡­å€Ÿé€æ˜çš„é€æ­¥è·Ÿè¸ªæä¾›äº†å“è¶Šçš„å¯è§£é‡Šæ€§ï¼Œæˆä¸ºå¼ºå¤§ä¸”å¯è§£è¯»çš„å¼€æºæ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æƒ…æ„Ÿåˆ†æé¢†åŸŸçš„åº”ç”¨åŠå…¶æŒ‘æˆ˜ã€‚</li>
<li>DeepSeek-R1ä¸å…¶ä»–æ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰çš„å¯¹æ¯”è¯„ä¼°ã€‚</li>
<li>DeepSeek-R1åœ¨å°‘æ ·æœ¬å­¦ä¹ æƒ…å¢ƒä¸‹çš„é«˜æ•ˆè¡¨ç°ã€‚</li>
<li>ä¸åŒæ¶æ„æ¨¡å‹çš„æ€§èƒ½å·®å¼‚ï¼ŒQwen2.5-basedæ¨¡å‹è¾ƒLlama-basedè¡¨ç°æ›´ä¼˜ã€‚</li>
<li>DeepSeek-R1çš„æ¨ç†è¿‡ç¨‹å¯èƒ½å½±å“æ•ˆç‡ï¼Œä½†æä¾›å“è¶Šçš„å¯è§£é‡Šæ€§ã€‚</li>
<li>DeepSeek-R1ä½œä¸ºå¼€æºæ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11655">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2503.11655v4/page_5_1.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Unlocking-Multimodal-Mathematical-Reasoning-via-Process-Reward-Model"><a href="#Unlocking-Multimodal-Mathematical-Reasoning-via-Process-Reward-Model" class="headerlink" title="Unlocking Multimodal Mathematical Reasoning via Process Reward Model"></a>Unlocking Multimodal Mathematical Reasoning via Process Reward Model</h2><p><strong>Authors:Ruilin Luo, Zhuofan Zheng, Yifan Wang, Xinzhe Ni, Zicheng Lin, Songtao Jiang, Yiyao Yu, Chufan Shi, Lei Wang, Ruihang Chu, Jin Zeng, Yujiu Yang</strong></p>
<p>Process Reward Models (PRMs) have shown promise in enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) through Test-Time Scaling (TTS). However, their integration into multimodal reasoning remains largely unexplored. In this work, we take the first step toward unlocking the potential of PRMs in multimodal mathematical reasoning. We identify three key challenges: (1) the scarcity of high-quality reasoning data constrains the capabilities of foundation Multimodal Large Language Models (MLLMs), which imposes further limitations on the upper bounds of TTS and reinforcement learning (RL); (2) a lack of automated methods for process labeling within multimodal contexts persists; (3) the employment of process rewards in unimodal RL faces issues like reward hacking, which may extend to multimodal scenarios. To address these issues, we introduce URSA, a three-stage Unfolding multimodal Process-Supervision Aided training framework. We first construct MMathCoT-1M, a high-quality large-scale multimodal Chain-of-Thought (CoT) reasoning dataset, to build a stronger math reasoning foundation MLLM, URSA-8B. Subsequently, we go through an automatic process to synthesize process supervision data, which emphasizes both logical correctness and perceptual consistency. We introduce DualMath-1.1M to facilitate the training of URSA-8B-RM. Finally, we propose Process-Supervised Group-Relative-Policy-Optimization (PS-GRPO), pioneering a multimodal PRM-aided online RL method that outperforms vanilla GRPO. With PS-GRPO application, URSA-8B-PS-GRPO outperforms Gemma3-12B and GPT-4o by 8.4% and 2.7% on average across 6 benchmarks. Code, data and checkpoint can be found at <a target="_blank" rel="noopener" href="https://github.com/URSA-MATH">https://github.com/URSA-MATH</a>.</p>
<blockquote>
<p>è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰é€šè¿‡æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤šæ¨¡æ€æ¨ç†ä¸­çš„é›†æˆä»ç„¶é²œæœ‰ç ”ç©¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¿ˆå‡ºäº†å®ç°PRMåœ¨å¤šæ¨¡æ€æ•°å­¦æ¨ç†ä¸­æ½œåŠ›çš„ç¬¬ä¸€æ­¥ã€‚æˆ‘ä»¬ç¡®å®šäº†ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰é«˜è´¨é‡æ¨ç†æ•°æ®çš„ç¨€ç¼ºé™åˆ¶äº†åŸºç¡€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„èƒ½åŠ›ï¼Œè¿™ç»™TTSå’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ä¸Šé™å¸¦æ¥äº†è¿›ä¸€æ­¥é™åˆ¶ï¼›ï¼ˆ2ï¼‰åœ¨å¤šæ¨¡æ€èƒŒæ™¯ä¸‹ç¼ºä¹è¿‡ç¨‹æ ‡ç­¾çš„è‡ªåŠ¨åŒ–æ–¹æ³•ä»ç„¶å­˜åœ¨ï¼›ï¼ˆ3ï¼‰åœ¨å•æ¨¡æ€RLä¸­ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±é¢ä¸´ç€å¥–åŠ±é»‘å®¢ç­‰é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å¯èƒ½ä¼šæ‰©å±•åˆ°å¤šæ¨¡æ€åœºæ™¯ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†URSAï¼Œè¿™æ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µå±•å¼€çš„å¤šæ¨¡æ€è¿‡ç¨‹ç›‘ç£è¾…åŠ©è®­ç»ƒæ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†MMathCoT-1Mè¿™ä¸€é«˜è´¨é‡çš„å¤§è§„æ¨¡å¤šæ¨¡æ€æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†æ•°æ®é›†ï¼Œä»¥å»ºç«‹æ›´å¼ºå¤§çš„æ•°å­¦æ¨ç†åŸºç¡€MLLMï¼Œå³URSA-8Bã€‚éšåï¼Œæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªè‡ªåŠ¨è¿‡ç¨‹æ¥åˆæˆè¿‡ç¨‹ç›‘ç£æ•°æ®ï¼Œè¿™ä¸€è¿‡ç¨‹å¼ºè°ƒé€»è¾‘æ­£ç¡®æ€§å’Œæ„ŸçŸ¥ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†DualMath-1.1Mæ¥ä¿ƒè¿›URSA-8B-RMçš„è®­ç»ƒã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†è¿‡ç¨‹ç›‘ç£ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆPS-GRPOï¼‰ï¼Œå¼€åˆ›äº†ä¸€ç§å¤šæ¨¡æ€PRMè¾…åŠ©çš„åœ¨çº¿RLæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¼˜äºæ ‡å‡†GRPOã€‚é€šè¿‡åº”ç”¨PS-GRPOï¼ŒURSA-8B-PS-GRPOåœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹³å‡è¡¨ç°ä¼˜äºGemma3-12Bå’ŒGPT-4oï¼Œåˆ†åˆ«æé«˜äº†8.4%å’Œ2.7%ã€‚ç›¸å…³ä»£ç ã€æ•°æ®å’Œæ£€æŸ¥ç‚¹å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/URSA-MATH%E4%BB%A5%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/URSA-MATHä»¥è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04686v6">PDF</a> NeurIPS 2025 Main Track</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ¢ç´¢äº†å°†è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰åº”ç”¨äºå¤šæ¨¡æ€æ¨ç†çš„æ½œåŠ›ã€‚æ–‡ç« è§£å†³äº†ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œæå‡ºURSAè®­ç»ƒæ¡†æ¶ï¼Œå¹¶æ„å»ºäº†å¤§å‹å¤šæ¨¡æ€æ¨ç†æ•°æ®é›†MMathCoT-1Mï¼Œç”¨äºè®­ç»ƒå…·æœ‰æ›´å¼ºæ•°å­¦æ¨ç†èƒ½åŠ›çš„MLLMæ¨¡å‹URSA-8Bã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„åœ¨çº¿RLæ–¹æ³•PS-GRPOæ¥ä¼˜åŒ–è¿‡ç¨‹å¥–åŠ±ç­–ç•¥ã€‚æœ€åé€šè¿‡è¯„ä¼°è¯æ˜è¯¥æ¡†æ¶æ–¹æ³•èƒ½å¤Ÿåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜åŠ¿ã€‚è¯¦æƒ…å‚è§URLé“¾æ¥ <a target="_blank" rel="noopener" href="https://github.com/URSA-MATH%E3%80%82">https://github.com/URSA-MATHã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡ç« é¦–æ¬¡æ¢ç´¢äº†å°†è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰åº”ç”¨äºå¤šæ¨¡æ€æ•°å­¦æ¨ç†çš„æ½œåŠ›ã€‚</li>
<li>æ–‡ç« è§£å†³äº†ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šé«˜è´¨é‡æ¨ç†æ•°æ®çš„ç¨€ç¼ºæ€§ã€å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ä¸­çš„è¿‡ç¨‹æ ‡ç­¾è‡ªåŠ¨åŒ–æ–¹æ³•çš„ç¼ºä¹ä»¥åŠåœ¨å•æ¨¡æ€å¼ºåŒ–å­¦ä¹ ä¸­ä½¿ç”¨è¿‡ç¨‹å¥–åŠ±çš„é—®é¢˜ã€‚</li>
<li>æå‡ºURSAè®­ç»ƒæ¡†æ¶ï¼Œå¹¶æ„å»ºå¤§å‹å¤šæ¨¡æ€æ¨ç†æ•°æ®é›†MMathCoT-1Mç”¨äºè®­ç»ƒMLLMæ¨¡å‹URSA-8Bã€‚</li>
<li>é€šè¿‡åˆæˆè¿‡ç¨‹ç›‘ç£æ•°æ®ï¼Œå¼ºè°ƒé€»è¾‘æ­£ç¡®æ€§å’Œæ„ŸçŸ¥ä¸€è‡´æ€§ã€‚å¼•å…¥DualMath-1.1Mä¿ƒè¿›URSA-8Bçš„è®­ç»ƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04686">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_R1_Reasoning/2501.04686v6/page_5_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-13/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-13/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-13/LLM/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-11-13\./crop_LLM/2510.11188v1/page_0_0.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-13  Protein as a Second Language for LLMs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-12/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-11-12\./crop_Talking Head Generation/2511.06833v1/page_4_0.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-12  ConsistTalk Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
