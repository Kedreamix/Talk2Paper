<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="医学图像">
    <meta name="description" content="医学图像 方向最新论文已更新，请持续关注 Update in 2025-01-07  Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>医学图像 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-970e1b1c8819dbfa82c0b6a5bd066932.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">医学图像</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">医学图像</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                医学图像
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    40 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-07-更新"><a href="#2025-01-07-更新" class="headerlink" title="2025-01-07 更新"></a>2025-01-07 更新</h1><h2 id="Detecting-and-Mitigating-Adversarial-Attacks-on-Deep-Learning-Based-MRI-Reconstruction-Without-Any-Retraining"><a href="#Detecting-and-Mitigating-Adversarial-Attacks-on-Deep-Learning-Based-MRI-Reconstruction-Without-Any-Retraining" class="headerlink" title="Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining"></a>Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining</h2><p><strong>Authors:Mahdi Saberi, Chi Zhang, Mehmet Akcakaya</strong></p>
<p>Deep learning (DL) methods, especially those based on physics-driven DL, have become the state-of-the-art for reconstructing sub-sampled magnetic resonance imaging (MRI) data. However, studies have shown that these methods are susceptible to small adversarial input perturbations, or attacks, resulting in major distortions in the output images. Various strategies have been proposed to reduce the effects of these attacks, but they require retraining and may lower reconstruction quality for non-perturbed&#x2F;clean inputs. In this work, we propose a novel approach for detecting and mitigating adversarial attacks on MRI reconstruction models without any retraining. Our detection strategy is based on the idea of cyclic measurement consistency. The output of the model is mapped to another set of MRI measurements for a different sub-sampling pattern, and this synthesized data is reconstructed with the same model. Intuitively, without an attack, the second reconstruction is expected to be consistent with the first, while with an attack, disruptions are present. Subsequently, this idea is extended to devise a novel objective function, which is minimized within a small ball around the attack input for mitigation. Experimental results show that our method substantially reduces the impact of adversarial perturbations across different datasets, attack types&#x2F;strengths and PD-DL networks, and qualitatively and quantitatively outperforms conventional mitigation methods that involve retraining. </p>
<blockquote>
<p>深度学习（DL）方法，尤其是基于物理驱动的DL方法，已成为重建子采样磁共振成像（MRI）数据的最新技术。然而，研究表明，这些方法容易受到微小敌对输入扰动或攻击的影响，导致输出图像出现重大失真。虽然已提出各种策略来减少这些攻击的影响，但它们需要重新训练，并可能降低对非扰动&#x2F;清洁输入的重建质量。在这项工作中，我们提出了一种无需重新训练即可检测和减轻MRI重建模型遭受敌对攻击的新方法。我们的检测策略基于循环测量一致性的理念。模型的输出被映射到另一组MRI测量值，用于不同的子采样模式，然后用同一模型重建这些合成数据。直观地说，在没有攻击的情况下，第二次重建应与第一次重建一致，而受到攻击时则会出现干扰。随后，将这个理念扩展到一个新的目标函数中，通过最小化攻击输入周围小范围内的该函数来减轻攻击影响。实验结果表明，我们的方法大大减少了不同数据集、攻击类型和强度以及PD-DL网络中的敌对扰动的影响，并且在定性和定量上均优于涉及重新训练的传统缓解方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01908v1">PDF</a> </p>
<p><strong>Summary</strong><br>     深度学习（DL）在重建子采样磁共振成像（MRI）数据方面表现出卓越性能，尤其是基于物理驱动的DL方法。然而，研究表明这些方法容易受到小型的对抗性输入扰动或攻击的影响，导致输出图像出现重大失真。本研究提出了一种无需重新训练即可检测和减轻MRI重建模型对抗性攻击的新方法。该方法基于循环测量一致性检测策略，并通过实验验证其能有效减少不同数据集、攻击类型和强度以及部分物理驱动DL网络中的对抗性扰动影响，并在定性和定量上优于涉及重新训练的常规缓解方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习在MRI数据重建中表现优异，尤其是物理驱动DL方法。</li>
<li>DL方法容易受到对抗性输入扰动或攻击的影响，导致输出图像失真。</li>
<li>本研究提出了一种无需重新训练的新方法，用于检测和减轻MRI重建模型的对抗性攻击。</li>
<li>该方法基于循环测量一致性检测策略。</li>
<li>实验证明该方法能有效减少不同数据集、攻击类型和强度中的对抗性扰动影响。</li>
<li>与常规需要重新训练的缓解方法相比，该方法在定性和定量上表现更优。</li>
<li>该方法具有广泛的应用前景，可应用于不同的MRI重建模型和情境。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01908">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-494f2270d29451caf9b59b6781f35edf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4af73b9dddc124c06a3d1b52577f7fe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a40a89da48e558cfc8550c0f8bf0705c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2f9b425e01172e94bbb73ef3ab4e97c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b54dd2e74f8dcdea6f89e12265683aa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a784e6e5f5e8b473b5385e719de0552.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Augmentation-Matters-A-Mix-Paste-Method-for-X-Ray-Prohibited-Item-Detection-under-Noisy-Annotations"><a href="#Augmentation-Matters-A-Mix-Paste-Method-for-X-Ray-Prohibited-Item-Detection-under-Noisy-Annotations" class="headerlink" title="Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item   Detection under Noisy Annotations"></a>Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item   Detection under Noisy Annotations</h2><p><strong>Authors:Ruikang Chen, Yan Yan, Jing-Hao Xue, Yang Lu, Hanzi Wang</strong></p>
<p>Automatic X-ray prohibited item detection is vital for public safety. Existing deep learning-based methods all assume that the annotations of training X-ray images are correct. However, obtaining correct annotations is extremely hard if not impossible for large-scale X-ray images, where item overlapping is ubiquitous.As a result, X-ray images are easily contaminated with noisy annotations, leading to performance deterioration of existing methods.In this paper, we address the challenging problem of training a robust prohibited item detector under noisy annotations (including both category noise and bounding box noise) from a novel perspective of data augmentation, and propose an effective label-aware mixed patch paste augmentation method (Mix-Paste). Specifically, for each item patch, we mix several item patches with the same category label from different images and replace the original patch in the image with the mixed patch. In this way, the probability of containing the correct prohibited item within the generated image is increased. Meanwhile, the mixing process mimics item overlapping, enabling the model to learn the characteristics of X-ray images. Moreover, we design an item-based large-loss suppression (LLS) strategy to suppress the large losses corresponding to potentially positive predictions of additional items due to the mixing operation. We show the superiority of our method on X-ray datasets under noisy annotations. In addition, we evaluate our method on the noisy MS-COCO dataset to showcase its generalization ability. These results clearly indicate the great potential of data augmentation to handle noise annotations. The source code is released at <a target="_blank" rel="noopener" href="https://github.com/wscds/Mix-Paste">https://github.com/wscds/Mix-Paste</a>. </p>
<blockquote>
<p>自动X射线违禁品检测对公共安全至关重要。现有的基于深度学习的方法都假设训练X射线图像的注释是正确的。然而，对于大规模的X射线图像，由于物品重叠普遍存在，获取正确的注释极其困难甚至不可能。因此，X射线图像很容易受到带有噪声的注释的污染，导致现有方法的性能下降。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01733v1">PDF</a> The manuscript has been ACCEPTED for publication as a regular paper   in the IEEE Transactions on Information Forensics &amp; Security</p>
<p><strong>Summary</strong></p>
<p>基于深度学习的自动X射线违禁物品检测在存在噪声标注的情况下性能会下降。本文创新性地从数据增强角度解决这一难题，提出一种标签感知混合补丁粘贴增强方法（Mix-Paste），通过混合相同类别标签的物品补丁，增加生成图像中包含正确违禁物品的概率，同时模仿物品重叠情况，使模型学习X射线图像的特性。此外，设计了一项基于物品的较大损失抑制策略，以抑制因混合操作产生的其他潜在阳性预测物品的较大损失。该策略在处理带有噪声标注的X射线数据集上表现卓越，并在噪声MS-COCO数据集上评估展示其泛化能力。数据增强在应对噪声标注方面具有巨大潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>自动X射线违禁物品检测对公共安全至关重要。</li>
<li>现有深度学习方法假设训练X光图像的注释是正确的，但在大规模图像中获得正确注释极其困难。</li>
<li>Mix-Paste方法通过数据增强解决噪声标注问题，提高模型对X光图像中违禁物品的识别能力。</li>
<li>Mix-Paste方法混合相同类别标签的物品补丁，增加生成图像的正确率并模仿物品重叠情况。</li>
<li>提出一种基于物品的较大损失抑制策略，以处理因混合操作产生的潜在阳性预测物品。</li>
<li>方法在带有噪声标注的X射线数据集上表现优越，并在噪声MS-COCO数据集上评估具有良好的泛化能力。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01733">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-12328be63ccd63faefdb7d24e904f70e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5a33b39f2106739fca0ce619cbb21f2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EAUWSeg-Eliminating-annotation-uncertainty-in-weakly-supervised-medical-image-segmentation"><a href="#EAUWSeg-Eliminating-annotation-uncertainty-in-weakly-supervised-medical-image-segmentation" class="headerlink" title="EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical   image segmentation"></a>EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical   image segmentation</h2><p><strong>Authors:Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi</strong></p>
<p>Weakly-supervised medical image segmentation is gaining traction as it requires only rough annotations rather than accurate pixel-to-pixel labels, thereby reducing the workload for specialists. Although some progress has been made, there is still a considerable performance gap between the label-efficient methods and fully-supervised one, which can be attributed to the uncertainty nature of these weak labels. To address this issue, we propose a novel weak annotation method coupled with its learning framework EAUWSeg to eliminate the annotation uncertainty. Specifically, we first propose the Bounded Polygon Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the tailored learning mechanism that explicitly treat bounded polygons as two separated annotations is proposed to learn invariant feature by providing adversarial supervision signal for model training. Subsequently, a confidence-auxiliary consistency learner incorporates with a classification-guided confidence generator is designed to provide reliable supervision signal for pixels in uncertain region by leveraging the feature presentation consistency across pixels within the same category as well as class-specific information encapsulated in bounded polygons annotation. Experimental results demonstrate that EAUWSeg outperforms existing weakly-supervised segmentation methods. Furthermore, compared to fully-supervised counterparts, the proposed method not only delivers superior performance but also costs much less annotation workload. This underscores the superiority and effectiveness of our approach. </p>
<blockquote>
<p>弱监督医学图像分割正受到越来越多的关注，因为它只需要粗略的注释，而不需要精确的像素到像素的标签，从而减少了专家的工作量。虽然已取得了一些进展，但标签效率高的方法与全监督方法之间的性能差距仍然很大，这可以归因于这些弱标签的不确定性。为了解决这一问题，我们提出了一种新的弱标注方法及其学习框架EAUWSeg，以消除标注的不确定性。具体来说，我们首先提出有界多边形注释（BPAnno），只需为病变标注两个多边形。然后，我们提出了一种定制的学习机制，将多边形明确地视为两个单独的注释进行处理，通过为模型训练提供对抗性监督信号来学习不变特征。随后，设计了一个与分类引导置信度生成器相结合的置信辅助一致性学习者，通过利用同一类别内像素之间的特征表示一致性以及包含在边界多边形注释中的类别特定信息，为不确定区域的像素提供可靠的监督信号。实验结果表明，EAUWSeg优于现有的弱监督分割方法。此外，与全监督方法相比，该方法不仅性能优越，而且大大减少了标注工作量。这凸显了我们方法的优越性和有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01658v1">PDF</a> </p>
<p><strong>Summary</strong><br>医学图像分割中，弱监督方法因仅需粗略标注而备受关注，但存在性能差距。为此，提出一种新型弱标注方法与学习框架EAUWSeg，通过Bounded Polygon Annotation（BPAnno）和对抗性监督信号消除标注不确定性，设计信心辅助一致性学习者，提供可靠监督信号。实验显示，EAUWSeg优于现有弱监督方法，与全监督方法相比，性能优越且标注工作量更少。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>弱监督医学图像分割因减少专家工作量而受关注。</li>
<li>现有方法存在性能差距，主要源于弱标注的不确定性。</li>
<li>提出新型弱标注方法BPAnno和学习框架EAUWSeg。</li>
<li>BPAnno通过仅标注两个多边形来代表病灶。</li>
<li>EAUWSeg利用对抗性监督信号学习不变特征。</li>
<li>信心辅助一致性学习者提供可靠监督信号，尤其针对不确定区域。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01658">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-72b853ce257783f27ce8963f216bbbe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c695bf284ea3a0bd79913fc4e7ee04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d01edef42f0d03893153f4ec586be0f7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-25227b8c5425e3d476ccbb6736c5e487.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Merging-Context-Clustering-with-Visual-State-Space-Models-for-Medical-Image-Segmentation"><a href="#Merging-Context-Clustering-with-Visual-State-Space-Models-for-Medical-Image-Segmentation" class="headerlink" title="Merging Context Clustering with Visual State Space Models for Medical   Image Segmentation"></a>Merging Context Clustering with Visual State Space Models for Medical   Image Segmentation</h2><p><strong>Authors:Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang</strong></p>
<p>Medical image segmentation demands the aggregation of global and local feature representations, posing a challenge for current methodologies in handling both long-range and short-range feature interactions. Recently, vision mamba (ViM) models have emerged as promising solutions for addressing model complexities by excelling in long-range feature iterations with linear complexity. However, existing ViM approaches overlook the importance of preserving short-range local dependencies by directly flattening spatial tokens and are constrained by fixed scanning patterns that limit the capture of dynamic spatial context information. To address these challenges, we introduce a simple yet effective method named context clustering ViM (CCViM), which incorporates a context clustering module within the existing ViM models to segment image tokens into distinct windows for adaptable local clustering. Our method effectively combines long-range and short-range feature interactions, thereby enhancing spatial contextual representations for medical image segmentation tasks. Extensive experimental evaluations on diverse public datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the superior performance of our method compared to current state-of-the-art methods. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM">https://github.com/zymissy/CCViM</a>. </p>
<blockquote>
<p>医学图像分割要求全局和局部特征表示的聚合，这对当前方法处理长程和短程特征交互提出了挑战。最近，视觉妈妈（ViM）模型以线性复杂度的长程特征迭代能力突出，成为解决模型复杂性的有前途的解决方案。然而，现有的ViM方法通过直接平铺空间令牌而忽略了保持短程局部依赖关系的重要性，并且受到固定扫描模式的约束，限制了动态空间上下文信息的捕获。为了解决这些挑战，我们提出了一种简单有效的方法，称为上下文聚类ViM（CCViM），该方法在现有的ViM模型内引入了一个上下文聚类模块，用于将图像令牌分割成不同的窗口进行自适应局部聚类。我们的方法有效地结合了长程和短程特征交互，从而增强了医学图像分割任务的上下文空间表示。在Kumar、CPM17、ISIC17、ISIC18和Synapse等多个公共数据集上的广泛实验评估表明，我们的方法与当前最先进的方法相比具有优越的性能。我们的代码位于<a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM%E3%80%82">https://github.com/zymissy/CCViM。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01618v1">PDF</a> Our paper has been accepted by the IEEE Transactions on Medical   Imaging. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM">https://github.com/zymissy/CCViM</a></p>
<p><strong>Summary</strong><br>医学图像分割需要融合全局和局部特征表示，这对当前方法处理长程和短程特征交互提出了挑战。新型的视觉mamba（ViM）模型以处理长程特征交互的线性复杂度为优势，应对模型复杂性。然而，现有ViM方法忽略了保持短程局部依赖性的重要性，通过直接扁平化空间令牌受到固定扫描模式的约束，限制了动态空间上下文信息的捕获。为解决这些问题，我们提出了一种简单有效的方法——上下文聚类ViM（CCViM），在现有ViM模型中引入上下文聚类模块，对图像令牌进行可适应的局部聚类。我们的方法有效地结合了长程和短程特征交互，从而提升医学图像分割任务的空间上下文表示。在Kumar、CPM17、ISIC17、ISIC18和Synapse等多个公共数据集上的广泛实验评估表明，我们的方法优于当前最先进的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医学图像分割需要兼顾全局和局部特征表示，存在挑战。</li>
<li>视觉mamba（ViM）模型能处理长程特征交互，但忽视短程局部依赖性。</li>
<li>现有ViM方法通过直接扁平化空间令牌受到固定扫描模式的约束。</li>
<li>上下文聚类ViM（CCViM）结合长程和短程特征交互。</li>
<li>CCViM通过引入上下文聚类模块，对图像令牌进行可适应的局部聚类。</li>
<li>CCViM在多个公共数据集上的表现优于当前最先进的方法。</li>
<li>相关代码已上传至GitHub（<a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM%EF%BC%89%E3%80%82">https://github.com/zymissy/CCViM）。</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01618">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-538a1211dd7c735f23e3459f29d382fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89720c2dc084f734168b39856cda0b31.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ac293990c9267c8608f7542d4d4e9d0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65ce41d6e3dd788a3ad6eb4c2f36bc63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75fc72a98cd15d67e4c908a797549cbe.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Fire-and-Ice-in-the-Whirlpool-Spatially-Resolved-Scaling-Relations-between-X-ray-Emitting-Hot-Gas-and-Cold-Molecular-Gas-in-M51"><a href="#Fire-and-Ice-in-the-Whirlpool-Spatially-Resolved-Scaling-Relations-between-X-ray-Emitting-Hot-Gas-and-Cold-Molecular-Gas-in-M51" class="headerlink" title="Fire and Ice in the Whirlpool: Spatially Resolved Scaling Relations   between X-ray Emitting Hot Gas and Cold Molecular Gas in M51"></a>Fire and Ice in the Whirlpool: Spatially Resolved Scaling Relations   between X-ray Emitting Hot Gas and Cold Molecular Gas in M51</h2><p><strong>Authors:Chunyi Zhang, Junfeng Wang, Tian-Wen Cao</strong></p>
<p>The cold and hot interstellar medium (ISM) in star forming galaxies resembles the reservoir for star formation and associated heating by stellar winds and explosions during stellar evolution, respectively. We utilize data from deep $Chandra$ observations and archival millimeter surveys to study the interconnection between these two phases and the relation to star formation activities in M51 on kiloparsec scales. A sharp radial decrease is present in the hot gas surface brightness profile within the inner 2 kpc of M51. The ratio between the total infrared luminosity ($L_{\rm IR}$) and the hot gas luminosity ($L_{\rm 0.5 - 2,keV}^{\rm gas}$) shows a positive correlation with the galactic radius in the central region. For the entire galaxy, a twofold correlation is revealed in the $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$ diagram, where $L_{\rm 0.5 - 2,keV}^{\rm gas}$ sharply increases with $L_{\rm IR}$ in the center but varies more slowly in the disk. The best fit gives a steep relation of ${\rm log}(L_{\rm 0.5-2,keV}^{\rm gas} &#x2F;{\rm erg,s^{-1}})&#x3D;1.82,{\rm log}(L_{\rm IR} &#x2F;{L_{\rm \odot}})+22.26$ for the center of M51. The similar twofold correlations are also found in the $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$molecular line luminosity ($L^\prime_{\rm gas}$) relations for the four molecular emission lines CO(1-0), CO(2-1), HCN(1-0), and HCO$^+$(1-0). We demonstrate that the core-collapse supernovae (SNe) are the primary source of energy for heating gas in the galactic center of M51, leading to the observed steep $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$ and $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L^\prime_{\rm gas}$ relations, as their X-ray radiation efficiencies ($\eta$ $\equiv$ $L_{\rm 0.5 - 2,keV}^{\rm gas}$&#x2F;$\dot{E}_\mathrm{SN}$) increase with the star formation rate surface densities, where $\dot{E}_\mathrm{SN}$ is the SN mechanical energy input rate. </p>
<blockquote>
<p>星际介质（ISM）在星系形成中起到重要作用，冷热交替状态反映了恒星形成及其演化过程中恒星风和爆炸产生的热量变化。我们利用深度钱德拉观测数据和存档毫米波调查数据来研究这两个阶段之间的联系以及与M51中星形成活动的关系，在千秒尺度上。在M51的2kpc内部区域中，热气体表面亮度分布呈现出明显的径向减少趋势。红外总辐射亮度（$L_{\rm IR}$）和热气体辐射亮度（$L_{\rm 0.5 - 2,keV}^{\rm gas}$）的比率在中心区域与星系半径呈现正相关。对于整个星系而言，在$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$图上呈现双倍的关联性，其中热气体辐射亮度在中心随红外总辐射亮度而急剧增加，但在盘状区域则变化较慢。最佳拟合给出中心区域的陡峭关系为${\rm log}(L_{\rm 0.5-2,keV}^{\rm gas} &#x2F;{\rm erg,s^{-1}})&#x3D;1.82{\rm log}(L_{\rm IR} &#x2F;{L_{\rm \odot}})+22.26$。在四种分子发射线CO（1-0）、CO（2-1）、HCN（1-0）和HCO+（1-0）的辐射中，也发现了类似的气体辐射亮度和分子线辐射亮度的双倍关联关系。我们证明核心坍缩超新星（SNe）是M51星系中心气体加热的主要能量来源，导致了观察到的陡峭的$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$和$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L^\prime_{\rm gas}$关系，因为随着恒星形成率表面密度的增加，其X射线辐射效率($\eta$)也相应增长，其中$\dot{E}_\mathrm{SN}$为超新星的机械能量输入率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01613v1">PDF</a> 10 pages, 6 figures, accepted for publication in the ApJ Letters</p>
<p><strong>Summary</strong><br>    研究发现在星系M51中，冷热气相交介质与恒星形成活动密切相关。利用深度$Chandra$观测数据和毫米波档案调查数据，发现M51内2kpc的热气体表面亮度急剧下降。红外辐射与热气体亮度存在正相关关系，中心区域的关联性尤为显著。中心区域的热气体光度与红外光度之间存在陡峭关系，表明核心崩溃超新星是M51中心气体加热的主要能源来源。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>M51星系中的冷热气相交介质与恒星形成活动紧密相关。</li>
<li>在M51内2kpc区域观察到热气体表面亮度急剧下降。</li>
<li>红外辐射与热气体亮度存在正相关性，这种关系在M51的中心区域尤为显著。</li>
<li>M51中心区域的热气体光度与红外光度之间存在陡峭关系。</li>
<li>核心崩溃超新星是M51中心气体加热的主要能源来源。</li>
<li>超新星的X射线辐射效率随着恒星形成率表面密度的增加而增加。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01613">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b426b3292020ddd0f6e49879cc7ecfcd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2e77d74004d3a6ced455f99b5a2ca970.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bb1a87524c15f908684635f00e548fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cddad9cec43301bdf1c6488d5ecadd26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de446527661191fa495c888222ded58e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d65d398b7355b039d788a047d2d26fe3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PB-UAP-Hybrid-Universal-Adversarial-Attack-For-Image-Segmentation"><a href="#PB-UAP-Hybrid-Universal-Adversarial-Attack-For-Image-Segmentation" class="headerlink" title="PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation"></a>PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation</h2><p><strong>Authors:Yufei Song, Ziqi Zhou, Minghui Li, Xianlong Wang, Hangtao Zhang, Menghao Deng, Wei Wan, Shengshan Hu, Leo Yu Zhang</strong></p>
<p>With the rapid advancement of deep learning, the model robustness has become a significant research hotspot, \ie, adversarial attacks on deep neural networks. Existing works primarily focus on image classification tasks, aiming to alter the model’s predicted labels. Due to the output complexity and deeper network architectures, research on adversarial examples for segmentation models is still limited, particularly for universal adversarial perturbations. In this paper, we propose a novel universal adversarial attack method designed for segmentation models, which includes dual feature separation and low-frequency scattering modules. The two modules guide the training of adversarial examples in the pixel and frequency space, respectively. Experiments demonstrate that our method achieves high attack success rates surpassing the state-of-the-art methods, and exhibits strong transferability across different models. </p>
<blockquote>
<p>随着深度学习的快速发展，模型的稳健性已成为一个重要的研究热点，即对深度神经网络的对抗性攻击。现有工作主要集中在图像分类任务上，旨在改变模型的预测标签。由于输出复杂和网络架构更深，针对分割模型的对抗性示例研究仍然有限，特别是通用对抗性扰动的研究。在本文中，我们提出了一种针对分割模型的新型通用对抗性攻击方法，包括双特征分离和低频散射模块。这两个模块分别在像素和频率空间引导对抗性示例的训练。实验表明，我们的方法实现了高攻击成功率，超越了最先进的方法，并在不同模型之间表现出强大的可迁移性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16651v2">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>随着深度学习技术的飞速发展，模型的稳健性逐渐成为研究热点，特别是针对深度神经网络的对抗性攻击。目前的研究主要关注图像分类任务，旨在改变模型的预测标签。然而，由于输出复杂性和更深的网络架构，针对分割模型的对抗性示例研究仍然有限，特别是通用对抗性扰动的研究。本文提出了一种新型的针对分割模型的通用对抗性攻击方法，包括双特征分离和低频散射模块。这两个模块分别在像素和频率空间指导对抗性示例的训练。实验表明，该方法实现了高攻击成功率，超越了最先进的方法，并在不同模型之间表现出强大的迁移性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习模型的稳健性成为研究热点，对抗性攻击是其中的重要研究方向。</li>
<li>当前研究主要关注图像分类任务的对抗性攻击，改变模型的预测标签。</li>
<li>针对分割模型的对抗性示例研究仍然有限，尤其是通用对抗性扰动的研究。</li>
<li>本文提出了一种新型的通用对抗性攻击方法，包括双特征分离和低频散射模块。</li>
<li>双特征分离模块在像素空间指导对抗性示例的训练。</li>
<li>低频散射模块在频率空间指导对抗性示例的训练。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16651">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d59afa7bdffbecf53700b51c5cd6fc0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-666a2e364bdc3d82cbe2ef77953ce70b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0fa161313acebbfb90cfd30e15094f0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="XLSTM-HVED-Cross-Modal-Brain-Tumor-Segmentation-and-MRI-Reconstruction-Method-Using-Vision-XLSTM-and-Heteromodal-Variational-Encoder-Decoder"><a href="#XLSTM-HVED-Cross-Modal-Brain-Tumor-Segmentation-and-MRI-Reconstruction-Method-Using-Vision-XLSTM-and-Heteromodal-Variational-Encoder-Decoder" class="headerlink" title="XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction   Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder"></a>XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction   Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder</h2><p><strong>Authors:Shenghao Zhu, Yifei Chen, Shuo Jiang, Weihong Chen, Chang Liu, Yuanhan Wang, Xu Chen, Yifan Ke, Feiwei Qin, Changmiao Wang, Zhu Zhu</strong></p>
<p>Neurogliomas are among the most aggressive forms of cancer, presenting considerable challenges in both treatment and monitoring due to their unpredictable biological behavior. Magnetic resonance imaging (MRI) is currently the preferred method for diagnosing and monitoring gliomas. However, the lack of specific imaging techniques often compromises the accuracy of tumor segmentation during the imaging process. To address this issue, we introduce the XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder framework with the Vision XLSTM module to reconstruct missing MRI modalities. By deeply fusing spatial and temporal features, it enhances tumor segmentation performance. The key innovation of our approach is the Self-Attention Variational Encoder (SAVE) module, which improves the integration of modal features. Additionally, it optimizes the interaction of features between segmentation and reconstruction tasks through the Squeeze-Fusion-Excitation Cross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset demonstrate that our model significantly outperforms existing advanced methods in handling cases where modalities are missing. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/Quanato607/XLSTM-HVED">https://github.com/Quanato607/XLSTM-HVED</a>. </p>
<blockquote>
<p>神经胶质瘤是最具侵袭性的癌症形式之一，由于其不可预测的生物行为，为治疗和监测带来了相当大的挑战。目前，磁共振成像（MRI）是诊断和监测胶质瘤的首选方法。然而，缺乏特定的成像技术往往会影响成像过程中肿瘤分割的准确性。为了解决这一问题，我们引入了XLSTM-HVED模型。该模型结合了异模式编码器-解码器框架和Vision XLSTM模块，以重建缺失的MRI模式。通过深度融合空间和时间特征，提高了肿瘤分割的性能。我们的方法的关键创新点是自注意力变分编码器（SAVE）模块，它改进了模式特征的融合。此外，它通过挤压-融合-兴奋交叉意识（SFECA）模块优化了分割和重建任务之间的特征交互。我们使用BraTS 2024数据集进行的实验表明，我们的模型在处理缺失模式的情况时显著优于现有的高级方法。我们的源代码可在<a target="_blank" rel="noopener" href="https://github.com/Quanato607/XLSTM-HVED%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Quanato607/XLSTM-HVED找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07804v2">PDF</a> 5 pages, 2 figures</p>
<p><strong>Summary</strong><br>     神经胶质瘤是最具侵袭性的癌症之一，其生物行为不可预测，为治疗和监测带来重大挑战。当前，磁共振成像（MRI）是诊断和监测胶质瘤的首选方法，但缺乏特定的成像技术，影响肿瘤分割的准确性。为解决这一问题，我们引入了XLSTM-HVED模型。该模型结合异模编码器-解码器框架与Vision XLSTM模块，重建缺失的MRI模式。通过深度融合空间和时间的特征，提高了肿瘤分割的性能。我们的方法的关键创新在于自注意力变分编码器（SAVE）模块，它改进了模态特征的融合。此外，它通过挤压-融合-兴奋交叉意识（SFECA）模块优化了分割和重建任务之间的特征交互。使用BraTS 2024数据集的实验表明，我们的模型在处理缺失模态的情况下显著优于现有高级方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>神经胶质瘤治疗与监测存在挑战，因其生物行为不可预测。</li>
<li>磁共振成像（MRI）是当前诊断和监测胶质瘤的主要手段。</li>
<li>缺乏特定的成像技术会影响肿瘤分割的准确性。</li>
<li>引入的XLSTM-HVED模型通过结合异模编码器-解码器框架与Vision XLSTM模块，旨在解决这一问题。</li>
<li>XLSTM-HVED模型通过深度融合空间和时间的特征，提高了肿瘤分割的性能。</li>
<li>自注意力变分编码器（SAVE）模块是该方法的关键创新点，改进了模态特征的融合。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07804">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-990b3a42569b056e4eccdce75fdef90e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da60db8443b675a68c3c47ba18158641.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-970e1b1c8819dbfa82c0b6a5bd066932.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7ac994a06936a3646fed8efd39998301.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-078694a99b64803abd171ca0ae8cce30.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DINO-LG-A-Task-Specific-DINO-Model-for-Coronary-Calcium-Scoring"><a href="#DINO-LG-A-Task-Specific-DINO-Model-for-Coronary-Calcium-Scoring" class="headerlink" title="DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring"></a>DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring</h2><p><strong>Authors:Mahmut S. Gokmen, Caner Ozcan, Moneera N. Haque, Steve W. Leung, C. Seth Parker, W. Brent Seales, Cody Bumgardner</strong></p>
<p>Coronary artery disease (CAD), one of the leading causes of mortality worldwide, necessitates effective risk assessment strategies, with coronary artery calcium (CAC) scoring via computed tomography (CT) being a key method for prevention. Traditional methods, primarily based on UNET architectures implemented on pre-built models, face challenges like the scarcity of annotated CT scans containing CAC and imbalanced datasets, leading to reduced performance in segmentation and scoring tasks. In this study, we address these limitations by incorporating the self-supervised learning (SSL) technique of DINO (self-distillation with no labels), which trains without requiring CAC-specific annotations, enhancing its robustness in generating distinct features. The DINO-LG model, which leverages label guidance to focus on calcified areas, achieves significant improvements, with a sensitivity of 89% and specificity of 90% for detecting CAC-containing CT slices, compared to the standard DINO model’s sensitivity of 79% and specificity of 77%. Additionally, false-negative and false-positive rates are reduced by 49% and 59%, respectively, instilling greater confidence in clinicians when ruling out calcification in low-risk patients and minimizing unnecessary imaging reviews by radiologists. Further, CAC scoring and segmentation tasks are conducted using a basic UNET architecture, applied specifically to CT slices identified by the DINO-LG model as containing calcified areas. This targeted approach enhances CAC scoring accuracy by feeding the UNET model with relevant slices, significantly improving diagnostic precision, reducing both false positives and false negatives, and ultimately lowering overall healthcare costs by minimizing unnecessary tests and treatments, presenting a valuable advancement in CAD risk assessment. </p>
<blockquote>
<p>冠状动脉疾病（CAD）是全球主要的死亡原因之一，必须进行有效的风险评估策略。计算机断层扫描（CT）中的冠状动脉钙化（CAC）评分是预防的关键方法。传统方法主要基于预构建模型上实施的UNET架构，面临挑战，如含有CAC的标注CT扫描稀缺和数据集不平衡，导致分割和评分任务性能下降。本研究通过融入无监督学习（SSL）技术来解决这些问题，即无需CAC特定标注进行训练的DINO（无标签自我蒸馏）技术，增强了其在生成独特特征方面的稳健性。利用标签指导聚焦于钙化区域的DINO-LG模型，与标准DINO模型相比，检测含有CAC的CT切片的敏感度和特异性分别达到了89%和90%（DINO模型为79%和77%），取得了显著改进。此外，假阴性和假阳性率分别降低了49%和59%，使临床医生在排除低风险患者的钙化情况时有更大的信心，并减少了对放射科医生进行不必要的影像复查的需求。此外，使用基本UNET架构进行CAC评分和分割任务，该架构特定应用于DINO-LG模型识别为含有钙化区域的CT切片。这种有针对性的方法通过向UNET模型提供相关的切片，提高了CAC评分的准确性，从而显著提高了诊断的精确度，减少了假阳性和假阴性结果，并最终通过减少不必要的测试和治疗来降低整体医疗保健成本，为CAD风险评估提供了宝贵的进步。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.07976v6">PDF</a> Developed by Center for Applied Artificial Intelligence (CAAI),   University of Kentucky</p>
<p><strong>Summary</strong></p>
<p>本摘要以汉语简洁表述论文主要内容：针对冠状动脉疾病的风险评估，研究采用无标签自监督学习方法DINO结合标签引导（DINO-LG模型）提升对含钙化区域CT切片的检测性能，通过精准定位钙化区域，提高冠状动脉钙化（CAC）评分和分割任务的准确性，为临床医生提供更可靠的诊断依据，降低误诊率和不必要的影像复查，进而降低整体医疗保健成本。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>冠状动脉疾病（CAD）是全球主要的死亡原因之一，需要有效的风险评估策略。</li>
<li>冠状动脉钙化（CAC）评分是预防CAD的关键方法，但传统方法面临数据标注不足和数据不平衡的挑战。</li>
<li>研究采用无标签自监督学习（SSL）技术中的DINO方法，无需CAC特定标注进行训练，提高了特征生成的稳健性。</li>
<li>DINO结合标签引导（DINO-LG模型）显著提高了检测CAC含钙化区域CT切片的敏感性和特异性。</li>
<li>DINO-LG模型降低了误诊率和不必要的影像复查，增强了医生对低危患者钙化排除的信心。</li>
<li>研究采用基本UNET架构进行CAC评分和分割任务，针对DINO-LG模型识别出的含钙化区域CT切片进行，提高了诊断精度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.07976">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-71fb6de08e48a8dc5221a77766000f42.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8499406100bcced8f388219febe8156f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe8528000a9211cdfa022eaad6078fe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d50a8f66c8afc847f1968b3eaacd6231.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Toward-Robust-Early-Detection-of-Alzheimer’s-Disease-via-an-Integrated-Multimodal-Learning-Approach"><a href="#Toward-Robust-Early-Detection-of-Alzheimer’s-Disease-via-an-Integrated-Multimodal-Learning-Approach" class="headerlink" title="Toward Robust Early Detection of Alzheimer’s Disease via an Integrated   Multimodal Learning Approach"></a>Toward Robust Early Detection of Alzheimer’s Disease via an Integrated   Multimodal Learning Approach</h2><p><strong>Authors:Yifei Chen, Shenghao Zhu, Zhaojie Fang, Chang Liu, Binfeng Zou, Yuhe Wang, Shuo Chang, Fan Jia, Feiwei Qin, Jin Fan, Yong Peng, Changmiao Wang</strong></p>
<p>Alzheimer’s Disease (AD) is a complex neurodegenerative disorder marked by memory loss, executive dysfunction, and personality changes. Early diagnosis is challenging due to subtle symptoms and varied presentations, often leading to misdiagnosis with traditional unimodal diagnostic methods due to their limited scope. This study introduces an advanced multimodal classification model that integrates clinical, cognitive, neuroimaging, and EEG data to enhance diagnostic accuracy. The model incorporates a feature tagger with a tabular data coding architecture and utilizes the TimesBlock module to capture intricate temporal patterns in Electroencephalograms (EEG) data. By employing Cross-modal Attention Aggregation module, the model effectively fuses Magnetic Resonance Imaging (MRI) spatial information with EEG temporal data, significantly improving the distinction between AD, Mild Cognitive Impairment, and Normal Cognition. Simultaneously, we have constructed the first AD classification dataset that includes three modalities: EEG, MRI, and tabular data. Our innovative approach aims to facilitate early diagnosis and intervention, potentially slowing the progression of AD. The source code and our private ADMC dataset are available at <a target="_blank" rel="noopener" href="https://github.com/JustlfC03/MSTNet">https://github.com/JustlfC03/MSTNet</a>. </p>
<blockquote>
<p>阿尔茨海默病（AD）是一种复杂的神经退行性疾病，以记忆丧失、执行功能障碍和个性改变为特征。由于早期症状细微且表现各异，早期诊断具有挑战性，往往使用传统的单一诊断方法会导致误诊，因为它们的应用范围有限。本研究引入了一种先进的跨模态分类模型，该模型融合了临床、认知、神经影像学和脑电图数据，以提高诊断的准确性。该模型采用特征标签器和表格数据编码架构，并使用TimesBlock模块捕捉脑电图（EEG）数据中复杂的时间模式。通过采用跨模态注意力聚合模块，该模型有效地融合了磁共振成像（MRI）的空间信息与EEG的时间数据，显著提高了对阿尔茨海默病、轻度认知障碍和正常认知的区分能力。同时，我们构建了首个包含三种模式（EEG、MRI和表格数据）的AD分类数据集。我们的创新方法旨在促进早期诊断和干预，可能有助于减缓阿尔茨海默病的进展。源代码和我们的私有ADMC数据集可在<a target="_blank" rel="noopener" href="https://github.com/JustlfC03/MSTNet%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/JustlfC03/MSTNet获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.16343v2">PDF</a> 5 pages, 2 figures</p>
<p><strong>Summary</strong><br>     本研究引入了一种先进的多模式分类模型，该模型集成了临床、认知、神经成像和脑电图数据，以提高对阿尔茨海默病（AD）的诊断准确性。通过采用跨模态注意力聚合模块，模型有效融合了磁共振成像（MRI）的空间信息与脑电图（EEG）的时间数据，显著提高了对AD、轻度认知障碍和正常认知的区分能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>阿尔茨海默病（AD）是一种复杂的神经退行性疾病，早期确诊具有挑战性。</li>
<li>传统的一维诊断方法由于局限性，常常导致误诊。</li>
<li>本研究提出了一种多模式分类模型，集成了临床、认知、神经成像和EEG数据，以提高诊断准确性。</li>
<li>模型采用特征标签器和表格数据编码架构。</li>
<li>TimesBlock模块用于捕捉EEG数据中复杂的时间模式。</li>
<li>Cross-modal Attention Aggregation模块有效融合了MRI的空间信息和EEG的时间数据，提高了对AD和其他认知状态的区分能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.16343">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f2c23d9ae917539a080d8348335e3603.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42982eab3747e1aa4151a268fcf139d3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c037be475ed91e82fc2b94b3073009bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cd22b03b42f861a3627028e04f344b8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="CT-AGRG-Automated-Abnormality-Guided-Report-Generation-from-3D-Chest-CT-Volumes"><a href="#CT-AGRG-Automated-Abnormality-Guided-Report-Generation-from-3D-Chest-CT-Volumes" class="headerlink" title="CT-AGRG: Automated Abnormality-Guided Report Generation from 3D Chest CT   Volumes"></a>CT-AGRG: Automated Abnormality-Guided Report Generation from 3D Chest CT   Volumes</h2><p><strong>Authors:Theo Di Piazza</strong></p>
<p>The rapid increase of computed tomography (CT) scans and their time-consuming manual analysis have created an urgent need for robust automated analysis techniques in clinical settings. These aim to assist radiologists and help them managing their growing workload. Existing methods typically generate entire reports directly from 3D CT images, without explicitly focusing on observed abnormalities. This unguided approach often results in repetitive content or incomplete reports, failing to prioritize anomaly-specific descriptions. We propose a new anomaly-guided report generation model, which first predicts abnormalities and then generates targeted descriptions for each. Evaluation on a public dataset demonstrates significant improvements in report quality and clinical relevance. We extend our work by conducting an ablation study to demonstrate its effectiveness. </p>
<blockquote>
<p>计算机断层扫描（CT）扫描的迅速增加及其耗时的人工分析，为临床环境中稳健的自动化分析技术创造了迫切的需求。这些技术的目标是帮助放射科医生处理他们日益增长的工作量。现有方法通常直接从3D CT图像生成整个报告，而没有明确关注观察到的异常情况。这种无导向的方法常常导致内容重复或报告不完整，无法优先提供异常情况的描述。我们提出了一种新的异常导向的报告生成模型，该模型首先预测异常情况，然后为每一个异常情况生成有针对性的描述。在公共数据集上的评估表明，该模型在报告质量和临床相关性方面都有显著提高。我们通过进行消融研究来进一步证明其有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.11965v5">PDF</a> 15 pages, 9 figures, accepted to ISBI 2025</p>
<p><strong>Summary</strong></p>
<p>文中指出CT扫描数量的迅速增加及其手动分析的耗时性，临床环境中对稳健的自动化分析技术有着迫切的需求。现有方法通常直接从3D CT图像生成整个报告，没有特别强调观察到的异常。本文提出了一种新的异常引导报告生成模型，该模型首先预测异常，然后为每个异常生成有针对性的描述。在公共数据集上的评估证明了该模型在报告质量和临床相关性方面的显著提高。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CT扫描数量增加，手动分析耗时，需要自动化分析技术辅助放射科医生处理大量工作。</li>
<li>现有方法直接从3D CT图像生成报告，缺乏重点关注异常。</li>
<li>新的异常引导报告生成模型首先预测异常，然后为每个异常生成描述。</li>
<li>在公共数据集上的评估证明了新模型在报告质量和临床相关性方面的显著提高。</li>
<li>新模型通过生成针对异常的描述，能够减少重复性内容和提高报告的完整性。</li>
<li>该研究通过进行消融研究来展示其模型的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.11965">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ec75bd29ea33c7f314e172def7c6ff2e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ac79443920f63d036961d0395423cd7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e3f8a872ddd6df83d522fdac7ad86ec.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-07/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-07/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">医学图像</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-07/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e262945a140a0fbcdb7ddae1a7741766.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-01-07  VITA-1.5 Towards GPT-4o Level Real-Time Vision and Speech Interaction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-07/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-22796e60db90a6a89c691934e9084105.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-01-07  ACE Anti-Editing Concept Erasure in Text-to-Image Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23154.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
