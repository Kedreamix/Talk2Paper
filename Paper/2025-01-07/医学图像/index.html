<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-07  Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-970e1b1c8819dbfa82c0b6a5bd066932.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-07-æ›´æ–°"><a href="#2025-01-07-æ›´æ–°" class="headerlink" title="2025-01-07 æ›´æ–°"></a>2025-01-07 æ›´æ–°</h1><h2 id="Detecting-and-Mitigating-Adversarial-Attacks-on-Deep-Learning-Based-MRI-Reconstruction-Without-Any-Retraining"><a href="#Detecting-and-Mitigating-Adversarial-Attacks-on-Deep-Learning-Based-MRI-Reconstruction-Without-Any-Retraining" class="headerlink" title="Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining"></a>Detecting and Mitigating Adversarial Attacks on Deep Learning-Based MRI   Reconstruction Without Any Retraining</h2><p><strong>Authors:Mahdi Saberi, Chi Zhang, Mehmet Akcakaya</strong></p>
<p>Deep learning (DL) methods, especially those based on physics-driven DL, have become the state-of-the-art for reconstructing sub-sampled magnetic resonance imaging (MRI) data. However, studies have shown that these methods are susceptible to small adversarial input perturbations, or attacks, resulting in major distortions in the output images. Various strategies have been proposed to reduce the effects of these attacks, but they require retraining and may lower reconstruction quality for non-perturbed&#x2F;clean inputs. In this work, we propose a novel approach for detecting and mitigating adversarial attacks on MRI reconstruction models without any retraining. Our detection strategy is based on the idea of cyclic measurement consistency. The output of the model is mapped to another set of MRI measurements for a different sub-sampling pattern, and this synthesized data is reconstructed with the same model. Intuitively, without an attack, the second reconstruction is expected to be consistent with the first, while with an attack, disruptions are present. Subsequently, this idea is extended to devise a novel objective function, which is minimized within a small ball around the attack input for mitigation. Experimental results show that our method substantially reduces the impact of adversarial perturbations across different datasets, attack types&#x2F;strengths and PD-DL networks, and qualitatively and quantitatively outperforms conventional mitigation methods that involve retraining. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºç‰©ç†é©±åŠ¨çš„DLæ–¹æ³•ï¼Œå·²æˆä¸ºé‡å»ºå­é‡‡æ ·ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ•°æ®çš„æœ€æ–°æŠ€æœ¯ã€‚ç„¶è€Œï¼Œç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æ–¹æ³•å®¹æ˜“å—åˆ°å¾®å°æ•Œå¯¹è¾“å…¥æ‰°åŠ¨æˆ–æ”»å‡»çš„å½±å“ï¼Œå¯¼è‡´è¾“å‡ºå›¾åƒå‡ºç°é‡å¤§å¤±çœŸã€‚è™½ç„¶å·²æå‡ºå„ç§ç­–ç•¥æ¥å‡å°‘è¿™äº›æ”»å‡»çš„å½±å“ï¼Œä½†å®ƒä»¬éœ€è¦é‡æ–°è®­ç»ƒï¼Œå¹¶å¯èƒ½é™ä½å¯¹éæ‰°åŠ¨&#x2F;æ¸…æ´è¾“å…¥çš„é‡å»ºè´¨é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯æ£€æµ‹å’Œå‡è½»MRIé‡å»ºæ¨¡å‹é­å—æ•Œå¯¹æ”»å‡»çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ£€æµ‹ç­–ç•¥åŸºäºå¾ªç¯æµ‹é‡ä¸€è‡´æ€§çš„ç†å¿µã€‚æ¨¡å‹çš„è¾“å‡ºè¢«æ˜ å°„åˆ°å¦ä¸€ç»„MRIæµ‹é‡å€¼ï¼Œç”¨äºä¸åŒçš„å­é‡‡æ ·æ¨¡å¼ï¼Œç„¶åç”¨åŒä¸€æ¨¡å‹é‡å»ºè¿™äº›åˆæˆæ•°æ®ã€‚ç›´è§‚åœ°è¯´ï¼Œåœ¨æ²¡æœ‰æ”»å‡»çš„æƒ…å†µä¸‹ï¼Œç¬¬äºŒæ¬¡é‡å»ºåº”ä¸ç¬¬ä¸€æ¬¡é‡å»ºä¸€è‡´ï¼Œè€Œå—åˆ°æ”»å‡»æ—¶åˆ™ä¼šå‡ºç°å¹²æ‰°ã€‚éšåï¼Œå°†è¿™ä¸ªç†å¿µæ‰©å±•åˆ°ä¸€ä¸ªæ–°çš„ç›®æ ‡å‡½æ•°ä¸­ï¼Œé€šè¿‡æœ€å°åŒ–æ”»å‡»è¾“å…¥å‘¨å›´å°èŒƒå›´å†…çš„è¯¥å‡½æ•°æ¥å‡è½»æ”»å‡»å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§å‡å°‘äº†ä¸åŒæ•°æ®é›†ã€æ”»å‡»ç±»å‹å’Œå¼ºåº¦ä»¥åŠPD-DLç½‘ç»œä¸­çš„æ•Œå¯¹æ‰°åŠ¨çš„å½±å“ï¼Œå¹¶ä¸”åœ¨å®šæ€§å’Œå®šé‡ä¸Šå‡ä¼˜äºæ¶‰åŠé‡æ–°è®­ç»ƒçš„ä¼ ç»Ÿç¼“è§£æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01908v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰åœ¨é‡å»ºå­é‡‡æ ·ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ•°æ®æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå°¤å…¶æ˜¯åŸºäºç‰©ç†é©±åŠ¨çš„DLæ–¹æ³•ã€‚ç„¶è€Œï¼Œç ”ç©¶è¡¨æ˜è¿™äº›æ–¹æ³•å®¹æ˜“å—åˆ°å°å‹çš„å¯¹æŠ—æ€§è¾“å…¥æ‰°åŠ¨æˆ–æ”»å‡»çš„å½±å“ï¼Œå¯¼è‡´è¾“å‡ºå›¾åƒå‡ºç°é‡å¤§å¤±çœŸã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯æ£€æµ‹å’Œå‡è½»MRIé‡å»ºæ¨¡å‹å¯¹æŠ—æ€§æ”»å‡»çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŸºäºå¾ªç¯æµ‹é‡ä¸€è‡´æ€§æ£€æµ‹ç­–ç•¥ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯å…¶èƒ½æœ‰æ•ˆå‡å°‘ä¸åŒæ•°æ®é›†ã€æ”»å‡»ç±»å‹å’Œå¼ºåº¦ä»¥åŠéƒ¨åˆ†ç‰©ç†é©±åŠ¨DLç½‘ç»œä¸­çš„å¯¹æŠ—æ€§æ‰°åŠ¨å½±å“ï¼Œå¹¶åœ¨å®šæ€§å’Œå®šé‡ä¸Šä¼˜äºæ¶‰åŠé‡æ–°è®­ç»ƒçš„å¸¸è§„ç¼“è§£æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨MRIæ•°æ®é‡å»ºä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯ç‰©ç†é©±åŠ¨DLæ–¹æ³•ã€‚</li>
<li>DLæ–¹æ³•å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§è¾“å…¥æ‰°åŠ¨æˆ–æ”»å‡»çš„å½±å“ï¼Œå¯¼è‡´è¾“å‡ºå›¾åƒå¤±çœŸã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒçš„æ–°æ–¹æ³•ï¼Œç”¨äºæ£€æµ‹å’Œå‡è½»MRIé‡å»ºæ¨¡å‹çš„å¯¹æŠ—æ€§æ”»å‡»ã€‚</li>
<li>è¯¥æ–¹æ³•åŸºäºå¾ªç¯æµ‹é‡ä¸€è‡´æ€§æ£€æµ‹ç­–ç•¥ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå‡å°‘ä¸åŒæ•°æ®é›†ã€æ”»å‡»ç±»å‹å’Œå¼ºåº¦ä¸­çš„å¯¹æŠ—æ€§æ‰°åŠ¨å½±å“ã€‚</li>
<li>ä¸å¸¸è§„éœ€è¦é‡æ–°è®­ç»ƒçš„ç¼“è§£æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºä¸åŒçš„MRIé‡å»ºæ¨¡å‹å’Œæƒ…å¢ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01908">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-494f2270d29451caf9b59b6781f35edf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4af73b9dddc124c06a3d1b52577f7fe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a40a89da48e558cfc8550c0f8bf0705c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2f9b425e01172e94bbb73ef3ab4e97c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b54dd2e74f8dcdea6f89e12265683aa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a784e6e5f5e8b473b5385e719de0552.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Augmentation-Matters-A-Mix-Paste-Method-for-X-Ray-Prohibited-Item-Detection-under-Noisy-Annotations"><a href="#Augmentation-Matters-A-Mix-Paste-Method-for-X-Ray-Prohibited-Item-Detection-under-Noisy-Annotations" class="headerlink" title="Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item   Detection under Noisy Annotations"></a>Augmentation Matters: A Mix-Paste Method for X-Ray Prohibited Item   Detection under Noisy Annotations</h2><p><strong>Authors:Ruikang Chen, Yan Yan, Jing-Hao Xue, Yang Lu, Hanzi Wang</strong></p>
<p>Automatic X-ray prohibited item detection is vital for public safety. Existing deep learning-based methods all assume that the annotations of training X-ray images are correct. However, obtaining correct annotations is extremely hard if not impossible for large-scale X-ray images, where item overlapping is ubiquitous.As a result, X-ray images are easily contaminated with noisy annotations, leading to performance deterioration of existing methods.In this paper, we address the challenging problem of training a robust prohibited item detector under noisy annotations (including both category noise and bounding box noise) from a novel perspective of data augmentation, and propose an effective label-aware mixed patch paste augmentation method (Mix-Paste). Specifically, for each item patch, we mix several item patches with the same category label from different images and replace the original patch in the image with the mixed patch. In this way, the probability of containing the correct prohibited item within the generated image is increased. Meanwhile, the mixing process mimics item overlapping, enabling the model to learn the characteristics of X-ray images. Moreover, we design an item-based large-loss suppression (LLS) strategy to suppress the large losses corresponding to potentially positive predictions of additional items due to the mixing operation. We show the superiority of our method on X-ray datasets under noisy annotations. In addition, we evaluate our method on the noisy MS-COCO dataset to showcase its generalization ability. These results clearly indicate the great potential of data augmentation to handle noise annotations. The source code is released at <a target="_blank" rel="noopener" href="https://github.com/wscds/Mix-Paste">https://github.com/wscds/Mix-Paste</a>. </p>
<blockquote>
<p>è‡ªåŠ¨Xå°„çº¿è¿ç¦å“æ£€æµ‹å¯¹å…¬å…±å®‰å…¨è‡³å…³é‡è¦ã€‚ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•éƒ½å‡è®¾è®­ç»ƒXå°„çº¿å›¾åƒçš„æ³¨é‡Šæ˜¯æ­£ç¡®çš„ã€‚ç„¶è€Œï¼Œå¯¹äºå¤§è§„æ¨¡çš„Xå°„çº¿å›¾åƒï¼Œç”±äºç‰©å“é‡å æ™®éå­˜åœ¨ï¼Œè·å–æ­£ç¡®çš„æ³¨é‡Šæå…¶å›°éš¾ç”šè‡³ä¸å¯èƒ½ã€‚å› æ­¤ï¼ŒXå°„çº¿å›¾åƒå¾ˆå®¹æ˜“å—åˆ°å¸¦æœ‰å™ªå£°çš„æ³¨é‡Šçš„æ±¡æŸ“ï¼Œå¯¼è‡´ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ä¸‹é™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01733v1">PDF</a> The manuscript has been ACCEPTED for publication as a regular paper   in the IEEE Transactions on Information Forensics &amp; Security</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨Xå°„çº¿è¿ç¦ç‰©å“æ£€æµ‹åœ¨å­˜åœ¨å™ªå£°æ ‡æ³¨çš„æƒ…å†µä¸‹æ€§èƒ½ä¼šä¸‹é™ã€‚æœ¬æ–‡åˆ›æ–°æ€§åœ°ä»æ•°æ®å¢å¼ºè§’åº¦è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæå‡ºä¸€ç§æ ‡ç­¾æ„ŸçŸ¥æ··åˆè¡¥ä¸ç²˜è´´å¢å¼ºæ–¹æ³•ï¼ˆMix-Pasteï¼‰ï¼Œé€šè¿‡æ··åˆç›¸åŒç±»åˆ«æ ‡ç­¾çš„ç‰©å“è¡¥ä¸ï¼Œå¢åŠ ç”Ÿæˆå›¾åƒä¸­åŒ…å«æ­£ç¡®è¿ç¦ç‰©å“çš„æ¦‚ç‡ï¼ŒåŒæ—¶æ¨¡ä»¿ç‰©å“é‡å æƒ…å†µï¼Œä½¿æ¨¡å‹å­¦ä¹ Xå°„çº¿å›¾åƒçš„ç‰¹æ€§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€é¡¹åŸºäºç‰©å“çš„è¾ƒå¤§æŸå¤±æŠ‘åˆ¶ç­–ç•¥ï¼Œä»¥æŠ‘åˆ¶å› æ··åˆæ“ä½œäº§ç”Ÿçš„å…¶ä»–æ½œåœ¨é˜³æ€§é¢„æµ‹ç‰©å“çš„è¾ƒå¤§æŸå¤±ã€‚è¯¥ç­–ç•¥åœ¨å¤„ç†å¸¦æœ‰å™ªå£°æ ‡æ³¨çš„Xå°„çº¿æ•°æ®é›†ä¸Šè¡¨ç°å“è¶Šï¼Œå¹¶åœ¨å™ªå£°MS-COCOæ•°æ®é›†ä¸Šè¯„ä¼°å±•ç¤ºå…¶æ³›åŒ–èƒ½åŠ›ã€‚æ•°æ®å¢å¼ºåœ¨åº”å¯¹å™ªå£°æ ‡æ³¨æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è‡ªåŠ¨Xå°„çº¿è¿ç¦ç‰©å“æ£€æµ‹å¯¹å…¬å…±å®‰å…¨è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•å‡è®¾è®­ç»ƒXå…‰å›¾åƒçš„æ³¨é‡Šæ˜¯æ­£ç¡®çš„ï¼Œä½†åœ¨å¤§è§„æ¨¡å›¾åƒä¸­è·å¾—æ­£ç¡®æ³¨é‡Šæå…¶å›°éš¾ã€‚</li>
<li>Mix-Pasteæ–¹æ³•é€šè¿‡æ•°æ®å¢å¼ºè§£å†³å™ªå£°æ ‡æ³¨é—®é¢˜ï¼Œæé«˜æ¨¡å‹å¯¹Xå…‰å›¾åƒä¸­è¿ç¦ç‰©å“çš„è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>Mix-Pasteæ–¹æ³•æ··åˆç›¸åŒç±»åˆ«æ ‡ç­¾çš„ç‰©å“è¡¥ä¸ï¼Œå¢åŠ ç”Ÿæˆå›¾åƒçš„æ­£ç¡®ç‡å¹¶æ¨¡ä»¿ç‰©å“é‡å æƒ…å†µã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºç‰©å“çš„è¾ƒå¤§æŸå¤±æŠ‘åˆ¶ç­–ç•¥ï¼Œä»¥å¤„ç†å› æ··åˆæ“ä½œäº§ç”Ÿçš„æ½œåœ¨é˜³æ€§é¢„æµ‹ç‰©å“ã€‚</li>
<li>æ–¹æ³•åœ¨å¸¦æœ‰å™ªå£°æ ‡æ³¨çš„Xå°„çº¿æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå¹¶åœ¨å™ªå£°MS-COCOæ•°æ®é›†ä¸Šè¯„ä¼°å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01733">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-12328be63ccd63faefdb7d24e904f70e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5a33b39f2106739fca0ce619cbb21f2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EAUWSeg-Eliminating-annotation-uncertainty-in-weakly-supervised-medical-image-segmentation"><a href="#EAUWSeg-Eliminating-annotation-uncertainty-in-weakly-supervised-medical-image-segmentation" class="headerlink" title="EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical   image segmentation"></a>EAUWSeg: Eliminating annotation uncertainty in weakly-supervised medical   image segmentation</h2><p><strong>Authors:Wang Lituan, Zhang Lei, Wang Yan, Wang Zhenbin, Zhang Zhenwei, Zhang Yi</strong></p>
<p>Weakly-supervised medical image segmentation is gaining traction as it requires only rough annotations rather than accurate pixel-to-pixel labels, thereby reducing the workload for specialists. Although some progress has been made, there is still a considerable performance gap between the label-efficient methods and fully-supervised one, which can be attributed to the uncertainty nature of these weak labels. To address this issue, we propose a novel weak annotation method coupled with its learning framework EAUWSeg to eliminate the annotation uncertainty. Specifically, we first propose the Bounded Polygon Annotation (BPAnno) by simply labeling two polygons for a lesion. Then, the tailored learning mechanism that explicitly treat bounded polygons as two separated annotations is proposed to learn invariant feature by providing adversarial supervision signal for model training. Subsequently, a confidence-auxiliary consistency learner incorporates with a classification-guided confidence generator is designed to provide reliable supervision signal for pixels in uncertain region by leveraging the feature presentation consistency across pixels within the same category as well as class-specific information encapsulated in bounded polygons annotation. Experimental results demonstrate that EAUWSeg outperforms existing weakly-supervised segmentation methods. Furthermore, compared to fully-supervised counterparts, the proposed method not only delivers superior performance but also costs much less annotation workload. This underscores the superiority and effectiveness of our approach. </p>
<blockquote>
<p>å¼±ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²æ­£å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ï¼Œå› ä¸ºå®ƒåªéœ€è¦ç²—ç•¥çš„æ³¨é‡Šï¼Œè€Œä¸éœ€è¦ç²¾ç¡®çš„åƒç´ åˆ°åƒç´ çš„æ ‡ç­¾ï¼Œä»è€Œå‡å°‘äº†ä¸“å®¶çš„å·¥ä½œé‡ã€‚è™½ç„¶å·²å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†æ ‡ç­¾æ•ˆç‡é«˜çš„æ–¹æ³•ä¸å…¨ç›‘ç£æ–¹æ³•ä¹‹é—´çš„æ€§èƒ½å·®è·ä»ç„¶å¾ˆå¤§ï¼Œè¿™å¯ä»¥å½’å› äºè¿™äº›å¼±æ ‡ç­¾çš„ä¸ç¡®å®šæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¼±æ ‡æ³¨æ–¹æ³•åŠå…¶å­¦ä¹ æ¡†æ¶EAUWSegï¼Œä»¥æ¶ˆé™¤æ ‡æ³¨çš„ä¸ç¡®å®šæ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºæœ‰ç•Œå¤šè¾¹å½¢æ³¨é‡Šï¼ˆBPAnnoï¼‰ï¼Œåªéœ€ä¸ºç—…å˜æ ‡æ³¨ä¸¤ä¸ªå¤šè¾¹å½¢ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å®šåˆ¶çš„å­¦ä¹ æœºåˆ¶ï¼Œå°†å¤šè¾¹å½¢æ˜ç¡®åœ°è§†ä¸ºä¸¤ä¸ªå•ç‹¬çš„æ³¨é‡Šè¿›è¡Œå¤„ç†ï¼Œé€šè¿‡ä¸ºæ¨¡å‹è®­ç»ƒæä¾›å¯¹æŠ—æ€§ç›‘ç£ä¿¡å·æ¥å­¦ä¹ ä¸å˜ç‰¹å¾ã€‚éšåï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸åˆ†ç±»å¼•å¯¼ç½®ä¿¡åº¦ç”Ÿæˆå™¨ç›¸ç»“åˆçš„ç½®ä¿¡è¾…åŠ©ä¸€è‡´æ€§å­¦ä¹ è€…ï¼Œé€šè¿‡åˆ©ç”¨åŒä¸€ç±»åˆ«å†…åƒç´ ä¹‹é—´çš„ç‰¹å¾è¡¨ç¤ºä¸€è‡´æ€§ä»¥åŠåŒ…å«åœ¨è¾¹ç•Œå¤šè¾¹å½¢æ³¨é‡Šä¸­çš„ç±»åˆ«ç‰¹å®šä¿¡æ¯ï¼Œä¸ºä¸ç¡®å®šåŒºåŸŸçš„åƒç´ æä¾›å¯é çš„ç›‘ç£ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEAUWSegä¼˜äºç°æœ‰çš„å¼±ç›‘ç£åˆ†å‰²æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä¸å…¨ç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸ä»…æ€§èƒ½ä¼˜è¶Šï¼Œè€Œä¸”å¤§å¤§å‡å°‘äº†æ ‡æ³¨å·¥ä½œé‡ã€‚è¿™å‡¸æ˜¾äº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œæœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01658v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­ï¼Œå¼±ç›‘ç£æ–¹æ³•å› ä»…éœ€ç²—ç•¥æ ‡æ³¨è€Œå¤‡å—å…³æ³¨ï¼Œä½†å­˜åœ¨æ€§èƒ½å·®è·ã€‚ä¸ºæ­¤ï¼Œæå‡ºä¸€ç§æ–°å‹å¼±æ ‡æ³¨æ–¹æ³•ä¸å­¦ä¹ æ¡†æ¶EAUWSegï¼Œé€šè¿‡Bounded Polygon Annotationï¼ˆBPAnnoï¼‰å’Œå¯¹æŠ—æ€§ç›‘ç£ä¿¡å·æ¶ˆé™¤æ ‡æ³¨ä¸ç¡®å®šæ€§ï¼Œè®¾è®¡ä¿¡å¿ƒè¾…åŠ©ä¸€è‡´æ€§å­¦ä¹ è€…ï¼Œæä¾›å¯é ç›‘ç£ä¿¡å·ã€‚å®éªŒæ˜¾ç¤ºï¼ŒEAUWSegä¼˜äºç°æœ‰å¼±ç›‘ç£æ–¹æ³•ï¼Œä¸å…¨ç›‘ç£æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½ä¼˜è¶Šä¸”æ ‡æ³¨å·¥ä½œé‡æ›´å°‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼±ç›‘ç£åŒ»å­¦å›¾åƒåˆ†å‰²å› å‡å°‘ä¸“å®¶å·¥ä½œé‡è€Œå—å…³æ³¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨æ€§èƒ½å·®è·ï¼Œä¸»è¦æºäºå¼±æ ‡æ³¨çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>æå‡ºæ–°å‹å¼±æ ‡æ³¨æ–¹æ³•BPAnnoå’Œå­¦ä¹ æ¡†æ¶EAUWSegã€‚</li>
<li>BPAnnoé€šè¿‡ä»…æ ‡æ³¨ä¸¤ä¸ªå¤šè¾¹å½¢æ¥ä»£è¡¨ç—…ç¶ã€‚</li>
<li>EAUWSegåˆ©ç”¨å¯¹æŠ—æ€§ç›‘ç£ä¿¡å·å­¦ä¹ ä¸å˜ç‰¹å¾ã€‚</li>
<li>ä¿¡å¿ƒè¾…åŠ©ä¸€è‡´æ€§å­¦ä¹ è€…æä¾›å¯é ç›‘ç£ä¿¡å·ï¼Œå°¤å…¶é’ˆå¯¹ä¸ç¡®å®šåŒºåŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01658">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-72b853ce257783f27ce8963f216bbbe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37c695bf284ea3a0bd79913fc4e7ee04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d01edef42f0d03893153f4ec586be0f7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-25227b8c5425e3d476ccbb6736c5e487.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Merging-Context-Clustering-with-Visual-State-Space-Models-for-Medical-Image-Segmentation"><a href="#Merging-Context-Clustering-with-Visual-State-Space-Models-for-Medical-Image-Segmentation" class="headerlink" title="Merging Context Clustering with Visual State Space Models for Medical   Image Segmentation"></a>Merging Context Clustering with Visual State Space Models for Medical   Image Segmentation</h2><p><strong>Authors:Yun Zhu, Dong Zhang, Yi Lin, Yifei Feng, Jinhui Tang</strong></p>
<p>Medical image segmentation demands the aggregation of global and local feature representations, posing a challenge for current methodologies in handling both long-range and short-range feature interactions. Recently, vision mamba (ViM) models have emerged as promising solutions for addressing model complexities by excelling in long-range feature iterations with linear complexity. However, existing ViM approaches overlook the importance of preserving short-range local dependencies by directly flattening spatial tokens and are constrained by fixed scanning patterns that limit the capture of dynamic spatial context information. To address these challenges, we introduce a simple yet effective method named context clustering ViM (CCViM), which incorporates a context clustering module within the existing ViM models to segment image tokens into distinct windows for adaptable local clustering. Our method effectively combines long-range and short-range feature interactions, thereby enhancing spatial contextual representations for medical image segmentation tasks. Extensive experimental evaluations on diverse public datasets, i.e., Kumar, CPM17, ISIC17, ISIC18, and Synapse demonstrate the superior performance of our method compared to current state-of-the-art methods. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM">https://github.com/zymissy/CCViM</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²è¦æ±‚å…¨å±€å’Œå±€éƒ¨ç‰¹å¾è¡¨ç¤ºçš„èšåˆï¼Œè¿™å¯¹å½“å‰æ–¹æ³•å¤„ç†é•¿ç¨‹å’ŒçŸ­ç¨‹ç‰¹å¾äº¤äº’æå‡ºäº†æŒ‘æˆ˜ã€‚æœ€è¿‘ï¼Œè§†è§‰å¦ˆå¦ˆï¼ˆViMï¼‰æ¨¡å‹ä»¥çº¿æ€§å¤æ‚åº¦çš„é•¿ç¨‹ç‰¹å¾è¿­ä»£èƒ½åŠ›çªå‡ºï¼Œæˆä¸ºè§£å†³æ¨¡å‹å¤æ‚æ€§çš„æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç°æœ‰çš„ViMæ–¹æ³•é€šè¿‡ç›´æ¥å¹³é“ºç©ºé—´ä»¤ç‰Œè€Œå¿½ç•¥äº†ä¿æŒçŸ­ç¨‹å±€éƒ¨ä¾èµ–å…³ç³»çš„é‡è¦æ€§ï¼Œå¹¶ä¸”å—åˆ°å›ºå®šæ‰«ææ¨¡å¼çš„çº¦æŸï¼Œé™åˆ¶äº†åŠ¨æ€ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•è·ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç§°ä¸ºä¸Šä¸‹æ–‡èšç±»ViMï¼ˆCCViMï¼‰ï¼Œè¯¥æ–¹æ³•åœ¨ç°æœ‰çš„ViMæ¨¡å‹å†…å¼•å…¥äº†ä¸€ä¸ªä¸Šä¸‹æ–‡èšç±»æ¨¡å—ï¼Œç”¨äºå°†å›¾åƒä»¤ç‰Œåˆ†å‰²æˆä¸åŒçš„çª—å£è¿›è¡Œè‡ªé€‚åº”å±€éƒ¨èšç±»ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ç»“åˆäº†é•¿ç¨‹å’ŒçŸ­ç¨‹ç‰¹å¾äº¤äº’ï¼Œä»è€Œå¢å¼ºäº†åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ç©ºé—´è¡¨ç¤ºã€‚åœ¨Kumarã€CPM17ã€ISIC17ã€ISIC18å’ŒSynapseç­‰å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM%E3%80%82">https://github.com/zymissy/CCViMã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01618v1">PDF</a> Our paper has been accepted by the IEEE Transactions on Medical   Imaging. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM">https://github.com/zymissy/CCViM</a></p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒåˆ†å‰²éœ€è¦èåˆå…¨å±€å’Œå±€éƒ¨ç‰¹å¾è¡¨ç¤ºï¼Œè¿™å¯¹å½“å‰æ–¹æ³•å¤„ç†é•¿ç¨‹å’ŒçŸ­ç¨‹ç‰¹å¾äº¤äº’æå‡ºäº†æŒ‘æˆ˜ã€‚æ–°å‹çš„è§†è§‰mambaï¼ˆViMï¼‰æ¨¡å‹ä»¥å¤„ç†é•¿ç¨‹ç‰¹å¾äº¤äº’çš„çº¿æ€§å¤æ‚åº¦ä¸ºä¼˜åŠ¿ï¼Œåº”å¯¹æ¨¡å‹å¤æ‚æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰ViMæ–¹æ³•å¿½ç•¥äº†ä¿æŒçŸ­ç¨‹å±€éƒ¨ä¾èµ–æ€§çš„é‡è¦æ€§ï¼Œé€šè¿‡ç›´æ¥æ‰å¹³åŒ–ç©ºé—´ä»¤ç‰Œå—åˆ°å›ºå®šæ‰«ææ¨¡å¼çš„çº¦æŸï¼Œé™åˆ¶äº†åŠ¨æ€ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•è·ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•â€”â€”ä¸Šä¸‹æ–‡èšç±»ViMï¼ˆCCViMï¼‰ï¼Œåœ¨ç°æœ‰ViMæ¨¡å‹ä¸­å¼•å…¥ä¸Šä¸‹æ–‡èšç±»æ¨¡å—ï¼Œå¯¹å›¾åƒä»¤ç‰Œè¿›è¡Œå¯é€‚åº”çš„å±€éƒ¨èšç±»ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ç»“åˆäº†é•¿ç¨‹å’ŒçŸ­ç¨‹ç‰¹å¾äº¤äº’ï¼Œä»è€Œæå‡åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡çš„ç©ºé—´ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚åœ¨Kumarã€CPM17ã€ISIC17ã€ISIC18å’ŒSynapseç­‰å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²éœ€è¦å…¼é¡¾å…¨å±€å’Œå±€éƒ¨ç‰¹å¾è¡¨ç¤ºï¼Œå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>è§†è§‰mambaï¼ˆViMï¼‰æ¨¡å‹èƒ½å¤„ç†é•¿ç¨‹ç‰¹å¾äº¤äº’ï¼Œä½†å¿½è§†çŸ­ç¨‹å±€éƒ¨ä¾èµ–æ€§ã€‚</li>
<li>ç°æœ‰ViMæ–¹æ³•é€šè¿‡ç›´æ¥æ‰å¹³åŒ–ç©ºé—´ä»¤ç‰Œå—åˆ°å›ºå®šæ‰«ææ¨¡å¼çš„çº¦æŸã€‚</li>
<li>ä¸Šä¸‹æ–‡èšç±»ViMï¼ˆCCViMï¼‰ç»“åˆé•¿ç¨‹å’ŒçŸ­ç¨‹ç‰¹å¾äº¤äº’ã€‚</li>
<li>CCViMé€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡èšç±»æ¨¡å—ï¼Œå¯¹å›¾åƒä»¤ç‰Œè¿›è¡Œå¯é€‚åº”çš„å±€éƒ¨èšç±»ã€‚</li>
<li>CCViMåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ç›¸å…³ä»£ç å·²ä¸Šä¼ è‡³GitHubï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/zymissy/CCViM%EF%BC%89%E3%80%82">https://github.com/zymissy/CCViMï¼‰ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01618">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-538a1211dd7c735f23e3459f29d382fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89720c2dc084f734168b39856cda0b31.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ac293990c9267c8608f7542d4d4e9d0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65ce41d6e3dd788a3ad6eb4c2f36bc63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75fc72a98cd15d67e4c908a797549cbe.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Fire-and-Ice-in-the-Whirlpool-Spatially-Resolved-Scaling-Relations-between-X-ray-Emitting-Hot-Gas-and-Cold-Molecular-Gas-in-M51"><a href="#Fire-and-Ice-in-the-Whirlpool-Spatially-Resolved-Scaling-Relations-between-X-ray-Emitting-Hot-Gas-and-Cold-Molecular-Gas-in-M51" class="headerlink" title="Fire and Ice in the Whirlpool: Spatially Resolved Scaling Relations   between X-ray Emitting Hot Gas and Cold Molecular Gas in M51"></a>Fire and Ice in the Whirlpool: Spatially Resolved Scaling Relations   between X-ray Emitting Hot Gas and Cold Molecular Gas in M51</h2><p><strong>Authors:Chunyi Zhang, Junfeng Wang, Tian-Wen Cao</strong></p>
<p>The cold and hot interstellar medium (ISM) in star forming galaxies resembles the reservoir for star formation and associated heating by stellar winds and explosions during stellar evolution, respectively. We utilize data from deep $Chandra$ observations and archival millimeter surveys to study the interconnection between these two phases and the relation to star formation activities in M51 on kiloparsec scales. A sharp radial decrease is present in the hot gas surface brightness profile within the inner 2 kpc of M51. The ratio between the total infrared luminosity ($L_{\rm IR}$) and the hot gas luminosity ($L_{\rm 0.5 - 2,keV}^{\rm gas}$) shows a positive correlation with the galactic radius in the central region. For the entire galaxy, a twofold correlation is revealed in the $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$ diagram, where $L_{\rm 0.5 - 2,keV}^{\rm gas}$ sharply increases with $L_{\rm IR}$ in the center but varies more slowly in the disk. The best fit gives a steep relation of ${\rm log}(L_{\rm 0.5-2,keV}^{\rm gas} &#x2F;{\rm erg,s^{-1}})&#x3D;1.82,{\rm log}(L_{\rm IR} &#x2F;{L_{\rm \odot}})+22.26$ for the center of M51. The similar twofold correlations are also found in the $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$molecular line luminosity ($L^\prime_{\rm gas}$) relations for the four molecular emission lines CO(1-0), CO(2-1), HCN(1-0), and HCO$^+$(1-0). We demonstrate that the core-collapse supernovae (SNe) are the primary source of energy for heating gas in the galactic center of M51, leading to the observed steep $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$ and $L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L^\prime_{\rm gas}$ relations, as their X-ray radiation efficiencies ($\eta$ $\equiv$ $L_{\rm 0.5 - 2,keV}^{\rm gas}$&#x2F;$\dot{E}_\mathrm{SN}$) increase with the star formation rate surface densities, where $\dot{E}_\mathrm{SN}$ is the SN mechanical energy input rate. </p>
<blockquote>
<p>æ˜Ÿé™…ä»‹è´¨ï¼ˆISMï¼‰åœ¨æ˜Ÿç³»å½¢æˆä¸­èµ·åˆ°é‡è¦ä½œç”¨ï¼Œå†·çƒ­äº¤æ›¿çŠ¶æ€åæ˜ äº†æ’æ˜Ÿå½¢æˆåŠå…¶æ¼”åŒ–è¿‡ç¨‹ä¸­æ’æ˜Ÿé£å’Œçˆ†ç‚¸äº§ç”Ÿçš„çƒ­é‡å˜åŒ–ã€‚æˆ‘ä»¬åˆ©ç”¨æ·±åº¦é’±å¾·æ‹‰è§‚æµ‹æ•°æ®å’Œå­˜æ¡£æ¯«ç±³æ³¢è°ƒæŸ¥æ•°æ®æ¥ç ”ç©¶è¿™ä¸¤ä¸ªé˜¶æ®µä¹‹é—´çš„è”ç³»ä»¥åŠä¸M51ä¸­æ˜Ÿå½¢æˆæ´»åŠ¨çš„å…³ç³»ï¼Œåœ¨åƒç§’å°ºåº¦ä¸Šã€‚åœ¨M51çš„2kpcå†…éƒ¨åŒºåŸŸä¸­ï¼Œçƒ­æ°”ä½“è¡¨é¢äº®åº¦åˆ†å¸ƒå‘ˆç°å‡ºæ˜æ˜¾çš„å¾„å‘å‡å°‘è¶‹åŠ¿ã€‚çº¢å¤–æ€»è¾å°„äº®åº¦ï¼ˆ$L_{\rm IR}$ï¼‰å’Œçƒ­æ°”ä½“è¾å°„äº®åº¦ï¼ˆ$L_{\rm 0.5 - 2,keV}^{\rm gas}$ï¼‰çš„æ¯”ç‡åœ¨ä¸­å¿ƒåŒºåŸŸä¸æ˜Ÿç³»åŠå¾„å‘ˆç°æ­£ç›¸å…³ã€‚å¯¹äºæ•´ä¸ªæ˜Ÿç³»è€Œè¨€ï¼Œåœ¨$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$å›¾ä¸Šå‘ˆç°åŒå€çš„å…³è”æ€§ï¼Œå…¶ä¸­çƒ­æ°”ä½“è¾å°„äº®åº¦åœ¨ä¸­å¿ƒéšçº¢å¤–æ€»è¾å°„äº®åº¦è€Œæ€¥å‰§å¢åŠ ï¼Œä½†åœ¨ç›˜çŠ¶åŒºåŸŸåˆ™å˜åŒ–è¾ƒæ…¢ã€‚æœ€ä½³æ‹Ÿåˆç»™å‡ºä¸­å¿ƒåŒºåŸŸçš„é™¡å³­å…³ç³»ä¸º${\rm log}(L_{\rm 0.5-2,keV}^{\rm gas} &#x2F;{\rm erg,s^{-1}})&#x3D;1.82{\rm log}(L_{\rm IR} &#x2F;{L_{\rm \odot}})+22.26$ã€‚åœ¨å››ç§åˆ†å­å‘å°„çº¿COï¼ˆ1-0ï¼‰ã€COï¼ˆ2-1ï¼‰ã€HCNï¼ˆ1-0ï¼‰å’ŒHCO+ï¼ˆ1-0ï¼‰çš„è¾å°„ä¸­ï¼Œä¹Ÿå‘ç°äº†ç±»ä¼¼çš„æ°”ä½“è¾å°„äº®åº¦å’Œåˆ†å­çº¿è¾å°„äº®åº¦çš„åŒå€å…³è”å…³ç³»ã€‚æˆ‘ä»¬è¯æ˜æ ¸å¿ƒåç¼©è¶…æ–°æ˜Ÿï¼ˆSNeï¼‰æ˜¯M51æ˜Ÿç³»ä¸­å¿ƒæ°”ä½“åŠ çƒ­çš„ä¸»è¦èƒ½é‡æ¥æºï¼Œå¯¼è‡´äº†è§‚å¯Ÿåˆ°çš„é™¡å³­çš„$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L_{\rm IR}$å’Œ$L_{\rm 0.5 - 2,keV}^{\rm gas}$${-}$$L^\prime_{\rm gas}$å…³ç³»ï¼Œå› ä¸ºéšç€æ’æ˜Ÿå½¢æˆç‡è¡¨é¢å¯†åº¦çš„å¢åŠ ï¼Œå…¶Xå°„çº¿è¾å°„æ•ˆç‡($\eta$)ä¹Ÿç›¸åº”å¢é•¿ï¼Œå…¶ä¸­$\dot{E}_\mathrm{SN}$ä¸ºè¶…æ–°æ˜Ÿçš„æœºæ¢°èƒ½é‡è¾“å…¥ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01613v1">PDF</a> 10 pages, 6 figures, accepted for publication in the ApJ Letters</p>
<p><strong>Summary</strong><br>    ç ”ç©¶å‘ç°åœ¨æ˜Ÿç³»M51ä¸­ï¼Œå†·çƒ­æ°”ç›¸äº¤ä»‹è´¨ä¸æ’æ˜Ÿå½¢æˆæ´»åŠ¨å¯†åˆ‡ç›¸å…³ã€‚åˆ©ç”¨æ·±åº¦$Chandra$è§‚æµ‹æ•°æ®å’Œæ¯«ç±³æ³¢æ¡£æ¡ˆè°ƒæŸ¥æ•°æ®ï¼Œå‘ç°M51å†…2kpcçš„çƒ­æ°”ä½“è¡¨é¢äº®åº¦æ€¥å‰§ä¸‹é™ã€‚çº¢å¤–è¾å°„ä¸çƒ­æ°”ä½“äº®åº¦å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œä¸­å¿ƒåŒºåŸŸçš„å…³è”æ€§å°¤ä¸ºæ˜¾è‘—ã€‚ä¸­å¿ƒåŒºåŸŸçš„çƒ­æ°”ä½“å…‰åº¦ä¸çº¢å¤–å…‰åº¦ä¹‹é—´å­˜åœ¨é™¡å³­å…³ç³»ï¼Œè¡¨æ˜æ ¸å¿ƒå´©æºƒè¶…æ–°æ˜Ÿæ˜¯M51ä¸­å¿ƒæ°”ä½“åŠ çƒ­çš„ä¸»è¦èƒ½æºæ¥æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>M51æ˜Ÿç³»ä¸­çš„å†·çƒ­æ°”ç›¸äº¤ä»‹è´¨ä¸æ’æ˜Ÿå½¢æˆæ´»åŠ¨ç´§å¯†ç›¸å…³ã€‚</li>
<li>åœ¨M51å†…2kpcåŒºåŸŸè§‚å¯Ÿåˆ°çƒ­æ°”ä½“è¡¨é¢äº®åº¦æ€¥å‰§ä¸‹é™ã€‚</li>
<li>çº¢å¤–è¾å°„ä¸çƒ­æ°”ä½“äº®åº¦å­˜åœ¨æ­£ç›¸å…³æ€§ï¼Œè¿™ç§å…³ç³»åœ¨M51çš„ä¸­å¿ƒåŒºåŸŸå°¤ä¸ºæ˜¾è‘—ã€‚</li>
<li>M51ä¸­å¿ƒåŒºåŸŸçš„çƒ­æ°”ä½“å…‰åº¦ä¸çº¢å¤–å…‰åº¦ä¹‹é—´å­˜åœ¨é™¡å³­å…³ç³»ã€‚</li>
<li>æ ¸å¿ƒå´©æºƒè¶…æ–°æ˜Ÿæ˜¯M51ä¸­å¿ƒæ°”ä½“åŠ çƒ­çš„ä¸»è¦èƒ½æºæ¥æºã€‚</li>
<li>è¶…æ–°æ˜Ÿçš„Xå°„çº¿è¾å°„æ•ˆç‡éšç€æ’æ˜Ÿå½¢æˆç‡è¡¨é¢å¯†åº¦çš„å¢åŠ è€Œå¢åŠ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01613">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b426b3292020ddd0f6e49879cc7ecfcd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2e77d74004d3a6ced455f99b5a2ca970.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bb1a87524c15f908684635f00e548fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cddad9cec43301bdf1c6488d5ecadd26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de446527661191fa495c888222ded58e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d65d398b7355b039d788a047d2d26fe3.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PB-UAP-Hybrid-Universal-Adversarial-Attack-For-Image-Segmentation"><a href="#PB-UAP-Hybrid-Universal-Adversarial-Attack-For-Image-Segmentation" class="headerlink" title="PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation"></a>PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation</h2><p><strong>Authors:Yufei Song, Ziqi Zhou, Minghui Li, Xianlong Wang, Hangtao Zhang, Menghao Deng, Wei Wan, Shengshan Hu, Leo Yu Zhang</strong></p>
<p>With the rapid advancement of deep learning, the model robustness has become a significant research hotspot, \ie, adversarial attacks on deep neural networks. Existing works primarily focus on image classification tasks, aiming to alter the modelâ€™s predicted labels. Due to the output complexity and deeper network architectures, research on adversarial examples for segmentation models is still limited, particularly for universal adversarial perturbations. In this paper, we propose a novel universal adversarial attack method designed for segmentation models, which includes dual feature separation and low-frequency scattering modules. The two modules guide the training of adversarial examples in the pixel and frequency space, respectively. Experiments demonstrate that our method achieves high attack success rates surpassing the state-of-the-art methods, and exhibits strong transferability across different models. </p>
<blockquote>
<p>éšç€æ·±åº¦å­¦ä¹ çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹çš„ç¨³å¥æ€§å·²æˆä¸ºä¸€ä¸ªé‡è¦çš„ç ”ç©¶çƒ­ç‚¹ï¼Œå³å¯¹æ·±åº¦ç¥ç»ç½‘ç»œçš„å¯¹æŠ—æ€§æ”»å‡»ã€‚ç°æœ‰å·¥ä½œä¸»è¦é›†ä¸­åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šï¼Œæ—¨åœ¨æ”¹å˜æ¨¡å‹çš„é¢„æµ‹æ ‡ç­¾ã€‚ç”±äºè¾“å‡ºå¤æ‚å’Œç½‘ç»œæ¶æ„æ›´æ·±ï¼Œé’ˆå¯¹åˆ†å‰²æ¨¡å‹çš„å¯¹æŠ—æ€§ç¤ºä¾‹ç ”ç©¶ä»ç„¶æœ‰é™ï¼Œç‰¹åˆ«æ˜¯é€šç”¨å¯¹æŠ—æ€§æ‰°åŠ¨çš„ç ”ç©¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹åˆ†å‰²æ¨¡å‹çš„æ–°å‹é€šç”¨å¯¹æŠ—æ€§æ”»å‡»æ–¹æ³•ï¼ŒåŒ…æ‹¬åŒç‰¹å¾åˆ†ç¦»å’Œä½é¢‘æ•£å°„æ¨¡å—ã€‚è¿™ä¸¤ä¸ªæ¨¡å—åˆ†åˆ«åœ¨åƒç´ å’Œé¢‘ç‡ç©ºé—´å¼•å¯¼å¯¹æŠ—æ€§ç¤ºä¾‹çš„è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é«˜æ”»å‡»æˆåŠŸç‡ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨ä¸åŒæ¨¡å‹ä¹‹é—´è¡¨ç°å‡ºå¼ºå¤§çš„å¯è¿ç§»æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16651v2">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„é£é€Ÿå‘å±•ï¼Œæ¨¡å‹çš„ç¨³å¥æ€§é€æ¸æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œçš„å¯¹æŠ—æ€§æ”»å‡»ã€‚ç›®å‰çš„ç ”ç©¶ä¸»è¦å…³æ³¨å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œæ—¨åœ¨æ”¹å˜æ¨¡å‹çš„é¢„æµ‹æ ‡ç­¾ã€‚ç„¶è€Œï¼Œç”±äºè¾“å‡ºå¤æ‚æ€§å’Œæ›´æ·±çš„ç½‘ç»œæ¶æ„ï¼Œé’ˆå¯¹åˆ†å‰²æ¨¡å‹çš„å¯¹æŠ—æ€§ç¤ºä¾‹ç ”ç©¶ä»ç„¶æœ‰é™ï¼Œç‰¹åˆ«æ˜¯é€šç”¨å¯¹æŠ—æ€§æ‰°åŠ¨çš„ç ”ç©¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é’ˆå¯¹åˆ†å‰²æ¨¡å‹çš„é€šç”¨å¯¹æŠ—æ€§æ”»å‡»æ–¹æ³•ï¼ŒåŒ…æ‹¬åŒç‰¹å¾åˆ†ç¦»å’Œä½é¢‘æ•£å°„æ¨¡å—ã€‚è¿™ä¸¤ä¸ªæ¨¡å—åˆ†åˆ«åœ¨åƒç´ å’Œé¢‘ç‡ç©ºé—´æŒ‡å¯¼å¯¹æŠ—æ€§ç¤ºä¾‹çš„è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜æ”»å‡»æˆåŠŸç‡ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨ä¸åŒæ¨¡å‹ä¹‹é—´è¡¨ç°å‡ºå¼ºå¤§çš„è¿ç§»æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç¨³å¥æ€§æˆä¸ºç ”ç©¶çƒ­ç‚¹ï¼Œå¯¹æŠ—æ€§æ”»å‡»æ˜¯å…¶ä¸­çš„é‡è¦ç ”ç©¶æ–¹å‘ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦å…³æ³¨å›¾åƒåˆ†ç±»ä»»åŠ¡çš„å¯¹æŠ—æ€§æ”»å‡»ï¼Œæ”¹å˜æ¨¡å‹çš„é¢„æµ‹æ ‡ç­¾ã€‚</li>
<li>é’ˆå¯¹åˆ†å‰²æ¨¡å‹çš„å¯¹æŠ—æ€§ç¤ºä¾‹ç ”ç©¶ä»ç„¶æœ‰é™ï¼Œå°¤å…¶æ˜¯é€šç”¨å¯¹æŠ—æ€§æ‰°åŠ¨çš„ç ”ç©¶ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é€šç”¨å¯¹æŠ—æ€§æ”»å‡»æ–¹æ³•ï¼ŒåŒ…æ‹¬åŒç‰¹å¾åˆ†ç¦»å’Œä½é¢‘æ•£å°„æ¨¡å—ã€‚</li>
<li>åŒç‰¹å¾åˆ†ç¦»æ¨¡å—åœ¨åƒç´ ç©ºé—´æŒ‡å¯¼å¯¹æŠ—æ€§ç¤ºä¾‹çš„è®­ç»ƒã€‚</li>
<li>ä½é¢‘æ•£å°„æ¨¡å—åœ¨é¢‘ç‡ç©ºé—´æŒ‡å¯¼å¯¹æŠ—æ€§ç¤ºä¾‹çš„è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16651">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d59afa7bdffbecf53700b51c5cd6fc0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-666a2e364bdc3d82cbe2ef77953ce70b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0fa161313acebbfb90cfd30e15094f0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="XLSTM-HVED-Cross-Modal-Brain-Tumor-Segmentation-and-MRI-Reconstruction-Method-Using-Vision-XLSTM-and-Heteromodal-Variational-Encoder-Decoder"><a href="#XLSTM-HVED-Cross-Modal-Brain-Tumor-Segmentation-and-MRI-Reconstruction-Method-Using-Vision-XLSTM-and-Heteromodal-Variational-Encoder-Decoder" class="headerlink" title="XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction   Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder"></a>XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction   Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder</h2><p><strong>Authors:Shenghao Zhu, Yifei Chen, Shuo Jiang, Weihong Chen, Chang Liu, Yuanhan Wang, Xu Chen, Yifan Ke, Feiwei Qin, Changmiao Wang, Zhu Zhu</strong></p>
<p>Neurogliomas are among the most aggressive forms of cancer, presenting considerable challenges in both treatment and monitoring due to their unpredictable biological behavior. Magnetic resonance imaging (MRI) is currently the preferred method for diagnosing and monitoring gliomas. However, the lack of specific imaging techniques often compromises the accuracy of tumor segmentation during the imaging process. To address this issue, we introduce the XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder framework with the Vision XLSTM module to reconstruct missing MRI modalities. By deeply fusing spatial and temporal features, it enhances tumor segmentation performance. The key innovation of our approach is the Self-Attention Variational Encoder (SAVE) module, which improves the integration of modal features. Additionally, it optimizes the interaction of features between segmentation and reconstruction tasks through the Squeeze-Fusion-Excitation Cross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset demonstrate that our model significantly outperforms existing advanced methods in handling cases where modalities are missing. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/Quanato607/XLSTM-HVED">https://github.com/Quanato607/XLSTM-HVED</a>. </p>
<blockquote>
<p>ç¥ç»èƒ¶è´¨ç˜¤æ˜¯æœ€å…·ä¾µè¢­æ€§çš„ç™Œç—‡å½¢å¼ä¹‹ä¸€ï¼Œç”±äºå…¶ä¸å¯é¢„æµ‹çš„ç”Ÿç‰©è¡Œä¸ºï¼Œä¸ºæ²»ç–—å’Œç›‘æµ‹å¸¦æ¥äº†ç›¸å½“å¤§çš„æŒ‘æˆ˜ã€‚ç›®å‰ï¼Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯è¯Šæ–­å’Œç›‘æµ‹èƒ¶è´¨ç˜¤çš„é¦–é€‰æ–¹æ³•ã€‚ç„¶è€Œï¼Œç¼ºä¹ç‰¹å®šçš„æˆåƒæŠ€æœ¯å¾€å¾€ä¼šå½±å“æˆåƒè¿‡ç¨‹ä¸­è‚¿ç˜¤åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†XLSTM-HVEDæ¨¡å‹ã€‚è¯¥æ¨¡å‹ç»“åˆäº†å¼‚æ¨¡å¼ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶å’ŒVision XLSTMæ¨¡å—ï¼Œä»¥é‡å»ºç¼ºå¤±çš„MRIæ¨¡å¼ã€‚é€šè¿‡æ·±åº¦èåˆç©ºé—´å’Œæ—¶é—´ç‰¹å¾ï¼Œæé«˜äº†è‚¿ç˜¤åˆ†å‰²çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å…³é”®åˆ›æ–°ç‚¹æ˜¯è‡ªæ³¨æ„åŠ›å˜åˆ†ç¼–ç å™¨ï¼ˆSAVEï¼‰æ¨¡å—ï¼Œå®ƒæ”¹è¿›äº†æ¨¡å¼ç‰¹å¾çš„èåˆã€‚æ­¤å¤–ï¼Œå®ƒé€šè¿‡æŒ¤å‹-èåˆ-å…´å¥‹äº¤å‰æ„è¯†ï¼ˆSFECAï¼‰æ¨¡å—ä¼˜åŒ–äº†åˆ†å‰²å’Œé‡å»ºä»»åŠ¡ä¹‹é—´çš„ç‰¹å¾äº¤äº’ã€‚æˆ‘ä»¬ä½¿ç”¨BraTS 2024æ•°æ®é›†è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤„ç†ç¼ºå¤±æ¨¡å¼çš„æƒ…å†µæ—¶æ˜¾è‘—ä¼˜äºç°æœ‰çš„é«˜çº§æ–¹æ³•ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Quanato607/XLSTM-HVED%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Quanato607/XLSTM-HVEDæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07804v2">PDF</a> 5 pages, 2 figures</p>
<p><strong>Summary</strong><br>     ç¥ç»èƒ¶è´¨ç˜¤æ˜¯æœ€å…·ä¾µè¢­æ€§çš„ç™Œç—‡ä¹‹ä¸€ï¼Œå…¶ç”Ÿç‰©è¡Œä¸ºä¸å¯é¢„æµ‹ï¼Œä¸ºæ²»ç–—å’Œç›‘æµ‹å¸¦æ¥é‡å¤§æŒ‘æˆ˜ã€‚å½“å‰ï¼Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯è¯Šæ–­å’Œç›‘æµ‹èƒ¶è´¨ç˜¤çš„é¦–é€‰æ–¹æ³•ï¼Œä½†ç¼ºä¹ç‰¹å®šçš„æˆåƒæŠ€æœ¯ï¼Œå½±å“è‚¿ç˜¤åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†XLSTM-HVEDæ¨¡å‹ã€‚è¯¥æ¨¡å‹ç»“åˆå¼‚æ¨¡ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ä¸Vision XLSTMæ¨¡å—ï¼Œé‡å»ºç¼ºå¤±çš„MRIæ¨¡å¼ã€‚é€šè¿‡æ·±åº¦èåˆç©ºé—´å’Œæ—¶é—´çš„ç‰¹å¾ï¼Œæé«˜äº†è‚¿ç˜¤åˆ†å‰²çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºè‡ªæ³¨æ„åŠ›å˜åˆ†ç¼–ç å™¨ï¼ˆSAVEï¼‰æ¨¡å—ï¼Œå®ƒæ”¹è¿›äº†æ¨¡æ€ç‰¹å¾çš„èåˆã€‚æ­¤å¤–ï¼Œå®ƒé€šè¿‡æŒ¤å‹-èåˆ-å…´å¥‹äº¤å‰æ„è¯†ï¼ˆSFECAï¼‰æ¨¡å—ä¼˜åŒ–äº†åˆ†å‰²å’Œé‡å»ºä»»åŠ¡ä¹‹é—´çš„ç‰¹å¾äº¤äº’ã€‚ä½¿ç”¨BraTS 2024æ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤„ç†ç¼ºå¤±æ¨¡æ€çš„æƒ…å†µä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰é«˜çº§æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»èƒ¶è´¨ç˜¤æ²»ç–—ä¸ç›‘æµ‹å­˜åœ¨æŒ‘æˆ˜ï¼Œå› å…¶ç”Ÿç‰©è¡Œä¸ºä¸å¯é¢„æµ‹ã€‚</li>
<li>ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰æ˜¯å½“å‰è¯Šæ–­å’Œç›‘æµ‹èƒ¶è´¨ç˜¤çš„ä¸»è¦æ‰‹æ®µã€‚</li>
<li>ç¼ºä¹ç‰¹å®šçš„æˆåƒæŠ€æœ¯ä¼šå½±å“è‚¿ç˜¤åˆ†å‰²çš„å‡†ç¡®æ€§ã€‚</li>
<li>å¼•å…¥çš„XLSTM-HVEDæ¨¡å‹é€šè¿‡ç»“åˆå¼‚æ¨¡ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ä¸Vision XLSTMæ¨¡å—ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>XLSTM-HVEDæ¨¡å‹é€šè¿‡æ·±åº¦èåˆç©ºé—´å’Œæ—¶é—´çš„ç‰¹å¾ï¼Œæé«˜äº†è‚¿ç˜¤åˆ†å‰²çš„æ€§èƒ½ã€‚</li>
<li>è‡ªæ³¨æ„åŠ›å˜åˆ†ç¼–ç å™¨ï¼ˆSAVEï¼‰æ¨¡å—æ˜¯è¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°ç‚¹ï¼Œæ”¹è¿›äº†æ¨¡æ€ç‰¹å¾çš„èåˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07804">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-990b3a42569b056e4eccdce75fdef90e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da60db8443b675a68c3c47ba18158641.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-970e1b1c8819dbfa82c0b6a5bd066932.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7ac994a06936a3646fed8efd39998301.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-078694a99b64803abd171ca0ae8cce30.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="DINO-LG-A-Task-Specific-DINO-Model-for-Coronary-Calcium-Scoring"><a href="#DINO-LG-A-Task-Specific-DINO-Model-for-Coronary-Calcium-Scoring" class="headerlink" title="DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring"></a>DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring</h2><p><strong>Authors:Mahmut S. Gokmen, Caner Ozcan, Moneera N. Haque, Steve W. Leung, C. Seth Parker, W. Brent Seales, Cody Bumgardner</strong></p>
<p>Coronary artery disease (CAD), one of the leading causes of mortality worldwide, necessitates effective risk assessment strategies, with coronary artery calcium (CAC) scoring via computed tomography (CT) being a key method for prevention. Traditional methods, primarily based on UNET architectures implemented on pre-built models, face challenges like the scarcity of annotated CT scans containing CAC and imbalanced datasets, leading to reduced performance in segmentation and scoring tasks. In this study, we address these limitations by incorporating the self-supervised learning (SSL) technique of DINO (self-distillation with no labels), which trains without requiring CAC-specific annotations, enhancing its robustness in generating distinct features. The DINO-LG model, which leverages label guidance to focus on calcified areas, achieves significant improvements, with a sensitivity of 89% and specificity of 90% for detecting CAC-containing CT slices, compared to the standard DINO modelâ€™s sensitivity of 79% and specificity of 77%. Additionally, false-negative and false-positive rates are reduced by 49% and 59%, respectively, instilling greater confidence in clinicians when ruling out calcification in low-risk patients and minimizing unnecessary imaging reviews by radiologists. Further, CAC scoring and segmentation tasks are conducted using a basic UNET architecture, applied specifically to CT slices identified by the DINO-LG model as containing calcified areas. This targeted approach enhances CAC scoring accuracy by feeding the UNET model with relevant slices, significantly improving diagnostic precision, reducing both false positives and false negatives, and ultimately lowering overall healthcare costs by minimizing unnecessary tests and treatments, presenting a valuable advancement in CAD risk assessment. </p>
<blockquote>
<p>å† çŠ¶åŠ¨è„‰ç–¾ç—…ï¼ˆCADï¼‰æ˜¯å…¨çƒä¸»è¦çš„æ­»äº¡åŸå› ä¹‹ä¸€ï¼Œå¿…é¡»è¿›è¡Œæœ‰æ•ˆçš„é£é™©è¯„ä¼°ç­–ç•¥ã€‚è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­çš„å† çŠ¶åŠ¨è„‰é’™åŒ–ï¼ˆCACï¼‰è¯„åˆ†æ˜¯é¢„é˜²çš„å…³é”®æ–¹æ³•ã€‚ä¼ ç»Ÿæ–¹æ³•ä¸»è¦åŸºäºé¢„æ„å»ºæ¨¡å‹ä¸Šå®æ–½çš„UNETæ¶æ„ï¼Œé¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚å«æœ‰CACçš„æ ‡æ³¨CTæ‰«æç¨€ç¼ºå’Œæ•°æ®é›†ä¸å¹³è¡¡ï¼Œå¯¼è‡´åˆ†å‰²å’Œè¯„åˆ†ä»»åŠ¡æ€§èƒ½ä¸‹é™ã€‚æœ¬ç ”ç©¶é€šè¿‡èå…¥æ— ç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æŠ€æœ¯æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œå³æ— éœ€CACç‰¹å®šæ ‡æ³¨è¿›è¡Œè®­ç»ƒçš„DINOï¼ˆæ— æ ‡ç­¾è‡ªæˆ‘è’¸é¦ï¼‰æŠ€æœ¯ï¼Œå¢å¼ºäº†å…¶åœ¨ç”Ÿæˆç‹¬ç‰¹ç‰¹å¾æ–¹é¢çš„ç¨³å¥æ€§ã€‚åˆ©ç”¨æ ‡ç­¾æŒ‡å¯¼èšç„¦äºé’™åŒ–åŒºåŸŸçš„DINO-LGæ¨¡å‹ï¼Œä¸æ ‡å‡†DINOæ¨¡å‹ç›¸æ¯”ï¼Œæ£€æµ‹å«æœ‰CACçš„CTåˆ‡ç‰‡çš„æ•æ„Ÿåº¦å’Œç‰¹å¼‚æ€§åˆ†åˆ«è¾¾åˆ°äº†89%å’Œ90%ï¼ˆDINOæ¨¡å‹ä¸º79%å’Œ77%ï¼‰ï¼Œå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚æ­¤å¤–ï¼Œå‡é˜´æ€§å’Œå‡é˜³æ€§ç‡åˆ†åˆ«é™ä½äº†49%å’Œ59%ï¼Œä½¿ä¸´åºŠåŒ»ç”Ÿåœ¨æ’é™¤ä½é£é™©æ‚£è€…çš„é’™åŒ–æƒ…å†µæ—¶æœ‰æ›´å¤§çš„ä¿¡å¿ƒï¼Œå¹¶å‡å°‘äº†å¯¹æ”¾å°„ç§‘åŒ»ç”Ÿè¿›è¡Œä¸å¿…è¦çš„å½±åƒå¤æŸ¥çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œä½¿ç”¨åŸºæœ¬UNETæ¶æ„è¿›è¡ŒCACè¯„åˆ†å’Œåˆ†å‰²ä»»åŠ¡ï¼Œè¯¥æ¶æ„ç‰¹å®šåº”ç”¨äºDINO-LGæ¨¡å‹è¯†åˆ«ä¸ºå«æœ‰é’™åŒ–åŒºåŸŸçš„CTåˆ‡ç‰‡ã€‚è¿™ç§æœ‰é’ˆå¯¹æ€§çš„æ–¹æ³•é€šè¿‡å‘UNETæ¨¡å‹æä¾›ç›¸å…³çš„åˆ‡ç‰‡ï¼Œæé«˜äº†CACè¯„åˆ†çš„å‡†ç¡®æ€§ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†è¯Šæ–­çš„ç²¾ç¡®åº¦ï¼Œå‡å°‘äº†å‡é˜³æ€§å’Œå‡é˜´æ€§ç»“æœï¼Œå¹¶æœ€ç»ˆé€šè¿‡å‡å°‘ä¸å¿…è¦çš„æµ‹è¯•å’Œæ²»ç–—æ¥é™ä½æ•´ä½“åŒ»ç–—ä¿å¥æˆæœ¬ï¼Œä¸ºCADé£é™©è¯„ä¼°æä¾›äº†å®è´µçš„è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.07976v6">PDF</a> Developed by Center for Applied Artificial Intelligence (CAAI),   University of Kentucky</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦ä»¥æ±‰è¯­ç®€æ´è¡¨è¿°è®ºæ–‡ä¸»è¦å†…å®¹ï¼šé’ˆå¯¹å† çŠ¶åŠ¨è„‰ç–¾ç—…çš„é£é™©è¯„ä¼°ï¼Œç ”ç©¶é‡‡ç”¨æ— æ ‡ç­¾è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•DINOç»“åˆæ ‡ç­¾å¼•å¯¼ï¼ˆDINO-LGæ¨¡å‹ï¼‰æå‡å¯¹å«é’™åŒ–åŒºåŸŸCTåˆ‡ç‰‡çš„æ£€æµ‹æ€§èƒ½ï¼Œé€šè¿‡ç²¾å‡†å®šä½é’™åŒ–åŒºåŸŸï¼Œæé«˜å† çŠ¶åŠ¨è„‰é’™åŒ–ï¼ˆCACï¼‰è¯„åˆ†å’Œåˆ†å‰²ä»»åŠ¡çš„å‡†ç¡®æ€§ï¼Œä¸ºä¸´åºŠåŒ»ç”Ÿæä¾›æ›´å¯é çš„è¯Šæ–­ä¾æ®ï¼Œé™ä½è¯¯è¯Šç‡å’Œä¸å¿…è¦çš„å½±åƒå¤æŸ¥ï¼Œè¿›è€Œé™ä½æ•´ä½“åŒ»ç–—ä¿å¥æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å† çŠ¶åŠ¨è„‰ç–¾ç—…ï¼ˆCADï¼‰æ˜¯å…¨çƒä¸»è¦çš„æ­»äº¡åŸå› ä¹‹ä¸€ï¼Œéœ€è¦æœ‰æ•ˆçš„é£é™©è¯„ä¼°ç­–ç•¥ã€‚</li>
<li>å† çŠ¶åŠ¨è„‰é’™åŒ–ï¼ˆCACï¼‰è¯„åˆ†æ˜¯é¢„é˜²CADçš„å…³é”®æ–¹æ³•ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•é¢ä¸´æ•°æ®æ ‡æ³¨ä¸è¶³å’Œæ•°æ®ä¸å¹³è¡¡çš„æŒ‘æˆ˜ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨æ— æ ‡ç­¾è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æŠ€æœ¯ä¸­çš„DINOæ–¹æ³•ï¼Œæ— éœ€CACç‰¹å®šæ ‡æ³¨è¿›è¡Œè®­ç»ƒï¼Œæé«˜äº†ç‰¹å¾ç”Ÿæˆçš„ç¨³å¥æ€§ã€‚</li>
<li>DINOç»“åˆæ ‡ç­¾å¼•å¯¼ï¼ˆDINO-LGæ¨¡å‹ï¼‰æ˜¾è‘—æé«˜äº†æ£€æµ‹CACå«é’™åŒ–åŒºåŸŸCTåˆ‡ç‰‡çš„æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§ã€‚</li>
<li>DINO-LGæ¨¡å‹é™ä½äº†è¯¯è¯Šç‡å’Œä¸å¿…è¦çš„å½±åƒå¤æŸ¥ï¼Œå¢å¼ºäº†åŒ»ç”Ÿå¯¹ä½å±æ‚£è€…é’™åŒ–æ’é™¤çš„ä¿¡å¿ƒã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨åŸºæœ¬UNETæ¶æ„è¿›è¡ŒCACè¯„åˆ†å’Œåˆ†å‰²ä»»åŠ¡ï¼Œé’ˆå¯¹DINO-LGæ¨¡å‹è¯†åˆ«å‡ºçš„å«é’™åŒ–åŒºåŸŸCTåˆ‡ç‰‡è¿›è¡Œï¼Œæé«˜äº†è¯Šæ–­ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.07976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-71fb6de08e48a8dc5221a77766000f42.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8499406100bcced8f388219febe8156f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe8528000a9211cdfa022eaad6078fe9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d50a8f66c8afc847f1968b3eaacd6231.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Toward-Robust-Early-Detection-of-Alzheimerâ€™s-Disease-via-an-Integrated-Multimodal-Learning-Approach"><a href="#Toward-Robust-Early-Detection-of-Alzheimerâ€™s-Disease-via-an-Integrated-Multimodal-Learning-Approach" class="headerlink" title="Toward Robust Early Detection of Alzheimerâ€™s Disease via an Integrated   Multimodal Learning Approach"></a>Toward Robust Early Detection of Alzheimerâ€™s Disease via an Integrated   Multimodal Learning Approach</h2><p><strong>Authors:Yifei Chen, Shenghao Zhu, Zhaojie Fang, Chang Liu, Binfeng Zou, Yuhe Wang, Shuo Chang, Fan Jia, Feiwei Qin, Jin Fan, Yong Peng, Changmiao Wang</strong></p>
<p>Alzheimerâ€™s Disease (AD) is a complex neurodegenerative disorder marked by memory loss, executive dysfunction, and personality changes. Early diagnosis is challenging due to subtle symptoms and varied presentations, often leading to misdiagnosis with traditional unimodal diagnostic methods due to their limited scope. This study introduces an advanced multimodal classification model that integrates clinical, cognitive, neuroimaging, and EEG data to enhance diagnostic accuracy. The model incorporates a feature tagger with a tabular data coding architecture and utilizes the TimesBlock module to capture intricate temporal patterns in Electroencephalograms (EEG) data. By employing Cross-modal Attention Aggregation module, the model effectively fuses Magnetic Resonance Imaging (MRI) spatial information with EEG temporal data, significantly improving the distinction between AD, Mild Cognitive Impairment, and Normal Cognition. Simultaneously, we have constructed the first AD classification dataset that includes three modalities: EEG, MRI, and tabular data. Our innovative approach aims to facilitate early diagnosis and intervention, potentially slowing the progression of AD. The source code and our private ADMC dataset are available at <a target="_blank" rel="noopener" href="https://github.com/JustlfC03/MSTNet">https://github.com/JustlfC03/MSTNet</a>. </p>
<blockquote>
<p>é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰æ˜¯ä¸€ç§å¤æ‚çš„ç¥ç»é€€è¡Œæ€§ç–¾ç—…ï¼Œä»¥è®°å¿†ä¸§å¤±ã€æ‰§è¡ŒåŠŸèƒ½éšœç¢å’Œä¸ªæ€§æ”¹å˜ä¸ºç‰¹å¾ã€‚ç”±äºæ—©æœŸç—‡çŠ¶ç»†å¾®ä¸”è¡¨ç°å„å¼‚ï¼Œæ—©æœŸè¯Šæ–­å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¾€å¾€ä½¿ç”¨ä¼ ç»Ÿçš„å•ä¸€è¯Šæ–­æ–¹æ³•ä¼šå¯¼è‡´è¯¯è¯Šï¼Œå› ä¸ºå®ƒä»¬çš„åº”ç”¨èŒƒå›´æœ‰é™ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§å…ˆè¿›çš„è·¨æ¨¡æ€åˆ†ç±»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èåˆäº†ä¸´åºŠã€è®¤çŸ¥ã€ç¥ç»å½±åƒå­¦å’Œè„‘ç”µå›¾æ•°æ®ï¼Œä»¥æé«˜è¯Šæ–­çš„å‡†ç¡®æ€§ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ç‰¹å¾æ ‡ç­¾å™¨å’Œè¡¨æ ¼æ•°æ®ç¼–ç æ¶æ„ï¼Œå¹¶ä½¿ç”¨TimesBlockæ¨¡å—æ•æ‰è„‘ç”µå›¾ï¼ˆEEGï¼‰æ•°æ®ä¸­å¤æ‚çš„æ—¶é—´æ¨¡å¼ã€‚é€šè¿‡é‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›èšåˆæ¨¡å—ï¼Œè¯¥æ¨¡å‹æœ‰æ•ˆåœ°èåˆäº†ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„ç©ºé—´ä¿¡æ¯ä¸EEGçš„æ—¶é—´æ•°æ®ï¼Œæ˜¾è‘—æé«˜äº†å¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…ã€è½»åº¦è®¤çŸ¥éšœç¢å’Œæ­£å¸¸è®¤çŸ¥çš„åŒºåˆ†èƒ½åŠ›ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ„å»ºäº†é¦–ä¸ªåŒ…å«ä¸‰ç§æ¨¡å¼ï¼ˆEEGã€MRIå’Œè¡¨æ ¼æ•°æ®ï¼‰çš„ADåˆ†ç±»æ•°æ®é›†ã€‚æˆ‘ä»¬çš„åˆ›æ–°æ–¹æ³•æ—¨åœ¨ä¿ƒè¿›æ—©æœŸè¯Šæ–­å’Œå¹²é¢„ï¼Œå¯èƒ½æœ‰åŠ©äºå‡ç¼“é˜¿å°”èŒ¨æµ·é»˜ç—…çš„è¿›å±•ã€‚æºä»£ç å’Œæˆ‘ä»¬çš„ç§æœ‰ADMCæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JustlfC03/MSTNet%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/JustlfC03/MSTNetè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.16343v2">PDF</a> 5 pages, 2 figures</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§å…ˆè¿›çš„å¤šæ¨¡å¼åˆ†ç±»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é›†æˆäº†ä¸´åºŠã€è®¤çŸ¥ã€ç¥ç»æˆåƒå’Œè„‘ç”µå›¾æ•°æ®ï¼Œä»¥æé«˜å¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰çš„è¯Šæ–­å‡†ç¡®æ€§ã€‚é€šè¿‡é‡‡ç”¨è·¨æ¨¡æ€æ³¨æ„åŠ›èšåˆæ¨¡å—ï¼Œæ¨¡å‹æœ‰æ•ˆèåˆäº†ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰çš„ç©ºé—´ä¿¡æ¯ä¸è„‘ç”µå›¾ï¼ˆEEGï¼‰çš„æ—¶é—´æ•°æ®ï¼Œæ˜¾è‘—æé«˜äº†å¯¹ADã€è½»åº¦è®¤çŸ¥éšœç¢å’Œæ­£å¸¸è®¤çŸ¥çš„åŒºåˆ†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆADï¼‰æ˜¯ä¸€ç§å¤æ‚çš„ç¥ç»é€€è¡Œæ€§ç–¾ç—…ï¼Œæ—©æœŸç¡®è¯Šå…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>ä¼ ç»Ÿçš„ä¸€ç»´è¯Šæ–­æ–¹æ³•ç”±äºå±€é™æ€§ï¼Œå¸¸å¸¸å¯¼è‡´è¯¯è¯Šã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ¨¡å¼åˆ†ç±»æ¨¡å‹ï¼Œé›†æˆäº†ä¸´åºŠã€è®¤çŸ¥ã€ç¥ç»æˆåƒå’ŒEEGæ•°æ®ï¼Œä»¥æé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨ç‰¹å¾æ ‡ç­¾å™¨å’Œè¡¨æ ¼æ•°æ®ç¼–ç æ¶æ„ã€‚</li>
<li>TimesBlockæ¨¡å—ç”¨äºæ•æ‰EEGæ•°æ®ä¸­å¤æ‚çš„æ—¶é—´æ¨¡å¼ã€‚</li>
<li>Cross-modal Attention Aggregationæ¨¡å—æœ‰æ•ˆèåˆäº†MRIçš„ç©ºé—´ä¿¡æ¯å’ŒEEGçš„æ—¶é—´æ•°æ®ï¼Œæé«˜äº†å¯¹ADå’Œå…¶ä»–è®¤çŸ¥çŠ¶æ€çš„åŒºåˆ†èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.16343">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f2c23d9ae917539a080d8348335e3603.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42982eab3747e1aa4151a268fcf139d3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c037be475ed91e82fc2b94b3073009bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cd22b03b42f861a3627028e04f344b8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="CT-AGRG-Automated-Abnormality-Guided-Report-Generation-from-3D-Chest-CT-Volumes"><a href="#CT-AGRG-Automated-Abnormality-Guided-Report-Generation-from-3D-Chest-CT-Volumes" class="headerlink" title="CT-AGRG: Automated Abnormality-Guided Report Generation from 3D Chest CT   Volumes"></a>CT-AGRG: Automated Abnormality-Guided Report Generation from 3D Chest CT   Volumes</h2><p><strong>Authors:Theo Di Piazza</strong></p>
<p>The rapid increase of computed tomography (CT) scans and their time-consuming manual analysis have created an urgent need for robust automated analysis techniques in clinical settings. These aim to assist radiologists and help them managing their growing workload. Existing methods typically generate entire reports directly from 3D CT images, without explicitly focusing on observed abnormalities. This unguided approach often results in repetitive content or incomplete reports, failing to prioritize anomaly-specific descriptions. We propose a new anomaly-guided report generation model, which first predicts abnormalities and then generates targeted descriptions for each. Evaluation on a public dataset demonstrates significant improvements in report quality and clinical relevance. We extend our work by conducting an ablation study to demonstrate its effectiveness. </p>
<blockquote>
<p>è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰æ‰«æçš„è¿…é€Ÿå¢åŠ åŠå…¶è€—æ—¶çš„äººå·¥åˆ†æï¼Œä¸ºä¸´åºŠç¯å¢ƒä¸­ç¨³å¥çš„è‡ªåŠ¨åŒ–åˆ†ææŠ€æœ¯åˆ›é€ äº†è¿«åˆ‡çš„éœ€æ±‚ã€‚è¿™äº›æŠ€æœ¯çš„ç›®æ ‡æ˜¯å¸®åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿå¤„ç†ä»–ä»¬æ—¥ç›Šå¢é•¿çš„å·¥ä½œé‡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç›´æ¥ä»3D CTå›¾åƒç”Ÿæˆæ•´ä¸ªæŠ¥å‘Šï¼Œè€Œæ²¡æœ‰æ˜ç¡®å…³æ³¨è§‚å¯Ÿåˆ°çš„å¼‚å¸¸æƒ…å†µã€‚è¿™ç§æ— å¯¼å‘çš„æ–¹æ³•å¸¸å¸¸å¯¼è‡´å†…å®¹é‡å¤æˆ–æŠ¥å‘Šä¸å®Œæ•´ï¼Œæ— æ³•ä¼˜å…ˆæä¾›å¼‚å¸¸æƒ…å†µçš„æè¿°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¼‚å¸¸å¯¼å‘çš„æŠ¥å‘Šç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é¦–å…ˆé¢„æµ‹å¼‚å¸¸æƒ…å†µï¼Œç„¶åä¸ºæ¯ä¸€ä¸ªå¼‚å¸¸æƒ…å†µç”Ÿæˆæœ‰é’ˆå¯¹æ€§çš„æè¿°ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æŠ¥å‘Šè´¨é‡å’Œä¸´åºŠç›¸å…³æ€§æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚æˆ‘ä»¬é€šè¿‡è¿›è¡Œæ¶ˆèç ”ç©¶æ¥è¿›ä¸€æ­¥è¯æ˜å…¶æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.11965v5">PDF</a> 15 pages, 9 figures, accepted to ISBI 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡ä¸­æŒ‡å‡ºCTæ‰«ææ•°é‡çš„è¿…é€Ÿå¢åŠ åŠå…¶æ‰‹åŠ¨åˆ†æçš„è€—æ—¶æ€§ï¼Œä¸´åºŠç¯å¢ƒä¸­å¯¹ç¨³å¥çš„è‡ªåŠ¨åŒ–åˆ†ææŠ€æœ¯æœ‰ç€è¿«åˆ‡çš„éœ€æ±‚ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç›´æ¥ä»3D CTå›¾åƒç”Ÿæˆæ•´ä¸ªæŠ¥å‘Šï¼Œæ²¡æœ‰ç‰¹åˆ«å¼ºè°ƒè§‚å¯Ÿåˆ°çš„å¼‚å¸¸ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¼‚å¸¸å¼•å¯¼æŠ¥å‘Šç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é¦–å…ˆé¢„æµ‹å¼‚å¸¸ï¼Œç„¶åä¸ºæ¯ä¸ªå¼‚å¸¸ç”Ÿæˆæœ‰é’ˆå¯¹æ€§çš„æè¿°ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†è¯¥æ¨¡å‹åœ¨æŠ¥å‘Šè´¨é‡å’Œä¸´åºŠç›¸å…³æ€§æ–¹é¢çš„æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CTæ‰«ææ•°é‡å¢åŠ ï¼Œæ‰‹åŠ¨åˆ†æè€—æ—¶ï¼Œéœ€è¦è‡ªåŠ¨åŒ–åˆ†ææŠ€æœ¯è¾…åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿå¤„ç†å¤§é‡å·¥ä½œã€‚</li>
<li>ç°æœ‰æ–¹æ³•ç›´æ¥ä»3D CTå›¾åƒç”ŸæˆæŠ¥å‘Šï¼Œç¼ºä¹é‡ç‚¹å…³æ³¨å¼‚å¸¸ã€‚</li>
<li>æ–°çš„å¼‚å¸¸å¼•å¯¼æŠ¥å‘Šç”Ÿæˆæ¨¡å‹é¦–å…ˆé¢„æµ‹å¼‚å¸¸ï¼Œç„¶åä¸ºæ¯ä¸ªå¼‚å¸¸ç”Ÿæˆæè¿°ã€‚</li>
<li>åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†æ–°æ¨¡å‹åœ¨æŠ¥å‘Šè´¨é‡å’Œä¸´åºŠç›¸å…³æ€§æ–¹é¢çš„æ˜¾è‘—æé«˜ã€‚</li>
<li>æ–°æ¨¡å‹é€šè¿‡ç”Ÿæˆé’ˆå¯¹å¼‚å¸¸çš„æè¿°ï¼Œèƒ½å¤Ÿå‡å°‘é‡å¤æ€§å†…å®¹å’Œæé«˜æŠ¥å‘Šçš„å®Œæ•´æ€§ã€‚</li>
<li>è¯¥ç ”ç©¶é€šè¿‡è¿›è¡Œæ¶ˆèç ”ç©¶æ¥å±•ç¤ºå…¶æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.11965">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec75bd29ea33c7f314e172def7c6ff2e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ac79443920f63d036961d0395423cd7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e3f8a872ddd6df83d522fdac7ad86ec.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-07/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-07/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-07/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e262945a140a0fbcdb7ddae1a7741766.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-07  VITA-1.5 Towards GPT-4o Level Real-Time Vision and Speech Interaction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-07/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-22796e60db90a6a89c691934e9084105.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-07  ACE Anti-Editing Concept Erasure in Text-to-Image Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23154.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
