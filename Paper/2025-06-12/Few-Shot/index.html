<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-06-12  AraReasoner Evaluating Reasoning-Based LLMs for Arabic NLP">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-01bd51cf355ba2bd9554a5a5c451e0f6.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-12-更新"><a href="#2025-06-12-更新" class="headerlink" title="2025-06-12 更新"></a>2025-06-12 更新</h1><h2 id="AraReasoner-Evaluating-Reasoning-Based-LLMs-for-Arabic-NLP"><a href="#AraReasoner-Evaluating-Reasoning-Based-LLMs-for-Arabic-NLP" class="headerlink" title="AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP"></a>AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP</h2><p><strong>Authors:Ahmed Hasanaath, Aisha Alansari, Ahmed Ashraf, Chafik Salmane, Hamzah Luqman, Saad Ezzini</strong></p>
<p>Large language models (LLMs) have shown remarkable progress in reasoning abilities and general natural language processing (NLP) tasks, yet their performance on Arabic data, characterized by rich morphology, diverse dialects, and complex script, remains underexplored. This paper presents a comprehensive benchmarking study of multiple reasoning-focused LLMs, with a special emphasis on the newly introduced DeepSeek models, across a suite of fifteen Arabic NLP tasks. We experiment with various strategies, including zero-shot, few-shot, and fine-tuning. This allows us to systematically evaluate performance on datasets covering a range of applications to examine their capacity for linguistic reasoning under different levels of complexity. Our experiments reveal several key findings. First, carefully selecting just three in-context examples delivers an average uplift of over 13 F1 points on classification tasks-boosting sentiment analysis from 35.3% to 87.5% and paraphrase detection from 56.1% to 87.0%. Second, reasoning-focused DeepSeek architectures outperform a strong GPT o4-mini baseline by an average of 12 F1 points on complex inference tasks in the zero-shot setting. Third, LoRA-based fine-tuning yields up to an additional 8 points in F1 and BLEU compared to equivalent increases in model scale. The code is available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AraReasoner41299">https://anonymous.4open.science/r/AraReasoner41299</a> </p>
<blockquote>
<p>大型语言模型（LLM）在推理能力和通用自然语言处理（NLP）任务方面取得了显著的进步，但在处理以丰富形态、多样方言和复杂脚本为特点的阿拉伯语数据方面的性能仍然被低估。本文全面评估了多个以推理为重点的LLM，特别强调新推出的DeepSeek模型，涵盖十五项阿拉伯语NLP任务。我们尝试了零样本、少样本和微调等多种策略。这使我们能够系统地评估在覆盖各种应用的数据集上的性能，以检验它们在不同复杂程度下的语言推理能力。我们的实验揭示了几个关键发现。首先，通过精心选择仅三个上下文实例，分类任务的平均提升幅度超过13个F1点——情感分析从35.3%提高到87.5%，改写检测从56.1%提高到87.0%。其次，在零样本设置中，以推理为重点的DeepSeek架构在复杂推理任务上的平均表现优于强大的GPT o4-mini基线12个F1点。第三，与模型规模的等效增加相比，基于LoRA的微调技术可额外提高F1和BLEU分数达8点。相关代码可通过<a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/AraReasoner41299%E8%AE%BF%E9%97%AE%E3%80%82">https://anonymous.4open.science/r/AraReasoner41299访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08768v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在阿拉伯文的自然语言处理（NLP）任务中的表现受到关注。本文采用基准测试方法，评估多个注重推理的LLM模型，特别是新推出的DeepSeek模型在十五项阿拉伯NLP任务中的性能。研究发现，精心选择三个实例进行微调可显著提高分类任务的平均F1得分；DeepSeek架构在零样本设置下优于GPT o4-mini基线模型；基于LoRA的微调技术有助于提高模型性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>精心选择三个实例进行微调可以显著提高分类任务的平均F1得分超过13点。</li>
<li>推理型的DeepSeek模型在零样本设置中表现优越，平均优于GPT o4-mini基线模型12点F1得分。</li>
<li>LoRA微调技术可以进一步提高模型性能，最多可达额外8点F1和BLEU得分。</li>
<li>大型语言模型在应对具有丰富形态、多样方言和复杂脚本的阿拉伯数据上仍有待深入探索。</li>
<li>实验中涉及了零样本、少样本和微调等多种策略，这有助于系统评估模型在不同复杂度层次的语言推理任务中的表现。</li>
<li>论文提供了一个全面的基准测试框架，涵盖了十五项阿拉伯NLP任务，这对于了解语言模型的性能非常有价值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08768">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-421341e02bd06b158e6d7a4040f483ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1b4e28a76543540f761275a06b6abda.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7b71d304e3eb728dd55864cbf2e976d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ClimateViz-A-Benchmark-for-Statistical-Reasoning-and-Fact-Verification-on-Scientific-Charts"><a href="#ClimateViz-A-Benchmark-for-Statistical-Reasoning-and-Fact-Verification-on-Scientific-Charts" class="headerlink" title="ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification   on Scientific Charts"></a>ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification   on Scientific Charts</h2><p><strong>Authors:Ruiran Su, Jiasheng Si, Zhijiang Guo, Janet B. Pierrehumbert</strong></p>
<p>Scientific fact-checking has mostly focused on text and tables, overlooking scientific charts, which are key for presenting quantitative evidence and statistical reasoning. We introduce ClimateViz, the first large-scale benchmark for scientific fact-checking using expert-curated scientific charts. ClimateViz contains 49,862 claims linked to 2,896 visualizations, each labeled as support, refute, or not enough information. To improve interpretability, each example includes structured knowledge graph explanations covering trends, comparisons, and causal relations. We evaluate state-of-the-art multimodal language models, including both proprietary and open-source systems, in zero-shot and few-shot settings. Results show that current models struggle with chart-based reasoning: even the best systems, such as Gemini 2.5 and InternVL 2.5, reach only 76.2 to 77.8 percent accuracy in label-only settings, far below human performance (89.3 and 92.7 percent). Explanation-augmented outputs improve performance in some models. We released our dataset and code alongside the paper. </p>
<blockquote>
<p>科学事实核查主要集中在文本和表格上，忽视了科学图表的重要性，这些图表对于展示定量证据和统计推理至关重要。我们引入了ClimateViz，这是一个使用专家策划的科学图表进行事实核查的大型基准测试。ClimateViz包含与2,896个可视化内容相关的49,862个声明，每个声明都被标记为支持、反驳或信息不足。为了提高可解释性，每个示例都包含结构化知识图谱解释，涵盖趋势、比较和因果关系。我们评估了最先进的多模式语言模型，包括专有和开源系统，在无预设或少预设的情况下进行了评估。结果表明，当前模型在基于图表的推理方面遇到了困难：即使是最好的系统，如Gemini 2.5和InternVL 2.5，在仅标签设置下的准确率也只有76.2%至77.8%，远低于人类的表现（89.3%和92.7%）。解释增强的输出提高了某些模型的表现。我们随论文发布了数据集和代码。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08700v1">PDF</a> </p>
<p><strong>Summary</strong>:<br>引入ClimateViz，首大规模科学事实核查基准测试集，聚焦于图表的形式展示定量证据和统计推理的核查。含49,862条声明与2,896可视化内容链接，每个标注为支持、反驳或信息不足。评估当前先进的多媒体语言模型，包括专有和开源系统，在零样本和少样本环境下表现。结果显示当前模型图表推理能力欠佳，最好的系统如Gemini 2.5和InternVL 2.5在仅标签设置下准确率仅达76.2至77.8%，远低于人类表现（89.3至92.7%）。解释增强输出可提高某些模型性能。已发布数据集和代码。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>科学事实核查主要关注文本和表格，忽略了图表在呈现定量证据和统计推理中的重要性。</li>
<li>引入ClimateViz作为首个大规模科学事实核查基准测试集，包含与可视化内容链接的声明，每个都有支持、反驳或信息不足的标注。</li>
<li>当前先进的多媒体语言模型在零样本和少样本环境下的表现被评估。</li>
<li>这些模型在基于图表的推理方面表现欠佳，即使最好的系统准确率也远低于人类表现。</li>
<li>解释增强的输出可以提高某些模型的表现。</li>
<li>论文中发布了数据集和代码以供使用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08700">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-91d390e349fedf85f76fc4587c4381d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6368c28cf322b83e3b278bd330873e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14b370b22dae9dedaae604369dd5f8e1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7ff5ddf4df5725cb1dbb52e8812f57b5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-da32eeba9056854a8b1b600142fc4a1d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Sample-Efficient-Demonstration-Selection-for-In-Context-Learning"><a href="#Sample-Efficient-Demonstration-Selection-for-In-Context-Learning" class="headerlink" title="Sample Efficient Demonstration Selection for In-Context Learning"></a>Sample Efficient Demonstration Selection for In-Context Learning</h2><p><strong>Authors:Kiran Purohit, V Venktesh, Sourangshu Bhattacharya, Avishek Anand</strong></p>
<p>The in-context learning paradigm with LLMs has been instrumental in advancing a wide range of natural language processing tasks. The selection of few-shot examples (exemplars &#x2F; demonstration samples) is essential for constructing effective prompts under context-length budget constraints. In this paper, we formulate the exemplar selection task as a top-m best arms identification problem. A key challenge in this setup is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel sample-efficient selective exploration strategy that maintains a shortlist of “challenger” arms, which are current candidates for the top-m arms. In each iteration, only one of the arms from this shortlist or the current topm set is pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to stochastic linear bandits setting. CASE achieves remarkable efficiency gains of up to 7x speedup in runtime while requiring 7x fewer LLM calls (87% reduction) without sacrificing performance compared to state-of-the-art exemplar selection methods. We release our code and data at <a target="_blank" rel="noopener" href="https://github.com/kiranpurohit/CASE">https://github.com/kiranpurohit/CASE</a> </p>
<blockquote>
<p>在广泛的自然语言处理任务中，大型语言模型（LLMs）的上下文学习范式起着至关重要的作用。在上下文长度预算约束下构建有效的提示时，选择少量示例（范例&#x2F;演示样本）至关重要。在本文中，我们将范例选择任务表述为识别最优m个臂的问题。在此设置中面临的关键挑战是需要评估的臂的数量呈指数增长。我们提出了CASE（用于范例选择的挑战臂采样），这是一种新颖的样本高效选择性探索策略，它维护一个“挑战者”臂的简短列表，这些是当前可能成为最优m个臂的候选者。在每次迭代中，仅从该简短列表或当前最优m个集合中拉出一个臂，从而减少样本复杂性，因此减少了对大型语言模型的评估次数。此外，我们使用参数化线性评分函数对范例子集（臂）进行建模，从而形成了随机线性强盗设置。CASE在不牺牲性能的情况下实现了高达7倍的加速运行时和减少7倍的大型语言模型调用次数（减少了87%），并获得了显著的效率提升。我们在<a target="_blank" rel="noopener" href="https://github.com/kiranpurohit/CASE%E4%B8%8A%E5%8F%91%E5%B8%83%E4%BA%86%E6%88%91%E4%BB%AC%E7%9A%84%E4%BB%A3%E7%A0%81%E5%92%8C%E6%95%B0%E6%8D%AE%E3%80%82">https://github.com/kiranpurohit/CASE上发布了我们的代码和数据。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08607v1">PDF</a> Accepted at ICML 2025 , 24 pages</p>
<p><strong>Summary</strong></p>
<p>本文介绍了在大型语言模型（LLM）的语境学习范式中，少样本示例的选择对于构建有效提示至关重要。针对此问题，文章提出了一种新的样本高效选择性探索策略CASE（挑战者采样选择法），通过维护一个“挑战者”手臂的简短列表，在每次迭代中只抽取列表中的一个手臂或当前最优手臂，从而减少样本复杂性并降低大型语言模型的评估次数。CASE方法实现了高达7倍的效率提升，同时在不牺牲性能的情况下减少了大型语言模型的调用次数。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）的语境学习范式中，少样本示例的选择对构建有效提示至关重要。</li>
<li>示例选择任务被形式化为寻找最佳的m个手臂的问题。</li>
<li>CASE方法是一种新型的样本高效选择性探索策略，通过维护简短列表的“挑战者”手臂，实现有效识别最优手臂。</li>
<li>在每次迭代中，CASE仅抽取列表中的一个手臂或当前最优手臂进行测试。</li>
<li>通过CASE方法，可以实现高达7倍的效率提升和高达87%的减少大型语言模型调用的需求。</li>
<li>文章公开了相关的代码和数据。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08607">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bb16389da811febe8f5136d9bcec95ed.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Meta-Adaptive-Prompt-Distillation-for-Few-Shot-Visual-Question-Answering"><a href="#Meta-Adaptive-Prompt-Distillation-for-Few-Shot-Visual-Question-Answering" class="headerlink" title="Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering"></a>Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering</h2><p><strong>Authors:Akash Gupta, Amos Storkey, Mirella Lapata</strong></p>
<p>Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to perform new tasks with minimal supervision. However, ICL performance, especially in smaller LMMs, is inconsistent and does not always improve monotonically with increasing examples. We hypothesize that this occurs due to the LMM being overwhelmed by additional information present in the image embeddings, which is not required for the downstream task. To address this, we propose a meta-learning approach that provides an alternative for inducing few-shot capabilities in LMMs, using a fixed set of soft prompts that are distilled from task-relevant image features and can be adapted at test time using a few examples. To facilitate this distillation, we introduce an attention-mapper module that can be easily integrated with the popular LLaVA v1.5 architecture and is jointly learned with soft prompts, enabling task adaptation in LMMs under low-data regimes with just a few gradient steps. Evaluation on the VL-ICL Bench shows that our method consistently outperforms ICL and related prompt-tuning approaches, even under image perturbations, improving task induction and reasoning across visual question answering tasks. </p>
<blockquote>
<p>大型多模态模型（LMM）通常依赖于上下文学习（ICL）来以最小的监督执行新任务。然而，ICL的性能，特别是在较小的LMM中，表现不一致，并且并不总是随着示例的增加而单调提高。我们假设这是因为LMM被图像嵌入中存在的额外信息所淹没，而这些信息对于下游任务来说并不是必需的。为了解决这一问题，我们提出了一种元学习方法，为在LMM中引入少样本能力提供替代方案，使用一套固定的软提示，这些软提示是从任务相关的图像特征中提炼出来的，可以在测试时使用少量示例进行适应。为了促进这种提炼，我们引入了一个注意力映射模块，它可以轻松集成到流行的LLaVA v1.5架构中，并与软提示联合学习，从而在低数据情况下，只需几个梯度步骤即可在LMM中实现任务适应。在VL-ICL Bench上的评估表明，我们的方法始终优于ICL和相关提示调整方法，即使在图像扰动下也能提高视觉问答任务的任务归纳和推理能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.06905v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型多模态模型（LMMs）在少量监督下通过上下文学习（ICL）执行新任务。然而，由于图像嵌入中的额外信息过多导致LMM处理效率低下，尤其是小型LMM中的ICL性能表现不一致且不会随例子数量增加单调改善。为解决这一问题，我们提出了一种元学习方法，通过从任务相关的图像特征中提炼出固定的一组软提示来实现LMM的少量学习，并在测试时通过几个例子进行适应。为此引入了注意力映射模块，可轻松集成到流行的LLaVA v1.5架构中并与软提示联合学习，使得在数据稀缺的情况下只需几个梯度步骤即可适应LMM的任务。在VL-ICL Bench上的评估表明，我们的方法在图像扰动下仍表现稳定，即使在视觉问答任务中也表现出优于ICL和相关提示调整方法的任务归纳和推理能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型多模态模型（LMMs）使用上下文学习（ICL）执行新任务，但性能表现不稳定。</li>
<li>LMM在ICL中容易受到图像嵌入中过多额外信息的影响。</li>
<li>提出一种元学习方法，通过提炼任务相关的图像特征的软提示来实现LMM的少量学习。</li>
<li>引入注意力映射模块，与LLaVA v1.5架构集成，并联合学习软提示。</li>
<li>该方法在少量梯度步骤下适应LMM的任务。</li>
<li>在VL-ICL Bench上的评估显示，该方法在图像扰动下性能稳定并优于ICL和其他方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.06905">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5403d426574517e7856435afb33dded0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0593c1bbdd98a5b3a74bb630e7c81079.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d825c926c830df2ef7acb01e27bafe2.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TextAtari-100K-Frames-Game-Playing-with-Language-Agents"><a href="#TextAtari-100K-Frames-Game-Playing-with-Language-Agents" class="headerlink" title="TextAtari: 100K Frames Game Playing with Language Agents"></a>TextAtari: 100K Frames Game Playing with Language Agents</h2><p><strong>Authors:Wenhao Li, Wenwu Li, Chuyun Shen, Junjie Sheng, Zixiao Huang, Di Wu, Yun Hua, Wei Yin, Xiangfeng Wang, Hongyuan Zha, Bo Jin</strong></p>
<p>We present TextAtari, a benchmark for evaluating language agents on very long-horizon decision-making tasks spanning up to 100,000 steps. By translating the visual state representations of classic Atari games into rich textual descriptions, TextAtari creates a challenging test bed that bridges sequential decision-making with natural language processing. The benchmark includes nearly 100 distinct tasks with varying complexity, action spaces, and planning horizons, all rendered as text through an unsupervised representation learning framework (AtariARI). We evaluate three open-source large language models (Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks (zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how different forms of prior knowledge affect performance on these long-horizon challenges. Four scenarios-Basic, Obscured, Manual Augmentation, and Reference-based-investigate the impact of semantic understanding, instruction comprehension, and expert demonstrations on agent decision-making. Our results reveal significant performance gaps between language agents and human players in extensive planning tasks, highlighting challenges in sequential reasoning, state tracking, and strategic planning across tens of thousands of steps. TextAtari provides standardized evaluation protocols, baseline implementations, and a framework for advancing research at the intersection of language models and planning. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/Lww007/Text-Atari-Agents">https://github.com/Lww007/Text-Atari-Agents</a>. </p>
<blockquote>
<p>我们推出了TextAtari，这是一个用于评估超长周期决策制定任务的自然语言处理基准测试平台，任务周期长达10万步。通过经典Atari游戏的视觉状态表示的文本翻译，生成丰富的文本描述，TextAtari建立了一个挑战性的测试平台，该平台将顺序决策制定与自然语言处理相结合。该基准测试平台包含近100个不同任务，具有不同的复杂性、动作空间和计划期限，所有任务都是通过无监督表示学习框架（AtariARI）以文本形式呈现。我们评估了三个开源大型语言模型（Qwen2.5-7B、Gemma-7B和Llama3.1-8B）在三种代理框架（零样本、少量思考的链和反思推理）下的表现，以观察不同形式的先验知识对这些长期规划挑战的影响。四种场景——基础、隐蔽、手动增强和参考基础——探讨了语义理解、指令理解和专家示范对代理决策制定过程的影响。我们的研究结果表明，在复杂的规划任务中，语言代理与人类玩家之间存在明显的性能差距，这凸显了语言模型在顺序推理、状态跟踪和长期战略规划方面的挑战。TextAtari提供了标准化的评估协议、基准实现和一个框架，用于推进语言模型和规划之间的交叉研究。我们的代码位于 <a target="_blank" rel="noopener" href="https://github.com/Lww007/Text-Atari-Agents%E3%80%82">https://github.com/Lww007/Text-Atari-Agents。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04098v2">PDF</a> 51 pages, 39 figures</p>
<p><strong>Summary</strong></p>
<p>文本介绍了一个名为TextAtari的基准测试，该测试旨在评估语言模型在长达10万步的长周期决策任务中的表现。通过将经典的Atari游戏的视觉状态表示转化为丰富的文本描述，TextAtari创建了一个挑战性的测试平台，该平台结合了序列决策和自然语言处理。该基准测试包括近100个具有不同复杂度、动作空间和规划时间的任务，所有任务均通过无监督表示学习框架呈现为文本。评估了三种开源大型语言模型在不同形式的先验知识下的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TextAtari是一个用于评估语言模型在长周期决策任务中的性能的基准测试。</li>
<li>它通过将Atari游戏的视觉状态转化为文本描述来模拟真实世界场景。</li>
<li>TextAtari包含近100个不同难度的任务，适合测试语言模型的决策能力。</li>
<li>评估了三种大型语言模型在三种不同形式的先验知识下的表现。</li>
<li>基准测试考察了语义理解、指令理解和专家示范对代理决策制定的影响。</li>
<li>研究发现语言模型在复杂的规划任务中与人类的性能差距显著。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04098">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-1eb9926189e9a7a3b31e0e0d1d8e6cbf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d4ba4a8e070f6724fdbe7118858581a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1834b5297bab66416db4eb00e259b4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1f7ef136f2f50968c5fbf6f7587d4256.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47047f50c44cb37898ed12da40830360.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Self-Training-Elicits-Concise-Reasoning-in-Large-Language-Models"><a href="#Self-Training-Elicits-Concise-Reasoning-in-Large-Language-Models" class="headerlink" title="Self-Training Elicits Concise Reasoning in Large Language Models"></a>Self-Training Elicits Concise Reasoning in Large Language Models</h2><p><strong>Authors:Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun</strong></p>
<p>Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens, incurring extraneous inference costs. Upon examination of the output distribution of current LLMs, we find evidence on their latent ability to reason more concisely, relative to their default behavior. To elicit this capability, we propose simple fine-tuning methods which leverage self-generated concise reasoning paths obtained by best-of-N sampling and few-shot conditioning, in task-specific settings. Our combined method achieves a 30% reduction in output tokens on average, across five model families on GSM8K and MATH, while maintaining average accuracy. By exploiting the fundamental stochasticity and in-context learning capabilities of LLMs, our self-training approach robustly elicits concise reasoning on a wide range of models, including those with extensive post-training. Code is available at <a target="_blank" rel="noopener" href="https://github.com/TergelMunkhbat/concise-reasoning">https://github.com/TergelMunkhbat/concise-reasoning</a> </p>
<blockquote>
<p>思维链（CoT）推理使得大型语言模型（LLM）能够通过中间标记利用额外的计算来解决复杂的任务。然而，我们认为典型的推理轨迹包含许多冗余的标记，产生了额外的推理成本。在检查当前LLM的输出分布时，我们发现它们相对于默认行为有进行更简洁推理的潜在能力。为了激发这一能力，我们提出了简单的微调方法，这些方法利用通过最佳N采样和少样本条件在特定任务环境中获得的自我生成的简洁推理路径。我们的组合方法在GSM8K和MATH上平均减少了五类模型的输出标记数量达30%，同时保持了平均准确性。通过利用LLM的基本随机性和上下文学习能力，我们的自我训练方法能够在广泛的模型上稳健地激发简洁推理，包括那些经过大量训练后的模型。代码可在<a target="_blank" rel="noopener" href="https://github.com/TergelMunkhbat/concise-reasoning%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/TergelMunkhbat/concise-reasoning找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20122v3">PDF</a> 26 pages, 10 figures, 23 tables. Accepted to Findings of ACL 2025</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）通过链式思维（CoT）推理利用中间令牌解决复杂任务。然而，我们提出，典型的推理轨迹包含许多冗余令牌，导致额外的推理成本。通过检查当前LLM的输出分布，我们发现它们相对于默认行为有进行更简洁推理的潜在能力。为了激发这种能力，我们提出通过最佳N采样和少样本条件等简单微调方法，在特定任务环境中利用自我生成的简洁推理路径。我们的综合方法在五大家族模型上平均减少了约30%的输出令牌，同时保持了平均准确性。我们的自我训练方法能够可靠地激发模型的简洁推理能力，包括那些经过大量训练后的模型。相关代码可在XXX获取。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型使用链式思维（CoT）进行推理以增强复杂任务性能。</li>
<li>通常的推理过程中存在冗余令牌，导致额外的推理成本。</li>
<li>当前LLM具有相对于默认行为的更简洁推理的潜在能力。</li>
<li>通过最佳N采样和少样本条件等简单微调方法，可激发这种能力。</li>
<li>方法在多个模型上实现平均输出令牌减少约30%，同时保持平均准确性。</li>
<li>利用LLM的基本随机性和上下文学习能力，自我训练方法可激发模型的简洁推理能力。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20122">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-01bd51cf355ba2bd9554a5a5c451e0f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-369fde6c06517113b9e8b389ce3fba2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c41c22530a71d65616b660cb13bbedb3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-52a205504d20d5833915ab13c9833aa7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fdfbdcaea9d19ca431edeee14dae9ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ceac12575253c651125a8a9d050e1703.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-12/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-12/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-13/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f2339f60031315509f905003087eeda9.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning 方向最新论文已更新，请持续关注 Update in 2025-06-13  A Shortcut-aware Video-QA Benchmark for Physical Understanding via   Minimal Video Pairs
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-12/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-47047f50c44cb37898ed12da40830360.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-06-12  VIKI-R Coordinating Embodied Multi-Agent Cooperation via Reinforcement   Learning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29474.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
