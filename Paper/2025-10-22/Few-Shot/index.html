<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  AcademicEval Live Long-Context LLM Benchmark">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-5c78eca75c00e10caf8ca8abb34e264f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073056&auth_key=1761073056-0-0-563e0c2bcb170175f696383f01fffec9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-22-æ›´æ–°"><a href="#2025-10-22-æ›´æ–°" class="headerlink" title="2025-10-22 æ›´æ–°"></a>2025-10-22 æ›´æ–°</h1><h2 id="AcademicEval-Live-Long-Context-LLM-Benchmark"><a href="#AcademicEval-Live-Long-Context-LLM-Benchmark" class="headerlink" title="AcademicEval: Live Long-Context LLM Benchmark"></a>AcademicEval: Live Long-Context LLM Benchmark</h2><p><strong>Authors:Haozhen Zhang, Tao Feng, Pengrui Han, Jiaxuan You</strong></p>
<p>Large Language Models (LLMs) have recently achieved remarkable performance in long-context understanding. However, current long-context LLM benchmarks are limited by rigid context length, labor-intensive annotation, and the pressing challenge of label leakage issues during LLM training. Therefore, we propose \textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context generation tasks. \textsc{AcademicEval} adopts papers on arXiv to introduce several academic writing tasks with long-context inputs, \textit{i.e.}, \textsc{Title}, \textsc{Abstract}, \textsc{Introduction}, and \textsc{Related Work}, which cover a wide range of abstraction levels and require no manual labeling. Moreover, \textsc{AcademicEval} integrates high-quality and expert-curated few-shot demonstrations from a collected co-author graph to enable flexible context length. Especially, \textsc{AcademicEval} features an efficient live evaluation, ensuring no label leakage. We conduct a holistic evaluation on \textsc{AcademicEval}, and the results illustrate that LLMs perform poorly on tasks with hierarchical abstraction levels and tend to struggle with long few-shot demonstrations, highlighting the challenge of our benchmark. Through experimental analysis, we also reveal some insights for enhancing LLMsâ€™ long-context modeling capabilities. Code is available at <a target="_blank" rel="noopener" href="https://github.com/ulab-uiuc/AcademicEval">https://github.com/ulab-uiuc/AcademicEval</a> </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€è¿‘åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆç»©ã€‚ç„¶è€Œï¼Œå½“å‰çš„é•¿ä¸Šä¸‹æ–‡LLMåŸºå‡†æµ‹è¯•å—åˆ°ä¸¥æ ¼ä¸Šä¸‹æ–‡é•¿åº¦ã€åŠ³åŠ¨å¯†é›†å‹çš„æ ‡æ³¨ä»¥åŠLLMè®­ç»ƒè¿‡ç¨‹ä¸­æ ‡ç­¾æ³„éœ²é—®é¢˜çš„ç´§è¿«æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†\emph{AcademicEval}ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆä»»åŠ¡ä¸­LLMsæ€§èƒ½çš„å®æ—¶åŸºå‡†æµ‹è¯•ã€‚AcademicEvalé‡‡ç”¨arXivä¸Šçš„è®ºæ–‡æ¥å¼•å…¥å…·æœ‰é•¿ä¸Šä¸‹æ–‡è¾“å…¥çš„å‡ ä¸ªå­¦æœ¯å†™ä½œä»»åŠ¡ï¼Œä¾‹å¦‚\emph{Title}ã€\emph{Abstract}ã€\emph{Introduction}å’Œ\emph{Related Work}ï¼Œè¿™äº›ä»»åŠ¡æ¶µç›–äº†å¹¿æ³›çš„æŠ½è±¡å±‚æ¬¡ï¼Œä¸”æ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚æ­¤å¤–ï¼ŒAcademicEvalé›†æˆäº†ä»æ”¶é›†çš„åˆè‘—è€…å›¾ä¸­ç²¾å¿ƒæŒ‘é€‰çš„é«˜è´¨é‡ã€ä¸“å®¶åˆ¶ä½œçš„å°‘æ ·æœ¬æ¼”ç¤ºï¼Œä»¥å®ç°çµæ´»çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ç‰¹åˆ«åœ°ï¼ŒAcademicEvalå…·æœ‰é«˜æ•ˆçš„å®æ—¶è¯„ä¼°åŠŸèƒ½ï¼Œç¡®ä¿æ— æ ‡ç­¾æ³„éœ²ã€‚æˆ‘ä»¬å¯¹AcademicEvalè¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œç»“æœè¡¨æ˜LLMsåœ¨å¤„ç†å…·æœ‰åˆ†å±‚æŠ½è±¡å±‚æ¬¡çš„ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”åœ¨é¢å¯¹é•¿çš„å°‘æ ·æœ¬æ¼”ç¤ºæ—¶å¾€å¾€æ„Ÿåˆ°å›°éš¾ï¼Œè¿™çªæ˜¾äº†æˆ‘ä»¬åŸºå‡†æµ‹è¯•çš„æŒ‘æˆ˜æ€§ã€‚é€šè¿‡å®éªŒåˆ†æï¼Œæˆ‘ä»¬è¿˜æ­ç¤ºäº†ä¸€äº›å¢å¼ºLLMsé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›çš„è§è§£ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ulab-uiuc/AcademicEval%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/ulab-uiuc/AcademicEvalæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17725v1">PDF</a> Accepted by TMLR. Code is available at   <a target="_blank" rel="noopener" href="https://github.com/ulab-uiuc/AcademicEval">https://github.com/ulab-uiuc/AcademicEval</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£é•¿æ–‡æœ¬æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰é•¿æ–‡æœ¬LLMåŸºå‡†æµ‹è¯•å­˜åœ¨ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ã€æ ‡æ³¨å·¥ä½œé‡å¤§å’Œæ ‡ç­¾æ³„éœ²ç­‰é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†AcademicEvalï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°LLMsåœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„å®æ—¶åŸºå‡†æµ‹è¯•ã€‚AcademicEvalé‡‡ç”¨arXivä¸Šçš„è®ºæ–‡ï¼Œå¼•å…¥äº†å¤šä¸ªé•¿æ–‡æœ¬è¾“å…¥çš„å­¦æœ¯å†™ä½œä»»åŠ¡ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€ä»‹ç»å’Œç›¸å…³å·¥ä½œç­‰ï¼Œæ¶µç›–å¹¿æ³›çš„æŠ½è±¡å±‚æ¬¡ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚æ­¤å¤–ï¼ŒAcademicEvalé€šè¿‡æ”¶é›†çš„ä½œè€…åˆä½œå›¾é›†æˆäº†é«˜è´¨é‡å’Œä¸“å®¶ç­–åˆ’çš„å°‘é‡æ¼”ç¤ºï¼Œå¯å®ç°çµæ´»çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒAcademicEvalå…·æœ‰é«˜æ•ˆçš„å®æ—¶è¯„ä¼°åŠŸèƒ½ï¼Œç¡®ä¿æ— æ ‡ç­¾æ³„éœ²ã€‚æˆ‘ä»¬å¯¹AcademicEvalè¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œç»“æœè¡¨æ˜LLMsåœ¨å¤„ç†å…·æœ‰å±‚æ¬¡æŠ½è±¡çš„ä»»åŠ¡å’Œé•¿å°‘é‡æ¼”ç¤ºæ—¶è¡¨ç°è¾ƒå·®ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬åŸºå‡†æµ‹è¯•çš„æŒ‘æˆ˜æ€§ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡å®éªŒåˆ†ææä¾›äº†ä¸€äº›æé«˜LLMsé•¿æ–‡æœ¬å»ºæ¨¡èƒ½åŠ›çš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ–‡æœ¬ç†è§£æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½ã€‚</li>
<li>å½“å‰é•¿æ–‡æœ¬LLMåŸºå‡†æµ‹è¯•å­˜åœ¨ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ã€æ ‡æ³¨å·¥ä½œé‡å¤§å’Œæ ‡ç­¾æ³„éœ²ç­‰é—®é¢˜ã€‚</li>
<li>æå‡ºäº†AcademicEvalå®æ—¶åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°LLMsåœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>AcademicEvalé‡‡ç”¨arXivè®ºæ–‡ï¼Œæ¶µç›–å¤šç§å­¦æœ¯å†™ä½œä»»åŠ¡ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€ä»‹ç»å’Œç›¸å…³å·¥ä½œç­‰ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚</li>
<li>AcademicEvalé€šè¿‡ä½œè€…åˆä½œå›¾é›†æˆé«˜è´¨é‡å’Œä¸“å®¶ç­–åˆ’çš„å°‘é‡æ¼”ç¤ºï¼Œå®ç°çµæ´»çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</li>
<li>LLMsåœ¨å¤„ç†å…·æœ‰å±‚æ¬¡æŠ½è±¡çš„ä»»åŠ¡å’Œé•¿å°‘é‡æ¼”ç¤ºæ—¶è¡¨ç°è¾ƒå·®ï¼Œå‡¸æ˜¾äº†åŸºå‡†æµ‹è¯•çš„æŒ‘æˆ˜æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17725">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8ad8ea870c8b511a45b82ce4cd0d6bd5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072946&auth_key=1761072946-0-0-62ff21e847893f154abde8369f446d23&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3f421f7b117f6104a380163d280845d3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072953&auth_key=1761072953-0-0-23ceeb86362c82eb123779ee19040032&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-99eca7c7025ef26280ec24a937ae3727~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072960&auth_key=1761072960-0-0-c1afc81b168dc10704a32e3e5200e26b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bd5fd9418c18e1492a4831e1ac7ae154~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072966&auth_key=1761072966-0-0-84d57615ebd37efedaacbb058cccdc77&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PANER-A-Paraphrase-Augmented-Framework-for-Low-Resource-Named-Entity-Recognition"><a href="#PANER-A-Paraphrase-Augmented-Framework-for-Low-Resource-Named-Entity-Recognition" class="headerlink" title="PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity   Recognition"></a>PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity   Recognition</h2><p><strong>Authors:Nanda Kumar Rengarajan, Jun Yan, Chun Wang</strong></p>
<p>Named Entity Recognition (NER) is a critical task that requires substantial annotated data, making it challenging in low-resource scenarios where label acquisition is expensive. While zero-shot and instruction-tuned approaches have made progress, they often fail to generalize to domain-specific entities and do not effectively utilize limited available data. We present a lightweight few-shot NER framework that addresses these challenges through two key innovations: (1) a new instruction tuning template with a simplified output format that combines principles from prior IT approaches to leverage the large context window of recent state-of-the-art LLMs; (2) introducing a strategic data augmentation technique that preserves entity information while paraphrasing the surrounding context, thereby expanding our training data without compromising semantic relationships. Experiments on benchmark datasets show that our method achieves performance comparable to state-of-the-art models on few-shot and zero-shot tasks, with our few-shot approach attaining an average F1 score of 80.1 on the CrossNER datasets. Models trained with our paraphrasing approach show consistent improvements in F1 scores of up to 17 points over baseline versions, offering a promising solution for groups with limited NER training data and compute power. </p>
<blockquote>
<p>å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ˜¯ä¸€é¡¹éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®çš„å…³é”®ä»»åŠ¡ï¼Œè¿™åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼ˆè·å–æ ‡ç­¾æˆæœ¬é«˜æ˜‚ï¼‰æ„æˆæŒ‘æˆ˜ã€‚è™½ç„¶é›¶æ ·æœ¬å’ŒæŒ‡ä»¤å¾®è°ƒæ–¹æ³•å·²ç»å–å¾—è¿›å±•ï¼Œä½†å®ƒä»¬é€šå¸¸éš¾ä»¥æ¨å¹¿åˆ°ç‰¹å®šé¢†åŸŸçš„å®ä½“ï¼Œå¹¶ä¸”æœªèƒ½æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„å¯å¾—æ•°æ®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„å°‘æ ·æœ¬NERæ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªæ–°çš„æŒ‡ä»¤å¾®è°ƒæ¨¡æ¿ï¼Œé‡‡ç”¨ç®€åŒ–çš„è¾“å‡ºæ ¼å¼ï¼Œç»“åˆå…ˆå‰çš„ITåŸåˆ™ï¼Œä»¥åˆ©ç”¨æœ€æ–°çš„å…ˆè¿›LLMçš„å¤§ä¸Šä¸‹æ–‡çª—å£ï¼›ï¼ˆ2ï¼‰å¼•å…¥äº†ä¸€ç§æˆ˜ç•¥æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œå®ƒåœ¨æ”¹è¿°å‘¨å›´ä¸Šä¸‹æ–‡çš„åŒæ—¶ä¿ç•™å®ä½“ä¿¡æ¯ï¼Œä»è€Œæ‰©å¤§äº†æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®è€Œä¸æŸå®³è¯­ä¹‰å…³ç³»ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“ï¼Œæˆ‘ä»¬çš„å°‘æ ·æœ¬æ–¹æ³•åœ¨CrossNERæ•°æ®é›†ä¸Šå¹³å‡F1åˆ†æ•°ä¸º80.1ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ”¹è¿°æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šè¾ƒåŸºçº¿ç‰ˆæœ¬æœ‰æŒç»­ä¸”é«˜è¾¾17åˆ†çš„æ”¹è¿›ï¼Œä¸ºæ‹¥æœ‰æœ‰é™çš„NERè®­ç»ƒæ•°æ®å’Œè®¡ç®—èƒ½åŠ›çš„å›¢é˜Ÿæä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17720v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§è§£å†³ä½èµ„æºåœºæ™¯ä¸‹å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä»»åŠ¡æŒ‘æˆ˜çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹æ¥å®ç°ï¼šä¸€æ˜¯ä½¿ç”¨æ–°çš„æŒ‡ä»¤å¾®è°ƒæ¨¡æ¿ï¼Œç®€åŒ–è¾“å‡ºæ ¼å¼ï¼Œåˆ©ç”¨æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤§çš„ä¸Šä¸‹æ–‡çª—å£ï¼›äºŒæ˜¯å¼•å…¥æˆ˜ç•¥æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œåœ¨æ”¹å†™å‘¨å›´è¯­å¢ƒçš„åŒæ—¶ä¿ç•™å®ä½“ä¿¡æ¯ï¼Œä»è€Œæ‰©å¤§è®­ç»ƒæ•°æ®ï¼Œä¸æŸå®³è¯­ä¹‰å…³ç³»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¸æœ€æ–°æ¨¡å‹ç›¸å½“ï¼Œç‰¹åˆ«æ˜¯åœ¨å°‘æ ·æœ¬ä»»åŠ¡ä¸Šï¼Œå¹³å‡F1åˆ†æ•°è¾¾åˆ°80.1ã€‚ä½¿ç”¨æ”¹å†™æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šå¹³å‡æé«˜äº†17ä¸ªç‚¹ï¼Œä¸ºè§£å†³æœ‰é™NERè®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºçš„å›¢é˜Ÿæä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„å°‘æ ·æœ¬å‘½åå®ä½“è¯†åˆ«æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹æ¥è§£å†³ä½èµ„æºåœºæ™¯ä¸‹çš„æŒ‘æˆ˜ã€‚</li>
<li>é‡‡ç”¨äº†æ–°çš„æŒ‡ä»¤å¾®è°ƒæ¨¡æ¿ï¼Œç®€åŒ–äº†è¾“å‡ºæ ¼å¼ï¼Œå¹¶å……åˆ†åˆ©ç”¨äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤§çš„ä¸Šä¸‹æ–‡çª—å£ã€‚</li>
<li>å¼•å…¥äº†æˆ˜ç•¥æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨ä¸æŸå®³è¯­ä¹‰å…³ç³»çš„æƒ…å†µä¸‹æ‰©å¤§è®­ç»ƒæ•°æ®ã€‚</li>
<li>åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜ç§€ï¼Œå°‘æ ·æœ¬ä»»åŠ¡å¹³å‡F1åˆ†æ•°è¾¾åˆ°80.1ã€‚</li>
<li>ä½¿ç”¨æ”¹å†™æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šç›¸æ¯”åŸºçº¿ç‰ˆæœ¬æœ‰äº†æ˜¾è‘—çš„æé«˜ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºè§£å†³NERè®­ç»ƒæ•°æ®æœ‰é™å’Œè®¡ç®—èµ„æºæœ‰é™çš„å›¢é˜Ÿæä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cc6bbc29979f2f477f410b57bae66946~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072974&auth_key=1761072974-0-0-22c58807fb206f9fb871f4755014d752&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-186bc6cba6c491a733771d815382d2a0~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072981&auth_key=1761072981-0-0-48141b40c9971e9bf274b5964715c60f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d98952cbb9841c4d567bee1f1abcea12~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072987&auth_key=1761072987-0-0-f8f69c4f97d554800b4b48e9b0678eb3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1890e0dbb30892ef97c724c28bc6d7e3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761072993&auth_key=1761072993-0-0-e1d4fd586eb52dbe9f1e72439616d495&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ddb0f8eacbaed6cdbeec22d2987167d9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073000&auth_key=1761073000-0-0-c12f92587c1af38dc1dcdb2bb920dba6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1228736c344e0ba40c1f5bcf95f5cf26~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073007&auth_key=1761073007-0-0-4897179afdf54e7b356688e66c2391f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="On-the-Fly-OVD-Adaptation-with-FLAME-Few-shot-Localization-via-Active-Marginal-Samples-Exploration"><a href="#On-the-Fly-OVD-Adaptation-with-FLAME-Few-shot-Localization-via-Active-Marginal-Samples-Exploration" class="headerlink" title="On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active   Marginal-Samples Exploration"></a>On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active   Marginal-Samples Exploration</h2><p><strong>Authors:Yehonathan Refael, Amit Aides, Aviad Barzilai, George Leifman, Genady Beryozkin, Vered Silverman, Bolous Jaber, Tomer Shekel</strong></p>
<p>Open-vocabulary object detection (OVD) models offer remarkable flexibility by detecting objects from arbitrary text queries. However, their zero-shot performance in specialized domains like Remote Sensing (RS) is often compromised by the inherent ambiguity of natural language, limiting critical downstream applications. For instance, an OVD model may struggle to distinguish between fine-grained classes such as â€œfishing boatâ€ and â€œyachtâ€ since their embeddings are similar and often inseparable. This can hamper specific user goals, such as monitoring illegal fishing, by producing irrelevant detections. To address this, we propose a cascaded approach that couples the broad generalization of a large pre-trained OVD model with a lightweight few-shot classifier. Our method first employs the zero-shot model to generate high-recall object proposals. These proposals are then refined for high precision by a compact classifier trained in real-time on only a handful of user-annotated examples - drastically reducing the high costs of RS imagery annotation.The core of our framework is FLAME, a one-step active learning strategy that selects the most informative samples for training. FLAME identifies, on the fly, uncertain marginal candidates near the decision boundary using density estimation, followed by clustering to ensure sample diversity. This efficient sampling technique achieves high accuracy without costly full-model fine-tuning and enables instant adaptation, within less then a minute, which is significantly faster than state-of-the-art alternatives.Our method consistently surpasses state-of-the-art performance on RS benchmarks, establishing a practical and resource-efficient framework for adapting foundation models to specific user needs. </p>
<blockquote>
<p>å¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹ï¼ˆOVDï¼‰æ¨¡å‹é€šè¿‡ä»ä»»æ„æ–‡æœ¬æŸ¥è¯¢ä¸­æ£€æµ‹å¯¹è±¡ï¼Œæä¾›äº†æƒŠäººçš„çµæ´»æ€§ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨é¥æ„Ÿï¼ˆRSï¼‰ç­‰ç‰¹å®šé¢†åŸŸçš„é›¶æ ·æœ¬æ€§èƒ½é€šå¸¸å—åˆ°è‡ªç„¶è¯­è¨€å›ºæœ‰æ¨¡ç³Šæ€§çš„é™åˆ¶ï¼Œä»è€Œå½±å“å…³é”®ä¸‹æ¸¸åº”ç”¨ç¨‹åºçš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼ŒOVDæ¨¡å‹å¯èƒ½åœ¨åŒºåˆ†ç²¾ç»†ç±»åˆ«ï¼ˆå¦‚â€œæ¸”èˆ¹â€å’Œâ€œæ¸¸è‰‡â€ï¼‰æ—¶é‡åˆ°å›°éš¾ï¼Œå› ä¸ºå®ƒä»¬çš„åµŒå…¥ç›¸ä¼¼ä¸”é€šå¸¸æ— æ³•åŒºåˆ†ã€‚è¿™å¯èƒ½ä¼šé˜»ç¢ç‰¹å®šçš„ç”¨æˆ·ç›®æ ‡ï¼Œä¾‹å¦‚é€šè¿‡äº§ç”Ÿæ— å…³çš„æ£€æµ‹ç»“æœæ¥ç›‘æµ‹éæ³•æ•é±¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§çº§è”æ–¹æ³•ï¼Œå°†å¤§å‹é¢„è®­ç»ƒOVDæ¨¡å‹çš„å¹¿æ³›æ³›åŒ–ä¸è½»é‡çº§å°æ ·æœ¬åˆ†ç±»å™¨ç›¸ç»“åˆã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆä½¿ç”¨é›¶æ ·æœ¬æ¨¡å‹ç”Ÿæˆé«˜å¬å›ç‡å¯¹è±¡ææ¡ˆã€‚ç„¶åï¼Œä½¿ç”¨ä»…å®æ—¶è®­ç»ƒå°‘é‡ç”¨æˆ·æ³¨é‡Šçš„ç¤ºä¾‹çš„ç´§å‡‘åˆ†ç±»å™¨å¯¹è¿™äº›æè®®è¿›è¡Œç²¾ç¡®åº¦çš„æ”¹è¿›ï¼Œå¤§å¤§é™ä½äº†é¥æ„Ÿå›¾åƒæ³¨é‡Šçš„æˆæœ¬ã€‚æˆ‘ä»¬æ¡†æ¶çš„æ ¸å¿ƒæ˜¯FLAMEï¼Œè¿™æ˜¯ä¸€ç§ä¸€æ­¥å¼ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œå¯é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒã€‚FLAMEå³æ—¶è¯†åˆ«å†³ç­–è¾¹ç•Œé™„è¿‘çš„ä¸ç¡®å®šè¾¹ç¼˜å€™é€‰å¯¹è±¡ï¼Œä½¿ç”¨å¯†åº¦ä¼°è®¡è¿›è¡Œç­›é€‰å’Œé›†ç¾¤ç¡®ä¿æ ·æœ¬å¤šæ ·æ€§ã€‚è¿™ç§é«˜æ•ˆçš„é‡‡æ ·æŠ€æœ¯æ— éœ€æ˜‚è´µçš„å…¨æ¨¡å‹å¾®è°ƒå³å¯å®ç°é«˜å‡†ç¡®æ€§ï¼Œå¹¶èƒ½åœ¨ä¸åˆ°ä¸€åˆ†é’Ÿçš„æ—¶é—´å†…å®ç°å³æ—¶é€‚åº”ï¼Œè¿™æ˜æ˜¾ä¼˜äºæœ€æ–°çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨é¥æ„ŸåŸºå‡†æµ‹è¯•ä¸Šå§‹ç»ˆè¶…è¶Šæœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œä¸ºæ ¹æ®ç‰¹å®šç”¨æˆ·éœ€æ±‚è°ƒæ•´åŸºç¡€æ¨¡å‹å»ºç«‹äº†ä¸€ä¸ªå®ç”¨ä¸”èµ„æºé«˜æ•ˆçš„æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17670v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†å¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹æ¨¡å‹åœ¨é¥æ„Ÿé¢†åŸŸçš„åº”ç”¨æŒ‘æˆ˜ã€‚ä¸ºè§£å†³æ¨¡å‹åœ¨ç²¾ç»†ç±»åˆ«åŒºåˆ†ä¸Šçš„ä¸è¶³ï¼Œæå‡ºä¸€ç§ç»“åˆå¤§å‹é¢„è®­ç»ƒOVDæ¨¡å‹å’Œè½»é‡çº§å°‘æ ·æœ¬åˆ†ç±»å™¨çš„çº§è”æ–¹æ³•ã€‚é¦–å…ˆåˆ©ç”¨é›¶æ ·æœ¬æ¨¡å‹ç”Ÿæˆé«˜å¬å›ç‡çš„å¯¹è±¡ææ¡ˆï¼Œç„¶åé€šè¿‡å®æ—¶è®­ç»ƒå°‘é‡ç”¨æˆ·æ ‡æ³¨çš„æ ·æœ¬å¯¹ææ¡ˆè¿›è¡Œç²¾ç‚¼ï¼Œä»¥æé«˜ç²¾åº¦ã€‚æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€æ­¥å¼ä¸»åŠ¨å­¦ä¹ ç­–ç•¥FLAMEï¼Œèƒ½é€‰æ‹©æœ€å…·æœ‰ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒã€‚FLAMEé€šè¿‡å¯†åº¦ä¼°è®¡å’Œèšç±»æŠ€æœ¯ï¼Œå¿«é€Ÿè¯†åˆ«å†³ç­–è¾¹ç•Œé™„è¿‘çš„ä¸ç¡®å®šè¾¹ç¼˜å€™é€‰æ ·æœ¬ï¼Œç¡®ä¿æ ·æœ¬å¤šæ ·æ€§ã€‚è¯¥æ–¹æ³•åœ¨ä¸è¿›è¡Œæ˜‚è´µçš„å…¨æ¨¡å‹å¾®è°ƒçš„æƒ…å†µä¸‹å®ç°äº†é«˜æ•ˆç‡é‡‡æ ·å’Œé«˜ç²¾åº¦ï¼Œå¯åœ¨ä¸åˆ°ä¸€åˆ†é’Ÿå†…å®Œæˆé€‚åº”ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ›¿ä»£æ–¹æ¡ˆã€‚æ­¤æ–¹æ³•åœ¨é¥æ„ŸåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ€§èƒ½ï¼Œä¸ºå°†åŸºç¡€æ¨¡å‹é€‚åº”ç‰¹å®šç”¨æˆ·éœ€æ±‚å»ºç«‹äº†å®ç”¨ä¸”èµ„æºé«˜æ•ˆçš„æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OVDæ¨¡å‹å¯é€šè¿‡ä»»æ„æ–‡æœ¬æŸ¥è¯¢æ£€æµ‹å¯¹è±¡ï¼Œä½†åœ¨é¥æ„Ÿç­‰ç‰¹å®šé¢†åŸŸï¼Œå…¶é›¶æ ·æœ¬æ€§èƒ½ä¼šå—åˆ°è‡ªç„¶è¯­è¨€å›ºæœ‰æ¨¡ç³Šæ€§çš„åˆ¶çº¦ã€‚</li>
<li>ç°æœ‰OVDæ¨¡å‹åœ¨ç²¾ç»†ç±»åˆ«åŒºåˆ†ï¼ˆå¦‚æ¸”èˆ¹å’Œæ¸¸è‰‡ï¼‰ä¸Šå¯èƒ½å­˜åœ¨å›°éš¾ã€‚</li>
<li>æå‡ºç»“åˆå¤§å‹é¢„è®­ç»ƒOVDæ¨¡å‹å’Œè½»é‡çº§å°‘æ ·æœ¬åˆ†ç±»å™¨çš„çº§è”æ–¹æ³•ï¼Œä»¥æé«˜å¯¹è±¡æ£€æµ‹çš„ç²¾åº¦å’Œæ•ˆç‡ã€‚</li>
<li>ä½¿ç”¨é›¶æ ·æœ¬æ¨¡å‹ç”Ÿæˆé«˜å¬å›ç‡çš„å¯¹è±¡ææ¡ˆï¼Œç„¶åé€šè¿‡å®æ—¶è®­ç»ƒå°‘é‡ç”¨æˆ·æ ‡æ³¨çš„æ ·æœ¬è¿›è¡Œç²¾ç‚¼ã€‚</li>
<li>æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€æ­¥å¼ä¸»åŠ¨å­¦ä¹ ç­–ç•¥FLAMEï¼Œèƒ½é€‰æ‹©æœ€å…·æœ‰ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œå®ç°é«˜æ•ˆç‡é‡‡æ ·å’Œé«˜ç²¾åº¦ã€‚</li>
<li>FLAMEé€šè¿‡å¯†åº¦ä¼°è®¡å’Œèšç±»æŠ€æœ¯è¯†åˆ«ä¸ç¡®å®šè¾¹ç¼˜å€™é€‰æ ·æœ¬ï¼Œç¡®ä¿æ ·æœ¬å¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17670">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3c852bf77b4f2693288ff859137f90f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073013&auth_key=1761073013-0-0-7145457aee220f6ad97d8bb0437a10cf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b3bdba836ff51f6b6c9b3500fd4437ed~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073020&auth_key=1761073020-0-0-8e320f19b599b83fa482ad288e1c4d12&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d65706092a1d0fbfa911420c09275408~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073027&auth_key=1761073027-0-0-0e7911c6c8b912536d8c4537cbef3615&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="One-Dinomaly2-Detect-Them-All-A-Unified-Framework-for-Full-Spectrum-Unsupervised-Anomaly-Detection"><a href="#One-Dinomaly2-Detect-Them-All-A-Unified-Framework-for-Full-Spectrum-Unsupervised-Anomaly-Detection" class="headerlink" title="One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum   Unsupervised Anomaly Detection"></a>One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum   Unsupervised Anomaly Detection</h2><p><strong>Authors:Jia Guo, Shuai Lu, Lei Fan, Zelin Li, Donglin Di, Yang Song, Weihang Zhang, Wenbing Zhu, Hong Yan, Fang Chen, Huiqi Li, Hongen Liao</strong></p>
<p>Unsupervised anomaly detection (UAD) has evolved from building specialized single-class models to unified multi-class models, yet existing multi-class models significantly underperform the most advanced one-for-one counterparts. Moreover, the field has fragmented into specialized methods tailored to specific scenarios (multi-class, 3D, few-shot, etc.), creating deployment barriers and highlighting the need for a unified solution. In this paper, we present Dinomaly2, the first unified framework for full-spectrum image UAD, which bridges the performance gap in multi-class models while seamlessly extending across diverse data modalities and task settings. Guided by the â€œless is moreâ€ philosophy, we demonstrate that the orchestration of five simple element achieves superior performance in a standard reconstruction-based framework. This methodological minimalism enables natural extension across diverse tasks without modification, establishing that simplicity is the foundation of true universality. Extensive experiments on 12 UAD benchmarks demonstrate Dinomaly2â€™s full-spectrum superiority across multiple modalities (2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class, inference-unified multi-class, few-shot) and application domains (industrial, biological, outdoor). For example, our multi-class model achieves unprecedented 99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For multi-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art performance with minimum adaptations. Moreover, using only 8 normal examples per class, our method surpasses previous full-shot models, achieving 98.7% and 97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design, computational scalability, and universal applicability positions Dinomaly2 as a unified solution for the full spectrum of real-world anomaly detection applications. </p>
<blockquote>
<p>æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆUADï¼‰å·²ç»ä»æ„å»ºä¸“é—¨å•ç±»æ¨¡å‹å‘å±•åˆ°ç»Ÿä¸€å¤šç±»æ¨¡å‹ï¼Œä½†ç°æœ‰å¤šç±»æ¨¡å‹æ˜¾è‘—è½åäºæœ€å…ˆè¿›çš„ä¸€å¯¹ä¸€ä¸ªæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥é¢†åŸŸå·²ç»ç»†åˆ†ä¸ºé’ˆå¯¹ç‰¹å®šåœºæ™¯ï¼ˆå¤šç±»ã€ä¸‰ç»´ã€å°æ ·æœ¬ç­‰ï¼‰çš„ä¸“ç”¨æ–¹æ³•ï¼Œé€ æˆäº†éƒ¨ç½²éšœç¢å¹¶å‡¸æ˜¾äº†å¯¹ç»Ÿä¸€è§£å†³æ–¹æ¡ˆçš„éœ€æ±‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Dinomaly2ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºå…¨é¢‘è°±å›¾åƒUADçš„ç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒç¼©å°äº†å¤šç±»æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼ŒåŒæ—¶æ— ç¼åœ°æ‰©å±•åˆ°ä¸åŒçš„æ•°æ®æ¨¡å¼å’Œä»»åŠ¡è®¾ç½®ã€‚ç§‰æ‰¿â€œå°‘å³æ˜¯å¤šâ€çš„ç†å¿µï¼Œæˆ‘ä»¬è¯æ˜äº†äº”ç§ç®€å•å…ƒç´ çš„ååŒèƒ½åœ¨æ ‡å‡†çš„é‡å»ºæ¡†æ¶ä¸­è¾¾åˆ°å“è¶Šçš„æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•è®ºä¸Šçš„ç®€çº¦æ€§ä½¿å¾—è·¨ä¸åŒä»»åŠ¡çš„è‡ªç„¶æ‰©å±•æˆä¸ºå¯èƒ½ï¼Œè€Œæ— éœ€è¿›è¡Œä¿®æ”¹ï¼Œè¯æ˜äº†ç®€çº¦æ€§æ˜¯çœŸæ­£æ™®éæ€§çš„åŸºç¡€ã€‚åœ¨12ä¸ªUADåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDinomaly2åœ¨å¤šæ¨¡å¼ï¼ˆäºŒç»´ã€å¤šè§†è§’ã€RGB-3Dã€RGB-IRï¼‰ã€ä»»åŠ¡è®¾ç½®ï¼ˆå•ç±»ã€å¤šç±»ã€æ¨ç†ç»Ÿä¸€å¤šç±»ã€å°æ ·æœ¬ï¼‰å’Œåº”ç”¨é¢†åŸŸï¼ˆå·¥ä¸šã€ç”Ÿç‰©ã€æˆ·å¤–ï¼‰ä¸­å…·æœ‰å…¨é¢‘è°±ä¼˜åŠ¿ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çš„å¤šç±»æ¨¡å‹åœ¨MVTec-ADå’ŒVisAä¸Šåˆ†åˆ«å®ç°äº†å‰æ‰€æœªæœ‰çš„99.9%å’Œ99.3%çš„å›¾åƒçº§ï¼ˆI-ï¼‰AUROCã€‚å¯¹äºå¤šè§†è§’å’Œå¤šæ¨¡å¼æ£€æŸ¥ï¼ŒDinomaly2åœ¨æœ€å°‘è°ƒæ•´çš„æƒ…å†µä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è€Œä¸”ï¼Œæ¯ä¸ªç±»åˆ«ä»…ä½¿ç”¨8ä¸ªæ­£å¸¸æ ·æœ¬ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°±è¶…è¶Šäº†ä¹‹å‰çš„å…¨é•œå¤´æ¨¡å‹ï¼Œåœ¨MVTec-ADå’ŒVisAä¸Šåˆ†åˆ«å®ç°äº†98.7%å’Œ97.4%çš„I-AUROCã€‚ç»“åˆç®€çº¦è®¾è®¡ã€è®¡ç®—å¯æ‰©å±•æ€§å’Œé€šç”¨é€‚ç”¨æ€§ï¼ŒDinomaly2æˆä¸ºå…¨é¢‘è°±ç°å®ä¸–ç•Œå¼‚å¸¸æ£€æµ‹åº”ç”¨çš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17611v1">PDF</a> Extended version of CVPR2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†Dinomaly2ï¼Œä¸€ä¸ªç”¨äºå…¨é¢‘è°±å›¾åƒæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹çš„ç»Ÿä¸€æ¡†æ¶ã€‚è¯¥æ¡†æ¶è§£å†³äº†å¤šç±»æ¨¡å‹æ€§èƒ½è¾ƒå·®çš„é—®é¢˜ï¼Œå¹¶èƒ½æ— ç¼åœ°åº”ç”¨äºä¸åŒçš„æ•°æ®æ¨¡æ€å’Œä»»åŠ¡è®¾ç½®ã€‚é€šè¿‡é‡‡ç”¨â€å°‘å³æ˜¯å¤šâ€çš„ç†å¿µï¼ŒDinomaly2åœ¨æ ‡å‡†é‡å»ºæ¡†æ¶ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚åœ¨å¤šä¸ªæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDinomaly2åœ¨å…¨é¢‘è°±ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼ŒåŒ…æ‹¬å¤šç§æ¨¡æ€ã€ä»»åŠ¡è®¾ç½®å’Œåº”ç”¨é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šç±»æ¨¡å‹ä¸­ï¼Œå®ƒå®ç°äº†å‰æ‰€æœªæœ‰çš„é«˜å›¾åƒçº§AUROCæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Dinomaly2æ˜¯ç¬¬ä¸€ä¸ªå…¨é¢‘è°±å›¾åƒæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹çš„ç»Ÿä¸€æ¡†æ¶ï¼Œèƒ½å¤Ÿå¼¥å¤šç±»æ¨¡å‹æ€§èƒ½å·®è·ï¼Œå¹¶è½»æ¾åº”ç”¨äºä¸åŒçš„æ•°æ®æ¨¡æ€å’Œä»»åŠ¡è®¾ç½®ã€‚</li>
<li>éµå¾ªâ€å°‘å³æ˜¯å¤šâ€çš„ç†å¿µï¼ŒDinomaly2åœ¨é‡å»ºæ¡†æ¶ä¸­é€šè¿‡åè°ƒäº”ä¸ªç®€å•å…ƒç´ å®ç°å“è¶Šæ€§èƒ½ã€‚</li>
<li>Dinomaly2å…·æœ‰æç®€çš„è®¾è®¡ã€è®¡ç®—ä¸Šçš„å¯æ‰©å±•æ€§å’Œæ™®éé€‚ç”¨æ€§ï¼Œä½¿å…¶æˆä¸ºå…¨é¢‘è°±ç°å®ä¸–ç•Œå¼‚å¸¸æ£€æµ‹åº”ç”¨çš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åœ¨å¤šä¸ªæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œè¯æ˜äº†Dinomaly2çš„ä¼˜è¶Šæ€§ï¼ŒåŒ…æ‹¬å¤šç§æ¨¡æ€ã€ä»»åŠ¡ç±»å‹å’Œåº”ç”¨é¢†åŸŸã€‚</li>
<li>åœ¨MVTec-ADå’ŒVisAä¸Šï¼Œå¤šç±»æ¨¡å‹çš„å›¾åƒçº§AUROCæ€§èƒ½è¾¾åˆ°å‰æ‰€æœªæœ‰çš„é«˜æ°´å¹³ã€‚</li>
<li>Dinomaly2åœ¨å¤šè§†å›¾å’Œå¤šæ¨¡æ€æ£€æŸ¥ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œåªéœ€è¿›è¡Œæœ€å°çš„è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-16635e2d4daf8338b64288efb197e902~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073035&auth_key=1761073035-0-0-0be9a3da204924656d67e6d08af40118&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a61ae61a8656a13a47d256d01bbb57a8~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073042&auth_key=1761073042-0-0-c71aaa5542bafe34967c11269d9482a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-55871a66326a11b731bd486b1e3e0545~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073049&auth_key=1761073049-0-0-ae2625490ccb698c3663107661708d7a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5c78eca75c00e10caf8ca8abb34e264f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073056&auth_key=1761073056-0-0-563e0c2bcb170175f696383f01fffec9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f14cc0b47f776de687a45370ac9c1777~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073062&auth_key=1761073062-0-0-7bc05802f332ff2cc475d95ecf9ef9cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DETree-DEtecting-Human-AI-Collaborative-Texts-via-Tree-Structured-Hierarchical-Representation-Learning"><a href="#DETree-DEtecting-Human-AI-Collaborative-Texts-via-Tree-Structured-Hierarchical-Representation-Learning" class="headerlink" title="DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured   Hierarchical Representation Learning"></a>DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured   Hierarchical Representation Learning</h2><p><strong>Authors:Yongxin He, Shan Zhang, Yixuan Cao, Lei Ma, Ping Luo</strong></p>
<p>Detecting AI-involved text is essential for combating misinformation, plagiarism, and academic misconduct. However, AI text generation includes diverse collaborative processes (AI-written text edited by humans, human-written text edited by AI, and AI-generated text refined by other AI), where various or even new LLMs could be involved. Texts generated through these varied processes exhibit complex characteristics, presenting significant challenges for detection. Current methods model these processes rather crudely, primarily employing binary classification (purely human vs. AI-involved) or multi-classification (treating human-AI collaboration as a new class). We observe that representations of texts generated through different processes exhibit inherent clustering relationships. Therefore, we propose DETree, a novel approach that models the relationships among different processes as a Hierarchical Affinity Tree structure, and introduces a specialized loss function that aligns text representations with this tree. To facilitate this learning, we developed RealBench, a comprehensive benchmark dataset that automatically incorporates a wide spectrum of hybrid texts produced through various human-AI collaboration processes. Our method improves performance in hybrid text detection tasks and significantly enhances robustness and generalization in out-of-distribution scenarios, particularly in few-shot learning conditions, further demonstrating the promise of training-based approaches in OOD settings. Our code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/heyongxin233/DETree">https://github.com/heyongxin233/DETree</a>. </p>
<blockquote>
<p>æ£€æµ‹æ¶‰åŠäººå·¥æ™ºèƒ½çš„æ–‡æœ¬å¯¹äºæ‰“å‡»è™šå‡ä¿¡æ¯ã€æŠ„è¢­å’Œå­¦æœ¯ä¸ç«¯è¡Œä¸ºè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œäººå·¥æ™ºèƒ½æ–‡æœ¬ç”ŸæˆåŒ…æ‹¬å¤šç§åä½œè¿‡ç¨‹ï¼ˆäººå·¥æ™ºèƒ½æ’°å†™çš„æ–‡æœ¬ç”±äººç±»ç¼–è¾‘ã€äººç±»æ’°å†™çš„æ–‡æœ¬ç”±äººå·¥æ™ºèƒ½ç¼–è¾‘ã€ä»¥åŠç”±å…¶ä»–äººå·¥æ™ºèƒ½å®Œå–„çš„äººå·¥æ™ºèƒ½ç”Ÿæˆæ–‡æœ¬ï¼‰ï¼Œå…¶ä¸­å¯èƒ½æ¶‰åŠå„ç§ç”šè‡³æ˜¯æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡è¿™äº›ä¸åŒè¿‡ç¨‹ç”Ÿæˆçš„æ–‡æœ¬è¡¨ç°å‡ºå¤æ‚çš„ç‰¹æ€§ï¼Œä¸ºæ£€æµ‹å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•å¯¹è¿™äº›è¿‡ç¨‹çš„å»ºæ¨¡è¾ƒä¸ºç²—ç³™ï¼Œä¸»è¦é‡‡ç”¨äºŒåˆ†ç±»ï¼ˆçº¯ç²¹çš„äººç±»åˆ›ä½œä¸äººå·¥æ™ºèƒ½å‚ä¸ï¼‰æˆ–å¤šåˆ†ç±»ï¼ˆå°†äººæœºåä½œè§†ä¸ºä¸€ä¸ªæ–°ç±»åˆ«ï¼‰ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œé€šè¿‡ä¸åŒè¿‡ç¨‹ç”Ÿæˆçš„æ–‡æœ¬è¡¨ç¤ºå‘ˆç°å‡ºå›ºæœ‰çš„èšç±»å…³ç³»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†DETreeè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒå°†ä¸åŒè¿‡ç¨‹ä¹‹é—´çš„å…³ç³»å»ºæ¨¡ä¸ºåˆ†å±‚äº²å’Œæ ‘ç»“æ„ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ä¸“ç”¨çš„æŸå¤±å‡½æ•°ï¼Œä½¿æ–‡æœ¬è¡¨ç¤ºä¸æ­¤æ ‘å¯¹é½ã€‚ä¸ºäº†ä¿ƒè¿›è¿™ä¸€å­¦ä¹ ï¼Œæˆ‘ä»¬å¼€å‘äº†RealBenchç»¼åˆåŸºå‡†æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å¯è‡ªåŠ¨åŒ…å«é€šè¿‡å„ç§äººæœºåä½œè¿‡ç¨‹äº§ç”Ÿçš„å¹¿æ³›æ··åˆæ–‡æœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ··åˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸Šæé«˜äº†æ€§èƒ½ï¼Œå¹¶åœ¨ç¦»ç¾¤åˆ†å¸ƒåœºæ™¯ä¸­æ˜¾è‘—å¢å¼ºäº†ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ ·æœ¬å­¦ä¹ æ¡ä»¶ä¸‹ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†åŸºäºè®­ç»ƒçš„æ–¹æ³•åœ¨OODç¯å¢ƒä¸­çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/heyongxin233/DETree%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/heyongxin233/DETreeè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17489v1">PDF</a> To appear in NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ£€æµ‹äººå·¥æ™ºèƒ½å‚ä¸æ–‡æœ¬çš„é‡è¦æ€§ï¼Œå¹¶é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚äº²å’Œæ ‘ç»“æ„ï¼ˆDETreeï¼‰çš„æ–‡æœ¬æ£€æµ‹æ–°æ–¹æ³•ã€‚DETreeæ—¨åœ¨é€šè¿‡å»ºæ¨¡ä¸åŒç”Ÿæˆè¿‡ç¨‹ä¹‹é—´çš„å…³ç³»æ¥è§£å†³å¤šæ¨¡å¼æ–‡æœ¬ç”Ÿæˆé—®é¢˜ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ä¸æ ‘ç»“æ„å¯¹é½çš„ä¸“ç”¨æŸå¤±å‡½æ•°ã€‚ä¸ºæé«˜å­¦ä¹ æ•ˆæœï¼Œè¿˜å¼€å‘äº†RealBenchåŸºå‡†æ•°æ®é›†ã€‚è¯¥æ–¹æ³•åœ¨æ··åˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å°æ ·æœ¬å­¦ä¹ æ¡ä»¶ä¸‹ï¼Œå¯¹äºæé«˜æ¨¡å‹åœ¨æœªçŸ¥åˆ†å¸ƒåœºæ™¯ä¸­çš„ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€æµ‹AIå‚ä¸æ–‡æœ¬å¯¹äºæ‰“å‡»è°£è¨€ã€æŠ„è¢­å’Œå­¦æœ¯ä¸ç«¯è¡Œä¸ºè‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–‡æœ¬æ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹å¤šæ¨¡å¼ç”Ÿæˆï¼ˆå¦‚AIè¾…åŠ©æˆ–çº¯AIç”Ÿæˆï¼‰çš„æ–‡æœ¬æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>DETreeæ–¹æ³•é€šè¿‡å»ºæ¨¡ä¸åŒæ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¹‹é—´çš„å…³ç³»æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>DETreeåˆ©ç”¨åˆ†å±‚äº²å’Œæ ‘ç»“æ„æ¥æ¨¡æ‹Ÿè¿™äº›å…³ç³»ï¼Œå¹¶å¼•å…¥ä¸“ç”¨æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚</li>
<li>RealBenchåŸºå‡†æ•°æ®é›†ç”¨äºæ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­çš„å„ç§äººæœºåˆä½œæ–‡æœ¬ç”Ÿæˆåœºæ™¯ï¼Œä¿ƒè¿›æ¨¡å‹å­¦ä¹ ã€‚</li>
<li>æ–¹æ³•åœ¨æ··åˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å°æ ·æœ¬å­¦ä¹ æ¡ä»¶ä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17489">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a745479d7040c3f5ffab70a0b561899b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073069&auth_key=1761073069-0-0-cc57fb1941d68740dbdea19bcfbbe77f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-26ab9a002eb565a76fd6071f0473c804~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073076&auth_key=1761073076-0-0-24633fc8fc8d1f9d8907bb765fa5087d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TabR1-Taming-GRPO-for-tabular-reasoning-LLMs"><a href="#TabR1-Taming-GRPO-for-tabular-reasoning-LLMs" class="headerlink" title="TabR1: Taming GRPO for tabular reasoning LLMs"></a>TabR1: Taming GRPO for tabular reasoning LLMs</h2><p><strong>Authors:Pengxiang Cai, Zihao Gao, Jintai Chen</strong></p>
<p>Tabular prediction has traditionally relied on gradient-boosted decision trees and specialized deep learning models, which excel within tasks but provide limited interpretability and weak transfer across tables. Reasoning large language models (LLMs) promise cross-task adaptability with trans- parent reasoning traces, yet their potential has not been fully realized for tabular data. This paper presents TabR1, the first reasoning LLM for tabular prediction with multi-step reasoning. At its core is Permutation Relative Policy Optimization (PRPO), a simple yet efficient reinforcement learning method that encodes column-permutation invariance as a structural prior. By construct- ing multiple label-preserving permutations per sample and estimating advantages both within and across permutations, PRPO transforms sparse rewards into dense learning signals and improves generalization. With limited supervision, PRPO activates the reasoning ability of LLMs for tabular prediction, enhancing few-shot and zero-shot performance as well as interpretability. Comprehensive experiments demonstrate that TabR1 achieves performance comparable to strong baselines under full-supervision fine-tuning. In the zero-shot setting, TabR1 approaches the performance of strong baselines under the 32-shot setting. Moreover, TabR1 (8B) substantially outperforms much larger LLMs across various tasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B). </p>
<blockquote>
<p>è¡¨æ ¼é¢„æµ‹ä¼ ç»Ÿä¸Šä¾èµ–äºæ¢¯åº¦æå‡å†³ç­–æ ‘å’Œä¸“ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨ä»»åŠ¡å†…è¡¨ç°ä¼˜å¼‚ï¼Œä½†æä¾›æœ‰é™çš„è§£é‡Šæ€§ï¼Œå¹¶ä¸”åœ¨è·¨è¡¨æ ¼è¿ç§»æ—¶è¡¨ç°è¾ƒå¼±ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†æ‰¿è¯ºè·¨ä»»åŠ¡é€‚åº”æ€§ï¼Œå…·æœ‰é€æ˜çš„æ¨ç†è½¨è¿¹ï¼Œä½†å…¶å¯¹è¡¨æ ¼æ•°æ®çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†å®ç°ã€‚æœ¬æ–‡æå‡ºäº†TabR1ï¼Œå®ƒæ˜¯é¦–ä¸ªç”¨äºè¡¨æ ¼é¢„æµ‹çš„å¤šæ­¥æ¨ç†æ¨ç†LLMã€‚å…¶æ ¸å¿ƒæ˜¯æ’åˆ—ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆPRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå°†åˆ—æ’åˆ—ä¸å˜æ€§ç¼–ç ä¸ºç»“æ„å…ˆéªŒã€‚é€šè¿‡å¯¹æ¯ä¸ªæ ·æœ¬æ„å»ºå¤šä¸ªæ ‡ç­¾ä¿ç•™æ’åˆ—å¹¶åœ¨æ’åˆ—å†…å’Œæ’åˆ—é—´ä¼°è®¡ä¼˜åŠ¿ï¼ŒPRPOå°†ç¨€ç–å¥–åŠ±è½¬åŒ–ä¸ºå¯†é›†çš„å­¦ä¹ ä¿¡å·å¹¶æé«˜äº†æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ‰é™çš„ç›‘ç£ä¸‹ï¼ŒPRPOæ¿€æ´»äº†LLMçš„æ¨ç†èƒ½åŠ›è¿›è¡Œè¡¨æ ¼é¢„æµ‹ï¼Œæé«˜äº†å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬çš„æ€§èƒ½ä»¥åŠè§£é‡Šæ€§ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTabR1åœ¨å…¨ç›‘ç£å¾®è°ƒçš„æƒ…å†µä¸‹å®ç°äº†ä¸å¼ºå¤§åŸºå‡†çº¿ç›¸å½“çš„æ€§èƒ½ã€‚åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­ï¼ŒTabR1æ¥è¿‘åœ¨32æ¬¡å±•ç¤ºä¸‹çš„å¼ºå¤§åŸºå‡†çº¿çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒTabR1ï¼ˆ8Bï¼‰åœ¨å„ç§ä»»åŠ¡ä¸Šå¤§å¤§ä¼˜äºæ›´å¤§çš„LLMsï¼Œç›¸å¯¹äºDeepSeek-R1ï¼ˆ685Bï¼‰æœ€å¤šæé«˜äº†53.17%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17385v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºTabR1çš„è¡¨æ ¼é¢„æµ‹æ¨ç†æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨ä»»åŠ¡é€‚åº”æ€§ç‰¹ç‚¹ï¼Œå¹¶å¼•å…¥äº†Permutation Relative Policy Optimizationï¼ˆPRPOï¼‰ç®—æ³•ã€‚PRPOç®—æ³•èƒ½æœ‰æ•ˆå¤„ç†è¡¨æ ¼æ•°æ®çš„åˆ—æ’åˆ—ä¸å˜æ€§ï¼Œå°†ç¨€ç–å¥–åŠ±è½¬åŒ–ä¸ºå¯†é›†å­¦ä¹ ä¿¡å·ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ‰é™çš„ç›‘ç£ä¸‹ï¼ŒTabR1èƒ½å¤Ÿæ¿€æ´»å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œæå‡å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬æ€§èƒ½ï¼Œå¹¶å¢å¼ºæ¨¡å‹çš„è§£é‡Šæ€§ã€‚å®éªŒè¯æ˜ï¼ŒTabR1åœ¨å®Œå…¨ç›‘ç£å¾®è°ƒçš„æƒ…å†µä¸‹è¾¾åˆ°ä¸åŸºçº¿æ¨¡å‹ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼ŒåŒæ—¶åœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹æ¥è¿‘åŸºçº¿æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚æ­¤å¤–ï¼ŒTabR1åœ¨ä¸åŒä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–å¤§å‹è¯­è¨€æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TabR1ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„è·¨ä»»åŠ¡é€‚åº”æ€§ï¼Œä¸“ä¸ºè¡¨æ ¼é¢„æµ‹è®¾è®¡ã€‚</li>
<li>TabR1å¼•å…¥Permutation Relative Policy Optimizationï¼ˆPRPOï¼‰ç®—æ³•å¤„ç†è¡¨æ ¼æ•°æ®çš„åˆ—æ’åˆ—ä¸å˜æ€§ã€‚</li>
<li>PRPOç®—æ³•èƒ½å°†ç¨€ç–å¥–åŠ±è½¬åŒ–ä¸ºå¯†é›†å­¦ä¹ ä¿¡å·ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>TabR1åœ¨æœ‰é™çš„ç›‘ç£ä¸‹èƒ½å¤Ÿæ¿€æ´»å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>TabR1æé«˜äº†å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬æƒ…å†µä¸‹çš„æ€§èƒ½è¡¨ç°ï¼ŒåŒæ—¶å¢å¼ºäº†æ¨¡å‹çš„è§£é‡Šæ€§ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºTabR1åœ¨å®Œå…¨ç›‘ç£å¾®è°ƒçš„æƒ…å†µä¸‹æ€§èƒ½ä¸åŸºçº¿æ¨¡å‹ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17385">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e8e7277f4e22f73b224bb64a73c703a8~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073083&auth_key=1761073083-0-0-40d847e1359b85ae02ac6e4b371b1959&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-14ccaa8ea0a131520c91e947b479a451~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073091&auth_key=1761073091-0-0-1b352b9496ff37fc24ccc1b33c02c0b7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6f990ade0b1b16afe422c8773fef08f9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073098&auth_key=1761073098-0-0-9b21663e685945ae2858b1b6d8003295&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ce1be3e60a071f85581a4d99f98964ea~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073104&auth_key=1761073104-0-0-1d1b73f76b882f5fefb312dd06fd2ba9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Reliability-of-Large-Language-Model-Generated-Clinical-Reasoning-in-Assisted-Reproductive-Technology-Blinded-Comparative-Evaluation-Study"><a href="#Reliability-of-Large-Language-Model-Generated-Clinical-Reasoning-in-Assisted-Reproductive-Technology-Blinded-Comparative-Evaluation-Study" class="headerlink" title="Reliability of Large Language Model Generated Clinical Reasoning in   Assisted Reproductive Technology: Blinded Comparative Evaluation Study"></a>Reliability of Large Language Model Generated Clinical Reasoning in   Assisted Reproductive Technology: Blinded Comparative Evaluation Study</h2><p><strong>Authors:Dou Liu, Ying Long, Sophia Zuoqiu, Di Liu, Kang Li, Yiting Lin, Hanyi Liu, Rong Yin, Tian Tang</strong></p>
<p>Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for explainable medical Artificial Intelligence (AI) while constrained by data scarcity. Although Large Language Models (LLMs) can synthesize medical data, their clinical reliability remains unverified. This study evaluates the reliability of LLM-generated CoTs and investigates prompting strategies to enhance their quality. In a blinded comparative study, senior clinicians in Assisted Reproductive Technology (ART) evaluated CoTs generated via three distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and Selective Few-shot (using diverse, high-quality examples). These expert ratings were compared against evaluations from a state-of-the-art AI model (GPT-4o). The Selective Few-shot strategy significantly outperformed other strategies across all human evaluation metrics (p &lt; .001). Critically, the Random Few-shot strategy offered no significant improvement over the Zero-shot baseline, demonstrating that low-quality examples are as ineffective as no examples. The success of the Selective strategy is attributed to two principles: â€œGold-Standard Depthâ€ (reasoning quality) and â€œRepresentative Diversityâ€ (generalization). Notably, the AI evaluator failed to discern these critical performance differences. The clinical reliability of synthetic CoTs is dictated by strategic prompt curation, not the mere presence of examples. We propose a â€œDual Principlesâ€ framework as a foundational methodology to generate trustworthy data at scale. This work offers a validated solution to the data bottleneck and confirms the indispensable role of human expertise in evaluating high-stakes clinical AI. </p>
<blockquote>
<p>åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œåˆ›å»ºé«˜è´¨é‡çš„ä¸´åºŠæ€ç»´é“¾ï¼ˆCoTsï¼‰å¯¹äºå¯è§£é‡Šæ€§åŒ»ç–—äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰è‡³å…³é‡è¦ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥åˆæˆåŒ»ç–—æ•°æ®ï¼Œä½†å…¶ä¸´åºŠå¯é æ€§å°šæœªå¾—åˆ°éªŒè¯ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°LLMç”Ÿæˆçš„CoTsçš„å¯é æ€§ï¼Œå¹¶ç ”ç©¶æé«˜è´¨é‡çš„æç¤ºç­–ç•¥ã€‚åœ¨ä¸€é¡¹ç›²æ¯”è¾ƒç ”ç©¶ä¸­ï¼Œè¾…åŠ©ç”Ÿæ®–æŠ€æœ¯ï¼ˆARTï¼‰é¢†åŸŸçš„èµ„æ·±ä¸´åºŠåŒ»ç”Ÿå¯¹é€šè¿‡ä¸‰ç§ä¸åŒç­–ç•¥ç”Ÿæˆçš„CoTsè¿›è¡Œäº†è¯„ä¼°ï¼šé›¶æ ·æœ¬ã€éšæœºå°‘æ ·æœ¬ï¼ˆä½¿ç”¨æµ…ä¾‹ï¼‰å’Œé€‰æ‹©æ€§å°‘æ ·æœ¬ï¼ˆä½¿ç”¨å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„ä¾‹å­ï¼‰ã€‚è¿™äº›ä¸“å®¶è¯„ä»·ä¸æ¥è‡ªæœ€æ–°AIæ¨¡å‹ï¼ˆGPT-4oï¼‰çš„è¯„ä»·è¿›è¡Œäº†æ¯”è¾ƒã€‚é€‰æ‹©æ€§å°‘æ ·æœ¬ç­–ç•¥åœ¨æ‰€æœ‰äººç±»è¯„ä»·æŒ‡æ ‡ä¸Šéƒ½æ˜¾è‘—ä¼˜äºå…¶ä»–ç­–ç•¥ï¼ˆp &lt; .0 ç›¸å¯¹äºé›¶æ ·æœ¬æ²¡æœ‰ä»»ä½•æ˜æ˜¾çš„æ”¹è¿›ã€‚é€‰æ‹©æ€§ç­–ç•¥çš„æˆåŠŸçš„å…³é”®æœ‰ä¸¤ä¸ªåŸåˆ™ï¼šâ€œé»„é‡‘æ ‡å‡†çš„æ·±åº¦â€ï¼ˆæ¨ç†è´¨é‡ï¼‰å’Œâ€œä»£è¡¨æ€§å¤šæ ·æ€§â€ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒAIè¯„ä¼°è€…æœªèƒ½åŒºåˆ†è¿™äº›å…³é”®æ€§èƒ½å·®å¼‚ã€‚åˆæˆCoTsçš„ä¸´åºŠå¯é æ€§å–å†³äºæˆ˜ç•¥æç¤ºç­–åˆ’ï¼Œè€Œä¸æ˜¯ç¤ºä¾‹çš„å­˜åœ¨ä¸å¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªâ€œåŒé‡åŸåˆ™â€æ¡†æ¶ï¼Œä½œä¸ºä¸€ç§åŸºç¡€æ–¹æ³•æ¥å¤§è§„æ¨¡ç”Ÿæˆå¯ä¿¡æ•°æ®ã€‚è¿™é¡¹å·¥ä½œä¸ºè§£å†³æ•°æ®ç“¶é¢ˆæä¾›äº†éªŒè¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶è¯å®äº†äººç±»ä¸“å®¶åœ¨è¯„ä¼°é«˜é£é™©ä¸´åºŠAIä¸­çš„ä¸å¯æˆ–ç¼ºä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16095v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ‘˜è¦æ¢è®¨äº†åœ¨æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹ï¼Œå¦‚ä½•åˆ©ç”¨æœ‰é™çš„ä¸´åºŠæ•°æ®åˆ›å»ºé«˜è´¨é‡çš„ä¸´åºŠæ¨ç†é“¾ï¼ˆChains-of-Thoughtï¼ŒCoTsï¼‰ä»¥å¢å¼ºåŒ»å­¦äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å¯è§£é‡Šæ€§ã€‚ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”ŸæˆCoTsçš„å¯é æ€§ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•é‡‡ç”¨æç¤ºç­–ç•¥æé«˜ç”Ÿæˆè´¨é‡ã€‚åœ¨ç›²æ€å¯¹æ¯”ç ”ç©¶ä¸­ï¼Œé‡‡ç”¨ä¸‰ç§ä¸åŒç­–ç•¥ç”ŸæˆCoTsï¼Œåˆ†åˆ«æ˜¯é›¶æ ·æœ¬ã€éšæœºå°‘æ ·æœ¬ï¼ˆä½¿ç”¨æµ…ä¾‹ï¼‰å’Œé€‰æ‹©æ€§å°‘æ ·æœ¬ï¼ˆä½¿ç”¨å¤šæ ·ã€é«˜è´¨é‡ä¾‹å­ï¼‰ã€‚æœ€ç»ˆå‘ç°é€‰æ‹©æ€§å°‘æ ·æœ¬ç­–ç•¥åœ¨æ‰€æœ‰äººç±»è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½æ˜¾è‘—ä¼˜äºå…¶ä»–ç­–ç•¥ï¼ˆp &lt; .001ï¼‰ã€‚æ­¤ç ”ç©¶çš„æˆåŠŸå½’åŠŸäºâ€œé‡‘æ ‡å‡†æ·±åº¦â€ï¼ˆæ¨ç†è´¨é‡ï¼‰å’Œâ€œä»£è¡¨æ€§å¤šæ ·æ€§â€ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰ä¸¤ä¸ªåŸåˆ™ã€‚AIè¯„ä¼°è€…æ— æ³•åŒºåˆ†è¿™äº›å…³é”®çš„æ€§èƒ½å·®å¼‚ï¼Œå› æ­¤ä¸´åºŠå¯é æ€§å–å†³äºç­–ç•¥æ€§æç¤ºçš„ç²¾å¿ƒç­–åˆ’ï¼Œè€Œéç¤ºä¾‹çš„å­˜åœ¨ä¸å¦ã€‚ç ”ç©¶æå‡ºäº†ä¸€ä¸ªâ€œåŒé‡åŸåˆ™â€æ¡†æ¶ï¼Œä½œä¸ºå¤§è§„æ¨¡ç”Ÿæˆå¯ä¿¡æ•°æ®çš„åŸºç¡€æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ›å»ºé«˜è´¨é‡çš„CoTså¯¹äºè§£é‡ŠåŒ»å­¦AIè‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ã€‚</li>
<li>LLMåœ¨åˆæˆåŒ»ç–—æ•°æ®æ–¹é¢çš„æ½œåŠ›ï¼Œä½†å…¶ä¸´åºŠå¯é æ€§å°šæœªå¾—åˆ°éªŒè¯ã€‚</li>
<li>åœ¨å¯¹æ¯”ç ”ç©¶ä¸­ï¼Œé€‰æ‹©æ€§å°‘æ ·æœ¬ç­–ç•¥åœ¨ç”ŸæˆCoTsæ–¹é¢è¡¨ç°æœ€ä½³ã€‚</li>
<li>æˆåŠŸçš„å…³é”®åœ¨äºâ€œé‡‘æ ‡å‡†æ·±åº¦â€å’Œâ€œä»£è¡¨æ€§å¤šæ ·æ€§â€ä¸¤ä¸ªåŸåˆ™ã€‚</li>
<li>AIè¯„ä¼°æ— æ³•è¯†åˆ«ä¸åŒç­–ç•¥ä¹‹é—´çš„å…³é”®æ€§èƒ½å·®å¼‚ï¼Œå¼ºè°ƒäººç±»ä¸“ä¸šçŸ¥è¯†åœ¨è¯„ä¼°é«˜é£é™©çš„ä¸´åºŠAIä¸­çš„ä¸å¯æˆ–ç¼ºä½œç”¨ã€‚</li>
<li>æç¤ºçš„ç²¾å¿ƒç­–åˆ’æ¯”ç¤ºä¾‹çš„å­˜åœ¨ä¸å¦æ›´èƒ½å†³å®šä¸´åºŠå¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4bb03707b5000b7f93a689cf38a7ae01~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073111&auth_key=1761073111-0-0-3e060fe2d736ac62879e8c35e50d95b8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f4f307555173b5ac05de0d355f26f976~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073119&auth_key=1761073119-0-0-5251876ede45ba63f76fd9eb7bc6d043&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c89e1e53082e811705208d9154da7aef~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073126&auth_key=1761073126-0-0-744becdb234e6bcf795dee5c85d8b0fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Synergistic-Enhancement-of-Requirement-to-Code-Traceability-A-Framework-Combining-Large-Language-Model-based-Data-Augmentation-and-an-Advanced-Encoder"><a href="#Synergistic-Enhancement-of-Requirement-to-Code-Traceability-A-Framework-Combining-Large-Language-Model-based-Data-Augmentation-and-an-Advanced-Encoder" class="headerlink" title="Synergistic Enhancement of Requirement-to-Code Traceability: A Framework   Combining Large Language Model based Data Augmentation and an Advanced   Encoder"></a>Synergistic Enhancement of Requirement-to-Code Traceability: A Framework   Combining Large Language Model based Data Augmentation and an Advanced   Encoder</h2><p><strong>Authors:Jianzhang Zhang, Jialong Zhou, Nan Niu, Jinping Hua, Chuang Liu</strong></p>
<p>Automated requirement-to-code traceability link recovery, essential for industrial system quality and safety, is critically hindered by the scarcity of labeled data. To address this bottleneck, this paper proposes and validates a synergistic framework that integrates large language model (LLM)-driven data augmentation with an advanced encoder. We first demonstrate that data augmentation, optimized through a systematic evaluation of bi-directional and zero&#x2F;few-shot prompting strategies, is highly effective, while the choice among leading LLMs is not a significant performance factor. Building on the augmented data, we further enhance an established, state-of-the-art pre-trained language model based method by incorporating an encoder distinguished by a broader pre-training corpus and an extended context window. Our experiments on four public datasets quantify the distinct contributions of our frameworkâ€™s components: on its own, data augmentation consistently improves the baseline method, providing substantial performance gains of up to 26.66%; incorporating the advanced encoder provides an additional lift of 2.21% to 11.25%. This synergy culminates in a fully optimized framework with maximum gains of up to 28.59% on $F_1$ score and 28.9% on $F_2$ score over the established baseline, decisively outperforming ten established baselines from three dominant paradigms. This work contributes a pragmatic and scalable methodology to overcome the data scarcity bottleneck, paving the way for broader industrial adoption of data-driven requirement-to-code traceability. </p>
<blockquote>
<p>è‡ªåŠ¨åŒ–éœ€æ±‚åˆ°ä»£ç çš„è¿½æº¯æ€§é“¾æ¥æ¢å¤å¯¹äºå·¥ä¸šç³»ç»Ÿçš„è´¨é‡å’Œå®‰å…¨è‡³å…³é‡è¦ï¼Œä½†å´å—åˆ°æ ‡è®°æ•°æ®ç¨€ç¼ºçš„ä¸¥é‡é˜»ç¢ã€‚é’ˆå¯¹è¿™ä¸€ç“¶é¢ˆï¼Œæœ¬æ–‡æå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ªååŒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èåˆäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°æ®å¢å¼ºæŠ€æœ¯ä¸å…ˆè¿›çš„ç¼–ç å™¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¯æ˜äº†é€šè¿‡åŒå‘å’Œé›¶&#x2F;å°‘æ ·æœ¬æç¤ºç­–ç•¥çš„ç³»ç»Ÿè¯„ä¼°ä¼˜åŒ–çš„æ•°æ®å¢å¼ºæ˜¯éå¸¸æœ‰æ•ˆçš„ï¼Œè€Œåœ¨é¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹é—´çš„é€‰æ‹©å¹¶ä¸æ˜¯æ€§èƒ½çš„é‡è¦å› ç´ ã€‚åŸºäºå¢å¼ºçš„æ•°æ®ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ”¹è¿›äº†ä¸€ç§åŸºäºå…ˆè¿›é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œå¹¶èå…¥äº†ä¸€ä¸ªç”±æ›´å¹¿æ³›çš„é¢„è®­ç»ƒè¯­æ–™åº“å’Œæ‰©å±•ä¸Šä¸‹æ–‡çª—å£åŒºåˆ†çš„ç¼–ç å™¨ã€‚æˆ‘ä»¬åœ¨å››ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒé‡åŒ–äº†æˆ‘ä»¬æ¡†æ¶ç»„ä»¶çš„ç‹¬ç‰¹è´¡çŒ®ï¼šä»…æ•°æ®å¢å¼ºæœ¬èº«å°±èƒ½æŒç»­æé«˜åŸºçº¿æ–¹æ³•çš„æ€§èƒ½ï¼Œæä¾›é«˜è¾¾26.66%çš„æ€§èƒ½æå‡ï¼›ç»“åˆå…ˆè¿›çš„ç¼–ç å™¨ï¼Œå¯æä¾›é¢å¤–çš„2.21%è‡³11.25%çš„æå‡ã€‚è¿™ç§ååŒä½œç”¨é€ å°±äº†ä¸€ä¸ªå®Œå…¨ä¼˜åŒ–çš„æ¡†æ¶ï¼Œåœ¨F1å¾—åˆ†ä¸Šæœ€é«˜æå‡äº†28.59%ï¼Œåœ¨F2å¾—åˆ†ä¸Šæœ€é«˜æå‡äº†28.9%ï¼Œæ˜æ˜¾è¶…è¶Šäº†ä¸‰ç§ä¸»æµèŒƒå¼ä¸­çš„åä¸ªåŸºçº¿æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œä¸ºè§£å†³æ•°æ®ç¨€ç¼ºçš„ç“¶é¢ˆæä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„æ–¹æ³•ï¼Œä¸ºæ•°æ®é©±åŠ¨çš„éœ€æ±‚åˆ°ä»£ç çš„è¿½æº¯æ€§åœ¨å·¥ä¸šä¸­çš„æ›´å¹¿æ³›åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.20149v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡é’ˆå¯¹å·¥ä¸šç³»ç»Ÿè´¨é‡ä¸å®‰å…¨çš„ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªååŒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ•°æ®å¢å¼ºå’Œå…ˆè¿›ç¼–ç å™¨ã€‚é€šè¿‡ç³»ç»Ÿè¯„ä¼°åŒå‘å’Œé›¶&#x2F;å°‘æ ·æœ¬æç¤ºç­–ç•¥ï¼Œè¯æ˜äº†æ•°æ®å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œé€šè¿‡ç»“åˆé¢„è®­ç»ƒè¯­æ–™åº“æ›´å¹¿æ³›ã€ä¸Šä¸‹æ–‡çª—å£æ›´æ‰©å±•çš„å…ˆè¿›ç¼–ç å™¨ï¼Œè¿›ä¸€æ­¥æ”¹è¿›äº†åŸºäºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶çš„å„ç»„æˆéƒ¨åˆ†å¯¹æ€§èƒ½æœ‰ç‹¬ç‰¹è´¡çŒ®ï¼Œæ•°æ®å¢å¼ºå’Œå…ˆè¿›ç¼–ç å™¨çš„ç»“åˆæä¾›äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¯¥ååŒæ¡†æ¶è§£å†³äº†æ•°æ®ç¨€ç¼ºçš„ç“¶é¢ˆé—®é¢˜ï¼Œä¸ºæ•°æ®é©±åŠ¨çš„è¦æ±‚åˆ°ä»£ç è·Ÿè¸ªçš„å·¥ä¸šåº”ç”¨å¼€è¾Ÿäº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªååŒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å·¥ä¸šç³»ç»Ÿä¸­è¦æ±‚ä¸ä»£ç ä¹‹é—´çš„è·Ÿè¸ªé“¾æ¥æ¢å¤é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶é›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ•°æ®å¢å¼ºå’Œå…ˆè¿›ç¼–ç å™¨ã€‚</li>
<li>æ•°æ®å¢å¼ºç­–ç•¥é€šè¿‡è¯„ä¼°ä¸åŒæç¤ºç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œè¢«è¯æ˜æ˜¯æå‡æ€§èƒ½çš„å…³é”®ã€‚</li>
<li>å…ˆè¿›ç¼–ç å™¨ç»“åˆé¢„è®­ç»ƒè¯­æ–™åº“å’Œæ‰©å±•çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œè¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨F1å’ŒF2åˆ†æ•°ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæœ€é«˜å¯è¾¾28.59%å’Œ28.9%ã€‚</li>
<li>è¯¥æ–¹æ³•è§£å†³äº†æ•°æ®ç¨€ç¼ºçš„ç“¶é¢ˆé—®é¢˜ï¼Œä¸ºå·¥ä¸šç³»ç»Ÿä¸­çš„æ•°æ®é©±åŠ¨è¦æ±‚åˆ°ä»£ç è·Ÿè¸ªæä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.20149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ba8e799ff2dd1ca75dbf4b3a28c46ce8~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073132&auth_key=1761073132-0-0-2a8263d2f16bc9327985fa12615e2d8d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-25b3631f04e84866001935c990f2a1f9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073140&auth_key=1761073140-0-0-849bd6a2713054d75234a3bfb9f3576e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Hierarchical-Material-Recognition-from-Local-Appearance"><a href="#Hierarchical-Material-Recognition-from-Local-Appearance" class="headerlink" title="Hierarchical Material Recognition from Local Appearance"></a>Hierarchical Material Recognition from Local Appearance</h2><p><strong>Authors:Matthew Beveridge, Shree K. Nayar</strong></p>
<p>We introduce a taxonomy of materials for hierarchical recognition from local appearance. Our taxonomy is motivated by vision applications and is arranged according to the physical traits of materials. We contribute a diverse, in-the-wild dataset with images and depth maps of the taxonomy classes. Utilizing the taxonomy and dataset, we present a method for hierarchical material recognition based on graph attention networks. Our model leverages the taxonomic proximity between classes and achieves state-of-the-art performance. We demonstrate the modelâ€™s potential to generalize to adverse, real-world imaging conditions, and that novel views rendered using the depth maps can enhance this capability. Finally, we show the modelâ€™s capacity to rapidly learn new materials in a few-shot learning setting. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åŸºäºå±€éƒ¨å¤–è§‚è¿›è¡Œå±‚æ¬¡è¯†åˆ«çš„ææ–™åˆ†ç±»æ³•ã€‚æˆ‘ä»¬çš„åˆ†ç±»æ³•å—åˆ°è§†è§‰åº”ç”¨çš„å¯å‘ï¼Œå¹¶æ ¹æ®ææ–™çš„ç‰©ç†ç‰¹å¾è¿›è¡Œæ’åˆ—ã€‚æˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªåŒ…å«åˆ†ç±»å›¾åƒå’Œæ·±åº¦å›¾çš„å¤šæ ·åŒ–ã€é‡å¤–æ•°æ®é›†ã€‚åˆ©ç”¨åˆ†ç±»æ³•å’Œæ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„å±‚æ¬¡ææ–™è¯†åˆ«æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ©ç”¨ç±»ä¹‹é—´çš„åˆ†ç±»é‚»è¿‘æ€§ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨æ¶åŠ£çš„ã€ç°å®ä¸–ç•Œçš„æˆåƒæ¡ä»¶ä¸‹çš„é€šç”¨åŒ–æ½œåŠ›ï¼Œä»¥åŠä½¿ç”¨æ·±åº¦å›¾å‘ˆç°çš„æ–°è§†è§’å¯ä»¥å¢å¼ºè¿™ç§èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨å°‘é‡å­¦ä¹ ç¯å¢ƒä¸­å¿«é€Ÿå­¦ä¹ æ–°ææ–™çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22911v3">PDF</a> ICCV 2025 Camera Ready</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†ç‰¹æ€§çš„ææ–™åˆ†ç±»æ³•ï¼Œç”¨äºä»å±€éƒ¨å¤–è§‚è¿›è¡Œå±‚æ¬¡è¯†åˆ«ã€‚æ–‡ç« å»ºç«‹äº†ä¸€ä¸ªå¤šæ ·åŒ–çš„è‡ªç„¶åœºæ™¯æ•°æ®é›†ï¼ŒåŒ…å«å„ç±»ææ–™çš„å›¾åƒå’Œæ·±åº¦å›¾ã€‚åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œå’Œææ–™åˆ†ç±»æ³•ï¼Œæå‡ºäº†ä¸€ç§å±‚æ¬¡ææ–™è¯†åˆ«æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç±»åˆ«ä¹‹é—´çš„åˆ†ç±»å­¦ç›¸å…³æ€§ï¼Œå®ç°äº†å…ˆè¿›æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ¨å¹¿åˆ°æ¶åŠ£çš„ç°å®ä¸­æˆåƒæ¡ä»¶ï¼Œå¹¶ä½¿ç”¨æ·±åº¦å›¾æ¸²æŸ“çš„æ–°è§†è§’æå‡å…¶æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å±•ç¤ºäº†åœ¨å°‘é‡æ ·æœ¬å­¦ä¹ æ–°ææ–™çš„å¿«é€Ÿå­¦ä¹ èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†ç‰¹æ€§çš„ææ–™åˆ†ç±»æ³•ï¼Œç”¨äºå±‚æ¬¡è¯†åˆ«ã€‚</li>
<li>å»ºç«‹äº†ä¸€ä¸ªåŒ…å«å„ç±»ææ–™å›¾åƒå’Œæ·±åº¦å›¾çš„æ•°æ®é›†ã€‚</li>
<li>åˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå’Œææ–™åˆ†ç±»æ³•ï¼Œæå‡ºäº†ä¸€ç§å±‚æ¬¡ææ–™è¯†åˆ«æ–¹æ³•ã€‚</li>
<li>æ¨¡å‹åˆ©ç”¨ç±»åˆ«ä¹‹é—´çš„åˆ†ç±»å­¦ç›¸å…³æ€§ï¼Œå®ç°äº†å…ˆè¿›æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿæ¨å¹¿åˆ°æ¶åŠ£çš„ç°å®ä¸­æˆåƒæ¡ä»¶ï¼Œå¹¶ä½¿ç”¨æ·±åº¦å›¾å¢å¼ºæ€§èƒ½ã€‚</li>
<li>æ¨¡å‹å±•ç¤ºäº†åœ¨å°‘é‡æ ·æœ¬å­¦ä¹ æ–°ææ–™çš„å¿«é€Ÿå­¦ä¹ èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6a32855801d1e13f7d211db253b531fa~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073147&auth_key=1761073147-0-0-d7557c1a82841f3c526284596cc10918&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c9cebce83d5ead194d8a7b566a93a9a~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073154&auth_key=1761073154-0-0-fe9686c96128751165c889a054af02b3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3eed7065abd7e35082205cdbd0705932~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073161&auth_key=1761073161-0-0-2df940f14a2c946daff482e38d5d0996&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4fcb0bd3b648c32bea97aa0c16543b6c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073168&auth_key=1761073168-0-0-2042b13e798c4d23ebcac9a5fe6508cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-69e605444a1efbfd8470d50b183b81d7~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073175&auth_key=1761073175-0-0-5fbc0b4c97bcba3332c4b7beb2740372&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Model-Predictive-Task-Sampling-for-Efficient-and-Robust-Adaptation"><a href="#Model-Predictive-Task-Sampling-for-Efficient-and-Robust-Adaptation" class="headerlink" title="Model Predictive Task Sampling for Efficient and Robust Adaptation"></a>Model Predictive Task Sampling for Efficient and Robust Adaptation</h2><p><strong>Authors:Qi Wang, Zehao Xiao, Yixiu Mao, Yun Qu, Jiayi Shen, Yiqin Lv, Xiangyang Ji</strong></p>
<p>Foundation models have revolutionized general-purpose problem-solving, offering rapid task adaptation through pretraining, meta-training, and finetuning. Recent crucial advances in these paradigms reveal the importance of challenging task prioritized sampling to enhance adaptation robustness under distribution shifts. However, ranking task difficulties over iteration as a preliminary step typically requires exhaustive task evaluation, which is practically unaffordable in computation and data-annotation. This study provides a novel perspective to illuminate the possibility of leveraging the dual importance of adaptation robustness and learning efficiency, particularly in scenarios where task evaluation is risky or costly, such as iterative agent-environment interactions for robotic policy evaluation or computationally intensive inference steps for finetuning foundation models. Firstly, we introduce Model Predictive Task Sampling (MPTS), a framework that bridges the task space and adaptation risk distributions, providing a theoretical foundation for robust active task sampling. MPTS employs a generative model to characterize the episodic optimization process and predicts task-specific adaptation risk via posterior inference. The resulting risk predictive model amortizes the costly evaluation of task adaptation performance and provably approximates task difficulty rankings. MPTS seamlessly integrates into zero-shot, few-shot, and supervised finetuning settings. Empirically, we conduct extensive experiments in pattern recognition using foundation models and sequential decision-making. Our results demonstrate that MPTS significantly enhances adaptation robustness for tail risk or out-of-distribution (OOD) tasks and improves learning efficiency compared to state-of-the-art (SoTA) methods. The code is available at the project site <a target="_blank" rel="noopener" href="https://github.com/thu-rllab/MPTS">https://github.com/thu-rllab/MPTS</a>. </p>
<blockquote>
<p>é¢„è®­ç»ƒæ¨¡å‹é€šè¿‡é¢„è®­ç»ƒã€å…ƒè®­ç»ƒå’Œå¾®è°ƒçš„æ–¹å¼ï¼Œå·²ç»å½»åº•æ”¹å˜äº†é€šç”¨é—®é¢˜è§£å†³çš„æ–¹æ³•ã€‚è¿™äº›æ¨¡å¼ä¸­çš„æœ€æ–°å…³é”®è¿›å±•æ­ç¤ºäº†ä¼˜å…ˆé‡‡æ ·æŒ‘æˆ˜æ€§ä»»åŠ¡åœ¨æé«˜åˆ†å¸ƒè½¬ç§»ä¸‹çš„é€‚åº”ç¨³å¥æ€§ä¸­çš„é‡è¦æ€§ã€‚ç„¶è€Œï¼Œä½œä¸ºåˆæ­¥æ­¥éª¤åœ¨è¿­ä»£ä¸­æŒ‰ä»»åŠ¡éš¾åº¦æ’åºé€šå¸¸éœ€è¦å…¨é¢çš„ä»»åŠ¡è¯„ä¼°ï¼Œè¿™åœ¨è®¡ç®—å’Œæ•°æ®æ ‡æ³¨æ–¹é¢å®é™…ä¸Šæ˜¯ä¸åˆ‡å®é™…çš„ã€‚æœ¬ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ï¼Œä»¥é˜æ˜åœ¨ä»»åŠ¡è¯„ä¼°é£é™©å¤§æˆ–ä»£ä»·é«˜æ˜‚çš„æƒ…å¢ƒä¸‹ï¼ŒåŒæ—¶åˆ©ç”¨é€‚åº”ç¨³å¥æ€§å’Œå­¦ä¹ æ•ˆç‡çš„åŒé‡é‡è¦æ€§æˆä¸ºå¯èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨æœºå™¨äººç­–ç•¥è¯„ä¼°çš„è¿­ä»£å¼äººæœºäº’åŠ¨æˆ–å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„è®¡ç®—å¯†é›†å‹æ¨ç†æ­¥éª¤ç­‰åœºæ™¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†æ¨¡å‹é¢„æµ‹ä»»åŠ¡é‡‡æ ·ï¼ˆMPTSï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¡¥æ¢ä»»åŠ¡ç©ºé—´å’Œé€‚åº”é£é™©åˆ†å¸ƒçš„æ¡†æ¶ï¼Œä¸ºç¨³å¥çš„ä¸»åŠ¨ä»»åŠ¡é‡‡æ ·æä¾›äº†ç†è®ºåŸºç¡€ã€‚MPTSé‡‡ç”¨ç”Ÿæˆæ¨¡å‹æ¥åˆ»ç”»å¹•å¼ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡åéªŒæ¨æ–­é¢„æµ‹ç‰¹å®šä»»åŠ¡çš„é€‚åº”é£é™©ã€‚ç»“æœå¾—åˆ°çš„é£é™©é¢„æµ‹æ¨¡å‹å‡å°‘äº†æ˜‚è´µçš„ä»»åŠ¡é€‚åº”æ€§èƒ½è¯„ä¼°ï¼Œå¹¶è¯æ˜å¯ä»¥è¿‘ä¼¼ä»»åŠ¡éš¾åº¦æ’åã€‚MPTSæ— ç¼é›†æˆåˆ°é›¶æ ·æœ¬ã€å°‘æ ·æœ¬å’Œå—ç›‘ç£å¾®è°ƒçš„ç¯å¢ƒä¸­ã€‚é€šè¿‡å®è¯ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„æ¨¡å¼è¯†åˆ«å’Œåºåˆ—å†³ç­–åˆ¶å®šæ–¹é¢è¿›è¡Œäº†å¤§é‡å®éªŒã€‚ç»“æœè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒMPTSæ˜¾è‘—æé«˜äº†å°¾é£é™©æˆ–è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„ä»»åŠ¡çš„é€‚åº”ç¨³å¥æ€§ï¼Œå¹¶æé«˜äº†å­¦ä¹ æ•ˆç‡ã€‚ä»£ç å¯åœ¨é¡¹ç›®ç½‘ç«™<a target="_blank" rel="noopener" href="https://github.com/thu-rllab/MPTS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/thu-rllab/MPTSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.11039v6">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ¨¡å‹é¢„æµ‹ä»»åŠ¡é‡‡æ ·ï¼ˆMPTSï¼‰æ¡†æ¶é€šè¿‡ç»“åˆä»»åŠ¡ç©ºé—´å’Œé€‚åº”é£é™©åˆ†å¸ƒï¼Œä¸ºç¨³å¥çš„æ´»åŠ¨ä»»åŠ¡é‡‡æ ·æä¾›äº†ç†è®ºåŸºç¡€ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç”Ÿæˆæ¨¡å‹æ¥è¡¨å¾ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡åéªŒæ¨ç†é¢„æµ‹ç‰¹å®šä»»åŠ¡çš„é€‚åº”é£é™©ã€‚MPTSèƒ½å¤Ÿå‡å°‘æ˜‚è´µçš„ä»»åŠ¡é€‚åº”æ€§èƒ½è¯„ä¼°ï¼Œå¹¶è¯æ˜å…¶èƒ½å¤Ÿè¿‘ä¼¼ä»»åŠ¡éš¾åº¦æ’åã€‚åœ¨æ¨¡å¼è¯†åˆ«å’Œåºåˆ—å†³ç­–åˆ¶å®šçš„å®éªŒä¸­ï¼ŒMPTSæ˜¾è‘—æé«˜äº†å¯¹å°¾é£é™©æˆ–è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰ä»»åŠ¡çš„é€‚åº”ç¨³å¥æ€§ï¼Œå¹¶æé«˜äº†å­¦ä¹ æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºé‡‘ä¼šæ¨¡å‹é€šè¿‡é¢„è®­ç»ƒã€å…ƒè®­ç»ƒå’Œå¾®è°ƒæä¾›äº†å¿«é€Ÿä»»åŠ¡é€‚åº”çš„èƒ½åŠ›ã€‚</li>
<li>ä»»åŠ¡éš¾åº¦æ’åºåœ¨è¿­ä»£ä¸­é€šå¸¸éœ€è¦è¿›è¡Œå…¨é¢çš„ä»»åŠ¡è¯„ä¼°ï¼Œè¿™åœ¨è®¡ç®—å’Œæ•°æ®æ ‡æ³¨ä¸Šæ˜¯ä¸åˆ‡å®é™…çš„ã€‚</li>
<li>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„æ¨¡å‹é¢„æµ‹ä»»åŠ¡é‡‡æ ·ï¼ˆMPTSï¼‰æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹ä»»åŠ¡çš„é€‚åº”é£é™©å¹¶ä¼˜åŒ–ä»»åŠ¡é‡‡æ ·ã€‚</li>
<li>MPTSåˆ©ç”¨ç”Ÿæˆæ¨¡å‹æ¥è¡¨å¾ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡åéªŒæ¨ç†é¢„æµ‹ä»»åŠ¡ç‰¹å®šçš„é€‚åº”é£é™©ã€‚</li>
<li>MPTSæ˜¾è‘—æé«˜äº†å¯¹å°¾é£é™©æˆ–è¶…å‡ºåˆ†å¸ƒï¼ˆOODï¼‰ä»»åŠ¡çš„é€‚åº”ç¨³å¥æ€§ã€‚</li>
<li>MPTSåœ¨æ¨¡å¼è¯†åˆ«å’Œåºåˆ—å†³ç­–åˆ¶å®šçš„å®éªŒä¸­è¯æ˜äº†å…¶èƒ½æé«˜å­¦ä¹ æ•ˆç‡ã€‚</li>
<li>ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/thu-rllab/MPTS%E3%80%82">https://github.com/thu-rllab/MPTSã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.11039">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cb9f48da6ba9fdbf35743adfac3fd612~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073183&auth_key=1761073183-0-0-e2a9ae3bb7bfda862aa46ee907cec48e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-35490cb84c073a66065f0435f77d698d~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073190&auth_key=1761073190-0-0-be352d0fa8f2cdb2b909a05bc973d992&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fdbe5c34e2b96f34c6ca5103e280fed5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073197&auth_key=1761073197-0-0-9ad6244ea8ad3409a37e5a18df74afe2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Packet-Inspection-Transformer-A-Self-Supervised-Journey-to-Unseen-Malware-Detection-with-Few-Samples"><a href="#Packet-Inspection-Transformer-A-Self-Supervised-Journey-to-Unseen-Malware-Detection-with-Few-Samples" class="headerlink" title="Packet Inspection Transformer: A Self-Supervised Journey to Unseen   Malware Detection with Few Samples"></a>Packet Inspection Transformer: A Self-Supervised Journey to Unseen   Malware Detection with Few Samples</h2><p><strong>Authors:Kyle Stein, Arash Mahyari, Guillermo Francia III, Eman El-Sheikh</strong></p>
<p>As networks continue to expand and become more interconnected, the need for novel malware detection methods becomes more pronounced. Traditional security measures are increasingly inadequate against the sophistication of modern cyber attacks. Deep Packet Inspection (DPI) has been pivotal in enhancing network security, offering an in-depth analysis of network traffic that surpasses conventional monitoring techniques. DPI not only examines the metadata of network packets, but also dives into the actual content being carried within the packet payloads, providing a comprehensive view of the data flowing through networks. While the integration of advanced deep learning techniques with DPI has introduced modern methodologies into malware detection and network traffic classification, state-of-the-art supervised learning approaches are limited by their reliance on large amounts of annotated data and their inability to generalize to novel, unseen malware threats. To address these limitations, this paper leverages the recent advancements in self-supervised learning (SSL) and few-shot learning (FSL). Our proposed self-supervised approach trains a transformer via SSL to learn the embedding of packet content, including payload, from vast amounts of unlabeled data by masking portions of packets, leading to a learned representation that generalizes to various downstream tasks. Once the representation is extracted from the packets, they are used to train a malware detection algorithm. The representation obtained from the transformer is then used to adapt the malware detector to novel types of attacks using few-shot learning approaches. Our experimental results demonstrate that our method achieves classification accuracies of up to 94.76% on the UNSW-NB15 dataset and 83.25% on the CIC-IoT23 dataset. </p>
<blockquote>
<p>éšç€ç½‘ç»œçš„ä¸æ–­æ‰©å¼ å’Œç›¸äº’è¿æ¥ï¼Œå¯¹æ–°å‹æ¶æ„è½¯ä»¶æ£€æµ‹æ–¹æ³•çš„éœ€æ±‚å˜å¾—æ›´åŠ è¿«åˆ‡ã€‚ä¼ ç»Ÿçš„å®‰å…¨æªæ–½è¶Šæ¥è¶Šéš¾ä»¥åº”å¯¹ç°ä»£ç½‘ç»œæ”»å‡»çš„å¤æ‚æ€§ã€‚æ·±åº¦åŒ…æ£€æµ‹ï¼ˆDPIï¼‰åœ¨å¢å¼ºç½‘ç»œå®‰å…¨æ–¹é¢å‘æŒ¥äº†å…³é”®ä½œç”¨ï¼Œå®ƒæä¾›äº†å¯¹ç½‘ç»œæµé‡çš„æ·±å…¥åˆ†æï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘æ§æŠ€æœ¯ã€‚DPIä¸ä»…æ£€æŸ¥ç½‘ç»œåŒ…çš„å…ƒæ•°æ®ï¼Œè¿˜æ·±å…¥æ¢ç©¶åŒ…æœ‰æ•ˆè½½è·ä¸­çš„å®é™…å†…å®¹ï¼Œæä¾›äº†æµç»ç½‘ç»œçš„æ•°æ®çš„å…¨é¢è§†å›¾ã€‚è™½ç„¶å°†å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸DPIç›¸ç»“åˆå·²ç»ä¸ºæ¶æ„è½¯ä»¶æ£€æµ‹å’Œç½‘ç»œæµé‡åˆ†ç±»å¼•å…¥äº†ç°ä»£æ–¹æ³•ï¼Œä½†æœ€å…ˆè¿›çš„ç›‘ç£å­¦ä¹ æ–¹æ³•å—é™äºå®ƒä»¬å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»¥åŠå®ƒä»¬æ— æ³•æ¨å¹¿åˆ°æ–°å‹æœªè§è¿‡çš„æ¶æ„è½¯ä»¶å¨èƒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡åˆ©ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰å’Œå°‘é•œå¤´å­¦ä¹ ï¼ˆFSLï¼‰çš„æœ€æ–°è¿›å±•ã€‚æˆ‘ä»¬æå‡ºçš„è‡ªæˆ‘ç›‘ç£æ–¹æ³•é€šè¿‡SSLè®­ç»ƒä¸€ä¸ªå˜å‹å™¨ï¼Œå­¦ä¹ åŒ…æ‹¬æœ‰æ•ˆè½½è·åœ¨å†…çš„æ•°æ®åŒ…å†…å®¹çš„åµŒå…¥ï¼Œé€šè¿‡æ©ç›–æ•°æ®åŒ…çš„éƒ¨åˆ†å†…å®¹ï¼Œä»å¤§é‡æœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ è¡¨ç¤ºå½¢å¼ï¼Œè¿™æœ‰åŠ©äºé€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡ã€‚ä¸€æ—¦ä»æ•°æ®åŒ…ä¸­æå–å‡ºè¡¨ç¤ºå½¢å¼ï¼Œå®ƒä»¬å°†è¢«ç”¨äºè®­ç»ƒæ¶æ„è½¯ä»¶æ£€æµ‹ç®—æ³•ã€‚ä»å˜å‹å™¨å¾—åˆ°çš„è¡¨ç¤ºå½¢å¼ç„¶åè¢«ç”¨äºå€ŸåŠ©å°‘é•œå¤´å­¦ä¹ æ–¹æ³•é€‚åº”æ–°å‹æ”»å‡»ç±»å‹çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨UNSW-NB15æ•°æ®é›†ä¸Šè¾¾åˆ°äº†é«˜è¾¾94.76%çš„åˆ†ç±»ç²¾åº¦ï¼Œåœ¨CIC-IoT23æ•°æ®é›†ä¸Šè¾¾åˆ°äº†83.25%çš„åˆ†ç±»ç²¾åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.18219v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€ç½‘ç»œä¸æ–­æ‰©å±•å’Œç›¸äº’è¿æ¥ï¼Œæ–°å‹æ¶æ„è½¯ä»¶æ£€æµ‹æ–¹æ³•çš„éœ€æ±‚æ„ˆå‘é‡è¦ã€‚ä¼ ç»Ÿå®‰å…¨æªæ–½éš¾ä»¥åº”å¯¹ç°ä»£ç½‘ç»œæ”»å‡»çš„å¤æ‚æ€§ã€‚æ·±åº¦åŒ…æ£€æµ‹ï¼ˆDPIï¼‰å¯¹äºå¢å¼ºç½‘ç»œå®‰å…¨è‡³å…³é‡è¦ï¼Œå®ƒæä¾›äº†å¯¹ç½‘ç»œæµé‡çš„æ·±å…¥åˆ†æï¼Œè¶…è¶Šäº†å¸¸è§„ç›‘æ§æŠ€æœ¯ã€‚æœ¬æ–‡åˆ©ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ çš„æœ€æ–°è¿›å±•ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„è½¯ä»¶æ£€æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ è®­ç»ƒä¸€ä¸ªä»å¤§é‡æœªæ ‡è®°æ•°æ®åŒ…ä¸­å­¦ä¹ è¡¨ç¤ºçš„è½¬æ¢å™¨ï¼Œå¹¶ä½¿ç”¨è¿™äº›è¡¨ç¤ºæ¥è®­ç»ƒæ¶æ„è½¯ä»¶æ£€æµ‹ç®—æ³•ï¼Œå¹¶ä½¿ç”¨å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•æ¥é€‚åº”æ–°å‹æ”»å‡»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨UNSW-NB15æ•°æ®é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡é«˜è¾¾94.76%ï¼Œåœ¨CIC-IoT23æ•°æ®é›†ä¸Šä¸º83.25%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç½‘ç»œäº’è”æ€§çš„å¢å¼ºä½¿å¾—æ–°å‹æ¶æ„è½¯ä»¶æ£€æµ‹çš„éœ€æ±‚æ„ˆå‘é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿå®‰å…¨æªæ–½åœ¨åº”å¯¹ç°ä»£ç½‘ç»œæ”»å‡»æ–¹é¢è¡¨ç°å‡ºä¸è¶³ã€‚</li>
<li>æ·±åº¦åŒ…æ£€æµ‹ï¼ˆDPIï¼‰åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸå‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œå¯ä»¥è¿›è¡Œæ·±åº¦ç½‘ç»œæµé‡åˆ†æã€‚</li>
<li>è¯¥è®ºæ–‡ç»“åˆäº†è‡ªæˆ‘ç›‘ç£å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ æ¥æ”¹è¿›æ¶æ„è½¯ä»¶æ£€æµ‹ã€‚</li>
<li>é€šè¿‡è‡ªæˆ‘ç›‘ç£å­¦ä¹ è®­ç»ƒè½¬æ¢å™¨ä»å¤§é‡æœªæ ‡è®°æ•°æ®åŒ…ä¸­å­¦ä¹ è¡¨ç¤ºã€‚</li>
<li>ä½¿ç”¨è¿™äº›å­¦ä¹ åˆ°çš„è¡¨ç¤ºæ¥è®­ç»ƒæ¶æ„è½¯ä»¶æ£€æµ‹ç®—æ³•ï¼Œå¹¶é€‚åº”æ–°å‹æ”»å‡»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.18219">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6c3e3c39e80d2ab7913313243eeb2b50~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073204&auth_key=1761073204-0-0-64cf19aefbefd339b4a270cc0f49aac6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a698b15db02b5ff193825b97a5c7bce5~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073212&auth_key=1761073212-0-0-ac6fb70010c2ddb185a4a318210da745&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-17b6e612408ffc824083326b18de05ff~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073218&auth_key=1761073218-0-0-10e94ae0a03c6ea2a3b60c8d9259bcea&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7c304509eb21ff1f4aa378aac112a860~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073225&auth_key=1761073225-0-0-53f5b4ebf68f2277c104d220fb868ca5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-78a6900eb8837a0aac14e78f6493fa69~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073231&auth_key=1761073231-0-0-15c15df2fea9ce358ad20c514824ce83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Adv-SSL-Adversarial-Self-Supervised-Representation-Learning-with-Theoretical-Guarantees"><a href="#Adv-SSL-Adversarial-Self-Supervised-Representation-Learning-with-Theoretical-Guarantees" class="headerlink" title="Adv-SSL: Adversarial Self-Supervised Representation Learning with   Theoretical Guarantees"></a>Adv-SSL: Adversarial Self-Supervised Representation Learning with   Theoretical Guarantees</h2><p><strong>Authors:Chenguang Duan, Yuling Jiao, Huazhen Lin, Wensen Ma, Jerry Zhijian Yang</strong></p>
<p>Learning transferable data representations from abundant unlabeled data remains a central challenge in machine learning. Although numerous self-supervised learning methods have been proposed to address this challenge, a significant class of these approaches aligns the covariance or correlation matrix with the identity matrix. Despite impressive performance across various downstream tasks, these methods often suffer from biased sample risk, leading to substantial optimization shifts in mini-batch settings and complicating theoretical analysis. In this paper, we introduce a novel \underline{\bf Adv}ersarial \underline{\bf S}elf-\underline{\bf S}upervised Representation \underline{\bf L}earning (Adv-SSL) for unbiased transfer learning with no additional cost compared to its biased counterparts. Our approach not only outperforms the existing methods across multiple benchmark datasets but is also supported by comprehensive end-to-end theoretical guarantees. Our analysis reveals that the minimax optimization in Adv-SSL encourages representations to form well-separated clusters in the embedding space, provided there is sufficient upstream unlabeled data. As a result, our method achieves strong classification performance even with limited downstream labels, shedding new light on few-shot learning. </p>
<blockquote>
<p>ä»å¤§é‡æœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ å¯è¿ç§»çš„æ•°æ®è¡¨ç¤ºä»ç„¶æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ã€‚å°½ç®¡å·²ç»æå‡ºäº†è®¸å¤šè‡ªç›‘ç£å­¦ä¹ æ–¹æ³•æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†å…¶ä¸­å¾ˆå¤§ä¸€éƒ¨åˆ†æ–¹æ³•æ˜¯å°†åæ–¹å·®æˆ–ç›¸å…³æ€§çŸ©é˜µä¸å•ä½çŸ©é˜µå¯¹é½ã€‚å°½ç®¡åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å­˜åœ¨æ ·æœ¬åå·®é£é™©ï¼Œå¯¼è‡´åœ¨å°å‹æ‰¹æ¬¡è®¾ç½®ä¸­å‡ºç°é‡å¤§çš„ä¼˜åŒ–å˜åŒ–ï¼Œå¹¶ä½¿å¾—ç†è®ºåˆ†æå¤æ‚åŒ–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°å‹çš„<strong>å¯¹æŠ—æ€§è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ ï¼ˆAdv-SSLï¼‰</strong>ï¼Œç”¨äºæ— åè¿ç§»å­¦ä¹ ï¼Œä¸æœ‰åçš„åŒç±»æ–¹æ³•ç›¸æ¯”ï¼Œæ— éœ€å¢åŠ ä»»ä½•æˆæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè€Œä¸”å¾—åˆ°äº†å…¨é¢çš„ç«¯åˆ°ç«¯ç†è®ºä¿è¯çš„æ”¯æŒã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼ŒAdv-SSLä¸­çš„æœ€å°æœ€å¤§ä¼˜åŒ–é¼“åŠ±è¡¨ç¤ºåœ¨åµŒå…¥ç©ºé—´ä¸­å½¢æˆåˆ†ç¦»è‰¯å¥½çš„èšç±»ï¼Œå‰ææ˜¯ä¸Šæ¸¸æœ‰è¶³å¤Ÿçš„æœªæ ‡è®°æ•°æ®ã€‚å› æ­¤ï¼Œå³ä½¿ä¸‹æ¸¸æ ‡ç­¾æœ‰é™ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿèƒ½å®ç°å¼ºå¤§çš„åˆ†ç±»æ€§èƒ½ï¼Œä¸ºå°æ ·å­¦ä¹ æä¾›äº†æ–°çš„è§†è§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.08533v2">PDF</a> Accepted at the Conference on Neural Information Processing Systems   (NeurIPS 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•â€”â€”å¯¹æŠ—æ€§è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ ï¼ˆAdv-SSLï¼‰ï¼Œç”¨äºå®ç°æ— åçš„è¿ç§»å­¦ä¹ ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å¾—åˆ°å…¨é¢çš„ç«¯åˆ°ç«¯ç†è®ºæ”¯æŒã€‚é€šè¿‡é‡‡ç”¨æå°æå¤§ä¼˜åŒ–ï¼ŒAdv-SSLèƒ½å¤Ÿåœ¨åµŒå…¥ç©ºé—´ä¸­å½¢æˆåˆ†ç¦»çš„ç°‡ï¼Œåœ¨æœ‰é™ä¸‹æ¸¸æ ‡ç­¾çš„æƒ…å†µä¸‹å®ç°äº†å‡ºè‰²çš„åˆ†ç±»æ€§èƒ½ã€‚è¿™ä¸ºå°‘æ ·æœ¬å­¦ä¹ æä¾›äº†æ–°çš„è§†è§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æŠ—æ€§è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ ï¼ˆAdv-SSLï¼‰è§£å†³äº†è¿ç§»å­¦ä¹ ä¸­çš„æ— åæ ·æœ¬é—®é¢˜ã€‚</li>
<li>ä¸ç°æœ‰çš„æœ‰åæ–¹æ³•ç›¸æ¯”ï¼ŒAdv-SSLæ— éœ€é¢å¤–æˆæœ¬ã€‚</li>
<li>Adv-SSLåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æå°æå¤§ä¼˜åŒ–åœ¨åµŒå…¥ç©ºé—´ä¸­å½¢æˆåˆ†ç¦»çš„ç°‡ã€‚</li>
<li>å……è¶³çš„æ— æ ‡ç­¾ä¸Šæ¸¸æ•°æ®å¯¹äºAdv-SSLçš„è¡¨ç°è‡³å…³é‡è¦ã€‚</li>
<li>Adv-SSLåœ¨æœ‰é™ä¸‹æ¸¸æ ‡ç­¾çš„æƒ…å†µä¸‹å®ç°äº†å‡ºè‰²çš„åˆ†ç±»æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.08533">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-acececf99078e856662bfe2e2230e5f7~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073238&auth_key=1761073238-0-0-11d7384d799e2db8cac5590c6440a319&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-211650a57f6565649036cc1e5ba51f16~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073245&auth_key=1761073245-0-0-d5e95fa093f1bfb9d405786959590f1b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-6fdbb4e366dc6e0bce49717389c19c7e~resize:0:q75.jpg?source=1f5c5e47&expiration=1761073816&auth_key=1761073816-0-0-1d95ebbfbf28b19c47fb2a6d20a13bbd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  Multilingual Text-to-Image Person Retrieval via Bidirectional Relation   Reasoning and Aligning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-765b2c580bd75d3c2ff645416ea2a085~resize:0:q75.jpg?source=1f5c5e47&expiration=1761071592&auth_key=1761071592-0-0-48b2a6d495dbc2f66fbaf8ea777efb0b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  Enterprise Deep Research Steerable Multi-Agent Deep Research for   Enterprise Analytics
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32102k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
