<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  DELULU Discriminative Embedding Learning Using Latent Units for   Speaker-Aware Self-Supervised Speech Foundational Model">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-169453d37b91e1fa9639eb4132ee8805')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-22-æ›´æ–°"><a href="#2025-10-22-æ›´æ–°" class="headerlink" title="2025-10-22 æ›´æ–°"></a>2025-10-22 æ›´æ–°</h1><h2 id="DELULU-Discriminative-Embedding-Learning-Using-Latent-Units-for-Speaker-Aware-Self-Supervised-Speech-Foundational-Model"><a href="#DELULU-Discriminative-Embedding-Learning-Using-Latent-Units-for-Speaker-Aware-Self-Supervised-Speech-Foundational-Model" class="headerlink" title="DELULU: Discriminative Embedding Learning Using Latent Units for   Speaker-Aware Self-Supervised Speech Foundational Model"></a>DELULU: Discriminative Embedding Learning Using Latent Units for   Speaker-Aware Self-Supervised Speech Foundational Model</h2><p><strong>Authors:Massa Baali, Rita Singh, Bhiksha Raj</strong></p>
<p>Self-supervised speech models have achieved remarkable success on content-driven tasks, yet they remain limited in capturing speaker-discriminative features critical for verification, diarization, and profiling applications. We introduce DELULU, a speaker-aware self-supervised foundational model that addresses this limitation by integrating external supervision into the pseudo-label generation process. DELULU leverages frame-level embeddings from ReDimNet, a state-of-the-art speaker verification model, to guide the k-means clustering step during pre-training, introducing a strong speaker-discriminative inductive bias that aligns representation learning with speaker identity. The model is trained using a dual objective that combines masked prediction and denoising, further enhancing robustness and generalization. DELULU significantly outperforms prior self-supervised learning (SSL) models across a range of speaker-centric tasks, achieving up to 62% relative improvement in equal error rate (EER) for speaker verification and consistent gains on zero-shot profiling tasks such as gender, age, accent, and speaker counting. Our findings demonstrate that DELULU is a strong universal encoder for speaker-aware speech processing, enabling superior performance even without task-specific fine-tuning. </p>
<blockquote>
<p>è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹åœ¨å†…å®¹é©±åŠ¨çš„ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨æ•è·å¯¹éªŒè¯ã€åˆ†æ¡£å’Œè½®å»“æç»˜åº”ç”¨è‡³å…³é‡è¦çš„åŒºåˆ†è¯´è¯äººçš„ç‰¹å¾æ–¹é¢ä»å­˜åœ¨å±€é™æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†DELULUï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰è¯´è¯äººæ„è¯†çš„è‡ªç›‘ç£åŸºç¡€æ¨¡å‹ï¼Œå®ƒé€šè¿‡ä¼ªæ ‡ç­¾ç”Ÿæˆè¿‡ç¨‹ä¸­èå…¥å¤–éƒ¨ç›‘ç£æ¥è§£å†³è¿™ä¸€å±€é™æ€§ã€‚DELULUåˆ©ç”¨æ¥è‡ªæœ€æ–°è¯­éŸ³éªŒè¯æ¨¡å‹ReDimNetçš„å¸§çº§åµŒå…¥ï¼Œæ¥æŒ‡å¯¼é¢„è®­ç»ƒè¿‡ç¨‹ä¸­çš„k-å‡å€¼èšç±»æ­¥éª¤ï¼Œå¼•å…¥ä¸€ä¸ªå¼ºå¤§çš„è¯´è¯äººåŒºåˆ†å½’çº³åè§ï¼Œä½¿è¡¨å¾å­¦ä¹ ä¸è¯´è¯äººèº«ä»½ä¿æŒä¸€è‡´ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ç»“åˆæ©ç é¢„æµ‹å’Œå»å™ªçš„åŒé‡ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚DELULUåœ¨å¤šç§ä»¥è¯´è¯äººä¸ºä¸­å¿ƒçš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå…ˆå‰çš„è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ¨¡å‹ï¼Œåœ¨ç­‰é”™è¯¯ç‡ï¼ˆEERï¼‰æ–¹é¢å®ç°äº†é«˜è¾¾62%çš„ç›¸å¯¹æ”¹è¿›ï¼ˆç”¨äºè¯­éŸ³éªŒè¯ä»»åŠ¡ï¼‰ï¼Œå¹¶ä¸”åœ¨é›¶æ ·æœ¬è½®å»“æç»˜ä»»åŠ¡ï¼ˆå¦‚æ€§åˆ«ã€å¹´é¾„ã€å£éŸ³å’Œè¯´è¯äººæ•°ç»Ÿè®¡ï¼‰ä¸Šè¡¨ç°ä¸€è‡´ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒDELULUæ˜¯ä¸€ä¸ªå¼ºå¤§çš„é€šç”¨ç¼–ç å™¨ï¼Œé€‚ç”¨äºå…·æœ‰è¯´è¯äººæ„è¯†çš„è¯­éŸ³å¤„ç†ï¼Œå³ä½¿åœ¨æ— éœ€ç‰¹å®šä»»åŠ¡å¾®è°ƒçš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°å“è¶Šæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17662v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†DELULUè¿™ä¸€å…·æœ‰è¯´è¯è€…æ„è¯†çš„è‡ªç›‘ç£åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆå¤–éƒ¨ç›‘ç£åˆ°ä¼ªæ ‡ç­¾ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œè§£å†³äº†ç°æœ‰è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹åœ¨æ•è·è¯´è¯è€…è¾¨è¯†ç‰¹å¾æ–¹é¢çš„å±€é™æ€§ã€‚DELULUåˆ©ç”¨ReDimNetçš„å¸§çº§åµŒå…¥æ¥æŒ‡å¯¼é¢„è®­ç»ƒä¸­çš„K-meansèšç±»æ­¥éª¤ï¼Œå¼•å…¥äº†å¼ºè¯´è¯è€…è¾¨è¯†çš„å½’çº³åç½®ï¼Œä½¿è¡¨å¾å­¦ä¹ ä¸è¯´è¯è€…èº«ä»½å¯¹é½ã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆæ©ç é¢„æµ‹å’Œå»å™ªçš„åŒç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œå¢å¼ºäº†ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚DELULUåœ¨å¤šç§ä»¥è¯´è¯è€…ä¸ºä¸­å¿ƒçš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå…ˆå‰çš„è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œåœ¨è¯´è¯è€…éªŒè¯çš„ç­‰é”™è¯¯ç‡ä¸Šå®ç°äº†é«˜è¾¾62%çš„ç›¸å¯¹æ”¹è¿›ï¼Œå¹¶åœ¨é›¶æ ·æœ¬åˆ†æä»»åŠ¡ä¸Šå–å¾—äº†æŒç»­çš„æ”¶ç›Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DELULUæ˜¯ä¸€ä¸ªå…·æœ‰è¯´è¯è€…æ„è¯†çš„è‡ªç›‘ç£åŸºç¡€æ¨¡å‹ï¼Œè§£å†³äº†ç°æœ‰è¯­éŸ³æ¨¡å‹åœ¨æ•è·è¯´è¯è€…è¾¨è¯†ç‰¹å¾ä¸Šçš„å±€é™æ€§ã€‚</li>
<li>DELULUé€šè¿‡é›†æˆå¤–éƒ¨ç›‘ç£åˆ°ä¼ªæ ‡ç­¾ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ReDimNetçš„å¸§çº§åµŒå…¥åœ¨DELULUçš„é¢„è®­ç»ƒä¸­èµ·åˆ°é‡è¦ä½œç”¨ï¼Œä¸ºK-meansèšç±»æä¾›äº†æŒ‡å¯¼ï¼Œå¼•å…¥äº†å¼ºè¯´è¯è€…è¾¨è¯†çš„å½’çº³åç½®ã€‚</li>
<li>DELULUé€šè¿‡ç»“åˆæ©ç é¢„æµ‹å’Œå»å™ªçš„åŒç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>DELULUåœ¨å¤šç§ä»¥è¯´è¯è€…ä¸ºä¸­å¿ƒçš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒåŒ…æ‹¬è¯´è¯è€…éªŒè¯ã€æ€§åˆ«ã€å¹´é¾„ã€å£éŸ³å’Œè¯´è¯è€…è®¡æ•°ç­‰ä»»åŠ¡ã€‚</li>
<li>DELULUå®ç°äº†é«˜è¾¾62%çš„ç›¸å¯¹æ”¹è¿›åœ¨è¯´è¯è€…éªŒè¯çš„ç­‰é”™è¯¯ç‡ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17662">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9c3a56a48b2b7e978db336428e17e3e9" align="middle">
<img src="https://picx.zhimg.com/v2-3197a9f67f0f115c617c2785b02bd8b8" align="middle">
<img src="https://picx.zhimg.com/v2-454aec9c12e7abe92aa6db43f65156c7" align="middle">
<img src="https://picx.zhimg.com/v2-4a27c026e4edc27476fa1031f553f7c3" align="middle">
<img src="https://picx.zhimg.com/v2-589b453b978e283c5b42c83197160fd2" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Schrodinger-Bridge-Mamba-for-One-Step-Speech-Enhancement"><a href="#Schrodinger-Bridge-Mamba-for-One-Step-Speech-Enhancement" class="headerlink" title="SchrÃ¶dinger Bridge Mamba for One-Step Speech Enhancement"></a>SchrÃ¶dinger Bridge Mamba for One-Step Speech Enhancement</h2><p><strong>Authors:Jing Yang, Sirui Wang, Chao Wu, Fan Fan</strong></p>
<p>We propose Schr&quot;odinger Bridge Mamba (SBM), a new concept of training-inference framework motivated by the inherent compatibility between Schr&quot;odinger Bridge (SB) training paradigm and selective state-space model Mamba. We exemplify the concept of SBM with an implementation for generative speech enhancement. Experiments on a joint denoising and dereverberation task using four benchmark datasets demonstrate that SBM, with only 1-step inference, outperforms strong baselines with 1-step or iterative inference and achieves the best real-time factor (RTF). Beyond speech enhancement, we discuss the integration of SB paradigm and selective state-space model architecture based on their underlying alignment, which indicates a promising direction for exploring new deep generative models potentially applicable to a broad range of generative tasks. Demo page: <a target="_blank" rel="noopener" href="https://sbmse.github.io/">https://sbmse.github.io</a> </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†SchrÃ¶dinger Bridge Mambaï¼ˆSBMï¼‰è¿™ä¸€æ–°çš„è®­ç»ƒæ¨ç†æ¡†æ¶æ¦‚å¿µï¼Œå…¶çµæ„Ÿæ¥æºäºSchrÃ¶dinger Bridgeï¼ˆSBï¼‰è®­ç»ƒèŒƒå¼ä¸é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹Mambaä¹‹é—´çš„å†…åœ¨å…¼å®¹æ€§ã€‚æˆ‘ä»¬é€šè¿‡ç”Ÿæˆå¼è¯­éŸ³å¢å¼ºçš„å®ç°æ¥ä¸¾ä¾‹è¯´æ˜SBMçš„æ¦‚å¿µã€‚ä½¿ç”¨å››ä¸ªåŸºå‡†æ•°æ®é›†è¿›è¡Œçš„è”åˆå»å™ªå’Œæ¶ˆæ··å“ä»»åŠ¡å®éªŒè¡¨æ˜ï¼ŒSBMåªéœ€è¿›è¡Œ1æ­¥æ¨ç†ï¼Œå³å¯è¶…è¶Šå…·æœ‰1æ­¥æˆ–è¿­ä»£æ¨ç†çš„å¼ºåŠ²åŸºå‡†çº¿ï¼Œå¹¶è¾¾åˆ°æœ€ä½³å®æ—¶å› å­ï¼ˆRTFï¼‰ã€‚é™¤äº†è¯­éŸ³å¢å¼ºï¼Œæˆ‘ä»¬è¿˜è®¨è®ºäº†åŸºäºSBèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„å†…åœ¨å¯¹é½è¿›è¡Œé›†æˆçš„æ–¹æ³•ï¼Œè¿™ä¸ºæˆ‘ä»¬æ¢ç´¢å¯å¹¿æ³›åº”ç”¨äºå„ç§ç”Ÿæˆä»»åŠ¡çš„æ–°å‹æ·±åº¦ç”Ÿæˆæ¨¡å‹æä¾›äº†æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚Demoé¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://sbmse.github.io/">https://sbmse.github.io</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16834v1">PDF</a> 5 pages, 1 figure</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†åŸºäºè–›å®šè°”æ¡¥ï¼ˆSBï¼‰è®­ç»ƒèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹Mambaçš„å†…åœ¨å…¼å®¹æ€§çš„æ–°è®­ç»ƒæ¨ç†æ¡†æ¶â€”â€”è–›å®šè°”æ¡¥Mambaï¼ˆSBMï¼‰ã€‚é€šè¿‡ç”Ÿæˆè¯­éŸ³å¢å¼ºçš„å®ç°æ¥å±•ç¤ºSBMçš„æ¦‚å¿µã€‚åœ¨è”åˆå»å™ªå’Œå»æ··å“ä»»åŠ¡ä¸Šçš„å››ä¸ªåŸºå‡†æ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼ŒSBMä»…ä¸€æ­¥æ¨ç†å°±è¶…è¶Šäº†å…·æœ‰ä¸€æ­¥æˆ–è¿­ä»£æ¨ç†çš„å¼ºåŸºçº¿ï¼Œå¹¶è·å¾—äº†æœ€ä½³å®æ—¶å› å­ï¼ˆRTFï¼‰ã€‚é™¤äº†è¯­éŸ³å¢å¼ºï¼Œæœ¬æ–‡è¿˜è®¨è®ºäº†SBèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„é›†æˆï¼ŒåŸºäºå®ƒä»¬çš„åŸºç¡€å¯¹é½ï¼Œè¿™ä¸ºæ¢ç´¢å¯å¹¿æ³›åº”ç”¨äºå„ç§ç”Ÿæˆä»»åŠ¡çš„æœ‰å‰é€”çš„æ·±å±‚ç”Ÿæˆæ¨¡å‹æŒ‡æ˜äº†æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†åŸºäºè–›å®šè°”æ¡¥ï¼ˆSBï¼‰è®­ç»ƒèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹Mambaçš„æ–°è®­ç»ƒæ¨ç†æ¡†æ¶â€”â€”è–›å®šè°”æ¡¥Mambaï¼ˆSBMï¼‰ã€‚</li>
<li>SBMé€šè¿‡ç”Ÿæˆè¯­éŸ³å¢å¼ºçš„å®ç°æ¥å±•ç¤ºå…¶æ¦‚å¿µã€‚</li>
<li>åœ¨è”åˆå»å™ªå’Œå»æ··å“ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSBMå…·æœ‰å‡ºè‰²çš„æ€§èƒ½ï¼Œä»…ä¸€æ­¥æ¨ç†å°±è¶…è¶Šäº†å¼ºåŸºçº¿ã€‚</li>
<li>SBMè·å¾—äº†æœ€ä½³å®æ—¶å› å­ï¼ˆRTFï¼‰ã€‚</li>
<li>é™¤äº†è¯­éŸ³å¢å¼ºï¼ŒSBMçš„é›†æˆè¿˜è®¨è®ºäº†SBèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„é›†æˆã€‚</li>
<li>SBèŒƒå¼å’Œé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„åŸºç¡€å¯¹é½ä¸ºæ¢ç´¢æ–°çš„æ·±å±‚ç”Ÿæˆæ¨¡å‹æä¾›äº†æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16834">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-73cc1bb20efabdc066d0dcc9a79d9833" align="middle">
<img src="https://picx.zhimg.com/v2-5f1e3f30c09879fbf02e7f19f195ba88" align="middle">
<img src="https://picx.zhimg.com/v2-03458972796cc14577880af372e2022a" align="middle">
<img src="https://picx.zhimg.com/v2-9d28599430f302be5b470a783aedb820" align="middle">
<img src="https://picx.zhimg.com/v2-9c7cc834b3be8e5baa88d7031ea92ad4" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SHANKS-Simultaneous-Hearing-and-Thinking-for-Spoken-Language-Models"><a href="#SHANKS-Simultaneous-Hearing-and-Thinking-for-Spoken-Language-Models" class="headerlink" title="SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models"></a>SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models</h2><p><strong>Authors:Cheng-Han Chiang, Xiaofei Wang, Linjie Li, Chung-Ching Lin, Kevin Lin, Shujie Liu, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang</strong></p>
<p>Current large language models (LLMs) and spoken language models (SLMs) begin thinking and taking actions only after the user has finished their turn. This prevents the model from interacting during the userâ€™s turn and can lead to high response latency while it waits to think. Consequently, thinking after receiving the full input is not suitable for speech-to-speech interaction, where real-time, low-latency exchange is important. We address this by noting that humans naturally â€œthink while listening.â€ In this paper, we propose SHANKS, a general inference framework that enables SLMs to generate unspoken chain-of-thought reasoning while listening to the user input. SHANKS streams the input speech in fixed-duration chunks and, as soon as a chunk is received, generates unspoken reasoning based on all previous speech and reasoning, while the user continues speaking. SHANKS uses this unspoken reasoning to decide whether to interrupt the user and to make tool calls to complete the task. We demonstrate that SHANKS enhances real-time user-SLM interaction in two scenarios: (1) when the user is presenting a step-by-step solution to a math problem, SHANKS can listen, reason, and interrupt when the user makes a mistake, achieving 37.1% higher interruption accuracy than a baseline that interrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can complete 56.9% of the tool calls before the user finishes their turn. Overall, SHANKS moves toward models that keep thinking throughout the conversation, not only after a turn ends. Animated illustrations of Shanks can be found at <a target="_blank" rel="noopener" href="https://d223302.github.io/SHANKS/">https://d223302.github.io/SHANKS/</a> </p>
<blockquote>
<p>å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå£è¯­æ¨¡å‹ï¼ˆSLMï¼‰åªæœ‰åœ¨ç”¨æˆ·å®Œæˆå…¶å‘è¨€åæ‰å¼€å§‹æ€è€ƒå’Œè¡ŒåŠ¨ã€‚è¿™é˜»æ­¢äº†æ¨¡å‹åœ¨ç”¨æˆ·å‘è¨€æ—¶çš„äº¤äº’ï¼Œå¹¶å¯èƒ½å¯¼è‡´å“åº”å»¶è¿Ÿã€‚å› æ­¤ï¼Œåœ¨æ¥æ”¶å®Œæ•´è¾“å…¥åå†æ€è€ƒä¸é€‚åˆè¯­éŸ³åˆ°è¯­éŸ³çš„äº¤äº’ï¼Œå…¶ä¸­å®æ—¶ã€ä½å»¶è¿Ÿçš„äº¤äº’éå¸¸é‡è¦ã€‚æˆ‘ä»¬é€šè¿‡æ³¨æ„åˆ°äººç±»è‡ªç„¶åœ°â€œè¾¹å¬è¾¹æƒ³â€æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºSHANKSï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨æ¨ç†æ¡†æ¶ï¼Œå®ƒä½¿SLMèƒ½å¤Ÿåœ¨å¬å–ç”¨æˆ·è¾“å…¥æ—¶ç”Ÿæˆæœªè¡¨è¾¾çš„æ€ç»´é“¾æ¨ç†ã€‚SHANKSä»¥å›ºå®šæŒç»­æ—¶é—´çš„å—æµè¾“å…¥è¯­éŸ³ï¼Œåœ¨æ”¶åˆ°ä¸€ä¸ªå—åï¼Œç«‹å³åŸºäºå…ˆå‰çš„è¯­éŸ³å’Œæ¨ç†ç”Ÿæˆæœªè¡¨è¾¾çš„æ¨ç†ï¼Œè€Œç”¨æˆ·ä»åœ¨ç»§ç»­è¯´è¯ã€‚SHANKSä½¿ç”¨è¿™ç§æœªè¡¨è¾¾çš„æ¨ç†æ¥å†³å®šæ˜¯å¦ä¸­æ–­ç”¨æˆ·å¹¶è¿›è¡Œå·¥å…·è°ƒç”¨ä»¥å®Œæˆä»»åŠ¡ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒSHANKSåœ¨ä¸¤ç§æƒ…å†µä¸‹å¢å¼ºäº†å®æ—¶ç”¨æˆ·-SLMäº¤äº’ï¼šï¼ˆ1ï¼‰å½“ç”¨æˆ·é€æ­¥è§£å†³æ•°å­¦é—®é¢˜æ—¶ï¼ŒSHANKSå¯ä»¥å€¾å¬ã€æ¨ç†ï¼Œå¹¶åœ¨ç”¨æˆ·çŠ¯é”™è¯¯æ—¶ä¸­æ–­ï¼Œå…¶ä¸­æ–­å‡†ç¡®æ€§æ¯”åœ¨æ²¡æœ‰æ€è€ƒçš„æƒ…å†µä¸‹ä¸­æ–­çš„åŸºçº¿é«˜å‡º37.1%ï¼›ï¼ˆ2ï¼‰åœ¨å·¥å…·å¢å¼ºçš„å¯¹è¯ä¸­ï¼ŒSHANKSå¯ä»¥åœ¨ç”¨æˆ·å®Œæˆå…¶å‘è¨€ä¹‹å‰å®Œæˆ56.9%çš„å·¥å…·è°ƒç”¨ã€‚æ€»çš„æ¥è¯´ï¼ŒSHANKSæ­£æœç€ä½¿æ¨¡å‹åœ¨æ•´ä¸ªå¯¹è¯è¿‡ç¨‹ä¸­ä¿æŒæ€è€ƒçš„æ–¹å‘å‘å±•ï¼Œè€Œä¸ä»…ä»…æ˜¯åœ¨ä¸€è½®å¯¹è¯ç»“æŸåã€‚æœ‰å…³Shanksçš„åŠ¨ç”»æ’å›¾ï¼Œè¯·è®¿é—®ï¼š[<a target="_blank" rel="noopener" href="https://d223302.github.io/SHANKS/]">https://d223302.github.io/SHANKS/]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06917v2">PDF</a> Work in progress</p>
<p><strong>Summary</strong>ï¼š</p>
<p>ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå£è¯­è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰åœ¨ç”¨æˆ·ç»“æŸå‘è¨€åæ‰è¿›è¡Œæ€è€ƒå¹¶è¡ŒåŠ¨ï¼Œå¯¼è‡´äº¤äº’æ—¶å“åº”å»¶è¿Ÿè¾ƒé«˜ï¼Œä¸é€‚åˆè¿›è¡Œè¯­éŸ³åˆ°è¯­éŸ³çš„å®æ—¶äº¤äº’ã€‚æœ¬æ–‡æå‡ºSHANKSè¿™ä¸€é€šç”¨æ¨ç†æ¡†æ¶ï¼Œä½¿SLMåœ¨ç”¨æˆ·è¾“å…¥æ—¶èƒ½å¤Ÿè¾¹å¬è¾¹æ€è€ƒï¼Œç”Ÿæˆæœªè¯´å‡ºçš„æ€ç»´é“¾ã€‚SHANKSé€šè¿‡å›ºå®šæ—¶é•¿å—æ¥æ”¶è¯­éŸ³è¾“å…¥ï¼Œå¹¶åœ¨æ¥æ”¶åˆ°ä¸€å—åå³åŸºäºä¹‹å‰çš„è¯­éŸ³å’Œæ¨ç†ç”Ÿæˆæœªè¯´å‡ºçš„æ€è€ƒã€‚å®éªŒè¡¨æ˜ï¼ŒSHANKSåœ¨ä¸¤ç§åœºæ™¯ä¸‹å¢å¼ºäº†ç”¨æˆ·ä¸SLMçš„å®æ—¶äº¤äº’ï¼šåœ¨ç”¨æˆ·é€æ­¥è§£å†³æ•°å­¦é—®é¢˜åŠå·¥å…·è¾…åŠ©å¯¹è¯ä¸­ï¼ŒSHANKSèƒ½å¤Ÿåœ¨ç”¨æˆ·å‘è¨€è¿‡ç¨‹ä¸­è¿›è¡Œæ€è€ƒå’Œä¸­æ–­ï¼Œæé«˜äº†ä¸­æ–­å‡†ç¡®æ€§å’Œå·¥å…·ä½¿ç”¨æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç°æœ‰è¯­è¨€æ¨¡å‹åœ¨ç”¨æˆ·ç»“æŸå‘è¨€åæ‰è¿›è¡Œæ€è€ƒï¼Œå¯¼è‡´äº¤äº’å“åº”å»¶è¿Ÿã€‚</li>
<li>SHANKSæ¡†æ¶èƒ½è®©SLMåœ¨ç”¨æˆ·è¾“å…¥æ—¶è¾¹å¬è¾¹æ€è€ƒï¼Œç”Ÿæˆæœªè¯´å‡ºçš„æ€ç»´é“¾ã€‚</li>
<li>SHANKSé€šè¿‡å›ºå®šæ—¶é•¿å—æ¥æ”¶è¯­éŸ³è¾“å…¥ï¼Œå¹¶å¿«é€Ÿç”ŸæˆåŸºäºä¹‹å‰è¯­éŸ³å’Œæ¨ç†çš„æœªè¯´å‡ºçš„æ€è€ƒã€‚</li>
<li>åœ¨è§£å†³æ•°å­¦é—®é¢˜æ—¶ï¼ŒSHANKSèƒ½å®æ—¶ç›‘å¬ã€æ¨ç†ï¼Œå¹¶åœ¨ç”¨æˆ·çŠ¯é”™æ—¶ä¸­æ–­ï¼Œæé«˜ä¸­æ–­å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨å·¥å…·è¾…åŠ©å¯¹è¯ä¸­ï¼ŒSHANKSèƒ½åœ¨ç”¨æˆ·å®Œæˆå‘è¨€å‰å®Œæˆå¤§éƒ¨åˆ†å·¥å…·è°ƒç”¨ï¼Œæé«˜å·¥å…·ä½¿ç”¨æ•ˆç‡ã€‚</li>
<li>SHANKSå®ç°äº†æ¨¡å‹åœ¨å¯¹è¯è¿‡ç¨‹ä¸­çš„æŒç»­æ€è€ƒï¼Œä¸ä»…é™äºåœ¨ç»“æŸä¸€å›åˆåçš„æ€è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06917">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1e4e93c9d517191952bdea070ba8b28e" align="middle">
<img src="https://picx.zhimg.com/v2-803df79cd6bb2806b37f96c795cee3ad" align="middle">
<img src="https://picx.zhimg.com/v2-77208d58dd00b35ca19159fc9e22ce30" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Speech-Foundation-Models-Generalize-to-Time-Series-Tasks-from-Wearable-Sensor-Data"><a href="#Speech-Foundation-Models-Generalize-to-Time-Series-Tasks-from-Wearable-Sensor-Data" class="headerlink" title="Speech Foundation Models Generalize to Time Series Tasks from Wearable   Sensor Data"></a>Speech Foundation Models Generalize to Time Series Tasks from Wearable   Sensor Data</h2><p><strong>Authors:Jaya Narain, Zakaria Aldeneh, Shirley Ren</strong></p>
<p>Both speech and sensor time series data encode information in both the time- and frequency- domains, like spectral powers and waveform shapelets. We show that speech foundation models learn representations that generalize beyond the speech domain and achieve state-of-the-art performance on diverse time-series tasks from wearable sensors. Probes trained on features extracted from HuBERT and wav2vec 2.0 outperform those extracted from self-supervised models trained directly on modality-specific datasets for mood classification, arrhythmia detection, and activity classification tasks. We find that the convolutional feature encoders of speech models are particularly relevant for wearable sensor applications. The proposed approach enhances performance on data-scarce time-series tasks using simple probing methods. This work takes a step toward developing generalized time-series models that unify speech and sensor modalities. </p>
<blockquote>
<p>è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ—¶é—´åºåˆ—æ•°æ®åœ¨æ—¶é—´å’Œé¢‘ç‡åŸŸä¸­éƒ½ç¼–ç ä¿¡æ¯ï¼Œå¦‚è°±åŠŸç‡å’Œæ³¢å½¢å½¢çŠ¶ã€‚æˆ‘ä»¬å±•ç¤ºè¯­éŸ³åŸºç¡€æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºèƒ½å¤Ÿæ¨å¹¿åˆ°è¯­éŸ³åŸŸä¹‹å¤–ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„æ—¶é—´åºåˆ—ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ï¼Œè¿™äº›ä»»åŠ¡æ¥è‡ªå¯ç©¿æˆ´ä¼ æ„Ÿå™¨ã€‚ä½¿ç”¨HuBERTå’Œwav2vec 2.0æå–çš„ç‰¹å¾è®­ç»ƒçš„æ¢é’ˆåœ¨æƒ…ç»ªåˆ†ç±»ã€å¿ƒå¾‹å¤±å¸¸æ£€æµ‹å’Œæ´»åŠ¨åˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç›´æ¥ä»ç‰¹å®šæ¨¡æ€æ•°æ®é›†ä¸Šè®­ç»ƒçš„è‡ªæˆ‘ç›‘ç£æ¨¡å‹æå–çš„ç‰¹å¾ã€‚æˆ‘ä»¬å‘ç°è¯­éŸ³æ¨¡å‹çš„å·ç§¯ç‰¹å¾ç¼–ç å™¨å¯¹äºå¯ç©¿æˆ´ä¼ æ„Ÿå™¨åº”ç”¨ç‰¹åˆ«é‡è¦ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä½¿ç”¨ç®€å•çš„æ¢æµ‹æ–¹æ³•æé«˜äº†æ•°æ®ç¨€ç¼ºæ—¶é—´åºåˆ—ä»»åŠ¡çš„æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œæœç€å¼€å‘ç»Ÿä¸€è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ¨¡æ€çš„é€šç”¨æ—¶é—´åºåˆ—æ¨¡å‹è¿ˆå‡ºäº†ä¸€æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.00221v2">PDF</a> Preprint, under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ—¶é—´åºåˆ—æ•°æ®åœ¨æ—¶é—´å’Œé¢‘ç‡åŸŸä¸­çš„ä¿¡æ¯ç¼–ç ï¼Œå¦‚è°±åŠŸç‡å’Œæ³¢å½¢ç‰¹å¾ã€‚ç ”ç©¶å±•ç¤ºäº†åŸºäºè¯­éŸ³çš„åŸºç¡€æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºæ–¹æ³•èƒ½å¤Ÿè·¨è¯­éŸ³é¢†åŸŸè¿›è¡Œæ¨å¹¿ï¼Œå¹¶åœ¨å¤šæ ·åŒ–çš„æ—¶é—´åºåˆ—ä»»åŠ¡ä¸Šå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¿™äº›ä»»åŠ¡åŒ…æ‹¬å¯ç©¿æˆ´ä¼ æ„Ÿå™¨çš„æƒ…ç»ªåˆ†ç±»ã€å¿ƒå¾‹å¤±å¸¸æ£€æµ‹å’Œæ´»åŠ¨åˆ†ç±»ã€‚ç ”ç©¶ä¸­å‘ç°ï¼Œè¯­éŸ³æ¨¡å‹çš„å·ç§¯ç‰¹å¾ç¼–ç å™¨å¯¹å¯ç©¿æˆ´ä¼ æ„Ÿå™¨åº”ç”¨ç‰¹åˆ«é‡è¦ã€‚é€šè¿‡ç®€å•çš„æ¢æµ‹æ–¹æ³•ï¼Œè¯¥ç ”ç©¶æé«˜äº†æ•°æ®ç¨€ç¼ºæ—¶é—´åºåˆ—ä»»åŠ¡çš„æ€§èƒ½ã€‚æœ¬ç ”ç©¶æœç€å¼€å‘ç»Ÿä¸€è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ¨¡æ€çš„é€šç”¨æ—¶é—´åºåˆ—æ¨¡å‹è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ—¶é—´åºåˆ—æ•°æ®åœ¨æ—¶é—´å’Œé¢‘ç‡åŸŸä¸­éƒ½åŒ…å«ä¿¡æ¯ï¼Œå¦‚è°±åŠŸç‡å’Œæ³¢å½¢ç‰¹å¾ã€‚</li>
<li>åŸºäºè¯­éŸ³çš„åŸºç¡€æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°è·¨è¯­éŸ³é¢†åŸŸçš„è¡¨ç¤ºæ–¹æ³•ã€‚</li>
<li>è¿™äº›æ¨¡å‹åœ¨å¤šæ ·åŒ–çš„æ—¶é—´åºåˆ—ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æƒ…ç»ªåˆ†ç±»ã€å¿ƒå¾‹å¤±å¸¸æ£€æµ‹å’Œæ´»åŠ¨åˆ†ç±»ç­‰å¯ç©¿æˆ´ä¼ æ„Ÿå™¨ä»»åŠ¡ã€‚</li>
<li>è¯­éŸ³æ¨¡å‹çš„å·ç§¯ç‰¹å¾ç¼–ç å™¨å¯¹å¯ç©¿æˆ´ä¼ æ„Ÿå™¨åº”ç”¨ç‰¹åˆ«é‡è¦ã€‚</li>
<li>é€šè¿‡ç®€å•çš„æ¢æµ‹æ–¹æ³•ï¼Œè¯¥ç ”ç©¶è¡¨æ˜èƒ½å¤Ÿæé«˜æ•°æ®ç¨€ç¼ºæ—¶é—´åºåˆ—ä»»åŠ¡çš„æ€§èƒ½ã€‚</li>
<li>æ­¤ç ”ç©¶ä¸ºå¼€å‘ç»Ÿä¸€çš„è¯­éŸ³å’Œä¼ æ„Ÿå™¨æ¨¡æ€çš„é€šç”¨æ—¶é—´åºåˆ—æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.00221">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0fb18e497bac61cd299ee34acbdcac26" align="middle">
<img src="https://picx.zhimg.com/v2-169453d37b91e1fa9639eb4132ee8805" align="middle">
<img src="https://picx.zhimg.com/v2-6a8356c58654a5ce71648ac39c614f37" align="middle">
<img src="https://picx.zhimg.com/v2-8defd0c3ce2c51d19f2c0a8b9e46de63" align="middle">
<img src="https://picx.zhimg.com/v2-83b552abd7ad475440b69d96db938093" align="middle">
<img src="https://picx.zhimg.com/v2-e12940cfae0f26dfd673b0c3bc4e8c7c" align="middle">
<img src="https://picx.zhimg.com/v2-63ba73a6752aa510a3986aca6d8d530b" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Late-Fusion-and-Multi-Level-Fission-Amplify-Cross-Modal-Transfer-in-Text-Speech-LMs"><a href="#Late-Fusion-and-Multi-Level-Fission-Amplify-Cross-Modal-Transfer-in-Text-Speech-LMs" class="headerlink" title="Late Fusion and Multi-Level Fission Amplify Cross-Modal Transfer in   Text-Speech LMs"></a>Late Fusion and Multi-Level Fission Amplify Cross-Modal Transfer in   Text-Speech LMs</h2><p><strong>Authors:Santiago Cuervo, Adel Moumen, Yanis Labrak, Sameer Khurana, Antoine Laurent, Mickael Rouvier, Phil Woodland, Ricard Marxer</strong></p>
<p>Text-Speech Language Models (TSLMs) â€“ language models trained to jointly process and generate text and speech â€“ are commonly trained through an early modality fusion&#x2F;fission approach, in which both modalities are fed and predicted from a shared backbone via linear layers. We hypothesize that this approach limits cross-modal transfer by neglecting feature compositionality â€“ specifically, the finer-grained nature of speech representations compared to text â€“ preventing the emergence of a shared feature hierarchy within model layers. In this paper, we argue that this limitation can be addressed through late fusion and fission, with a fission process that accesses both high- and low-level features for speech generation. Our models implementing these principles, SmolTolk, rival or surpass state-of-the-art TSLMs trained with orders of magnitude more compute, and achieve significantly improved cross-modal performance relative to early fusion&#x2F;fission baselines. Representation analyses further suggest that our method enhances the modelâ€™s ability to abstract higher-level, more semantic features from speech, and leads to increasingly shared representation spaces across layers. </p>
<blockquote>
<p>æ–‡æœ¬-è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆTSLMsï¼‰â€”â€”è®­ç»ƒç”¨äºè”åˆå¤„ç†å’Œç”Ÿæˆæ–‡æœ¬å’Œè¯­éŸ³çš„è¯­è¨€æ¨¡å‹â€”â€”é€šå¸¸é€šè¿‡æ—©æœŸçš„æ¨¡æ€èåˆ&#x2F;åˆ†è£‚æ–¹æ³•è®­ç»ƒï¼Œå…¶ä¸­é€šè¿‡çº¿æ€§å±‚ä»å…±äº«ä¸»å¹²è¾“å…¥å¹¶é¢„æµ‹ä¸¤ç§æ¨¡æ€ã€‚æˆ‘ä»¬å‡è®¾è¿™ç§æ–¹æ³•å¿½ç•¥äº†ç‰¹å¾ç»„åˆæ€§ï¼Œå³ä¸æ–‡æœ¬ç›¸æ¯”ï¼Œè¯­éŸ³è¡¨ç¤ºçš„ç²’åº¦æ›´ç²¾ç»†ï¼Œé™åˆ¶äº†è·¨æ¨¡æ€è½¬ç§»ï¼Œé˜»ç¢äº†æ¨¡å‹å±‚å†…å…±äº«ç‰¹å¾å±‚æ¬¡ç»“æ„çš„å‡ºç°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºé€šè¿‡åæœŸèåˆå’Œåˆ†è£‚å¯ä»¥è§£å†³è¿™ä¸€é™åˆ¶ï¼Œåˆ†è£‚è¿‡ç¨‹å¯ä»¥è®¿é—®ç”¨äºè¯­éŸ³ç”Ÿæˆçš„é«˜ã€ä½å±‚æ¬¡ç‰¹å¾ã€‚å®ç°è¿™äº›åŸåˆ™çš„æ¨¡å‹SmolTolkä¸æœ€å…ˆè¿›çš„TSLMç›¸æ¯”ï¼Œè®¡ç®—é‡é«˜å‡ºæ•°å€ï¼Œç›¸å¯¹äºæ—©æœŸèåˆåˆ†è£‚åŸºçº¿å®ç°äº†æ˜¾è‘—çš„è·¨æ¨¡æ€æ€§èƒ½æå‡ã€‚è¡¨å¾åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†æ¨¡å‹ä»è¯­éŸ³ä¸­æŠ½è±¡å‡ºé«˜çº§ã€æ›´è¯­ä¹‰ç‰¹å¾çš„èƒ½åŠ›ï¼Œå¹¶å¯¼è‡´é€å±‚ä¹‹é—´è¶Šæ¥è¶Šå…±äº«è¡¨ç¤ºç©ºé—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06211v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä¸»è¦ä»‹ç»äº†æ–‡æœ¬è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆTSLMsï¼‰çš„å¸¸è§è®­ç»ƒæ–¹å¼æ˜¯é€šè¿‡æ—©æœŸæ¨¡æ€èåˆ&#x2F;åˆ†è£‚æ³•ï¼Œé‡‡ç”¨çº¿æ€§å±‚åœ¨å…±äº«éª¨å¹²ä¸­è¿›è¡Œå¤„ç†å’Œé¢„æµ‹ã€‚è¯¥ç ”ç©¶å‡è®¾æ—©æœŸæ¨¡æ€èåˆ&#x2F;åˆ†è£‚æ–¹æ³•å¿½ç•¥äº†ç‰¹å¾ç»„åˆæ€§ï¼Œå¯¼è‡´è·¨æ¨¡æ€è¿ç§»å—é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†åŸºäºåæœŸèåˆå’Œåˆ†è£‚çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åˆ†è£‚è¿‡ç¨‹èƒ½å¤Ÿè®¿é—®è¯­éŸ³ç”Ÿæˆçš„é«˜ã€ä½å±‚æ¬¡ç‰¹å¾ã€‚å®ç°çš„æ¨¡å‹SmolTolkä¸é‡‡ç”¨å¤§é‡è®¡ç®—è®­ç»ƒçš„å…ˆè¿›TSLMç›¸æ¯”å…·æœ‰ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶ä¸”ç›¸å¯¹äºæ—©æœŸèåˆåˆ†è£‚åŸºçº¿æ˜¾ç¤ºå‡ºæ˜¾è‘—æ”¹è¿›çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚åˆ†ææ˜¾ç¤ºè¯¥æ–¹æ³•æé«˜äº†æ¨¡å‹ä»è¯­éŸ³ä¸­æå–é«˜çº§è¯­ä¹‰ç‰¹å¾çš„èƒ½åŠ›ï¼Œå¹¶ä¸”æœ‰åŠ©äºåœ¨ä¸åŒå±‚çº§å»ºç«‹å…±äº«è¡¨ç¤ºç©ºé—´ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TSLMsé€šå¸¸ä½¿ç”¨æ—©æœŸæ¨¡æ€èåˆ&#x2F;åˆ†è£‚æ³•è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡å…±äº«éª¨å¹²å’Œçº¿æ€§å±‚å¤„ç†é¢„æµ‹ä¸¤ç§æ¨¡æ€ã€‚</li>
<li>æ—©æœŸæ¨¡æ€èåˆ&#x2F;åˆ†è£‚æ–¹æ³•å¿½ç•¥äº†ç‰¹å¾ç»„åˆæ€§ï¼Œé™åˆ¶äº†è·¨æ¨¡æ€è¿ç§»èƒ½åŠ›ã€‚</li>
<li>ç ”ç©¶è€…æå‡ºåŸºäºåæœŸèåˆå’Œåˆ†è£‚çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡åˆ†è£‚è¿‡ç¨‹è·å–è¯­éŸ³ç”Ÿæˆçš„é«˜ã€ä½å±‚æ¬¡ç‰¹å¾ã€‚</li>
<li>SmolTolkæ¨¡å‹åœ¨è·¨æ¨¡æ€æ€§èƒ½ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä¸å¤§é‡è®¡ç®—è®­ç»ƒçš„å…ˆè¿›TSLMç›¸æ¯”å…·æœ‰ç›¸å½“çš„æ€§èƒ½ã€‚</li>
<li>SmolTolkæ¨¡å‹ç›¸å¯¹äºæ—©æœŸèåˆåˆ†è£‚åŸºçº¿æ˜¾ç¤ºå‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>è¡¨ç¤ºåˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æé«˜äº†æ¨¡å‹ä»è¯­éŸ³ä¸­æå–é«˜çº§è¯­ä¹‰ç‰¹å¾çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06211">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-024fd9b3f92a603c1a9d6214174af35d" align="middle">
<img src="https://picx.zhimg.com/v2-5cfe75bd13f2dde774204851e185c5cf" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Nexus-An-Omni-Perceptive-And-Interactive-Model-for-Language-Audio-And-Vision"><a href="#Nexus-An-Omni-Perceptive-And-Interactive-Model-for-Language-Audio-And-Vision" class="headerlink" title="Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio,   And Vision"></a>Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio,   And Vision</h2><p><strong>Authors:Che Liu, Yingji Zhang, Dong Zhang, Weijie Zhang, Chenggong Gong, Yu Lu, Shilin Zhou, Ziliang Gan, Ziao Wang, Haipang Wu, Ji Liu, AndrÃ© Freitas, Qifan Wang, Zenglin Xu, Rongjuncheng Zhang, Yong Dai</strong></p>
<p>This work proposes an industry-level omni-modal large language model (LLM) pipeline that integrates auditory, visual, and linguistic modalities to overcome challenges such as limited tri-modal datasets, high computational costs, and complex feature alignments. Our pipeline consists of three main components: First, a modular framework enabling flexible configuration of various encoder-LLM-decoder architectures. Second, a lightweight training strategy that pre-trains audio-language alignment on the state-of-the-art vision-language model Qwen2.5-VL, thus avoiding the costly pre-training of vision-specific modalities. Third, an audio synthesis pipeline that generates high-quality audio-text data from diverse real-world scenarios, supporting applications such as Automatic Speech Recognition and Speech-to-Speech chat. To this end, we introduce an industry-level omni-modal LLM, Nexus. Extensive experiments validate the efficacy of our pipeline, yielding the following key findings:(1) In the visual understanding task, Nexus exhibits superior performance compared with its backbone model - Qwen2.5-VL-7B, validating the efficiency of our training strategy. (2) Within the English Spoken Question-Answering task, the model achieves better accuracy than the same-period competitor (i.e, MiniCPM-o2.6-7B) in the LLaMA Q. benchmark. (3) In our real-world ASR testset, Nexus achieves outstanding performance, indicating its robustness in real scenarios. (4) In the Speech-to-Text Translation task, our model outperforms Qwen2-Audio-Instruct-7B. (5) In the Text-to-Speech task, based on pretrained vocoder (e.g., Fishspeech1.4 or CosyVoice2.0), Nexus is comparable to its backbone vocoder on Seed-TTS benchmark. (6) An in-depth analysis of tri-modal alignment reveals that incorporating the audio modality enhances representational alignment between vision and language. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è·¨è¡Œä¸šçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œè¯¥ç®¡é“èåˆäº†å¬è§‰ã€è§†è§‰å’Œè¯­è¨€å­¦æ¨¡æ€ï¼Œä»¥å…‹æœå¦‚æœ‰é™çš„ä¸‰æ¨¡æ€æ•°æ®é›†ã€é«˜è®¡ç®—æˆæœ¬å’Œå¤æ‚ç‰¹å¾å¯¹é½ç­‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç®¡é“ä¸»è¦ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼šé¦–å…ˆï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œèƒ½å¤Ÿçµæ´»é…ç½®å„ç§ç¼–ç å™¨-LLM-è§£ç å™¨æ¶æ„ã€‚å…¶æ¬¡ï¼Œä¸€ç§è½»é‡çº§çš„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡å¯¹æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹Qwen2.5-VLè¿›è¡ŒéŸ³é¢‘è¯­è¨€å¯¹é½çš„é¢„è®­ç»ƒï¼Œä»è€Œé¿å…äº†é’ˆå¯¹ç‰¹å®šè§†è§‰æ¨¡æ€çš„æ˜‚è´µé¢„è®­ç»ƒã€‚æœ€åï¼Œä¸€ä¸ªéŸ³é¢‘åˆæˆç®¡é“ï¼Œå…¶ä»å„ç§çœŸå®åœºæ™¯ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘æ–‡æœ¬æ•°æ®ï¼Œæ”¯æŒå¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆ°è¯­éŸ³èŠå¤©ç­‰åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¡Œä¸šçº§åˆ«çš„å¤šæ¨¡æ€LLMï¼ŒNexusã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬ç®¡é“çš„æœ‰æ•ˆæ€§ï¼Œå¹¶äº§ç”Ÿäº†ä»¥ä¸‹å…³é”®å‘ç°ï¼šï¼ˆ1ï¼‰åœ¨è§†è§‰ç†è§£ä»»åŠ¡ä¸­ï¼ŒNexusç›¸è¾ƒäºå…¶éª¨å¹²æ¨¡å‹Qwen2.5-VL-7Bå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„è®­ç»ƒç­–ç•¥çš„æ•ˆç‡ã€‚ï¼ˆ2ï¼‰åœ¨è‹±è¯­å£è¯­é—®ç­”ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨LLaMA Q. benchmarkä¸Šå®ç°äº†æ¯”åŒæœŸç«äº‰å¯¹æ‰‹ï¼ˆå³MiniCPM-o2.6-7Bï¼‰æ›´é«˜çš„å‡†ç¡®æ€§ã€‚ï¼ˆ3ï¼‰åœ¨æˆ‘ä»¬çš„çœŸå®ä¸–ç•ŒASRæµ‹è¯•é›†ä¸­ï¼ŒNexuså®ç°äº†å“è¶Šæ€§èƒ½ï¼Œè¡¨æ˜å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„ç¨³å¥æ€§ã€‚ï¼ˆ4ï¼‰åœ¨è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¶…è¶Šäº†Qwen2-Audio-Instruct-7Bã€‚ï¼ˆ5ï¼‰åœ¨æ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ä¸­ï¼ŒåŸºäºé¢„è®­ç»ƒçš„vocoderï¼ˆä¾‹å¦‚Fishspeech1.4æˆ–CosyVoice2.0ï¼‰ï¼ŒNexusåœ¨Seed-TTS benchmarkä¸Šçš„è¡¨ç°ä¸å…¶éª¨å¹²vocoderç›¸å½“ã€‚ï¼ˆ6ï¼‰å¯¹ä¸‰æ¨¡æ€å¯¹é½çš„æ·±å…¥åˆ†æè¡¨æ˜ï¼ŒåŠ å…¥éŸ³é¢‘æ¨¡æ€å¢å¼ºäº†è§†è§‰å’Œè¯­è¨€ä¹‹é—´çš„ä»£è¡¨æ€§å¯¹é½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.01879v4">PDF</a> Project: <a target="_blank" rel="noopener" href="https://github.com/HiThink-Research/NEXUS-O">https://github.com/HiThink-Research/NEXUS-O</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è·¨è¡Œä¸šçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œè¯¥ç®¡é“èåˆäº†å¬è§‰ã€è§†è§‰å’Œè¯­è¨€å­¦ä¸‰å¤§æ¨¡æ€ï¼Œä»¥å…‹æœå¦‚æœ‰é™çš„ä¸‰æ¨¡æ€æ•°æ®é›†ã€é«˜æ˜‚çš„è®¡ç®—æˆæœ¬å’Œå¤æ‚çš„ç‰¹å¾å¯¹é½ç­‰æŒ‘æˆ˜ã€‚è¯¥ç®¡é“åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šä¸€æ˜¯æ¨¡å—åŒ–æ¡†æ¶ï¼Œå¯çµæ´»é…ç½®å„ç§ç¼–ç å™¨-LLM-è§£ç å™¨æ¶æ„ï¼›äºŒæ˜¯è½»é‡çº§è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é¢„è®­ç»ƒéŸ³é¢‘è¯­è¨€å¯¹é½åœ¨å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹Qwen2.5-VLä¸Šï¼Œé¿å…äº†æ˜‚è´µçš„è§†è§‰ç‰¹å®šæ¨¡æ€çš„é¢„è®­ç»ƒï¼›ä¸‰æ˜¯éŸ³é¢‘åˆæˆç®¡é“ï¼Œä»å„ç§çœŸå®åœºæ™¯ä¸­ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘æ–‡æœ¬æ•°æ®ï¼Œæ”¯æŒå¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆ°è¯­éŸ³èŠå¤©ç­‰åº”ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNexusæ¨¡å‹åœ¨è§†è§‰ç†è§£ä»»åŠ¡ã€è‹±è¯­é—®ç­”ä»»åŠ¡ã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³ç¿»è¯‘å’Œæ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ·±åº¦åˆ†ææ˜¾ç¤ºï¼ŒåŠ å…¥éŸ³é¢‘æ¨¡æ€å¢å¼ºäº†è§†è§‰å’Œè¯­è¨€çš„ä»£è¡¨æ€§å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œé›†æˆäº†å¬è§‰ã€è§†è§‰å’Œè¯­è¨€å­¦ä¸‰å¤§æ¨¡æ€ï¼Œä»¥åº”å¯¹æŒ‘æˆ˜å¦‚æœ‰é™æ•°æ®é›†ã€é«˜è®¡ç®—æˆæœ¬å’Œå¤æ‚ç‰¹å¾å¯¹é½ã€‚</li>
<li>ç®¡é“åŒ…å«æ¨¡å—åŒ–æ¡†æ¶ã€è½»é‡çº§è®­ç»ƒç­–ç•¥å’ŒéŸ³é¢‘åˆæˆç®¡é“ä¸‰ä¸ªä¸»è¦ç»„ä»¶ã€‚</li>
<li>Nexusæ¨¡å‹åœ¨è§†è§‰ç†è§£ä»»åŠ¡ã€è‹±è¯­é—®ç­”ä»»åŠ¡ã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³ç¿»è¯‘å’Œæ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>é€šè¿‡é¢„è®­ç»ƒéŸ³é¢‘è¯­è¨€å¯¹é½åœ¨å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ä¸Šï¼Œé¿å…äº†æ˜‚è´µçš„è§†è§‰ç‰¹å®šæ¨¡æ€çš„é¢„è®­ç»ƒã€‚</li>
<li>æ·±åº¦åˆ†ææ˜¾ç¤ºï¼ŒåŠ å…¥éŸ³é¢‘æ¨¡æ€å¢å¼ºäº†è§†è§‰å’Œè¯­è¨€çš„ä»£è¡¨æ€§å¯¹é½ã€‚</li>
<li>è¯¥æ¨¡å‹å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆ°è¯­éŸ³èŠå¤©ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.01879">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-78125e7a9aa3a72152b27a5ac462bba8" align="middle">
<img src="https://picx.zhimg.com/v2-88f1d29a330302a2f6c76f3fc5c0107f" align="middle">
<img src="https://picx.zhimg.com/v2-6acec14c2780b4d7beced11d34f417e8" align="middle">
<img src="https://picx.zhimg.com/v2-7476f59f20929343b9491403e165d160" align="middle">
<img src="https://picx.zhimg.com/v2-6da19ab65f5bc992fa31c8fb735286ba" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Efficient-Long-duration-Talking-Video-Synthesis-with-Linear-Diffusion-Transformer-under-Multimodal-Guidance"><a href="#Efficient-Long-duration-Talking-Video-Synthesis-with-Linear-Diffusion-Transformer-under-Multimodal-Guidance" class="headerlink" title="Efficient Long-duration Talking Video Synthesis with Linear Diffusion   Transformer under Multimodal Guidance"></a>Efficient Long-duration Talking Video Synthesis with Linear Diffusion   Transformer under Multimodal Guidance</h2><p><strong>Authors:Haojie Zhang, Zhihao Liang, Ruibo Fu, Bingyan Liu, Zhengqi Wen, Xuefei Liu, Jianhua Tao, Yaling Liang</strong></p>
<p>Long-duration talking video synthesis faces enduring challenges in achieving high video quality, portrait and temporal consistency, and computational efficiency. As video length increases, issues such as visual degradation, identity inconsistency, temporal incoherence, and error accumulation become increasingly problematic, severely affecting the realism and reliability of the results. To address these challenges, we present LetsTalk, a diffusion transformer framework equipped with multimodal guidance and a novel memory bank mechanism, explicitly maintaining contextual continuity and enabling robust, high-quality, and efficient generation of long-duration talking videos. In particular, LetsTalk introduces a noise-regularized memory bank to alleviate error accumulation and sampling artifacts during extended video generation. To further improve efficiency and spatiotemporal consistency, LetsTalk employs a deep compression autoencoder and a spatiotemporal-aware transformer with linear attention for effective multimodal fusion. We systematically analyze three fusion schemes and show that combining deep (Symbiotic Fusion) for portrait features and shallow (Direct Fusion) for audio achieves superior visual realism and precise speech-driven motion, while preserving diversity of movements. Extensive experiments demonstrate that LetsTalk establishes new state-of-the-art in generation quality, producing temporally coherent and realistic talking videos with enhanced diversity and liveliness, and maintains remarkable efficiency with 8x fewer parameters than previous approaches. </p>
<blockquote>
<p>é•¿æ—¶é—´å¯¹è¯è§†é¢‘åˆæˆé¢ä¸´ç€å®ç°é«˜è´¨é‡è§†é¢‘ã€è‚–åƒå’Œæ—¶åºä¸€è‡´æ€§ä»¥åŠè®¡ç®—æ•ˆç‡çš„æŒä¹…æŒ‘æˆ˜ã€‚éšç€è§†é¢‘é•¿åº¦çš„å¢åŠ ï¼Œè§†è§‰é€€åŒ–ã€èº«ä»½ä¸ä¸€è‡´ã€æ—¶åºä¸ä¸€è‡´å’Œè¯¯å·®ç´¯ç§¯ç­‰é—®é¢˜å˜å¾—è¶Šæ¥è¶Šä¸¥é‡ï¼Œä¸¥é‡å½±å“äº†ç»“æœçš„é€¼çœŸåº¦å’Œå¯é æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†LetsTalkï¼Œè¿™æ˜¯ä¸€ä¸ªé…å¤‡å¤šæ¨¡å¼æŒ‡å¯¼å’Œæ–°å‹è®°å¿†åº“æœºåˆ¶çš„æ‰©æ•£å˜æ¢æ¡†æ¶ï¼Œèƒ½å¤Ÿæ˜ç¡®ä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå¹¶å®ç°ç¨³å¥ã€é«˜è´¨é‡å’Œé«˜æ•ˆçš„é•¿æ—¶é•¿å¯¹è¯è§†é¢‘ç”Ÿæˆã€‚ç‰¹åˆ«åœ°ï¼ŒLetsTalkå¼•å…¥äº†ä¸€ä¸ªå™ªå£°æ­£åˆ™åŒ–è®°å¿†åº“ï¼Œä»¥å‡è½»æ‰©å±•è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¯¯å·®ç´¯ç§¯å’Œé‡‡æ ·ä¼ªå½±ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ•ˆç‡å’Œæ—¶ç©ºä¸€è‡´æ€§ï¼ŒLetsTalké‡‡ç”¨æ·±åº¦å‹ç¼©è‡ªç¼–ç å™¨å’Œå…·æœ‰çº¿æ€§æ³¨æ„åŠ›çš„æ—¶ç©ºæ„ŸçŸ¥å˜æ¢å™¨ï¼Œä»¥å®ç°æœ‰æ•ˆçš„å¤šæ¨¡å¼èåˆã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†ä¸‰ç§èåˆæ–¹æ¡ˆï¼Œå¹¶è¡¨æ˜æ·±åº¦ï¼ˆå…±ç”Ÿèåˆï¼‰ç”¨äºè‚–åƒç‰¹å¾å’Œæµ…åº¦ï¼ˆç›´æ¥èåˆï¼‰ç”¨äºéŸ³é¢‘çš„ç»“åˆå®ç°äº†å“è¶Šçš„è§†è§‰é€¼çœŸåº¦å’Œç²¾ç¡®çš„è¯­éŸ³é©±åŠ¨è¿åŠ¨ï¼ŒåŒæ—¶ä¿æŒäº†è¿åŠ¨çš„å¤šæ ·æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLetsTalkåœ¨ç”Ÿæˆè´¨é‡æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œç”Ÿæˆäº†æ—¶åºè¿è´¯å’Œé€¼çœŸçš„å¯¹è¯è§†é¢‘ï¼Œå¢å¼ºäº†å¤šæ ·æ€§å’Œç”ŸåŠ¨æ€§ï¼Œå¹¶åœ¨å‚æ•°æ–¹é¢ä¿æŒäº†æ˜¾è‘—çš„æ•ˆç‡ï¼Œåªæœ‰ä»¥å‰æ–¹æ³•çš„å…«åˆ†ä¹‹ä¸€å‚æ•°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16748v4">PDF</a> 10 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>è¿™æ˜¯ä¸€é¡¹å…³äºé•¿æœŸå¯¹è¯è§†é¢‘åˆæˆçš„æŒ‘æˆ˜çš„ç ”ç©¶ã€‚ç ”ç©¶ä¸­æå‡ºäº†LetsTalkæ¨¡å‹ï¼Œé‡‡ç”¨æ‰©æ•£è½¬æ¢å™¨æ¡†æ¶å’Œå¤šæ¨¡æ€æŒ‡å¯¼ï¼Œé€šè¿‡æ–°å‹å†…å­˜åº“æœºåˆ¶æ˜¾å¼ç»´æŒä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå®ç°ç¨³å¥ã€é«˜è´¨é‡ã€é«˜æ•ˆçš„é•¿æœŸå¯¹è¯è§†é¢‘ç”Ÿæˆã€‚è¯¥æ¨¡å‹è§£å†³äº†è§†è§‰é€€åŒ–ã€èº«ä»½ä¸ä¸€è‡´ã€æ—¶é—´ä¸ä¸€è‡´å’Œè¯¯å·®ç´¯ç§¯ç­‰é—®é¢˜ï¼Œæé«˜äº†ç”Ÿæˆè§†é¢‘çš„çœŸå®æ€§å’Œå¯é æ€§ã€‚é€šè¿‡æ·±åº¦å‹ç¼©è‡ªç¼–ç å™¨å’Œæ—¶ç©ºæ„ŸçŸ¥è½¬æ¢å™¨ï¼Œå®ç°äº†é«˜æ•ˆå’Œå¤šæ¨¡æ€èåˆã€‚ç ”ç©¶è¡¨æ˜ï¼Œèåˆæ–¹æ¡ˆç»“åˆæ·±èåˆç”¨äºè‚–åƒç‰¹å¾å’Œæµ…èåˆç”¨äºéŸ³é¢‘ï¼Œå¯è·å¾—æœ€ä½³çš„è§†è§‰çœŸå®æ„Ÿå’Œç²¾ç¡®çš„è¯­éŸ³é©±åŠ¨è¿åŠ¨ï¼ŒåŒæ—¶ä¿æŒè¿åŠ¨çš„å¤šæ ·æ€§ã€‚LetTalkåœ¨ç”Ÿæˆè´¨é‡ä¸Šè¾¾åˆ°æ–°çš„æ°´å¹³ï¼Œç”Ÿæˆäº†æ—¶é—´è¿è´¯å’Œç°å®æ€§å¼ºçš„å¯¹è¯è§†é¢‘ï¼Œä¸”å…·å¤‡å“è¶Šçš„è¿ç®—æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é•¿æœŸå¯¹è¯è§†é¢‘åˆæˆé¢ä¸´é«˜è§†é¢‘è´¨é‡ã€è‚–åƒå’Œæ—¶é—´çš„è¿è´¯æ€§ï¼Œä»¥åŠè®¡ç®—æ•ˆç‡çš„æŒ‘æˆ˜ã€‚</li>
<li>LetTalkæ¨¡å‹é‡‡ç”¨æ‰©æ•£è½¬æ¢å™¨æ¡†æ¶å’Œå¤šæ¨¡æ€æŒ‡å¯¼æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>LetTalkä½¿ç”¨å™ªå£°æ­£åˆ™åŒ–å†…å­˜åº“å‡è½»é”™è¯¯ç´¯ç§¯å’Œé‡‡æ ·æ—¶çš„ä¼ªå½±é—®é¢˜ã€‚</li>
<li>é€šè¿‡æ·±åº¦å‹ç¼©è‡ªç¼–ç å™¨å’Œæ—¶ç©ºæ„ŸçŸ¥è½¬æ¢å™¨æé«˜äº†æ•ˆç‡å’Œæ—¶ç©ºè¿è´¯æ€§ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆæ·±èåˆç”¨äºè‚–åƒç‰¹å¾å’Œæµ…èåˆç”¨äºéŸ³é¢‘å¯è·å¾—æœ€ä½³æ•ˆæœã€‚</li>
<li>LetTalkæ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡ä¸Šè¾¾åˆ°æ–°çš„æ°´å¹³ï¼Œç”Ÿæˆäº†æ›´è¿è´¯ã€çœŸå®çš„å¯¹è¯è§†é¢‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16748">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a093f785b24fbc41e2fd4b92a69df74e" align="middle">
<img src="https://picx.zhimg.com/v2-1d1da715a10edbe23b1d08fff46b814e" align="middle">
<img src="https://picx.zhimg.com/v2-b83a97512c6120fd09ae516f07aead4b" align="middle">
<img src="https://picx.zhimg.com/v2-afa26eec912757fa41f1692f7a9da2e7" align="middle">
<img src="https://picx.zhimg.com/v2-30ac3b5962f32623eb45e4ff2f40f17a" align="middle">
<img src="https://picx.zhimg.com/v2-24758ed84dfef215f6a1c603c127b63e" align="middle">
<img src="https://picx.zhimg.com/v2-8cf821eb2878698ad5af1011535d8e9a" align="middle">
<img src="https://picx.zhimg.com/v2-aad7a47730924b7cbc97ce809e10725d" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-96989003d47bf913ee9c9702c77c8b46" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  Is Artificial Intelligence Generated Image Detection a Solved Problem?
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-8d2269479cf4f942a6adb5559ca0daff" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  CARE Contrastive Alignment for ADL Recognition from Event-Triggered   Sensor Streams
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
