<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  PANER A Paraphrase-Augmented Framework for Low-Resource Named Entity   Recognition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-186bc6cba6c491a733771d815382d2a0~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070193&auth_key=1761070193-0-0-b0287077545a57b55ca7d1bd82b74b5e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-22
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    53 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-22-æ›´æ–°"><a href="#2025-10-22-æ›´æ–°" class="headerlink" title="2025-10-22 æ›´æ–°"></a>2025-10-22 æ›´æ–°</h1><h2 id="PANER-A-Paraphrase-Augmented-Framework-for-Low-Resource-Named-Entity-Recognition"><a href="#PANER-A-Paraphrase-Augmented-Framework-for-Low-Resource-Named-Entity-Recognition" class="headerlink" title="PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity   Recognition"></a>PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity   Recognition</h2><p><strong>Authors:Nanda Kumar Rengarajan, Jun Yan, Chun Wang</strong></p>
<p>Named Entity Recognition (NER) is a critical task that requires substantial annotated data, making it challenging in low-resource scenarios where label acquisition is expensive. While zero-shot and instruction-tuned approaches have made progress, they often fail to generalize to domain-specific entities and do not effectively utilize limited available data. We present a lightweight few-shot NER framework that addresses these challenges through two key innovations: (1) a new instruction tuning template with a simplified output format that combines principles from prior IT approaches to leverage the large context window of recent state-of-the-art LLMs; (2) introducing a strategic data augmentation technique that preserves entity information while paraphrasing the surrounding context, thereby expanding our training data without compromising semantic relationships. Experiments on benchmark datasets show that our method achieves performance comparable to state-of-the-art models on few-shot and zero-shot tasks, with our few-shot approach attaining an average F1 score of 80.1 on the CrossNER datasets. Models trained with our paraphrasing approach show consistent improvements in F1 scores of up to 17 points over baseline versions, offering a promising solution for groups with limited NER training data and compute power. </p>
<blockquote>
<p>å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ˜¯ä¸€é¡¹éœ€è¦å¤§æ‰¹é‡æ ‡æ³¨æ•°æ®çš„ä»»åŠ¡ï¼Œè¿™åœ¨èµ„æºåŒ®ä¹çš„åœºæ™¯ä¸‹é¢‡å…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè·å–æ ‡ç­¾çš„æˆæœ¬é«˜æ˜‚ã€‚å°½ç®¡é›¶æ ·æœ¬å’ŒæŒ‡ä»¤å¾®è°ƒçš„æ–¹æ³•å·²ç»å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†å®ƒä»¬é€šå¸¸éš¾ä»¥æ¨å¹¿åˆ°ç‰¹å®šé¢†åŸŸçš„å®ä½“ï¼Œå¹¶ä¸”ä¸èƒ½æœ‰æ•ˆåœ°åˆ©ç”¨æœ‰é™çš„å¯ç”¨æ•°æ®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„å°‘æ ·æœ¬NERæ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªæ–°çš„æŒ‡ä»¤å¾®è°ƒæ¨¡æ¿ï¼Œé‡‡ç”¨ç®€åŒ–çš„è¾“å‡ºæ ¼å¼ï¼Œç»“åˆäº†å…ˆå‰çš„ITåŸåˆ™ï¼Œä»¥åˆ©ç”¨æœ€æ–°çš„å…ˆè¿›LLMçš„å¤§è¯­å¢ƒçª—å£ï¼›ï¼ˆ2ï¼‰å¼•å…¥äº†ä¸€ç§æˆ˜ç•¥æ€§çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œåœ¨æ”¹è¿°å‘¨å›´è¯­å¢ƒçš„åŒæ—¶ä¿ç•™å®ä½“ä¿¡æ¯ï¼Œä»è€Œæ‰©å¤§äº†æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ï¼Œä¸”ä¸æŸå®³è¯­ä¹‰å…³ç³»ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æ¨¡å‹ç›¸å½“ï¼Œæˆ‘ä»¬çš„å°‘æ ·æœ¬æ–¹æ³•åœ¨CrossNERæ•°æ®é›†ä¸Šçš„å¹³å‡F1åˆ†æ•°ä¸º80.1ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ”¹è¿°æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šè¾ƒåŸºçº¿ç‰ˆæœ¬æœ‰æŒç»­ä¸”æ˜¾è‘—çš„æ”¹è¿›ï¼Œæ”¹è¿›å¹…åº¦é«˜è¾¾17ä¸ªç‚¹ï¼Œä¸ºæ‹¥æœ‰æœ‰é™çš„NERè®­ç»ƒæ•°æ®å’Œè®¡ç®—èƒ½åŠ›çš„å›¢é˜Ÿæä¾›äº†æœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17720v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§è½»é‡çº§çš„å°‘æ ·æœ¬å‘½åå®ä½“è¯†åˆ«æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹è§£å†³ä½èµ„æºåœºæ™¯ä¸‹çš„æŒ‘æˆ˜ï¼šä¸€æ˜¯é‡‡ç”¨æ–°çš„æŒ‡ä»¤è°ƒæ•´æ¨¡æ¿ï¼Œç®€åŒ–è¾“å‡ºæ ¼å¼ï¼Œç»“åˆå‰æœŸITæ–¹æ³•çš„åŸç†ï¼Œåˆ©ç”¨æœ€æ–°å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£ï¼›äºŒæ˜¯å¼•å…¥æˆ˜ç•¥æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œåœ¨æ”¹å†™ä¸Šä¸‹æ–‡çš„åŒæ—¶ä¿ç•™å®ä½“ä¿¡æ¯ï¼Œä»è€Œæ‰©å±•è®­ç»ƒæ•°æ®è€Œä¸æŸå®³è¯­ä¹‰å…³ç³»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æ¨¡å‹ç›¸å½“ï¼Œå°‘æ ·æœ¬æ–¹æ³•åœ¨CrossNERæ•°æ®é›†ä¸Šçš„å¹³å‡F1åˆ†æ•°è¾¾åˆ°80.1ã€‚ä½¿ç”¨æ­¤æ”¹å†™æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šè¾ƒåŸºçº¿ç‰ˆæœ¬æœ‰æ˜¾è‘—æ”¹å–„ï¼Œæœ€é«˜å¯è¾¾17åˆ†ï¼Œä¸ºè§£å†³å‘½åå®ä½“è¯†åˆ«è®­ç»ƒæ•°æ®æœ‰é™å’Œè®¡ç®—èƒ½åŠ›æœ‰é™çš„å›¢é˜Ÿæä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰åœ¨ä½èµ„æºåœºæ™¯ä¸‹å…·æœ‰æŒ‘æˆ˜ï¼Œå› ä¸ºéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å°‘æ ·æœ¬NERæ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šæŒ‡ä»¤è°ƒæ•´æ¨¡æ¿å’Œæ•°æ®å¢å¼ºæŠ€æœ¯ã€‚</li>
<li>æŒ‡ä»¤è°ƒæ•´æ¨¡æ¿ç»“åˆäº†ç®€åŒ–è¾“å‡ºæ ¼å¼å’Œæœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£åŸç†ã€‚</li>
<li>æ•°æ®å¢å¼ºæŠ€æœ¯åœ¨ä¸æŸå®³è¯­ä¹‰å…³ç³»çš„å‰æä¸‹æ‰©å±•è®­ç»ƒæ•°æ®ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æ¨¡å‹ç›¸å½“ã€‚</li>
<li>åœ¨CrossNERæ•°æ®é›†ä¸Šï¼Œå°‘æ ·æœ¬æ–¹æ³•çš„å¹³å‡F1åˆ†æ•°è¾¾åˆ°80.1ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cc6bbc29979f2f477f410b57bae66946~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070187&auth_key=1761070187-0-0-27dc49fe4d8622899af0b578b7fb906c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-186bc6cba6c491a733771d815382d2a0~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070193&auth_key=1761070193-0-0-b0287077545a57b55ca7d1bd82b74b5e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d98952cbb9841c4d567bee1f1abcea12~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070200&auth_key=1761070200-0-0-1a9b62ea4e1539a249d6bbaa7227087b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1890e0dbb30892ef97c724c28bc6d7e3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070206&auth_key=1761070206-0-0-7cd3bd2b41575e870e3eaf4b3d9bab64&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ddb0f8eacbaed6cdbeec22d2987167d9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070213&auth_key=1761070213-0-0-ba8f1d963d6bc7c033a42cf655fc75ae&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1228736c344e0ba40c1f5bcf95f5cf26~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070219&auth_key=1761070219-0-0-e1c963977a83967cb42f50c2475263c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Qomhra-A-Bilingual-Irish-English-Large-Language-Model"><a href="#Qomhra-A-Bilingual-Irish-English-Large-Language-Model" class="headerlink" title="Qomhra: A Bilingual Irish-English Large Language Model"></a>Qomhra: A Bilingual Irish-English Large Language Model</h2><p><strong>Authors:Joseph McInerney</strong></p>
<p>This paper introduces Qomhr&#39;a, a bilingual Irish-English large language model (LLM), developed under low-resource constraints presenting a complete pipeline spanning bilingual continued pre-training, instruction tuning, and alignment from human preferences. Newly accessible Irish corpora and English text are mixed and curated to improve Irish performance while preserving English ability. 6 closed-weight LLMs are judged for their Irish text generation by a native speaker, a learner and other LLMs. Googleâ€™s Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise instruction tuning and human preference datasets. Two datasets are contributed leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning dataset and a 1K human preference dataset, generating accepted and rejected responses that show near perfect alignment with a native Irish speaker. Qomhr&#39;a is comprehensively evaluated across benchmarks testing translation, gender understanding, topic identification and world knowledge with gains of up to 29% in Irish and 44% in English. Qomhr&#39;a also undergoes instruction tuning and demonstrates clear progress in instruction following, crucial for chatbot functionality. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†Qomhrâ€™aï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹å¼€å‘çš„åŒè¯­çˆ±å°”å…°è¯­-è‹±è¯­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚å®ƒå‘ˆç°äº†ä¸€ä¸ªå®Œæ•´çš„æµç¨‹ï¼ŒåŒ…æ‹¬åŒè¯­æŒç»­é¢„è®­ç»ƒã€æŒ‡ä»¤è°ƒæ•´å’Œäººç±»åå¥½çš„å¯¹é½ã€‚æ–°è·å¾—çš„çˆ±å°”å…°è¯­æ–™åº“å’Œè‹±è¯­æ–‡æœ¬è¢«æ··åˆå’Œç­›é€‰ï¼Œä»¥æé«˜çˆ±å°”å…°è¯­æ€§èƒ½çš„åŒæ—¶ä¿æŒè‹±è¯­èƒ½åŠ›ã€‚æœ‰6ä¸ªå°é—­æƒé‡çš„LLMè¢«é‚€è¯·å¯¹å®ƒä»¬çš„çˆ±å°”å…°æ–‡æœ¬ç”Ÿæˆè¿›è¡Œè¯„ä¼°ï¼Œè¯„ä¼°äººå‘˜åŒ…æ‹¬æ¯è¯­è€…ã€å­¦ä¹ è€…å’Œå…¶ä»–LLMã€‚è°·æ­Œçš„Gemini-2.5-Proè¢«è¯„ä¸ºæœ€ä½³æ¨¡å‹ï¼Œéšåè¢«ç”¨æ¥åˆæˆæŒ‡ä»¤è°ƒæ•´å’Œäººç±»åå¥½æ•°æ®é›†ã€‚åˆ©ç”¨Gemini-2.5-Proè´¡çŒ®äº†ä¸¤ä¸ªæ•°æ®é›†ï¼šä¸€ä¸ªåŒ…å«çˆ±å°”å…°è¯­å’Œè‹±è¯­å¹³è¡ŒæŒ‡ä»¤çš„3ä¸‡å¥è®­ç»ƒæ•°æ®é›†å’Œä¸€ä¸ªåŒ…å«1åƒå¥çš„äººç±»åå¥½æ•°æ®é›†ã€‚ç”Ÿæˆæ¥å—çš„å›åº”ä¸æ‹’ç»å›åº”æ˜¾ç¤ºå‡ ä¹å®Œç¾åœ°ä¸æ¯è¯­è€…ä¸€è‡´ã€‚Qomhrâ€™aåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬ç¿»è¯‘ã€æ€§åˆ«ç†è§£ã€ä¸»é¢˜è¯†åˆ«å’Œä¸–ç•ŒçŸ¥è¯†ç­‰ï¼Œåœ¨çˆ±å°”å…°è¯­æ–¹é¢æé«˜äº†é«˜è¾¾29%ï¼Œåœ¨è‹±è¯­æ–¹é¢æé«˜äº†é«˜è¾¾44%ã€‚æ­¤å¤–ï¼ŒQomhrâ€™aè¿˜ç»å†äº†æŒ‡ä»¤è°ƒæ•´é˜¶æ®µï¼Œå¹¶åœ¨æ‰§è¡ŒæŒ‡ä»¤æ–¹é¢æ˜¾ç¤ºå‡ºæ˜æ˜¾çš„è¿›æ­¥ï¼Œè¿™å¯¹äºèŠå¤©æœºå™¨äººåŠŸèƒ½è‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17652v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†ä¸€ä¸ªåä¸ºQomhrâ€™açš„è·¨åŒè¯­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ä½èµ„æºæ¡ä»¶ä¸‹å¼€å‘ï¼ŒåŒ…æ‹¬åŒè¯­æŒç»­é¢„è®­ç»ƒã€æŒ‡ä»¤è°ƒä¼˜å’ŒåŸºäºäººç±»åå¥½çš„å¯¹é½ç­‰å®Œæ•´æµç¨‹ã€‚é€šè¿‡æ··åˆå’Œç²¾é€‰æ–°è¿‘å¯è®¿é—®çš„çˆ±å°”å…°è¯­æ–™åº“å’Œè‹±æ–‡æ–‡æœ¬ï¼Œæé«˜äº†çˆ±å°”å…°è¯­çš„æ€§èƒ½åŒæ—¶ä¿ç•™äº†è‹±æ–‡èƒ½åŠ›ã€‚ç»è¿‡å¯¹å…­ä¸ªå°é—­æƒé‡LLMçš„è¯„ä¼°ï¼ŒGoogleçš„Gemini-2.5-Proåœ¨çˆ±å°”å…°æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°æœ€ä½³ã€‚åˆ©ç”¨Gemini-2.5-ProåˆæˆæŒ‡ä»¤è°ƒä¼˜å’Œäººç±»åå¥½æ•°æ®é›†ï¼Œè´¡çŒ®äº†ä¸¤ä¸ªæ•°æ®é›†ï¼šä¸€ä¸ªåŒ…å«çˆ±å°”å…°è¯­å’Œè‹±è¯­çš„å¹³è¡ŒæŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†å’Œä¸€ä¸ªäººç±»åå¥½æ•°æ®é›†ã€‚Qomhrâ€™aç»è¿‡å…¨é¢è¯„ä¼°ï¼Œåœ¨ç¿»è¯‘ã€æ€§åˆ«ç†è§£ã€ä¸»é¢˜è¯†åˆ«å’Œä¸–ç•ŒçŸ¥è¯†ç­‰æ–¹é¢æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨çˆ±å°”å…°è¯­çš„æŒ‡ä»¤éµå¾ªæ–¹é¢å–å¾—äº†æ˜æ˜¾è¿›å±•ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„åŒè¯­è¯­è¨€æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Qomhrâ€™aæ˜¯ä¸€ä¸ªåŒè¯­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ”¯æŒçˆ±å°”å…°è¯­å’Œè‹±è¯­ã€‚</li>
<li>æ¨¡å‹åœ¨ä½èµ„æºæ¡ä»¶ä¸‹å¼€å‘ï¼Œå±•ç¤ºäº†ä¸€ä¸ªå®Œæ•´çš„ä»é¢„è®­ç»ƒåˆ°æŒ‡ä»¤è°ƒä¼˜çš„ç®¡é“ã€‚</li>
<li>åˆ©ç”¨æ–°çˆ±å°”å…°è¯­æ–™åº“å’Œè‹±è¯­æ–‡æœ¬ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>Googleçš„Gemini-2.5-Proè¢«é€‰ä¸ºæœ€ä½³çš„æ¨¡å‹ä¹‹ä¸€è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜å’Œæ•°æ®é›†åˆæˆã€‚</li>
<li>åˆæˆä¸¤ä¸ªæ•°æ®é›†ï¼šä¸€ä¸ªåŒ…å«çˆ±å°”å…°è¯­å’Œè‹±è¯­çš„å¹³è¡ŒæŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†å’Œä¸€ä¸ªåŸºäºäººç±»åå¥½çš„æ•°æ®é›†ã€‚</li>
<li>Qomhrâ€™aåœ¨ç¿»è¯‘ã€æ€§åˆ«ç†è§£ã€ä¸»é¢˜è¯†åˆ«å’Œä¸–ç•ŒçŸ¥è¯†ç­‰æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17652">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8a06c30372337de52b8e1bac72416a28~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070227&auth_key=1761070227-0-0-6c3edd77138a49dee1149e0ef1b74333&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a1096c60fe296af303aa93c67ab75b72~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070234&auth_key=1761070234-0-0-1aa4dee5a007cb61d12cae04af7d9e7e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-55047ac0ad7f3c2d521cff2cbce06262~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070240&auth_key=1761070240-0-0-a0748857987f88a27cf99f2900137583&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SimBench-Benchmarking-the-Ability-of-Large-Language-Models-to-Simulate-Human-Behaviors"><a href="#SimBench-Benchmarking-the-Ability-of-Large-Language-Models-to-Simulate-Human-Behaviors" class="headerlink" title="SimBench: Benchmarking the Ability of Large Language Models to Simulate   Human Behaviors"></a>SimBench: Benchmarking the Ability of Large Language Models to Simulate   Human Behaviors</h2><p><strong>Authors:Tiancheng Hu, Joachim Baumann, Lorenzo Lupo, Dirk Hovy, Nigel Collier, Paul RÃ¶ttger</strong></p>
<p>Large language model (LLM) simulations of human behavior have the potential to revolutionize the social and behavioral sciences, if and only if they faithfully reflect real human behaviors. Current evaluations are fragmented, based on bespoke tasks and metrics, creating a patchwork of incomparable results. To address this, we introduce SimBench, the first large-scale, standardized benchmark for a robust, reproducible science of LLM simulation. By unifying 20 diverse datasets covering tasks from moral decision-making to economic choice across a large global participant pool, SimBench provides the necessary foundation to ask fundamental questions about when, how, and why LLM simulations succeed or fail. We show that, while even the best LLMs today have limited simulation ability (score: 40.80&#x2F;100), performance scales log-linearly with model size. Simulation performance is not improved by increased inference-time compute. We demonstrate an alignment-simulation trade-off: instruction-tuning improves performance on low-entropy (consensus) questions but degrades it on high-entropy (diverse) ones. Models particularly struggle when simulating specific demographic groups. Finally, we demonstrate that simulation ability correlates most strongly with deep, knowledge-intensive reasoning (MMLU-Pro, r&#x3D;0.939). By making progress measurable, we aim to accelerate the development of more faithful LLM simulators. </p>
<blockquote>
<p>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äººç±»è¡Œä¸ºçš„æ¨¡æ‹Ÿå…·æœ‰é¢ è¦†ç¤¾ä¼šå’Œè¡Œä¸ºç§‘å­¦çš„æ½œåŠ›ï¼Œå‰ææ˜¯èƒ½çœŸå®åæ˜ äººç±»è¡Œä¸ºã€‚ç›®å‰çš„è¯„ä¼°æ˜¯åˆ†æ•£çš„ï¼ŒåŸºäºç‰¹å®šä»»åŠ¡å’ŒæŒ‡æ ‡ï¼Œå¯¼è‡´ç»“æœæ— æ³•æ¯”è¾ƒã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºSimBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•ï¼Œä¸ºLLMæ¨¡æ‹Ÿå»ºç«‹ä¸€ä¸ªç¨³å¥ã€å¯å¤åˆ¶çš„ç§‘å­¦ä½“ç³»ã€‚é€šè¿‡ç»Ÿä¸€æ¶µç›–ä»é“å¾·å†³ç­–åˆ°ç»æµé€‰æ‹©ç­‰ä»»åŠ¡çš„20ä¸ªä¸åŒæ•°æ®é›†ï¼Œå¹¶åœ¨å…¨çƒå¤§è§„æ¨¡å‚ä¸è€…ç¾¤ä½“ä¸­å¼€å±•æµ‹è¯•ï¼ŒSimBenchä¸ºå…³äºLLMæ¨¡æ‹Ÿä½•æ—¶ã€å¦‚ä½•ä»¥åŠä¸ºä½•æˆåŠŸæˆ–å¤±è´¥çš„æ ¹æœ¬é—®é¢˜æä¾›äº†å¿…è¦çš„åŸºç¡€ã€‚æˆ‘ä»¬å‘ç°ï¼Œå°½ç®¡ä»Šå¤©æœ€å…ˆè¿›çš„LLMæ¨¡æ‹Ÿèƒ½åŠ›ä»ç„¶æœ‰é™ï¼ˆå¾—åˆ†ï¼š40.80&#x2F;100ï¼‰ï¼Œä½†éšç€æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§ï¼Œæ€§èƒ½å‘ˆå¯¹æ•°çº¿æ€§å¢é•¿ã€‚å¢åŠ æ¨ç†æ—¶é—´çš„è®¡ç®—å¹¶ä¸ä¼šæé«˜æ¨¡æ‹Ÿæ€§èƒ½ã€‚æˆ‘ä»¬è¯æ˜äº†æŒ‡ä»¤è°ƒæ•´ä¸æ¨¡æ‹Ÿä¹‹é—´å­˜åœ¨æƒè¡¡ï¼šæŒ‡ä»¤è°ƒæ•´åœ¨ä½ç†µï¼ˆå…±è¯†ï¼‰é—®é¢˜ä¸Šçš„è¡¨ç°æœ‰æ‰€æé«˜ï¼Œä½†åœ¨é«˜ç†µï¼ˆå¤šæ ·æ€§ï¼‰é—®é¢˜ä¸Šçš„è¡¨ç°åˆ™ä¸‹é™ã€‚ç‰¹åˆ«æ˜¯åœ¨æ¨¡æ‹Ÿç‰¹å®šäººç¾¤æ—¶é¢ä¸´å›°éš¾ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜äº†æ¨¡æ‹Ÿèƒ½åŠ›ä¸æ·±åº¦çŸ¥è¯†å¯†é›†å‹æ¨ç†ä¹‹é—´å…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼ˆMMLU-Proç›¸å…³æ€§ç³»æ•°ä¸º0.939ï¼‰ã€‚é€šè¿‡åˆ¶å®šå¯è¡¡é‡çš„æ ‡å‡†ï¼Œæˆ‘ä»¬å¸Œæœ›åŠ é€Ÿæ›´çœŸå®LLMæ¨¡æ‹Ÿå™¨çš„å¼€å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17516v1">PDF</a> Project Website: <a target="_blank" rel="noopener" href="http://simbench.tiancheng.hu/">http://simbench.tiancheng.hu/</a> Data:   <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/pitehu/SimBench">https://huggingface.co/datasets/pitehu/SimBench</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äººç±»è¡Œä¸ºçš„æ¨¡æ‹Ÿå…·æœ‰é©æ–°ç¤¾ä¼šå’Œè¡Œä¸ºç§‘å­¦çš„æ½œåŠ›ï¼Œå‰ææ˜¯å…¶å¿…é¡»çœŸå®åæ˜ äººç±»è¡Œä¸ºã€‚å½“å‰è¯„ä¼°åŸºäºç‰¹å®šä»»åŠ¡å’ŒæŒ‡æ ‡ï¼Œç¼ºä¹ç»Ÿä¸€æ ‡å‡†ï¼Œå¯¼è‡´ç»“æœéš¾ä»¥æ¯”è¾ƒã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥SimBenchï¼Œå³é¦–ä¸ªå¤§è§„æ¨¡ã€æ ‡å‡†åŒ–åŸºå‡†æµ‹è¯•ï¼Œä»¥å»ºç«‹ç¨³å¥ã€å¯å¤åˆ¶çš„å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿç§‘å­¦ã€‚SimBenchç»Ÿä¸€äº†20ä¸ªæ¶µç›–ä»é“å¾·å†³ç­–åˆ°ç»æµé€‰æ‹©ç­‰ä»»åŠ¡çš„å¤šæ ·åŒ–æ•°æ®é›†ï¼Œå¹¶åœ¨å…¨çƒå¤§è§„æ¨¡å‚ä¸è€…æ± ä¸­å»ºç«‹åŸºç¡€ï¼Œä¸ºå…³äºå¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿä½•æ—¶ã€å¦‚ä½•ä»¥åŠä¸ºä½•æˆåŠŸæˆ–å¤±è´¥çš„æ ¹æœ¬é—®é¢˜æä¾›ç­”æ¡ˆã€‚ç ”ç©¶æ˜¾ç¤ºï¼Œç›®å‰æœ€å¥½çš„å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿèƒ½åŠ›ä¾ç„¶æœ‰é™ï¼ˆå¾—åˆ†ä¸º40.80&#x2F;100ï¼‰ï¼Œä½†æ€§èƒ½éšæ¨¡å‹è§„æ¨¡å‘ˆå¯¹æ•°çº¿æ€§å¢é•¿ã€‚æ¨¡æ‹Ÿæ€§èƒ½å¹¶ä¸ä¼šå› æ¨ç†æ—¶é—´çš„è®¡ç®—å¢åŠ è€Œæé«˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å±•ç¤ºäº†æŒ‡ä»¤è°ƒæ•´å¯¹ä½ç†µï¼ˆå…±è¯†ï¼‰é—®é¢˜æ€§èƒ½çš„æå‡ä»¥åŠå¯¹é«˜ç†µï¼ˆå¤šæ ·æ€§ï¼‰é—®é¢˜çš„æ¶åŒ–ä¹‹é—´çš„æƒè¡¡ã€‚ç‰¹åˆ«æ˜¯åœ¨æ¨¡æ‹Ÿç‰¹å®šäººç¾¤æ—¶ï¼Œæ¨¡å‹é¢ä¸´æŒ‘æˆ˜ã€‚æœ€åï¼Œç ”ç©¶æŒ‡å‡ºæ¨¡æ‹Ÿèƒ½åŠ›ä¸æ·±åº¦çŸ¥è¯†æ¨ç†ä¹‹é—´å­˜åœ¨å¼ºçƒˆç›¸å…³æ€§ï¼ˆMMLU-Proï¼Œr&#x3D;0.939ï¼‰ã€‚é€šè¿‡ä½¿è¿›æ­¥å¯è¡¡é‡ï¼Œæœ¬æ–‡æ—¨åœ¨åŠ é€Ÿæ›´çœŸå®çš„å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿå™¨çš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹äººç±»è¡Œä¸ºçš„æ¨¡æ‹Ÿå…·æœ‰å¯¹ç¤¾ä¼šå’Œè¡Œä¸ºç§‘å­¦çš„æ½œåœ¨é©å‘½æ€§å½±å“ã€‚</li>
<li>å½“å‰ç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†å¯¼è‡´LLMæ¨¡æ‹Ÿç»“æœéš¾ä»¥æ¯”è¾ƒã€‚</li>
<li>SimBenchä½œä¸ºé¦–ä¸ªå¤§è§„æ¨¡ã€æ ‡å‡†åŒ–çš„LLMæ¨¡æ‹ŸåŸºå‡†æµ‹è¯•æä¾›äº†å¿…è¦çš„ç»Ÿä¸€åŸºç¡€ã€‚</li>
<li>LLMæ¨¡æ‹Ÿæ€§èƒ½ä¸æ¨¡å‹è§„æ¨¡å¯¹æ•°çº¿æ€§ç›¸å…³ã€‚</li>
<li>æ¨¡æ‹Ÿæ€§èƒ½ä¸å› æ¨ç†æ—¶é—´è®¡ç®—å¢åŠ è€Œæé«˜ã€‚</li>
<li>å­˜åœ¨æŒ‡ä»¤è°ƒæ•´å¯¹æ¨¡æ‹Ÿæ€§èƒ½çš„å½±å“æƒè¡¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šæ ·æ€§é—®é¢˜æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17516">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-36792ede46dcf53442267b04771e109d~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070247&auth_key=1761070247-0-0-170fdb8b797a657eab90a8300444b42b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5d4c1ed777d490906f144590f6ceafc1~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070254&auth_key=1761070254-0-0-e055d62820ba5dc63f14e0849070b481&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SOLE-Hardware-Software-Co-design-of-Softmax-and-LayerNorm-for-Efficient-Transformer-Inference"><a href="#SOLE-Hardware-Software-Co-design-of-Softmax-and-LayerNorm-for-Efficient-Transformer-Inference" class="headerlink" title="SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient   Transformer Inference"></a>SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient   Transformer Inference</h2><p><strong>Authors:Wenxun Wang, Shuchang Zhou, Wenyu Sun, Peiqin Sun, Yongpan Liu</strong></p>
<p>Transformers have shown remarkable performance in both natural language processing (NLP) and computer vision (CV) tasks. However, their real-time inference speed and efficiency are limited due to the inefficiency in Softmax and Layer Normalization (LayerNorm). Previous works based on function approximation suffer from inefficient implementation as they place emphasis on computation while disregarding memory overhead concerns. Moreover, such methods rely on retraining to compensate for approximation error which can be costly and inconvenient.   In this paper, we present SOLE, a hardware-software co-design for Softmax and LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes log2 quantization of exponent function and log-based division to approximate Softmax while AILayerNorm adopts low-precision statistic calculation. Compared with state-of-the-art designs, we achieve both low-precision calculation and low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE maintains inference accuracy without retraining while offering orders of magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements over prior state-of-the-art custom hardware for Softmax and LayerNorm, respectively. </p>
<blockquote>
<p>è½¬æ¢å™¨åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œè®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºå…¶Softmaxå’ŒLayer Normalizationï¼ˆLayerNormï¼‰çš„æ•ˆç‡ä½ä¸‹ï¼Œå®æ—¶æ¨ç†é€Ÿåº¦å’Œæ•ˆç‡å—åˆ°é™åˆ¶ã€‚ä¹‹å‰åŸºäºå‡½æ•°è¿‘ä¼¼çš„å·¥ä½œå­˜åœ¨å®ç°æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œå› ä¸ºå®ƒä»¬æ³¨é‡è®¡ç®—è€Œå¿½ç•¥äº†å†…å­˜å¼€é”€çš„æ‹…å¿§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•éœ€è¦ä¾èµ–é‡æ–°è®­ç»ƒæ¥å¼¥è¡¥è¿‘ä¼¼è¯¯å·®ï¼Œè¿™æ—¢æ˜‚è´µåˆä¸æ–¹ä¾¿ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SOLEï¼Œä¸€ç§ä¸ºSoftmaxå’ŒLayerNormçš„è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼Œå®ƒç”±E2Softmaxå’ŒAILayerNormç»„æˆã€‚E2Softmaxåˆ©ç”¨æŒ‡æ•°å‡½æ•°çš„log2é‡åŒ–å’ŒåŸºäºlogçš„é™¤æ³•æ¥è¿‘ä¼¼Softmaxï¼Œè€ŒAILayerNormé‡‡ç”¨ä½ç²¾åº¦ç»Ÿè®¡è®¡ç®—ã€‚ä¸æœ€æ–°è®¾è®¡ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨Softmaxå’ŒLayerNormä¸Šå®ç°äº†ä½ç²¾åº¦è®¡ç®—å’Œä½ä½å®½å­˜å‚¨ã€‚å®éªŒè¡¨æ˜ï¼ŒSOLEåœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ä¿æŒäº†æ¨ç†ç²¾åº¦ï¼ŒåŒæ—¶ä¸GPUç›¸æ¯”å®ç°äº†æ•°é‡çº§çš„åŠ é€Ÿå’ŒèŠ‚èƒ½ã€‚ä¸æœ€æ–°çš„é’ˆå¯¹Softmaxå’ŒLayerNormçš„å®šåˆ¶ç¡¬ä»¶ç›¸æ¯”ï¼Œåˆ†åˆ«å®ç°äº†3.04å€ã€3.86å€çš„èƒ½æ•ˆæ”¹è¿›å’Œ2.82å€ã€3.32å€çš„é¢ç§¯æ•ˆç‡æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17189v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†é’ˆå¯¹Transformeråœ¨å®æ—¶æ¨ç†é€Ÿåº¦å’Œæ•ˆç‡æ–¹é¢çš„é—®é¢˜ï¼Œæå‡ºä¸€ç§è½¯ç¡¬ä»¶ååŒè®¾è®¡æ–¹æ³•â€”â€”SOLEï¼ŒåŒ…å«E2Softmaxå’ŒAILayerNormä¸¤éƒ¨åˆ†ã€‚E2Softmaxåˆ©ç”¨å¯¹æ•°é‡åŒ–æ–¹æ³•å’Œå¯¹æ•°é™¤æ³•è¿‘ä¼¼Softmaxï¼Œè€ŒAILayerNormé‡‡ç”¨ä½ç²¾åº¦ç»Ÿè®¡è®¡ç®—ã€‚ç›¸è¾ƒäºç°æœ‰è®¾è®¡ï¼Œæœ¬æ–‡å®ç°äº†Softmaxå’ŒLayerNormçš„ä½ç²¾åº¦è®¡ç®—å’Œä½ä½å®½å­˜å‚¨ã€‚å®éªŒè¡¨æ˜ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œå³å¯ä¿æŒæ¨ç†ç²¾åº¦ï¼ŒåŒæ—¶åœ¨GPUä¸Šå®ç°æ•°é‡çº§çš„é€Ÿåº¦æå‡å’ŒèŠ‚èƒ½æ•ˆæœï¼Œç›¸è¾ƒäºå…ˆå‰çš„å®šåˆ¶ç¡¬ä»¶è®¾è®¡ï¼Œèƒ½é‡æ•ˆç‡å’Œé¢ç§¯æ•ˆç‡å‡æœ‰æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>Transformersåœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®æ—¶æ¨ç†é€Ÿåº¦å’Œæ•ˆç‡å—é™ã€‚</li>
<li>ç°æœ‰åŸºäºåŠŸèƒ½è¿‘ä¼¼çš„ä¼˜åŒ–æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¹¶å¿½ç•¥äº†å†…å­˜å¼€é”€é—®é¢˜ã€‚</li>
<li>SOLEæ˜¯ä¸€ç§è½¯ç¡¬ä»¶ååŒè®¾è®¡æ–¹æ³•ï¼Œé’ˆå¯¹Softmaxå’ŒLayerNormè¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>E2Softmaxåˆ©ç”¨å¯¹æ•°é‡åŒ–æ–¹æ³•å’Œå¯¹æ•°é™¤æ³•æ¥å®ç°Softmaxçš„è¿‘ä¼¼è®¡ç®—ã€‚</li>
<li>AILayerNormé‡‡ç”¨ä½ç²¾åº¦ç»Ÿè®¡è®¡ç®—æ¥ä¼˜åŒ–LayerNormçš„è®¡ç®—æ•ˆç‡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯ä¿æŒæ¨ç†ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17189">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8521636a291835ed402699951ec0f123~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070262&auth_key=1761070262-0-0-1856b8cd3d7b736b63ccc96e1389d419&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-181b1638dfdb1540fb38df8ebbc2f7d4~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070269&auth_key=1761070269-0-0-fdbbbedfaa4355f3df1235fd307affa7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0ef79db160b821287a91d8ed11e19d84~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070275&auth_key=1761070275-0-0-de066c2a451ba83f6c3ae6c7982dee02&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-623d3a0964f89fc585c4530cc08ea382~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070282&auth_key=1761070282-0-0-e7d946a77b723159ba0a475380792683&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fefaf664feeae5bca669643f9fed9525~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070289&auth_key=1761070289-0-0-364040e15a2be607bae4c095f972b9b2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4dd8487ab95eb45917370dbe8032b485~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070295&auth_key=1761070295-0-0-c15aa223ec29340797d737572454d3ec&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c170600ad5d9f6068e50e3d863959863~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070301&auth_key=1761070301-0-0-be2d77d18184ba0891a6600dfa7eeeee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Video-Reasoning-without-Training"><a href="#Video-Reasoning-without-Training" class="headerlink" title="Video Reasoning without Training"></a>Video Reasoning without Training</h2><p><strong>Authors:Deepak Sridhar, Kartikeya Bhardwaj, Jeya Pradha Jeyaraj, Nuno Vasconcelos, Ankita Nayak, Harris Teague</strong></p>
<p>Video reasoning using Large Multimodal Models (LMMs) relies on costly reinforcement learning (RL) and verbose chain-of-thought, resulting in substantial computational overhead during both training and inference. Moreover, the mechanisms that control the thinking process in these reasoning models are very limited. In this paper, using entropy of the modelâ€™s output as a signal, we discover that the high-quality models go through a series of micro-explorations and micro-exploitations which keep the reasoning process grounded (i.e., avoid excessive randomness while the model is exploring or thinking through an answer). We further observe that once this â€œthinkingâ€ process is over, more accurate models demonstrate a better convergence by reducing the entropy significantly via a final exploitation phase (i.e., a more certain convergence towards a solution trajectory). We then use these novel, theoretically-grounded insights to tune the modelâ€™s behavior directly at inference, without using any RL or supervised fine-tuning. Specifically, during inference, our proposed approach called V-Reason (Video-Reason) adapts the value cache of the LMM via a few optimization steps on a small, trainable controller using an entropy-based objective, i.e., no supervision from any dataset or RL is necessary. This tuning improves the modelâ€™s micro-exploration and exploitation behavior during inference. Our experiments show that our proposed method achieves significant improvements over the base instruction-tuned models across several video reasoning datasets, narrowing the gap with RL-trained models to within 0.6% average accuracy without any training, while offering massive efficiency benefits: output tokens are reduced by 58.6% compared to the RL model. </p>
<blockquote>
<p>ä½¿ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰è¿›è¡Œè§†é¢‘æ¨ç†ä¾èµ–äºæ˜‚è´µçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œå†—é•¿çš„æ€ç»´é“¾ï¼Œå¯¼è‡´åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿå¤§é‡çš„è®¡ç®—å¼€é”€ã€‚è€Œä¸”ï¼Œè¿™äº›æ¨ç†æ¨¡å‹æ§åˆ¶æ€ç»´è¿‡ç¨‹çš„æœºåˆ¶éå¸¸æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»¥æ¨¡å‹è¾“å‡ºçš„ç†µä½œä¸ºä¿¡å·ï¼Œå‘ç°é«˜è´¨é‡æ¨¡å‹ä¼šç»å†ä¸€ç³»åˆ—çš„å¾®è§‚æ¢ç´¢å’Œå¾®è§‚åˆ©ç”¨ï¼Œä½¿æ¨ç†è¿‡ç¨‹ä¿æŒæ‰å®ï¼ˆå³ï¼Œåœ¨æ¨¡å‹æ¢ç´¢æˆ–é€šè¿‡æ€è€ƒå¯»æ‰¾ç­”æ¡ˆæ—¶é¿å…è¿‡åº¦éšæœºæ€§ï¼‰ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è§‚å¯Ÿåˆ°ï¼Œä¸€æ—¦â€œæ€è€ƒâ€è¿‡ç¨‹ç»“æŸï¼Œæ›´ç²¾ç¡®çš„æ¨¡å‹ä¼šé€šè¿‡æœ€ç»ˆçš„åˆ©ç”¨é˜¶æ®µæ˜¾è‘—å‡å°‘ç†µï¼Œä»è€Œæ˜¾ç¤ºå‡ºæ›´å¥½çš„æ”¶æ•›æ€§ï¼ˆå³ï¼Œæ›´ç¡®å®šåœ°æœå‘è§£å†³æ–¹æ¡ˆè½¨è¿¹ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™äº›æ–°çš„ã€ç†è®ºä¸Šçš„è§è§£ï¼Œç›´æ¥åœ¨æ¨ç†æ—¶è°ƒæ•´æ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œæ— éœ€ä½¿ç”¨ä»»ä½•RLæˆ–ç›‘ç£å¾®è°ƒã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨æ¨ç†æœŸé—´ï¼Œæˆ‘ä»¬æå‡ºçš„åä¸ºV-Reasonï¼ˆè§†é¢‘æ¨ç†ï¼‰çš„æ–¹æ³•é€šè¿‡å‡ ä¸ªä¼˜åŒ–æ­¥éª¤ï¼Œå¯¹LMMçš„å€¼ç¼“å­˜è¿›è¡Œé€‚åº”ï¼Œè¿™äº›ä¼˜åŒ–æ­¥éª¤åœ¨ä¸€ä¸ªå°å‹çš„ã€å¯è®­ç»ƒçš„æ§åˆ¶å™¨ä¸ŠåŸºäºç†µçš„ç›®æ ‡è¿›è¡Œï¼Œå³æ— éœ€ä»»ä½•æ•°æ®é›†æˆ–RLçš„ç›‘ç£ã€‚è¿™ç§è°ƒæ•´æ”¹è¿›äº†æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„å¾®è§‚æ¢ç´¢å’Œåˆ©ç”¨è¡Œä¸ºã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸åŸºäºæŒ‡ä»¤è°ƒæ•´çš„åŸºç¡€æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘æ¨ç†æ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨æ— éœ€ä»»ä½•è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¸RLè®­ç»ƒæ¨¡å‹çš„å¹³å‡å‡†ç¡®ç‡å·®è·ç¼©å°è‡³0.6%ï¼ŒåŒæ—¶å¸¦æ¥äº†å·¨å¤§çš„æ•ˆç‡æ•ˆç›Šï¼šä¸RLæ¨¡å‹ç›¸æ¯”ï¼Œè¾“å‡ºä»¤ç‰Œå‡å°‘äº†58.6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.17045v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰çš„è§†é¢‘æ¨ç†ä¾èµ–äºæ˜‚è´µçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œå†—é•¿çš„æ€è€ƒé“¾ï¼Œå¯¼è‡´è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­è®¡ç®—å¼€é”€è¾ƒå¤§ã€‚æœ¬æ–‡å‘ç°é«˜è´¨é‡æ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—å¾®è§‚æ¢ç´¢å’Œå¾®è§‚åˆ©ç”¨æ¥ä¿æŒæ¨ç†è¿‡ç¨‹çš„ç¨³å¥æ€§ï¼Œé¿å…è¿‡åº¦éšæœºæ€§ã€‚æ¨¡å‹æ€è€ƒç»“æŸåï¼Œæ›´å‡†ç¡®æ¨¡å‹é€šè¿‡æœ€ç»ˆåˆ©ç”¨é˜¶æ®µæ˜¾è‘—å‡å°‘ç†µï¼Œè¡¨ç°å‡ºæ›´å¥½çš„æ”¶æ•›æ€§ã€‚æœ¬æ–‡åˆ©ç”¨è¿™äº›æ–°ç†è®ºè§è§£ï¼Œæ— éœ€ä½¿ç”¨ä»»ä½•RLæˆ–ç›‘ç£å¾®è°ƒï¼Œç›´æ¥åœ¨æ¨ç†æ—¶è°ƒæ•´æ¨¡å‹è¡Œä¸ºã€‚å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘æ¨ç†æ•°æ®é›†ä¸Šè¾ƒåŸºç¡€æŒ‡ä»¤è°ƒæ•´æ¨¡å‹æœ‰æ˜¾è‘—æ”¹å–„ï¼Œä¸RLè®­ç»ƒæ¨¡å‹çš„å¹³å‡å‡†ç¡®ç‡å·®è·ç¼©å°è‡³0.6%ä»¥å†…ï¼ŒåŒæ—¶å¤§å¤§æé«˜äº†æ•ˆç‡ï¼šè¾“å‡ºä»¤ç‰Œå‡å°‘58.6%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è§†é¢‘æ¨ç†ä¸­çš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰ä¾èµ–å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œè®¡ç®—å’Œæ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨æ˜¾è‘—çš„è®¡ç®—å¼€é”€ã€‚</li>
<li>é«˜è´¨é‡æ¨¡å‹é€šè¿‡å¾®è§‚æ¢ç´¢å’Œå¾®è§‚åˆ©ç”¨è¿‡ç¨‹ä¿æŒæ¨ç†ç¨³å¥æ€§ï¼Œé¿å…è¿‡åº¦éšæœºæ€§ã€‚</li>
<li>æ¨¡å‹åœ¨æ€è€ƒç»“æŸåï¼Œé€šè¿‡å‡å°‘ç†µè¡¨ç°å‡ºæ›´å¥½çš„æ”¶æ•›æ€§ã€‚</li>
<li>åˆ©ç”¨ç†µä½œä¸ºä¿¡å·ï¼Œå¯ä»¥ç›´æ¥åœ¨æ¨ç†æ—¶è°ƒæ•´æ¨¡å‹è¡Œä¸ºï¼Œæ— éœ€ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–ç›‘ç£å¾®è°ƒã€‚</li>
<li>æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªè§†é¢‘æ¨ç†æ•°æ®é›†ä¸Šè¾ƒåŸºç¡€æ¨¡å‹æœ‰æ˜¾è‘—æ”¹å–„ã€‚</li>
<li>ä¸å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å‹ç›¸æ¯”ï¼Œå¹³å‡å‡†ç¡®ç‡å·®è·ç¼©å°è‡³0.6%ä»¥å†…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.17045">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4cb2fd8c2b7f9bf6d2bc083895adf3ea~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070309&auth_key=1761070309-0-0-860d21b8fedd23658818359ba4916e83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1393839c7ae7ee0c5ff31d0251c46322~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070316&auth_key=1761070316-0-0-1d390666dffa99d08c3271c84bb47cb6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bd1e7ac066589de197a723d8c62a1c3a~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070323&auth_key=1761070323-0-0-f42d01d4b00ec5c6781e1d023f551d7a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Parameter-Efficient-Fine-Tuning-for-Low-Resource-Languages-A-Comparative-Study-of-LLMs-for-Bengali-Hate-Speech-Detection"><a href="#Parameter-Efficient-Fine-Tuning-for-Low-Resource-Languages-A-Comparative-Study-of-LLMs-for-Bengali-Hate-Speech-Detection" class="headerlink" title="Parameter-Efficient Fine-Tuning for Low-Resource Languages: A   Comparative Study of LLMs for Bengali Hate Speech Detection"></a>Parameter-Efficient Fine-Tuning for Low-Resource Languages: A   Comparative Study of LLMs for Bengali Hate Speech Detection</h2><p><strong>Authors:Akif Islam, Mohd Ruhul Ameen</strong></p>
<p>Bengali social media platforms have witnessed a sharp increase in hate speech, disproportionately affecting women and adolescents. While datasets such as BD-SHS provide a basis for structured evaluation, most prior approaches rely on either computationally costly full-model fine-tuning or proprietary APIs. This paper presents the first application of Parameter-Efficient Fine-Tuning (PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three instruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and Mistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated comments. Each model was adapted by training fewer than 1% of its parameters, enabling experiments on a single consumer-grade GPU. The results show that Llama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at 88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical and replicable strategy for Bengali and related low-resource languages. </p>
<blockquote>
<p>å­ŸåŠ æ‹‰ç¤¾äº¤åª’ä½“å¹³å°è§è¯äº†ä»‡æ¨è¨€è®ºçš„æ€¥å‰§å¢åŠ ï¼Œå¯¹å¦‡å¥³å’Œé’å°‘å¹´äº§ç”Ÿäº†ä¸æˆæ¯”ä¾‹çš„å½±å“ã€‚è™½ç„¶BD-SHSç­‰æ•°æ®é›†ä¸ºç»“æ„åŒ–è¯„ä¼°æä¾›äº†åŸºç¡€ï¼Œä½†å¤§å¤šæ•°å…ˆå‰çš„æ–¹æ³•éƒ½ä¾èµ–äºè®¡ç®—æˆæœ¬é«˜æ˜‚çš„å…¨æ¨¡å‹å¾®è°ƒæˆ–ä¸“æœ‰APIã€‚æœ¬æ–‡é¦–æ¬¡åº”ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰è¿›è¡Œå­ŸåŠ æ‹‰ä»‡æ¨è¨€è®ºæ£€æµ‹ï¼Œä½¿ç”¨LoRAå’ŒQLoRAæ–¹æ³•ã€‚åœ¨å«æœ‰50,281ä¸ªæ³¨é‡Šè¯„è®ºçš„BD-SHSæ•°æ®é›†ä¸Šï¼Œå¯¹ä¸‰ä¸ªæŒ‡ä»¤è°ƒæ•´çš„å¤§å‹è¯­è¨€æ¨¡å‹â€”â€”Gemma-3-4Bã€Llama-3.2-3Bå’ŒMistral-7Bè¿›è¡Œäº†å¾®è°ƒã€‚æ¯ä¸ªæ¨¡å‹çš„å‚æ•°é€‚åº”éƒ½æ˜¯é€šè¿‡è®­ç»ƒä¸åˆ°1%çš„å‚æ•°æ¥å®ç°çš„ï¼Œå¯åœ¨å•ä¸ªæ¶ˆè´¹çº§GPUä¸Šè¿›è¡Œå®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒLlama-3.2-3Bçš„F1å¾—åˆ†æœ€é«˜ï¼Œè¾¾åˆ°92.23%ï¼Œå…¶æ¬¡æ˜¯Mistral-7Bçš„88.94%å’ŒGemma-3-4Bçš„80.25%ã€‚è¿™äº›å‘ç°è¯æ˜äº†PEFTåœ¨å­ŸåŠ æ‹‰è¯­å’Œç›¸å…³ä½èµ„æºè¯­è¨€ä¸­æ˜¯ä¸€ç§å®ç”¨ä¸”å¯å¤åˆ¶çš„ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16985v1">PDF</a> Accepted to IEEE COMPAS 2025. 6 pages, 3 figures, 6 tables</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡å…³æ³¨å­ŸåŠ æ‹‰è¯­ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ä»‡æ¨è¨€è®ºé—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¥³æ€§å’Œé’å°‘å¹´çš„å½±å“ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œè®ºæ–‡é¦–æ¬¡åº”ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ï¼Œåˆ©ç”¨LoRAå’ŒQLoRAæ–¹æ³•è¿›è¡Œå­ŸåŠ æ‹‰è¯­ä»‡æ¨è¨€è®ºæ£€æµ‹ã€‚é€šè¿‡å¯¹ä¸‰ä¸ªæŒ‡ä»¤è°ƒä¼˜çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå®éªŒç»“æœæ˜¾ç¤ºï¼ŒLlama-3.2-3Bæ¨¡å‹è¡¨ç°æœ€ä½³ï¼ŒF1åˆ†æ•°è¾¾åˆ°92.23%ï¼Œå…¶æ¬¡æ˜¯Mistral-7Bå’ŒGemma-3-4Bæ¨¡å‹ã€‚ç ”ç©¶è¯æ˜äº†å‚æ•°é«˜æ•ˆå¾®è°ƒæ˜¯ä¸€ç§é’ˆå¯¹å­ŸåŠ æ‹‰è¯­å’Œç›¸å…³ä½èµ„æºè¯­è¨€çš„å®ç”¨ä¸”å¯å¤åˆ¶çš„ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å­ŸåŠ æ‹‰è¯­ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„ä»‡æ¨è¨€è®ºé—®é¢˜æ—¥ç›Šä¸¥é‡ï¼Œå¯¹å¥³æ€§å’Œé’å°‘å¹´é€ æˆä¸æˆæ¯”ä¾‹çš„å½±å“ã€‚</li>
<li>æ•°æ®é›†å¦‚BD-SHSä¸ºç»“æ„åŒ–è¯„ä¼°æä¾›äº†åŸºç¡€ï¼Œä½†ä¹‹å‰çš„æ–¹æ³•è¦ä¹ˆè®¡ç®—æˆæœ¬é«˜ï¼Œè¦ä¹ˆä¾èµ–ä¸“æœ‰APIã€‚</li>
<li>è®ºæ–‡é¦–æ¬¡å°†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯åº”ç”¨äºå­ŸåŠ æ‹‰è¯­ä»‡æ¨è¨€è®ºæ£€æµ‹ã€‚</li>
<li>ä½¿ç”¨äº†LoRAå’ŒQLoRAæ–¹æ³•æ¥è¿›è¡Œå¾®è°ƒã€‚</li>
<li>ä¸‰ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆGemma-3-4Bã€Llama-3.2-3Bå’ŒMistral-7Bï¼‰åœ¨BD-SHSæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚</li>
<li>Llama-3.2-3Bæ¨¡å‹è¡¨ç°æœ€ä½³ï¼ŒF1åˆ†æ•°è¾¾åˆ°92.23%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16985">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-fdfcbf1aa3c56d62c93443b8a80b161c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070332&auth_key=1761070332-0-0-f5d8bba35eb47634b7cfced41536ee10&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e2ff854e82cb5a92dac5cd917ad5a85f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070339&auth_key=1761070339-0-0-7372b3997451a92388dd5a04f02781b1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d1f1a5e4eadc7a0bdbfbf506fd4bed32~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070345&auth_key=1761070345-0-0-d20ffc625c2eb33cfa684076b0740957&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-db42774048dfd3b31d8ea35ec64460cd~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070353&auth_key=1761070353-0-0-c865ffb1e2d9808ec19594e7a7fc9de1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-851df09998bf7492b77b3513d392e257~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070359&auth_key=1761070359-0-0-01b4b86090b00215fadfe04797b47bc3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-09bec984d541ae76a70dd7a0bf977cd9~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070366&auth_key=1761070366-0-0-7ca471053c17d2d90c9b5b1af87e0ee5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-da522e6b87944c486def375faadf184a~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070373&auth_key=1761070373-0-0-dd6900cfdf6f9cb7f219b5a9e8da06c3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6e19a2e8784ec2bb0e8b596664f09922~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070379&auth_key=1761070379-0-0-24b2ce9fe96beb3d220024562470e5c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="UniGTE-Unified-Graph-Text-Encoding-for-Zero-Shot-Generalization-across-Graph-Tasks-and-Domains"><a href="#UniGTE-Unified-Graph-Text-Encoding-for-Zero-Shot-Generalization-across-Graph-Tasks-and-Domains" class="headerlink" title="UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across   Graph Tasks and Domains"></a>UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across   Graph Tasks and Domains</h2><p><strong>Authors:Duo Wang, Yuan Zuo, Guangyue Lu, Junjie Wu</strong></p>
<p>Generalizing to unseen graph tasks without task-specific supervision is challenging: conventional graph neural networks are typically tied to a fixed label space, while large language models (LLMs) struggle to capture graph structure. We introduce UniGTE, an instruction-tuned encoder-decoder framework that unifies structural and semantic reasoning. The encoder augments a pretrained autoregressive LLM with learnable alignment tokens and a structure-aware graph-text attention mechanism, enabling it to attend jointly to a tokenized graph and a natural-language task prompt while remaining permutation-invariant to node order. This yields compact, task-aware graph representations. Conditioned solely on these representations, a frozen LLM decoder predicts and reconstructs: it outputs the task answer and simultaneously paraphrases the input graph in natural language. The reconstruction objective regularizes the encoder to preserve structural cues. UniGTE is instruction-tuned on five datasets spanning node-level, edge-level, and graph-level tasks across diverse domains, yet requires no fine-tuning at inference. It achieves new state-of-the-art zero-shot results on node classification, link prediction, graph classification, and graph regression under cross-task and cross-domain settings, demonstrating that tight integration of graph structure with LLM semantics enables robust, transferable graph reasoning. </p>
<blockquote>
<p>å°†æœªè§è¿‡å›¾çš„ä»»åŠ¡æ¨å¹¿åˆ°æœªè§ç‰¹å®šä»»åŠ¡ç›‘ç£æ˜¯æœ‰æŒ‘æˆ˜æ€§çš„ï¼šä¼ ç»Ÿçš„å›¾ç¥ç»ç½‘ç»œé€šå¸¸ç»‘å®šåˆ°ä¸€ä¸ªå›ºå®šçš„æ ‡ç­¾ç©ºé—´ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•æ‰å›¾ç»“æ„æ–¹é¢è¡¨ç°æŒ£æ‰ã€‚æˆ‘ä»¬å¼•å…¥äº†UniGTEï¼Œè¿™æ˜¯ä¸€ä¸ªæŒ‡ä»¤è°ƒä¼˜çš„ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œå®ƒç»Ÿä¸€äº†ç»“æ„æ€§å’Œè¯­ä¹‰æ¨ç†ã€‚ç¼–ç å™¨é€šè¿‡å¯å­¦ä¹ çš„å¯¹é½ä»¤ç‰Œå’Œç»“æ„æ„ŸçŸ¥å›¾æ–‡æœ¬æ³¨æ„åŠ›æœºåˆ¶æ¥å¢å¼ºé¢„è®­ç»ƒçš„è‡ªå›å½’LLMï¼Œä½¿å…¶åœ¨ä»¤ç‰ŒåŒ–å›¾å’Œè‡ªç„¶è¯­è¨€ä»»åŠ¡æç¤ºçš„åŒæ—¶èƒ½å¤Ÿå…±åŒå…³æ³¨ï¼ŒåŒæ—¶å¯¹èŠ‚ç‚¹é¡ºåºä¿æŒç½®æ¢ä¸å˜ã€‚è¿™äº§ç”Ÿäº†ç´§å‡‘çš„ä»»åŠ¡æ„ŸçŸ¥å›¾è¡¨ç¤ºã€‚ä»…åŸºäºè¿™äº›è¡¨ç¤ºï¼Œå†»ç»“çš„LLMè§£ç å™¨è¿›è¡Œé¢„æµ‹å’Œé‡å»ºï¼šå®ƒè¾“å‡ºä»»åŠ¡ç­”æ¡ˆï¼ŒåŒæ—¶ç”¨è‡ªç„¶è¯­è¨€å¯¹è¾“å…¥å›¾è¿›è¡ŒåŒä¹‰æ›¿æ¢ã€‚é‡å»ºç›®æ ‡ä½¿ç¼–ç å™¨èƒ½å¤Ÿä¿ç•™ç»“æ„çº¿ç´¢ã€‚UniGTEåœ¨æ¶µç›–èŠ‚ç‚¹çº§ã€è¾¹ç¼˜çº§å’Œå›¾çº§ä»»åŠ¡çš„äº”ä¸ªæ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œæ¶‰åŠå¤šä¸ªé¢†åŸŸï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦å¾®è°ƒã€‚å®ƒåœ¨è·¨ä»»åŠ¡å’Œè·¨åŸŸè®¾ç½®ä¸‹å®ç°äº†èŠ‚ç‚¹åˆ†ç±»ã€é“¾æ¥é¢„æµ‹ã€å›¾åˆ†ç±»å’Œå›¾å›å½’çš„é›¶æ ·æœ¬æ–°æœ€ä½³ç»“æœï¼Œè¡¨æ˜å°†å›¾ç»“æ„ä¸LLMè¯­ä¹‰ç´§å¯†ç»“åˆå¯å®ç°ç¨³å¥ã€å¯è½¬ç§»çš„å›¾æ¨ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16885v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šé€šç”¨å›¾ä»»åŠ¡ä¸­ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡ç›‘ç£æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚å¸¸è§„å›¾ç¥ç»ç½‘ç»œå—é™äºå›ºå®šæ ‡ç­¾ç©ºé—´ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹éš¾ä»¥æ•æ‰å›¾ç»“æ„ã€‚æˆ‘ä»¬æ¨å‡ºUniGTEï¼Œä¸€ç§æŒ‡ä»¤è°ƒä¼˜çš„ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œç»Ÿä¸€ç»“æ„æ€§å’Œè¯­ä¹‰æ¨ç†ã€‚ç¼–ç å™¨é€šè¿‡å¯å­¦ä¹ å¯¹é½ä»¤ç‰Œå’Œç»“æ„æ„ŸçŸ¥å›¾æ–‡æœ¬æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºé¢„è®­ç»ƒè‡ªå›å½’å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤ŸåŒæ—¶å…³æ³¨ä»¤ç‰ŒåŒ–å›¾å’Œè‡ªç„¶è¯­è¨€ä»»åŠ¡æç¤ºï¼Œå¯¹èŠ‚ç‚¹é¡ºåºä¿æŒç½®æ¢ä¸å˜æ€§ã€‚è¿™äº§ç”Ÿç´§å‡‘çš„ä»»åŠ¡æ„ŸçŸ¥å›¾è¡¨ç¤ºã€‚ä»…åŸºäºè¿™äº›è¡¨ç¤ºï¼Œå†»ç»“çš„å¤§å‹è¯­è¨€æ¨¡å‹è§£ç å™¨å¯é¢„æµ‹å¹¶é‡å»ºï¼šè¾“å‡ºä»»åŠ¡ç­”æ¡ˆï¼ŒåŒæ—¶ç”¨è‡ªç„¶è¯­è¨€å¤è¿°è¾“å…¥å›¾ã€‚é‡å»ºç›®æ ‡ä½¿ç¼–ç å™¨ä¿æŒç»“æ„çº¿ç´¢ã€‚UniGTEåœ¨æ¶µç›–èŠ‚ç‚¹çº§ã€è¾¹ç¼˜çº§å’Œå›¾çº§ä»»åŠ¡çš„äº”ä¸ªæ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œè·¨è¶Šä¸åŒé¢†åŸŸï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— éœ€å¾®è°ƒã€‚å®ƒåœ¨è·¨ä»»åŠ¡å’Œè·¨åŸŸè®¾ç½®ä¸‹å®ç°äº†èŠ‚ç‚¹åˆ†ç±»ã€é“¾æ¥é¢„æµ‹ã€å›¾å½¢åˆ†ç±»å’Œå›¾å½¢å›å½’çš„æœ€æ–°é›¶æ ·æœ¬ç»“æœï¼Œè¯æ˜äº†å›¾ç»“æ„ä¸å¤§å‹è¯­è¨€æ¨¡å‹è¯­ä¹‰ç´§å¯†ç»“åˆå¯å®ç°ç¨³å¥ã€å¯è½¬ç§»çš„å›¾æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>UniGTEæ¡†æ¶æˆåŠŸå°†ç»“æ„æ€§å’Œè¯­ä¹‰æ¨ç†ç»“åˆèµ·æ¥ï¼Œé€šè¿‡ç¼–ç å™¨å¢å¼ºé¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å›¾æ•°æ®ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆç´§å‡‘çš„ä»»åŠ¡æ„ŸçŸ¥å›¾è¡¨ç¤ºï¼Œä»…åŸºäºè¿™äº›è¡¨ç¤ºï¼Œè§£ç å™¨å°±èƒ½é¢„æµ‹å¹¶é‡å»ºä»»åŠ¡ç­”æ¡ˆå’Œå›¾çš„è‡ªç„¶è¯­è¨€æè¿°ã€‚</li>
<li>UniGTEé€šè¿‡å¼•å…¥å¯å­¦ä¹ å¯¹é½ä»¤ç‰Œå’Œå›¾å½¢æ–‡æœ¬æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶å…³æ³¨å›¾å½¢æ•°æ®å’Œè‡ªç„¶è¯­è¨€æç¤ºï¼Œä¸”å¯¹èŠ‚ç‚¹é¡ºåºå…·æœ‰ä¸å˜æ€§ã€‚</li>
<li>é‡å»ºç›®æ ‡æœ‰åŠ©äºç¼–ç å™¨ä¿æŒç»“æ„çº¿ç´¢ï¼Œå¼ºåŒ–æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>UniGTEåœ¨å¤šç§ä»»åŠ¡å’Œé¢†åŸŸä¸Šè¿›è¡Œäº†æŒ‡ä»¤è°ƒä¼˜ï¼Œä½†æ¨ç†è¿‡ç¨‹ä¸­æ— éœ€å¾®è°ƒã€‚</li>
<li>è¯¥æ¡†æ¶å®ç°äº†è·¨ä»»åŠ¡å’Œè·¨åŸŸçš„é›¶æ ·æœ¬å­¦ä¹ æ–°çºªå½•ï¼Œåœ¨èŠ‚ç‚¹åˆ†ç±»ã€é“¾æ¥é¢„æµ‹ã€å›¾å½¢åˆ†ç±»å’Œå›¾å½¢å›å½’æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16885">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5cd90e16e861dd64b82d04dd22a6445d~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070387&auth_key=1761070387-0-0-d9b1b8d3f2ff36fbd3088f805039e30e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3b7c8f128f40e546288802e6adbbcffd~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070394&auth_key=1761070394-0-0-629571cf189f68618969ea624da76882&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AtomBench-A-Benchmark-for-Generative-Atomic-Structure-Models-using-GPT-Diffusion-and-Flow-Architectures"><a href="#AtomBench-A-Benchmark-for-Generative-Atomic-Structure-Models-using-GPT-Diffusion-and-Flow-Architectures" class="headerlink" title="AtomBench: A Benchmark for Generative Atomic Structure Models using GPT,   Diffusion, and Flow Architectures"></a>AtomBench: A Benchmark for Generative Atomic Structure Models using GPT,   Diffusion, and Flow Architectures</h2><p><strong>Authors:Charles Rhys Campbell, Aldo H. Romero, Kamal Choudhary</strong></p>
<p>Generative models have become significant assets in the exploration and identification of new materials, enabling the rapid proposal of candidate crystal structures that satisfy target properties. Despite the increasing adoption of diverse architectures, a rigorous comparative evaluation of their performance on materials datasets is lacking. In this work, we present a systematic benchmark of three representative generative models- AtomGPT (a transformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE), and FlowMM (a Riemannian flow matching model). These models were trained to reconstruct crystal structures from subsets of two publicly available superconductivity datasets- JARVIS Supercon 3D and DS A&#x2F;B from the Alexandria database. Performance was assessed using the Kullback-Leibler (KL) divergence between predicted and reference distributions of lattice parameters, as well as the mean absolute error (MAE) of individual lattice constants. For the computed KLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and then FlowMM. All benchmarking code and model configurations will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/atomgptlab/atombench_inverse">https://github.com/atomgptlab/atombench_inverse</a>. </p>
<blockquote>
<p>ç”Ÿæˆæ¨¡å‹åœ¨æ¢ç´¢å’Œè¯†åˆ«æ–°ææ–™æ–¹é¢å·²æˆä¸ºé‡è¦èµ„äº§ï¼Œèƒ½å¤Ÿè¿…é€Ÿæå‡ºæ»¡è¶³ç›®æ ‡å±æ€§çš„å€™é€‰æ™¶ä½“ç»“æ„ã€‚å°½ç®¡é‡‡ç”¨äº†å¤šç§ä¸åŒçš„æ¶æ„ï¼Œä½†åœ¨ææ–™æ•°æ®é›†ä¸Šå¯¹å…¶æ€§èƒ½è¿›è¡Œä¸¥æ ¼çš„æ¯”è¾ƒè¯„ä¼°ä»ç„¶ç¼ºä¹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸‰ç§å…·æœ‰ä»£è¡¨æ€§çš„ç”Ÿæˆæ¨¡å‹è¿›è¡Œäº†ç³»ç»ŸåŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬AtomGPTï¼ˆåŸºäºè½¬æ¢å™¨çš„æ¨¡å‹ï¼‰ã€æ™¶ä½“æ‰©æ•£å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆCDVAEï¼‰å’ŒæµåŒ¹é…æ¨¡å‹FlowMMï¼ˆé»æ›¼æµåŒ¹é…æ¨¡å‹ï¼‰ã€‚è¿™äº›æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œèƒ½å¤Ÿä»ä¸¤ä¸ªå…¬å¼€å¯ç”¨çš„è¶…å¯¼æ€§æ•°æ®é›†çš„å­é›†ï¼ˆJARVIS Supercon 3Då’ŒAlexandriaæ•°æ®åº“çš„DS A&#x2F;Bï¼‰é‡å»ºæ™¶ä½“ç»“æ„ã€‚æ€§èƒ½è¯„ä¼°é‡‡ç”¨é¢„æµ‹æ™¶æ ¼å‚æ•°åˆ†å¸ƒä¸å‚è€ƒåˆ†å¸ƒä¹‹é—´çš„Kullback-Leiblerï¼ˆKLï¼‰æ•£åº¦ï¼Œä»¥åŠå•ä¸ªæ™¶æ ¼å¸¸æ•°çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚æ ¹æ®è®¡ç®—çš„KLDå’ŒMAEåˆ†æ•°ï¼ŒCDVAEè¡¨ç°æœ€ä¸ºä¼˜è¶Šï¼Œå…¶æ¬¡æ˜¯AtomGPTï¼Œç„¶åæ˜¯FlowMMã€‚æ‰€æœ‰åŸºå‡†æµ‹è¯•ä»£ç å’Œæ¨¡å‹é…ç½®å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/atomgptlab/atombench_inverse%E4%B8%8A%E5%85%AC%E5%BC%80%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/atomgptlab/atombench_inverseä¸Šå…¬å¼€æä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16165v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç§ä»£è¡¨æ€§ç”Ÿæˆæ¨¡å‹ï¼šAtomGPTã€Crystal Diffusion Variational Autoencoderï¼ˆCDVAEï¼‰å’ŒFlowMMï¼Œåœ¨ææ–™æ•°æ®é›†ä¸Šçš„æ€§èƒ½ç³»ç»Ÿè¯„ä¼°ã€‚è¿™äº›æ¨¡å‹è¢«è®­ç»ƒç”¨äºä»å…¬å¼€å¯ç”¨çš„è¶…å¯¼ææ–™æ•°æ®é›†ä¸­é‡å»ºæ™¶ä½“ç»“æ„ã€‚é€šè¿‡é¢„æµ‹çš„æ™¶æ ¼å‚æ•°åˆ†å¸ƒä¸å‚è€ƒåˆ†å¸ƒä¹‹é—´çš„Kullback-Leiblerï¼ˆKLï¼‰æ•£åº¦ä»¥åŠæ™¶æ ¼å¸¸æ•°çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰æ¥è¯„ä¼°æ€§èƒ½ã€‚ç»“æœæ˜¾ç¤ºCDVAEè¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯AtomGPTï¼Œæœ€åæ˜¯FlowMMã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸‰ç§ä»£è¡¨æ€§ç”Ÿæˆæ¨¡å‹è¢«ç”¨äºæ™¶ä½“ç»“æ„çš„é‡å»ºï¼ŒåŒ…æ‹¬AtomGPTã€CDVAEå’ŒFlowMMã€‚</li>
<li>è¿™äº›æ¨¡å‹åœ¨å…¬å¼€å¯ç”¨çš„è¶…å¯¼ææ–™æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>æ€§èƒ½è¯„ä¼°åŸºäºé¢„æµ‹çš„æ™¶æ ¼å‚æ•°åˆ†å¸ƒä¸å‚è€ƒåˆ†å¸ƒä¹‹é—´çš„KLæ•£åº¦å’Œæ™¶æ ¼å¸¸æ•°çš„MAEã€‚</li>
<li>CDVAEåœ¨æ€§èƒ½è¯„ä¼°ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
<li>AtomGPTè¡¨ç°ä¼˜äºFlowMMã€‚</li>
<li>æ‰€æœ‰åŸºå‡†æµ‹è¯•ä»£ç å’Œæ¨¡å‹é…ç½®å°†å…¬å¼€æä¾›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3614860da7281b9ec391ff8f9e116a9a~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070401&auth_key=1761070401-0-0-d5f621b2b933c019ee7821147aeb2d16&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="A-Novel-GPT-Based-Framework-for-Anomaly-Detection-in-System-Logs"><a href="#A-Novel-GPT-Based-Framework-for-Anomaly-Detection-in-System-Logs" class="headerlink" title="A Novel GPT-Based Framework for Anomaly Detection in System Logs"></a>A Novel GPT-Based Framework for Anomaly Detection in System Logs</h2><p><strong>Authors:Zeng Zhang, Wenjie Yin, Xiaoqi Li</strong></p>
<p>Identification of anomalous events within system logs constitutes a pivotal element within the frame- work of cybersecurity defense strategies. However, this process faces numerous challenges, including the management of substantial data volumes, the distribution of anomalies, and the precision of con- ventional methods. To address this issue, the present paper puts forward a proposal for an intelligent detection method for system logs based on Genera- tive Pre-trained Transformers (GPT). The efficacy of this approach is attributable to a combination of structured input design and a Focal Loss op- timization strategy, which collectively result in a substantial enhancement of the performance of log anomaly detection. The initial approach involves the conversion of raw logs into event ID sequences through the use of the Drain parser. Subsequently, the Focal Loss loss function is employed to address the issue of class imbalance. The experimental re- sults demonstrate that the optimized GPT-2 model significantly outperforms the unoptimized model in a range of key metrics, including precision, recall, and F1 score. In specific tasks, comparable or superior performance has been demonstrated to that of the GPT-3.5 API. </p>
<blockquote>
<p>åœ¨ç³»ç»Ÿæ—¥å¿—ä¸­è¯†åˆ«å¼‚å¸¸äº‹ä»¶æ˜¯ç½‘ç»œå®‰å…¨é˜²å¾¡ç­–ç•¥æ¡†æ¶ä¸­çš„å…³é”®è¦ç´ ã€‚ç„¶è€Œï¼Œè¿™ä¸ªè¿‡ç¨‹é¢ä¸´è®¸å¤šæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç®¡ç†å¤§é‡æ•°æ®ã€å¼‚å¸¸åˆ†å¸ƒå’Œä¼ ç»Ÿæ–¹æ³•çš„ç²¾ç¡®åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆé¢„è®­ç»ƒå˜å‹å™¨ï¼ˆGPTï¼‰çš„æ™ºèƒ½æ£€æµ‹ç³»ç»Ÿæ—¥å¿—çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å½’å› äºç»“æ„åŒ–è¾“å…¥è®¾è®¡å’Œç„¦ç‚¹æŸå¤±ä¼˜åŒ–ç­–ç•¥çš„ç»“åˆï¼Œå®ƒä»¬å…±åŒå¯¼è‡´æ—¥å¿—å¼‚å¸¸æ£€æµ‹æ€§èƒ½çš„å¤§å¹…æé«˜ã€‚åˆå§‹æ–¹æ³•æ¶‰åŠä½¿ç”¨Drainè§£æå™¨å°†åŸå§‹æ—¥å¿—è½¬æ¢ä¸ºäº‹ä»¶IDåºåˆ—ã€‚éšåï¼Œç„¦ç‚¹æŸå¤±æŸå¤±å‡½æ•°è¢«ç”¨æ¥è§£å†³ç±»ä¸å¹³è¡¡é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡ä¼˜åŒ–çš„GPT-2æ¨¡å‹åœ¨ç²¾åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°ç­‰ä¸€ç³»åˆ—å…³é”®æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºæœªä¼˜åŒ–çš„æ¨¡å‹ã€‚åœ¨ç‰¹å®šä»»åŠ¡ä¸­ï¼Œå…¶è¡¨ç°ä¸GPT-3.5 APIç›¸å½“æˆ–æ›´ä¼˜ç§€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.16044v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç³»ç»Ÿæ—¥å¿—ä¸­çš„å¼‚å¸¸äº‹ä»¶è¯†åˆ«æ˜¯ç½‘ç»œå®‰å…¨é˜²å¾¡ç­–ç•¥ä¸­çš„å…³é”®éƒ¨åˆ†ï¼Œä½†é¢ä¸´æ•°æ®é‡å¤§ã€å¼‚å¸¸åˆ†å¸ƒå’Œå¸¸è§„æ–¹æ³•ç²¾åº¦ä½ç­‰æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç”Ÿæˆå¼é¢„è®­ç»ƒè½¬æ¢å™¨ï¼ˆGPTï¼‰çš„æ™ºèƒ½æ£€æµ‹æ–¹æ³•çš„å»ºè®®ï¼Œé€šè¿‡ç»“æ„åŒ–çš„è¾“å…¥è®¾è®¡å’ŒFocal Lossä¼˜åŒ–ç­–ç•¥ï¼Œå¤§å¹…æé«˜æ—¥å¿—å¼‚å¸¸æ£€æµ‹çš„æ•ˆèƒ½ã€‚è¯¥æ–¹æ³•å…ˆå°†åŸå§‹æ—¥å¿—è½¬æ¢ä¸ºäº‹ä»¶IDåºåˆ—ï¼Œç„¶åä½¿ç”¨Drainè§£æå™¨ï¼Œå¹¶é‡‡ç”¨Focal LossæŸå¤±å‡½æ•°è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–åçš„GPT-2æ¨¡å‹åœ¨å…³é”®æŒ‡æ ‡ï¼ˆå¦‚ç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°ï¼‰ä¸Šæ˜¾è‘—ä¼˜äºæœªä¼˜åŒ–çš„æ¨¡å‹ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸GPT-3.5 APIç›¸å½“æˆ–æ›´å¥½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç³»ç»Ÿæ—¥å¿—ä¸­çš„å¼‚å¸¸äº‹ä»¶è¯†åˆ«æ˜¯ç½‘ç»œå®‰å…¨çš„é‡è¦éƒ¨åˆ†ã€‚</li>
<li>å½“å‰é¢ä¸´æ•°æ®é‡å¤§ã€å¼‚å¸¸åˆ†å¸ƒå’Œå¸¸è§„æ–¹æ³•ç²¾åº¦ä½çš„æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºGPTçš„æ™ºèƒ½æ£€æµ‹æ–¹æ³•æ¥æ£€æµ‹ç³»ç»Ÿæ—¥å¿—å¼‚å¸¸ã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆç»“æ„åŒ–çš„è¾“å…¥è®¾è®¡å’ŒFocal Lossä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜äº†å¼‚å¸¸æ£€æµ‹çš„æ•ˆèƒ½ã€‚</li>
<li>é€šè¿‡å°†åŸå§‹æ—¥å¿—è½¬æ¢ä¸ºäº‹ä»¶IDåºåˆ—å’Œä½¿ç”¨Drainè§£æå™¨ï¼Œå†è¿›è¡ŒFocal LossæŸå¤±å‡½æ•°å¤„ç†ï¼Œæ¥è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–åçš„GPT-2æ¨¡å‹åœ¨ç²¾åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°ç­‰å…³é”®æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.16044">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bf2d62861ff8d1135f90c73399db6005~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070409&auth_key=1761070409-0-0-bac53a5f005a239c26bc958a507360dd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-903a992a4f6adf561574440581fe7e2f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070416&auth_key=1761070416-0-0-71641cb0530b700b8d24eafa8ba37c23&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bcd7771dbb2a0bdf25e3dd0e7f5b2592~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070423&auth_key=1761070423-0-0-f5b863fe18b59036b2cdfe1e8474e449&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-00fde9e4060716cdde11ee1c87f6d22f~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070429&auth_key=1761070429-0-0-50a9ea27a7bcb99c497e283ac6f19f8f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-030193e44336523e481878668723e860~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070436&auth_key=1761070436-0-0-5f2d9ab9a42b3306906d0f236009b104&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f471396bb9058430f4a555e261f666eb~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070443&auth_key=1761070443-0-0-cd566b925e8ed038ae30fbf8a34ed9ed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Wavy-Transformer"><a href="#Wavy-Transformer" class="headerlink" title="Wavy Transformer"></a>Wavy Transformer</h2><p><strong>Authors:Satoshi Noguchi, Yoshinobu Kawahara</strong></p>
<p>Transformers have achieved remarkable success across natural language processing (NLP) and computer vision (CV). However, deep transformer models often suffer from an over-smoothing issue, in which token representations converge to similar values as they pass through successive transformer blocks. In this paper, we establish an equivalence between the hidden-state dynamics induced by stacked attention layers and graph neural diffusion on a complete graph. From this perspective, over-smoothing can be interpreted as a consequence of the dissipative nature of the underlying diffusion dynamics. Motivated by this physical interpretation, we propose Wavy Transformer, which consists of a novel attention layer based on second-order wavy dynamics. We also introduce a feed-forward network and a normalization layer designed to preserve the physical state-velocity relationship under the chain rule, thereby extending the transformer architecture. We further validate our proposed techniques on various transformer models for NLP and CV tasks. The results consistently demonstrate that Wavy Transformer improves performance with minimal additional parameters and no extra hyperparameter tuning. </p>
<blockquote>
<p>è½¬æ¢å™¨åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œè®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œæ·±åº¦è½¬æ¢å™¨æ¨¡å‹å¸¸å¸¸é¢ä¸´è¿‡åº¦å¹³æ»‘çš„é—®é¢˜ï¼Œåœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œä»¤ç‰Œè¡¨ç¤ºé€šè¿‡è¿ç»­çš„è½¬æ¢å™¨å—æ—¶æ”¶æ•›åˆ°ç›¸ä¼¼çš„å€¼ã€‚æœ¬æ–‡å»ºç«‹äº†å †å çš„æ³¨æ„åŠ›å±‚äº§ç”Ÿçš„éšè—çŠ¶æ€åŠ¨åŠ›å­¦ä¸å®Œå…¨å›¾ä¸Šçš„å›¾ç¥ç»æ‰©æ•£ä¹‹é—´çš„ç­‰ä»·å…³ç³»ã€‚ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œè¿‡åº¦å¹³æ»‘å¯ä»¥è¢«è§£é‡Šä¸ºåº•å±‚æ‰©æ•£åŠ¨åŠ›å­¦çš„è€—æ•£æ€§è´¨çš„åæœã€‚å—è¿™ç§ç‰©ç†è§£é‡Šçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†æ³¢æµªè½¬æ¢å™¨ï¼Œå®ƒåŸºäºäºŒé˜¶æ³¢æµªåŠ¨åŠ›å­¦çš„æ–°å‹æ³¨æ„åŠ›å±‚ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªå‰é¦ˆç½‘ç»œå’Œè§„èŒƒåŒ–å±‚ï¼Œæ—¨åœ¨æ ¹æ®é“¾å¼è§„åˆ™ä¿æŒç‰©ç†çŠ¶æ€é€Ÿåº¦å…³ç³»ï¼Œä»è€Œæ‰©å±•äº†è½¬æ¢å™¨çš„æ¶æ„ã€‚æˆ‘ä»¬åœ¨NLPå’ŒCVä»»åŠ¡çš„å¤šç§è½¬æ¢å™¨æ¨¡å‹ä¸Šè¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æŠ€æœ¯ã€‚ç»“æœä¸€è‡´è¡¨æ˜ï¼Œæ³¢æµªè½¬æ¢å™¨åœ¨æé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œåªéœ€æå°‘é‡çš„é¢å¤–å‚æ•°å’Œæ— éœ€é¢å¤–çš„è¶…å‚æ•°è°ƒæ•´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12787v2">PDF</a> Accepted by NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ·±åº¦Transformeræ¨¡å‹ä¸­çš„è¿‡å¹³æ»‘é—®é¢˜ï¼Œå¹¶å»ºç«‹äº†å †å æ³¨æ„åŠ›å±‚äº§ç”Ÿçš„éšè—çŠ¶æ€åŠ¨åŠ›å­¦ä¸å®Œå…¨å›¾ä¸Šçš„å›¾ç¥ç»ç½‘ç»œæ‰©æ•£ä¹‹é—´çš„ç­‰ä»·å…³ç³»ã€‚åŸºäºè¿™ç§ç‰©ç†è§£é‡Šï¼Œæœ¬æ–‡æå‡ºäº†Wavy Transformeræ¨¡å‹ï¼Œå…¶ä¸­åŒ…æ‹¬åŸºäºäºŒé˜¶æ³¢åŠ¨åŠ¨åŠ›å­¦çš„æ³¨æ„åŠ›å±‚ï¼Œå¹¶è¿›ä¸€æ­¥éªŒè¯å…¶åœ¨NLPå’ŒCVä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼ŒWavy Transformeråœ¨ä¸å¢åŠ é¢å¤–å‚æ•°å’Œæ— éœ€é¢å¤–è¶…å‚æ•°è°ƒæ•´çš„æƒ…å†µä¸‹ï¼Œèƒ½æ˜¾è‘—æé«˜æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformeræ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†æ·±åº¦Transformeræ¨¡å‹å­˜åœ¨è¿‡å¹³æ»‘é—®é¢˜ã€‚</li>
<li>è¿‡å¹³æ»‘é—®é¢˜å¯ä»¥è§£é‡Šä¸ºåº•å±‚æ‰©æ•£åŠ¨åŠ›å­¦çš„è€—æ•£æ€§è´¨çš„ç»“æœã€‚</li>
<li>æœ¬æ–‡å»ºç«‹äº†å †å æ³¨æ„åŠ›å±‚äº§ç”Ÿçš„éšè—çŠ¶æ€åŠ¨åŠ›å­¦ä¸å›¾ç¥ç»ç½‘ç»œæ‰©æ•£ä¹‹é—´çš„ç­‰ä»·å…³ç³»ã€‚</li>
<li>åŸºäºç‰©ç†è§£é‡Šï¼Œæå‡ºäº†Wavy Transformeræ¨¡å‹ï¼ŒåŒ…æ‹¬åŸºäºäºŒé˜¶æ³¢åŠ¨åŠ¨åŠ›å­¦çš„æ³¨æ„åŠ›å±‚ã€‚</li>
<li>Wavy Transformeræ‰©å±•äº†Transformeræ¶æ„ï¼Œå¹¶å¼•å…¥äº†å‰é¦ˆç½‘ç»œå’Œå½’ä¸€åŒ–å±‚ï¼Œæ—¨åœ¨ä¿æŒç‰©ç†çŠ¶æ€é€Ÿåº¦å…³ç³»ã€‚</li>
<li>åœ¨NLPå’ŒCVä»»åŠ¡ä¸ŠéªŒè¯äº†Wavy Transformerçš„æ€§èƒ½ï¼Œç»“æœè¡¨æ˜å…¶èƒ½æé«˜æ€§èƒ½ä¸”ä¸éœ€è¦å¢åŠ é¢å¤–çš„å‚æ•°å’Œè¶…å‚æ•°è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12787">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-80e2564c7e11ea68bd8547481c35a994~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070452&auth_key=1761070452-0-0-b536f5accd767c0811faedc82e621791&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d128b4f5045e1bcb3f1061584d5b2c26~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070459&auth_key=1761070459-0-0-c772168df322394020db48c77450a8f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Watch-the-Weights-Unsupervised-monitoring-and-control-of-fine-tuned-LLMs"><a href="#Watch-the-Weights-Unsupervised-monitoring-and-control-of-fine-tuned-LLMs" class="headerlink" title="Watch the Weights: Unsupervised monitoring and control of fine-tuned   LLMs"></a>Watch the Weights: Unsupervised monitoring and control of fine-tuned   LLMs</h2><p><strong>Authors:Ziqian Zhong, Aditi Raghunathan</strong></p>
<p>The releases of powerful open-weight large language models (LLMs) are often not accompanied by access to their full training data. Existing interpretability methods, particularly those based on activations, often require or assume distributionally similar data. This is a significant limitation when detecting and defending against novel potential threats like backdoors, which are by definition out-of-distribution.   In this work, we introduce a new method for understanding, monitoring and controlling fine-tuned LLMs that interprets weights, rather than activations, thereby side stepping the need for data that is distributionally similar to the unknown training data. We demonstrate that the top singular vectors of the weight difference between a fine-tuned model and its base model correspond to newly acquired behaviors. By monitoring the cosine similarity of activations along these directions, we can detect salient behaviors introduced during fine-tuning with high precision.   For backdoored models that bypasses safety mechanisms when a secret trigger is present, our method stops up to 100% of attacks with a false positive rate below 1.2%. For models that have undergone unlearning, we detect inference on erased topics with accuracy up to 95.42% and can even steer the model to recover â€œunlearnedâ€ information. Besides monitoring, our method also shows potential for pre-deployment model auditing: by analyzing commercial instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover model-specific fine-tuning focus including marketing strategies and Midjourney prompt generation.   Our implementation can be found at <a target="_blank" rel="noopener" href="https://github.com/fjzzq2002/WeightWatch">https://github.com/fjzzq2002/WeightWatch</a>. </p>
<blockquote>
<p>å¼ºå¤§çš„å¼€æ”¾æƒé‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å¸ƒé€šå¸¸ä¸ä¼šé™„å¸¦å…¶å®Œæ•´çš„è®­ç»ƒæ•°æ®ã€‚ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºæ¿€æ´»çš„æ–¹æ³•ï¼Œé€šå¸¸éœ€è¦æˆ–å‡è®¾åˆ†å¸ƒç›¸ä¼¼çš„æ•°æ®ã€‚å½“æ£€æµ‹å’Œé˜²å¾¡åé—¨ç­‰æ–°å‹æ½œåœ¨å¨èƒæ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªé‡è¦çš„é™åˆ¶ï¼Œåé—¨å¨èƒåœ¨å®šä¹‰ä¸Šå±äºåˆ†å¸ƒå¤–æ•°æ®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„ç†è§£ã€ç›‘æ§å’Œè°ƒæ•´ç²¾ç»†è°ƒæ•´è¿‡çš„LLMçš„æ–¹æ³•ï¼Œå®ƒè§£é‡Šæƒé‡è€Œä¸æ˜¯æ¿€æ´»ï¼Œä»è€Œé¿å…äº†éœ€è¦ç±»ä¼¼äºæœªçŸ¥è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒæ•°æ®ã€‚æˆ‘ä»¬è¯æ˜ï¼Œç²¾ç»†è°ƒæ•´æ¨¡å‹ä¸å…¶åŸºç¡€æ¨¡å‹ä¹‹é—´çš„æƒé‡å·®å¼‚çš„ä¸Šéƒ¨å¥‡å¼‚å‘é‡å¯¹åº”äºæ–°è·å¾—çš„è¡Œä¸ºã€‚é€šè¿‡ç›‘æµ‹è¿™äº›æ–¹å‘ä¸Šæ¿€æ´»çš„ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬å¯ä»¥é«˜ç²¾åº¦åœ°æ£€æµ‹ç²¾ç»†è°ƒæ•´è¿‡ç¨‹ä¸­å¼•å…¥çš„å…³é”®è¡Œä¸ºã€‚å¯¹äºå¸¦æœ‰ç§˜å¯†è§¦å‘æœºåˆ¶æ—¶ç»•è¿‡å®‰å…¨æœºåˆ¶çš„åé—¨æ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é˜»æ­¢é«˜è¾¾100%çš„æ”»å‡»ï¼Œè¯¯æŠ¥ç‡ä½äº1.2%ã€‚å¯¹äºå·²ç»ç»å†è¿‡é—å¿˜å­¦ä¹ çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å‡†ç¡®æ£€æµ‹åˆ°é«˜è¾¾95.42%çš„å·²åˆ é™¤ä¸»é¢˜çš„æ¨æ–­ï¼Œç”šè‡³å¯ä»¥å¼•å¯¼æ¨¡å‹æ¢å¤â€œæœªå­¦ä¹ â€çš„ä¿¡æ¯ã€‚é™¤äº†ç›‘æ§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜æ˜¾ç¤ºå‡ºåœ¨é¢„éƒ¨ç½²æ¨¡å‹å®¡è®¡æ–¹é¢çš„æ½œåŠ›ï¼šé€šè¿‡åˆ†æå•†ä¸šæŒ‡ä»¤è°ƒæ•´æ¨¡å‹ï¼ˆOLMoã€Llamaã€Qwenï¼‰ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå‘ç°ç‰¹å®šæ¨¡å‹çš„ç²¾ç»†è°ƒæ•´é‡ç‚¹ï¼ŒåŒ…æ‹¬è¥é”€ç­–ç•¥å’ŒMidjourneyæç¤ºç”Ÿæˆã€‚æˆ‘ä»¬çš„å®ç°å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/fjzzq2002/WeightWatch">https://github.com/fjzzq2002/WeightWatch</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00161v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å¸ƒé€šå¸¸ä¸é™„å¸¦å…¶å®Œæ•´è®­ç»ƒæ•°æ®çš„è®¿é—®æƒé™ã€‚ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºæ¿€æ´»çš„æ–¹æ³•ï¼Œé€šå¸¸éœ€è¦æˆ–å‡è®¾ä¸æœªçŸ¥è®­ç»ƒæ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ•°æ®ï¼Œè¿™åœ¨æ£€æµ‹å’Œé˜²èŒƒåé—¨ç­‰æ–°å‹æ½œåœ¨å¨èƒæ—¶å­˜åœ¨é‡å¤§å±€é™æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„ç†è§£ã€ç›‘æ§å’Œæ§åˆ¶å¾®è°ƒLLMçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è§£é‡Šæƒé‡è€Œä¸æ˜¯æ¿€æ´»ï¼Œä»è€Œé¿å…äº†éœ€è¦ç±»ä¼¼äºæœªçŸ¥è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒæ•°æ®ã€‚æˆ‘ä»¬è¯æ˜å¾®è°ƒæ¨¡å‹ä¸åŸºç¡€æ¨¡å‹ä¹‹é—´çš„æƒé‡å·®å¼‚çš„ä¸Šå¥‡å¼‚å‘é‡å¯¹åº”æ–°è·å¾—çš„è¡Œä¸ºã€‚é€šè¿‡ç›‘æµ‹è¿™äº›æ–¹å‘ä¸Šæ¿€æ´»çš„ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬å¯ä»¥é«˜ç²¾åº¦åœ°æ£€æµ‹å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥çš„å…³é”®è¡Œä¸ºã€‚å¯¹äºå¸¦æœ‰ç§˜å¯†è§¦å‘æœºåˆ¶çš„åé—¨æ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é˜»æ­¢é«˜è¾¾100%çš„æ”»å‡»ï¼Œè¯¯æŠ¥ç‡ä½äº1.2%ã€‚å¯¹äºå·²ç»è¿›è¡Œæœªå­¦ä¹ çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å‡†ç¡®æ£€æµ‹è¢«åˆ é™¤çš„ä¸»é¢˜çš„æ¨ç†è¿‡ç¨‹ï¼Œç”šè‡³å¯ä»¥å¼•å¯¼æ¨¡å‹æ¢å¤â€œæœªå­¦ä¹ â€çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜æ˜¾ç¤ºå‡ºåœ¨éƒ¨ç½²å‰è¿›è¡Œæ¨¡å‹å®¡è®¡çš„æ½œåŠ›ï¼šé€šè¿‡åˆ†æå•†ä¸šæŒ‡ä»¤è°ƒæ•´æ¨¡å‹ï¼ˆOLMoã€Llamaã€Qwenï¼‰ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå‘ç°ç‰¹å®šæ¨¡å‹çš„å¾®è°ƒé‡ç‚¹ï¼ŒåŒ…æ‹¬è¥é”€ç­–ç•¥å’ŒMidjourneyæç¤ºç”Ÿæˆç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰LLMçš„å¯è§£é‡Šæ€§æ–¹æ³•å—é™äºéœ€è¦åˆ†å¸ƒç›¸ä¼¼æ•°æ®ï¼Œéš¾ä»¥åº”å¯¹æ–°å‹å¨èƒå¦‚åé—¨æ”»å‡»ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºæƒé‡è§£é‡Šçš„æ–°æ–¹æ³•ï¼Œç»•è¿‡å¯¹åˆ†å¸ƒç›¸ä¼¼æ•°æ®çš„éœ€è¦ã€‚</li>
<li>é€šè¿‡ç›‘æµ‹ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œå¯é«˜ç²¾åº¦æ£€æµ‹å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥çš„å…³é”®è¡Œä¸ºã€‚</li>
<li>å¯¹åé—¨æ”»å‡»çš„æ£€æµ‹ç‡å¯è¾¾100%ï¼Œè¯¯æŠ¥ç‡ä½äº1.2%ã€‚</li>
<li>èƒ½å¤Ÿæ£€æµ‹æœªå­¦ä¹ æ¨¡å‹çš„å·²åˆ é™¤ä¸»é¢˜æ¨ç†ï¼Œå¹¶å¼•å¯¼æ¨¡å‹æ¢å¤æœªå­¦ä¹ ä¿¡æ¯ã€‚</li>
<li>æ–¹æ³•å…·æœ‰æ½œåœ¨ç”¨äºéƒ¨ç½²å‰æ¨¡å‹å®¡è®¡çš„èƒ½åŠ›ï¼Œå¯å‘ç°ç‰¹å®šæ¨¡å‹çš„å¾®è°ƒé‡ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00161">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d9775c36db6020b1ffaa4eeb12ae8d14~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070466&auth_key=1761070466-0-0-9a8a24acee850b0fd8e8e48cf9fca8cb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d89be6f921dc2349abbd82a50315f1a3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070473&auth_key=1761070473-0-0-c423a0c05e9a0e92dce7ea61dd8267e9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9df9817a329fda1ea24c261eb8175ac4~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070480&auth_key=1761070480-0-0-3230577e93e54c8fe6784e7fd42cea51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-143b433846d1688f1c9000723ac5e052~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070486&auth_key=1761070486-0-0-11a8f3a308e21ea0b539865e2bb35a93&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="From-Sequence-to-Structure-Uncovering-Substructure-Reasoning-in-Transformers"><a href="#From-Sequence-to-Structure-Uncovering-Substructure-Reasoning-in-Transformers" class="headerlink" title="From Sequence to Structure: Uncovering Substructure Reasoning in   Transformers"></a>From Sequence to Structure: Uncovering Substructure Reasoning in   Transformers</h2><p><strong>Authors:Xinnan Dai, Kai Yang, Jay Revolinsky, Kai Guo, Aoran Wang, Bohang Zhang, Jiliang Tang</strong></p>
<p>Recent studies suggest that large language models (LLMs) possess the capability to solve graph reasoning tasks. Notably, even when graph structures are embedded within textual descriptions, LLMs can still effectively answer related questions. This raises a fundamental question: How can a decoder-only Transformer architecture understand underlying graph structures? To address this, we start with the substructure extraction task, interpreting the inner mechanisms inside the transformers and analyzing the impact of the input queries. Specifically, through both empirical results and theoretical analysis, we present Induced Substructure Filtration (ISF), a perspective that captures the substructure identification in the multi-layer transformers. We further validate the ISF process in LLMs, revealing consistent internal dynamics across layers. Building on these insights, we explore the broader capabilities of Transformers in handling diverse graph types. Specifically, we introduce the concept of thinking in substructures to efficiently extract complex composite patterns, and demonstrate that decoder-only Transformers can successfully extract substructures from attributed graphs, such as molecular graphs. Together, our findings offer a new insight on how sequence-based Transformers perform the substructure extraction task over graph data. </p>
<blockquote>
<p>æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡è§£å†³å›¾å½¢æ¨ç†ä»»åŠ¡çš„èƒ½åŠ›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿åœ¨æ–‡æœ¬æè¿°ä¸­åµŒå…¥å›¾å½¢ç»“æ„ï¼ŒLLMä»ç„¶å¯ä»¥æœ‰æ•ˆåœ°å›ç­”ç›¸å…³é—®é¢˜ã€‚è¿™å¼•å‘äº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„é—®é¢˜ï¼šä»…ä»…è§£ç çš„Transformeræ¶æ„æ˜¯å¦‚ä½•ç†è§£æ½œåœ¨çš„å›¾å½¢ç»“æ„çš„ï¼Ÿä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬ä»å­ç»“æ„æå–ä»»åŠ¡å¼€å§‹ï¼Œè§£è¯»Transformerå†…éƒ¨æœºåˆ¶ï¼Œå¹¶åˆ†æè¾“å…¥æŸ¥è¯¢çš„å½±å“ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡å®è¯ç»“æœå’Œç†è®ºåˆ†æï¼Œæå‡ºäº†è¯±å¯¼å­ç»“æ„è¿‡æ»¤ï¼ˆISFï¼‰çš„è§‚ç‚¹ï¼Œè¯¥è§‚ç‚¹æ•æ‰äº†å¤šå±‚Transformerä¸­çš„å­ç»“æ„è¯†åˆ«ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥éªŒè¯äº†LLMä¸­çš„ISFè¿‡ç¨‹ï¼Œæ­ç¤ºäº†è·¨å±‚çš„å†…éƒ¨åŠ¨æ€ä¸€è‡´æ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æ¢ç´¢äº†Transformerå¤„ç†ä¸åŒç±»å‹å›¾è¡¨çš„æ›´å¹¿æ³›èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†å­ç»“æ„æ€ç»´çš„æ¦‚å¿µï¼Œä»¥æœ‰æ•ˆåœ°æå–å¤æ‚çš„ç»„åˆæ¨¡å¼ï¼Œå¹¶è¯æ˜ä»…è§£ç çš„Transformerå¯ä»¥æˆåŠŸåœ°ä»å±æ€§å›¾ä¸­æå–å­ç»“æ„ï¼Œä¾‹å¦‚åˆ†å­å›¾ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸ºåŸºäºåºåˆ—çš„Transformerå¦‚ä½•åœ¨å›¾å½¢æ•°æ®ä¸Šæ‰§è¡Œå­ç»“æ„æå–ä»»åŠ¡æä¾›äº†æ–°çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.10435v2">PDF</a> Camera Ready version for Neurips 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡è§£å†³å›¾å½¢æ¨ç†ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå³ä½¿å›¾å½¢ç»“æ„åµŒå…¥åœ¨æ–‡æœ¬æè¿°ä¸­ï¼Œä¹Ÿèƒ½æœ‰æ•ˆåœ°å›ç­”é—®é¢˜ã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•é€šè¿‡ä¸€ä¸ªä»…åŒ…å«è§£ç å™¨çš„Transformeræ¶æ„ç†è§£æ½œåœ¨å›¾å½¢ç»“æ„çš„é—®é¢˜ï¼Œé€šè¿‡å­ç»“æ„æå–ä»»åŠ¡æ¥è§£è¯»Transformerå†…éƒ¨æœºåˆ¶ï¼Œå¹¶åˆ†æäº†è¾“å…¥æŸ¥è¯¢çš„å½±å“ã€‚æå‡ºäº†Induced Substructure Filtrationï¼ˆISFï¼‰çš„è§†è§’ï¼Œæ¥æ•æ‰å¤šå±‚Transformerä¸­çš„å­ç»“æ„è¯†åˆ«ã€‚é€šè¿‡éªŒè¯ISFåœ¨LLMä¸­çš„è¿‡ç¨‹ï¼Œå‘ç°å…¶åœ¨å„å±‚ä¹‹é—´å…·æœ‰ä¸€è‡´çš„å†…éƒ¨åŠ¨æ€ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æ¢è®¨äº†Transformerå¤„ç†ä¸åŒç±»å‹å›¾æ•°æ®çš„æ½œåŠ›ï¼Œå¼•å…¥äº†å­ç»“æ„æ€ç»´çš„æ¦‚å¿µï¼Œå¹¶å±•ç¤ºäº†ä»…è§£ç å™¨TransformeræˆåŠŸä»å±æ€§å›¾ï¼ˆå¦‚åˆ†å­å›¾ï¼‰ä¸­æå–å­ç»“æ„çš„èƒ½åŠ›ã€‚è¿™äº›å‘ç°æä¾›äº†åºåˆ—åŸºäºTransformeråœ¨å›¾å½¢æ•°æ®ä¸Šè¿›è¡Œå­ç»“æ„æå–ä»»åŠ¡çš„æ–°è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥å¤„ç†å›¾å½¢æ¨ç†ä»»åŠ¡ï¼Œå³ä½¿å›¾å½¢ç»“æ„éšè—åœ¨æ–‡æœ¬æè¿°ä¸­ä¹Ÿèƒ½æœ‰æ•ˆå›ç­”ç›¸å…³é—®é¢˜ã€‚</li>
<li>LLMé€šè¿‡å­ç»“æ„æå–ä»»åŠ¡ç†è§£æ½œåœ¨å›¾å½¢ç»“æ„ï¼Œè¿™éœ€è¦è§£è¯»Transformerçš„å†…éƒ¨æœºåˆ¶ã€‚</li>
<li>Induced Substructure Filtrationï¼ˆISFï¼‰è§†è§’æœ‰åŠ©äºæ•æ‰å¤šå±‚Transformerä¸­çš„å­ç»“æ„è¯†åˆ«ã€‚</li>
<li>LLMä¸­çš„ISFè¿‡ç¨‹åœ¨å„å±‚ä¹‹é—´å…·æœ‰ä¸€è‡´çš„å†…éƒ¨åŠ¨æ€ã€‚</li>
<li>Transformeræ¶æ„å…·æœ‰å¤„ç†ä¸åŒç±»å‹å›¾æ•°æ®çš„èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡å¼•å…¥å­ç»“æ„æ€ç»´ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°ä»å±æ€§å›¾ä¸­æå–å¤æ‚å¤åˆæ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.10435">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ddd93d488bcad6e78a73acf5a98c992c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070493&auth_key=1761070493-0-0-5265c68a3d573a2b2871968b74c916c9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-55ca0f253ba1f948588c88f80de1fe5b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070501&auth_key=1761070501-0-0-c788d9f9485c66f6f2894c9a861e51cb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5763f7a9f1142bb52540c629414b3c30~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070507&auth_key=1761070507-0-0-2e2ebbac6b8553ca5edd6d3f5bf2a6a5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b0454c28ac12f3ebffe5ab752f866e4c~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070514&auth_key=1761070514-0-0-7b65b4507274b2572d53b6fb2d7c5a76&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f13b978fdf430bbf5d2b0413d7d47ace~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070520&auth_key=1761070520-0-0-25bd686f061c097369406d551105623f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Forecasting-Clinical-Risk-from-Textual-Time-Series-Structuring-Narratives-for-Temporal-AI-in-Healthcare"><a href="#Forecasting-Clinical-Risk-from-Textual-Time-Series-Structuring-Narratives-for-Temporal-AI-in-Healthcare" class="headerlink" title="Forecasting Clinical Risk from Textual Time Series: Structuring   Narratives for Temporal AI in Healthcare"></a>Forecasting Clinical Risk from Textual Time Series: Structuring   Narratives for Temporal AI in Healthcare</h2><p><strong>Authors:Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss</strong></p>
<p>Clinical case reports encode temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings â€“ extracted via an LLM-assisted annotation pipeline â€“ serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use. </p>
<blockquote>
<p>ä¸´åºŠç—…ä¾‹æŠ¥å‘Šæè¿°äº†æ‚£è€…çš„æ—¶åºè½¨è¿¹ï¼Œè¿™äº›è½¨è¿¹å¸¸å¸¸è¢«ä¾èµ–ç»“æ„åŒ–æ•°æ®çš„ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•æ‰€å¿½è§†ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»æ–‡æœ¬æ—¶é—´åºåˆ—ä¸­å¼•å…¥äº†é¢„æµ‹é—®é¢˜ï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©çš„æ³¨é‡Šç®¡é“æå–çš„æ—¶é—´æˆ³ä¸´åºŠå‘ç°ä½œä¸ºé¢„æµ‹çš„ä¸»è¦è¾“å…¥ã€‚æˆ‘ä»¬å¯¹ä¸€ç³»åˆ—æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼ŒåŒ…æ‹¬å¾®è°ƒè¿‡çš„åŸºäºè§£ç å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹å’ŒåŸºäºç¼–ç å™¨çš„è½¬æ¢å™¨ï¼Œç”¨äºäº‹ä»¶å‘ç”Ÿçš„é¢„æµ‹ã€æ—¶é—´é¡ºåºå’Œç”Ÿå­˜åˆ†æä»»åŠ¡ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºç¼–ç å™¨çš„æ¨¡å‹åœ¨çŸ­æœŸå’Œé•¿æœŸäº‹ä»¶é¢„æµ‹ä¸­å§‹ç»ˆè·å¾—æ›´é«˜çš„F1åˆ†æ•°å’Œä¼˜è¶Šçš„æ—¶é—´ä¸€è‡´æ€§ï¼Œè€Œå¾®è°ƒè¿‡çš„æ©ç æ–¹æ³•æé«˜äº†æ’åæ€§èƒ½ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç»è¿‡æŒ‡ä»¤è®­ç»ƒçš„è§£ç å™¨æ¨¡å‹åœ¨ç”Ÿå­˜åˆ†æä¸­æ˜¾ç¤ºå‡ºç›¸å¯¹ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸé¢„åè®¾ç½®ä¸­ã€‚æˆ‘ä»¬çš„æ•æ„Ÿæ€§åˆ†æè¿›ä¸€æ­¥è¡¨æ˜æ—¶é—´é¡ºåºçš„é‡è¦æ€§ï¼Œè¿™éœ€è¦ä¸´åºŠæ—¶é—´åºåˆ—çš„æ„å»ºï¼Œä¸æ–‡æœ¬é¡ºåºï¼ˆå³LLMç»å…¸è®­ç»ƒæ–‡æœ¬è¾“å…¥æ ¼å¼ï¼‰ç›¸å¯¹æ¯”ã€‚è¿™çªå‡ºäº†æœ‰åºè¯­æ–™åº“æ‰€èƒ½å¸¦æ¥çš„é¢å¤–å¥½å¤„ï¼Œå¯¹å¹¿æ³›ä½¿ç”¨LLMçš„æ—¶ä»£çš„æ—¶é—´ä»»åŠ¡å…·æœ‰æŒ‡å¯¼æ„ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10340v4">PDF</a> AAAI AI for Social Impact 2026. Shahriar Noroozizadeh, Sayantan Kumar   (authors contributed equally)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸´åºŠç—…ä¾‹æŠ¥å‘Šä¸­çš„æ—¶é—´æ‚£è€…è½¨è¿¹ï¼Œè¿™äº›è½¨è¿¹å¸¸å¸¸è¢«ä¼ ç»Ÿä¾èµ–ç»“æ„åŒ–æ•°æ®çš„æœºå™¨å­¦ä¹ æ–¹æ³•æ‰€å¿½è§†ã€‚ç ”ç©¶å¼•å…¥äº†æ–‡æœ¬æ—¶é—´åºåˆ—çš„é¢„æµ‹é—®é¢˜ï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¾…åŠ©çš„æ³¨é‡Šç®¡é“æå–çš„æ—¶é—´æˆ³ä¸´åºŠå‘ç°ä½œä¸ºä¸»è¦é¢„æµ‹è¾“å…¥ã€‚é€šè¿‡ç³»ç»Ÿåœ°è¯„ä¼°å„ç§æ¨¡å‹ï¼ŒåŒ…æ‹¬å¾®è°ƒåçš„åŸºäºè§£ç å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹å’ŒåŸºäºç¼–ç å™¨çš„è½¬æ¢å™¨ï¼Œæœ¬ç ”ç©¶åœ¨äº‹ä»¶å‘ç”Ÿçš„é¢„æµ‹ã€æ—¶é—´é¡ºåºå’Œç”Ÿå­˜åˆ†æä»»åŠ¡ä¸Šå‘ç°åŸºäºç¼–ç å™¨çš„æ¨¡å‹å…·æœ‰æ›´é«˜çš„F1åˆ†æ•°å’Œè‰¯å¥½çš„æ—¶é—´ä¸€è‡´æ€§ï¼Œå¯¹äºçŸ­æœŸå’Œé•¿æœŸäº‹ä»¶é¢„æµ‹å§‹ç»ˆè¡¨ç°ä¼˜å¼‚ï¼Œè€Œç»è¿‡å¾®è°ƒçš„æ©ç æ–¹æ³•åˆ™æé«˜äº†æ’åæ€§èƒ½ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç»è¿‡æŒ‡ä»¤è®­ç»ƒçš„è§£ç å™¨æ¨¡å‹åœ¨ç”Ÿå­˜åˆ†æä¸­æ˜¾ç¤ºå‡ºç›¸å¯¹ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸé¢„åç¯å¢ƒä¸­ã€‚æ•æ„Ÿæ€§åˆ†æè¿›ä¸€æ­¥å¼ºè°ƒäº†æ—¶é—´é¡ºåºçš„é‡è¦æ€§ï¼Œè¿™éœ€è¦ä¸´åºŠæ—¶é—´åºåˆ—çš„æ„å»ºï¼Œä¸ä¼ ç»Ÿçš„LLMè®­ç»ƒæ–‡æœ¬è¾“å…¥æ ¼å¼ç›¸æ¯”ï¼Œæ—¶é—´é¡ºåºçš„è¦æ±‚æ˜¯ä¸€ä¸ªäº®ç‚¹ï¼Œè¿™å¯¹å¹¿æ³›é‡‡ç”¨LLMçš„æ—¶ä»£çš„æ—¶é—´ä»»åŠ¡å…·æœ‰å¯ç¤ºæ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸´åºŠç—…ä¾‹æŠ¥å‘Šä¸­çš„æ—¶é—´æ‚£è€…è½¨è¿¹å¸¸å¸¸è¢«ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•å¿½è§†ã€‚</li>
<li>æ–‡æœ¬æ—¶é—´åºåˆ—é¢„æµ‹é—®é¢˜è¢«å¼•å…¥ï¼Œä½¿ç”¨LLMè¾…åŠ©çš„æ³¨é‡Šç®¡é“æå–çš„æ—¶é—´æˆ³ä¸´åºŠå‘ç°ä½œä¸ºé¢„æµ‹çš„ä¸»è¦è¾“å…¥ã€‚</li>
<li>åŸºäºç¼–ç å™¨çš„æ¨¡å‹åœ¨äº‹ä»¶é¢„æµ‹ã€æ—¶é—´é¡ºåºå’Œç”Ÿå­˜åˆ†æä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰æ›´é«˜çš„F1åˆ†æ•°å’Œè‰¯å¥½çš„æ—¶é—´ä¸€è‡´æ€§ã€‚</li>
<li>ç»è¿‡å¾®è°ƒçš„æ©ç æ–¹æ³•æé«˜äº†æ’åæ€§èƒ½ã€‚</li>
<li>æŒ‡ä»¤è®­ç»ƒçš„è§£ç å™¨æ¨¡å‹åœ¨ç”Ÿå­˜åˆ†æä¸­ç›¸å¯¹ä¼˜åŠ¿æ˜¾è‘—ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—©æœŸé¢„åç¯å¢ƒä¸­ã€‚</li>
<li>æ—¶é—´é¡ºåºåœ¨ä¸´åºŠæ—¶é—´åºåˆ—çš„æ„å»ºä¸­è‡³å…³é‡è¦ï¼Œä¸LLMä¼ ç»Ÿè®­ç»ƒçš„æ–‡æœ¬è¾“å…¥æ ¼å¼ä¸åŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10340">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-95b36bd03175f5bf088a3359a41edc0b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070533&auth_key=1761070533-0-0-2ffd61433a21ad14535ec99732a6cfa2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e67793a9c10dd84efca48f4651b6bc7b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070541&auth_key=1761070541-0-0-45cb40454b9dc93022082e9b75b34785&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f94f573c7d9097d16d868e102536aa43~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070548&auth_key=1761070548-0-0-f04852d33fd3a9c2e07fcbe48041f54e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e690b439f0dfbc0ca0df4cf4ab60561b~resize:0:q75.jpg?source=1f5c5e47&expiration=1761070555&auth_key=1761070555-0-0-605995d0d214e883495bc2e085c62b79&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-22/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-765b2c580bd75d3c2ff645416ea2a085~resize:0:q75.jpg?source=1f5c5e47&expiration=1761071592&auth_key=1761071592-0-0-48b2a6d495dbc2f66fbaf8ea777efb0b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  Enterprise Deep Research Steerable Multi-Agent Deep Research for   Enterprise Analytics
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-22/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-cdfb4915883ab6c25cc150a33c2ea3f3~resize:0:q75.jpg?source=1f5c5e47&expiration=1761068879&auth_key=1761068879-0-0-a927a61fddc6d89b6187211df259f2a8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-22  Robobench A Comprehensive Evaluation Benchmark for Multimodal Large   Language Models as Embodied Brain
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32127.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
