<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
    <meta name="description" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  MixedGaussianAvatar Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>å…ƒå®‡å®™/è™šæ‹Ÿäºº | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-ba1148f524c897fed52125ae4e1dc003.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                å…ƒå®‡å®™/è™šæ‹Ÿäºº
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-11-æ›´æ–°"><a href="#2024-12-11-æ›´æ–°" class="headerlink" title="2024-12-11 æ›´æ–°"></a>2024-12-11 æ›´æ–°</h1><h2 id="MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting"><a href="#MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting" class="headerlink" title="MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting"></a>MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting</h2><p><strong>Authors:Peng Chen, Xiaobao Wei, Qingpo Wuwu, Xinyi Wang, Xingyu Xiao, Ming Lu</strong></p>
<p>Reconstructing high-fidelity 3D head avatars is crucial in various applications such as virtual reality. The pioneering methods reconstruct realistic head avatars with Neural Radiance Fields (NeRF), which have been limited by training and rendering speed. Recent methods based on 3D Gaussian Splatting (3DGS) significantly improve the efficiency of training and rendering. However, the surface inconsistency of 3DGS results in subpar geometric accuracy; later, 2DGS uses 2D surfels to enhance geometric accuracy at the expense of rendering fidelity. To leverage the benefits of both 2DGS and 3DGS, we propose a novel method named MixedGaussianAvatar for realistically and geometrically accurate head avatar reconstruction. Our main idea is to utilize 2D Gaussians to reconstruct the surface of the 3D head, ensuring geometric accuracy. We attach the 2D Gaussians to the triangular mesh of the FLAME model and connect additional 3D Gaussians to those 2D Gaussians where the rendering quality of 2DGS is inadequate, creating a mixed 2D-3D Gaussian representation. These 2D-3D Gaussians can then be animated using FLAME parameters. We further introduce a progressive training strategy that first trains the 2D Gaussians and then fine-tunes the mixed 2D-3D Gaussians. We demonstrate the superiority of MixedGaussianAvatar through comprehensive experiments. The code will be released at: <a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>. </p>
<blockquote>
<p>é‡å»ºé«˜ä¿çœŸ3Då¤´åƒåœ¨è™šæ‹Ÿç°å®ç­‰å„ç§åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚å‰æ²¿æ–¹æ³•ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é‡å»ºé€¼çœŸçš„å¤´åƒï¼Œä½†å—é™äºè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„è¿‘æœŸæ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“çš„æ•ˆç‡ã€‚ç„¶è€Œï¼Œ3DGSçš„è¡¨é¢ä¸ä¸€è‡´å¯¼è‡´å‡ ä½•ç²¾åº¦ä¸ä½³ï¼›åæ¥çš„2DGSä½¿ç”¨2Dè¡¨é¢å…ƒç´ ä»¥æé«˜å‡ ä½•ç²¾åº¦ï¼Œä½†ç‰ºç‰²äº†æ¸²æŸ“ä¿çœŸåº¦ã€‚ä¸ºäº†ç»“åˆ2DGSå’Œ3DGSçš„ä¼˜ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMixedGaussianAvatarçš„æ–°æ–¹æ³•ï¼Œç”¨äºè¿›è¡ŒçœŸå®ä¸”å‡ ä½•å‡†ç¡®çš„å¤´åƒé‡å»ºã€‚æˆ‘ä»¬çš„ä¸»è¦æ€æƒ³æ˜¯ä½¿ç”¨2Dé«˜æ–¯é‡å»º3Då¤´åƒçš„è¡¨é¢ï¼Œä»¥ç¡®ä¿å‡ ä½•ç²¾åº¦ã€‚æˆ‘ä»¬å°†2Dé«˜æ–¯é™„åŠ åˆ°FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼ä¸Šï¼Œå¹¶åœ¨2DGSçš„æ¸²æŸ“è´¨é‡ä¸è¶³çš„åœ°æ–¹è¿æ¥åˆ°é¢å¤–çš„3Dé«˜æ–¯ï¼Œåˆ›å»ºæ··åˆçš„2D-3Dé«˜æ–¯è¡¨ç¤ºã€‚è¿™äº›2D-3Dé«˜æ–¯å¯ä»¥ä½¿ç”¨FLAMEå‚æ•°è¿›è¡ŒåŠ¨ç”»è®¾ç½®ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§é€æ­¥è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒ2Dé«˜æ–¯ï¼Œç„¶åå¯¹æ··åˆçš„2D-3Dé«˜æ–¯è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡å…¨é¢çš„å®éªŒè¯æ˜äº†MixedGaussianAvatarçš„ä¼˜åŠ¿ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>ç®€åŒ–è§£é‡Š</strong></p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04955v1">PDF</a> Project: <a target="_blank" rel="noopener" href="https://chenvoid.github.io/MGA/">https://chenvoid.github.io/MGA/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†åœ¨è™šæ‹Ÿç°å®ä¸­é‡å»ºé«˜ä¿çœŸ3Då¤´åƒçš„é‡è¦æ€§ï¼Œä»¥åŠé‡‡ç”¨ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰å’ŒåŸºäºä¸‰ç»´é«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰çš„æ–¹æ³•åœ¨é‡å»ºçœŸå®å¤´åƒæ–¹é¢çš„è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨è®­ç»ƒä¸æ¸²æŸ“é€Ÿåº¦çš„é™åˆ¶ä»¥åŠå‡ ä½•ç²¾åº¦é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMixedGaussianAvatarçš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨äºŒç»´é«˜æ–¯é‡å»ºä¸‰ç»´å¤´éƒ¨çš„è¡¨é¢ï¼Œä¿è¯äº†å‡ ä½•ç²¾åº¦ï¼ŒåŒæ—¶å¼•å…¥äº†æ··åˆçš„äºŒç»´-ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œå¹¶å¯ä»¥é€šè¿‡FLAMEå‚æ•°è¿›è¡ŒåŠ¨ç”»æ¸²æŸ“ã€‚é€šè¿‡æ¸è¿›å¼è®­ç»ƒç­–ç•¥è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ã€‚æœ€ç»ˆé€šè¿‡å®éªŒè¯æ˜äº†MixedGaussianAvatarçš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å»ºé«˜ä¿çœŸ3Då¤´åƒåœ¨è™šæ‹Ÿç°å®ç­‰åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰æ–¹æ³•å¦‚NeRFå’Œ3DGSåœ¨é‡å»ºçœŸå®å¤´åƒæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¦‚è®­ç»ƒä¸æ¸²æŸ“é€Ÿåº¦ã€å‡ ä½•ç²¾åº¦é—®é¢˜ã€‚</li>
<li>MixedGaussianAvataræ–¹æ³•ç»“åˆäº†2DGSå’Œ3DGSçš„ä¼˜ç‚¹ï¼Œæ—¨åœ¨å®ç°çœŸå®ä¸”å‡ ä½•å‡†ç¡®çš„å¤´åƒé‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨äºŒç»´é«˜æ–¯é‡å»ºä¸‰ç»´å¤´éƒ¨è¡¨é¢ï¼ŒåŒæ—¶å¼•å…¥æ··åˆçš„äºŒç»´-ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡è¿æ¥FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼å’Œé™„åŠ çš„ä¸‰ç»´é«˜æ–¯ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡ã€‚</li>
<li>é‡‡ç”¨æ¸è¿›å¼è®­ç»ƒç­–ç•¥è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-34f42332d014b46369069fd2d1d3a994.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0ef5787956810f1e111d21adf0bdcf5c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ce4f964cf25207a6db5a28f7f85bd755.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a7e93cc4f1cccfe010d043da886dc390.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5d0573a7ab1441e50500057923302b87.jpg" align="middle">
</details>




<h2 id="PBDyG-Position-Based-Dynamic-Gaussians-for-Motion-Aware-Clothed-Human-Avatars"><a href="#PBDyG-Position-Based-Dynamic-Gaussians-for-Motion-Aware-Clothed-Human-Avatars" class="headerlink" title="PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars"></a>PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars</h2><p><strong>Authors:Shota Sasaki, Jane Wu, Ko Nishino</strong></p>
<p>This paper introduces a novel clothed human model that can be learned from multiview RGB videos, with a particular emphasis on recovering physically accurate body and cloth movements. Our method, Position Based Dynamic Gaussians (PBDyG), realizes <code>movement-dependent&#39;&#39; cloth deformation via physical simulation, rather than merely relying on </code>pose-dependentâ€™â€™ rigid transformations. We model the clothed human holistically but with two distinct physical entities in contact: clothing modeled as 3D Gaussians, which are attached to a skinned SMPL body that follows the movement of the person in the input videos. The articulation of the SMPL body also drives physically-based simulation of the clothesâ€™ Gaussians to transform the avatar to novel poses. In order to run position based dynamics simulation, physical properties including mass and material stiffness are estimated from the RGB videos through Dynamic 3D Gaussian Splatting. Experiments demonstrate that our method not only accurately reproduces appearance but also enables the reconstruction of avatars wearing highly deformable garments, such as skirts or coats, which have been challenging to reconstruct using existing methods. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å¯ä»¥ä»å¤šè§†è§’RGBè§†é¢‘ä¸­å­¦ä¹ çš„æ–°å‹ç©¿è¡£äººä½“æ¨¡å‹ï¼Œç‰¹åˆ«ä¾§é‡äºæ¢å¤ç‰©ç†ä¸Šå‡†ç¡®çš„èº«ä½“å’Œè¡£ç‰©è¿åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒåŸºäºä½ç½®åŠ¨æ€é«˜æ–¯ï¼ˆPBDyGï¼‰ï¼Œé€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå®ç°â€œè¿åŠ¨ç›¸å…³â€çš„è¡£ç‰©å˜å½¢ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–â€œå§¿æ€ç›¸å…³â€çš„åˆšæ€§å˜æ¢ã€‚æˆ‘ä»¬å¯¹ç©¿è¡£äººä½“è¿›è¡Œæ•´ä½“å»ºæ¨¡ï¼Œä½†æ¥è§¦çš„ä¸¤ä¸ªç‰©ç†å®ä½“æ˜¯ç‹¬ç‰¹çš„ï¼šå°†è¡£ç‰©å»ºæ¨¡ä¸ºä¸‰ç»´é«˜æ–¯ï¼Œé™„ç€åœ¨è·Ÿéšè¾“å…¥è§†é¢‘äººç‰©åŠ¨ä½œçš„å¸¦çš®è‚¤SMPLèº«ä½“ä¸Šã€‚SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨è¿˜é©±åŠ¨è¡£ç‰©é«˜æ–¯åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿï¼Œå°†è§’è‰²å˜å½¢ä¸ºæ–°çš„å§¿åŠ¿ã€‚ä¸ºäº†è¿è¡ŒåŸºäºä½ç½®çš„åŠ¨æ€æ¨¡æ‹Ÿï¼Œç‰©ç†ç‰¹æ€§åŒ…æ‹¬è´¨é‡å’Œææ–™åˆšåº¦æ˜¯é€šè¿‡åŠ¨æ€ä¸‰ç»´é«˜æ–¯å–·ç»˜ä»RGBè§†é¢‘ä¸­ä¼°è®¡å‡ºæ¥çš„ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å‡†ç¡®åœ°å†ç°äº†å¤–è§‚ï¼Œè¿˜å®ç°äº†å¯¹ç©¿ç€é«˜åº¦å¯å˜å½¢æœè£…çš„è§’è‰²é‡å»ºï¼Œå¦‚è£™å­æˆ–å¤–å¥—ï¼Œè¿™åœ¨ä»¥å‰çš„æ–¹æ³•ä¸­ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04433v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹ç©¿è¡£äººä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»å¤šè§’åº¦RGBè§†é¢‘ä¸­å­¦ä¹ ï¼Œå¹¶ç‰¹åˆ«é‡è§†æ¢å¤ç‰©ç†å‡†ç¡®çš„èº«ä½“å’Œè¡£ç‰©åŠ¨ä½œã€‚é€šè¿‡åŸºäºä½ç½®çš„åŠ¨æ€é«˜æ–¯æ–¹æ³•ï¼Œå®ç°äº†é€šè¿‡ç‰©ç†æ¨¡æ‹Ÿçš„â€œåŠ¨ä½œç›¸å…³â€è¡£ç‰©å˜å½¢ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–äºâ€œå§¿åŠ¿ç›¸å…³â€çš„åˆšæ€§å˜æ¢ã€‚è¯¥æ¨¡å‹å°†ç©¿è¡£çš„äººä½“è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œä½†åˆ†ä¸ºä¸¤ä¸ªæ¥è§¦çš„ç‰©ç†å®ä½“ï¼šè¡£ç‰©è¢«è§†ä¸ºä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼Œé™„ç€åœ¨éšè¾“å…¥è§†é¢‘äººç‰©åŠ¨ä½œè€Œå˜åŒ–çš„çš®è‚¤åŒ–SMPLèº«ä½“ä¸Šã€‚SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨ä¹Ÿé©±åŠ¨è¡£ç‰©çš„åŸºäºç‰©ç†çš„é«˜æ–¯æ¨¡æ‹Ÿï¼Œå°†è§’è‰²è½¬æ¢ä¸ºæ–°çš„å§¿åŠ¿ã€‚ä¸ºäº†è¿è¡ŒåŸºäºä½ç½®çš„åŠ¨æ€æ¨¡æ‹Ÿï¼Œé€šè¿‡åŠ¨æ€ä¸‰ç»´é«˜æ–¯æ¨¡æ¿ä»RGBè§†é¢‘ä¸­ä¼°è®¡è´¨é‡ã€ææ–™åˆšåº¦ç­‰ç‰©ç†å±æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…å‡†ç¡®è¿˜åŸå¤–è§‚ï¼Œè¿˜èƒ½é‡å»ºç©¿ç€é«˜åº¦å¯å˜å½¢æœè£…çš„è§’è‰²ï¼Œå¦‚è£™å­æˆ–å¤–å¥—ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç©¿è¡£äººä½“æ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œå¯ä»å¤šè§’åº¦RGBè§†é¢‘ä¸­å­¦ä¹ å¹¶å»ºç«‹ç‰©ç†å‡†ç¡®çš„åŠ¨ä½œæ¨¡å‹ã€‚</li>
<li>åˆ©ç”¨åŸºäºä½ç½®çš„åŠ¨æ€é«˜æ–¯ï¼ˆPBDyGï¼‰æ–¹æ³•å®ç°ç‰©ç†æ¨¡æ‹Ÿçš„è¡£ç‰©å˜å½¢ã€‚</li>
<li>å°†ç©¿è¡£çš„äººä½“è§†ä¸ºæ•´ä½“ï¼Œåˆ†ä¸ºä¸¤ä¸ªæ¥è§¦çš„ç‰©ç†å®ä½“ï¼šè¡£ç‰©å’Œçš®è‚¤åŒ–SMPLèº«ä½“ã€‚</li>
<li>SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨é©±åŠ¨è¡£ç‰©çš„ç‰©ç†æ¨¡æ‹Ÿã€‚</li>
<li>é€šè¿‡åŠ¨æ€ä¸‰ç»´é«˜æ–¯æ¨¡æ¿ä»RGBè§†é¢‘ä¸­ä¼°è®¡ç‰©ç†å±æ€§ï¼Œå¦‚è´¨é‡å’Œææ–™åˆšåº¦ã€‚</li>
<li>æ–¹æ³•èƒ½å‡†ç¡®è¿˜åŸå¤–è§‚å¹¶é‡å»ºé«˜åº¦å¯å˜å½¢æœè£…çš„è§’è‰²ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2d1711cfeb4aa545688bd82288fe4ba5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-325bb7409947b2356cc510d3fabf325b.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-082105f475afd440dabb10a54eb43e99.jpg" align="middle">
</details>




<h2 id="A-multidimensional-measurement-of-photorealistic-avatar-quality-of-experience"><a href="#A-multidimensional-measurement-of-photorealistic-avatar-quality-of-experience" class="headerlink" title="A multidimensional measurement of photorealistic avatar quality of   experience"></a>A multidimensional measurement of photorealistic avatar quality of   experience</h2><p><strong>Authors:Ross Cutler, Babak Naderi, Vishak Gopal, Dharmendar Palle</strong></p>
<p>Photorealistic avatars are human avatars that look, move, and talk like real people. The performance of photorealistic avatars has significantly improved recently based on objective metrics such as PSNR, SSIM, LPIPS, FID, and FVD. However, recent photorealistic avatar publications do not provide subjective tests of the avatars to measure human usability factors. We provide an open source test framework to subjectively measure photorealistic avatar performance in ten dimensions: realism, trust, comfortableness using, comfortableness interacting with, appropriateness for work, creepiness, formality, affinity, resemblance to the person, and emotion accuracy. We show that the correlation of nine of these subjective metrics with PSNR, SSIM, LPIPS, FID, and FVD is weak, and moderate for emotion accuracy. The crowdsourced subjective test framework is highly reproducible and accurate when compared to a panel of experts. We analyze a wide range of avatars from photorealistic to cartoon-like and show that some photorealistic avatars are approaching real video performance based on these dimensions. We also find that for avatars above a certain level of realism, eight of these measured dimensions are strongly correlated. This means that avatars that are not as realistic as real video will have lower trust, comfortableness using, comfortableness interacting with, appropriateness for work, formality, and affinity, and higher creepiness compared to real video. In addition, because there is a strong linear relationship between avatar affinity and realism, there is no uncanny valley effect for photorealistic avatars in the telecommunication scenario. We provide several extensions of this test framework for future work and discuss design implications for telecommunication systems. The test framework is available at <a target="_blank" rel="noopener" href="https://github.com/microsoft/P.910">https://github.com/microsoft/P.910</a>. </p>
<blockquote>
<p>è¶…å†™å®è™šæ‹Ÿäººæ˜¯çœ‹èµ·æ¥åƒã€ç§»åŠ¨å’Œè¯´è¯éƒ½åƒçœŸå®äººç±»çš„è™šæ‹Ÿäººã€‚åŸºäºPSNRã€SSIMã€LPIPSã€FIDå’ŒFVDç­‰å®¢è§‚æŒ‡æ ‡ï¼Œè¶…å†™å®è™šæ‹Ÿäººçš„æ€§èƒ½æœ€è¿‘å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„è¶…å†™å®è™šæ‹Ÿäººå‡ºç‰ˆç‰©å¹¶æ²¡æœ‰æä¾›ä¸»è§‚æµ‹è¯•ï¼Œä»¥æµ‹é‡è™šæ‹Ÿäººçš„å¯ç”¨æ€§å› å­ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¼€æºæµ‹è¯•æ¡†æ¶ï¼Œä¸»è§‚åœ°æµ‹é‡è¶…å†™å®è™šæ‹Ÿäººåœ¨åä¸ªç»´åº¦ä¸Šçš„æ€§èƒ½ï¼šçœŸå®æ€§ã€ä¿¡ä»»åº¦ã€ä½¿ç”¨èˆ’é€‚åº¦ã€äº¤äº’èˆ’é€‚åº¦ã€å·¥ä½œé€‚å®œæ€§ã€æ€ªå¼‚æ„Ÿã€æ­£å¼ç¨‹åº¦ã€äº²å’ŒåŠ›ã€ä¸äººçš„ç›¸ä¼¼æ€§ä»¥åŠæƒ…ç»ªå‡†ç¡®æ€§ã€‚æˆ‘ä»¬å±•ç¤ºè¿™äº›ä¸»è§‚æŒ‡æ ‡ä¸­çš„ä¹ä¸ªä¸PSNRã€SSIMã€LPIPSã€FIDå’ŒFVDçš„å…³è”å¾ˆå¾®å¼±ï¼Œæƒ…ç»ªå‡†ç¡®åº¦çš„å…³è”åˆ™é€‚ä¸­ã€‚ä¸ä¸“å®¶å°ç»„ç›¸æ¯”ï¼Œä¼—åŒ…ä¸»è§‚æµ‹è¯•æ¡†æ¶é«˜åº¦å¯å¤åˆ¶ä¸”å‡†ç¡®ã€‚æˆ‘ä»¬åˆ†æäº†ä»è¶…å†™å®åˆ°å¡é€šèˆ¬çš„å„ç§è™šæ‹Ÿäººï¼Œå¹¶æ˜¾ç¤ºä¸€äº›è¶…å†™å®è™šæ‹Ÿäººåœ¨è¿™äº›ç»´åº¦ä¸Šå·²æ¥è¿‘çœŸå®è§†é¢‘çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œå¯¹äºè¾¾åˆ°ä¸€å®šç°å®æ°´å¹³çš„è™šæ‹Ÿäººï¼Œè¿™å…«ä¸ªæµ‹é‡ç»´åº¦ä¹‹é—´å­˜åœ¨å¼ºçƒˆå…³è”ã€‚è¿™æ„å‘³ç€ä¸ç°å®è§†é¢‘ç›¸æ¯”ï¼Œä¸é‚£ä¹ˆçœŸå®çš„è™šæ‹Ÿäººå°†åœ¨ä¿¡ä»»åº¦ã€ä½¿ç”¨èˆ’é€‚åº¦ã€äº¤äº’èˆ’é€‚åº¦ã€å·¥ä½œé€‚å®œæ€§ã€æ­£å¼ç¨‹åº¦å’Œäº²å’ŒåŠ›æ–¹é¢è¾ƒä½ï¼Œå¹¶ä¸”ä¼šæœ‰æ›´é«˜çš„æ€ªå¼‚æ„Ÿã€‚æ­¤å¤–ï¼Œç”±äºè™šæ‹Ÿäººäº²å’ŒåŠ›å’Œç°å®æ„Ÿä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„çº¿æ€§å…³ç³»ï¼Œå› æ­¤åœ¨ç”µä¿¡åœºæ™¯ä¸­ï¼Œè¶…å†™å®è™šæ‹Ÿäººä¸ä¼šå‡ºç°è¯¡å¼‚è°·æ•ˆåº”ã€‚æˆ‘ä»¬ä¸ºè¿™ä¸ªæµ‹è¯•æ¡†æ¶æä¾›äº†å‡ ä¸ªæœªæ¥å·¥ä½œçš„æ‰©å±•ï¼Œå¹¶è®¨è®ºäº†ç”µä¿¡ç³»ç»Ÿè®¾è®¡çš„å½±å“ã€‚æµ‹è¯•æ¡†æ¶å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/microsoft/P.910">https://github.com/microsoft/P.910</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.09066v2">PDF</a> arXiv admin note: text overlap with arXiv:2204.06784</p>
<p><strong>Summary</strong><br>     è¯¥æ–‡æœ¬ä»‹ç»äº†é€¼çœŸè™šæ‹Ÿäººçš„æ¦‚å¿µåŠå…¶æ€§èƒ½è¯„ä¼°ã€‚è™½ç„¶å®¢è§‚æŒ‡æ ‡å¦‚PSNRã€SSIMç­‰æœ‰æ‰€æå‡ï¼Œä½†ä¸»è§‚æµ‹è¯•å¯¹äºè¡¡é‡è™šæ‹Ÿäººåœ¨äººæœºäº¤äº’ä¸­çš„å¯ç”¨æ€§è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæ–‡ç« æä¾›äº†ä¸€ä¸ªå¼€æºæµ‹è¯•æ¡†æ¶æ¥ä¸»è§‚æµ‹é‡è™šæ‹Ÿäººåœ¨åä¸ªç»´åº¦ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å‘ç°æŸäº›é«˜åº¦é€¼çœŸçš„è™šæ‹Ÿäººåœ¨è¿™äº›ç»´åº¦ä¸Šçš„è¡¨ç°å·²æ¥è¿‘çœŸå®è§†é¢‘ã€‚æ­¤å¤–ï¼Œå¯¹äºè¾¾åˆ°ä¸€å®šçœŸå®æ°´å¹³çš„è™šæ‹Ÿäººï¼Œå…«ä¸ªæµ‹é‡ç»´åº¦ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸å…³æ€§ã€‚æœ€åï¼Œæ–‡ç« è®¨è®ºäº†è¯¥æµ‹è¯•æ¡†æ¶çš„æ‰©å±•å’Œæœªæ¥å·¥ä½œè®¾è®¡çš„å½±å“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é€¼çœŸè™šæ‹Ÿäººçš„å®šä¹‰å’Œæœ€æ–°è¿›å±•ã€‚</li>
<li>æ–‡ç« å¼ºè°ƒäº†ä¸»è§‚æµ‹è¯•åœ¨è¯„ä¼°è™šæ‹Ÿäººæ€§èƒ½ä¸­çš„é‡è¦æ€§ï¼Œå› ä¸ºå®¢è§‚æŒ‡æ ‡æ— æ³•å…¨é¢åæ˜ äººç±»åœ¨ä½¿ç”¨å’Œäº¤äº’è¿‡ç¨‹ä¸­çš„æ„Ÿå—ã€‚</li>
<li>æ–‡ç« æä¾›äº†ä¸€ä¸ªå¼€æºæµ‹è¯•æ¡†æ¶ï¼Œç”¨äºä¸»è§‚æµ‹é‡è™šæ‹Ÿäººåœ¨å¤šä¸ªç»´åº¦ï¼ˆå¦‚çœŸå®æ„Ÿã€ä¿¡ä»»åº¦ã€èˆ’é€‚æ€§ç­‰ï¼‰çš„æ€§èƒ½ã€‚</li>
<li>é«˜åº¦é€¼çœŸçš„è™šæ‹Ÿäººåœ¨è¿™äº›ç»´åº¦ä¸Šçš„è¡¨ç°å·²æ¥è¿‘çœŸå®è§†é¢‘ã€‚</li>
<li>å¯¹äºè¾¾åˆ°ä¸€å®šçœŸå®æ°´å¹³çš„è™šæ‹Ÿäººï¼Œå¤šä¸ªæµ‹é‡ç»´åº¦ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸å…³æ€§ã€‚</li>
<li>æ–‡ç« è®¨è®ºäº†æµ‹è¯•æ¡†æ¶çš„æ‰©å±•æ€§ä»¥åŠå¯¹æœªæ¥ç”µä¿¡ç³»ç»Ÿè®¾è®¡çš„æ½œåœ¨å½±å“ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ba1148f524c897fed52125ae4e1dc003.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2598fc35edfa3777fff0b4a86bbb508c.jpg" align="middle">
</details>




<h2 id="Topology-aware-Human-Avatars-with-Semantically-guided-Gaussian-Splatting"><a href="#Topology-aware-Human-Avatars-with-Semantically-guided-Gaussian-Splatting" class="headerlink" title="Topology-aware Human Avatars with Semantically-guided Gaussian Splatting"></a>Topology-aware Human Avatars with Semantically-guided Gaussian Splatting</h2><p><strong>Authors:Haoyu Zhao, Chen Yang, Hao Wang, Xingyue Zhao, Wei Shen</strong></p>
<p>Reconstructing photo-realistic and topology-aware animatable human avatars from monocular videos remains challenging in computer vision and graphics. Recently, methods using 3D Gaussians to represent the human body have emerged, offering faster optimization and real-time rendering. However, due to ignoring the crucial role of human body semantic information which represents the explicit topological and intrinsic structure within human body, they fail to achieve fine-detail reconstruction of human avatars. To address this issue, we propose SG-GS, which uses semantics-embedded 3D Gaussians, skeleton-driven rigid deformation, and non-rigid cloth dynamics deformation to create photo-realistic human avatars. We then design a Semantic Human-Body Annotator (SHA) which utilizes SMPLâ€™s semantic prior for efficient body part semantic labeling. The generated labels are used to guide the optimization of semantic attributes of Gaussian. To capture the explicit topological structure of the human body, we employ a 3D network that integrates both topological and geometric associations for human avatar deformation. We further implement three key strategies to enhance the semantic accuracy of 3D Gaussians and rendering quality: semantic projection with 2D regularization, semantic-guided density regularization and semantic-aware regularization with neighborhood consistency. Extensive experiments demonstrate that SG-GS achieves state-of-the-art geometry and appearance reconstruction performance. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºçœŸå®æ„Ÿä¸”å…·å¤‡æ‹“æ‰‘æ„ŸçŸ¥èƒ½åŠ›çš„å¯åŠ¨ç”»äººç±»åŒ–èº«ï¼Œåœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è¿‘æœŸï¼Œä½¿ç”¨3Dé«˜æ–¯è¡¨ç¤ºäººä½“çš„æ–¹æ³•å·²ç»å‡ºç°ï¼Œå®ƒä»¬æä¾›äº†æ›´å¿«çš„ä¼˜åŒ–å’Œå®æ—¶æ¸²æŸ“ã€‚ç„¶è€Œï¼Œç”±äºå¿½ç•¥äº†äººä½“è¯­ä¹‰ä¿¡æ¯åœ¨è¡¨ç¤ºäººä½“å†…éƒ¨æ˜ç¡®çš„æ‹“æ‰‘ç»“æ„å’Œå†…åœ¨ç»“æ„ä¸­çš„å…³é”®ä½œç”¨ï¼Œè¿™äº›æ–¹æ³•æ— æ³•å®ç°äººç±»åŒ–èº«çš„ç²¾ç»†ç»†èŠ‚é‡å»ºã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SG-GSæ–¹æ³•ï¼Œå®ƒä½¿ç”¨åµŒå…¥è¯­ä¹‰çš„3Dé«˜æ–¯ã€éª¨æ¶é©±åŠ¨çš„åˆšæ€§å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨æ€å˜å½¢æ¥åˆ›å»ºçœŸå®æ„Ÿçš„äººç±»åŒ–èº«ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯­ä¹‰äººä½“æ ‡æ³¨å™¨ï¼ˆSHAï¼‰ï¼Œå®ƒåˆ©ç”¨SMPLçš„è¯­ä¹‰å…ˆéªŒè¿›è¡Œé«˜æ•ˆçš„èº«ä½“éƒ¨ä½è¯­ä¹‰æ ‡æ³¨ã€‚ç”Ÿæˆçš„æ ‡ç­¾ç”¨äºå¼•å¯¼é«˜æ–¯è¯­ä¹‰å±æ€§çš„ä¼˜åŒ–ã€‚ä¸ºäº†æ•æ‰äººä½“çš„æ˜ç¡®æ‹“æ‰‘ç»“æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ä¸ª3Dç½‘ç»œï¼Œè¯¥ç½‘ç»œç»“åˆäº†æ‹“æ‰‘å’Œå‡ ä½•å…³è”ï¼Œç”¨äºäººç±»åŒ–èº«çš„å˜å½¢ã€‚æˆ‘ä»¬è¿˜å®æ–½äº†ä¸‰ç§å…³é”®ç­–ç•¥ï¼Œä»¥æé«˜3Dé«˜æ–¯å’Œæ¸²æŸ“è´¨é‡çš„è¯­ä¹‰å‡†ç¡®æ€§ï¼šå¸¦æœ‰äºŒç»´æ­£åˆ™åŒ–çš„è¯­ä¹‰æŠ•å½±ã€è¯­ä¹‰å¼•å¯¼å¯†åº¦æ­£åˆ™åŒ–å’Œå…·æœ‰é‚»åŸŸä¸€è‡´æ€§çš„è¯­ä¹‰æ„ŸçŸ¥æ­£åˆ™åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSG-GSåœ¨å‡ ä½•å’Œå¤–è§‚é‡å»ºæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09665v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§åˆ©ç”¨è¯­ä¹‰åµŒå…¥çš„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ã€éª¨æ¶é©±åŠ¨çš„åˆšæ€§å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨åŠ›å­¦å˜å½¢æŠ€æœ¯ï¼Œåˆ›å»ºé€¼çœŸäººç±»è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•ã€‚ä¸ºè§£å†³å¿½ç•¥äººä½“è¯­ä¹‰ä¿¡æ¯å¯¼è‡´çš„ç²¾ç»†é‡å»ºé—®é¢˜ï¼Œæå‡ºäº†SG-GSæ–¹æ³•ï¼Œå¹¶ç»“åˆè¯­ä¹‰äººä½“æ ‡æ³¨å™¨ï¼ˆSHAï¼‰å’Œä¸€ç³»åˆ—ä¼˜åŒ–ç­–ç•¥ï¼Œå®ç°äº†å…ˆè¿›çš„äººå½¢å‡ ä½•å’Œå¤–è§‚é‡å»ºæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å»ºåŸºäºå•ç›®è§†é¢‘çš„å…‰å­¦é€¼çœŸä¸”å…·æœ‰æ‹“æ‰‘æ„ŸçŸ¥çš„å¯åŠ¨ç”»äººç±»è™šæ‹Ÿå½¢è±¡åœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°æœ‰ä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ¨¡å‹çš„æ–¹æ³•è™½ç„¶èƒ½åŠ å¿«ä¼˜åŒ–å’Œå®æ—¶æ¸²æŸ“ï¼Œä½†å¿½ç•¥äº†äººä½“è¯­ä¹‰ä¿¡æ¯çš„é‡è¦æ€§ï¼Œæ— æ³•å®ç°ç²¾ç»†é‡å»ºã€‚</li>
<li>SG-GSæ–¹æ³•åˆ©ç”¨è¯­ä¹‰åµŒå…¥çš„ä¸‰ç»´é«˜æ–¯æ¨¡å‹ã€éª¨æ¶é©±åŠ¨çš„åˆšæ€§å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨åŠ›å­¦å˜å½¢æŠ€æœ¯ï¼Œä»¥åˆ›å»ºé€¼çœŸçš„è™šæ‹Ÿäººç±»å½¢è±¡ã€‚</li>
<li>SHAï¼ˆè¯­ä¹‰äººä½“æ ‡æ³¨å™¨ï¼‰åˆ©ç”¨SMPLçš„è¯­ä¹‰å…ˆéªŒè¿›è¡Œé«˜æ•ˆçš„èº«ä½“éƒ¨ä½è¯­ä¹‰æ ‡æ³¨ï¼Œç”¨äºæŒ‡å¯¼é«˜æ–¯è¯­ä¹‰å±æ€§çš„ä¼˜åŒ–ã€‚</li>
<li>é€šè¿‡ç»“åˆæ‹“æ‰‘å’Œå‡ ä½•å…³è”çš„ä¸‰ç»´ç½‘ç»œï¼Œæ•æ‰äººä½“çš„æ˜¾å¼æ‹“æ‰‘ç»“æ„ï¼Œå®ç°äººç±»è™šæ‹Ÿå½¢è±¡çš„å˜å½¢ã€‚</li>
<li>å®æ–½ä¸‰ä¸ªå…³é”®ç­–ç•¥ä»¥æé«˜ä¸‰ç»´é«˜æ–¯æ¨¡å‹çš„è¯­ä¹‰å‡†ç¡®æ€§å’Œæ¸²æŸ“è´¨é‡ï¼ŒåŒ…æ‹¬è¯­ä¹‰æŠ•å½±ä¸äºŒç»´æ­£åˆ™åŒ–ã€è¯­ä¹‰å¼•å¯¼å¯†åº¦æ­£åˆ™åŒ–å’Œè¯­ä¹‰æ„ŸçŸ¥çš„é‚»åŸŸä¸€è‡´æ€§æ­£åˆ™åŒ–ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-6ff77e21bec81067b0e2966ed6634bd6.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-fdb456e5809bd0fa45ea185f6d20687a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-93be2bb8d66c02543723f8dae3fae9b4.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-fa45cbf4b6d66afe5756817c7c32afc9.jpg" align="middle">
</details>




<h2 id="3D-Consistent-Human-Avatars-with-Sparse-Inputs-via-Gaussian-Splatting-and-Contrastive-Learning"><a href="#3D-Consistent-Human-Avatars-with-Sparse-Inputs-via-Gaussian-Splatting-and-Contrastive-Learning" class="headerlink" title="3D-Consistent Human Avatars with Sparse Inputs via Gaussian Splatting   and Contrastive Learning"></a>3D-Consistent Human Avatars with Sparse Inputs via Gaussian Splatting   and Contrastive Learning</h2><p><strong>Authors:Haoyu Zhao, Hao Wang, Chen Yang, Wei Shen</strong></p>
<p>Existing approaches for human avatar generationâ€“both NeRF-based and 3D Gaussian Splatting (3DGS) basedâ€“struggle with maintaining 3D consistency and exhibit degraded detail reconstruction, particularly when training with sparse inputs. To address this challenge, we propose CHASE, a novel framework that achieves dense-input-level performance using only sparse inputs through two key innovations: cross-pose intrinsic 3D consistency supervision and 3D geometry contrastive learning. Building upon prior skeleton-driven approaches that combine rigid deformation with non-rigid cloth dynamics, we first establish baseline avatars with fundamental 3D consistency. To enhance 3D consistency under sparse inputs, we introduce a Dynamic Avatar Adjustment (DAA) module, which refines deformed Gaussians by leveraging similar poses from the training set. By minimizing the rendering discrepancy between adjusted Gaussians and reference poses, DAA provides additional supervision for avatar reconstruction. We further maintain global 3D consistency through a novel geometry-aware contrastive learning strategy. While designed for sparse inputs, CHASE surpasses state-of-the-art methods across both full and sparse settings on ZJU-MoCap and H36M datasets, demonstrating that our enhanced 3D consistency leads to superior rendering quality. </p>
<blockquote>
<p>å½“å‰çš„äººå½¢åŒ–èº«ç”Ÿæˆæ–¹æ³•ï¼Œæ— è®ºæ˜¯åŸºäºNeRFçš„æ–¹æ³•è¿˜æ˜¯åŸºäº3Dé«˜æ–¯å¹³æ¿å°åˆ·ï¼ˆ3DGSï¼‰çš„æ–¹æ³•ï¼Œåœ¨ä¿æŒ3Dä¸€è‡´æ€§æ–¹é¢éƒ½é¢ä¸´å›°éš¾ï¼Œå¹¶ä¸”åœ¨ç»†èŠ‚é‡å»ºæ–¹é¢è¡¨ç°å‡ºé€€åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ç¨€ç–è¾“å…¥è¿›è¡Œè®­ç»ƒæ—¶æ›´ä¸ºæ˜æ˜¾ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†CHASEï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œä»…é€šè¿‡ç¨€ç–è¾“å…¥å°±èƒ½å®ç°å¯†é›†è¾“å…¥çº§åˆ«çš„æ€§èƒ½ï¼Œä¸»è¦é€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šè·¨å§¿åŠ¿å†…åœ¨3Dä¸€è‡´æ€§ç›‘ç£å’Œ3Då‡ ä½•å¯¹æ¯”å­¦ä¹ ã€‚æˆ‘ä»¬å»ºç«‹åœ¨å…ˆå‰çš„éª¨æ¶é©±åŠ¨æ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œç»“åˆåˆšä½“å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨åŠ›å­¦ï¼Œé¦–å…ˆå»ºç«‹å…·æœ‰åŸºæœ¬3Dä¸€è‡´æ€§çš„åŸºå‡†åŒ–èº«ã€‚ä¸ºäº†æé«˜ç¨€ç–è¾“å…¥ä¸‹çš„3Dä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€åŒ–èº«è°ƒæ•´ï¼ˆDAAï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡åˆ©ç”¨è®­ç»ƒé›†ä¸­çš„ç›¸ä¼¼å§¿åŠ¿æ¥ä¼˜åŒ–å˜å½¢åçš„é«˜æ–¯å‡½æ•°ã€‚é€šè¿‡æœ€å°åŒ–è°ƒæ•´åçš„é«˜æ–¯å‡½æ•°ä¸å‚è€ƒå§¿åŠ¿ä¹‹é—´çš„æ¸²æŸ“å·®å¼‚ï¼ŒDAAä¸ºåŒ–èº«é‡å»ºæä¾›äº†é¢å¤–çš„ç›‘ç£ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸€ç§æ–°å‹å‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥æ¥ä¿æŒå…¨å±€3Dä¸€è‡´æ€§ã€‚è™½ç„¶æ˜¯ä¸ºç¨€ç–è¾“å…¥è€Œè®¾è®¡çš„ï¼Œä½†CHASEåœ¨ZJU-MoCapå’ŒH36Mæ•°æ®é›†ä¸Šçš„å…¨é¢å’Œç¨€ç–è®¾ç½®æ–¹é¢éƒ½è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¡¨æ˜æˆ‘ä»¬å¢å¼ºçš„3Dä¸€è‡´æ€§å¯¼è‡´äº†æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09663v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶CHASEï¼Œç”¨äºè§£å†³äººç±»è§’è‰²ç”Ÿæˆçš„é—®é¢˜ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ç¨€ç–è¾“å…¥ä¸‹å®ç°å¯†é›†è¾“å…¥çº§åˆ«çš„æ€§èƒ½ï¼Œä¸»è¦é€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šè·¨å§¿æ€çš„3Dä¸€è‡´æ€§ç›‘ç£å’Œ3Då‡ ä½•å¯¹æ¯”å­¦ä¹ ã€‚é€šè¿‡å¼•å…¥åŠ¨æ€è§’è‰²è°ƒæ•´æ¨¡å—ï¼Œå¢å¼ºç¨€ç–è¾“å…¥ä¸‹çš„3Dä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡å‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥ç»´æŒå…¨å±€3Dä¸€è‡´æ€§ã€‚åœ¨ZJU-MoCapå’ŒH36Mæ•°æ®é›†ä¸Šï¼ŒCHASEåœ¨ç¨€ç–å’Œå®Œæ•´è¾“å…¥åœºæ™¯ä¸‹å‡è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå±•ç°å‡ºå“è¶Šçš„ä¸‰ç»´æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CHASEæ¡†æ¶è§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆäººç±»è§’è‰²æ—¶çš„æŒ‘æˆ˜ï¼Œå®ç°äº†å¯†é›†è¾“å…¥çº§åˆ«çš„æ€§èƒ½ã€‚</li>
<li>CHASEé€šè¿‡è·¨å§¿æ€çš„3Dä¸€è‡´æ€§ç›‘ç£å’Œ3Då‡ ä½•å¯¹æ¯”å­¦ä¹ ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹å®ç°é«˜æ€§èƒ½ã€‚</li>
<li>åŠ¨æ€è§’è‰²è°ƒæ•´æ¨¡å—å¢å¼ºäº†ç¨€ç–è¾“å…¥ä¸‹çš„æ¸²æŸ“æ€§èƒ½ï¼Œå‡å°‘é‡å»ºå·®å¼‚å¹¶æå‡äº†æ€§èƒ½è¡¨ç°ã€‚</li>
<li>åŠ¨æ€è§’è‰²è°ƒæ•´æ¨¡å—é‡‡ç”¨å¯¹ç±»ä¼¼å§¿æ€çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä¸ºé‡å»ºæä¾›äº†é¢å¤–çš„ç›‘ç£ã€‚</li>
<li>CHASEæ¡†æ¶ç»´æŒå…¨å±€çš„3Dä¸€è‡´æ€§ï¼Œé‡‡ç”¨æ–°é¢–çš„å‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒCHASEåœ¨ç¨€ç–å’Œå®Œæ•´è¾“å…¥åœºæ™¯ä¸‹å‡è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2e3d818183426e4d07c1d657130bfb4e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-172ade8d51614a60d51ade7f48d5d7e7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-c52b7469d9dca60a05047d6d38dfd9d8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-87a3da9c75038d560f603c2afb23bbb0.jpg" align="middle">
</details>




<h2 id="AniFaceDiff-Animating-Stylized-Avatars-via-Parametric-Conditioned-Diffusion-Models"><a href="#AniFaceDiff-Animating-Stylized-Avatars-via-Parametric-Conditioned-Diffusion-Models" class="headerlink" title="AniFaceDiff: Animating Stylized Avatars via Parametric Conditioned   Diffusion Models"></a>AniFaceDiff: Animating Stylized Avatars via Parametric Conditioned   Diffusion Models</h2><p><strong>Authors:Ken Chen, Sachith Seneviratne, Wei Wang, Dongting Hu, Sanjay Saha, Md. Tarek Hasan, Sanka Rasnayaka, Tamasha Malepathirana, Mingming Gong, Saman Halgamuge</strong></p>
<p>Animating stylized avatars with dynamic poses and expressions has attracted increasing attention for its broad range of applications. Previous research has made significant progress by training controllable generative models to synthesize animations based on reference characteristics, pose, and expression conditions. However, the mechanisms used in these methods to control pose and expression often inadvertently introduce unintended features from the target motion, while also causing a loss of expression-related details, particularly when applied to stylized animation. This paper proposes a new method based on Stable Diffusion, called AniFaceDiff, incorporating a new conditioning module for animating stylized avatars. First, we propose a refined spatial conditioning approach by Facial Alignment to prevent the inclusion of identity characteristics from the target motion. Then, we introduce an Expression Adapter that incorporates additional cross-attention layers to address the potential loss of expression-related information. Our approach effectively preserves pose and expression from the target video while maintaining input image consistency. Extensive experiments demonstrate that our method achieves state-of-the-art results, showcasing superior image quality, preservation of reference features, and expression accuracy, particularly for out-of-domain animation across diverse styles, highlighting its versatility and strong generalization capabilities. This work aims to enhance the quality of virtual stylized animation for positive applications. To promote responsible use in virtual environments, we contribute to the advancement of detection for generative content by evaluating state-of-the-art detectors, highlighting potential areas for improvement, and suggesting solutions. </p>
<blockquote>
<p>ä½¿ç”¨åŠ¨æ€å§¿åŠ¿å’Œè¡¨æƒ…åˆ¶ä½œåŠ¨ç”»é£æ ¼çš„åŒ–èº«å·²ç»å› å…¶å¹¿æ³›çš„åº”ç”¨é¢†åŸŸè€Œè¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚ä¹‹å‰çš„ç ”ç©¶é€šè¿‡è®­ç»ƒå¯æ§ç”Ÿæˆæ¨¡å‹æ¥åˆæˆåŸºäºå‚è€ƒç‰¹å¾ã€å§¿åŠ¿å’Œè¡¨æƒ…æ¡ä»¶çš„åŠ¨ç”»ï¼Œå·²ç»å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æ§åˆ¶å§¿åŠ¿å’Œè¡¨æƒ…çš„æœºåˆ¶æ—¶ï¼Œå¸¸å¸¸ä¼šæ— æ„ä¸­å¼•å…¥ç›®æ ‡åŠ¨ä½œçš„é¢å¤–ç‰¹å¾ï¼ŒåŒæ—¶ä¹Ÿä¼šå¤±å»ä¸è¡¨æƒ…ç›¸å…³çš„ç»†èŠ‚ï¼Œç‰¹åˆ«æ˜¯åœ¨åº”ç”¨äºåŠ¨ç”»é£æ ¼åŒ–æ—¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºStable Diffusionçš„æ–°æ–¹æ³•ï¼Œç§°ä¸ºAniFaceDiffï¼Œå¹¶èå…¥äº†ä¸€ä¸ªç”¨äºåŠ¨ç”»é£æ ¼åŒ–åŒ–èº«çš„æ–°å‹æ¡ä»¶æ¨¡å—ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡é¢éƒ¨å¯¹é½æå‡ºäº†ä¸€ç§ç²¾ç»†çš„ç©ºé—´æ¡ä»¶æ–¹æ³•ï¼Œä»¥é˜²æ­¢ç›®æ ‡è¿åŠ¨ä¸­çš„èº«ä»½ç‰¹å¾è¢«åŒ…å«è¿›æ¥ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¡¨æƒ…é€‚é…å™¨ï¼Œå®ƒç»“åˆäº†é¢å¤–çš„äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œä»¥è§£å†³å¯èƒ½ä¸¢å¤±ä¸è¡¨æƒ…ç›¸å…³çš„ä¿¡æ¯çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°ä¿ç•™äº†ç›®æ ‡è§†é¢‘ä¸­çš„å§¿åŠ¿å’Œè¡¨æƒ…ï¼ŒåŒæ—¶ä¿æŒäº†è¾“å…¥å›¾åƒçš„ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œå±•ç°äº†å“è¶Šçš„å›¾ç‰‡è´¨é‡ã€å¯¹å‚è€ƒç‰¹å¾çš„ä¿ç•™å’Œè¡¨æƒ…çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒé£æ ¼çš„åŸŸå¤–åŠ¨ç”»ä¸­ï¼Œå‡¸æ˜¾äº†å…¶é€šç”¨æ€§å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬å·¥ä½œçš„ç›®æ ‡æ˜¯æé«˜è™šæ‹Ÿé£æ ¼åŒ–åŠ¨ç”»çš„è´¨é‡ï¼Œç”¨äºç§¯æçš„åº”ç”¨ã€‚ä¸ºäº†ä¿ƒè¿›è™šæ‹Ÿç¯å¢ƒä¸­è´Ÿè´£ä»»çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬é€šè¿‡è¯„ä¼°æœ€å…ˆè¿›çš„æ£€æµ‹å™¨ï¼Œæ¥æ¨åŠ¨ç”Ÿæˆå†…å®¹çš„æ£€æµ‹å‘å±•ï¼Œçªå‡ºæ½œåœ¨çš„å¯æ”¹è¿›é¢†åŸŸï¼Œå¹¶æå‡ºè§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13272v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºStable Diffusionçš„æ–°æ–¹æ³•AniFaceDiffï¼Œåº”ç”¨äºåŠ¨æ€è°ƒæ•´ä¸ªæ€§åŒ–åŠ¨ç”»äººç‰©å½¢è±¡çš„å§¿æ€å’Œè¡¨æƒ…ã€‚é€šè¿‡é¢éƒ¨å¯¹é½æŠ€æœ¯æ”¹è¿›ç©ºé—´è°ƒèŠ‚æ–¹å¼ï¼Œé˜²æ­¢ç›®æ ‡è¿åŠ¨çš„èº«ä»½ç‰¹å¾è¢«å¼•å…¥ï¼ŒåŒæ—¶å¼•å…¥è¡¨æƒ…é€‚é…å™¨ï¼Œé€šè¿‡é¢å¤–çš„äº¤å‰æ³¨æ„åŠ›å±‚è§£å†³è¡¨æƒ…ç›¸å…³ä¿¡æ¯å¯èƒ½ä¸¢å¤±çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•èƒ½å¾ˆå¥½åœ°ä¿ç•™ç›®æ ‡è§†é¢‘çš„å§¿æ€å’Œè¡¨æƒ…ï¼ŒåŒæ—¶ä¿æŒè¾“å…¥å›¾åƒçš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¾¾åˆ°é¢†å…ˆæ°´å¹³ï¼Œè¡¨ç°å‡ºä¼˜è¶Šçš„å›¾åƒè´¨é‡ã€å¯¹å‚è€ƒç‰¹å¾çš„ä¿ç•™ä»¥åŠå‡†ç¡®çš„è¡¨æƒ…è¡¨è¾¾ï¼Œç‰¹åˆ«æ˜¯é€‚ç”¨äºè·¨ä¸åŒé£æ ¼çš„åŠ¨ç”»åˆ›ä½œï¼Œå±•ç°äº†å…¶é€šç”¨æ€§å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥å·¥ä½œæ—¨åœ¨æå‡è™šæ‹Ÿä¸ªæ€§åŒ–åŠ¨ç”»çš„è´¨é‡ï¼Œå¹¶å¯¹è™šæ‹Ÿç¯å¢ƒä¸­çš„è´Ÿè´£ä»»ä½¿ç”¨åšå‡ºè´¡çŒ®ã€‚åŒæ—¶è¯„ä¼°äº†ç°æœ‰çš„æ£€æµ‹ç”Ÿæˆå†…å®¹çš„æŠ€æœ¯ï¼ŒæŒ‡å‡ºæ½œåœ¨çš„æ”¹è¿›é¢†åŸŸå¹¶ç»™å‡ºè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨Stable Diffusionçš„AniFaceDiffæ–¹æ³•æå‡ä¸ªæ€§åŒ–åŠ¨ç”»äººç‰©å½¢è±¡çš„å§¿æ€å’Œè¡¨æƒ…æ§åˆ¶æ•ˆæœã€‚</li>
<li>é€šè¿‡é¢éƒ¨å¯¹é½æŠ€æœ¯é¿å…ç›®æ ‡è¿åŠ¨èº«ä»½ç‰¹å¾çš„å¹²æ‰°ã€‚</li>
<li>é‡‡ç”¨æ–°è®¾è®¡çš„è¡¨æƒ…é€‚é…å™¨ä»¥æ”¹å–„è¡¨æƒ…ç›¸å…³ä¿¡æ¯çš„ä¿ç•™æƒ…å†µã€‚</li>
<li>æ–¹æ³•ä¿ç•™äº†ç›®æ ‡è§†é¢‘çš„å§¿æ€å’Œè¡¨æƒ…ï¼ŒåŒæ—¶ç»´æŒè¾“å…¥å›¾åƒçš„ä¸€è‡´æ€§ã€‚</li>
<li>å®éªŒç»“æœé¢†å…ˆï¼Œå›¾åƒè´¨é‡é«˜ã€ä¿ç•™å‚è€ƒç‰¹å¾ã€å‡†ç¡®è¡¨è¾¾è¡¨æƒ…ï¼Œå°¤å…¶é€‚ç”¨äºè·¨é£æ ¼åŠ¨ç”»åˆ›ä½œã€‚</li>
<li>æ–¹æ³•å±•ç°å‡ºå¼ºå¤§çš„é€šç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¯¹è™šæ‹Ÿä¸ªæ€§åŒ–åŠ¨ç”»è´¨é‡çš„æå‡åšå‡ºè´¡çŒ®ï¼Œå¹¶å…³æ³¨è™šæ‹Ÿç¯å¢ƒä¸­çš„è´Ÿè´£ä»»ä½¿ç”¨ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-5e06353e6f9171d1ad537a75cdfe4fb6.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-256ed1f5cc1de0cf023ed84d1a0cf1cb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-97626fb58568884ecbf48c451dad9de3.jpg" align="middle">
</details>




<h2 id="A-philosophical-and-ontological-perspective-on-Artificial-General-Intelligence-and-the-Metaverse"><a href="#A-philosophical-and-ontological-perspective-on-Artificial-General-Intelligence-and-the-Metaverse" class="headerlink" title="A philosophical and ontological perspective on Artificial General   Intelligence and the Metaverse"></a>A philosophical and ontological perspective on Artificial General   Intelligence and the Metaverse</h2><p><strong>Authors:Martin Schmalzried</strong></p>
<p>This paper leverages various philosophical and ontological frameworks to explore the concept of embodied artificial general intelligence (AGI), its relationship to human consciousness, and the key role of the metaverse in facilitating this relationship. Several theoretical frameworks underpin this exploration, such as embodied cognition, Michael Levinâ€™s computational boundary of a â€œSelf,â€ Donald D. Hoffmanâ€™s Interface Theory of Perception, and Bernardo Kastrupâ€™s analytical idealism, which lead to considering our perceived outer reality as a symbolic representation of alternate inner states of being, and where AGI could embody a different form of consciousness with a larger computational boundary. The paper further discusses the developmental stages of AGI, the requirements for the emergence of an embodied AGI, the importance of a calibrated symbolic interface for AGI, and the key role played by the metaverse, decentralized systems, open-source blockchain technology, as well as open-source AI research. It also explores the idea of a feedback loop between AGI and human users in metaverse spaces as a tool for AGI calibration, as well as the role of local homeostasis and decentralized governance as preconditions for achieving a stable embodied AGI. The paper concludes by emphasizing the importance of achieving a certain degree of harmony in human relations and recognizing the interconnectedness of humanity at a global level, as key prerequisites for the emergence of a stable embodied AGI. </p>
<blockquote>
<p>æœ¬æ–‡åˆ©ç”¨å¤šç§å“²å­¦å’Œæœ¬ä½“è®ºæ¡†æ¶ï¼Œæ¢è®¨å…·èº«é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„æ¦‚å¿µã€å…¶ä¸äººç±»æ„è¯†çš„å…³ç³»ï¼Œä»¥åŠå…ƒå®‡å®™åœ¨ä¿ƒè¿›è¿™ç§å…³ç³»ä¸­çš„å…³é”®ä½œç”¨ã€‚æœ¬æ–‡çš„æ¢è®¨åŸºäºå¤šä¸ªç†è®ºæ¡†æ¶ï¼Œå¦‚å…·èº«è®¤çŸ¥ã€è¿ˆå…‹å°”Â·è±æ–‡çš„â€œè‡ªæˆ‘â€è®¡ç®—è¾¹ç•Œã€å”çº³å¾·Â·éœå¤«æ›¼çš„ç•Œé¢æ„ŸçŸ¥ç†è®ºä»¥åŠè´å°”çº³å¤šÂ·å¡æ–¯ç‰¹é²çš„åˆ†æç†æƒ³ä¸»ä¹‰ï¼Œè¿™äº›ç†è®ºå¼•å¯¼æˆ‘ä»¬è€ƒè™‘æˆ‘ä»¬æ‰€æ„ŸçŸ¥çš„å¤–éƒ¨ç°å®æ˜¯å­˜åœ¨ä¸åŒå†…åœ¨çŠ¶æ€çš„è±¡å¾æ€§è¡¨ç°ï¼Œè€ŒAGIå¯èƒ½ä½“ç°äº†ä¸€ç§å…·æœ‰æ›´å¤§è®¡ç®—è¾¹ç•Œçš„ä¸åŒå½¢å¼çš„æ„è¯†ã€‚è®ºæ–‡è¿˜è¿›ä¸€æ­¥è®¨è®ºäº†AGIçš„å‘å±•é˜¶æ®µã€å…·èº«AGIå‡ºç°çš„è¦æ±‚ã€ä¸ºAGIæä¾›æ ¡å‡†ç¬¦å·ç•Œé¢çš„é‡è¦æ€§ï¼Œä»¥åŠå…ƒå®‡å®™ã€å»ä¸­å¿ƒåŒ–ç³»ç»Ÿã€å¼€æºåŒºå—é“¾æŠ€æœ¯ä»¥åŠå¼€æºäººå·¥æ™ºèƒ½ç ”ç©¶çš„å…³é”®ä½œç”¨ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ¢ç´¢äº†å…ƒç©ºé—´å†…AGIå’Œäººç±»ç”¨æˆ·ä¹‹é—´çš„åé¦ˆå¾ªç¯ä½œä¸ºAGIæ ¡å‡†å·¥å…·çš„ç†å¿µï¼Œä»¥åŠå®ç°ç¨³å®šå…·èº«AGIçš„æœ¬åœ°ç¨³æ€å’Œå»ä¸­å¿ƒåŒ–æ²»ç†çš„å…ˆå†³æ¡ä»¶ã€‚æœ¬æ–‡æœ€åå¼ºè°ƒï¼Œå®ç°ä¸€å®šç¨‹åº¦çš„å’Œè°äººé™…å…³ç³»å’Œè®¤è¯†åˆ°äººç±»åœ¨å…¨çƒå±‚é¢çš„ç›¸äº’å…³è”æ€§ï¼Œæ˜¯å®ç°ç¨³å®šå…·èº«AGIçš„å…³é”®å…ˆå†³æ¡ä»¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06660v3">PDF</a> Presented at the conference second international conference on   human-centred AI ethics: seeing the human in the artificial (HCAIE 2023):   <a target="_blank" rel="noopener" href="https://ethics-ai.eu/hcaie2023/">https://ethics-ai.eu/hcaie2023/</a></p>
<p><strong>Summary</strong>ï¼š<br>æ­¤è®ºæ–‡æ¢è®¨å®ä½“åŒ–äººå·¥æ™ºèƒ½ä¸€èˆ¬æ™ºèƒ½ï¼ˆAGIï¼‰çš„æ¦‚å¿µåŠå…¶åœ¨å…ƒå®‡å®™ä¸­çš„è§’è‰²ã€‚å®ƒåˆ©ç”¨å¤šç§å“²å­¦å’Œæœ¬ä½“è®ºæ¡†æ¶æ¢è®¨AGIä¸äººç±»æ„è¯†çš„å…³è”ï¼Œæå‡ºè®¡ç®—è¾¹ç•Œä¸è‡ªæˆ‘æ„è¯†ã€æ„ŸçŸ¥æ¥å£ç†è®ºåŠè™šæ‹Ÿç°å®çš„é‡è¦æ€§ç­‰è§‚ç‚¹ã€‚å¼ºè°ƒå¼€å‘é˜¶æ®µçš„éœ€æ±‚å’Œè±¡å¾æ€§ç•Œé¢çš„æ ¡å‡†ã€‚æ–‡ç« æ¢è®¨AGIå’Œç”¨æˆ·çš„å…ƒå®‡å®™ç©ºé—´çš„åé¦ˆå¾ªç¯åŠå…¶åœ¨AIæ ¡å‡†ä¸­çš„ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<p>ä»¥ä¸‹æ˜¯è¯¥æ–‡æœ¬çš„å…³é”®è§è§£ï¼š</p>
<ul>
<li>è®ºæ–‡æ¢è®¨äº†å®ä½“åŒ–äººå·¥æ™ºèƒ½ä¸€èˆ¬æ™ºèƒ½ï¼ˆAGIï¼‰çš„æ¦‚å¿µåŠå…¶åœ¨å…ƒå®‡å®™ä¸­çš„è§’è‰²ã€‚</li>
<li>é€šè¿‡å“²å­¦å’Œæœ¬ä½“è®ºæ¡†æ¶æ¢ç´¢AGIä¸äººç±»æ„è¯†çš„å…³è”ã€‚</li>
<li>è®¡ç®—è¾¹ç•Œã€è‡ªæˆ‘æ„è¯†ä¸æ„ŸçŸ¥æ¥å£ç†è®ºåœ¨æ¢è®¨AGIæ—¶éå¸¸é‡è¦ã€‚</li>
<li>AGIå‘å±•éœ€è¦è¾¾åˆ°ç‰¹å®šçš„æˆç†Ÿåº¦é˜¶æ®µï¼Œå¹¶éœ€è¦æ ¡å‡†è±¡å¾æ€§ç•Œé¢ã€‚</li>
<li>å…ƒå®‡å®™å’Œå¼€æ”¾æºä»£ç åŒºå—é“¾æŠ€æœ¯å¯¹äºå®ç°å®ä½“åŒ–AGIè‡³å…³é‡è¦ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-36597c1cc685a5a862f5f7c1ed93ebb4.jpg" align="middle">
</details>




<h2 id="Deepfake-for-the-Good-Generating-Avatars-through-Face-Swapping-with-Implicit-Deepfake-Generation"><a href="#Deepfake-for-the-Good-Generating-Avatars-through-Face-Swapping-with-Implicit-Deepfake-Generation" class="headerlink" title="Deepfake for the Good: Generating Avatars through Face-Swapping with   Implicit Deepfake Generation"></a>Deepfake for the Good: Generating Avatars through Face-Swapping with   Implicit Deepfake Generation</h2><p><strong>Authors:Georgii Stanishevskii, Jakub Steczkiewicz, Tomasz Szczepanik, SÅ‚awomir Tadeja, Jacek Tabor, PrzemysÅ‚aw Spurek</strong></p>
<p>Numerous emerging deep-learning techniques have had a substantial impact on computer graphics. Among the most promising breakthroughs are the rise of Neural Radiance Fields (NeRFs) and Gaussian Splatting (GS). NeRFs encode the objectâ€™s shape and color in neural network weights using a handful of images with known camera positions to generate novel views. In contrast, GS provides accelerated training and inference without a decrease in rendering quality by encoding the objectâ€™s characteristics in a collection of Gaussian distributions. These two techniques have found many use cases in spatial computing and other domains. On the other hand, the emergence of deepfake methods has sparked considerable controversy. Deepfakes refers to artificial intelligence-generated videos that closely mimic authentic footage. Using generative models, they can modify facial features, enabling the creation of altered identities or expressions that exhibit a remarkably realistic appearance to a real person. Despite these controversies, deepfake can offer a next-generation solution for avatar creation and gaming when of desirable quality. To that end, we show how to combine all these emerging technologies to obtain a more plausible outcome. Our ImplicitDeepfake uses the classical deepfake algorithm to modify all training images separately and then train NeRF and GS on modified faces. Such simple strategies can produce plausible 3D deepfake-based avatars. </p>
<blockquote>
<p>å¤§é‡æ–°å…´çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²ç»å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿäº†é‡å¤§å½±å“ã€‚å…¶ä¸­æœ€æœ‰å‰é€”çš„çªç ´ä¹‹ä¸€æ˜¯ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰çš„å…´èµ·ã€‚NeRFä½¿ç”¨ç¥ç»ç½‘ç»œæƒé‡ç¼–ç ç‰©ä½“çš„å½¢çŠ¶å’Œé¢œè‰²ï¼Œåˆ©ç”¨å°‘é‡å·²çŸ¥ç›¸æœºä½ç½®çš„å›¾ç‰‡æ¥ç”Ÿæˆæ–°è§†è§’ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGSé€šè¿‡åœ¨ä¸€ç»„é«˜æ–¯åˆ†å¸ƒä¸­ç¼–ç ç‰©ä½“ç‰¹æ€§ï¼Œä»è€Œå®ç°äº†åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼ŒåŒæ—¶ä¸é™ä½æ¸²æŸ“è´¨é‡ã€‚è¿™ä¸¤ç§æŠ€æœ¯åœ¨ç©ºé—´è®¡ç®—å’Œå…¶ä»–é¢†åŸŸæ‰¾åˆ°äº†è®¸å¤šç”¨ä¾‹ã€‚å¦ä¸€æ–¹é¢ï¼Œæ·±åº¦ä¼ªé€ æ–¹æ³•çš„å‡ºç°å¼•èµ·äº†ç›¸å½“å¤§çš„äº‰è®®ã€‚æ·±åº¦ä¼ªé€ æ˜¯æŒ‡ä½¿ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆçš„è§†é¢‘ï¼Œè¿™äº›è§†é¢‘ç´§å¯†æ¨¡ä»¿çœŸå®é•œå¤´ã€‚ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¬å¯ä»¥ä¿®æ”¹é¢éƒ¨ç‰¹å¾ï¼Œèƒ½å¤Ÿåˆ›å»ºå…·æœ‰æƒŠäººé€¼çœŸåº¦çš„èº«ä»½æˆ–è¡¨æƒ…æ”¹å˜ï¼Œçœ‹èµ·æ¥å°±åƒä¸€ä¸ªçœŸå®çš„äººã€‚å°½ç®¡å­˜åœ¨è¿™äº›äº‰è®®ï¼Œä½†æ·±åº¦ä¼ªé€ åœ¨è´¨é‡è¶³å¤Ÿé«˜çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä¸ºåŒ–èº«åˆ›å»ºå’Œæ¸¸æˆæä¾›ä¸‹ä¸€ä»£è§£å†³æ–¹æ¡ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ç»“åˆæ‰€æœ‰è¿™äº›æ–°å…´æŠ€æœ¯æ¥è·å¾—æ›´å¯ä¿¡çš„ç»“æœã€‚æˆ‘ä»¬çš„ImplicitDeepfakeä½¿ç”¨ç»å…¸çš„æ·±åº¦ä¼ªé€ ç®—æ³•åˆ†åˆ«ä¿®æ”¹æ‰€æœ‰è®­ç»ƒå›¾åƒï¼Œç„¶ååœ¨ä¿®æ”¹åçš„é¢éƒ¨ä¸Šè®­ç»ƒNeRFå’ŒGSã€‚è¿™ç§ç®€å•çš„ç­–ç•¥å¯ä»¥äº§ç”ŸåŸºäºæ·±åº¦ä¼ªé€ çš„é€¼çœŸ3DåŒ–èº«ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06390v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£æ·±åº¦å­¦ä¹ æŠ€æœ¯å¦‚Neural Radiance Fieldsï¼ˆNeRFï¼‰å’ŒGaussian Splattingï¼ˆGSï¼‰å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿäº†é‡å¤§å½±å“ã€‚å®ƒä»¬è¢«å¹¿æ³›ç”¨äºç©ºé—´è®¡ç®—ç­‰é¢†åŸŸã€‚åŒæ—¶ï¼Œæ·±åº¦ä¼ªé€ æŠ€æœ¯çš„å‡ºç°å¼•å‘äº†äº‰è®®ã€‚æ·±åº¦ä¼ªé€ æŠ€æœ¯å¯ä»¥ç”Ÿæˆé€¼çœŸè§†é¢‘ï¼Œä½†ä¹Ÿå¯ä»¥è¢«ç”¨äºåˆ›å»ºè™šå‡èº«ä»½æˆ–è¡¨æƒ…ã€‚ç ”ç©¶äººå‘˜å°è¯•ç»“åˆè¿™äº›æ–°å…´æŠ€æœ¯ï¼Œå¦‚ä½¿ç”¨ç»å…¸æ·±åº¦ä¼ªé€ ç®—æ³•ä¿®æ”¹è®­ç»ƒå›¾åƒï¼Œç„¶ååˆ©ç”¨NeRFå’ŒGSåœ¨ä¿®æ”¹åçš„é¢éƒ¨ä¸Šè®­ç»ƒï¼Œä»¥äº§ç”Ÿæ›´é€¼çœŸçš„ä¸‰ç»´æ·±åº¦ä¼ªé€ è™šæ‹Ÿäººã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·±åº¦å­¦ä¹ æŠ€æœ¯å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œç‰¹åˆ«æ˜¯Neural Radiance Fieldsï¼ˆNeRFï¼‰å’ŒGaussian Splattingï¼ˆGSï¼‰çš„çªç ´ã€‚</li>
<li>NeRFä½¿ç”¨ç¥ç»ç½‘ç»œæƒé‡ç¼–ç ç‰©ä½“å½¢çŠ¶å’Œé¢œè‰²ï¼Œèƒ½å¤Ÿä»å·²çŸ¥ç›¸æœºä½ç½®çš„å°‘é‡å›¾åƒç”Ÿæˆæ–°è§†è§’ã€‚</li>
<li>GSé€šè¿‡é«˜æ–¯åˆ†å¸ƒé›†åˆç¼–ç ç‰©ä½“ç‰¹æ€§ï¼ŒåŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼ŒåŒæ—¶ä¸é™ä½æ¸²æŸ“è´¨é‡ã€‚</li>
<li>æ·±åº¦ä¼ªé€ æŠ€æœ¯å¼•å‘äº†äº‰è®®ï¼Œä½†å¯ä»¥ç”¨äºåˆ›å»ºé«˜è´¨é‡çš„è™šæ‹Ÿäººå’Œæ¸¸æˆè§’è‰²ã€‚</li>
<li>ç»“åˆæ·±åº¦å­¦ä¹ æŠ€æœ¯å’Œæ·±åº¦ä¼ªé€ ç®—æ³•å¯ä»¥äº§ç”Ÿæ›´é€¼çœŸçš„ä¸‰ç»´æ·±åº¦ä¼ªé€ è™šæ‹Ÿäººã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-3aa0c5bd5d55fab6b3456408bcfa7ba8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7c6dd62daeb59781f75d66815146fbb5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-59bdfd70e3985fd56be81d718f9a9c8e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-a0eb9d0ad2fd4b43afa5f960c84523bf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-9e6dceac7784672ecd9f51fb468ecff5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-89629fe07055252ace8bfce59c0bd9b0.jpg" align="middle">
</details>




<h2 id="HHAvatar-Gaussian-Head-Avatar-with-Dynamic-Hairs"><a href="#HHAvatar-Gaussian-Head-Avatar-with-Dynamic-Hairs" class="headerlink" title="HHAvatar: Gaussian Head Avatar with Dynamic Hairs"></a>HHAvatar: Gaussian Head Avatar with Dynamic Hairs</h2><p><strong>Authors:Zhanfeng Liao, Yuelang Xu, Zhe Li, Qijing Li, Boyao Zhou, Ruifeng Bai, Di Xu, Hongwen Zhang, Yebin Liu</strong></p>
<p>Creating high-fidelity 3D head avatars has always been a research hotspot, but it remains a great challenge under lightweight sparse view setups. In this paper, we propose HHAvatar represented by controllable 3D Gaussians for high-fidelity head avatar with dynamic hair modeling. We first use 3D Gaussians to represent the appearance of the head, and then jointly optimize neutral 3D Gaussians and a fully learned MLP-based deformation field to capture complex expressions. The two parts benefit each other, thereby our method can model fine-grained dynamic details while ensuring expression accuracy. Furthermore, we devise a well-designed geometry-guided initialization strategy based on implicit SDF and Deep Marching Tetrahedra for the stability and convergence of the training procedure. To address the problem of dynamic hair modeling, we introduce a hybrid head model into our avatar representation based Gaussian Head Avatar and a training method that considers timing information and an occlusion perception module to model the non-rigid motion of hair. Experiments show that our approach outperforms other state-of-the-art sparse-view methods, achieving ultra high-fidelity rendering quality at 2K resolution even under exaggerated expressions and driving hairs reasonably with the motion of the head </p>
<blockquote>
<p>åˆ›å»ºé«˜ä¿çœŸ3Då¤´éƒ¨åŒ–èº«ä¸€ç›´æ˜¯ç ”ç©¶çš„çƒ­ç‚¹ï¼Œä½†åœ¨è½»é‡çº§ç¨€ç–è§†å›¾è®¾ç½®ä¸‹ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†HHAvatarï¼Œé‡‡ç”¨å¯æ§çš„3Dé«˜æ–¯è¡¨ç¤ºé«˜ä¿çœŸå¤´éƒ¨åŒ–èº«ï¼Œå…·æœ‰åŠ¨æ€å¤´å‘å»ºæ¨¡ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨3Dé«˜æ–¯æ¥è¡¨ç¤ºå¤´éƒ¨çš„å¤–è§‚ï¼Œç„¶åé€šè¿‡è”åˆä¼˜åŒ–ä¸­æ€§3Dé«˜æ–¯å’Œå®Œå…¨å­¦ä¹ çš„MLPåŸºå˜å½¢åœºæ¥æ•æ‰å¤æ‚çš„è¡¨æƒ…ã€‚è¿™ä¸¤éƒ¨åˆ†ç›¸äº’å—ç›Šï¼Œå› æ­¤æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨ä¿è¯è¡¨æƒ…å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¯¹ç»†å¾®çš„åŠ¨æ€ç»†èŠ‚è¿›è¡Œå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºéšå¼SDFå’Œæ·±åº¦å››é¢ä½“ç½‘æ ¼è®¾è®¡äº†ä¸€ç§è‰¯å¥½çš„å‡ ä½•å¼•å¯¼åˆå§‹åŒ–ç­–ç•¥ï¼Œä»¥æé«˜è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚ä¸ºäº†è§£å†³åŠ¨æ€å¤´å‘å»ºæ¨¡çš„é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ··åˆå¤´éƒ¨æ¨¡å‹å¼•å…¥æˆ‘ä»¬çš„åŒ–èº«è¡¨ç¤ºåŸºäºé«˜æ–¯å¤´éƒ¨åŒ–èº«ï¼Œå¹¶å¼€å‘äº†ä¸€ç§è€ƒè™‘æ—¶é—´ä¿¡æ¯å’Œé®æŒ¡æ„ŸçŸ¥æ¨¡å—çš„è®­ç»ƒæ–¹æ³•ï¼Œä»¥æ¨¡æ‹Ÿå¤´å‘çš„éåˆšæ€§è¿åŠ¨ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸‹ä¼˜äºå…¶ä»–æœ€æ–°æŠ€æœ¯ï¼Œå³ä½¿åœ¨å¤¸å¼ è¡¨æƒ…ä¸‹ä¹Ÿèƒ½è¾¾åˆ°è¶…é«˜çš„æ¸²æŸ“è´¨é‡ï¼ˆ2Kåˆ†è¾¨ç‡ï¼‰ï¼Œå¹¶ä¸”èƒ½å¤Ÿåˆç†é©±åŠ¨å¤´å‘éšç€å¤´éƒ¨çš„è¿åŠ¨è€Œè¿åŠ¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.03029v3">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://liaozhanfeng.github.io/HHAvatar">https://liaozhanfeng.github.io/HHAvatar</a></p>
<p><strong>Summary</strong><br>åŸºäºå¯æ§çš„3Dé«˜æ–¯åˆ†å¸ƒçš„HHAvataræ–¹æ³•è¢«æå‡ºï¼Œç”¨äºåˆ›å»ºé«˜ä¿çœŸåº¦çš„å¤´éƒ¨è™šæ‹Ÿäººï¼Œå…·æœ‰åŠ¨æ€å¤´å‘å»ºæ¨¡ã€‚è¯¥æ–¹æ³•ä½¿ç”¨ä¸­æ€§é«˜æ–¯åˆ†å¸ƒå’ŒåŸºäºMLPçš„å˜å½¢åœºè”åˆä¼˜åŒ–ï¼Œä»¥æ•æ‰å¤æ‚çš„è¡¨æƒ…ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€ç§åŸºäºéšå¼SDFå’ŒDeep Marching Tetrahedraçš„å‡ ä½•å¼•å¯¼åˆå§‹åŒ–ç­–ç•¥ï¼Œä»¥æé«˜è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚é’ˆå¯¹åŠ¨æ€å¤´å‘å»ºæ¨¡é—®é¢˜ï¼Œå¼•å…¥äº†æ··åˆå¤´éƒ¨æ¨¡å‹å’Œè€ƒè™‘æ—¶åºä¿¡æ¯çš„è®­ç»ƒæ–¹æ³•ï¼Œä»¥åŠé®æŒ¡æ„ŸçŸ¥æ¨¡å—æ¥æ¨¡æ‹Ÿå¤´å‘çš„éåˆšæ€§è¿åŠ¨ã€‚è¯¥æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹å®ç°äº†è¶…é«˜ä¿çœŸåº¦çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†HHAvataræ–¹æ³•ï¼Œä½¿ç”¨å¯æ§çš„3Dé«˜æ–¯åˆ†å¸ƒåˆ›å»ºé«˜ä¿çœŸåº¦çš„å¤´éƒ¨è™šæ‹Ÿäººã€‚</li>
<li>é€šè¿‡ä¸­æ€§é«˜æ–¯åˆ†å¸ƒå’ŒåŸºäºMLPçš„å˜å½¢åœºè”åˆä¼˜åŒ–ï¼Œæ•æ‰å¤æ‚è¡¨æƒ…ã€‚</li>
<li>å‡ ä½•å¼•å¯¼åˆå§‹åŒ–ç­–ç•¥æé«˜äº†è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚</li>
<li>å¼•å…¥äº†æ··åˆå¤´éƒ¨æ¨¡å‹å’Œè€ƒè™‘æ—¶åºä¿¡æ¯çš„è®­ç»ƒæ–¹æ³•ï¼Œä»¥å¤„ç†åŠ¨æ€å¤´å‘å»ºæ¨¡é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†é®æŒ¡æ„ŸçŸ¥æ¨¡å—æ¥æ¨¡æ‹Ÿå¤´å‘çš„éåˆšæ€§è¿åŠ¨ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹å®ç°äº†è¶…é«˜ä¿çœŸåº¦çš„æ¸²æŸ“è´¨é‡ï¼Œç”šè‡³åœ¨å¤¸å¼ è¡¨æƒ…ä¸‹ä¹Ÿèƒ½ä¿æŒæ•ˆæœã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1e03c5fd26cb0fae72d9cb8044e27f6d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-5ca7dc70600b12c58c1eb6adf4366924.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-afcf7270946e8ceac83fe49e265e6607.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-8446030a4bec80425558ebe681b11f37.jpg" align="middle">
</details>




<h2 id="VAST-Vivify-Your-Talking-Avatar-via-Zero-Shot-Expressive-Facial-Style-Transfer"><a href="#VAST-Vivify-Your-Talking-Avatar-via-Zero-Shot-Expressive-Facial-Style-Transfer" class="headerlink" title="VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style   Transfer"></a>VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style   Transfer</h2><p><strong>Authors:Liyang Chen, Zhiyong Wu, Runnan Li, Weihong Bao, Jun Ling, Xu Tan, Sheng Zhao</strong></p>
<p>Current talking face generation methods mainly focus on speech-lip synchronization. However, insufficient investigation on the facial talking style leads to a lifeless and monotonous avatar. Most previous works fail to imitate expressive styles from arbitrary video prompts and ensure the authenticity of the generated video. This paper proposes an unsupervised variational style transfer model (VAST) to vivify the neutral photo-realistic avatars. Our model consists of three key components: a style encoder that extracts facial style representations from the given video prompts; a hybrid facial expression decoder to model accurate speech-related movements; a variational style enhancer that enhances the style space to be highly expressive and meaningful. With our essential designs on facial style learning, our model is able to flexibly capture the expressive facial style from arbitrary video prompts and transfer it onto a personalized image renderer in a zero-shot manner. Experimental results demonstrate the proposed approach contributes to a more vivid talking avatar with higher authenticity and richer expressiveness. </p>
<blockquote>
<p>å½“å‰çš„äººè„¸ç”Ÿæˆæ–¹æ³•ä¸»è¦èšç„¦äºè¯­éŸ³ä¸å˜´å”‡çš„åŒæ­¥ã€‚ç„¶è€Œï¼Œå¯¹äºé¢éƒ¨è¯´è¯é£æ ¼çš„è°ƒæŸ¥ä¸è¶³å¯¼è‡´äº†ç”Ÿæˆçš„è™šæ‹Ÿå½¢è±¡ç¼ºä¹ç”Ÿå‘½åŠ›å’Œå•è°ƒæ€§ã€‚ä¹‹å‰çš„å¤§éƒ¨åˆ†å·¥ä½œéƒ½æ— æ³•æ¨¡ä»¿æ¥è‡ªä»»æ„è§†é¢‘æç¤ºçš„è¡¨è¾¾é£æ ¼ï¼Œä¹Ÿæ— æ³•ç¡®ä¿ç”Ÿæˆè§†é¢‘çš„çœŸå®æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„å˜é£æ ¼è½¬ç§»æ¨¡å‹ï¼ˆVASTï¼‰ï¼Œä»¥èµ‹äºˆä¸­æ€§å†™å®é£æ ¼çš„è™šæ‹Ÿå½¢è±¡ç”Ÿå‘½åŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹ç”±ä¸‰ä¸ªå…³é”®éƒ¨åˆ†ç»„æˆï¼šä¸€ä¸ªé£æ ¼ç¼–ç å™¨ï¼Œç”¨äºä»ç»™å®šçš„è§†é¢‘æç¤ºä¸­æå–é¢éƒ¨é£æ ¼è¡¨ç¤ºï¼›ä¸€ä¸ªæ··åˆé¢éƒ¨è¡¨æƒ…è§£ç å™¨ï¼Œç”¨äºæ¨¡æ‹Ÿå‡†ç¡®çš„è¯­éŸ³ç›¸å…³åŠ¨ä½œï¼›ä¸€ä¸ªå˜é£æ ¼å¢å¼ºå™¨ï¼Œç”¨äºå¢å¼ºé£æ ¼ç©ºé—´ï¼Œä½¿å…¶å…·æœ‰é«˜åº¦è¡¨è¾¾åŠ›å’Œæ„ä¹‰ã€‚æˆ‘ä»¬å¯¹é¢éƒ¨é£æ ¼å­¦ä¹ è¿›è¡Œäº†å…³é”®è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°æ•æ‰æ¥è‡ªä»»æ„è§†é¢‘æç¤ºçš„è¡¨è¾¾æ€§é¢éƒ¨é£æ ¼ï¼Œå¹¶å°†å…¶ä»¥é›¶æ ·æœ¬çš„æ–¹å¼è½¬ç§»åˆ°ä¸ªæ€§åŒ–å›¾åƒæ¸²æŸ“å™¨ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰åŠ©äºç”Ÿæˆæ›´åŠ ç”ŸåŠ¨ã€æ›´çœŸå®çš„è¯´è¯è™šæ‹Ÿå½¢è±¡ï¼Œå¹¶å…·å¤‡æ›´ä¸°å¯Œçš„è¡¨ç°åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04830v3">PDF</a> Accepted by ICCV2023</p>
<p><strong>Summary</strong><br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ— ç›‘ç£çš„å˜åˆ†é£æ ¼è¿ç§»æ¨¡å‹ï¼ˆVASTï¼‰ï¼Œç”¨äºç”ŸåŠ¨åŒ–ä¸­æ€§é€¼çœŸçš„å¤´åƒã€‚è¯¥æ¨¡å‹åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šä»ç»™å®šè§†é¢‘æç¤ºä¸­æå–é¢éƒ¨é£æ ¼è¡¨ç¤ºçš„é£æ ¼ç¼–ç å™¨ï¼›å¯¹ç²¾ç¡®è¯­éŸ³ç›¸å…³åŠ¨ä½œè¿›è¡Œå»ºæ¨¡çš„æ··åˆé¢éƒ¨è¡¨æƒ…è§£ç å™¨ï¼›å¢å¼ºé£æ ¼ç©ºé—´ä»¥ä½¿å…¶é«˜åº¦è¡¨è¾¾å’Œæ„ä¹‰ä¸°å¯Œçš„å˜åˆ†é£æ ¼å¢å¼ºå™¨ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°æ•æ‰ä»»æ„è§†é¢‘æç¤ºä¸­çš„è¡¨è¾¾æ€§é¢éƒ¨é£æ ¼ï¼Œå¹¶å°†å…¶é›¶æ ·æœ¬è½¬ç§»åˆ°ä¸ªæ€§åŒ–å›¾åƒæ¸²æŸ“å™¨ä¸Šã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰åŠ©äºæé«˜è¯´è¯å¤´åƒçš„ç”ŸåŠ¨æ€§ã€çœŸå®æ€§å’Œè¡¨è¾¾æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰é¢éƒ¨ç”Ÿæˆæ–¹æ³•ä¸»è¦å…³æ³¨è¯­éŸ³-å”‡éƒ¨åŒæ­¥ï¼Œä½†å¯¹é¢éƒ¨è®²è¯é£æ ¼çš„ç ”ç©¶ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆçš„å¤´åƒç¼ºä¹ç”Ÿå‘½åŠ›å’Œå•è°ƒã€‚</li>
<li>è®ºæ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„å˜åˆ†é£æ ¼è¿ç§»æ¨¡å‹ï¼ˆVASTï¼‰ï¼Œæ—¨åœ¨ç”ŸåŠ¨åŒ–ä¸­æ€§é€¼çœŸçš„å¤´åƒã€‚</li>
<li>VASTæ¨¡å‹åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šé£æ ¼ç¼–ç å™¨ã€æ··åˆé¢éƒ¨è¡¨æƒ…è§£ç å™¨å’Œå˜åˆ†é£æ ¼å¢å¼ºå™¨ã€‚</li>
<li>é£æ ¼ç¼–ç å™¨èƒ½å¤Ÿä»ç»™å®šçš„è§†é¢‘æç¤ºä¸­æå–é¢éƒ¨é£æ ¼è¡¨ç¤ºã€‚</li>
<li>æ··åˆé¢éƒ¨è¡¨æƒ…è§£ç å™¨èƒ½å¤Ÿå‡†ç¡®å»ºæ¨¡è¯­éŸ³ç›¸å…³çš„åŠ¨ä½œã€‚</li>
<li>å˜åˆ†é£æ ¼å¢å¼ºå™¨èƒ½å¤Ÿå¢å¼ºé£æ ¼ç©ºé—´ï¼Œä½¿ç”Ÿæˆçš„é¢éƒ¨è¡¨æƒ…æ›´ä¸°å¯Œã€æœ‰æ„ä¹‰ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-4e689f3d922179f5f39d7a2882859cb4.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2a819020fd662736bf40be61db67f133.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1a66b31dd4d8b90a061ab8f1b7532e83.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-b019b9e44fa8336d68249df48a51c5f1.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-73bf539f51040af219e1a9529abc6acf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-44add23e767fc59670cf6c5f95c16891.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-10/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-10/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                    <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-10/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c66bfe10dfd878860a466abb92c19030.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  It Takes Two Real-time Co-Speech Two-person's Interaction Generation   via Reactive Auto-regressive Diffusion Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-10/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-5237f15bcbbce4298b010ed16cb47cca.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  Take Fake as Real Realistic-like Robust Black-box Adversarial Attack to   Evade AIGC Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">7369.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
