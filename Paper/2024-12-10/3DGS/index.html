<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  Deblur4DGS 4D Gaussian Splatting from Blurry Monocular Video">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-084788d1a3c9bf4a759bc1df2b42fdad.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    28k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    113 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-11-æ›´æ–°"><a href="#2024-12-11-æ›´æ–°" class="headerlink" title="2024-12-11 æ›´æ–°"></a>2024-12-11 æ›´æ–°</h1><h2 id="Deblur4DGS-4D-Gaussian-Splatting-from-Blurry-Monocular-Video"><a href="#Deblur4DGS-4D-Gaussian-Splatting-from-Blurry-Monocular-Video" class="headerlink" title="Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video"></a>Deblur4DGS: 4D Gaussian Splatting from Blurry Monocular Video</h2><p><strong>Authors:Renlong Wu, Zhilu Zhang, Mingyang Chen, Xiaopeng Fan, Zifei Yan, Wangmeng Zuo</strong></p>
<p>Recent 4D reconstruction methods have yielded impressive results but rely on sharp videos as supervision. However, motion blur often occurs in videos due to camera shake and object movement, while existing methods render blurry results when using such videos for reconstructing 4D models. Although a few NeRF-based approaches attempted to address the problem, they struggled to produce high-quality results, due to the inaccuracy in estimating continuous dynamic representations within the exposure time. Encouraged by recent works in 3D motion trajectory modeling using 3D Gaussian Splatting (3DGS), we suggest taking 3DGS as the scene representation manner, and propose the first 4D Gaussian Splatting framework to reconstruct a high-quality 4D model from blurry monocular video, named Deblur4DGS. Specifically, we transform continuous dynamic representations estimation within an exposure time into the exposure time estimation. Moreover, we introduce exposure regularization to avoid trivial solutions, as well as multi-frame and multi-resolution consistency ones to alleviate artifacts. Furthermore, to better represent objects with large motion, we suggest blur-aware variable canonical Gaussians. Beyond novel-view synthesis, Deblur4DGS can be applied to improve blurry video from multiple perspectives, including deblurring, frame interpolation, and video stabilization. Extensive experiments on the above four tasks show that Deblur4DGS outperforms state-of-the-art 4D reconstruction methods. The codes are available at <a target="_blank" rel="noopener" href="https://github.com/ZcsrenlongZ/Deblur4DGS">https://github.com/ZcsrenlongZ/Deblur4DGS</a>. </p>
<blockquote>
<p>æœ€è¿‘çš„4Dé‡å»ºæ–¹æ³•å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†å®ƒä»¬ä¾èµ–äºæ¸…æ™°è§†é¢‘ä½œä¸ºç›‘ç£ã€‚ç„¶è€Œï¼Œç”±äºç›¸æœºæŠ–åŠ¨å’Œç‰©ä½“ç§»åŠ¨ï¼Œè§†é¢‘ä¸­çš„è¿åŠ¨æ¨¡ç³Šç»å¸¸å‘ç”Ÿï¼Œè€Œå½“ä½¿ç”¨æ­¤ç±»è§†é¢‘è¿›è¡Œ4Dæ¨¡å‹é‡å»ºæ—¶ï¼Œç°æœ‰æ–¹æ³•ä¼šäº§ç”Ÿæ¨¡ç³Šçš„ç»“æœã€‚å°½ç®¡æœ‰ä¸€äº›åŸºäºNeRFçš„æ–¹æ³•è¯•å›¾è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†ç”±äºåœ¨æ›å…‰æ—¶é—´å†…ä¼°è®¡è¿ç»­åŠ¨æ€è¡¨ç¤ºçš„ä¸å‡†ç¡®æ€§ï¼Œå®ƒä»¬å¾ˆéš¾äº§ç”Ÿé«˜è´¨é‡çš„ç»“æœã€‚å—åˆ°ä½¿ç”¨3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰è¿›è¡Œ3Dè¿åŠ¨è½¨è¿¹å»ºæ¨¡çš„è¿‘æœŸå·¥ä½œçš„å¯å‘ï¼Œæˆ‘ä»¬å»ºè®®å°†3DGSä½œä¸ºåœºæ™¯è¡¨ç¤ºæ–¹å¼ï¼Œå¹¶æå‡ºç¬¬ä¸€ä¸ª4Dé«˜æ–¯è´´å›¾æ¡†æ¶ï¼Œä»æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­é‡å»ºé«˜è´¨é‡4Dæ¨¡å‹ï¼Œå‘½åä¸ºDeblur4DGSã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†è¿ç»­åŠ¨æ€è¡¨ç¤ºä¼°è®¡è½¬åŒ–ä¸ºæ›å…‰æ—¶é—´ä¼°è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ›å…‰æ­£åˆ™åŒ–ä»¥é¿å…å¹³å‡¡è§£ï¼Œä»¥åŠå¤šå¸§å’Œå¤šåˆ†è¾¨ç‡ä¸€è‡´æ€§æ–¹æ³•æ¥å‡è½»ä¼ªå½±ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ›´å¥½åœ°è¡¨ç¤ºå…·æœ‰å¤§è¿åŠ¨çš„ç‰©ä½“ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨æ¨¡ç³Šæ„ŸçŸ¥å¯å˜è§„èŒƒé«˜æ–¯ã€‚é™¤äº†æ–°å‹è§†å›¾åˆæˆå¤–ï¼ŒDeblur4DGSè¿˜å¯ä»¥åº”ç”¨äºä»å¤šä¸ªè§’åº¦æé«˜æ¨¡ç³Šè§†é¢‘çš„è´¨é‡ï¼ŒåŒ…æ‹¬å»æ¨¡ç³Šã€å¸§å†…æ’å’Œè§†é¢‘ç¨³å®šã€‚åœ¨ä¸Šè¿°å››ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDeblur4DGSä¼˜äºæœ€æ–°çš„4Dé‡å»ºæ–¹æ³•ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ZcsrenlongZ/Deblur4DGS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ZcsrenlongZ/Deblur4DGSè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06424v1">PDF</a> 17 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäº3Dé«˜æ–¯æç”»ï¼ˆ3DGSï¼‰çš„4Dé«˜æ–¯æç”»æ¡†æ¶ï¼Œç”¨äºä»æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­é‡å»ºé«˜è´¨é‡çš„å››ç»´æ¨¡å‹ã€‚é€šè¿‡è½¬æ¢æ›å…‰æ—¶é—´å†…çš„è¿ç»­åŠ¨æ€è¡¨ç¤ºä¼°è®¡ä¸ºæ›å…‰æ—¶é—´ä¼°è®¡ï¼Œå¼•å…¥æ›å…‰æ­£åˆ™åŒ–ä»¥åŠå¤šå¸§å’Œå¤šåˆ†è¾¨ç‡ä¸€è‡´æ€§ï¼Œä»¥å‡è½»æ¨¡ç³Šå’Œä¼ªå½±ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ›´å¥½åœ°è¡¨ç¤ºå…·æœ‰å¤§è¿åŠ¨çš„ç‰©ä½“ï¼Œå»ºè®®ä½¿ç”¨æ¨¡ç³Šæ„ŸçŸ¥çš„å¯å˜è§„èŒƒé«˜æ–¯ã€‚é™¤äº†æ–°é¢–è§†å›¾åˆæˆå¤–ï¼ŒDeblur4DGSè¿˜å¯åº”ç”¨äºä»å¤šä¸ªè§’åº¦æ”¹è¿›æ¨¡ç³Šè§†é¢‘ï¼ŒåŒ…æ‹¬å»æ¨¡ç³Šã€å¸§æ’å€¼ã€è§†é¢‘ç¨³å®šç­‰ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜Deblur4DGSä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„4Dé‡å»ºæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥ç ”ç©¶è§£å†³äº†ä½¿ç”¨æ¨¡ç³Šè§†é¢‘é‡å»ºå››ç»´æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäº3Dé«˜æ–¯æç”»ï¼ˆ3DGSï¼‰çš„4Dé«˜æ–¯æç”»æ¡†æ¶â€”â€”Deblur4DGSã€‚</li>
<li>Deblur4DGSé€šè¿‡è½¬æ¢è¿ç»­åŠ¨æ€è¡¨ç¤ºä¼°è®¡åˆ°æ›å…‰æ—¶é—´ä¼°è®¡æ¥å¤„ç†è¿åŠ¨æ¨¡ç³Šã€‚</li>
<li>å¼•å…¥æ›å…‰æ­£åˆ™åŒ–ä»¥åŠå¤šå¸§å’Œå¤šåˆ†è¾¨ç‡ä¸€è‡´æ€§æ¥å‡è½»ä¼ªå½±å’Œæ¨¡ç³Šã€‚</li>
<li>ä¸ºäº†æ›´å¥½åœ°è¡¨ç¤ºå¤§è¿åŠ¨ç‰©ä½“ï¼Œæå‡ºäº†æ¨¡ç³Šæ„ŸçŸ¥çš„å¯å˜è§„èŒƒé«˜æ–¯ã€‚</li>
<li>é™¤äº†æ–°é¢–è§†å›¾åˆæˆï¼ŒDeblur4DGSè¿˜èƒ½åº”ç”¨äºå»æ¨¡ç³Šã€å¸§æ’å€¼ã€è§†é¢‘ç¨³å®šç­‰ä»»åŠ¡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒDeblur4DGSåœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„4Dé‡å»ºæ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-eb4709786b9ef5c49feda7de5a777dbf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-35024d82687819b373aaa935de3f9899.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6bd3ba1717d7318727ec5abbb2a4e394.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-b69bf3ecf99c8bc81f5bf524de313771.jpg" align="middle">
</details>




<h2 id="4D-Gaussian-Splatting-with-Scale-aware-Residual-Field-and-Adaptive-Optimization-for-Real-time-Rendering-of-Temporally-Complex-Dynamic-Scenes"><a href="#4D-Gaussian-Splatting-with-Scale-aware-Residual-Field-and-Adaptive-Optimization-for-Real-time-Rendering-of-Temporally-Complex-Dynamic-Scenes" class="headerlink" title="4D Gaussian Splatting with Scale-aware Residual Field and Adaptive   Optimization for Real-time Rendering of Temporally Complex Dynamic Scenes"></a>4D Gaussian Splatting with Scale-aware Residual Field and Adaptive   Optimization for Real-time Rendering of Temporally Complex Dynamic Scenes</h2><p><strong>Authors:Jinbo Yan, Rui Peng, Luyang Tang, Ronggang Wang</strong></p>
<p>Reconstructing dynamic scenes from video sequences is a highly promising task in the multimedia domain. While previous methods have made progress, they often struggle with slow rendering and managing temporal complexities such as significant motion and object appearance&#x2F;disappearance. In this paper, we propose SaRO-GS as a novel dynamic scene representation capable of achieving real-time rendering while effectively handling temporal complexities in dynamic scenes. To address the issue of slow rendering speed, we adopt a Gaussian primitive-based representation and optimize the Gaussians in 4D space, which facilitates real-time rendering with the assistance of 3D Gaussian Splatting. Additionally, to handle temporally complex dynamic scenes, we introduce a Scale-aware Residual Field. This field considers the size information of each Gaussian primitive while encoding its residual feature and aligns with the self-splitting behavior of Gaussian primitives. Furthermore, we propose an Adaptive Optimization Schedule, which assigns different optimization strategies to Gaussian primitives based on their distinct temporal properties, thereby expediting the reconstruction of dynamic regions. Through evaluations on monocular and multi-view datasets, our method has demonstrated state-of-the-art performance. Please see our project page at <a target="_blank" rel="noopener" href="https://yjb6.github.io/SaRO-GS.github.io">https://yjb6.github.io/SaRO-GS.github.io</a>. </p>
<blockquote>
<p>ä»è§†é¢‘åºåˆ—é‡å»ºåŠ¨æ€åœºæ™¯æ˜¯å¤šåª’ä½“é¢†åŸŸä¸€ä¸ªéå¸¸æœ‰å‰æ™¯çš„ä»»åŠ¡ã€‚å°½ç®¡ä¹‹å‰çš„æ–¹æ³•å·²ç»å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†æ˜¾è‘—çš„åŠ¨æ€åœºæ™¯å’Œç‰©ä½“å‡ºç°ä¸æ¶ˆå¤±ç­‰å¤æ‚çš„æ—¶ç©ºåŠ¨æ€æ–¹é¢ä»å­˜åœ¨æ¸²æŸ“ç¼“æ…¢çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€åœºæ™¯è¡¨ç¤ºæ–¹æ³•SaRO-GSï¼Œå®ƒèƒ½å¤Ÿå®æ—¶æ¸²æŸ“å¹¶æœ‰æ•ˆå¤„ç†åŠ¨æ€åœºæ™¯çš„æ—¶ç©ºå¤æ‚æ€§ã€‚ä¸ºè§£å†³æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢çš„é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºé«˜æ–¯åŸè¯­è¡¨ç¤ºçš„æ–¹æ³•ï¼Œåœ¨å››ç»´ç©ºé—´ä¸­å¯¹é«˜æ–¯è¿›è¡Œä¼˜åŒ–ï¼Œå€ŸåŠ©ä¸‰ç»´é«˜æ–¯å¹³å±•æŠ€æœ¯å®ç°å®æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œä¸ºäº†å¤„ç†å¤æ‚çš„åŠ¨æ€åœºæ™¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°ºåº¦æ„ŸçŸ¥æ®‹å·®åœºã€‚è¯¥åœºåœ¨ç¼–ç æ¯ä¸ªé«˜æ–¯åŸè¯­çš„æ®‹å·®ç‰¹å¾æ—¶è€ƒè™‘äº†å…¶å¤§å°ä¿¡æ¯ï¼Œå¹¶ä¸é«˜æ–¯åŸè¯­çš„è‡ªåˆ†è£‚è¡Œä¸ºç›¸ä¸€è‡´ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªé€‚åº”ä¼˜åŒ–è°ƒåº¦ç­–ç•¥ï¼Œæ ¹æ®é«˜æ–¯åŸè¯­çš„ä¸åŒæ—¶é—´ç‰¹æ€§ä¸ºå…¶åˆ†é…ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»è€ŒåŠ å¿«åŠ¨æ€åŒºåŸŸçš„é‡å»ºé€Ÿåº¦ã€‚åœ¨å•ç›®å’Œå¤šè§†è§’æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢äº†è§£æ›´å¤šä¿¡æ¯ï¼š<a target="_blank" rel="noopener" href="https://yjb6.github.io/SaRO-GS.github.io%E3%80%82">https://yjb6.github.io/SaRO-GS.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06299v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSaRO-GSçš„æ–°å‹åŠ¨æ€åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°å®æ—¶æ¸²æŸ“ï¼Œå¹¶æœ‰æ•ˆå¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„æ—¶é—´å¤æ‚æ€§ã€‚é€šè¿‡é‡‡ç”¨åŸºäºé«˜æ–¯åŸå§‹è¡¨ç¤ºçš„4Dç©ºé—´ä¼˜åŒ–å’Œ3Dé«˜æ–¯SplattingæŠ€æœ¯ï¼Œè§£å†³äº†æ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†å°ºåº¦æ„ŸçŸ¥æ®‹å·®åœºå’Œè‡ªé€‚åº”ä¼˜åŒ–è°ƒåº¦ç­–ç•¥ï¼Œä»¥æé«˜å¯¹å¤æ‚åŠ¨æ€åœºæ™¯çš„å¤„ç†èƒ½åŠ›å’Œä¼˜åŒ–åŠ¨æ€åŒºåŸŸçš„é‡å»ºé€Ÿåº¦ã€‚åœ¨å•ç›®å’Œå¤šè§†è§’æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†å…ˆè¿›æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SaRO-GSæ˜¯ä¸€ç§æ–°å‹åŠ¨æ€åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å®æ—¶æ¸²æŸ“å¹¶å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„æ—¶é—´å¤æ‚æ€§ã€‚</li>
<li>é‡‡ç”¨é«˜æ–¯åŸå§‹è¡¨ç¤ºçš„4Dç©ºé—´ä¼˜åŒ–å’Œ3Dé«˜æ–¯SplattingæŠ€æœ¯è§£å†³æ¸²æŸ“é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥å°ºåº¦æ„ŸçŸ¥æ®‹å·®åœºï¼Œè€ƒè™‘é«˜æ–¯åŸå§‹çš„å¤§å°ä¿¡æ¯ï¼Œç¼–ç å…¶æ®‹å·®ç‰¹å¾ï¼Œå¹¶ä¸é«˜æ–¯åŸå§‹çš„è‡ªåˆ†è£‚è¡Œä¸ºå¯¹é½ã€‚</li>
<li>æå‡ºè‡ªé€‚åº”ä¼˜åŒ–è°ƒåº¦ç­–ç•¥ï¼Œæ ¹æ®é«˜æ–¯åŸå§‹çš„ä¸åŒæ—¶é—´å±æ€§åˆ†é…ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥ï¼ŒåŠ å¿«åŠ¨æ€åŒºåŸŸçš„é‡å»ºé€Ÿåº¦ã€‚</li>
<li>æ–¹æ³•åœ¨å•ç›®å’Œå¤šè§†è§’æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>é¡¹ç›®é¡µé¢æä¾›äº†æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œèµ„æºé“¾æ¥ï¼ˆ[é“¾æ¥åœ°å€éœ€å®é™…é“¾æ¥åœ°å€æ›¿æ¢]ï¼‰ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0824dfc5893e9a8cd189fa6ea75327b1.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a232f038b19ac26745b601a7697c6c1a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-f747120b425f8856b67b30c976e24747.jpg" align="middle">
</details>




<h2 id="Advancing-Extended-Reality-with-3D-Gaussian-Splatting-Innovations-and-Prospects"><a href="#Advancing-Extended-Reality-with-3D-Gaussian-Splatting-Innovations-and-Prospects" class="headerlink" title="Advancing Extended Reality with 3D Gaussian Splatting: Innovations and   Prospects"></a>Advancing Extended Reality with 3D Gaussian Splatting: Innovations and   Prospects</h2><p><strong>Authors:Shi Qiu, Binzhu Xie, Qixuan Liu, Pheng-Ann Heng</strong></p>
<p>3D Gaussian Splatting (3DGS) has attracted significant attention for its potential to revolutionize 3D representation, rendering, and interaction. Despite the rapid growth of 3DGS research, its direct application to Extended Reality (XR) remains underexplored. Although many studies recognize the potential of 3DGS for XR, few have explicitly focused on or demonstrated its effectiveness within XR environments. In this paper, we aim to synthesize innovations in 3DGS that show specific potential for advancing XR research and development. We conduct a comprehensive review of publicly available 3DGS papers, with a focus on those referencing XR-related concepts. Additionally, we perform an in-depth analysis of innovations explicitly relevant to XR and propose a taxonomy to highlight their significance. Building on these insights, we propose several prospective XR research areas where 3DGS can make promising contributions, yet remain rarely touched. By investigating the intersection of 3DGS and XR, this paper provides a roadmap to push the boundaries of XR using cutting-edge 3DGS techniques. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰å› å…¶æ”¹å˜3Dè¡¨ç¤ºã€æ¸²æŸ“å’Œäº¤äº’çš„æ½œåŠ›è€Œå¤‡å—å…³æ³¨ã€‚å°½ç®¡3DGSç ”ç©¶å‘å±•è¿…é€Ÿï¼Œä½†å…¶åœ¨æ‰©å±•ç°å®ï¼ˆXRï¼‰ä¸­çš„ç›´æ¥åº”ç”¨ä»ç„¶è¢«å¿½è§†ã€‚å°½ç®¡è®¸å¤šç ”ç©¶è®¤è¯†åˆ°äº†3DGSåœ¨XRé¢†åŸŸçš„æ½œåŠ›ï¼Œä½†å¾ˆå°‘æœ‰ç ”ç©¶æ˜ç¡®å…³æ³¨æˆ–è¯æ˜å…¶åœ¨XRç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨åˆæˆåœ¨æ¨åŠ¨XRç ”å‘æ–¹é¢å…·æœ‰ç‰¹å®šæ½œåŠ›çš„åˆ›æ–°å‹3DGSæŠ€æœ¯ã€‚æˆ‘ä»¬å¯¹å…¬å¼€çš„å…³äºç ”ç©¶ç°çŠ¶è¿›è¡Œäº†å…¨é¢ç»¼è¿°åˆ†æè®ºæ–‡é‡ç‚¹èšç„¦äºæ¶‰åŠXRç›¸å…³æ¦‚å¿µçš„æ–‡çŒ®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ·±å…¥åˆ†æäº†ä¸XRæ˜ç¡®ç›¸å…³çš„åˆ›æ–°æŠ€æœ¯å¹¶æå‡ºäº†åˆ†ç±»ï¼Œä»¥çªå‡ºå…¶é‡è¦æ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†å‡ ä¸ªå…·æœ‰å‰æ™¯çš„XRç ”ç©¶é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä½¿ç”¨å‰æ²¿çš„3DGSæŠ€æœ¯æœ‰æœ›åšå‡ºæœ‰å‰æ™¯çš„è´¡çŒ®ï¼Œä½†ç›®å‰è¿™äº›é¢†åŸŸçš„ç ”ç©¶å¾ˆå°‘è§¦åŠã€‚æœ¬æ–‡é€šè¿‡æ¢è®¨3DGSä¸XRçš„äº¤é›†ï¼Œä¸ºä½¿ç”¨å‰æ²¿çš„3DGSæŠ€æœ¯æ¨åŠ¨XRçš„è¾¹ç•Œæä¾›äº†ä¸€æ¡è·¯çº¿å›¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06257v1">PDF</a> IEEE AIxVR 2025</p>
<p><strong>Summary</strong></p>
<p>3DGSæŠ€æœ¯å¯¹äºæ‰©å±•ç°å®ï¼ˆXRï¼‰é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå°½ç®¡å·²æœ‰ç ”ç©¶è®¤è¯†åˆ°äº†è¿™ä¸€ç‚¹ï¼Œä½†å…¶åœ¨XRç¯å¢ƒä¸­çš„å®é™…åº”ç”¨ä»è¢«è¾ƒå°‘æ¢ç´¢ã€‚æœ¬æ–‡å¯¹å…¬å¼€çš„3DGSæ–‡çŒ®è¿›è¡Œå…¨é¢å›é¡¾ï¼Œé‡ç‚¹å…³æ³¨ä¸XRç›¸å…³çš„ç ”ç©¶å†…å®¹ï¼ŒåŒæ—¶æ·±å…¥åˆ†æå¯¹XRæœ‰æ˜ç¡®æ„ä¹‰çš„æŠ€æœ¯åˆ›æ–°ï¼Œå¹¶æå‡ºåˆ†ç±»æ–¹æ¡ˆã€‚åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡æå‡ºäº†å‡ ä¸ªæœ‰æœ›ç”±3DGSæŠ€æœ¯åšå‡ºé‡è¦è´¡çŒ®çš„XRç ”ç©¶é¢†åŸŸï¼Œå¹¶ç»™å‡ºäº†ä½¿ç”¨å‰æ²¿çš„3DGSæŠ€æœ¯æ¨åŠ¨XRè¾¹ç•Œçš„ç ”ç©¶è·¯çº¿å›¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3Dé«˜æ–¯å·å±•ï¼ˆ3DGSï¼‰å…·æœ‰é©æ–°3Dè¡¨ç¤ºã€æ¸²æŸ“å’Œäº¤äº’çš„æ½œåŠ›ã€‚</li>
<li>å°½ç®¡å·²æœ‰ç ”ç©¶è®¤è¯†åˆ°äº†å…¶åœ¨æ‰©å±•ç°å®ï¼ˆXRï¼‰ä¸­çš„æ½œåŠ›ï¼Œä½†åœ¨XRç¯å¢ƒä¸­çš„å®é™…åº”ç”¨ä»è¾ƒå°‘æ¢ç´¢ã€‚</li>
<li>æœ¬æ–‡å¯¹æ¶‰åŠXRç›¸å…³çš„æ¦‚å¿µå’ŒæŠ€æœ¯åˆ›æ–°çš„æ–‡çŒ®è¿›è¡Œäº†å…¨é¢å›é¡¾å’Œåˆ†æã€‚</li>
<li>é€šè¿‡æ·±å…¥åˆ†æå¯¹XRæœ‰æ˜ç¡®æ„ä¹‰çš„æŠ€æœ¯åˆ›æ–°ï¼Œæå‡ºäº†ä¸€ä¸ªåˆ†ç±»æ–¹æ¡ˆæ¥çªå‡ºå…¶é‡è¦æ€§ã€‚</li>
<li>åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡æŒ‡å‡ºäº†å‡ ä¸ªæœ‰æœ›ç”±3DGSæŠ€æœ¯åšå‡ºé‡è¦è´¡çŒ®çš„XRç ”ç©¶é¢†åŸŸã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-170c4dec43209ea55fe0043bfe7425ef.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c94f588cc45df7fdf669a408cb194b84.jpg" align="middle">
</details>




<h2 id="Generative-Densification-Learning-to-Densify-Gaussians-for-High-Fidelity-Generalizable-3D-Reconstruction"><a href="#Generative-Densification-Learning-to-Densify-Gaussians-for-High-Fidelity-Generalizable-3D-Reconstruction" class="headerlink" title="Generative Densification: Learning to Densify Gaussians for   High-Fidelity Generalizable 3D Reconstruction"></a>Generative Densification: Learning to Densify Gaussians for   High-Fidelity Generalizable 3D Reconstruction</h2><p><strong>Authors:Seungtae Nam, Xiangyu Sun, Gyeongjin Kang, Younggeun Lee, Seungjun Oh, Eunbyung Park</strong></p>
<p>Generalized feed-forward Gaussian models have achieved significant progress in sparse-view 3D reconstruction by leveraging prior knowledge from large multi-view datasets. However, these models often struggle to represent high-frequency details due to the limited number of Gaussians. While the densification strategy used in per-scene 3D Gaussian splatting (3D-GS) optimization can be adapted to the feed-forward models, it may not be ideally suited for generalized scenarios. In this paper, we propose Generative Densification, an efficient and generalizable method to densify Gaussians generated by feed-forward models. Unlike the 3D-GS densification strategy, which iteratively splits and clones raw Gaussian parameters, our method up-samples feature representations from the feed-forward models and generates their corresponding fine Gaussians in a single forward pass, leveraging the embedded prior knowledge for enhanced generalization. Experimental results on both object-level and scene-level reconstruction tasks demonstrate that our method outperforms state-of-the-art approaches with comparable or smaller model sizes, achieving notable improvements in representing fine details. </p>
<blockquote>
<p>å¹¿ä¹‰å‰é¦ˆé«˜æ–¯æ¨¡å‹é€šè¿‡åˆ©ç”¨å¤§å‹å¤šè§†è§’æ•°æ®é›†ä¸­çš„å…ˆéªŒçŸ¥è¯†ï¼Œåœ¨ç¨€ç–è§†è§’3Dé‡å»ºæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºé«˜æ–¯æ•°é‡çš„é™åˆ¶ï¼Œè¿™äº›æ¨¡å‹å¾€å¾€éš¾ä»¥è¡¨ç¤ºé«˜é¢‘ç»†èŠ‚ã€‚è™½ç„¶åœºæ™¯3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3D-GSï¼‰ä¼˜åŒ–ä¸­ä½¿ç”¨çš„å¯†é›†åŒ–ç­–ç•¥å¯ä»¥é€‚åº”å‰é¦ˆæ¨¡å‹ï¼Œä½†å¯èƒ½å¹¶ä¸é€‚åˆé€šç”¨åœºæ™¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”Ÿæˆå¯†é›†åŒ–ï¼ˆGenerative Densificationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æœ‰æ•ˆä¸”é€šç”¨çš„æ–¹æ³•æ¥å¯†é›†åŒ–å‰é¦ˆæ¨¡å‹äº§ç”Ÿçš„é«˜æ–¯ã€‚ä¸3D-GSå¯†é›†åŒ–ç­–ç•¥ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯åœ¨è¿­ä»£ä¸­åˆ†è£‚å’Œå…‹éš†åŸå§‹é«˜æ–¯å‚æ•°ï¼Œè€Œæ˜¯å¯¹å‰é¦ˆæ¨¡å‹çš„ç‰¹æ€§è¡¨ç¤ºè¿›è¡Œä¸Šé‡‡æ ·ï¼Œå¹¶åœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆå…¶å¯¹åº”çš„ç²¾ç»†é«˜æ–¯ï¼Œåˆ©ç”¨åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†æ¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨å¯¹è±¡çº§å’Œåœºæ™¯çº§çš„é‡å»ºä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰ç›¸å½“æˆ–æ›´å°æ¨¡å‹å¤§å°çš„æœ€å…ˆè¿›æ–¹æ³•ä¸­è¡¨ç°æ›´å¥½ï¼Œåœ¨è¡¨ç¤ºç»†èŠ‚æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06234v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹å¹¿ä¹‰ç¨€ç–è§†å›¾3Dé‡å»ºçš„é«˜æ•ˆå¯æ³›åŒ–æ–¹æ³•â€”â€”ç”Ÿæˆå‹ç¨ åŒ–æ³•ã€‚é€šè¿‡åœ¨å‰é¦ˆæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬ä¸Šè¿›è¡Œç¨ åŒ–ï¼Œæå‡äº†æ¨¡å‹å¯¹é«˜é¢‘ç»†èŠ‚çš„è¡¨è¾¾èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„é€åœºæ™¯ä¸‰ç»´é«˜æ–¯æ¨¡ç³Šï¼ˆ3D-GSï¼‰ä¼˜åŒ–ä¸åŒï¼Œç”Ÿæˆå‹ç¨ åŒ–æ³•åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­å³å¯ç”Ÿæˆç²¾ç»†çš„é«˜æ–¯æ•°æ®ï¼Œå®ç°äº†æ›´ä½³çš„æ³›åŒ–æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ä½“çº§åˆ«å’Œåœºæ™¯çº§åˆ«çš„é‡å»ºä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸”åœ¨æ¨¡å‹å¤§å°ç›¸å½“çš„æƒ…å†µä¸‹è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¹¿ä¹‰å‰é¦ˆé«˜æ–¯æ¨¡å‹åœ¨ç¨€ç–è§†å›¾3Dé‡å»ºä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å—é™äºé«˜æ–¯æ•°é‡çš„é«˜é¢‘ç»†èŠ‚è¡¨ç¤ºèƒ½åŠ›è¾ƒå¼±ã€‚</li>
<li>ä¼ ç»Ÿçš„é«˜æ–¯ç¨ åŒ–ç­–ç•¥ï¼ˆå¦‚3D-GSï¼‰å¯èƒ½ä¸é€‚ç”¨äºå‰é¦ˆæ¨¡å‹çš„æ³›åŒ–åœºæ™¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿæˆå‹ç¨ åŒ–æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å‰é¦ˆæ¨¡å‹ç”Ÿæˆçš„æ ·æœ¬ä¸Šè¿›è¡Œç¨ åŒ–ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé«˜é¢‘ç»†èŠ‚è¡¨è¾¾èƒ½åŠ›ã€‚</li>
<li>ç”Ÿæˆå‹ç¨ åŒ–æ³•åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç”Ÿæˆç²¾ç»†çš„é«˜æ–¯æ•°æ®ï¼Œä¸åŒäºä¼ ç»Ÿçš„è¿­ä»£åˆ†è£‚å’Œå…‹éš†åŸå§‹é«˜æ–¯å‚æ•°çš„æ–¹æ³•ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç‰©ä½“çº§åˆ«å’Œåœºæ™¯çº§åˆ«çš„é‡å»ºä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ¨¡å‹å¤§å°ç›¸å½“çš„æƒ…å†µä¸‹è¡¨ç°å‡ºæ›´ä½³çš„æ€§èƒ½ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-132387334ec02d1446d2a5caa01a14cb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-12c21ec02bc369626374a35959e07bce.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-4479be5547324d83fdeaa3b58677659d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-85956cf4f31294f70d75d86762b95a87.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5eaeea5479222becb5295f8a93d2c29c.jpg" align="middle">
</details>




<h2 id="Efficient-Semantic-Splatting-for-Remote-Sensing-Multi-view-Segmentation"><a href="#Efficient-Semantic-Splatting-for-Remote-Sensing-Multi-view-Segmentation" class="headerlink" title="Efficient Semantic Splatting for Remote Sensing Multi-view Segmentation"></a>Efficient Semantic Splatting for Remote Sensing Multi-view Segmentation</h2><p><strong>Authors:Zipeng Qi, Hao Chen, Haotian Zhang, Zhengxia Zou, Zhenwei Shi</strong></p>
<p>In this paper, we propose a novel semantic splatting approach based on Gaussian Splatting to achieve efficient and low-latency. Our method projects the RGB attributes and semantic features of point clouds onto the image plane, simultaneously rendering RGB images and semantic segmentation results. Leveraging the explicit structure of point clouds and a one-time rendering strategy, our approach significantly enhances efficiency during optimization and rendering. Additionally, we employ SAM2 to generate pseudo-labels for boundary regions, which often lack sufficient supervision, and introduce two-level aggregation losses at the 2D feature map and 3D spatial levels to improve the view-consistent and spatial continuity. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯Splattingçš„æ–°å‹è¯­ä¹‰Splattingæ–¹æ³•ï¼Œä»¥å®ç°é«˜æ•ˆå’Œä½å»¶è¿Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ç‚¹äº‘çš„RGBå±æ€§å’Œè¯­ä¹‰ç‰¹å¾æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šï¼ŒåŒæ—¶å‘ˆç°RGBå›¾åƒå’Œè¯­ä¹‰åˆ†å‰²ç»“æœã€‚æˆ‘ä»¬åˆ©ç”¨ç‚¹äº‘çš„æ˜ç¡®ç»“æ„å’Œä¸€æ¬¡æ€§æ¸²æŸ“ç­–ç•¥ï¼Œåœ¨ä¼˜åŒ–å’Œæ¸²æŸ“è¿‡ç¨‹ä¸­æ˜¾è‘—æé«˜æ•ˆç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨SAM2ä¸ºç¼ºä¹è¶³å¤Ÿç›‘ç£çš„è¾¹ç•ŒåŒºåŸŸç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œå¹¶åœ¨äºŒç»´ç‰¹å¾å›¾å’Œä¸‰ç»´ç©ºé—´å±‚æ¬¡ä¸Šå¼•å…¥ä¸¤çº§èšåˆæŸå¤±ï¼Œä»¥æé«˜è§†å›¾ä¸€è‡´æ€§å’Œç©ºé—´è¿ç»­æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05969v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æŠ•å½±çš„è¯­ä¹‰ç‚¹äº‘æ˜ å°„æŠ€æœ¯ï¼Œå®ç°äº†é«˜æ•ˆå’Œä½å»¶è¿Ÿçš„æ¸²æŸ“æ•ˆæœã€‚è¯¥æ–¹æ³•å°†ç‚¹äº‘çš„RGBå±æ€§å’Œè¯­ä¹‰ç‰¹å¾æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šï¼ŒåŒæ—¶ç”ŸæˆRGBå›¾åƒå’Œè¯­ä¹‰åˆ†å‰²ç»“æœã€‚é€šè¿‡åˆ©ç”¨ç‚¹äº‘çš„æ˜ç¡®ç»“æ„å’Œä¸€æ¬¡æ¸²æŸ“ç­–ç•¥ï¼Œæé«˜äº†ä¼˜åŒ–å’Œæ¸²æŸ“è¿‡ç¨‹çš„æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨SAM2æŠ€æœ¯ä¸ºè¾¹ç•ŒåŒºåŸŸç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œè§£å†³äº†ç›‘ç£ä¸è¶³çš„é—®é¢˜ï¼Œå¹¶å¼•å…¥äºŒç»´ç‰¹å¾å›¾å’Œä¸‰ç»´ç©ºé—´ä¸¤ä¸ªçº§åˆ«çš„èšåˆæŸå¤±ï¼Œæé«˜äº†è§†å›¾ä¸€è‡´æ€§å’Œç©ºé—´è¿ç»­æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºé«˜æ–¯æŠ•å½±çš„è¯­ä¹‰ç‚¹äº‘æ˜ å°„æ–¹æ³•ï¼Œå®ç°äº†é«˜æ•ˆå’Œä½å»¶è¿Ÿçš„æ¸²æŸ“ã€‚</li>
<li>æ–¹æ³•å°†ç‚¹äº‘çš„RGBå±æ€§å’Œè¯­ä¹‰ç‰¹å¾æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šï¼ŒåŒæ—¶ç”ŸæˆRGBå›¾åƒå’Œè¯­ä¹‰åˆ†å‰²ç»“æœã€‚</li>
<li>åˆ©ç”¨ç‚¹äº‘çš„æ˜ç¡®ç»“æ„å’Œä¸€æ¬¡æ¸²æŸ“ç­–ç•¥ï¼Œæé«˜äº†ä¼˜åŒ–å’Œæ¸²æŸ“çš„æ•ˆç‡ã€‚</li>
<li>ä½¿ç”¨SAM2æŠ€æœ¯ä¸ºè¾¹ç•ŒåŒºåŸŸç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œè§£å†³ç›‘ç£ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥äºŒç»´ç‰¹å¾å›¾å’Œä¸‰ç»´ç©ºé—´ä¸¤ä¸ªçº§åˆ«çš„èšåˆæŸå¤±ï¼Œæé«˜äº†è§†å›¾ä¸€è‡´æ€§å’Œç©ºé—´è¿ç»­æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰éœ€è¦é«˜æ•ˆæ¸²æŸ“çš„é¢†åŸŸã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-60778ac7ab810578fdf49d79641cfdeb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-938afbcaab2fd784bf1e56b4a8ed630d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-d736ab67df80ac632916ef225b983c40.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-e0d5647eeb43d4a997328c2a4a53b302.jpg" align="middle">
</details>




<h2 id="GBR-Generative-Bundle-Refinement-for-High-fidelity-Gaussian-Splatting-and-Meshing"><a href="#GBR-Generative-Bundle-Refinement-for-High-fidelity-Gaussian-Splatting-and-Meshing" class="headerlink" title="GBR: Generative Bundle Refinement for High-fidelity Gaussian Splatting   and Meshing"></a>GBR: Generative Bundle Refinement for High-fidelity Gaussian Splatting   and Meshing</h2><p><strong>Authors:Jianing Zhang, Yuchao Zheng, Ziwei Li, Qionghai Dai, Xiaoyun Yuan</strong></p>
<p>Gaussian splatting has gained attention for its efficient representation and rendering of 3D scenes using continuous Gaussian primitives. However, it struggles with sparse-view inputs due to limited geometric and photometric information, causing ambiguities in depth, shape, and texture.   we propose GBR: Generative Bundle Refinement, a method for high-fidelity Gaussian splatting and meshing using only 4-6 input views. GBR integrates a neural bundle adjustment module to enhance geometry accuracy and a generative depth refinement module to improve geometry fidelity. More specifically, the neural bundle adjustment module integrates a foundation network to produce initial 3D point maps and point matches from unposed images, followed by bundle adjustment optimization to improve multiview consistency and point cloud accuracy. The generative depth refinement module employs a diffusion-based strategy to enhance geometric details and fidelity while preserving the scale. Finally, for Gaussian splatting optimization, we propose a multimodal loss function incorporating depth and normal consistency, geometric regularization, and pseudo-view supervision, providing robust guidance under sparse-view conditions. Experiments on widely used datasets show that GBR significantly outperforms existing methods under sparse-view inputs. Additionally, GBR demonstrates the ability to reconstruct and render large-scale real-world scenes, such as the Pavilion of Prince Teng and the Great Wall, with remarkable details using only 6 views. </p>
<blockquote>
<p>é«˜æ–¯ç‚¹äº‘æŠ€æœ¯å› å…¶ä½¿ç”¨è¿ç»­çš„é«˜æ–¯åŸºå…ƒå¯¹3Dåœºæ™¯è¿›è¡Œé«˜æ•ˆè¡¨ç¤ºå’Œæ¸²æŸ“è€Œå—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºå‡ ä½•å’Œå…‰åº¦ä¿¡æ¯æœ‰é™ï¼Œå®ƒåœ¨ç¨€ç–è§†å›¾è¾“å…¥æ–¹é¢è¡¨ç°æŒ£æ‰ï¼Œå¯¼è‡´æ·±åº¦ã€å½¢çŠ¶å’Œçº¹ç†çš„æ¨¡ç³Šæ€§ã€‚æˆ‘ä»¬æå‡ºGBRï¼šç”ŸæˆæŸè°ƒæ•´æ³•ï¼ˆGenerative Bundle Refinementï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä»…ä½¿ç”¨4-6ä¸ªè¾“å…¥è§†å›¾è¿›è¡Œé«˜ä¿çœŸé«˜æ–¯ç‚¹äº‘å’Œç½‘æ ¼åŒ–çš„æ–¹æ³•ã€‚GBRé›†æˆäº†ä¸€ä¸ªç¥ç»æŸè°ƒæ•´æ¨¡å—ï¼Œä»¥æé«˜å‡ ä½•ç²¾åº¦å’Œä¸€ä¸ªç”Ÿæˆæ·±åº¦ç»†åŒ–æ¨¡å—ï¼Œä»¥æé«˜å‡ ä½•ä¿çœŸåº¦ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œç¥ç»æŸè°ƒæ•´æ¨¡å—é›†æˆäº†ä¸€ä¸ªåŸºç¡€ç½‘ç»œï¼Œç”¨äºä»éå®šä½å›¾åƒç”Ÿæˆåˆå§‹çš„3Dç‚¹å›¾å’Œç‚¹åŒ¹é…ï¼Œç„¶åè¿›è¡ŒæŸè°ƒæ•´ä¼˜åŒ–ï¼Œä»¥æé«˜å¤šè§†å›¾çš„ä¸€è‡´æ€§å’Œç‚¹äº‘ç²¾åº¦ã€‚ç”Ÿæˆæ·±åº¦ç»†åŒ–æ¨¡å—é‡‡ç”¨åŸºäºæ‰©æ•£çš„ç­–ç•¥ï¼Œä»¥å¢å¼ºå‡ ä½•ç»†èŠ‚å’Œä¿çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒå°ºåº¦ã€‚æœ€åï¼Œé’ˆå¯¹é«˜æ–¯ç‚¹äº‘ä¼˜åŒ–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€æŸå¤±å‡½æ•°ï¼Œèåˆäº†æ·±åº¦å’Œæ³•å‘é‡ä¸€è‡´æ€§ã€å‡ ä½•æ­£åˆ™åŒ–å’Œä¼ªè§†å›¾ç›‘ç£ï¼Œåœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹æä¾›ç¨³å¥çš„å¼•å¯¼ã€‚åœ¨å¸¸ç”¨æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGBRåœ¨ç¨€ç–è§†å›¾è¾“å…¥ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒGBRè¿˜å±•ç¤ºäº†ä»…ä½¿ç”¨6ä¸ªè§†å›¾å°±èƒ½é‡å»ºå’Œæ¸²æŸ“å¤§è§„æ¨¡çœŸå®åœºæ™¯ï¼Œå¦‚å¤ªå­äº­å’Œå¤§é•¿åŸï¼Œå…·æœ‰ä»¤äººç©ç›®çš„ç»†èŠ‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05908v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†åŸºäºé«˜æ–¯åŸè¯­çš„è¿ç»­é«˜æ–¯è’™çš®æ–¹æ³•åŠå…¶åœ¨ç¨€ç–è§†è§’è¾“å…¥ä¸‹çš„é«˜æ•ˆè¡¨ç¤ºå’Œæ¸²æŸ“ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæå‡ºäº†GBRï¼ˆç”ŸæˆæŸä¼˜åŒ–æ³•ï¼‰ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œæŸè°ƒæ•´æ¨¡å—æé«˜å‡ ä½•ç²¾åº¦ï¼Œé€šè¿‡ç”Ÿæˆæ·±åº¦ç»†åŒ–æ¨¡å—æé«˜å‡ ä½•ä¿çœŸåº¦ã€‚GBRåœ¨ä»…ä½¿ç”¨4-6ä¸ªè¾“å…¥è§†è§’çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†é«˜ä¿çœŸåº¦çš„é«˜æ–¯è’™çš®å’Œç½‘æ ¼ç”Ÿæˆã€‚å®éªŒè¯æ˜ï¼Œåœ¨ç¨€ç–è§†è§’è¾“å…¥ä¸‹ï¼ŒGBRæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½é‡å»ºå’Œæ¸²æŸ“å¤§è§„æ¨¡çœŸå®åœºæ™¯ï¼Œå¦‚æ»•å…¬æ®¿å’Œé•¿åŸç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯è’™çš®æ–¹æ³•ä½¿ç”¨è¿ç»­é«˜æ–¯åŸè¯­è¿›è¡Œä¸‰ç»´åœºæ™¯çš„è¡¨ç¤ºå’Œæ¸²æŸ“ï¼Œä½†å…¶åœ¨ç¨€ç–è§†è§’è¾“å…¥ä¸‹å­˜åœ¨æ·±åº¦ã€å½¢çŠ¶å’Œçº¹ç†çš„æ­§ä¹‰æ€§é—®é¢˜ã€‚</li>
<li>GBRé€šè¿‡ç¥ç»ç½‘ç»œæŸè°ƒæ•´æ¨¡å—å’Œç”Ÿæˆæ·±åº¦ç»†åŒ–æ¨¡å—è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæé«˜å‡ ä½•ç²¾åº¦å’Œå‡ ä½•ä¿çœŸåº¦ã€‚</li>
<li>GBRä»…ä½¿ç”¨4-6ä¸ªè§†è§’çš„è¾“å…¥ï¼Œå³å¯å®ç°é«˜ä¿çœŸåº¦çš„é«˜æ–¯è’™çš®å’Œç½‘æ ¼ç”Ÿæˆã€‚</li>
<li>GBRä½¿ç”¨å¤šæ¨¡æ€æŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼Œè¯¥å‡½æ•°åœ¨ç¨€ç–è§†è§’æ¡ä»¶ä¸‹æä¾›ç¨³å¥çš„å¼•å¯¼ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒGBRåœ¨ç¨€ç–è§†è§’è¾“å…¥ä¸‹çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>GBRèƒ½å¤Ÿé‡å»ºå’Œæ¸²æŸ“å¤§è§„æ¨¡çœŸå®åœºæ™¯ï¼Œå¦‚æ»•å…¬æ®¿å’Œé•¿åŸç­‰ï¼Œå¹¶å±•ç°å‡ºç²¾ç»†çš„ç»†èŠ‚ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-167f7f5c1162a0cbbb76ab69b560779f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1d4abcfecce6bc3b503531f33bac12d3.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a04c5950f1c04421a1a30fbd82b28c91.jpg" align="middle">
</details>




<h2 id="SizeGS-Size-aware-Compression-of-3D-Gaussians-with-Hierarchical-Mixed-Precision-Quantization"><a href="#SizeGS-Size-aware-Compression-of-3D-Gaussians-with-Hierarchical-Mixed-Precision-Quantization" class="headerlink" title="SizeGS: Size-aware Compression of 3D Gaussians with Hierarchical Mixed   Precision Quantization"></a>SizeGS: Size-aware Compression of 3D Gaussians with Hierarchical Mixed   Precision Quantization</h2><p><strong>Authors:Shuzhao Xie, Jiahang Liu, Weixiang Zhang, Shijia Ge, Sicheng Pan, Chen Tang, Yunpeng Bai, Zhi Wang</strong></p>
<p>Effective compression technology is crucial for 3DGS to adapt to varying storage and transmission conditions. However, existing methods fail to address size constraints while maintaining optimal quality. In this paper, we introduce SizeGS, a framework that compresses 3DGS within a specified size budget while optimizing visual quality. We start with a size estimator to establish a clear relationship between file size and hyperparameters. Leveraging this estimator, we incorporate mixed precision quantization (MPQ) into 3DGS attributes, structuring MPQ in two hierarchical level â€“ inter-attribute and intra-attribute â€“ to optimize visual quality under the size constraint. At the inter-attribute level, we assign bit-widths to each attribute channel by formulating the combinatorial optimization as a 0-1 integer linear program, which can be efficiently solved. At the intra-attribute level, we divide each attribute channel into blocks of vectors, quantizing each vector based on the optimal bit-width derived at the inter-attribute level. Dynamic programming determines block lengths. Using the size estimator and MPQ, we develop a calibrated algorithm to identify optimal hyperparameters in just 10 minutes, achieving a 1.69$\times$ efficiency increase with quality comparable to state-of-the-art methods. </p>
<blockquote>
<p>æœ‰æ•ˆçš„å‹ç¼©æŠ€æœ¯å¯¹äº3DGSé€‚åº”ä¸åŒçš„å­˜å‚¨å’Œä¼ è¾“æ¡ä»¶è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•æ— æ³•åœ¨ä¿æŒæœ€ä¼˜è´¨é‡çš„åŒæ—¶è§£å†³å¤§å°çº¦æŸé—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SizeGSæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨æŒ‡å®šçš„å¤§å°é¢„ç®—å†…å‹ç¼©3DGSï¼ŒåŒæ—¶ä¼˜åŒ–è§†è§‰è´¨é‡ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å¤§å°ä¼°è®¡å™¨æ¥å»ºç«‹æ–‡ä»¶å¤§å°ä¸è¶…å‚æ•°ä¹‹é—´çš„æ˜ç¡®å…³ç³»ã€‚åˆ©ç”¨è¿™ä¸ªä¼°è®¡å™¨ï¼Œæˆ‘ä»¬å°†æ··åˆç²¾åº¦é‡åŒ–ï¼ˆMPQï¼‰èå…¥åˆ°3DGSå±æ€§ä¸­ï¼Œå°†MPQæ„å»ºä¸ºä¸¤ä¸ªå±‚æ¬¡â€”â€”è·¨å±æ€§å†…å’Œå±æ€§å†…ï¼Œä»¥åœ¨å¤§å°çº¦æŸä¸‹ä¼˜åŒ–è§†è§‰è´¨é‡ã€‚åœ¨è·¨å±æ€§å±‚é¢ï¼Œæˆ‘ä»¬é€šè¿‡å°†ç»„åˆä¼˜åŒ–åˆ¶å®šä¸º0-1æ•´æ•°çº¿æ€§è§„åˆ’æ¥ä¸ºæ¯ä¸ªå±æ€§é€šé“åˆ†é…ä½å®½ï¼Œè¿™å¯ä»¥é«˜æ•ˆæ±‚è§£ã€‚åœ¨å±æ€§å†…éƒ¨å±‚é¢ï¼Œæˆ‘ä»¬å°†æ¯ä¸ªå±æ€§é€šé“åˆ†ä¸ºå‘é‡å—ï¼ŒåŸºäºè·¨å±æ€§å±‚é¢å¾—å‡ºçš„æœ€ä¼˜ä½å®½å¯¹æ¯ä¸ªå‘é‡è¿›è¡Œé‡åŒ–ã€‚åŠ¨æ€è§„åˆ’ç¡®å®šå—é•¿åº¦ã€‚é€šè¿‡ä½¿ç”¨å¤§å°ä¼°è®¡å™¨å’ŒMPQï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ ¡å‡†ç®—æ³•ï¼Œåªéœ€10åˆ†é’Ÿå³å¯ç¡®å®šæœ€ä½³è¶…å‚æ•°ï¼Œå®ç°äº†1.69å€çš„æ•ˆç‡æå‡ï¼ŒåŒæ—¶è´¨é‡å¯ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸åª²ç¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05808v1">PDF</a> Automatically compressing 3DGS into the desired file size while   maximizing the visual quality</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºSizeGSæ¡†æ¶ï¼Œé’ˆå¯¹3DGSè¿›è¡Œå‹ç¼©ï¼Œåœ¨é™å®šæ–‡ä»¶å¤§å°çš„åŒæ—¶ä¼˜åŒ–è§†è§‰è´¨é‡ã€‚é€šè¿‡å°ºå¯¸ä¼°è®¡å™¨å»ºç«‹æ–‡ä»¶å¤§å°ä¸è¶…å‚æ•°ä¹‹é—´çš„å…³ç³»ï¼Œç»“åˆæ··åˆç²¾åº¦é‡åŒ–ï¼ˆMPQï¼‰æŠ€æœ¯ï¼Œåˆ†ä¸¤çº§ä¼˜åŒ–è§†è§‰è´¨é‡ã€‚åœ¨å±æ€§é—´çº§åˆ«ï¼Œé€šè¿‡ç»„åˆä¼˜åŒ–å…¬å¼åˆ†é…å„å±æ€§é€šé“çš„ä½å®½ï¼Œä»¥0-1æ•´æ•°çº¿æ€§è§„åˆ’æ±‚è§£ï¼›åœ¨å±æ€§å†…çº§åˆ«ï¼Œå°†æ¯ä¸ªå±æ€§é€šé“åˆ†ä¸ºå‘é‡å—è¿›è¡Œé‡åŒ–ã€‚ä½¿ç”¨å°ºå¯¸ä¼°è®¡å™¨å’ŒMPQï¼Œå¼€å‘å‡ºé«˜æ•ˆæ ¡å‡†çš„ç®—æ³•ï¼Œå¯åœ¨çŸ­æ—¶é—´å†…ç¡®å®šæœ€ä½³è¶…å‚æ•°ï¼Œæé«˜æ•ˆç‡1.69å€ï¼ŒåŒæ—¶ä¿æŒä¸ç°æœ‰æŠ€æœ¯ç›¸å½“çš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SizeGSæ¡†æ¶ç”¨äº3DGSå‹ç¼©ï¼Œå¯åœ¨é™å®šæ–‡ä»¶å¤§å°çš„åŒæ—¶ä¼˜åŒ–è§†è§‰è´¨é‡ã€‚</li>
<li>å¼•å…¥å°ºå¯¸ä¼°è®¡å™¨æ¥å»ºç«‹æ–‡ä»¶å¤§å°ä¸è¶…å‚æ•°ä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>ç»“åˆæ··åˆç²¾åº¦é‡åŒ–ï¼ˆMPQï¼‰æŠ€æœ¯ï¼Œå®ç°ä¸¤çº§ä¼˜åŒ–è§†è§‰è´¨é‡ï¼šå±æ€§é—´å’Œå±æ€§å†…ã€‚</li>
<li>åœ¨å±æ€§é—´çº§åˆ«ï¼Œé€šè¿‡0-1æ•´æ•°çº¿æ€§è§„åˆ’åˆ†é…å„å±æ€§é€šé“çš„ä½å®½ã€‚</li>
<li>åœ¨å±æ€§å†…çº§åˆ«ï¼Œå°†å±æ€§é€šé“åˆ†ä¸ºå‘é‡å—è¿›è¡Œé‡åŒ–ã€‚</li>
<li>ä½¿ç”¨å°ºå¯¸ä¼°è®¡å™¨å’ŒMPQå¼€å‘å‡ºé«˜æ•ˆæ ¡å‡†çš„ç®—æ³•ï¼ŒçŸ­æ—¶é—´å†…ç¡®å®šæœ€ä½³è¶…å‚æ•°ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5440c4116fa3d5e74b78b387f09a0116.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-97d082d93e70773fbb7d83894513ef83.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-bd928a663f386a4b22c448bcbb8b1b79.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-9efa675795194e23be8af92e3d907314.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-f47bda1166d2c05c6a471c9809d952cf.jpg" align="middle">
</details>




<h2 id="Temporally-Compressed-3D-Gaussian-Splatting-for-Dynamic-Scenes"><a href="#Temporally-Compressed-3D-Gaussian-Splatting-for-Dynamic-Scenes" class="headerlink" title="Temporally Compressed 3D Gaussian Splatting for Dynamic Scenes"></a>Temporally Compressed 3D Gaussian Splatting for Dynamic Scenes</h2><p><strong>Authors:Saqib Javed, Ahmad Jarrar Khan, Corentin Dumery, Chen Zhao, Mathieu Salzmann</strong></p>
<p>Recent advancements in high-fidelity dynamic scene reconstruction have leveraged dynamic 3D Gaussians and 4D Gaussian Splatting for realistic scene representation. However, to make these methods viable for real-time applications such as AR&#x2F;VR, gaming, and rendering on low-power devices, substantial reductions in memory usage and improvements in rendering efficiency are required. While many state-of-the-art methods prioritize lightweight implementations, they struggle in handling scenes with complex motions or long sequences. In this work, we introduce Temporally Compressed 3D Gaussian Splatting (TC3DGS), a novel technique designed specifically to effectively compress dynamic 3D Gaussian representations. TC3DGS selectively prunes Gaussians based on their temporal relevance and employs gradient-aware mixed-precision quantization to dynamically compress Gaussian parameters. It additionally relies on a variation of the Ramer-Douglas-Peucker algorithm in a post-processing step to further reduce storage by interpolating Gaussian trajectories across frames. Our experiments across multiple datasets demonstrate that TC3DGS achieves up to 67$\times$ compression with minimal or no degradation in visual quality. </p>
<blockquote>
<p>è¿‘æœŸé«˜ä¿çœŸåŠ¨æ€åœºæ™¯é‡å»ºçš„æœ€æ–°è¿›å±•åˆ©ç”¨åŠ¨æ€ä¸‰ç»´é«˜æ–¯å’Œå››ç»´é«˜æ–¯æº…å°„è¿›è¡ŒçœŸå®åœºæ™¯è¡¨ç¤ºã€‚ç„¶è€Œï¼Œä¸ºäº†ä½¿è¿™äº›æ–¹æ³•å¯¹äºå¢å¼ºç°å®&#x2F;è™šæ‹Ÿç°å®ã€æ¸¸æˆå’Œåœ¨ä½åŠŸè€—è®¾å¤‡ä¸Šè¿›è¡Œæ¸²æŸ“ç­‰å®æ—¶åº”ç”¨å˜å¾—å¯è¡Œï¼Œéœ€è¦å¤§å¹…åº¦å‡å°‘å†…å­˜ä½¿ç”¨å¹¶æé«˜æ¸²æŸ“æ•ˆç‡ã€‚è™½ç„¶è®¸å¤šæœ€æ–°æ–¹æ³•éƒ½ä¼˜å…ˆè€ƒè™‘è½»ä¾¿çš„å®ç°ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†å¤æ‚è¿åŠ¨åœºæ™¯æˆ–é•¿åºåˆ—æ—¶é‡åˆ°å›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ—¶é—´å‹ç¼©ä¸‰ç»´é«˜æ–¯æº…å°„ï¼ˆTC3DGSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡ç”¨äºæœ‰æ•ˆå‹ç¼©åŠ¨æ€ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºçš„æ–°æŠ€æœ¯ã€‚TC3DGSæ ¹æ®é«˜æ–¯çš„æ—¶é—´ç›¸å…³æ€§é€‰æ‹©æ€§åœ°åˆ é™¤é«˜æ–¯ï¼Œå¹¶é‡‡ç”¨æ¢¯åº¦æ„ŸçŸ¥æ··åˆç²¾åº¦é‡åŒ–æ¥åŠ¨æ€å‹ç¼©é«˜æ–¯å‚æ•°ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜åœ¨åå¤„ç†æ­¥éª¤ä¸­ä¾èµ–Ramer-Douglas-Peuckerç®—æ³•çš„å˜ä½“ï¼Œé€šè¿‡è·¨å¸§æ’å€¼é«˜æ–¯è½¨è¿¹æ¥è¿›ä¸€æ­¥å‡å°‘å­˜å‚¨ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTC3DGSå®ç°äº†é«˜è¾¾67å€çš„å‹ç¼©ï¼Œè§†è§‰è´¨é‡å‡ ä¹æ²¡æœ‰æˆ–æ²¡æœ‰é™çº§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05700v1">PDF</a> Code will be released soon</p>
<p><strong>Summary</strong><br>     æœ€æ–°é«˜ä¿çœŸåŠ¨æ€åœºæ™¯é‡å»ºæŠ€æœ¯åˆ©ç”¨åŠ¨æ€3Dé«˜æ–¯å’Œ4Dé«˜æ–¯æ³¼æº…è¿›è¡ŒçœŸå®åœºæ™¯è¡¨ç¤ºã€‚ä¸ºä½¿è¿™äº›æ–¹æ³•é€‚ç”¨äºAR&#x2F;VRã€æ¸¸æˆå’Œä½åŠŸè€—è®¾å¤‡çš„å®æ—¶æ¸²æŸ“ï¼Œéœ€è¦å¤§å¹…å‡å°‘å†…å­˜ä½¿ç”¨å¹¶æé«˜æ¸²æŸ“æ•ˆç‡ã€‚æˆ‘ä»¬å¼•å…¥æ—¶é—´å‹ç¼©3Dé«˜æ–¯æ³¼æº…ï¼ˆTC3DGSï¼‰æ–°æŠ€æœ¯ï¼Œä¸“é—¨æœ‰æ•ˆå‹ç¼©åŠ¨æ€3Dé«˜æ–¯è¡¨ç¤ºã€‚TC3DGSåŸºäºæ—¶é—´ç›¸å…³æ€§é€‰æ‹©æ€§åˆ é™¤é«˜æ–¯ï¼Œå¹¶é‡‡ç”¨æ¢¯åº¦æ„ŸçŸ¥æ··åˆç²¾åº¦é‡åŒ–è¿›è¡ŒåŠ¨æ€å‹ç¼©é«˜æ–¯å‚æ•°ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨åå¤„ç†æ­¥éª¤ä¸­é‡‡ç”¨Ramer-Douglas-Peuckerç®—æ³•çš„å˜ä½“ï¼Œé€šè¿‡è·¨å¸§æ’å€¼é«˜æ–¯è½¨è¿¹è¿›ä¸€æ­¥å‡å°‘å­˜å‚¨ã€‚å®éªŒè¯æ˜ï¼ŒTC3DGSå¯å®ç°é«˜è¾¾67å€çš„å‹ç¼©ï¼Œè§†è§‰è´¨é‡å‡ ä¹æ— æŸå¤±æˆ–å‡ ä¹æ²¡æœ‰é€€åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ€æ–°æŠ€æœ¯åˆ©ç”¨åŠ¨æ€3Dé«˜æ–¯å’Œ4Dé«˜æ–¯æ³¼æº…è¿›è¡Œé«˜ä¿çœŸåŠ¨æ€åœºæ™¯é‡å»ºã€‚</li>
<li>ä¸ºå®ç°å®æ—¶åº”ç”¨ï¼Œéœ€è¦é™ä½å†…å­˜ä½¿ç”¨å’Œæé«˜æ¸²æŸ“æ•ˆç‡ã€‚</li>
<li>å¼•å…¥TC3DGSæŠ€æœ¯ï¼Œä¸“é—¨å‹ç¼©åŠ¨æ€3Dé«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>TC3DGSåŸºäºæ—¶é—´ç›¸å…³æ€§é€‰æ‹©æ€§åˆ é™¤é«˜æ–¯ã€‚</li>
<li>é‡‡ç”¨æ¢¯åº¦æ„ŸçŸ¥æ··åˆç²¾åº¦é‡åŒ–è¿›è¡ŒåŠ¨æ€å‹ç¼©é«˜æ–¯å‚æ•°ã€‚</li>
<li>åå¤„ç†æ­¥éª¤é‡‡ç”¨Ramer-Douglas-Peuckerç®—æ³•çš„å˜ä½“è¿›ä¸€æ­¥å‡å°‘å­˜å‚¨ã€‚</li>
<li>å®éªŒè¯æ˜TC3DGSå¯å®ç°é«˜æ•ˆå‹ç¼©ï¼Œä¸”è§†è§‰è´¨é‡æ— æ˜æ˜¾æŸå¤±ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1f5ae46c56b33d01fdfea9703f62b659.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ead58ca06a529dd568169f0b67f608f1.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-a0ef219baebd73070f7137e4a9e6c833.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-e0959fff05e4eb67c684994c0a5a127f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-340564ff43174bc0f92c230d4aaca694.jpg" align="middle">
</details>




<h2 id="Template-free-Articulated-Gaussian-Splatting-for-Real-time-Reposable-Dynamic-View-Synthesis"><a href="#Template-free-Articulated-Gaussian-Splatting-for-Real-time-Reposable-Dynamic-View-Synthesis" class="headerlink" title="Template-free Articulated Gaussian Splatting for Real-time Reposable   Dynamic View Synthesis"></a>Template-free Articulated Gaussian Splatting for Real-time Reposable   Dynamic View Synthesis</h2><p><strong>Authors:Diwen Wan, Yuxiang Wang, Ruijie Lu, Gang Zeng</strong></p>
<p>While novel view synthesis for dynamic scenes has made significant progress, capturing skeleton models of objects and re-posing them remains a challenging task. To tackle this problem, in this paper, we propose a novel approach to automatically discover the associated skeleton model for dynamic objects from videos without the need for object-specific templates. Our approach utilizes 3D Gaussian Splatting and superpoints to reconstruct dynamic objects. Treating superpoints as rigid parts, we can discover the underlying skeleton model through intuitive cues and optimize it using the kinematic model. Besides, an adaptive control strategy is applied to avoid the emergence of redundant superpoints. Extensive experiments demonstrate the effectiveness and efficiency of our method in obtaining re-posable 3D objects. Not only can our approach achieve excellent visual fidelity, but it also allows for the real-time rendering of high-resolution images. </p>
<blockquote>
<p>å…³äºåŠ¨æ€åœºæ™¯çš„æ–°è§†å›¾åˆæˆè™½ç„¶å·²ç»æœ‰äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†æ•æ‰ç‰©ä½“çš„éª¨æ¶æ¨¡å‹å¹¶å¯¹å…¶è¿›è¡Œé‡æ–°å®šä½ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œæ— éœ€ç‰¹å®šå¯¹è±¡çš„æ¨¡æ¿ï¼Œå³å¯è‡ªåŠ¨ä»è§†é¢‘ä¸­å‘ç°åŠ¨æ€å¯¹è±¡çš„å…³è”éª¨æ¶æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯æ‹¼æ¥å’Œè¶…çº§ç‚¹æ¥é‡å»ºåŠ¨æ€å¯¹è±¡ã€‚é€šè¿‡å°†è¶…çº§ç‚¹è§†ä¸ºåˆšæ€§éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç›´è§‚çº¿ç´¢å‘ç°æ½œåœ¨çš„éª¨æ¶æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨è¿åŠ¨å­¦æ¨¡å‹å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¿˜åº”ç”¨äº†è‡ªé€‚åº”æ§åˆ¶ç­–ç•¥ï¼Œä»¥é¿å…å‡ºç°å†—ä½™çš„è¶…çº§ç‚¹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è·å¾—å¯é‡æ–°å®šä½çš„ä¸‰ç»´ç‰©ä½“æ–¹é¢æ—¢æœ‰æ•ˆåˆé«˜æ•ˆã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…èƒ½è¾¾åˆ°ä¼˜ç§€çš„è§†è§‰ä¿çœŸåº¦ï¼Œè¿˜èƒ½å®ç°é«˜åˆ†è¾¨ç‡å›¾åƒçš„å®æ—¶æ¸²æŸ“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05570v1">PDF</a> Accepted by NeurIPS 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ä»è§†é¢‘ä¸­è‡ªåŠ¨å‘ç°åŠ¨æ€å¯¹è±¡å…³è”éª¨æ¶æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œæ— éœ€ç‰¹å®šå¯¹è±¡æ¨¡æ¿ã€‚è¯¥æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯å–·ç»˜å’Œè¶…ç‚¹é‡å»ºåŠ¨æ€å¯¹è±¡ï¼Œé€šè¿‡ç›´è§‚çº¿ç´¢å‘ç°åº•å±‚éª¨æ¶æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨è¿åŠ¨å­¦æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚è‡ªé€‚åº”æ§åˆ¶ç­–ç•¥é¿å…äº†å†—ä½™è¶…ç‚¹çš„å‡ºç°ï¼Œå®ç°äº†å¯é‡æ–°å®šä½çš„ä¸‰ç»´å¯¹è±¡çš„é«˜æ•ˆè·å–ã€‚è¯¥æ–¹æ³•ä¸ä»…è¾¾åˆ°å“è¶Šçš„è§†è§‰ä¿çœŸåº¦ï¼Œè¿˜å…è®¸å®æ—¶æ¸²æŸ“é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»è§†é¢‘ä¸­è‡ªåŠ¨å‘ç°åŠ¨æ€å¯¹è±¡çš„éª¨æ¶æ¨¡å‹ï¼Œæ— éœ€ç‰¹å®šå¯¹è±¡çš„æ¨¡æ¿ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†3Dé«˜æ–¯å–·ç»˜å’Œè¶…ç‚¹æŠ€æœ¯ï¼Œç”¨äºé‡å»ºåŠ¨æ€å¯¹è±¡ã€‚</li>
<li>é€šè¿‡ç›´è§‚çº¿ç´¢å‘ç°åº•å±‚éª¨æ¶æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è¿åŠ¨å­¦æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>è‡ªé€‚åº”æ§åˆ¶ç­–ç•¥é¿å…äº†å†—ä½™è¶…ç‚¹çš„äº§ç”Ÿã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°è·å–å¯é‡æ–°å®šä½çš„ä¸‰ç»´å¯¹è±¡ã€‚</li>
<li>æ–¹æ³•çš„è§†è§‰ä¿çœŸåº¦å“è¶Šã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-d427f6951472348cba64441ddbd8516c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b23193280118c2b564057260a17548e5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a8edfb1c1928a485367c30dd54e49bfc.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-ff03a7726de758e2691cd04d64a212df.jpg" align="middle">
</details>




<h2 id="Text-to-3D-Gaussian-Splatting-with-Physics-Grounded-Motion-Generation"><a href="#Text-to-3D-Gaussian-Splatting-with-Physics-Grounded-Motion-Generation" class="headerlink" title="Text-to-3D Gaussian Splatting with Physics-Grounded Motion Generation"></a>Text-to-3D Gaussian Splatting with Physics-Grounded Motion Generation</h2><p><strong>Authors:Wenqing Wang, Yun Fu</strong></p>
<p>Text-to-3D generation is a valuable technology in virtual reality and digital content creation. While recent works have pushed the boundaries of text-to-3D generation, producing high-fidelity 3D objects with inefficient prompts and simulating their physics-grounded motion accurately still remain unsolved challenges. To address these challenges, we present an innovative framework that utilizes the Large Language Model (LLM)-refined prompts and diffusion priors-guided Gaussian Splatting (GS) for generating 3D models with accurate appearances and geometric structures. We also incorporate a continuum mechanics-based deformation map and color regularization to synthesize vivid physics-grounded motion for the generated 3D Gaussians, adhering to the conservation of mass and momentum. By integrating text-to-3D generation with physics-grounded motion synthesis, our framework renders photo-realistic 3D objects that exhibit physics-aware motion, accurately reflecting the behaviors of the objects under various forces and constraints across different materials. Extensive experiments demonstrate that our approach achieves high-quality 3D generations with realistic physics-grounded motion. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°ä¸‰ç»´ç”ŸæˆæŠ€æœ¯æ˜¯è™šæ‹Ÿç°å®çš„æ•°å­—å†…å®¹åˆ›å»ºä¸­çš„ä¸€é¡¹å®è´µæŠ€æœ¯ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶å·²ç»æ¨åŠ¨äº†æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆçš„è¾¹ç•Œï¼Œä½†æ˜¯ä»å­˜åœ¨æœªè§£å†³çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚ä½¿ç”¨ä¸é«˜æ•ˆçš„æç¤ºæ¥ç”Ÿæˆé«˜ä¿çœŸåº¦çš„ä¸‰ç»´ç‰©ä½“ï¼Œä»¥åŠå‡†ç¡®æ¨¡æ‹ŸåŸºäºç‰©ç†çš„è¿åŠ¨ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç²¾ç‚¼æç¤ºå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„Gaussian Splattingï¼ˆGSï¼‰æ¥ç”Ÿæˆå…·æœ‰å‡†ç¡®å¤–è§‚å’Œå‡ ä½•ç»“æ„çš„ä¸‰ç»´æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜ç»“åˆäº†åŸºäºè¿ç»­åŠ›å­¦çš„å˜å½¢å›¾å’Œé¢œè‰²æ­£åˆ™åŒ–ï¼Œä»¥åˆæˆç”ŸåŠ¨çš„åŸºäºç‰©ç†çš„è¿åŠ¨ï¼Œç”¨äºç”Ÿæˆçš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒï¼ŒåŒæ—¶éµå®ˆè´¨é‡å’ŒåŠ¨é‡çš„å®ˆæ’ã€‚é€šè¿‡å°†æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆä¸åŸºäºç‰©ç†çš„è¿åŠ¨åˆæˆç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿæ¸²æŸ“å‡ºå…·æœ‰ç‰©ç†æ„ŸçŸ¥è¿åŠ¨çš„å…‰å­¦é€¼çœŸä¸‰ç»´ç‰©ä½“ï¼Œå‡†ç¡®åæ˜ ä¸åŒææ–™ä¸‹ç‰©ä½“åœ¨å„ç§åŠ›å’Œçº¦æŸä¸‹çš„è¡Œä¸ºã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°å…·æœ‰çœŸå®ç‰©ç†åŸºç¡€è¿åŠ¨çš„é«˜è´¨é‡ä¸‰ç»´ç”Ÿæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05560v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°ä¸‰ç»´ç”ŸæˆæŠ€æœ¯æ˜¯è™šæ‹Ÿç°å®å’Œæ•°å­—å†…å®¹åˆ›å»ºä¸­çš„ä¸€é¡¹é‡è¦æŠ€æœ¯ã€‚é’ˆå¯¹æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆä¸­çš„æŒ‘æˆ˜ï¼Œæå‡ºä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¼˜åŒ–æç¤ºå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„é«˜æ–¯æ¶‚å¸ƒæ³•ç”Ÿæˆä¸‰ç»´æ¨¡å‹ï¼Œé‡‡ç”¨åŸºäºè¿ç»­åŠ›å­¦çš„å˜å½¢å›¾å’Œé¢œè‰²æ­£åˆ™åŒ–åˆæˆç”ŸåŠ¨é€¼çœŸçš„ç‰©ç†è¿åŠ¨ã€‚è¯¥æ¡†æ¶å®ç°äº†æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆä¸ç‰©ç†è¿åŠ¨åˆæˆçš„ç»“åˆï¼Œå¯ç”Ÿæˆå…·æœ‰ç‰©ç†æ„ŸçŸ¥è¿åŠ¨çš„å…‰ç…§çœŸå®ä¸‰ç»´å¯¹è±¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°ä¸‰ç»´ç”ŸæˆæŠ€æœ¯æ˜¯è™šæ‹Ÿç°å®å’Œæ•°å­—å†…å®¹åˆ›å»ºçš„é‡è¦é¢†åŸŸã€‚</li>
<li>å½“å‰é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬ç”Ÿæˆé«˜ä¿çœŸä¸‰ç»´å¯¹è±¡å’Œä½¿ç”¨æœ‰æ•ˆæç¤ºæ¨¡æ‹Ÿå…¶åŸºäºç‰©ç†çš„è¿åŠ¨ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¼˜åŒ–æç¤ºå’Œæ‰©æ•£å…ˆéªŒå¼•å¯¼çš„é«˜æ–¯æ¶‚å¸ƒæ³•ç”Ÿæˆä¸‰ç»´æ¨¡å‹ã€‚</li>
<li>æ¡†æ¶ç»“åˆäº†æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆå’Œç‰©ç†è¿åŠ¨åˆæˆï¼Œç”Ÿæˆå…·æœ‰ç‰©ç†æ„ŸçŸ¥è¿åŠ¨çš„å…‰ç…§çœŸå®ä¸‰ç»´å¯¹è±¡ã€‚</li>
<li>é‡‡ç”¨åŸºäºè¿ç»­åŠ›å­¦çš„å˜å½¢å›¾å’Œé¢œè‰²æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œç¡®ä¿ç”Ÿæˆçš„ä¸‰ç»´é«˜æ–¯ç¬¦åˆç‰©ç†è§„å¾‹ã€‚</li>
<li>é€šè¿‡å¹¿æ³›å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•å¯å®ç°é«˜è´¨é‡çš„ä¸‰ç»´ç”Ÿæˆï¼Œå…·æœ‰é€¼çœŸçš„ç‰©ç†è¿åŠ¨ã€‚</li>
<li>è¯¥æŠ€æœ¯æœ‰åŠ©äºæ¨è¿›è™šæ‹Ÿç°å®çš„çœŸå®æ„Ÿå’Œæ•°å­—å†…å®¹åˆ›å»ºçš„ä¸°å¯Œæ€§ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-1d2ef77d1eb422e22476e45eb489ea47.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-476172e4f5ca771e329f7f4efc79f0f6.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-3a375188401f1cbb41f37558cee75619.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a4ebed75bc645cd72541b3c22f2a528a.jpg" align="middle">
</details>




<h2 id="Radiant-Large-scale-3D-Gaussian-Rendering-based-on-Hierarchical-Framework"><a href="#Radiant-Large-scale-3D-Gaussian-Rendering-based-on-Hierarchical-Framework" class="headerlink" title="Radiant: Large-scale 3D Gaussian Rendering based on Hierarchical   Framework"></a>Radiant: Large-scale 3D Gaussian Rendering based on Hierarchical   Framework</h2><p><strong>Authors:Haosong Peng, Tianyu Qi, Yufeng Zhan, Hao Li, Yalun Dai, Yuanqing Xia</strong></p>
<p>With the advancement of computer vision, the recently emerged 3D Gaussian Splatting (3DGS) has increasingly become a popular scene reconstruction algorithm due to its outstanding performance. Distributed 3DGS can efficiently utilize edge devices to directly train on the collected images, thereby offloading computational demands and enhancing efficiency. However, traditional distributed frameworks often overlook computational and communication challenges in real-world environments, hindering large-scale deployment and potentially posing privacy risks. In this paper, we propose Radiant, a hierarchical 3DGS algorithm designed for large-scale scene reconstruction that considers system heterogeneity, enhancing the model performance and training efficiency. Via extensive empirical study, we find that it is crucial to partition the regions for each edge appropriately and allocate varying camera positions to each device for image collection and training. The core of Radiant is partitioning regions based on heterogeneous environment information and allocating workloads to each device accordingly. Furthermore, we provide a 3DGS model aggregation algorithm that enhances the quality and ensures the continuity of modelsâ€™ boundaries. Finally, we develop a testbed, and experiments demonstrate that Radiant improved reconstruction quality by up to 25.7% and reduced up to 79.6% end-to-end latency. </p>
<blockquote>
<p>éšç€è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„è¿›æ­¥ï¼Œæœ€è¿‘å‡ºç°çš„3Dé«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰å› å…¶å“è¶Šæ€§èƒ½è€Œè¶Šæ¥è¶Šæˆä¸ºæµè¡Œçš„åœºæ™¯é‡å»ºç®—æ³•ã€‚åˆ†å¸ƒå¼3DGSèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è¾¹ç¼˜è®¾å¤‡å¯¹æ”¶é›†çš„å›¾åƒè¿›è¡Œç›´æ¥è®­ç»ƒï¼Œä»è€Œå‡è½»è®¡ç®—è´Ÿæ‹…ï¼Œæé«˜æ•ˆç‡ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„åˆ†å¸ƒå¼æ¡†æ¶å¾€å¾€å¿½ç•¥äº†çœŸå®ç¯å¢ƒä¸­çš„è®¡ç®—å’Œé€šä¿¡æŒ‘æˆ˜ï¼Œé˜»ç¢äº†å¤§è§„æ¨¡éƒ¨ç½²ï¼Œå¹¶å¯èƒ½å¸¦æ¥éšç§é£é™©ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå¤§è§„æ¨¡åœºæ™¯é‡å»ºçš„åˆ†å±‚3DGSç®—æ³•â€”â€”Radiantï¼Œè¯¥ç®—æ³•è€ƒè™‘äº†ç³»ç»Ÿå¼‚è´¨æ€§ï¼Œæé«˜äº†æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒæ•ˆç‡ã€‚é€šè¿‡å¹¿æ³›çš„å®è¯ç ”ç©¶ï¼Œæˆ‘ä»¬å‘ç°é€‚å½“åœ°ä¸ºæ¯ä¸ªè¾¹ç¼˜åˆ’åˆ†åŒºåŸŸï¼Œå¹¶ä¸ºå›¾åƒæ”¶é›†å’Œè®­ç»ƒåˆ†é…ä¸åŒçš„ç›¸æœºä½ç½®æ˜¯è‡³å…³é‡è¦çš„ã€‚Radiantçš„æ ¸å¿ƒæ˜¯æ ¹æ®å¼‚æ„ç¯å¢ƒä¿¡æ¯åˆ’åˆ†åŒºåŸŸï¼Œå¹¶ç›¸åº”åœ°å°†å·¥ä½œé‡åˆ†é…ç»™æ¯ä¸ªè®¾å¤‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§3DGSæ¨¡å‹èšåˆç®—æ³•ï¼Œä»¥æé«˜æ¨¡å‹è´¨é‡å¹¶ç¡®ä¿æ¨¡å‹è¾¹ç•Œçš„è¿ç»­æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæµ‹è¯•å¹³å°ï¼Œå®éªŒè¡¨æ˜ï¼ŒRadiantæé«˜äº†é‡å»ºè´¨é‡ï¼Œæœ€é«˜è¾¾25.7%ï¼Œå¹¶å‡å°‘äº†é«˜è¾¾79.6%çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05546v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„å‘å±•ï¼Œ3Dé«˜æ–¯èåˆæŠ€æœ¯ï¼ˆ3DGSï¼‰å› å‡ºè‰²çš„æ€§èƒ½è€Œé€æ¸æˆä¸ºåœºæ™¯é‡å»ºçš„çƒ­é—¨ç®—æ³•ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿåˆ†å¸ƒå¼æ¡†æ¶åœ¨ç°å®ç¯å¢ƒä¸­å¿½ç•¥äº†è®¡ç®—å’Œé€šä¿¡çš„æŒ‘æˆ˜ï¼Œé˜»ç¢äº†å¤§è§„æ¨¡éƒ¨ç½²å¹¶å¯èƒ½å¸¦æ¥éšç§é£é™©ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å¤§è§„æ¨¡åœºæ™¯é‡å»ºçš„åˆ†å±‚3DGSç®—æ³•Radiantï¼Œè€ƒè™‘ç³»ç»Ÿå¼‚è´¨æ€§ä»¥æé«˜æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒæ•ˆç‡ã€‚é€šè¿‡å¯¹è¾¹ç¼˜åŒºåŸŸçš„é€‚å½“åˆ†åŒºå’Œä¸åŒçš„ç›¸æœºä½ç½®åˆ†é…ï¼ŒRadiantèƒ½å¤Ÿåœ¨å›¾åƒé‡‡é›†å’Œè®­ç»ƒæ–¹é¢æ›´åŠ é«˜æ•ˆã€‚æ ¸å¿ƒæ˜¯é€šè¿‡ç¯å¢ƒä¿¡æ¯çš„å¼‚è´¨æ€§è¿›è¡ŒåŒºåŸŸåˆ’åˆ†ï¼Œå¹¶ç›¸åº”åˆ†é…å·¥ä½œè´Ÿè½½ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ç§æé«˜æ¨¡å‹è´¨é‡å¹¶ç¡®ä¿æ¨¡å‹è¾¹ç•Œè¿ç»­æ€§çš„3DGSæ¨¡å‹èšåˆç®—æ³•ã€‚å®éªŒè¯æ˜ï¼ŒRadiantæé«˜äº†é‡å»ºè´¨é‡è¾¾25.7%ï¼Œå¹¶å‡å°‘äº†é«˜è¾¾79.6%çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSç®—æ³•å·²æˆä¸ºåœºæ™¯é‡å»ºé¢†åŸŸçš„çƒ­é—¨é€‰æ‹©ï¼Œå› å…¶åœ¨æ€§èƒ½ä¸Šçš„å‡ºè‰²è¡¨ç°ã€‚</li>
<li>ä¼ ç»Ÿåˆ†å¸ƒå¼æ¡†æ¶å­˜åœ¨è®¡ç®—å’Œé€šä¿¡æŒ‘æˆ˜ï¼Œå½±å“å¤§è§„æ¨¡éƒ¨ç½²å¹¶å¯èƒ½å¼•å‘éšç§é£é™©ã€‚</li>
<li>Radiantç®—æ³•æ˜¯ä¸€ç§åˆ†å±‚çš„3DGSæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡åœºæ™¯é‡å»ºé—®é¢˜ï¼Œå¹¶è€ƒè™‘ç³»ç»Ÿå¼‚è´¨æ€§ã€‚</li>
<li>åŒºåŸŸé€‚å½“åˆ†åŒºå’Œç›¸æœºä½ç½®åˆ†é…å¯¹å›¾åƒé‡‡é›†å’Œè®­ç»ƒæ•ˆç‡è‡³å…³é‡è¦ã€‚</li>
<li>Radiantçš„æ ¸å¿ƒæ˜¯æ ¹æ®ç¯å¢ƒä¿¡æ¯çš„å¼‚è´¨æ€§è¿›è¡ŒåŒºåŸŸåˆ’åˆ†ï¼Œå¹¶ç›¸åº”åˆ†é…å·¥ä½œè´Ÿè½½ã€‚</li>
<li>æä¾›äº†ä¸€ç§æ–°çš„3DGSæ¨¡å‹èšåˆç®—æ³•ï¼Œä»¥æé«˜æ¨¡å‹è´¨é‡å’Œç¡®ä¿è¾¹ç•Œè¿ç»­æ€§ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-98310b2b12fc7c46eb9c5672288678c3.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-9c21ccf0c5e3eb9b26b230f714d5ccdf.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-ed90a267bc513d0882b5805a4165cde2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ecf3c6c316a83316506c332e32c74048.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ac517c91630ef59e28c50ed726db9565.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-8fdd4b74891bb556b2c7c4178608a79a.jpg" align="middle">
</details>




<h2 id="Extrapolated-Urban-View-Synthesis-Benchmark"><a href="#Extrapolated-Urban-View-Synthesis-Benchmark" class="headerlink" title="Extrapolated Urban View Synthesis Benchmark"></a>Extrapolated Urban View Synthesis Benchmark</h2><p><strong>Authors:Xiangyu Han, Zhen Jia, Boyi Li, Yan Wang, Boris Ivanovic, Yurong You, Lingjie Liu, Yue Wang, Marco Pavone, Chen Feng, Yiming Li</strong></p>
<p>Photorealistic simulators are essential for the training and evaluation of vision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis (NVS), a crucial capability that generates diverse unseen viewpoints to accommodate the broad and continuous pose distribution of AVs. Recent advances in radiance fields, such as 3D Gaussian Splatting, achieve photorealistic rendering at real-time speeds and have been widely used in modeling large-scale driving scenes. However, their performance is commonly evaluated using an interpolated setup with highly correlated training and test views. In contrast, extrapolation, where test views largely deviate from training views, remains underexplored, limiting progress in generalizable simulation technology. To address this gap, we leverage publicly available AV datasets with multiple traversals, multiple vehicles, and multiple cameras to build the first Extrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct quantitative and qualitative evaluations of state-of-the-art Gaussian Splatting methods across different difficulty levels. Our results show that Gaussian Splatting is prone to overfitting to training views. Besides, incorporating diffusion priors and improving geometry cannot fundamentally improve NVS under large view changes, highlighting the need for more robust approaches and large-scale training. We have released our data to help advance self-driving and urban robotics simulation technology. </p>
<blockquote>
<p>çœŸå®æ„Ÿæ¨¡æ‹Ÿå™¨å¯¹äºä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„è®­ç»ƒå’Œè¯„ä¼°è‡³å…³é‡è¦ã€‚å…¶æ ¸å¿ƒæ˜¯æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿç”Ÿæˆå¤šç§æœªè§è§‚ç‚¹ä»¥é€‚åº”è‡ªåŠ¨é©¾é©¶æ±½è½¦å¹¿æ³›å’Œè¿ç»­å§¿æ€åˆ†å¸ƒçš„å…³é”®èƒ½åŠ›ã€‚æœ€è¿‘ï¼Œè¾å°„åœºå–å¾—äº†è¿›å±•ï¼Œä¾‹å¦‚3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œèƒ½å¤Ÿä»¥å®æ—¶é€Ÿåº¦å®ç°çœŸå®æ„Ÿæ¸²æŸ“ï¼Œå¹¶å·²å¹¿æ³›åº”ç”¨äºæ¨¡æ‹Ÿå¤§è§„æ¨¡é©¾é©¶åœºæ™¯ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æ€§èƒ½é€šå¸¸ä½¿ç”¨æ’å€¼è®¾ç½®è¿›è¡Œè¯„ä¼°ï¼Œå…¶ä¸­è®­ç»ƒå’Œæµ‹è¯•è§‚ç‚¹é«˜åº¦ç›¸å…³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¤–æ¨ï¼ˆå³æµ‹è¯•è§‚ç‚¹ä¸è®­ç»ƒè§‚ç‚¹å­˜åœ¨è¾ƒå¤§åå·®ï¼‰çš„æƒ…å†µä»è¢«è¾ƒå°‘æ¢ç´¢ï¼Œè¿™é™åˆ¶äº†é€šç”¨ä»¿çœŸæŠ€æœ¯çš„è¿›æ­¥ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬åˆ©ç”¨å…¬å¼€å¯ç”¨çš„è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼ˆåŒ…å«å¤šæ¬¡éå†ã€å¤šè¾†è½¦å’Œå¤šç›¸æœºï¼‰æ¥å»ºç«‹ç¬¬ä¸€ä¸ªå¤–æ¨åŸå¸‚è§†å›¾åˆæˆï¼ˆEUVSï¼‰åŸºå‡†æµ‹è¯•ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¯¹ä¸åŒéš¾åº¦çº§åˆ«çš„æœ€æ–°é«˜æ–¯æ‹¼è´´æ–¹æ³•è¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œé«˜æ–¯æ‹¼è´´å®¹æ˜“å¯¹è®­ç»ƒè§‚ç‚¹äº§ç”Ÿè¿‡åº¦æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œèå…¥æ‰©æ•£å…ˆéªŒçŸ¥è¯†å’Œæ”¹è¿›å‡ ä½•ç»“æ„å¹¶ä¸èƒ½åœ¨è¾ƒå¤§è§†è§’å˜åŒ–ä¸‹ä»æ ¹æœ¬ä¸Šæ”¹å–„NVSï¼Œè¿™å‡¸æ˜¾äº†éœ€è¦æ›´ç¨³å¥çš„æ–¹æ³•å’Œå¤§è§„æ¨¡è®­ç»ƒã€‚æˆ‘ä»¬å·²ç»å‘å¸ƒæ•°æ®ï¼Œä»¥å¸®åŠ©æ¨åŠ¨è‡ªåŠ¨é©¾é©¶å’ŒåŸå¸‚æœºå™¨äººä»¿çœŸæŠ€æœ¯çš„è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.05256v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://ai4ce.github.io/EUVS-Benchmark/">https://ai4ce.github.io/EUVS-Benchmark/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼ºè°ƒäº†çœŸå®æ„Ÿæ¨¡æ‹Ÿå™¨å¯¹äºä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆAVsï¼‰è®­ç»ƒå’Œè¯„ä¼°çš„é‡è¦æ€§ã€‚æ–‡ç« ä»‹ç»äº†å…³é”®æŠ€æœ¯â€”â€”Novel View Synthesisï¼ˆNVSï¼‰ï¼Œå®ƒèƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„æœªè§è§†è§’ä»¥é€‚åº”AVså¹¿æ³›çš„è¿ç»­å§¿æ€åˆ†å¸ƒã€‚è™½ç„¶è¿‘æœŸè¾å°„åœºæŠ€æœ¯å¦‚3Dé«˜æ–¯æ‹¼è´´è¾¾åˆ°äº†å®æ—¶æ¸²æŸ“é€¼çœŸåº¦å¹¶åœ¨å¤§è§„æ¨¡é©¾é©¶åœºæ™¯å»ºæ¨¡ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶æ€§èƒ½è¯„ä¼°é€šå¸¸é‡‡ç”¨æ’å€¼è®¾ç½®ï¼Œæµ‹è¯•è§†è§’ä¸è®­ç»ƒè§†è§’é«˜åº¦ç›¸å…³ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œæ–‡ç« å»ºç«‹äº†é¦–ä¸ªExtrapolated Urban View Synthesisï¼ˆEUVSï¼‰åŸºå‡†æµ‹è¯•å¹³å°ï¼Œè¯¥å¹³å°ä½¿ç”¨å…¬å¼€å¯ç”¨çš„åŒ…å«å¤šè½¨è¿¹ã€å¤šè½¦è¾†å’Œå¤šç›¸æœºçš„AVæ•°æ®é›†è¿›è¡Œæ„å»ºï¼ŒåŒæ—¶å¯¹æœ€æ–°é«˜æ–¯æ‹¼è´´æ–¹æ³•è¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé«˜æ–¯æ‹¼è´´æ˜“å¯¹è®­ç»ƒè§†è§’äº§ç”Ÿè¿‡æ‹Ÿåˆç°è±¡ï¼Œè€Œå¼•å…¥æ‰©æ•£å…ˆéªŒå’Œæ”¹è¿›å‡ ä½•ç»“æ„å¹¶ä¸èƒ½ä»æ ¹æœ¬ä¸Šæ”¹å–„å¤§è§†è§’å˜åŒ–ä¸‹çš„NVSæ€§èƒ½ï¼Œè¿™å‡¸æ˜¾äº†éœ€è¦æ›´ç¨³å¥çš„æ–¹æ³•å’Œå¤§è§„æ¨¡è®­ç»ƒæ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çœŸå®æ„Ÿæ¨¡æ‹Ÿå™¨å¯¹äºè‡ªåŠ¨é©¾é©¶æ±½è½¦çš„è®­ç»ƒå’Œè¯„ä¼°è‡³å…³é‡è¦ã€‚</li>
<li>Novel View Synthesisï¼ˆNVSï¼‰æ˜¯ç”Ÿæˆå¤šæ ·åŒ–æœªè§è§†è§’çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œé€‚åº”äº†è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„å¹¿æ³›å§¿æ€åˆ†å¸ƒã€‚</li>
<li>ç°æœ‰æŠ€æœ¯å¦‚3Dé«˜æ–¯æ‹¼è´´åœ¨è¾å°„åœºæŠ€æœ¯ä¸­å®ç°äº†å®æ—¶æ¸²æŸ“ï¼Œä½†åœ¨å¤„ç†æµ‹è¯•è§†è§’ä¸è®­ç»ƒè§†è§’é«˜åº¦ç›¸å…³æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>å»ºç«‹äº†é¦–ä¸ªExtrapolated Urban View Synthesisï¼ˆEUVSï¼‰åŸºå‡†æµ‹è¯•å¹³å°æ¥æ¨åŠ¨ç ”ç©¶è¿›æ­¥ã€‚</li>
<li>é«˜æ–¯æ‹¼è´´æ–¹æ³•å­˜åœ¨è¿‡æ‹Ÿåˆç°è±¡ï¼Œéœ€è¦æ›´ç¨³å¥çš„æ–¹æ³•å’Œå¤§è§„æ¨¡è®­ç»ƒæ•°æ®æ¥æ”¹å–„æ€§èƒ½ã€‚</li>
<li>å¼•å…¥æ‰©æ•£å…ˆéªŒå’Œæ”¹è¿›å‡ ä½•ç»“æ„åœ¨å¤§è§†è§’å˜åŒ–ä¸‹å¯¹NVSæ€§èƒ½çš„æå‡æœ‰é™ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-f2156b671f8a0eb9c52a82014a137f4c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-d9cb94809b59abfde99df6fbbcac73e2.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-a91d403b6f050262902041447ef5cfa9.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-49e3691ead92f7eb48a6c213847eb901.jpg" align="middle">
</details>




<h2 id="MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting"><a href="#MixedGaussianAvatar-Realistically-and-Geometrically-Accurate-Head-Avatar-via-Mixed-2D-3D-Gaussian-Splatting" class="headerlink" title="MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting"></a>MixedGaussianAvatar: Realistically and Geometrically Accurate Head   Avatar via Mixed 2D-3D Gaussian Splatting</h2><p><strong>Authors:Peng Chen, Xiaobao Wei, Qingpo Wuwu, Xinyi Wang, Xingyu Xiao, Ming Lu</strong></p>
<p>Reconstructing high-fidelity 3D head avatars is crucial in various applications such as virtual reality. The pioneering methods reconstruct realistic head avatars with Neural Radiance Fields (NeRF), which have been limited by training and rendering speed. Recent methods based on 3D Gaussian Splatting (3DGS) significantly improve the efficiency of training and rendering. However, the surface inconsistency of 3DGS results in subpar geometric accuracy; later, 2DGS uses 2D surfels to enhance geometric accuracy at the expense of rendering fidelity. To leverage the benefits of both 2DGS and 3DGS, we propose a novel method named MixedGaussianAvatar for realistically and geometrically accurate head avatar reconstruction. Our main idea is to utilize 2D Gaussians to reconstruct the surface of the 3D head, ensuring geometric accuracy. We attach the 2D Gaussians to the triangular mesh of the FLAME model and connect additional 3D Gaussians to those 2D Gaussians where the rendering quality of 2DGS is inadequate, creating a mixed 2D-3D Gaussian representation. These 2D-3D Gaussians can then be animated using FLAME parameters. We further introduce a progressive training strategy that first trains the 2D Gaussians and then fine-tunes the mixed 2D-3D Gaussians. We demonstrate the superiority of MixedGaussianAvatar through comprehensive experiments. The code will be released at: <a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>. </p>
<blockquote>
<p>é‡å»ºé«˜ä¿çœŸ3Då¤´åƒå¯¹äºè™šæ‹Ÿç°å®ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚å‰æ²¿çš„æ–¹æ³•ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é‡å»ºé€¼çœŸçš„å¤´åƒï¼Œä½†å—é™äºè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦ã€‚åŸºäº3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰çš„æœ€æ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“çš„æ•ˆç‡ã€‚ç„¶è€Œï¼Œ3DGSçš„è¡¨é¢ä¸ä¸€è‡´å¯¼è‡´å‡ ä½•ç²¾åº¦ä¸ä½³ï¼›åæ¥çš„2DGSä½¿ç”¨2Dè¡¨é¢å…ƒç´ ä»¥æé«˜å‡ ä½•ç²¾åº¦ï¼Œä½†ç‰ºç‰²äº†æ¸²æŸ“ä¿çœŸåº¦ã€‚ä¸ºäº†ç»“åˆ2DGSå’Œ3DGSçš„ä¼˜ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMixedGaussianAvatarçš„æ–°æ–¹æ³•ï¼Œç”¨äºçœŸå®ä¸”å‡ ä½•ç²¾ç¡®çš„å¤´åƒé‡å»ºã€‚æˆ‘ä»¬çš„ä¸»è¦æ€æƒ³æ˜¯åˆ©ç”¨2Dé«˜æ–¯é‡å»º3Då¤´åƒçš„è¡¨é¢ï¼Œä»¥ç¡®ä¿å‡ ä½•ç²¾åº¦ã€‚æˆ‘ä»¬å°†2Dé«˜æ–¯é™„åŠ åˆ°FLAMEæ¨¡å‹çš„ä¸‰è§’ç½‘æ ¼ä¸Šï¼Œå¹¶åœ¨2DGSçš„æ¸²æŸ“è´¨é‡ä¸è¶³çš„åœ°æ–¹è¿æ¥åˆ°é¢å¤–çš„3Dé«˜æ–¯ï¼Œåˆ›å»ºæ··åˆçš„2D-3Dé«˜æ–¯è¡¨ç¤ºã€‚è¿™äº›2D-3Dé«˜æ–¯å¯ä»¥ä½¿ç”¨FLAMEå‚æ•°è¿›è¡ŒåŠ¨ç”»è®¾ç½®ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ¸è¿›çš„è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒ2Dé«˜æ–¯ï¼Œç„¶åå¯¹æ··åˆçš„2D-3Dé«˜æ–¯è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡å…¨é¢çš„å®éªŒè¯æ˜äº†MixedGaussianAvatarçš„ä¼˜è¶Šæ€§ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/ChenVoid/MGA/">https://github.com/ChenVoid/MGA/</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04955v1">PDF</a> Project: <a target="_blank" rel="noopener" href="https://chenvoid.github.io/MGA/">https://chenvoid.github.io/MGA/</a></p>
<p><strong>Summary</strong><br>åœ¨è™šæ‹Ÿç°å®ä¸­é‡å»ºé«˜ä¿çœŸä¸‰ç»´å¤´éƒ¨åŒ–èº«éå¸¸å…³é”®ã€‚æœ€è¿‘é‡‡ç”¨åŸºäºä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯çš„æ–¹æ³•æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“æ•ˆç‡ï¼Œä½†å…¶è¡¨é¢ä¸€è‡´æ€§ä¸è¶³å¯¼è‡´å‡ ä½•ç²¾åº¦è¾ƒå·®ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ··åˆäºŒç»´é«˜æ–¯ä¸ä¸‰ç»´é«˜æ–¯æŠ€æœ¯çš„å…¨æ–°æ–¹æ³•ï¼Œå³MixedGaussianAvatarã€‚å®ƒé€šè¿‡äºŒç»´é«˜æ–¯é‡å»ºä¸‰ç»´å¤´éƒ¨è¡¨é¢ç¡®ä¿å‡ ä½•ç²¾åº¦ï¼Œåœ¨å¿…è¦æ—¶é‡‡ç”¨ä¸‰ç»´é«˜æ–¯è¿›è¡Œè¡¥å……ã€‚è¿™ç§æ–¹æ³•å¯å®ç°åŠ¨ç”»åŒ–ï¼Œå¹¶å¼•å…¥æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼Œå³å…ˆè®­ç»ƒäºŒç»´é«˜æ–¯å†å¾®è°ƒæ··åˆäºŒç»´-ä¸‰ç»´é«˜æ–¯æŠ€æœ¯ã€‚MixedGaussianAvatarçš„ä¼˜åŠ¿é€šè¿‡å®éªŒå¾—åˆ°éªŒè¯ã€‚ç›¸å…³ä»£ç å°†åœ¨GitHubä¸Šå‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¸‰ç»´å¤´éƒ¨åŒ–èº«é‡å»ºåœ¨è™šæ‹Ÿç°å®ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>æœ€è¿‘çš„ä¸‰ç»´é«˜æ–¯æ‹¼æ¥æŠ€æœ¯æ–¹æ³•è™½ç„¶æé«˜äº†è®­ç»ƒå’Œæ¸²æŸ“æ•ˆç‡ï¼Œä½†å­˜åœ¨å‡ ä½•ç²¾åº¦é—®é¢˜ã€‚</li>
<li>MixedGaussianAvataræ–¹æ³•ç»“åˆäºŒç»´é«˜æ–¯å’Œä¸‰ç»´é«˜æ–¯æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³å‡ ä½•ç²¾åº¦é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨äºŒç»´é«˜æ–¯é‡å»ºä¸‰ç»´å¤´éƒ¨è¡¨é¢ï¼Œå¹¶åœ¨å¿…è¦æ—¶ä½¿ç”¨ä¸‰ç»´é«˜æ–¯è¡¥å……ã€‚</li>
<li>MixedGaussianAvatarå¯ä»¥å®ç°åŠ¨ç”»åŒ–ï¼Œå¹¶é‡‡ç”¨äº†æ¸è¿›å¼è®­ç»ƒç­–ç•¥æ¥æé«˜æ•ˆç‡ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-34f42332d014b46369069fd2d1d3a994.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0ef5787956810f1e111d21adf0bdcf5c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-ce4f964cf25207a6db5a28f7f85bd755.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-a7e93cc4f1cccfe010d043da886dc390.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-5d0573a7ab1441e50500057923302b87.jpg" align="middle">
</details>




<h2 id="PBDyG-Position-Based-Dynamic-Gaussians-for-Motion-Aware-Clothed-Human-Avatars"><a href="#PBDyG-Position-Based-Dynamic-Gaussians-for-Motion-Aware-Clothed-Human-Avatars" class="headerlink" title="PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars"></a>PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars</h2><p><strong>Authors:Shota Sasaki, Jane Wu, Ko Nishino</strong></p>
<p>This paper introduces a novel clothed human model that can be learned from multiview RGB videos, with a particular emphasis on recovering physically accurate body and cloth movements. Our method, Position Based Dynamic Gaussians (PBDyG), realizes <code>movement-dependent&#39;&#39; cloth deformation via physical simulation, rather than merely relying on </code>pose-dependentâ€™â€™ rigid transformations. We model the clothed human holistically but with two distinct physical entities in contact: clothing modeled as 3D Gaussians, which are attached to a skinned SMPL body that follows the movement of the person in the input videos. The articulation of the SMPL body also drives physically-based simulation of the clothesâ€™ Gaussians to transform the avatar to novel poses. In order to run position based dynamics simulation, physical properties including mass and material stiffness are estimated from the RGB videos through Dynamic 3D Gaussian Splatting. Experiments demonstrate that our method not only accurately reproduces appearance but also enables the reconstruction of avatars wearing highly deformable garments, such as skirts or coats, which have been challenging to reconstruct using existing methods. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å¯ä»¥ä»å¤šè§’åº¦RGBè§†é¢‘ä¸­å­¦ä¹ çš„æ–°å‹ç€è£…äººä½“æ¨¡å‹ï¼Œç‰¹åˆ«ä¾§é‡äºæ¢å¤ç‰©ç†ä¸Šå‡†ç¡®çš„èº«ä½“å’Œè¡£ç‰©è¿åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼ŒåŸºäºä½ç½®çš„åŠ¨åŠ›å­¦é«˜æ–¯ï¼ˆPBDyGï¼‰ï¼Œé€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå®ç°â€œè¿åŠ¨ç›¸å…³â€çš„å¸ƒæ–™å˜å½¢ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–â€œå§¿æ€ç›¸å…³â€çš„åˆšæ€§å˜æ¢ã€‚æˆ‘ä»¬å¯¹ç©¿è¡£çš„äººä½“è¿›è¡Œæ•´ä½“å»ºæ¨¡ï¼Œä½†å°†å…¶æ¥è§¦ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ç‰©ç†å®ä½“ï¼šå°†è¡£ç‰©å»ºæ¨¡ä¸ºä¸‰ç»´é«˜æ–¯ï¼Œé™„ç€åœ¨è·Ÿéšè¾“å…¥è§†é¢‘äººç‰©è¿åŠ¨çš„çš®è‚¤åŒ–SMPLèº«ä½“ä¸Šã€‚SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨ä¹Ÿé©±åŠ¨è¡£ç‰©çš„åŸºäºç‰©ç†çš„é«˜æ–¯æ¨¡æ‹Ÿï¼Œå°†è§’è‰²è½¬å˜ä¸ºæ–°çš„å§¿æ€ã€‚ä¸ºäº†è¿è¡ŒåŸºäºä½ç½®çš„åŠ¨åŠ›å­¦æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬é€šè¿‡åŠ¨æ€ä¸‰ç»´é«˜æ–¯å–·æ¶‚ä»RGBè§†é¢‘ä¸­ä¼°è®¡è´¨é‡ã€ææ–™åˆšåº¦ç­‰ç‰©ç†å±æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å‡†ç¡®åœ°å†ç°äº†å¤–è§‚ï¼Œè¿˜èƒ½é‡å»ºç©¿ç€é«˜åº¦å¯å˜å½¢æœè£…çš„è§’è‰²ï¼Œå¦‚è£™å­æˆ–å¤–å¥—ï¼Œè¿™åœ¨ä»¥å‰ä½¿ç”¨ç°æœ‰æ–¹æ³•é‡å»ºæ—¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04433v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ä»å¤šè§†è§’RGBè§†é¢‘ä¸­å­¦ä¹ äººä½“ç€è£…æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ³¨é‡æ¢å¤ç‰©ç†å‡†ç¡®çš„èº«ä½“å’Œè¡£ç‰©è¿åŠ¨ã€‚è¯¥æ–¹æ³•é€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå®ç°â€œè¿åŠ¨ç›¸å…³â€çš„è¡£ç‰©å˜å½¢ï¼Œè€Œä¸æ˜¯ä»…ä¾èµ–â€œå§¿æ€ç›¸å…³â€çš„åˆšæ€§å˜æ¢ã€‚å»ºæ¨¡äººä½“ç€è£…ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œä½†æ¥è§¦é¢ç”±ä¸¤ä¸ªç‹¬ç«‹çš„ç‰©ç†å®ä½“ç»„æˆï¼šè¡£ç‰©è¢«æ¨¡æ‹Ÿä¸º3Dé«˜æ–¯åˆ†å¸ƒï¼Œé™„ç€åœ¨è·Ÿéšè¾“å…¥è§†é¢‘äººç‰©è¿åŠ¨çš„çš®è‚¤åŒ–SMPLèº«ä½“ä¸Šã€‚SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨ä¹Ÿé©±åŠ¨è¡£ç‰©çš„é«˜æ–¯ç‰©ç†æ¨¡æ‹Ÿï¼Œä»¥ç”Ÿæˆæ–°é¢–å§¿æ€çš„è™šæ‹Ÿå½¢è±¡ã€‚é€šè¿‡åŠ¨æ€ä¸‰ç»´é«˜æ–¯ç¢ç‚¹æŠ€æœ¯ä»RGBè§†é¢‘ä¸­ä¼°ç®—è´¨é‡ã€ææ–™åˆšåº¦ç­‰ç‰©ç†å±æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…å‡†ç¡®å†ç°å¤–è§‚ï¼Œè¿˜èƒ½é‡å»ºç©¿ç€é«˜åº¦å¯å˜å½¢è¡£ç‰©çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¦‚è£™å­æˆ–å¤–å¥—ï¼Œè¿™æ˜¯ç°æœ‰æ–¹æ³•éš¾ä»¥é‡å»ºçš„ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„ä»å¤šè§†è§’RGBè§†é¢‘å­¦ä¹ äººä½“ç€è£…æ¨¡å‹çš„æ–¹æ³•ã€‚</li>
<li>é‡ç‚¹åœ¨äºæ¢å¤ç‰©ç†å‡†ç¡®çš„èº«ä½“å’Œè¡£ç‰©è¿åŠ¨ã€‚</li>
<li>é€šè¿‡ç‰©ç†æ¨¡æ‹Ÿå®ç°è¿åŠ¨ç›¸å…³çš„è¡£ç‰©å˜å½¢ã€‚</li>
<li>äººä½“ç€è£…è¢«å»ºæ¨¡ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œæ¥è§¦é¢ç”±ä¸¤ä¸ªç‰©ç†å®ä½“ï¼ˆè¡£ç‰©å’Œçš®è‚¤åŒ–SMPLèº«ä½“ï¼‰ç»„æˆã€‚</li>
<li>SMPLèº«ä½“çš„å…³èŠ‚æ´»åŠ¨é©±åŠ¨è¡£ç‰©çš„ç‰©ç†æ¨¡æ‹Ÿã€‚</li>
<li>åˆ©ç”¨åŠ¨æ€ä¸‰ç»´é«˜æ–¯ç¢ç‚¹æŠ€æœ¯ä»RGBè§†é¢‘ä¸­ä¼°ç®—ç‰©ç†å±æ€§ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2d1711cfeb4aa545688bd82288fe4ba5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-325bb7409947b2356cc510d3fabf325b.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-082105f475afd440dabb10a54eb43e99.jpg" align="middle">
</details>




<h2 id="EmbodiedOcc-Embodied-3D-Occupancy-Prediction-for-Vision-based-Online-Scene-Understanding"><a href="#EmbodiedOcc-Embodied-3D-Occupancy-Prediction-for-Vision-based-Online-Scene-Understanding" class="headerlink" title="EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online   Scene Understanding"></a>EmbodiedOcc: Embodied 3D Occupancy Prediction for Vision-based Online   Scene Understanding</h2><p><strong>Authors:Yuqi Wu, Wenzhao Zheng, Sicheng Zuo, Yuanhui Huang, Jie Zhou, Jiwen Lu</strong></p>
<p>3D occupancy prediction provides a comprehensive description of the surrounding scenes and has become an essential task for 3D perception. Most existing methods focus on offline perception from one or a few views and cannot be applied to embodied agents which demands to gradually perceive the scene through progressive embodied exploration. In this paper, we formulate an embodied 3D occupancy prediction task to target this practical scenario and propose a Gaussian-based EmbodiedOcc framework to accomplish it. We initialize the global scene with uniform 3D semantic Gaussians and progressively update local regions observed by the embodied agent. For each update, we extract semantic and structural features from the observed image and efficiently incorporate them via deformable cross-attention to refine the regional Gaussians. Finally, we employ Gaussian-to-voxel splatting to obtain the global 3D occupancy from the updated 3D Gaussians. Our EmbodiedOcc assumes an unknown (i.e., uniformly distributed) environment and maintains an explicit global memory of it with 3D Gaussians. It gradually gains knowledge through the local refinement of regional Gaussians, which is consistent with how humans understand new scenes through embodied exploration. We reorganize an EmbodiedOcc-ScanNet benchmark based on local annotations to facilitate the evaluation of the embodied 3D occupancy prediction task. Experiments demonstrate that our EmbodiedOcc outperforms existing local prediction methods and accomplishes the embodied occupancy prediction with high accuracy and strong expandability. Code: <a target="_blank" rel="noopener" href="https://github.com/YkiWu/EmbodiedOcc">https://github.com/YkiWu/EmbodiedOcc</a>. </p>
<blockquote>
<p>3Då ç”¨é¢„æµ‹ä¸ºå‘¨å›´åœºæ™¯æä¾›äº†å…¨é¢çš„æè¿°ï¼Œå·²æˆä¸º3Dæ„ŸçŸ¥çš„é‡è¦ä»»åŠ¡ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾§é‡äºä»ä¸€ä¸ªæˆ–å°‘æ•°å‡ ä¸ªè§†è§’è¿›è¡Œçš„ç¦»çº¿æ„ŸçŸ¥ï¼Œæ— æ³•åº”ç”¨äºéœ€è¦é€šè¿‡é€æ­¥çš„èº«ä½“æ¢ç´¢æ¥æ„ŸçŸ¥åœºæ™¯çš„ä¸»ä½“ä»£ç†ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€å®é™…åœºæ™¯åˆ¶å®šäº†ä¸»ä½“3Då ç”¨é¢„æµ‹ä»»åŠ¡ï¼Œå¹¶æå‡ºäº†åŸºäºé«˜æ–¯å‡½æ•°çš„EmbodiedOccæ¡†æ¶æ¥å®Œæˆã€‚æˆ‘ä»¬åˆ©ç”¨ç»Ÿä¸€çš„3Dè¯­ä¹‰é«˜æ–¯å›¾åˆå§‹åŒ–å…¨å±€åœºæ™¯ï¼Œå¹¶é€æ­¥æ›´æ–°ä¸»ä½“ä»£ç†è§‚å¯Ÿåˆ°çš„å±€éƒ¨åŒºåŸŸã€‚å¯¹äºæ¯æ¬¡æ›´æ–°ï¼Œæˆ‘ä»¬ä»è§‚å¯Ÿåˆ°çš„å›¾åƒä¸­æå–è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œå¹¶é€šè¿‡å¯å˜å½¢äº¤å‰æ³¨æ„åŠ›æœ‰æ•ˆåœ°ç»“åˆå®ƒä»¬ï¼Œä»¥ä¼˜åŒ–åŒºåŸŸé«˜æ–¯å›¾ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯åˆ°ä½“ç´ çš„æ‘Šå¼€æ¥è·å¾—å…¨å±€3Då ç”¨å›¾ï¼Œè¿™äº›å›¾æ˜¯ä»æ›´æ–°çš„3Dé«˜æ–¯å›¾ä¸­è·å–çš„ã€‚æˆ‘ä»¬çš„EmbodiedOccå‡è®¾ç¯å¢ƒæœªçŸ¥ï¼ˆå³å‡åŒ€åˆ†å¸ƒï¼‰ï¼Œå¹¶åˆ©ç”¨æ˜ç¡®çš„å…¨çƒå†…å­˜ä½¿ç”¨ä¸‰ç»´é«˜æ–¯å¯¹å…¶è¿›è¡Œç»´æŠ¤ã€‚å®ƒé€šè¿‡åŒºåŸŸé«˜æ–¯å›¾çš„å±€éƒ¨ä¼˜åŒ–é€æ­¥è·å–çŸ¥è¯†ï¼Œè¿™ä¸äººç±»é€šè¿‡èº«ä½“æ¢ç´¢ç†è§£æ–°åœºæ™¯çš„æ–¹å¼æ˜¯ä¸€è‡´çš„ã€‚æˆ‘ä»¬æ ¹æ®å±€éƒ¨æ³¨é‡Šé‡æ–°ç»„ç»‡äº†EmbodiedOcc-ScanNetåŸºå‡†æµ‹è¯•ï¼Œä»¥ä¾¿å¯¹ä¸»ä½“3Då ç”¨é¢„æµ‹ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„EmbodiedOccä¼˜äºç°æœ‰çš„å±€éƒ¨é¢„æµ‹æ–¹æ³•ï¼Œå¹¶èƒ½ä»¥é«˜åº¦çš„å‡†ç¡®æ€§å’Œå¼ºå¤§çš„å¯æ‰©å±•æ€§å®Œæˆä¸»ä½“å ç”¨é¢„æµ‹ã€‚ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/YkiWu/EmbodiedOcc">https://github.com/YkiWu/EmbodiedOcc</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04380v2">PDF</a> Code: <a target="_blank" rel="noopener" href="https://github.com/YkiWu/EmbodiedOcc">https://github.com/YkiWu/EmbodiedOcc</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºé«˜æ–¯åˆ†å¸ƒçš„EmbodiedOccæ¡†æ¶ï¼Œç”¨äºå®ç°åœºæ™¯ä¸­çš„ä¸‰ç»´å ç”¨é¢„æµ‹ã€‚é€šè¿‡é€æ­¥æ›´æ–°ç”±æ™ºèƒ½ä½“è§‚å¯Ÿåˆ°çš„å±€éƒ¨åŒºåŸŸï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€æ­¥æ„ŸçŸ¥åœºæ™¯ï¼Œé€‚ç”¨äºæ™ºèƒ½ä½“åœ¨ç°å®ç¯å¢ƒä¸­çš„å®é™…åº”ç”¨ã€‚å®éªŒè¡¨æ˜ï¼ŒEmbodiedOccåœ¨æœ¬åœ°é¢„æµ‹æ–¹æ³•ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿå®ç°é«˜åº¦å‡†ç¡®å’Œå¯æ‰©å±•çš„ä¸‰ç»´å ç”¨é¢„æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„EmbodiedOccæ¡†æ¶ç”¨äºä¸‰ç»´å ç”¨é¢„æµ‹ã€‚</li>
<li>è¯¥æ¡†æ¶é€‚ç”¨äºæ™ºèƒ½ä½“é€šè¿‡æ¸è¿›å¼æ¢ç´¢æ„ŸçŸ¥åœºæ™¯çš„å®é™…åº”ç”¨åœºæ™¯ã€‚</li>
<li>EmbodiedOccé‡‡ç”¨åŸºäºé«˜æ–¯åˆ†å¸ƒçš„æ–¹æ³•ï¼Œé€šè¿‡æ›´æ–°å±€éƒ¨åŒºåŸŸæ¥é€æ­¥æ„ŸçŸ¥åœºæ™¯ã€‚</li>
<li>æ¡†æ¶é€šè¿‡æå–å›¾åƒä¸­çš„è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œå¹¶ç»“åˆå¯å˜å½¢äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æ¥ä¼˜åŒ–å±€éƒ¨é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>é‡‡ç”¨é«˜æ–¯åˆ°ä½“ç´ æ‰©æ•£æŠ€æœ¯ï¼Œä»æ›´æ–°çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒä¸­è·å–å…¨å±€ä¸‰ç»´å ç”¨ä¿¡æ¯ã€‚</li>
<li>EmbodiedOccå‡è®¾ç¯å¢ƒæœªçŸ¥ï¼Œå¹¶ä½¿ç”¨å…¨å±€å†…å­˜ä¸­çš„ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒæ¥ç»´æŠ¤åœºæ™¯çš„æ˜ç¡®è¡¨ç¤ºã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5c9d7468862e425f0827c9471bf9d251.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-29d616c351dbf01cc2c59b1f444ba16f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0983ad3009902349ececf872cc48d61c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1c71ae3dea446bcef7b0379d1b5f29d8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0c464a00b164155673d712c083fa68d4.jpg" align="middle">
</details>




<h2 id="3DSceneEditor-Controllable-3D-Scene-Editing-with-Gaussian-Splatting"><a href="#3DSceneEditor-Controllable-3D-Scene-Editing-with-Gaussian-Splatting" class="headerlink" title="3DSceneEditor: Controllable 3D Scene Editing with Gaussian Splatting"></a>3DSceneEditor: Controllable 3D Scene Editing with Gaussian Splatting</h2><p><strong>Authors:Ziyang Yan, Lei Li, Yihua Shao, Siyu Chen, Zongkai Wu, Jenq-Neng Hwang, Hao Zhao, Fabio Remondino</strong></p>
<p>The creation of 3D scenes has traditionally been both labor-intensive and costly, requiring designers to meticulously configure 3D assets and environments. Recent advancements in generative AI, including text-to-3D and image-to-3D methods, have dramatically reduced the complexity and cost of this process. However, current techniques for editing complex 3D scenes continue to rely on generally interactive multi-step, 2D-to-3D projection methods and diffusion-based techniques, which often lack precision in control and hamper real-time performance. In this work, we propose 3DSceneEditor, a fully 3D-based paradigm for real-time, precise editing of intricate 3D scenes using Gaussian Splatting. Unlike conventional methods, 3DSceneEditor operates through a streamlined 3D pipeline, enabling direct manipulation of Gaussians for efficient, high-quality edits based on input prompts.The proposed framework (i) integrates a pre-trained instance segmentation model for semantic labeling; (ii) employs a zero-shot grounding approach with CLIP to align target objects with user prompts; and (iii) applies scene modifications, such as object addition, repositioning, recoloring, replacing, and deletion directly on Gaussians. Extensive experimental results show that 3DSceneEditor achieves superior editing precision and speed with respect to current SOTA 3D scene editing approaches, establishing a new benchmark for efficient and interactive 3D scene customization. </p>
<blockquote>
<p>ä¼ ç»Ÿä¸Šåˆ›å»ºä¸‰ç»´åœºæ™¯æ—¢è€—è´¹åŠ³åŠ›åˆæˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦è®¾è®¡å¸ˆç²¾å¿ƒé…ç½®ä¸‰ç»´èµ„æºå’Œç¯å¢ƒã€‚è¿‘æœŸç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„è¿›æ­¥ï¼ŒåŒ…æ‹¬æ–‡æœ¬è½¬ä¸‰ç»´å’Œå›¾åƒè½¬ä¸‰ç»´çš„æ–¹æ³•ï¼Œå·²ç»å¤§å¤§é™ä½äº†è¿™ä¸€è¿‡ç¨‹çš„å¤æ‚æ€§å’Œæˆæœ¬ã€‚ç„¶è€Œï¼Œå½“å‰ç¼–è¾‘å¤æ‚ä¸‰ç»´åœºæ™¯çš„æŠ€æœ¯ä»ç„¶ä¾èµ–äºä¸€èˆ¬äº¤äº’å¼çš„å¤šæ­¥éª¤äºŒç»´è½¬ä¸‰ç»´æŠ•å½±æ–¹æ³•å’Œæ‰©æ•£æŠ€æœ¯ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ç¼ºä¹æ§åˆ¶ç²¾åº¦å¹¶å½±å“å®æ—¶æ€§èƒ½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå…¨ä¸‰ç»´çš„å®æ—¶ç²¾ç¡®ç¼–è¾‘å¤æ‚ä¸‰ç»´åœºæ™¯çš„èŒƒå¼â€”â€”ä¸‰ç»´åœºæ™¯ç¼–è¾‘å™¨ï¼ˆSceneEditorï¼‰ã€‚å®ƒé€šè¿‡é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼ˆGaussian Splattingï¼‰è¿›è¡Œç›´æ¥æ“ä½œã€‚ä¸ä¼ ç»Ÿçš„ç¼–è¾‘æ–¹æ³•ä¸åŒï¼Œä¸‰ç»´åœºæ™¯ç¼–è¾‘å™¨é€šè¿‡ç®€åŒ–çš„ä¸‰ç»´æµç¨‹è¿›è¡Œæ“ä½œï¼Œèƒ½å¤Ÿå®ç°åŸºäºè¾“å…¥æç¤ºçš„é«˜æ•ˆé«˜è´¨é‡ç¼–è¾‘ã€‚æ‰€æå‡ºçš„æ¡†æ¶ï¼ˆä¸€ï¼‰é›†æˆäº†é¢„è®­ç»ƒçš„å®ä¾‹åˆ†å‰²æ¨¡å‹è¿›è¡Œè¯­ä¹‰æ ‡æ³¨ï¼›ï¼ˆäºŒï¼‰é‡‡ç”¨CLIPè¿›è¡Œé›¶æ ·æœ¬å®šä½æ³•æ¥åŒ¹é…ç›®æ ‡å¯¹è±¡ä¸ç”¨æˆ·æç¤ºï¼›ï¼ˆä¸‰ï¼‰ç›´æ¥åœ¨é«˜æ–¯æ¸²æŸ“ä¸Šå¯¹åœºæ™¯è¿›è¡Œä¿®æ”¹ï¼Œå¦‚æ·»åŠ å¯¹è±¡ã€é‡æ–°å®šä½ã€æ›´æ”¹é¢œè‰²ã€æ›¿æ¢å’Œåˆ é™¤å¯¹è±¡ç­‰ã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºå½“å‰å…ˆè¿›çš„ä¸‰ç»´åœºæ™¯ç¼–è¾‘æ–¹æ³•ï¼Œä¸‰ç»´åœºæ™¯ç¼–è¾‘å™¨åœ¨ç¼–è¾‘ç²¾åº¦å’Œé€Ÿåº¦ä¸Šæ›´èƒœä¸€ç­¹ï¼Œä¸ºé«˜æ•ˆäº¤äº’å¼ä¸‰ç»´åœºæ™¯å®šåˆ¶æ ‘ç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01583v2">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://ziyangyan.github.io/3DSceneEditor">https://ziyangyan.github.io/3DSceneEditor</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¼ ç»Ÿåˆ›å»º3Dåœºæ™¯æ—¢è€—æ—¶åˆæ˜‚è´µçš„é—®é¢˜ï¼Œå¹¶æŒ‡å‡ºè¿‘å¹´æ¥ç”Ÿæˆå¼AIçš„è¿›æ­¥æ˜¾è‘—é™ä½äº†è¿™ä¸€è¿‡ç¨‹çš„å¤æ‚æ€§å’Œæˆæœ¬ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤æ‚3Dåœºæ™¯ç¼–è¾‘æŠ€æœ¯ä»ä¾èµ–äºäº’åŠ¨å¤šæ­¥éª¤çš„2D-to-3DæŠ•å½±æ–¹æ³•å’Œæ‰©æ•£æŠ€æœ¯ï¼Œç¼ºä¹ç²¾ç¡®æ§åˆ¶å’Œå®æ—¶æ€§èƒ½ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„å…¨3Dåœºæ™¯ç¼–è¾‘æ¡†æ¶â€”â€”3DSceneEditorï¼Œå®ƒé‡‡ç”¨é«˜æ–¯æç”»æŠ€æœ¯ï¼Œèƒ½å¤Ÿå®ç°å®æ—¶ç²¾ç¡®ç¼–è¾‘å¤æ‚çš„3Dåœºæ™¯ã€‚è¯¥æ¡†æ¶é›†æˆäº†é¢„è®­ç»ƒçš„å®ä¾‹åˆ†å‰²æ¨¡å‹è¿›è¡Œè¯­ä¹‰æ ‡æ³¨ï¼Œå¹¶é‡‡ç”¨é›¶æ ·æœ¬å®šä½æ³•ä¸ç”¨æˆ·æç¤ºå¯¹é½ç›®æ ‡å¯¹è±¡ï¼Œå®ç°åœºæ™¯ä¿®æ”¹ï¼Œå¦‚æ·»åŠ ã€é‡æ–°å®šä½ã€æ”¹å˜é¢œè‰²ã€æ›¿æ¢å’Œåˆ é™¤å¯¹è±¡ç­‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºå½“å‰æœ€å…ˆè¿›çš„3Dåœºæ™¯ç¼–è¾‘æ–¹æ³•ï¼Œ3DSceneEditoråœ¨ç¼–è¾‘ç²¾åº¦å’Œé€Ÿåº¦ä¸Šæ›´èƒœä¸€ç­¹ï¼Œä¸ºé«˜æ•ˆã€äº¤äº’å¼çš„3Dåœºæ™¯å®šåˆ¶æ ‘ç«‹äº†æ–°æ ‡æ†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿåˆ›å»º3Dåœºæ™¯è¿‡ç¨‹æ—¢è€—æ—¶åˆæ˜‚è´µã€‚</li>
<li>ç”Ÿæˆå¼AIçš„è¿›æ­¥é™ä½äº†åˆ›å»ºè¿‡ç¨‹çš„å¤æ‚æ€§å’Œæˆæœ¬ã€‚</li>
<li>å½“å‰å¤æ‚3Dåœºæ™¯ç¼–è¾‘æŠ€æœ¯ç¼ºä¹ç²¾ç¡®æ§åˆ¶å’Œå®æ—¶æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†å…¨æ–°çš„å…¨3Dåœºæ™¯ç¼–è¾‘æ¡†æ¶â€”â€”3DSceneEditorã€‚</li>
<li>3DSceneEditoré‡‡ç”¨é«˜æ–¯æç”»æŠ€æœ¯å®ç°å®æ—¶ç²¾ç¡®ç¼–è¾‘ã€‚</li>
<li>3DSceneEditoré›†æˆäº†é¢„è®­ç»ƒçš„å®ä¾‹åˆ†å‰²æ¨¡å‹å’Œé›¶æ ·æœ¬å®šä½æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-b9d87e461f3cebe6013819023510b584.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-e1ff0fe311c97ffcf7b0123ba405e822.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-58e0ec171c82bd8a60e6b5b488a232ff.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-cee0903bb1750b37ed6471b648f1f176.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9f27e0e6cdc22f8ba7208e6112810a42.jpg" align="middle">
</details>




<h2 id="A-Lesson-in-Splats-Teacher-Guided-Diffusion-for-3D-Gaussian-Splats-Generation-with-2D-Supervision"><a href="#A-Lesson-in-Splats-Teacher-Guided-Diffusion-for-3D-Gaussian-Splats-Generation-with-2D-Supervision" class="headerlink" title="A Lesson in Splats: Teacher-Guided Diffusion for 3D Gaussian Splats   Generation with 2D Supervision"></a>A Lesson in Splats: Teacher-Guided Diffusion for 3D Gaussian Splats   Generation with 2D Supervision</h2><p><strong>Authors:Chensheng Peng, Ido Sobol, Masayoshi Tomizuka, Kurt Keutzer, Chenfeng Xu, Or Litany</strong></p>
<p>We introduce a diffusion model for Gaussian Splats, SplatDiffusion, to enable generation of three-dimensional structures from single images, addressing the ill-posed nature of lifting 2D inputs to 3D. Existing methods rely on deterministic, feed-forward predictions, which limit their ability to handle the inherent ambiguity of 3D inference from 2D data. Diffusion models have recently shown promise as powerful generative models for 3D data, including Gaussian splats; however, standard diffusion frameworks typically require the target signal and denoised signal to be in the same modality, which is challenging given the scarcity of 3D data. To overcome this, we propose a novel training strategy that decouples the denoised modality from the supervision modality. By using a deterministic model as a noisy teacher to create the noised signal and transitioning from single-step to multi-step denoising supervised by an image rendering loss, our approach significantly enhances performance compared to the deterministic teacher. Additionally, our method is flexible, as it can learn from various 3D Gaussian Splat (3DGS) teachers with minimal adaptation; we demonstrate this by surpassing the performance of two different deterministic models as teachers, highlighting the potential generalizability of our framework. Our approach further incorporates a guidance mechanism to aggregate information from multiple views, enhancing reconstruction quality when more than one view is available. Experimental results on object-level and scene-level datasets demonstrate the effectiveness of our framework. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é«˜æ–¯Splatsçš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸ºSplatDiffusionï¼Œç”¨äºä»å•å¼ å›¾åƒç”Ÿæˆä¸‰ç»´ç»“æ„ï¼Œè§£å†³å°†äºŒç»´è¾“å…¥æå‡åˆ°ä¸‰ç»´çš„ä¸é€‚å®šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç¡®å®šæ€§å‰é¦ˆé¢„æµ‹ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¤„ç†ä»äºŒç»´æ•°æ®åˆ°ä¸‰ç»´æ¨æ–­çš„å†…åœ¨æ¨¡ç³Šæ€§çš„èƒ½åŠ›ã€‚æ‰©æ•£æ¨¡å‹æœ€è¿‘åœ¨ä¸‰ç»´æ•°æ®çš„å¼ºå¤§ç”Ÿæˆæ¨¡å‹æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼ŒåŒ…æ‹¬é«˜æ–¯splatsï¼›ç„¶è€Œï¼Œæ ‡å‡†çš„æ‰©æ•£æ¡†æ¶é€šå¸¸éœ€è¦ç›®æ ‡ä¿¡å·å’Œå»å™ªä¿¡å·å¤„äºåŒä¸€æ¨¡æ€ï¼Œè¿™åœ¨ä¸‰ç»´æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒç­–ç•¥ï¼Œå°†å»å™ªæ¨¡æ€ä¸ç›‘ç£æ¨¡æ€è§£è€¦ã€‚é€šè¿‡ä½¿ç”¨ç¡®å®šæ€§æ¨¡å‹ä½œä¸ºå™ªå£°æ•™å¸ˆæ¥åˆ›å»ºå™ªå£°ä¿¡å·ï¼Œå¹¶ä»å•æ­¥è¿‡æ¸¡åˆ°ç”±å›¾åƒæ¸²æŸ“æŸå¤±ç›‘ç£çš„å¤šæ­¥å»å™ªï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç¡®å®šæ€§æ•™å¸ˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¾ˆçµæ´»ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°ä»å„ç§ä¸‰ç»´é«˜æ–¯Splatï¼ˆ3DGSï¼‰æ•™å¸ˆé‚£é‡Œå­¦ä¹ ï¼Œå¹¶ä¸”å‡ ä¹ä¸éœ€è¦é€‚åº”ï¼›æˆ‘ä»¬é€šè¿‡è¶…è¶Šä¸¤ä¸ªä¸åŒç¡®å®šæ€§æ¨¡å‹æ•™å¸ˆçš„æ€§èƒ½æ¥è¯æ˜è¿™ä¸€ç‚¹ï¼Œçªå‡ºäº†æˆ‘ä»¬æ¡†æ¶çš„æ½œåœ¨é€šç”¨æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜é‡‡ç”¨äº†ä¸€ç§æŒ‡å¯¼æœºåˆ¶æ¥æ•´åˆå¤šä¸ªè§†è§’çš„ä¿¡æ¯ï¼Œåœ¨å¯ç”¨å¤šä¸ªè§†è§’æ—¶æé«˜é‡å»ºè´¨é‡ã€‚åœ¨å¯¹è±¡çº§å’Œåœºæ™¯çº§æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00623v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§ç”¨äºä»å•ä¸€å›¾åƒç”Ÿæˆä¸‰ç»´ç»“æ„çš„æ‰©æ•£æ¨¡å‹â€”â€”SplatDiffusionã€‚è¯¥æ¨¡å‹è§£å†³äº†å°†äºŒç»´è¾“å…¥æå‡åˆ°ä¸‰ç»´çš„é€‚å®šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç¡®å®šæ€§å‰é¦ˆé¢„æµ‹ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¤„ç†ä»äºŒç»´æ•°æ®æ¨æ–­ä¸‰ç»´ä¿¡æ¯çš„å›ºæœ‰æ¨¡ç³Šæ€§çš„èƒ½åŠ›ã€‚æœ¬ç ”ç©¶é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œæå‡ºä¸€ç§æ–°å‹è®­ç»ƒç­–ç•¥ï¼Œå°†å»å™ªæ¨¡æ€ä¸ç›‘ç£æ¨¡æ€è§£è€¦ï¼Œä½¿ç”¨ç¡®å®šæ€§æ¨¡å‹ä½œä¸ºå™ªå£°æ•™å¸ˆåˆ›å»ºå™ªå£°ä¿¡å·ï¼Œä»å•æ­¥è¿‡æ¸¡åˆ°å¤šæ­¥å»å™ªï¼Œç”±å›¾åƒæ¸²æŸ“æŸå¤±è¿›è¡Œç›‘ç£ã€‚è¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼Œå¹¶å…·å¤‡çµæ´»æ€§ï¼Œèƒ½å¤Ÿä»ä¸åŒ3Dé«˜æ–¯å¹³æ¿æ•™å¸ˆæ¨¡å‹ä¸­å­¦ä¹ ï¼Œé€šè¿‡è¶…è¶Šä¸¤ä¸ªä¸åŒç¡®å®šæ€§æ•™å¸ˆçš„æ€§èƒ½æ¥å±•ç¤ºæ¡†æ¶çš„æ½œåœ¨é€šç”¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èå…¥äº†ä¸€ç§æŒ‡å¯¼æœºåˆ¶ï¼Œèƒ½å¤Ÿèšåˆå¤šè§†è§’çš„ä¿¡æ¯ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å¼•å…¥äº†SplatDiffusionæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºä»å•ä¸€å›¾åƒç”Ÿæˆä¸‰ç»´ç»“æ„çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹è§£å†³äº†å°†äºŒç»´è¾“å…¥æå‡åˆ°ä¸‰ç»´çš„é€‚å®šæ€§é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ç¡®å®šæ€§å‰é¦ˆé¢„æµ‹ï¼Œå­˜åœ¨å¤„ç†3Dæ¨æ–­çš„å›ºæœ‰æ¨¡ç³Šæ€§çš„é™åˆ¶ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨æ‰©æ•£æ¨¡å‹å¹¶æå‡ºæ–°å‹è®­ç»ƒç­–ç•¥ï¼Œå°†å»å™ªæ¨¡æ€ä¸ç›‘ç£æ¨¡æ€è§£è€¦ã€‚</li>
<li>ä½¿ç”¨ç¡®å®šæ€§æ¨¡å‹ä½œä¸ºå™ªå£°æ•™å¸ˆï¼Œä»å•æ­¥å»å™ªè¿‡æ¸¡åˆ°å¤šæ­¥å»å™ªï¼Œé€šè¿‡å›¾åƒæ¸²æŸ“æŸå¤±è¿›è¡Œç›‘ç£ï¼Œæé«˜æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹å…·å¤‡çµæ´»æ€§ï¼Œèƒ½å¤Ÿè½»æ¾é€‚åº”ä¸åŒçš„3Dé«˜æ–¯å¹³æ¿æ•™å¸ˆæ¨¡å‹ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-606e77eb3e4cee441eb31eabecc22dc8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c81b83f99d93a83d7c2028ac1044dc8d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-70642a33d93152eb1c9958c72d4694a5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-084788d1a3c9bf4a759bc1df2b42fdad.jpg" align="middle">
</details>




<h2 id="Make-It-Animatable-An-Efficient-Framework-for-Authoring-Animation-Ready-3D-Characters"><a href="#Make-It-Animatable-An-Efficient-Framework-for-Authoring-Animation-Ready-3D-Characters" class="headerlink" title="Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready   3D Characters"></a>Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready   3D Characters</h2><p><strong>Authors:Zhiyang Guo, Jinxu Xiang, Kai Ma, Wengang Zhou, Houqiang Li, Ran Zhang</strong></p>
<p>3D characters are essential to modern creative industries, but making them animatable often demands extensive manual work in tasks like rigging and skinning. Existing automatic rigging tools face several limitations, including the necessity for manual annotations, rigid skeleton topologies, and limited generalization across diverse shapes and poses. An alternative approach is to generate animatable avatars pre-bound to a rigged template mesh. However, this method often lacks flexibility and is typically limited to realistic human shapes. To address these issues, we present Make-It-Animatable, a novel data-driven method to make any 3D humanoid model ready for character animation in less than one second, regardless of its shapes and poses. Our unified framework generates high-quality blend weights, bones, and pose transformations. By incorporating a particle-based shape autoencoder, our approach supports various 3D representations, including meshes and 3D Gaussian splats. Additionally, we employ a coarse-to-fine representation and a structure-aware modeling strategy to ensure both accuracy and robustness, even for characters with non-standard skeleton structures. We conducted extensive experiments to validate our frameworkâ€™s effectiveness. Compared to existing methods, our approach demonstrates significant improvements in both quality and speed. </p>
<blockquote>
<p>ä¸‰ç»´è§’è‰²åœ¨ç°ä»£åˆ›æ„äº§ä¸šä¸­è‡³å…³é‡è¦ï¼Œä½†ä½¿å…¶å¯åŠ¨ç”»åŒ–é€šå¸¸éœ€è¦å¤§é‡æ‰‹åŠ¨å·¥ä½œï¼Œå¦‚è£…é…å’Œè’™çš®ç­‰ä»»åŠ¡ã€‚ç°æœ‰çš„è‡ªåŠ¨è£…é…å·¥å…·é¢ä¸´å¤šç§é™åˆ¶ï¼ŒåŒ…æ‹¬éœ€è¦æ‰‹åŠ¨æ³¨é‡Šã€åˆšæ€§çš„éª¨éª¼æ‹“æ‰‘ç»“æ„ä»¥åŠåœ¨å„ç§å½¢çŠ¶å’Œå§¿åŠ¿ä¸Šçš„é€šç”¨æ€§æœ‰é™ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯ç”Ÿæˆé¢„å…ˆç»‘å®šåˆ°è£…é…æ¨¡æ¿ç½‘æ ¼çš„å¯åŠ¨ç”»åŒ–èº«ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•é€šå¸¸ç¼ºä¹çµæ´»æ€§ï¼Œå¹¶ä¸”é€šå¸¸ä»…é™äºé€¼çœŸçš„äººå½¢ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Make-It-Animatableè¿™ä¸€æ–°å‹æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œå¯åœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…ä½¿ä»»ä½•ä¸‰ç»´äººå½¢æ¨¡å‹ä¸ºè§’è‰²åŠ¨ç”»åšå¥½å‡†å¤‡ï¼Œæ— è®ºå…¶å½¢çŠ¶å’Œå§¿åŠ¿å¦‚ä½•ã€‚æˆ‘ä»¬çš„ç»Ÿä¸€æ¡†æ¶ç”Ÿæˆé«˜è´¨é‡çš„æ··åˆæƒé‡ã€éª¨éª¼å’Œå§¿åŠ¿è½¬æ¢ã€‚é€šè¿‡é‡‡ç”¨åŸºäºç²’å­çš„å½¢çŠ¶è‡ªç¼–ç å™¨ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒå„ç§ä¸‰ç»´è¡¨ç¤ºï¼ŒåŒ…æ‹¬ç½‘æ ¼å’Œä¸‰ç»´é«˜æ–¯æ–‘å—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨äº†ä»ç²—åˆ°ç»†çš„ä»£è¡¨å’Œç»“æ„æ„ŸçŸ¥å»ºæ¨¡ç­–ç•¥ï¼Œä»¥ç¡®ä¿å³ä½¿åœ¨å…·æœ‰éæ ‡å‡†éª¨éª¼ç»“æ„çš„è§’è‰²èº«ä¸Šä¹Ÿèƒ½å®ç°å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒæ¥éªŒè¯æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡å’Œé€Ÿåº¦æ–¹é¢éƒ½æ˜¾ç¤ºå‡ºæ˜¾ç€æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18197v2">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://jasongzy.github.io/Make-It-Animatable/">https://jasongzy.github.io/Make-It-Animatable/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºMake-It-Animatableçš„æ–°å‹æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯åœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…ä½¿ä»»ä½•3Däººç±»æ¨¡å‹ä¸ºè§’è‰²åŠ¨ç”»åšå¥½å‡†å¤‡ï¼Œä¸å—å½¢çŠ¶å’Œå§¿åŠ¿çš„é™åˆ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”Ÿæˆé«˜è´¨é‡æ··åˆæƒé‡ã€éª¨éª¼å’Œå§¿åŠ¿è½¬æ¢ï¼Œæ”¯æŒå¤šç§3Dè¡¨ç¤ºå½¢å¼ï¼ŒåŒ…æ‹¬ç½‘æ ¼å’Œ3Dé«˜æ–¯æ–‘å—ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç”±ç²—åˆ°ç»†çš„è¡¨ç°å½¢å¼å’Œç»“æ„æ„ŸçŸ¥å»ºæ¨¡ç­–ç•¥ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼Œå³ä½¿å¯¹äºå…·æœ‰éæ ‡å‡†éª¨éª¼ç»“æ„çš„è§’è‰²ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dè§’è‰²åœ¨ç°ä»£åˆ›æ„äº§ä¸šä¸­çš„é‡è¦æ€§ä»¥åŠè‡ªåŠ¨ä½¿å…¶å¯åŠ¨ç”»åŒ–çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰è‡ªåŠ¨çŸ«å½¢å·¥å…·å­˜åœ¨çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬éœ€è¦æ‰‹åŠ¨æ³¨é‡Šã€éª¨éª¼æ‹“æ‰‘ç»“æ„åƒµç¡¬ä»¥åŠéš¾ä»¥åœ¨å¤šç§å½¢çŠ¶å’Œå§¿åŠ¿ä¹‹é—´å®ç°é€šç”¨æ€§ã€‚</li>
<li>Make-It-Animatableæ–¹æ³•çš„æ ¸å¿ƒç‰¹ç‚¹ï¼šåœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…ä½¿ä»»ä½•3Däººç±»æ¨¡å‹ä¸ºè§’è‰²åŠ¨ç”»åšå¥½å‡†å¤‡ï¼Œä¸å—å½¢çŠ¶å’Œå§¿åŠ¿é™åˆ¶ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ç”Ÿæˆé«˜è´¨é‡æ··åˆæƒé‡ã€éª¨éª¼å’Œå§¿åŠ¿è½¬æ¢æ¥æ”¯æŒå¤šç§3Dè¡¨ç¤ºå½¢å¼ï¼ŒåŒ…æ‹¬ç½‘æ ¼å’Œ3Dé«˜æ–¯æ–‘å—ã€‚</li>
<li>æ–¹æ³•çš„ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šç²’å­åŸºç¡€çš„å½¢çŠ¶è‡ªç¼–ç å™¨å’Œä»ç²—åˆ°ç»†çš„è¡¨ç°æ–¹å¼åŠç»“æ„æ„ŸçŸ¥å»ºæ¨¡ç­–ç•¥ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è´¨é‡å’Œé€Ÿåº¦æ–¹é¢ä¸ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2efd6a8dc8ffd9b0ae3e6599946e7408.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-e7f64c190593e275f6f99870fe8083d3.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-58ac5da7f81c0ceae21e68fe6bffa15a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a55ffce4647c76495c00e81206ef5994.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6f435426e35ef93ebae490e535356005.jpg" align="middle">
</details>




<h2 id="SpectroMotion-Dynamic-3D-Reconstruction-of-Specular-Scenes"><a href="#SpectroMotion-Dynamic-3D-Reconstruction-of-Specular-Scenes" class="headerlink" title="SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes"></a>SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes</h2><p><strong>Authors:Cheng-De Fan, Chen-Wei Chang, Yi-Ruei Liu, Jie-Ying Lee, Jiun-Long Huang, Yu-Chee Tseng, Yu-Lun Liu</strong></p>
<p>We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes. Previous methods extending 3DGS to model dynamic scenes have struggled to represent specular surfaces accurately. Our method addresses this limitation by introducing a residual correction technique for accurate surface normal computation during deformation, complemented by a deformable environment map that adapts to time-varying lighting conditions. We implement a coarse-to-fine training strategy that significantly enhances scene geometry and specular color prediction. It is the only existing 3DGS method capable of synthesizing photorealistic real-world dynamic specular scenes, outperforming state-of-the-art methods in rendering complex, dynamic, and specular scenes. See our project page for video results at <a target="_blank" rel="noopener" href="https://cdfan0627.github.io/spectromotion/">https://cdfan0627.github.io/spectromotion/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†SpectroMotionï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ã€åŸºäºç‰©ç†çš„æ¸²æŸ“ï¼ˆPBRï¼‰å’Œå˜å½¢åœºæ¥é‡å»ºåŠ¨æ€é•œé¢åœºæ™¯çš„æ–°æ–¹æ³•ã€‚ä¹‹å‰å°†3DGSæ‰©å±•åˆ°åŠ¨æ€åœºæ™¯å»ºæ¨¡çš„æ–¹æ³•åœ¨å‡†ç¡®è¡¨ç¤ºé•œé¢è¡¨é¢æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å¼•å…¥æ®‹å·®æ ¡æ­£æŠ€æœ¯æ¥è§£å†³è¿™ä¸€é™åˆ¶ï¼Œä»¥åœ¨å˜å½¢è¿‡ç¨‹ä¸­è¿›è¡Œå‡†ç¡®çš„è¡¨é¢æ³•çº¿è®¡ç®—ï¼Œè¾…ä»¥å¯é€‚åº”æ—¶é—´å˜åŒ–å…‰ç…§æ¡ä»¶çš„å¯å˜å½¢ç¯å¢ƒè´´å›¾ã€‚æˆ‘ä»¬å®ç°äº†ä»ç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†åœºæ™¯å‡ ä½•å’Œé•œé¢é¢œè‰²é¢„æµ‹ã€‚å®ƒæ˜¯ç›®å‰å”¯ä¸€ä¸€ç§èƒ½å¤Ÿåˆæˆé€¼çœŸåŠ¨æ€é•œé¢åœºæ™¯çš„3DGSæ–¹æ³•ï¼Œåœ¨æ¸²æŸ“å¤æ‚ã€åŠ¨æ€å’Œé•œé¢åœºæ™¯æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è§†é¢‘ç»“æœè¯·å‚è§æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://cdfan0627.github.io/spectromotion/%E3%80%82">https://cdfan0627.github.io/spectromotion/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17249v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://cdfan0627.github.io/spectromotion/">https://cdfan0627.github.io/spectromotion/</a></p>
<p><strong>Summary</strong><br>å…‰è°±è¿åŠ¨æ˜¯ä¸€ç§ç»“åˆ3Dé«˜æ–¯å–·æº…æŠ€æœ¯ï¼ˆ3DGSï¼‰ã€ç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰å’Œå˜å½¢åœºæ¥é‡å»ºåŠ¨æ€é•œé¢åœºæ™¯çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•è§£å†³äº†ä¹‹å‰å°†3DGSæ‰©å±•åˆ°åŠ¨æ€åœºæ™¯å»ºæ¨¡ä¸­éš¾ä»¥å‡†ç¡®è¡¨ç¤ºé•œé¢è¡¨é¢çš„é—®é¢˜ï¼Œå¹¶å¯é€šè¿‡æ®‹ä½™æ ¡æ­£æŠ€æœ¯å’Œå¯å˜å½¢ç¯å¢ƒæ˜ å°„æŠ€æœ¯æ¥é€‚åº”éšæ—¶é—´å˜åŒ–çš„å…‰ç…§æ¡ä»¶ã€‚å®æ–½äº†ä¸€ç§ç”±ç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œå¯æ˜¾è‘—æé«˜åœºæ™¯å‡ ä½•å’Œé•œé¢é¢œè‰²çš„é¢„æµ‹èƒ½åŠ›ï¼Œæˆä¸ºå”¯ä¸€èƒ½å¤Ÿåˆæˆé€¼çœŸç°å®åŠ¨æ€é•œé¢åœºæ™¯çš„3DGSæ–¹æ³•ï¼Œä¼˜äºå½“å‰åœ¨æ¸²æŸ“å¤æ‚ã€åŠ¨æ€å’Œé•œé¢åœºæ™¯æ–¹é¢çš„å…¶ä»–æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SpectroMotionç»“åˆäº†3DGSã€PBRå’Œå˜å½¢åœºæŠ€æœ¯æ¥é‡å»ºåŠ¨æ€é•œé¢åœºæ™¯ã€‚</li>
<li>å¼•å…¥æ®‹ä½™æ ¡æ­£æŠ€æœ¯ï¼Œè§£å†³äº†ä¹‹å‰æ–¹æ³•éš¾ä»¥å‡†ç¡®è¡¨ç¤ºé•œé¢è¡¨é¢çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡å¯å˜å½¢ç¯å¢ƒæ˜ å°„æŠ€æœ¯ï¼Œé€‚åº”äº†éšæ—¶é—´å˜åŒ–çš„å…‰ç…§æ¡ä»¶ã€‚</li>
<li>é‡‡ç”¨äº†ç”±ç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œæé«˜äº†åœºæ™¯å‡ ä½•å’Œé•œé¢é¢œè‰²é¢„æµ‹çš„ç²¾ç¡®åº¦ã€‚</li>
<li>æˆä¸ºå”¯ä¸€èƒ½å¤Ÿåˆæˆé€¼çœŸç°å®åŠ¨æ€é•œé¢åœºæ™¯çš„3DGSæ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ¸²æŸ“å¤æ‚ã€åŠ¨æ€å’Œé•œé¢åœºæ™¯æ–¹é¢ä¼˜äºå½“å‰çš„å…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-395c6977841c86605d6f258fe3a75c1f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-6fdc5ad74cea9765a17e9ea4ad6a32a8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7f2b0ea9be9f6642b1e3bd8b8db8d180.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9982c03a3d487e383bde7fee70b238ea.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-c17d50afb4448a27f9d9a12891409219.jpg" align="middle">
</details>




<h2 id="LUDVIG-Learning-free-Uplifting-of-2D-Visual-features-to-Gaussian-Splatting-scenes"><a href="#LUDVIG-Learning-free-Uplifting-of-2D-Visual-features-to-Gaussian-Splatting-scenes" class="headerlink" title="LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian   Splatting scenes"></a>LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian   Splatting scenes</h2><p><strong>Authors:Juliette Marrie, Romain Menegaux, Michael Arbel, Diane Larlus, Julien Mairal</strong></p>
<p>We address the problem of extending the capabilities of vision foundation models such as DINO, SAM, and CLIP, to 3D tasks. Specifically, we introduce a novel method to uplift 2D image features into 3D Gaussian Splatting scenes. Unlike traditional approaches that rely on minimizing a reconstruction loss, our method employs a simpler and more efficient feature aggregation technique, augmented by a graph diffusion mechanism. Graph diffusion enriches features from a given model, such as CLIP, by leveraging 3D geometry and pairwise similarities induced by another strong model such as DINOv2. Our approach achieves performance comparable to the state of the art on multiple downstream tasks while delivering significant speed-ups. Notably, we obtain competitive segmentation results using generic DINOv2 features, despite DINOv2 not being trained on millions of annotated segmentation masks like SAM. When applied to CLIP features, our method demonstrates strong performance in open-vocabulary object detection tasks, highlighting the versatility of our approach. </p>
<blockquote>
<p>æˆ‘ä»¬è‡´åŠ›äºæ‰©å±•å¦‚DINOã€SAMå’ŒCLIPç­‰è§†è§‰åŸºç¡€æ¨¡å‹åœ¨3Dä»»åŠ¡ä¸Šçš„èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†2Då›¾åƒç‰¹å¾æå‡åˆ°3Dé«˜æ–¯è´´å›¾åœºæ™¯çš„æ–°æ–¹æ³•ã€‚ä¸åŒäºä¼ ç»Ÿæ–¹æ³•ä¾èµ–æœ€å°åŒ–é‡å»ºæŸå¤±ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨æ›´ç®€å•é«˜æ•ˆçš„ç‰¹å¾èšåˆæŠ€æœ¯ï¼Œè¾…ä»¥å›¾æ‰©æ•£æœºåˆ¶ã€‚å›¾æ‰©æ•£é€šè¿‡åˆ©ç”¨3Då‡ ä½•å’Œç”±å¦ä¸€ä¸ªå¼ºå¤§æ¨¡å‹ï¼ˆå¦‚DINOv2ï¼‰å¼•èµ·çš„é…å¯¹ç›¸ä¼¼æ€§ï¼Œä¸°å¯Œäº†ç»™å®šæ¨¡å‹ï¼ˆå¦‚CLIPï¼‰çš„ç‰¹å¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šå®ç°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿DINOv2æ²¡æœ‰åƒSAMé‚£æ ·åœ¨æ•°ç™¾ä¸‡ä¸ªæ ‡æ³¨çš„åˆ†å‰²æ©è†œä¸Šè¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä»¬ä»ç„¶è·å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„åˆ†å‰²ç»“æœã€‚å½“åº”ç”¨äºCLIPç‰¹æ€§æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡è¡¨å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬æ–¹æ³•çš„é€šç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.14462v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨å¦‚ä½•å°†è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOã€SAMå’ŒCLIPï¼‰çš„èƒ½åŠ›æ‰©å±•åˆ°3Dä»»åŠ¡ã€‚æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå°†2Då›¾åƒç‰¹å¾æå‡ä¸º3Dé«˜æ–¯æ··åˆåœºæ™¯ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•é‡‡ç”¨æ›´ç®€å•é«˜æ•ˆçš„ç‰¹å¾èšåˆæŠ€æœ¯ï¼Œè¾…ä»¥å›¾æ‰©æ•£æœºåˆ¶ã€‚å›¾æ‰©æ•£ä¸°å¯Œäº†ç»™å®šæ¨¡å‹ï¼ˆå¦‚CLIPï¼‰çš„ç‰¹å¾ï¼Œåˆ©ç”¨3Då‡ ä½•å’Œç”±å¦ä¸€å¼ºå¤§æ¨¡å‹ï¼ˆå¦‚DINOv2ï¼‰å¼•èµ·çš„æˆå¯¹ç›¸ä¼¼æ€§ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“ï¼ŒåŒæ—¶æä¾›äº†æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚åœ¨é€šç”¨DINOv2ç‰¹å¾ä¸Šè·å¾—å…·æœ‰ç«äº‰åŠ›çš„åˆ†å‰²ç»“æœï¼Œå³ä½¿åœ¨SAMæœªè¿›è¡Œæ•°ç™¾ä¸‡æ ‡æ³¨åˆ†å‰²æ©è†œè®­ç»ƒçš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å½“åº”ç”¨äºCLIPç‰¹æ€§æ—¶ï¼Œè¯¥æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡è¡¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½“ç°äº†è¯¥æ–¹æ³•çš„é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æ‰©å±•äº†è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOã€SAMå’ŒCLIPï¼‰åœ¨3Dä»»åŠ¡ä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡3Dé«˜æ–¯æ··åˆåœºæ™¯å°†2Då›¾åƒç‰¹å¾è½¬åŒ–ä¸º3Dã€‚</li>
<li>ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ–°æ–¹æ³•é‡‡ç”¨ç‰¹å¾èšåˆæŠ€æœ¯å’Œå›¾æ‰©æ•£æœºåˆ¶ï¼Œæ›´é«˜æ•ˆã€æ›´ç®€å•ã€‚</li>
<li>å›¾æ‰©æ•£æœºåˆ¶ä¸°å¯Œäº†æ¨¡å‹çš„ç‰¹å¾ï¼Œç»“åˆäº†3Då‡ ä½•å’Œæˆå¯¹ç›¸ä¼¼æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“ï¼Œå¹¶ä¸”å…·æœ‰æ˜¾è‘—çš„é€Ÿåº¦ä¼˜åŠ¿ã€‚</li>
<li>ä½¿ç”¨é€šç”¨çš„DINOv2ç‰¹å¾è·å¾—æœ‰ç«äº‰åŠ›çš„åˆ†å‰²ç»“æœï¼Œå³ä½¿åœ¨æ²¡æœ‰ä¸“é—¨çš„è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-cd99cfe05c50565ed1042f6c4c401e2d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6e2d514ade6269c2983c2f12c1a69710.jpg" align="middle">
</details>




<h2 id="Topology-aware-Human-Avatars-with-Semantically-guided-Gaussian-Splatting"><a href="#Topology-aware-Human-Avatars-with-Semantically-guided-Gaussian-Splatting" class="headerlink" title="Topology-aware Human Avatars with Semantically-guided Gaussian Splatting"></a>Topology-aware Human Avatars with Semantically-guided Gaussian Splatting</h2><p><strong>Authors:Haoyu Zhao, Chen Yang, Hao Wang, Xingyue Zhao, Wei Shen</strong></p>
<p>Reconstructing photo-realistic and topology-aware animatable human avatars from monocular videos remains challenging in computer vision and graphics. Recently, methods using 3D Gaussians to represent the human body have emerged, offering faster optimization and real-time rendering. However, due to ignoring the crucial role of human body semantic information which represents the explicit topological and intrinsic structure within human body, they fail to achieve fine-detail reconstruction of human avatars. To address this issue, we propose SG-GS, which uses semantics-embedded 3D Gaussians, skeleton-driven rigid deformation, and non-rigid cloth dynamics deformation to create photo-realistic human avatars. We then design a Semantic Human-Body Annotator (SHA) which utilizes SMPLâ€™s semantic prior for efficient body part semantic labeling. The generated labels are used to guide the optimization of semantic attributes of Gaussian. To capture the explicit topological structure of the human body, we employ a 3D network that integrates both topological and geometric associations for human avatar deformation. We further implement three key strategies to enhance the semantic accuracy of 3D Gaussians and rendering quality: semantic projection with 2D regularization, semantic-guided density regularization and semantic-aware regularization with neighborhood consistency. Extensive experiments demonstrate that SG-GS achieves state-of-the-art geometry and appearance reconstruction performance. </p>
<blockquote>
<p>é‡å»ºå•çœ¼è§†é¢‘ä¸­çš„ç…§ç‰‡çº§çœŸå®å’Œæ‹“æ‰‘æ„ŸçŸ¥åŠ¨ç”»äººå½¢ï¼Œåœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è¿‘æœŸï¼Œä½¿ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºäººä½“çš„æ–¹æ³•å·²ç»å‡ºç°ï¼Œæä¾›äº†æ›´å¿«çš„ä¼˜åŒ–å’Œå®æ—¶æ¸²æŸ“ã€‚ç„¶è€Œï¼Œç”±äºå¿½ç•¥äº†äººä½“è¯­ä¹‰ä¿¡æ¯çš„é‡è¦è§’è‰²ï¼Œè¿™äº›è¯­ä¹‰ä¿¡æ¯ä»£è¡¨äººä½“å†…éƒ¨çš„æ˜ç¡®æ‹“æ‰‘ç»“æ„å’Œå†…åœ¨ç»“æ„ï¼Œå› æ­¤å®ƒä»¬æ— æ³•å®ç°å¯¹äººå½¢çš„ç²¾ç»†ç»†èŠ‚é‡å»ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SG-GSï¼Œå®ƒä½¿ç”¨åµŒå…¥è¯­ä¹‰çš„ä¸‰ç»´é«˜æ–¯ã€éª¨æ¶é©±åŠ¨çš„åˆšæ€§å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨æ€å˜å½¢æ¥åˆ›å»ºç…§ç‰‡çº§çœŸå®çš„äººå½¢ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯­ä¹‰äººä½“æ³¨é‡Šå™¨ï¼ˆSHAï¼‰ï¼Œå®ƒåˆ©ç”¨SMPLçš„è¯­ä¹‰å…ˆéªŒæ¥è¿›è¡Œæœ‰æ•ˆçš„èº«ä½“éƒ¨ä½è¯­ä¹‰æ ‡è®°ã€‚ç”Ÿæˆçš„æ ‡ç­¾è¢«ç”¨æ¥æŒ‡å¯¼é«˜æ–¯è¯­ä¹‰å±æ€§çš„ä¼˜åŒ–ã€‚ä¸ºäº†æ•æ‰äººä½“çš„æ˜ç¡®æ‹“æ‰‘ç»“æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ä¸ªä¸‰ç»´ç½‘ç»œï¼Œè¯¥ç½‘ç»œç»“åˆäº†æ‹“æ‰‘å’Œå‡ ä½•å…³è”æ¥è¿›è¡Œäººå½¢å˜å½¢ã€‚æˆ‘ä»¬è¿˜å®æ–½äº†ä¸‰ä¸ªå…³é”®ç­–ç•¥ï¼Œä»¥æé«˜ä¸‰ç»´é«˜æ–¯çš„è¯­ä¹‰å‡†ç¡®æ€§å’Œæ¸²æŸ“è´¨é‡ï¼šäºŒç»´æ­£åˆ™åŒ–çš„è¯­ä¹‰æŠ•å½±ã€è¯­ä¹‰å¼•å¯¼çš„å¯†åº¦æ­£åˆ™åŒ–å’Œå…·æœ‰é‚»åŸŸä¸€è‡´æ€§çš„è¯­ä¹‰æ„ŸçŸ¥æ­£åˆ™åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSG-GSè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡ ä½•å’Œå¤–è§‚é‡å»ºæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09665v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºå•ç›®è§†é¢‘é‡å»ºå…·æœ‰çœŸå®æ„Ÿå’Œæ‹“æ‰‘æ„ŸçŸ¥çš„åŠ¨æ€äººä½“avatarä»å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ€è¿‘å‡ºç°ä½¿ç”¨3Dé«˜æ–¯è¡¨ç¤ºäººä½“çš„æ–¹æ³•ï¼Œä½†å¿½ç•¥äº†äººä½“è¯­ä¹‰ä¿¡æ¯çš„é‡è¦æ€§ï¼Œæ— æ³•å®ç°ç²¾ç»†çš„äººä½“é‡å»ºã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºSG-GSæ–¹æ³•ï¼Œç»“åˆè¯­ä¹‰åµŒå…¥çš„3Dé«˜æ–¯ã€éª¨æ¶é©±åŠ¨çš„åˆšæ€§å˜å½¢å’Œéåˆšæ€§å¸ƒæ–™åŠ¨æ€å˜å½¢æŠ€æœ¯ï¼Œåˆ›å»ºçœŸå®æ„Ÿçš„äººä½“avatarã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯­ä¹‰äººä½“æ ‡æ³¨å™¨ï¼ˆSHAï¼‰ï¼Œåˆ©ç”¨SMPLçš„è¯­ä¹‰å…ˆéªŒè¿›è¡Œé«˜æ•ˆçš„éƒ¨ä½è¯­ä¹‰æ ‡æ³¨ã€‚é€šè¿‡å®æ–½ä¸‰ä¸ªå…³é”®ç­–ç•¥æé«˜3Dé«˜æ–¯çš„è¯­ä¹‰å‡†ç¡®æ€§å’Œæ¸²æŸ“è´¨é‡ï¼šäºŒç»´æ­£åˆ™åŒ–çš„è¯­ä¹‰æŠ•å½±ã€è¯­ä¹‰å¼•å¯¼çš„å¯†åº¦æ­£åˆ™åŒ–å’Œå…·æœ‰é‚»åŸŸä¸€è‡´æ€§çš„è¯­ä¹‰æ„ŸçŸ¥æ­£åˆ™åŒ–ã€‚å®éªŒè¯æ˜SG-GSè¾¾åˆ°é¢†å…ˆçš„å‡ ä½•å’Œå¤–è§‚é‡å»ºæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é‡å»ºçœŸå®å’Œæ‹“æ‰‘æ„ŸçŸ¥çš„åŠ¨æ€äººä½“avataråœ¨å•ç›®è§†é¢‘ä¸­ä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç›®å‰æ–¹æ³•ä½¿ç”¨3Dé«˜æ–¯è¡¨ç¤ºäººä½“ï¼Œä½†å¿½ç•¥äº†è¯­ä¹‰ä¿¡æ¯çš„é‡è¦æ€§ï¼Œå½±å“ç²¾ç»†é‡å»ºã€‚</li>
<li>æå‡ºSG-GSæ–¹æ³•ç»“åˆè¯­ä¹‰åµŒå…¥çš„3Dé«˜æ–¯å’Œéª¨æ¶é©±åŠ¨å˜å½¢æŠ€æœ¯ï¼Œå®ç°çœŸå®æ„Ÿçš„äººä½“avataråˆ›å»ºã€‚</li>
<li>è®¾è®¡è¯­ä¹‰äººä½“æ ‡æ³¨å™¨ï¼ˆSHAï¼‰è¿›è¡Œé«˜æ•ˆéƒ¨ä½è¯­ä¹‰æ ‡æ³¨ã€‚</li>
<li>å®æ–½ä¸‰ä¸ªç­–ç•¥æé«˜è¯­ä¹‰å‡†ç¡®æ€§å’Œæ¸²æŸ“è´¨é‡ï¼šè¯­ä¹‰æŠ•å½±ã€å¯†åº¦æ­£åˆ™åŒ–å’Œè¯­ä¹‰æ„ŸçŸ¥æ­£åˆ™åŒ–ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-6ff77e21bec81067b0e2966ed6634bd6.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-fdb456e5809bd0fa45ea185f6d20687a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-93be2bb8d66c02543723f8dae3fae9b4.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-fa45cbf4b6d66afe5756817c7c32afc9.jpg" align="middle">
</details>




<h2 id="3D-Consistent-Human-Avatars-with-Sparse-Inputs-via-Gaussian-Splatting-and-Contrastive-Learning"><a href="#3D-Consistent-Human-Avatars-with-Sparse-Inputs-via-Gaussian-Splatting-and-Contrastive-Learning" class="headerlink" title="3D-Consistent Human Avatars with Sparse Inputs via Gaussian Splatting   and Contrastive Learning"></a>3D-Consistent Human Avatars with Sparse Inputs via Gaussian Splatting   and Contrastive Learning</h2><p><strong>Authors:Haoyu Zhao, Hao Wang, Chen Yang, Wei Shen</strong></p>
<p>Existing approaches for human avatar generationâ€“both NeRF-based and 3D Gaussian Splatting (3DGS) basedâ€“struggle with maintaining 3D consistency and exhibit degraded detail reconstruction, particularly when training with sparse inputs. To address this challenge, we propose CHASE, a novel framework that achieves dense-input-level performance using only sparse inputs through two key innovations: cross-pose intrinsic 3D consistency supervision and 3D geometry contrastive learning. Building upon prior skeleton-driven approaches that combine rigid deformation with non-rigid cloth dynamics, we first establish baseline avatars with fundamental 3D consistency. To enhance 3D consistency under sparse inputs, we introduce a Dynamic Avatar Adjustment (DAA) module, which refines deformed Gaussians by leveraging similar poses from the training set. By minimizing the rendering discrepancy between adjusted Gaussians and reference poses, DAA provides additional supervision for avatar reconstruction. We further maintain global 3D consistency through a novel geometry-aware contrastive learning strategy. While designed for sparse inputs, CHASE surpasses state-of-the-art methods across both full and sparse settings on ZJU-MoCap and H36M datasets, demonstrating that our enhanced 3D consistency leads to superior rendering quality. </p>
<blockquote>
<p>ç°æœ‰çš„äººå½¢åŒ–èº«ç”Ÿæˆæ–¹æ³•ï¼Œæ— è®ºæ˜¯åŸºäºNeRFçš„è¿˜æ˜¯åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„ï¼Œåœ¨ä¿æŒ3Dä¸€è‡´æ€§æ–¹é¢éƒ½å­˜åœ¨å›°éš¾ï¼Œå¹¶ä¸”åœ¨ç»†èŠ‚é‡å»ºæ–¹é¢è¡¨ç°å‡ºé€€åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ç¨€ç–è¾“å…¥è¿›è¡Œè®­ç»ƒæ—¶æ›´æ˜¯å¦‚æ­¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†CHASEï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå®ƒä»…é€šè¿‡ä¸¤é¡¹å…³é”®åˆ›æ–°â€”â€”è·¨å§¿åŠ¿å†…åœ¨3Dä¸€è‡´æ€§ç›‘ç£å’Œ3Då‡ ä½•å¯¹æ¯”å­¦ä¹ ï¼Œä½¿ç”¨ç¨€ç–è¾“å…¥å®ç°å¯†é›†è¾“å…¥çº§åˆ«çš„æ€§èƒ½ã€‚æˆ‘ä»¬å»ºç«‹åœ¨å…ˆå‰ç»“åˆåˆšæ€§å˜å½¢ä¸éåˆšæ€§å¸ƒæ–™åŠ¨åŠ›å­¦çš„éª¨æ¶é©±åŠ¨æ–¹æ³•ä¹‹ä¸Šï¼Œé¦–å…ˆå»ºç«‹å…·æœ‰åŸºæœ¬3Dä¸€è‡´æ€§çš„åŸºå‡†åŒ–èº«ã€‚ä¸ºäº†æé«˜ç¨€ç–è¾“å…¥ä¸‹çš„3Dä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€åŒ–èº«è°ƒæ•´ï¼ˆDAAï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—é€šè¿‡åˆ©ç”¨è®­ç»ƒé›†ä¸­çš„ç›¸ä¼¼å§¿åŠ¿æ¥ä¼˜åŒ–å˜å½¢çš„é«˜æ–¯ã€‚é€šè¿‡æœ€å°åŒ–è°ƒæ•´åçš„é«˜æ–¯ä¸å‚è€ƒå§¿åŠ¿ä¹‹é—´çš„æ¸²æŸ“å·®å¼‚ï¼ŒDAAä¸ºåŒ–èº«é‡å»ºæä¾›äº†é¢å¤–çš„ç›‘ç£ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸€ç§æ–°å‹å‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥æ¥ä¿æŒå…¨å±€3Dä¸€è‡´æ€§ã€‚è™½ç„¶æ˜¯ä¸ºç¨€ç–è¾“å…¥è€Œè®¾è®¡çš„ï¼Œä½†CHASEåœ¨ZJU-MoCapå’ŒH36Mæ•°æ®é›†ä¸Šçš„å…¨é¢å’Œç¨€ç–è®¾ç½®æ–¹é¢éƒ½è¶…è¶Šäº†æœ€æ–°æ–¹æ³•ï¼Œè¡¨æ˜æˆ‘ä»¬å¢å¼ºçš„3Dä¸€è‡´æ€§å¯¼è‡´äº†æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.09663v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç°æœ‰çš„äººç±»è§’è‰²ç”Ÿæˆæ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºCHASEçš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨ç¨€ç–è¾“å…¥ä¸‹å®ç°äº†å¯†é›†è¾“å…¥çº§åˆ«çš„æ€§èƒ½è¡¨ç°ã€‚é€šè¿‡å¼•å…¥è·¨å§¿æ€å†…åœ¨ä¸‰ç»´ä¸€è‡´æ€§ç›‘ç£å’Œä¸‰ç»´å‡ ä½•å¯¹æ¯”å­¦ä¹ ä¸¤å¤§åˆ›æ–°ç‚¹ï¼Œè¯¥æ¡†æ¶ä¼˜åŒ–äº†ä¸‰ç»´ä¸€è‡´æ€§å¹¶ä¿æŒäº†å¯¹ç¨€ç–è¾“å…¥çš„ç»†èŠ‚é‡å»ºã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥åŠ¨æ€è§’è‰²è°ƒæ•´æ¨¡å—æ¥ä¼˜åŒ–ç°æœ‰è§’è‰²ï¼Œä»¥åŠå‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥æ¥ç»´æŒå…¨å±€ä¸‰ç»´ä¸€è‡´æ€§ã€‚é€šè¿‡å®éªŒè¯æ˜ï¼Œæ— è®ºæ˜¯åœ¨å…¨æ•°æ®è¿˜æ˜¯ç¨€ç–æ•°æ®ç¯å¢ƒä¸‹ï¼ŒCHASEæ¡†æ¶åœ¨ZJU-MoCapå’ŒH36Mæ•°æ®é›†ä¸Šçš„è¡¨ç°å‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå±•ç°äº†å…¶å“è¶Šçš„ä¸‰ç»´ä¸€è‡´æ€§å’Œæ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CHASEæ¡†æ¶è§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨ä¿æŒä¸‰ç»´ä¸€è‡´æ€§å’Œé‡å»ºç»†èŠ‚æ–¹é¢çš„æŒ‘æˆ˜ã€‚</li>
<li>CHASEæ¡†æ¶å¼•å…¥ä¸¤å¤§åˆ›æ–°ç‚¹ï¼šè·¨å§¿æ€å†…åœ¨ä¸‰ç»´ä¸€è‡´æ€§ç›‘ç£å’Œä¸‰ç»´å‡ ä½•å¯¹æ¯”å­¦ä¹ ã€‚</li>
<li>åŠ¨æ€è§’è‰²è°ƒæ•´æ¨¡å—ç”¨äºä¼˜åŒ–ç°æœ‰è§’è‰²ï¼Œé€šè¿‡æœ€å°åŒ–è°ƒæ•´åçš„é«˜æ–¯å’Œå‚è€ƒå§¿æ€ä¹‹é—´çš„æ¸²æŸ“å·®å¼‚æ¥å®ç°å¯¹è§’è‰²é‡å»ºçš„é¢å¤–ç›‘ç£ã€‚</li>
<li>å‡ ä½•æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç­–ç•¥ç”¨äºç»´æŒå…¨å±€ä¸‰ç»´ä¸€è‡´æ€§ã€‚</li>
<li>CHASEæ¡†æ¶åœ¨ZJU-MoCapå’ŒH36Mæ•°æ®é›†ä¸Šçš„è¡¨ç°è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
<li>CHASEæ¡†æ¶é€‚ç”¨äºä¸åŒçš„è¾“å…¥ç¯å¢ƒï¼ŒåŒ…æ‹¬ç¨€ç–è¾“å…¥å’Œå…¨æ•°æ®ç¯å¢ƒã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2e3d818183426e4d07c1d657130bfb4e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-172ade8d51614a60d51ade7f48d5d7e7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c52b7469d9dca60a05047d6d38dfd9d8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-87a3da9c75038d560f603c2afb23bbb0.jpg" align="middle">
</details>




<h2 id="LumiGauss-Relightable-Gaussian-Splatting-in-the-Wild"><a href="#LumiGauss-Relightable-Gaussian-Splatting-in-the-Wild" class="headerlink" title="LumiGauss: Relightable Gaussian Splatting in the Wild"></a>LumiGauss: Relightable Gaussian Splatting in the Wild</h2><p><strong>Authors:Joanna Kaleta, Kacper Kania, Tomasz Trzcinski, Marek Kowalski</strong></p>
<p>Decoupling lighting from geometry using unconstrained photo collections is notoriously challenging. Solving it would benefit many users as creating complex 3D assets takes days of manual labor. Many previous works have attempted to address this issue, often at the expense of output fidelity, which questions the practicality of such methods. We introduce LumiGauss - a technique that tackles 3D reconstruction of scenes and environmental lighting through 2D Gaussian Splatting. Our approach yields high-quality scene reconstructions and enables realistic lighting synthesis under novel environment maps. We also propose a method for enhancing the quality of shadows, common in outdoor scenes, by exploiting spherical harmonics properties. Our approach facilitates seamless integration with game engines and enables the use of fast precomputed radiance transfer. We validate our method on the NeRF-OSR dataset, demonstrating superior performance over baseline methods. Moreover, LumiGauss can synthesize realistic images for unseen environment maps. Our code: <a target="_blank" rel="noopener" href="https://github.com/joaxkal/lumigauss">https://github.com/joaxkal/lumigauss</a>. </p>
<blockquote>
<p>ä½¿ç”¨æ— çº¦æŸç…§ç‰‡é›†å°†ç…§æ˜ä¸å‡ ä½•åˆ†ç¦»æ˜¯å‡ºäº†åçš„å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è§£å†³è¿™ä¸€é—®é¢˜å°†ä½¿è®¸å¤šç”¨æˆ·å—ç›Šï¼Œå› ä¸ºåˆ›å»ºå¤æ‚çš„3Dèµ„äº§éœ€è¦æ•°å¤©çš„äººå·¥åŠ³åŠ¨ã€‚è®¸å¤šä»¥å‰çš„å·¥ä½œè¯•å›¾è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé€šå¸¸ä»¥è¾“å‡ºä¿çœŸåº¦çš„æŸå¤±ä¸ºä»£ä»·ï¼Œè¿™å¼•å‘äº†å¯¹æ­¤ç±»æ–¹æ³•å®ç”¨æ€§çš„è´¨ç–‘ã€‚æˆ‘ä»¬ä»‹ç»äº†LumiGaussâ€”â€”ä¸€ç§é€šè¿‡äºŒç»´é«˜æ–¯Splattingè§£å†³åœºæ™¯ä¸‰ç»´é‡å»ºå’Œç¯å¢ƒç…§æ˜é—®é¢˜çš„æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½äº§ç”Ÿé«˜è´¨é‡çš„åœºæ™¯é‡å»ºï¼Œå¹¶åœ¨æ–°çš„ç¯å¢ƒè´´å›¾ä¸‹å®ç°é€¼çœŸçš„ç…§æ˜åˆæˆã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åˆ©ç”¨çƒé¢è°æ³¢å±æ€§æ”¹å–„æˆ·å¤–åœºæ™¯ä¸­å¸¸è§é˜´å½±è´¨é‡çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ¸¸æˆå¼•æ“æ— ç¼é›†æˆï¼Œå¹¶åˆ©ç”¨å¿«é€Ÿé¢„è®¡ç®—è¾å°„ä¼ è¾“ã€‚æˆ‘ä»¬åœ¨NeRF-OSRæ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¡¨ç°å‡ºä¼˜äºåŸºå‡†æ–¹æ³•çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒLumiGaussè¿˜å¯ä»¥ä¸ºæœªè§è¿‡çš„ç¯å¢ƒåœ°å›¾åˆæˆé€¼çœŸçš„å›¾åƒã€‚æˆ‘ä»¬çš„ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/joaxkal/lumigauss%E3%80%82">https://github.com/joaxkal/lumigaussã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.04474v2">PDF</a> Accepted at WACV2025</p>
<p><strong>Summary</strong><br>å…‰ç…§ä¸å‡ ä½•çš„è§£è€¦æ˜¯ä¸€é¡¹æŒ‘æˆ˜æ€§ä»»åŠ¡ï¼Œæ¶‰åŠå¤§é‡å¤æ‚çš„3Då»ºæ¨¡å·¥ä½œã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆå¸¸ä¼šå½±å“è¾“å‡ºçš„çœŸå®æ„Ÿï¼Œå½±å“äº†å®é™…åº”ç”¨æ•ˆæœã€‚æœ¬ç ”ç©¶æ¨å‡ºLumiGaussæŠ€æœ¯ï¼Œå€ŸåŠ©äºŒç»´é«˜æ–¯ç»†åˆ†è§£å†³ä¸‰ç»´åœºæ™¯çš„é‡å»ºå’Œç…§æ˜é—®é¢˜ã€‚ä¸ä»…èƒ½é‡æ„é«˜è´¨é‡åœºæ™¯ï¼Œè¿˜èƒ½åœ¨å…¨æ–°ç¯å¢ƒä¸‹ç”ŸæˆçœŸå®ç…§æ˜ç¯å¢ƒåœ°å›¾ã€‚åŒæ—¶ï¼Œè¯¥æŠ€æœ¯è¿˜èƒ½ä¼˜åŒ–æˆ·å¤–åœºæ™¯ä¸­çš„é˜´å½±è´¨é‡ï¼Œåˆ©ç”¨çƒé¢è°æ³¢å±æ€§æå‡æ•ˆæœã€‚è¯¥æŠ€æœ¯æ˜“äºä¸æ¸¸æˆå¼•æ“é›†æˆï¼Œæ”¯æŒå¿«é€Ÿé¢„è®¡ç®—è¾å°„åº¦è½¬ç§»ã€‚åœ¨NeRF-OSRæ•°æ®é›†ä¸Šçš„éªŒè¯æ˜¾ç¤ºå…¶æ€§èƒ½ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œè¿˜èƒ½åˆæˆæœªè§ç¯å¢ƒåœ°å›¾çš„çœŸå®å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LumiGaussæŠ€æœ¯èƒ½å¤Ÿå®ç°å…‰ç…§ä¸å‡ ä½•è§£è€¦çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œç…§æ˜åˆæˆã€‚</li>
<li>é€šè¿‡äºŒç»´é«˜æ–¯ç»†åˆ†å®ç°é«˜è´¨é‡åœºæ™¯é‡æ„åŠçœŸå®æ„Ÿç…§æ˜åˆæˆã€‚</li>
<li>åˆ©ç”¨çƒé¢è°æ³¢å±æ€§ä¼˜åŒ–æˆ·å¤–åœºæ™¯çš„é˜´å½±è´¨é‡ã€‚</li>
<li>æŠ€æœ¯æ˜“äºä¸æ¸¸æˆå¼•æ“é›†æˆï¼Œæ”¯æŒå¿«é€Ÿé¢„è®¡ç®—è¾å°„åº¦è½¬ç§»ã€‚</li>
<li>åœ¨NeRF-OSRæ•°æ®é›†ä¸Šçš„éªŒè¯è¯æ˜äº†å…¶æ€§èƒ½ä¼˜è¶Šæ€§ã€‚</li>
<li>LumiGaussèƒ½åˆæˆæœªè§ç¯å¢ƒåœ°å›¾çš„çœŸå®å›¾åƒã€‚</li>
<li>è¯¥æŠ€æœ¯å¯¹äºç®€åŒ–å¤æ‚3Dèµ„äº§åˆ›å»ºè¿‡ç¨‹å…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-37590b752e9fedcb8e80fd96ed87b71a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c4d8519a5831263c1fa14dcbd21ace15.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-183b4b1f5584c92e19ac89e20b636209.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c879dedaed1b93cbf266f97635060f35.jpg" align="middle">
</details>




<h2 id="CRiM-GS-Continuous-Rigid-Motion-Aware-Gaussian-Splatting-from-Motion-Blurred-Images"><a href="#CRiM-GS-Continuous-Rigid-Motion-Aware-Gaussian-Splatting-from-Motion-Blurred-Images" class="headerlink" title="CRiM-GS: Continuous Rigid Motion-Aware Gaussian Splatting from   Motion-Blurred Images"></a>CRiM-GS: Continuous Rigid Motion-Aware Gaussian Splatting from   Motion-Blurred Images</h2><p><strong>Authors:Jungho Lee, Donghyeong Kim, Dogyoon Lee, Suhwan Cho, Minhyeok Lee, Sangyoun Lee</strong></p>
<p>3D Gaussian Splatting (3DGS) has gained significant attention for their high-quality novel view rendering, motivating research to address real-world challenges. A critical issue is the camera motion blur caused by movement during exposure, which hinders accurate 3D scene reconstruction. In this study, we propose CRiM-GS, a \textbf{C}ontinuous \textbf{Ri}gid \textbf{M}otion-aware \textbf{G}aussian \textbf{S}platting that reconstructs precise 3D scenes from motion-blurred images while maintaining real-time rendering speed. Considering the complex motion patterns inherent in real-world camera movements, we predict continuous camera trajectories using neural ordinary differential equations (ODE). To ensure accurate modeling, we employ rigid body transformations with proper regularization, preserving object shape and size. Additionally, we introduce an adaptive distortion-aware transformation to compensate for potential nonlinear distortions, such as rolling shutter effects, and unpredictable camera movements. By revisiting fundamental camera theory and leveraging advanced neural training techniques, we achieve precise modeling of continuous camera trajectories. Extensive experiments demonstrate state-of-the-art performance both quantitatively and qualitatively on benchmark datasets. </p>
<blockquote>
<p>ä¸‰ç»´é«˜æ–¯æ··åˆ·æŠ€æœ¯ï¼ˆ3DGSï¼‰å› å…¶é«˜è´¨é‡çš„æ–°è§†è§’æ¸²æŸ“è€Œå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œè¿™æ¿€å‘äº†è§£å†³ç°å®ä¸–ç•ŒæŒ‘æˆ˜çš„ç ”ç©¶åŠ¨åŠ›ã€‚ä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯æ›å…‰è¿‡ç¨‹ä¸­è¿åŠ¨å¼•èµ·çš„ç›¸æœºè¿åŠ¨æ¨¡ç³Šï¼Œè¿™é˜»ç¢äº†å‡†ç¡®çš„3Dåœºæ™¯é‡å»ºã€‚æœ¬ç ”ç©¶æå‡ºäº†CRiM-GSï¼Œä¸€ç§è¿ç»­åˆšä½“è¿åŠ¨æ„ŸçŸ¥é«˜æ–¯æ··åˆ·æŠ€æœ¯ï¼ˆGaussian Splattingï¼‰ï¼Œèƒ½å¤Ÿä»è¿åŠ¨æ¨¡ç³Šå›¾åƒé‡å»ºç²¾ç¡®çš„3Dåœºæ™¯ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚è€ƒè™‘åˆ°çœŸå®ä¸–ç•Œç›¸æœºè¿åŠ¨æ‰€å›ºæœ‰çš„å¤æ‚è¿åŠ¨æ¨¡å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰é¢„æµ‹è¿ç»­çš„ç›¸æœºè½¨è¿¹ã€‚ä¸ºäº†ç¡®ä¿å‡†ç¡®å»ºæ¨¡ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆšä½“å˜æ¢å’Œé€‚å½“çš„æ­£åˆ™åŒ–ï¼Œä¿æŒç‰©ä½“å½¢çŠ¶å’Œå¤§å°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥è‡ªé€‚åº”ç•¸å˜æ„ŸçŸ¥å˜æ¢ï¼Œä»¥è¡¥å¿æ½œåœ¨çš„éçº¿æ€§ç•¸å˜ï¼Œå¦‚æ»šé™æ•ˆåº”å’Œä¸å¯é¢„æµ‹çš„ç›¸æœºè¿åŠ¨ã€‚é€šè¿‡é‡æ¸©åŸºæœ¬ç›¸æœºç†è®ºå¹¶åˆ©ç”¨å…ˆè¿›çš„ç¥ç»è®­ç»ƒæŠ€æœ¯ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹è¿ç»­ç›¸æœºè½¨è¿¹çš„ç²¾ç¡®å»ºæ¨¡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šï¼Œæ— è®ºåœ¨æ•°é‡ä¸Šè¿˜æ˜¯è´¨é‡ä¸Šï¼Œæˆ‘ä»¬çš„æ€§èƒ½å‡è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.03923v2">PDF</a> Project Page : <a target="_blank" rel="noopener" href="https://jho-yonsei.github.io/CRiM-Gaussian/">https://jho-yonsei.github.io/CRiM-Gaussian/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ç ”ç©¶äº†åŸºäºä¸‰ç»´é«˜æ–¯æç”»ï¼ˆ3DGSï¼‰æŠ€æœ¯çš„è¿åŠ¨æ¨¡ç³Šå›¾åƒä¸‹çš„ä¸‰ç»´åœºæ™¯é‡å»ºæ–¹æ³•ã€‚é’ˆå¯¹ç›¸æœºè¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œæå‡ºä¸€ç§è¿ç»­åˆšæ€§è¿åŠ¨æ„ŸçŸ¥çš„é«˜æ–¯æç”»æ–¹æ³•ï¼ˆCRiM-GSï¼‰ï¼Œèƒ½åœ¨ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦çš„åŒæ—¶ï¼Œä»è¿åŠ¨æ¨¡ç³Šå›¾åƒä¸­ç²¾ç¡®é‡å»ºä¸‰ç»´åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSåœ¨æ–°å‹è§†å›¾æ¸²æŸ“æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œå¼•å‘äº†å¯¹ç°å®æŒ‘æˆ˜çš„ç ”ç©¶ã€‚</li>
<li>ç›¸æœºè¿åŠ¨æ¨¡ç³Šæ˜¯é˜»ç¢å‡†ç¡®ä¸‰ç»´åœºæ™¯é‡å»ºçš„å…³é”®å› ç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•CRiM-GSï¼Œèƒ½å¤Ÿä»è¿åŠ¨æ¨¡ç³Šçš„å›¾åƒä¸­é‡å»ºç²¾ç¡®çš„ä¸‰ç»´åœºæ™¯ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>åˆ©ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹é¢„æµ‹è¿ç»­çš„ç›¸æœºè½¨è¿¹ï¼Œä»¥åº”å¯¹ç°å®ä¸–ç•Œä¸­çš„å¤æ‚è¿åŠ¨æ¨¡å¼ã€‚</li>
<li>é‡‡ç”¨åˆšä½“å˜æ¢å’Œé€‚å½“çš„æ­£åˆ™åŒ–ï¼Œç¡®ä¿ç²¾ç¡®å»ºæ¨¡ï¼ŒåŒæ—¶ä¿æŒç‰©ä½“å½¢çŠ¶å’Œå¤§å°ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”ç•¸å˜æ„ŸçŸ¥å˜æ¢ï¼Œä»¥è¡¥å¿æ½œåœ¨çš„éçº¿æ€§ç•¸å˜ï¼Œå¦‚æ»šåŠ¨å¿«é—¨æ•ˆåº”å’Œä¸å¯é¢„æµ‹çš„ç›¸æœºè¿åŠ¨ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-b1335c1a28681785146e29918b8290a7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9594d5fb1b8f3e164f7c86460704b527.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-d85127156df10818d3f1eebfeb0a318b.jpg" align="middle">
</details>




<h2 id="HumanSplat-Generalizable-Single-Image-Human-Gaussian-Splatting-with-Structure-Priors"><a href="#HumanSplat-Generalizable-Single-Image-Human-Gaussian-Splatting-with-Structure-Priors" class="headerlink" title="HumanSplat: Generalizable Single-Image Human Gaussian Splatting with   Structure Priors"></a>HumanSplat: Generalizable Single-Image Human Gaussian Splatting with   Structure Priors</h2><p><strong>Authors:Panwang Pan, Zhuo Su, Chenguo Lin, Zhen Fan, Yongjie Zhang, Zeming Li, Tingting Shen, Yadong Mu, Yebin Liu</strong></p>
<p>Despite recent advancements in high-fidelity human reconstruction techniques, the requirements for densely captured images or time-consuming per-instance optimization significantly hinder their applications in broader scenarios. To tackle these issues, we present HumanSplat which predicts the 3D Gaussian Splatting properties of any human from a single input image in a generalizable manner. In particular, HumanSplat comprises a 2D multi-view diffusion model and a latent reconstruction transformer with human structure priors that adeptly integrate geometric priors and semantic features within a unified framework. A hierarchical loss that incorporates human semantic information is further designed to achieve high-fidelity texture modeling and better constrain the estimated multiple views. Comprehensive experiments on standard benchmarks and in-the-wild images demonstrate that HumanSplat surpasses existing state-of-the-art methods in achieving photorealistic novel-view synthesis. </p>
<blockquote>
<p>å°½ç®¡æœ€è¿‘é«˜ä¿çœŸäººç±»é‡å»ºæŠ€æœ¯æœ‰æ‰€è¿›å±•ï¼Œä½†å¯¹å¯†é›†æ•è·å›¾åƒæˆ–è€—æ—¶çš„é€å®ä¾‹ä¼˜åŒ–çš„è¦æ±‚ä»ç„¶æå¤§åœ°é˜»ç¢äº†å®ƒä»¬åœ¨æ›´å¹¿æ³›åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†HumanSplatï¼Œå®ƒä»¥é€šç”¨æ–¹å¼é¢„æµ‹ä»»ä½•äººç±»çš„3Dé«˜æ–¯å±•å¼€å±æ€§ï¼Œä»…ä»å•å¼ è¾“å…¥å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚ç‰¹åˆ«çš„æ˜¯ï¼ŒHumanSplatåŒ…æ‹¬ä¸€ä¸ª2Då¤šè§†è§’æ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªå…·æœ‰äººä½“ç»“æ„å…ˆéªŒçš„æ½œåœ¨é‡å»ºè½¬æ¢å™¨ï¼Œè¯¥è½¬æ¢å™¨å·§å¦™åœ°åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…æ•´åˆå‡ ä½•å…ˆéªŒå’Œè¯­ä¹‰ç‰¹å¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥å®ç°é«˜ä¿çœŸçº¹ç†å»ºæ¨¡å¹¶æ›´å¥½åœ°çº¦æŸä¼°è®¡çš„å¤šè§†è§’ï¼Œè®¾è®¡äº†åŒ…å«äººä½“è¯­ä¹‰ä¿¡æ¯çš„åˆ†å±‚æŸå¤±ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•å’Œé‡ç”Ÿå›¾åƒä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒHumanSplatåœ¨è¾¾åˆ°é«˜åº¦é€¼çœŸçš„æ–°è§†è§’åˆæˆæ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.12459v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºHumanSplatçš„æ–¹æ³•ï¼Œå¯ä»¥ä»å•ä¸€è¾“å…¥å›¾åƒé¢„æµ‹ä»»ä½•äººçš„3Dé«˜æ–¯å–·æº…å±æ€§ï¼Œå¹¶ä»¥é€šç”¨æ–¹å¼å®ç°ã€‚è¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´å¤šè§†è§’æ‰©æ•£æ¨¡å‹å’Œå…·æœ‰äººç±»ç»“æ„å…ˆéªŒçš„æ½œåœ¨é‡å»ºè½¬æ¢å™¨ï¼Œåœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…å·§å¦™åœ°èåˆäº†å‡ ä½•å…ˆéªŒå’Œè¯­ä¹‰ç‰¹å¾ã€‚è®¾è®¡äº†ä¸€ç§åˆ†å±‚æŸå¤±å‡½æ•°ï¼Œä»¥ç»“åˆäººç±»è¯­ä¹‰ä¿¡æ¯ï¼Œå®ç°é«˜ä¿çœŸçº¹ç†å»ºæ¨¡ï¼Œå¹¶æ›´å¥½åœ°çº¦æŸä¼°è®¡çš„å¤šè§†è§’ã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•å’ŒçœŸå®ä¸–ç•Œå›¾åƒä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒHumanSplatåœ¨è¾¾åˆ°é€¼çœŸçš„æ–°è§†è§’åˆæˆæ–¹é¢è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HumanSplatè§£å†³äº†é«˜ä¿çœŸäººç±»é‡å»ºæŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬éœ€è¦å¯†é›†é‡‡é›†çš„å›¾åƒæˆ–è€—æ—¶çš„é€å®ä¾‹ä¼˜åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„åº”ç”¨åœºæ™¯ä¸­ä½¿ç”¨ã€‚</li>
<li>HumanSplatä»å•ä¸€è¾“å…¥å›¾åƒé¢„æµ‹3Dé«˜æ–¯å–·æº…å±æ€§å¹¶å®ç°äº†ä¸€èˆ¬åŒ–ã€‚</li>
<li>æ–¹æ³•ç»“åˆäº†äºŒç»´å¤šè§†è§’æ‰©æ•£æ¨¡å‹å’Œå…·æœ‰äººç±»ç»“æ„å…ˆéªŒçš„æ½œåœ¨é‡å»ºè½¬æ¢å™¨ã€‚</li>
<li>HumanSplatå·§å¦™åœ°åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…èåˆå‡ ä½•å…ˆéªŒå’Œè¯­ä¹‰ç‰¹å¾ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ç»“åˆäººç±»è¯­ä¹‰ä¿¡æ¯çš„åˆ†å±‚æŸå¤±å‡½æ•°ï¼Œä»¥å®ç°é«˜ä¿çœŸçº¹ç†å»ºæ¨¡å’Œæ›´å¥½çš„å¤šè§†è§’ä¼°è®¡çº¦æŸã€‚</li>
<li>åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•å’ŒçœŸå®ä¸–ç•Œå›¾åƒä¸Šçš„ç»¼åˆå®éªŒéªŒè¯äº†HumanSplatçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b5152eedaf8cb1fcb810f1271efbd89c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-6fa723f04e633d36ddd50c5abaca7115.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-059579561c3075563ac5e47f5992cd7a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-73de2b61d7ba67b3c6eaf273f905501b.jpg" align="middle">
</details>




<h2 id="Effective-Rank-Analysis-and-Regularization-for-Enhanced-3D-Gaussian-Splatting"><a href="#Effective-Rank-Analysis-and-Regularization-for-Enhanced-3D-Gaussian-Splatting" class="headerlink" title="Effective Rank Analysis and Regularization for Enhanced 3D Gaussian   Splatting"></a>Effective Rank Analysis and Regularization for Enhanced 3D Gaussian   Splatting</h2><p><strong>Authors:Junha Hyung, Susung Hong, Sungwon Hwang, Jaeseong Lee, Jaegul Choo, Jin-Hwa Kim</strong></p>
<p>3D reconstruction from multi-view images is one of the fundamental challenges in computer vision and graphics. Recently, 3D Gaussian Splatting (3DGS) has emerged as a promising technique capable of real-time rendering with high-quality 3D reconstruction. This method utilizes 3D Gaussian representation and tile-based splatting techniques, bypassing the expensive neural field querying. Despite its potential, 3DGS encounters challenges such as needle-like artifacts, suboptimal geometries, and inaccurate normals caused by the Gaussians converging into anisotropic shapes with one dominant variance. We propose using the effective rank analysis to examine the shape statistics of 3D Gaussian primitives, and identify the Gaussians indeed converge into needle-like shapes with the effective rank 1. To address this, we introduce the effective rank as a regularization, which constrains the structure of the Gaussians. Our new regularization method enhances normal and geometry reconstruction while reducing needle-like artifacts. The approach can be integrated as an add-on module to other 3DGS variants, improving their quality without compromising visual fidelity. The project page is available at <a target="_blank" rel="noopener" href="https://junhahyung.github.io/erankgs.github.io">https://junhahyung.github.io/erankgs.github.io</a>. </p>
<blockquote>
<p>ä»å¤šè§†è§’å›¾åƒè¿›è¡Œ3Dé‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„åŸºæœ¬æŒ‘æˆ˜ä¹‹ä¸€ã€‚è¿‘æœŸï¼Œ3Dé«˜æ–¯å±•é“ºï¼ˆ3DGSï¼‰ä½œä¸ºä¸€ç§å…·æœ‰å®æ—¶æ¸²æŸ“èƒ½åŠ›çš„æ½œåŠ›æŠ€æœ¯å¤‡å—å…³æ³¨ï¼Œå¹¶å¯å®ç°é«˜è´¨é‡çš„3Dé‡å»ºã€‚è¯¥æ–¹æ³•åˆ©ç”¨3Dé«˜æ–¯è¡¨ç¤ºå’ŒåŸºäºç“¦ç‰‡çš„å±•é“ºæŠ€æœ¯ï¼Œé¿å…äº†æ˜‚è´µçš„ç¥ç»ç½‘ç»œæŸ¥è¯¢ã€‚å°½ç®¡æ½œåŠ›å·¨å¤§ï¼Œä½†3DGSé¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚é’ˆçŠ¶ä¼ªå½±ã€å‡ ä½•å½¢çŠ¶ä¸ä½³ä»¥åŠç”±äºé«˜æ–¯æ”¶æ•›ä¸ºå…·æœ‰ä¸€ä¸ªä¸»å¯¼æ–¹å·®å„å‘å¼‚æ€§å½¢çŠ¶æ‰€å¯¼è‡´çš„æ³•çº¿ä¸å‡†ç¡®ç­‰é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºä½¿ç”¨æœ‰æ•ˆç§©åˆ†ææ¥æ£€æŸ¥3Dé«˜æ–¯åŸå§‹å½¢çŠ¶ç»Ÿè®¡æ•°æ®ï¼Œå¹¶å‘ç°é«˜æ–¯ç¡®å®ä¼šæ”¶æ•›æˆå…·æœ‰æœ‰æ•ˆç§©1çš„é’ˆçŠ¶å½¢çŠ¶ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å°†æœ‰æ•ˆç§©ä½œä¸ºæ­£åˆ™åŒ–æ–¹æ³•åŠ ä»¥ä»‹ç»ï¼Œçº¦æŸé«˜æ–¯ç»“æ„ã€‚æˆ‘ä»¬çš„æ–°æ­£åˆ™åŒ–æ–¹æ³•æé«˜äº†æ³•çº¿å’Œå‡ ä½•é‡å»ºæ•ˆæœï¼ŒåŒæ—¶å‡å°‘äº†é’ˆçŠ¶ä¼ªå½±ã€‚è¯¥æ–¹æ³•å¯ä»¥ä½œä¸ºå…¶ä»–3DGSå˜ä½“çš„é™„åŠ æ¨¡å—è¿›è¡Œé›†æˆï¼Œåœ¨æé«˜è´¨é‡çš„åŒæ—¶ä¸ä¼šæŸå®³è§†è§‰ä¿çœŸåº¦ã€‚é¡¹ç›®é¡µé¢ä½äº<a target="_blank" rel="noopener" href="https://junhahyung.github.io/erankgs.github.io%E3%80%82">https://junhahyung.github.io/erankgs.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.11672v3">PDF</a> project page: <a target="_blank" rel="noopener" href="https://junhahyung.github.io/erankgs.github.io">https://junhahyung.github.io/erankgs.github.io</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå¤šè§†è§’å›¾åƒçš„å®æ—¶é«˜è´¨é‡ä¸‰ç»´é‡å»ºæŠ€æœ¯ä¸­çš„ä¸€é¡¹æ–°å…´æŠ€æœ¯â€”â€”ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼ˆ3DGSï¼‰ã€‚é€šè¿‡é‡‡ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºå’ŒåŸºäºç“¦ç‰‡çš„å–·ç»˜æŠ€æœ¯ï¼Œé¿å…äº†æ˜‚è´µçš„ç¥ç»ç½‘ç»œæŸ¥è¯¢è¿‡ç¨‹ã€‚æœ¬æ–‡åˆ†æäº†ä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“çš„å½¢çŠ¶ç»Ÿè®¡é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨æœ‰æ•ˆç§©åˆ†ææ¥è§£å†³é«˜æ–¯å‡ ä½•åœ¨é‡æ„æ—¶å¯èƒ½å‡ºç°çš„å°–é”çŠ¶å½¢çŠ¶é—®é¢˜ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œå¼•å…¥æœ‰æ•ˆç§©ä½œä¸ºæ­£åˆ™åŒ–çº¦æŸï¼Œä»¥æé«˜å‡ ä½•å’Œæ³•çº¿é‡å»ºè´¨é‡ï¼ŒåŒæ—¶å‡å°‘å°–é”çŠ¶ä¼ªå½±ã€‚æ­¤æ–¹æ³•å¯ä½œä¸ºå…¶ä»–ä¸‰ç»´é‡å»ºæŠ€æœ¯çš„é™„åŠ æ¨¡å—é›†æˆï¼Œä»¥æé«˜è´¨é‡è€Œä¸æŸå¤±è§†è§‰ä¿çœŸåº¦ã€‚é¡¹ç›®é¡µé¢å·²å‘å¸ƒåœ¨ç›¸å…³ç½‘ç«™ä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæ˜¯ä¸€ç§æ–°å…´çš„ä¸‰ç»´é‡å»ºæŠ€æœ¯ï¼Œå¯å®ç°å®æ—¶é«˜è´¨é‡æ¸²æŸ“ã€‚</li>
<li>è¯¥æŠ€æœ¯åˆ©ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºå’Œç“¦ç‰‡å–·ç»˜æŠ€æœ¯ã€‚</li>
<li>3DGSé¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬é’ˆçŠ¶ä¼ªå½±ã€å‡ ä½•å½¢çŠ¶ä¸ä½³å’Œæ³•çº¿ä¸å‡†ç¡®ç­‰é—®é¢˜ã€‚</li>
<li>æœ‰æ•ˆç§©åˆ†æç”¨äºç ”ç©¶ä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“çš„å½¢çŠ¶ç»Ÿè®¡é—®é¢˜ã€‚</li>
<li>é«˜æ–¯å‡ ä½•åœ¨é‡æ„æ—¶å‘ˆç°å°–é”çŠ¶å½¢çŠ¶çš„é—®é¢˜å¯é€šè¿‡å¼•å…¥æœ‰æ•ˆç§©æ­£åˆ™åŒ–è§£å†³ã€‚</li>
<li>æœ‰æ•ˆç§©æ­£åˆ™åŒ–èƒ½æé«˜å‡ ä½•å’Œæ³•çº¿é‡å»ºè´¨é‡ï¼ŒåŒæ—¶å‡å°‘å°–é”çŠ¶ä¼ªå½±çš„å‡ºç°ã€‚</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-5fe34ab4eaf1e9f6594c095cda477651.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6f34a81c1731dee196543ce285fa7b85.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-61828f967499439eb14bde826b7dea3f.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-13caa14afff05ab27c0d7fc40f66c71f.jpg" align="middle">
</details>




<h2 id="DDGS-CT-Direction-Disentangled-Gaussian-Splatting-for-Realistic-Volume-Rendering"><a href="#DDGS-CT-Direction-Disentangled-Gaussian-Splatting-for-Realistic-Volume-Rendering" class="headerlink" title="DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume   Rendering"></a>DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume   Rendering</h2><p><strong>Authors:Zhongpai Gao, Benjamin Planche, Meng Zheng, Xiao Chen, Terrence Chen, Ziyan Wu</strong></p>
<p>Digitally reconstructed radiographs (DRRs) are simulated 2D X-ray images generated from 3D CT volumes, widely used in preoperative settings but limited in intraoperative applications due to computational bottlenecks, especially for accurate but heavy physics-based Monte Carlo methods. While analytical DRR renderers offer greater efficiency, they overlook anisotropic X-ray image formation phenomena, such as Compton scattering. We present a novel approach that marries realistic physics-inspired X-ray simulation with efficient, differentiable DRR generation using 3D Gaussian splatting (3DGS). Our direction-disentangled 3DGS (DDGS) method separates the radiosity contribution into isotropic and direction-dependent components, approximating complex anisotropic interactions without intricate runtime simulations. Additionally, we adapt the 3DGS initialization to account for tomography data properties, enhancing accuracy and efficiency. Our method outperforms state-of-the-art techniques in image accuracy. Furthermore, our DDGS shows promise for intraoperative applications and inverse problems such as pose registration, delivering superior registration accuracy and runtime performance compared to analytical DRR methods. </p>
<blockquote>
<p>æ•°å­—é‡å»ºæ”¾å°„å½±åƒï¼ˆDRRsï¼‰æ˜¯ä»ä¸‰ç»´CTä½“ç§¯ç”Ÿæˆçš„æ¨¡æ‹ŸäºŒç»´Xå°„çº¿å½±åƒï¼Œå¹¿æ³›åº”ç”¨äºæœ¯å‰ç¯å¢ƒï¼Œä½†ç”±äºè®¡ç®—ç“¶é¢ˆï¼Œç‰¹åˆ«æ˜¯åœ¨ç²¾ç¡®ä½†å¤æ‚çš„åŸºäºç‰©ç†çš„è’™ç‰¹å¡ç½—æ–¹æ³•æ–¹é¢ï¼Œåœ¨æœ¯ä¸­åº”ç”¨æœ‰é™ã€‚è™½ç„¶åˆ†æå‹DRRæ¸²æŸ“å™¨æä¾›äº†æ›´é«˜çš„æ•ˆç‡ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†å„å‘å¼‚æ€§çš„Xå°„çº¿å›¾åƒå½¢æˆç°è±¡ï¼Œå¦‚åº·æ™®é¡¿æ•£å°„ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œå®ƒå°†é€¼çœŸçš„å—ç‰©ç†å¯å‘çš„Xå°„çº¿ä»¿çœŸä¸é«˜æ•ˆã€å¯åŒºåˆ†çš„DRRç”Ÿæˆç›¸ç»“åˆï¼Œä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ï¼ˆ3DGSï¼‰ã€‚æˆ‘ä»¬çš„æ–¹å‘åˆ†ç¦»ä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ï¼ˆDDGSï¼‰æ–¹æ³•å°†æ”¾å°„è´¡çŒ®åˆ†ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ä¾èµ–æˆåˆ†ï¼Œåœ¨ä¸éœ€è¦å¤æ‚è¿è¡Œæ—¶ä»¿çœŸæƒ…å†µä¸‹è¿‘ä¼¼å¤æ‚çš„å„å‘å¼‚æ€§äº¤äº’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ ¹æ®æ–­å±‚æ‰«ææ•°æ®ç‰¹æ€§è°ƒæ•´3DGSåˆå§‹åŒ–ï¼Œä»¥æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒå‡†ç¡®æ€§æ–¹é¢ä¼˜äºæœ€æ–°æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„DDGSåœ¨æœ¯ä¸­åº”ç”¨å’Œåå‘é—®é¢˜ï¼ˆå¦‚å§¿åŠ¿æ³¨å†Œï¼‰æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸è§£æå‹DRRæ–¹æ³•ç›¸æ¯”ï¼Œå¯æä¾›æ›´é«˜çš„æ³¨å†Œå‡†ç¡®æ€§å’Œè¿è¡Œæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02518v2">PDF</a> Accepted by NeurIPS2024</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ•°å­—é‡å»ºæ”¾å°„å½±åƒï¼ˆDRRsï¼‰æŠ€æœ¯çš„åˆ›æ–°åº”ç”¨ï¼Œç ”ç©¶è€…æå‡ºä¸€ç§ç»“åˆç‰©ç†åŸç†ä¸é«˜æ•ˆå¯å¾®åˆ†çš„DRRç”ŸæˆæŠ€æœ¯çš„æ–°æ–¹æ³•ï¼Œä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ˜ å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰ã€‚æ­¤æ–¹æ³•é€šè¿‡å°†æ”¾å°„çº¿è´¡çŒ®åˆ†ä¸ºåŒå‘å’Œå®šå‘ç›¸å…³çš„æˆåˆ†ï¼Œç®€åŒ–äº†å¤æ‚çš„å¼‚æ„äº¤äº’è¿‡ç¨‹ï¼Œå¹¶ä¸”é€‚åº”æ–­å±‚æ‰«ææ•°æ®ç‰¹æ€§ï¼Œæé«˜ç²¾å‡†åº¦å’Œæ•ˆç‡ã€‚æ­¤æŠ€æœ¯ç›¸å¯¹äºç°æœ‰çš„å›¾åƒå¤„ç†æ–¹æ³•è¡¨ç°å‡ºæ›´é«˜çš„å›¾åƒå‡†ç¡®åº¦ï¼Œåœ¨æœ¯ä¸­åº”ç”¨å’Œåå‘é—®é¢˜ï¼ˆå¦‚å§¿æ€æ³¨å†Œï¼‰ä¸­å…·æœ‰è‰¯å¥½å‰æ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DRRsæ˜¯ä»ä¸‰ç»´CTä½“ç§¯ç”Ÿæˆçš„æ¨¡æ‹ŸäºŒç»´Xå°„çº¿å›¾åƒï¼Œå¹¿æ³›åº”ç”¨äºæœ¯å‰è®¾ç½®ã€‚</li>
<li>ç°æœ‰æŠ€æœ¯é¢ä¸´è®¡ç®—ç“¶é¢ˆï¼Œç‰¹åˆ«æ˜¯åœ¨æœ¯ä¸­åº”ç”¨å’Œç‰©ç†åŸºç¡€è’™ç‰¹å¡æ´›æ–¹æ³•ä¸­çš„é«˜ç²¾åº¦è®¡ç®—ã€‚</li>
<li>ä¼ ç»Ÿçš„DRRæ¸²æŸ“å™¨å¿½è§†äº†Xå°„çº¿å›¾åƒçš„å¼‚æ„ç°è±¡ï¼Œå¦‚åº·æ™®é¡¿æ•£å°„ã€‚</li>
<li>æ–°çš„æ–¹æ³•ç»“åˆäº†ç‰©ç†åŸç†çš„Xå°„çº¿æ¨¡æ‹Ÿå’Œé«˜æ•ˆçš„ã€å¯å¾®åˆ†çš„DRRç”ŸæˆæŠ€æœ¯ã€‚</li>
<li>ä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ˜ å°„æŠ€æœ¯ï¼ˆ3DGSï¼‰ï¼Œå°†æ”¾å°„çº¿è´¡çŒ®åˆ†ä¸ºåŒå‘å’Œå®šå‘ç›¸å…³çš„æˆåˆ†ï¼Œç®€åŒ–äº†å¤æ‚çš„è®¡ç®—è¿‡ç¨‹ã€‚</li>
<li>é€‚åº”æ–­å±‚æ‰«ææ•°æ®ç‰¹æ€§ï¼Œæé«˜ç²¾å‡†åº¦å’Œæ•ˆç‡ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-8a63aefe41b12cf774dad39344713166.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-107fc1bcea7e331e681b9f163de5ec22.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-43c08d71ca7404702f8277c07086f6d7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-7749305bd8a5ba3d0a222a758a12221e.jpg" align="middle">
</details>




<h2 id="OpenGaussian-Towards-Point-Level-3D-Gaussian-based-Open-Vocabulary-Understanding"><a href="#OpenGaussian-Towards-Point-Level-3D-Gaussian-based-Open-Vocabulary-Understanding" class="headerlink" title="OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary   Understanding"></a>OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary   Understanding</h2><p><strong>Authors:Yanmin Wu, Jiarui Meng, Haijie Li, Chenming Wu, Yahao Shi, Xinhua Cheng, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang, Jian Zhang</strong></p>
<p>This paper introduces OpenGaussian, a method based on 3D Gaussian Splatting (3DGS) capable of 3D point-level open vocabulary understanding. Our primary motivation stems from observing that existing 3DGS-based open vocabulary methods mainly focus on 2D pixel-level parsing. These methods struggle with 3D point-level tasks due to weak feature expressiveness and inaccurate 2D-3D feature associations. To ensure robust feature presentation and 3D point-level understanding, we first employ SAM masks without cross-frame associations to train instance features with 3D consistency. These features exhibit both intra-object consistency and inter-object distinction. Then, we propose a two-stage codebook to discretize these features from coarse to fine levels. At the coarse level, we consider the positional information of 3D points to achieve location-based clustering, which is then refined at the fine level. Finally, we introduce an instance-level 3D-2D feature association method that links 3D points to 2D masks, which are further associated with 2D CLIP features. Extensive experiments, including open vocabulary-based 3D object selection, 3D point cloud understanding, click-based 3D object selection, and ablation studies, demonstrate the effectiveness of our proposed method. The source code is available at our project page: <a target="_blank" rel="noopener" href="https://3d-aigc.github.io/OpenGaussian">https://3d-aigc.github.io/OpenGaussian</a> </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†OpenGaussianæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäº3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå®ç°3Dç‚¹çº§åˆ«çš„å¼€æ”¾è¯æ±‡ç†è§£ã€‚æˆ‘ä»¬çš„ä¸»è¦åŠ¨æœºæºäºè§‚å¯Ÿåˆ°ç°æœ‰çš„åŸºäº3DGSçš„å¼€æ”¾è¯æ±‡æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨2Dåƒç´ çº§åˆ«çš„è§£æä¸Šã€‚è¿™äº›æ–¹æ³•åœ¨3Dç‚¹çº§åˆ«ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼ŒåŸå› åœ¨äºç‰¹å¾è¡¨è¾¾è¾ƒå¼±ä»¥åŠ2D-3Dç‰¹å¾å…³è”ä¸å‡†ç¡®ã€‚ä¸ºäº†ç¡®ä¿ç¨³å¥çš„ç‰¹å¾è¡¨è¾¾å’Œ3Dç‚¹çº§åˆ«ç†è§£ï¼Œæˆ‘ä»¬é¦–å…ˆé‡‡ç”¨SAMæ©è†œè¿›è¡Œè®­ç»ƒï¼Œæ— éœ€è·¨å¸§å…³è”ï¼Œä»¥ç”Ÿæˆå…·æœ‰3Dä¸€è‡´æ€§çš„å®ä¾‹ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾åœ¨å†…éƒ¨å¯¹è±¡ä¹‹é—´è¡¨ç°å‡ºä¸€è‡´æ€§ï¼Œå¹¶åœ¨ä¸åŒå¯¹è±¡ä¹‹é—´æœ‰æ‰€åŒºåˆ†ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤çº§ç¼–ç ç°¿ï¼Œä»ç²—ç•¥åˆ°ç²¾ç»†å±‚æ¬¡ç¦»æ•£åŒ–è¿™äº›ç‰¹å¾ã€‚åœ¨ç²—ç•¥å±‚æ¬¡ä¸Šï¼Œæˆ‘ä»¬è€ƒè™‘3Dç‚¹çš„ä½ç½®ä¿¡æ¯æ¥å®ç°åŸºäºä½ç½®çš„èšç±»ï¼Œç„¶ååœ¨ç²¾ç»†å±‚æ¬¡ä¸Šè¿›è¡Œç»†åŒ–ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å®ä¾‹çº§åˆ«çš„3D-2Dç‰¹å¾å…³è”æ–¹æ³•ï¼Œå°†3Dç‚¹ä¸2Dæ©è†œç›¸å…³è”ï¼Œå¹¶è¿›ä¸€æ­¥ä¸2D CLIPç‰¹å¾ç›¸å…³è”ã€‚å¤§é‡å®éªŒåŒ…æ‹¬åŸºäºå¼€æ”¾è¯æ±‡è¡¨çš„3Då¯¹è±¡é€‰æ‹©ã€3Dç‚¹äº‘ç†è§£ã€åŸºäºç‚¹å‡»çš„3Då¯¹è±¡é€‰æ‹©ä»¥åŠæ¶ˆèç ”ç©¶ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚é¡¹ç›®æºä»£ç å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢è·å–ï¼š<a target="_blank" rel="noopener" href="https://3d-aigc.github.io/OpenGaussian">https://3d-aigc.github.io/OpenGaussian</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02058v2">PDF</a> NeurIPS2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ’å€¼ï¼ˆ3DGSï¼‰çš„OpenGaussianæ–¹æ³•ï¼Œå¯å®ç°3Dç‚¹çº§çš„å¼€æ”¾è¯æ±‡ç†è§£ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³ç°æœ‰3DGSå¼€æ”¾è¯æ±‡æ–¹æ³•ä¸»è¦ä¸“æ³¨äº2Dåƒç´ çº§è§£æçš„é—®é¢˜ï¼Œé¢ä¸´3Dç‚¹çº§ä»»åŠ¡æ—¶ç‰¹å¾è¡¨è¾¾è¾ƒå¼±ä»¥åŠ2D-3Dç‰¹å¾å…³è”ä¸å‡†ç¡®çš„é—®é¢˜ã€‚é€šè¿‡é‡‡ç”¨SAMæ©è†œè®­ç»ƒå®ä¾‹ç‰¹å¾ï¼Œå®ç°3Dä¸€è‡´æ€§ï¼Œæå‡ºä¸¤é˜¶æ®µä»£ç ç°¿å¯¹ç‰¹å¾è¿›è¡Œç¦»æ•£åŒ–ï¼Œå¹¶åœ¨ç²—åˆ°ç»†çº§åˆ«ä¸Šå®ç°ä½ç½®ä¿¡æ¯é©±åŠ¨èšç±»ã€‚æœ€åå¼•å…¥å®ä¾‹çº§çš„3D-2Dç‰¹å¾å…³è”æ–¹æ³•ï¼Œå°†3Dç‚¹ä¸2Dæ©è†œä»¥åŠCLIPç‰¹å¾å…³è”èµ·æ¥ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡çš„3Då¯¹è±¡é€‰æ‹©ã€3Dç‚¹äº‘ç†è§£ã€ç‚¹å‡»å¼3Då¯¹è±¡é€‰æ‹©ç­‰ä»»åŠ¡ä¸Šæ•ˆæœæ˜¾è‘—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OpenGaussianæ˜¯ä¸€ç§åŸºäº3DGSçš„å¼€æ”¾è¯æ±‡ç†è§£æ–¹æ³•ã€‚</li>
<li>ç°æœ‰åŸºäº3DGSçš„å¼€æ”¾è¯æ±‡æ–¹æ³•ä¸»è¦å…³æ³¨äº2Dåƒç´ çº§è§£æï¼Œéš¾ä»¥å¤„ç†å¤æ‚çš„3Dç‚¹çº§ä»»åŠ¡ã€‚</li>
<li>OpenGaussiané€šè¿‡SAMæ©è†œè®­ç»ƒå®ä¾‹ç‰¹å¾ä»¥å®ç°ç¨³å¥çš„ç‰¹å¾è¡¨è¾¾å’Œ3Dç‚¹çº§ç†è§£ã€‚</li>
<li>æå‡ºä¸¤é˜¶æ®µä»£ç ç°¿å¯¹ç‰¹å¾è¿›è¡Œç¦»æ•£åŒ–ï¼Œä»ç²—åˆ°ç»†çº§åˆ«è¿›è¡Œä½ç½®ä¿¡æ¯é©±åŠ¨èšç±»ã€‚</li>
<li>å¼•å…¥å®ä¾‹çº§çš„3D-2Dç‰¹å¾å…³è”æ–¹æ³•ï¼Œå®ç°è·¨ç»´åº¦çš„ä¿¡æ¯æ•´åˆã€‚</li>
<li>å®éªŒç»“æœè¯æ˜OpenGaussianåœ¨å¤šç§ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-03763943dd2330b2a8ebeb070fc26951.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-e2b4930a934a39f0fa1615b6c9fe609c.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-156984d4ba895cb35d5d6806f6c11e48.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-cbf2a672d55eb41aebc68cc9d472af0a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-07c07d9eff339201feabd488a80a6be6.jpg" align="middle">
</details>




<h2 id="EvaGaussians-Event-Stream-Assisted-Gaussian-Splatting-from-Blurry-Images"><a href="#EvaGaussians-Event-Stream-Assisted-Gaussian-Splatting-from-Blurry-Images" class="headerlink" title="EvaGaussians: Event Stream Assisted Gaussian Splatting from Blurry   Images"></a>EvaGaussians: Event Stream Assisted Gaussian Splatting from Blurry   Images</h2><p><strong>Authors:Wangbo Yu, Chaoran Feng, Jiye Tang, Jiashu Yang, Zhenyu Tang, Xu Jia, Yuchao Yang, Li Yuan, Yonghong Tian</strong></p>
<p>3D Gaussian Splatting (3D-GS) has demonstrated exceptional capabilities in 3D scene reconstruction and novel view synthesis. However, its training heavily depends on high-quality, sharp images and accurate camera poses. Fulfilling these requirements can be challenging in non-ideal real-world scenarios, where motion-blurred images are commonly encountered in high-speed moving cameras or low-light environments that require long exposure times. To address these challenges, we introduce Event Stream Assisted Gaussian Splatting (EvaGaussians), a novel approach that integrates event streams captured by an event camera to assist in reconstructing high-quality 3D-GS from blurry images. Capitalizing on the high temporal resolution and dynamic range offered by the event camera, we leverage the event streams to explicitly model the formation process of motion-blurred images and guide the deblurring reconstruction of 3D-GS. By jointly optimizing the 3D-GS parameters and recovering camera motion trajectories during the exposure time, our method can robustly facilitate the acquisition of high-fidelity novel views with intricate texture details. We comprehensively evaluated our method and compared it with previous state-of-the-art deblurring rendering methods. Both qualitative and quantitative comparisons demonstrate that our method surpasses existing techniques in restoring fine details from blurry images and producing high-fidelity novel views. </p>
<blockquote>
<p>3Dé«˜æ–¯Splattingï¼ˆ3D-GSï¼‰åœ¨3Dåœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…¶è®­ç»ƒä¸¥é‡ä¾èµ–äºé«˜è´¨é‡ã€æ¸…æ™°çš„å›¾åƒå’Œå‡†ç¡®çš„ç›¸æœºå§¿æ€ã€‚åœ¨éç†æƒ³çš„çœŸå®ä¸–ç•Œåœºæ™¯ä¸­ï¼Œæ»¡è¶³è¿™äº›è¦æ±‚å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºåœ¨é«˜é€Ÿè¿åŠ¨ç›¸æœºæˆ–ä½å…‰ç…§ç¯å¢ƒä¸­ç»å¸¸ä¼šé‡åˆ°è¿åŠ¨æ¨¡ç³Šå›¾åƒï¼Œè¿™äº›ç¯å¢ƒéœ€è¦é•¿æ—¶é—´æ›å…‰ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†äº‹ä»¶æµè¾…åŠ©é«˜æ–¯Splattingï¼ˆEvaGaussiansï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å°†äº‹ä»¶ç›¸æœºæ•è·çš„äº‹ä»¶æµé›†æˆåˆ°é‡å»ºé«˜è´¨é‡3D-GSä¸­çš„æ–°æ–¹æ³•ï¼Œä»¥ä»æ¨¡ç³Šå›¾åƒä¸­ååŠ©é‡å»ºã€‚åˆ©ç”¨äº‹ä»¶ç›¸æœºæä¾›çš„é«˜æ—¶é—´åˆ†è¾¨ç‡å’ŒåŠ¨æ€èŒƒå›´ï¼Œæˆ‘ä»¬å€ŸåŠ©äº‹ä»¶æµæ˜¾å¼å»ºæ¨¡è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„å½¢æˆè¿‡ç¨‹ï¼Œå¹¶å¼•å¯¼3D-GSçš„å»æ¨¡ç³Šé‡å»ºã€‚é€šè¿‡è”åˆä¼˜åŒ–3D-GSå‚æ•°å¹¶åœ¨æ›å…‰æ—¶é—´å†…æ¢å¤ç›¸æœºè¿åŠ¨è½¨è¿¹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç¨³å¥åœ°è·å–å…·æœ‰ç²¾ç»†çº¹ç†ç»†èŠ‚çš„é«˜ä¿çœŸæ–°é¢–è§†è§’ã€‚æˆ‘ä»¬å…¨é¢è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶ä¸ä¹‹å‰çš„æœ€æ–°å»æ¨¡ç³Šæ¸²æŸ“æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚å®šæ€§å’Œå®šé‡æ¯”è¾ƒå‡è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¢å¤æ¨¡ç³Šå›¾åƒä¸­çš„ç»†èŠ‚ä»¥åŠç”Ÿæˆé«˜ä¿çœŸæ–°é¢–è§†è§’æ–¹é¢è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.20224v3">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://www.falcary.com/EvaGaussians/">https://www.falcary.com/EvaGaussians/</a></p>
<p><strong>æ‘˜è¦</strong><br>    äº‹ä»¶æµè¾…åŠ©é«˜æ–¯è´´å›¾æŠ€æœ¯ï¼ˆEvaGaussiansï¼‰ç»“åˆäº†äº‹ä»¶ç›¸æœºæ•æ‰çš„äº‹ä»¶æµï¼Œç”¨äºä»æ¨¡ç³Šå›¾åƒé‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´é«˜æ–¯è´´å›¾ï¼ˆ3D-GSï¼‰ï¼Œè§£å†³äº†åœ¨é«˜é€Ÿç›¸æœºæˆ–ä½å…‰ç…§ç¯å¢ƒä¸‹è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„é—®é¢˜ã€‚å€ŸåŠ©äº‹ä»¶ç›¸æœºæä¾›çš„é«˜æ—¶é—´åˆ†è¾¨ç‡å’ŒåŠ¨æ€èŒƒå›´ï¼Œè¯¥æŠ€æœ¯æ˜¾å¼å»ºæ¨¡è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„å½¢æˆè¿‡ç¨‹ï¼Œå¼•å¯¼3D-GSå»æ¨¡ç³Šé‡å»ºã€‚é€šè¿‡è”åˆä¼˜åŒ–3D-GSå‚æ•°å’Œæ›å…‰æ—¶é—´å†…ç›¸æœºè¿åŠ¨è½¨è¿¹çš„æ¢å¤ï¼Œè¯¥æ–¹æ³•å¯ç¨³å¥åœ°è·å–å…·æœ‰ç²¾ç»†çº¹ç†ç»†èŠ‚çš„é«˜ä¿çœŸæ–°è§†è§’ã€‚ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œç›¸è¾ƒäºæœ€æ–°çš„å»æ¨¡ç³Šæ¸²æŸ“æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•åœ¨æ¢å¤æ¨¡ç³Šå›¾åƒç»†èŠ‚å’Œç”Ÿæˆé«˜ä¿çœŸæ–°è§†è§’æ–¹é¢æ›´èƒœä¸€ç­¹ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>Event Stream Assisted Gaussian Splatting (EvaGaussians) ç»“åˆäº†äº‹ä»¶ç›¸æœºæ•æ‰çš„äº‹ä»¶æµï¼Œç”¨äºè§£å†³éç†æƒ³ç°å®åœºæ™¯ä¸­çš„è¿åŠ¨æ¨¡ç³Šå’Œä½å…‰ç…§é—®é¢˜ã€‚</li>
<li>EvaGaussians åˆ©ç”¨äº‹ä»¶ç›¸æœºçš„é«˜æ—¶é—´åˆ†è¾¨ç‡å’ŒåŠ¨æ€èŒƒå›´ï¼Œæ˜¾å¼å»ºæ¨¡è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„å½¢æˆè¿‡ç¨‹ã€‚</li>
<li>EvaGaussians èƒ½å¤ŸæŒ‡å¯¼å»æ¨¡ç³Šé‡å»º3D-GSï¼Œé€šè¿‡è”åˆä¼˜åŒ–3D-GSå‚æ•°å’Œæ›å…‰æ—¶é—´å†…ç›¸æœºè¿åŠ¨è½¨è¿¹çš„æ¢å¤ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½ç¨³å¥åœ°è·å–é«˜ä¿çœŸæ–°è§†è§’ï¼Œå…·æœ‰ç²¾ç»†çº¹ç†ç»†èŠ‚ã€‚</li>
<li>EvaGaussians åœ¨æ¢å¤æ¨¡ç³Šå›¾åƒç»†èŠ‚æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å»æ¨¡ç³Šæ¸²æŸ“æŠ€æœ¯ã€‚</li>
<li>ç»¼åˆè¯„ä¼°è¯æ˜EvaGaussiansåœ¨ç”Ÿæˆé«˜ä¿çœŸå›¾åƒæ–¹é¢çš„ä¼˜åŠ¿ã€‚</li>
<li>EvaGaussians çš„åº”ç”¨å°†ä¿ƒè¿›3Dåœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„è´¨é‡æå‡ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-2a6dfeebc8af740b3ffbd36deda21ca7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-e93e06d8497678c387f3765916b5a4aa.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-030962cde277f5b7075f93ed3de54d39.jpg" align="middle">
</details>




<h2 id="Deepfake-for-the-Good-Generating-Avatars-through-Face-Swapping-with-Implicit-Deepfake-Generation"><a href="#Deepfake-for-the-Good-Generating-Avatars-through-Face-Swapping-with-Implicit-Deepfake-Generation" class="headerlink" title="Deepfake for the Good: Generating Avatars through Face-Swapping with   Implicit Deepfake Generation"></a>Deepfake for the Good: Generating Avatars through Face-Swapping with   Implicit Deepfake Generation</h2><p><strong>Authors:Georgii Stanishevskii, Jakub Steczkiewicz, Tomasz Szczepanik, SÅ‚awomir Tadeja, Jacek Tabor, PrzemysÅ‚aw Spurek</strong></p>
<p>Numerous emerging deep-learning techniques have had a substantial impact on computer graphics. Among the most promising breakthroughs are the rise of Neural Radiance Fields (NeRFs) and Gaussian Splatting (GS). NeRFs encode the objectâ€™s shape and color in neural network weights using a handful of images with known camera positions to generate novel views. In contrast, GS provides accelerated training and inference without a decrease in rendering quality by encoding the objectâ€™s characteristics in a collection of Gaussian distributions. These two techniques have found many use cases in spatial computing and other domains. On the other hand, the emergence of deepfake methods has sparked considerable controversy. Deepfakes refers to artificial intelligence-generated videos that closely mimic authentic footage. Using generative models, they can modify facial features, enabling the creation of altered identities or expressions that exhibit a remarkably realistic appearance to a real person. Despite these controversies, deepfake can offer a next-generation solution for avatar creation and gaming when of desirable quality. To that end, we show how to combine all these emerging technologies to obtain a more plausible outcome. Our ImplicitDeepfake uses the classical deepfake algorithm to modify all training images separately and then train NeRF and GS on modified faces. Such simple strategies can produce plausible 3D deepfake-based avatars. </p>
<blockquote>
<p>ä¼—å¤šæ–°å…´çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿå·¨å¤§å½±å“ã€‚å…¶ä¸­æœ€æœ‰å‰é€”çš„çªç ´ä¹‹ä¸€æ˜¯ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯å–·æ¶‚ï¼ˆGSï¼‰çš„å…´èµ·ã€‚NeRFä½¿ç”¨ç¥ç»ç½‘ç»œæƒé‡ç¼–ç å¯¹è±¡çš„å½¢çŠ¶å’Œé¢œè‰²ï¼Œåˆ©ç”¨å°‘é‡å·²çŸ¥ç›¸æœºä½ç½®çš„å›¾ç‰‡æ¥ç”Ÿæˆæ–°è§†è§’ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGSé€šè¿‡åœ¨ä¸€ç»„é«˜æ–¯åˆ†å¸ƒä¸­ç¼–ç å¯¹è±¡ç‰¹æ€§ï¼Œæä¾›äº†åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼ŒåŒæ—¶ä¸é™ä½æ¸²æŸ“è´¨é‡ã€‚è¿™ä¸¤ç§æŠ€æœ¯åœ¨ç©ºé—´è®¡ç®—å’Œå…¶ä»–é¢†åŸŸæ‰¾åˆ°äº†è®¸å¤šç”¨ä¾‹ã€‚å¦ä¸€æ–¹é¢ï¼Œæ·±åº¦ä¼ªé€ æ–¹æ³•çš„å‡ºç°å¼•èµ·äº†ç›¸å½“å¤§çš„äº‰è®®ã€‚æ·±åº¦ä¼ªé€ æ˜¯æŒ‡ä½¿ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆçš„è§†é¢‘ï¼Œè¿™äº›è§†é¢‘å¯†åˆ‡æ¨¡ä»¿çœŸå®é•œå¤´ã€‚ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¬å¯ä»¥ä¿®æ”¹é¢éƒ¨ç‰¹å¾ï¼Œèƒ½å¤Ÿåˆ›å»ºå‡ºå…·æœ‰æƒŠäººçœŸå®å¤–è§‚çš„æ›´æ”¹èº«ä»½æˆ–è¡¨æƒ…ï¼Œä¸çœŸå®äººç‰©éå¸¸ç›¸ä¼¼ã€‚å°½ç®¡å­˜åœ¨è¿™äº›äº‰è®®ï¼Œä½†æ·±åº¦ä¼ªé€ æŠ€æœ¯å¯ä»¥åœ¨è´¨é‡è¾¾æ ‡çš„æƒ…å†µä¸‹ä¸ºåŒ–èº«åˆ›å»ºå’Œæ¸¸æˆæä¾›ä¸‹ä¸€ä»£è§£å†³æ–¹æ¡ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ç»“åˆæ‰€æœ‰è¿™äº›æ–°å…´æŠ€æœ¯æ¥è·å¾—æ›´åˆç†çš„ç»“æœã€‚æˆ‘ä»¬çš„ImplicitDeepfakeä½¿ç”¨ç»å…¸çš„æ·±åº¦ä¼ªé€ ç®—æ³•åˆ†åˆ«ä¿®æ”¹æ‰€æœ‰è®­ç»ƒå›¾åƒï¼Œç„¶ååœ¨ä¿®æ”¹åçš„é¢éƒ¨ä¸Šè®­ç»ƒNeRFå’ŒGSã€‚è¿™ç§ç®€å•çš„ç­–ç•¥å¯ä»¥äº§ç”ŸåŸºäºæ·±åº¦ä¼ªé€ çš„åˆç†3DåŒ–èº«ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06390v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æ–°å…´æ·±åº¦å­¦ä¹ æŠ€æœ¯å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯æ¶‚å¸ƒï¼ˆGSï¼‰ç­‰çªç ´æŠ€æœ¯ä¸ºç©ºé—´è®¡ç®—ç­‰é¢†åŸŸå¸¦æ¥äº†è®¸å¤šç”¨ä¾‹ã€‚åŒæ—¶ï¼Œæ·±åº¦ä¼ªé€ æ–¹æ³•çš„å‡ºç°å¼•èµ·äº†å¹¿æ³›äº‰è®®ã€‚æ·±åº¦ä¼ªé€ æŒ‡çš„æ˜¯ä½¿ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆçš„è§†é¢‘ï¼Œèƒ½å¤Ÿæ¨¡ä»¿çœŸå®ç”»é¢ã€‚ç»“åˆå„ç§æ–°å…´æŠ€æœ¯ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ›´é€¼çœŸçš„ç»“æœã€‚æœ¬ç ”ç©¶ç»“åˆæ·±åº¦ä¼ªé€ ç®—æ³•ä¿®æ”¹æ‰€æœ‰è®­ç»ƒå›¾åƒï¼Œç„¶åå¯¹ä¿®æ”¹åçš„é¢éƒ¨è¿›è¡ŒNeRFå’ŒGSè®­ç»ƒï¼Œäº§ç”Ÿå¯ä¿¡çš„3Dæ·±åº¦ä¼ªé€ è™šæ‹Ÿå½¢è±¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æŠ€æœ¯å¯¹è®¡ç®—æœºå›¾å½¢äº§ç”Ÿé‡å¤§å½±å“ï¼Œå‡ºç°å¤šç§æ–°å…´æŠ€æœ¯å¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯æ¶‚å¸ƒï¼ˆGSï¼‰ã€‚</li>
<li>NeRFé€šè¿‡ç¼–ç å¯¹è±¡çš„å½¢çŠ¶å’Œé¢œè‰²åœ¨ç¥ç»ç½‘ç»œæƒé‡ä¸­ï¼Œä½¿ç”¨å·²çŸ¥ç›¸æœºä½ç½®çš„å›¾ç‰‡ç”Ÿæˆæ–°è§†è§’ã€‚</li>
<li>GSé€šè¿‡é«˜æ–¯åˆ†å¸ƒç¼–ç å¯¹è±¡ç‰¹æ€§ï¼Œæä¾›åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†ï¼ŒåŒæ—¶ä¸é™ä½æ¸²æŸ“è´¨é‡ã€‚</li>
<li>æ·±åº¦ä¼ªé€ æ–¹æ³•å¼•èµ·å¹¿æ³›äº‰è®®ï¼Œä½†å¯ä¸ºåŒ–èº«åˆ›å»ºå’Œæ¸¸æˆæä¾›ä¸‹ä¸€ä»£è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç»“åˆæ·±åº¦ä¼ªé€ ç®—æ³•ä¿®æ”¹è®­ç»ƒå›¾åƒï¼Œç„¶åä½¿ç”¨NeRFå’ŒGSè®­ç»ƒï¼Œå¯ä»¥äº§ç”Ÿæ›´é€¼çœŸçš„3Dæ·±åº¦ä¼ªé€ è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>æ·±åº¦ä¼ªé€ æŠ€æœ¯éœ€è¦è¿›ä¸€æ­¥æé«˜è´¨é‡ï¼Œä»¥å®ç°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-3aa0c5bd5d55fab6b3456408bcfa7ba8.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7c6dd62daeb59781f75d66815146fbb5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-59bdfd70e3985fd56be81d718f9a9c8e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a0eb9d0ad2fd4b43afa5f960c84523bf.jpg" align="middle">q
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-9e6dceac7784672ecd9f51fb468ecff5.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-89629fe07055252ace8bfce59c0bd9b0.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-10/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-10/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-10/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-aa0498f2de39d156ab924e917d63e25f.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  Dynamic EventNeRF Reconstructing General Dynamic Scenes from Multi-view   Event Cameras
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-10/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d460005db73d4069a7ca154e972bd229.jpg" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-11  UNet++ and LSTM combined approach for Breast Ultrasound Image   Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">7390.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
