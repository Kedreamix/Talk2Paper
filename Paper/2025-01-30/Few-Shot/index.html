<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-01-30  ASTRAL Automated Safety Testing of Large Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5fa120b9e84049a65fb0ecbf165d77ba.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    31 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-30-更新"><a href="#2025-01-30-更新" class="headerlink" title="2025-01-30 更新"></a>2025-01-30 更新</h1><h2 id="ASTRAL-Automated-Safety-Testing-of-Large-Language-Models"><a href="#ASTRAL-Automated-Safety-Testing-of-Large-Language-Models" class="headerlink" title="ASTRAL: Automated Safety Testing of Large Language Models"></a>ASTRAL: Automated Safety Testing of Large Language Models</h2><p><strong>Authors:Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura, Aitor Arrieta</strong></p>
<p>Large Language Models (LLMs) have recently gained attention due to their ability to understand and generate sophisticated human-like content. However, ensuring their safety is paramount as they might provide harmful and unsafe responses. Existing LLM testing frameworks address various safety-related concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due to unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool that automates the generation and execution of test cases (i.e., prompts) for testing the safety of LLMs. First, we introduce a novel black-box coverage criterion to generate balanced and diverse unsafe test inputs across a diverse set of safety categories as well as linguistic writing characteristics (i.e., different style and persuasive writing techniques). Second, we propose an LLM-based approach that leverages Retrieval Augmented Generation (RAG), few-shot prompting strategies and web browsing to generate up-to-date test inputs. Lastly, similar to current LLM test automation techniques, we leverage LLMs as test oracles to distinguish between safe and unsafe test outputs, allowing a fully automated testing approach. We conduct an extensive evaluation on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms other LLMs when acting as the test oracle, accurately detecting unsafe responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard); ii) the results confirm that our approach can uncover nearly twice as many unsafe LLM behaviors with the same number of test inputs compared to currently used static datasets; and iii) our black-box coverage criterion combined with web browsing can effectively guide the LLM on generating up-to-date unsafe test inputs, significantly increasing the number of unsafe LLM behaviors. </p>
<blockquote>
<p>大型语言模型（LLM）由于其能够理解和生成复杂的人类内容而受到关注。然而，确保它们的安全至关重要，因为它们可能会提供有害和不安全的回应。现有的LLM测试框架解决了各种与安全相关的问题（例如，毒品、恐怖主义、虐待动物），但由于数据集不平衡和过时，常常面临挑战。在本文中，我们介绍了ASTRAL，这是一个能够自动生成和执行测试用例（即提示）以测试LLM安全性的工具。首先，我们引入了一种新的黑盒覆盖标准，以生成在安全类别（如不同风格和说服性写作技巧）之间平衡和多样化的不安全测试输入。其次，我们提出了一种基于LLM的方法，利用检索增强生成（RAG）、少数提示策略和网页浏览来生成最新的测试输入。最后，与当前的LLM测试自动化技术类似，我们利用LLM作为测试裁决者来区分安全和不安全的测试输出，从而实现全自动化测试方法。我们对知名的LLM进行了广泛评估，揭示了以下关键发现：i）GPT3.5在作为测试裁决者时表现出比其他LLM更优越的性能，能够准确检测不安全的响应，甚至超越更新近的LLM（例如GPT-4），以及专门用于检测不安全LLM输出的LLM（如LlamaGuard）；ii）结果证实，我们的方法可以覆盖近两倍的不安全LLM行为，与使用相同数量的测试输入相比静态数据集；iii）我们的黑盒覆盖标准与网页浏览相结合，可以有效地指导LLM生成最新的不安全测试输入，从而显著增加不安全LLM的行为数量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17132v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大规模语言模型（LLMs）能够理解和生成复杂的人类内容，受到广泛关注。然而，确保其安全性至关重要，因为它们可能会提供有害和不安全的回应。现有LLM测试框架解决了各种安全相关问题，但仍面临不平衡和过时数据集的挑战。本文介绍了一种名为ASTRAL的工具，它可以自动生成并执行测试用例以测试LLMs的安全性。首先，我们提出了一种新颖的黑盒覆盖标准来生成平衡和多样化的不安全测试输入，涵盖多种安全类别和语言写作特征。其次，我们提出了一种基于LLM的方法，利用检索增强生成（RAG）、少镜头提示策略和网页浏览来生成最新的测试输入。最后，我们利用LLMs作为测试仲裁者来区分安全和不安全测试输出，从而实现全自动测试方法。对知名LLMs的广泛评估揭示了以下关键发现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ASTRAL工具通过自动生成并执行测试用例来测试LLMs的安全性，解决了现有测试框架面临的不平衡和过时数据集的问题。</li>
<li>引入黑盒覆盖标准来生成平衡和多样化的不安全测试输入，涵盖多种安全类别和语言特征。</li>
<li>利用LLM结合检索增强生成（RAG）和少镜头提示策略生成最新测试输入。</li>
<li>GPT3.5作为测试仲裁者表现优异，能准确检测不安全回应，甚至超越GPT-4等更新模型以及针对不安全LLM输出的检测工具LlamaGuard。</li>
<li>结果表明，与现有静态数据集相比，使用相同数量的测试输入时，该方法可以检测到近两倍的不安全LLM行为。</li>
<li>结合黑盒覆盖标准和网页浏览可有效引导LLM生成最新的不安全测试输入，显著提高检测到的不安全LLM行为数量。</li>
<li>该方法具有广泛的应用前景，可应用于评估LLM在各种场景中的安全性表现。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17132">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-29fa02cefc7f75ebc626dbfba6e65645.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e07c92b16d3fcadaf743adb3b983fa5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a08f83fbb790fbfef40ad1d571c48811.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d5e143ff8ffca310fe82b5370838561.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-967bfcbea5d409e6170012c3c4f625e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55f9820b5115adf94a5fb44976de7aad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fb8b2c68404f8a034adbed1db73948f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Few-Edges-Are-Enough-Few-Shot-Network-Attack-Detection-with-Graph-Neural-Networks"><a href="#Few-Edges-Are-Enough-Few-Shot-Network-Attack-Detection-with-Graph-Neural-Networks" class="headerlink" title="Few Edges Are Enough: Few-Shot Network Attack Detection with Graph   Neural Networks"></a>Few Edges Are Enough: Few-Shot Network Attack Detection with Graph   Neural Networks</h2><p><strong>Authors:Tristan Bilot, Nour El Madhoun, Khaldoun Al Agha, Anis Zouaoui</strong></p>
<p>Detecting cyberattacks using Graph Neural Networks (GNNs) has seen promising results recently. Most of the state-of-the-art models that leverage these techniques require labeled examples, hard to obtain in many real-world scenarios. To address this issue, unsupervised learning and Self-Supervised Learning (SSL) have emerged as interesting approaches to reduce the dependency on labeled data. Nonetheless, these methods tend to yield more anomalous detection algorithms rather than effective attack detection systems. This paper introduces Few Edges Are Enough (FEAE), a GNN-based architecture trained with SSL and Few-Shot Learning (FSL) to better distinguish between false positive anomalies and actual attacks. To maximize the potential of few-shot examples, our model employs a hybrid self-supervised objective that combines the advantages of contrastive-based and reconstruction-based SSL. By leveraging only a minimal number of labeled attack events, represented as attack edges, FEAE achieves competitive performance on two well-known network datasets compared to both supervised and unsupervised methods. Remarkably, our experimental results unveil that employing only 1 malicious event for each attack type in the dataset is sufficient to achieve substantial improvements. FEAE not only outperforms self-supervised GNN baselines but also surpasses some supervised approaches on one of the datasets. </p>
<blockquote>
<p>使用图神经网络（GNNs）检测网络攻击最近取得了令人鼓舞的结果。大多数利用这些技术的最先进的模型都需要有标签的示例，这在许多真实场景中很难获得。为了解决这一问题，无监督学习和自监督学习（SSL）作为减少对有标签数据依赖的有趣方法而出现。然而，这些方法更倾向于产生异常检测算法，而不是有效的攻击检测系统。本文介绍了FEAE（少数边缘已足够），这是一种基于图神经网络的架构，采用自监督学习和小样本学习（FSL）进行训练，以更好地区分假阳性异常值和实际攻击。为了最大化小样本示例的潜力，我们的模型采用了一种混合自监督目标，结合了基于对比和基于重建的SSL的优点。通过利用只有少数标记的攻击事件（表示为攻击边缘），FEAE在两个著名的网络数据集上的性能表现具有竞争力，与监督和无监督方法相比均有不俗表现。值得一提的是，我们的实验结果表明，在数据集中每种攻击类型只使用1个恶意事件就足以实现重大改进。FEAE不仅超越了自监督GNN基线，而且在其中一个数据集上甚至超过了某些监督方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16964v1">PDF</a> This is the version of the author, accepted for publication at IWSEC   2024. Published version available at   <a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-981-97-7737-2_15">https://link.springer.com/chapter/10.1007/978-981-97-7737-2_15</a></p>
<p><strong>Summary</strong></p>
<p>基于图神经网络（GNNs）的网络安全攻击检测方法已经取得显著的成果。现有的高级模型主要依赖于标记数据，在真实环境中很难获得。针对此问题，研究者提出了无监督学习和自监督学习（SSL）方法，以减少对标记数据的依赖，但倾向于产生异常检测算法而非有效的攻击检测系统。本文介绍了一种基于SSL和少量学习（FSL）的GNN架构FEAE，通过最小化标注攻击事件的数目，FEAE可以区分出误报异常和实际攻击事件。该架构使用结合了对比和重建的混合自监督目标来提高有限示例的性能。通过在两个知名网络数据集上进行实验，FEAE在性能上超过了监督和无监督方法。特别地，实验结果显示只需每个攻击类型使用一次恶意事件就能实现显著的提升。FEAE不仅超越了自监督的GNN基线，还在其中一个数据集上超越了某些监督方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GNNs在网络安全攻击检测中展现出良好效果。</li>
<li>当前模型对标记数据高度依赖，真实环境中获取困难。</li>
<li>无监督学习和SSL方法被提出以解决对标记数据的依赖问题。</li>
<li>这些方法主要产生异常检测算法，而非高效的攻击检测系统。</li>
<li>FEAE架构结合SSL和少量学习（FSL），以提高对有限样本的学习性能。</li>
<li>FEAE使用混合自监督目标，结合了对比和重建方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16964">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-59938545c87ac8b00c8993d482817ab5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ddb9453a80ea33940be8662804e21f9.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="One-Head-Eight-Arms-Block-Matrix-based-Low-Rank-Adaptation-for-CLIP-based-Few-Shot-Learning"><a href="#One-Head-Eight-Arms-Block-Matrix-based-Low-Rank-Adaptation-for-CLIP-based-Few-Shot-Learning" class="headerlink" title="One Head Eight Arms: Block Matrix based Low Rank Adaptation for   CLIP-based Few-Shot Learning"></a>One Head Eight Arms: Block Matrix based Low Rank Adaptation for   CLIP-based Few-Shot Learning</h2><p><strong>Authors:Chunpeng Zhou, Qianqian Shen, Zhi Yu, Jiajun Bu, Haishuai Wang</strong></p>
<p>Recent advancements in fine-tuning Vision-Language Foundation Models (VLMs) have garnered significant attention for their effectiveness in downstream few-shot learning tasks.While these recent approaches exhibits some performance improvements, they often suffer from excessive training parameters and high computational costs. To address these challenges, we propose a novel Block matrix-based low-rank adaptation framework, called Block-LoRA, for fine-tuning VLMs on downstream few-shot tasks. Inspired by recent work on Low-Rank Adaptation (LoRA), Block-LoRA partitions the original low-rank decomposition matrix of LoRA into a series of sub-matrices while sharing all down-projection sub-matrices. This structure not only reduces the number of training parameters, but also transforms certain complex matrix multiplication operations into simpler matrix addition, significantly lowering the computational cost of fine-tuning. Notably, Block-LoRA enables fine-tuning CLIP on the ImageNet few-shot benchmark using a single 24GB GPU. We also show that Block-LoRA has the more tighter bound of generalization error than vanilla LoRA. Without bells and whistles, extensive experiments demonstrate that Block-LoRA achieves competitive performance compared to state-of-the-art CLIP-based few-shot methods, while maintaining a low training parameters count and reduced computational overhead. </p>
<blockquote>
<p>最近，对视觉语言基础模型（VLMs）进行微调方面的最新进展已引起人们对其在下游小样本学习任务中有效性的广泛关注。虽然这些最新方法表现出了一些性能改进，但它们通常存在训练参数过多和计算成本过高的缺点。为了解决这些挑战，我们提出了一种基于块矩阵的低秩自适应框架，称为Block-LoRA，用于在下游小样本任务上对VLMs进行微调。Block-LoRA受到最近低秩适应（LoRA）工作的启发，它将LoRA的原始低秩分解矩阵划分为一系列子矩阵，同时共享所有下投影子矩阵。这种结构不仅减少了训练参数的数量，而且将某些复杂的矩阵乘法运算转换为更简单的矩阵加法，从而显著降低了微调的计算成本。值得注意的是，Block-LoRA能够在使用单个24GB GPU的情况下，对ImageNet小样本基准测试进行CLIP微调。我们还表明，Block-LoRA具有比传统LoRA更严格的一般化误差界限。没有额外的修饰，大量实验证明，Block-LoRA与基于CLIP的小样本方法相比具有竞争力，同时保持较低的训练参数数量和减少的计算开销。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16720v1">PDF</a> Under Review</p>
<p><strong>Summary</strong></p>
<p>近期对视觉语言基础模型（VLMs）的微调技术取得了显著进展，这引起了人们对下游少样本学习任务的关注。尽管这些方法表现出了一定的性能提升，但它们常常面临训练参数过多和计算成本高昂的问题。为解决这些挑战，我们提出了一种基于块矩阵的低秩适应框架——Block-LoRA，用于在下游少样本任务上微调VLMs。Block-LoRA通过引入块矩阵分解减少训练参数数量，并简化了复杂矩阵乘法运算，从而降低了计算成本。实验表明，Block-LoRA在ImageNet少样本基准测试上实现了有竞争力的性能表现，并具有更低的训练参数和计算开销。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>近期对视觉语言基础模型的微调技术取得了进展，引起了对少样本学习任务的关注。</li>
<li>现有方法面临训练参数过多和计算成本高昂的挑战。</li>
<li>提出了一种基于块矩阵的低秩适应框架——Block-LoRA，用于微调VLMs。</li>
<li>Block-LoRA通过块矩阵分解减少训练参数数量，并简化计算。</li>
<li>Block-LoRA在ImageNet少样本基准测试上表现有竞争力。</li>
<li>Block-LoRA具有更低的训练参数和计算开销。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16720">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-b2d77a1c39cfe47826f13fa95e64d6d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fa120b9e84049a65fb0ecbf165d77ba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53256fba9ba1ba9993795e3943ee689b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dad77940065aaf2f761338d6f35f63d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d9a281214cd598e704e57dcc2c383f70.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Auto-Differentiating-Any-LLM-Workflow-A-Farewell-to-Manual-Prompting"><a href="#Auto-Differentiating-Any-LLM-Workflow-A-Farewell-to-Manual-Prompting" class="headerlink" title="Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting"></a>Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting</h2><p><strong>Authors:Li Yin, Zhangyang Wang</strong></p>
<p>Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows. Yet, prompt engineering – the task of crafting textual inputs to effectively direct LLMs – remains difficult and labor-intensive, particularly for complex pipelines that combine multiple LLM calls with functional operations like retrieval and data formatting. We introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods (such as Text-Grad) to multi-component, potentially cyclic LLM architectures. Implemented within the AdalFlow library, LLM-AutoDiff treats each textual input as a trainable parameter and uses a frozen backward engine LLM to generate feedback-akin to textual gradients – that guide iterative prompt updates. Unlike prior single-node approaches, LLM-AutoDiff inherently accommodates functional nodes, preserves time-sequential behavior in repeated calls (e.g., multi-hop loops), and combats the “lost-in-the-middle” problem by isolating distinct sub-prompts (instructions, formats, or few-shot examples). It further boosts training efficiency by focusing on error-prone samples through selective gradient computation. Across diverse tasks, including single-step classification, multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff consistently outperforms existing textual gradient baselines in both accuracy and training cost. By unifying prompt optimization through a graph-centric lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows - mirroring the transformative role that automatic differentiation libraries have long played in neural network research. </p>
<blockquote>
<p>大型语言模型（LLM）已经重塑了自然语言处理领域，推动了从多跳检索和问答到自主代理工作流程的各种应用。然而，提示工程——即设计文本输入以有效指导LLM的任务——仍然很困难且劳动密集型，特别是对于结合多个LLM调用与检索和数据格式化等功能的复杂管道。我们推出了LLM-AutoDiff：一种用于自动提示工程（APE）的新型框架，它将基于文本的梯度方法（如Text-Grad）扩展到多组件、可能循环的LLM架构。LLM-AutoDiff在AdalFlow库中实现，它将每个文本输入视为可训练参数，并使用冻结的向后引擎LLM生成反馈来指导迭代提示更新，类似于文本梯度。不同于先前的单点方法，LLM-AutoDiff天然适应功能节点，在重复调用中保持时间顺序行为（例如，多跳循环），并通过隔离不同的子提示（指令、格式或少量示例）来解决“迷失在中间”的问题。它通过选择性梯度计算来重点关注易出错样本，进一步提高训练效率。在包括单步分类、多跳检索问答和代理驱动管道等各种任务中，LLM-AutoDiff在准确率和训练成本方面均优于现有的文本梯度基线。通过以图为中心的视角统一提示优化，LLM-AutoDiff为扩展和自动化LLM工作流程提供了强大的新范式，这与自动微分库在神经网络研究中长期发挥的变革性作用相呼应。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16673v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在自然语言处理领域的应用广泛，包括多跳检索、问答和自主代理工作流程等。然而，提示工程（即有效指导LLM的文本输入制作任务）仍然困难且劳动密集，特别是在结合多个LLM调用与功能操作（如检索和数据格式化）的复杂管道中。我们推出LLM-AutoDiff，一种用于自动提示工程（APE）的新型框架，它将文本梯度方法扩展到多组件、潜在循环的LLM架构。LLM-AutoDiff将每个文本输入视为可训练参数，并使用冻结的逆向引擎LLM生成反馈，以指导迭代提示更新。它不同于先前的单点方法，天然适应功能节点，保持重复调用中的时间顺序行为（如多跳循环），并通过隔离不同子提示（指令、格式或少量示例）来解决“迷失在中间”的问题。通过选择性梯度计算专注于易出错样本，提高训练效率。在包括单步分类、多跳检索问答和代理驱动管道等多样化任务中，LLM-AutoDiff在准确性和训练成本方面均优于现有文本梯度基线。通过统一的图形中心视角整合提示优化，LLM-AutoDiff为扩展和自动化LLM工作流程提供了强大的新范式。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM在自然语言处理领域的应用广泛，但提示工程仍然是一个挑战。</li>
<li>LLM-AutoDiff是一个用于自动提示工程的框架，适用于多组件和潜在循环的LLM架构。</li>
<li>LLM-AutoDiff将文本输入视为可训练参数，并使用冻结的逆向引擎LLM生成反馈。</li>
<li>与先前的单点方法不同，LLM-AutoDiff适应功能节点，并保持时间顺序行为。</li>
<li>LLM-AutoDiff通过隔离子提示解决“迷失在中间”的问题，并提高训练效率。</li>
<li>LLM-AutoDiff在多样任务中表现优异，包括单步分类、多跳检索问答和代理驱动管道。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16673">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b17905e9ddc1e63e78afe7082541cf3b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b90a33388bdce658415dec2ca0dd0ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e60c07482456b902449b3b87815f595e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="How-well-can-LLMs-Grade-Essays-in-Arabic"><a href="#How-well-can-LLMs-Grade-Essays-in-Arabic" class="headerlink" title="How well can LLMs Grade Essays in Arabic?"></a>How well can LLMs Grade Essays in Arabic?</h2><p><strong>Authors:Rayed Ghazawi, Edwin Simpson</strong></p>
<p>This research assesses the effectiveness of state-of-the-art large language models (LLMs), including ChatGPT, Llama, Aya, Jais, and ACEGPT, in the task of Arabic automated essay scoring (AES) using the AR-AES dataset. It explores various evaluation methodologies, including zero-shot, few-shot in-context learning, and fine-tuning, and examines the influence of instruction-following capabilities through the inclusion of marking guidelines within the prompts. A mixed-language prompting strategy, integrating English prompts with Arabic content, was implemented to improve model comprehension and performance. Among the models tested, ACEGPT demonstrated the strongest performance across the dataset, achieving a Quadratic Weighted Kappa (QWK) of 0.67, but was outperformed by a smaller BERT-based model with a QWK of 0.88. The study identifies challenges faced by LLMs in processing Arabic, including tokenization complexities and higher computational demands. Performance variation across different courses underscores the need for adaptive models capable of handling diverse assessment formats and highlights the positive impact of effective prompt engineering on improving LLM outputs. To the best of our knowledge, this study is the first to empirically evaluate the performance of multiple generative Large Language Models (LLMs) on Arabic essays using authentic student data. </p>
<blockquote>
<p>本文研究了当前先进的大型语言模型（LLM），包括ChatGPT、Llama、Aya、Jais和ACEGPT，在阿拉伯自动作文评分（AES）任务中使用AR-AES数据集的有效性。它探索了各种评估方法，包括零样本、少样本上下文学习和微调，并通过提示中包含的标记指南研究了指令遵循能力的影响。实施了一种混合语言提示策略，将英语提示与阿拉伯内容相结合，以提高模型的理解力和性能。在测试的模型中，ACEGPT在整个数据集上表现最强，达到0.67的二次加权kappa（QWK），但被一个较小的基于BERT的模型以0.88的QWK超越。该研究确定了LLM在处理阿拉伯语时面临的挑战，包括分词复杂性和更高的计算需求。不同课程之间的性能差异强调了需要能够适应各种评估格式的模型，并突出了有效提示工程对改善LLM输出的积极影响。据我们所知，这项研究是首次实证评估多个生成式大型语言模型（LLM）在阿拉伯作文上的表现，使用了真实的学生数据。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16516v1">PDF</a> 18 pages</p>
<p><strong>Summary</strong></p>
<p>该研究发现评估了包括ChatGPT、Llama、Aya、Jais和ACEGPT在内的当前先进技术的大型语言模型在阿拉伯自动作文评分任务中的有效性。该研究使用了AR-AES数据集，探讨了零样本、少样本上下文学习和微调等评估方法，并考察了模型遵循指令能力的影响。通过混合语言提示策略（整合英语提示和阿拉伯内容），提高了模型的理解和性能。在测试中，ACEGPT在数据集上表现最佳，二次加权κ值达到0.67，但仍被基于BERT的小型模型超越，后者二次加权κ值为0.88。该研究指出了大型语言模型在处理阿拉伯语时面临的挑战，包括令牌化复杂性和更高的计算需求。不同课程之间的性能变化强调了需要能够适应不同评估格式的模型，并突出了有效提示工程对改善大型语言模型输出的积极影响。据我们所知，这是首次使用真实学生数据实证评估多个生成式大型语言模型在阿拉伯作文上的表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在阿拉伯自动作文评分任务中的有效性得到评估。</li>
<li>多种评估方法，包括零样本、少样本上下文学习和微调被探讨。</li>
<li>ACEGPT在数据集上表现良好，但仍有提升空间。</li>
<li>混合语言提示策略提高了模型的理解和性能。</li>
<li>基于BERT的小型模型在某些评估指标上超越了大型语言模型。</li>
<li>大型语言模型在处理阿拉伯语时面临挑战，如令牌化复杂性和高计算需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16516">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7f14a2355ef85317f72089f361f1342b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7676e14ce6b092ee81c5345893ac2401.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c32e43bea40dd0bb1615f1f2346251a8.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Closed-Form-Feedback-Free-Learning-with-Forward-Projection"><a href="#Closed-Form-Feedback-Free-Learning-with-Forward-Projection" class="headerlink" title="Closed-Form Feedback-Free Learning with Forward Projection"></a>Closed-Form Feedback-Free Learning with Forward Projection</h2><p><strong>Authors:Robert O’Shea, Bipin Rajendran</strong></p>
<p>State-of-the-art methods for backpropagation-free learning employ local error feedback to direct iterative optimisation via gradient descent. In this study, we examine the more restrictive setting where retrograde communication from neuronal outputs is unavailable for pre-synaptic weight optimisation. To address this challenge, we propose Forward Projection (FP). This novel randomised closed-form training method requires only a single forward pass over the entire dataset for model fitting, without retrograde communication. Target values for pre-activation membrane potentials are generated layer-wise via nonlinear projections of pre-synaptic inputs and the labels. Local loss functions are optimised over pre-synaptic inputs using closed-form regression, without feedback from neuronal outputs or downstream layers. Interpretability is a key advantage of FP training; membrane potentials of hidden neurons in FP-trained networks encode information which is interpretable layer-wise as label predictions. We demonstrate the effectiveness of FP across four biomedical datasets. In few-shot learning tasks, FP yielded more generalisable models than those optimised via backpropagation. In large-sample tasks, FP-based models achieve generalisation comparable to gradient descent-based local learning methods while requiring only a single forward propagation step, achieving significant speed up for training. Interpretation functions defined on local neuronal activity in FP-based models successfully identified clinically salient features for diagnosis in two biomedical datasets. Forward Projection is a computationally efficient machine learning approach that yields interpretable neural network models without retrograde communication of neuronal activity during training. </p>
<blockquote>
<p>当前最先进的无反向传播学习方法采用局部误差反馈来指导通过梯度下降法的迭代优化过程。在这项研究中，我们探讨了更严格的设置环境，即当神经元输出的逆向通信无法用于突触前权重优化时的情况。为了应对这一挑战，我们提出了“前向投影”（FP）方法。这种新型随机闭合形式的训练方法仅需对整个数据集进行一次前向传递即可完成模型拟合，无需逆向通信。目标值通过突触前输入的非线性投影和标签逐层生成。局部损失函数通过闭合形式的回归对突触前输入进行优化，无需神经元输出或下游层的反馈。可解释性是FP训练的关键优势；FP训练后的网络中隐藏神经元的膜电位编码的信息可以按层解读为标签预测。我们在四个生物医学数据集上展示了FP的有效性。在少量样本学习任务中，FP产生的模型比通过反向传播优化的模型更具泛化能力。在大样本任务中，FP模型的泛化能力与基于梯度下降的局部学习方法相当，但仅需进行一次前向传播步骤，大大加快了训练速度。在FP模型上定义的解读函数成功识别了两个生物医学数据集中用于诊断的临床重要特征。前向投影是一种计算效率高的机器学习方法，可在训练过程中无需神经元活动的逆向通信，生成可解释的神经网络模型。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16476v1">PDF</a> 26 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种名为Forward Projection（FP）的新型随机闭式训练方法，该方法在无需逆向神经元输出进行预突触权重优化的限制条件下，仅通过单次前向传播即可完成模型拟合。FP通过逐层生成目标预激活膜电位值，并利用闭式回归对预突触输入进行局部损失函数优化，无需神经元输出的反馈或下游层级的信息。FP训练的优势在于其解释性，隐藏层神经元的膜电位编码的信息在逐层上可解读为标签预测。在四个生物医学数据集上，FP在少样本学习任务中表现出更高的模型泛化能力，在大样本任务中其泛化能力与基于梯度下降的地方学习方法相当，但只需进行一次前向传播，实现了训练速度的显著加速。此外，基于FP模型的解释函数能够成功识别两个生物医学数据集中的临床显著特征，为诊断提供帮助。总体而言，Forward Projection是一种计算高效的机器学习方式，能够在训练过程中无需神经元活动的逆向通信，生成可解释性强的神经网络模型。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Forward Projection (FP) 是一种新型的随机闭式训练方法，仅需单次前向传播即可完成模型拟合，无需逆向通信。</li>
<li>FP通过逐层生成目标预激活膜电位值，利用闭式回归优化局部损失函数。</li>
<li>FP提高模型解释性，隐藏层神经元的膜电位编码的信息可解读为标签预测。</li>
<li>在少样本学习任务中，FP表现出更高的模型泛化能力。</li>
<li>在大样本任务中，FP的泛化能力与基于梯度下降的方法相当，但训练速度更快。</li>
<li>基于FP模型的解释函数能识别临床显著特征，有助于诊断。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16476">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c81923e1f3f5aea52272062c7d34aed7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-176557c0fdc1219d9279aa5a41eba60a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="In-Context-Learning-on-a-Budget-A-Case-Study-in-Token-Classification"><a href="#In-Context-Learning-on-a-Budget-A-Case-Study-in-Token-Classification" class="headerlink" title="In-Context Learning on a Budget: A Case Study in Token Classification"></a>In-Context Learning on a Budget: A Case Study in Token Classification</h2><p><strong>Authors:Uri Berger, Tal Baumel, Gabriel Stanovsky</strong></p>
<p>Few shot in-context learning (ICL) typically assumes access to large annotated training sets. However, in many real world scenarios, such as domain adaptation, there is only a limited budget to annotate a small number of samples, with the goal of maximizing downstream performance. We study various methods for selecting samples to annotate within a predefined budget, focusing on token classification tasks, which are expensive to annotate and are relatively less studied in ICL setups. Across various tasks, models, and datasets, we observe that no method significantly outperforms the others, with most yielding similar results, including random sample selection for annotation. Moreover, we demonstrate that a relatively small annotated sample pool can achieve performance comparable to using the entire training set. We hope that future work adopts our realistic paradigm which takes annotation budget into account. </p>
<blockquote>
<p>少样本上下文学习（ICL）通常假设可以访问大型注释训练集。然而，在许多现实世界场景中，如域适应，注释样本的预算有限，目标是最大化下游性能。我们研究了在预定预算内选择样本进行注释的各种方法，重点关注令牌分类任务，这些任务注释成本高昂，在ICL设置中相对研究较少。在各种任务、模型和数据集上，我们观察到没有一种方法显著优于其他方法，大多数方法的结果相似，包括随机样本选择进行注释。此外，我们证明了一个相对较小的注释样本池可以实现与使用整个训练集相当的性能。我们希望未来的工作能采用我们考虑注释预算的现实主义范式。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13274v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>在有限的标注预算下，针对token分类任务，研究不同的样本标注选择方法对于提高下游性能至关重要。本研究发现不同方法和模型在标注样本选择上表现相似，即使是随机选择也有较好结果。少量标注样本即可达到与使用整个训练集相近的性能。建议未来研究考虑标注预算的现实情况。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究关注于在有限的标注预算下，如何选择样本进行标注，以最大化下游性能。</li>
<li>针对token分类任务，这些任务在标注时成本较高，在ICL设置中的研究相对较少。</li>
<li>研究发现不同标注样本选择方法表现相似，包括随机样本选择。</li>
<li>即使使用相对较小的标注样本池，也可以实现与使用整个训练集相当的性能。</li>
<li>未来的研究应该考虑标注预算的现实情况，以更贴近实际应用场景。</li>
<li>此研究对于如何在资源有限的情况下优化模型性能提供了有价值的见解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.13274">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-af0cb1a786d589bf8607251ce6ea4fdb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9a7064a34225a30eb5c4bc40ccd06ded.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-95ff516aad929ade3ee29650aff0b6b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5258dc6c4d0a716f680456d971c6a98.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-77eec650234f37b302d62056705d07f0.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer 方向最新论文已更新，请持续关注 Update in 2025-01-30  Modulating CNN Features with Pre-Trained ViT Representations for   Open-Vocabulary Object Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-14a8fc0ae1779698a021c0d0ec26cf3e.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-01-30  Revisit Mixture Models for Multi-Agent Simulation Experimental Study   within a Unified Framework
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">24417.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
