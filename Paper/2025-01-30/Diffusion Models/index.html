<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-30  CubeDiff Repurposing Diffusion-Based Image Models for Panorama   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fdf0db8b8061d6603296201be49b6811.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    33 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-30-æ›´æ–°"><a href="#2025-01-30-æ›´æ–°" class="headerlink" title="2025-01-30 æ›´æ–°"></a>2025-01-30 æ›´æ–°</h1><h2 id="CubeDiff-Repurposing-Diffusion-Based-Image-Models-for-Panorama-Generation"><a href="#CubeDiff-Repurposing-Diffusion-Based-Image-Models-for-Panorama-Generation" class="headerlink" title="CubeDiff: Repurposing Diffusion-Based Image Models for Panorama   Generation"></a>CubeDiff: Repurposing Diffusion-Based Image Models for Panorama   Generation</h2><p><strong>Authors:Nikolai Kalischek, Michael Oechsle, Fabian Manhardt, Philipp Henzler, Konrad Schindler, Federico Tombari</strong></p>
<p>We introduce a novel method for generating 360{\deg} panoramas from text prompts or images. Our approach leverages recent advances in 3D generation by employing multi-view diffusion models to jointly synthesize the six faces of a cubemap. Unlike previous methods that rely on processing equirectangular projections or autoregressive generation, our method treats each face as a standard perspective image, simplifying the generation process and enabling the use of existing multi-view diffusion models. We demonstrate that these models can be adapted to produce high-quality cubemaps without requiring correspondence-aware attention layers. Our model allows for fine-grained text control, generates high resolution panorama images and generalizes well beyond its training set, whilst achieving state-of-the-art results, both qualitatively and quantitatively. Project page: <a target="_blank" rel="noopener" href="https://cubediff.github.io/">https://cubediff.github.io/</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ä»æ–‡å­—æç¤ºæˆ–å›¾åƒç”Ÿæˆ360Â°å…¨æ™¯çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨3Dç”Ÿæˆçš„æœ€æ–°è¿›å±•ï¼Œé‡‡ç”¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹è”åˆåˆæˆç«‹æ–¹ä½“è´´å›¾çš„å…­ä¸ªé¢ã€‚ä¸ä»¥å¾€ä¾èµ–äºå¤„ç†ç­‰è·æŠ•å½±æˆ–è‡ªå›å½’ç”Ÿæˆçš„æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†æ¯é¢è§†ä¸ºæ ‡å‡†é€è§†å›¾åƒï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶ä½¿å¾—ç°æœ‰å¤šè§†è§’æ‰©æ•£æ¨¡å‹çš„ä½¿ç”¨æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥é€‚åº”äº§ç”Ÿé«˜è´¨é‡çš„ç«‹æ–¹ä½“è´´å›¾ï¼Œè€Œæ— éœ€å¯¹åº”æ„ŸçŸ¥æ³¨æ„åŠ›å±‚ã€‚æˆ‘ä»¬çš„æ¨¡å‹å…è®¸ç²¾ç»†çš„æ–‡æœ¬æ§åˆ¶ï¼Œç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„å…¨æ™¯å›¾åƒï¼Œå¹¶ä¸”åœ¨è®­ç»ƒé›†ä¹‹å¤–ä¹Ÿèƒ½å¾ˆå¥½åœ°æ¨å¹¿ï¼ŒåŒæ—¶åœ¨å®šæ€§å’Œå®šé‡ä¸Šè¾¾åˆ°æœ€æ–°æ°´å¹³çš„ç»“æœã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://cubediff.github.io/">https://cubediff.github.io/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17162v1">PDF</a> Accepted at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ä»æ–‡æœ¬æç¤ºæˆ–å›¾åƒç”Ÿæˆ360Â°å…¨æ™¯å›¾çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æœ€æ–°çš„3Dç”ŸæˆæŠ€æœ¯ï¼Œé€šè¿‡é‡‡ç”¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹è”åˆåˆæˆç«‹æ–¹ä½“è´´å›¾çš„å…­ä¸ªé¢ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–ç­‰è·æŠ•å½±æˆ–è‡ªå›å½’ç”Ÿæˆçš„æ–¹æ³•ï¼Œæœ¬æ–‡æ–¹æ³•å°†æ¯ä¸ªé¢è§†ä¸ºæ ‡å‡†é€è§†å›¾åƒï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶å…è®¸ä½¿ç”¨ç°æœ‰çš„å¤šè§†è§’æ‰©æ•£æ¨¡å‹ã€‚å®éªŒè¯æ˜ï¼Œè¿™äº›æ¨¡å‹å¯é€‚åº”äº§ç”Ÿé«˜è´¨é‡ç«‹æ–¹ä½“è´´å›¾ï¼Œæ— éœ€å¯¹åº”æ„ŸçŸ¥æ³¨æ„åŠ›å±‚ã€‚è¯¥æ–¹æ³•å…·æœ‰ç²¾ç»†çš„æ–‡æœ¬æ§åˆ¶åŠŸèƒ½ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å…¨æ™¯å›¾åƒï¼Œå¹¶åœ¨è®­ç»ƒé›†ä¹‹å¤–å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶è¾¾åˆ°å®šæ€§å’Œå®šé‡çš„æœ€ä½³ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§ç”Ÿæˆ360Â°å…¨æ™¯å›¾çš„æ–°æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨å¤šè§†è§’æ‰©æ•£æ¨¡å‹è”åˆåˆæˆç«‹æ–¹ä½“è´´å›¾çš„å…­ä¸ªé¢ã€‚</li>
<li>å°†æ¯ä¸ªé¢è§†ä¸ºæ ‡å‡†é€è§†å›¾åƒï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>æ–¹æ³•ä¸éœ€è¦å¯¹åº”æ„ŸçŸ¥æ³¨æ„åŠ›å±‚ï¼Œå³å¯äº§ç”Ÿé«˜è´¨é‡ç«‹æ–¹ä½“è´´å›¾ã€‚</li>
<li>å…·æœ‰ç²¾ç»†çš„æ–‡æœ¬æ§åˆ¶åŠŸèƒ½ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å…¨æ™¯å›¾åƒã€‚</li>
<li>åœ¨è®­ç»ƒé›†ä¹‹å¤–å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17162">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cd35aa05915bb6cfa4f8d148d2459519.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7959b3d92d204d5be1ee061fbb0fb5a5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="IC-Portrait-In-Context-Matching-for-View-Consistent-Personalized-Portrait"><a href="#IC-Portrait-In-Context-Matching-for-View-Consistent-Personalized-Portrait" class="headerlink" title="IC-Portrait: In-Context Matching for View-Consistent Personalized   Portrait"></a>IC-Portrait: In-Context Matching for View-Consistent Personalized   Portrait</h2><p><strong>Authors:Han Yang, Enis Simsar, Sotiris Anagnostidi, Yanlong Zang, Thomas Hofmann, Ziwei Liu</strong></p>
<p>Existing diffusion models show great potential for identity-preserving generation. However, personalized portrait generation remains challenging due to the diversity in user profiles, including variations in appearance and lighting conditions. To address these challenges, we propose IC-Portrait, a novel framework designed to accurately encode individual identities for personalized portrait generation. Our key insight is that pre-trained diffusion models are fast learners (e.g.,100 ~ 200 steps) for in-context dense correspondence matching, which motivates the two major designs of our IC-Portrait framework. Specifically, we reformulate portrait generation into two sub-tasks: 1) Lighting-Aware Stitching: we find that masking a high proportion of the input image, e.g., 80%, yields a highly effective self-supervisory representation learning of reference image lighting. 2) View-Consistent Adaptation: we leverage a synthetic view-consistent profile dataset to learn the in-context correspondence. The reference profile can then be warped into arbitrary poses for strong spatial-aligned view conditioning. Coupling these two designs by simply concatenating latents to form ControlNet-like supervision and modeling, enables us to significantly enhance the identity preservation fidelity and stability. Extensive evaluations demonstrate that IC-Portrait consistently outperforms existing state-of-the-art methods both quantitatively and qualitatively, with particularly notable improvements in visual qualities. Furthermore, IC-Portrait even demonstrates 3D-aware relighting capabilities. </p>
<blockquote>
<p>ç°æœ‰çš„æ‰©æ•£æ¨¡å‹åœ¨èº«ä»½ä¿ç•™ç”Ÿæˆæ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºç”¨æˆ·èµ„æ–™çš„å¤šæ ·æ€§ï¼ŒåŒ…æ‹¬å¤–è§‚å’Œå…‰ç…§æ¡ä»¶çš„å·®å¼‚ï¼Œä¸ªæ€§åŒ–è‚–åƒç”Ÿæˆä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†IC-Portraitï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å‡†ç¡®ç¼–ç ä¸ªäººèº«ä»½ç”¨äºä¸ªæ€§åŒ–è‚–åƒç”Ÿæˆçš„æ–°å‹æ¡†æ¶ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹äºä¸Šä¸‹æ–‡ä¸­çš„å¯†é›†å¯¹åº”å…³ç³»åŒ¹é…æ˜¯å¿«é€Ÿå­¦ä¹ è€…ï¼ˆä¾‹å¦‚ï¼Œ100è‡³200æ­¥ï¼‰ï¼Œè¿™æ¿€å‘äº†æˆ‘ä»¬IC-Portraitæ¡†æ¶çš„ä¸¤ä¸ªä¸»è¦è®¾è®¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†è‚–åƒç”Ÿæˆé‡æ–°å®šä¹‰ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼š1ï¼‰å…‰ç…§æ„ŸçŸ¥æ‹¼æ¥ï¼šæˆ‘ä»¬å‘ç°é®æŒ¡è¾“å…¥å›¾åƒçš„é«˜æ¯”ä¾‹éƒ¨åˆ†ï¼ˆä¾‹å¦‚80ï¼…ï¼‰å¯ä»¥æœ‰æ•ˆåœ°è¿›è¡Œå‚è€ƒå›¾åƒå…‰ç…§çš„è‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ ã€‚2ï¼‰è§†å›¾ä¸€è‡´é€‚åº”ï¼šæˆ‘ä»¬åˆ©ç”¨åˆæˆè§†å›¾ä¸€è‡´çš„è½®å»“æ•°æ®é›†æ¥å­¦ä¹ ä¸Šä¸‹æ–‡ä¸­çš„å¯¹åº”å…³ç³»ã€‚ç„¶åï¼Œå¯ä»¥å°†å‚è€ƒè½®å»“å˜å½¢ä¸ºä»»æ„å§¿åŠ¿ï¼Œä»¥å®ç°å¼ºå¤§çš„ç©ºé—´å¯¹é½è§†å›¾æ¡ä»¶ã€‚é€šè¿‡ç®€å•åœ°è¿æ¥æ½œåœ¨ç©ºé—´ä»¥å½¢æˆç±»ä¼¼ControlNetçš„ç›‘ç£å’Œç®¡ç†ï¼Œå¯ä»¥å¤§å¤§å¢å¼ºèº«ä»½ä¿ç•™çš„ä¿çœŸåº¦å’Œç¨³å®šæ€§ã€‚å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒIC-Portraitåœ¨å®šé‡å’Œå®šæ€§æ–¹é¢å‡å§‹ç»ˆä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨è§†è§‰å“è´¨æ–¹é¢å°¤å…¶å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒIC-Portraitç”šè‡³å±•ç¤ºäº†3Dæ„ŸçŸ¥çš„é‡ç…§æ˜èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17159v1">PDF</a> technical report</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºIC-Portraitçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸ªæ€§åŒ–è‚–åƒç”Ÿæˆä¸­çš„èº«ä»½ä¿ç•™æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¿«é€Ÿå­¦ä¹ ï¼Œé€šè¿‡ä¸¤ä¸ªä¸»è¦è®¾è®¡å®ç°å‡†ç¡®ç¼–ç ä¸ªä½“èº«ä»½ï¼šä¸€æ˜¯å…‰ç…§æ„ŸçŸ¥æ‹¼æ¥ï¼Œé€šè¿‡é®æŒ¡å¤§éƒ¨åˆ†è¾“å…¥å›¾åƒå®ç°è‡ªæˆ‘ç›‘ç£å­¦ä¹ å‚è€ƒå›¾åƒå…‰ç…§ï¼›äºŒæ˜¯è§†è§’ä¸€è‡´æ€§é€‚åº”ï¼Œåˆ©ç”¨åˆæˆè§†è§’ä¸€è‡´æ€§è½®å»“æ•°æ®é›†å­¦ä¹ ä¸Šä¸‹æ–‡å¯¹åº”å…³ç³»ã€‚IC-Portraité€šè¿‡ç»“åˆè¿™ä¸¤ä¸ªè®¾è®¡ï¼Œæ˜¾è‘—æé«˜äº†èº«ä»½ä¿ç•™çš„ä¿çœŸåº¦å’Œç¨³å®šæ€§ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒIC-Portraitåœ¨å®šé‡å’Œå®šæ€§ä¸Šå‡ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ï¼Œå°¤å…¶åœ¨è§†è§‰å“è´¨ä¸Šæœ‰æ˜¾è‘—æ”¹è¿›ï¼Œç”šè‡³å±•ç¤ºäº†3Dæ„ŸçŸ¥çš„é‡ç…§æ˜èƒ½åŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>IC-Portraitæ¡†æ¶è¢«è®¾è®¡ä¸ºè§£å†³ä¸ªæ€§åŒ–è‚–åƒç”Ÿæˆä¸­çš„èº«ä»½ä¿ç•™æŒ‘æˆ˜ã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¿«é€Ÿå­¦ä¹ ï¼Œå®ç°å‡†ç¡®ç¼–ç ä¸ªä½“èº«ä»½ã€‚</li>
<li>é€šè¿‡å…‰ç…§æ„ŸçŸ¥æ‹¼æ¥å’Œè§†è§’ä¸€è‡´æ€§é€‚åº”ä¸¤ä¸ªä¸»è¦è®¾è®¡ï¼Œæé«˜èº«ä»½ä¿ç•™çš„ä¿çœŸåº¦å’Œç¨³å®šæ€§ã€‚</li>
<li>å…‰ç…§æ„ŸçŸ¥æ‹¼æ¥é€šè¿‡é®æŒ¡å¤§éƒ¨åˆ†è¾“å…¥å›¾åƒå®ç°è‡ªæˆ‘ç›‘ç£å­¦ä¹ å‚è€ƒå›¾åƒå…‰ç…§ã€‚</li>
<li>è§†è§’ä¸€è‡´æ€§é€‚åº”åˆ©ç”¨åˆæˆè§†è§’ä¸€è‡´æ€§è½®å»“æ•°æ®é›†å­¦ä¹ ä¸Šä¸‹æ–‡å¯¹åº”å…³ç³»ã€‚</li>
<li>IC-Portraitåœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå°¤å…¶åœ¨è§†è§‰å“è´¨ä¸Šæœ‰æ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17159">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-677957cefff1d0534559d2c7db7e89ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fae033f722c11754e250050fab37ce49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-181c421d2e16684151e8b7a5e915cf66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3effc876bcfaae1951eea6ed552d3b7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ad8455a2766e6494eabe2810c31bf337.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DIRIGENt-End-To-End-Robotic-Imitation-of-Human-Demonstrations-Based-on-a-Diffusion-Model"><a href="#DIRIGENt-End-To-End-Robotic-Imitation-of-Human-Demonstrations-Based-on-a-Diffusion-Model" class="headerlink" title="DIRIGENt: End-To-End Robotic Imitation of Human Demonstrations Based on   a Diffusion Model"></a>DIRIGENt: End-To-End Robotic Imitation of Human Demonstrations Based on   a Diffusion Model</h2><p><strong>Authors:Josua Spisak, Matthias Kerzel, Stefan Wermter</strong></p>
<p>There has been substantial progress in humanoid robots, with new skills continuously being taught, ranging from navigation to manipulation. While these abilities may seem impressive, the teaching methods often remain inefficient. To enhance the process of teaching robots, we propose leveraging a mechanism effectively used by humans: teaching by demonstrating. In this paper, we introduce DIRIGENt (DIrect Robotic Imitation GENeration model), a novel end-to-end diffusion approach that directly generates joint values from observing human demonstrations, enabling a robot to imitate these actions without any existing mapping between it and humans. We create a dataset in which humans imitate a robot and then use this collected data to train a diffusion model that enables a robot to imitate humans. The following three aspects are the core of our contribution. First is our novel dataset with natural pairs between human and robot poses, allowing our approach to imitate humans accurately despite the gap between their anatomies. Second, the diffusion input to our model alleviates the challenge of redundant joint configurations, limiting the search space. And finally, our end-to-end architecture from perception to action leads to an improved learning capability. Through our experimental analysis, we show that combining these three aspects allows DIRIGENt to outperform existing state-of-the-art approaches in the field of generating joint values from RGB images. </p>
<blockquote>
<p>äººå½¢æœºå™¨äººåœ¨æŠ€èƒ½å­¦ä¹ æ–¹é¢å–å¾—äº†å·¨å¤§è¿›æ­¥ï¼Œä¸æ–­ä¹ å¾—æ–°æŠ€èƒ½ï¼Œä»å¯¼èˆªåˆ°æ“ä½œéƒ½æœ‰æ¶‰åŠã€‚å°½ç®¡è¿™äº›èƒ½åŠ›ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†æ•™å­¦æ–¹æ³•å¾€å¾€æ•ˆç‡ä½ä¸‹ã€‚ä¸ºäº†æ”¹è¿›æœºå™¨äººæ•™å­¦è¿‡ç¨‹ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨äººç±»æœ‰æ•ˆä½¿ç”¨çš„ä¸€ç§æœºåˆ¶ï¼šé€šè¿‡ç¤ºèŒƒè¿›è¡Œæ•™å­¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†DIRIGENtï¼ˆç›´æ¥æœºå™¨äººæ¨¡ä»¿ç”Ÿæˆæ¨¡å‹ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç«¯åˆ°ç«¯æ‰©æ•£æ–¹æ³•ï¼Œèƒ½å¤Ÿç›´æ¥ä»äººç±»ç¤ºèŒƒä¸­ç”Ÿæˆå…³èŠ‚å€¼ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ¨¡ä»¿è¿™äº›åŠ¨ä½œï¼Œè€Œæ— éœ€åœ¨æœºå™¨äººå’Œäººç±»ä¹‹é—´å»ºç«‹ç°æœ‰æ˜ å°„ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼Œäººç±»åœ¨å…¶ä¸­æ¨¡ä»¿æœºå™¨äººï¼Œç„¶åä½¿ç”¨æ”¶é›†çš„æ•°æ®æ¥è®­ç»ƒä¸€ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ¨¡ä»¿äººç±»ã€‚æˆ‘ä»¬è´¡çŒ®çš„æ ¸å¿ƒåœ¨äºä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ‹¥æœ‰è‡ªç„¶çš„äººç±»å’Œæœºå™¨äººå§¿åŠ¿é…å¯¹æ•°æ®é›†ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬çš„æ–¹æ³•å³ä½¿åœ¨ä»–ä»¬è§£å‰–ç»“æ„ä¹‹é—´å­˜åœ¨å·®å¼‚çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½å‡†ç¡®åœ°æ¨¡ä»¿äººç±»ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ¨¡å‹çš„æ‰©æ•£è¾“å…¥å‡è½»äº†å†—ä½™å…³èŠ‚é…ç½®çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æœç´¢ç©ºé—´ã€‚æœ€åï¼Œæˆ‘ä»¬ä»æ„ŸçŸ¥åˆ°åŠ¨ä½œçš„ç«¯åˆ°ç«¯æ¶æ„æé«˜äº†å­¦ä¹ èƒ½åŠ›ã€‚é€šè¿‡æˆ‘ä»¬çš„å®éªŒåˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†ç»“åˆè¿™ä¸‰ä¸ªæ–¹é¢å¯ä»¥ä½¿DIRIGENtåœ¨ä»RGBå›¾åƒç”Ÿæˆå…³èŠ‚å€¼é¢†åŸŸè¶…è¶Šç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16800v1">PDF</a> </p>
<p><strong>Summary</strong><br>     äººç±»å‹æœºå™¨äººå–å¾—æ˜¾è‘—è¿›å±•ï¼Œä¹ å¾—æ–°æŠ€èƒ½ï¼Œå¦‚å¯¼èˆªå’Œæ“æ§ã€‚ä¸ºæå‡æœºå™¨äººæ•™å­¦è¿‡ç¨‹çš„æ•ˆç‡ï¼Œæœ¬æ–‡æå‡ºå€Ÿé‰´äººç±»å¸¸ç”¨çš„æ•™å­¦æ–¹å¼â€”â€”é€šè¿‡ç¤ºèŒƒè¿›è¡Œæ•™å­¦ï¼Œå¹¶ä»‹ç»DIRIGENtï¼ˆç›´æ¥æœºå™¨äººæ¨¡ä»¿ç”Ÿæˆæ¨¡å‹ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å…¨æ–°çš„ç«¯åˆ°ç«¯æ‰©æ•£æ–¹æ³•ï¼Œå®ƒèƒ½ä»è§‚å¯Ÿäººç±»ç¤ºèŒƒåŠ¨ä½œä¸­ç›´æ¥ç”Ÿæˆå…³èŠ‚å€¼ï¼Œè®©æœºå™¨äººåœ¨æ— éœ€ä¸äººç±»å»ºç«‹æ˜ å°„å…³ç³»çš„æƒ…å†µä¸‹æ¨¡ä»¿åŠ¨ä½œã€‚æœ¬æ–‡åˆ›å»ºäº†äººç±»æ¨¡ä»¿æœºå™¨äººçš„æ•°æ®é›†ï¼Œå¹¶ç”¨å…¶è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä½¿æœºå™¨äººèƒ½æ¨¡ä»¿äººç±»ã€‚æœ¬æ–‡çš„æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬ä¸‰ä¸ªæ–¹é¢ï¼šè‡ªç„¶é…å¯¹çš„äººç±»å’Œæœºå™¨äººå§¿æ€æ„æˆçš„æ–°æ•°æ®é›†ï¼Œè®©æœºå™¨äººèƒ½å¤Ÿå‡†ç¡®æ¨¡ä»¿äººç±»ï¼›æ¨¡å‹æ‰©æ•£è¾“å…¥è§£å†³äº†å…³èŠ‚é…ç½®å†—ä½™é—®é¢˜å¹¶ç¼©å‡äº†æœç´¢ç©ºé—´ï¼›ç«¯åˆ°ç«¯çš„æ„ŸçŸ¥åˆ°è¡ŒåŠ¨æ¶æ„æé«˜äº†å­¦ä¹ èƒ½åŠ›ã€‚å®éªŒè¯æ˜DIRIGENtåœ¨ç”±RGBå›¾åƒç”Ÿæˆå…³èŠ‚å€¼æ–¹é¢è¡¨ç°è¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»å‹æœºå™¨äººåœ¨æŠ€èƒ½å’ŒåŠ¨ä½œä¸Šå–å¾—æ˜¾è‘—è¿›æ­¥ã€‚</li>
<li>å½“å‰æœºå™¨äººæ•™å­¦æ–¹å¼å­˜åœ¨æ•ˆç‡é—®é¢˜ã€‚</li>
<li>å€Ÿé‰´äººç±»é€šè¿‡ç¤ºèŒƒè¿›è¡Œæ•™å­¦çš„æ–¹å¼ï¼Œæå‡ºDIRIGENtæ¨¡å‹ã€‚</li>
<li>DIRIGENtæ¨¡å‹æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„æ‰©æ•£æ–¹æ³•ï¼Œèƒ½ä»äººç±»ç¤ºèŒƒä¸­ç›´æ¥ç”Ÿæˆå…³èŠ‚å€¼ã€‚</li>
<li>åˆ›å»ºäº†äººç±»æ¨¡ä»¿æœºå™¨äººçš„æ•°æ®é›†ç”¨äºè®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹çš„æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬æ–°æ•°æ®é›†ã€æ‰©æ•£è¾“å…¥è§£å†³å…³èŠ‚é…ç½®å†—ä½™é—®é¢˜ä»¥åŠç«¯åˆ°ç«¯çš„æ„ŸçŸ¥åˆ°è¡ŒåŠ¨æ¶æ„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-420bd86e752028bbddd24aa1ef9d9ac0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9accd520e2fadac716b720cb36c94ffa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b37d013d9a3ca043b3373a35be8bd1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a964ccd5bc2feec9caf79e33a4867a20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-242342f980ce0987dcce8fad9031fe8a.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DiffSplat-Repurposing-Image-Diffusion-Models-for-Scalable-Gaussian-Splat-Generation"><a href="#DiffSplat-Repurposing-Image-Diffusion-Models-for-Scalable-Gaussian-Splat-Generation" class="headerlink" title="DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian   Splat Generation"></a>DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian   Splat Generation</h2><p><strong>Authors:Chenguo Lin, Panwang Pan, Bangbang Yang, Zeming Li, Yadong Mu</strong></p>
<p>Recent advancements in 3D content generation from text or a single image struggle with limited high-quality 3D datasets and inconsistency from 2D multi-view generation. We introduce DiffSplat, a novel 3D generative framework that natively generates 3D Gaussian splats by taming large-scale text-to-image diffusion models. It differs from previous 3D generative models by effectively utilizing web-scale 2D priors while maintaining 3D consistency in a unified model. To bootstrap the training, a lightweight reconstruction model is proposed to instantly produce multi-view Gaussian splat grids for scalable dataset curation. In conjunction with the regular diffusion loss on these grids, a 3D rendering loss is introduced to facilitate 3D coherence across arbitrary views. The compatibility with image diffusion models enables seamless adaptions of numerous techniques for image generation to the 3D realm. Extensive experiments reveal the superiority of DiffSplat in text- and image-conditioned generation tasks and downstream applications. Thorough ablation studies validate the efficacy of each critical design choice and provide insights into the underlying mechanism. </p>
<blockquote>
<p>å…³äºæ–‡æœ¬æˆ–å•å¹…å›¾åƒç”Ÿæˆä¸‰ç»´å†…å®¹çš„æœ€æ–°è¿›å±•å—é™äºé«˜è´¨é‡çš„ä¸‰ç»´æ•°æ®é›†ä»¥åŠäºŒç»´å¤šè§†è§’ç”Ÿæˆçš„ä¸ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†DiffSplatï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸‰ç»´ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒé€šè¿‡é©¯æœå¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ¥åŸç”Ÿç”Ÿæˆä¸‰ç»´é«˜æ–¯å…‰æ–‘ã€‚å®ƒä¸ä¹‹å‰çš„ä¸‰ç»´ç”Ÿæˆæ¨¡å‹ä¸åŒï¼Œèƒ½å¤Ÿåœ¨ç»Ÿä¸€æ¨¡å‹ä¸­æœ‰æ•ˆåˆ©ç”¨ç½‘ç»œè§„æ¨¡çš„äºŒç»´å…ˆéªŒçŸ¥è¯†ï¼ŒåŒæ—¶ä¿æŒä¸‰ç»´ä¸€è‡´æ€§ã€‚ä¸ºäº†å¯åŠ¨è®­ç»ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„é‡å»ºæ¨¡å‹ï¼Œç”¨äºå³æ—¶ç”Ÿæˆå¤šè§†è§’é«˜æ–¯å…‰æ–‘ç½‘æ ¼ï¼Œä»¥å®ç°å¯æ‰©å±•çš„æ•°æ®é›†æ•´ç†ã€‚ç»“åˆè¿™äº›ç½‘æ ¼ä¸Šçš„å¸¸è§„æ‰©æ•£æŸå¤±ï¼Œå¼•å…¥äº†ä¸€ç§ä¸‰ç»´æ¸²æŸ“æŸå¤±ï¼Œä»¥ä¿ƒè¿›ä»»æ„è§†è§’ä¸‹çš„ä¸‰ç»´è¿è´¯æ€§ã€‚å…¶ä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…¼å®¹æ€§ä½¿å¾—ä¼—å¤šå›¾åƒç”ŸæˆæŠ€æœ¯èƒ½å¤Ÿæ— ç¼é€‚åº”ä¸‰ç»´é¢†åŸŸã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDiffSplatåœ¨æ–‡æœ¬å’Œå›¾åƒæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä»¥åŠä¸‹æ¸¸åº”ç”¨ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚è¯¦å°½çš„æ¶ˆèç ”ç©¶éªŒè¯äº†æ¯ä¸ªå…³é”®è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ·±å…¥äº†è§£äº†å…¶å†…åœ¨æœºåˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16764v1">PDF</a> Accepted to ICLR 2025; Project page:   <a target="_blank" rel="noopener" href="https://chenguolin.github.io/projects/DiffSplat">https://chenguolin.github.io/projects/DiffSplat</a></p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£ä¸‰ç»´å†…å®¹ç”ŸæˆæŠ€æœ¯é¢ä¸´æ•°æ®é›†è´¨é‡ä¸é«˜å’Œå¤šè§†è§’ç”Ÿæˆä¸ä¸€è‡´çš„é—®é¢˜ã€‚æˆ‘ä»¬æ¨å‡ºDiffSplatï¼Œä¸€ç§æ–°å‹ä¸‰ç»´ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡é©¾é©­å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç›´æ¥ç”Ÿæˆä¸‰ç»´é«˜æ–¯ç‚¹äº‘ã€‚å®ƒä¸åŒäºä»¥å¾€çš„ä¸‰ç»´ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½æœ‰æ•ˆåˆ©ç”¨äº’è”ç½‘è§„æ¨¡çš„äºŒç»´å…ˆéªŒçŸ¥è¯†ï¼ŒåŒæ—¶åœ¨ç»Ÿä¸€æ¨¡å‹ä¸­ä¿æŒä¸‰ç»´ä¸€è‡´æ€§ã€‚ä¸ºå¯åŠ¨è®­ç»ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§é‡å»ºæ¨¡å‹ï¼Œå¯ç«‹å³ç”Ÿæˆå¤šè§†è§’é«˜æ–¯ç‚¹äº‘ç½‘æ ¼ï¼Œä¾¿äºæ‰©å±•æ•°æ®é›†æ•´ç†ã€‚é™¤äº†åœ¨è¿™äº›ç½‘æ ¼ä¸Šçš„å¸¸è§„æ‰©æ•£æŸå¤±ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸‰ç»´æ¸²æŸ“æŸå¤±ï¼Œä»¥ä¿ƒè¿›ä»»æ„è§†è§’ä¸‹çš„ä¸‰ç»´è¿è´¯æ€§ã€‚å…¶ä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…¼å®¹æ€§ä½¿å¾—ä¼—å¤šå›¾åƒç”ŸæˆæŠ€æœ¯èƒ½å¤Ÿæ— ç¼é€‚åº”ä¸‰ç»´é¢†åŸŸã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDiffSplatåœ¨æ–‡æœ¬å’Œå›¾åƒæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä»¥åŠä¸‹æ¸¸åº”ç”¨ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚å½»åº•çš„æ¶ˆèç ”ç©¶éªŒè¯äº†å…³é”®è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ­ç¤ºäº†å…¶å†…åœ¨æœºåˆ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DiffSplatæ˜¯ä¸€ç§æ–°å‹ä¸‰ç»´ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿç›´æ¥ç”Ÿæˆä¸‰ç»´é«˜æ–¯ç‚¹äº‘ã€‚</li>
<li>ä¸å…¶ä»–ä¸‰ç»´ç”Ÿæˆæ¨¡å‹ä¸åŒï¼ŒDiffSplatæœ‰æ•ˆåˆ©ç”¨äº’è”ç½‘è§„æ¨¡çš„äºŒç»´å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ç»´æŒç»Ÿä¸€æ¨¡å‹ä¸­çš„ä¸‰ç»´ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡è½»é‡çº§é‡å»ºæ¨¡å‹å¿«é€Ÿç”Ÿæˆå¤šè§†è§’é«˜æ–¯ç‚¹äº‘ç½‘æ ¼ï¼Œä¿ƒè¿›æ•°æ®é›†æ•´ç†ã€‚</li>
<li>å¼•å…¥ä¸‰ç»´æ¸²æŸ“æŸå¤±ï¼Œå¢å¼ºä»»æ„è§†è§’ä¸‹çš„ä¸‰ç»´è¿è´¯æ€§ã€‚</li>
<li>DiffSplatä¸å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…¼å®¹æ€§ä½¿å¾—å›¾åƒç”ŸæˆæŠ€æœ¯èƒ½æ— ç¼é€‚åº”ä¸‰ç»´é¢†åŸŸã€‚</li>
<li>å¤§é‡å®éªŒè¯æ˜DiffSplatåœ¨æ–‡æœ¬å’Œå›¾åƒæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä»¥åŠä¸‹æ¸¸åº”ç”¨ä¸­çš„å“è¶Šæ€§èƒ½ã€‚</li>
<li>æ¶ˆèç ”ç©¶éªŒè¯äº†å…³é”®è®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ï¼Œæ­ç¤ºäº†å…¶å†…åœ¨æœºåˆ¶å’Œå·¥ä½œåŸç†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16764">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a08db892e6154dea051f9f796e88a32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a92f569f82ed878130b8a4cf061f7152.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d325368ed949026d796ea05784910ee.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ITVTON-Virtual-Try-On-Diffusion-Transformer-Model-Based-on-Integrated-Image-and-Text"><a href="#ITVTON-Virtual-Try-On-Diffusion-Transformer-Model-Based-on-Integrated-Image-and-Text" class="headerlink" title="ITVTON:Virtual Try-On Diffusion Transformer Model Based on Integrated   Image and Text"></a>ITVTON:Virtual Try-On Diffusion Transformer Model Based on Integrated   Image and Text</h2><p><strong>Authors:Haifeng Ni</strong></p>
<p>Recent advancements in virtual fitting for characters and clothing have leveraged diffusion models to improve the realism of garment fitting. However, challenges remain in handling complex scenes and poses, which can result in unnatural garment fitting and poorly rendered intricate patterns. In this work, we introduce ITVTON, a novel method that enhances clothing-character interactions by combining clothing and character images along spatial channels as inputs, thereby improving fitting accuracy for the inpainting model. Additionally, we incorporate integrated textual descriptions from multiple images to boost the realism of the generated visual effects. To optimize computational efficiency, we limit training to the attention parameters within a single diffusion transformer (Single-DiT) block. To more rigorously address the complexities of real-world scenarios, we curated training samples from the IGPair dataset, thereby enhancing ITVTONâ€™s performance across diverse environments. Extensive experiments demonstrate that ITVTON outperforms baseline methods both qualitatively and quantitatively, setting a new standard for virtual fitting tasks. </p>
<blockquote>
<p>åœ¨å­—ç¬¦å’Œæœè£…è™šæ‹Ÿé€‚é…æ–¹é¢çš„æœ€æ–°è¿›å±•å·²ç»åˆ©ç”¨æ‰©æ•£æ¨¡å‹æé«˜äº†æœè£…é€‚é…çš„çœŸå®æ€§ã€‚ç„¶è€Œï¼Œåœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œå§¿åŠ¿æ—¶ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½å¯¼è‡´æœè£…é€‚é…ä¸è‡ªç„¶ï¼Œç²¾ç»†å›¾æ¡ˆæ¸²æŸ“ä¸ä½³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ITVTONï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç»“åˆæœè£…å’Œè§’è‰²å›¾åƒä½œä¸ºç©ºé—´é€šé“è¾“å…¥æ¥å¢å¼ºæœè£…ä¸è§’è‰²äº¤äº’çš„æ–°å‹æ–¹æ³•ï¼Œä»è€Œæé«˜è¡¥å…¨æ¨¡å‹çš„é€‚é…å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»å¤šå¼ å›¾åƒä¸­èå…¥é›†æˆçš„æ–‡æœ¬æè¿°ï¼Œä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„çœŸå®æ€§ã€‚ä¸ºäº†ä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬å°†è®­ç»ƒé™åˆ¶åœ¨å•ä¸ªæ‰©æ•£å˜å‹å™¨ï¼ˆSingle-DiTï¼‰å—å†…çš„æ³¨æ„åŠ›å‚æ•°ã€‚ä¸ºäº†æ›´ä¸¥æ ¼åœ°è§£å†³ç°å®åœºæ™¯çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬ä»IGPairæ•°æ®é›†ä¸­ç²¾é€‰è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œæé«˜ITVTONåœ¨ä¸åŒç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒITVTONåœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œä¸ºè™šæ‹Ÿé€‚é…ä»»åŠ¡æ ‘ç«‹äº†æ–°çš„æ ‡å‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16757v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹åœ¨è™šæ‹Ÿè§’è‰²æœè£…æ‹Ÿåˆä¸­çš„åº”ç”¨ï¼Œè¿‘æœŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæå‡äº†æœè£…çœŸå®æ„Ÿã€‚ç„¶è€Œï¼Œå¤„ç†å¤æ‚åœºæ™¯å’Œå§¿åŠ¿çš„æŒ‘æˆ˜ä»ç„¶å­˜åœ¨ï¼Œå¯èƒ½å¯¼è‡´æœè£…æ‹Ÿåˆä¸è‡ªç„¶å’Œç²¾ç»†å›¾æ¡ˆæ¸²æŸ“ä¸è‰¯ã€‚æœ¬ç ”ç©¶å¼•å…¥ITVTONæ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæœè£…å’Œè§’è‰²å›¾åƒä½œä¸ºç©ºé—´é€šé“è¾“å…¥ï¼Œæé«˜è¡£ç‰©ä¸è§’è‰²çš„äº’åŠ¨ï¼Œæ”¹å–„å¡«å……æ¨¡å‹çš„æ‹Ÿåˆç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¿˜èå…¥å¤šå¼ å›¾åƒçš„æ–‡æœ¬æè¿°ï¼Œå¢å¼ºç”Ÿæˆè§†è§‰æ•ˆæœçš„çœŸå®æ„Ÿã€‚ä¸ºä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Œä»…åœ¨å•ä¸ªæ‰©æ•£å˜å‹å™¨ï¼ˆSingle-DiTï¼‰å—å†…è®­ç»ƒæ³¨æ„åŠ›å‚æ•°ã€‚é€šè¿‡é‡‡é›†IGPairæ•°æ®é›†çš„è®­ç»ƒæ ·æœ¬ï¼Œåº”å¯¹ç°å®åœºæ™¯çš„å¤æ‚æ€§ï¼ŒITVTONåœ¨å¤šç§ç¯å¢ƒä¸‹è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒITVTONåœ¨å®šæ€§å’Œå®šé‡ä¸Šå‡ä¼˜äºåŸºå‡†æ–¹æ³•ï¼Œä¸ºè™šæ‹Ÿæ‹Ÿåˆä»»åŠ¡æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹ç”¨äºæ”¹è¿›è™šæ‹Ÿè§’è‰²æœè£…æ‹Ÿåˆçš„é€¼çœŸåº¦ã€‚</li>
<li>å¤„ç†å¤æ‚åœºæ™¯å’Œå§¿åŠ¿çš„æŒ‘æˆ˜ä»ç„¶çªå‡ºã€‚</li>
<li>ITVTONæ–¹æ³•ç»“åˆæœè£…å’Œè§’è‰²å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæé«˜è¡£ç‰©ä¸è§’è‰²çš„äº’åŠ¨ã€‚</li>
<li>é€šè¿‡ç»“åˆå¤šå¼ å›¾åƒçš„æ–‡æœ¬æè¿°ï¼Œå¢å¼ºç”Ÿæˆçš„è§†è§‰æ•ˆæœçš„çœŸå®æ„Ÿã€‚</li>
<li>ä¸ºä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Œä»…åœ¨å•ä¸ªæ‰©æ•£å˜å‹å™¨å—å†…è®­ç»ƒæ³¨æ„åŠ›å‚æ•°ã€‚</li>
<li>ä½¿ç”¨IGPairæ•°æ®é›†çš„è®­ç»ƒæ ·æœ¬åº”å¯¹ç°å®åœºæ™¯çš„å¤æ‚æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16757">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-11bfa00085039cd8ff1afdf1a84f5a06.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c89784a80c90d41cda593cc1b4a3265a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69e86fa1f6b1ae716747084f19fb617d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39557d16a1f7c191ea38d9d20c140e8c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f291e7077e762a9129efeb3ad3dc527b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60d39c9b509de00863c93c6c2384fe1d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a44092cc779b330b2080fa08116fd6a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CascadeV-An-Implementation-of-Wurstchen-Architecture-for-Video-Generation"><a href="#CascadeV-An-Implementation-of-Wurstchen-Architecture-for-Video-Generation" class="headerlink" title="CascadeV: An Implementation of Wurstchen Architecture for Video   Generation"></a>CascadeV: An Implementation of Wurstchen Architecture for Video   Generation</h2><p><strong>Authors:Wenfeng Lin, Jiangchuan Wei, Boyuan Liu, Yichen Zhang, Shiyue Yan, Mingyu Guo</strong></p>
<p>Recently, with the tremendous success of diffusion models in the field of text-to-image (T2I) generation, increasing attention has been directed toward their potential in text-to-video (T2V) applications. However, the computational demands of diffusion models pose significant challenges, particularly in generating high-resolution videos with high frame rates. In this paper, we propose CascadeV, a cascaded latent diffusion model (LDM), that is capable of producing state-of-the-art 2K resolution videos. Experiments demonstrate that our cascaded model achieves a higher compression ratio, substantially reducing the computational challenges associated with high-quality video generation. We also implement a spatiotemporal alternating grid 3D attention mechanism, which effectively integrates spatial and temporal information, ensuring superior consistency across the generated video frames. Furthermore, our model can be cascaded with existing T2V models, theoretically enabling a 4$\times$ increase in resolution or frames per second without any fine-tuning. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/bytedance/CascadeV">https://github.com/bytedance/CascadeV</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œéšç€æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ç”Ÿæˆé¢†åŸŸçš„å·¨å¤§æˆåŠŸï¼Œäººä»¬è¶Šæ¥è¶Šå…³æ³¨å…¶åœ¨æ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œæ‰©æ•£æ¨¡å‹çš„è®¡ç®—éœ€æ±‚æ„æˆäº†é‡å¤§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆé«˜å¸§ç‡çš„é«˜åˆ†è¾¨ç‡è§†é¢‘æ—¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†CascadeVï¼Œè¿™æ˜¯ä¸€ç§çº§è”çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ï¼Œèƒ½å¤Ÿäº§ç”Ÿæœ€å…ˆè¿›çš„2Kåˆ†è¾¨ç‡è§†é¢‘ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„çº§è”æ¨¡å‹å®ç°äº†æ›´é«˜çš„å‹ç¼©æ¯”ï¼Œå¤§å¤§é™ä½äº†é«˜è´¨é‡è§†é¢‘ç”Ÿæˆçš„è®¡ç®—æŒ‘æˆ˜ã€‚æˆ‘ä»¬è¿˜å®ç°äº†ä¸€ç§æ—¶ç©ºäº¤æ›¿ç½‘æ ¼3Dæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆåœ°ç»“åˆäº†ç©ºé—´å’Œæ—¶é—´ä¿¡æ¯ï¼Œç¡®ä¿äº†ç”Ÿæˆè§†é¢‘å¸§ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ä¸ç°æœ‰çš„T2Væ¨¡å‹çº§è”ï¼Œç†è®ºä¸Šå¯ä»¥åœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹å®ç°æ¯ç§’å¸§æ•°æˆ–åˆ†è¾¨ç‡çš„å››å€æå‡ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bytedance/CascadeV%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/bytedance/CascadeVæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16612v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œå…¶åœ¨æ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰åº”ç”¨ä¸­çš„æ½œåŠ›æ­£å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œæ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—éœ€æ±‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡å’Œé«˜å¸§ç‡è§†é¢‘æ—¶ã€‚æœ¬æ–‡æå‡ºäº†CascadeVï¼Œä¸€ç§çº§è”æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ï¼Œèƒ½å¤Ÿç”Ÿæˆæœ€å…ˆè¿›çš„2Kåˆ†è¾¨ç‡è§†é¢‘ã€‚å®éªŒè¡¨æ˜ï¼Œçº§è”æ¨¡å‹å®ç°äº†æ›´é«˜çš„å‹ç¼©æ¯”ï¼Œå‡å°‘äº†é«˜è´¨é‡è§†é¢‘ç”Ÿæˆçš„è®¡ç®—æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè¿˜å®ç°äº†æ—¶ç©ºäº¤æ›¿ç½‘æ ¼3Dæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆæ•´åˆç©ºé—´å’Œæ—¶é—´ä¿¡æ¯ï¼Œç¡®ä¿ç”Ÿæˆè§†é¢‘å¸§ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚è¯¥æ¨¡å‹è¿˜å¯ä»¥ä¸ç°æœ‰T2Væ¨¡å‹çº§è”ï¼Œç†è®ºä¸Šå¯ä»¥æé«˜åˆ†è¾¨ç‡æˆ–å¸§ç‡è€Œä¸éœ€å¾®è°ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆé¢†åŸŸçš„åº”ç”¨æ½œåŠ›æ­£åœ¨å—åˆ°å…³æ³¨ã€‚</li>
<li>çº§è”æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆCascadeVï¼‰èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„2Kåˆ†è¾¨ç‡è§†é¢‘ã€‚</li>
<li>çº§è”æ¨¡å‹å®ç°äº†é«˜å‹ç¼©æ¯”ï¼Œé™ä½è®¡ç®—éœ€æ±‚ã€‚</li>
<li>å®ç°äº†æ—¶ç©ºäº¤æ›¿ç½‘æ ¼3Dæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºè§†é¢‘å¸§é—´ä¸€è‡´æ€§ã€‚</li>
<li>CascadeVæ¨¡å‹å¯ä»¥ä¸ç°æœ‰T2Væ¨¡å‹çº§è”ï¼Œæé«˜åˆ†è¾¨ç‡æˆ–å¸§ç‡ã€‚</li>
<li>è¯¥æ¨¡å‹ç†è®ºä¸Šçš„ä¼˜ç‚¹åŒ…æ‹¬åœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹æé«˜åˆ†è¾¨ç‡æˆ–å¸§ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16612">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b273b7f797cfff232a7a43a50e60c696.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a58a7d8bfb3af09d7cf5ede4a52eac63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-164cae4de0e896a8393ea2fb00213c4d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-83ac14e54fc138462f3a6d40d5c8efc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdf0db8b8061d6603296201be49b6811.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7b18a1dd45678ae22c2706bf1abdb0e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7870065adfaaf13a437ea3037bfccd1e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Slot-Guided-Adaptation-of-Pre-trained-Diffusion-Models-for-Object-Centric-Learning-and-Compositional-Generation"><a href="#Slot-Guided-Adaptation-of-Pre-trained-Diffusion-Models-for-Object-Centric-Learning-and-Compositional-Generation" class="headerlink" title="Slot-Guided Adaptation of Pre-trained Diffusion Models for   Object-Centric Learning and Compositional Generation"></a>Slot-Guided Adaptation of Pre-trained Diffusion Models for   Object-Centric Learning and Compositional Generation</h2><p><strong>Authors:Adil Kaan Akan, Yucel Yemez</strong></p>
<p>We present SlotAdapt, an object-centric learning method that combines slot attention with pretrained diffusion models by introducing adapters for slot-based conditioning. Our method preserves the generative power of pretrained diffusion models, while avoiding their text-centric conditioning bias. We also incorporate an additional guidance loss into our architecture to align cross-attention from adapter layers with slot attention. This enhances the alignment of our model with the objects in the input image without using external supervision. Experimental results show that our method outperforms state-of-the-art techniques in object discovery and image generation tasks across multiple datasets, including those with real images. Furthermore, we demonstrate through experiments that our method performs remarkably well on complex real-world images for compositional generation, in contrast to other slot-based generative methods in the literature. The project page can be found at <a target="_blank" rel="noopener" href="https://kaanakan.github.io/SlotAdapt/">https://kaanakan.github.io/SlotAdapt/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†SlotAdaptï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆæ’æ§½æ³¨æ„åŠ›å’Œé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„é¢å‘å¯¹è±¡çš„å­¦ä¹ æ–¹æ³•ï¼Œå®ƒé€šè¿‡å¼•å…¥é€‚é…å™¨æ¥å®ç°åŸºäºæ’æ§½çš„æ¡ä»¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¿ç•™äº†é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶é¿å…äº†å…¶é¢å‘æ–‡æœ¬çš„æ¡ä»¶åå·®ã€‚æˆ‘ä»¬è¿˜å°†é¢å¤–çš„æŒ‡å¯¼æŸå¤±çº³å…¥æˆ‘ä»¬çš„æ¶æ„ï¼Œä»¥è°ƒæ•´é€‚é…å™¨å±‚çš„äº¤å‰æ³¨æ„åŠ›ä¸æ’æ§½æ³¨æ„åŠ›ã€‚è¿™å¢å¼ºäº†æˆ‘ä»¬çš„æ¨¡å‹ä¸è¾“å…¥å›¾åƒä¸­çš„å¯¹è±¡çš„å¯¹é½æ€§ï¼Œè€Œæ— éœ€ä½¿ç”¨å¤–éƒ¨ç›‘ç£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¯¹è±¡å‘ç°å’Œå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ä¼˜äºæœ€å…ˆè¿›çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬é‚£äº›å¸¦æœ‰çœŸå®å›¾åƒçš„æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œé€šè¿‡è¯•éªŒï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤æ‚çœŸå®å›¾åƒçš„åˆæˆç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸æ–‡çŒ®ä¸­çš„å…¶ä»–åŸºäºæ’æ§½çš„ç”Ÿæˆæ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚é¡¹ç›®é¡µé¢ä½äº<a target="_blank" rel="noopener" href="https://kaanakan.github.io/SlotAdapt/%E3%80%82">https://kaanakan.github.io/SlotAdapt/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15878v2">PDF</a> Accepted to ICLR2025. Project page:   <a target="_blank" rel="noopener" href="https://kaanakan.github.io/SlotAdapt/">https://kaanakan.github.io/SlotAdapt/</a></p>
<p><strong>Summary</strong></p>
<p>SlotAdaptç»“åˆæ§½ä½æ³¨æ„åŠ›å’Œé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥é€‚é…å™¨è¿›è¡Œæ§½ä½æ¡ä»¶åŒ–ï¼Œå®ç°å¯¹è±¡çº§å­¦ä¹ ã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›çš„åŒæ—¶ï¼Œé¿å…äº†å…¶æ–‡æœ¬ä¸­å¿ƒåŒ–çš„æ¡ä»¶åå·®ã€‚é€šè¿‡å¼•å…¥é¢å¤–çš„æŒ‡å¯¼æŸå¤±ï¼Œå¢å¼ºæ¨¡å‹ä¸è¾“å…¥å›¾åƒä¸­å¯¹è±¡çš„å¯¹é½åº¦ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç‰©ä½“å‘ç°å’Œå›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ“…é•¿å¤„ç†å¤æ‚çœŸå®å›¾åƒçš„åˆæˆç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SlotAdaptç»“åˆäº†æ§½ä½æ³¨æ„åŠ›å’Œé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>é€šè¿‡å¼•å…¥é€‚é…å™¨å®ç°æ§½ä½æ¡ä»¶åŒ–ï¼Œä¿ç•™æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>æ–¹æ³•é¿å…äº†æ–‡æœ¬ä¸­å¿ƒåŒ–çš„æ¡ä»¶åå·®ã€‚</li>
<li>é€šè¿‡å¼•å…¥é¢å¤–çš„æŒ‡å¯¼æŸå¤±å¢å¼ºæ¨¡å‹ä¸è¾“å…¥å›¾åƒä¸­å¯¹è±¡çš„å¯¹é½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„ç‰©ä½“å‘ç°å’Œå›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>ç‰¹åˆ«æ“…é•¿å¤„ç†å¤æ‚çœŸå®å›¾åƒçš„åˆæˆç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15878">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-58a46ebcaa30f6b754313d244022d9b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05a8b9e8034e74bb394fb6eb8b24573d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Label-Efficient-Data-Augmentation-with-Video-Diffusion-Models-for-Guidewire-Segmentation-in-Cardiac-Fluoroscopy"><a href="#Label-Efficient-Data-Augmentation-with-Video-Diffusion-Models-for-Guidewire-Segmentation-in-Cardiac-Fluoroscopy" class="headerlink" title="Label-Efficient Data Augmentation with Video Diffusion Models for   Guidewire Segmentation in Cardiac Fluoroscopy"></a>Label-Efficient Data Augmentation with Video Diffusion Models for   Guidewire Segmentation in Cardiac Fluoroscopy</h2><p><strong>Authors:Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun</strong></p>
<p>The accurate segmentation of guidewires in interventional cardiac fluoroscopy videos is crucial for computer-aided navigation tasks. Although deep learning methods have demonstrated high accuracy and robustness in wire segmentation, they require substantial annotated datasets for generalizability, underscoring the need for extensive labeled data to enhance model performance. To address this challenge, we propose the Segmentation-guided Frame-consistency Video Diffusion Model (SF-VD) to generate large collections of labeled fluoroscopy videos, augmenting the training data for wire segmentation networks. SF-VD leverages videos with limited annotations by independently modeling scene distribution and motion distribution. It first samples the scene distribution by generating 2D fluoroscopy images with wires positioned according to a specified input mask, and then samples the motion distribution by progressively generating subsequent frames, ensuring frame-to-frame coherence through a frame-consistency strategy. A segmentation-guided mechanism further refines the process by adjusting wire contrast, ensuring a diverse range of visibility in the synthesized image. Evaluation on a fluoroscopy dataset confirms the superior quality of the generated videos and shows significant improvements in guidewire segmentation. </p>
<blockquote>
<p>åœ¨ä»‹å…¥å¿ƒè„è§å…‰é€è§†è§†é¢‘ä¸­ï¼Œå¯¹å¯¼çº¿è¿›è¡Œå‡†ç¡®çš„åˆ†å‰²å¯¹äºè®¡ç®—æœºè¾…åŠ©å¯¼èˆªä»»åŠ¡è‡³å…³é‡è¦ã€‚è™½ç„¶æ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨å¯¼çº¿åˆ†å‰²æ–¹é¢å·²ç»æ˜¾ç¤ºå‡ºé«˜å‡†ç¡®åº¦å’Œç¨³å¥æ€§ï¼Œä½†å®ƒä»¬éœ€è¦å¤§è§„æ¨¡çš„æ ‡æ³¨æ•°æ®é›†æ¥å®ç°æ™®éé€‚ç”¨æ€§ï¼Œè¿™å‡¸æ˜¾äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„éœ€è¦ï¼Œä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†â€œåŸºäºåˆ†å‰²å¼•å¯¼çš„å¸§ä¸€è‡´æ€§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆSF-VDï¼‰â€ï¼Œç”¨äºç”Ÿæˆå¤§é‡æ ‡è®°çš„è§å…‰é€è§†è§†é¢‘ï¼Œå¢å¼ºå¯¼çº¿åˆ†å‰²ç½‘ç»œçš„è®­ç»ƒæ•°æ®ã€‚SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒæ¥åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨è§†é¢‘ã€‚å®ƒé€šè¿‡æ ¹æ®æŒ‡å®šçš„è¾“å…¥æ©ç ç”Ÿæˆå¸¦æœ‰å¯¼çº¿çš„äºŒç»´è§å…‰é€è§†å›¾åƒæ¥é‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œç„¶åé€šè¿‡é€æ­¥ç”Ÿæˆåç»­å¸§æ¥é‡‡æ ·è¿åŠ¨åˆ†å¸ƒï¼Œå¹¶é€šè¿‡å¸§ä¸€è‡´æ€§ç­–ç•¥ç¡®ä¿å¸§ä¸å¸§ä¹‹é—´çš„è¿è´¯æ€§ã€‚åˆ†å‰²å¼•å¯¼æœºåˆ¶è¿›ä¸€æ­¥è°ƒæ•´äº†å¯¼çº¿å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§èŒƒå›´å¤šæ ·åŒ–ã€‚åœ¨è§å…‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯å®äº†æ‰€ç”Ÿæˆè§†é¢‘çš„å“è¶Šè´¨é‡ï¼Œå¹¶æ˜¾ç¤ºå‡ºå¯¼çº¿åˆ†å‰²çš„æ˜¾è‘—æ”¹å–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16050v4">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¿ƒè„ä»‹å…¥æ‰‹æœ¯è§å…‰é€è§†è§†é¢‘ä¸­å‡†ç¡®åˆ†å‰²å¯¼ä¸å¯¹äºè®¡ç®—æœºè¾…åŠ©å¯¼èˆªä»»åŠ¡è‡³å…³é‡è¦ã€‚é’ˆå¯¹æ·±åº¦å­¦ä¹ æ–¹æ³•éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®é›†ä»¥æé«˜å¯¼ä¸åˆ†å‰²çš„æ™®éæ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å‰²å¼•å¯¼çš„å¸§ä¸€è‡´æ€§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆSF-VDï¼‰ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¤§é‡æ ‡æ³¨çš„è§å…‰é€è§†è§†é¢‘ï¼Œå¢å¼ºå¯¼ä¸åˆ†å‰²ç½‘ç»œçš„è®­ç»ƒæ•°æ®ã€‚SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒï¼Œåˆ©ç”¨æœ‰é™æ ‡æ³¨çš„è§†é¢‘è¿›è¡Œå·¥ä½œã€‚å®ƒé¦–å…ˆæ ¹æ®æŒ‡å®šçš„è¾“å…¥æ©è†œç”ŸæˆäºŒç»´è§å…‰é€è§†å›¾åƒæ¥é‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œç„¶åé€šè¿‡é€æ­¥ç”Ÿæˆåç»­å¸§æ¥é‡‡æ ·è¿åŠ¨åˆ†å¸ƒï¼Œç¡®ä¿å¸§é—´ä¸€è‡´æ€§ã€‚åˆ†å‰²å¼•å¯¼æœºåˆ¶è¿›ä¸€æ­¥è°ƒæ•´å¯¼ä¸å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§å¤šæ ·æ€§ã€‚åœ¨è§å…‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†ç”Ÿæˆè§†é¢‘çš„é«˜è´¨é‡ï¼Œå¹¶æ˜¾ç¤ºå‡ºåœ¨å¯¼ä¸åˆ†å‰²æ–¹é¢çš„æ˜¾è‘—æ”¹å–„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¼ä¸åœ¨å¿ƒè„ä»‹å…¥æ‰‹æœ¯è§å…‰é€è§†è§†é¢‘ä¸­çš„å‡†ç¡®åˆ†å‰²å¯¹è®¡ç®—æœºè¾…åŠ©å¯¼èˆªè‡³å…³é‡è¦ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•è™½èƒ½é«˜ç²¾åº¦ã€ç¨³å¥åœ°è¿›è¡Œå¯¼ä¸åˆ†å‰²ï¼Œä½†éœ€å¤§é‡æ ‡æ³¨æ•°æ®ä»¥æ”¹å–„æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æå‡ºåŸºäºåˆ†å‰²å¼•å¯¼çš„å¸§ä¸€è‡´æ€§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆSF-VDï¼‰ä»¥ç”Ÿæˆå¤§é‡æ ‡æ³¨çš„è§å…‰é€è§†è§†é¢‘ï¼Œå¢å¼ºè®­ç»ƒæ•°æ®ã€‚</li>
<li>SF-VDé€šè¿‡ç‹¬ç«‹å»ºæ¨¡åœºæ™¯åˆ†å¸ƒå’Œè¿åŠ¨åˆ†å¸ƒæ¥å·¥ä½œã€‚</li>
<li>æ¨¡å‹é€šè¿‡ç”ŸæˆäºŒç»´è§å…‰é€è§†å›¾åƒé‡‡æ ·åœºæ™¯åˆ†å¸ƒï¼Œå¹¶é€šè¿‡é€æ­¥ç”Ÿæˆåç»­å¸§æ¥ç¡®ä¿å¸§é—´ä¸€è‡´æ€§ã€‚</li>
<li>åˆ†å‰²å¼•å¯¼æœºåˆ¶è°ƒæ•´å¯¼ä¸å¯¹æ¯”åº¦ï¼Œç¡®ä¿åˆæˆå›¾åƒçš„å¯è§æ€§å¤šæ ·æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16050">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-495b0d7f8e63084a5494496228682813.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1812b9f580ab1045f66623b4f6e47d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6dfead2b062aa6a8f15edfc59eb3429.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d47112dbe22818737ff4b9362916e1d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="StableMaterials-Enhancing-Diversity-in-Material-Generation-via-Semi-Supervised-Learning"><a href="#StableMaterials-Enhancing-Diversity-in-Material-Generation-via-Semi-Supervised-Learning" class="headerlink" title="StableMaterials: Enhancing Diversity in Material Generation via   Semi-Supervised Learning"></a>StableMaterials: Enhancing Diversity in Material Generation via   Semi-Supervised Learning</h2><p><strong>Authors:Giuseppe Vecchio</strong></p>
<p>We introduce StableMaterials, a novel approach for generating photorealistic physical-based rendering (PBR) materials that integrate semi-supervised learning with Latent Diffusion Models (LDMs). Our method employs adversarial training to distill knowledge from existing large-scale image generation models, minimizing the reliance on annotated data and enhancing the diversity in generation. This distillation approach aligns the distribution of the generated materials with that of image textures from an SDXL model, enabling the generation of novel materials that are not present in the initial training dataset. Furthermore, we employ a diffusion-based refiner model to improve the visual quality of the samples and achieve high-resolution generation. Finally, we distill a latent consistency model for fast generation in just four steps and propose a new tileability technique that removes visual artifacts typically associated with fewer diffusion steps. We detail the architecture and training process of StableMaterials, the integration of semi-supervised training within existing LDM frameworks and show the advantages of our approach. Comparative evaluations with state-of-the-art methods show the effectiveness of StableMaterials, highlighting its potential applications in computer graphics and beyond. StableMaterials is publicly available at <a target="_blank" rel="noopener" href="https://gvecchio.com/stablematerials">https://gvecchio.com/stablematerials</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†StableMaterialsï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™ç”Ÿæˆçš„æ–°å‹æ–¹æ³•ï¼Œå®ƒå°†åŠç›‘ç£å­¦ä¹ ä¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ç›¸ç»“åˆã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨å¯¹æŠ—è®­ç»ƒä»ç°æœ‰çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­æç‚¼çŸ¥è¯†ï¼Œå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¹¶å¢å¼ºç”Ÿæˆçš„å¤šæ ·æ€§ã€‚è¿™ç§æç‚¼æ–¹æ³•ä½¿ç”Ÿæˆææ–™çš„åˆ†å¸ƒä¸SDXLæ¨¡å‹ä¸­çš„å›¾åƒçº¹ç†åˆ†å¸ƒç›¸ä¸€è‡´ï¼Œèƒ½å¤Ÿç”Ÿæˆåˆå§‹è®­ç»ƒæ•°æ®é›†ä¸­ä¸å­˜åœ¨çš„æ–°ææ–™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºæ‰©æ•£çš„ç»†åŒ–æ¨¡å‹æ¥æé«˜æ ·æœ¬çš„è§†è§‰è´¨é‡ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ç”Ÿæˆã€‚æœ€åï¼Œæˆ‘ä»¬æç‚¼äº†ä¸€ä¸ªæ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ï¼Œåªéœ€å››ä¸ªæ­¥éª¤å³å¯å¿«é€Ÿç”Ÿæˆï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å¯å¹³é“ºæŠ€æœ¯ï¼Œæ¶ˆé™¤äº†ç”±äºè¾ƒå°‘çš„æ‰©æ•£æ­¥éª¤è€Œé€šå¸¸å‡ºç°çš„è§†è§‰ä¼ªå½±ã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†StableMaterialsçš„æ¶æ„å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œä»¥åŠåœ¨ç°æœ‰LDMæ¡†æ¶å†…åŠç›‘ç£è®­ç»ƒçš„é›†æˆï¼Œå±•ç¤ºäº†æˆ‘ä»¬çš„ä¼˜åŠ¿ã€‚ä¸æœ€æ–°æ–¹æ³•çš„æ¯”è¾ƒè¯„ä¼°è¡¨æ˜ï¼ŒStableMaterialsæ˜¯æœ‰æ•ˆçš„ï¼Œçªå‡ºäº†å…¶åœ¨è®¡ç®—æœºå›¾å½¢ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚StableMaterialså¯åœ¨<a target="_blank" rel="noopener" href="https://gvecchio.com/stablematerials%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://gvecchio.com/stablematerialså…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.09293v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>StableMaterialsæ˜¯ä¸€ç§ç»“åˆåŠç›‘ç£å­¦ä¹ ä¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼ŒLDMï¼‰ç”ŸæˆçœŸå®ç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¯¹æŠ—è®­ç»ƒä»ç°æœ‰å¤§è§„æ¨¡å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­æç‚¼çŸ¥è¯†ï¼Œå‡å°‘äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜äº†ç”Ÿæˆçš„å¤šæ ·æ€§ã€‚é€šè¿‡è’¸é¦æ–¹æ³•ä¸SDXLæ¨¡å‹å›¾åƒçº¹ç†çš„åˆ†å¸ƒå¯¹é½ï¼Œç”Ÿæˆä¸å­˜åœ¨äºåˆå§‹è®­ç»ƒé›†ä¸­çš„æ–°ææ–™ã€‚æ­¤å¤–ï¼Œä½¿ç”¨åŸºäºæ‰©æ•£çš„ç»†åŒ–æ¨¡å‹æé«˜æ ·æœ¬çš„è§†è§‰è´¨é‡ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ç”Ÿæˆã€‚æœ€åï¼Œæˆ‘ä»¬æç‚¼äº†ä¸€ä¸ªå…·æœ‰å¿«é€Ÿå››æ­¥ç”Ÿæˆèƒ½åŠ›çš„æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ï¼Œå¹¶æå‡ºä¸€ç§æ–°çš„å»ç“¦æŠ€æœ¯ï¼Œæ¶ˆé™¤äº†å› å‡å°‘æ‰©æ•£æ­¥éª¤è€Œäº§ç”Ÿçš„å…¸å‹è§†è§‰ä¼ªå½±ã€‚StableMaterialsçš„ä¼˜åŠ¿åœ¨äºå…¶æ¶æ„å’Œè®­ç»ƒè¿‡ç¨‹çš„ç»†èŠ‚ï¼Œä»¥åŠå…¶åœ¨è®¡ç®—æœºå›¾å½¢ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StableMaterialsç»“åˆäº†åŠç›‘ç£å­¦ä¹ ä¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ç”ŸæˆçœŸå®ç‰©ç†æ¸²æŸ“ï¼ˆPBRï¼‰ææ–™ã€‚</li>
<li>é€šè¿‡å¯¹æŠ—è®­ç»ƒä»å¤§è§„æ¨¡å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­æç‚¼çŸ¥è¯†ï¼Œå‡å°‘æ ‡æ³¨æ•°æ®ä¾èµ–å¹¶æé«˜ç”Ÿæˆå¤šæ ·æ€§ã€‚</li>
<li>ç”Ÿæˆçš„ææ–™ä¸SDXLæ¨¡å‹å›¾åƒçº¹ç†åˆ†å¸ƒå¯¹é½ï¼Œèƒ½ç”Ÿæˆåˆå§‹è®­ç»ƒé›†ä¸­ä¸å­˜åœ¨çš„æ–°ææ–™ã€‚</li>
<li>ä½¿ç”¨åŸºäºæ‰©æ•£çš„ç»†åŒ–æ¨¡å‹æé«˜æ ·æœ¬çš„è§†è§‰è´¨é‡ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ç”Ÿæˆã€‚</li>
<li>æç‚¼äº†ä¸€ä¸ªå¿«é€Ÿå››æ­¥ç”Ÿæˆçš„æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ã€‚</li>
<li>æå‡ºæ–°çš„å»ç“¦æŠ€æœ¯ï¼Œæ¶ˆé™¤å› å‡å°‘æ‰©æ•£æ­¥éª¤è€Œäº§ç”Ÿçš„è§†è§‰ä¼ªå½±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.09293">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-523c9d09a7c66eb768087b2d5c8259a2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-effc1adb54fabc2a31187d6324d4ef4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-840a9b20e6b27aa78038176d6b15e57a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df03359706f47abcb521bd41373db8e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e5f30ac883811912e4dba1d2724ef4b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2208dc6c1b22c16cef30efe6649ac00e.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-30  Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain   Research
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-71fd8ac1e8219487b111cd2d07631692.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-30  LinPrim Linear Primitives for Differentiable Volumetric Rendering
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
