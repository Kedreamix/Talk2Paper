<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="医学图像">
    <meta name="description" content="医学图像 方向最新论文已更新，请持续关注 Update in 2025-01-30  Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain   Research">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>医学图像 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2208dc6c1b22c16cef30efe6649ac00e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">医学图像</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">医学图像</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                医学图像
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    10.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    42 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-01-30-更新"><a href="#2025-01-30-更新" class="headerlink" title="2025-01-30 更新"></a>2025-01-30 更新</h1><h2 id="Sensitivity-of-Quantitative-Susceptibility-Mapping-in-Clinical-Brain-Research"><a href="#Sensitivity-of-Quantitative-Susceptibility-Mapping-in-Clinical-Brain-Research" class="headerlink" title="Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain   Research"></a>Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain   Research</h2><p><strong>Authors:Fahad Salman, Abhisri Ramesh, Thomas Jochmann, Mirjam Prayer, Ademola Adegbemigun, Jack A. Reeves, Gregory E. Wilding, Junghun Cho, Dejan Jakimovski, Niels Bergsland, Michael G. Dwyer, Robert Zivadinov, Ferdinand Schweser</strong></p>
<p>Background: Quantitative susceptibility mapping (QSM) of the brain is an advanced MRI technique for assessing tissue characteristics based on magnetic susceptibility, which varies with the composition of the tissue, such as iron, calcium, and myelin levels. QSM consists of multiple processing steps, with various choices for each step. Despite its increasing application in detecting and monitoring neurodegenerative diseases, the impact of algorithmic choices in QSM’s workflow on clinical outcomes has not been thoroughly quantified.   Objective: This study aimed to evaluate how choices in background field removal (BFR), dipole inversion algorithms, and anatomical referencing impact the sensitivity and reproducibility error of QSM in detecting group-level and longitudinal changes in deep gray matter susceptibility in a clinical setting.   Methods: We compared 378 different QSM pipelines using a 10-year follow-up dataset of healthy adults. We analyzed the sensitivity of pipelines to detect known aging-related susceptibility changes in the DGM over time.   Results: We found high variability in the sensitivity of QSM pipelines to detect susceptibility changes. The study highlighted that while most pipelines could detect changes reliably, the choice of BFR algorithm and the referencing strategy substantially influenced the outcome reproducibility error and sensitivity. Notably, pipelines using RESHARP with AMP-PE, HEIDI or LSQR inversion showed the highest overall sensitivity.   Conclusions: The findings underscore the critical influence of algorithmic choices in QSM processing on the accuracy and reliability of detecting physiological changes in the brain. This has profound implications for clinical research and trials where QSM is used as a biomarker for disease progression, highlighting that careful consideration should be given to pipeline configuration to optimize clinical outcomes. </p>
<blockquote>
<p>背景：脑定量敏感性映射（QSM）是一种基于磁化率的组织特性评估的高级MRI技术。这种技术会随着组织的成分（如铁、钙和髓磷脂水平）而变化。QSM包含多个处理步骤，每个步骤都有多种选择。尽管其在检测神经退行性疾病方面的应用日益广泛，但QSM工作流中算法选择对临床结果的影响尚未得到充分的量化评估。</p>
</blockquote>
<p>目的：本研究旨在评估背景场移除（BFR）、偶极反转算法和解剖参照的选择对QSM检测临床环境中深层灰质群体水平和纵向变化的敏感性以及重现性误差的影响。</p>
<p>方法：我们使用健康成年人的10年随访数据集，对比了378种不同的QSM管道。我们分析了管道对检测已知与衰老相关的DGM易感性变化的敏感性。</p>
<p>结果：我们发现QSM管道检测易感性变化的敏感性存在很大差异。研究表明，虽然大多数管道都能可靠地检测到变化，但BFR算法和参照策略的选择对结果的重现性误差和敏感性有着显著影响。值得注意的是，使用RESHARP与AMP-PE、HEIDI或LSQR反转的管道表现出最高的总体敏感性。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17158v1">PDF</a> </p>
<p><strong>Summary</strong><br>     本研究探讨了定量磁化率成像（QSM）中背景场移除（BFR）、偶极反转算法和解剖参照的选择对检测深层灰质磁化率变化的敏感性及重现性误差的影响。研究指出，不同算法的选择对QSM检测生理变化结果的准确性和可靠性具有重要影响，特定算法组合展现较高灵敏度。这对使用QSM作为疾病进展生物标志物的临床研究与试验具有重要意义。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QSM是一种基于磁化率评估脑组织特性的高级MRI技术，该技术通过不同组织成分（如铁、钙和髓磷脂）的磁化率变化进行成像。</li>
<li>QSM工作流程中的算法选择会对临床结果产生影响，但这一影响尚未被全面量化。</li>
<li>研究通过对健康成年人进行长达十年的随访数据集比较了378种不同的QSM管道。</li>
<li>在检测已知与衰老相关的磁化率变化方面，QSM管道的敏感性存在很大差异。</li>
<li>BFR算法和参照策略的选择对结果的可靠性和敏感性有显著影响。</li>
<li>使用特定算法组合（如RESHARP与AMP-PE、HEIDI或LSQR反转）的管道展现出最高的总体灵敏度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17158">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2678af8844966e436be73fa291e1ac79.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Three-Dimensional-Diffusion-Weighted-Multi-Slab-MRI-With-Slice-Profile-Compensation-Using-Deep-Energy-Model"><a href="#Three-Dimensional-Diffusion-Weighted-Multi-Slab-MRI-With-Slice-Profile-Compensation-Using-Deep-Energy-Model" class="headerlink" title="Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile   Compensation Using Deep Energy Model"></a>Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile   Compensation Using Deep Energy Model</h2><p><strong>Authors:Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani</strong></p>
<p>Three-dimensional (3D) multi-slab acquisition is a technique frequently employed in high-resolution diffusion-weighted MRI in order to achieve the best signal-to-noise ratio (SNR) efficiency. However, this technique is limited by slab boundary artifacts that cause intensity fluctuations and aliasing between slabs which reduces the accuracy of anatomical imaging. Addressing this issue is crucial for advancing diffusion MRI quality and making high-resolution imaging more feasible for clinical and research applications. In this work, we propose a regularized slab profile encoding (PEN) method within a Plug-and-Play ADMM framework, incorporating multi-scale energy (MuSE) regularization to effectively improve the slab combined reconstruction. Experimental results demonstrate that the proposed method significantly improves image quality compared to non-regularized and TV-regularized PEN approaches. The regularized PEN framework provides a more robust and efficient solution for high-resolution 3D diffusion MRI, potentially enabling clearer, more reliable anatomical imaging across various applications. </p>
<blockquote>
<p>三维（3D）多薄层采集技术是高分辨率扩散加权MRI中经常采用的一种技术，以实现最佳信噪比（SNR）效率。然而，该技术受限于薄层边界伪影，导致薄层之间的强度波动和混叠，从而降低了结构成像的准确性。解决这一问题对于提高扩散MRI质量以及使高分辨率成像在临床和研究应用中更加可行至关重要。在这项工作中，我们在Plug-and-Play ADMM框架内提出了一种正则化薄层轮廓编码（PEN）方法，采用多尺度能量（MuSE）正则化，以有效提高薄层组合重建的效果。实验结果表明，与未正则化和TV正则化的PEN方法相比，所提出的方法显著提高了图像质量。正则化的PEN框架为高分屛的三维扩散MRI提供了更稳健和高效的解决方案，有望在各种应用中实现更清晰、更可靠的结构成像。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17152v1">PDF</a> 4 pages, 4 figures, ISBI2025 Conference paper</p>
<p><strong>Summary</strong><br>     三维多层面采集在高分辨率扩散加权MRI中常用来实现最佳的信噪比效率，但受限于层面边界伪影，导致层面间强度波动和混叠，降低了成像准确性。本研究提出一种基于Plug-and-Play ADMM框架的正则化层面轮廓编码（PEN）方法，采用多尺度能量（MuSE）正则化有效提高层面组合重建效果。实验结果表明，该方法相较于非正则化和TV正则化的PEN方法能显著提高图像质量，为各种应用提供更清晰、更可靠的解剖图像。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>三维多层面采集在扩散加权MRI中重要，但受层面边界伪影限制。</li>
<li>层面边界伪影导致强度波动和混叠，降低成像准确性。</li>
<li>提出一种基于Plug-and-Play ADMM框架的正则化PEN方法。</li>
<li>采用多尺度能量（MuSE）正则化提高层面组合重建效果。</li>
<li>实验结果表明，该方法能显著提高图像质量。</li>
<li>正则化PEN方法为高分辨率3D扩散MRI提供更稳健、高效的解决方案。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17152">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c749b0f88f8ffcacc3cf839911aac13d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bebc17566ccc64fd62af955f94643786.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7fa46c6f63c0e80bace53a420bf8ded.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54a07fa7a7b0bd1082f7c7e27dcfbbe2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="FedEFM-Federated-Endovascular-Foundation-Model-with-Unseen-Data"><a href="#FedEFM-Federated-Endovascular-Foundation-Model-with-Unseen-Data" class="headerlink" title="FedEFM: Federated Endovascular Foundation Model with Unseen Data"></a>FedEFM: Federated Endovascular Foundation Model with Unseen Data</h2><p><strong>Authors:Tuong Do, Nghia Vu, Tudor Jianu, Baoru Huang, Minh Vu, Jionglong Su, Erman Tjiputra, Quang D. Tran, Te-Chuan Chiu, Anh Nguyen</strong></p>
<p>In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover’s Distance within a knowledge distillation framework. Once trained, our foundation model’s weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain. </p>
<blockquote>
<p>在血管内手术中，X光图像中对导管和导丝的精确识别对于降低干预风险至关重要。然而，由于标记数据的有限可用性，准确分割导管和导丝结构具有挑战性。基础模型通过收集类似领域的数据来训练模型，其权重可以进行微调以适应下游任务，因此提供了一种有前途的解决方案。然而，大规模的数据收集用于训练受到保持患者隐私的制约。本文提出了一种在分散的联邦学习环境中训练基础模型的新方法，用于血管内干预。为了确保训练的可行性，我们采用知识蒸馏框架内的可微分的地球移动者距离来解决未见数据的问题。一旦训练完成，我们的基础模型的权重为下游任务提供了有价值的初始化，从而提高了任务特定性能。密集的实验表明，我们的方法取得了最新的最先进的成果，为血管内干预和机器人辅助血管内手术的发展做出了贡献，同时解决了医疗领域数据共享的关键问题。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16992v1">PDF</a> 8 pages. Accepted to ICRA 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出在分布式联邦学习环境中训练基础模型的新方法，用于血管内介入手术。为解决训练过程中未见数据的问题，采用可微分的Earth Mover’s Distance在知识蒸馏框架内进行处理。训练后的基础模型权重为下游任务提供有价值的初始化，从而提高任务特定性能。实验证明，该方法达到最新水平，促进血管内介入和机器人辅助血管内手术的发展，同时解决医疗领域数据共享的关键问题。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>在血管内手术中，X光影像中精确识别导管和导丝对降低干预风险至关重要。</li>
<li>准确分割导管和导丝结构具有挑战性，因为缺乏标记数据。</li>
<li>基础模型通过收集类似领域的数据来训练模型，其权重可以进行微调以适应下游任务，为解决上述问题提供了有前景的解决方案。</li>
<li>论文提出在分布式联邦学习环境中训练基础模型的新方法，适用于血管内介入治疗。</li>
<li>为确保训练的可行性，采用可微分的Earth Mover’s Distance在知识蒸馏框架内解决未见数据的问题。</li>
<li>训练后的基础模型权重为下游任务提供有价值的初始化，从而提高任务性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16992">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0b7eaf5ed17355d274812ab0c1d403c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba3f6a314b344e7b8368c7106a39bf79.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d4108357f09f55c652a82c4f1c63385.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ec9eafa4473a643d2f2b1193196c9144.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-69d125d3c69fe8c38f7589c1915001fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fce2d1c49e883478b58223326613c109.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-555fa28e2b8583d49c1c1f99a4605730.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6ab1114ca6f07b4250b7b37ba6703531.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Dynamic-Hypergraph-Representation-for-Bone-Metastasis-Cancer-Analysis"><a href="#Dynamic-Hypergraph-Representation-for-Bone-Metastasis-Cancer-Analysis" class="headerlink" title="Dynamic Hypergraph Representation for Bone Metastasis Cancer Analysis"></a>Dynamic Hypergraph Representation for Bone Metastasis Cancer Analysis</h2><p><strong>Authors:Yuxuan Chen, Jiawen Li, Huijuan Shi, Yang Xu, Tian Guan, Lianghui Zhu, Yonghong He, Anjia Han</strong></p>
<p>Bone metastasis analysis is a significant challenge in pathology and plays a critical role in determining patient quality of life and treatment strategies. The microenvironment and specific tissue structures are essential for pathologists to predict the primary bone cancer origins and primary bone cancer subtyping. By digitizing bone tissue sections into whole slide images (WSIs) and leveraging deep learning to model slide embeddings, this analysis can be enhanced. However, tumor metastasis involves complex multivariate interactions with diverse bone tissue structures, which traditional WSI analysis methods such as multiple instance learning (MIL) fail to capture. Moreover, graph neural networks (GNNs), limited to modeling pairwise relationships, are hard to represent high-order biological associations. To address these challenges, we propose a dynamic hypergraph neural network (DyHG) that overcomes the edge construction limitations of traditional graph representations by connecting multiple nodes via hyperedges. A low-rank strategy is used to reduce the complexity of parameters in learning hypergraph structures, while a Gumbel-Softmax-based sampling strategy optimizes the patch distribution across hyperedges. An MIL aggregator is then used to derive a graph-level embedding for comprehensive WSI analysis. To evaluate the effectiveness of DyHG, we construct two large-scale datasets for primary bone cancer origins and subtyping classification based on real-world bone metastasis scenarios. Extensive experiments demonstrate that DyHG significantly outperforms state-of-the-art (SOTA) baselines, showcasing its ability to model complex biological interactions and improve the accuracy of bone metastasis analysis. </p>
<blockquote>
<p>骨转移分析是病理学领域的一个重大挑战，对于确定患者的生活质量和治疗策略起着至关重要的作用。病理学家预测原发性骨癌的起源和原发性骨癌亚型时，微环境和特定的组织结构都是至关重要的。通过将骨组织切片数字化为全切片图像（WSIs）并利用深度学习来构建幻灯片嵌入，可以增强这种分析。然而，肿瘤转移涉及与多种骨组织结构的复杂多元交互，传统的WSI分析方法（如多实例学习（MIL））无法捕捉到这一点。此外，图神经网络（GNNs）受限于建模二元关系，难以表示高阶生物关联。为了解决这些挑战，我们提出了一种动态超图神经网络（DyHG），它通过超边连接多个节点，克服了传统图表示在构建边缘上的局限性。利用低秩策略降低学习超图结构参数的复杂性，而基于Gumbel-Softmax的采样策略优化了超边之间的斑块分布。然后，使用MIL聚合器推导图级嵌入，用于全面的WSI分析。为了评估DyHG的有效性，我们构建了两个大规模数据集，用于基于现实世界的骨转移情景进行原发性骨癌起源和分型分类。大量实验表明，DyHG显著优于最新技术水平的基线方法，展示了其建模复杂生物交互和提高骨转移分析准确性的能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16787v1">PDF</a> 12 pages,11 figures</p>
<p><strong>Summary</strong></p>
<p>本文提出了一个动态超图神经网络（DyHG）模型，用于解决病理学中骨转移分析面临的挑战。该模型通过构建超图来克服传统图表示的边缘构建限制，并采用了低阶策略来降低学习超图结构的参数复杂性。此外，使用基于Gumbel-Softmax的采样策略优化超边中的补丁分布，并结合多实例聚合器进行全幻灯片级别的分析。实验证明，DyHG在原发性骨癌起源和分型分类方面显著优于现有方法，展现了其处理复杂生物学交互和改进骨转移分析准确性的能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>骨转移分析在病理学中是一项重要挑战，涉及预测骨癌起源和分型。</li>
<li>传统WSI分析方法（如多实例学习）无法捕捉复杂的骨转移多元交互。</li>
<li>图神经网络受限于建模二元关系，难以表示高阶生物关联。</li>
<li>提出的动态超图神经网络（DyHG）通过构建超图克服这些限制。</li>
<li>DyHG使用低阶策略学习超图结构，优化补丁分布并使用多实例聚合进行WSI分析。</li>
<li>DyHG在基于真实世界骨转移场景的骨癌起源和分型分类方面表现出显著优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16787">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8b069b552edc916dfbc3cf4575eb926a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-129f5e20f4a6f640b1cb93e095393540.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d72781676105ef97b355c64f63c0705.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5bafaa6542b4406e21b64c7c68da5f7d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BASS-XLV-Quantifying-AGN-Selection-Effects-in-the-Chandra-COSMOS-Legacy-Survey-with-BASS"><a href="#BASS-XLV-Quantifying-AGN-Selection-Effects-in-the-Chandra-COSMOS-Legacy-Survey-with-BASS" class="headerlink" title="BASS XLV: Quantifying AGN Selection Effects in the Chandra COSMOS-Legacy   Survey with BASS"></a>BASS XLV: Quantifying AGN Selection Effects in the Chandra COSMOS-Legacy   Survey with BASS</h2><p><strong>Authors:Yarone M. Tokayer, Michael J. Koss, C. Megan Urry, Priyamvada Natarajan, Richard Mushotzky, Mislav Balokovic, Franz E. Bauer, Peter Boorman, Alessandro Peca, Claudio Ricci, Federica Ricci, Daniel Stern, Ezequiel Treister, Benny Trakhtenbrot</strong></p>
<p>Deep extragalactic X-ray surveys, such as the Chandra COSMOS-Legacy field (CCLS), are prone to be biased against active galactic nuclei (AGN) with high column densities due to their lower count rates at a given luminosity. To quantify this selection effect, we forward model nearby ($z\sim0.05$) AGN from the BAT AGN Spectroscopic Survey (BASS) with well-characterized ($\gtrsim$1000 cts) broadband X-ray spectra (0.5-195 keV) to simulate the CCLS absorption distribution. We utilize the BASS low-redshift analogs with similar luminosities to the CCLS ($L_\mathrm{2-10\ keV}^\mathrm{int}\sim10^{42-45}\ \mathrm{erg}\ \mathrm{s}^{-1}$), which are much less affected by obscuration and low-count statistics, as the seed for our simulations, and follow the spectral fitting of the CCLS. Our simulations reveal that Chandra would fail to detect the majority (53.3%; 563&#x2F;1056) of obscured ($N_\mathrm{H}&gt;10^{22}\ \mathrm{cm}^{-2}$) simulated BASS AGN given the observed redshift and luminosity distribution of the CCLS. Even for detected sources with sufficient counts ($\geq30$) for spectral modeling, the level of obscuration is significantly overestimated. This bias is most extreme for objects whose best fit indicates a high-column density AGN ($N_\mathrm{H}\geq10^{24}\ \mathrm{cm}^{-2}$), since the majority (66.7%; 18&#x2F;27) of these are actually unobscured sources ($N_\mathrm{H}&lt;10^{22}\ \mathrm{cm}^{-2}$). This implies that previous studies may have significantly overestimated the increase in the obscured fraction with redshift and the fraction of luminous obscured AGN. Our findings highlight the importance of directly considering obscuration biases and forward modeling in X-ray surveys, as well as the need for higher-sensitivity X-ray missions such as the Advanced X-ray Imaging Satellite (AXIS), and the importance of multi-wavelength indicators to estimate obscuration in distant supermassive black holes. </p>
<blockquote>
<p>深度星系外X射线调查，如钱德拉宇宙学大尺度结构（CCLS）调查，由于给定光度下的计数率较低，容易对高柱密度活动星系核（AGN）产生偏见。为了量化这种选择效应，我们利用BAT AGN光谱调查（BASS）附近的（z~0.05）且特征明显的（≥1000个计数）宽频X射线光谱（0.5-195 keV）来模拟CCLS吸收分布。我们利用BASS的低红移类似物作为模拟的种子，这些类似物的光度与CCLS相似（L_int_2-10\ keV~~介于10^42至10^45之间），受遮蔽和低计数统计的影响较小，然后跟随CCLS的光谱拟合。我们的模拟表明，鉴于CCLS观测到的红移和光度分布，钱德拉将无法检测到大多数（53.3%；563&#x2F;1056）遮蔽的（NH&gt; 10^22 cm^-2）模拟BASS AGN。即使对于具有足够计数（≥30）进行光谱建模的已检测源，遮蔽程度也被大大高估了。对于最佳拟合指示高柱密度（NH≥ 10^24 cm^-2）的天体，这种偏见最为极端，因为大多数（占66.7%；有半数以上的星系属于未被遮蔽的情况。这暗示之前的许多研究可能已经显著高估了遮蔽比例随红移的增加以及高光度遮蔽星系的比例。我们的研究强调了直接考虑遮蔽偏见和正向建模的重要性。因此需要根据具体情况，设立适应性较强的太空调查机构来改善对未来深远高灵空间星座事件的正确统计、调研估算甚至推举等方法具有理论支持和评估提升价值的宝贵思路也渐受瞩目。，而更为敏感的X射线任务例如先进X射线成像卫星(AXIS)的必要性则变得更为迫切凸显其必要性以及应用多重波长指标在估算遥远超大质量黑洞遮蔽中的重要性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16708v1">PDF</a> 32 pages, 20 figures. Accepted for publication in The Astrophysical   Journal</p>
<p><strong>摘要</strong><br>     针对深远的银河系外X射线巡天观测如CCLS存在高柱密度活动星系核（AGNs）的选择偏见问题，我们通过模拟研究评估了这一选择效应。利用BASS低红移类似天体的宽带X射线光谱进行模拟，模拟样本与CCLS类似光度范围内的天体相似，受遮蔽影响较小且低计数统计更少。模拟显示，对于给定CCLS观测到的红移和光度分布的遮蔽模拟BASS AGN（柱密度大于$ 10^{22}\ \mathrm{cm}^{-2}$ ），Chandra将遗漏多数（约半数以上）。即使在具有足够计数（大于或等于30）进行光谱建模的检测源中，遮蔽程度的估计也偏高。对于最佳拟合显示高柱密度AGNs（柱密度大于或等于$ 10^{24}\ \mathrm{cm}^{-2}$ ）的对象，这种偏见尤为极端，其中大多数（约三分之二）实际上为未遮蔽源（柱密度小于$ 10^{22}\ \mathrm{cm}^{-2}$）。这意味着之前的研究可能显著高估了随红移变化的遮蔽部分增加情况和遮蔽型高光度AGNs的比例。我们的研究结果强调了直接考虑遮蔽偏见和前向建模对X射线调查的重要性，强调了更灵敏的X射线任务（如AXIS卫星）的重要性以及通过多波长指标来估计遥远超大质量黑洞遮蔽的必要性。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>深远的银河系外X射线巡天观测如CCLS存在对高柱密度活动星系核（AGNs）的选择偏见问题。</li>
<li>模拟研究表明，给定CCLS观测到的红移和光度分布，多数遮蔽型BASS AGN将被遗漏。</li>
<li>即使考虑到足够的计数用于光谱建模的遮蔽型源中，估计的遮蔽程度也可能偏高。</li>
<li>存在严重的对高柱密度AGNs的偏见：大多数被认为是高柱密度的源实际上并非如此。</li>
<li>之前的研究可能高估了随红移变化的遮蔽部分增加情况和遮蔽型高光度AGNs的比例。</li>
<li>在X射线调查中需要直接考虑遮蔽偏见并进行前向建模。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16708">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bb374898273f55f32751051d6d3bd918.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5083badb80b0163b373b7afcd00382ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-115dfb8db9cfa90b53b1f2448d6ab0f9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb0262a16cc1522ded24535f3821ab0c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CSPCL-Category-Semantic-Prior-Contrastive-Learning-for-Deformable-DETR-Based-Prohibited-Item-Detectors"><a href="#CSPCL-Category-Semantic-Prior-Contrastive-Learning-for-Deformable-DETR-Based-Prohibited-Item-Detectors" class="headerlink" title="CSPCL: Category Semantic Prior Contrastive Learning for Deformable   DETR-Based Prohibited Item Detectors"></a>CSPCL: Category Semantic Prior Contrastive Learning for Deformable   DETR-Based Prohibited Item Detectors</h2><p><strong>Authors:Mingyuan Li, Tong Jia, Hui Lu, Bowen Ma, Hao Wang, Dongyue Chen</strong></p>
<p>Prohibited item detection based on X-ray images is one of the most effective security inspection methods. However, the foreground-background feature coupling caused by the overlapping phenomenon specific to X-ray images makes general detectors designed for natural images perform poorly. To address this issue, we propose a Category Semantic Prior Contrastive Learning (CSPCL) mechanism, which aligns the class prototypes perceived by the classifier with the content queries to correct and supplement the missing semantic information responsible for classification, thereby enhancing the model sensitivity to foreground features.To achieve this alignment, we design a specific contrastive loss, CSP loss, which includes Intra-Class Truncated Attraction (ITA) loss and Inter-Class Adaptive Repulsion (IAR) loss, and outperforms classic N-pair loss and InfoNCE loss. Specifically, ITA loss leverages class prototypes to attract intra-class category-specific content queries while preserving necessary distinctiveness. IAR loss utilizes class prototypes to adaptively repel inter-class category-specific content queries based on the similarity between class prototypes, helping disentangle features of similar categories.CSPCL is general and can be easily integrated into Deformable DETR-based models. Extensive experiments on the PIXray and OPIXray datasets demonstrate that CSPCL significantly enhances the performance of various state-of-the-art models without increasing complexity.The code will be open source once the paper is accepted. </p>
<blockquote>
<p>基于X射线图像的违禁品检测是最有效的安全检查方法之一。然而，X射线图像特有的重叠现象导致的前景背景特征耦合，使得为自然图像设计的通用检测器表现不佳。为了解决这一问题，我们提出了一种类别语义先验对比学习（CSPCL）机制，该机制将分类器感知的类别原型与内容查询对齐，以修正和补充负责分类的缺失语义信息，从而提高模型对前景特征的敏感性。为了实现这种对齐，我们设计了一种特定的对比损失，即CSP损失，它包括类内截断吸引（ITA）损失和类间自适应排斥（IAR）损失，并优于经典的N-pair损失和InfoNCE损失。具体而言，ITA损失利用类别原型来吸引类内特定的内容查询，同时保持必要的区分性。IAR损失则利用类别原型，根据类别原型之间的相似性，自适应地排斥类间特定的内容查询，有助于解开相似类别的特征。CSPCL是通用的，可以轻松地集成到基于可变形DETR的模型中。在PIXray和OPIXray数据集上的大量实验表明，CSPCL能显著提高各种最新模型的性能，且不会增加复杂性。论文被接受后，代码将开源。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16665v1">PDF</a> 10 pages</p>
<p><strong>Summary</strong></p>
<p>基于X光图像的违禁品检测是安全检测中最有效的方法之一。针对X光图像特有的重叠现象导致的前景背景特征耦合问题，通用自然图像检测器表现不佳。为此，我们提出了类别语义先验对比学习（CSPCL）机制，通过使分类器感知的类别原型与内容查询对齐，修正并补充缺失的语义信息，提高模型对前景特征的敏感性。为实现这一对齐，我们设计了特定的对比损失CSP损失，包括类内截断吸引（ITA）损失和类间自适应排斥（IAR）损失，且表现优于经典的N-pair损失和InfoNCE损失。CSPCL机制通用性强，可轻松融入基于可变形DETR的模型。在PIXray和OPIXray数据集上的大量实验表明，CSPCL可显著提高各种最新模型的性能，且不会增加复杂性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>X光图像违禁品检测是安全检测的重要方法。</li>
<li>X光图像中的前景背景特征耦合问题导致通用检测器效果不佳。</li>
<li>提出了CSPCL机制，通过类别语义先验对比学习提高模型对前景特征的敏感性。</li>
<li>CSPCL机制包括ITA损失和IAR损失，优于N-pair损失和InfoNCE损失。</li>
<li>ITA损失通过类原型吸引同类特定内容查询，保持必要差异性。</li>
<li>IAR损失根据类原型之间的相似性，自适应排斥不同类别特定内容查询，有助于解开相似类别的特征。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16665">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bed4ee070a64f858abd6864a293e39af.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aeb165bf600891693825c9b10031f3f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06ccb61d533c95c4389fd68d7213e2d6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b39de73e0c24a1b3080e8c5b508e721.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Multi-Objective-Deep-Learning-based-Biomechanical-Deformable-Image-Registration-with-MOREA"><a href="#Multi-Objective-Deep-Learning-based-Biomechanical-Deformable-Image-Registration-with-MOREA" class="headerlink" title="Multi-Objective Deep-Learning-based Biomechanical Deformable Image   Registration with MOREA"></a>Multi-Objective Deep-Learning-based Biomechanical Deformable Image   Registration with MOREA</h2><p><strong>Authors:Georgios Andreadis, Eduard Ruiz Munné, Thomas H. W. Bäck, Peter A. N. Bosman, Tanja Alderliesten</strong></p>
<p>When choosing a deformable image registration (DIR) approach for images with large deformations and content mismatch, the realism of found transformations often needs to be traded off against the required runtime. DIR approaches using deep learning (DL) techniques have shown remarkable promise in instantly predicting a transformation. However, on difficult registration problems, the realism of these transformations can fall short. DIR approaches using biomechanical, finite element modeling (FEM) techniques can find more realistic transformations, but tend to require much longer runtimes. This work proposes the first hybrid approach to combine them, with the aim of getting the best of both worlds. This hybrid approach, called DL-MOREA, combines a recently introduced multi-objective DL-based DIR approach which leverages the VoxelMorph framework, called DL-MODIR, with MOREA, an evolutionary algorithm-based, multi-objective DIR approach in which a FEM-like biomechanical mesh transformation model is used. In our proposed hybrid approach, the DL results are used to smartly initialize MOREA, with the aim of more efficiently optimizing its mesh transformation model. We empirically compare DL-MOREA against its components, DL-MODIR and MOREA, on CT scan pairs capturing large bladder filling differences of 15 cervical cancer patients. While MOREA requires a median runtime of 45 minutes, DL-MOREA can already find high-quality transformations after 5 minutes. Compared to the DL-MODIR transformations, the transformations found by DL-MOREA exhibit far less folding and improve or preserve the bladder contour distance error. </p>
<blockquote>
<p>在选择具有大变形和内容不匹配图像的形变图像配准（DIR）方法时，所找到的变换的真实性通常需要与所需的运行时间进行权衡。使用深度学习（DL）技术的DIR方法在预测变换方面显示出巨大的潜力。然而，在复杂的注册问题上，这些变换的真实性可能会不足。使用生物力学、有限元建模（FEM）技术的DIR方法可以找到更真实的变换，但往往需要的运行时间更长。这项工作提出了将它们结合起来的第一个混合方法，旨在实现两者的最佳效果。这种混合方法称为DL-MOREA，它将最近引入的基于多目标的深度学习DIR方法与被称为DL-MODIR的VoxelMorph框架相结合，并与基于进化算法的多目标DIR方法MOREA相结合，其中使用FEM类似的生物力学网格变换模型。在我们提出的混合方法中，使用DL结果智能地初始化MOREA，旨在更有效地优化其网格变换模型。我们通过CT扫描对（捕捉15名宫颈癌患者膀胱充盈差异较大）实证比较DL-MOREA与其组件DL-MODIR和MOREA。虽然MOREA的中位运行时间为45分钟，但DL-MOREA在5分钟内就可以找到高质量的变换。与DL-MODIR变换相比，DL-MOREA找到的变换表现出较少的折叠，并改善或保持了膀胱轮廓距离误差。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16525v1">PDF</a> Pre-print for the SPIE Medical Imaging: Image Processing Conference</p>
<p><strong>Summary</strong></p>
<p>本文提出一种混合方法，名为DL-MOREA，结合了基于深度学习的可变形图像配准（DIR）方法和基于进化算法的多目标DIR方法。该方法旨在利用深度学习技术的优势快速预测变换，并结合有限元模型技术找到更真实的变换。通过智能初始化进化算法来优化网格变换模型，以实现更高效的优化。对15例宫颈癌患者的CT扫描数据进行实验比较，结果表明DL-MOREA能够在短时间内找到高质量的变换，减少了折叠现象，提高了膀胱轮廓距离误差的准确性和保留性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文章介绍了混合方法DL-MOREA，结合了深度学习（DL）技术和进化算法的多目标可变形图像配准（DIR）。</li>
<li>DL-MOREA旨在实现深度学习快速预测变换与有限元模型真实变换的结合。</li>
<li>进化算法被智能初始化以优化网格变换模型，提高优化效率。</li>
<li>实验比较显示DL-MOREA在短时间找到高质量的变换。</li>
<li>与仅使用深度学习的DL-MODIR相比，DL-MOREA找到的变换减少了折叠现象。</li>
<li>DL-MOREA提高了膀胱轮廓距离误差的准确性和保留性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16525">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-3f2cb9349dd9cde3f55043d35bbbbcaf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2208dc6c1b22c16cef30efe6649ac00e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-32b5e2c11aff88a4f8691577ebb11f80.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ee462787c25228aa92ff091bcc867425.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03165983f396a8a745f32b87d2102f20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ccff8a005ccf965c196cb9d8a8ec171f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Generating-customized-prompts-for-Zero-Shot-Rare-Event-Medical-Image-Classification-using-LLM"><a href="#Generating-customized-prompts-for-Zero-Shot-Rare-Event-Medical-Image-Classification-using-LLM" class="headerlink" title="Generating customized prompts for Zero-Shot Rare Event Medical Image   Classification using LLM"></a>Generating customized prompts for Zero-Shot Rare Event Medical Image   Classification using LLM</h2><p><strong>Authors:Payal Kamboj, Ayan Banerjee, Bin Xu, Sandeep Gupta</strong></p>
<p>Rare events, due to their infrequent occurrences, do not have much data, and hence deep learning techniques fail in estimating the distribution for such data. Open-vocabulary models represent an innovative approach to image classification. Unlike traditional models, these models classify images into any set of categories specified with natural language prompts during inference. These prompts usually comprise manually crafted templates (e.g., ‘a photo of a {}’) that are filled in with the names of each category. This paper introduces a simple yet effective method for generating highly accurate and contextually descriptive prompts containing discriminative characteristics. Rare event detection, especially in medicine, is more challenging due to low inter-class and high intra-class variability. To address these, we propose a novel approach that uses domain-specific expert knowledge on rare events to generate customized and contextually relevant prompts, which are then used by large language models for image classification. Our zero-shot, privacy-preserving method enhances rare event classification without additional training, outperforming state-of-the-art techniques. </p>
<blockquote>
<p>由于稀有事件发生的频率较低，因此没有大量数据，深度学习技术在此类数据的分布估计上表现不佳。开放词汇模型代表了图像分类的一种创新方法。与传统的模型不同，这些模型在推理期间将图像分类为用自然语言提示指定的任何类别集。这些提示通常包含手工制作的模板（例如，“一张……的照片”），在推理期间会填入每个类别的名称。本文介绍了一种简单有效的方法来生成包含辨别特征的准确且上下文描述性的提示。稀有事件检测，特别是在医学领域，由于类间低相似性和类内高差异性，更具挑战性。为了解决这些问题，我们提出了一种使用关于稀有事件的特定领域专业知识来生成定制和上下文相关的提示的新方法，然后将其用于大型语言模型进行图像分类。我们的零样本、保护隐私的方法在无需额外训练的情况下提高了稀有事件分类的性能，优于最新的技术。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16481v1">PDF</a> Accepted in IEEE ISBI, 2025</p>
<p><strong>Summary</strong></p>
<p>本文提出一种简单有效的方法，用于生成高度准确且上下文描述性的提示，这些提示包含用于图像分类的判别特征。针对医学中的罕见事件检测，结合领域特定的专业知识生成定制且上下文相关的提示，然后由大型语言模型用于图像分类。该方法为零样本、保护隐私的方法，无需额外训练即可提高罕见事件的分类性能，优于现有技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>罕见事件由于数据稀少，深度学习技术在估计其分布时遭遇挑战。</li>
<li>开放词汇模型采用自然语言提示进行分类，与传统模型不同。</li>
<li>本文提出了一种生成包含判别特征的准确且上下文描述性提示的方法。</li>
<li>在医学领域的罕见事件检测中，存在低类间和高类内变异性问题。</li>
<li>结合领域专业知识生成定制提示，用于提高罕见事件的分类性能。</li>
<li>所提方法为零样本、保护隐私的方法，无需额外训练。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16481">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-11d9c2502112ebf60ca3aeb3f176a5ae.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4bc797946e20f2f411b2594c066a491d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68b3da724b6ea3a065d16abed65a2bce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0b01e655630638c236944d31accb88e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MSDet-Receptive-Field-Enhanced-Multiscale-Detection-for-Tiny-Pulmonary-Nodule"><a href="#MSDet-Receptive-Field-Enhanced-Multiscale-Detection-for-Tiny-Pulmonary-Nodule" class="headerlink" title="MSDet: Receptive Field Enhanced Multiscale Detection for Tiny Pulmonary   Nodule"></a>MSDet: Receptive Field Enhanced Multiscale Detection for Tiny Pulmonary   Nodule</h2><p><strong>Authors:Guohui Cai, Ruicheng Zhang, Hongyang He, Zeyu Zhang, Daji Ergu, Yuanzhouhan Cao, Jinman Zhao, Binbin Hu, Zhinbin Liao, Yang Zhao, Ying Cai</strong></p>
<p>Pulmonary nodules are critical indicators for the early diagnosis of lung cancer, making their detection essential for timely treatment. However, traditional CT imaging methods suffered from cumbersome procedures, low detection rates, and poor localization accuracy. The subtle differences between pulmonary nodules and surrounding tissues in complex lung CT images, combined with repeated downsampling in feature extraction networks, often lead to missed or false detections of small nodules. Existing methods such as FPN, with its fixed feature fusion and limited receptive field, struggle to effectively overcome these issues. To address these challenges, our paper proposed three key contributions: Firstly, we proposed MSDet, a multiscale attention and receptive field network for detecting tiny pulmonary nodules. Secondly, we proposed the extended receptive domain (ERD) strategy to capture richer contextual information and reduce false positives caused by nodule occlusion. We also proposed the position channel attention mechanism (PCAM) to optimize feature learning and reduce multiscale detection errors, and designed the tiny object detection block (TODB) to enhance the detection of tiny nodules. Lastly, we conducted thorough experiments on the public LUNA16 dataset, achieving state-of-the-art performance, with an mAP improvement of 8.8% over the previous state-of-the-art method YOLOv8. These advancements significantly boosted detection accuracy and reliability, providing a more effective solution for early lung cancer diagnosis. The code will be available at <a target="_blank" rel="noopener" href="https://github.com/CaiGuoHui123/MSDet">https://github.com/CaiGuoHui123/MSDet</a> </p>
<blockquote>
<p>肺部结节是肺癌早期诊断的关键指标，因此及时检测它们对于及时治疗至关重要。然而，传统的CT成像方法存在程序繁琐、检测率低和定位精度差的问题。在复杂的肺部CT图像中，肺部结节与周围组织的细微差异，以及在特征提取网络中的重复下采样，常常导致小结节被遗漏或错误检测。现有方法如FPN，其固定的特征融合和有限的感受野，难以有效克服这些问题。为了应对这些挑战，我们的论文提出了三个关键贡献：首先，我们提出了MSDet，这是一种多尺度注意力和感受野网络，用于检测微小的肺部结节。其次，我们提出了扩展感受域（ERD）策略，以捕获更丰富的上下文信息，并减少由结节遮挡引起的误报。我们还提出了位置通道注意机制（PCAM），以优化特征学习并减少多尺度检测错误，并设计了微小目标检测块（TODB）以增强微小结节的检测。最后，我们在公共LUNA16数据集上进行了全面的实验，取得了最先进的性能，与之前的最新方法YOLOv8相比，mAP提高了8.8%。这些进步显著提高了检测准确性和可靠性，为肺癌的早期诊断提供了更有效的解决方案。代码将在<a target="_blank" rel="noopener" href="https://github.com/CaiGuoHui123/MSDet%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/CaiGuoHui123/MSDet上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.14028v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一系列针对肺部CT图像中微小肺结节检测的挑战和创新解决方案。通过引入多尺度注意力与感受野网络MSDet，扩展感受野策略ERD和位置通道注意力机制PCAM等技术，提高了肺结节检测的准确性和可靠性，为肺癌的早期诊断提供了更有效的解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>肺部结节是肺癌早期诊断的关键指标，但其检测面临传统CT成像方法程序繁琐、检测率低和定位精度差的挑战。</li>
<li>现有方法如FPN在固定特征融合和有限感受野方面存在局限，难以有效应对上述问题。</li>
<li>MSDet网络被提出，利用多尺度注意力和感受野来检测微小肺部结节。</li>
<li>引入扩展感受野（ERD）策略，以捕获更丰富的上下文信息，减少因结节遮挡导致的误报。</li>
<li>位置通道注意力机制（PCAM）被用于优化特征学习，减少多尺度检测错误。</li>
<li>设计了微小目标检测块（TODB），以增强对微小结节的检测。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.14028">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-97182cfbafa0950344aad87354c5e9a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80d954c31bf575996c4269c07fb77a93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96b2d5ed1d3776518167703ce48fb5d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c975f3665872b61eb887a3cc13edc0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c600ceba2d40650f5037bac7c61166a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-854108f95a99ef589ae0ff733c44442c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-728cda66c804f3ad120a3fa9bbb8e30c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="GFE-Mamba-Mamba-based-AD-Multi-modal-Progression-Assessment-via-Generative-Feature-Extraction-from-MCI"><a href="#GFE-Mamba-Mamba-based-AD-Multi-modal-Progression-Assessment-via-Generative-Feature-Extraction-from-MCI" class="headerlink" title="GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via   Generative Feature Extraction from MCI"></a>GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via   Generative Feature Extraction from MCI</h2><p><strong>Authors:Zhaojie Fang, Shenghao Zhu, Yifei Chen, Binfeng Zou, Fan Jia, Linwei Qiu, Chang Liu, Xiang Feng, Changmiao Wang, Feiwei Qin, Jin Fan, Changbiao Chu</strong></p>
<p>Alzheimer’s Disease (AD) is a progressive, irreversible neurodegenerative disorder that often originates from Mild Cognitive Impairment (MCI). This progression results in significant memory loss and severely affects patients’ quality of life. Clinical trials have consistently shown that early and targeted interventions for individuals with MCI may slow or even prevent the advancement of AD. Research indicates that accurate medical classification requires diverse multimodal data, including detailed assessment scales and neuroimaging techniques like Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET). However, simultaneously collecting the aforementioned three modalities for training presents substantial challenges. To tackle these difficulties, we propose GFE-Mamba, a multimodal classifier founded on Generative Feature Extractor. The intermediate features provided by this Extractor can compensate for the shortcomings of PET and achieve profound multimodal fusion in the classifier. The Mamba block, as the backbone of the classifier, enables it to efficiently extract information from long-sequence scale information. Pixel-level Bi-cross Attention supplements pixel-level information from MRI and PET. We provide our rationale for developing this cross-temporal progression prediction dataset and the pre-trained Extractor weights. Our experimental findings reveal that the GFE-Mamba model effectively predicts the progression from MCI to AD and surpasses several leading methods in the field. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/Tinysqua/GFE-Mamba">https://github.com/Tinysqua/GFE-Mamba</a>. </p>
<blockquote>
<p>阿尔茨海默病（AD）是一种渐进性、不可逆的神经退行性疾病，通常起源于轻度认知障碍（MCI）。这种进展会导致明显的记忆力减退，严重影响患者的生活质量。临床试验反复表明，对MCI患者进行早期和有针对性的干预可以减缓甚至阻止AD的进展。研究表明，准确的医学分类需要包括详细评估量表和神经成像技术（如磁共振成像（MRI）和正电子发射断层扫描（PET））在内的多种模式数据。然而，同时收集上述三种模式进行培训存在相当大的挑战。为了应对这些困难，我们提出了基于生成特征提取器的多模式分类器GFE-Mamba。该提取器提供的中间特征可以弥补PET的不足，在分类器中实现深刻的多模式融合。作为分类器的骨干，“Mamba”块使其能够高效地从长序列尺度信息中提取信息。像素级双向交叉注意力补充了MRI和PET的像素级信息。我们阐述了建立这个跨时间进展预测数据集和开发预训练提取器权重的理由。我们的实验结果表明，GFE-Mamba模型有效地预测了从MCI到AD的进展，并超越了该领域的几种领先方法。我们的源代码可在<a target="_blank" rel="noopener" href="https://github.com/Tinysqua/GFE-Mamba">https://github.com/Tinysqua/GFE-Mamba</a>获得。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.15719v2">PDF</a> 13 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>本文主要介绍了针对阿尔茨海默病（AD）的早期干预和预测模型。研究指出，针对轻度认知障碍（MCI）的个体进行早期和有针对性的干预可能减缓甚至阻止AD的进展。为了准确进行医学分类，需要包括详细评估量表、磁共振成像（MRI）和正电子发射断层扫描（PET）等多模态数据。文章提出了一种基于生成特征提取器的多模态分类器GFE-Mamba，该分类器能够补偿PET的不足，实现深刻的跨模态融合，并有效地预测从MCI到AD的进展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>阿尔茨海默病（AD）是一种不可逆的神经性退行性疾病，常由轻度认知障碍（MCI）发展而来。</li>
<li>早期针对MCI的干预可能减缓或阻止AD的进展。</li>
<li>准确医学分类需要多模态数据，包括详细评估量表、MRI和PET等技术。</li>
<li>提出了一种新的多模态分类器GFE-Mamba，基于生成特征提取器。</li>
<li>GFE-Mamba能够通过中间特征补偿PET的不足，并实现跨模态融合。</li>
<li>GFE-Mamba模型能够预测从MCI到AD的进展，并在实验中超越了领域内的几种领先方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.15719">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-669da913055a161e67591002b887971d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-82f5ba747a28df4478f2fc04c9d407df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b410dfe4c3dd9ffd1d983fadc18672b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b028244a578679204091b3081a9b705.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e6de1bbe236e711d0bf7d39e1596c9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df7327493f05a57c91736dc1d7a7ebf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dac37c7ed53c8dd0c0836f8619ec3161.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-30/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">医学图像</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-9940b96333fe9fdf920ad8a04fc11ed7.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive 方向最新论文已更新，请持续关注 Update in 2025-01-30  Slow Manifolds for PDE with Fast Reactions and Small Cross Diffusion
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-30/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fdf0db8b8061d6603296201be49b6811.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-01-30  CubeDiff Repurposing Diffusion-Based Image Models for Panorama   Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23523.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
