<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-06  Octax Accelerated CHIP-8 Arcade Environments for Reinforcement Learning   in JAX">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-4cb31ae91ffa917d13a3b2f3319f48e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028160&auth_key=1760028160-0-0-251f60f2f8ecbe87122d64049ef1f9bc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-23
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    21.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    86 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-06-æ›´æ–°"><a href="#2025-10-06-æ›´æ–°" class="headerlink" title="2025-10-06 æ›´æ–°"></a>2025-10-06 æ›´æ–°</h1><h2 id="Octax-Accelerated-CHIP-8-Arcade-Environments-for-Reinforcement-Learning-in-JAX"><a href="#Octax-Accelerated-CHIP-8-Arcade-Environments-for-Reinforcement-Learning-in-JAX" class="headerlink" title="Octax: Accelerated CHIP-8 Arcade Environments for Reinforcement Learning   in JAX"></a>Octax: Accelerated CHIP-8 Arcade Environments for Reinforcement Learning   in JAX</h2><p><strong>Authors:Waris Radji, Thomas Michel, Hector Piteau</strong></p>
<p>Reinforcement learning (RL) research requires diverse, challenging environments that are both tractable and scalable. While modern video games may offer rich dynamics, they are computationally expensive and poorly suited for large-scale experimentation due to their CPU-bound execution. We introduce Octax, a high-performance suite of classic arcade game environments implemented in JAX, based on CHIP-8 emulation, a predecessor to Atari, which is widely adopted as a benchmark in RL research. Octax provides the JAX community with a long-awaited end-to-end GPU alternative to the Atari benchmark, offering image-based environments, spanning puzzle, action, and strategy genres, all executable at massive scale on modern GPUs. Our JAX-based implementation achieves orders-of-magnitude speedups over traditional CPU emulators while maintaining perfect fidelity to the original game mechanics. We demonstrate Octaxâ€™s capabilities by training RL agents across multiple games, showing significant improvements in training speed and scalability compared to existing solutions. The environmentâ€™s modular design enables researchers to easily extend the suite with new games or generate novel environments using large language models, making it an ideal platform for large-scale RL experimentation. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç ”ç©¶éœ€è¦å¤šæ ·ä¸”å…·æŒ‘æˆ˜æ€§çš„ç¯å¢ƒï¼Œè¿™äº›ç¯å¢ƒæ—¢æ˜“äºå¤„ç†åˆå…·å¤‡å¯æ‰©å±•æ€§ã€‚è™½ç„¶ç°ä»£è§†é¢‘æ¸¸æˆå¯èƒ½æä¾›ä¸°å¯Œçš„åŠ¨æ€æ€§ï¼Œä½†ç”±äºå…¶CPUå¯†é›†å‹æ‰§è¡Œç‰¹æ€§ï¼Œå®ƒä»¬åœ¨è®¡ç®—ä¸Šæˆæœ¬é«˜æ˜‚ï¼Œä¸é€‚åˆå¤§è§„æ¨¡å®éªŒã€‚æˆ‘ä»¬æ¨å‡ºäº†Octaxï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨JAXä¸­å®ç°ç»å…¸è¡—æœºæ¸¸æˆç¯å¢ƒçš„é«˜æ€§èƒ½å¥—ä»¶ï¼ŒåŸºäºCHIP-8ä»¿çœŸæŠ€æœ¯ï¼Œæ˜¯Atariçš„å…ˆé©±ï¼Œå¹¿æ³›åº”ç”¨äºRLç ”ç©¶ä¸­çš„åŸºå‡†æµ‹è¯•ã€‚Octaxä¸ºJAXç¤¾åŒºæä¾›äº†AtariåŸºå‡†æµ‹è¯•çš„ä¹…ç›¼æœªè‡³çš„ç«¯åˆ°ç«¯GPUæ›¿ä»£æ–¹æ¡ˆï¼Œæä¾›åŸºäºå›¾åƒçš„ç¯å¢ƒï¼Œæ¶µç›–ç›Šæ™ºã€åŠ¨ä½œå’Œç­–ç•¥ç­‰å¤šç§ç±»å‹ï¼Œæ‰€æœ‰å†…å®¹éƒ½å¯åœ¨ç°ä»£GPUä¸Šå¤§è§„æ¨¡æ‰§è¡Œã€‚æˆ‘ä»¬çš„åŸºäºJAXçš„å®ç°ç›¸å¯¹äºä¼ ç»Ÿçš„CPUæ¨¡æ‹Ÿå™¨å®ç°äº†æ•°é‡çº§çš„åŠ é€Ÿï¼ŒåŒæ—¶å®Œç¾å¿ å®äºåŸå§‹çš„æ¸¸æˆæœºåˆ¶ã€‚æˆ‘ä»¬é€šè¿‡è®­ç»ƒå¤šä¸ªæ¸¸æˆä¸­çš„RLä»£ç†æ¥å±•ç¤ºOctaxçš„åŠŸèƒ½ï¼Œä¸ç°æœ‰è§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼Œåœ¨è®­ç»ƒé€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ–¹é¢æ˜¾ç¤ºå‡ºæ˜¾ç€æ”¹è¿›ã€‚ç¯å¢ƒçš„æ¨¡å—åŒ–è®¾è®¡ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿè½»æ¾åœ°å°†æ–°æ¸¸æˆæ‰©å±•åˆ°å¥—ä»¶ä¸­æˆ–ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–°ç¯å¢ƒï¼Œä½¿å…¶æˆä¸ºå¤§è§„æ¨¡RLå®éªŒçš„ç†æƒ³å¹³å°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01764v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç ”ç©¶çš„éœ€è¦ï¼Œä¸€ä¸ªé«˜æ€§èƒ½çš„ç»å…¸è¡—æœºæ¸¸æˆç¯å¢ƒå¥—ä»¶Octaxè¢«å¼•å…¥ã€‚Octaxé‡‡ç”¨JAXå®ç°ï¼ŒåŸºäºCHIP-8æ¨¡æ‹Ÿï¼Œæ˜¯Atariçš„å…ˆé©±ï¼Œä¸ºRLç ”ç©¶æä¾›äº†å¹¿æ³›é‡‡ç”¨çš„åŸºå‡†æµ‹è¯•ã€‚Octaxä¸ºJAXç¤¾åŒºæä¾›äº†AtariåŸºå‡†æµ‹è¯•çš„ç«¯åˆ°ç«¯GPUæ›¿ä»£æ–¹æ¡ˆï¼Œæä¾›å›¾åƒç¯å¢ƒï¼Œæ¶µç›–ç›Šæ™ºã€åŠ¨ä½œå’Œç­–ç•¥ç­‰å¤šç§ç±»å‹æ¸¸æˆï¼Œå¯åœ¨ç°ä»£GPUä¸Šå¤§è§„æ¨¡æ‰§è¡Œã€‚ä¸ä¼ ç»Ÿçš„CPUæ¨¡æ‹Ÿå™¨ç›¸æ¯”ï¼ŒåŸºäºJAXçš„å®ç°å–å¾—äº†æ•°é‡çº§çš„åŠ é€Ÿï¼ŒåŒæ—¶å®Œç¾åœ°ä¿æŒäº†åŸå§‹æ¸¸æˆæœºåˆ¶ã€‚é€šè¿‡è®­ç»ƒRLä»£ç†è¿›è¡Œå¤šæ¸¸æˆæ¼”ç¤ºï¼Œå±•ç¤ºäº†ä¸ç°æœ‰è§£å†³æ–¹æ¡ˆç›¸æ¯”åœ¨è®­ç»ƒé€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„æ˜¾è‘—æ”¹å–„ã€‚å…¶æ¨¡å—åŒ–è®¾è®¡ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿè½»æ¾æ·»åŠ æ–°æ¸¸æˆæˆ–åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–°ç¯å¢ƒï¼Œä½¿å…¶æˆä¸ºå¤§è§„æ¨¡RLå®éªŒçš„ç†æƒ³å¹³å°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Octaxæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„åŸºäºJAXå®ç°çš„ç»å…¸è¡—æœºæ¸¸æˆç¯å¢ƒå¥—ä»¶ï¼Œæ—¨åœ¨ä¸ºå¼ºåŒ–å­¦ä¹ ç ”ç©¶æä¾›å¤šæ ·åŒ–ã€å¯ä¼¸ç¼©çš„æŒ‘æˆ˜ç¯å¢ƒã€‚</li>
<li>Octaxæä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„GPUæ›¿ä»£æ–¹æ¡ˆï¼Œä¸ºJAXç¤¾åŒºæä¾›äº†AtariåŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>Octaxæä¾›å›¾åƒç¯å¢ƒï¼ŒåŒ…æ‹¬å¤šç§ç±»å‹çš„æ¸¸æˆï¼Œå¦‚ç›Šæ™ºã€åŠ¨ä½œå’Œç­–ç•¥ç­‰ï¼Œå¯åœ¨ç°ä»£GPUä¸Šå¤§è§„æ¨¡æ‰§è¡Œã€‚</li>
<li>ä¸ä¼ ç»ŸCPUæ¨¡æ‹Ÿå™¨ç›¸æ¯”ï¼ŒåŸºäºJAXçš„Octaxå®ç°å…·æœ‰æ•°é‡çº§çš„åŠ é€Ÿæ€§èƒ½ã€‚</li>
<li>Octaxèƒ½å¤Ÿå®Œç¾åœ°ä¿æŒåŸå§‹æ¸¸æˆæœºåˆ¶ï¼ŒåŒæ—¶æ”¯æŒè®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚</li>
<li>åœ¨å¤šä¸ªæ¸¸æˆä¸­è®­ç»ƒRLä»£ç†çš„æ¼”ç¤ºè¯æ˜äº†Octaxåœ¨è®­ç»ƒé€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„æ˜¾è‘—æ”¹å–„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01764">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-24370735be356b258e9f78349d2651ea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028168&auth_key=1760028168-0-0-7ffb9e1e537871b80cb75c824f1c3f74&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-63eff47518c42450c33d06c1030a0c26~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028175&auth_key=1760028175-0-0-3a85cf3a530792413ca5001b09001377&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-60ecaeb4bd0566c38a2b36b89eaf5d20~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028182&auth_key=1760028182-0-0-4d50e845b3f919adc6cf36954ad05cd3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f608f4eb0990416caa1ddf62b63229ba~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028189&auth_key=1760028189-0-0-55da5e6cb9c2100a7f91f2f1d4a4d23e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e6b2702f38b16dece70b626ae073584f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028196&auth_key=1760028196-0-0-75c22628f86fcbc39357c76c34a2d177&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Round-trip-Reinforcement-Learning-Self-Consistent-Training-for-Better-Chemical-LLMs"><a href="#Round-trip-Reinforcement-Learning-Self-Consistent-Training-for-Better-Chemical-LLMs" class="headerlink" title="Round-trip Reinforcement Learning: Self-Consistent Training for Better   Chemical LLMs"></a>Round-trip Reinforcement Learning: Self-Consistent Training for Better   Chemical LLMs</h2><p><strong>Authors:Lecheng Kong, Xiyuan Wang, Yixin Chen, Muhan Zhang</strong></p>
<p>Large Language Models (LLMs) are emerging as versatile foundation models for computational chemistry, handling bidirectional tasks like reaction prediction and retrosynthesis. However, these models often lack round-trip consistency. For instance, a state-of-the-art chemical LLM may successfully caption a molecule, yet be unable to accurately reconstruct the original structure from its own generated text. This inconsistency suggests that models are learning unidirectional memorization rather than flexible mastery. Indeed, recent work has demonstrated a strong correlation between a modelâ€™s round-trip consistency and its performance on the primary tasks. This strong correlation reframes consistency into a direct target for model improvement. We therefore introduce Round-Trip Reinforcement Learning (RTRL), a novel framework that trains a model to improve its consistency by using the success of a round-trip transformation as a reward signal. We further propose an iterative variant where forward and reverse mappings alternately train each other in a self-improvement loop, a process that is highly data-efficient and notably effective with the massive amount of unlabelled data common in chemistry. Experiments demonstrate that RTRL significantly \textbf{boosts performance and consistency} over strong baselines across supervised, self-supervised, and synthetic data regimes. This work shows that round-trip consistency is not just a desirable property but a trainable objective, offering a new path toward more robust and reliable foundation models. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£æˆä¸ºè®¡ç®—åŒ–å­¦çš„é€šç”¨åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ååº”é¢„æµ‹å’Œé€†åˆæˆç­‰åŒå‘ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¾€å¾€ç¼ºä¹å¾€è¿”ä¸€è‡´æ€§ã€‚ä¾‹å¦‚ï¼Œæœ€å…ˆè¿›çš„åŒ–å­¦LLMå¯èƒ½æˆåŠŸåœ°æ ‡æ³¨äº†ä¸€ä¸ªåˆ†å­ï¼Œä½†æ— æ³•æ ¹æ®å…¶ç”Ÿæˆçš„æ–‡æœ¬å‡†ç¡®é‡å»ºåŸå§‹ç»“æ„ã€‚è¿™ç§ä¸ä¸€è‡´æ€§è¡¨æ˜ï¼Œæ¨¡å‹å­¦ä¹ çš„æ˜¯å•å‘è®°å¿†ï¼Œè€Œä¸æ˜¯çµæ´»æŒæ¡ã€‚ç¡®å®ï¼Œæœ€è¿‘çš„å·¥ä½œæ˜¾ç¤ºæ¨¡å‹å¾€è¿”ä¸€è‡´æ€§ä¸å…¶ä¸»è¦ä»»åŠ¡æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸å…³æ€§ã€‚è¿™ç§å¼ºçƒˆçš„ç›¸å…³æ€§å°†ä¸€è‡´æ€§é‡æ–°å®šä¹‰ä¸ºæ¨¡å‹æ”¹è¿›çš„ç›´æ¥ç›®æ ‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¾€è¿”å¼ºåŒ–å­¦ä¹ ï¼ˆRTRLï¼‰è¿™ä¸€æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä»¥å¾€è¿”è½¬æ¢çš„æˆåŠŸä½œä¸ºå¥–åŠ±ä¿¡å·æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»¥æé«˜å…¶ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªè¿­ä»£å˜ä½“ï¼Œå…¶ä¸­æ­£å‘å’Œåå‘æ˜ å°„äº¤æ›¿è¿›è¡Œç›¸äº’è®­ç»ƒï¼Œå½¢æˆä¸€ä¸ªè‡ªæˆ‘æ”¹è¿›å¾ªç¯ï¼Œè¿™ä¸€è¿‡ç¨‹åœ¨åŒ–å­¦ä¸­å¤§é‡å¸¸è§çš„æ— æ ‡ç­¾æ•°æ®ä¸‹éå¸¸é«˜æ•ˆä¸”æ•ˆæœæ˜¾è‘—ã€‚å®éªŒè¡¨æ˜ï¼ŒRTRLåœ¨ç›‘ç£ã€è‡ªç›‘ç£å’Œåˆæˆæ•°æ®æƒ…å†µä¸‹å‡æ˜¾è‘—æé«˜äº†å¼ºå¤§åŸºå‡†çº¿çš„æ€§èƒ½å’Œä¸€è‡´æ€§ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œå¾€è¿”ä¸€è‡´æ€§ä¸ä»…æ˜¯ä¸€ä¸ªç†æƒ³å±æ€§ï¼Œè€Œä¸”æ˜¯ä¸€ä¸ªå¯è®­ç»ƒçš„ç›®æ ‡ï¼Œä¸ºæ›´ç¨³å¥å’Œå¯é çš„åŸºç¡€æ¨¡å‹æä¾›äº†æ–°çš„å‘å±•é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01527v1">PDF</a> 19 pages</p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—åŒ–å­¦é¢†åŸŸå±•ç°å‡ºé€šç”¨åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ï¼Œèƒ½å¤Ÿå¤„ç†å¦‚ååº”é¢„æµ‹å’Œé€†å‘åˆæˆç­‰åŒå‘ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¾€å¾€ç¼ºä¹å¾€è¿”ä¸€è‡´æ€§ï¼Œå³æˆåŠŸæè¿°åˆ†å­åéš¾ä»¥å‡†ç¡®é‡å»ºå…¶åŸå§‹ç»“æ„ï¼Œè¡¨æ˜å®ƒä»¬å­¦ä¹ çš„æ˜¯å•å‘è®°å¿†è€Œéçµæ´»æŒæ¡ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œæ¨¡å‹çš„å¾€è¿”ä¸€è‡´æ€§ä¸å…¶ä¸»è¦ä»»åŠ¡çš„æ€§èƒ½ä¹‹é—´å­˜åœ¨å¼ºçƒˆå…³è”ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å¼•å…¥äº†å¾€è¿”å¼ºåŒ–å­¦ä¹ ï¼ˆRTRLï¼‰æ¡†æ¶ï¼Œä½¿ç”¨å¾€è¿”è½¬æ¢çš„æˆåŠŸä½œä¸ºå¥–åŠ±ä¿¡å·æ¥è®­ç»ƒæ¨¡å‹ï¼Œæé«˜å…¶ä¸€è‡´æ€§ã€‚åœ¨åŒ–å­¦é¢†åŸŸå¤§é‡æ— æ ‡ç­¾æ•°æ®çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹æ³•çš„è®­ç»ƒæ•ˆç‡é«˜ä¸”æ•ˆæœæ˜¾è‘—ã€‚å®éªŒè¡¨æ˜ï¼ŒRTRLåœ¨ç›‘ç£ã€è‡ªç›‘ç£ä»¥åŠåˆæˆæ•°æ®æ¨¡å¼ä¸‹ï¼Œæ˜¾è‘—æé«˜æ€§èƒ½å¹¶å¢å¼ºä¸€è‡´æ€§ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜å¾€è¿”ä¸€è‡´æ€§ä¸ä»…æ˜¯ç†æƒ³å±æ€§ï¼Œè¿˜å¯ä½œä¸ºè®­ç»ƒç›®æ ‡ï¼Œä¸ºæ›´ç¨³å¥å’Œå¯é çš„åŸºç¡€æ¨¡å‹å¼€è¾Ÿäº†æ–°çš„è·¯å¾„ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—åŒ–å­¦é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬å¤„ç†åŒå‘ä»»åŠ¡å¦‚ååº”é¢„æµ‹å’Œé€†å‘åˆæˆã€‚</li>
<li>è¿™äº›æ¨¡å‹å¸¸ç¼ºä¹å¾€è¿”ä¸€è‡´æ€§ï¼Œå³éš¾ä»¥ä»è‡ªèº«ç”Ÿæˆçš„æ–‡æœ¬ä¸­å‡†ç¡®é‡å»ºåŸå§‹ç»“æ„ã€‚</li>
<li>å¾€è¿”ä¸€è‡´æ€§å¯¹äºæ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ï¼Œä¸ä¸»è¦ä»»åŠ¡çš„è¡¨ç°å­˜åœ¨å¼ºçƒˆå…³è”ã€‚</li>
<li>å¼•å…¥çš„å¾€è¿”å¼ºåŒ–å­¦ä¹ ï¼ˆRTRLï¼‰æ¡†æ¶æ—¨åœ¨é€šè¿‡å¥–åŠ±ä¿¡å·æé«˜æ¨¡å‹çš„å¾€è¿”ä¸€è‡´æ€§ã€‚</li>
<li>RTRLæ¡†æ¶é‡‡ç”¨è¿­ä»£æ–¹å¼ï¼Œé€šè¿‡å‰å‘å’Œåå‘æ˜ å°„ç›¸äº’è®­ç»ƒï¼Œæé«˜æ•°æ®æ•ˆç‡ã€‚</li>
<li>åœ¨åŒ–å­¦é¢†åŸŸå¤§é‡æ— æ ‡ç­¾æ•°æ®çš„æƒ…å†µä¸‹ï¼ŒRTRLæ•ˆæœæ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01527">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bf0a818117621a2350afa19bc67a6157~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028204&auth_key=1760028204-0-0-2a1e46ba3d22d24c680d0955ed99f64e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-460c2415799110b235d9048279d70f97~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028211&auth_key=1760028211-0-0-e5a80deba5107218f08b8664a87a3f69&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="BroRL-Scaling-Reinforcement-Learning-via-Broadened-Exploration"><a href="#BroRL-Scaling-Reinforcement-Learning-via-Broadened-Exploration" class="headerlink" title="BroRL: Scaling Reinforcement Learning via Broadened Exploration"></a>BroRL: Scaling Reinforcement Learning via Broadened Exploration</h2><p><strong>Authors:Jian Hu, Mingjie Liu, Ximing Lu, Fang Wu, Zaid Harchaoui, Shizhe Diao, Yejin Choi, Pavlo Molchanov, Jun Yang, Jan Kautz, Yi Dong</strong></p>
<p>Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key ingredient for unlocking complex reasoning capabilities in large language models. Recent work ProRL has shown promise in scaling RL by increasing the number of training steps. However, performance plateaus after thousands of steps, with clear diminishing returns from allocating more computation to additional training. In this work, we investigate a complementary paradigm for scaling RL, BroR-Lincreasing the number of rollouts per example to hundreds to exhaustively Broaden exploration, which yields continuous performance gains beyond the saturation point observed in ProRL when scaling the number of training steps. Our approach is motivated by a mass balance equation analysis allowing us to characterize the rate of change in probability mass for correct and incorrect tokens during the reinforcement process. We show that under a one-step RL assumption, sampled rollout tokens always contribute to correct-mass expansion, while unsampled tokens outside rollouts may lead to gains or losses depending on their distribution and the net reward balance. Importantly, as the number of rollouts per example N increases, the effect of unsampled terms diminishes, ensuring overall correct-mass expansion. To validate our theoretical analysis, we conduct simulations under more relaxed conditions and find that a sufficiently large rollout size N-corresponding to ample exploration-guarantees an increase in the probability mass of all correct tokens. Empirically, BroRL revives models saturated after 3K ProRL training steps and demonstrates robust, continuous improvement, achieving state-of-the-art results for the 1.5B model across diverse benchmarks. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰å·²æˆä¸ºè§£é”å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¤æ‚æ¨ç†èƒ½åŠ›çš„é‡è¦æˆåˆ†ã€‚æœ€è¿‘çš„ProRLå·¥ä½œé€šè¿‡å¢åŠ è®­ç»ƒæ­¥éª¤æ•°é‡å±•ç°å‡ºå¼ºåŒ–å­¦ä¹ æ‰©å±•æ€§çš„å‰æ™¯ã€‚ç„¶è€Œï¼Œåœ¨æ•°åƒæ­¥åæ€§èƒ½è¾¾åˆ°å³°å€¼ï¼Œé€šè¿‡åˆ†é…æ›´å¤šè®¡ç®—èµ„æºæ¥è¿›è¡Œé¢å¤–è®­ç»ƒæ‰€äº§ç”Ÿçš„å›æŠ¥æ˜æ˜¾é€’å‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ç§ä¸æ‰©å±•å¼ºåŒ–å­¦ä¹ äº’è¡¥çš„æ–¹æ³•ï¼Œå³é€šè¿‡æ¯ä¸ªä¾‹å­è¿›è¡Œæ•°ç™¾æ¬¡çš„æ»šåŠ¨ä»¥è¯¦å°½åœ°æ‹“å®½æ¢ç´¢ï¼ˆBroRï¼‰ã€‚å½“åœ¨ProRLä¸­æ‰©å¤§è®­ç»ƒæ­¥éª¤æ•°é‡æ—¶ï¼Œæˆ‘ä»¬æ–¹æ³•äº§ç”Ÿè¿ç»­çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†è§‚å¯Ÿåˆ°çš„é¥±å’Œç‚¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å—åˆ°è´¨é‡å¹³è¡¡æ–¹ç¨‹åˆ†æçš„å¯å‘ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè¡¨å¾å¼ºåŒ–è¿‡ç¨‹ä¸­æ­£ç¡®å’Œé”™è¯¯ä»¤ç‰Œæ¦‚ç‡è´¨é‡çš„å˜åŒ–ç‡ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œåœ¨ä¸€æ­¥å¼ºåŒ–å­¦ä¹ çš„å‡è®¾ä¸‹ï¼Œé‡‡æ ·æ»šåŠ¨ä»¤ç‰Œå§‹ç»ˆæœ‰åŠ©äºæ­£ç¡®è´¨é‡çš„æ‰©å±•ï¼Œè€Œæœªé‡‡æ ·çš„ä»¤ç‰Œå¯èƒ½å¯¼è‡´æ”¶ç›Šæˆ–æŸå¤±ï¼Œè¿™å–å†³äºå…¶åˆ†å¸ƒå’Œå‡€å¥–åŠ±å¹³è¡¡ã€‚é‡è¦çš„æ˜¯ï¼Œéšç€æ¯ä¸ªä¾‹å­çš„æ»šåŠ¨æ¬¡æ•°Nçš„å¢åŠ ï¼Œæœªé‡‡æ ·é¡¹çš„å½±å“å‡å°ï¼Œä»è€Œç¡®ä¿äº†æ€»ä½“ä¸Šçš„æ­£ç¡®è´¨é‡æ‰©å±•ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„ç†è®ºåˆ†æï¼Œæˆ‘ä»¬åœ¨æ›´å®½æ¾çš„æ¡ä»¶ä¸‹è¿›è¡Œæ¨¡æ‹Ÿï¼Œå¹¶å‘ç°è¶³å¤Ÿå¤§çš„æ»šåŠ¨è§„æ¨¡Nï¼ˆå¯¹åº”äºå……åˆ†çš„æ¢ç´¢ï¼‰ä¿è¯äº†æ‰€æœ‰æ­£ç¡®ä»¤ç‰Œçš„æ¦‚ç‡è´¨é‡å¢åŠ ã€‚ç»éªŒä¸Šï¼ŒBroRLä½¿åœ¨3K ProRLè®­ç»ƒæ­¥éª¤åè¾¾åˆ°é¥±å’Œçš„æ¨¡å‹æ¢å¤æ´»åŠ›ï¼Œå¹¶å±•ç°å‡ºç¨³å¥çš„ã€æŒç»­çš„æ”¹è¿›ï¼Œåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†1.5Bæ¨¡å‹çš„æœ€æ–°ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01180v1">PDF</a> 16 pages, 4 figures</p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ é€šè¿‡å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æˆä¸ºè§£é”å¤§å‹è¯­è¨€æ¨¡å‹å¤æ‚æ¨ç†èƒ½åŠ›çš„é‡è¦æˆåˆ†ã€‚ProRLå±•ç°å‡ºäº†åœ¨å¢åŠ è®­ç»ƒæ­¥éª¤ä¸Šæé«˜æ€§èƒ½çš„æ½œåŠ›ï¼Œä½†å½“è®­ç»ƒæ­¥éª¤è¾¾åˆ°ä¸€å®šæ•°é‡åï¼Œæ€§èƒ½è¶‹äºé¥±å’Œã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä¸€ä¸ªä¸ProRLäº’è¡¥çš„ç­–ç•¥BroRLï¼Œé€šè¿‡å¢åŠ æ¯ä¸ªä¾‹å­çš„æŠ½æ ·æ¬¡æ•°æ¥æ‰©å¤§æ¢ç´¢èŒƒå›´ï¼Œä»è€Œåœ¨ProRLè®­ç»ƒæ­¥éª¤é¥±å’Œåä»ç„¶èƒ½å¤ŸæŒç»­æé«˜æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•å—åˆ°è´¨é‡å¹³è¡¡æ–¹ç¨‹åˆ†æçš„å¯å‘ï¼Œèƒ½å¤Ÿè¡¨å¾å¼ºåŒ–è¿‡ç¨‹ä¸­æ­£ç¡®å’Œé”™è¯¯ä»£å¸æ¦‚ç‡è´¨é‡çš„å˜åŒ–ç‡ã€‚å®éªŒæ˜¾ç¤ºï¼Œå¢åŠ æŠ½æ ·æ¬¡æ•°Nå¯ä»¥é™ä½æœªæŠ½æ ·ä»£å¸çš„å½±å“ï¼Œä¿è¯æ­£ç¡®ä»£å¸çš„æ•´ä½“è´¨é‡æ‰©å¼ ã€‚ç»éªŒä¸Šï¼ŒBroRLèƒ½é‡å¯åœ¨3Kæ­¥è®­ç»ƒåé¥±å’Œçš„æ¨¡å‹ï¼Œå¹¶å®ç°ç¨³å¥çš„æŒç»­æå‡ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—æœ€ä½³ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¤æ‚æ¨ç†èƒ½åŠ›è‡³å…³é‡è¦ã€‚</li>
<li>ProRLé€šè¿‡å¢åŠ è®­ç»ƒæ­¥éª¤å±•ç°æ€§èƒ½æå‡æ½œåŠ›ï¼Œä½†å­˜åœ¨æ€§èƒ½é¥±å’Œé—®é¢˜ã€‚</li>
<li>BroRLç­–ç•¥æ—¨åœ¨é€šè¿‡å¢åŠ æ¯ä¸ªä¾‹å­çš„æŠ½æ ·æ¬¡æ•°æ¥æ‰©å¤§æ¢ç´¢èŒƒå›´ï¼Œå®ç°æŒç»­æ€§èƒ½æå‡ã€‚</li>
<li>è´¨é‡å¹³è¡¡æ–¹ç¨‹åˆ†ææŒ‡å¯¼äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæè¿°äº†æ­£ç¡®å’Œé”™è¯¯ä»£å¸æ¦‚ç‡è´¨é‡çš„å˜åŒ–ç‡ã€‚</li>
<li>å¢åŠ æŠ½æ ·æ¬¡æ•°Nå¯é™ä½æœªæŠ½æ ·ä»£å¸çš„å½±å“ï¼Œç¡®ä¿æ­£ç¡®ä»£å¸çš„æ•´ä½“è´¨é‡æ‰©å¼ ã€‚</li>
<li>BroRLèƒ½é‡å¯é¥±å’Œæ¨¡å‹å¹¶ç»§ç»­æå‡æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01180">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-11a25f3549d86aca4479844525f9359e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028219&auth_key=1760028219-0-0-44bd4b429d451672ed5531dae827ce3a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bfd8d3a9fb65b16c7fd5f7ec03f26dff~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028226&auth_key=1760028226-0-0-9bc161802ace5b1d430f172965e446aa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0cbb8ea814a84446be11de491e852152~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028233&auth_key=1760028233-0-0-d5c4d962b9068badef0690badf699907&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4cb31ae91ffa917d13a3b2f3319f48e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028239&auth_key=1760028239-0-0-2e51427830656759367a4885aeded2fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Prompt-Curriculum-Learning-for-Efficient-LLM-Post-Training"><a href="#Prompt-Curriculum-Learning-for-Efficient-LLM-Post-Training" class="headerlink" title="Prompt Curriculum Learning for Efficient LLM Post-Training"></a>Prompt Curriculum Learning for Efficient LLM Post-Training</h2><p><strong>Authors:Zhaolin Gao, Joongwon Kim, Wen Sun, Thorsten Joachims, Sid Wang, Richard Yuanzhe Pang, Liang Tan</strong></p>
<p>We introduce Prompt Curriculum Learning (PCL), a lightweight reinforcement learning (RL) algorithm that selects intermediate-difficulty prompts using a learned value model to post-train language models. Since post-training LLMs via RL remains sensitive to batching and prompt selection strategies, we first conduct a series of systematic experiments where we (1) determine the optimal training batch size that balances generation efficiency and gradient quality and (2) establish the importance of focusing on prompts of intermediate difficulty for the policy. We build upon these results to design PCL, which identifies prompts of intermediate difficulty for the current policy in an on-policy manner by using a value model that is concurrently updated based on the current policy. By focusing on informative prompts that yield high effective ratios, PCL achieves either the highest performance or requires significantly less time to reach comparable performance to its counterparts. Compared to rollout-based filtering methods, PCL avoids costly rollouts and achieves $12.1\times$ and $16.9\times$ faster speed on identifying intermediate-difficulty prompts when training on MATH and DeepScaleR, respectively. We further demonstrate that our value model accurately predicts prompt difficulty and allows PCL to focus on progressively more challenging prompts during RL. Our results present a new methodology that delivers improved tradeoff between upper-bound performance and efficiency for reasoning-focused RL. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Promptè¯¾ç¨‹å­¦ä¹ ï¼ˆPCLï¼‰è¿™ä¸€è½»é‡çº§å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•ï¼Œå®ƒé€šè¿‡åˆ©ç”¨å­¦ä¹ å¾—åˆ°çš„å€¼æ¨¡å‹æ¥é€‰æ‹©ä¸­ç­‰éš¾åº¦çš„æç¤ºæ¥å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œåè®­ç»ƒã€‚ç”±äºé€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œåè®­ç»ƒä»ç„¶å¯¹æ‰¹å¤„ç†å’Œæç¤ºé€‰æ‹©ç­–ç•¥æ•æ„Ÿï¼Œæˆ‘ä»¬é¦–å…ˆè¿›è¡Œäº†ä¸€ç³»åˆ—ç³»ç»Ÿå®éªŒï¼Œä»¥ç¡®å®šï¼ˆ1ï¼‰åœ¨å¹³è¡¡ç”Ÿæˆæ•ˆç‡å’Œæ¢¯åº¦è´¨é‡æ–¹é¢è¡¨ç°æœ€ä½³çš„è®­ç»ƒæ‰¹å¤„ç†å¤§å°ï¼›ï¼ˆ2ï¼‰ç¡®å®šäº†å…³æ³¨ä¸­ç­‰éš¾åº¦æç¤ºå¯¹ç­–ç•¥çš„é‡è¦æ€§ã€‚æˆ‘ä»¬åŸºäºè¿™äº›ç»“æœè®¾è®¡äº†PCLï¼Œå®ƒé‡‡ç”¨å€¼æ¨¡å‹æ¥ç¡®å®šå½“å‰ç­–ç•¥çš„æç¤ºä¸­ç­‰éš¾åº¦ï¼Œä»¥ç­–ç•¥ä¾èµ–çš„æ–¹å¼ä½¿ç”¨åŸºäºå½“å‰ç­–ç•¥æ›´æ–°çš„å€¼æ¨¡å‹ã€‚é€šè¿‡ä¸“æ³¨äºäº§ç”Ÿé«˜æœ‰æ•ˆç‡çš„æç¤ºä¿¡æ¯ï¼ŒPCLè¦ä¹ˆå®ç°äº†æœ€é«˜æ€§èƒ½ï¼Œè¦ä¹ˆåœ¨è¾¾åˆ°ä¸åŒç±»ç›¸å½“çš„æ€§èƒ½æ—¶æ‰€éœ€çš„æ—¶é—´å¤§å¤§å‡å°‘ã€‚ä¸åŸºäºå›åˆçš„è¿‡æ»¤æ–¹æ³•ç›¸æ¯”ï¼ŒPCLé¿å…äº†æ˜‚è´µçš„å›åˆå¹¶ä¸”åœ¨è¿›è¡ŒMATHå’ŒDeepScaleRè®­ç»ƒæ—¶åˆ†åˆ«åŠ å¿«äº†12.1å€å’Œæ›´é«˜çš„16.9å€çš„ä¸­ç­‰éš¾åº¦æç¤ºè¯†åˆ«é€Ÿåº¦ã€‚æˆ‘ä»¬è¿˜è¿›ä¸€æ­¥è¯æ˜æˆ‘ä»¬çš„å€¼æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æç¤ºçš„éš¾åº¦ï¼Œä½¿PCLèƒ½å¤Ÿåœ¨å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­ä¸“æ³¨äºè¶Šæ¥è¶Šå…·æœ‰æŒ‘æˆ˜æ€§çš„æç¤ºã€‚æˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œåœ¨è¾¾åˆ°ä¸Šé™æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´æä¾›äº†æ›´å¥½çš„æƒè¡¡ï¼Œé€‚ç”¨äºä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„å¼ºåŒ–å­¦ä¹ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01135v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„Promptè¯¾ç¨‹å­¦ä¹ ï¼ˆPCLï¼‰æ–¹æ³•ã€‚PCLé€šè¿‡åˆ©ç”¨ä»·å€¼æ¨¡å‹é€‰æ‹©ä¸­ç­‰éš¾åº¦çš„æç¤ºæ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚æœ¬æ–‡ç ”ç©¶äº†æ‰¹é‡å¤„ç†å’Œæç¤ºé€‰æ‹©ç­–ç•¥å¯¹è®­ç»ƒçš„å½±å“ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡PCLç®—æ³•ï¼Œå®ç°é«˜æ€§èƒ½ä¸”æ•ˆç‡è¾ƒé«˜çš„æç¤ºé€‰æ‹©è¿‡ç¨‹ã€‚åŒæ—¶å¼•å…¥äº†ä»·å€¼æ¨¡å‹æ¥é¢„æµ‹æç¤ºéš¾åº¦ï¼Œå…è®¸PCLåœ¨RLè¿‡ç¨‹ä¸­é€æ­¥æŒ‘æˆ˜æ›´å›°éš¾çš„æç¤ºã€‚è¯¥ç ”ç©¶ä¸ºæé«˜æ¨ç†èƒ½åŠ›ç›¸å…³çš„å¼ºåŒ–å­¦ä¹ çš„æ€§èƒ½ä¸æ•ˆç‡æä¾›äº†æ–°çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PCLæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è½»é‡çº§ç®—æ³•ï¼Œç”¨äºé€šè¿‡ä»·å€¼æ¨¡å‹é€‰æ‹©ä¸­ç­‰éš¾åº¦çš„æç¤ºæ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚</li>
<li>PCLè®¾è®¡ç”¨äºå¹³è¡¡ç”Ÿæˆæ•ˆç‡å’Œæ¢¯åº¦è´¨é‡çš„æœ€ä¼˜è®­ç»ƒæ‰¹é‡å¤§å°çš„ç ”ç©¶ã€‚</li>
<li>ä¸­ç­‰éš¾åº¦çš„æç¤ºå¯¹å¼ºåŒ–å­¦ä¹ ç­–ç•¥å°¤ä¸ºé‡è¦ï¼ŒPCLèƒ½å¤Ÿé€šè¿‡ä»·å€¼æ¨¡å‹åœ¨çº¿ç­–ç•¥åœ°è¯†åˆ«è¿™äº›æç¤ºã€‚</li>
<li>PCLæ–¹æ³•èšç„¦äºèƒ½å¤Ÿäº§ç”Ÿé«˜æœ‰æ•ˆç‡çš„æç¤ºï¼Œä»è€Œè¾¾åˆ°é«˜æ€§èƒ½æˆ–è¾ƒå¿«çš„è®­ç»ƒæ—¶é—´ã€‚</li>
<li>ä¸åŸºäºrolloutçš„è¿‡æ»¤æ–¹æ³•ç›¸æ¯”ï¼ŒPCLé¿å…äº†æ˜‚è´µçš„rolloutè¿‡ç¨‹ï¼Œæ˜¾è‘—æé«˜äº†è¯†åˆ«ä¸­ç­‰éš¾åº¦æç¤ºçš„é€Ÿåº¦ã€‚</li>
<li>ä»·å€¼æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æç¤ºçš„éš¾åº¦ï¼Œå¸®åŠ©PCLåœ¨å¼ºåŒ–å­¦ä¹ ä¸­é€æ­¥æŒ‘æˆ˜æ›´å¤æ‚çš„æç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01135">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-747fa30c3be5f05cca3e70f216291f3d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028247&auth_key=1760028247-0-0-a5b3d406f506d8fc7751a9b4d54bc7f9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e3ab4bf332d0b9cf0fed8213769acd04~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028255&auth_key=1760028255-0-0-8aef0ed1b23d473b33a767b53c33fc89&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-35f135b62e969f95c2a70bfb90ddfe48~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028262&auth_key=1760028262-0-0-e9aa797e4a647fffff79a7764c5c86c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5d449f1f76748f9b0270e0f1ed032afe~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028269&auth_key=1760028269-0-0-099074e141b9d0d89f8bb2e4ed68faa5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1ecc58c71bc6cc775bb934ba397ad5f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028276&auth_key=1760028276-0-0-377fa8a74eaf464822145f2aebbaac3d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Practitionerâ€™s-Guide-to-Multi-turn-Agentic-Reinforcement-Learning"><a href="#A-Practitionerâ€™s-Guide-to-Multi-turn-Agentic-Reinforcement-Learning" class="headerlink" title="A Practitionerâ€™s Guide to Multi-turn Agentic Reinforcement Learning"></a>A Practitionerâ€™s Guide to Multi-turn Agentic Reinforcement Learning</h2><p><strong>Authors:Ruiyi Wang, Prithviraj Ammanabrolu</strong></p>
<p>We study what actually works and what doesnâ€™t for training large language models as agents via multi-turn reinforcement learning. Despite rapid progress, existing frameworks and definitions are fragmented, and there is no systematic formulation or analysis of which design choices matter across tasks. We address this gap by first breaking down the design space into three inter-related pillars â€“ environment, reward, and policy â€“ and empirically derive a recipe for training LLM agents in situated textual domains. In particular, we test TextWorld and ALFWorld, popular domains for testing situated embodied reasoning, as well as SWE-Gym for more software engineering style tasks. (i) For the environment, we analyze the impacts of task complexity in terms of sizes of the state and action spaces as well as optimal solution length, finding that even simple environments within a domain can provide signal on how well an agent can generalize to more complex tasks. (ii) For the reward, we ablate relative reward sparsity, observing that while dense turn-level rewards accelerate training, performance and stability is highly dependent on the choice of RL algorithm. (iii) And for the agentâ€™s policy, we explore the interplay between reward sparsity and biased (PPO, GRPO) and unbiased (RLOO) policy gradient methods in addition to showing how to find the optimal Supervised Fine-tuning (SFT) to RL training ratio given a fixed budget. We distill these findings into a training recipe that guides co-design across the three pillars, facilitating research and practical efforts in multi-turn agentic RL. Code: <a target="_blank" rel="noopener" href="https://github.com/pearls-lab/meow-tea-taro">https://github.com/pearls-lab/meow-tea-taro</a> </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶é€šè¿‡å¤šè½®å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºä»£ç†æ—¶ï¼Œå“ªäº›æ–¹æ³•å®é™…ä¸Šæœ‰æ•ˆï¼Œå“ªäº›æ— æ•ˆã€‚å°½ç®¡å–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œä½†ç°æœ‰æ¡†æ¶å’Œå®šä¹‰æ˜¯é›¶ç¢çš„ï¼Œæ²¡æœ‰ç³»ç»Ÿçš„è¡¨è¿°æˆ–åˆ†æï¼Œä¹Ÿæ²¡æœ‰æ˜ç¡®å“ªäº›è®¾è®¡é€‰æ‹©åœ¨ä¸åŒä»»åŠ¡ä¸­å¾ˆé‡è¦ã€‚æˆ‘ä»¬é€šè¿‡é¦–å…ˆå°†å…¶åˆ†è§£ä¸ºä¸‰ä¸ªç›¸äº’å…³è”çš„æ”¯æŸ±â€”â€”ç¯å¢ƒã€å¥–åŠ±å’Œæ”¿ç­–æ¥è§£å†³è¿™ä¸€å·®è·ï¼Œå¹¶å®è¯æ¨å¯¼å‡ºåœ¨æƒ…å¢ƒæ–‡æœ¬åŸŸä¸­è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„é£Ÿè°±ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æµ‹è¯•äº†ç”¨äºæµ‹è¯•æƒ…å¢ƒä½“æ¨ç†çš„æµè¡Œé¢†åŸŸTextWorldå’ŒALFWorldï¼Œä»¥åŠç”¨äºè½¯ä»¶å·¥ç¨‹è®¾è®¡ä»»åŠ¡çš„SWE-Gymã€‚(i)åœ¨ç¯å¢ƒæ–¹é¢ï¼Œæˆ‘ä»¬åˆ†æäº†ä»»åŠ¡å¤æ‚æ€§å¯¹çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´å¤§å°ä»¥åŠæœ€ä½³è§£å†³æ–¹æ¡ˆé•¿åº¦çš„å½±å“ï¼Œå‘ç°å³ä½¿åœ¨æŸä¸ªåŸŸå†…çš„ç®€å•ç¯å¢ƒä¹Ÿå¯ä»¥æä¾›å…³äºä»£ç†å¦‚ä½•æ›´å¥½åœ°æ¨å¹¿åˆ°æ›´å¤æ‚ä»»åŠ¡çš„ä¿¡å·ã€‚(ii)åœ¨å¥–åŠ±æ–¹é¢ï¼Œæˆ‘ä»¬åˆ†æäº†ç›¸å¯¹å¥–åŠ±ç¨€ç–æ€§ï¼Œè§‚å¯Ÿåˆ°è™½ç„¶å¯†é›†çš„å›åˆçº§å¥–åŠ±å¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œä½†æ€§èƒ½å’Œç¨³å®šæ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºé€‰æ‹©çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚(iii)å¯¹äºä»£ç†çš„æ”¿ç­–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¥–åŠ±ç¨€ç–æ€§ä¸æœ‰åï¼ˆPPOï¼ŒGRPOï¼‰å’Œæ— åï¼ˆRLOOï¼‰æ”¿ç­–æ¢¯åº¦æ–¹æ³•ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åœ¨å›ºå®šé¢„ç®—ä¸‹æ‰¾åˆ°æœ€ä½³çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åˆ°å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ¯”ä¾‹ã€‚æˆ‘ä»¬æ€»ç»“å‡ºè¿™äº›å‘ç°ï¼Œå½¢æˆäº†ä¸€ä»½æŒ‡å¯¼è¿™ä¸‰ä¸ªæ”¯æŸ±å…±åŒè®¾è®¡çš„è®­ç»ƒé£Ÿè°±ï¼Œä¿ƒè¿›äº†å¤šè½®ä»£ç†å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶å’Œå®è·µå·¥ä½œã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/pearls-lab/meow-tea-taro">https://github.com/pearls-lab/meow-tea-taro</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01132v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä¸»è¦ç ”ç©¶äº†é€šè¿‡å¤šè½®å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºä»£ç†çš„å®é™…æ•ˆæœã€‚æ–‡ç« é’ˆå¯¹å½“å‰æ¡†æ¶å’Œå®šä¹‰çš„ç¢ç‰‡åŒ–é—®é¢˜ï¼Œé€šè¿‡å®è¯æ–¹æ³•æ¢ç´¢äº†ç¯å¢ƒã€å¥–åŠ±å’Œæ”¿ç­–ä¸‰ä¸ªç›¸äº’å…³è”çš„æ”¯æŸ±åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¹¶æ¨å¯¼å‡ºäº†ä¸€ä¸ªåœ¨æƒ…å¢ƒæ–‡æœ¬åŸŸä¸­è®­ç»ƒLLMä»£ç†äººçš„é…æ–¹ã€‚æ–‡ç« åˆ†æäº†ä»»åŠ¡å¤æ‚æ€§å¯¹çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´ä»¥åŠæœ€ä¼˜è§£é•¿åº¦çš„å½±å“ï¼Œæ¢è®¨äº†å¥–åŠ±ç¨€ç–æ€§å¯¹è®­ç»ƒçš„å½±å“ï¼Œå¹¶æ¢ç´¢äº†ä»£ç†ç­–ç•¥ä¸­å¥–åŠ±ç¨€ç–æ€§ä¸åå‘å’Œæ— åå‘ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æœ€åï¼Œæ–‡ç« å°†ç ”ç©¶æˆæœæ€»ç»“ä¸ºä¸€ä»½è®­ç»ƒé…æ–¹ï¼ŒæŒ‡å¯¼è·¨ä¸‰ä¸ªæ”¯æŸ±çš„ååŒè®¾è®¡ï¼Œä¿ƒè¿›å¤šè½®ä»£ç†å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶å’Œå®è·µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« ç ”ç©¶äº†é€šè¿‡å¤šè½®å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•ˆæœï¼Œå¹¶å¡«è¡¥äº†å½“å‰ç¼ºä¹ç³»ç»Ÿæ€§åˆ†æå’Œè®¾è®¡é€‰æ‹©çš„é‡è¦æ€§è¿™ä¸€ç©ºç™½ã€‚</li>
<li>æ–‡ç« å°†è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„è®¾è®¡ç©ºé—´åˆ†ä¸ºä¸‰ä¸ªç›¸äº’å…³è”çš„æ”¯æŸ±ï¼šç¯å¢ƒã€å¥–åŠ±å’Œæ”¿ç­–ã€‚</li>
<li>æ–‡ç« é€šè¿‡å®è¯åˆ†æï¼Œå‘ç°ä»»åŠ¡å¤æ‚æ€§å¯¹è®­ç»ƒæ•ˆæœæœ‰å½±å“ï¼Œç®€å•ç¯å¢ƒå†…çš„ä»»åŠ¡ä¹Ÿèƒ½ä¸ºæ›´å¤æ‚ä»»åŠ¡çš„æ³›åŒ–æä¾›ä¿¡å·ã€‚</li>
<li>æ–‡ç« æ¢è®¨äº†å¥–åŠ±ç¨€ç–æ€§å¯¹è®­ç»ƒçš„å½±å“ï¼Œå‘ç°è™½ç„¶å¯†é›†çš„å›åˆçº§å¥–åŠ±å¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œä½†æ€§èƒ½å’Œç¨³å®šæ€§é«˜åº¦ä¾èµ–äºé€‰æ‹©çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚</li>
<li>æ–‡ç« æ¢ç´¢äº†ä»£ç†ç­–ç•¥ä¸­å¥–åŠ±ç¨€ç–æ€§ä¸åå‘å’Œæ— åå‘ç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•æ‰¾åˆ°ç»™å®šå›ºå®šé¢„ç®—ä¸‹çš„æœ€ä½³ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¯”ä¾‹ã€‚</li>
<li>æ–‡ç« å°†ç ”ç©¶æˆæœæ€»ç»“ä¸ºä¸€ä»½è®­ç»ƒé…æ–¹ï¼Œä¸ºè·¨ä¸‰ä¸ªæ”¯æŸ±çš„ååŒè®¾è®¡æä¾›äº†æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01132">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9d43be1f0bcc1fa869aeb8160286dc77~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028283&auth_key=1760028283-0-0-75fedf8201d53380f3a2c94db86b7640&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-27f80c20a1967a28b8d29d39b16b08f2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028290&auth_key=1760028290-0-0-ff1f23a571e94eab7c7ac5be42ef5308&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b4852cb5348829e9b57bb456cd4666c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028296&auth_key=1760028296-0-0-164438ab20aebfb720e1a325c0a80333&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b65297c9c3da01abebf1406c5445fad6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028303&auth_key=1760028303-0-0-b9dc26bcd2c8759c145575f0c7dcbe4a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4d1a93ba562fcc68b09515e845abe49e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028310&auth_key=1760028310-0-0-9534f2cfcd52fa8c18bb7c37605ed3b8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CurES-From-Gradient-Analysis-to-Efficient-Curriculum-Learning-for-Reasoning-LLMs"><a href="#CurES-From-Gradient-Analysis-to-Efficient-Curriculum-Learning-for-Reasoning-LLMs" class="headerlink" title="CurES: From Gradient Analysis to Efficient Curriculum Learning for   Reasoning LLMs"></a>CurES: From Gradient Analysis to Efficient Curriculum Learning for   Reasoning LLMs</h2><p><strong>Authors:Yongcheng Zeng, Zexu Sun, Bokai Ji, Erxue Min, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Haifeng Zhang, Xu Chen, Jun Wang</strong></p>
<p>Curriculum learning plays a crucial role in enhancing the training efficiency of large language models (LLMs) on reasoning tasks. However, existing methods often fail to adequately account for variations in prompt difficulty or rely on simplistic filtering mechanisms to select prompt datasets within a narrow criterion range, resulting in significant computational waste. In this work, we approach the problem from the perspective of reinforcement learning gradient optimization, offering a systematic and theoretical investigation into how to improve the training efficiency of LLMs. We identify two key factors influencing training efficiency: the selection of training prompts and the allocation of rollout quantities across different prompts. Our theoretical analysis reveals that the sampling distribution of prompts dictates the convergence rate of gradient descent, while the allocation of the rollout quantity influences the consistency and stability of overall gradient updates. Based on these insights, we propose CurES, an efficient training method that accelerates convergence and employs Bayesian posterior estimation to minimize computational overhead. Experiments demonstrate that our CurES outperforms Group Relative Policy Optimization (GRPO) by \textbf{+3.30} points and \textbf{+4.82} points with 1.5B and 7B models, respectively. Additionally, CurES exhibits faster convergence compared to baselines, including GRPO. </p>
<blockquote>
<p>è¯¾ç¨‹å­¦ä¹ åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è®­ç»ƒæ•ˆç‡æ–¹é¢èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æœªèƒ½å……åˆ†è€ƒè™‘åˆ°æç¤ºéš¾åº¦çš„å˜åŒ–ï¼Œæˆ–è€…åœ¨é€‰æ‹©æç¤ºæ•°æ®é›†æ—¶ä¾èµ–äºç®€åŒ–çš„è¿‡æ»¤æœºåˆ¶ï¼Œä»…åœ¨ç‹­çª„çš„æ ‡å‡†èŒƒå›´å†…è¿›è¡Œé€‰æ‹©ï¼Œä»è€Œå¯¼è‡´å¤§é‡çš„è®¡ç®—æµªè´¹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»å¼ºåŒ–å­¦ä¹ æ¢¯åº¦ä¼˜åŒ–çš„è§’åº¦æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¯¹å¦‚ä½•æé«˜LLMçš„è®­ç»ƒæ•ˆç‡è¿›è¡Œäº†ç³»ç»Ÿå’Œç†è®ºçš„ç ”ç©¶ã€‚æˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªå½±å“è®­ç»ƒæ•ˆç‡çš„å…³é”®å› ç´ ï¼šè®­ç»ƒæç¤ºçš„é€‰æ‹©å’Œä¸åŒæç¤ºçš„rolloutæ•°é‡åˆ†é…ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼Œæç¤ºçš„é‡‡æ ·åˆ†å¸ƒå†³å®šäº†æ¢¯åº¦ä¸‹é™çš„æ”¶æ•›ç‡ï¼Œè€Œrolloutæ•°é‡çš„åˆ†é…å½±å“äº†æ•´ä½“æ¢¯åº¦æ›´æ–°çš„ä¸€è‡´æ€§å’Œç¨³å®šæ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†CurESï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œå¯ä»¥åŠ é€Ÿæ”¶æ•›ï¼Œå¹¶é‡‡ç”¨è´å¶æ–¯åéªŒä¼°è®¡æ¥æœ€å°åŒ–è®¡ç®—å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„CurESåœ¨1.5Bå’Œ7Bçš„æ¨¡å‹ä¸Šåˆ†åˆ«ä¼˜äºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰\textbf{+3.30}ç‚¹å’Œ\textbf{+4.82}ç‚¹ã€‚æ­¤å¤–ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒCurESè¿˜è¡¨ç°å‡ºæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼ŒåŒ…æ‹¬GRPOã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01037v1">PDF</a> 25 pages, 10 Figures</p>
<p><strong>Summary</strong><br>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è®­ç»ƒæ•ˆç‡å¯é€šè¿‡è¯¾ç¨‹å­¦ä¹ å¢å¼ºã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘æç¤ºéš¾åº¦çš„å˜åŒ–æˆ–ä¾èµ–è¿‡äºç®€åŒ–çš„è¿‡æ»¤æœºåˆ¶é€‰æ‹©æç¤ºæ•°æ®é›†ï¼Œé€ æˆå¤§é‡è®¡ç®—æµªè´¹ã€‚æœ¬ç ”ç©¶ä»å¼ºåŒ–å­¦ä¹ æ¢¯åº¦ä¼˜åŒ–çš„è§’åº¦å…¥æ‰‹ï¼Œæå‡ºä¸€ç§ç³»ç»Ÿçš„æé«˜LLMè®­ç»ƒæ•ˆç‡çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«è®­ç»ƒæç¤ºçš„é€‰æ‹©å’Œåœ¨ä¸åŒæç¤ºä¸Šçš„rolloutæ•°é‡åˆ†é…ä¸¤ä¸ªå…³é”®å› ç´ æ¥å½±å“è®­ç»ƒæ•ˆç‡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„CurESæ–¹æ³•ä¼˜äºGroup Relative Policy Optimizationï¼ˆGRPOï¼‰ï¼Œå¹¶åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åŒæ—¶ï¼ŒCurESç›¸è¾ƒäºåŸºçº¿æ–¹æ³•å…·æœ‰æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¾ç¨‹å­¦ä¹ åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†ä»»åŠ¡è®­ç»ƒæ•ˆç‡æ–¹é¢å‘æŒ¥å…³é”®ä½œç”¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨å¯¹æç¤ºéš¾åº¦å˜åŒ–çš„è€ƒè™‘ä¸è¶³å’Œä¾èµ–ç®€åŒ–è¿‡æ»¤æœºåˆ¶çš„é—®é¢˜ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹ã€‚</li>
<li>æœ¬ç ”ç©¶ä»å¼ºåŒ–å­¦ä¹ æ¢¯åº¦ä¼˜åŒ–çš„è§’åº¦ç³»ç»Ÿæé«˜LLMè®­ç»ƒæ•ˆç‡ã€‚</li>
<li>è®­ç»ƒæç¤ºçš„é€‰æ‹©å’Œåœ¨ä¸åŒæç¤ºä¸Šçš„rolloutæ•°é‡åˆ†é…æ˜¯å½±å“è®­ç»ƒæ•ˆç‡çš„å…³é”®å› ç´ ã€‚</li>
<li>é‡‡æ ·åˆ†å¸ƒçš„æç¤ºå†³å®šäº†æ¢¯åº¦ä¸‹é™çš„æ”¶æ•›é€Ÿç‡ï¼Œè€Œrolloutæ•°é‡çš„åˆ†é…å½±å“æ¢¯åº¦æ›´æ–°çš„ç¨³å®šæ€§å’Œä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºçš„CurESæ–¹æ³•é€šè¿‡åŠ é€Ÿæ”¶æ•›å’Œé‡‡ç”¨è´å¶æ–¯åéªŒä¼°è®¡æ¥æœ€å°åŒ–è®¡ç®—å¼€é”€ï¼Œå®ç°æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01037">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-34ca8476784e3cf5e901ae8c9b5ea980~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028317&auth_key=1760028317-0-0-8d47ecb03c6eadfbd4cf68afbe9c66fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0a71cf288d9d72576a6b96b5aa9712c6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028325&auth_key=1760028325-0-0-99229c36aae42396daf706e8bb1e79ef&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Reinforcement-Learning-with-Verifiable-yet-Noisy-Rewards-under-Imperfect-Verifiers"><a href="#Reinforcement-Learning-with-Verifiable-yet-Noisy-Rewards-under-Imperfect-Verifiers" class="headerlink" title="Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect   Verifiers"></a>Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect   Verifiers</h2><p><strong>Authors:Xin-Qiang Cai, Wei Wang, Feng Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama</strong></p>
<p>Reinforcement Learning with Verifiable Rewards (RLVR) trains policies against automated verifiers to avoid costly human labeling. To reduce vulnerability to verifier hacking, many RLVR systems collapse rewards to binary ${0,1}$ during training. This choice carries a cost: it introduces \textit{false negatives} (rejecting correct answers, FNs) and \textit{false positives} (accepting incorrect ones, FPs). For instance, a rule-based checker may mark the correct fraction $\frac{12}{36}$ as wrong when compared against the canonical $\frac{1}{3}$ due to brittle parsing&#x2F;equivalence rules (FN), while a large language model (LLM) judges can be gamed by superficial cues or even a single adversarial token, yielding inflated correctness for wrong solutions (FP). We formalize verifier unreliability by modeling the verifier as a stochastic reward channel with asymmetric noise rates. From this abstraction, we derive two correction algorithms for verifier errors. The first is a \textit{backward} correction that de-biases the observed binary reward to recover an \textit{unbiased} estimator of the clean policy gradient. The second is a \textit{forward} correction that reweights score-function terms so that the expected update direction aligns with the \textit{clean gradient}; notably, it requires only the FN rate. We implement both as lightweight hooks in a group relative policy optimization (GRPO)-based RLVR pipeline and evaluate them on math-reasoning models and benchmarks. Across models and datasets, both corrections improve over uncorrected training; the forward variant converges faster and remains stable under heavier noise. Finally, we show a practical appeal mechanism in which a lightweight LLM verifier estimates the FN rate online by rechecking rule-based negatives, obtaining outperformance compared with other state-of-the-art contenders. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰é€šè¿‡é’ˆå¯¹è‡ªåŠ¨åŒ–éªŒè¯å™¨è®­ç»ƒç­–ç•¥ï¼Œä»¥é¿å…æ˜‚è´µçš„äººåŠ›æ ‡æ³¨ã€‚ä¸ºäº†å‡å°‘éªŒè¯å™¨æ”»å‡»å¸¦æ¥çš„è„†å¼±æ€§ï¼Œè®¸å¤šRLVRç³»ç»Ÿåœ¨è®­ç»ƒæ—¶å°†å¥–åŠ±ç®€åŒ–ä¸ºäºŒå…ƒ{0,1}ã€‚è¿™ç§é€‰æ‹©å¸¦æœ‰æˆæœ¬ï¼šå®ƒå¼•å…¥äº†â€œå‡é˜´æ€§â€ï¼ˆæ‹’ç»æ­£ç¡®ç­”æ¡ˆï¼‰å’Œâ€œå‡é˜³æ€§â€ï¼ˆæ¥å—é”™è¯¯ç­”æ¡ˆï¼‰ã€‚ä¾‹å¦‚ï¼ŒåŸºäºè§„åˆ™çš„æ£€æŸ¥å™¨åœ¨ä¸æ ‡å‡†ç­”æ¡ˆç›¸æ¯”æ—¶ï¼Œå¯èƒ½ä¼šå°†æ­£ç¡®çš„åˆ†æ•°12&#x2F;36æ ‡è®°ä¸ºé”™è¯¯ï¼Œè¿™æ˜¯ç”±äºè„†å¼±çš„è§£æ&#x2F;ç­‰ä»·è§„åˆ™ï¼ˆå‡é˜´æ€§ï¼‰ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åˆ¤æ–­å¯èƒ½ä¼šå—åˆ°è¡¨é¢çº¿ç´¢ç”šè‡³æ˜¯å•ä¸ªå¯¹æŠ—æ€§ä»¤ç‰Œçš„å½±å“ï¼Œä¸ºé”™è¯¯è§£å†³æ–¹æ¡ˆæä¾›è†¨èƒ€çš„æ­£ç¡®æ€§ï¼ˆå‡é˜³æ€§ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡å°†éªŒè¯å™¨å»ºæ¨¡ä¸ºå…·æœ‰ä¸å¯¹ç§°å™ªå£°ç‡çš„éšæœºå¥–åŠ±é€šé“æ¥å½¢å¼åŒ–éªŒè¯å™¨çš„ä¸å¯é æ€§ã€‚ä»è¿™ä¸ªæŠ½è±¡ä¸­ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºä¸¤ç§çº æ­£éªŒè¯å™¨é”™è¯¯çš„ç®—æ³•ã€‚ç¬¬ä¸€ç§æ˜¯â€œå‘åâ€æ ¡æ­£ï¼Œå®ƒé€šè¿‡æ¶ˆé™¤è§‚å¯Ÿåˆ°çš„äºŒå…ƒå¥–åŠ±çš„åè§æ¥æ¢å¤å¹²å‡€çš„æ”¿ç­–æ¢¯åº¦çš„â€œæ— åè§â€ä¼°è®¡å™¨ã€‚ç¬¬äºŒç§æ˜¯â€œå‘å‰â€æ ¡æ­£ï¼Œå®ƒé‡æ–°åŠ æƒåˆ†æ•°å‡½æ•°é¡¹ï¼Œä»¥ä½¿é¢„æœŸæ›´æ–°æ–¹å‘ä¸â€œå¹²å‡€æ¢¯åº¦â€ä¸€è‡´ï¼›å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®ƒåªéœ€è¦FNç‡ã€‚æˆ‘ä»¬å°†è¿™ä¸¤ç§æ–¹æ³•éƒ½å®ç°ä¸ºåŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„RLVRç®¡é“ä¸­çš„è½»é‡çº§é’©å­ï¼Œå¹¶åœ¨æ•°å­¦æ¨ç†æ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œè¯„ä¼°ã€‚åœ¨è·¨æ¨¡å‹å’Œæ•°æ®é›†æ–¹é¢ï¼Œä¸¤ç§æ ¡æ­£æ–¹æ³•éƒ½ä¼˜äºæœªæ ¡æ­£çš„è®­ç»ƒï¼›å‘å‰å˜ç§æ”¶æ•›æ›´å¿«ï¼Œåœ¨æ›´é‡çš„å™ªå£°ä¸‹ä¿æŒç¨³å®šã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ç§å®ç”¨å¸å¼•åŠ›æœºåˆ¶ï¼Œå…¶ä¸­è½»é‡çº§LLMéªŒè¯å™¨é€šè¿‡é‡æ–°æ£€æŸ¥åŸºäºè§„åˆ™çš„è´Ÿé¢ç»“æœæ¥åœ¨çº¿ä¼°è®¡FNç‡ï¼Œå¹¶ä¸å…¶ä»–æœ€æ–°ç«äº‰å¯¹æ‰‹ç›¸æ¯”å–å¾—æ€§èƒ½ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00915v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨è®­ç»ƒç­–ç•¥æ—¶å®¹æ˜“å—åˆ°å¥–åŠ±çš„å½±å“ï¼Œä¸ºäº†å‡å°‘äººå·¥æ ‡ç­¾çš„æˆæœ¬ï¼Œé‡‡ç”¨è‡ªåŠ¨åŒ–éªŒè¯å™¨æ¥å¥–åŠ±çš„ç­–ç•¥ã€‚ä½†è‡ªåŠ¨åŒ–éªŒè¯å™¨å®¹æ˜“è¢«æ”»å‡»ï¼Œä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œä¸€äº›RLç³»ç»Ÿä¼šé€‰æ‹©åœ¨è®­ç»ƒæ—¶å°†å¥–åŠ±è®¾ä¸ºäºŒå…ƒåŒ–ï¼ˆ${0, 1}$ï¼‰ã€‚ç„¶è€Œï¼Œè¿™ç§é€‰æ‹©ä¼šå¯¼è‡´å‡ºç°å‡é˜´æ€§ï¼ˆæ‹’ç»æ­£ç¡®ç­”æ¡ˆï¼‰å’Œå‡é˜³æ€§ï¼ˆæ¥å—é”™è¯¯ç­”æ¡ˆï¼‰çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§å½¢å¼åŒ–çš„éªŒè¯å™¨ä¸ç¨³å®šæ€§æ¨¡å‹ï¼Œä½¿ç”¨éšæœºå¥–åŠ±é€šé“ä¸ä¸å¯¹ç§°å™ªå£°ç‡æ¥æè¿°å…¶å¯é æ€§é—®é¢˜ã€‚æ®æ­¤æ¨å¯¼å‡ºäº†ä¸¤ç§ç”¨äºä¿®æ­£éªŒè¯å™¨é”™è¯¯çš„ç®—æ³•ï¼Œä¸€ç§æ˜¯å‘åä¿®æ­£æ³•ï¼Œç”¨äºçº æ­£è§‚å¯Ÿåˆ°çš„äºŒå…ƒå¥–åŠ±çš„åè§ï¼Œæ¢å¤å¯¹æ¸…æ´æ”¿ç­–æ¢¯åº¦çš„æ— åè§ä¼°è®¡ï¼›å¦ä¸€ç§æ˜¯å‘å‰ä¿®æ­£æ³•ï¼Œé€šè¿‡é‡æ–°åŠ æƒå¾—åˆ†å‡½æ•°é¡¹ä½¿é¢„æœŸçš„æ›´æ–°æ–¹å‘ä¸æ¸…æ´æ¢¯åº¦ä¸€è‡´ã€‚è¿™ä¸¤ç§æ–¹æ³•å‡åœ¨å®é™…åº”ç”¨çš„RLVRç®¡é“ä¸­å¾—åˆ°äº†éªŒè¯ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¿™ä¸¤ç§ä¿®æ­£æ–¹æ³•éƒ½ä¼˜äºæœªä¿®æ­£çš„è®­ç»ƒæ–¹æ³•ï¼Œå…¶ä¸­å‘å‰ä¿®æ­£æ³•æ”¶æ•›æ›´å¿«ï¼Œåœ¨æ›´é‡çš„å™ªå£°ä¸‹ä»èƒ½ä¿æŒç¨³å®šã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åˆ©ç”¨è½»é‡çº§LLMéªŒè¯å™¨åœ¨çº¿ä¼°è®¡å‡é˜´æ€§ç‡çš„å®ç”¨æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ç›¸å¯¹äºå…¶ä»–å…ˆè¿›çš„æ–¹æ³•è¡¨ç°å‡ºäº†è¾ƒå¥½çš„æ€§èƒ½ã€‚æ€»çš„æ¥è¯´ï¼Œæœ¬æ–‡ä¸ºå¤„ç†éªŒè¯å™¨å¥–åŠ±çš„ä¸ç¨³å®šæ€§å’Œæé«˜å¼ºåŒ–å­¦ä¹ è®­ç»ƒç­–ç•¥çš„å¯é æ€§æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ä½¿ç”¨è‡ªåŠ¨åŒ–éªŒè¯å™¨è¿›è¡Œå¥–åŠ±çš„ç­–ç•¥è®­ç»ƒæ—¶é¢ä¸´å®‰å…¨æ€§é—®é¢˜ï¼Œä¸ºäº†å‡å°‘äººå·¥æ ‡ç­¾æˆæœ¬é€‰æ‹©äº†äºŒå…ƒåŒ–çš„å¥–åŠ±æ–¹å¼ã€‚è¿™å¯¼è‡´å‡ºç°å‡é˜´æ€§åŠå‡é˜³æ€§ç»“æœçš„é£é™©å¢åŠ ã€‚</li>
<li>é€šè¿‡å»ºæ¨¡éªŒè¯äº†éªŒè¯å™¨çš„ä¸å¯é æ€§æ˜¯ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼Œç”¨éšæœºå¥–åŠ±é€šé“ä¸ä¸å¯¹ç§°å™ªå£°ç‡è¿›è¡Œæè¿°ã€‚æ­¤æ¨¡å‹ä½¿å¾—ç†è§£éªŒè¯å™¨é”™è¯¯çš„åŸå› å˜å¾—æ›´ä¸ºç›´è§‚ã€‚</li>
<li>åŸºäºå»ºæ¨¡æå‡ºäº†ä¸¤ç§éªŒè¯å™¨é”™è¯¯çš„ä¿®æ­£ç®—æ³•ï¼šå‘åä¿®æ­£æ³•å’Œå‘å‰ä¿®æ­£æ³•ï¼Œå‰è€…çº æ­£è§‚å¯Ÿåˆ°çš„äºŒå…ƒå¥–åŠ±åè§ï¼Œåè€…é€šè¿‡é‡æ–°åŠ æƒå¾—åˆ†å‡½æ•°é¡¹æé«˜é¢„æœŸæ›´æ–°æ–¹å‘ä¸æ¸…æ´æ¢¯åº¦çš„å¯¹é½æ€§ã€‚ä¸¤è€…éƒ½åœ¨å®è·µä¸­è¢«è¯å®æœ‰æ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00915">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-67946fda4cc5b9570ecaa0f48d627af8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028332&auth_key=1760028332-0-0-31c5638e41aa1591048e9e337d6e270a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fd0bbec6f3bb5d80832b722d5b635ffd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028340&auth_key=1760028340-0-0-e33879c36233079a3848e190b7ee6bb0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="RiskPO-Risk-based-Policy-Optimization-via-Verifiable-Reward-for-LLM-Post-Training"><a href="#RiskPO-Risk-based-Policy-Optimization-via-Verifiable-Reward-for-LLM-Post-Training" class="headerlink" title="RiskPO: Risk-based Policy Optimization via Verifiable Reward for LLM   Post-Training"></a>RiskPO: Risk-based Policy Optimization via Verifiable Reward for LLM   Post-Training</h2><p><strong>Authors:Tao Ren, Jinyang Jiang, Hui Yang, Wan Tian, Minhao Zou, Guanghao Li, Zishi Zhang, Qinghao Wang, Shentao Qin, Yanjun Zhao, Rui Tao, Hui Shao, Yijie Peng</strong></p>
<p>Reinforcement learning with verifiable reward has recently emerged as a central paradigm for post-training large language models (LLMs); however, prevailing mean-based methods, such as Group Relative Policy Optimization (GRPO), suffer from entropy collapse and limited reasoning gains. We argue that these issues stem from overemphasizing high-probability output sequences while neglecting rare but informative reasoning paths. To address these challenges, we propose Risk-based Policy Optimization (RiskPO), which substitutes classical mean-based objectives with principled risk measures. Specifically, we introduce a Mixed Value-at-Risk objective that integrates weighted attention over multiple regions of the reward distribution, thereby amplifying gradient signals on challenging instances and preventing overconfident convergence. We further design a bundling scheme that aggregates multiple questions into bundles, thus enriching the feedback signal and yielding more stable and informative training dynamics. Theoretically, we prove that the risk-averse update alleviates entropy collapse and promotes exploration. Numerically, RiskPO achieves consistent and significant improvements in mathematical reasoning, multi-modal reasoning, and code generation benchmarks, surpassing GRPO and its variants on both Pass@1 and Pass@k metrics. Our results demonstrate that risk-based optimization provides a rigorous and effective paradigm for enhancing LLM reasoning capabilities. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ç›¸ç»“åˆï¼Œå·²æˆä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åçš„æ ¸å¿ƒèŒƒå¼ï¼›ç„¶è€Œï¼Œæµè¡Œçš„åŸºäºå‡å€¼çš„æ–¹æ³•ï¼Œå¦‚ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œå­˜åœ¨ç†µå´©æºƒå’Œæ¨ç†å¢ç›Šæœ‰é™çš„é—®é¢˜ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™äº›é—®é¢˜æºäºè¿‡åˆ†å¼ºè°ƒé«˜æ¦‚ç‡çš„è¾“å‡ºåºåˆ—ï¼Œè€Œå¿½è§†äº†ç¨€æœ‰ä½†å¯Œæœ‰ä¿¡æ¯é‡çš„æ¨ç†è·¯å¾„ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé£é™©çš„ç­–ç•¥ä¼˜åŒ–ï¼ˆRiskPOï¼‰ï¼Œå®ƒä»¥åŸåˆ™æ€§çš„é£é™©åº¦é‡æ›¿ä»£äº†ä¼ ç»Ÿçš„åŸºäºå‡å€¼çš„ç›®æ ‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ··åˆValue-at-Riskç›®æ ‡ï¼Œè¯¥ç›®æ ‡é€šè¿‡åŠ æƒå…³æ³¨å¥–åŠ±åˆ†å¸ƒçš„å¤šä¸ªåŒºåŸŸï¼Œä»è€Œå¼ºåŒ–äº†å¯¹å›°éš¾å®ä¾‹çš„æ¢¯åº¦ä¿¡å·å¹¶é˜²æ­¢è¿‡åº¦è‡ªä¿¡çš„æ”¶æ•›ã€‚æˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§æ†ç»‘æ–¹æ¡ˆï¼Œå°†å¤šä¸ªé—®é¢˜èšé›†åœ¨ä¸€èµ·ï¼Œä»è€Œä¸°å¯Œäº†åé¦ˆä¿¡å·å¹¶äº§ç”Ÿäº†æ›´ç¨³å®šå’Œå¯Œæœ‰ä¿¡æ¯çš„è®­ç»ƒåŠ¨æ€ã€‚ç†è®ºä¸Šï¼Œæˆ‘ä»¬è¯æ˜äº†é£é™©åŒæ¶æ›´æ–°å¯ä»¥ç¼“è§£ç†µå´©æºƒå¹¶ä¿ƒè¿›æ¢ç´¢ã€‚ä»æ•°å€¼ä¸Šçœ‹ï¼ŒRiskPOåœ¨æ•°å­¦æ¨ç†ã€å¤šæ¨¡æ€æ¨ç†å’Œä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æŒç»­å’Œæ˜¾è‘—çš„æ”¹è¿›ï¼Œåœ¨Pass@1å’ŒPass@kæŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†GRPOåŠå…¶å˜ä½“ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒåŸºäºé£é™©çš„ä¼˜åŒ–ä¸ºæé«˜LLMæ¨ç†èƒ½åŠ›æä¾›äº†ä¸¥æ ¼æœ‰æ•ˆçš„èŒƒå¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00911v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±å·²æˆä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡è¦èŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºå‡å€¼çš„æ–¹æ³•ï¼ˆå¦‚ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼‰å­˜åœ¨ç†µå´©æºƒå’Œæ¨ç†æ”¶ç›Šæœ‰é™çš„é—®é¢˜ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåŸºäºé£é™©çš„ç­–ç•¥ä¼˜åŒ–ï¼ˆRiskPOï¼‰ï¼Œä»¥é£é™©è¡¡é‡å–ä»£ä¼ ç»Ÿçš„åŸºäºå‡å€¼çš„ç›®æ ‡ã€‚é€šè¿‡å¼•å…¥æ··åˆå€¼åœ¨é£é™©ç›®æ ‡ä¸­æ•´åˆå¥–åŠ±åˆ†å¸ƒçš„å¤šä¸ªåŒºåŸŸçš„åŠ æƒæ³¨æ„åŠ›ï¼Œé˜²æ­¢è¿‡åº¦è‡ªä¿¡æ”¶æ•›ï¼Œåœ¨æŒ‘æˆ˜æ€§å®ä¾‹ä¸Šæ”¾å¤§æ¢¯åº¦ä¿¡å·ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ†ç»‘æ–¹æ¡ˆï¼Œå°†å¤šä¸ªé—®é¢˜æ†ç»‘åœ¨ä¸€èµ·ï¼Œä»è€Œä¸°å¯Œåé¦ˆä¿¡å·ï¼Œäº§ç”Ÿæ›´ç¨³å®šå’Œä¸°å¯Œçš„è®­ç»ƒåŠ¨æ€ã€‚ç†è®ºè¯æ˜ï¼Œé£é™©åŒæ¶æ›´æ–°å¯ç¼“è§£ç†µå´©æºƒå¹¶ä¿ƒè¿›æ¢ç´¢ã€‚æ•°å€¼ä¸Šï¼ŒRiskPOåœ¨æ•°å­¦æ¨ç†ã€å¤šæ¨¡æ€æ¨ç†å’Œä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æŒç»­è€Œæ˜¾è‘—çš„æ”¹è¿›ï¼Œåœ¨Pass@1å’ŒPass@kæŒ‡æ ‡ä¸Šè¶…è¶Šäº†GRPOåŠå…¶å˜ä½“ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºé£é™©çš„ä¼˜åŒ–ä¸ºæé«˜LLMæ¨ç†èƒ½åŠ›æä¾›äº†ä¸¥æ ¼æœ‰æ•ˆçš„èŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±å·²æˆä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„é‡è¦æ–¹æ³•ã€‚</li>
<li>ç°æœ‰åŸºäºå‡å€¼çš„æ–¹æ³•å­˜åœ¨ç†µå´©æºƒå’Œæ¨ç†æ”¶ç›Šæœ‰é™çš„é—®é¢˜ã€‚</li>
<li>åŸºäºé£é™©çš„ç­–ç•¥ä¼˜åŒ–ï¼ˆRiskPOï¼‰é€šè¿‡å¼•å…¥é£é™©è¡¡é‡æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>RiskPOé€šè¿‡æ··åˆå€¼åœ¨é£é™©ç›®æ ‡ä¸­æ•´åˆå¥–åŠ±åˆ†å¸ƒçš„å¤šä¸ªåŒºåŸŸæ¥æ”¾å¤§æ¢¯åº¦ä¿¡å·å¹¶é˜²æ­¢è¿‡åº¦è‡ªä¿¡æ”¶æ•›ã€‚</li>
<li>RiskPOè®¾è®¡äº†ä¸€ç§æ†ç»‘æ–¹æ¡ˆæ¥ä¸°å¯Œåé¦ˆä¿¡å·å¹¶äº§ç”Ÿæ›´ç¨³å®šå’Œä¸°å¯Œçš„è®­ç»ƒåŠ¨æ€ã€‚</li>
<li>é£é™©åŒæ¶æ›´æ–°å¯ç¼“è§£ç†µå´©æºƒå¹¶ä¿ƒè¿›æ¢ç´¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2e8a42c6eeefc128cde91745cd25e5b8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028347&auth_key=1760028347-0-0-169691ce1fba03e99562809343c72a8a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cb7c0dfdb61cee38a5654d169c8f87d7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028354&auth_key=1760028354-0-0-50b2656eda42cba4c5d0826ff8616f52&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="ACPO-Adaptive-Curriculum-Policy-Optimization-for-Aligning-Vision-Language-Models-in-Complex-Reasoning"><a href="#ACPO-Adaptive-Curriculum-Policy-Optimization-for-Aligning-Vision-Language-Models-in-Complex-Reasoning" class="headerlink" title="ACPO: Adaptive Curriculum Policy Optimization for Aligning   Vision-Language Models in Complex Reasoning"></a>ACPO: Adaptive Curriculum Policy Optimization for Aligning   Vision-Language Models in Complex Reasoning</h2><p><strong>Authors:Yunhao Wang, Ziting Li, Shuai Chen, Tao Liu, Chao Song, Junjie Jiang, Jian Zhu, Peng Gao, Bin Qin</strong></p>
<p>Aligning large-scale vision-language models (VLMs) for complex reasoning via reinforcement learning is often hampered by the limitations of existing policy optimization algorithms, such as static training schedules and the rigid, uniform clipping mechanism in Proximal Policy Optimization (PPO). In this work, we introduce Adaptive Curriculum Policy Optimization (ACPO), a novel framework that addresses these challenges through a dual-component adaptive learning strategy. First, ACPO employs a dynamic curriculum that orchestrates a principled transition from a stable, near on-policy exploration phase to an efficient, off-policy exploitation phase by progressively increasing sample reuse. Second, we propose an Advantage-Aware Adaptive Clipping (AAAC) mechanism that replaces the fixed clipping hyperparameter with dynamic, sample-wise bounds modulated by the normalized advantage of each token. This allows for more granular and robust policy updates, enabling larger gradients for high-potential samples while safeguarding against destructive ones. We conduct extensive experiments on a suite of challenging multimodal reasoning benchmarks, including MathVista, LogicVista, and MMMU-Pro. Results demonstrate that ACPO consistently outperforms strong baselines such as DAPO and PAPO, achieving state-of-the-art performance, accelerated convergence, and superior training stability. </p>
<blockquote>
<p>å°†å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆè¿›è¡Œå¤æ‚æ¨ç†æ—¶ï¼Œé€šå¸¸ä¼šå—åˆ°ç°æœ‰ç­–ç•¥ä¼˜åŒ–ç®—æ³•çš„é™åˆ¶ï¼Œä¾‹å¦‚å›ºå®šçš„è®­ç»ƒè®¡åˆ’å’Œè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ä¸­çš„åˆšæ€§ç»Ÿä¸€è£å‰ªæœºåˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†è‡ªé€‚åº”è¯¾ç¨‹ç­–ç•¥ä¼˜åŒ–ï¼ˆACPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åŒç»„ä»¶è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥æ¥è§£å†³è¿™äº›æŒ‘æˆ˜çš„æ–°å‹æ¡†æ¶ã€‚é¦–å…ˆï¼ŒACPOé‡‡ç”¨åŠ¨æ€è¯¾ç¨‹ï¼Œé€šè¿‡æœ‰åŸåˆ™åœ°è¿‡æ¸¡ï¼Œä»ç¨³å®šçš„è¿‘ç­–ç•¥æ¢ç´¢é˜¶æ®µé€æ­¥è¿‡æ¸¡åˆ°é«˜æ•ˆçš„ç¦»ç­–ç•¥åˆ©ç”¨é˜¶æ®µï¼ŒåŒæ—¶é€æ­¥æé«˜æ ·æœ¬å¤ç”¨ç‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¼˜åŠ¿æ„ŸçŸ¥è‡ªé€‚åº”è£å‰ªï¼ˆAAACï¼‰æœºåˆ¶ï¼Œè¯¥æœºåˆ¶ç”¨åŠ¨æ€æ ·æœ¬ç‰¹å®šçš„è¾¹ç•Œæ›¿ä»£å›ºå®šçš„è£å‰ªè¶…å‚æ•°ï¼Œè¿™äº›è¾¹ç•Œç”±æ¯ä¸ªæ ‡è®°çš„å½’ä¸€åŒ–ä¼˜åŠ¿è°ƒåˆ¶ã€‚è¿™å…è®¸è¿›è¡Œæ›´ç²¾ç»†å’Œæ›´ç¨³å¥çš„ç­–ç•¥æ›´æ–°ï¼Œä½¿å¾—å¯¹é«˜æ½œåŠ›æ ·æœ¬çš„æ¢¯åº¦æ›´å¤§ï¼ŒåŒæ—¶é¿å…ç ´åæ€§æ ·æœ¬çš„é£é™©ã€‚æˆ‘ä»¬åœ¨ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼ŒåŒ…æ‹¬MathVistaã€LogicVistaå’ŒMMMU-Proã€‚ç»“æœè¡¨æ˜ï¼ŒACPOå§‹ç»ˆä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œå¦‚DAPOå’ŒPAPOï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€åŠ é€Ÿæ”¶æ•›å’Œä¼˜è¶Šçš„è®­ç»ƒç¨³å®šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00690v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºAdaptive Curriculum Policy Optimizationï¼ˆACPOï¼‰çš„æ–°æ¡†æ¶ï¼Œä»¥è§£å†³å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œå¯¹é½æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ACPOé‡‡ç”¨åŒç»„åˆ†è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…æ‹¬åŠ¨æ€è¯¾ç¨‹å®‰æ’å’Œä¼˜åŠ¿æ„ŸçŸ¥è‡ªé€‚åº”è£å‰ªæœºåˆ¶ã€‚åŠ¨æ€è¯¾ç¨‹å®‰æ’å®ç°ä»ç¨³å®šã€è¿‘ç­–ç•¥æ¢ç´¢é˜¶æ®µå‘é«˜æ•ˆã€ç¦»ç­–ç•¥åˆ©ç”¨é˜¶æ®µçš„åŸåˆ™æ€§è¿‡æ¸¡ã€‚ä¼˜åŠ¿æ„ŸçŸ¥è‡ªé€‚åº”è£å‰ªæœºåˆ¶åˆ™æ›¿ä»£å›ºå®šè£å‰ªè¶…å‚æ•°ï¼Œé‡‡ç”¨æ ·æœ¬ä¼˜åŠ¿çš„åŠ¨æ€è°ƒæ•´ã€‚å®éªŒè¯æ˜ï¼ŒACPOåœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œå¦‚MathVistaã€LogicVistaå’ŒMMMU-Proï¼Œä¼˜äºDAPOå’ŒPAPOç­‰å¼ºåŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ACPOæ¡†æ¶è§£å†³äº†å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œå¯¹é½çš„æŒ‘æˆ˜ã€‚</li>
<li>é‡‡ç”¨åŠ¨æ€è¯¾ç¨‹å®‰æ’ï¼Œå®ç°ä»ç¨³å®šæ¢ç´¢é˜¶æ®µåˆ°é«˜æ•ˆåˆ©ç”¨é˜¶æ®µçš„è¿‡æ¸¡ã€‚</li>
<li>å¼•å…¥ä¼˜åŠ¿æ„ŸçŸ¥è‡ªé€‚åº”è£å‰ªæœºåˆ¶ï¼Œæ›¿ä»£å›ºå®šè£å‰ªè¶…å‚æ•°ã€‚</li>
<li>ACPOåœ¨å¤šä¸ªå¤šæ¨¡æ€æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå¦‚MathVistaã€LogicVistaå’ŒMMMU-Proã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00690">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d12d2233891b7bfb0f47a2b9e106f633~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028361&auth_key=1760028361-0-0-5732fe0cab1ef3f473344de4e385063f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-38a741739e62c6b499740c4b4ee52f88~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028369&auth_key=1760028369-0-0-44078aacf627f8d00d31efe60880a5e5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8bb79fc27844735d09ce724ff5a26f25~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028376&auth_key=1760028376-0-0-a510041a3369d08a619ffe954e299c52&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-937f64a9d476857b1125062c1cff5b54~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028383&auth_key=1760028383-0-0-681b675eba22743e210b5539e0178088&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="OIG-Bench-A-Multi-Agent-Annotated-Benchmark-for-Multimodal-One-Image-Guides-Understanding"><a href="#OIG-Bench-A-Multi-Agent-Annotated-Benchmark-for-Multimodal-One-Image-Guides-Understanding" class="headerlink" title="OIG-Bench: A Multi-Agent Annotated Benchmark for Multimodal One-Image   Guides Understanding"></a>OIG-Bench: A Multi-Agent Annotated Benchmark for Multimodal One-Image   Guides Understanding</h2><p><strong>Authors:Jiancong Xie, Wenjin Wang, Zhuomeng Zhang, Zihan Liu, Qi Liu, Ke Feng, Zixun Sun, Yuedong Yang</strong></p>
<p>Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities. However, evaluating their capacity for human-like understanding in One-Image Guides remains insufficiently explored. One-Image Guides are a visual format combining text, imagery, and symbols to present reorganized and structured information for easier comprehension, which are specifically designed for human viewing and inherently embody the characteristics of human perception and understanding. Here, we present OIG-Bench, a comprehensive benchmark focused on One-Image Guide understanding across diverse domains. To reduce the cost of manual annotation, we developed a semi-automated annotation pipeline in which multiple intelligent agents collaborate to generate preliminary image descriptions, assisting humans in constructing image-text pairs. With OIG-Bench, we have conducted a comprehensive evaluation of 29 state-of-the-art MLLMs, including both proprietary and open-source models. The results show that Qwen2.5-VL-72B performs the best among the evaluated models, with an overall accuracy of 77%. Nevertheless, all models exhibit notable weaknesses in semantic understanding and logical reasoning, indicating that current MLLMs still struggle to accurately interpret complex visual-text relationships. In addition, we also demonstrate that the proposed multi-agent annotation system outperforms all MLLMs in image captioning, highlighting its potential as both a high-quality image description generator and a valuable tool for future dataset construction. Datasets are available at <a target="_blank" rel="noopener" href="https://github.com/XiejcSYSU/OIG-Bench">https://github.com/XiejcSYSU/OIG-Bench</a>. </p>
<blockquote>
<p>è¿‘æœŸå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›å±•å±•ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¯„ä¼°å®ƒä»¬åœ¨ä»¥å›¾æ–‡å¼•å¯¼ï¼ˆOne-Image Guidesï¼‰å½¢å¼çš„äººæœºç±»ç†è§£æ–¹é¢ä»ç ”ç©¶ä¸è¶³ã€‚å›¾æ–‡å¼•å¯¼æ˜¯ä¸€ç§ç»“åˆäº†æ–‡æœ¬ã€å›¾åƒå’Œç¬¦å·çš„è§†è§‰å½¢å¼ï¼Œç”¨ä»¥å‘ˆç°é‡æ–°ç»„ç»‡å’Œç»“æ„åŒ–çš„ä¿¡æ¯ä»¥ä¾¿äºç†è§£ï¼Œä¸“ä¸ºäººç±»è§‚çœ‹è®¾è®¡ï¼Œæœ¬è´¨ä¸Šä½“ç°äº†äººç±»æ„ŸçŸ¥å’Œç†è§£çš„ç‰¹ç‚¹ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†OIG-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢å…³æ³¨å›¾æ–‡å¼•å¯¼ç†è§£çš„è·¨åŸŸåŸºå‡†æµ‹è¯•ã€‚ä¸ºäº†é™ä½æ‰‹åŠ¨æ ‡æ³¨çš„æˆæœ¬ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŠè‡ªåŠ¨æ ‡æ³¨ç®¡é“ï¼Œå¤šä¸ªæ™ºèƒ½ä»£ç†åœ¨å…¶ä¸­åä½œç”Ÿæˆåˆæ­¥çš„å›¾åƒæè¿°ï¼ŒååŠ©äººç±»æ„å»ºå›¾åƒæ–‡æœ¬å¯¹ã€‚é€šè¿‡OIG-Benchï¼Œæˆ‘ä»¬å¯¹29ä¸ªæœ€æ–°MLLMsè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬ä¸“æœ‰å’Œå¼€æºæ¨¡å‹ã€‚ç»“æœæ˜¾ç¤ºï¼ŒQwen2.5-VL-72Båœ¨è¯„ä¼°æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ï¼Œæ€»ä½“å‡†ç¡®ç‡ä¸º77%ã€‚ç„¶è€Œï¼Œæ‰€æœ‰æ¨¡å‹åœ¨è¯­ä¹‰ç†è§£å’Œé€»è¾‘æ¨ç†æ–¹é¢éƒ½å­˜åœ¨æ˜æ˜¾å¼±ç‚¹ï¼Œè¡¨æ˜å½“å‰MLLMsåœ¨å‡†ç¡®è§£é‡Šå¤æ‚è§†è§‰æ–‡æœ¬å…³ç³»æ–¹é¢ä»æœ‰å›°éš¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯æ˜ï¼Œæå‡ºçš„å¤šä»£ç†æ ‡æ³¨ç³»ç»Ÿåœ¨å›¾åƒæè¿°æ–¹é¢ä¼˜äºæ‰€æœ‰MLLMsï¼Œæ˜¾ç¤ºå‡ºå…¶ä½œä¸ºé«˜è´¨é‡å›¾åƒæè¿°ç”Ÿæˆå™¨å’Œæœªæ¥æ•°æ®é›†æ„å»ºå·¥å…·çš„æ½œåŠ›ã€‚æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/XiejcSYSU/OIG-Bench%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/XiejcSYSU/OIG-Benchè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.00069v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†æœ€è¿‘çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç†è§£One-Image Guidesæ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹çš„è¡¨ç°ï¼Œç ”ç©¶è€…ä»¬æå‡ºäº†OIG-BenchåŸºå‡†æµ‹è¯•ï¼Œå¹¶å¯¹29ä¸ªæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼ŒQwen2.5-VL-72Bæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œä½†æ‰€æœ‰æ¨¡å‹åœ¨è¯­ä¹‰ç†è§£å’Œé€»è¾‘æ¨ç†æ–¹é¢éƒ½å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜å‘ç°é‡‡ç”¨çš„å¤šæ™ºèƒ½ä»£ç†æ³¨é‡Šç³»ç»Ÿåœ¨å›¾åƒæè¿°æ–¹é¢ä¼˜äºæ‰€æœ‰MLLMsã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç†è§£One-Image Guidesæ–¹é¢å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚</li>
<li>OIG-Benchæ˜¯ä¸€ä¸ªé’ˆå¯¹One-Image Guideç†è§£çš„ç»¼åˆæ€§åŸºå‡†æµ‹è¯•ã€‚</li>
<li>Qwen2.5-VL-72Båœ¨OIG-Benchæµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ï¼Œä½†æ‰€æœ‰æ¨¡å‹åœ¨è¯­ä¹‰ç†è§£å’Œé€»è¾‘æ¨ç†æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä»£ç†æ³¨é‡Šç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåœ¨å›¾åƒæè¿°æ–¹é¢ä¼˜äºæ‰€æœ‰MLLMsã€‚</li>
<li>è¯¥æ³¨é‡Šç³»ç»Ÿå¯ç”Ÿæˆé«˜è´¨é‡å›¾åƒæè¿°ï¼Œå¯¹äºæœªæ¥æ•°æ®é›†æ„å»ºå…·æœ‰æ½œåœ¨ä»·å€¼ã€‚</li>
<li>æ•°æ®é›†å¯åœ¨XiejcSYSU&#x2F;OIG-Benchçš„GitHubä»“åº“è·å–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.00069">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-bbb72312466e9c4ff4702a545022c3be~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028390&auth_key=1760028390-0-0-d35312dc2e94772ffeb9f67ba37d1ed7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6528270483199bd8ad33f0a955722003~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028397&auth_key=1760028397-0-0-2de13f21ce66d86c26e18ba124251366&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-71a1da7dfa02c5cc024e95a3909d72b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028404&auth_key=1760028404-0-0-47165636356f179ee4c9b0abff97c6c7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7432491a943dbb7c6992ae1f370fecfa~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028410&auth_key=1760028410-0-0-2df5f58a16f04577c59892d474d0b6dc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Interactive-Learning-for-LLM-Reasoning"><a href="#Interactive-Learning-for-LLM-Reasoning" class="headerlink" title="Interactive Learning for LLM Reasoning"></a>Interactive Learning for LLM Reasoning</h2><p><strong>Authors:Hehai Lin, Shilei Cao, Sudong Wang, Haotian Wu, Minzhi Li, Linyi Yang, Juepeng Zheng, Chengwei Qin</strong></p>
<p>Existing multi-agent learning approaches have developed interactive training environments to explicitly promote collaboration among multiple Large Language Models (LLMs), thereby constructing stronger multi-agent systems (MAS). However, during inference, they require re-executing the MAS to obtain final solutions, which diverges from human cognition that individuals can enhance their reasoning capabilities through interactions with others and resolve questions independently in the future. To investigate whether multi-agent interaction can enhance LLMsâ€™ independent problem-solving ability, we introduce ILR, a novel co-learning framework for MAS that integrates two key components: Dynamic Interaction and Perception Calibration. Specifically, Dynamic Interaction first adaptively selects either cooperative or competitive strategies depending on question difficulty and model ability. LLMs then exchange information through Idea3 (Idea Sharing, Idea Analysis, and Idea Fusion), an innovative interaction paradigm designed to mimic human discussion, before deriving their respective final answers. In Perception Calibration, ILR employs Group Relative Policy Optimization (GRPO) to train LLMs while integrating one LLMâ€™s reward distribution characteristics into anotherâ€™s reward function, thereby enhancing the cohesion of multi-agent interactions. We validate ILR on three LLMs across two model families of varying scales, evaluating performance on five mathematical benchmarks and one coding benchmark. Experimental results show that ILR consistently outperforms single-agent learning, yielding an improvement of up to 5% over the strongest baseline. We further discover that Idea3 can enhance the robustness of stronger LLMs during multi-agent inference, and dynamic interaction types can boost multi-agent learning compared to pure cooperative or competitive strategies. </p>
<blockquote>
<p>ç°æœ‰çš„å¤šæ™ºèƒ½ä½“å­¦ä¹ æ–¹æ³•å·²ç»æ„å»ºäº†äº¤äº’å¼è®­ç»ƒç¯å¢ƒï¼Œä»¥æ˜ç¡®ä¿ƒè¿›å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¹‹é—´çš„åä½œï¼Œä»è€Œæ„å»ºæ›´å¼ºå¤§çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ã€‚ç„¶è€Œï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒä»¬éœ€è¦é‡æ–°æ‰§è¡ŒMASæ¥è·å¾—æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œè¿™ä¸äººç±»è®¤çŸ¥ç›¸æ‚–â€”â€”äººç±»å¯ä»¥é€šè¿‡ä¸ä»–äººäº’åŠ¨å¢å¼ºè‡ªå·±çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨æœªæ¥ç‹¬ç«‹è§£å†³é—®é¢˜ã€‚ä¸ºäº†è°ƒæŸ¥å¤šæ™ºèƒ½ä½“äº’åŠ¨æ˜¯å¦èƒ½å¢å¼ºLLMçš„ç‹¬ç«‹è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†ILRï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“ååŒå­¦ä¹ æ¡†æ¶ï¼Œå®ƒé›†æˆäº†ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šåŠ¨æ€äº¤äº’å’Œæ„ŸçŸ¥æ ¡å‡†ã€‚å…·ä½“æ¥è¯´ï¼ŒåŠ¨æ€äº¤äº’é¦–å…ˆæ ¹æ®é—®é¢˜çš„éš¾åº¦å’Œæ¨¡å‹èƒ½åŠ›è‡ªé€‚åº”åœ°é€‰æ‹©åˆä½œæˆ–ç«äº‰ç­–ç•¥ã€‚ç„¶åLLMé€šè¿‡æ¨¡ä»¿äººç±»è®¨è®ºçš„åˆ›æ–°äº’åŠ¨æ¨¡å¼Idea3ï¼ˆæ€æƒ³å…±äº«ã€æ€æƒ³åˆ†æå’Œæ€æƒ³èåˆï¼‰ï¼Œäº¤æ¢ä¿¡æ¯ï¼Œç„¶åå¾—å‡ºå„è‡ªçš„æœ€ç»ˆç­”æ¡ˆã€‚åœ¨æ„ŸçŸ¥æ ¡å‡†ä¸­ï¼ŒILRé‡‡ç”¨ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¥è®­ç»ƒLLMï¼ŒåŒæ—¶å°†ä¸€ä¸ªLLMçš„å¥–åŠ±åˆ†å¸ƒç‰¹æ€§æ•´åˆåˆ°å¦ä¸€ä¸ªLLMçš„å¥–åŠ±å‡½æ•°ä¸­ï¼Œä»è€Œæé«˜å¤šæ™ºèƒ½ä½“äº’åŠ¨çš„å‡èšåŠ›ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªä¸åŒè§„æ¨¡çš„æ¨¡å‹å®¶æ—ä¸­çš„ä¸‰ä¸ªLLMä¸ŠéªŒè¯äº†ILRçš„æœ‰æ•ˆæ€§ï¼Œé€šè¿‡äº”ä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•å’Œä¸€ä¸ªç¼–ç åŸºå‡†æµ‹è¯•è¯„ä¼°æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒILRå§‹ç»ˆä¼˜äºå•æ™ºèƒ½ä½“å­¦ä¹ ï¼Œæ¯”æœ€å¼ºåŸºçº¿æé«˜äº†é«˜è¾¾5%ã€‚æˆ‘ä»¬è¿˜å‘ç°Idea3å¯ä»¥å¢å¼ºæ›´å¼ºLLMåœ¨å¤šæ™ºèƒ½ä½“æ¨ç†è¿‡ç¨‹ä¸­çš„ç¨³å¥æ€§ï¼Œå¹¶ä¸”ä¸çº¯ç²¹çš„åˆä½œæˆ–ç«äº‰ç­–ç•¥ç›¸æ¯”ï¼ŒåŠ¨æ€äº¤äº’ç±»å‹å¯ä»¥ä¿ƒè¿›å¤šæ™ºèƒ½ä½“å­¦ä¹ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.26306v3">PDF</a> The code is available at   <a target="_blank" rel="noopener" href="https://github.com/linhh29/Interactive-Learning-for-LLM-Reasoning">https://github.com/linhh29/Interactive-Learning-for-LLM-Reasoning</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç°æœ‰çš„å¤šæ™ºèƒ½ä½“å­¦ä¹ æ–¹æ³•æ˜¯æ„å»ºäº¤äº’å¼è®­ç»ƒç¯å¢ƒä»¥ä¿ƒè¿›å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹é—´çš„åä½œï¼Œè¿›è€Œæ„å»ºæ›´å¼ºçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚ç„¶è€Œï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒä»¬éœ€è¦é‡æ–°æ‰§è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ‰èƒ½è·å¾—æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼Œè¿™ä¸äººç±»è®¤çŸ¥ä¸åŒï¼Œäººç±»å¯ä»¥åœ¨ä¸ä»–äººäº’åŠ¨ä¸­æå‡æ¨ç†èƒ½åŠ›å¹¶åœ¨æœªæ¥ç‹¬ç«‹è§£å†³é—®é¢˜ã€‚ä¸ºäº†æ¢ç©¶å¤šæ™ºèƒ½ä½“äº¤äº’æ˜¯å¦èƒ½æå‡å¤§å‹è¯­è¨€æ¨¡å‹ç‹¬ç«‹è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†ILRï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»ŸååŒå­¦ä¹ æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŠ¨æ€äº¤äº’å’Œæ„ŸçŸ¥æ ¡å‡†ã€‚åŠ¨æ€äº¤äº’æ ¹æ®é—®é¢˜çš„éš¾åº¦å’Œæ¨¡å‹èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©åˆä½œæˆ–ç«äº‰ç­–ç•¥ã€‚å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡æ¨¡ä»¿äººç±»è®¨è®ºçš„ç†å¿µäº¤æ¢ä¿¡æ¯ï¼Œç„¶åè¿›è¡Œæœ€ç»ˆçš„ç­”æ¡ˆæ¨å¯¼ã€‚åœ¨æ„ŸçŸ¥æ ¡å‡†ä¸­ï¼ŒILRé‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–æ–¹æ³•è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶æ•´åˆä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„å¥–åŠ±åˆ†å¸ƒç‰¹æ€§åˆ°å¦ä¸€ä¸ªçš„å¥–åŠ±å‡½æ•°ä¸­ï¼Œä»è€Œæå‡å¤šæ™ºèƒ½ä½“äº¤äº’çš„å‡èšåŠ›ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªä¸åŒè§„æ¨¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸ŠéªŒè¯äº†ILRçš„æœ‰æ•ˆæ€§ï¼Œè¯„ä¼°å…¶åœ¨äº”ä¸ªæ•°å­¦åŸºå‡†æµ‹è¯•å’Œä¸€ä¸ªç¼–ç åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒILRå§‹ç»ˆä¼˜äºå•æ™ºèƒ½ä½“å­¦ä¹ ï¼Œå¹¶åœ¨æœ€å¼ºçš„åŸºå‡†æµ‹è¯•ä¸Šæé«˜äº†æœ€å¤š5%çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜å‘ç°ç†å¿µäº¤æ¢åœ¨å¤šæ™ºèƒ½ä½“æ¨ç†ä¸­å¢å¼ºäº†å¼ºå¤§æ¨¡å‹çš„ç¨³å¥æ€§ï¼Œè€ŒåŠ¨æ€äº¤äº’ç±»å‹ç›¸è¾ƒäºçº¯ç²¹çš„åˆä½œæˆ–ç«äº‰ç­–ç•¥æ›´èƒ½ä¿ƒè¿›å¤šæ™ºèƒ½ä½“å­¦ä¹ ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å­¦ä¹ æ–¹æ³•é€šè¿‡æ„å»ºäº¤äº’å¼è®­ç»ƒç¯å¢ƒä¿ƒè¿›å¤§å‹è¯­è¨€æ¨¡å‹é—´çš„åä½œã€‚</li>
<li>ç°æœ‰æ–¹æ³•éœ€è¦é‡æ–°æ‰§è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¥è·å¾—è§£å†³æ–¹æ¡ˆï¼Œä¸äººç±»ç‹¬ç«‹è§£å†³é—®é¢˜çš„èƒ½åŠ›æœ‰æ‰€ä¸åŒã€‚</li>
<li>ILRæ¡†æ¶å¼•å…¥åŠ¨æ€äº¤äº’å’Œæ„ŸçŸ¥æ ¡å‡†æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„ç‹¬ç«‹é—®é¢˜è§£å†³èƒ½åŠ›ã€‚</li>
<li>åŠ¨æ€äº¤äº’æ ¹æ®é—®é¢˜éš¾åº¦å’Œæ¨¡å‹èƒ½åŠ›è‡ªé€‚åº”é€‰æ‹©åˆä½œæˆ–ç«äº‰ç­–ç•¥ã€‚</li>
<li>é€šè¿‡æ¨¡ä»¿äººç±»è®¨è®ºçš„ç†å¿µäº¤æ¢ä¿¡æ¯ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæœ€ç»ˆçš„ç­”æ¡ˆæ¨å¯¼ã€‚</li>
<li>æ„ŸçŸ¥æ ¡å‡†é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–æ–¹æ³•è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¢å¼ºå¤šæ™ºèƒ½ä½“äº¤äº’çš„å‡èšåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.26306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b31a00848c9e9085a89f4b79ea3b0059~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028418&auth_key=1760028418-0-0-3740d50f16ad5367d93496a7e41b8ac5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d428ccc45900ea3daf9be38941fb8b05~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028425&auth_key=1760028425-0-0-312959a04069a1bd5ab1300ccb3d4c2b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9c9e460d7d988f375d06468f38f54f5c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028432&auth_key=1760028432-0-0-3e238b4b02783d2f6a935fe8f3653ff4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="More-Thought-Less-Accuracy-On-the-Dual-Nature-of-Reasoning-in-Vision-Language-Models"><a href="#More-Thought-Less-Accuracy-On-the-Dual-Nature-of-Reasoning-in-Vision-Language-Models" class="headerlink" title="More Thought, Less Accuracy? On the Dual Nature of Reasoning in   Vision-Language Models"></a>More Thought, Less Accuracy? On the Dual Nature of Reasoning in   Vision-Language Models</h2><p><strong>Authors:Xinyu Tian, Shu Zou, Zhaoyuan Yang, Mengqi He, Fabian Waschkowski, Lukas Wesemann, Peter Tu, Jing Zhang</strong></p>
<p>Reasoning has emerged as a pivotal capability in Large Language Models (LLMs). Through Reinforcement Learning (RL), typically Group Relative Policy Optimization (GRPO), these models are able to solve complex tasks such as mathematics and code generation. Building on these advances, recent research has sought to extend reasoning to Vision-Language Models (VLMs), yielding promising results across diverse visual tasks. Despite this progress, our study uncovers the dual nature of multimodal reasoning: while it substantially enhances logical inference and facilitates performance on challenging problems, it may gradually impair perceptual grounding, leading to recognition failures on otherwise basic visual questions. Through further analysis, we attribute this phenomenon to visual forgetting, wherein prolonged reasoning causes the model to increasingly disregard visual input. To address this, we propose Vision-Anchored Policy Optimization (VAPO), a simple yet effective method that explicitly steers the reasoning process toward visually grounded trajectories. Our result model, VAPO-Thinker-7B, significantly strengthens the modelâ€™s reliance on visual information and achieves new state-of-the-art results on a wide range of established benchmarks. Project page: <a target="_blank" rel="noopener" href="https://xytian1008.github.io/VAPO/">https://xytian1008.github.io/VAPO/</a> </p>
<blockquote>
<p>æ¨ç†å·²æˆä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„å…³é”®èƒ½åŠ›ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œé€šå¸¸æ˜¯ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿè§£å†³æ•°å­¦å’Œä»£ç ç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡ã€‚åœ¨è¿™äº›è¿›å±•çš„åŸºç¡€ä¸Šï¼Œæœ€è¿‘çš„ç ”ç©¶è¯•å›¾å°†æ¨ç†æ‰©å±•åˆ°è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººé¼“èˆçš„ç»“æœã€‚å°½ç®¡å–å¾—äº†è¿›å±•ï¼Œä½†æˆ‘ä»¬çš„ç ”ç©¶å‘ç°å¤šæ¨¡æ€æ¨ç†å…·æœ‰åŒé‡æ€§ï¼šè™½ç„¶å®ƒå¤§å¤§æé«˜äº†é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¹¶æœ‰åŠ©äºè§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œä½†å®ƒå¯èƒ½ä¼šé€æ¸æŸå®³æ„ŸçŸ¥å®šä½èƒ½åŠ›ï¼Œå¯¼è‡´å¯¹åŸºæœ¬è§†è§‰é—®é¢˜çš„è¯†åˆ«å¤±è´¥ã€‚é€šè¿‡è¿›ä¸€æ­¥åˆ†æï¼Œæˆ‘ä»¬å°†è¿™ç§ç°è±¡å½’å› äºè§†è§‰é—å¿˜ï¼Œé•¿æ—¶é—´çš„æ¨ç†ä¼šå¯¼è‡´æ¨¡å‹è¶Šæ¥è¶Šå¿½è§†è§†è§‰è¾“å…¥ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è§†è§‰é”šå®šç­–ç•¥ä¼˜åŒ–ï¼ˆVAPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿæ˜ç¡®å¼•å¯¼æ¨ç†è¿‡ç¨‹èµ°å‘è§†è§‰å®šä½è½¨è¿¹ã€‚æˆ‘ä»¬çš„ç»“æœæ¨¡å‹VAPO-Thinker-7Bå¤§å¤§å¢å¼ºäº†æ¨¡å‹å¯¹è§†è§‰ä¿¡æ¯çš„ä¾èµ–ï¼Œå¹¶åœ¨å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†åˆ›çºªå½•çš„è¶…é«˜æ°´å¹³ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://xytian1008.github.io/VAPO/%EF%BC%88%E5%A6%82%E6%B6%89%E5%8F%8A%E5%88%B0%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%BF%BB%E8%AF%91%E4%B8%8D%E7%B2%BE%E7%A1%AE%E6%83%85%E5%86%B5%EF%BC%8C%E8%AF%B7%E4%BB%A5%E5%85%B7%E4%BD%93%E5%AD%A6%E6%9C%AF%E5%87%BA%E7%89%88%E7%89%A9%E4%B8%BA%E5%87%86%EF%BC%89">https://xytian1008.github.io/VAPO/ï¼ˆå¦‚æ¶‰åŠåˆ°ä¸“ä¸šæœ¯è¯­å¯èƒ½å­˜åœ¨ç¿»è¯‘ä¸ç²¾ç¡®æƒ…å†µï¼Œè¯·ä»¥å…·ä½“å­¦æœ¯å‡ºç‰ˆç‰©ä¸ºå‡†ï¼‰</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25848v2">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œé›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥å®Œæˆæ•°å­¦å’Œä»£ç ç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡ã€‚æœ€æ–°ç ”ç©¶å°†æ¨ç†æ‰©å±•åˆ°è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç°å¤šæ¨¡æ€æ¨ç†å…·æœ‰åŒé‡æ€§è´¨ï¼Œåœ¨æé«˜é€»è¾‘æ¨æ–­èƒ½åŠ›çš„åŒæ—¶ï¼Œå¯èƒ½å¯¼è‡´åŸºæœ¬è§†è§‰é—®é¢˜çš„è¯†åˆ«å¤±è´¥ï¼Œè¿™æ˜¯ç”±äºè§†è§‰é—å¿˜ç°è±¡å¯¼è‡´çš„ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†è§†è§‰é”šå®šç­–ç•¥ä¼˜åŒ–ï¼ˆVAPOï¼‰ï¼Œè®©æ¨ç†è¿‡ç¨‹æ›´åŠ ä¾èµ–è§†è§‰ä¿¡æ¯ï¼Œæ–°çš„æ¨¡å‹VAPO-Thinker-7Båœ¨å¹¿æ³›çš„æ ‡å‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æŠ€æœ¯æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œé›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚</li>
<li>è§†è§‰è¯­è¨€æ¨¡å‹çš„æœ€æ–°ç ”ç©¶æ‰©å±•äº†æ¨ç†èƒ½åŠ›ï¼Œåœ¨å¤šç§è§†è§‰ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>å¤šæ¨¡æ€æ¨ç†å…·æœ‰åŒé‡æ€§è´¨ï¼Œæ—¢æé«˜é€»è¾‘æ¨æ–­èƒ½åŠ›åˆå¯èƒ½å¯¼è‡´åŸºæœ¬è§†è§‰é—®é¢˜çš„è¯†åˆ«å¤±è´¥ã€‚</li>
<li>å¤šæ¨¡æ€æ¨ç†ä¸­è§†è§‰é—å¿˜ç°è±¡å¯¼è‡´æ¨¡å‹å¿½ç•¥è§†è§‰è¾“å…¥ã€‚</li>
<li>ä¸ºè§£å†³è§†è§‰é—å¿˜é—®é¢˜ï¼Œæå‡ºäº†è§†è§‰é”šå®šç­–ç•¥ä¼˜åŒ–æ–¹æ³•ã€‚</li>
<li>æ–°çš„æ¨¡å‹VAPO-Thinker-7Bæ›´åŠ ä¾èµ–è§†è§‰ä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25848">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-2099d76e88ac3d2e8bf2de72db4944e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028439&auth_key=1760028439-0-0-493563aaf54e563bbabdc0ad52713985&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ba378dd9af35af3afc2b52b0166cc054~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028446&auth_key=1760028446-0-0-3227d6bd7c3eee61d208ef8883a9b761&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fefacbfacaba099ae8b9dd878f684134~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028453&auth_key=1760028453-0-0-908cce87a9633f1ff1a424ca56839d01&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0b6397cf408acb49c863d54421090147~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028460&auth_key=1760028460-0-0-871cb44d8448219ac28af398896c4e54&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Euclidâ€™s-Gift-Enhancing-Spatial-Perception-and-Reasoning-in-Vision-Language-Models-via-Geometric-Surrogate-Tasks"><a href="#Euclidâ€™s-Gift-Enhancing-Spatial-Perception-and-Reasoning-in-Vision-Language-Models-via-Geometric-Surrogate-Tasks" class="headerlink" title="Euclidâ€™s Gift: Enhancing Spatial Perception and Reasoning in   Vision-Language Models via Geometric Surrogate Tasks"></a>Euclidâ€™s Gift: Enhancing Spatial Perception and Reasoning in   Vision-Language Models via Geometric Surrogate Tasks</h2><p><strong>Authors:Shijie Lian, Changti Wu, Laurence Tianruo Yang, Hang Yuan, Bin Yu, Lei Zhang, Kai Chen</strong></p>
<p>Spatial intelligence spans a rich suite of abilities, including visualising and transforming shapes, mentally rotating objects, judging relational positions and containment, and estimating numerosity. However, it still remains a critical unresolved challenge for Multimodal Large Language Models (MLLMs).To fill this gap, we propose to treat Euclidean geometry problem-solving as a surrogate task. Specifically, we meticulously constructed a curated multimodal dataset, called Euclid30K, comprising approximately 30K plane and solid geometry problems. To enable the model to acquire and apply Euclidean principles from these geometry problems, we employed Group Relative Policy Optimization (GRPO) to finetune the Qwen2.5VL family and RoboBrain2.0 family, inspiring the models to identify shapes, count, and relate entities, and perform multi-step deductive reasoning using Euclidean principles. Our experiments demonstrate that the resulting models achieve substantial zero-shot gains across four spatial reasoning benchmarks (Super-CLEVR, Omni3DBench, VSI-Bench, and MindCube) without any task-specific adaptations. Notably, after training on the Euclid30K, the mean VSI-Bench accuracy of all evaluated models rose from 34.5% to 40.5%, improving by 5.5 percentage points. Among them, RoboBrain2.0-Euclid-7B achieves 49.6% accuracy, surpassing the previous state-of-the-art model, Spatial-MLLM.To our knowledge, this is the first systematic study showing that geometry-centric fine-tuning can confer vision-language models with broadly transferable spatial skills. Code and Euclid30K dataset can be found in <a target="_blank" rel="noopener" href="https://zgca-ai4edu.github.io/Euclids_Gift">https://zgca-ai4edu.github.io/Euclids_Gift</a>. </p>
<blockquote>
<p>ç©ºé—´æ™ºèƒ½æ¶µç›–äº†ä¸€ç³»åˆ—ä¸°å¯Œçš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¯è§†åŒ–å¹¶è½¬æ¢å½¢çŠ¶ã€åœ¨è„‘æµ·ä¸­æ—‹è½¬ç‰©ä½“ã€åˆ¤æ–­ç›¸å¯¹ä½ç½®å’ŒåŒ…å«å…³ç³»ï¼Œä»¥åŠä¼°è®¡æ•°é‡ã€‚ç„¶è€Œï¼Œå¯¹äºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ¥è¯´ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªå°šæœªè§£å†³çš„å…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æè®®å°†æ¬§å‡ é‡Œå¾—å‡ ä½•é—®é¢˜æ±‚è§£ä½œä¸ºæ›¿ä»£ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç²¾å¿ƒæ„å»ºäº†ä¸€ä¸ªåä¸ºEuclid30Kçš„å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å«å¤§çº¦30000ä¸ªå¹³é¢å’Œç«‹ä½“å‡ ä½•é—®é¢˜ã€‚ä¸ºäº†è®©æ¨¡å‹ä»è¿™äº›å‡ ä½•é—®é¢˜ä¸­å­¦ä¹ å¹¶åº”ç”¨æ¬§å‡ é‡Œå¾—åŸç†ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ¥å¯¹Qwen2.5VLå®¶æ—å’ŒRoboBrain2.0å®¶æ—è¿›è¡Œå¾®è°ƒï¼Œæ¿€åŠ±æ¨¡å‹è¯†åˆ«å½¢çŠ¶ã€è®¡æ•°å’Œå…³è”å®ä½“ï¼Œå¹¶ä½¿ç”¨æ¬§å‡ é‡Œå¾—åŸç†è¿›è¡Œå¤šæ­¥éª¤æ¨ç†ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œç”±æ­¤äº§ç”Ÿçš„æ¨¡å‹åœ¨å››ä¸ªç©ºé—´æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆSuper-CLEVRã€Omni3DBenchã€VSI-Benchå’ŒMindCubeï¼‰ä¸Šå®ç°äº†æ˜¾è‘—çš„é›¶æ ·æœ¬å¢ç›Šï¼Œè€Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„é€‚åº”ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç»è¿‡Euclid30Kè®­ç»ƒåï¼Œæ‰€æœ‰è¯„ä¼°æ¨¡å‹çš„VSI-Benchå¹³å‡å‡†ç¡®ç‡ä»34.5%æé«˜åˆ°40.5%ï¼Œæé«˜äº†5.5ä¸ªç™¾åˆ†ç‚¹ã€‚å…¶ä¸­ï¼ŒRoboBrain2.0-Euclid-7Bçš„å‡†ç¡®ç‡è¾¾åˆ°49.6%ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€ä½³æ¨¡å‹Spatial-MLLMã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€é¡¹ç³»ç»Ÿç ”ç©¶ï¼Œè¡¨æ˜ä»¥å‡ ä½•ä¸ºä¸­å¿ƒçš„å¾®è°ƒå¯ä»¥èµ‹äºˆè§†è§‰è¯­è¨€æ¨¡å‹å¹¿æ³›å¯è½¬ç§»çš„ç©ºé—´æŠ€èƒ½ã€‚ä»£ç å’ŒEuclid30Kæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://zgca-ai4edu.github.io/Euclids_Gift">https://zgca-ai4edu.github.io/Euclids_Gift</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24473v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç©ºé—´æ™ºèƒ½æ¶µç›–äº†ä¸€ç³»åˆ—èƒ½åŠ›ï¼ŒåŒ…æ‹¬è§†è§‰åŒ–å½¢çŠ¶ã€è½¬æ¢å½¢çŠ¶ã€å¿ƒç†æ—‹è½¬ç‰©ä½“ã€åˆ¤æ–­ä½ç½®å…³ç³»å’Œæ•°é‡å…³ç³»ï¼Œä»¥åŠä¼°ç®—æ•°é‡ç­‰ã€‚ç„¶è€Œï¼Œå¯¹äºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ¥è¯´ï¼Œç©ºé—´æ™ºèƒ½ä»ç„¶æ˜¯ä¸€ä¸ªå°šæœªè§£å†³çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå°†æ¬§å‡ é‡Œå¾—å‡ ä½•é—®é¢˜æ±‚è§£ä½œä¸ºæ›¿ä»£ä»»åŠ¡ã€‚æˆ‘ä»¬ç²¾å¿ƒæ„å»ºäº†ä¸€ä¸ªåä¸ºEuclid30Kçš„å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å«çº¦3ä¸‡é“å¹³é¢å’Œç«‹ä½“å‡ ä½•é—®é¢˜ã€‚é€šè¿‡é‡‡ç”¨ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¯¹Qwen2.5VLå®¶æ—å’ŒRoboBrain2.0å®¶æ—è¿›è¡Œå¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»è¿™äº›å‡ ä½•é—®é¢˜ä¸­å­¦ä¹ å¹¶åº”ç”¨æ¬§å‡ é‡Œå¾—åŸç†ã€‚å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹åœ¨å››é¡¹ç©ºé—´æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆSuper-CLEVRã€Omni3DBenchã€VSI-Benchå’ŒMindCubeï¼‰ä¸Šå®ç°äº†æ˜¾è‘—çš„é›¶æ ·æœ¬å¢ç›Šï¼Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡é€‚åº”ã€‚ç‰¹åˆ«åœ°ï¼Œåœ¨Euclid30Kè®­ç»ƒåï¼ŒVSI-Benchçš„å¹³å‡å‡†ç¡®ç‡ä»34.5%æé«˜åˆ°40.5%ï¼Œæé«˜äº†5.5ä¸ªç™¾åˆ†ç‚¹ã€‚å…¶ä¸­ï¼ŒRoboBrain2.0-Euclid-7Bè¾¾åˆ°49.6%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æœ€ä½³æ¨¡å‹Spatial-MLLMã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡æœ‰ç³»ç»Ÿçš„ç ”ç©¶è¡¨æ˜ï¼Œä»¥å‡ ä½•ä¸ºä¸­å¿ƒçš„å¾®è°ƒå¯ä»¥ä¸ºè§†è§‰è¯­è¨€æ¨¡å‹èµ‹äºˆå¹¿æ³›å¯è½¬ç§»çš„ç©ºé—´æŠ€èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç©ºé—´æ™ºèƒ½æ¶µç›–å¤šç§èƒ½åŠ›ï¼ŒåŒ…æ‹¬å½¢çŠ¶è§†è§‰åŒ–ã€è½¬æ¢ã€å¿ƒç†æ—‹è½¬ã€ä½ç½®å…³ç³»åˆ¤æ–­ã€æ•°é‡å…³ç³»åŠæ•°é‡ä¼°ç®—ç­‰ï¼Œæ˜¯å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„é‡è¦æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºå°†æ¬§å‡ é‡Œå¾—å‡ ä½•é—®é¢˜æ±‚è§£ä½œä¸ºæ›¿ä»£ä»»åŠ¡ï¼Œä»¥æ”¹å–„æ¨¡å‹çš„ç©ºé—´æ™ºèƒ½è¡¨ç°ã€‚</li>
<li>æ„å»ºäº†åä¸ºEuclid30Kçš„å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…å«çº¦3ä¸‡é“å‡ ä½•é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½ä»å‡ ä½•é—®é¢˜ä¸­å­¦ä¹ å’Œåº”ç”¨æ¬§å‡ é‡Œå¾—åŸç†ã€‚</li>
<li>æ¨¡å‹åœ¨å¤šé¡¹ç©ºé—´æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨VSI-Benchä¸Šçš„å‡†ç¡®ç‡æé«˜äº†5.5ä¸ªç™¾åˆ†ç‚¹ã€‚</li>
<li>RoboBrain2.0-Euclid-7Bæ¨¡å‹è¾¾åˆ°49.6%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šç°æœ‰æœ€ä½³æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24473">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-fbc70b2a7cb4588c7dbef0c496d12855~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028468&auth_key=1760028468-0-0-d1fc3f7ed67532695613eeecb0657c11&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-59d7f0b8ff047bdb7bbb7544f789cae6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028475&auth_key=1760028475-0-0-a811c0ff1af6dcd12cd71a35fd16a15e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ccf55f66205f66ee2f7ff37ac0d08994~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028482&auth_key=1760028482-0-0-f5db4a9cb7d39a8e1f718d8c425a59bd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-72332904b33f2e58979d3d48b68bf0af~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028489&auth_key=1760028489-0-0-87e9a1ca7a2fe8c07ef402fcf3dc2001&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6c34c1254702ff73b3826fa76e96ded8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028496&auth_key=1760028496-0-0-11339d46a54c103f2d0417192ede4241&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Advancing-Multi-agent-Traffic-Simulation-via-R1-Style-Reinforcement-Fine-Tuning"><a href="#Advancing-Multi-agent-Traffic-Simulation-via-R1-Style-Reinforcement-Fine-Tuning" class="headerlink" title="Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement   Fine-Tuning"></a>Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement   Fine-Tuning</h2><p><strong>Authors:Muleilan Pei, Shaoshuai Shi, Shaojie Shen</strong></p>
<p>Scalable and realistic simulation of multi-agent traffic behavior is critical for advancing autonomous driving technologies. Although existing data-driven simulators have made significant strides in this domain, they predominantly rely on supervised learning to align simulated distributions with real-world driving scenarios. A persistent challenge, however, lies in the distributional shift that arises between training and testing, which often undermines model generalization in unseen environments. To address this limitation, we propose SMART-R1, a novel R1-style reinforcement fine-tuning paradigm tailored for next-token prediction models to better align agent behavior with human preferences and evaluation metrics. Our approach introduces a metric-oriented policy optimization algorithm to improve distribution alignment and an iterative â€œSFT-RFT-SFTâ€ training strategy that alternates between Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) to maximize performance gains. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) validate the effectiveness of this simple yet powerful R1-style training framework in enhancing foundation models. The results on the Waymo Open Sim Agents Challenge (WOSAC) showcase that SMART-R1 achieves state-of-the-art performance with an overall realism meta score of 0.7858, ranking first on the leaderboard at the time of submission. </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“äº¤é€šè¡Œä¸ºçš„æ¨¡æ‹Ÿä¸­ï¼Œå®ç°å¯æ‰©å±•ä¸”çœŸå®çš„æ¨¡æ‹Ÿå¯¹äºæ¨åŠ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•è‡³å…³é‡è¦ã€‚å°½ç®¡ç°æœ‰çš„æ•°æ®é©±åŠ¨æ¨¡æ‹Ÿå™¨åœ¨è¯¥é¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†å®ƒä»¬ä¸»è¦ä¾èµ–äºç›‘ç£å­¦ä¹ æ¥ä½¿æ¨¡æ‹Ÿåˆ†å¸ƒä¸çœŸå®ä¸–ç•Œé©¾é©¶åœºæ™¯ç›¸ç¬¦ã€‚ç„¶è€Œï¼ŒæŒç»­çš„æŒ‘æˆ˜åœ¨äºè®­ç»ƒå’Œæµ‹è¯•ä¹‹é—´å‡ºç°çš„åˆ†å¸ƒåç§»ï¼Œè¿™å¸¸å¸¸ä¼šå½±å“æ¨¡å‹åœ¨æœªè§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SMART-R1ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ä¸‹ä¸€ä¸ªä»¤ç‰Œé¢„æµ‹æ¨¡å‹çš„æ–°å‹R1é£æ ¼å¼ºåŒ–å¾®è°ƒèŒƒå¼ï¼Œå¯ä»¥æ›´å¥½åœ°ä½¿æ™ºèƒ½ä½“è¡Œä¸ºä¸äººçš„åå¥½å’Œè¯„ä»·æŒ‡æ ‡ç›¸ç¬¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§é¢å‘æŒ‡æ ‡çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œä»¥æé«˜åˆ†å¸ƒå¯¹é½æ€§ï¼Œä»¥åŠä¸€ç§äº¤æ›¿è¿›è¡Œâ€œSFT-RFT-SFTâ€çš„è®­ç»ƒç­–ç•¥ï¼Œå³åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰ä¹‹é—´è¿›è¡Œäº¤æ›¿ï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜æ€§èƒ½æ”¶ç›Šã€‚åœ¨å¤§å‹Waymo Open Motion Datasetï¼ˆWOMDï¼‰ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒéªŒè¯äº†è¿™ç§ç®€å•è€Œå¼ºå¤§çš„R1é£æ ¼è®­ç»ƒæ¡†æ¶åœ¨æé«˜åŸºç¡€æ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚åœ¨Waymo Open Sim Agents Challengeï¼ˆWOSACï¼‰ä¸Šçš„ç»“æœæ˜¾ç¤ºï¼ŒSMART-R1è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ€»ä½“ç°å®æ„Ÿå¾—åˆ†ä¸º0.7858ï¼Œåœ¨æäº¤æ—¶ä½å±…æ’è¡Œæ¦œé¦–ä½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23993v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤šæ™ºèƒ½ä½“äº¤é€šè¡Œä¸ºçš„å¤§è§„æ¨¡ä»¿çœŸå¯¹äºæ¨åŠ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ•°æ®é©±åŠ¨æ¨¡æ‹Ÿå™¨å·²ç»åœ¨è¿™ä¸€é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬ä¸»è¦ä¾èµ–äºç›‘ç£å­¦ä¹ æ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œé©¾é©¶åœºæ™¯ä¸­çš„åˆ†å¸ƒã€‚ç„¶è€Œï¼Œè®­ç»ƒä¸æµ‹è¯•ä¹‹é—´å‡ºç°çš„åˆ†å¸ƒåç§»é—®é¢˜å¸¸å¸¸å¯¼è‡´æ¨¡å‹åœ¨æœªè§ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†SMART-R1ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹ä¸‹ä¸€ä»£ä»¤ç‰Œé¢„æµ‹æ¨¡å‹çš„R1é£æ ¼å¼ºåŒ–å¾®è°ƒèŒƒå¼ï¼Œèƒ½æ›´å¥½åœ°å°†æ™ºèƒ½ä½“è¡Œä¸ºä¸äººçš„åå¥½å’Œè¯„ä»·æŒ‡æ ‡å¯¹é½ã€‚é€šè¿‡å¼•å…¥é¢å‘æŒ‡æ ‡çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•æ¥æé«˜åˆ†å¸ƒå¯¹é½æ€§ï¼Œå¹¶é‡‡ç”¨äº¤æ›¿è¿›è¡Œçš„æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰çš„â€œSFT-RFT-SFTâ€è®­ç»ƒç­–ç•¥æ¥æœ€å¤§åŒ–æ€§èƒ½æå‡ã€‚åœ¨å¤§è§„æ¨¡Waymo Open Motion Datasetï¼ˆWOMDï¼‰ä¸Šçš„å®éªŒéªŒè¯äº†è¿™ä¸€ç®€å•è€Œå¼ºå¤§çš„R1é£æ ¼è®­ç»ƒæ¡†æ¶åœ¨æå‡åŸºç¡€æ¨¡å‹æ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚åœ¨Waymo Open Sim Agents Challengeï¼ˆWOSACï¼‰ä¸Šçš„ç»“æœå±•ç¤ºäº†SMART-R1è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œåœ¨æäº¤æ—¶æ’åç¬¬ä¸€ï¼Œæ•´ä½“ç°å®æ„Ÿå¾—åˆ†ä¸º0.7858ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“äº¤é€šè¡Œä¸ºä»¿çœŸå¯¹è‡ªåŠ¨é©¾é©¶æŠ€æœ¯å‘å±•è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ¨¡æ‹Ÿå™¨ä¸»è¦ä¾èµ–ç›‘ç£å­¦ä¹ æ¨¡æ‹ŸçœŸå®é©¾é©¶åœºæ™¯åˆ†å¸ƒï¼Œä½†å­˜åœ¨åˆ†å¸ƒåç§»é—®é¢˜ã€‚</li>
<li>SMART-R1é€šè¿‡å¼•å…¥é¢å‘æŒ‡æ ‡çš„å¼ºåŒ–å¾®è°ƒèŒƒå¼è§£å†³åˆ†å¸ƒåç§»é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>SMART-R1é‡‡ç”¨â€œSFT-RFT-SFTâ€è®­ç»ƒç­–ç•¥ï¼Œç»“åˆäº†ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å¾®è°ƒçš„ä¼˜åŠ¿ã€‚</li>
<li>åœ¨å¤§è§„æ¨¡æ•°æ®é›†WOMDä¸Šçš„å®éªŒéªŒè¯äº†SMART-R1çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åœ¨WOSACæŒ‘æˆ˜ä¸­ï¼ŒSMART-R1æ’åç¬¬ä¸€ï¼Œç°å®æ„Ÿå¾—åˆ†ä¸º0.7858ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23993">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b6dcd2583214b12ca733270e016e7c33~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028503&auth_key=1760028503-0-0-12b908e84ec8d7dc376a0bf855f1a0d3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0b79ce1a0ce2ca3172a1f7491da32a59~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028511&auth_key=1760028511-0-0-6d29ef0504227e597837097a5959103f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0fff4a60a665d961c5bef832a35a157c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028518&auth_key=1760028518-0-0-76889c9ac9115a72746a290bf0202149&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-011704996525f9dd45d5e7b2b890319f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028524&auth_key=1760028524-0-0-c7a3bc1d098ac18bb64e93802faece92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="The-Hidden-Costs-of-Translation-Accuracy-Distillation-Quantization-and-Environmental-Impact"><a href="#The-Hidden-Costs-of-Translation-Accuracy-Distillation-Quantization-and-Environmental-Impact" class="headerlink" title="The Hidden Costs of Translation Accuracy: Distillation, Quantization,   and Environmental Impact"></a>The Hidden Costs of Translation Accuracy: Distillation, Quantization,   and Environmental Impact</h2><p><strong>Authors:Dhaathri Vijay, Anandaswarup Vadapalli</strong></p>
<p>The rapid expansion of large language models (LLMs) has heightened concerns about their computational and environmental costs. This study investigates the trade-offs between translation quality and efficiency by comparing full-scale, distilled, and quantized models using machine translation as a case study. We evaluated performance on the Flores+ benchmark and through human judgments of conversational translations in French, Hindi, and Kannada. Our analysis revealed that the full 3.3B FP32 model, while achieving the highest BLEU scores, incurred the largest environmental footprint (~ 0.007-0.008 kg CO2 per run). The distilled 600M FP32 model reduced inference time by 71-78% and carbon emissions by 63-65% compared with the full model, with only minimal reductions in BLEU scores. Human evaluations further showed that even aggressive quantization (INT4) preserved high levels of accuracy and fluency, with differences between models generally minor. These findings demonstrate that model compression strategies can substantially reduce computational demands and environmental impact while maintaining competitive translation quality, though trade-offs are more pronounced in low-resource settings. We argue for evaluation frameworks that integrate efficiency and sustainability alongside accuracy as central dimensions of progress in NLP. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å¼•å‘äº†äººä»¬å¯¹å®ƒä»¬çš„è®¡ç®—å’Œç¯å¢ƒæˆæœ¬çš„å…³æ³¨ã€‚æœ¬ç ”ç©¶é€šè¿‡å¯¹æ¯”æœºå™¨ç¿»è¯‘ä¸­çš„å…¨å°ºå¯¸ã€è’¸é¦å’Œé‡åŒ–æ¨¡å‹ï¼Œæ¢è®¨ç¿»è¯‘è´¨é‡ä¸æ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚æˆ‘ä»¬åœ¨Flores+åŸºå‡†æµ‹è¯•ä»¥åŠæ³•è¯­ã€å°åœ°è¯­å’Œåçº³è¾¾è¯­çš„å¯¹è¯ç¿»è¯‘çš„äººç±»åˆ¤æ–­ä¸­è¯„ä¼°äº†æ€§èƒ½ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œè™½ç„¶å®Œæ•´çš„3.3B FP32æ¨¡å‹è·å¾—äº†æœ€é«˜çš„BLEUå¾—åˆ†ï¼Œä½†å®ƒä¹Ÿäº§ç”Ÿäº†æœ€å¤§çš„ç¯å¢ƒè¶³è¿¹ï¼ˆæ¯æ¬¡è¿è¡Œçº¦äº§ç”Ÿ0.007-0.008å…¬æ–¤çš„äºŒæ°§åŒ–ç¢³æ’æ”¾ï¼‰ã€‚ä¸å…¨æ¨¡å‹ç›¸æ¯”ï¼Œè’¸é¦çš„600M FP32æ¨¡å‹å°†æ¨ç†æ—¶é—´å‡å°‘äº†71-78%ï¼Œç¢³æ’æ”¾é‡å‡å°‘äº†63-65%ï¼Œè€ŒBLEUå¾—åˆ†åªæœ‰è½»å¾®ä¸‹é™ã€‚äººç±»è¯„ä¼°è¿›ä¸€æ­¥è¡¨æ˜ï¼Œå³ä½¿é‡‡ç”¨æ¿€çƒˆçš„é‡åŒ–ï¼ˆINT4ï¼‰ä¹Ÿèƒ½ä¿æŒé«˜æ°´å¹³çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ï¼Œå„æ¨¡å‹ä¹‹é—´çš„å·®å¼‚é€šå¸¸å¾ˆå°ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œæ¨¡å‹å‹ç¼©ç­–ç•¥å¯ä»¥åœ¨ä¿æŒç«äº‰åŠ›ç¿»è¯‘è´¨é‡çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½è®¡ç®—éœ€æ±‚å’Œç¯å¢ƒå½±å“ï¼Œä½†åœ¨ä½èµ„æºç¯å¢ƒä¸­ï¼Œæƒè¡¡æ›´ä¸ºçªå‡ºã€‚æˆ‘ä»¬ä¸»å¼ è¯„ä¼°æ¡†æ¶åº”æ•´åˆæ•ˆç‡ã€å¯æŒç»­æ€§ä¸å‡†ç¡®æ€§ï¼Œå°†å…¶ä½œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†è¿›å±•çš„æ ¸å¿ƒç»´åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23990v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å¼•å‘äº†å¯¹å…¶è®¡ç®—å’Œç¯ä¿æˆæœ¬çš„é«˜åº¦å…³æ³¨ã€‚æœ¬ç ”ç©¶é€šè¿‡å¯¹æ¯”å…¨è§„æ¨¡ã€è’¸é¦å’Œé‡åŒ–æ¨¡å‹ï¼Œæ¢è®¨æœºå™¨ç¿»è¯‘é¢†åŸŸç¿»è¯‘è´¨é‡ä¸æ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚åœ¨Flores+åŸºå‡†æµ‹è¯•ä»¥åŠæ³•è¯­ã€å°åœ°è¯­å’Œåçº³è¾¾è¯­çš„å¯¹è¯ç¿»è¯‘äººå·¥è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬å‘ç°3.3B FP32å…¨æ¨¡å‹è™½ç„¶è·å¾—æœ€é«˜BLEUåˆ†æ•°ï¼Œä½†å…¶ç¯å¢ƒè¶³è¿¹æœ€å¤§ï¼ˆçº¦0.007-0.008å…¬æ–¤CO2&#x2F;æ¬¡è¿è¡Œï¼‰ã€‚ç›¸æ¯”å…¨æ¨¡å‹ï¼Œè’¸é¦600M FP32æ¨¡å‹å°†æ¨ç†æ—¶é—´å‡å°‘71-78%ï¼Œç¢³æ’æ”¾å‡å°‘63-65%ï¼Œè€ŒBLEUåˆ†æ•°ä»…ç•¥æœ‰ä¸‹é™ã€‚äººç±»è¯„ä¼°è¿›ä¸€æ­¥è¡¨æ˜ï¼Œå³ä½¿é‡‡ç”¨æ¿€çƒˆçš„é‡åŒ–ï¼ˆINT4ï¼‰ä¹Ÿèƒ½ä¿æŒè¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ï¼Œå„æ¨¡å‹ä¹‹é—´çš„å·®å¼‚é€šå¸¸è¾ƒå°ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨¡å‹å‹ç¼©ç­–ç•¥å¯ä»¥åœ¨ä¿æŒç«äº‰æ€§çš„ç¿»è¯‘è´¨é‡çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½è®¡ç®—éœ€æ±‚å’Œç¯ä¿å½±å“ï¼Œä½†åœ¨ä½èµ„æºç¯å¢ƒä¸­æƒè¡¡æ›´ä¸ºçªå‡ºã€‚æˆ‘ä»¬ä¸»å¼ åœ¨NLPçš„è¯„ä¼°æ¡†æ¶ä¸­ï¼Œå°†æ•ˆç‡ã€å¯æŒç»­æ€§ä¸å‡†ç¡®æ€§ä¸€åŒä½œä¸ºæ ¸å¿ƒç»´åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å¸¦æ¥è®¡ç®—å’Œç¯ä¿æˆæœ¬çš„å…³æ³¨ã€‚</li>
<li>ç ”ç©¶å¯¹æ¯”äº†å…¨è§„æ¨¡ã€è’¸é¦å’Œé‡åŒ–æ¨¡å‹åœ¨æœºå™¨ç¿»è¯‘æ–¹é¢çš„è¡¨ç°ã€‚</li>
<li>3.3B FP32å…¨æ¨¡å‹è™½è·å¾—æœ€é«˜BLEUåˆ†æ•°ï¼Œä½†ç¯å¢ƒæˆæœ¬è¾ƒé«˜ã€‚</li>
<li>è’¸é¦æ¨¡å‹èƒ½åœ¨å‡å°‘æ¨ç†æ—¶é—´å’Œç¢³æ’æ”¾çš„åŒæ—¶ï¼Œä¿æŒè¾ƒé«˜çš„ç¿»è¯‘è´¨é‡ã€‚</li>
<li>é‡åŒ–æ¨¡å‹ï¼ˆINT4ï¼‰åœ¨ä¿æŒç¿»è¯‘å‡†ç¡®æ€§å’Œæµç•…æ€§æ–¹é¢è¡¨ç°è‰¯å¥½ã€‚</li>
<li>æ¨¡å‹å‹ç¼©ç­–ç•¥æœ‰åŠ©äºé™ä½è®¡ç®—éœ€æ±‚å’Œç¯ä¿å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23990">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d87e80d3c1d93a18b55b3c512311992d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028532&auth_key=1760028532-0-0-8ed0cd17c66ab7fdd2946a07fbb3eb05&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6703cf8898bf7e8597940808461b78c0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028539&auth_key=1760028539-0-0-dbcb14899932e938ff2206a7dc54c6ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ea3e8796c4a382b1ee2dc512920acc8a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028546&auth_key=1760028546-0-0-49902a8972e63a05314cdd520a065b2a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="From-Reasoning-to-Answer-Empirical-Attention-Based-and-Mechanistic-Insights-into-Distilled-DeepSeek-R1-Models"><a href="#From-Reasoning-to-Answer-Empirical-Attention-Based-and-Mechanistic-Insights-into-Distilled-DeepSeek-R1-Models" class="headerlink" title="From Reasoning to Answer: Empirical, Attention-Based and Mechanistic   Insights into Distilled DeepSeek R1 Models"></a>From Reasoning to Answer: Empirical, Attention-Based and Mechanistic   Insights into Distilled DeepSeek R1 Models</h2><p><strong>Authors:Jue Zhang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang</strong></p>
<p>Large Reasoning Models (LRMs) generate explicit reasoning traces alongside final answers, yet the extent to which these traces influence answer generation remains unclear. In this work, we conduct a three-stage investigation into the interplay between reasoning and answer generation in three distilled DeepSeek R1 models. First, through empirical evaluation, we demonstrate that including explicit reasoning consistently improves answer quality across diverse domains. Second, attention analysis reveals that answer tokens attend substantially to reasoning tokens, with certain mid-layer Reasoning-Focus Heads (RFHs) closely tracking the reasoning trajectory, including self-reflective cues. Third, we apply mechanistic interventions using activation patching to assess the dependence of answer tokens on reasoning activations. Our results show that perturbations to key reasoning tokens can reliably alter the final answers, confirming a directional and functional flow of information from reasoning to answer. These findings deepen our understanding of how LRMs leverage reasoning tokens for answer generation, highlighting the functional role of intermediate reasoning in shaping model outputs. Our data and code are publicly available at \href{<a target="_blank" rel="noopener" href="https://aka.ms/R2A-code%7D%7Bthis">https://aka.ms/R2A-code}{this</a> URL}. </p>
<blockquote>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨æœ€ç»ˆç­”æ¡ˆæ—è¾¹ç”Ÿæˆæ˜ç¡®çš„æ¨ç†ç—•è¿¹ï¼Œä½†è¿™äº›ç—•è¿¹å¯¹ç­”æ¡ˆç”Ÿæˆçš„å½±å“ç¨‹åº¦å°šä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸‰ç§è’¸é¦çš„DeepSeek R1æ¨¡å‹ä¸­æ¨ç†ä¸ç­”æ¡ˆç”Ÿæˆä¹‹é—´çš„ç›¸äº’ä½œç”¨è¿›è¡Œäº†ä¸‰é˜¶æ®µçš„ç ”ç©¶ã€‚é¦–å…ˆï¼Œé€šè¿‡å®è¯ç ”ç©¶ï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨å¤šä¸ªé¢†åŸŸä¸­åŒ…å«æ˜ç¡®çš„æ¨ç†å¯ä»¥æŒç»­æé«˜ç­”æ¡ˆçš„è´¨é‡ã€‚å…¶æ¬¡ï¼Œæ³¨æ„åŠ›åˆ†æè¡¨æ˜ç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ ‡è®°çš„å…³æ³¨åº¦å¾ˆé«˜ï¼ŒæŸäº›ä¸­å±‚æ¨ç†ç„¦ç‚¹å¤´ï¼ˆRFHï¼‰ç´§å¯†è·Ÿè¸ªæ¨ç†è½¨è¿¹ï¼ŒåŒ…æ‹¬è‡ªæˆ‘åæ€çº¿ç´¢ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨æ¿€æ´»è¡¥ä¸è¿›è¡Œæœºæ¢°å¹²é¢„æ¥è¯„ä¼°ç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ¿€æ´»çš„ä¾èµ–ç¨‹åº¦ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¯¹å…³é”®æ¨ç†æ ‡è®°çš„å¹²æ‰°å¯ä»¥å¯é åœ°æ”¹å˜æœ€ç»ˆç­”æ¡ˆï¼Œè¯å®äº†ä»æ¨ç†åˆ°ç­”æ¡ˆçš„ä¿¡æ¯çš„å®šå‘å’ŒåŠŸèƒ½æµåŠ¨ã€‚è¿™äº›å‘ç°æ·±åŒ–äº†æˆ‘ä»¬å¯¹LRMå¦‚ä½•åˆ©ç”¨æ¨ç†æ ‡è®°ç”Ÿæˆç­”æ¡ˆçš„ç†è§£ï¼Œçªå‡ºäº†ä¸­é—´æ¨ç†åœ¨å¡‘é€ æ¨¡å‹è¾“å‡ºä¸­çš„åŠŸèƒ½ä½œç”¨ã€‚æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç å¯ä»¥åœ¨è¿™ä¸ªURLä¸­æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://aka.ms/R2A-code">https://aka.ms/R2A-code</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23676v1">PDF</a> Accepted by EMNLPâ€™25 (Main)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ä¸­çš„æ¨ç†ä¸ç­”æ¡ˆç”Ÿæˆä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æ–‡ç« è¿›è¡Œäº†ä¸‰é˜¶æ®µçš„æ¢ç©¶ï¼Œé¦–å…ˆé€šè¿‡å®è¯ç ”ç©¶è¯æ˜äº†æ˜¾å¼æ¨ç†çš„åŠ å…¥èƒ½æŒç»­æé«˜è·¨ä¸åŒé¢†åŸŸçš„ç­”æ¡ˆè´¨é‡ã€‚å…¶æ¬¡ï¼Œæ³¨æ„åŠ›åˆ†ææ˜¾ç¤ºç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ ‡è®°çš„å…³æ³¨åº¦å¾ˆé«˜ï¼ŒæŸäº›ä¸­å±‚æ¨ç†ç„¦ç‚¹å¤´ï¼ˆRFHï¼‰ç´§å¯†è¿½è¸ªæ¨ç†è½¨è¿¹ï¼ŒåŒ…æ‹¬è‡ªæˆ‘åæ€çº¿ç´¢ã€‚æœ€åï¼Œé€šè¿‡æ¿€æ´»è¡¥ä¸è¿›è¡Œæœºåˆ¶å¹²é¢„ï¼Œè¯„ä¼°ç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ¿€æ´»çš„ä¾èµ–æ€§ã€‚ç»“æœæ˜¾ç¤ºå¯¹å…³é”®æ¨ç†æ ‡è®°çš„å¹²æ‰°èƒ½å¯é åœ°æ”¹å˜æœ€ç»ˆç­”æ¡ˆï¼Œè¯å®äº†ä»æ¨ç†åˆ°ç­”æ¡ˆçš„ä¿¡æ¯æµåŠ¨å…·æœ‰æ–¹å‘æ€§å’ŒåŠŸèƒ½æ€§ã€‚æœ¬æ–‡åŠ æ·±äº†æˆ‘ä»¬å¯¹äºLRMå¦‚ä½•åˆ©ç”¨æ¨ç†æ ‡è®°è¿›è¡Œç­”æ¡ˆç”Ÿæˆçš„ç†è§£ï¼Œçªå‡ºäº†ä¸­é—´æ¨ç†åœ¨å¡‘é€ æ¨¡å‹è¾“å‡ºä¸­çš„åŠŸèƒ½ä½œç”¨ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ˜¾å¼æ¨ç†çš„åŠ å…¥èƒ½æé«˜è·¨ä¸åŒé¢†åŸŸçš„ç­”æ¡ˆè´¨é‡ã€‚</li>
<li>æ³¨æ„åŠ›åˆ†ææ˜¾ç¤ºç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ ‡è®°çš„ä¾èµ–æ€§å¼ºã€‚</li>
<li>ä¸­å±‚æ¨ç†ç„¦ç‚¹å¤´ï¼ˆRFHï¼‰ç´§å¯†è¿½è¸ªæ¨ç†è½¨è¿¹ã€‚</li>
<li>é€šè¿‡æœºåˆ¶å¹²é¢„ç¡®è®¤ï¼Œå¯¹å…³é”®æ¨ç†æ ‡è®°çš„å¹²æ‰°èƒ½æ”¹å˜æœ€ç»ˆç­”æ¡ˆã€‚</li>
<li>ä»æ¨ç†åˆ°ç­”æ¡ˆçš„ä¿¡æ¯æµåŠ¨å…·æœ‰æ–¹å‘æ€§å’ŒåŠŸèƒ½æ€§ã€‚</li>
<li>ä¸­é—´æ¨ç†åœ¨æ¨¡å‹è¾“å‡ºä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>ç ”ç©¶æ•°æ®å’Œä»£ç å·²å…¬å¼€å¯ä¾›è®¿é—®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23676">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c0610fa5ffdb2c744c99208f954dbc50~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028553&auth_key=1760028553-0-0-85162fd0823eddb183806a92dbe0629d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-34799876f9c39c1e332fc30845afa8b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028560&auth_key=1760028560-0-0-bf0075510a498a4a7dd11c1cf0b7a5c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49c72afa896ede10a4575fe92d4fc3cc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028566&auth_key=1760028566-0-0-99cca0c15665cd7ed7ff3cdc364504fe&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49d925ddb29177260f873823babcdd0d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028573&auth_key=1760028573-0-0-af63d86a16efa171e48259d7537e7678&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-459fe61bd2c12b7fe233d4e0cb6732a2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028580&auth_key=1760028580-0-0-bb06c292ec920e2728fb0e0ed493cd65&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9116b7bb293b9ad6b4230f045c6156dd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028587&auth_key=1760028587-0-0-4de36155e8384e750ff29461dfd851f6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="p-less-Sampling-A-Robust-Hyperparameter-Free-Approach-for-LLM-Decoding"><a href="#p-less-Sampling-A-Robust-Hyperparameter-Free-Approach-for-LLM-Decoding" class="headerlink" title="$p$-less Sampling: A Robust Hyperparameter-Free Approach for LLM   Decoding"></a>$p$-less Sampling: A Robust Hyperparameter-Free Approach for LLM   Decoding</h2><p><strong>Authors:Runyan Tan, Shuang Wu, Phillip Howard</strong></p>
<p>Obtaining high-quality outputs from Large Language Models (LLMs) often depends upon the choice of a sampling-based decoding strategy to probabilistically choose the next token at each generation step. While a variety of such sampling methods have been proposed, their performance can be sensitive to the selection of hyperparameters which may require different settings depending upon the generation task and temperature configuration. In this work, we introduce $p$-less sampling: an information-theoretic approach to sampling which dynamically sets a truncation threshold at each decoding step based on the entire token probability distribution. Unlike existing methods, $p$-less sampling has no hyperparameters and consistently produces high-quality outputs as temperature increases. We provide theoretical perspectives on $p$-less sampling to ground our proposed method and conduct experiments to empirically validate its effectiveness across a range of math, logical reasoning, and creative writing tasks. Our results demonstrate how $p$-less sampling consistently outperforms existing sampling approaches while exhibiting much less degradation in text quality at higher temperature values. We further show how $p$-less achieves greater inference-time efficiency than alternative methods through lower average token sampling times and shorter generation lengths, without sacrificing accuracy. Finally, we provide analyses to highlight the benefits of $p$-less through qualitative examples, case studies, and diversity assessments. </p>
<blockquote>
<p>ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è·å¾—é«˜è´¨é‡è¾“å‡ºé€šå¸¸å–å†³äºåŸºäºé‡‡æ ·çš„è§£ç ç­–ç•¥çš„é€‰æ‹©ï¼Œè¯¥ç­–ç•¥ä»¥æ¦‚ç‡æ–¹å¼é€‰æ‹©æ¯ä¸ªç”Ÿæˆæ­¥éª¤ä¸­çš„ä¸‹ä¸€ä¸ªä»¤ç‰Œã€‚è™½ç„¶å·²ç»æå‡ºäº†å¤šç§è¿™æ ·çš„é‡‡æ ·æ–¹æ³•ï¼Œä½†å®ƒä»¬çš„æ€§èƒ½å¯¹è¶…å‚æ•°çš„é€‰æ‹©å¾ˆæ•æ„Ÿï¼Œè¿™å¯èƒ½éœ€è¦æ ¹æ®ä¸åŒçš„ç”Ÿæˆä»»åŠ¡å’Œæ¸©åº¦é…ç½®è¿›è¡Œè®¾ç½®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ— pé‡‡æ ·ï¼šä¸€ç§åŸºäºä¿¡æ¯ç†è®ºçš„é‡‡æ ·æ–¹æ³•ï¼Œå®ƒä¼šåœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­æ ¹æ®æ•´ä¸ªä»¤ç‰Œæ¦‚ç‡åˆ†å¸ƒåŠ¨æ€è®¾ç½®æˆªæ–­é˜ˆå€¼ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæ— pé‡‡æ ·æ²¡æœ‰ä»»ä½•è¶…å‚æ•°ï¼Œéšç€æ¸©åº¦çš„å‡é«˜ï¼Œå®ƒå§‹ç»ˆèƒ½äº§ç”Ÿé«˜è´¨é‡çš„è¾“å‡ºã€‚æˆ‘ä»¬ä»ç†è®ºä¸Šé˜è¿°äº†æ— pé‡‡æ ·çš„æ–¹æ³•ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨æ•°å­¦ã€é€»è¾‘æ¨ç†å’Œåˆ›é€ æ€§å†™ä½œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ— pé‡‡æ ·å¦‚ä½•å§‹ç»ˆä¼˜äºç°æœ‰çš„é‡‡æ ·æ–¹æ³•ï¼ŒåŒæ—¶åœ¨è¾ƒé«˜çš„æ¸©åº¦å€¼ä¸‹æ–‡æœ¬è´¨é‡ä¸‹é™è¾ƒå°‘ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†æ— på¦‚ä½•é€šè¿‡é™ä½å¹³å‡ä»¤ç‰Œé‡‡æ ·æ—¶é—´å’Œç¼©çŸ­ç”Ÿæˆé•¿åº¦æ¥å®ç°æ›´é«˜çš„æ¨ç†æ•ˆç‡ï¼ŒåŒæ—¶ä¸ç‰ºç‰²å‡†ç¡®æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å®šæ€§ç¤ºä¾‹ã€æ¡ˆä¾‹ç ”ç©¶å’Œå¤šæ ·æ€§è¯„ä¼°æ¥åˆ†ææ— pçš„ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23234v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ— å‚æ•°é‡‡æ ·ï¼ˆp-less samplingï¼‰è¿™ä¸€æ–°çš„åŸºäºä¿¡æ¯ç†è®ºçš„é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§£ç ç­–ç•¥ã€‚è¯¥æ–¹æ³•æ ¹æ®æ•´ä¸ªtokenæ¦‚ç‡åˆ†å¸ƒåŠ¨æ€è®¾å®šæˆªæ–­é˜ˆå€¼ï¼Œæ— éœ€è°ƒæ•´è¶…å‚æ•°ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒæ¸©åº¦ä¸‹ç¨³å®šäº§ç”Ÿé«˜è´¨é‡è¾“å‡ºã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯ï¼Œè¡¨æ˜p-lessé‡‡æ ·åœ¨æ•°å­¦ã€é€»è¾‘æ¨ç†å’Œåˆ›é€ æ€§å†™ä½œä»»åŠ¡ä¸Šä¼˜äºç°æœ‰é‡‡æ ·æ–¹æ³•ï¼Œå¹¶åœ¨è¾ƒé«˜æ¸©åº¦ä¸‹ä»èƒ½ä¿æŒè¾ƒå¥½çš„æ–‡æœ¬è´¨é‡ã€‚æ­¤å¤–ï¼Œp-lessé‡‡æ ·è¿˜å…·æœ‰æ›´é«˜çš„æ¨ç†æ•ˆç‡ï¼Œå¹³å‡tokené‡‡æ ·æ—¶é—´çŸ­ï¼Œç”Ÿæˆé•¿åº¦çŸ­ï¼Œä¸”ä¸ç‰ºç‰²å‡†ç¡®æ€§ã€‚æœ€åé€šè¿‡å®šæ€§ä¾‹å­ã€æ¡ˆä¾‹ç ”ç©¶å’Œå¤šæ ·æ€§è¯„ä¼°åˆ†æè¯æ˜äº†p-lessé‡‡æ ·çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>p-lessé‡‡æ ·æ˜¯ä¸€ç§åŸºäºä¿¡æ¯ç†è®ºçš„é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è§£ç ç­–ç•¥ã€‚</li>
<li>p-lessé‡‡æ ·èƒ½å¤Ÿæ ¹æ®æ•´ä¸ªtokenæ¦‚ç‡åˆ†å¸ƒåŠ¨æ€è®¾å®šæˆªæ–­é˜ˆå€¼ã€‚</li>
<li>p-lessé‡‡æ ·æ— éœ€è°ƒæ•´è¶…å‚æ•°ï¼Œå¯é€‚åº”ä¸åŒçš„ç”Ÿæˆä»»åŠ¡å’Œæ¸©åº¦é…ç½®ã€‚</li>
<li>p-lessé‡‡æ ·åœ¨ä¸åŒæ¸©åº¦ä¸‹éƒ½èƒ½äº§ç”Ÿé«˜è´¨é‡è¾“å‡ºã€‚</li>
<li>å®éªŒéªŒè¯è¡¨æ˜p-lessé‡‡æ ·åœ¨å¤šç§ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰é‡‡æ ·æ–¹æ³•ã€‚</li>
<li>p-lessé‡‡æ ·å…·æœ‰æ›´é«˜çš„æ¨ç†æ•ˆç‡ï¼Œå¹³å‡tokené‡‡æ ·æ—¶é—´çŸ­ï¼Œç”Ÿæˆé•¿åº¦çŸ­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23234">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7b388d710660fddea31dd7c2c844cff8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028595&auth_key=1760028595-0-0-8a3440d43e1cc4622e652567556e996b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-eb1166edcfe1f484574aeff3852399a6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028602&auth_key=1760028602-0-0-4739494ca858d70b8ca6d8c0be0a20a2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5d7df353ea675a241831b2c36cde26fb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028609&auth_key=1760028609-0-0-960a43a11a243fcfd5a0b65eee1f0caa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8b5aab67e9914294d066e179b7c18ca1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028615&auth_key=1760028615-0-0-6eedb6a11b9f0b4bc6c57f61ee8fd0d2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Critique-to-Verify-Accurate-and-Honest-Test-Time-Scaling-with-RL-Trained-Verifiers"><a href="#Critique-to-Verify-Accurate-and-Honest-Test-Time-Scaling-with-RL-Trained-Verifiers" class="headerlink" title="Critique to Verify: Accurate and Honest Test-Time Scaling with   RL-Trained Verifiers"></a>Critique to Verify: Accurate and Honest Test-Time Scaling with   RL-Trained Verifiers</h2><p><strong>Authors:Zhicheng Yang, Zhijiang Guo, Yinya Huang, Yongxin Wang, Yiwei Wang, Xiaodan Liang, Jing Tang</strong></p>
<p>Test-time scaling via solution sampling and aggregation has become a key paradigm for improving the reasoning performance of Large Language Models (LLMs). While reward model selection is commonly employed in this approach, it often fails to identify minority-yet-correct answers, which limits its effectiveness beyond that of simple majority voting. We argue that this limitation stems from a lack of informative critique signals during verifier training. To bridge this gap, we introduce Mirror-Critique, a framework that trains a verifier with informative critiques. Our key insight is to leverage the rich critique signal by contrasting model-generated solutions with ground-truth solutions. We deploy a small instruction-tuned model to synthesize high-quality critique data with rejection sampling that teaches the verifier not only what is wrong, but also why. The synthetic data is used to cold-start the LLMs in the RLVR process to further improve the verification ability. The resulting Mirror-Verifier is deployed to evaluate candidate solutions by generating multiple critiques per solution, aggregating them into a verify score used for weighted voting or selective abstention. The experimental results show that our Mirror-Verifier significantly outperforms majority voting in terms of solution accuracy and also improves the solverâ€™s honesty to recognize and abstain from answering beyond its capability boundaries. </p>
<blockquote>
<p>é€šè¿‡è§£å†³æ–¹æ¡ˆé‡‡æ ·å’Œèšåˆè¿›è¡Œæµ‹è¯•æ—¶ç¼©æ”¾ï¼Œå·²æˆä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ€§èƒ½çš„å…³é”®èŒƒå¼ã€‚è™½ç„¶å¥–åŠ±æ¨¡å‹é€‰æ‹©åœ¨æ­¤æ–¹æ³•ä¸­å¸¸ç”¨ï¼Œä½†å®ƒå¾€å¾€æ— æ³•è¯†åˆ«å‡ºå°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆï¼Œè¿™é™åˆ¶äº†å…¶æ•ˆæœï¼Œä»…è¶…è¶Šç®€å•å¤šæ•°æŠ•ç¥¨ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™ä¸€å±€é™æ€§æºäºéªŒè¯å™¨è®­ç»ƒæœŸé—´ç¼ºä¹ä¿¡æ¯æ€§æ‰¹åˆ¤ä¿¡å·ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†Mirror-Critiqueæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨ä¿¡æ¯æ€§æ‰¹åˆ¤æ¥è®­ç»ƒéªŒè¯å™¨ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€šè¿‡å¯¹æ¯”æ¨¡å‹ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆä¸çœŸå®è§£å†³æ–¹æ¡ˆæ¥åˆ©ç”¨ä¸°å¯Œçš„æ‰¹åˆ¤ä¿¡å·ã€‚æˆ‘ä»¬éƒ¨ç½²äº†ä¸€ä¸ªå°å‹æŒ‡ä»¤è°ƒæ•´æ¨¡å‹ï¼Œé€šè¿‡æ‹’ç»é‡‡æ ·åˆæˆé«˜è´¨é‡çš„æ‰¹åˆ¤æ•°æ®ï¼Œä¸ä»…æ•™ä¼šéªŒè¯å™¨ä»€ä¹ˆæ˜¯é”™è¯¯çš„ï¼Œè¿˜æ•™ä¼šå®ƒä¸ºä»€ä¹ˆé”™è¯¯ã€‚åˆæˆæ•°æ®ç”¨äºåœ¨RLVRè¿‡ç¨‹ä¸­å†·å¯åŠ¨LLMï¼Œä»¥è¿›ä¸€æ­¥æé«˜éªŒè¯èƒ½åŠ›ã€‚æ‰€å¾—çš„Mirror-Verifierç”¨äºè¯„ä¼°å€™é€‰è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ä¸ºæ¯ä¸ªè§£å†³æ–¹æ¡ˆç”Ÿæˆå¤šä¸ªæ‰¹åˆ¤å¹¶å°†å…¶èšåˆä¸ºéªŒè¯åˆ†æ•°ï¼Œç”¨äºåŠ æƒæŠ•ç¥¨æˆ–é€‰æ‹©æ€§å¼ƒæƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„Mirror-Verifieråœ¨è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºå¤šæ•°æŠ•ç¥¨ï¼Œå¹¶æé«˜äº†æ±‚è§£è€…çš„è¯šä¿¡åº¦ï¼Œä½¿å…¶èƒ½å¤Ÿè¯†åˆ«å’Œé¿å…è¶…å‡ºå…¶èƒ½åŠ›è¾¹ç•Œçš„ç­”æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23152v1">PDF</a> 15 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>è®­ç»ƒéªŒè¯å™¨ä»¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½çš„è¿‡ç¨‹ä¸­å­˜åœ¨ä¸è¶³ä¹‹å¤„ï¼Œä¸»è¦åœ¨äºç¼ºå°‘å¯¹æ¨¡å‹çš„æ‰¹è¯„æ€§ä¿¡å·åé¦ˆã€‚å› æ­¤æå‡ºMirror-Critiqueæ¡†æ¶ï¼Œé€šè¿‡å¯¹æ¯”æ¨¡å‹ç”Ÿæˆç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆæ¥è®­ç»ƒéªŒè¯å™¨ï¼Œä½¿å…¶å…·å¤‡å¯¹ç­”æ¡ˆçš„æ‰¹è¯„æ€§åé¦ˆèƒ½åŠ›ã€‚é€šè¿‡é‡‡ç”¨æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ‰¹è¯„æ•°æ®å¹¶é‡‡ç”¨æ‹’ç»é‡‡æ ·æ–¹æ³•ï¼Œè®©éªŒè¯å™¨ä¸ä»…äº†è§£ç­”æ¡ˆé”™è¯¯ä¹‹å¤„ï¼Œè¿˜èƒ½ç†è§£é”™è¯¯åŸå› ã€‚è¯¥æ¡†æ¶èƒ½æ˜¾è‘—æé«˜éªŒè¯å™¨æ€§èƒ½ï¼Œåœ¨è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§æ–¹é¢ä¼˜äºå¤šæ•°æŠ•ç¥¨åˆ¶ï¼Œå¹¶æå‡æ¨¡å‹åœ¨è¶…å‡ºèƒ½åŠ›è¾¹ç•Œæ—¶æ‹’ç»å›ç­”çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§£å†³æ–¹æ¡ˆé‡‡æ ·ä¸èšåˆæ˜¯æ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½çš„å…³é”®èŒƒå¼ã€‚</li>
<li>ç›®å‰å­˜åœ¨çš„é—®é¢˜æ˜¯å¥–åŠ±æ¨¡å‹é€‰æ‹©æ— æ³•è¯†åˆ«å°‘æ•°æ­£ç¡®ä½†éä¸»æµçš„ç­”æ¡ˆã€‚</li>
<li>è¿™ç§å±€é™æ€§æºäºéªŒè¯å™¨è®­ç»ƒæœŸé—´ç¼ºä¹ä¿¡æ¯æ€§æ‰¹è¯„ä¿¡å·ã€‚</li>
<li>Mirror-Critiqueæ¡†æ¶æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡å¯¹æ¯”æ¨¡å‹ç”Ÿæˆç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆæ¥è®­ç»ƒéªŒè¯å™¨ï¼Œä½¿å…¶å…·å¤‡æ‰¹è¯„æ€§åé¦ˆèƒ½åŠ›ã€‚</li>
<li>é‡‡ç”¨æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ‰¹è¯„æ•°æ®å¹¶é‡‡ç”¨æ‹’ç»é‡‡æ ·æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨åˆæˆçš„æ‰¹è¯„æ•°æ®æ¥å¯åŠ¨éªŒè¯å™¨åœ¨å†·å¯åŠ¨è¿‡ç¨‹ä¸­è¿›ä¸€æ­¥æé«˜éªŒè¯èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23152">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0d6dda79364da6db33722e701263256a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028623&auth_key=1760028623-0-0-abde526e7ed9a80717359cf005dd0224&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ed5382522c38be3f41253ff07fbbeb0f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028630&auth_key=1760028630-0-0-b085512e0ac3b30aacaaac27dab55e3a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b86e20e9087f0d5171cc4763952f5ca4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028637&auth_key=1760028637-0-0-4fca72bab9bca0b2c8c3aa2014ab7aa0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Multiplayer-Nash-Preference-Optimization"><a href="#Multiplayer-Nash-Preference-Optimization" class="headerlink" title="Multiplayer Nash Preference Optimization"></a>Multiplayer Nash Preference Optimization</h2><p><strong>Authors:Fang Wu, Xu Huang, Weihao Xuan, Zhiwei Zhang, Yijia Xiao, Guancheng Wan, Xiaomin Li, Bing Hu, Peng Xia, Jure Leskovec, Yejin Choi</strong></p>
<p>Reinforcement learning from human feedback (RLHF) has emerged as the standard paradigm for aligning large language models (LLMs) with human preferences. However, reward-based methods built on the Bradley-Terry assumption struggle to capture the non-transitive and heterogeneous nature of real-world preferences. To address this, recent studies have reframed alignment as a two-player Nash game, giving rise to Nash learning from human feedback (NLHF). While this perspective has inspired algorithms such as INPO, ONPO, and EGPO with strong theoretical and empirical guarantees, they remain fundamentally restricted to two-player interactions, creating a single-opponent bias that fails to capture the full complexity of realistic preference structures. In this work, we introduce Multiplayer Nash Preference Optimization (MNPO), a novel framework that generalizes NLHF to the multiplayer regime. It formulates alignment as an $n$-player game, where each policy competes against a population of opponents while being regularized toward a reference model. Our framework establishes well-defined Nash equilibria in multiplayer settings and extends the concept of duality gap to quantify approximation quality. We demonstrate that MNPO inherits the equilibrium guarantees of two-player methods while enabling richer competitive dynamics and improved coverage of diverse preference structures. Through comprehensive empirical evaluation, we show that MNPO consistently outperforms existing NLHF baselines on instruction-following benchmarks, achieving superior alignment quality under heterogeneous annotator conditions and mixed-policy evaluation scenarios. Together, these results establish MNPO as a principled and scalable framework for aligning LLMs with complex, non-transitive human preferences. Code is available at <a target="_blank" rel="noopener" href="https://github.com/smiles724/MNPO">https://github.com/smiles724/MNPO</a>. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰å·²ç»ä½œä¸ºå¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸äººç±»åå¥½çš„æ ‡å‡†èŒƒå¼ã€‚ç„¶è€Œï¼ŒåŸºäºBradley-Terryå‡è®¾çš„å¥–åŠ±æ–¹æ³•å¾ˆéš¾æ•æ‰ç°å®ä¸–ç•Œä¸­åå¥½çš„éä¼ é€’æ€§å’Œå¼‚è´¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ€è¿‘çš„ç ”ç©¶å°†å¯¹é½é‡æ–°æ„å»ºä¸ºä¸€ä¸ªä¸¤äººçº³ä»€æ¸¸æˆï¼Œä»è€Œäº§ç”Ÿäº†åŸºäºäººç±»åé¦ˆçš„çº³ä»€å­¦ä¹ ï¼ˆNLHFï¼‰ã€‚è™½ç„¶è¿™ä¸€è§†è§’æ¿€å‘äº†å¦‚INPOã€ONPOå’ŒEGPOç­‰ç®—æ³•ï¼Œå…·æœ‰å¼ºå¤§çš„ç†è®ºå’Œå®è¯ä¿è¯ï¼Œä½†å®ƒä»¬ä»æ ¹æœ¬ä¸Šå±€é™äºä¸¤äººäº’åŠ¨ï¼Œäº§ç”Ÿäº†å•ä¸€çš„å¯¹æ‰‹åè§ï¼Œæ— æ³•æ•æ‰ç°å®åå¥½ç»“æ„çš„å…¨éƒ¨å¤æ‚æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šäººçº³ä»€åå¥½ä¼˜åŒ–ï¼ˆMNPOï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†NLHFæ¨å¹¿åˆ°å¤šäººæ¨¡å¼çš„æ–°å‹æ¡†æ¶ã€‚å®ƒå°†å¯¹é½åˆ¶å®šä¸ºä¸€ä¸ªnäººæ¸¸æˆï¼Œå…¶ä¸­æ¯ä¸ªç­–ç•¥éƒ½ä¸ä¸€ç¾¤å¯¹æ‰‹ç«äº‰ï¼ŒåŒæ—¶å‘å‚è€ƒæ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨å¤šäººè®¾ç½®ä¸­å»ºç«‹äº†æ˜ç¡®çš„çº³ä»€å‡è¡¡ï¼Œå¹¶å°†å¯¹å¶é—´éš™çš„æ¦‚å¿µæ‰©å±•åˆ°é‡åŒ–è¿‘ä¼¼è´¨é‡ã€‚æˆ‘ä»¬è¯æ˜äº†MNPOç»§æ‰¿äº†ä¸¤äººæ–¹æ³•çš„å‡è¡¡ä¿è¯ï¼ŒåŒæ—¶å®ç°äº†æ›´ä¸°å¯Œçš„ç«äº‰åŠ¨æ€å’Œæ”¹è¿›äº†å¯¹å¤šæ ·åŒ–åå¥½ç»“æ„çš„è¦†ç›–ã€‚é€šè¿‡å…¨é¢çš„ç»éªŒè¯„ä¼°ï¼Œæˆ‘ä»¬è¡¨æ˜MNPOåœ¨æŒ‡ä»¤éµå¾ªåŸºå‡†æµ‹è¯•ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰çš„NLHFåŸºçº¿ï¼Œåœ¨å¼‚è´¨æ³¨é‡Šè€…æ¡ä»¶å’Œæ··åˆç­–ç•¥è¯„ä¼°åœºæ™¯ä¸­å®ç°äº†ä¼˜è´¨çš„å¯¹é½ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœç¡®ç«‹äº†MNPOä½œä¸ºä¸€ä¸ªæœ‰åŸåˆ™ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¯¹é½å…·æœ‰å¤æ‚éä¼ é€’æ€§äººç±»åå¥½çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/smiles724/MNPO%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/smiles724/MNPOä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23102v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¤§è¯­è¨€æ¨¡å‹ä¸äººç±»åå¥½çš„å¯¹é½é€šå¸¸é‡‡ç”¨çš„æ˜¯åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æ ‡å‡†èŒƒå¼ã€‚ç„¶è€Œï¼ŒåŸºäºBradley-Terryå‡è®¾çš„å¥–åŠ±æ–¹æ³•å¾ˆéš¾æ•æ‰ç°å®ä¸–ç•Œä¸­éä¼ é€’æ€§å’Œå¼‚è´¨æ€§çš„åå¥½ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿‘æœŸç ”ç©¶å°†å¯¹é½é—®é¢˜é‡æ–°æ„å»ºä¸ºä¸¤äººNashåšå¼ˆï¼Œäº§ç”Ÿäº†åŸºäºäººç±»åé¦ˆçš„Nashå­¦ä¹ ï¼ˆNLHFï¼‰ã€‚å°½ç®¡è¿™ç§è§†è§’å¯å‘äº†å…·æœ‰å¼ºå¤§ç†è®ºå’Œå®è¯ä¿è¯çš„INPOã€ONPOå’ŒEGPOç­‰ç®—æ³•ï¼Œä½†å®ƒä»¬ä»å±€é™äºä¸¤äººäº’åŠ¨ï¼Œæ— æ³•æ•æ‰ç°å®åå¥½ç»“æ„çš„å…¨é¢å¤æ‚æ€§ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šäººNashåå¥½ä¼˜åŒ–ï¼ˆMNPOï¼‰ï¼Œä¸€ä¸ªå°†NLHFæ¨å¹¿åˆ°å¤šäººåˆ¶åº¦çš„æ–°æ¡†æ¶ã€‚å®ƒå°†å¯¹é½åˆ¶å®šä¸ºä¸€ä¸ªnäººæ¸¸æˆï¼Œå…¶ä¸­æ¯ä¸ªç­–ç•¥éƒ½ä¸ä¸€ç¾¤å¯¹æ‰‹ç«äº‰ï¼ŒåŒæ—¶å‘å‚è€ƒæ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨å¤šäººè®¾ç½®ä¸­å»ºç«‹äº†æ˜ç¡®çš„Nashå‡è¡¡ï¼Œå¹¶æ‰©å±•äº†é‡åŒ–è¿‘ä¼¼è´¨é‡çš„æ¦‚å¿µâ€”â€”å¯¹å¶é—´éš™ã€‚æˆ‘ä»¬è¯æ˜MNPOç»§æ‰¿äº†ä¸¤äººæ–¹æ³•çš„å‡è¡¡ä¿è¯ï¼ŒåŒæ—¶å®ç°æ›´ä¸°å¯Œçš„ç«äº‰åŠ¨æ€å’Œæ”¹è¿›å¯¹ä¸åŒåå¥½ç»“æ„çš„è¦†ç›–ã€‚é€šè¿‡å…¨é¢çš„å®è¯è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜MNPOåœ¨æŒ‡ä»¤éµå¾ªåŸºå‡†æµ‹è¯•ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰çš„NLHFåŸºçº¿ï¼Œåœ¨å¼‚è´¨æ³¨é‡Šè€…æ¡ä»¶å’Œæ··åˆç­–ç•¥è¯„ä¼°åœºæ™¯ä¸­å®ç°ä¼˜è´¨å¯¹é½ã€‚è¿™äº›ç»“æœå…±åŒç¡®ç«‹äº†MNPOä½œä¸ºä¸€ä¸ªæœ‰åŸåˆ™ã€å¯æ‰©å……çš„æ¡†æ¶ï¼Œç”¨äºå¯¹é½å…·æœ‰å¤æ‚ã€éä¼ é€’æ€§çš„äººç±»åå¥½çš„å¤§è¯­è¨€æ¨¡å‹ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/smiles724/MNPO%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/smiles724/MNPOè·å–ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰å·²æˆä¸ºå¯¹é½å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ ‡å‡†èŒƒå¼ã€‚</li>
<li>åŸºäºBradley-Terryå‡è®¾çš„å¥–åŠ±æ–¹æ³•éš¾ä»¥æ•æ‰ç°å®ä¸–ç•Œä¸­åå¥½çš„éä¼ é€’æ€§å’Œå¼‚è´¨æ€§ã€‚</li>
<li>æœ€è¿‘çš„ç ”ç©¶é€šè¿‡å°†å¯¹é½é—®é¢˜è§†ä¸ºä¸¤äººNashåšå¼ˆï¼Œæå‡ºäº†Nashå­¦ä¹ ä»äººç±»åé¦ˆï¼ˆNLHFï¼‰ã€‚</li>
<li>ç°æœ‰ç®—æ³•å¦‚INPOã€ONPOå’ŒEGPOè™½åœ¨ç†è®ºå’Œå®è¯ä¸Šæœ‰ä¿éšœï¼Œä½†ä»…é™äºä¸¤äººäº’åŠ¨ï¼Œæ— æ³•å…¨é¢æ•æ‰ç°å®åå¥½ç»“æ„ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”å¤šäººNashåå¥½ä¼˜åŒ–ï¼ˆMNPOï¼‰ï¼Œå®ƒå°†NLHFæ¨å¹¿åˆ°å¤šäººç¯å¢ƒï¼Œå…è®¸æ›´å¤æ‚çš„ç«äº‰åŠ¨æ€å’Œæ›´å¹¿æ³›çš„åå¥½ç»“æ„è¦†ç›–ã€‚</li>
<li>MNPOé€šè¿‡å»ºç«‹æ˜ç¡®çš„Nashå‡è¡¡å’Œæ‰©å±•å¯¹å¶é—´éš™çš„æ¦‚å¿µæ¥ä¿è¯å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>å®è¯è¯„ä¼°æ˜¾ç¤ºï¼ŒMNPOåœ¨æŒ‡ä»¤éµå¾ªåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºç°æœ‰çš„NLHFåŸºçº¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼‚è´¨æ³¨é‡Šè€…æ¡ä»¶å’Œæ··åˆç­–ç•¥è¯„ä¼°åœºæ™¯ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23102">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-40851e7d55ff3965ae0979cf1c244eac~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028644&auth_key=1760028644-0-0-136265cbc6a682384818442d9d44d45e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-77b4346d21aa329fc5d27e764e39afea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028651&auth_key=1760028651-0-0-d5b3a4643338fd3c4eb308927089118c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-06/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-06/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-06/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-2cd7d9e316a461ba1a249fa172d19ecc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028658&auth_key=1760028658-0-0-91c357543e5f372af096827fbce7ce6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-06  LitterBox+ An Extensible Framework for LLM-enhanced Scratch Static Code   Analysis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-04/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-3736827f0a7bff363c7a850484b633bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760031667&auth_key=1760031667-0-0-86daafd11fd4bd24701f7ca55649e934&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-04  Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming   Attacks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31180k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
