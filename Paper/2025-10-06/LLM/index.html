<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-06  LitterBox+ An Extensible Framework for LLM-enhanced Scratch Static Code   Analysis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-2cd7d9e316a461ba1a249fa172d19ecc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028658&auth_key=1760028658-0-0-91c357543e5f372af096827fbce7ce6f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    38 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-06-æ›´æ–°"><a href="#2025-10-06-æ›´æ–°" class="headerlink" title="2025-10-06 æ›´æ–°"></a>2025-10-06 æ›´æ–°</h1><h2 id="LitterBox-An-Extensible-Framework-for-LLM-enhanced-Scratch-Static-Code-Analysis"><a href="#LitterBox-An-Extensible-Framework-for-LLM-enhanced-Scratch-Static-Code-Analysis" class="headerlink" title="LitterBox+: An Extensible Framework for LLM-enhanced Scratch Static Code   Analysis"></a>LitterBox+: An Extensible Framework for LLM-enhanced Scratch Static Code   Analysis</h2><p><strong>Authors:Benedikt Fein, Florian ObermÃ¼ller, Gordon Fraser</strong></p>
<p>Large language models (LLMs) have become an essential tool to support developers using traditional text-based programming languages, but the graphical notation of the block-based Scratch programming environment inhibits the use of LLMs. To overcome this limitation, we propose the LitterBox+ framework that extends the Scratch static code analysis tool LitterBox with the generative abilities of LLMs. By converting block-based code to a textual representation suitable for LLMs, LitterBox+ allows users to query LLMs about their programs, about quality issues reported by LitterBox, and it allows generating code fixes. Besides offering a programmatic API for these functionalities, LitterBox+ also extends the Scratch user interface to make these functionalities available directly in the environment familiar to learners. The framework is designed to be easily extensible with other prompts, LLM providers, and new features combining the program analysis capabilities of LitterBox with the generative features of LLMs. We provide a screencast demonstrating the tool at <a target="_blank" rel="noopener" href="https://youtu.be/RZ6E0xgrIgQ">https://youtu.be/RZ6E0xgrIgQ</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æˆä¸ºæ”¯æŒå¼€å‘è€…ä½¿ç”¨ä¼ ç»Ÿæ–‡æœ¬ç¼–ç¨‹è¯­è¨€çš„é‡è¦å·¥å…·ï¼Œä½†åŸºäºå—çš„Scratchç¼–ç¨‹ç¯å¢ƒçš„å›¾å½¢æ ‡è®°é˜»ç¢äº†LLMçš„ä½¿ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†LitterBox+æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ‰©å±•äº†Scratché™æ€ä»£ç åˆ†æå·¥å…·LitterBoxï¼Œå¹¶å¢åŠ äº†LLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡å°†åŸºäºå—çš„ä»£ç è½¬æ¢ä¸ºé€‚åˆLLMçš„æ–‡æœ¬è¡¨ç¤ºå½¢å¼ï¼ŒLitterBox+å…è®¸ç”¨æˆ·æŸ¥è¯¢LLMå…³äºä»–ä»¬çš„ç¨‹åºã€å…³äºLitterBoxæŠ¥å‘Šçš„è´¨é‡é—®é¢˜ï¼Œå¹¶å…è®¸ç”Ÿæˆä»£ç ä¿®å¤ã€‚é™¤äº†ä¸ºè¿™äº›åŠŸèƒ½æä¾›ç¨‹åºåŒ–APIå¤–ï¼ŒLitterBox+è¿˜æ‰©å±•äº†Scratchç”¨æˆ·ç•Œé¢ï¼Œä½¿è¿™äº›åŠŸèƒ½åœ¨ç†Ÿæ‚‰çš„å­¦ä¹ è€…ç¯å¢ƒä¸­ç›´æ¥ä½¿ç”¨ã€‚è¯¥æ¡†æ¶è®¾è®¡æ˜“äºä¸å…¶ä»–æç¤ºã€LLMæä¾›å•†å’Œæ–°åŠŸèƒ½æ‰©å±•ç»“åˆï¼Œå°†LitterBoxçš„ç¨‹åºåˆ†æåŠŸèƒ½ä¸LLMçš„ç”ŸæˆåŠŸèƒ½ç›¸ç»“åˆã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå±å¹•å½•åƒæ¼”ç¤ºå·¥å…·ï¼š<a target="_blank" rel="noopener" href="https://youtu.be/RZ6E0xgrIgQ">ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.12021v2">PDF</a> ASE 2025 Tool Demonstration Track</p>
<p><strong>æ‘˜è¦</strong></p>
<p>LLMå·²æˆä¸ºå¼€å‘è€…ä½¿ç”¨ä¼ ç»Ÿæ–‡æœ¬ç¼–ç¨‹è¯­è¨€çš„é‡è¦å·¥å…·ï¼Œä½†ç”±äºScratchç¼–ç¨‹ç¯å¢ƒçš„å›¾å½¢ç¬¦å·è¡¨ç¤ºé™åˆ¶äº†LLMçš„ä½¿ç”¨ã€‚ä¸ºå…‹æœè¿™ä¸€å±€é™ï¼Œæå‡ºLitterBox+æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ‰©å±•äº†Scratché™æ€ä»£ç åˆ†æå·¥å…·LitterBoxï¼Œèåˆäº†LLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚LitterBox+èƒ½å°†åŸºäºå—çš„ä»£ç è½¬æ¢ä¸ºé€‚åˆLLMçš„æ–‡æœ¬è¡¨ç¤ºå½¢å¼ï¼Œä½¿ç”¨æˆ·èƒ½å¤ŸæŸ¥è¯¢LLMå…³äºä»–ä»¬çš„ç¨‹åºã€å…³äºLitterBoxæŠ¥å‘Šçš„è´¨é‡é—®é¢˜ï¼Œå¹¶ç”Ÿæˆä»£ç ä¿®å¤ã€‚é™¤äº†é€šè¿‡è¿™äº›åŠŸèƒ½çš„ç¨‹åºåŒ–APIæä¾›è¿™äº›åŠŸèƒ½å¤–ï¼ŒLitterBox+è¿˜æ‰©å±•äº†Scratchç”¨æˆ·ç•Œé¢ï¼Œä½¿è¿™äº›åŠŸèƒ½åœ¨å­¦ä¹ è€…ç†Ÿæ‚‰çš„ç¯å¢ƒä¸­å¯ç”¨ã€‚è¯¥æ¡†æ¶è®¾è®¡æ˜“äºä¸å…¶ä»–æç¤ºã€LLMæä¾›å•†å’Œæ–°åŠŸèƒ½æ‰©å±•ç»“åˆï¼Œå°†LitterBoxçš„ç¨‹åºåˆ†æåŠŸèƒ½ä¸LLMçš„ç”ŸæˆåŠŸèƒ½ç›¸ç»“åˆã€‚å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://youtu.be/RZ6E0xgrIgQ">https://youtu.be/RZ6E0xgrIgQ</a>è§‚çœ‹æ¼”ç¤ºè¯¥å·¥å…·çš„è§†é¢‘ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LLMå·²æˆä¸ºä¼ ç»Ÿæ–‡æœ¬ç¼–ç¨‹è¯­è¨€å¼€å‘çš„é‡è¦æ”¯æŒå·¥å…·ã€‚</li>
<li>Scratchç¼–ç¨‹ç¯å¢ƒçš„å›¾å½¢è¡¨ç¤ºé™åˆ¶äº†LLMçš„ä½¿ç”¨ã€‚</li>
<li>LitterBox+æ¡†æ¶æ‰©å±•äº†LitterBoxï¼Œèåˆäº†LLMçš„ç”Ÿæˆèƒ½åŠ›ï¼Œä»¥å…‹æœè¿™ä¸€é™åˆ¶ã€‚</li>
<li>LitterBox+èƒ½å°†åŸºäºå—çš„ä»£ç è½¬æ¢ä¸ºé€‚åˆLLMçš„æ–‡æœ¬æ ¼å¼ã€‚</li>
<li>ç”¨æˆ·å¯ä»¥åˆ©ç”¨LitterBox+æŸ¥è¯¢LLMå…³äºç¨‹åºå’Œè´¨é‡é—®é¢˜ï¼Œå¹¶ç”Ÿæˆä»£ç ä¿®å¤ã€‚</li>
<li>LitterBox+æä¾›äº†ç¨‹åºåŒ–APIå’Œæ‰©å±•çš„Scratchç”¨æˆ·ç•Œé¢ï¼Œä½¿åŠŸèƒ½æ›´æ˜“äºä½¿ç”¨ã€‚</li>
<li>LitterBox+æ¡†æ¶è®¾è®¡å…·æœ‰å¯æ‰©å±•æ€§ï¼Œæ˜“äºä¸å…¶ä»–æç¤ºã€LLMæä¾›å•†å’Œæ–°åŠŸèƒ½ç»“åˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.12021">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-871b0f0f8c193dee0c5278ff27419de3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028665&auth_key=1760028665-0-0-1794363f97591246e15334f42a0eadce&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5aa61a701968048a3bf19e6365089073~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028673&auth_key=1760028673-0-0-df7e069873483fcf23abda1859b29ec9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Probabilistic-Reasoning-with-LLMs-for-k-anonymity-Estimation"><a href="#Probabilistic-Reasoning-with-LLMs-for-k-anonymity-Estimation" class="headerlink" title="Probabilistic Reasoning with LLMs for k-anonymity Estimation"></a>Probabilistic Reasoning with LLMs for k-anonymity Estimation</h2><p><strong>Authors:Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu</strong></p>
<p>Probabilistic reasoning is a key aspect of both human and artificial intelligence that allows for handling uncertainty and ambiguity in decision-making. In this paper, we introduce a new numerical reasoning task under uncertainty for large language models, focusing on estimating the privacy risk of user-generated documents containing privacy-sensitive information. We propose BRANCH, a new LLM methodology that estimates the k-privacy value of a text-the size of the population matching the given information. BRANCH factorizes a joint probability distribution of personal information as random variables. The probability of each factor in a population is estimated separately using a Bayesian network and combined to compute the final k-value. Our experiments show that this method successfully estimates the k-value 73% of the time, a 13% increase compared to o3-mini with chain-of-thought reasoning. We also find that LLM uncertainty is a good indicator for accuracy, as high-variance predictions are 37.47% less accurate on average. </p>
<blockquote>
<p>æ¦‚ç‡æ¨ç†æ˜¯äººç±»å’Œäººå·¥æ™ºèƒ½å†³ç­–ä¸­çš„å…³é”®æ–¹é¢ï¼Œå®ƒå…è®¸å¤„ç†ä¸ç¡®å®šæ€§å’Œæ¨¡ç³Šæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹å¼•å…¥äº†ä¸€ç§æ–°çš„ä¸ç¡®å®šæ€§æ•°å€¼æ¨ç†ä»»åŠ¡ï¼Œé‡ç‚¹æ˜¯å¯¹åŒ…å«éšç§æ•æ„Ÿä¿¡æ¯çš„ç”¨æˆ·ç”Ÿæˆæ–‡æ¡£è¿›è¡Œéšç§é£é™©è¯„ä¼°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„LLMæ–¹æ³•BRANCHï¼Œç”¨äºä¼°è®¡æ–‡æœ¬çš„kéšç§å€¼â€”â€”ä¸ç»™å®šä¿¡æ¯ç›¸åŒ¹é…çš„äººå£è§„æ¨¡ã€‚BRANCHå°†ä¸ªäººä¿¡æ¯çš„è”åˆæ¦‚ç‡åˆ†å¸ƒåˆ†è§£ä¸ºéšæœºå˜é‡ã€‚åˆ†åˆ«ä½¿ç”¨è´å¶æ–¯ç½‘ç»œä¼°è®¡äººå£ä¸­æ¯ä¸ªå› ç´ çš„æ¦‚å€¼ï¼Œå¹¶å°†å…¶ç»„åˆèµ·æ¥è®¡ç®—æœ€ç»ˆçš„kå€¼ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸæˆåŠŸä¼°ç®—å‡ºå¤§å¤šæ•°æ—¶é—´çš„kå€¼ï¼Œå³ä¼°ç®—æ­£ç¡®ç‡è¾¾åˆ°ä¸º73%ï¼Œä¸å¸¦æœ‰é“¾æ€ç»´æ¨ç†çš„o3-miniç›¸æ¯”å¢åŠ äº†13%ã€‚æˆ‘ä»¬è¿˜å‘ç°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§æ˜¯å‡†ç¡®æ€§çš„è‰¯å¥½æŒ‡æ ‡ï¼Œå› ä¸ºé«˜æ–¹å·®é¢„æµ‹çš„å¹³å‡å‡†ç¡®æ€§é™ä½äº†37.47%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09674v4">PDF</a> 10 pages, Accepted to NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä»‹ç»äº†æ¦‚ç‡æ¨ç†åœ¨äººå·¥æ™ºèƒ½ä¸äººç±»å†³ç­–ä¸­çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºå¤„ç†ä¸ç¡®å®šæ€§å’Œæ¨¡ç³Šæ€§æ˜¯å…¶ä¸»è¦ç‰¹ç‚¹ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„æ•°å€¼æ¨ç†ä»»åŠ¡ï¼Œé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¼°è®¡ç”¨æˆ·ç”Ÿæˆæ–‡æ¡£ä¸­éšç§æ•æ„Ÿä¿¡æ¯çš„éšç§é£é™©ã€‚æ–‡ç« ä»‹ç»äº†ä¸€ç§æ–°çš„LLMæ–¹æ³•BRANCHï¼Œç”¨äºä¼°è®¡æ–‡æœ¬çš„kéšç§å€¼ï¼Œå³ä¸ç»™å®šä¿¡æ¯åŒ¹é…çš„äººå£è§„æ¨¡ã€‚BRANCHå°†ä¸ªäººä¿¡æ¯ä½œä¸ºéšæœºå˜é‡åˆ†è§£è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚åˆ†åˆ«ä½¿ç”¨è´å¶æ–¯ç½‘ç»œä¼°è®¡äººå£ä¸­æ¯ä¸ªå› ç´ çš„æ¦‚ç‡ä¸ºå•ç‹¬ï¼Œå¹¶ç»„åˆè®¡ç®—æœ€ç»ˆçš„kå€¼ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸä¼°è®¡kå€¼çš„æ¦‚ç‡ä¸ºç™¾åˆ†ä¹‹ä¸ƒåä¸‰ï¼Œç›¸è¾ƒäºä½¿ç”¨æ€ç»´é“¾æ¨ç†çš„o3-miniæé«˜äº†ç™¾åˆ†ä¹‹åä¸‰ã€‚è¿˜å‘ç°LLMçš„ä¸ç¡®å®šæ€§æ˜¯å‡†ç¡®æ€§çš„è‰¯å¥½æŒ‡æ ‡ï¼Œé«˜æ–¹å·®é¢„æµ‹çš„å¹³å‡å‡†ç¡®æ€§é™ä½äº†ç™¾åˆ†ä¹‹ä¸‰åä¸ƒç‚¹å››ä¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¦‚ç‡æ¨ç†æ˜¯äººå·¥æ™ºèƒ½ä¸äººç±»å†³ç­–å¤„ç†ä¸ç¡®å®šæ€§å’Œæ¨¡ç³Šæ€§çš„å…³é”®æ–¹é¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°å€¼æ¨ç†ä»»åŠ¡ï¼Œé‡ç‚¹åœ¨äºä¼°è®¡ç”¨æˆ·ç”Ÿæˆæ–‡æ¡£çš„éšç§é£é™©ã€‚</li>
<li>ä»‹ç»äº†ä¸€ç§æ–°çš„LLMæ–¹æ³•BRANCHï¼Œç”¨äºä¼°è®¡æ–‡æœ¬çš„kéšç§å€¼ã€‚</li>
<li>BRANCHé€šè¿‡åˆ†è§£ä¸ªäººä¿¡æ¯çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå¹¶å•ç‹¬ä¼°è®¡æ¯ä¸ªå› ç´ çš„æ¦‚ç‡ä¸ºï¼Œæ¥è®¡ç®—kå€¼ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºBRANCHæ–¹æ³•æˆåŠŸä¼°è®¡kå€¼çš„æ¦‚ç‡è¾ƒé«˜ã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒBRANCHåœ¨ä¼°è®¡éšç§é£é™©çš„å‡†ç¡®æ€§æ–¹é¢æœ‰æ‰€æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09674">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0e8cee6243a92026b54f6dd47d841c4f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028680&auth_key=1760028680-0-0-68dff82f676ec874c2137a6103a36acb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cd153f37ab648c086cd1d8dbb58452cf~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028687&auth_key=1760028687-0-0-79e48bd0aaa0a0ddc4e6b7236db8a024&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d8d0d19d15d759de44e71673d10996df~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028694&auth_key=1760028694-0-0-d32fed60dc2300950bb9112a1a4d0c22&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Forget-Forgetting-Continual-Learning-in-a-World-of-Abundant-Memory"><a href="#Forget-Forgetting-Continual-Learning-in-a-World-of-Abundant-Memory" class="headerlink" title="Forget Forgetting: Continual Learning in a World of Abundant Memory"></a>Forget Forgetting: Continual Learning in a World of Abundant Memory</h2><p><strong>Authors:Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha</strong></p>
<p>Continual learning (CL) has traditionally focused on minimizing exemplar memory, a constraint often misaligned with modern systems where GPU time, not storage, is the primary bottleneck. This paper challenges this paradigm by investigating a more realistic regime: one where memory is abundant enough to mitigate forgetting, but full retraining from scratch remains prohibitively expensive. In this practical â€œmiddle groundâ€, we find that the core challenge shifts from stability to plasticity, as models become biased toward prior tasks and struggle to learn new ones. Conversely, improved stability allows simple replay baselines to outperform the state-of-the-art methods at a fraction of the GPU cost. To address this newly surfaced trade-off, we propose Weight Space Consolidation, a lightweight method that combines (1) rank-based parameter resets to restore plasticity with (2) weight averaging to enhance stability. Validated on both class-incremental learning with image classifiers and continual instruction tuning with large language models, our approach outperforms strong baselines while matching the low computational cost of replay, offering a scalable alternative to expensive full-retraining. These findings challenge long-standing CL assumptions and establish a new, cost-efficient baseline for real-world CL systems where exemplar memory is no longer the limiting factor. </p>
<blockquote>
<p>æŒç»­å­¦ä¹ ï¼ˆCLï¼‰ä¼ ç»Ÿä¸Šä¸»è¦å…³æ³¨å‡å°‘æ ·æœ¬å†…å­˜ï¼Œä½†è¿™ç§çº¦æŸä¸ç°ä»£ç³»ç»Ÿå¾€å¾€ä¸åŒ¹é…ï¼Œå› ä¸ºç°ä»£ç³»ç»Ÿçš„ä¸»è¦ç“¶é¢ˆåœ¨äºGPUæ—¶é—´è€Œéå­˜å‚¨ç©ºé—´ã€‚æœ¬æ–‡æŒ‘æˆ˜äº†è¿™ä¸€èŒƒå¼ï¼Œæ¢è®¨äº†ä¸€ä¸ªæ›´ç°å®çš„æƒ…å¢ƒï¼šä¸€ä¸ªå†…å­˜å……è¶³è¶³ä»¥ç¼“è§£é—å¿˜ä½†å®Œå…¨ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒä»ç„¶è¿‡äºæ˜‚è´µçš„æƒ…å¢ƒã€‚åœ¨è¿™ç§å®é™…çš„â€œä¸­é—´åœ°å¸¦â€ä¸­ï¼Œæˆ‘ä»¬å‘ç°æ ¸å¿ƒæŒ‘æˆ˜ä»ç¨³å®šæ€§è½¬å‘äº†å¯å¡‘æ€§ï¼Œå› ä¸ºæ¨¡å‹åå‘äºå…ˆå‰çš„ä»»åŠ¡ï¼Œéš¾ä»¥å­¦ä¹ æ–°ä»»åŠ¡ã€‚ç›¸åï¼Œå¢å¼ºç¨³å®šæ€§ä½¿å¾—ç®€å•çš„å›æ”¾åŸºçº¿å¯ä»¥åœ¨GPUæˆæœ¬æå°çš„æƒ…å†µä¸‹è¶…è¶Šæœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚ä¸ºäº†åº”å¯¹æ–°å‡ºç°çš„è¿™ç§æƒè¡¡ï¼Œæˆ‘ä»¬æå‡ºäº†æƒé‡ç©ºé—´å·©å›ºï¼ˆWeight Space Consolidationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§çš„æ–¹æ³•ï¼Œå®ƒå°†ï¼ˆ1ï¼‰åŸºäºæ’åçš„å‚æ•°é‡ç½®ç”¨äºæ¢å¤å¯å¡‘æ€§ï¼Œï¼ˆ2ï¼‰æƒé‡å¹³å‡ç”¨äºå¢å¼ºç¨³å®šæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»è¿‡å›¾åƒåˆ†ç±»å™¨çš„ç±»å¢é‡å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒç»­æŒ‡ä»¤è°ƒæ•´éªŒè¯ï¼Œåœ¨è¶…è¶Šå¼ºå¤§åŸºçº¿çš„åŒæ—¶åŒ¹é…äº†å›æ”¾çš„ä½è®¡ç®—æˆæœ¬ï¼Œä¸ºæ˜‚è´µçš„å®Œå…¨é‡æ–°è®­ç»ƒæä¾›äº†å¯ä¼¸ç¼©çš„æ›¿ä»£æ–¹æ¡ˆã€‚è¿™äº›å‘ç°æŒ‘æˆ˜äº†é•¿æœŸå­˜åœ¨çš„CLå‡è®¾ï¼Œå¹¶ä¸ºç°å®ä¸–ç•Œä¸­çš„CLç³»ç»Ÿå»ºç«‹äº†æ–°çš„ä½æˆæœ¬åŸºçº¿ï¼Œå…¶ä¸­æ ·æœ¬å†…å­˜ä¸å†æ˜¯é™åˆ¶å› ç´ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07274v4">PDF</a> 24 pages, 11 figures</p>
<p><strong>Summary</strong></p>
<p>åœ¨å†…å­˜å……è¶³ä½†ä»éœ€è€ƒè™‘GPUæˆæœ¬çš„ç°å®æƒ…å†µä¸‹ï¼Œä¼ ç»Ÿçš„æŒç»­å­¦ä¹ ï¼ˆCLï¼‰æ–¹æ³•ä¸å†é€‚ç”¨ã€‚æ¨¡å‹åœ¨æ–°ä»»åŠ¡å­¦ä¹ æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œä¸»è¦åœ¨äºåå‘å…ˆå‰çš„ä»»åŠ¡å¹¶å¤±å»å¯¹æ–°ä»»åŠ¡çš„é€‚åº”åŠ›ã€‚é’ˆå¯¹æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Weight Space Consolidationæ–¹æ³•ï¼Œé€šè¿‡ç»“åˆåŸºäºæ’åçš„å‚æ•°é‡ç½®å’Œæƒé‡å¹³å‡æ¥è§£å†³ç¨³å®šæ€§å’Œå¯å¡‘æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»å™¨çš„ç±»å¢é‡å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿ç»­æŒ‡ä»¤è°ƒæ•´ä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸”è®¡ç®—æˆæœ¬ä½ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†é•¿æœŸçš„CLå‡è®¾ï¼Œä¸ºç°å®ä¸–ç•Œçš„CLç³»ç»Ÿå»ºç«‹äº†æ–°çš„ã€æˆæœ¬æ•ˆç›Šé«˜çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»ŸæŒç»­å­¦ä¹ ï¼ˆCLï¼‰ä¸»è¦å…³æ³¨æœ€å°åŒ–ç¤ºä¾‹å†…å­˜ï¼Œä½†åœ¨å†…å­˜å……è¶³ä½†GPUæˆæœ¬é«˜æ˜‚çš„ç°å®æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚</li>
<li>åœ¨è¿™ç§ç°å®æƒ…å†µä¸‹ï¼Œæ¨¡å‹é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä»ç¨³å®šæ€§è½¬å‘äº†å¯å¡‘æ€§ï¼Œå› ä¸ºæ¨¡å‹åå‘äºå…ˆå‰çš„ä»»åŠ¡å¹¶éš¾ä»¥å­¦ä¹ æ–°ä»»åŠ¡ã€‚</li>
<li>ä¸ºäº†è§£å†³ç¨³å®šæ€§å’Œå¯å¡‘æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Weight Space Consolidationæ–¹æ³•ï¼Œç»“åˆäº†åŸºäºæ’åçš„å‚æ•°é‡ç½®å’Œæƒé‡å¹³å‡æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å›¾åƒåˆ†ç±»å™¨çš„ç±»å¢é‡å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿ç»­æŒ‡ä»¤è°ƒæ•´ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œæ€§èƒ½ä¼˜äºå¼ºåŸºçº¿ï¼ŒåŒæ—¶åŒ¹é…äº†å›æ”¾ï¼ˆreplayï¼‰çš„ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>è¯¥æ–¹æ³•æŒ‘æˆ˜äº†é•¿æœŸçš„CLå‡è®¾ï¼Œå¹¶ä¸ºç°å®ä¸–ç•Œçš„CLç³»ç»Ÿæä¾›äº†æ–°çš„ã€æˆæœ¬æ•ˆç›Šé«˜çš„åŸºå‡†ã€‚</li>
<li>è¯¥æ–¹æ³•æ³¨é‡åœ¨ä¸éœ€è¦æ˜‚è´µçš„å…¨é‡è®­ç»ƒçš„å‰æä¸‹ï¼Œå®ç°æ¨¡å‹çš„æŒç»­å­¦ä¹ å’Œé€‚åº”æ–°ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-39102b07c4f431e0569ca197467d48a8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028702&auth_key=1760028702-0-0-9392996442c7173bced003a5583188eb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7dd6e28f2557dd10d876fef993aa0c13~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028709&auth_key=1760028709-0-0-5965ef32010644d0add6169a6fe72012&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dcfa2b8d84c081efa8ea43a439d04399~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028716&auth_key=1760028716-0-0-652cebf44ac688eea2dae1c348b979a0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ab16f77c53eca15a44921625f5118e2e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028723&auth_key=1760028723-0-0-5cbc64a1798a7ed59fcd801427310a6c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-747f92f7434b40604dec4baefed0f761~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028729&auth_key=1760028729-0-0-2f2ed192ed0d18a4965861c1ee8ae6a6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Adapting-Large-Language-Models-for-Character-based-Augmentative-and-Alternative-Communication"><a href="#Adapting-Large-Language-Models-for-Character-based-Augmentative-and-Alternative-Communication" class="headerlink" title="Adapting Large Language Models for Character-based Augmentative and   Alternative Communication"></a>Adapting Large Language Models for Character-based Augmentative and   Alternative Communication</h2><p><strong>Authors:Dylan Gaines, Keith Vertanen</strong></p>
<p>Users of Augmentative and Alternative Communication (AAC) may write letter-by-letter via an interface that uses a character language model. However, most state-of-the-art large pretrained language models predict subword tokens of variable length. We investigate how to practically use such models to make accurate and efficient character predictions. Our algorithm for producing character predictions from a subword large language model (LLM) provides more accurate predictions than using a classification layer, a byte-level LLM, or an n-gram model. Additionally, we investigate a domain adaptation procedure based on a large dataset of sentences we curated based on scoring how useful each sentence might be for spoken or written AAC communication. We find our procedure further improves model performance on simple, conversational text. </p>
<blockquote>
<p>å¢å¼ºå’Œæ›¿ä»£é€šä¿¡ï¼ˆAACï¼‰çš„ç”¨æˆ·å¯ä»¥é€šè¿‡ä½¿ç”¨å­—ç¬¦è¯­è¨€æ¨¡å‹çš„ç•Œé¢é€å­—è¿›è¡Œä¹¦å†™ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æœ€å…ˆè¿›çš„å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹é¢„æµ‹çš„æ˜¯å¯å˜é•¿åº¦çš„å­è¯æ ‡è®°ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†å¦‚ä½•å®é™…ä½¿ç”¨æ­¤ç±»æ¨¡å‹è¿›è¡Œå‡†ç¡®é«˜æ•ˆçš„å­—ç¬¦é¢„æµ‹ã€‚æˆ‘ä»¬ä»å­è¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­äº§ç”Ÿå­—ç¬¦é¢„æµ‹çš„ç®—æ³•ï¼Œæ¯”ä½¿ç”¨åˆ†ç±»å±‚ã€å­—èŠ‚çº§LLMæˆ–n-gramæ¨¡å‹æä¾›æ›´å‡†ç¡®çš„é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è°ƒæŸ¥äº†ä¸€ç§åŸºäºæˆ‘ä»¬æ ¹æ®æ¯ä¸ªå¥å­å¯¹å£è¯­æˆ–ä¹¦é¢AACé€šä¿¡çš„æ½œåœ¨ä½œç”¨è¯„åˆ†è€Œç²¾å¿ƒåˆ¶ä½œçš„å¤§é‡æ•°æ®é›†è¿›è¡Œçš„åŸŸè‡ªé€‚åº”è¿‡ç¨‹ã€‚æˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„è¿‡ç¨‹åœ¨ç®€å•çš„å¯¹è¯æ–‡æœ¬ä¸Šè¿›ä¸€æ­¥æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10582v3">PDF</a> To appear in Findings of EMNLP 2025</p>
<p><strong>Summary</strong></p>
<p>ä½¿ç”¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œå­—ç¬¦é¢„æµ‹çš„å®è·µæ–¹æ³•ï¼Œå¯¹äºå¢å¼ºå’Œæ›¿ä»£äº¤æµï¼ˆAACï¼‰çš„ç”¨æˆ·æ¥è¯´è‡³å…³é‡è¦ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä»å­è¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­äº§ç”Ÿå­—ç¬¦é¢„æµ‹çš„ç®—æ³•ï¼Œç›¸è¾ƒäºåˆ†ç±»å±‚ã€å­—èŠ‚çº§LLMæˆ–n-gramæ¨¡å‹ï¼Œè¯¥ç®—æ³•é¢„æµ‹æ›´ä¸ºå‡†ç¡®ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åŸºäºæˆ‘ä»¬æ ¹æ®å¥å­å¯¹å£è¯­æˆ–ä¹¦é¢AACäº¤æµçš„æ½œåœ¨ä»·å€¼è¿›è¡Œè¯„åˆ†è€Œç²¾å¿ƒæŒ‘é€‰çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ¢ç´¢äº†ä¸€ç§é¢†åŸŸé€‚åº”ç¨‹åºã€‚è¯¥ç¨‹åºå¯è¿›ä¸€æ­¥æå‡æ¨¡å‹åœ¨ç®€å•å¯¹è¯æ–‡æœ¬ä¸Šçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¯ç”¨äºå¢å¼ºå’Œæ›¿ä»£äº¤æµï¼ˆAACï¼‰ç”¨æˆ·çš„å­—ç¬¦é¢„æµ‹ã€‚</li>
<li>æå‡ºçš„ç®—æ³•å¯ä»¥ä»å­è¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­äº§ç”Ÿæ›´å‡†ç¡®çš„å­—ç¬¦é¢„æµ‹ã€‚</li>
<li>ä¸åˆ†ç±»å±‚ã€å­—èŠ‚çº§LLMæˆ–n-gramæ¨¡å‹ç›¸æ¯”ï¼Œè¯¥ç®—æ³•çš„é¢„æµ‹å‡†ç¡®æ€§æ›´é«˜ã€‚</li>
<li>ç ”ç©¶åˆ©ç”¨å¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œé¢†åŸŸé€‚åº”ï¼Œä»¥æé«˜æ¨¡å‹åœ¨ç®€å•å¯¹è¯æ–‡æœ¬ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>æ•°æ®é›†çš„é€‰å–åŸºäºå¥å­å¯¹å£è¯­æˆ–ä¹¦é¢AACäº¤æµæ½œåœ¨ä»·å€¼çš„è¯„åˆ†ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨AACäº¤æµä¸­çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10582">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-14ef9b5ce5b21384b46899c59816180f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028737&auth_key=1760028737-0-0-9a363069de33df1e127bccf2d1c9b2fb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a21dee43293d8d64774a074adfb39f67~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028744&auth_key=1760028744-0-0-f3a7131d1225c3161b347ed2db18e272&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a47433adbe492618fce723ee27dd9941~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028751&auth_key=1760028751-0-0-f674a2bb930137f18772ffbc65814418&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LongProc-Benchmarking-Long-Context-Language-Models-on-Long-Procedural-Generation"><a href="#LongProc-Benchmarking-Long-Context-Language-Models-on-Long-Procedural-Generation" class="headerlink" title="LongProc: Benchmarking Long-Context Language Models on Long Procedural   Generation"></a>LongProc: Benchmarking Long-Context Language Models on Long Procedural   Generation</h2><p><strong>Authors:Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen</strong></p>
<p>Existing benchmarks for evaluating long-context language models (LCLMs) primarily focus on long-context recall, requiring models to produce short responses based on a few critical snippets while processing thousands of irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new benchmark that requires both the integration of highly dispersed information and long-form generation. LongProc consists of six diverse procedural generation tasks, such as extracting structured information from HTML pages into a TSV format and executing complex search procedures to create travel plans. These tasks challenge LCLMs by testing their ability to follow detailed procedural instructions, synthesize and reason over dispersed information, and generate structured, long-form outputs (up to 8K tokens). Furthermore, as these tasks adhere to deterministic procedures and yield structured outputs, they enable reliable rule-based evaluation. We evaluated 23 LCLMs, including instruction-tuned models and recent reasoning models, on LongProc at three difficulty levels, with the maximum number of output tokens set at 500, 2K, and 8K. Notably, while all tested models claim a context window size above 32K tokens, open-weight models typically falter on 2K-token tasks, and closed-source models like GPT-4o show significant degradation on 8K-token tasks. Reasoning models achieve stronger overall performance in long-form generation, benefiting from long CoT training. Further analysis reveals that LCLMs struggle to maintain long-range coherence in long-form generations. These findings highlight critical limitations in current LCLMs and suggest substantial room for improvement. Data and code available at: <a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc">https://princeton-pli.github.io/LongProc</a>. </p>
<blockquote>
<p>ç°æœ‰è¯„ä¼°é•¿è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­åœ¨é•¿è¯­å¢ƒå›å¿†ä¸Šï¼Œè¦æ±‚æ¨¡å‹åœ¨å¤„ç†æˆåƒä¸Šä¸‡çš„æ— å…³æ ‡è®°æ—¶ï¼ŒåŸºäºå‡ ä¸ªå…³é”®ç‰‡æ®µäº§ç”ŸçŸ­å›å¤ã€‚æˆ‘ä»¬æ¨å‡ºäº†LongProcï¼ˆé•¿ç¨‹åºç”Ÿæˆï¼‰æ–°åŸºå‡†æµ‹è¯•ï¼Œå®ƒè¦æ±‚é«˜åº¦åˆ†æ•£çš„ä¿¡æ¯æ•´åˆå’Œé•¿ç¯‡ç”Ÿæˆã€‚LongProcåŒ…å«å…­ä¸ªä¸åŒçš„ç¨‹åºç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ä»HTMLé¡µé¢æå–ç»“æ„åŒ–ä¿¡æ¯å¹¶è½¬æ¢ä¸ºTSVæ ¼å¼ï¼Œæ‰§è¡Œå¤æ‚çš„æœç´¢ç¨‹åºä»¥åˆ›å»ºæ—…è¡Œè®¡åˆ’ã€‚è¿™äº›ä»»åŠ¡é€šè¿‡æµ‹è¯•LCLMéµå¾ªè¯¦ç»†ç¨‹åºæŒ‡ä»¤ã€åˆæˆå’Œæ¨ç†åˆ†æ•£ä¿¡æ¯ã€ç”Ÿæˆç»“æ„åŒ–é•¿ç¯‡è¾“å‡ºï¼ˆæœ€å¤šè¾¾8Kä»¤ç‰Œï¼‰çš„èƒ½åŠ›æ¥æŒ‘æˆ˜LCLMã€‚æ­¤å¤–ï¼Œç”±äºè¿™äº›ä»»åŠ¡éµå¾ªç¡®å®šæ€§ç¨‹åºå¹¶äº§ç”Ÿç»“æ„åŒ–è¾“å‡ºï¼Œå› æ­¤å®ƒä»¬å¯ä»¥è¿›è¡Œå¯é çš„åŸºäºè§„åˆ™çš„è¯„ä»·ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªéš¾åº¦çº§åˆ«ä¸Šä½¿ç”¨LongProcè¯„ä¼°äº†23ä¸ªLCLMï¼ŒåŒ…æ‹¬æŒ‡ä»¤è°ƒæ•´æ¨¡å‹å’Œæœ€æ–°çš„æ¨ç†æ¨¡å‹ï¼Œæœ€å¤§è¾“å‡ºä»¤ç‰Œæ•°è®¾å®šä¸º500ã€2Kå’Œ8Kã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æ‰€æœ‰æµ‹è¯•æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°éƒ½è¶…è¿‡32Kä»¤ç‰Œï¼Œä½†å¼€æ”¾å¼æƒé‡æ¨¡å‹é€šå¸¸åœ¨2Kä»¤ç‰Œä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œè€Œé—­æºæ¨¡å‹å¦‚GPT-4oåœ¨8Kä»¤ç‰Œä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—é€€åŒ–ã€‚æ¨ç†æ¨¡å‹åœ¨é•¿ç¯‡æ–‡ç« ç”Ÿæˆæ–¹é¢æ€»ä½“è¡¨ç°æ›´å¼ºï¼Œå¾—ç›Šäºé•¿æœŸCoTè®­ç»ƒã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒLCLMåœ¨é•¿ç¯‡ç”Ÿæˆä¸­éš¾ä»¥ç»´æŒé•¿æœŸè¿è´¯æ€§ã€‚è¿™äº›å‘ç°çªå‡ºäº†å½“å‰LCLMçš„å…³é”®å±€é™æ€§ï¼Œå¹¶è¡¨æ˜æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚[æ•°æ®é›†å’Œä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc%E8%8E%B7%E5%8F%96%E3%80%82">https://princeton-pli.github.io/LongProc è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05414v3">PDF</a> COLM 2025. Data and code available at:   <a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc">https://princeton-pli.github.io/LongProc</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹é•¿è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„æ–°åŸºå‡†æµ‹è¯•LongProcï¼Œå®ƒè¦æ±‚æ¨¡å‹åœ¨é›†æˆé«˜åº¦åˆ†æ•£çš„ä¿¡æ¯çš„åŒæ—¶è¿›è¡Œé•¿æ–‡æœ¬ç”Ÿæˆã€‚LongProcåŒ…å«å…­ä¸ªä¸åŒçš„è¿‡ç¨‹ç”Ÿæˆä»»åŠ¡ï¼ŒæŒ‘æˆ˜äº†LCLMéµå¾ªè¯¦ç»†ç¨‹åºæŒ‡ä»¤ã€åˆæˆå’Œæ¨ç†åˆ†æ•£ä¿¡æ¯ä»¥åŠç”Ÿæˆç»“æ„åŒ–é•¿æ–‡æœ¬çš„èƒ½åŠ›ã€‚è¯„ä¼°å‘ç°ï¼Œç°æœ‰æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¦‚å¼€æ”¾æƒé‡æ¨¡å‹åœ¨2Kæ ‡è®°ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå°é—­æºæ¨¡å‹å¦‚GPT-4oåœ¨8Kæ ‡è®°ä»»åŠ¡ä¸Šæ˜¾è‘—é€€åŒ–ã€‚å°½ç®¡æ‰€æœ‰æµ‹è¯•æ¨¡å‹éƒ½å£°ç§°æ‹¥æœ‰è¶…è¿‡32Kæ ‡è®°çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œä½†æ•´ä½“è€Œè¨€ï¼Œæ¨ç†æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°æ›´å¥½ï¼Œå¾—ç›Šäºé•¿æœŸè®­ç»ƒã€‚å»ºè®®æ”¹å–„ç°æœ‰æ¨¡å‹å¹¶ä¼˜åŒ–å…¶åœ¨é•¿æ–‡æœ¬ä¸Šä¸‹æ–‡å¤„ç†æ–¹é¢çš„æ€§èƒ½ã€‚æ›´å¤šä¿¡æ¯å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc%E8%AE%BF%E9%97%AE%E3%80%82">https://princeton-pli.github.io/LongProcè®¿é—®ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥LongProcä½œä¸ºè¯„ä¼°é•¿è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„æ–°åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–å…­ä¸ªä¸åŒçš„è¿‡ç¨‹ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>LongProcä»»åŠ¡è¦æ±‚æ¨¡å‹é›†æˆé«˜åº¦åˆ†æ•£çš„ä¿¡æ¯å¹¶è¿›è¡Œé•¿æ–‡æœ¬ç”Ÿæˆï¼ŒæŒ‘æˆ˜äº†æ¨¡å‹çš„è¯¦ç»†ç¨‹åºæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€ä¿¡æ¯åˆæˆå’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰LCLMæ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œä¸åŒæ¨¡å‹åœ¨ä¸åŒéš¾åº¦çš„ä»»åŠ¡ä¸­è¡¨ç°ä¸åŒã€‚</li>
<li>å¼€æ”¾æƒé‡æ¨¡å‹åœ¨2Kæ ‡è®°ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œè€Œå°é—­æºæ¨¡å‹å¦‚GPT-4oåœ¨8Kæ ‡è®°ä»»åŠ¡ä¸Šæ˜¾è‘—é€€åŒ–ã€‚</li>
<li>å°½ç®¡æ‰€æœ‰æµ‹è¯•æ¨¡å‹éƒ½å£°ç§°æ‹¥æœ‰è¾ƒå¤§çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œä½†æ¨ç†æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°æ›´å¥½ï¼Œå¾—ç›Šäºé•¿æœŸè®­ç»ƒã€‚</li>
<li>åˆ†æå‘ç°LCLMåœ¨é•¿æ–‡æœ¬ç”Ÿæˆçš„è¿è´¯æ€§æ–¹é¢å­˜åœ¨é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05414">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0c6d883e4626dd3513358850e78eddeb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028758&auth_key=1760028758-0-0-b392e1d687af1433e36ed26f36358cd3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3b41204dfde1ef1e80938de7e11f102c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028766&auth_key=1760028766-0-0-d63c66197f447f82326122365a7495f9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-eb0733cef48bc83fe87a3759e887d292~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028773&auth_key=1760028773-0-0-a62aa953b027893d0189d5888f3fd8bb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0b5b630e9789166049f6a9833fbeb87b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028779&auth_key=1760028779-0-0-497e6fc6e4d146fc823a927951a98ca5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CART-Compositional-Auto-Regressive-Transformer-for-Image-Generation"><a href="#CART-Compositional-Auto-Regressive-Transformer-for-Image-Generation" class="headerlink" title="CART: Compositional Auto-Regressive Transformer for Image Generation"></a>CART: Compositional Auto-Regressive Transformer for Image Generation</h2><p><strong>Authors:Siddharth Roheda, Rohit Chowdhury, Aniruddha Bala, Rohan Jaiswal</strong></p>
<p>We propose a novel Auto-Regressive (AR) image generation approach that models images as hierarchical compositions of interpretable visual layers. While AR models have achieved transformative success in language modeling, replicating this success in vision tasks has presented unique challenges due to inherent spatial dependencies in images. Addressing the unique challenges of vision tasks, our method (CART) adds image details iteratively via semantically meaningful decompositions. We demonstrate the flexibility and generality of CART by applying it across three distinct decomposition strategies: (i) Base-Detail Decomposition (Mumford-Shah smoothness), (ii) Intrinsic Decomposition (albedo&#x2F;shading), and (iii) Specularity Decomposition (diffuse&#x2F;specular). This â€œnext-detailâ€ strategy outperforms traditional â€œnext-tokenâ€ and â€œnext-scaleâ€ approaches, improving controllability, semantic interpretability, and resolution scalability. Experiments show CART generates visually compelling results while enabling structured image manipulation, opening new directions for controllable generative modeling via physically or perceptually motivated image factorization. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è‡ªåŠ¨å›å½’ï¼ˆARï¼‰å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†å›¾åƒå»ºæ¨¡ä¸ºå¯è§£é‡Šè§†è§‰å±‚æ¬¡ç»“æ„çš„åˆ†å±‚ç»„åˆã€‚è™½ç„¶ARæ¨¡å‹åœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å–å¾—äº†é©å‘½æ€§çš„æˆåŠŸï¼Œä½†åœ¨è§†è§‰ä»»åŠ¡ä¸­å¤åˆ¶è¿™ä¸€æˆåŠŸå´é¢ä¸´äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå›¾åƒå­˜åœ¨å›ºæœ‰çš„ç©ºé—´ä¾èµ–æ€§ã€‚ä¸ºäº†åº”å¯¹è§†è§‰ä»»åŠ¡çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ï¼ˆCARTï¼‰é€šè¿‡è¯­ä¹‰æœ‰æ„ä¹‰çš„åˆ†è§£è¿­ä»£åœ°æ·»åŠ å›¾åƒç»†èŠ‚ã€‚æˆ‘ä»¬å±•ç¤ºäº†CARTçš„çµæ´»æ€§å’Œé€šç”¨æ€§ï¼Œå°†å…¶åº”ç”¨äºä¸‰ç§ä¸åŒçš„åˆ†è§£ç­–ç•¥ï¼šï¼ˆiï¼‰åŸºç¡€ç»†èŠ‚åˆ†è§£ï¼ˆMumford-Shahå¹³æ»‘ï¼‰ï¼Œï¼ˆiiï¼‰å†…åœ¨åˆ†è§£ï¼ˆäº®åº¦&#x2F;é˜´å½±ï¼‰ï¼Œä»¥åŠï¼ˆiiiï¼‰å…‰æ³½åˆ†è§£ï¼ˆæ¼«åå°„&#x2F;å…‰æ³½ï¼‰ã€‚è¿™ç§â€œä¸‹ä¸€ä¸ªç»†èŠ‚â€ç­–ç•¥ä¼˜äºä¼ ç»Ÿçš„â€œä¸‹ä¸€ä¸ªæ ‡è®°â€å’Œâ€œä¸‹ä¸€ä¸ªå°ºåº¦â€æ–¹æ³•ï¼Œæé«˜äº†å¯æ§æ€§ã€è¯­ä¹‰å¯è§£é‡Šæ€§å’Œåˆ†è¾¨ç‡çš„å¯æ‰©å±•æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒCARTåœ¨ç”Ÿæˆè§†è§‰ä¸Šå¼•äººæ³¨ç›®çš„ç»“æœçš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°ç»“æ„åŒ–å›¾åƒæ“ä½œï¼Œä¸ºé€šè¿‡ç‰©ç†æˆ–æ„ŸçŸ¥é©±åŠ¨çš„å›¾åƒåˆ†è§£å®ç°å¯æ§ç”Ÿæˆå»ºæ¨¡å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.10180v2">PDF</a> figures compressed to meet arxiv size limit</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„Auto-Regressiveï¼ˆARï¼‰å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†å›¾åƒå»ºæ¨¡ä¸ºå¯è§£é‡Šè§†è§‰å±‚çš„å±‚æ¬¡ç»„åˆã€‚å°½ç®¡ARæ¨¡å‹åœ¨è¯­è¨€å»ºæ¨¡ä¸­å–å¾—äº†çªç ´æ€§æˆåŠŸï¼Œä½†åœ¨è§†è§‰ä»»åŠ¡ä¸­å¤åˆ¶è¿™ä¸€æˆåŠŸå´é¢ä¸´äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¯ç”±äºå›¾åƒå›ºæœ‰çš„ç©ºé—´ä¾èµ–æ€§æ‰€å¯¼è‡´çš„ã€‚æœ¬æ–‡çš„æ–¹æ³•ï¼ˆCARTï¼‰é€šè¿‡è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„åˆ†è§£è¿­ä»£åœ°æ·»åŠ å›¾åƒç»†èŠ‚ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨ä¸‰ç§ä¸åŒåˆ†è§£ç­–ç•¥ä¸Šçš„çµæ´»æ€§å’Œé€šç”¨æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒCARTç”Ÿæˆäº†è§†è§‰å¸å¼•äººçš„ç»“æœï¼ŒåŒæ—¶å®ç°äº†ç»“æ„åŒ–å›¾åƒæ“çºµï¼Œä¸ºå¯æ§ç”Ÿæˆå»ºæ¨¡æä¾›äº†æ–°çš„æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†Auto-Regressiveï¼ˆARï¼‰å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œå°†å›¾åƒå»ºæ¨¡ä¸ºå±‚æ¬¡åŒ–çš„å¯è§£é‡Šè§†è§‰å±‚ç»„åˆã€‚</li>
<li>ARæ¨¡å‹åœ¨è§†è§‰ä»»åŠ¡ä¸­é¢ä¸´äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œå¦‚å›¾åƒçš„ç©ºé—´ä¾èµ–æ€§ã€‚</li>
<li>CARTæ–¹æ³•é€šè¿‡è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„åˆ†è§£è¿­ä»£åœ°æ·»åŠ å›¾åƒç»†èŠ‚ã€‚</li>
<li>CARTå¯åº”ç”¨äºä¸‰ç§ä¸åŒçš„åˆ†è§£ç­–ç•¥ï¼šBase-Detailåˆ†è§£ã€Intrinsicåˆ†è§£å’ŒSpecularityåˆ†è§£ã€‚</li>
<li>CARTçš„â€œnext-detailâ€ç­–ç•¥ä¼˜äºä¼ ç»Ÿçš„â€œnext-tokenâ€å’Œâ€œnext-scaleâ€æ–¹æ³•ï¼Œæé«˜äº†å¯æ§æ€§ã€è¯­ä¹‰å¯è§£é‡Šæ€§å’Œåˆ†è¾¨ç‡å¯æ‰©å±•æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜CARTèƒ½ç”Ÿæˆè§†è§‰ä¸Šå¸å¼•äººçš„ç»“æœï¼Œå¹¶å®ç°äº†ç»“æ„åŒ–å›¾åƒæ“ä½œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.10180">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-b006987d7c1a699f1b4b91b21769ef7e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028787&auth_key=1760028787-0-0-0599d723baba94a96ce16f1a5975406b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2cd7d9e316a461ba1a249fa172d19ecc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028794&auth_key=1760028794-0-0-42d9e821c71d4940aaf87c227064c99d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-caede51e3bc23972eddea158f78ce659~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028800&auth_key=1760028800-0-0-3362d9a89c01418ba0dbe80f61d0d606&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7632e4d32b8fc97788301f21c5f2ff7d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028807&auth_key=1760028807-0-0-92607c853753ba8a8b148a408070a0fb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3c721b352917b7c9574a823ad0ac99f7~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028814&auth_key=1760028814-0-0-f3ed9cffc87f1dcd2b33800ffe62f1a8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-511a880beacfd7d30a58e3cd8abc14fe~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028820&auth_key=1760028820-0-0-2899a0ecd89376130321b559c6160b72&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-94ce1033db46907d9ca6cc1b29bdf094~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028827&auth_key=1760028827-0-0-5e4dfbc912be7770213998c3f3a172ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="PETAH-Parameter-Efficient-Task-Adaptation-for-Hybrid-Transformers-in-a-resource-limited-Context"><a href="#PETAH-Parameter-Efficient-Task-Adaptation-for-Hybrid-Transformers-in-a-resource-limited-Context" class="headerlink" title="PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a   resource-limited Context"></a>PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a   resource-limited Context</h2><p><strong>Authors:Maximilian Augustin, Syed Shakib Sarwar, Mostafa Elhoushi, Sai Qian Zhang, Yuecheng Li, Barbara De Salvo</strong></p>
<p>Following their success in natural language processing (NLP), there has been a shift towards transformer models in computer vision. While transformers perform well and offer promising multi-tasking performance, due to their high compute requirements, many resource-constrained applications still rely on convolutional or hybrid models that combine the benefits of convolution and attention layers and achieve the best results in the sub 100M parameter range. Simultaneously, task adaptation techniques that allow for the use of one shared transformer backbone for multiple downstream tasks, resulting in great storage savings at negligible cost in performance, have not yet been adopted for hybrid transformers. In this work, we investigate how to achieve the best task-adaptation performance and introduce PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers. We further combine PETAH adaptation with pruning to achieve highly performant and storage friendly models for multi-tasking. In our extensive evaluation on classification and other vision tasks, we demonstrate that our PETAH-adapted hybrid models outperform established task-adaptation techniques for ViTs while requiring fewer parameters and being more efficient on mobile hardware. </p>
<blockquote>
<p>ç»§å…¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸçš„æˆåŠŸåï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸä¹Ÿå¼€å§‹è½¬å‘ä½¿ç”¨Transformeræ¨¡å‹ã€‚è™½ç„¶Transformerè¡¨ç°è‰¯å¥½å¹¶æä¾›æœ‰å‰æ™¯çš„å¤šä»»åŠ¡æ€§èƒ½ï¼Œä½†ç”±äºå…¶è®¡ç®—éœ€æ±‚è¾ƒé«˜ï¼Œè®¸å¤šèµ„æºå—é™çš„åº”ç”¨ç¨‹åºä»ç„¶ä¾èµ–äºå·ç§¯æˆ–æ··åˆæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ç»“åˆäº†å·ç§¯å±‚å’Œæ³¨æ„åŠ›å±‚çš„ä¼˜ç‚¹ï¼Œå¹¶åœ¨å°äº100Mçš„å‚æ•°èŒƒå›´å†…å–å¾—äº†æœ€ä½³ç»“æœã€‚åŒæ—¶ï¼Œå…è®¸ä½¿ç”¨ä¸€ä¸ªå…±äº«çš„Transformerä¸»å¹²è¿›è¡Œå¤šä¸ªä¸‹æ¸¸ä»»åŠ¡çš„ä»»åŠ¡é€‚é…æŠ€æœ¯ï¼Œå¯ä»¥åœ¨æ€§èƒ½æŸå¤±æå°çš„æƒ…å†µä¸‹å®ç°å·¨å¤§çš„å­˜å‚¨èŠ‚çœï¼Œä½†å°šæœªè¢«æ··åˆTransformeræ‰€é‡‡ç”¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¦‚ä½•å®ç°æœ€ä½³çš„ä»»åŠ¡é€‚é…æ€§èƒ½ï¼Œå¹¶ä»‹ç»äº†PETAHï¼šæ··åˆTransformerçš„å‚æ•°é«˜æ•ˆä»»åŠ¡é€‚é…ã€‚æˆ‘ä»¬è¿˜å°†PETAHé€‚é…ä¸ä¿®å‰ªç›¸ç»“åˆï¼Œä»¥å®ç°å¤šä»»åŠ¡çš„é«˜æ€§èƒ½ä¸”å­˜å‚¨å‹å¥½çš„æ¨¡å‹ã€‚åœ¨åˆ†ç±»å’Œå…¶ä»–è§†è§‰ä»»åŠ¡çš„å¹¿æ³›è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„PETAHé€‚é…çš„æ··åˆæ¨¡å‹åœ¨å‚æ•°æ›´å°‘ã€ç§»åŠ¨ç¡¬ä»¶ä¸Šæ•ˆç‡æ›´é«˜çš„åŒæ—¶ï¼Œä¼˜äºViTçš„ç°æœ‰ä»»åŠ¡é€‚é…æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17661v2">PDF</a> Published in CVPRW 2025</p>
<p><strong>Summary</strong><br>     éšç€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„æˆåŠŸï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå¼€å§‹è½¬å‘ä½¿ç”¨Transformeræ¨¡å‹ã€‚è™½ç„¶Transformerè¡¨ç°è‰¯å¥½å¹¶æä¾›æœ‰å‰æ™¯çš„å¤šä»»åŠ¡æ€§èƒ½ï¼Œä½†ç”±äºå…¶é«˜è®¡ç®—éœ€æ±‚ï¼Œè®¸å¤šèµ„æºå—é™çš„åº”ç”¨ä»ä¾èµ–äºå·ç§¯æˆ–æ··åˆæ¨¡å‹ã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•å®ç°æœ€ä½³çš„ä»»åŠ¡é€‚åº”æ€§ï¼Œå¹¶å¼•å…¥äº†PETAHï¼šæ··åˆTransformerçš„å‚æ•°é«˜æ•ˆä»»åŠ¡é€‚åº”æ€§æŠ€æœ¯ã€‚æˆ‘ä»¬è¿˜é€šè¿‡å‰ªæè¿›ä¸€æ­¥æé«˜PETAHé€‚åº”æ€§ï¼Œä»¥å®ç°å¯¹å¤šä»»åŠ¡çš„é«˜æ•ˆå¤„ç†ã€‚åœ¨åˆ†ç±»å’Œå…¶ä»–è§†è§‰ä»»åŠ¡ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„PETAHè‡ªé€‚åº”æ··åˆæ¨¡å‹åœ¨å‚æ•°éœ€æ±‚æ›´å°‘ä¸”ç§»åŠ¨ç«¯ç¡¬ä»¶æ•ˆç‡æ›´é«˜çš„åŒæ—¶ï¼Œä¼˜äºViTçš„ä»»åŠ¡é€‚åº”æ€§æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformeræ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åº”ç”¨é€æ¸æ™®åŠã€‚</li>
<li>è™½ç„¶Transformerå…·æœ‰è‰¯å¥½çš„å¤šä»»åŠ¡æ€§èƒ½ï¼Œä½†å…¶é«˜è®¡ç®—éœ€æ±‚ä½¿å¾—èµ„æºå—é™çš„åº”ç”¨ä»ä¾èµ–å·ç§¯æˆ–æ··åˆæ¨¡å‹ã€‚</li>
<li>PETAHæŠ€æœ¯æ—¨åœ¨å®ç°æ··åˆTransformerçš„æœ€ä½³ä»»åŠ¡é€‚åº”æ€§ã€‚</li>
<li>PETAHæŠ€æœ¯ä¸å‰ªæç›¸ç»“åˆï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå­˜å‚¨æ•ˆç‡ã€‚</li>
<li>åœ¨åˆ†ç±»å’Œå…¶ä»–è§†è§‰ä»»åŠ¡ä¸Šï¼ŒPETAHè‡ªé€‚åº”æ··åˆæ¨¡å‹çš„æ€§èƒ½ä¼˜äºViTçš„ä»»åŠ¡é€‚åº”æ€§æŠ€æœ¯ã€‚</li>
<li>PETAHè‡ªé€‚åº”æ··åˆæ¨¡å‹å…·æœ‰æ›´å°‘çš„å‚æ•°éœ€æ±‚å’Œé«˜ç§»åŠ¨ç«¯ç¡¬ä»¶æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17661">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-337a1d3aef8f1246f6374d5bc7ba1597~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028835&auth_key=1760028835-0-0-dfa6c2289ca612a18b893821dd6a14fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-77f08df2448ecba569a455fbfeabfe2f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028843&auth_key=1760028843-0-0-69a0f6632340abe1910cc9bae9345dc6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f170797bf79683da221e12b3094d4890~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028849&auth_key=1760028849-0-0-90f0d547603024c4956ce371ca1c7150&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e05bf91bb2bc2125a2b286d0e6c8b7f4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028856&auth_key=1760028856-0-0-1204b0f111260e343152a92e3655115a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cfa7ab545164f40598806c707a3cff3f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028862&auth_key=1760028862-0-0-38e37308ba309c800af8c9fbcf11031b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0a2ad968f7528629e2157efbe757326a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028869&auth_key=1760028869-0-0-55aafe5bf36ee3c96e6df332b2464347&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="M6-GPT-3-Generating-Multitrack-Modifiable-Multi-Minute-MIDI-Music-from-Text-using-Genetic-algorithms-Probabilistic-methods-and-GPT-Models-in-any-Progression-and-Time-Signature"><a href="#M6-GPT-3-Generating-Multitrack-Modifiable-Multi-Minute-MIDI-Music-from-Text-using-Genetic-algorithms-Probabilistic-methods-and-GPT-Models-in-any-Progression-and-Time-Signature" class="headerlink" title="M6(GPT)3: Generating Multitrack Modifiable Multi-Minute MIDI Music from   Text using Genetic algorithms, Probabilistic methods and GPT Models in any   Progression and Time Signature"></a>M6(GPT)3: Generating Multitrack Modifiable Multi-Minute MIDI Music from   Text using Genetic algorithms, Probabilistic methods and GPT Models in any   Progression and Time Signature</h2><p><strong>Authors:Jakub PoÄ‡wiardowski, Mateusz Modrzejewski, Marek S. Tatara</strong></p>
<p>This work introduces the M6(GPT)3 composer system, capable of generating complete, multi-minute musical compositions with complex structures in any time signature, in the MIDI domain from input descriptions in natural language. The system utilizes an autoregressive transformer language model to map natural language prompts to composition parameters in JSON format. The defined structure includes time signature, scales, chord progressions, and valence-arousal values, from which accompaniment, melody, bass, motif, and percussion tracks are created. We propose a genetic algorithm for the generation of melodic elements. The algorithm incorporates mutations with musical significance and a fitness function based on normal distribution and predefined musical feature values. The values adaptively evolve, influenced by emotional parameters and distinct playing styles. The system for generating percussion in any time signature utilises probabilistic methods, including Markov chains. Through both human and objective evaluations, we demonstrate that our music generation approach outperforms baselines on specific, musically meaningful metrics, offering a viable alternative to purely neural network-based systems. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†M6ï¼ˆGPTï¼‰3ä½œæ›²ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿåœ¨MIDIé¢†åŸŸä¸­æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆå®Œæ•´ã€å¤šåˆ†é’Ÿçš„å…·æœ‰å¤æ‚ç»“æ„çš„éŸ³ä¹ã€‚ç³»ç»Ÿé‡‡ç”¨è‡ªå›å½’è½¬æ¢å™¨è¯­è¨€æ¨¡å‹ï¼Œå°†è‡ªç„¶è¯­è¨€æç¤ºæ˜ å°„åˆ°JSONæ ¼å¼çš„ä½œæ›²å‚æ•°ä¸Šã€‚æ‰€å®šä¹‰çš„å‚æ•°ç»“æ„åŒ…æ‹¬æ—¶é—´ç­¾åã€éŸ³é˜¶ã€å’Œå¼¦è¿›å±•ä»¥åŠæƒ…æ„Ÿå€¼ï¼Œç”±æ­¤ç”Ÿæˆä¼´å¥ã€æ—‹å¾‹ã€ä½éŸ³ã€åŠ¨æœºå’Œæ‰“å‡»ä¹è½¨é“ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºç”Ÿæˆæ—‹å¾‹å…ƒç´ çš„é—ä¼ ç®—æ³•ã€‚è¯¥ç®—æ³•ç»“åˆäº†å…·æœ‰éŸ³ä¹æ„ä¹‰çš„çªå˜å’ŒåŸºäºæ­£æ€åˆ†å¸ƒå’Œé¢„å®šä¹‰éŸ³ä¹ç‰¹å¾å€¼çš„é€‚åº”åº¦å‡½æ•°ã€‚è¿™äº›å€¼ä¼šé€‚åº”æ€§åœ°æ¼”å˜ï¼Œå—åˆ°æƒ…ç»ªå‚æ•°å’Œç‹¬ç‰¹æ¼”å¥é£æ ¼çš„å½±å“ã€‚ç³»ç»Ÿç”Ÿæˆä»»ä½•æ—¶é—´ç­¾åçš„æ‰“å‡»ä¹éƒ¨åˆ†é‡‡ç”¨äº†æ¦‚ç‡æ–¹æ³•ï¼ŒåŒ…æ‹¬é©¬å°”å¯å¤«é“¾ã€‚é€šè¿‡äººç±»å’Œå®¢è§‚è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„éŸ³ä¹ç”Ÿæˆæ–¹æ³•åœ¨ç‰¹å®šçš„éŸ³ä¹æ„ä¹‰ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œä¸ºä»…åŸºäºç¥ç»ç½‘ç»œçš„ç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.12638v3">PDF</a> Published in 2025 IEEE International Conference on Multimedia and   Expo Workshops (ICMEW)</p>
<p><strong>Summary</strong><br>è¯¥å·¥ä½œä»‹ç»äº†M6ï¼ˆGPTï¼‰3ä½œæ›²ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆå®Œæ•´ã€å¤šåˆ†é’Ÿçš„éŸ³ä¹ä½œå“ï¼Œå…·æœ‰å¤æ‚çš„ç»“æ„å¹¶èƒ½é€‚åº”ä»»ä½•çš„æ—¶é—´ç­¾åã€‚ç³»ç»Ÿé‡‡ç”¨è‡ªå›å½’è½¬æ¢å™¨è¯­è¨€æ¨¡å‹ï¼Œå°†è‡ªç„¶è¯­è¨€æç¤ºæ˜ å°„åˆ°JSONæ ¼å¼çš„åˆ›ä½œå‚æ•°ä¸Šã€‚é€šè¿‡é—ä¼ ç®—æ³•ç”Ÿæˆæ—‹å¾‹å…ƒç´ ï¼Œç»“åˆéŸ³ä¹æ„ä¹‰çš„çªå˜å’ŒåŸºäºæ­£æ€åˆ†å¸ƒåŠé¢„å®šä¹‰éŸ³ä¹ç‰¹å¾å€¼çš„é€‚åº”åº¦å‡½æ•°ã€‚ç³»ç»Ÿå¯ç”Ÿæˆä»»ä½•æ—¶é—´ç­¾åçš„æ‰“å‡»ä¹ï¼Œé‡‡ç”¨æ¦‚ç‡æ–¹æ³•ï¼ŒåŒ…æ‹¬é©¬å°”å¯å¤«é“¾ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥éŸ³ä¹ç”Ÿæˆæ–¹æ³•åœ¨æŸäº›éŸ³ä¹ç›¸å…³æŒ‡æ ‡ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæ˜¯çº¯ç²¹åŸºäºç¥ç»ç½‘ç»œç³»ç»Ÿçš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>M6(GPT)3ä½œæ›²ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆå…·æœ‰å¤æ‚ç»“æ„çš„å®Œæ•´éŸ³ä¹ä½œå“ã€‚</li>
<li>ç³»ç»Ÿé‡‡ç”¨è‡ªå›å½’è½¬æ¢å™¨è¯­è¨€æ¨¡å‹å°†è‡ªç„¶è¯­è¨€æç¤ºè½¬æ¢ä¸ºJSONæ ¼å¼çš„åˆ›ä½œå‚æ•°ã€‚</li>
<li>é‡‡ç”¨é—ä¼ ç®—æ³•ç”Ÿæˆæ—‹å¾‹å…ƒç´ ï¼Œç»“åˆéŸ³ä¹æ„ä¹‰çš„çªå˜å’Œé€‚åº”åº¦å‡½æ•°ã€‚</li>
<li>ç³»ç»Ÿå¯ä»¥é€‚åº”ä¸åŒçš„æ—¶é—´ç­¾åå¹¶ç”Ÿæˆç›¸åº”çš„éŸ³ä¹ä½œå“ã€‚</li>
<li>æ‰“å‡»ä¹çš„ç”Ÿæˆé‡‡ç”¨äº†æ¦‚ç‡æ–¹æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨é©¬å°”å¯å¤«é“¾ã€‚</li>
<li>è¯¥éŸ³ä¹ç”Ÿæˆæ–¹æ³•åœ¨ç‰¹å®šéŸ³ä¹æŒ‡æ ‡ä¸Šçš„è¡¨ç°ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.12638">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-0212663e00b02c36ef653cffc78568a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028877&auth_key=1760028877-0-0-e2d13456bb2adc3ff9a0931cd89efcd3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-498cc76d1b953b767a27843b64e735a0~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028884&auth_key=1760028884-0-0-f61e9eb79ce92b5641668a2f9c3f1c0f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f0f6529b794f1aca9594611a6019da13~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028891&auth_key=1760028891-0-0-16b38fea5bdb2eaf3136f40aa3e73591&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3fab5191981212fed0af77e6beb93138~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028898&auth_key=1760028898-0-0-8beabe7c2a2fa9bd1b97945271be2983&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-998c4d3192ad006e1674b8952472dac4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028904&auth_key=1760028904-0-0-3cfdaedcd31113fea80dddd422a00f20&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="StarTrail-Concentric-Ring-Sequence-Parallelism-for-Efficient-Near-Infinite-Context-Transformer-Model-Training"><a href="#StarTrail-Concentric-Ring-Sequence-Parallelism-for-Efficient-Near-Infinite-Context-Transformer-Model-Training" class="headerlink" title="StarTrail: Concentric Ring Sequence Parallelism for Efficient   Near-Infinite-Context Transformer Model Training"></a>StarTrail: Concentric Ring Sequence Parallelism for Efficient   Near-Infinite-Context Transformer Model Training</h2><p><strong>Authors:Ziming Liu, Shaoyu Wang, Shenggan Cheng, Zhongkai Zhao, Kai Wang, Xuanlei Zhao, James Demmel, Yang You</strong></p>
<p>Training Transformer models on long sequences in a distributed setting poses significant challenges in terms of efficiency and scalability. Current methods are either constrained by the number of attention heads or excessive communication overheads. To address this problem, we propose StarTrail, a multi-dimensional concentric distributed training system for long sequences, fostering an efficient communication paradigm and providing additional tuning flexibility for communication arrangements. Specifically, StarTrail introduces an extra parallel dimension and divides the peer-to-peer communication into sub-rings to substantially reduce communication volume and avoid bandwidth bottlenecks. Through comprehensive experiments across diverse hardware environments and on both Natural Language Processing (NLP) and Computer Vision (CV) tasks, we demonstrate that our approach significantly surpasses state-of-the-art methods that support Long sequence lengths, achieving performance improvements of up to 77.12% on GPT-style models and up to 114.33% on DiT (Diffusion Transformer) models without affecting the computations results. </p>
<blockquote>
<p>åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å¯¹é•¿åºåˆ—è¿›è¡ŒTransformeræ¨¡å‹è®­ç»ƒï¼Œåœ¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢é¢ä¸´ç€å·¨å¤§æŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•è¦ä¹ˆå—åˆ°æ³¨æ„åŠ›å¤´æ•°é‡çš„é™åˆ¶ï¼Œè¦ä¹ˆå­˜åœ¨è¿‡å¤šçš„é€šä¿¡å¼€é”€ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†StarTrailï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé•¿åºåˆ—çš„å¤šç»´åŒå¿ƒåˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿï¼Œå®ƒä¿ƒè¿›äº†ä¸€ç§é«˜æ•ˆçš„é€šä¿¡èŒƒå¼ï¼Œå¹¶ä¸ºé€šä¿¡å®‰æ’æä¾›äº†é¢å¤–çš„è°ƒæ•´çµæ´»æ€§ã€‚å…·ä½“æ¥è¯´ï¼ŒStarTrailå¼•å…¥äº†ä¸€ä¸ªé¢å¤–çš„å¹¶è¡Œç»´åº¦ï¼Œå°†ç‚¹å¯¹ç‚¹é€šä¿¡åˆ†æˆå­ç¯ï¼Œä»è€Œå¤§å¹…åº¦å‡å°‘äº†é€šä¿¡é‡å¹¶é¿å…äº†å¸¦å®½ç“¶é¢ˆã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸åŒç¡¬ä»¶ç¯å¢ƒä¸Šè¿›è¡Œçš„å…¨é¢å®éªŒï¼Œä»¥åŠè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œè®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰ä»»åŠ¡ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—è¶…è¿‡äº†æ”¯æŒé•¿åºåˆ—é•¿åº¦çš„æœ€æ–°æ–¹æ³•ï¼Œåœ¨GPTé£æ ¼æ¨¡å‹ä¸Šå®ç°äº†é«˜è¾¾77.12%çš„æ€§èƒ½æå‡ï¼Œåœ¨DiTï¼ˆæ‰©æ•£å˜æ¢å™¨ï¼‰æ¨¡å‹ä¸Šå®ç°äº†é«˜è¾¾114.33%çš„æ€§èƒ½æå‡ï¼Œä¸”ä¸å½±å“è®¡ç®—ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.00611v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è®­ç»ƒé•¿åºåˆ—çš„Transformeræ¨¡å‹é¢ä¸´æ•ˆç‡å’Œå¯æ‰©å±•æ€§çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºStarTrailç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨å¤šç»´åŒå¿ƒåˆ†å¸ƒå¼è®­ç»ƒæ¶æ„ï¼Œä¼˜åŒ–äº†é€šä¿¡æ¨¡å¼å¹¶ä¸ºé€šä¿¡å®‰æ’æä¾›äº†é¢å¤–çš„è°ƒæ•´çµæ´»æ€§ã€‚StarTrailé€šè¿‡å¼•å…¥é¢å¤–çš„å¹¶è¡Œç»´åº¦å’Œå°†ç‚¹å¯¹ç‚¹é€šä¿¡åˆ’åˆ†ä¸ºå­ç¯æ¥å‡å°‘é€šä¿¡é‡å¹¶é¿å…å¸¦å®½ç“¶é¢ˆã€‚å®éªŒè¡¨æ˜ï¼ŒStarTrailåœ¨æ”¯æŒé•¿åºåˆ—é•¿åº¦æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯æ–¹æ³•ï¼ŒGPTé£æ ¼æ¨¡å‹å’ŒDiTï¼ˆæ‰©æ•£è½¬æ¢å™¨ï¼‰æ¨¡å‹çš„æ€§èƒ½åˆ†åˆ«æé«˜äº†77.12%å’Œæœ€é«˜å¯è¾¾ä¸Šè¶…è¿‡æˆ‘ä»¬çš„åšæ³•é€šè¿‡ç®€åŒ–çš„åˆ›æ–°ç®—æ³•è¡¨æ˜åºåˆ—æ¯”ç°æœ‰æŠ€æœ¯æ–¹æ³•æé«˜äº†é«˜è¾¾ä¸Šæé«˜äº†é«˜è¾¾ä¸Šè¶…è¿‡æˆ‘ä»¬çš„åšæ³•ã€‚é€šè¿‡åœ¨å¤šæ ·åŒ–çš„ç¡¬ä»¶ç¯å¢ƒå’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œè®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰ä»»åŠ¡ä¸Šçš„å…¨é¢å®éªŒï¼Œè¯æ˜äº†StarTrailçš„æœ‰æ•ˆæ€§ã€‚è¿™äº›æ–¹æ³•åœ¨ä¸å½±å“è®¡ç®—ç»“æœçš„æƒ…å†µä¸‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®­ç»ƒTransformeræ¨¡å‹åœ¨é•¿åºåˆ—çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­å­˜åœ¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚</li>
<li>å½“å‰æ–¹æ³•å—åˆ°æ³¨æ„åŠ›å¤´æ•°é‡çš„é™åˆ¶æˆ–é€šä¿¡å¼€é”€è¿‡å¤§çš„å½±å“ã€‚</li>
<li>StarTrailç³»ç»Ÿæå‡ºä¸€ä¸ªå¤šç»´åŒå¿ƒåˆ†å¸ƒå¼è®­ç»ƒæ¶æ„æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>StarTrailå¼•å…¥é¢å¤–çš„å¹¶è¡Œç»´åº¦ï¼Œå°†ç‚¹å¯¹ç‚¹é€šä¿¡åˆ’åˆ†ä¸ºå­ç¯æ¥å‡å°‘é€šä¿¡é‡å’Œé¿å…å¸¦å®½ç“¶é¢ˆã€‚</li>
<li>StarTrailé€šè¿‡ä¼˜åŒ–é€šä¿¡æ¨¡å¼ä¸ºé€šä¿¡å®‰æ’æä¾›é¢å¤–çš„è°ƒæ•´çµæ´»æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒStarTrailåœ¨æ”¯æŒé•¿åºåˆ—é•¿åº¦æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯æ–¹æ³•ï¼ŒGPTé£æ ¼æ¨¡å‹å’ŒDiTæ¨¡å‹çš„æ€§èƒ½æå‡æ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.00611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6edfdef04fa474554a054ae66ffa5d0e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028912&auth_key=1760028912-0-0-491ceadd7f6aee88c0ff632760958e0d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a9b25a29efb6ff1e712c0138fffd119~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028919&auth_key=1760028919-0-0-b938e0539be66f79de3c6d935e5feb50&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0e07c7d52eb7c2f55dcdce056cc9db65~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028926&auth_key=1760028926-0-0-79cf4ef1a9bc75d4c84ecd28eedb7c7f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-af27c6f5b038b256e8e4ee1f10a58c8b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028934&auth_key=1760028934-0-0-242de3e8f5fc513869f5504af8533a4f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-00132758286cf18ae89b5d7a543080a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028941&auth_key=1760028941-0-0-70272f925ecb5b27e1f7d64b5124da91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4d1f91b25e2e70a50863c90c3ac4acc6~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028948&auth_key=1760028948-0-0-3f1f8661dcc49a97c60b8addfb9cd420&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="PaECTER-Patent-level-Representation-Learning-using-Citation-informed-Transformers"><a href="#PaECTER-Patent-level-Representation-Learning-using-Citation-informed-Transformers" class="headerlink" title="PaECTER: Patent-level Representation Learning using Citation-informed   Transformers"></a>PaECTER: Patent-level Representation Learning using Citation-informed   Transformers</h2><p><strong>Authors:Mainak Ghosh, Michael E. Rose, Sebastian Erhardt, Erik Buunk, Dietmar Harhoff</strong></p>
<p>PaECTER is an open-source document-level encoder specific for patents. We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the patent specific pre-trained language model (BERT for Patents) and general-purpose text embedding models (e.g., E5, GTE, and BGE) on our patent citation prediction test dataset on different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners. </p>
<blockquote>
<p>PaECTERæ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸“åˆ©çš„å¼€æºæ–‡æ¡£çº§åˆ«ç¼–ç å™¨ã€‚æˆ‘ä»¬ä½¿ç”¨å®¡æŸ¥å‘˜æ·»åŠ çš„å¼•æ–‡ä¿¡æ¯å¯¹ä¸“åˆ©çš„BERTæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥ç”Ÿæˆä¸“åˆ©æ–‡æ¡£çš„æ•°å€¼è¡¨ç¤ºã€‚åœ¨ç›¸ä¼¼åº¦ä»»åŠ¡æ–¹é¢ï¼ŒPaECTERçš„è¡¨ç°ä¼˜äºå½“å‰ä¸“åˆ©é¢†åŸŸä¸­ä½¿ç”¨çš„æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸“åˆ©å¼•æ–‡é¢„æµ‹æµ‹è¯•æ•°æ®é›†ä¸Šçš„ä¸åŒæ’åè¯„ä¼°æŒ‡æ ‡ä¸Šï¼Œè¶…è¶Šäº†é’ˆå¯¹ä¸“åˆ©çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆä¸“åˆ©BERTï¼‰å’Œé€šç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆä¾‹å¦‚E5ã€GTEå’ŒBGEï¼‰ã€‚å½“ä¸25ç¯‡ä¸ç›¸å…³çš„ä¸“åˆ©ç›¸æ¯”æ—¶ï¼ŒPaECTERå¹³å‡åœ¨æ’åç¬¬ä¸€æ—¶è‡³å°‘é¢„æµ‹å‡ºä¸€ç¯‡æœ€ç›¸ä¼¼çš„ä¸“åˆ©ï¼Œç›¸ä¼¼åº¦å¹³å‡å€¼ä¸º1.32ã€‚ç”±PaECTERä»ä¸“åˆ©æ–‡æœ¬ç”Ÿæˆçš„æ•°å€¼è¡¨ç¤ºå¯ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€è¿½è¸ªçŸ¥è¯†æµæˆ–è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€‚è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢å¯¹äºå‘æ˜å®¶å’Œä¸“åˆ©å®¡æŸ¥å‘˜çš„ç°æœ‰æŠ€æœ¯æœç´¢æ¥è¯´å°¤å…¶é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.19411v2">PDF</a> 8 pages, 3 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>PaECTERæ˜¯ä¸€ç§é’ˆå¯¹ä¸“åˆ©çš„å¼€æºæ–‡æ¡£çº§åˆ«ç¼–ç å™¨ã€‚é€šè¿‡åˆ©ç”¨å®¡æŸ¥å‘˜æ·»åŠ çš„å¼•æ–‡ä¿¡æ¯å¯¹BERT for Patentsè¿›è¡Œå¾®è°ƒï¼Œç”Ÿæˆä¸“åˆ©æ–‡æ¡£çš„æ•°å€¼è¡¨ç¤ºã€‚åœ¨ä¸“åˆ©ç›¸ä¼¼æ€§ä»»åŠ¡ä¸­ï¼ŒPaECTERçš„è¡¨ç°ä¼˜äºå½“å‰ä¸“åˆ©é¢†åŸŸçš„æœ€å…ˆè¿›æ¨¡å‹ã€‚å®ƒèƒ½å¤Ÿåœ¨ä¸“åˆ©å¼•æ–‡é¢„æµ‹æµ‹è¯•æ•°æ®é›†ä¸Šè¶…è¶Šä¸“åˆ©ç‰¹å®šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚BERT for Patentsï¼‰å’Œé€šç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆå¦‚E5ã€GTEå’ŒBGEï¼‰ï¼Œåœ¨ä¸åŒæ’åè¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚PaECTERé¢„æµ‹çš„è‡³å°‘ä¸€ä¸ªæœ€ç›¸ä¼¼ä¸“åˆ©çš„å¹³å‡æ’åä¸º1.32ï¼Œä¸25ä¸ªä¸ç›¸å…³ä¸“åˆ©ç›¸æ¯”ã€‚ç”±PaECTERä»ä¸“åˆ©æ–‡æœ¬ç”Ÿæˆçš„æ•°å€¼è¡¨ç¤ºå¯ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€è¿½è¸ªçŸ¥è¯†æµæˆ–è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€‚è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢å¯¹äºå‘æ˜äººå’Œä¸“åˆ©å®¡æŸ¥å‘˜çš„å…ˆå‰æŠ€æœ¯æœç´¢å°¤ä¸ºé‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PaECTERæ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸“åˆ©çš„å¼€æºæ–‡æ¡£çº§åˆ«ç¼–ç å™¨ã€‚</li>
<li>é€šè¿‡å®¡æŸ¥å‘˜æ·»åŠ çš„å¼•æ–‡ä¿¡æ¯å¯¹BERTè¿›è¡Œå¾®è°ƒï¼Œç”Ÿæˆä¸“åˆ©æ–‡æ¡£çš„æ•°å€¼è¡¨ç¤ºã€‚</li>
<li>PaECTERåœ¨ä¸“åˆ©ç›¸ä¼¼æ€§ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>PaECTERåœ¨ä¸“åˆ©å¼•æ–‡é¢„æµ‹æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒåŒ…æ‹¬ä¸“åˆ©ç‰¹å®šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å’Œé€šç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚</li>
<li>PaECTERèƒ½å¤Ÿé¢„æµ‹è‡³å°‘ä¸€ä¸ªæœ€ç›¸ä¼¼ä¸“åˆ©çš„å¹³å‡æ’åä¸º1.32ã€‚</li>
<li>PaECTERç”Ÿæˆçš„æ•°å€¼è¡¨ç¤ºå¯ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€è¿½è¸ªçŸ¥è¯†æµå’Œè¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.19411">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8f7df05397f26ed416962b99326fb799~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028956&auth_key=1760028956-0-0-145c71ac50be31dd68148632c0c0ba2e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4389f31b4dcd8d459f6911114ae20e22~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028963&auth_key=1760028963-0-0-c9d87fb3e634a87962b4618585f022a9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b8cf70ddb1e1e7b79f7df242d17ad78~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028969&auth_key=1760028969-0-0-14a2c17c4315cdf94d823c18c1f1d939&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8a0825a515f273f6a03e93fe4916ca1a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028976&auth_key=1760028976-0-0-b49b263823ff8fba295c16a51067a88a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-457d8203f475f19b472783edf2c2c074~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028982&auth_key=1760028982-0-0-3b734765e3d73d1f9b2f856fb57f9d84&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-541eee299be9eb985b90f72a6bb9cf18~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028989&auth_key=1760028989-0-0-28eb30954b69b16ecd3800086423b88e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-06/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-06/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-06/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-247a0b8c6ce3d0ad2feaa6dfd33a5440~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028995&auth_key=1760028995-0-0-f18537dd2b7a72360c5bfd86771e16e6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-06  Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level   Preference Optimization
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-06/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-4cb31ae91ffa917d13a3b2f3319f48e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760028160&auth_key=1760028160-0-0-251f60f2f8ecbe87122d64049ef1f9bc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-06  Octax Accelerated CHIP-8 Arcade Environments for Reinforcement Learning   in JAX
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30341.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
