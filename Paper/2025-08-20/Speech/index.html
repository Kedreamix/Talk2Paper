<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-20  Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with   Transformer-Based Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-30e5c45217a2c470230c1e3173c6aefe.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    23 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-20-æ›´æ–°"><a href="#2025-08-20-æ›´æ–°" class="headerlink" title="2025-08-20 æ›´æ–°"></a>2025-08-20 æ›´æ–°</h1><h2 id="Arabic-ASR-on-the-SADA-Large-Scale-Arabic-Speech-Corpus-with-Transformer-Based-Models"><a href="#Arabic-ASR-on-the-SADA-Large-Scale-Arabic-Speech-Corpus-with-Transformer-Based-Models" class="headerlink" title="Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with   Transformer-Based Models"></a>Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with   Transformer-Based Models</h2><p><strong>Authors:Branislav Gerazov, Marcello Politi, SÃ©bastien BratiÃ¨res</strong></p>
<p>We explore the performance of several state-of-the-art automatic speech recognition (ASR) models on a large-scale Arabic speech dataset, the SADA (Saudi Audio Dataset for Arabic), which contains 668 hours of high-quality audio from Saudi television shows. The dataset includes multiple dialects and environments, specifically a noisy subset that makes it particularly challenging for ASR. We evaluate the performance of the models on the SADA test set, and we explore the impact of fine-tuning, language models, as well as noise and denoising on their performance. We find that the best performing model is the MMS 1B model finetuned on SADA with a 4-gram language model that achieves a WER of 40.9% and a CER of 17.6% on the SADA test clean set. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹å¤šä¸ªæœ€å…ˆè¿›çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹åœ¨å¤§å‹é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³æ•°æ®é›†SADAï¼ˆæ²™ç‰¹é˜¿æ‹‰ä¼¯é˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†ï¼‰ä¸Šçš„è¡¨ç°è¿›è¡Œäº†æ¢ç´¢ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªæ²™ç‰¹é˜¿æ‹‰ä¼¯ç”µè§†å‰§çš„668å°æ—¶é«˜è´¨é‡éŸ³é¢‘ã€‚è¯¥æ•°æ®é›†åŒ…å«å¤šç§æ–¹è¨€å’Œç¯å¢ƒï¼Œç‰¹åˆ«æ˜¯ä¸€ä¸ªå˜ˆæ‚çš„å­é›†ï¼Œè¿™ä½¿å¾—è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬åœ¨SADAæµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ¢è®¨äº†å¾®è°ƒã€è¯­è¨€æ¨¡å‹ä»¥åŠå™ªå£°å’Œé™å™ªå¯¹æ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬å‘ç°è¡¨ç°æœ€å¥½çš„æ¨¡å‹æ˜¯åœ¨SADAä¸Šå¾®è°ƒè¿‡çš„MMS 1Bæ¨¡å‹ï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ª4å…ƒè¯­è¨€æ¨¡å‹ï¼Œåœ¨SADAæµ‹è¯•é›†å¹²å‡€é›†ä¸Šå®ç°äº†è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä¸º40.9%ï¼Œå­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ä¸º17.6%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12968v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæˆ‘ä»¬å¯¹å¤šä¸ªå‰æ²¿çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹åœ¨å¤§å‹é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³æ•°æ®é›†SADAä¸Šçš„è¡¨ç°è¿›è¡Œäº†æ¢ç´¢ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªæ²™ç‰¹ç”µè§†èŠ‚ç›®çš„é«˜è´¨é‡éŸ³é¢‘ï¼Œæ—¶é•¿668å°æ—¶ï¼ŒåŒ…å«å¤šç§æ–¹è¨€å’Œç¯å¢ƒï¼Œå°¤å…¶æ˜¯å™ªéŸ³å­é›†ï¼Œå¯¹ASRæ¥è¯´æå…·æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬åœ¨SADAæµ‹è¯•é›†ä¸Šè¯„ä¼°äº†è¿™äº›æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶æ¢è®¨äº†å¾®è°ƒã€è¯­è¨€æ¨¡å‹ä»¥åŠå™ªå£°å’Œå»å™ªå¯¹æ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨SADAçš„æ¸…æ´é›†ä¸Šï¼Œç»SADAå¾®è°ƒè¿‡çš„MMS 1Bæ¨¡å‹é…åˆ4-gramè¯­è¨€æ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œå­—é”™è¯¯ç‡ï¼ˆWERï¼‰è¾¾åˆ°40.9%ï¼Œå­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ä¸º17.6%ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è®ºæ–‡ç ”ç©¶äº†å¤šä¸ªå‰æ²¿è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹åœ¨æ²™ç‰¹é˜¿æ‹‰ä¼¯éŸ³é¢‘æ•°æ®é›†ï¼ˆSADAï¼‰ä¸Šçš„è¡¨ç°ã€‚</li>
<li>SADAæ•°æ®é›†åŒ…å«å¤šç§æ–¹è¨€å’Œç¯å¢ƒï¼Œå¯¹ASRç³»ç»Ÿæ¥è¯´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</li>
<li>ç ”ç©¶è€…è¯„ä¼°äº†æ¨¡å‹åœ¨SADAæµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>æœ€å¥½çš„æ¨¡å‹æ˜¯MMS 1Bæ¨¡å‹ï¼Œç»è¿‡åœ¨SADAæ•°æ®é›†ä¸Šçš„å¾®è°ƒï¼Œå¹¶é…åˆä½¿ç”¨4-gramè¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¯¥æœ€ä½³æ¨¡å‹åœ¨SADAæ¸…æ´æµ‹è¯•é›†ä¸Šå®ç°äº†è¾ƒä½çš„å­—é”™è¯¯ç‡ï¼ˆWERï¼‰å’Œå­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ã€‚</li>
<li>ç ”ç©¶å‘ç°å™ªå£°å’Œå»å™ªå¯¹ASRæ¨¡å‹æ€§èƒ½æœ‰å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12968">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-efb218af5ef688b1277eb241015d160b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-589048573219f060235a44c47863da62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6133da511eae3b6d1f3d71d0fd79343.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CarelessWhisper-Turning-Whisper-into-a-Causal-Streaming-Model"><a href="#CarelessWhisper-Turning-Whisper-into-a-Causal-Streaming-Model" class="headerlink" title="CarelessWhisper: Turning Whisper into a Causal Streaming Model"></a>CarelessWhisper: Turning Whisper into a Causal Streaming Model</h2><p><strong>Authors:Tomer Krichli, Bhiksha Raj, Joseph Keshet</strong></p>
<p>Automatic Speech Recognition (ASR) has seen remarkable progress, with models like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA) performance in offline transcription. However, these models are not designed for streaming (online or real-time) transcription, due to limitations in their architecture and training methodology. We propose a method to turn the transformer encoder-decoder model into a low-latency streaming model that is careless about future context. We present an analysis explaining why it is not straightforward to convert an encoder-decoder transformer to a low-latency streaming model. Our proposed method modifies the existing (non-causal) encoder to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated inference mechanism that utilizes the fine-tune causal encoder and decoder to yield greedy and beam-search decoding, and is shown to be locally optimal. Experiments on low-latency chunk sizes (less than 300 msec) show that our fine-tuned model outperforms existing non-fine-tuned streaming approaches in most cases, while using a lower complexity. Additionally, we observe that our training process yields better alignment, enabling a simple method for extracting word-level timestamps. We release our training and inference code, along with the fine-tuned models, to support further research and development in streaming ASR. </p>
<blockquote>
<p>è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä¾‹å¦‚OpenAIwhisperå’ŒNVIDIAcanaryç­‰æ¨¡å‹åœ¨ç¦»çº¿è½¬å½•æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¹¶ä¸é€‚ç”¨äºæµå¼ï¼ˆåœ¨çº¿æˆ–å®æ—¶ï¼‰è½¬å½•ï¼Œè¿™æ˜¯ç”±äºå®ƒä»¬çš„æ¶æ„å’Œè®­ç»ƒæ–¹æ³•çš„å±€é™æ€§æ‰€å¯¼è‡´çš„ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†è½¬æ¢å™¨ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è½¬åŒ–ä¸ºä½å»¶è¿Ÿæµå¼æ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ¨¡å‹ä¸å…³å¿ƒæœªæ¥ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬è¿›è¡Œäº†åˆ†æï¼Œè§£é‡Šäº†ä¸ºä»€ä¹ˆå°†ç¼–ç å™¨-è§£ç å™¨è½¬æ¢å™¨è½¬æ¢ä¸ºä½å»¶è¿Ÿæµå¼æ¨¡å‹å¹¶ä¸ç®€å•ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•é€šè¿‡å°†ç°æœ‰ï¼ˆéå› æœï¼‰ç¼–ç å™¨å¾®è°ƒä¸ºå› æœç¼–ç å™¨ï¼ŒåŒæ—¶åˆ©ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’Œå¼±å¯¹é½æ•°æ®é›†å¯¹ç¼–ç å™¨å’Œè§£ç å™¨è¿›è¡Œå¾®è°ƒã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›´æ–°çš„æ¨ç†æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åˆ©ç”¨å¾®è°ƒçš„å› æœç¼–ç å™¨å’Œè§£ç å™¨æ¥äº§ç”Ÿè´ªå¿ƒå’Œè§£ç æŸæœç´¢ï¼Œå¹¶è¢«è®¤ä¸ºæ˜¯å±€éƒ¨æœ€ä¼˜çš„ã€‚åœ¨ä½å»¶è¿Ÿå—å¤§å°ï¼ˆå°äº300æ¯«ç§’ï¼‰çš„å®éªŒä¸­ï¼Œè¡¨æ˜æˆ‘ä»¬çš„å¾®è°ƒæ¨¡å‹åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½ä¼˜äºç°æœ‰çš„æœªå¾®è°ƒæµå¼æ–¹æ³•ï¼ŒåŒæ—¶ä½¿ç”¨æ›´ä½çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹äº§ç”Ÿäº†æ›´å¥½çš„å¯¹é½æ•ˆæœï¼Œè¿™ä¸ºå®ç°ç®€å•çš„æå–è¯çº§æ—¶é—´æˆ³æ–¹æ³•æä¾›äº†å¯èƒ½ã€‚æˆ‘ä»¬å‘å¸ƒæˆ‘ä»¬çš„è®­ç»ƒå’Œæ¨ç†ä»£ç ä»¥åŠå¾®è°ƒæ¨¡å‹ï¼Œä»¥æ”¯æŒæµå¼ASRçš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12301v1">PDF</a> 17 pages, 7 Figures, This work has been submitted to the IEEE for   possible publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æµå¼è½¬ç æ¨¡å‹çš„ç ”ç©¶ã€‚æ–‡ç« æŒ‡å‡ºï¼Œè™½ç„¶OpenAI Whisperå’ŒNVIDIA Canaryç­‰æ¨¡å‹åœ¨ç¦»çº¿è½¬å½•æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½†å®ƒä»¬å¹¶ä¸é€‚ç”¨äºæµå¼è½¬å½•ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§å°†è½¬æ¢å™¨ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è½¬æ¢ä¸ºä½å»¶è¿Ÿæµå¼æ¨¡å‹çš„æ–¹æ³•ï¼Œå¹¶è¯¦ç»†è§£é‡Šäº†è½¬æ¢çš„éš¾ç‚¹ã€‚é€šè¿‡å¾®è°ƒç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå¹¶ä½¿ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’Œå¼±å¯¹é½æ•°æ®é›†ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„å› æœç¼–ç å™¨ã€‚æ›´æ–°çš„æ¨ç†æœºåˆ¶åˆ©ç”¨ç²¾ç»†è°ƒæ•´çš„å› æœç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå®ç°è´ªå©ªå’Œé›†æŸæœç´¢è§£ç ï¼Œå¹¶è¯æ˜å…¶å±€éƒ¨æœ€ä¼˜ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä½å£°å»¶è¿Ÿå—å¤§å°ä¸‹ï¼Œç²¾ç»†è°ƒæ•´åçš„æ¨¡å‹åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºç°æœ‰çš„éç²¾ç»†è°ƒæ•´æµå¼æ–¹æ³•ï¼ŒåŒæ—¶é™ä½äº†å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œè¯¥è®­ç»ƒè¿‡ç¨‹è¿˜äº§ç”Ÿäº†æ›´å¥½çš„å¯¹é½æ•ˆæœï¼Œä¸ºæå–å•è¯çº§æ—¶é—´æˆ³æä¾›äº†ä¸€ç§ç®€å•æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« æŒ‡å‡ºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„åœ¨çº¿æˆ–å®æ—¶è½¬å½•ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå°½ç®¡å·²æœ‰æ¨¡å‹åœ¨ç¦»çº¿è½¬å½•æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>æ–‡ç« æå‡ºäº†ä¸€ç§å°†è½¬æ¢å™¨ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹è½¬æ¢ä¸ºä½å»¶è¿Ÿæµå¼æ¨¡å‹çš„æ–¹æ³•ã€‚</li>
<li>è½¬æ¢çš„éš¾ç‚¹åœ¨äºå¦‚ä½•å°†æ¨¡å‹çš„æ¶æ„å’Œè®­ç»ƒæ–¹æ³•è¿›è¡Œè°ƒæ•´ä»¥é€‚åº”æµå¼å¤„ç†çš„éœ€æ±‚ã€‚</li>
<li>é€šè¿‡å¯¹ç¼–ç å™¨å’Œè§£ç å™¨çš„å¾®è°ƒï¼Œä»¥åŠä½¿ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’Œå¼±å¯¹é½æ•°æ®é›†ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å› æœç¼–ç å™¨ã€‚</li>
<li>æ›´æ–°åçš„æ¨ç†æœºåˆ¶å¯ä»¥å®ç°è´ªå©ªå’Œé›†æŸæœç´¢è§£ç ï¼Œå¹¶å…·æœ‰å±€éƒ¨æœ€ä¼˜æ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä½å»¶è¿Ÿæ¡ä»¶ä¸‹ï¼Œç²¾ç»†è°ƒæ•´åçš„æ¨¡å‹æ€§èƒ½ä¼˜äºå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ï¼Œä¸”è®¡ç®—å¤æ‚åº¦è¾ƒä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0666f0ebb8e0fae15e8b87792f92656d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32b9c1cc8fdf256726ab8c1857d6626e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-30e5c45217a2c470230c1e3173c6aefe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a8207d4869d4728fabd1013e9a21bab.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Exploring-Self-Supervised-Audio-Models-for-Generalized-Anomalous-Sound-Detection"><a href="#Exploring-Self-Supervised-Audio-Models-for-Generalized-Anomalous-Sound-Detection" class="headerlink" title="Exploring Self-Supervised Audio Models for Generalized Anomalous Sound   Detection"></a>Exploring Self-Supervised Audio Models for Generalized Anomalous Sound   Detection</h2><p><strong>Authors:Bing Han, Anbai Jiang, Xinhu Zheng, Wei-Qiang Zhang, Jia Liu, Pingyi Fan, Yanmin Qian</strong></p>
<p>Machine anomalous sound detection (ASD) is a valuable technique across various applications. However, its generalization performance is often limited due to challenges in data collection and the complexity of acoustic environments. Inspired by the success of large pre-trained models in numerous fields, this paper introduces a robust ASD model that leverages self-supervised pre-trained models trained on large-scale speech and audio datasets. Although there are inconsistencies between the pre-training datasets and the ASD task, our findings indicate that pre-training still provides substantial benefits for ASD. To mitigate overfitting and retain learned knowledge when fine-tuning with limited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an alternative to full fine-tuning. Additionally, we propose a Machine-aware Group Adapter module, which enables the model to capture differences between various machines within a unified framework, thereby enhancing the generalization performance of ASD systems. To address the challenge of missing attribute labels, we design a novel objective function that dynamically clusters unattributed data using vector quantization and optimizes through a dual-level contrastive learning loss. The proposed methods are evaluated on all benchmark datasets, including the DCASE 2020-2024 five ASD challenges, and the experimental results show significant improvements of our new approach and demonstrate the effectiveness of our proposed strategies. </p>
<blockquote>
<p>æœºå™¨å¼‚å¸¸å£°éŸ³æ£€æµ‹ï¼ˆASDï¼‰åœ¨å¤šç§åº”ç”¨ä¸­æ˜¯ä¸€é¡¹æœ‰ä»·å€¼çš„æŠ€æœ¯ã€‚ç„¶è€Œï¼Œç”±äºå…¶æ•°æ®æ”¶é›†çš„æŒ‘æˆ˜å’Œå£°éŸ³ç¯å¢ƒçš„å¤æ‚æ€§ï¼Œå…¶æ³›åŒ–æ€§èƒ½é€šå¸¸å—åˆ°é™åˆ¶ã€‚å—å¤§å‹é¢„è®­ç»ƒæ¨¡å‹åœ¨ä¼—å¤šé¢†åŸŸæˆåŠŸçš„å¯å‘ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªç¨³å¥çš„ASDæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨åœ¨å¤§å‹è¯­éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†ä¸Šè®­ç»ƒçš„è‡ªæˆ‘ç›‘ç£é¢„è®­ç»ƒæ¨¡å‹ã€‚å°½ç®¡é¢„è®­ç»ƒæ•°æ®é›†ä¸ASDä»»åŠ¡ä¹‹é—´å­˜åœ¨ä¸ä¸€è‡´ï¼Œä½†æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé¢„è®­ç»ƒä»ç„¶å¯¹ASDæä¾›é‡å¤§ç›Šå¤„ã€‚ä¸ºäº†ç¼“è§£è¿‡åº¦æ‹Ÿåˆé—®é¢˜å¹¶åœ¨ä½¿ç”¨æœ‰é™æ•°æ®è¿›è¡Œå¾®è°ƒæ—¶ä¿ç•™æ‰€å­¦çŸ¥è¯†ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å…¨è¿æ¥ä½ç§©é€‚é…ï¼ˆLoRAï¼‰ä½œä¸ºå…¨å¾®è°ƒçš„ä¸€ç§æ›¿ä»£æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†æœºå™¨æ„ŸçŸ¥ç»„é€‚é…å™¨æ¨¡å—ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ç»Ÿä¸€æ¡†æ¶å†…æ•æ‰å„ç§æœºå™¨ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæé«˜ASDç³»ç»Ÿçš„æ³›åŒ–æ€§èƒ½ã€‚ä¸ºäº†è§£å†³ç¼ºå¤±å±æ€§æ ‡ç­¾çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°çš„ç›®æ ‡å‡½æ•°ï¼Œè¯¥å‡½æ•°é€šè¿‡å‘é‡é‡åŒ–åŠ¨æ€èšç±»æœªæ ‡è®°æ•°æ®ï¼Œå¹¶é€šè¿‡åŒé‡å¯¹æ¯”å­¦ä¹ æŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨æ‰€æœ‰åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬DCASE 2020-2024äº”ä¸ªASDæŒ‘æˆ˜ï¼Œå®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–°æ–¹æ³•å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œå¹¶è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12230v1">PDF</a> Accepted by TASLP. 15 pages, 7 figures;</p>
<p><strong>Summary</strong>ï¼šæœºå™¨å¼‚å¸¸å£°éŸ³æ£€æµ‹ï¼ˆASDï¼‰æ˜¯ä¸€é¡¹åœ¨å¤šé¢†åŸŸå…·æœ‰åº”ç”¨ä»·å€¼çš„æ£€æµ‹æŠ€æœ¯ã€‚æœ¬æ–‡é€šè¿‡å€Ÿé‰´é¢„è®­ç»ƒæ¨¡å‹åœ¨å…¶ä»–é¢†åŸŸçš„æˆåŠŸç»éªŒï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºå¤§è§„æ¨¡è¯­éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†çš„é¢„è®­ç»ƒASDæ¨¡å‹ã€‚é’ˆå¯¹é¢„è®­ç»ƒæ•°æ®é›†ä¸ASDä»»åŠ¡é—´çš„ä¸ä¸€è‡´æ€§ï¼Œç ”ç©¶å‘ç°é¢„è®­ç»ƒä»ä¸ºASDå¸¦æ¥å®è´¨æ•ˆç›Šã€‚ä¸ºç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜å¹¶åœ¨æœ‰é™æ•°æ®ä¸Šä¿ç•™å­¦ä¹ åˆ°çš„çŸ¥è¯†ï¼Œæœ¬æ–‡æ¢ç´¢äº†å…¨è¿æ¥ä½ç§©é€‚é…ï¼ˆLoRAï¼‰ä½œä¸ºä¼ ç»Ÿå¾®è°ƒçš„æ›¿ä»£æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†æœºå™¨æ„ŸçŸ¥ç»„é€‚é…å™¨æ¨¡å—ï¼Œèƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…æ•æ‰ä¸åŒæœºå™¨ä¹‹é—´çš„å·®å¼‚ï¼Œæé«˜äº†ASDç³»ç»Ÿçš„æ³›åŒ–æ€§èƒ½ã€‚é’ˆå¯¹ç¼ºå°‘å±æ€§æ ‡ç­¾çš„æŒ‘æˆ˜ï¼Œè®¾è®¡äº†ä¸€ç§æ–°çš„ç›®æ ‡å‡½æ•°ï¼Œé€šè¿‡å‘é‡é‡åŒ–å’ŒåŒå±‚æ¬¡å¯¹æ¯”å­¦ä¹ æŸå¤±æ¥åŠ¨æ€èšç±»æ— å±æ€§æ•°æ®å¹¶è¿›è¡Œä¼˜åŒ–ã€‚åœ¨DCASE 2020-2024äº”ä¸ªASDæŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†æ£€æµ‹æ€§èƒ½ï¼ŒéªŒè¯äº†æ‰€æç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>é¢„è®­ç»ƒæ¨¡å‹å¯¹äºæœºå™¨å¼‚å¸¸å£°éŸ³æ£€æµ‹ï¼ˆASDï¼‰æœ‰å®è´¨æ€§ç›Šå¤„ï¼Œå³ä½¿é¢„è®­ç»ƒæ•°æ®é›†ä¸ASDä»»åŠ¡å­˜åœ¨ä¸ä¸€è‡´æ€§ã€‚</li>
<li>é‡‡ç”¨å…¨è¿æ¥ä½ç§©é€‚é…ï¼ˆLoRAï¼‰èƒ½æœ‰æ•ˆç¼“è§£ASDæ¨¡å‹è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶åœ¨æœ‰é™æ•°æ®ä¸Šä¿ç•™å­¦ä¹ åˆ°çš„çŸ¥è¯†ã€‚</li>
<li>æå‡ºçš„æœºå™¨æ„ŸçŸ¥ç»„é€‚é…å™¨æ¨¡å—èƒ½å¤Ÿæ•æ‰ä¸åŒæœºå™¨ä¹‹é—´çš„å·®å¼‚ï¼Œæé«˜äº†ASDç³»ç»Ÿçš„æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>é’ˆå¯¹ç¼ºå°‘å±æ€§æ ‡ç­¾çš„æŒ‘æˆ˜ï¼Œé€šè¿‡è®¾è®¡æ–°çš„ç›®æ ‡å‡½æ•°å®ç°äº†æ— å±æ€§æ•°æ®çš„åŠ¨æ€èšç±»ã€‚</li>
<li>é‡‡ç”¨å‘é‡é‡åŒ–å’ŒåŒå±‚æ¬¡å¯¹æ¯”å­¦ä¹ æŸå¤±è¿›è¡Œä¼˜åŒ–ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>åœ¨DCASE 2020-2024äº”ä¸ªASDæŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†æ£€æµ‹æ•ˆæœã€‚</li>
<li>æœ¬æ–‡ç­–ç•¥çš„æœ‰æ•ˆæ€§å¾—åˆ°äº†éªŒè¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12230">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a0542758bccb57972f3635accca7756a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfff545015ee693a44f88a9a6a3f3e72.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b18f9334bbdbd93cc1e7d8b2036464a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5de30dcccf57a899740665e76bdd0ea8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1297fa74e46b73eddd1c015d51f5ebe6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts"><a href="#FNH-TTS-A-Fast-Natural-and-Human-Like-Speech-Synthesis-System-with-advanced-prosodic-modeling-based-on-Mixture-of-Experts" class="headerlink" title="FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts"></a>FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with   advanced prosodic modeling based on Mixture of Experts</h2><p><strong>Authors:Qingliang Meng, Luogeng Xiong, Wei Liang, Limei Yu, Huizhi Liang, Tian Li</strong></p>
<p>Achieving natural and human-like speech synthesis with low inference costs remains a major challenge in speech synthesis research. This study focuses on human prosodic patterns and synthesized spectrum harmony, addressing the challenges of prosody modeling and artifact issues in non-autoregressive models. To enhance prosody modeling and synthesis quality, we introduce a new Duration Predictor based on the Mixture of Experts alongside a new Vocoder with two advanced multi-scale discriminators. We integrated the these new modules into the VITS system, forming our FNH-TTS system. Our experiments on LJSpeech, VCTK, and LibriTTS demonstrate the systemâ€™s superiority in synthesis quality, phoneme duration prediction, Vocoder results, and synthesis speed. Our prosody visualization results show that FNH-TTS produces duration predictions that more closely align with natural human beings than other systems. </p>
<blockquote>
<p>åœ¨è¯­éŸ³åˆæˆç ”ç©¶ä¸­ï¼Œå®ç°ä½æˆæœ¬ã€è‡ªç„¶ã€æ‹ŸäººåŒ–çš„è¯­éŸ³åˆæˆä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶å…³æ³¨äººç±»è¯­è°ƒæ¨¡å¼å’Œåˆæˆé¢‘è°±å’Œè°æ€§ï¼Œè§£å†³è¯­è°ƒå»ºæ¨¡å’Œéè‡ªå›å½’æ¨¡å‹ä¸­çš„ä¼ªå½±é—®é¢˜çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å¢å¼ºè¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºä¸“å®¶æ··åˆçš„æ–°æŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œä»¥åŠä¸€ç§å…·æœ‰ä¸¤ä¸ªå…ˆè¿›å¤šå°ºåº¦é‰´åˆ«å™¨çš„æ–°Vocoderã€‚æˆ‘ä»¬å°†è¿™äº›æ–°æ¨¡å—é›†æˆåˆ°VITSç³»ç»Ÿä¸­ï¼Œå½¢æˆäº†æˆ‘ä»¬çš„FNH-TTSç³»ç»Ÿã€‚æˆ‘ä»¬åœ¨LJSpeechã€VCTKå’ŒLibriTTSä¸Šçš„å®éªŒè¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹ã€Vocoderç»“æœå’Œåˆæˆé€Ÿåº¦ä¸Šçš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬çš„è¯­è°ƒå¯è§†åŒ–ç»“æœæ˜¾ç¤ºï¼ŒFNH-TTSäº§ç”Ÿçš„æŒç»­æ—¶é—´é¢„æµ‹ä¸å…¶ä»–ç³»ç»Ÿç›¸æ¯”ï¼Œæ›´æ¥è¿‘è‡ªç„¶äººç±»çš„æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12001v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶å…³æ³¨äººç±»è¯­è°ƒæ¨¡å¼å’Œåˆæˆé¢‘è°±å’Œè°æ€§ï¼Œæ—¨åœ¨è§£å†³éè‡ªå›å½’æ¨¡å‹ä¸­çš„è¯­è°ƒå»ºæ¨¡å’Œä¼ªè¿¹é—®é¢˜ã€‚é€šè¿‡å¼•å…¥åŸºäºä¸“å®¶æ··åˆçš„æ–°æŒç»­æ—¶é—´é¢„æµ‹å™¨å’Œå¸¦æœ‰ä¸¤ä¸ªå…ˆè¿›å¤šå°ºåº¦é‰´åˆ«å™¨çš„æ–°çš„å£°ç å™¨ï¼Œæé«˜äº†è¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ã€‚é›†æˆåˆ°æ–°VITSç³»ç»Ÿä¸­ï¼Œå½¢æˆäº†æˆ‘ä»¬çš„FNH-TTSç³»ç»Ÿã€‚å®éªŒè¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹ã€å£°ç å™¨ç»“æœå’Œåˆæˆé€Ÿåº¦æ–¹é¢å‡ä¼˜äºå…¶ä»–ç³»ç»Ÿï¼Œäº§ç”Ÿçš„è¯­è°ƒå¯è§†åŒ–ç»“æœæ›´æ¥è¿‘è‡ªç„¶äººç±»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨è‡ªç„¶å’Œäººç±»åŒ–çš„è¯­éŸ³åˆæˆï¼ŒæŒ‘æˆ˜åœ¨äºå®ç°ä½æ¨ç†æˆæœ¬çš„è¯­éŸ³åˆæˆã€‚</li>
<li>ç ”ç©¶é‡ç‚¹ä¹‹ä¸€æ˜¯ç†è§£å’Œæ¨¡æ‹Ÿäººç±»è¯­è°ƒæ¨¡å¼ä»¥åŠåˆæˆé¢‘è°±å’Œè°æ€§ã€‚</li>
<li>ä¸ºäº†æé«˜è¯­è°ƒå»ºæ¨¡å’Œåˆæˆè´¨é‡ï¼Œå¼•å…¥äº†æ–°çš„æŒç»­æ—¶é—´é¢„æµ‹å™¨å’Œå£°ç å™¨ã€‚</li>
<li>æ–°çš„æ¨¡å—æ˜¯åŸºäºä¸“å®¶æ··åˆå’Œå…ˆè¿›çš„å¤šå°ºåº¦é‰´åˆ«å™¨è®¾è®¡çš„ã€‚</li>
<li>è¿™äº›æ–°æ¨¡å—è¢«é›†æˆåˆ°VITSç³»ç»Ÿä¸­ï¼Œå½¢æˆäº†FNH-TTSç³»ç»Ÿã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒFNH-TTSç³»ç»Ÿåœ¨åˆæˆè´¨é‡ã€éŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹ã€å£°ç å™¨ç»“æœå’Œåˆæˆé€Ÿåº¦ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12001">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-367770a9fcc7e391c1c05254d8668432.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07b87d647c08768811ba838a389ecb82.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb8293187e68dbe3b98515438382d6fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2765146d8e9ba422ab874481d39df87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de212c5e25c77b537dc513df982ccb9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aabfb140e32162546fd1d2ea0b491f08.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TeleAntiFraud-28k-An-Audio-Text-Slow-Thinking-Dataset-for-Telecom-Fraud-Detection"><a href="#TeleAntiFraud-28k-An-Audio-Text-Slow-Thinking-Dataset-for-Telecom-Fraud-Detection" class="headerlink" title="TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud   Detection"></a>TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud   Detection</h2><p><strong>Authors:Zhiming Ma, Peidong Wang, Minhua Huang, Jingpeng Wang, Kai Wu, Xiangzhao Lv, Yachun Pang, Yin Yang, Wenjie Tang, Yuchen Kang</strong></p>
<p>The detection of telecom fraud faces significant challenges due to the lack of high-quality multimodal training data that integrates audio signals with reasoning-oriented textual analysis. To address this gap, we present TeleAntiFraud-28k, the first open-source audio-text slow-thinking dataset specifically designed for automated telecom fraud analysis. Our dataset is constructed through three strategies: (1) Privacy-preserved text-truth sample generation using automatically speech recognition (ASR)-transcribed call recordings (with anonymized original audio), ensuring real-world consistency through text-to-speech (TTS) model regeneration; (2) Semantic enhancement via large language model (LLM)-based self-instruction sampling on authentic ASR outputs to expand scenario coverage; (3) Multi-agent adversarial synthesis that simulates emerging fraud tactics through predefined communication scenarios and fraud typologies. The generated dataset contains 28,511 rigorously processed speech-text pairs, complete with detailed annotations for fraud reasoning. The dataset is divided into three tasks: scenario classification, fraud detection, fraud type classification. Furthermore, we construct TeleAntiFraud-Bench, a standardized evaluation benchmark comprising proportionally sampled instances from the dataset, to facilitate systematic testing of model performance on telecom fraud detection tasks. We also contribute a production-optimized supervised fine-tuning (SFT) model trained on hybrid real&#x2F;synthetic data, while open-sourcing the data processing framework to enable community-driven dataset expansion. This work establishes a foundational framework for multimodal anti-fraud research while addressing critical challenges in data privacy and scenario diversity. The project will be released at <a target="_blank" rel="noopener" href="https://github.com/JimmyMa99/TeleAntiFraud">https://github.com/JimmyMa99/TeleAntiFraud</a>. </p>
<blockquote>
<p>ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ï¼Œè¿™æ˜¯ç”±äºç¼ºä¹é«˜è´¨é‡çš„å¤šæ¨¡å¼è®­ç»ƒæ•°æ®ï¼Œæ— æ³•å°†éŸ³é¢‘ä¿¡å·ä¸é¢å‘æ¨ç†çš„æ–‡æœ¬åˆ†æç›¸ç»“åˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†TeleAntiFraud-28kï¼Œè¿™æ˜¯ä¸“é—¨ä¸ºç”µä¿¡æ¬ºè¯ˆè‡ªåŠ¨åŒ–åˆ†æè®¾è®¡çš„ç¬¬ä¸€ä¸ªå¼€æºéŸ³é¢‘æ–‡æœ¬æ…¢æ€è€ƒæ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ•°æ®é›†é€šè¿‡ä»¥ä¸‹ä¸‰ç§ç­–ç•¥æ„å»ºï¼šï¼ˆ1ï¼‰ä½¿ç”¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰è½¬å½•çš„é€šè¯å½•éŸ³ç”Ÿæˆéšç§ä¿æŠ¤çš„æ–‡æœ¬çœŸå®æ ·æœ¬ï¼ˆå¸¦æœ‰åŒ¿ååŸå§‹éŸ³é¢‘ï¼‰ï¼Œå¹¶é€šè¿‡æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹å†ç”Ÿç¡®ä¿ç°å®ä¸€è‡´æ€§ï¼›ï¼ˆ2ï¼‰é€šè¿‡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªæˆ‘æŒ‡ä»¤é‡‡æ ·å¯¹çœŸå®çš„ASRè¾“å‡ºè¿›è¡Œè¯­ä¹‰å¢å¼ºï¼Œä»¥æ‰©å¤§åœºæ™¯è¦†ç›–ï¼›ï¼ˆ3ï¼‰æ¨¡æ‹Ÿæ–°å…´æ¬ºè¯ˆç­–ç•¥çš„å¤šä»£ç†å¯¹æŠ—åˆæˆé€šè¿‡é¢„è®¾çš„é€šä¿¡åœºæ™¯å’Œæ¬ºè¯ˆç±»å‹ã€‚ç”Ÿæˆçš„æ•°æ®é›†åŒ…å«ç»è¿‡ä¸¥æ ¼å¤„ç†çš„28511ä¸ªè¯­éŸ³æ–‡æœ¬å¯¹ï¼Œå¸¦æœ‰è¯¦ç»†çš„æ¬ºè¯ˆæ¨ç†æ³¨é‡Šã€‚æ•°æ®é›†åˆ†ä¸ºä¸‰ä¸ªä»»åŠ¡ï¼šåœºæ™¯åˆ†ç±»ã€æ¬ºè¯ˆæ£€æµ‹ã€æ¬ºè¯ˆç±»å‹åˆ†ç±»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†TeleAntiFraud-Benchï¼Œä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯„ä¼°åŸºå‡†ï¼ŒåŒ…å«ä»æ•°æ®é›†ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·çš„å®ä¾‹ï¼Œä»¥ä¿ƒè¿›ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹ä»»åŠ¡ä¸Šæ¨¡å‹æ€§èƒ½çš„ç³»ç»Ÿæµ‹è¯•ã€‚æˆ‘ä»¬è¿˜ä¸ºæ··åˆçœŸå®&#x2F;åˆæˆæ•°æ®è®­ç»ƒçš„ç”Ÿäº§ä¼˜åŒ–ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ¨¡å‹åšå‡ºäº†è´¡çŒ®ï¼ŒåŒæ—¶å¼€æºæ•°æ®å¤„ç†æ¡†æ¶ä»¥æ¨åŠ¨ç¤¾åŒºé©±åŠ¨çš„æ•°æ®é›†æ‰©å±•ã€‚è¿™é¡¹å·¥ä½œä¸ºè·¨æ¨¡å¼åæ¬ºè¯ˆç ”ç©¶å»ºç«‹äº†åŸºç¡€æ¡†æ¶ï¼ŒåŒæ—¶è§£å†³äº†æ•°æ®éšç§å’Œåœºæ™¯å¤šæ ·æ€§æ–¹é¢çš„å…³é”®æŒ‘æˆ˜ã€‚è¯¥é¡¹ç›®å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/JimmyMa99/TeleAntiFraud">https://github.com/JimmyMa99/TeleAntiFraud</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.24115v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†é’ˆå¯¹ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹é¢†åŸŸæ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å¼€æ”¾æºä»£ç éŸ³é¢‘æ–‡æœ¬æ…¢æ€è€ƒæ•°æ®é›†TeleAntiFraud-28kã€‚è¯¥æ•°æ®é›†é€šè¿‡ä¸‰ç§ç­–ç•¥æ„å»ºï¼ŒåŒ…æ‹¬éšç§ä¿æŠ¤çš„æ–‡æœ¬çœŸå®æ ·æœ¬ç”Ÿæˆã€è¯­ä¹‰å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æŒ‡ä»¤é‡‡æ ·ä»¥åŠå¤šæ™ºèƒ½ä½“å¯¹æŠ—åˆæˆã€‚æ•°æ®é›†åŒ…å«ç»è¿‡ä¸¥æ ¼å¤„ç†çš„28,511ä¸ªè¯­éŸ³æ–‡æœ¬å¯¹ï¼Œå…·æœ‰è¯¦ç»†çš„æ¬ºè¯ˆæ¨ç†æ³¨é‡Šï¼Œåˆ†ä¸ºåœºæ™¯åˆ†ç±»ã€æ¬ºè¯ˆæ£€æµ‹å’Œæ¬ºè¯ˆç±»å‹åˆ†ç±»ä¸‰ä¸ªä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¿˜æ„å»ºäº†TeleAntiFraud-Benchæ ‡å‡†åŒ–è¯„ä¼°åŸºå‡†ï¼Œä»¥ç³»ç»ŸåŒ–æµ‹è¯•ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹ä»»åŠ¡çš„æ¨¡å‹æ€§èƒ½ã€‚æœ¬å·¥ä½œå¥ å®šäº†å¤šæ¨¡å¼æŠ—æ¬ºè¯ˆç ”ç©¶çš„åŸºç¡€æ¡†æ¶ï¼Œå¹¶è§£å†³äº†æ•°æ®éšç§å’Œåœºæ™¯å¤šæ ·æ€§ç­‰å…³é”®æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TeleAntiFraud-28kæ˜¯ä¸“é—¨ä¸ºç”µä¿¡æ¬ºè¯ˆåˆ†æè®¾è®¡çš„é¦–ä¸ªå¼€æ”¾æºä»£ç éŸ³é¢‘æ–‡æœ¬æ…¢æ€è€ƒæ•°æ®é›†ã€‚</li>
<li>æ•°æ®é›†é€šè¿‡éšç§ä¿æŠ¤çš„æ–‡æœ¬çœŸå®æ ·æœ¬ç”Ÿæˆã€è¯­ä¹‰å¢å¼ºåŠå¤šæ™ºèƒ½ä½“å¯¹æŠ—åˆæˆç­‰ä¸‰ç§ç­–ç•¥æ„å»ºã€‚</li>
<li>æ•°æ®é›†åŒ…å«28,511ä¸ªè¯­éŸ³æ–‡æœ¬å¯¹ï¼Œå…·å¤‡è¯¦ç»†çš„æ¬ºè¯ˆæ¨ç†æ³¨é‡Šï¼Œåˆ†ä¸ºä¸‰ä¸ªä»»åŠ¡ï¼šåœºæ™¯åˆ†ç±»ã€æ¬ºè¯ˆæ£€æµ‹ã€æ¬ºè¯ˆç±»å‹åˆ†ç±»ã€‚</li>
<li>å»ºç«‹äº†TeleAntiFraud-Benchè¯„ä¼°åŸºå‡†ï¼Œä»¥ä¾¿ç³»ç»ŸåŒ–æµ‹è¯•ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¯¥å·¥ä½œè§£å†³äº†ç”µä¿¡æ¬ºè¯ˆæ£€æµ‹ä¸­çš„æ•°æ®éšç§å’Œåœºæ™¯å¤šæ ·æ€§ç­‰å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>å…¬å¼€äº†æ•°æ®å¤„ç†æ¡†æ¶ï¼Œä¾¿äºç¤¾åŒºè¿›è¡Œæ•°æ®é›†æ‰©å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.24115">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8d3b36609c9ab9a09876a9207f9b7bce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60f7f634e6142e39dd5314cbbc507d2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-253fa7d6973f26d24d2c81d519deac01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e8ff0522c821f7aed3553f25af23621.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d40fdd3e5088aee9979809c6fd59961.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39efe517225eb10b12914a9414a2343d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d70a53acc5fdca0b1a3370df29b3b8e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3a36244324f42384a7e1ed1581aedb9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d4440e8a7f2508cb3f2258cf2944964e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="VisualSpeech-Enhancing-Prosody-Modeling-in-TTS-Using-Video"><a href="#VisualSpeech-Enhancing-Prosody-Modeling-in-TTS-Using-Video" class="headerlink" title="VisualSpeech: Enhancing Prosody Modeling in TTS Using Video"></a>VisualSpeech: Enhancing Prosody Modeling in TTS Using Video</h2><p><strong>Authors:Shumin Que, Anton Ragni</strong></p>
<p>Text-to-Speech (TTS) synthesis faces the inherent challenge of producing multiple speech outputs with varying prosody given a single text input. While previous research has addressed this by predicting prosodic information from both text and speech, additional contextual information, such as video, remains under-utilized despite being available in many applications. This paper investigates the potential of integrating visual context to enhance prosody prediction. We propose a novel model, VisualSpeech, which incorporates visual and textual information for improving prosody generation in TTS. Empirical results indicate that incorporating visual features improves prosodic modeling, enhancing the expressiveness of the synthesized speech. Audio samples are available at <a target="_blank" rel="noopener" href="https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/">https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/</a>. </p>
<blockquote>
<p>æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆé¢ä¸´ä¸€ä¸ªå›ºæœ‰çš„æŒ‘æˆ˜ï¼Œå³å¦‚ä½•æ ¹æ®å•ä¸€çš„æ–‡æœ¬è¾“å…¥ç”Ÿæˆå…·æœ‰ä¸åŒéŸµå¾‹çš„å¤šä¸ªè¯­éŸ³è¾“å‡ºã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶å·²ç»é€šè¿‡ä»æ–‡æœ¬å’Œè¯­éŸ³ä¸­é¢„æµ‹éŸµå¾‹ä¿¡æ¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†åœ¨è®¸å¤šåº”ç”¨ç¨‹åºä¸­éƒ½å¯è·å¾—çš„å…¶ä»–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚è§†é¢‘ï¼‰ä»æœªå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚æœ¬æ–‡æ¢è®¨äº†æ•´åˆè§†è§‰ä¸Šä¸‹æ–‡ä»¥å¢å¼ºéŸµå¾‹é¢„æµ‹çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¨¡å‹VisualSpeechï¼Œè¯¥æ¨¡å‹ç»“åˆäº†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œæ—¨åœ¨æ”¹å–„TTSä¸­çš„éŸµå¾‹ç”Ÿæˆã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥è§†è§‰ç‰¹å¾å¯æ”¹å–„éŸµå¾‹å»ºæ¨¡ï¼Œæé«˜åˆæˆè¯­éŸ³çš„è¡¨è¾¾åŠ›ã€‚éŸ³é¢‘æ ·æœ¬å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/">https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19258v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>éšç€æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆï¼ˆTTSï¼‰çš„å‘å±•ï¼Œå¯¹äºç»™å®šå•ä¸€æ–‡æœ¬è¾“å…¥äº§ç”Ÿå¤šç§ä¸åŒè¯­è°ƒè¾“å‡ºçš„æŒ‘æˆ˜æ„ˆå‘æ˜¾è‘—ã€‚å…ˆå‰çš„ç ”ç©¶é€šè¿‡é¢„æµ‹æ–‡æœ¬å’Œè¯­éŸ³ä¸­çš„éŸµå¾‹ä¿¡æ¯æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†å¿½ç•¥äº†å¯åˆ©ç”¨çš„é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚è§†é¢‘ä¿¡æ¯ã€‚æœ¬æ–‡æ¢ç´¢æ•´åˆè§†è§‰ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥æé«˜éŸµå¾‹é¢„æµ‹èƒ½åŠ›ã€‚æå‡ºäº†èåˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„å…¨æ–°æ¨¡å‹VisualSpeechï¼Œç”¨äºæ”¹è¿›TTSä¸­çš„éŸµå¾‹ç”Ÿæˆã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œèå…¥è§†è§‰ç‰¹å¾æœ‰åŠ©äºæ”¹å–„éŸµå¾‹å»ºæ¨¡ï¼Œæé«˜åˆæˆè¯­éŸ³çš„è¡¨è¾¾åŠ›ã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/">https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/</a>è·å–ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>TTSåˆæˆé¢ä¸´å•ä¸€æ–‡æœ¬è¾“å…¥äº§ç”Ÿå¤šæ ·è¯­éŸ³è¾“å‡ºçš„æŒ‘æˆ˜ã€‚</li>
<li>VisualSpeechæ¨¡å‹æ•´åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ä»¥æ”¹è¿›éŸµå¾‹ç”Ÿæˆã€‚</li>
<li>è§†è§‰ç‰¹å¾çš„èå…¥æé«˜äº†éŸµå¾‹å»ºæ¨¡çš„å‡†ç¡®åº¦ã€‚</li>
<li>è§†è§‰ä¸Šä¸‹æ–‡ä¿¡æ¯åœ¨å¢å¼ºè¯­éŸ³è¡¨è¾¾åŠ›æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚</li>
<li>VisualSpeechæ¨¡å‹å¯æé«˜TTSç³»ç»Ÿçš„æ€§èƒ½ï¼Œä½¿å…¶æ›´è‡ªç„¶ã€æ›´å¯Œæœ‰è¡¨ç°åŠ›ã€‚</li>
<li>éŸ³é¢‘æ ·æœ¬å±•ç¤ºäº†æ”¹è¿›åçš„è¯­éŸ³åˆæˆæ•ˆæœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4f3a3f18a3f09ce2fe085d82303e900e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6958f7bb32b2c3c23364206e03e226e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-679468f62b17ba913467ad7c51454110.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da9e3db4ef45450b3abb7461f194a0c7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-437f0974eda4de52c76f56d65ebc5910.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-20/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-20/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-20/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e83cfbcfc54ef6020ccbcdd7582e46ed.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-20  WP-CLIP Leveraging CLIP to Predict WÃ¶lfflin's Principles in Visual   Art
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-20/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-857881371a0aa747f6cc48c760feaa2f.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-20  Single-Reference Text-to-Image Manipulation with Dual Contrastive   Denoising Score
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30762.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
